From Steve_Burgess at worldonline.co.za  Sun Feb  1 09:39:22 2004
From: Steve_Burgess at worldonline.co.za (Steve Burgess)
Date: Sun, 1 Feb 2004 10:39:22 +0200
Subject: [R] Assistance with data import from Statistica
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAogciHeoUmkiKaxLqpQ+gKcKAAAAQAAAACakJBVvX9UyL0tIrnafzWgEAAAAA@worldonline.co.za>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040201/ed01de82/attachment.pl

From ozric at web.de  Sun Feb  1 10:30:31 2004
From: ozric at web.de (Christian Schulz)
Date: Sun, 1 Feb 2004 10:30:31 +0100
Subject: [R] Assistance with data import from Statistica
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAogciHeoUmkiKaxLqpQ+gKcKAAAAQAAAACakJBVvX9UyL0tIrnafzWgEAAAAA@worldonline.co.za>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAogciHeoUmkiKaxLqpQ+gKcKAAAAQAAAACakJBVvX9UyL0tIrnafzWgEAAAAA@worldonline.co.za>
Message-ID: <200402011030.32339.ozric@web.de>

I'm never work with Stats but 
IMHO you find in library(foreign)  all what you need.

cheers,christian

Am Sonntag, 1. Februar 2004 09:39 schrieb Steve Burgess:
> I am a new R user attempting to convert files from Statistica to R.  I
> can export from Statistica to SPSS .por format, but not to the SPSS .sav
> format.  Is there a procedure for easily accomplishing this, which will
> allow me to keep variable short and long labels (big surveys LOTS of
> time to replace all this work).
>
> Many thanks for sharing your time and knowledge.
>
> steve
>
> Dr Steven M Burgess
> Associate Director (Research)
> Professor of Business Administration in Marketing
> Graduate School of Business
> University of Cape Town
> Breakwater Campus, Portswood Road
> Greenpoint, Cape Town 8001
> South Africa
>
> Office:  Tel +27-21-406-1416, fax +27-21-406-1412
> Mobile:  Tel +27-83-226-2811
> Home:    Tel +27-21-791-3423, fax +27-21-791-3425
>
> "Confidentiality: This e-mail message is for the sole use of the
> intended recipient(s) and may contain confidential and privileged
> information. Any unauthorised review, use, disclosure or distribution is
> prohibited. If you are not the intended recipient, please contact the
> sender by reply e-mail and destroy all copies of the original message. I
> do not represent, warrant and/or guarantee that the integrity of this
> communication has been maintained nor that the communication is free of
> virus, interception or interference or errors caused by virus,
> interception or interference."
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From ozric at web.de  Sun Feb  1 11:10:45 2004
From: ozric at web.de (Christian Schulz)
Date: Sun, 1 Feb 2004 11:10:45 +0100
Subject: [R] Assistance with data import from Statistica
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAogciHeoUmkiKaxLqpQ+gKcKAAAAQAAAACakJBVvX9UyL0tIrnafzWgEAAAAA@worldonline.co.za>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAogciHeoUmkiKaxLqpQ+gKcKAAAAQAAAACakJBVvX9UyL0tIrnafzWgEAAAAA@worldonline.co.za>
Message-ID: <200402011110.45567.ozric@web.de>

oops , sorry i'm misreading you mean statistica not stata.
So i only have the notice that  the command-line utility
dataload is very usefuel.

One possible download is here:
http://www.steepturns.com/filedown/dataload.zip

,but i remember there exist a newer version which
could handle  *.Rdata files, too , but isn't downloadable from the original 
site at present!?

cheers, christian






Am Sonntag, 1. Februar 2004 09:39 schrieb Steve Burgess:
> I am a new R user attempting to convert files from Statistica to R.  I
> can export from Statistica to SPSS .por format, but not to the SPSS .sav
> format.  Is there a procedure for easily accomplishing this, which will
> allow me to keep variable short and long labels (big surveys LOTS of
> time to replace all this work).
>
> Many thanks for sharing your time and knowledge.
>
> steve
>
> Dr Steven M Burgess
> Associate Director (Research)
> Professor of Business Administration in Marketing
> Graduate School of Business
> University of Cape Town
> Breakwater Campus, Portswood Road
> Greenpoint, Cape Town 8001
> South Africa
>
> Office:  Tel +27-21-406-1416, fax +27-21-406-1412
> Mobile:  Tel +27-83-226-2811
> Home:    Tel +27-21-791-3423, fax +27-21-791-3425
>
> "Confidentiality: This e-mail message is for the sole use of the
> intended recipient(s) and may contain confidential and privileged
> information. Any unauthorised review, use, disclosure or distribution is
> prohibited. If you are not the intended recipient, please contact the
> sender by reply e-mail and destroy all copies of the original message. I
> do not represent, warrant and/or guarantee that the integrity of this
> communication has been maintained nor that the communication is free of
> virus, interception or interference or errors caused by virus,
> interception or interference."
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sun Feb  1 11:43:55 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 01 Feb 2004 11:43:55 +0100
Subject: [R] Assistance with data import from Statistica
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAogciHeoUmkiKaxLqpQ+gKcKAAAAQAAAACakJBVvX9UyL0tIrnafzWgEAAAAA@worldonline.co.za>
Message-ID: <401CD86B.344F4386@statistik.uni-dortmund.de>

Steve Burgess wrote:
> 
> I am a new R user attempting to convert files from Statistica to R.  I
> can export from Statistica to SPSS .por format, but not to the SPSS .sav
> format.  Is there a procedure for easily accomplishing this, which will
> allow me to keep variable short and long labels (big surveys LOTS of
> time to replace all this work).
> 
> Many thanks for sharing your time and knowledge.

What about using a database? (or ASCII files if nothing else works...)

Uwe Ligges



From p.dalgaard at biostat.ku.dk  Sun Feb  1 13:02:29 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Feb 2004 13:02:29 +0100
Subject: [R] Assistance with data import from Statistica
In-Reply-To: <401CD86B.344F4386@statistik.uni-dortmund.de>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAogciHeoUmkiKaxLqpQ+gKcKAAAAQAAAACakJBVvX9UyL0tIrnafzWgEAAAAA@worldonline.co.za>
	<401CD86B.344F4386@statistik.uni-dortmund.de>
Message-ID: <x2fzdvj9d6.fsf@biostat.ku.dk>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

> Steve Burgess wrote:
> > 
> > I am a new R user attempting to convert files from Statistica to R.  I
> > can export from Statistica to SPSS .por format, but not to the SPSS .sav
> > format.  Is there a procedure for easily accomplishing this, which will
> > allow me to keep variable short and long labels (big surveys LOTS of
> > time to replace all this work).
> > 
> > Many thanks for sharing your time and knowledge.
> 
> What about using a database? (or ASCII files if nothing else works...)

I suspect that was what Steve was trying to avoid...

According to our documentation, read.spss *should* be able to read
.por files:

    'read.spss' reads a file stored by the SPSS 'save' and 'export'
     commands and returns a list.

(and EXPORT is the SPSS for creating portable files).

Whether this is actually true and whether it also applies to labels,
should be worth an experiment to find out... Our code is based on the
PSPP code by Ben Pfaff and that seems to have deciphered the file
format ( http://www.gnu.org/software/pspp/manual/pspp_toc.html )
pretty well, but we may not have lifted enough of the code for
portable files.

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Sun Feb  1 13:23:42 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Feb 2004 13:23:42 +0100
Subject: [R] Assistance with data import from Statistica
In-Reply-To: <401CD86B.344F4386@statistik.uni-dortmund.de>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAogciHeoUmkiKaxLqpQ+gKcKAAAAQAAAACakJBVvX9UyL0tIrnafzWgEAAAAA@worldonline.co.za>
	<401CD86B.344F4386@statistik.uni-dortmund.de>
Message-ID: <x2ad43j8dt.fsf@biostat.ku.dk>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

> Steve Burgess wrote:
> > 
> > I am a new R user attempting to convert files from Statistica to R.  I
> > can export from Statistica to SPSS .por format, but not to the SPSS .sav
> > format.  Is there a procedure for easily accomplishing this, which will
> > allow me to keep variable short and long labels (big surveys LOTS of
> > time to replace all this work).
> > 
> > Many thanks for sharing your time and knowledge.
> 
> What about using a database? (or ASCII files if nothing else works...)

Action speaks louder than words:

> x <- read.spss("tate96.por")
> names(x)[1:10]
 [1] "ID"       "EMPLYEE"  "SMSKEY"   "SMSTZONE" "SMSSTATE" "SMSCNTY"
 [7] "SMSCD"    "SMSMSA"   "SMSREP"   "SMSSTRTA"
> attr(x,"variable.labels")[1:10]
                                        ID
              "Pre-election Respondent ID"
                                   EMPLYEE
             "Pre-election Interviewer ID"
                                    SMSKEY
                         "Sample Record $"
                                  SMSTZONE
                  "Pre-election Time Zone"
                                  SMSSTATE
            "Pre-election FIPS State Code"
                                   SMSCNTY
           "Pre-election FIPS County code"
                                     SMSCD
"Pre-election FIPS Congressional District"
                                    SMSMSA
              "Pre-election FIPS MSA Code"
                                    SMSREP
                                        ""
                                  SMSSTRTA
                                  "Strata"
> x <- read.spss("tate96.por")
> attr(x,"variable.labels")[1:5]
                            ID                        EMPLYEE
  "Pre-election Respondent ID"  "Pre-election Interviewer ID"
                        SMSKEY                       SMSTZONE
             "Sample Record $"       "Pre-election Time Zone"
                      SMSSTATE
"Pre-election FIPS State Code"
> levels(x[[4]])
[1] "Pacific"  "Mountain" "Eastern"  "Central"

...etc...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ggrothendieck at myway.com  Sun Feb  1 14:16:01 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun,  1 Feb 2004 08:16:01 -0500 (EST)
Subject: [R] Assistance with data import from Statistica
Message-ID: <20040201131601.4F238396D@mprdmxin.myway.com>



Unfortunately the dataload web site is down because
dataload is no longer longer being offered.  There is
a commercial offering called Stat Transfer (see
www.stattransfer.com) but I have never used it so don't
know more.

Date:   Sun, 1 Feb 2004 11:10:45 +0100 
From:   Christian Schulz <ozric at web.de>
To:   <Steve_Burgess at worldonline.co.za>, <R-help at stat.math.ethz.ch> 
Subject:   Re: [R] Assistance with data import from Statistica 

 
oops , sorry i'm misreading you mean statistica not stata.
So i only have the notice that the command-line utility
dataload is very usefuel.

One possible download is here:
http://www.steepturns.com/filedown/dataload.zip

,but i remember there exist a newer version which
could handle *.Rdata files, too , but isn't downloadable from the original 
site at present!?

cheers, christian






Am Sonntag, 1. Februar 2004 09:39 schrieb Steve Burgess:
> I am a new R user attempting to convert files from Statistica to R. I
> can export from Statistica to SPSS .por format, but not to the SPSS .sav
> format. Is there a procedure for easily accomplishing this, which will
> allow me to keep variable short and long labels (big surveys LOTS of
> time to replace all this work).
>
> Many thanks for sharing your time and knowledge.
>
> steve
>
> Dr Steven M Burgess
> Associate Director (Research)
> Professor of Business Administration in Marketing
> Graduate School of Business
> University of Cape Town
> Breakwater Campus, Portswood Road
> Greenpoint, Cape Town 8001
> South Africa
>
> Office: Tel +27-21-406-1416, fax +27-21-406-1412
> Mobile: Tel +27-83-226-2811
> Home: Tel +27-21-791-3423, fax +27-21-791-3425
>
> "Confidentiality: This e-mail message is for the sole use of the
> intended recipient(s) and may contain confidential and privileged
> information. Any unauthorised review, use, disclosure or distribution is
> prohibited. If you are not the intended recipient, please contact the
> sender by reply e-mail and destroy all copies of the original message. I
> do not represent, warrant and/or guarantee that the integrity of this
> communication has been maintained nor that the communication is free of
> virus, interception or interference or errors caused by virus,
> interception or interference."
>



From rvencio at ime.usp.br  Sun Feb  1 15:55:59 2004
From: rvencio at ime.usp.br (Ricardo Zorzetto Nicoliello Vencio)
Date: Sun, 1 Feb 2004 12:55:59 -0200 (BRST)
Subject: [R] I can't make .C(...) web-page example.
In-Reply-To: <200402011113.i11B4VxK022726@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0402011237080.27404-100000@kevlar.ime.usp.br>


Hi everyone!

I'm trying to lear how to call external C code in R but even the R help
web-page example is drive me crazy.

I copy-paste the example at:

http://stat.ethz.ch/R-manual/R-patched/doc/manual/R-exts.html#Interface%20functions%20.C%20and%20.Fortran

here is the example:

void convolve(double *a, int *na, double *b, int *nb, double *ab)
{
  int i, j, nab = *na + *nb - 1;

  for(i = 0; i < nab; i++)
    ab[i] = 0.0;
  for(i = 0; i < *na; i++)
    for(j = 0; j < *nb; j++)
      ab[i + j] += a[i] * b[j];
}

called from R by

conv <- function(a, b)
  .C("convolve",
     as.double(a),
     as.integer(length(a)),
     as.double(b),
     as.integer(length(b)),
     ab = double(length(a) + length(b) - 1))$ab


but using the conv function in simple examples give me trouble:

> conv(1:10,2:11)
Error in conv(1:10, 2:11) : pairlist object cannot be coerced to double

> conv( rnorm(10,10,1) , rnorm(10,11,1) )
Segmentation fault

> conv( c(10.53, 8.456, 6.6) , c(10.53, 8.456, 6.6) )
Error in conv(c(10.53, 8.456, 6.6), c(10.53, 8.456, 6.6)) :
        cannot allocate vector of length 1717986918

> a = c(1.46756, 5.56456, 2.3646)
> b = a + 5.4
> conv(a,b)
Error in conv(a, b) : cannot coerce type promise to double vector


and so on.

These results appear if I have only the .c file or if I use gcc -c conv.c
to create .o file. I cannot create executable because there is no
main(...) in .c file but just the copy-pasted example.


Someone knows what is happening to me ?



From ripley at stats.ox.ac.uk  Sun Feb  1 16:22:47 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 1 Feb 2004 15:22:47 +0000 (GMT)
Subject: [R] I can't make .C(...) web-page example.
In-Reply-To: <Pine.LNX.4.44.0402011237080.27404-100000@kevlar.ime.usp.br>
Message-ID: <Pine.LNX.4.44.0402011519190.16255-100000@gannet.stats>

Change the name.  There is a convolve C function in R 1.8.x (but not
R-devel) that is being found rather than yours.


On Sun, 1 Feb 2004, Ricardo Zorzetto Nicoliello Vencio wrote:

> 
> Hi everyone!
> 
> I'm trying to lear how to call external C code in R but even the R help
> web-page example is drive me crazy.
> 
> I copy-paste the example at:
> 
> http://stat.ethz.ch/R-manual/R-patched/doc/manual/R-exts.html#Interface%20functions%20.C%20and%20.Fortran
> 
> here is the example:
> 
> void convolve(double *a, int *na, double *b, int *nb, double *ab)
> {
>   int i, j, nab = *na + *nb - 1;
> 
>   for(i = 0; i < nab; i++)
>     ab[i] = 0.0;
>   for(i = 0; i < *na; i++)
>     for(j = 0; j < *nb; j++)
>       ab[i + j] += a[i] * b[j];
> }
> 
> called from R by
> 
> conv <- function(a, b)
>   .C("convolve",
>      as.double(a),
>      as.integer(length(a)),
>      as.double(b),
>      as.integer(length(b)),
>      ab = double(length(a) + length(b) - 1))$ab
> 
> 
> but using the conv function in simple examples give me trouble:
> 
> > conv(1:10,2:11)
> Error in conv(1:10, 2:11) : pairlist object cannot be coerced to double
> 
> > conv( rnorm(10,10,1) , rnorm(10,11,1) )
> Segmentation fault
> 
> > conv( c(10.53, 8.456, 6.6) , c(10.53, 8.456, 6.6) )
> Error in conv(c(10.53, 8.456, 6.6), c(10.53, 8.456, 6.6)) :
>         cannot allocate vector of length 1717986918
> 
> > a = c(1.46756, 5.56456, 2.3646)
> > b = a + 5.4
> > conv(a,b)
> Error in conv(a, b) : cannot coerce type promise to double vector
> 
> 
> and so on.
> 
> These results appear if I have only the .c file or if I use gcc -c conv.c
> to create .o file. I cannot create executable because there is no
> main(...) in .c file but just the copy-pasted example.
> 
> 
> Someone knows what is happening to me ?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jimclark at duke.edu  Sun Feb  1 16:13:48 2004
From: jimclark at duke.edu (Jim Clark)
Date: Sun, 01 Feb 2004 10:13:48 -0500
Subject: [R] coxph in R
Message-ID: <5.2.0.9.0.20040201101237.00a63800@mail-ji.acpub.duke.edu>

Where are the estimates of the baseline hazard in the output of coxph?

Thanks,
Jim


James S. Clark
H.L. Blomquist Professor
Department of Biology and Nicholas School of the Environment
Duke University
Durham, NC 27708
Biology: http://www.biology.duke.edu/research_by_area/eeob/clark.html
Center on Global Change: http://www.env.duke.edu/cgc/
Ecology Program: http://www.ecology.duke.edu/



From jimclark at duke.edu  Sun Feb  1 16:14:50 2004
From: jimclark at duke.edu (Jim Clark)
Date: Sun, 01 Feb 2004 10:14:50 -0500
Subject: [R] coxph
Message-ID: <5.2.0.9.0.20040201101421.00a63980@mail-ji.acpub.duke.edu>

Where are the estimates of the baseline hazard for coxph?

Thanks,
Jim

James S. Clark
H.L. Blomquist Professor
Department of Biology and Nicholas School of the Environment
Duke University
Durham, NC 27708
Biology: http://www.biology.duke.edu/research_by_area/eeob/clark.html
Center on Global Change: http://www.env.duke.edu/cgc/
Ecology Program: http://www.ecology.duke.edu/



From Rau at demogr.mpg.de  Sun Feb  1 16:32:01 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Sun, 1 Feb 2004 16:32:01 +0100
Subject: [R] I can't make .C(...) web-page example.
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A0642@hermes.demogr.mpg.de>

Hi!

I am by no means an R-expert nor a C-expert but the document "An
Introduction to .C Interface to R" by Roger D. Peng and  Jan de Leeuw helped
me a lot to find out how it works in principle to use the .C function call.
You can find it on the homepage of Roger D. Peng
(http://www.biostat.jhsph.edu/~rpeng/ ) at the following URL:
http://www.biostat.jhsph.edu/~rpeng/docs/interface.pdf


Hope this is what you were looking for.

Best,
Roland


> -----Original Message-----
> From:	Ricardo Zorzetto Nicoliello Vencio [SMTP:rvencio at ime.usp.br]
> Sent:	Sunday, February 01, 2004 3:56 PM
> To:	R-help at stat.math.ethz.ch
> Subject:	[R] I can't make .C(...) web-page example.
> 
> 
> Hi everyone!
> 
> I'm trying to lear how to call external C code in R but even the R help
> web-page example is drive me crazy.
> 
> I copy-paste the example at:
> 
> http://stat.ethz.ch/R-manual/R-patched/doc/manual/R-exts.html#Interface%20
> functions%20.C%20and%20.Fortran
> 
> here is the example:
> 
> void convolve(double *a, int *na, double *b, int *nb, double *ab)
> {
>   int i, j, nab = *na + *nb - 1;
> 
>   for(i = 0; i < nab; i++)
>     ab[i] = 0.0;
>   for(i = 0; i < *na; i++)
>     for(j = 0; j < *nb; j++)
>       ab[i + j] += a[i] * b[j];
> }
> 
> called from R by
> 
> conv <- function(a, b)
>   .C("convolve",
>      as.double(a),
>      as.integer(length(a)),
>      as.double(b),
>      as.integer(length(b)),
>      ab = double(length(a) + length(b) - 1))$ab
> 
> 
> but using the conv function in simple examples give me trouble:
> 
> > conv(1:10,2:11)
> Error in conv(1:10, 2:11) : pairlist object cannot be coerced to double
> 
> > conv( rnorm(10,10,1) , rnorm(10,11,1) )
> Segmentation fault
> 
> > conv( c(10.53, 8.456, 6.6) , c(10.53, 8.456, 6.6) )
> Error in conv(c(10.53, 8.456, 6.6), c(10.53, 8.456, 6.6)) :
>         cannot allocate vector of length 1717986918
> 
> > a = c(1.46756, 5.56456, 2.3646)
> > b = a + 5.4
> > conv(a,b)
> Error in conv(a, b) : cannot coerce type promise to double vector
> 
> 
> and so on.
> 
> These results appear if I have only the .c file or if I use gcc -c conv.c
> to create .o file. I cannot create executable because there is no
> main(...) in .c file but just the copy-pasted example.
> 
> 
> Someone knows what is happening to me ?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html


+++++
This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked.   If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.



From ligges at statistik.uni-dortmund.de  Sun Feb  1 16:34:46 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 01 Feb 2004 16:34:46 +0100
Subject: [R] I can't make .C(...) web-page example.
In-Reply-To: <Pine.LNX.4.44.0402011237080.27404-100000@kevlar.ime.usp.br>
References: <Pine.LNX.4.44.0402011237080.27404-100000@kevlar.ime.usp.br>
Message-ID: <401D1C96.20104@statistik.uni-dortmund.de>

Ricardo Zorzetto Nicoliello Vencio wrote:

> Hi everyone!
> 
> I'm trying to lear how to call external C code in R but even the R help
> web-page example is drive me crazy.
> 
> I copy-paste the example at:
> 
> http://stat.ethz.ch/R-manual/R-patched/doc/manual/R-exts.html#Interface%20functions%20.C%20and%20.Fortran
> 
> here is the example:
> 
> void convolve(double *a, int *na, double *b, int *nb, double *ab)
> {
>   int i, j, nab = *na + *nb - 1;
> 
>   for(i = 0; i < nab; i++)
>     ab[i] = 0.0;
>   for(i = 0; i < *na; i++)
>     for(j = 0; j < *nb; j++)
>       ab[i + j] += a[i] * b[j];
> }
> 
> called from R by
> 
> conv <- function(a, b)
>   .C("convolve",
>      as.double(a),
>      as.integer(length(a)),
>      as.double(b),
>      as.integer(length(b)),
>      ab = double(length(a) + length(b) - 1))$ab
> 
> 
> but using the conv function in simple examples give me trouble:
> 
> 
> conv(1:10,2:11)
 >
> Error in conv(1:10, 2:11) : pairlist object cannot be coerced to double
> 
> 
>>conv( rnorm(10,10,1) , rnorm(10,11,1) )
> 
> Segmentation fault
> 
> 
>>conv( c(10.53, 8.456, 6.6) , c(10.53, 8.456, 6.6) )
> 
> Error in conv(c(10.53, 8.456, 6.6), c(10.53, 8.456, 6.6)) :
>         cannot allocate vector of length 1717986918
> 
> 
>>a = c(1.46756, 5.56456, 2.3646)
>>b = a + 5.4
>>conv(a,b)
> 
> Error in conv(a, b) : cannot coerce type promise to double vector
> 
> 
> and so on.
> 
> These results appear if I have only the .c file or if I use gcc -c conv.c
> to create .o file. I cannot create executable because there is no
> main(...) in .c file but just the copy-pasted example.

Most easily, use the R wrapper to compile and link files as in:

R CMD SHLIB convolve.c
which produces an .so file you can dyn.load().
(If you are on Windows: Rcmd SHLIB makes a dll.)

Uwe Ligges


> 
> Someone knows what is happening to me ?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From q.liu at unn.ac.uk  Sun Feb  1 16:44:06 2004
From: q.liu at unn.ac.uk (Qin Liu)
Date: Sun, 1 Feb 2004 15:44:06 -0000
Subject: [R] CART: rapart vs bagging
Message-ID: <61B1A61B4F4AD711B3450008C791F6FA01BA1F8D@clearwater.unn.ac.uk>

Hi, 

Is here anyone knows the difference between rapart and bagging when grow a
CART tree? 

Thanks

Qin



From Siegfried.Macho at unifr.ch  Mon Feb  2 01:53:21 2004
From: Siegfried.Macho at unifr.ch (Siegfried.Macho)
Date: Sun, 01 Feb 2004 16:53:21 -0800
Subject: [R] 3 little questions
Message-ID: <5.1.0.14.0.20040201164550.0223c050@MAIL.UNIFR.CH>

Dear R-helpers,

3 questions:
1. Is there a package that contains a routine for computing Kendall's W 
(coefficient of concordance), with and without ties ?
2. Is there a package that contains a routine for computing Goodman' s Gamma.
3. I there a simple method for computing the number of ties as well as 
their lengths within a vector fo ranks,
e.g.
 >r1 <- rank(c(1, 3, 2, 3, 3, 2, 4))

gives:

[1] 1.0 5.0 2.5 5.0 5.0 2.5 7.0

which contains 2 ties with length 2 and 3.

Thanks in advance,
S.M


==============================================
Dr. Siegfried Macho
Department of Psychology
University of Fribourg
Rue de Faucigny 2
CH-1700 Fribourg

Tel.: +41-26-3007635
Fax.: +41-26-3009712
http://www.unifr.ch/psycho/general/macho.htm



From p.dalgaard at biostat.ku.dk  Sun Feb  1 17:22:57 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Feb 2004 17:22:57 +0100
Subject: [R] I can't make .C(...) web-page example.
In-Reply-To: <Pine.LNX.4.44.0402011237080.27404-100000@kevlar.ime.usp.br>
References: <Pine.LNX.4.44.0402011237080.27404-100000@kevlar.ime.usp.br>
Message-ID: <x265eqkbvi.fsf@biostat.ku.dk>

Ricardo Zorzetto Nicoliello Vencio <rvencio at ime.usp.br> writes:

> Hi everyone!
> 
> I'm trying to lear how to call external C code in R but even the R help
> web-page example is drive me crazy.
> 
> I copy-paste the example at:
> 
> http://stat.ethz.ch/R-manual/R-patched/doc/manual/R-exts.html#Interface%20functions%20.C%20and%20.Fortran
> 
> here is the example:
> 
> void convolve(double *a, int *na, double *b, int *nb, double *ab)
> {
>   int i, j, nab = *na + *nb - 1;
> 
>   for(i = 0; i < nab; i++)
>     ab[i] = 0.0;
>   for(i = 0; i < *na; i++)
>     for(j = 0; j < *nb; j++)
>       ab[i + j] += a[i] * b[j];
> }
> 
> called from R by
> 
> conv <- function(a, b)
>   .C("convolve",
>      as.double(a),
>      as.integer(length(a)),
>      as.double(b),
>      as.integer(length(b)),
>      ab = double(length(a) + length(b) - 1))$ab
> 
> 
> but using the conv function in simple examples give me trouble:
> 
> > conv(1:10,2:11)
> Error in conv(1:10, 2:11) : pairlist object cannot be coerced to double
> 
> > conv( rnorm(10,10,1) , rnorm(10,11,1) )
> Segmentation fault
> 
> > conv( c(10.53, 8.456, 6.6) , c(10.53, 8.456, 6.6) )
> Error in conv(c(10.53, 8.456, 6.6), c(10.53, 8.456, 6.6)) :
>         cannot allocate vector of length 1717986918
> 
> > a = c(1.46756, 5.56456, 2.3646)
> > b = a + 5.4
> > conv(a,b)
> Error in conv(a, b) : cannot coerce type promise to double vector
> 
> 
> and so on.
> 
> These results appear if I have only the .c file or if I use gcc -c conv.c
> to create .o file. I cannot create executable because there is no
> main(...) in .c file but just the copy-pasted example.
> 
> 
> Someone knows what is happening to me ?

Looks like you haven't quite understood how to generate a shared
library (R CMD SHLIB) and load it dynamically (dyn.load), and then
somehow pick up a different convolve entry point (doesn't seem
possible with Linux, but you're not tellig us what your system is...).
Either that or you managed to confuse R badly through some earlier
attempts to load the module.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Sun Feb  1 17:25:48 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 1 Feb 2004 16:25:48 +0000 (GMT)
Subject: [R] coxph in R
In-Reply-To: <5.2.0.9.0.20040201101237.00a63800@mail-ji.acpub.duke.edu>
Message-ID: <Pine.LNX.4.44.0402011621410.16322-100000@gannet.stats>

Nowhere.  They are not in Cox's (1972) paper either!  (One place is in the 
discussion of that paper, but the point is that they are an orthogonal 
concept to partial likelihood estimation of the coefficients.)

You use survfit() on a coxph fit object to compute them.

On Sun, 1 Feb 2004, Jim Clark wrote:

> Where are the estimates of the baseline hazard in the output of coxph?
> 
> Thanks,
> Jim
> 
> 
> James S. Clark
> H.L. Blomquist Professor
> Department of Biology and Nicholas School of the Environment
> Duke University
> Durham, NC 27708
> Biology: http://www.biology.duke.edu/research_by_area/eeob/clark.html
> Center on Global Change: http://www.env.duke.edu/cgc/
> Ecology Program: http://www.ecology.duke.edu/

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Sun Feb  1 17:33:10 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Feb 2004 17:33:10 +0100
Subject: [R] coxph
In-Reply-To: <5.2.0.9.0.20040201101421.00a63980@mail-ji.acpub.duke.edu>
References: <5.2.0.9.0.20040201101421.00a63980@mail-ji.acpub.duke.edu>
Message-ID: <x21xpekbeh.fsf@biostat.ku.dk>

Jim Clark <jimclark at duke.edu> writes:

[twice...]
> Where are the estimates of the baseline hazard for coxph?

That's not an estimable quantity. However, estimates of the integrated
hazard or the survival function can be obtained with basehaz(fit)
resp. survfit(fit).
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Sun Feb  1 18:30:16 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 1 Feb 2004 17:30:16 +0000 (GMT)
Subject: [R] I can't make .C(...) web-page example.
In-Reply-To: <x265eqkbvi.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0402011724460.16389-100000@gannet.stats>

On 1 Feb 2004, Peter Dalgaard wrote:

> Ricardo Zorzetto Nicoliello Vencio <rvencio at ime.usp.br> writes:
> 
> > Hi everyone!
> > 
> > I'm trying to lear how to call external C code in R but even the R help
> > web-page example is drive me crazy.
> > 
> > I copy-paste the example at:
> > 
> > http://stat.ethz.ch/R-manual/R-patched/doc/manual/R-exts.html#Interface%20functions%20.C%20and%20.Fortran
> > 
> > here is the example:
> > 
> > void convolve(double *a, int *na, double *b, int *nb, double *ab)
> > {
> >   int i, j, nab = *na + *nb - 1;
> > 
> >   for(i = 0; i < nab; i++)
> >     ab[i] = 0.0;
> >   for(i = 0; i < *na; i++)
> >     for(j = 0; j < *nb; j++)
> >       ab[i + j] += a[i] * b[j];
> > }
> > 
> > called from R by
> > 
> > conv <- function(a, b)
> >   .C("convolve",
> >      as.double(a),
> >      as.integer(length(a)),
> >      as.double(b),
> >      as.integer(length(b)),
> >      ab = double(length(a) + length(b) - 1))$ab
> > 
> > 
> > but using the conv function in simple examples give me trouble:
> > 
> > > conv(1:10,2:11)
> > Error in conv(1:10, 2:11) : pairlist object cannot be coerced to double
> > 
> > > conv( rnorm(10,10,1) , rnorm(10,11,1) )
> > Segmentation fault
> > 
> > > conv( c(10.53, 8.456, 6.6) , c(10.53, 8.456, 6.6) )
> > Error in conv(c(10.53, 8.456, 6.6), c(10.53, 8.456, 6.6)) :
> >         cannot allocate vector of length 1717986918
> > 
> > > a = c(1.46756, 5.56456, 2.3646)
> > > b = a + 5.4
> > > conv(a,b)
> > Error in conv(a, b) : cannot coerce type promise to double vector
> > 
> > 
> > and so on.
> > 
> > These results appear if I have only the .c file or if I use gcc -c conv.c
> > to create .o file. I cannot create executable because there is no
> > main(...) in .c file but just the copy-pasted example.
> > 
> > 
> > Someone knows what is happening to me ?
> 
> Looks like you haven't quite understood how to generate a shared
> library (R CMD SHLIB) and load it dynamically (dyn.load), and then
> somehow pick up a different convolve entry point (doesn't seem
> possible with Linux, but you're not tellig us what your system is...).
> Either that or you managed to confuse R badly through some earlier
> attempts to load the module.

There is an entry point convolve in package ts which is nowadays loaded by
default.  A week or so ago that one was being found under Windows even
after dynamically loading convolve.dll, so I renamed it in R-devel.  I got
the first error message listed above with that example.

If you try another name (convolve1, for example) it should either work or 
report that the symbol cannot be found, hence my suggestion to use another 
name.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Feb  1 18:39:11 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 1 Feb 2004 17:39:11 +0000 (GMT)
Subject: [R] CART: rapart vs bagging
In-Reply-To: <61B1A61B4F4AD711B3450008C791F6FA01BA1F8D@clearwater.unn.ac.uk>
Message-ID: <Pine.LNX.4.44.0402011730290.16389-100000@gannet.stats>

On Sun, 1 Feb 2004, Qin Liu wrote:

> Is here anyone knows the difference between rapart and bagging when grow a
> CART tree? 

Short answer: `Yes'.

Slightly longer answer: `rapart classification tree' is not something
Google knows about, and bagging is not to do with `grow a tree'.

More informative answer:

Bagging is a method to combine ensembles of classification trees, and
*rpart* is a package in R which does grow and prune classification trees.

CART is the trademark of a commercial program to grow and prune
classification trees.

Put `bagging Breiman' into Google to help you with the concept of bagging,
and then look at package ipred.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Feb  1 19:32:43 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 1 Feb 2004 18:32:43 +0000 (GMT)
Subject: [R] coxph
In-Reply-To: <x21xpekbeh.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0402011741200.16389-100000@gannet.stats>

On 1 Feb 2004, Peter Dalgaard wrote:

> Jim Clark <jimclark at duke.edu> writes:
> 
> [twice...]
> > Where are the estimates of the baseline hazard for coxph?
> 
> That's not an estimable quantity. However, estimates of the integrated
> hazard or the survival function can be obtained with basehaz(fit)
> resp. survfit(fit).

Not estimable?  Well, neither is the cumulative hazard/survival fnction 
then, as you only get estimates at the event times.

In both cases you need further assumptions on the hazard, which can be
smoothness or sum of delta functions or ....  

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Charles.Annis at statisticalengineering.com  Sun Feb  1 19:53:14 2004
From: Charles.Annis at statisticalengineering.com (Charles Annis, P.E.)
Date: Sun, 1 Feb 2004 13:53:14 -0500
Subject: [R] interactive 2-D plot interrogation
Message-ID: <200402011853.i11Iqxwd005695@hypatia.math.ethz.ch>

Greetings Friends:

I am trying to find a widget or some other method to let me interrogate a 
2-D image using the mouse.  I have a data.frame that I can visualize using
image() in R.  I would like to point to a pixel and have its coordinates
displayed.

I've read Peter Dalgaard's primer on R-Tcl/Tk, R-News, 1(3):27-31, and his
update R-News2(3):25-27, but am still struggling. 

Can anyone suggest a method for interactively interrogating of a 2-D image?

Many thanks.

Charles Annis, P.E.
 
Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  503-217-4849
http://www.StatisticalEngineering.com



From jinsong_zh at yahoo.com  Sun Feb  1 20:09:28 2004
From: jinsong_zh at yahoo.com (Jinsong Zhao)
Date: Sun, 1 Feb 2004 11:09:28 -0800 (PST)
Subject: [R] Stepwise Regression and PLS
Message-ID: <20040201190928.41718.qmail@web20805.mail.yahoo.com>

Dear all,

I am a newcomer to R. I intend to using R to do
stepwise regression and PLS with a data set (a 55x20
matrix, with one dependent and 19 independent
variable). Based on the same data set, I have done the
same work using SPSS and SAS. However, there is much
difference between the results obtained by R and SPSS
or SAS.

In the case of stepwise, SPSS gave out a model with 4
independent variable, but with step(), R gave out a
model with 10 and much higher R2. Furthermore,
regsubsets() also indicate the 10 variable is one of
the best regression subset. How to explain this
difference? And in the case of my data set, how many
variables that enter the model would be reasonable?

In the case of PLS, the results of mvr function of
pls.pcr package is also different with that of SAS.
Although the number of optimum latent variables is
same, the difference between R2 is much large. Why?

Any comment and suggestion is very appreciated. Thanks
in advance!

Best wishes,

Jinsong Zhao


=====
(Mr.) Jinsong Zhao
Ph.D. Candidate
School of the Environment
Nanjing University
22 Hankou Road, Nanjing 210093
P.R. China
E-mail: jinsong_zh at yahoo.com



From edd at debian.org  Sun Feb  1 20:23:13 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 1 Feb 2004 13:23:13 -0600
Subject: [R] interactive 2-D plot interrogation
In-Reply-To: <200402011853.i11Iqxwd005695@hypatia.math.ethz.ch>
References: <200402011853.i11Iqxwd005695@hypatia.math.ethz.ch>
Message-ID: <20040201192313.GA16233@sonny.eddelbuettel.com>

On Sun, Feb 01, 2004 at 01:53:14PM -0500, Charles Annis, P.E. wrote:
> Greetings Friends:
> 
> I am trying to find a widget or some other method to let me interrogate a 
> 2-D image using the mouse.  I have a data.frame that I can visualize using
> image() in R.  I would like to point to a pixel and have its coordinates
> displayed.
> 
> I've read Peter Dalgaard's primer on R-Tcl/Tk, R-News, 1(3):27-31, and his
> update R-News2(3):25-27, but am still struggling. 
> 
> Can anyone suggest a method for interactively interrogating of a 2-D image?

Look at the InteractiveTkrPlot example on James Wettenhall's site:
http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/InteractiveTkrPlot.html

His example is over discrete set of points, which you can adapt to find the
location with respect to curves or lines (which I did at work, where I can't
get to right now).

The key is that the 'widget' you bind to an event (like left-Mouse in his
example) get (x,y) pixel coordinates from the system which given appropriate
information from par() can be translated into your data coordinates in just
a few steps.

James' site is a treasure chest for R and tcltk. Highly recommended.

Hope this helps, Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From feh3k at spamcop.net  Sun Feb  1 20:31:34 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Sun, 1 Feb 2004 14:31:34 -0500
Subject: [R] Stepwise Regression and PLS
In-Reply-To: <20040201190928.41718.qmail@web20805.mail.yahoo.com>
References: <20040201190928.41718.qmail@web20805.mail.yahoo.com>
Message-ID: <20040201143134.1dbd5904.feh3k@spamcop.net>

On Sun, 1 Feb 2004 11:09:28 -0800 (PST)
Jinsong Zhao <jinsong_zh at yahoo.com> wrote:

> Dear all,
> 
> I am a newcomer to R. I intend to using R to do
> stepwise regression and PLS with a data set (a 55x20
> matrix, with one dependent and 19 independent
> variable). Based on the same data set, I have done the
> same work using SPSS and SAS. However, there is much
> difference between the results obtained by R and SPSS
> or SAS.
> 
> In the case of stepwise, SPSS gave out a model with 4
> independent variable, but with step(), R gave out a
> model with 10 and much higher R2. Furthermore,
> regsubsets() also indicate the 10 variable is one of
> the best regression subset. How to explain this
> difference? And in the case of my data set, how many
> variables that enter the model would be reasonable?
> 
> In the case of PLS, the results of mvr function of
> pls.pcr package is also different with that of SAS.
> Although the number of optimum latent variables is
> same, the difference between R2 is much large. Why?
> 
> Any comment and suggestion is very appreciated. Thanks
> in advance!
> 
> Best wishes,
> 
> Jinsong Zhao
> 

In your case SPSS, SAS, R, S-Plus, Stata, Systat, Statistica, and every
other package will agree in one sense, because results from all of them
will be virtually meaningless.  Simulate some data from a known model and
you'll quickly find out why stepwise variable selection is often a train
wreck.

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From p.dalgaard at biostat.ku.dk  Sun Feb  1 21:43:21 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Feb 2004 21:43:21 +0100
Subject: [R] coxph
In-Reply-To: <Pine.LNX.4.44.0402011741200.16389-100000@gannet.stats>
References: <Pine.LNX.4.44.0402011741200.16389-100000@gannet.stats>
Message-ID: <x2wu76il92.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On 1 Feb 2004, Peter Dalgaard wrote:
> 
> > Jim Clark <jimclark at duke.edu> writes:
> > 
> > [twice...]
> > > Where are the estimates of the baseline hazard for coxph?
> > 
> > That's not an estimable quantity. However, estimates of the integrated
> > hazard or the survival function can be obtained with basehaz(fit)
> > resp. survfit(fit).
> 
> Not estimable?  Well, neither is the cumulative hazard/survival fnction 
> then, as you only get estimates at the event times.
> 
> In both cases you need further assumptions on the hazard, which can be
> smoothness or sum of delta functions or ....  

Well.... This *is* quibbling you know. 

The relation is basically the same as with densities and distribution
functions. 

You can of course, if you want to, define the estimated hazard as a
sum of delta functions. However, it won't converge to the true hazard
function in any of the standard senses as n increases (although it
will in the distribution sense, but that is basically the point of
saying that its indefinite integral is estimable).

In contrast, you can define the integrated hazard function by
extending the value at event times as a right-continuous step function
and it will converge pointwise under relatively mild conditions (the
censoring mechanism cannot be too harsh and the regressors should
behave sensibly).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.murrell at auckland.ac.nz  Sun Feb  1 22:07:08 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 02 Feb 2004 10:07:08 +1300
Subject: [R] lines in 3d-cloud plot (lattice)
References: <401A4A7F.1050301@unibas.ch>	<200401301238.17940.deepayan@stat.wisc.edu>
	<Pine.SOL.4.58.0401301353340.2982@tetris.gpcc.itd.umich.edu>
Message-ID: <401D6A7C.1040507@stat.auckland.ac.nz>

Hi

Staying with Trellis graphics, and depending on what sort of lines you 
want to add, you could do something similar to persp() example # 2 using 
cloud() by writing your own panel.3d.cloud() function, which calls 
panel.3dscatter() and then does some further drawing.  This is an 
analogue to "the sequence plot(), followed by points() or
lines() in the base plotting functions", all done within a lattice panel 
function.  From a quick look at help(panel.cloud) it looks like the 
required transformation information is available via something like 
ltransform3dto3d().

Paul


Tom Blackwell wrote:
> Pascal  -
> 
> Getting away from Trellis graphics, you might consider using
> persp() with regular graphics.  Look at example # 2 under
> help("persp").
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Fri, 30 Jan 2004, Deepayan Sarkar wrote:
> 
> 
>>On Friday 30 January 2004 06:13, Pascal A. Niklaus wrote:
>>
>>>Hi all,
>>>
>>>I'd like to plot a set of data (x,y,z) as 3D-cloud, and add several line
>>>plots to the same 3D graph:
>>>
>>>Two questions:
>>>
>>>1) How do I connect points to get a line?
>>>
>>>
>>>>cloud(z~x*y,data=d,zlim=c(0,1))        # works
>>>>cloud(z~x*predict(l),data=d,zlim=c(0,1),type="l")   # type="l" doesn't
>>>
>>>Warning message:
>>>type = l not implemented, consider using 'panel.3d.cloud =
>>>panel.3dscatter.old' in: panel.3d.cloud(x = x, y = y, z = z, rot.mat =
>>>rot.mat, za = za,
>>
>>Well, have you considered taking the hint and try
>>
>>cloud(z~x*predict(l),data=d,zlim=c(0,1),type="l",
>>      panel.3d.cloud = panel.3dscatter.old)
>>
>>?
>>
>>
>>>help.search("panel.3d.cloud") also didn't report any hits.
>>
>>panel.3d.cloud is the name of an argument to the panel.cloud function.
>>See ?panel.cloud for details. (Unfortunately, the docs are a bit outdated).
>>
>>
>>Briefly, panel.3dscatter.old is a very simple function, that calculates the 2D
>>projections of the given 3D points and then calls panel.xyplot with those.
>>Any 'type' argument which works with panel.xyplot would also work here,
>>including 'p' and 'l'. But no consideration is made of the fact that these
>>are 3D data. For instance, type = 'h' would not give you what you would
>>expect.
>>
>>
>>panel.3dscatter (the newer version) is a bit more sophisticated. For type =
>>'p', it draws the points in order of increasing depth, so that closer points
>>overwrite distant ones. Unfortunately, a collection of line segments is not
>>well ordered, and I haven't decided yet what to do in that case (which is why
>>the older version is still retained).
>>
>>
>>
>>>2) How do I superimpose a second data set onto the same graph?
>>>
>>>(something equivalent to the sequence plot(), followed by points() or
>>>lines() in the base plotting functions)
>>
>>
>>I'm not sure what you mean. Trellis plots are not supposed to be used for two
>>unrelated data sets, they are typically very much dependent on the structure
>>of the data set. Maybe we could help if you give more details of what exactly
>>you want to do, but before that you should read the ?panel.cloud help page
>>carefully, since anything 'special' would almost invariably involve playing
>>with things documented there.
>>
>>Hth,
>>
>>Deepayan
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From p.murrell at auckland.ac.nz  Sun Feb  1 22:17:06 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 02 Feb 2004 10:17:06 +1300
Subject: [R] interactive 2-D plot interrogation
References: <200402011853.i11Iqxwd005695@hypatia.math.ethz.ch>
	<20040201192313.GA16233@sonny.eddelbuettel.com>
Message-ID: <401D6CD2.5070102@stat.auckland.ac.nz>

Hi

Depending on how you want the coordinates displayed, the locator() 
function may help you, or perhaps a simple function written around 
locator() to process its result into something more meaningful for your 
siutation.

Paul


Dirk Eddelbuettel wrote:
> On Sun, Feb 01, 2004 at 01:53:14PM -0500, Charles Annis, P.E. wrote:
> 
>>Greetings Friends:
>>
>>I am trying to find a widget or some other method to let me interrogate a 
>>2-D image using the mouse.  I have a data.frame that I can visualize using
>>image() in R.  I would like to point to a pixel and have its coordinates
>>displayed.
>>
>>I've read Peter Dalgaard's primer on R-Tcl/Tk, R-News, 1(3):27-31, and his
>>update R-News2(3):25-27, but am still struggling. 
>>
>>Can anyone suggest a method for interactively interrogating of a 2-D image?
> 
> 
> Look at the InteractiveTkrPlot example on James Wettenhall's site:
> http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/InteractiveTkrPlot.html
> 
> His example is over discrete set of points, which you can adapt to find the
> location with respect to curves or lines (which I did at work, where I can't
> get to right now).
> 
> The key is that the 'widget' you bind to an event (like left-Mouse in his
> example) get (x,y) pixel coordinates from the system which given appropriate
> information from par() can be translated into your data coordinates in just
> a few steps.
> 
> James' site is a treasure chest for R and tcltk. Highly recommended.
> 
> Hope this helps, Dirk
> 


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From p.murrell at auckland.ac.nz  Sun Feb  1 22:35:59 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 02 Feb 2004 10:35:59 +1300
Subject: [R] How to plot a small figure in a bigger one???
References: <401D555F@webmail.uic.edu>
Message-ID: <401D713F.1030605@stat.auckland.ac.nz>

Hi


jzhang10 wrote:
> Hi,
> I want to insert a small figure into a bigger plot. I saw people are doing 
> this all the time, but I just could not figure out how to do it in R.
> Thanks for your help!
> Jinfeng Zhang


There are a number of ways to do this in R;  some pointers to get you 
started ...

(i)  par(new=TRUE) allows you to overlay several plots on the same page
(ii) par(fig) and par(plt) provide fine control over where a plot 
appears on a page
(iii) accurately locating subplots within a bigger plot may require some 
conversions between coordinate systems;  par("usr"), par("plt"), ... can 
be used to obtain information on current coordinate systems
(iv) you can have all the transformations done for you, by using the 
grid package to create viewports and the gridBase package to align them 
with a bigger plot - see the recent R News article "Integrating grid 
Graphics Output with Base Graphics Output" 
(http://cran.stat.auckland.ac.nz/doc/Rnews/Rnews_2003-2.pdf)

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From risdpizza at yahoo.co.jp  Mon Feb  2 02:40:34 2004
From: risdpizza at yahoo.co.jp (SI)
Date: Mon, 2 Feb 2004 10:40:34 +0900 (JST)
Subject: [R] print comment lines on `sink'ed files?
Message-ID: <20040202014034.92101.qmail@web505.mail.yahoo.co.jp>

Hi,

I am using many comment lines like this
	#	a comment line
in a script.  Is there any way to print
comment lines when I use sink() function?
Or, are there any plans to include as
an option to sink() function in the near
future?  I would not want to use cat() 
function as it will look messy in the 
original script file.

Thanks!

SI

__________________________________________________




From ggrothendieck at myway.com  Mon Feb  2 03:22:15 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun,  1 Feb 2004 21:22:15 -0500 (EST)
Subject: [R] 3 little questions
Message-ID: <20040202022215.BE08A3986@mprdmxin.myway.com>



See ?cor.test
Also, 

  rowSums(outer(unique(r1),r1,"=="))

gives the number of occurrences of the elements of unique(r1)

---
Date:   Sun, 01 Feb 2004 16:53:21 -0800 
From:   Siegfried.Macho <Siegfried.Macho at unifr.ch>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] 3 little questions 

 
Dear R-helpers,

3 questions:
1. Is there a package that contains a routine for computing Kendall's W 
(coefficient of concordance), with and without ties ?
2. Is there a package that contains a routine for computing Goodman' s Gamma.
3. I there a simple method for computing the number of ties as well as 
their lengths within a vector fo ranks,
e.g.
>r1 <- rank(c(1, 3, 2, 3, 3, 2, 4))

gives:

[1] 1.0 5.0 2.5 5.0 5.0 2.5 7.0

which contains 2 ties with length 2 and 3.

Thanks in advance,
S.M


==============================================
Dr. Siegfried Macho
Department of Psychology
University of Fribourg
Rue de Faucigny 2
CH-1700 Fribourg



From jinsong_zh at yahoo.com  Mon Feb  2 04:13:49 2004
From: jinsong_zh at yahoo.com (Jinsong Zhao)
Date: Sun, 1 Feb 2004 19:13:49 -0800 (PST)
Subject: [R] Stepwise Regression and PLS
In-Reply-To: <20040201143134.1dbd5904.feh3k@spamcop.net>
Message-ID: <20040202031349.5160.qmail@web20805.mail.yahoo.com>


--- Frank E Harrell Jr <feh3k at spamcop.net> wrote:
> On Sun, 1 Feb 2004 11:09:28 -0800 (PST)
> Jinsong Zhao <jinsong_zh at yahoo.com> wrote:
> 
> > Dear all,
> > 
> > I am a newcomer to R. I intend to using R to do
> > stepwise regression and PLS with a data set (a
> 55x20
> > matrix, with one dependent and 19 independent
> > variable). Based on the same data set, I have done
> the
> > same work using SPSS and SAS. However, there is
> much
> > difference between the results obtained by R and
> SPSS
> > or SAS.
> > 
> > In the case of stepwise, SPSS gave out a model
> with 4
> > independent variable, but with step(), R gave out
> a
> > model with 10 and much higher R2. Furthermore,
> > regsubsets() also indicate the 10 variable is one
> of
> > the best regression subset. How to explain this
> > difference? And in the case of my data set, how
> many
> > variables that enter the model would be
> reasonable?
> > 
> > In the case of PLS, the results of mvr function of
> > pls.pcr package is also different with that of
> SAS.
> > Although the number of optimum latent variables is
> > same, the difference between R2 is much large.
> Why?
> > 
> > Any comment and suggestion is very appreciated.
> Thanks
> > in advance!
> > 
> > Best wishes,
> > 
> > Jinsong Zhao
> > 
> 
> In your case SPSS, SAS, R, S-Plus, Stata, Systat,
> Statistica, and every
> other package will agree in one sense, because
> results from all of them
> will be virtually meaningless.  Simulate some data
> from a known model and
> you'll quickly find out why stepwise variable
> selection is often a train
> wreck.
> 
> ---
> Frank E Harrell Jr   Professor and Chair          
> School of Medicine
>                      Department of Biostatistics  
> Vanderbilt University

For the case of stepwise regression, I have found that
the subsets I got using regsubsets() are collinear.
However, the variables in SPSS's result are not
collinear. I wonder what I should do to get a same or
better linear model.

Thanks!



From feh3k at spamcop.net  Mon Feb  2 04:42:31 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Sun, 1 Feb 2004 22:42:31 -0500
Subject: [R] Stepwise Regression and PLS
In-Reply-To: <20040202031349.5160.qmail@web20805.mail.yahoo.com>
References: <20040201143134.1dbd5904.feh3k@spamcop.net>
	<20040202031349.5160.qmail@web20805.mail.yahoo.com>
Message-ID: <20040201224231.5336fe77.feh3k@spamcop.net>

On Sun, 1 Feb 2004 19:13:49 -0800 (PST)
Jinsong Zhao <jinsong_zh at yahoo.com> wrote:

> 
> --- Frank E Harrell Jr <feh3k at spamcop.net> wrote:
> > On Sun, 1 Feb 2004 11:09:28 -0800 (PST)
> > Jinsong Zhao <jinsong_zh at yahoo.com> wrote:
> > 
> > > Dear all,
> > > 
> > > I am a newcomer to R. I intend to using R to do
> > > stepwise regression and PLS with a data set (a
> > 55x20
> > > matrix, with one dependent and 19 independent
> > > variable). Based on the same data set, I have done
> > the
> > > same work using SPSS and SAS. However, there is
> > much
> > > difference between the results obtained by R and
> > SPSS
> > > or SAS.
> > > 
> > > In the case of stepwise, SPSS gave out a model
> > with 4
> > > independent variable, but with step(), R gave out
> > a
> > > model with 10 and much higher R2. Furthermore,
> > > regsubsets() also indicate the 10 variable is one
> > of
> > > the best regression subset. How to explain this
> > > difference? And in the case of my data set, how
> > many
> > > variables that enter the model would be
> > reasonable?
> > > 
> > > In the case of PLS, the results of mvr function of
> > > pls.pcr package is also different with that of
> > SAS.
> > > Although the number of optimum latent variables is
> > > same, the difference between R2 is much large.
> > Why?
> > > 
> > > Any comment and suggestion is very appreciated.
> > Thanks
> > > in advance!
> > > 
> > > Best wishes,
> > > 
> > > Jinsong Zhao
> > > 
> > 
> > In your case SPSS, SAS, R, S-Plus, Stata, Systat,
> > Statistica, and every
> > other package will agree in one sense, because
> > results from all of them
> > will be virtually meaningless.  Simulate some data
> > from a known model and
> > you'll quickly find out why stepwise variable
> > selection is often a train
> > wreck.
> > 
> > ---
> > Frank E Harrell Jr   Professor and Chair          
> > School of Medicine
> >                      Department of Biostatistics  
> > Vanderbilt University
> 
> For the case of stepwise regression, I have found that
> the subsets I got using regsubsets() are collinear.
> However, the variables in SPSS's result are not
> collinear. I wonder what I should do to get a same or
> better linear model.

I think you missed the point.  None of the variable selection procedures
will provide results that have a fair probability of replicating in
another sample.

FH
---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From jinsong_zh at yahoo.com  Mon Feb  2 05:04:48 2004
From: jinsong_zh at yahoo.com (Jinsong Zhao)
Date: Sun, 1 Feb 2004 20:04:48 -0800 (PST)
Subject: [R] Stepwise Regression and PLS
In-Reply-To: <20040201224231.5336fe77.feh3k@spamcop.net>
Message-ID: <20040202040448.88152.qmail@web20808.mail.yahoo.com>


--- Frank E Harrell Jr <feh3k at spamcop.net> wrote:
> > 
> > For the case of stepwise regression, I have found
> that
> > the subsets I got using regsubsets() are
> collinear.
> > However, the variables in SPSS's result are not
> > collinear. I wonder what I should do to get a same
> or
> > better linear model.
> 
> I think you missed the point.  None of the variable
> selection procedures
> will provide results that have a fair probability of
> replicating in
> another sample.
> 
> FH
> ---
> Frank E Harrell Jr   Professor and Chair          
> School of Medicine
>                      Department of Biostatistics  
> Vanderbilt University

Do you mean different procedures will provide
different results? Maybe I don't understand your email
correctly. Now, I just hope I could get a reasonable
linear model using stepwise method in R, but I don't
know how to deal with collinear problem.

=====
(Mr.) Jinsong Zhao
Ph.D. Candidate
School of the Environment
Nanjing University
22 Hankou Road, Nanjing 210093
P.R. China
E-mail: jinsong_zh at yahoo.com



From glaziou at pasteur-kh.org  Mon Feb  2 05:07:40 2004
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Mon, 2 Feb 2004 11:07:40 +0700
Subject: [R] print comment lines on `sink'ed files?
In-Reply-To: <20040202014034.92101.qmail@web505.mail.yahoo.co.jp>
References: <20040202014034.92101.qmail@web505.mail.yahoo.co.jp>
Message-ID: <20040202040740.GB722@pasteur-kh.org>

SI <risdpizza at yahoo.co.jp> wrote:
> I am using many comment lines like this
> 	#	a comment line
> in a script.  Is there any way to print
> comment lines when I use sink() function?
> Or, are there any plans to include as
> an option to sink() function in the near
> future?  I would not want to use cat() 
> function as it will look messy in the 
> original script file.



Since you are using script files, you may not need to use R 
in an interactive session. One suggestion under unix would be:


cunegonde:~> R --no-save --quiet < test > saved
cunegonde:~> cat saved
> # a comment line
> i<-1:10
> outer(i,i,"*")
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    1    2    3    4    5    6    7    8    9    10
 [2,]    2    4    6    8   10   12   14   16   18    20
 [3,]    3    6    9   12   15   18   21   24   27    30
 [4,]    4    8   12   16   20   24   28   32   36    40
 [5,]    5   10   15   20   25   30   35   40   45    50
 [6,]    6   12   18   24   30   36   42   48   54    60
 [7,]    7   14   21   28   35   42   49   56   63    70
 [8,]    8   16   24   32   40   48   56   64   72    80
 [9,]    9   18   27   36   45   54   63   72   81    90
[10,]   10   20   30   40   50   60   70   80   90   100
> # the end
>

All commands including comments appear in the saved output.

HTH,

-- 
Philippe Glaziou
Epidemiologist



From cnlawren at olemiss.edu  Mon Feb  2 06:03:45 2004
From: cnlawren at olemiss.edu (Chris Lawrence)
Date: Sun, 01 Feb 2004 23:03:45 -0600
Subject: [R] Stepwise Regression and PLS
In-Reply-To: <20040202040448.88152.qmail@web20808.mail.yahoo.com>
References: <20040202040448.88152.qmail@web20808.mail.yahoo.com>
Message-ID: <401DDA31.4080908@olemiss.edu>

Jinsong Zhao wrote:

> Do you mean different procedures will provide different results? Maybe 
> I don't understand your email correctly. Now, I just hope I could get 
> a reasonable linear model using stepwise method in R, but I don't know 
> how to deal with collinear problem.

What Dr. Harrell means (in part) is that stepwise regression leads to 
models that often "overfit" the observed data pattern--i.e. models that 
are not generalizable.  More elaboration can be found here (including 
comments from Dr. Harrell):

http://www.gseis.ucla.edu/courses/ed230bc1/notes4/swprobs.html

Key quote: "Personally, I would no more let an automatic routine select 
my model than I would let some best-fit procedure pack my suitcase."  
The bottom line advice here would be: don't use stepwise regression.

Peter Kennedy, in "A Guide to Econometrics" (pp. 187-89) suggests the 
following options for dealing with collinearity:

1. "Do nothing."  The main problem in OLS when variables are collinear 
is that the estimated variances of the parameters are often inflated.
2. Obtain more data.
3. Formalize relationships among regressors (for example, in a 
simultaneous equation model).
4. Specify a relationship among the *parameters*.
5. Drop one or more variables.  (In essence, a subset of #4 where 
coefficients are set to zero.)
6. Incorporate estimates from other studies.  (A Bayesian might consider 
using a strong prior.)
7. Form a principal component from the variables, and use that instead.
8. Shrink the OLS estimates using the ridge or Stein estimators.

Hope this helps.


Chris

-- 
Dr. Chris Lawrence <cnlawren at olemiss.edu> - http://blog.lordsutch.com/



From andy_liaw at merck.com  Mon Feb  2 00:01:39 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 1 Feb 2004 18:01:39 -0500
Subject: [R] 3 little questions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76EA@usrymx25.merck.com>

> From: Siegfried.Macho
> 
> Dear R-helpers,
> 
> 3 questions:
> 1. Is there a package that contains a routine for computing 
> Kendall's W 
> (coefficient of concordance), with and without ties ?

Is that the same as Kendall's tau, as in cor(..., method="kendall")?

> 2. Is there a package that contains a routine for computing 
> Goodman' s Gamma.

Don't know, if you can find out by search on CRAN.

> 3. I there a simple method for computing the number of ties 
> as well as their lengths within a vector fo ranks,
> e.g.
>  >r1 <- rank(c(1, 3, 2, 3, 3, 2, 4))
> 
> gives:
> 
> [1] 1.0 5.0 2.5 5.0 5.0 2.5 7.0
> 
> which contains 2 ties with length 2 and 3.

Try table(), which gives you frequencies.

HTH,
Andy
 
> Thanks in advance,
> S.M
> 
> 
> ==============================================
> Dr. Siegfried Macho
> Department of Psychology
> University of Fribourg
> Rue de Faucigny 2
> CH-1700 Fribourg
> 
> Tel.: +41-26-3007635
> Fax.: +41-26-3009712
> http://www.unifr.ch/psycho/general/macho.htm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From risdpizza at yahoo.co.jp  Mon Feb  2 07:01:27 2004
From: risdpizza at yahoo.co.jp (SI)
Date: Mon, 2 Feb 2004 15:01:27 +0900 (JST)
Subject: [R] print comment lines on `sink'ed files?
Message-ID: <20040202060127.43769.qmail@web501.mail.yahoo.co.jp>

Thanks for your help, Phillipe.  You're right; I don't
need to use sink() function. I was using R for windows in
an interactive mode and have totally forgotten about batch
mode.

For others' reference I opened up a command prompt and
typed in:

  Rterm --no-save --quiet <test.R >test.log

and created test.log gave me the results I wanted.


Cheers, 

SI
-----------------
SI <risdpizza at yahoo.co.jp> wrote:
> I am using many comment lines like this
> 	#	a comment line
> in a script.  Is there any way to print
> comment lines when I use sink() function?
> Or, are there any plans to include as
> an option to sink() function in the near
> future?  I would not want to use cat() 
> function as it will look messy in the 
> original script file.



Since you are using script files, you may not need to use
R 
in an interactive session. One suggestion under unix would
be:


cunegonde:~> R --no-save --quiet < test > saved
cunegonde:~> cat saved
> # a comment line
> i<-1:10
> outer(i,i,"*")
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    1    2    3    4    5    6    7    8    9    10
 [2,]    2    4    6    8   10   12   14   16   18    20
 [3,]    3    6    9   12   15   18   21   24   27    30
 [4,]    4    8   12   16   20   24   28   32   36    40
 [5,]    5   10   15   20   25   30   35   40   45    50
 [6,]    6   12   18   24   30   36   42   48   54    60
 [7,]    7   14   21   28   35   42   49   56   63    70
 [8,]    8   16   24   32   40   48   56   64   72    80
 [9,]    9   18   27   36   45   54   63   72   81    90
[10,]   10   20   30   40   50   60   70   80   90   100
> # the end
>

All commands including comments appear in the saved
output.

HTH,

-- 
Philippe Glaziou
Epidemiologist
------------------
__________________________________________________




From MSchwartz at medanalytics.com  Mon Feb  2 07:01:55 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 02 Feb 2004 00:01:55 -0600
Subject: [R] 3 little questions
In-Reply-To: <20040202022215.BE08A3986@mprdmxin.myway.com>
References: <20040202022215.BE08A3986@mprdmxin.myway.com>
Message-ID: <1075701715.5825.107.camel@localhost.localdomain>

On Sun, 2004-02-01 at 20:22, Gabor Grothendieck wrote:
> See ?cor.test

I'll stand to be corrected here, but I do not believe that cor.test()
will work for Kendall's W, since it can only handle two variables.
Kendall's W is designed for >= 3 variables as a generalization of
rho/tau and Friedman's test.

There are some suggestions I have seen that estimations of Kendall's W
can be done by using the average of multiple pairwise Kendall's tau
across the variables, with two formula variations depending upon whether
there is an even or odd number of variables AND in the case of no ties.

I have also seen a suggestion that the R^2 from a one-way ANOVA yields
an approximation of Kendall's W. In fact, the SAS macro I reference
below uses this approach. 

However, each of the aforementioned approaches can vary from W and so
carries various caveats under certain conditions.

I have not seen anything searching on r-help or CRAN for Kendall's W and
I have not coded it myself. However, I did find one reference on the
s-news list at:

http://www.biostat.wustl.edu/archives/html/s-news/2001-03/msg00197.html

and I also located a SAS Macro called %MAGREE at:

http://ewe3.sas.com/techsup/download/stat/magree.html

If you are familiar with SAS, that might be helpful as well.

Another reference which has various formulas and worked examples for W
is:

Nonparametric Measures of Association
Jean Dickson Gibbons
Sage, 1993

With respect to gamma, I have worked through a methodology to calculate
this and some other measures in R, that I have planned to add to the
CrossTable() function in the gregmisc package. Unfortunately, I have not
yet completed the coding for several of the measures and the associated
ASE's and p values due to lack of time.

I have done gamma however and the code is below, starting with the
functions to compute concordant and discordant pairs. These approaches
(using a cross-tabulation and matrix partitioning) can save a fair
amount of time, if the number of "unique pairs" in the data is
substantially less than the total number of pairs.

# Calculate CONcordant Pairs in a table
# cycle through x[r, c] and multiply by
# sum(x elements below and to the right of x[r, c])
# x = table
concordant <- function(x)
{
  # get sum(matrix values > r AND > c)
  # for each matrix[r, c]
  mat.lr <- function(r, c)
  { 
    lr <- x[(r.x > r) & (c.x > c)]
    sum(lr)
  }

  # get row and column index for each
  # matrix element
  r.x <- row(x)
  c.x <- col(x)

  # return the sum of each matrix[r, c] * sums
  # using mapply to sequence thru each matrix[r, c]
  sum(x * mapply(mat.lr, r = r.x, c = c.x))
}

# Calculate DIScordant Pairs in a table
# cycle through x[r, c] and multiply by
# sum(x elements below and to the left of x[r, c])
# x = table
discordant <- function(x)
{
  # get sum(matrix values > r AND < c)
  # for each matrix[r, c]
  mat.ll <- function(r, c)
  { 
    ll <- x[(r.x > r) & (c.x < c)]
    sum(ll)
  }

  # get row and column index for each
  # matrix element
  r.x <- row(x)
  c.x <- col(x)

  # return the sum of each matrix[r, c] * sums
  # using mapply to sequence thru each matrix[r, c]
  sum(x * mapply(mat.ll, r = r.x, c = c.x))
}


# Calculate Goodman-Kruskal gamma
# x = table
calc.gamma <- function(x)
{
  c <- concordant(x)
  d <- discordant(x)

  gamma <- (c - d) / (c + d)

  gamma
}

Here is an example of use. Keep in mind that x is the cross tabulation
of two vectors of measures, in this example, yielding a 3 x 3 table:

> x <- matrix(c(70, 10, 27, 85, 134, 60, 15, 41, 100), ncol = 3)
> x
     [,1] [,2] [,3]
[1,]   70   85   15
[2,]   10  134   41
[3,]   27   60  100

> calc.gamma(x)
[1] 0.57045

If you have any questions on the above, let me know.

Hope this helps.

Marc Schwartz


On Sun, 2004-02-01 at 18:53, Siegfried.Macho wrote: 
> Dear R-helpers,
> 
> 3 questions:
> 1. Is there a package that contains a routine for computing Kendall's W 
> (coefficient of concordance), with and without ties ?
> 2. Is there a package that contains a routine for computing Goodman' s Gamma.
> 3. I there a simple method for computing the number of ties as well as 
> their lengths within a vector fo ranks,
> e.g.
>  >r1 <- rank(c(1, 3, 2, 3, 3, 2, 4))
> 
> gives:
> 
> [1] 1.0 5.0 2.5 5.0 5.0 2.5 7.0
> 
> which contains 2 ties with length 2 and 3.



From andy_liaw at merck.com  Mon Feb  2 02:03:24 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 1 Feb 2004 20:03:24 -0500
Subject: [R] CART: rapart vs bagging
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76EB@usrymx25.merck.com>

> From:  Qin Liu
> 
> Hi, 
> 
> Is here anyone knows the difference between rapart and 
> bagging when grow a
> CART tree? 

rpart produces one classification or regression tree.  Bagging is a general
technique for combining classifiers or regression models, usually trees,
from bootstrap samples.  The bagging() function in the `ipred' package just
loop over call to rpart().

Andy

 
> Thanks
> 
> Qin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From zh_jinsong at yahoo.com.cn  Sun Feb  1 15:05:15 2004
From: zh_jinsong at yahoo.com.cn (=?gb2312?q?Jinsong=20Zhao?=)
Date: Sun, 1 Feb 2004 22:05:15 +0800 (CST)
Subject: [R] Stepwise regression and PLS
Message-ID: <20040201140515.88747.qmail@web15410.mail.cnb.yahoo.com>

Dear all,

I am a newcomer to R. I intend to using R to do stepwise regression and
PLS with a data set (a 55x20 matrix, with one dependent and 19
independent variable). Based on the same data set, I have done the same
work using SPSS and SAS. However, there is much difference between the
results obtained by R and SPSS or SAS.

In the case of stepwise, SPSS gave out a model with 4 independent
variable, but with step(), R gave out a model with 10 and much higher
R2. Furthermore, regsubsets() also indicate the 10 variable is one of
the best regression subset. How to explain this difference? And in the
case of my data set, how many variables that enter the model would be
reasonable?

In the case of PLS, the results of mvr function of pls.pcr package is
also different with that of SAS. Although the number of optimum latent
variables is same, the difference between R2 is much large. Why?

Any comment and suggestion is very appreciated. Thanks in advance!

Best wishes,

Jinsong Zhao

=====
(Mr.) Jinsong Zhao
Ph.D. Candidate
School of the Environment
Nanjing University
No.22 Hankou Road, Najing 210093
P.R. China
E-mail: zh_jinsong at yahoo.com.cn

_________________________________________________________




From bhx2 at mevik.net  Mon Feb  2 09:48:19 2004
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Mon, 02 Feb 2004 09:48:19 +0100
Subject: [R] MATLAB to R
In-Reply-To: <4368A860.211D5ACA.0B088159@aol.com> (DivineSAAM@aol.com's
	message of "Fri, 30 Jan 2004 16:04:52 -0500")
References: <4368A860.211D5ACA.0B088159@aol.com>
Message-ID: <7o3c9tj298.fsf@foo.nemo-project.org>

DivineSAAM at aol.com writes:

> In MATLAB, I can write:
>
> for J=1:M
> Y(J+1)=Y(J)+ h * feval(f,T(J),Y(J));
> ...
>
> In R, I can write above as:
>
> for (J in 2:M)
> {
>  y = y + h * f(t,y)
> ...
> }

Are you sure this gives the same result?  If Y and T in Matlab are
vectors, I believe

for (J in 1:M)
{
  y[J+1] <- y[J] + h * f(tt[J], y[J])
  ...
}

is what you want.  (Don't use `t' as a variable; t() is the function
to transpose a matrix.)

> for J=1:M
> k1 = feval(f,T(J),Y(J));
> k2 = feval(f,T(J+1),Y(J)+ h * k1

I assume you mean k1(J) = ... and k2(J) = ...

> How do I write k2 in R?
> k1 = f(t,y)
> k2 = ?

## If f can take vector arguments:
k1 <- f(tt[-M],y)
k2 <- f(tt[-1], y+h*k1)
## Otherwise:
for (J in 1:M) {
  k1[J] <- f(tt[J], y[J])
  k2[J] <- f(tt[J+1], y[J] + h*k1[J])
}

-- 
Hth,
Bj?rn-Helge Mevik



From debrc.stage1 at bch.ap-hop-paris.fr  Mon Feb  2 10:32:07 2004
From: debrc.stage1 at bch.ap-hop-paris.fr (=?iso-8859-1?Q?xavi=E8re_panhard?=)
Date: Mon, 02 Feb 2004 10:32:07 +0100
Subject: [R] PLS discriminant analysis
Message-ID: <004101c3e96f$70082710$ed2101a4@biostat8>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040202/c1be390c/attachment.pl

From Simon.Fear at synequanon.com  Mon Feb  2 10:42:23 2004
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Mon, 2 Feb 2004 09:42:23 -0000
Subject: [R] how to keep functions while remove all other commands
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F021B7@synequanon01>

As an alternative to Petr's approach of using separate
directories, one can also write a function (which I find quite
useful in its own right) to separate ls() output by mode, e.g.

"lsd" <- function(splitby=mode, pos=1, ...) {
    lsout <- ls(pos=pos, ...)
    tapply(lsout,
      sapply(lsout, function(x) {splitby(get(x))}),
      invisible)
}

Given that, you can use expressions such as

rm(list=lsd()$numeric)
rm(list=lsd(splitby=class, all.names=T)$integer)

or to remove functions,

rm(list=lsd()$"function") # nb reserved word function needs quotes

this latter also removes `lsd` itself, so do also follow the advice
re keeping a copy of all your functions in a text file somewhere!

> -----Original Message-----
> On 24 Jan 2004 at 21:47, Yong Wang wrote:
> 
> > Dear all:
> > a quick question:
> > I am used to apply  rm(list=()) regularly to remove all old codes in
> > preventing them creeping in current analysis.however, with that
> > application, functions I wrote are also removed. please let me know
> > how to keep the thing you want while remove those you don't.
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From debene at unimc.it  Mon Feb  2 10:51:30 2004
From: debene at unimc.it (Luca De Benedictis)
Date: Mon, 02 Feb 2004 10:51:30 +0100
Subject: [R] ordering in dotplot
Message-ID: <401E1DA2.6080706@unimc.it>

Dear R-friends,

the dataset I am using (data.it) is organized as follows

partner    stp    btp    reg
hk    0.64    1    s
ger    0.27    1    d
tur    0.27    1    s
rom    0.24    1    s-f
por    0.24    1    s
spa    0.23    1    s
gre    0.22    1    d-f
aus    0.17    1    d
uk    0.16    1    s
be    0.16    1    d
arg    0.15    1    s
usa    0.13    1    d-f
fra    0.13    1    s
neth    0.05    1    s-f
pol    0.05    1    d
bra    0.04    1    s
ko    0.006    1    s
un    -0.009    2    d-f
svi    -0.022    2    s-f
cin    -0.040    2   d
ru    -0.074    2    d-f
mex    -0.077    2    s
...    ...    ...    ...

and plotting it using dotplot, I specified the script as:

library(lattice)
attach(data.ita)
dotplot(reg~stp | partner, data=data.ita, groups=btp,
            xlab=list("Data - 
it",cex=1.5),col=c("black","red"),aspect=0.3,as.table=TRUE,xlim=c(-1,1))
detach(data.ita)

In the resulting plot the variable "reg" is ordered alphabetically. 
Instead, I would like the variable to be plotted in the following order: 
"s", "s-f", "d", "d-f".
How can I do it?

Many thanks
Luca



From ccleland at optonline.net  Mon Feb  2 11:23:38 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 02 Feb 2004 05:23:38 -0500
Subject: [R] ordering in dotplot
In-Reply-To: <401E1DA2.6080706@unimc.it>
References: <401E1DA2.6080706@unimc.it>
Message-ID: <401E252A.3040308@optonline.net>

Luca De Benedictis wrote:
> the dataset I am using (data.it) is organized as follows
> ...    ...    ...    ...
> and plotting it using dotplot, I specified the script as:
> 
> library(lattice)
> attach(data.ita)
> dotplot(reg~stp | partner, data=data.ita, groups=btp,
>            xlab=list("Data - 
> it",cex=1.5),col=c("black","red"),aspect=0.3,as.table=TRUE,xlim=c(-1,1))
> detach(data.ita)
> 
> In the resulting plot the variable "reg" is ordered alphabetically. 
> Instead, I would like the variable to be plotted in the following order: 
> "s", "s-f", "d", "d-f".

Make that an ordered factor as follows:

data.it$reg <- ordered(data.it$reg, levels=c("s", "s-f", "d", "d-f"))

hope this helps,

Chuck Cleland

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From giampi at speech.kth.se  Mon Feb  2 11:28:44 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Mon, 2 Feb 2004 11:28:44 +0100 (CET)
Subject: [R] array of variable length vectors
In-Reply-To: <401E1DA2.6080706@unimc.it>
References: <401E1DA2.6080706@unimc.it>
Message-ID: <Pine.LNX.4.58.0402021116570.1347@bayes.speech.kth.se>

Hi,
I'd like to store N vectors of different lengths, and to be able to
access them with an index, and eventually free the memory for one
of them without modifying the indexes to the others.

In C this would be a vector of N pointers that point to memory cells
independently allocated.

For example

int *pv[3];

pv[0] = (int *) malloc(13 * sizeof(int));
pv[1] = (int *) malloc(7 * sizeof(int));
pv[2] = (int *) malloc(110 * sizeof(int));

free(pv[1])
...

What is the best data type (or class) in R to do such a thing?

Thank you!
Giampiero
_________________________________________________________
Giampiero Salvi, M.Sc.          www.speech.kth.se/~giampi
Speech, Music and Hearing       Tel:      +46-8-790 75 62
Royal Institute of Technology   Fax:      +46-8-790 78 54
Drottning Kristinasv. 31,  SE-100 44,  Stockholm,  Sweden



From B.Rowlingson at lancaster.ac.uk  Mon Feb  2 12:22:09 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 02 Feb 2004 11:22:09 +0000
Subject: [R] array of variable length vectors
In-Reply-To: <Pine.LNX.4.58.0402021116570.1347@bayes.speech.kth.se>
References: <401E1DA2.6080706@unimc.it>
	<Pine.LNX.4.58.0402021116570.1347@bayes.speech.kth.se>
Message-ID: <401E32E1.5030202@lancaster.ac.uk>

Giampiero Salvi wrote:
> Hi,
> I'd like to store N vectors of different lengths, and to be able to
> access them with an index, and eventually free the memory for one
> of them without modifying the indexes to the others.

> int *pv[3];
> 
> pv[0] = (int *) malloc(13 * sizeof(int));
> pv[1] = (int *) malloc(7 * sizeof(int));
> pv[2] = (int *) malloc(110 * sizeof(int));
> 
> free(pv[1])
> ...
> 
> What is the best data type (or class) in R to do such a thing?

  A list, with vector elements (index starts at 1 in R):

  pv = list()
  pv[[1]] = real(13)
  pv[[2]] = real(7)
  pv[[3]] = real(110)

  then the equivalent of freeing the memory and keeping the indexing 
would be:

  pv[[2]] = real(0)

  and NOT

  pv[[2]] = NULL  (which deletes element 2)

  *BUT* I dont know if R will really free() the memory at that point. 
You may need to force the garbage collection with gc()....

Baz



From ripley at stats.ox.ac.uk  Mon Feb  2 12:42:32 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 2 Feb 2004 11:42:32 +0000 (GMT)
Subject: [R] array of variable length vectors
In-Reply-To: <Pine.LNX.4.58.0402021116570.1347@bayes.speech.kth.se>
Message-ID: <Pine.LNX.4.44.0402021135410.3654-100000@gannet.stats>

On Mon, 2 Feb 2004, Giampiero Salvi wrote:

> Hi,
> I'd like to store N vectors of different lengths, and to be able to
> access them with an index, and eventually free the memory for one
> of them without modifying the indexes to the others.
> 
> In C this would be a vector of N pointers that point to memory cells
> independently allocated.
> 
> For example
> 
> int *pv[3];
> 
> pv[0] = (int *) malloc(13 * sizeof(int));
> pv[1] = (int *) malloc(7 * sizeof(int));
> pv[2] = (int *) malloc(110 * sizeof(int));
> 
> free(pv[1])
> ...
> 
> What is the best data type (or class) in R to do such a thing?

Sounds like an R list.  However, in R you cannot free memory, but what 
you can do (carefully) is to change the list element to NULL and then 
memory will be salvaged at a future garbage collection.

z <- vector("list", 3)
z[[1]] <- integer(13)
z[[2]] <- integer(7)
z[[3]] <- integer(110)

then

z[1] <- list(NULL)  # and not z[[1]] <- NULL

will potentially release the memory allocated for the first element.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From feh3k at spamcop.net  Mon Feb  2 12:43:44 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Mon, 2 Feb 2004 06:43:44 -0500
Subject: [R] Stepwise Regression and PLS
In-Reply-To: <20040202040336.4194.qmail@web20809.mail.yahoo.com>
References: <20040201224231.5336fe77.feh3k@spamcop.net>
	<20040202040336.4194.qmail@web20809.mail.yahoo.com>
Message-ID: <20040202064344.3d40f3b6.feh3k@spamcop.net>

On Sun, 1 Feb 2004 20:03:36 -0800 (PST)
Jinsong Zhao <jinsong_zh at yahoo.com> wrote:

> 
> --- Frank E Harrell Jr <feh3k at spamcop.net> wrote:
> > > 
> > > For the case of stepwise regression, I have found
> > that
> > > the subsets I got using regsubsets() are
> > collinear.
> > > However, the variables in SPSS's result are not
> > > collinear. I wonder what I should do to get a same
> > or
> > > better linear model.
> > 
> > I think you missed the point.  None of the variable
> > selection procedures
> > will provide results that have a fair probability of
> > replicating in
> > another sample.
> > 
> > FH
> > ---
> > Frank E Harrell Jr   Professor and Chair          
> > School of Medicine
> >                      Department of Biostatistics  
> > Vanderbilt University
> 
> Do you mean different procedures will provide
> different results? Maybe I don't understand your email
> correctly. Now, I just hope I could get a reasonable
> linear model using stepwise method in R, but I don't
> know how to deal with collinear problem.
> 
> =====
> (Mr.) Jinsong Zhao

No, I mean the SAME procedure will provide different results.  Use the
bootstrap, or use simulation to repeatedly sample from the same population
and the same true regression model.  You will see dramatically different
"final models" selected by same algorithm.  The algorithm is inherently
unstable unless perhaps you have a sample an order of magnitude larger
than the one you have.  See
http://www.pitt.edu/~wpilib/statfaq/regrfaq.html) which contains some good
references.

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From ligges at statistik.uni-dortmund.de  Mon Feb  2 12:48:42 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 02 Feb 2004 12:48:42 +0100
Subject: [R] array of variable length vectors
In-Reply-To: <Pine.LNX.4.58.0402021116570.1347@bayes.speech.kth.se>
References: <401E1DA2.6080706@unimc.it>
	<Pine.LNX.4.58.0402021116570.1347@bayes.speech.kth.se>
Message-ID: <401E391A.6060200@statistik.uni-dortmund.de>

Giampiero Salvi wrote:

> Hi,
> I'd like to store N vectors of different lengths, and to be able to
> access them with an index, and eventually free the memory for one
> of them without modifying the indexes to the others.
> 
> In C this would be a vector of N pointers that point to memory cells
> independently allocated.
> 
> For example
> 
> int *pv[3];
> 
> pv[0] = (int *) malloc(13 * sizeof(int));
> pv[1] = (int *) malloc(7 * sizeof(int));
> pv[2] = (int *) malloc(110 * sizeof(int));
> 
> free(pv[1])
> ...
> 
> What is the best data type (or class) in R to do such a thing?

See ?list

Uwe Ligges



From flom at ndri.org  Mon Feb  2 13:15:17 2004
From: flom at ndri.org (Peter Flom)
Date: Mon, 02 Feb 2004 07:15:17 -0500
Subject: [R] Stepwise Regression and PLS
Message-ID: <s01df90b.038@MAIL.NDRI.ORG>

Frank Harrell wrote

> I think you missed the point.  None of the variable
> selection procedures
> will provide results that have a fair probability of
> replicating in
> another sample.
> 
> FH


And Jinsong Zhao answered
<<<
Do you mean different procedures will provide
different results? Maybe I don't understand your email
correctly. Now, I just hope I could get a reasonable
linear model using stepwise method in R, but I don't
know how to deal with collinear problem.
>>>>

The problem is not with R, SAS, or SPSS, but with your desire to
produce "a reasonable linear model using stepwise".  Stepwise does not,
in general, produce reasonable linear models, nor does it produce 
models that are generally replicable.

This issue has been discussed here in the past, but there have been
more extensive discussions on SAS-L, or in numerous statistics books,
including Dr. Harrell's excellent one.

HTH

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



From kasia at darwin.epbi.cwru.edu  Mon Feb  2 14:42:18 2004
From: kasia at darwin.epbi.cwru.edu (Catherine Stein)
Date: Mon, 2 Feb 2004 08:42:18 -0500 (EST)
Subject: [R] for loops?
Message-ID: <Pine.OSF.4.30.0402020839560.161133-100000@darwin.epbi.cwru.edu>


Hello R people!

How can one use a for loop (or something similar) in R?  As I type in each
line, I get syntax errors... I'm just confused how much to type in at each
">" prompt.

Thanks for your help,
cathy



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Catherine M. Stein
Research Assistant, Tuberculosis Research Unit
Doctoral Candidate in Genetic Epidemiology
Department of Epidemiology and Biostatistics
Case Western Reserve University
office: (216)368-0875 or (216)778-1378
e-mail: kasia at darwin.cwru.edu, or cmstein at cwru.edu
http://darwin.cwru.edu/~kasia

EPBI Student Resources Page:
http://hal.epbi.cwru.edu/stures/
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From andy_liaw at merck.com  Mon Feb  2 15:19:37 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 2 Feb 2004 09:19:37 -0500
Subject: [R] PLS discriminant analysis
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76ED@usrymx25.merck.com>

You could have at least look on CRAN, where you would have found pls.pcr,
which does PLS and PC regression.

As to using PLS for discrimination, you might want to look at the gpls
package in the BioConductor suite.

Andy

> From: xavi?re panhard
> 
> Hi everyone, 
> 
> we would like to perform a PLS discriminant analysis with R.
> Does anyone knows if at least a PLS regression package is available?
> 
> Thanks by advance,
> 
> Xavi?re Panhard
> University Hospital Bichat - Claude Bernard
> Paris


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From andy_liaw at merck.com  Mon Feb  2 15:46:03 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 2 Feb 2004 09:46:03 -0500
Subject: [R] Stepwise Regression and PLS
Message-ID: <3A822319EB35174CA3714066D590DCD504AF76EE@usrymx25.merck.com>

Just a few more comments to what Chris said:

Collinearity usually arise in two situations:
1. Insufficient sample; i.e., data points that make the variables _not_ as
collinear are not included in the sample.
2. The variables are `naturally' correlated.

If it's the first, then #2 from the list Chris cited is an possible option.
Otherwise, I'd say shrinkage makes more sense than regressing on principal
components.  Both are in the same class of biased estimators, but one needs
to be lucky to have the first few PCs correlate well to the response in case
of PCR.  In any case, interpretation of model coefficients from such data
will likely be difficult.

Just my $0.02...

Andy

> From: Chris Lawrence
Peter Kennedy, in "A Guide to Econometrics" (pp. 187-89) suggests the 
following options for dealing with collinearity:

1. "Do nothing."  The main problem in OLS when variables are collinear 
is that the estimated variances of the parameters are often inflated.
2. Obtain more data.
3. Formalize relationships among regressors (for example, in a 
simultaneous equation model).
4. Specify a relationship among the *parameters*.
5. Drop one or more variables.  (In essence, a subset of #4 where 
coefficients are set to zero.)
6. Incorporate estimates from other studies.  (A Bayesian might consider 
using a strong prior.)
7. Form a principal component from the variables, and use that instead.
8. Shrink the OLS estimates using the ridge or Stein estimators.





------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From theis at statistik.uni-dortmund.de  Mon Feb  2 17:36:15 2004
From: theis at statistik.uni-dortmund.de (Winfried Theis)
Date: 02 Feb 2004 17:36:15 +0100
Subject: [R] for loops?
In-Reply-To: <Pine.OSF.4.30.0402020839560.161133-100000@darwin.epbi.cwru.edu>
References: <Pine.OSF.4.30.0402020839560.161133-100000@darwin.epbi.cwru.edu>
Message-ID: <1075739775.2562.47.camel@malepartus>

Hello Cathy

you should open some curly brackets after the "for" statement e.g.

for(i in 1:1000){
print("Hello!")
print(sum(15+i*3))
}

or simlarly. But please keep in mind that R is rather slow with loops.
So have a look at apply & friends and check if you can rephrase your
problem to use them.

cheers,

Winni
On Mon, 2004-02-02 at 14:42, Catherine Stein wrote:
> 
> Hello R people!
> 
> How can one use a for loop (or something similar) in R?  As I type in each
> line, I get syntax errors... I'm just confused how much to type in at each
> ">" prompt.
> 
> Thanks for your help,
> cathy
> 
> 
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Catherine M. Stein
> Research Assistant, Tuberculosis Research Unit
> Doctoral Candidate in Genetic Epidemiology
> Department of Epidemiology and Biostatistics
> Case Western Reserve University
> office: (216)368-0875 or (216)778-1378
> e-mail: kasia at darwin.cwru.edu, or cmstein at cwru.edu
> http://darwin.cwru.edu/~kasia
> 
> EPBI Student Resources Page:
> http://hal.epbi.cwru.edu/stures/
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-- 
---------------------------------------------------------------------
Dipl.-Math. Winfried Theis
SFB 475, Fachbereich Statistik, Universit"at Dortmund, 44221 Dortmund
Tel.: +49-231-755-5903 FAX: +49-231-755-4387



From prodrigues at dcc.fc.up.pt  Mon Feb  2 16:08:26 2004
From: prodrigues at dcc.fc.up.pt (Pedro Rodrigues)
Date: 02 Feb 2004 15:08:26 +0000
Subject: [R] for loops?
In-Reply-To: <Pine.OSF.4.30.0402020839560.161133-100000@darwin.epbi.cwru.edu>
References: <Pine.OSF.4.30.0402020839560.161133-100000@darwin.epbi.cwru.edu>
Message-ID: <1075734506.3080.23.camel@atlantic.ocean>

On Mon, 2004-02-02 at 13:42, Catherine Stein wrote:
> Hello R people!
> 
> How can one use a for loop (or something similar) in R?  As I type in each
> line, I get syntax errors... I'm just confused how much to type in at each
> ">" prompt.
> 
> Thanks for your help,
> cathy

Hello.

I believe you want something like:

for(i in 1:n){
...some lines here...
}

If you have only one line within the for loop you can use it without the
brackets.

If the environment is still open (as within the for loop) you will not
get a new ">" prompt but a "+" prompt to continue as if you were writing
on the same line.

Only when you close the brackets the prompt will return to ">" after
executing the for loop.

Hope this will help.

Pedro

-- 
-----------------------------------------------------------
   Pedro Pereira Rodrigues
   http://www.dcc.fc.up.pt/~prodrigues/

   Phone: +351 226078830 - Ext: 121
   Snail: Department of Computer Science
	  Faculty of Sciences - University of Porto
	  Rua do Campo Alegre, 823
	  4150-180 Porto - Portugal



From B.Rowlingson at lancaster.ac.uk  Mon Feb  2 16:18:07 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 02 Feb 2004 15:18:07 +0000
Subject: [R] for loops?
In-Reply-To: <Pine.OSF.4.30.0402020839560.161133-100000@darwin.epbi.cwru.edu>
References: <Pine.OSF.4.30.0402020839560.161133-100000@darwin.epbi.cwru.edu>
Message-ID: <401E6A2F.8010001@lancaster.ac.uk>

Catherine Stein wrote:

> How can one use a for loop (or something similar) in R?  As I type in each
> line, I get syntax errors... I'm just confused how much to type in at each
> ">" prompt.
> 

  Have you read help("for") (you need to quote 'for' here to avoid a 
syntax error!)?

  If you'd shown us exactly what you'd typed we could probably help 
better. Suppose you want to loop from 1 to 10 and print it. You can do 
the following, where '>' is the R prompt (dont type it):

  > for(i in 1:10)print(i)
     - ie all on one line

  > for(i in 1:10){print(i)}
     - with curly brackets

  > for(i in 1:10)
  + print(i)

    - where '+' is the continuation prompt (dont type it) - R gives you 
this when it realises you havent written a complete expression yet.

  > for(i in 1:10) {
  + print(i)
  + }

     - curly brackets enclose as many expressions as you like inside the 
loop.

  > for(i in 1:10)
  + { print(i)
  + }

     - curly brackets anywhere. R works it out.

  You can even do, and I didn't think this would work...

  > for(i in
  + 1:10)
  + {print(i)}


  So in short, I cant get it to give a syntax error :) What are you 
doing? What version of R, and what platform?

Baz



From petr.pikal at precheza.cz  Mon Feb  2 16:19:15 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 02 Feb 2004 16:19:15 +0100
Subject: [R] for loops?
In-Reply-To: <Pine.OSF.4.30.0402020839560.161133-100000@darwin.epbi.cwru.edu>
Message-ID: <401E7883.14191.10A5CD7@localhost>

Hi

On 2 Feb 2004 at 8:42, Catherine Stein wrote:

> 
> Hello R people!
> 
> How can one use a for loop (or something similar) in R?  As I type in
> each line, I get syntax errors... I'm just confused how much to type

Use curly braces
for (i in ...) {

your long commands
in several lines

}

"An Introduction to R" in doc directory is your best friend.

Cheers
Petr

> in at each ">" prompt.
> 
> Thanks for your help,
> cathy
> 
> 
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ~~~~~~~~~ Catherine M. Stein Research Assistant, Tuberculosis Research
> Unit Doctoral Candidate in Genetic Epidemiology Department of
> Epidemiology and Biostatistics Case Western Reserve University office:
> (216)368-0875 or (216)778-1378 e-mail: kasia at darwin.cwru.edu, or
> cmstein at cwru.edu http://darwin.cwru.edu/~kasia
> 
> EPBI Student Resources Page:
> http://hal.epbi.cwru.edu/stures/
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ~~~~~~
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From andel at ifi.unizh.ch  Mon Feb  2 18:03:19 2004
From: andel at ifi.unizh.ch (David Andel)
Date: 2 Feb 2004 18:03:19 +0100
Subject: [R] axes in boxplots
Message-ID: <401E82D7.4000504@ifi.unizh.ch>

Hi

I am struggling with controlling the axes of boxplots. I need to produce 
two horizontal boxplots with the same x-axis for comparison purposes.
But when I generate a plot(c(-12,8), c(-6,1), type="n") first, then the 
following boxplot always overwrites it! I went into the code of 
boxplot.default, but even that without success.

Thanks for any hint!

David



From Ivailo.Partchev at uni-jena.de  Mon Feb  2 18:18:04 2004
From: Ivailo.Partchev at uni-jena.de (Ivailo Partchev)
Date: Mon, 02 Feb 2004 18:18:04 +0100
Subject: [R] filled contour + points
Message-ID: <401E864C.70501@uni-jena.de>

Hello

I have a small problem with filled contour plots. I'd like to plot point 
on top of that using points(). Trouble is, the x axis of the contour 
plot is modified to make room for the legend but points() is not aware 
of that. It could be easily tackled by using a linear transformation of 
x in points(), but does anyone know exactly  *what* transformation?

Kind regards

Ivailo Partchev



From ligges at statistik.uni-dortmund.de  Mon Feb  2 18:19:53 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 02 Feb 2004 18:19:53 +0100
Subject: [R] axes in boxplots
In-Reply-To: <401E82D7.4000504@ifi.unizh.ch>
References: <401E82D7.4000504@ifi.unizh.ch>
Message-ID: <401E86B9.8010706@statistik.uni-dortmund.de>

David Andel wrote:

> Hi
> 
> I am struggling with controlling the axes of boxplots. I need to produce 
> two horizontal boxplots with the same x-axis for comparison purposes.
> But when I generate a plot(c(-12,8), c(-6,1), type="n") first, then the 
> following boxplot always overwrites it! I went into the code of 
> boxplot.default, but even that without success.
> 	
> Thanks for any hint!

  boxplot(dat1, dat2, horizontal=TRUE)
plots 2 parallel boxplots of dat1 and dat2 respectively.

Uwe Ligges



From tlumley at u.washington.edu  Mon Feb  2 18:47:32 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 2 Feb 2004 09:47:32 -0800 (PST)
Subject: [R] Stepwise regression and PLS
In-Reply-To: <20040201140515.88747.qmail@web15410.mail.cnb.yahoo.com>
References: <20040201140515.88747.qmail@web15410.mail.cnb.yahoo.com>
Message-ID: <Pine.A41.4.58.0402020937340.45400@homer27.u.washington.edu>

On Sun, 1 Feb 2004, [gb2312] Jinsong Zhao wrote:

>
> In the case of stepwise, SPSS gave out a model with 4 independent
> variable, but with step(), R gave out a model with 10 and much higher
> R2. Furthermore, regsubsets() also indicate the 10 variable is one of
> the best regression subset. How to explain this difference? And in the
> case of my data set, how many variables that enter the model would be
> reasonable?
>

Most likely because step() uses AIC and SPSS uses a p-value criterion, so
the models are `best' in different ways.   regsubsets() gives best models
of each size, so it doesn't address the 4 vs 10 issue.

This isn't what regsubsets() is intended for.  If you want a single model
for prediction, you need a method based on an honest estimate of
prediction error and if you want a single model to explain relationships
you need to think about relationships.

While people seem to want to use it for finding a single model,
the purpose of regsubsets() is to give you many models,  precisely as a
way around the problem of instability everyone else has pointed out.
Given a large number of models you can see what features
are common to them, or you can do a crude but reasonably effective
approximation to model averaging.


	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From rpeng at jhsph.edu  Mon Feb  2 19:03:25 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 02 Feb 2004 13:03:25 -0500
Subject: [R] filled contour + points
In-Reply-To: <401E864C.70501@uni-jena.de>
References: <401E864C.70501@uni-jena.de>
Message-ID: <401E90ED.1010008@jhsph.edu>

Rather than transform the points, you can use the 
`plot.axes' argument to filled.contour() and call points() 
from there.

-roger

Ivailo Partchev wrote:
> Hello
> 
> I have a small problem with filled contour plots. I'd like to plot point 
> on top of that using points(). Trouble is, the x axis of the contour 
> plot is modified to make room for the legend but points() is not aware 
> of that. It could be easily tackled by using a linear transformation of 
> x in points(), but does anyone know exactly  *what* transformation?
> 
> Kind regards
> 
> Ivailo Partchev
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From chuck at bureau13.cc.uky.edu  Mon Feb  2 19:29:14 2004
From: chuck at bureau13.cc.uky.edu (Charles F. Fisher)
Date: Mon, 2 Feb 2004 13:29:14 -0500
Subject: [R] problem building R on HPUX 11.23
Message-ID: <20040202132914.A24350@bureau13>

When building the X11 modules under HPUX 11.23 I get the following errors

ld: Unsatisfied symbol "Rf_isNull" in file dataentry.lo
ld: Unsatisfied symbol "Rf_length" in file dataentry.lo
ld: Unsatisfied symbol "Rf_warningcall" in file devX11.lo
ld: Unsatisfied symbol "UNIMPLEMENTED" in file dataentry.lo
ld: Unsatisfied symbol "R_alloc" in file devX11.lo
ld: Unsatisfied symbol "R_GlobalEnv" in file dataentry.lo
ld: Unsatisfied symbol "R_setX11Routines" in file devX11.lo
ld: Unsatisfied symbol "Rf_devNumber" in file devX11.lo
ld: Unsatisfied symbol "Rf_elt" in file devX11.lo
ld: Unsatisfied symbol "R_NaInt" in file dataentry.lo

I assume I need to link in an R library built earlier; which library would 
I need?

Please reply directly, as I am not on the list.

Thanks
Chuck Fisher
chuck at uky.edu



From cstrato at aon.at  Mon Feb  2 20:28:51 2004
From: cstrato at aon.at (cstrato)
Date: Mon, 02 Feb 2004 20:28:51 +0100
Subject: [R] Robust nonlinear regression - sin(x)/x?
In-Reply-To: <401AA785.5010609@aon.at>
References: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>	<3FC51AB5.6020806@aon.at>
	<401AA785.5010609@aon.at>
Message-ID: <401EA4F3.70303@aon.at>

Dear all

Since I did not receive any answer to my general question (?),
let me ask a concrete question:

How can I fit the simple function y = a*sin(x)/b*x?

This is the code that I tried, but nls gives an error:

x <- seq(1,10,0.1)
y <- sin(x)/x
plot(x,y)
z <- jitter(y,amount=0.1)
plot(x,z)
df <- as.data.frame(cbind(x,z))
nf <- nls(z ~ a*sin(x)/b*x, data=df,
           start=list(a=0.8,b=0.9), trace = TRUE)

I have followed the Puromycin sample which works fine:
Pur.wt <- nls(rate ~ (Vm * conc)/(K + conc), data = Treated,
               start = list(Vm = 200, K = 0.1), trace = TRUE)

Do I make some mistake or is it not possible to fit sin(x)/x?

Thank you in advance
Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._


cstrato wrote:
> Dear R experts
> 
> This is a general question:
> Does R have functions for nonlinear robust regression,
> analogous to e.g. LTS?
> 
> Searching google I have found
> 1, an abstract to generalize LTS for nonlinear regression
> models, see: http://smealsearch.psu.edu/1509.html
> 2, an AD-model builder, see: http://otter-rsch.com/admodel/cc1.html
> but no mention of R/S
> 
> Thank you in advance
> Best regards
> Christian
> _._._._._._._._._._._._._._._._
> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a       A.u.s.t.r.i.a
> _._._._._._._._._._._._._._._._
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From spencer.graves at pdf.com  Mon Feb  2 20:46:08 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 02 Feb 2004 11:46:08 -0800
Subject: [R] Robust nonlinear regression - sin(x)/x?
In-Reply-To: <401EA4F3.70303@aon.at>
References: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>	<3FC51AB5.6020806@aon.at>	<401AA785.5010609@aon.at>
	<401EA4F3.70303@aon.at>
Message-ID: <401EA900.1060600@pdf.com>

      You didn't tell us what the error message nls gave, but it should 
be obvious:  You can estimate either a or b in this model (or their 
ratio), but you can't estimate both.  See any good book on nonlinear 
regression, e.g., Bates and Watts (1988) Nonlinear Regression and Its 
Applications (Wiley). 

      With that simplification, the equation is linear. 

      However, I see another problem:  If x is 0, sin(x)/x is "NaN".  
For a situation like this, I typically write a function to first compute 
"sin(x)/x", then test for x being 0 or very small, and replace the value 
in such cases with a more accurate Taylor series or asymptotic expansion. 

      hope this helps. 
      spencer graves

cstrato wrote:

> Dear all
>
> Since I did not receive any answer to my general question (?),
> let me ask a concrete question:
>
> How can I fit the simple function y = a*sin(x)/b*x?
>
> This is the code that I tried, but nls gives an error:
>
> x <- seq(1,10,0.1)
> y <- sin(x)/x
> plot(x,y)
> z <- jitter(y,amount=0.1)
> plot(x,z)
> df <- as.data.frame(cbind(x,z))
> nf <- nls(z ~ a*sin(x)/b*x, data=df,
>           start=list(a=0.8,b=0.9), trace = TRUE)
>
> I have followed the Puromycin sample which works fine:
> Pur.wt <- nls(rate ~ (Vm * conc)/(K + conc), data = Treated,
>               start = list(Vm = 200, K = 0.1), trace = TRUE)
>
> Do I make some mistake or is it not possible to fit sin(x)/x?
>
> Thank you in advance
> Best regards
> Christian
> _._._._._._._._._._._._._._._._
> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a       A.u.s.t.r.i.a
> _._._._._._._._._._._._._._._._
>
>
> cstrato wrote:
>
>> Dear R experts
>>
>> This is a general question:
>> Does R have functions for nonlinear robust regression,
>> analogous to e.g. LTS?
>>
>> Searching google I have found
>> 1, an abstract to generalize LTS for nonlinear regression
>> models, see: http://smealsearch.psu.edu/1509.html
>> 2, an AD-model builder, see: http://otter-rsch.com/admodel/cc1.html
>> but no mention of R/S
>>
>> Thank you in advance
>> Best regards
>> Christian
>> _._._._._._._._._._._._._._._._
>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>> V.i.e.n.n.a       A.u.s.t.r.i.a
>> _._._._._._._._._._._._._._._._
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From rvaradha at jhsph.edu  Mon Feb  2 20:46:42 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Mon, 02 Feb 2004 14:46:42 -0500
Subject: [R] Robust nonlinear regression - sin(x)/x?
Message-ID: <87591e8763d2.8763d287591e@jhsph.edu>

You reall have only one parameter in your model, c = a/b. You can't 
identify both a and b from your model, therefore, you should fit the 
linear model:  lm(z ~ c* sin(x)/x)

Ravi.

----- Original Message -----
From: cstrato <cstrato at aon.at>
Date: Monday, February 2, 2004 2:28 pm
Subject: [R] Robust nonlinear regression - sin(x)/x?

> Dear all
> 
> Since I did not receive any answer to my general question (?),
> let me ask a concrete question:
> 
> How can I fit the simple function y = a*sin(x)/b*x?
> 
> This is the code that I tried, but nls gives an error:
> 
> x <- seq(1,10,0.1)
> y <- sin(x)/x
> plot(x,y)
> z <- jitter(y,amount=0.1)
> plot(x,z)
> df <- as.data.frame(cbind(x,z))
> nf <- nls(z ~ a*sin(x)/b*x, data=df,
>           start=list(a=0.8,b=0.9), trace = TRUE)
> 
> I have followed the Puromycin sample which works fine:
> Pur.wt <- nls(rate ~ (Vm * conc)/(K + conc), data = Treated,
>               start = list(Vm = 200, K = 0.1), trace = TRUE)
> 
> Do I make some mistake or is it not possible to fit sin(x)/x?
> 
> Thank you in advance
> Best regards
> Christian
> _._._._._._._._._._._._._._._._
> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a       A.u.s.t.r.i.a
> _._._._._._._._._._._._._._._._
> 
> 
> cstrato wrote:
> > Dear R experts
> > 
> > This is a general question:
> > Does R have functions for nonlinear robust regression,
> > analogous to e.g. LTS?
> > 
> > Searching google I have found
> > 1, an abstract to generalize LTS for nonlinear regression
> > models, see: http://smealsearch.psu.edu/1509.html
> > 2, an AD-model builder, see: http://otter-rsch.com/admodel/cc1.html
> > but no mention of R/S
> > 
> > Thank you in advance
> > Best regards
> > Christian
> > _._._._._._._._._._._._._._._._
> > C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> > V.i.e.n.n.a       A.u.s.t.r.i.a
> > _._._._._._._._._._._._._._._._
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From p.dalgaard at biostat.ku.dk  Mon Feb  2 20:57:16 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Feb 2004 20:57:16 +0100
Subject: [R] Robust nonlinear regression - sin(x)/x?
In-Reply-To: <401EA4F3.70303@aon.at>
References: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>
	<3FC51AB5.6020806@aon.at> <401AA785.5010609@aon.at>
	<401EA4F3.70303@aon.at>
Message-ID: <x2isip45lv.fsf@biostat.ku.dk>

cstrato <cstrato at aon.at> writes:

> Dear all
> 
> Since I did not receive any answer to my general question (?),
> let me ask a concrete question:
> 
> How can I fit the simple function y = a*sin(x)/b*x?
> 
> This is the code that I tried, but nls gives an error:
> 
> x <- seq(1,10,0.1)
> y <- sin(x)/x
> plot(x,y)
> z <- jitter(y,amount=0.1)
> plot(x,z)
> df <- as.data.frame(cbind(x,z))
> nf <- nls(z ~ a*sin(x)/b*x, data=df,
>            start=list(a=0.8,b=0.9), trace = TRUE)
> 
> I have followed the Puromycin sample which works fine:
> Pur.wt <- nls(rate ~ (Vm * conc)/(K + conc), data = Treated,
>                start = list(Vm = 200, K = 0.1), trace = TRUE)
> 
> Do I make some mistake or is it not possible to fit sin(x)/x?

The expression only depends on a/b so you cannot estimate both.

Besides, you need to check up on operator precedence and
associativity: What you wrote is equivalent to a*sin(x)*x/b.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From yunfang at yahoo-inc.com  Mon Feb  2 20:59:21 2004
From: yunfang at yahoo-inc.com (Yun-Fang Juan)
Date: Mon, 2 Feb 2004 11:59:21 -0800
Subject: [R] memory problem for R --Summary
References: <3A822319EB35174CA3714066D590DCD504AF76D6@usrymx25.merck.com>
Message-ID: <023201c3e9c7$0cc9a090$90ea7ecf@YUNFANG2>

Thank you very much for the replies you have sent me regarding the memory
problem.
The following is the summary
(I tried to read all the messages through. I apologized if I overlooked your
message)

Cheers,

Yun-Fang
----------------------------
Backgrounds:
a. Data: 1million rows with 73 numeric attributes
b. Environment: R 1.7.1 on FreeBSD 4.3 with  2GB memory and double CPU
   Pentium III/Pentium III Xeon/Celeron
    with  data seg size (kbytes) =1572864  limit

Suggested Solutions:
z. use SAS since SAS is not trying to read all the data into RAM.
a. random sampling from the large data set i.e. 10% of 1 million rows
    (the option singular.ok=TRUE can be used in lm for singular matrice.)
b. use kalman filter with migration variance =0. ( see the dse package for
details)
c. add the following configuration: options(object.size=1e8)
   Results:  still OOM
d. if data is all numeric, add colClasses="numeric" in read.table()
   Results: read.table read in the data successfully but I failed to access
the dataset after the loading
(even dataset[1:10,] didn't work)

----- Original Message -----
From: "Liaw, Andy" <andy_liaw at merck.com>
To: "'Yun-Fang Juan'" <yunfang at yahoo-inc.com>; "Prof Brian Ripley"
<ripley at stats.ox.ac.uk>
Cc: <r-help at stat.math.ethz.ch>
Sent: Friday, January 30, 2004 11:44 AM
Subject: RE: [R] memory problem for R


> You still have not read the posting guide, have you?
>
> See more below.
>
> > From: Yun-Fang Juan
>
> [...]
>
> > I tried 10% sample and it turned out the matrix became
> > singular after I did that.
> > Ther reason is some of the attributes only have zero values
> > most of the time.
> > The data i am using is web log data and after some
> > transformation, they are all numeric.
> > Can we specify some parameters in read.table so that the
> > program will treat all the vars as numeric
> > (with this context, hopefully that will reduce the memory
> > consumption)  ?
>
> and you clearly have not read my (private) reply, either, in which I told
> you *exactly* how to do that, via the colClasses argument to read.table().
>
> Please take the help given to you seriously.  If you want attention, you
> have to pay attention.
>
> Andy
>
> > thanks a lot,
> >
> > Yun-Fang
>
>
> --------------------------------------------------------------------------
----
> Notice:  This e-mail message, together with any attachments, contains
> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New
> Jersey, USA 08889), and/or its affiliates (which may be known outside the
> United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as
> Banyu) that may be confidential, proprietary copyrighted and/or legally
> privileged. It is intended solely for the use of the individual or entity
> named on this message.  If you are not the intended recipient, and have
> received this message in error, please notify us immediately by reply
e-mail
> and then delete it from your system.
> --------------------------------------------------------------------------
----
>
>



From sjordan at princeton.edu  Mon Feb  2 21:02:59 2004
From: sjordan at princeton.edu (Stuart V Jordan)
Date: Mon, 2 Feb 2004 15:02:59 -0500
Subject: [R] mvrnorm problem
Message-ID: <000001c3e9c7$cddd9340$28287080@WWS7X5TK31>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040202/14c190d7/attachment.pl

From smelov at mac.com  Mon Feb  2 21:13:33 2004
From: smelov at mac.com (Simon Melov)
Date: Mon, 2 Feb 2004 12:13:33 -0800
Subject: [R] ordering and plotting question
Message-ID: <46C633BF-55BC-11D8-9478-000A956F2984@mac.com>

Hi,
I am trying to plot several rows out of a list of thousands. I have 40 
columns, and about 16,000 rows with the following Df structure.

ID X01 X02 X03..X40
AI456 45 64 23...
AI943 14 3 45 ..
AI278 78 12 68..
BW768 -2 -7 34..
...

My question is, I have a list of 100 IDs generated elsewhere 
(Df-"Ofinterest"), I would like to plot the 100 IDs from that data 
frame over the 40 columns (40 points per ID, with each column being 1 x 
value). But I cant figure out how to retrieve the values from the main 
Df and plot them. Ive tried looking at order, rank etc, but these seem 
to apply to numbers, and not text strings.

thanks

Simon.



From rvaradha at jhsph.edu  Mon Feb  2 21:19:00 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Mon, 02 Feb 2004 15:19:00 -0500
Subject: [R] Robust nonlinear regression - sin(x)/x?
Message-ID: <886999885841.885841886999@jhsph.edu>

A small correction to my previous email:
You actually specify the following call to lm:

y <- sin(x)/x
lm(z ~ y - 1)

to make sure that the intercept is not estimated.

Ravi.

----- Original Message -----
From: Ravi Varadhan <rvaradha at jhsph.edu>
Date: Monday, February 2, 2004 2:46 pm
Subject: Re: [R] Robust nonlinear regression - sin(x)/x?

> You reall have only one parameter in your model, c = a/b. You 
> can't 
> identify both a and b from your model, therefore, you should fit 
> the 
> linear model:  lm(z ~ c* sin(x)/x)
> 
> Ravi.
> 
> ----- Original Message -----
> From: cstrato <cstrato at aon.at>
> Date: Monday, February 2, 2004 2:28 pm
> Subject: [R] Robust nonlinear regression - sin(x)/x?
> 
> > Dear all
> > 
> > Since I did not receive any answer to my general question (?),
> > let me ask a concrete question:
> > 
> > How can I fit the simple function y = a*sin(x)/b*x?
> > 
> > This is the code that I tried, but nls gives an error:
> > 
> > x <- seq(1,10,0.1)
> > y <- sin(x)/x
> > plot(x,y)
> > z <- jitter(y,amount=0.1)
> > plot(x,z)
> > df <- as.data.frame(cbind(x,z))
> > nf <- nls(z ~ a*sin(x)/b*x, data=df,
> >           start=list(a=0.8,b=0.9), trace = TRUE)
> > 
> > I have followed the Puromycin sample which works fine:
> > Pur.wt <- nls(rate ~ (Vm * conc)/(K + conc), data = Treated,
> >               start = list(Vm = 200, K = 0.1), trace = TRUE)
> > 
> > Do I make some mistake or is it not possible to fit sin(x)/x?
> > 
> > Thank you in advance
> > Best regards
> > Christian
> > _._._._._._._._._._._._._._._._
> > C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> > V.i.e.n.n.a       A.u.s.t.r.i.a
> > _._._._._._._._._._._._._._._._
> > 
> > 
> > cstrato wrote:
> > > Dear R experts
> > > 
> > > This is a general question:
> > > Does R have functions for nonlinear robust regression,
> > > analogous to e.g. LTS?
> > > 
> > > Searching google I have found
> > > 1, an abstract to generalize LTS for nonlinear regression
> > > models, see: http://smealsearch.psu.edu/1509.html
> > > 2, an AD-model builder, see: http://otter-
> rsch.com/admodel/cc1.html> > but no mention of R/S
> > > 
> > > Thank you in advance
> > > Best regards
> > > Christian
> > > _._._._._._._._._._._._._._._._
> > > C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> > > V.i.e.n.n.a       A.u.s.t.r.i.a
> > > _._._._._._._._._._._._._._._._
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > > 
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-
> project.org/posting-
> > guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From cstrato at aon.at  Mon Feb  2 22:09:31 2004
From: cstrato at aon.at (cstrato)
Date: Mon, 02 Feb 2004 22:09:31 +0100
Subject: [R] Robust nonlinear regression - sin(x)/x?
In-Reply-To: <x2isip45lv.fsf@biostat.ku.dk>
References: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>	<3FC51AB5.6020806@aon.at>
	<401AA785.5010609@aon.at>	<401EA4F3.70303@aon.at>
	<x2isip45lv.fsf@biostat.ku.dk>
Message-ID: <401EBC8B.3010908@aon.at>

Dear all

Thank you very much this time for the fast response and
your many comments, and sorry for the stupid mistake.

1, The following gives the following error:
nf <- nls(z ~ a*sin(x)/(b*x), data=df,
                   start=list(a=0.8,b=0.9), trace = TRUE)
Error in nlsModel(formula, mf, start) : singular gradient matrix at 
initial parameter estimates

2, However, as Peter Dalgaard mentioned, the following
gives the correct result:
nf <- nls(z ~ c*sin(x)/x, data=df,
                   start=list(c=0.5), trace = TRUE)
2.113783 :  0.5
0.3187204 :  1.022591

3, Now to the question of robust nonlinear fitting:
Let me introduce some outliers:
z1 <- z
z1[c(6,12,13,34,36,42,67,69,72,76)] <- 
c(0.8,0.9,0.8,-0.5,-0.4,-0.6,0.5,0.6,0.8,0.7)
plot(x,z1)
df1 <- as.data.frame(cbind(x,z1))

Now, the fit gives:
nf1 <- nls(z1 ~ c*sin(x)/x, data=df1,
                   start=list(c=0.5), trace = TRUE)
4.814774 :  0.5
2.072135 :  1.145962

The true result should be   c=1.0
fitting w/o outliers gives  c=1.023
fitting with outliers gives c=1.146
Can this fit considered to be robust?

Best regards
Christian


Peter Dalgaard wrote:

> cstrato <cstrato at aon.at> writes:
> 
> 
>>Dear all
>>
>>Since I did not receive any answer to my general question (?),
>>let me ask a concrete question:
>>
>>How can I fit the simple function y = a*sin(x)/b*x?
>>
>>This is the code that I tried, but nls gives an error:
>>
>>x <- seq(1,10,0.1)
>>y <- sin(x)/x
>>plot(x,y)
>>z <- jitter(y,amount=0.1)
>>plot(x,z)
>>df <- as.data.frame(cbind(x,z))
>>nf <- nls(z ~ a*sin(x)/b*x, data=df,
>>           start=list(a=0.8,b=0.9), trace = TRUE)
>>
>>I have followed the Puromycin sample which works fine:
>>Pur.wt <- nls(rate ~ (Vm * conc)/(K + conc), data = Treated,
>>               start = list(Vm = 200, K = 0.1), trace = TRUE)
>>
>>Do I make some mistake or is it not possible to fit sin(x)/x?
> 
> 
> The expression only depends on a/b so you cannot estimate both.
> 
> Besides, you need to check up on operator precedence and
> associativity: What you wrote is equivalent to a*sin(x)*x/b.
>



From Venherm.Borchers at t-online.de  Mon Feb  2 22:25:56 2004
From: Venherm.Borchers at t-online.de (Hans W Borchers)
Date: Mon, 02 Feb 2004 22:25:56 +0100
Subject: [R] Nearest Neighbor Algorithm in R -- again.
Message-ID: <401EC064.6000609@t-online.de>

Several of the methods I use for analyzing large data sets, such as

  WinGamma: determining the level of noise in data
  Relief-F: estimating the influence of variables

depend on finding the k nearest neighbors of a point in a data frame or
matrix efficiently. (For large data sets it is not feasible to compute
the 'dist' matrix anyway.)

Seeing the proposed solution to "[R] distance between two matrices"
last month for finding _one_ nearest neighbor I came up with a solution
'nearest(A, n, k)' as appended.

Still, this is very clumsy and slow if you have to find the 3 nearest
neighbors for 1000 points in a data frame with 100000 entries at least
-- about 2 secs per data point on my computer or half an hour for an
application from real life.

Are there better/faster ways to perform this task using R functions?
Even better, is there a free implementation of kd-trees that I could
utilize (the one I found did not conform to the ANSI C standard)?

Someome pointed to 'spdep' of the R-Sig-Geo project, but 'knearneigh'
only accepts 2D data points.

Hans Werner Borchers
ABB Corporate Research, Germany
________________________________________________________________________

require (class)
nearest <- function (X, n, k=3)
##  Find k nearest neighbors of X[n, ] in the data frame
##  or matrix X, utilizing function knn1 k-times.
{
    N <- nrow(X)
    # inds contains the indices of nearest neighbors
    inds <- c(n); i <- 0
    while (i < k) {
        # use knn1 for one index...
        j  <- as.integer(knn1(X [-inds, ], X[n, ], 1:(N-length(inds))))
        # ...and change to true index of neighbor
        inds <- c(inds, setdiff(1:N, inds)[j])
        i <- i+1
    }
    # return nearest neighbor indices (without n, of course)
    return(inds[-1])
}



From dray at biomserv.univ-lyon1.fr  Mon Feb  2 22:33:58 2004
From: dray at biomserv.univ-lyon1.fr (Stephane DRAY)
Date: Mon, 02 Feb 2004 16:33:58 -0500
Subject: [R] problems when compiling C code
In-Reply-To: <46C633BF-55BC-11D8-9478-000A956F2984@mac.com>
Message-ID: <5.2.1.1.0.20040202162209.00b4c488@biomserv.univ-lyon1.fr>

Hello,

I would like to call C code from R. My C code is divided in two files. In 
the file "testpermut.c", I have the following lines:

#include "adesub.h"

In my working folder, I have the files:
- adesub.c which contains general functions
- adesub.h with the header of functions contained in adesub.c
- testpermut.c which call some functions defined in adesub.c

When I try to  create my dll (Work on Windows XP, R-1.8.1), I obtain error 
message:

$ Rcmd shlib testpermut.c
making adesub.d from adesub.c
making testpermut.d from testpermut.c
gcc   -Ic:/Rdev/R-1.8.1/src/include -Wall -O2   -c testpermut.c -o testpermut.o
ar cr testpermut.a *.o
ranlib testpermut.a
gcc  --shared -s  -o testpermut.dll testpermut.def 
testpermut.a  -Lc:/Rdev/R-1.8
.1/src/gnuwin32  -lg2c -lR
testpermut.a(testpermut.o.b)(.text+0x35):testpermut.c: undefined reference 
to `taballoc'
testpermut.a(testpermut.o.b)(.text+0x49):testpermut.c: undefined reference 
to `taballoc'
testpermut.a(testpermut.o.b)(.text+0x62):testpermut.c: undefined reference 
to `taballoc'
testpermut.a(testpermut.o.b)(.text+0x14c):testpermut.c: undefined reference 
to `freetab'
testpermut.a(testpermut.o.b)(.text+0x156):testpermut.c: undefined reference 
to `freetab'
testpermut.a(testpermut.o.b)(.text+0x160):testpermut.c: undefined reference 
to `freetab'
testpermut.a(testpermut.o.b)(.text+0x192):testpermut.c: undefined reference 
to `taballoc'
testpermut.a(testpermut.o.b)(.text+0x22b):testpermut.c: undefined reference 
to `taballoc'
testpermut.a(testpermut.o.b)(.text+0x23f):testpermut.c: undefined reference 
to `vecalloc'
testpermut.a(testpermut.o.b)(.text+0x24b):testpermut.c: undefined reference 
to `vecalloc'
testpermut.a(testpermut.o.b)(.text+0x339):testpermut.c: undefined reference 
to `freevec'
testpermut.a(testpermut.o.b)(.text+0x343):testpermut.c: undefined reference 
to `freevec'
testpermut.a(testpermut.o.b)(.text+0x34d):testpermut.c: undefined reference 
to `freetab'
testpermut.a(testpermut.o.b)(.text+0x412):testpermut.c: undefined reference 
to `taballoc'
make: *** [testpermut.dll] Error 1
$

The functions taballoc, freetab, vecalloc and freevec are defined in adesub 
files. So it seems that gcc does not make the links between my files. If I 
include the problematic functions in testpermut.c, gcc works perfectly and 
my dll is created.

Perhaps someone could explain me what is my problem although it is not an R 
problem but probably a misuse of gcc ?.

Thanks in advance.
St?phane DRAY
-------------------------------------------------------------------------------------------------- 

D?partement des Sciences Biologiques
Universit? de Montr?al, C.P. 6128, succursale centre-ville
Montr?al, Qu?bec H3C 3J7, Canada

Tel : 514 343 6111 poste 1233
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From cstrato at aon.at  Mon Feb  2 22:38:55 2004
From: cstrato at aon.at (cstrato)
Date: Mon, 02 Feb 2004 22:38:55 +0100
Subject: [R] Robust nonlinear regression - sin(x)/x?
In-Reply-To: <886999885841.885841886999@jhsph.edu>
References: <886999885841.885841886999@jhsph.edu>
Message-ID: <401EC36F.5070108@aon.at>

Dear Ravi

Sorry, I forgot to mention that you have also  indicated
that I have only one parameter. Fitting using lm gives:
c=1.023 w/o and c=1.146 with outliers.

Maybe sin(x)/x was a bad example, how about trying to
fit a polynomial of degree n?

Best regards
Christian

Ravi Varadhan wrote:

> A small correction to my previous email:
> You actually specify the following call to lm:
> 
> y <- sin(x)/x
> lm(z ~ y - 1)
> 
> to make sure that the intercept is not estimated.
> 
> Ravi.
> 
> ----- Original Message -----
> From: Ravi Varadhan <rvaradha at jhsph.edu>
> Date: Monday, February 2, 2004 2:46 pm
> Subject: Re: [R] Robust nonlinear regression - sin(x)/x?
> 
> 
>>You reall have only one parameter in your model, c = a/b. You 
>>can't 
>>identify both a and b from your model, therefore, you should fit 
>>the 
>>linear model:  lm(z ~ c* sin(x)/x)
>>
>>Ravi.
>>
>>----- Original Message -----
>>From: cstrato <cstrato at aon.at>
>>Date: Monday, February 2, 2004 2:28 pm
>>Subject: [R] Robust nonlinear regression - sin(x)/x?
>>
>>
>>>Dear all
>>>
>>>Since I did not receive any answer to my general question (?),
>>>let me ask a concrete question:
>>>
>>>How can I fit the simple function y = a*sin(x)/b*x?
>>>
>>>This is the code that I tried, but nls gives an error:
>>>
>>>x <- seq(1,10,0.1)
>>>y <- sin(x)/x
>>>plot(x,y)
>>>z <- jitter(y,amount=0.1)
>>>plot(x,z)
>>>df <- as.data.frame(cbind(x,z))
>>>nf <- nls(z ~ a*sin(x)/b*x, data=df,
>>>          start=list(a=0.8,b=0.9), trace = TRUE)
>>>
>>>I have followed the Puromycin sample which works fine:
>>>Pur.wt <- nls(rate ~ (Vm * conc)/(K + conc), data = Treated,
>>>              start = list(Vm = 200, K = 0.1), trace = TRUE)
>>>
>>>Do I make some mistake or is it not possible to fit sin(x)/x?
>>>
>>>Thank you in advance
>>>Best regards
>>>Christian
>>>_._._._._._._._._._._._._._._._
>>>C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>V.i.e.n.n.a       A.u.s.t.r.i.a
>>>_._._._._._._._._._._._._._._._
>>>
>>>
>>>cstrato wrote:
>>>
>>>>Dear R experts
>>>>
>>>>This is a general question:
>>>>Does R have functions for nonlinear robust regression,
>>>>analogous to e.g. LTS?
>>>>
>>>>Searching google I have found
>>>>1, an abstract to generalize LTS for nonlinear regression
>>>>models, see: http://smealsearch.psu.edu/1509.html
>>>>2, an AD-model builder, see: http://otter-
>>
>>rsch.com/admodel/cc1.html> > but no mention of R/S
>>
>>>>Thank you in advance
>>>>Best regards
>>>>Christian
>>>>_._._._._._._._._._._._._._._._
>>>>C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>V.i.e.n.n.a       A.u.s.t.r.i.a
>>>>_._._._._._._._._._._._._._._._
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! 
>>>>http://www.R-project.org/posting-guide.html
>>>>
>>>>
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-
>>
>>project.org/posting-
>>
>>>guide.html
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-
>>guide.html
> 
> 
> 
>



From p.dalgaard at biostat.ku.dk  Mon Feb  2 22:47:08 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Feb 2004 22:47:08 +0100
Subject: [R] mvrnorm problem
In-Reply-To: <000001c3e9c7$cddd9340$28287080@WWS7X5TK31>
References: <000001c3e9c7$cddd9340$28287080@WWS7X5TK31>
Message-ID: <x2ektd40ir.fsf@biostat.ku.dk>

Stuart V Jordan <sjordan at princeton.edu> writes:

> > mvrnorm(n = 1000,B,V)
> Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) : 
>         non-conformable arrays
> > mvrnorm(n = 1000,t(B),V)
> Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) : 
>         non-conformable arrays

You might, for at least two good reasons, have said that this is from
library(MASS). The point is that

> mvrnorm(n=10,matrix(c(1,1),1,2),diag(2))
Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) :
        non-conformable arrays
> mvrnorm(n=10,matrix(c(1,1),2,1),diag(2))
Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) :
        non-conformable arrays
> mvrnorm(n=10,c(1,1),diag(2))
            [,1]       [,2]
 [1,]  0.5005327  1.1919216
 [2,]  2.8273925  2.7004788
 [3,]  2.6493970  1.1304274
....

and the docs quite clearly say that mu wants to be a vector, not a
matrix. 

Curiously enough, this works with rmvnorm from the mvtnorm package by
Genz, Bretz, and Hothorn, the difference being that this version adds
in the means with a sweep() operation, whereas mvrnorm just adds mu
(to the transpose of the ultimate result) and relies on recycling
rules. I.e. the point is that

> x <- matrix(1:2,1,2)
> M <- matrix(1:4,2)
> x+M
Error in x + M : non-conformable arrays
> t(x)+M
Error in t(x) + M : non-conformable arrays
> c(x)+M
     [,1] [,2]
[1,]    2    4
[2,]    4    6
> sweep(M,1,x,"+")
     [,1] [,2]
[1,]    2    4
[2,]    4    6


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jcjorgensen at wisc.edu  Mon Feb  2 23:16:13 2004
From: jcjorgensen at wisc.edu (Jeff Jorgensen)
Date: Mon, 02 Feb 2004 16:16:13 -0600
Subject: [R] sorting by date
Message-ID: <5.2.1.1.2.20040202160522.02279428@wiscmail.wisc.edu>

Hello,

I have set up a data.frame and one of the columns contains a date of the 
form (with slashes as separators):

mm/dd/yyyy

I would like to use formulas on other columns in the data.frame organized 
by date, for example:

tapply(var1, sort(date), mean)

However, when I try sort(date) it sorts based on the first two entries in 
the date field:

9/1/2001	9/1/2002	9/1/2003	9/2/2001 ...
5.6		7.5		6.4		7.0 ...

Instead of:

9/1/2001	9/2/2001	9/3/2001	9/4/2001 ...
5.6		6.1		7.2		6.8 ...

I would greatly appreciate any help in sorting chronologically.  Do I need 
to create separate columns for month, day, and year, and then use order() 
and then stipulate the hierarchy for which to sort the output?  Or, is 
there some other more efficient way?

Thanks,

Jeff



From cstrato at aon.at  Mon Feb  2 23:17:33 2004
From: cstrato at aon.at (cstrato)
Date: Mon, 02 Feb 2004 23:17:33 +0100
Subject: [R] Robust nonlinear regression - better example
In-Reply-To: <401EA4F3.70303@aon.at>
References: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>	<3FC51AB5.6020806@aon.at>	<401AA785.5010609@aon.at>
	<401EA4F3.70303@aon.at>
Message-ID: <401ECC7D.7060502@aon.at>

Dear all

Here is a hopefully better example with regards to
nonlinear robust fitting:

# fitting a polynomial:
x <- seq(-10,10,0.2)
y <- 10*x + 4*x*x - 2*x*x*x
plot(x,y)
z <- jitter(y,amount=300)
plot(x,z)
df <- as.data.frame(cbind(x,z))
nf <- nls(z ~ a*x + b*x*x + c*x*x*x, data=df,
+           start=list(a=4,b=2,c=1), trace = TRUE)
127697531 :  4 2 1
2974480 :  10.972123  3.793426 -1.942278

# introducing outliers before fitting the  polynomial:
z1 <- z
z1[c(16,22,23,34,36,42,67,69,72,76)] <-
+ c(2000,1900,2000,1900,1600,1600,500,-2000,-1700,-1800)
plot(x,z1)
df1 <- as.data.frame(cbind(x,z1))
nf1 <- nls(z1 ~ a*x + b*x*x + c*x*x*x, data=df1,
+           start=list(a=4,b=2,c=1), trace = TRUE)
159359174 :  4 2 1
24098548 :  -59.053288   4.169518  -1.072027

# plotting the results:
y1 <- 10.97*x + 3.79*x*x - 1.94*x*x*x
y2 <- -59.05*x + 4.17*x*x - 1.07*x*x*x
oldpar <- par(pty="s",mfrow=c(2,2),mar=c(5,5,4,1))
plot(x,y)
plot(x,z1)
plot(x,y1)
plot(x,y2)
par(oldpar)

In my opinion this fit could hardly be considered
to be robust.

Are there functions in R which can do robust fitting?
(Sorrowly, at the moment I could not test the package
nlrq mentioned by Roger Koenker)

Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._



From ripley at stats.ox.ac.uk  Mon Feb  2 23:29:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 2 Feb 2004 22:29:38 +0000 (GMT)
Subject: [R] Nearest Neighbor Algorithm in R -- again.
In-Reply-To: <401EC064.6000609@t-online.de>
Message-ID: <Pine.LNX.4.44.0402022228100.2086-100000@gannet.stats>

Why not modify the C code of knn? (Not knn1)

On Mon, 2 Feb 2004, Hans W Borchers wrote:

> Several of the methods I use for analyzing large data sets, such as
> 
>   WinGamma: determining the level of noise in data
>   Relief-F: estimating the influence of variables
> 
> depend on finding the k nearest neighbors of a point in a data frame or
> matrix efficiently. (For large data sets it is not feasible to compute
> the 'dist' matrix anyway.)
> 
> Seeing the proposed solution to "[R] distance between two matrices"
> last month for finding _one_ nearest neighbor I came up with a solution
> 'nearest(A, n, k)' as appended.
> 
> Still, this is very clumsy and slow if you have to find the 3 nearest
> neighbors for 1000 points in a data frame with 100000 entries at least
> -- about 2 secs per data point on my computer or half an hour for an
> application from real life.
> 
> Are there better/faster ways to perform this task using R functions?
> Even better, is there a free implementation of kd-trees that I could
> utilize (the one I found did not conform to the ANSI C standard)?
> 
> Someome pointed to 'spdep' of the R-Sig-Geo project, but 'knearneigh'
> only accepts 2D data points.
> 
> Hans Werner Borchers
> ABB Corporate Research, Germany
> ________________________________________________________________________
> 
> require (class)
> nearest <- function (X, n, k=3)
> ##  Find k nearest neighbors of X[n, ] in the data frame
> ##  or matrix X, utilizing function knn1 k-times.
> {
>     N <- nrow(X)
>     # inds contains the indices of nearest neighbors
>     inds <- c(n); i <- 0
>     while (i < k) {
>         # use knn1 for one index...
>         j  <- as.integer(knn1(X [-inds, ], X[n, ], 1:(N-length(inds))))
>         # ...and change to true index of neighbor
>         inds <- c(inds, setdiff(1:N, inds)[j])
>         i <- i+1
>     }
>     # return nearest neighbor indices (without n, of course)
>     return(inds[-1])
> }
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at medanalytics.com  Mon Feb  2 23:36:56 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 02 Feb 2004 16:36:56 -0600
Subject: [R] ordering and plotting question
In-Reply-To: <46C633BF-55BC-11D8-9478-000A956F2984@mac.com>
References: <46C633BF-55BC-11D8-9478-000A956F2984@mac.com>
Message-ID: <1075761416.16606.54.camel@localhost.localdomain>

On Mon, 2004-02-02 at 14:13, Simon Melov wrote:
> Hi,
> I am trying to plot several rows out of a list of thousands. I have 40 
> columns, and about 16,000 rows with the following Df structure.
> 
> ID X01 X02 X03..X40
> AI456 45 64 23...
> AI943 14 3 45 ..
> AI278 78 12 68..
> BW768 -2 -7 34..
> ...
> 
> My question is, I have a list of 100 IDs generated elsewhere 
> (Df-"Ofinterest"), I would like to plot the 100 IDs from that data 
> frame over the 40 columns (40 points per ID, with each column being 1 x 
> value). But I cant figure out how to retrieve the values from the main 
> Df and plot them. Ive tried looking at order, rank etc, but these seem 
> to apply to numbers, and not text strings.
> 
> thanks
> 
> Simon.


I am not entirely sure what type of plot you want, however the following
will enable you to subset the main dataframe, based upon matching ID's:

# Create an example vector of the ID's you want
df.index <- c("AI456", "AI278", "BW768")

> df.index
[1] "AI456" "AI278" "BW768"
 
# Create a df with the subset of data you have above
df <- data.frame(ID = c("AI456", "AI943", "AI278", "BW768"),
                 X01 = c(45, 14, 78, -2),
                 X02 = c(64, 3, 12, -7),
                 X03 = c(23, 45, 68, 34))

> df
     ID X01 X02 X03
1 AI456  45  64  23
2 AI943  14   3  45
3 AI278  78  12  68
4 BW768  -2  -7  34

# Use which() and %in% to get a vector containing the
# row indices in df that match the three entries in df.index
found <- which(df$ID %in% df.index)

> found
[1] 1 3 4

# Now subset df to include only those rows that match
MySubset <- df[found, ]

> MySubset
     ID X01 X02 X03
1 AI456  45  64  23
3 AI278  78  12  68
4 BW768  -2  -7  34


MySubset now contains only those rows that match based upon your IDs in
the "index" vector.

If you know how to generate the plot you want from here, have at it. If
not, let me know what you wish to do and I can help further.

See ?which and ?%in% for more information. Also, see ?subset for
additional ways to subset dataframes using more complex logicals.

HTH,

Marc Schwartz



From ripley at stats.ox.ac.uk  Mon Feb  2 23:38:07 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 2 Feb 2004 22:38:07 +0000 (GMT)
Subject: [R] sorting by date
In-Reply-To: <5.2.1.1.2.20040202160522.02279428@wiscmail.wisc.edu>
Message-ID: <Pine.LNX.4.44.0402022230050.2086-100000@gannet.stats>

Convert to POSIXct and sort.

Note that tapply will coerce to a factor, so you need to create a factor 
with the levels sorted as you want them: just sorting date will not help.
Something like

udate <- unique(date)
lev <- udate[sort.list(as.POSIXct(strptime(udate, "%m/%d/%Y")))]
date <- factor(date, levels=lev)


On Mon, 2 Feb 2004, Jeff Jorgensen wrote:

> I have set up a data.frame and one of the columns contains a date of the 
> form (with slashes as separators):
> 
> mm/dd/yyyy
> 
> I would like to use formulas on other columns in the data.frame organized 
> by date, for example:
> 
> tapply(var1, sort(date), mean)
> 
> However, when I try sort(date) it sorts based on the first two entries in 
> the date field:
> 
> 9/1/2001	9/1/2002	9/1/2003	9/2/2001 ...
> 5.6		7.5		6.4		7.0 ...
> 
> Instead of:
> 
> 9/1/2001	9/2/2001	9/3/2001	9/4/2001 ...
> 5.6		6.1		7.2		6.8 ...
> 
> I would greatly appreciate any help in sorting chronologically.  Do I need 
> to create separate columns for month, day, and year, and then use order() 
> and then stipulate the hierarchy for which to sort the output?  Or, is 
> there some other more efficient way?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Mon Feb  2 23:49:44 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Feb 2004 23:49:44 +0100
Subject: [R] sorting by date
In-Reply-To: <5.2.1.1.2.20040202160522.02279428@wiscmail.wisc.edu>
References: <5.2.1.1.2.20040202160522.02279428@wiscmail.wisc.edu>
Message-ID: <x265ep3xmf.fsf@biostat.ku.dk>

Jeff Jorgensen <jcjorgensen at wisc.edu> writes:

> Hello,
> 
> I have set up a data.frame and one of the columns contains a date of
> the form (with slashes as separators):
> 
> mm/dd/yyyy
> 
> I would like to use formulas on other columns in the data.frame
> organized by date, for example:
> 
> tapply(var1, sort(date), mean)

I don't think that does what I think you think it does!


 
> However, when I try sort(date) it sorts based on the first two entries
> in the date field:
> 
> 9/1/2001	9/1/2002	9/1/2003	9/2/2001 ...
> 5.6		7.5		6.4		7.0 ...
> 
> Instead of:
> 
> 9/1/2001	9/2/2001	9/3/2001	9/4/2001 ...
> 5.6		6.1		7.2		6.8 ...
> 
> I would greatly appreciate any help in sorting chronologically.  Do I
> need to create separate columns for month, day, and year, and then use
> order() and then stipulate the hierarchy for which to sort the output?
> Or, is there some other more efficient way?

You now know why the ISO standard has yyyy-mm-dd ... 

It's a bit awkward, but I think you need something like

pdate <- as.POSIXct(strptime(date,"%m/%d/%Y"))
tapply(var1, pdate, mean)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Tue Feb  3 00:05:42 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 02 Feb 2004 15:05:42 -0800
Subject: [R] Robust nonlinear regression - better example
In-Reply-To: <401ECC7D.7060502@aon.at>
References: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>	<3FC51AB5.6020806@aon.at>	<401AA785.5010609@aon.at>	<401EA4F3.70303@aon.at>
	<401ECC7D.7060502@aon.at>
Message-ID: <401ED7C6.3060004@pdf.com>

      1.  The question of "linear" vs. "nonlinear" means "linear in the 
parameters to be estimated.  All the examples you have given so far are 
linear in the parameters to be estimated.  The fact that they are 
nonlinear in "x" is immaterial. 

      2.  With this hint and the posting guide 
"http://www.R-project.org/posting-guide.html", you may find more 
information.  A search there exposed much discussion of "robust 
regression" and even "robust nonlinear regression", if you actually 
still need that.  In addition, I found useful information on robust 
regression in Venables and Ripley (2002) Modern Applied Statistics with 
S, 4th ed. (Springer). 

      hope this helps. 
      spencer graves

cstrato wrote:

> Dear all
>
> Here is a hopefully better example with regards to
> nonlinear robust fitting:
>
> # fitting a polynomial:
> x <- seq(-10,10,0.2)
> y <- 10*x + 4*x*x - 2*x*x*x
> plot(x,y)
> z <- jitter(y,amount=300)
> plot(x,z)
> df <- as.data.frame(cbind(x,z))
> nf <- nls(z ~ a*x + b*x*x + c*x*x*x, data=df,
> +           start=list(a=4,b=2,c=1), trace = TRUE)
> 127697531 :  4 2 1
> 2974480 :  10.972123  3.793426 -1.942278
>
> # introducing outliers before fitting the  polynomial:
> z1 <- z
> z1[c(16,22,23,34,36,42,67,69,72,76)] <-
> + c(2000,1900,2000,1900,1600,1600,500,-2000,-1700,-1800)
> plot(x,z1)
> df1 <- as.data.frame(cbind(x,z1))
> nf1 <- nls(z1 ~ a*x + b*x*x + c*x*x*x, data=df1,
> +           start=list(a=4,b=2,c=1), trace = TRUE)
> 159359174 :  4 2 1
> 24098548 :  -59.053288   4.169518  -1.072027
>
> # plotting the results:
> y1 <- 10.97*x + 3.79*x*x - 1.94*x*x*x
> y2 <- -59.05*x + 4.17*x*x - 1.07*x*x*x
> oldpar <- par(pty="s",mfrow=c(2,2),mar=c(5,5,4,1))
> plot(x,y)
> plot(x,z1)
> plot(x,y1)
> plot(x,y2)
> par(oldpar)
>
> In my opinion this fit could hardly be considered
> to be robust.
>
> Are there functions in R which can do robust fitting?
> (Sorrowly, at the moment I could not test the package
> nlrq mentioned by Roger Koenker)
>
> Best regards
> Christian
> _._._._._._._._._._._._._._._._
> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a       A.u.s.t.r.i.a
> _._._._._._._._._._._._._._._._
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Tue Feb  3 00:16:26 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 2 Feb 2004 23:16:26 +0000 (GMT)
Subject: [R] problems when compiling C code
In-Reply-To: <5.2.1.1.0.20040202162209.00b4c488@biomserv.univ-lyon1.fr>
Message-ID: <Pine.LNX.4.44.0402022315110.2149-100000@gannet.stats>

On Mon, 2 Feb 2004, Stephane DRAY wrote:

> Hello,
> 
> I would like to call C code from R. My C code is divided in two files. In 
> the file "testpermut.c", I have the following lines:
> 
> #include "adesub.h"
> 
> In my working folder, I have the files:
> - adesub.c which contains general functions
> - adesub.h with the header of functions contained in adesub.c
> - testpermut.c which call some functions defined in adesub.c
> 
> When I try to  create my dll (Work on Windows XP, R-1.8.1), I obtain error 
> message:
> 
> $ Rcmd shlib testpermut.c

You only included one of the files. You need

Rcmd SHLIB testpermut.c adesub.c

I believe.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From babailey at stat.uiuc.edu  Tue Feb  3 00:35:12 2004
From: babailey at stat.uiuc.edu (Barbara Bailey)
Date: Mon, 2 Feb 2004 17:35:12 -0600 (CST)
Subject: [R] Re: packages
Message-ID: <Pine.SOL.3.91.1040202172352.13791J-100000@lyapunov.stat.uiuc.edu>

Hi,

I am trying to make my own package of R functions, datasets and help 
files, which were originally in S and have been converted. As a Unix 
user, I am trying to make a package that installs on Windows and I am 
having some trouble. 

I have a zip file that seems to unzip fine, but I have to use the source 
command to make functions accessible.  

e.g. source("C:/Program Files/R/rw1081/library/slab/R/slab.q")

Is there a command that make happen? or is the .q extention causing trouble?

It turns out that the data() command works fine, but help files are not 
accessible either. 

Thanks for your help,
Barb Bailey



From HankeA at mar.dfo-mpo.gc.ca  Mon Feb  2 16:13:50 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Mon, 02 Feb 2004 11:13:50 -0400
Subject: [R] glm.poisson.disp versus glm.nb
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE124925@msgmarsta01.bio.dfo.ca>

Dear list,
This is a question about overdispersion and the ML estimates of the
parameters returned by the glm.poisson.disp (L. Scrucca) and glm.nb
(Venables and Ripley) functions. Both appear to assume a negative binomial
distribution for the response variable.

Paul and Banerjee (1998) developed C(alpha) tests for "interaction and main
effects, in an unbalanced two-way layout of counts involving two fixed
factors, when data are Poisson distributed, and when data are extra
dispersed". In R I coded their C(alpha) test statistic (called TNBI) for
interaction for the case where the counts are extra-dispersed, as well as
their test for extra-dispersion (called T_a). Using the Quine data set
(Quine, 1975) the authors collapse the orginal 4x2x2x2 study design into a
2x4 table and obtained estimates of TNBI=10.36 and T_a=90.81.
Using the dispersion estimate from glm.poisson.disp and the estimates for mu
I got exactly the same results for TNBI and T_a. This made me happy. Now I
thought to try the ML estimates from glm.nb to see if the results would be
the same but I am having difficulty relating the dispersion phi from
glm.poisson.disp to theta estimated by glm.nb.
According to the R help for glm.poisson.disp " Var(y_i) =  mu_i(1+mu_i*phi)
". The help for glm.nb lead me to a book by V&R (1994) which indicates that
Var(y)=mu+mu^2/theta. From this I gathered that phi=1/theta but the
estimates do not relate to each other in this way unless one is in error. In
a document by L.P. Ammann he says a "negative binomial model can be
specified with mean mu and dispersion phi by taking theta=mu/(phi-1)". I had
a problem implementing this because in my mind mu is a vector whereas phi
and theta are scalars.

Consequently, I would like to know  how to get phi from theta so that I can
compare the glm.poisson.disp and glm.nb methods for estimating dispersion. 

Regards, Alex




Alex Hanke
Department of Fisheries and Oceans
St. Andrews Biological Station
531 Brandy Cove Road
St. Andrews, NB
Canada
E5B 2L9



From andel at ifi.unizh.ch  Tue Feb  3 00:25:01 2004
From: andel at ifi.unizh.ch (David Andel)
Date: 3 Feb 2004 00:25:01 +0100
Subject: [R] how to label plots?
Message-ID: <401EDC4D.2050906@ifi.unizh.ch>

Hi

With main="Title" I can write centered above the plot.
Is there also a way to write into the left (or right) upper corner?
I'd like to label my plots by (a), (b), ...

Thanks,
David



From DivineSAAM at aol.com  Tue Feb  3 00:27:37 2004
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Mon, 02 Feb 2004 18:27:37 -0500
Subject: [R] problems when compiling C code
Message-ID: <74126408.7651A489.0B088159@aol.com>

Hello,

Do you have S Programming by Venables and Ripley, Springer, 2000?

There is an excellent discussion and examples there on compiling multifile codes.

I think your problem is in the order of the compilation of the multiple files.

Best,
/oal



From ggrothendieck at myway.com  Tue Feb  3 01:27:16 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon,  2 Feb 2004 19:27:16 -0500 (EST)
Subject: [R] sorting by date
Message-ID: <20040203002716.8D0073982@mprdmxin.myway.com>


I assume the dates are strings.  If they are factors use 
as.character(date) in place of date below.  str(date) will
tell you what you have.

It so happens that chron maps dates in your format to days 
since an origin (which sort properly) so you could try this:

require(chron)
z <- tapply( var1, date, mean )
z[order(chron(names(z)))]

Note that date() is a function in R so you might want to
choose a different variable name to prevent confusion.


Date:   Mon, 02 Feb 2004 16:16:13 -0600 
From:   Jeff Jorgensen <jcjorgensen at wisc.edu>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] sorting by date 

 
Hello,

I have set up a data.frame and one of the columns contains a date of the 
form (with slashes as separators):

mm/dd/yyyy

I would like to use formulas on other columns in the data.frame organized 
by date, for example:

tapply(var1, sort(date), mean)

However, when I try sort(date) it sorts based on the first two entries in 
the date field:

9/1/2001     9/1/2002     9/1/2003     9/2/2001 ...
5.6          7.5          6.4          7.0 ...

Instead of:

9/1/2001     9/2/2001     9/3/2001     9/4/2001 ...
5.6          6.1          7.2          6.8 ...

I would greatly appreciate any help in sorting chronologically. Do I need 
to create separate columns for month, day, and year, and then use order() 
and then stipulate the hierarchy for which to sort the output? Or, is 
there some other more efficient way?

Thanks,

Jeff

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From MSchwartz at medanalytics.com  Tue Feb  3 02:28:38 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 02 Feb 2004 19:28:38 -0600
Subject: [R] how to label plots?
In-Reply-To: <401EDC4D.2050906@ifi.unizh.ch>
References: <401EDC4D.2050906@ifi.unizh.ch>
Message-ID: <1075771718.16606.64.camel@localhost.localdomain>

On Mon, 2004-02-02 at 17:25, David Andel wrote:
> Hi
> 
> With main="Title" I can write centered above the plot.
> Is there also a way to write into the left (or right) upper corner?
> I'd like to label my plots by (a), (b), ...
> 
> Thanks,
> David


# Create a basic plot
plot(1:5)

# Now set the outer plot margin to 1 line at the top
# and 0 for bottom, left and right
# See ?par for more information
par(oma = c(0, 0, 1, 0))

# Now use mtext() to place text in the outer margin
# The outer margin coordinates go from 0 to 1
# See ?mtext for more information

#For the upper left hand corner, use the following:
mtext("(a)", side = 3, line = 0, at = 0, outer = TRUE, adj = 0)

#For the upper right hand corner, use the following:
mtext("(b)", side = 3, line = 0, at = 1, outer = TRUE, adj = 1)


You can play with the outer margin settings for more space if you wish
and the 'adj' argument in mtext() manipulates the positioning of the
text at the "x,y" coordinate of "line, at".

HTH,

Marc Schwartz



From MSchwartz at medanalytics.com  Tue Feb  3 02:33:10 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 02 Feb 2004 19:33:10 -0600
Subject: [R] how to label plots?
In-Reply-To: <1075771718.16606.64.camel@localhost.localdomain>
References: <401EDC4D.2050906@ifi.unizh.ch>
	<1075771718.16606.64.camel@localhost.localdomain>
Message-ID: <1075771990.16606.69.camel@localhost.localdomain>

On Mon, 2004-02-02 at 19:28, Marc Schwartz wrote:
> You can play with the outer margin settings for more space if you wish
> and the 'adj' argument in mtext() manipulates the positioning of the
> text at the "x,y" coordinate of "line, at".


Oops...That last line should read:

text at the "x,y" coordinate of "at, line".

Sorry.

Marc



From h_m_ at po.harenet.ne.jp  Tue Feb  3 02:46:41 2004
From: h_m_ at po.harenet.ne.jp (Hiroto Miyoshi)
Date: Tue, 3 Feb 2004 10:46:41 +0900
Subject: [R] output from multcomp and lm
Message-ID: <009701c3e9f7$9424f5f0$0c01a8c0@HP31522725682>

Dear R-users

I analysed the same data set by two different ways;
analysis of covariance by using lm and anova functions
and multiple comparison by using simtest function in
the multcomp library.

The output from the analysis of covariance is;

>   y<-lm(D~Cond+Q1,data=x)
> anova(y)
Analysis of Variance Table

Response: D
             Df Sum Sq Mean Sq F value    Pr(>F)
Cond        2 1017.8   508.9   4.7548  0.0135041 *
Q1           1 1652.7  1652.7 15.4417  0.0002969 ***
Residuals 44 4709.2   107.0
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

where Cond is a factor with three levels (A,B,C)
and Q1 is a covariate.



Now, simtest showed the following output

>   o5<-summary(simtest(D~Cond+Q1,conf.level=0.95,data=x,type="Tukey"))
>   o5

  Simultaneous tests: Tukey contrasts

Call:
simtest.formula(formula = D ~ Cond + Q1, data = x, conf.level = 0.95,
    type = "Tukey")

  Tukey contrasts for factor Cond, covariable:  Q1

Contrast matrix:
              CondA CondB CondC
CondB-CondA 0    -1     1     0 0
CondC-CondA 0    -1     0     1 0
CondC-CondB 0     0    -1     1 0


Absolute Error Tolerance:  0.001

Coefficients:
                    Estimate t value Std.Err. p raw  p Bonf  p adj
CondB-CondA    5.555  -1.461    3.802  0.151   0.453   0.319
CondC-CondB   -5.248  -1.365    3.661 0.179   0.453   0.319
CondC-CondA    0.306  -0.084    3.844  0.934   0.934   0.934

The results from two analyses seem so different that I am
wondering why.  I do understand that multiple comparison may
not show any significant difference even when the overall analysis
of (co)variance shows the statistical significance of a factor.

However, in my analysis, overall analysis showed statistical significance of
1.4% level and mutiple comparison showed significance of 32% level
Could this happen? and why?  Please enlighten me.

Sincerely
------------------------
Hiroto Miyoshi
????
h_m_ at po.harenet.ne.jp



From edd at debian.org  Tue Feb  3 03:09:17 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 2 Feb 2004 20:09:17 -0600
Subject: [R] Re: packages
In-Reply-To: <Pine.SOL.3.91.1040202172352.13791J-100000@lyapunov.stat.uiuc.edu>
References: <Pine.SOL.3.91.1040202172352.13791J-100000@lyapunov.stat.uiuc.edu>
Message-ID: <20040203020917.GA30191@sonny.eddelbuettel.com>

On Mon, Feb 02, 2004 at 05:35:12PM -0600, Barbara Bailey wrote:
> I am trying to make my own package of R functions, datasets and help 
> files, which were originally in S and have been converted. As a Unix 
> user, I am trying to make a package that installs on Windows and I am 
> having some trouble. 

AFAIK that is not guaranteed to work. Generally speaking, for any given
system, binary R packages (as opposed to source packages) are built on that
architecture.

There are exceptions, most notably the cross-builds for Windows i386 that
can be generated, given a suitable environment, on a Linux system. This is
documented in a few places; google should find it.

For the normal case, your best bet is to read some more of the fine 'Writing
R Extensions' manual, and to possibly study some of the examples provided by
the over 300 source packages available on CRAN.

Hth, Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From brook at biology.nmsu.edu  Tue Feb  3 03:26:04 2004
From: brook at biology.nmsu.edu (brook@biology.nmsu.edu)
Date: Mon, 2 Feb 2004 19:26:04 -0700
Subject: [R] running R from PHP
Message-ID: <16415.1724.787098.9123@viola.nmsu.edu>

I would like to construct a PHP script that runs R to generate a
graphics file.  Running R itself is no problem.  However, it seems
impossible to instantiate one of the graphics devices to create
output.  For example, the "normal" bitmap devices (e.g., jpeg, png,
etc.) are derived from X11, which requires a display.  This seems
true, even if no output is ever directed to a real display.  For some
reason, the postscript device seems to suffer from similar problems.

Is there a trick to creating a graphics device in the absence of an
actual display in order to create an image in a file?

Thanks for your help.

Cheers,
Brook



From glaziou at pasteur-kh.org  Tue Feb  3 06:24:33 2004
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Tue, 3 Feb 2004 12:24:33 +0700
Subject: [R] running R from PHP
In-Reply-To: <16415.1724.787098.9123@viola.nmsu.edu>
References: <16415.1724.787098.9123@viola.nmsu.edu>
Message-ID: <20040203052433.GA25105@pasteur-kh.org>

@biology.nmsu.edu <brook at biology.nmsu.edu> wrote:
> I would like to construct a PHP script that runs R to generate a
> graphics file.  Running R itself is no problem.  However, it seems
> impossible to instantiate one of the graphics devices to create
> output.  For example, the "normal" bitmap devices (e.g., jpeg, png,
> etc.) are derived from X11, which requires a display.  This seems
> true, even if no output is ever directed to a real display.  For some
> reason, the postscript device seems to suffer from similar problems.
> 
> Is there a trick to creating a graphics device in the absence of an
> actual display in order to create an image in a file?


If you need a bitmap graphic file, I would suggest the use of
ImageMagick:


cunegonde:~/tmp> ls
foo

cunegonde:~/tmp> cat foo
pdf(file="g.pdf")
plot(1:5)
dev.off()

cunegonde:~/tmp> R --no-save <foo>/dev/null && convert g.pdf g.png

cunegonde:~/tmp> ls -g
-rw-------    1 glaziou      3374 2004-02-03 11:58 g.pdf
-rw-------    1 glaziou      4115 2004-02-03 11:58 g.png
-rw-------    1 glaziou        80 2004-02-03 11:58 foo


This works from a unix console without X running (the postcript
device works similarly on my machine). R can easily be fed this
way with a file and parameters passed from a php script.

-- 
Philippe Glaziou, MD
Epidemiologist
Institut Pasteur du Cambodge



From paul.bliese at us.army.mil  Mon Feb  2 17:45:31 2004
From: paul.bliese at us.army.mil (Bliese, Paul D MAJ USAMH)
Date: Mon, 2 Feb 2004 17:45:31 +0100 
Subject: [R] Order in barchart
Message-ID: <B32E0B24DEA2E344930910DEC438D0CF309394@amedmlmhah02.heidelberg.amedd.army.mil>

Sorry if this is a FAQ -- I checked the archives and help files, but was
stumped.

In the data T3 (provided below) the values are sorted from lowest to
highest.

> T3
      10        7       19       13        5        3       15       18
2       24 
2.650568 2.666237 2.731649 2.749221 2.777130 2.801124 2.804472 2.813891
2.838316 2.839654 
      36       20       25       32       26       12       14       29
23        6 
2.843043 2.868335 2.882906 2.896539 2.922535 2.931397 2.939590 2.944353
2.983473 3.015235 
      39        4       17        9       30       21       33       22
8       35 
3.017590 3.020495 3.038758 3.066808 3.084511 3.086072 3.106873 3.127783
3.167053 3.173310 
      28       16       37        1       31       40       27       11
34       38 
3.173323 3.221106 3.236643 3.274417 3.274772 3.283696 3.307872 3.355327
3.382744 3.498301 


If I use barchart in the trellis library, the bars are arranged by factor
order of the labels (1,10,11,12,etc.).

> barchart(T3,xlab="Mean Values",col="dark blue")

Would it be possible to have the bars arranged from highest to lowest in
terms of the values (2.65, 2.66, 2.73, etc.) as it is done in barplot?

>barplot(T3,xlab="Mean Values",col="dark blue",horiz=T,cex.names=.5)

I would like to use barchart instead of barplot because of some of the
additional features of the lattice library.

Thanks,

Paul



From Venherm.Borchers at t-online.de  Tue Feb  3 07:41:24 2004
From: Venherm.Borchers at t-online.de (Hans W Borchers)
Date: Tue, 03 Feb 2004 07:41:24 +0100
Subject: [R] Nearest Neighbor Algorithm in R -- again.
Message-ID: <401F4294.6060405@t-online.de>

> /Why not modify the C code of knn? (Not knn1)/

Because I thought it would not be a good idea to apply 'knn' a 1000
times or more.

Instead I was looking for a procedure that returns a structure making
it easy to find nearest neighbors for any point one wants. This way I
used 'dist' for smaller data sets.

The next step could be to extent nearest neighbors to data frames with
factors generalizing, for example, the 'daisy' function.

But you might be right that looking at the 'knn' implementation will
be a faster road for the moment.

Hans Werner Borchers
ABB Corporate Research, Germany



From ripley at stats.ox.ac.uk  Tue Feb  3 07:54:52 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Feb 2004 06:54:52 +0000 (GMT)
Subject: [R] Re: packages
In-Reply-To: <Pine.SOL.3.91.1040202172352.13791J-100000@lyapunov.stat.uiuc.edu>
Message-ID: <Pine.LNX.4.44.0402030653130.2756-100000@gannet.stats>

You need to install the package on Windows just as you do on Unix, not 
unzip a *source* package in the destination area.

Please consult the relevant FAQ.

On Mon, 2 Feb 2004, Barbara Bailey wrote:

> I am trying to make my own package of R functions, datasets and help 
> files, which were originally in S and have been converted. As a Unix 
> user, I am trying to make a package that installs on Windows and I am 
> having some trouble. 
> 
> I have a zip file that seems to unzip fine, but I have to use the source 
> command to make functions accessible.  
> 
> e.g. source("C:/Program Files/R/rw1081/library/slab/R/slab.q")
> 
> Is there a command that make happen? or is the .q extention causing trouble?
> 
> It turns out that the data() command works fine, but help files are not 
> accessible either. 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb  3 08:04:58 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Feb 2004 07:04:58 +0000 (GMT)
Subject: [R] running R from PHP
In-Reply-To: <20040203052433.GA25105@pasteur-kh.org>
Message-ID: <Pine.LNX.4.44.0402030658060.2756-100000@gannet.stats>

On Tue, 3 Feb 2004, Philippe Glaziou wrote:

> @biology.nmsu.edu <brook at biology.nmsu.edu> wrote:
> > I would like to construct a PHP script that runs R to generate a
> > graphics file.  Running R itself is no problem.  However, it seems
> > impossible to instantiate one of the graphics devices to create
> > output.  For example, the "normal" bitmap devices (e.g., jpeg, png,
> > etc.) are derived from X11, which requires a display.  This seems
> > true, even if no output is ever directed to a real display.  

It _is_ documented on the help page, and output _is_ directed to a real 
display: you just mever see it.  It is possible make use a virtual display 
such as that provided by Xvfb.

> > For some reason, the postscript device seems to suffer from similar
> > problems.
> > 
> > Is there a trick to creating a graphics device in the absence of an
> > actual display in order to create an image in a file?
> 
> 
> If you need a bitmap graphic file, I would suggest the use of
> ImageMagick:

You may as well use the bitmap() device built into R, which is also a 
wrapper for the use of ghostscript.  That too is described on the help 
page.

I have never seen a reported problem with getting postscript output from a
script. After reading the posting guide, please give us some useful
details of what happened.

> cunegonde:~/tmp> ls
> foo
> 
> cunegonde:~/tmp> cat foo
> pdf(file="g.pdf")
> plot(1:5)
> dev.off()
> 
> cunegonde:~/tmp> R --no-save <foo>/dev/null && convert g.pdf g.png
> 
> cunegonde:~/tmp> ls -g
> -rw-------    1 glaziou      3374 2004-02-03 11:58 g.pdf
> -rw-------    1 glaziou      4115 2004-02-03 11:58 g.png
> -rw-------    1 glaziou        80 2004-02-03 11:58 foo
> 
> 
> This works from a unix console without X running (the postcript
> device works similarly on my machine). R can easily be fed this
> way with a file and parameters passed from a php script.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb  3 08:26:58 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Feb 2004 07:26:58 +0000 (GMT)
Subject: [R] Order in barchart
In-Reply-To: <B32E0B24DEA2E344930910DEC438D0CF309394@amedmlmhah02.heidelberg.amedd.army.mil>
Message-ID: <Pine.LNX.4.44.0402030713020.2756-100000@gannet.stats>

I think you misunderstand what barchart does.  It expects a formula, not a 
named vector, as its first argument.

nm <- names(T3)
z <- factor(nm, levels=nm)
barchart(z ~ T3, xlab="Mean Values", col="dark blue")

is probably what you are looking for.  The factor z is constructed to be 
in the order you want.

That barchart() accepts a named vector appears to be undocumented.  For an 
unnamed vector it does not behave similarly to barplot().


On Mon, 2 Feb 2004, Bliese, Paul D MAJ USAMH wrote:

> Sorry if this is a FAQ -- I checked the archives and help files, but was
> stumped.
> 
> In the data T3 (provided below) the values are sorted from lowest to
> highest.
> 
> > T3
>       10        7       19       13        5        3       15       18
> 2       24 
> 2.650568 2.666237 2.731649 2.749221 2.777130 2.801124 2.804472 2.813891
> 2.838316 2.839654 
>       36       20       25       32       26       12       14       29
> 23        6 
> 2.843043 2.868335 2.882906 2.896539 2.922535 2.931397 2.939590 2.944353
> 2.983473 3.015235 
>       39        4       17        9       30       21       33       22
> 8       35 
> 3.017590 3.020495 3.038758 3.066808 3.084511 3.086072 3.106873 3.127783
> 3.167053 3.173310 
>       28       16       37        1       31       40       27       11
> 34       38 
> 3.173323 3.221106 3.236643 3.274417 3.274772 3.283696 3.307872 3.355327
> 3.382744 3.498301 
> 
> 
> If I use barchart in the trellis library, the bars are arranged by factor
> order of the labels (1,10,11,12,etc.).
> 
> > barchart(T3,xlab="Mean Values",col="dark blue")
> 
> Would it be possible to have the bars arranged from highest to lowest in
> terms of the values (2.65, 2.66, 2.73, etc.) as it is done in barplot?
> 
> >barplot(T3,xlab="Mean Values",col="dark blue",horiz=T,cex.names=.5)
> 
> I would like to use barchart instead of barplot because of some of the
> additional features of the lattice library.
> 
> Thanks,
> 
> Paul
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mail at joeconway.com  Tue Feb  3 08:15:46 2004
From: mail at joeconway.com (Joe Conway)
Date: Mon, 02 Feb 2004 23:15:46 -0800
Subject: [R] running R from PHP
In-Reply-To: <16415.1724.787098.9123@viola.nmsu.edu>
References: <16415.1724.787098.9123@viola.nmsu.edu>
Message-ID: <401F4AA2.2090609@joeconway.com>

brook at biology.nmsu.edu wrote:
> Is there a trick to creating a graphics device in the absence of an
> actual display in order to create an image in a file?

Look for Xvfb (X virtual frame buffer). Not sure what OS you are 
running, but on RH9 and Fedora, at least, there is a package called 
XFree86-Xvfb.

I use Xvfb with the following command:

   /usr/X11R6/bin/Xvfb :5 -screen 0 1024x768x16

More specifically I wrote an init script and set Xvfb up to start as a 
service on boot.

Then in R I use:
   x11(display=":5")

HTH,

Joe



From allan at stats.uct.ac.za  Tue Feb  3 08:59:31 2004
From: allan at stats.uct.ac.za (allan clark)
Date: Tue, 03 Feb 2004 09:59:31 +0200
Subject: [R] R: plotting multiple functions
Message-ID: <401F54E3.7540EF5D@stats.uct.ac.za>

Hi all

Another simple question.

I would like to plot three graphs one the same plot with different
colours. Say red, blue and black. Here are the functions.

r1<-1+5*cos(2*pi*seq(1:100)/20)+rnorm(100)
r2<-1+7*sin(2*pi*seq(1:100)/20)+rnorm(100)
r3<-1+7*sin(2*pi*seq(1:100)/20)+5*cos(2*pi*seq(1:100)/20)+rnorm(100)

Regards
Allan

From bhx2 at mevik.net  Tue Feb  3 09:25:18 2004
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Tue, 03 Feb 2004 09:25:18 +0100
Subject: [R] Stepwise Regression and PLS
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF76EE@usrymx25.merck.com>
	(Andy Liaw's message of "Mon, 2 Feb 2004 09:46:03 -0500")
References: <3A822319EB35174CA3714066D590DCD504AF76EE@usrymx25.merck.com>
Message-ID: <7o8yjk8t8x.fsf@foo.nemo-project.org>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> one needs to be lucky to have the first few PCs correlate well to
> the response in case of PCR.

Which is one reason PLSR is often preferred over PCR in at least the
field of chemometrics.  Since the components of PLSR maximise the
covariance with the response, the first few components are usually
more correlated to the response than PCs.  For spectroscopists, the
PLSR loadings are often very interpretable, and are much used to
qualitatively validate the model.

-- 
Bj?rn-Helge Mevik



From janus at ices.dk  Tue Feb  3 09:35:46 2004
From: janus at ices.dk (Janus Larsen)
Date: Tue, 3 Feb 2004 09:35:46 +0100
Subject: [R] filled maps
Message-ID: <ADD1C7333B42E4459D6E3363FE04A74B0AB1B9@coral.ices.local>

Hi R-Help,

I would like to make filled contour maps of ocean data overlaid by
costlines from the map package.
I can draw the filled contours and the coastlines om the same plot, but
the filled contour also covers part of the land. To get rid of that I
tried to draw a filled coastline map on top of the filled contour, but
the filled map only draws the closed contours - so most of the land is
missing.
Example:
map("worldHires",xlim=c(0,15),ylim=c(50,60)) #Draw relevant region
(North Sea and Denmark waters)
map("worldHires",xlim=c(0,15),ylim=c(50,60),fill=TRUE) # This only draws
Denmark and Holland (Sweden, uk, Germany etc. disappears because they
are not closed polygons).

Any hint on how to fix this problem or a different approach is most
welcome.
Janus



From s-plus at wiwi.uni-bielefeld.de  Tue Feb  3 09:50:39 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Tue, 03 Feb 2004 09:50:39 +0100
Subject: [R] R: plotting multiple functions
References: <401F54E3.7540EF5D@stats.uct.ac.za>
Message-ID: <401F60DF.1060004@wiwi.uni-bielefeld.de>

allan clark wrote:

>Hi all
>
>Another simple question.
>
>I would like to plot three graphs one the same plot with different
>colours. Say red, blue and black. Here are the functions.
>
>r1<-1+5*cos(2*pi*seq(1:100)/20)+rnorm(100)
>r2<-1+7*sin(2*pi*seq(1:100)/20)+rnorm(100)
>r3<-1+7*sin(2*pi*seq(1:100)/20)+5*cos(2*pi*seq(1:100)/20)+rnorm(100)
>
>Regards
>Allan
>
Try:

r1<-1+5*cos(2*pi*seq(1:100)/20)+rnorm(100)
r2<-1+7*sin(2*pi*seq(1:100)/20)+rnorm(100)
r3<-1+7*sin(2*pi*seq(1:100)/20)+5*cos(2*pi*seq(1:100)/20)+rnorm(100)

x <- 1:100
y.min<-min(r1,r2,r3)
y.max<-max(r1,r2,r3)
plot(x,type="n",main="3 graphs", xlab="x",ylab="",ylim=c(y.min,y.max))
lines(x,r1,col="red")
lines(x,r2,col="blue")
lines(x,r3,col="black")
vp<-par()$usr
legend(vp[1]+0.85*(vp[2]-vp[1]),
              vp[3]+0.9*(vp[4]-vp[3]),
              legend=c("graph1","graph2","graph3"),             
              col=c("red","blue","black"),
              lty=rep(1,3),
              bty="n")


Peter



From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Feb  3 09:50:05 2004
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 3 Feb 2004 09:50:05 +0100 (CET)
Subject: [R] mvrnorm problem
In-Reply-To: <x2ektd40ir.fsf@biostat.ku.dk>
References: <000001c3e9c7$cddd9340$28287080@WWS7X5TK31>
	<x2ektd40ir.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.51.0402030948180.19157@artemis.imbe.med.uni-erlangen.de>



> Stuart V Jordan <sjordan at princeton.edu> writes:
>
> > > mvrnorm(n = 1000,B,V)
> > Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) :
> >         non-conformable arrays
> > > mvrnorm(n = 1000,t(B),V)
> > Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) :
> >         non-conformable arrays
>
> You might, for at least two good reasons, have said that this is from
> library(MASS). The point is that
>
> > mvrnorm(n=10,matrix(c(1,1),1,2),diag(2))
> Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) :
>         non-conformable arrays
> > mvrnorm(n=10,matrix(c(1,1),2,1),diag(2))
> Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) :
>         non-conformable arrays
> > mvrnorm(n=10,c(1,1),diag(2))
>             [,1]       [,2]
>  [1,]  0.5005327  1.1919216
>  [2,]  2.8273925  2.7004788
>  [3,]  2.6493970  1.1304274
> ....
>
> and the docs quite clearly say that mu wants to be a vector, not a
> matrix.
>
> Curiously enough, this works with rmvnorm from the mvtnorm package by
> Genz, Bretz, and Hothorn, the difference being that this version adds
> in the means with a sweep() operation, whereas mvrnorm just adds mu
> (to the transpose of the ultimate result) and relies on recycling
> rules.

Credits to Fritz: {rd}mvnorm moved from `e1071' to `mvtnorm' for
obvious reasons some time ago.

Best,

Torsten

> I.e. the point is that
>
> > x <- matrix(1:2,1,2)
> > M <- matrix(1:4,2)
> > x+M
> Error in x + M : non-conformable arrays
> > t(x)+M
> Error in t(x) + M : non-conformable arrays
> > c(x)+M
>      [,1] [,2]
> [1,]    2    4
> [2,]    4    6
> > sweep(M,1,x,"+")
>      [,1] [,2]
> [1,]    2    4
> [2,]    4    6
>
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From maechler at stat.math.ethz.ch  Tue Feb  3 09:54:09 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 3 Feb 2004 09:54:09 +0100
Subject: [R] R: plotting multiple functions
In-Reply-To: <401F54E3.7540EF5D@stats.uct.ac.za>
References: <401F54E3.7540EF5D@stats.uct.ac.za>
Message-ID: <16415.25009.107037.985226@gargle.gargle.HOWL>

>>>>> "allan" == allan clark <allan at stats.uct.ac.za>
>>>>>     on Tue, 03 Feb 2004 09:59:31 +0200 writes:

    allan> Hi all Another simple question.

    allan> I would like to plot three graphs one the same plot
    allan> with different colours. Say red, blue and black. Here
    allan> are the functions.

    allan> r1<-1+5*cos(2*pi*seq(1:100)/20)+rnorm(100)
    allan> r2<-1+7*sin(2*pi*seq(1:100)/20)+rnorm(100)
    allan> r3<-1+7*sin(2*pi*seq(1:100)/20)+5*cos(2*pi*seq(1:100)/20)+rnorm(100)

Use matplot()  and save intermediate things such as in


n <- 100
x <- 2*pi* seq(1:n)/20
mx <- cbind(r1 = 1+5*cos(x) + rnorm(n),
            r2 = 1+7*sin(x) + rnorm(n),
            r3 = 1+7*sin(x)+5*cos(x)+rnorm(n))

matplot(x, mx, type = 'b')
# or if you really want other colours (and no points, e.g.)
matplot(x, mx, type = 'l', col = c("red", "blue", "black"))

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From Timur.Elzhov at jinr.ru  Tue Feb  3 10:13:47 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Tue, 3 Feb 2004 12:13:47 +0300
Subject: [R] R: plotting multiple functions
In-Reply-To: <401F54E3.7540EF5D@stats.uct.ac.za>
References: <401F54E3.7540EF5D@stats.uct.ac.za>
Message-ID: <20040203091347.GA1049@nf034.jinr.ru>

On Tue, Feb 03, 2004 at 09:59:31AM +0200, allan clark wrote:

> Another simple question.
> 
> I would like to plot three graphs one the same plot with different
> colours. Say red, blue and black. Here are the functions.
> 
> r1<-1+5*cos(2*pi*seq(1:100)/20)+rnorm(100)
> r2<-1+7*sin(2*pi*seq(1:100)/20)+rnorm(100)
> r3<-1+7*sin(2*pi*seq(1:100)/20)+5*cos(2*pi*seq(1:100)/20)+rnorm(100)

plot(r1, type = "n")
points(r1, col = "red", pch = 19)  ## see also ?lines
points(r2, col = "blue", pch = 19)
points(r3, col = "black", pch = 19)



From l.houdusse at cerep.fr  Tue Feb  3 10:22:50 2004
From: l.houdusse at cerep.fr (Laurent Houdusse)
Date: Tue, 3 Feb 2004 10:22:50 +0100 
Subject: [R] Normal distribution
Message-ID: <BA420EFAAC96D311A7A0006097D37BDB04515A1B@EOLE>


Hi all!

How to verify a normal distribution in a vector?

thanks


Laurent Houdusse 
Analyste Programmeur



From Ted.Harding at nessie.mcc.ac.uk  Mon Feb  2 23:17:13 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 02 Feb 2004 22:17:13 -0000 (GMT)
Subject: [R] mvrnorm problem
In-Reply-To: <000001c3e9c7$cddd9340$28287080@WWS7X5TK31>
Message-ID: <XFMail.040202221713.Ted.Harding@nessie.mcc.ac.uk>

On 02-Feb-04 Stuart V Jordan wrote:
> I am trying to simulate draws from a multivariate normal using mvrnorm,
> and
> am getting the following error message:
>  
>     Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) : 
>             non-conformable arrays
[...]

Hmmm ... using the same B and V as giben by Stuart Jordan, I get:

> mvrnorm(1,B,V)
 [1]  -179.8332342     0.9632282     2.5687489    -2.2337125    47.2717626
 [6] -3745.3844310     0.9632282     0.2839965    -0.1500585     0.5804460
[11]     5.1919420    -4.7381677    -0.2382119
> mvrnorm(2,B,V)
Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) : 
        non-conformable arrays

?????

Ted.

PS By the way, [near] singularity seems to have nothing to do
   with it here:
   If I brutally make V non-singular:

     diag(V) <- diag(V)+10000000

   it goes the same way.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 02-Feb-04                                       Time: 22:17:13
------------------------------ XFMail ------------------------------



From mendigo at netcabo.pt  Tue Feb  3 11:07:02 2004
From: mendigo at netcabo.pt (M. M. Palhoto N. Rodrigues)
Date: Tue, 3 Feb 2004 10:07:02 -0000
Subject: [R] How to build a  AR(q)-GARCH(q) process ?
Message-ID: <000a01c3ea3d$7b123000$eaa716d5@galactic>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040203/0b1bb62f/attachment.pl

From arv at ono.com  Tue Feb  3 11:28:13 2004
From: arv at ono.com (antonio rodriguez)
Date: Tue, 3 Feb 2004 11:28:13 +0100
Subject: [R] filled maps
In-Reply-To: <ADD1C7333B42E4459D6E3363FE04A74B0AB1B9@coral.ices.local>
Message-ID: <IPEFKICOHOECENGJBAGLMEKPCNAA.arv@ono.com>

Hi,

Some time ago, Roger Peng posted this solution, which I found very useful:

junk.mat <- matrix(rnorm(1600), 16, 100)
contour.mat <- ifelse(junk.mat < 2, 0, junk.mat)
filled.contour(junk.mat, color = terrain.colors, 
               plot.axes = contour(contour.mat, levels = 1, 
                                   drawlabels = FALSE, axes = FALSE, 
                                   frame.plot = FFALSE, add = TRUE))

The 'plot.axes' argument to filled.contour() gives you access to the
coordinate system in the actual plotting area.  However, you will notice
that the axes are missing.  You need to add them explicitly, as in:

filled.contour(junk.mat, color = terrain.colors, 
               plot.axes = { contour(contour.mat, levels = 1, 
                                     drawlabels = FALSE, axes = FALSE, 
                                     frame.plot = FFALSE, add = TRUE);
			     axis(1); axis(2) } )


Cheers,

Antonio

> -----Mensaje original-----
> De: r-help-bounces+arv=ono.com at stat.math.ethz.ch
> [mailto:r-help-bounces+arv=ono.com at stat.math.ethz.ch]En nombre de Janus
> Larsen
> Enviado el: martes, 03 de febrero de 2004 9:36
> Para: R-help at stat.math.ethz.ch
> Asunto: [R] filled maps
> 
> 
> Hi R-Help,
> 
> I would like to make filled contour maps of ocean data overlaid by
> costlines from the map package.
> I can draw the filled contours and the coastlines om the same plot, but
> the filled contour also covers part of the land. To get rid of that I
> tried to draw a filled coastline map on top of the filled contour, but
> the filled map only draws the closed contours - so most of the land is
> missing.
> Example:
> map("worldHires",xlim=c(0,15),ylim=c(50,60)) #Draw relevant region
> (North Sea and Denmark waters)
> map("worldHires",xlim=c(0,15),ylim=c(50,60),fill=TRUE) # This only draws
> Denmark and Holland (Sweden, uk, Germany etc. disappears because they
> are not closed polygons).
> 
> Any hint on how to fix this problem or a different approach is most
> welcome.
> Janus
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html
---
Incoming mail is certified Virus Free.



---



From Roger.Bivand at nhh.no  Tue Feb  3 11:34:06 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 3 Feb 2004 11:34:06 +0100 (CET)
Subject: [R] filled maps
In-Reply-To: <ADD1C7333B42E4459D6E3363FE04A74B0AB1B9@coral.ices.local>
Message-ID: <Pine.LNX.4.44.0402031126440.13233-100000@reclus.nhh.no>

On Tue, 3 Feb 2004, Janus Larsen wrote:

> Hi R-Help,
> 
> I would like to make filled contour maps of ocean data overlaid by
> costlines from the map package.
> I can draw the filled contours and the coastlines om the same plot, but
> the filled contour also covers part of the land. To get rid of that I
> tried to draw a filled coastline map on top of the filled contour, but
> the filled map only draws the closed contours - so most of the land is
> missing.
> Example:
> map("worldHires",xlim=c(0,15),ylim=c(50,60)) #Draw relevant region
> (North Sea and Denmark waters)
> map("worldHires",xlim=c(0,15),ylim=c(50,60),fill=TRUE) # This only draws
> Denmark and Holland (Sweden, uk, Germany etc. disappears because they
> are not closed polygons).

Looks as though you can use the regions= argument:

> res <- map("worldHires",xlim=c(0,15),ylim=c(50,60), plot=FALSE, 
+ namesonly=TRUE)
> res
 [1] "Denmark"                     "USSR"                       
 [3] "Netherlands"                 "Netherlands:IJsselmeer"     
 [5] "France"                      "Czechoslovakia"             
 [7] "Poland"                      "Germany"                    
 [9] "Luxembourg"                  "Belgium"                    
[11] "Norway"                      "Sweden"                     
[13] "Germany:Usedom"              "Netherlands:South"          
[15] "Germany:Langeoog"            "Denmark:Mors"               
[17] "Denmark:Mon"                 "Lake Fjerritslev"           
[19] "UK:Great Britain"            "Denmark:Samso"              
[21] "Netherlands:Ameland"         "Netherlands:Terschelling"   
[23] "Denmark:Als"                 "Denmark:Sjaelland"          
[25] "Denmark:Fyn"                 "Netherlands:Schiermonnikoog"
[27] "Denmark:Laeso"               "Sweden:Orust"               
[29] "Germany:Borkum"              "Denmark:Lolland"            
[31] "Netherlands:Texel"           "Netherlands:Flevoland"      
[33] "Norway:Sunnhordland"         "UK:Isle of Sheppey"         
[35] "Denmark:Langeland"           "Denmark:Bornholm"           
[37] "Germany:Fehmarn"             "Germany:Rugen"              
[39] "Germany:Norderney"           "Norway:Karmoy"       
> map("worldHires",xlim=c(0,15),ylim=c(50,60))
> map("worldHires",regions=res, fill=TRUE, add=TRUE)

fixes it for me. Curiously, the longitudes add 2.5 degrees on each side.

Roger

PS. For film viewers who enjoyed "Good bye, Lenin!", we still provide 
region="USSR" above!


> 
> Any hint on how to fix this problem or a different approach is most
> welcome.
> Janus
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From baud-bovy.gabriel at hsr.it  Tue Feb  3 11:40:19 2004
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Tue, 03 Feb 2004 11:40:19 +0100
Subject: [R] Implementating streams in R
Message-ID: <5.2.1.1.1.20040203111204.00b820c8@mail.hsr.it>

Dear all,

I have an implementation of streams in R. The current implementation of 
delay() and force() is
inspired from  the LISP implementation found in Part VI "Languages for AI 
problem solving" of
"Artificial Intelligence" by G. Luger.

I have tested it with the Fibonacci example in the same book (see examples 
below).  It works
but I do run into a problem when I try to generate fibonacci series more 
than 25 elements.

 > accumulate.into.list(25,fibonacci.stream(0,1))
Error in cons.stream(fibonacci1 + fibonacci2, 
fibonacci.stream(fibonacci2,  : evaluation is nested too deeply: infinite 
recursion?

Traceback show that the call stack has 101 elements at this point. What is 
the parameter
limiting the number of recursive calls to 100?  What is its relation to the 
"expressions" setting
in options()?

More fundamentally, I would appreciate any comment on this implementation 
or suggestion about
the best way of implementing streams in R.  My objective is to implement 
logic programming
interpreter in R as done in LISP by G.F.Luger in his book or by  Abelson & 
Sussman in "Structure
and Interpreation of Computer Program".

Thank you,

Gabriel


###
### Examples
###


 > fib<-fibonacci.stream(0,1)

Note that the  fibonacci.stream() function is a nonterminating recursive 
function. It works only because
of the delayed evaluation introduced by the delay() function in 
cons.stream() . It would not work if I
implemented streams as simple list (see example at the very end of this 
posting).

 > head.stream(fib)   # get the first element
[1] 1
 > tail.stream(fib)     # get the second element
[[1]]
[1] 2
[[2]]
function ()
expression
<environment: 00F343E0>

 > tail.stream(tail.stream(fib)) # get the third element
[[1]]
[1] 3
[[2]]
function ()
expression
<environment: 01958774>

 > accumulate.into.list(5,fibonacci.stream(0,1)) # construct a list with 
the 5 first Fibonacci numbers
 > accumulate.into.list(5,filter.odds(fibonacci.stream(0,1)))  # construct 
a list with the 5 first Fibonacci odd numbers


###
### Fibonaccy stream
###

fibonacci.stream<-function(fibonacci1,fibonacci2) {
         cons.stream(fibonacci1+fibonacci2,
                 fibonacci.stream(fibonacci2, fibonacci1+fibonacci2))
}

filter.odds<-function(stream) {
         if(is.even(head.stream(stream))) {
                 filter.odds(tail.stream(stream))
         } else {
                 cons.stream(head.stream(stream),filter.odds(tail.stream(stream)))
         }
}

accumulate.into.list<-function(n,stream) {
         if(n==0) {
                 NULL
         } else {
                 cons(head.stream(stream),
                         accumulate.into.list(n-1,tail.stream(stream)))
         }
}

is.even<-function(x) x%%2==0

###
### stream functions
###

delay<-function(expression) {
         as.function(alist(expression))
}

force<-function(function.closure) {
         function.closure()
}

cons.stream<-function(expression,stream) {
         list(expression,delay(stream))
}

head.stream<-function(stream) {
         stream[[1]]
}

tail.stream<-function(stream) {
         force(stream[[2]])
}


###
### lists
###

cons<-function(element,list) {
         c(list(element),list)
}

car<-function(list) {
         list[[1]]
}

cdr<-function(list)  {
         list[-1]
}

is.empty.list<-function(list) {
         length(list)==0
}

make.empty.list<-function() {
         vector(mode="list",length=0)
}



if(0) {

# This implementation of streams as simple lists (see definition of cons, 
car and cdr below) leads
# to an infinite recursion because fibonacci is a nonterminating recursive 
function and that both
# arguments are evaluated.

cons.stream<-function(expression,stream) cons(expression,stream)
head.stream<-function(stream) car(stream)
tail.stream<-function(stream) cdr(stream)

 > fibonacci.stream(0,1)
Error in cons(expression, stream) : evaluation is nested too deeply: 
infinite recursion?

}

--------------------------------------------------------------------
Gabriel Baud-Bovy
Faculty of Psychology
UHSR University
via Olgettina, 58	tel: (+39) 02 2643 4839
20132 Milan, Italy	fax: (+39) 02 2643 4892



From arv at ono.com  Tue Feb  3 11:44:21 2004
From: arv at ono.com (antonio rodriguez)
Date: Tue, 3 Feb 2004 11:44:21 +0100
Subject: [R] filled maps
In-Reply-To: <ADD1C7333B42E4459D6E3363FE04A74B0AB1C5@coral.ices.local>
Message-ID: <IPEFKICOHOECENGJBAGLIELACNAA.arv@ono.com>

Hi Janus,

Try this:


filled.contour(x,y,corr.map2, color = terrain.colors,
plot.axes = { contour(x,y,corr.map2,nlevels=20,
drawlabels = T, frame.plot = FFALSE, add = TRUE);
axis(1); axis(2);
world(col="red",add=T,lwd=3)},
key.title = title(main="values"),
xlab="longitude",ylab="latitude" )


Antonio

> -----Mensaje original-----
> De: Janus Larsen [mailto:janus at ices.dk]
> Enviado el: martes, 03 de febrero de 2004 11:36
> Para: antonio rodriguez
> Asunto: RE: [R] filled maps
> 
> 
> Hi Antonio,
> 
> Thanks for your prompt answer - but I can't see how that will solve my
> problem (which is overlaying contour plots with filled coastlines from
> the mapdata package).
> As far as I can see, what you show is how to add contour lines to a
> filled contour plot.. Or am I missing something?
> 
> Cheers,
> Janus
> 
> -----Original Message-----
> From: antonio rodriguez [mailto:arv at ono.com] 
> Sent: 03 February 2004 11:28
> To: Janus Larsen; R-help at stat.math.ethz.ch
> Subject: RE: [R] filled maps
> 
> 
> Hi,
> 
> Some time ago, Roger Peng posted this solution, which I found very
> useful:
> 
> junk.mat <- matrix(rnorm(1600), 16, 100)
> contour.mat <- ifelse(junk.mat < 2, 0, junk.mat)
> filled.contour(junk.mat, color = terrain.colors, 
>                plot.axes = contour(contour.mat, levels = 1, 
>                                    drawlabels = FALSE, axes = FALSE, 
>                                    frame.plot = FFALSE, add = TRUE))
> 
> The 'plot.axes' argument to filled.contour() gives you access to the
> coordinate system in the actual plotting area.  However, you will notice
> that the axes are missing.  You need to add them explicitly, as in:
> 
> filled.contour(junk.mat, color = terrain.colors, 
>                plot.axes = { contour(contour.mat, levels = 1, 
>                                      drawlabels = FALSE, axes = FALSE, 
>                                      frame.plot = FFALSE, add = TRUE);
> 			     axis(1); axis(2) } )
> 
> 
> Cheers,
> 
> Antonio
> 
> > -----Mensaje original-----
> > De: r-help-bounces+arv=ono.com at stat.math.ethz.ch
> > [mailto:r-help-bounces+arv=ono.com at stat.math.ethz.ch]En nombre de 
> > Janus Larsen Enviado el: martes, 03 de febrero de 2004 9:36
> > Para: R-help at stat.math.ethz.ch
> > Asunto: [R] filled maps
> > 
> > 
> > Hi R-Help,
> > 
> > I would like to make filled contour maps of ocean data overlaid by 
> > costlines from the map package. I can draw the filled contours and the
> 
> > coastlines om the same plot, but the filled contour also covers part 
> > of the land. To get rid of that I tried to draw a filled coastline map
> 
> > on top of the filled contour, but the filled map only draws the closed
> 
> > contours - so most of the land is missing.
> > Example:
> > map("worldHires",xlim=c(0,15),ylim=c(50,60)) #Draw relevant region
> > (North Sea and Denmark waters)
> > map("worldHires",xlim=c(0,15),ylim=c(50,60),fill=TRUE) # This only
> draws
> > Denmark and Holland (Sweden, uk, Germany etc. disappears because they
> > are not closed polygons).
> > 
> > Any hint on how to fix this problem or a different approach is most 
> > welcome. Janus
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> ---
> Incoming mail is certified Virus Free.
> Checked by AVG anti-virus system (http://www.grisoft.com).
> Version: 6.0.571 / Virus Database: 361 - Release Date: 26/01/2004
> 
> ---
> Outgoing mail is certified Virus Free.
> Checked by AVG anti-virus system (http://www.grisoft.com).
> Version: 6.0.571 / Virus Database: 361 - Release Date: 26/01/2004
> 
> ---
> Incoming mail is certified Virus Free.
> Checked by AVG anti-virus system (http://www.grisoft.com).
> Version: 6.0.571 / Virus Database: 361 - Release Date: 26/01/2004
> 
---



From feh3k at spamcop.net  Tue Feb  3 11:45:02 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 3 Feb 2004 05:45:02 -0500
Subject: [R] Stepwise Regression and PLS
In-Reply-To: <7o8yjk8t8x.fsf@foo.nemo-project.org>
References: <3A822319EB35174CA3714066D590DCD504AF76EE@usrymx25.merck.com>
	<7o8yjk8t8x.fsf@foo.nemo-project.org>
Message-ID: <20040203054502.2ec2816c.feh3k@spamcop.net>

On Tue, 03 Feb 2004 09:25:18 +0100
bhx2 at mevik.net (Bj?rn-Helge Mevik) wrote:

> "Liaw, Andy" <andy_liaw at merck.com> writes:
> 
> > one needs to be lucky to have the first few PCs correlate well to
> > the response in case of PCR.
> 
> Which is one reason PLSR is often preferred over PCR in at least the
> field of chemometrics.  Since the components of PLSR maximise the
> covariance with the response, the first few components are usually
> more correlated to the response than PCs.  For spectroscopists, the
> PLSR loadings are often very interpretable, and are much used to
> qualitatively validate the model.
> 
> -- 
> Bj?rn-Helge Mevik

>From what you described PLSR needs an additional validation step not
needed as much by PCR, because its optimization to the response variable
can cause overfitting.  PCR does not use the response until data reduction
is completed.

Frank
---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From simon.hosking at general.monash.edu.au  Tue Feb  3 10:43:18 2004
From: simon.hosking at general.monash.edu.au (Simon Hosking)
Date: Tue, 03 Feb 2004 20:43:18 +1100
Subject: [R] creating a factor
In-Reply-To: <200402021312.i12BsGB1018655@hypatia.math.ethz.ch>
References: <200402021312.i12BsGB1018655@hypatia.math.ethz.ch>
Message-ID: <1075801398.4771.15.camel@localhost.localdomain>

Hi list,
I'd like to make a factor with seven 1s and three 2s using the
factor() function. 
That is,

1
1
1
1
1
1
1
2
2
2
 

I will then bind this factor to the matrix below using cbind.data.frame().

0.56	0.48
0.22	0.59
0.32	0.64
0.26	0.60
0.25	0.38
0.24	0.45
0.56	0.67
0.78	0.97
0.87	0.79
0.82	0.85



I am new to R and have been using various manuals and have made many attempts without success
any help appreciated.
thanks,
Simon



From ripley at stats.ox.ac.uk  Tue Feb  3 12:39:05 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Feb 2004 11:39:05 +0000 (GMT)
Subject: [R] Implementating streams in R
In-Reply-To: <5.2.1.1.1.20040203111204.00b820c8@mail.hsr.it>
Message-ID: <Pine.LNX.4.44.0402031134430.3897-100000@gannet.stats>

On Tue, 3 Feb 2004, Gabriel Baud-Bovy wrote:

> Dear all,
> 
> I have an implementation of streams in R. The current implementation of 
> delay() and force() is
> inspired from  the LISP implementation found in Part VI "Languages for AI 
> problem solving" of
> "Artificial Intelligence" by G. Luger.
> 
> I have tested it with the Fibonacci example in the same book (see examples 
> below).  It works
> but I do run into a problem when I try to generate fibonacci series more 
> than 25 elements.
> 
>  > accumulate.into.list(25,fibonacci.stream(0,1))
> Error in cons.stream(fibonacci1 + fibonacci2, 
> fibonacci.stream(fibonacci2,  : evaluation is nested too deeply: infinite 
> recursion?
> 
> Traceback show that the call stack has 101 elements at this point. What is 
> the parameter
> limiting the number of recursive calls to 100?  What is its relation to the 
> "expressions" setting
> in options()?

There isn't one.  The limit is on nesting expressions, as given in 
options().  One call may generate several expressions, though, and your 
calls probably generate 5 each.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb  3 12:42:57 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Feb 2004 11:42:57 +0000 (GMT)
Subject: [R] mvrnorm problem
In-Reply-To: <XFMail.040202221713.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0402031139520.3897-100000@gannet.stats>

As Peter Dalgaard has already pointed out, you both need to read the help 
page.

If you supply a matrix where the help page asks for a vector, you are 
likely to get troubles.  I will coerce it for the next version, but I 
would like to point out that in about 12 years of providing mvrnorm (often 
as here without credit), this it the first time anyone has made this error 
in public.  Anticipating what people will try is not easy.

On Mon, 2 Feb 2004 Ted.Harding at nessie.mcc.ac.uk wrote:

> On 02-Feb-04 Stuart V Jordan wrote:
> > I am trying to simulate draws from a multivariate normal using mvrnorm,
> > and
> > am getting the following error message:
> >  
> >     Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) : 
> >             non-conformable arrays
> [...]
> 
> Hmmm ... using the same B and V as giben by Stuart Jordan, I get:
> 
> > mvrnorm(1,B,V)
>  [1]  -179.8332342     0.9632282     2.5687489    -2.2337125    47.2717626
>  [6] -3745.3844310     0.9632282     0.2839965    -0.1500585     0.5804460
> [11]     5.1919420    -4.7381677    -0.2382119
> > mvrnorm(2,B,V)
> Error in mu + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) : 
>         non-conformable arrays
> 
> ?????
> 
> Ted.
> 
> PS By the way, [near] singularity seems to have nothing to do
>    with it here:
>    If I brutally make V non-singular:
> 
>      diag(V) <- diag(V)+10000000
> 
>    it goes the same way.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 02-Feb-04                                       Time: 22:17:13
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Tue Feb  3 12:49:06 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 03 Feb 2004 06:49:06 -0500
Subject: [R] Implementating streams in R
In-Reply-To: <5.2.1.1.1.20040203111204.00b820c8@mail.hsr.it>
References: <5.2.1.1.1.20040203111204.00b820c8@mail.hsr.it>
Message-ID: <ki2v10pdo44jcftqf59amouhprtu2g5vh8@4ax.com>

On Tue, 03 Feb 2004 11:40:19 +0100, you wrote:

>Dear all,
>
>I have an implementation of streams in R.
...
>More fundamentally, I would appreciate any comment on this implementation 
>or suggestion about
>the best way of implementing streams in R. 

Could you describe in a language-independent way what you mean by
"streams"?  My understanding of the word is matches S "connections",
which are already there.

Duncan Murdoch



From allan at stats.uct.ac.za  Tue Feb  3 12:57:53 2004
From: allan at stats.uct.ac.za (allan clark)
Date: Tue, 03 Feb 2004 13:57:53 +0200
Subject: [R] R: lags and plots
Message-ID: <401F8CC1.24C3FDE@stats.uct.ac.za>

Hi all

I want to calculate certain lags of a time series and plot them
simultaneously on a graph. can anyone help?



From p.dalgaard at biostat.ku.dk  Tue Feb  3 13:39:04 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Feb 2004 13:39:04 +0100
Subject: [R] creating a factor
In-Reply-To: <1075801398.4771.15.camel@localhost.localdomain>
References: <200402021312.i12BsGB1018655@hypatia.math.ethz.ch>
	<1075801398.4771.15.camel@localhost.localdomain>
Message-ID: <x2llnk2v87.fsf@biostat.ku.dk>

Simon Hosking <simon.hosking at general.monash.edu.au> writes:

> Hi list,
> I'd like to make a factor with seven 1s and three 2s using the
> factor() function. 
> That is,
> 
> 1
> 1
> 1
> 1
> 1
> 1
> 1
> 2
> 2
> 2
>  
> 
> I will then bind this factor to the matrix below using cbind.data.frame().
> 
> 0.56	0.48
> 0.22	0.59
> 0.32	0.64
> 0.26	0.60
> 0.25	0.38
> 0.24	0.45
> 0.56	0.67
> 0.78	0.97
> 0.87	0.79
> 0.82	0.85
> 
> 
> 
> I am new to R and have been using various manuals and have made many attempts without success
> any help appreciated.
> thanks,
> Simon


> f <- factor(scan())
1: 1
2: 1
3: 1
4: 1
5: 1
6: 1
7: 1
8: 2
9: 2
10: 2
11:
Read 10 items


> df <- read.table(stdin())
0: 0.56 0.48
1: 0.22 0.59
2: 0.32 0.64
3: 0.26 0.60
4: 0.25 0.38
6: 0.24 0.45
7: 0.56 0.67
8: 0.78 0.97
9: 0.87 0.79
10: 0.82 0.85
11:


> cbind(df,f)
     V1   V2 f
1  0.56 0.48 1
2  0.22 0.59 1
3  0.32 0.64 1
4  0.26 0.60 1
5  0.25 0.38 1
6  0.24 0.45 1
7  0.56 0.67 1
8  0.78 0.97 2
9  0.87 0.79 2
10 0.82 0.85 2

> summary(cbind(df,f))
       V1               V2         f
 Min.   :0.2200   Min.   :0.3800   1:7
 1st Qu.:0.2525   1st Qu.:0.5075   2:3
 Median :0.4400   Median :0.6200
 Mean   :0.4880   Mean   :0.6420
 3rd Qu.:0.7250   3rd Qu.:0.7600
 Max.   :0.8700   Max.   :0.9700


so what was the problem?? 

I suspect your df was a matrix, not a data frame: just take
as.data.frame first. Otherwise, you'll find that f gets converted to
numeric.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jfox at mcmaster.ca  Tue Feb  3 14:04:00 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 03 Feb 2004 08:04:00 -0500
Subject: [R] output from multcomp and lm
In-Reply-To: <009701c3e9f7$9424f5f0$0c01a8c0@HP31522725682>
Message-ID: <5.1.0.14.2.20040203080012.02002cf0@127.0.0.1>

Dear Hiroto,

The anova() function reports a sequential analysis of variance, so the test 
for Cond ignores the covariate. A good guess is that the effect of Cond 
isn't significant controlling for the covariate. You could instead use 
drop1() or Anova() in the car package.

I hope that this helps,
  John

At 10:46 AM 2/3/2004 +0900, Hiroto Miyoshi wrote:

>Dear R-users
>
>I analysed the same data set by two different ways;
>analysis of covariance by using lm and anova functions
>and multiple comparison by using simtest function in
>the multcomp library.
>
>The output from the analysis of covariance is;
>
> >   y<-lm(D~Cond+Q1,data=x)
> > anova(y)
>Analysis of Variance Table
>
>Response: D
>              Df Sum Sq Mean Sq F value    Pr(>F)
>Cond        2 1017.8   508.9   4.7548  0.0135041 *
>Q1           1 1652.7  1652.7 15.4417  0.0002969 ***
>Residuals 44 4709.2   107.0
>---
>Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
>where Cond is a factor with three levels (A,B,C)
>and Q1 is a covariate.
>
>
>
>Now, simtest showed the following output
>
> >   o5<-summary(simtest(D~Cond+Q1,conf.level=0.95,data=x,type="Tukey"))
> >   o5
>
>   Simultaneous tests: Tukey contrasts
>
>Call:
>simtest.formula(formula = D ~ Cond + Q1, data = x, conf.level = 0.95,
>     type = "Tukey")
>
>   Tukey contrasts for factor Cond, covariable:  Q1
>
>Contrast matrix:
>               CondA CondB CondC
>CondB-CondA 0    -1     1     0 0
>CondC-CondA 0    -1     0     1 0
>CondC-CondB 0     0    -1     1 0
>
>
>Absolute Error Tolerance:  0.001
>
>Coefficients:
>                     Estimate t value Std.Err. p raw  p Bonf  p adj
>CondB-CondA    5.555  -1.461    3.802  0.151   0.453   0.319
>CondC-CondB   -5.248  -1.365    3.661 0.179   0.453   0.319
>CondC-CondA    0.306  -0.084    3.844  0.934   0.934   0.934
>
>The results from two analyses seem so different that I am
>wondering why.  I do understand that multiple comparison may
>not show any significant difference even when the overall analysis
>of (co)variance shows the statistical significance of a factor.
>
>However, in my analysis, overall analysis showed statistical significance of
>1.4% level and mutiple comparison showed significance of 32% level
>Could this happen? and why?  Please enlighten me.
]
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From jfox at mcmaster.ca  Tue Feb  3 14:08:50 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 03 Feb 2004 08:08:50 -0500
Subject: [R] creating a factor
In-Reply-To: <1075801398.4771.15.camel@localhost.localdomain>
References: <200402021312.i12BsGB1018655@hypatia.math.ethz.ch>
	<200402021312.i12BsGB1018655@hypatia.math.ethz.ch>
Message-ID: <5.1.0.14.2.20040203080536.0205bbc0@127.0.0.1>

Dear Simon,

One doesn't generally use cbind.data.frame() directly, but rather through 
the generic function cbind(). I believe that the following will give you 
what you want:

fac <- factor(c(rep(1,7), rep(2,3)))
cbind(fac, as.data.frame(mat))

where mat is the matrix.

I hope that this helps,
  John



At 08:43 PM 2/3/2004 +1100, Simon Hosking wrote:
>Hi list,
>I'd like to make a factor with seven 1s and three 2s using the
>factor() function.
>That is,
>
>1
>1
>1
>1
>1
>1
>1
>2
>2
>2
>
>
>I will then bind this factor to the matrix below using cbind.data.frame().
>
>0.56    0.48
>0.22    0.59
>0.32    0.64
>0.26    0.60
>0.25    0.38
>0.24    0.45
>0.56    0.67
>0.78    0.97
>0.87    0.79
>0.82    0.85
>
>
>
>I am new to R and have been using various manuals and have made many 
>attempts without success
>any help appreciated.
>thanks,
>Simon

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From bates at stat.wisc.edu  Tue Feb  3 14:10:11 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 03 Feb 2004 07:10:11 -0600
Subject: [R] creating a factor
In-Reply-To: <1075801398.4771.15.camel@localhost.localdomain>
References: <200402021312.i12BsGB1018655@hypatia.math.ethz.ch>
	<1075801398.4771.15.camel@localhost.localdomain>
Message-ID: <6rfzdsb970.fsf@bates4.stat.wisc.edu>

Simon Hosking <simon.hosking at general.monash.edu.au> writes:

> I'd like to make a factor with seven 1s and three 2s using the
> factor() function. 
> That is,
> 
> 1
> 1
> 1
> 1
> 1
> 1
> 1
> 2
> 2
> 2

factor(rep(1:2, c(7,3)))

> I will then bind this factor to the matrix below using cbind.data.frame().
> 
> 0.56	0.48
> 0.22	0.59
> 0.32	0.64
> 0.26	0.60
> 0.25	0.38
> 0.24	0.45
> 0.56	0.67
> 0.78	0.97
> 0.87	0.79
> 0.82	0.85

It is not a good idea to use methods like cbind.data.frame directly.
Use the generic function cbind instead.  The point of having method
functions is to be able to choose the method that is appropriate to
the data.

If you have the matrix shown above stored as a matrix named mat then

cbind(factor(rep(1:2, c(7,3))), mat)

will work but it will also work if mat is a data frame.

> factor(rep(1:2, c(7,3)))
 [1] 1 1 1 1 1 1 1 2 2 2
Levels: 1 2
> mat = read.table("/tmp/foo.dat")
> mat
     V1   V2
1  0.56 0.48
2  0.22 0.59
3  0.32 0.64
4  0.26 0.60
5  0.25 0.38
6  0.24 0.45
7  0.56 0.67
8  0.78 0.97
9  0.87 0.79
10 0.82 0.85
> str(mat)
`data.frame':	10 obs. of  2 variables:
 $ V1: num  0.56 0.22 0.32 0.26 0.25 0.24 0.56 0.78 0.87 0.82
 $ V2: num  0.48 0.59 0.64 0.6 0.38 0.45 0.67 0.97 0.79 0.85
> mm = cbind(factor(rep(1:2, c(7,3))), mat)
> str(mm)
`data.frame':	10 obs. of  3 variables:
 $ factor(rep(1:2, c(7, 3))): Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 2 2 2
 $ V1                       : num  0.56 0.22 0.32 0.26 0.25 0.24 0.56 0.78 0.87 0.82
 $ V2                       : num  0.48 0.59 0.64 0.6 0.38 0.45 0.67 0.97 0.79 0.85

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From l.houdusse at cerep.fr  Tue Feb  3 14:14:54 2004
From: l.houdusse at cerep.fr (Laurent Houdusse)
Date: Tue, 3 Feb 2004 14:14:54 +0100 
Subject: [R] Normal distribution
Message-ID: <BA420EFAAC96D311A7A0006097D37BDB04515A1D@EOLE>

I try to use ks.test to determine a normal distribution:

x<-c(11.5,27.9,9,10.7,30.0,9.5,14.2,14,9.4,6.1)
ks.test(x,function(x) pnorm(x,mean=mean(x),sd=sd(x)))

Is it a correct method?
I verify with SigmaStat, the D value is the same but the p-value is
different, Why??
SigmaStat p-value=0.01      R p-value=0.3234

Thanks for your help!



Laurent Houdusse 
Analyste Programmeur



From luke at stat.uiowa.edu  Tue Feb  3 14:16:38 2004
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 3 Feb 2004 07:16:38 -0600 (CST)
Subject: [R] Implementating streams in R
In-Reply-To: <5.2.1.1.1.20040203111204.00b820c8@mail.hsr.it>
Message-ID: <Pine.LNX.4.44.0402030707450.10716-100000@itasca2.stat.uiowa.edu>

I worked on this a bit a while back for a possible article for Rnews
that won't get written anytime soon.  I've put a snapshot in

	http://www.stat.uiowa.edu/~luke/R/lazy/

It is based on examples in Paulson's ML book and Abelson and Susman;
the overall design seems similar to the one you have but the details
differ.  Hope it's of some use.

luke

On Tue, 3 Feb 2004, Gabriel Baud-Bovy wrote:

> Dear all,
> 
> I have an implementation of streams in R. The current implementation of 
> delay() and force() is
> inspired from  the LISP implementation found in Part VI "Languages for AI 
> problem solving" of
> "Artificial Intelligence" by G. Luger.
> 
> I have tested it with the Fibonacci example in the same book (see examples 
> below).  It works
> but I do run into a problem when I try to generate fibonacci series more 
> than 25 elements.
> 
>  > accumulate.into.list(25,fibonacci.stream(0,1))
> Error in cons.stream(fibonacci1 + fibonacci2, 
> fibonacci.stream(fibonacci2,  : evaluation is nested too deeply: infinite 
> recursion?
> 
> Traceback show that the call stack has 101 elements at this point. What is 
> the parameter
> limiting the number of recursive calls to 100?  What is its relation to the 
> "expressions" setting
> in options()?
> 
> More fundamentally, I would appreciate any comment on this implementation 
> or suggestion about
> the best way of implementing streams in R.  My objective is to implement 
> logic programming
> interpreter in R as done in LISP by G.F.Luger in his book or by  Abelson & 
> Sussman in "Structure
> and Interpreation of Computer Program".
> 
> Thank you,
> 
> Gabriel
> 
> 
> ###
> ### Examples
> ###
> 
> 
>  > fib<-fibonacci.stream(0,1)
> 
> Note that the  fibonacci.stream() function is a nonterminating recursive 
> function. It works only because
> of the delayed evaluation introduced by the delay() function in 
> cons.stream() . It would not work if I
> implemented streams as simple list (see example at the very end of this 
> posting).
> 
>  > head.stream(fib)   # get the first element
> [1] 1
>  > tail.stream(fib)     # get the second element
> [[1]]
> [1] 2
> [[2]]
> function ()
> expression
> <environment: 00F343E0>
> 
>  > tail.stream(tail.stream(fib)) # get the third element
> [[1]]
> [1] 3
> [[2]]
> function ()
> expression
> <environment: 01958774>
> 
>  > accumulate.into.list(5,fibonacci.stream(0,1)) # construct a list with 
> the 5 first Fibonacci numbers
>  > accumulate.into.list(5,filter.odds(fibonacci.stream(0,1)))  # construct 
> a list with the 5 first Fibonacci odd numbers
> 
> 
> ###
> ### Fibonaccy stream
> ###
> 
> fibonacci.stream<-function(fibonacci1,fibonacci2) {
>          cons.stream(fibonacci1+fibonacci2,
>                  fibonacci.stream(fibonacci2, fibonacci1+fibonacci2))
> }
> 
> filter.odds<-function(stream) {
>          if(is.even(head.stream(stream))) {
>                  filter.odds(tail.stream(stream))
>          } else {
>                  cons.stream(head.stream(stream),filter.odds(tail.stream(stream)))
>          }
> }
> 
> accumulate.into.list<-function(n,stream) {
>          if(n==0) {
>                  NULL
>          } else {
>                  cons(head.stream(stream),
>                          accumulate.into.list(n-1,tail.stream(stream)))
>          }
> }
> 
> is.even<-function(x) x%%2==0
> 
> ###
> ### stream functions
> ###
> 
> delay<-function(expression) {
>          as.function(alist(expression))
> }
> 
> force<-function(function.closure) {
>          function.closure()
> }
> 
> cons.stream<-function(expression,stream) {
>          list(expression,delay(stream))
> }
> 
> head.stream<-function(stream) {
>          stream[[1]]
> }
> 
> tail.stream<-function(stream) {
>          force(stream[[2]])
> }
> 
> 
> ###
> ### lists
> ###
> 
> cons<-function(element,list) {
>          c(list(element),list)
> }
> 
> car<-function(list) {
>          list[[1]]
> }
> 
> cdr<-function(list)  {
>          list[-1]
> }
> 
> is.empty.list<-function(list) {
>          length(list)==0
> }
> 
> make.empty.list<-function() {
>          vector(mode="list",length=0)
> }
> 
> 
> 
> if(0) {
> 
> # This implementation of streams as simple lists (see definition of cons, 
> car and cdr below) leads
> # to an infinite recursion because fibonacci is a nonterminating recursive 
> function and that both
> # arguments are evaluated.
> 
> cons.stream<-function(expression,stream) cons(expression,stream)
> head.stream<-function(stream) car(stream)
> tail.stream<-function(stream) cdr(stream)
> 
>  > fibonacci.stream(0,1)
> Error in cons(expression, stream) : evaluation is nested too deeply: 
> infinite recursion?
> 
> }
> 
> --------------------------------------------------------------------
> Gabriel Baud-Bovy
> Faculty of Psychology
> UHSR University
> via Olgettina, 58	tel: (+39) 02 2643 4839
> 20132 Milan, Italy	fax: (+39) 02 2643 4892
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From laurent.tatin at netcourrier.com  Tue Feb  3 14:47:05 2004
From: laurent.tatin at netcourrier.com (Laurent TATIN)
Date: Tue,  3 Feb 2004 14:47:05 CET
Subject: [R] GEE
Message-ID: <mnet1.1075816025.20643.laurent.tatin@netcourrier.com>

Bonjour,

J'etudie une population de chevaux en captivite. Je souhaite identifier le ou les facteurs qui influencent la fecondite des femelles (=nombre de poulain= 0 ou 1) depuis 1995 jusqu'a 2003. Les variables explicatives sont donc disponibles pour les femelles par annee :
fem1_annee1
fem2_annee1
fem3_annee1
fem1_annee2
fem2_annee2
fem3_annee2
fem4_annee2
etc.

Le nombre de femelles n'est donc pas le meme par annee puisque de nouvelles femelles deviennent matures.
J'ai choisi d'utiliser les GEE pour repondre a ma question... est-ce le meilleur modele pour ca ? Si oui faut-il considerer les annees comme clusters ou bien les femelles ? comment specifier le "correlation link" ?

merci de votre aide

Laurent

Association TAKH
Station Biologique Tour du Valat
13200 ARLES
France
web site: www.tourduvalat.org

-------------------------------------------------------------
NetCourrier, votre bureau virtuel sur Internet : Mail, Agenda, Clubs, Toolbar...
Web/Wap : www.netcourrier.com
T?l?phone/Fax : 08 92 69 00 21 (0,34  TTC/min)
Minitel: 3615 NETCOURRIER (0,16  TTC/min)



From petr.pikal at precheza.cz  Tue Feb  3 14:52:54 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 03 Feb 2004 14:52:54 +0100
Subject: [R] creating a factor
In-Reply-To: <1075801398.4771.15.camel@localhost.localdomain>
References: <200402021312.i12BsGB1018655@hypatia.math.ethz.ch>
Message-ID: <401FB5C6.15420.FD5F48@localhost>

Hallo

On 3 Feb 2004 at 20:43, Simon Hosking wrote:

> Hi list,
> I'd like to make a factor with seven 1s and three 2s using the
> factor() function. 
> That is,
> 

your.f <- factor(rep(c(1,2),c(7,3)))

> 1
> 1
> 1
> 1
> 1
> 1
> 1
> 2
> 2
> 2
> 
> 
> I will then bind this factor to the matrix below using
> cbind.data.frame().
> 
> 0.56	0.48
> 0.22	0.59
> 0.32	0.64
> 0.26	0.60
> 0.25	0.38
> 0.24	0.45
> 0.56	0.67
> 0.78	0.97
> 0.87	0.79
> 0.82	0.85
> 

your.frame<-cbind(your.f,your.matrix)

with your numbers ordered into 10x2 matrix like

cbind(factor(rep(c(1,2),c(7,3))),matrix(rnorm(20),10,2))
or
data.frame(var.f=factor(rep(c(1,2),c(7,3))),matrix(rnorm(20),10,2))


> 
> 
> I am new to R and have been using various manuals and have made many

Did you really follow examples from "An Introduction to R" manual?

> attempts without success any help appreciated. thanks, Simon

Cheers Petr


> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From JonesW at kssg.com  Tue Feb  3 15:01:28 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Tue, 3 Feb 2004 14:01:28 -0000 
Subject: [R] R: lags and plots
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0F8B@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040203/02134273/attachment.pl

From Laetitia.Marisa at cgm.cnrs-gif.fr  Tue Feb  3 15:23:58 2004
From: Laetitia.Marisa at cgm.cnrs-gif.fr (Laetitia Marisa)
Date: Tue, 03 Feb 2004 15:23:58 +0100
Subject: [R] Prompt / Console problem
Message-ID: <401FAEFE.7010101@cgm.cnrs-gif.fr>

Hi,

I have R installed under a Mandrake linux system and I don't have shell 
utilities any more under my R console such as completion when writing a 
file path, back and forth in the history, bindkeys... Moreover when I 
quit R by saving, no .Rhistory file is created while the .Rdata is. I 
don't get how this work, I thought it was based on the user unix shell 
but it does not seem.
Any ideas??

Thanks for you help,

Laetitia.



From Achim.Zeileis at wu-wien.ac.at  Tue Feb  3 15:29:38 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 3 Feb 2004 15:29:38 +0100
Subject: [R] R: lags and plots
In-Reply-To: <401F8CC1.24C3FDE@stats.uct.ac.za>
References: <401F8CC1.24C3FDE@stats.uct.ac.za>
Message-ID: <20040203152938.11640b4e.Achim.Zeileis@wu-wien.ac.at>

On Tue, 03 Feb 2004 13:57:53 +0200 allan clark wrote:

> Hi all
> 
> I want to calculate certain lags of a time series and plot them
> simultaneously on a graph. can anyone help?

Something like this?

R> x <- ts(cumsum(rnorm(20)), start = 0, freq = 10)
R> plot(x)
R> lines(lag(x, k = -1), col = 4)

hth
Z



From p.dalgaard at biostat.ku.dk  Tue Feb  3 15:41:23 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Feb 2004 15:41:23 +0100
Subject: [R] Normal distribution
In-Reply-To: <BA420EFAAC96D311A7A0006097D37BDB04515A1D@EOLE>
References: <BA420EFAAC96D311A7A0006097D37BDB04515A1D@EOLE>
Message-ID: <x23c9s2pkc.fsf@biostat.ku.dk>

Laurent Houdusse <l.houdusse at cerep.fr> writes:

> I try to use ks.test to determine a normal distribution:
> 
> x<-c(11.5,27.9,9,10.7,30.0,9.5,14.2,14,9.4,6.1)
> ks.test(x,function(x) pnorm(x,mean=mean(x),sd=sd(x)))
> 
> Is it a correct method?
> I verify with SigmaStat, the D value is the same but the p-value is
> different, Why??
> SigmaStat p-value=0.01      R p-value=0.3234
> 
> Thanks for your help!

ks.test works for comparison with a fixed distribution, and you are
plugging in estimated parameters. This makes the test highly
conservative. SigmaStat presumably uses a correction term. 

Anyway shapiro.test() would be a more obvious choice in my opinion.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From wolski at molgen.mpg.de  Tue Feb  3 16:17:49 2004
From: wolski at molgen.mpg.de (wolski)
Date: Tue, 03 Feb 2004 16:17:49 +0100
Subject: [R] Passing characters by .Call
Message-ID: <200402031617490336.04A903D0@harry.molgen.mpg.de>

Hi!

I try to pass a character by the .Call interface to an c function. And to cast it into  a 

char *ch;

Is it possible to do it and how?


Eryk



From eje4 at cornell.edu  Tue Feb  3 16:29:46 2004
From: eje4 at cornell.edu (Eric Evans)
Date: Tue, 03 Feb 2004 10:29:46 -0500
Subject: [R] Linux installation problem
Message-ID: <5.2.1.1.2.20040203102544.00b6b698@postoffice9.mail.cornell.edu>

Hello everyone,

I downloaded the latest Linux version of R and tried installing it, but 
during the installation process I found that this version of R requires tcl 
8.3 and tk 8.3.  The problem is that I've been unable to find Linux 
versions of tcl 8.3 and tk 8.3.  The only Linux versions of tcl/tk I've 
been able to find are 8.4.  Has anybody been successful in getting R to 
install on Linux recently, and if so can you please tell me where you got 
your tcl/tk 8.3?  Thanks very much.

Eric Evans



From spencer.graves at pdf.com  Tue Feb  3 16:29:29 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 03 Feb 2004 07:29:29 -0800
Subject: [R] R: lags and plots
In-Reply-To: <401F8CC1.24C3FDE@stats.uct.ac.za>
References: <401F8CC1.24C3FDE@stats.uct.ac.za>
Message-ID: <401FBE59.6050404@pdf.com>

      Consider the following: 

       plot(1:9, (1:10)[-1])
       lines(1:9, (1:10)[-10])

      Does this help? 
      spencer graves

allan clark wrote:

>Hi all
>
>I want to calculate certain lags of a time series and plot them
>simultaneously on a graph. can anyone help?
>
>
>  
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From stuart.leask at nottingham.ac.uk  Tue Feb  3 16:44:37 2004
From: stuart.leask at nottingham.ac.uk (Stuart Leask)
Date: Tue, 3 Feb 2004 15:44:37 -0000
Subject: [R] r-squared equivalent for locally-smoothed figures?
References: <401A4A7F.1050301@unibas.ch>	<200401301238.17940.deepayan@stat.wisc.edu><Pine.SOL.4.58.0401301353340.2982@tetris.gpcc.itd.umich.edu>
	<401D6A7C.1040507@stat.auckland.ac.nz>
Message-ID: <004c01c3ea6c$a0fa9490$f2e1f380@OPENZAURUS>

Does anyone know a rough equivalent of the r-squared statistic for lines or
surfaces fitted to data using local smoothing (eg. using the sm or locfit
libraries)? I feel there must be some manner in which such locally-smoothed
figures explain a fraction of the total squared error in the data...  Can
such a fraction be obtained from locfit (or sm) objects?

Stuart

Dr Stuart Leask DM MRCPsych, Senior Lecturer in Clinical Psychiatry
University Dept of Psychiatry, Duncan Macmillan House
Porchester Road, Nottingham. NG3 6AA. UK
http://www.nottingham.ac.uk/psychiatry/staff/s_leask.html



From maechler at stat.math.ethz.ch  Tue Feb  3 17:02:08 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 3 Feb 2004 17:02:08 +0100
Subject: [R] R: lags and plots
In-Reply-To: <401F8CC1.24C3FDE@stats.uct.ac.za>
References: <401F8CC1.24C3FDE@stats.uct.ac.za>
Message-ID: <16415.50688.689426.72289@gargle.gargle.HOWL>

>>>>> "allan" == allan clark <allan at stats.uct.ac.za>
>>>>>     on Tue, 03 Feb 2004 13:57:53 +0200 writes:

    allan> Hi all I want to calculate certain lags of a time
    allan> series and plot them simultaneously on a graph. can
    allan> anyone help?

Use  lag.plot()  {name and part of UI is for S+ compatibility}

Martin



From Roger.Bivand at nhh.no  Tue Feb  3 17:02:55 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 3 Feb 2004 17:02:55 +0100 (CET)
Subject: [R] Passing characters by .Call
In-Reply-To: <200402031617490336.04A903D0@harry.molgen.mpg.de>
Message-ID: <Pine.LNX.4.44.0402031650200.13233-100000@reclus.nhh.no>

On Tue, 3 Feb 2004, wolski wrote:

> Hi!
> 
> I try to pass a character by the .Call interface to an c function. And to cast it into  a 
> 
> char *ch;
> 
> Is it possible to do it and how?
> 

Yes. First make sure you have your "Writing R Extensions" handy. Next
decide whether you are going to use Rdefines.h or Rinternals.h. Then read
the chosen header file (in R/includes/). (Rdefines.h includes
Rinternals.h). For example line 255 in Rinternals.h gives

#define STRING_ELT(x,i)	((SEXP *) DATAPTR(x))[i]

I have used incantations like

CHAR(STRING_ELT(x, 0)) 

where x is a character vector - be prepared to use Rprintf() to check that
your assignment works out. 

> 
> Eryk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From wolski at molgen.mpg.de  Tue Feb  3 17:09:53 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Tue, 03 Feb 2004 17:09:53 +0100
Subject: [R] Passing characters by .Call
In-Reply-To: <Pine.LNX.4.44.0402031650200.13233-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0402031650200.13233-100000@reclus.nhh.no>
Message-ID: <200402031709530693.06820FE2@harry.molgen.mpg.de>

Hi!

Thank a lot!
Its what I was  looking for.

Eryk.




*********** REPLY SEPARATOR  ***********

On 2/3/2004 at 5:02 PM Roger Bivand wrote:

>On Tue, 3 Feb 2004, wolski wrote:
>
>> Hi!
>> 
>> I try to pass a character by the .Call interface to an c function. And
>to cast it into  a 
>> 
>> char *ch;
>> 
>> Is it possible to do it and how?
>> 
>
>Yes. First make sure you have your "Writing R Extensions" handy. Next
>decide whether you are going to use Rdefines.h or Rinternals.h. Then read
>the chosen header file (in R/includes/). (Rdefines.h includes
>Rinternals.h). For example line 255 in Rinternals.h gives
>
>#define STRING_ELT(x,i)	((SEXP *) DATAPTR(x))[i]
>
>I have used incantations like
>
>CHAR(STRING_ELT(x, 0)) 
>
>where x is a character vector - be prepared to use Rprintf() to check that
>your assignment works out. 
>
>> 
>> Eryk
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>> 
>
>-- 
>Roger Bivand
>Econonic Geography Section, Department of Economics, Norwegian School of 
>Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
>Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics   
Ihnestrasse 73 14195 Berlin          'v'    
tel: 0049-30-84131285               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From Timur.Elzhov at jinr.ru  Tue Feb  3 17:25:53 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Tue, 3 Feb 2004 19:25:53 +0300
Subject: [R] lm coefficients
Message-ID: <20040203162553.GA2938@nf034.jinr.ru>

Dear R experts,

Excuse me if my question will be stupid...
I'd like to fit data with x^2 polynomial:

d <- read.table(file = "Oleg.dat", head = TRUE)
d
  X         T
  3720.00   4.113
  3715.00   4.123
  3710.00   4.132
  ...

out <- lm(T ~ poly(X, 4), data = d)
out
  Call:
  lm(formula = T ~ poly(X, 2), data = d)
  
  Coefficients:
  (Intercept)  poly(X, 2)1  poly(X, 2)2  
        9.803     -108.075       51.007  

So, d$T best fitted with function
  9.803 -108.075 * X + 51.007 * X^2,
yes?

T1 <- 9.803 -108.075 * d$X + 51.007 * d$X^2
T1
  705453240
  703557595
  701664500
  699773956
  ...

So, T1 obviosly gets non-sensible values.. :( Why?
Thanks a lot!

--
WBR,
Timur.



From ryszard.czerminski at pharma.novartis.com  Tue Feb  3 17:39:44 2004
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Tue, 3 Feb 2004 11:39:44 -0500
Subject: [R] problem with read.table
Message-ID: <OF7A5C2B46.CAFAAB4D-ON85256E2F.005B0393-85256E2F.005BA8AE@EU.novartis.net>

Any ideas why read.table complains about not correct number of elements in 
line
while readLine/strsplit indicate that all lines have the same number of 
elements ?

R


> tbl <- read.table('tmp', header = T, sep = '\t')
Error in scan(file = file, what = what, sep = sep, quote = quote, dec = 
dec,  : 
        line 32 did not have 27 elements
> lines <- readLines('tmp')
> v <- 1:length(lines)
> i <- 0; for (line in lines) { i <- i + 1; v[i] <- length(strsplit(line, 
'\t')[[1]]) }
> v
 [1] 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 
27 27
[26] 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 
27 27
[51] 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27
> sum((v - v[1])^2)
[1] 0
> length(strsplit(lines[32], '\t')[[1]])
[1] 27



From rbaer at atsu.edu  Tue Feb  3 17:43:57 2004
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Tue, 3 Feb 2004 10:43:57 -0600
Subject: [R] creating a factor
Message-ID: <003701c3ea74$eb13b8b0$2e80010a@BigBaer>

> Hi list,
> I'd like to make a factor with seven 1s and three 2s using the
> factor() function.
> That is,
>
> 1
> 1
> 1
> 1
> 1
> 1
> 1
> 2
> 2
> 2
>
>
> I will then bind this factor to the matrix below using cbind.data.frame().
>
> 0.56 0.48
> 0.22 0.59
> 0.32 0.64
> 0.26 0.60
> 0.25 0.38
> 0.24 0.45
> 0.56 0.67
> 0.78 0.97
> 0.87 0.79
> 0.82 0.85
_________________
See if this code sequence gives you insight:

 x1=c(0.56,0.22,0.32,0.26,0.25,0.24,0.56,0.78,0.87,0.82)
 x2=c(0.48,0.59,0.64,0.6,0.38,0.45,0.67,0.97,0.79,0.85)
 x=data.frame(cbind(x1,x2))
fac2=as.factor(c("dog","dog","dog","dog","dog","dog","dog","cat","cat","cat"
))
 xf=cbind(fac2,x)
xf
data.class(xf)
data.class(xf$fac2)
levels(xf$fac2)

Rob Baer



From deepayan at stat.wisc.edu  Tue Feb  3 17:52:26 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 3 Feb 2004 10:52:26 -0600
Subject: [R] Order in barchart
In-Reply-To: <Pine.LNX.4.44.0402030713020.2756-100000@gannet.stats>
References: <Pine.LNX.4.44.0402030713020.2756-100000@gannet.stats>
Message-ID: <200402031052.27109.deepayan@stat.wisc.edu>

On Tuesday 03 February 2004 01:26, Prof Brian Ripley wrote:

> I think you misunderstand what barchart does.  It expects a formula, not a
> named vector, as its first argument.
>
> nm <- names(T3)
> z <- factor(nm, levels=nm)
> barchart(z ~ T3, xlab="Mean Values", col="dark blue")
>
> is probably what you are looking for.  The factor z is constructed to be
> in the order you want.
>
> That barchart() accepts a named vector appears to be undocumented.  


This is true in S-PLUS as well (AFAIK), but seemed to be a common enough 
usage. I wasn't able to fiure out exactly what S-PLUS does, but what lattice 
does is the following:

step 1. A call like barchart(x) is converted to barchart( ~ x)

step 2. If x is named, the missing y is generated by y = names(x).
        If x is not named, y = rep('', length(x))

I'll add this information to the documentation.


Anyway, the rest of the explanation is the usual one of factor levels being 
ordered alphabetically by default, which you would have to override as 
indicated by Prof Ripley.

Deepayan



> unnamed vector it does not behave similarly to barplot().
>
> On Mon, 2 Feb 2004, Bliese, Paul D MAJ USAMH wrote:
> > Sorry if this is a FAQ -- I checked the archives and help files, but was
> > stumped.
> >
> > In the data T3 (provided below) the values are sorted from lowest to
> > highest.
> >
> > > T3
> >
> >       10        7       19       13        5        3       15       18
> > 2       24
> > 2.650568 2.666237 2.731649 2.749221 2.777130 2.801124 2.804472 2.813891
> > 2.838316 2.839654
> >       36       20       25       32       26       12       14       29
> > 23        6
> > 2.843043 2.868335 2.882906 2.896539 2.922535 2.931397 2.939590 2.944353
> > 2.983473 3.015235
> >       39        4       17        9       30       21       33       22
> > 8       35
> > 3.017590 3.020495 3.038758 3.066808 3.084511 3.086072 3.106873 3.127783
> > 3.167053 3.173310
> >       28       16       37        1       31       40       27       11
> > 34       38
> > 3.173323 3.221106 3.236643 3.274417 3.274772 3.283696 3.307872 3.355327
> > 3.382744 3.498301
> >
> >
> > If I use barchart in the trellis library, the bars are arranged by factor
> > order of the labels (1,10,11,12,etc.).
> >
> > > barchart(T3,xlab="Mean Values",col="dark blue")
> >
> > Would it be possible to have the bars arranged from highest to lowest in
> > terms of the values (2.65, 2.66, 2.73, etc.) as it is done in barplot?
> >
> > >barplot(T3,xlab="Mean Values",col="dark blue",horiz=T,cex.names=.5)
> >
> > I would like to use barchart instead of barplot because of some of the
> > additional features of the lattice library.
> >
> > Thanks,
> >
> > Paul



From sundar.dorai-raj at pdf.com  Tue Feb  3 17:57:12 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 03 Feb 2004 10:57:12 -0600
Subject: [R] lm coefficients
In-Reply-To: <20040203162553.GA2938@nf034.jinr.ru>
References: <20040203162553.GA2938@nf034.jinr.ru>
Message-ID: <401FD2E8.20400@pdf.com>

Look at ?poly. It's doing something your not expecting.

What you want is

lm(T ~ X + I(X^2), data = d)

Regards,
Sundar


Timur Elzhov wrote:

> Dear R experts,
> 
> Excuse me if my question will be stupid...
> I'd like to fit data with x^2 polynomial:
> 
> d <- read.table(file = "Oleg.dat", head = TRUE)
> d
>   X         T
>   3720.00   4.113
>   3715.00   4.123
>   3710.00   4.132
>   ...
> 
> out <- lm(T ~ poly(X, 4), data = d)
> out
>   Call:
>   lm(formula = T ~ poly(X, 2), data = d)
>   
>   Coefficients:
>   (Intercept)  poly(X, 2)1  poly(X, 2)2  
>         9.803     -108.075       51.007  
> 
> So, d$T best fitted with function
>   9.803 -108.075 * X + 51.007 * X^2,
> yes?
> 
> T1 <- 9.803 -108.075 * d$X + 51.007 * d$X^2
> T1
>   705453240
>   703557595
>   701664500
>   699773956
>   ...
> 
> So, T1 obviosly gets non-sensible values.. :( Why?
> Thanks a lot!
> 
> --
> WBR,
> Timur.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From bates at stat.wisc.edu  Tue Feb  3 18:00:34 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 03 Feb 2004 11:00:34 -0600
Subject: [R] Passing characters by .Call
In-Reply-To: <200402031709530693.06820FE2@harry.molgen.mpg.de>
References: <Pine.LNX.4.44.0402031650200.13233-100000@reclus.nhh.no>
	<200402031709530693.06820FE2@harry.molgen.mpg.de>
Message-ID: <6rektcksi5.fsf@bates4.stat.wisc.edu>

> On 2/3/2004 at 5:02 PM Roger Bivand wrote:

> >Yes. First make sure you have your "Writing R Extensions" handy. Next
> >decide whether you are going to use Rdefines.h or Rinternals.h. Then read
> >the chosen header file (in R/includes/). (Rdefines.h includes
> >Rinternals.h). For example line 255 in Rinternals.h gives
> >
> >#define STRING_ELT(x,i)	((SEXP *) DATAPTR(x))[i]
> >
> >I have used incantations like
> >
> >CHAR(STRING_ELT(x, 0)) 
> >
> >where x is a character vector - be prepared to use Rprintf() to check that
> >your assignment works out. 

Another incantation that helps when you are passing a single character
string is
  CHAR(asChar(x))
because asChar will check the type of its argument and coerce it if
necessary.

Similar functions called asInteger, asLogical, and asReal exist for
other types.

Note that these only give you the first element of their argument (or
NA if the argument has length zero or cannot be coerced).



From tlumley at u.washington.edu  Tue Feb  3 18:04:12 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 3 Feb 2004 09:04:12 -0800 (PST)
Subject: [R] lm coefficients
In-Reply-To: <20040203162553.GA2938@nf034.jinr.ru>
References: <20040203162553.GA2938@nf034.jinr.ru>
Message-ID: <Pine.A41.4.58.0402030902300.107162@homer04.u.washington.edu>

On Tue, 3 Feb 2004, Timur Elzhov wrote:

> Dear R experts,
>
> Excuse me if my question will be stupid...
> I'd like to fit data with x^2 polynomial:
>
<snip>
> out <- lm(T ~ poly(X, 4), data = d)
> out
>   Call:
>   lm(formula = T ~ poly(X, 2), data = d)
>
>   Coefficients:
>   (Intercept)  poly(X, 2)1  poly(X, 2)2
>         9.803     -108.075       51.007
>
> So, d$T best fitted with function
>   9.803 -108.075 * X + 51.007 * X^2,


No.  The predictors are not X and X^2, but two orthogonal polynomials.
Look at the help page for poly().

	-thomas



From spencer.graves at pdf.com  Tue Feb  3 18:22:09 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 03 Feb 2004 09:22:09 -0800
Subject: [R] lm coefficients
In-Reply-To: <20040203162553.GA2938@nf034.jinr.ru>
References: <20040203162553.GA2938@nf034.jinr.ru>
Message-ID: <401FD8C1.70801@pdf.com>

      The function "poly" produces orthogonal polynomials, and those 
depend on the exact combinations of levels of X in "d".  Consider the 
following: 

 > round(poly(1:3, 2), 2)
         1     2
[1,] -0.71  0.41
[2,]  0.00 -0.82
[3,]  0.71  0.41

 > round(poly(1:4, 2), 2)
         1    2
[1,] -0.67  0.5
[2,] -0.22 -0.5
[3,]  0.22 -0.5
[4,]  0.67  0.5

      Does this answer your question? 
      spencer graves

Timur Elzhov wrote:

>Dear R experts,
>
>Excuse me if my question will be stupid...
>I'd like to fit data with x^2 polynomial:
>
>d <- read.table(file = "Oleg.dat", head = TRUE)
>d
>  X         T
>  3720.00   4.113
>  3715.00   4.123
>  3710.00   4.132
>  ...
>
>out <- lm(T ~ poly(X, 4), data = d)
>out
>  Call:
>  lm(formula = T ~ poly(X, 2), data = d)
>  
>  Coefficients:
>  (Intercept)  poly(X, 2)1  poly(X, 2)2  
>        9.803     -108.075       51.007  
>
>So, d$T best fitted with function
>  9.803 -108.075 * X + 51.007 * X^2,
>yes?
>
>T1 <- 9.803 -108.075 * d$X + 51.007 * d$X^2
>T1
>  705453240
>  703557595
>  701664500
>  699773956
>  ...
>
>So, T1 obviosly gets non-sensible values.. :( Why?
>Thanks a lot!
>
>--
>WBR,
>Timur.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ripley at stats.ox.ac.uk  Tue Feb  3 18:27:40 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Feb 2004 17:27:40 +0000 (GMT)
Subject: [R] lm coefficients
In-Reply-To: <20040203162553.GA2938@nf034.jinr.ru>
Message-ID: <Pine.LNX.4.44.0402031726060.10082-100000@gannet.stats>

Do read ?poly: you have orthogonal polynomials.

On Tue, 3 Feb 2004, Timur Elzhov wrote:

> Dear R experts,
> 
> Excuse me if my question will be stupid...
> I'd like to fit data with x^2 polynomial:
> 
> d <- read.table(file = "Oleg.dat", head = TRUE)
> d
>   X         T
>   3720.00   4.113
>   3715.00   4.123
>   3710.00   4.132
>   ...
> 
> out <- lm(T ~ poly(X, 4), data = d)

You asked for 4 and got 2?  Really?

> out
>   Call:
>   lm(formula = T ~ poly(X, 2), data = d)
>   
>   Coefficients:
>   (Intercept)  poly(X, 2)1  poly(X, 2)2  
>         9.803     -108.075       51.007  
> 
> So, d$T best fitted with function
>   9.803 -108.075 * X + 51.007 * X^2,
> yes?

No!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From a.trapletti at bluewin.ch  Tue Feb  3 18:28:31 2004
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Tue, 03 Feb 2004 18:28:31 +0100
Subject: [R] How to build a  AR(q)-GARCH(q) process ?
Message-ID: <401FDA3F.7060209@bluewin.ch>

>
>
>Hello all,    
>
>I would like how to modelized a time serie with AR-ARCH process.
>It can be used arma and garch functions in tseries package for build
>ar process or a garch process, but how can it be modelized a ar-garch
>model ?
>
>Thanks
>	[[alternative HTML version deleted]]
>

For example, follow "A.A.Weiss: ARMA models with ARCH errors. Journal of 
Time Series Analysis, No. 2, Vol. 5, 1984."

best
Adrian

-- 
Dr. Adrian Trapletti
Trapletti Statistical Computing
Wildsbergstrasse 31, 8610 Uster
Switzerland
Phone & Fax : +41 (0) 1 994 5631
Mobile : +41 (0) 76 370 5631
Email : mailto:a.trapletti at bluewin.ch
WWW : http://trapletti.homelinux.com



From rpeng at jhsph.edu  Tue Feb  3 19:39:03 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 03 Feb 2004 13:39:03 -0500
Subject: [R] Prompt / Console problem
In-Reply-To: <401FAEFE.7010101@cgm.cnrs-gif.fr>
References: <401FAEFE.7010101@cgm.cnrs-gif.fr>
Message-ID: <401FEAC7.9000105@jhsph.edu>

The features you are looking for are provided to R by the 
readline library.  Most likely, your version of R was not 
built with readline support.

On some Linux distributions with package management systems 
(I'm not sure about Mandrake), you sometimes need to install 
a package named readline-devel or something like that (the 
development version of the library) before compiling R.

-roger

Laetitia Marisa wrote:
> Hi,
> 
> I have R installed under a Mandrake linux system and I don't have shell 
> utilities any more under my R console such as completion when writing a 
> file path, back and forth in the history, bindkeys... Moreover when I 
> quit R by saving, no .Rhistory file is created while the .Rdata is. I 
> don't get how this work, I thought it was based on the user unix shell 
> but it does not seem.
> Any ideas??
> 
> Thanks for you help,
> 
> Laetitia.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue Feb  3 19:47:05 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Feb 2004 18:47:05 +0000 (GMT)
Subject: [R] Prompt / Console problem
In-Reply-To: <401FAEFE.7010101@cgm.cnrs-gif.fr>
Message-ID: <Pine.LNX.4.44.0402031845030.10339-100000@gannet.stats>

It depends on having readline available.  If you compiled this yourself, 
please consult the R-admin manual (as INSTALL asks).  If you installed an 
RPM, please talk to the provider of the RPM.

On Tue, 3 Feb 2004, Laetitia Marisa wrote:

> I have R installed under a Mandrake linux system and I don't have shell 
> utilities any more under my R console such as completion when writing a 
> file path, back and forth in the history, bindkeys... Moreover when I 
> quit R by saving, no .Rhistory file is created while the .Rdata is. I 
> don't get how this work, I thought it was based on the user unix shell 
> but it does not seem.
> Any ideas??

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From partha_bagchi at hgsi.com  Tue Feb  3 20:27:38 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue, 3 Feb 2004 14:27:38 -0500
Subject: [R] Insightful acquires "S" language
Message-ID: <OF15553D54.609C745A-ON85256E2F.006AB346-85256E2F.006AE633@hgsi.com>

Has anyone else received an email saying that Insightful has acquired the 
S programming language? What do you think is the impact (if any) of this 
news on R?

Partha



From p.murrell at auckland.ac.nz  Tue Feb  3 20:41:27 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 04 Feb 2004 08:41:27 +1300
Subject: [R] Re: R Home Page Graphic Competition
References: <3FC10F03.1050608@stat.auckland.ac.nz>
Message-ID: <401FF967.90201@stat.auckland.ac.nz>

Hi

Due to the low number of entries received so far, the deadline for the R 
Home Page Graphic Competition has been extended to February 29 2004.

The free registration to useR! 2004 is still available and if we do not 
receive any image that we can use for the home page, we will draw a name 
at random from among the submissions we receive.

The original competition announcement is included below:


> R Home Page Graphic Competition
> ===============================
> 
> We're looking for a snazzy graphic for the home page of the R Project.
> 
> Please send us your favourite R image and the best (as chosen by R-core) 
> will be used on the web site.  The author of the winning image will also 
> receive *free registration* for the useR! 2004 conference 
> (http://www.ci.tuwien.ac.at/Conferences/useR-2004/)
> 
> The original image should be produced using R.  Images which have been 
> "jazzed up" using a graphics program such as gimp will also be 
> considered (but may suffer an "impurity" penalty in the judging).
> 
> Please send images and source code (and data) used to produce them, to 
> paul at stat.auckland.ac.nz
> 
> R-core reserves the right to decide that the R user base is just as 
> devoid of artistic talent as R-core itself;  we only promise to make use 
> of zero or more of the submitted images on the web site.
> 
> The R-core development team.


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From eje4 at cornell.edu  Tue Feb  3 20:48:04 2004
From: eje4 at cornell.edu (Eric Evans)
Date: Tue, 03 Feb 2004 14:48:04 -0500
Subject: [R] Linux R installation problem, never mind....
Message-ID: <5.2.1.1.2.20040203144556.00b75008@postoffice9.mail.cornell.edu>

Hi friends,

Please disregard my previous plea for help.  I finally found the tcl/tk 
packages I needed in order to get the Linux version of R to install.  The 
tcl/tk packages can be found at http://prdownloads.sourceforge.net/tcl/.

Eric



From pburns at pburns.seanet.com  Tue Feb  3 20:46:10 2004
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 03 Feb 2004 19:46:10 +0000
Subject: [R] How to build a  AR(q)-GARCH(q) process ?
References: <000a01c3ea3d$7b123000$eaa716d5@galactic>
Message-ID: <401FFA82.8010301@pburns.seanet.com>

In the absence of a function that will estimate a joint AR-GARCH
model, you can estimate them separately.  So you could estimate
the AR parameters and then estimate GARCH on the residuals
from the AR model.

I know that MA parameter estimates are quite robust to GARCH.
I don't know for sure that AR is as well, but I suspect so.

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

M. M. Palhoto N. Rodrigues wrote:

>Hello all,    
>
>I would like how to modelized a time serie with AR-ARCH process.
>It can be used arma and garch functions in tseries package for build
>ar process or a garch process, but how can it be modelized a ar-garch
>model ?
>
>Thanks
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From N.L.Pace at m.cc.utah.edu  Tue Feb  3 21:42:50 2004
From: N.L.Pace at m.cc.utah.edu (Nathan Leon Pace, MD, MStat)
Date: Tue, 03 Feb 2004 13:42:50 -0700
Subject: [R] S
Message-ID: <8843034D-5689-11D8-9D39-000393B3E9D0@utah.edu>

The Splus people have bought S from lucent.

Does that have implications for R?

Nathan
Nathan Leon Pace, MD, MStat	Work:n.l.pace at utah.edu
Department of Anesthesiology	Home:nlpaces at comcast.net
University of Utah			Work:801.581.6393
Salt Lake City, Utah			    Home:801.467.2925
					Fax:801.581.4367										Cell:801.558.3987



From cstrato at aon.at  Tue Feb  3 21:48:45 2004
From: cstrato at aon.at (cstrato)
Date: Tue, 03 Feb 2004 21:48:45 +0100
Subject: [R] Robust regression of nonlinear function
In-Reply-To: <401ED7C6.3060004@pdf.com>
References: <3A822319EB35174CA3714066D590DCD50205CE96@usrymx25.merck.com>	<3FC51AB5.6020806@aon.at>	<401AA785.5010609@aon.at>	<401EA4F3.70303@aon.at>
	<401ECC7D.7060502@aon.at> <401ED7C6.3060004@pdf.com>
Message-ID: <4020092D.30605@aon.at>

Dear Spencer and all

As you see, I have changed the subject title, because at the moment
this was my interest.

ad 2, I am checking always MASS first.

ad 1, As mentioned above, I wanted to do a robust fit of a nonlinear
function, although robust nonlinear regression is also of interest
to me. Thank you all for your replies, especially Sundar Dorai-Raj,
who gave the final hint:
lf <- lm(z ~ x + I(x^2) + I(x^3) - 1, data = df)
lf
Coefficients:
      x  I(x^2)  I(x^3)
10.972   3.793  -1.942

lf1 <- lm(z1 ~ x + I(x^2) + I(x^3) - 1, data = df1)
lf1
Coefficients:
       x   I(x^2)   I(x^3)
-59.053    4.170   -1.072

Now, using rlm from MASS gives the following results:
rlf <- rlm(z ~ x + I(x^2) + I(x^3) - 1, data = df)
rlf
Converged in 3 iterations

Coefficients:
         x    I(x^2)    I(x^3)
11.118137  3.793672 -1.943496

rlf1 <- rlm(z1 ~ x + I(x^2) + I(x^3) - 1, data = df1)
rlf1
Converged in 5 iterations

Coefficients:
         x    I(x^2)    I(x^3)
-2.169452  3.826027 -1.778487

Comparing lm and rlm reveals that rlm is able to
handle outliers much better than lm.

Best regards
Christian



Spencer Graves wrote:

>      1.  The question of "linear" vs. "nonlinear" means "linear in the 
> parameters to be estimated.  All the examples you have given so far are 
> linear in the parameters to be estimated.  The fact that they are 
> nonlinear in "x" is immaterial.
>      2.  With this hint and the posting guide 
> "http://www.R-project.org/posting-guide.html", you may find more 
> information.  A search there exposed much discussion of "robust 
> regression" and even "robust nonlinear regression", if you actually 
> still need that.  In addition, I found useful information on robust 
> regression in Venables and Ripley (2002) Modern Applied Statistics with 
> S, 4th ed. (Springer).
>      hope this helps.      spencer graves
> 
> cstrato wrote:
> 
>> Dear all
>>
>> Here is a hopefully better example with regards to
>> nonlinear robust fitting:
>>
>> # fitting a polynomial:
>> x <- seq(-10,10,0.2)
>> y <- 10*x + 4*x*x - 2*x*x*x
>> plot(x,y)
>> z <- jitter(y,amount=300)
>> plot(x,z)
>> df <- as.data.frame(cbind(x,z))
>> nf <- nls(z ~ a*x + b*x*x + c*x*x*x, data=df,
>> +           start=list(a=4,b=2,c=1), trace = TRUE)
>> 127697531 :  4 2 1
>> 2974480 :  10.972123  3.793426 -1.942278
>>
>> # introducing outliers before fitting the  polynomial:
>> z1 <- z
>> z1[c(16,22,23,34,36,42,67,69,72,76)] <-
>> + c(2000,1900,2000,1900,1600,1600,500,-2000,-1700,-1800)
>> plot(x,z1)
>> df1 <- as.data.frame(cbind(x,z1))
>> nf1 <- nls(z1 ~ a*x + b*x*x + c*x*x*x, data=df1,
>> +           start=list(a=4,b=2,c=1), trace = TRUE)
>> 159359174 :  4 2 1
>> 24098548 :  -59.053288   4.169518  -1.072027
>>
>> # plotting the results:
>> y1 <- 10.97*x + 3.79*x*x - 1.94*x*x*x
>> y2 <- -59.05*x + 4.17*x*x - 1.07*x*x*x
>> oldpar <- par(pty="s",mfrow=c(2,2),mar=c(5,5,4,1))
>> plot(x,y)
>> plot(x,z1)
>> plot(x,y1)
>> plot(x,y2)
>> par(oldpar)
>>
>> In my opinion this fit could hardly be considered
>> to be robust.
>>
>> Are there functions in R which can do robust fitting?
>> (Sorrowly, at the moment I could not test the package
>> nlrq mentioned by Roger Koenker)
>>
>> Best regards
>> Christian
>> _._._._._._._._._._._._._._._._
>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>> V.i.e.n.n.a       A.u.s.t.r.i.a
>> _._._._._._._._._._._._._._._._
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
> 
> 
> 
> 
>



From cc164 at york.ac.uk  Tue Feb  3 21:50:36 2004
From: cc164 at york.ac.uk (C Chang)
Date: 03 Feb 2004 20:50:36 +0000
Subject: [R] how to change one of the axis to normal probability scale
Message-ID: <200402032050.UAA11644@webmail0.york.ac.uk>

Hi,
 
I would like to plot a graph with one axis in log scale and the other in
normal probability scale using R. I cannot change the axis scale to
probability scale. What can be a solution? Thanks.
 
CT



From ray at mcs.vuw.ac.nz  Tue Feb  3 21:49:01 2004
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Wed, 4 Feb 2004 09:49:01 +1300 (NZDT)
Subject: [R] filled maps
Message-ID: <200402032049.i13Kn1oc006489@tahi.mcs.vuw.ac.nz>

> Date: Tue, 3 Feb 2004 11:34:06 +0100 (CET)
> From: Roger Bivand <Roger.Bivand at nhh.no>
> 
> On Tue, 3 Feb 2004, Janus Larsen wrote:
> 
> > Hi R-Help,
> > 
> > I would like to make filled contour maps of ocean data overlaid by
> > costlines from the map package.
> > I can draw the filled contours and the coastlines om the same plot, but
> > the filled contour also covers part of the land. To get rid of that I
> > tried to draw a filled coastline map on top of the filled contour, but
> > the filled map only draws the closed contours - so most of the land is
> > missing.
> > Example:
> > map("worldHires",xlim=c(0,15),ylim=c(50,60)) #Draw relevant region
> > (North Sea and Denmark waters)
> > map("worldHires",xlim=c(0,15),ylim=c(50,60),fill=TRUE) # This only draws
> > Denmark and Holland (Sweden, uk, Germany etc. disappears because they
> > are not closed polygons).
> 
> Looks as though you can use the regions= argument:
> 
> > res <- map("worldHires",xlim=c(0,15),ylim=c(50,60), plot=FALSE, 
> + namesonly=TRUE)
> > map("worldHires",xlim=c(0,15),ylim=c(50,60))
> > map("worldHires",regions=res, fill=TRUE, add=TRUE)
> 
Thanks Roger, I hadn't got around to figuring out that workaround.
Certainly the mapgetg code explicitly excludes incomplete polygons if 
fill=TRUE, but since the polygon() function is happy to clip what it is
filling, your workaround takes advantage of that.

I'll have a look at getting mapgetg to do this itself - it would have
to always provide complete polygons if fill=TRUE instead of just
'visible' polylines.

> fixes it for me. Curiously, the longitudes add 2.5 degrees on each side.
> 
Actually this is to preserve aspect ratio.  An earlier version of the
maps package adjusted the shape of the figure to conform to both aspect
ratio and imposed limits.  I didn't deliberately change this, but I
think I know why it has happened, so I'll look at this also.

Ray Brownrigg



From p.dalgaard at biostat.ku.dk  Tue Feb  3 22:04:13 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Feb 2004 22:04:13 +0100
Subject: [R] Linux installation problem
In-Reply-To: <5.2.1.1.2.20040203102544.00b6b698@postoffice9.mail.cornell.edu>
References: <5.2.1.1.2.20040203102544.00b6b698@postoffice9.mail.cornell.edu>
Message-ID: <x2hdy750z6.fsf@biostat.ku.dk>

Eric Evans <eje4 at cornell.edu> writes:

> Hello everyone,
> 
> I downloaded the latest Linux version of R and tried installing it,
> but during the installation process I found that this version of R
> requires tcl 8.3 and tk 8.3.  The problem is that I've been unable to
> find Linux versions of tcl 8.3 and tk 8.3.  The only Linux versions of
> tcl/tk I've been able to find are 8.4.  Has anybody been successful in
> getting R to install on Linux recently, and if so can you please tell
> me where you got your tcl/tk 8.3?  Thanks very much.

Binaries? If so, what platform? As far as I've seen the sources are
quite happy with everything newer than 8.1:

pd at linux:~/r-devel/BUILD> ldd library/tcltk/libs/tcltk.so
        libtcl8.4.so => /usr/lib64/libtcl8.4.so (0x0000002a95681000)
        libtk8.4.so => /usr/lib64/libtk8.4.so (0x0000002a95838000)
        libX11.so.6 => /usr/X11R6/lib64/libX11.so.6
        (0x0000002a95a2f000)
        libdl.so.2 => /lib64/libdl.so.2 (0x0000002a95c43000)
  ....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From MSchwartz at medanalytics.com  Tue Feb  3 22:17:32 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 03 Feb 2004 15:17:32 -0600
Subject: [R] Re: R Home Page Graphic Competition
In-Reply-To: <401FF967.90201@stat.auckland.ac.nz>
References: <3FC10F03.1050608@stat.auckland.ac.nz>
	<401FF967.90201@stat.auckland.ac.nz>
Message-ID: <1075843052.16606.116.camel@localhost.localdomain>

On Tue, 2004-02-03 at 13:41, Paul Murrell wrote:
> Hi
> 
> Due to the low number of entries received so far, the deadline for the R 
> Home Page Graphic Competition has been extended to February 29 2004.
> 
> The free registration to useR! 2004 is still available and if we do not 
> receive any image that we can use for the home page, we will draw a name 
> at random from among the submissions we receive.
> 
> The original competition announcement is included below:


> > R-core reserves the right to decide that the R user base is just as 
> > devoid of artistic talent as R-core itself;  we only promise to make use 
> > of zero or more of the submitted images on the web site.


Is this an indication that the above paragraph from the original
announcement was somewhat prophetic and may have introduced some "a
priori" bias?

;-)

Marc



From sebastiendurand at videotron.ca  Tue Feb  3 22:26:46 2004
From: sebastiendurand at videotron.ca (Sebastien Durand)
Date: Tue, 03 Feb 2004 16:26:46 -0500
Subject: [R] Locate a warning
Message-ID: <a06020409bc45c1e48e2e@[192.168.2.3]>

I am writing my own program in R through Mac os X terminal.
Here is my question, is there an easy way to find on which line 
warnings are created

I am getting the following warning:

Warning message:
number of items to replace is not a multiple of replacement length

You I just would be happy to find what cause it


Thanks a lot



From dmurdoch at pair.com  Tue Feb  3 22:42:59 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 03 Feb 2004 16:42:59 -0500
Subject: [R] how to change one of the axis to normal probability scale
In-Reply-To: <200402032050.UAA11644@webmail0.york.ac.uk>
References: <200402032050.UAA11644@webmail0.york.ac.uk>
Message-ID: <e15020hufsfl43oteaht71mut9jt9h6srq@4ax.com>

On 03 Feb 2004 20:50:36 +0000, C Chang <cc164 at york.ac.uk> wrote :

>Hi,
> 
>I would like to plot a graph with one axis in log scale and the other in
>normal probability scale using R. I cannot change the axis scale to
>probability scale. What can be a solution? Thanks.

You should plot with "axes=F", then add the axes manually.

For example, 

x <- sort(rnorm(100))
y <- sort(rnorm(100))
plot(x,y,axes=F)
box()
at <- c(0.01,0.1,0.5,0.9,0.99)
axis(1,at=qnorm(at),labels=at)
axis(2,at=qnorm(at),labels=at)
box()

(At least I think that's a "normal probability scale", but you better
check against your own definition.)

Duncan Murdoch



From john.lewis at sympatico.ca  Tue Feb  3 22:58:35 2004
From: john.lewis at sympatico.ca (john lewis)
Date: Tue, 3 Feb 2004 16:58:35 -0500
Subject: [R] S language
Message-ID: <001201c3eaa0$df9b9c10$8c00a8c0@max>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040203/ad2556f1/attachment.pl

From jfox at mcmaster.ca  Tue Feb  3 23:11:14 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 03 Feb 2004 17:11:14 -0500
Subject: [R] r-squared equivalent for locally-smoothed figures?
In-Reply-To: <004c01c3ea6c$a0fa9490$f2e1f380@OPENZAURUS>
References: <401A4A7F.1050301@unibas.ch>
	<200401301238.17940.deepayan@stat.wisc.edu>
	<Pine.SOL.4.58.0401301353340.2982@tetris.gpcc.itd.umich.edu>
	<401D6A7C.1040507@stat.auckland.ac.nz>
Message-ID: <5.0.2.1.0.20040203170615.00af1008@127.0.0.1>

Dear Stuart,

Since residuals(mod) works for models fit by locfit(), you could calculate 
an analog to R^2 as 1 - (sum(residuals(mod)^2)/sum((y - mean(y))^2). I'm 
not sure whether you can get residuals from sm.

I hope that this helps,
  John

At 03:44 PM 2/3/2004 +0000, Stuart Leask wrote:
>Does anyone know a rough equivalent of the r-squared statistic for lines or
>surfaces fitted to data using local smoothing (eg. using the sm or locfit
>libraries)? I feel there must be some manner in which such locally-smoothed
>figures explain a fraction of the total squared error in the data...  Can
>such a fraction be obtained from locfit (or sm) objects?
>
>Stuart

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From Charles.Annis at statisticalengineering.com  Tue Feb  3 23:41:09 2004
From: Charles.Annis at statisticalengineering.com (Charles Annis, P.E.)
Date: Tue, 3 Feb 2004 17:41:09 -0500
Subject: [R] how to change one of the axis to normal probability scale
In-Reply-To: <200402032050.UAA11644@webmail0.york.ac.uk>
Message-ID: <200402032240.i13MeOwd002189@hypatia.math.ethz.ch>

Dear C. Chang:

It's very helpful to draw your own grid in situations like this.  I have
included the code for mine below.

First some disclaimers:

1) The probability axis goes from p=1.e-7 to p=1-1.e-7, ridiculous
extrapolations by most accounts.  However, the engineers with whom I work do
this extrapolation, often unthinkingly.  At least plotting on this grid
forces them to consider what they are doing and how much (or little) data
they have to substantiate it.  You can fix this easily in your routine, by
only considering, say, p=0.001, to p=0.999.

2) The grid looks great as drawn but scales poorly because the location of
labels etc. are absolute rather than relative or some cobbled combination of
these.  Since it does what I need, I use it.  In your grid you may want to
make it easier to scale.

3) Notice that the plot is set up like this:
plot(NA, NA, xlim=c(3, 7), ylim=c(z.min, z.max), ...
so that you will be plotting on a Cartesian grid in x-units of log10() and
y-units of qnorm()

Anyway here's the code.  Watch out for superfluous carriage-returns inserted
by the mail handler.

#####  R code to draw a lognormal CDF grid.   #####
lognormal.CDF.fn <- function(x.axis.title="Nf, Cycles"){
#   lognormal CDF grid
# First draw the grid with no points.  
# The x-axis is log cycles.  The y-axis, although labled probability, is
ploted as normal z units.
z.min <- -5.5
z.max <- -z.min
z.norm <- seq(z.min, z.max, length=101)
plot(NA, NA, xlim=c(3, 7), ylim=c(z.min, z.max), type="n", xaxt="n",
yaxt="n", frame = FALSE, xlab = "", ylab = "Cumulative Probability (Fraction
less than N)")
#
# Draw the x-axis
axis(side = 1, labels = FALSE, at = c(3, 4, 5, 6, 7), line = 0., tick=TRUE,
outer = FALSE)
text(x=c(3, 4, 5, 6, 7),      y=rep(z.min-1.0, 5), rep("10", 5), xpd = NA,
cex=1.)
text(x=c(3, 4, 5, 6, 7)+ 0.1, y=rep(z.min-0.8, 5)+0.08, c("3", "4", "5",
"6", "7"), xpd = NA, cex=0.8)
text(x=5.05, y=z.min-1.6, x.axis.title, xpd=NA, cex=1.)
# Draw the interior log tick marks
for (i in 3:6){
axis(side=1, at=log10(c(2, 3, 4, 5, 6, 7, 8, 9))+ i,   cex=1, labels=NA,,
line = 0, tck = -0.01)
text(x=log10(c(2, 3, 4, 5, 6, 7, 8))+ i, y=rep(z.min-0.7, 7), c("2", "3",
"4", "5", "6", "7", "8"), xpd = NA, cex=0.7)
}
#
# Draw the y-probability axis
probs <- c(1e-7, 1e-6, 1e-5, 1e-4, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05,
0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98, 0.99, 0.995, 0.998,
0.999, 0.9999, 0.99999, 0.999999, 0.9999999)
z.vals <- qnorm(probs)
axis(side=2, at=z.vals , labels=NA, line = 0, tck = -0.01)
text(x=rep(3.-0.4, 4),  y= -0.1+qnorm(c(1e-7, 1e-6, 1e-5, 1e-4)), cex=0.8,
xpd = NA, labels=rep("10", 6))
text(x=rep(3.-0.3  , 4),  y=  0.1+qnorm(c(1e-7, 1e-6, 1e-5, 1e-4)), cex=0.6,
xpd = NA,labels=c("-7", "-6", "-5", "-4"))
text(x=rep(3.-0.25, 6),  y= qnorm(c(0.001, 0.01, 0.1, 0.5, 0.9, 0.99,
0.999)), cex=0.7,  xpd = NA,labels=c("0.001", "0.01", "0.1", "0.5", "0.9",
"0.99", "0.999"), adj=1)
text(x=rep(3.-0.4, 4),  y= -0.1-qnorm(c(1e-7, 1e-6, 1e-5, 1e-4)), cex=0.8,
xpd = NA, labels=rep("1-10", 6))
text(x=rep(3.-0.27  , 4),  y=  0.1-qnorm(c(1e-7, 1e-6, 1e-5, 1e-4)),
cex=0.6,  xpd = NA,labels=c("-7", "-6", "-5", "-4"))
box()
}
### Test it
lognormal.CDF.fn()
###################################################################


Charles Annis, P.E.
 
Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  503-217-4849
http://www.StatisticalEngineering.com

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of C Chang
Sent: Tuesday, February 03, 2004 3:51 PM
To: r-help at stat.math.ethz.ch
Subject: [R] how to change one of the axis to normal probability scale

Hi,
 
I would like to plot a graph with one axis in log scale and the other in
normal probability scale using R. I cannot change the axis scale to
probability scale. What can be a solution? Thanks.
 
CT

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From bates at stat.wisc.edu  Tue Feb  3 23:43:28 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 03 Feb 2004 16:43:28 -0600
Subject: [R] problem with read.table
In-Reply-To: <OF7A5C2B46.CAFAAB4D-ON85256E2F.005B0393-85256E2F.005BA8AE@EU.novartis.net>
References: <OF7A5C2B46.CAFAAB4D-ON85256E2F.005B0393-85256E2F.005BA8AE@EU.novartis.net>
Message-ID: <6rznbzkcmn.fsf@bates4.stat.wisc.edu>

ryszard.czerminski at pharma.novartis.com writes:

> Any ideas why read.table complains about not correct number of elements in 
> line
> while readLine/strsplit indicate that all lines have the same number of 
> elements ?
> 
> R
> 
> 
> > tbl <- read.table('tmp', header = T, sep = '\t')
> Error in scan(file = file, what = what, sep = sep, quote = quote, dec = 
> dec,  : 
>         line 32 did not have 27 elements
> > lines <- readLines('tmp')
> > v <- 1:length(lines)
> > i <- 0; for (line in lines) { i <- i + 1; v[i] <- length(strsplit(line, 
> '\t')[[1]]) }
> > v
>  [1] 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 
> 27 27
> [26] 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 
> 27 27
> [51] 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27
> > sum((v - v[1])^2)
> [1] 0
> > length(strsplit(lines[32], '\t')[[1]])
> [1] 27

Try count.fields to see what line is giving problems.  Watch
especially for comment characters (default is '#') and quote
characters.  My good friends in Biological Sciences (including my
spouse and one of my children) have a habit of incorporating 3' and 5'
in descriptive text and that always trips me up.



From Jason.L.Higbee at stls.frb.org  Tue Feb  3 23:51:01 2004
From: Jason.L.Higbee at stls.frb.org (Jason.L.Higbee@stls.frb.org)
Date: Tue, 3 Feb 2004 16:51:01 -0600
Subject: [R] Error in f(x, ...) : subscript out of bounds
Message-ID: <20040203225102.DC33F85D12@p3fed1.frb.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040203/2a01241b/attachment.pl

From andy_liaw at merck.com  Wed Feb  4 00:16:06 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 3 Feb 2004 18:16:06 -0500
Subject: [R] Locate a warning
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7708@usrymx25.merck.com>

Try options(warn=2) and run your code again, and perhaps traceback()
afterward.

HTH,
Andy

> From: Sebastien Durand
> 
> I am writing my own program in R through Mac os X terminal.
> Here is my question, is there an easy way to find on which line 
> warnings are created
> 
> I am getting the following warning:
> 
> Warning message:
> number of items to replace is not a multiple of replacement length
> 
> You I just would be happy to find what cause it
> 
> 
> Thanks a lot
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ripley at stats.ox.ac.uk  Wed Feb  4 00:20:36 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Feb 2004 23:20:36 +0000 (GMT)
Subject: [R] problem with read.table
In-Reply-To: <OF7A5C2B46.CAFAAB4D-ON85256E2F.005B0393-85256E2F.005BA8AE@EU.novartis.net>
Message-ID: <Pine.LNX.4.44.0402032316300.11771-100000@gannet.stats>

On Tue, 3 Feb 2004 ryszard.czerminski at pharma.novartis.com wrote:

> Any ideas why read.table complains about not correct number of elements in 
> line
> while readLine/strsplit indicate that all lines have the same number of 
> elements ?

That is what count.fields is for.  Setting fill=TRUE in read.table can 
help detection, too.

One guess is that you have a comment character on that line, but one 
thing you did not show us is the appropriate lines of the file.

> > tbl <- read.table('tmp', header = T, sep = '\t')
> Error in scan(file = file, what = what, sep = sep, quote = quote, dec = 
> dec,  : 
>         line 32 did not have 27 elements
> > lines <- readLines('tmp')
> > v <- 1:length(lines)
> > i <- 0; for (line in lines) { i <- i + 1; v[i] <- length(strsplit(line, 
> '\t')[[1]]) }
> > v
>  [1] 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 
> 27 27
> [26] 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 
> 27 27
> [51] 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27
> > sum((v - v[1])^2)
> [1] 0
> > length(strsplit(lines[32], '\t')[[1]])
> [1] 27
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bacolli at uark.edu  Wed Feb  4 00:24:50 2004
From: bacolli at uark.edu (Bret Collier)
Date: Tue, 03 Feb 2004 17:24:50 -0600
Subject: [R] Novice problems with write()
In-Reply-To: <200402032240.i13MeOwd002189@hypatia.math.ethz.ch>
References: <200402032050.UAA11644@webmail0.york.ac.uk>
Message-ID: <5.2.1.1.0.20040203171542.00b06430@mail.uark.edu>

R-Users,
         As a relatively new user of R, I have a quick (and probably 
simple) question about using write().  I have a population simulation that 
I am running and I want to output a set of variables for each run of the 
simulation into a text file for use in another program.  However, whenever 
I attempt to use write(), the only output that I am able to get is the 
final numbers from the simulation.

for example:

x <- 5
for (i in 1:10){
  z <- x+i
print(z)
write(z, "c:/test.txt")
}

In this simple case,  with print(z) I can see that z has what I am looking 
for, but all that is output for the write statement is 15;  While this is 
simplified, it shows my problem.

I searched the help files, and on the R website, but I could not find 
anything addressing this.  I suspect that it is my lack of knowledge and I 
am missing something obvious (or should be using write.table).  If anyone 
could point me in the right direction I would appreciate it.

Thanks,

Bret Collier
Univ. Arkansas



From andy_liaw at merck.com  Wed Feb  4 01:34:22 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 3 Feb 2004 19:34:22 -0500
Subject: [R] S language
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7709@usrymx25.merck.com>

I'm probably the least authoratative to say anything, but before we get a
flood of messages like this...

(IMHO) in a word, "nothing".

What Insightful aquired (I believe) is the right to the core S code that
were used underneath S-PLUS.  Without this right, Insightful would have to
renew the license with Bell Labs every few years.  That adds some
uncertainty to their business.

R to S-PLUS is sort of like Linux to Unix(TM), from the IP perspective.  It
was written from scratch, without any orginial Bell Labs S source.  Even the
S4 classes implemented in the methods package was a complete
re-implementation, because R and S are so different `under the hood'.

OK, I've say too much already...

Andy

> From: john lewis
> 
> Hello
> I just received an email from Insightful, Inc. saying that they have 
> purchased the S license from Lucent Technologies. 
> Will this have any major impact on R or the future development of R?
> John Lewis
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From sheth at economics.rutgers.edu  Wed Feb  4 02:37:03 2004
From: sheth at economics.rutgers.edu (Arnav Sheth)
Date: Tue, 3 Feb 2004 20:37:03 -0500
Subject: [R] Clustering with 'agnes'
Message-ID: <000f01c3eabf$69424630$722617ac@arnav>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040203/2ae3f45b/attachment.pl

From andy_liaw at merck.com  Wed Feb  4 03:39:33 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 3 Feb 2004 21:39:33 -0500
Subject: [R] Novice problems with write()
Message-ID: <3A822319EB35174CA3714066D590DCD504AF770B@usrymx25.merck.com>

> From: Bret Collier
> 
> R-Users,
>          As a relatively new user of R, I have a quick (and probably 
> simple) question about using write().  I have a population 
> simulation that 
> I am running and I want to output a set of variables for each 
> run of the 
> simulation into a text file for use in another program.  
> However, whenever 
> I attempt to use write(), the only output that I am able to 
> get is the 
> final numbers from the simulation.
> 
> for example:
> 
> x <- 5
> for (i in 1:10){
>   z <- x+i
> print(z)
> write(z, "c:/test.txt")
> }

What you have done is write 6 through 15 to the file test.txt 10 times, each
with one number.  write() opens a file, write to it, and then close the
file, so if you do it in the loop, it would open the file 10 times, write
one number to it 10 times, and close the file 10 times.

You're probably looking for something like:

fout <- file("c:/test.txt", "w")
x <- 5
for (i in 1:10) {
  z <- x + i
  writeLines(paste(z, "\n"), fout)
}
close(fout)

Or simply:

write(5 + 1:10, file="c:/test.txt", ncol=1)

Andy

 
> In this simple case,  with print(z) I can see that z has what 
> I am looking 
> for, but all that is output for the write statement is 15;  
> While this is 
> simplified, it shows my problem.
> 
> I searched the help files, and on the R website, but I could not find 
> anything addressing this.  I suspect that it is my lack of 
> knowledge and I 
> am missing something obvious (or should be using 
> write.table).  If anyone 
> could point me in the right direction I would appreciate it.
> 
> Thanks,
> 
> Bret Collier
> Univ. Arkansas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From Mark.Bravington at csiro.au  Wed Feb  4 04:14:38 2004
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Wed, 4 Feb 2004 14:14:38 +1100
Subject: [R] Directory-like data organisation w/ environments?
Message-ID: <C4178DC99E08604EA5E2BDB989F0938001797FD2@extas2-hba.tas.csiro.au>


> -----Original Message-----
> 
> Dear r-users!
> 
> I wonder if there is a way of designing a directory like 
> structure for holding my data using environments?
> 
> It would be nice if I could implement a kind of 'cd' command 
> to change to a differend environment etc.
> 
> Can anybody give me a hint?
> 
> -cl

Hi Christophe

You might want to check out the 'mvbutils' package on CRAN, and specifically those sections relating to the 'cd' command. This allows you to create & maintain a hierarchical project structure (like a directory tree). You can switch between workspaces within a single R session, search thru the hierarchy, move stuff around, etc.

[A colleague passed on your email to me-- he may already have sent you this info directly.]

Hope this helps

Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington at csiro.au



From ligges at statistik.uni-dortmund.de  Wed Feb  4 08:41:05 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 04 Feb 2004 08:41:05 +0100
Subject: [R] Novice problems with write()
In-Reply-To: <5.2.1.1.0.20040203171542.00b06430@mail.uark.edu>
References: <200402032050.UAA11644@webmail0.york.ac.uk>
	<5.2.1.1.0.20040203171542.00b06430@mail.uark.edu>
Message-ID: <4020A211.4020400@statistik.uni-dortmund.de>

Bret Collier wrote:

> R-Users,
>         As a relatively new user of R, I have a quick (and probably 
> simple) question about using write().  I have a population simulation 
> that I am running and I want to output a set of variables for each run 
> of the simulation into a text file for use in another program.  However, 
> whenever I attempt to use write(), the only output that I am able to get 
> is the final numbers from the simulation.
> 
> for example:
> 
> x <- 5
> for (i in 1:10){
>  z <- x+i
> print(z)
> write(z, "c:/test.txt")
> }


For each i in 1:10 you are printing z to the console and writing z into 
a file test.txt.
Note that you only see the last z in the file, since it has been been 
overwritten several times, while the output on your console produced by 
print() has not been not overwritten.

Uwe Ligges



> In this simple case,  with print(z) I can see that z has what I am 
> looking for, but all that is output for the write statement is 15;  
> While this is simplified, it shows my problem.
> 
> I searched the help files, and on the R website, but I could not find 
> anything addressing this.  I suspect that it is my lack of knowledge and 
> I am missing something obvious (or should be using write.table).  If 
> anyone could point me in the right direction I would appreciate it.
> 
> Thanks,
> 
> Bret Collier
> Univ. Arkansas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Feb  4 08:45:02 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 04 Feb 2004 08:45:02 +0100
Subject: [R] Clustering with 'agnes'
In-Reply-To: <000f01c3eabf$69424630$722617ac@arnav>
References: <000f01c3eabf$69424630$722617ac@arnav>
Message-ID: <4020A2FE.5000702@statistik.uni-dortmund.de>

Arnav Sheth wrote:

> Hello,
> 
> I had a question regarding clustering using the agnes() function from the 'cluster' package.
> 
> I was wondering if anyone knew how I can identify cluster points after running the agnes function. 
> 
> For example, I created a dataset with points randomly scattered around (0,0), (0,1) and (1,0). After clustering, the dendrogram shows all the clustered points and I get the ordering and height and the agglomerative coefficient. But nowhere do I see the three actual points listed. Although agnes clusters until there is one main cluster, it is clear that at three clusters, each of the clusters consist of points around the three main points. I was wondering if there was any way in which I can have R give me the actual cluster points at three (or any number, for that matter) clusters, ie (0,0), (0,1) and (1,0). A visual display of the clusters would be even better.
> 
> I have tried using idenfity after converting the agnes object to an hclust object, but that only gives me a listing of the points in each cluster.
> 
> I hope this question is clear. I am a little new with both clustering and using R for clustering, so please ask me to clarify if anything is unclear.
> 
> Your help would be most appreciated!

See the example of ?agnes, where the points are labeled.
Most easily use agnes() on a data.frame with rownames.

Uwe Ligges






> With regards,
> Arnav
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Feb  4 08:57:22 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 04 Feb 2004 08:57:22 +0100
Subject: [R] Error in f(x, ...) : subscript out of bounds
In-Reply-To: <20040203225102.DC33F85D12@p3fed1.frb.org>
References: <20040203225102.DC33F85D12@p3fed1.frb.org>
Message-ID: <4020A5E2.80108@statistik.uni-dortmund.de>

Jason.L.Higbee at stls.frb.org wrote:

> R-Listers:
> 
> I am doing a quasi-maximum likelihood estimation and I get a "subscript 
> out of bound" error message,  Typically I would think this means that a 
> subscript used in the function is literally out of bounds however I don't 
> think this is the case.  All I change in the code is a constant, that is 
> hard-wired in (not data dependent and not parameter dependent), 
> furthermore, the constant is not used in any subscripting.
> 
> Sorry I cannot provide a toy example, but the likelihood function looks 
> like this:
> 
> lnL <- function(theta, gsvr, gsvR) { 
>             # theta[1]= mu, theta[2]=gamma, theta[3]=kappa1, 
> theta[4]=kappa2
>             nn <- 252
>             d <- 0:nn
>             wd <- exp((theta[3] * d + theta[4] * d^2))/(sum(exp(theta[3] * 
> d + theta[4] * d^2)))
>             sigsq <- numeric(length(gsvR$ret))
>             x <- numeric(length(gsvR$ret)

Obviously, this is not the original code you have got a problem with, 
since a delimeter is missing the line above. Please don't send code you 
have not tested yourself ....




> 
>         # Below this line can be specified differently
>              x[1] <- 1
>             lenR <- length(gsvR$ret)
>             for (i in 1:(lenR-1)) {
>                     x[i+1] <- sum(gsvR$rw[1:i]) + 1
>                     rsq <- (gsvr$ret[(x[i]):(nn+x[i])])^2
>                     sigsq[i] <- 22 * sum(wd * rsq)
>             }
>  
>            if((nn+x[lenR]) < length(gsvr$ret)) rsq <- 
> (gsvr$ret[(x[lenR]):(nn+x[lenR])])^2 else rsq <- NA
>            sigsq[length(gsvR$ret)] <- 22 * sum(wd * rsq)
>            sigsq <- na.omit(sigsq)
>             sigsq <- sigsq[-1]
>            # Above this line can be specified differently
> 
>             Ret <- gsvR$ret[1:length(sigsq)]
>             mymu <- (theta[1]+theta[2]*(sigsq))
>             n <- length(wd)#/22 
>             ll <- numeric(length(sigsq))
>             for (j in 1:length(sigsq)) {
>             ll[j] <- -(n/2) * log(2*pi) - (n/2) * log(sigsq[j]) - 0.5 * 
> sum(((Ret - mymu[j])^2)/(sigsq[j]))
>             } 
>             l <- mean(ll)
>             -l
>        }
> #########Alternative specitication################
>             for (i in 1:(length(gsvR$ret))) {
>             x[i] <- sum(gsvR$rw[1:i]) + 1
>             rsq <- (gsvr$ret[(x[i]):(nn+x[i])])^2
>             sigsq[i] <- 22 * sum(wd * rsq)
>  
>             }
>  
>             sigsq <- na.omit(sigsq)
> ###############################################
> 
> 
> 
> The constant that is changed is "n" when the n <- length(wd)/22 the 
> optimization converges using both nlm and optim(with the default method), 
> however with n <- length(wd) the functions returns the subscript out of 
> bounds error message.  Maximizing the likelihood with the alternative 
> specification replacing the  code marked in the original function allows 
> the optimization to converge.  It should be noted that the original 
> likelihood function and the alternative specification return the same 
> likelihood value when evaluated at the initial values.
> 
> I realize that in the original specification the variable sigsq could be 
> all NAs and na.omit(sigsq) would produce a zero length vector, upon which 
> sigsq[-1] would be out of bounds, however the original specification 
> converges when n<-length(wd)/22, in which case the aforementioned case 
> would still be true.  Plus both specifications evaluate the initial values 
> when submitted line by line (rather than in the function), using both 
> n<-length(wd)/22 and n<-length(wd).
> 
> Could the error "subscript out of bounds" mean something different?  Is 
> there likely to be a bug? 

I'm pretty sure it's a big in your code.

I haven't checked the rest of your code, since it doesn't seem to make 
sense to look into code that is buggy by copy&paste or whatever (see above).

There are *many* lines where your code might result in invalid 
subscripts, depending on the data.

Say length(gsvR$ret) == 1, then:

  lenR <- length(gsvR$ret) # lenR == 1
  for (i in 1:(lenR-1)) {  # 1:(lenR-1) == 1:0 !!!!!
   x[i+1] <- sum(gsvR$rw[1:i]) + 1 # 1:i == 1:0 !!!!!

in for() you might want to use seq(along = gsvR$ret)


Uwe Ligges




> I am using:
> 
> 
>>version
> 
>          _ 
> platform i386-pc-mingw32
> arch     i386 
> os       mingw32 
> system   i386, mingw32 
> status 
> major    1 
> minor    8.0 
> year     2003 
> month    10 
> day      08 
> language R 
> 
> 
> Thanks for reading, and/or replying to this.
> 
> Jason Higbee
> Research Associate
> Federal Reserve Bank of St. Louis
> T: 314.444.7316
> F:314.444.8731
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From cs369 at cam.ac.uk  Wed Feb  4 10:44:56 2004
From: cs369 at cam.ac.uk (C. Spanou)
Date: 04 Feb 2004 09:44:56 +0000
Subject: [R] (no subject)
Message-ID: <E1AoJaa-00067F-8v.--06cf218964f999de68b4225df20ccc8ff47400c6@maroon.csi.cam.ac.uk>

Hello
 I am doing a project on ordered logit/probit models using Splus. I am 
using the polr function in library(MASS) which is exactly the same code as 
in R. Unfortunatelly I am not very succesfull with it. The code I used was:
> polr(factor(resp)~.,data=data3) # data3 does not consist the resp
 variable
 But I am getting the same warning message 21 times. The message is the
 following: 
1: singularity encountered in: nlminb.1(temp, p, liv, lv,
 objective, gradient, bounds, scale) 

  I guess the corresponding warning message in R is:
 Error in optim(start, fmin, gmin, method = "BFGS", hessian = Hess)

 I would be very greatfull if someone could suggest what it might be wrong 
with
 my model anh how I can overcome it. 
Thanking you in advance 
Charis Spanou



From umberto_maggiore at hotmail.com  Wed Feb  4 11:03:51 2004
From: umberto_maggiore at hotmail.com (Umberto Maggiore)
Date: Wed, 04 Feb 2004 10:03:51 +0000
Subject: [R] xypplot (lattice): colours of lines
Message-ID: <BAY8-F49WPXBemybNxv0006cb72@hotmail.com>

Using data from a multicenter study with a parallel-group design comparing
two treatments, I plotted each subject's time change of X after stratifying
for center:

xyplot(X ~ time | center, type="l", panel=panel.superpose, groups=subject)

Now I want these lines to take different colours according to the variable
"treatment". Any help?
Umberto

_________________________________________________________________
Filtri antispamming e antivirus per la tua casella di posta



From gaelle.barrot at gazdefrance.com  Wed Feb  4 11:28:13 2004
From: gaelle.barrot at gazdefrance.com (Gaelle BARROT)
Date: Wed, 4 Feb 2004 11:28:13 +0100
Subject: [R] arima function
Message-ID: <OFD671AEDC.96B67A08-ON41256E30.00378E44-41256E30.00396ED6@notes.edfgdf.fr>

Hello,
I am a beginner user of R and I would like to estimate a model with AR
errors. I use arima function:

modele
<-arima(conso,xreg=var.exogenes,order=c(ordre,0,0),include.mean=TRUE,method
="CSS")

My inputs are dummies for each month except one, and the same thing for
each day and each hour.   I have this error message:
Warning message:
possible convergence problem: optim gave code= 1 in: arima(as.ts(conso),
xreg = table, order = c(10, 0, 0), include.mean = TRUE,

I try to estimate this model with SAS and I have a result.

Have you a solution to solve this problem?
Thank you very much,

Gaelle Barrot



From wolski at molgen.mpg.de  Wed Feb  4 11:39:36 2004
From: wolski at molgen.mpg.de (wolski)
Date: Wed, 04 Feb 2004 11:39:36 +0100
Subject: [R] Returnin char back through the .Call interface
Message-ID: <200402041139360466.08D0C17B@harry.molgen.mpg.de>

Hi!

My results or error messages are copied in a string and than have to be passed back through the .Call interface togheter with numeric results
What is the best way to allocate storage to a character? (R_alloc?)
And how to add it to a list? (e.g. allocVector(VECSXP, 9))


Help are highly appreciated.

Eryk



Ps.
I tried a with mkChar
and with
PROTECT(ral1 = NEW_CHARACTER(1));



From ripley at stats.ox.ac.uk  Wed Feb  4 12:05:18 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 4 Feb 2004 11:05:18 +0000 (GMT)
Subject: [R] arima function
In-Reply-To: <OFD671AEDC.96B67A08-ON41256E30.00378E44-41256E30.00396ED6@notes.edfgdf.fr>
Message-ID: <Pine.LNX.4.44.0402041101580.12951-100000@gannet.stats>

You can look the message up!  ?optim gives

convergence: An integer code. '0' indicates successful convergence.
          Error codes are

          '1' indicates that the iteration limit 'maxit' had been
               reached.

and so you should try an increased limit via the optim.control argument.

If I understand correctly, you have two possible ways to model trends, and 
it is likely that makes the optimization ill-determined.

On Wed, 4 Feb 2004, Gaelle BARROT wrote:

> Hello,
> I am a beginner user of R and I would like to estimate a model with AR
> errors. I use arima function:
> 
> modele
> <-arima(conso,xreg=var.exogenes,order=c(ordre,0,0),include.mean=TRUE,method
> ="CSS")
> 
> My inputs are dummies for each month except one, and the same thing for
> each day and each hour.   I have this error message:
> Warning message:
> possible convergence problem: optim gave code= 1 in: arima(as.ts(conso),
> xreg = table, order = c(10, 0, 0), include.mean = TRUE,
> 
> I try to estimate this model with SAS and I have a result.

> Have you a solution to solve this problem?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Roger.Bivand at nhh.no  Wed Feb  4 12:17:31 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 4 Feb 2004 12:17:31 +0100 (CET)
Subject: [R] Returnin char back through the .Call interface
In-Reply-To: <200402041139360466.08D0C17B@harry.molgen.mpg.de>
Message-ID: <Pine.LNX.4.44.0402041214190.13809-100000@reclus.nhh.no>

On Wed, 4 Feb 2004, wolski wrote:

> Hi!
> 
> My results or error messages are copied in a string and than have to be
> passed back through the .Call interface togheter with numeric results
> What is the best way to allocate storage to a character? (R_alloc?) And
> how to add it to a list? (e.g. allocVector(VECSXP, 9))
> 
> 
> Help are highly appreciated.

Again, browsing the header files usually helps. A short and probably not 
ideal example (COPY_TO_USER_STRING() does the work):

SEXP R_G_get_gisrc_file() {
      SEXP ans;
      char *gisrc;
      
      PROTECT(ans=NEW_CHARACTER(1));
      gisrc = G__get_gisrc_file();
      if (gisrc) {
	   gisrc = G_store(gisrc);
           SET_STRING_ELT(ans, 0,
                COPY_TO_USER_STRING(gisrc));
      } else {
           SET_STRING_ELT(ans, 0,
                COPY_TO_USER_STRING("empty"));
       }
      UNPROTECT(1);
      return(ans);
}


> 
> Eryk
> 
> 
> 
> Ps.
> I tried a with mkChar
> and with
> PROTECT(ral1 = NEW_CHARACTER(1));
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From philippe at wwphi.net  Wed Feb  4 12:33:15 2004
From: philippe at wwphi.net (Philippe de Rochambeau)
Date: Wed, 4 Feb 2004 12:33:15 +0100
Subject: [R] Various newbie questions
Message-ID: <EC288D72-5705-11D8-BE5B-003065D64D74@wwphi.net>

Hello,

1) What is the difference between a "data frame" (J H Maindonald, Using 
R, p. 12) and a "vector"?

In Using R, the author asks the reader to enter the following data in a 
data frame, which I will call "mydata":

year snow.cover
1970 6.5
1971 12.0
1972 14.9
1973 10.0
1974 10.7
1975 7.9
...

mydata=data.frame(year=c(1970,...),snow.cover=c(6.5,...))

2) How to you retrieve say, snow.cover's second data item? mydata[1][2] 
does not work, neither does mydata[1,2].

hist(mydata[1,2]) does not work. How would you create a histogram with 
the above data?

In a French statistics book, the author provides the following data:

Group A	Number: 35	Mean:27
Group B  Number: 42  Mean:24

and asks: "what is the mean of the group constituted by the reunion of 
the two groups?"

The answer is of course (27 x 35) + (24 x 42) / 77

3) Is there a way to compute this mean in R (apart from doing the above 
operation, of course) if you have two sets of data?

4) How do you set class limits in R, for instance

10-20
21-31
etc.

5) How do you determine quartiles in R? Is there a way to determine the 
"semi-inter-quartile deviation" ("?cart semi-inter-quartile" in 
French)?

Many thanks!

Philippe de Rochambeau



From kamoun_wassim at yahoo.fr  Wed Feb  4 12:38:54 2004
From: kamoun_wassim at yahoo.fr (=?iso-8859-1?q?Wassim=20Kamoum?=)
Date: Wed, 4 Feb 2004 12:38:54 +0100 (CET)
Subject: [R] implement a function
Message-ID: <20040204113854.4384.qmail@web41313.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040204/bac0b41c/attachment.pl

From philippe at wwphi.net  Wed Feb  4 12:41:08 2004
From: philippe at wwphi.net (Philippe de Rochambeau)
Date: Wed, 4 Feb 2004 12:41:08 +0100
Subject: [R] Newbie question: histogram
Message-ID: <05FA90DC-5707-11D8-BE5B-003065D64D74@wwphi.net>

Hello,

how do you create a histogram with a data frame?

year snow.cover
1970 6.5
1971 12.0
1972 14.9
1973 10.0
1974 10.7
1975 7.9
...

mydata=data.frame(year=c(1970,...),snow.cover=c(6.5,...))

hist(mydata) does not work.

Many thanks.

PR



From wolski at molgen.mpg.de  Wed Feb  4 13:34:08 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 04 Feb 2004 13:34:08 +0100
Subject: [R] Returnin char back through the .Call interface
In-Reply-To: <Pine.LNX.4.44.0402041214190.13809-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0402041214190.13809-100000@reclus.nhh.no>
Message-ID: <200402041334080786.00D036D1@harry.molgen.mpg.de>

Hi!
Thanks a lot! Its what I am looking for.

Eryk.

*********** REPLY SEPARATOR  ***********

On 2/4/2004 at 12:17 PM Roger Bivand wrote:

>On Wed, 4 Feb 2004, wolski wrote:
>
>> Hi!
>> 
>> My results or error messages are copied in a string and than have to be
>> passed back through the .Call interface togheter with numeric results
>> What is the best way to allocate storage to a character? (R_alloc?) And
>> how to add it to a list? (e.g. allocVector(VECSXP, 9))
>> 
>> 
>> Help are highly appreciated.
>
>Again, browsing the header files usually helps. A short and probably not 
>ideal example (COPY_TO_USER_STRING() does the work):
>
>SEXP R_G_get_gisrc_file() {
>      SEXP ans;
>      char *gisrc;
>      
>      PROTECT(ans=NEW_CHARACTER(1));
>      gisrc = G__get_gisrc_file();
>      if (gisrc) {
>	   gisrc = G_store(gisrc);
>           SET_STRING_ELT(ans, 0,
>                COPY_TO_USER_STRING(gisrc));
>      } else {
>           SET_STRING_ELT(ans, 0,
>                COPY_TO_USER_STRING("empty"));
>       }
>      UNPROTECT(1);
>      return(ans);
>}
>
>
>> 
>> Eryk
>> 
>> 
>> 
>> Ps.
>> I tried a with mkChar
>> and with
>> PROTECT(ral1 = NEW_CHARACTER(1));
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>> 
>
>-- 
>Roger Bivand
>Econonic Geography Section, Department of Economics, Norwegian School of 
>Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
>Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics   
Ihnestrasse 73 14195 Berlin          'v'    
tel: 0049-30-84131285               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From baud-bovy.gabriel at hsr.it  Wed Feb  4 13:38:40 2004
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Wed, 04 Feb 2004 13:38:40 +0100
Subject: [R] Implementing streams in R
Message-ID: <5.2.1.1.1.20040204132351.00b9c7d0@mail.hsr.it>


Thanks to Prof Brian Ripley, Duncan Murdoch and Luke Tierney for your replies.
In particular, I found Luke Tierney's info very useful. I just would like to
answer Duncan Murdoch's question (what is a stream [Lazy list in Luke's
implementation] in plain english?) in case it interests somebody else.
In fact, I will quote from "Structure and Interpretation  of Computer
Programs",  MIT Press, 1985, by Abelson and Sussman with some editing of my 
own:

"From an abstract point of view, streams are simply a
sequence of data objects. However, we will find that
straighforward implementation of streams as lists does
not allow us to exploit the power of stream processing. To
solve this problem, we introduced the technique of delayed
evaluation which enables us to represent very large (even infinite) data
structure as streams." (p. 242)

Unlike lists which are usually constructed entirely before
being processed,  "The basic idea is that [a stream is constructed only
partially] and to pass the partial construction to the program that consumes
the stream. If the consumer attempts to access a part of the stream
that has not yet been constructed, the stream will automatically construct
just enough more of itself to enable the consumer to access
the required part" (p. 261)

"We use streams to organize computations on a collections
of data in a way that corresponds in spirit to an electrical
engineer's concept of signal processing system [...], i.e.
in terms of signals flowing through a cascade of stages,
each of which implement part of the program plan." (p. 244)

For example, let us imagine a procedure that enumerate all
Fibonacci number until 20 odd ones have been found. Streams
avoid to have to enumerate anymore Fibonacci numbers than
necessary (this number does not even have to be specified).

accumulate.into.list(20,filter.odds(fibonacci.stream()))

Another example might help to explain why implementing streams
as list is very innefficient. The following expression computes
the second prime in the interval from 10000 to 1000000:

head.stream(tail.stream(filter.prime(enumerate.interval(10000,1000000))))

If streams were implemented as a lists, enumerate.interval would
construct a list of almost a million intergers, then each element
would be tested for primality, then almost all of that would
be ignored since we are interested only in finding the second prime
number in this interval. In a procedural programming style,
we would interleave the enumeration and the filtering and stio when
we reached the second prime. By using the technique of delayed
evaluation, we can use the elegant stream formulation while
preserving the efficiency of incremental computation. [abridged
from p. 260-261]

Gabriel
--------------------------------------------------------------------
Gabriel Baud-Bovy
Faculty of Psychology
UHSR University
via Olgettina, 58	tel: (+39) 02 2643 4839
20132 Milan, Italy	fax: (+39) 02 2643 4892



From mihastaut at hotmail.com  Wed Feb  4 13:41:16 2004
From: mihastaut at hotmail.com (Miha STAUT)
Date: Wed, 04 Feb 2004 12:41:16 +0000
Subject: [R] Latin 2 encoding + fonts
Message-ID: <BAY2-F156ZCHusMjQHt0004fece@hotmail.com>

Hi,

In the FAQ I read about options to specify different fonts than the default 
ones for the console (in the file Rprofile) and for the graphical output 
(Rdevga). I would however like to replace Latin 1 with Latin 2 enconding for 
both (console and graphical) output in Windows and just graphical output in 
Linux.

I guess it is possible but I did not find the way.

How can I use the fonts (*.afm) and the (presumably) encondings (*.enc) in 
R/rw1081/afm? How do I know what are the real font names. Are those only the 
ones listed in the man page for Hershey?

Thanks, Miha



From mlaia at fcav.unesp.br  Wed Feb  4 14:50:04 2004
From: mlaia at fcav.unesp.br (Marcelo Luiz de Laia)
Date: Wed, 4 Feb 2004 10:50:04 -0300
Subject: [R] New Discussion list about R in PORTUGUESE - Lista de
 =?iso-8859-15?q?discuss=E3o?= sobre a linguagem R em Portugues
Message-ID: <20040204105004.0000421b@lbmsala4>

Dear Users List,

A friend created a discussion list about R in Portuguese (Brazil) in the yahoogroups.

The next text is written in Brazilian Portuguese and it refers to the creation of a discussion list about R in yahoogroups with the objective of giving support to the users that speak Portuguese. This discussion list has as objective the change of information, questions and answers on the use of the R language, in Portuguese.

Para quem se interessar...

Criamos uma lista sobre a linguagem R. Esta lista de discuss?o tem como
objetivo a troca de informa??es, perguntas e respostas sobre o uso da
linguagem R.

Para se cadastrar na mesma, entre no site:

http://br.groups.yahoo.com/group/R_STAT/

ou envie um e-mail para o endere?o:

R_STAT-subscribe at yahoogrupos.com.br

N?o esque?a o underscore (sublinhado) entre o R e STAT.

-- 
Marcelo Luiz de Laia, M.Sc.
Dep. de Tecnologia, Lab. Bioqu?mica e de Biologia Molecular
Universidade Estadual Paulista - UNESP
Via de Acesso Prof. Paulo Donato Castelane, Km 05
14.884-900 - Jaboticabal, SP, Brazil
PhoneFax: 16 3209-2675/2676/2677 R. 202/208/203 (trab.)
HomePhone: 16 3203 2328 - www.lbm.fcav.unesp.br - mlaia at yahoo.com



From andy_liaw at merck.com  Wed Feb  4 14:13:32 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 4 Feb 2004 08:13:32 -0500
Subject: [R] implement a function
Message-ID: <3A822319EB35174CA3714066D590DCD504AF770F@usrymx25.merck.com>

Reading the manual surely will help a lot:

http://cran.r-project.org/doc/manuals/R-exts.pdf

Andy

> From: Wassim Kamoum
> 
> Hello
> 
> I'm beginner on R ,I'm work on the starma model ,I have the 
> source code in R but they must be implemented in the library 
> of this software for applying them 
> 
> please give me the necessarly process 
> 
> Thank you


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From Arne.Muller at aventis.com  Wed Feb  4 14:19:24 2004
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Wed, 4 Feb 2004 14:19:24 +0100
Subject: [R] number point under-flow
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADECDCF0D@crbsmxsusr04.pharma.aventis.com>

Hello,

I've come across the following situation in R-1.8.1 (compile + running under
RedHat 7.1):

> phyper(24, 514, 5961-514, 53, lower.tail=T)
[1] 1
> phyper(24, 514, 5961-514, 53, lower.tail=F)
[1] -1.037310e-11

I'd expect the later to be 0 or some very small positive number. Is this a
number under-flow of the calculation? Do you think I'm safe if I just set the
result to 0 in these cases?

	kind regards,

	Arne



From l.houdusse at cerep.fr  Wed Feb  4 14:37:54 2004
From: l.houdusse at cerep.fr (Laurent Houdusse)
Date: Wed, 4 Feb 2004 14:37:54 +0100 
Subject: [R] nortest package
Message-ID: <BA420EFAAC96D311A7A0006097D37BDB04515A24@EOLE>



Hi,

I'm a newbie and i am unable to use lillie.test in nortest
I have a message: "Couldn't find function "lillie.test"
I am under windows2000 with R1.8.1
nortest is listed with .packages(TRUE)

How to do to use lillie.test function?


Laurent Houdusse 
Analyste Programmeur



From tobias.verbeke at bivv.be  Wed Feb  4 14:40:22 2004
From: tobias.verbeke at bivv.be (tobias.verbeke@bivv.be)
Date: Wed, 4 Feb 2004 14:40:22 +0100
Subject: [R] Various newbie questions
In-Reply-To: <EC288D72-5705-11D8-BE5B-003065D64D74@wwphi.net>
Message-ID: <OFA0F60BF5.B85BA633-ONC1256E30.0049EBA9-C1256E30.004B1D08@BIVV.BE>






r-help-bounces at stat.math.ethz.ch wrote on 04/02/2004 12:33:15:

> Hello,
>
> 1) What is the difference between a "data frame" (J H Maindonald, Using
> R, p. 12) and a "vector"?

a vector is a sequence of data of a certain kind ("of a certain mode").
You can have a vector of numbers

> myvector <- c(1,2,3,4,5,6)
> mode(a)
[1] "numeric"

or a vector of character strings

> myvector <- c("have", "a", "look", "at", "Manuals", "section", "on",
"CRAN")
> mode(myvector)
[1] "character"

or vectors of other kinds (e.g. logical).

a data frame is what you would call 'une matrice de donn?es' in French.
In R a matrix can contain only one type of data (e.g. numerical data or
character strings) whilst a data.frame can contain different data types
in different columns (one per column, though).

These things are explained more clearly in "An Introduction to R",
that you can find on CRAN in the Manuals section.


> In Using R, the author asks the reader to enter the following data in a
> data frame, which I will call "mydata":
>
> year snow.cover
> 1970 6.5
> 1971 12.0
> 1972 14.9
> 1973 10.0
> 1974 10.7
> 1975 7.9
> ...
>
> mydata=data.frame(year=c(1970,...),snow.cover=c(6.5,...))
>
> 2) How to you retrieve say, snow.cover's second data item? mydata[1][2]
> does not work, neither does mydata[1,2].

mydata[i,j] will give you the element of the ith row and jth column
mydata[2,2] will give what you want.


[question on histogram]


>
> In a French statistics book, the author provides the following data:
>
> Group A   Number: 35   Mean:27
> Group B  Number: 42  Mean:24
>
> and asks: "what is the mean of the group constituted by the reunion of
> the two groups?"
>
> The answer is of course (27 x 35) + (24 x 42) / 77
>
> 3) Is there a way to compute this mean in R (apart from doing the above
> operation, of course) if you have two sets of data?
>

R is a very flexible programming language, so you can do
a lot of what you can imagine and more.

If you have the two sets, there is no need to do this,
just concatenate these two sets and calculate the mean.
If you want to make your own function for doing this,
it could be done as follows:

myfun <- function(set1, set2){
  set1and2 <- c(set1, set2)
  overallmean <- mean(set1and2)
  return(overallmean)
}

Then use this new user-defined function with
two vectors of your own, say a and b

> a <- c(1,2,3)
> b <- c(4,5,6)
> myfun(a, b)
[1] 3.5

If you only have the data of the exercise in the
statistics textbook, you can use
the weighted.mean function of R:

> weighted.mean(c(27,24), w=c(35,42))
[1] 25.36364

which is correct

> (27*35+24*42)/77
[1] 25.36364


> 4) How do you set class limits in R, for instance
>
> 10-20
> 21-31
> etc.

For this you could use the cut() function
Type ?cut at the R prompt and the help page
on this function will show up.

> 5) How do you determine quartiles in R? Is there a way to determine the
> "semi-inter-quartile deviation" ("?cart semi-inter-quartile" in
> French)?
>

I know of IQR, but am not sure it is what you want.
Read its help page by typing ?IQR


I hope that this helps,

Tobias



From bwheeler at echip.com  Wed Feb  4 14:22:02 2004
From: bwheeler at echip.com (Bob Wheeler)
Date: Wed, 04 Feb 2004 08:22:02 -0500
Subject: [R] [R-pkgs] AlgDesign
Message-ID: <4020F1FA.6040203@echip.com>

AlgDesign is a new package for calculating algorithmic experimental
designs. It will calculate both exact and approximate designs for a
variety of criteria. It will handle very large designs. It will also
block designs in a variety of ways, including split plotting. You should
find it at least as capable as other software for this purpose.

I'd normally submit this sort of thing to beta test, but I guess the R
users are the beta testers, so have at it. It would probably be best to
send the bug reports directly to me rather then clutter up the newsgroups.


-- 
Bob Wheeler --- http://www.bobwheeler.com/
           ECHIP, Inc. ---
Randomness comes in bunches.

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From rpeng at jhsph.edu  Wed Feb  4 14:49:23 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 04 Feb 2004 08:49:23 -0500
Subject: [R] number point under-flow
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADECDCF0D@crbsmxsusr04.pharma.aventis.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADECDCF0D@crbsmxsusr04.pharma.aventis.com>
Message-ID: <4020F863.70102@jhsph.edu>

Did you compile with gcc-2.96?  I think there were some 
problems with the floating point arithmetic with that 
compiler (at least for the earlier versions released by Red 
Hat).

-roger

Arne.Muller at aventis.com wrote:
> Hello,
> 
> I've come across the following situation in R-1.8.1 (compile + running under
> RedHat 7.1):
> 
> 
>>phyper(24, 514, 5961-514, 53, lower.tail=T)
> 
> [1] 1
> 
>>phyper(24, 514, 5961-514, 53, lower.tail=F)
> 
> [1] -1.037310e-11
> 
> I'd expect the later to be 0 or some very small positive number. Is this a
> number under-flow of the calculation? Do you think I'm safe if I just set the
> result to 0 in these cases?
> 
> 	kind regards,
> 
> 	Arne
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Atropin75 at t-online.de  Wed Feb  4 14:51:20 2004
From: Atropin75 at t-online.de (Felix Eschenburg)
Date: Wed, 4 Feb 2004 14:51:20 +0100
Subject: [R] Newbie question: histogram
In-Reply-To: <05FA90DC-5707-11D8-BE5B-003065D64D74@wwphi.net>
References: <05FA90DC-5707-11D8-BE5B-003065D64D74@wwphi.net>
Message-ID: <200402041451.20017.atropin75@t-online.de>

Hello,
it looks like this is what you want.

year <- c(1970:1980)
> snow <- sample(10,length(year),replace=T)
> snow
 [1]  3  3  3  4  8  3  2  6  6  6 10
> year
 [1] 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980
> mydata <- data.frame(year,snow)
> attach(mydata)
> barplot(snow,names.arg=year,las=2)

for a histogram of snow you might try something like this
hist(snow,breaks=c((min(snow)-0.5):(max(snow)+0.5)))

Felix (who is a newbie himself, so excuse me please if i didnt get your 
problem)


Am Mittwoch, 4. Februar 2004 12:41 schrieb Philippe de Rochambeau:
> Hello,
>
> how do you create a histogram with a data frame?
>
> year snow.cover
> 1970 6.5
> 1971 12.0
> 1972 14.9
> 1973 10.0
> 1974 10.7
> 1975 7.9
> ...
>
> mydata=data.frame(year=c(1970,...),snow.cover=c(6.5,...))
>
> hist(mydata) does not work.
>
> Many thanks.
>
> PR
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Wed Feb  4 14:51:33 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 4 Feb 2004 14:51:33 +0100
Subject: [R] help(Memory)  [forwarded message]
Message-ID: <16416.63717.122602.224482@gargle.gargle.HOWL>

I can't understand that people still send things like this to
R-core...

------- start of forwarded message -------
From: Tineke Casneuf <ticas at psb.ugent.be>
Sender: r-core-bounces at stat.math.ethz.ch
To: R-core at r-project.org
Subject: help(Memory)
Date: Wed, 04 Feb 2004 13:39:32 +0100

Dear,

I am trying to find a appropriate package to analyse gene expression
data from DNA microarray experiments. My data are allready normalized,
so for the clustering of my data I used the 'mva' package. All I
actually need is to calculate euclidean, manhatten, ... distances and
various kinds of correlation coefficients. I am a R beginner, and to me
it's not clear which package I should use (there's so many of them!!). I
have looked at the Bioconductor website, but it looks as if those
packages are meant to be used for fancy tools for smaller datasets
(hundreds of genes): like ANOVA, identification of differentially
expressed genes,... All I want is to calculate distances and correlation
coefficients for all the genes on the microarray (up to 22 000 genes). I
have allready tried to do some calculations, with the mva package, but
the process kills itself and returns a warning: 'heap memory exhausted'.
So I read in the manual how to increase the heap memory: I put it up to
--vsize=2000M, but he still keeps saying it (needed 83Kb or some, more).
I have tried to increase the heap memory to 2200M but he won't let me do
it (too large and ignored). I used a 7 000 rows dataset.

The commands I used are:
> scan ("list_genes", what = "list") -> genenames
> read.table(file ="list_signals", row.names = genenames) -> data
> library (mva)
> as.matrix(dist(data, method = "euclidean", diag = TRUE)) -> matrix
> write.table(matrix, file = "euclidmartix")

So here's my problem: maybe I can't use R (or this package) for this
kind of big datasets (he needs to calculate a 7000 to 7000 matrix), or
there's something wrong with my commands, since R is given 2 giga and he
still crashes. Is there maybe a better package for me to use? Or it this
amount of heap memory not unusual for this big dataset and do I need to
add more?

Can somebody please help me with this?

Thanks in advance,

T.Casneuf

--
==================================================================
Tineke Casneuf          Tel: 32 (0)9 3313692
DEPARTMENT OF PLANT SYSTEMS BIOLOGY           Fax:32 (0)9 3313809
GHENT UNIVERSITY/VIB,    Technology Park 927, B-9052 Gent, Belgium
Vlaams Interuniversitair Instituut voor Biotechnologie         VIB
e-mail:ticas at psb.ugent.be     http://www.psb.ugent.be/bioinformatics/
==================================================================
------- end of forwarded message -------



From Arne.Muller at aventis.com  Wed Feb  4 14:53:11 2004
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Wed, 4 Feb 2004 14:53:11 +0100
Subject: [R] number point under-flow
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADECDCF0F@crbsmxsusr04.pharma.aventis.com>

Hi,

yes, I did compile it with gcc 2.96 ... . Do you've an estimate on how "bad"
this error is, e.g. how much it effects the calculations in R?

	kind regards,
	
	Arne

> -----Original Message-----
> From: Roger D. Peng [mailto:rpeng at jhsph.edu]
> Sent: 04 February 2004 14:49
> To: Muller, Arne PH/FR
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] number point under-flow
> 
> 
> Did you compile with gcc-2.96?  I think there were some 
> problems with the floating point arithmetic with that 
> compiler (at least for the earlier versions released by Red 
> Hat).
> 
> -roger
> 
> Arne.Muller at aventis.com wrote:
> > Hello,
> > 
> > I've come across the following situation in R-1.8.1 
> (compile + running under
> > RedHat 7.1):
> > 
> > 
> >>phyper(24, 514, 5961-514, 53, lower.tail=T)
> > 
> > [1] 1
> > 
> >>phyper(24, 514, 5961-514, 53, lower.tail=F)
> > 
> > [1] -1.037310e-11
> > 
> > I'd expect the later to be 0 or some very small positive 
> number. Is this a
> > number under-flow of the calculation? Do you think I'm safe 
> if I just set the
> > result to 0 in these cases?
> > 
> > 	kind regards,
> > 
> > 	Arne
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> > 
>



From fabien.fivaz at unine.ch  Wed Feb  4 14:51:10 2004
From: fabien.fivaz at unine.ch (Fabien Fivaz)
Date: Wed, 04 Feb 2004 14:51:10 +0100
Subject: [R] Using huge datasets
Message-ID: <4020F8CE.2010101@unine.ch>

Hi,

Here is what I want to do. I have a dataset containing 4.2 *million* 
rows and about 10 columns and want to do some statistics with it, mainly 
using it as a prediction set for GAM and GLM models. I tried to load it 
from a csv file but, after filling up memory and part of the swap (1 gb 
each), I get a segmentation fault and R stops. I use R under Linux. Here 
are my questions :

1) Has anyone ever tried to use such a big dataset?
2) Do you think that it would possible on a more powerfull machine, such 
as a cluster of computers?
3) Finaly, does R has some "memory limitation" or does it just depend on 
the machine I'm using?

Best wishes

Fabien Fivaz



From Atropin75 at t-online.de  Wed Feb  4 15:05:23 2004
From: Atropin75 at t-online.de (Felix Eschenburg)
Date: Wed, 4 Feb 2004 15:05:23 +0100
Subject: [R] Various newbie questions
In-Reply-To: <EC288D72-5705-11D8-BE5B-003065D64D74@wwphi.net>
References: <EC288D72-5705-11D8-BE5B-003065D64D74@wwphi.net>
Message-ID: <200402041505.23309.atropin75@t-online.de>

Am Mittwoch, 4. Februar 2004 12:33 schrieb Philippe de Rochambeau:
> Hello,
>
> 1) What is the difference between a "data frame" (J H Maindonald, Using
> R, p. 12) and a "vector"?

a vector looks like this: 1 2 3 4 5 ...
a data.frame has two dimensions, the rows and the coloumns

>
> In Using R, the author asks the reader to enter the following data in a
> data frame, which I will call "mydata":
>
> year snow.cover
> 1970 6.5
> 1971 12.0
> 1972 14.9
> 1973 10.0
> 1974 10.7
> 1975 7.9
> ...
>
> mydata=data.frame(year=c(1970,...),snow.cover=c(6.5,...))
>
> 2) How to you retrieve say, snow.cover's second data item? mydata[1][2]
> does not work, neither does mydata[1,2].
mydata[2,1] should do the trick: to get a specific cell out of a data.frame 
you use this: name.of.frame[row,coloumn]
try help(apply), this should make the logic behind that a little more clearer 

> hist(mydata[1,2]) does not work. How would you create a histogram with
> the above data?
a histogram gives, as far as i kinow, the frequency of the values of one 
variable, so you might try hist(mydata$snow) to get the histogram for snow
try help(hist) for more information

>
> In a French statistics book, the author provides the following data:
>
> Group A	Number: 35	Mean:27
> Group B  Number: 42  Mean:24
>
> and asks: "what is the mean of the group constituted by the reunion of
> the two groups?"
>
> The answer is of course (27 x 35) + (24 x 42) / 77
>
> 3) Is there a way to compute this mean in R (apart from doing the above
> operation, of course) if you have two sets of data?

lets say you have two vectory called A and B with your given options, you 
would get their mean by 
mean(c(A,B))

> 4) How do you set class limits in R, for instance
>
> 10-20
> 21-31
> etc.
try help(cut)

> 5) How do you determine quartiles in R? Is there a way to determine the
> "semi-inter-quartile deviation" ("?cart semi-inter-quartile" in
> French)?
this question i did not understand

for getting a start in R i recommend "R for Beginners" by Emmanuel Paradis, 
which can be found after following the link "contributed" on 
www.r-project.org

Felix Eschenburg



From jfox at mcmaster.ca  Wed Feb  4 15:20:43 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 04 Feb 2004 09:20:43 -0500
Subject: [R] Newbie question: histogram
In-Reply-To: <05FA90DC-5707-11D8-BE5B-003065D64D74@wwphi.net>
Message-ID: <5.1.0.14.2.20040204091735.01ff3128@127.0.0.1>

Dear Philippe,

I suppose that you want a histogram for snow.cover and not for year. There 
are several ways to proceed; two are

hist(mydata$snow.cover)

and

attach(mydata)
hist(snow.cover)

More generally, it's a good idea to read the introductory manual that comes 
with R (or a book that introduces R). See, in particular, the section on 
lists and data frames in the Introduction to R.

I hope that this helps,
  John

At 12:41 PM 2/4/2004 +0100, Philippe de Rochambeau wrote:
>Hello,
>
>how do you create a histogram with a data frame?
>
>year snow.cover
>1970 6.5
>1971 12.0
>1972 14.9
>1973 10.0
>1974 10.7
>1975 7.9
>...
>
>mydata=data.frame(year=c(1970,...),snow.cover=c(6.5,...))
>
>hist(mydata) does not work.
>
>Many thanks.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From jmacdon at med.umich.edu  Wed Feb  4 15:25:57 2004
From: jmacdon at med.umich.edu (James MacDonald)
Date: Wed, 04 Feb 2004 09:25:57 -0500
Subject: [R] Newbie question: histogram
Message-ID: <s020babe.042@med-gwia-02a.med.umich.edu>

You don't make a histogram with a data.frame. You have to pass a vector
of numeric values to hist(). If you want to make a histogram using a
*column* of a df, you have to subset the df in the call to hist.

hist(mydata[,1]) -or- hist(mydata[,"year"])
hist(mydata[,2]) - or- hist(mydata[,"snow.cover"])

HTH,

Jim

James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> Philippe de Rochambeau <philippe at wwphi.net> 02/04/04 06:41AM >>>
>Hello,

>how do you create a histogram with a data frame?

>year snow.cover
>1970 6.5
>1971 12.0
>1972 14.9
>1973 10.0
>1974 10.7
>1975 7.9
>...

>mydata=data.frame(year=c(1970,...),snow.cover=c(6.5,...))

>hist(mydata) does not work.

>Many thanks.

>PR

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ozric at web.de  Wed Feb  4 15:38:39 2004
From: ozric at web.de (Christian Schulz)
Date: Wed, 4 Feb 2004 15:38:39 +0100
Subject: [R] running R from PHP
In-Reply-To: <16415.1724.787098.9123@viola.nmsu.edu>
References: <16415.1724.787098.9123@viola.nmsu.edu>
Message-ID: <200402041538.40029.ozric@web.de>

Perhaps this is a interesting starting point for you?

http://steve.stat.tku.edu.tw/R_PHP/doR.html

regards,christian


Am Dienstag, 3. Februar 2004 03:26 schrieb brook at biology.nmsu.edu:
> I would like to construct a PHP script that runs R to generate a
> graphics file.  Running R itself is no problem.  However, it seems
> impossible to instantiate one of the graphics devices to create
> output.  For example, the "normal" bitmap devices (e.g., jpeg, png,
> etc.) are derived from X11, which requires a display.  This seems
> true, even if no output is ever directed to a real display.  For some
> reason, the postscript device seems to suffer from similar problems.
>
> Is there a trick to creating a graphics device in the absence of an
> actual display in order to create an image in a file?
>
> Thanks for your help.
>
> Cheers,
> Brook
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From sway at tanox.com  Wed Feb  4 15:31:56 2004
From: sway at tanox.com (Shawn Way)
Date: Wed, 4 Feb 2004 08:31:56 -0600 
Subject: [R] Date Time Conversion problems...
Message-ID: <2F3262756375D411B0CC00B0D049775D01A4CDB9@westpark>

At one time (version 1.7), the code below used to work for converting and
extracting based on the Date Time.  In version 1.8.1, something changed I
know, but I cannot for the life of me figure out what...

Data:

UserName,RequestDate,PO,OrderDate,ExpDelivDate,Vendor,Total
"Woody, Jim",12/19/2002,AP15063,1/7/2003,2/10/2003,Ames ,8570
"Harrold, Paul",12/31/2002,AP15083,1/9/2003,1/10/2003,Ryan ,1039.5
"Vo, Hoang",12/27/2002,AP15055,1/6/2003,1/13/2003,TIDEA,1005.36
"Way, Shawn",1/2/2003,AP15043,1/2/2003,1/9/2003,JS   ,1000
"Vo, Hoang",1/7/2003,SO17440,1/8/2003,12/31/2003,USFi-,3705
"Harrold, Paul",1/10/2003,AP15122,1/13/2003,1/14/2003,FishM,65.06

Old Code:

library(lattice)
data <- read.csv("h:\\list3.csv",header=TRUE)
data2 <-
data.frame(Name=data$UserName,Date=data$RequestDate,Vendor=data$Vendor,Cost=
data$Total)
data2$Date <- strptime(as.character(data2$Date),format="%m/%d/%Y")
start <- strptime(c("1/01/2003"),format="%m/%d/%Y")
end <- strptime(c("12/31/2003"),format="%m/%d/%Y")
data3 <- data2[data2$Date >= start & data2$Date <= end,]
lset(col.whitebg())
xyplot(Cost~as.POSIXct(Date)|Name,data=data3,
       xlab="Date",
       ylab="PO Cost($)",
       ylim=c(0,10000),
       panel= function(x,y){
         a <- mean(y)
         panel.grid(h=-1,v=2)
         panel.xyplot(x,y)
         panel.abline(h=a,col="red")
       }
       )

The error I get is from line 4, 

> data2$Date <- strptime(as.character(data2$Date),format="%m/%d/%Y")
Error in "$<-.data.frame"(`*tmp*`, "Date", value =
strptime(as.character(data2$Date),  : 
	replacement has 9 rows, data has 230

This used to work for replacing the dates with POSIX values...

Also of interest is the extraction for data3, is this the correct method for
extraction?

What I'm looking at is the spending habits of individuals...

Thanks for your help...

  _____  

"Don't rush me, you rush a miracle, you get a rotten miracle." 
-Miracle Max, The Princess Bride

  _____  

 	Shawn Way, PE	 Tanox, Inc.	
Engineering Manager	 10301 Stella Link	
sway at tanox.com	 Houston, TX 77025



From GPetris at uark.edu  Wed Feb  4 15:36:44 2004
From: GPetris at uark.edu (Giovanni Petris)
Date: Wed, 4 Feb 2004 08:36:44 -0600 (CST)
Subject: [R] Novice problems with write()
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF770B@usrymx25.merck.com>
	(andy_liaw@merck.com)
References: <3A822319EB35174CA3714066D590DCD504AF770B@usrymx25.merck.com>
Message-ID: <200402041436.i14EaitM012141@definetti.uark.edu>


write() also take an `append' argument.

GP

> Date: Tue, 03 Feb 2004 21:39:33 -0500
> From: "Liaw, Andy" <andy_liaw at merck.com>
> Sender: r-help-bounces at stat.math.ethz.ch
> Cc: 
> Precedence: list
> 
> > From: Bret Collier
> > 
> > R-Users,
> >          As a relatively new user of R, I have a quick (and probably 
> > simple) question about using write().  I have a population 
> > simulation that 
> > I am running and I want to output a set of variables for each 
> > run of the 
> > simulation into a text file for use in another program.  
> > However, whenever 
> > I attempt to use write(), the only output that I am able to 
> > get is the 
> > final numbers from the simulation.
> > 
> > for example:
> > 
> > x <- 5
> > for (i in 1:10){
> >   z <- x+i
> > print(z)
> > write(z, "c:/test.txt")
> > }
> 
> What you have done is write 6 through 15 to the file test.txt 10 times, each
> with one number.  write() opens a file, write to it, and then close the
> file, so if you do it in the loop, it would open the file 10 times, write
> one number to it 10 times, and close the file 10 times.
> 
> You're probably looking for something like:
> 
> fout <- file("c:/test.txt", "w")
> x <- 5
> for (i in 1:10) {
>   z <- x + i
>   writeLines(paste(z, "\n"), fout)
> }
> close(fout)
> 
> Or simply:
> 
> write(5 + 1:10, file="c:/test.txt", ncol=1)
> 
> Andy
> 
>  
> > In this simple case,  with print(z) I can see that z has what 
> > I am looking 
> > for, but all that is output for the write statement is 15;  
> > While this is 
> > simplified, it shows my problem.
> > 
> > I searched the help files, and on the R website, but I could not find 
> > anything addressing this.  I suspect that it is my lack of 
> > knowledge and I 
> > am missing something obvious (or should be using 
> > write.table).  If anyone 
> > could point me in the right direction I would appreciate it.
> > 
> > Thanks,
> > 
> > Bret Collier
> > Univ. Arkansas
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments,...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From brook at biology.nmsu.edu  Wed Feb  4 15:44:30 2004
From: brook at biology.nmsu.edu (brook@biology.nmsu.edu)
Date: Wed, 4 Feb 2004 07:44:30 -0700
Subject: [R] running R from PHP
In-Reply-To: <Pine.LNX.4.44.0402030658060.2756-100000@gannet.stats>
References: <20040203052433.GA25105@pasteur-kh.org>
	<Pine.LNX.4.44.0402030658060.2756-100000@gannet.stats>
Message-ID: <16417.1358.182591.402294@viola.nmsu.edu>

Below are 2 scripts (png.R and pdf.R) I am trying to run in R from
PHP.  

     # png.R
     x11(display=":5")
     png(filename="g.png")
     plot(1:5)
     graphics.off()

     # pdf.R
     pdf(file="g.pdf")
     plot(1:5)
     graphics.off()

Both run from terminals and png.R will run without a normal X server
if Xvfb is running.  Neither runs under PHP, though (when invoked as
"R --no-save < xxx.R").  They yield the following errors (with the R
startup banner deleted for compactness):

     > x11(display=":5")
     > png(filename="g.png")
     Error in X11(paste("png::", filename, sep = ""), width, height, pointsize,  : 
	     unable to start device PNG
     In addition: Warning message: 
     could not open PNG file `g.png'
     Execution halted

and

     > pdf(file="/usr/pkg/share/httpd/htdocs/test-R/g.pdf")
     Error in PDF(file, old$family, old$encoding, old$bg, old$fg, width, height,  :
	     unable to start device pdf
     In addition: Warning message:
     cannot open `pdf' file argument `/usr/pkg/share/httpd/htdocs/test-R/g.pdf'
     Execution halted

For reference, the R banner information includes the following:

    R : Copyright 2003, The R Development Core Team
    Version 1.6.2  (2003-01-10)

Any help on how to get these scripts to work is greatly appreciated.

Cheers,
Brook



From clandry at fas.harvard.edu  Wed Feb  4 15:45:19 2004
From: clandry at fas.harvard.edu (Christian Landry)
Date: Wed, 04 Feb 2004 09:45:19 -0500
Subject: [R] 2 questions: batch file + R 1.8 on Red-Hat 9.0
Message-ID: <5.1.0.14.2.20040204093437.00b56758@fas.harvard.edu>

Hi,

I have 2 different questions:

First:

I would like to know what is the format of an input command file when 
running R non interactively on a unix machine.

R< command.file

Is there a reference somewhere where I could read on that? Is it just a 
list of the command we would enter interactively usually?

Second:

Is there anyone who had success installing R 1.8 on Red hat Linux 9.0. I am 
new to both Linux and R and I receive error message when installing it.

Thanks a lot for your help



From thpe at hhbio.wasser.tu-dresden.de  Wed Feb  4 15:48:17 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Wed, 04 Feb 2004 15:48:17 +0100
Subject: [R] Sweave and .Rd files
Message-ID: <40210631.1000700@hhbio.wasser.tu-dresden.de>

Hello,

I found Sweave to be a very promising approach and in R-News 2003-2 
Friedrich Leisch wrotes about writing package vignettes.

There is another approach of Henrik Bengtsons R.oo package mixing R 
sourcecode and documentation, so I wonder if there is an approach using 
Sweave together with .Rd documentation files.

How does the development proceed in this field? Are there already 
practical experiences?

Thomas



From ligges at statistik.uni-dortmund.de  Wed Feb  4 15:50:43 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 04 Feb 2004 15:50:43 +0100
Subject: [R] nortest package
In-Reply-To: <BA420EFAAC96D311A7A0006097D37BDB04515A24@EOLE>
References: <BA420EFAAC96D311A7A0006097D37BDB04515A24@EOLE>
Message-ID: <402106C3.2070706@statistik.uni-dortmund.de>

Laurent Houdusse wrote:

> 
> Hi,
> 
> I'm a newbie and i am unable to use lillie.test in nortest
> I have a message: "Couldn't find function "lillie.test"
> I am under windows2000 with R1.8.1
> nortest is listed with .packages(TRUE)
> 
> How to do to use lillie.test function?

Have you attached the package?
  library(nortest)


Uwe Ligges


> 
> Laurent Houdusse 
> Analyste Programmeur
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Feb  4 15:54:52 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 04 Feb 2004 15:54:52 +0100
Subject: [R] Newbie question: histogram
In-Reply-To: <05FA90DC-5707-11D8-BE5B-003065D64D74@wwphi.net>
References: <05FA90DC-5707-11D8-BE5B-003065D64D74@wwphi.net>
Message-ID: <402107BC.90700@statistik.uni-dortmund.de>

Philippe de Rochambeau wrote:

> Hello,
> 
> how do you create a histogram with a data frame?
> 
> year snow.cover
> 1970 6.5
> 1971 12.0
> 1972 14.9
> 1973 10.0
> 1974 10.7
> 1975 7.9
> ...
> 
> mydata=data.frame(year=c(1970,...),snow.cover=c(6.5,...))
> 
> hist(mydata) does not work.

I guess you are not going to create a histogram but a barplot as in:

barplot(mydata$snow.cover, mydata$year, names = mydata$year)

Uwe Ligges


> Many thanks.
> 
> PR
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From bwheeler at echip.com  Wed Feb  4 15:57:06 2004
From: bwheeler at echip.com (Bob Wheeler)
Date: Wed, 04 Feb 2004 09:57:06 -0500
Subject: [R] number point under-flow
References: <C80ECAFA2ACC1B45BE45D133ED660ADECDCF0D@crbsmxsusr04.pharma.aventis.com>
	<4020F863.70102@jhsph.edu>
Message-ID: <40210842.5000000@echip.com>

It's not the compiler. pghyper() in SuppDists does the same thing. Its 
just rounding error. Set the result to 0 if it bothers you.

pghyper(24,514,53, 5961, lower.tail=F)
[1] -3.325965e-12


Roger D. Peng wrote:
> Did you compile with gcc-2.96?  I think there were some problems with 
> the floating point arithmetic with that compiler (at least for the 
> earlier versions released by Red Hat).
> 
> -roger
> 
> Arne.Muller at aventis.com wrote:
> 
>> Hello,
>>
>> I've come across the following situation in R-1.8.1 (compile + running 
>> under
>> RedHat 7.1):
>>
>>
>>> phyper(24, 514, 5961-514, 53, lower.tail=T)
>>
>>
>> [1] 1
>>
>>> phyper(24, 514, 5961-514, 53, lower.tail=F)
>>
>>
>> [1] -1.037310e-11
>>
>> I'd expect the later to be 0 or some very small positive number. Is 
>> this a
>> number under-flow of the calculation? Do you think I'm safe if I just 
>> set the
>> result to 0 in these cases?
>>
>>     kind regards,
>>
>>     Arne
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


-- 
Bob Wheeler --- http://www.bobwheeler.com/
         ECHIP, Inc. ---
Randomness comes in bunches.



From l.houdusse at cerep.fr  Wed Feb  4 15:57:04 2004
From: l.houdusse at cerep.fr (Laurent Houdusse)
Date: Wed, 4 Feb 2004 15:57:04 +0100 
Subject: [R] nortest package
Message-ID: <BA420EFAAC96D311A7A0006097D37BDB04515A25@EOLE>


>Have you attached the package?
>  library(nortest)

Yes, but there is no return



From russelr at science.oregonstate.edu  Wed Feb  4 16:47:11 2004
From: russelr at science.oregonstate.edu (Roly Russell)
Date: Wed, 4 Feb 2004 07:47:11 -0800 (PST)
Subject: [R] Fitting nonlinear (quantile) models to linear data.
Message-ID: <Pine.LNX.4.44.0402040746310.23788-100000@frontend.science.oregonstate.edu>

Hello.

I am trying to fit an asymptotic relationship (nonlinear) to some 
ecological data, and am having problems.  I am interested in the upper 
bound on the data (i.e. if there is an upper limit to 'y' across a range 
of 'x').  As such, I am using the nonlinear quantile regression package 
(nlrq) to fit a michaelis mention type model.

The errors I get (which are dependant on the quantile of interest and the 
particular dataset) tend to result in illogical regression results with 
the nlqr package.  

To test this, I created artificial datasets that were based on underlying 
asymptotic or linear data.  When tested with a nonlinear model, the linear 
data produces an error (step factor reduced below 'midFactor'--a problem 
dealt with previously on this list).  This script is below, for interest.

My question is whether this is a problem that I should deal with through 
fixing my script somehow, or whether fitting a nonlinear model to data 
that may have an underlying linear pattern is inherently statistically 
wrong (I thought that I could use the estimate of the asymptote as a 
metric of how linear versus asymptotic the data were).  

Many thanks, in advance.

roly russell - oregon state university

PS - I have not consulted Bates & Watts yet; I will.



     # build artificial data with multiplicative error
     Dat <- NULL; Dat$x <- rep(seq(1,25,by=3), 5)
     set.seed(1)
     Dat$y <- SSmicmen(Dat$x, 50, 12)*rnorm(45, 1, 0.1)
     plot(Dat)
     # fit a classical least-square regression
     Dat.nls <- nls(y ~ SSmicmen(x, Vmax, Km), data=Dat); Dat.nls
     lines(1:25, predict(Dat.nls, newdata=list(x=1:25)), col=1)
     # the 1st and 3rd quartiles regressions
     Dat.nlrq <- nlrq(y ~ SSmicmen(x, Asym, mid), data=Dat, tau=0.25, 
trace=TRUE)
     lines(1:25, predict(Dat.nlrq, newdata=list(x=1:25)), col=3)
     Dat.nlrq <- nlrq(y ~ SSmicmen(x, Asym, mid), data=Dat, tau=0.75, 
trace=TRUE)
     lines(1:25, predict(Dat.nlrq, newdata=list(x=1:25)), col=3)


    # build artificial LINEAR data with multiplicative error
     Dat <- NULL; Dat$x <- rep(1:25, 2)
     set.seed(1)
     Dat$y <- (Dat$x)*rnorm(50, 1, 0.1)
     plot(Dat)
    # fit first a classical least-square regression
     Dat.nls <- nls(y ~ SSmicmen(x, Vmax, Km), 
data=Dat,control=nls.control(minFactor=1/4096)); Dat.nls
     lines(1:25, predict(Dat.nls, newdata=list(x=1:25)), col=1)



From ligges at statistik.uni-dortmund.de  Wed Feb  4 16:50:30 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 04 Feb 2004 16:50:30 +0100
Subject: [R] number point under-flow
In-Reply-To: <4020F863.70102@jhsph.edu>
References: <C80ECAFA2ACC1B45BE45D133ED660ADECDCF0D@crbsmxsusr04.pharma.aventis.com>
	<4020F863.70102@jhsph.edu>
Message-ID: <402114C6.8010006@statistik.uni-dortmund.de>

Roger D. Peng wrote:

> Did you compile with gcc-2.96?  I think there were some problems with 
> the floating point arithmetic with that compiler (at least for the 
> earlier versions released by Red Hat).

Not (solely) a gcc-2.96 bug, since we get

   phyper(24, 514, 5961-514, 53, lower.tail=F)
[1] -3.325784e-12

on Windows compiled with gcc-3.3.1

Uwe Ligges


> -roger
> 
> Arne.Muller at aventis.com wrote:
> 
>> Hello,
>>
>> I've come across the following situation in R-1.8.1 (compile + running 
>> under
>> RedHat 7.1):
>>
>>
>>> phyper(24, 514, 5961-514, 53, lower.tail=T)
>>
>>
>> [1] 1
>>
>>> phyper(24, 514, 5961-514, 53, lower.tail=F)
>>
>>
>> [1] -1.037310e-11
>>
>> I'd expect the later to be 0 or some very small positive number. Is 
>> this a
>> number under-flow of the calculation? Do you think I'm safe if I just 
>> set the
>> result to 0 in these cases?
>>
>>     kind regards,
>>
>>     Arne
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Feb  4 16:52:33 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 04 Feb 2004 16:52:33 +0100
Subject: [R] nortest package
In-Reply-To: <BA420EFAAC96D311A7A0006097D37BDB04515A25@EOLE>
References: <BA420EFAAC96D311A7A0006097D37BDB04515A25@EOLE>
Message-ID: <40211541.1060000@statistik.uni-dortmund.de>

Laurent Houdusse wrote:

>>Have you attached the package?
>> library(nortest)
> 
> 
> Yes, but there is no return
> 
> 


For me

  install.packages("nortest")
  library(nortest)
  lillie.test(rnorm(100, mean = 5, sd = 3))

works:



         Lilliefors (Kolmogorov-Smirnov) normality test

data:  rnorm(100, mean = 5, sd = 3)
D = 0.0581, p-value = 0.5571



Uwe Ligges



From l.houdusse at cerep.fr  Wed Feb  4 16:57:42 2004
From: l.houdusse at cerep.fr (Laurent Houdusse)
Date: Wed, 4 Feb 2004 16:57:42 +0100 
Subject: [R] nortest package
Message-ID: <BA420EFAAC96D311A7A0006097D37BDB04515A26@EOLE>

Thanks!

I had downloaded source files and not binary
So , it's good now


Laurent Houdusse
Analyste Programmeur



-----Message d'origine-----
De : Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Envoy? : mercredi 4 f?vrier 2004 16:53
? : Laurent Houdusse
Cc : 'r-help at stat.math.ethz.ch'
Objet : Re: RE : [R] nortest package


Laurent Houdusse wrote:

>>Have you attached the package?
>> library(nortest)
> 
> 
> Yes, but there is no return
> 
> 


For me

  install.packages("nortest")
  library(nortest)
  lillie.test(rnorm(100, mean = 5, sd = 3))

works:



         Lilliefors (Kolmogorov-Smirnov) normality test

data:  rnorm(100, mean = 5, sd = 3)
D = 0.0581, p-value = 0.5571



Uwe Ligges



From ripley at stats.ox.ac.uk  Wed Feb  4 17:01:17 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 4 Feb 2004 16:01:17 +0000 (GMT)
Subject: [R] number point under-flow
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADECDCF0D@crbsmxsusr04.pharma.aventis.com>
Message-ID: <Pine.LNX.4.44.0402041558450.1693-100000@gannet.stats>

Try the latest patched version, as this has already been fixed.

> phyper(24, 514, 5961-514, 53, lower.tail=F)
[1] 1.084688e-13

    o   [l]choose() use a more accurate formula which also slightly
        improves p- and qhyper(); choose(n, k) now returns 0 instead
        of NaN for k < 0 or > n.



On Wed, 4 Feb 2004 Arne.Muller at aventis.com wrote:

> Hello,
> 
> I've come across the following situation in R-1.8.1 (compile + running under
> RedHat 7.1):
> 
> > phyper(24, 514, 5961-514, 53, lower.tail=T)
> [1] 1
> > phyper(24, 514, 5961-514, 53, lower.tail=F)
> [1] -1.037310e-11
> 
> I'd expect the later to be 0 or some very small positive number. Is this a
> number under-flow of the calculation? Do you think I'm safe if I just set the
> result to 0 in these cases?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Wed Feb  4 17:11:59 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 4 Feb 2004 11:11:59 -0500
Subject: [R] Using huge datasets
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7716@usrymx25.merck.com>

A matrix of that size takes up just over 320MB to store in memory.  I'd
imagine you probably can do it with 2GB physical RAM (assuming your
`columns' are all numeric variables; i.e., no factors).

However, perhaps better way than the brute-force, one-shot way, is to read
in the data in chunks and do the prediction piece by piece.  You can use
scan(), or open()/readLines()/close() to do this fairly easily.

My understanding of how (most) clusters work is that you need at least one
node that will accommodate the memory load for the monolithic R process, so
probably not much help.  (I could very well be wrong about this.  If so, I'd
be very grateful for correction.)

HTH,
Andy

> From: Fabien Fivaz
> 
> Hi,
> 
> Here is what I want to do. I have a dataset containing 4.2 *million* 
> rows and about 10 columns and want to do some statistics with 
> it, mainly 
> using it as a prediction set for GAM and GLM models. I tried 
> to load it 
> from a csv file but, after filling up memory and part of the 
> swap (1 gb 
> each), I get a segmentation fault and R stops. I use R under 
> Linux. Here 
> are my questions :
> 
> 1) Has anyone ever tried to use such a big dataset?
> 2) Do you think that it would possible on a more powerfull 
> machine, such 
> as a cluster of computers?
> 3) Finaly, does R has some "memory limitation" or does it 
> just depend on 
> the machine I'm using?
> 
> Best wishes
> 
> Fabien Fivaz
> 
 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From rpeng at jhsph.edu  Wed Feb  4 17:18:45 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 04 Feb 2004 11:18:45 -0500
Subject: [R] Using huge datasets
In-Reply-To: <4020F8CE.2010101@unine.ch>
References: <4020F8CE.2010101@unine.ch>
Message-ID: <40211B65.30706@jhsph.edu>

By my calculation, your dataset should occupy less than 
400MB of RAM, so this is not a terribly large dataset (these 
days).  But that's not including any possible attributes 
(like row names) which often also take up a lot of memory. 
Considering that a function like read.csv() makes a copy of 
the dataset your actual requirements are ~800MB, which for a 
1GB machine may be too big depending on what else the 
computer is doing.  I have successfully loaded *much* bigger 
datasets into R (2-4GB) without a problem.

Some possible solutions are

1. Buy more RAM
2. Use scan(), which doesn't make a copy of the dataset
3. Use a 64-bit machine and buy even more RAM.

Using a cluster of computers doesn't really help in this 
situation because there's no easy way to spread a dataset 
across multiple machines.  So you will still be limited by 
the memory on a single machine.

As far as I know, R does not have a "memory limitation" -- 
the only limit is the memory installed on your computer.

-roger

Fabien Fivaz wrote:
> Hi,
> 
> Here is what I want to do. I have a dataset containing 4.2 *million* 
> rows and about 10 columns and want to do some statistics with it, mainly 
> using it as a prediction set for GAM and GLM models. I tried to load it 
> from a csv file but, after filling up memory and part of the swap (1 gb 
> each), I get a segmentation fault and R stops. I use R under Linux. Here 
> are my questions :
> 
> 1) Has anyone ever tried to use such a big dataset?
> 2) Do you think that it would possible on a more powerfull machine, such 
> as a cluster of computers?
> 3) Finaly, does R has some "memory limitation" or does it just depend on 
> the machine I'm using?
> 
> Best wishes
> 
> Fabien Fivaz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From abunn at montana.edu  Wed Feb  4 17:31:47 2004
From: abunn at montana.edu (Andy Bunn)
Date: Wed, 4 Feb 2004 09:31:47 -0700
Subject: [R] nortest package
In-Reply-To: <BA420EFAAC96D311A7A0006097D37BDB04515A24@EOLE>
Message-ID: <001c01c3eb3c$73eb4730$78f05a99@msu.montana.edu>

Did you load the library?

library(nortest)
lillie.test(rnorm(100, mean = 5, sd = 3))
lillie.test(runif(100, min = 2, max = 4))



From maechler at stat.math.ethz.ch  Wed Feb  4 18:04:44 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 4 Feb 2004 18:04:44 +0100
Subject: [R] gcc 2.96 {was 'number point under-flow'}
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADECDCF0F@crbsmxsusr04.pharma.aventis.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADECDCF0F@crbsmxsusr04.pharma.aventis.com>
Message-ID: <16417.9772.316202.266985@gargle.gargle.HOWL>

>>>>> "ArneM" ==   <Arne.Muller at aventis.com>
>>>>>     on Wed, 4 Feb 2004 14:53:11 +0100 writes:

    ArneM> Hi, yes, I did compile it with gcc 2.96 ... . Do
    ArneM> you've an estimate on how "bad" this error is,
    ArneM> e.g. how much it effects the calculations in R?

In my memory, the effects are bad enough to very quickly drop
such a version of R and get one which is correctly compiled.

Even if only 1 in 10000 computations go wrong; you will hardly
notice and you have chance of knowing which of your final
results will be inaccurate by how much.

This has been on this mailing list and in many installation
instructions. "gcc 2.96" has never been an official release of
gcc and the fact that Redhat had bundled it with one of their
distributions was probably the biggest mistake they've ever
made.

Google for "gcc 2.96" and you will find
       http://gcc.gnu.org/gcc-2.96.html
and much more variations on this theme.

Current is gcc 3.3.2, released last October, but gcc 3.2.x might
be acceptable too (but 3.2.1 and 3.2.2 are broken on Solaris).



From maechler at stat.math.ethz.ch  Wed Feb  4 18:07:46 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 4 Feb 2004 18:07:46 +0100
Subject: [R] Newbie question: histogram
In-Reply-To: <5.1.0.14.2.20040204091735.01ff3128@127.0.0.1>
References: <05FA90DC-5707-11D8-BE5B-003065D64D74@wwphi.net>
	<5.1.0.14.2.20040204091735.01ff3128@127.0.0.1>
Message-ID: <16417.9954.719475.515558@gargle.gargle.HOWL>

>>>>> "JohnF" == John Fox <jfox at mcmaster.ca>
>>>>>     on Wed, 04 Feb 2004 09:20:43 -0500 writes:

    JohnF> Dear Philippe, I suppose that you want a histogram
    JohnF> for snow.cover and not for year. There are several
    JohnF> ways to proceed; two are

    JohnF> hist(mydata$snow.cover)

    JohnF> and

    JF> attach(mydata)
    JF> hist(snow.cover)

Actually, attaching data frames is a bit discouraged these days.
The modern R way for this (and more complicated situations) is

  with(mydata,  hist(snow.cover) )
   

    JohnF> More generally, it's a good idea to read the
    JohnF> introductory manual that comes with R (or a book that
    JohnF> introduces R). See, in particular, the section on
    JohnF> lists and data frames in the Introduction to R.

definitely!

Martin



From Rau at demogr.mpg.de  Wed Feb  4 14:59:48 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Wed, 4 Feb 2004 14:59:48 +0100
Subject: [R] Various newbie questions
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A0662@hermes.demogr.mpg.de>

Hi,

> -----Original Message-----
> From:	Philippe de Rochambeau [SMTP:philippe at wwphi.net]
> Sent:	Wednesday, February 04, 2004 12:33 PM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] Various newbie questions
> 
> year snow.cover
> 1970 6.5
> 1971 12.0
> 1972 14.9
> 1973 10.0
> 1974 10.7
> 1975 7.9
> ...
> 
> mydata=data.frame(year=c(1970,...),snow.cover=c(6.5,...))
> 
> 2) How to you retrieve say, snow.cover's second data item? mydata[1][2] 
> does not work, neither does mydata[1,2].
> 
	year <- 1970:1975
	snow.cover <- c(6.5,12,14.9,10,10.7,7.9)
	mydata <- data.frame(cbind(year,snow.cover))

	# retrieving 2nd column:
	mydata[,2]

	# retrieving 3rd row:
	mydata[3,]

	# snow.cover's second data-item:
	mydata[2,2]
	# or:
	mydata$snow.cover[2]

> In a French statistics book, the author provides the following data:
> 
> Group A	Number: 35	Mean:27
> Group B  Number: 42  Mean:24
> 
> and asks: "what is the mean of the group constituted by the reunion of 
> the two groups?"
> 
> The answer is of course (27 x 35) + (24 x 42) / 77
> 
> 3) Is there a way to compute this mean in R (apart from doing the above 
> operation, of course) if you have two sets of data?
> 
	numbers <- c(35,42)
	arithmeans <- c(27,24)

	weighted.mean(arithmeans,numbers)


	Just a general remark: the first thing you should do (as is written
in the R-Posting-Guide) is consulting the available online help of R.
	For example, you could use
	?vector
	?data.frame
	to get an answer for your first question.
	If you don't know actually what you are looking for, you can also
enter a search string and, optionally, the package.
	In the case of question 3, you could have written:
	help.search("mean", package="base")
	and R would have returned several commands - among them also
"weighted.mean"

	Best,
	Roland



+++++
This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked.   If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.



From ripley at stats.ox.ac.uk  Wed Feb  4 18:21:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 4 Feb 2004 17:21:38 +0000 (GMT Standard Time)
Subject: [R] Latin 2 encoding + fonts
In-Reply-To: <BAY2-F156ZCHusMjQHt0004fece@hotmail.com>
References: <BAY2-F156ZCHusMjQHt0004fece@hotmail.com>
Message-ID: <Pine.WNT.4.58.0402041717020.3368@auk>

On Wed, 4 Feb 2004, Miha STAUT wrote:

> Hi,
>
> In the FAQ I read about options to specify different fonts than the default
> ones for the console (in the file Rprofile) and for the graphical output
> (Rdevga). I would however like to replace Latin 1 with Latin 2 enconding for
> both (console and graphical) output in Windows and just graphical output in
> Linux.

You are confusing fonts with encodings.

Windows does not use either Latin 1 or Latin 2, and R for Windows does not
encode for the console or the graphical device.  Just use the Windows
version of a ISO-8859-2 locale and a font supported by your locale (almost
all under NT, fewer under Win9x).

> I guess it is possible but I did not find the way.
>
> How can I use the fonts (*.afm) and the (presumably) encondings (*.enc) in
> R/rw1081/afm? How do I know what are the real font names. Are those only the
> ones listed in the man page for Hershey?

This is nothing to do with Hershey.  All the information you need is on the
help page for postscript().

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Jim_Garrett at bd.com  Wed Feb  4 17:13:02 2004
From: Jim_Garrett at bd.com (Jim_Garrett@bd.com)
Date: Wed, 4 Feb 2004 11:13:02 -0500
Subject: [R] Job opportunity
Message-ID: <OF328112B5.7A1619ED-ON85256E30.00566846@bd.com>

I'm pleased to announce that my employer, Becton Dickinson, has an open
position for software implementation in the Matlab and S languages.  If
interested, send a cover letter and resume (or CV) to Dr. Richard Moore at
richard_moore at bd.com.  If you have questions, contact myself (at
jim_garrett at bd.com) or Dr. Moore.

Below find a position description.

Jim Garrett
Becton Dickinson Diagnostics
Baltimore, Maryland, USA

***

BECTON DICKINSON DIAGNOSTIC SYSTEMS
POSITION DESCRIPTION

POSITION TITLE: Senior Engineer, Algorithm Implementation

DEPARTMENT: 10148014, Systems Engineering

REPORTS TO: Richard Moore, Manager Systems Engineering

Date: 1/6/04

The statements below are intended to describe the general nature and
level of work being performed by associates assigned to this job. This
job description is not intended to be an exhaustive list of all
responsibilities, duties, and skills required of associates so
classified.

JOB SUMMARY:

Works closely with senior members of the R&D engineering and
statistics group to implement and optimize algorithms in the areas
of signal processing, classification, and other fields relative to
in vitro diagnostics.

DUTIES AND RESPONSIBILITIES:

* Uses and integrates "high-level" tools and packages to perform data
  analysis and implement algorithms designed by R&D scientists,
  engineers, and statisticians
* Optimizes existing tools and algorithms using low level languages as
required
* Applies analyses to large data sets in a database environment
* Modifies databases to match analysis needs
* Adheres to R&D software development, documentation, and validation
standards

QUALIFICATIONS:

KNOWLEDGE AND SKILLS:
* Experience with Matlab is required
* Experience with C or C++ is required
* Experience with relational database management systems is required
* Experience with the S language (R or S-Plus) is desirable
* Experience with signal processing techniques is desirable
* Experience with object-oriented software design is desirable
* Knowledge of linear algebra and numerical analysis is desirable
* Strong interpersonal skills
* Strong oral and written communication skills
* Strong problem solving skills and attention to detail

EDUCATION AND EXPERIENCE:
* B.S. and 5 years experience or M.S. and 3 years experience in
  Applied Math, Computer Science, Engineering or related field is
  required.


**********************************************************************
This message is intended only for the designated recipient(s...{{dropped}}



From Fabien.Fivaz at unine.ch  Wed Feb  4 18:30:05 2004
From: Fabien.Fivaz at unine.ch (FIVAZ Fabien)
Date: Wed, 4 Feb 2004 18:30:05 +0100
Subject: [R] Using huge datasets
Message-ID: <3FD6056F2FB7784B81146E4952493C8D0462CC73@mail01.unine.ch>

You were all right. My data, when I load it with scan() just takes about 300MB of memory and I do not have any problem with it. When loaded with scan, it is not yet a matrix, and I can easily convert it to a matrix with matrix(blabla). The problem I have is that I have to convert it to a data frame (I have a mix of numbers and factors). It takes some time but it's OK. But I cannot read or work with the created data frame, it always ends with a seg fault ! I *just* did variable[1] (where variable is the name of my variable :-)), and it returned a seg fault.

Why is there such a difference between matrices and data frames? Is it because data frames store much more informations?

Best wishes, Fabien


-------- Message d'origine--------
De:	Liaw, Andy [mailto:andy_liaw at merck.com]
Date:	mer. 04.02.2004 17:11
?:	FIVAZ Fabien; r-help at stat.math.ethz.ch
Cc:	
Objet:	RE: [R] Using huge datasets
A matrix of that size takes up just over 320MB to store in memory.  I'd
imagine you probably can do it with 2GB physical RAM (assuming your
`columns' are all numeric variables; i.e., no factors).

However, perhaps better way than the brute-force, one-shot way, is to read
in the data in chunks and do the prediction piece by piece.  You can use
scan(), or open()/readLines()/close() to do this fairly easily.

My understanding of how (most) clusters work is that you need at least one
node that will accommodate the memory load for the monolithic R process, so
probably not much help.  (I could very well be wrong about this.  If so, I'd
be very grateful for correction.)

HTH,
Andy

> From: Fabien Fivaz
> 
> Hi,
> 
> Here is what I want to do. I have a dataset containing 4.2 *million* 
> rows and about 10 columns and want to do some statistics with 
> it, mainly 
> using it as a prediction set for GAM and GLM models. I tried 
> to load it 
> from a csv file but, after filling up memory and part of the 
> swap (1 gb 
> each), I get a segmentation fault and R stops. I use R under 
> Linux. Here 
> are my questions :
> 
> 1) Has anyone ever tried to use such a big dataset?
> 2) Do you think that it would possible on a more powerfull 
> machine, such 
> as a cluster of computers?
> 3) Finaly, does R has some "memory limitation" or does it 
> just depend on 
> the machine I'm using?
> 
> Best wishes
> 
> Fabien Fivaz
> 
 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From edd at debian.org  Wed Feb  4 18:30:49 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 4 Feb 2004 11:30:49 -0600
Subject: [R] Date Time Conversion problems...
In-Reply-To: <2F3262756375D411B0CC00B0D049775D01A4CDB9@westpark>
References: <2F3262756375D411B0CC00B0D049775D01A4CDB9@westpark>
Message-ID: <20040204173049.GA17282@sonny.eddelbuettel.com>

On Wed, Feb 04, 2004 at 08:31:56AM -0600, Shawn Way wrote:
> At one time (version 1.7), the code below used to work for converting and
> extracting based on the Date Time.  In version 1.8.1, something changed I
> know, but I cannot for the life of me figure out what...
> 
> Data:
> 
> UserName,RequestDate,PO,OrderDate,ExpDelivDate,Vendor,Total
> "Woody, Jim",12/19/2002,AP15063,1/7/2003,2/10/2003,Ames ,8570
> "Harrold, Paul",12/31/2002,AP15083,1/9/2003,1/10/2003,Ryan ,1039.5
> "Vo, Hoang",12/27/2002,AP15055,1/6/2003,1/13/2003,TIDEA,1005.36
> "Way, Shawn",1/2/2003,AP15043,1/2/2003,1/9/2003,JS   ,1000
> "Vo, Hoang",1/7/2003,SO17440,1/8/2003,12/31/2003,USFi-,3705
> "Harrold, Paul",1/10/2003,AP15122,1/13/2003,1/14/2003,FishM,65.06
> 
> Old Code:
> 
> library(lattice)
> data <- read.csv("h:\\list3.csv",header=TRUE)
> data2 <-
> data.frame(Name=data$UserName,Date=data$RequestDate,Vendor=data$Vendor,Cost=
> data$Total)
> data2$Date <- strptime(as.character(data2$Date),format="%m/%d/%Y")
> start <- strptime(c("1/01/2003"),format="%m/%d/%Y")
> end <- strptime(c("12/31/2003"),format="%m/%d/%Y")
> data3 <- data2[data2$Date >= start & data2$Date <= end,]
> lset(col.whitebg())
> xyplot(Cost~as.POSIXct(Date)|Name,data=data3,
>        xlab="Date",
>        ylab="PO Cost($)",
>        ylim=c(0,10000),
>        panel= function(x,y){
>          a <- mean(y)
>          panel.grid(h=-1,v=2)
>          panel.xyplot(x,y)
>          panel.abline(h=a,col="red")
>        }
>        )
> 
> The error I get is from line 4, 
> 
> > data2$Date <- strptime(as.character(data2$Date),format="%m/%d/%Y")
> Error in "$<-.data.frame"(`*tmp*`, "Date", value =
> strptime(as.character(data2$Date),  : 
> 	replacement has 9 rows, data has 230

The '9 rows' gives it aways -- it works with an explicit time object cast:

data2$Date <- as.POSIXct(strptime(as.character(data2$Date),format="%m/%d/%Y"))
start <- as.POSIXct(strptime(c("1/01/2003"),format="%m/%d/%Y"))
end <- as.POSIXct(strptime(c("12/31/2003"),format="%m/%d/%Y"))

> This used to work for replacing the dates with POSIX values...
> 
> Also of interest is the extraction for data3, is this the correct method for
> extraction?

It works.  A more formal way is in the subsetting and range functions for
the its package.

Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From ggrothendieck at myway.com  Wed Feb  4 18:35:23 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed,  4 Feb 2004 12:35:23 -0500 (EST)
Subject: [R] Date Time Conversion problems...
Message-ID: <20040204173523.632FB396E@mprdmxin.myway.com>



One uses POSIXct dates in data frames, not POSIXlt 
dates (which is what strptime produces).

To correct this replace:

   strptime(...) with as.POSIXct(strptime(...))

or just add 0, i.e. replace:

   strptime(...) with strptime(...)+0


---

Date:   Wed, 4 Feb 2004 08:31:56 -0600  
From:   Shawn Way <sway at tanox.com>
To:   'r-help at stat.math.ethz.ch' <r-help at stat.math.ethz.ch> 
Subject:   [R] Date Time Conversion problems... 

 
At one time (version 1.7), the code below used to work for converting and
extracting based on the Date Time. In version 1.8.1, something changed I
know, but I cannot for the life of me figure out what...

Data:

UserName,RequestDate,PO,OrderDate,ExpDelivDate,Vendor,Total
"Woody, Jim",12/19/2002,AP15063,1/7/2003,2/10/2003,Ames ,8570
"Harrold, Paul",12/31/2002,AP15083,1/9/2003,1/10/2003,Ryan ,1039.5
"Vo, Hoang",12/27/2002,AP15055,1/6/2003,1/13/2003,TIDEA,1005.36
"Way, Shawn",1/2/2003,AP15043,1/2/2003,1/9/2003,JS ,1000
"Vo, Hoang",1/7/2003,SO17440,1/8/2003,12/31/2003,USFi-,3705
"Harrold, Paul",1/10/2003,AP15122,1/13/2003,1/14/2003,FishM,65.06

Old Code:

library(lattice)
data <- read.csv("h:\\list3.csv",header=TRUE)
data2 <-
data.frame(Name=data$UserName,Date=data$RequestDate,Vendor=data$Vendor,Cost=
data$Total)
data2$Date <- strptime(as.character(data2$Date),format="%m/%d/%Y")
start <- strptime(c("1/01/2003"),format="%m/%d/%Y")
end <- strptime(c("12/31/2003"),format="%m/%d/%Y")
data3 <- data2[data2$Date >= start & data2$Date <= end,]
lset(col.whitebg())
xyplot(Cost~as.POSIXct(Date)|Name,data=data3,
xlab="Date",
ylab="PO Cost($)",
ylim=c(0,10000),
panel= function(x,y){
a <- mean(y)
panel.grid(h=-1,v=2)
panel.xyplot(x,y)
panel.abline(h=a,col="red")
}
)

The error I get is from line 4, 

> data2$Date <- strptime(as.character(data2$Date),format="%m/%d/%Y")
Error in "$<-.data.frame"(`*tmp*`, "Date", value =
strptime(as.character(data2$Date), : 
     replacement has 9 rows, data has 230

This used to work for replacing the dates with POSIX values...

Also of interest is the extraction for data3, is this the correct method for
extraction?

What I'm looking at is the spending habits of individuals...

Thanks for your help...

_____ 

"Don't rush me, you rush a miracle, you get a rotten miracle." 
-Miracle Max, The Princess Bride

_____ 

     Shawn Way, PE      Tanox, Inc.     
Engineering Manager      10301 Stella Link     
sway at tanox.com      Houston, TX 77025



From p.dalgaard at biostat.ku.dk  Wed Feb  4 18:49:58 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Feb 2004 18:49:58 +0100
Subject: [R] running R from PHP
In-Reply-To: <16417.1358.182591.402294@viola.nmsu.edu>
References: <20040203052433.GA25105@pasteur-kh.org>
	<Pine.LNX.4.44.0402030658060.2756-100000@gannet.stats>
	<16417.1358.182591.402294@viola.nmsu.edu>
Message-ID: <x2znby3fax.fsf@biostat.ku.dk>

<brook at biology.nmsu.edu> writes:

> Below are 2 scripts (png.R and pdf.R) I am trying to run in R from
> PHP.  
> 
>      # png.R
>      x11(display=":5")
>      png(filename="g.png")
>      plot(1:5)
>      graphics.off()
> 
>      # pdf.R
>      pdf(file="g.pdf")
>      plot(1:5)
>      graphics.off()
> 
> Both run from terminals and png.R will run without a normal X server
> if Xvfb is running.  Neither runs under PHP, though (when invoked as
> "R --no-save < xxx.R").  They yield the following errors (with the R
> startup banner deleted for compactness):
> 
>      > x11(display=":5")
>      > png(filename="g.png")
>      Error in X11(paste("png::", filename, sep = ""), width, height, pointsize,  : 
> 	     unable to start device PNG
>      In addition: Warning message: 
>      could not open PNG file `g.png'
>      Execution halted
> 
> and
> 
>      > pdf(file="/usr/pkg/share/httpd/htdocs/test-R/g.pdf")
>      Error in PDF(file, old$family, old$encoding, old$bg, old$fg, width, height,  :
> 	     unable to start device pdf
>      In addition: Warning message:
>      cannot open `pdf' file argument `/usr/pkg/share/httpd/htdocs/test-R/g.pdf'
>      Execution halted
> 
> For reference, the R banner information includes the following:
> 
>     R : Copyright 2003, The R Development Core Team
>     Version 1.6.2  (2003-01-10)
> 
> Any help on how to get these scripts to work is greatly appreciated.

Your R version is about a year out of date, but that's hardly the
issue. I don't do PHP, but the error message in both cases has to do
with file opening, so how about checking permissions on your current
directory: Try sticking this into your script
 
   system("id; pwd; ls -la") 

Also notice that web applications often take special security measures
and may change one or all of the following: working directory, root
directory, user id, and group id.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From eugenedalt at yahoo.com  Wed Feb  4 18:50:55 2004
From: eugenedalt at yahoo.com (eugene dalt)
Date: Wed, 4 Feb 2004 09:50:55 -0800 (PST)
Subject: [R] Insightful acquires "S" language
In-Reply-To: <OF15553D54.609C745A-ON85256E2F.006AB346-85256E2F.006AE633@hgsi.com>
Message-ID: <20040204175055.36071.qmail@web10913.mail.yahoo.com>

This is a very good news for R...chances are
Insightful
would copy more great features of R showing how good
is R...just as they did for Bioconductor! 
--- partha_bagchi at hgsi.com wrote:
> Has anyone else received an email saying that
> Insightful has acquired the 
> S programming language? What do you think is the
> impact (if any) of this 
> news on R?
> 
> Partha
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Wed Feb  4 18:51:52 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 4 Feb 2004 17:51:52 +0000 (GMT)
Subject: [R] Date Time Conversion problems...
In-Reply-To: <2F3262756375D411B0CC00B0D049775D01A4CDB9@westpark>
Message-ID: <Pine.LNX.4.44.0402041745090.7824-100000@gannet.stats>

It never worked: there was an undetected error and you got a corrupt data 
frame.  Here is concocted example from 1.7.0

> date <- as.POSIXlt(c(Sys.time(), Sys.time()))
> DF <- data.frame(x=1)
> DF$date <- date
> DF
Error in data.frame(x = "1", date = c("2004-02-04 17:47:50", "2004-02-04
...

You cannot add a list of length 9 to a dataframe by

data2$Date <- strptime(as.character(data2$Date),format="%m/%d/%Y")

and now you get a sensible error message.

You need to convert Date to POSIXct before trying to put the object in a
data frame.


On Wed, 4 Feb 2004, Shawn Way wrote:

> At one time (version 1.7), the code below used to work for converting and
> extracting based on the Date Time.  In version 1.8.1, something changed I
> know, but I cannot for the life of me figure out what...
> 
> Data:
> 
> UserName,RequestDate,PO,OrderDate,ExpDelivDate,Vendor,Total
> "Woody, Jim",12/19/2002,AP15063,1/7/2003,2/10/2003,Ames ,8570
> "Harrold, Paul",12/31/2002,AP15083,1/9/2003,1/10/2003,Ryan ,1039.5
> "Vo, Hoang",12/27/2002,AP15055,1/6/2003,1/13/2003,TIDEA,1005.36
> "Way, Shawn",1/2/2003,AP15043,1/2/2003,1/9/2003,JS   ,1000
> "Vo, Hoang",1/7/2003,SO17440,1/8/2003,12/31/2003,USFi-,3705
> "Harrold, Paul",1/10/2003,AP15122,1/13/2003,1/14/2003,FishM,65.06
> 
> Old Code:
> 
> library(lattice)
> data <- read.csv("h:\\list3.csv",header=TRUE)
> data2 <-
> data.frame(Name=data$UserName,Date=data$RequestDate,Vendor=data$Vendor,Cost=
> data$Total)
> data2$Date <- strptime(as.character(data2$Date),format="%m/%d/%Y")
> start <- strptime(c("1/01/2003"),format="%m/%d/%Y")
> end <- strptime(c("12/31/2003"),format="%m/%d/%Y")
> data3 <- data2[data2$Date >= start & data2$Date <= end,]
> lset(col.whitebg())
> xyplot(Cost~as.POSIXct(Date)|Name,data=data3,
>        xlab="Date",
>        ylab="PO Cost($)",
>        ylim=c(0,10000),
>        panel= function(x,y){
>          a <- mean(y)
>          panel.grid(h=-1,v=2)
>          panel.xyplot(x,y)
>          panel.abline(h=a,col="red")
>        }
>        )
> 
> The error I get is from line 4, 
> 
> > data2$Date <- strptime(as.character(data2$Date),format="%m/%d/%Y")
> Error in "$<-.data.frame"(`*tmp*`, "Date", value =
> strptime(as.character(data2$Date),  : 
> 	replacement has 9 rows, data has 230
> 
> This used to work for replacing the dates with POSIX values...


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jinsong_zh at yahoo.com  Wed Feb  4 20:18:28 2004
From: jinsong_zh at yahoo.com (Jinsong Zhao)
Date: Wed, 4 Feb 2004 11:18:28 -0800 (PST)
Subject: [R] center or scale before analyzing using pls.pcr
Message-ID: <20040204191828.34792.qmail@web20813.mail.yahoo.com>

Dear all,

I found pls.pcr package will give different results if the data are
centered and scaled using scale().

I am not sure about when I should scale my data, and whether the
dependent variable should be scaled. If the dependent variable is
scaled, how I give a prediction to the real data?

I appreciate for any suggestions and comments.

Best regards,

Jinsong


=====
(Mr.) Jinsong Zhao
Ph.D. Candidate
School of the Environment
Nanjing University
22 Hankou Road, Nanjing 210093
P.R. China
E-mail: jinsong_zh at yahoo.com



From ripley at stats.ox.ac.uk  Wed Feb  4 20:18:18 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 4 Feb 2004 19:18:18 +0000 (GMT)
Subject: [R] number point under-flow
In-Reply-To: <402114C6.8010006@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0402041917470.8080-100000@gannet.stats>

Note R-patched and R-devel get more accurate answers.

On Wed, 4 Feb 2004, Uwe Ligges wrote:

> Roger D. Peng wrote:
> 
> > Did you compile with gcc-2.96?  I think there were some problems with 
> > the floating point arithmetic with that compiler (at least for the 
> > earlier versions released by Red Hat).
> 
> Not (solely) a gcc-2.96 bug, since we get
> 
>    phyper(24, 514, 5961-514, 53, lower.tail=F)
> [1] -3.325784e-12
> 
> on Windows compiled with gcc-3.3.1
> 
> Uwe Ligges
> 
> 
> > -roger
> > 
> > Arne.Muller at aventis.com wrote:
> > 
> >> Hello,
> >>
> >> I've come across the following situation in R-1.8.1 (compile + running 
> >> under
> >> RedHat 7.1):
> >>
> >>
> >>> phyper(24, 514, 5961-514, 53, lower.tail=T)
> >>
> >>
> >> [1] 1
> >>
> >>> phyper(24, 514, 5961-514, 53, lower.tail=F)
> >>
> >>
> >> [1] -1.037310e-11
> >>
> >> I'd expect the later to be 0 or some very small positive number. Is 
> >> this a
> >> number under-flow of the calculation? Do you think I'm safe if I just 
> >> set the
> >> result to 0 in these cases?
> >>
> >>     kind regards,
> >>
> >>     Arne
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide! 
> >> http://www.R-project.org/posting-guide.html
> >>
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Wed Feb  4 20:25:38 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 04 Feb 2004 14:25:38 -0500
Subject: [R] Newbie question: histogram
In-Reply-To: <16417.9954.719475.515558@gargle.gargle.HOWL>
References: <5.1.0.14.2.20040204091735.01ff3128@127.0.0.1>
	<05FA90DC-5707-11D8-BE5B-003065D64D74@wwphi.net>
	<5.1.0.14.2.20040204091735.01ff3128@127.0.0.1>
Message-ID: <5.1.0.14.2.20040204142315.01ff2128@127.0.0.1>

Dear Martin,

At 06:07 PM 2/4/2004 +0100, Martin Maechler wrote:
> >>>>> "JohnF" == John Fox <jfox at mcmaster.ca>
> >>>>>     on Wed, 04 Feb 2004 09:20:43 -0500 writes:
>
>     JohnF> Dear Philippe, I suppose that you want a histogram
>     JohnF> for snow.cover and not for year. There are several
>     JohnF> ways to proceed; two are
>
>     JohnF> hist(mydata$snow.cover)
>
>     JohnF> and
>
>     JF> attach(mydata)
>     JF> hist(snow.cover)
>
>Actually, attaching data frames is a bit discouraged these days.
>The modern R way for this (and more complicated situations) is
>
>   with(mydata,  hist(snow.cover) )
>

Although I'm aware of (some of) the problems and possibly confusing 
situations that can arise from attaching a data frame, I believe that, 
especially for novice users, there's an advantage in doing so. In 
particular, although using with() is perhaps less ambiguous, it is 
necessary to repeat it for each command.

Regards,
  John

>     JohnF> More generally, it's a good idea to read the
>     JohnF> introductory manual that comes with R (or a book that
>     JohnF> introduces R). See, in particular, the section on
>     JohnF> lists and data frames in the Introduction to R.
>
>definitely!
>
>Martin

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From mail at joeconway.com  Wed Feb  4 20:21:02 2004
From: mail at joeconway.com (Joe Conway)
Date: Wed, 04 Feb 2004 11:21:02 -0800
Subject: [R] running R from PHP
In-Reply-To: <16417.1358.182591.402294@viola.nmsu.edu>
References: <20040203052433.GA25105@pasteur-kh.org>	<Pine.LNX.4.44.0402030658060.2756-100000@gannet.stats>
	<16417.1358.182591.402294@viola.nmsu.edu>
Message-ID: <4021461E.10906@joeconway.com>

brook at biology.nmsu.edu wrote:
> Both run from terminals and png.R will run without a normal X server 
> if Xvfb is running.

> Neither runs under PHP, though (when invoked as "R --no-save < 
> xxx.R").

> They yield the following errors (with the R startup banner deleted 
> for compactness):

> could not open PNG file `g.png'

> cannot open `pdf' file argument
> `/usr/pkg/share/httpd/htdocs/test-R/g.pdf'

 From the evidence above, I'd guess a file permission error. The web 
server probably runs as the user "apache" or something similar -- does 
that user have write permission to the place where you are trying to 
create the images?

Try writing to "/tmp/g.png" and "/tmp/g.pdf" and see if the files get 
created.

HTH,

Joe



From sheth at economics.rutgers.edu  Wed Feb  4 20:36:55 2004
From: sheth at economics.rutgers.edu (Arnav Sheth)
Date: Wed,  4 Feb 2004 14:36:55 -0500
Subject: [R] Clustering with 'agnes'
In-Reply-To: <4020A2FE.5000702@statistik.uni-dortmund.de>
References: <000f01c3eabf$69424630$722617ac@arnav>
	<4020A2FE.5000702@statistik.uni-dortmund.de>
Message-ID: <1075923415.402149d71193f@webmail.econ.rutgers.edu>


Hi Uwe,

Thanks for the tip. I already have row labels. My problem is, (referring to the 
example below) how can I get R to tell me that upto three clusters, the points 
are clustered around (0,0), (1,0) and (0,1)?

Perhaps it is not even possible, I am not sure.

With regards,
Arnav


Quoting Uwe Ligges <ligges at statistik.uni-dortmund.de>:

> Arnav Sheth wrote:
> 
> > Hello,
> > 
> > I had a question regarding clustering using the agnes() function from the
> 'cluster' package.
> > 
> > I was wondering if anyone knew how I can identify cluster points after
> running the agnes function. 
> > 
> > For example, I created a dataset with points randomly scattered around
> (0,0), (0,1) and (1,0). After clustering, the dendrogram shows all the
> clustered points and I get the ordering and height and the agglomerative
> coefficient. But nowhere do I see the three actual points listed. Although
> agnes clusters until there is one main cluster, it is clear that at three
> clusters, each of the clusters consist of points around the three main
> points. I was wondering if there was any way in which I can have R give me
> the actual cluster points at three (or any number, for that matter) clusters,
> ie (0,0), (0,1) and (1,0). A visual display of the clusters would be even
> better.
> > 
> > I have tried using idenfity after converting the agnes object to an hclust
> object, but that only gives me a listing of the points in each cluster.
> > 
> > I hope this question is clear. I am a little new with both clustering and
> using R for clustering, so please ask me to clarify if anything is unclear.
> > 
> > Your help would be most appreciated!
> 
> See the example of ?agnes, where the points are labeled.
> Most easily use agnes() on a data.frame with rownames.
> 
> Uwe Ligges
> 
> 
> 
> 
> 
> 
> > With regards,
> > Arnav
> > 
> > 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
>



From brian_cade at usgs.gov  Wed Feb  4 20:54:49 2004
From: brian_cade at usgs.gov (Brian S Cade)
Date: Wed, 4 Feb 2004 12:54:49 -0700
Subject: [R] Fitting nonlinear (quantile) models to linear data.
Message-ID: <OF0009ACD6.807350B9-ON07256E30.006BF2D2@cr.usgs.gov>


Roly:  I don't know if I can speak to your question about the linear model
fit with the nonlinear function.  But in general I have observed that when
using a fairly flexible nonlinear model form in nlrq() that initial
estimates obtained for any specified quantile may be quite erroneous in the
sense that the proportion of residuals less than or greater than the
estimate are way off what they should be for a specified quantile (e..g,
for tau = 0.90, I've obtained initial estimates that might have as few as
75% of the residuals <= estimate or as many as 97% <= estimate; we would
like a solution that has close to 90% <= estimate (with some inequality
required because of the zero residuals associated with the fit).  This
seems to produce both some strange fits when plotted against the data as
well as some fits that might seem reasonable but have to be wrong.   It
seems to be quite important with this nlrq() code to explore different
starting values and tolerance values before you can believe that you've
converged to a reasonable solution for any selected quantile.   I always
check the proportion of residuals <= estimate as I iterate through
solutions.  You might want to check this for your models.   Again, I repeat
the problems I've had with this occur with very heterogeneous data with
fairly flexible nonlinear functions (e.g., piecewise linear models with
unknown breakpoints and quadratic curvature allowed to connect the pieces).

Any comments\suggestions from Roger Koenker?

Brian


Brian S. Cade

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  brian_cade at usgs.gov
tel:  970 226-9326


                                                                                                                
                      Roly Russell                                                                              
                      <russelr at science.orego        To:       r-help at stat.math.ethz.ch                          
                      nstate.edu>                   cc:                                                         
                      Sent by:                      Subject:  [R] Fitting nonlinear (quantile) models to linear 
                      r-help-bounces at stat.ma         data.                                                      
                      th.ethz.ch                                                                                
                                                                                                                
                                                                                                                
                      02/04/2004 08:47 AM                                                                       
                                                                                                                
                                                                                                                




Hello.

I am trying to fit an asymptotic relationship (nonlinear) to some
ecological data, and am having problems.  I am interested in the upper
bound on the data (i.e. if there is an upper limit to 'y' across a range
of 'x').  As such, I am using the nonlinear quantile regression package
(nlrq) to fit a michaelis mention type model.

The errors I get (which are dependant on the quantile of interest and the
particular dataset) tend to result in illogical regression results with
the nlqr package.

To test this, I created artificial datasets that were based on underlying
asymptotic or linear data.  When tested with a nonlinear model, the linear
data produces an error (step factor reduced below 'midFactor'--a problem
dealt with previously on this list).  This script is below, for interest.

My question is whether this is a problem that I should deal with through
fixing my script somehow, or whether fitting a nonlinear model to data
that may have an underlying linear pattern is inherently statistically
wrong (I thought that I could use the estimate of the asymptote as a
metric of how linear versus asymptotic the data were).

Many thanks, in advance.

roly russell - oregon state university

PS - I have not consulted Bates & Watts yet; I will.



     # build artificial data with multiplicative error
     Dat <- NULL; Dat$x <- rep(seq(1,25,by=3), 5)
     set.seed(1)
     Dat$y <- SSmicmen(Dat$x, 50, 12)*rnorm(45, 1, 0.1)
     plot(Dat)
     # fit a classical least-square regression
     Dat.nls <- nls(y ~ SSmicmen(x, Vmax, Km), data=Dat); Dat.nls
     lines(1:25, predict(Dat.nls, newdata=list(x=1:25)), col=1)
     # the 1st and 3rd quartiles regressions
     Dat.nlrq <- nlrq(y ~ SSmicmen(x, Asym, mid), data=Dat, tau=0.25,
trace=TRUE)
     lines(1:25, predict(Dat.nlrq, newdata=list(x=1:25)), col=3)
     Dat.nlrq <- nlrq(y ~ SSmicmen(x, Asym, mid), data=Dat, tau=0.75,
trace=TRUE)
     lines(1:25, predict(Dat.nlrq, newdata=list(x=1:25)), col=3)


    # build artificial LINEAR data with multiplicative error
     Dat <- NULL; Dat$x <- rep(1:25, 2)
     set.seed(1)
     Dat$y <- (Dat$x)*rnorm(50, 1, 0.1)
     plot(Dat)
    # fit first a classical least-square regression
     Dat.nls <- nls(y ~ SSmicmen(x, Vmax, Km),
data=Dat,control=nls.control(minFactor=1/4096)); Dat.nls
     lines(1:25, predict(Dat.nls, newdata=list(x=1:25)), col=1)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.connolly at hortresearch.co.nz  Wed Feb  4 21:35:42 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 5 Feb 2004 09:35:42 +1300
Subject: [R] Date Time Conversion problems...
In-Reply-To: <2F3262756375D411B0CC00B0D049775D01A4CDB9@westpark>;
	from sway@tanox.com on Wed, Feb 04, 2004 at 08:31:56AM -0600
References: <2F3262756375D411B0CC00B0D049775D01A4CDB9@westpark>
Message-ID: <20040205093542.N935@hortresearch.co.nz>

On Wed, 04-Feb-2004 at 08:31AM -0600, Shawn Way wrote:

|> At one time (version 1.7), the code below used to work for converting and
|> extracting based on the Date Time.  In version 1.8.1, something changed I
|> know, but I cannot for the life of me figure out what...


[...]

|> 
|> The error I get is from line 4, 
|> 
|> > data2$Date <- strptime(as.character(data2$Date),format="%m/%d/%Y")
|> Error in "$<-.data.frame"(`*tmp*`, "Date", value =
|> strptime(as.character(data2$Date),  : 
|> 	replacement has 9 rows, data has 230
|> 
|> This used to work for replacing the dates with POSIX values...

Try:

data2$Date <- as.POSIXct(strptime(as.character(data2$Date),format="%m/%d/%Y"))

You'll find that it prints the date labels more usefully in 1.8.1

HTH

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From sfalcon at fhcrc.org  Wed Feb  4 20:33:36 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 4 Feb 2004 11:33:36 -0800
Subject: [R] 2 questions: batch file + R 1.8 on Red-Hat 9.0
In-Reply-To: <5.1.0.14.2.20040204093437.00b56758@fas.harvard.edu>
References: <5.1.0.14.2.20040204093437.00b56758@fas.harvard.edu>
Message-ID: <20040204193336.GD1464@queenbee.fhcrc.org>

I can help with the first question:

> I would like to know what is the format of an input command file when 
> running R non interactively on a unix machine.

Put R commands just as you would enter on the command line, or in a file
that you would source() into somefile.R.  Then 

R --no-save --slave < somefile.R

Take a look at "man R" for some details on command line options.

HTH,

+ seth

PS: You'll need to provide some more info on your second question such
as how you are trying to install (from source or from binary) and what
specific errors you are encountering.

> Second:
> 
> Is there anyone who had success installing R 1.8 on Red hat Linux 9.0. I am 
> new to both Linux and R and I receive error message when installing it.
>



From p.dalgaard at biostat.ku.dk  Wed Feb  4 21:39:01 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Feb 2004 21:39:01 +0100
Subject: [R] gcc 2.96 {was 'number point under-flow'}
In-Reply-To: <16417.9772.316202.266985@gargle.gargle.HOWL>
References: <C80ECAFA2ACC1B45BE45D133ED660ADECDCF0F@crbsmxsusr04.pharma.aventis.com>
	<16417.9772.316202.266985@gargle.gargle.HOWL>
Message-ID: <x2r7xa37h6.fsf@biostat.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> >>>>> "ArneM" ==   <Arne.Muller at aventis.com>
> >>>>>     on Wed, 4 Feb 2004 14:53:11 +0100 writes:
> 
>     ArneM> Hi, yes, I did compile it with gcc 2.96 ... . Do
>     ArneM> you've an estimate on how "bad" this error is,
>     ArneM> e.g. how much it effects the calculations in R?
> 
> In my memory, the effects are bad enough to very quickly drop
> such a version of R and get one which is correctly compiled.
> 
> Even if only 1 in 10000 computations go wrong; you will hardly
> notice and you have chance of knowing which of your final
> results will be inaccurate by how much.

Correct me if I'm wrong, but I don't think the compiler is the only
problem here. I got negative phyper values with Martyn's RPM on RH8.0,
and that appears to have been done with GCC 3.2. The devel version, on
the same machine, gets it right (well, gets a positive result...) and
I do have a vague recollection of seeing a variation of this before, so
I suspect there was a bug and someone fixed it.

Possibly, this records the fix:

    o   [l]choose() use a more accurate formula which also slightly
        improves p- and qhyper(); choose(n, k) now returns 0 instead
        of NaN for k < 0 or > n.

If so, then r-patched should fix it too.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jg_liao at yahoo.com  Wed Feb  4 22:59:55 2004
From: jg_liao at yahoo.com (Jason Liao)
Date: Wed, 4 Feb 2004 13:59:55 -0800 (PST)
Subject: [R] Very Fast Multivariate Kernel Density Estimation
Message-ID: <20040204215955.33417.qmail@web10502.mail.yahoo.com>

One of the real advances (in my humble oppinion of course) of 2003 is
the Very Fast Multivariate Kernel Density Estimation algorithm by Alex
Gray which achieves several order of speed improvement by using
Computational Geometry to organize the data. The algorithm is now
implemented in C++ with Mathlab interface by Alexander Ihler of MIT:

http://ssg.mit.edu/~ihler/code/kde.shtml

I wondered if a capable R and C++ user here would make it available to
R users. That would be very useful to many people here. I wanted to do
it myself. But I do not know C, let alone C++. I gave up after studying
the code for two days.

Thank you.

Jason

=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone 732-235-5429, fax (732) 235-5464
http://www.geocities.com/jg_liao



From p.murrell at auckland.ac.nz  Wed Feb  4 23:25:11 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 05 Feb 2004 11:25:11 +1300
Subject: [R] Latin 2 encoding + fonts
References: <BAY2-F156ZCHusMjQHt0004fece@hotmail.com>
	<Pine.WNT.4.58.0402041717020.3368@auk>
Message-ID: <40217147.8090001@stat.auckland.ac.nz>

Hi


Prof Brian D Ripley wrote:
> On Wed, 4 Feb 2004, Miha STAUT wrote:
> 
> 
>>Hi,
>>
>>In the FAQ I read about options to specify different fonts than the default
>>ones for the console (in the file Rprofile) and for the graphical output
>>(Rdevga). I would however like to replace Latin 1 with Latin 2 enconding for
>>both (console and graphical) output in Windows and just graphical output in
>>Linux.
> 
> 
> You are confusing fonts with encodings.
> 
> Windows does not use either Latin 1 or Latin 2, and R for Windows does not
> encode for the console or the graphical device.  Just use the Windows
> version of a ISO-8859-2 locale and a font supported by your locale (almost
> all under NT, fewer under Win9x).
> 
> 
>>I guess it is possible but I did not find the way.
>>
>>How can I use the fonts (*.afm) and the (presumably) encondings (*.enc) in
>>R/rw1081/afm? How do I know what are the real font names. Are those only the
>>ones listed in the man page for Hershey?
> 
> 
> This is nothing to do with Hershey.  All the information you need is on the
> help page for postscript().


And in case you're interested in the grubby details ...

The files in R/rw1081/afm are used for PostScript and PDF output (the 
*.afm are font metric files used for determining characters sizes, 
espectially for mathematical annotation;  the *.enc are encoding files). 
  They are "used" by specifying the family and/or encoding argument(s) 
when starting one of these devices.  See ?postscript and ?pdf

The Hershey fonts are available for all graphical formats and can be 
accessed via a vfont argument currently.  See ?text
All Hershey fonts are hard-coded to use a fixed encoding (mostly 
ISO-Latin-1).

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From cere at u.washington.edu  Thu Feb  5 00:45:10 2004
From: cere at u.washington.edu (Cere M. Davis)
Date: Wed, 4 Feb 2004 15:45:10 -0800 (PST)
Subject: [R] RE: error (fwd)
Message-ID: <Pine.LNX.4.44.0402041536250.678-100000@localhost>


Hi folks,

I've got this funny problem with R's foreign library when reading stata
files.  One file consistently produces vector out of memory errors after
gobbling up 2.7G of memory.  I parsed through the read.dta function and
figured out where the error occurs and the description is below.  I am
running R-1.8.1 on Debian stable system glibc2.2 kernel 2.4.24.  R is is
compiled from source as a shared library.  The file that I am reading is
only 172M in size.  The system I am using has 4G of free memory and 8 G of
swap so this doesn't seem to be a problem for lack of free memory.  See
Below.

Thanks.
-----------------------------------------------------------------------

I stepped through the
function and found that everything runs fine but I get a bunch of warnings
duing the convert.factors section of the code like:

> warnings()
Warning messages:
1: Value labels (fafdstmp) for afdstmp are missing
2: Value labels (fafsmon) for afsmon are missing
3: Value labels (fafsnum) for afsnum are missing
4: Value labels (fafsval) for afsval are missing
5: Value labels (fahcmcar) for ahcmcare are missing
6: Value labels (fahengyv) for ahengyv are missing
7: Value labels (fahenrgy) for ahenrgy are missing
8: Value labels (fahflnch) for ahflnch are missing
9: Value labels (fahflnno) for ahflnno are missing
10: Value labels (fahhcvhi) for ahhcvhi are missing
11: Value labels (fahhhino) for ahhhino are missing
12: Value labels (fahhnum) for ahhnum are missing
13: Value labels (fahmcnum) for ahmcnum are missing
14: Value labels (fahncvhi) for ahncvhi are missing

etc.


then when I try and return rval as the last line in the function and this
is where R starts gobbling up a tone of memory and eventualy dies with a
vector memory exhausted error.

Do you have a sense of where this could be coming from?  Must be something
funny about the communication between the foreign library and the main R
lib.

I'll email the R folks.

On Wed, 4 Feb 2004, Mark S. Handcock wrote:

> Date: Wed, 4 Feb 2004 14:38:12 -0800
> From: Mark S. Handcock <handcock at stat.washington.edu>
> To: 'Cere M. Davis' <cere at u.washington.edu>,
>      'R. Anderson' <anders10 at u.washington.edu>
> Cc: morrism at u.washington.edu, 'Matthew B Weatherford' <mbw at u.washington.edu>,
>      Msh <handcock at stat.washington.edu>
> Subject: RE: error
>
> Cere,
>
> This is useful information. How large is the original data file? If it is
> small (<1Gb) then the 2.7Gb is excessive. Have you searched the R users
> group on www.r-project.org?
>
> Also, can you try:
>
>  rval <- .External("do_readStata", "file", PACKAGE = "foreign")
>
> where "file" is the stata file name on both machines. This is the internal R
> read using  C, so if that works it is elsewhere in the "read.dta" function
> which is easy to fix.
>
> Mark
>
> > -----Original Message-----
> > From: Cere M. Davis [mailto:cere at u.washington.edu]
> > Sent: Monday, February 02, 2004 10:45 PM
> > To: R. Anderson
> > Cc: morrism at u.washington.edu; handcock at stat.washington.edu;
> > Matthew B Weatherford
> > Subject: Re: error
> >
> >
> > More info on the R memory problem.  Just reading one dta file
> > in via the
> > foreign library requires upwards of 2.7G of memory on any
> > machine, 2.7G is
> > the point at which the process runs out of memory so I can't know the
> > upper limit of this process.  I am running the R read process
> > on Libra now
> > but it's been 5 hours since I started the read request and
> > the disk swap
> > is so busy that I cannot tell when the process will finish.
> > There does
> > appear to be a problem with this R job using system swap
> > space on Mosix so
> > a quick test and fix for this is coopt another machine and
> > aggregate some
> > RAM from another machine - if there is physical space in the machine -
> > sometime tommorow hopefully.
> >
> > Stay tuned.
> >
> > >
> > >
> > > Thanks Robin for this email.  I am able to reproduce what
> > you reported
> > > using the file that you gave me below so thank you very
> > much for that.
> > > From what I can see this appears to me a memory allocation
> > issue that
> > > affects all systems but because the main node has such fast ethernet
> > > speeds on can see the results of the problem quckly.  I am
> > testing this
> > > problem on a system with more memory and may have a better
> > sense of what
> > > is needed once I see the results.
> > >
> > > I'll let you know as I learn more perhaps later today.
> > >
> > > Thanks,
> > > Cere
> > >
> > > On Wed, 28 Jan 2004, R. Anderson wrote:
> > >
> > > > Date: Wed, 28 Jan 2004 22:25:11 -0800 (PST)
> > > > From: R. Anderson <anders10 at u.washington.edu>
> > > > To: Cere M. Davis <cere at u.washington.edu>
> > > > Cc: morrism at u.washington.edu
> > > > Subject: Re: error
> > > >
> > > > Cere-
> > > > In the March files(which use the same .dta as the match
> > files-- we were
> > > > looking at on friday),  I was able to get 1979-1988 and
> > 1996-2001 to
> > > > run with marchdatameta.R and create Rdata files.
> > > >
> > > > However when the meta file ran, for example, 1989, the
> > vector error
> > > > occured again.
> > > >
> > > > So I tried running some of the files (marchdatacopy1989.R,
> > > > marchdatacopy1990.R,...) individually.  I was able to
> > produce an RData set
> > > > from the 1989 file.
> > > >
> > > > However when I ran the 1990.R file, I got the
> > > > follwing error:
> > > >
> > ______________________________________________________________________
> > > >
> > > >
> > > > > ##################################################
> > > > > # marchdatacopy1990.R                            #
> > > > > # 10 Jan 2004  -ra                               #
> > > > > #                                                #
> > > > > # This is a template file that is used to read   #
> > > > > # SPSS data into R and should prepare the basic  #
> > > > > # variables needed for the analysis of income    #
> > > > > # for any year 1990 that is specified. It is     #
> > > > > # sourced by the shell script "marchmetacode"    #
> > > > > # for years that are specified in                #
> > > > > # "marchdatameta.R".                             #
> > > > > #  -RA, 10 Jan 2004                         #
> > > > > ##################################################
> > > > >
> > > > > library(foreign)
> > > > > options(object.size = 10000000)
> > > > > mar1990 <-
> > > >
> > read.dta("/net/home/morrism/Data/CPS/March/Extracts.all/mar1990.dta")
> > > > Error: vector memory exhausted (limit reached?)
> > > >
> > > > Process R segmentation fault at Wed Jan 28 21:14:41 2004
> > > >
> > ______________________________________________________________
> > _________
> > > > This was ran in mos2, interactively in emacs and the
> > error differs from
> > > > the other vecor errors.
> > > >
> > > > And then I ran the marchdatacopy1990.R in klee and got
> > the following
> > > > warning:
> > > >
> > ______________________________________________________________
> > _______________
> > > > run marchdatacopy1990.R
> > > > /usr/local/R-1.8.1/lib/R/bin/BATCH: line 55: 31545 Done
> > > > ( echo "invisible(options(echo = TRUE))"; cat ${in}; echo
> > "proc.time()" )
> > > >      31546 Killed                  | ${R_HOME}/bin/R
> > ${opts} >${out} 2>&1
> > > >
> > ______________________________________________________________
> > _____________
> > > >
> > > > When I openned the outfile, marchdatacopy1990.Rout, There
> > was nothing but
> > > > the R prompt.(This is outfile after running the file in klee)
> > > >
> > > > I can stop by Friday morning or Thursday
> > > > afternoon(I meet with Prof Morris at 3 and can stop by
> > afterwards).
> > > >
> > > > I think it is very odd that the marchdatameta file ran
> > without error some
> > > > of the years and others it produced an error.  Aslo note
> > that running
> > > > the matchdatameta file continued to produce same errors
> > as before for all
> > > > years.
> > > >
> > > >
> > > > The directories for the match and march are:
> > > >
> > > > /net/home/morrism/Data/CPS/Comp/R/Code/MarchData ---For march
> > > > /net/home/morrism/Data/CPS/Comp/R/Code/MatchData ---For match
> > > >
> > > > In each directory I am creating datasets from the same
> > .dta files, which
> > > > are in:
> > > >
> > > > /net/home/morrism/Data/CPS/March/Extracts.all
> > > >
> > > > So I do not understand why the marchdatameta file will
> > work for some years
> > > > and the matchdatameta produces the vector error for all years.
> > > >
> > > >
> > > > Thanks,
> > > > Robin Anderson
> > > >
> > > >
> > > >
> > > > On Fri, 23 Jan 2004, Cere M. Davis wrote:
> > > >
> > > > >
> > > > > If you are going to be around today please come by and
> > we'll work on this
> > > > > some more if you have time.
> > > > >
> > > > > >
> > > > > >
> > > > > > Cere-
> > > > > > By running ..1987.R through the matchdatmeta.R I do
> > get the "vector"
> > > > > > error.
> > > > > > I am running that file interactivly through emacs/R
> > split window.
> > > > > > Here is the file path for the .Rout file:
> > > > > >
> > > > > >
> > /net/home/morrism/Data/CPS/Comp/R/Code/MatchData/matchdatacopy
> > 1987.Rout
> > > > > >
> > > > > > This is the file path for the file that creates an R
> > for each year, runs
> > > > > > the R file, by R BATCH --no-save, to get the .Rout file.:
> > > > > >
> > > > > >
> > /net/home/morrism/Data/CPS/Comp/R/Code/MatchData/matchdatameta.R
> > > > > >
> > > > > > Thanks Again
> > > > > > Robin
> > > > > >
> > > > >
> > > > > - - - - - - - - - - - - - - - - - - - - - - - - - - - -
> > - - - - - - - - -
> > > > > 		        Cere Davis
> > > > > 		Unix Systems Administrator - CSDE
> > > > >             cere at u.washington.edu   ph: 206.685.5346
> > > > >          https://staff.washington.edu/cere
> > > > >
> > > > > GnuPG Key   http://staff.washington.edu/cere/gpgkey.txt
> > > > > Key fingerprint = B63C 2361 3B9B 8599 ECC9  D061 3E48
> > A832 F455 9E7FA
> > > > >
> > > > >
> > > > >
> > > > >
> > > >
> > >
> > > - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
> > - - - - - - -
> > > 		        Cere Davis
> > > 		Unix Systems Administrator - CSDE
> > >             cere at u.washington.edu   ph: 206.685.5346
> > >          https://staff.washington.edu/cere
> > >
> > > GnuPG Key   http://staff.washington.edu/cere/gpgkey.txt
> > > Key fingerprint = B63C 2361 3B9B 8599 ECC9  D061 3E48 A832
> > F455 9E7FA
> > >
> > >
> > >
> > >
> > >
> > >
> >
> > - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
> > - - - - - -
> > 		        Cere Davis
> > 		Unix Systems Administrator - CSDE
> >             cere at u.washington.edu   ph: 206.685.5346
> >          https://staff.washington.edu/cere
> >
> > GnuPG Key   http://staff.washington.edu/cere/gpgkey.txt
> > Key fingerprint = B63C 2361 3B9B 8599 ECC9  D061 3E48 A832 F455 9E7FA
> >
> >
> >
>
>

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
		        Cere Davis
		Unix Systems Administrator - CSDE
            cere at u.washington.edu   ph: 206.685.5346
         https://staff.washington.edu/cere

GnuPG Key   http://staff.washington.edu/cere/gpgkey.txt
Key fingerprint = B63C 2361 3B9B 8599 ECC9  D061 3E48 A832 F455 9E7FA



From jeaneid at chass.utoronto.ca  Thu Feb  5 01:38:56 2004
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Wed, 4 Feb 2004 19:38:56 -0500 (Eastern Standard Time)
Subject: [R] lines and dates 
Message-ID: <Pine.WNT.4.58.0402041823180.3900@Scorpion>

Dear All,
I have the following data.frame

`data.frame':	1563 obs. of  4 variables:
 $ Model      :Class 'AsIs'  chr [1:40] "Astro" "Astro" "Astro" "Astro"
 $ Make       :Class 'AsIs'  chr [1:40] "Chevrolet" "Chevrolet"
 $ Production : num  11219 12384  1082  5409  5458 ...
 $ date       :`POSIXlt', format: chr  "2000-05-01" "2000-06-01"


The data frame contains production levels of some cars from 2000 to 2003.
My question is about plotting production for  each  model.
I have a code that  outputs a plot for each model and
it works fine.  However I would like to plot couple of models together i.e
when I do

plot(temp$date, temp$Production, type="n")
by(temp, list(temp$Model), function(x) lines(x[, "date"], x[,
"Production"]))

I get an error:
      Error in xy.coords(x, y) : x and y lengths differ

I believe that it has something to do with POSIXlt. when I issue a length
or NROW command on temp$date it returns the value 9.

any help is greatly appreciated,

Jean



From bates at stat.wisc.edu  Thu Feb  5 02:13:31 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 04 Feb 2004 19:13:31 -0600
Subject: [R] Newbie question: histogram
In-Reply-To: <5.1.0.14.2.20040204142315.01ff2128@127.0.0.1>
References: <5.1.0.14.2.20040204091735.01ff3128@127.0.0.1>
	<05FA90DC-5707-11D8-BE5B-003065D64D74@wwphi.net>
	<5.1.0.14.2.20040204091735.01ff3128@127.0.0.1>
	<5.1.0.14.2.20040204142315.01ff2128@127.0.0.1>
Message-ID: <6rd68u5nwk.fsf@bates4.stat.wisc.edu>

John Fox <jfox at mcmaster.ca> writes:

> At 06:07 PM 2/4/2004 +0100, Martin Maechler wrote:
> > >>>>> "JohnF" == John Fox <jfox at mcmaster.ca>
> > >>>>>     on Wed, 04 Feb 2004 09:20:43 -0500 writes:
> >
> >     JohnF> Dear Philippe, I suppose that you want a histogram
> >     JohnF> for snow.cover and not for year. There are several
> >     JohnF> ways to proceed; two are
> >
> >     JohnF> hist(mydata$snow.cover)
> >
> >     JohnF> and
> >
> >     JF> attach(mydata)
> >     JF> hist(snow.cover)
> >
> >Actually, attaching data frames is a bit discouraged these days.
> >The modern R way for this (and more complicated situations) is
> >
> >   with(mydata,  hist(snow.cover) )
> >
> 
> Although I'm aware of (some of) the problems and possibly confusing
> situations that can arise from attaching a data frame, I believe that,
> especially for novice users, there's an advantage in doing so. In
> particular, although using with() is perhaps less ambiguous, it is
> necessary to repeat it for each command.

But with any version of R compiled with the readline library and with
the Windows GUI and with ESS for emacs you can use the arrow keys to
retrieve the last line typed then edit it.  Repeating information from
earlier lines is not terribly difficult.

I use the 
 with(datafr, func(colname))
paradigm in live sessions for introductory classes and I don't find it
overly cumbersome.



From maj at stats.waikato.ac.nz  Thu Feb  5 03:08:23 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu, 05 Feb 2004 15:08:23 +1300
Subject: [R] Sweave problem
Message-ID: <4021A597.2080301@stats.waikato.ac.nz>

Here is the file minimal.Snw:

\documentclass[a4paper]{article}
\title{R tips and tricks}
\author{Murray Jorgensen}
\usepackage{Sweave}
\begin{document}
\maketitle
\section*{Entering data from a single variable}
The following data are transformed tensile strength measurements on 
polyester
fibres. They may be found on the file \texttt{TENSILE.DAT}. We
may enter this data into R using the \texttt{scan} command.
<<>>=
strength <- scan()
0.023   0.032   0.054   0.069   0.081   0.094
0.105   0.127   0.148   0.169   0.188   0.216

@
\end{document}

and now I attempt to use SWeave to convert it to minimal.tex:

 > Sweave("minimal.Snw")
Writing to file minimal.tex
Processing code chunks ...
  1 : echo term verbatim

Error:  chunk 1
Error in parse(file, n, text, prompt) : parse error

It seems a rather simple piece of code to generate such an error message!

Murray

[R 1.8.1 on Windows XP]
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From jfox at mcmaster.ca  Thu Feb  5 03:13:29 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 04 Feb 2004 21:13:29 -0500
Subject: [R] Newbie question: histogram
In-Reply-To: <6rd68u5nwk.fsf@bates4.stat.wisc.edu>
References: <5.1.0.14.2.20040204142315.01ff2128@127.0.0.1>
	<5.1.0.14.2.20040204091735.01ff3128@127.0.0.1>
	<05FA90DC-5707-11D8-BE5B-003065D64D74@wwphi.net>
	<5.1.0.14.2.20040204091735.01ff3128@127.0.0.1>
	<5.1.0.14.2.20040204142315.01ff2128@127.0.0.1>
Message-ID: <5.1.0.14.2.20040204210236.0204c4b8@127.0.0.1>

Dear Doug,

At 07:13 PM 2/4/2004 -0600, Douglas Bates wrote:
>John Fox <jfox at mcmaster.ca> writes:
>
> > At 06:07 PM 2/4/2004 +0100, Martin Maechler wrote:
> > > >>>>> "JohnF" == John Fox <jfox at mcmaster.ca>
> > > >>>>>     on Wed, 04 Feb 2004 09:20:43 -0500 writes:
> > >
> > >     JohnF> Dear Philippe, I suppose that you want a histogram
> > >     JohnF> for snow.cover and not for year. There are several
> > >     JohnF> ways to proceed; two are
> > >
> > >     JohnF> hist(mydata$snow.cover)
> > >
> > >     JohnF> and
> > >
> > >     JF> attach(mydata)
> > >     JF> hist(snow.cover)
> > >
> > >Actually, attaching data frames is a bit discouraged these days.
> > >The modern R way for this (and more complicated situations) is
> > >
> > >   with(mydata,  hist(snow.cover) )
> > >
> >
> > Although I'm aware of (some of) the problems and possibly confusing
> > situations that can arise from attaching a data frame, I believe that,
> > especially for novice users, there's an advantage in doing so. In
> > particular, although using with() is perhaps less ambiguous, it is
> > necessary to repeat it for each command.
>
>But with any version of R compiled with the readline library and with
>the Windows GUI and with ESS for emacs you can use the arrow keys to
>retrieve the last line typed then edit it.  Repeating information from
>earlier lines is not terribly difficult.
>
>I use the
>  with(datafr, func(colname))
>paradigm in live sessions for introductory classes and I don't find it
>overly cumbersome.

The with() mechanism has much to recommend it. In particular, it makes you 
think about where the data for a computation are coming from. I don't 
believe that this is necessarily an advantage,. however, for a novice user, 
who I believe will find it easier to attach a data frame, compute new 
variables in the global environment, and not have to think about where the 
data are coming from. Sometimes that can cause problems, but I believe that 
it's usually a simpler way to proceed. On the other hand, I can see the 
argument for encouraging good habits from the start.

Regards,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From Toby.Patterson at csiro.au  Thu Feb  5 04:17:47 2004
From: Toby.Patterson at csiro.au (Toby.Patterson@csiro.au)
Date: Thu, 5 Feb 2004 14:17:47 +1100
Subject: [R] lines and dates 
Message-ID: <C4178DC99E08604EA5E2BDB989F0938001E076B1@extas2-hba.tas.csiro.au>

As per the stuff on the list earlier, it looks like you probably need to
convert the POSIXlt's to POSIXct's 
Try: 

?as.POSIXct 



-----Original Message-----
From: Jean Eid [mailto:jeaneid at chass.utoronto.ca] 
Sent: Thursday, February 05, 2004 11:39 AM
To: r-help at stat.math.ethz.ch
Subject: [R] lines and dates 


Dear All,
I have the following data.frame

`data.frame':	1563 obs. of  4 variables:
 $ Model      :Class 'AsIs'  chr [1:40] "Astro" "Astro" "Astro" "Astro"
 $ Make       :Class 'AsIs'  chr [1:40] "Chevrolet" "Chevrolet"
 $ Production : num  11219 12384  1082  5409  5458 ...
 $ date       :`POSIXlt', format: chr  "2000-05-01" "2000-06-01"


The data frame contains production levels of some cars from 2000 to
2003. My question is about plotting production for  each  model. I have
a code that  outputs a plot for each model and it works fine.  However I
would like to plot couple of models together i.e when I do

plot(temp$date, temp$Production, type="n")
by(temp, list(temp$Model), function(x) lines(x[, "date"], x[,
"Production"]))

I get an error:
      Error in xy.coords(x, y) : x and y lengths differ

I believe that it has something to do with POSIXlt. when I issue a
length or NROW command on temp$date it returns the value 9.

any help is greatly appreciated,

Jean

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Thu Feb  5 08:44:57 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Feb 2004 07:44:57 +0000 (GMT)
Subject: [R] Sweave problem
In-Reply-To: <4021A597.2080301@stats.waikato.ac.nz>
Message-ID: <Pine.LNX.4.44.0402050730570.8979-100000@gannet.stats>

Note that ?scan says

    file: the name of a file to read data values from.  If the
          specified file is '""', then input is taken from the keyboard

and you want it to come from the file.  So I would not have expected it to 
work.

However, the help file is not totally accurate, as this will work in a
batch file in R (although it has not worked in some versions of S-PLUS).  
The problem is that Sweave does expect the input to all be S code, and
does not get as far as running it.


Far from being `rather simple', this is a rather sophisticated usage, 
intended for use only at a keyboard.


On Thu, 5 Feb 2004, Murray Jorgensen wrote:

> Here is the file minimal.Snw:
> 
> \documentclass[a4paper]{article}
> \title{R tips and tricks}
> \author{Murray Jorgensen}
> \usepackage{Sweave}
> \begin{document}
> \maketitle
> \section*{Entering data from a single variable}
> The following data are transformed tensile strength measurements on 
> polyester
> fibres. They may be found on the file \texttt{TENSILE.DAT}. We
> may enter this data into R using the \texttt{scan} command.
> <<>>=
> strength <- scan()
> 0.023   0.032   0.054   0.069   0.081   0.094
> 0.105   0.127   0.148   0.169   0.188   0.216
> 
> @
> \end{document}
> 
> and now I attempt to use SWeave to convert it to minimal.tex:
> 
>  > Sweave("minimal.Snw")
> Writing to file minimal.tex
> Processing code chunks ...
>   1 : echo term verbatim
> 
> Error:  chunk 1
> Error in parse(file, n, text, prompt) : parse error
> 
> It seems a rather simple piece of code to generate such an error message!
> 
> Murray
> 
> [R 1.8.1 on Windows XP]
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maj at stats.waikato.ac.nz  Thu Feb  5 08:57:57 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu, 05 Feb 2004 20:57:57 +1300
Subject: [R] Sweave problem
In-Reply-To: <Pine.LNX.4.44.0402050730570.8979-100000@gannet.stats>
References: <4021A597.2080301@stats.waikato.ac.nz>
Message-ID: <E1AoeR2-0000OP-00@newton.math.waikato.ac.nz>

Sorry, in an effort to be minimal I cut away some of my surrounding text:
The first code block is meant to be typed in by the user, except for the
numbers which are to be thought of as pasted in. I certainly do not wish to
supply a file name to scan() for this particular example.

Murray

At 07:44 5/02/2004 +0000, Prof Brian Ripley wrote:
>Note that ?scan says
>
>    file: the name of a file to read data values from.  If the
>          specified file is '""', then input is taken from the keyboard
>
>and you want it to come from the file.  So I would not have expected it to 
>work.
>
>However, the help file is not totally accurate, as this will work in a
>batch file in R (although it has not worked in some versions of S-PLUS).  
>The problem is that Sweave does expect the input to all be S code, and
>does not get as far as running it.
>
>
>Far from being `rather simple', this is a rather sophisticated usage, 
>intended for use only at a keyboard.
>
>
>On Thu, 5 Feb 2004, Murray Jorgensen wrote:
>
>> Here is the file minimal.Snw:
>> 
>> \documentclass[a4paper]{article}
>> \title{R tips and tricks}
>> \author{Murray Jorgensen}
>> \usepackage{Sweave}
>> \begin{document}
>> \maketitle
>> \section*{Entering data from a single variable}
>> The following data are transformed tensile strength measurements on 
>> polyester
>> fibres. They may be found on the file \texttt{TENSILE.DAT}. We
>> may enter this data into R using the \texttt{scan} command.
>> <<>>=
>> strength <- scan()
>> 0.023   0.032   0.054   0.069   0.081   0.094
>> 0.105   0.127   0.148   0.169   0.188   0.216
>> 
>> @
>> \end{document}
>> 
>> and now I attempt to use SWeave to convert it to minimal.tex:
>> 
>>  > Sweave("minimal.Snw")
>> Writing to file minimal.tex
>> Processing code chunks ...
>>   1 : echo term verbatim
>> 
>> Error:  chunk 1
>> Error in parse(file, n, text, prompt) : parse error
>> 
>> It seems a rather simple piece of code to generate such an error message!
>> 
>> Murray
>> 
>> [R 1.8.1 on Windows XP]
>> 
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From bhx2 at mevik.net  Thu Feb  5 10:36:47 2004
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Thu, 05 Feb 2004 10:36:47 +0100
Subject: [R] center or scale before analyzing using pls.pcr
In-Reply-To: <20040204191828.34792.qmail@web20813.mail.yahoo.com> (Jinsong
	Zhao's message of "Wed, 4 Feb 2004 11:18:28 -0800 (PST)")
References: <20040204191828.34792.qmail@web20813.mail.yahoo.com>
Message-ID: <7oisil98b4.fsf@foo.nemo-project.org>

Jinsong Zhao <jinsong_zh at yahoo.com> writes:

> I found pls.pcr package will give different results if the data are
> centered and scaled using scale().

Centering is done automatically by all implementations of PLSR I am
aware of (including pls.pcr, afaics).

> I am not sure about when I should scale my data,

There are no fixed rules about this.  Many practitioners live more or
less by the rule that unless the variables are `of the same type' or have
equal or comparable scales, they are scaled.  One example of data that
is typically not scaled (at least to begin with) is spectroscopic data.

> and whether the dependent variable should be scaled.

There is no need for scaling the dependent variable.

-- 
Bj?rn-Helge Mevik



From sam.kemp2 at ntlworld.com  Thu Feb  5 11:29:38 2004
From: sam.kemp2 at ntlworld.com (Samuel Kemp)
Date: Thu, 05 Feb 2004 10:29:38 -0000
Subject: [R] Gamma Test package
Message-ID: <opr2v7fowxfwb18v@smtp.ntlworld.com>

Hi,

I have written a Gamma Test package. The Gamma Test (GT) is a 
non-parametric non-linear modelling tool that estimates the variance of 
the noise in an input/output dataset (including time series). The GT was 
recently given a rigourous mathematical proof in the Royal Society. All 
the papers on this work to date can be found at Antonia Jone's (Professor 
of Neural and Evolutionary computing at Cardiff University) web site see 
below.....


	http://www.cs.cf.ac.uk/user/Antonia.J.Jones/GammaArchive/IndexPage.htm

This work has proved to be extremely useful in the non-linear modelling 
process particularly neural networks, where there is now no need for a 
validation set.

Before I upload version 0.01 onto CRAN I was wondering if anyone wanted to 
play about with it (who is interested in non-linear modelling, signal 
processing) and give me some feed back (the more constructive criticism 
the better :-)) so I can make any neccessary adjustments on the code or 
returned parameters. I will be adding more tools to the package in the 
near future (e.g. from a simple Gamma test, we can determine the minimal 
number of data points required in the training process - this is called 
the M-test, also there is a model identification procedure, which I will 
be working on soon to make a fully automated procedure). Additional tools 
will be added in the medium-long term future as more theory is pumped out.

Apologies in advance if I have sent this to the wrong posting place - 
please do not give me a b******ing. In the past people on this mail list 
have ranted at me for asking questions that I could have got from google.

Cheers,

Sam.



From meriema.aupetit at free.fr  Thu Feb  5 11:29:43 2004
From: meriema.aupetit at free.fr (meriema.aupetit@free.fr)
Date: Thu,  5 Feb 2004 11:29:43 +0100
Subject: [R] (no subject)
Message-ID: <1075976983.40221b17ea051@imp3-q.free.fr>



Hello,
Splus contains the function intbin(x,l).

This function allows to make a conversion from an integer x to a binary of 
length l.

for example

intbin(3,2) returns 11

intbin(3,3) returns 011

Do you know how to do it in R ?

Thank you meriema



From umberto_maggiore at hotmail.com  Thu Feb  5 12:31:59 2004
From: umberto_maggiore at hotmail.com (Umberto Maggiore)
Date: Thu, 05 Feb 2004 11:31:59 +0000
Subject: [R] xyplot (lattice): colours of lines
Message-ID: <BAY8-F117eHW6xvSaVw0006fdb6@hotmail.com>

using either one of the following codes:

xyplot(X ~ time | center, type="l", panel=panel.superpose, groups=subject, 
col = treatment)

xyplot(X ~ time | center, groups = subject,
  panel = function(x, y, ...){
    panel.superpose(x, y, col = treatment, type = "l", ...)
    })

I get two different colours for the lines by these colours do not match the 
corresponding
treatment variable

Umberto


Umberto Maggiore wrote:

    Using data from a multicenter study with a parallel-group design 
comparing
two treatments, I plotted each subject's time change of X after stratifying
for center:

xyplot(X ~ time | center, type="l", panel=panel.superpose, groups=subject)

Now I want these lines to take different colours according to the variable
"treatment". Any help?
Umberto

_________________________________________________________________

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html





xyplot(X ~ time | center, type="l", panel=panel.superpose, groups=subject, 
col = treatment)

might work, or more explicitely:

xyplot(X ~ time | center, groups = subject,
  panel = function(x, y, ...){
    panel.superpose(x, y, col = treatment, type = "l", ...)
    })

Best,

Renaud

_________________________________________________________________



From p.dalgaard at biostat.ku.dk  Thu Feb  5 13:35:20 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Feb 2004 13:35:20 +0100
Subject: [R] (no subject)
In-Reply-To: <1075976983.40221b17ea051@imp3-q.free.fr>
References: <1075976983.40221b17ea051@imp3-q.free.fr>
Message-ID: <x2k731ogaf.fsf@biostat.ku.dk>

meriema.aupetit at free.fr writes:

> Hello,
> Splus contains the function intbin(x,l).
> 
> This function allows to make a conversion from an integer x to a binary of 
> length l.
> 
> for example
> 
> intbin(3,2) returns 11
> 
> intbin(3,3) returns 011
> 
> Do you know how to do it in R ?

How about this?

intbin <- function(x, n) 
  if(n) 
    paste(intbin(x%/%2, n-1), x%%2, sep="")
  else if (x)
    stop("Insufficient field width")

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From s-plus at wiwi.uni-bielefeld.de  Thu Feb  5 13:36:32 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Thu, 05 Feb 2004 13:36:32 +0100
Subject: [R] (no subject) -- integer to binary
References: <1075976983.40221b17ea051@imp3-q.free.fr>
Message-ID: <402238D0.9070206@wiwi.uni-bielefeld.de>

meriema.aupetit at free.fr wrote:

>Hello,
>Splus contains the function intbin(x,l).
>
>This function allows to make a conversion from an integer x to a binary of 
>length l.
>
>for example
>
>intbin(3,2) returns 11
>
>intbin(3,3) returns 011
>
>Do you know how to do it in R ?
>
>Thank you meriema
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

you can use the following function

encode <- function(number, base) {
   # simple version of APL-encode / APL-representation "T", pw 10/02
   # "encode" converts the numbers "number" using the radix vector "base"
   n.base <- length(base); result <- matrix(0, length(base), length(number))
   for(i in n.base:1){
     result[i,] <- if(base[i]>0) number %% base[i] else number
     number     <- ifelse(rep(base[i]>0,length(number)),
                          floor(number/base[i]), 0)
   }
   return( if(length(number)==1) result[,1] else result )
}

paste(encode(c(13), c(2,2, 2, 2, 2)),collapse="")
[1] "01101"
encode(c(13), c(2,2, 2, 2, 2))
[1] 0 1 1 0 1

See also:

http://www.wiwi.uni-bielefeld.de/~wolf/software/R-wtools/decodeencode/decodeencode.rev

Peter



From fm3a004 at math.uni-hamburg.de  Thu Feb  5 14:02:18 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Thu, 5 Feb 2004 14:02:18 +0100 (MET)
Subject: [R] Clustering with 'agnes'
In-Reply-To: <1075923415.402149d71193f@webmail.econ.rutgers.edu>
Message-ID: <Pine.GSO.3.95q.1040205135530.19260H-100000@sun11.math.uni-hamburg.de>

Hi,

the underlying principle of hierarchical clustering is *not* that the
clusters can be represented by some centroid points. Most methods are
distance based, i.e. they can be calculated also in absence of any R^p
representation of the points.

If you want to recover centroids, you should do kmeans, normal mixture
clustering (mclust) or pam/clara. Of course you can also take the points
belonging to an agnes cluster and compute the mean vector (or any other
summary statistic), but that's not what hierarchical clustering is
meant to do (it may be reasonable with Ward's method, though).

Christian 

On Wed, 4 Feb 2004, Arnav Sheth wrote:

> 
> Hi Uwe,
> 
> Thanks for the tip. I already have row labels. My problem is, (referring to the 
> example below) how can I get R to tell me that upto three clusters, the points 
> are clustered around (0,0), (1,0) and (0,1)?
> 
> Perhaps it is not even possible, I am not sure.
> 
> With regards,
> Arnav

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From Simon.Fear at synequanon.com  Thu Feb  5 14:45:36 2004
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Thu, 5 Feb 2004 13:45:36 -0000
Subject: [R] Newbie question: histogram
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F021D2@synequanon01>

It's not world shattering but for the record the following is not true:

> -----Original Message-----
> From: John Fox [mailto:jfox at mcmaster.ca]
> (snip)
> In particular, although using with() is perhaps less ambiguous, it is 
> necessary to repeat it for each command.

You can group as many commands as you like, as in

> df <- data.frame(x=1:10, y=1:10)
> with(df, {print(x)
+ print(y)})
 [1]  1  2  3  4  5  6  7  8  9 10
 [1]  1  2  3  4  5  6  7  8  9 10  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From M.E.J.Raijmakers at uva.nl  Thu Feb  5 15:05:40 2004
From: M.E.J.Raijmakers at uva.nl (Maartje Raijmakers)
Date: Thu, 05 Feb 2004 15:05:40 +0100
Subject: [R] Installing odesolve under MacOSX
Message-ID: <BC480C44.1CC8%M.E.J.Raijmakers@uva.nl>

Installing odesolve in Raqua 1.8.0 or 1.8.1 under MacOSX gives the following
message:

Warning message: Installation of package odesolve had non-zero exit status
in: install.packages(ui.pkgs, CRAN = getOption(where), lib = .libPaths()[1])

Moreover, in the source of odesolve is no makefile.

Does anyone know how to get a proper installation?


Maartje



From sheth at economics.rutgers.edu  Thu Feb  5 15:06:02 2004
From: sheth at economics.rutgers.edu (Arnav Sheth)
Date: Thu, 5 Feb 2004 09:06:02 -0500
Subject: [R] Clustering with 'agnes'
References: <Pine.GSO.3.95q.1040205135530.19260H-100000@sun11.math.uni-hamburg.de>
Message-ID: <001901c3ebf1$55a41c10$722617ac@arnav>


Hey Christian,

That clarifies a lot of things. Thank you.

With regards,
Arnav


----- Original Message -----
From: "Christian Hennig" <fm3a004 at math.uni-hamburg.de>
To: "Arnav Sheth" <sheth at economics.rutgers.edu>
Cc: "Uwe Ligges" <ligges at statistik.uni-dortmund.de>;
<R-help at stat.math.ethz.ch>
Sent: Thursday, February 05, 2004 8:02 AM
Subject: Re: [R] Clustering with 'agnes'


> Hi,
>
> the underlying principle of hierarchical clustering is *not* that the
> clusters can be represented by some centroid points. Most methods are
> distance based, i.e. they can be calculated also in absence of any R^p
> representation of the points.
>
> If you want to recover centroids, you should do kmeans, normal mixture
> clustering (mclust) or pam/clara. Of course you can also take the points
> belonging to an agnes cluster and compute the mean vector (or any other
> summary statistic), but that's not what hierarchical clustering is
> meant to do (it may be reasonable with Ward's method, though).
>
> Christian
>
> On Wed, 4 Feb 2004, Arnav Sheth wrote:
>
> >
> > Hi Uwe,
> >
> > Thanks for the tip. I already have row labels. My problem is, (referring
to the
> > example below) how can I get R to tell me that upto three clusters, the
points
> > are clustered around (0,0), (1,0) and (0,1)?
> >
> > Perhaps it is not even possible, I am not sure.
> >
> > With regards,
> > Arnav
>
> ***********************************************************************
> Christian Hennig
> Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
> hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
> #######################################################################
> ich empfehle www.boag-online.de
>
>



From jfox at mcmaster.ca  Thu Feb  5 15:34:11 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 05 Feb 2004 09:34:11 -0500
Subject: [R] Newbie question: histogram
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572F021D2@synequanon01>
Message-ID: <5.1.0.14.2.20040205093028.0204af00@127.0.0.1>

Dear Simon,

At 01:45 PM 2/5/2004 +0000, Simon Fear wrote:
>It's not world shattering but for the record the following is not true:
>
> > -----Original Message-----
> > From: John Fox [mailto:jfox at mcmaster.ca]
> > (snip)
> > In particular, although using with() is perhaps less ambiguous, it is
> > necessary to repeat it for each command.
>
>You can group as many commands as you like, as in
>
> > df <- data.frame(x=1:10, y=1:10)
> > with(df, {print(x)
>+ print(y)})
>  [1]  1  2  3  4  5  6  7  8  9 10
>  [1]  1  2  3  4  5  6  7  8  9 10
>

Indeed, and doing so can be useful, but in analyzing data interactively, 
one generally types a command (or two), examines the output, and then types 
another. Frankly, it's not so much the typing (as Doug Bates pointed out, 
one can recover previous commands) as the inability to forget about the 
data frame that seems the issue to me (and a small one at that).

Regards,
  John

>Simon Fear
>Senior Statistician
>Syne qua non Ltd
>Tel: +44 (0) 1379 644449
>Fax: +44 (0) 1379 644445
>email: Simon.Fear at synequanon.com
>web: http://www.synequanon.com
>
>Number of attachments included with this message: 0
>
>This message (and any associated files) is confidential and
>contains information which may be legally privileged.  It is
>intended for the stated addressee(s) only.  Access to this
>email by anyone else is unauthorised.  If you are not the
>intended addressee, any action taken (or not taken) in
>reliance on it, or any disclosure or copying of the contents of
>it is unauthorised and unlawful.  If you are not the addressee,
>please inform the sender immediately and delete the email
>from your system.
>
>This message and any associated attachments have been
>checked for viruses using an internationally recognised virus
>detection process.  However, Internet communications cannot
>be guaranteed to be secure or error-free as information could
>be intercepted, corrupted, lost, destroyed, arrive late or
>incomplete. Therefore, we do not accept responsibility for any
>errors or omissions that are present in this message, or any
>attachment, that have arisen as a result of e-mail transmission.
>If verification is required, please request a hard-copy version.
>Any views or opinions presented are solely those of the author
>and do not necessarily represent those of Syne qua non.
>
>
>

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From H.Andersson at nioo.knaw.nl  Thu Feb  5 16:13:23 2004
From: H.Andersson at nioo.knaw.nl (Andersson, Henrik)
Date: Thu, 5 Feb 2004 16:13:23 +0100
Subject: [R] Savitzky-Golay smoothing for reflectance data
Message-ID: <65F6E1EC64DCA6489800C09A2007FC6E181720@cememail1.nioo.int>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040205/e9ac7fca/attachment.pl

From consentino at infinito.it  Thu Feb  5 16:11:52 2004
From: consentino at infinito.it (Fabrizio Consentino)
Date: Thu, 5 Feb 2004 16:11:52 +0100
Subject: [R] Multilevel in R
Message-ID: <004201c3ebfb$6ddcee60$9a111d97@consentino>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040205/9a9f8abd/attachment.pl

From tlumley at u.washington.edu  Thu Feb  5 16:35:37 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 5 Feb 2004 07:35:37 -0800 (PST)
Subject: [R] RE: error (fwd)
In-Reply-To: <Pine.LNX.4.44.0402041536250.678-100000@localhost>
References: <Pine.LNX.4.44.0402041536250.678-100000@localhost>
Message-ID: <Pine.A41.4.58.0402050728530.95412@homer41.u.washington.edu>

On Wed, 4 Feb 2004, Cere M. Davis wrote:

>
> Hi folks,
>
> I've got this funny problem with R's foreign library when reading stata
> files.  One file consistently produces vector out of memory errors after
> gobbling up 2.7G of memory.  I parsed through the read.dta function and
> figured out where the error occurs and the description is below.  I am
> running R-1.8.1 on Debian stable system glibc2.2 kernel 2.4.24.  R is is
> compiled from source as a shared library.  The file that I am reading is
> only 172M in size.  The system I am using has 4G of free memory and 8 G of
> swap so this doesn't seem to be a problem for lack of free memory.  See
> Below.


I though this bug had already been fixed (Stefano Iacus reported it to me
a while back).  The problem occurs when a variable has a set of factor
names assigned, but that set of names is not present in the file -- it was
not clear from the otherwise excellent Stata documentation that this is
possible in  a valid .dta file.

Obviously the fix is not completely effective.  I'll look into it.

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From tlumley at u.washington.edu  Thu Feb  5 16:44:20 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 5 Feb 2004 07:44:20 -0800 (PST)
Subject: [R] Using huge datasets
In-Reply-To: <40211B65.30706@jhsph.edu>
References: <4020F8CE.2010101@unine.ch> <40211B65.30706@jhsph.edu>
Message-ID: <Pine.A41.4.58.0402050740050.95412@homer41.u.washington.edu>

On Wed, 4 Feb 2004, Roger D. Peng wrote:

>
> As far as I know, R does not have a "memory limitation" --
> the only limit is the memory installed on your computer.
>

The only practical limitation is the pointer size of your machine, so
32-bit machine can't address more than 4Gb, and R probably won't get all
of that.

Further out, R will run into problems if you try to have a vector with
more than 2^31 elements (since length() returns an integer), and probably
if you have more than 2^31 objects.  I would guess that there are tighter
limitations implied by the .rda save format.

	-thomas



From deepayan at stat.wisc.edu  Thu Feb  5 16:58:18 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 5 Feb 2004 09:58:18 -0600
Subject: [R] xypplot (lattice): colours of lines
In-Reply-To: <BAY8-F49WPXBemybNxv0006cb72@hotmail.com>
References: <BAY8-F49WPXBemybNxv0006cb72@hotmail.com>
Message-ID: <200402050958.18742.deepayan@stat.wisc.edu>

On Wednesday 04 February 2004 04:03, Umberto Maggiore wrote:
> Using data from a multicenter study with a parallel-group design comparing
> two treatments, I plotted each subject's time change of X after stratifying
> for center:
>
> xyplot(X ~ time | center, type="l", panel=panel.superpose, groups=subject)
>
> Now I want these lines to take different colours according to the variable
> "treatment". Any help?

Umm, you should already have lines colored differently by different 
'subject's. Do you want to further differentiate by treatment ? 

If that's so, there's probably no good way. You could try creating a new 
factor combining subject and treatment and use that as the groups argument, 
e.g.,

factor(paste(as.character(subject), as.character(treatment), sep = "/"))

Deepayan



From Maarten.van.der.Hoeven at knmi.nl  Thu Feb  5 17:09:52 2004
From: Maarten.van.der.Hoeven at knmi.nl (Hoeven, Maarten van der)
Date: Thu, 5 Feb 2004 17:09:52 +0100
Subject: [R] Available in S-plus, also in R1.8.1?
Message-ID: <1F8990C21AC73945BE6AAC5AD6D4CAE906404A@BCSXAC.knmi.nl>

Hello all,

I'm looking for the R-equivalent of the S-option "Connect type: half
horiz first". Link:
http://miner.stern.nyu.edu/Splus/help/guihelp/__hhelp/connect_type.htm

I'm plotting with type="s" or type="S"; this is giving me a stairstep
starting, or ending with the value on the x-axis (as documented). But, I
want the x-value in the middle of the step, like "half horiz first" in
S-plus does.

Is this possible in R?


Thanks,
Maarten
--------------------------------------------------------------
Zie ook/see also: http://www.knmi.nl/maildisclaimer.html



From macq at llnl.gov  Thu Feb  5 17:10:33 2004
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 5 Feb 2004 08:10:33 -0800
Subject: [R] Installing odesolve under MacOSX
In-Reply-To: <BC480C44.1CC8%M.E.J.Raijmakers@uva.nl>
References: <BC480C44.1CC8%M.E.J.Raijmakers@uva.nl>
Message-ID: <p06002000bc481736bf01@[128.115.153.6]>

I realize this may not be the most helpful, because I have R 1.8.1 
installed from source code, not RAqua. Nonetheless, odesolve appears 
to install successfully, albeit with some warning messages about 
multiple symbol definitions. OS X 10.2.8.    Were there *no* other 
error messages?

-Don

>  version
          _                       
platform powerpc-apple-darwin6.8.5
arch     powerpc                 
os       darwin6.8.5             
system   powerpc, darwin6.8.5    
status   Patched                 
major    1                       
minor    8.1                     
year     2004                    
month    01                      
day      12                      
language R                       


>  install.packages('odesolve')
trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 156465 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
..
downloaded 152Kb

trying URL `http://cran.r-project.org/src/contrib/odesolve_0.5-8.tar.gz'
Content type `application/x-tar' length 71163 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .........
downloaded 69Kb

* Installing *source* package 'odesolve' ...
** libs
g77   -fno-common  -g -O2 -c bnorm.f -o bnorm.o
gcc -no-cpp-precomp -I/Users/macq/darwin.apps/R/R-1.8.1/build/include 
-I/sw/include   -fno-common  -I/sw/include -c call_lsoda.c -o 
call_lsoda.o
g77   -fno-common  -g -O2 -c cfode.f -o cfode.o
g77   -fno-common  -g -O2 -c dgbfa.f -o dgbfa.o
g77   -fno-common  -g -O2 -c dgbsl.f -o dgbsl.o
g77   -fno-common  -g -O2 -c dgefa.f -o dgefa.o
g77   -fno-common  -g -O2 -c dgesl.f -o dgesl.o
g77   -fno-common  -g -O2 -c ewset.f -o ewset.o
g77   -fno-common  -g -O2 -c fdump.f -o fdump.o
g77   -fno-common  -g -O2 -c fnorm.f -o fnorm.o
g77   -fno-common  -g -O2 -c i1mach.f -o i1mach.o
g77   -fno-common  -g -O2 -c intdy.f -o intdy.o
g77   -fno-common  -g -O2 -c j4save.f -o j4save.o
g77   -fno-common  -g -O2 -c lsoda.f -o lsoda.o
gcc -no-cpp-precomp -I/Users/macq/darwin.apps/R/R-1.8.1/build/include 
-I/sw/include   -fno-common  -I/sw/include -c odesolve_utils.c -o 
odesolve_utils.o
g77   -fno-common  -g -O2 -c prja.f -o prja.o
g77   -fno-common  -g -O2 -c solsy.f -o solsy.o
g77   -fno-common  -g -O2 -c stoda.f -o stoda.o
g77   -fno-common  -g -O2 -c vmnorm.f -o vmnorm.o
g77   -fno-common  -g -O2 -c xercnt.f -o xercnt.o
g77   -fno-common  -g -O2 -c xerrwv.f -o xerrwv.o
g77   -fno-common  -g -O2 -c xsetf.f -o xsetf.o
gcc -bundle -flat_namespace -undefined suppress -L/sw/lib -o 
odesolve.so bnorm.o call_lsoda.o cfode.o dgbfa.o dgbsl.o dgefa.o 
dgesl.o ewset.o fdump.o fnorm.o i1mach.o intdy.o j4save.o lsoda.o 
odesolve_utils.o prja.o solsy.o stoda.o vmnorm.o xercnt.o xerrwv.o 
xsetf.o -framework vecLib -L/sw/lib 
-L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4 
-L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/../../.. -lfrtbegin 
-lg2c -lSystem -lcc_dynamic 
-L/Users/macq/darwin.apps/R/R-1.8.1/build/bin -lR
ld: warning multiple definitions of symbol _xerbla_
/System/Library/Frameworks/vecLib.framework/vecLib(ProjectBuilderMasterObjectFile.o) 
definition of _xerbla_
/Users/macq/darwin.apps/R/R-1.8.1/build/bin/libR.dylib(print.lo) 
definition of _xerbla_
ld: warning multiple definitions of symbol _i1mach_
i1mach.o definition of _i1mach_ in section (__TEXT,__text)
/Users/macq/darwin.apps/R/R-1.8.1/build/bin/libR.dylib(i1mach.lo) 
definition of _i1mach_
ld: warning multiple definitions of symbol _BC
/sw/lib/libreadline.4.dylib(terminal.so) definition of _BC
/sw/lib/libncurses.5.dylib(lib_termcap.lo) definition of _BC
ld: warning multiple definitions of symbol _UP
/sw/lib/libreadline.4.dylib(terminal.so) definition of _UP
/sw/lib/libncurses.5.dylib(lib_termcap.lo) definition of _UP
ld: warning multiple definitions of symbol _PC
/sw/lib/libreadline.4.dylib(terminal.so) definition of _PC
/sw/lib/libncurses.5.dylib(lib_tputs.lo) definition of _PC
** R
** data
** demo
** inst
** help
  >>> Building/Updating help pages for package 'odesolve'
      Formats: text html latex example
   ccl4data                          text    html    latex   example
   ccl4data.avg                      text    html    latex   example
   lsoda                             text    html    latex   example
   rk4                               text    html    latex   example
* DONE (odesolve)

Delete downloaded files (y/N)? y

>   example('lsoda','odesolve')

## followed by various output and some graphs

At 3:05 PM +0100 2/5/04, Maartje Raijmakers wrote:
>Installing odesolve in Raqua 1.8.0 or 1.8.1 under MacOSX gives the following
>message:
>
>Warning message: Installation of package odesolve had non-zero exit status
>in: install.packages(ui.pkgs, CRAN = getOption(where), lib = .libPaths()[1])
>
>Moreover, in the source of odesolve is no makefile.
>
>Does anyone know how to get a proper installation?
>
>
>Maartje
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From giampi at speech.kth.se  Thu Feb  5 17:29:54 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Thu, 5 Feb 2004 17:29:54 +0100 (CET)
Subject: [R] multiple plots in different windows
In-Reply-To: <65F6E1EC64DCA6489800C09A2007FC6E181720@cememail1.nioo.int>
References: <65F6E1EC64DCA6489800C09A2007FC6E181720@cememail1.nioo.int>
Message-ID: <Pine.LNX.4.58.0402051701380.23202@bayes.speech.kth.se>

Hi all,
I'd like to generate a number of plots to compare different
vectors I have stored in a list. To do this I do something like
(in a linux system):

for(i in 1:L) {
 X11()
 plot(listOfFunctions[[i]])
}

First question is: is this the right way to create several plots (in
different windows) ?
Second question: what are the corresponding commands for the matlab
'figure(n)' to activate a certain figure and 'close(1:n)' to close
several figures at once?

Thank you,
Giampiero



From giampi at speech.kth.se  Thu Feb  5 18:15:22 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Thu, 5 Feb 2004 18:15:22 +0100 (CET)
Subject: [R] Re: multiple plots in different windows
In-Reply-To: <Pine.LNX.4.58.0402051701380.23202@bayes.speech.kth.se>
References: <65F6E1EC64DCA6489800C09A2007FC6E181720@cememail1.nioo.int>
	<Pine.LNX.4.58.0402051701380.23202@bayes.speech.kth.se>
Message-ID: <Pine.LNX.4.58.0402051814010.23202@bayes.speech.kth.se>

Don't need to answer to my previous post: I found the functions in the
meantime:

     dev.cur()
     dev.list()
     dev.next(which = dev.cur())
     dev.prev(which = dev.cur())
     dev.off(which = dev.cur())
     dev.set(which = dev.next())
     graphics.off()

Thanks anyway,
Giampiero

On Thu, 5 Feb 2004, Giampiero Salvi wrote:

> Hi all,
> I'd like to generate a number of plots to compare different
> vectors I have stored in a list. To do this I do something like
> (in a linux system):
>
> for(i in 1:L) {
>  X11()
>  plot(listOfFunctions[[i]])
> }
>
> First question is: is this the right way to create several plots (in
> different windows) ?
> Second question: what are the corresponding commands for the matlab
> 'figure(n)' to activate a certain figure and 'close(1:n)' to close
> several figures at once?
>
> Thank you,
> Giampiero
>



From bates at stat.wisc.edu  Thu Feb  5 18:14:54 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 05 Feb 2004 11:14:54 -0600
Subject: [R] Multilevel in R
In-Reply-To: <004201c3ebfb$6ddcee60$9a111d97@consentino>
References: <004201c3ebfb$6ddcee60$9a111d97@consentino>
Message-ID: <6r65elsb1t.fsf@bates4.stat.wisc.edu>

"Fabrizio Consentino" <consentino at infinito.it> writes:

> Hello, 
> 
> I have difficulties to deal with multilevel model. My dataset is composed 
> of 10910 observations, 1237 plants nested within 17 stations. The data set is not 
> balanced. Response variable is binary and repeated.
> 
> I tried to fit this model
> 
> model<- glmmPQL( y ~ z1.lon*lun + z2.lat*lun + z1.lon*lar + z2.lat*lar + z1.lon*sca + z2.lat*sca +z1.lon*eta + z2.lat*eta,
>  random = ~ lun + lar + sca + eta | sta/piante, family=binomial, data=variabili)
> 
> where  y is presence (1) or absence (0) of a flowering
> 
> lun, lar, sca, eta are level 1 variables
> 
> z1.lon, z2.lat are level 2 variables.
> 
> but during third iteration it stop because there is a singular matrix in solve.
> 
> I stopped it after two iterations, however the results are not correct.
> 
> How can I fit this data? Are there other functions that I can use?
> 
> I would be thankfull for all the insights.

Start with a simpler model.  Try random = ~ 1 | sta/piante and see if
that converges.

You could also try function GLMM from the lme4 package.

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From Jesus.Frias at dit.ie  Thu Feb  5 19:04:49 2004
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Thu, 05 Feb 2004 18:04:49 +0000
Subject: [R] Savitzky-Golay smoothing for reflectance data
In-Reply-To: <65F6E1EC64DCA6489800C09A2007FC6E181720@cememail1.nioo.int>
Message-ID: <LGECJJCANFBOOHCMGPJEMEGGCPAA.Jesus.Frias@dit.ie>

Hi,
	Quote:

	"The Savitzky-Golay smoothing turns out to be exactly equivalent to fitting
data to a polynomial as described" (Skoog, Holler and Nieman, Principles of
Instrumental Analysis, pp 111)

	While R is not a tool for instrumental analysis, I am sure you can find
smoothing methods that will suit your problem in R (there are plenty of
them). There is a thread on this topic on this from March 2003 where Andy
Liaw points to the KernSmooth package.

http://maths.newcastle.edu.au/~rking/R/help/03a/2995.html

all the best,

Jesus

--------------------------------------------------------------
Jes?s Mar?a Fr?as Celayeta
School of Food Sci. and Env. Health.
Faculty of Tourism and Food
Dublin Institute of Technology
Cathal Brugha St., Dublin 1. Ireland
Phone: +353 1 4024459 Fax: +353 1 4024495
http://www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Andersson, Henrik
> Sent: 05 February 2004 15:13
> To: r-help at stat.math.ethz.ch
> Subject: [R] Savitzky-Golay smoothing for reflectance data
>
>
> I got a question from a fellow PhD student that work with spectrum
> analysis in Excel and now he has lots of spectrums that needs to be
> smoothed, which would be nice to be able to do in batch.
>
> Is there an R package that can do:
>
> Savitzky-Golay smoothing for reflectance spectral data
>
> or a function that does something similar.
>
> _______________________________________
> Henrik Andersson
> Netherlands Insitute of Ecology
> h.andersson at nioo.knaw.nl
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

--
This message has been scanned for content and
viruses by the DIT Information Services MailScanner
Service, and is believed to be clean.
http://www.dit.ie


-- 
This message has been scanned for content and 
viruses by the DIT Information Services MailScanner 
Service, and is believed to be clean.
http://www.dit.ie



From svetlana.eden at vanderbilt.edu  Thu Feb  5 19:15:26 2004
From: svetlana.eden at vanderbilt.edu (Svetlana Eden)
Date: Thu, 5 Feb 2004 12:15:26 -0600
Subject: [R] What is the correct way of using function C() for factors:
Message-ID: <20040205121526.4d3f9662.svetlana.eden@vanderbilt.edu>


The funciton c() works differently for strings and for factors:


For strings:

> l = c('a', 'b')
> l
[1] "a" "b"


For factors:

> l = c(factor('a'), factor('b'))
> l
[1] 1 1


What should be the right technique for merging factors?




-- 
Svetlana Eden        Biostatistician II            School of Medicine
                     Department of Biostatistics   Vanderbilt University



From cmoffet at nwrc.ars.usda.gov  Thu Feb  5 19:33:35 2004
From: cmoffet at nwrc.ars.usda.gov (Corey Moffet)
Date: Thu, 05 Feb 2004 11:33:35 -0700
Subject: [R] What is the correct way of using function C() for
  factors:
In-Reply-To: <20040205121526.4d3f9662.svetlana.eden@vanderbilt.edu>
Message-ID: <3.0.6.32.20040205113335.010620b0@nwrc.ars.usda.gov>

try:

l <- factor(c('a','b'))
l

At 12:15 PM 2/5/2004 -0600, Svetlana Eden wrote:
>
>The funciton c() works differently for strings and for factors:
>
>
>For strings:
>
>> l = c('a', 'b')
>> l
>[1] "a" "b"
>
>
>For factors:
>
>> l = c(factor('a'), factor('b'))
>> l
>[1] 1 1
>
>
>What should be the right technique for merging factors?
>
>
>
>
>-- 
>Svetlana Eden        Biostatistician II            School of Medicine
>                     Department of Biostatistics   Vanderbilt University
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Rangeland Scientist

USDA-ARS
Northwest Watershed Research Center
800 Park Blvd, Plaza IV, Suite 105
Boise, ID 83712-7716

Voice: (208) 422-0718
FAX:   (208) 334-1502



From spencer.graves at pdf.com  Thu Feb  5 19:56:14 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 05 Feb 2004 10:56:14 -0800
Subject: [R] What is the correct way of using function C() for  factors:
In-Reply-To: <3.0.6.32.20040205113335.010620b0@nwrc.ars.usda.gov>
References: <3.0.6.32.20040205113335.010620b0@nwrc.ars.usda.gov>
Message-ID: <402291CE.3090402@pdf.com>

      To combine objects that are already factors, the solution I've 
found is to first coerce them to mode character: 

 > F1 <- factor("a")
 > F2 <- factor("b")
 > factor(c(as.character(F1), as.character(F2)))
[1] a b
Levels: a b

      hope this helps. 
      spencer graves

Corey Moffet wrote:

>try:
>
>l <- factor(c('a','b'))
>l
>
>At 12:15 PM 2/5/2004 -0600, Svetlana Eden wrote:
>  
>
>>The funciton c() works differently for strings and for factors:
>>
>>
>>For strings:
>>
>>    
>>
>>>l = c('a', 'b')
>>>l
>>>      
>>>
>>[1] "a" "b"
>>
>>
>>For factors:
>>
>>    
>>
>>>l = c(factor('a'), factor('b'))
>>>l
>>>      
>>>
>>[1] 1 1
>>
>>
>>What should be the right technique for merging factors?
>>
>>
>>
>>
>>-- 
>>Svetlana Eden        Biostatistician II            School of Medicine
>>                    Department of Biostatistics   Vanderbilt University
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>    
>>
>With best wishes and kind regards I am
>
>Sincerely,
>
>Corey A. Moffet
>Rangeland Scientist
>
>USDA-ARS
>Northwest Watershed Research Center
>800 Park Blvd, Plaza IV, Suite 105
>Boise, ID 83712-7716
>
>Voice: (208) 422-0718
>FAX:   (208) 334-1502
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From bjz9 at cdc.gov  Thu Feb  5 20:19:20 2004
From: bjz9 at cdc.gov (Shoultz, Gerald)
Date: Thu, 5 Feb 2004 14:19:20 -0500
Subject: [R] I am totally lost on how to install R . . .
Message-ID: <8A4148E4383C434980BE3D08AE2436921C55A9@m-nchs-1.nchs.cdc.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040205/65cdd803/attachment.pl

From ripley at stats.ox.ac.uk  Thu Feb  5 20:45:29 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Feb 2004 19:45:29 +0000 (GMT)
Subject: [R] What is the correct way of using function C() for  factors:
In-Reply-To: <3.0.6.32.20040205113335.010620b0@nwrc.ars.usda.gov>
Message-ID: <Pine.LNX.4.44.0402051944070.1461-100000@gannet.stats>

Did you mean the function c() or the function(C)?  They are not the same 
thing!

Also,  R does not have `strings' but it does have character vectors.

On Thu, 5 Feb 2004, Corey Moffet wrote:

> try:
> 
> l <- factor(c('a','b'))
> l
> 
> At 12:15 PM 2/5/2004 -0600, Svetlana Eden wrote:
> >
> >The funciton c() works differently for strings and for factors:
> >
> >
> >For strings:
> >
> >> l = c('a', 'b')
> >> l
> >[1] "a" "b"
> >
> >
> >For factors:
> >
> >> l = c(factor('a'), factor('b'))
> >> l
> >[1] 1 1
> >
> >
> >What should be the right technique for merging factors?
> >
> >
> >
> >
> >-- 
> >Svetlana Eden        Biostatistician II            School of Medicine
> >                     Department of Biostatistics   Vanderbilt University
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> With best wishes and kind regards I am
> 
> Sincerely,
> 
> Corey A. Moffet
> Rangeland Scientist
> 
> USDA-ARS
> Northwest Watershed Research Center
> 800 Park Blvd, Plaza IV, Suite 105
> Boise, ID 83712-7716
> 
> Voice: (208) 422-0718
> FAX:   (208) 334-1502
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From svetlana.eden at vanderbilt.edu  Thu Feb  5 20:51:27 2004
From: svetlana.eden at vanderbilt.edu (Svetlana Eden)
Date: Thu, 5 Feb 2004 13:51:27 -0600
Subject: [R] What is the correct way to merge factors?
In-Reply-To: <3.0.6.32.20040205113335.010620b0@nwrc.ars.usda.gov>
References: <20040205121526.4d3f9662.svetlana.eden@vanderbilt.edu>
	<3.0.6.32.20040205113335.010620b0@nwrc.ars.usda.gov>
Message-ID: <20040205135127.6252410c.svetlana.eden@vanderbilt.edu>

I have two factors l1, l2, and I'd like to merge them.
Function c() does not give me the result I want:

> l1 = factor(c('a', 'b'))
> l2 = factor(c('c', 'd'))
> lMerge = c(l1, l2)
> lMerge
[1] 1 2 1 2
>

I'd like to merge l1 and l2 and to get lMerge 
----------------------------------------------

[1] a b c d
Levels: a b c d

instead of 
----------

[1] 1 2 1 2
>

How should I do that?
---------------------

-- 
Svetlana Eden        Biostatistician II            School of Medicine
                     Department of Biostatistics   Vanderbilt University



From umberto_maggiore at hotmail.com  Thu Feb  5 20:52:40 2004
From: umberto_maggiore at hotmail.com (Umberto Maggiore)
Date: Thu, 05 Feb 2004 19:52:40 +0000
Subject: [R] xyplot (lattice): colours of lines
Message-ID: <BAY8-F82kNO4gZZu9Zv00040759@hotmail.com>

It works. However, now I get another odd result: in some plots there are
straight lines connecting the end of a line with the beginning of another 
one.

On Wednesday 04 February 2004 04:03, Umberto Maggiore wrote:
>Using data from a multicenter study with a parallel-group design comparing
>two treatments, I plotted each subject's time change of X after stratifying
>for center:
>
>xyplot(X ~ time | center, type="l", panel=panel.superpose, groups=subject)
>
>Now I want these lines to take different colours according to the variable
>"treatment". Any help?

Umm, you should already have lines colored differently by different
'subject's. Do you want to further differentiate by treatment ?

If that's so, there's probably no good way. You could try creating a new
factor combining subject and treatment and use that as the groups argument,
e.g.,

factor(paste(as.character(subject), as.character(treatment), sep = "/"))

Deepayan



From k.wang at auckland.ac.nz  Thu Feb  5 21:02:32 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 6 Feb 2004 09:02:32 +1300
Subject: [R] I am totally lost on how to install R . . .
In-Reply-To: <8A4148E4383C434980BE3D08AE2436921C55A9@m-nchs-1.nchs.cdc.gov>
Message-ID: <20040205200255.UWWY11548.web3-rme.xtra.co.nz@kevinlpt>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shoultz, Gerald
> Sent: Friday, February 06, 2004 8:19 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] I am totally lost on how to install R . . .
>
> Second, I am trying to install R on windows XP.  In looking at the
> instruction manual I get the following:
>
> The simplest way is to use 'rw1081.exe' or 'miniR.exe'. Just
> double-click on the icon
> and follow the instructions. If you installed R this way you can
> uninstall it from the Control Panel.
>
> How do I get the "rw1081.exe" or "miniR.exe"?  All I have right now is
> the R-latest.tgz file and I have absolutely NO idea on how to open or
> use that.  Could someone point me to a clear, step-by-step method for
> installing R on my computer?  Please advise; you may write me directly
> if you like.

Which part of the manual were you looking at?  I am assuming you meant the
R for Windows FAQ, in which case, the section before "How do I install R
for Windows" tells you where to get it!  Take a look at
http://cran.r-project.org/bin/windows/rw-FAQ.html#Where%20can%20I%20find%20
the%20latest%20version%3f

HTH

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
SLC Stats Workshops Co-ordinator
The University of Auckland
New Zealand



From bjz9 at cdc.gov  Thu Feb  5 21:03:13 2004
From: bjz9 at cdc.gov (Shoultz, Gerald)
Date: Thu, 5 Feb 2004 15:03:13 -0500
Subject: [R] Thanks for help
Message-ID: <8A4148E4383C434980BE3D08AE2436921F8637@m-nchs-1.nchs.cdc.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040205/81ace625/attachment.pl

From svetlana.eden at vanderbilt.edu  Thu Feb  5 21:11:56 2004
From: svetlana.eden at vanderbilt.edu (Svetlana Eden)
Date: Thu, 5 Feb 2004 14:11:56 -0600
Subject: [R] correction to the previously asked question (about merging
	factors)
Message-ID: <20040205141156.372939dc.svetlana.eden@vanderbilt.edu>


I have two factors l1, l2, and I'd like to merge them.

(Remark:       The factors can not be converted to charaters)

Function c() does not give me the result I want:


> l1 = factor(c('aaaa', 'bbbb'))
> l2 = factor(c('ccc', 'dd'))
> lMerge = factor(c(l1, l2))
> lMerge
[1] 1 2 1 2
Levels: 1 2
>
I'd like to merge l1 and l2 and to get lMerge 
----------------------------------------------

[1] aaaa bbbb ccc dd
Levels: aaaa bbbb ccc dd

instead of 
----------

[1] 1 2 1 2
Levels: 1 2
>

How should I do that without converting the factors back to strings.
-------------------------------------------------------------------

-- 
Svetlana Eden        Biostatistician II            School of Medicine
                     Department of Biostatistics   Vanderbilt University


















-- 
Svetlana Eden        Biostatistician II            School of Medicine
                     Department of Biostatistics   Vanderbilt University



From andy_liaw at merck.com  Thu Feb  5 21:22:45 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 5 Feb 2004 15:22:45 -0500
Subject: [R] What is the correct way to merge factors?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7736@usrymx25.merck.com>

You can do:

  factor(c(as.character(l1), as.character(l2)))

HTH,
Andy

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Svetlana Eden
> Sent: Thursday, February 05, 2004 2:51 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] What is the correct way to merge factors?
> 
> 
> I have two factors l1, l2, and I'd like to merge them.
> Function c() does not give me the result I want:
> 
> > l1 = factor(c('a', 'b'))
> > l2 = factor(c('c', 'd'))
> > lMerge = c(l1, l2)
> > lMerge
> [1] 1 2 1 2
> >
> 
> I'd like to merge l1 and l2 and to get lMerge 
> ----------------------------------------------
> 
> [1] a b c d
> Levels: a b c d
> 
> instead of 
> ----------
> 
> [1] 1 2 1 2
> >
> 
> How should I do that?
> ---------------------
> 
> -- 
> Svetlana Eden        Biostatistician II            School of Medicine
>                      Department of Biostatistics   Vanderbilt 
> University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From spencer.graves at pdf.com  Thu Feb  5 21:44:04 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 05 Feb 2004 12:44:04 -0800
Subject: [R] correction to the previously asked question (about merging
	factors)
In-Reply-To: <20040205141156.372939dc.svetlana.eden@vanderbilt.edu>
References: <20040205141156.372939dc.svetlana.eden@vanderbilt.edu>
Message-ID: <4022AB14.80308@pdf.com>

      What about the following: 

 > F1 <- factor(c("b", "a"))
 > F2 <- factor(c("c", "b"))
 > k1 <- length(F1)
 > k2 <- length(F2)
 > F12.lvls <- unique(c(levels(F1), levels(F2)))
 > F. <- factor(rep(F12.lvls[1], k1+k1), levels=F12.lvls)
 > F.[1:k1] <- F1
 > F.[-(1:k1)] <- F2
 > F.
[1] b a c b
Levels: a b c

      This saves converting the factors to characters, which might save 
computer time at the expense of your time. 
      hope this helps. 
      spencer graves

Svetlana Eden wrote:

>I have two factors l1, l2, and I'd like to merge them.
>
>(Remark:       The factors can not be converted to charaters)
>
>Function c() does not give me the result I want:
>
>
>  
>
>>l1 = factor(c('aaaa', 'bbbb'))
>>l2 = factor(c('ccc', 'dd'))
>>lMerge = factor(c(l1, l2))
>>lMerge
>>    
>>
>[1] 1 2 1 2
>Levels: 1 2
>  
>
>I'd like to merge l1 and l2 and to get lMerge 
>----------------------------------------------
>
>[1] aaaa bbbb ccc dd
>Levels: aaaa bbbb ccc dd
>
>instead of 
>----------
>
>[1] 1 2 1 2
>Levels: 1 2
>  
>
>
>How should I do that without converting the factors back to strings.
>-------------------------------------------------------------------
>
>  
>



From DJNordlund at aol.com  Thu Feb  5 21:55:35 2004
From: DJNordlund at aol.com (DJNordlund@aol.com)
Date: Thu, 5 Feb 2004 15:55:35 EST
Subject: [R] correction to the previously asked question (about merging
	factors)
Message-ID: <1d2.1901b925.2d5407c7@aol.com>

>In a message dated 2/5/2004 12:25:01 PM Pacific Standard Time, 
>svetlana.eden at vanderbilt.edu writes:
>I have two factors l1, l2, and I'd like to merge them.
>
>(Remark:       The factors can not be converted to charaters)
>
>Function c() does not give me the result I want:
>
>
>> l1 = factor(c('aaaa', 'bbbb'))
>> l2 = factor(c('ccc', 'dd'))
>> lMerge = factor(c(l1, l2))
>> lMerge
>[1] 1 2 1 2
>Levels: 1 2
>
>I'd like to merge l1 and l2 and to get lMerge 
>----------------------------------------------
>
>[1] aaaa bbbb ccc dd
>Levels: aaaa bbbb ccc dd

How about something like:

     IMerge<- factor(c(as.character(I1),as.character(I2)))

Dan Nodlund



From sundar.dorai-raj at pdf.com  Thu Feb  5 21:58:39 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 05 Feb 2004 14:58:39 -0600
Subject: [R] correction to the previously asked question (about merging
	factors)
In-Reply-To: <4022AB14.80308@pdf.com>
References: <20040205141156.372939dc.svetlana.eden@vanderbilt.edu>
	<4022AB14.80308@pdf.com>
Message-ID: <4022AE7F.4070301@pdf.com>

How about simply

F1 <- factor(c("b", "a"))
F2 <- factor(c("c", "b"))
F3 <- factor(c(levels(F1)[F1], levels(F2)[F2]))

-sundar

Spencer Graves wrote:

>      What about the following:
>  > F1 <- factor(c("b", "a"))
>  > F2 <- factor(c("c", "b"))
>  > k1 <- length(F1)
>  > k2 <- length(F2)
>  > F12.lvls <- unique(c(levels(F1), levels(F2)))
>  > F. <- factor(rep(F12.lvls[1], k1+k1), levels=F12.lvls)
>  > F.[1:k1] <- F1
>  > F.[-(1:k1)] <- F2
>  > F.
> [1] b a c b
> Levels: a b c
> 
>      This saves converting the factors to characters, which might save 
> computer time at the expense of your time.      hope this helps.      
> spencer graves
> 
> Svetlana Eden wrote:
> 
>> I have two factors l1, l2, and I'd like to merge them.
>>
>> (Remark:       The factors can not be converted to charaters)
>>
>> Function c() does not give me the result I want:
>>
>>
>>  
>>
>>> l1 = factor(c('aaaa', 'bbbb'))
>>> l2 = factor(c('ccc', 'dd'))
>>> lMerge = factor(c(l1, l2))
>>> lMerge
>>>   
>>
>> [1] 1 2 1 2
>> Levels: 1 2
>>  
>>
>> I'd like to merge l1 and l2 and to get lMerge 
>> ----------------------------------------------
>>
>> [1] aaaa bbbb ccc dd
>> Levels: aaaa bbbb ccc dd
>>
>> instead of ----------
>>
>> [1] 1 2 1 2
>> Levels: 1 2
>>  
>>
>>
>> How should I do that without converting the factors back to strings.
>> -------------------------------------------------------------------
>>
>>  
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From deepayan at stat.wisc.edu  Thu Feb  5 22:08:49 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 5 Feb 2004 15:08:49 -0600
Subject: [R] xyplot (lattice): colours of lines
In-Reply-To: <BAY8-F82kNO4gZZu9Zv00040759@hotmail.com>
References: <BAY8-F82kNO4gZZu9Zv00040759@hotmail.com>
Message-ID: <200402051508.50224.deepayan@stat.wisc.edu>


I would need a real example to figure this out. Could you send me your data as 
an rda file (saved using save() and your code ? (No guarantees as to how fast 
I can reply, though. I'm somewhat busy with other things.)

On Thursday 05 February 2004 01:52 pm, Umberto Maggiore wrote:
> It works. However, now I get another odd result: in some plots there are
> straight lines connecting the end of a line with the beginning of another
> one.
>
> On Wednesday 04 February 2004 04:03, Umberto Maggiore wrote:
> >Using data from a multicenter study with a parallel-group design comparing
> >two treatments, I plotted each subject's time change of X after
> > stratifying for center:
> >
> >xyplot(X ~ time | center, type="l", panel=panel.superpose, groups=subject)
> >
> >Now I want these lines to take different colours according to the variable
> >"treatment". Any help?
>
> Umm, you should already have lines colored differently by different
> 'subject's. Do you want to further differentiate by treatment ?
>
> If that's so, there's probably no good way. You could try creating a new
> factor combining subject and treatment and use that as the groups argument,
> e.g.,
>
> factor(paste(as.character(subject), as.character(treatment), sep = "/"))
>
> Deepayan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Thu Feb  5 22:13:39 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 05 Feb 2004 13:13:39 -0800
Subject: [R] correction to the previously asked question (about merging
	factors)
In-Reply-To: <4022AE7F.4070301@pdf.com>
References: <20040205141156.372939dc.svetlana.eden@vanderbilt.edu>
	<4022AB14.80308@pdf.com> <4022AE7F.4070301@pdf.com>
Message-ID: <4022B203.1040309@pdf.com>

      Sundar:  Your solution is not only more elegant than mine, it's 
also faster, at least with this tiny example: 

 > start.time <- proc.time()
 > k1 <- length(F1)
 > k2 <- length(F2)
 > F12.lvls <- unique(c(levels(F1), levels(F2)))
 > F. <- factor(rep(F12.lvls[1], k1+k1), levels=F12.lvls)
 > F.[1:k1] <- F1
 > F.[-(1:k1)] <- F2
 > proc.time()-start.time
[1] 0.00 0.00 0.42   NA   NA
 >
 > start.time <- proc.time()
 > F1 <- factor(c("b", "a"))
 > F2 <- factor(c("c", "b"))
 > F3 <- factor(c(levels(F1)[F1], levels(F2)[F2]))
 > proc.time()-start.time
[1] 0.00 0.00 0.24   NA   NA
 >
      With longer vectors, mine may be faster -- but yours is still more 
elegant. 

      Best Wishes,
      spencer graves

Sundar Dorai-Raj wrote:

> How about simply
>
> F1 <- factor(c("b", "a"))
> F2 <- factor(c("c", "b"))
> F3 <- factor(c(levels(F1)[F1], levels(F2)[F2]))
>
> -sundar
>
> Spencer Graves wrote:
>
>>      What about the following:
>>  > F1 <- factor(c("b", "a"))
>>  > F2 <- factor(c("c", "b"))
>>  > k1 <- length(F1)
>>  > k2 <- length(F2)
>>  > F12.lvls <- unique(c(levels(F1), levels(F2)))
>>  > F. <- factor(rep(F12.lvls[1], k1+k1), levels=F12.lvls)
>>  > F.[1:k1] <- F1
>>  > F.[-(1:k1)] <- F2
>>  > F.
>> [1] b a c b
>> Levels: a b c
>>
>>      This saves converting the factors to characters, which might 
>> save computer time at the expense of your time.      hope this 
>> helps.      spencer graves
>>
>> Svetlana Eden wrote:
>>
>>> I have two factors l1, l2, and I'd like to merge them.
>>>
>>> (Remark:       The factors can not be converted to charaters)
>>>
>>> Function c() does not give me the result I want:
>>>
>>>
>>>  
>>>
>>>> l1 = factor(c('aaaa', 'bbbb'))
>>>> l2 = factor(c('ccc', 'dd'))
>>>> lMerge = factor(c(l1, l2))
>>>> lMerge
>>>>   
>>>
>>>
>>> [1] 1 2 1 2
>>> Levels: 1 2
>>>  
>>>
>>> I'd like to merge l1 and l2 and to get lMerge 
>>> ----------------------------------------------
>>>
>>> [1] aaaa bbbb ccc dd
>>> Levels: aaaa bbbb ccc dd
>>>
>>> instead of ----------
>>>
>>> [1] 1 2 1 2
>>> Levels: 1 2
>>>  
>>>
>>>
>>> How should I do that without converting the factors back to strings.
>>> -------------------------------------------------------------------
>>>
>>>  
>>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>



From andy_liaw at merck.com  Thu Feb  5 22:32:43 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 5 Feb 2004 16:32:43 -0500
Subject: [R] correction to the previously asked question (about
	mergin g factors)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF773A@usrymx25.merck.com>

First of all, I do not understand why conversion to characters are not
allowed.  That's what Sundar's solution is doing implicitly (but more
elegantly).

Here's a test of all three.  See the function definitions below.

> f1 <- factor(sample(letters[1:3], 1e4, replace=TRUE))
> f2 <- factor(sample(letters[3:5], 1e4, replace=TRUE))
> f3 <- factor(sample(letters[5:7], 1e4, replace=TRUE))
> 
> system.time(for (i in 1:1e2) mf <- mergeFac(f1, f2, f3))
[1] 4.54 0.00 4.73   NA   NA
> system.time(for (i in 1:1e2) mf2 <- mergeFac2(f1, f2, f3))
[1] 3.95 0.01 4.11   NA   NA
> system.time(for (i in 1:1e2) mf3 <- mergeFac3(f1, f2, f3))
[1] 3.61 0.00 3.76   NA   NA
> all(mf == mf2)
[1] TRUE
> all(mf == mf3)
[1] TRUE

First, my attempt at generalizing Spencer's suggestion:

mergeFac <- function(...) {
  l <- list(...)
  len <- sapply(l, length)
  lev <- unique(unlist(lapply(l, levels)))
  ans <- factor(rep(lev[1], sum(len)), levels=lev)
  idx.end <- cumsum(len)
  idx.start <- c(1, idx.end[-length(len)] + 1)
  for (i in seq(along=l)) {
    ans[idx.start[i]:idx.end[i]] <- l[[i]]
  }
  ans
}

Then explicit coercion to characters:

mergeFac2 <- function(...) {
  l <- list(...)
  factor(unlist(lapply(l, as.character)))
}

Then Sundar's solution:
mergeFac3 <- function(...) {
  l <- list(...)
  factor(do.call("c", lapply(l, function(x) levels(x)[x])))
}

Cheers,
Andy


> From: Sundar Dorai-Raj
> 
> How about simply
> 
> F1 <- factor(c("b", "a"))
> F2 <- factor(c("c", "b"))
> F3 <- factor(c(levels(F1)[F1], levels(F2)[F2]))
> 
> -sundar
> 
> Spencer Graves wrote:
> 
> >      What about the following:
> >  > F1 <- factor(c("b", "a"))
> >  > F2 <- factor(c("c", "b"))
> >  > k1 <- length(F1)
> >  > k2 <- length(F2)
> >  > F12.lvls <- unique(c(levels(F1), levels(F2)))
> >  > F. <- factor(rep(F12.lvls[1], k1+k1), levels=F12.lvls)
> >  > F.[1:k1] <- F1
> >  > F.[-(1:k1)] <- F2
> >  > F.
> > [1] b a c b
> > Levels: a b c
> > 
> >      This saves converting the factors to characters, which 
> might save 
> > computer time at the expense of your time.      hope this 
> helps.      
> > spencer graves
> > 
> > Svetlana Eden wrote:
> > 
> >> I have two factors l1, l2, and I'd like to merge them.
> >>
> >> (Remark:       The factors can not be converted to charaters)
> >>
> >> Function c() does not give me the result I want:
> >>
> >>
> >>  
> >>
> >>> l1 = factor(c('aaaa', 'bbbb'))
> >>> l2 = factor(c('ccc', 'dd'))
> >>> lMerge = factor(c(l1, l2))
> >>> lMerge
> >>>   
> >>
> >> [1] 1 2 1 2
> >> Levels: 1 2
> >>  
> >>
> >> I'd like to merge l1 and l2 and to get lMerge 
> >> ----------------------------------------------
> >>
> >> [1] aaaa bbbb ccc dd
> >> Levels: aaaa bbbb ccc dd
> >>
> >> instead of ----------
> >>
> >> [1] 1 2 1 2
> >> Levels: 1 2
> >>  
> >>
> >>
> >> How should I do that without converting the factors back 
> to strings.
> >> -------------------------------------------------------------------
> >>
> >>  
> >>
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From Mike.Prager at noaa.gov  Thu Feb  5 22:35:15 2004
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Thu, 05 Feb 2004 16:35:15 -0500
Subject: [R] I am totally lost on how to install R . . .
In-Reply-To: <8A4148E4383C434980BE3D08AE2436921C55A9@m-nchs-1.nchs.cdc.g
 ov>
References: <8A4148E4383C434980BE3D08AE2436921C55A9@m-nchs-1.nchs.cdc.gov>
Message-ID: <6.0.1.1.2.20040205163307.01c515b8@hermes.nos.noaa.gov>

At 02:19 PM 2/5/2004, Shoultz, Gerald wrote:
>First . . . SUBSCRIBE (I want to subscribe to the list).
>
>Second, I am trying to install R on windows XP.  In looking at the
>instruction manual I get the following:
>
>The simplest way is to use 'rw1081.exe' or 'miniR.exe'. Just
>double-click on the icon
>and follow the instructions. If you installed R this way you can
>uninstall it from the Control Panel.
>
>How do I get the "rw1081.exe" or "miniR.exe"?


With a Web browser, go to Google.  Type in

r cran statistics

The link for CRAN will come up.  Click on it.

Look at "procompiled binary distributions."

You will find the link to download rw1081.exe.  Download it, click on it, 
and the program will self-install.

Do NOT use the .tgz file as it is for Unix.  Ordinary users on Windows 
don't need it.

Does that help?




>All I have right now is
>the R-latest.tgz file and I have absolutely NO idea on how to open or
>use that.  Could someone point me to a clear, step-by-step method for
>installing R on my computer?  Please advise; you may write me directly
>if you like.
>
>I found this email address on the R website; I am assuming that this is
>some kind of "list"--is there a way to look at other entries on this
>"list"?  Please advise.
>
>Thanks!
>
>Gerald Shoultz
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Michael Prager, Ph.D.
Division Chief (acting), NMFS Programs at Beaufort
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/



From Atropin75 at t-online.de  Thu Feb  5 22:45:58 2004
From: Atropin75 at t-online.de (Felix Eschenburg)
Date: Thu, 5 Feb 2004 22:45:58 +0100
Subject: [R] (Novice-) Problem with the plot-function
Message-ID: <200402052245.58610.atropin75@t-online.de>

Hello,
i have written this little function to draw different normal distributions:

n.Plot <- function(x,my,sigma) {
e <- exp(1)
names(x) <- x
f.x <- (1/(sigma*sqrt(2*pi)))*e^(-1*(((x-my)^2)/2*(sigma^2)))
plot(f.x,type="l",xlim=c(-5,5))
return(f.x)
}

if i define x like this:
x <- seq(-5,5,0.01)

Now 
n.Plot(x,0,1) 
DOES draw the correct plot, but the x-axis is labeled from 0 - 1000.
If i give the plot function the xlim=c(-5,5) option, the plot is only drawn 
for the first 5 values of x.
How do i tell plot not to take the indices of x, but the values (or their 
range) of x for labeling the x-axis ?

Felix Eschenburg



From Icabalceta_j at wlf.state.la.us  Thu Feb  5 22:52:40 2004
From: Icabalceta_j at wlf.state.la.us (Icabalceta, Jorge L.)
Date: Thu, 5 Feb 2004 15:52:40 -0600 
Subject: [R] rgamma question
Message-ID: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B0@wlfnt1.wlf.state.la.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040205/d599de1b/attachment.pl

From edwardweisun at hotmail.com  Thu Feb  5 23:02:31 2004
From: edwardweisun at hotmail.com (Edward Sun)
Date: Thu, 05 Feb 2004 23:02:31 +0100
Subject: [R] for help about MLE in R
Message-ID: <BAY13-F46KKA9vRZhs600062a51@hotmail.com>

Dear Sir,

I am using R to estimate two parameters in Normal distribution. I generated 
100 normal distributed numbers, on which to estimate the parameter. The 
syntax is:

>fn<-function(x)-50*log((y)^2)+50*log(2*pi)-(1/2*(z^2))*(sum((x-y)^2))
>out<-nlm(fn, x, hessian=TRUE)

but it does not work. Could you please help me to compose the syntax for the 
purpose that find maximum likelihood estimates of the generated random 
numbers by direct maximization of the likelihood function?

Thanks a lot.

Best regards
Edward Sun



From svetlana.eden at vanderbilt.edu  Thu Feb  5 23:10:04 2004
From: svetlana.eden at vanderbilt.edu (Svetlana Eden)
Date: Thu, 5 Feb 2004 16:10:04 -0600
Subject: [R] Thank you for your answers: Re: correction to the previously
 asked question (about merging factors)
Message-ID: <20040205161004.78144267.svetlana.eden@vanderbilt.edu>


Thank you all very much for your attention and patience.
The different answers made a lot of things clear to me.
I've got the answer and learned a lot.

-- 
Svetlana Eden        Biostatistician II            School of Medicine
                     Department of Biostatistics   Vanderbilt University



From sundar.dorai-raj at pdf.com  Thu Feb  5 23:29:31 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 05 Feb 2004 16:29:31 -0600
Subject: [R] (Novice-) Problem with the plot-function
In-Reply-To: <200402052245.58610.atropin75@t-online.de>
References: <200402052245.58610.atropin75@t-online.de>
Message-ID: <4022C3CB.8090804@pdf.com>

I think you meant to do

plot(x, f.x, ...)

BTW, you've re-invented the wheel. See ?dnorm for evaluating the normal pdf.

Best,
Sundar


Felix Eschenburg wrote:

> Hello,
> i have written this little function to draw different normal distributions:
> 
> n.Plot <- function(x,my,sigma) {
> e <- exp(1)
> names(x) <- x
> f.x <- (1/(sigma*sqrt(2*pi)))*e^(-1*(((x-my)^2)/2*(sigma^2)))
> plot(f.x,type="l",xlim=c(-5,5))
> return(f.x)
> }
> 
> if i define x like this:
> x <- seq(-5,5,0.01)
> 
> Now 
> n.Plot(x,0,1) 
> DOES draw the correct plot, but the x-axis is labeled from 0 - 1000.
> If i give the plot function the xlim=c(-5,5) option, the plot is only drawn 
> for the first 5 values of x.
> How do i tell plot not to take the indices of x, but the values (or their 
> range) of x for labeling the x-axis ?
> 
> Felix Eschenburg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From abunn at montana.edu  Thu Feb  5 23:29:53 2004
From: abunn at montana.edu (Andy Bunn)
Date: Thu, 5 Feb 2004 15:29:53 -0700
Subject: [R] (Novice-) Problem with the plot-function
In-Reply-To: <200402052245.58610.atropin75@t-online.de>
Message-ID: <000001c3ec37$a5085910$78f05a99@msu.montana.edu>

See ?range. And note that I changed plot to more explicitly show what is
being plotted.
HTH, Andy


#~~~~~~~~~~~~~~~~~~
n.Plot <- function(x,my,sigma) {
e <- exp(1)
names(x) <- x
f.x <- (1/(sigma*sqrt(2*pi)))*e^(-1*(((x-my)^2)/2*(sigma^2)))
plot(x, f.x, type="l", xlim = range(x))
return(f.x)
}

n.Plot(seq(-5,5,0.01),0,1)
n.Plot(seq(-50,50,0.01),0,0.1)



From sundar.dorai-raj at pdf.com  Thu Feb  5 23:33:09 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 05 Feb 2004 16:33:09 -0600
Subject: [R] rgamma question
In-Reply-To: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B0@wlfnt1.wlf.state.la.us>
References: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B0@wlfnt1.wlf.state.la.us>
Message-ID: <4022C4A5.2010907@pdf.com>


Icabalceta, Jorge L. wrote:

> I was trying to generate random numbers with a gamma distribution. In R the
> function is: 
> rgamma(n, shape, rate = 1, scale = 1/rate). My question is that if
> X~gamma(alpha, beta) and I want to generate one random number where do I
> plug alpha and beta in rgamma? and, what is the meaning and use of rate?
> Thanks for your attention,
> Jorge 
>  

Did you look at the help? From ?rgamma:

<quote>
Details:

      If 'scale' is omitted, it assumes the default value of '1'.

      The Gamma distribution with parameters 'shape' = a and 'scale' = s
      has density

                f(x)= 1/(s^a Gamma(a)) x^(a-1) e^-(x/s)

      for x > 0, a > 0 and s > 0. The mean and variance are E(X) = a*s
      and Var(X) = a*s^2.
</quote>

Then, depending how you define "alpha" and "beta" use the above to 
figure out how to use rgamma.

-sundar



From p.dalgaard at biostat.ku.dk  Thu Feb  5 23:42:08 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Feb 2004 23:42:08 +0100
Subject: [R] correction to the previously asked question (about merging
	factors)
In-Reply-To: <4022B203.1040309@pdf.com>
References: <20040205141156.372939dc.svetlana.eden@vanderbilt.edu>
	<4022AB14.80308@pdf.com> <4022AE7F.4070301@pdf.com>
	<4022B203.1040309@pdf.com>
Message-ID: <x2y8rhno73.fsf@biostat.ku.dk>

Spencer Graves <spencer.graves at pdf.com> writes:

>       Sundar:  Your solution is not only more elegant than mine, it's
> also faster, at least with this tiny example: > start.time <-
> proc.time()
>  > k1 <- length(F1)
>  > k2 <- length(F2)
>  > F12.lvls <- unique(c(levels(F1), levels(F2)))
>  > F. <- factor(rep(F12.lvls[1], k1+k1), levels=F12.lvls)
>  > F.[1:k1] <- F1
>  > F.[-(1:k1)] <- F2
>  > proc.time()-start.time
> [1] 0.00 0.00 0.42   NA   NA
>  >
>  > start.time <- proc.time()
>  > F1 <- factor(c("b", "a"))
>  > F2 <- factor(c("c", "b"))
>  > F3 <- factor(c(levels(F1)[F1], levels(F2)[F2]))
>  > proc.time()-start.time
> [1] 0.00 0.00 0.24   NA   NA
>  >
>       With longer vectors, mine may be faster -- but yours is still
> more elegant.     Best Wishes,
>       spencer graves

Actually, Sundars solution is exactly equivalent to the 

factor(c(as.character(F1),as.character(F2)))

that several have suggested, and which may actually be good enough for
the vast majority of cases. It is in fact the same thing that goes on
inside rbind.data.frame (that uses as.vector, which is equivalent).

If you really want something optimal, in the sense of not allocating a
large amount of character strings and comparing them individually to
a joint level set, I think you need something like this:

l1 <- levels(F1)
l2 <- levels(F2)
ll <- sort(unique(c(l1, l2)))
m1 <- match(l1, ll)
m2 <- match(l2, ll)
factor(c(m1[F1], m2[F2]), labels=ll)

or if you want to be really hardcore, bypass the inefficiencies inside
factor() and do

structure(c(m1[F1], m2[F2]), levels=ll, class="factor")

(People have been known to regret coding with explicit calls to
structure(), though...)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From hodgess at gator.uhd.edu  Fri Feb  6 00:00:14 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Thu, 5 Feb 2004 17:00:14 -0600
Subject: [R] Plotting question
Message-ID: <200402052300.i15N0EW13309@gator.dt.uh.edu>

Hi Felix:

How about this:
> n1.Plot
function(x,my=0,sigma=1) {
f.x <- dnorm(x,mean=my,sd=sigma)
plot(x,f.x,type="l",xlim=c(-5,5))
return(f.x)
}

Hope this helps!
Sincerely,
Erin Hodgess
mailto: hodgess at gator.uhd.edu



i have written this little function to draw different normal distributions:

n.Plot <- function(x,my,sigma) {
e <- exp(1)
names(x) <- x
f.x <- (1/(sigma*sqrt(2*pi)))*e^(-1*(((x-my)^2)/2*(sigma^2)))
plot(f.x,type="l",xlim=c(-5,5))
return(f.x)
}

if i define x like this:
x <- seq(-5,5,0.01)

Now 
n.Plot(x,0,1) 
DOES draw the correct plot, but the x-axis is labeled from 0 - 1000.
If i give the plot function the xlim=c(-5,5) option, the plot is only drawn 
for the first 5 values of x.
How do i tell plot not to take the indices of x, but the values (or their 
range) of x for labeling the x-axis ?

Felix Eschenburg



From p.dalgaard at biostat.ku.dk  Thu Feb  5 23:45:34 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Feb 2004 23:45:34 +0100
Subject: [R] (Novice-) Problem with the plot-function
In-Reply-To: <200402052245.58610.atropin75@t-online.de>
References: <200402052245.58610.atropin75@t-online.de>
Message-ID: <x2u125no1d.fsf@biostat.ku.dk>

Atropin75 at t-online.de (Felix Eschenburg) writes:

> Hello,
> i have written this little function to draw different normal distributions:
> 
> n.Plot <- function(x,my,sigma) {
> e <- exp(1)
> names(x) <- x
> f.x <- (1/(sigma*sqrt(2*pi)))*e^(-1*(((x-my)^2)/2*(sigma^2)))
> plot(f.x,type="l",xlim=c(-5,5))
> return(f.x)
> }
> 
> if i define x like this:
> x <- seq(-5,5,0.01)
> 
> Now 
> n.Plot(x,0,1) 
> DOES draw the correct plot, but the x-axis is labeled from 0 - 1000.
> If i give the plot function the xlim=c(-5,5) option, the plot is only drawn 
> for the first 5 values of x.
> How do i tell plot not to take the indices of x, but the values (or their 
> range) of x for labeling the x-axis ?

Tell plot what your x coordinates are:

plot(x, f.x, type="l", xlim=c(-5,5))
     
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Thu Feb  5 23:54:08 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Feb 2004 23:54:08 +0100
Subject: [R] rgamma question
In-Reply-To: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B0@wlfnt1.wlf.state.la.us>
References: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B0@wlfnt1.wlf.state.la.us>
Message-ID: <x2ptctnnn3.fsf@biostat.ku.dk>

"Icabalceta, Jorge L." <Icabalceta_j at wlf.state.la.us> writes:

> I was trying to generate random numbers with a gamma distribution. In R the
> function is: 
> rgamma(n, shape, rate = 1, scale = 1/rate). My question is that if
> X~gamma(alpha, beta) and I want to generate one random number where do I
> plug alpha and beta in rgamma? and, what is the meaning and use of rate?

Well, it depends on your definition of alpha and beta.... You need to
match up your notation for the gamma density with that given on
help(rgamma), which will also tell you what to do with them.

The "rate" argument just allows you to specify the scale as its
inverse. A large rate corresponds to a narrow distribution. I suspect
this is popular notation for interarrival distributions in queuing
theory.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Atropin75 at t-online.de  Thu Feb  5 23:56:47 2004
From: Atropin75 at t-online.de (Felix Eschenburg)
Date: Thu, 5 Feb 2004 23:56:47 +0100
Subject: [R] (Novice-) Problem with the plot-function
In-Reply-To: <x2u125no1d.fsf@biostat.ku.dk>
References: <200402052245.58610.atropin75@t-online.de>
	<x2u125no1d.fsf@biostat.ku.dk>
Message-ID: <200402052356.47582.atropin75@t-online.de>


Thank you all, that did the trick. Sometimes i can be a real blockhead.



> Atropin75 at t-online.de (Felix Eschenburg) writes:
> > Hello,
> > i have written this little function to draw different normal
> > distributions:
> >
> > n.Plot <- function(x,my,sigma) {
> > e <- exp(1)
> > names(x) <- x
> > f.x <- (1/(sigma*sqrt(2*pi)))*e^(-1*(((x-my)^2)/2*(sigma^2)))
> > plot(f.x,type="l",xlim=c(-5,5))
> > return(f.x)
> > }
> >
> > if i define x like this:
> > x <- seq(-5,5,0.01)
> >
> > Now
> > n.Plot(x,0,1)
> > DOES draw the correct plot, but the x-axis is labeled from 0 - 1000.
> > If i give the plot function the xlim=c(-5,5) option, the plot is only
> > drawn for the first 5 values of x.
> > How do i tell plot not to take the indices of x, but the values (or their
> > range) of x for labeling the x-axis ?
>
> Tell plot what your x coordinates are:
>
> plot(x, f.x, type="l", xlim=c(-5,5))



From DJNordlund at aol.com  Fri Feb  6 00:17:59 2004
From: DJNordlund at aol.com (DJNordlund@aol.com)
Date: Thu, 5 Feb 2004 18:17:59 EST
Subject: [R] (Novice-) Problem with the plot-function
Message-ID: <a4.4271e288.2d542927@aol.com>

Felix,

there may be more elegant ways of plotting the normal curve, but given your 
current program, you can simply change your plot statment to use a formula:

plot(f.x ~ x, type="l", xlim=c(-5,5))

Dan Nordlund

---------Original message----------
In a message dated 2/5/2004 2:52:04 PM Pacific Standard Time, 
Atropin75 at t-online.de writes:
Hello,
i have written this little function to draw different normal distributions:

n.Plot <- function(x,my,sigma) {
e <- exp(1)
names(x) <- x
f.x <- (1/(sigma*sqrt(2*pi)))*e^(-1*(((x-my)^2)/2*(sigma^2)))
plot(f.x,type="l",xlim=c(-5,5))
return(f.x)
}

if i define x like this:
x <- seq(-5,5,0.01)

Now 
n.Plot(x,0,1) 
DOES draw the correct plot, but the x-axis is labeled from 0 - 1000.
If i give the plot function the xlim=c(-5,5) option, the plot is only drawn 
for the first 5 values of x.
How do i tell plot not to take the indices of x, but the values (or their 
range) of x for labeling the x-axis ?

Felix Eschenburg



From tlumley at u.washington.edu  Fri Feb  6 00:26:05 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 5 Feb 2004 15:26:05 -0800 (PST)
Subject: [R] rgamma question
In-Reply-To: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B0@wlfnt1.wlf.state.la.us>
References: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B0@wlfnt1.wlf.state.la.us>
Message-ID: <Pine.A41.4.58.0402051524010.55686@homer25.u.washington.edu>

On Thu, 5 Feb 2004, Icabalceta, Jorge L. wrote:

> I was trying to generate random numbers with a gamma distribution. In R the
> function is:
> rgamma(n, shape, rate = 1, scale = 1/rate). My question is that if
> X~gamma(alpha, beta) and I want to generate one random number where do I
> plug alpha and beta in rgamma? and, what is the meaning and use of rate?

It depends on what you mean by gamma(alpha,beta). It could be
	rgamma(1,alpha,beta)
or
 	rgamma(1,alpha,1/beta)
since both of these parameterisations are used.

If you think the mean of gamma(alpha,beta) is alpha*beta, use the second
one, if you think it is alpha/beta use the first one.

	-thomas



From spencer.graves at pdf.com  Fri Feb  6 00:44:32 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 05 Feb 2004 15:44:32 -0800
Subject: [R] rgamma question
In-Reply-To: <x2ptctnnn3.fsf@biostat.ku.dk>
References: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B0@wlfnt1.wlf.state.la.us>
	<x2ptctnnn3.fsf@biostat.ku.dk>
Message-ID: <4022D560.8050701@pdf.com>

      Jorge:  If I have trouble understanding documentation with 
something like this, I make plots, e.g., of dgamma vs. x for different 
values for shape and rate or scale. 
      hope this helps.  spencer graves

Peter Dalgaard wrote:

>"Icabalceta, Jorge L." <Icabalceta_j at wlf.state.la.us> writes:
>
>  
>
>>I was trying to generate random numbers with a gamma distribution. In R the
>>function is: 
>>rgamma(n, shape, rate = 1, scale = 1/rate). My question is that if
>>X~gamma(alpha, beta) and I want to generate one random number where do I
>>plug alpha and beta in rgamma? and, what is the meaning and use of rate?
>>    
>>
>
>Well, it depends on your definition of alpha and beta.... You need to
>match up your notation for the gamma density with that given on
>help(rgamma), which will also tell you what to do with them.
>
>The "rate" argument just allows you to specify the scale as its
>inverse. A large rate corresponds to a narrow distribution. I suspect
>this is popular notation for interarrival distributions in queuing
>theory.
>
>  
>



From spencer.graves at pdf.com  Fri Feb  6 00:44:57 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 05 Feb 2004 15:44:57 -0800
Subject: [R] correction to the previously asked question (about merging
	factors)
In-Reply-To: <x2y8rhno73.fsf@biostat.ku.dk>
References: <20040205141156.372939dc.svetlana.eden@vanderbilt.edu>	<4022AB14.80308@pdf.com>
	<4022AE7F.4070301@pdf.com>	<4022B203.1040309@pdf.com>
	<x2y8rhno73.fsf@biostat.ku.dk>
Message-ID: <4022D579.4090202@pdf.com>

      Thanks, Peter. 

      So Sundar's more elegant solution is equivalent to my initial 
response to this question -- which shows how much one can lose trying to 
be too clever. 

      Best Wishes,
      spencer graves

Peter Dalgaard wrote:

>Spencer Graves <spencer.graves at pdf.com> writes:
>
>  
>
>>      Sundar:  Your solution is not only more elegant than mine, it's
>>also faster, at least with this tiny example: > start.time <-
>>proc.time()
>> > k1 <- length(F1)
>> > k2 <- length(F2)
>> > F12.lvls <- unique(c(levels(F1), levels(F2)))
>> > F. <- factor(rep(F12.lvls[1], k1+k1), levels=F12.lvls)
>> > F.[1:k1] <- F1
>> > F.[-(1:k1)] <- F2
>> > proc.time()-start.time
>>[1] 0.00 0.00 0.42   NA   NA
>> >
>> > start.time <- proc.time()
>> > F1 <- factor(c("b", "a"))
>> > F2 <- factor(c("c", "b"))
>> > F3 <- factor(c(levels(F1)[F1], levels(F2)[F2]))
>> > proc.time()-start.time
>>[1] 0.00 0.00 0.24   NA   NA
>> >
>>      With longer vectors, mine may be faster -- but yours is still
>>more elegant.     Best Wishes,
>>      spencer graves
>>    
>>
>
>Actually, Sundars solution is exactly equivalent to the 
>
>factor(c(as.character(F1),as.character(F2)))
>
>that several have suggested, and which may actually be good enough for
>the vast majority of cases. It is in fact the same thing that goes on
>inside rbind.data.frame (that uses as.vector, which is equivalent).
>
>If you really want something optimal, in the sense of not allocating a
>large amount of character strings and comparing them individually to
>a joint level set, I think you need something like this:
>
>l1 <- levels(F1)
>l2 <- levels(F2)
>ll <- sort(unique(c(l1, l2)))
>m1 <- match(l1, ll)
>m2 <- match(l2, ll)
>factor(c(m1[F1], m2[F2]), labels=ll)
>
>or if you want to be really hardcore, bypass the inefficiencies inside
>factor() and do
>
>structure(c(m1[F1], m2[F2]), levels=ll, class="factor")
>
>(People have been known to regret coding with explicit calls to
>structure(), though...)
>
>  
>



From Meredith.Briggs at team.telstra.com  Fri Feb  6 00:08:40 2004
From: Meredith.Briggs at team.telstra.com (Briggs, Meredith M)
Date: Fri, 6 Feb 2004 10:08:40 +1100
Subject: [R] Histograms by two factors
Message-ID: <3B5823541A25D311B3B90008C7F9056410E352B0@ntmsg0092.corpmail.telstra.com.au>

Hi


I am trying to print out means, STDs and histograms under two sets of factors. I can manage it for one set - see below but not for two  sets. That is, I want ot print out the mean STD and Histogram for each ITEM code within each DELIVERABLE code. In addition I can only get to view the histogram for the last item. How do you get R to stop overriding the histogram for eg  level 1 for factor 1 by level 2 of factor 1?

thanks




X11()

Indat <- read.table ("C:/testdata.txt",header=T)

B <- c(Indat[,1],Indat[,2],Indat[,3],Indat[,4],Indat[,5])
y <- Indat[,5]/Indat[,4]
DELIV <- Indat[,1]
ITEM <- Indat[,3]
Df1 <- factor(DELIV)
Df2 <- factor(ITEM)

d1 <- tapply(y,Df1, mean)
d2 <- tapply(y, Df1,sd)
d3 <- tapply(y, Df1,max)
d4 <- tapply(y, Df1,hist)

print(d1)
print(d4)



From p.dalgaard at biostat.ku.dk  Fri Feb  6 01:07:25 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 Feb 2004 01:07:25 +0100
Subject: [R] for help about MLE in R
In-Reply-To: <BAY13-F46KKA9vRZhs600062a51@hotmail.com>
References: <BAY13-F46KKA9vRZhs600062a51@hotmail.com>
Message-ID: <x2llnhnk8y.fsf@biostat.ku.dk>

"Edward Sun" <edwardweisun at hotmail.com> writes:

> Dear Sir,
> 
> I am using R to estimate two parameters in Normal distribution. I
> generated 100 normal distributed numbers, on which to estimate the
> parameter. The syntax is:
> 
> >fn<-function(x)-50*log((y)^2)+50*log(2*pi)-(1/2*(z^2))*(sum((x-y)^2))
> >out<-nlm(fn, x, hessian=TRUE)
> 
> but it does not work. Could you please help me to compose the syntax
> for the purpose that find maximum likelihood estimates of the
> generated random numbers by direct maximization of the likelihood
> function?

Apologies if this wasn't a homework question, but

a) That is not the likelihood function. Try fn(0). What is the z doing
in there? The log((y)^2) makes the whole thing vector valued, which
you do not want. Get this right first and perhaps do a plot of the
function values.

b) Second argument to nlm is supposed to be a starting value for the
parameter (e.g., 0.5), and you seem to be thinking differently. Also
note that you are feeding the log-likelihood to a *minimizer*.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From whs at brown.edu  Fri Feb  6 04:41:18 2004
From: whs at brown.edu (William Sheffler)
Date: Thu, 05 Feb 2004 22:41:18 -0500
Subject: [R] availability of heap or priority queue
Message-ID: <40230CDE.7050306@brown.edu>

Is there a heap or priority queue data structure available in R, or 
anything similar?

thanks,
-Will Sheffler



From parrinel at med.unibs.it  Thu Feb  5 18:17:10 2004
From: parrinel at med.unibs.it (parrinel@med.unibs.it)
Date: Thu, 05 Feb 2004 18:17:10 +0100
Subject: [R] Incomplete Factorial design 
Message-ID: <402288A6.4945.17058B1@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040205/bf137711/attachment.pl

From tura at centroin.com.br  Fri Feb  6 09:42:12 2004
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Fri, 06 Feb 2004 06:42:12 -0200
Subject: [R] multiple plots in different windows
Message-ID: <6.0.0.22.2.20040206064151.03079b70@pop.centroin.com.br>

At 14:29 05-02-2004, you wrote:

>Hi all,
>I'd like to generate a number of plots to compare different
>vectors I have stored in a list. To do this I do something like
>(in a linux system):
>
>for(i in 1:L) {
> X11()
> plot(listOfFunctions[[i]])
>}
>
>First question is: is this the right way to create several plots (in
>different windows) ?

Hi 

I think wich the correct code is:

>for(i in 1:L) {
>windows()
> plot(listOfFunctions[[i]])
>}

This work in my computer.

I dont know thje answer for your second question


Best wishes

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil  

From petr.pikal at precheza.cz  Fri Feb  6 09:58:56 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 06 Feb 2004 09:58:56 +0100
Subject: [R] Latin 2 encoding + fonts
In-Reply-To: <BAY2-F156ZCHusMjQHt0004fece@hotmail.com>
Message-ID: <40236560.1998.6CD275@localhost>

Hallo

On 4 Feb 2004 at 12:41, Miha STAUT wrote:

> Hi,
> 
> In the FAQ I read about options to specify different fonts than the
> default ones for the console (in the file Rprofile) and for the
> graphical output (Rdevga). I would however like to replace Latin 1
> with Latin 2 enconding for both (console and graphical) output in
> Windows and just graphical output in Linux.

I asked a question about enconding few weeks ago and I have got 
a hint from Prof.Ripley which led me to check files Rdevga and 
Rconsole in directory etc and experiment with font names 
specified there. 

I must say that it is also a system version specific issue as W98 
requires other fonts then WNT.

Cheers
Petr



> 
> I guess it is possible but I did not find the way.
> 
> How can I use the fonts (*.afm) and the (presumably) encondings
> (*.enc) in R/rw1081/afm? How do I know what are the real font names.
> Are those only the ones listed in the man page for Hershey?
> 
> Thanks, Miha
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From petr.pikal at precheza.cz  Fri Feb  6 10:18:14 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 06 Feb 2004 10:18:14 +0100
Subject: [R] Date Time Conversion problems...
In-Reply-To: <2F3262756375D411B0CC00B0D049775D01A4CDB9@westpark>
Message-ID: <402369E6.4884.7E7BE2@localhost>

Hi

On 4 Feb 2004 at 8:31, Shawn Way wrote:

> At one time (version 1.7), the code below used to work for converting
> and extracting based on the Date Time.  In version 1.8.1, something
> changed I know, but I cannot for the life of me figure out what...
> 
> Data:
> 
> UserName,RequestDate,PO,OrderDate,ExpDelivDate,Vendor,Total
> "Woody, Jim",12/19/2002,AP15063,1/7/2003,2/10/2003,Ames ,8570
> "Harrold, Paul",12/31/2002,AP15083,1/9/2003,1/10/2003,Ryan ,1039.5
> "Vo, Hoang",12/27/2002,AP15055,1/6/2003,1/13/2003,TIDEA,1005.36 "Way,
> Shawn",1/2/2003,AP15043,1/2/2003,1/9/2003,JS   ,1000 "Vo,
> Hoang",1/7/2003,SO17440,1/8/2003,12/31/2003,USFi-,3705 "Harrold,
> Paul",1/10/2003,AP15122,1/13/2003,1/14/2003,FishM,65.06
> 
> Old Code:
> 
> library(lattice)
> data <- read.csv("h:\\list3.csv",header=TRUE)
> data2 <-
> data.frame(Name=data$UserName,Date=data$RequestDate,Vendor=data$Vendor
> ,Cost= data$Total) data2$Date <-
> strptime(as.character(data2$Date),format="%m/%d/%Y") start <-
> strptime(c("1/01/2003"),format="%m/%d/%Y") end <-
> strptime(c("12/31/2003"),format="%m/%d/%Y") data3 <- data2[data2$Date
> >= start & data2$Date <= end,] lset(col.whitebg())
> xyplot(Cost~as.POSIXct(Date)|Name,data=data3,
>        xlab="Date",
>        ylab="PO Cost($)",
>        ylim=c(0,10000),
>        panel= function(x,y){
>          a <- mean(y)
>          panel.grid(h=-1,v=2)
>          panel.xyplot(x,y)
>          panel.abline(h=a,col="red")
>        }
>        )
> 
> The error I get is from line 4, 
> 
> > data2$Date <- strptime(as.character(data2$Date),format="%m/%d/%Y")
> Error in "$<-.data.frame"(`*tmp*`, "Date", value =
> strptime(as.character(data2$Date),  : 
>  replacement has 9 rows, data has 230

most probably you have POSIXlt format

try

length(strptime(as.character(data2$Date),format="%m/%d/%Y"))
should result 9

you have to change to POSIXct through as.POSIXct

andd you than get lengthof your date vector to be correct.

Cheers
Petr



> 
> This used to work for replacing the dates with POSIX values...
> 
> Also of interest is the extraction for data3, is this the correct
> method for extraction?
> 
> What I'm looking at is the spending habits of individuals...
> 
> Thanks for your help...
> 
>   _____  
> 
> "Don't rush me, you rush a miracle, you get a rotten miracle." 
> -Miracle Max, The Princess Bride
> 
>   _____  
> 
>   Shawn Way, PE	 Tanox, Inc.	
> Engineering Manager	 10301 Stella Link	
> sway at tanox.com	 Houston, TX 77025
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From l.houdusse at cerep.fr  Fri Feb  6 10:20:11 2004
From: l.houdusse at cerep.fr (Laurent Houdusse)
Date: Fri, 6 Feb 2004 10:20:11 +0100 
Subject: [R] Normality Test on several groups
Message-ID: <BA420EFAAC96D311A7A0006097D37BDB04515A31@EOLE>

Hi,

I use ks.test or lillie.test to verify a normal distribution. It's performed
for a group
My users use SigmaStat software and a One Way ANOVA on several groups
In the result page there is a probability value to determine if Normality
test is failed or passed
So, how can i retrieve this probability value on several groups?
Is there another function in R to verify normality on several groups?

Thanks



Laurent Houdusse 
Analyste Programmeur



From ivonefig at ipimar.pt  Fri Feb  6 10:44:23 2004
From: ivonefig at ipimar.pt (Ivone Figueiredo)
Date: Fri, 6 Feb 2004 09:44:23 -0000
Subject: [R] Any help
Message-ID: <004301c3ec95$cd67f3d0$c9040a0a@Ivone1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040206/a0ffa13e/attachment.pl

From p.dalgaard at biostat.ku.dk  Fri Feb  6 11:34:53 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 Feb 2004 11:34:53 +0100
Subject: [R] Histograms by two factors
In-Reply-To: <3B5823541A25D311B3B90008C7F9056410E352B0@ntmsg0092.corpmail.telstra.com.au>
References: <3B5823541A25D311B3B90008C7F9056410E352B0@ntmsg0092.corpmail.telstra.com.au>
Message-ID: <x2k7304hte.fsf@biostat.ku.dk>

"Briggs, Meredith M" <Meredith.Briggs at team.telstra.com> writes:

> Hi
> 
> 
> I am trying to print out means, STDs and histograms under two sets
> of factors. I can manage it for one set - see below but not for two
> sets. That is, I want ot print out the mean STD and Histogram for
> each ITEM code within each DELIVERABLE code. 

Tapply accepts a list of factors, tapply(y,list(Df1,Df2),mean), and so
forth (and the help page does say so...).

> In addition I can only get to view the histogram for the last item.

You do get to view the others, just not for very long ;-)

> How do you get R to stop overriding the histogram for eg level 1 for
> factor 1 by level 2 of factor 1?

par(ask=TRUE) is one possible answer. 
Others include 
- turning on plot history (in the Windows GUI) or use
  recordPlot/replayPlot
- switching graphics device to a file and viewing it later
- opening a separate graphics device for each histogram
- setting up for multiple plots on the same page.


> 
> thanks
> 
> 
> 
> 
> X11()
> 
> Indat <- read.table ("C:/testdata.txt",header=T)
> 
> B <- c(Indat[,1],Indat[,2],Indat[,3],Indat[,4],Indat[,5])
> y <- Indat[,5]/Indat[,4]
> DELIV <- Indat[,1]
> ITEM <- Indat[,3]
> Df1 <- factor(DELIV)
> Df2 <- factor(ITEM)
> 
> d1 <- tapply(y,Df1, mean)
> d2 <- tapply(y, Df1,sd)
> d3 <- tapply(y, Df1,max)
> d4 <- tapply(y, Df1,hist)
> 
> print(d1)
> print(d4)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From pascal.dessaux at noos.fr  Fri Feb  6 12:24:12 2004
From: pascal.dessaux at noos.fr (pascal dessaux)
Date: Fri, 6 Feb 2004 12:24:12 +0100
Subject: [R] information on R
Message-ID: <OEEGKALHOGJEPCDLIEDNGEFJCBAA.pascal.dessaux@noos.fr>

Hello

I am a trader and work on systematic trading. I develop my own back testing
and trading tools for personal use.

My development are done in microsoft Visual C++.  I search a library for
wavelet algo and I discover WAVESLIM which run on R.

You write on the R home page that:

"Advanced users can write C code to manipulate R objects directly"

does it mean that I can use WAVESLIM like a library from a visual C++?(my
program are developed in C++ ANSI/ISO)
does it exit example of such project?

Thank for your help

Pascal



From ajtee at ajtee.uklinux.net  Fri Feb  6 13:01:46 2004
From: ajtee at ajtee.uklinux.net (Adam Tee)
Date: Fri, 06 Feb 2004 12:01:46 +0000
Subject: [R] Converting a Dissimilarity Matrix
Message-ID: <4023822A.507@ajtee.uklinux.net>

Hi all,

I'm trying to perform a hierarchical clustering on some
dissimilarity data that I have but the data matrix I have already 
contains the dissimilarity values.  These values are calculated using
a separate program.  The dissimilarity matrix in complete with no 
missing values but the hclust, and agnes routines require it in the
form produced by daisy or dist.  Is there any of converting my complete 
matrix to this format without changing the values??


Thanks

Adam



From wolski at molgen.mpg.de  Fri Feb  6 13:16:26 2004
From: wolski at molgen.mpg.de (wolski)
Date: Fri, 06 Feb 2004 13:16:26 +0100
Subject: [R] How to remove method initialize./package methods
Message-ID: <200402061316260092.09311A7A@harry.molgen.mpg.de>


Have defined a new class (by setClass) and added a method initialize (setMethod("initialize"). 

setMethod("initialize"
          ,signature(.Object="Massvector")
          ,function(.Object,data,info,tcoor,gelcoor)

But I dont like it and want to remove it!

> showMethods("initialize")
...
.Object = "Massvector"
    (inherited from .Object = "ANY")

>removeMethod("initialize","Massvector")
[1] FALSE
Warning message: 
No method found for function "initialize" and signature "Massvector" in: removeMethod("initialize", "Massvector") 



How to remove it?

Eryk.



From Simon.Fear at synequanon.com  Fri Feb  6 13:55:05 2004
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Fri, 6 Feb 2004 12:55:05 -0000
Subject: [R] 0.1 + 0.2 != 0.3 revisited
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F021D8@synequanon01>

Prompted by Peter Dalgard's recent elegant "intbin" function,
I have been playing with the extension to converting reals to binary
representation. The decimal part can be done like this:

decbase <- function(x, n=52, base=2) {
  if(n) {
    x <- x*base
    paste(trunc(x), decbase(x%%1, n-1, base), sep="")
  }
}

n=52 default because that's the number of bits in the significand of
a 64-bit float.

Now, `decbase(0.1)` is a bit curious in that the 0.1 is going to be
converted to a binary float by the interpreter ... and then re-converted
by `decbase`, so really I should
insist on character format for the number I want to convert. But
anyway I do get the right answer up to the point of truncation:

> decbase(.1)
[1] "0001100110011001100110011001100110011001100110011001"
> decbase(.2)
[1] "0011001100110011001100110011001100110011001100110011"
> decbase(.3)
[1] "0100110011001100110011001100110011001100110011001100"

That is to say, decbase(.1) + decbase(.2) really does equal
decbase(.3). But not if R does its own arithmetic first:

> decbase(.1+.2)
[1] "0100110011001100110011001100110011001100110011001101"

What has gone on here? Why does R apparently get it's
internal representation of one of .1 or .2 "wrong" ? Does the
end of the internal binary for .1 get rounded up instead of 
truncated ? Why wouldn't that show in decbase(.1) ?  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From jfox at mcmaster.ca  Fri Feb  6 14:43:17 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 06 Feb 2004 08:43:17 -0500
Subject: [R] Histograms by two factors
In-Reply-To: <3B5823541A25D311B3B90008C7F9056410E352B0@ntmsg0092.corpmai
	l.telstra.com.au>
Message-ID: <5.1.0.14.2.20040206082420.0205f248@127.0.0.1>

Dear Meredith,

At 10:08 AM 2/6/2004 +1100, Briggs, Meredith M wrote:

>I am trying to print out means, STDs and histograms under two sets of 
>factors. I can manage it for one set - see below but not for two  sets. 
>That is, I want ot print out the mean STD and Histogram for each ITEM code 
>within each DELIVERABLE code.

You can use commands such as tapply(y, list(deliv=Df1, item=Df2), mean).

>  In addition I can only get to view the histogram for the last item. How 
> do you get R to stop overriding the histogram for eg  level 1 for factor 
> 1 by level 2 of factor 1?

If you set par(ask=TRUE) after opening the graphics device, then you will 
be prompted to press the enter key before each plot. Alternatively, you 
could do something like

par(mfrow=c(nlevels(Df1), nlevels(Df2))
tapply(y, list(Df1, Df2), function(y) hist(y, main=""))

to get an array of histograms (though the labelling leaves something to be 
desired).

I hope this helps,
  John

>thanks
>
>
>
>
>X11()
>
>Indat <- read.table ("C:/testdata.txt",header=T)
>
>B <- c(Indat[,1],Indat[,2],Indat[,3],Indat[,4],Indat[,5])
>y <- Indat[,5]/Indat[,4]
>DELIV <- Indat[,1]
>ITEM <- Indat[,3]
>Df1 <- factor(DELIV)
>Df2 <- factor(ITEM)
>
>d1 <- tapply(y,Df1, mean)
>d2 <- tapply(y, Df1,sd)
>d3 <- tapply(y, Df1,max)
>d4 <- tapply(y, Df1,hist)
>
>print(d1)
>print(d4)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From HankeA at mar.dfo-mpo.gc.ca  Fri Feb  6 15:26:27 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Fri, 06 Feb 2004 10:26:27 -0400
Subject: [R] glm.poisson.disp versus glm.nb
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE12492B@msgmarsta01.bio.dfo.ca>

In response to my own query (see below),
The estimate theta from glm.nb is actually 1/phi or 1/alpha in some texts,
where phi  is the dispersion parameter for the negative binomial
distribution. However, the dispersion estimate from glm.poisson.disp does
not equal 1/theta because 1/theta is a maximum likelihood (ML) estimate
whereas the dispersion estimate from glm.poisson.disp is based on the method
of moments (MM). Correct me if I'm wrong!
The two estimates for dispersion are fairly different.
Paul and Banerjee (1998) observe that the test statistic discussed below
(TNBI) is more conservative when one uses the moment generated estimates for
phi, and that phi is underestimated by ML and overestimated by MM. However,
the overestimation by MM is slight compared to the underestimation by ML.
Does that then mean MM estimates of phi are to be preferred?

Alex

Dear list,
This is a question about overdispersion and the ML estimates of the
parameters returned by the glm.poisson.disp (L. Scrucca) and glm.nb
(Venables and Ripley) functions. Both appear to assume a negative binomial
distribution for the response variable.

Paul and Banerjee (1998) developed C(alpha) tests for "interaction and main
effects, in an unbalanced two-way layout of counts involving two fixed
factors, when data are Poisson distributed, and when data are extra
dispersed". In R I coded their C(alpha) test statistic (called TNBI) for
interaction for the case where the counts are extra-dispersed, as well as
their test for extra-dispersion (called T_a). Using the Quine data set
(Quine, 1975) the authors collapse the orginal 4x2x2x2 study design into a
2x4 table and obtained estimates of TNBI=10.36 and T_a=90.81.
Using the dispersion estimate from glm.poisson.disp and the estimates for mu
I got exactly the same results for TNBI and T_a. This made me happy. Now I
thought to try the ML estimates from glm.nb to see if the results would be
the same but I am having difficulty relating the dispersion phi from
glm.poisson.disp to theta estimated by glm.nb.
According to the R help for glm.poisson.disp " Var(y_i) =  mu_i(1+mu_i*phi)
". The help for glm.nb lead me to a book by V&R (1994) which indicates that
Var(y)=mu+mu^2/theta. From this I gathered that phi=1/theta but the
estimates do not relate to each other in this way unless one is in error. In
a document by L.P. Ammann he says a "negative binomial model can be
specified with mean mu and dispersion phi by taking theta=mu/(phi-1)". I had
a problem implementing this because in my mind mu is a vector whereas phi
and theta are scalars.



Alex Hanke
Department of Fisheries and Oceans
St. Andrews Biological Station
531 Brandy Cove Road
St. Andrews, NB
Canada
E5B 2L9



From Timur.Elzhov at jinr.ru  Wed Feb  4 10:25:08 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Wed, 4 Feb 2004 12:25:08 +0300
Subject: [R] lm coefficients
In-Reply-To: <Pine.LNX.4.44.0402031726060.10082-100000@gannet.stats>
References: <20040203162553.GA2938@nf034.jinr.ru>
	<Pine.LNX.4.44.0402031726060.10082-100000@gannet.stats>
Message-ID: <20040204092508.GA5607@nf034.jinr.ru>

On Tue, Feb 03, 2004 at 05:27:40PM +0000, Prof Brian Ripley wrote:

>> out <- lm(T ~ poly(X, 4), data = d)
> You asked for 4 and got 2?  Really?

No, in fact I have a 4-power model, I just posted example with power
of 2, for simplicity. I forgot to replace the poly argument :)

Thanks too all who helped me!

--
WBR,
Timur.



From optimisation1.stagiaire at lagardere-active.com  Fri Feb  6 15:36:54 2004
From: optimisation1.stagiaire at lagardere-active.com (optimisation1.stagiaire@lagardere-active.com)
Date: Fri, 6 Feb 2004 15:36:54 +0100
Subject: [R] nnet problem
Message-ID: <OFE25E3B6A.952E54DC-ONC1256E32.004FCC04-C1256E32.005048CC@e-c-s.fr>






Hello everybody,

I want to use the nnet library and my problem is that the algorithm seems
to accept only class as target when the neural is fiiting. So the output
when I use predict.nnet is also a class. Is it possible to have numeric
variable as target ? If yes, what is the syntax ?

Thank you.


Cordialement,

R?gis CHARIGNON


**************************************************************************************************************************************************************
Attention : le present message et toutes les pieces jointes (le "message") sont confidentiels et etablis a l'attention exclusive du ou des destinataire(s) 
indique(s). Toute autre diffusion ou utilisation non autorisee est interdite. Si vous recevez ce message par erreur, veuillez immediatement en avertir 
l'expediteur par e-mail en retour, detruire le message et vous abstenir de toute reference aux informations qui y figurent afin d'eviter les sanctions 
attachees a la divulgation et a l'utilisation d'informations confidentielles. Les messages electroniques sont susceptibles d'alteration. Lagardere SCA 
et ses filiales declinent toute responsabilite en cas d'alteration ou de falsification du present message.

Warning : this e-mail and any files attached (the "e-mail") are confidential and intended solely to the named addressee(s). Any unauthorised dissemination 
or use is strictly prohibited. If you received this e-mail in error, please immediately notify the sender by reply e-mail and then delete the e-mail from 
your system. Please do not copy, use or make reference to it for any purpose, or disclose its contents to any person : to do so could expose you to sanctions. 
E-mails can be altered or falsified. Lagardere SCA and its subsidiary companies shall not be liable for any alteration or falsification on this e-mail.



From spencer.graves at pdf.com  Fri Feb  6 15:38:34 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 06 Feb 2004 06:38:34 -0800
Subject: [R] Incomplete Factorial design
In-Reply-To: <402288A6.4945.17058B1@localhost>
References: <402288A6.4945.17058B1@localhost>
Message-ID: <4023A6EA.4040700@pdf.com>

      I assume that means you have two treatments, say A and B, can be 
either absent or present.  The standard analysis codes them as -1 or +1 
for absent or present, respectively.  If you have observations in all 4 
cells, you can write the following equation: 

      y(A,B) = b0 + b1*A + b2*B + b12*A*B + error. 

      This equation has 4 unknowns, b1, b1, b2 and b12.  If you have all 
4 cells in the 2x2 table, then you can estimate all 4 unknowns.  If you 
have data for only 3 cells, the standard analysis pretends that b12 = 0 
and estimates the other three.  If you have only 2 cells, say (both 
absent) and (both present), the standard analysis can estimate b0 plus 
either of b1 or b2.  However, in fact, these really estimate (b0+b12) 
and (b1+b2).  To understand this, consult any good book that discusses 
confounding with 2-level fractional factorial designs. 

      To do this in R, use "lm", as

      fit <- lm(y~A+B, data.frame(y=..., A=..., B=..,)

      hope this helps. 
      spencer graves

parrinel at med.unibs.it wrote:

>Hello,
>I am planning a study with the main point to evaluate the interaction of two treatments, 
>but for ethical reasons one cell is empty, that with patients receaving no treatment at all
>
>                                                                    
>                                                                    
>                            Treatment B
>                                  
>                                                                    
>                                                                    
>+
>-
>
>Treatment A
>+
>a
>b
>
>                                                                    
>-
>c
>-------
>
>
>I am looking for functions in R to estimate the sample size and/or to conduct the 
>analysis. I have just found an article from Byar in Statistics in Medicine for a 2^3 
>incomplete factorial design, but I would like not to discover again the wheel..
>TIA
>dr. Giovanni Parrinello
>Section of Medical Statistics
>Department of Biosciences
>University of Brescia
>25127 Viale Europa, 11
>Brescia Italy
>Tel: +390303717528
>Fax: +390303701157
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From andy_liaw at merck.com  Fri Feb  6 15:39:01 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 6 Feb 2004 09:39:01 -0500
Subject: [R] Converting a Dissimilarity Matrix
Message-ID: <3A822319EB35174CA3714066D590DCD504AF773F@usrymx25.merck.com>

Wrap the matrix in as.dist().

HTH,
Andy

> From: Adam Tee
> 
> Hi all,
> 
> I'm trying to perform a hierarchical clustering on some
> dissimilarity data that I have but the data matrix I have already 
> contains the dissimilarity values.  These values are calculated using
> a separate program.  The dissimilarity matrix in complete with no 
> missing values but the hclust, and agnes routines require it in the
> form produced by daisy or dist.  Is there any of converting 
> my complete matrix to this format without changing the values??
> 
> Thanks
> 
> Adam


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From kmw at mail.rockefeller.edu  Fri Feb  6 15:44:48 2004
From: kmw at mail.rockefeller.edu (Knut M. Wittkowski)
Date: Fri, 06 Feb 2004 09:44:48 -0500
Subject: [R] Normality Test on several groups
In-Reply-To: <BA420EFAAC96D311A7A0006097D37BDB04515A31@EOLE>
Message-ID: <5.1.0.14.0.20040206091648.076e08c0@imap.rockefeller.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040206/a8d4db3c/attachment.pl

From spencer.graves at pdf.com  Fri Feb  6 15:47:38 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 06 Feb 2004 06:47:38 -0800
Subject: [R] Any help
In-Reply-To: <004301c3ec95$cd67f3d0$c9040a0a@Ivone1>
References: <004301c3ec95$cd67f3d0$c9040a0a@Ivone1>
Message-ID: <4023A90A.7080703@pdf.com>

      It looks like "nls" may have tested something like q = 0, for 
which IFOXM is (-Inf), provided the other numbers are sensible. 

      With problems like this, before I invoke "nls", I study the 
formula and evaluate it with all the different combinations of arguments 
that might produce NA or Inf.  If I find a value unacceptable to "nls", 
I change the parameterization to eliminate it.  For example, if r, q and 
K must be positive, then I replace them with log.r, log.q, and log.K. 

      hope this helps.  spencer graves

Ivone Figueiredo wrote:

> Hi could anyone help me how to bypass this problem
>
> IFOXM <- function(r, q , K) { (2*r*log(q*K))/(2+r)+((2-r)/(2+r))* 
>
> v1
>
> -(q/(2+r))* v2}
>
> v3 <- IFOXArist$Ln.Ut.1
>
> IFOXMArist <- nls(v3~ IFOXM (r, q , K),start=list(r=0.5, q=0.01,
>
> K=2000))
>
>Error in numericDeriv(form[[3]], names(ind), env) : 
>
>Missing value or an Infinity produced when evaluating the 
>
> model In addition: Warning message: NaNs produced in: log(x)
>
> 
>
> Regards
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From davl-s0p0a0m at cistron.nl  Fri Feb  6 16:07:18 2004
From: davl-s0p0a0m at cistron.nl (David A. van Leeuwen)
Date: Fri, 06 Feb 2004 16:07:18 +0100
Subject: [R] more or less pager
Message-ID: <4023ADA6.3070401@cistron.nl>

R-users,

(forgive my return adres)

I've been breaking my head why R---which i find fabulous, by the 
way---does not pipe interactive output through a pager (more or less), 
like it does with help(), or like GNU Octave does with arrays with more 
than terminal height rows. 

Maybe it is my installation (Debian/GNU Linux).  Maybe it is my 
configuration, but i don't think so because with help() it works

## Default pager
PAGER=${PAGER-'/usr/bin/less'}

But i think it really is because R-users apparently don't look at 
dataframes with more than, say, 24 rows.  I always seem to be intetrested
in column names with some rows of data, so often I type

 > data[1,]

just to see what the columns were called again.

In order to circumvent the problem of data running off the screen, I've 
made a simple hack:

more <- function(x) {
  tmp <- paste("/tmp/R", floor(runif(1,0,1e6)), sep=".")
  sink(tmp)
  print(x)
  sink()
  file.show(tmp, delete.file=TRUE)
}

which isn't the prettiest implementation of `tmpfile', but hey, it 
allows my to type

 > more(data)

Please ignore this if there is a more proper way of doing this in R 
(preferrably by default without the more()), but also please include 
some reference to this under keywords `pager', `more' or `less' in the 
documentation.

Developers, thanks for all the work.

-- 
David A. van Leeuwen			< @ElseWare.nl>

	  Echt stijlvol sterven doe je / bij een ander op de mat
	  Op de dag dat je bezorgd wordt / door het NRC Handelsblad
	
							---Joop Visser



From Simon.Fear at synequanon.com  Fri Feb  6 16:09:21 2004
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Fri, 6 Feb 2004 15:09:21 -0000
Subject: [R] Incomplete Factorial design
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F021D9@synequanon01>

One could also fit

fit <- lm(y~A*B - 1, data.frame(y=..., A=..., B=..,)

which will give a direct a:b term (as the negative of the
intercept in Spenser's formulation). Arguably this is more
natural in a setting where there is no placebo so that
an intercept term has a less obvious interpretation.

> -----Original Message-----
> From: Spencer Graves [mailto:spencer.graves at pdf.com]
> Sent: 06 February 2004 14:39
> To: parrinel at med.unibs.it
> Cc: R-help at stat.math.ethz.ch
> Subject: Re: [R] Incomplete Factorial design
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
>       I assume that means you have two treatments, say A and 
> B, can be 
> either absent or present.  The standard analysis codes them 
> as -1 or +1 
> for absent or present, respectively.  If you have 
> observations in all 4 
> cells, you can write the following equation: 
> 
>       y(A,B) = b0 + b1*A + b2*B + b12*A*B + error. 
> 
>       This equation has 4 unknowns, b1, b1, b2 and b12.  If 
> you have all 
> 4 cells in the 2x2 table, then you can estimate all 4 
> unknowns.  If you 
> have data for only 3 cells, the standard analysis pretends 
> that b12 = 0 
> and estimates the other three.  If you have only 2 cells, say (both 
> absent) and (both present), the standard analysis can 
> estimate b0 plus 
> either of b1 or b2.  However, in fact, these really estimate (b0+b12) 
> and (b1+b2).  To understand this, consult any good book that 
> discusses 
> confounding with 2-level fractional factorial designs. 
> 
>       To do this in R, use "lm", as
> 
>       fit <- lm(y~A+B, data.frame(y=..., A=..., B=..,)
> 
>       hope this helps. 
>       spencer graves
> 
> parrinel at med.unibs.it wrote:
> 
> >Hello,
> >I am planning a study with the main point to evaluate the 
> interaction of two treatments, 
> >but for ethical reasons one cell is empty, that with 
> patients receaving no treatment at all
> >
> >                                                                    
> >                                                                    
> >                            Treatment B
> >                                  
> >                                                                    
> >                                                                    
> >+
> >-
> >
> >Treatment A
> >+
> >a
> >b
> >
> >                                                                    
> >-
> >c
> >-------
> >
> >
> >I am looking for functions in R to estimate the sample size 
> and/or to conduct the 
> >analysis. I have just found an article from Byar in 
> Statistics in Medicine for a 2^3 
> >incomplete factorial design, but I would like not to 
> discover again the wheel..
> >TIA
> >dr. Giovanni Parrinello
> >Section of Medical Statistics
> >Department of Biosciences
> >University of Brescia
> >25127 Viale Europa, 11
> >Brescia Italy
> >Tel: +390303717528
> >Fax: +390303701157
> >
> >
> >
> >	[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html
>  
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From int20h at yahoo.com  Fri Feb  6 16:47:15 2004
From: int20h at yahoo.com (alka seltzer)
Date: Fri, 6 Feb 2004 07:47:15 -0800 (PST)
Subject: [R] How to get the pseudo left inverse of a singular squarem atrix?
Message-ID: <20040206154715.50638.qmail@web13509.mail.yahoo.com>

>I'm rusty, but not *that* rusty here, I hope.
>
>If W (=Z*Z' in your case) is singular, it can not
have >inverse, which by
>definition also mean that nothing multiply by it will
>produce the identity
>matrix (for otherwise it would have an inverse and
>thus nonsingular).
>
>The definition of a generalized inverse is something
>like:  If A is a
>non-null matrix, and G satisfy AGA = A, then G is
>called a generalized
>inverse of A.  This is not unique, but a unique one
>that satisfy some
>additional properties is the Moore-Penrose inverse. 
I >don't know if this is
>what ginv() in MASS returns, as I have not used it
>before.

Andy


The inverse of a Matrix A is defined as a Matrix B
such that B*A=A*B=I and not just B*A=I. But there are
matrices B for singular matrices A such that B*A=I but
A*B != I, therefore there exist "left-inverses" (or
"right-inverses") for non-invertable matrices.

Best Regards

__________________________________




From kjetil at entelnet.bo  Fri Feb  6 16:50:01 2004
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Fri, 06 Feb 2004 11:50:01 -0400
Subject: [R] Converting a Dissimilarity Matrix
In-Reply-To: <4023822A.507@ajtee.uklinux.net>
Message-ID: <40237F69.7919.9D6C4B@localhost>

On 6 Feb 2004 at 12:01, Adam Tee wrote:

?as.dist

Kjetil Halvorsen

> Hi all,
> 
> I'm trying to perform a hierarchical clustering on some
> dissimilarity data that I have but the data matrix I have already
> contains the dissimilarity values.  These values are calculated using
> a separate program.  The dissimilarity matrix in complete with no
> missing values but the hclust, and agnes routines require it in the
> form produced by daisy or dist.  Is there any of converting my
> complete matrix to this format without changing the values??
> 
> 
> Thanks
> 
> Adam
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From tlumley at u.washington.edu  Fri Feb  6 16:30:50 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 6 Feb 2004 07:30:50 -0800 (PST)
Subject: [R] Incomplete Factorial design
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572F021D9@synequanon01>
References: <6C8A8033ABC1E3468048ABC4F13CE572F021D9@synequanon01>
Message-ID: <Pine.A41.4.58.0402060728490.68312@homer05.u.washington.edu>

On Fri, 6 Feb 2004, Simon Fear wrote:

> One could also fit
>
> fit <- lm(y~A*B - 1, data.frame(y=..., A=..., B=..,)
>
> which will give a direct a:b term (as the negative of the
> intercept in Spenser's formulation). Arguably this is more
> natural in a setting where there is no placebo so that
> an intercept term has a less obvious interpretation.
>

I would have though the natural analysis was to compare A+B to B alone and
A+B to A alone with two separate t.tests, and power the analysis for
these.  It's not really a factorial design at all.

	-thomas



From GPetris at uark.edu  Fri Feb  6 16:30:31 2004
From: GPetris at uark.edu (Giovanni Petris)
Date: Fri, 6 Feb 2004 09:30:31 -0600 (CST)
Subject: [R] quantile function
Message-ID: <200402061530.i16FUVSG014049@definetti.uark.edu>


I am trying to `cut' a continuous variable into contiguous classes
containing approximately an equal number of observations. I thought
quantile() was the appropriate function to use in order to find the
breakpoints, but I end up with classes of different sizes - see
example below. Does anybody have an explanation for that? And what is
the `recommended' way of computing what I am looking for?

Example:

> ca$age
 [1] 28 42 46 45 34 44 48 45 38 45 49 45 41 46 49 46 44 48 52 48 45 50 53 57 46
[26] 52 54 57 47 52 55 59 50 54 57 60 51 55 46 63 51 59 48 35 53 59 57 37 55 32
[51] 60 43 59 37 30 47 60 38 34 48 32 38 36 49 33 42 38 58 35 43 39 59 39 43 42
[76] 60 40 44
> table(cut(ca$age,breaks=c(-Inf,quantile(ca$age, seq(0,1,length=11)[-1]))))

(-Inf,35] (35,38.4] (38.4,43]   (43,45] (45,46.5] (46.5,49]   (49,52]   (52,55] 
        9         7        10         8         5        10         7         7 
  (55,59]   (59,63] 
       10         5 

Thanks in advance,
Giovanni

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From tlumley at u.washington.edu  Fri Feb  6 17:04:39 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 6 Feb 2004 08:04:39 -0800 (PST)
Subject: [R] quantile function
In-Reply-To: <200402061530.i16FUVSG014049@definetti.uark.edu>
References: <200402061530.i16FUVSG014049@definetti.uark.edu>
Message-ID: <Pine.A41.4.58.0402060758050.68312@homer05.u.washington.edu>

On Fri, 6 Feb 2004, Giovanni Petris wrote:

>
> I am trying to `cut' a continuous variable into contiguous classes
> containing approximately an equal number of observations. I thought
> quantile() was the appropriate function to use in order to find the
> breakpoints, but I end up with classes of different sizes - see
> example below. Does anybody have an explanation for that? And what is
> the `recommended' way of computing what I am looking for?

Your variable is actually quite discrete, which is causing the problem.
For example, you have two 35s, so the lower groups could only be equal if one
35 was in one group and the other in the other group.

Now, if you want the groups to be equal even at the cost of not depending
just on the value there are at least two possible approaches
 - break ties randomly, for example by jitter()ing the data first
 - order the data by age and then take the first 8, next 8, and so on.

	-thomas


> Example:
>
> > ca$age
>  [1] 28 42 46 45 34 44 48 45 38 45 49 45 41 46 49 46 44 48 52 48 45 50
> 53 57 46  52 54 57 47 52 55 59 50 54 57 60 51 55 46 63 51 59 48 35
> 53 59 57 37 55 32  60 43 59 37 30 47 60 38 34 48 32 38 36 49 33 42
> 38 58 35 43 39 59 39 43 42  60 40 44

> > table(cut(ca$age,breaks=c(-Inf,quantile(ca$age, seq(0,1,length=11)[-1]))))
>
> (-Inf,35] (35,38.4] (38.4,43]   (43,45] (45,46.5] (46.5,49]   (49,52]   (52,55]
>         9         7        10         8         5        10         7         7
>   (55,59]   (59,63]
>        10         5
>
> Thanks in advance,
> Giovanni
>
> --
>
>  __________________________________________________
> [                                                  ]
> [ Giovanni Petris                 GPetris at uark.edu ]
> [ Department of Mathematical Sciences              ]
> [ University of Arkansas - Fayetteville, AR 72701  ]
> [ Ph: (479) 575-6324, 575-8630 (fax)               ]
> [ http://definetti.uark.edu/~gpetris/              ]
> [__________________________________________________]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From spencer.graves at pdf.com  Fri Feb  6 17:17:26 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 06 Feb 2004 08:17:26 -0800
Subject: [R] How to get the pseudo left inverse of a singular squarem
	atrix?
In-Reply-To: <20040206154715.50638.qmail@web13509.mail.yahoo.com>
References: <20040206154715.50638.qmail@web13509.mail.yahoo.com>
Message-ID: <4023BE16.3070106@pdf.com>

      The documentation for "ginv" in MASS says it "Calculates the 
Moore-Penrose generalized inverse of a matrix 'X'."  The theory says 
that for each m x n matrix A, there is a unique n x m matrix G 
satisfying AGA = A and GAG = G.  
(http://mathworld.wolfram.com/Moore-PenroseMatrixInverse.html). 

      Consider the following simple example: 

>  A <- array(c(1,1,0,0), dim=c(2,2))
[2,]  0.0  0.0
>  A
     [,1] [,2]
[1,]    1    0
[2,]    1    0
>  ginv(A)
     [,1] [,2]
[1,]  0.5  0.5
[2,]  0.0  0.0
>  ginv(A)%*%A
     [,1] [,2]
[1,]    1    0
[2,]    0    0
>  A%*%ginv(A)
     [,1] [,2]
[1,]  0.5  0.5
[2,]  0.5  0.5
>  A%*%ginv(A)%*%A
     [,1] [,2]
[1,]    1    0
[2,]    1    0
>  ginv(A)%*%A%*%ginv(A)
     [,1] [,2]
[1,]  0.5  0.5
[2,]  0.0  0.0

      hope this helps.  spencer graves

alka seltzer wrote:

>>I'm rusty, but not *that* rusty here, I hope.
>>
>>If W (=Z*Z' in your case) is singular, it can not
>>    
>>
>have >inverse, which by
>  
>
>>definition also mean that nothing multiply by it will
>>produce the identity
>>matrix (for otherwise it would have an inverse and
>>thus nonsingular).
>>
>>The definition of a generalized inverse is something
>>like:  If A is a
>>non-null matrix, and G satisfy AGA = A, then G is
>>called a generalized
>>inverse of A.  This is not unique, but a unique one
>>that satisfy some
>>additional properties is the Moore-Penrose inverse. 
>>    
>>
>I >don't know if this is
>  
>
>>what ginv() in MASS returns, as I have not used it
>>before.
>>    
>>
>
>Andy
>
>
>The inverse of a Matrix A is defined as a Matrix B
>such that B*A=A*B=I and not just B*A=I. But there are
>matrices B for singular matrices A such that B*A=I but
>A*B != I, therefore there exist "left-inverses" (or
>"right-inverses") for non-invertable matrices.
>
>Best Regards
>
>__________________________________
>

>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From dmurdoch at pair.com  Fri Feb  6 17:26:25 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 06 Feb 2004 11:26:25 -0500
Subject: [R] 0.1 + 0.2 != 0.3 revisited
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572F021D8@synequanon01>
References: <6C8A8033ABC1E3468048ABC4F13CE572F021D8@synequanon01>
Message-ID: <3if720tukrh46rikg23jb4fvh3o2vhoah1@4ax.com>

On Fri, 6 Feb 2004 12:55:05 -0000, "Simon Fear"
<Simon.Fear at synequanon.com> wrote :

>Prompted by Peter Dalgard's recent elegant "intbin" function,
>I have been playing with the extension to converting reals to binary
>representation. The decimal part can be done like this:
>
>decbase <- function(x, n=52, base=2) {
>  if(n) {
>    x <- x*base
>    paste(trunc(x), decbase(x%%1, n-1, base), sep="")
>  }
>}
>
>n=52 default because that's the number of bits in the significand of
>a 64-bit float.

Remember that IEEE double formats are complicated, they're not fixed
point formats.

Both 0.1 and 0.2 are less than 1, so the n=52 count is wrong.  I think
0.1 would be stored as (1 + 0.6)*2^(-4) and 0.2 would be stored as (1
+ 0.6)*2^(-3), whereas 0.3 would be stored as (1 + 0.2)*2^(-2).  You
should expect 56 decimal (binary?) place accuracy on 0.1, 55 place
accuracy on 0.2, and 54 place accuracy on 0.3.  It's not surprising
weird things happen!

Duncan Murdoch



From spencer.graves at pdf.com  Fri Feb  6 16:47:49 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 06 Feb 2004 07:47:49 -0800
Subject: [R] Incomplete Factorial design
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572F021D9@synequanon01>
References: <6C8A8033ABC1E3468048ABC4F13CE572F021D9@synequanon01>
Message-ID: <4023B725.8010209@pdf.com>

      Hi, Simon:  Excellent observation, reinforcing the point that 
interpretation of confounded effects depends on the context. 

      Best Wishes,
      spencer graves

Simon Fear wrote:

>One could also fit
>
>fit <- lm(y~A*B - 1, data.frame(y=..., A=..., B=..,)
>
>which will give a direct a:b term (as the negative of the
>intercept in Spenser's formulation). Arguably this is more
>natural in a setting where there is no placebo so that
>an intercept term has a less obvious interpretation.
>
>  
>
>>-----Original Message-----
>>From: Spencer Graves [mailto:spencer.graves at pdf.com]
>>Sent: 06 February 2004 14:39
>>To: parrinel at med.unibs.it
>>Cc: R-help at stat.math.ethz.ch
>>Subject: Re: [R] Incomplete Factorial design
>>
>>
>>Security Warning: 
>>If you are not sure an attachment is safe to open please contact  
>>Andy on x234. There are 0 attachments with this message. 
>>________________________________________________________________ 
>> 
>>      I assume that means you have two treatments, say A and 
>>B, can be 
>>either absent or present.  The standard analysis codes them 
>>as -1 or +1 
>>for absent or present, respectively.  If you have 
>>observations in all 4 
>>cells, you can write the following equation: 
>>
>>      y(A,B) = b0 + b1*A + b2*B + b12*A*B + error. 
>>
>>      This equation has 4 unknowns, b1, b1, b2 and b12.  If 
>>you have all 
>>4 cells in the 2x2 table, then you can estimate all 4 
>>unknowns.  If you 
>>have data for only 3 cells, the standard analysis pretends 
>>that b12 = 0 
>>and estimates the other three.  If you have only 2 cells, say (both 
>>absent) and (both present), the standard analysis can 
>>estimate b0 plus 
>>either of b1 or b2.  However, in fact, these really estimate (b0+b12) 
>>and (b1+b2).  To understand this, consult any good book that 
>>discusses 
>>confounding with 2-level fractional factorial designs. 
>>
>>      To do this in R, use "lm", as
>>
>>      fit <- lm(y~A+B, data.frame(y=..., A=..., B=..,)
>>
>>      hope this helps. 
>>      spencer graves
>>
>>parrinel at med.unibs.it wrote:
>>
>>    
>>
>>>Hello,
>>>I am planning a study with the main point to evaluate the 
>>>      
>>>
>>interaction of two treatments, 
>>    
>>
>>>but for ethical reasons one cell is empty, that with 
>>>      
>>>
>>patients receaving no treatment at all
>>    
>>
>>>                                                                   
>>>                                                                   
>>>                           Treatment B
>>>                                 
>>>                                                                   
>>>                                                                   
>>>+
>>>-
>>>
>>>Treatment A
>>>+
>>>a
>>>b
>>>
>>>                                                                   
>>>-
>>>c
>>>-------
>>>
>>>
>>>I am looking for functions in R to estimate the sample size 
>>>      
>>>
>>and/or to conduct the 
>>    
>>
>>>analysis. I have just found an article from Byar in 
>>>      
>>>
>>Statistics in Medicine for a 2^3 
>>    
>>
>>>incomplete factorial design, but I would like not to 
>>>      
>>>
>>discover again the wheel..
>>    
>>
>>>TIA
>>>dr. Giovanni Parrinello
>>>Section of Medical Statistics
>>>Department of Biosciences
>>>University of Brescia
>>>25127 Viale Europa, 11
>>>Brescia Italy
>>>Tel: +390303717528
>>>Fax: +390303701157
>>>
>>>
>>>
>>>	[[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! 
>>>      
>>>
>http://www.R-project.org/posting-guide.html
>  
>
>> 
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html  
> 
>Simon Fear 
>Senior Statistician 
>Syne qua non Ltd 
>Tel: +44 (0) 1379 644449 
>Fax: +44 (0) 1379 644445 
>email: Simon.Fear at synequanon.com 
>web: http://www.synequanon.com 
>  
>Number of attachments included with this message: 0 
>  
>This message (and any associated files) is confidential and\...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From d.firth at warwick.ac.uk  Fri Feb  6 17:09:09 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Fri, 6 Feb 2004 16:09:09 +0000
Subject: [R] structured random effects
Message-ID: <CB96E9A6-58BE-11D8-A92F-000A95A6625E@warwick.ac.uk>

Are there facilities in R or packages to estimate the parameters of a 
(generalized) linear mixed model like this one: the design is crossed, 
and response $y_{ij}$ relates to fixed and random effects through a 
linear predictor
\[
       \eta_{ij} = \beta x_{ij} + U_i - U_j
\]
where $U_1, U_2, \ldots$ are iid $N(0, \tau^2)$.

Any suggestions would be welcomed.

David

Professor David Firth
Dept of Statistics
University of Warwick
Coventry CV4 7AL
United Kingdom

Voice: +44 (0)247 657 2581
Fax:   +44 (0)247 652 4532
Web:   http://www.warwick.ac.uk/go/dfirth



From spencer.graves at pdf.com  Fri Feb  6 17:28:38 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 06 Feb 2004 08:28:38 -0800
Subject: [R] structured random effects
In-Reply-To: <CB96E9A6-58BE-11D8-A92F-000A95A6625E@warwick.ac.uk>
References: <CB96E9A6-58BE-11D8-A92F-000A95A6625E@warwick.ac.uk>
Message-ID: <4023C0B6.7010407@pdf.com>

      Have you considered "lme"?  For applications like this, I highly 
recommend Pinheiro and Bates (2000) Mixed-Effects Models in S and S-Plus 
(Springer).  I failed to produce anything with "lme" until I read this 
book. 

      hope this helps.  spencer graves

David Firth wrote:

> Are there facilities in R or packages to estimate the parameters of a 
> (generalized) linear mixed model like this one: the design is crossed, 
> and response $y_{ij}$ relates to fixed and random effects through a 
> linear predictor
> \[
>       \eta_{ij} = \beta x_{ij} + U_i - U_j
> \]
> where $U_1, U_2, \ldots$ are iid $N(0, \tau^2)$.
>
> Any suggestions would be welcomed.
>
> David
>
> Professor David Firth
> Dept of Statistics
> University of Warwick
> Coventry CV4 7AL
> United Kingdom
>
> Voice: +44 (0)247 657 2581
> Fax:   +44 (0)247 652 4532
> Web:   http://www.warwick.ac.uk/go/dfirth
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ssullivan at qedgroupllc.com  Fri Feb  6 18:05:50 2004
From: ssullivan at qedgroupllc.com (Steve Sullivan)
Date: Fri, 6 Feb 2004 12:05:50 -0500
Subject: [R] more or less pager
Message-ID: <D4C203B93FEDF04CA2B493EB08F2E43160BFD4@qeds001.hq.wash.qedgroupllc>

David, try fix() or names() with your dataframe (to view column names +
data and column names, respectively).  

STS

-----Original Message-----
From: David A. van Leeuwen [mailto:davl-s0p0a0m at cistron.nl] 
Sent: Friday, February 06, 2004 10:07 AM
To: r-help at stat.math.ethz.ch
Subject: [R] more or less pager

R-users,

(forgive my return adres)

I've been breaking my head why R---which i find fabulous, by the 
way---does not pipe interactive output through a pager (more or less), 
like it does with help(), or like GNU Octave does with arrays with more 
than terminal height rows. 

Maybe it is my installation (Debian/GNU Linux).  Maybe it is my 
configuration, but i don't think so because with help() it works

## Default pager
PAGER=${PAGER-'/usr/bin/less'}

But i think it really is because R-users apparently don't look at 
dataframes with more than, say, 24 rows.  I always seem to be
intetrested
in column names with some rows of data, so often I type

 > data[1,]

just to see what the columns were called again.

In order to circumvent the problem of data running off the screen, I've 
made a simple hack:

more <- function(x) {
  tmp <- paste("/tmp/R", floor(runif(1,0,1e6)), sep=".")
  sink(tmp)
  print(x)
  sink()
  file.show(tmp, delete.file=TRUE)
}

which isn't the prettiest implementation of `tmpfile', but hey, it 
allows my to type

 > more(data)

Please ignore this if there is a more proper way of doing this in R 
(preferrably by default without the more()), but also please include 
some reference to this under keywords `pager', `more' or `less' in the 
documentation.

Developers, thanks for all the work.

-- 
David A. van Leeuwen			< @ElseWare.nl>

	  Echt stijlvol sterven doe je / bij een ander op de mat
	  Op de dag dat je bezorgd wordt / door het NRC Handelsblad
	
							---Joop Visser

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From edd at debian.org  Fri Feb  6 18:10:25 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 6 Feb 2004 11:10:25 -0600
Subject: [R] more or less pager
In-Reply-To: <4023ADA6.3070401@cistron.nl>
References: <4023ADA6.3070401@cistron.nl>
Message-ID: <20040206171025.GA9673@sonny.eddelbuettel.com>

On Fri, Feb 06, 2004 at 04:07:18PM +0100, David A. van Leeuwen wrote:
> R-users,
> 
> (forgive my return adres)
> 
> I've been breaking my head why R---which i find fabulous, by the 
> way---does not pipe interactive output through a pager (more or less), 
> like it does with help(), or like GNU Octave does with arrays with more 
> than terminal height rows. 
> 
> Maybe it is my installation (Debian/GNU Linux).  Maybe it is my 
> configuration, but i don't think so because with help() it works
> 
> ## Default pager
> PAGER=${PAGER-'/usr/bin/less'}

[ Future Debian R packages will have this default to PAGER-'/usr/bin/pager'
  which is handled by the dpkg-alternatives mechanism; this helps e.g. users
  in the Far East who use jless or jv; and everybody else who may prefer
  most or one of the other pagers. This follows a wishlist request I had
  for octave2.1, and which also makes sense for R. 
  
  Can't help you with the more R-internal request of paging wider than 80col,
  other than with the default answer to just about every UI question: use ESS
  as you then get the benefit if (x)emacs buffers around your session. Plus 
  much much more. It is really worth it, and on Debian only the few
  keystrokes of 'apt-get install ess' away. ]
  
> But i think it really is because R-users apparently don't look at 
> dataframes with more than, say, 24 rows.  I always seem to be intetrested
> in column names with some rows of data, so often I type
> 
> > data[1,]
> 
> just to see what the columns were called again.
> 
> In order to circumvent the problem of data running off the screen, I've 
> made a simple hack:
> 
> more <- function(x) {
>  tmp <- paste("/tmp/R", floor(runif(1,0,1e6)), sep=".")
>  sink(tmp)
>  print(x)
>  sink()
>  file.show(tmp, delete.file=TRUE)
> }
> 
> which isn't the prettiest implementation of `tmpfile', but hey, it 
> allows my to type
> 
> > more(data)

Not bad. But then again, there is ESS :)

Dirk

> 
> Please ignore this if there is a more proper way of doing this in R 
> (preferrably by default without the more()), but also please include 
> some reference to this under keywords `pager', `more' or `less' in the 
> documentation.
> 
> Developers, thanks for all the work.
> 
> -- 
> David A. van Leeuwen			< @ElseWare.nl>
> 
> 	  Echt stijlvol sterven doe je / bij een ander op de mat
> 	  Op de dag dat je bezorgd wordt / door het NRC Handelsblad
> 	
> 							---Joop Visser
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From Ulrich.Halekoh at agrsci.dk  Fri Feb  6 18:19:11 2004
From: Ulrich.Halekoh at agrsci.dk (Ulrich Halekoh)
Date: Fri, 6 Feb 2004 18:19:11 +0100
Subject: [R] erroneous additional weighting in plot.lm for glm objetcs?
Message-ID: <EA09C4B2B0F16E44B8F3311629493C0DCC47CC@DJFPOST01.djf.agrsci.dk>


Hej,

In 'plot.lm' the deviance residuals
for a glm object are  
multiplied by the  square root of the objects weights
in the computation of the standardized deviance residuals.

But the deviance residuals contain already the 
square root of the prior weights as a factor.

Is the weighting in plot.lm for glm-objects erroneous and 
does it yield 
incorrect scale-location plots?


example:
Fitting a normal linear model for observations with
variances proportional to  w .
 
A glm-fit using weights=1/w
yields a scale-location plot which shows defects in the
variance model.

 w<-rep(c(1,25,100),rep(100,3))
 y<-rnorm(300)*sqrt(w)
 k<-glm(y~factor(w),weights=1/w)
 plot(k,which=3)

ulrich


==============================================================
Ulrich Halekoh,  PhD                         Phone: +45 8999 1825
Biometry Research Unit                       Fax:   +45 8999 1300
Danish Institute of Agricultural Sciences    E-mail: ulrich.halekoh at agrsci.dk
Research Centre Foulum, DK-8830 Tjele, Denmark



From kmw at mail.rockefeller.edu  Fri Feb  6 18:19:47 2004
From: kmw at mail.rockefeller.edu (Knut M. Wittkowski)
Date: Fri, 06 Feb 2004 12:19:47 -0500
Subject: [R] quantile function
In-Reply-To: <200402061530.i16FUVSG014049@definetti.uark.edu>
Message-ID: <5.1.0.14.0.20040206121543.076e1f08@imap.rockefeller.edu>

Another problem with the R function "quantile" is that its definition of 
"quantiles" may be not what you expect. Consider the following:

 > x <- matrix(c(1:4))
 > quantile(x,c(0,.25,.5,.75,1))
   0%  25%  50%  75% 100%
1.00 1.75 2.50 3.25 4.00

 > x <- matrix(c(1:6))
 > quantile(x,c(0,.25,.5,.75,1))
   0%  25%  50%  75% 100%
1.00 2.25 3.50 4.75 6.00

 > x <- matrix(c(1:8))
 > quantile(x,c(0,.25,.5,.75,1))
   0%  25%  50%  75% 100%
1.00 2.75 4.50 6.25 8.00

With your implicit definition of quantiles (splitting the data set into 
classes of equal size), each class should have 1.5 observations, so that 
the quantiles should be

 > x <- matrix(c(1:4))
 > equalSizeClasses(x,c(0,.25,.5,.75,1))
   0%  25%  50%  75% 100%
-Inf  1.50 2.50 3.50 +Inf

 > x <- matrix(c(1:6))
 > equalSizeClasses(x,c(0,.25,.5,.75,1))
   0%  25%  50%  75% 100%
-Inf  2.00 3.50 5.00 +Inf

 > x <- matrix(c(1:8))
 > equalSizeClasses(x,c(0,.25,.5,.75,1))
   0%  25%  50%  75% 100%
-Inf  2.50 4.50 6.50 +Inf

Knut

At 09:30 2004-02-06 -0600, Giovanni Petris wrote:

>I am trying to `cut' a continuous variable into contiguous classes
>containing approximately an equal number of observations. I thought
>quantile() was the appropriate function to use in order to find the
>breakpoints, but I end up with classes of different sizes - see
>example below. Does anybody have an explanation for that? And what is
>the `recommended' way of computing what I am looking for?
>
>Example:
>
> > ca$age
>  [1] 28 42 46 45 34 44 48 45 38 45 49 45 41 46 49 46 44 48 52 48 45 50 53 
> 57 46
>[26] 52 54 57 47 52 55 59 50 54 57 60 51 55 46 63 51 59 48 35 53 59 57 37 
>55 32
>[51] 60 43 59 37 30 47 60 38 34 48 32 38 36 49 33 42 38 58 35 43 39 59 39 
>43 42
>[76] 60 40 44
> > table(cut(ca$age,breaks=c(-Inf,quantile(ca$age, seq(0,1,length=11)[-1]))))
>
>(-Inf,35] (35,38.4] (38.4,43]   (43,45] (45,46.5] 
>(46.5,49]   (49,52]   (52,55]
>         9         7        10         8         5        10         7 
>      7
>   (55,59]   (59,63]
>        10         5
>
>Thanks in advance,
>Giovanni
>
>--
>
>  __________________________________________________
>[                                                  ]
>[ Giovanni Petris                 GPetris at uark.edu ]
>[ Department of Mathematical Sciences              ]
>[ University of Arkansas - Fayetteville, AR 72701  ]
>[ Ph: (479) 575-6324, 575-8630 (fax)               ]
>[ http://definetti.uark.edu/~gpetris/              ]
>[__________________________________________________]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Knut M. Wittkowski, PhD,DSc
------------------------------------------
The Rockefeller University, GCRC
Experimental Design and Biostatistics
1230 York Ave #121B, Box 322, NY,NY 10021
+1(212)327-7175, +1(212)327-8450 (Fax)
kmw at rockefeller.edu
http://www.rucares.org/clinicalresearch/dept/biometry/



From jinsong_zh at yahoo.com  Fri Feb  6 17:50:36 2004
From: jinsong_zh at yahoo.com (Jinsong Zhao)
Date: Fri, 6 Feb 2004 08:50:36 -0800 (PST)
Subject: [R] problem to get coefficient from lm()
Message-ID: <20040206165036.62255.qmail@web20804.mail.yahoo.com>

Dear all,

The following is a example that I run and hope to get a linear model.
However, I find the lm() can not give correct coefficients for the
linear model.

I hope it's just my own mistake. Please help. TIA.

Regards,

Jinsong

> x
 [1] 3.760216 3.997288 3.208872 3.985417 3.265704 3.497505 2.923540
3.193937
 [9] 3.102787 3.419574 3.169374 2.928510 3.153821 3.100385 3.768770
3.610583
[17] 3.588902 3.180961 3.415033 3.595447 2.826521 3.283875 3.125694
3.558275
[25] 4.625191 3.735673 4.387571 4.884388 3.067845 2.993892 3.068684
4.166771
[33] 4.680322 4.103344 4.340546 3.685950 4.026451 4.161470 3.696610
4.026815
[41] 3.854591 3.399321 3.492201 3.479075 4.417633 3.579751 3.433551
3.248359
[49] 2.874979 3.123579 3.131758 3.447368 3.086075 3.558168 4.537077
> y
 [1] 4.431 4.560 2.920 4.481 3.295 3.679 2.779 2.654 2.837 3.664 3.421
2.693
[13] 2.624 3.057 4.633 3.807 3.886 3.011 3.873 3.717 2.077 3.324 2.064
3.390
[25] 4.170 3.232 3.114 4.701 3.746 2.880 3.723 4.015 4.881 4.483 4.762
3.834
[37] 4.321 3.837 3.624 4.306 3.466 3.492 3.502 3.510 4.236 3.286 3.657
3.218
[49] 2.840 3.011 3.417 3.625 3.524 3.390 4.296
> g <- lm(y ~ x)
> summary(g)

Call:
lm(formula = y ~ x)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.2736 -0.2094  0.0098  0.2654  0.8642 

Coefficients:
              Estimate Std. Error   t value Pr(>|t|)    
(Intercept) -1.274e-15  4.027e-01 -3.16e-15        1    
x            1.000e+00  1.113e-01     8.982 3.13e-12 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Residual standard error: 0.4179 on 53 degrees of freedom
Multiple R-Squared: 0.6035,     Adjusted R-squared: 0.596 
F-statistic: 80.68 on 1 and 53 DF,  p-value: 3.128e-12 

 

__________________________________


From bates at stat.wisc.edu  Fri Feb  6 18:03:45 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 06 Feb 2004 11:03:45 -0600
Subject: [R] (Novice-) Problem with the plot-function
In-Reply-To: <4022C3CB.8090804@pdf.com>
References: <200402052245.58610.atropin75@t-online.de>
	<4022C3CB.8090804@pdf.com>
Message-ID: <6rvfmkta1a.fsf@bates4.stat.wisc.edu>

Sundar Dorai-Raj <sundar.dorai-raj at pdf.com> writes:

> I think you meant to do
> 
> plot(x, f.x, ...)
> 
> BTW, you've re-invented the wheel. See ?dnorm for evaluating the normal pdf.
> 
> Best,
> Sundar

Even easier is to combine dnorm and curve (although Luke will grimace
at the syntax).

curve(dnorm(x, mean = 0, sd = 1), from = -5, to = 5)

This form allows you to change the mean and the standard deviation.
If you want to pretty it up a bit use

curve(dnorm(x, mean = 0, sd = 1), from = -5, to = 5, las = 1)



From f.harrell at vanderbilt.edu  Fri Feb  6 18:16:44 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 6 Feb 2004 11:16:44 -0600
Subject: [R] quantile function
In-Reply-To: <200402061530.i16FUVSG014049@definetti.uark.edu>
References: <200402061530.i16FUVSG014049@definetti.uark.edu>
Message-ID: <20040206111644.14fffc0f.f.harrell@vanderbilt.edu>

On Fri, 6 Feb 2004 09:30:31 -0600 (CST)
Giovanni Petris <GPetris at uark.edu> wrote:

> 
> I am trying to `cut' a continuous variable into contiguous classes
> containing approximately an equal number of observations. I thought
> quantile() was the appropriate function to use in order to find the
> breakpoints, but I end up with classes of different sizes - see
> example below. Does anybody have an explanation for that? And what is
> the `recommended' way of computing what I am looking for?
> 
> Example:
> 
> > ca$age
>  [1] 28 42 46 45 34 44 48 45 38 45 49 45 41 46 49 46 44 48 52 48 45 50
>  53 57 46
> [26] 52 54 57 47 52 55 59 50 54 57 60 51 55 46 63 51 59 48 35 53 59 57
> 37 55 32[51] 60 43 59 37 30 47 60 38 34 48 32 38 36 49 33 42 38 58 35 43
> 39 59 39 43 42[76] 60 40 44
> > table(cut(ca$age,breaks=c(-Inf,quantile(ca$age,
> > seq(0,1,length=11)[-1]))))
> 
> (-Inf,35] (35,38.4] (38.4,43]   (43,45] (45,46.5] (46.5,49]   (49,52]  
> (52,55] 
>         9         7        10         8         5        10         7   
>              7 
>   (55,59]   (59,63] 
>        10         5 
> 
> Thanks in advance,
> Giovanni
> 
> -- 
> 

The cut2 function in the Hmisc package tries to do this the best it can.

Frank

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From prodrigues at dcc.fc.up.pt  Fri Feb  6 18:36:10 2004
From: prodrigues at dcc.fc.up.pt (Pedro Rodrigues)
Date: 06 Feb 2004 17:36:10 +0000
Subject: [R] nnet problem
In-Reply-To: <OFE25E3B6A.952E54DC-ONC1256E32.004FCC04-C1256E32.005048CC@e-c-s.fr>
References: <OFE25E3B6A.952E54DC-ONC1256E32.004FCC04-C1256E32.005048CC@e-c-s.fr>
Message-ID: <1076088970.3602.27.camel@atlantic.ocean>


I believe you want to fit a nnet model to predict numeric data.

you can try as follows:

xx <- "Matrix of size INPUTS*EXAMPLESTRAIN"
yy <- "Vector of size EXAMPLESTRAIN"
x1 <- "Matrix of size INPUTS*EXAMPLESTEST"

# fit your model like this
nnetmodel <- nnet(x=xx, y=yy, ....)
# or like this only if dealing with a data.frame
nnetmodel <- nnet(outname ~ in1name + ... inNname, ....)

# here numdata will become a vector of size EXAMPLESTEST.
numdata <- predict(nnetmodel, x1) 

Best Regards

Pedro

On Fri, 2004-02-06 at 14:36,
optimisation1.stagiaire at lagardere-active.com wrote:
> 
> 
> 
> Hello everybody,
> 
> I want to use the nnet library and my problem is that the algorithm seems
> to accept only class as target when the neural is fiiting. So the output
> when I use predict.nnet is also a class. Is it possible to have numeric
> variable as target ? If yes, what is the syntax ?
> 
> Thank you.
> 
> 
> Cordialement,
> 
> R?gis CHARIGNON
> 
> 
> **************************************************************************************************************************************************************
> Attention : le present message et toutes les pieces jointes (le "message") sont confidentiels et etablis a l'attention exclusive du ou des destinataire(s) 
> indique(s). Toute autre diffusion ou utilisation non autorisee est interdite. Si vous recevez ce message par erreur, veuillez immediatement en avertir 
> l'expediteur par e-mail en retour, detruire le message et vous abstenir de toute reference aux informations qui y figurent afin d'eviter les sanctions 
> attachees a la divulgation et a l'utilisation d'informations confidentielles. Les messages electroniques sont susceptibles d'alteration. Lagardere SCA 
> et ses filiales declinent toute responsabilite en cas d'alteration ou de falsification du present message.
> 
> Warning : this e-mail and any files attached (the "e-mail") are confidential and intended solely to the named addressee(s). Any unauthorised dissemination 
> or use is strictly prohibited. If you received this e-mail in error, please immediately notify the sender by reply e-mail and then delete the e-mail from 
> your system. Please do not copy, use or make reference to it for any purpose, or disclose its contents to any person : to do so could expose you to sanctions. 
> E-mails can be altered or falsified. Lagardere SCA and its subsidiary companies shall not be liable for any alteration or falsification on this e-mail.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From bates at stat.wisc.edu  Fri Feb  6 19:28:23 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 06 Feb 2004 12:28:23 -0600
Subject: [R] structured random effects
In-Reply-To: <4023C0B6.7010407@pdf.com>
References: <CB96E9A6-58BE-11D8-A92F-000A95A6625E@warwick.ac.uk>
	<4023C0B6.7010407@pdf.com>
Message-ID: <6r7jz0t648.fsf@bates4.stat.wisc.edu>

Spencer Graves <spencer.graves at pdf.com> writes:

>       Have you considered "lme"?  For applications like this, I highly
> recommend Pinheiro and Bates (2000) Mixed-Effects Models in S and
> S-Plus (Springer).  I failed to produce anything with "lme" until I
> read this book.     hope this helps.  spencer graves

Actually lme is better suited to nested designs than to crossed
designs and lme doesn't handle generalized linear mixed models.

GLMM from package lme4 does handle generalized linear mixed models but
does not handle crossed random effects easily.

I'm working on code that will handle nested, crossed and partially
crossed random effects but it will be some time before it appears in a
finished package

> 
> 
> David Firth wrote:
> 
> > Are there facilities in R or packages to estimate the parameters of
> > a (generalized) linear mixed model like this one: the design is
> > crossed, and response $y_{ij}$ relates to fixed and random effects
> > through a linear predictor
> 
> > \[
> >       \eta_{ij} = \beta x_{ij} + U_i - U_j
> > \]
> > where $U_1, U_2, \ldots$ are iid $N(0, \tau^2)$.
> >
> > Any suggestions would be welcomed.
> >
> > David
> >
> > Professor David Firth
> > Dept of Statistics
> > University of Warwick
> > Coventry CV4 7AL
> > United Kingdom
> >
> > Voice: +44 (0)247 657 2581
> > Fax:   +44 (0)247 652 4532
> > Web:   http://www.warwick.ac.uk/go/dfirth
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From jfox at mcmaster.ca  Fri Feb  6 19:33:56 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 06 Feb 2004 13:33:56 -0500
Subject: [R] problem to get coefficient from lm()
In-Reply-To: <20040206165036.62255.qmail@web20804.mail.yahoo.com>
Message-ID: <web-13186284@cgpsrv2.cis.mcmaster.ca>

Dear Jinsong,

Why do you say that the coefficients are wrong? The slope is 1 and the
intercept 0 (within rounding) -- Isn't this what you intended?

John

On Fri, 6 Feb 2004 08:50:36 -0800 (PST)
 Jinsong Zhao <jinsong_zh at yahoo.com> wrote:
> Dear all,
> 
> The following is a example that I run and hope to get a linear model.
> However, I find the lm() can not give correct coefficients for the
> linear model.
> 
> I hope it's just my own mistake. Please help. TIA.
> 
> Regards,
> 
> Jinsong
> 
> > x
>  [1] 3.760216 3.997288 3.208872 3.985417 3.265704 3.497505 2.923540
> 3.193937
>  [9] 3.102787 3.419574 3.169374 2.928510 3.153821 3.100385 3.768770
> 3.610583
> [17] 3.588902 3.180961 3.415033 3.595447 2.826521 3.283875 3.125694
> 3.558275
> [25] 4.625191 3.735673 4.387571 4.884388 3.067845 2.993892 3.068684
> 4.166771
> [33] 4.680322 4.103344 4.340546 3.685950 4.026451 4.161470 3.696610
> 4.026815
> [41] 3.854591 3.399321 3.492201 3.479075 4.417633 3.579751 3.433551
> 3.248359
> [49] 2.874979 3.123579 3.131758 3.447368 3.086075 3.558168 4.537077
> > y
>  [1] 4.431 4.560 2.920 4.481 3.295 3.679 2.779 2.654 2.837 3.664
> 3.421
> 2.693
> [13] 2.624 3.057 4.633 3.807 3.886 3.011 3.873 3.717 2.077 3.324
> 2.064
> 3.390
> [25] 4.170 3.232 3.114 4.701 3.746 2.880 3.723 4.015 4.881 4.483
> 4.762
> 3.834
> [37] 4.321 3.837 3.624 4.306 3.466 3.492 3.502 3.510 4.236 3.286
> 3.657
> 3.218
> [49] 2.840 3.011 3.417 3.625 3.524 3.390 4.296
> > g <- lm(y ~ x)
> > summary(g)
> 
> Call:
> lm(formula = y ~ x)
> 
> Residuals:
>     Min      1Q  Median      3Q     Max 
> -1.2736 -0.2094  0.0098  0.2654  0.8642 
> 
> Coefficients:
>               Estimate Std. Error   t value Pr(>|t|)    
> (Intercept) -1.274e-15  4.027e-01 -3.16e-15        1    
> x            1.000e+00  1.113e-01     8.982 3.13e-12 ***
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> 
> Residual standard error: 0.4179 on 53 degrees of freedom
> Multiple R-Squared: 0.6035,     Adjusted R-squared: 0.596 
> F-statistic: 80.68 on 1 and 53 DF,  p-value: 3.128e-12 
> 
>  
> 
> __________________________________
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From rxg218 at psu.edu  Fri Feb  6 19:49:30 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Fri, 06 Feb 2004 13:49:30 -0500
Subject: [R] a grep/regexpr problem
Message-ID: <1076093370.14208.16.camel@ra.chem.psu.edu>

Hi,
  I'm trying to parse lines of the form:

dan001.hin (0): fingerprint={256, 411, 426, 947, 973, 976}

What I need is the sequence of number between {}. I'm using grep as

match <- grep("{([0-9,\s]*)}",s,perl=T,value=T)

where s is a character vector.

But all I get is the whole string s. I tried using regexpr in an attempt
to get just the sequence I wanted:

match <- regexpr("{([0-9,\s]*)}", s , perl=T) 

but then I get -1 as the return value indicating that there was no
match. 

If grep is able to return the matched element (though I dont know why
the whole string is being returned) why is regexpr failing?

Finally, could anybody provide a hint as to how I should modify the
regex to get the sequence between {}. (I've used the same regex in
Python code to get the sequence and it works fine.)

Thanks,


-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Entropy requires no maintenance.
-- Markoff Chaney



From d.firth at warwick.ac.uk  Fri Feb  6 20:38:55 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Fri, 6 Feb 2004 19:38:55 +0000
Subject: [R] structured random effects
In-Reply-To: <6r7jz0t648.fsf@bates4.stat.wisc.edu>
Message-ID: <1976B446-58DC-11D8-AD15-0050E4C03977@warwick.ac.uk>

Thanks to Douglas and Spencer for their helpful replies.

I take that as a fairly authoritative "no" to my question!  The 
difficulty
in the model I mentioned is not only the crossed design, but the
"homologous" factors (ie i and j take the same values),
and U_i - U_j with the *same* "U" variable
appearing twice with different subscripts in the predictor.

Thanks again -- I am happy to know that If I work on this I'm not
reinventing what already exists.

Best regards,
David

On Friday, Feb 6, 2004, at 18:28 Europe/London, Douglas Bates wrote:

> Spencer Graves <spencer.graves at pdf.com> writes:
>
>>       Have you considered "lme"?  For applications like this, I highly
>> recommend Pinheiro and Bates (2000) Mixed-Effects Models in S and
>> S-Plus (Springer).  I failed to produce anything with "lme" until I
>> read this book.     hope this helps.  spencer graves
>
> Actually lme is better suited to nested designs than to crossed
> designs and lme doesn't handle generalized linear mixed models.
>
> GLMM from package lme4 does handle generalized linear mixed models but
> does not handle crossed random effects easily.
>
> I'm working on code that will handle nested, crossed and partially
> crossed random effects but it will be some time before it appears in a
> finished package
>
>>
>>
>> David Firth wrote:
>>
>>> Are there facilities in R or packages to estimate the parameters of
>>> a (generalized) linear mixed model like this one: the design is
>>> crossed, and response $y_{ij}$ relates to fixed and random effects
>>> through a linear predictor
>>
>>> \[
>>>       \eta_{ij} = \beta x_{ij} + U_i - U_j
>>> \]
>>> where $U_1, U_2, \ldots$ are iid $N(0, \tau^2)$.
>>>
>>> Any suggestions would be welcomed.
>>>
>>> David
>>>
>>> Professor David Firth
>>> Dept of Statistics
>>> University of Warwick
>>> Coventry CV4 7AL
>>> United Kingdom
>>>
>>> Voice: +44 (0)247 657 2581
>>> Fax:   +44 (0)247 652 4532
>>> Web:   http://www.warwick.ac.uk/go/dfirth
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
> -- 
> Douglas Bates                            bates at stat.wisc.edu
> Statistics Department                    608/262-2598
> University of Wisconsin - Madison        
> http://www.stat.wisc.edu/~bates/



From deepayan at stat.wisc.edu  Fri Feb  6 20:46:48 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 6 Feb 2004 13:46:48 -0600
Subject: [R] xyplot (lattice): colours of lines
In-Reply-To: <BAY8-F65yGAfVAB3duo0000f77a@hotmail.com>
References: <BAY8-F65yGAfVAB3duo0000f77a@hotmail.com>
Message-ID: <200402061346.48917.deepayan@stat.wisc.edu>


[I'm CC-ing this to r-help since this is an interesting problem]

I think I finally understand what you mean. You want a different line for each 
subject-treatment combination, but you want the lines to be color-coded only 
on the basis of treatment. Is that correct ?

When you create the new factor 

A$patient <- factor(paste(as.character(A$subject), 
                    as.character(A$treatment), sep ="/"))

it has 134 levels:

> levels(A$patient)
  [1] "100/1"  "10/1"   "101/2"  "102/1"  "103/2"  "104/2"  "105/1"  "11/2"  
  [9] "113/1"  "114/2"  "115/1"  "116/2"  "117/1"  "118/2"  "119/1"  "12/1"  
 [17] "121/2"  "129/1"  "131/2"  "13/2"   "133/2"  "134/1"  "135/1"  "136/2" 
 [25] "139/2"  "140/2"  "141/1"  "144/2"  "145/2"  "146/1"  "148/2"  "149/2" 
 [33] "150/1"  "151/1"  "15/2"   "152/2"  "155/1"  "156/2"  "157/1"  "158/2" 
 [41] "159/1"  "16/1"   "166/2"  "167/1"  "17/1"   "171/1"  "172/2"  "173/1" 
 [49] "174/2"  "175/1"  "176/2"  "179/2"  "180/1"  "181/1"  "18/2"   "182/2" 
 [57] "183/2"  "184/1"  "185/2"  "186/1"  "189/2"  "190/1"  "19/1"   "20/2"  
 [65] "207/1"  "21/1"   "211/2"  "212/1"  "213/2"  "214/1"  "215/2"  "220/1" 
 [73] "221/2"  "22/2"   "222/2"  "224/1"  "225/1"  "227/2"  "24/1"   "26/1"  
 [81] "32/1"   "34/2"   "36/1"   "37/2"   "38/1"   "42/1"   "43/2"   "47/2"  
 [89] "50/1"   "5115/1" "534/2"  "535/1"  "536/2"  "55/2"   "56/1"   "57/2"  
 [97] "58/1"   "587/2"  "60/2"   "61/2"   "62/1"   "63/2"   "64/1"   "65/1"  
[105] "66/2"   "67/1"   "68/2"   "69/1"   "70/2"   "7/1"    "71/1"   "72/1"  
[113] "73/1"   "77/1"   "78/2"   "80/2"   "81/2"   "8/2"    "83/2"   "84/1"  
[121] "85/1"   "86/1"   "87/2"   "88/2"   "89/2"   "90/1"   "91/1"   "9/2"   
[129] "92/2"   "93/1"   "94/2"   "95/2"   "97/1"   "98/2"  

You want to have distinct lines for each of these, but you want the line color 
to be red or green depending only on whether the last digit is 1 or 2. 

One way to do this would be:


plev <- levels(A$patient)
plev <- strsplit(plev, split = "/", fixed = TRUE)
plev <- as.numeric(do.call("rbind", plev)[,2])
col.groups <- c("red", "green")[plev]

xyplot(X ~ time | center, data=A, type="l", 
       panel=panel.superpose, groups=patient,
       col = col.groups, 
       xlab="TIME", ylab="X")


I hope that's what you are looking for.

Deepayan



On Friday 06 February 2004 12:40, you wrote:
> there is still something wrong:
> if you check the plot the two colours do not correspond to treatment
> assignments. For instance,
> center 35 has 2 green lines instead of 1 red and 1 green
> center 21 has 3 red lines and 1 green instead of 2 red and 2 green
> center 41 has 3 downsloping red lines instead of only two
> I am sorry If i was not clear earlier, that is probably for my bad english
> many many thanks, for all this help you are giving me
> Umberto
>
>
> From: Deepayan Sarkar <deepayan at stat.wisc.edu>
>
> >To: "Umberto Maggiore" <umberto_maggiore at hotmail.com>
> >Subject: Re: [R] xyplot (lattice): colours of lines
> >Date: Fri, 6 Feb 2004 12:13:19 -0600
> >
> >
> >That's not consistent with what you asked for earlier.
> >
> >If you need only patients as a grouping factor, just use
> >
> >xyplot(<...>, panel = panel.superpose,
> >        groups = patients, col = c("red", "green"))
> >
> >Deepayan
> >
> >On Friday 06 February 2004 11:37, you wrote:
> > > The problem is that I want only two colours, say green for patients on
> > > treatment=1
> > > and red for patients on treatment=2
> > > Umberto
> > >
> > >
> > > From: Deepayan Sarkar <deepayan at stat.wisc.edu>
> > >
> > > >To: "Umberto Maggiore" <umberto_maggiore at hotmail.com>
> > > >Subject: Re: [R] xyplot (lattice): colours of lines
> > > >Date: Fri, 6 Feb 2004 10:48:33 -0600
> > > >
> > > >On Thursday 05 February 2004 13:52, Umberto Maggiore wrote:
> > > > > It works. However, now I get another odd result: in some plots
> > > > > there are straight lines connecting the end of a line with the
> > > > > beginning of another one.
> > > >
> > > >I don't see the problem (see attached pdf for what I get). Do you get
> > > >something different ? If so, what versions of R and lattice are you
> > > >using ?
> > > >
> > > >Note that A$patients now has 134 levels, with only 7 colors to be
> > > > recycled, so
> > > >you will get repititions.
> > > >
> > > >Deepayan



From Ted.Harding at nessie.mcc.ac.uk  Fri Feb  6 20:58:56 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 06 Feb 2004 19:58:56 -0000 (GMT)
Subject: [R] more or less pager
In-Reply-To: <4023ADA6.3070401@cistron.nl>
Message-ID: <XFMail.040206195856.Ted.Harding@nessie.mcc.ac.uk>

On 06-Feb-04 David A. van Leeuwen wrote:
>## Default pager
> PAGER=${PAGER-'/usr/bin/less'}
> 
> But i think it really is because R-users apparently don't look at 
> dataframes with more than, say, 24 rows.  I always seem to be
> intetrested in column names with some rows of data, so often I type
> 
>  > data[1,]
> 
> just to see what the columns were called again.

I don't think there's a way of getting long output from a raw command
(which "data[1,]" is) to be paged in an interactive terminal (though
I stand to be corrected and would be interested in the details if I
am wrong). If the output is not too long, the scroll bar on the xterm
running R (or Shift-PgUp/Shift-PgDn) will allow you to look at what
has scrolled up off the screen.

> In order to circumvent the problem of data running off the screen, I've
> made a simple hack:
> 
> more <- function(x) {
> ...
> }
> 
> which isn't the prettiest implementation of `tmpfile', but hey, it 
> allows my to type
> 
>  > more(data)

Since [above] your default pager is 'less', you can do

  page(data)

without defining a new function for it. See "?page". (Here, "data"
is no longer a "raw command" since it is wrapped in "page").

You may also be interested in the following, which I owe to helpful
people on the R list. In my ~/.Rprofile I have the following lines:

.xthelp <- function() {
    tdir <- tempdir()
    pgr <- paste(tdir, "/pgr", sep="")
    con <- file(pgr, "w")
    cat("#! /bin/bash\n", file=con)
    cat("export HLPFIL=`mktemp ", tdir, "/R_hlp.XXXXXX`\n", sep="",
        file=con)
    cat("cat > $HLPFIL\nxterm -e less $HLPFIL &\n", file=con)
    close(con)
    system(paste("chmod 755 ", pgr, sep=""))
    options(pager=pgr)
}
.xthelp()
rm(.xthelp)

After these have been read in and executed at R startup, the command

  page(data)

will open a separate xterm window in which the output from "data"
will be displayed via 'less'. The same applies if you look up
something R-ish using the "?" help command and the "help.search"
command.

Hoping this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 06-Feb-04                                       Time: 19:58:56
------------------------------ XFMail ------------------------------



From Amer.Siddique at ssa.gov  Fri Feb  6 21:10:46 2004
From: Amer.Siddique at ssa.gov (Siddique, Amer)
Date: Fri, 6 Feb 2004 14:10:46 -0600 
Subject: [R] vector of factors to POSIXlt
Message-ID: <F151C5EFCA66314D9FE66CB7199F4AADE0EE51@sad6cd1.ch.ssa.gov>

hello,
I have a vector of factors
> str(rcptdt)
 Factor w/ 51 levels "1/10/03","1/13/03",..:
> length(rcptdt)
[1] 87

which i want to convert to class POSIXlt to extract the day, so:
a1<-format(rcptdt,"%m/%d/%y")
> length(a1)
[1] 87

and:
a2<-strptime(a1, "%m/%d/%y")
str(a2)
`POSIXlt', format: chr [1:87] "2002-04-18" "2002-07-19" "2002-08-02"
"2002-08-14" ...
> a2[1]-a2[2]
Time difference of -92 days

but the length differs 
> length(a2)
[1] 9

and i cant update rcptdt...

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    8.1            
year     2003           
month    11             
day      21             
language R 

thanks,

amer
research analyst
disability det. bureau
madtown-wi-usa



From rxg218 at psu.edu  Fri Feb  6 21:14:03 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Fri, 06 Feb 2004 15:14:03 -0500
Subject: [R] a grep/regexpr problem
Message-ID: <1076098442.14601.0.camel@ra.chem.psu.edu>

(Its seems it did'nt get posted the first time around)

Hi,
  I'm trying to parse lines of the form:

dan001.hin (0): fingerprint={256, 411, 426, 947, 973, 976}

What I need is the sequence of number between {}. I'm using grep as

match <- grep("{([0-9,\s]*)}",s,perl=T,value=T)

where s is a character vector.
But all I get is the whole string s. I tried using regexpr in an attempt
to get just the sequence I wanted:

match <- regexpr("{([0-9,\s]*)}", s , perl=T) 

but then I get -1 as the return value indicating that there was no
match. 

If grep is able to return the matched element (though I dont know why
the whole string is being returned) why is regexpr failing?

Finally, could anybody provide a hint as to how I should modify the
regex to get the sequence between {}. (I've used the same regex in
Python code to get the sequence and it works fine.)

Thanks,


-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
A motion to adjourn is always in order.



From Icabalceta_j at wlf.state.la.us  Fri Feb  6 22:07:07 2004
From: Icabalceta_j at wlf.state.la.us (Icabalceta, Jorge L.)
Date: Fri, 6 Feb 2004 15:07:07 -0600 
Subject: [R] rgamma question
Message-ID: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B3@wlfnt1.wlf.state.la.us>

Sorry to bother you. I am sort of confused with the random number generation
from a gamma distribution. For some reason, if a variable X~gamma(shape,
scale)I have been told that the mean mu can be eithe mu=shape/scale or
mu=shape*scale. Why is that so? This is making me have doubt about the
random generation I am using:

1.- The first variable I have is the precision (h) (the inverse of the
variance)distributed as:
h~gamma((T-2)/2, SSE/2) where T is the number of observations and SSE is the
sum of square errors. How do I draw random number in R with this
information. How do I plug this into 
rgamma(n,shape,scale)?

2.- The second variable is L^-1 ~ gamma(T+1, vi-ln(r*)^-1) (please, don't
mind my no explanation for the terms used in the shape and scale
parameters). Again, How do I plug this into 
rgamma(n,shape,scale)?

3.- I am having a problem putting the results of each iteration from for(i
1:11000) into samp. For some reason I get 10000 identical values for each
column. What am I doing wrong? To see what the problem is you can try to run
the program. Attached is the data I am using, the program with  comments and
without them.

I appreciate your help.
Jorge

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: trans3_1_4g1.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040206/e8b0538d/trans3_1_4g1.txt
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: stoch_fron.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040206/e8b0538d/stoch_fron.txt
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: stoch_fron-c.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040206/e8b0538d/stoch_fron-c.txt

From White.Denis at epamail.epa.gov  Fri Feb  6 22:57:26 2004
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Fri, 06 Feb 2004 13:57:26 -0800
Subject: [R] column names in matrix vs. data frame in R 1.8
Message-ID: <OF3DABCB1C.C509CD02-ON88256E32.00781A2F-88256E32.00789BB3@epamail.epa.gov>





Is the difference in behavior below, introduced in 1.8, inconsistent or,
at least, undesirable?  I couldn't find this in the NEWS.

On the one hand,

> a <- matrix (1:4, nrow=2)
> a <- data.frame (a)
> names (a) <- c("break","next")
> names (a)
[1] "break" "next"

On the other,

> a <- matrix (1:4, nrow=2)
> dimnames(a) <- list (1:2, c("break","next"))
> a <- data.frame (a)
> names(a)
[1] "break." "next."

thanks,
Denis



From tlumley at u.washington.edu  Fri Feb  6 23:09:21 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 6 Feb 2004 14:09:21 -0800 (PST)
Subject: [R] rgamma question
In-Reply-To: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B3@wlfnt1.wlf.state.la.us>
References: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B3@wlfnt1.wlf.state.la.us>
Message-ID: <Pine.A41.4.58.0402061405390.91302@homer10.u.washington.edu>

On Fri, 6 Feb 2004, Icabalceta, Jorge L. wrote:

> Sorry to bother you. I am sort of confused with the random number generation
> from a gamma distribution. For some reason, if a variable X~gamma(shape,
> scale)I have been told that the mean mu can be eithe mu=shape/scale or
> mu=shape*scale. Why is that so?

It isn't.  The mean is always shape*scale.  However, the notation
Gamma(alpha,beta) is ambiguous.  Some people use beta=scale (in which
case mean=alpha*beta)  and others use beta=1/scale (in which case
mean=alpha/beta).  A few people even use use alpha=mean, beta=variance,
but they usually know who they are.


	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From alex_s_42 at yahoo.com  Fri Feb  6 23:18:41 2004
From: alex_s_42 at yahoo.com (Alexander Sirotkin [at Yahoo])
Date: Fri, 6 Feb 2004 14:18:41 -0800 (PST)
Subject: [R] problem with bagging
Message-ID: <20040206221841.76904.qmail@web60001.mail.yahoo.com>

I'm having the most weird problem with bagging
function.
For some unknown reason it does not improve the
classification (compared to rpart), but instead gives
much worse results !

Running rpart on my data gives error rate of about 0.3
and bagging, instead of improving this results, gives
error rate of 0.9 !!! 

I'm running both rpart and bagging with exactly the
same parameters, I even tried to run bagging() with
nbagg=1, which should be identical to rpart, but still
- bagging gives this terrible error rate.

Any help would be appriciated.



From rxg218 at psu.edu  Fri Feb  6 23:19:00 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Fri, 06 Feb 2004 17:19:00 -0500
Subject: [R] error message from regsubsets
Message-ID: <1076105940.14712.8.camel@ra.chem.psu.edu>

Hi, I'm using regsubsets and it works fine when nvmax = 4. However when
I go for any value above 4, I get the error:

Warning message:
XHAUST returned error code -999 in: leaps.exhaustive(a, really.big =
really.big)

I'm calling regsubsets as:

lp <- regsubsets(x,y,nbest=1,nvmax=5,intercept=T,really.big=T,
method="exhaustive")

x is a data.frame with 40 variables and 277 observations (in the rows)
and y is a vector of length 277. The manual mentions that really.big
should be TRUE when there are more than 50 variables. But even if when I
set it to FALSE in the above command it still fails with the error
mesage.
Thanks

Could anybody explain what this error means?
-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Enzymes are things invented by biologists that explain things which
otherwise require harder thinking.
-- Jerome Lettvin



From Venherm.Borchers at t-online.de  Fri Feb  6 23:48:24 2004
From: Venherm.Borchers at t-online.de (Hans W Borchers)
Date: Fri, 06 Feb 2004 23:48:24 +0100
Subject: [R] Savitzky-Golay smoothing -- an R implementation
Message-ID: <402419B8.2080408@t-online.de>

As the request for the Savitzky-Golay Algorithm in R has come up several
times, I here include my implementation based on code written for Matlab.
Savitzky-Golay uses the pseudo-inverse pinv() of a matrix. There is an
'generalized inverse' ginv() in the MASS package, but I use a simpler form
because I didn't want to 'require' MASS any time I apply Savitzky-Golay.

Savitzky-Golay is not only a good method for chemical engineering, it can
successfully be applied to smooth process data. One approach is to determine
the noise level in a time series (ACF, winGamma, ...) and then choose the
parameter fl such that the difference between the time series and its
Savitzky-Golay approximation reflects the noise level.

I would be glad to hear about comments and improvements.

Hans W. Borchers
ABB Corporate Research

P. S.:   Example:

    t  <- sin(2*pi*(1:1000)/200)
    t1 <- t + rnorm(1000)/10
    t2 <- sav.gol(t1, 51)
    plot(1:1000, t1)
    lines(1:1000, t,  col="blue")
    lines(1:1000, t2, col="red")

# ----------------------------------------------------------------------
#   Savitzky-Golay Algorithm
# ----------------------------------------------------------------------
# T2 <- sav.gol(T, fl, forder=4, dorder=0);
#
# Polynomial filtering method of Savitzky and Golay
# See Numerical Recipes, 1992, Chapter 14.8, for details.
#
# T      = vector of signals to be filtered
#          (the derivative is calculated for each ROW)
# fl     = filter length (for instance fl = 51..151)
# forder = filter order (2 = quadratic filter, 4= quartic)
# dorder = derivative order (0 = smoothing, 1 = first derivative, etc.)
#
sav.gol <- function(T, fl, forder=4, dorder=0)
{
    m <- length(T)
    dorder <- dorder + 1

    # -- calculate filter coefficients --
    fc <- (fl-1)/2                          # index: window left and right
    X  <- outer(-fc:fc, 0:forder, FUN="^")  # polynomial terms and 
coefficients
    Y  <- pinv(X);                          # pseudoinverse

    # -- filter via convolution and take care of the end points --
    T2 <- convolve(T, rev(Y[dorder,]), type="o")    # convolve(...)
    T2 <- T2[(fc+1):(length(T2)-fc)]
}
#-----------------------------------------------------------------------
#   *** PseudoInvers of a Matrix ***
#   using singular value decomposition
#
pinv <- function (A)
{
    s <- svd(A)
    # D <- diag(s$d); Dinv <- diag(1/s$d)
    # U <- s$u; V <- s$v
    # A = U D V'
    # X = V Dinv U'
    s$v %*% diag(1/s$d) %*% t(s$u)
}
#-----------------------------------------------------------------------



From p.dalgaard at biostat.ku.dk  Fri Feb  6 23:54:08 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 Feb 2004 23:54:08 +0100
Subject: [R] vector of factors to POSIXlt
In-Reply-To: <F151C5EFCA66314D9FE66CB7199F4AADE0EE51@sad6cd1.ch.ssa.gov>
References: <F151C5EFCA66314D9FE66CB7199F4AADE0EE51@sad6cd1.ch.ssa.gov>
Message-ID: <x23c9nlsz3.fsf@biostat.ku.dk>

"Siddique, Amer" <Amer.Siddique at ssa.gov> writes:

> hello,
> I have a vector of factors
> > str(rcptdt)
>  Factor w/ 51 levels "1/10/03","1/13/03",..:
> > length(rcptdt)
> [1] 87
> 
> which i want to convert to class POSIXlt to extract the day, so:
> a1<-format(rcptdt,"%m/%d/%y")

Eh? Why? 

A simple as.character() should do it. The format string has no effect.

> > length(a1)
> [1] 87
> 
> and:
> a2<-strptime(a1, "%m/%d/%y")
> str(a2)
> `POSIXlt', format: chr [1:87] "2002-04-18" "2002-07-19" "2002-08-02"
> "2002-08-14" ...
> > a2[1]-a2[2]
> Time difference of -92 days
> 
> but the length differs 
> > length(a2)
> [1] 9
> 
> and i cant update rcptdt...

as.POSIXct(...) is needed, I believe.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From sfalcon at fhcrc.org  Sat Feb  7 00:31:06 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 6 Feb 2004 15:31:06 -0800
Subject: [R] a grep/regexpr problem
In-Reply-To: <1076093370.14208.16.camel@ra.chem.psu.edu>
References: <1076093370.14208.16.camel@ra.chem.psu.edu>
Message-ID: <20040206233105.GV2227@queenbee.fhcrc.org>

Is this what you're looking for?
    > s = "dan001.hin (0): fingerprint={256, 411, 426, 947, 973, 976}"
    > sub(".*{([0-9,\\s]+)}", "\\1", s, perl=T)
    [1] "256, 411, 426, 947, 973, 976"

+ seth

On Fri, Feb 06, 2004 at 01:49:30PM -0500, Rajarshi Guha wrote:
> Hi,
>   I'm trying to parse lines of the form:
> 
> dan001.hin (0): fingerprint={256, 411, 426, 947, 973, 976}
> 
> What I need is the sequence of number between {}. I'm using grep as
> 
> match <- grep("{([0-9,\s]*)}",s,perl=T,value=T)
> 
> where s is a character vector.
> 
> But all I get is the whole string s. I tried using regexpr in an attempt
> to get just the sequence I wanted:
> 
> match <- regexpr("{([0-9,\s]*)}", s , perl=T) 
> 
> but then I get -1 as the return value indicating that there was no
> match. 
> 
> If grep is able to return the matched element (though I dont know why
> the whole string is being returned) why is regexpr failing?
> 
> Finally, could anybody provide a hint as to how I should modify the
> regex to get the sequence between {}. (I've used the same regex in
> Python code to get the sequence and it works fine.)
> 
> Thanks,
> 
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> Entropy requires no maintenance.
> -- Markoff Chaney
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From bates at stat.wisc.edu  Sat Feb  7 01:21:53 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 06 Feb 2004 18:21:53 -0600
Subject: [R] column names in matrix vs. data frame in R 1.8
In-Reply-To: <OF3DABCB1C.C509CD02-ON88256E32.00781A2F-88256E32.00789BB3@epamail.epa.gov>
References: <OF3DABCB1C.C509CD02-ON88256E32.00781A2F-88256E32.00789BB3@epamail.epa.gov>
Message-ID: <6rptcrrb6m.fsf@bates4.stat.wisc.edu>

White.Denis at epamail.epa.gov writes:

> Is the difference in behavior below, introduced in 1.8, inconsistent or,
> at least, undesirable?  I couldn't find this in the NEWS.
> 
> On the one hand,
> 
> > a <- matrix (1:4, nrow=2)
> > a <- data.frame (a)
> > names (a) <- c("break","next")
> > names (a)
> [1] "break" "next"
> 
> On the other,
> 
> > a <- matrix (1:4, nrow=2)
> > dimnames(a) <- list (1:2, c("break","next"))
> > a <- data.frame (a)
> > names(a)
> [1] "break." "next."

Works fine if you don't use keywords as column names

> a <- matrix (1:4, nrow=2)
> dimnames(a) <- list (1:2, c("foo","bar"))
> b <- data.frame(a)
> names(b)
[1] "foo" "bar"

The difference in the result for your example has to do with an extra
step in the second case to obtain a legitimate name that can be used
with the $ operator.  R generates a syntax error for

a$break

but not for 

a$break.



From scott.rifkin at yale.edu  Sat Feb  7 01:50:22 2004
From: scott.rifkin at yale.edu (Scott Rifkin)
Date: Fri, 6 Feb 2004 19:50:22 -0500 (EST)
Subject: [R] display functions in groupedData and lme
Message-ID: <Pine.LNX.4.44.0402061944580.32158-100000@ajax.its.yale.edu>

I'm trying to set up a mixed model to solve using lme.  It will have 3 
fixed effects, two random effects and two interaction terms. 

I've been reading Pinheiro's and Bates's book on the nmle library, but
find the part about display functions to be unclear.  When creating a 
groupedData object from a data.frame, you need to enter a function of the 
form: response ~primary|grouping

Does this display function serve any purpose later on when specifying the 
model in the call to lme?  If so, how would I include more terms in 
primary or grouping (I tried primary1+primary2+... as per one post in the 
archives, but it didn't work).  If not, is it just for purposes of 
displaying the data?

Thanks much,
Scott Rifkin



From xma at arcturusag.com  Sat Feb  7 01:52:11 2004
From: xma at arcturusag.com (Xiao-Jun Ma)
Date: Fri, 6 Feb 2004 16:52:11 -0800 
Subject: [R] knn using custom distance metric
Message-ID: <BBAF0DEC119BD41193C100B0D0788DFE3FD02B@GENOME>

Hi,

There are two packages providing knn classification: class and knnTree.
However, it seems both uses Eucleadian distances only. How can I uses a
custom distance function with either package?

Thanks,

Xiao-Jun



From ggrothendieck at myway.com  Sat Feb  7 03:20:52 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri,  6 Feb 2004 21:20:52 -0500 (EST)
Subject: [R] more or less pager
Message-ID: <20040207022052.8003E3967@mprdmxin.myway.com>



str() is also useful.

---
Date:   Fri, 6 Feb 2004 12:05:50 -0500 
From:   Steve Sullivan <ssullivan at qedgroupllc.com>
[ Add to Address Book | Block Address | Report as Spam ] 
To:   <r-help at stat.math.ethz.ch> 
Subject:   RE: [R] more or less pager 

 
David, try fix() or names() with your dataframe (to view column names +
data and column names, respectively). 

STS

-----Original Message-----
From: David A. van Leeuwen [mailto:davl-s0p0a0m at cistron.nl] 
Sent: Friday, February 06, 2004 10:07 AM
To: r-help at stat.math.ethz.ch
Subject: [R] more or less pager

R-users,

(forgive my return adres)

I've been breaking my head why R---which i find fabulous, by the 
way---does not pipe interactive output through a pager (more or less), 
like it does with help(), or like GNU Octave does with arrays with more 
than terminal height rows. 

Maybe it is my installation (Debian/GNU Linux). Maybe it is my 
configuration, but i don't think so because with help() it works

## Default pager
PAGER=${PAGER-'/usr/bin/less'}

But i think it really is because R-users apparently don't look at 
dataframes with more than, say, 24 rows. I always seem to be
intetrested
in column names with some rows of data, so often I type

> data[1,]

just to see what the columns were called again.

In order to circumvent the problem of data running off the screen, I've 
made a simple hack:

more <- function(x) {
tmp <- paste("/tmp/R", floor(runif(1,0,1e6)), sep=".")
sink(tmp)
print(x)
sink()
file.show(tmp, delete.file=TRUE)
}

which isn't the prettiest implementation of `tmpfile', but hey, it 
allows my to type

> more(data)

Please ignore this if there is a more proper way of doing this in R 
(preferrably by default without the more()), but also please include 
some reference to this under keywords `pager', `more' or `less' in the 
documentation.

Developers, thanks for all the work.

-- 
David A. van Leeuwen               < @ElseWare.nl>

      Echt stijlvol sterven doe je / bij een ander op de mat
      Op de dag dat je bezorgd wordt / door het NRC Handelsblad
     
                                   ---Joop Visser



From jinsong_zh at yahoo.com  Sat Feb  7 03:35:23 2004
From: jinsong_zh at yahoo.com (Jinsong Zhao)
Date: Fri, 6 Feb 2004 18:35:23 -0800 (PST)
Subject: [R] problem to get coefficient from lm()
In-Reply-To: <web-13186284@cgpsrv2.cis.mcmaster.ca>
Message-ID: <20040207023523.67035.qmail@web20808.mail.yahoo.com>

Dear John,

Thank you very much for your response. I made a mistake for my
careless. I used the same data in Excel, and regressed x on y, and got
a different equation, and then compared it to what I got in R.

Regards,
Jinsong

--- John Fox <jfox at mcmaster.ca> wrote:
> Dear Jinsong,
> 
> Why do you say that the coefficients are wrong? The slope is 1 and
> the
> intercept 0 (within rounding) -- Isn't this what you intended?
> 
> John
>



From ggrothendieck at myway.com  Sat Feb  7 03:51:39 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri,  6 Feb 2004 21:51:39 -0500 (EST)
Subject: [R] vector of factors to POSIXlt
Message-ID: <20040207025139.53B203960@mprdmxin.myway.com>


These are the 9 elements of POSIXlt.
For example, try this to see the 9 components:

   unclass(a2)

The day of the month, which is what
you are looking for, is a2$mday .

If you want an 87 element vector of dates you probably
want to store them as POSIXct:

   length(as.POSIXct(a2))

or as chron dates:

   require(chron)
   length(chron(as.character(rcptdt)))

Note that you could also get the day of the month this way:

   require(chron)
   month.day.year(chron(as.character(rcptdt)))$day

Also note that your format call can be shortened to format(rcptdt)
or as.character(rcptdt) since, at that point, you are not yet dealing
with dates.

---
Date:   Fri, 6 Feb 2004 14:10:46 -0600  
From:   Siddique, Amer <Amer.Siddique at ssa.gov>
To:   R (r-help at stat.math.ethz.ch) <r-help at stat.math.ethz.ch> 
Subject:   [R] vector of factors to POSIXlt 

 
hello,
I have a vector of factors
> str(rcptdt)
Factor w/ 51 levels "1/10/03","1/13/03",..:
> length(rcptdt)
[1] 87

which i want to convert to class POSIXlt to extract the day, so:
a1<-format(rcptdt,"%m/%d/%y")
> length(a1)
[1] 87

and:
a2<-strptime(a1, "%m/%d/%y")
str(a2)
`POSIXlt', format: chr [1:87] "2002-04-18" "2002-07-19" "2002-08-02"
"2002-08-14" ...
> a2[1]-a2[2]
Time difference of -92 days

but the length differs 
> length(a2)
[1] 9

and i cant update rcptdt...

> version
_ 
platform i386-pc-mingw32
arch i386 
os mingw32 
system i386, mingw32 
status 
major 1 
minor 8.1 
year 2003 
month 11 
day 21 
language R 

thanks,

amer
research analyst
disability det. bureau
madtown-wi-usa



From andy_liaw at merck.com  Sat Feb  7 03:55:55 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 6 Feb 2004 21:55:55 -0500
Subject: [R] knn using custom distance metric
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7747@usrymx25.merck.com>

What I have done is made a copy of the R and C functions, renamed them, and
modified the C code to compute the distance desired.  Very easy to do if you
know some C.

Andy

> From: Xiao-Jun Ma
> 
> Hi,
> 
> There are two packages providing knn classification: class 
> and knnTree.
> However, it seems both uses Eucleadian distances only. How 
> can I uses a
> custom distance function with either package?
> 
> Thanks,
> 
> Xiao-Jun
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ggrothendieck at myway.com  Sat Feb  7 04:00:08 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri,  6 Feb 2004 22:00:08 -0500 (EST)
Subject: [R] a grep/regexpr problem
Message-ID: <20040207030008.1DC1239B2@mprdmxin.myway.com>



Try this:

gsub(".*{|}","",s)

which deletes everything up to and including the { and then deletes
the }.

---
Date:   Fri, 06 Feb 2004 13:49:30 -0500 
From:   Rajarshi Guha <rxg218 at psu.edu>
To:   R <r-help at stat.math.ethz.ch> 
Subject:   [R] a grep/regexpr problem 

 
Hi,
I'm trying to parse lines of the form:

dan001.hin (0): fingerprint={256, 411, 426, 947, 973, 976}

What I need is the sequence of number between {}. I'm using grep as

match <- grep("{([0-9,\s]*)}",s,perl=T,value=T)

where s is a character vector.

But all I get is the whole string s. I tried using regexpr in an attempt
to get just the sequence I wanted:

match <- regexpr("{([0-9,\s]*)}", s , perl=T) 

but then I get -1 as the return value indicating that there was no
match. 

If grep is able to return the matched element (though I dont know why
the whole string is being returned) why is regexpr failing?

Finally, could anybody provide a hint as to how I should modify the
regex to get the sequence between {}. (I've used the same regex in
Python code to get the sequence and it works fine.)

Thanks,


-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>;
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Entropy requires no maintenance.
-- Markoff Chaney



From ajayshah at mayin.org  Sat Feb  7 06:17:27 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Sat, 07 Feb 2004 10:47:27 +0530
Subject: [R] Subset function of lm() does not seem to work
Message-ID: <E1ApKqN-0004q2-00@sanna.igidr.ac.in>

Folks,

I have an elementary question about  the lm() function, where I'm
trying to exploit the "subset" feature, to make it use only a subset
of the observations. My code is:

  ----------------------------------------------------------------------
  A <- read.table(file="datafile.2",
         col.names=c("date","dlinrchf","dlusdchf","dljpychf","dldemchf"))
  # The file datafile.2 has 100 observations.
  # I want to do a regression using the first 25 only

  # Subset vector : the 1st 25 are on, the remaining 75 are off.
  window = c(rep(1,25), rep(0,75))

  model <- lm(dlinrchf ~ dlusdchf + dljpychf + dldemchf, A, window)
  summary(model)
  ----------------------------------------------------------------------

This doesn't work: I get --

  Coefficients: (3 not defined because of singularities)
                Estimate Std. Error    t value Pr(>|t|)    
  (Intercept) -3.088e-03  1.384e-19 -2.232e+16   <2e-16 ***
  dlusdchf            NA         NA         NA       NA    
  dljpychf            NA         NA         NA       NA    
  dldemchf            NA         NA         NA       NA    

I have tested using alternative software (stata) and the 1st 25
observations are quite fine for doing a regression. I find that even
if I set window to rep(1,100) (i.e. a vector of 100 ones) the lm()
does not work.

I guess I'm making some mistake in using the "subset" capability of
lm(). Any help will be most appreciated...



From p.dalgaard at biostat.ku.dk  Sat Feb  7 12:00:46 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 07 Feb 2004 12:00:46 +0100
Subject: [R] Subset function of lm() does not seem to work
In-Reply-To: <E1ApKqN-0004q2-00@sanna.igidr.ac.in>
References: <E1ApKqN-0004q2-00@sanna.igidr.ac.in>
Message-ID: <x2u123jgrl.fsf@biostat.ku.dk>

Ajay Shah <ajayshah at mayin.org> writes:

>   # Subset vector : the 1st 25 are on, the remaining 75 are off.
>   window = c(rep(1,25), rep(0,75))
> 
>   model <- lm(dlinrchf ~ dlusdchf + dljpychf + dldemchf, A, window)
>   summary(model)
>   ----------------------------------------------------------------------
> 
> This doesn't work: I get --
[singular model fit snipped]

Subsetting works just like indexing, and:

> window <- c(rep(1,25), rep(0,75))
> x <- rnorm(100)
> x[window]
 [1] 0.1900275 0.1900275 0.1900275 0.1900275 0.1900275 0.1900275 0.1900275
 [8] 0.1900275 0.1900275 0.1900275 0.1900275 0.1900275 0.1900275 0.1900275
[15] 0.1900275 0.1900275 0.1900275 0.1900275 0.1900275 0.1900275 0.1900275
[22] 0.1900275 0.1900275 0.1900275 0.1900275

This is because

> x[0]
numeric(0)
> x[1]
[1] 0.1900275

whereas

> window <- c(rep(TRUE,25), rep(FALSE,75))
> x[window]
 [1]  0.19002751  0.78343198 -0.52160803 -0.89006812 -1.00943372 -0.28583173
 [7]  0.68715861  0.92054258 -0.61218864 -0.20847005 -0.34776935 0.49181302
[13] -0.70108931 -1.27045238  1.28170084 -0.43450470 -0.77251777 -0.73847935
[19]  1.69325725  1.40293178 -1.10930475  0.61299845  1.15125407 -0.02241302
[25]  0.22170428

and window <- 1:25 works as well.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jfox at mcmaster.ca  Sat Feb  7 14:25:12 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 07 Feb 2004 08:25:12 -0500
Subject: [R] display functions in groupedData and lme
In-Reply-To: <Pine.LNX.4.44.0402061944580.32158-100000@ajax.its.yale.edu
 >
Message-ID: <5.1.0.14.2.20040207081952.01ff97b8@127.0.0.1>

Dear Scott,

I believe that normally the display formula is just used to construct 
graphs of the data, although when a grouped-data object is passed in the 
data argument to lme(), the grouping structure can be obtained from the 
object and need not be specified explicitly. As well, it is possible to 
specify additional "outer" and "inner" covariates beyond the principal 
covariate given in the display formula, and these can be used in graphs of 
the data. All this is described, if I remember right, in the section on 
grouped-data objects in Pinheiro and Bates.

I hope that this helps,
  John

At 07:50 PM 2/6/2004 -0500, Scott Rifkin wrote:
>I'm trying to set up a mixed model to solve using lme.  It will have 3
>fixed effects, two random effects and two interaction terms.
>
>I've been reading Pinheiro's and Bates's book on the nmle library, but
>find the part about display functions to be unclear.  When creating a
>groupedData object from a data.frame, you need to enter a function of the
>form: response ~primary|grouping
>
>Does this display function serve any purpose later on when specifying the
>model in the call to lme?  If so, how would I include more terms in
>primary or grouping (I tried primary1+primary2+... as per one post in the
>archives, but it didn't work).  If not, is it just for purposes of
>displaying the data?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From marko at astro.cornell.edu  Sat Feb  7 17:45:16 2004
From: marko at astro.cornell.edu (Marko Krco)
Date: Sat, 7 Feb 2004 11:45:16 -0500 (EST)
Subject: [R] Newbie help with calling R from C programs
Message-ID: <Pine.GSO.4.31.0402071130060.826-100000@katana.astro.cornell.edu>

Hi,

I'm a new user of R (since yesterday) and I'd like to see if I can use it
in my codes. I often run large simulations which can take hours or days to
complete and I need a way of viewing how my data is evolving while the
simulation is running.

I figure I can output my temporary data into a file and then use the
system command in C to execute R with some command line parameters. Now is
there a way that I can order R to load in the data file, set some plotting
parameters, create a plot and exit? I'd like to be able to do it in such a
way that the only visible output is the plot display window and no input
is required of the user.

Any advice would be appreciated, or if you know of someplace this question
has been adressed before.

Thank you,
Marko Krco

P.S. I'll be doing this in Linux



From andyj at splash.princeton.edu  Sat Feb  7 18:38:59 2004
From: andyj at splash.princeton.edu (Andy Jacobson)
Date: Sat, 07 Feb 2004 12:38:59 -0500
Subject: [R] Normality Test on several groups
Message-ID: <f2kbroan618.fsf@splash.princeton.edu>

Hi Knut,

 Knut> Unfortunately, a non-significant test is merely
 Knut> non-conclusive (Popper KR, 1979), so one would have to test for
 Knut> equivalence, e.g., as TOST (two one-sided tests).

 Knut> As to whether you can do a Lilliefors test for several groups,
 Knut> that depends entirely on your ability to understand what the
 Knut> underlying question would be (see Adams D 1979)

 Could you please provide more information on the Popper and Adams
 references you cite above?  While I'm fairly certain that Popper
 1979 is:

 Popper, Karl. Objective knowledge: an evolutionary approach. Oxford:
 Oxford University Press; 1979,

 I've had a bit of trouble searching for the Adams reference.  It
 appears that Douglas Adams published "The Hitchhiker's Guide to the
 Galaxy" in 1979, and as a result of that work's popularity there's
 almost no hope of using a general search engine to find a different
 "Adams D 1979".

 On the other hand, the context of the citation:

 Knut> that depends entirely on your ability to understand what the
 Knut> underlying question would be (see Adams D 1979)

 leads me to suspect that you intended to cite The Hitchhikker's
 Guide.  

 Cheers,

        Andy
-- 
Andy Jacobson

andyj at aos.princeton.edu

Program in Atmospheric and Oceanic Sciences
Sayre Hall, Forrestal Campus
Princeton University
PO Box CN710 Princeton, NJ 08544-0710 USA

Tel: 609/258-5260  Fax: 609/258-2850



From yc176 at yahoo.com  Sat Feb  7 20:43:52 2004
From: yc176 at yahoo.com (Y.C. Tao)
Date: Sat, 7 Feb 2004 11:43:52 -0800 (PST)
Subject: [R] Adding a color bar to image
Message-ID: <20040207194352.11116.qmail@web20724.mail.yahoo.com>

How can I add a color bar to show the color scales to
what is generated by image(), similar to the one in
figures generated by filled.contour()?

Thanks.

Y. C. Tao



From p.dalgaard at biostat.ku.dk  Sat Feb  7 20:54:58 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 07 Feb 2004 20:54:58 +0100
Subject: [R] Normality Test on several groups
In-Reply-To: <f2kbroan618.fsf@splash.princeton.edu>
References: <f2kbroan618.fsf@splash.princeton.edu>
Message-ID: <x2ptcqk6lp.fsf@biostat.ku.dk>

Andy Jacobson <andyj at splash.princeton.edu> writes:

>  On the other hand, the context of the citation:
> 
>  Knut> that depends entirely on your ability to understand what the
>  Knut> underlying question would be (see Adams D 1979)
> 
>  leads me to suspect that you intended to cite The Hitchhikker's
>  Guide.  

...in which case the answer is forty-two, surely.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ross at biostat.ucsf.edu  Sat Feb  7 23:15:54 2004
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Sat, 07 Feb 2004 14:15:54 -0800
Subject: [R] R does in memory analysis only?
Message-ID: <1076192154.17814.104.camel@iron.libaux.ucsf.edu>

I wonder if someone would confirm something I'm 99% sure of from the
docs and discussion on the list, but can't find stated explicitly:
R works only on problems that fit into (real or virtual) memory.

Thus, even if you have a problem (e.g., simple regression) that could be
solved by doing some operation on each row of a dataset at a time, you
can't solve it unless the entire dataset and associated intermediate
results fit in memory.

So if you're in 32 bits, your max problem size is about 2G (regular
Windows and Linux limit your process size to this, though I think some
fancy versions let you go a bit higher).

Is there any thought of relaxing this limitation?  I realize doing so
would be a big job.  I also realize that 64 bits makes it much less
pressing.

Finally, does S-Plus have the same limitation?

Thanks.
-- 
Ross Boylan                                      wk:  (415) 502-4031
530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
University of California, San Francisco
San Francisco, CA 94143-0840                     hm:  (415) 550-1062



From cornulier at cebc.cnrs.fr  Sat Feb  7 23:32:49 2004
From: cornulier at cebc.cnrs.fr (cornulier)
Date: Sat, 07 Feb 2004 23:32:49 +0100
Subject: [R] Adding a color bar to image
References: <20040207194352.11116.qmail@web20724.mail.yahoo.com>
Message-ID: <40256791.C364C627@cebc.cnrs.fr>

I've been using Paulo Ribeiro's
legend.krige {geoR}
to do similar things
HTH,
Thomas

"Y.C. Tao" wrote:

> How can I add a color bar to show the color scales to
> what is generated by image(), similar to the one in
> figures generated by filled.contour()?
>
> Thanks.
>
> Y. C. Tao
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

--
--------------------------------------------
             Thomas Cornulier
Centre d'Etudes Biologiques de Chiz? - CNRS
         79360 Beauvoir sur Niort

+33 (0)549099613 / fax +33 (0)549096526
mobile +33 (0)620660784



From giampi at speech.kth.se  Sat Feb  7 23:40:36 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Sat, 7 Feb 2004 23:40:36 +0100 (CET)
Subject: [R] references on cluster analysis
In-Reply-To: <f2kbroan618.fsf@splash.princeton.edu>
References: <f2kbroan618.fsf@splash.princeton.edu>
Message-ID: <Pine.LNX.4.58.0402071927360.819@bayes.speech.kth.se>

Hi all,
I'm doing a study on predicting the "true" number of clusters in
a hierarchical clustering scheme. My main reference is at the moment

Milligan GW and Cooper MC (1985) "An examination of procedures for
determining the number of clusters in a data set"
Psychometrika vol 50 no 2 pp 159-179

and all the references included in that paper.

I'm planning to perform a similar comparison on a number of indexes,
but on a much larger data set (in the order of 3000 points), and with
a much higher "true" number of clusters (in the order of some hundreds),
to see if the properties of the indexes scale accordingly.

I was wondering if the set of indexes described in the reference are
still "state of the art" (most of them were introduced in the '60s
and '70s), or if there are new indexes and methods I could include in
my study. I would really appreciate if you could point me to some newer
references addressing this problem.

I also read Milligan's chapter in the book "Clustering and
Classification" from 1995, but didn't find information on this subject
that wasn't included in the previous paper.

Thank you very much,
Giampiero

_________________________________________________________
Giampiero Salvi, M.Sc.          www.speech.kth.se/~giampi
Speech, Music and Hearing       Tel:      +46-8-790 75 62
Royal Institute of Technology   Fax:      +46-8-790 78 54
Drottning Kristinasv. 31,  SE-100 44,  Stockholm,  Sweden



From dmurdoch at pair.com  Sun Feb  8 01:01:00 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 07 Feb 2004 19:01:00 -0500
Subject: [R] R does in memory analysis only?
In-Reply-To: <1076192154.17814.104.camel@iron.libaux.ucsf.edu>
References: <1076192154.17814.104.camel@iron.libaux.ucsf.edu>
Message-ID: <5rua20p0klh8ep4m72mniof7es5degml1c@4ax.com>

On Sat, 07 Feb 2004 14:15:54 -0800, you wrote:

>I wonder if someone would confirm something I'm 99% sure of from the
>docs and discussion on the list, but can't find stated explicitly:
>R works only on problems that fit into (real or virtual) memory.

The base libraries have that limitation.  I think various people are
working on packages that handle objects that don't fit in memory.

>Is there any thought of relaxing this limitation?  I realize doing so
>would be a big job.  I also realize that 64 bits makes it much less
>pressing.

I haven't heard of any plans to remove the limit in the base packages.
There's definitely interest in supporting 64 bit platforms.

Duncan Murdoch



From nusbj at hotmail.com  Sun Feb  8 06:56:49 2004
From: nusbj at hotmail.com (Z P)
Date: Sun, 08 Feb 2004 13:56:49 +0800
Subject: [R] 2D histogram
Message-ID: <Sea2-F68fMHTs2FZQTG0000fddb@hotmail.com>

Dear all,

Is there any function to draw a 2D histogram? I only can find some kernel 
estimation. I now only want to draw the 2D histogram. Thanks.



From nusbj at hotmail.com  Sun Feb  8 08:19:43 2004
From: nusbj at hotmail.com (Z P)
Date: Sun, 08 Feb 2004 15:19:43 +0800
Subject: [R] 2D density contour plot
Message-ID: <Sea2-F5fw5VmKldz8ax0000375e@hotmail.com>

Dear all,

Is there any function to construct bivariate kernel estimates using the 
sphering choice of bandwidth matrix H=h*S^(1/2), where S is the sample 
covariance matrix? Then draw a contour plot to see the structure? Thanks.

_________________________________________________________________
Download games, logos, wallpapers and lots more at MSN Mobile!



From andy_liaw at merck.com  Sun Feb  8 03:44:43 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 7 Feb 2004 21:44:43 -0500
Subject: [R] Newbie help with calling R from C programs
Message-ID: <3A822319EB35174CA3714066D590DCD504AF774D@usrymx25.merck.com>

If all you want R to do is the graphics, you might as well use gnuplot for
that, IMHO.

Andy

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marko Krco
> Sent: Saturday, February 07, 2004 11:45 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Newbie help with calling R from C programs
> 
> 
> Hi,
> 
> I'm a new user of R (since yesterday) and I'd like to see if 
> I can use it
> in my codes. I often run large simulations which can take 
> hours or days to
> complete and I need a way of viewing how my data is evolving while the
> simulation is running.
> 
> I figure I can output my temporary data into a file and then use the
> system command in C to execute R with some command line 
> parameters. Now is
> there a way that I can order R to load in the data file, set 
> some plotting
> parameters, create a plot and exit? I'd like to be able to do 
> it in such a
> way that the only visible output is the plot display window 
> and no input
> is required of the user.
> 
> Any advice would be appreciated, or if you know of someplace 
> this question
> has been adressed before.
> 
> Thank you,
> Marko Krco
> 
> P.S. I'll be doing this in Linux
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From tblackw at umich.edu  Sun Feb  8 15:09:35 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Sun, 8 Feb 2004 09:09:35 -0500 (EST)
Subject: [R] Newbie help with calling R from C programs
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF774D@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF774D@usrymx25.merck.com>
Message-ID: <Pine.SOL.4.58.0402080841001.2566@zektor.gpcc.itd.umich.edu>

Marko  -

Here's how I would do it.  Your simulation code writes (or overwrites)
its summary to a named file.  Then your simulation code does a system
call (somehow) that creates a subshell with a Bourne or csh command
line and sends the command "R --vanilla < script.file &".  (I'm not
quite sure at the moment how I would reach this shell again to
terminate both R and the shell.  You might have to kill it by process
number from outside the whole operation.)

*All* of the R-specific stuff is in 'script.file'.  This is an ascii
file containing exactly the R commands you would type interactively
at the R command line to get the display you want, line by line in the
file, and NOT including 'q()'.  Here's a real simple one:

tmp <- read.table("named.file")

X11()
par(lab=c(24,12,7), las=1, tcl=-0.35, mgp=c(1.5,0.5,0), pch=15)
plot(tmp$X1, tmp$X2, type="l", log="y")

It can have comments, blank lines, etc. in it -- anything you would
type at R's command line.  It has the file name for the named file
wired into it.

So the R process starts, reads data from the named file, and does
whatever you tell it to.  The R process has to stay running as long
as the plot window is displayed.  (How would you reach the window
process to kill it otherwise ?)  As soon as R has read the data
from "named.file", R has the data and "named.file" can disappear
or be overwritten without affecting R.

You're on your own to figure out R's interactions with the X window
manager if you want to try to do something fancy like specify the
geometry of the R command window, or minimize it or whatever.

But that's how I would do it.

Why this way ?  It's modular.  Easy to alter, experiment with and
improve.  Your simulation code needs to know only two file names,
and the format of the summary data it will write to "named.file".
It doesn't know anything about the contents of "script.file", so
you can change those at will without continually re-compiling your
simulation code.  In contrast to Andy, I think it's a *good*
solution.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Sat, 7 Feb 2004, Liaw, Andy wrote:

> If all you want R to do is the graphics, you might as well use gnuplot for
> that, IMHO.
>
> Andy
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marko Krco
> > Sent: Saturday, February 07, 2004 11:45 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Newbie help with calling R from C programs
> >
> >
> > Hi,
> >
> > I'm a new user of R (since yesterday) and I'd like to see if
> > I can use it
> > in my codes. I often run large simulations which can take
> > hours or days to
> > complete and I need a way of viewing how my data is evolving while the
> > simulation is running.
> >
> > I figure I can output my temporary data into a file and then use the
> > system command in C to execute R with some command line
> > parameters. Now is
> > there a way that I can order R to load in the data file, set
> > some plotting
> > parameters, create a plot and exit? I'd like to be able to do
> > it in such a
> > way that the only visible output is the plot display window
> > and no input
> > is required of the user.
> >
> > Any advice would be appreciated, or if you know of someplace
> > this question
> > has been adressed before.
> >
> > Thank you,
> > Marko Krco
> >
> > P.S. I'll be doing this in Linux
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
>
>
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments,...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From tblackw at umich.edu  Sun Feb  8 15:23:14 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Sun, 8 Feb 2004 09:23:14 -0500 (EST)
Subject: [R] Newbie help with calling R from C programs
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF774D@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF774D@usrymx25.merck.com>
Message-ID: <Pine.SOL.4.58.0402080913080.4272@zektor.gpcc.itd.umich.edu>

Marko  -

I can't resist.

The next more elegant solution would be to have a single R process
poll the directory entry for "named.file" periodically to see whether
the file date has changed since it was last read.  See help("file.info")
for an R tool that will help do this.  Use  'system("sleep 600", F)'
in R to space the polling ten minutes apart.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



From tblackw at umich.edu  Sun Feb  8 15:47:09 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Sun, 8 Feb 2004 09:47:09 -0500 (EST)
Subject: [R] Newbie help with calling R from C programs
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF774D@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF774D@usrymx25.merck.com>
Message-ID: <Pine.SOL.4.58.0402080941470.6222@asteroids.gpcc.itd.umich.edu>

Marko  -

  . . . and, using a single R process, rather than calling it
from inside the simulation code, means that the R process doesn't
need to be running on the same machine as the simulation code.
It only needs to run on a machine which has shared file access
with the simulation process.

And now, I REALLY have got to stop thinking about this and get
down to my own work !!

-  best  -  tom blackwell  -  umichigan medical school  -  ann arbor  -



From juli at ceam.es  Sun Feb  8 18:38:40 2004
From: juli at ceam.es (juli g. pausas)
Date: Sun, 08 Feb 2004 18:38:40 +0100
Subject: [R] APE: compar.gee( )
Message-ID: <40267420.8060108@ceam.es>

Dear all,
I don't understand the following behaviour: Running  compar.gee   (in 
library ape ) with and without the option 'data', it give me different 
results
Example:

.... Start R ....
> load("eiber.RData")
> ls()
[1] "gee.na" "mydata" "mytree"
> library(ape) 
> # runnig with the option data= mydata
> compar.gee(alt ~ R, family="gaussian", data=mydata, phy=mytree) 
Loading required package: gee 
[1] "Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27"
[1] "running glm to get initial regression estimate"
[1] 7.9500000 0.5155172

Call:
  formula: alt ~ R

Number of observations:  37 

Model:
 Link:                      identity 
 Variance to Mean Relation: gaussian 

Summary of Residuals:
        Min          1Q      Median          3Q         Max 
-12.1267954  -9.4267954  -7.4267954  -0.4267954  20.7903982 


Coefficients:
            Estimate     S.E.        t Pr(T > |t|)
(Intercept) 9.209602 4.760274 1.934679  0.08798892
R1          3.217194 2.548273 1.262500  0.24130121

Estimated Scale Parameter:  86.39367
"Phylogenetic" df (dfP):  10.24615 

> # Second way, without the option data (so attaching the dataframe)
> attach(mydata)
> compar.gee(alt ~ R, family="gaussian", phy=mytree) 
[1] "Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27"
[1] "running glm to get initial regression estimate"
[1] 7.9500000 0.5155172

Call:
  formula: alt ~ R

Number of observations:  37 

Model:
 Link:                      identity 
 Variance to Mean Relation: gaussian 

Summary of Residuals:
       Min         1Q     Median         3Q        Max 
-14.123399 -11.423399  -8.856398  -1.856398  20.143602 


Coefficients:
            Estimate     S.E.        t Pr(T > |t|)
(Intercept) 9.856398 5.137029 1.918696  0.09020828
R1          4.567001 2.351966 1.941781  0.08701965

Estimated Scale Parameter:  103.2713
"Phylogenetic" df (dfP):  10.24615 
> search()
 [1] ".GlobalEnv"      "mydata"          "package:gee"     "package:ape"    
 [5] "package:methods" "package:ctest"   "package:mva"     "package:modreg" 
 [9] "package:nls"     "package:ts"      "Autoloads"       "package:base"   
> 

(R 1.8.1 for Windows
ape 1.2)



Note that the results are different.
Am I doing something wrong? Which is the correct answer?
Thanks for any help

Juli



From kmw at mail.rockefeller.edu  Sun Feb  8 18:45:30 2004
From: kmw at mail.rockefeller.edu (Knut M. Wittkowski)
Date: Sun, 08 Feb 2004 12:45:30 -0500
Subject: [R] Normality Test on several groups
In-Reply-To: <f2kbroan618.fsf@splash.princeton.edu>
Message-ID: <5.1.0.14.0.20040208114921.02132248@imap.rockefeller.edu>

Andy and Peter: Of yours, both of you are right.

Re h2g2 (Adams DN 1979):

>"[42] quite definitely is the answer. I think the problem, to be quite 
>honest with you, is that you've never actually known what the question is. 
>[...] So once you do know what the question actually is, you'll know what 
>the answer means."

Re Sir Karl, I have to admit a typo (1+6 instead of 6-1, see 
en.wikipedia.org/wiki/The_Answer_to_Life,_the_Universe,_and_Everything for 
related algebraic problems) and I should have quoted the original publication:

>Popper KR. Logik der Forschung. Julius Springer: Wien; 1937. English: The 
>Logic of Scientific Discovery. Basic Books: New York; 1959.

Cheers, Knut

At 12:38 2004-02-07 -0500, Andy wrote:
>Hi Knut,
>
>Could you please provide more information on the Popper and Adams 
>references you cite above?  While I'm fairly certain that Popper 1979 is:
>
>Popper, Karl. Objective knowledge: an evolutionary approach. Oxford: 
>Oxford University Press; 1979,
>
>Knut> that depends entirely on your ability to understand what the
>Knut> underlying question would be (see Adams D 1979)
>
>leads me to suspect that you intended to cite The Hitchhikker's Guide.
>
>Cheers, Andy
>--
>Andy Jacobson
>Program in Atmospheric and Oceanic Sciences
>Sayre Hall, Forrestal Campus
>Princeton University
>PO Box CN710 Princeton, NJ 08544-0710 USA
>Tel: 609/258-5260  Fax: 609/258-2850

At 20:54 2004-02-07 +0100, Peter wrote:

>...in which case the answer is forty-two, surely.
>
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


Knut M. Wittkowski, PhD,DSc
------------------------------------------
The Rockefeller University, GCRC
Experimental Design and Biostatistics
1230 York Ave #121B, Box 322, NY,NY 10021
+1(212)327-7175, +1(212)327-8450 (Fax)
kmw at rockefeller.edu
http://www.rucares.org/clinicalresearch/dept/biometry/



From andrejk at zrc-sazu.si  Sun Feb  8 19:01:08 2004
From: andrejk at zrc-sazu.si (Andrej Kveder)
Date: Sun, 08 Feb 2004 19:01:08 +0100
Subject: [R] bootstrap estimates for lme
Message-ID: <000501c3ee6d$87f59350$cb00a8c0@poldi>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040208/7095d760/attachment.pl

From ligges at statistik.uni-dortmund.de  Sun Feb  8 19:15:11 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 08 Feb 2004 19:15:11 +0100
Subject: [R] APE: compar.gee( )
In-Reply-To: <40267420.8060108@ceam.es>
References: <40267420.8060108@ceam.es>
Message-ID: <40267CAF.5060301@statistik.uni-dortmund.de>

juli g. pausas wrote:

> Dear all,
> I don't understand the following behaviour: Running  compar.gee   (in 
> library ape ) with and without the option 'data', it give me different 
> results
> Example:
> 
> .... Start R ....
> 
>> load("eiber.RData")
>> ls()
> 
> [1] "gee.na" "mydata" "mytree"
> 
>> library(ape) # runnig with the option data= mydata
>> compar.gee(alt ~ R, family="gaussian", data=mydata, phy=mytree) 
> 
> Loading required package: gee [1] "Beginning Cgee S-function, @(#) 
> geeformula.q 4.13 98/01/27"
> [1] "running glm to get initial regression estimate"
> [1] 7.9500000 0.5155172
> 
> Call:
>  formula: alt ~ R
> 
> Number of observations:  37
> Model:
> Link:                      identity Variance to Mean Relation: gaussian
> Summary of Residuals:
>        Min          1Q      Median          3Q         Max -12.1267954  
> -9.4267954  -7.4267954  -0.4267954  20.7903982
> 
> Coefficients:
>            Estimate     S.E.        t Pr(T > |t|)
> (Intercept) 9.209602 4.760274 1.934679  0.08798892
> R1          3.217194 2.548273 1.262500  0.24130121
> 
> Estimated Scale Parameter:  86.39367
> "Phylogenetic" df (dfP):  10.24615
> 
>> # Second way, without the option data (so attaching the dataframe)
>> attach(mydata)
>> compar.gee(alt ~ R, family="gaussian", phy=mytree) 
> 
> [1] "Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27"
> [1] "running glm to get initial regression estimate"
> [1] 7.9500000 0.5155172
> 
> Call:
>  formula: alt ~ R
> 
> Number of observations:  37
> Model:
> Link:                      identity Variance to Mean Relation: gaussian
> Summary of Residuals:
>       Min         1Q     Median         3Q        Max -14.123399 
> -11.423399  -8.856398  -1.856398  20.143602
> 
> Coefficients:
>            Estimate     S.E.        t Pr(T > |t|)
> (Intercept) 9.856398 5.137029 1.918696  0.09020828
> R1          4.567001 2.351966 1.941781  0.08701965
> 
> Estimated Scale Parameter:  103.2713
> "Phylogenetic" df (dfP):  10.24615
> 
>> search()
> 
> [1] ".GlobalEnv"      "mydata"          "package:gee"     
> "package:ape"    [5] "package:methods" "package:ctest"   
> "package:mva"     "package:modreg" [9] "package:nls"     
> "package:ts"      "Autoloads"       "package:base"  
> 
>>
> 
> (R 1.8.1 for Windows
> ape 1.2)


Note that ape 1.2-1 is the recent version.

> 
> 
> Note that the results are different.
> Am I doing something wrong? Which is the correct answer?
> Thanks for any help

I guess that one with the data argument:
Are you sure there is no object called "alt" or "R" in your workspace 
before attaching the data frame (it will mask the attached object)?

You might want to check that:
  identical(R, mydata$R)
  identical(alt, mydata$alt)

If those objects are identical, you might want to ask the maintainer of 
ape, Emmanuel Paradis <paradis at isem.univ-montp2.fr>.


Uwe Ligges


> Juli
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From j.zutt at ewi.tudelft.nl  Sun Feb  8 21:39:13 2004
From: j.zutt at ewi.tudelft.nl (Jonne Zutt)
Date: Sun, 8 Feb 2004 21:39:13 +0100
Subject: [R] parsing numbers from a string
Message-ID: <200402082139.18116.j.zutt@ewi.tudelft.nl>

Dear R-help members,

I have several large data sets from certain simulations I did and now I want to plot the results nicely.
I don't know anything about the size of the x and y values in advance.
Plotting these values is not a problem.
However, I want to add errorbars (errbar in the Hmisc package).

1) For this I'm factoring the data (xdata00 varies from 0 to max(xdata00))
	xfactor00 = factor(cut(xdata00, breaks = (max(xdata00)/10)*(0:100)))

2) I compute the means of the different levels
	ymeans00 = tapply(ydata00, xfactor00, mean)

3) I compute the errors of the different levels
	ystdevs00 = tapply(ydata00, xfactor00, sd)

4) And then I use the errbar function
	errbar((xlim/20)+(xlim/10)*(0:(length(ymeans00)-1)), ymeans00, ymeans00+ystdevs00, ymeans00-ystdevs00, add=T)

My problem is that the x-values that I provide to the errbar are not
correct if there are empty parts in my initial data.

To give an example of this:
> ymeans00
  (0,74.4] (74.4,149]  (149,223]  (223,298]  (298,372]  (372,447]  (670,744]
  20.74706  195.90000  275.62500  316.00000  329.75000  373.00000  478.75000

Here we see the 6th and 7th intervals are not neighbors, in fact there are three missing.
The errbar function now plots the last error bar at a too small x value.

A possible solution for me would be to compute the correct x value from the following output
> names(ymeans00)
[1] "(0,74.4]"   "(74.4,149]" "(149,223]"  "(223,298]"  "(298,372]"
[6] "(372,447]"  "(670,744]"

I want a vector containing [0+74.4/2, 74.4+149/2, ...etc]

But I don't know how to parse these strings.
Does anyone know how to do this, or maybe is there a simpler way?

Thanks in advance,
Jonne.



From femke at geog.umd.edu  Sun Feb  8 22:07:44 2004
From: femke at geog.umd.edu (femke)
Date: Sun, 8 Feb 2004 16:07:44 -0500
Subject: [R] iterating over files in a directory with R
Message-ID: <003601c3ee87$9eff4130$72180281@jawks2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040208/e714d05f/attachment.pl

From tblackw at umich.edu  Sun Feb  8 22:13:33 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Sun, 8 Feb 2004 16:13:33 -0500 (EST)
Subject: [R] iterating over files in a directory with R
In-Reply-To: <003601c3ee87$9eff4130$72180281@jawks2>
References: <003601c3ee87$9eff4130$72180281@jawks2>
Message-ID: <Pine.SOL.4.58.0402081611060.12248@mspacman.gpcc.itd.umich.edu>


Try  help("list.files"), help("file.info"), help("file"),  and
look in the "see also" section in each of those help files for
other functions which you may find useful for doing this.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Sun, 8 Feb 2004, femke wrote:

> Hello,
>
> I'm an R newbie and was wondering whether there are R commands for iterating over files in a directory.  Basically what I want to do is to iterate over many files and apply some R functions to each file seperately.
>
> e.g. for (each file in a directory) do { some R calculation with the info in that file }
>
> Could someone please give me a pointer to how (or if) this might be done with R - I haven't yet been able to find anything relevant in the manuals.  Or would I need to call each file with some language such as Java and then use R once I have the file name?
>
> Thanks for your help,
>
> femke
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From h.wickham at auckland.ac.nz  Sun Feb  8 22:28:53 2004
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Mon, 09 Feb 2004 10:28:53 +1300
Subject: [R] iterating over files in a directory with R
In-Reply-To: <003601c3ee87$9eff4130$72180281@jawks2>
References: <003601c3ee87$9eff4130$72180281@jawks2>
Message-ID: <4026AA15.8070608@auckland.ac.nz>

?list.files

?"for"

Hadley

femke wrote:

> Hello, 
> 
> I'm an R newbie and was wondering whether there are R commands for iterating over files in a directory.  Basically what I want to do is to iterate over many files and apply some R functions to each file seperately.  
> 
> e.g. for (each file in a directory) do { some R calculation with the info in that file }
> 
> Could someone please give me a pointer to how (or if) this might be done with R - I haven't yet been able to find anything relevant in the manuals.  Or would I need to call each file with some language such as Java and then use R once I have the file name?
> 
> Thanks for your help,
> 
> femke
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dmurdoch at pair.com  Sun Feb  8 22:33:21 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 08 Feb 2004 16:33:21 -0500
Subject: [R] iterating over files in a directory with R
In-Reply-To: <003601c3ee87$9eff4130$72180281@jawks2>
References: <003601c3ee87$9eff4130$72180281@jawks2>
Message-ID: <nlad20p1icvg89lu323o2u01a3jqjrsb7h@4ax.com>

On Sun, 8 Feb 2004 16:07:44 -0500, you wrote:

>Hello, 
>
>I'm an R newbie and was wondering whether there are R commands for iterating over files in a directory.  Basically what I want to do is to iterate over many files and apply some R functions to each file seperately.  

The apply() and related functions do iteration over various things,
and list.files() and choose.files() select files (the latter
interactively on Windows).

So something like this might do what you want:

 lapply(list.files(), function(x) paste('filename is ',x))

Duncan Murdoch



From tlumley at u.washington.edu  Sun Feb  8 22:34:19 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 8 Feb 2004 13:34:19 -0800 (PST)
Subject: [R] iterating over files in a directory with R
In-Reply-To: <003601c3ee87$9eff4130$72180281@jawks2>
References: <003601c3ee87$9eff4130$72180281@jawks2>
Message-ID: <Pine.A41.4.58.0402081332430.139062@homer01.u.washington.edu>

On Sun, 8 Feb 2004, femke wrote:

> Hello,
>
> I'm an R newbie and was wondering whether there are R commands for
> iterating over files in a directory.  Basically what I want to do is to
> iterate over many files and apply some R functions to each file
> seperately.
>
> e.g. for (each file in a directory) do { some R calculation with the
> info in that file }
>

sapply(list.files("a directory"), some.R.calculation)

or

files<-list.files("a directory")
for(each.file in files){
	some.R.calculation
}


	-thomas



From rpeng at jhsph.edu  Sun Feb  8 22:34:58 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sun, 08 Feb 2004 16:34:58 -0500
Subject: [R] iterating over files in a directory with R
In-Reply-To: <003601c3ee87$9eff4130$72180281@jawks2>
References: <003601c3ee87$9eff4130$72180281@jawks2>
Message-ID: <4026AB82.7060206@jhsph.edu>

I usually do something like this:

filelist <- dir(path = ".") ## files in current directory

for(filename in filelist) {
	do.something(filename)
}

-roger

femke wrote:

> Hello, 
> 
> I'm an R newbie and was wondering whether there are R commands for iterating over files in a directory.  Basically what I want to do is to iterate over many files and apply some R functions to each file seperately.  
> 
> e.g. for (each file in a directory) do { some R calculation with the info in that file }
> 
> Could someone please give me a pointer to how (or if) this might be done with R - I haven't yet been able to find anything relevant in the manuals.  Or would I need to call each file with some language such as Java and then use R once I have the file name?
> 
> Thanks for your help,
> 
> femke
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From myfirstname at elseware.nl  Mon Feb  9 00:07:55 2004
From: myfirstname at elseware.nl (David A. van Leeuwen)
Date: Mon, 09 Feb 2004 00:07:55 +0100
Subject: [R] substitute, eval, quote and functions
Message-ID: <4026C14B.80202@elseware.nl>

Hi,

i am working with large data frames with many dependend variables.  I 
want to write some functions that will allow me to quickly select 
variables from the frame and plot them in various colors depending on 
factor columns, possibly selecting rows according to factor conditions. 

In order to do this in a nice function, i need to understand how to work 
with a column name in the body of a function. 

To simplify my problem, how do i write a function with a body like

scatter.plot <- function (data, x, y) {
    plot(data$x, data$y)
}

(which doesn't work, of course---i need a series of `substitute's and 
evals---but i can't get it to work---in Perl it would be something along 
the lines of $$x, dereferencing $x another time)
so that i can call

scatter.plot(x, one, two)

as a `short' for

plot(x$one, x$two)

In my real application I want to pass the `column selecting' arguments 
to `subset', which evan with the code of subset.data.frame I have not 
been successful after a whole evening...

Thanks,


-- 
David A. van Leeuwen			< @ElseWare.nl>

	  Echt stijlvol sterven doe je / bij een ander op de mat
	  Op de dag dat je bezorgd wordt / door het NRC Handelsblad
	
							---Joop Visser



From bates at stat.wisc.edu  Mon Feb  9 00:19:02 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 08 Feb 2004 17:19:02 -0600
Subject: [R] substitute, eval, quote and functions
In-Reply-To: <4026C14B.80202@elseware.nl>
References: <4026C14B.80202@elseware.nl>
Message-ID: <6risihcg7t.fsf@bates4.stat.wisc.edu>

"David A. van Leeuwen" <myfirstname at elseware.nl> writes:

> Hi,
> 
> i am working with large data frames with many dependend variables.  I
> want to write some functions that will allow me to quickly select
> variables from the frame and plot them in various colors depending on
> factor columns, possibly selecting rows according to factor
> conditions. In order to do this in a nice function, i need to
> understand how to work with a column name in the body of a
> function. To simplify my problem, how do i write a function with a
> body like
> 
> 
> scatter.plot <- function (data, x, y) {
>     plot(data$x, data$y)
> }

Use 
   plot(data[[x]], data[[y]])
instead

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From p.dalgaard at biostat.ku.dk  Mon Feb  9 01:30:07 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Feb 2004 01:30:07 +0100
Subject: [R] substitute, eval, quote and functions
In-Reply-To: <6risihcg7t.fsf@bates4.stat.wisc.edu>
References: <4026C14B.80202@elseware.nl> <6risihcg7t.fsf@bates4.stat.wisc.edu>
Message-ID: <x2k72xjdrk.fsf@biostat.ku.dk>

Douglas Bates <bates at stat.wisc.edu> writes:

> "David A. van Leeuwen" <myfirstname at elseware.nl> writes:
> 
> > Hi,
> > 
> > i am working with large data frames with many dependend variables.  I
> > want to write some functions that will allow me to quickly select
> > variables from the frame and plot them in various colors depending on
> > factor columns, possibly selecting rows according to factor
> > conditions. In order to do this in a nice function, i need to
> > understand how to work with a column name in the body of a
> > function. To simplify my problem, how do i write a function with a
> > body like
> > 
> > 
> > scatter.plot <- function (data, x, y) {
> >     plot(data$x, data$y)
> > }
> 
> Use 
>    plot(data[[x]], data[[y]])
> instead

The plot labels won't come out right then. I think David was
looking for something like 

function(data, x, y)
        eval(substitute(plot(x,y)), data)

or to be able to pass names:

function(data, x, y)
   eval(substitute(plot(x,y),list(x=as.name(x), y=as.name(y))), data)



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From andy_liaw at merck.com  Mon Feb  9 01:31:30 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 8 Feb 2004 19:31:30 -0500
Subject: [R] parsing numbers from a string
Message-ID: <3A822319EB35174CA3714066D590DCD504AF774E@usrymx25.merck.com>

Here's one possible way:

> xrange <- scan("clipboard", what="")
Read 7 items
> xrange
[1] "(0,74.4]"   "(74.4,149]" "(149,223]"  "(223,298]"  "(298,372]"
"(372,447]" 
[7] "(670,744]" 
> sapply(strsplit(substring(xrange, 2, nchar(xrange)-1), ","), as.numeric)
     [,1]  [,2] [,3] [,4] [,5] [,6] [,7]
[1,]  0.0  74.4  149  223  298  372  670
[2,] 74.4 149.0  223  298  372  447  744

HTH,
Andy


> From: Jonne Zutt
> 
> Dear R-help members,
> 
> I have several large data sets from certain simulations I did 
> and now I want to plot the results nicely.
> I don't know anything about the size of the x and y values in advance.
> Plotting these values is not a problem.
> However, I want to add errorbars (errbar in the Hmisc package).
> 
> 1) For this I'm factoring the data (xdata00 varies from 0 to 
> max(xdata00))
> 	xfactor00 = factor(cut(xdata00, breaks = 
> (max(xdata00)/10)*(0:100)))
> 
> 2) I compute the means of the different levels
> 	ymeans00 = tapply(ydata00, xfactor00, mean)
> 
> 3) I compute the errors of the different levels
> 	ystdevs00 = tapply(ydata00, xfactor00, sd)
> 
> 4) And then I use the errbar function
> 	errbar((xlim/20)+(xlim/10)*(0:(length(ymeans00)-1)), 
> ymeans00, ymeans00+ystdevs00, ymeans00-ystdevs00, add=T)
> 
> My problem is that the x-values that I provide to the errbar are not
> correct if there are empty parts in my initial data.
> 
> To give an example of this:
> > ymeans00
>   (0,74.4] (74.4,149]  (149,223]  (223,298]  (298,372]  
> (372,447]  (670,744]
>   20.74706  195.90000  275.62500  316.00000  329.75000  
> 373.00000  478.75000
> 
> Here we see the 6th and 7th intervals are not neighbors, in 
> fact there are three missing.
> The errbar function now plots the last error bar at a too 
> small x value.
> 
> A possible solution for me would be to compute the correct x 
> value from the following output
> > names(ymeans00)
> [1] "(0,74.4]"   "(74.4,149]" "(149,223]"  "(223,298]"  "(298,372]"
> [6] "(372,447]"  "(670,744]"
> 
> I want a vector containing [0+74.4/2, 74.4+149/2, ...etc]
> 
> But I don't know how to parse these strings.
> Does anyone know how to do this, or maybe is there a simpler way?
> 
> Thanks in advance,
> Jonne.
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ok at cs.otago.ac.nz  Mon Feb  9 02:08:03 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Mon, 9 Feb 2004 14:08:03 +1300 (NZDT)
Subject: [R] PhD student reading list, suggestions wanted
Message-ID: <200402090108.i19183js023881@atlas.otago.ac.nz>

I've got a PhD student starting this year.
She'll be working on data mining.
She has asked for a reading list while she's still in her home
country, which is a really good sign.
Her cosupervisor and I don't (think we) have any problem with
choosing things that are specifically about data mining, but
there are some statistical ideas (sampling, exploratory-vs-confirmatory,
clustering) where I have things on my shelves I can recommend but
wouldn't mind advice.

But above all, I would like her to use R whenever it's appropriate.
We have MASS and Dalgaard's introductory book in the library here, I'm
aware of "S Poetry", but what do you think would be the best start for
someone learning R in order to use it for doing data mining?



From alistair.campbell at jcu.edu.au  Mon Feb  9 02:55:11 2004
From: alistair.campbell at jcu.edu.au (Alistair Campbell)
Date: Mon, 9 Feb 2004 11:55:11 +1000
Subject: [R] Can S-Plus packages be used in R without modification?
Message-ID: <000001c3eeaf$c0f27af0$691edb89@alistaircampbel>

Hi,

I have had a quick search to see whether this question has been
asked/answered before but haven't found anything directly related to it.

Basically, I am wondering if I can run the packages, developed by Shafer
for S-Plus, that allow multiple imputation of missing data - NORM, CAT,
MIX, and PAN.

If not, does anyone know if someone has done the modification that would
make these packages available in R?

And/or, does anyone know of other packages that facilitate multiple
imputation of missing data that can be run from R?

Cheers

Alistair Campbell
School of Psychology
James Cook University
Townsville QLD AUST



From jfox at mcmaster.ca  Mon Feb  9 05:27:00 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 08 Feb 2004 23:27:00 -0500
Subject: [R] Can S-Plus packages be used in R without modification?
In-Reply-To: <000001c3eeaf$c0f27af0$691edb89@alistaircampbel>
Message-ID: <5.1.0.14.2.20040208231745.0214e950@127.0.0.1>

Dear Alistair,

All of Shafer's packages have been ported to R and are on CRAN. There are 
also some facilities for multiple imputation in the Hmisc package, and in 
the mice package -- not on CRAN, but available at 
<http://www.multiple-imputation.com/>. There are probably other multiple 
imputation facilities in R of which I'm unaware.

I hope that this helps,
John

At 11:55 AM 2/9/2004 +1000, Alistair Campbell wrote:
>Hi,
>
>I have had a quick search to see whether this question has been
>asked/answered before but haven't found anything directly related to it.
>
>Basically, I am wondering if I can run the packages, developed by Shafer
>for S-Plus, that allow multiple imputation of missing data - NORM, CAT,
>MIX, and PAN.
>
>If not, does anyone know if someone has done the modification that would
>make these packages available in R?
>
>And/or, does anyone know of other packages that facilitate multiple
>imputation of missing data that can be run from R?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From k.wang at auckland.ac.nz  Mon Feb  9 05:54:59 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Mon, 9 Feb 2004 17:54:59 +1300
Subject: [R] PhD student reading list, suggestions wanted
In-Reply-To: <200402090108.i19183js023881@atlas.otago.ac.nz>
Message-ID: <20040209045512.GNCS9271.mta1-rme.xtra.co.nz@kevinlpt>

Hi,

> -----Original Message-----
> But above all, I would like her to use R whenever it's appropriate.
> We have MASS and Dalgaard's introductory book in the library here, I'm
> aware of "S Poetry", but what do you think would be the best start for
> someone learning R in order to use it for doing data mining?

Not specifically for R, but a must-have for anyone going into data mining
area is "The Elements of Statistical Learning: Data Mining, Inference, and
Prediction", by Hastie et. al.

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
SLC Stats Workshops Co-ordinator
The University of Auckland
New Zealand



From ggrothendieck at myway.com  Mon Feb  9 07:10:16 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon,  9 Feb 2004 01:10:16 -0500 (EST)
Subject: [R] parsing numbers from a string
Message-ID: <20040209061016.3DF1E39B1@mprdmxin.myway.com>


Try this:

   sapply( parse( text = chartr( "(],", "  +", z ) ), eval ) / 2

chartr translates ( to space, ] to space and comma to +.  Then
the character strings are parsed and evaluated as R expressions.
Finally, we divide by 2.

---
Date:   Sun, 8 Feb 2004 21:39:13 +0100 
From:   Jonne Zutt <j.zutt at ewi.tudelft.nl>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] parsing numbers from a string 

 
Dear R-help members,

I have several large data sets from certain simulations I did and now I want to plot the results nicely.
I don't know anything about the size of the x and y values in advance.
Plotting these values is not a problem.
However, I want to add errorbars (errbar in the Hmisc package).

1) For this I'm factoring the data (xdata00 varies from 0 to max(xdata00))
     xfactor00 = factor(cut(xdata00, breaks = (max(xdata00)/10)*(0:100)))

2) I compute the means of the different levels
     ymeans00 = tapply(ydata00, xfactor00, mean)

3) I compute the errors of the different levels
     ystdevs00 = tapply(ydata00, xfactor00, sd)

4) And then I use the errbar function
     errbar((xlim/20)+(xlim/10)*(0:(length(ymeans00)-1)), ymeans00, ymeans00+ystdevs00, ymeans00-ystdevs00, add=T)

My problem is that the x-values that I provide to the errbar are not
correct if there are empty parts in my initial data.

To give an example of this:
> ymeans00
(0,74.4] (74.4,149] (149,223] (223,298] (298,372] (372,447] (670,744]
20.74706 195.90000 275.62500 316.00000 329.75000 373.00000 478.75000

Here we see the 6th and 7th intervals are not neighbors, in fact there are three missing.
The errbar function now plots the last error bar at a too small x value.

A possible solution for me would be to compute the correct x value from the following output
> names(ymeans00)
[1] "(0,74.4]" "(74.4,149]" "(149,223]" "(223,298]" "(298,372]"
[6] "(372,447]" "(670,744]"

I want a vector containing [0+74.4/2, 74.4+149/2, ...etc]

But I don't know how to parse these strings.
Does anyone know how to do this, or maybe is there a simpler way?

Thanks in advance,
Jonne.



From christian.hoffmann at wsl.ch  Mon Feb  9 08:52:09 2004
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Mon, 09 Feb 2004 08:52:09 +0100
Subject: [R] 0.1 + 0.2 != 0.3 revisited
In-Reply-To: <3if720tukrh46rikg23jb4fvh3o2vhoah1@4ax.com>
References: <6C8A8033ABC1E3468048ABC4F13CE572F021D8@synequanon01>
	<3if720tukrh46rikg23jb4fvh3o2vhoah1@4ax.com>
Message-ID: <40273C29.4010706@wsl.ch>

Hi,

IEEE says that real numbers are normalized (a few below 10^(-16) may be 
not [gradual underflow]), so that they look like 0.1ddd2^ex. Then only 
ddd and ex are kept:
0.1 = 0.00011.. 2^0 = 0.11001100.. 2^(-3) -> (11001100.., -3)
0.2 = 0.0011..  2^0 = 0.11001100.. 2^(-2) -> (11001100.., -2)
0.3 = 0.010011..2^0 = 0.10011001.. 2^(-1) -> (10011001.., -1)

Duncan Murdoch wrote:

> On Fri, 6 Feb 2004 12:55:05 -0000, "Simon Fear"
> <Simon.Fear at synequanon.com> wrote :
> 
> 
>>Prompted by Peter Dalgard's recent elegant "intbin" function,
>>I have been playing with the extension to converting reals to binary
>>representation. The decimal part can be done like this:
>>
>>decbase <- function(x, n=52, base=2) {
>> if(n) {
>>   x <- x*base
>>   paste(trunc(x), decbase(x%%1, n-1, base), sep="")
>> }
>>}
>>
>>n=52 default because that's the number of bits in the significand of
>>a 64-bit float.
> 
> 
> Remember that IEEE double formats are complicated, they're not fixed
> point formats.
> 
> Both 0.1 and 0.2 are less than 1, so the n=52 count is wrong.  I think
> 0.1 would be stored as (1 + 0.6)*2^(-4) and 0.2 would be stored as (1
> + 0.6)*2^(-3), whereas 0.3 would be stored as (1 + 0.2)*2^(-2).  You
> should expect 56 decimal (binary?) place accuracy on 0.1, 55 place
> accuracy on 0.2, and 54 place accuracy on 0.3.  It's not surprising
> weird things happen!

I don *not* think so: all mantissas here have *52 binary* places!

> Duncan Murdoch
Christian Hoffmann
-- 
Dr.sc.math.Christian W. Hoffmann, 
http://www.wsl.ch/staff/christian.hoffmann
Mathematics + Statistical Computing   e-mail: hoffmacw at wsl.ch
Swiss Federal Research Institute WSL  Tel: ++41-1-73922..  ..77  (self)
CH-8903 Birmensdorf, Switzerland           ..11(exchange), ..15  (Fax)



From p.dalgaard at biostat.ku.dk  Mon Feb  9 10:25:54 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Feb 2004 10:25:54 +0100
Subject: [R] substitute, eval, quote and functions
In-Reply-To: <x2k72xjdrk.fsf@biostat.ku.dk>
References: <4026C14B.80202@elseware.nl> <6risihcg7t.fsf@bates4.stat.wisc.edu>
	<x2k72xjdrk.fsf@biostat.ku.dk>
Message-ID: <x23c9kob8d.fsf@biostat.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> > > scatter.plot <- function (data, x, y) {
> > >     plot(data$x, data$y)
> > > }
> > 
> > Use 
> >    plot(data[[x]], data[[y]])
> > instead
> 
> The plot labels won't come out right then. I think David was
> looking for something like 
> 
> function(data, x, y)
>         eval(substitute(plot(x,y)), data)
> 
> or to be able to pass names:
> 
> function(data, x, y)
>    eval(substitute(plot(x,y),list(x=as.name(x), y=as.name(y))), data)

...On the other hand, come to think of it, there's quite a lot to be
said for just doing

   plot(data[[x]], data[[y]], xlab=x, ylab=y) 

at least in the latter case. (The former has the advantage that you
can pass in entire expressions.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jean-noel.candau at avignon.inra.fr  Mon Feb  9 11:24:39 2004
From: jean-noel.candau at avignon.inra.fr (Jean-Noel)
Date: Mon, 9 Feb 2004 11:24:39 +0100
Subject: [R] Recursive partitioning with multicollinear variables
Message-ID: <GOENJEALPPDFMBOMCKOJGENCCAAA.jean-noel.candau@avignon.inra.fr>

Dear all,
I would like to perform a regression tree analysis on a dataset with
multicollinear variables (as climate variables often are). The questions
that I am asking are:
 1- Is there any particular statistical problem in using multicollinear
variables in a regression tree?
 2- Multicollinear variables should appear as alternate splits. Would it be
more accurate to present these alternate splits in the results of the
analysis or apply a variable selection or reduction procedure before the
regression tree?
Thank you in advance,

Jean-Noel Candau

INRA - Unit? de Recherches Foresti?res M?diterran?ennes
Avenue A. Vivaldi
84000 AVIGNON
Tel: (33) 4 90 13 59 22
Fax: (33) 4 90 13 59 59



From p.dalgaard at biostat.ku.dk  Mon Feb  9 11:24:16 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Feb 2004 11:24:16 +0100
Subject: [R] 0.1 + 0.2 != 0.3 revisited
In-Reply-To: <40273C29.4010706@wsl.ch>
References: <6C8A8033ABC1E3468048ABC4F13CE572F021D8@synequanon01>
	<3if720tukrh46rikg23jb4fvh3o2vhoah1@4ax.com> <40273C29.4010706@wsl.ch>
Message-ID: <x2y8rcmtyn.fsf@biostat.ku.dk>

Christian Hoffmann <christian.hoffmann at wsl.ch> writes:

> > 0.1 would be stored as (1 + 0.6)*2^(-4) and 0.2 would be stored as (1
> > + 0.6)*2^(-3), whereas 0.3 would be stored as (1 + 0.2)*2^(-2).  You
> > should expect 56 decimal (binary?) place accuracy on 0.1, 55 place
> > accuracy on 0.2, and 54 place accuracy on 0.3.  It's not surprising
> > weird things happen!
> 
> I don *not* think so: all mantissas here have *52 binary* places!

(53, since the leading 1 is not stored...)

Actually, in the x86 FPUs numbers get extended to 64 bits during
evaluation, so after alignment for addition, the smaller numbers may
have bits beyond the truncation point of the larger ones. These bits
disappear when the result is stored, but rounding may be affected
giving those unit-in-the-last-place differences.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ajayshah at mayin.org  Mon Feb  9 12:27:57 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Mon, 9 Feb 2004 16:57:57 +0530
Subject: [R] Subset function of lm(); "rolling regressions"
Message-ID: <20040209112757.GA3135@igidr.ac.in>

Folks,

I asked a question on this mailing list about the subset support of
lm(). In a flash, I got three helpful responses from
  Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
  Erin Hodgess <hodgess at gator.uhd.edu>
and
  Peter Dalgaard <p.dalgaard at biostat.ku.dk>

:-) and it was just great.

The mistake I was making was in not understanding the notion of a
`subset'. I was thinking that if I have 10 observations, and I want to
only use observations 3,5,7, then I have to pass in a subset vector
which looks like (0,0,1,0,1,0,1,0,0,0). Nowhere does it say this, but
I jumped to this conclusion (it sortof looked reasonable to me). The
correct thing is to just pass a vector containing 3,5,7. Examples of
working code which do this are at http://www.mayin.org/ajayshah/KB/R/ols.html



I tried to carry this forward into a program which does `rolling
regressions', and I got stuck. I am trying to write a program where I
walk over 100 obs, doing a regression of a "moving window" of 25 obs
at a time. The first regression runs over 1..25, the second from
2..26, etc. I want to make a vector of 75 different slopes obtained
thusly. My code is:

   ---------------------------------------------------------------------------
   A <- read.table(file="datafile.2",
          col.names=c("date","dlinrchf","dlusdchf","dljpychf","dldemchf"))

   # The file datafile.2 has 100 observations. I want window width of 25.
   T=100
   width=25

   # Embark on the loop that will do rolling windows across the dataset.
   # Will build up a vector `beta' (of 75 elems) in the process.
   for (i in 1:T-width) {
       model <- lm(dlinrchf ~ dlusdchf + dljpychf + dldemchf, A, i:i+25)
       tmp <- coefficients(model)
       beta[i] = tmp[2]
   }
   summary(beta)
   ---------------------------------------------------------------------------

I get the error --

Error in "[<-"(`*tmp*`, i, value = tmp[2]) : 
        object is not subsetable
Execution halted

I am quite stuck. I know for sure that the n1:n2 type notation works
for supplying a set. But when I use 'i' in it, it breaks. Could you
suggest what I should do?

I am very new to R and so I might be missing out on very basic
things. But I am unable to understand why this program does not print
out the numbers from 1 to 10:

for (i in 1:10) {
  i
}

Confused,

        -ans.

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From Bill.Venables at csiro.au  Mon Feb  9 12:32:50 2004
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Mon, 9 Feb 2004 21:32:50 +1000
Subject: [R] Recursive partitioning with multicollinear variables
Message-ID: <CD1115EE475A874E9D619CE11DEF58361DA73C@exqld3-bne.qld.csiro.au>

No, for regression trees collinearity is a non-issue, because it is not a linear procedure.  Having variables that are linearly dependent (even exactly so) merely widens the scope of choice that the algorithm has to make cuts.

I'm not sure what you mean by "Multicollinear variables should appear as alternate splits".  Do you mean that every second split should be in one variable of a particular set?  Perhaps you mean "alternative" instead of "alternate"?  In either case I think you are worrying over nothing.  Just go ahead and do the tree-based model analysis and don't worry about it.

Here is a little picture that might clarify things.  Suppose Latitude and Longitude are two variables on which the algorithm may choose to split.  This means that splits in these geographical variables can only occur in a North-South or an East-West direction.  Let's suppose you add in two extra variables that are completely dependent on the first, namely

	LatPlusLong <- Latitude + Longitude
	LatMinusLong <- Latitude - Longitude

and now offer all four variables as potential split variables.  Now the algorithm may split North-South, East-West, NorthEast-SouthWest or NorthWest-SouthEast.  All you have done is increase the scope of choice for the algorithm to make splits.  Not only does the linear dependence not matter, but I'd argue it could be a pretty good thing.

One serious message to take from this as well, though, is to use regression trees for prediction.  Don't read too much into the variables that the algorithm has chosen to use at any stage.

Bill Venables.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jean-Noel
Sent: Monday, 9 February 2004 8:25 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Recursive partitioning with multicollinear variables


Dear all,
I would like to perform a regression tree analysis on a dataset with multicollinear variables (as climate variables often are). The questions that I am asking are:
 1- Is there any particular statistical problem in using multicollinear variables in a regression tree?
 2- Multicollinear variables should appear as alternate splits. Would it be more accurate to present these alternate splits in the results of the analysis or apply a variable selection or reduction procedure before the regression tree? Thank you in advance,

Jean-Noel Candau

INRA - Unit? de Recherches Foresti?res M?diterran?ennes
Avenue A. Vivaldi
84000 AVIGNON
Tel: (33) 4 90 13 59 22
Fax: (33) 4 90 13 59 59

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From feh3k at spamcop.net  Mon Feb  9 12:53:47 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Mon, 9 Feb 2004 06:53:47 -0500
Subject: [R] Recursive partitioning with multicollinear variables
In-Reply-To: <GOENJEALPPDFMBOMCKOJGENCCAAA.jean-noel.candau@avignon.inra.fr>
References: <GOENJEALPPDFMBOMCKOJGENCCAAA.jean-noel.candau@avignon.inra.fr>
Message-ID: <20040209065347.75a33e0d.feh3k@spamcop.net>

On Mon, 9 Feb 2004 11:24:39 +0100
"Jean-Noel" <jean-noel.candau at avignon.inra.fr> wrote:

> Dear all,
> I would like to perform a regression tree analysis on a dataset with
> multicollinear variables (as climate variables often are). The questions
> that I am asking are:
>  1- Is there any particular statistical problem in using multicollinear
> variables in a regression tree?
>  2- Multicollinear variables should appear as alternate splits. Would it
>  be
> more accurate to present these alternate splits in the results of the
> analysis or apply a variable selection or reduction procedure before the
> regression tree?
> Thank you in advance,
> 
> Jean-Noel Candau

A more accurate and stable result would be obtained by performing a data
reduction procedure that ignores the response variable.  Combining
collinear variables into an index is often better than arbitrarily
choosing between them.  Then use the indexes in a regression model unless
you have tens of thousands of observations for recursive partitioning, or
are using bagging of trees or a related procedure to cancel out the
instability in the tree growing process [which unfortunately will often
result in an average of trees that is more complex in appearance than a
regression model].

Frank
---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From dmurdoch at pair.com  Mon Feb  9 13:08:26 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 09 Feb 2004 07:08:26 -0500
Subject: [R] 0.1 + 0.2 != 0.3 revisited
In-Reply-To: <40273C29.4010706@wsl.ch>
References: <6C8A8033ABC1E3468048ABC4F13CE572F021D8@synequanon01>
	<3if720tukrh46rikg23jb4fvh3o2vhoah1@4ax.com>
	<40273C29.4010706@wsl.ch>
Message-ID: <mrse20tacvr7fhev81ff7k6fg3sdri6fvr@4ax.com>

On Mon, 09 Feb 2004 08:52:09 +0100, you wrote:

>Hi,
>
>IEEE says that real numbers are normalized (a few below 10^(-16) may be 
>not [gradual underflow]), so that they look like 0.1ddd2^ex. Then only 
>ddd and ex are kept:
>0.1 = 0.00011.. 2^0 = 0.11001100.. 2^(-3) -> (11001100.., -3)

Right, that's pretty much what I said, since 1.6 = 1.101100...

>> Both 0.1 and 0.2 are less than 1, so the n=52 count is wrong.  I think
>> 0.1 would be stored as (1 + 0.6)*2^(-4) and 0.2 would be stored as (1
>> + 0.6)*2^(-3),


>> You
>> should expect 56 decimal (binary?) place accuracy on 0.1, 55 place
>> accuracy on 0.2, and 54 place accuracy on 0.3.  It's not surprising
>> weird things happen!
>
>I don *not* think so: all mantissas here have *52 binary* places!

Yes, but I was counting bits after the binary point, not bits that are
stored.  The latter is 52 for all numbers, but it translates into more
or less bits after the binary point, depending on the magnitude of the
exponent. 

You can argue that I got the exponent wrong (saying it was -4, when
you say it's -3), and I could live with that.  I was just following
the Intel convention that the mantissa is 1.dddd.. instead of
0.1dddd.. .

Duncan Murdoch



From gwiggner at lix.polytechnique.fr  Mon Feb  9 13:48:35 2004
From: gwiggner at lix.polytechnique.fr (Claus Gwiggner)
Date: Mon, 9 Feb 2004 13:48:35 +0100 (CET)
Subject: [R] Estimate Covariance Matrix of two vectors
Message-ID: <Pine.LNX.4.44.0402091339510.16523-100000@lix.polytechnique.fr>

Hi,

I have m observations of a vector (p1,...,pp) of random variables and 
another m of a second vector (v1,...,vp) of same length.
How can I get an estimation of the covariance matrix for all pairs 
of variables (pi,vj) ?

Thanks.



From FWS4 at CDRH.FDA.GOV  Mon Feb  9 13:56:07 2004
From: FWS4 at CDRH.FDA.GOV (Samuelson, Frank*)
Date: Mon, 9 Feb 2004 07:56:07 -0500
Subject: [R] moments, skewness, kurtosis
Message-ID: <644D9337A02FC24689647BF9E48EC39E08ABB75F@drm556>

I checked the help and the mailing list archives, but I can
find no mention of a routine that calculates higher 
moments like skewness and kurtosis.   Of course, these
are easy enough to write myself, but I was thinking
that they MUST be in here.  Am I wrong?

Thanks.

-Frank



From andy_liaw at merck.com  Mon Feb  9 14:08:42 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 9 Feb 2004 08:08:42 -0500
Subject: [R] PhD student reading list, suggestions wanted
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7751@usrymx25.merck.com>

> From: Ko-Kang Kevin Wang
> 
> Hi,
> 
> > -----Original Message-----
> > But above all, I would like her to use R whenever it's appropriate.
> > We have MASS and Dalgaard's introductory book in the 
> library here, I'm
> > aware of "S Poetry", but what do you think would be the 
> best start for
> > someone learning R in order to use it for doing data mining?
> 
> Not specifically for R, but a must-have for anyone going into 
> data mining
> area is "The Elements of Statistical Learning: Data Mining, 
> Inference, and Prediction", by Hastie et. al.

I would add BDR's 1996 Pattern Recognition and Neural Networks, and FEH's
2002 Regression Modeling Strategies.

Even though Prof. Harrell's book is not strictly about data mining, it has
lots of things that dataminers need to know about, or at least be aware of,
IMHO.

Andy

 
> Kevin
> 
> --------------------------------------------
> Ko-Kang Kevin Wang, MSc(Hon)
> SLC Stats Workshops Co-ordinator
> The University of Auckland
> New Zealand
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From olefc at daimi.au.dk  Mon Feb  9 14:10:37 2004
From: olefc at daimi.au.dk (Ole F. Christensen)
Date: Mon, 09 Feb 2004 14:10:37 +0100
Subject: [R] Subset function of lm(); "rolling regressions"
Message-ID: <402786CD.3050608@daimi.au.dk>

You need brackets in i:(i+25)

3:3+25

is not want you

3:(3+25)

is what you want.

to explicitly print out values in a for loop you need to use print

for (i in 1:10) {
  print(i)
}


Ole

-- 
Ole F. Christensen
Center for Bioinformatik
Aarhus Universitet
Ny Munkegade, Bygning 540
8000 Aarhus C



From Rau at demogr.mpg.de  Mon Feb  9 14:09:20 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Mon, 9 Feb 2004 14:09:20 +0100
Subject: [R] moments, skewness, kurtosis
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A0682@hermes.demogr.mpg.de>

Hi,

> -----Original Message-----
> From:	Samuelson, Frank* [SMTP:FWS4 at CDRH.FDA.GOV]
> Sent:	Monday, February 09, 2004 1:56 PM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] moments, skewness, kurtosis
> 
> I checked the help and the mailing list archives, but I can
> find no mention of a routine that calculates higher 
> moments like skewness and kurtosis.   Of course, these
> are easy enough to write myself, but I was thinking
> that they MUST be in here.  Am I wrong?
> 
	Is this what you are looking for?
	library(e1071)
	?moment

	I found it via:
	help.search("moments")

	Best,
	Roland



+++++
This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked.   If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.



From partha_bagchi at hgsi.com  Mon Feb  9 14:12:08 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Mon, 9 Feb 2004 08:12:08 -0500
Subject: [R] moments, skewness, kurtosis
Message-ID: <OF5CCCCF8F.A804A244-ON85256E35.00487B82-85256E35.004885C6@hgsi.com>

package e1071 on CRAN





"Samuelson, Frank*" <FWS4 at CDRH.FDA.GOV>
Sent by: r-help-bounces at stat.math.ethz.ch
02/09/2004 07:56 AM

 
        To:     r-help at stat.math.ethz.ch
        cc: 
        Subject:        [R] moments, skewness, kurtosis


I checked the help and the mailing list archives, but I can
find no mention of a routine that calculates higher
moments like skewness and kurtosis.   Of course, these
are easy enough to write myself, but I was thinking
that they MUST be in here.  Am I wrong?

Thanks.

-Frank

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

--
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From andy_liaw at merck.com  Mon Feb  9 15:00:15 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 9 Feb 2004 09:00:15 -0500
Subject: [R] Estimate Covariance Matrix of two vectors
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7754@usrymx25.merck.com>

cov(mat1, mat2) will give you the covariances in a p1 by p2 matrix, assuming
mat1 has p1 columns and mat2 has p2 columns.

HTH,
Andy

> From: Claus Gwiggner
> 
> Hi,
> 
> I have m observations of a vector (p1,...,pp) of random variables and 
> another m of a second vector (v1,...,vp) of same length.
> How can I get an estimation of the covariance matrix for all pairs 
> of variables (pi,vj) ?
> 
> Thanks.


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ernesto at ipimar.pt  Mon Feb  9 15:21:43 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon, 09 Feb 2004 14:21:43 +0000
Subject: [R] PhD student reading list, suggestions wanted
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7751@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7751@usrymx25.merck.com>
Message-ID: <1076336502.27203.40.camel@gandalf.local>

On Mon, 2004-02-09 at 13:08, Liaw, Andy wrote:
> > From: Ko-Kang Kevin Wang
> > 
> > Hi,
> > 
> > > -----Original Message-----
> > > But above all, I would like her to use R whenever it's appropriate.
> > > We have MASS and Dalgaard's introductory book in the 
> > library here, I'm
> > > aware of "S Poetry", but what do you think would be the 
> > best start for
> > > someone learning R in order to use it for doing data mining?
> > 
> > Not specifically for R, but a must-have for anyone going into 
> > data mining
> > area is "The Elements of Statistical Learning: Data Mining, 
> > Inference, and Prediction", by Hastie et. al.
> 
> I would add BDR's 1996 Pattern Recognition and Neural Networks, and FEH's
> 2002 Regression Modeling Strategies.
> 
> Even though Prof. Harrell's book is not strictly about data mining, it has
> lots of things that dataminers need to know about, or at least be aware of,
> IMHO.
> 
> Andy
> 
>  
> > Kevin
> > 
> > --------------------------------------------
> > Ko-Kang Kevin Wang, MSc(Hon)
> > SLC Stats Workshops Co-ordinator
> > The University of Auckland
> > New Zealand

Hi,

What online references would you propose ?

Regards

EJ



From HStevens at muohio.edu  Mon Feb  9 15:21:21 2004
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Mon, 9 Feb 2004 09:21:21 -0500
Subject: [R] citing a package?
Message-ID: <3C15EE06-5B0B-11D8-98CD-000A958F43CC@MUOhio.edu>

How do I cite a package (not R itself - I know how to do that)? Any 
thoughts or links?
Many thanks in advance?
Hank Stevens

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/



From vtas at uosis.mif.vu.lt  Mon Feb  9 15:34:47 2004
From: vtas at uosis.mif.vu.lt (vtas@uosis.mif.vu.lt)
Date: Mon, 9 Feb 2004 16:34:47 +0200 (EET)
Subject: [R] PhD student reading list, suggestions wanted
Message-ID: <2588.193.219.42.106.1076337287.squirrel@kedras.mif.vu.lt>

Hi,
maybe "Data Data Mining with R: learning by case studies" by Luis Torgo
(http://www.liacc.up.pt/~ltorgo/DataMiningWithR/)
will be usefull.

Vytautas Maniusis,
Vilnius University, Lithuania



From bjz9 at cdc.gov  Mon Feb  9 15:38:07 2004
From: bjz9 at cdc.gov (Shoultz, Gerald)
Date: Mon, 9 Feb 2004 09:38:07 -0500
Subject: [R] Another question,
	unfortunately. . . .(Installing "foreign"/trying to
	import/export SAS files)
Message-ID: <8A4148E4383C434980BE3D08AE2436921C55AC@m-nchs-1.nchs.cdc.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040209/88a3ef5c/attachment.pl

From rdiaz at cnio.es  Mon Feb  9 15:02:17 2004
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Mon, 9 Feb 2004 15:02:17 +0100
Subject: [R] citing a package?
In-Reply-To: <3C15EE06-5B0B-11D8-98CD-000A958F43CC@MUOhio.edu>
References: <3C15EE06-5B0B-11D8-98CD-000A958F43CC@MUOhio.edu>
Message-ID: <200402091502.17476.rdiaz@cnio.es>

Dear Martin,

I'd suggest you check the "DESCRIPTION" file and ask the author(s) of the 
package (e.g., a package might be related to a tech report which might, now, 
be in press, or whatever).

Best,

R.


On Monday 09 February 2004 15:21, Martin Henry H. Stevens wrote:
> How do I cite a package (not R itself - I know how to do that)? Any
> thoughts or links?
> Many thanks in advance?
> Hank Stevens
>
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/botany/bot/henry.html
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz
PGP KeyID: 0xE89B3462
(http://bioinfo.cnio.es/~rdiaz/0xE89B3462.asc)



From paulojus at est.ufpr.br  Mon Feb  9 15:59:47 2004
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Mon, 9 Feb 2004 12:59:47 -0200 (BRST)
Subject: [R] citing a package?
In-Reply-To: <3C15EE06-5B0B-11D8-98CD-000A958F43CC@MUOhio.edu>
References: <3C15EE06-5B0B-11D8-98CD-000A958F43CC@MUOhio.edu>
Message-ID: <Pine.LNX.4.58L0.0402091252580.19018@est.ufpr.br>

Hi
As far I'm concern the package author should tell you that.
Some packages have an article about them in the R-NEWS and this is a
possible way to cite them.
Otherwise we are left with the reference to the contributed packages
session of the CRAN web-site.

R has the citation() function and inspired by this
we create the functions cite.geoR() and cite.geoRglm() the packages geoR
and geoRglm.

Would it be an idea having some global standard, including this a a
requirement for the packages (?)

P.J.

On Mon, 9 Feb 2004, Martin Henry H. Stevens wrote:

> How do I cite a package (not R itself - I know how to do that)? Any
> thoughts or links?
> Many thanks in advance?
> Hank Stevens
>
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/botany/bot/henry.html
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From jarioksa at sun3.oulu.fi  Mon Feb  9 16:20:24 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 09 Feb 2004 17:20:24 +0200
Subject: [R] citing a package?
In-Reply-To: <3C15EE06-5B0B-11D8-98CD-000A958F43CC@MUOhio.edu>
References: <3C15EE06-5B0B-11D8-98CD-000A958F43CC@MUOhio.edu>
Message-ID: <1076340024.3880.11.camel@biol102145.oulu.fi>

On Mon, 2004-02-09 at 16:21, Martin Henry H. Stevens wrote:
> How do I cite a package (not R itself - I know how to do that)? Any 
> thoughts or links?
> Many thanks in advance?

I think it is the duty of a package author to write a citable paper, if
he thinks that such is needed. It could be useful to have this kind of
information easily available in the package, so that you do not have to
ask the authors how to cite their package. A natural looking place for
this kind of information is the package DESCRIPTION. However, there is
no standard entry for citation there. Now it seems that some packages
have a hint to citing (for instance, MASS: "Functions and datasets to
support Venables and Ripley, 'Modern Applied Statistics with S' (4th
edition)"), while some book-backed packages have no pointers to the book
(nlme, for instance). However, all CRAN packages have a pdf file of the
package documentation in CRAN. If citing URL is allowed in the journal,
this is a place to point.

cheers, jari oksanen 
-- 
J.Oksanen, Oulu, Finland.
"Object-oriented programming is an exceptionally bad idea which could
only have originated in California." E. Dijkstra



From bjz9 at cdc.gov  Mon Feb  9 16:24:48 2004
From: bjz9 at cdc.gov (Shoultz, Gerald)
Date: Mon, 9 Feb 2004 10:24:48 -0500
Subject: [R] Re:  Another question, unfortunately.
Message-ID: <8A4148E4383C434980BE3D08AE2436921C55AD@m-nchs-1.nchs.cdc.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040209/3fdcdb1f/attachment.pl

From p.dalgaard at biostat.ku.dk  Mon Feb  9 16:28:50 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Feb 2004 16:28:50 +0100
Subject: [R] Another question,
	unfortunately. . . .(Installing "foreign"/trying to import/export SAS
	files)
In-Reply-To: <8A4148E4383C434980BE3D08AE2436921C55AC@m-nchs-1.nchs.cdc.gov>
References: <8A4148E4383C434980BE3D08AE2436921C55AC@m-nchs-1.nchs.cdc.gov>
Message-ID: <x2hdy0mfv1.fsf@biostat.ku.dk>

"Shoultz, Gerald" <bjz9 at cdc.gov> writes:

> I have downloaded R--no problem there. Unfortunately, I have run into a
> second problem.
> 
> I am trying to use read.ssd and then read.xport (to get a SAS data set).
> I have imported the package "foreign" according to instructions (
> options(CRAN="http://cran.us.r-project.org/") and
> install.packages("foreign") ), but when I do so and then use either
> read.ssd or read.xport I get the message 'couldn't find function . . .'.
> Obviously these two directions are not getting the file installed
> properly. Is there something I have overlooked somewhere? Please advise.

I suspect you forgot to do

library(foreign)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From friendly at yorku.ca  Mon Feb  9 16:34:23 2004
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 09 Feb 2004 10:34:23 -0500
Subject: [R] nedit syntax highlighting patterns for R?
Message-ID: <4027A87F.9080404@yorku.ca>

I tried to install the syntax pattern file, R-5.1.pats (obtained from 
www.nedit.org)
in version 5.3 of nedit, but it gives the following errors.   Does 
anyone have a
more up-to-date copy?

euclid: ~/nedit % nedit -import R-5.1.pats
NEdit: language mode must be specified in highlight pattern:
 
<==
NEdit: style name required in style specification:
Note:darkRed:Italic
<==
NEdit: expecting quoted string in language mode specification:
<==q .r .R::::::

-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From Rau at demogr.mpg.de  Mon Feb  9 16:47:25 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Mon, 9 Feb 2004 16:47:25 +0100
Subject: [R] Another question, unfortunately. . . .(Installing "foreig
	n"/trying to import/export SAS files)
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A0687@hermes.demogr.mpg.de>

Hi,

> -----Original Message-----
> From:	Shoultz, Gerald [SMTP:bjz9 at cdc.gov]
> Sent:	Monday, February 09, 2004 3:38 PM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] Another question, unfortunately. . . .(Installing
> "foreign"/trying to import/export SAS files)
> 
> 
> I am trying to use read.ssd and then read.xport (to get a SAS data set).
> I have imported the package "foreign" according to instructions (
> options(CRAN="http://cran.us.r-project.org/") and
> install.packages("foreign") ), but when I do so and then use either
> read.ssd or read.xport I get the message 'couldn't find function . . .'.
> Obviously these two directions are not getting the file installed
> properly. Is there something I have overlooked somewhere? Please advise.
> 
	In the default settings, the library "foreign" is not pre-installed.
	You have to add it to the current session by typing:
	library(foreign)
	Now, the functions read.ssd and read.xport should be available.

	Best,
	Roland




+++++
This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked.   If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.



From tlumley at u.washington.edu  Mon Feb  9 17:08:18 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 9 Feb 2004 08:08:18 -0800 (PST)
Subject: [R] citing a package?
In-Reply-To: <200402091502.17476.rdiaz@cnio.es>
References: <3C15EE06-5B0B-11D8-98CD-000A958F43CC@MUOhio.edu>
	<200402091502.17476.rdiaz@cnio.es>
Message-ID: <Pine.A41.4.58.0402090757440.23088@homer25.u.washington.edu>

On Mon, 9 Feb 2004, Ramon Diaz-Uriarte wrote:

> Dear Martin,
>
> I'd suggest you check the "DESCRIPTION" file and ask the author(s) of the
> package (e.g., a package might be related to a tech report which might, now,
> be in press, or whatever).
>

The posted suggestions seem to be that you don't cite the package, you
cite something else vaguely related to it instead.  This violates both the
purpose of a citation (a link to the original source) and the principle
(which I hope R users support) that software is publishable in itself, not
just as an appendage to text.

Most citation styles give rules for citing software and rules for citing
URIs.  Even when the package author has been completely unhelpful in
constructing a package title you can still put together a perfectly
reasonable citation, eg,

Lumley T (2003) Rmeta version 2.10. R package. http://cran.r-project.org

Some publishers might want a download date, or an explicit statement that
it is software (eg to make searching easier).

	-thomas



From ernesto at ipimar.pt  Mon Feb  9 17:19:22 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon, 09 Feb 2004 16:19:22 +0000
Subject: [R] nedit syntax highlighting patterns for R?
In-Reply-To: <4027A87F.9080404@yorku.ca>
References: <4027A87F.9080404@yorku.ca>
Message-ID: <1076343562.27203.59.camel@gandalf.local>

Hi,

I've updated to version 5.3, maybe it's not on the web site. You can
find it here

http://ernesto.freezope.org/cmf/starthere/opensource/r/R-5.3.pats

Best regards

EJ

On Mon, 2004-02-09 at 15:34, Michael Friendly wrote:
> I tried to install the syntax pattern file, R-5.1.pats (obtained from 
> www.nedit.org)
> in version 5.3 of nedit, but it gives the following errors.   Does 
> anyone have a
> more up-to-date copy?
> 
> euclid: ~/nedit % nedit -import R-5.1.pats
> NEdit: language mode must be specified in highlight pattern:
>  
> <==
> NEdit: style name required in style specification:
> Note:darkRed:Italic
> <==
> NEdit: expecting quoted string in language mode specification:
> <==q .r .R::::::



From spencer.graves at pdf.com  Mon Feb  9 17:20:26 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 09 Feb 2004 08:20:26 -0800
Subject: [R] citing a package?
In-Reply-To: <1076340024.3880.11.camel@biol102145.oulu.fi>
References: <3C15EE06-5B0B-11D8-98CD-000A958F43CC@MUOhio.edu>
	<1076340024.3880.11.camel@biol102145.oulu.fi>
Message-ID: <4027B34A.6000305@pdf.com>

      While the idea of writing a citable paper is great and 
appropriate, I think the word "duty" is too strong.  Competent 
professionals can still make valuable contributions to the R Project 
without this kind of external publication. 

      In academia, at least in the US, professors are paid in part to 
publish. Outside of academia, anyone who wishes to publish has much less 
support for doing so, and is often actively discouraged by intellectual 
property clauses in employment contracts that require internal reviews 
by people with little understanding of how "new knowledge" is created. 

      We should all be thankful for the contributions made to R by those 
who can NOT even get credit for it in an annual performance review.  
Their contributions should be judged on utility to other R users, not on 
whether it is converted into a separate publication. 

      just my humble opinion. 
      spencer graves

Jari Oksanen wrote:

>On Mon, 2004-02-09 at 16:21, Martin Henry H. Stevens wrote:
>  
>
>>How do I cite a package (not R itself - I know how to do that)? Any 
>>thoughts or links?
>>Many thanks in advance?
>>    
>>
>
>I think it is the duty of a package author to write a citable paper, if
>he thinks that such is needed. It could be useful to have this kind of
>information easily available in the package, so that you do not have to
>ask the authors how to cite their package. A natural looking place for
>this kind of information is the package DESCRIPTION. However, there is
>no standard entry for citation there. Now it seems that some packages
>have a hint to citing (for instance, MASS: "Functions and datasets to
>support Venables and Ripley, 'Modern Applied Statistics with S' (4th
>edition)"), while some book-backed packages have no pointers to the book
>(nlme, for instance). However, all CRAN packages have a pdf file of the
>package documentation in CRAN. If citing URL is allowed in the journal,
>this is a place to point.
>
>cheers, jari oksanen 
>  
>



From bjz9 at cdc.gov  Mon Feb  9 17:27:15 2004
From: bjz9 at cdc.gov (Shoultz, Gerald)
Date: Mon, 9 Feb 2004 11:27:15 -0500
Subject: [R] Importing a SAS file to R: Alas,
	STILL more problems--has anyone gotten this message before, and why 
Message-ID: <8A4148E4383C434980BE3D08AE2436921C55AF@m-nchs-1.nchs.cdc.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040209/a78ac40d/attachment.pl

From stvjc at channing.harvard.edu  Mon Feb  9 17:37:57 2004
From: stvjc at channing.harvard.edu (Vincent Carey 525-2265)
Date: Mon, 9 Feb 2004 11:37:57 -0500 (EST)
Subject: [R] Re: Importing a SAS file to R: Alas,
 STILL more problems--has anyone gotten this message before, and why 
In-Reply-To: <8A4148E4383C434980BE3D08AE2436921C55AF@m-nchs-1.nchs.cdc.gov>
References: <8A4148E4383C434980BE3D08AE2436921C55AF@m-nchs-1.nchs.cdc.gov>
Message-ID: <Pine.GSO.4.58.0402091134110.28408@capecod.bwh.harvard.edu>

i am the author of read.ssd, and did not accommodate sas for
windows in the creation of that function.  i do not know how
sas is called under windows, but it is possible that if you
learn how to invoke sas through the R "system" command, you
can supply the invocation command as the "sascmd" parameter
to read.ssd

other ways of transferring the information from SAS to R
include 1) using a put statement to write the data out record
by record into a whitespace delimited file, and then using
read.table in R to collect the data for use in R, 2) using
read.ssd on a unix system, saving the resulting R object,
and then transferring the R object back to windows.

---
Vince Carey

On Mon, 9 Feb 2004, Shoultz, Gerald wrote:

> Sorry to write twice in one day--I am a relative newbie to some of these
> parts of R, and I am pulling my hair out!  B/c I am preparing a file to
> use WINBUGS I am cross-posting to the BUGS group as well, in case anyone
> there has some ideas on this.
>
> I've got a large SAS dataset that I want to put in R form to more easily
> use the file with the hierarchical modeling software WINBUGS. It has
> numerous variables, so setting up "vertical text files" could be
> awkward. I did get the library foreign installed OK.  I am now trying to
> run read.ssd.  What I have below is similar to that found in the
> documentation for the foreign package, p.9:
>
> >  list.files("C:/Project_data/WINBUGSfiles")
> [1] "lastfile.sas7bdat"
> > dtabunch<-read.ssd("C:/Project_data/WINBUGSfiles","lastfile")
>
> I unfortunately got this:
>
> SAS failed.  SAS program at
> C:\DOCUME~1\bjz9\LOCALS~1\Temp\Rtmp23335\file29621.sas
> a log and other error products should be in the vicinity
> Warning messages:
> 1: sas not found
> 2: ls not found
> 3: SAS return code was -1 in: read.ssd("C:/Project_data/WINBUGSfiles",
> "lastfile")
>
> I have tried to find the log file but have been unable to do so.Can
> someone who has had this happen before kindly tell me what exactly (or
> possibly) is going on?  I went to the SAS Technical Support Document
> TS-140 to try to get help and really didn't get much out of that.  Does
> anyone know a better (as in "foolproof/will avoid meaningless error
> messages") way to get a SAS dataset into R-format?  Any help on this
> would be most appreciated.
>
> Thanks!
>
> Gerald Shoultz
>
>
>



From andihund at hotmail.com  Mon Feb  9 18:00:29 2004
From: andihund at hotmail.com (Andi Hund)
Date: Mon, 9 Feb 2004 09:00:29 -0800
Subject: [R] Duncan's Multiple Range test
Message-ID: <Law11-OE53EVldCJuw00003454f@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040209/d3d3bcb3/attachment.pl

From p.dalgaard at biostat.ku.dk  Mon Feb  9 18:10:07 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Feb 2004 18:10:07 +0100
Subject: [R] Re: Importing a SAS file to R: Alas,
	STILL more problems--has anyone gotten this message before, and why
In-Reply-To: <Pine.GSO.4.58.0402091134110.28408@capecod.bwh.harvard.edu>
References: <8A4148E4383C434980BE3D08AE2436921C55AF@m-nchs-1.nchs.cdc.gov>
	<Pine.GSO.4.58.0402091134110.28408@capecod.bwh.harvard.edu>
Message-ID: <x2d68omb68.fsf@biostat.ku.dk>

Vincent Carey 525-2265 <stvjc at channing.harvard.edu> writes:

> i am the author of read.ssd, and did not accommodate sas for
> windows in the creation of that function.  i do not know how
> sas is called under windows, but it is possible that if you
> learn how to invoke sas through the R "system" command, you
> can supply the invocation command as the "sascmd" parameter
> to read.ssd
> 
> other ways of transferring the information from SAS to R
> include 1) using a put statement to write the data out record
> by record into a whitespace delimited file, and then using
> read.table in R to collect the data for use in R, 2) using
> read.ssd on a unix system, saving the resulting R object,
> and then transferring the R object back to windows.

...or use various export facilities from the toolbar in SAS for
Windows (availability may or may not require that you have or have not
started the Analyst application...). You can write SPSS .por files
which can be read in R by read.spss, for instance. 

Or, create an XPORT library for read.xport with a variation of the
following SAS code snippet.

libname foo xport "foo.xpt";
DATA foo.bar;
set sasuser.bar;
run;
 
> ---
> Vince Carey
> 
> On Mon, 9 Feb 2004, Shoultz, Gerald wrote:
> 
> > Sorry to write twice in one day--I am a relative newbie to some of these
> > parts of R, and I am pulling my hair out!  B/c I am preparing a file to
> > use WINBUGS I am cross-posting to the BUGS group as well, in case anyone
> > there has some ideas on this.
> >
> > I've got a large SAS dataset that I want to put in R form to more easily
> > use the file with the hierarchical modeling software WINBUGS. It has
> > numerous variables, so setting up "vertical text files" could be
> > awkward. I did get the library foreign installed OK.  I am now trying to
> > run read.ssd.  What I have below is similar to that found in the
> > documentation for the foreign package, p.9:
> >
> > >  list.files("C:/Project_data/WINBUGSfiles")
> > [1] "lastfile.sas7bdat"
> > > dtabunch<-read.ssd("C:/Project_data/WINBUGSfiles","lastfile")
> >
> > I unfortunately got this:
> >
> > SAS failed.  SAS program at
> > C:\DOCUME~1\bjz9\LOCALS~1\Temp\Rtmp23335\file29621.sas
> > a log and other error products should be in the vicinity
> > Warning messages:
> > 1: sas not found
> > 2: ls not found
> > 3: SAS return code was -1 in: read.ssd("C:/Project_data/WINBUGSfiles",
> > "lastfile")
> >
> > I have tried to find the log file but have been unable to do so.Can
> > someone who has had this happen before kindly tell me what exactly (or
> > possibly) is going on?  I went to the SAS Technical Support Document
> > TS-140 to try to get help and really didn't get much out of that.  Does
> > anyone know a better (as in "foolproof/will avoid meaningless error
> > messages") way to get a SAS dataset into R-format?  Any help on this
> > would be most appreciated.
> >
> > Thanks!
> >
> > Gerald Shoultz
> >
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From White.Denis at epamail.epa.gov  Mon Feb  9 18:27:58 2004
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Mon, 09 Feb 2004 09:27:58 -0800
Subject: [R] column names in matrix vs. data frame in R 1.8
Message-ID: <OFEFE12043.8E7182F1-ON88256E35.005FA9A8-88256E35.005FEE89@epamail.epa.gov>





> White.Denis at epamail.epa.gov writes:
>
> > Is the difference in behavior below, introduced in 1.8, inconsistent
or,
> > at least, undesirable?  I couldn't find this in the NEWS.
> >
> > On the one hand,
> >
> > > a <- matrix (1:4, nrow=2)
> > > a <- data.frame (a)
> > > names (a) <- c("break","next")
> > > names (a)
> > [1] "break" "next"
> >
> > On the other,
> >
> > > a <- matrix (1:4, nrow=2)
> > > dimnames(a) <- list (1:2, c("break","next"))
> > > a <- data.frame (a)
> > > names(a)
> > [1] "break." "next."
>
> Works fine if you don't use keywords as column names
>
> > a <- matrix (1:4, nrow=2)
> > dimnames(a) <- list (1:2, c("foo","bar"))
> > b <- data.frame(a)
> > names(b)
> [1] "foo" "bar"
>
> The difference in the result for your example has to do with an extra
> step in the second case to obtain a legitimate name that can be used
> with the $ operator.  R generates a syntax error for
>
> a$break
>
> but not for
>
> a$break.

Ok, I'll regard it as an inconsistency that the conversion of dimnames
to data frame column names changes reserved words to legitimate names
but direct assignment doesn't.



From marcos.sanches at ipsos-opinion.com.br  Mon Feb  9 19:59:01 2004
From: marcos.sanches at ipsos-opinion.com.br (Marcos Sanches)
Date: Mon, 9 Feb 2004 15:59:01 -0300
Subject: RES: [R] Duncan's Multiple Range test
In-Reply-To: <Law11-OE53EVldCJuw00003454f@hotmail.com>
Message-ID: <002b01c3ef3e$c7da2900$d297a8c0@opinionserver>


 Hi all!

 I wrote a very basic program in R, which has some loops ('for' and
'while').  Is there a way to print the 'for' (or while) indice while the
program is running so that I am able to estimate where the program is
and how long it will last?

I mean, I want something like this:

i<-0
While(i<100){
"do a lot of commands"
"print i"
i<-i+1
}

How do I "print" the "i" at each step?

Thanks in advance,

Marcos



From feh3k at spamcop.net  Mon Feb  9 18:53:08 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Mon, 9 Feb 2004 12:53:08 -0500
Subject: [R] Re: Importing a SAS file to R: Alas, STILL more
	problems--has anyone gotten this message before, and why
In-Reply-To: <Pine.GSO.4.58.0402091134110.28408@capecod.bwh.harvard.edu>
References: <8A4148E4383C434980BE3D08AE2436921C55AF@m-nchs-1.nchs.cdc.gov>
	<Pine.GSO.4.58.0402091134110.28408@capecod.bwh.harvard.edu>
Message-ID: <20040209125308.482d0cff.feh3k@spamcop.net>

On Mon, 9 Feb 2004 11:37:57 -0500 (EST)
Vincent Carey 525-2265 <stvjc at channing.harvard.edu> wrote:

> i am the author of read.ssd, and did not accommodate sas for
> windows in the creation of that function.  i do not know how
> sas is called under windows, but it is possible that if you
> learn how to invoke sas through the R "system" command, you
> can supply the invocation command as the "sascmd" parameter
> to read.ssd
> 
> other ways of transferring the information from SAS to R
> include 1) using a put statement to write the data out record
> by record into a whitespace delimited file, and then using
> read.table in R to collect the data for use in R, 2) using
> read.ssd on a unix system, saving the resulting R object,
> and then transferring the R object back to windows.
> 
> ---
> Vince Carey

Also take a look at the sas.get and sasxport.get (which calls read.xport)
functions in the Hmisc package.

Frank

> 
> On Mon, 9 Feb 2004, Shoultz, Gerald wrote:
> 
> > Sorry to write twice in one day--I am a relative newbie to some of
> > these parts of R, and I am pulling my hair out!  B/c I am preparing a
> > file to use WINBUGS I am cross-posting to the BUGS group as well, in
> > case anyone there has some ideas on this.
> >
> > I've got a large SAS dataset that I want to put in R form to more
> > easily use the file with the hierarchical modeling software WINBUGS.
> > It has numerous variables, so setting up "vertical text files" could
> > be awkward. I did get the library foreign installed OK.  I am now
> > trying to run read.ssd.  What I have below is similar to that found in
> > the documentation for the foreign package, p.9:
> >
> > >  list.files("C:/Project_data/WINBUGSfiles")
> > [1] "lastfile.sas7bdat"
> > > dtabunch<-read.ssd("C:/Project_data/WINBUGSfiles","lastfile")
> >
> > I unfortunately got this:
> >
> > SAS failed.  SAS program at
> > C:\DOCUME~1\bjz9\LOCALS~1\Temp\Rtmp23335\file29621.sas
> > a log and other error products should be in the vicinity
> > Warning messages:
> > 1: sas not found
> > 2: ls not found
> > 3: SAS return code was -1 in: read.ssd("C:/Project_data/WINBUGSfiles",
> > "lastfile")
> >
> > I have tried to find the log file but have been unable to do so.Can
> > someone who has had this happen before kindly tell me what exactly (or
> > possibly) is going on?  I went to the SAS Technical Support Document
> > TS-140 to try to get help and really didn't get much out of that. 
> > Does anyone know a better (as in "foolproof/will avoid meaningless
> > error messages") way to get a SAS dataset into R-format?  Any help on
> > this would be most appreciated.
> >
> > Thanks!
> >
> > Gerald Shoultz
> >
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html


---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From marcos.sanches at ipsos-opinion.com.br  Mon Feb  9 20:08:38 2004
From: marcos.sanches at ipsos-opinion.com.br (Marcos Sanches)
Date: Mon, 9 Feb 2004 16:08:38 -0300
Subject: [R] Printting 'for' and 'while' indices
Message-ID: <002c01c3ef40$20297880$d297a8c0@opinionserver>

Sorry, I forgot to correct the message subject, so I am resending my
doubt it below:


 Hi all!

 I wrote a very basic program in R, which has some loops ('for' and
'while').  Is there a way to print the 'for' (or while) indice while the
program is running so that I am able to estimate where the program is
and how long it will last?

I mean, I want something like this:

i<-0
While(i<100){
"do a lot of commands"
"print i"
i<-i+1
}

How do I "print" the "i" at each step?

Thanks in advance,

Marcos



From sfalcon at fhcrc.org  Mon Feb  9 19:13:26 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 9 Feb 2004 10:13:26 -0800
Subject: [R] xtable table placement
Message-ID: <20040209181325.GB16392@queenbee.fhcrc.org>

Hi all,

I'm wondering if there is a way specify LaTeX table position within a a
call to xtable.

xtable(adataframe) produces LaTeX code for tables containing:

    \begin{table}[ht]
                 ^^^^

I would like to specify the position parameters.  Looking at the code
for print.xtable I was hoping 

    > xtable(adataframe, table.placement = "hp")

would work, but it does not.  Am I missing something simple?

Thanks,

+ seth



From k.wang at auckland.ac.nz  Mon Feb  9 19:18:11 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 10 Feb 2004 07:18:11 +1300
Subject: [R] PhD student reading list, suggestions wanted
In-Reply-To: <1076336502.27203.40.camel@gandalf.local>
Message-ID: <20040209181823.TZZE11548.web3-rme.xtra.co.nz@kevinlpt>

Hi,

[This is slightly offtopic as it has nothing to do with R, but I'm still
sending it to the list in case someone else is interested].

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ernesto Jardim
> Sent: Tuesday, February 10, 2004 3:22 AM
> To: Mailing List R
> Subject: RE: [R] PhD student reading list, suggestions wanted
>
> Hi,
>
> What online references would you propose ?

It depends on how much you already know about data mining.  Two Crow's
"Introduction to Data Mining and Knowledge Discovery" (http://www.twocrows.
com/) might be a good introductory guide and is available for free download
(it is a recommended reading at a Year 3 undergraduate course here at my
university).  Journal of Machine Learning Research (http://www.jmlr.org/)
may have some useful article.  My Master's Dissertation
(http://www.stat.auckland.ac.nz/~kwan022/research.php) sort of briefly
compared a few methods (neural net, decision trees and Logistic regression)
and benchmarked them, but that is using SAS Enterprise Miner.  If you want
some data to try out data mining methods, the UCI Machine Learning
Repository (http://www.ics.uci.edu/~mlearn/) is the best place to go.

And finally, there is google....;-D.

HTH,

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
SLC Stats Workshops Co-ordinator
The University of Auckland
New Zealand



From dsmith at insightful.com  Mon Feb  9 19:32:05 2004
From: dsmith at insightful.com (David Smith)
Date: Mon, 9 Feb 2004 10:32:05 -0800
Subject: [R] R does in memory analysis only?
Message-ID: <EDAC416B87ECCA44BEAB4D0CF48034EF2C672D@se2kexch01.insightful.com>

Ross Boylan writes:
> R works only on problems that fit into (real or virtual) memory.
> ... does S-Plus have the same limitation?

S-PLUS, like R, does its computations in-memory. So you're limited to solving
problems which can fit in the available RAM (plus available swap space).  The
OS may impose additional limits (e.g. 2GB of total address space on many
Windows systems).

However, Insightful Miner, which works with S-PLUS, does include algorithms
which can process data sets out of memory. This includes the ability to
perform regressions on data sets much larger than the available RAM (the only
limit is the availability of disk space to store the results).  You can also
link S-PLUS with Insightful to perform out-of-memory calculations using
S-PLUS functions.  This works especially well with operations like predicting
from a model, which can be performed on a row-by-row basis.

I wrote a long discussion about in-memory and out-of-memory algorithms in the
context of S-PLUS and Insightful Miner, which you can download from:

http://www.insightful.com/support/whitepaper_download.asp

# David Smith

-- 
David M Smith <dsmith at insightful.com>
Product Manager, Insightful Corp, Seattle WA
Tel: +1 (206) 802 2360
Fax: +1 (206) 283 6310

New Insightful Miner 3! Discover how Pfizer, Bank of America and others are
using Insightful Miner -- a highly scalable data analysis workbench. Learn
more at http://www.insightful.com/products/iminer

> -----Original Message-----
> From: Ross Boylan [mailto:ross at biostat.ucsf.edu]
> Sent: Saturday, February 07, 2004 2:16 PM
> To: r-help
> Subject: [R] R does in memory analysis only?
> 
> 
> I wonder if someone would confirm something I'm 99% sure of from the
> docs and discussion on the list, but can't find stated explicitly:
> R works only on problems that fit into (real or virtual) memory.
> 
> Thus, even if you have a problem (e.g., simple regression) 
> that could be
> solved by doing some operation on each row of a dataset at a time, you
> can't solve it unless the entire dataset and associated intermediate
> results fit in memory.
> 
> So if you're in 32 bits, your max problem size is about 2G (regular
> Windows and Linux limit your process size to this, though I think some
> fancy versions let you go a bit higher).
> 
> Is there any thought of relaxing this limitation?  I realize doing so
> would be a big job.  I also realize that 64 bits makes it much less
> pressing.
> 
> Finally, does S-Plus have the same limitation?
> 
> Thanks.
> -- 
> Ross Boylan                                      wk:  (415) 502-4031
> 530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
> Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
> University of California, San Francisco
> San Francisco, CA 94143-0840                     hm:  (415) 550-1062
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From Vlad.Zaha at hmbg.utah.edu  Mon Feb  9 19:51:13 2004
From: Vlad.Zaha at hmbg.utah.edu (Vlad Zaha)
Date: Mon, 9 Feb 2004 11:51:13 -0700
Subject: [R] Affy library: error on ReadAffy()
Message-ID: <CB844A2CB7DC7442B3345C55AE08736C08C170@mse.hmbg.utah.edu>

When I try to load cel files (hgu133a) using the ReadAffy() in R 1.8.1
command I get an error message:

> x<-ReadAffy()
Error: cannot allocate vector of size 102973 Kb

Does anybody know what does this error mean and how to overcome it?

I have tried to load the same data with R 1.7.1 and it works. There is
also no error when I use R 1.8.1 to load moe430 cel files.

Thanks very much for any input.

Vlad



From bwheeler at echip.com  Mon Feb  9 19:50:22 2004
From: bwheeler at echip.com (Bob Wheeler)
Date: Mon, 09 Feb 2004 13:50:22 -0500
Subject: [R] citing a package?
References: <3C15EE06-5B0B-11D8-98CD-000A958F43CC@MUOhio.edu>	<200402091502.17476.rdiaz@cnio.es>
	<Pine.A41.4.58.0402090757440.23088@homer25.u.washington.edu>
Message-ID: <4027D66E.1010707@echip.com>

I faced this problem recently when documenting the AlgDesign package. It 
contains some stuff the isn't in the literature, so I added a citation 
statement in the AUTHOR section of each function. Even after the 
material is published, I think a citation to a working "model" is quite 
appropriate.

Thomas Lumley wrote:
> On Mon, 9 Feb 2004, Ramon Diaz-Uriarte wrote:
> 
> 
>>Dear Martin,
>>
>>I'd suggest you check the "DESCRIPTION" file and ask the author(s) of the
>>package (e.g., a package might be related to a tech report which might, now,
>>be in press, or whatever).
>>
> 
> 
> The posted suggestions seem to be that you don't cite the package, you
> cite something else vaguely related to it instead.  This violates both the
> purpose of a citation (a link to the original source) and the principle
> (which I hope R users support) that software is publishable in itself, not
> just as an appendage to text.
> 
> Most citation styles give rules for citing software and rules for citing
> URIs.  Even when the package author has been completely unhelpful in
> constructing a package title you can still put together a perfectly
> reasonable citation, eg,
> 
> Lumley T (2003) Rmeta version 2.10. R package. http://cran.r-project.org
> 
> Some publishers might want a download date, or an explicit statement that
> it is software (eg to make searching easier).
> 
> 	-thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Bob Wheeler --- http://www.bobwheeler.com/
         ECHIP, Inc. ---
Randomness comes in bunches.



From tura at centroin.com.br  Mon Feb  9 20:05:38 2004
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Mon, 09 Feb 2004 16:05:38 -0300
Subject: [R] Fit system of equations
Message-ID: <6.0.0.22.2.20040209155454.034098b0@pop.centroin.com.br>

Hi R-masters

I have this system of equations

R(x,t)= a(t)+b(x,t)
a(t) = c + d*t
b(t) = e + f*t

where 
x is a vetor of age<-c(37,42,47,52,57,62,67,72,77,83),
t is vetor of year (1980:2000)
R(x,t) = Rate of mortality in age x on year t
a(t) = base mortality on year t
b(x,t) = exponential rate of mortality for age x on year t
b(t) = exponential rate of mortality on year t

I wish is possible fit this system in R?
Case positive Which the best method?



Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil 

From amiraa10 at yahoo.fr  Mon Feb  9 20:09:13 2004
From: amiraa10 at yahoo.fr (=?iso-8859-1?q?AMIRA=20BLANCO?=)
Date: Mon, 9 Feb 2004 20:09:13 +0100 (CET)
Subject: [R] STARMA model building
Message-ID: <20040209190913.10928.qmail@web21107.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040209/c153c4a5/attachment.pl

From heberto.ghezzo at mcgill.ca  Mon Feb  9 20:30:07 2004
From: heberto.ghezzo at mcgill.ca (r.ghezzo)
Date: Mon, 09 Feb 2004 14:30:07 -0500
Subject: [R] how to use try()
In-Reply-To: <2588.193.219.42.106.1076337287.squirrel@kedras.mif.vu.lt>
References: <2588.193.219.42.106.1076337287.squirrel@kedras.mif.vu.lt>
Message-ID: <4027DFBF.7090604@mcgill.ca>

Hello, I have a program with this section:
..
for(i in 1:20){
   lo <- nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
   beta[i] <- lo$m$getPars()[4]
}
..
If the fit works this is OK but if the fit fails, the whole program 
fails so:
..
for(i in 1:20){
   try(lo <- 
nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
   beta[i] <- lo$m$getPars()[4]
}
..
but the try catches the error in nls and beta[i] gets assigned beta[i-1] 
from the previous loop. This is bad but no so bad as it can be checked,
Now in some cases the error is in i=1 and the program stops!!
is there a way to set lo$m$getPars() to zero before the call?
I tried to understand the use of tryCatch() but frankly it is above me. 
Sorry
Thanks for any help
Heberto Ghezzo
Meakins-Christie Labs



From HStevens at muohio.edu  Mon Feb  9 20:35:44 2004
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Mon, 9 Feb 2004 14:35:44 -0500
Subject: [R] citing a package?
In-Reply-To: <Pine.A41.4.58.0402090757440.23088@homer25.u.washington.edu>
References: <3C15EE06-5B0B-11D8-98CD-000A958F43CC@MUOhio.edu>
	<200402091502.17476.rdiaz@cnio.es>
	<Pine.A41.4.58.0402090757440.23088@homer25.u.washington.edu>
Message-ID: <275C5A6F-5B37-11D8-98CD-000A958F43CC@MUOhio.edu>

Thank you to all the contributors to my original post. It has been 
informative to me, and appears to have provoked a small but important 
discussion about how we perform our duties in our various capacities as 
creators, developers and users.
I like Thomas' suggestion,
> eg,
> Lumley T (2003) Rmeta version 2.10. R package. 
> http://cran.r-project.org
in addition to citing papers or books that discuss details of use, 
e.g., citing Venalbles and Ripley (2002) Modern Applied Statistics with 
S, for the MASS package.

Thanks again,
Hank Stevens

On Feb 9, 2004, at 11:08 AM, Thomas Lumley wrote:

> On Mon, 9 Feb 2004, Ramon Diaz-Uriarte wrote:
>
>> Dear Martin,
>>
>> I'd suggest you check the "DESCRIPTION" file and ask the author(s) of 
>> the
>> package (e.g., a package might be related to a tech report which 
>> might, now,
>> be in press, or whatever).
>>
>
> The posted suggestions seem to be that you don't cite the package, you
> cite something else vaguely related to it instead.  This violates both 
> the
> purpose of a citation (a link to the original source) and the principle
> (which I hope R users support) that software is publishable in itself, 
> not
> just as an appendage to text.
>
> Most citation styles give rules for citing software and rules for 
> citing
> URIs.  Even when the package author has been completely unhelpful in
> constructing a package title you can still put together a perfectly
> reasonable citation, eg,
>
> Lumley T (2003) Rmeta version 2.10. R package. 
> http://cran.r-project.org
>
> Some publishers might want a download date, or an explicit statement 
> that
> it is software (eg to make searching easier).
>
> 	-thomas
>
>
Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/



From gustavo at estatcamp.com.br  Mon Feb  9 21:47:36 2004
From: gustavo at estatcamp.com.br (Gustavo Pinheiro)
Date: Mon, 9 Feb 2004 17:47:36 -0300
Subject: [R] data.frame to matrix
Message-ID: <000401c3ef4d$f3d7c3f0$6200a8c0@blackdog>

Hello all,

I've had trouble converting a data.frame to a matrix (numeric) using either
data.matrix() and as.matrix().
After executing one of those I end up with another data.frame with only the
first column of the original data.frame.
I use a window (tcltk) to let the user choose the columns he wants and then
I retrieve them using the following:

varstemp <- .numeric[as.numeric(tkcurselection(subgroupsBox)) + 1]

where ".numeric" is the original (complete) data.frame.

Any ideas why is this happening? I'm using R1.8.1 in WinXP by the way.

Thanks.



From jgentry at jimmy.harvard.edu  Mon Feb  9 20:49:14 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon, 9 Feb 2004 14:49:14 -0500 (EST)
Subject: [R] Printting 'for' and 'while' indices
In-Reply-To: <002c01c3ef40$20297880$d297a8c0@opinionserver>
Message-ID: <Pine.SOL.4.20.0402091449060.4254-100000@santiam.dfci.harvard.edu>

> How do I "print" the "i" at each step?

print(i)?



From abunn at montana.edu  Mon Feb  9 20:49:41 2004
From: abunn at montana.edu (Andy Bunn)
Date: Mon, 9 Feb 2004 12:49:41 -0700
Subject: [R] citing a package?
In-Reply-To: <4027D66E.1010707@echip.com>
Message-ID: <000c01c3ef45$ef347440$a0a00ecf@simATE>

I had a reviewer request a citation for a package that I had neglected to
cite. I followed a similar format to that suggested by Thomas Lumley and
also referenced a related book by the package's author. The editor thought
it was nifty.

My two cents.

-Andy



From abunn at montana.edu  Mon Feb  9 20:54:02 2004
From: abunn at montana.edu (Andy Bunn)
Date: Mon, 9 Feb 2004 12:54:02 -0700
Subject: [R] Printting 'for' and 'while' indices
In-Reply-To: <002c01c3ef40$20297880$d297a8c0@opinionserver>
Message-ID: <000d01c3ef46$8c834c30$a0a00ecf@simATE>

Try this. Look at ?flsuh.console if you are on windows

HTH, Andy

#~~~~~~~~~~~~~~~~~~~~~~~~
i<-0
while(i<100){
## "do a lot of commands"

##"print i"
cat(i, "\n")

## if using windows
flush.console()

i<-i+1
}



From rpeng at jhsph.edu  Mon Feb  9 21:00:56 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 09 Feb 2004 15:00:56 -0500
Subject: [R] Printting 'for' and 'while' indices
In-Reply-To: <002c01c3ef40$20297880$d297a8c0@opinionserver>
References: <002c01c3ef40$20297880$d297a8c0@opinionserver>
Message-ID: <4027E6F8.3080707@jhsph.edu>

Use cat() or print().

-roger

Marcos Sanches wrote:
> Sorry, I forgot to correct the message subject, so I am resending my
> doubt it below:
> 
> 
>  Hi all!
> 
>  I wrote a very basic program in R, which has some loops ('for' and
> 'while').  Is there a way to print the 'for' (or while) indice while the
> program is running so that I am able to estimate where the program is
> and how long it will last?
> 
> I mean, I want something like this:
> 
> i<-0
> While(i<100){
> "do a lot of commands"
> "print i"
> i<-i+1
> }
> 
> How do I "print" the "i" at each step?
> 
> Thanks in advance,
> 
> Marcos
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Mon Feb  9 21:08:15 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 09 Feb 2004 12:08:15 -0800
Subject: [R] Printting 'for' and 'while' indices
In-Reply-To: <002c01c3ef40$20297880$d297a8c0@opinionserver>
References: <002c01c3ef40$20297880$d297a8c0@opinionserver>
Message-ID: <4027E8AF.6010807@pdf.com>

      Consider the following: 

 > i <- 0
 > while(i < 5) {
    "do stuff"
    print(i)
    i <- i + 1
}
[1] 0
[1] 1
[1] 2
[1] 3
[1] 4
 > i <- 0
 > while(i < 5) {
    "do stuff"
    cat(i, "")
    i <- i + 1
}
0 1 2 3 4 > i <- 0
 > while(i < 100) {
    "do stuff"
    if((i %% 10) == 0)
        cat(i, "")
    i <- i + 1
}
0 10 20 30 40 50 60 70 80 90

      This was produced in S-Plus 6.2 under Windows 2000.  For some 
reason, when I copy this code from S-Plus to R1.8.1 via XEmacs, this is 
locking up R for me right now, and I can't figure out why.  However, I 
see no reason why these constructs would not work in R. 

      hope this helps. 
      spencer graves

Marcos Sanches wrote:

>Sorry, I forgot to correct the message subject, so I am resending my
>doubt it below:
>
>
> Hi all!
>
> I wrote a very basic program in R, which has some loops ('for' and
>'while').  Is there a way to print the 'for' (or while) indice while the
>program is running so that I am able to estimate where the program is
>and how long it will last?
>
>I mean, I want something like this:
>
>i<-0
>While(i<100){
>"do a lot of commands"
>"print i"
>i<-i+1
>}
>
>How do I "print" the "i" at each step?
>
>Thanks in advance,
>
>Marcos
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From rog at stanford.edu  Mon Feb  9 21:22:48 2004
From: rog at stanford.edu (Roger Levy)
Date: 09 Feb 2004 12:22:48 -0800
Subject: [R] simple question on picking out some rows of a matrix/data frame
Message-ID: <25isigovdz.fsf@joel.Stanford.EDU>

Hi,

I have a simple question about matrix/data frame manipulation.  I have
a data frame that looks a something like this

  X    Y    Z
  1    0    "apples"
  -1   -1   "oranges"
  ...
  0    -1   "bananas"

and I'd like to pull out all the rows for which X and Y are (un)equal
into a submatrix.

How can I do that?

Many thanks,

Roger Levy



From dmurdoch at pair.com  Mon Feb  9 21:24:52 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 09 Feb 2004 15:24:52 -0500
Subject: [R] data.frame to matrix
In-Reply-To: <000401c3ef4d$f3d7c3f0$6200a8c0@blackdog>
References: <000401c3ef4d$f3d7c3f0$6200a8c0@blackdog>
Message-ID: <sqqf20tpv3dnolf2eoqvfjotorgdj6d6as@4ax.com>

On Mon, 9 Feb 2004 17:47:36 -0300, "Gustavo Pinheiro"
<gustavo at estatcamp.com.br> wrote :

>Hello all,
>
>I've had trouble converting a data.frame to a matrix (numeric) using either
>data.matrix() and as.matrix().
>After executing one of those I end up with another data.frame with only the
>first column of the original data.frame.
>I use a window (tcltk) to let the user choose the columns he wants and then
>I retrieve them using the following:
>
>varstemp <- .numeric[as.numeric(tkcurselection(subgroupsBox)) + 1]
>
>where ".numeric" is the original (complete) data.frame.
>
>Any ideas why is this happening? I'm using R1.8.1 in WinXP by the way.

I'd guess "as.numeric(tkcurselection(subgroupsBox)) + 1" isn't
returning what you think it's returning, or maybe .numeric isn't in
the form you think.

I'd also recommend using both row and column indices when working with
data frames.  What you have selects columns from a data.frame, but not
from a matrix (assuming that the index is a vector of integers).  I
find it's safer to treat data.frames as matrices whenever you can,
i.e. use a blank row index

varstemp <- .numeric[ , as.numeric(tkcurselection(subgroupsBox)) + 1] 

Duncan Murdoch



From marcos.sanches at ipsos-opinion.com.br  Mon Feb  9 22:38:17 2004
From: marcos.sanches at ipsos-opinion.com.br (Marcos Sanches)
Date: Mon, 9 Feb 2004 18:38:17 -0300
Subject: [R] RConsole
Message-ID: <003501c3ef55$076df090$d297a8c0@opinionserver>


	I changed my R console configurations, for example, the letters
are white, the background is black, etc,... Then I saved this new
configuration. What should I do if I want to have this new configuration
everytime I open R?

	TIA



From bates at stat.wisc.edu  Mon Feb  9 22:05:05 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 09 Feb 2004 15:05:05 -0600
Subject: [R] simple question on picking out some rows of a matrix/data
	frame
In-Reply-To: <25isigovdz.fsf@joel.Stanford.EDU>
References: <25isigovdz.fsf@joel.Stanford.EDU>
Message-ID: <6roes8ynem.fsf@bates4.stat.wisc.edu>

"subset" will do the selection.  If you really want a matrix for the
result you will need to coerce it using "as.matrix".

Roger Levy <rog at stanford.edu> writes:

> I have a simple question about matrix/data frame manipulation.  I have
> a data frame that looks a something like this
> 
>   X    Y    Z
>   1    0    "apples"
>   -1   -1   "oranges"
>   ...
>   0    -1   "bananas"
> 
> and I'd like to pull out all the rows for which X and Y are (un)equal
> into a submatrix.
> 
> How can I do that?
> 
> Many thanks,
> 
> Roger Levy



From gustavo at estatcamp.com.br  Mon Feb  9 23:10:00 2004
From: gustavo at estatcamp.com.br (Gustavo Pinheiro)
Date: Mon, 9 Feb 2004 19:10:00 -0300
Subject: RES: [R] data.frame to matrix
In-Reply-To: <sqqf20tpv3dnolf2eoqvfjotorgdj6d6as@4ax.com>
Message-ID: <000501c3ef59$76c90840$6200a8c0@blackdog>

Hi Duncan,

You were right. It was a vector and not a data.frame that I was dealing
with. But still I am having dificulties. Please, take a look at some output
(I am using R Commander GUI by the way):

R-cmdr> print(b) 
 [1] 0.70 0.85 0.80 0.70 0.75 0.75 0.80 0.70 0.80 0.75 0.80 0.79 0.78 0.75
0.76
[16] 0.70 0.70 0.70 0.80 0.80 0.70 0.65 0.60 0.70 0.55 0.80 0.65 0.60 0.70
 [1] 0.65 0.75 0.80 0.70 0.65 0.75 0.65 0.80 0.85 0.70 0.80 0.79 0.78 0.85
0.76
[16] 0.75 0.85 0.60 0.80 0.75 0.85 0.85 0.65 0.70 0.65 0.65 0.75 0.60 0.60
 [1] 0.65 0.75 0.80 0.70 0.65 0.75 0.65 0.80 0.85 0.70 0.80 0.79 0.78 0.85
0.76
[16] 0.75 0.85 0.60 0.80 0.75 0.85 0.85 0.65 0.70 0.65 0.65 0.75 0.60 0.60

R-cmdr> print(length(b)) 
[1] 29
[1] 29
[1] 29

R-cmdr> print(b[1])
[1] 0.70
[1] 0.65
[1] 0.65

R-cmdr> print(b[1,])
Error: incorrect number of dimention 

R-cmdr> print(b[,2])
Error: incorrect number of dimention

Looking at this output I figured b is a vector of vectors (3 to be exact).
The thing is I want to create a matrix made of b's lines (which were
originaly columns in my dataset) as columns, but I could not find a way to
retrieve a line from b in a way similar to what one would do with dataframes
(dataframe[1,]). You can see in the above output that a call to b[1,]
returns an error and a call to b[1] returns the first column. So, how to
retrieve a whole line? Keep in mind that the size of b is not known before
hand, so if it turns out to be necessary to go through each element another
problem would arise: a call to length() returns the length of each one of
these 3 vectors, but not the length of the containg vector b which is 3.

Was I clear enough? My english is not so great ;-)

Regards,

Gustavo.

-----Mensagem original-----
De: Duncan Murdoch [mailto:dmurdoch at pair.com] 
Enviada em: Monday, February 09, 2004 5:25 PM
Para: Gustavo Pinheiro
Cc: r-help at stat.math.ethz.ch
Assunto: Re: [R] data.frame to matrix


On Mon, 9 Feb 2004 17:47:36 -0300, "Gustavo Pinheiro"
<gustavo at estatcamp.com.br> wrote :

>Hello all,
>
>I've had trouble converting a data.frame to a matrix (numeric) using 
>either
>data.matrix() and as.matrix().
>After executing one of those I end up with another data.frame with only the
>first column of the original data.frame.
>I use a window (tcltk) to let the user choose the columns he wants and then
>I retrieve them using the following:
>
>varstemp <- .numeric[as.numeric(tkcurselection(subgroupsBox)) + 1]
>
>where ".numeric" is the original (complete) data.frame.
>
>Any ideas why is this happening? I'm using R1.8.1 in WinXP by the way.

I'd guess "as.numeric(tkcurselection(subgroupsBox)) + 1" isn't returning
what you think it's returning, or maybe .numeric isn't in the form you
think.

I'd also recommend using both row and column indices when working with data
frames.  What you have selects columns from a data.frame, but not from a
matrix (assuming that the index is a vector of integers).  I find it's safer
to treat data.frames as matrices whenever you can, i.e. use a blank row
index

varstemp <- .numeric[ , as.numeric(tkcurselection(subgroupsBox)) + 1] 

Duncan Murdoch



From k.wang at auckland.ac.nz  Mon Feb  9 21:31:39 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 10 Feb 2004 09:31:39 +1300
Subject: [R] Printting 'for' and 'while' indices
In-Reply-To: <002c01c3ef40$20297880$d297a8c0@opinionserver>
References: <002c01c3ef40$20297880$d297a8c0@opinionserver>
Message-ID: <1076358699.e688231efb5ee@webmail.auckland.ac.nz>

Quoting Marcos Sanches <marcos.sanches at ipsos-opinion.com.br>:

> I mean, I want something like this:
> 
> i<-0
> While(i<100){
> "do a lot of commands"
> "print i"
> i<-i+1
> }
> 
> How do I "print" the "i" at each step?

Is
  print(i)
what you want?

Cheers,

Kevin
------------------------------------------------------------
Ko-Kang Kevin Wang
SLC Statistics Workshops Co-ordinator
Student Learning Centre
University of Auckland
New Zealand

-------------------------------------------------
This mail sent through University of Auckland
http://www.auckland.ac.nz/



From jfox at mcmaster.ca  Mon Feb  9 22:16:13 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 09 Feb 2004 16:16:13 -0500
Subject: [R] data.frame to matrix
In-Reply-To: <000401c3ef4d$f3d7c3f0$6200a8c0@blackdog>
Message-ID: <web-13826920@cgpsrv2.cis.mcmaster.ca>

Dear Gustavo,

To fill in other list members, this is occurring with code written to
augment the Rcmdr package.

The problem is that .numeric is a vector of names of numeric variables
in the "active data set" (data frame) maintained by Rcmdr, it is not
itself a data frame. Consequently, your varstemp is also a vector of
names, which could be used to index the active data set, whose name is
stored in .activeDataSet.

I hope that this helps,
 John

On Mon, 9 Feb 2004 17:47:36 -0300
 "Gustavo Pinheiro" <gustavo at estatcamp.com.br> wrote:
> Hello all,
> 
> I've had trouble converting a data.frame to a matrix (numeric) using
> either
> data.matrix() and as.matrix().
> After executing one of those I end up with another data.frame with
> only the
> first column of the original data.frame.
> I use a window (tcltk) to let the user choose the columns he wants
> and then
> I retrieve them using the following:
> 
> varstemp <- .numeric[as.numeric(tkcurselection(subgroupsBox)) + 1]
> 
> where ".numeric" is the original (complete) data.frame.
> 
> Any ideas why is this happening? I'm using R1.8.1 in WinXP by the
> way.
> 
> Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From lisas at salford-systems.com  Mon Feb  9 22:21:10 2004
From: lisas at salford-systems.com (Lisa Solomon)
Date: Mon, 09 Feb 2004 13:21:10 -0800
Subject: [R] CART Data Mining 2004 Conference, San Francisco,
	SCHEDULE information
Message-ID: <4027F9C6.4010205@salford-systems.com>

Apologies for cross posting

CART Data Mining 2004, San Francisco, March 22-24, 2004

Below are links for the registration and the 
latest scheduling information. Please note that you can register with an early-bird 
discount if you register NOW and write the words "SCHEDULE" on your 
registration form.

Homepage: http://www.cartdatamining.com
Detailed Conference Schedule: http://www.cartdatamining.com/program.htm
Registration (San Francisco): http://www.cartdatamining.com/RegCART04.pdf

**
OPENING SESSION, Monday March 22nd, 7:30 PM

Personal recollections of Leo Breiman, Jerome Friedman, Richard Olshen,
Charles Stone. Join us to hear Breiman, Friedman, Olshen and Stone
discuss their early research interests and trace the ideas,
decisions, and chance events that culminated in CART, their landmark work.

**
Join us for John Elder's popular presentation: "Top Ten Data Mining
Mistakes (with real-world examples)"

"Best Practices" for Data Mining will be (accidentally)illuminated by 
their (rarely described) opposites. Come hear cautionary tales of 
endangered projects and embarrassed teams -- and thereby perhaps avoid such a fate yourself.

**
Immediately Preceding the Opening Session
NEW TUTORIAL! NEVER OFFERED BEFORE!

Introducing Jerome Friedman's TreeNet/MART and Leo Breiman's
Random Forests, revolutionary new contributions to data mining.

Cost: 35% Discount for all Conference Attendees.

Other optional pre-conference tutorials for CART, MARS and Hybrid
Modeling will be offered the week preceding the conference. These
hands-on Tutorials will be discounted 35% for conference attendees.
Tutorial Registration: http://www.cartdatamining.com/workshops.htm 

**
Early-bird Registration Discount Deadline extension for SAN FRANCISCO:
Must write code: SCHEDULE on the registration form.
http://www.cartdatamining.com/RegCART04.pdf 

Early-bird Registration Discount Deadline for Madrid venue: March 30, 2004
http://www.cartdatamining.com/RegCART04Madrid.pdf

To register, please click on the links above or call: 619-543-8880

**
To be placed on the CART Data Mining mailing list, please respond to
info at cartdatamining.com



Please let me know if you have any 
further questions.

Sincerely,
Lisa Solomon
lisas at salford-systems.com
619-543-8880 x14



From tlumley at u.washington.edu  Mon Feb  9 22:25:55 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 9 Feb 2004 13:25:55 -0800 (PST)
Subject: [R] simple question on picking out some rows of a matrix/data
	frame
In-Reply-To: <25isigovdz.fsf@joel.Stanford.EDU>
References: <25isigovdz.fsf@joel.Stanford.EDU>
Message-ID: <Pine.A41.4.58.0402091325260.56386@homer18.u.washington.edu>

On Mon, 9 Feb 2004, Roger Levy wrote:

> Hi,
>
> I have a simple question about matrix/data frame manipulation.  I have
> a data frame that looks a something like this
>
>   X    Y    Z
>   1    0    "apples"
>   -1   -1   "oranges"
>   ...
>   0    -1   "bananas"
>
> and I'd like to pull out all the rows for which X and Y are (un)equal
> into a submatrix.
>

subset(the.data.frame,  X!=Y)

	-thomas



From jfox at mcmaster.ca  Mon Feb  9 22:28:02 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 09 Feb 2004 16:28:02 -0500
Subject: [R] simple question on picking out some rows of a
	matrix/data frame
In-Reply-To: <25isigovdz.fsf@joel.Stanford.EDU>
Message-ID: <web-13830411@cgpsrv2.cis.mcmaster.ca>

Dear Roger,

Something like mat[mat[,1] == mat[,2],] or mat[mat[,1] != mat[,2],]
should give you what you want.

I hope that this helps,
 John

On 09 Feb 2004 12:22:48 -0800
 Roger Levy <rog at stanford.edu> wrote:
> Hi,
> 
> I have a simple question about matrix/data frame manipulation.  I
> have
> a data frame that looks a something like this
> 
>   X    Y    Z
>   1    0    "apples"
>   -1   -1   "oranges"
>   ...
>   0    -1   "bananas"
>
> and I'd like to pull out all the rows for which X and Y are (un)equal
> into a submatrix.
> 
> How can I do that?
> 
> Many thanks,
> 
> Roger Levy
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From rog at stanford.edu  Mon Feb  9 22:44:11 2004
From: rog at stanford.edu (Roger Levy)
Date: 09 Feb 2004 13:44:11 -0800
Subject: [R] Re: simple question on picking out some rows of a matrix/data
	frame
In-Reply-To: <25isigovdz.fsf@joel.Stanford.EDU>
Message-ID: <25u1203p3o.fsf@joel.Stanford.EDU>

Many thanks for the numerous edifying responses!

Best

Roger



From sundar.dorai-raj at pdf.com  Mon Feb  9 23:05:17 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 09 Feb 2004 16:05:17 -0600
Subject: [R] how to use try()
In-Reply-To: <4027DFBF.7090604@mcgill.ca>
References: <2588.193.219.42.106.1076337287.squirrel@kedras.mif.vu.lt>
	<4027DFBF.7090604@mcgill.ca>
Message-ID: <4028041D.2020808@pdf.com>



r.ghezzo wrote:

> Hello, I have a program with this section:
> ..
> for(i in 1:20){
>   lo <- nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
>   beta[i] <- lo$m$getPars()[4]
> }
> ..
> If the fit works this is OK but if the fit fails, the whole program 
> fails so:
> ..
> for(i in 1:20){
>   try(lo <- nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
>   beta[i] <- lo$m$getPars()[4]
> }
> ..
> but the try catches the error in nls and beta[i] gets assigned beta[i-1] 
> from the previous loop. This is bad but no so bad as it can be checked,
> Now in some cases the error is in i=1 and the program stops!!
> is there a way to set lo$m$getPars() to zero before the call?
> I tried to understand the use of tryCatch() but frankly it is above me. 
> Sorry
> Thanks for any help
> Heberto Ghezzo
> Meakins-Christie Labs
> 

How about:

beta[i] <- if(data.class(lo) == "Error") 0 else lo$m$getPars()[4]

-sundar



From p.dalgaard at biostat.ku.dk  Mon Feb  9 23:11:49 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Feb 2004 23:11:49 +0100
Subject: [R] how to use try()
In-Reply-To: <4027DFBF.7090604@mcgill.ca>
References: <2588.193.219.42.106.1076337287.squirrel@kedras.mif.vu.lt>
	<4027DFBF.7090604@mcgill.ca>
Message-ID: <x27jyvkimy.fsf@biostat.ku.dk>

"r.ghezzo" <heberto.ghezzo at mcgill.ca> writes:

> Hello, I have a program with this section:
> ..
> for(i in 1:20){
>    lo <- nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
>    beta[i] <- lo$m$getPars()[4]
> }
> ..
> If the fit works this is OK but if the fit fails, the whole program
> fails so:
> ..
> for(i in 1:20){
>    try(lo <-
> nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
>    beta[i] <- lo$m$getPars()[4]
> }
> ..
> but the try catches the error in nls and beta[i] gets assigned
> beta[i-1] from the previous loop. This is bad but no so bad as it can
> be checked,
> Now in some cases the error is in i=1 and the program stops!!
> is there a way to set lo$m$getPars() to zero before the call?
> I tried to understand the use of tryCatch() but frankly it is above
> me. Sorry

Just check the return value from try:

beta[i] <- if(inherits(try(.....),"try-error")) NA else lo$etc...

(or use sapply) and, er, shouldn't there be a dependency on i
somewhere in the model fit???

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jfox at mcmaster.ca  Mon Feb  9 23:11:39 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 09 Feb 2004 17:11:39 -0500
Subject: [R] how to use try()
In-Reply-To: <4027DFBF.7090604@mcgill.ca>
Message-ID: <web-13842274@cgpsrv2.cis.mcmaster.ca>

Dear Heberto,

beta is a vector? Then something like

lo <-
try(nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
beta[i] <- if (class(lo) == "try-error") NA else lo$m$getPars()[4]

might do what you want.

John

On Mon, 09 Feb 2004 14:30:07 -0500
 "r.ghezzo" <heberto.ghezzo at mcgill.ca> wrote:
> Hello, I have a program with this section:
> ..
> for(i in 1:20){
>   lo <-
> nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
>   beta[i] <- lo$m$getPars()[4]
> }
> ..
> If the fit works this is OK but if the fit fails, the whole program
> fails so:
> ..
> for(i in 1:20){
>   try(lo <- 
> nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
>   beta[i] <- lo$m$getPars()[4]
> }
> ..
> but the try catches the error in nls and beta[i] gets assigned
> beta[i-1] from the previous loop. This is bad but no so bad as it can
> be checked,
> Now in some cases the error is in i=1 and the program stops!!
> is there a way to set lo$m$getPars() to zero before the call?
> I tried to understand the use of tryCatch() but frankly it is above
> me. Sorry
> Thanks for any help
> Heberto Ghezzo
> Meakins-Christie Labs
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From tlumley at u.washington.edu  Mon Feb  9 23:15:32 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 9 Feb 2004 14:15:32 -0800 (PST)
Subject: [R] how to use try()
In-Reply-To: <4027DFBF.7090604@mcgill.ca>
References: <2588.193.219.42.106.1076337287.squirrel@kedras.mif.vu.lt>
	<4027DFBF.7090604@mcgill.ca>
Message-ID: <Pine.A41.4.58.0402091410040.56386@homer18.u.washington.edu>

On Mon, 9 Feb 2004, r.ghezzo wrote:

> Hello, I have a program with this section:
> ..
> for(i in 1:20){
>    lo <- nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
>    beta[i] <- lo$m$getPars()[4]
> }
> ..
> If the fit works this is OK but if the fit fails, the whole program
> fails so:
> ..
> for(i in 1:20){
>    try(lo <-
> nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
>    beta[i] <- lo$m$getPars()[4]
> }
> ..
> but the try catches the error in nls and beta[i] gets assigned beta[i-1]
> from the previous loop. This is bad but no so bad as it can be checked,


You want either both assignments inside the try()
try({
	lo<-nls(....)
	beta[i]<-lo$m$getPars(4)
})

or both outside

lo<- try(nls(....))
if (inherits(lo,"try-error")) beta[i]<-NA else beta[i]<-lo$m$getPars()[4]


	-thomas



From sundar.dorai-raj at pdf.com  Mon Feb  9 23:28:38 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 09 Feb 2004 16:28:38 -0600
Subject: [R] how to use try()
In-Reply-To: <x27jyvkimy.fsf@biostat.ku.dk>
References: <2588.193.219.42.106.1076337287.squirrel@kedras.mif.vu.lt>	<4027DFBF.7090604@mcgill.ca>
	<x27jyvkimy.fsf@biostat.ku.dk>
Message-ID: <40280996.40006@pdf.com>

Sorry, got my S-PLUS and R confused. Peter is right. The class is 
"try-error" and not "Error" (as it is in S-PLUS).

Sundar


Peter Dalgaard wrote:

> "r.ghezzo" <heberto.ghezzo at mcgill.ca> writes:
> 
> 
>>Hello, I have a program with this section:
>>..
>>for(i in 1:20){
>>   lo <- nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
>>   beta[i] <- lo$m$getPars()[4]
>>}
>>..
>>If the fit works this is OK but if the fit fails, the whole program
>>fails so:
>>..
>>for(i in 1:20){
>>   try(lo <-
>>nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
>>   beta[i] <- lo$m$getPars()[4]
>>}
>>..
>>but the try catches the error in nls and beta[i] gets assigned
>>beta[i-1] from the previous loop. This is bad but no so bad as it can
>>be checked,
>>Now in some cases the error is in i=1 and the program stops!!
>>is there a way to set lo$m$getPars() to zero before the call?
>>I tried to understand the use of tryCatch() but frankly it is above
>>me. Sorry
> 
> 
> Just check the return value from try:
> 
> beta[i] <- if(inherits(try(.....),"try-error")) NA else lo$etc...
> 
> (or use sapply) and, er, shouldn't there be a dependency on i
> somewhere in the model fit???
>



From hb at maths.lth.se  Mon Feb  9 23:40:14 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Mon, 9 Feb 2004 23:40:14 +0100
Subject: [R] Printting 'for' and 'while' indices
In-Reply-To: <Pine.SOL.4.20.0402091449060.4254-100000@santiam.dfci.harvard.edu>
Message-ID: <000001c3ef5d$b43b2d80$160040d5@maths.lth.se>

Hmm, maybe you mean that you've got problems with buffered output when
using Rgui under Windows? If so, turn it off by the "Misc | Buffered
Output (Ctrl+W)" menu item.

Henrik Bengtsson


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jeff Gentry
> Sent: den 9 februari 2004 20:49
> To: Marcos Sanches
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Printting 'for' and 'while' indices
> 
> 
> > How do I "print" the "i" at each step?
> 
> print(i)?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From david at elseware.nl  Mon Feb  9 23:40:47 2004
From: david at elseware.nl (David A. van Leeuwen)
Date: Mon, 09 Feb 2004 23:40:47 +0100
Subject: [R] Re: substitute, eval, quote and functions
Message-ID: <40280C6F.8020606@elseware.nl>

Peter Dalgaard wrote:

> I think David was
> looking for something like
>
> function(data, x, y)
>
>         eval(substitute(plot(x,y)), data)
>
This was _exactly_ what i was looking for, after having spent quite some 
time reading the language definition and some example code such as 
subset.data.frame.  Thanks!

So now I've got my function that plots two dependent variables in 
different coulors and/or point types.  It even makes legends, although 
the positioning isn't great.  It can probably do with some code cleaning 
up, but hey, I'm new.  There might even be a function that does this 
already, but I haven't found it yet.

---david

## Plots colums `xcol' vs. `ycol' in colors accortding to levels `ccol',
## and point types according to `pcol'.
##
## optionally first select rows under condition `cond'

plotcol <- function(data, xcol, ycol, ccol=NULL, pcol=NULL, cond=TRUE) {
  ## extract relevant data
  s <- eval(substitute(subset(data, cond, c(xcol,ycol,ccol,pcol))), data)
  ## help to place the legends
  xrange <- range(s[,1], na.rm=TRUE)
  yrange <- range(s[,2], na.rm=TRUE)
  ## colour
  if (missing(ccol)) col=1
  else {
    ccol <- eval(substitute(ccol), s)   # replace name with data
    col <- as.numeric(ccol)                # make colors
  }
  ## point type
  if (missing(pcol)) pch=1
  else {
    pcol <- eval(substitute(pcol), s)
    pch=as.numeric(pcol)
  }
  ## make the plot
  plot(s[,1:2], col=col, pch=pch)
  ## and fix the legends
  if (length(col)>1) {
    size <- legend(xrange[1], yrange[2], legend=levels(ccol),
                   col=1:nlevels(ccol), pch=1, lty=1)
    y <- yrange[2]-size$rect$h          # calculate pos of next legend
  } else y <- yrange[2]
  if (length(pch)>1)
    legend(xrange[1], y, legend=levels(pcol), pch=1:nlevels(pcol))
}



From andrejk at zrc-sazu.si  Mon Feb  9 23:46:52 2004
From: andrejk at zrc-sazu.si (Andrej Kveder)
Date: Mon, 09 Feb 2004 23:46:52 +0100
Subject: [R] how to use try()
In-Reply-To: <4027DFBF.7090604@mcgill.ca>
Message-ID: <000001c3ef5e$9ce3e090$cb00a8c0@poldi>

Just check the class() of the lo.

You could try something like this...

for(i in 1:20){
   lo <- try(nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
   if (class(lo)=="try-error") beta[i]=NA else
   beta[i] <- lo$m$getPars()[4]
}

Hth

Andrej

_________
Andrej Kveder, M.A.
researcher
Institute of Medical Sciences SRS SASA; Novi trg 2, SI-1000 Ljubljana,
Slovenia
phone: +386 1 47 06 440   fax: +386 1 42 61 493

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of r.ghezzo
Sent: Monday, February 09, 2004 8:30 PM
To: r-help at stat.math.ethz.ch
Subject: [R] how to use try()


Hello, I have a program with this section:
..
for(i in 1:20){
   lo <- nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
   beta[i] <- lo$m$getPars()[4]
}
..
If the fit works this is OK but if the fit fails, the whole program 
fails so:
..
for(i in 1:20){
   try(lo <- 
nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
   beta[i] <- lo$m$getPars()[4]
}
..
but the try catches the error in nls and beta[i] gets assigned beta[i-1] 
from the previous loop. This is bad but no so bad as it can be checked, Now
in some cases the error is in i=1 and the program stops!! is there a way to
set lo$m$getPars() to zero before the call? I tried to understand the use of
tryCatch() but frankly it is above me. 
Sorry
Thanks for any help
Heberto Ghezzo
Meakins-Christie Labs

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From h.wickham at auckland.ac.nz  Tue Feb 10 00:26:35 2004
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Tue, 10 Feb 2004 12:26:35 +1300
Subject: [R] simple question on picking out some rows of a matrix/data
	frame
In-Reply-To: <25isigovdz.fsf@joel.Stanford.EDU>
References: <25isigovdz.fsf@joel.Stanford.EDU>
Message-ID: <4028172B.4000503@auckland.ac.nz>

Have you looked at subset?
eg subset(dataframe, x != y, select = c(x, y))

Hadley

Roger Levy wrote:
> Hi,
> 
> I have a simple question about matrix/data frame manipulation.  I have
> a data frame that looks a something like this
> 
>   X    Y    Z
>   1    0    "apples"
>   -1   -1   "oranges"
>   ...
>   0    -1   "bananas"
> 
> and I'd like to pull out all the rows for which X and Y are (un)equal
> into a submatrix.
> 
> How can I do that?
> 
> Many thanks,
> 
> Roger Levy
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From h.wickham at auckland.ac.nz  Tue Feb 10 00:31:03 2004
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Tue, 10 Feb 2004 12:31:03 +1300
Subject: [R] how to use try()
In-Reply-To: <4027DFBF.7090604@mcgill.ca>
References: <2588.193.219.42.106.1076337287.squirrel@kedras.mif.vu.lt>
	<4027DFBF.7090604@mcgill.ca>
Message-ID: <40281837.5050406@auckland.ac.nz>

You could also put both statements inside the try block:

for(i in 1:20){
   try({
	lo <- nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
	beta[i] <- lo$m$getPars()[4]
    })
}

Now beta[i] will only be assigned if nls runs without error.

Hadley

r.ghezzo wrote:

> Hello, I have a program with this section:
> ..
> for(i in 1:20){
>   lo <- nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
>   beta[i] <- lo$m$getPars()[4]
> }
> ..
> If the fit works this is OK but if the fit fails, the whole program 
> fails so:
> ..
> for(i in 1:20){
>   try(lo <- nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
>   beta[i] <- lo$m$getPars()[4]
> }
> ..
> but the try catches the error in nls and beta[i] gets assigned beta[i-1] 
> from the previous loop. This is bad but no so bad as it can be checked,
> Now in some cases the error is in i=1 and the program stops!!
> is there a way to set lo$m$getPars() to zero before the call?
> I tried to understand the use of tryCatch() but frankly it is above me. 
> Sorry
> Thanks for any help
> Heberto Ghezzo
> Meakins-Christie Labs
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From bates at stat.wisc.edu  Tue Feb 10 00:47:26 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 09 Feb 2004 17:47:26 -0600
Subject: [R] how to use try()
In-Reply-To: <4027DFBF.7090604@mcgill.ca>
References: <2588.193.219.42.106.1076337287.squirrel@kedras.mif.vu.lt>
	<4027DFBF.7090604@mcgill.ca>
Message-ID: <6rad3rvmr5.fsf@bates4.stat.wisc.edu>

Check the function nlsList in package nlme.  It does something very
like what you want to do.

"r.ghezzo" <heberto.ghezzo at mcgill.ca> writes:

> Hello, I have a program with this section:
> ..
> for(i in 1:20){
>    lo <- nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
>    beta[i] <- lo$m$getPars()[4]
> }
> ..
> If the fit works this is OK but if the fit fails, the whole program
> fails so:
> 
> ..
> for(i in 1:20){
>    try(lo <-
> 
> nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
>    beta[i] <- lo$m$getPars()[4]
> }

It is not a good idea to use lo$m$getPars() directly.  It is better to
use the generic function, which in this case is coef(), as in

coef(lo)[4]



From spencer.graves at pdf.com  Tue Feb 10 01:15:41 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 09 Feb 2004 16:15:41 -0800
Subject: [R] simple question on picking out some rows of a matrix/data
	frame
In-Reply-To: <6roes8ynem.fsf@bates4.stat.wisc.edu>
References: <25isigovdz.fsf@joel.Stanford.EDU>
	<6roes8ynem.fsf@bates4.stat.wisc.edu>
Message-ID: <402822AD.5080509@pdf.com>

      One alternative that I use is illustrated in the following examples: 

 > DF[DF$x==DF$y, ]
   x  y z
1 -1 -1 a
4  1  1 d
 >
 > sel <- (DF$x != DF$y)
 > DF[sel,]
   x  y z
2  1 -1 b
3 -1  1 c

       hope this help. 
      spencer graves

Douglas Bates wrote:

>"subset" will do the selection.  If you really want a matrix for the
>result you will need to coerce it using "as.matrix".
>
>Roger Levy <rog at stanford.edu> writes:
>
>  
>
>>I have a simple question about matrix/data frame manipulation.  I have
>>a data frame that looks a something like this
>>
>>  X    Y    Z
>>  1    0    "apples"
>>  -1   -1   "oranges"
>>  ...
>>  0    -1   "bananas"
>>
>>and I'd like to pull out all the rows for which X and Y are (un)equal
>>into a submatrix.
>>
>>How can I do that?
>>
>>Many thanks,
>>
>>Roger Levy
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From andy_liaw at merck.com  Tue Feb 10 01:32:26 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 9 Feb 2004 19:32:26 -0500
Subject: [R] RConsole
Message-ID: <3A822319EB35174CA3714066D590DCD504AF776E@usrymx25.merck.com>

On Windows, I suppose?  Save the Rconsole file in the etc subdirectory under
where you installed R.

HTH,
Andy

> From: Marcos Sanches
> 
> 	I changed my R console configurations, for example, the letters
> are white, the background is black, etc,... Then I saved this new
> configuration. What should I do if I want to have this new 
> configuration
> everytime I open R?
> 
> 	TIA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From dmurdoch at pair.com  Tue Feb 10 03:31:17 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 09 Feb 2004 21:31:17 -0500
Subject: RES: [R] data.frame to matrix
In-Reply-To: <000501c3ef59$76c90840$6200a8c0@blackdog>
References: <sqqf20tpv3dnolf2eoqvfjotorgdj6d6as@4ax.com>
	<000501c3ef59$76c90840$6200a8c0@blackdog>
Message-ID: <q1fg20l3ouh1allienc1h6s302jll40lf4@4ax.com>

On Mon, 9 Feb 2004 19:10:00 -0300, you wrote:

>Hi Duncan,
>
>You were right. It was a vector and not a data.frame that I was dealing
>with. But still I am having dificulties. Please, take a look at some output
>(I am using R Commander GUI by the way):
>
>R-cmdr> print(b) 
> [1] 0.70 0.85 0.80 0.70 0.75 0.75 0.80 0.70 0.80 0.75 0.80 0.79 0.78 0.75
>0.76
>[16] 0.70 0.70 0.70 0.80 0.80 0.70 0.65 0.60 0.70 0.55 0.80 0.65 0.60 0.70
> [1] 0.65 0.75 0.80 0.70 0.65 0.75 0.65 0.80 0.85 0.70 0.80 0.79 0.78 0.85
>0.76
>[16] 0.75 0.85 0.60 0.80 0.75 0.85 0.85 0.65 0.70 0.65 0.65 0.75 0.60 0.60
> [1] 0.65 0.75 0.80 0.70 0.65 0.75 0.65 0.80 0.85 0.70 0.80 0.79 0.78 0.85
>0.76
>[16] 0.75 0.85 0.60 0.80 0.75 0.85 0.85 0.65 0.70 0.65 0.65 0.75 0.60 0.60

That's a strange looking display -- b is probably some sort of object
with a special print method.  You can figure out what it is using
"str(b)".

Duncan Murdoch



From f0z6305 at labs.tamu.edu  Tue Feb 10 03:42:17 2004
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Mon, 9 Feb 2004 20:42:17 -0600
Subject: [R] How to compute the minimal distanct between a point and curve
	in N-dim space
Message-ID: <001601c3ef7f$7fb6d740$a7560d18@f0z6305>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040209/9d25fca9/attachment.pl

From RichardsonS at landcareresearch.co.nz  Tue Feb 10 03:16:07 2004
From: RichardsonS at landcareresearch.co.nz (Sarah Richardson)
Date: Tue, 10 Feb 2004 15:16:07 +1300
Subject: [R] GLMMpql: reporting on main effects
Message-ID: <s028f5c4.059@Iris.lincoln.landcareresearch.co.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/dd396f65/attachment.pl

From ligges at statistik.uni-dortmund.de  Tue Feb 10 08:37:50 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 10 Feb 2004 08:37:50 +0100
Subject: [R] RConsole
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF776E@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF776E@usrymx25.merck.com>
Message-ID: <40288A4E.8040103@statistik.uni-dortmund.de>

Liaw, Andy wrote:

> On Windows, I suppose?  Save the Rconsole file in the etc subdirectory under
> where you installed R.
> 
> HTH,
> Andy
> 
> 
>>From: Marcos Sanches
>>
>>	I changed my R console configurations, for example, the letters
>>are white, the background is black, etc,... Then I saved this new
>>configuration. What should I do if I want to have this new 
>>configuration
>>everytime I open R?
>>
>>	TIA


See also ?Rconsole which tells you:

"There are system copies of these files in 'R_HOME\etc?. Users can have 
personal copies of the files: these are looked for in the location given 
by the environment variable R_USER. The system files are read only if a 
corresponding personal file is not found.

If the environment variable R_USER is not set, the R system sets it to 
HOME if that is set (stripping any trailing slash), otherwise to 
{HOMEDRIVE}{HOMEPATH} if HOMEDRIVE is set otherwise to the working 
directory."

Uwe Ligges



From Maarten.van.der.Hoeven at knmi.nl  Tue Feb 10 09:38:44 2004
From: Maarten.van.der.Hoeven at knmi.nl (Hoeven, Maarten van der)
Date: Tue, 10 Feb 2004 09:38:44 +0100
Subject: [R] Available in S-plus, also in R1.8.1?
Message-ID: <1F8990C21AC73945BE6AAC5AD6D4CAE9064051@BCSXAC.knmi.nl>

Hi,

I've send this one to the list last Thursday, no reaction yet. It's
about the Connect Type in S+.

===

Hello all,

I'm looking for the R-equivalent of the S-option "Connect type: half
horiz first". Link:
http://miner.stern.nyu.edu/Splus/help/guihelp/__hhelp/connect_type.htm

I'm plotting with type="s" or type="S"; this is giving me a stairstep
starting, or ending with the value on the x-axis (as documented). But, I
want the x-value in the middle of the step, like "half horiz first" in
S-plus does.

Is this possible in R?


Thanks,
Maarten
--------------------------------------------------------------
Zie ook/see also: http://www.knmi.nl/maildisclaimer.html



From TyagiAnupam at aol.com  Tue Feb 10 10:00:35 2004
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Tue, 10 Feb 2004 04:00:35 EST
Subject: [R] confidence-intervals in barchart
Message-ID: <1d0.192c1e17.2d59f7b3@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/2ae1fcdc/attachment.pl

From ligges at statistik.uni-dortmund.de  Tue Feb 10 10:10:51 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 10 Feb 2004 10:10:51 +0100
Subject: [R] Available in S-plus, also in R1.8.1?
In-Reply-To: <1F8990C21AC73945BE6AAC5AD6D4CAE9064051@BCSXAC.knmi.nl>
References: <1F8990C21AC73945BE6AAC5AD6D4CAE9064051@BCSXAC.knmi.nl>
Message-ID: <4028A01B.3080101@statistik.uni-dortmund.de>

Hoeven, Maarten van der wrote:

> Hi,
> 
> I've send this one to the list last Thursday, no reaction yet. It's
> about the Connect Type in S+.

In order to get an answer, you might want to be more specific what
"Connect type: half horiz first" really does in S-PLUS. I don't think 
something like that is available within an existing R function (I might 
be wrong here), but it can easily be coded (e.g. along the lines of code 
in package "stepfun"), given there is an *explicit definition* (and the 
cited URL is not very helpful here).
My question is: How do you define the "middle of a step", in particular 
if the interesting x values of your step-function are not equidistant?

And another question: Why do you want to create a plot that needs to be 
explained? Other plots are much more intuitive (at least for me).

Uwe Ligges



> ===
> 
> Hello all,
> 
> I'm looking for the R-equivalent of the S-option "Connect type: half
> horiz first". Link:
> http://miner.stern.nyu.edu/Splus/help/guihelp/__hhelp/connect_type.htm
> 
> I'm plotting with type="s" or type="S"; this is giving me a stairstep
> starting, or ending with the value on the x-axis (as documented). But, I
> want the x-value in the middle of the step, like "half horiz first" in
> S-plus does.
> 
> Is this possible in R?
> 
> 
> Thanks,
> Maarten
> --------------------------------------------------------------
> Zie ook/see also: http://www.knmi.nl/maildisclaimer.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Maarten.van.der.Hoeven at knmi.nl  Tue Feb 10 10:28:46 2004
From: Maarten.van.der.Hoeven at knmi.nl (Hoeven, Maarten van der)
Date: Tue, 10 Feb 2004 10:28:46 +0100
Subject: [R] Available in S-plus, also in R1.8.1?
Message-ID: <1F8990C21AC73945BE6AAC5AD6D4CAE9064054@BCSXAC.knmi.nl>

Agree, if a plot needs to be explained, something is not very well
thought of. However, there are good rationals to do it this way.
Moreover, I'm using R to replace SPSS-functionality (and imaging by
pvwave) within a project, and I want to be close as possible to the
image output of the preceeding project. Hence, this question.

The assumption is indeed an equidistant x-axis. This is true in my case.

What the stairstep-plot in R does (type="s" or type="S"), is to draw a
horizontal line between two points on the x-axis. For example,

x1 = 1980
x2 = 1981
x3 = 1982
y1 = 10
y2 = 12
y3 = 14

it draws a horizontal line between 1980 and 1981, at y-level 10 (or 12,
depening on type="s" or type="S").

What I'm looking for, and this can be achieved in S+ by the mentioned
connect type, is that the horizontal line *NOT* starts at exactly the
x-values, but half between. See the attached example, where there is
only one y-value of 1, at x=1995. You see the plot been drawn halfway
1995 (half before 1995, and half after 1995). This is what I'm look ing
for. When using type="s" and type="S" in the plot-function, this would
result in a polot that starts exactly at 1995, or ends exactly at 1995.
I want to have it in between.

Thanks,

Maarten


> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Sent: Tuesday, February 10, 2004 10:11 AM
> To: Hoeven, Maarten van der
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Available in S-plus, also in R1.8.1?
> 
> 
> Hoeven, Maarten van der wrote:
> 
> > Hi,
> > 
> > I've send this one to the list last Thursday, no reaction yet. It's
> > about the Connect Type in S+.
> 
> In order to get an answer, you might want to be more specific what
> "Connect type: half horiz first" really does in S-PLUS. I don't think 
> something like that is available within an existing R 
> function (I might 
> be wrong here), but it can easily be coded (e.g. along the 
> lines of code 
> in package "stepfun"), given there is an *explicit 
> definition* (and the 
> cited URL is not very helpful here).
> My question is: How do you define the "middle of a step", in 
> particular 
> if the interesting x values of your step-function are not equidistant?
> 
> And another question: Why do you want to create a plot that 
> needs to be 
> explained? Other plots are much more intuitive (at least for me).
> 
> Uwe Ligges
> 
> 
> 
> > ===
> > 
> > Hello all,
> > 
> > I'm looking for the R-equivalent of the S-option "Connect type: half
> > horiz first". Link:
> > 
> http://miner.stern.nyu.edu/Splus/help/guihelp/__hhelp/connect_type.htm
> > 
> > I'm plotting with type="s" or type="S"; this is giving me a 
> stairstep
> > starting, or ending with the value on the x-axis (as 
> documented). But, I
> > want the x-value in the middle of the step, like "half 
> horiz first" in
> > S-plus does.
> > 
> > Is this possible in R?
> > 
> > 
> > Thanks,
> > Maarten
> > --------------------------------------------------------------
> > Zie ook/see also: http://www.knmi.nl/maildisclaimer.html
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>
--------------------------------------------------------------
Zie ook/see also: http://www.knmi.nl/maildisclaimer.html 

From TyagiAnupam at aol.com  Tue Feb 10 10:30:46 2004
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Tue, 10 Feb 2004 04:30:46 EST
Subject: [R] confidence-intervals in dotchart
Message-ID: <bc.435cb204.2d59fec6@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/44e28e90/attachment.pl

From marwan.khawaja at aub.edu.lb  Mon Feb  9 17:34:27 2004
From: marwan.khawaja at aub.edu.lb (Marwan Khawaja)
Date: Mon, 9 Feb 2004 11:34:27 -0500
Subject: [R] confidence-intervals in barchart
In-Reply-To: <1d0.192c1e17.2d59f7b3@aol.com>
Message-ID: <CLECJBOEBGOMOKJHJNDAIECDDKAA.marwan.khawaja@aub.edu.lb>

Try 'parplot2' -- 'gregmisc' package.
Marwan


-------------------------------------------------------------------
Marwan Khawaja         http://staff.aub.edu.lb/~mk36/
-------------------------------------------------------------------


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of
> TyagiAnupam at aol.com
> Sent: Tuesday, February 10, 2004 4:01 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] confidence-intervals in barchart
>
>
> Hi R users,
>
> 1)  How does one show confidence-intervals in a barchart and use rownames for
> labels on the y-axes?  I have looked at "plotCI" in "gregmisc" package . But
> it does not seem to produce something like a barchart.  The statistic, error,
> upper-bound, and lower-bound are in a dataframe.
>
> 2) How to show CI in a barchart either using the statistic and, either (a)
> errors or (b) upper and lower bounds from a dataframe?
>
> An example will be very helpful.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dominique.couturier at unine.ch  Tue Feb 10 10:52:41 2004
From: dominique.couturier at unine.ch (Dominique Couturier)
Date: Tue, 10 Feb 2004 10:52:41 +0100
Subject: [R] confidence-intervals in barchart
In-Reply-To: <CLECJBOEBGOMOKJHJNDAIECDDKAA.marwan.khawaja@aub.edu.lb>
References: <CLECJBOEBGOMOKJHJNDAIECDDKAA.marwan.khawaja@aub.edu.lb>
Message-ID: <DE15E63C-5BAE-11D8-A512-0003931DD6AE@unine.ch>


hello,
you can find a very detailed example of barplot with CI in the volume 
3/2 of R-news (october 2003).
hope this help.
dlc

>>
>> Hi R users,
>>
>> 1)  How does one show confidence-intervals in a barchart and use 
>> rownames for
>> labels on the y-axes?  I have looked at "plotCI" in "gregmisc" 
>> package . But
>> it does not seem to produce something like a barchart.  The 
>> statistic, error,
>> upper-bound, and lower-bound are in a dataframe.
>>
>> 2) How to show CI in a barchart either using the statistic and, 
>> either (a)
>> errors or (b) upper and lower bounds from a dataframe?
>>
>> An example will be very helpful.
>>



From marwan.khawaja at aub.edu.lb  Mon Feb  9 17:53:22 2004
From: marwan.khawaja at aub.edu.lb (Marwan Khawaja)
Date: Mon, 9 Feb 2004 11:53:22 -0500
Subject: [R] confidence-intervals in barchart
In-Reply-To: <CLECJBOEBGOMOKJHJNDAIECDDKAA.marwan.khawaja@aub.edu.lb>
Message-ID: <CLECJBOEBGOMOKJHJNDAMECEDKAA.marwan.khawaja@aub.edu.lb>

Sorry I meant 'barplot2'!
Marwan

-------------------------------------------------------------------
Marwan Khawaja         http://staff.aub.edu.lb/~mk36/
-------------------------------------------------------------------


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Marwan Khawaja
> Sent: Monday, February 09, 2004 11:34 AM
> To: TyagiAnupam at aol.com; r-help at stat.math.ethz.ch
> Subject: RE: [R] confidence-intervals in barchart
>
>
> Try 'parplot2' -- 'gregmisc' package.
> Marwan
>
>
> -------------------------------------------------------------------
> Marwan Khawaja         http://staff.aub.edu.lb/~mk36/
> -------------------------------------------------------------------
>
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of
> > TyagiAnupam at aol.com
> > Sent: Tuesday, February 10, 2004 4:01 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] confidence-intervals in barchart
> >
> >
> > Hi R users,
> >
> > 1)  How does one show confidence-intervals in a barchart and use
> rownames for
> > labels on the y-axes?  I have looked at "plotCI" in "gregmisc" package . But
> > it does not seem to produce something like a barchart.  The
> statistic, error,
> > upper-bound, and lower-bound are in a dataframe.
> >
> > 2) How to show CI in a barchart either using the statistic and, either (a)
> > errors or (b) upper and lower bounds from a dataframe?
> >
> > An example will be very helpful.
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Feb 10 11:01:04 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 10 Feb 2004 11:01:04 +0100
Subject: [R] confidence-intervals in barchart
In-Reply-To: <1d0.192c1e17.2d59f7b3@aol.com>
References: <1d0.192c1e17.2d59f7b3@aol.com>
Message-ID: <4028ABE0.5050709@statistik.uni-dortmund.de>

TyagiAnupam at aol.com wrote:

> Hi R users,
> 
> 1)  How does one show confidence-intervals in a barchart and use rownames for 
> labels on the y-axes?  I have looked at "plotCI" in "gregmisc" package . But 
> it does not seem to produce something like a barchart.  The statistic, error, 
> upper-bound, and lower-bound are in a dataframe.
> 
> 2) How to show CI in a barchart either using the statistic and, either (a) 
> errors or (b) upper and lower bounds from a dataframe?
> 
> An example will be very helpful.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


See the "R Help Desk" by Marc Schwartz in R News 3/2, 2003, pp. 2-6,
http://cran.r-project.org/doc/Rnews/Rnews_2003-2.pdf

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Tue Feb 10 11:47:02 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 10 Feb 2004 11:47:02 +0100
Subject: [R] Available in S-plus, also in R1.8.1?
In-Reply-To: <1F8990C21AC73945BE6AAC5AD6D4CAE9064054@BCSXAC.knmi.nl>
References: <1F8990C21AC73945BE6AAC5AD6D4CAE9064054@BCSXAC.knmi.nl>
Message-ID: <4028B6A6.1090503@statistik.uni-dortmund.de>

Hoeven, Maarten van der wrote:

> Agree, if a plot needs to be explained, something is not very well
> thought of. However, there are good rationals to do it this way.
> Moreover, I'm using R to replace SPSS-functionality (and imaging by
> pvwave) within a project, and I want to be close as possible to the
> image output of the preceeding project. Hence, this question.
> 
> The assumption is indeed an equidistant x-axis. This is true in my case.
> 
> What the stairstep-plot in R does (type="s" or type="S"), is to draw a
> horizontal line between two points on the x-axis. For example,
> 
> x1 = 1980
> x2 = 1981
> x3 = 1982
> y1 = 10
> y2 = 12
> y3 = 14
> 
> it draws a horizontal line between 1980 and 1981, at y-level 10 (or 12,
> depening on type="s" or type="S").
> 
> What I'm looking for, and this can be achieved in S+ by the mentioned
> connect type, is that the horizontal line *NOT* starts at exactly the
> x-values, but half between. See the attached example, where there is
> only one y-value of 1, at x=1995. You see the plot been drawn halfway
> 1995 (half before 1995, and half after 1995). This is what I'm look ing
> for. When using type="s" and type="S" in the plot-function, this would
> result in a polot that starts exactly at 1995, or ends exactly at 1995.
> I want to have it in between.

Now that I (hopefully) understand what you are going to do, the solution 
seems to be simple:

  x <- 1980:1982
  y <- c(10, 12, 14)

  n <- length(x)
  xdiff2 <- diff(x[1:2])/2
  x2 <- c(x - xdiff2, x[n] + xdiff2)
  y2 <- c(y, y[n])
  plot(x2, y2, type="s")


Uwe Ligges





> Thanks,
> 
> Maarten
> 
> 
> 
>>-----Original Message-----
>>From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
>>Sent: Tuesday, February 10, 2004 10:11 AM
>>To: Hoeven, Maarten van der
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] Available in S-plus, also in R1.8.1?
>>
>>
>>Hoeven, Maarten van der wrote:
>>
>>
>>>Hi,
>>>
>>>I've send this one to the list last Thursday, no reaction yet. It's
>>>about the Connect Type in S+.
>>
>>In order to get an answer, you might want to be more specific what
>>"Connect type: half horiz first" really does in S-PLUS. I don't think 
>>something like that is available within an existing R 
>>function (I might 
>>be wrong here), but it can easily be coded (e.g. along the 
>>lines of code 
>>in package "stepfun"), given there is an *explicit 
>>definition* (and the 
>>cited URL is not very helpful here).
>>My question is: How do you define the "middle of a step", in 
>>particular 
>>if the interesting x values of your step-function are not equidistant?
>>
>>And another question: Why do you want to create a plot that 
>>needs to be 
>>explained? Other plots are much more intuitive (at least for me).
>>
>>Uwe Ligges
>>
>>
>>
>>
>>>===
>>>
>>>Hello all,
>>>
>>>I'm looking for the R-equivalent of the S-option "Connect type: half
>>>horiz first". Link:
>>>
>>
>>http://miner.stern.nyu.edu/Splus/help/guihelp/__hhelp/connect_type.htm
>>
>>>I'm plotting with type="s" or type="S"; this is giving me a 
>>
>>stairstep
>>
>>>starting, or ending with the value on the x-axis (as 
>>
>>documented). But, I
>>
>>>want the x-value in the middle of the step, like "half 
>>
>>horiz first" in
>>
>>>S-plus does.
>>>
>>>Is this possible in R?
>>>
>>>
>>>Thanks,
>>>Maarten
>>>--------------------------------------------------------------
>>>Zie ook/see also: http://www.knmi.nl/maildisclaimer.html
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! 
>>
>>http://www.R-project.org/posting-guide.html
>>
>>
> 
> --------------------------------------------------------------
> Zie ook/see also: http://www.knmi.nl/maildisclaimer.html 
> 
> 
> ------------------------------------------------------------------------
>



From dimorett at istat.it  Tue Feb 10 11:53:17 2004
From: dimorett at istat.it (Diego Moretti)
Date: Tue, 10 Feb 2004 11:53:17 +0100
Subject: [R] Evaluating R. I need to open "a dataset".
Message-ID: <4028B81D.6060207@istat.it>

Hello,
Our  Statistics Group is evaluating the use of R for the elaboration of 
some index.
We have some datasets sas and we would like to evaluate performance in 
the elaborations of mean, percentile, Gini index of a population and of 
a survey sample.
I need to open "a dataset". Currently I've understood that I've to 
follow a code sequence like this:

alfa <- {a moltiplicator}
memory.limit(alfa*round(memory.limit()/1048576.0, 2))
library(foreign)
hereis <- read.xport("C:/R/ { my exported file sas }")

The dimension of { my exported file sas } is 120 mega
Is correct to allocate all the file in memory in a variable ( hereis ) ?
With an alfa ( the moltiplicator ) of  2 , I have the following error:

Error: cannot allocate vector of size 214 Kb
In addition: Warning message:
Reached total allocation of 446Mb: see help(memory.size)

Thank you for any advice.

Diego Moretti

-- 
============================================================
Diego Moretti                           (dimorett at istat.it)
Italian National Statistical Institute  (ISTAT)



From feh3k at spamcop.net  Tue Feb 10 12:31:06 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 10 Feb 2004 06:31:06 -0500
Subject: [R] confidence-intervals in dotchart
In-Reply-To: <bc.435cb204.2d59fec6@aol.com>
References: <bc.435cb204.2d59fec6@aol.com>
Message-ID: <20040210063106.6b6ce44d.feh3k@spamcop.net>

On Tue, 10 Feb 2004 04:30:46 EST
TyagiAnupam at aol.com wrote:

> My earlier posting should have said "dotchart", not "barchart".
> 
> 1)  How does one show confidence-intervals in a "dotchart" and use
> rownames for labels on the y-axes?  I have looked at "plotCI" in
> "gregmisc" package . But it does not seem to produce something like a
> dotchart.  The statistic, error, upper-bound, and lower-bound are in a
> dataframe.
> 
> 2) How to show CI in a dotchart either using the statistic and, either
> (a) errors or (b) upper and lower bounds from a dataframe?
> 
> An example will be very helpful.

You might look at the example on p.149
http://cran.r-project.org/doc/contrib/Harrell-statcomp-notes.pdf and other
examples in that section.  These use the xYplot and Dotplot functions in
the Hmisc package, which extend lattice graphics to easily handle error
bars and bands.

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From Lennart.Borgman at astrazeneca.com  Tue Feb 10 14:27:21 2004
From: Lennart.Borgman at astrazeneca.com (Lennart.Borgman@astrazeneca.com)
Date: Tue, 10 Feb 2004 14:27:21 +0100
Subject: [R] The ttest.c example in R under MS Windows
Message-ID: <26D5AB9F6512D611A8610001FA7E136F032783B2@se-drc-mail4.selu.astrazeneca.net>

We are trying to compile and run the ttest.c example that comes with R (in
C:\Program Files\R\rw1081\src\library\windlgs\src\ttest.c). After compiling
it with MS Visual C++ we load the DLL with dyn.load. 

So far it seems good, but when we try to call it from R (after running
C:\Program Files\R\rw1081\src\library\windlgs\R\windlgs.R) R crashes.

We have tried changing the exports from DLL but have failed so far. Since I
have a guy helping me who is fluent in MS Visual C++ I believe we are
missing something crucial. Have anyone compiled and used the example above
using MS Visual C++? Has anyone done this using the gcc (or Mingw) compiler
on MS Windows?

I would be very glad to find a complete example for compiling under MS
Windows.


- Lennart



From frs2 at cwru.edu  Tue Feb 10 14:59:10 2004
From: frs2 at cwru.edu (Fredrick Schumacher)
Date: Tue, 10 Feb 2004 08:59:10 -0500
Subject: [R] coxph error
Message-ID: <000201c3efde$0ec3d880$44d11681@epbichao>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/5d7faf33/attachment.pl

From dmurdoch at pair.com  Tue Feb 10 15:00:50 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 10 Feb 2004 09:00:50 -0500
Subject: [R] The ttest.c example in R under MS Windows
In-Reply-To: <26D5AB9F6512D611A8610001FA7E136F032783B2@se-drc-mail4.selu.astrazeneca.net>
References: <26D5AB9F6512D611A8610001FA7E136F032783B2@se-drc-mail4.selu.astrazeneca.net>
Message-ID: <79oh20l6glsqabrb7lbeinrk19d3lam2rc@4ax.com>

On Tue, 10 Feb 2004 14:27:21 +0100, Lennart.Borgman at astrazeneca.com
wrote :

>We are trying to compile and run the ttest.c example that comes with R (in
>C:\Program Files\R\rw1081\src\library\windlgs\src\ttest.c). After compiling
>it with MS Visual C++ we load the DLL with dyn.load. 
>
>So far it seems good, but when we try to call it from R (after running
>C:\Program Files\R\rw1081\src\library\windlgs\R\windlgs.R) R crashes.
>
>We have tried changing the exports from DLL but have failed so far. Since I
>have a guy helping me who is fluent in MS Visual C++ I believe we are
>missing something crucial. Have anyone compiled and used the example above
>using MS Visual C++? Has anyone done this using the gcc (or Mingw) compiler
>on MS Windows?
>
>I would be very glad to find a complete example for compiling under MS
>Windows.

There's some general information about this sort of thing on my web
page,
<http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs/>.

The readme.packages file contains specific instructions about VC++,
but they may be out of date:  I use gcc, and Brian Ripley (who wrote
those instructions) doesn't use Windows as much as he used to.

>From the symptoms ("when we call it R crashes"), my guess would be a
problem with the calling convention, as described on my web page.  You
need to make sure your exports use the C calling convention, not
stdcall.  I don't know how to do that in VC++, but presumably your
fluent helper would.

If you do find what's wrong and it's a case of our documentation being
out of date or incomplete, please write up a description of what works
instead.  This could be incorporated into readme.packages or put up on
my web page.

Duncan Murdoch



From heberto.ghezzo at mcgill.ca  Tue Feb 10 15:03:59 2004
From: heberto.ghezzo at mcgill.ca (r.ghezzo)
Date: Tue, 10 Feb 2004 09:03:59 -0500
Subject: [R] how to use  try()
In-Reply-To: <26D5AB9F6512D611A8610001FA7E136F032783B2@se-drc-mail4.selu.astrazeneca.net>
References: <26D5AB9F6512D611A8610001FA7E136F032783B2@se-drc-mail4.selu.astrazeneca.net>
Message-ID: <4028E4CF.7010307@mcgill.ca>

Thanks to everybody who answered my question. Here are the suggestion 
for completion sake of the archives.
from John Fox @ Mcmaster.ca
lo <-
try(nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
beta[i] <- if (class(lo) == "try-error") NA else lo$m$getPars()[4]

from Peter Dalgaard @ biostat.ku.dk
Just check the return value from try:
beta[i] <- if(inherits(try(.....),"try-error")) NA else lo$etc...

from Thomas Lumley @ u.washington.edu
You want either both assignments inside the try()
try({
	lo<-nls(....)
	beta[i]<-lo$m$getPars(4)
})

or both outside

lo<- try(nls(....))
if (inherits(lo,"try-error")) beta[i]<-NA else beta[i]<-lo$m$getPars()[4]

from Sundar Dorai-Raj @ pdf.com
if (inherits(lo,"try-error")) beta[i]<-NA else beta[i]<-lo$m$getPars()[4]

also from Andrej Kveder @ zrc-sazu.si; Patric Burns @ pburns.seanet.com
Hadley Wickham @ auckland.ac.nz;

from Douglas Bates @ stat.wisc.edu
Check the function nlsList in package nlme.  It does something very
like what you want to do.
It is not a good idea to use lo$m$getPars() directly.  It is better to
use the generic function, which in this case is coef(), as in
coef(lo)[4]


On Mon, 09 Feb 2004 14:30:07 -0500
  "r.ghezzo" <heberto.ghezzo at mcgill.ca> wrote:

>> Hello, I have a program with this section:
>> ..
>> for(i in 1:20){
>>   lo <-
>> nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
>>   beta[i] <- lo$m$getPars()[4]
>> }
>> ..
>> If the fit works this is OK but if the fit fails, the whole program
>> fails so:
>> ..
>> for(i in 1:20){
>>   try(lo <- 
>> nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
>>   beta[i] <- lo$m$getPars()[4]
>> }
>> ..
>> but the try catches the error in nls and beta[i] gets assigned
>> beta[i-1] from the previous loop. This is bad but no so bad as it can
>> be checked,
>> Now in some cases the error is in i=1 and the program stops!!
>> is there a way to set lo$m$getPars() to zero before the call?
>> I tried to understand the use of tryCatch() but frankly it is above
>> me. Sorry
>> Thanks for any help
>> Heberto Ghezzo
>> Meakins-Christie Labs
>> 
>>



From TyagiAnupam at aol.com  Tue Feb 10 15:38:29 2004
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Tue, 10 Feb 2004 09:38:29 EST
Subject: [R] confidence-intervals in dotchart
Message-ID: <1ab.2014cc2f.2d5a46e5@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/a54dac90/attachment.pl

From consentino at infinito.it  Tue Feb 10 15:40:56 2004
From: consentino at infinito.it (Fabrizio Consentino)
Date: Tue, 10 Feb 2004 15:40:56 +0100
Subject: [R] Diagnostic in multilevel models
Message-ID: <002a01c3efe3$e4d31800$e7131d97@consentino>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/9cd9332e/attachment.pl

From allan at stats.uct.ac.za  Tue Feb 10 15:48:22 2004
From: allan at stats.uct.ac.za (allan clark)
Date: Tue, 10 Feb 2004 16:48:22 +0200
Subject: [R] R: lags
Message-ID: <4028EF36.D68A778D@stats.uct.ac.za>

hi all

how does one simulate a random walk process?

i.e

y(0)=0

y(t)=y(t-1)+ e(t)

where e(t) is normal(0,1)  say.

Regards
allan

From andy_liaw at merck.com  Tue Feb 10 15:53:33 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 10 Feb 2004 09:53:33 -0500
Subject: [R] The ttest.c example in R under MS Windows
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7775@usrymx25.merck.com>

Works just fine for me with the recommended compilers and tools.  Here's a
transcript of the build:

c:\tools\R-1.8.1\src\gnuwin32>Rcmd install windlgs


---------- Making package windlgs ------------
  adding build stamp to DESCRIPTION
  making DLL ...
making ttest.d from ttest.c
gcc   -Ic:/tools/R-1.8.1/src/include -Wall -O2
-Ic:/tools/R-1.8.1/src/gnuwin32/
graphapp  -c ttest.c -o ttest.o
ar cr windlgs.a *.o
ranlib windlgs.a
windres --include-dir c:/tools/R-1.8.1/src/include  -i windlgs_res.rc -o
windlgs
_res.o
gcc  --shared -s  -o windlgs.dll windlgs.def windlgs.a windlgs_res.o
-Lc:/tools
/R-1.8.1/src/gnuwin32  -lg2c -lR
  ... DLL made
  installing DLL
  installing R files
  installing man source files
  installing indices
  installing help
 >>> Building/Updating help pages for package 'windlgs'
     Formats: text html latex example
  menu.ttest                        text    html    latex   example
 >>> Building/Updating help pages for package 'windlgs'
     Formats: chm
  menu.ttest                                                        chm
Microsoft HTML Help Compiler 4.74.8702

Compiling c:\tools\R-1.8.1\src\gnuwin32\windlgs\chm\windlgs.chm


Compile time: 0 minutes, 2 seconds
2       Topics
4       Local links
0       Internet links
1       Graphic


Created c:\tools\R-1.8.1\src\gnuwin32\windlgs\chm\windlgs.chm, 22,531 bytes
Compression increased file by 8,709 bytes.
  adding MD5 sums


And here's the test:
> library(windlgs)
To remove the Statistics menu use del.ttest()
> x <- runif(10)
> y <- runif(20)
[click on `Statistics' from the menu, choose `ttest:1' and fill in.]
> menu.ttest()

        Welch Two Sample t-test

data:  x and y 
t = 2.1473, df = 22.03, p-value = 0.04303
alternative hypothesis: true difference in means is not equal to 0 
95 percent confidence interval:
 0.007352435 0.422008138 
sample estimates:
mean of x mean of y 
0.6706490 0.4559688 

Andy


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Lennart.Borgman at astrazeneca.com
> Sent: Tuesday, February 10, 2004 8:27 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] The ttest.c example in R under MS Windows
> 
> 
> We are trying to compile and run the ttest.c example that 
> comes with R (in
> C:\Program Files\R\rw1081\src\library\windlgs\src\ttest.c). 
> After compiling
> it with MS Visual C++ we load the DLL with dyn.load. 
> 
> So far it seems good, but when we try to call it from R (after running
> C:\Program Files\R\rw1081\src\library\windlgs\R\windlgs.R) R crashes.
> 
> We have tried changing the exports from DLL but have failed 
> so far. Since I
> have a guy helping me who is fluent in MS Visual C++ I believe we are
> missing something crucial. Have anyone compiled and used the 
> example above
> using MS Visual C++? Has anyone done this using the gcc (or 
> Mingw) compiler
> on MS Windows?
> 
> I would be very glad to find a complete example for compiling under MS
> Windows.
> 
> 
> - Lennart
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From JonesW at kssg.com  Tue Feb 10 15:55:10 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Tue, 10 Feb 2004 14:55:10 -0000
Subject: [R] R: lags
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0F9A@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/c0662c30/attachment.pl

From anielsen at math.ku.dk  Tue Feb 10 16:09:23 2004
From: anielsen at math.ku.dk (Anders Nielsen)
Date: Tue, 10 Feb 2004 16:09:23 +0100 (CET)
Subject: [R] R: lags
In-Reply-To: <4028EF36.D68A778D@stats.uct.ac.za>
Message-ID: <Pine.LNX.4.40.0402101608410.17637-100000@shannon.math.ku.dk>


How about:

y<-cumsum(c(0,rnorm(100)))



On Tue, 10 Feb 2004, allan clark wrote:

> hi all
>
> how does one simulate a random walk process?
>
> i.e
>
> y(0)=0
>
> y(t)=y(t-1)+ e(t)
>
> where e(t) is normal(0,1)  say.
>
> Regards
> allan
>



From ekstrom at dina.kvl.dk  Tue Feb 10 16:11:51 2004
From: ekstrom at dina.kvl.dk (ekstrom@dina.kvl.dk)
Date: Tue, 10 Feb 2004 16:11:51 +0100
Subject: [R] R: lags
In-Reply-To: <4028EF36.D68A778D@stats.uct.ac.za>
References: <4028EF36.D68A778D@stats.uct.ac.za>
Message-ID: <20040210151151.GA19853@dina.kvl.dk>

> how does one simulate a random walk process?
> 
> i.e
> 
> y(0)=0
> 
> y(t)=y(t-1)+ e(t)
> 
> where e(t) is normal(0,1)  say.

cumsum(c(0,rnorm(10000)))

?

Claus

-- 
*****************************************
Claus Thorn Ekstr?m <ekstrom at dina.kvl.dk>
Dept of Mathematics and Physics, KVL
Thorvaldsensvej 40
DK-1871 Frederiksberg C
Denmark
Phone:[+45] 3528 2341
Fax:  [+45] 3528 2350



From sfalcon at fhcrc.org  Tue Feb 10 16:15:58 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 10 Feb 2004 07:15:58 -0800
Subject: [R] coxph error
In-Reply-To: <000201c3efde$0ec3d880$44d11681@epbichao>
References: <000201c3efde$0ec3d880$44d11681@epbichao>
Message-ID: <20040210151557.GA17446@queenbee.fhcrc.org>

Take a look at ?try and see the thread on this list of yesterday about
how to use try to skip errors within a loop.

On Tue, Feb 10, 2004 at 08:59:10AM -0500, Fredrick Schumacher wrote:
> R list:
> 
>  
> 
> I am using a 'for' loop to run a number of different models (stratified
> by different variables) with coxph.   The data becomes sparse when some
> strata are used causing the model to become unstable.  The following
> error occurs and the analysis is terminated.
> 
>  
> 
> >Error in fitter(X, Y, strats, offset, init, control, weights = weights,
> : 
> 
>       (converted from warning) Loglik converged before variable  1 ;
> beta may be infinite. 
> 
>  
> 
> Is there any way to have R skip the models without convergence and apply
> 'NA' to the results, then go on to the other models?
> 
>  
> 
> The same situation occurs with windows and unix versions.
> 
>  
> 
> Thanks,
> 
> Fred
> 
> ____________________________________
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From f0z6305 at labs.tamu.edu  Tue Feb 10 16:17:39 2004
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue, 10 Feb 2004 09:17:39 -0600
Subject: [R] How to compute the minimal distanct between a point and curve
	in N-dim space
Message-ID: <007f01c3efe9$05d37b30$a7560d18@f0z6305>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/4caceeff/attachment.pl

From tlumley at u.washington.edu  Tue Feb 10 16:28:37 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 10 Feb 2004 07:28:37 -0800 (PST)
Subject: [R] R: lags
In-Reply-To: <4028EF36.D68A778D@stats.uct.ac.za>
References: <4028EF36.D68A778D@stats.uct.ac.za>
Message-ID: <Pine.A41.4.58.0402100728100.25516@homer40.u.washington.edu>

On Tue, 10 Feb 2004, allan clark wrote:

> hi all
>
> how does one simulate a random walk process?
>
> i.e
>
> y(0)=0
>
> y(t)=y(t-1)+ e(t)
>
> where e(t) is normal(0,1)  say.
>

e<-rnorm(100)
y<-cumsum(e)

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From tlumley at u.washington.edu  Tue Feb 10 16:32:06 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 10 Feb 2004 07:32:06 -0800 (PST)
Subject: [R] coxph error
In-Reply-To: <000201c3efde$0ec3d880$44d11681@epbichao>
References: <000201c3efde$0ec3d880$44d11681@epbichao>
Message-ID: <Pine.A41.4.58.0402100728460.25516@homer40.u.washington.edu>

On Tue, 10 Feb 2004, Fredrick Schumacher wrote:

> R list:
>
>
>
> I am using a 'for' loop to run a number of different models (stratified
> by different variables) with coxph.   The data becomes sparse when some
> strata are used causing the model to become unstable.  The following
> error occurs and the analysis is terminated.
>
>
>
> >Error in fitter(X, Y, strats, offset, init, control, weights = weights,
> :
>
>       (converted from warning) Loglik converged before variable  1 ;
> beta may be infinite.
>
>
>
> Is there any way to have R skip the models without convergence and apply
> 'NA' to the results, then go on to the other models?

This is usually a warning, not an error, and for good reason since it does
not reliably indicate lack of convergence (poor sensitivity and poor
specificity). You have deliberately turned it into an error with the
setting of options(warn).

If you really want it to be an error but not fatal then use try() to
capture it.


	-thomas



From spencer.graves at pdf.com  Tue Feb 10 16:47:55 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 10 Feb 2004 07:47:55 -0800
Subject: [R] coxph error
In-Reply-To: <000201c3efde$0ec3d880$44d11681@epbichao>
References: <000201c3efde$0ec3d880$44d11681@epbichao>
Message-ID: <4028FD2B.2050903@pdf.com>

      Have you considered "try"? 

      hope this helps.  spencer graves

Fredrick Schumacher wrote:

>R list:
>
> 
>
>I am using a 'for' loop to run a number of different models (stratified
>by different variables) with coxph.   The data becomes sparse when some
>strata are used causing the model to become unstable.  The following
>error occurs and the analysis is terminated.
>
> 
>
>  
>
>>Error in fitter(X, Y, strats, offset, init, control, weights = weights,
>>    
>>
>: 
>
>      (converted from warning) Loglik converged before variable  1 ;
>beta may be infinite. 
>
> 
>
>Is there any way to have R skip the models without convergence and apply
>'NA' to the results, then go on to the other models?
>
> 
>
>The same situation occurs with windows and unix versions.
>
> 
>
>Thanks,
>
>Fred
>
>____________________________________
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From jfox at mcmaster.ca  Tue Feb 10 16:48:10 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 10 Feb 2004 10:48:10 -0500
Subject: [R] R: lags
In-Reply-To: <4028EF36.D68A778D@stats.uct.ac.za>
Message-ID: <web-14010168@cgpsrv2.cis.mcmaster.ca>

Dear Alan,

Perhaps there's a more clever solution, but the following will work and
follows directly from your statement of the problem (e.g., for 100
observations):

e <- rnorm(100)
y <- rep(0, 101)
for (t in 2:101) y[t] <- y[t-1] + e[t]
y <- y[-1]

I hope that this helps,
 John

On Tue, 10 Feb 2004 16:48:22 +0200
 allan clark <allan at stats.uct.ac.za> wrote:
> hi all
> 
> how does one simulate a random walk process?
> 
> i.e
> 
> y(0)=0
> 
> y(t)=y(t-1)+ e(t)
> 
> where e(t) is normal(0,1)  say.
> 
> Regards
> allan



From andy_liaw at merck.com  Tue Feb 10 16:52:39 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 10 Feb 2004 10:52:39 -0500
Subject: [R] how to get the GUI directory chooser on Windows?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7776@usrymx25.merck.com>

Dear R-help,

Can anyone tell me if it's possible to call up the "directory chooser" (the
one you get when you click on "File" -> "Change Dir...") in Rgui from the R
command line?  Seems like file.choose() can't be used to choose a directory.

This is in R-1.8.1 on WinXPPro.

Any help much appreciated!

Andy



------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From Nathalie.Peyrard at avignon.inra.fr  Tue Feb 10 16:55:56 2004
From: Nathalie.Peyrard at avignon.inra.fr (Peyrard Nathalie)
Date: Tue, 10 Feb 2004 16:55:56 +0100
Subject: [R] interfacing C code in Windows
Message-ID: <4028FF0C.3090006@avignon.inra.fr>

Hi,

I know how to incorporate C code in R if using Linux. Can someone 
explain me how to do the same using Windows (if it is possible)?
Thanks

 Nathalie Peyrard



From lutz.thieme at amd.com  Tue Feb 10 17:34:05 2004
From: lutz.thieme at amd.com (lutz.thieme@amd.com)
Date: Tue, 10 Feb 2004 17:34:05 +0100
Subject: [R] name space conflict using RMySQL and ROracle
Message-ID: <E540DF203FFED21182EB0008C728756014A87800@deexmta4.amd.com>

Hello everybody,

could anybody give me a hint how to to use RMySQL and ROracle libraries at the same
time without getting conflict with name spaces?
Because it needs to much time, unloading and reloading the libraries is no solution...

Example:
----------- snip -----------------
library(ROracle)
library(RMySQL)

mysql	<- MySQL()
con	<- dbConnect(mysql, user=MySQL.name, password=MySQL.pwd, dbname=MySQL.DB, host=MySQL.host)
MySQLres <- dbGetQuery(con, MySQL.query)
dbDisconnect(con)

ora			<- Oracle()
con			<- dbConnect(ora, user=Oracle.name, password=Oracle.pwd, dbname=Oracle.DB)
OraRes	<- dbGetQuery(con, Ora.query)
dbDisconnect(con)
----------- snap -----------------

platform sparc-sun-solaris2.8
arch     sparc               
os       solaris2.8          
system   sparc, solaris2.8   
status                       
major    1                   
minor    7.1                 
year     2003                
month    06                  
day      16                  
language R       


Thank you in advance!

	Kind regards,

	Lutz


	Lutz Thieme
	Product Engineering
	AMD Saxony Limited Liability Company & Co. KG
	M/S E22-PE, Wilschdorfer Landstr. 101
	D-01109 Dresden, Gemany
	phone:	+ 49-351-277 -  4269
	fax:		+ 49-351-277-9-4269



From p.dalgaard at biostat.ku.dk  Tue Feb 10 17:50:19 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Feb 2004 17:50:19 +0100
Subject: [R] R: lags
In-Reply-To: <4028EF36.D68A778D@stats.uct.ac.za>
References: <4028EF36.D68A778D@stats.uct.ac.za>
Message-ID: <x2isievpys.fsf@biostat.ku.dk>

allan clark <allan at stats.uct.ac.za> writes:

> hi all
> 
> how does one simulate a random walk process?
> 
> i.e
> 
> y(0)=0
> 
> y(t)=y(t-1)+ e(t)
> 
> where e(t) is normal(0,1)  say.

E.g.,

c(0,cumsum(rnorm(1000)))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Tue Feb 10 18:22:31 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 10 Feb 2004 09:22:31 -0800
Subject: [R] how to use  try()
In-Reply-To: <4028E4CF.7010307@mcgill.ca>
References: <26D5AB9F6512D611A8610001FA7E136F032783B2@se-drc-mail4.selu.astrazeneca.net>
	<4028E4CF.7010307@mcgill.ca>
Message-ID: <40291357.3070705@pdf.com>

      The "try" solutions suggested won't work in S-Plus.  If you want 
transportable code, the following worked for me just now in both S-Plus 
6.2 and R 1.8.1: 

error <- function()stop()

result <- try(error())
if(regexpr("error", casefold(class(result)))>0)
    "try trapped an error"

      Best Wishes,
      spencer graves

r.ghezzo wrote:

> Thanks to everybody who answered my question. Here are the suggestion 
> for completion sake of the archives.
> from John Fox @ Mcmaster.ca
> lo <-
> try(nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
> beta[i] <- if (class(lo) == "try-error") NA else lo$m$getPars()[4]
>
> from Peter Dalgaard @ biostat.ku.dk
> Just check the return value from try:
> beta[i] <- if(inherits(try(.....),"try-error")) NA else lo$etc...
>
> from Thomas Lumley @ u.washington.edu
> You want either both assignments inside the try()
> try({
>     lo<-nls(....)
>     beta[i]<-lo$m$getPars(4)
> })
>
> or both outside
>
> lo<- try(nls(....))
> if (inherits(lo,"try-error")) beta[i]<-NA else beta[i]<-lo$m$getPars()[4]
>
> from Sundar Dorai-Raj @ pdf.com
> if (inherits(lo,"try-error")) beta[i]<-NA else beta[i]<-lo$m$getPars()[4]
>
> also from Andrej Kveder @ zrc-sazu.si; Patric Burns @ pburns.seanet.com
> Hadley Wickham @ auckland.ac.nz;
>
> from Douglas Bates @ stat.wisc.edu
> Check the function nlsList in package nlme.  It does something very
> like what you want to do.
> It is not a good idea to use lo$m$getPars() directly.  It is better to
> use the generic function, which in this case is coef(), as in
> coef(lo)[4]
>
>
> On Mon, 09 Feb 2004 14:30:07 -0500
>  "r.ghezzo" <heberto.ghezzo at mcgill.ca> wrote:
>
>>> Hello, I have a program with this section:
>>> ..
>>> for(i in 1:20){
>>>   lo <-
>>> nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1))
>>>   beta[i] <- lo$m$getPars()[4]
>>> }
>>> ..
>>> If the fit works this is OK but if the fit fails, the whole program
>>> fails so:
>>> ..
>>> for(i in 1:20){
>>>   try(lo <- 
>>> nls(y~y0+a/(1+(x/x0)^b),start=list(y0=0.1,a=a0,x0=x00,b=-8.1)))
>>>   beta[i] <- lo$m$getPars()[4]
>>> }
>>> ..
>>> but the try catches the error in nls and beta[i] gets assigned
>>> beta[i-1] from the previous loop. This is bad but no so bad as it can
>>> be checked,
>>> Now in some cases the error is in i=1 and the program stops!!
>>> is there a way to set lo$m$getPars() to zero before the call?
>>> I tried to understand the use of tryCatch() but frankly it is above
>>> me. Sorry
>>> Thanks for any help
>>> Heberto Ghezzo
>>> Meakins-Christie Labs
>>>
>>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From wolfram at fischer-zim.ch  Tue Feb 10 18:27:43 2004
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Tue, 10 Feb 2004 18:27:43 +0100
Subject: [R] lattice: scales beginning at zero with relation="free"
Message-ID: <20040210172743.GA13971@s1x.local>

Is there an easy way to have scales beginning with zero and
ending with the local maximum data value of each panel
when using a lattice function with ``scales=list( relation="free" )''?

Thanks. Wolfram



From apjaworski at mmm.com  Tue Feb 10 18:54:46 2004
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Tue, 10 Feb 2004 11:54:46 -0600
Subject: [R] How to compute the minimal distanct between a point and
	curve	in N-dim space
Message-ID: <OFC00C2CF1.4AE838F7-ON86256E36.00612D9B-86256E36.006265D8@mmm.com>


In general there will be no closed form solution.  In fact, for a general
curve in N dimensions one can have multiple discrete solutions or even a
continuum of solutions.  A trivial example of this is a problem of finding
a point on a circle in 2D closest to its center.

A curve in N dimensions can be described by a set of N coordinate functions
of a single parameter.  For example, a straight line in 3D going through
the (x0, y0, z0) point and having the "directional vector" (a, b, c) can be
described by

      x(t) = x0 + a*t
      y(t) = y0 + b*t
      z(t) = z0 + c*t

Then, the (Euclidean) distance between an arbitrary point (x1, y1, z1) and
a point on the curve can be written as:

      d(t) = sqrt((x(t) - x1)^2 + (y(t) - y1)^2 + (z(t) - z1)^2).

This function could be minimized either analytically or numerically with
respect to t.  In the straight line example, an analytical solution is
possible.  In fact the minimum value of the parameter t happens to be

      t(min) = (a*(x1-x0) + b*(y1-y0) + c*(z1-z0))/(a^2 + b^2 + c^2)

and substituting this value into the line equations gives the coordinates
of the minimum solution.


Hope this helps,

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+-------------------------------->
|         |           "Feng Zhang"         |
|         |           <f0z6305 at labs.tamu.ed|
|         |           u>                   |
|         |           Sent by:             |
|         |           r-help-bounces at stat.m|
|         |           ath.ethz.ch          |
|         |                                |
|         |                                |
|         |           02/10/2004 09:17     |
|         |                                |
|---------+-------------------------------->
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       "R-help mailing list" <r-help at stat.math.ethz.ch>                                                             |
  |      cc:                                                                                                                    |
  |      Subject:  [R] How to compute the minimal distanct between a point and curve       in N-dim space                       |
  >-----------------------------------------------------------------------------------------------------------------------------|




Dear All,

In the N-dimensional space, give a data point A and a curve f,
how to write the explicit expression for calculating the
minimal distance between A and f?

Or have to use some nonlinear optimization method to calcualte it?

Thanks for your point.

Fred





             [[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From TyagiAnupam at aol.com  Tue Feb 10 18:55:58 2004
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Tue, 10 Feb 2004 12:55:58 EST
Subject: [R] Dotplot:  y-labels from rownames 
Message-ID: <3c.3ae0fa53.2d5a752e@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/59fd32cd/attachment.pl

From consentino at infinito.it  Tue Feb 10 19:31:20 2004
From: consentino at infinito.it (Fabrizio Consentino)
Date: Tue, 10 Feb 2004 19:31:20 +0100
Subject: [R] Diagnostic in multilevel models
Message-ID: <014301c3f004$150720f0$7b201d97@consentino>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/61cdda7c/attachment.pl

From elvis at xlsolutions-corp.com  Tue Feb 10 20:10:33 2004
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 10 Feb 2004 12:10:33 -0700
Subject: [R] Course***R/S-plus Programming Techniques in Raleigh,
	February 26-27
Message-ID: <20040210191033.22453.qmail@webmail4.mesa1.secureserver.net>


   XLSolutions Corporation ([1]www.xlsolutions-corp.com) is proud
   to announce February-March 2004 2-day "R/S-plus Fundamentals and
   Programming
   Techniques".
   ****Raleigh, NC --------------------> February, 26,27

   Interested in our R/Splus Advanced Programming course?  Please email
   us!
   Reserve your seat now at the early bird rates! Payment due AFTER the
   class.

   Course Description:
   This two-day beginner to intermediate R/S-plus course focuses
    on a broad spectrum of topics,
   from reading raw data to a comparison of R and S. We will learn
   the essentials of data manipulation, graphical visualization
   and R/S-plus programming. We will explore statistical data analysis
   tools,including graphics with data sets. How to enhance your plots.
   We will perform basic statistics and fit linear regression models.
   Participants are encouraged to bring data for interactive sessions

   With the following outline:
   - An Overview of R and S
   - Data Manipulation and Graphics
   - Using Lattice Graphics
   - A Comparison of R and S-Plus
   - How can R Complement SAS?
   - Writing Functions
   - Avoiding Loops
   - Vectorization
   - Statistical Modeling
   - Project Management
   - Techniques for Effective use of R and S
   - Enhancing Plots
   - Using High-level Plotting Functions
   - Building and Distributing Packages (libraries)

   Early Bird Research: $995 (Includes course materials and snacks);
   Email us for group discounts.
   Email Sue Turner: [2]sue at xlsolutions-corp.com
   Phone: 206-686-1578
   Visit us: [3]www.xlsolutions-corp.com/training.htm
   Please let us know if you and your colleagues are interested in this
   classto take advantage of group discount. Register now to secure your
   seat!
   Interested in R/Splus Advanced course? email us.

   Cheers,
   Elvis Miller, PhD
   Manager Training.
   XLSolutions Corporation
   206 686 1578
   [4]www.xlsolutions-corp.com
   [5]elvis at xlsolutions-corp.com

References

   1. http://www.xlsolutions-corp.com/
   2. mailto:sue at xlsolutions-corp.com
   3. http://www.xlsolutions-corp.com/training.htm
   4. http://www.xlsolutions-corp.com/
   5. mailto:elvis at xlsolutions-corp.com


From deepayan at stat.wisc.edu  Tue Feb 10 20:47:28 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 10 Feb 2004 13:47:28 -0600
Subject: [R] lattice: scales beginning at zero with relation="free"
In-Reply-To: <20040210172743.GA13971@s1x.local>
References: <20040210172743.GA13971@s1x.local>
Message-ID: <200402101347.28188.deepayan@stat.wisc.edu>

On Tuesday 10 February 2004 11:27, Wolfram Fischer wrote:

> Is there an easy way to have scales beginning with zero and
> ending with the local maximum data value of each panel
> when using a lattice function with ``scales=list( relation="free" )''?

Add 

prepanel = function(x, y, ...) list(xlim = c(0, max(x)), ylim = c(0, max(y)))

If you want this for only one of the axes, just leave out the other component. 
If you want to suppress the automatic extension of the limits, you need to 
add axs = "i" in the appropriate component of scales.

Deepayan



From dmurdoch at pair.com  Tue Feb 10 20:56:01 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 10 Feb 2004 14:56:01 -0500
Subject: [R] Constructing an environment from a data.frame
Message-ID: <97di201lmt4olugcajuejn1jmi8ifm8cc0@4ax.com>

Code like

df <- data.frame(x=1:10)
y <- 20:29

eval(quote(x+y), env=df)

does what you might expect:  it looks for x and y in the data.frame,
and when it doesn't find y there, it looks in the parent environment.

However, sometimes I'd like to construct a single environment out of
df, so that I can pass it to nested functions and get the same
behaviour.  Right now, I get the wrong answer from code like this:

f1 <- function(df) {
    g <- function() {
	eval(quote(x+y), env=df)
    }
    y <- 1:10
    g()
}

f1(df)

because the eval looks in the environment of f1, finds y there, and
gives me the wrong answer.

I can modify f1 so it works:

f2 <- function(df) {
    g <- function(env) {
	eval(quote(x+y), env=df, enclos=env)
    }
    y <- 1:10
    g(parent.frame())
}

but this means carrying around both parent.frame() and df.  I'd like
to do this:

f3 <- function(df) {
    env <- as.environment(df)

    g <- function() {
	eval(quote(x+y), env=env)
    }

    y <- 1:10
    g()
}

and get the same result as from f2(df), but currently as.environment
doesn't like to be passed a data.frame.  Is there a better way to do
the same thing?

Duncan Murdoch



From VERSRJ at inel.gov  Tue Feb 10 21:23:31 2004
From: VERSRJ at inel.gov (VERSRJ@inel.gov)
Date: Tue, 10 Feb 2004 13:23:31 -0700
Subject: [R] Invoking R from PHP/Mysql environment
Message-ID: <OF60867B45.65B25A8C-ON87256E36.006F2CAF@inel.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/9b1cecdf/attachment.pl

From deepayan at stat.wisc.edu  Tue Feb 10 21:49:08 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 10 Feb 2004 14:49:08 -0600
Subject: [R] Dotplot:  y-labels from rownames
In-Reply-To: <3c.3ae0fa53.2d5a752e@aol.com>
References: <3c.3ae0fa53.2d5a752e@aol.com>
Message-ID: <200402101449.08121.deepayan@stat.wisc.edu>

On Tuesday 10 February 2004 11:55, TyagiAnupam at aol.com wrote:
> How can I use row.names() as y-labels in Dotplot? How to set horizontal
> orientation for y-lables in lattice()?
>
> Dotplot(stcod1 ~ Cbind(statgh2,statgh2-1.96*segh2,statgh2+1.96*segh2)[og],
> subset=statgh2[og]>0.1, data=h2inqerrg02st, xlab="G",
> ylab=row.names(h2inqerrg02st)[og], main="")
>
> I have tried doing it with mtext() as well, but there is not enough space
> besides
> y-axis.

Your terminology is unclear. In particular, your attempted usage of xlab and 
ylab look inconsistent. 

Before trying to use non-default features of lattice, please read 
help("Lattice") and help("dotplot"). In particular the section on 'scales' in 
the latter should answer some of your questions.

Deepayan



From rolf at math.unb.ca  Tue Feb 10 21:49:16 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 10 Feb 2004 16:49:16 -0400 (AST)
Subject: [R] make check in 1.8.1.
Message-ID: <200402102049.i1AKnGlX007535@erdos.math.unb.ca>


I just (finally!!!) got R version 1.8.1 to configure and build under
Solaris 9 (after much travail; there were funnies in my environment
variables that mucked things up, but that's another story).

Anyhow, when I ran ``make check'' I got an error right toward the
end.  Looking in the directory ``tests'' I found that the error was
associated with the file reg-tests-3.R, and the complaint was that it
couldn't find the object Cars93 from the MASS package.

So I edited reg-tests-3.R and stuck in the line ``data(Cars93)'':

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
## lm.influence where hat[1] == 1
if(require(MASS)) {
#
     data(Cars93)  # <------------------------- INSERTED LINE
#
    fit <- lm(formula = 1000/MPG.city ~ Weight + Cylinders + Type + EngineSize + DriveTrain, data = Cars93)
    print(lm.influence(fit))
    ## row 57 should have hat = 1 and resid=0.
    summary(influence.measures(fit))
}
## only last two cols in row 57 should be influential
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

Then I re-ran make check, and everything seemed to go OK.

I had a brief scan of the r-help mailing list archives just now and
could find no allusions to this problem.

Has anyone else encountered the problem?  ***Should*** that line
``data(Cars93)'' be in the code?  If not, what is going on?  If so,
why hasn't anyone else been bitten?  (Like, I mean, why me?) :-)


				cheers,

					Rolf Turner
					rolf at math.unb.ca

P. S.  Version details:
 > version
         _
platform sparc-sun-solaris2.9
arch     sparc
os       solaris2.9
system   sparc, solaris2.9
status
major    1
minor    8.1
year     2003
month    11
day      21
language R



From p.murrell at auckland.ac.nz  Tue Feb 10 21:49:50 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 11 Feb 2004 09:49:50 +1300
Subject: [R] Invoking R from PHP/Mysql environment
References: <OF60867B45.65B25A8C-ON87256E36.006F2CAF@inel.gov>
Message-ID: <402943EE.3070604@stat.auckland.ac.nz>

Hi


VERSRJ at inel.gov wrote:
> We have a setup in which we use PHP (with Geeklog as a CMS) as a front end
> to MySQL. We plan to use R for offering user driven and automated
> statistical analysis of some of the data we obtain. We'll be using the R 
> interface
> to the MySQL database from omegahat (www.omegahat.org) for getting
> the data out of the database, but we were wondering if somebody tackled
> the problem of how to integrate R nicely with PHP.
> 
> Specifically, we know how to get R to run as a system command from PHP, 
> but
> ideally we'd like to call R as a PHP function. If somebody did this we'd 
> like
> to have some pointers as to how they did it If not, we'll probably do it 
> ourselves
> and post the results


You might want to take a look at R-php (http://dssm.unipa.it/R-php/) and 
R_PHP_Online (http://steve-chen.net/R_PHP/).

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From rolf at math.unb.ca  Tue Feb 10 22:15:33 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 10 Feb 2004 17:15:33 -0400 (AST)
Subject: [R] Permissions after install of R 1.8.1.
Message-ID: <200402102115.i1ALFXMA009557@erdos.math.unb.ca>


I just encountered another mild funny in encounters with R 1.8.1.  I
did a make install (as root) of my newly built R 1.8.1.  When I tried
to test it I was told ``permission denied'' in respect of
/usr/local/lib/R/bin/R.bin.

I had a look, and the permissions on R.bin were indeed

-rwx------    1 root     other     7138492 Feb 10 16:52 R.bin*

Every ***other*** file in the directory, except for one, had permissions

		-rwxr-xr-x

as I would have expected (root's umask is 22).

The one other oddball file was libRlapack.so which had permissions
-rwx------ like unto R.bin.

I changed the permissions and everything seems to be working now ....
But ***why***?  (And again, why me?)

					cheers,

						Rolf Turner
						rolf at math.unb.ca



From hxc05 at health.state.ny.us  Tue Feb 10 22:44:02 2004
From: hxc05 at health.state.ny.us (Haiyan Chen)
Date: Tue, 10 Feb 2004 16:44:02 -0500
Subject: [R] generate random sample from ZINB
Message-ID: <OF78DADD36.533FEB8F-ON85256E36.0076C470@health.state.ny.us>

I want to generate 1,000 random samples of sample size=1,000 from ZINB.
I know there is a rnegbin() to generate random samples from NB, and I know
I can use
the following process:

do i=1 to 1000

n=0

do i=1 to 1000

 if runi(1)>0.1 then x(i) = 0; else
x(i)=rnegbin();

n=n+1;

if n>1000 then stop;

end;

output;
end;

Anybody can help me out with the R code?
Thanks very much ahead of time.
Heyen



From jim.lemon at uts.edu.au  Tue Feb 10 23:09:02 2004
From: jim.lemon at uts.edu.au (Jim Lemon)
Date: Wed, 11 Feb 2004 09:09:02 +1100
Subject: [R] Bug in concord package
Message-ID: <0HSW009MC2KXSP@mail.uts.edu.au>

Please note that there is a bug in the tie correction function in the package:

concord_1.2.tar.gz

Thanks to Dr Siegfried Macho, who discovered it. I have fixed it, and 
uploaded  the revised package:

concord_1.2-1.tar.gz

If anyone has downloaded the first package, please replace it with the second 
one.

Thanks,

Jim

Dr Jim Lemon
Research Psychologist
Health Psychology Unit
University of Technology, Sydney

Feel free to ignore any garbage beneath this line.




DISCLAIMER\ ================================================...{{dropped}}



From TyagiAnupam at aol.com  Tue Feb 10 23:11:29 2004
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Tue, 10 Feb 2004 17:11:29 EST
Subject: [R] Dotplot:  y-labels from rownames
Message-ID: <103.3ef2d25a.2d5ab111@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040210/baa34fe0/attachment.pl

From macq at llnl.gov  Tue Feb 10 23:12:53 2004
From: macq at llnl.gov (Don MacQueen)
Date: Tue, 10 Feb 2004 14:12:53 -0800
Subject: [R] make check in 1.8.1.
In-Reply-To: <200402102049.i1AKnGlX007535@erdos.math.unb.ca>
References: <200402102049.i1AKnGlX007535@erdos.math.unb.ca>
Message-ID: <p06002007bc4f06d23f84@[128.115.153.6]>

Whatever it is, it's apparently a bit on the subtle side. Perhaps a 
previous test loads the data, and for some reason that previous test 
doesn't run for you. I couldn't find one that did, though.

 From my 'make check':

running code in '../../source/tests/reg-tests-3.R' ... OK
comparing 'reg-tests-3.Rout' to 
'../../source/tests/reg-tests-3.Rout.save' ... OK

And my reg-tests-3.R does not have the data() statement:

if(require(MASS)) {
     fit <- lm(formula = 1000/MPG.city ~ Weight + Cylinders + Type + 
EngineSize + DriveTrain, data = Cars93)
     print(lm.influence(fit))
     ## row 57 should have hat = 1 and 
resid=0.                                                                             
     summary(influence.measures(fit))
}

-Don

At 4:49 PM -0400 2/10/04, Rolf Turner wrote:
>I just (finally!!!) got R version 1.8.1 to configure and build under
>Solaris 9 (after much travail; there were funnies in my environment
>variables that mucked things up, but that's another story).
>
>Anyhow, when I ran ``make check'' I got an error right toward the
>end.  Looking in the directory ``tests'' I found that the error was
>associated with the file reg-tests-3.R, and the complaint was that it
>couldn't find the object Cars93 from the MASS package.
>
>So I edited reg-tests-3.R and stuck in the line ``data(Cars93)'':
>
>===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
>## lm.influence where hat[1] == 1
>if(require(MASS)) {
>#
>      data(Cars93)  # <------------------------- INSERTED LINE
>#
>     fit <- lm(formula = 1000/MPG.city ~ Weight + Cylinders + Type + 
>EngineSize + DriveTrain, data = Cars93)
>     print(lm.influence(fit))
>     ## row 57 should have hat = 1 and resid=0.
>     summary(influence.measures(fit))
>}
>## only last two cols in row 57 should be influential
>===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
>
>Then I re-ran make check, and everything seemed to go OK.
>
>I had a brief scan of the r-help mailing list archives just now and
>could find no allusions to this problem.
>
>Has anyone else encountered the problem?  ***Should*** that line
>``data(Cars93)'' be in the code?  If not, what is going on?  If so,
>why hasn't anyone else been bitten?  (Like, I mean, why me?) :-)
>
>
>				cheers,
>
>					Rolf Turner
>					rolf at math.unb.ca
>
>P. S.  Version details:
>  > version
>          _
>platform sparc-sun-solaris2.9
>arch     sparc
>os       solaris2.9
>system   sparc, solaris2.9
>status
>major    1
>minor    8.1
>year     2003
>month    11
>day      21
>language R
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From spencer.graves at pdf.com  Tue Feb 10 23:15:03 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 10 Feb 2004 14:15:03 -0800
Subject: [R] generate random sample from ZINB
In-Reply-To: <OF78DADD36.533FEB8F-ON85256E36.0076C470@health.state.ny.us>
References: <OF78DADD36.533FEB8F-ON85256E36.0076C470@health.state.ny.us>
Message-ID: <402957E7.3090809@pdf.com>

      Have you done a search on "www.r-project.org" -> search -> "R site 
search"?  I just got 2 hits there, both of which suggest "Jim Lindsey's 
fmr function in the gnlm package. The help page has an example of both 
ZIP and ZINB model fits. The gnlm package can be downloaded from 
http://alpha.luc.ac.be/~jlindsey/rcode.html ". 

      hope this helps. 
      spencer graves

Haiyan Chen wrote:

>I want to generate 1,000 random samples of sample size=1,000 from ZINB.
>I know there is a rnegbin() to generate random samples from NB, and I know
>I can use
>the following process:
>
>do i=1 to 1000
>
>n=0
>
>do i=1 to 1000
>
> if runi(1)>0.1 then x(i) = 0; else
>x(i)=rnegbin();
>
>n=n+1;
>
>if n>1000 then stop;
>
>end;
>
>output;
>end;
>
>Anybody can help me out with the R code?
>Thanks very much ahead of time.
>Heyen
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From mail at joeconway.com  Wed Feb 11 00:15:44 2004
From: mail at joeconway.com (Joe Conway)
Date: Tue, 10 Feb 2004 15:15:44 -0800
Subject: [R] Invoking R from PHP/Mysql environment
In-Reply-To: <OF60867B45.65B25A8C-ON87256E36.006F2CAF@inel.gov>
References: <OF60867B45.65B25A8C-ON87256E36.006F2CAF@inel.gov>
Message-ID: <40296620.6090204@joeconway.com>

VERSRJ at inel.gov wrote:
> We have a setup in which we use PHP (with Geeklog as a CMS) as a
> front end to MySQL. We plan to use R for offering user driven and
> automated statistical analysis of some of the data we obtain. We'll
> be using the R interface to the MySQL database from omegahat
> (www.omegahat.org) for getting the data out of the database, but we
> were wondering if somebody tackled the problem of how to integrate R
> nicely with PHP.

If you can use Postgres instead of MySQL, see:
   http://www.joeconway.com/oscon-pres-2003-1.pdf
Page 23 has an example PHP code snippet. Very simple because most of the 
work is done in the PL/R function.

Joe



From jcjorgensen at wisc.edu  Wed Feb 11 01:07:35 2004
From: jcjorgensen at wisc.edu (Jeff Jorgensen)
Date: Tue, 10 Feb 2004 18:07:35 -0600
Subject: [R] levelplot colorkey
Message-ID: <5.2.1.1.2.20040210175033.02327c38@wiscmail.wisc.edu>

Dear R'ers,

I've scanned available documentation and the web, but I can't seem to 
figure out where I've gone wrong in adding numbers to scale the colorkey in 
levelplot (Lattice package).  For example,

levelplot(z, contour=T, labels=T, cuts=10, region=T,...
            colorkey=list(T, space="bottom",
                           at=seq(0,2000,length=20),
                                 labels=list(as.character(seq(0,2000,length=20))))
)

If I leave out the colorkey command the levelplot function works great, if 
I put it in I get the following error mesage:

Error in draw.colorkey(x$colorkey) : length(col) must be length(at)-1

Is there a way to find out length(col) (BTW, does col=color?) so that I can 
readjust the label locations (at=...), or have I completely missed 
something obvious that would quickly fix this up?


Cheers,

Jeff Jorgensen

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Jeff Jorgensen

Center for Limnology                             jcjorgensen at wisc.edu
University of Wisconsin Madison           ph (608) 263-2304
680 North Park Street                           fx (608) 265-2340
Madison, Wisconsin 53706                http://limnology.wisc.edu

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From alistair.campbell at jcu.edu.au  Wed Feb 11 01:15:31 2004
From: alistair.campbell at jcu.edu.au (Alistair Campbell)
Date: Wed, 11 Feb 2004 10:15:31 +1000
Subject: [R] Clinical significance as a package?
Message-ID: <000d01c3f034$28e27040$691edb89@alistaircampbel>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040211/d8347f1c/attachment.pl

From nikko at hailmail.net  Wed Feb 11 02:32:41 2004
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Wed, 11 Feb 2004 09:32:41 +0800
Subject: [R] RE: Savitzky-Golay smoothing -- an R implementation
Message-ID: <1076463161.13557.180834942@webmail.messagingengine.com>

Hi,
Savitzky and Golay were indeed pioneers of local least squares methods.
However the SG smoother is
hard to implement in practice because of missing values and problems at
the boundary. Paul Eilers 
at Leiden has presented a very nice method for smoothing series based on
penalized least squares 
known as Whittaker smoothing, develeoped in 1923 for life tables. Look at
Analytical Chemistry (2003) 75, 3299-3304.
Here is an R implementation that requires the SparseM package.

The smoothing parameter lambda, controls the amount of smoothing, and
"good" values can be found by cross validation.


difsm <- function(y, lambda, d){
# Smoothing with a finite difference penalty
# y:      signal to be smoothed
# lambda: smoothing parameter
# d:      order of differences in penalty (generally 2)
 
# Paul Eilers, 2002, ported from matlab by Nicholas Lewin-Koh
  require(SparseM)
  m <- length(y)
  E <- as(m,"matrix.diag.csr")
  D <- diff(E,differences=d)
  B <- E + (lambda * t(D)%*%D)
  z <- solve(B,y)
  z
}



From deepayan at stat.wisc.edu  Wed Feb 11 02:38:18 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 10 Feb 2004 19:38:18 -0600
Subject: [R] levelplot colorkey
In-Reply-To: <5.2.1.1.2.20040210175033.02327c38@wiscmail.wisc.edu>
References: <5.2.1.1.2.20040210175033.02327c38@wiscmail.wisc.edu>
Message-ID: <200402101938.18239.deepayan@stat.wisc.edu>

On Tuesday 10 February 2004 18:07, Jeff Jorgensen wrote:
> Dear R'ers,
>
> I've scanned available documentation and the web, but I can't seem to
> figure out where I've gone wrong in adding numbers to scale the colorkey in
> levelplot (Lattice package).  For example,
>
> levelplot(z, contour=T, labels=T, cuts=10, region=T,...
>             colorkey=list(T, space="bottom",
                            ^
                      what's this for ?

>                            at=seq(0,2000,length=20),
> labels=list(as.character(seq(0,2000,length=20)))) )

I think you wanted to do 

colorkey = list(space = "bottom",
                labels = list(at = seq(0,2000,length=20),
                              lab = seq(0,2000,length=20)))

and then you would have changed the 20 to 21 :-)

Deepayan



From yzhang4 at turing.une.edu.au  Wed Feb 11 03:22:30 2004
From: yzhang4 at turing.une.edu.au (Yuandan Zhang)
Date: Wed, 11 Feb 2004 13:22:30 +1100
Subject: [R] RW1081.exe installation
Message-ID: <402991E6.2050406@turing.une.edu.au>

Hi, I download R 1.081 for windows (RW1081.exe). I tried to install it 
on windows 98 or windows xp, it stoped and stated that 'This program 
must be run under Win32'. Any one have suggestion how to fix it ?

Thanks Yuandan



From grzm at myrealbox.com  Wed Feb 11 05:07:06 2004
From: grzm at myrealbox.com (Michael Glaesemann)
Date: Wed, 11 Feb 2004 13:07:06 +0900
Subject: [R] Installation on Mac OS X 10.3.2 with Fink readline and headers
Message-ID: <C13A5A79-5C47-11D8-A9DE-000A95C88220@myrealbox.com>

Hello!

I'd like to install R on my machine in order to work with Joe Conway's 
pl/R in PostgreSQL. I'm running Mac OS X 10.3.2 with readline installed 
via Fink. I downloaded the Rdevel.dmg, and installed first 
Rframework.pkg and then Rapp.pkg. (I did not install the 
J_libreadline.pkg, J_libxml2.pkg, or J_tcltk.pkg also included on the 
disk image.) Both Rframework and Rapp installed apparently 
successfully, but R wouldn't launch. Checking the console log, I 
noticed this:

dyld: 
/Library/Frameworks/R.framework/Versions/1.9.0/Resources/bin/R.bin 
can't open library: /usr/local/lib/libreadline.4.3.dylib  (No such file 
or directory, errno = 2)

I know I have readline installed via Fink. As a hack, I created a 
symbolic link in /usr/local/lib to /sw/lib/libreadline.4.3.dylib, which 
is where Fink put it. Upon reinstalling Rframework.pkg and Rapp.pkg, it 
seems to work. R launches and I've been able to do a few (very) simple 
things.

In the README for pl/R, I find these notes:

     - R headers are required. Download and install R prior to building
       PL/R.

     - R must have been built with the --enable-R-shlib option when it 
was
       configured, in order for the libR shared object library to be 
available.

I tried to make pl/R, but I get this error:

*** Cannot build PL/R because libR is not a shared library.
*** You might have to rebuild your R installation.  Refer to
*** the documentation for details.

So it looks like the package installer does not do the equivalent of 
building with --enable-R-shlib. I'm also wondering whether the R 
headers are in a place where pl/R can find them.

Is there a way to specify my readline installation to the package 
installer (instead of manually creating the symbolic link)? And is 
there a way to install with --enable-R-shlib with the package 
installer?

Thanks for any help. I've checked the archives and done a bit of 
googling, but didn't find anything I thought was applicable.

Michael Glaesemann
grzm myrealbox com



From jdn at cs.sfu.ca  Wed Feb 11 06:54:40 2004
From: jdn at cs.sfu.ca (Jason Nielsen)
Date: Tue, 10 Feb 2004 21:54:40 -0800 (PST)
Subject: [R] lapply and dynamically linked functions
Message-ID: <Pine.LNX.4.53.0402102144060.2494@lenny>

Hi all,

I'm trying to use lapply on a list with the following command:

out<-lapply(mylist,myfun,par1=p,par2=d)               (1)

where

myfun<-function(x,par1,par1) {.....}                  (2)

now this function is in fact a wrapper for some Fortran code I have
written so I think this might be the problem.  When I call lapply() as in
(1)  I get the following message:

Error in get(x, envir, mode, inherits) : variable "mylist" was not found

but if I say do:

out<-lapply(mylist,sum)

it returns a nice list with the sums of the elements in the list.  So
after all that I guess my question is does this have to do with the fact
that my function is a wrapper for my Fortran code (which works fine on its
own.. and if I use a loop as opposed to lapply() )?  I imagine that lapply
which is a wrapper for the .Internal lapply might have some trouble with
my Fortran wrapper?  Is this the case or is it something dumb on my end?  
Any input is appreciated.

Cheers,
Jason



From miriamdreissig at web.de  Wed Feb 11 08:42:04 2004
From: miriamdreissig at web.de (=?iso-8859-1?Q? Miriam=20Drei=DFig ?=)
Date: Wed, 11 Feb 2004 08:42:04 +0100
Subject: [R] MCD-Estimator in R
Message-ID: <200402110742.i1B7g4Q06881@mailgate5.cinetic.de>

Content-Type: text/html; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
X-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on hypatia.math.ethz.ch
X-Spam-Status: No, hits=0.7 required=5.0 tests=BAYES_30,HTML_MESSAGE,MIME_HTML_ONLY autolearn=no version=2.63
X-Spam-Level: 

<html><style>p {margin: 0px}</style><body bgcolor=3D'#ffffff' style=3D'font-si=
ze:9pt; font-family:Verdana; font-family: Verdana' ><STYLE>p {margin: 0px}=
</STYLE><P>Hello!</P><P>I have a question concerning the use of the MCD-es=
timator in the funtion 'lda' and 'qda'. I'm working with the R-version 1.7=
.0, which doesn't allow to use 'cov.mcd' in either 'lda'&nbsp;ot 'qda' (on=
ly the cov.mve etc. but that's not what I need). So, I was wondering if th=
e newer verions do. Thanks for your help.</P><P>Best regards,</P><P>Miriam=
 Drei=DFig</P><P>&nbsp;</P></body></html>
=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=
=5F=5F=5F=5F<br>Erdbeben im Iran: Zehntausende Kinder brauchen Hilfe. UNICEF hilft=
 den<br>Kindern - helfen Sie mit! https://www.unicef.de/spe/spe=5F03.php



From ligges at statistik.uni-dortmund.de  Wed Feb 11 09:38:03 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 11 Feb 2004 09:38:03 +0100
Subject: [R] MCD-Estimator in R
In-Reply-To: <200402110742.i1B7g4Q06881@mailgate5.cinetic.de>
References: <200402110742.i1B7g4Q06881@mailgate5.cinetic.de>
Message-ID: <4029E9EB.7080601@statistik.uni-dortmund.de>

Miriam Drei?ig wrote:
> Content-Type: text/html; charset="iso-8859-1"
> Content-Transfer-Encoding: quoted-printable
> X-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on hypatia.math.ethz.ch
> X-Spam-Status: No, hits=0.7 required=5.0 tests=BAYES_30,HTML_MESSAGE,MIME_HTML_ONLY autolearn=no version=2.63
> X-Spam-Level: 
> 
> <html><style>p {margin: 0px}</style><body bgcolor=3D'#ffffff' style=3D'font-si=
> ze:9pt; font-family:Verdana; font-family: Verdana' ><STYLE>p {margin: 0px}=
> </STYLE><P>Hello!</P><P>I have a question concerning the use of the MCD-es=
> timator in the funtion 'lda' and 'qda'. I'm working with the R-version 1.7=
> .0, which doesn't allow to use 'cov.mcd' in either 'lda'&nbsp;ot 'qda' (on=
> ly the cov.mve etc. but that's not what I need). So, I was wondering if th=
> e newer verions do. Thanks for your help.</P><P>Best regards,</P><P>Miriam=
>  Drei=DFig</P><P>&nbsp;</P></body></html>
> =5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=5F=
> =5F=5F=5F=5F<br>Erdbeben im Iran: Zehntausende Kinder brauchen Hilfe. UNICEF hilft=
>  den<br>Kindern - helfen Sie mit! https://www.unicef.de/spe/spe=5F03.php
> 


Please tell your e-mail software to send plain text messages to lists 
like this.
Please upgrade to the recent version, R-1.8.1, since many bugs are fixed 
  and a lot of features have been introduced.
Please note that lda() and qda() are in package MASS in the VR package 
bundle, not in R itself.
Finally, documentation does not mention 'cov.mcd' in the recent version 
of the VR bundle.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Wed Feb 11 09:53:02 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 11 Feb 2004 09:53:02 +0100
Subject: [R] RW1081.exe installation
In-Reply-To: <402991E6.2050406@turing.une.edu.au>
References: <402991E6.2050406@turing.une.edu.au>
Message-ID: <4029ED6E.60404@statistik.uni-dortmund.de>

Yuandan Zhang wrote:

> Hi, I download R 1.081

It's called R-1.8.1.


> for windows (RW1081.exe). I tried to install it 
> on windows 98 or windows xp, it stoped and stated that 'This program 
> must be run under Win32'. Any one have suggestion how to fix it ?

Hmm. Strange.
Can you try to download the file again (if it is corrupted).
I have not heard of such a problem before. Maybe something is strange 
with your version(s) of Windows?

Uwe Ligges



> Thanks Yuandan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From dimorett at istat.it  Wed Feb 11 10:48:04 2004
From: dimorett at istat.it (Diego Moretti)
Date: Wed, 11 Feb 2004 10:48:04 +0100
Subject: [R] The use of R for the elaboration of some index
Message-ID: <4029FA54.8040605@istat.it>

Hello,
Our  Statistics Group is evaluating the use of R for the elaboration of 
some index.
We have some datasets sas (120 Mb) and we would like to evaluate 
performance in the elaborations of mean, percentile, Gini index of a 
population and of a survey sample.
I need to open "a dataset". Currently I've understood that I've to 
follow a code sequence like this:

alfa <- {a moltiplicator}
memory.limit(alfa*round(memory.limit()/1048576.0, 2))
library(foreign)
hereis <- read.xport("C:/R/ { my exported file sas }")

The dimension of { my exported file sas } is 120 mega
Is correct to allocate all the file in memory in a variable ( hereis ) ?
With an alfa ( the moltiplicator ) of  2 , I have the following errors:
    Error: cannot allocate vector of size 214 Kb
    In addition: Warning message:
    Reached total allocation of 446Mb: see help(memory.size)
How can I solve this problem?
Is R-language able to manage data of 100-150 Mb ? And in which conditions?

I'm looking for informations about the use of R and some specific problems.
I'm looking for example (Code of) of complex program in R.
The program I must build could be described by the following steps:
1) open a dataset sas of 120 mega
2) merge it with a weighting universe little dataset
3) calculate a survey index
4) store it in a file
I'm looking also for some developers/users in R language.

Thank you for any advice.
Yours faithfully

Diego Moretti

-- 
============================================================
Diego Moretti                           (dimorett at istat.it)
Italian National Statistical Institute  (ISTAT)



From ligges at statistik.uni-dortmund.de  Wed Feb 11 11:32:52 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 11 Feb 2004 11:32:52 +0100
Subject: [R] Constructing an environment from a data.frame
In-Reply-To: <97di201lmt4olugcajuejn1jmi8ifm8cc0@4ax.com>
References: <97di201lmt4olugcajuejn1jmi8ifm8cc0@4ax.com>
Message-ID: <402A04D4.6000501@statistik.uni-dortmund.de>

Duncan Murdoch wrote:

> Code like
> 
> df <- data.frame(x=1:10)
> y <- 20:29
> 
> eval(quote(x+y), env=df)
> 
> does what you might expect:  it looks for x and y in the data.frame,
> and when it doesn't find y there, it looks in the parent environment.
> 
> However, sometimes I'd like to construct a single environment out of
> df, so that I can pass it to nested functions and get the same
> behaviour.  Right now, I get the wrong answer from code like this:
> 
> f1 <- function(df) {
>     g <- function() {
> 	eval(quote(x+y), env=df)
>     }
>     y <- 1:10
>     g()
> }
> 
> f1(df)
> 
> because the eval looks in the environment of f1, finds y there, and
> gives me the wrong answer.
> 
> I can modify f1 so it works:
> 
> f2 <- function(df) {
>     g <- function(env) {
> 	eval(quote(x+y), env=df, enclos=env)
>     }
>     y <- 1:10
>     g(parent.frame())
> }
> 
> but this means carrying around both parent.frame() and df.  I'd like
> to do this:
> 
> f3 <- function(df) {
>     env <- as.environment(df)
> 
>     g <- function() {
> 	eval(quote(x+y), env=env)
>     }
> 
>     y <- 1:10
>     g()
> }
> 
> and get the same result as from f2(df), but currently as.environment
> doesn't like to be passed a data.frame.  Is there a better way to do
> the same thing?
> 
> Duncan Murdoch


I don't think it's easily possibe (but Luke et al. might want to correct 
me). My dirty solution would be:

f4 <- function(df) {
     env <- new.env()
     mapply(function(x, y) assign(y, x, envir=env), df, names(df))
     g <- function()
         eval(quote(x+y), env=env)
     y <- 1:10
     g()
}
f4(df)



Uwe



From Agustin.Lobo at ija.csic.es  Wed Feb 11 12:52:04 2004
From: Agustin.Lobo at ija.csic.es (Agustin.Lobo@ija.csic.es)
Date: Wed, 11 Feb 2004 12:52:04 +0100
Subject: [R] Bhat: installation problem
Message-ID: <1076500324.402a1764510b4@orogeno.ija.csic.es>

Hi!

I'm trying to install package Bhat on
a Win machine, had a problem and figured out
a fix, but would like to report the
problem and make sure the fix is correct. This is what I do:
1. Download Bhat_0.9-07.tar.gz
2. Uncompress it and compress it back to Bhat_0.9-07.zip
3. Install from the R windows gui (that
apparentely requires the zip compression and cannot 
deal with the tar.gz)

But when I type
library(Bhat)

I get:

Error in testRversion(descfirlds): This package has not been installed
properly. See Note in ?library

There it says that a "Built:" field should exist in DESCRIPTION.
As it is not there, I've copied a Built field from another
package and now library(Bhat) seems to work. But, is this
fix correct?

Thanks for any help on this,

Agus

PLEASE NOTE NEW E-MAIL ADDRESS
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera"
CSIC
Lluis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
e-mail Agustin.Lobo at ija.csic.es



From Agustin.Lobo at ija.csic.es  Wed Feb 11 13:00:05 2004
From: Agustin.Lobo at ija.csic.es (Agustin.Lobo@ija.csic.es)
Date: Wed, 11 Feb 2004 13:00:05 +0100
Subject: [R] Bhat: installation problem(2)
Message-ID: <1076500805.402a1945bc77a@orogeno.ija.csic.es>

Sorry I went too fast:
copying a "Built:" field
to DESCRIPTION
 makes library(Bhat) not
to issue any error message but
although "package:Bhat" is in
workspace 2, it's empty. This
fix does not work.

Agus

PLEASE NOTE NEW E-MAIL ADDRESS
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera"
CSIC
Lluis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
e-mail Agustin.Lobo at ija.csic.es



From ivonefig at ipimar.pt  Wed Feb 11 12:15:43 2004
From: ivonefig at ipimar.pt (Ivone Figueiredo)
Date: Wed, 11 Feb 2004 11:15:43 -0000
Subject: [R] Any help with bootstrapping
Message-ID: <000001c3f090$63b132e0$c9040a0a@Ivone1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040211/cf433007/attachment.pl

From chris1 at psyctc.org  Wed Feb 11 12:03:34 2004
From: chris1 at psyctc.org (Chris Evans)
Date: Wed, 11 Feb 2004 11:03:34 -0000
Subject: [R] Clinical significance as a package?  [Scanned by NHC]
In-Reply-To: <000d01c3f034$28e27040$691edb89@alistaircampbel>
Message-ID: <402A0C06.12144.9EE9EF@localhost>

On 11 Feb 2004 at 10:15, Alistair Campbell wrote:

> But, to my question. Does anyone know if there is a package developed
> for evaluating clinical significance using Jacobson and Truax's, or
> variations thereof, procedures?

Not exactly but you might want to look at:
   http://www.psyctc.org/stats/R/CSC1.html
which works using R and CGIwithR and shows some of the logic of CSC.

I'd be very interested to help with doing something and know a bit 
about the issues and have proselytised for the idea a bit:
	Evans, C., Margison, F. & Barkham, M. (1998) The contribution of 
reliable and clinically significant change methods to evidence-based 
mental health. Evidence Based Mental Health, 1, 70-72.

Chris

-- 
Chris Evans <chris at psyctc.org>
Consultant Psychiatrist in Psychotherapy, Rampton Hospital; 
Forensic Research Programme Director, Nottinghamshire NHS Trust, 
Research Consultant, Tavistock & Portman NHS Trust; 
Hon. SL Institute of Psychiatry
*** My views are my own and not representative 
of those institutions ***



From steve.roberts at man.ac.uk  Wed Feb 11 12:30:35 2004
From: steve.roberts at man.ac.uk (Steve Roberts)
Date: Wed, 11 Feb 2004 11:30:35 +0000
Subject: [R] RGui (Windows) crashes after use of a Salford Fortran DLL
Message-ID: <402A125A.22585.B50464@localhost>

Anybody out there successfully using the Salford Fortran compilers 
with R? 

I have created a DLL using the Salford FTN95 compiler and it works 
in as far I can dyn.load it, run the routines and get the  right 
answers back. Unfortunately subsequently, sometime later, the 
Rgui crashes (access violation I think from the DrWatson log). The 
crashes depend on whether or not I paste the code as one big 
chunk, or as little chunks, and sometimes I can do a few things 
before it crashes and other times not - but if I do exactly the same 
things the crashes are reproducible. The crashes are sometimes in 
the DLL and sometimes in pure R code. R1.7.1 and 1.8.1 seem to 
behave identically. Windows 2000 Pro.

I do get the dyn.load warning about the DLL changing the FPU 
control word.

Does this ring any bells with anyone?

Steve.

  Dr Steve Roberts 
  steve.roberts at man.ac.uk

Senior Lecturer in Medical Statistics,
CMMCH NHS Trust and University of Manchester Biostatistics Group,
0161 275 5192 / 0161 276 5785



From apiszcz at solarrain.com  Wed Feb 11 12:48:48 2004
From: apiszcz at solarrain.com (Al Piszcz)
Date: Wed, 11 Feb 2004 06:48:48 -0500 (EST)
Subject: [R] Comment: R patterns
Message-ID: <Pine.LNX.4.55.0402110646320.25568@l1>


A number of the threads that occur in this mail list
are excellent descriptions of usage patterns with R.

Is anyone developing a catalog of these?

The recent 'try' thread and many others are examples that may
have value as a separate document or to be merged with
the package help documentation.



From pvremort at vub.ac.be  Wed Feb 11 13:30:22 2004
From: pvremort at vub.ac.be (Piet van Remortel)
Date: Wed, 11 Feb 2004 13:30:22 +0100
Subject: [R] large fonts on plots
Message-ID: <opr27g0whfgzo14j@mach.vub.ac.be>

Hi all,

I need to enlarge te fonts used oo R-plots (plots, histograms, ...) in 
labels and titles etc.

I seem to be unable to figure out how to do it.    The problem is that the 
titles of the plots are simply unreadable when I insert them into my LaTeX 
text, since they are relatively small compared to the entire plot.

I am sure it is pretty simple, can anybody give me a hint ?

Please reply to:  pvremortNOSPAM at vub.ac.be


Thanks,


Piet


-- 
Piet van Remortel
PhD Student
pvremort at vub.ac.be
http://como.vub.ac.be/Members/Piet.htm



From uleopold at science.uva.nl  Wed Feb 11 13:31:24 2004
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: 11 Feb 2004 13:31:24 +0100
Subject: [R] Erro in loadNamespace
Message-ID: <1076502684.31409.5.camel@snowdon.science.uva.nl>

Dear list,

Iget the following error message:

> help.search("omit.na")
Error in loadNamespace(name) : package 'tools' does not have a name
space

I do not quite understand what it means in this case. Is something
corrupt in the installation?

I run R-1.8.1 in Linux RedHat 9 with kernel 2.6.2 on Intel P4.

Regards, Ulrich



-- 
__________________________________________________

Ulrich Leopold MSc.

Computational Bio- and Physical Geography (CBPG)
Institute for Biodiversity and Ecosystem Dynamics (IBED)
Faculty of Science
University of Amsterdam
Nieuwe Achtergracht 166
NL-1018WV Amsterdam

Room:   B2.52
Phone:	+31 20 525 7456 (7451 Secretary)
Fax:	+31 20 525 7431
Mobile:	+31 64 220 3028
Email:	uleopold at science.uva.nl
URL:    www.science.uva.nl/ibed/cbpg



From susana.barbosa at fc.up.pt  Wed Feb 11 13:42:27 2004
From: susana.barbosa at fc.up.pt (susana)
Date: Wed, 11 Feb 2004 12:42:27 +0000
Subject: [R] Error on imodwt function - package waveslim
Message-ID: <200402111242.27907.susana.barbosa@fc.up.pt>


Hi,

I'm using package waveslim (V 1.3)  for wavelet analysis, and I get the 
following error:

mra1=mra(data,J=5)
imodwt(mra1)
Error in imodwt(mra1) : argument `y' is not of class "modwt"

I tried to overcome this doing

 class(mra1)="modwt"
 
but then I get

imodwt(mra1)
Error in switch(name, haar = select.haar(), d4 = select.d4(), mb4 = select.mb4
(),  :
        switch: EXPR must return a length 1 vector


I would appreciate any insights on this

Thanks in advance,

Susana Barbosa


Details:
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    8.1
year     2003
month    11
day      21
language R



From andy_liaw at merck.com  Wed Feb 11 13:54:50 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 11 Feb 2004 07:54:50 -0500
Subject: [R] lapply and dynamically linked functions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF777F@usrymx25.merck.com>

My guess is that you probably refer to `mylist' instead of `x' inside
`myfun'.  Please show us the entire code, rather than leave us guessing.

Andy

> From: Jason Nielsen
> 
> Hi all,
> 
> I'm trying to use lapply on a list with the following command:
> 
> out<-lapply(mylist,myfun,par1=p,par2=d)               (1)
> 
> where
> 
> myfun<-function(x,par1,par1) {.....}                  (2)
> 
> now this function is in fact a wrapper for some Fortran code I have
> written so I think this might be the problem.  When I call 
> lapply() as in
> (1)  I get the following message:
> 
> Error in get(x, envir, mode, inherits) : variable "mylist" 
> was not found
> 
> but if I say do:
> 
> out<-lapply(mylist,sum)
> 
> it returns a nice list with the sums of the elements in the list.  So
> after all that I guess my question is does this have to do 
> with the fact
> that my function is a wrapper for my Fortran code (which 
> works fine on its
> own.. and if I use a loop as opposed to lapply() )?  I 
> imagine that lapply
> which is a wrapper for the .Internal lapply might have some 
> trouble with
> my Fortran wrapper?  Is this the case or is it something dumb 
> on my end?  
> Any input is appreciated.
> 
> Cheers,
> Jason
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From dominique.couturier at unine.ch  Wed Feb 11 14:02:08 2004
From: dominique.couturier at unine.ch (~ DLC ~)
Date: Wed, 11 Feb 2004 14:02:08 +0100
Subject: [R] Any help with bootstrapping
In-Reply-To: <000001c3f090$63b132e0$c9040a0a@Ivone1>
References: <000001c3f090$63b132e0$c9040a0a@Ivone1>
Message-ID: <7FBE6632-5C92-11D8-BCFB-0003931DD6AE@unine.ch>

hello,
The distribution of your t* seems so asymmetric that the correction for 
the acceleration is big and extreme t* are selected as critical values 
of your CI. As BCa CI have the propriety of transformation invariance, 
a transformation of the scale makes no sense. (you could choose 
transformed bootstrap-t CI).
One possibility to avoid your problem with BCa Ci is to increase R, the 
number of replications. Try 1500 or more...
hope this help,
dlc

> Could someone help me on how to correctly try to correct this error
> message
>
> arning : BCa Intervals used Extreme Quantiles
> Some BCa intervals may be unstable
> Warning message:
> Extreme Order Statistics used as Endpoints in: norm.inter(t, adj.alpha)
>
> Regards
> IF
>



From ligges at statistik.uni-dortmund.de  Wed Feb 11 14:02:58 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 11 Feb 2004 14:02:58 +0100
Subject: [R] Comment: R patterns
In-Reply-To: <Pine.LNX.4.55.0402110646320.25568@l1>
References: <Pine.LNX.4.55.0402110646320.25568@l1>
Message-ID: <402A2802.4020809@statistik.uni-dortmund.de>

Al Piszcz wrote:

> A number of the threads that occur in this mail list
> are excellent descriptions of usage patterns with R.
> 
> Is anyone developing a catalog of these?
> 
> The recent 'try' thread and many others are examples that may
> have value as a separate document or to be merged with
> the package help documentation.

Paul Johnson has collected many answers. Also, there are the searchable 
  mailing list archives (made easily searchable by John Baron) where the 
threads are stored.

Uwe Ligges



> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Wed Feb 11 14:01:49 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 11 Feb 2004 08:01:49 -0500
Subject: [R] RGui (Windows) crashes after use of a Salford Fortran
 DLL
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7780@usrymx25.merck.com>

My suggestion would be to make sure that your code works with the
recommended compilers, and that the problem is not in your code.  (This is
harder than you might think:  I recently found a bug in a Fortran subroutine
that crashes R _only_ if I use the latest GCC _and_ turn on optimization.)

Andy

> From: Steve Roberts
> 
> Anybody out there successfully using the Salford Fortran compilers 
> with R? 
> 
> I have created a DLL using the Salford FTN95 compiler and it works 
> in as far I can dyn.load it, run the routines and get the  right 
> answers back. Unfortunately subsequently, sometime later, the 
> Rgui crashes (access violation I think from the DrWatson log). The 
> crashes depend on whether or not I paste the code as one big 
> chunk, or as little chunks, and sometimes I can do a few things 
> before it crashes and other times not - but if I do exactly the same 
> things the crashes are reproducible. The crashes are sometimes in 
> the DLL and sometimes in pure R code. R1.7.1 and 1.8.1 seem to 
> behave identically. Windows 2000 Pro.
> 
> I do get the dyn.load warning about the DLL changing the FPU 
> control word.
> 
> Does this ring any bells with anyone?
> 
> Steve.
> 
>   Dr Steve Roberts 
>   steve.roberts at man.ac.uk
> 
> Senior Lecturer in Medical Statistics,
> CMMCH NHS Trust and University of Manchester Biostatistics Group,
> 0161 275 5192 / 0161 276 5785
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ligges at statistik.uni-dortmund.de  Wed Feb 11 14:05:30 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 11 Feb 2004 14:05:30 +0100
Subject: [R] Bhat: installation problem
In-Reply-To: <1076500324.402a1764510b4@orogeno.ija.csic.es>
References: <1076500324.402a1764510b4@orogeno.ija.csic.es>
Message-ID: <402A289A.8030805@statistik.uni-dortmund.de>

Agustin.Lobo at ija.csic.es wrote:

> Hi!
> 
> I'm trying to install package Bhat on
> a Win machine, had a problem and figured out
> a fix, but would like to report the
> problem and make sure the fix is correct. This is what I do:
> 1. Download Bhat_0.9-07.tar.gz
> 2. Uncompress it and compress it back to Bhat_0.9-07.zip
> 3. Install from the R windows gui (that
> apparentely requires the zip compression and cannot 
> deal with the tar.gz)
> 
> But when I type
> library(Bhat)
> 
> I get:
> 
> Error in testRversion(descfirlds): This package has not been installed
> properly. See Note in ?library
> 
> There it says that a "Built:" field should exist in DESCRIPTION.
> As it is not there, I've copied a Built field from another
> package and now library(Bhat) seems to work. But, is this
> fix correct?
> 
> Thanks for any help on this,
> 
> Agus


You have installed a source package instead of a binary package.

Just
  install.packages("Bhat")
should work and install the correct package from CRAN.

Please read the R for Windows FAQ re package installation, the R 
Installation and Administration manual, and you might also be interested 
in the recent R News' Help Desk article.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Wed Feb 11 14:11:20 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 11 Feb 2004 14:11:20 +0100
Subject: [R] RGui (Windows) crashes after use of a Salford Fortran DLL
In-Reply-To: <402A125A.22585.B50464@localhost>
References: <402A125A.22585.B50464@localhost>
Message-ID: <402A29F8.70605@statistik.uni-dortmund.de>

Steve Roberts wrote:

> Anybody out there successfully using the Salford Fortran compilers 
> with R? 
> 
> I have created a DLL using the Salford FTN95 compiler and it works 
> in as far I can dyn.load it, run the routines and get the  right 
> answers back. Unfortunately subsequently, sometime later, the 
> Rgui crashes (access violation I think from the DrWatson log). The 
> crashes depend on whether or not I paste the code as one big 
> chunk, or as little chunks, and sometimes I can do a few things 
> before it crashes and other times not - but if I do exactly the same 
> things the crashes are reproducible. The crashes are sometimes in 
> the DLL and sometimes in pure R code. R1.7.1 and 1.8.1 seem to 
> behave identically. Windows 2000 Pro.
> 
> I do get the dyn.load warning about the DLL changing the FPU 
> control word.
> 
> Does this ring any bells with anyone?

Duncan Murdoch has collected some notes on different compiler issues on 
Windows (don't know whether Salford FTN95 is among them). Nevertheless, 
it is recommended to use the MinGW port of the gcc compiler with R.

Uwe Ligges



> Steve.
> 
>   Dr Steve Roberts 
>   steve.roberts at man.ac.uk
> 
> Senior Lecturer in Medical Statistics,
> CMMCH NHS Trust and University of Manchester Biostatistics Group,
> 0161 275 5192 / 0161 276 5785
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From wolski at molgen.mpg.de  Wed Feb 11 14:13:04 2004
From: wolski at molgen.mpg.de (wolski)
Date: Wed, 11 Feb 2004 14:13:04 +0100
Subject: [R] .Call setAttrib(ans,R_DimSymbol,dim); Crashes.
Message-ID: <200402111413040019.04546ED8@harry.molgen.mpg.de>

 Hi!


I want to return a matrix. 
The code does the R interfacing.
This version does it fine.

  SEXP ans,dim;
  PROTECT(ans = NEW_NUMERIC(count*2));
  memcpy(NUMERIC_POINTER(ans),result,count*sizeof(double));
  memcpy(&(NUMERIC_POINTER(ans)[count]),occur,count*sizeof(double));
/**  PROTECT(dim=NEW_INTEGER(2));
    INTEGER_POINTER(dim)[0]=2;
   INTEGER_POINTER(dim)[1]=count; 
   setAttrib(ans,R_DimSymbol,dim); 
*/
  UNPROTECT(7);

If I uncomment the lines 5 to 8 than all is working fine four small count's (tested 10,20).
But if the result is an array with about 2000 entries R crashes vicious and violently with the lax comment

Process R trace trap at Wed Feb 11 13:55:45 2004

Anyone is seeiing something what I can not see?

Sincerely Eryk.
Windows 2000
R 1.8.1



From ligges at statistik.uni-dortmund.de  Wed Feb 11 14:14:35 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 11 Feb 2004 14:14:35 +0100
Subject: [R] Erro in loadNamespace
In-Reply-To: <1076502684.31409.5.camel@snowdon.science.uva.nl>
References: <1076502684.31409.5.camel@snowdon.science.uva.nl>
Message-ID: <402A2ABB.3040900@statistik.uni-dortmund.de>

Ulrich Leopold wrote:

> Dear list,
> 
> Iget the following error message:
> 
> 
>>help.search("omit.na")
> 
> Error in loadNamespace(name) : package 'tools' does not have a name
> space
> 
> I do not quite understand what it means in this case. Is something
> corrupt in the installation?
> 
> I run R-1.8.1 in Linux RedHat 9 with kernel 2.6.2 on Intel P4.
> 
> Regards, Ulrich


Does not happen with the released (unpatched) version of R-1.8.1 for me 
(neither on Windows nor Solaris). So it looks like a broken installation.

Since "tools" has got a namespace, I guess at least this package's 
installation is broken.

So my suggestion is to reinstall R.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Wed Feb 11 14:17:08 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 11 Feb 2004 14:17:08 +0100
Subject: [R] Any help with bootstrapping
In-Reply-To: <000001c3f090$63b132e0$c9040a0a@Ivone1>
References: <000001c3f090$63b132e0$c9040a0a@Ivone1>
Message-ID: <402A2B54.80004@statistik.uni-dortmund.de>

Ivone Figueiredo wrote:

> Could someone help me on how to correctly try to correct this error
> message
>  
> arning : BCa Intervals used Extreme Quantiles
> Some BCa intervals may be unstable
> Warning message: 
> Extreme Order Statistics used as Endpoints in: norm.inter(t, adj.alpha)
>  
> Regards
> IF

Note that this is not an error, but a "just" warning. Can we assume you 
used boot() from package "boot"?

Uwe Ligges



From rpeng at jhsph.edu  Wed Feb 11 14:19:19 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 11 Feb 2004 08:19:19 -0500
Subject: [R] Any help with bootstrapping
In-Reply-To: <000001c3f090$63b132e0$c9040a0a@Ivone1>
References: <000001c3f090$63b132e0$c9040a0a@Ivone1>
Message-ID: <402A2BD7.3050508@jhsph.edu>

This is not an error.  It is a warning.  I sometimes get it when there 
are aren't enough data or there aren't enough bootstrap iterations.

-roger

Ivone Figueiredo wrote:
> Could someone help me on how to correctly try to correct this error
> message
>  
> arning : BCa Intervals used Extreme Quantiles
> Some BCa intervals may be unstable
> Warning message: 
> Extreme Order Statistics used as Endpoints in: norm.inter(t, adj.alpha)
>  
> Regards
> IF
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Wed Feb 11 14:21:28 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 11 Feb 2004 14:21:28 +0100
Subject: [R] interfacing C code in Windows
In-Reply-To: <4028FF0C.3090006@avignon.inra.fr>
References: <4028FF0C.3090006@avignon.inra.fr>
Message-ID: <402A2C58.4000401@statistik.uni-dortmund.de>

Peyrard Nathalie wrote:

> Hi,
> 
> I know how to incorporate C code in R if using Linux. Can someone 
> explain me how to do the same using Windows (if it is possible)?

The same as under Linux, in principle.

See the "Writing R Extensions" , the R for Windows FAQs, and in 
particular the file
.../src/gnuwin32/readme.packages for a list and description on (how to 
get) the required tools and compilers.

Uwe Ligges



> Thanks
> 
> Nathalie Peyrard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ccleland at optonline.net  Wed Feb 11 14:34:51 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 11 Feb 2004 08:34:51 -0500
Subject: [R] large fonts on plots
In-Reply-To: <opr27g0whfgzo14j@mach.vub.ac.be>
References: <opr27g0whfgzo14j@mach.vub.ac.be>
Message-ID: <402A2F7B.20706@optonline.net>

Piet van Remortel wrote:
> I need to enlarge te fonts used oo R-plots (plots, histograms, ...) in 
> labels and titles etc.
> 
> I seem to be unable to figure out how to do it.    The problem is that 
> the titles of the plots are simply unreadable when I insert them into my 
> LaTeX text, since they are relatively small compared to the entire plot.

Does this help?

  par(mar=c(10,10,10,10), cex.axis=2, cex.lab=2, cex.main=4)
  plot(runif(20))
  title("Main Title")

see ?par

Chuck Cleland

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ahmlatif at yahoo.com  Wed Feb 11 14:35:36 2004
From: ahmlatif at yahoo.com (Mahbub Latif)
Date: Wed, 11 Feb 2004 05:35:36 -0800 (PST)
Subject: [R] large fonts on plots
In-Reply-To: <opr27g0whfgzo14j@mach.vub.ac.be>
Message-ID: <20040211133536.21000.qmail@web41209.mail.yahoo.com>

see ?par

Mahbub.
--- Piet van Remortel <pvremort at vub.ac.be> wrote:
> Hi all,
> 
> I need to enlarge te fonts used oo R-plots (plots,
> histograms, ...) in 
> labels and titles etc.
> 
> I seem to be unable to figure out how to do it.   
> The problem is that the 
> titles of the plots are simply unreadable when I
> insert them into my LaTeX 
> text, since they are relatively small compared to
> the entire plot.
> 
> I am sure it is pretty simple, can anybody give me a
> hint ?
> 
> Please reply to:  pvremortNOSPAM at vub.ac.be
> 
> 
> Thanks,
> 
> 
> Piet
> 
> 
> -- 
> Piet van Remortel
> PhD Student
> pvremort at vub.ac.be
> http://como.vub.ac.be/Members/Piet.htm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From petr.pikal at precheza.cz  Wed Feb 11 15:06:59 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 11 Feb 2004 15:06:59 +0100
Subject: [R] large fonts on plots
In-Reply-To: <opr27g0whfgzo14j@mach.vub.ac.be>
Message-ID: <402A4513.1264.C05D9B@localhost>


Hallo

On 11 Feb 2004 at 13:30, Piet van Remortel wrote:

> Hi all,
> 
> I need to enlarge te fonts used oo R-plots (plots, histograms, ...) in
> labels and titles etc.

using cex.main=some.number.greater.than.1 in 
title(...) 
will enlarge fonts in main title.

follow  ?par, ?title, ?axis


However I do not know if it works when inserting figures to LaTeX text.

Cheers
Petr

> 
> I seem to be unable to figure out how to do it.    The problem is that
> the titles of the plots are simply unreadable when I insert them into
> my LaTeX text, since they are relatively small compared to the entire
> plot.
> 
> I am sure it is pretty simple, can anybody give me a hint ?
> 
> Please reply to:  pvremortNOSPAM at vub.ac.be
> 
> 
> Thanks,
> 
> 
> Piet
> 
> 
> -- 
> Piet van Remortel
> PhD Student
> pvremort at vub.ac.be
> http://como.vub.ac.be/Members/Piet.htm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ligges at statistik.uni-dortmund.de  Wed Feb 11 15:12:11 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 11 Feb 2004 15:12:11 +0100
Subject: [R] large fonts on plots
In-Reply-To: <opr27g0whfgzo14j@mach.vub.ac.be>
References: <opr27g0whfgzo14j@mach.vub.ac.be>
Message-ID: <402A383B.9070804@statistik.uni-dortmund.de>

Piet van Remortel wrote:

> Hi all,
> 
> I need to enlarge te fonts used oo R-plots (plots, histograms, ...) in 
> labels and titles etc.
> 
> I seem to be unable to figure out how to do it.    The problem is that 
> the titles of the plots are simply unreadable when I insert them into my 
> LaTeX text, since they are relatively small compared to the entire plot.
> 
> I am sure it is pretty simple, can anybody give me a hint ?
> 
> Please reply to:  pvremortNOSPAM at vub.ac.be
> 
> 
> Thanks,
> 
> 
> Piet
> 
> 

See ?par

Uwe Ligges



From dmurdoch at pair.com  Wed Feb 11 15:11:34 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 11 Feb 2004 09:11:34 -0500
Subject: [R] RGui (Windows) crashes after use of a Salford Fortran DLL
In-Reply-To: <402A125A.22585.B50464@localhost>
References: <402A125A.22585.B50464@localhost>
Message-ID: <2ldk201adl81lbu9etle4hk1h44ua8r27b@4ax.com>

On Wed, 11 Feb 2004 11:30:35 +0000, "Steve Roberts"
<steve.roberts at man.ac.uk> wrote :

>Anybody out there successfully using the Salford Fortran compilers 
>with R? 
>
>I have created a DLL using the Salford FTN95 compiler and it works 
>in as far I can dyn.load it, run the routines and get the  right 
>answers back. Unfortunately subsequently, sometime later, the 
>Rgui crashes (access violation I think from the DrWatson log). The 
>crashes depend on whether or not I paste the code as one big 
>chunk, or as little chunks, and sometimes I can do a few things 
>before it crashes and other times not - but if I do exactly the same 
>things the crashes are reproducible. The crashes are sometimes in 
>the DLL and sometimes in pure R code. R1.7.1 and 1.8.1 seem to 
>behave identically. Windows 2000 Pro.
>
>I do get the dyn.load warning about the DLL changing the FPU 
>control word.
>
>Does this ring any bells with anyone?

A reproducible crash sometime later sounds to me like memory
corruption.  I'd guess the crash occurs at the next garbage
collection; something has happened to mess up the internal memory
structures, so R goes down.

You can call gc() to trigger a garbage collection just after your call
to your DLL; that's likely to trigger the crash if my guess is right.
Fixing it will be harder:  you need to find why your DLL is writing in
someone else's memory space.  Perhaps make your arrays larger than
necessary, and check that values that weren't supposed to be touched
stay untouched?

Regarding the FPU control word:  general instructions to fix this bug
in your DLL are given on my web page
<http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs/>. If
there's anything special about the Salford compiler that needs
mentioning there, please write it up and send it to me.

Duncan Murdoch



From ligges at statistik.uni-dortmund.de  Wed Feb 11 15:14:15 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 11 Feb 2004 15:14:15 +0100
Subject: [R] how to get the GUI directory chooser on Windows?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7776@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7776@usrymx25.merck.com>
Message-ID: <402A38B7.2070505@statistik.uni-dortmund.de>

Liaw, Andy wrote:

> Dear R-help,
> 
> Can anyone tell me if it's possible to call up the "directory chooser" (the
> one you get when you click on "File" -> "Change Dir...") in Rgui from the R
> command line?  Seems like file.choose() can't be used to choose a directory.

Looks like there is no R function to do so.

The C level code is in
./src/gnuwin32/rui.c
and
./src/gnuwin32/graphapp/dialogs.c
and friends.

Uwe Ligges


> This is in R-1.8.1 on WinXPPro.
> 
> Any help much appreciated!
> 
> Andy
> 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments,...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dmurdoch at pair.com  Wed Feb 11 15:20:10 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 11 Feb 2004 09:20:10 -0500
Subject: [R] large fonts on plots
In-Reply-To: <opr27g0whfgzo14j@mach.vub.ac.be>
References: <opr27g0whfgzo14j@mach.vub.ac.be>
Message-ID: <d3ek201brc62oir5ag3fpci2sbj2egefra@4ax.com>

On Wed, 11 Feb 2004 13:30:22 +0100, Piet van Remortel
<pvremort at vub.ac.be> wrote :

>Hi all,
>
>I need to enlarge te fonts used oo R-plots (plots, histograms, ...) in 
>labels and titles etc.
>
>I seem to be unable to figure out how to do it.    The problem is that the 
>titles of the plots are simply unreadable when I insert them into my LaTeX 
>text, since they are relatively small compared to the entire plot.
>
>I am sure it is pretty simple, can anybody give me a hint ?
>
>Please reply to:  pvremortNOSPAM at vub.ac.be

You probably want to use the cex arguments, e.g.

plot(rnorm(10),rnorm(10), cex.axis=1.5, cex.lab=1.5, cex=1.5)

You might need to make the figure margins bigger to have space for the
big labels.  

?par documents all of these options (except cex, which is documented
in ?plot.default, I think).

Duncan Murdoch



From datkins at u.washington.edu  Wed Feb 11 14:51:15 2004
From: datkins at u.washington.edu (Dave Atkins)
Date: Wed, 11 Feb 2004 05:51:15 -0800
Subject: [R] Re: Clinical Significance as a package
In-Reply-To: <200402111137.i1BBb4wj018987@hypatia.math.ethz.ch>
References: <200402111137.i1BBb4wj018987@hypatia.math.ethz.ch>
Message-ID: <402A3353.5020403@u.washington.edu>


Alistair--

I wrote functions to calculate Clinical Significance in Splus for the 
following article:

McGlinchey, J. B., Atkins, D. C., & Jacobson, N. S. (2002).  Clinical 
significance methods: Which one to use and how useful are they? 
Behavior Therapy, 33, 529-550.

I will send the functions to you back-channel.

cheers, Dave

-- 
Dave Atkins, PhD
Assistant Professor in Clinical Psychology
Travis Research Institute
Fuller Theological Seminary
Email: datkins at fuller.edu


Message: 43
Date: Wed, 11 Feb 2004 10:15:31 +1000
From: "Alistair Campbell" <alistair.campbell at jcu.edu.au>
Subject: [R] Clinical significance as a package?
To: <r-help at stat.math.ethz.ch>
Message-ID: <000d01c3f034$28e27040$691edb89 at alistaircampbel>
Content-Type: text/plain

Hi,

Many thanks to those of you who responded to my last post about
Schafer's MI packages. I am really pleased to have access to them
through R which, I have to say, is an amazing piece of software. I am
only sorry that I haven't found it until now.

But, to my question. Does anyone know if there is a package developed
for evaluating clinical significance using Jacobson and Truax's, or
variations thereof, procedures?

Cheers

Alistair Campbell
School of Psychology
James Cook University
Townsville QLD



From mcardeal at ufba.br  Wed Feb 11 15:49:00 2004
From: mcardeal at ufba.br (Mauricio Cardeal)
Date: Wed, 11 Feb 2004 11:49:00 -0300
Subject: [R] proportions
References: <3A822319EB35174CA3714066D590DCD504AF777F@usrymx25.merck.com>
Message-ID: <007801c3f0ae$2f89c680$5234a8c0@mcardeal>

Hi all:

Please be patient with my silly question:

How can I get proportions if I have a contingency table ? 

I tried the table command, but I almost sure I made my usual mistakes.

Thaks

Mauricio



From Lennart.Borgman at astrazeneca.com  Wed Feb 11 17:24:44 2004
From: Lennart.Borgman at astrazeneca.com (Lennart.Borgman@astrazeneca.com)
Date: Wed, 11 Feb 2004 17:24:44 +0100
Subject: [R] The ttest.c example in R under MS Windows
Message-ID: <26D5AB9F6512D611A8610001FA7E136F032783B9@se-drc-mail4.selu.astrazeneca.net>

Thank you Andy, and thank you to all others who responded. 

I downloaded the tools and the compiler (though I used MSYS from the MINGW
site, which seems to have the desired tools). From the bash shell that comes
with MSYS I ran the commands in readme.packages:

    $ cd R_HOME/src/gnuwin32
    $ make libR.a libRblas.a

They seemed to work fine. Then I believe I am missing something crucial. I
found a directory windlgs in the C:\Program Files\R\rw1081\src\library
directory. So I cd-ed to this and tried to run the install command (again
from the bash shell where the tools are in the path):

    $ rcmd install windlgs

    make: *** No rule to make target `Files/R/rw1081/src/library'.  Stop.
    *** Installation of windlgs failed ***

What is missing here?

- Lennart


-----Original Message-----
From: Liaw, Andy [mailto:andy_liaw at merck.com]
Sent: 10 februari 2004 15:57
To: Borgman, Lennart; r-help at stat.math.ethz.ch
Subject: RE: [R] The ttest.c example in R under MS Windows


Works just fine for me with the recommended compilers and tools.  Here's a
transcript of the build:

c:\tools\R-1.8.1\src\gnuwin32>Rcmd install windlgs


---------- Making package windlgs ------------
  adding build stamp to DESCRIPTION
  making DLL ...
making ttest.d from ttest.c
gcc   -Ic:/tools/R-1.8.1/src/include -Wall -O2
-Ic:/tools/R-1.8.1/src/gnuwin32/
graphapp  -c ttest.c -o ttest.o
ar cr windlgs.a *.o
ranlib windlgs.a
windres --include-dir c:/tools/R-1.8.1/src/include  -i windlgs_res.rc -o
windlgs
_res.o
gcc  --shared -s  -o windlgs.dll windlgs.def windlgs.a windlgs_res.o
-Lc:/tools
/R-1.8.1/src/gnuwin32  -lg2c -lR
  ... DLL made
  installing DLL
  installing R files
  installing man source files
  installing indices
  installing help
 >>> Building/Updating help pages for package 'windlgs'
     Formats: text html latex example
  menu.ttest                        text    html    latex   example
 >>> Building/Updating help pages for package 'windlgs'
     Formats: chm
  menu.ttest                                                        chm
Microsoft HTML Help Compiler 4.74.8702

Compiling c:\tools\R-1.8.1\src\gnuwin32\windlgs\chm\windlgs.chm


Compile time: 0 minutes, 2 seconds
2       Topics
4       Local links
0       Internet links
1       Graphic


Created c:\tools\R-1.8.1\src\gnuwin32\windlgs\chm\windlgs.chm, 22,531 bytes
Compression increased file by 8,709 bytes.
  adding MD5 sums


And here's the test:
> library(windlgs)
To remove the Statistics menu use del.ttest()
> x <- runif(10)
> y <- runif(20)
[click on `Statistics' from the menu, choose `ttest:1' and fill in.]
> menu.ttest()

        Welch Two Sample t-test

data:  x and y 
t = 2.1473, df = 22.03, p-value = 0.04303
alternative hypothesis: true difference in means is not equal to 0 
95 percent confidence interval:
 0.007352435 0.422008138 
sample estimates:
mean of x mean of y 
0.6706490 0.4559688 

Andy


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Lennart.Borgman at astrazeneca.com
> Sent: Tuesday, February 10, 2004 8:27 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] The ttest.c example in R under MS Windows
> 
> 
> We are trying to compile and run the ttest.c example that 
> comes with R (in
> C:\Program Files\R\rw1081\src\library\windlgs\src\ttest.c). 
> After compiling
> it with MS Visual C++ we load the DLL with dyn.load. 
> 
> So far it seems good, but when we try to call it from R (after running
> C:\Program Files\R\rw1081\src\library\windlgs\R\windlgs.R) R crashes.
> 
> We have tried changing the exports from DLL but have failed 
> so far. Since I
> have a guy helping me who is fluent in MS Visual C++ I believe we are
> missing something crucial. Have anyone compiled and used the 
> example above
> using MS Visual C++? Has anyone done this using the gcc (or 
> Mingw) compiler
> on MS Windows?
> 
> I would be very glad to find a complete example for compiling under MS
> Windows.
> 
> 
> - Lennart
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


----------------------------------------------------------------------------
--
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From marcos.sanches at ipsos-opinion.com.br  Wed Feb 11 18:53:33 2004
From: marcos.sanches at ipsos-opinion.com.br (Marcos Sanches)
Date: Wed, 11 Feb 2004 14:53:33 -0300
Subject: [R] AGREP
Message-ID: <000701c3f0c7$f7497350$d297a8c0@opinionserver>


	Hi all, I have two questions

1 - I have the version 1.4.1 of R, and it doesn't have the 'agrep'
function in the base library. Is there a way to make this funcion
avaliable in R 1.4.1? I mean, how to 'copy' it from R 1.8.1 and 'paste'
it in R 1.4.1?

2 - The AGREP function doesn't give me the Levenshtein distance (edit
distance). Is there a function in R that does it? Is there a way to use
AGREP to acomplish this task? I've written such a function, but it is so
slow (has so many loops) that it is beeing useless. 

TIA



From song.baiyi at udo.edu  Wed Feb 11 18:33:48 2004
From: song.baiyi at udo.edu (Song Baiyi)
Date: Wed, 11 Feb 2004 18:33:48 +0100
Subject: [R] About the macro defined in Rinternals.h
Message-ID: <402A677C.8060805@udo.edu>

Hello everyone,

I try to  write a c++ code which calls embedded R and uses some of R 
internal functions. What I read is just lots of macro names defined in 
the Rinternals.h or Rdefines like R_Parse, Rf_install and so on. But 
where can I get the detailed information about the parameters of these 
macro?  For example, what about the parameters of  SEXP 
R_ParseVector(SEXP, int, ParseStatus *)?

Thank you very much!

Baiyi Song
Computer Engineering Institute
Dortmund Univercity



From bates at stat.wisc.edu  Wed Feb 11 18:58:51 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 Feb 2004 11:58:51 -0600
Subject: [R] .Call setAttrib(ans,R_DimSymbol,dim); Crashes.
In-Reply-To: <200402111413040019.04546ED8@harry.molgen.mpg.de>
References: <200402111413040019.04546ED8@harry.molgen.mpg.de>
Message-ID: <6rsmhhcxb8.fsf@bates4.stat.wisc.edu>

"wolski" <wolski at molgen.mpg.de> writes:

> I want to return a matrix. The code does the R interfacing.  This
> version does it fine.
> 
>   SEXP ans,dim;
>   PROTECT(ans = NEW_NUMERIC(count*2));
>   memcpy(NUMERIC_POINTER(ans),result,count*sizeof(double));
>   memcpy(&(NUMERIC_POINTER(ans)[count]),occur,count*sizeof(double));
> /**  PROTECT(dim=NEW_INTEGER(2));
>     INTEGER_POINTER(dim)[0]=2;
>    INTEGER_POINTER(dim)[1]=count; 
>    setAttrib(ans,R_DimSymbol,dim); 
> */
>   UNPROTECT(7);
> 
> If I uncomment the lines 5 to 8 than all is working fine four small
> count's (tested 10,20).  But if the result is an array with about
> 2000 entries R crashes vicious and violently with the lax comment
> 
> Process R trace trap at Wed Feb 11 13:55:45 2004
> 
> Anyone is seeiing something what I can not see?

In most cases it is easier to use allocMatrix instead of assigning a
dimension attribute to a numeric vector.  You could write this as

   SEXP ans = PROTECT(allocMatrix(REALSXP, 2, count));
   memcpy(NUMERIC_POINTER(ans),result,count*sizeof(double));
   memcpy(&(NUMERIC_POINTER(ans)[count]),occur,count*sizeof(double));
   UNPROTECT(1);

Another enhancement is use Memcpy, as in

   SEXP ans = PROTECT(allocMatrix(REALSXP, 2, count));
   double *ansp = REAL(ans);    /* same as NUMERIC_POINTER(ans) */

   Memcpy(ansp, result, count);
   Memcpy(ansp + count, occur, count);
   UNPROTECT(1);

Regarding your particular problem, did you happen to change the
argument to UNPROTECT when you changed the code?  You may be getting a
stack imbalance if you change the number of PROTECTs that are executed
and don't change the UNPROTECT count.

This is why I generally try to write C functions with only one PROTECT
in then.  Because PROTECTing an object also PROTECTs all components
reachable from that object I allocate other storage as components of
the (PROTECT'ed) result then manipulate those components.  For
example, if I don't use allocMatrix I would write what you did as

   SEXP ans = PROTECT(NEW_NUMERIC(count * 2));
   double *ansp = NUMERIC_POINTER(ans);
   int *dims;

   Memcpy(ansp, result, count);
   Memcpy(ansp + count, occur, count);
   setAttrib(ans, R_DimSymbol, NEW_INTEGER(2));
   dims = INTEGER_POINTER(getAttrib(ans, R_DimSymbol));
   dims[0] = 2;
   dims[1] = count;
   UNPROTECT(1);

It is a matter of taste whether you prefer to assign the component
then select it or to allocate the component by itself and remember to
PROTECT and UNPROTECT it.  Both are a bit tedious but I find the
former to be less error-prone.

If you look at the C sources for the new Matrix_0.6 package (in the
1.9 contributed section on CRAN) you will see that just about every C
function that returns an SEXP ends with

   UNPROTECT(1);
   return ans;

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From JSweval at illumigen.com  Wed Feb 11 19:00:15 2004
From: JSweval at illumigen.com (John Sweval)
Date: Wed, 11 Feb 2004 10:00:15 -0800
Subject: [R] 64-bit Windows 2003 build of R
Message-ID: <E4E4C6B0D39DAC4CAA15D09B594DD98C3C965A@exon.illumigen.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040211/480d4e6b/attachment.pl

From FWS4 at CDRH.FDA.GOV  Wed Feb 11 19:51:06 2004
From: FWS4 at CDRH.FDA.GOV (Samuelson, Frank*)
Date: Wed, 11 Feb 2004 13:51:06 -0500
Subject: [R] how much memory?  was: R does in memory analysis only?
Message-ID: <644D9337A02FC24689647BF9E48EC39E08ABB767@drm556>

Is there a way to tell how much memory the computer
running R has?

-Frank


-----Original Message-----
From: David Smith [mailto:dsmith at insightful.com] 
Sent: Monday, February 09, 2004 1:32 PM
To: Ross Boylan
Cc: r-help
Subject: RE: [R] R does in memory analysis only?


Ross Boylan writes:
> R works only on problems that fit into (real or virtual) memory.
> ... does S-Plus have the same limitation?

S-PLUS, like R, does its computations in-memory. So you're limited to
solving
problems which can fit in the available RAM (plus available swap space).
The
OS may impose additional limits (e.g. 2GB of total address space on many
Windows systems).

However, Insightful Miner, which works with S-PLUS, does include algorithms
which can process data sets out of memory. This includes the ability to
perform regressions on data sets much larger than the available RAM (the
only
limit is the availability of disk space to store the results).  You can also
link S-PLUS with Insightful to perform out-of-memory calculations using
S-PLUS functions.  This works especially well with operations like
predicting
from a model, which can be performed on a row-by-row basis.

I wrote a long discussion about in-memory and out-of-memory algorithms in
the
context of S-PLUS and Insightful Miner, which you can download from:

http://www.insightful.com/support/whitepaper_download.asp

# David Smith

-- 
David M Smith <dsmith at insightful.com>
Product Manager, Insightful Corp, Seattle WA
Tel: +1 (206) 802 2360
Fax: +1 (206) 283 6310

New Insightful Miner 3! Discover how Pfizer, Bank of America and others are
using Insightful Miner -- a highly scalable data analysis workbench. Learn
more at http://www.insightful.com/products/iminer

> -----Original Message-----
> From: Ross Boylan [mailto:ross at biostat.ucsf.edu]
> Sent: Saturday, February 07, 2004 2:16 PM
> To: r-help
> Subject: [R] R does in memory analysis only?
> 
> 
> I wonder if someone would confirm something I'm 99% sure of from the
> docs and discussion on the list, but can't find stated explicitly:
> R works only on problems that fit into (real or virtual) memory.
> 
> Thus, even if you have a problem (e.g., simple regression) 
> that could be
> solved by doing some operation on each row of a dataset at a time, you
> can't solve it unless the entire dataset and associated intermediate
> results fit in memory.
> 
> So if you're in 32 bits, your max problem size is about 2G (regular
> Windows and Linux limit your process size to this, though I think some
> fancy versions let you go a bit higher).
> 
> Is there any thought of relaxing this limitation?  I realize doing so
> would be a big job.  I also realize that 64 bits makes it much less
> pressing.
> 
> Finally, does S-Plus have the same limitation?
> 
> Thanks.
> -- 
> Ross Boylan                                      wk:  (415) 502-4031
> 530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
> Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
> University of California, San Francisco
> San Francisco, CA 94143-0840                     hm:  (415) 550-1062
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From itayf at fhcrc.org  Wed Feb 11 20:00:24 2004
From: itayf at fhcrc.org (Itay Furman)
Date: Wed, 11 Feb 2004 11:00:24 -0800 (PST)
Subject: [R] large fonts on plots
In-Reply-To: <402A4513.1264.C05D9B@localhost>
Message-ID: <Pine.LNX.4.44.0402111054500.5352-100000@cezanne.fhcrc.org>


On Wed, 11 Feb 2004, Petr Pikal wrote:

> On 11 Feb 2004 at 13:30, Piet van Remortel wrote:
> 
> > Hi all,
> > 
> > I need to enlarge te fonts used oo R-plots (plots, histograms, ...) in
> > labels and titles etc.
> 
> using cex.main=some.number.greater.than.1 in 
> title(...) 
> will enlarge fonts in main title.
> 

>From my experience you will have to enlarge also the plot 
margins, otherwise label/s might be clipped out. See par() for 
margin handling.

> However I do not know if it works when inserting figures to LaTeX text.
> 

It works fine.

	Cheers,
	Itay Furman

--
itayf at fhcrc.org			Fred Hutchinson Cancer Research Center



From MSchwartz at medanalytics.com  Wed Feb 11 20:11:21 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 11 Feb 2004 13:11:21 -0600
Subject: [R] proportions
In-Reply-To: <007801c3f0ae$2f89c680$5234a8c0@mcardeal>
References: <3A822319EB35174CA3714066D590DCD504AF777F@usrymx25.merck.com>
	<007801c3f0ae$2f89c680$5234a8c0@mcardeal>
Message-ID: <1076526681.25682.202.camel@localhost.localdomain>

On Wed, 2004-02-11 at 08:49, Mauricio Cardeal wrote:
> Hi all:
> 
> Please be patient with my silly question:
> 
> How can I get proportions if I have a contingency table ? 
> 
> I tried the table command, but I almost sure I made my usual mistakes.
> 
> Thaks
> 
> Mauricio


See ?prop.table

HTH,

Marc Schwartz



From stecalza at tiscali.it  Wed Feb 11 20:33:55 2004
From: stecalza at tiscali.it (Stefano Calza)
Date: Wed, 11 Feb 2004 20:33:55 +0100
Subject: [R] proportions
In-Reply-To: <1076526681.25682.202.camel@localhost.localdomain>
References: <3A822319EB35174CA3714066D590DCD504AF777F@usrymx25.merck.com>
	<007801c3f0ae$2f89c680$5234a8c0@mcardeal>
	<1076526681.25682.202.camel@localhost.localdomain>
Message-ID: <20040211193355.GA2900@med.unibs.it>

Or look at CrossTable in package gregmisc (which actually uses prop.table) to get something like proc freq in SAS.

HIH,
Stefano

On Wed, Feb 11, 2004 at 01:11:21PM -0600, Marc Schwartz wrote:
> On Wed, 2004-02-11 at 08:49, Mauricio Cardeal wrote:
> > Hi all:
> > 
> > Please be patient with my silly question:
> > 
> > How can I get proportions if I have a contingency table ? 
> > 
> > I tried the table command, but I almost sure I made my usual mistakes.
> > 
> > Thaks
> > 
> > Mauricio
> 
> 
> See ?prop.table
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Wed Feb 11 20:29:40 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 11 Feb 2004 14:29:40 -0500
Subject: [R] how to get the GUI directory chooser on Windows?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7787@usrymx25.merck.com>

Thanks to Uwe and Duncan Murdoch (who replied off-list).  The bottom line is
as Uwe said: no existing R level functionality.

I guess it might be possible to do something similar with Tcl/Tk, but I do
not know Tcl/tk...

Best,
Andy

> From: Uwe Ligges
> 
> Liaw, Andy wrote:
> 
> > Dear R-help,
> > 
> > Can anyone tell me if it's possible to call up the 
> "directory chooser" (the
> > one you get when you click on "File" -> "Change Dir...") in 
> Rgui from the R
> > command line?  Seems like file.choose() can't be used to 
> choose a directory.
> 
> Looks like there is no R function to do so.
> 
> The C level code is in
> ./src/gnuwin32/rui.c
> and
> ./src/gnuwin32/graphapp/dialogs.c
> and friends.
> 
> Uwe Ligges
> 
> 
> > This is in R-1.8.1 on WinXPPro.
> > 
> > Any help much appreciated!
> > 
> > Andy
> > 
> > 
> > 
> > 
> --------------------------------------------------------------
> ----------------
> > Notice:  This e-mail message, together with any 
> attachments,...{{dropped}}
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From dmurdoch at pair.com  Wed Feb 11 20:31:38 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 11 Feb 2004 14:31:38 -0500
Subject: [R] The ttest.c example in R under MS Windows
In-Reply-To: <26D5AB9F6512D611A8610001FA7E136F032783B9@se-drc-mail4.selu.astrazeneca.net>
References: <26D5AB9F6512D611A8610001FA7E136F032783B9@se-drc-mail4.selu.astrazeneca.net>
Message-ID: <nm0l20p1n17032qt1rmknckbhdjk6n9bj6@4ax.com>

On Wed, 11 Feb 2004 17:24:44 +0100, Lennart.Borgman at astrazeneca.com
wrote :

>    $ rcmd install windlgs
>
>    make: *** No rule to make target `Files/R/rw1081/src/library'.  Stop.
>    *** Installation of windlgs failed ***
>
>What is missing here?

Some of the tools get confused by spaces in pathnames.  It's better to
put things in a path with no spaces in it.

Duncan Murdoch



From Icabalceta_j at wlf.state.la.us  Wed Feb 11 20:38:15 2004
From: Icabalceta_j at wlf.state.la.us (Icabalceta, Jorge L.)
Date: Wed, 11 Feb 2004 13:38:15 -0600
Subject: [R] gelman.diag question
Message-ID: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0B9@wlfnt1.wlf.state.la.us>

Dear Friends,
I am trying to use the gelman-rubin convergence test. I generated a matrix
samp[10,000x86] with the gibbs sampler. the test requires the creation of
"mcmc" objects. Since I don't know how to define samp as a "mcmc" object, I
tried to create one mcmc object by means of the mcmc() function. With this
function I tried to create a mcmc object dul from samp but I got the message
below. What am I doing wrong? 
> dim(samp)
[1] 10000    86
> dul<-mcmc(b1<-samp[,1],start=1, end=10000, thin=10)
Error in data[1:nobs, , drop = FALSE] : incorrect number of dimensions

Then, as described below,I tried other way to create the mcmc object  but I
get the message "Error in gelman.diag(dul3) : You need at least two chains".
I think I am not understanding how the Gelman-Rubin test works in R. Could
you give me a small example. 

> dul2<-mcmc(b1<-as.matrix(samp[,1]),start=1, end=10000, thin=10)
> dul3<-matrix(1000,2,c(dul,dul2))
> is.mcmc(dul3)
[1] FALSE
> dul3<-as.mcmc(dul3)
> is.mcmc(dul3)
[1] TRUE
> gelman.diag(dul3)
Error in gelman.diag(dul3) : You need at least two chains

I really appreciate your patience, help, and time,
Jorge



From bates at stat.wisc.edu  Wed Feb 11 20:52:28 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 Feb 2004 13:52:28 -0600
Subject: [R] About the macro defined in Rinternals.h
In-Reply-To: <402A677C.8060805@udo.edu>
References: <402A677C.8060805@udo.edu>
Message-ID: <6r1xp1cs1v.fsf@bates4.stat.wisc.edu>

Song Baiyi <song.baiyi at udo.edu> writes:

> I try to  write a c++ code which calls embedded R and uses some of R
> internal functions. What I read is just lots of macro names defined in
> the Rinternals.h or Rdefines like R_Parse, Rf_install and so on. But
> where can I get the detailed information about the parameters of these
> macro?  For example, what about the parameters of  SEXP
> R_ParseVector(SEXP, int, ParseStatus *)?

You can check in "Writing R Extensions" but, as always, the most
authorative documentation is the source.  Fortunately, R is an open
source project, which means that you can download the sources and
read them.

Note that we don't guarantee stability between releases except for
those routines that are documented as part of the API in the manual
"Writing R Extensions" (and sometimes not even for them :-) .



From bates at stat.wisc.edu  Wed Feb 11 21:07:42 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 Feb 2004 14:07:42 -0600
Subject: [R] .Call setAttrib(ans,R_DimSymbol,dim); Crashes.
In-Reply-To: <6rsmhhcxb8.fsf@bates4.stat.wisc.edu>
References: <200402111413040019.04546ED8@harry.molgen.mpg.de>
	<6rsmhhcxb8.fsf@bates4.stat.wisc.edu>
Message-ID: <6rwu6tbcs1.fsf@bates4.stat.wisc.edu>

Douglas Bates <bates at cs.wisc.edu> writes:

> "wolski" <wolski at molgen.mpg.de> writes:
> 
> > I want to return a matrix. The code does the R interfacing.  This
> > version does it fine.
> > 
> >   SEXP ans,dim;
> >   PROTECT(ans = NEW_NUMERIC(count*2));
> >   memcpy(NUMERIC_POINTER(ans),result,count*sizeof(double));
> >   memcpy(&(NUMERIC_POINTER(ans)[count]),occur,count*sizeof(double));
> > /**  PROTECT(dim=NEW_INTEGER(2));
> >     INTEGER_POINTER(dim)[0]=2;
> >    INTEGER_POINTER(dim)[1]=count; 
> >    setAttrib(ans,R_DimSymbol,dim); 
> > */
> >   UNPROTECT(7);
> > 
> > If I uncomment the lines 5 to 8 than all is working fine four small
> > count's (tested 10,20).  But if the result is an array with about
> > 2000 entries R crashes vicious and violently with the lax comment
> > 
> > Process R trace trap at Wed Feb 11 13:55:45 2004
> > 
> > Anyone is seeiing something what I can not see?
> 
> In most cases it is easier to use allocMatrix instead of assigning a
> dimension attribute to a numeric vector.  You could write this as
> 
>    SEXP ans = PROTECT(allocMatrix(REALSXP, 2, count));
>    memcpy(NUMERIC_POINTER(ans),result,count*sizeof(double));
>    memcpy(&(NUMERIC_POINTER(ans)[count]),occur,count*sizeof(double));
>    UNPROTECT(1);
> 
> Another enhancement is use Memcpy, as in
> 
>    SEXP ans = PROTECT(allocMatrix(REALSXP, 2, count));
>    double *ansp = REAL(ans);    /* same as NUMERIC_POINTER(ans) */
> 
>    Memcpy(ansp, result, count);
>    Memcpy(ansp + count, occur, count);
>    UNPROTECT(1);
> 
> Regarding your particular problem, did you happen to change the
> argument to UNPROTECT when you changed the code?  You may be getting a
> stack imbalance if you change the number of PROTECTs that are executed
> and don't change the UNPROTECT count.
> 
> This is why I generally try to write C functions with only one PROTECT
> in then.  Because PROTECTing an object also PROTECTs all components
> reachable from that object I allocate other storage as components of
> the (PROTECT'ed) result then manipulate those components.  For
> example, if I don't use allocMatrix I would write what you did as
> 
>    SEXP ans = PROTECT(NEW_NUMERIC(count * 2));
>    double *ansp = NUMERIC_POINTER(ans);
>    int *dims;
> 
>    Memcpy(ansp, result, count);
>    Memcpy(ansp + count, occur, count);
>    setAttrib(ans, R_DimSymbol, NEW_INTEGER(2));
>    dims = INTEGER_POINTER(getAttrib(ans, R_DimSymbol));
>    dims[0] = 2;
>    dims[1] = count;
>    UNPROTECT(1);

By the way, you probably have the dimensions backwards here.  Recall
that R stores matrices in column-major ordering so you probably want
the dimensions to be (count, 2) not (2, count).



From fernando.freitas at ipea.gov.br  Wed Feb 11 21:16:51 2004
From: fernando.freitas at ipea.gov.br (fernando freitas)
Date: Wed, 11 Feb 2004 17:16:51 -0300
Subject: [R] tobit Heteroscedasticity
Message-ID: <402A8DB3.2040900@ipea.gov.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040211/f9e18292/attachment.pl

From ray at mcs.vuw.ac.nz  Wed Feb 11 21:32:23 2004
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Thu, 12 Feb 2004 09:32:23 +1300 (NZDT)
Subject: [R] large fonts on plots
Message-ID: <200402112032.i1BKWNtP006900@tahi.mcs.vuw.ac.nz>

On 11 Feb 2004 at 13:30, Piet van Remortel wrote:

> Hi all,
> 
> I need to enlarge te fonts used oo R-plots (plots, histograms, ...) in
> labels and titles etc.

Nobody seems to have mentioned another way of achieving this, which is
to scale the original plot to suit the intended final size in the
document.  E.g. if you use:
> postscript(file="plot1.ps", width=4, height=4)
then the 4"x4" figure will 'automatically' have relatively larger
text and plot symbols.  This works well with x11() which is
subsequently printed, and pdf() also.

HTH,
Ray Brownrigg



From jfox at mcmaster.ca  Wed Feb 11 22:20:44 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 11 Feb 2004 16:20:44 -0500
Subject: [R] how to get the GUI directory chooser on Windows?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7787@usrymx25.merck.co
 m>
Message-ID: <5.1.0.14.2.20040211161917.0200bd28@127.0.0.1>

Dear Andy,

At 02:29 PM 2/11/2004 -0500, Liaw, Andy wrote:
>Thanks to Uwe and Duncan Murdoch (who replied off-list).  The bottom line is
>as Uwe said: no existing R level functionality.
>
>I guess it might be possible to do something similar with Tcl/Tk, but I do
>not know Tcl/tk...

With the tcltk package loaded, it's as simple as 
tclvalue(tkchooseDirectory()), which returns the directory name as a 
character string.

I hope that this helps,
  John

>Best,
>Andy
>
> > From: Uwe Ligges
> >
> > Liaw, Andy wrote:
> >
> > > Dear R-help,
> > >
> > > Can anyone tell me if it's possible to call up the
> > "directory chooser" (the
> > > one you get when you click on "File" -> "Change Dir...") in
> > Rgui from the R
> > > command line?  Seems like file.choose() can't be used to
> > choose a directory.
> >
> > Looks like there is no R function to do so.
> >
> > The C level code is in
> > ./src/gnuwin32/rui.c
> > and
> > ./src/gnuwin32/graphapp/dialogs.c
> > and friends.
> >
> > Uwe Ligges
> >
> >
> > > This is in R-1.8.1 on WinXPPro.
> > >
> > > Any help much appreciated!
> > >
> > > Andy
> > >
> > >
> > >
> > >

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From andy_liaw at merck.com  Wed Feb 11 22:26:29 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 11 Feb 2004 16:26:29 -0500
Subject: [R] how to get the GUI directory chooser on Windows?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF778B@usrymx25.merck.com>

Fantastic!  Thanks very much, John.  Now I can use:

cd <- function(dir = tclvalue(tkchooseDirectory()), saveOld=FALSE,
               loadNew=TRUE) {
  require(tcltk)
  if (saveOld) save.image(compress=TRUE)
  setwd(dir)
  rm(list=ls(all=TRUE, envir=.GlobalEnv), envir=.GlobalEnv)
  if (loadNew && file.exists(".RData")) {
    loaded <- load(".RData", envir=.GlobalEnv)
    return(invisible(loaded))
  }
}

so when I simply type cd() at the Rgui prompt, I can choose a directory,
click "OK", and have R switch to the new directory and load the workspace
image, if one is present.

[The code probably could use a bit more safeguard; e.g., checking that dir
is actually a valid directory, if given in the call to cd().]

Best,
Andy

> From: John Fox [mailto:jfox at mcmaster.ca] 
> 
> Dear Andy,
> 
> At 02:29 PM 2/11/2004 -0500, Liaw, Andy wrote:
> >Thanks to Uwe and Duncan Murdoch (who replied off-list).  
> The bottom line is
> >as Uwe said: no existing R level functionality.
> >
> >I guess it might be possible to do something similar with 
> Tcl/Tk, but I do
> >not know Tcl/tk...
> 
> With the tcltk package loaded, it's as simple as 
> tclvalue(tkchooseDirectory()), which returns the directory name as a 
> character string.
> 
> I hope that this helps,
>   John
> 
> >Best,
> >Andy
> >
> > > From: Uwe Ligges
> > >
> > > Liaw, Andy wrote:
> > >
> > > > Dear R-help,
> > > >
> > > > Can anyone tell me if it's possible to call up the
> > > "directory chooser" (the
> > > > one you get when you click on "File" -> "Change Dir...") in
> > > Rgui from the R
> > > > command line?  Seems like file.choose() can't be used to
> > > choose a directory.
> > >
> > > Looks like there is no R function to do so.
> > >
> > > The C level code is in
> > > ./src/gnuwin32/rui.c
> > > and
> > > ./src/gnuwin32/graphapp/dialogs.c
> > > and friends.
> > >
> > > Uwe Ligges
> > >
> > >
> > > > This is in R-1.8.1 on WinXPPro.
> > > >
> > > > Any help much appreciated!
> > > >
> > > > Andy
> > > >
> > > >
> > > >
> > > >
> 
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From bates at stat.wisc.edu  Wed Feb 11 22:38:46 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 Feb 2004 15:38:46 -0600
Subject: [R] how much memory?  was: R does in memory analysis only?
In-Reply-To: <644D9337A02FC24689647BF9E48EC39E08ABB767@drm556>
References: <644D9337A02FC24689647BF9E48EC39E08ABB767@drm556>
Message-ID: <6r3c9hb8k9.fsf@bates4.stat.wisc.edu>

"Samuelson, Frank*" <FWS4 at CDRH.FDA.GOV> writes:

> Is there a way to tell how much memory the computer
> running R has?

Most Linux distributions have a program called 'free' that reports on
the total amount of memory available and the amount used for different
purposes.  From within R you could use

> system("free")
             total       used       free     shared    buffers     cached
Mem:       1552072    1462044      90028          0     176892     922176
-/+ buffers/cache:     362976    1189096
Swap:      1951888      12360    1939528

which shows that the total amount of memory on this machine is 1.5 GB,
of which about 1.2 GB is available if needed.

Another method in Linux (depending on your kernel) is

> system("cat /proc/meminfo")
        total:    used:    free:  shared: buffers:  cached:
Mem:  1589321728 1497116672 92205056        0 181149696 945790976
Swap: 1998733312 12656640 1986076672
MemTotal:      1552072 kB
MemFree:         90044 kB
MemShared:           0 kB
Buffers:        176904 kB
Cached:         922172 kB
SwapCached:       1452 kB
Active:         664200 kB
Inactive:       543492 kB
HighTotal:      655344 kB
HighFree:        10372 kB
LowTotal:       896728 kB
LowFree:         79672 kB
SwapTotal:     1951888 kB
SwapFree:      1939528 kB



From p.dalgaard at biostat.ku.dk  Wed Feb 11 23:06:38 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Feb 2004 23:06:38 +0100
Subject: [R] 64-bit Windows 2003 build of R
In-Reply-To: <E4E4C6B0D39DAC4CAA15D09B594DD98C3C965A@exon.illumigen.com>
References: <E4E4C6B0D39DAC4CAA15D09B594DD98C3C965A@exon.illumigen.com>
Message-ID: <x2k72t9spd.fsf@biostat.ku.dk>

"John Sweval" <JSweval at illumigen.com> writes:

> I am running into serious memory constraint issues with the 32 bit build
> of R.  We have Windows 2003 on an Itanium 64 box with the Intel 64-bit C
> compiler (8.0.041) and want to create a 64-bit version of R.
> Unfortunately, I am no longer "current" with C builds, i.e. - I haven't
> done one in years and have never used the Intel 64-bit compiler.  I
> could use any suggestions, make file, assistance, etc. from anyone who
> may have already compiled a 64-bit Windows version of R.

Well, as you probably realized while typing that, you'll likely be
short of luck unless you find someone with similar hardware, OS, and
compilers PLUS the stamina to go through the "flagmire" of configuring
for a different set of compilers/linkers than those normally used to
build R on Windows. And 64-bit Windows installs appear to be quite
rare. 

It's not easy. Building R with other compilers than the recommended
GCC/MinGW tools is hard (as in "not recommended"!) even on 32 bit
Windows.

Then there's the option of ignoring the Intel compiler and using GNU
tools like the ones for Win32, but I suspect that you'll still run
into porting issues. It shouldn't be too hard to cross-build a 64 bit
GCC compiler and binutils toolchain, but there's still an issue about
what to do with the win32api stuff.

The most efficient way to get a 64 bit system running here and now is
to switch the operating system entirely, since R is known to build
pretty much out of the box on Linux for IA64 and x86-64 systems.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From marcos.sanches at ipsos-opinion.com.br  Thu Feb 12 01:44:05 2004
From: marcos.sanches at ipsos-opinion.com.br (Marcos Sanches)
Date: Wed, 11 Feb 2004 21:44:05 -0300
Subject: [R] AGREP
In-Reply-To: <000701c3f0c7$f7497350$d297a8c0@opinionserver>
Message-ID: <002501c3f101$5117ee50$d297a8c0@opinionserver>

Hi listers

If you don't know what is the Edit Distance beetwen two strings, I will
try to explain, in fact it is very simple to understund but not to
calculate througth a program. It is simplilly the minimum number of
operations you must perform to transform string A on string B, by
operations I mean delete letters, insert letters or substitute letter.

If you need to do few operations, it means string A is almost the same
as string B. Otherwise they are more differente as the number of
operations increase.

If you have a idea of how to make a function to calculate this distance,
it would be very important for me. 

Thanks very much,

Marcos



From jdn at cs.sfu.ca  Thu Feb 12 00:46:30 2004
From: jdn at cs.sfu.ca (Jason Nielsen)
Date: Wed, 11 Feb 2004 15:46:30 -0800 (PST)
Subject: [R] lapply and dynamically linked functions
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF777F@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF777F@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.53.0402111541590.2510@lenny>

Well I finally figured it out.  After proving to myself that it wasn't the 
Fortran wrapper with a simple example I started to dig into this.  The 
problem is that I was naming one of my parameters X... which is the name 
of the input value in lapply... I'm not sure if this is a bug or just the 
way it works but here is an example:

examplegood<-function(kn,XX)
{
  out<-sum(kn)*sum(XX)
  out
}

examplebad<-function(kn,X)
{
  out<-sum(kn)*sum(X)
  out
}

mylist<-vector("list")

for(i in 1:5) mylist[[i]]<-i

a<-1:10

Now run lapply and you get:

> lapply(mylist,examplebad,X=a)
Error in get(x, envir, mode, inherits) : variable "mylist" was not found

> lapply(mylist,examplegood,XX=a)
[[1]]
[1] 55

[[2]]
[1] 110

[[3]]
[1] 165

[[4]]
[1] 220

[[5]]
[1] 275

Well there you have it!

Cheers,
Jason


On Wed, 11 Feb 2004, Liaw, Andy wrote:

> My guess is that you probably refer to `mylist' instead of `x' inside
> `myfun'.  Please show us the entire code, rather than leave us guessing.
> 
> Andy
> 
> > From: Jason Nielsen
> > 
> > Hi all,
> > 
> > I'm trying to use lapply on a list with the following command:
> > 
> > out<-lapply(mylist,myfun,par1=p,par2=d)               (1)
> > 
> > where
> > 
> > myfun<-function(x,par1,par1) {.....}                  (2)
> > 
> > now this function is in fact a wrapper for some Fortran code I have
> > written so I think this might be the problem.  When I call 
> > lapply() as in
> > (1)  I get the following message:
> > 
> > Error in get(x, envir, mode, inherits) : variable "mylist" 
> > was not found
> > 
> > but if I say do:
> > 
> > out<-lapply(mylist,sum)
> > 
> > it returns a nice list with the sums of the elements in the list.  So
> > after all that I guess my question is does this have to do 
> > with the fact
> > that my function is a wrapper for my Fortran code (which 
> > works fine on its
> > own.. and if I use a loop as opposed to lapply() )?  I 
> > imagine that lapply
> > which is a wrapper for the .Internal lapply might have some 
> > trouble with
> > my Fortran wrapper?  Is this the case or is it something dumb 
> > on my end?  
> > Any input is appreciated.
> > 
> > Cheers,
> > Jason
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New Jersey, USA 08889), and/or its affiliates (which may be known outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be confidential, proprietary copyrighted and/or legally privileged. It is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please notify us immediately by reply e-mail and then delete it from your system.
> ------------------------------------------------------------------------------
>



From fjmolina at ams.ucsc.edu  Thu Feb 12 04:22:00 2004
From: fjmolina at ams.ucsc.edu (Francisco J Molina)
Date: Wed, 11 Feb 2004 19:22:00 -0800
Subject: [R] How to detect whether a file exists or not?
Message-ID: <16426.61784.830882.606328@dhcp-63-193.cse.ucsc.edu>


I would like my program to load variables x,y,x from a file 'myFile.r' but
if this file does not exist, I want my program to create/initialize x,y,z.

Does anyone know how to do this?

Thank you very much.

Francisco J. Molina



From edd at debian.org  Thu Feb 12 04:24:28 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 11 Feb 2004 21:24:28 -0600
Subject: [R] How to detect whether a file exists or not?
In-Reply-To: <16426.61784.830882.606328@dhcp-63-193.cse.ucsc.edu>
References: <16426.61784.830882.606328@dhcp-63-193.cse.ucsc.edu>
Message-ID: <20040212032428.GA5422@sonny.eddelbuettel.com>

On Wed, Feb 11, 2004 at 07:22:00PM -0800, Francisco J Molina wrote:
> 
> I would like my program to load variables x,y,x from a file 'myFile.r' but
> if this file does not exist, I want my program to create/initialize x,y,z.
> 
> Does anyone know how to do this?

?file.info			# as help.search("file") would have revealed

Hth, Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From rpeng at jhsph.edu  Thu Feb 12 04:42:20 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 11 Feb 2004 22:42:20 -0500
Subject: [R] How to detect whether a file exists or not?
In-Reply-To: <20040212032428.GA5422@sonny.eddelbuettel.com>
References: <16426.61784.830882.606328@dhcp-63-193.cse.ucsc.edu>
	<20040212032428.GA5422@sonny.eddelbuettel.com>
Message-ID: <402AF61C.2030509@jhsph.edu>

Even better, file.exists().

-roger

Dirk Eddelbuettel wrote:
> On Wed, Feb 11, 2004 at 07:22:00PM -0800, Francisco J Molina wrote:
> 
>>I would like my program to load variables x,y,x from a file 'myFile.r' but
>>if this file does not exist, I want my program to create/initialize x,y,z.
>>
>>Does anyone know how to do this?
> 
> 
> ?file.info			# as help.search("file") would have revealed
> 
> Hth, Dirk
>



From ggrothendieck at myway.com  Thu Feb 12 04:43:17 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 11 Feb 2004 22:43:17 -0500 (EST)
Subject: [R] How to detect whether a file exists or not?
Message-ID: <20040212034317.24E6839AB@mprdmxin.myway.com>



You can adapt this to your situation:

   z <- try( read.table("myfile", header=T) )
   if (class(z) == "try-error") z <- data.frame(x=1,y=2,z=3)

You may also be interested in the silent= arg of try.  See ?try

Date:   Wed, 11 Feb 2004 19:22:00 -0800 
From:   Francisco J Molina <fjmolina at ams.ucsc.edu>
To:   r-help <r-help at stat.math.ethz.ch> 
Subject:   [R] How to detect whether a file exists or not? 

 

I would like my program to load variables x,y,x from a file 'myFile.r' but
if this file does not exist, I want my program to create/initialize x,y,z.

Does anyone know how to do this?

Thank you very much.

Francisco J. Molina



From jgentry at jimmy.harvard.edu  Thu Feb 12 06:18:28 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu, 12 Feb 2004 00:18:28 -0500 (EST)
Subject: [R] How to detect whether a file exists or not?
In-Reply-To: <16426.61784.830882.606328@dhcp-63-193.cse.ucsc.edu>
Message-ID: <Pine.SOL.4.20.0402120018180.6321-100000@santiam.dfci.harvard.edu>

> I would like my program to load variables x,y,x from a file 'myFile.r' but
> if this file does not exist, I want my program to create/initialize x,y,z.
> Does anyone know how to do this?

?file.exists



From James.McCulloch at uts.edu.au  Thu Feb 12 07:25:18 2004
From: James.McCulloch at uts.edu.au (James McCulloch)
Date: Thu, 12 Feb 2004 17:25:18 +1100
Subject: [R] Kernel Density Estimator for 2D Binned Data
Message-ID: <000101c3f130$fc5b9350$674c198a@FIND321JimM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040212/4d4c705a/attachment.pl

From ggrothendieck at myway.com  Thu Feb 12 07:26:00 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 12 Feb 2004 01:26:00 -0500 (EST)
Subject: [R] AGREP
Message-ID: <20040212062600.42C033968@mprdmxin.myway.com>




1. The agrep function in 1.8.1 is not written entirely in R so
you would have to move the C code over too.

If you have the agrep command at the operating system level
(for windows you can get find it by searching for agrep.exe in
google) you could try something like this:

   readLines(pipe("agrep -1 pattern myfile"))

where you have written out your lines from R to myfile.  If
pipe was not available that far back you could use the system
command and redirect the output to a file and read it into R.

2. I am not sure if this is practical for you but you could try
running agrep, agrep -1, agrep -2, etc. and then
assign each line the number at which it first appears.

---
Date:   Wed, 11 Feb 2004 14:53:33 -0300 
From:   Marcos Sanches <marcos.sanches at ipsos-opinion.com.br>
[ Add to Address Book | Block Address | Report as Spam ] 
To:   R Help <r-help at stat.math.ethz.ch> 
Subject:   [R] AGREP 

 

     Hi all, I have two questions

1 - I have the version 1.4.1 of R, and it doesn't have the 'agrep'
function in the base library. Is there a way to make this funcion
avaliable in R 1.4.1? I mean, how to 'copy' it from R 1.8.1 and 'paste'
it in R 1.4.1?

2 - The AGREP function doesn't give me the Levenshtein distance (edit
distance). Is there a function in R that does it? Is there a way to use
AGREP to acomplish this task? I've written such a function, but it is so
slow (has so many loops) that it is beeing useless. 

TIA



From nikko at hailmail.net  Thu Feb 12 09:56:50 2004
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Thu, 12 Feb 2004 16:56:50 +0800
Subject: [R] RE: Kernel Density Estimator for 2D Binned Data
Message-ID: <1076576210.27513.180916553@webmail.messagingengine.com>

Hi James,
You can try the hexbin package at www.bioconductor.org. Do the following

bin<-hexbin(x,y)
## This will give you hexagonal bins of the data
binsm<-smooth.hexbin(bin)
plot(binsm)

This is an approximation to what you want. The other way is to use a 2d
bspline 
on the bin center of masses of the hexagons and use the bin counts as
weights.

Nicholas



From wolfram at fischer-zim.ch  Thu Feb 12 10:12:18 2004
From: wolfram at fischer-zim.ch (Wolfram Fischer - Z/I/M)
Date: Thu, 12 Feb 2004 10:12:18 +0100
Subject: [R] lattice: showing panels for factor levels with no values
Message-ID: <20040212091218.GA4752@s1x.local>

How to show panels for factor levels of conditioning variables
which do have no values?

E.g. there are panels for "Grand Rapids" when they have values:
	data( barley )
	with( barley, dotplot(variety ~ yield | year * site, layout=c(6,2) ) )

There are no panels for "Grand Rapids"
when there are no values for "Grand Rapids":
	my.barley <- subset( barley, ! ( site == "Grand Rapids" ) )
	with( my.barley, dotplot(variety ~ yield | year * site, layout=c(6,2) ) )

But there is a level "Grand Rapids":
	levels( my.barley$site )
	[1] "Grand Rapids"    "Duluth"
	[3] "University Farm" "Morris"         
	[5] "Crookston"       "Waseca" 

Is there an option to show empty panels for "Grand Rapids" in ``my.barley''?

Thanks. Wolfram



From tsing at mpi-sb.mpg.de  Thu Feb 12 12:08:55 2004
From: tsing at mpi-sb.mpg.de (Tobias Sing)
Date: Thu, 12 Feb 2004 12:08:55 +0100
Subject: [R] Debugging R Code
Message-ID: <200402121208.55156.tsing@mpi-sb.mpg.de>

Hi all,

is there a more convenient way to debug R code than the built in debug() 
function? (so that one can set breakpoints, step in and out of function 
calls,...). I read the section on debugging compiled code in the manual 
"Writing R Extensions" (I only want to debug ordinary code but thought that 
maybe the advice there could help), but didn't find out how I can start 
debugging my code after typing "R -d gdb", which brought me to the gdb prompt 
(I'm using R 1.6.2 in xemacs via ESS).

Thanks,
  Tobias


__________________________________________
Tobias Sing

Computational Biology Group 
Max-Planck-Institut f?r Informatik
Stuhlsatzenhausweg 85
66123 Saarbr?cken, Germany

Phone: +49 681 9325 314
Fax: +49 681 9325 399
E-mail: tsing at mpi-sb.mpg.de
WWW: http://www.mpi-sb.mpg.de/units/ag3/



From gayatri at igib.res.in  Thu Feb 12 12:02:40 2004
From: gayatri at igib.res.in (GAYATRI)
Date: Thu, 12 Feb 2004 16:32:40 +0530
Subject: [R] How to download
Message-ID: <000801c3f157$c1c77930$4facc0c8@308sh>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040212/bf5524c7/attachment.pl

From jgu at codan.dk  Thu Feb 12 12:12:01 2004
From: jgu at codan.dk (Jim Gustafsson)
Date: Thu, 12 Feb 2004 12:12:01 +0100
Subject: [R] R-help
Message-ID: <OFBFE7316D.09A3C0AE-ONC1256E38.003D5CCD@codan.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040212/cd43091d/attachment.pl

From dominique.couturier at unine.ch  Thu Feb 12 12:26:54 2004
From: dominique.couturier at unine.ch (dlc)
Date: Thu, 12 Feb 2004 12:26:54 +0100
Subject: [R] Debugging R Code
In-Reply-To: <200402121208.55156.tsing@mpi-sb.mpg.de>
References: <200402121208.55156.tsing@mpi-sb.mpg.de>
Message-ID: <5C289976-5D4E-11D8-A505-0003931DD6AE@unine.ch>

hello,
the new library "debug" contains such possibilities and has a nice 
tcl/tk interface.
Read the description of that library in the last volume of R-news 
(volume 3/3, december 03, p.29)
hope this help,
dlc

> Hi all,
>
> is there a more convenient way to debug R code than the built in 
> debug()
> function? (so that one can set breakpoints, step in and out of function
> calls,...). I read the section on debugging compiled code in the manual
> "Writing R Extensions" (I only want to debug ordinary code but thought 
> that
> maybe the advice there could help), but didn't find out how I can start
> debugging my code after typing "R -d gdb", which brought me to the gdb 
> prompt
> (I'm using R 1.6.2 in xemacs via ESS).
>
> Thanks,
>   Tobias
>
>
> __________________________________________
> Tobias Sing
>
> Computational Biology Group
> Max-Planck-Institut f?r Informatik
> Stuhlsatzenhausweg 85
> 66123 Saarbr?cken, Germany
>
> Phone: +49 681 9325 314
> Fax: +49 681 9325 399
> E-mail: tsing at mpi-sb.mpg.de
> WWW: http://www.mpi-sb.mpg.de/units/ag3/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>



From pallier at lscp.ehess.fr  Thu Feb 12 11:57:42 2004
From: pallier at lscp.ehess.fr (Christophe Pallier)
Date: Thu, 12 Feb 2004 11:57:42 +0100
Subject: [R] calling R from a shell script and have it display graphics
Message-ID: <402B5C26.90706@lscp.ehess.fr>

Hello,

I am running R under Linux/x11.

I would like to call R from a shell script and have it display a series 
of graphics.
The graphics should remain visible until the user clicks or presses a key.

I first tried R BATCH, but it does not load the x11 module, making it 
impossible to open x11 or png devices.

Then, I tried to call R with a 'here' script:

R --vanilla --quiet --args text.txt <<'EOF'
file=commandArgs()[5]
cat('processing ',file,'\n')
...
x11()
plot(f2,log='xy',type='b',las=1,cex=.5,xlab='rang',ylab='freq')
Sys.sleep(10)
q()
EOF

The problem with this approach is that the script cannot interact with 
the user.
par(ask=T) will fail because it reads input from the script rather than 
from the keyboard.

While I am writing this, a solution comes to my mind: I could save all 
the graphics in png format (using R <script.R), and when it is finished, 
call ImageMagick's display to show all the png (or use any other 
diaporama system). However, I find it a dirty hack.

Is there a simpler and cleaner way to achieve this?

Christophe Pallier
www.pallier.org



From simon at stats.gla.ac.uk  Thu Feb 12 12:30:50 2004
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Thu, 12 Feb 2004 11:30:50 +0000 (GMT)
Subject: [R] Debugging R Code
In-Reply-To: <200402121208.55156.tsing@mpi-sb.mpg.de>
References: <200402121208.55156.tsing@mpi-sb.mpg.de>
Message-ID: <Pine.SOL.4.58.0402121129510.4103@moon.stats.gla.ac.uk>

Maybe try Mark Bravingtons's debug package? (see article in last R news)

> is there a more convenient way to debug R code than the built in debug()
> function? (so that one can set breakpoints, step in and out of function
> calls,...). I read the section on debugging compiled code in the manual
> "Writing R Extensions" (I only want to debug ordinary code but thought that
> maybe the advice there could help), but didn't find out how I can start
> debugging my code after typing "R -d gdb", which brought me to the gdb prompt
> (I'm using R 1.6.2 in xemacs via ESS).
>
> Thanks,
>   Tobias
>
>
> __________________________________________
> Tobias Sing
>
> Computational Biology Group
> Max-Planck-Institut f?r Informatik
> Stuhlsatzenhausweg 85
> 66123 Saarbr?cken, Germany
>
> Phone: +49 681 9325 314
> Fax: +49 681 9325 399
> E-mail: tsing at mpi-sb.mpg.de
> WWW: http://www.mpi-sb.mpg.de/units/ag3/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dmurdoch at pair.com  Thu Feb 12 12:45:19 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 12 Feb 2004 06:45:19 -0500
Subject: [R] AGREP
In-Reply-To: <000701c3f0c7$f7497350$d297a8c0@opinionserver>
References: <000701c3f0c7$f7497350$d297a8c0@opinionserver>
Message-ID: <miom20p1682idqe5n5m2co35gc9ktep8sk@4ax.com>

On Wed, 11 Feb 2004 14:53:33 -0300, you wrote:

>
>	Hi all, I have two questions
>
>1 - I have the version 1.4.1 of R, and it doesn't have the 'agrep'
>function in the base library. Is there a way to make this funcion
>avaliable in R 1.4.1? I mean, how to 'copy' it from R 1.8.1 and 'paste'
>it in R 1.4.1?

The easiest way is to install 1.8.1.  There have been a *lot* of
improvements in R since 1.4.1

>2 - The AGREP function doesn't give me the Levenshtein distance (edit
>distance). Is there a function in R that does it? Is there a way to use
>AGREP to acomplish this task? I've written such a function, but it is so
>slow (has so many loops) that it is beeing useless. 

I don't think there's a function, but I imagine this should be
possible.  You'd need to look at src/main/apse.c to find which
function returns this information, and then write code something like
do_agrep (in character.c) to call that function instead of calling
apse_match.

Duncan Murdoch



From ligges at statistik.uni-dortmund.de  Thu Feb 12 13:05:41 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 12 Feb 2004 13:05:41 +0100
Subject: [R] How to download
In-Reply-To: <000801c3f157$c1c77930$4facc0c8@308sh>
References: <000801c3f157$c1c77930$4facc0c8@308sh>
Message-ID: <402B6C15.2020009@statistik.uni-dortmund.de>

GAYATRI wrote:

> Sir/Madam,
> 
>                  I have been trying to install packages from bioconductor or CRAN but we get an error message saying "can't open URL http://www.                  bioconductor.org/bin/windows/contrib/1.7/PACKAGES". Kindly help me in resolving this problem.
>            Further, I would like to know that  to whom I should request for scripts of ADE-4 package.
> 
> GAYATRI
> Project Assistant,
> IGIB, New Delhi.
> India
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


If your internet connection works, you might need to configure a proxy? 
If you are on Windows (you haven't told about your OS), please read the 
R for Windows FAQ.

Package ade4 is available on CRAN.

BTW: You can download packages manually from both CRAN and BioConductor 
and install those packages afterwards.

Uwe Ligges



From bates at stat.wisc.edu  Thu Feb 12 13:09:23 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 12 Feb 2004 06:09:23 -0600
Subject: [R] How to download
In-Reply-To: <000801c3f157$c1c77930$4facc0c8@308sh>
References: <000801c3f157$c1c77930$4facc0c8@308sh>
Message-ID: <6rn07oxzws.fsf@bates4.stat.wisc.edu>

"GAYATRI" <gayatri at igib.res.in> writes:

> I have been trying to install packages from bioconductor or CRAN but
> we get an error message saying "can't open URL http://www.
> bioconductor.org/bin/windows/contrib/1.7/PACKAGES". Kindly help me
> in resolving this problem.

The 1.7 in that URL indicates that you are running version 1.7.x of
R.  The current release is 1.8.1.  It may help to upgrade to the
current release.

>  Further, I would like to know that to whom I should request for
>  scripts of ADE-4 package.

You should be able to install that package with

install.packages("ade4")

when running on a computer connected to the internet.  The Windows and
Mac OS X gui versions of R have a menu-bar selection that makes this a
bit easier (see the "Packages" menu).



From JonesW at kssg.com  Thu Feb 12 13:00:15 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Thu, 12 Feb 2004 12:00:15 -0000
Subject: [R] Almost Ideal Demand System
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0FA6@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040212/3851317a/attachment.pl

From gayatri at igib.res.in  Thu Feb 12 13:14:10 2004
From: gayatri at igib.res.in (GAYATRI)
Date: Thu, 12 Feb 2004 17:44:10 +0530
Subject: [R] (no subject)
Message-ID: <001601c3f161$baa568b0$4facc0c8@308sh>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040212/20607844/attachment.pl

From angel_lul at hotmail.com  Thu Feb 12 13:43:14 2004
From: angel_lul at hotmail.com (Angel)
Date: Thu, 12 Feb 2004 13:43:14 +0100
Subject: [R] Debugging R Code
References: <200402121208.55156.tsing@mpi-sb.mpg.de>
Message-ID: <Law11-OE60ixqbWt0ab00006ba9@hotmail.com>

If you plan using Mark Bravingtons's debug package within emacs via ess you
should read this:
https://www.stat.math.ethz.ch/pipermail/ess-help/2004-February/001708.html
were Mark suggested that in emacs you should set
options( debug.command.recall=FALSE)' before running the debugger.
Cheers,
Angel
----- Original Message -----
From: "Tobias Sing" <tsing at mpi-sb.mpg.de>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, February 12, 2004 12:08 PM
Subject: [R] Debugging R Code


> Hi all,
>
> is there a more convenient way to debug R code than the built in debug()
> function? (so that one can set breakpoints, step in and out of function
> calls,...). I read the section on debugging compiled code in the manual
> "Writing R Extensions" (I only want to debug ordinary code but thought
that
> maybe the advice there could help), but didn't find out how I can start
> debugging my code after typing "R -d gdb", which brought me to the gdb
prompt
> (I'm using R 1.6.2 in xemacs via ESS).
>
> Thanks,
>   Tobias
>
>
> __________________________________________
> Tobias Sing
>
> Computational Biology Group
> Max-Planck-Institut f?r Informatik
> Stuhlsatzenhausweg 85
> 66123 Saarbr?cken, Germany
>
> Phone: +49 681 9325 314
> Fax: +49 681 9325 399
> E-mail: tsing at mpi-sb.mpg.de
> WWW: http://www.mpi-sb.mpg.de/units/ag3/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From feh3k at spamcop.net  Thu Feb 12 13:36:15 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Thu, 12 Feb 2004 07:36:15 -0500
Subject: [R] R-help
In-Reply-To: <OFBFE7316D.09A3C0AE-ONC1256E38.003D5CCD@codan.dk>
References: <OFBFE7316D.09A3C0AE-ONC1256E38.003D5CCD@codan.dk>
Message-ID: <20040212073615.5bdf9c25.feh3k@spamcop.net>

On Thu, 12 Feb 2004 12:12:01 +0100
Jim Gustafsson <jgu at codan.dk> wrote:

> Hi,
> I have a problem.
> I would like to put my SAS-code into R.
> Could I do that, if yes, how?
> 
> 
> Best regards
> Jim Gustafsson

Just reverse the procedure you use when you put R code into SAS.   ;)

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From rolf at math.unb.ca  Thu Feb 12 13:53:02 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 12 Feb 2004 08:53:02 -0400 (AST)
Subject: [R] R-help
Message-ID: <200402121253.i1CCr22A010306@erdos.math.unb.ca>


Jim Gustafsson <jgu at codan.dk> wrote:

> I have a problem.

	Boy, do you ever.

> I would like to put my SAS-code into R.
> Could I do that, if yes, how?

Right.  I have a couple of questions for you too.

	(1) How long is a piece of string?

	(2) How do I bring peace, prosperity, and universal
	brotherhood to the world?

Finally, let me draw your attention to the addendum which is appended
to all r-help postings these days:

	PLEASE do read the posting guide!
        http://www.R-project.org/posting-guide.html

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From deepayan at stat.wisc.edu  Thu Feb 12 14:11:02 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 12 Feb 2004 07:11:02 -0600
Subject: [R] lattice: showing panels for factor levels with no values
In-Reply-To: <20040212091218.GA4752@s1x.local>
References: <20040212091218.GA4752@s1x.local>
Message-ID: <200402120711.02960.deepayan@stat.wisc.edu>

On Thursday 12 February 2004 03:12, Wolfram Fischer - Z/I/M wrote:
> How to show panels for factor levels of conditioning variables
> which do have no values?
>
> E.g. there are panels for "Grand Rapids" when they have values:
> 	data( barley )
> 	with( barley, dotplot(variety ~ yield | year * site, layout=c(6,2) ) )
>
> There are no panels for "Grand Rapids"
> when there are no values for "Grand Rapids":
> 	my.barley <- subset( barley, ! ( site == "Grand Rapids" ) )
> 	with( my.barley, dotplot(variety ~ yield | year * site, layout=c(6,2) ) )
>
> But there is a level "Grand Rapids":
> 	levels( my.barley$site )
> 	[1] "Grand Rapids"    "Duluth"
> 	[3] "University Farm" "Morris"
> 	[5] "Crookston"       "Waseca"
>
> Is there an option to show empty panels for "Grand Rapids" in
> ``my.barley''?

No, unused factor levels are dropped. I'll see if adding an option for this is 
feasible.

Deepayan



From andy_liaw at merck.com  Thu Feb 12 14:11:11 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 12 Feb 2004 08:11:11 -0500
Subject: [R] lapply and dynamically linked functions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF778D@usrymx25.merck.com>

That's the expected behavior, not a bug, because:

> args(lapply)
function (X, FUN, ...) 
NULL

so lapply has `X' as an formal argument.  Any calls to lapply() with named
argument `X=...' will match to that, so the net effect is that the `X=...'
part gets used by lapply() as the list to operate on, rather than pass down
to `FUN'.  You might want to read the relevant section of the `R Language
Definition' manual.

I believe the argument is deliberately named with capital `X' to avoid
collision with `x'.

Andy

> From: Jason Nielsen
> 
> Well I finally figured it out.  After proving to myself that 
> it wasn't the 
> Fortran wrapper with a simple example I started to dig into 
> this.  The 
> problem is that I was naming one of my parameters X... which 
> is the name 
> of the input value in lapply... I'm not sure if this is a bug 
> or just the 
> way it works but here is an example:
> 
> examplegood<-function(kn,XX)
> {
>   out<-sum(kn)*sum(XX)
>   out
> }
> 
> examplebad<-function(kn,X)
> {
>   out<-sum(kn)*sum(X)
>   out
> }
> 
> mylist<-vector("list")
> 
> for(i in 1:5) mylist[[i]]<-i
> 
> a<-1:10
> 
> Now run lapply and you get:
> 
> > lapply(mylist,examplebad,X=a)
> Error in get(x, envir, mode, inherits) : variable "mylist" 
> was not found
> 
> > lapply(mylist,examplegood,XX=a)
> [[1]]
> [1] 55
> 
> [[2]]
> [1] 110
> 
> [[3]]
> [1] 165
> 
> [[4]]
> [1] 220
> 
> [[5]]
> [1] 275
> 
> Well there you have it!
> 
> Cheers,
> Jason
> 
> 
> On Wed, 11 Feb 2004, Liaw, Andy wrote:
> 
> > My guess is that you probably refer to `mylist' instead of 
> `x' inside
> > `myfun'.  Please show us the entire code, rather than leave 
> us guessing.
> > 
> > Andy
> > 
> > > From: Jason Nielsen
> > > 
> > > Hi all,
> > > 
> > > I'm trying to use lapply on a list with the following command:
> > > 
> > > out<-lapply(mylist,myfun,par1=p,par2=d)               (1)
> > > 
> > > where
> > > 
> > > myfun<-function(x,par1,par1) {.....}                  (2)
> > > 
> > > now this function is in fact a wrapper for some Fortran 
> code I have
> > > written so I think this might be the problem.  When I call 
> > > lapply() as in
> > > (1)  I get the following message:
> > > 
> > > Error in get(x, envir, mode, inherits) : variable "mylist" 
> > > was not found
> > > 
> > > but if I say do:
> > > 
> > > out<-lapply(mylist,sum)
> > > 
> > > it returns a nice list with the sums of the elements in 
> the list.  So
> > > after all that I guess my question is does this have to do 
> > > with the fact
> > > that my function is a wrapper for my Fortran code (which 
> > > works fine on its
> > > own.. and if I use a loop as opposed to lapply() )?  I 
> > > imagine that lapply
> > > which is a wrapper for the .Internal lapply might have some 
> > > trouble with
> > > my Fortran wrapper?  Is this the case or is it something dumb 
> > > on my end?  
> > > Any input is appreciated.
> > > 
> > > Cheers,
> > > Jason
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > > 
> > > 
> > 
> > 
> > 
> --------------------------------------------------------------
> ----------------
> > Notice:  This e-mail message, together with any 
> attachments, contains information of Merck & Co., Inc. (One 
> Merck Drive, Whitehouse Station, New Jersey, USA 08889), 
> and/or its affiliates (which may be known outside the United 
> States as Merck Frosst, Merck Sharp & Dohme or MSD and in 
> Japan, as Banyu) that may be confidential, proprietary 
> copyrighted and/or legally privileged. It is intended solely 
> for the use of the individual or entity named on this 
> message.  If you are not the intended recipient, and have 
> received this message in error, please notify us immediately 
> by reply e-mail and then delete it from your system.
> > 
> --------------------------------------------------------------
> ----------------
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From andy_liaw at merck.com  Thu Feb 12 14:17:20 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 12 Feb 2004 08:17:20 -0500
Subject: [R] R-help
Message-ID: <3A822319EB35174CA3714066D590DCD504AF778E@usrymx25.merck.com>

[Sorry.  Just can't resist...]

Probably quite easy.  Something like:

system("sas mysascode.sas")

Andy

> From: Jim Gustafsson
> 
> Hi,
> I have a problem.
> I would like to put my SAS-code into R.
> Could I do that, if yes, how?
> 
> 
> Best regards
> Jim Gustafsson
> ______________________________________________________________
> _________________
> Codan Insurance, Gammel Kongevej 60, DK-1790 Copenhagen V
> telephone: +45 33 55 55 55, fax: +45 33 55 21 22
> e-mail: jgu at codan.dk
> http://www.codan.dk
> 	[[alternative HTML version deleted]]
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From chhalling at earthlink.net  Thu Feb 12 14:35:22 2004
From: chhalling at earthlink.net (Conrad Halling)
Date: Thu, 12 Feb 2004 08:35:22 -0500
Subject: [R] Edit strings (was: AGREP)
In-Reply-To: <002501c3f101$5117ee50$d297a8c0@opinionserver>
References: <002501c3f101$5117ee50$d297a8c0@opinionserver>
Message-ID: <402B811A.70004@earthlink.net>

I have not written such a function, but a good place to learn more is 
Chapter 11 of _Algorithms on Strings, Trees, and Sequences_ by Dan Gusfield.

Marcos Sanches wrote:

>Hi listers
>
>If you don't know what is the Edit Distance beetwen two strings, I will
>try to explain, in fact it is very simple to understund but not to
>calculate througth a program. It is simplilly the minimum number of
>operations you must perform to transform string A on string B, by
>operations I mean delete letters, insert letters or substitute letter.
>
>If you need to do few operations, it means string A is almost the same
>as string B. Otherwise they are more differente as the number of
>operations increase.
>
>If you have a idea of how to make a function to calculate this distance,
>it would be very important for me. 
>  
>
-- 
Conrad Halling
chhalling at earthlink.net



From baud-bovy.gabriel at hsr.it  Thu Feb 12 14:56:49 2004
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Thu, 12 Feb 2004 14:56:49 +0100
Subject: [R] Porting let* from Common LISP to R
Message-ID: <5.2.1.1.1.20040212142504.00b71850@mail.hsr.it>


In porting some Common LISP code to R, I am trying to found out whether special
care must be taken for the let* function. In Common LISP, "the let* block 
is like
let except it is guaranteed to evaluate the initialization of its local
variables in sequentially nested scopes, i.e. it provides an order to the
binding and visibility of preceding variables.".

I have included the recursive Common LISP function in which let* block appears
and a straighforward R port.

Thank you,

Gabriel Baud-Bovy


The let* block appears in the following LISP function:

(defun infer (goal subsitution kb)
   (if(null kb)
     (make-empty-stream)
     (let* ((assertion (rename-variable (car kb)))    ; *********
            (match ([...])))
           (if (equal match 'failed)
              (infer goal substitutions (cdr kb))
              (if (rulep assertion)
                 (combine-streams ([...]) (infer goal substitutions (cdr kb)))
                 (cons-stream match (infer goal substitutions (cdr kb))))))))

A straighforward R-translation would be

infer<-function(goal,subsitution,kb) {
   if(is.null(kb)) make-empty-stream()
   else {
     assertion<-rename-variable(car(kb))
     match<- [...]
     if(match=="failed") infer(goal,substitutions,cdr(kb))
     else  {
        if(is.rule(assertion))
           combine-streams( [...], infer(goal,substitutions,cdr(kb))
        else
           cons-stream(match,infer(goal,substitutions,cdr(kb))
     }
   }
}

I ask this question because I sometimes encounter infinite recursion in
testing my code. I think that the problem might come from differences
between the Common LISP and R evaluation models.

--------------------------------------------------------------------
Gabriel Baud-Bovy
Faculty of Psychology
UHSR University
via Olgettina, 58	tel: (+39) 02 2643 4839
20132 Milan, Italy	fax: (+39) 02 2643 4892



From MSchwartz at medanalytics.com  Thu Feb 12 14:59:34 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 12 Feb 2004 07:59:34 -0600
Subject: [R] R-help
In-Reply-To: <20040212073615.5bdf9c25.feh3k@spamcop.net>
References: <OFBFE7316D.09A3C0AE-ONC1256E38.003D5CCD@codan.dk>
	<20040212073615.5bdf9c25.feh3k@spamcop.net>
Message-ID: <1076594374.14423.13.camel@localhost.localdomain>

On Thu, 2004-02-12 at 06:36, Frank E Harrell Jr wrote:
> On Thu, 12 Feb 2004 12:12:01 +0100
> Jim Gustafsson <jgu at codan.dk> wrote:
> 
> > Hi,
> > I have a problem.
> > I would like to put my SAS-code into R.
> > Could I do that, if yes, how?
> > 
> > 
> > Best regards
> > Jim Gustafsson
> 
> Just reverse the procedure you use when you put R code into SAS.   ;)


This reminds me of a quote from Albert Einstein:

"The significant problems we face cannot be solved at the same level of
thinking we were at when we created them."

;-)


Jim, just for clarification, do you truly mean the SAS *code* or did you
mean the SAS *dataset*?

If the former, as you are probably picking up, no go. There is no direct
translation. It would be like expecting a C compiler to compile Fortan
code.

If the latter, see either read.ssd() and friends in the 'foreign'
package, which is part of the typical R install OR see Frank's sas.get()
function in the Hmisc package on CRAN. In both cases, you will need an
executable copy of SAS available.

HTH,

Marc Schwartz



From rodrigo.abt at sii.cl  Thu Feb 12 15:01:19 2004
From: rodrigo.abt at sii.cl (Rodrigo Abt)
Date: Thu, 12 Feb 2004 11:01:19 -0300
Subject: [R] AGREP
Message-ID: <000001c3f170$b106cd30$2a01240a@rodrigoabt>

"Marcos Sanches" <marcos.sanches at ipsos-opinion.com.br> writes:

>Hi listers
>
>If you don't know what is the Edit Distance beetwen two strings, I will
>try to explain, in fact it is very simple to understund but not to
>calculate througth a program. It is simplilly the minimum number of
>operations you must perform to transform string A on string B, by
>operations I mean delete letters, insert letters or substitute letter.
>
>If you need to do few operations, it means string A is almost the same
>as string B. Otherwise they are more differente as the number of
>operations increase.
>
>If you have a idea of how to make a function to calculate this distance,
>it would be very important for me.
>
>Thanks very much,
>
>Marcos

I guess you're looking for Levenshtein distance, so try this:

levenshtein<-function(s1,s2) {
	# Make sure args are strings
	a<-as.character(s1);an=nchar(s1)+1
	b<-as.character(s2);bn=nchar(s2)+1

	# Initialize matrix for calculations
	m<-matrix(nrow=an,ncol=bn)

	# If one arg is an empty string, returns the length of the other
	if (nchar(a)==0)
		return(nchar(b))
	if (nchar(b)==0)
		return(nchar(a))

	# Matrix initialization
	for (i in 1:an) {
		for (j in 1:bn) {
			m[i,j]<-0
			m[1,j]<-j
		}
		m[i,1]<-i
	}

	# Cost calculation
	for (i in 2:an) {
		for (j in 2:bn) {
			if (substr(a,i-1,i-1)==substr(b,j-1,j-1))
				cost<-0
			else
				cost<-1
		m[i,j]=min(m[i-1,j]+1,m[i,j-1]+1,m[i-1,j-1]+cost)
		}
	}
	# Returns the distance
	m[an,bn]-1
}

Examples:

> levenshtein("Great","Grreat")		<-- One addition
[1] 1
> levenshtein("mahrcoz","Marcos")         <-- One substitution,one deletion
and one substitution
[1] 3

Note that this function IS case sensitive. If you want to apply this on
vectors of strings you'll have to write the
corresponding wrapper function.

Hope that helps,

Rodrigo Abt B,
Analyst,
Dept. Economic Studies,
SII, Chile.



From partha_bagchi at hgsi.com  Thu Feb 12 15:17:15 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Thu, 12 Feb 2004 09:17:15 -0500
Subject: [R] R-help
Message-ID: <OF716453DE.CDD3F4A5-ON85256E38.004E59B1-85256E38.004E7BBF@hgsi.com>

Perhaps he means that he wants to translate SAS code to R code? I couldn't 
tell from the email. If you want to execute SAS code from R, you can 
definitely do what you suggest (tongue in cheek perhaps) but still 
legitimate question?





"Liaw, Andy" <andy_liaw at merck.com>
Sent by: r-help-bounces at stat.math.ethz.ch
02/12/2004 08:17 AM

 
        To:     "'Jim Gustafsson'" <jgu at codan.dk>, r-help at stat.math.ethz.ch
        cc: 
        Subject:        RE: [R] R-help


[Sorry.  Just can't resist...]

Probably quite easy.  Something like:

system("sas mysascode.sas")

Andy

> From: Jim Gustafsson
>
> Hi,
> I have a problem.
> I would like to put my SAS-code into R.
> Could I do that, if yes, how?
>
>
> Best regards
> Jim Gustafsson
> ______________________________________________________________
> _________________
> Codan Insurance, Gammel Kongevej 60, DK-1790 Copenhagen V
> telephone: +45 33 55 55 55, fax: +45 33 55 21 22
> e-mail: jgu at codan.dk
> http://www.codan.dk
>       [[alternative HTML version deleted]]
>


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

--
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From luke at stat.uiowa.edu  Thu Feb 12 15:50:06 2004
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 12 Feb 2004 08:50:06 -0600 (CST)
Subject: [R] Porting let* from Common LISP to R
In-Reply-To: <5.2.1.1.1.20040212142504.00b71850@mail.hsr.it>
Message-ID: <Pine.LNX.4.44.0402120843360.31095-100000@itasca2.stat.uiowa.edu>

Just creating variables with assignments is essentialy the same as
let*.  If you need to limit the scope of the variables to part of a
function you can use local(); just remember to use <<- if you want to
change the value of a variable outside the local().

Most Comman Lisp systems have higher default stack limits than R; when
I do lisp-style things I bump up the R stack limit
(options(expressions)) to 1000 or 2000.  Don't go too high or you may
overflow the C stack, which will cause a segmentation fault.  If your
C stack setting is too low, as it is by default in Mac OS X you may
need to increase that at the OS level.  R's lazy evaluation of
arguments also causes different stack usage patterns in recursive
code; sometimes more stack is needed, sometimes less--depends on the
code.

Hope that helps.

luke

On Thu, 12 Feb 2004, Gabriel Baud-Bovy wrote:

> 
> In porting some Common LISP code to R, I am trying to found out whether special
> care must be taken for the let* function. In Common LISP, "the let* block 
> is like
> let except it is guaranteed to evaluate the initialization of its local
> variables in sequentially nested scopes, i.e. it provides an order to the
> binding and visibility of preceding variables.".
> 
> I have included the recursive Common LISP function in which let* block appears
> and a straighforward R port.
> 
> Thank you,
> 
> Gabriel Baud-Bovy
> 
> 
> The let* block appears in the following LISP function:
> 
> (defun infer (goal subsitution kb)
>    (if(null kb)
>      (make-empty-stream)
>      (let* ((assertion (rename-variable (car kb)))    ; *********
>             (match ([...])))
>            (if (equal match 'failed)
>               (infer goal substitutions (cdr kb))
>               (if (rulep assertion)
>                  (combine-streams ([...]) (infer goal substitutions (cdr kb)))
>                  (cons-stream match (infer goal substitutions (cdr kb))))))))
> 
> A straighforward R-translation would be
> 
> infer<-function(goal,subsitution,kb) {
>    if(is.null(kb)) make-empty-stream()
>    else {
>      assertion<-rename-variable(car(kb))
>      match<- [...]
>      if(match=="failed") infer(goal,substitutions,cdr(kb))
>      else  {
>         if(is.rule(assertion))
>            combine-streams( [...], infer(goal,substitutions,cdr(kb))
>         else
>            cons-stream(match,infer(goal,substitutions,cdr(kb))
>      }
>    }
> }
> 
> I ask this question because I sometimes encounter infinite recursion in
> testing my code. I think that the problem might come from differences
> between the Common LISP and R evaluation models.
> 
> --------------------------------------------------------------------
> Gabriel Baud-Bovy
> Faculty of Psychology
> UHSR University
> via Olgettina, 58	tel: (+39) 02 2643 4839
> 20132 Milan, Italy	fax: (+39) 02 2643 4892
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From f.calboli at ucl.ac.uk  Thu Feb 12 16:41:14 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 12 Feb 2004 15:41:14 +0000
Subject: [R] left eigenvector
Message-ID: <1076600474.2961.3.camel@monkey>

Dear All,

how do I compute the left eigenvector of a matrix? I gather that "eigen"
computes the right eigenvectors...

Regards,

Federico Calboli
-- 



=================================

Federico C. F. Calboli

PLEASE NOTE NEW ADDRESS

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 251 208

f.calboli at ucl.ac.uk



From ggrothendieck at myway.com  Thu Feb 12 16:06:46 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 12 Feb 2004 10:06:46 -0500 (EST)
Subject: [R] AGREP
Message-ID: <20040212150646.5D9B3399A@mprdmxin.myway.com>




One could shorten it slightly with these minor improvements.  Unfortunately, the key performance problem, the double loop 
at the end which implements the dynamic programming calculation, 
is still there.

levenshtein<-function(s1,s2) {
     # Make sure args are strings
     a <- as.character(s1); an <- nchar(s1)+1
     b <- as.character(s2); bn <- nchar(s2)+1

     # If one arg is an empty string, returns the length of the other
     if (nchar(a)==0) return(nchar(b))
     if (nchar(b)==0) return(nchar(a))

     # Initialize matrix for calculations
     m <- matrix(0, nrow=an, ncol=bn)
     m[1,] <- 1:bn
     m[,1] <- 1:an 

     # Cost calculation - line beginning (substr... is 0-1 cost f'n
     for (i in 2:an) 
          for (j in 2:bn) 
		  m[i,j] <- min( m[i-1,j]+1, m[i,j-1]+1, m[i-1,j-1]+
		       (substr(a,i-1,i-1)!=substr(b,j-1,j-1)) ) 

     # Returns the distance
     m[an,bn]-1
}

---
Date:   Thu, 12 Feb 2004 11:01:19 -0300 
From:   Rodrigo Abt <rodrigo.abt at sii.cl>
To:   'Lista de Correo de R' <r-help at stat.math.ethz.ch> 
Subject:   Re: [R] AGREP 

 
"Marcos Sanches" <marcos.sanches at ipsos-opinion.com.br> writes:

>Hi listers
>
>If you don't know what is the Edit Distance beetwen two strings, I will
>try to explain, in fact it is very simple to understund but not to
>calculate througth a program. It is simplilly the minimum number of
>operations you must perform to transform string A on string B, by
>operations I mean delete letters, insert letters or substitute letter.
>
>If you need to do few operations, it means string A is almost the same
>as string B. Otherwise they are more differente as the number of
>operations increase.
>
>If you have a idea of how to make a function to calculate this distance,
>it would be very important for me.
>
>Thanks very much,
>
>Marcos

I guess you're looking for Levenshtein distance, so try this:

levenshtein<-function(s1,s2) {
     # Make sure args are strings
     a<-as.character(s1);an=nchar(s1)+1
     b<-as.character(s2);bn=nchar(s2)+1

     # Initialize matrix for calculations
     m<-matrix(nrow=an,ncol=bn)

     # If one arg is an empty string, returns the length of the other
     if (nchar(a)==0)
          return(nchar(b))
     if (nchar(b)==0)
          return(nchar(a))

     # Matrix initialization
     for (i in 1:an) {
          for (j in 1:bn) {
               m[i,j]<-0
               m[1,j]<-j
          }
          m[i,1]<-i
     }

     # Cost calculation
     for (i in 2:an) {
          for (j in 2:bn) {
               if (substr(a,i-1,i-1)==substr(b,j-1,j-1))
                    cost<-0
               else
                    cost<-1
          m[i,j]=min(m[i-1,j]+1,m[i,j-1]+1,m[i-1,j-1]+cost)
          }
     }
     # Returns the distance
     m[an,bn]-1
}

Examples:

> levenshtein("Great","Grreat")          <-- One addition
[1] 1
> levenshtein("mahrcoz","Marcos") <-- One substitution,one deletion
and one substitution
[1] 3

Note that this function IS case sensitive. If you want to apply this on
vectors of strings you'll have to write the
corresponding wrapper function.

Hope that helps,

Rodrigo Abt B,
Analyst,
Dept. Economic Studies,
SII, Chile.



From tblackw at umich.edu  Thu Feb 12 16:39:10 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Thu, 12 Feb 2004 10:39:10 -0500 (EST)
Subject: [R] left eigenvector
In-Reply-To: <1076600474.2961.3.camel@monkey>
References: <1076600474.2961.3.camel@monkey>
Message-ID: <Pine.SOL.4.58.0402121034450.8254@rygar.gpcc.itd.umich.edu>

Federico  -

If a matrix is symmetric, its left and right eigenvectors are identical.
If a matrix is not symmetric, its left eigenvector is the right eigenvector
of its transpose.  However, without checking, I don't recall which R functions
will return the correct right eigenvectors for a non-symmetric matrix.

-  best  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 12 Feb 2004, Federico Calboli wrote:

> Dear All,
>
> how do I compute the left eigenvector of a matrix? I gather that "eigen"
> computes the right eigenvectors...
>
> Regards,
>
> Federico Calboli
> --
>
>
>
> =================================
>
> Federico C. F. Calboli
>
> PLEASE NOTE NEW ADDRESS
>
> Dipartimento di Biologia
> Via Selmi 3
> 40126 Bologna
> Italy
>
> tel (+39) 051 209 4187
> fax (+39) 051 251 208
>
> f.calboli at ucl.ac.uk
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From macq at llnl.gov  Thu Feb 12 16:45:42 2004
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 12 Feb 2004 07:45:42 -0800
Subject: [R] calling R from a shell script and have it display graphics
In-Reply-To: <402B5C26.90706@lscp.ehess.fr>
References: <402B5C26.90706@lscp.ehess.fr>
Message-ID: <p06002001bc514f2c36e7@[128.115.153.6]>

I don't know about the "simpler" part, but you could use the tcltk 
package to put up a window that prompts the user to continue.

-Don


At 11:57 AM +0100 2/12/04, Christophe Pallier wrote:
>Hello,
>
>I am running R under Linux/x11.
>
>I would like to call R from a shell script and have it display a 
>series of graphics.
>The graphics should remain visible until the user clicks or presses a key.
>
>I first tried R BATCH, but it does not load the x11 module, making 
>it impossible to open x11 or png devices.
>
>Then, I tried to call R with a 'here' script:
>
>R --vanilla --quiet --args text.txt <<'EOF'
>file=commandArgs()[5]
>cat('processing ',file,'\n')
>...
>x11()
>plot(f2,log='xy',type='b',las=1,cex=.5,xlab='rang',ylab='freq')
>Sys.sleep(10)
>q()
>EOF
>
>The problem with this approach is that the script cannot interact 
>with the user.
>par(ask=T) will fail because it reads input from the script rather 
>than from the keyboard.
>
>While I am writing this, a solution comes to my mind: I could save 
>all the graphics in png format (using R <script.R), and when it is 
>finished, call ImageMagick's display to show all the png (or use any 
>other diaporama system). However, I find it a dirty hack.
>
>Is there a simpler and cleaner way to achieve this?
>
>Christophe Pallier
>www.pallier.org
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From marcos.sanches at ipsos-opinion.com.br  Thu Feb 12 18:06:09 2004
From: marcos.sanches at ipsos-opinion.com.br (Marcos Sanches)
Date: Thu, 12 Feb 2004 14:06:09 -0300
Subject: RES: [R] AGREP
In-Reply-To: <20040212150646.5D9B3399A@mprdmxin.myway.com>
Message-ID: <001a01c3f18a$82dedb90$d297a8c0@opinionserver>

Thanks very much, this function is just what I am looking for!!!

Marcos

-----Mensagem original-----
De: Gabor Grothendieck [mailto:ggrothendieck at myway.com] 
Enviada em: quinta-feira, 12 de fevereiro de 2004 12:07
Para: rodrigo.abt at sii.cl; r-help at stat.math.ethz.ch
Cc: marcos.sanches at ipsos-opinion.com.br
Assunto: Re: [R] AGREP





One could shorten it slightly with these minor improvements.
Unfortunately, the key performance problem, the double loop 
at the end which implements the dynamic programming calculation, 
is still there.

levenshtein<-function(s1,s2) {
     # Make sure args are strings
     a <- as.character(s1); an <- nchar(s1)+1
     b <- as.character(s2); bn <- nchar(s2)+1

     # If one arg is an empty string, returns the length of the other
     if (nchar(a)==0) return(nchar(b))
     if (nchar(b)==0) return(nchar(a))

     # Initialize matrix for calculations
     m <- matrix(0, nrow=an, ncol=bn)
     m[1,] <- 1:bn
     m[,1] <- 1:an 

     # Cost calculation - line beginning (substr... is 0-1 cost f'n
     for (i in 2:an) 
          for (j in 2:bn) 
		  m[i,j] <- min( m[i-1,j]+1, m[i,j-1]+1, m[i-1,j-1]+
		       (substr(a,i-1,i-1)!=substr(b,j-1,j-1)) ) 

     # Returns the distance
     m[an,bn]-1
}

---
Date:   Thu, 12 Feb 2004 11:01:19 -0300 
From:   Rodrigo Abt <rodrigo.abt at sii.cl>
To:   'Lista de Correo de R' <r-help at stat.math.ethz.ch> 
Subject:   Re: [R] AGREP 

 
"Marcos Sanches" <marcos.sanches at ipsos-opinion.com.br> writes:

>Hi listers
>
>If you don't know what is the Edit Distance beetwen two strings, I will

>try to explain, in fact it is very simple to understund but not to 
>calculate througth a program. It is simplilly the minimum number of 
>operations you must perform to transform string A on string B, by 
>operations I mean delete letters, insert letters or substitute letter.
>
>If you need to do few operations, it means string A is almost the same 
>as string B. Otherwise they are more differente as the number of 
>operations increase.
>
>If you have a idea of how to make a function to calculate this 
>distance, it would be very important for me.
>
>Thanks very much,
>
>Marcos

I guess you're looking for Levenshtein distance, so try this:

levenshtein<-function(s1,s2) {
     # Make sure args are strings
     a<-as.character(s1);an=nchar(s1)+1
     b<-as.character(s2);bn=nchar(s2)+1

     # Initialize matrix for calculations
     m<-matrix(nrow=an,ncol=bn)

     # If one arg is an empty string, returns the length of the other
     if (nchar(a)==0)
          return(nchar(b))
     if (nchar(b)==0)
          return(nchar(a))

     # Matrix initialization
     for (i in 1:an) {
          for (j in 1:bn) {
               m[i,j]<-0
               m[1,j]<-j
          }
          m[i,1]<-i
     }

     # Cost calculation
     for (i in 2:an) {
          for (j in 2:bn) {
               if (substr(a,i-1,i-1)==substr(b,j-1,j-1))
                    cost<-0
               else
                    cost<-1
          m[i,j]=min(m[i-1,j]+1,m[i,j-1]+1,m[i-1,j-1]+cost)
          }
     }
     # Returns the distance
     m[an,bn]-1
}

Examples:

> levenshtein("Great","Grreat")          <-- One addition
[1] 1
> levenshtein("mahrcoz","Marcos") <-- One substitution,one deletion
and one substitution
[1] 3

Note that this function IS case sensitive. If you want to apply this on
vectors of strings you'll have to write the corresponding wrapper
function.

Hope that helps,

Rodrigo Abt B,
Analyst,
Dept. Economic Studies,
SII, Chile.



From Icabalceta_j at wlf.state.la.us  Thu Feb 12 17:06:41 2004
From: Icabalceta_j at wlf.state.la.us (Icabalceta, Jorge L.)
Date: Thu, 12 Feb 2004 10:06:41 -0600
Subject: [R] How do you create a "MCMC" object?
Message-ID: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0BB@wlfnt1.wlf.state.la.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040212/5aae2951/attachment.pl

From spencer.graves at pdf.com  Thu Feb 12 17:09:07 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 12 Feb 2004 08:09:07 -0800
Subject: [R] left eigenvector
In-Reply-To: <Pine.SOL.4.58.0402121034450.8254@rygar.gpcc.itd.umich.edu>
References: <1076600474.2961.3.camel@monkey>
	<Pine.SOL.4.58.0402121034450.8254@rygar.gpcc.itd.umich.edu>
Message-ID: <402BA523.3010609@pdf.com>

      What about the following: 

 > A <- array(1:4, dim=c(2,2))
 > leftA <- eigen(t(A))
 > t(leftA$vectors)
           [,1]       [,2]
[1,] -0.4159736 -0.9093767
[2,] -0.8245648  0.5657675

      hope this helps.  spencer graves

Tom Blackwell wrote:

>Federico  -
>
>If a matrix is symmetric, its left and right eigenvectors are identical.
>If a matrix is not symmetric, its left eigenvector is the right eigenvector
>of its transpose.  However, without checking, I don't recall which R functions
>will return the correct right eigenvectors for a non-symmetric matrix.
>
>-  best  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
>
>On Thu, 12 Feb 2004, Federico Calboli wrote:
>
>  
>
>>Dear All,
>>
>>how do I compute the left eigenvector of a matrix? I gather that "eigen"
>>computes the right eigenvectors...
>>
>>Regards,
>>
>>Federico Calboli
>>--
>>
>>
>>
>>=================================
>>
>>Federico C. F. Calboli
>>
>>PLEASE NOTE NEW ADDRESS
>>
>>Dipartimento di Biologia
>>Via Selmi 3
>>40126 Bologna
>>Italy
>>
>>tel (+39) 051 209 4187
>>fax (+39) 051 251 208
>>
>>f.calboli at ucl.ac.uk
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From hb at maths.lth.se  Thu Feb 12 17:11:44 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 12 Feb 2004 17:11:44 +0100
Subject: [R] AGREP
In-Reply-To: <20040212150646.5D9B3399A@mprdmxin.myway.com>
Message-ID: <000901c3f182$e8659600$e502eb82@maths.lth.se>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gabor 
> Grothendieck
> Sent: den 12 februari 2004 16:07
> To: rodrigo.abt at sii.cl; r-help at stat.math.ethz.ch
> Subject: Re: [R] AGREP
> 
> One could shorten it slightly with these minor improvements.  
> Unfortunately, the key performance problem, the double loop 
> at the end which implements the dynamic programming calculation, 
> is still there.
> 
> levenshtein<-function(s1,s2) {
>      # Make sure args are strings
>      a <- as.character(s1); an <- nchar(s1)+1
>      b <- as.character(s2); bn <- nchar(s2)+1
> 
>      # If one arg is an empty string, returns the length of the
other
>      if (nchar(a)==0) return(nchar(b))
>      if (nchar(b)==0) return(nchar(a))
> 
>      # Initialize matrix for calculations
>      m <- matrix(0, nrow=an, ncol=bn)
>      m[1,] <- 1:bn
>      m[,1] <- 1:an 
> 
>      # Cost calculation - line beginning (substr... is 0-1 cost f'n
>      for (i in 2:an) 
>           for (j in 2:bn) 
> 		  m[i,j] <- min( m[i-1,j]+1, m[i,j-1]+1, m[i-1,j-1]+
> 		       (substr(a,i-1,i-1)!=substr(b,j-1,j-1)) ) 
> 
>      # Returns the distance
>      m[an,bn]-1
> }
> 

But a very expensive part of the code though is the substr() calls.
Instead of doing this nchar(a)*nchar(b) times it's enough to do it
nchar(a)+nchar(b). Even better is to use strsplit() first as below:

levenshteinFast <- function(s1,s2) {
  # Make sure args are strings
  a <- as.character(s1)
  b <- as.character(s2)

  # Split strings into vectors
  a <- strsplit(a, split="")[[1]]
  b <- strsplit(b, split="")[[1]]
  
  # If one arg is an empty string, returns the length of the other
  an <- length(a)
  bn <- length(b)
  if (an==0) return(bn)
  if (bn==0) return(an)

  # Initialize matrix for calculations
  m <- matrix(0, nrow=an+1, ncol=bn+1)
  m[1,] <- 1:(bn+1)
  m[,1] <- 1:(an+1)

  # Cost calculation - line beginning (substr... is 0-1 cost f'n
  for (i in 2:(an+1)) {
    for (j in 2:(bn+1)) {
      m[i,j] <- min(m[i-1,j  ] + 1,
                    m[i  ,j-1] + 1,
                    m[i-1,j-1] + !identical(a[i-1],b[j-1]))
    }
  }

  # Returns the distance
  m[an+1,bn+1]-1;
} # levenshteinFast()


# Example
N <- 500
s1 <- sample(letters, size=N, replace=TRUE)
s1 <- paste(s1, collapse="")
s2 <- sample(letters, size=N, replace=TRUE)
s2 <- paste(s2, collapse="")

t1 <- system.time(dist1 <- levenshtein(s1,s2))
print(c(t1,dist1))
# [1]  46.83   0.23  54.24     NA     NA 443.00

t2 <- system.time(dist2 <- levenshteinFast(s1,s2))
print(c(t2,dist2))
# [1]  18.82   0.07  20.90     NA     NA 443.00

/Henrik

> ---
> Date:   Thu, 12 Feb 2004 11:01:19 -0300 
> From:   Rodrigo Abt <rodrigo.abt at sii.cl>
> To:   'Lista de Correo de R' <r-help at stat.math.ethz.ch> 
> Subject:   Re: [R] AGREP 
> 
>  
> "Marcos Sanches" <marcos.sanches at ipsos-opinion.com.br> writes:
> 
> >Hi listers
> >
> >If you don't know what is the Edit Distance beetwen two 
> strings, I will 
> >try to explain, in fact it is very simple to understund but not to 
> >calculate througth a program. It is simplilly the minimum number of

> >operations you must perform to transform string A on string B, by 
> >operations I mean delete letters, insert letters or 
> substitute letter.
> >
> >If you need to do few operations, it means string A is 
> almost the same 
> >as string B. Otherwise they are more differente as the number of 
> >operations increase.
> >
> >If you have a idea of how to make a function to calculate this 
> >distance, it would be very important for me.
> >
> >Thanks very much,
> >
> >Marcos
> 
> I guess you're looking for Levenshtein distance, so try this:
> 
> levenshtein<-function(s1,s2) {
>      # Make sure args are strings
>      a<-as.character(s1);an=nchar(s1)+1
>      b<-as.character(s2);bn=nchar(s2)+1
> 
>      # Initialize matrix for calculations
>      m<-matrix(nrow=an,ncol=bn)
> 
>      # If one arg is an empty string, returns the length of the
other
>      if (nchar(a)==0)
>           return(nchar(b))
>      if (nchar(b)==0)
>           return(nchar(a))
> 
>      # Matrix initialization
>      for (i in 1:an) {
>           for (j in 1:bn) {
>                m[i,j]<-0
>                m[1,j]<-j
>           }
>           m[i,1]<-i
>      }
> 
>      # Cost calculation
>      for (i in 2:an) {
>           for (j in 2:bn) {
>                if (substr(a,i-1,i-1)==substr(b,j-1,j-1))
>                     cost<-0
>                else
>                     cost<-1
>           m[i,j]=min(m[i-1,j]+1,m[i,j-1]+1,m[i-1,j-1]+cost)
>           }
>      }
>      # Returns the distance
>      m[an,bn]-1
> }
> 
> Examples:
> 
> > levenshtein("Great","Grreat")          <-- One addition
> [1] 1
> > levenshtein("mahrcoz","Marcos") <-- One substitution,one deletion
> and one substitution
> [1] 3
> 
> Note that this function IS case sensitive. If you want to 
> apply this on vectors of strings you'll have to write the 
> corresponding wrapper function.
> 
> Hope that helps,
> 
> Rodrigo Abt B,
> Analyst,
> Dept. Economic Studies,
> SII, Chile.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From kimm at pet.auh.dk  Thu Feb 12 17:23:49 2004
From: kimm at pet.auh.dk (Kim Mouridsen)
Date: Thu, 12 Feb 2004 17:23:49 +0100
Subject: [R] MARS in classification problem
Message-ID: <000001c3f184$98900be0$ce65030a@pckim>

Dear R-experts

I recently tried out the Salford Systems MARS software on a large
dataset. Apparently MARS outperformed traditional techniques such as
logistic regression and k-nearest-neighbor.

Since I usually perform all my data analyses in R I have installed the
'mda' package but I seem to get much worse results with R than with the
Salford Systems software. 

In my data set I have 7 continuous predictors and a binary outcome. The
training data set has 100.000 samples. I try to use the same parameters
I used in the MARS program: 

mars(x=train.set,y=response,degree=2,nk=80,penalty=3)

With the MARS program I would get GCV values of approximately 0.11 but
with R I get 0.15. The corresponding reduction in area under the
operator characteristics curve (AUC) is from 0.83 to 0.70.

What am I doing wrong?

Thanks in advance!

Kim Mouridsen.



From jjgazaille at yahoo.ca  Thu Feb 12 17:32:02 2004
From: jjgazaille at yahoo.ca (John J. Gazaille)
Date: Thu, 12 Feb 2004 11:32:02 -0500 (EST)
Subject: [R] How to predict ARMA models?
Message-ID: <20040212163202.80801.qmail@web60907.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040212/30fcd193/attachment.pl

From ivo.welch at yale.edu  Thu Feb 12 17:39:51 2004
From: ivo.welch at yale.edu (ivo welch)
Date: Thu, 12 Feb 2004 11:39:51 -0500
Subject: [R] suggestion "suggestion" and dataframe operations
In-Reply-To: <200402121155.i1CBshwg005875@hypatia.math.ethz.ch>
References: <200402121155.i1CBshwg005875@hypatia.math.ethz.ch>
Message-ID: <402BAC57.6060600@yale.edu>


hi chaps:

a simple suggestion:  R tells me who the contributors() are, but this 
should also tell me where I should mail suggestions to.  Is it this 
mailing list?  a repository of suggestions?  an individual?

this came up because i wanted to suggest two small enhancements:

the first is for the summary() method for plain data frames.  it would 
seem to me that the number of "NA"s should be printed as an integer, not 
necessarily in scientific notation.  I have also yet to determine when 
summary() likes to give means and when it does not.  (maybe it was an 
older version that sometimes did not give means).  summary does not seem 
to have optional parameters to specify what statistics I would like. 
this could be useful, too.

another small enhancement:  there are four elementary data frame 
operations that bedevil novices, so they really should have named 
function wrappers:

	delrow( dataframe d, index=45);
	insrow( dataframe d, (row)vector v);
	delcol( dataframe d, "name");
	inscol( dataframe d, (col)vector v);

I looked at my R "bible" (venables&ripley), too, but here too it is not 
as clear as it needs to be.  yes, this may be programmable, but it ain't 
as obvious as it should be for beginners.

regards,

/iaw



From Ted.Harding at nessie.mcc.ac.uk  Thu Feb 12 17:42:36 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 12 Feb 2004 16:42:36 -0000 (GMT)
Subject: [R] R-help
In-Reply-To: <1076594374.14423.13.camel@localhost.localdomain>
Message-ID: <XFMail.040212164236.Ted.Harding@nessie.mcc.ac.uk>

On 12-Feb-04 Marc Schwartz wrote:
> Jim, just for clarification, do you truly mean the SAS *code* or did
> you mean the SAS *dataset*?
> 
> If the former, as you are probably picking up, no go. There is no
> direct translation. It would be like expecting a C compiler to compile
> Fortan code.

Been there, done that ... A lot of Fortran programs can be quite easily
re-structured into C; in the limit, f2c is your friend ... I don't think
SAS could be that easily re-written as R, though; and we certainly do
not have sas2r yet!

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 12-Feb-04                                       Time: 16:42:36
------------------------------ XFMail ------------------------------



From sfalcon at fhcrc.org  Thu Feb 12 18:03:47 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 12 Feb 2004 09:03:47 -0800
Subject: [R] calling R from a shell script and have it display graphics
In-Reply-To: <p06002001bc514f2c36e7@[128.115.153.6]>
References: <402B5C26.90706@lscp.ehess.fr>
	<p06002001bc514f2c36e7@[128.115.153.6]>
Message-ID: <20040212170347.GB21801@queenbee.fhcrc.org>

How about saving to png and writing a small html file and then launching
a browser?



On Thu, Feb 12, 2004 at 07:45:42AM -0800, Don MacQueen wrote:
> I don't know about the "simpler" part, but you could use the tcltk 
> package to put up a window that prompts the user to continue.
> 
> -Don
> 
> 
> At 11:57 AM +0100 2/12/04, Christophe Pallier wrote:
> >Hello,
> >
> >I am running R under Linux/x11.
> >
> >I would like to call R from a shell script and have it display a 
> >series of graphics.
> >The graphics should remain visible until the user clicks or presses a key.
> >
> >I first tried R BATCH, but it does not load the x11 module, making 
> >it impossible to open x11 or png devices.
> >
> >Then, I tried to call R with a 'here' script:
> >
> >R --vanilla --quiet --args text.txt <<'EOF'
> >file=commandArgs()[5]
> >cat('processing ',file,'\n')
> >...
> >x11()
> >plot(f2,log='xy',type='b',las=1,cex=.5,xlab='rang',ylab='freq')
> >Sys.sleep(10)
> >q()
> >EOF
> >
> >The problem with this approach is that the script cannot interact 
> >with the user.
> >par(ask=T) will fail because it reads input from the script rather 
> >than from the keyboard.
> >
> >While I am writing this, a solution comes to my mind: I could save 
> >all the graphics in png format (using R <script.R), and when it is 
> >finished, call ImageMagick's display to show all the png (or use any 
> >other diaporama system). However, I find it a dirty hack.
> >
> >Is there a simpler and cleaner way to achieve this?
> >
> >Christophe Pallier
> >www.pallier.org
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> >http://www.R-project.org/posting-guide.html
> 
> 
> -- 
> --------------------------------------
> Don MacQueen
> Environmental Protection Department
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From MSchwartz at medanalytics.com  Thu Feb 12 18:32:36 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 12 Feb 2004 11:32:36 -0600
Subject: [R] R-help
In-Reply-To: <XFMail.040212164236.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.040212164236.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <1076607156.14423.28.camel@localhost.localdomain>

On Thu, 2004-02-12 at 10:42, Ted.Harding at nessie.mcc.ac.uk wrote:
> On 12-Feb-04 Marc Schwartz wrote:
> > Jim, just for clarification, do you truly mean the SAS *code* or did
> > you mean the SAS *dataset*?
> > 
> > If the former, as you are probably picking up, no go. There is no
> > direct translation. It would be like expecting a C compiler to compile
> > Fortan code.
> 
> Been there, done that ... A lot of Fortran programs can be quite easily
> re-structured into C; in the limit, f2c is your friend ... I don't think
> SAS could be that easily re-written as R, though; and we certainly do
> not have sas2r yet!
> 
> Ted.


Thanks for the clarification Ted. I was more thinking along the lines of
"native" compilation as opposed passing the code to a
filtering/conversion program prior to compilation.

I perhaps could have picked a better example of two languages where an
intermediate filter/conversion program was not available.  :-)

Marc



From jdn at cs.sfu.ca  Thu Feb 12 18:44:36 2004
From: jdn at cs.sfu.ca (Jason Nielsen)
Date: Thu, 12 Feb 2004 09:44:36 -0800 (PST)
Subject: [R] lapply and dynamically linked functions
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF778D@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF778D@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.53.0402120926360.2659@lenny>

I figured this much by looking at the function:

> lapply
function (X, FUN, ...) 
{
    FUN <- match.fun(FUN)
    if (!is.list(X)) 
        X <- as.list(X)
    rval <- .Internal(lapply(X, FUN))
    names(rval) <- names(X)
    return(rval)
}
<environment: namespace:base>

however I have to say that the help page doesn't say anything about this
and it was only once I figured out what the problem was that the
realization dawned on me.  I agree that this may not be a bug but it isn't
consistent with the way in which a normal user interacts with the
interpreter, for instance:

> mean<-4           
> dnorm(mean,mean=3)
[1] 0.2419707
> dnorm(4,mean=3)
[1] 0.2419707

ugly I agree and not something you would do intentionally but something
which is done all the time I'm sure... plot(y,x).  I apparently do it
without thinking about it as my little problem shows... X is a design
matrix I'm passing to a little sim (which of course is now XX) I'm doing
so not really that odd of a variable name.  Since in general you don't
have to be concerned with such things I have gotten lazy about variable
names (I realize this is how lapply passes the list to .Internal lapply in
this case).  I guess my point is that maybe a little blurb in the help
page or perhaps a more useful error message than:

Error in get(x, envir, mode, inherits) : variable "mylist"

which isn't very helpful would be appropriate here.

Cheers,
Jason


On Thu, 12 Feb 2004, Liaw, Andy wrote:

> That's the expected behavior, not a bug, because:
> 
> > args(lapply)
> function (X, FUN, ...) 
> NULL
> 
> so lapply has `X' as an formal argument.  Any calls to lapply() with named
> argument `X=...' will match to that, so the net effect is that the `X=...'
> part gets used by lapply() as the list to operate on, rather than pass down
> to `FUN'.  You might want to read the relevant section of the `R Language
> Definition' manual.
> 
> I believe the argument is deliberately named with capital `X' to avoid
> collision with `x'.
> 
> Andy
> 
> > From: Jason Nielsen
> > 
> > Well I finally figured it out.  After proving to myself that 
> > it wasn't the 
> > Fortran wrapper with a simple example I started to dig into 
> > this.  The 
> > problem is that I was naming one of my parameters X... which 
> > is the name 
> > of the input value in lapply... I'm not sure if this is a bug 
> > or just the 
> > way it works but here is an example:
> > 
> > examplegood<-function(kn,XX)
> > {
> >   out<-sum(kn)*sum(XX)
> >   out
> > }
> > 
> > examplebad<-function(kn,X)
> > {
> >   out<-sum(kn)*sum(X)
> >   out
> > }
> > 
> > mylist<-vector("list")
> > 
> > for(i in 1:5) mylist[[i]]<-i
> > 
> > a<-1:10
> > 
> > Now run lapply and you get:
> > 
> > > lapply(mylist,examplebad,X=a)
> > Error in get(x, envir, mode, inherits) : variable "mylist" 
> > was not found
> > 
> > > lapply(mylist,examplegood,XX=a)
> > [[1]]
> > [1] 55
> > 
> > [[2]]
> > [1] 110
> > 
> > [[3]]
> > [1] 165
> > 
> > [[4]]
> > [1] 220
> > 
> > [[5]]
> > [1] 275
> > 
> > Well there you have it!
> > 
> > Cheers,
> > Jason
> > 
> > 
> > On Wed, 11 Feb 2004, Liaw, Andy wrote:
> > 
> > > My guess is that you probably refer to `mylist' instead of 
> > `x' inside
> > > `myfun'.  Please show us the entire code, rather than leave 
> > us guessing.
> > > 
> > > Andy
> > > 
> > > > From: Jason Nielsen
> > > > 
> > > > Hi all,
> > > > 
> > > > I'm trying to use lapply on a list with the following command:
> > > > 
> > > > out<-lapply(mylist,myfun,par1=p,par2=d)               (1)
> > > > 
> > > > where
> > > > 
> > > > myfun<-function(x,par1,par1) {.....}                  (2)
> > > > 
> > > > now this function is in fact a wrapper for some Fortran 
> > code I have
> > > > written so I think this might be the problem.  When I call 
> > > > lapply() as in
> > > > (1)  I get the following message:
> > > > 
> > > > Error in get(x, envir, mode, inherits) : variable "mylist" 
> > > > was not found
> > > > 
> > > > but if I say do:
> > > > 
> > > > out<-lapply(mylist,sum)
> > > > 
> > > > it returns a nice list with the sums of the elements in 
> > the list.  So
> > > > after all that I guess my question is does this have to do 
> > > > with the fact
> > > > that my function is a wrapper for my Fortran code (which 
> > > > works fine on its
> > > > own.. and if I use a loop as opposed to lapply() )?  I 
> > > > imagine that lapply
> > > > which is a wrapper for the .Internal lapply might have some 
> > > > trouble with
> > > > my Fortran wrapper?  Is this the case or is it something dumb 
> > > > on my end?  
> > > > Any input is appreciated.
> > > > 
> > > > Cheers,
> > > > Jason
> > > > 
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide! 
> > > > http://www.R-project.org/posting-guide.html
> > > > 
> > > > 
> > > 
> > > 
> > > 
> > --------------------------------------------------------------
> > ----------------
> > > Notice:  This e-mail message, together with any 
> > attachments, contains information of Merck & Co., Inc. (One 
> > Merck Drive, Whitehouse Station, New Jersey, USA 08889), 
> > and/or its affiliates (which may be known outside the United 
> > States as Merck Frosst, Merck Sharp & Dohme or MSD and in 
> > Japan, as Banyu) that may be confidential, proprietary 
> > copyrighted and/or legally privileged. It is intended solely 
> > for the use of the individual or entity named on this 
> > message.  If you are not the intended recipient, and have 
> > received this message in error, please notify us immediately 
> > by reply e-mail and then delete it from your system.
> > > 
> > --------------------------------------------------------------
> > ----------------
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments, contains
> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New
> Jersey, USA 08889), and/or its affiliates (which may be known outside the
> United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as
> Banyu) that may be confidential, proprietary copyrighted and/or legally
> privileged. It is intended solely for the use of the individual or entity
> named on this message.  If you are not the intended recipient, and have
> received this message in error, please notify us immediately by reply e-mail
> and then delete it from your system.
> ------------------------------------------------------------------------------
>



From dmurdoch at pair.com  Thu Feb 12 20:27:53 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 12 Feb 2004 14:27:53 -0500
Subject: [R] How do you create a "MCMC" object?
In-Reply-To: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0BB@wlfnt1.wlf.state.la.us>
References: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0BB@wlfnt1.wlf.state.la.us>
Message-ID: <pmkn20hqi33rj2s1rpn0jhknsfir7ma27m@4ax.com>

On Thu, 12 Feb 2004 10:06:41 -0600, "Icabalceta, Jorge L."
<Icabalceta_j at wlf.state.la.us> wrote :

>I have been running a Gibbs Sampler to estimate levels of efficiency in the
>Louisiana Shrimp Industry. I created a matrix (samp) where I stored the
>results of each iteration for 86 variables. I run 10,000 iterations. So, the
>matrix samp is 10,000 x 86. I want to use the gelman-rubin test to check for
>convergence. To do that, I need at least two chains. If I run second chain
>with different starting values and seed, I could save to the matrix 'samp2'.
>So, I will have two matrices 10,000x86. I want to use the function
>gelman.diag(x, confidence = 0.95, transform=FALSE), where x: An 'mcmc.list'
>object with more than one chain, and with starting values that are
>overdispersed with respect to the posterior distribution. How do I create
>mcmc object from these matrices? I need to create an mcmc object with the
>two chains I have stored in 'samp' and 'samp2'.
>Thanks for your help and attention.

I think you're asking about functions from the coda package.

The normal way to create an MCMC object is to read BUGS output, but
it's probably not hard to create one from your own data.  There's a
function called "as.mcmc" which looks like it should do what you need;
if not, you might want to write to the coda maintainer, Martyn Plummer
<plummer at iarc.fr>.

Duncan Murdoch



From marcos.sanches at ipsos-opinion.com.br  Thu Feb 12 21:35:54 2004
From: marcos.sanches at ipsos-opinion.com.br (Marcos Sanches)
Date: Thu, 12 Feb 2004 17:35:54 -0300
Subject: RES: [R] AGREP
In-Reply-To: <000901c3f182$e8659600$e502eb82@maths.lth.se>
Message-ID: <002001c3f1a7$d03c6fc0$d297a8c0@opinionserver>


Hi Henrik,

	Your function is really faster, but I tested it to solve my
problem. And I found it is too time consuming yet for me. This happens
because I need to compare strings from two very large vectors. Bellow I
wrote the syntax I have to use:

##########################

Ls1<-length(s1)
Ls2<-length(s2) 
for ( p in 1:ls1){
   for (q in 1:ls2){
     t1<-levenshteinFast(s1[p],s2[q])
     if (t1<s12[p]){
       s12[p]<-s2[q]
       n12[q]<-t1}
   }
}

#############################

If you want to have na idea, the size of my loop are:

Ls1=42000
Ls2=70000

I think I will wait for months untill this program ends. Do you have any
sugestion to increase the speed? The AGREP function is much faster, and
I am using it, but I don't have a efficient comparation because
AGREP(a,b) is not equal AGREP(b,a). 

Thanks,

Marcos



-----Mensagem original-----
De: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] Em nome de Henrik Bengtsson
Enviada em: quinta-feira, 12 de fevereiro de 2004 13:12
Para: ggrothendieck at myway.com; rodrigo.abt at sii.cl;
r-help at stat.math.ethz.ch
Assunto: RE: [R] AGREP


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gabor 
> Grothendieck
> Sent: den 12 februari 2004 16:07
> To: rodrigo.abt at sii.cl; r-help at stat.math.ethz.ch
> Subject: Re: [R] AGREP
> 
> One could shorten it slightly with these minor improvements.
> Unfortunately, the key performance problem, the double loop 
> at the end which implements the dynamic programming calculation, 
> is still there.
> 
> levenshtein<-function(s1,s2) {
>      # Make sure args are strings
>      a <- as.character(s1); an <- nchar(s1)+1
>      b <- as.character(s2); bn <- nchar(s2)+1
> 
>      # If one arg is an empty string, returns the length of the
other
>      if (nchar(a)==0) return(nchar(b))
>      if (nchar(b)==0) return(nchar(a))
> 
>      # Initialize matrix for calculations
>      m <- matrix(0, nrow=an, ncol=bn)
>      m[1,] <- 1:bn
>      m[,1] <- 1:an
> 
>      # Cost calculation - line beginning (substr... is 0-1 cost f'n
>      for (i in 2:an) 
>           for (j in 2:bn) 
> 		  m[i,j] <- min( m[i-1,j]+1, m[i,j-1]+1, m[i-1,j-1]+
> 		       (substr(a,i-1,i-1)!=substr(b,j-1,j-1)) )
> 
>      # Returns the distance
>      m[an,bn]-1
> }
> 

But a very expensive part of the code though is the substr() calls.
Instead of doing this nchar(a)*nchar(b) times it's enough to do it
nchar(a)+nchar(b). Even better is to use strsplit() first as below:

levenshteinFast <- function(s1,s2) {
  # Make sure args are strings
  a <- as.character(s1)
  b <- as.character(s2)

  # Split strings into vectors
  a <- strsplit(a, split="")[[1]]
  b <- strsplit(b, split="")[[1]]
  
  # If one arg is an empty string, returns the length of the other
  an <- length(a)
  bn <- length(b)
  if (an==0) return(bn)
  if (bn==0) return(an)

  # Initialize matrix for calculations
  m <- matrix(0, nrow=an+1, ncol=bn+1)
  m[1,] <- 1:(bn+1)
  m[,1] <- 1:(an+1)

  # Cost calculation - line beginning (substr... is 0-1 cost f'n
  for (i in 2:(an+1)) {
    for (j in 2:(bn+1)) {
      m[i,j] <- min(m[i-1,j  ] + 1,
                    m[i  ,j-1] + 1,
                    m[i-1,j-1] + !identical(a[i-1],b[j-1]))
    }
  }

  # Returns the distance
  m[an+1,bn+1]-1;
} # levenshteinFast()


# Example
N <- 500
s1 <- sample(letters, size=N, replace=TRUE)
s1 <- paste(s1, collapse="")
s2 <- sample(letters, size=N, replace=TRUE)
s2 <- paste(s2, collapse="")

t1 <- system.time(dist1 <- levenshtein(s1,s2))
print(c(t1,dist1))
# [1]  46.83   0.23  54.24     NA     NA 443.00

t2 <- system.time(dist2 <- levenshteinFast(s1,s2))
print(c(t2,dist2))
# [1]  18.82   0.07  20.90     NA     NA 443.00

/Henrik

> ---
> Date:   Thu, 12 Feb 2004 11:01:19 -0300 
> From:   Rodrigo Abt <rodrigo.abt at sii.cl>
> To:   'Lista de Correo de R' <r-help at stat.math.ethz.ch> 
> Subject:   Re: [R] AGREP 
> 
>  
> "Marcos Sanches" <marcos.sanches at ipsos-opinion.com.br> writes:
> 
> >Hi listers
> >
> >If you don't know what is the Edit Distance beetwen two
> strings, I will
> >try to explain, in fact it is very simple to understund but not to
> >calculate througth a program. It is simplilly the minimum number of

> >operations you must perform to transform string A on string B, by
> >operations I mean delete letters, insert letters or 
> substitute letter.
> >
> >If you need to do few operations, it means string A is
> almost the same
> >as string B. Otherwise they are more differente as the number of
> >operations increase.
> >
> >If you have a idea of how to make a function to calculate this
> >distance, it would be very important for me.
> >
> >Thanks very much,
> >
> >Marcos
> 
> I guess you're looking for Levenshtein distance, so try this:
> 
> levenshtein<-function(s1,s2) {
>      # Make sure args are strings
>      a<-as.character(s1);an=nchar(s1)+1
>      b<-as.character(s2);bn=nchar(s2)+1
> 
>      # Initialize matrix for calculations
>      m<-matrix(nrow=an,ncol=bn)
> 
>      # If one arg is an empty string, returns the length of the
other
>      if (nchar(a)==0)
>           return(nchar(b))
>      if (nchar(b)==0)
>           return(nchar(a))
> 
>      # Matrix initialization
>      for (i in 1:an) {
>           for (j in 1:bn) {
>                m[i,j]<-0
>                m[1,j]<-j
>           }
>           m[i,1]<-i
>      }
> 
>      # Cost calculation
>      for (i in 2:an) {
>           for (j in 2:bn) {
>                if (substr(a,i-1,i-1)==substr(b,j-1,j-1))
>                     cost<-0
>                else
>                     cost<-1
>           m[i,j]=min(m[i-1,j]+1,m[i,j-1]+1,m[i-1,j-1]+cost)
>           }
>      }
>      # Returns the distance
>      m[an,bn]-1
> }
> 
> Examples:
> 
> > levenshtein("Great","Grreat")          <-- One addition
> [1] 1
> > levenshtein("mahrcoz","Marcos") <-- One substitution,one deletion
> and one substitution
> [1] 3
> 
> Note that this function IS case sensitive. If you want to
> apply this on vectors of strings you'll have to write the 
> corresponding wrapper function.
> 
> Hope that helps,
> 
> Rodrigo Abt B,
> Analyst,
> Dept. Economic Studies,
> SII, Chile.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From rxg218 at psu.edu  Thu Feb 12 20:42:12 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Thu, 12 Feb 2004 14:42:12 -0500
Subject: [R] variances of values predicted using a lm object
Message-ID: <1076614932.14334.4.camel@ra.chem.psu.edu>

Hi,
  is there a function in R that will give me the variances of a
predicted values obtained using predict.lm().

If no function is available I would need to calculate them myself -
which involves taking the inverse of X'X (' indicating transpose)
where X is my model matrix. I know that calculating an inverse directly
is not a good idea in general - could anybody suggest a way around this?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
If you believe in telekinesis, raise my hand.



From miramos at ucdavis.edu  Thu Feb 12 20:49:18 2004
From: miramos at ucdavis.edu (Marisa Ramos)
Date: Thu, 12 Feb 2004 11:49:18 -0800
Subject: [R] Basic Help
Message-ID: <6.0.1.1.2.20040212114736.02adde80@mailbox.ucdavis.edu>

OK I have been trying to learn how to use this program and I cannot even 
import any data into it.  I have downloaded all the manuals but they do not 
seem to help.  Is there a book on R for dummies???



From sundar.dorai-raj at pdf.com  Thu Feb 12 20:50:36 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 12 Feb 2004 11:50:36 -0800
Subject: [R] variances of values predicted using a lm object
In-Reply-To: <1076614932.14334.4.camel@ra.chem.psu.edu>
References: <1076614932.14334.4.camel@ra.chem.psu.edu>
Message-ID: <402BD90C.7080003@pdf.com>



Rajarshi Guha wrote:
> Hi,
>   is there a function in R that will give me the variances of a
> predicted values obtained using predict.lm().
> 
> If no function is available I would need to calculate them myself -
> which involves taking the inverse of X'X (' indicating transpose)
> where X is my model matrix. I know that calculating an inverse directly
> is not a good idea in general - could anybody suggest a way around this?
> 
> Thanks,
> 

 From ?predict.lm:

<quote>
Details:

      'predict.lm' produces predicted values, obtained by evaluating the
      regression function in the frame 'newdata' (which defaults to
      'model.frame(object)'.  If the logical 'se.fit' is 'TRUE',
      standard errors of the predictions are calculated.
</quote>

Is this what you need?

-sundar



From andy_liaw at merck.com  Thu Feb 12 20:51:49 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 12 Feb 2004 14:51:49 -0500
Subject: [R] variances of values predicted using a lm object
Message-ID: <3A822319EB35174CA3714066D590DCD504AF779C@usrymx25.merck.com>

In case you haven't read ?predict.lm, please do, and if you did, please do
it yet again.  Look for the `se.fit' and `interval' arguments.

Andy

> From: Rajarshi Guha
> 
> Hi,
>   is there a function in R that will give me the variances of a
> predicted values obtained using predict.lm().
> 
> If no function is available I would need to calculate them myself -
> which involves taking the inverse of X'X (' indicating transpose)
> where X is my model matrix. I know that calculating an 
> inverse directly
> is not a good idea in general - could anybody suggest a way 
> around this?
> 
> Thanks,
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> If you believe in telekinesis, raise my hand.


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From monica.palaseanu-lovejoy at stud.man.ac.uk  Thu Feb 12 20:56:35 2004
From: monica.palaseanu-lovejoy at stud.man.ac.uk (Monica Palaseanu-Lovejoy)
Date: Thu, 12 Feb 2004 19:56:35 -0000
Subject: [R] kriging prediction intervals
In-Reply-To: <200402111140.i1BBb4x6018987@hypatia.math.ethz.ch>
Message-ID: <E1ArMx2-0009Nq-LQ@probity.mcc.ac.uk>

Hi everybody,

I am interested in calculating kriging prediction intervals. Any 
suggestions will be very much appreciated. Thank you in advance,

Monica



From greenberg at ucdavis.edu  Thu Feb 12 21:07:40 2004
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Thu, 12 Feb 2004 12:07:40 -0800
Subject: [R] Importing BSQ/BIP/BIL files into R
Message-ID: <BC511D0C.195B5%greenberg@ucdavis.edu>

I was hoping I could get some help with an import question.  I work with
remote sensing imagery which commonly comes in binary form in various
interleaving formats (byte interleaved by line, by pixel, etc..).  These
files are 2d spatial x B bands in size, and I want to be able to extract the
band values from various pixels (so each line of data into R would be one
pixel x B bands).

What's the easiest way of importing this type of data?  These files are
often massive (4 - 16gb), so is there a way of having R read the lines of
the data as I am running the process, rather than trying to load the whole
image into memory at once?  Thanks!  For those of you with remote sensing
experience, I'm using RSI's ENVI package.

--j

-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From rxg218 at psu.edu  Thu Feb 12 21:06:57 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Thu, 12 Feb 2004 15:06:57 -0500
Subject: [R] variances of values predicted using a lm object
In-Reply-To: <402BD90C.7080003@pdf.com>
References: <1076614932.14334.4.camel@ra.chem.psu.edu>
	<402BD90C.7080003@pdf.com>
Message-ID: <1076616416.14334.6.camel@ra.chem.psu.edu>

On Thu, 2004-02-12 at 14:50, Sundar Dorai-Raj wrote:
> Rajarshi Guha wrote:
> > Hi,
> >   is there a function in R that will give me the variances of a
> > predicted values obtained using predict.lm().

>  From ?predict.lm:
> 
> <quote>
> Details:
> 
>       'predict.lm' produces predicted values, obtained by evaluating the
>       regression function in the frame 'newdata' (which defaults to
>       'model.frame(object)'.  If the logical 'se.fit' is 'TRUE',
>       standard errors of the predictions are calculated.
> </quote>
> 
> Is this what you need?

Oops. Yes, thank you.

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
667:
The neighbor of the beast.



From k.wang at auckland.ac.nz  Thu Feb 12 21:14:27 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 13 Feb 2004 09:14:27 +1300
Subject: [R] Basic Help
In-Reply-To: <6.0.1.1.2.20040212114736.02adde80@mailbox.ucdavis.edu>
Message-ID: <000101c3f1a4$d0756170$6633d882@stat.auckland.ac.nz>




> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marisa Ramos
> Sent: Friday, February 13, 2004 8:49 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Basic Help
> 
> 
> OK I have been trying to learn how to use this program and I 
> cannot even 
> import any data into it.  I have downloaded all the manuals 
> but they do not 
> seem to help.  Is there a book on R for dummies???

Chapter 7 in "An Introduction to R" explains how to read the data in, it
should be pretty good....if you're still unsure, look at the
documentation for read.table() and scan().

Chapter 2 of my incomplete book,
http://www.stat.auckland.ac.nz/~kwan022/pub/R/RBook/, has a short
explanation about data structure in R.  The chapter has sort of been
complete (it's in the draft version).... 

HTH,

Kevin Wang

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
Statistics Workshops Co-ordinator
Student Learning Centre
University of Auckland
New Zealand



From andy_liaw at merck.com  Thu Feb 12 21:18:14 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 12 Feb 2004 15:18:14 -0500
Subject: [R] Basic Help
Message-ID: <3A822319EB35174CA3714066D590DCD504AF779D@usrymx25.merck.com>

Other than the official "An Introduction to R" manual, there are a few
intro-level documentations on CRAN.  Do you mean to say that all of them are
too advanced for you?

Andy

> From: Marisa Ramos
> 
> OK I have been trying to learn how to use this program and I 
> cannot even 
> import any data into it.  I have downloaded all the manuals 
> but they do not 
> seem to help.  Is there a book on R for dummies???
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From partha_bagchi at hgsi.com  Thu Feb 12 21:19:08 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Thu, 12 Feb 2004 15:19:08 -0500
Subject: [R] Basic Help
Message-ID: <OF9154103D.43165DFD-ON85256E38.006F781A-85256E38.006F9D51@hgsi.com>

Have you looked at the manual :  " R Data Import /Export" that comes with 
R? If you are using Windows platform Go to Help -->Manuals --> R Data 
Import/ Export.

Hope that helps.

Partha





Marisa Ramos <miramos at ucdavis.edu>
Sent by: r-help-bounces at stat.math.ethz.ch
02/12/2004 02:49 PM

 
        To:     R-help at stat.math.ethz.ch
        cc: 
        Subject:        [R] Basic Help


OK I have been trying to learn how to use this program and I cannot even
import any data into it.  I have downloaded all the manuals but they do 
not
seem to help.  Is there a book on R for dummies???

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

--
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From jasont at indigoindustrial.co.nz  Thu Feb 12 21:25:16 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 13 Feb 2004 09:25:16 +1300 (NZDT)
Subject: [R] Basic Help
In-Reply-To: <6.0.1.1.2.20040212114736.02adde80@mailbox.ucdavis.edu>
References: <6.0.1.1.2.20040212114736.02adde80@mailbox.ucdavis.edu>
Message-ID: <21182.203.9.176.60.1076617516.squirrel@new-webmail.maxnet.co.nz>

> OK I have been trying to learn how to use this program and I cannot even
> import any data into it.  I have downloaded all the manuals but they do
> not
> seem to help.  Is there a book on R for dummies???

I don't know about dummies, but Peter Dalgaard's book, "Introductory
Statistics with R" is an intro that is both gentle and thorough.

Cheers

Jason



From abunn at montana.edu  Thu Feb 12 21:36:21 2004
From: abunn at montana.edu (Andy Bunn)
Date: Thu, 12 Feb 2004 13:36:21 -0700
Subject: [R] Basic Help
In-Reply-To: <6.0.1.1.2.20040212114736.02adde80@mailbox.ucdavis.edu>
Message-ID: <000001c3f1a7$f22e9f40$78f05a99@msu.montana.edu>

Marisa,

If the examples in R Data Import/Export can't help you you'll have to be
way way way more specific.

http://cran.r-project.org/doc/manuals/R-data.pdf

I'm assuming you are using windows. Here's an example. Try saving the
attached file to c:\temp and copying the commands below into R. This
file junk.csv is a text file where each value is seperated by a comma.
You can open it in Excel or with a text editor like notepad. Try looking
at it with both. In windows it's often easiest to get you data from
excel to R by saving it as a comma seperated file (.csv) from excel.

Good luck, Andy


#### Start copy and paste

# Set the working directory so R knows where your files are
setwd("c:/temp")

# Read the data (see read.csv for comma seperated files too)

some.data <- read.table(file = "junk.csv", header = T, sep = ",")

# Now try some things with this data
some.data
summary(some.data)
attach(some.data)
a.model <- lm(Y ~ X1 + X2)
detach(some.data)
summary(a.model)


# now look at the help pages for these commands
?read.table
?setwd
?lm
?summary
?attach
?detach

#### End copy and paste


Here's a copy of the attached file junk.csv which probably won't make it
to the R-Help list.

ID,Y,X1,X2,X3
1,2,2,75,645
2,5,6,35,8
3,73,2,754,323
4,8,7,26,76
5,3,21,6,25

From WAY3 at CDRH.FDA.GOV  Thu Feb 12 21:44:47 2004
From: WAY3 at CDRH.FDA.GOV (Yousef, Waleed A*)
Date: Thu, 12 Feb 2004 15:44:47 -0500
Subject: [R] C-Code
Message-ID: <644D9337A02FC24689647BF9E48EC39E08F76BF0@drm556>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040212/e96565ac/attachment.pl

From greenberg at ucdavis.edu  Thu Feb 12 22:45:55 2004
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Thu, 12 Feb 2004 13:45:55 -0800
Subject: [R] Importing BSQ/BIP/BIL files into R
Message-ID: <BC513413.195D0%greenberg@ucdavis.edu>

I was hoping I could get some help with an import question.  I work with
remote sensing imagery which commonly comes in binary form in various
interleaving formats (byte interleaved by line, by pixel, etc..).  These
files are 2d spatial x B bands in size, and I want to be able to extract the
band values from various pixels (so each line of data into R would be one
pixel x B bands).

What's the easiest way of importing this type of data?  These files are
often massive (4 - 16gb), so is there a way of having R read the lines of
the data as I am running the process, rather than trying to load the whole
image into memory at once?  Thanks!  For those of you with remote sensing
experience, I'm using RSI's ENVI package.

--j

-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From ysun8 at uic.edu  Fri Feb 13 01:12:25 2004
From: ysun8 at uic.edu (ysun8)
Date: Thu, 12 Feb 2004 18:12:25 -0600
Subject: [R] how to get the cluster output as a text file but not a graphic
	one?
Message-ID: <4039B321@webmail.uic.edu>

Hi,

I got a problem when using the cluster in R.  Instead of getting the graphic 
output, I prefer a text format output rather than a graphic one.  How can I 
get the text file if it's possible?

Thanks a lot!

Sincerely,
Ying



From Hui_Wang at affymetrix.com  Fri Feb 13 02:14:50 2004
From: Hui_Wang at affymetrix.com (Wang, Hui)
Date: Thu, 12 Feb 2004 17:14:50 -0800
Subject: [R] Puzzled by write.table function
Message-ID: <48F1F432BF75D6118FAC0002B325BE36035111F4@ntex04.affymetrix.com>

I am puzzled by the following:

I use two write.table function(write into files)  in my code  as following
(I use  source to call the code): 
....
write.table (x1, file ="x1.txt", quote = "FALSE", append=FALSE, sep="\t",
eol="\n", "na=NA"...)
....(more statement)
..
write.table (x2, file="x2.txt"...)


 it turned out the second one is always empty. 

I know there is nothing the code itself as I can get second write.table
statement work if I comment the first.

Does anybody know what happened here?

Thanks.
-h


Hui Wang,  Ph.D. | Research, Affymetrix Laboratories | AFFYMETRIX, INC. |
3450 central expressway | Santa Clara, CA 95051 | 408-731-5668 (office) |
408-772-4750 (cell) | 408-481-0543 (fax)



From jasont at indigoindustrial.co.nz  Fri Feb 13 02:28:19 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 13 Feb 2004 14:28:19 +1300 (NZDT)
Subject: [R] C-Code
In-Reply-To: <644D9337A02FC24689647BF9E48EC39E08F76BF0@drm556>
References: <644D9337A02FC24689647BF9E48EC39E08F76BF0@drm556>
Message-ID: <27523.203.9.176.60.1076635699.squirrel@new-webmail.maxnet.co.nz>

> Can you assist me of a C-code or a compiled c-code for the
> statistics-functions that exist in R.
>

Easy.  Just download the latest source verion - it's all open, and there
for you to see.  Most of the functions have self-descriptive file names.

http://cran.r-project.org/src/base/R-1.8.1.tgz

Cheers

Jason



From ok at cs.otago.ac.nz  Fri Feb 13 02:45:33 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Fri, 13 Feb 2004 14:45:33 +1300 (NZDT)
Subject: RES: [R] AGREP
Message-ID: <200402130145.i1D1jXsn087732@atlas.otago.ac.nz>

"Marcos Sanches" <marcos.sanches at ipsos-opinion.com.br> wrote:
	Ls1<-length(s1)
	Ls2<-length(s2) 
	for ( p in 1:ls1){
	   for (q in 1:ls2){
	     t1<-levenshteinFast(s1[p],s2[q])
...

	Ls1=42000
	Ls2=70000
	
	I think I will wait for months untill this program ends. Do you have any
	sugestion to increase the speed?

The first suggestion has to be "search HARD in the on-line literature;
as others are bound to have had similar problems."

My second suggestion is to consider sorting.
The cost of distance(x,y) is proportional to |x|*|y|.
Now suppose y and z have a common prefix of length n.
Then the computation of distance(x,z) can be done in |x|*(|z|-n) time
by reusing the first n+1 columns of the matrix developed for y.
The simplest way to arrange strings so that strings with a common
prefix are adjacent is to sort them.

Depending on what your strings are like, this might make a big
improvement, or it might be a waste of time,

There are various approximate algorithms out there; the bioinformatics
literature is vast.  But the use of the simple insert=1 delete=1 change=1
cost function is *also* an approximation.  If strings are typed, some
keys are closer than others.  If they are transcribed from speech, some
sounds are more similar than others and some deletions (such as reduced
vowels) are likelier than others.  So don't be afraid of approximations.



From p.connolly at hortresearch.co.nz  Fri Feb 13 03:07:49 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Fri, 13 Feb 2004 15:07:49 +1300
Subject: [R] How to get time differences in consistent units?
Message-ID: <20040213150749.F935@hortresearch.co.nz>

I'm still having trouble getting to grips with time classes.

I wish to calculate the difference in days between events.  


Browse[1]> insp.j$First
[1] "2002-02-19 13:00:00 NZDT"
Browse[1]> spray.j$Date
[1] "2001-11-29 13:00:00 NZDT"
Browse[1]> insp.jk - spray.j$Date
Time difference of 82 days

If I save insp.jk to a vector, I get a nice useful value of 82.

However, when the dreaded daylight savings enters the picture, we get
this sort of thing:

Browse[1]> insp.j$First
[1] "2003-02-14 13:00:00 NZDT"
Browse[1]> spray.j$Date
[1] "2002-12-16 13:00:00 NZDT" "2003-01-15 13:00:00 NZDT"
[3] "2003-02-14 13:00:00 NZDT" "2003-02-14 13:00:00 NZDT"
[5] "2003-03-25 12:00:00 NZST"
Browse[1]> insp.jk - spray.j$Date
Time differences of  5184000,  2592000,        0,        0, -3369600 secs

Saving that insp.jk to a vector, I get one in seconds which isn't
simply comparable to others.  It would be simple enough to put in an
as.numeric() so that comparisons are always in seconds, but it would
be preferable to have some control over how the difference is reported.


Looking through previous discussions on this sort of thing I thought I
could save hassle by using tz = GMT for everything which is what I've
tried, and hence that's why the times are shown as 1pm and noon
depending on whether it's NZST or NSDT.  It appears to me that while
the dates are known to the software as GMT, they are displayed in
local time equivalent but before the differnce between them is
calculated, that converson happens again whether we like it or not.


Evidently, that's not what happens when as.numeric() is used before
calculating the difference since in that case (with my data), the
difference is always a whole number of days which is appropriate.

Is my experience with date differences standard behaviour or an OS
idiosyncrasy? 


platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    8.1              
year     2003             
month    11               
day      21       

Redhat 7.3 (with the dreaded gcc-2.96 compiler)

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From greenberg at ucdavis.edu  Fri Feb 13 03:51:00 2004
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Thu, 12 Feb 2004 18:51:00 -0800
Subject: [R] Readbin and file position
Message-ID: <BC517B94.1960B%greenberg@ucdavis.edu>

I have a binary file which is an image with multiple bands, arranged in BSQ
format such that R, B and G are all N x M sized matrices (corresponding to
Red, Blue and Green colors respectively).  The BSQ file arranges the data as
[R, B, G], so to access the B matrix, I have to read forward N x M + 1
number of samples.  Is there a fast way to define a variable as the B matrix
exclusively (e.g. Can I use readbin to "fast forward" N x M + 1 samples to
the beginning of the B matrix, and then read/define the B matrix
exclusively, or do I have to read the entire file into memory, then subset
out the B matrix?)

Thanks!

--j

-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From dmurdoch at pair.com  Fri Feb 13 04:07:06 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 12 Feb 2004 22:07:06 -0500
Subject: RES: [R] AGREP
In-Reply-To: <200402130145.i1D1jXsn087732@atlas.otago.ac.nz>
References: <200402130145.i1D1jXsn087732@atlas.otago.ac.nz>
Message-ID: <eofo20pdivajf778n9kl3fgqemm80iv3jh@4ax.com>

On Fri, 13 Feb 2004 14:45:33 +1300 (NZDT), you wrote:

>"Marcos Sanches" <marcos.sanches at ipsos-opinion.com.br> wrote:
>	Ls1<-length(s1)
>	Ls2<-length(s2) 
>	for ( p in 1:ls1){
>	   for (q in 1:ls2){
>	     t1<-levenshteinFast(s1[p],s2[q])
>...
>
>	Ls1=42000
>	Ls2=70000
>	
>	I think I will wait for months untill this program ends. Do you have any
>	sugestion to increase the speed?
>
>The first suggestion has to be "search HARD in the on-line literature;
>as others are bound to have had similar problems."

As I mentioned earlier, R already contains the source to do this using
the same library as agrep() uses.  You just need to write the R
interface to it.

Duncan Murdoch



From sic03001 at sp.uconn.edu  Fri Feb 13 04:42:04 2004
From: sic03001 at sp.uconn.edu (Cheng)
Date: Thu, 12 Feb 2004 22:42:04 -0500 (EST)
Subject: [R] IIA tests
Message-ID: <Pine.A41.4.10.10402122241200.62486-100000@enf1n6.ucc.uconn.edu>

Dear Listeners,

Does anyone know how to do an IIA test (Independence of Irrelevant
Alternatives) after estimating a multinomial logit model?  The literature
discusses 4 different types of IIA test after a multinomial logit model:
Hausman, Small/Hsiao, MTT, and H.  How many of these tests are implemented
into the software?

Thanks.

Simon



From ggrothendieck at myway.com  Fri Feb 13 05:03:38 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 12 Feb 2004 23:03:38 -0500 (EST)
Subject: [R] How to get time differences in consistent units?
Message-ID: <20040213040338.455EE397C@mprdmxin.myway.com>



If date1 and date2 have been defined in the GMT time zone
then this should do it:

   difftime( date1, date2, tz="GMT" )

The other way is to represent your dates as chron dates since chron
does not support time zones at all.  In that case you could just do:

   date1 - date2

---
Date: Fri, 13 Feb 2004 15:07:49 +1300 
From:   Patrick Connolly <p.connolly at hortresearch.co.nz>
To:   R-help <r-help at stat.math.ethz.ch> 
Subject:   [R] How to get time differences in consistent units? 

 
I'm still having trouble getting to grips with time classes.

I wish to calculate the difference in days between events. 


Browse[1]> insp.j$First
[1] "2002-02-19 13:00:00 NZDT"
Browse[1]> spray.j$Date
[1] "2001-11-29 13:00:00 NZDT"
Browse[1]> insp.jk - spray.j$Date
Time difference of 82 days

If I save insp.jk to a vector, I get a nice useful value of 82.

However, when the dreaded daylight savings enters the picture, we get
this sort of thing:

Browse[1]> insp.j$First
[1] "2003-02-14 13:00:00 NZDT"
Browse[1]> spray.j$Date
[1] "2002-12-16 13:00:00 NZDT" "2003-01-15 13:00:00 NZDT"
[3] "2003-02-14 13:00:00 NZDT" "2003-02-14 13:00:00 NZDT"
[5] "2003-03-25 12:00:00 NZST"
Browse[1]> insp.jk - spray.j$Date
Time differences of 5184000, 2592000, 0, 0, -3369600 secs

Saving that insp.jk to a vector, I get one in seconds which isn't
simply comparable to others. It would be simple enough to put in an
as.numeric() so that comparisons are always in seconds, but it would
be preferable to have some control over how the difference is reported.


Looking through previous discussions on this sort of thing I thought I
could save hassle by using tz = GMT for everything which is what I've
tried, and hence that's why the times are shown as 1pm and noon
depending on whether it's NZST or NSDT. It appears to me that while
the dates are known to the software as GMT, they are displayed in
local time equivalent but before the differnce between them is
calculated, that converson happens again whether we like it or not.


Evidently, that's not what happens when as.numeric() is used before
calculating the difference since in that case (with my data), the
difference is always a whole number of days which is appropriate.

Is my experience with date differences standard behaviour or an OS
idiosyncrasy? 


platform i686-pc-linux-gnu
arch i686 
os linux-gnu 
system i686, linux-gnu 
status 
major 1 
minor 8.1 
year 2003 
month 11 
day 21 

Redhat 7.3 (with the dreaded gcc-2.96 compiler)

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it. ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From chetan at cdacindia.com  Fri Feb 13 08:11:50 2004
From: chetan at cdacindia.com (Chetan Kumar)
Date: Fri, 13 Feb 2004 12:41:50 +0530
Subject: [R] Help in installing packages
Message-ID: <402C78B6.8080802@cdac.ernet.in>

Hi all,
My R installtion was fine till a few days back.
On trying to install a package I see this
"/usr/lib/R/bin/INSTALL: line 420: cd: src: No such file or directory"
I HAVE installed packages in the past without this kind of situation
having ever arisen.
To get around this I installed  R-1.8.1-2.i386.rpm again without
resolution of the problem.
Any suggestions ?
TIA
Chetan



From ligges at statistik.uni-dortmund.de  Fri Feb 13 08:28:55 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 13 Feb 2004 08:28:55 +0100
Subject: [R] Puzzled by write.table function
In-Reply-To: <48F1F432BF75D6118FAC0002B325BE36035111F4@ntex04.affymetrix.com>
References: <48F1F432BF75D6118FAC0002B325BE36035111F4@ntex04.affymetrix.com>
Message-ID: <402C7CB7.8050704@statistik.uni-dortmund.de>

Wang, Hui wrote:
> I am puzzled by the following:
> 
> I use two write.table function(write into files)  in my code  as following
> (I use  source to call the code): 
> ....
> write.table (x1, file ="x1.txt", quote = "FALSE", append=FALSE, sep="\t",
> eol="\n", "na=NA"...)
> ....(more statement)
> ..
> write.table (x2, file="x2.txt"...)
> 
> 
>  it turned out the second one is always empty. 
> 
> I know there is nothing the code itself as I can get second write.table
> statement work if I comment the first.
> 
> Does anybody know what happened here?

No, in particular not in this case, because you have given a 
non-reproducible example (moreover, it is syntactically wrong!).

Please also tell us your version of R and your OS.

Uwe Ligges



From olefc at daimi.au.dk  Fri Feb 13 08:31:21 2004
From: olefc at daimi.au.dk (Ole F. Christensen)
Date: Fri, 13 Feb 2004 08:31:21 +0100
Subject: [R] kriging prediction intervals
Message-ID: <402C7D49.4040009@daimi.au.dk>

Dear Monica

Take a look at some of the spatial packages.
kriging prediction errors are implemented, and from these you can obtain kriging prediction intervals.

See Also

http://sal.agecon.uiuc.edu/csiss/Rgeo/index.html


Cheers Ole


Hi everybody,

I am interested in calculating kriging prediction intervals. Any 
suggestions will be very much appreciated. Thank you in advance,

Monica

-- 
Ole F. Christensen
Center for Bioinformatik
Aarhus Universitet
Ny Munkegade, Bygning 540
8000 Aarhus C



From ligges at statistik.uni-dortmund.de  Fri Feb 13 08:42:04 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 13 Feb 2004 08:42:04 +0100
Subject: [R] Readbin and file position
In-Reply-To: <BC517B94.1960B%greenberg@ucdavis.edu>
References: <BC517B94.1960B%greenberg@ucdavis.edu>
Message-ID: <402C7FCC.6050100@statistik.uni-dortmund.de>

Jonathan Greenberg wrote:

> I have a binary file which is an image with multiple bands, arranged in BSQ
> format such that R, B and G are all N x M sized matrices (corresponding to
> Red, Blue and Green colors respectively).  The BSQ file arranges the data as
> [R, B, G], so to access the B matrix, I have to read forward N x M + 1
> number of samples.  Is there a fast way to define a variable as the B matrix
> exclusively (e.g. Can I use readbin to "fast forward" N x M + 1 samples to
> the beginning of the B matrix, and then read/define the B matrix
> exclusively, or do I have to read the entire file into memory, then subset
> out the B matrix?)
> 
> Thanks!
> 
> --j
> 


?readBin points us to ?connections which finally points us to ?seek 
which is the function you are looking for.

Uwe ligges



From ligges at statistik.uni-dortmund.de  Fri Feb 13 08:43:56 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 13 Feb 2004 08:43:56 +0100
Subject: [R] Importing BSQ/BIP/BIL files into R
In-Reply-To: <BC513413.195D0%greenberg@ucdavis.edu>
References: <BC513413.195D0%greenberg@ucdavis.edu>
Message-ID: <402C803C.1070502@statistik.uni-dortmund.de>

Jonathan Greenberg wrote:

> I was hoping I could get some help with an import question.  I work with
> remote sensing imagery which commonly comes in binary form in various
> interleaving formats (byte interleaved by line, by pixel, etc..).  These
> files are 2d spatial x B bands in size, and I want to be able to extract the
> band values from various pixels (so each line of data into R would be one
> pixel x B bands).
> 
> What's the easiest way of importing this type of data?  These files are
> often massive (4 - 16gb), so is there a way of having R read the lines of
> the data as I am running the process, rather than trying to load the whole
> image into memory at once?  Thanks!  For those of you with remote sensing
> experience, I'm using RSI's ENVI package.
> 
> --j
> 

See ?connections which points you to many other function that help you 
to deal with reading in single values / blocks of values from a file.

Uwe ligges



From Hui_Wang at affymetrix.com  Fri Feb 13 08:35:18 2004
From: Hui_Wang at affymetrix.com (Wang, Hui)
Date: Thu, 12 Feb 2004 23:35:18 -0800
Subject: [R] Puzzled by write.table function
Message-ID: <48F1F432BF75D6118FAC0002B325BE36035111F5@ntex04.affymetrix.com>

Hi,
Sorry,the syntax in the email was wrong. 


The code is boring, it virtually processes some data and write the results
out using write.table function at the end. The output has <10,000 rows.

Here is part of the code:

....

write.table(sigGene, file="sigGene1.tab",append=FALSE, quote = FALSE, sep
="\t", eol = "\n", na = "NA", dec = ".", row.names =FALSE, col.names=FALSE);

write.table(cbind(gene,geneScored), file="sigGene_scored.tab",append=FALSE,
quote = FALSE, sep="\t", eol = "\n", na = "NA", dec = ".", row.names
=FALSE,col.names=FALSE);

sigGene is a matrix of 2 cols, gene, geneScored  are vectors generated by
early code.


I used the linux version 1.7.1.


Thanks

-h

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: Thursday, February 12, 2004 11:29 PM
To: Wang, Hui
Cc: R-help
Subject: Re: [R] Puzzled by write.table function


Wang, Hui wrote:
> I am puzzled by the following:
> 
> I use two write.table function(write into files)  in my code  as 
> following (I use  source to call the code): ....
> write.table (x1, file ="x1.txt", quote = "FALSE", append=FALSE, sep="\t",
> eol="\n", "na=NA"...)
> ....(more statement)
> ..
> write.table (x2, file="x2.txt"...)
> 
> 
>  it turned out the second one is always empty.
> 
> I know there is nothing the code itself as I can get second 
> write.table statement work if I comment the first.
> 
> Does anybody know what happened here?

No, in particular not in this case, because you have given a 
non-reproducible example (moreover, it is syntactically wrong!).

Please also tell us your version of R and your OS.

Uwe Ligges



From Roger.Bivand at nhh.no  Fri Feb 13 08:52:31 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 13 Feb 2004 08:52:31 +0100 (CET)
Subject: [R] Importing BSQ/BIP/BIL files into R
In-Reply-To: <BC513413.195D0%greenberg@ucdavis.edu>
Message-ID: <Pine.LNX.4.44.0402130847340.30657-100000@reclus.nhh.no>

On Thu, 12 Feb 2004, Jonathan Greenberg wrote:

> I was hoping I could get some help with an import question.  I work with
> remote sensing imagery which commonly comes in binary form in various
> interleaving formats (byte interleaved by line, by pixel, etc..).  These
> files are 2d spatial x B bands in size, and I want to be able to extract the
> band values from various pixels (so each line of data into R would be one
> pixel x B bands).
> 
> What's the easiest way of importing this type of data?  These files are
> often massive (4 - 16gb), so is there a way of having R read the lines of
> the data as I am running the process, rather than trying to load the whole
> image into memory at once?  Thanks!  For those of you with remote sensing
> experience, I'm using RSI's ENVI package.

You may like to use the R bindings to GDAL in package rgdal. You need to 
have installed GDAL first, and then install the R source package, so this 
works on Unix/Linux, and probably Mac OSX, but on Windows you need to 
build GDAL under MSYS/MinGW, and alter Makevars in rgdal/src by hand. 
Because rgdal binds to GDAL, it allows selection of subscenes. If you have 
the PROJ.4 library installed too, it may provide geo-referencing, but 
YMMV. Contact me off-list if this is worth following up.

Roger

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From icasas at maths.uwa.edu.au  Fri Feb 13 10:38:29 2004
From: icasas at maths.uwa.edu.au (Isabel)
Date: Fri, 13 Feb 2004 17:38:29 +0800 (WST)
Subject: [R] Parallel programming with R
Message-ID: <Pine.LNX.4.44.0402131736300.17781-100000@isopogon.maths.uwa.edu.au>

Hello,

I am trying to do some parallel programming with R. I programmed with C 
and MPI before. I heard that there is a package called Rmpi and one called 
snow. What is the difference? I know the administrator installed snow in 
our system so I wonder if this mean there is Rmpi in it. I believe the 
Rmpi will have similar functions than MPI that is why I am specially 
interested in it.

Thanks for your help
Isabel



From PHewson at devon.gov.uk  Fri Feb 13 13:37:33 2004
From: PHewson at devon.gov.uk (Paul Hewson)
Date: Fri, 13 Feb 2004 12:37:33 -0000
Subject: [R] Windows dll compilation (mingw32): how to find R.h and other
	head er files when sketching short functions
Message-ID: <17634721EB46D611A35E0002A5424F170CF258D5@cor-exg1.devon.gov.uk>

Sorry, this seems like a particularly stupid question, but here goes.   It
relates to some "sketching" work I'm doing under Windoze.

I can only get my C code to find R.h and friends if I shift these header
files files and folders into the analogous mingw32 folders.   This seems a
rather clumsy way of doing things, and I wondered what I've missed?   (I'm
using the gcc -02 etc. commands as per Venables and Ripley's S Programming -
which works fine.   However, having a duplicate set of header files doesn't
seem too elegant)

I have no problem compiling (other peoples) packages from source, but my own
code isn't quite ready to be packaged yet.

Thanks for any pointers.

Paul

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
Paul Hewson     tel. (01392) 382773
Data Analyst and Research Officer

Road Safety Team, Environment Directorate, 
Devon County Council,
1st Floor, Lucombe House,
County Hall
Topsham Road
Exeter EX2 4QW

tel (01392) 382773   fax (01392) 382135
email phewson at devon.gov.uk
www.devon.gov.uk/roadsafe



From p.dalgaard at biostat.ku.dk  Fri Feb 13 13:53:21 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Feb 2004 13:53:21 +0100
Subject: [R] Windows dll compilation (mingw32): how to find R.h and other
	head er files when sketching short functions
In-Reply-To: <17634721EB46D611A35E0002A5424F170CF258D5@cor-exg1.devon.gov.uk>
References: <17634721EB46D611A35E0002A5424F170CF258D5@cor-exg1.devon.gov.uk>
Message-ID: <x2wu6r16pq.fsf@biostat.ku.dk>

Paul Hewson <PHewson at devon.gov.uk> writes:

> Sorry, this seems like a particularly stupid question, but here goes.   It
> relates to some "sketching" work I'm doing under Windoze.
> 
> I can only get my C code to find R.h and friends if I shift these header
> files files and folders into the analogous mingw32 folders.   This seems a
> rather clumsy way of doing things, and I wondered what I've missed?   (I'm
> using the gcc -02 etc. commands as per Venables and Ripley's S Programming -
> which works fine.   However, having a duplicate set of header files doesn't
> seem too elegant)
> 
> I have no problem compiling (other peoples) packages from source, but my own
> code isn't quite ready to be packaged yet.
> 
> Thanks for any pointers.

Are you looking for the -I option to gcc ?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From mmiller3 at iupui.edu  Fri Feb 13 13:54:21 2004
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Fri, 13 Feb 2004 07:54:21 -0500
Subject: [R] calling R from a shell script and have it display graphics
In-Reply-To: <p06002001bc514f2c36e7@[128.115.153.6]> (Don MacQueen's message
	of "Thu, 12 Feb 2004 07:45:42 -0800")
References: <402B5C26.90706@lscp.ehess.fr>
	<p06002001bc514f2c36e7@[128.115.153.6]>
Message-ID: <87u11vp2bm.fsf@lumen.indyrad.iupui.edu>

>>>>> "Don" == Don MacQueen <macq at llnl.gov> writes:

    > I don't know about the "simpler" part, but you could use
    > the tcltk package to put up a window that prompts the user
    > to continue.

Here's a function that does that.  I use to prompt the user to
choose among printing the current device with dev.print, saving
it with dev.copy2eps or continuing without doing anything.  I
write my codes to use this function and then, depending on
whether or not the code is running from a script or not, I
redefine it with the tk version.

Mike

##===================================================================================
## give the user some options at the command prompt
print.or.not <- function() {
  print("<return> to continue, `p' to print, `s' to save to R.ps...")
  result <- readline("[<ret>ps] ")
  if ( result == "p" ) { dev.print() }
  if ( result == "s" ) { dev.copy2eps(file="R.ps") }
}

##===================================================================================
## give the user some options in a tk window...
print.or.not <- function() {
  tt.print <- tktoplevel()
  tktitle(tt.print) <- 'Print or save plot?'
  b.print <- tkbutton(tt.print,
                      text='print',
                      command=function(...){ dev.print()
                                             tkdestroy(tt.print)
                                           }
                      )
  b.save <- tkbutton(tt.print,
                     text='save',
                     command=function(...){ file.obj <- tkgetSaveFile()
                                            file.name <- tclvalue(file.obj)
                                            dev.copy2eps(file=file.name)
                                            tkdestroy(tt.print)
                                          }
                     )
  b.continue <- tkbutton(tt.print,
                         text='continue',
                         command=function(...){ tkdestroy(tt.print)
                                              }
                         )
  tkpack(b.print, b.save, b.continue,fill='both')
  tkwait.window(tt.print)
}



From andy_liaw at merck.com  Fri Feb 13 14:08:00 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 13 Feb 2004 08:08:00 -0500
Subject: [R] Windows dll compilation (mingw32): how to find R.h and
	ot her head er files when sketching short functions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77A5@usrymx25.merck.com>

I thought Rcmd SHLIB mycode.c should take care of that, no?

Andy

> From: Paul Hewson
> 
> Sorry, this seems like a particularly stupid question, but 
> here goes.   It
> relates to some "sketching" work I'm doing under Windoze.
> 
> I can only get my C code to find R.h and friends if I shift 
> these header
> files files and folders into the analogous mingw32 folders.   
> This seems a
> rather clumsy way of doing things, and I wondered what I've 
> missed?   (I'm
> using the gcc -02 etc. commands as per Venables and Ripley's 
> S Programming -
> which works fine.   However, having a duplicate set of header 
> files doesn't
> seem too elegant)
> 
> I have no problem compiling (other peoples) packages from 
> source, but my own
> code isn't quite ready to be packaged yet.
> 
> Thanks for any pointers.
> 
> Paul
> 
> -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
> Paul Hewson     tel. (01392) 382773
> Data Analyst and Research Officer
> 
> Road Safety Team, Environment Directorate, 
> Devon County Council,
> 1st Floor, Lucombe House,
> County Hall
> Topsham Road
> Exeter EX2 4QW
> 
> tel (01392) 382773   fax (01392) 382135
> email phewson at devon.gov.uk
> www.devon.gov.uk/roadsafe
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From pac at uhb.fr  Fri Feb 13 14:17:08 2004
From: pac at uhb.fr (Pierre-Andre Cornillon)
Date: Fri, 13 Feb 2004 14:17:08 +0100 (CET)
Subject: [R] R installation and reg-test
Message-ID: <Pine.LNX.4.58.0402131310030.17833@sa2391.rec.uhb.fr>

Hello

I have encountered some problem in R 1-8-1 installation.
The compilation run smoothly (make) but the (make) check step
fails at the reg-tests-1.R step
It is said that (at the end of reg-tests-1.Rout.fail)
library(mva)
## cmdscale
## failed in versions <= 1.4.0 :
data(eurodist)
cm1 <- cmdscale(eurodist, k=1, add=TRUE, x.ret = TRUE)
cmdsE <- cmdscale(eurodist, k=20, add = TRUE, eig = TRUE, x.ret = TRUE)
stopifnot(identical(cm1$x,  cmdsE$x),
          identical(cm1$ac, cmdsE$ac))
failed

When I rerun the test without cleaning anything, the "make check"
pass the reg-test and all the subsequent one.

When I manually run the portion of the test it succeeds.
<topbuiddir>/bin/R --vanilla

When I clean everything, rerun configure without ATLAS library
rerun make and make check everything run smoothly including all test.

Atlas library passed all its tests and it was built with P4 arch
and thread support enabled

What does it means ?

Some specifications
I have a dual Xeon 2.4 Ghz with Linux Suse 9.0 :
kernel, gcc and make version
2.4.21-99-smp
gcc (GCC) 3.3.1 (SuSE Linux)
GNU Make 3.80

Rversion : R-1.8.1

Atlas version 3.6.0

Thanks
Pierre-Andre Cornillon



From dieter.menne at menne-biomed.de  Fri Feb 13 14:18:03 2004
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 13 Feb 2004 14:18:03 +0100
Subject: [R] lattice: showing panels for factor levels with no values
Message-ID: <JLEPLGAANFCEAEDCAGJNAEHMCHAA.dieter.menne@menne-biomed.de>

Wolfram Fischer wrote (

> Is there an option to show empty panels for "Grand Rapids" in
> ``my.barley''?

Deepayan
No, unused factor levels are dropped. I'll see if adding an option for this
is feasible.

Dieter Menne:

See also

http://maths.newcastle.edu.au/~rking/R/help/01c/2820.html

Deepayan, at that time I received an e-mail (not in the archives) from you
saying that this feature was already in the code, but not yet active (quoted
from memory).


Dieter Menne



From matthew_wiener at merck.com  Fri Feb 13 14:57:55 2004
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Fri, 13 Feb 2004 08:57:55 -0500
Subject: [R] Readbin and file position
Message-ID: <AEBD81486231A343B1813FE62D335225077D2373@usrymx15.merck.com>

The "seek" command will allow you to skip to a particular byte position in
the file.  You can define the position you want relative to your current
position, or to the start of the file.

Hope this helps,

Matt Wiener

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jonathan Greenberg
Sent: Thursday, February 12, 2004 9:51 PM
To: R-help
Subject: [R] Readbin and file position


I have a binary file which is an image with multiple bands, arranged in BSQ
format such that R, B and G are all N x M sized matrices (corresponding to
Red, Blue and Green colors respectively).  The BSQ file arranges the data as
[R, B, G], so to access the B matrix, I have to read forward N x M + 1
number of samples.  Is there a fast way to define a variable as the B matrix
exclusively (e.g. Can I use readbin to "fast forward" N x M + 1 samples to
the beginning of the B matrix, and then read/define the B matrix
exclusively, or do I have to read the entire file into memory, then subset
out the B matrix?)

Thanks!

--j

-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ahenningsen at email.uni-kiel.de  Fri Feb 13 15:31:32 2004
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Fri, 13 Feb 2004 15:31:32 +0100
Subject: [R] Almost Ideal Demand System
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB021F0FA6@gimli.middleearth.kssg.com>
References: <6B5A9304046AD411BD0200508BDFB6CB021F0FA6@gimli.middleearth.kssg.com>
Message-ID: <200402131531.32816.ahenningsen@email.uni-kiel.de>

Hi Wayne, 

I did some demand analsis with R and the systemfit package. For me it worked 
very well. Therefore, I want to prepare a new package for R that contains the 
functions to estimate the (LA-)AIDS, calculates the demand elasticities and 
so on. However, it will take me some time until this package will be ready, 
but if you are (or someone else is) interested, I can prepare an (almost 
undocumented) "alpha" release.

Best wishes,
Arne


On Thursday 12 February 2004 13:00, Wayne Jones wrote:
> Hi there fellow R users,
>
>
> Has anyone got an R example of applying an Ideal demand system, possibly
> using the library systemfit??
>
>
> Thanks
>
> Wayne
>
>
> Dr Wayne R. Jones
> Senior Statistician / Research Analyst
> KSS Limited
> St James's Buildings
> 79 Oxford Street
> Manchester M1 6SS
> Tel: +44(0)161 609 4084
> Mob: +44(0)7810 523 713
>
>
>
>
> KSS Ltd
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS 
> England Company Registration Number 2800886
> Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com		http://www.kssg.com
>
>
> The information in this Internet email is confidential and m...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From bates at stat.wisc.edu  Fri Feb 13 15:40:49 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 13 Feb 2004 08:40:49 -0600
Subject: [R] Parallel programming with R
In-Reply-To: <Pine.LNX.4.44.0402131736300.17781-100000@isopogon.maths.uwa.edu.au>
References: <Pine.LNX.4.44.0402131736300.17781-100000@isopogon.maths.uwa.edu.au>
Message-ID: <6rk72rrqj2.fsf@bates4.stat.wisc.edu>

Isabel <icasas at maths.uwa.edu.au> writes:

> I am trying to do some parallel programming with R. I programmed with C 
> and MPI before. I heard that there is a package called Rmpi and one called 
> snow. What is the difference? 

Frequently that type of question is answered in the documentation for
the two packages.  Did you try looking at

               http://www.stats.uwo.ca/faculty/yu/Rmpi/

and

        http://www.stat.uiowa.edu/~luke/R/cluster/cluster.html

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From cg.pettersson at evp.slu.se  Fri Feb 13 16:06:18 2004
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Fri, 13 Feb 2004 16:06:18 +0100
Subject: [R] Problems loading dataset in Rcmdr
Message-ID: <200402131506.i1DF6IAA019201@mail1.slu.se>

Hello all!
I?ve been using Rcmdr for some time, as a quick way of producing
graphics and basic statistics. I run R1.8.1, OS W2000.

Two days ago the dataset loader stopped working. Normally, the button
<No active dataset> is clickable to give you the opportunity to choose
dataset to load in the Rcmdr context. Clicking on the button now
produces this:

Rcmdr Version 0.9-3
Error in parse(file, n, text, prompt) : parse error

What is happening and what could I do to get out of it?
(I have removed Rcmdr and downloaded it again from CRAN, as well as
uninstalled R, reinstalling it from the copy of my download.

Doesn?t help so far.
Please help!

/CG

CG Pettersson, MSci, PhD Stud.
Swedish University of Agricultural Sciences
Dep. of Ecology and Crop Production. Box 7043
SE-750 07 Uppsala



From Saghir.Bashir at ucb-group.com  Fri Feb 13 16:44:30 2004
From: Saghir.Bashir at ucb-group.com (Bashir Saghir (Aztek Global))
Date: Fri, 13 Feb 2004 16:44:30 +0100
Subject: [R] Basic Help
Message-ID: <3EBA5559F490D61189430002A5F0AE8905632482@ntexcrd.braine.ucb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040213/deedfe67/attachment.pl

From pocernic at rap.ucar.edu  Fri Feb 13 17:33:29 2004
From: pocernic at rap.ucar.edu (Matt Pocernich)
Date: Fri, 13 Feb 2004 09:33:29 -0700 (MST)
Subject: [R] generic/method .. find.package
Message-ID: <Pine.LNX.4.44.0402130917040.31668-100000@albedo.rap.ucar.edu>

Hello,

I get the following error running R CMD check on a simple package.  This
package just contains 3 functions and does not call any other packages.
Do you have any idea what might be the issue, or what I might check?

Thanks,

Matt

* checking generic/method consistency ... WARNING
Error in .find.package(package, lib.loc) :
        none of the packages were found
Execution halted
* checking for assignment functions with final arg not named 'value' ...
WARNINGError in .find.package(package, lib.loc) :
        none of the packages were found
Execution halted
* checking Rd files ... OK
* checking for undocumented objects ... ERROR
Error in .find.package(package, lib.loc) :

Matt Pocernich
NCAR - Research Applications Program
303-497-8312



From dsheuman at rogers.com  Fri Feb 13 17:34:14 2004
From: dsheuman at rogers.com (dsheuman@rogers.com)
Date: Fri, 13 Feb 2004 11:34:14 -0500
Subject: [R] Calculate Closest 5 Cases?
Message-ID: <20040213163414.QVOS322971.fep04-mail.bloor.is.net.cable.rogers.com@localhost>

I've only begun investigating R as a substitute for SPSS.

I have a need to identify for each CASE the closest (or most similar) 5 
other CASES (not including itself as it is automatically the closest).  I 
have a fairly large matrix (50000 cases by 50 vars).  In SPSS, I can use Correlate > Distances to generate a matrix of similarity, but only on a small sample.  The entire matrix can not be processed at once due to memory limitations.

The data are all percents, so they are easy comparable.  

Is there any way to do this in R?

Below is a small sample of the data (from SPSS) and the desired output.

Thanks,

Danny




*Sample Data.
DATA LIST LIST /id(F8) var1(F8.2) var2(F8.2) var3(F8.2) var4(F8.2) var5
(F8.2) var6(F8.2) var7(F8.2) var8(F8.2) var9(F8.2) var10(F8.2) var11(F8.2).
BEGIN DATA.
10170069	3.51	4.02	6.53	11.05	6.53	8.04	13.57	20.10	11.05	8.55
	7.04
10190229	1.89	5.66	4.61	7.62	8.45	13.21	9.50	20.82	16.07	9.36
	3.77
10540023	3.40	5.08	3.39	4.52	10.18	14.71	13.56	16.38	9.60	7.89
	11.85
10650413	6.64	6.64	3.73	4.70	3.78	13.23	19.82	15.98	12.26	8.48
	3.78
10662074	5.11	5.81	4.37	5.11	6.55	14.60	18.97	11.68	10.25	8.75
	8.79
10770041	6.43	4.17	6.34	4.26	6.34	4.26	19.11	19.20	14.95	12.77
	4.35
11010422	3.14	4.71	6.81	7.85	5.75	6.81	15.18	15.18	13.61	11.00
	9.44
11060762	7.03	5.03	6.95	5.99	5.92	12.94	15.01	12.06	11.98	8.06
	9.02
11070078	4.61	9.22	4.61	7.94	6.27	12.75	14.02	20.49	7.75	7.75
	4.61
11180646	4.48	5.35	6.29	5.42	4.55	11.71	20.74	15.32	14.45	8.09
	3.61
11460001	5.71	7.34	6.48	5.68	4.07	10.55	13.83	18.69	12.15	9.76
	4.87
11650133	6.00	3.72	6.72	6.00	7.50	17.94	13.44	16.37	13.51	5.15
	3.65
11650275	4.02	8.06	6.06	8.10	5.06	8.10	17.16	14.12	12.14	14.12
	4.02
11780034	4.25	4.28	5.30	5.33	6.38	14.88	15.96	18.08	14.85	7.48
	3.20
11790016	4.40	4.40	5.54	4.40	4.40	10.93	17.67	19.72	13.20	12.13
	4.33
12660338	6.60	7.54	5.66	8.49	10.38	11.31	16.06	12.26	8.49	8.49
	4.73
12660644	5.51	3.14	3.95	7.09	7.11	14.98	15.72	18.90	9.44	5.50
	8.65
12661667	5.44	4.50	5.44	4.50	5.44	12.69	13.63	11.81	9.07	13.68
	13.79
END DATA.

*Output should be:.
*.
*	ID1	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
*	ID2	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
*	ID3	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
*	ID4	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
*	ID5	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.



From beniltoncarvalho at hotmail.com  Fri Feb 13 18:15:22 2004
From: beniltoncarvalho at hotmail.com (Benilton Carvalho)
Date: Fri, 13 Feb 2004 17:15:22 +0000
Subject: [R] Frailty Model - parameter inferences
Message-ID: <Sea2-F57TzFm15k4R9x000098dd@hotmail.com>

Hi, I've been trying to find how to extract the inference info about \theta 
... Is there any easy way to do it?

Thanks,

Benilton

_________________________________________________________________
Create your own personal Web page with the info you use most, at My MSN. 
http://click.atdmt.com/AVE/go/onm00200364ave/direct/01/



From deepayan at stat.wisc.edu  Fri Feb 13 18:22:57 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 13 Feb 2004 11:22:57 -0600
Subject: [R] lattice: showing panels for factor levels with no values
In-Reply-To: <JLEPLGAANFCEAEDCAGJNAEHMCHAA.dieter.menne@menne-biomed.de>
References: <JLEPLGAANFCEAEDCAGJNAEHMCHAA.dieter.menne@menne-biomed.de>
Message-ID: <200402131122.57892.deepayan@stat.wisc.edu>

On Friday 13 February 2004 07:18, Dieter Menne wrote:

[...]

> Dieter Menne:
>
> See also
>
> http://maths.newcastle.edu.au/~rking/R/help/01c/2820.html
>
> Deepayan, at that time I received an e-mail (not in the archives) from you
> saying that this feature was already in the code, but not yet active
> (quoted from memory).

I remember seeing this plot, but I can't remember (or imagine) what solution I 
was thinking of. In your example, the number of levels is already 17 in the 
fit returned by lme():

> fm4Oats <- lme( yield ~ nitro, data = Oats1, random = ~ 1 | Block/Variety ) 
> fm4Oats
Linear mixed-effects model fit by REML
  Data: Oats1 
[...]
Number of Observations: 68
Number of Groups: 
             Block Variety %in% Block 
                 6                 17 

and the subsequent augPred and plot.augPred calls retain that. In other words, 
the 'dropping' of levels has already happened when xyplot is called, and the 
fact that xyplot would have dropped unused levels doesn't come into play. I 
don't think there's an easy way to get what you want here.

Deepayan



From polzehl at wias-berlin.de  Fri Feb 13 19:19:44 2004
From: polzehl at wias-berlin.de (Joerg Polzehl)
Date: Fri, 13 Feb 2004 19:19:44 +0100
Subject: [R] Problems with R CMD INSTALL on SUSE-LINUX 9.0
Message-ID: <402D1540.1020407@wias-berlin.de>

Dear Colleagues,

     I've recently upgraded to SUSE-LINUX 9.0 and R 1.8.1  (using the 
RPM-'s from CRAN).
I've checked that all required LINUX-Packages as listet in the 
README.html in /bin/linux/SUSE
are installed.

I've then tried to INSTALL and check a package.

Installation with

R CMD INSTALL -l Rcontrib aws
* Installing *source* package 'aws' ...
** libs
make: ?aws.so? ist bereits aktualisiert.
** help
 >>> Building/Updating help pages for package 'aws'
     Formats: text html latex example
* DONE (aws)

looks fine.

When I try to use the package I get the following:

polzehl at dhcp-154:~> R

R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

 > library(aws)
 > aws
Error: Object "aws" not found
 > ls(pos=2)
character(0)
q()

The reason is easy to detect:

polzehl at dhcp-154:~> cd Rcontrib/aws
polzehl at dhcp-154:~/Rcontrib/aws> ls
CONTENTS  DESCRIPTION  help  html  INDEX  latex  libs  man  Meta  R-ex

INSTALL has not created an directory for the source code ... .

Did I miss something ???   May I need to install some additional package 
from the SUSE-LINUX-distribution ?

Any suggestion is highly appreciated.

Best regards and thanks in advance,

J?rg Polzehl

PS 1: I also tried to install R 1.8.1. from the sources. Everything runs 
as it sould. The base system was working correctly,
installing packages from CRAN works, but again R CMD INSTALL did not 
create the directory for the R-code.

PS 2: The same library installs correctly with   Rcmd INSTALL aws  under 
WINDOWS XP and R 1.8.1.
If I just copy the missing directory from the WINDOWS Installation 
everything works. So the problem either
lies with my LINUX-Box or the INSTALL script ...




**



From tjagoe at liverpool.ac.uk  Fri Feb 13 19:25:35 2004
From: tjagoe at liverpool.ac.uk (Thomas Jagoe)
Date: Fri, 13 Feb 2004 18:25:35 -0000
Subject: [R] predict function
Message-ID: <BEEGJHNEILCHNDMIFAIAIEAGCGAA.tjagoe@liv.ac.uk>

I am using R to do a loess normalisation procedure.
In 1.5.1 I used the following commands to normalise the variable "logratio",
over a 2d surface (defined by coordinates x and y):

> array <- read.table("121203B_QCnew.txt", header=T, sep="\t")
> array$logs555<-log(array$s555)/log(2)
> array$logs647<-log(array$s647)/log(2)
> array$logratio<-array$logs555-array$logs647
> array$logav<-(array$logs555+array$logs647)/2
> library(modreg)
> loess2d<-loess(logratio~x+y,data=array)
> array$logratio2DLoeNorm <-array$logratio - predict.loess(loess2d, array)

However in 1.8.1 all goes well until the last step when I get an error:

Error: couldn't find function "predict.loess"

Can anyone help ?

Thomas



From ligges at statistik.uni-dortmund.de  Fri Feb 13 19:40:04 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 13 Feb 2004 19:40:04 +0100
Subject: [R] predict function
In-Reply-To: <BEEGJHNEILCHNDMIFAIAIEAGCGAA.tjagoe@liv.ac.uk>
References: <BEEGJHNEILCHNDMIFAIAIEAGCGAA.tjagoe@liv.ac.uk>
Message-ID: <402D1A04.1060808@statistik.uni-dortmund.de>

Thomas Jagoe wrote:

> I am using R to do a loess normalisation procedure.
> In 1.5.1 I used the following commands to normalise the variable "logratio",
> over a 2d surface (defined by coordinates x and y):
> 
> 
>>array <- read.table("121203B_QCnew.txt", header=T, sep="\t")
>>array$logs555<-log(array$s555)/log(2)
>>array$logs647<-log(array$s647)/log(2)
>>array$logratio<-array$logs555-array$logs647
>>array$logav<-(array$logs555+array$logs647)/2
>>library(modreg)
>>loess2d<-loess(logratio~x+y,data=array)
>>array$logratio2DLoeNorm <-array$logratio - predict.loess(loess2d, array)
> 
> 
> However in 1.8.1 all goes well until the last step when I get an error:
> 
> Error: couldn't find function "predict.loess"
> 
> Can anyone help ?


Use predict() instead of predict.loess() (the method is hidden in a 
namespace, you should use the generic function).

Uwe Ligges



From tblackw at umich.edu  Fri Feb 13 19:40:25 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Fri, 13 Feb 2004 13:40:25 -0500 (EST)
Subject: [R] Calculate Closest 5 Cases?
In-Reply-To: <20040213163414.QVOS322971.fep04-mail.bloor.is.net.cable.rogers.com@localhost>
References: <20040213163414.QVOS322971.fep04-mail.bloor.is.net.cable.rogers.com@localhost>
Message-ID: <Pine.SOL.4.58.0402131324001.22683@mspacman.gpcc.itd.umich.edu>

Danny  -

The flip answer is, it depends on the size of your computer.
One can readily calculate the number of entries in the pairwise
distance matrix that you would like to calculate, and ask whether
it will fit inside the physical memory installed in your computer.
It is  50,000 x 50,000 x 8 bytes per floating point number, for
a total of 20,000,000,000 bytes or 20 gigabytes.  The critical
information that's still missing is that R needs enough space
for 10 or 20 copies of the largest object in its workspace, in
order to turn around and assign that object to a new name, or
do any summaries on it, etc.  So,  . . .  if you have a computer
with between 200 and 400 gigabytes of random access memory, yes,
you can calculate and summarize the matrix of pairwise distances.
But that requires more memory slots than any ordinary motherboard
provides.  (It would be a mother of a motherboard !)

So, failing that, you could always use Adrian Raftery and Chris
Fraley's 'mclust' package to cluster your data into 50 or more
clusters of very similar cases (instructions for running mclust()
on large data sets are found in the manual which comes with the
package), then calculate all pairwise distances only between the
cases within each cluster.  That's a bit of work to code up.
You wouldn't want to work interactively for each of 50 clusters.
But it certainly can be done in R.  Depends how much effort you
want to put into it.

-  tom blackwell  -  u mighigan medical school  -  ann arbor  -

On Fri, 13 Feb 2004 dsheuman at rogers.com wrote:

> I've only begun investigating R as a substitute for SPSS.
>
> I have a need to identify for each CASE the closest (or most similar) 5
> other CASES (not including itself as it is automatically the closest).  I
> have a fairly large matrix (50000 cases by 50 vars).  In SPSS, I can use Correlate > Distances to generate a matrix of similarity, but only on a small sample.  The entire matrix can not be processed at once due to memory limitations.
>
> The data are all percents, so they are easy comparable.
>
> Is there any way to do this in R?
>
> Below is a small sample of the data (from SPSS) and the desired output.
>
> Thanks,
>
> Danny
>
>
>
>
> *Sample Data.
> DATA LIST LIST /id(F8) var1(F8.2) var2(F8.2) var3(F8.2) var4(F8.2) var5
> (F8.2) var6(F8.2) var7(F8.2) var8(F8.2) var9(F8.2) var10(F8.2) var11(F8.2).
> BEGIN DATA.
> 10170069	3.51	4.02	6.53	11.05	6.53	8.04	13.57	20.10	11.05	8.55
> 	7.04
> 10190229	1.89	5.66	4.61	7.62	8.45	13.21	9.50	20.82	16.07	9.36
> 	3.77
> 10540023	3.40	5.08	3.39	4.52	10.18	14.71	13.56	16.38	9.60	7.89
> 	11.85
> 10650413	6.64	6.64	3.73	4.70	3.78	13.23	19.82	15.98	12.26	8.48
> 	3.78
> 10662074	5.11	5.81	4.37	5.11	6.55	14.60	18.97	11.68	10.25	8.75
> 	8.79
> 10770041	6.43	4.17	6.34	4.26	6.34	4.26	19.11	19.20	14.95	12.77
> 	4.35
> 11010422	3.14	4.71	6.81	7.85	5.75	6.81	15.18	15.18	13.61	11.00
> 	9.44
> 11060762	7.03	5.03	6.95	5.99	5.92	12.94	15.01	12.06	11.98	8.06
> 	9.02
> 11070078	4.61	9.22	4.61	7.94	6.27	12.75	14.02	20.49	7.75	7.75
> 	4.61
> 11180646	4.48	5.35	6.29	5.42	4.55	11.71	20.74	15.32	14.45	8.09
> 	3.61
> 11460001	5.71	7.34	6.48	5.68	4.07	10.55	13.83	18.69	12.15	9.76
> 	4.87
> 11650133	6.00	3.72	6.72	6.00	7.50	17.94	13.44	16.37	13.51	5.15
> 	3.65
> 11650275	4.02	8.06	6.06	8.10	5.06	8.10	17.16	14.12	12.14	14.12
> 	4.02
> 11780034	4.25	4.28	5.30	5.33	6.38	14.88	15.96	18.08	14.85	7.48
> 	3.20
> 11790016	4.40	4.40	5.54	4.40	4.40	10.93	17.67	19.72	13.20	12.13
> 	4.33
> 12660338	6.60	7.54	5.66	8.49	10.38	11.31	16.06	12.26	8.49	8.49
> 	4.73
> 12660644	5.51	3.14	3.95	7.09	7.11	14.98	15.72	18.90	9.44	5.50
> 	8.65
> 12661667	5.44	4.50	5.44	4.50	5.44	12.69	13.63	11.81	9.07	13.68
> 	13.79
> END DATA.
>
> *Output should be:.
> *.
> *	ID1	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
> *	ID2	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
> *	ID3	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
> *	ID4	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
> *	ID5	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Fri Feb 13 19:42:26 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 13 Feb 2004 19:42:26 +0100
Subject: [R] Problems with R CMD INSTALL on SUSE-LINUX 9.0
In-Reply-To: <402D1540.1020407@wias-berlin.de>
References: <402D1540.1020407@wias-berlin.de>
Message-ID: <402D1A92.8040201@statistik.uni-dortmund.de>

Joerg Polzehl wrote:

> Dear Colleagues,
> 
>     I've recently upgraded to SUSE-LINUX 9.0 and R 1.8.1  (using the 
> RPM-'s from CRAN).
> I've checked that all required LINUX-Packages as listet in the 
> README.html in /bin/linux/SUSE
> are installed.
> 
> I've then tried to INSTALL and check a package.
> 
> Installation with
> 
> R CMD INSTALL -l Rcontrib aws
> * Installing *source* package 'aws' ...
> ** libs
> make: ?aws.so? ist bereits aktualisiert.
> ** help
>  >>> Building/Updating help pages for package 'aws'
>     Formats: text html latex example
> * DONE (aws)
> 
> looks fine.

Yes.


> When I try to use the package I get the following:
> 
> polzehl at dhcp-154:~> R
> 
> R : Copyright 2003, The R Foundation for Statistical Computing
> Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
> 
>  > library(aws)
>  > aws
> Error: Object "aws" not found
>  > ls(pos=2)
> character(0)
> q()

Have you set R_LIBS, so that R looks for packages in library Rcontrib ?
I guess you forgot that point.



> The reason is easy to detect:
> 
> polzehl at dhcp-154:~> cd Rcontrib/aws
> polzehl at dhcp-154:~/Rcontrib/aws> ls
> CONTENTS  DESCRIPTION  help  html  INDEX  latex  libs  man  Meta  R-ex
> 
> INSTALL has not created an directory for the source code ... .


Well, binary packages do not contain source code, in principle. So this 
is correct.


Uwe Ligges



> Did I miss something ???   May I need to install some additional package 
> from the SUSE-LINUX-distribution ?
> 
> Any suggestion is highly appreciated.
> 
> Best regards and thanks in advance,
> 
> J?rg Polzehl
> 
> PS 1: I also tried to install R 1.8.1. from the sources. Everything runs 
> as it sould. The base system was working correctly,
> installing packages from CRAN works, but again R CMD INSTALL did not 
> create the directory for the R-code.
> 
> PS 2: The same library installs correctly with   Rcmd INSTALL aws  under 
> WINDOWS XP and R 1.8.1.
> If I just copy the missing directory from the WINDOWS Installation 
> everything works. So the problem either
> lies with my LINUX-Box or the INSTALL script ...
> 
>



From dgrove at fhcrc.org  Fri Feb 13 19:41:54 2004
From: dgrove at fhcrc.org (Douglas Grove)
Date: Fri, 13 Feb 2004 10:41:54 -0800 (PST)
Subject: [R] predict function
In-Reply-To: <BEEGJHNEILCHNDMIFAIAIEAGCGAA.tjagoe@liv.ac.uk>
Message-ID: <Pine.LNX.4.44.0402131040070.11626-100000@jerboa.fhcrc.org>

You can't use this anymore.  The function predict() has a method
for loess objects, but there is no longer an available function
called "predict.loess".   So just replace "predict.loess"
with "predict".


On Fri, 13 Feb 2004, Thomas Jagoe wrote:

> I am using R to do a loess normalisation procedure.
> In 1.5.1 I used the following commands to normalise the variable "logratio",
> over a 2d surface (defined by coordinates x and y):
> 
> > array <- read.table("121203B_QCnew.txt", header=T, sep="\t")
> > array$logs555<-log(array$s555)/log(2)
> > array$logs647<-log(array$s647)/log(2)
> > array$logratio<-array$logs555-array$logs647
> > array$logav<-(array$logs555+array$logs647)/2
> > library(modreg)
> > loess2d<-loess(logratio~x+y,data=array)
> > array$logratio2DLoeNorm <-array$logratio - predict.loess(loess2d, array)
> 
> However in 1.8.1 all goes well until the last step when I get an error:
> 
> Error: couldn't find function "predict.loess"
> 
> Can anyone help ?
> 
> Thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From aragon at berkeley.edu  Fri Feb 13 20:16:36 2004
From: aragon at berkeley.edu (Tomas Aragon)
Date: Fri, 13 Feb 2004 11:16:36 -0800 (PST)
Subject: [R] proportions
In-Reply-To: <007801c3f0ae$2f89c680$5234a8c0@mcardeal>
Message-ID: <20040213191636.23190.qmail@web13904.mail.yahoo.com>


--- Mauricio Cardeal <mcardeal at ufba.br> wrote:
> Hi all:
> 
> Please be patient with my silly question:
> 
> How can I get proportions if I have a contingency table ? 
> 
> I tried the table command, but I almost sure I made my usual
> mistakes.
> 
Try the prop.table function

I am also putting together R manual for epidemiologist, some of which
you may find useful. It available at
http://www.ucbcidp.org/courses/epiwithr.pdf

Tomas

> Thaks
> 
> Mauricio
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html


=====
Tomas Aragon, MD, DrPH
http://www.medepi.org/aragon
Support Open Access! Visit http://www.plos.org



From brahm at alum.mit.edu  Fri Feb 13 20:33:59 2004
From: brahm at alum.mit.edu (David Brahm)
Date: Fri, 13 Feb 2004 14:33:59 -0500
Subject: [R] calling R from a shell script and have it display graphics
References: <402B5C26.90706@lscp.ehess.fr>
Message-ID: <16429.9895.204135.788659@arbres1a.fmr.com>

Christophe Pallier <pallier at lscp.ehess.fr> wrote:
> I would like to call R from a shell script and have it display a series 
> of graphics.
> The graphics should remain visible until the user clicks or presses a key.

One trick is to use locator(1), which waits for a mouse click on a plot.
Here's a minimal Perl script that runs R, displays a plot, and exits when the
click is detected.


eval 'exec /usr/local/bin/perl -s -S $0 "$@"'
  if 0;
open(SCRIPT, "| R --vanilla --slave");
print SCRIPT <<'EOF';

x11(width=5, height=3.5)
plot(1:10, 1:10)
z <- locator(1)
q()

EOF
close(SCRIPT);

-- 
                              -- David Brahm (brahm at alum.mit.edu)



From acuster at nature.berkeley.edu  Fri Feb 13 21:11:26 2004
From: acuster at nature.berkeley.edu (Adrian Custer)
Date: Fri, 13 Feb 2004 12:11:26 -0800
Subject: [R] How to plot a blank plot
Message-ID: <1076703086.3816.44.camel@tsetse.lab-net>

Hello everyone,

In plotting several graphics, I'd like to be able to plot a blank plot
as in:

par(mfrow=c(2,1))
plot(BLANK)
hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="Emergence")

I realize screen allows me to do this, but I figure the functionality
must be there. Is there an equivalent to plot(BLANK)?

thanks,
adrian

PS. please reply direct as I'm not subscribed to the list.



From andy_liaw at merck.com  Fri Feb 13 21:21:11 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 13 Feb 2004 15:21:11 -0500
Subject: [R] How to plot a blank plot
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77B2@usrymx25.merck.com>

Is plot.new() what you're looking for?

Andy

> From: Adrian Custer
> 
> Hello everyone,
> 
> In plotting several graphics, I'd like to be able to plot a blank plot
> as in:
> 
> par(mfrow=c(2,1))
> plot(BLANK)
> hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="
> Emergence")
> 
> I realize screen allows me to do this, but I figure the functionality
> must be there. Is there an equivalent to plot(BLANK)?
> 
> thanks,
> adrian
> 
> PS. please reply direct as I'm not subscribed to the list.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ccleland at optonline.net  Fri Feb 13 21:28:57 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 13 Feb 2004 15:28:57 -0500
Subject: [R] How to plot a blank plot
In-Reply-To: <1076703086.3816.44.camel@tsetse.lab-net>
References: <1076703086.3816.44.camel@tsetse.lab-net>
Message-ID: <402D3389.40304@optonline.net>

Adrian Custer wrote:

> In plotting several graphics, I'd like to be able to plot a blank plot
> as in:
> 
> par(mfrow=c(2,1))
> plot(BLANK)
> hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="Emergence")
> 
> I realize screen allows me to do this, but I figure the functionality
> must be there. Is there an equivalent to plot(BLANK)?

par(mfrow=c(2,1))
frame()
hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="Emergence")

see ?frame

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From MSchwartz at medanalytics.com  Fri Feb 13 21:31:19 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 13 Feb 2004 14:31:19 -0600
Subject: [R] How to plot a blank plot
In-Reply-To: <1076703086.3816.44.camel@tsetse.lab-net>
References: <1076703086.3816.44.camel@tsetse.lab-net>
Message-ID: <1076704278.18869.1.camel@localhost.localdomain>

On Fri, 2004-02-13 at 14:11, Adrian Custer wrote:
> Hello everyone,
> 
> In plotting several graphics, I'd like to be able to plot a blank plot
> as in:
> 
> par(mfrow=c(2,1))
> plot(BLANK)
> hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="Emergence")
> 
> I realize screen allows me to do this, but I figure the functionality
> must be there. Is there an equivalent to plot(BLANK)?
> 
> thanks,
> adrian
> 
> PS. please reply direct as I'm not subscribed to the list.


Try either:

par(mfrow=c(2,1))
frame()
hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="Emergence")

or 

par(mfrow=c(2,1))
plot.new()
hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="Emergence")

See ?plot.new or ?frame, which will lead you to the same help page.

HTH,

Marc Schwartz



From dsheuman at rogers.com  Fri Feb 13 21:35:23 2004
From: dsheuman at rogers.com (dsheuman@rogers.com)
Date: Fri, 13 Feb 2004 15:35:23 -0500
Subject: [R] Re: Re: Find Closest 5 Cases?
Message-ID: <20040213203523.JMFR490347.web02-imail.rogers.com@localhost>

Art (and group),

I'm doing this as a form of missing value analysis.  Approximately 30% of the cases are missing data for one variable.  To impute values for those cases, I'd like to match those cases that are missing the variable to all other cases and then take an average of those to infill.

I realize there are many methods for imputing data.  I'm not well versed on any in particular (expect regression and cluster analysis).  That said, given that I have an extensive data set already with most variables populated, I can find the closest observations in N-dimentional space and impute the value that way - by focusing on the best matches.

If there are any other thoughts on how to do this (relatively easily), I'm open to suggestions and being educated.

Thanks,

Danny

> From: Art Kendall <Art at DrKendall.org>
> Date: 2004/02/13 Fri PM 02:47:00 EST
> To: Danny Heuman <a0079454 at airnews.net>
> Subject: Re: Find Closest 5 Cases?
> 
> This would be extremely compute intensive.
> Why are you trying to do this?
> Do the 5 percentages sum to a constant total?
> 
> If you tell us more about the problem and its context perhaps we can make some suggestions.
> 
> E.g., if you could live with groups of any size that are close
> you might try transforming the percentages to z's and applying a TWOSTEP
> procedure.
> 
> If your really, really need 5, the use of cluster membership variables
> and distances from cluster centers, could be used to limit searches, but
> I wouldn't want to try to work it out without more info especially since
> I do not presently have SPSS on my system so I could verify my
> recommendations.
> 
> Hope this helps.
> 
> Art
> Art at DrKendall.org
> Social Research Consultants
> University Park, MD USA
> (301) 864-5570
> 
> 
> Danny Heuman wrote:
> 
> > I have a need to identify for each CASE the closest (or most similar) 5 
> > other CASES (not including itself as it is automatically the closest).  I 
> > have a fairly large matrix (50000 cases by 50 vars). 
> 
> 
> 
> 
>



From p.dalgaard at biostat.ku.dk  Fri Feb 13 21:37:18 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Feb 2004 21:37:18 +0100
Subject: [R] Calculate Closest 5 Cases?
In-Reply-To: <20040213163414.QVOS322971.fep04-mail.bloor.is.net.cable.rogers.com@localhost>
References: <20040213163414.QVOS322971.fep04-mail.bloor.is.net.cable.rogers.com@localhost>
Message-ID: <x2oes21zsx.fsf@biostat.ku.dk>

<dsheuman at rogers.com> writes:

> I've only begun investigating R as a substitute for SPSS.
> 
> I have a need to identify for each CASE the closest (or most similar) 5 
> other CASES (not including itself as it is automatically the closest).  I 
> have a fairly large matrix (50000 cases by 50 vars).  In SPSS, I can use Correlate > Distances to generate a matrix of similarity, but only on a small sample.  The entire matrix can not be processed at once due to memory limitations.
> 
> The data are all percents, so they are easy comparable.  
> 
> Is there any way to do this in R?
> 
> Below is a small sample of the data (from SPSS) and the desired output.
> 
> Thanks,
> 
> Danny

This seems to be close:

d <- read.table("tempfile") # needed to edit to get 12 items per line.
close6 <- function(r)
  d$V1[order(apply(d[-1],1,
                   function(r2)dist(rbind(r,r2))))][1:6]
t(apply(d[-1],1,close6))

       [,1]     [,2]     [,3]     [,4]     [,5]     [,6]
1  10170069 11010422 11460001 11070078 12660644 11790016
2  10190229 11780034 11460001 10170069 11650133 11070078
3  10540023 12660644 10662074 11060762 12661667 11070078
4  10650413 11180646 11780034 11790016 10662074 11460001
5  10662074 11060762 10650413 12660338 11180646 10540023
6  10770041 11790016 11650275 11010422 11460001 11180646
7  11010422 10170069 11650275 11460001 11060762 11790016
8  11060762 10662074 12660338 12661667 11010422 11460001
9  11070078 11460001 12660644 10170069 11780034 12660338
10 11180646 10650413 11780034 11790016 11460001 10662074
11 11460001 11790016 11070078 11780034 10650413 10170069
12 11650133 11780034 12660644 11060762 10650413 11460001
13 11650275 11010422 11460001 11790016 11180646 10770041
14 11780034 11650133 11180646 10650413 11790016 11460001
15 11790016 11460001 11180646 11780034 10650413 10770041
16 12660338 11060762 10662074 11650275 11070078 10650413
17 12660644 10540023 11650133 11780034 11070078 11060762
18 12661667 11060762 10662074 10540023 11010422 12660644


Notice that I use a function to get the closest *6* ID's because the
method will include the row itself. If multiple rows have distance
zero, this might be a problem since you're not guaranteed to get the
ID of the "self" row sorted first.

Here's another try:

close5 <- function(i)
  d$V1[-i][order(apply(d[-i,-1],1,function(r)dist(rbind(d[i,-1],r))))[1:5]]

do.call("rbind",lapply(1,nrow(d),close5))

However, for some reason this is much slower. Getting rid of the more
obvious inefficiencies (some of which would really kill you on a large
data set since they involve copying the entire data frame!) doesn't
really help:

dd <- d[-1]
close5 <- function(i) {r1 <- dd[i,];
d$V1[-i][order(apply(dd,1,function(r)dist(rbind(r1,r)))[-i])[1:5]]}

>system.time(do.call("rbind",lapply(1:nrow(d),close5)))
[1] 1.67 0.00 1.67 0.00 0.00

whereas

> system.time(t(apply(d[-1],1,close6)))
[1] 0.23 0.00 0.23 0.00 0.00

Anyone have a better idea, or just an explanation of the slowness? 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From acuster at nature.berkeley.edu  Fri Feb 13 21:39:16 2004
From: acuster at nature.berkeley.edu (Adrian Custer)
Date: Fri, 13 Feb 2004 12:39:16 -0800
Subject: [R] How to plot a blank plot
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF77B2@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF77B2@usrymx25.merck.com>
Message-ID: <1076704756.3816.47.camel@tsetse.lab-net>

No, the opposite.

plot.new() will allow me to plot again in the same location. I want to
skip the current location and plot on the next (bottom) split. I want my
plots on the bottom half of the page so the top half can have my notes.

--adrian

On Fri, 2004-02-13 at 12:21, Liaw, Andy wrote:
> Is plot.new() what you're looking for?
> 
> Andy
> 
> > From: Adrian Custer
> > 
> > Hello everyone,
> > 
> > In plotting several graphics, I'd like to be able to plot a blank plot
> > as in:
> > 
> > par(mfrow=c(2,1))
> > plot(BLANK)
> > hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="
> > Emergence")
> > 
> > I realize screen allows me to do this, but I figure the functionality
> > must be there. Is there an equivalent to plot(BLANK)?
> > 
> > thanks,
> > adrian
> > 
> > PS. please reply direct as I'm not subscribed to the list.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New Jersey, USA 08889), and/or its affiliates (which may be known outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be confidential, proprietary copyrighted and/or legally privileged. It is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please notify us immediately by reply e-mail and then delete it from your system.
> ------------------------------------------------------------------------------



From acuster at nature.berkeley.edu  Fri Feb 13 21:41:16 2004
From: acuster at nature.berkeley.edu (Adrian Custer)
Date: Fri, 13 Feb 2004 12:41:16 -0800
Subject: [R] How to plot a blank plot
In-Reply-To: <402D3389.40304@optonline.net>
References: <1076703086.3816.44.camel@tsetse.lab-net>
	<402D3389.40304@optonline.net>
Message-ID: <1076704876.3582.49.camel@tsetse.lab-net>

frame() it is!

I suspected there would be something simple. :-)

Thanks everyone.

--adrian

On Fri, 2004-02-13 at 12:28, Chuck Cleland wrote:
> Adrian Custer wrote:
> 
> > In plotting several graphics, I'd like to be able to plot a blank plot
> > as in:
> > 
> > par(mfrow=c(2,1))
> > plot(BLANK)
> > hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="Emergence")
> > 
> > I realize screen allows me to do this, but I figure the functionality
> > must be there. Is there an equivalent to plot(BLANK)?
> 
> par(mfrow=c(2,1))
> frame()
> hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="Emergence")
> 
> see ?frame



From Art at drkendall.org  Fri Feb 13 22:09:15 2004
From: Art at drkendall.org (Art Kendall)
Date: Fri, 13 Feb 2004 16:09:15 -0500
Subject: [R] Re: Find Closest 5 Cases?
In-Reply-To: <20040213203523.JMFR490347.web02-imail.rogers.com@localhost>
References: <20040213203523.JMFR490347.web02-imail.rogers.com@localhost>
Message-ID: <402D3CFB.5060405@DrKendall.org>

Dealing with missing data can be very complex.  A lot depends on the 
actual research area under study.  Giving reasonable suggestions would 
take a lot more understanding of the context in which the question is 
being asked, the nature of the data, and the review procedures the 
results would undergo.  How much effort it would take to justify a novel 
way of dealing with missing data also needs to be considered.

Are there variables for each case outside the 5 that are measured as 
percentages?  
Why was the data gathered in the first place? 
What questions is it being used to answer?

Why are the values missing for these particular cases?  Is there any 
reason to believe that missingness is related to what the "true value" is?

Art

dsheuman at rogers.com wrote:

>Art (and group),
>
>I'm doing this as a form of missing value analysis.  Approximately 30% of the cases are missing data for one variable.  To impute values for those cases, I'd like to match those cases that are missing the variable to all other cases and then take an average of those to infill.
>
>I realize there are many methods for imputing data.  I'm not well versed on any in particular (expect regression and cluster analysis).  That said, given that I have an extensive data set already with most variables populated, I can find the closest observations in N-dimentional space and impute the value that way - by focusing on the best matches.
>
>If there are any other thoughts on how to do this (relatively easily), I'm open to suggestions and being educated.
>
>Thanks,
>
>Danny
>
>  
>
>>From: Art Kendall <Art at DrKendall.org>
>>Date: 2004/02/13 Fri PM 02:47:00 EST
>>To: Danny Heuman <a0079454 at airnews.net>
>>Subject: Re: Find Closest 5 Cases?
>>
>>This would be extremely compute intensive.
>>Why are you trying to do this?
>>Do the 5 percentages sum to a constant total?
>>
>>If you tell us more about the problem and its context perhaps we can make some suggestions.
>>
>>E.g., if you could live with groups of any size that are close
>>you might try transforming the percentages to z's and applying a TWOSTEP
>>procedure.
>>
>>If your really, really need 5, the use of cluster membership variables
>>and distances from cluster centers, could be used to limit searches, but
>>I wouldn't want to try to work it out without more info especially since
>>I do not presently have SPSS on my system so I could verify my
>>recommendations.
>>
>>Hope this helps.
>>
>>Art
>>Art at DrKendall.org
>>Social Research Consultants
>>University Park, MD USA
>>(301) 864-5570
>>
>>
>>Danny Heuman wrote:
>>
>>    
>>
>>>I have a need to identify for each CASE the closest (or most similar) 5 
>>>other CASES (not including itself as it is automatically the closest).  I 
>>>have a fairly large matrix (50000 cases by 50 vars). 
>>>      
>>>
>>
>>
>>
>>    
>>
>
>
>  
>



From davison at uchicago.edu  Fri Feb 13 22:12:42 2004
From: davison at uchicago.edu (Dan Davison)
Date: Fri, 13 Feb 2004 15:12:42 -0600 (CST)
Subject: [R] profiling C code
Message-ID: <Pine.GSO.4.21.0402131507440.20593-100000@harper.uchicago.edu>

I'd like to profile some C code that I'm calling using .Call(). Could
someone point me towards some instructions for doing this, or suggest a
way to go about it (other than creating an independent C program from my
code?)?

Thanks a lot,

Dan

-------------------------------------------------------------
Dan Davison     
Committee on Evolutionary Biology, University of Chicago, USA
Field Museum of Natural History, Chicago, USA
http://home.uchicago.edu/~davison/



From macq at llnl.gov  Fri Feb 13 22:31:04 2004
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 13 Feb 2004 13:31:04 -0800
Subject: [R] How to plot a blank plot
In-Reply-To: <1076704876.3582.49.camel@tsetse.lab-net>
References: <1076703086.3816.44.camel@tsetse.lab-net>
	<402D3389.40304@optonline.net>
	<1076704876.3582.49.camel@tsetse.lab-net>
Message-ID: <p06002006bc52f1c6547d@[128.115.153.6]>

And although frame() is obviously the better way, if you really 
wanted to know what to put inside plot(), this will do it:

    plot(1, type='n', xaxt='n', yaxt='n', xlab='', ylab='', bty='n')

-Don

At 12:41 PM -0800 2/13/04, Adrian Custer wrote:
>frame() it is!
>
>I suspected there would be something simple. :-)
>
>Thanks everyone.
>
>--adrian
>
>On Fri, 2004-02-13 at 12:28, Chuck Cleland wrote:
>>  Adrian Custer wrote:
>>
>>  > In plotting several graphics, I'd like to be able to plot a blank plot
>>  > as in:
>>  >
>>  > par(mfrow=c(2,1))
>>  > plot(BLANK)
>>  > hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="Emergence")
>>  >
>>  > I realize screen allows me to do this, but I figure the functionality
>>  > must be there. Is there an equivalent to plot(BLANK)?
>>
>>  par(mfrow=c(2,1))
>>  frame()
>>  hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="Emergence")
>>
>>  see ?frame
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From jones at reed.edu  Fri Feb 13 22:32:48 2004
From: jones at reed.edu (Albyn Jones)
Date: Fri, 13 Feb 2004 13:32:48 -0800
Subject: [R] Calculate Closest 5 Cases?
In-Reply-To: <Pine.SOL.4.58.0402131324001.22683@mspacman.gpcc.itd.umich.edu>
References: <20040213163414.QVOS322971.fep04-mail.bloor.is.net.cable.rogers.com@localhost>
	<Pine.SOL.4.58.0402131324001.22683@mspacman.gpcc.itd.umich.edu>
Message-ID: <20040213213247.GY19137@sellwood.reed.edu>

A quick and dirty clustering method (I think its due to Hartigan, at
least I recall first seeing it in his book on clustering) is to pick a
random set of seed cases, and then make one pass through the data,
assigning each case to the seed closest to it.  Then you can compute
your distance matrices within the resulting clusters.  You could do
this within the resulting clusters again to reduce the size of the
distance matrix computation, and you would need to check neighboring
"clusters" for close points.

albyn

On Fri, Feb 13, 2004 at 01:40:25PM -0500, Tom Blackwell wrote:
> Danny  -
> 
> The flip answer is, it depends on the size of your computer.
> One can readily calculate the number of entries in the pairwise
> distance matrix that you would like to calculate, and ask whether
> it will fit inside the physical memory installed in your computer.
> It is  50,000 x 50,000 x 8 bytes per floating point number, for
> a total of 20,000,000,000 bytes or 20 gigabytes.  The critical
> information that's still missing is that R needs enough space
> for 10 or 20 copies of the largest object in its workspace, in
> order to turn around and assign that object to a new name, or
> do any summaries on it, etc.  So,  . . .  if you have a computer
> with between 200 and 400 gigabytes of random access memory, yes,
> you can calculate and summarize the matrix of pairwise distances.
> But that requires more memory slots than any ordinary motherboard
> provides.  (It would be a mother of a motherboard !)
> 
> So, failing that, you could always use Adrian Raftery and Chris
> Fraley's 'mclust' package to cluster your data into 50 or more
> clusters of very similar cases (instructions for running mclust()
> on large data sets are found in the manual which comes with the
> package), then calculate all pairwise distances only between the
> cases within each cluster.  That's a bit of work to code up.
> You wouldn't want to work interactively for each of 50 clusters.
> But it certainly can be done in R.  Depends how much effort you
> want to put into it.
> 
> -  tom blackwell  -  u mighigan medical school  -  ann arbor  -
> 
> On Fri, 13 Feb 2004 dsheuman at rogers.com wrote:
> 
> > I've only begun investigating R as a substitute for SPSS.
> >
> > I have a need to identify for each CASE the closest (or most similar) 5
> > other CASES (not including itself as it is automatically the closest).  I
> > have a fairly large matrix (50000 cases by 50 vars).  In SPSS, I can use Correlate > Distances to generate a matrix of similarity, but only on a small sample.  The entire matrix can not be processed at once due to memory limitations.
> >
> > The data are all percents, so they are easy comparable.
> >
> > Is there any way to do this in R?
> >
> > Below is a small sample of the data (from SPSS) and the desired output.
> >
> > Thanks,
> >
> > Danny
> >
> >
> >
> >
> > *Sample Data.
> > DATA LIST LIST /id(F8) var1(F8.2) var2(F8.2) var3(F8.2) var4(F8.2) var5
> > (F8.2) var6(F8.2) var7(F8.2) var8(F8.2) var9(F8.2) var10(F8.2) var11(F8.2).
> > BEGIN DATA.
> > 10170069	3.51	4.02	6.53	11.05	6.53	8.04	13.57	20.10	11.05	8.55
> > 	7.04
> > 10190229	1.89	5.66	4.61	7.62	8.45	13.21	9.50	20.82	16.07	9.36
> > 	3.77
> > 10540023	3.40	5.08	3.39	4.52	10.18	14.71	13.56	16.38	9.60	7.89
> > 	11.85
> > 10650413	6.64	6.64	3.73	4.70	3.78	13.23	19.82	15.98	12.26	8.48
> > 	3.78
> > 10662074	5.11	5.81	4.37	5.11	6.55	14.60	18.97	11.68	10.25	8.75
> > 	8.79
> > 10770041	6.43	4.17	6.34	4.26	6.34	4.26	19.11	19.20	14.95	12.77
> > 	4.35
> > 11010422	3.14	4.71	6.81	7.85	5.75	6.81	15.18	15.18	13.61	11.00
> > 	9.44
> > 11060762	7.03	5.03	6.95	5.99	5.92	12.94	15.01	12.06	11.98	8.06
> > 	9.02
> > 11070078	4.61	9.22	4.61	7.94	6.27	12.75	14.02	20.49	7.75	7.75
> > 	4.61
> > 11180646	4.48	5.35	6.29	5.42	4.55	11.71	20.74	15.32	14.45	8.09
> > 	3.61
> > 11460001	5.71	7.34	6.48	5.68	4.07	10.55	13.83	18.69	12.15	9.76
> > 	4.87
> > 11650133	6.00	3.72	6.72	6.00	7.50	17.94	13.44	16.37	13.51	5.15
> > 	3.65
> > 11650275	4.02	8.06	6.06	8.10	5.06	8.10	17.16	14.12	12.14	14.12
> > 	4.02
> > 11780034	4.25	4.28	5.30	5.33	6.38	14.88	15.96	18.08	14.85	7.48
> > 	3.20
> > 11790016	4.40	4.40	5.54	4.40	4.40	10.93	17.67	19.72	13.20	12.13
> > 	4.33
> > 12660338	6.60	7.54	5.66	8.49	10.38	11.31	16.06	12.26	8.49	8.49
> > 	4.73
> > 12660644	5.51	3.14	3.95	7.09	7.11	14.98	15.72	18.90	9.44	5.50
> > 	8.65
> > 12661667	5.44	4.50	5.44	4.50	5.44	12.69	13.63	11.81	9.07	13.68
> > 	13.79
> > END DATA.
> >
> > *Output should be:.
> > *.
> > *	ID1	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
> > *	ID2	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
> > *	ID3	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
> > *	ID4	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
> > *	ID5	CLOSEID1	CLOSEID2	CLOSEID3	CLOSEID4	CLOSEID5.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
========================================================================
 ...armaments were not created chiefly for the protection of the 
    nations but for their enslavement.  

    The new political gospel: public office is private graft.

    [Mark Twain]
================================================================
http://www.reed.edu/~jones    Albyn Jones	  jones at reed.edu
Reed College, Portland OR 97202             (503)-771-1112 x7418



From sdavis2 at mail.nih.gov  Fri Feb 13 22:45:52 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 13 Feb 2004 16:45:52 -0500
Subject: [R] Re: Re: Find Closest 5 Cases?
In-Reply-To: <20040213203523.JMFR490347.web02-imail.rogers.com@localhost>
Message-ID: <BC52AFC0.4976%sdavis2@mail.nih.gov>

Danny,

In the bioconductor suite (www.bioconductor.org) in the pamr package there
is a program called pamr.knnimpute that will probably at least close to what
you would like to do.

Sean
-- 
Sean Davis, M.D., Ph.D.

Clinical Fellow
National Institutes of Health
National Cancer Institute
National Human Genome Research Institute

Clinical Fellow, Johns Hopkins
Department of Pediatric Oncology
-- 



On 2/13/04 3:35 PM, "dsheuman at rogers.com" <dsheuman at rogers.com> wrote:

> Art (and group),
> 
> I'm doing this as a form of missing value analysis.  Approximately 30% of the
> cases are missing data for one variable.  To impute values for those cases,
> I'd like to match those cases that are missing the variable to all other cases
> and then take an average of those to infill.
> 
> I realize there are many methods for imputing data.  I'm not well versed on
> any in particular (expect regression and cluster analysis).  That said, given
> that I have an extensive data set already with most variables populated, I can
> find the closest observations in N-dimentional space and impute the value that
> way - by focusing on the best matches.
> 
> If there are any other thoughts on how to do this (relatively easily), I'm
> open to suggestions and being educated.
> 
> Thanks,
> 
> Danny
> 
>> From: Art Kendall <Art at DrKendall.org>
>> Date: 2004/02/13 Fri PM 02:47:00 EST
>> To: Danny Heuman <a0079454 at airnews.net>
>> Subject: Re: Find Closest 5 Cases?
>> 
>> This would be extremely compute intensive.
>> Why are you trying to do this?
>> Do the 5 percentages sum to a constant total?
>> 
>> If you tell us more about the problem and its context perhaps we can make
>> some suggestions.
>> 
>> E.g., if you could live with groups of any size that are close
>> you might try transforming the percentages to z's and applying a TWOSTEP
>> procedure.
>> 
>> If your really, really need 5, the use of cluster membership variables
>> and distances from cluster centers, could be used to limit searches, but
>> I wouldn't want to try to work it out without more info especially since
>> I do not presently have SPSS on my system so I could verify my
>> recommendations.
>> 
>> Hope this helps.
>> 
>> Art
>> Art at DrKendall.org
>> Social Research Consultants
>> University Park, MD USA
>> (301) 864-5570
>> 
>> 
>> Danny Heuman wrote:
>> 
>>> I have a need to identify for each CASE the closest (or most similar) 5
>>> other CASES (not including itself as it is automatically the closest).  I
>>> have a fairly large matrix (50000 cases by 50 vars).
>> 
>> 
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ccleland at optonline.net  Fri Feb 13 23:02:12 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 13 Feb 2004 17:02:12 -0500
Subject: [R] Re: Re: Find Closest 5 Cases?
In-Reply-To: <20040213203523.JMFR490347.web02-imail.rogers.com@localhost>
References: <20040213203523.JMFR490347.web02-imail.rogers.com@localhost>
Message-ID: <402D4964.7080000@optonline.net>

dsheuman at rogers.com wrote:
> I'm doing this as a form of missing value analysis.  Approximately 30% of the cases are missing data for one variable.  To impute values for those cases, I'd like to match those cases that are missing the variable to all other cases and then take an average of those to infill.
> 
> I realize there are many methods for imputing data.  I'm not well versed on any in particular (expect regression and cluster analysis).  That said, given that I have an extensive data set already with most variables populated, I can find the closest observations in N-dimentional space and impute the value that way - by focusing on the best matches.
> 
> If there are any other thoughts on how to do this (relatively easily), I'm open to suggestions and being educated.

You might have a look at impute.knn() in the impute package on CRAN.

mymat <- matrix(rbinom(50000*20, 1, .5), ncol=20)
mymat[sample(50000, 50000*.30),5] <- NA
summary(mymat)
summary(impute.knn(mymat, k=5)$data)

hope this helps,

Chuck Cleland

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From jfox at mcmaster.ca  Fri Feb 13 23:13:27 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 13 Feb 2004 17:13:27 -0500
Subject: [R] Problems loading dataset in Rcmdr
In-Reply-To: <200402131506.i1DF6IAA019201@mail1.slu.se>
Message-ID: <5.1.0.14.2.20040213170834.02009df0@127.0.0.1>

Dear CG,

These symptoms seem very odd to me, particularly since everything was 
working well until two days ago.

Is it possible that you have a saved workspace that is being loaded each 
time you run R? I don't believe that a saved workspace will be removed by 
an uninstall and reinstall of R (to the same location). It's possible, I 
suppose, that there's something in the workspace that is interfering with 
the Rcmdr.

If this proves not to be the case, does traceback() give you any useful 
information? Are you able to read data sets from any source in Rcmdr?

I hope this helps, but if it doesn't perhaps you can supply some more 
information.

John

At 04:06 PM 2/13/2004 +0100, CG Pettersson wrote:
>Hello all!
>I?ve been using Rcmdr for some time, as a quick way of producing
>graphics and basic statistics. I run R1.8.1, OS W2000.
>
>Two days ago the dataset loader stopped working. Normally, the button
><No active dataset> is clickable to give you the opportunity to choose
>dataset to load in the Rcmdr context. Clicking on the button now
>produces this:
>
>Rcmdr Version 0.9-3
>Error in parse(file, n, text, prompt) : parse error
>
>What is happening and what could I do to get out of it?
>(I have removed Rcmdr and downloaded it again from CRAN, as well as
>uninstalled R, reinstalling it from the copy of my download.
>
>Doesn?t help so far.
>Please help!
>
>/CG

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From tkubarych at vcu.edu  Fri Feb 13 23:16:05 2004
From: tkubarych at vcu.edu (Tom Kubarych)
Date: Fri, 13 Feb 2004 17:16:05 -0500
Subject: [R] parametric bootstrap and computing factor scores
Message-ID: <402D4CA5.7060707@vcu.edu>

We have a project on which we need to compare various methods for 
computing factor scores.  Are there any R routines available that do 
parametric bootstrap or compute factor scores?



From friendly at yorku.ca  Sat Feb 14 00:18:39 2004
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 13 Feb 2004 18:18:39 -0500
Subject: [R] AGREP
Message-ID: <402D5B4F.2070506@yorku.ca>

The problem of calculating levenshtein distances between strings reminds 
me of what I faced
years ago when writing an APL system to control interactive memory 
experiments, where subjects
typed words they could remember from a given list. 

To handle typos, I used the generalized outer product operator, null dot 
equals to create
a binary matrix comparing an input string with each correct word,

input o.= word

giving a 0/1 array whose rows reprepresented the letters in the input 
and whose columns
the letters in the output, from which varous measures of string 
similarity could be calculated
using reduction operators, or even a correlation, based on the positions 
of the 1s.
Thinking in arrays always helps avoid explicit loops.

-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From Danny at intelligent-results.com  Sat Feb 14 00:48:48 2004
From: Danny at intelligent-results.com (Danny Rosenthal)
Date: Fri, 13 Feb 2004 15:48:48 -0800
Subject: [R] Problems getting R to work from Java under Windows
Message-ID: <9886170319A92C40BDA3ADE59A5A34BE02CDA0@exchange2.intelligent-results.com>

Hi:

I have been trying to get R to work from Java in a Windows XP
environment.  I have spent a significant amount of time looking at how
other people resolved my issue but have not found anything so far.

Specifically when I try to start up the interpreter, such as through the
JavaRCall example, I get the following message:

        Fatal error: unable to open the base package.

I have checked everything I can think of.  I have all the environment
variables, including R_HOME, set up, and I have all the classpath
information included.  I looked at all the file permissions, and they
are all set for full access.

I have tried this with build 1081 and 1071, and I get the same results.

Any ideas?

Danny Rosenthal



From rbaer at atsu.edu  Sat Feb 14 01:56:02 2004
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Fri, 13 Feb 2004 18:56:02 -0600
Subject: [R] Digital Image Processing
Message-ID: <002001c3f295$51b01910$2e80010a@BigBaer>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040213/4cb3ae6e/attachment.pl

From stms_th at ybb.ne.jp  Sat Feb 14 02:09:43 2004
From: stms_th at ybb.ne.jp (Masaei Sato)
Date: Sat, 14 Feb 2004 10:09:43 +0900 (JST)
Subject: [R] Almost Ideal Demand System
In-Reply-To: <200402131531.32816.ahenningsen@email.uni-kiel.de>
References: <6B5A9304046AD411BD0200508BDFB6CB021F0FA6@gimli.middleearth.kssg.com>
	<200402131531.32816.ahenningsen@email.uni-kiel.de>
Message-ID: <20040214.100943.78701824.stms_th@ybb.ne.jp>

Hi Arne,

I think that the R is a powerful programming language for an
econometric analysis. But the R is less used in economics as
compared with other fields.  So, if you will release your
package, those who are working/studying in the field of
applied economics will surely get profit. 
I'm looking forward to your package.

--
Masaei Sato

From: Arne Henningsen <ahenningsen at email.uni-kiel.de>
Subject: Re: [R] Almost Ideal Demand System
Date: Fri, 13 Feb 2004 15:31:32 +0100
Message-ID: <200402131531.32816.ahenningsen at email.uni-kiel.de>

> Hi Wayne, 
> 
> I did some demand analsis with R and the systemfit package. For me it worked 
> very well. Therefore, I want to prepare a new package for R that contains the 
> functions to estimate the (LA-)AIDS, calculates the demand elasticities and 
> so on. However, it will take me some time until this package will be ready, 
> but if you are (or someone else is) interested, I can prepare an (almost 
> undocumented) "alpha" release.
> 
> Best wishes,
> Arne
> 
> 
> On Thursday 12 February 2004 13:00, Wayne Jones wrote:
> > Hi there fellow R users,
> >
> >>>> <!-- auto_snip -->
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> 
> -- 
> Arne Henningsen
> Department of Agricultural Economics
> University of Kiel
> Olshausenstr. 40
> D-24098 Kiel (Germany)
> Tel: +49-431-880 4445
> Fax: +49-431-880 1397
> ahenningsen at agric-econ.uni-kiel.de
> http://www.uni-kiel.de/agrarpol/ahenningsen/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From MSchwartz at medanalytics.com  Sat Feb 14 05:20:33 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 13 Feb 2004 22:20:33 -0600
Subject: [R] How to plot a blank plot
In-Reply-To: <p06002006bc52f1c6547d@[128.115.153.6]>
References: <1076703086.3816.44.camel@tsetse.lab-net>
	<402D3389.40304@optonline.net>
	<1076704876.3582.49.camel@tsetse.lab-net>
	<p06002006bc52f1c6547d@[128.115.153.6]>
Message-ID: <1076732433.18869.57.camel@localhost.localdomain>

On Fri, 2004-02-13 at 15:31, Don MacQueen wrote:
> And although frame() is obviously the better way, if you really 
> wanted to know what to put inside plot(), this will do it:
> 
>     plot(1, type='n', xaxt='n', yaxt='n', xlab='', ylab='', bty='n')
> 
> -Don


A slightly shorter version of the same thing is:

plot(1, ann = FALSE, axes = FALSE, type = "n")

This gives you a blank plot area with the following, perhaps most
important, par value:

> par("usr")
[1] 0.568 1.432 0.568 1.432


plot.new() and frame() give you the following:

> par("usr")
[1] -0.04  1.04 -0.04  1.04

Recall that par("usr") is c(x1, x2, y1, y2).


In either case, the above values can be overridden by a subsequent call
to par("usr"), such as the following:

par(usr = c(0, 1, 0, 1))

Thus setting the x and y ranges to known values if one needs them a
particular way.  

Another way of accomplishing the same thing with a single function call
is:

plot(1, ann = FALSE, axes = FALSE, xlim = c(0, 1), ylim = c(0, 1), 
     type = "n", xaxs = "i", yaxs = "i")

The use of 'xaxs' and 'yaxs' sets the ranges of the x and y axes to
exactly the limits specified, rather than extending both by 4%, which is
the default (with values of "r"). This yields:

> par("usr")
[1] 0 1 0 1

instead of:

> par("usr")
[1] -0.04  1.04 -0.04  1.04

as seen above from a default call to plot.new() or frame().

So, ultimately, if you are not going to actually draw anything in the
particular plot region as is Adrian's situation, such that you are not
concerned with the coordinates and other details, plot.new() and frame()
are the quickest as Don, I and others have pointed out. 

Indeed, as ?frame points out:

"...('frame' is an alias for 'plot.new')..."

> frame
function () 
.Internal(plot.new())
<environment: namespace:base>


So which one you pick is really a personal preference choice. As is the
case frequently with R, there is more than one way to get to the same
end point, some more 'elegant' than others.

HTH,

Marc Schwartz



From bw at northbranchlogic.com  Sat Feb 14 02:31:55 2004
From: bw at northbranchlogic.com (Barnet Wagman)
Date: Fri, 13 Feb 2004 19:31:55 -0600
Subject: [R] 
	How to configure ess-5.2.0beta3-1.i586.rpm, Xemacs and SuSE 9.0?
Message-ID: <402D7A8B.6010006@northbranchlogic.com>

I'm trying to get R and ESS to work with Xemacs on a newly installed 
SuSE 9.0 system. Is some setup required beyond installing the rpms?  
I've installed the Xemacs packages from SuSE

xemacs-info-21.4.13-35
xemacs-packages-el-20030629-37
xemacs-21.4.13-35
xemacs-el-21.4.13-35
xemacs-packages-info-20030629-37
xemacs-packages-20030629-37


ess-5.2.0beta3-1.i586.rpm



From bw at northbranchlogic.com  Sat Feb 14 02:41:09 2004
From: bw at northbranchlogic.com (Barnet Wagman)
Date: Fri, 13 Feb 2004 19:41:09 -0600
Subject: [R] PLEASE IGNORE PREVIOUS: How to configure
 ess-5.2.0beta3-1.i586.rpm, Xemacs and SuSE 9.0?
Message-ID: <402D7CB5.4050908@northbranchlogic.com>

Please ignore (and excuse) my previous message - it is incomplete.

I'm trying to get R and ESS to work with Xemacs on a newly installed 
SuSE 9.0 system. Is some setup required beyond installing the rpms?  
I've installed the Xemacs packages from SuSE

xemacs-info-21.4.13-35
xemacs-packages-el-20030629-37
xemacs-21.4.13-35
xemacs-el-21.4.13-35
xemacs-packages-info-20030629-37
xemacs-packages-20030629-37

R-base-1.8.1-3.i586.rpm (from the SuSE 9.0 directory on CRAN)

and

ess-5.2.0beta3-1.i586.rpm     R-base-1.8.1-3.i586.rpm

The usual 'M-x R' command sequence is not recognized by Xemacs. I 
vaguely recall a requirement (in older versions) to add something to the 
.xemacs file, but haven't been able to find anything about this in the 
ESS web page or on this list.

Thanks,

bw



From rossini at blindglobe.net  Sat Feb 14 08:52:54 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 13 Feb 2004 23:52:54 -0800
Subject: [R] PLEASE IGNORE PREVIOUS: How to configure
	ess-5.2.0beta3-1.i586.rpm, Xemacs and SuSE 9.0?
In-Reply-To: <402D7CB5.4050908@northbranchlogic.com> (Barnet Wagman's
	message of "Fri, 13 Feb 2004 19:41:09 -0600")
References: <402D7CB5.4050908@northbranchlogic.com>
Message-ID: <85bro2umg9.fsf@servant.blindglobe.net>


You need something like 

(require 'ess-site) 

in your .xemacs/init.el file.    I'd suggest posting to the ESS-help
list, though.



Barnet Wagman <bw at northbranchlogic.com> writes:

> Please ignore (and excuse) my previous message - it is incomplete.
>
> I'm trying to get R and ESS to work with Xemacs on a newly installed
> SuSE 9.0 system. Is some setup required beyond installing the rpms?
> I've installed the Xemacs packages from SuSE
>
> xemacs-info-21.4.13-35
> xemacs-packages-el-20030629-37
> xemacs-21.4.13-35
> xemacs-el-21.4.13-35
> xemacs-packages-info-20030629-37
> xemacs-packages-20030629-37
>
> R-base-1.8.1-3.i586.rpm (from the SuSE 9.0 directory on CRAN)
>
> and
>
> ess-5.2.0beta3-1.i586.rpm     R-base-1.8.1-3.i586.rpm
>
> The usual 'M-x R' command sequence is not recognized by Xemacs. I
> vaguely recall a requirement (in older versions) to add something to
> the .xemacs file, but haven't been able to find anything about this in
> the ESS web page or on this list.
>
> Thanks,
>
> bw
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From patrick.giraudoux at univ-fcomte.fr  Sat Feb 14 10:10:49 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 14 Feb 2004 10:10:49 +0100
Subject: [R] points inout a circle
Message-ID: <000901c3f2da$761e10a0$7d703051@PC728329681112>

Dear all,

I would like to generate a circles of various diameters centered on a point in such a way each circle could be considered as a
polygon and used further as such eg with the library splancs. The aim is to sweep each point on a grid or a "random" field of points
and select other points wich are included in the circle (eg inout), for neighbourhood analysis.

II wonder if such a function has been implemented in a package? (I did not find anything in the archives).

Thanks for any hint.

Best regards,

Patrick Giraudoux



From Roger.Bivand at nhh.no  Sat Feb 14 11:24:05 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 14 Feb 2004 11:24:05 +0100 (CET)
Subject: [R] Digital Image Processing
In-Reply-To: <002001c3f295$51b01910$2e80010a@BigBaer>
Message-ID: <Pine.LNX.4.44.0402141115100.1670-100000@reclus.nhh.no>

On Fri, 13 Feb 2004, Robert W. Baer, Ph.D. wrote:

> I have seen several posts (but few answers) in "R-help search" as to
> whether there are any packages that use R to process digital images.  
> There are several categories related to the general type of problem that
> are useful to know about: -- Any existing packages for taking a digital
> image format {any flavor like TIFF, jpg, png, or GIF (or even TWAIN
> input)} and representing it internally in R as RGB or HSB arrays? -- Any
> existing packages for taking array representations of an image and
> representing it "graphically" as a "bitmap" (colored?) image in an R
> window? -- Any digital filter, image (signal) processing packages
> specifically directed at "image processing" or computer vision sorts of
> problems?

The basic package is pixmap, which reads PNM files on all platforms, and 
converts them to new-style class "pixmap" objects, which are arrays. It is 
not efficient, because each pixel is represented by a double in each band, 
but can be used as a structure to start with.

Beyond that, for reading other formats (including subscenes of other 
formats), rgdal uses the GDAL abstraction library, and can deliver 
pixmaps, or raw vectors of band data, which can also be displayed. Because 
rgdal depends on external libraries, it is not distributed compiled for 
Windows.

Several of the medical image analysis packages also include i/o and 
display functions suited to the data formats they use. 

One (minor) drawback to working with images is that displaying large 
images can tax the graphics output functions, where the basic model is 
vector graphics, but as with all things here, ideas and contributions can 
make a difference. Certainly for prototyping, there should be quite a lot 
of potential.

Roger

> 
> And perhaps the question I should have asked first,  is it silly to think that R might be a useful tool for exploring (prototyping solutions) to image processing problems?
> 
> Thanks for any insights,
> Rob Baer
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Sat Feb 14 11:35:39 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 14 Feb 2004 11:35:39 +0100 (CET)
Subject: [R] points inout a circle
In-Reply-To: <000901c3f2da$761e10a0$7d703051@PC728329681112>
Message-ID: <Pine.LNX.4.44.0402141130510.1670-100000@reclus.nhh.no>

On Sat, 14 Feb 2004, Patrick Giraudoux wrote:

> Dear all,
> 
> I would like to generate a circles of various diameters centered on a
> point in such a way each circle could be considered as a polygon and
> used further as such eg with the library splancs. The aim is to sweep
> each point on a grid or a "random" field of points and select other
> points wich are included in the circle (eg inout), for neighbourhood
> analysis.
> 
> I wonder if such a function has been implemented in a package? (I did
> not find anything in the archives).
> 

Making a circular polygon and then using inout() feels like overkill. If 
you need to stay in splancs, you could just wrap .C("pythag", ...) up in a 
function comparing the returned distance with the circle radius, having 
given it the locations of the two points.

However, I think dnearneigh() in spdep will do what you need, which
returns a list of integer vectors giving the point id numbers for
neighbours satisfying the distance criteria.

Roger

> Thanks for any hint.
> 
> Best regards,
> 
> Patrick Giraudoux
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From mike.hollegger at aon.at  Sat Feb 14 12:03:20 2004
From: mike.hollegger at aon.at (Mike Hollegger)
Date: Sat, 14 Feb 2004 12:03:20 +0100
Subject: [R] converting data to date format
Message-ID: <MABBIKGDCBONJPKOHDOIEEHECBAA.mike.hollegger@aon.at>

Dear all,

I import my data from a csv-file containing one row with date-entries. How
can I tell R to treat this data as dates?

I've tried to bring it in character-format (as.charachter()) followed by
as.POSIXlt() but I get an error message, that the character string is not in
a standard unambiguous format, although the date is of format yyyy-mm-dd
(what is standard format according to R reference manual).

Another thing I tried was to work with as.date() from package date. The
format of the "source"-data is month, day, year (the standard format for the
as.date() function and the error message I got was "cannot coerce to date
format".

Thank you very much for any usefull hint!

Mike



From bxc at steno.dk  Sat Feb 14 12:36:00 2004
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Sat, 14 Feb 2004 12:36:00 +0100
Subject: [R] converting data to date format
Message-ID: <0ABD88905D18E347874E0FB71C0B29E9F74FA1@exdkba022.novo.dk>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mike Hollegger
> Sent: Saturday, February 14, 2004 12:03 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] converting data to date format
> 
> 
> Dear all,
> 

...snip

> I've tried to bring it in character-format (as.charachter()) 
> followed by
> as.POSIXlt() but I get an error message, that the character 
> string is not in
> a standard unambiguous format, although the date is of format 
> yyyy-mm-dd
> (what is standard format according to R reference manual).

...snip

> Thank you very much for any usefull hint!

There seems to be someting fishy about 1 january 1970, I think it
is a bug in Windows:

> as.POSIXlt("1970-01-01")
Error in fromchar(x) : character string is not in a standard unambiguous
format
> as.POSIXlt("1970-01-02")
[1] "1970-01-02"
> as.POSIXlt("1970-02-01")
[1] "1970-02-01"
> as.POSIXlt("1970-12-31")
[1] "1970-12-31"

A workaround is:

> as.POSIXlt( strptime("1970-01-01",format="%Y-%m-%d") )
[1] "1970-01-01"

A peep at fromchar which is defined inside as.POSIXlt lead one to
try the following:

> is.na( strptime("1970-01-01", f <- "%Y-%m-%d") )
[1] TRUE
> strptime("1970-01-01", f <- "%Y-%m-%d")
[1] "1970-01-01"
> is.na( strptime("1970-01-02", f <- "%Y-%m-%d") )
[1] FALSE
> strptime("1970-01-02", f <- "%Y-%m-%d")
[1] "1970-01-02"

I would like to why this is so. And whether thereason for this
it is beyond R.

Btw, I use:
> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    8.1            
year     2003           
month    11             
day      21             
language R   

Bendix Carstensen
----------------------
Bendix Carstensen
Senior Statistician
Steno Diabetes Center
Niels Steensens Vej 2
DK-2820 Gentofte
Denmark
tel: +45 44 43 87 38
mob: +45 30 75 87 38
fax: +45 44 43 07 06
bxc at steno.dk
www.biostat.ku.dk/~bxc



From bxc at steno.dk  Sat Feb 14 12:50:40 2004
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Sat, 14 Feb 2004 12:50:40 +0100
Subject: [R] A course in using R for Epidemiology
Message-ID: <0ABD88905D18E347874E0FB71C0B29E9F74FA2@exdkba022.novo.dk>

Course in
STATISTICAL PRACTICE IN EPIDEMIOLOGY USING R
====================================================
Tartu, Estonia, 29 May - 4 June 2004.

Aimed at young statisticians and epidemiologists wishing to broaden
their epidemiological skills, in particular with respect to practical
statistical analysis. Participants will gain access to the versatile
analysis tool R, which has good analytical in particular graphical 
capabilities.

Participants are required to have a fairly good understanding of
statistical principles and some familiarity with epidemiological
concepts. The course will be mainly practically oriented with more
than half the time at the computer.

Price: 400 EUR. (200 EUR for non-EU countries).

Application deadline: 1 April 2004.

Further information at: www.biostat.ku.dk/~bxc/SPE

------------------------------------------------------
Krista Fischer, University of Tartu, Estonia
Esa L??r?, University of Oulu, Finland
Bendix Carstensen, Steno Diabetes Center, Denmark 
(Organizers)



From ggrothendieck at myway.com  Sat Feb 14 14:49:58 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 14 Feb 2004 08:49:58 -0500 (EST)
Subject: [R] converting data to date format
Message-ID: <20040214134958.E65CD3964@mprdmxin.myway.com>



What version of Windows are you running?  I tried your commands
on Windows 2000 Pro and Windows XP Pro and was unable to reproduce
the output R gave you on either:

> as.POSIXlt("1970-01-01")
[1] "1970-01-01"
> as.POSIXlt("1970-01-02")
[1] "1970-01-02"
> as.POSIXlt("1970-02-01")
[1] "1970-02-01"
> as.POSIXlt("1970-12-31")
[1] "1970-12-31"
> as.POSIXlt( strptime("1970-01-01",format="%Y-%m-%d") )
[1] "1970-01-01"
> is.na( strptime("1970-01-01", f <- "%Y-%m-%d") )
[1] FALSE
> strptime("1970-01-01", f <- "%Y-%m-%d")
[1] "1970-01-01"
> is.na( strptime("1970-01-02", f <- "%Y-%m-%d") )
[1] FALSE
> strptime("1970-01-02", f <- "%Y-%m-%d")
[1] "1970-01-02"
> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    8.1            
year     2003           
month    11             
day      21             
language R              
> 


---
Date:   Sat, 14 Feb 2004 12:36:00 +0100 
From:   BXC (Bendix Carstensen) <bxc at steno.dk>
To:   Mike Hollegger <mike.hollegger at aon.at> 
Cc:   <r-help at stat.math.ethz.ch> 
Subject:   RE: [R] converting data to date format 

 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mike Hollegger
> Sent: Saturday, February 14, 2004 12:03 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] converting data to date format
> 
> 
> Dear all,
> 

...snip

> I've tried to bring it in character-format (as.charachter()) 
> followed by
> as.POSIXlt() but I get an error message, that the character 
> string is not in
> a standard unambiguous format, although the date is of format 
> yyyy-mm-dd
> (what is standard format according to R reference manual).

...snip

> Thank you very much for any usefull hint!

There seems to be someting fishy about 1 january 1970, I think it
is a bug in Windows:

> as.POSIXlt("1970-01-01")
Error in fromchar(x) : character string is not in a standard unambiguous
format
> as.POSIXlt("1970-01-02")
[1] "1970-01-02"
> as.POSIXlt("1970-02-01")
[1] "1970-02-01"
> as.POSIXlt("1970-12-31")
[1] "1970-12-31"

A workaround is:

> as.POSIXlt( strptime("1970-01-01",format="%Y-%m-%d") )
[1] "1970-01-01"

A peep at fromchar which is defined inside as.POSIXlt lead one to
try the following:

> is.na( strptime("1970-01-01", f <- "%Y-%m-%d") )
[1] TRUE
> strptime("1970-01-01", f <- "%Y-%m-%d")
[1] "1970-01-01"
> is.na( strptime("1970-01-02", f <- "%Y-%m-%d") )
[1] FALSE
> strptime("1970-01-02", f <- "%Y-%m-%d")
[1] "1970-01-02"

I would like to why this is so. And whether thereason for this
it is beyond R.

Btw, I use:
> version
_ 
platform i386-pc-mingw32
arch i386 
os mingw32 
system i386, mingw32 
status 
major 1 
minor 8.1 
year 2003 
month 11 
day 21 
language R 

Bendix Carstensen
----------------------
Bendix Carstensen
Senior Statistician
Steno Diabetes Center
Niels Steensens Vej 2
DK-2820 Gentofte
Denmark
tel: +45 44 43 87 38
mob: +45 30 75 87 38
fax: +45 44 43 07 06
bxc at steno.dk
www.biostat.ku.dk/~bxc

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rolf at math.unb.ca  Sat Feb 14 16:27:22 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Sat, 14 Feb 2004 11:27:22 -0400 (AST)
Subject: [R] predict function
Message-ID: <200402141527.i1EFRMII023171@erdos.math.unb.ca>


Uwe Ligges wrote:

> Thomas Jagoe wrote:
> 
> > I am using R to do a loess normalisation procedure.
    .
    .
    .
> > However in 1.8.1 all goes well until the last step when I get an error:
> > 
> > Error: couldn't find function "predict.loess"
> > 
> > Can anyone help ?
> 
> 
> Use predict() instead of predict.loess() (the method is hidden in a 
> namespace, you should use the generic function).
> 
> Uwe Ligges

Why are the developers ***DOING*** these things to us?

It used to be so simple and straightforward!  If I wanted to look
at an object, including a function object, I typed its name.  Now
I get hand-cuffed by this ``namespace'' business!  I will wager
Euros to doughnuts that no-one apart from the developers has a clue
what a ``namespace'' is, much less what it is good for.  Whatever
problem ``namespaces'' were introduced to solve, it pales by
comparison with the handicaps they introduce.

It's classic tail-wagging-the-dog syndrome.

When I get errors from R code, which come from within ``system''
functions, it has been my practice to make a local copy (in the
.Globalenv) of the function, stick in calls to browser(), and
thereby track down what's going on/wrong.  This always worked like a
charm. Now if the problem arises within, e.g. predict.loess, I'm
stuffed.

					cheers,

						Rolf Turner
						rolf at math.unb.ca



From kmote at hotmail.com  Sat Feb 14 16:33:02 2004
From: kmote at hotmail.com (Pramote Khuwijitjaru)
Date: Sat, 14 Feb 2004 15:33:02 +0000
Subject: [R] Beginner's question about t.test()
Message-ID: <BAY10-F118evGMVJ7An0004eb14@hotmail.com>

Dear All,
I am doing some exercise in statistics textbook on comparison of two 
experimental means. Is it possible to use t.test() do t-test when I have 
only two means, sample size, two standard deviations ? (no raw data).

Thanks.

Pramote



From andy_liaw at merck.com  Sat Feb 14 16:41:41 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 14 Feb 2004 10:41:41 -0500
Subject: [R] predict function
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77BA@usrymx25.merck.com>

If you know what you're looking for, you can always get to non-exported
function by using :::, e.g., modreg:::predict.loess will give you the
function.  

Andy

> From: Rolf Turner
> 
> Uwe Ligges wrote:
> 
> > Thomas Jagoe wrote:
> > 
> > > I am using R to do a loess normalisation procedure.
>     .
>     .
>     .
> > > However in 1.8.1 all goes well until the last step when I 
> get an error:
> > > 
> > > Error: couldn't find function "predict.loess"
> > > 
> > > Can anyone help ?
> > 
> > 
> > Use predict() instead of predict.loess() (the method is hidden in a 
> > namespace, you should use the generic function).
> > 
> > Uwe Ligges
> 
> Why are the developers ***DOING*** these things to us?
> 
> It used to be so simple and straightforward!  If I wanted to look
> at an object, including a function object, I typed its name.  Now
> I get hand-cuffed by this ``namespace'' business!  I will wager
> Euros to doughnuts that no-one apart from the developers has a clue
> what a ``namespace'' is, much less what it is good for.  Whatever
> problem ``namespaces'' were introduced to solve, it pales by
> comparison with the handicaps they introduce.
> 
> It's classic tail-wagging-the-dog syndrome.
> 
> When I get errors from R code, which come from within ``system''
> functions, it has been my practice to make a local copy (in the
> .Globalenv) of the function, stick in calls to browser(), and
> thereby track down what's going on/wrong.  This always worked like a
> charm. Now if the problem arises within, e.g. predict.loess, I'm
> stuffed.
> 
> 					cheers,
> 
> 						Rolf Turner
> 						rolf at math.unb.ca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From dmurdoch at pair.com  Sat Feb 14 17:10:31 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 14 Feb 2004 11:10:31 -0500
Subject: [R] How to plot a blank plot
In-Reply-To: <1076703086.3816.44.camel@tsetse.lab-net>
References: <1076703086.3816.44.camel@tsetse.lab-net>
Message-ID: <gshs201auqglou5h2srds3kc617bcfemqp@4ax.com>

On Fri, 13 Feb 2004 12:11:26 -0800, you wrote:

>Hello everyone,
>
>In plotting several graphics, I'd like to be able to plot a blank plot
>as in:
>
>par(mfrow=c(2,1))
>plot(BLANK)
>hist(rgamma(100000,6463.7,scale=0.015471),xlim=c(0,120),main="Emergence")
>
>I realize screen allows me to do this, but I figure the functionality
>must be there. Is there an equivalent to plot(BLANK)?

"frame()" is probably what you want.

You can also get a blank plot (but set up coordinates, etc.) with
something like

plot(1, type="n", axes=F, xlab="", ylab="")

This would allow you to plot points and lines and text in the empty
space; frame() would not.

Duncan Murdoch



From dmurdoch at pair.com  Sat Feb 14 17:27:11 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 14 Feb 2004 11:27:11 -0500
Subject: [R] predict function
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF77BA@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF77BA@usrymx25.merck.com>
Message-ID: <n9is201glqrlf0s7j0j6b2r4ova2j4fhu6@4ax.com>

On Sat, 14 Feb 2004 10:41:41 -0500, you wrote:

>If you know what you're looking for, you can always get to non-exported
>function by using :::, e.g., modreg:::predict.loess will give you the
>function.  

Or

 getAnywhere('predict.loess')

or

 getS3method('predict','loess')

(which are both good to know, because predict.loess won't be in modreg
in 1.9, it's in the new "stats" package).

Rolf said:
>Why are the developers ***DOING*** these things to us?
>
>It used to be so simple and straightforward!  If I wanted to look
>at an object, including a function object, I typed its name.  Now
>I get hand-cuffed by this ``namespace'' business!

Things weren't so simple in the old days in cases where two packages
both defined their own predict.loess functions, or when a user created
a function named "c" or "t", or in lots of other situations of name
collisions.  When two things had the same name, problems were really
likely to arise.

The point of namespaces is to protect the code in packages from
accidental name collisions.  Packages with namespaces can safely use
c() and t() and know what is going to happen.

The decision not to export the name "predict.loess" follows from the
general principle that you shouldn't export things unless you need to.
You should be calling "predict".  If you really need to call
"predict.loess" and "predict" won't get you there, you need to jump
through extra hoops to get it.

Duncan Murdoch



From jfox at mcmaster.ca  Sat Feb 14 17:30:32 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 14 Feb 2004 11:30:32 -0500
Subject: [R] predict function
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF77BA@usrymx25.merck.co
 m>
Message-ID: <5.1.0.14.2.20040214111105.0204cb20@127.0.0.1>

Dear Roft and Andy,

At 10:41 AM 2/14/2004 -0500, Liaw, Andy wrote:
>If you know what you're looking for, you can always get to non-exported
>function by using :::, e.g., modreg:::predict.loess will give you the
>function.

and getS3method("predict", "loess") or getAnywhere("predict.loess") will 
retrieve the function without specifying where it resides.

I'm sure that opinions are divided (and perhaps the current implementation 
could be improved), but I like the namespace mechanism: Namespaces give a 
package author the ability to create objects without (inadvertently) 
shadowing objects of the same names in other packages, and the ability to 
shadow objects intentionally that are (potentially) in locations higher on 
the search path. To my mind, the traditional flat namespace in R was a 
liability.

Regards,
  John

>Andy
>
> > From: Rolf Turner
> >
> > Uwe Ligges wrote:
> >
> > > Thomas Jagoe wrote:
> > >
> > > > I am using R to do a loess normalisation procedure.
> >     .
> >     .
> >     .
> > > > However in 1.8.1 all goes well until the last step when I
> > get an error:
> > > >
> > > > Error: couldn't find function "predict.loess"
> > > >
> > > > Can anyone help ?
> > >
> > >
> > > Use predict() instead of predict.loess() (the method is hidden in a
> > > namespace, you should use the generic function).
> > >
> > > Uwe Ligges
> >
> > Why are the developers ***DOING*** these things to us?
> >
> > It used to be so simple and straightforward!  If I wanted to look
> > at an object, including a function object, I typed its name.  Now
> > I get hand-cuffed by this ``namespace'' business!  I will wager
> > Euros to doughnuts that no-one apart from the developers has a clue
> > what a ``namespace'' is, much less what it is good for.  Whatever
> > problem ``namespaces'' were introduced to solve, it pales by
> > comparison with the handicaps they introduce.
> >
> > It's classic tail-wagging-the-dog syndrome.
> >
> > When I get errors from R code, which come from within ``system''
> > functions, it has been my practice to make a local copy (in the
> > .Globalenv) of the function, stick in calls to browser(), and
> > thereby track down what's going on/wrong.  This always worked like a
> > charm. Now if the problem arises within, e.g. predict.loess, I'm
> > stuffed.
> >
> >                                       cheers,
> >
> >                                               Rolf Turner
> >                                               rolf at math.unb.ca
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments,...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From MSchwartz at medanalytics.com  Sat Feb 14 17:51:22 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sat, 14 Feb 2004 10:51:22 -0600
Subject: [R] ftp.stat.math.ethz.ch not accessible?
Message-ID: <1076777481.7030.8.camel@localhost.localdomain>

Hi all,

I have been trying to get to the ftp site to download the R patched
tarball and cannot seem to get to it today.

I have tried via browser, gFTP and get without success. I can seem to do
an anonymous login, but that is as far as I can go.

Is there a known issue with the site today?

Thanks,

Marc



From MSchwartz at medanalytics.com  Sat Feb 14 18:10:16 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sat, 14 Feb 2004 11:10:16 -0600
Subject: [R] ftp.stat.math.ethz.ch not accessible?
In-Reply-To: <1076777481.7030.8.camel@localhost.localdomain>
References: <1076777481.7030.8.camel@localhost.localdomain>
Message-ID: <1076778615.7030.14.camel@localhost.localdomain>

On Sat, 2004-02-14 at 10:51, Marc Schwartz wrote:
> Hi all,
> 
> I have been trying to get to the ftp site to download the R patched
> tarball and cannot seem to get to it today.
> 
> I have tried via browser, gFTP and get without success. I can seem to do
> an anonymous login, but that is as far as I can go.
> 
> Is there a known issue with the site today?


A quick follow up. I was successful using rsync against CVS, so I found
a workaround.

FTP access however still seems to be problematic.

Thanks,

Marc



From jfox at mcmaster.ca  Sat Feb 14 18:17:09 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 14 Feb 2004 12:17:09 -0500
Subject: [R] parametric bootstrap and computing factor scores
In-Reply-To: <402D4CA5.7060707@vcu.edu>
Message-ID: <5.1.0.14.2.20040214121118.0200f1a8@127.0.0.1>

Dear Tom,

The factanal function will compute factor scores by two different methods 
-- see ?factanal. The boot package (pretty much the standard for 
boostrapping in R) will do parametric bootstrapping.

Note that the help.search() function would likely have led you to these.

I hope that this helps,
  John

At 05:16 PM 2/13/2004 -0500, Tom Kubarych wrote:
>We have a project on which we need to compare various methods for 
>computing factor scores.  Are there any R routines available that do 
>parametric bootstrap or compute factor scores?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From ligges at statistik.uni-dortmund.de  Sat Feb 14 18:28:08 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 14 Feb 2004 18:28:08 +0100
Subject: [R] ftp.stat.math.ethz.ch not accessible?
In-Reply-To: <1076777481.7030.8.camel@localhost.localdomain>
References: <1076777481.7030.8.camel@localhost.localdomain>
Message-ID: <402E5AA8.5070008@statistik.uni-dortmund.de>

Marc Schwartz wrote:

> Hi all,
> 
> I have been trying to get to the ftp site to download the R patched
> tarball and cannot seem to get to it today.
> 
> I have tried via browser, gFTP and get without success. I can seem to do
> an anonymous login, but that is as far as I can go.
> 
> Is there a known issue with the site today?
> 
> Thanks,

Marc,

let's wait until Monday.
Then it will be time to ask the tech staff at ETH Zurich for help, given 
they will not have found it out themselves and fixed the problem.

(Martin Maechler is on holidays, so we should not disturb him.
Hmm - last time Martin was on holidays the R-help list broke down....... 
;-) )

Uwe



From MSchwartz at medanalytics.com  Sat Feb 14 18:33:11 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sat, 14 Feb 2004 11:33:11 -0600
Subject: [R] ftp.stat.math.ethz.ch not accessible?
In-Reply-To: <402E5AA8.5070008@statistik.uni-dortmund.de>
References: <1076777481.7030.8.camel@localhost.localdomain>
	<402E5AA8.5070008@statistik.uni-dortmund.de>
Message-ID: <1076779991.7030.20.camel@localhost.localdomain>

On Sat, 2004-02-14 at 11:28, Uwe Ligges wrote:
> Marc Schwartz wrote:
> 
> > Hi all,
> > 
> > I have been trying to get to the ftp site to download the R patched
> > tarball and cannot seem to get to it today.
> > 
> > I have tried via browser, gFTP and get without success. I can seem to do
> > an anonymous login, but that is as far as I can go.
> > 
> > Is there a known issue with the site today?
> > 
> > Thanks,
> 
> Marc,
> 
> let's wait until Monday.
> Then it will be time to ask the tech staff at ETH Zurich for help, given 
> they will not have found it out themselves and fixed the problem.
> 
> (Martin Maechler is on holidays, so we should not disturb him.
> Hmm - last time Martin was on holidays the R-help list broke down....... 
> ;-) )
> 
> Uwe


Uwe,

Thanks for your follow up. I agree on all counts.

As I mentioned in my follow up, I was able to achieve success via rsync,
so there is a workaround available.

Perhaps we need to clone Martin?  ;-)

Best regards,

Marc



From sdhyok at email.unc.edu  Sat Feb 14 19:07:17 2004
From: sdhyok at email.unc.edu (Shin)
Date: Sat, 14 Feb 2004 13:07:17 -0500
Subject: [R] Time Series?
Message-ID: <200402141307.17460.sdhyok@email.unc.edu>

Hi, let me ask a basic question.
Is there any class like timeDate or timeSeries in S-PLUS?
I have a trouble in finding the classes in R manuals.
Thanks in advance.

Shin, Daehyok



From ggrothendieck at myway.com  Sat Feb 14 19:29:20 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 14 Feb 2004 13:29:20 -0500 (EST)
Subject: [R] predict function
Message-ID: <20040214182920.3B72C3949@mprdmxin.myway.com>



Other things one might want to ask:

- what is the S3 generic corresponding to predict.loess?

  answer: predict

- what are the other methods associated with that S3 generic?

  answer: methods(predict)

- what are all the methods for a given S3 class?

  answer: apropos("[.]loess$") may find some of them but its 
  not guaranteed to find all of them.  In fact, in this case it 
  does not find any.  

Date:   Sat, 14 Feb 2004 11:27:11 -0500 
From:   Duncan Murdoch <dmurdoch at pair.com>
To:   Liaw, Andy <andy_liaw at merck.com> 
Cc:   <r-help at stat.math.ethz.ch>, <ligges at statistik.uni-dortmund.de>,'Rolf Turner' <rolf at math.unb.ca> 
Subject:   Re: [R] predict function 

 
On Sat, 14 Feb 2004 10:41:41 -0500, you wrote:

>If you know what you're looking for, you can always get to non-exported
>function by using :::, e.g., modreg:::predict.loess will give you the
>function. 

Or

getAnywhere('predict.loess')

or

getS3method('predict','loess')

(which are both good to know, because predict.loess won't be in modreg
in 1.9, it's in the new "stats" package).

Rolf said:
>Why are the developers ***DOING*** these things to us?
>
>It used to be so simple and straightforward! If I wanted to look
>at an object, including a function object, I typed its name. Now
>I get hand-cuffed by this ``namespace'' business!

Things weren't so simple in the old days in cases where two packages
both defined their own predict.loess functions, or when a user created
a function named "c" or "t", or in lots of other situations of name
collisions. When two things had the same name, problems were really
likely to arise.

The point of namespaces is to protect the code in packages from
accidental name collisions. Packages with namespaces can safely use
c() and t() and know what is going to happen.

The decision not to export the name "predict.loess" follows from the
general principle that you shouldn't export things unless you need to.
You should be calling "predict". If you really need to call
"predict.loess" and "predict" won't get you there, you need to jump
through extra hoops to get it.

Duncan Murdoch

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Sat Feb 14 19:54:08 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Feb 2004 19:54:08 +0100
Subject: [R] Beginner's question about t.test()
In-Reply-To: <BAY10-F118evGMVJ7An0004eb14@hotmail.com>
References: <BAY10-F118evGMVJ7An0004eb14@hotmail.com>
Message-ID: <x27jyp1ohb.fsf@biostat.ku.dk>

"Pramote Khuwijitjaru" <kmote at hotmail.com> writes:

> Dear All,
> I am doing some exercise in statistics textbook on comparison of two
> experimental means. Is it possible to use t.test() do t-test when I
> have only two means, sample size, two standard deviations ? (no raw
> data).

Only if you "cheat".

fake.data <- function(n,mu,sigma) mu + sigma*scale(rnorm(n))
x1 <- fake.data(20, 12.345, .678)
x2 <- fake.data(20, 13.456, .789)
mean(x1)
sd(x1)
mean(x2)
sd(x2)

t.test(x1,x2)
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From cottenie at nceas.ucsb.edu  Sat Feb 14 23:23:52 2004
From: cottenie at nceas.ucsb.edu (karl cottenie)
Date: Sat, 14 Feb 2004 14:23:52 -0800
Subject: [R] speed in batch mode versus interactive mode
Message-ID: <1076797432.3459.35.camel@dhcp108.nceas.ucsb.edu>

Hello R-users,

is there a speed gain in submitting R code in batch mode as opposed to
the normal interactive. I searched the R website and the archives, and
only found a reference R-data.html that "to read in very large objects
it may be preferable to use the dumpfile as a batch script rather than
source". Is this true for any R code on both Windows and Linux systems,
and how much speed improvement can be gained (5 % or maybe 20 %)?

thanks,

Karl



From greenberg at ucdavis.edu  Sun Feb 15 00:10:08 2004
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Sat, 14 Feb 2004 15:10:08 -0800
Subject: [R] Converting a number column to a factor in a data frame?
Message-ID: <BC53EAD0.196D1%greenberg@ucdavis.edu>

Is there an easy way of taking a dataframe which is comprised of only
numbers, and converting one of the integer columns to a factor column?  How
do I go about this?

--j

-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From abunn at montana.edu  Sun Feb 15 00:19:36 2004
From: abunn at montana.edu (Andy Bunn)
Date: Sat, 14 Feb 2004 16:19:36 -0700
Subject: [R] Converting a number column to a factor in a data frame?
In-Reply-To: <BC53EAD0.196D1%greenberg@ucdavis.edu>
Message-ID: <000001c3f351$15298910$78f05a99@msu.montana.edu>

Look at ?as.factor

HTH, Andy

## Example
# Make some data
foo.df <- data.frame(X1 = rnorm(10), X2 = runif(10), Y = round(runif(10)
+ 1))

# Summarize it
summary(foo.df)

# Tak an extra close look at column Y
class(foo.df$Y)

# Change Y to a factor
foo.df$Y <- as.factor(foo.df$Y)

# Look at it again
summary(foo.df)
class(foo.df$Y)
levels(foo.df$Y)



From p.dalgaard at biostat.ku.dk  Sun Feb 15 01:45:03 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 15 Feb 2004 01:45:03 +0100
Subject: [R] speed in batch mode versus interactive mode
In-Reply-To: <1076797432.3459.35.camel@dhcp108.nceas.ucsb.edu>
References: <1076797432.3459.35.camel@dhcp108.nceas.ucsb.edu>
Message-ID: <x2u11tyxv4.fsf@biostat.ku.dk>

karl cottenie <cottenie at nceas.ucsb.edu> writes:

> Hello R-users,
> 
> is there a speed gain in submitting R code in batch mode as opposed to
> the normal interactive. I searched the R website and the archives, and
> only found a reference R-data.html that "to read in very large objects
> it may be preferable to use the dumpfile as a batch script rather than
> source". Is this true for any R code on both Windows and Linux systems,
> and how much speed improvement can be gained (5 % or maybe 20 %)?

Well, you could try it and see... The statement in R-data.html would
seem to only marginally related to your question since it is about
restoring objects created by dump() and I'm not even sure it is true
in that case. 

The source() command will parse the whole input before executing
anything, which may carry a space penalty on (very) long scripts. On
the other hand complicated expressions on standard input may get
reparsed from the start several times until R is satisfied that the
expression is complete.

Another issue is that interactive R (in the Windows GUI at least) may
have trouble getting rid of its output fast enough; this is why we
have the option of buffering the console output, but batch mode does
not have this problem.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From michael.scheidgen at uni-mainz.de  Sun Feb 15 02:16:12 2004
From: michael.scheidgen at uni-mainz.de (Michael Scheidgen)
Date: Sun, 15 Feb 2004 02:16:12 +0100
Subject: [R] Error Installing dse Package
Message-ID: <8B1596A7-5F54-11D8-8C62-0005029BFBBC@uni-mainz.de>

Hi there,

I ran into some trouble trying to install the dse library on os 10.3 
with RAqua as the installation of the dse1 package failed. On the R 
console I got the error message

Warning message:
Installation of package dse had non-zero exit status in: 
install.packages(ui.pkgs, CRAN = getOption(where), lib = 
.libPaths()[1])
 >

and the console of the os x said

gcc -bundle -flat_namespace -undefined suppress -L/usr/local/lib -o 
dse1.so dsefor.o  -L/usr/local/lib 
-L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4 
-L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/../../.. -lfrtbegin 
-lg2c -lSystem -lcc_dynamic
Looking for devices matching vendor ID=1193 and product ID=8718
Received 16 Bytes of Call Info Message, 1'st byte = 1
Looking for devices matching vendor ID=1193 and product ID=8717
Received 16 Bytes of Call Info Message, 1'st byte = 1
ld: dsefor.o has local relocation entries in non-writable section 
(__TEXT,__const)
make: *** [dse1.so] Error 1
ERROR: compilation failed for package 'dse1'

The two packages setNRG and tFrame seemed to install fine since they 
both show up as loadable packages in RAqua.

Any help definitely appreciated !!!

Tanks very much,
michael



From tlumley at u.washington.edu  Sun Feb 15 03:55:42 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 14 Feb 2004 18:55:42 -0800 (PST)
Subject: [R] Error Installing dse Package
In-Reply-To: <8B1596A7-5F54-11D8-8C62-0005029BFBBC@uni-mainz.de>
References: <8B1596A7-5F54-11D8-8C62-0005029BFBBC@uni-mainz.de>
Message-ID: <Pine.A41.4.58.0402141853170.110580@homer05.u.washington.edu>

On Sun, 15 Feb 2004, Michael Scheidgen wrote:

> Hi there,
>
> I ran into some trouble trying to install the dse library on os 10.3
> with RAqua as the installation of the dse1 package failed. On the R
> console I got the error message
>
<snip>
>
> and the console of the os x said
<snip>

> ld: dsefor.o has local relocation entries in non-writable section
> (__TEXT,__const)


This seems to be a common symptom when packages fail to build under RAqua,
but I don't know what causes it.

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From kmote at hotmail.com  Sun Feb 15 04:16:49 2004
From: kmote at hotmail.com (Pramote Khuwijitjaru)
Date: Sun, 15 Feb 2004 03:16:49 +0000
Subject: [R] Beginner's question about t.test()
Message-ID: <BAY10-F686j6JIoEyTa0005f7fe@hotmail.com>

Dear Peter Dalgaard

Thank you very much.



>From: <p.dalgaard at biostat.ku.dk>

>
>"Pramote Khuwijitjaru" <kmote at hotmail.com> writes:
>
> > Dear All,
> > I am doing some exercise in statistics textbook on comparison of two
> > experimental means. Is it possible to use t.test() do t-test when I
> > have only two means, sample size, two standard deviations ? (no raw
> > data).
>
>Only if you "cheat".
>
>fake.data <- function(n,mu,sigma) mu + sigma*scale(rnorm(n))
>x1 <- fake.data(20, 12.345, .678)
>x2 <- fake.data(20, 13.456, .789)
>mean(x1)
>sd(x1)
>mean(x2)
>sd(x2)
>
>t.test(x1,x2)
>--
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From gmpowers at terra.com.br  Sun Feb 15 05:49:50 2004
From: gmpowers at terra.com.br (Graciliano M. P.)
Date: Sun, 15 Feb 2004 01:49:50 -0300
Subject: [R] source() function and crash of R!
Message-ID: <004201c3f37f$254daeb0$098cb0c8@main>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040215/b5979c03/attachment.pl

From zh_jinsong at yahoo.com.cn  Sun Feb 15 06:18:19 2004
From: zh_jinsong at yahoo.com.cn (=?gb2312?q?Jinsong=20Zhao?=)
Date: Sun, 15 Feb 2004 13:18:19 +0800 (CST)
Subject: [R] help on compilation of R help file in LaTeX format.
Message-ID: <20040215051819.36238.qmail@web15404.mail.cnb.yahoo.com>

Dear all,

I hope to know how to compile the R help file in LaTeX format under
Windows 2000. The TeX/LaTeX system is TeXLive 2002, and the version of
R is 1.8.x.

Another question, I hope to get the upright Greek letters, just as
these in Prof. Faraway's book "Practical Regression and Anova in R",
but I don't know which package(s) and/or font(s) should be used in
LaTeX. 

Any reply and suggestion will be appreciated. TIA.

Regards,

Jinsong

_________________________________________________________




From itayf at fhcrc.org  Sun Feb 15 07:48:27 2004
From: itayf at fhcrc.org (Itay Furman)
Date: Sat, 14 Feb 2004 22:48:27 -0800 (PST)
Subject: [R] help on compilation of R help file in LaTeX format.
In-Reply-To: <20040215051819.36238.qmail@web15404.mail.cnb.yahoo.com>
Message-ID: <Pine.LNX.4.44.0402142245570.12309-100000@cezanne.fhcrc.org>


On Sun, 15 Feb 2004, [gb2312] Jinsong Zhao wrote:

> Another question, I hope to get the upright Greek letters, just as
> these in Prof. Faraway's book "Practical Regression and Anova in R",
> but I don't know which package(s) and/or font(s) should be used in
> LaTeX. 
> 

Maybe search for 'greek upright' in CTAN:
	http://www.ctan.org/search/?action=/index.html

	Itay



From loraine at loraine.net  Sun Feb 15 08:52:29 2004
From: loraine at loraine.net (Ann Loraine)
Date: Sat, 14 Feb 2004 23:52:29 -0800
Subject: [R] father and son heights
In-Reply-To: <Pine.LNX.4.44.0402142245570.12309-100000@cezanne.fhcrc.org>
References: <Pine.LNX.4.44.0402142245570.12309-100000@cezanne.fhcrc.org>
Message-ID: <E770C25E-5F8B-11D8-B356-000A959EED5E@loraine.net>


Hello,

I'm looking for Pearson's father and son height data.

Is this data set available in R?

Thanks!

Ann Loraine



From gmpowers at terra.com.br  Sun Feb 15 10:22:17 2004
From: gmpowers at terra.com.br (Graciliano M. P.)
Date: Sun, 15 Feb 2004 06:22:17 -0300
Subject: [R] source() function and crash of R!
References: <Pine.GSO.4.31.0402150806040.7640-100000@toucan.stats>
Message-ID: <004001c3f3a5$34f30100$098cb0c8@main>


> Do read the posting guide.
>
> I bet you get an error message, not a crash, and that you are running R in
> non-interactive mode: not that you have told us what you are doing in any
> detail.
>

No, actually the R interpreter goes out, like if the process was killed!

Note that if we open R and type a code with an invalid syntax, R will just
alert with some error msg. But when loaded with source(), this code makes
the interpreter quit.

> ...you are running R in non-interactive mode...

What you mean with "non-interactive mode"?

I'm running it from console. On Win32 Rterm, and linux just R. Here's the
command to start it on Linux:

  $> R --slave --vanilla --gui=none <bridge.r >output.log

Regards,
Graciliano M. P.



From ripley at stats.ox.ac.uk  Sun Feb 15 10:30:02 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 15 Feb 2004 09:30:02 +0000 (GMT)
Subject: [R] source() function and crash of R!
In-Reply-To: <004001c3f3a5$34f30100$098cb0c8@main>
Message-ID: <Pine.GSO.4.31.0402150925040.7715-100000@toucan.stats>

On Sun, 15 Feb 2004, Graciliano M. P. wrote:

> > Do read the posting guide.

Don't post private messages to the list without permission.

> > I bet you get an error message, not a crash, and that you are running R in
> > non-interactive mode: not that you have told us what you are doing in any
> > detail.
> >
>
> No, actually the R interpreter goes out, like if the process was killed!

You should get an error message followed by normal termination: do please
read the posting guide and follow what it requests.  Killing a process is
not a `crash' ....

> Note that if we open R and type a code with an invalid syntax, R will just
> alert with some error msg. But when loaded with source(), this code makes
> the interpreter quit.
>
> > ...you are running R in non-interactive mode...
>
> What you mean with "non-interactive mode"?

Exactly what I say.  See ?interactive.

> I'm running it from console. On Win32 Rterm, and linux just R. Here's the
> command to start it on Linux:
>
>   $> R --slave --vanilla --gui=none <bridge.r >output.log

That *is* non-interactive mode, when by default errors are fatal.

See ?options, under `error', which refers you to ?stop.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pallier at lscp.ehess.fr  Sun Feb 15 10:51:39 2004
From: pallier at lscp.ehess.fr (pallier)
Date: Sun, 15 Feb 2004 10:51:39 +0100
Subject: [R] Beginner's question about t.test()
In-Reply-To: <BAY10-F118evGMVJ7An0004eb14@hotmail.com>
References: <BAY10-F118evGMVJ7An0004eb14@hotmail.com>
Message-ID: <402F412B.7010307@lscp.ehess.fr>

Pramote Khuwijitjaru wrote:

> Is it possible to use t.test() do t-test when I have only two means, 
> sample size, two standard deviations ? (no raw data).


When you type 't.test.default', you get the source code of the t.test 
function.

If you are conducting a t.test with var.equal=T, paired=F, 
alternative=two.sided,
the following commands are executed:

       df <- nx + ny - 2
       v <- ((nx - 1) * vx + (ny - 1) * vy)/df
       stderr <- sqrt(v * (1/nx + 1/ny))
       tstat <- (mx - my - mu)/stderr
       pval <- 2 * pt(-abs(tstat), df)


You could write your own function taking nx, mx, vx and ny, my and vy as 
args.
(vx=var(x))

my.t.test <- function (nx,mx,vx,ny,my,vy) {
       df <- nx + ny - 2
       v <- ((nx - 1) * vx + (ny - 1) * vy)/df
       stderr <- sqrt(v * (1/nx + 1/ny))
       tstat <- (mx - my)/stderr
       pval <- 2 * pt(-abs(tstat), df)

       cat("df=",df)
       cat("\nT=",tstat)
       cat("\np=",pval)
}

Christophe Pallier
www.pallier.org



From ligges at statistik.uni-dortmund.de  Sun Feb 15 11:44:28 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 15 Feb 2004 11:44:28 +0100
Subject: [R] source() function and crash of R!
References: <Pine.GSO.4.31.0402150806040.7640-100000@toucan.stats>
	<004001c3f3a5$34f30100$098cb0c8@main>
Message-ID: <402F4D8C.7C441F62@statistik.uni-dortmund.de>



"Graciliano M. P." wrote:
> 
> > Do read the posting guide.
> >
> > I bet you get an error message, not a crash, and that you are running R in
> > non-interactive mode: not that you have told us what you are doing in any
> > detail.
> >
> 
> No, actually the R interpreter goes out, like if the process was killed!
> 
> Note that if we open R and type a code with an invalid syntax, R will just
> alert with some error msg. But when loaded with source(), this code makes
> the interpreter quit.
> 
> > ...you are running R in non-interactive mode...
> 
> What you mean with "non-interactive mode"?
>
> I'm running it from console. On Win32 Rterm, and linux just R. Here's the
> command to start it on Linux:
> 
>   $> R --slave --vanilla --gui=none <bridge.r >output.log


This is what Prof. Ripley (why do you reply in public to his private
message?) meant with "non-interactive", you do not interactively
communicate with R.

I also guess that R does NOT crash in your case:
If you use source(), this is a complete statement in R. If anything
sourced() produces an error (e.g. syntax error), the source() call exits
with this error. 
That is an expected behaviour. Functions are exiting if anything called
within that function got an error...
You should have seen the error message in output.log, but neither a
segmentation fault nor any other kind of a crash.

You can catch an error by using try(). See ?try.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Sun Feb 15 11:52:16 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 15 Feb 2004 11:52:16 +0100
Subject: [R] help on compilation of R help file in LaTeX format.
References: <20040215051819.36238.qmail@web15404.mail.cnb.yahoo.com>
Message-ID: <402F4F60.23661F9D@statistik.uni-dortmund.de>

Jinsong Zhao wrote:
> 
> Dear all,
> 
> I hope to know how to compile the R help file in LaTeX format under
> Windows 2000. The TeX/LaTeX system is TeXLive 2002, and the version of
> R is 1.8.x.


See ?help, in particular look for its argument "offline" and the section
"Details":

     If 'offline' is 'TRUE', hardcopy of the documentation is produced
     by running the LaTeX version of the help page through 'latex'
     (note that LaTeX 2e is needed).  You need to customize the file
     'R_HOME/bin/helpPRINT.bat' which contains an example. The
     appearance of the output can be customized through a file
     'Rhelp.cfg' somewhere in your LaTeX search path.

See also ?Rdconv for converting Rd files to several formats. 

If you still need more information, please read the "Writing R
Extensions" manual.

Uwe Ligges
 
> Another question, I hope to get the upright Greek letters, just as
> these in Prof. Faraway's book "Practical Regression and Anova in R",
> but I don't know which package(s) and/or font(s) should be used in
> LaTeX.
>
> Any reply and suggestion will be appreciated. TIA.
> 
> Regards,
> 
> Jinsong



From Detlef.Steuer at unibw-hamburg.de  Sun Feb 15 12:11:23 2004
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Sun, 15 Feb 2004 12:11:23 +0100
Subject: [R] 	How to configure ess-5.2.0beta3-1.i586.rpm, Xemacs and
	SuSE 9.0?
In-Reply-To: <402D7A8B.6010006@northbranchlogic.com>
References: <402D7A8B.6010006@northbranchlogic.com>
Message-ID: <20040215121123.446e09b7@gaia.unibw-hamburg.de>

Hi!

The rpm is for emacs, not Xemacs.
ess is, as far as I know, contained in the "sumo" package
for Xemacs. 
(I'm no user of Xemacs, so no guarantee)

Hth

detlef

On Fri, 13 Feb 2004 19:31:55 -0600
Barnet Wagman <bw at northbranchlogic.com> wrote:

> I'm trying to get R and ESS to work with Xemacs on a newly installed 
> SuSE 9.0 system. Is some setup required beyond installing the rpms?  
> I've installed the Xemacs packages from SuSE
> 
> xemacs-info-21.4.13-35
> xemacs-packages-el-20030629-37
> xemacs-21.4.13-35
> xemacs-el-21.4.13-35
> xemacs-packages-info-20030629-37
> xemacs-packages-20030629-37
> 
> 
> ess-5.2.0beta3-1.i586.rpm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****

"Die herrschenden Ideen sind die Ideen der Herrschenden."
--- K. Marx



From spencer.graves at pdf.com  Sun Feb 15 14:46:37 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 15 Feb 2004 05:46:37 -0800
Subject: [R] father and son heights
In-Reply-To: <E770C25E-5F8B-11D8-B356-000A959EED5E@loraine.net>
References: <Pine.LNX.4.44.0402142245570.12309-100000@cezanne.fhcrc.org>
	<E770C25E-5F8B-11D8-B356-000A959EED5E@loraine.net>
Message-ID: <402F783D.1080000@pdf.com>

      Do you have this data set in any form?  If yes, do you have it in 
any electronic form?  If yes, have you tried following relevant 
suggestions in the manual on "R Data Import/Export"?  [I got this as a 
hot link from within R 1.8.1 "help.start()".]

      hope this helps.
      spencer graves

Ann Loraine wrote:

>
> Hello,
>
> I'm looking for Pearson's father and son height data.
>
> Is this data set available in R?
>
> Thanks!
>
> Ann Loraine
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From kmote at hotmail.com  Sun Feb 15 15:51:47 2004
From: kmote at hotmail.com (Pramote Khuwijitjaru)
Date: Sun, 15 Feb 2004 14:51:47 +0000
Subject: [R] Beginner's question about t.test()
Message-ID: <BAY10-F10cf3ednHM3S000125ce@hotmail.com>

>From: pallier <pallier at lscp.ehess.fr>
>To: Pramote Khuwijitjaru <kmote at hotmail.com>
>Subject: Re: [R] Beginner's question about t.test()
>Date: Sun, 15 Feb 2004 10:48:05 +0100
>
>Pramote Khuwijitjaru wrote:
>
>>Dear All,
>>I am doing some exercise in statistics textbook on comparison of two 
>>experimental means. Is it possible to use t.test() do t-test when I have 
>>only two means, sample size, two standard deviations ? (no raw data).
>
>
>When you type 't.test.default', you get the source code of the t.test 
>function.
>
>If you are conducting a t.test with var.equal=T, paired=F, 
>alternative=two.sided,
>the following commands are executed:
>
>        df <- nx + ny - 2
>        v <- ((nx - 1) * vx + (ny - 1) * vy)/df
>        stderr <- sqrt(v * (1/nx + 1/ny))
>        tstat <- (mx - my - mu)/stderr
>        pval <- 2 * pt(-abs(tstat), df)
>
>
>You could write your own function taking nx, mx, vx and ny, my and vy as 
>args.
>
>my.t.test <- function (nx,mx,vx,ny,my,vy) {
>        df <- nx + ny - 2
>        v <- ((nx - 1) * vx + (ny - 1) * vy)/df
>        stderr <- sqrt(v * (1/nx + 1/ny))
>        tstat <- (mx - my)/stderr
>        pval <- 2 * pt(-abs(tstat), df)
>
>        cat("df=",df)
>        cat("\nT=",tstat)
>        cat("\np=",pval)
>}
>
>Christophe Pallier
>www.pallier.org
>
>
Thanks for your advice. Writing my own function should be the best way.

But  when I type t.test, I got
>t.test
function (x, ...)
UseMethod("t.test")
<environment: namespace:ctest>

and

>t.test.default
Error: Object "t.test.default" not found

I tried other couple of functions and found that only some functions (sd, 
var) will show their source when  type the name.

Could you point out the way to see function's source again ?

                                                                             
                 Pramote



From rolf at math.unb.ca  Sun Feb 15 16:23:26 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Sun, 15 Feb 2004 11:23:26 -0400 (AST)
Subject: [R] Beginner's question about t.test()
Message-ID: <200402151523.i1FFNQoT016071@erdos.math.unb.ca>


(a) You don't really need/want to look at t.test.default; your own
code --- to do t tests based on summary statistics rather than data
--- will have little or nothing to do with the code in
t.test.default.  Just write code to do the t test ``as if you were
doing it by hand'' which is very simple and straightforward.

(b) The reason that you can't ``see'' the t.test.default code is the
namespace business on which I recently wrote a perhaps ill-advised
rant to this list.

It was gently pointed out to me that the namespace idea certainly
does have its uses and advantages.  It was also pointed out that you
CAN get at functions which are ``hidden away'' by the namespace
mechanism.  Three ways (of which I was kindly informed by Andy Liaw
and Duncan Murdoch) are:

	> ctest:::t.test.default
	> getAnywhere("t.test.default")
	> getS3method("t.test","default")

Hope this helps.

					cheers,

						Rolf Turner
						rolf at math.unb.ca



From copellifulvio at yahoo.it  Sun Feb 15 17:22:38 2004
From: copellifulvio at yahoo.it (=?iso-8859-1?q?Fulvio=20Copex?=)
Date: Sun, 15 Feb 2004 17:22:38 +0100 (CET)
Subject: [R] linear regression and chi square test of data with standard
	deviation
Message-ID: <20040215162238.30375.qmail@web25207.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040215/c34c48ae/attachment.pl

From copellifulvio at yahoo.it  Sun Feb 15 17:42:00 2004
From: copellifulvio at yahoo.it (=?iso-8859-1?q?Fulvio=20Copex?=)
Date: Sun, 15 Feb 2004 17:42:00 +0100 (CET)
Subject: [R] linear regression of data with standard deviation
Message-ID: <20040215164200.93224.qmail@web25210.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040215/ad3fd374/attachment.pl

From spencer.graves at pdf.com  Sun Feb 15 18:43:52 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 15 Feb 2004 09:43:52 -0800
Subject: [R] linear regression of data with standard deviation
In-Reply-To: <20040215164200.93224.qmail@web25210.mail.ukl.yahoo.com>
References: <20040215164200.93224.qmail@web25210.mail.ukl.yahoo.com>
Message-ID: <402FAFD8.1010307@pdf.com>

      I'm not certain what you are asking, but I wonder if you want 
"errors in X regression".  If yes, have you considered the "sem" package 
("structural equations modeling")? 

      If you don't already have this package, you can get it using the 
"download.packages" under Windows or by following the instructions in 
the FAQs. 

      hope this helps. 
      spencer graves

Fulvio Copex wrote:

>Hello everyone,
>I know that to calculate the linear regression between x and y I
>have to use the function "lm".
>But how to do if x and y have a standard deviation like in the
>following example?
>How to compute the chi square test in this case?
>Thank you,
>Fulvio.
> 
>example:
>x  +-  dx
>5       2
>13     4
>17     4
>23     6
>y  +- dy
>6.3   0.6
>9.2   0.9
>14    1
>21    4
>
>
>
>
>
>---------------------------------
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From loraine at loraine.net  Sun Feb 15 19:37:08 2004
From: loraine at loraine.net (Ann Loraine)
Date: Sun, 15 Feb 2004 10:37:08 -0800
Subject: [R] father and son heights
In-Reply-To: <402F783D.1080000@pdf.com>
References: <Pine.LNX.4.44.0402142245570.12309-100000@cezanne.fhcrc.org>
	<E770C25E-5F8B-11D8-B356-000A959EED5E@loraine.net>
	<402F783D.1080000@pdf.com>
Message-ID: <F59A80A2-5FE5-11D8-B356-000A959EED5E@loraine.net>

Actually, no.  It's a data set that is used to teach Pearson's 
correlation coefficient in a popular statistics textbook - "Statistics" 
by Freedman, Pisani, et al.

It contains over a thousand measurements of son's and their father's 
heights.

I would like to find it in electronic form so that I can use it to 
prepare figures and examples for a lecture.

If anyone knows where I could find it, please let me know.  I've done a 
few Google searches but haven't had any luck so far.  I also used the 
data() command to look through R's built-in data sets and couldn't find 
it.  Any suggestions would be most welcome!

Yours,

Ann Loraine


On Feb 15, 2004, at 5:46 AM, Spencer Graves wrote:

>      Do you have this data set in any form?  If yes, do you have it in 
> any electronic form?  If yes, have you tried following relevant 
> suggestions in the manual on "R Data Import/Export"?  [I got this as a 
> hot link from within R 1.8.1 "help.start()".]
>
>      hope this helps.
>      spencer graves
>
> Ann Loraine wrote:
>
>>
>> Hello,
>>
>> I'm looking for Pearson's father and son height data.
>>
>> Is this data set available in R?
>>
>> Thanks!
>>
>> Ann Loraine
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
>



From friendly at yorku.ca  Sun Feb 15 19:56:34 2004
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 15 Feb 2004 13:56:34 -0500
Subject: [R] manova() with a data frame
Message-ID: <402FC0E2.80503@yorku.ca>

I'm trying to learn to use manova(), and don't understand why none of 
the following work:

 > data(iris)
 > fit <- manova(~ Species, data=iris)
Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
        incompatible dimensions
 > fit <- manova(iris[,1:4] ~ Species, data=iris)
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        invalid variable type
 >
 > YY <- iris[,1:4]
 > species <- iris[,5]
 > fit <- manova(YY ~ species)
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        invalid variable type

It does work if I coerce YY to a matrix:

 > fit <- manova(as.matrix(YY) ~ species)

But, ?manova gives no details, and just points to ?aov which says

     aov(formula, data = NULL, projections = FALSE, qr = TRUE,
         contrasts = NULL, ...)
 
Arguments:
 
 formula: A formula specifying the model.
 
    data: A data frame in which the variables specified in the formula
          will be found. If missing, the variables are searched for in
          the standard way.
   ...

If this is not a bug, perhaps the documentation needs to be  clearer.  
The only example for
manova() is found in  ?summary.manova.  (It would also help if 
model.frame returned
something to indicate which variable had an invalid type.)
 
-Michael

-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From MSchwartz at medanalytics.com  Sun Feb 15 20:21:19 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 15 Feb 2004 13:21:19 -0600
Subject: [R] father and son heights
In-Reply-To: <F59A80A2-5FE5-11D8-B356-000A959EED5E@loraine.net>
References: <Pine.LNX.4.44.0402142245570.12309-100000@cezanne.fhcrc.org>
	<E770C25E-5F8B-11D8-B356-000A959EED5E@loraine.net>
	<402F783D.1080000@pdf.com>
	<F59A80A2-5FE5-11D8-B356-000A959EED5E@loraine.net>
Message-ID: <1076872879.7030.45.camel@localhost.localdomain>

On Sun, 2004-02-15 at 12:37, Ann Loraine wrote:
> Actually, no.  It's a data set that is used to teach Pearson's 
> correlation coefficient in a popular statistics textbook - "Statistics" 
> by Freedman, Pisani, et al.
> 
> It contains over a thousand measurements of son's and their father's 
> heights.
> 
> I would like to find it in electronic form so that I can use it to 
> prepare figures and examples for a lecture.
> 
> If anyone knows where I could find it, please let me know.  I've done a 
> few Google searches but haven't had any luck so far.  I also used the 
> data() command to look through R's built-in data sets and couldn't find 
> it.  Any suggestions would be most welcome!
> 
> Yours,
> 
> Ann Loraine
> 
> 
> On Feb 15, 2004, at 5:46 AM, Spencer Graves wrote:
> 
> >      Do you have this data set in any form?  If yes, do you have it in 
> > any electronic form?  If yes, have you tried following relevant 
> > suggestions in the manual on "R Data Import/Export"?  [I got this as a 
> > hot link from within R 1.8.1 "help.start()".]
> >
> >      hope this helps.
> >      spencer graves
> >
> > Ann Loraine wrote:
> >
> >>
> >> Hello,
> >>
> >> I'm looking for Pearson's father and son height data.
> >>
> >> Is this data set available in R?
> >>
> >> Thanks!
> >>
> >> Ann Loraine


Found it here:

http://stat-www.berkeley.edu/users/juliab/141C/pearson.dat

It consists of 1,078 pairs of father (col 1) and son (col 2) paired
data.  Used to not only show Pearson correlation, but also used to
demonstrate Regression to the Mean, or as Galton called it, Regression
Towards Mediocrity.

You can save the page as a text file, then read it into R via
read.table().

HTH,

Marc Schwartz



From ggrothendieck at myway.com  Sun Feb 15 20:27:52 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 15 Feb 2004 14:27:52 -0500 (EST)
Subject: [R] father and son heights
Message-ID: <20040215192752.1088F3980@mprdmxin.myway.com>



Faraway's book titled "Practical Regression and Anova using R", 
with full text available online at:

   http://cran.r-project.org/doc/contrib/Faraway-PRA.pdf

refers to a data set, stat500, which compares midterm and final
grades.  It can be used to illustrate similar concepts.

A google search for faraway.zip will locate the actual data.

---
Date:   Sun, 15 Feb 2004 10:37:08 -0800 
From:   Ann Loraine <loraine at loraine.net>
[ Add to Address Book | Block Address | Report as Spam ] 
To:   rhelp <r-help at stat.math.ethz.ch> 
Subject:   Re: [R] father and son heights 

 
Actually, no. It's a data set that is used to teach Pearson's 
correlation coefficient in a popular statistics textbook - "Statistics" 
by Freedman, Pisani, et al.

It contains over a thousand measurements of son's and their father's 
heights.

I would like to find it in electronic form so that I can use it to 
prepare figures and examples for a lecture.

If anyone knows where I could find it, please let me know. I've done a 
few Google searches but haven't had any luck so far. I also used the 
data() command to look through R's built-in data sets and couldn't find 
it. Any suggestions would be most welcome!

Yours,

Ann Loraine


On Feb 15, 2004, at 5:46 AM, Spencer Graves wrote:

> Do you have this data set in any form? If yes, do you have it in 
> any electronic form? If yes, have you tried following relevant 
> suggestions in the manual on "R Data Import/Export"? [I got this as a 
> hot link from within R 1.8.1 "help.start()".]
>
> hope this helps.
> spencer graves
>
> Ann Loraine wrote:
>
>>
>> Hello,
>>
>> I'm looking for Pearson's father and son height data.
>>
>> Is this data set available in R?
>>
>> Thanks!
>>
>> Ann Loraine
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
>



From rolf at math.unb.ca  Sun Feb 15 20:30:43 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Sun, 15 Feb 2004 15:30:43 -0400 (AST)
Subject: [R] father and son heights
Message-ID: <200402151930.i1FJUhul019638@erdos.math.unb.ca>

Ann Loraine wrote:

> I'm looking for Pearson's father and son height data.
> ...........  It's a data set that is used to teach Pearson's 
> correlation coefficient in a popular statistics textbook - "Statistics" 
> by Freedman, Pisani, et al.
> 
> It contains over a thousand measurements of son's and their father's 
> heights.
> 
> I would like to find it in electronic form so that I can use it to 
> prepare figures and examples for a lecture.
> 
> If anyone knows where I could find it, please let me know.  I've done a 
> few Google searches but haven't had any luck so far.  I also used the 
> data() command to look through R's built-in data sets and couldn't find 
> it.  Any suggestions would be most welcome!

I believe that you have been searching under the wrong name.  The
data are most closely associated with Galton (the bloke to whom the
word ``regression'' is due) rather than with Pearson.

A search on

	Galton height

led me immediately to

	http://wiener.math.csi.cuny.edu/UsingR/Data/galton.html	

where the data appear to be readily available.

I ***presume*** that these are the data you seek, although there are
only 930 observations, not ``over a thousand''.  (Close, but!)

The data are given to a limited accurracy, which induces a strangely
grid-like appearance when they are plotted, but that is presumably
the nature of this data set.  They were apparently taken from a table
prepared by Galton.  Values which were originally given in Galton's
table as ``>= 73.7'' or ``<= 61.7'' are truncated to their respective
bounds.

One thing that puzzles me:  The documentation says that the data
pertain to 928 children, yet there are 930 data points. (????)
I can't find an explanation in the documentation.  Maybe I'm just
blind.  Or thick.


				cheers,

					Rolf Turner
					rolf at math.unb.ca



From ccleland at optonline.net  Sun Feb 15 20:34:23 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Sun, 15 Feb 2004 14:34:23 -0500
Subject: [R] father and son heights
In-Reply-To: <1076872879.7030.45.camel@localhost.localdomain>
References: <Pine.LNX.4.44.0402142245570.12309-100000@cezanne.fhcrc.org>
	<E770C25E-5F8B-11D8-B356-000A959EED5E@loraine.net>
	<402F783D.1080000@pdf.com>
	<F59A80A2-5FE5-11D8-B356-000A959EED5E@loraine.net>
	<1076872879.7030.45.camel@localhost.localdomain>
Message-ID: <402FC9BF.8040303@optonline.net>

Marc Schwartz wrote:
> ...
> Found it here:
> 
> http://stat-www.berkeley.edu/users/juliab/141C/pearson.dat
> 
> It consists of 1,078 pairs of father (col 1) and son (col 2) paired
> data.  Used to not only show Pearson correlation, but also used to
> demonstrate Regression to the Mean, or as Galton called it, Regression
> Towards Mediocrity.
> 
> You can save the page as a text file, then read it into R via
> read.table().

Or read it directly from that location with

galton <- 
read.table("http://stat-www.berkeley.edu/users/juliab/141C/pearson.dat", 
sep=" ")[,-1]

names(galton) <- c("fheight", "sheight")

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From rolf at math.unb.ca  Sun Feb 15 20:43:12 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Sun, 15 Feb 2004 15:43:12 -0400 (AST)
Subject: [R] father and son heights
Message-ID: <200402151943.i1FJhCqq019814@erdos.math.unb.ca>


Marc Schwartz wrote:

> Found it here:
> 
> http://stat-www.berkeley.edu/users/juliab/141C/pearson.dat
> 
> It consists of 1,078 pairs of father (col 1) and son (col 2) paired
> data.  Used to not only show Pearson correlation, but also used to
> demonstrate Regression to the Mean, or as Galton called it, Regression
> Towards Mediocrity.

Whoops.  I guess I jumped to an unwarrented conclusion when I
found the Galton data set.

Sorry 'bout that folks!

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From ccleland at optonline.net  Sun Feb 15 20:55:19 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Sun, 15 Feb 2004 14:55:19 -0500
Subject: [R] manova() with a data frame
In-Reply-To: <402FC0E2.80503@yorku.ca>
References: <402FC0E2.80503@yorku.ca>
Message-ID: <402FCEA7.1030908@optonline.net>

   The details section of the help for lm() suggests the response 
should either be a numeric vector or a matrix.  And the help for 
aov() says:

"Fit an analysis of variance model by a call to 'lm' for each 
stratum."

hope this helps,

Chuck Cleland

Michael Friendly wrote:
> I'm trying to learn to use manova(), and don't understand why none of 
> the following work:
> 
>  > data(iris)
>  > fit <- manova(~ Species, data=iris)
> Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>        incompatible dimensions
>  > fit <- manova(iris[,1:4] ~ Species, data=iris)
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>        invalid variable type
>  >
>  > YY <- iris[,1:4]
>  > species <- iris[,5]
>  > fit <- manova(YY ~ species)
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>        invalid variable type
> 
> It does work if I coerce YY to a matrix:
> 
>  > fit <- manova(as.matrix(YY) ~ species)
> 
> But, ?manova gives no details, and just points to ?aov which says
> 
>     aov(formula, data = NULL, projections = FALSE, qr = TRUE,
>         contrasts = NULL, ...)
> 
> Arguments:
> 
> formula: A formula specifying the model.
> 
>    data: A data frame in which the variables specified in the formula
>          will be found. If missing, the variables are searched for in
>          the standard way.
>   ...
> 
> If this is not a bug, perhaps the documentation needs to be  clearer.  
> The only example for
> manova() is found in  ?summary.manova.  (It would also help if 
> model.frame returned
> something to indicate which variable had an invalid type.)

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ggrothendieck at myway.com  Sun Feb 15 20:57:10 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 15 Feb 2004 14:57:10 -0500 (EST)
Subject: [R] father and son heights
Message-ID: <20040215195710.4A3B3397F@mprdmxin.myway.com>



According to:

http://www.spss.com/research/wilkinson/Publications/galton.pdf

there are actually two father/son height datasets.  One was
collected by Galton.  Apparently Pearson used that data but 
also collected and used a second dataset together with Alice Lee 
in roughly the same time frame.

---
Date:   Sun, 15 Feb 2004 15:30:43 -0400 (AST) 
From:   Rolf Turner <rolf at math.unb.ca>
To:   <loraine at loraine.net> 
Cc:   <r-help at stat.math.ethz.ch> 
Subject:   Re: [R] father and son heights 

 
Ann Loraine wrote:

> I'm looking for Pearson's father and son height data.
> ........... It's a data set that is used to teach Pearson's 
> correlation coefficient in a popular statistics textbook - "Statistics" 
> by Freedman, Pisani, et al.
> 
> It contains over a thousand measurements of son's and their father's 
> heights.
> 
> I would like to find it in electronic form so that I can use it to 
> prepare figures and examples for a lecture.
> 
> If anyone knows where I could find it, please let me know. I've done a 
> few Google searches but haven't had any luck so far. I also used the 
> data() command to look through R's built-in data sets and couldn't find 
> it. Any suggestions would be most welcome!

I believe that you have been searching under the wrong name. The
data are most closely associated with Galton (the bloke to whom the
word ``regression'' is due) rather than with Pearson.

A search on

     Galton height

led me immediately to

     http://wiener.math.csi.cuny.edu/UsingR/Data/galton.html     

where the data appear to be readily available.

I ***presume*** that these are the data you seek, although there are
only 930 observations, not ``over a thousand''. (Close, but!)

The data are given to a limited accurracy, which induces a strangely
grid-like appearance when they are plotted, but that is presumably
the nature of this data set. They were apparently taken from a table
prepared by Galton. Values which were originally given in Galton's
table as ``>= 73.7'' or ``<= 61.7'' are truncated to their respective
bounds.

One thing that puzzles me: The documentation says that the data
pertain to 928 children, yet there are 930 data points. (????)
I can't find an explanation in the documentation. Maybe I'm just
blind. Or thick.


                    cheers,

                         Rolf Turner
                         rolf at math.unb.ca



From debene at unimc.it  Sun Feb 15 21:40:48 2004
From: debene at unimc.it (Luca De Benedictis)
Date: Sun, 15 Feb 2004 21:40:48 +0100
Subject: [R] panel data
Message-ID: <402FD950.4080401@unimc.it>

Dear R-friends,
has anyone developed a package for panel data or even dynamic panel data?
Thanks
Luca



From edwardweisun at hotmail.com  Sun Feb 15 21:48:37 2004
From: edwardweisun at hotmail.com (Edward Sun)
Date: Sun, 15 Feb 2004 21:48:37 +0100
Subject: [R] Maximum likelihood estimation in R
Message-ID: <BAY14-F7lkS0tDXKaJH00006dd2@hotmail.com>


Dear Sir,

I am a new user of R and I am doing a tast, which is: find the maximum 
likelihood estimate of the parameter of Gaussian distribution for generated 
100 numbers by using >x=rnorm(100, mean=3, sd=1).

I tried to use following Maximum Likelihood function
>fn<-function(x)
(-50*log((sd(x))^2))-50*log(sqrt(2*pi))-(1/2*((mean(x))^2))*(sum((x-(mean(x))^2)),
but it did not work.

I am looking for the complete syntax to finish my target task.

Thanks for your help.

Best regards.
Edward Sun
Germany



From DivineSAAM at aol.com  Sun Feb 15 22:23:44 2004
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Sun, 15 Feb 2004 16:23:44 -0500
Subject: [R] Maximum likelihood estimation in R
Message-ID: <3173B95E.5B3FCAF0.0B088159@aol.com>

Hello,

Use

> x=rnorm(100, mean=3, sd=1)
> library(MASS)
>fitdistr(x, "normal")
      mean          sd    
  2.93666631   0.99673982 
 (0.09967398) (0.07048015)

Hope this helps,

Shrieb



From spencer.graves at pdf.com  Sun Feb 15 23:25:36 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 15 Feb 2004 14:25:36 -0800
Subject: [R] Maximum likelihood estimation in R
In-Reply-To: <3173B95E.5B3FCAF0.0B088159@aol.com>
References: <3173B95E.5B3FCAF0.0B088159@aol.com>
Message-ID: <402FF1E0.7000800@pdf.com>

      If, however, you are more interested in general methods for 
maximizing a likelihood function, I suggest you look at "optim", work 
the examples on the help page, etc. 

      hope this helps.  spencer graves

DivineSAAM at aol.com wrote:

>Hello,
>
>Use
>
>  
>
>>x=rnorm(100, mean=3, sd=1)
>>library(MASS)
>>fitdistr(x, "normal")
>>    
>>
>      mean          sd    
>  2.93666631   0.99673982 
> (0.09967398) (0.07048015)
>
>Hope this helps,
>
>Shrieb
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From spencer.graves at pdf.com  Sun Feb 15 23:32:49 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 15 Feb 2004 14:32:49 -0800
Subject: [R] panel data
In-Reply-To: <402FD950.4080401@unimc.it>
References: <402FD950.4080401@unimc.it>
Message-ID: <402FF391.1070300@pdf.com>

      How does "structural equation modeling" relate to "analysis of 
panel data"?  If structural equation modeling would help, then you may 
be interested in the "sem" package obtainable via 
"download.packages('sem')" from R 1.8.1 under windows (or see the FAQs). 

      hope this helps, spencer graves

Luca De Benedictis wrote:

> Dear R-friends,
> has anyone developed a package for panel data or even dynamic panel data?
> Thanks
> Luca
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Sun Feb 15 23:54:23 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 15 Feb 2004 17:54:23 -0500
Subject: [R] Maximum likelihood estimation in R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77BC@usrymx25.merck.com>

Or:

library(mle)
?mle

(which, BTW, uses optim() underneath.)

Also, for those not aware of it, fitdistr(x, "normal") just computes mean(x)
and (n-1)/n * var(x) and return them.  (I can't imagine any reason to do
otherwise for normal distribution.)

Best,
Andy

> From: Spencer Graves
> 
>       If, however, you are more interested in general methods for 
> maximizing a likelihood function, I suggest you look at "optim", work 
> the examples on the help page, etc. 
> 
>       hope this helps.  spencer graves
> 
> DivineSAAM at aol.com wrote:
> 
> >Hello,
> >
> >Use
> >
> >  
> >
> >>x=rnorm(100, mean=3, sd=1)
> >>library(MASS)
> >>fitdistr(x, "normal")
> >>    
> >>
> >      mean          sd    
> >  2.93666631   0.99673982 
> > (0.09967398) (0.07048015)
> >
> >Hope this helps,
> >
> >Shrieb
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >  
> >
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ggrothendieck at myway.com  Mon Feb 16 01:01:01 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 15 Feb 2004 19:01:01 -0500 (EST)
Subject: [R] father and son heights
Message-ID: <20040216000101.4915B3955@mprdmxin.myway.com>



I just noticed that the faraway package on CRAN contains
the stat500 dataset so you can just install that in the
usualy way, rather than googling around for faraway.zip .

Date:   Sun, 15 Feb 2004 14:27:52 -0500 (EST) 
From:   Gabor Grothendieck <ggrothendieck at myway.com>
To:   <loraine at loraine.net>, <r-help at stat.math.ethz.ch> 
Subject:   Re: [R] father and son heights 

 


Faraway's book titled "Practical Regression and Anova using R", 
with full text available online at:

http://cran.r-project.org/doc/contrib/Faraway-PRA.pdf

refers to a data set, stat500, which compares midterm and final
grades. It can be used to illustrate similar concepts.

A google search for faraway.zip will locate the actual data.

---
Date: Sun, 15 Feb 2004 10:37:08 -0800 
From: Ann Loraine <loraine at loraine.net>
[ Add to Address Book | Block Address | Report as Spam ] 
To: rhelp <r-help at stat.math.ethz.ch> 
Subject: Re: [R] father and son heights 


Actually, no. It's a data set that is used to teach Pearson's 
correlation coefficient in a popular statistics textbook - "Statistics" 
by Freedman, Pisani, et al.

It contains over a thousand measurements of son's and their father's 
heights.

I would like to find it in electronic form so that I can use it to 
prepare figures and examples for a lecture.

If anyone knows where I could find it, please let me know. I've done a 
few Google searches but haven't had any luck so far. I also used the 
data() command to look through R's built-in data sets and couldn't find 
it. Any suggestions would be most welcome!

Yours,

Ann Loraine


On Feb 15, 2004, at 5:46 AM, Spencer Graves wrote:

> Do you have this data set in any form? If yes, do you have it in 
> any electronic form? If yes, have you tried following relevant 
> suggestions in the manual on "R Data Import/Export"? [I got this as a 
> hot link from within R 1.8.1 "help.start()".]
>
> hope this helps.
> spencer graves
>
> Ann Loraine wrote:
>
>>
>> Hello,
>>
>> I'm looking for Pearson's father and son height data.
>>
>> Is this data set available in R?
>>
>> Thanks!
>>
>> Ann Loraine



From Don.Driscoll at flinders.edu.au  Mon Feb 16 03:18:15 2004
From: Don.Driscoll at flinders.edu.au (Don Driscoll)
Date: Mon, 16 Feb 2004 12:48:15 +1030
Subject: [R] unbalanced
Message-ID: <6.0.1.1.1.20040216124134.01b30dd0@mail.flinders.edu.au>

G'day,

The following code gives a two-way factorial anova, which is completely 
balanced.  However when model.tables is called, the response is:
"Design is unbalanced - use se.contrasts for se's", and SEs are not available.

Why doesn't R think my design is balanced and how do I convince it that it 
is and get the SEs that I want?

response<-c(rnorm(5,5,2),rnorm(5,12,2),rnorm(5,18,2),rnorm(5,12,2))
factor1<-factor(rep(c(1,2),each=10))
factor2 <- factor(rep(rep(c(1,2),each=5),2))

ddmodel<-aov(response~factor1*factor2)
summary(ddmodel)
model.tables(ddmodel, type="means",se=T)


Don.



Dr Don Driscoll
Lecturer in Biodiversity
School of Biological Sciences
Flinders University
GPO Box 2100
Adelaide SA 5001
(08) 8201 2165



From kmote at hotmail.com  Mon Feb 16 05:59:23 2004
From: kmote at hotmail.com (Pramote Khuwijitjaru)
Date: Mon, 16 Feb 2004 04:59:23 +0000
Subject: [R] Beginner's question about t.test()
Message-ID: <BAY10-F81baonE0Jxml0005e014@hotmail.com>


>From: Rolf Turner <rolf at math.unb.ca>
>To: kmote at hotmail.com
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] Beginner's question about t.test()
>Date: Sun, 15 Feb 2004 11:23:26 -0400 (AST)
>
>(a) You don't really need/want to look at t.test.default; your own
>code --- to do t tests based on summary statistics rather than data
>--- will have little or nothing to do with the code in
>t.test.default.  Just write code to do the t test ``as if you were
>doing it by hand'' which is very simple and straightforward.
>
>(b) The reason that you can't ``see'' the t.test.default code is the
>namespace business on which I recently wrote a perhaps ill-advised
>rant to this list.
>
>It was gently pointed out to me that the namespace idea certainly
>does have its uses and advantages.  It was also pointed out that you
>CAN get at functions which are ``hidden away'' by the namespace
>mechanism.  Three ways (of which I was kindly informed by Andy Liaw
>and Duncan Murdoch) are:
>
>	> ctest:::t.test.default
>	> getAnywhere("t.test.default")
>	> getS3method("t.test","default")
>
>Hope this helps.
>
>					cheers,
>
>						Rolf Turner
>						rolf at math.unb.ca



You are right, I really don't want to correct the function code because it 
seems too complex for me to understand it right now.   :)

Thanks for advice how to see the code.


                                                                             
   Pramote



From Rau at demogr.mpg.de  Mon Feb 16 10:22:38 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Mon, 16 Feb 2004 10:22:38 +0100
Subject: [R] Maximum likelihood estimation in R
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A06A3@hermes.demogr.mpg.de>

Hi,

> -----Original Message-----
> From:	DivineSAAM at aol.com [SMTP:DivineSAAM at aol.com]
> Sent:	Sunday, February 15, 2004 10:24 PM
> To:	edwardweisun at hotmail.com; r-help at stat.math.ethz.ch
> Subject:	Re: [R] Maximum likelihood estimation in R
> 
> Hello,
> 
> Use
> 
> > x=rnorm(100, mean=3, sd=1)
> > library(MASS)
> >fitdistr(x, "normal")
>       mean          sd    
>   2.93666631   0.99673982 
>  (0.09967398) (0.07048015)
> 
	For me, this example does not work. As it looks like copy+paste, I
guess this something platform dependent? At least I have to specify some
starting values as shown below. But maybe I did something wrong?

	Best,
	Roland
	(I am using at the moment R 1.8.1 on WinNT)

	> x=rnorm(100, mean=3, sd=1)
	> library(MASS)
	> fitdistr(x, "normal")
	Error in fitdistr(x, "normal") : 'start' must be a named list
	> fitdistr(x, "normal", start=list(mean=1, sd=0.4))
	      mean          sd    
	  3.03167815   1.06637851 
	 (0.10663786) (0.07539617)
	> 


+++++
This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked.   If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.



From nirmalg at psu.edu  Mon Feb 16 10:44:20 2004
From: nirmalg at psu.edu (Nirmal Govind)
Date: Mon, 16 Feb 2004 04:44:20 -0500
Subject: [R] intercept row in anova()
Message-ID: <403090F4.7000902@psu.edu>

Hi,

Is there a way to obtain the intercept row in the table that anova() 
outputs?

Thanks,
nirmal



From wayne.hallstrom at ualberta.ca  Mon Feb 16 11:25:25 2004
From: wayne.hallstrom at ualberta.ca (Wayne Hallstrom)
Date: Mon, 16 Feb 2004 03:25:25 -0700
Subject: [R] repeated measures nonlinear regression
Message-ID: <4032D86A@webmail.ualberta.ca>

Hi, 
I found this email on the R website.  I am trying to figure out how to
analyse a data set that I believe will need to be run through a procedure
involving repeated measures, regression and mixed models.

The data is of insect populations (dependent variable - either 0/1=binomial,
or as counts=poisson) in sites with different characteristics (multiple
independent variables which are both categorical and continuous).  These
populations were repeatedly sampled (an unequal number of times) at different
times during the year.

The standard stats packages are not able to do what I would like to do.  Any 
suggestions for some alternative methods such as those which are specially 
programmed for R and are suited to the type of data which I am analysing?  I 
understand I will need a flexible repeated measures application to be able to 
accept the unequal sampling.  I also will need a gnlm regression to fit the 
general data structure.  And also, I think, the mixed models capability in 
order to fit in the true nature of the data (see next paragraph).

Lastly, I have a question about independent variables.  For example, I have a
measure for host plant density at a site, which I am using as a
predictive/independent variable to compare with the insect population/response
variable.  However, the values for the host plant data at each site are 
produced by many samples taken in the site to derive a mean. The normal method 
in ecology is to then use this mean as 'the' host plant value for that site in 
your analysis.  I don't think this represents the full qualities of the data, 
and would like to be able to include the fact that this is really a mean +/- 
SD into the final statistical model, since this is what it really is, not just 
a single perfect value.  Any suggestions on how to do this?  I thought maybe a 
generalized linear mixed model (glmm) might allow this type of analysis to be 
done.  Perhaps it could be accomplished with some restructuring of the data?  
>From my reading about statistics I gather it is a general problem in 
regression.


Thank you for your time,
Wayne Hallstrom

Wayne Hallstrom
Department of Biological Sciences
CW 405, Biological Sciences Centre
University of Alberta
Edmonton, Alberta
Canada, T6G 2E9 
Telephone: (780) 492-1180
Fax: (780) 492-9234



From heydebre at molgen.mpg.de  Mon Feb 16 11:41:13 2004
From: heydebre at molgen.mpg.de (Anja von Heydebreck)
Date: Mon, 16 Feb 2004 11:41:13 +0100
Subject: [R] labRow/labCol options in heatmap()
Message-ID: <40309E49.2090803@molgen.mpg.de>

The function heatmap() allows to specify row/column labels
via the options labRow/labCol. From the code of heatmap(),
I understand that when no labels are specified, the row/column
labels (or indices) of the input matrix are taken as labels and 
re-ordered together with the rows and columns of the matrix before 
plotting, whereas labels supplied via labRow/labCol are plotted
in the original order.

Code from heatmap(), R 1.8.1:

x <- x[rowInd, colInd]
if (is.null(labRow))
    labRow <- if (is.null(rownames(x)))
        (1:nr)[rowInd]
    else rownames(x)
if (is.null(labCol))
    labCol <- if (is.null(colnames(x)))
        (1:nc)[colInd]
    else colnames(x)
...
axis(1, 1:nc, labels = labCol, las = 2, line = -0.5, tick = 0,
         cex.axis = cexCol)
axis(4, iy, labels = labRow, las = 2, line = -0.5, tick = 0,
         cex.axis = cexRow)

To see an example, try

a <- matrix(c(1,1,1,2,0,2), nrow=3)
rownames(a) <- 1:3
x11()
heatmap(a)
x11()
heatmap(a, labRow=rownames(a))

Is this really meant to work like this? - From
the help of heatmap(), one might expect also user-supplied
labels to be re-ordered together with the rows and
columns of the matrix.

Cheers,
Anja

-- 
Dr. Anja von Heydebreck
Max Planck Institute for Molecular Genetics
Dept. Computational Molecular Biology
Ihnestr. 73
14195 Berlin, Germany
heydebre at molgen.mpg.de             phone: +49-30-8413-1168
http://www.molgen.mpg.de/~heydebre   fax: +49-30-8413-1152



From SAULEAUEA at ch-mulhouse.fr  Mon Feb 16 11:46:14 2004
From: SAULEAUEA at ch-mulhouse.fr (=?iso-8859-1?Q?SAULEAU_Erik-Andr=E9?=)
Date: Mon, 16 Feb 2004 11:46:14 +0100
Subject: [R] Offset in GLMM
Message-ID: <A91EF0B9121F834EA6484582DFE1CF4436F11B@messagerie.chm.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/5647d307/attachment.pl

From thomas.fabbro at unifr.ch  Mon Feb 16 12:37:54 2004
From: thomas.fabbro at unifr.ch (Fabbro Thomas)
Date: Mon, 16 Feb 2004 12:37:54 +0100
Subject: [R] nlme_crossed AND nested random effects
Message-ID: <a05210501bc5658fefa55@[134.21.19.169]>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/bdf7e01f/attachment.pl

From demiurg at post.tau.ac.il  Mon Feb 16 13:17:52 2004
From: demiurg at post.tau.ac.il (demiurg@post.tau.ac.il)
Date: Mon, 16 Feb 2004 14:17:52 +0200
Subject: [R] aov and Error documentation
Message-ID: <1076933872.4030b4f05f7cf@webmail.tau.ac.il>

I could not find any documentation about aov() and Error() usage.
Both help pages (for aov and Error) does not specify it.

I'm mainly interested in aov with random effects.

Thanks a lot.



----------------------------------------------------------------
This message was sent using IMP, the Internet Messaging Program.



From bates at stat.wisc.edu  Mon Feb 16 13:56:30 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 Feb 2004 06:56:30 -0600
Subject: [R] repeated measures nonlinear regression
In-Reply-To: <4032D86A@webmail.ualberta.ca>
References: <4032D86A@webmail.ualberta.ca>
Message-ID: <6r3c9bqj29.fsf@bates4.stat.wisc.edu>

Wayne Hallstrom <wayne.hallstrom at ualberta.ca> writes:

> I found this email on the R website.  I am trying to figure out how
> to analyse a data set that I believe will need to be run through a
> procedure involving repeated measures, regression and mixed models.
> 
> The data is of insect populations (dependent variable - either
> 0/1=binomial, or as counts=poisson) in sites with different
> characteristics (multiple independent variables which are both
> categorical and continuous).  These populations were repeatedly
> sampled (an unequal number of times) at different times during the
> year.
> 
> The standard stats packages are not able to do what I would like to
> do.  Any suggestions for some alternative methods such as those
> which are specially programmed for R and are suited to the type of
> data which I am analysing?  I understand I will need a flexible
> repeated measures application to be able to accept the unequal
> sampling.  I also will need a gnlm regression to fit the general
> data structure.  And also, I think, the mixed models capability in
> order to fit in the true nature of the data (see next paragraph).

It sounds like you should be fitting a generalized linear mixed
model.  Look for the functions GLMM in package lme4 or glmmPQL in
package MASS.



From bates at stat.wisc.edu  Mon Feb 16 13:58:13 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 Feb 2004 06:58:13 -0600
Subject: [R] Offset in GLMM
In-Reply-To: <A91EF0B9121F834EA6484582DFE1CF4436F11B@messagerie.chm.com>
References: <A91EF0B9121F834EA6484582DFE1CF4436F11B@messagerie.chm.com>
Message-ID: <6ry8r3p4ey.fsf@bates4.stat.wisc.edu>

SAULEAU Erik-Andr? <SAULEAUEA at ch-mulhouse.fr> writes:

> Dear R-list,
> 
> I try to adjust GLMM on incidence cancer data. Without random
> effect, in GLM the command is, for example with sex effect,
> glm(Observed~sex+offset(log(Expected)),family=poisson) because the
> observed are Poisson distribued with parameter Expected*incidence
> rate. But know I want to introduce random effect (for example
> spatial effect) and it seems to me that the "offset" does not work
> in
> glmmPQL(Observed~sex+offset(log(Expected)),random=~1|ED,...,family=poisson)?
> I mean it does not work in lme.
> 
> what is the problem with my offset? thank you in advance, with best
> regards,

Did you try function GLMM from package lme4?  I believe that GLMM
allows an offset.



From bates at stat.wisc.edu  Mon Feb 16 14:22:59 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 Feb 2004 07:22:59 -0600
Subject: [R] nlme_crossed AND nested random effects
In-Reply-To: <a05210501bc5658fefa55@[134.21.19.169]>
References: <a05210501bc5658fefa55@[134.21.19.169]>
Message-ID: <6ru11rp39o.fsf@bates4.stat.wisc.edu>

Fabbro Thomas <thomas.fabbro at unifr.ch> writes:

> How can I define a lme with 3 factors(a,b,c), where c is nested in b, 
> and a is crossed with b/c?
> I think that:
> 
> lme(response ~ ..., data = Data,
>       random = pdBlocked(list(pdIdent(~ a - 1), pdIdent(~ b - 1))))
> 
> is one part of the answer and:
> 
> lme(response~...,  data=Data, random=~1|b/c)
> 
> is the other part of the answer but how can I combine them??

It's messy and inefficient with the current lme syntax, which was
specifically designed for nested random effects and does not handle
crossed random effects elegantly.

(I am working on other methods for lme that will make this much
easier.  however, it will be some time before I am able to release
even experimental versions of that code.  The changes involve tearing
apart all the lme code and rebuilding the underlying data structures
from scratch.  This is the fourth time that I have done that and I
keep thinking of a line from an old blues song about "keep doing it
wrong till you do it right".)

You need to generate a factor that corresponds to b/c.  Depending upon
how c is coded you may need to create it as

Data$bc = factor(paste(Data$b, Data$c, sep = "/"))

You will also need a factor with only one level

Data$const = factor(rep(1, nrow(Data)))

and you just generate the random effects model matrix from the various
sections

lme(response ~ ..., data = Data,
  random = list(const = pdBlocked(pdIdent(~a - 1), pdIdent(~ b - 1), 
    pdIdent(~ bc - 1)))

As I said, this is ugly and inefficient but it isn't the type of model
for which the current lme was designed.



From MSchwartz at medanalytics.com  Mon Feb 16 14:54:54 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 16 Feb 2004 07:54:54 -0600
Subject: [R] R Included with Open Infrastructure for Outcomes (OIO) system
Message-ID: <1076939694.10250.20.camel@localhost.localdomain>

Hi all,

I came across this article on LinuxMedNews (http://www.linuxmednews.com)
this morning:

http://www.linuxmednews.com/linuxmednews/1076524250/index_html

This refers to an integrated data management and analysis system (OIO),
which includes R and utilizes the RSessionDA package (Greg Warnes).

More information is available here for those interested:

http://zope.org/Members/aho/Open_Infrastructure_for_Outcomes/LiveOIO/liveoio/LiveOIO_1_0_8

There is one statement pertaining to R on the above page that I might
challenge:

"Unfortunately, it is a bit intimidating to use except by expert
statisticians."

If I can use it, anybody can...

;-)

Regards,

Marc Schwartz



From adrian_humbert at yahoo.com  Mon Feb 16 15:01:15 2004
From: adrian_humbert at yahoo.com (Adi Humbert)
Date: Mon, 16 Feb 2004 06:01:15 -0800 (PST)
Subject: [R] error in nls, step factor reduced below minFactor
Message-ID: <20040216140115.70993.qmail@web12102.mail.yahoo.com>

Hello, 

I am trying to estimate 4 parameters of a non-linear
model using nls.
My model function is a Fourier integral and is very
expensive to
calculate.  I get the following error:

> theta0 <- c(0.045, 1.02*10^(-4), 0.00169,
5.67*10^(-4))
> res <- nls(log(y) ~ log(model(theta,r,t)),
data=dataModel,
+     start=list(theta=theta0), trace=TRUE,
+     control=nls.control(tol=1e-2))
20.03975 :  0.045000 0.000102 0.001690 0.000567 
13.96798 :  0.0080957877 0.0001002399 0.0009541090
0.0005878496 
13.57454 :  8.099613e-03 9.852037e-05 9.341490e-04
5.970604e-04 
13.26752 :  0.0082989896 0.0000969310 0.0009268296
0.0006044495 
13.02448 :  8.654227e-03 9.546088e-05 9.288864e-04
6.103760e-04 
12.83024 :  9.135635e-03 9.410033e-05 9.377541e-04
6.151250e-04 
12.67412 :  9.720556e-03 9.284061e-05 9.514689e-04
6.189244e-04 
12.54838 :  0.0103914582 0.0000916738 0.0009685641
0.0006219567 
12.44723 :  1.113468e-02 9.059271e-05 9.879688e-04
6.243689e-04 
12.36625 :  1.193956e-02 8.959072e-05 1.008918e-03
6.262796e-04 
12.30196 :  0.0127978556 0.0000886618 0.0010308793
0.0006277845 
12.25158 :  1.370321e-02 8.780041e-05 1.053488e-03
6.289612e-04 
12.21285 :  1.465077e-02 8.700148e-05 1.076503e-03
6.298729e-04 
12.18390 :  1.563687e-02 8.626033e-05 1.099771e-03
6.305706e-04 
12.16319 :  1.665875e-02 8.557265e-05 1.123197e-03
6.310961e-04 
12.14939 :  0.0177143504 0.0000849345 0.0011467278
0.0006314833 
12.14139 :  1.880212e-02 8.434221e-05 1.170336e-03
6.317599e-04 
12.13825 :  1.992089e-02 8.379241e-05 1.194012e-03
6.319485e-04 
12.13761 :  0.0204953365 0.0000835372 0.0012058834
0.0006320080 
12.13748 :  2.078483e-02 8.341414e-05 1.211783e-03
6.320311e-04 
12.13747 :  0.0209299955 0.0000833537 0.0012147203
0.0006320413 
12.13746 :  2.096633e-02 8.333872e-05 1.215453e-03
6.320436e-04 
12.13746 :  2.098450e-02 8.333124e-05 1.215819e-03
6.320448e-04 
12.13746 :  2.099359e-02 8.332751e-05 1.216002e-03
6.320454e-04 
12.13746 :  2.099813e-02 8.332565e-05 1.216093e-03
6.320456e-04 
12.13746 :  2.099927e-02 8.332518e-05 1.216116e-03
6.320457e-04 
Error in nls(log(y) ~ log(model(theta, r, t)), data =
dataModel, start = list(theta = theta0),  : 
        step factor 0.000488281 reduced below
`minFactor' of 0.000976563
> 

The parameters seem to converge well.  I don't
understand why the
optimization does not stop.  I tried different
nls.controls, to
increase the tol, to reduce the minFactor, but it
makes no difference.
I keep getting the same error.  The function "model"
also returns the
gradient calculated numerically.  A run like the one
above takes me a
few hours.  Can you help?  I looked in the archive and
I've seen this
problem popping up, but no clear solution was
presented. 

Thank you, 
Adrian Dragulescu



From salfner at informatik.hu-berlin.de  Mon Feb 16 15:42:36 2004
From: salfner at informatik.hu-berlin.de (Felix Salfner)
Date: Mon, 16 Feb 2004 15:42:36 +0100
Subject: [R] how to solve a linear equation system with polynomial factors?
Message-ID: <4030D6DC.7090907@informatik.hu-berlin.de>

I'm looking for a way to solve a linear equation system where the factors are polynomials:

Here is a simplified example (To solve my problem, I have to deal with dimensions larger than 2):

(        s + 2) x1 + (s - 3) x2 = 2
( s^2 + 2s - 1) x1 -      2  x2 = 1

Theoretically the solution is easy: By performing polynomial multiplications, divisions and sums.

I found out, that R is able to perform the operations +, - , *, /  on polynomials but I don't 
know how to create a matrix of polynomials. 
matrix( c( polynomial( c(1,2,3)), polynomial( c(3,2,1)), ...)) does not work.

Even if I would manage to create such a matrix, will solve(A,r) work?

Can anyone help? 

Thanks in advance
Felix



From DivineSAAM at aol.com  Mon Feb 16 15:51:16 2004
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Mon, 16 Feb 2004 09:51:16 -0500
Subject: [R] Maximum likelihood estimation in R
Message-ID: <06CA49F8.50FDB882.0B088159@aol.com>

Hello,

Excellent, also the book:

Pawitan, Yudi (2001). In all Likelihood: Statistical Modelling and Inference using Likelihood, Clarendon Press, Oxford.

Is very good and the associated Web Site is full of MLE using R.

Hope this also helps.
/oal



From pburns at pburns.seanet.com  Mon Feb 16 16:09:27 2004
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 16 Feb 2004 15:09:27 +0000
Subject: [R] R Included with Open Infrastructure for Outcomes (OIO) system
References: <1076939694.10250.20.camel@localhost.localdomain>
Message-ID: <4030DD27.9010707@pburns.seanet.com>

Marc Schwartz wrote:

>[snip]
>

>There is one statement pertaining to R on the above page that I might
>challenge:
>
>"Unfortunately, it is a bit intimidating to use except by expert
>statisticians."
>
>If I can use it, anybody can...
>
>;-)
>
>Regards,
>
>Marc Schwartz
>  
>

I think this perception is our biggest challenge in spreading R. 
 Spreadsheets and
word processors also were thought to be intimidating.  Indeed if we 
needed to
know all of what R does to use it, then anyone would be more than a bit
intimidated, I'm sure.

There are two counter-attacks that I see:

1)  Make it clear that you can do useful work in R without knowing 
everything.
This can be facilitated by clear instructions on how to do some 
(subject-specific)
tasks.  The clarity of the instructions can be called into question, but an
example of what I have in mind is:
http://www.burns-stat.com/pages/Techan/r_for_tac.html

2)  Highlight what is central, and make that as simple and intuitive as 
possible.
I think the new division into a small "base" is a good step in that 
direction.

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

>  
>



From Icabalceta_j at wlf.state.la.us  Mon Feb 16 16:44:00 2004
From: Icabalceta_j at wlf.state.la.us (Icabalceta, Jorge L.)
Date: Mon, 16 Feb 2004 09:44:00 -0600
Subject: [R] How do we obtain Posterior Predictive (Bayesian) P-values in R
Message-ID: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0BF@wlfnt1.wlf.state.la.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/17ea34dd/attachment.pl

From bill.shipley at usherbrooke.ca  Mon Feb 16 16:50:23 2004
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Mon, 16 Feb 2004 10:50:23 -0500
Subject: [R] specifying partial nesting in lme
Message-ID: <001401c3f4a4$96b1e280$801ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/77b5b9b8/attachment.pl

From kamoun_wassim at yahoo.fr  Mon Feb 16 17:12:04 2004
From: kamoun_wassim at yahoo.fr (=?iso-8859-1?q?Wassim=20Kamoum?=)
Date: Mon, 16 Feb 2004 17:12:04 +0100 (CET)
Subject: [R] problem for installing package
Message-ID: <20040216161204.42879.qmail@web41306.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/74b67de1/attachment.pl

From ozric at web.de  Mon Feb 16 17:14:30 2004
From: ozric at web.de (Christian Schulz)
Date: Mon, 16 Feb 2004 17:14:30 +0100
Subject: [R] understanding loops  for "loop-plotting"
Message-ID: <200402161714.30282.ozric@web.de>

Hi,

i make some practice on "loops"  to understand this important
issue in "difference" to the wrappers like  apply  finally!
The point is that i want plot's for different different const  and wish in one 
pdf the 5 plots . So i want  plots for const=1:5 which change the undelying 
data expressed in t1 and t2.

I attempt  some trials , while, for  and now
repeat loop now , but didn't getting success . I get only the first plot  and 
the loop hang?

Many thanks for help ,Christian.

#modeldat  and YS are data.frames.
special <-  function(const,modeldat,YS) {
const=const
repeat {

t1  <-  apply(YS,1, function(x) {  ifelse(all(is.na(x)) | all(na.omit(x) < 
0 ,NA, which( x > const ))})

t1[is.na(t1)] <-  13

t2  <-  sapply(t1,function(x) { ifelse(x ==13,0,1)})

modeldat$MONTH  <- t1
modeldat$ACTIVE <- t2
modeldats <- na.omit(modeldat)
mod1 <-  coxph(Surv(MONTH,ACTIVE) ~  ALTER+RISIKO,data=modeldats)
pdf(file = "c:/Survivalx.pdf",    width = 6, height = 6, onefile = TRUE,
family = "Helvetica",title = "R Graphics Output")
plot(survfit(mod1),ylim=c(.7,1),xlab='Month',ylab='Proportion not Active')
const=const+1
if(const > 5) break
}
dev.off()
}



From Giovanni_Millo at generali.com  Mon Feb 16 17:15:19 2004
From: Giovanni_Millo at generali.com (Millo Giovanni)
Date: Mon, 16 Feb 2004 17:15:19 +0100
Subject: [R] Data for use in maps()
Message-ID: <74F2D4ED68558643B63A6CC21746040D9A06D5@BEMAILEXTS1.ad.generali.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/3b8f5517/attachment.pl

From pavlicov at stat.ohio-state.edu  Mon Feb 16 17:37:27 2004
From: pavlicov at stat.ohio-state.edu (Martina Pavlicova)
Date: Mon, 16 Feb 2004 11:37:27 -0500 (EST)
Subject: [R] 2 bwplots - different colors
Message-ID: <Pine.GSO.4.58.0402161122320.1504@spatial.stat.ohio-state.edu>


Hi all,

I would like to draw one picture which would show two different types of
boxplots using the same axes (kind of on top of each other). However, I
would like to plot each boxplot using a different color or different
shading inside the box, so they could be better distinquished from each
other... Could you help me?

Here is an example of the plot I have so far. I was only able to change
the color the median-dot (to 'red').

library(lattice)
foo1 <- matrix(rnorm(600),30,20)
foo2 <- matrix(rchisq(600,3),30,20)
bwplot(t(foo1)~c(1:20), xlim=as.character(seq(.01, .2, by=.01)),
       horizontal=F, bty=n, ylim=c(-3,11),
       panel=function(x,y,axes=F,...){
         panel.bwplot(x,y,bty=n,...)
         panel.bwplot(x, foo2, bty=n, col="red", ...)
       }
       )

Thank you very much for your help.

Martina Pavlicova

--------------------------------------------------------------------------
Department of Statistics             Office Phone: (614) 292-1567
1958 Neil Avenue, 304E Cockins Hall  FAX: (614) 292-2096
The Ohio State University            E-mail: pavlicov at stat.ohio-state.edu
Columbus, OH 43210-1247              www.stat.ohio-state.edu/~pavlicov



From spencer.graves at pdf.com  Mon Feb 16 17:44:26 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 16 Feb 2004 08:44:26 -0800
Subject: [R] Maximum likelihood estimation in R
In-Reply-To: <3699CDBC4ED5D511BE6400306E1C0D81030A06A3@hermes.demogr.mpg.de>
References: <3699CDBC4ED5D511BE6400306E1C0D81030A06A3@hermes.demogr.mpg.de>
Message-ID: <4030F36A.9090007@pdf.com>

      I got the same error message in R 1.8.1 and S-Plus 6.1.  Then I 
read the error message:  "'start' must be a named list".  Then I read 
help("fitdistr") and learned that "fitdistr" required 3 arguments, the 
third of which was "start: A named list giving the parameters to be 
optimized with initial values.  This can be omitted for some of the 
named distributions (see Details)."  The normal distribution was NOT one 
of the named distributions.  When I supplied a named list for "start", 
it worked: 

 > fitdistr(x, "normal", list(mean=0, sd=1))
      mean          sd   
  2.97093013   0.88852969
 (0.08885297) (0.06281083)

      hope this helps.  spencer graves

Rau, Roland wrote:

>Hi,
>
>  
>
>>-----Original Message-----
>>From:	DivineSAAM at aol.com [SMTP:DivineSAAM at aol.com]
>>Sent:	Sunday, February 15, 2004 10:24 PM
>>To:	edwardweisun at hotmail.com; r-help at stat.math.ethz.ch
>>Subject:	Re: [R] Maximum likelihood estimation in R
>>
>>Hello,
>>
>>Use
>>
>>    
>>
>>>x=rnorm(100, mean=3, sd=1)
>>>library(MASS)
>>>fitdistr(x, "normal")
>>>      
>>>
>>      mean          sd    
>>  2.93666631   0.99673982 
>> (0.09967398) (0.07048015)
>>
>>    
>>
>	For me, this example does not work. As it looks like copy+paste, I
>guess this something platform dependent? At least I have to specify some
>starting values as shown below. But maybe I did something wrong?
>
>	Best,
>	Roland
>	(I am using at the moment R 1.8.1 on WinNT)
>
>	> x=rnorm(100, mean=3, sd=1)
>	> library(MASS)
>	> fitdistr(x, "normal")
>	Error in fitdistr(x, "normal") : 'start' must be a named list
>	> fitdistr(x, "normal", start=list(mean=1, sd=0.4))
>	      mean          sd    
>	  3.03167815   1.06637851 
>	 (0.10663786) (0.07539617)
>	> 
>
>
>+++++
>This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked.   If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ripley at stats.ox.ac.uk  Mon Feb 16 17:52:37 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 16 Feb 2004 16:52:37 +0000 (GMT)
Subject: [R] column names in matrix vs. data frame in R 1.8
In-Reply-To: <OFEFE12043.8E7182F1-ON88256E35.005FA9A8-88256E35.005FEE89@epamail.epa.gov>
Message-ID: <Pine.LNX.4.44.0402161648310.26899-100000@gannet.stats>

On Mon, 9 Feb 2004 White.Denis at epamail.epa.gov wrote:

> 
> 
> 
> 
> > White.Denis at epamail.epa.gov writes:
> >
> > > Is the difference in behavior below, introduced in 1.8, inconsistent
> or,
> > > at least, undesirable?  I couldn't find this in the NEWS.
> > >
> > > On the one hand,
> > >
> > > > a <- matrix (1:4, nrow=2)
> > > > a <- data.frame (a)
> > > > names (a) <- c("break","next")
> > > > names (a)
> > > [1] "break" "next"
> > >
> > > On the other,
> > >
> > > > a <- matrix (1:4, nrow=2)
> > > > dimnames(a) <- list (1:2, c("break","next"))
> > > > a <- data.frame (a)
> > > > names(a)
> > > [1] "break." "next."
> >
> > Works fine if you don't use keywords as column names
> >
> > > a <- matrix (1:4, nrow=2)
> > > dimnames(a) <- list (1:2, c("foo","bar"))
> > > b <- data.frame(a)
> > > names(b)
> > [1] "foo" "bar"
> >
> > The difference in the result for your example has to do with an extra
> > step in the second case to obtain a legitimate name that can be used
> > with the $ operator.  R generates a syntax error for
> >
> > a$break
> >
> > but not for
> >
> > a$break.
> 
> Ok, I'll regard it as an inconsistency that the conversion of dimnames
> to data frame column names changes reserved words to legitimate names
> but direct assignment doesn't.

It's not inconsistent.  data.frame has an argument `check.names' to
control the behaviour on *creating* a data frame, and you didn't consult
the documentation.  Using the function names<- on the list underlying the
data frame does not know or care it is applied to a data frame.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wegmann at biozentrum.uni-wuerzburg.de  Mon Feb 16 18:07:40 2004
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Mon, 16 Feb 2004 18:07:40 +0100
Subject: [R] problem for installing package
In-Reply-To: <20040216161204.42879.qmail@web41306.mail.yahoo.com>
References: <20040216161204.42879.qmail@web41306.mail.yahoo.com>
Message-ID: <200402161807.40862.wegmann@biozentrum.uni-wuerzburg.de>

Hello, 

On Monday 16 February 2004 17:12, Wassim Kamoum wrote:
> Hello
>
> I would like to install a package on R (splancs package)
> after downloading them
> what is the step for implementing them in my library?

I don't know which operating system you are using if Windows that you might 
have a look at the "R for Windows FAQ", if it is a Unix type OS then the 
install procedure for additional packages is described in the "R FAQ" 
section. 

another very convenient option would be 
install.packages("splancs") inside R

both options are described in detail in the FAQ section, regards Martin



From aet21 at hermes.cam.ac.uk  Mon Feb 16 18:20:09 2004
From: aet21 at hermes.cam.ac.uk (A.E. Teschendorff)
Date: Mon, 16 Feb 2004 17:20:09 +0000 (GMT)
Subject: [R] consensus trees/groups from clustering
Message-ID: <Pine.SOL.4.44.0402161712350.8972-100000@red.csi.cam.ac.uk>


 Hi,
 I wish to build consensus groups/tree from a set of bootstraps from a
clustering algorithm such as hc or k-means, but can't find an R-function
that does this. Does anyone know of an R procedure/function which allows
one to build such consensus groups/tree .?

 Many thanks,
 Andrew


*******************************************************************
Dr Andrew E Teschendorff
Hutchison/MRC Research Centre
Department of Oncology/Cancer Research UK
University of Cambridge
Hills Road
Cambridge
CB2 2XZ
UK

aet21 at cam.ac.uk    aet21 at hutchison-mrc.cam.ac.uk
07771 898256



From oehl_list at gmx.de  Mon Feb 16 18:52:54 2004
From: oehl_list at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Mon, 16 Feb 2004 18:52:54 +0100 (MET)
Subject: [R] consensus trees/groups from clustering
Message-ID: <4728.1076953974@www52.gmx.net>


Andrew,

have a look at 

library(e1071) 
?bclust

which does bagging of kmeans cluster centers followed by hierarchical
cluster analysis.
Smart and fast.

Best regards


Jens Oehlschl?gel

> I wish to build consensus groups/tree from a set of bootstraps from a
> clustering algorithm such as hc or k-means, but can't find an R-function
> that does this. Does anyone know of an R procedure/function which allows
> one to build such consensus groups/tree .?


-- 
GMX ProMail (250 MB Mailbox, 50 FreeSMS, Virenschutz, 2,99 EUR/Monat...)
jetzt 3 Monate GRATIS + 3x DER SPIEGEL +++ http://www.gmx.net/derspiegel +++



From ripley at stats.ox.ac.uk  Mon Feb 16 18:42:33 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 16 Feb 2004 17:42:33 +0000 (GMT)
Subject: [R] Maximum likelihood estimation in R
In-Reply-To: <4030F36A.9090007@pdf.com>
Message-ID: <Pine.LNX.4.44.0402161741090.26899-100000@gannet.stats>

"normal" is in the list in the current versions of MASS, but not that 
released with R 1.8.1.  Try update.packages() in R.

On Mon, 16 Feb 2004, Spencer Graves wrote:

>       I got the same error message in R 1.8.1 and S-Plus 6.1.  Then I 
> read the error message:  "'start' must be a named list".  Then I read 
> help("fitdistr") and learned that "fitdistr" required 3 arguments, the 
> third of which was "start: A named list giving the parameters to be 
> optimized with initial values.  This can be omitted for some of the 
> named distributions (see Details)."  The normal distribution was NOT one 
> of the named distributions.  When I supplied a named list for "start", 
> it worked: 
> 
>  > fitdistr(x, "normal", list(mean=0, sd=1))
>       mean          sd   
>   2.97093013   0.88852969
>  (0.08885297) (0.06281083)
> 
>       hope this helps.  spencer graves
> 
> Rau, Roland wrote:
> 
> >Hi,
> >
> >  
> >
> >>-----Original Message-----
> >>From:	DivineSAAM at aol.com [SMTP:DivineSAAM at aol.com]
> >>Sent:	Sunday, February 15, 2004 10:24 PM
> >>To:	edwardweisun at hotmail.com; r-help at stat.math.ethz.ch
> >>Subject:	Re: [R] Maximum likelihood estimation in R
> >>
> >>Hello,
> >>
> >>Use
> >>
> >>    
> >>
> >>>x=rnorm(100, mean=3, sd=1)
> >>>library(MASS)
> >>>fitdistr(x, "normal")
> >>>      
> >>>
> >>      mean          sd    
> >>  2.93666631   0.99673982 
> >> (0.09967398) (0.07048015)
> >>
> >>    
> >>
> >	For me, this example does not work. As it looks like copy+paste, I
> >guess this something platform dependent? At least I have to specify some
> >starting values as shown below. But maybe I did something wrong?
> >
> >	Best,
> >	Roland
> >	(I am using at the moment R 1.8.1 on WinNT)
> >
> >	> x=rnorm(100, mean=3, sd=1)
> >	> library(MASS)
> >	> fitdistr(x, "normal")
> >	Error in fitdistr(x, "normal") : 'start' must be a named list
> >	> fitdistr(x, "normal", start=list(mean=1, sd=0.4))
> >	      mean          sd    
> >	  3.03167815   1.06637851 
> >	 (0.10663786) (0.07539617)
> >	> 
> >
> >
> >+++++
> >This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked.   If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >  
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From deepayan at stat.wisc.edu  Mon Feb 16 19:17:43 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 16 Feb 2004 12:17:43 -0600
Subject: [R] 2 bwplots - different colors
In-Reply-To: <Pine.GSO.4.58.0402161122320.1504@spatial.stat.ohio-state.edu>
References: <Pine.GSO.4.58.0402161122320.1504@spatial.stat.ohio-state.edu>
Message-ID: <200402161217.43167.deepayan@stat.wisc.edu>


On Monday 16 February 2004 10:37, Martina Pavlicova wrote:

> Hi all,
>
> I would like to draw one picture which would show two
> different types of boxplots using the same axes (kind of
> on top of each other). However, I would like to plot each
> boxplot using a different color or different shading
> inside the box, so they could be better distinquished
> from each other... Could you help me?
>
> Here is an example of the plot I have so far. I was only
> able to change the color the median-dot (to 'red').

Your code doesn't work for me as it is.

bwplot isn't really designed for grouped displays. Why don't 
you plot them in different panels ? I don't see any point 
in superposing them. For example,


library(lattice)
foo1 <- rnorm(600)
foo2 <- rchisq(600, 3)
bwplot(foo1 + foo2 ~ gl(20, 30), allow.m = T, outer = T)



If you really want to superimpose them, I would suggest 
using the following approach:



bwplot(foo1 + foo2 ~ gl(20, 30), allow.m = T, outer = F,
       panel =
       function(x, y, subscripts, groups, ...) {
           opar <- trellis.par.get()
           x <- as.numeric(x)
           y <- as.numeric(y)

           settings <- list()
           settings[[1]] <- 
               list(box.rectangle = list(col = "cyan"),
                    box.umbrella = list(col = "cyan"),
                    plot.symbol = list(col = "cyan"),
                    box.dot = list(col = "blue"))

           settings[[2]] <- 
               list(box.rectangle = list(col = "pink"),
                    box.umbrella = list(col = "pink"),
                    plot.symbol = list(col = "pink"),
                    box.dot = list(col = "red"))

           vals <- levels(groups)
           for (i in 1:2)
           {
               lset(settings[[i]])
               id <- groups[subscripts] == vals[i]
               panel.bwplot(x = x[id], y = y[id], ...)
               lset(opar)
           }
       })



Note that there are too many graphical parameters 
controlling boxplots to be included in panel.bwplot, and 
you need to modify the global settings to get anything 
useful. The relevant parameters that you may want to modify 
are given by

trellis.par.get("box.rectangle")
trellis.par.get("box.umbrella")
trellis.par.get("box.dot")
trellis.par.get("plot.symbol")


Hope that helps,

Deepayan



From ripley at stats.ox.ac.uk  Mon Feb 16 19:29:18 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 16 Feb 2004 18:29:18 +0000 (GMT)
Subject: [R] aov and Error documentation
In-Reply-To: <1076933872.4030b4f05f7cf@webmail.tau.ac.il>
Message-ID: <Pine.LNX.4.44.0402161824570.26899-100000@gannet.stats>

On Mon, 16 Feb 2004 demiurg at post.tau.ac.il wrote:

> I could not find any documentation about aov() and Error() usage.
> Both help pages (for aov and Error) does not specify it.

My copy says

     If the formula contains a single 'Error' term, this is used to
     specify error strata, and appropriate models are fitted within
     each error stratum.

and gives an example *and* a reference.  (If you know about this sort of
thing, that is sufficient information. If not, read the reference.)

> I'm mainly interested in aov with random effects.

Depends what you mean by that: it is not what the help pages says it does, 
and depending what you mean it may be better to use lme in package nlme.

There are worked examples in MASS (see the FAQ) and this was actaully 
implemented in R to support those examples.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rxg218 at psu.edu  Mon Feb 16 19:31:42 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Mon, 16 Feb 2004 13:31:42 -0500
Subject: [R] resizing a plot area when using mfrow
Message-ID: <1076956302.838.8.camel@ra.chem.psu.edu>

Hi,
  I'm trying to plot two graphs next to each other using the plot()
command. I've used 

par(mfrow=c(1,2),pty='s')

to get the plots on 1 row.
However what happens is that I get a large plot area with the 2 plots in
the center of it, so there is a large amount of white space above and
below the plots.

Currently I take the EPS and then cut out the white boundaries in a
image manipulation program. 

Is there someway I can specify in R that the plot area should resize to
just enclose the row of plots without generating large areas of
whitespace?

Thanks,
-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
C Code.
C Code Run.
Run, Code, RUN!
PLEASE!!!!



From Jim_Garrett at bd.com  Mon Feb 16 20:22:56 2004
From: Jim_Garrett at bd.com (Jim_Garrett@bd.com)
Date: Mon, 16 Feb 2004 14:22:56 -0500
Subject: [R] Calculate Closest 5 Cases? 
Message-ID: <OFCA76353E.D064D598-ON85256E3C.005529E3@bd.com>

Danny,

Here's another approach that doesn't use sorting.  Instead, after
calculating distances it considers a threshold on distance and counts how
many cases are within the threshold.  Then a search over thresholds is
conducted to find a threshold yielding the desired number of cases.  Then
case numbers satisfying the found threshold are returned.

Why go to this bother to avoid sorting?  Since the computation required to
sort N distances grows more quickly than the computation required to make a
pass through a vector of distances and count values less than a threshold,
for some N this approach ought to be more efficient than one based on
sorting.  Well, maybe, if the number of iterations grows slowly enough with
N.  Call it a conjecture.  On the other hand, the N for which this occurs
depends on the efficiency of the sort algorithm (pretty darned efficient
and using compiled code, I imagine) and the efficiency of the search
algorithm.  Here I use uniroot, which isn't really designed with step
functions in mind, so perhaps there are possible improvements.  So I
couldn't say whether this will work faster than the other suggestions
you've gotten with your data, or even for data one is likely to ever see.

If there are ties for the 6th-nearest case (counting the point itself),
this routine should either include or exclude all the ties, whichever comes
closest to yielding 5 points.

Here's the code:

## Args:
## CaseNo:     Row number of case for which to find nearest neighbors.
## x:          A numeric matrix.
## k:          The desired number of neighbors, not counting the point of
interest.
## TempIndex:  Index of row numbers.  If you use this function many many
times you
##             might gain an iota of efficiency by creating this vector
once and
##             passing it in as an argument with each call.  Probably not
worth the
##             trouble, I couldn't help myself....
## verbose:    Tells you how many iterations uniroot used, if you're
curious.
## Value:
## A vector of (hopefully) k row numbers indicating the k nearest
neighbors.
nearestKNeighbors <- function(CaseNo, x, k, TempIndex = 1:nrow(x), verbose
= F) {
  ## make sure x is a matrix
  if(!is.matrix(x))
    stop("x must be a matrix.")

  TempVect <- x[CaseNo, ]
  SquaredDistances <- apply(x, 1, function(s) sum((s - TempVect)^2) )

  tempFun <- function(h) sum(SquaredDistances < h^2) - (k + 1)
  TempSolution <- uniroot(tempFun, interval = range(SquaredDistances))
  if(verbose)
    cat("Required", TempSolution$iter, "iterations.\n")

  sort(setdiff(TempIndex[SquaredDistances < TempSolution$root^2], CaseNo))
}

You would apply this to each row of your dataset using some variety of
"apply" or a loop.  I don't know if memory usage would differ.  In the
event of ties, you may not have 5 neighbors, so I might put the results in
a list, which can accommodate different lengths in each component (indeed,
it can accommodate completely different data structures):

## data in matrix temp.matrix
ListOutput <-
  lapply(as.list(1:nrow(temp.matrix)),
         function(s) nearestKNeighbors(s, temp.matrix, 5))

or

ListOutput <-
  vector(nrow(temp.matrix), mode = "list")
for(i in 1:nrow(temp.matrix))
  ListOutput[[i]] <- nearestKNeighbors(i, temp.matrix, 5)

and then you can manipulate the list however you like.  For instance, to
see if all components have length 5,

all(unlist(lapply(ListOutput, length)) == 5)

or, if there are such components, find out which one(s):

(1:length(ListOutput))[unlist(lapply(ListOutput, length)) != 5]

Welcome to R!

Best,

-Jim Garrett

***

> I've only begun investigating R as a substitute for SPSS.

> I have a need to identify for each CASE the closest (or most similar) 5
> other CASES (not including itself as it is automatically the closest).  I

> have a fairly large matrix (50000 cases by 50 vars).  In SPSS, I can use
> Correlate > Distances to generate a matrix of similarity, but only on a
small
> sample.  The entire matrix can not be processed at once due to memory
limitations.

> The data are all percents, so they are easy comparable.

> Is there any way to do this in R?

> Below is a small sample of the data (from SPSS) and the desired output.

> Thanks,

> Danny


**********************************************************************
This message is intended only for the designated recipient(s...{{dropped}}



From k.wang at auckland.ac.nz  Mon Feb 16 20:30:21 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 17 Feb 2004 08:30:21 +1300
Subject: [R] problem for installing package
In-Reply-To: <20040216161204.42879.qmail@web41306.mail.yahoo.com>
Message-ID: <20040216193032.GYNJ9271.mta1-rme.xtra.co.nz@kevinlpt>

Hi,

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wassim Kamoum
> Sent: Tuesday, February 17, 2004 5:12 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] problem for installing package
>
> Hello
>
> I would like to install a package on R (splancs package)
> after downloading them
> what is the step for implementing them in my library?

Which operating system are you running R on?

Reading the manuals might be a good start.....

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
SLC Stats Workshops Co-ordinator
The University of Auckland
New Zealand



From nisa_bakkalbasi at hotmail.com  Mon Feb 16 20:50:02 2004
From: nisa_bakkalbasi at hotmail.com (Nisa Bakkalbasi)
Date: Mon, 16 Feb 2004 14:50:02 -0500
Subject: [R] Binary logistic model using lrm function
Message-ID: <BAY7-F12b7HhFqmCNM100021098@hotmail.com>

Hello all,

Could someone tell me what I am doing wrong here?

I am trying to fit a binary logistic model using the lrm function in Design. 
The dataset I am using has a dichotomous response variable, 'covered' 
(1-yes, 0-no) with explanatory variables, 'nepall', 'title', 'abstract', 
'series', and 'author1.'

I am running the following script and all seems to be working.

library(Hmisc, T)
library(Design, T)
Mydata <- read.table("author1.df", header=T)
attach(Mydata)
dd <- datadist(nepall, title, abstract, series, author1)
fit <- lrm(covered ~ nepall + title + abstract + series +
    author1, data = Mydata, x = TRUE, y = TRUE)
anova(fit)
detach()

However, when I look at the output for predict(fit), I am getting values 
below 0 and above 1, which does not make much sense. Can someone lead me in 
the right direction?

Thank you for your help in advance.

Nisa Bakkalbasi

_________________________________________________________________
Get some great ideas here for your sweetheart on Valentine's Day - and 
beyond. http://special.msn.com/network/celebrateromance.armx



From MSchwartz at medanalytics.com  Mon Feb 16 20:53:34 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 16 Feb 2004 13:53:34 -0600
Subject: [R] resizing a plot area when using mfrow
In-Reply-To: <1076956302.838.8.camel@ra.chem.psu.edu>
References: <1076956302.838.8.camel@ra.chem.psu.edu>
Message-ID: <1076961214.10250.73.camel@localhost.localdomain>

On Mon, 2004-02-16 at 12:31, Rajarshi Guha wrote:
> Hi,
>   I'm trying to plot two graphs next to each other using the plot()
> command. I've used 
> 
> par(mfrow=c(1,2),pty='s')
> 
> to get the plots on 1 row.
> However what happens is that I get a large plot area with the 2 plots in
> the center of it, so there is a large amount of white space above and
> below the plots.
> 
> Currently I take the EPS and then cut out the white boundaries in a
> image manipulation program. 
> 
> Is there someway I can specify in R that the plot area should resize to
> just enclose the row of plots without generating large areas of
> whitespace?
> 
> Thanks,


One approach is to adjust the page size that you use for the EPS output,
since you are forcing a square plot region. A rough guess might be to
use a page width that is twice the page height. Be sure to use 'paper =
"special"' to adjust the EPS bounding box.


# Specify the EPS output
postscript(file = "RPlot.eps", onefile = TRUE, paper = "special",
           width = 10, height = 5, horizontal = FALSE)

# Set 1 row, 2 cols, square plot region
par(mfrow=c(1,2), pty = "s")

# Generate two plots
plot(1:5)
plot(1:10)

# Close postscript device
dev.off()

Take a look at RPlot.eps and see if this is what you require.

HTH,

Marc Schwartz



From rxg218 at psu.edu  Mon Feb 16 21:00:02 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Mon, 16 Feb 2004 15:00:02 -0500
Subject: [R] resizing a plot area when using mfrow
In-Reply-To: <1076961214.10250.73.camel@localhost.localdomain>
References: <1076956302.838.8.camel@ra.chem.psu.edu>
	<1076961214.10250.73.camel@localhost.localdomain>
Message-ID: <1076961602.1605.5.camel@ra.chem.psu.edu>

On Mon, 2004-02-16 at 14:53, Marc Schwartz wrote:
> On Mon, 2004-02-16 at 12:31, Rajarshi Guha wrote:
> > Hi,
> >   I'm trying to plot two graphs next to each other using the plot()
> > command. I've used 
> > 
> > par(mfrow=c(1,2),pty='s')
> > 
> > to get the plots on 1 row.
> > However what happens is that I get a large plot area with the 2 plots in
> > the center of it, so there is a large amount of white space above and
> > below the plots.

> One approach is to adjust the page size that you use for the EPS output,
> since you are forcing a square plot region. A rough guess might be to
> use a page width that is twice the page height. Be sure to use 'paper =
> "special"' to adjust the EPS bounding box.
> 
> 
> # Specify the EPS output
> postscript(file = "RPlot.eps", onefile = TRUE, paper = "special",
>            width = 10, height = 5, horizontal = FALSE)
> 
> # Set 1 row, 2 cols, square plot region
> par(mfrow=c(1,2), pty = "s")
> 
> # Generate two plots
> plot(1:5)
> plot(1:10)
> 
> # Close postscript device
> dev.off()

Thanks - that does exactly what I need. 

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Artificial intelligence has the same relation to intelligence as
artificial flowers have to flowers.
-- David Parnas



From dingdong1205 at yahoo.com  Mon Feb 16 21:04:11 2004
From: dingdong1205 at yahoo.com (Cynthia He)
Date: Mon, 16 Feb 2004 12:04:11 -0800 (PST)
Subject: [R] question about matrix
Message-ID: <20040216200411.26259.qmail@web20915.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/a5bfa93d/attachment.pl

From bates at stat.wisc.edu  Mon Feb 16 21:20:08 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 Feb 2004 14:20:08 -0600
Subject: [R] question about matrix
In-Reply-To: <20040216200411.26259.qmail@web20915.mail.yahoo.com>
References: <20040216200411.26259.qmail@web20915.mail.yahoo.com>
Message-ID: <6r8yj2vksn.fsf@bates4.stat.wisc.edu>

Cynthia He <dingdong1205 at yahoo.com> writes:

>      How to write this matrix in R?  The "^" sign is a power symbol.
>  
>      Thanks a lot!
>  
>  
>  0^1   0^2  .........  0^n 
>  1^1   1^2  .........  1^n
>  2^1   2^2  .........  2^n
> ................................
> ................................
>  q^1   q^2  .........  q^n

Use the outer product function, as in

> outer(0:5, 1:4, "^")
     [,1] [,2] [,3] [,4]
[1,]    0    0    0    0
[2,]    1    1    1    1
[3,]    2    4    8   16
[4,]    3    9   27   81
[5,]    4   16   64  256
[6,]    5   25  125  625



From spencer.graves at pdf.com  Mon Feb 16 21:24:20 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 16 Feb 2004 12:24:20 -0800
Subject: [R] question about matrix
In-Reply-To: <20040216200411.26259.qmail@web20915.mail.yahoo.com>
References: <20040216200411.26259.qmail@web20915.mail.yahoo.com>
Message-ID: <403126F4.8090006@pdf.com>

 outer(0:2, 1:2, "^")
     [,1] [,2]
[1,]    0    0
[2,]    1    1
[3,]    2    4

      Is this what you want? 

      spencer graves

Cynthia He wrote:

>Hello there,
> 
>     How to write this matrix in R?  The "^" sign is a power symbol.
> 
>     Thanks a lot!
> 
> 
> 0^1   0^2  .........  0^n 
> 1^1   1^2  .........  1^n
> 2^1   2^2  .........  2^n
>................................
>................................
> q^1   q^2  .........  q^n
>
>
>---------------------------------
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From duoduoxiaozhan at yahoo.com  Mon Feb 16 21:41:30 2004
From: duoduoxiaozhan at yahoo.com (duoduo chen)
Date: Mon, 16 Feb 2004 12:41:30 -0800 (PST)
Subject: [R] Questions about Matrix
Message-ID: <20040216204130.20354.qmail@web61109.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/cd60cfc6/attachment.pl

From rossini at blindglobe.net  Mon Feb 16 21:44:20 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 16 Feb 2004 12:44:20 -0800
Subject: [R] R Included with Open Infrastructure for Outcomes (OIO) system
In-Reply-To: <1076939694.10250.20.camel@localhost.localdomain> (Marc
	Schwartz's message of "Mon, 16 Feb 2004 07:54:54 -0600")
References: <1076939694.10250.20.camel@localhost.localdomain>
Message-ID: <85brnysqjf.fsf@servant.blindglobe.net>

Marc Schwartz <MSchwartz at medanalytics.com> writes:

> Hi all,
>
> I came across this article on LinuxMedNews (http://www.linuxmednews.com)
> this morning:
>
> http://www.linuxmednews.com/linuxmednews/1076524250/index_html
>
> This refers to an integrated data management and analysis system (OIO),
> which includes R and utilizes the RSessionDA package (Greg Warnes).
>
> More information is available here for those interested:
>
> http://zope.org/Members/aho/Open_Infrastructure_for_Outcomes/LiveOIO/liveoio/LiveOIO_1_0_8
>
> There is one statement pertaining to R on the above page that I might
> challenge:
>
> "Unfortunately, it is a bit intimidating to use except by expert
> statisticians."
>
> If I can use it, anybody can...

Consider the application area of OIO, though, which is the collection
of CRF's (patient-based case report forms for hospital as well as
possibly clinical-trials related activities).  This is a fair caution,
I think, for that general population of researchers and hospital IT
folks (and clinician/IT types).  

Issues include use of R as well as application of medium to advanced
statistical methods.

On the other hand, it's a nice approach, and one which we are working
on to leverage for similar projects.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From rolf at math.unb.ca  Mon Feb 16 22:43:34 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 16 Feb 2004 17:43:34 -0400 (AST)
Subject: [R] Questions about Matrix
Message-ID: <200402162143.i1GLhYKt010653@erdos.math.unb.ca>


duoduo chen <duoduoxiaozhan at yahoo.com> wrote:

> How to Generate the Matrix (t+1)*m ?
>  
> (0-1)^n   (0-2)^n  ,,,,    (0-m)^n
> (1-1)^n   (1-2)^n  ,,,,    (1-m)^n
> (2-1)^n   (2-2)^n  ,,,,    (2-m)^n
>    ..           ...     ,,,,     .......
> (t-1)^n    (t-2)^n   ,,,,    (t-m)^n  
>  
>  
> Appreciate your kindly help!

Gee, this question looks awfully familiar!  There must be
a lot of this going around ....

Homework problem?

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From gracestat at yahoo.com  Mon Feb 16 22:44:45 2004
From: gracestat at yahoo.com (Grace Conlon)
Date: Mon, 16 Feb 2004 13:44:45 -0800 (PST)
Subject: [R] Matrix mulitplication
Message-ID: <20040216214445.86581.qmail@web21403.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/05033c40/attachment.pl

From myao at ou.edu  Mon Feb 16 22:48:21 2004
From: myao at ou.edu (Yao, Minghua)
Date: Mon, 16 Feb 2004 15:48:21 -0600
Subject: [R] Questions about Matrix
Message-ID: <78B50CF247E5D04B8A5E02D001CC8E9A595C1F@XMAIL.sooner.net.ou.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/caa183ec/attachment.pl

From myao at ou.edu  Mon Feb 16 22:53:39 2004
From: myao at ou.edu (Yao, Minghua)
Date: Mon, 16 Feb 2004 15:53:39 -0600
Subject: [R] Questions about Matrix
Message-ID: <78B50CF247E5D04B8A5E02D001CC8E9A595C22@XMAIL.sooner.net.ou.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/4b657296/attachment.pl

From Icabalceta_j at wlf.state.la.us  Mon Feb 16 23:05:21 2004
From: Icabalceta_j at wlf.state.la.us (Icabalceta, Jorge L.)
Date: Mon, 16 Feb 2004 16:05:21 -0600
Subject: [R] How do we obtain Posterior Predictive (Bayesian) P-values in R
	(a sking a second time)
Message-ID: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0C2@wlfnt1.wlf.state.la.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/2e5f31ee/attachment.pl

From j.zhu at imb.uq.edu.au  Mon Feb 16 23:10:21 2004
From: j.zhu at imb.uq.edu.au (Justin Xi ZHU)
Date: Tue, 17 Feb 2004 08:10:21 +1000
Subject: [R] plot
Message-ID: <5.1.0.14.2.20040217080821.054fd520@mail.imb.uq.edu.au>

Hi,

How could I plot two vectors on the same graph? For example, if I have two 
lists of results, each list is a vector. I want to display them on the same 
graph, so I can compare them. How could I do that?

Regards, Justin



From gregory_r_warnes at groton.pfizer.com  Mon Feb 16 23:25:16 2004
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Mon, 16 Feb 2004 17:25:16 -0500
Subject: [R] xls2csv.pl:  Script to translate Excel files into CSV
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20680AEF1@groexmb02.pfizer.com>



I've created a Perl script that translates Microsoft Excel (.xls) files into
comma-delimited text files (.csv) using the Perl Spreadsheet::ParseExcel
module. 

Usage
-----

perl xls2csv.pl <excel file> [<output file>] [<worksheet number>]

Translate the Microsoft Excel spreadsheet file contained in
<excel file> into comma separated value format (CSV) and store
in <output file>.

If <output file> is not specified, the output file will have the
same name as the input file with '.xls' or '.XLS' (if any)
removed and '.csv' appended.

If no worksheet number is given, each worksheet will be written to
a separate file with the name '<output file>_<worksheet name>.csv'.

Dependencies
------------

xls2csv.pl depends on the OLE::Storage-Lite and Spreadsheet::ParseExcel
packages which are available below or from the author's CPAN
<http://search.cpan.org/author/KWITKNR/> site. 


Where to get it
----------------

http://www.analytics.washington.edu/Zope/projects/xls2csv.pl

Contacting the Author
---------------------

The xls2csv.pl script is maintained by Gregory R. Warnes
gregory_r_warnes at groton.pfizer.com
<mailto:gregory_r_warnes at groton.pfizer.com>. Questions, comments, patches,
etc. are welcome. 

-Greg

Gregory R. Warnes
Manager, Non-Clinical Statistics
Pfizer Global Research and Development
Tel: 860-715-3536



LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From Ted.Harding at nessie.mcc.ac.uk  Mon Feb 16 23:35:46 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 16 Feb 2004 22:35:46 -0000 (GMT)
Subject: [R] Matrix mulitplication
In-Reply-To: <20040216214445.86581.qmail@web21403.mail.yahoo.com>
Message-ID: <XFMail.040216223546.Ted.Harding@nessie.mcc.ac.uk>

On 16-Feb-04 Grace Conlon wrote:
> ABCD are four matrix.
> A * Inverse((Transpose(A)*Tranpose(B)*B*A+C)) * Transpose(A) *
> Transpose(B) * D
>  
> how to write in R in an efficient way?

The only "efficiency saving" I can see here is to evaluate transposes
only once:

  At <- t(A)
  Bt <- t(B)
  A%*%solve(At%*%Bt%*%B%*%A + C)%*%At%*%Bt%*%D

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 16-Feb-04                                       Time: 22:35:46
------------------------------ XFMail ------------------------------



From tblackw at umich.edu  Mon Feb 16 23:59:07 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Mon, 16 Feb 2004 17:59:07 -0500 (EST)
Subject: [R] plot
In-Reply-To: <5.1.0.14.2.20040217080821.054fd520@mail.imb.uq.edu.au>
References: <5.1.0.14.2.20040217080821.054fd520@mail.imb.uq.edu.au>
Message-ID: <Pine.SOL.4.58.0402161754470.10211@timepilot.gpcc.itd.umich.edu>

Justin  -

If both vectors are the same length, and the interpretations given
to successive elements of each are the same, you might wish to make
a bivariate scatterplot:  plot(result.1, result.2).  Otherwise, you
could plot the values in each vector against their element numbers:
plot(result.1, pch=15)
points(result.2, pch=18)
Depends on what makes sense in your own context.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 17 Feb 2004, Justin Xi ZHU wrote:

> Hi,
>
> How could I plot two vectors on the same graph? For example, if I have two
> lists of results, each list is a vector. I want to display them on the same
> graph, so I can compare them. How could I do that?
>
> Regards, Justin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dmurdoch at pair.com  Tue Feb 17 00:08:34 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 16 Feb 2004 18:08:34 -0500
Subject: [R] Questions about Matrix
In-Reply-To: <200402162143.i1GLhYKt010653@erdos.math.unb.ca>
References: <200402162143.i1GLhYKt010653@erdos.math.unb.ca>
Message-ID: <u8j2301vrabf6mfvdih50efac9s2t307eo@4ax.com>

On Mon, 16 Feb 2004 17:43:34 -0400 (AST), you wrote:

>
>duoduo chen <duoduoxiaozhan at yahoo.com> wrote:
>
>> How to Generate the Matrix (t+1)*m ?
>>  
>> (0-1)^n   (0-2)^n  ,,,,    (0-m)^n
>> (1-1)^n   (1-2)^n  ,,,,    (1-m)^n
>> (2-1)^n   (2-2)^n  ,,,,    (2-m)^n
>>    ..           ...     ,,,,     .......
>> (t-1)^n    (t-2)^n   ,,,,    (t-m)^n  
>>  
>>  
>> Appreciate your kindly help!
>
>Gee, this question looks awfully familiar!  There must be
>a lot of this going around ....
>
>Homework problem?

Both postings were through Yahoo from U. Mass., so it's vaguely
possible...

Duncan Murdoch



From Ted.Harding at nessie.mcc.ac.uk  Tue Feb 17 00:05:21 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 16 Feb 2004 23:05:21 -0000 (GMT)
Subject: [R] Matrix mulitplication
In-Reply-To: <XFMail.040216223546.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.040216230521.Ted.Harding@nessie.mcc.ac.uk>

On 16-Feb-04 Ted Harding wrote:
> On 16-Feb-04 Grace Conlon wrote:
>> ABCD are four matrix.
>> A * Inverse((Transpose(A)*Tranpose(B)*B*A+C)) * Transpose(A) *
>> Transpose(B) * D
>>  
>> how to write in R in an efficient way?
> 
> The only "efficiency saving" I can see here is to evaluate transposes
> only once:
> 
>   At <- t(A)
>   Bt <- t(B)
>   A%*%solve(At%*%Bt%*%B%*%A + C)%*%At%*%Bt%*%D

Sorry! Missed a trick here:

    At <- t(A)
    Bt <- t(B)
    E  <- B%*%A
    Et <- t(E)
    A%*%solve(Et%*%E + C)%*%Et%*%D

(saves 2 multiplications at the relatively cheap cost of 1 transpose)

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 16-Feb-04                                       Time: 23:05:21
------------------------------ XFMail ------------------------------



From p.dalgaard at biostat.ku.dk  Tue Feb 17 00:35:03 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Feb 2004 00:35:03 +0100
Subject: [R] Matrix mulitplication
In-Reply-To: <XFMail.040216230521.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.040216230521.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <x2r7wu4mzc.fsf@biostat.ku.dk>

(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:

> Sorry! Missed a trick here:
> 
>     At <- t(A)
>     Bt <- t(B)
>     E  <- B%*%A
>     Et <- t(E)
>     A%*%solve(Et%*%E + C)%*%Et%*%D
> 
> (saves 2 multiplications at the relatively cheap cost of 1 transpose)

Well, you might consider getting rid of the first two transposes since
you're not actually using them for anything....


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Ted.Harding at nessie.mcc.ac.uk  Tue Feb 17 00:41:57 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 16 Feb 2004 23:41:57 -0000 (GMT)
Subject: [R] Matrix mulitplication
In-Reply-To: <x2r7wu4mzc.fsf@biostat.ku.dk>
Message-ID: <XFMail.040216234157.Ted.Harding@nessie.mcc.ac.uk>

On 16-Feb-04 Peter Dalgaard wrote:
> (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:
> 
>> Sorry! Missed a trick here:
>> 
>>     At <- t(A)
>>     Bt <- t(B)
>>     E  <- B%*%A
>>     Et <- t(E)
>>     A%*%solve(Et%*%E + C)%*%Et%*%D
>> 
>> (saves 2 multiplications at the relatively cheap cost of 1 transpose)
> 
> Well, you might consider getting rid of the first two transposes since
> you're not actually using them for anything....

Touch? ... !
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 16-Feb-04                                       Time: 23:41:57
------------------------------ XFMail ------------------------------



From andy_liaw at merck.com  Tue Feb 17 01:08:18 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 16 Feb 2004 19:08:18 -0500
Subject: [R] Binary logistic model using lrm function
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77C9@usrymx25.merck.com>

You need to (re-)read the help page for predict.lrm, especially the `type'
argument.

Andy

> From: Nisa Bakkalbasi
> 
> Hello all,
> 
> Could someone tell me what I am doing wrong here?
> 
> I am trying to fit a binary logistic model using the lrm 
> function in Design. 
> The dataset I am using has a dichotomous response variable, 'covered' 
> (1-yes, 0-no) with explanatory variables, 'nepall', 'title', 
> 'abstract', 
> 'series', and 'author1.'
> 
> I am running the following script and all seems to be working.
> 
> library(Hmisc, T)
> library(Design, T)
> Mydata <- read.table("author1.df", header=T)
> attach(Mydata)
> dd <- datadist(nepall, title, abstract, series, author1)
> fit <- lrm(covered ~ nepall + title + abstract + series +
>     author1, data = Mydata, x = TRUE, y = TRUE)
> anova(fit)
> detach()
> 
> However, when I look at the output for predict(fit), I am 
> getting values 
> below 0 and above 1, which does not make much sense. Can 
> someone lead me in 
> the right direction?
> 
> Thank you for your help in advance.
> 
> Nisa Bakkalbasi
> 
> _________________________________________________________________
> Get some great ideas here for your sweetheart on Valentine's 
> Day - and 
> beyond. http://special.msn.com/network/celebrateromance.armx
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From erich.neuwirth at univie.ac.at  Tue Feb 17 01:16:50 2004
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Tue, 17 Feb 2004 01:16:50 +0100
Subject: [R] Questions about Matrix
In-Reply-To: <78B50CF247E5D04B8A5E02D001CC8E9A595C22@XMAIL.sooner.net.ou.edu>
References: <78B50CF247E5D04B8A5E02D001CC8E9A595C22@XMAIL.sooner.net.ou.edu>
Message-ID: <40315D72.7070000@univie.ac.at>

whatisit<-function(t,m,n) outer(0:t,1:m,function(x,y)(x-y)^n)

 > whatisit(3,2,4)
      [,1] [,2]
[1,]    1   16
[2,]    0    1
[3,]    1    0
[4,]   16    1



Yao, Minghua wrote:

> M <- matrix(0, t+1, m)
> for (i in 1:(t+1))
>   for(j in 1:m)
>     M[i,j] <- (i-1-j)^n
> 
> 
> ________________________________
> 
> From: r-help-bounces+myao=ou.edu at stat.math.ethz.ch on behalf of duoduo chen
> Sent: Mon 2/16/2004 2:41 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Questions about Matrix
> 
> 
> 
> How to Generate the Matrix (t+1)*m ?
> 
> (0-1)^n   (0-2)^n  ,,,,    (0-m)^n
> (1-1)^n   (1-2)^n  ,,,,    (1-m)^n
> (2-1)^n   (2-2)^n  ,,,,    (2-m)^n
>    ..           ...     ,,,,     .......
> (t-1)^n    (t-2)^n   ,,,,    (t-m)^n 
> 
> 
> Appreciate your kindly help!
> 
> 
> 
> ---------------------------------
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386



From k.wang at auckland.ac.nz  Tue Feb 17 01:28:47 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 17 Feb 2004 13:28:47 +1300
Subject: [R] plot
In-Reply-To: <5.1.0.14.2.20040217080821.054fd520@mail.imb.uq.edu.au>
Message-ID: <000c01c3f4ed$02a37880$6633d882@stat.auckland.ac.nz>


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Justin Xi ZHU
> Sent: Tuesday, February 17, 2004 11:10 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] plot
> 
> 
> Hi,
> 
> How could I plot two vectors on the same graph? For example, 
> if I have two 
> lists of results, each list is a vector. I want to display 
> them on the same 
> graph, so I can compare them. How could I do that?

You have to be more specific.  What kind of vertors are they?  Are they
both numeric continuous variables?  What kind of plot(s) do you want to
draw?

Assuming you have two continuous variables and you want to draw a
scatter plot, one way to do it is to use plot().  For example:
  plot(x, y)

Take a loot at ?plot to find out how to use it.

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
Statistics Workshops Co-ordinator
Student Learning Centre
University of Auckland
New Zealand



From spencer.graves at pdf.com  Tue Feb 17 02:03:06 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 16 Feb 2004 17:03:06 -0800
Subject: [R] Matrix mulitplication
In-Reply-To: <XFMail.040216234157.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.040216234157.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <4031684A.3090004@pdf.com>

      One can also use "crossprod" AND use "solve" to actually "solve" 
the system of linear equations rather than just get the inverse, which 
is later multiplied by t(BA)%*%D.  However, the difference seems very 
small: 

 > set.seed(1)
 > n <- 500
 > A <- array(rnorm(n^2), dim=c(n,n))
 > B <- array(rnorm(n^2), dim=c(n,n))
 > C. <- array(rnorm(n^2), dim=c(n,n))
 > D <- array(rnorm(n^2), dim=c(n,n))
 >
 > BA <- B%*%A
 >
 > start.time <- proc.time()
 > A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D
 > proc.time()-start.time
[1] 4.75 0.03 5.13   NA   NA
 >
 > start.time <- proc.time()
 > A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D))
 > proc.time()-start.time
[1] 4.19 0.01 4.49   NA   NA
 > all.equal(A1, A2)
[1] TRUE

      This was in R 1.8.1 under Windows 2000 on an IBM Thinkpad T30 with 
a Mobile Intel Pentium 4-M, 1.8Ghz, 1Gbyte RAM.  The same script under 
S-Plus 6.2 produced the following elapsed times: 

[1] 3.325 0.121 3.815 0.000 0.000

[1] 2.934 0.070 3.355 0.000 0.000

      Thus, roughly, using "crossprod" plus "solving with solve" gave a 
10% speed improvement and S-Plus 6.2 gave a 25% speed improvement in 
this one small benchmark.  Using smaller matrices did not show as big a 
difference just because the time was too short to measure accurately, I 
think. 

      Enough trivia for now. 
      Best Wishes,
      spencer graves

(Ted Harding) wrote:

>On 16-Feb-04 Peter Dalgaard wrote:
>  
>
>>(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:
>>
>>    
>>
>>>Sorry! Missed a trick here:
>>>
>>>    At <- t(A)
>>>    Bt <- t(B)
>>>    E  <- B%*%A
>>>    Et <- t(E)
>>>    A%*%solve(Et%*%E + C)%*%Et%*%D
>>>
>>>(saves 2 multiplications at the relatively cheap cost of 1 transpose)
>>>      
>>>
>>Well, you might consider getting rid of the first two transposes since
>>you're not actually using them for anything....
>>    
>>
>
>Touch? ... !
>Ted.
>
>
>--------------------------------------------------------------------
>E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
>Fax-to-email: +44 (0)870 167 1972
>Date: 16-Feb-04                                       Time: 23:41:57
>------------------------------ XFMail ------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From k.wang at auckland.ac.nz  Tue Feb 17 02:30:10 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 17 Feb 2004 14:30:10 +1300
Subject: [R] plot
In-Reply-To: <5.1.0.14.2.20040217112839.15a058c0@mail.imb.uq.edu.au>
Message-ID: <000e01c3f4f5$95874160$6633d882@stat.auckland.ac.nz>

> -----Original Message-----
> From: Justin Xi ZHU [mailto:j.zhu at imb.uq.edu.au] 
> Sent: Tuesday, February 17, 2004 2:30 PM
> To: Ko-Kang Kevin Wang
> Subject: RE: [R] plot
> 
> 
> Hi,
> 
> Thanks for your email.
> 
> 
> Result 1: 23, 234, 45, 39 corresponding to Q1, Q2, Q3 and Q4.
> Result 2: 123, 34, 454, 45 corresponding to Q1, Q2, Q3 and Q4.
> 
> I would like to plot both result 1 and result 2 on the same 
> graph. The 
> x-axis is Q1, Q2, Q3 and Q4. I would like to compare two trends.
> 
> Regards, Justin

What you can do is to plot the question labels on the x-axis and use
points (with different types/colours) and/or lies for the two "Results".

You may want to take a look at the documentation for plot(), points() or
lines().

I'm sure there are better plots, but I'll leave that to the other
r-helpers to help you -- I'm too busy finishing up a consulting report
*_*.

Cheers,

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
Statistics Workshops Co-ordinator
Student Learning Centre
University of Auckland
New Zealand



From ggrothendieck at myway.com  Tue Feb 17 02:42:37 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 16 Feb 2004 20:42:37 -0500 (EST)
Subject: [R] Matrix mulitplication
Message-ID: <20040217014237.1EAA43991@mprdmxin.myway.com>



If you have to compute it many times for the same value of C
but different values of A and B then you could use the 
Sherman-Morrison-Woodbury formula which expresses the inverse
of C+UV' in terms of the inverse of C.  This would allow you
to avoid computing any inverses (except for C which only has to
be done once).  See:

http://mathworld.wolfram.com/WoodburyFormula.html

---
Date:   Mon, 16 Feb 2004 13:44:45 -0800 (PST) 
From:   Grace Conlon <gracestat at yahoo.com>
To:   <R-help at stat.math.ethz.ch> 
Subject:   [R] Matrix mulitplication 

 
ABCD are four matrix.
A * Inverse((Transpose(A)*Tranpose(B)*B*A+C)) * Transpose(A) * Transpose(B) * D

how to write in R in an efficient way?



From p.murrell at auckland.ac.nz  Tue Feb 17 03:42:09 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 17 Feb 2004 15:42:09 +1300
Subject: [R] understanding loops  for "loop-plotting"
References: <200402161714.30282.ozric@web.de>
Message-ID: <40317F81.1030004@stat.auckland.ac.nz>

Hi

If you make the pdf() call BEFORE entering the loop does it do what you 
want?

Paul


Christian Schulz wrote:
> Hi,
> 
> i make some practice on "loops"  to understand this important
> issue in "difference" to the wrappers like  apply  finally!
> The point is that i want plot's for different different const  and wish in one 
> pdf the 5 plots . So i want  plots for const=1:5 which change the undelying 
> data expressed in t1 and t2.
> 
> I attempt  some trials , while, for  and now
> repeat loop now , but didn't getting success . I get only the first plot  and 
> the loop hang?
> 
> Many thanks for help ,Christian.
> 
> #modeldat  and YS are data.frames.
> special <-  function(const,modeldat,YS) {
> const=const
> repeat {
> 
> t1  <-  apply(YS,1, function(x) {  ifelse(all(is.na(x)) | all(na.omit(x) < 
> 0 ,NA, which( x > const ))})
> 
> t1[is.na(t1)] <-  13
> 
> t2  <-  sapply(t1,function(x) { ifelse(x ==13,0,1)})
> 
> modeldat$MONTH  <- t1
> modeldat$ACTIVE <- t2
> modeldats <- na.omit(modeldat)
> mod1 <-  coxph(Surv(MONTH,ACTIVE) ~  ALTER+RISIKO,data=modeldats)
> pdf(file = "c:/Survivalx.pdf",    width = 6, height = 6, onefile = TRUE,
> family = "Helvetica",title = "R Graphics Output")
> plot(survfit(mod1),ylim=c(.7,1),xlab='Month',ylab='Proportion not Active')
> const=const+1
> if(const > 5) break
> }
> dev.off()
> }
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From mmchug4 at lsu.edu  Tue Feb 17 04:14:07 2004
From: mmchug4 at lsu.edu (Maurice McHugh)
Date: Mon, 16 Feb 2004 21:14:07 -0600
Subject: [R] varimax rotation in R
Message-ID: <004401c3f504$1aefbfe0$b9f60b44@br.no.cox.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040216/8e67d93f/attachment.pl

From ozric at web.de  Tue Feb 17 07:44:39 2004
From: ozric at web.de (Christian Schulz)
Date: Tue, 17 Feb 2004 07:44:39 +0100
Subject: [R] understanding loops  for "loop-plotting"
In-Reply-To: <40317F81.1030004@stat.auckland.ac.nz>
References: <200402161714.30282.ozric@web.de>
	<40317F81.1030004@stat.auckland.ac.nz>
Message-ID: <200402170744.39816.ozric@web.de>

yes, yesterday when i go to
sleep i recognize my stupid error!

Thanks,Christian

Am Dienstag, 17. Februar 2004 03:42 schrieb Paul Murrell:
> Hi
>
> If you make the pdf() call BEFORE entering the loop does it do what you
> want?
>
> Paul
>
> Christian Schulz wrote:
> > Hi,
> >
> > i make some practice on "loops"  to understand this important
> > issue in "difference" to the wrappers like  apply  finally!
> > The point is that i want plot's for different different const  and wish
> > in one pdf the 5 plots . So i want  plots for const=1:5 which change the
> > undelying data expressed in t1 and t2.
> >
> > I attempt  some trials , while, for  and now
> > repeat loop now , but didn't getting success . I get only the first plot 
> > and the loop hang?
> >
> > Many thanks for help ,Christian.
> >
> > #modeldat  and YS are data.frames.
> > special <-  function(const,modeldat,YS) {
> > const=const
> > repeat {
> >
> > t1  <-  apply(YS,1, function(x) {  ifelse(all(is.na(x)) | all(na.omit(x)
> > < 0 ,NA, which( x > const ))})
> >
> > t1[is.na(t1)] <-  13
> >
> > t2  <-  sapply(t1,function(x) { ifelse(x ==13,0,1)})
> >
> > modeldat$MONTH  <- t1
> > modeldat$ACTIVE <- t2
> > modeldats <- na.omit(modeldat)
> > mod1 <-  coxph(Surv(MONTH,ACTIVE) ~  ALTER+RISIKO,data=modeldats)
> > pdf(file = "c:/Survivalx.pdf",    width = 6, height = 6, onefile = TRUE,
> > family = "Helvetica",title = "R Graphics Output")
> > plot(survfit(mod1),ylim=c(.7,1),xlab='Month',ylab='Proportion not
> > Active') const=const+1
> > if(const > 5) break
> > }
> > dev.off()
> > }
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html



From samuel.bertrand at paris.ensam.fr  Tue Feb 17 09:32:38 2004
From: samuel.bertrand at paris.ensam.fr (Samuel Bertrand)
Date: Tue, 17 Feb 2004 09:32:38 +0100
Subject: [R] normality test
Message-ID: <5.0.2.1.2.20040217092449.00b066a8@mailhost.paris.ensam.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040217/9a126a94/attachment.pl

From alessandro.semeria at cramont.it  Tue Feb 17 09:53:52 2004
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Tue, 17 Feb 2004 09:53:52 +0100
Subject: [R] normality test
Message-ID: <OFC52DA91B.9C8C019C-ONC1256E3D.0030E05F@tomware.it>





A qqplot is a good raw test to look quickly
the normality of a distribution.
best
A.S.

----------------------------

Alessandro Semeria
Models and Simulations Laboratory
Montecatini Environmental Research Center (Edison Group),
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: alessandro.semeria at cramont.it



From baron at psych.upenn.edu  Tue Feb 17 10:10:54 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 17 Feb 2004 04:10:54 -0500
Subject: [R] normality test
In-Reply-To: <OFC52DA91B.9C8C019C-ONC1256E3D.0030E05F@tomware.it>
References: <OFC52DA91B.9C8C019C-ONC1256E3D.0030E05F@tomware.it>
Message-ID: <20040217091054.GA23150@psych>

shapiro.test
is also relevant.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From luke.keele at politics-and-international-relations.oxford.ac.uk  Tue Feb 17 10:51:46 2004
From: luke.keele at politics-and-international-relations.oxford.ac.uk (Luke Keele)
Date: Tue, 17 Feb 2004 09:51:46 -0000
Subject: [R] Lattice graphics and strip function
Message-ID: <000901c3f53b$a7bccdf0$903701a3@politics.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040217/81059e6f/attachment.pl

From tor.strand at cih.uib.no  Tue Feb 17 11:00:27 2004
From: tor.strand at cih.uib.no (Tor A Strand)
Date: Tue, 17 Feb 2004 11:00:27 +0100
Subject: [R] Bad Plotting subrange
Message-ID: <1C997562-6130-11D8-8A1B-000A9568DB4C@cih.uib.no>

Dear helpers,

In a script that displays the (y) fitted values, (y) observed values 
against the x values I occasionally get the error message "Bad Plotting 
subrange". The error message comes rather randomly and I have no clue 
why.

Can anybody explain me what this message means and what the problem 
might be?

thanks,

I am using version 5.6.4



From ripley at stats.ox.ac.uk  Tue Feb 17 12:00:10 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Feb 2004 11:00:10 +0000 (GMT)
Subject: [R] varimax rotation in R
In-Reply-To: <004401c3f504$1aefbfe0$b9f60b44@br.no.cox.net>
Message-ID: <Pine.LNX.4.44.0402171050210.6017-100000@gannet.stats>

On Mon, 16 Feb 2004, Maurice McHugh wrote:

> I have used several methods to calculate principal components rotated
> using the varimax procedure.  This is simple enough.  But I would like
> to calculate the % of variance explained associated with each PC before
> and after rotation.
> 
> factanal returns the % of variance explained associated with each PC but
> I cannot seem to get it to change after rotation.

factanal does factor analysis, not principal component analysis.  Factor
rotation makes sense for factor analysis (the latent variables are
rotationally equivariant) but not much sense for PCA (where successive PCs
maximize the variance).  factanal() does a varimax rotation by default 
so that a further varimax rotation does nothing.

What the print method for factanal reports is the same as the print method 
for loadings().  So to continue example(varimax)

loadings(fa)
new <- varimax(fa$loadings, normalize = FALSE)
class(new$loadings) <- "loadings"
loadings(new)


Your description is confused, but it is hard for us to know where the 
confusion lies.

> Many thanks for your help!
> 
> Maurice
> 
> mmchug4 at lsu.edu
> 
> Maurice McHugh
> Department of Geography and Anthropology
> Louisiana State University
> Baton Rouge, LA

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From yukangtu at hotmail.com  Tue Feb 17 12:39:46 2004
From: yukangtu at hotmail.com (Tu Yu-Kang)
Date: Tue, 17 Feb 2004 11:39:46 +0000
Subject: [R] extracting standard error from lme output
Message-ID: <BAY12-F43y8WPPN5Gmf0002b562@hotmail.com>

Dear R experts,

I want to extract standard error from the output of lme, but I found  
fix.effects() does not include SE of the coefficients.  Many thanks in 
advance.

Best regards,

Yu-Kang

_________________________________________________________________
{bNW MSN |GbuWsBA



From krcabrer at perseus.unalmed.edu.co  Tue Feb 17 13:40:13 2004
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Tue, 17 Feb 2004 07:40:13 -0500
Subject: [R] =?utf-8?q?citation=28=29_doesn=C2=B4t_work?=
Message-ID: <opr3ilhbdcfaouaq@200.24.8.4>

Hi R users:

I want to know if you have the same problem with
the citation() function, it doesn?t work!

Thank you

R in W2K, version 1.8.1.


-- 
Kenneth Cabrera
Universidad Nacional de Colombia
Tel 430 9351
Cel 315 504 9339
Medell?n



From ajayshah at mayin.org  Tue Feb 17 12:20:19 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Tue, 17 Feb 2004 16:50:19 +0530
Subject: [R] Bug report for fracdiff
Message-ID: <E1At3H1-0005ai-00@sanna.igidr.ac.in>


I was sniffing in the fracdiff library (this is for fractionally integrated
ARMA processes; Haslett and Raftery 1989).

The documentation suggests that one tries the following simple example:

library(fracdiff)
ts.test <- fracdiff.sim( 5000, ar = .2, ma = -.4, d = .3)
fracdiff( ts.test$series, nar = length(ts.test$ar), nma = length(ts.test$ma))

When I run this, I get the following error:

R --vanilla < demo.R > demo.out
Warning message: 
unable to compute correlation matrix in: switch(temp$info, warning("warning in gamma function"), warning("singular Hessian"),  


This doesn't look nice. Should I be worried? Is this a bug report? Does
R have a system like Debian's `reportbug' for submitting bugs.



From mmarques at inescporto.pt  Tue Feb 17 13:45:55 2004
From: mmarques at inescporto.pt (MMarques Power)
Date: Tue, 17 Feb 2004 12:45:55 +0000
Subject: [R] plot
In-Reply-To: <5.1.0.14.2.20040217080821.054fd520@mail.imb.uq.edu.au>
References: <5.1.0.14.2.20040217080821.054fd520@mail.imb.uq.edu.au>
Message-ID: <4412018531.20040217124555@power.inescn.pt>

Hello Justin,

Monday, February 16, 2004, 10:10:21 PM, you wrote:

JXZ> How could I plot two vectors on the same graph? For example, if I have two
JXZ> lists of results, each list is a vector. I want to display them on the same 
JXZ> graph, so I can compare them. How could I do that?
JXZ> Regards, Justin

There several aproachs to that question.

Something like
plot(x, type ="l")
lines(y)
if both vectors have the same range...

another is

par(mfrow=c(1,2))
plot(x)
plot(y)

with each plot in diferent boxes...


Still reading the plot help and par could  be needed



or





Best regards,
 MMarques                            mailto:mmarques at power.inescn.pt



From ripley at stats.ox.ac.uk  Tue Feb 17 13:51:49 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Feb 2004 12:51:49 +0000 (GMT)
Subject: [R] =?utf-8?q?citation=28=29_doesn=C2=B4t_work?=
In-Reply-To: <opr3ilhbdcfaouaq@200.24.8.4>
Message-ID: <Pine.LNX.4.44.0402171250380.437-100000@gannet.stats>

On Tue, 17 Feb 2004, Kenneth Cabrera wrote:

> Hi R users:
> 
> I want to know if you have the same problem with
> the citation() function, it doesn??t work!

So, what exactly happens on your system?  I get

> citation()
To cite R in publications, use

....

on R-1.8.1 under Windows.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Roger.Bivand at nhh.no  Tue Feb 17 13:54:33 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 17 Feb 2004 13:54:33 +0100 (CET)
Subject: [R] Data for use in maps()
In-Reply-To: <74F2D4ED68558643B63A6CC21746040D9A06D5@BEMAILEXTS1.ad.generali.	com>
Message-ID: <Pine.LNX.4.44.0402171339020.13338-100000@reclus.nhh.no>

On Mon, 16 Feb 2004, Millo Giovanni wrote:

> Dear all,
> 
> I am interested in plotting maps visualizing spatial statistics in an
> aggregated fashion, according to administrative boundaries. 
> More specifically, I have fitted a cross-section model on data regarding
> Italian "counties" (province, for Italian readers) and I would like to
> visualize residual behavior on a map, in order to have a first
> assessment of their spatial autocorrelation. I would also make some EDA
> on the spatial patterns (if any) of the regressors.
> 
> I have found the maps package (and related) and would be able to do what
> I want, e.g., for the USA, essentially by
> >map("state",fill=T,col=color)
> where color is dependent on the statistic of interest, but I still lack
> a data file for counties' boundaries in Italy. Does anybody know where
> to find one? Is there any convenient tool for converting from other
> formats? I would like to do everything in R if possible.
> 

Unfortunately, while the US government makes available a large amount of 
free map data - such as administrative boundaries, this is certainly not 
the case in Europe. Of course, administrative boundaries also change, so 
the map data source you use should match the data you are trying to map. 
At least two proprietary GIS programs distribute maps of Italian provinces 
for use in their programs (MapInfo and ArcGIS), but I believe you need a 
license to access the data - it is (unlike US data) not downloadable.

It is possible that you can use the data referenced in the RArcInfo 
contributed package, which is downloaded from:

http://www.grid.unep.ch/data/grid/gnv158.php

but these are NUTS 2 regions dating at latest from the early 1990's, and 
do not seem to be the same as the CIA Italian provinces map. 

So there are three questions:

1) finding a free (or non-free) source of boundary data appropriate for
the provinces that suit your attribute data;

2) getting that into R (and possibly projecting it);

3) plotting the map.

On 2 and 3, you may find http://sal.agecon.uiuc.edu/csiss/Rgeo/index.html 
useful, especially the sections on maps. It may be that your organisation 
has purchased suitable non-free boundary data - in which case a 
"shapefile" is probably the easiest format to ask for.

> Thanks in advance
> 
> Giovanni Millo
> R&D Dept.
> Assicurazioni Generali SpA
> Trieste, Italy

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From m.okasha at palnet.com  Tue Feb 17 14:14:17 2004
From: m.okasha at palnet.com (Dr. Mahmoud K. Okasha)
Date: Tue, 17 Feb 2004 15:14:17 +0200
Subject: =?ISO-8859-1?Q?Re:_=5BR=5D_citation=28=29_doesn=B4t_work?=
References: <Pine.LNX.4.44.0402171250380.437-100000@gannet.stats>
Message-ID: <006101c3f557$f2cbaca0$30334ed9@okasha>

No, I have just used it. the result is:

> citation()
To cite R in publications, use

  R Development Core Team (2003). R: A language and environment for
statistical
  computing. R Foundation for Statistical Computing, Vienna, Austria. ISBN
  3-900051-00-3, URL http://www.R-project.org.

We have invested a lot of effort in creating R, please cite it when using it
for data
analysis.

A BibTeX entry for LaTeX users is

  @Manual{,
     title        = {R: A language and environment for
                     statistical computing},
     author       = {{R Development Core Team}},
     organization = {R Foundation for Statistical Computing},
     address      = {Vienna, Austria},
     year         = 2003,
     note         = {ISBN 3-900051-00-3},
     url          = {http://www.R-project.org}
   }

>
Best regards...

----- Original Message -----
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Kenneth Cabrera" <krcabrer at perseus.unalmed.edu.co>
Cc: <r-help at stat.math.ethz.ch>
Sent: Tuesday, February 17, 2004 2:51 PM
Subject: Re: [R] citation() doesn?t work


> On Tue, 17 Feb 2004, Kenneth Cabrera wrote:
>
> > Hi R users:
> >
> > I want to know if you have the same problem with
> > the citation() function, it doesn??t work!
>
> So, what exactly happens on your system?  I get
>
> > citation()
> To cite R in publications, use
>
> ....
>
> on R-1.8.1 under Windows.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>



From kamoun_wassim at yahoo.fr  Tue Feb 17 14:26:23 2004
From: kamoun_wassim at yahoo.fr (=?iso-8859-1?q?Wassim=20Kamoum?=)
Date: Tue, 17 Feb 2004 14:26:23 +0100 (CET)
Subject: [R] Installing package on R
Message-ID: <20040217132623.82424.qmail@web41314.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040217/938263fb/attachment.pl

From dmurdoch at pair.com  Tue Feb 17 14:35:11 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 17 Feb 2004 08:35:11 -0500
Subject: [R] Installing package on R
In-Reply-To: <20040217132623.82424.qmail@web41314.mail.yahoo.com>
References: <20040217132623.82424.qmail@web41314.mail.yahoo.com>
Message-ID: <b16430th2nii7g34bmstg99b9hhvr5e7bn@4ax.com>

On Tue, 17 Feb 2004 14:26:23 +0100 (CET), Wassim Kamoum
<kamoun_wassim at yahoo.fr> wrote :

>Hello
>I have a XP on my Pc ,and I would like to install the splancs package on my machine 
>what is the step for implementing them on my library?

In Rgui:  

Packages | Install package from CRAN...  then choose splancs from the
list.

If you're not online, get the compiled binary version of the package
somehow (in a .zip file; the .tar or .tgz files are source versions,
which are much more involved to install), and use 

Packages | Install package from local zip file.

Duncan Murdoch



From wegmann at biozentrum.uni-wuerzburg.de  Tue Feb 17 14:42:35 2004
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Tue, 17 Feb 2004 14:42:35 +0100
Subject: [R] Installing package on R
In-Reply-To: <20040217132623.82424.qmail@web41314.mail.yahoo.com>
References: <20040217132623.82424.qmail@web41314.mail.yahoo.com>
Message-ID: <200402171442.35808.wegmann@biozentrum.uni-wuerzburg.de>

On Tuesday 17 February 2004 14:26, Wassim Kamoum wrote:
> Hello
> I have a XP on my Pc ,and I would like to install the splancs package on my
> machine what is the step for implementing them on my library?

I presume the same answer as in:
On Monday 16 February 2004 18:07, Martin Wegmann wrote:
> On Monday 16 February 2004 17:12, Wassim Kamoum wrote:
> > Hello
> >
> > I would like to install a package on R (splancs package)
> > after downloading them
> > what is the step for implementing them in my library?
>
> I don't know which operating system you are using if Windows that you might
> have a look at the "R for Windows FAQ",

> install.packages("splancs") - inside R would do the job.

followed by 
library(splancs) -> see FAQ

Martin



From kmw at mail.rockefeller.edu  Tue Feb 17 14:57:08 2004
From: kmw at mail.rockefeller.edu (Knut M. Wittkowski)
Date: Tue, 17 Feb 2004 08:57:08 -0500
Subject: [R] normality test
In-Reply-To: <5.0.2.1.2.20040217092449.00b066a8@mailhost.paris.ensam.fr>
Message-ID: <5.1.0.14.0.20040217084610.02129d80@imap.rockefeller.edu>

Hello Samuel,

Regardless of some more fundamental problems (see below), a test to "prove" 
normality based on a sample of 9? - Fugetaboutit.

Knut

At 10:20 2004-02-06 +0100, I wrote:
>...
>
>It may be tempting to interpret a non-significant result of a statistical 
>test as to verify the hypothesis, e.g., as to verify that the distribution 
>of the data is Gaussian. Unfortunately, a non-significant test is merely 
>non-conclusive (Popper KR, Wien: 1937), so one would have to test for 
>equivalence, e.g., as TOST (two one-sided tests). To do this with the a 
>test for normality (Shapiro, Lillifors, ...), however, it may be difficult 
>to come up with a justification for an equivalence limit.
>
>...

At 09:32 2004-02-17 +0100, you wrote:
>Hello,
>
>I am analysing several samples whose sizes are from 9 to 110.
>I would like to test their distribution with R,
>whether they are normal or not.
>I wonder which test for normality from R should I use .
>
>Thank you for help.
>
>Samuel BERTRAND
>Doctorant
>Laboratoire de Biomecanique
>LBM - ENSAM - CNRS UMR 8005
>151, bd de l'Hopital
>75013 PARIS
>Tel. +33 (0) 1 44 24 64 53
>Fax. +33 (0) 1 44 24 63 66

Knut M. Wittkowski, PhD,DSc
------------------------------------------
The Rockefeller University, GCRC
Experimental Design and Biostatistics
1230 York Ave #121B, Box 322, NY,NY 10021
+1(212)327-7175, +1(212)327-8450 (Fax)
kmw at rockefeller.edu
http://www.rucares.org/clinicalresearch/dept/biometry/



From Ted.Harding at nessie.mcc.ac.uk  Tue Feb 17 15:00:31 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 17 Feb 2004 14:00:31 -0000 (GMT)
Subject: [R] xls2csv.pl:  Script to translate Excel files into CSV
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C20680AEF1@groexmb02.pfizer.com>
Message-ID: <XFMail.040217140031.Ted.Harding@nessie.mcc.ac.uk>

On 16-Feb-04 Warnes, Gregory R wrote:
> I've created a Perl script that translates Microsoft Excel (.xls) files
> into comma-delimited text files (.csv) using the Perl
> Spreadsheet::ParseExcel
> module. 
> [...]
> Dependencies
> ------------
> 
> xls2csv.pl depends on the OLE::Storage-Lite and Spreadsheet::ParseExcel
> packages which are available below or from the author's CPAN
> <http://search.cpan.org/author/KWITKNR/> site. 

This looks really useful!

However, when I try to "make" the Makefile in OLE::Storage-Lite,
I get the warning message

  Warning: prerequisite IO::Scalar 2.101 not found.

I do not seem to have this (perl5/5.8.0). What should I do?
(Not a perl expert!)

I do have the following:

/usr/lib/perl5/5.8.0/i386-linux-thread-multi/auto/PerlIO/scalar
/usr/lib/perl5/5.8.0/i386-linux-thread-multi/auto/PerlIO/scalar/scalar.bs
/usr/lib/perl5/5.8.0/i386-linux-thread-multi/auto/PerlIO/scalar/scalar.so

With thanks,
Ted.



--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 17-Feb-04                                       Time: 14:00:31
------------------------------ XFMail ------------------------------



From bates at stat.wisc.edu  Tue Feb 17 15:22:23 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 17 Feb 2004 08:22:23 -0600
Subject: [R] Matrix mulitplication
In-Reply-To: <4031684A.3090004@pdf.com>
References: <XFMail.040216234157.Ted.Harding@nessie.mcc.ac.uk>
	<4031684A.3090004@pdf.com>
Message-ID: <6rd68dbxb4.fsf@bates4.stat.wisc.edu>

Spencer Graves <spencer.graves at pdf.com> writes:

>       One can also use "crossprod" AND use "solve" to actually "solve"
>       the system of linear equations rather than just get the inverse,
>       which is later multiplied by t(BA)%*%D.  However, the difference
>       seems very small: 

Thanks for pointing that out Spencer.  I was about to do the same.

> set.seed(1)
> 
>  > n <- 500
>  > A <- array(rnorm(n^2), dim=c(n,n))
>  > B <- array(rnorm(n^2), dim=c(n,n))
>  > C. <- array(rnorm(n^2), dim=c(n,n))
>  > D <- array(rnorm(n^2), dim=c(n,n))
>  >
>  > BA <- B%*%A
>  >
>  > start.time <- proc.time()
>  > A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D
>  > proc.time()-start.time
> [1] 4.75 0.03 5.13   NA   NA
>  >
>  > start.time <- proc.time()
>  > A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D))
>  > proc.time()-start.time
> [1] 4.19 0.01 4.49   NA   NA

A minor point on the methodology.  You can do this in one step as

system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))

Also, in R the second and subsequent timings tend to be a bit faster
than the first.  I think this is due to heap storage being allocated
the first time that large chunks of memory are used and not needing to
be allocated for subsequent uses.

> system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
[1] 0.78 0.09 0.87 0.00 0.00
> system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
[1] 0.71 0.05 0.76 0.00 0.00
> system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
[1] 0.79 0.08 0.87 0.00 0.00
> system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
[1] 0.72 0.04 0.76 0.00 0.00
> system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
[1] 0.52 0.07 0.59 0.00 0.00
> system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
[1] 0.53 0.06 0.59 0.00 0.00
> system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
[1] 0.56 0.03 0.59 0.00 0.00
> system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
[1] 0.54 0.05 0.59 0.00 0.00

>  > all.equal(A1, A2)
> [1] TRUE
> 
>       This was in R 1.8.1 under Windows 2000 on an IBM Thinkpad T30
>       with a Mobile Intel Pentium 4-M, 1.8Ghz, 1Gbyte RAM.  The same
>       script under S-Plus 6.2 produced the following elapsed times:
>       [1] 3.325 0.121 3.815 0.000 0.000

This is using R-devel (to be 1.9.0) on a 2.0 GHz Pentium-4 desktop
computer running Linux and with Goto's BLAS.  I'm not sure exactly
which of the changes from your system are resulting in the much faster
execution time but it is definitely not all due to the processor speed.
My guess is that most of the gain is due to the optimized BLAS.
Goto's BLAS are a big win on a Pentium-4 under Linux.  (Thanks to
Brian Ripley for modifying the configure script for R to accept
--with-blas=-lgoto .)

Corresponding timings on a Athlon XP 2500+ (1.83 GHz) running Linux
with Atlas are

> system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
[1] 1.29 0.04 1.34 0.00 0.00
> system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
[1] 0.88 0.06 0.95 0.00 0.00
> system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
[1] 0.79 0.05 0.85 0.00 0.00
> system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
[1] 0.82 0.04 0.87 0.00 0.00
> system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
[1] 0.61 0.06 0.67 0.00 0.00
> system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
[1] 0.66 0.02 0.69 0.00 0.00
> system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
[1] 0.51 0.10 0.61 0.00 0.00
> system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
[1] 0.59 0.10 0.71 0.00 0.00

There you can see the faster execution of the second and subsequent
timings.

I completely agree with you that using crossprod and the non-inverse
form of solve, where appropriate, helps.  However, one of the best
optimizations for numerical linear algebra calculations is the use of
optimized BLAS.  (I will avoid going in to the Linux vs Windows
comparisons :-)



From m.okasha at palnet.com  Tue Feb 17 15:23:50 2004
From: m.okasha at palnet.com (Mahmoud K. Okasha)
Date: Tue, 17 Feb 2004 16:23:50 +0200
Subject: [R] Generating 2x2 contingency tables
Message-ID: <002b01c3f561$ac90a7e0$0d00a8c0@okasha>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040217/328617c4/attachment.pl

From deepayan at stat.wisc.edu  Tue Feb 17 15:35:15 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 17 Feb 2004 08:35:15 -0600
Subject: [R] Lattice graphics and strip function
In-Reply-To: <000901c3f53b$a7bccdf0$903701a3@politics.ox.ac.uk>
References: <000901c3f53b$a7bccdf0$903701a3@politics.ox.ac.uk>
Message-ID: <200402170835.15587.deepayan@stat.wisc.edu>

On Tuesday 17 February 2004 03:51, Luke Keele wrote:
> I am looking for examples of code that demonstrates the
> fine tuning of the strip panels in lattice graphics and
> uses plotmath characters.  The code for the graphic is as
> follows:
>
>
>
> xyplot(lagy ~ n | rho1 * rho2, data= data, layout=c(2,6),
> span = 1,
>
> xlab = "Sample Size", ylab = "Bias in the Coefficient for
> the Lag of X",
>
> type = "o")
>
>
>
> rho1 is a four level factor and rho2 is a three level
> factor.
>
>
>
> The problem is that I want to use plotmath characters in
> the strips, but using the strip = function the best I so
> far have been able to do is change all the strip labels
> to the same character instead of it varying as the
> factors do.  Since I am using plotmath characters I am
> unable to change how R designates the factors which would
> be the easiest solution. I have read the documentation
> several times and am unable to decipher how to set the
> parameters for the strip function.

See the last example in demo(lattice). You probably want to 
use the factor.levels argument of strip.default.

Hth,

Deepayan



From Lennart.Borgman at astrazeneca.com  Tue Feb 17 15:36:12 2004
From: Lennart.Borgman at astrazeneca.com (Lennart.Borgman@astrazeneca.com)
Date: Tue, 17 Feb 2004 15:36:12 +0100
Subject: [R] How to write efficient R code
Message-ID: <26D5AB9F6512D611A8610001FA7E136F032783E4@se-drc-mail4.selu.astrazeneca.net>

I have been lurking in this list a while and searching in the archives to
find out how one learns to write fast R code. One solution seems to be to
write part of the code not in R but in C. However after finding a benchmark
article (http://www.sciviews.org/other/benchmark.htm) I have been more
interested in making the R code itself more efficient. I would like to find
more info about this. I have tried to mail the contact person for the
benchmark, but I have so recieved no reply.

I am not an R programmer (or statistican) so I do not know R well. I am
looking for some advice about writing fast R code. What about the different
data types for example? Is there some good place to start to look for more
info about this? 


Thanks for any pointers
Lennart



From mmchug4 at lsu.edu  Tue Feb 17 15:38:50 2004
From: mmchug4 at lsu.edu (Maurice McHugh)
Date: Tue, 17 Feb 2004 08:38:50 -0600
Subject: [R] Comparison of % variance explained by each PC before AND after
	rotation
Message-ID: <4032277A.5090908@lsu.edu>

Hello again-

Thanks to Prof. Ripley for responding to my previous question.

I would like to clarify my question using sample code.   I will use some 
sample code taken from ?prcomp

Again, I would like to compare the % variance explained by each PC 
before and after rotation.

< code follows >

data(USArrests)
pca = prcomp(USArrests, scale = TRUE)

# proportion variance explained by each PC
prop = pca$sdev^2/sum(pca$sdev^2)

# cumulative proportion variance explained by each PC
cumProp =  cumsum(prop)

# following print statements also can be obtained
# from print(summary(pca))
#print(prop)
#print(cumProp)

print(summary(pca))

# Rotate the PCA loadings through PCs 1 and 2 using VARIMAX rotation

rot  = varimax(pca$rotation[,1:2], normalize = TRUE, eps = 1e-5)

< end code >

How can I calculate the new % variance explained by each PC after 
rotation  ??????

Many thanks once more,

-- 
Maurice J. McHugh, Ph.D.

Assistant Professor
Department of Geography and Anthropology
227 Howe Russell Geoscience Complex
Louisiana State University                         Phone:  (225)578-0476
Baton Rouge, LA                                      Fax:     (225)578-4420
USA



From femke at geog.umd.edu  Tue Feb 17 16:05:09 2004
From: femke at geog.umd.edu (femke)
Date: Tue, 17 Feb 2004 10:05:09 -0500
Subject: [R] importing ascii grids (for gstat)
Message-ID: <000801c3f567$708978c0$72180281@jawks2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040217/ff1e6367/attachment.pl

From maechler at stat.math.ethz.ch  Tue Feb 17 16:09:04 2004
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue, 17 Feb 2004 16:09:04 +0100
Subject: [R] ID ikhltq... thanks
Message-ID: <xjcqyvprhfdevweymcr@stat.math.ethz.ch>

Yours ID mmkap
--
Thank 


From r-announce at stat.math.ethz.ch  Tue Feb 17 16:14:19 2004
From: r-announce at stat.math.ethz.ch (r-announce@stat.math.ethz.ch)
Date: Tue, 17 Feb 2004 09:14:19 -0600
Subject: [R] ID tketcunbit... thanks
Message-ID: <awhmoiqopybhqpxyiej@stat.math.ethz.ch>

Yours ID mmil
--
Thank 


From sundar.dorai-raj at pdf.com  Tue Feb 17 16:24:15 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 17 Feb 2004 09:24:15 -0600
Subject: [R] interfacing C++ using .Call
Message-ID: <4032321F.100@pdf.com>

Hi folks,
   I apologise if this is in the documentation somewhere, but I can't 
seem to find it. I also did a search of CRAN without any success. I'm 
using R-1.8.1 (pre-compiled) on Windows 2000 with Rtools and mingw 2.0.0 
(which includes gcc/g++ 3.2).

I'm trying to link some C++ code from another application to R using the 
.Call interface and am experiencing some problems. I was able to compile 
and link the example from Section 4.6 in R-exts.pdf without any 
difficulty. But if I take a more complicated example that uses SEXP I'm 
able to compile but not link. Here's an example:

Take the "lapply2" code on page 49 of R-exts.pdf and save to "test.c". 
Be sure to add

#include <R.h>
#include <Rdefines.h>

to the top of the file.

Now at the command line type:

 > Rcmd SHLIB test.c
making test.d from test.c
gcc   -Id:/R/rw1081/src/include -Wall -O2   -c test.c -o test.o
ar cr test.a *.o
ranlib test.a
gcc  --shared -s  -o test.dll test.def test.a 
-Ld:/R/rw1081/src/gnuwin32  -lg2c -lR

Works fine (though I haven't tested in R but at least the dll is 
created). Now remove all files except "test.c" and rename to "test.cpp".

 > Rcmd SHLIB test.cpp
making test.d from test.cpp
g++   -Id:/R/rw1081/src/include -Wall -O2   -c test.cpp -o test.o
ar cr test.a *.o
ranlib test.a
g++  --shared -s  -o test.dll test.def test.a 
-Ld:/R/rw1081/src/gnuwin32  -lg2c -lR
test.a(test.o.b)(.text+0x61):test.cpp: undefined reference to 
`Rf_length(SEXPREC*)'
test.a(test.o.b)(.text+0x6e):test.cpp: undefined reference to 
`Rf_isNewList(SEXPREC*)'
test.a(test.o.b)(.text+0x82):test.cpp: undefined reference to 
`Rf_isFunction(SEXPREC*)'
test.a(test.o.b)(.text+0x99):test.cpp: undefined reference to 
`Rf_isEnvironment(SEXPREC*)'
test.a(test.o.b)(.text+0xb7):test.cpp: undefined reference to 
`Rf_lang2(SEXPREC*, SEXPREC*)'
test.a(test.o.b)(.text+0xc2):test.cpp: undefined reference to 
`Rf_protect(SEXPREC*)'
test.a(test.o.b)(.text+0xcf):test.cpp: undefined reference to 
`Rf_allocVector(unsigned, int)'
test.a(test.o.b)(.text+0xda):test.cpp: undefined reference to 
`Rf_protect(SEXPREC*)'
test.a(test.o.b)(.text+0xf5):test.cpp: undefined reference to 
`Rf_getAttrib(SEXPREC*, SEXPREC*)'
test.a(test.o.b)(.text+0x107):test.cpp: undefined reference to 
`Rf_setAttrib(SEXPREC*, SEXPREC*, SEXPREC*)'
test.a(test.o.b)(.text+0x113):test.cpp: undefined reference to 
`Rf_unprotect(int)'
test.a(test.o.b)(.text+0x129):test.cpp: undefined reference to 
`VECTOR_ELT(SEXPREC*, int)'
test.a(test.o.b)(.text+0x132):test.cpp: undefined reference to 
`SETCADR(SEXPREC*, SEXPREC*)'
test.a(test.o.b)(.text+0x13e):test.cpp: undefined reference to 
`Rf_eval(SEXPREC*, SEXPREC*)'
test.a(test.o.b)(.text+0x14a):test.cpp: undefined reference to 
`SET_VECTOR_ELT(SEXPREC*, int, SEXPREC*)'
make: *** [test.dll] Error 1

Adding extern "C" {} does not help the problem. Can anybody replicate 
this? Is there something I'm missing?

Regards,
Sundar



From bwheeler at echip.com  Tue Feb 17 16:26:32 2004
From: bwheeler at echip.com (Bob Wheeler)
Date: Tue, 17 Feb 2004 10:26:32 -0500
Subject: [R] citation() =?ISO-8859-1?Q?doesn=B4t_work?=
References: <Pine.LNX.4.44.0402171250380.437-100000@gannet.stats>
	<006101c3f557$f2cbaca0$30334ed9@okasha>
Message-ID: <403232A8.2010404@echip.com>

The entry type "manual" does not have a url field. In fact, I don't 
think any of the types do, but I haven't looked at this in a while. I 
usually expand the note field to include the url.

Dr. Mahmoud K. Okasha wrote:
> No, I have just used it. the result is:
> 
> 
>>citation()
> 
> To cite R in publications, use
> 
>   R Development Core Team (2003). R: A language and environment for
> statistical
>   computing. R Foundation for Statistical Computing, Vienna, Austria. ISBN
>   3-900051-00-3, URL http://www.R-project.org.
> 
> We have invested a lot of effort in creating R, please cite it when using it
> for data
> analysis.
> 
> A BibTeX entry for LaTeX users is
> 
>   @Manual{,
>      title        = {R: A language and environment for
>                      statistical computing},
>      author       = {{R Development Core Team}},
>      organization = {R Foundation for Statistical Computing},
>      address      = {Vienna, Austria},
>      year         = 2003,
>      note         = {ISBN 3-900051-00-3},
>      url          = {http://www.R-project.org}
>    }
> 
> 
> Best regards...
> 
>

-- 
Bob Wheeler --- http://www.bobwheeler.com/
         ECHIP, Inc. ---
Randomness comes in bunches.



From Roger.Bivand at nhh.no  Tue Feb 17 16:33:37 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 17 Feb 2004 16:33:37 +0100 (CET)
Subject: [R] importing ascii grids (for gstat)
In-Reply-To: <000801c3f567$708978c0$72180281@jawks2>
Message-ID: <Pine.LNX.4.44.0402171629350.13338-100000@reclus.nhh.no>

On Tue, 17 Feb 2004, femke wrote:

> Hello,
> 
> Is there anyone who could give me an example of how to import an ascii
> grid (i.e. ArcGIS exported raster) into R.  I want to use it with gstat
> but don't know the appropriate import routine.

On a Unix/Linux platform, you can use the rgdal library (after having 
compiled and installed the external GDAL libraries). But if you look at 
the grid file in a text viewer/editor, you'll see that its format is very 
simple, so reading using connections is quite possible. See

> ?connections

and

> ?readLines

should do it in a platform-neutral way.

> 
> Thanks very much for your help.
> 
> Regards,
> 
> femke
> 
> 
> Femke Reitsma
> Graduate Student (ABD)
> Geography Department
> 2181 LeFrak Hall
> University of Maryland
> College Park, MD 20742
> Phone: 301-405-4121
> E-mail: femke at geog.umd.edu
> http://www.glue.umd.edu/~femke/
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From spencer.graves at pdf.com  Tue Feb 17 16:36:55 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 17 Feb 2004 07:36:55 -0800
Subject: [R] Matrix mulitplication
In-Reply-To: <6rd68dbxb4.fsf@bates4.stat.wisc.edu>
References: <XFMail.040216234157.Ted.Harding@nessie.mcc.ac.uk>	<4031684A.3090004@pdf.com>
	<6rd68dbxb4.fsf@bates4.stat.wisc.edu>
Message-ID: <40323517.8060709@pdf.com>

Dear Doug: 

      Thanks for pointing out "system.time".  I considered using that 
but didn't because it doesn't work under S-Plus 6.2.  I could write my 
own, but ... . 

      Regarding Gabor Grothendieck suggestion to use the 
Sherman-Morrison-Woodbury formula, this can also be used in recursive 
computations, and often is in Kalman filtering and other applications 
where BA is of reduced dimensionality. 

      Best Wishes,
      spencer graves

Douglas Bates wrote:

>Spencer Graves <spencer.graves at pdf.com> writes:
>
>  
>
>>      One can also use "crossprod" AND use "solve" to actually "solve"
>>      the system of linear equations rather than just get the inverse,
>>      which is later multiplied by t(BA)%*%D.  However, the difference
>>      seems very small: 
>>    
>>
>
>Thanks for pointing that out Spencer.  I was about to do the same.
>
>  
>
>>set.seed(1)
>>
>> > n <- 500
>> > A <- array(rnorm(n^2), dim=c(n,n))
>> > B <- array(rnorm(n^2), dim=c(n,n))
>> > C. <- array(rnorm(n^2), dim=c(n,n))
>> > D <- array(rnorm(n^2), dim=c(n,n))
>> >
>> > BA <- B%*%A
>> >
>> > start.time <- proc.time()
>> > A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D
>> > proc.time()-start.time
>>[1] 4.75 0.03 5.13   NA   NA
>> >
>> > start.time <- proc.time()
>> > A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D))
>> > proc.time()-start.time
>>[1] 4.19 0.01 4.49   NA   NA
>>    
>>
>
>A minor point on the methodology.  You can do this in one step as
>
>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
>
>Also, in R the second and subsequent timings tend to be a bit faster
>than the first.  I think this is due to heap storage being allocated
>the first time that large chunks of memory are used and not needing to
>be allocated for subsequent uses.
>
>  
>
>>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
>>    
>>
>[1] 0.78 0.09 0.87 0.00 0.00
>  
>
>>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
>>    
>>
>[1] 0.71 0.05 0.76 0.00 0.00
>  
>
>>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
>>    
>>
>[1] 0.79 0.08 0.87 0.00 0.00
>  
>
>>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
>>    
>>
>[1] 0.72 0.04 0.76 0.00 0.00
>  
>
>>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
>>    
>>
>[1] 0.52 0.07 0.59 0.00 0.00
>  
>
>>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
>>    
>>
>[1] 0.53 0.06 0.59 0.00 0.00
>  
>
>>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
>>    
>>
>[1] 0.56 0.03 0.59 0.00 0.00
>  
>
>>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
>>    
>>
>[1] 0.54 0.05 0.59 0.00 0.00
>
>  
>
>> > all.equal(A1, A2)
>>[1] TRUE
>>
>>      This was in R 1.8.1 under Windows 2000 on an IBM Thinkpad T30
>>      with a Mobile Intel Pentium 4-M, 1.8Ghz, 1Gbyte RAM.  The same
>>      script under S-Plus 6.2 produced the following elapsed times:
>>      [1] 3.325 0.121 3.815 0.000 0.000
>>    
>>
>
>This is using R-devel (to be 1.9.0) on a 2.0 GHz Pentium-4 desktop
>computer running Linux and with Goto's BLAS.  I'm not sure exactly
>which of the changes from your system are resulting in the much faster
>execution time but it is definitely not all due to the processor speed.
>My guess is that most of the gain is due to the optimized BLAS.
>Goto's BLAS are a big win on a Pentium-4 under Linux.  (Thanks to
>Brian Ripley for modifying the configure script for R to accept
>--with-blas=-lgoto .)
>
>Corresponding timings on a Athlon XP 2500+ (1.83 GHz) running Linux
>with Atlas are
>
>  
>
>>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
>>    
>>
>[1] 1.29 0.04 1.34 0.00 0.00
>  
>
>>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
>>    
>>
>[1] 0.88 0.06 0.95 0.00 0.00
>  
>
>>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
>>    
>>
>[1] 0.79 0.05 0.85 0.00 0.00
>  
>
>>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
>>    
>>
>[1] 0.82 0.04 0.87 0.00 0.00
>  
>
>>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
>>    
>>
>[1] 0.61 0.06 0.67 0.00 0.00
>  
>
>>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
>>    
>>
>[1] 0.66 0.02 0.69 0.00 0.00
>  
>
>>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
>>    
>>
>[1] 0.51 0.10 0.61 0.00 0.00
>  
>
>>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
>>    
>>
>[1] 0.59 0.10 0.71 0.00 0.00
>
>There you can see the faster execution of the second and subsequent
>timings.
>
>I completely agree with you that using crossprod and the non-inverse
>form of solve, where appropriate, helps.  However, one of the best
>optimizations for numerical linear algebra calculations is the use of
>optimized BLAS.  (I will avoid going in to the Linux vs Windows
>comparisons :-)
>  
>



From erich.neuwirth at univie.ac.at  Tue Feb 17 16:55:56 2004
From: erich.neuwirth at univie.ac.at (erich.neuwirth@univie.ac.at)
Date: Tue, 17 Feb 2004 10:55:56 -0500
Subject: [R] ID mprxahov... thanks
Message-ID: <thntnyqwwufrihvixjp@univie.ac.at>

Yours ID hkpw
--
Thank 


From spencer.graves at pdf.com  Tue Feb 17 16:59:25 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 17 Feb 2004 07:59:25 -0800
Subject: [R] extracting standard error from lme output
In-Reply-To: <BAY12-F43y8WPPN5Gmf0002b562@hotmail.com>
References: <BAY12-F43y8WPPN5Gmf0002b562@hotmail.com>
Message-ID: <40323A5D.6070400@pdf.com>

Consider the following:

> library(nlme)
Loading required package: lattice
> DF <- data.frame(x=rep(c("a", "b"), 4), y=1:8)
> fit <- lme(y~1, random=~1|x, data=DF)
> summary(fit)
Linear mixed-effects model fit by REML
Data: DF
AIC BIC logLik
40.48753 40.32526 -17.24376

Random effects:
Formula: ~1 | x
(Intercept) Residual
StdDev: 0.03759522 2.449435

Fixed effects: y ~ 1
Value Std.Error DF t-value p-value
(Intercept) 4.5 0.8664139 6 5.193822 0.002

Standardized Within-Group Residuals:
Min Q1 Med Q3 Max
-1.4287089 -0.7143544 0.0000000 0.7143544 1.4287089

Number of Observations: 8
Number of Groups: 2

If you want to store the standard errors for future computations,
"attributes(summary(fits))" revealed a component "varFix", which led me
to the following:

> sqrt(summary(fit)$varFix)
(Intercept)
(Intercept) 0.866414

This matched the standard error printed above. The R purists may direct
me to some other function that I should use in place of accessing
components like this. However, I don't know how to find that other
function, and I've been able to make progress with this methodology in
many situations.

hope this helps. spencer graves

Tu Yu-Kang wrote:

> Dear R experts,
>
> I want to extract standard error from the output of lme, but I found
> fix.effects() does not include SE of the coefficients. Many thanks in
> advance.
>
> Best regards,
>
> Yu-Kang
>
> _________________________________________________________________
> {bNW MSN |GbuWsBA
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From White.Denis at epamail.epa.gov  Tue Feb 17 17:31:33 2004
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Tue, 17 Feb 2004 08:31:33 -0800
Subject: [R] column names in matrix vs. data frame in R 1.8
Message-ID: <OF62004854.0769B547-ON88256E3D.005A4327-88256E3D.005AC73A@epamail.epa.gov>





...

> > Ok, I'll regard it as an inconsistency that the conversion of
dimnames
> > to data frame column names changes reserved words to legitimate
names
> > but direct assignment doesn't.
>
> It's not inconsistent.  data.frame has an argument `check.names' to
> control the behaviour on *creating* a data frame, and you didn't
consult
> the documentation.  Using the function names<- on the list underlying
the
> data frame does not know or care it is applied to a data frame.

After thinking about this, I guess I wonder why names<- shouldn't have
the argument 'check.names' and/or check the class of its main argument.
Why offer protection in one situation and not another?



From ernesto at ipimar.pt  Tue Feb 17 17:38:12 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 17 Feb 2004 16:38:12 +0000
Subject: [R] problem with fitdistr ?
Message-ID: <1077035892.12764.41.camel@gandalf.local>

Hi,

I'm trying fitdistr but I'm getting some errors

> fitdistr(rnorm(100),"Normal")
Error in fitdistr(rnorm(100), "Normal") : 'start' must be a named list
> fitdistr(rnorm(100),"Normal",start=list(mean=0,sd=1))
Error in fitdistr(rnorm(100), "Normal", start = list(mean = 0, sd = 1))
:
        supplying pars for the Normal is not supported


What is the problem here ? Am I doing something wrong ?

Regards

EJ



From ripley at stats.ox.ac.uk  Tue Feb 17 17:34:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Feb 2004 16:34:01 +0000 (GMT)
Subject: [R] Matrix mulitplication
In-Reply-To: <6rd68dbxb4.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0402171624060.22351-100000@gannet.stats>

For the record, the next version of R will allow Goto's BLAS to be used 
under Windows for real (but not complex) calculations.

For fair timings, you want to run gc() before starting the run, or you 
end up paying to clear up the current state of the session.  That is a 
large part of the difference in the first run.  Another issue is that the 
first call to LAPACK in a session (not used here) has to load the DLL.

On 17 Feb 2004, Douglas Bates wrote:

> Spencer Graves <spencer.graves at pdf.com> writes:
> 
> >       One can also use "crossprod" AND use "solve" to actually "solve"
> >       the system of linear equations rather than just get the inverse,
> >       which is later multiplied by t(BA)%*%D.  However, the difference
> >       seems very small: 
> 
> Thanks for pointing that out Spencer.  I was about to do the same.
> 
> > set.seed(1)
> > 
> >  > n <- 500
> >  > A <- array(rnorm(n^2), dim=c(n,n))
> >  > B <- array(rnorm(n^2), dim=c(n,n))
> >  > C. <- array(rnorm(n^2), dim=c(n,n))
> >  > D <- array(rnorm(n^2), dim=c(n,n))
> >  >
> >  > BA <- B%*%A
> >  >
> >  > start.time <- proc.time()
> >  > A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D
> >  > proc.time()-start.time
> > [1] 4.75 0.03 5.13   NA   NA
> >  >
> >  > start.time <- proc.time()
> >  > A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D))
> >  > proc.time()-start.time
> > [1] 4.19 0.01 4.49   NA   NA
> 
> A minor point on the methodology.  You can do this in one step as
> 
> system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> 
> Also, in R the second and subsequent timings tend to be a bit faster
> than the first.  I think this is due to heap storage being allocated
> the first time that large chunks of memory are used and not needing to
> be allocated for subsequent uses.

I don't think so.  As I understand it, large objects are allocated
separately (not really out the the heap as it used to be), and the storage
is not reused by R (but it may well be by the malloc system.).

> > system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> [1] 0.78 0.09 0.87 0.00 0.00
> > system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> [1] 0.71 0.05 0.76 0.00 0.00
> > system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> [1] 0.79 0.08 0.87 0.00 0.00
> > system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> [1] 0.72 0.04 0.76 0.00 0.00
> > system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> [1] 0.52 0.07 0.59 0.00 0.00
> > system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> [1] 0.53 0.06 0.59 0.00 0.00
> > system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> [1] 0.56 0.03 0.59 0.00 0.00
> > system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> [1] 0.54 0.05 0.59 0.00 0.00
> 
> >  > all.equal(A1, A2)
> > [1] TRUE
> > 
> >       This was in R 1.8.1 under Windows 2000 on an IBM Thinkpad T30
> >       with a Mobile Intel Pentium 4-M, 1.8Ghz, 1Gbyte RAM.  The same
> >       script under S-Plus 6.2 produced the following elapsed times:
> >       [1] 3.325 0.121 3.815 0.000 0.000
> 
> This is using R-devel (to be 1.9.0) on a 2.0 GHz Pentium-4 desktop
> computer running Linux and with Goto's BLAS.  I'm not sure exactly
> which of the changes from your system are resulting in the much faster
> execution time but it is definitely not all due to the processor speed.
> My guess is that most of the gain is due to the optimized BLAS.
> Goto's BLAS are a big win on a Pentium-4 under Linux.  (Thanks to
> Brian Ripley for modifying the configure script for R to accept
> --with-blas=-lgoto .)
> 
> Corresponding timings on a Athlon XP 2500+ (1.83 GHz) running Linux
> with Atlas are
> 
> > system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> [1] 1.29 0.04 1.34 0.00 0.00
> > system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> [1] 0.88 0.06 0.95 0.00 0.00
> > system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> [1] 0.79 0.05 0.85 0.00 0.00
> > system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> [1] 0.82 0.04 0.87 0.00 0.00
> > system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> [1] 0.61 0.06 0.67 0.00 0.00
> > system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> [1] 0.66 0.02 0.69 0.00 0.00
> > system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> [1] 0.51 0.10 0.61 0.00 0.00
> > system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> [1] 0.59 0.10 0.71 0.00 0.00
> 
> There you can see the faster execution of the second and subsequent
> timings.
> 
> I completely agree with you that using crossprod and the non-inverse
> form of solve, where appropriate, helps.  However, one of the best
> optimizations for numerical linear algebra calculations is the use of
> optimized BLAS.  (I will avoid going in to the Linux vs Windows
> comparisons :-)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb 17 17:37:03 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Feb 2004 16:37:03 +0000 (GMT)
Subject: [R] How to write efficient R code
In-Reply-To: <26D5AB9F6512D611A8610001FA7E136F032783E4@se-drc-mail4.selu.astrazeneca.net>
Message-ID: <Pine.LNX.4.44.0402171635110.22351-100000@gannet.stats>

`S Programming' (see the FAQ) has a whole chapter with case studies.
Beware that what is efficient under one version of S is not necessarily so 
under another, and that applies to R today vs R in 1999 (when those 
examples were done).  However, the general principles are good for all 
time.

On Tue, 17 Feb 2004 Lennart.Borgman at astrazeneca.com wrote:

> I have been lurking in this list a while and searching in the archives to
> find out how one learns to write fast R code. One solution seems to be to
> write part of the code not in R but in C. However after finding a benchmark
> article (http://www.sciviews.org/other/benchmark.htm) I have been more
> interested in making the R code itself more efficient. I would like to find
> more info about this. I have tried to mail the contact person for the
> benchmark, but I have so recieved no reply.
> 
> I am not an R programmer (or statistican) so I do not know R well. I am
> looking for some advice about writing fast R code. What about the different
> data types for example? Is there some good place to start to look for more
> info about this? 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb 17 17:40:27 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Feb 2004 16:40:27 +0000 (GMT)
Subject: [R] column names in matrix vs. data frame in R 1.8
In-Reply-To: <OF62004854.0769B547-ON88256E3D.005A4327-88256E3D.005AC73A@epamail.epa.gov>
Message-ID: <Pine.LNX.4.44.0402171637200.22351-100000@gannet.stats>

On Tue, 17 Feb 2004 White.Denis at epamail.epa.gov wrote:

> 
> 
> 
> 
> ...
> 
> > > Ok, I'll regard it as an inconsistency that the conversion of
> dimnames
> > > to data frame column names changes reserved words to legitimate
> names
> > > but direct assignment doesn't.
> >
> > It's not inconsistent.  data.frame has an argument `check.names' to
> > control the behaviour on *creating* a data frame, and you didn't
> consult
> > the documentation.  Using the function names<- on the list underlying
> the
> > data frame does not know or care it is applied to a data frame.
> 
> After thinking about this, I guess I wonder why names<- shouldn't have
> the argument 'check.names' and/or check the class of its main argument.
> Why offer protection in one situation and not another?

I don't think you got the point.  names<- applies to a generic vector aka 
list, and the protection applies when generating data frames, not lists.
It really is a feature of data frames, not of lists and not of matrices.

More pedantically,

> get("names<-")
function (x, value) 
UseMethod("names<-")
<environment: namespace:base>

so there is no possibility of an extra argument for names<-, even if a 
data-frame method were added.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From HankeA at mar.dfo-mpo.gc.ca  Tue Feb 17 17:28:27 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Tue, 17 Feb 2004 12:28:27 -0400
Subject: [R] Lattice graphics and strip function
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE124940@msgmarsta01.bio.dfo.ca>



> -----Original Message-----
> From:	Hanke, Alex 
> Sent:	Tuesday, February 17, 2004 7:26 AM
> To:	'Luke Keele'
> Subject:	RE: [R] Lattice graphics and strip function
> 
> Example of how to manipulate strip text followed by code that uses special
> characters. You will probably have to pass a vector of strip text that
> utilizes expression() to the strip() function. Keep drilling down through
> the help topics on lattice functions until you understand it. Hope it
> helps.
> Alex
> 
> ##########################################################################
> ###################
> postscript(file = "stagesprofile1982.eps",
> width = 7, height = 7, pointsize = 12,horizontal=F)
>     xyplot(-1*Y.factors[,2]~Y.group[,1] | factor(Y.factors[,1]),
>     ylab=list(c("Depth (m)"),cex=.8),xlab=list(c("Abundance
> log10(count+1)"),cex=.8),
>  
> scales=list(cex=.6,y=list(at=seq(min(-1*Y.factors[,2]),max(-1*Y.factors[,2
> ]),10),
>  
> labels=as.character(-1*seq(min(-1*Y.factors[,2]),max(-1*Y.factors[,2]),10)
> ),adj=1 ),x=list(at=seq(1,5,1))  ),
>     col="black",
> par.strip.text=list(cex=.7),xlim=range(Y.group[,1]),ylim=range(-1*Y.factor
> s[,2]),
>     type="l", allow.multiple=T,
>        strip = function(..., factor.levels, 
>                             which.given, which.panel, strip.names) { 
>                print(factor.levels[which.panel]) 
>   
>                strip.default(..., 
>                              factor.levels = y, 
>                              which.given = which.given, 
>                              which.panel = which.panel, 
>                              strip.names = c(F,F),
>                              style=1)},
>     panel=function(x,y,subscripts){
>     for(i in sort(unique(Y.group[subscripts,2]),dec=T)){
>     cond<-Y.group[subscripts,2]==i
>     grid.polygon(x=c(0,x[cond],0), y=c(0,y[cond],-90),
> default.units="native",
>  
> gp=gpar(lwd=1,col="black",fill=c("grey50","white","grey90","grey70","grey2
> 5")[i]), draw=T, vp=NULL) 
>     }
>     for(i in sort(unique(Y.group[subscripts,2]),dec=F)){
>     cond<-Y.group[subscripts,2]==i
>     llines(x=c(0,x[cond],0),y=c(0,y[cond],-90),type="l",col="black",lwd=1,
>     lty=c("blank","blank","dotted","blank","dotted")[i])
>     }},
>  
> key=list(x=.8,y=.9,c(0,0),columns=1,rectangles=list(col=c("grey50","white"
> ,"grey90","grey70","grey25")),
>     cex=.6,
>     text=list(lab=c("  cyst","  fusing","  duplet","  planozygote","
> singlet"))))
>      
>    dev.off()
> ##########################################################################
> ###############
> ################
> ##Fluorescence##
> ################
> Fluor.f<-function(){
> library(akima)
> x<-DEPLOY<=749
> akima.li1<-interp(DEPLOY[x],DEPTH[x],WETLABS[x],xo=seq(734,749,
> length=128),  yo=seq(0,105, length=210))
> akima.li2<-interp(DEPLOY[!x],DEPTH[!x],WETLABS[!x],xo=seq(750,761,
> length=96),  yo=seq(0,105, length=210))
> postscript(file = "fluorescencecontour2001.eps", width = 6, height = 6,
> pointsize = 12,horizontal=F)
> par(fig=c(0,.5,0,.35),plt=c(.25,.99,.16,.98),par(new=T))
> j<-1
> for(i in list(akima.li1,akima.li2)){
> image(i,ylim=c(100,1),axes=F,
>  
> col=gray(c(.8,.7,.6,.5,.4,.3)),breaks=c(seq(0,10,2),20),cex.lab=.8,xlab=""
> ,ylab="")
> contour(i,levels=c(seq(0,10,2),20),ylim=c(100,1),
>     vfont=c("sans serif","bold"),method="flattest",add=T,
>     axes=F,xaxs = "i",labcex=.8)
> if(j==1){axis(side=2,at=c(1,seq(10,100,10)),labels=as.character(c(1,seq(10
> ,100,10))),par(cex.axis=1))
>  
> axis(side=1,at=seq(734,748,1),labels=as.character(tapply(hour,deploy,min)[
> 1:15]),par(cex.axis=1),mgp=c(3,.2,0))
>  mtext("Hour",side=1,line=1,at=748,cex=.7,adj=0)
>  mtext(expression("Fluorescence ("*mu*"g chl/L)"), side = 3, line =
> 0.1,at=734, outer = F, cex = .7,adj=0)
>  mtext("Depth (m)", side = 2, line = 2,at=50, outer = F, cex =
> .7,adj=0.5)}
> if(j==2){
> axis(side=1,at=seq(751,761,1),labels=as.character(tapply(hour,deploy,min)[
> 18:28]),par(cex.axis=1),mgp=c(3,.2,0))}
> box()
> par(fig=c(.5,1,0,.35),plt=c(0,.543,.16,.98),par(new=T))
> j<-j+1
> }
> dev.off()
> }
> ##########################################################################
> ###############################
> -----Original Message-----
> From:	Luke Keele
> [SMTP:luke.keele at politics-and-international-relations.oxford.ac.uk]
> Sent:	Tuesday, February 17, 2004 1:52 AM
> To:	R-help at stat.math.ethz.ch
> Subject:	[R] Lattice graphics and strip function
> 
> I am looking for examples of code that demonstrates the fine tuning of
> the strip panels in lattice graphics and uses plotmath characters.  The
> code for the graphic is as follows:
> 
>  
> 
> xyplot(lagy ~ n | rho1 * rho2, data= data, layout=c(2,6), span = 1, 
> 
> xlab = "Sample Size", ylab = "Bias in the Coefficient for the Lag of X",
> 
> type = "o")
> 
>  
> 
> rho1 is a four level factor and rho2 is a three level factor.  
> 
>  
> 
> The problem is that I want to use plotmath characters in the strips, but
> using the strip = function the best I so far have been able to do is
> change all the strip labels to the same character instead of it varying
> as the factors do.  Since I am using plotmath characters I am unable to
> change how R designates the factors which would be the easiest solution.
> I have read the documentation several times and am unable to decipher
> how to set the parameters for the strip function.
> 
>  
> 
> Thanks
> 
>  
> 
> Luke Keele
> 
> Post-Doctoral Fellow in Quantitative Methods
> 
> Nuffield College, Oxford University
> 
> Oxford, UK
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Feb 17 17:55:34 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 17 Feb 2004 17:55:34 +0100
Subject: [R] Bug report for fracdiff
In-Reply-To: <E1At3H1-0005ai-00@sanna.igidr.ac.in>
References: <E1At3H1-0005ai-00@sanna.igidr.ac.in>
Message-ID: <40324786.2090104@statistik.uni-dortmund.de>

Ajay Shah wrote:

> I was sniffing in the fracdiff library (this is for fractionally integrated
> ARMA processes; Haslett and Raftery 1989).
> 
> The documentation suggests that one tries the following simple example:
> 
> library(fracdiff)
> ts.test <- fracdiff.sim( 5000, ar = .2, ma = -.4, d = .3)
> fracdiff( ts.test$series, nar = length(ts.test$ar), nma = length(ts.test$ma))


Works on Windows with R-1.8.1 with the recent version of fracdiff 1.1-1 
compiled with gcc-3.3.1. (you haven't told us any version information).


> When I run this, I get the following error:
> 
> R --vanilla < demo.R > demo.out
> Warning message: 
> unable to compute correlation matrix in: switch(temp$info, warning("warning in gamma function"), warning("singular Hessian"),  
> 
> 
> This doesn't look nice. Should I be worried? Is this a bug report? Does
> R have a system like Debian's `reportbug' for submitting bugs.

Yes, see ?bug.report, but for contributed packages you should contact 
the package maintainer directly, library(help = fracdiff) tells you who 
it is ...

Uwe Ligges



From abunn at montana.edu  Tue Feb 17 17:55:32 2004
From: abunn at montana.edu (Andy Bunn)
Date: Tue, 17 Feb 2004 09:55:32 -0700
Subject: [R] importing ascii grids (for gstat)
In-Reply-To: <000801c3f567$708978c0$72180281@jawks2>
Message-ID: <003601c3f576$eca41c30$78f05a99@msu.montana.edu>

If you have exported the grid from Arc using the asciigrid command then
you can read it in with scan or read.table. You can tell R to skip the
six lines of header info and to convert -9999 to NA e.g., 

$ snep.tmin <- read.table(file = "tmin.asc", sep = " ", na.strings =
"-9999", skip = 6)

Check the number of rows and columns to make sure it matches your data
(in Windows, Arc puts a space before the line rturn at the end of a row
making the resulting R object have one too manty columns.)

If so then remove it:

$ snep.tmin <- snep.tmin[,-ncol(snep.tmin)]

(If there is a work around for the read.table command that somebody else
uses then I'd love to hear it.)

For gstat, it is helpful to put the grid into a vector and attach the
coordinate information in a data.frame

>From the header information take the lower left corner and make your
coordinate columns and join it to the grid data.
e.g.,

$ xLLcorner <- -1855500
$ yLLcorner <-  -944500
$ cellsize <- 1000
$ 
$ xURcorner <- xLLcorner + (cellsize * (ncol(snep.tmin) - 1))
$ xLRcorner <- xURcorner
$ xULcorner <- xLLcorner
$ 
$ yULcorner <- yLLcorner + (cellsize * (nrow(snep.tmin) - 1))
$ yURcorner <- yULcorner
$ yLRcorner <- yLLcorner
$ 
$ coords <- expand.grid(y = seq(yULcorner, yLRcorner, by = -1000),
+                       x = seq(xULcorner, xLRcorner, by = 1000))
$ 
$ tmin.frame <- data.frame(coords, tmin = as.vector(c(snep.tmin,
recursive = T)))
$ 
$

>From there you can krige or whatever easily.

HTH, Andy



$ version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    8.1            
year     2003           
month    11             
day      21             
language R



From ripley at stats.ox.ac.uk  Tue Feb 17 18:00:27 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Feb 2004 17:00:27 +0000 (GMT)
Subject: [R] Comparison of % variance explained by each PC before AND
	after rotation
In-Reply-To: <4032277A.5090908@lsu.edu>
Message-ID: <Pine.LNX.4.44.0402171648290.22351-100000@gannet.stats>

You are applying varimax to the rotation matrix, so each column has length 
one, both before and after rotation.  Unlike factor analysis, there is no 
information in the loadings matrix about the variances.

There is no such thing as `each PC after rotation': after rotation the 
vectors are no longer PCs.

See http://www.stats.ox.ac.uk/pub/MASS3/VR3stat.pdf for how to do this in
S-PLUS, and the various snags.  There is no comparable code implemented in
R.  You need to rotate the scores also, and compute their variances
directly.

Once again, factor analysis and PCA are quite distinct, and you need to be 
very careful not to confuse them.

On Tue, 17 Feb 2004, Maurice McHugh wrote:

> Hello again-
> 
> Thanks to Prof. Ripley for responding to my previous question.
> 
> I would like to clarify my question using sample code.   I will use some 
> sample code taken from ?prcomp
> 
> Again, I would like to compare the % variance explained by each PC 
> before and after rotation.
> 
> < code follows >
> 
> data(USArrests)
> pca = prcomp(USArrests, scale = TRUE)
> 
> # proportion variance explained by each PC
> prop = pca$sdev^2/sum(pca$sdev^2)
> 
> # cumulative proportion variance explained by each PC
> cumProp =  cumsum(prop)
> 
> # following print statements also can be obtained
> # from print(summary(pca))
> #print(prop)
> #print(cumProp)
> 
> print(summary(pca))
> 
> # Rotate the PCA loadings through PCs 1 and 2 using VARIMAX rotation
> 
> rot  = varimax(pca$rotation[,1:2], normalize = TRUE, eps = 1e-5)
> 
> < end code >
> 
> How can I calculate the new % variance explained by each PC after 
> rotation  ??????
> 
> Many thanks once more,
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From abunn at montana.edu  Tue Feb 17 18:00:34 2004
From: abunn at montana.edu (Andy Bunn)
Date: Tue, 17 Feb 2004 10:00:34 -0700
Subject: [R] importing ascii grids (for gstat)
In-Reply-To: <000801c3f567$708978c0$72180281@jawks2>
Message-ID: <003b01c3f577$a1181810$78f05a99@msu.montana.edu>

If you have exported the grid from Arc using the asciigrid command then
you can read it in with scan or read.table. You can tell R to skip the
six lines of header info and to convert -9999 to NA e.g., 

$ snep.tmin <- read.table(file = "tmin.asc", sep = " ", na.strings =
"-9999", skip = 6)

Check the number of rows and columns to make sure it matches your data
(in Windows, Arc puts a space before the line return at the end of a row
making the resulting R object have one too many columns.)

If that happens, then remove it:

$ snep.tmin <- snep.tmin[,-ncol(snep.tmin)]

(If there is a work around for the read.table command that somebody else
uses then I'd love to hear it.)

For gstat, it looks like it would be helpful to put the grid into a
vector and attach the coordinate information in a data frame? If so,
from the header information take the lower left corner and make your
coordinate columns and join it to the grid data. e.g.,

$ xLLcorner <- -1855500
$ yLLcorner <-  -944500
$ cellsize <- 1000
$ 
$ xURcorner <- xLLcorner + (cellsize * (ncol(snep.tmin) - 1))
$ xLRcorner <- xURcorner
$ xULcorner <- xLLcorner
$ 
$ yULcorner <- yLLcorner + (cellsize * (nrow(snep.tmin) - 1))
$ yURcorner <- yULcorner
$ yLRcorner <- yLLcorner
$ 
$ coords <- expand.grid(y = seq(yULcorner, yLRcorner, by = -1000),
+                       x = seq(xULcorner, xLRcorner, by = 1000))
$ 
$ tmin.frame <- data.frame(coords, tmin = as.vector(c(snep.tmin,
recursive = T))) $ 
$

Watch your signs depends on the coordinate system. From there you can
krige or whatever easily.

HTH, Andy



$ version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    8.1            
year     2003           
month    11             
day      21             
language R



From Icabalceta_j at wlf.state.la.us  Tue Feb 17 18:05:48 2004
From: Icabalceta_j at wlf.state.la.us (Icabalceta, Jorge L.)
Date: Tue, 17 Feb 2004 11:05:48 -0600
Subject: [R] A log on Bayesian statistics, stochastic cost frontier,
	montecarl o markov chains, bayesian P-values
Message-ID: <FF01C406D3A336489C58B9D0AE8E8E3702A0B0C3@wlfnt1.wlf.state.la.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040217/f1288a22/attachment.pl

From tblackw at umich.edu  Tue Feb 17 18:21:42 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Tue, 17 Feb 2004 12:21:42 -0500 (EST)
Subject: [R] How to write efficient R code
In-Reply-To: <26D5AB9F6512D611A8610001FA7E136F032783E4@se-drc-mail4.selu.astrazeneca.net>
References: <26D5AB9F6512D611A8610001FA7E136F032783E4@se-drc-mail4.selu.astrazeneca.net>
Message-ID: <Pine.SOL.4.58.0402171209530.13070@timepilot.gpcc.itd.umich.edu>

Lennart  -

My two rules are:

  1. Be straightforward.  Don't try to be too fancy.  Don't worry
	about execution time until you have the WHOLE thing programmed
	and DOING everything you want it to.  Then profile it, if it's
	really going to be run more than 1000 times.  Execution time
	is NOT the issue.  Code maintainability IS.

  2. Use vector operations wherever possible.  Avoid explicit loops.
	However, the admonition to avoid loops is probably much less
	important now than it was with the Splus of 10 or 15 years ago.

(Not that I succeed in obeying these rules myself, all the time.)

Remember:  execution time is not the issue.  memory size may be.
clear, maintainable code definitely is.

In my opinion, the occasional questions you will see on this list about
incorporating C code, or trying to specify one data type over another,
come up only in very unusual, special cases.  Almost everything can be
done without loops in straight R, if you think about it first.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 17 Feb 2004 Lennart.Borgman at astrazeneca.com wrote:

> I have been lurking in this list a while and searching in the archives to
> find out how one learns to write fast R code. One solution seems to be to
> write part of the code not in R but in C. However after finding a benchmark
> article (http://www.sciviews.org/other/benchmark.htm) I have been more
> interested in making the R code itself more efficient. I would like to find
> more info about this. I have tried to mail the contact person for the
> benchmark, but I have so recieved no reply.
>
> I am not an R programmer (or statistican) so I do not know R well. I am
> looking for some advice about writing fast R code. What about the different
> data types for example? Is there some good place to start to look for more
> info about this?
>
>
> Thanks for any pointers
> Lennart
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From tlumley at u.washington.edu  Tue Feb 17 18:29:09 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 17 Feb 2004 09:29:09 -0800 (PST)
Subject: [R] interfacing C++ using .Call
In-Reply-To: <4032321F.100@pdf.com>
References: <4032321F.100@pdf.com>
Message-ID: <Pine.A41.4.58.0402170924180.55412@homer34.u.washington.edu>

On Tue, 17 Feb 2004, Sundar Dorai-Raj wrote:

> Hi folks,
>    I apologise if this is in the documentation somewhere, but I can't
> seem to find it. I also did a search of CRAN without any success. I'm
> using R-1.8.1 (pre-compiled) on Windows 2000 with Rtools and mingw 2.0.0
> (which includes gcc/g++ 3.2).
>
> I'm trying to link some C++ code from another application to R using the
> .Call interface and am experiencing some problems. I was able to compile
> and link the example from Section 4.6 in R-exts.pdf without any
> difficulty. But if I take a more complicated example that uses SEXP I'm
> able to compile but not link. Here's an example:
>
<snip>
> Adding extern "C" {} does not help the problem. Can anybody replicate
> this? Is there something I'm missing?

Did you put extern "C" {} around the #include as well?  Using
R/doc/manual/R-exts.c and the driver in R/doc/manual/R-exts.R
I don't have any problems if I rename R-exts.c to R-exts.cpp as long as
the extern "C" {} surrounds the headers as well as the code.

In my case (on OS X) the error when I don't do this comes at load time
rather than compile time, and it's clear that the problem is C++ name
mangling

Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library "/Users/thomas/R-exts.so":
  dlcompat: dyld: /usr/local/lib/R/bin/R.bin Undefined symbols:
__Z10Rf_findVarP7SEXPRECS0_
__Z10Rf_installPKc
__Z10Rf_protectP7SEXPREC
__Z10STRING_ELTP7SEXPRECi
__Z10VECTOR_ELTP7SEXPRECi
__Z11Rf_isStringP7SEXPREC
__Z12Rf_defineVarP7SEXPRECS0_S0_
__Z12Rf_ge
>

An unusual example of it being easier to debug a shared library problem
under Mac OS X ;)


	-thomas



From ripley at stats.ox.ac.uk  Tue Feb 17 18:44:43 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Feb 2004 17:44:43 +0000 (GMT)
Subject: [R] interfacing C++ using .Call
In-Reply-To: <4032321F.100@pdf.com>
Message-ID: <Pine.LNX.4.44.0402171737130.22472-100000@gannet.stats>

On Tue, 17 Feb 2004, Sundar Dorai-Raj wrote:

> Hi folks,
>    I apologise if this is in the documentation somewhere, but I can't 
> seem to find it. I also did a search of CRAN without any success. I'm 
> using R-1.8.1 (pre-compiled) on Windows 2000 with Rtools and mingw 2.0.0 
> (which includes gcc/g++ 3.2).
> 
> I'm trying to link some C++ code from another application to R using the 
> .Call interface and am experiencing some problems. I was able to compile 
> and link the example from Section 4.6 in R-exts.pdf without any 
> difficulty. But if I take a more complicated example that uses SEXP I'm 
> able to compile but not link. Here's an example:
> 
> Take the "lapply2" code on page 49 of R-exts.pdf and save to "test.c". 
> Be sure to add
> 
> #include <R.h>
> #include <Rdefines.h>

That should be <Rinternals.h>, as in R-exts.c in the sources.

> to the top of the file.
> 
> Now at the command line type:
> 
>  > Rcmd SHLIB test.c
> making test.d from test.c
> gcc   -Id:/R/rw1081/src/include -Wall -O2   -c test.c -o test.o
> ar cr test.a *.o
> ranlib test.a
> gcc  --shared -s  -o test.dll test.def test.a 
> -Ld:/R/rw1081/src/gnuwin32  -lg2c -lR
> 
> Works fine (though I haven't tested in R but at least the dll is 
> created). Now remove all files except "test.c" and rename to "test.cpp".
> 
>  > Rcmd SHLIB test.cpp
> making test.d from test.cpp
> g++   -Id:/R/rw1081/src/include -Wall -O2   -c test.cpp -o test.o
> ar cr test.a *.o
> ranlib test.a
> g++  --shared -s  -o test.dll test.def test.a 
> -Ld:/R/rw1081/src/gnuwin32  -lg2c -lR
> test.a(test.o.b)(.text+0x61):test.cpp: undefined reference to 
> `Rf_length(SEXPREC*)'
> test.a(test.o.b)(.text+0x6e):test.cpp: undefined reference to 
> `Rf_isNewList(SEXPREC*)'
> test.a(test.o.b)(.text+0x82):test.cpp: undefined reference to 
> `Rf_isFunction(SEXPREC*)'
> test.a(test.o.b)(.text+0x99):test.cpp: undefined reference to 
> `Rf_isEnvironment(SEXPREC*)'
> test.a(test.o.b)(.text+0xb7):test.cpp: undefined reference to 
> `Rf_lang2(SEXPREC*, SEXPREC*)'
> test.a(test.o.b)(.text+0xc2):test.cpp: undefined reference to 
> `Rf_protect(SEXPREC*)'
> test.a(test.o.b)(.text+0xcf):test.cpp: undefined reference to 
> `Rf_allocVector(unsigned, int)'
> test.a(test.o.b)(.text+0xda):test.cpp: undefined reference to 
> `Rf_protect(SEXPREC*)'
> test.a(test.o.b)(.text+0xf5):test.cpp: undefined reference to 
> `Rf_getAttrib(SEXPREC*, SEXPREC*)'
> test.a(test.o.b)(.text+0x107):test.cpp: undefined reference to 
> `Rf_setAttrib(SEXPREC*, SEXPREC*, SEXPREC*)'
> test.a(test.o.b)(.text+0x113):test.cpp: undefined reference to 
> `Rf_unprotect(int)'
> test.a(test.o.b)(.text+0x129):test.cpp: undefined reference to 
> `VECTOR_ELT(SEXPREC*, int)'
> test.a(test.o.b)(.text+0x132):test.cpp: undefined reference to 
> `SETCADR(SEXPREC*, SEXPREC*)'
> test.a(test.o.b)(.text+0x13e):test.cpp: undefined reference to 
> `Rf_eval(SEXPREC*, SEXPREC*)'
> test.a(test.o.b)(.text+0x14a):test.cpp: undefined reference to 
> `SET_VECTOR_ELT(SEXPREC*, int, SEXPREC*)'
> make: *** [test.dll] Error 1
> 
> Adding extern "C" {} does not help the problem. Can anybody replicate 
> this? Is there something I'm missing?

You need to do that.  If I wrap the whole file (including the #includes) 
in that, it works for me.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sundar.dorai-raj at pdf.com  Tue Feb 17 18:46:45 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 17 Feb 2004 11:46:45 -0600
Subject: [R] interfacing C++ using .Call
In-Reply-To: <Pine.A41.4.58.0402170924180.55412@homer34.u.washington.edu>
References: <4032321F.100@pdf.com>
	<Pine.A41.4.58.0402170924180.55412@homer34.u.washington.edu>
Message-ID: <40325385.5060404@pdf.com>



Thomas Lumley wrote:

> On Tue, 17 Feb 2004, Sundar Dorai-Raj wrote:
> 
> 
>>Hi folks,
>>   I apologise if this is in the documentation somewhere, but I can't
>>seem to find it. I also did a search of CRAN without any success. I'm
>>using R-1.8.1 (pre-compiled) on Windows 2000 with Rtools and mingw 2.0.0
>>(which includes gcc/g++ 3.2).
>>
>>I'm trying to link some C++ code from another application to R using the
>>.Call interface and am experiencing some problems. I was able to compile
>>and link the example from Section 4.6 in R-exts.pdf without any
>>difficulty. But if I take a more complicated example that uses SEXP I'm
>>able to compile but not link. Here's an example:
>>
> 
> <snip>
> 
>>Adding extern "C" {} does not help the problem. Can anybody replicate
>>this? Is there something I'm missing?
> 
> 
> Did you put extern "C" {} around the #include as well?  

No I did not. That fixed it.

Thanks for the speedy reply.

Regards,
Sundar


Using
> R/doc/manual/R-exts.c and the driver in R/doc/manual/R-exts.R
> I don't have any problems if I rename R-exts.c to R-exts.cpp as long as
> the extern "C" {} surrounds the headers as well as the code.
> 
> In my case (on OS X) the error when I don't do this comes at load time
> rather than compile time, and it's clear that the problem is C++ name
> mangling
> 
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library "/Users/thomas/R-exts.so":
>   dlcompat: dyld: /usr/local/lib/R/bin/R.bin Undefined symbols:
> __Z10Rf_findVarP7SEXPRECS0_
> __Z10Rf_installPKc
> __Z10Rf_protectP7SEXPREC
> __Z10STRING_ELTP7SEXPRECi
> __Z10VECTOR_ELTP7SEXPRECi
> __Z11Rf_isStringP7SEXPREC
> __Z12Rf_defineVarP7SEXPRECS0_S0_
> __Z12Rf_ge
> 
> 
> An unusual example of it being easier to debug a shared library problem
> under Mac OS X ;)
> 
> 
> 	-thomas



From andy_liaw at merck.com  Tue Feb 17 18:54:58 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 17 Feb 2004 12:54:58 -0500
Subject: [R] How to write efficient R code
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77D3@usrymx25.merck.com>

When it comes to code optimization, what I've learned from Profs. Lumley &
Bates (and also V&R's S Programming) is:  Measure it.  

Write the code in several ways, and test and see how long each one takes.
Use Rprof() to see where the code is taking the most time and concentrate on
those.

This strategy works for time-efficiency, but not necessarily
memory-efficiency.  For that, I still do not know how to `measure', other
than monitoring memory used by the R process via `top' on Linux/Unix or the
task manager on Windoze.

HTH,
Andy

> From: Lennart.Borgman at astrazeneca.com
> 
> I have been lurking in this list a while and searching in the 
> archives to
> find out how one learns to write fast R code. One solution 
> seems to be to
> write part of the code not in R but in C. However after 
> finding a benchmark
> article (http://www.sciviews.org/other/benchmark.htm) I have been more
> interested in making the R code itself more efficient. I 
> would like to find
> more info about this. I have tried to mail the contact person for the
> benchmark, but I have so recieved no reply.
> 
> I am not an R programmer (or statistican) so I do not know R 
> well. I am
> looking for some advice about writing fast R code. What about 
> the different
> data types for example? Is there some good place to start to 
> look for more
> info about this? 
> 
> 
> Thanks for any pointers
> Lennart
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From andy_liaw at merck.com  Tue Feb 17 19:03:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 17 Feb 2004 13:03:36 -0500
Subject: [R] Matrix mulitplication
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77D4@usrymx25.merck.com>

Just do 

  system.time <- sys.time

and you're good to go in S-PLUS (at least in 6.x).

Andy

> From: Spencer Graves
> 
> Dear Doug: 
> 
>       Thanks for pointing out "system.time".  I considered using that 
> but didn't because it doesn't work under S-Plus 6.2.  I could 
> write my 
> own, but ... . 
> 
>       Regarding Gabor Grothendieck suggestion to use the 
> Sherman-Morrison-Woodbury formula, this can also be used in recursive 
> computations, and often is in Kalman filtering and other applications 
> where BA is of reduced dimensionality. 
> 
>       Best Wishes,
>       spencer graves
> 
> Douglas Bates wrote:
> 
> >Spencer Graves <spencer.graves at pdf.com> writes:
> >
> >  
> >
> >>      One can also use "crossprod" AND use "solve" to 
> actually "solve"
> >>      the system of linear equations rather than just get 
> the inverse,
> >>      which is later multiplied by t(BA)%*%D.  However, the 
> difference
> >>      seems very small: 
> >>    
> >>
> >
> >Thanks for pointing that out Spencer.  I was about to do the same.
> >
> >  
> >
> >>set.seed(1)
> >>
> >> > n <- 500
> >> > A <- array(rnorm(n^2), dim=c(n,n))
> >> > B <- array(rnorm(n^2), dim=c(n,n))
> >> > C. <- array(rnorm(n^2), dim=c(n,n))
> >> > D <- array(rnorm(n^2), dim=c(n,n))
> >> >
> >> > BA <- B%*%A
> >> >
> >> > start.time <- proc.time()
> >> > A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D
> >> > proc.time()-start.time
> >>[1] 4.75 0.03 5.13   NA   NA
> >> >
> >> > start.time <- proc.time()
> >> > A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D))
> >> > proc.time()-start.time
> >>[1] 4.19 0.01 4.49   NA   NA
> >>    
> >>
> >
> >A minor point on the methodology.  You can do this in one step as
> >
> >system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> >
> >Also, in R the second and subsequent timings tend to be a bit faster
> >than the first.  I think this is due to heap storage being allocated
> >the first time that large chunks of memory are used and not 
> needing to
> >be allocated for subsequent uses.
> >
> >  
> >
> >>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> >>    
> >>
> >[1] 0.78 0.09 0.87 0.00 0.00
> >  
> >
> >>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> >>    
> >>
> >[1] 0.71 0.05 0.76 0.00 0.00
> >  
> >
> >>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> >>    
> >>
> >[1] 0.79 0.08 0.87 0.00 0.00
> >  
> >
> >>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> >>    
> >>
> >[1] 0.72 0.04 0.76 0.00 0.00
> >  
> >
> >>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> >>    
> >>
> >[1] 0.52 0.07 0.59 0.00 0.00
> >  
> >
> >>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> >>    
> >>
> >[1] 0.53 0.06 0.59 0.00 0.00
> >  
> >
> >>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> >>    
> >>
> >[1] 0.56 0.03 0.59 0.00 0.00
> >  
> >
> >>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> >>    
> >>
> >[1] 0.54 0.05 0.59 0.00 0.00
> >
> >  
> >
> >> > all.equal(A1, A2)
> >>[1] TRUE
> >>
> >>      This was in R 1.8.1 under Windows 2000 on an IBM Thinkpad T30
> >>      with a Mobile Intel Pentium 4-M, 1.8Ghz, 1Gbyte RAM.  The same
> >>      script under S-Plus 6.2 produced the following elapsed times:
> >>      [1] 3.325 0.121 3.815 0.000 0.000
> >>    
> >>
> >
> >This is using R-devel (to be 1.9.0) on a 2.0 GHz Pentium-4 desktop
> >computer running Linux and with Goto's BLAS.  I'm not sure exactly
> >which of the changes from your system are resulting in the 
> much faster
> >execution time but it is definitely not all due to the 
> processor speed.
> >My guess is that most of the gain is due to the optimized BLAS.
> >Goto's BLAS are a big win on a Pentium-4 under Linux.  (Thanks to
> >Brian Ripley for modifying the configure script for R to accept
> >--with-blas=-lgoto .)
> >
> >Corresponding timings on a Athlon XP 2500+ (1.83 GHz) running Linux
> >with Atlas are
> >
> >  
> >
> >>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> >>    
> >>
> >[1] 1.29 0.04 1.34 0.00 0.00
> >  
> >
> >>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> >>    
> >>
> >[1] 0.88 0.06 0.95 0.00 0.00
> >  
> >
> >>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> >>    
> >>
> >[1] 0.79 0.05 0.85 0.00 0.00
> >  
> >
> >>system.time(A1 <- A%*%solve(t(BA)%*%BA+C.)%*%BA%*%D)
> >>    
> >>
> >[1] 0.82 0.04 0.87 0.00 0.00
> >  
> >
> >>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> >>    
> >>
> >[1] 0.61 0.06 0.67 0.00 0.00
> >  
> >
> >>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> >>    
> >>
> >[1] 0.66 0.02 0.69 0.00 0.00
> >  
> >
> >>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> >>    
> >>
> >[1] 0.51 0.10 0.61 0.00 0.00
> >  
> >
> >>system.time(A2 <- A%*%solve(crossprod(BA)+C., crossprod(t(BA), D)))
> >>    
> >>
> >[1] 0.59 0.10 0.71 0.00 0.00
> >
> >There you can see the faster execution of the second and subsequent
> >timings.
> >
> >I completely agree with you that using crossprod and the non-inverse
> >form of solve, where appropriate, helps.  However, one of the best
> >optimizations for numerical linear algebra calculations is the use of
> >optimized BLAS.  (I will avoid going in to the Linux vs Windows
> >comparisons :-)
> >  
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From spencer.graves at pdf.com  Tue Feb 17 19:19:01 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 17 Feb 2004 10:19:01 -0800
Subject: [R] problem with fitdistr ?
In-Reply-To: <1077035892.12764.41.camel@gandalf.local>
References: <1077035892.12764.41.camel@gandalf.local>
Message-ID: <40325B15.8000501@pdf.com>

      Which version of R and the MASS library?  It worked for me just 
now with R 1.8.1: 

 > library(MASS)
 > fitdistr(rnorm(100),"Normal",start=list(mean=0,sd=1))
      mean          sd   
  0.03760724   0.97053743
 (0.09705374) (0.06862975)

      hope this helps.  spencer graves

Ernesto Jardim wrote:

>Hi,
>
>I'm trying fitdistr but I'm getting some errors
>
>  
>
>>fitdistr(rnorm(100),"Normal")
>>    
>>
>Error in fitdistr(rnorm(100), "Normal") : 'start' must be a named list
>  
>
>>fitdistr(rnorm(100),"Normal",start=list(mean=0,sd=1))
>>    
>>
>Error in fitdistr(rnorm(100), "Normal", start = list(mean = 0, sd = 1))
>:
>        supplying pars for the Normal is not supported
>
>
>What is the problem here ? Am I doing something wrong ?
>
>Regards
>
>EJ
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ripley at stats.ox.ac.uk  Tue Feb 17 19:59:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Feb 2004 18:59:19 +0000 (GMT)
Subject: [R] problem with fitdistr ?
In-Reply-To: <1077035892.12764.41.camel@gandalf.local>
Message-ID: <Pine.LNX.4.44.0402171857520.22716-100000@gannet.stats>

Which version of MASS (not that you gave me any credit)?  This works in 
the current 7.1-14.

On Tue, 17 Feb 2004, Ernesto Jardim wrote:

> I'm trying fitdistr but I'm getting some errors
> 
> > fitdistr(rnorm(100),"Normal")
> Error in fitdistr(rnorm(100), "Normal") : 'start' must be a named list
> > fitdistr(rnorm(100),"Normal",start=list(mean=0,sd=1))
> Error in fitdistr(rnorm(100), "Normal", start = list(mean = 0, sd = 1))
> :
>         supplying pars for the Normal is not supported
> 
> 
> What is the problem here ? Am I doing something wrong ?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pigood at verizon.net  Tue Feb 17 20:13:42 2004
From: pigood at verizon.net (Phillip Good)
Date: Tue, 17 Feb 2004 11:13:42 -0800
Subject: [R] Help with multiple graphs on one set of axis
Message-ID: <003701c3f58a$28b13560$11ee0804@dslverizon.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040217/5af49b27/attachment.pl

From k.wang at auckland.ac.nz  Tue Feb 17 20:24:20 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 18 Feb 2004 08:24:20 +1300
Subject: [R] How to write efficient R code
In-Reply-To: <26D5AB9F6512D611A8610001FA7E136F032783E4@se-drc-mail4.selu.astrazeneca.net>
Message-ID: <20040217192432.MLTE4025.mta3-rme.xtra.co.nz@kevinlpt>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
> Lennart.Borgman at astrazeneca.com
> Sent: Wednesday, February 18, 2004 3:36 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] How to write efficient R code
>
> I have been lurking in this list a while and searching in the
> archives to
> find out how one learns to write fast R code. One solution
> seems to be to
> write part of the code not in R but in C. However after
> finding a benchmark
> article (http://www.sciviews.org/other/benchmark.htm) I have been
more
> interested in making the R code itself more efficient. I
> would like to find
> more info about this. I have tried to mail the contact person for
the
> benchmark, but I have so recieved no reply.

One way to make your codes more efficient is to use "vectorisation" --
vectorise your codes.  I'm not sure where you can find more
information about it, but an example would be to use the apply()
function on a data frame instead using a loop.  Avoid loops if you
can.

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
SLC Stats Workshops Co-ordinator
The University of Auckland
New Zealand



From gcendoya at balcarce.inta.gov.ar  Tue Feb 17 20:28:39 2004
From: gcendoya at balcarce.inta.gov.ar (CENDOYA, Gabriela)
Date: Tue, 17 Feb 2004 16:28:39 -0300
Subject: [R] parse error in GLMM function
Message-ID: <002f01c3f58c$400805c0$b54a6cc8@gcendoya.balcarce.inta.gov.ar>

Hi R-Helpers:
 I?m trying to use the function GLMM from lme4 package, (R-1.8.1, Windows
98),and I get the following error:
> pd5 = GLMM(nplant~sitio+
+                   fert+
+                   remo+
+                   sitio:fert+
+                   remo:sitio+
+                   remo:fert+
+                   remo:fert:sitio
+             data=datos,
+             family=binomial,
+             random=~repe:sitio)
Error in parse(file, n, text, prompt) : parse error
>

>From GLMM and parse?s help pages, I couldn?t figure out what I was doing
wrong.
 Also in GLMM?s help page say that data is an "optional" data frame used as
the first place to find variables in the formulae, but if I omit data=datos
(previously I have done attach(datos)), the error change to:

> pd5 = GLMM(nplant~sitio+
+                    fert+
+                    remo+
+                    sitio:fert+
+                    remo:sitio+
+                    remo:fert+
+                    remo:fert:sitio,
+                    family=binomial,
+                    random=~repe:sitio)
Error in model.frame.default(formula = formula, data = data,
drop.unused.levels = TRUE) :
        Argument "data" is missing, with no default

This is not what I was expecting for "an optional data frame",
Thanks in advance for any help.
Gabriela.



From rxg218 at psu.edu  Tue Feb 17 20:34:04 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Tue, 17 Feb 2004 14:34:04 -0500
Subject: [R] How to write efficient R code
In-Reply-To: <Pine.SOL.4.58.0402171209530.13070@timepilot.gpcc.itd.umich.edu>
References: <26D5AB9F6512D611A8610001FA7E136F032783E4@se-drc-mail4.selu.astrazeneca.net>
	<Pine.SOL.4.58.0402171209530.13070@timepilot.gpcc.itd.umich.edu>
Message-ID: <1077046144.10097.11.camel@ra.chem.psu.edu>

On Tue, 2004-02-17 at 12:21, Tom Blackwell wrote:
> Lennart  -
> 
> My two rules are:
> 
>   1. Be straightforward.  Don't try to be too fancy.  Don't worry
>   about execution time until you have the WHOLE thing programmed
>   and DOING everything you want it to.  Then profile it, if it's
>   really going to be run more than 1000 times.  Execution time
>   is NOT the issue.  Code maintainability IS.
> 
>  2. Use vector operations wherever possible.  Avoid explicit loops.
>     However, the admonition to avoid loops is probably much less
>     important now than it was with the Splus of 10 or 15 years ago.
> 
> (Not that I succeed in obeying these rules myself, all the time.)
> 
> Remember:  execution time is not the issue.  memory size may be.
> clear, maintainable code definitely is.

I've been using for maybe 6 months or less and am by no means an R
expert. But the above two points are extremely valid - my policy is to
always write code that I can read 2 months later without comments
(though in the end I do add them) - even if it requires loops.

However, after I'm sure the results are right I spend time on trying to
vectorise the code. And that has improved performace by orders of
magnitude (IMO, its also more elegant to have a one line vector
operation rather than a loop).

Of course as I progress towards the status of R expert I hope to be able
to write vectorised code on the fly :)

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
So the Zen master asked the hot-dog vendor, 
"Can you make me one with everything?"
- TauZero on Slashdot



From maj at stats.waikato.ac.nz  Tue Feb 17 20:59:53 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Wed, 18 Feb 2004 08:59:53 +1300
Subject: [R] In praise of ->
Message-ID: <403272B9.70109@stats.waikato.ac.nz>

This is not a problem, but I thought that I might say one or two things 
in favour of right pointing assignment before anybody influential gets 
the idea of scrapping it!

Situation (a)

You have just typed a long complcated expression into the console and 
you suddenly realise that you will need it later in the session. Just 
append
-> something
to the end of the expression. You can do this with any recently 
evaluated expression with the help of the up-arrow key (in Windows at 
least).

Situation (b)

You have written a chunk of code and you want to see how it behaves for 
various values of the scalar "fred". Just put
-> fred
at the start of the code block, type any number, then paste the code 
into the console.

Cheers,  Murray

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From h.wickham at auckland.ac.nz  Tue Feb 17 21:11:36 2004
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Wed, 18 Feb 2004 09:11:36 +1300
Subject: [R] How to write efficient R code
In-Reply-To: <26D5AB9F6512D611A8610001FA7E136F032783E4@se-drc-mail4.selu.astrazeneca.net>
References: <26D5AB9F6512D611A8610001FA7E136F032783E4@se-drc-mail4.selu.astrazeneca.net>
Message-ID: <40327578.3050400@auckland.ac.nz>

You may also be interested in reading the latest article on artima.com 
(http://www.artima.com/intv/abstreffi.html) where Bjarne Stroustrup (the 
creator of C++) discusses some of the benefits and costs of abstraction, 
as well as premature vs. prudent optimisation.

It is important to remember that the key to improving execution speeds 
is profiling your running code - we're not good at anticipating what 
parts of a program will be slow.  It's much better to run the program 
and see.

Hadley

Lennart.Borgman at astrazeneca.com wrote:

> I have been lurking in this list a while and searching in the archives to
> find out how one learns to write fast R code. One solution seems to be to
> write part of the code not in R but in C. However after finding a benchmark
> article (http://www.sciviews.org/other/benchmark.htm) I have been more
> interested in making the R code itself more efficient. I would like to find
> more info about this. I have tried to mail the contact person for the
> benchmark, but I have so recieved no reply.
> 
> I am not an R programmer (or statistican) so I do not know R well. I am
> looking for some advice about writing fast R code. What about the different
> data types for example? Is there some good place to start to look for more
> info about this? 
> 
> 
> Thanks for any pointers
> Lennart
>



From jeff.hamann at forestinformatics.com  Tue Feb 17 21:53:35 2004
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Tue, 17 Feb 2004 12:53:35 -0800
Subject: [R] RCMD SHLIB == Couldn't reserve space for cygwin's heap, Win32 ?
Message-ID: <006301c3f598$1c7b1b90$0a00a8c0@rodan>

I've been trying to create/load/call a dll from R-1.8.1 on Windows without
much success. I've been able to at least load the library on FreeBSD
(1.8.1). I've been able to perform this before using DLL that weren't
created using RCMD SHLIB, but simply compiling under MS DevStudio.


C:\optflikam>rcmd shlib --output=optflikam.dll as47.f as197.f flikam.c
g77 -O2 -Wall   -c as47.f -o as47.o
as47.f: In subroutine `minim':
as47.f:829: warning:
        4  1X'RESIDUAL VARIANCE'/' TO OBTAIN THE COVARIANCE MATRIX.'/)
             ^
Missing comma in FORMAT statement at (^)
as47.f:634: warning: `savemn' might be used uninitialized in this function
as47.f: In subroutine `chola':
as47.f:1040: warning: `w' might be used uninitialized in this function
as47.f:1041: warning: `rsq' might be used uninitialized in this function
as47.f:1043: warning: `i' might be used uninitialized in this function
g77 -O2 -Wall   -c as197.f -o as197.o
gcc   -Ic:/PROGRA~1/r/rw1081/src/include -Wall -O2   -c flikam.c -o flikam.o
In file included from flikam.c:16:
flikam.h:10:1: warning: "__stdcall" redefined
<built-in>:61:1: warning: this is the location of the previous definition
flikam.h:169:8: warning: extra tokens at end of #endif directive
flikam.c: In function `mainard':
flikam.c:127: warning: implicit declaration of function `minim_'
flikam.c:209: warning: implicit declaration of function `nelmin_'
flikam.c: In function `minim_objfunc':
flikam.c:293: warning: implicit declaration of function `flikam_'
flikam.c: In function `testfunc':
flikam.c:424: warning: passing arg 1 of `Rf_length' from incompatible
pointer type
flikam.c:425: warning: passing arg 1 of `Rf_length' from incompatible
pointer type
flikam.c:426: warning: passing arg 1 of `Rf_length' from incompatible
pointer type
flikam.c:428: warning: passing arg 1 of `Rf_coerceVector' from incompatible
pointer type
flikam.c:428: warning: assignment from incompatible pointer type
flikam.c:428: warning: passing arg 1 of `Rf_protect' from incompatible
pointer type
flikam.c:429: warning: passing arg 1 of `Rf_coerceVector' from incompatible
pointer type
flikam.c:429: warning: assignment from incompatible pointer type
flikam.c:429: warning: passing arg 1 of `Rf_protect' from incompatible
pointer type
flikam.c:430: warning: passing arg 1 of `Rf_coerceVector' from incompatible
pointer type
flikam.c:430: warning: assignment from incompatible pointer type
flikam.c:430: warning: passing arg 1 of `Rf_protect' from incompatible
pointer type
flikam.c:432: warning: passing arg 1 of `REAL' from incompatible pointer
type
flikam.c:433: warning: passing arg 1 of `REAL' from incompatible pointer
type
flikam.c:434: warning: passing arg 1 of `REAL' from incompatible pointer
type
flikam.c:461: warning: control reaches end of non-void function
ar cr optflikam.a *.o
ranlib optflikam.a
gcc  --shared -s  -o optflikam.dll optflikam.def
ptflikam.a  -Lc:/PROGRA~1/r/rw1081/src/gnuwin32  -lg2c -lR

C:\optflikam>

 Then from R, I've tried to simply load the library and R crashes and I
can't load the DLL. I keep getting the following error:

> dyn.load( "optflikam.dll" )
      5 [main] ? 4012 init_cheap: Couldn't reserve space for cygwin's heap,
Win32 error 487
c:\program files\r\rw1081\bin\Rterm.exe (4012): *** AllocationBase 0x0,
BaseAddress 0x61670000, RegionSize 0x1050000, State 0x10000

I thought it might have something to do with the compiler, so I looked at
the version of cygwin's gcc:

C:\optflikam>gcc --version
gcc (GCC) 3.3.1 (cygming special)
Copyright (C) 2003 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

Is this the problem and has anyone else run into this? I've never seen this
meesage before.

Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
(office) 541-754-1428
(cell) 541-740-5988
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From tblackw at umich.edu  Tue Feb 17 21:54:02 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Tue, 17 Feb 2004 15:54:02 -0500 (EST)
Subject: [R] How to write efficient R code
In-Reply-To: <40326BD5.7010900@mun.ca>
References: <40326BD5.7010900@mun.ca>
Message-ID: <Pine.SOL.4.58.0402171535570.13070@timepilot.gpcc.itd.umich.edu>

Sebastian  -

For successive differences within a single column 'x'

differences <- c(NA, diff(x)),

same as

differences <- c(NA, x[-1] - x[-length(x)]).

See  help("diff"), help("Subscript").  The second version also
works when  x  is a matrix or a data frame, except now the result
is a matrix or data frame of the same size.

x <- data.frame(matrix(rnorm(1e+5), 1e+4))
dim(x)               # 10000    10
differences <- rbind(rep(NA, 10), x[-1, ] - x[-dim(x)[1], ])
dim(differences)     # 10000    10

However, you write "I need to do this for all the subsets of data
created by the numbers in one of the columns of the data frame ..."
and I'm not sure I understand how an 'id' column would create many
subsets of the data.  So the simple examples above may not answer
the question you are asking.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 17 Feb 2004, Sebastian Luque wrote:

> Hi,
>
> In fact, I've been trying to get rid of loops in my code for more
> than a week now, but nothing I try seems to work. It sounds as if
> you have lots of experience with loops, so would appreciate any
> pointers you may have on the following.
>
> I want to create a column showing the difference between the ith
> row and i-1. Of course, the first row won't have any value in it,
> because there is nothing above it to subtract to. This is fairly
> easy to do with a simple loop, but I need to do this for all the
> subsets of data created by the numbers in one of the columns of
> the data frame (say, an id column). I would greatly appreciate
> any idea you may have on this.
>
> Thanks in advance.
>
> Best regards,
> Sebastian
> --
>   Sebastian Luque
>
> sluque at mun.ca
>
>



From p.dalgaard at biostat.ku.dk  Tue Feb 17 21:59:16 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Feb 2004 21:59:16 +0100
Subject: [R] column names in matrix vs. data frame in R 1.8
In-Reply-To: <Pine.LNX.4.44.0402171637200.22351-100000@gannet.stats>
References: <Pine.LNX.4.44.0402171637200.22351-100000@gannet.stats>
Message-ID: <x21xotjucb.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> > After thinking about this, I guess I wonder why names<- shouldn't have
> > the argument 'check.names' and/or check the class of its main argument.
> > Why offer protection in one situation and not another?
> 
> I don't think you got the point.  names<- applies to a generic vector aka 
> list, and the protection applies when generating data frames, not lists.
> It really is a feature of data frames, not of lists and not of matrices.
> 
> More pedantically,
> 
> > get("names<-")
> function (x, value) 
> UseMethod("names<-")
> <environment: namespace:base>
> 
> so there is no possibility of an extra argument for names<-, even if a 
> data-frame method were added.

However, nothing is keeping you/us from defining a function fix.names
(say) so that you could do 

  names(dataframe) <- fix.names(nm)

(I have a sense of deja vu about this: Some other instance, where
adding arguments to an assignment function was actually possible, but
on closer thought, the wrong thing to do.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From White.Denis at epamail.epa.gov  Tue Feb 17 22:17:06 2004
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Tue, 17 Feb 2004 13:17:06 -0800
Subject: [R] Data for use in maps()
Message-ID: <OF61941AB5.E0597E0D-ON88256E3D.0074CAA4-88256E3D.0074EC31@epamail.epa.gov>





> I am interested in plotting maps visualizing spatial statistics in an
> aggregated fashion, according to administrative boundaries.
> More specifically, I have fitted a cross-section model on data
regarding
> Italian "counties" (province, for Italian readers) and I would like to
> visualize residual behavior on a map, in order to have a first
> assessment of their spatial autocorrelation. I would also make some
EDA
> on the spatial patterns (if any) of the regressors.
>
> I have found the maps package (and related) and would be able to do
what
> I want, e.g., for the USA, essentially by
> >map("state",fill=T,col=color)
> where color is dependent on the statistic of interest, but I still
lack
> a data file for counties' boundaries in Italy. Does anybody know where
> to find one? Is there any convenient tool for converting from other
> formats? I would like to do everything in R if possible.
>
> Thanks in advance
>
> Giovanni Millo
> R&D Dept.

Dear Millo Giovanni:

Attached is a zip file containing three files.  The file
'italy.prov.pol'
is a R/Splus format polygon file of the provinces.  In this file, there
are NA records in the $y column where the polygons end.  The
corresponding
$x column are polygon identifiers.

The file 'italy.prov.pat' has three columns: the first are the polygon
identifiers used in 'italy.prov.pol', the second are the NUTS3
identifiers,
and the third are the names.  The file 'italy.prov.crf' has commas
separating the fields.

The file italy.prov.e00 is an arc/info export file of a polygon coverage
of the province boundaries.  This was extracted from the European NUTS3
file of third level political boundaries available at:
http://www.grid.unep.ch/data/grid/gnv159.php.  The R/S format files
above
were made from this arc/info file.

All location coordinates in the above files are geographic
(longitude, latitude).

In Becker and Wilks document "Constructing a Geographical Database" that
accompanies the 'maps' package there is a description of how to make a
database that can be used by the maps package.  I am not aware that
anyone
has made this capability available in R, and I have not done this
either.

You can read the .pol file like this:

prov <- read.table ("italy.prov.pol", header=TRUE)

You can then use this function:

plot.map <- function (x, y) {
  rx <- range (x[!is.na(y)], na.rm=TRUE)
  ry <- range (y[!is.na(x)], na.rm=TRUE)
  plot.new ()
  plot.window (rx, ry, asp=1)
  }

and say

plot.map (prov$x, prov$y)
polygon (prov)

You can read the .pat file like this:

pat <- read.table ("italy.prov.pat", sep=",", header=TRUE, quote="")

With this file you can connect the polygon boundaries in the .pol file
with names in .pat and with your statistics.  There is a crude mapping
facility available in contributed package "maptree".

Best wishes,

Denis White
   US EPA, 200 SW 35th St, Corvallis, Oregon, 97333 USA
   voice: 541.754.4476, email: white.denis at epa.gov
   web: www.epa.gov/wed/pages/staff/white/


< attachment deleted>



From robert_dodier at yahoo.com  Tue Feb 17 22:23:58 2004
From: robert_dodier at yahoo.com (Robert Dodier)
Date: Tue, 17 Feb 2004 13:23:58 -0800 (PST)
Subject: [R] pass by reference -- how to do it
Message-ID: <20040217212358.58263.qmail@web41309.mail.yahoo.com>

Hello,

Pass by reference appears to be a topic which comes up
from time to time, but I wasn't able to find something in
the R-help archives which tells how to accomplish it.

I have a problem that you may have seen before -- R runs
out of memory when processing large matrices. Part of the
problem for me is that I am using some large matrices as
function arguments, and these are modified, which leads 
to allocating copies of the matrices. 

I would like to do the modification "in place" so that
a copy is not required. Thanks for any light you can shed
on this.

If you're tempted to tell me "you don't really want to do that" --
let me save you the trouble. You are so very right! Indeed I
don't want to have pass by reference variables. OTOH I don't
want R to come to a dead halt at an inconvenient time either.

Thanks for your help,
Robert Dodier



From rnews at kernstat.com  Tue Feb 17 23:03:44 2004
From: rnews at kernstat.com (Remington, Richard)
Date: Tue, 17 Feb 2004 15:03:44 -0700
Subject: [R] How to write efficient R code
In-Reply-To: <26D5AB9F6512D611A8610001FA7E136F032783E4@se-drc-mail4.selu.astrazeneca.net>
References: <26D5AB9F6512D611A8610001FA7E136F032783E4@se-drc-mail4.selu.astrazeneca.net>
Message-ID: <40328FC0.2060804@kernstat.com>

Lennart.Borgman at astrazeneca.com wrote:

> I have been lurking in this list a while and searching in the archives to
> find out how one learns to write fast R code. One solution seems to be to
> write part of the code not in R but in C. However after finding a benchmark
> article (http://www.sciviews.org/other/benchmark.htm) I have been more
> interested in making the R code itself more efficient. I would like to find
> more info about this. I have tried to mail the contact person for the
> benchmark, but I have so recieved no reply.
> 
> I am not an R programmer (or statistican) so I do not know R well. I am
> looking for some advice about writing fast R code. What about the different
> data types for example? Is there some good place to start to look for more
> info about this? 
> 
> 
> Thanks for any pointers
> Lennart
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

Lennart

To learn about "data types" take a look at the early chapters of An 
Introduction To R available at

http://cran.r-project.org/manuals.html

Richard
-- 

Richard E. Remington III
Statistician
KERN Statistical Services, Inc.
PO Box 1046
Boise, ID 83701
Tel: 208.426.0113
KernStat.com



From tlumley at u.washington.edu  Tue Feb 17 23:19:49 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 17 Feb 2004 14:19:49 -0800 (PST)
Subject: [R] How to write efficient R code
In-Reply-To: <20040217192432.MLTE4025.mta3-rme.xtra.co.nz@kevinlpt>
References: <20040217192432.MLTE4025.mta3-rme.xtra.co.nz@kevinlpt>
Message-ID: <Pine.A41.4.58.0402171413040.55412@homer34.u.washington.edu>

On Wed, 18 Feb 2004, Ko-Kang Kevin Wang wrote:
>
> One way to make your codes more efficient is to use "vectorisation" --
> vectorise your codes.  I'm not sure where you can find more
> information about it, but an example would be to use the apply()
> function on a data frame instead using a loop.  Avoid loops if you
> can.

Umm. No.  Vectorization is definitely a good thing -- just about the only
coding change that improves both clarity and speed -- but replacing a loop
with apply() is not vectorisation in that sense.

Except for some cases of lapply, the apply functions are mostly clarity
optimisations rather than speed optimisations.


	-thomas



From xiaoliu at jhmi.edu  Tue Feb 17 23:38:46 2004
From: xiaoliu at jhmi.edu (XIAO LIU)
Date: Tue, 17 Feb 2004 17:38:46 -0500
Subject: [R] Apply a function to each cell of a ragged matrix
Message-ID: <105adc7105dbf6.105dbf6105adc7@jhmimail.jhmi.edu>

R-Helpers:

There are a matrix x and a factor f.  nrow(x) == length(f), e.g.:
x <- matrix(1:6, nrow = 3)
f <- factor(c("daytime", "daytime", "night"))

I want the sum of all elements of rows of "x" for each corresponding level in factor "f",
In this case, I want output like:
"daytime" [1] x[1,1]+x[2,1]+x[1,2]+x[2,2]
"night"   [2] x[3,1]+x[3,2]

But, tapply(x,f,sum) or by(x,f,sum) do not work.  What other functions can I use?

Thank you very much

Xiao



From bates at stat.wisc.edu  Tue Feb 17 23:56:29 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 17 Feb 2004 16:56:29 -0600
Subject: [R] parse error in GLMM function
In-Reply-To: <002f01c3f58c$400805c0$b54a6cc8@gcendoya.balcarce.inta.gov.ar>
References: <002f01c3f58c$400805c0$b54a6cc8@gcendoya.balcarce.inta.gov.ar>
Message-ID: <6rfzd9qpr6.fsf@bates4.stat.wisc.edu>

"CENDOYA, Gabriela" <gcendoya at balcarce.inta.gov.ar> writes:

>  I'm trying to use the function GLMM from lme4 package, (R-1.8.1, Windows
> 98),and I get the following error:
> > pd5 = GLMM(nplant~sitio+
> +                   fert+
> +                   remo+
> +                   sitio:fert+
> +                   remo:sitio+
> +                   remo:fert+
> +                   remo:fert:sitio
> +             data=datos,
> +             family=binomial,
> +             random=~repe:sitio)
> Error in parse(file, n, text, prompt) : parse error

Could you tell us the version of the lme4 package please?

> From GLMM and parse's help pages, I couldn't figure out what I was
> doing wrong.  Also in GLMM's help page say that data is an
> "optional" data frame used as the first place to find variables in
> the formulae, but if I omit data=datos (previously I have done
> attach(datos)), the error changes to:
> 
> > pd5 = GLMM(nplant~sitio+
> +                    fert+
> +                    remo+
> +                    sitio:fert+
> +                    remo:sitio+
> +                    remo:fert+
> +                    remo:fert:sitio,
> +                    family=binomial,
> +                    random=~repe:sitio)
> Error in model.frame.default(formula = formula, data = data,
> drop.unused.levels = TRUE) :
>         Argument "data" is missing, with no default

> This is not what I was expecting for "an optional data frame",

Well if you are going to be picky about it! :-)

I guess the optional data frame is not quite as optional as we had
intended.  Time to add another check.  Thanks for pointing this out.



From smyth at wehi.edu.au  Wed Feb 18 00:02:26 2004
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Wed, 18 Feb 2004 10:02:26 +1100
Subject: [R] Test for pre-existing Win menu or item
Message-ID: <6.0.1.1.1.20040218095902.029527a8@imaphost.wehi.edu.au>

Before using winMenuAdd(), is it possible to test whether the menu already 
exists? One could use try(winMenuAddItem()) with appropriate arguments, but 
is there anything more elegant?

Many thanks
Gordon



From andy_liaw at merck.com  Wed Feb 18 00:15:56 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 17 Feb 2004 18:15:56 -0500
Subject: [R] In praise of ->
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77E0@usrymx25.merck.com>

> From: Murray Jorgensen
> 
> This is not a problem, but I thought that I might say one or 
> two things 
> in favour of right pointing assignment before anybody 
> influential gets 
> the idea of scrapping it!
> 
> Situation (a)
> 
> You have just typed a long complcated expression into the console and 
> you suddenly realise that you will need it later in the session. Just 
> append
> -> something
> to the end of the expression. You can do this with any recently 
> evaluated expression with the help of the up-arrow key (in Windows at 
> least).

You can do this just as easily in two ways:

1. IforgotThis <- .Last.value   [This always works, even if command editing
is not available.]

2. If command line editing is available, hit [up-arrow], [home] (or ctrl-a)
then type IforgotThis = ...
 
> Situation (b)
> 
> You have written a chunk of code and you want to see how it 
> behaves for 
> various values of the scalar "fred". Just put
> -> fred
> at the start of the code block, type any number, then paste the code 
> into the console.

This is also easily accomodated w/o the use of ->:  Instead of 

MyValue -> fred
[code that follows]

use:

fred <-
MyValue
[code that follows]

Andy

 
> Cheers,  Murray
> 
> -- 
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz                                Fax 7 838 4155
> Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From andy_liaw at merck.com  Wed Feb 18 00:26:07 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 17 Feb 2004 18:26:07 -0500
Subject: [R] Apply a function to each cell of a ragged matrix
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77E1@usrymx25.merck.com>

> sapply(split(x,f), sum)
daytime   night 
     12       9 

HTH,
Andy

> From: XIAO LIU
> 
> R-Helpers:
> 
> There are a matrix x and a factor f.  nrow(x) == length(f), e.g.:
> x <- matrix(1:6, nrow = 3)
> f <- factor(c("daytime", "daytime", "night"))
> 
> I want the sum of all elements of rows of "x" for each 
> corresponding level in factor "f",
> In this case, I want output like:
> "daytime" [1] x[1,1]+x[2,1]+x[1,2]+x[2,2]
> "night"   [2] x[3,1]+x[3,2]
> 
> But, tapply(x,f,sum) or by(x,f,sum) do not work.  What other 
> functions can I use?
> 
> Thank you very much
> 
> Xiao


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From p.dalgaard at biostat.ku.dk  Wed Feb 18 00:28:56 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Feb 2004 00:28:56 +0100
Subject: [R] problem with fitdistr ?
In-Reply-To: <Pine.LNX.4.44.0402171857520.22716-100000@gannet.stats>
References: <Pine.LNX.4.44.0402171857520.22716-100000@gannet.stats>
Message-ID: <x2k72li8uf.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> Which version of MASS (not that you gave me any credit)?  This works in 
> the current 7.1-14.

Odd things are happening for me with r-devel, though:

> library(MASS)
> fitdistr(rnorm(100),"Normal")
Error in dn[[2]] : subscript out of bounds
> fitdistr(rnorm(100),"Normal",start=list(mean=0,sd=1))
Error in fitdistr(rnorm(100), "Normal", start = list(mean = 0, sd =
> 1)) :
        supplying pars for the Normal is not supported
> x <- fitdistr(rnorm(100),"normal")
> x
Error in dn[[2]] : subscript out of bounds
> str(x)
List of 2
 $ estimate: num 0.217
 $ sd      : num 0.99
 - attr(*, "class")= chr "fitdistr"

And the rest of the story is that this bit of print.fitdistr computes
"ans" without dimnames and thus refers to dn[[2]] before there's
anything there:

    ans <- format(rbind(x$estimate, x$sd), digits = digits)
    ans[1, ] <- sapply(ans[1, ], function(x) paste("", x))
    ans[2, ] <- sapply(ans[2, ], function(x) paste("(", x, ")",
        sep = ""))
    dn <- dimnames(ans)
    dn[[1]] <- rep("", 2)
    dn[[2]] <- paste(substring("      ", 1, (nchar(ans[2, ]) -
        nchar(dn[[2]]))%/%2), dn[[2]])


 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From maj at stats.waikato.ac.nz  Wed Feb 18 00:30:57 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Wed, 18 Feb 2004 12:30:57 +1300
Subject: [R] In praise of ->
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF77E0@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF77E0@usrymx25.merck.com>
Message-ID: <4032A431.9030203@stats.waikato.ac.nz>



Liaw, Andy wrote:


 > This is also easily accomodated w/o the use of ->:  Instead of
 >
 > MyValue -> fred
 > [code that follows]
 >
 > use:
 >
 > fred <-
 > MyValue
 > [code that follows]
 >
 > Andy

The point is that

-> fred
[code that follows]

is sitting as one piece in the clipboard. So instead of

3 <paste>
8 <paste>
etc

you need to do

fred -> 3 <paste>
fred -> 8 <paste>
etc

Not a big saving, but some of us are lazy!


-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From andy_liaw at merck.com  Wed Feb 18 00:35:21 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 17 Feb 2004 18:35:21 -0500
Subject: [R] How to write efficient R code
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77E2@usrymx25.merck.com>

I'm guessing what Sebatian want is to do the differencing by a stratifying
variable such as ID; e.g., the data may look like:

df <- as.data.frame(cbind(ID=rep(1:5, each=3), x=matrix(rnorm(45), 15, 3))

So using Tom's solution, one would do something like:

mdiff <- function(x) x[-1,] - x[nrow(x),]
sapply(split(df[,-1], df[,1]), mdiff)

There could well be more efficient ways!

Andy

> From: Tom Blackwell
> 
> Sebastian  -
> 
> For successive differences within a single column 'x'
> 
> differences <- c(NA, diff(x)),
> 
> same as
> 
> differences <- c(NA, x[-1] - x[-length(x)]).
> 
> See  help("diff"), help("Subscript").  The second version also
> works when  x  is a matrix or a data frame, except now the result
> is a matrix or data frame of the same size.
> 
> x <- data.frame(matrix(rnorm(1e+5), 1e+4))
> dim(x)               # 10000    10
> differences <- rbind(rep(NA, 10), x[-1, ] - x[-dim(x)[1], ])
> dim(differences)     # 10000    10
> 
> However, you write "I need to do this for all the subsets of data
> created by the numbers in one of the columns of the data frame ..."
> and I'm not sure I understand how an 'id' column would create many
> subsets of the data.  So the simple examples above may not answer
> the question you are asking.
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Tue, 17 Feb 2004, Sebastian Luque wrote:
> 
> > Hi,
> >
> > In fact, I've been trying to get rid of loops in my code for more
> > than a week now, but nothing I try seems to work. It sounds as if
> > you have lots of experience with loops, so would appreciate any
> > pointers you may have on the following.
> >
> > I want to create a column showing the difference between the ith
> > row and i-1. Of course, the first row won't have any value in it,
> > because there is nothing above it to subtract to. This is fairly
> > easy to do with a simple loop, but I need to do this for all the
> > subsets of data created by the numbers in one of the columns of
> > the data frame (say, an id column). I would greatly appreciate
> > any idea you may have on this.
> >
> > Thanks in advance.
> >
> > Best regards,
> > Sebastian
> > --
> >   Sebastian Luque
> >
> > sluque at mun.ca
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From p.dalgaard at biostat.ku.dk  Wed Feb 18 00:52:19 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Feb 2004 00:52:19 +0100
Subject: [R] How to write efficient R code
In-Reply-To: <1077046144.10097.11.camel@ra.chem.psu.edu>
References: <26D5AB9F6512D611A8610001FA7E136F032783E4@se-drc-mail4.selu.astrazeneca.net>
	<Pine.SOL.4.58.0402171209530.13070@timepilot.gpcc.itd.umich.edu>
	<1077046144.10097.11.camel@ra.chem.psu.edu>
Message-ID: <x2fzd9i7rg.fsf@biostat.ku.dk>

Rajarshi Guha <rxg218 at psu.edu> writes:

> On Tue, 2004-02-17 at 12:21, Tom Blackwell wrote:
> > Lennart  -
> > 
> > My two rules are:
> > 
> >   1. Be straightforward.  Don't try to be too fancy.  Don't worry
> >   about execution time until you have the WHOLE thing programmed
> >   and DOING everything you want it to.  Then profile it, if it's
> >   really going to be run more than 1000 times.  Execution time
> >   is NOT the issue.  Code maintainability IS.
> > 
> >  2. Use vector operations wherever possible.  Avoid explicit loops.
> >     However, the admonition to avoid loops is probably much less
> >     important now than it was with the Splus of 10 or 15 years ago.
> > 
> > (Not that I succeed in obeying these rules myself, all the time.)
> > 
> > Remember:  execution time is not the issue.  memory size may be.
> > clear, maintainable code definitely is.
> 
> I've been using for maybe 6 months or less and am by no means an R
> expert. But the above two points are extremely valid - my policy is to
> always write code that I can read 2 months later without comments
> (though in the end I do add them) - even if it requires loops.
> 
> However, after I'm sure the results are right I spend time on trying to
> vectorise the code. And that has improved performace by orders of
> magnitude (IMO, its also more elegant to have a one line vector
> operation rather than a loop).

All true. A couple of additional remarks:

1) Some constructs are spectacularly inefficient, as you'll realize
   when you think about what they have to do. One standard example is

        for (i in 1:10000) 
            x[i] <- f(i)

   which becomes much faster if you preallocate x <- numeric(10000)
   (never mind that sapply will do it more neatly). Without
   preallocation, R will need to extend the array on every iteration,
   which require the whole array to be copied to a new location. It is
   a very good idea to keep your eyes open for these situations and
   try to avoid them.

2) On the other hand, don't be trapped by efficiency differences that
   might be "accidental" and go away in later releases. We've seen a
   couple of cases were the Wrong Way was actually faster than the
   Right Way (details elude me -- something with deparse/reparse vs.
   symbolic computations, I suspect), but you this easily leads to
   code that is hard to read, and may have subtle bugs.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From h.wickham at auckland.ac.nz  Wed Feb 18 01:04:29 2004
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Wed, 18 Feb 2004 13:04:29 +1300
Subject: [R] setMethod
Message-ID: <4032AC0D.5000208@auckland.ac.nz>

I'm having problems understanding how setMethod works.  I'm trying to 
create a class specfic method for xyplot, so I thought I should do 
something like this:

setMethod("xyplot",
	signature(data = "marrayRaw"),
	function(formula, data, ...) {
		xyplot.ma(formula, do.something.with.data(data), ...)
	}
)

but I get the following error:

In method for function "xyplot": Expanding the signature to include omitted
arguments in definition: allow.multiple = "missing", outer = "missing",
auto.key = "missing", aspect = "missing", layout = "missing", panel =
"missing", prepanel = "missing", scales = "missing", strip = "missing",
groups = "missing", xlab = "missing", xlim = "missing", ylab = "missing",
ylim = "missing", subscripts = "missing", subset = "missing"
Error in .MakeSignature(new("signature"), def, signature) :
         The names in signature for method (formula, data, , , , , , , , 
, , , , , , , , , ) don't match function's arguments
(formula, data, allow.multiple, outer, auto.key, aspect, layout, panel, 
prepanel, scales, strip, groups, xlab, xlim, ylab, ylim, subscripts, subset)

What I am doing wrong?  I have tried using the full argument list for 
xyplot (where I have function(formula, data, ...) above) but then I run 
into problems passing on the arguments that have no defaults (eg. xlab, 
ylab).

Thanks for you help,

Hadley



From jcjorgensen at wisc.edu  Wed Feb 18 01:05:05 2004
From: jcjorgensen at wisc.edu (Jeff Jorgensen)
Date: Tue, 17 Feb 2004 18:05:05 -0600
Subject: [R] persp and lines()
Message-ID: <5.2.1.1.2.20040217175258.022e2590@wiscmail.wisc.edu>

R-sters:

I'm interested in keeping data plotted in persp to preserve the wireframe 
look, I'd just like to change one of the lines drawn (in either the x or y 
direction) into a different color so that it stands out.

Or is there some way to add a line (say, via lines(), or abline()) to a 
persp() plot at the designated x or y that would follow the z surface 
contour?  I could add a line using 2D representations of the data, but I'd 
like to use the perspective plot if possible.

Any advice?

Cheers,

Jeff



From ggrothendieck at myway.com  Wed Feb 18 01:10:11 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 17 Feb 2004 19:10:11 -0500 (EST)
Subject: [R] Apply a function to each cell of a ragged matrix
Message-ID: <20040218001011.5CE14397C@mprdmxin.myway.com>



rowsum(x,f)

---
Date:   Tue, 17 Feb 2004 17:38:46 -0500 
From:   XIAO LIU <xiaoliu at jhmi.edu>
To:   R Help <r-help at stat.math.ethz.ch> 
Subject:   [R] Apply a function to each cell of a ragged matrix 

 
R-Helpers:

There are a matrix x and a factor f. nrow(x) == length(f), e.g.:
x <- matrix(1:6, nrow = 3)
f <- factor(c("daytime", "daytime", "night"))

I want the sum of all elements of rows of "x" for each corresponding level in factor "f",
In this case, I want output like:
"daytime" [1] x[1,1]+x[2,1]+x[1,2]+x[2,2]
"night" [2] x[3,1]+x[3,2]

But, tapply(x,f,sum) or by(x,f,sum) do not work. What other functions can I use?

Thank you very much

Xiao



From tblackw at umich.edu  Wed Feb 18 01:45:58 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Tue, 17 Feb 2004 19:45:58 -0500 (EST)
Subject: [R] persp and lines()
In-Reply-To: <5.2.1.1.2.20040217175258.022e2590@wiscmail.wisc.edu>
References: <5.2.1.1.2.20040217175258.022e2590@wiscmail.wisc.edu>
Message-ID: <Pine.SOL.4.58.0402171944060.13070@timepilot.gpcc.itd.umich.edu>

Jeff  -

See the section titled "Value:" and example (2) from  help("persp")
for instructions and an example of doing exactly what you ask.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 17 Feb 2004, Jeff Jorgensen wrote:

> R-sters:
>
> I'm interested in keeping data plotted in persp to preserve the wireframe
> look, I'd just like to change one of the lines drawn (in either the x or y
> direction) into a different color so that it stands out.
>
> Or is there some way to add a line (say, via lines(), or abline()) to a
> persp() plot at the designated x or y that would follow the z surface
> contour?  I could add a line using 2D representations of the data, but I'd
> like to use the perspective plot if possible.
>
> Any advice?
>
> Cheers,
>
> Jeff
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From m.okasha at palnet.com  Wed Feb 18 01:46:06 2004
From: m.okasha at palnet.com (Mahmoud K. Okasha)
Date: Wed, 18 Feb 2004 02:46:06 +0200
Subject: [R] Apply a function to each cell of a ragged matrix
References: <105adc7105dbf6.105dbf6105adc7@jhmimail.jhmi.edu>
Message-ID: <002901c3f5b8$98d9bd20$2b334ed9@okasha>

Hi,
you could simply use functions such as:

time <- dim (3)
for ( i in 1:3) time [i] <- x[i,1]+x[i,2]

the result of time will be the sum of rows.

best regards..

----- Original Message -----
From: "XIAO LIU" <xiaoliu at jhmi.edu>
To: "R Help" <r-help at stat.math.ethz.ch>
Sent: Wednesday, February 18, 2004 12:38 AM
Subject: [R] Apply a function to each cell of a ragged matrix


> R-Helpers:
>
> There are a matrix x and a factor f.  nrow(x) == length(f), e.g.:
> x <- matrix(1:6, nrow = 3)
> f <- factor(c("daytime", "daytime", "night"))
>
> I want the sum of all elements of rows of "x" for each corresponding level
in factor "f",
> In this case, I want output like:
> "daytime" [1] x[1,1]+x[2,1]+x[1,2]+x[2,2]
> "night"   [2] x[3,1]+x[3,2]
>
> But, tapply(x,f,sum) or by(x,f,sum) do not work.  What other functions can
I use?
>
> Thank you very much
>
> Xiao
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>



From Craig at resolutions.co.nz  Wed Feb 18 02:19:00 2004
From: Craig at resolutions.co.nz (Craig MacKinlay)
Date: Wed, 18 Feb 2004 14:19:00 +1300
Subject: [R] Discriminant Analysis Using Anova in R
Message-ID: <F144EEB47F5662438D2C2372AED64FF41170BC@server.resolutions.local>

Hi there,

I work for a market research company and I would like to do the following. I have a dependent variable which is commitment, and I want to see how other variables such as how 5 satisfaction variables (which are all binary variables, take the values 0 and 1) influence commitment using a discriminant analysis, could you please tell me how I can do this in R, ie: the commands for it?

Also I am using the function "rpart" for obtaining a regression tree for the same dependent variable and using the same independent satifaction variables to help explain it. How do I label the tree, I understand that to do the analysis I use:

model<-rpart(Commitment~.,data=datasetname)
plot(model) to draw the tree
text(model) to label tree.

However the text(model) command does not work. have you any suggestions?

cheers Craig



From ggrothendieck at myway.com  Wed Feb 18 02:44:46 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 17 Feb 2004 20:44:46 -0500 (EST)
Subject: [R] Apply a function to each cell of a ragged matrix
Message-ID: <20040218014446.68DA8396C@mprdmxin.myway.com>


I misread your post.  Try any of these:

rowSums(rowsum(x,f))

rowsum(rowSums(x),f)

tapply(rowSums(x),f,sum)

by(rowSums(x),f,sum)

---

Date:   Tue, 17 Feb 2004 19:10:11 -0500 (EST) 
From:   Gabor Grothendieck <ggrothendieck at myway.com>
To:   <xiaoliu at jhmi.edu>, <r-help at stat.math.ethz.ch> 
Subject:   RE: [R] Apply a function to each cell of a ragged matrix 

 


rowsum(x,f)

---
Date: Tue, 17 Feb 2004 17:38:46 -0500 
From: XIAO LIU <xiaoliu at jhmi.edu>
To: R Help <r-help at stat.math.ethz.ch> 
Subject: [R] Apply a function to each cell of a ragged matrix 


R-Helpers:

There are a matrix x and a factor f. nrow(x) == length(f), e.g.:
x <- matrix(1:6, nrow = 3)
f <- factor(c("daytime", "daytime", "night"))

I want the sum of all elements of rows of "x" for each corresponding level in factor "f",
In this case, I want output like:
"daytime" [1] x[1,1]+x[2,1]+x[1,2]+x[2,2]
"night" [2] x[3,1]+x[3,2]

But, tapply(x,f,sum) or by(x,f,sum) do not work. What other functions can I use?



From jgentry at jimmy.harvard.edu  Wed Feb 18 03:00:36 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Tue, 17 Feb 2004 21:00:36 -0500 (EST)
Subject: [R] Test for pre-existing Win menu or item
In-Reply-To: <6.0.1.1.1.20040218095902.029527a8@imaphost.wehi.edu.au>
Message-ID: <Pine.SOL.4.20.0402172058530.10746-100000@santiam.dfci.harvard.edu>

> Before using winMenuAdd(), is it possible to test whether the menu already 
> exists? One could use try(winMenuAddItem()) with appropriate arguments, but 
> is there anything more elegant?

winMenuNames() and winMenuItems() should give you the sort of information
you're looking for, tho they're in R-devel and not R-1.8.x.

-J



From spencer.graves at pdf.com  Wed Feb 18 03:01:24 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 17 Feb 2004 18:01:24 -0800
Subject: [R] persp and lines()
In-Reply-To: <5.2.1.1.2.20040217175258.022e2590@wiscmail.wisc.edu>
References: <5.2.1.1.2.20040217175258.022e2590@wiscmail.wisc.edu>
Message-ID: <4032C774.9040408@pdf.com>

      The help file for persp (in R 1.8.1, at least) includes a function 
to "Add to existing persp plot".  Have you tried that?  Alternative, 
have you considered "wireframe" in package lattice? 

      hope this helps.  spencer graves

Jeff Jorgensen wrote:

> R-sters:
>
> I'm interested in keeping data plotted in persp to preserve the 
> wireframe look, I'd just like to change one of the lines drawn (in 
> either the x or y direction) into a different color so that it stands 
> out.
>
> Or is there some way to add a line (say, via lines(), or abline()) to 
> a persp() plot at the designated x or y that would follow the z 
> surface contour?  I could add a line using 2D representations of the 
> data, but I'd like to use the perspective plot if possible.
>
> Any advice?
>
> Cheers,
>
> Jeff
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From smyth at wehi.edu.au  Wed Feb 18 04:33:04 2004
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Wed, 18 Feb 2004 14:33:04 +1100
Subject: [R] Test for pre-existing Win menu or item
In-Reply-To: <Pine.SOL.4.20.0402172058530.10746-100000@santiam.dfci.harv
	ard.edu>
References: <6.0.1.1.1.20040218095902.029527a8@imaphost.wehi.edu.au>
	<Pine.SOL.4.20.0402172058530.10746-100000@santiam.dfci.harvard.edu>
Message-ID: <6.0.1.1.1.20040218142032.02952cf8@imaphost.wehi.edu.au>

Many thanks to Hadley Wickham for pointing out that my question had already 
been answered on the R-help list in December, see

https://www.stat.math.ethz.ch/pipermail/r-help/2003-December/041786.html or
http://maths.newcastle.edu.au/~rking/R/help/03b/7525.html

and to Jeff Gentry for pointing out to look out for new functions 
winMenuNames() and winMenuItems() in R 1.9.0.

Gordon



From ggrothendieck at myway.com  Wed Feb 18 05:19:02 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 17 Feb 2004 23:19:02 -0500 (EST)
Subject: [R] pass by reference -- how to do it
Message-ID: <20040218041902.5DF3E39C6@mprdmxin.myway.com>



If you don't mind NOT passing your arrays at all then you 
can do this:

f <- function() a[1] <<- a[1] + 1
a <- 1:5
f()  # increments first element of a by 1
a     # c(2,2,3,4,5)

The <<- causes the expression to take place in the global 
environment.

If you want to actually pass your arrays by reference then the
following works although its a bit messy:

g <- function(z) eval(eval(substitute(expression(z[1] <<- z[1]+1))))
a <- 1:5
g(a)  # increments first element of a by 1
a     # c(2,2,3,4,5)

The <<- causes the expression to be evaluated in the global 
environment. expression() turns its argument into an object
of mode expression.  substitute() replaces z with the argument 
passed to f in that expression and returns an object of mode 
call.  The inner eval turns the object of mode call into an 
object of mode expression and the outer eval evaluates that expression.  

---
Date:   Tue, 17 Feb 2004 13:23:58 -0800 (PST) 
From:   Robert Dodier <robert_dodier at yahoo.com>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] pass by reference -- how to do it 

 
Hello,

Pass by reference appears to be a topic which comes up
from time to time, but I wasn't able to find something in
the R-help archives which tells how to accomplish it.

I have a problem that you may have seen before -- R runs
out of memory when processing large matrices. Part of the
problem for me is that I am using some large matrices as
function arguments, and these are modified, which leads 
to allocating copies of the matrices. 

I would like to do the modification "in place" so that
a copy is not required. Thanks for any light you can shed
on this.

If you're tempted to tell me "you don't really want to do that" --
let me save you the trouble. You are so very right! Indeed I
don't want to have pass by reference variables. OTOH I don't
want R to come to a dead halt at an inconvenient time either.

Thanks for your help,
Robert Dodier

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From greenberg at ucdavis.edu  Wed Feb 18 05:41:39 2004
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Tue, 17 Feb 2004 20:41:39 -0800
Subject: [R] Printing values within a function
Message-ID: <BC582D03.19A11%greenberg@ucdavis.edu>

This is probably a really stupid question, but how do I print the value of a
variable within a function?  Of course in normal command-line mode I just
type the name of the variable, but how do I have this value exported within
a function?

--j

-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From ggrothendieck at myway.com  Wed Feb 18 05:46:36 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 17 Feb 2004 23:46:36 -0500 (EST)
Subject: [R] Printing values within a function
Message-ID: <20040218044636.4BDDC396A@mprdmxin.myway.com>



Here are two ways:

f <- function(x) print(2*x)
g <- function(x) cat("the value of twice x is", 2*x, "\n")


---
Date:   Tue, 17 Feb 2004 20:41:39 -0800 
From:   Jonathan Greenberg <greenberg at ucdavis.edu>
To:   R-help <r-help at stat.math.ethz.ch> 
Subject:   [R] Printing values within a function 

 
This is probably a really stupid question, but how do I print the value of a
variable within a function? Of course in normal command-line mode I just
type the name of the variable, but how do I have this value exported within
a function?



From yunfang at yahoo-inc.com  Wed Feb 18 06:19:11 2004
From: yunfang at yahoo-inc.com (Yun-Fang Juan)
Date: Tue, 17 Feb 2004 21:19:11 -0800
Subject: [R] ANOVA procedure on the sufficient  statistics
Message-ID: <01d501c3f5de$bdd566d0$90ea7ecf@YUNFANG2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040217/d2b745d8/attachment.pl

From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Feb 18 08:30:47 2004
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 18 Feb 2004 08:30:47 +0100 (CET)
Subject: [R] Generating 2x2 contingency tables
In-Reply-To: <002b01c3f561$ac90a7e0$0d00a8c0@okasha>
References: <002b01c3f561$ac90a7e0$0d00a8c0@okasha>
Message-ID: <Pine.LNX.4.51.0402180827590.25051@artemis.imbe.med.uni-erlangen.de>


On Tue, 17 Feb 2004, Mahmoud K. Okasha wrote:

> Hello R-users,
>
> I would like to generate two-way contingency tables with zero in one cell. I tried to use the function r2dtable but I could not force one cell to have zero value.
>

r2dtable samples from the conditional distribution of the table given the
margins. And with margins fixed AND one cell fixed (to zero) the
conditional distribution just puts mass one at the observed table.

You may want to sample from a multinomial distribution with one
of the parameters fixed to zero.

Best,

Torsten

> Any Idea?
>
> Best regards..
> Mahmoud
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From ripley at stats.ox.ac.uk  Wed Feb 18 09:10:57 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Feb 2004 08:10:57 +0000 (GMT)
Subject: [R] problem with fitdistr ?
In-Reply-To: <x2k72li8uf.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0402180805560.23582-100000@gannet.stats>

It works under the versions 7.2-0 dated Jan 22 or later: that on CRAN is 
dated Jan 14 and predates 7.1-14.

Since R-devel is `under development', the pieces are not at all times in 
sync.

On 18 Feb 2004, Peter Dalgaard wrote:

> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> 
> > Which version of MASS (not that you gave me any credit)?  This works in 
> > the current 7.1-14.
> 
> Odd things are happening for me with r-devel, though:
> 
> > library(MASS)
> > fitdistr(rnorm(100),"Normal")
> Error in dn[[2]] : subscript out of bounds
> > fitdistr(rnorm(100),"Normal",start=list(mean=0,sd=1))
> Error in fitdistr(rnorm(100), "Normal", start = list(mean = 0, sd =
> > 1)) :
>         supplying pars for the Normal is not supported
> > x <- fitdistr(rnorm(100),"normal")
> > x
> Error in dn[[2]] : subscript out of bounds
> > str(x)
> List of 2
>  $ estimate: num 0.217
>  $ sd      : num 0.99
>  - attr(*, "class")= chr "fitdistr"
> 
> And the rest of the story is that this bit of print.fitdistr computes
> "ans" without dimnames and thus refers to dn[[2]] before there's
> anything there:
> 
>     ans <- format(rbind(x$estimate, x$sd), digits = digits)
>     ans[1, ] <- sapply(ans[1, ], function(x) paste("", x))
>     ans[2, ] <- sapply(ans[2, ], function(x) paste("(", x, ")",
>         sep = ""))
>     dn <- dimnames(ans)
>     dn[[1]] <- rep("", 2)
>     dn[[2]] <- paste(substring("      ", 1, (nchar(ans[2, ]) -
>         nchar(dn[[2]]))%/%2), dn[[2]])
> 
> 
>  
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ernesto at ipimar.pt  Wed Feb 18 10:36:30 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Wed, 18 Feb 2004 09:36:30 +0000
Subject: [R] problem with fitdistr ?
In-Reply-To: <Pine.LNX.4.44.0402171857520.22716-100000@gannet.stats>
References: <Pine.LNX.4.44.0402171857520.22716-100000@gannet.stats>
Message-ID: <1077096989.18290.3.camel@gandalf.local>

On Tue, 2004-02-17 at 18:59, Prof Brian Ripley wrote:
> Which version of MASS (not that you gave me any credit)?  This works in 
> the current 7.1-14.
> 
> On Tue, 17 Feb 2004, Ernesto Jardim wrote:
> 
> > I'm trying fitdistr but I'm getting some errors
> > 
> > > fitdistr(rnorm(100),"Normal")
> > Error in fitdistr(rnorm(100), "Normal") : 'start' must be a named list
> > > fitdistr(rnorm(100),"Normal",start=list(mean=0,sd=1))
> > Error in fitdistr(rnorm(100), "Normal", start = list(mean = 0, sd = 1))
> > :
> >         supplying pars for the Normal is not supported
> > 
> > 
> > What is the problem here ? Am I doing something wrong ?

Hi,

I'm using R-1.8.1 with MASS 7.1-13. Sorry for not mentioning MASS.

Regards

EJ



                Information on Package 'MASS'
                                                                                
Description:
 
Package: MASS
Description: The main library and the datasets
Title: Main Library of Venables and Ripley's MASS
Bundle: VR
Priority: recommended
Version: 7.1-13
Date: 2003-12-06
Depends: R (>= 1.8.0), lattice, nlme (>= 3.1-40), survival
Author: S original by Venables & Ripley. R port by Brian Ripley
        <ripley at stats.ox.ac.uk>, following earlier work by Kurt Hornik
        and Albrecht Gebhardt.
Maintainer: Brian Ripley <ripley at stats.ox.ac.uk>
BundleDescription: Functions and datasets to support Venables and
        Ripley, 'Modern Applied Statistics with S' (4th edition).
License: GPL (version 2 or later)
URL: http://www.stats.ox.ac.uk/pub/MASS4/
Packaged: Sat Dec 6 20:47:49 2003; ripley
Built: R 1.8.1; i686-pc-linux-gnu; 2004-01-08 15:37:40; unix



From ripley at stats.ox.ac.uk  Wed Feb 18 10:46:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Feb 2004 09:46:01 +0000 (GMT)
Subject: [R] problem with fitdistr ?
In-Reply-To: <1077096989.18290.3.camel@gandalf.local>
Message-ID: <Pine.LNX.4.44.0402180943430.12870-100000@gannet.stats>

On Wed, 18 Feb 2004, Ernesto Jardim wrote:

> On Tue, 2004-02-17 at 18:59, Prof Brian Ripley wrote:
> > Which version of MASS (not that you gave me any credit)?  This works in 
> > the current 7.1-14.
> > 
> > On Tue, 17 Feb 2004, Ernesto Jardim wrote:
> > 
> > > I'm trying fitdistr but I'm getting some errors
> > > 
> > > > fitdistr(rnorm(100),"Normal")
> > > Error in fitdistr(rnorm(100), "Normal") : 'start' must be a named list
> > > > fitdistr(rnorm(100),"Normal",start=list(mean=0,sd=1))
> > > Error in fitdistr(rnorm(100), "Normal", start = list(mean = 0, sd = 1))
> > > :
> > >         supplying pars for the Normal is not supported
> > > 
> > > 
> > > What is the problem here ? Am I doing something wrong ?
> 
> Hi,
> 
> I'm using R-1.8.1 with MASS 7.1-13. Sorry for not mentioning MASS.

It was a bug in that version (only, AFAICS -- 7.1-12 required start 
values).  Please update to 7.1-14.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sb at ihe.se  Wed Feb 18 11:04:10 2004
From: sb at ihe.se (Sixten Borg)
Date: Wed, 18 Feb 2004 11:04:10 +0100
Subject: Ang: [R] How to write efficient R code
Message-ID: <s03346b6.037@gwmail.ihe.se>

Hej Lennart,

I would like to add one thing:
Often, there already exists an R function that solves the problem at hand. Instead of writing your own function, search the help files [apropos(), help.search()]. What I some times find difficult though, is guessing what key words will produce relevant search hits...

Mvh
Sixten

>>> <Lennart.Borgman at astrazeneca.com> 2004-02-17 15:36:12 >>>
I have been lurking in this list a while and searching in the archives to
find out how one learns to write fast R code. One solution seems to be to
write part of the code not in R but in C. However after finding a benchmark
article (http://www.sciviews.org/other/benchmark.htm) I have been more
interested in making the R code itself more efficient. I would like to find
more info about this. I have tried to mail the contact person for the
benchmark, but I have so recieved no reply.

I am not an R programmer (or statistican) so I do not know R well. I am
looking for some advice about writing fast R code. What about the different
data types for example? Is there some good place to start to look for more
info about this? 


Thanks for any pointers
Lennart

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From m.okasha at palnet.com  Wed Feb 18 11:11:47 2004
From: m.okasha at palnet.com (Mahmoud K. Okasha)
Date: Wed, 18 Feb 2004 12:11:47 +0200
Subject: [R] Generating 2x2 contingency tables
References: <002b01c3f561$ac90a7e0$0d00a8c0@okasha>
	<Pine.LNX.4.51.0402180827590.25051@artemis.imbe.med.uni-erlangen.de>
Message-ID: <001601c3f607$9ed3f200$2e334ed9@okasha>

Hi again,
Thank you. I solved my problem by sampling from the multinomial
distribution..
Best regards ...

----- Original Message -----
From: "Torsten Hothorn" <Torsten.Hothorn at rzmail.uni-erlangen.de>
To: "Mahmoud K. Okasha" <m.okasha at palnet.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Wednesday, February 18, 2004 9:30 AM
Subject: Re: [R] Generating 2x2 contingency tables


>
> On Tue, 17 Feb 2004, Mahmoud K. Okasha wrote:
>
> > Hello R-users,
> >
> > I would like to generate two-way contingency tables with zero in one
cell. I tried to use the function r2dtable but I could not force one cell to
have zero value.
> >
>
> r2dtable samples from the conditional distribution of the table given the
> margins. And with margins fixed AND one cell fixed (to zero) the
> conditional distribution just puts mass one at the observed table.
>
> You may want to sample from a multinomial distribution with one
> of the parameters fixed to zero.
>
> Best,
>
> Torsten
>
> > Any Idea?
> >
> > Best regards..
> > Mahmoud
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> >
> >
>
>



From p.dalgaard at biostat.ku.dk  Wed Feb 18 11:26:40 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Feb 2004 11:26:40 +0100
Subject: [R] problem with fitdistr ?
In-Reply-To: <Pine.LNX.4.44.0402180805560.23582-100000@gannet.stats>
References: <Pine.LNX.4.44.0402180805560.23582-100000@gannet.stats>
Message-ID: <x2isi4u1i7.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> It works under the versions 7.2-0 dated Jan 22 or later: that on CRAN is 
> dated Jan 14 and predates 7.1-14.
> 
> Since R-devel is `under development', the pieces are not at all times in 
> sync.

OK. I'm still picking up the older version from CRAN on r-devel
builds, though.

I'd bump the build number rather than rely on the date to discern
different versions of packages.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Wed Feb 18 11:30:11 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Feb 2004 10:30:11 +0000 (GMT)
Subject: [R] problem with fitdistr ?
In-Reply-To: <x2isi4u1i7.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0402181028030.23481-100000@gannet.stats>

On 18 Feb 2004, Peter Dalgaard wrote:

> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> 
> > It works under the versions 7.2-0 dated Jan 22 or later: that on CRAN is 
> > dated Jan 14 and predates 7.1-14.
> > 
> > Since R-devel is `under development', the pieces are not at all times in 
> > sync.
> 
> OK. I'm still picking up the older version from CRAN on r-devel
> builds, though.

I have submitted an update to CRAN.

> I'd bump the build number rather than rely on the date to discern
> different versions of packages.

I do once they are released, but this one is not released (hence the -0).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From marten.bjellerup at ehv.vxu.se  Wed Feb 18 14:10:32 2004
From: marten.bjellerup at ehv.vxu.se (=?iso-8859-1?Q?M=E5rten_Bjellerup?=)
Date: Wed, 18 Feb 2004 14:10:32 +0100
Subject: [R] Plotting a three parameter gamma distribution
Message-ID: <001b01c3f620$96e9d8c0$d54d2fc2@EHV87C8823E7D5>

using GammaDist you have to normalize so that the location parameter equals
zero. However, I want to plot a gamma distribution using the three parameter
distribution, i.e. I want to be able to specify the location parameter. Does
anybody now how I can do this or is there already a routine somewhere that I
haven't found?

Thanx in advance,

M?rten


M?rten Bjellerup
Doctoral Student in Economics
School of Management and Economics
V?xj? University
SE-351 95  V?xj?
Sweden

Tel: +46 470 708410
Fax: +46 470 82478
Mobile: +46 70 969 88 88
Mail: marten.bjellerup at ehv.vxu.se
Web: http://www.ehv.vxu.se
-------------------------------------
"Forecasting is like trying to
drive a car blindfolded and
following directions given
by a person who is looking
out of the back window"



From andy_liaw at merck.com  Wed Feb 18 14:25:18 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 18 Feb 2004 08:25:18 -0500
Subject: [R] How to write efficient R code
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77E4@usrymx25.merck.com>

Sorry about the typo.  There should be a "-" in front of nrow(x); i.e.,

mdiff <- function(x) x[-1,] - x[-nrow(x),]

... and sapply() won't work, but lapply() will.  So the whole thing looks
like:

> do.call("rbind",lapply(split(df[,-1], df$ID), function(x) x[-1,] -
x[-nrow(x),]))
             V2         V3         V4
1.2  -0.1250197  0.6446575 -1.0504143
1.3  -0.4104924  0.5638618  2.4117082
2.5  -3.1917997 -1.8687987 -0.9026947
2.6   2.2405199  3.5321711  1.0417581
3.8   1.7029947  0.3666408  0.8117269
3.9  -1.6701011 -0.8246094 -0.9099002
4.11  0.5183960  1.1066630  1.0484818
4.12  0.3563826 -1.9202869 -3.5635572
5.14  2.2746317  2.9820733 -2.4086057
5.15 -2.5767889 -2.5492538 -0.3083154

However, looking at this, I can't imagine this being the most efficient way
to go about it.  If the IDs are contiguous (i.e., data for the same ID are
in consecutive rows), then you can operate on the entire data and then throw
out the unwanted row of each ID:

> df.diff <- df[-1, -1] - df[-nrow(df), -1]
> del <- which(diff(as.numeric(df$ID)) != 0)
> del
[1]  3  6  9 12
> df.diff[-del,]
           V2         V3         V4
2  -0.1250197  0.6446575 -1.0504143
3  -0.4104924  0.5638618  2.4117082
5  -3.1917997 -1.8687987 -0.9026947
6   2.2405199  3.5321711  1.0417581
8   1.7029947  0.3666408  0.8117269
9  -1.6701011 -0.8246094 -0.9099002
11  0.5183960  1.1066630  1.0484818
12  0.3563826 -1.9202869 -3.5635572
14  2.2746317  2.9820733 -2.4086057
15 -2.5767889 -2.5492538 -0.3083154

HTH,
Andy

> From: Sebastian Luque [mailto:sluque at mun.ca] 
> 
> Hi,
> 
> This is exactly what I meant Andy, the stratifying variable can be 
> thought of as a factor. However, I tried your code and I get 
> the error: 
> "Error in Ops.data.frame......- only defined for equally-sized data 
> frames". What may be happening?
> The result of 'apply' functions, or 'split' or 'by' and the like give 
> lists as results, with a names attribute that, in my case, would have 
> the levels of the factor. How can one get the results back to a 
> data.frame object, with the newly calculated variables? The 
> indexing for 
> lists is not as straight forward as for data frames.
> 
> Thanks to both of you for showing me the power of indexing in 
> R functions!
> 
> Sebastian
> 
> 
> Liaw, Andy wrote:
> 
> >I'm guessing what Sebatian want is to do the differencing by 
> a stratifying
> >variable such as ID; e.g., the data may look like:
> >
> >df <- as.data.frame(cbind(ID=rep(1:5, each=3), 
> x=matrix(rnorm(45), 15, 3))
> >
> >So using Tom's solution, one would do something like:
> >
> >mdiff <- function(x) x[-1,] - x[nrow(x),]
> >sapply(split(df[,-1], df[,1]), mdiff)
> >
> >There could well be more efficient ways!
> >
> >Andy
> >
> >  
> >
> >>From: Tom Blackwell
> >>
> >>Sebastian  -
> >>
> >>For successive differences within a single column 'x'
> >>
> >>differences <- c(NA, diff(x)),
> >>
> >>same as
> >>
> >>differences <- c(NA, x[-1] - x[-length(x)]).
> >>
> >>See  help("diff"), help("Subscript").  The second version also
> >>works when  x  is a matrix or a data frame, except now the result
> >>is a matrix or data frame of the same size.
> >>
> >>x <- data.frame(matrix(rnorm(1e+5), 1e+4))
> >>dim(x)               # 10000    10
> >>differences <- rbind(rep(NA, 10), x[-1, ] - x[-dim(x)[1], ])
> >>dim(differences)     # 10000    10
> >>
> >>However, you write "I need to do this for all the subsets of data
> >>created by the numbers in one of the columns of the data frame ..."
> >>and I'm not sure I understand how an 'id' column would create many
> >>subsets of the data.  So the simple examples above may not answer
> >>the question you are asking.
> >>
> >>-  tom blackwell  -  u michigan medical school  -  ann arbor  -
> >>
> >>On Tue, 17 Feb 2004, Sebastian Luque wrote:
> >>
> >>    
> >>
> >>>Hi,
> >>>
> >>>In fact, I've been trying to get rid of loops in my code for more
> >>>than a week now, but nothing I try seems to work. It sounds as if
> >>>you have lots of experience with loops, so would appreciate any
> >>>pointers you may have on the following.
> >>>
> >>>I want to create a column showing the difference between the ith
> >>>row and i-1. Of course, the first row won't have any value in it,
> >>>because there is nothing above it to subtract to. This is fairly
> >>>easy to do with a simple loop, but I need to do this for all the
> >>>subsets of data created by the numbers in one of the columns of
> >>>the data frame (say, an id column). I would greatly appreciate
> >>>any idea you may have on this.
> >>>
> >>>Thanks in advance.
> >>>
> >>>Best regards,
> >>>Sebastian
> >>>--
> >>>  Sebastian Luque
> >>>
> >>>sluque at mun.ca
> >>>
> >>>
> >>>      
> >>>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! 
> >>http://www.R-project.org/posting-guide.html
> >>
> >>
> >>    
> >>
> >
> >
> >-------------------------------------------------------------
> -----------------
> >Notice:  This e-mail message, together with any attachments, contains
> >information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New
> >Jersey, USA 08889), and/or its affiliates (which may be 
> known outside the
> >United States as Merck Frosst, Merck Sharp & Dohme or MSD 
> and in Japan, as
> >Banyu) that may be confidential, proprietary copyrighted 
> and/or legally
> >privileged. It is intended solely for the use of the 
> individual or entity
> >named on this message.  If you are not the intended 
> recipient, and have
> >received this message in error, please notify us immediately 
> by reply e-mail
> >and then delete it from your system.
> >-------------------------------------------------------------
> -----------------
> >
> >  
> >
> 
> -- 
> Sebastian Luque
> 
> sluque at mun.ca
> Tel.: +1 (204) 586-8170
> 
> 
> 
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From schnitzlerj at gmx.de  Wed Feb 18 14:34:40 2004
From: schnitzlerj at gmx.de (Johannes Schnitzler)
Date: Wed, 18 Feb 2004 14:34:40 +0100 (MET)
Subject: [R] PNG Problem on Windows 98
Message-ID: <22554.1077111280@www58.gmx.net>

Dear all,


with the new version of R it is normally no problem to produce very fast
graphics in the png format.

In the office i want to work with R - Windows 98 is used.
There are french versions and english versions of Windows 98 second edition.

The png graphics are only on one computer correct.
On the other computers - the x-axis labels, the legend text and the "mtext"
(on the bottom) is missing. 
Attached are simple example files one in jpg (which is ok) and one in png
format.

produced with:

png("test3.png");
plot(1:100);
mtext(c("aaa","bbb"),c(1,2),c(4,1));
legend(50,50,"llll");
dev.off()

for jpeg with jpeg(......)


Any idea where the difference in the installation could be, like missing
files ore necesarry updates for the windows system? 

Thank you very much in advance for any help.      


Johannes

From tblackw at umich.edu  Wed Feb 18 14:40:14 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Wed, 18 Feb 2004 08:40:14 -0500 (EST)
Subject: [R] perhaps 'aggregate()' (was: How to write efficient R code)
In-Reply-To: <4032D4D9.6020202@mun.ca>
References: <3A822319EB35174CA3714066D590DCD504AF77E2@usrymx25.merck.com>
	<4032D4D9.6020202@mun.ca>
Message-ID: <Pine.SOL.4.58.0402180820001.1103@tetris.gpcc.itd.umich.edu>

Sebastian and Andy  -

Yes, Andy has read the question correctly.  A similar task that
I do quite often is to subtract the mean of a class from all of
the members of the class, and do this within every column of a
(numeric) data frame.  Kurt Hornik's function  aggregate()  is
the one to use.  Here's an example using the same data set that
he uses in the example on the help page.  (Only the commands are
shown here.  You'll have to try them to see the output, because
I cannot cut and paste easily into my email.)

data(state)
ls()
	#  This data set puts individual columns into your workspace,
	#  rather than making a data frame of them.

example <- data.frame(state.abb, state.name, state.region, state.x77)
str(example)
means   <- aggregate(example[ ,3+seq(8)], list(example[ ,3]), mean)
str(means)
residuals <- example[ ,3+seq(8)] - means[as.numeric(example[ ,3]), -1]
result  <- cbind(example[ ,seq(3)], residuals)
str(result)

 -- Ah, I think this example would be easier to read if I had used
the columns from the workspace directly, rather than packaging them
into a data frame 'example' first, the using numeric subscripts on
the data frame.  But, at least this illustrates some common ways of
subscripting subsets of columns from a data frame.

Again, see  help("aggregate"), help("Subscript")  to see what I am
doing here.

-  best  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

(Ah, I see that Andy has just replied this morning as well.  I'll see
what his reply was as soon as I send off this one.)

On Tue, 17 Feb 2004, Sebastian Luque wrote:

> Hi,
>
> This is exactly what I meant Andy, the stratifying variable can be
> thought of as a factor. However, I tried your code and I get the error:
> "Error in Ops.data.frame......- only defined for equally-sized data
> frames". What may be happening?
> The result of 'apply' functions, or 'split' or 'by' and the like give
> lists as results, with a names attribute that, in my case, would have
> the levels of the factor. How can one get the results back to a
> data.frame object, with the newly calculated variables? The indexing for
> lists is not as straight forward as for data frames.
>
> Thanks to both of you for showing me the power of indexing in R functions!
>
> Sebastian
>
>
> Liaw, Andy wrote:
>
> >I'm guessing what Sebatian want is to do the differencing by a stratifying
> >variable such as ID; e.g., the data may look like:
> >
> >df <- as.data.frame(cbind(ID=rep(1:5, each=3), x=matrix(rnorm(45), 15, 3))
> >
> >So using Tom's solution, one would do something like:
> >
> >mdiff <- function(x) x[-1,] - x[nrow(x),]
> >sapply(split(df[,-1], df[,1]), mdiff)
> >
> >There could well be more efficient ways!
> >
> >Andy
> >
> >
> >
> >>From: Tom Blackwell
> >>
> >>Sebastian  -
> >>
> >>For successive differences within a single column 'x'
> >>
> >>differences <- c(NA, diff(x)),
> >>
> >>same as
> >>
> >>differences <- c(NA, x[-1] - x[-length(x)]).
> >>
> >>See  help("diff"), help("Subscript").  The second version also
> >>works when  x  is a matrix or a data frame, except now the result
> >>is a matrix or data frame of the same size.
> >>
> >>x <- data.frame(matrix(rnorm(1e+5), 1e+4))
> >>dim(x)               # 10000    10
> >>differences <- rbind(rep(NA, 10), x[-1, ] - x[-dim(x)[1], ])
> >>dim(differences)     # 10000    10
> >>
> >>However, you write "I need to do this for all the subsets of data
> >>created by the numbers in one of the columns of the data frame ..."
> >>and I'm not sure I understand how an 'id' column would create many
> >>subsets of the data.  So the simple examples above may not answer
> >>the question you are asking.
> >>
> >>-  tom blackwell  -  u michigan medical school  -  ann arbor  -
> >>
> >>On Tue, 17 Feb 2004, Sebastian Luque wrote:
> >>
> >>
> >>
> >>>Hi,
> >>>
> >>>In fact, I've been trying to get rid of loops in my code for more
> >>>than a week now, but nothing I try seems to work. It sounds as if
> >>>you have lots of experience with loops, so would appreciate any
> >>>pointers you may have on the following.
> >>>
> >>>I want to create a column showing the difference between the ith
> >>>row and i-1. Of course, the first row won't have any value in it,
> >>>because there is nothing above it to subtract to. This is fairly
> >>>easy to do with a simple loop, but I need to do this for all the
> >>>subsets of data created by the numbers in one of the columns of
> >>>the data frame (say, an id column). I would greatly appreciate
> >>>any idea you may have on this.
> >>>
> >>>Thanks in advance.
> >>>
> >>>Best regards,
> >>>Sebastian
> >>>--
> >>>  Sebastian Luque
> >>>
> >>>sluque at mun.ca
> >>>
> >>>
> >>>
> >>>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide!
> >>http://www.R-project.org/posting-guide.html
> >>
> >>
> >>
> >>
> >
> >
> >------------------------------------------------------------------------------
> >Notice:  This e-mail message, together with any attachments, contains
> >information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New
> >Jersey, USA 08889), and/or its affiliates (which may be known outside the
> >United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as
> >Banyu) that may be confidential, proprietary copyrighted and/or legally
> >privileged. It is intended solely for the use of the individual or entity
> >named on this message.  If you are not the intended recipient, and have
> >received this message in error, please notify us immediately by reply e-mail
> >and then delete it from your system.
> >------------------------------------------------------------------------------
> >
> >
> >
>
> --
> Sebastian Luque
>
> sluque at mun.ca
> Tel.: +1 (204) 586-8170
>
>
>
>
>



From andy_liaw at merck.com  Wed Feb 18 14:40:34 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 18 Feb 2004 08:40:34 -0500
Subject: [R] ANOVA procedure on the sufficient  statistics
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77E5@usrymx25.merck.com>

You can apply the trick that Prof. Dalgaard recently posted in response to a
similar question (for one-way ANOVA).  For each cell, generate data as:

y <- cell.mean + cell.sd * scale(rnorm(cell.count))

Then generate the data frame to feed to aov.

HTH,
Andy

> From: Yun-Fang Juan
> 
> Hi, 
> I have a two-way anova with unequal cell numbers that I want 
> to analyze. 
> The problem is I don't have individual observations of the data.
> I only have the sufficient statistics (mean, variance, # of 
> observations) for each cell. 
> Is there any existing function in S-plus that would allow me 
> to do aov() with the sufficient statistics?
>  
> The table is like 
> 
>      G1 G2 G3 G5 G6
>  T1 
>  T2
>  T3
> 
> 
> For cell (Ti, Gj) i have mean,  variance and # observations 
> and the factors are unordered.
> 
> Thanks a lot for helping me on this in advance.
> 
> 
> Yun-Fang
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From friendly at yorku.ca  Wed Feb 18 14:52:32 2004
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 18 Feb 2004 08:52:32 -0500
Subject: [R] ANOVA procedure on the sufficient statistics
Message-ID: <40336E20.4080803@yorku.ca>

>
>
>Hi, 
>I have a two-way anova with unequal cell numbers that I want to analyze. 
>The problem is I don't have individual observations of the data.
>I only have the sufficient statistics (mean, variance, # of observations) for each cell. 
>Is there any existing function in S-plus that would allow me to do aov() with the sufficient statistics?
>  
>

See:
David Larsen, Analysis of Variance With Just Summary Statistics
   as Input,  The American Statistician, May 1992, Vol. 46(2), 151-152.

This is implemented in SAS,
  Doc: http://www.math.yorku.ca/SCS/sasmac/stat2dat.html

Shouldn't be hard to do in R.

-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From andy_liaw at merck.com  Wed Feb 18 14:55:45 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 18 Feb 2004 08:55:45 -0500
Subject: [R] pass by reference -- how to do it
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77E7@usrymx25.merck.com>

One needs to be more careful with "<<-" in R than in S-PLUS, because of the
scoping rule difference.  ?"<<-" says:

     The operators '<<-' and '->>' cause a search to made through the
     environment for an existing definition of the variable being
     assigned.  If such a variable is found then its value is
     redefined, otherwise assignment takes place globally. Note that
     their semantics differ from that in the S language, but is useful
     in conjunction with the scoping rules of R.

Andy

> From: Gabor Grothendieck
> 
> If you don't mind NOT passing your arrays at all then you 
> can do this:
> 
> f <- function() a[1] <<- a[1] + 1
> a <- 1:5
> f()  # increments first element of a by 1
> a     # c(2,2,3,4,5)
> 
> The <<- causes the expression to take place in the global 
> environment.
> 
> If you want to actually pass your arrays by reference then the
> following works although its a bit messy:
> 
> g <- function(z) eval(eval(substitute(expression(z[1] <<- z[1]+1))))
> a <- 1:5
> g(a)  # increments first element of a by 1
> a     # c(2,2,3,4,5)
> 
> The <<- causes the expression to be evaluated in the global 
> environment. expression() turns its argument into an object
> of mode expression.  substitute() replaces z with the argument 
> passed to f in that expression and returns an object of mode 
> call.  The inner eval turns the object of mode call into an 
> object of mode expression and the outer eval evaluates that 
> expression.  
> 
> ---
> Date:   Tue, 17 Feb 2004 13:23:58 -0800 (PST) 
> From:   Robert Dodier <robert_dodier at yahoo.com>
> To:   <r-help at stat.math.ethz.ch> 
> Subject:   [R] pass by reference -- how to do it 
> 
>  
> Hello,
> 
> Pass by reference appears to be a topic which comes up
> from time to time, but I wasn't able to find something in
> the R-help archives which tells how to accomplish it.
> 
> I have a problem that you may have seen before -- R runs
> out of memory when processing large matrices. Part of the
> problem for me is that I am using some large matrices as
> function arguments, and these are modified, which leads 
> to allocating copies of the matrices. 
> 
> I would like to do the modification "in place" so that
> a copy is not required. Thanks for any light you can shed
> on this.
> 
> If you're tempted to tell me "you don't really want to do that" --
> let me save you the trouble. You are so very right! Indeed I
> don't want to have pass by reference variables. OTOH I don't
> want R to come to a dead halt at an inconvenient time either.
> 
> Thanks for your help,
> Robert Dodier
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From gcendoya at balcarce.inta.gov.ar  Wed Feb 18 14:55:12 2004
From: gcendoya at balcarce.inta.gov.ar (CENDOYA, Gabriela)
Date: Wed, 18 Feb 2004 10:55:12 -0300
Subject: [R] parse error in GLMM function
Message-ID: <000b01c3f626$d4d317e0$b54a6cc8@gcendoya.balcarce.inta.gov.ar>


"Douglas Bates" write:

>"CENDOYA, Gabriela" <gcendoya at balcarce.inta.gov.ar> writes:
>I'm trying to use the function GLMM from lme4 package, (R-1.8.1, Windows
>> 98),and I get the following error:
> > pd5 = GLMM(nplant~sitio+
>> + fert+
>> + remo+
>> + sitio:fert+
>> + remo:sitio+
>> + remo:fert+
>> + remo:fert:sitio
>> + data=datos,
>> + family=binomial,
>> + random=~repe:sitio)
>> Error in parse(file, n, text, prompt) : parse error

>Could you tell us the version of the lme4 package please?

lme4  version: 0.4-7


 About the "optional data frame" I didn?t want to sound "picky", I just
mention it because I thought it could be related to the other problem.
 In fact, I am really amazed about how good, complete and clear are the help
pages in R.
Thanks again
Gabriela



From schnitzlerj at gmx.de  Wed Feb 18 15:03:06 2004
From: schnitzlerj at gmx.de (Johannes Schnitzler)
Date: Wed, 18 Feb 2004 15:03:06 +0100 (MET)
Subject: [R] PNG Problem on Windows 98 
Message-ID: <11505.1077112986@www56.gmx.net>


For clarification to my first email (PNG Problem on Windows 98 ), i'm using
R 1.8.1

<.....with the new version of R it is normally no problem to produce very
fast
<graphics in the png format.
<
<In the office i want to work with R - Windows 98 is used.
<There are french versions and english versions of Windows 98 second
edition.
<
<The png graphics are only on one computer correct.
<On the other computers - the x-axis labels, the legend text and the "mtext"
<(on the bottom) is missing. 

Johannes



From dmurdoch at pair.com  Wed Feb 18 15:13:13 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 18 Feb 2004 09:13:13 -0500
Subject: [R] PNG Problem on Windows 98
In-Reply-To: <22554.1077111280@www58.gmx.net>
References: <22554.1077111280@www58.gmx.net>
Message-ID: <u7s630pvo42m4ai0fg5cu1ir1rtrggnq6a@4ax.com>

On Wed, 18 Feb 2004 14:34:40 +0100 (MET), "Johannes Schnitzler"
<schnitzlerj at gmx.de> wrote :

>The png graphics are only on one computer correct.
>On the other computers - the x-axis labels, the legend text and the "mtext"
>(on the bottom) is missing. 
>Attached are simple example files one in jpg (which is ok) and one in png
>format.

I don't have access to a Win98 machine to test any more.  However, I
notice that I've been doing builds with an out of date version of the
PNG library (version 1.2.0).  I've just downloaded 1.2.5, and am
building r-devel with it.

Could you download r-devel from CRAN tomorrow, and see if this bug is
fixed?  (I'll upload it today, but it won't be visible until
tomorrow.)

You should look in

 <http://cran.r-project.org/bin/windows/base/rdevel.html>

to find the download.  Make sure it is dated Feb 18 or later.

Duncan Murdoch



From jcjorgensen at wisc.edu  Wed Feb 18 16:10:27 2004
From: jcjorgensen at wisc.edu (Jeff Jorgensen)
Date: Wed, 18 Feb 2004 09:10:27 -0600
Subject: [R] persp and lines()
In-Reply-To: <Pine.SOL.4.58.0402171944060.13070@timepilot.gpcc.itd.umich.edu>
References: <5.2.1.1.2.20040217175258.022e2590@wiscmail.wisc.edu>
	<5.2.1.1.2.20040217175258.022e2590@wiscmail.wisc.edu>
Message-ID: <5.2.1.1.2.20040218085409.021fb798@wiscmail.wisc.edu>

Tom,

Thanks for the nudge to reexamine the instructions.  I wasn't calling the 
right object with "pmat".  I first had to create a perspective plot object 
which creates the plot, and then call *that* object for "pmat", not the 
matrix I used to create the plot in the first place:

surface<-persp(x=..., y=..., z=perspmatrix, ....)

## function needed to add things to persp, found in the ?persp help menu ##
trans3d <- function(x,y,z, pmat) {
        tr <- cbind(x,y,z,1) %*% pmat
        list(x = tr[,1]/tr[,4], y= tr[,2]/tr[,4])
      }

lines(trans3d(x=..., y=..., z=..., pmat=surface), ...)



At 07:45 PM 2/17/2004 -0500, you wrote:
>Jeff  -
>
>See the section titled "Value:" and example (2) from  help("persp")
>for instructions and an example of doing exactly what you ask.
>
>-  tom blackwell  -  u michigan medical school  -  ann arbor  -
>
>On Tue, 17 Feb 2004, Jeff Jorgensen wrote:
>
> > R-sters:
> >
> > I'm interested in keeping data plotted in persp to preserve the wireframe
> > look, I'd just like to change one of the lines drawn (in either the x or y
> > direction) into a different color so that it stands out.
> >
> > Or is there some way to add a line (say, via lines(), or abline()) to a
> > persp() plot at the designated x or y that would follow the z surface
> > contour?  I could add a line using 2D representations of the data, but I'd
> > like to use the perspective plot if possible.
> >
> > Any advice?
> >
> > Cheers,
> >
> > Jeff
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >



From hxc05 at health.state.ny.us  Wed Feb 18 16:39:29 2004
From: hxc05 at health.state.ny.us (Haiyan Chen)
Date: Wed, 18 Feb 2004 10:39:29 -0500
Subject: [R] How to repeat a procedure
Message-ID: <OF5F33C567.A1B22A84-ON85256E3E.0055D43D@health.state.ny.us>

Hello,

1. After I generate a 100x50 matrix by x3<-matrix(0,100,50);for (i in
1:100) {x1<-rpois(50, mu[i]);x2<-x1; x2[runif(50)<.01]<-0; x3[i,]<-x2},

2. I want to calculate means and sample variances of each row and create a
new matrix 100x2;

3. I then want to repeat above procedure 500 times so that eventually I
will have 500 100x2 matrices.

Would someone mind helping me to code 2 & 3?

Thanks ahead of time.

Heyen



From kjetil at entelnet.bo  Wed Feb 18 17:07:46 2004
From: kjetil at entelnet.bo (kjetil@entelnet.bo)
Date: Wed, 18 Feb 2004 12:07:46 -0400
Subject: [R] Help with multiple graphs on one set of axis
In-Reply-To: <003701c3f58a$28b13560$11ee0804@dslverizon.net>
Message-ID: <40335592.9993.36E8E2@localhost>

On 17 Feb 2004 at 11:13, Phillip Good wrote:

> Can you suggest code to plot two cumulative distribution functions on
> the same set of axis?
> 

> library(stepfun)
> x <- rnorm(100)
> y <- rnorm(110, 0.5)
> plot(ecdf(x), col.p="red",col.h="red",col.v="red")
> plot(ecdf(y),add=TRUE, col.p="blue",col.h="blue",col.v="blue")

Kjetil Halvorsen


> Phillp Good
> 
> "Never trust anything that can think for itself if you can't see where
> it keeps its brain."  Mr. Weasley
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From dfs at research.att.com  Wed Feb 18 17:34:10 2004
From: dfs at research.att.com (Deborah Swayne)
Date: Wed, 18 Feb 2004 11:34:10 -0500
Subject: [R] building the development version
Message-ID: <16435.37890.689870.747788@fry.research.att.com>


I'm trying to build the current development version of R on an SGI
running IRIX6.5.  Everything proceeds merrily until I reach the eda
package.  This is the error message I get if I cd to the appropriate
directory and type 'make' or 'make all.'  Does this make sense to
anyone?  -- Thanks, Debby

gmake[3]: Entering directory `/l/fsc/dfs/src/R/src/library/eda'
building package 'eda'
../../../library/eda/R/eda is unchanged
../../../library/eda/man/eda.Rd is unchanged
/home/dfs/src/R/src/library/eda/src
gmake[4]: Entering directory `/l/fsc/dfs/src/R/src/library/eda/src'
config.status: error: invalid argument: src/library/eda/src/Makefile



From tlumley at u.washington.edu  Wed Feb 18 17:41:05 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 18 Feb 2004 08:41:05 -0800 (PST)
Subject: [R] How to repeat a procedure
In-Reply-To: <OF5F33C567.A1B22A84-ON85256E3E.0055D43D@health.state.ny.us>
References: <OF5F33C567.A1B22A84-ON85256E3E.0055D43D@health.state.ny.us>
Message-ID: <Pine.A41.4.58.0402180833480.132464@homer05.u.washington.edu>

On Wed, 18 Feb 2004, Haiyan Chen wrote:

> Hello,
>
> 1. After I generate a 100x50 matrix by x3<-matrix(0,100,50);for (i in
> 1:100) {x1<-rpois(50, mu[i]);x2<-x1; x2[runif(50)<.01]<-0; x3[i,]<-x2},

YOu can do this without the loop, eg

x3<-rpois(50*100, rep(mu,each=100))
x3<-ifelse(runif(50*100)<0.01, 0, x3)
x3<-matrix(x3, ncol=50)

> 2. I want to calculate means and sample variances of each row and create a
> new matrix 100x2;

means<-apply(x3,2,mean)
vars<-apply(x3,2,var)
cbind(means,vars)

> 3. I then want to repeat above procedure 500 times so that eventually I
> will have 500 100x2 matrices.

make.a.matrix<-function(...){
	x3<-rpois(50*100, rep(mu,each=100))
	x3<-ifelse(runif(50*100)<0.01, 0, x3)
	x3<-matrix(x3, ncol=50)
	cbind(apply(x3,2,mean), apply(x3,2, var))
}

many.matrices<-lapply(1:500, make.a.matrix)

gives a list of 500 matrices.  This isn't quite the most efficient
solution, but it's not bad.


	-thomas



From svetlana.eden at vanderbilt.edu  Wed Feb 18 17:45:23 2004
From: svetlana.eden at vanderbilt.edu (Svetlana Eden)
Date: Wed, 18 Feb 2004 10:45:23 -0600
Subject: [R] interesting feature
Message-ID: <20040218104523.223796e9.svetlana.eden@vanderbilt.edu>

Hi, everybody.
This was an interesting discussion last time and it helped me a lot.

Could you please have a look at some feature and tell me
why it was designed this way
(my questions are under #########)

> x = c(1, 10)
> y = c(99, 55)
> d <- data.frame(x = x, y = y)
> d
   x  y
1  1 99
2 10 55
> add <- data.frame(x = 14, y = 99)
> add
   x  y
1 14 99
> d <- rbind(d, add)
> d
    x  y
1   1 99
2  10 55
11 14 99
######### it would be more natural to index the rows: 1,2,3 instead of
#1,2,11  ?!
>
> d[3,1]
[1] 14
> d[11,1]
[1] NA
######### especially if index '11' is not functioning...
>
> add1 <- data.frame(x = 10, y = 87)
> d <- rbind(d, add)
######### now I would think that the next index should be 21, BUT:
> d
    x  y
1   1 99
2  10 55
11 14 99
12 10 87
######### so what is the intuition of such indexing?


-- 
Svetlana Eden        Biostatistician II            School of Medicine
                     Department of Biostatistics   Vanderbilt University



From rossini at blindglobe.net  Wed Feb 18 17:47:30 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 18 Feb 2004 08:47:30 -0800
Subject: [R] building the development version
In-Reply-To: <16435.37890.689870.747788@fry.research.att.com> (Deborah
	Swayne's message of "Wed, 18 Feb 2004 11:34:10 -0500")
References: <16435.37890.689870.747788@fry.research.att.com>
Message-ID: <85ekssz659.fsf@servant.blindglobe.net>


Are you rebuilding?  

    ./config.status 

might need to be run to remake the Makefile, or:

      ./config.status --recheck ; ./config.status

(from top level directory in the R tree).  I've had the same problems
before. 

Deborah Swayne <dfs at research.att.com> writes:

> I'm trying to build the current development version of R on an SGI
> running IRIX6.5.  Everything proceeds merrily until I reach the eda
> package.  This is the error message I get if I cd to the appropriate
> directory and type 'make' or 'make all.'  Does this make sense to
> anyone?  -- Thanks, Debby
>
> gmake[3]: Entering directory `/l/fsc/dfs/src/R/src/library/eda'
> building package 'eda'
> ../../../library/eda/R/eda is unchanged
> ../../../library/eda/man/eda.Rd is unchanged
> /home/dfs/src/R/src/library/eda/src
> gmake[4]: Entering directory `/l/fsc/dfs/src/R/src/library/eda/src'
> config.status: error: invalid argument: src/library/eda/src/Makefile
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From ripley at stats.ox.ac.uk  Wed Feb 18 17:56:03 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Feb 2004 16:56:03 +0000 (GMT)
Subject: [R] building the development version
In-Reply-To: <16435.37890.689870.747788@fry.research.att.com>
Message-ID: <Pine.LNX.4.44.0402181652490.1418-100000@gannet.stats>

On Wed, 18 Feb 2004, Deborah Swayne wrote:

> I'm trying to build the current development version of R on an SGI
> running IRIX6.5.  Everything proceeds merrily until I reach the eda
> package.  This is the error message I get if I cd to the appropriate
> directory and type 'make' or 'make all.'  Does this make sense to
> anyone?  -- Thanks, Debby

There should be no such directory.  Did you do this in a clean build 
directory, as this is what would happen if you try to rebuild over 
sources from a couple of months ago?  Please try again starting in an 
empty build directory.

> 
> gmake[3]: Entering directory `/l/fsc/dfs/src/R/src/library/eda'
> building package 'eda'
> ../../../library/eda/R/eda is unchanged
> ../../../library/eda/man/eda.Rd is unchanged
> /home/dfs/src/R/src/library/eda/src
> gmake[4]: Entering directory `/l/fsc/dfs/src/R/src/library/eda/src'
> config.status: error: invalid argument: src/library/eda/src/Makefile

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From JonesW at kssg.com  Wed Feb 18 17:52:12 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Wed, 18 Feb 2004 16:52:12 -0000
Subject: [R] How to repeat a procedure
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0FB4@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040218/549e02fd/attachment.pl

From ripley at stats.ox.ac.uk  Wed Feb 18 18:04:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Feb 2004 17:04:55 +0000 (GMT)
Subject: [R] interesting feature
In-Reply-To: <20040218104523.223796e9.svetlana.eden@vanderbilt.edu>
Message-ID: <Pine.LNX.4.44.0402181702040.1476-100000@gannet.stats>

You are adding a row with name "1" each time.  R just adds a suffix to 
make it unique.  What you call indices are the *row names* of the data 
frame.

Suppose the row name had been "Eden".  Then "Eden1" and "Eden2" make more 
sense than your suggestions.

On Wed, 18 Feb 2004, Svetlana Eden wrote:

> Hi, everybody.
> This was an interesting discussion last time and it helped me a lot.
> 
> Could you please have a look at some feature and tell me
> why it was designed this way
> (my questions are under #########)
> 
> > x = c(1, 10)
> > y = c(99, 55)
> > d <- data.frame(x = x, y = y)
> > d
>    x  y
> 1  1 99
> 2 10 55
> > add <- data.frame(x = 14, y = 99)
> > add
>    x  y
> 1 14 99
> > d <- rbind(d, add)
> > d
>     x  y
> 1   1 99
> 2  10 55
> 11 14 99
> ######### it would be more natural to index the rows: 1,2,3 instead of
> #1,2,11  ?!
> >
> > d[3,1]
> [1] 14
> > d[11,1]
> [1] NA
> ######### especially if index '11' is not functioning...

You need "11": it is a row name and not a row index.

> > add1 <- data.frame(x = 10, y = 87)
> > d <- rbind(d, add)
> ######### now I would think that the next index should be 21, BUT:
> > d
>     x  y
> 1   1 99
> 2  10 55
> 11 14 99
> 12 10 87
> ######### so what is the intuition of such indexing?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Wed Feb 18 18:04:26 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 18 Feb 2004 11:04:26 -0600
Subject: [R] parse error in GLMM function
In-Reply-To: <000b01c3f626$d4d317e0$b54a6cc8@gcendoya.balcarce.inta.gov.ar>
References: <000b01c3f626$d4d317e0$b54a6cc8@gcendoya.balcarce.inta.gov.ar>
Message-ID: <6rr7ws1fqd.fsf@bates4.stat.wisc.edu>

"CENDOYA, Gabriela" <gcendoya at balcarce.inta.gov.ar> writes:

> Douglas Bates write:
> 
> >"CENDOYA, Gabriela" <gcendoya at balcarce.inta.gov.ar> writes:
> >I'm trying to use the function GLMM from lme4 package, (R-1.8.1, Windows
> >> 98),and I get the following error:
> > > pd5 = GLMM(nplant~sitio+
> >> + fert+
> >> + remo+
> >> + sitio:fert+
> >> + remo:sitio+
> >> + remo:fert+
> >> + remo:fert:sitio
> >> + data=datos,
> >> + family=binomial,
> >> + random=~repe:sitio)
> >> Error in parse(file, n, text, prompt) : parse error
> 
> >Could you tell us the version of the lme4 package please?
> 
> lme4  version: 0.4-7
> 
> 
>  About the optional data frame I didn't want to sound picky, I just
> mention it because I thought it could be related to the other problem.
>  In fact, I am really amazed about how good, complete and clear are the help
> pages in R.

My response about being picky was intended to be a joke.  Having the
code fail to agree with the documentation is definitely a bug in
either the code or the documentation, which is why I said "thanks for
pointing this out".  Sorry that my reply didn't sound the way that I
had intended it.



From bates at stat.wisc.edu  Wed Feb 18 18:14:23 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 18 Feb 2004 11:14:23 -0600
Subject: [R] interesting feature
In-Reply-To: <20040218104523.223796e9.svetlana.eden@vanderbilt.edu>
References: <20040218104523.223796e9.svetlana.eden@vanderbilt.edu>
Message-ID: <6risi41f9s.fsf@bates4.stat.wisc.edu>

Svetlana Eden <svetlana.eden at vanderbilt.edu> writes:

> Hi, everybody.
> This was an interesting discussion last time and it helped me a lot.
> 
> Could you please have a look at some feature and tell me
> why it was designed this way
> (my questions are under #########)
> 
> > x = c(1, 10)
> > y = c(99, 55)
> > d <- data.frame(x = x, y = y)
> > d
>    x  y
> 1  1 99
> 2 10 55
> > add <- data.frame(x = 14, y = 99)
> > add
>    x  y
> 1 14 99
> > d <- rbind(d, add)
> > d
>     x  y
> 1   1 99
> 2  10 55
> 11 14 99
> ######### it would be more natural to index the rows: 1,2,3 instead of
> #1,2,11  ?!

It's not the number 11, it is the string "11".

Row names are character strings.  In your original data frame the row
names were "1" and "2" for the first frame and "1" for the second.
The rbind function should not create a duplicate row name so it
prepended a "1" to all the names in the second frame.  That explains
the "11" and "12" in your last example.  They are simply the original
names "1" and "2" with a "1" prepended to them.

> >
> > d[3,1]
> [1] 14
> > d[11,1]

Try d["11", 1]

> [1] NA
> ######### especially if index '11' is not functioning...
> >
> > add1 <- data.frame(x = 10, y = 87)
> > d <- rbind(d, add)
> ######### now I would think that the next index should be 21, BUT:
> > d
>     x  y
> 1   1 99
> 2  10 55
> 11 14 99
> 12 10 87
> ######### so what is the intuition of such indexing?



From s-plus at wiwi.uni-bielefeld.de  Wed Feb 18 18:23:11 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Wed, 18 Feb 2004 18:23:11 +0100
Subject: [R] How to repeat a procedure
References: <OF5F33C567.A1B22A84-ON85256E3E.0055D43D@health.state.ny.us>
Message-ID: <40339F7F.50402@wiwi.uni-bielefeld.de>

Haiyan Chen wrote:

>Hello,
>
>1. After I generate a 100x50 matrix by x3<-matrix(0,100,50);for (i in
>1:100) {x1<-rpois(50, mu[i]);x2<-x1; x2[runif(50)<.01]<-0; x3[i,]<-x2},
>
>
>2. I want to calculate means and sample variances of each row and create a
>new matrix 100x2;
>
Try:

mean.var<-function(n=10, m=5){
 mu<-(1:n)^2
 x<-matrix(rpois(n*m,mu),n,m)
 stat<-t(apply(x,1,function(x)c(mean(x),var(x))))
}

to set some elements of x to zero you can add an additional line in mean.var

>3. I then want to repeat above procedure 500 times so that eventually I
>will have 500 100x2 matrices.
>
n<-100; m<-50
n.comp<-500
for(i in 1:n.comp) 
eval(parse(text=paste("result",i,"<-mean.var(n,m)",sep="")))


Peter

>Would someone mind helping me to code 2 & 3?
>
>Thanks ahead of time.
>
>Heyen
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From thpe at hhbio.wasser.tu-dresden.de  Wed Feb 18 18:23:23 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Wed, 18 Feb 2004 18:23:23 +0100
Subject: [R] interesting feature
In-Reply-To: <20040218104523.223796e9.svetlana.eden@vanderbilt.edu>
References: <20040218104523.223796e9.svetlana.eden@vanderbilt.edu>
Message-ID: <40339F8B.6040003@hhbio.wasser.tu-dresden.de>

Svetlana Eden wrote:

> Hi, everybody.
> This was an interesting discussion last time and it helped me a lot.
> 
> Could you please have a look at some feature and tell me
> why it was designed this way

What you see in the first column are the row names. The index is 1,2,3,4 
as usual.

Thomas P.



From treebc at telus.net  Wed Feb 18 18:29:38 2004
From: treebc at telus.net (treebc@telus.net)
Date: Wed, 18 Feb 2004 09:29:38 -0800
Subject: [R] Generalized Estimating Equations and log-likelihood calculation
Message-ID: <1077125378.4033a10213b47@webmail.telus.net>

Hi there,

I'm working with clustered data sets and trying to calculate log-likelihood 
(and/or AIC, AICc) for my models.  In using the gee and geese packages one 
gets Wald test output; but apparently there is no no applicable method 
for "logLik" (log-likelihood)calculation.

Is anyone aware of a way to calculate log-likelihood for GEE models?

Thanks for the help,
Bruce



From supratik at stat.ucc.ie  Wed Feb 18 18:35:41 2004
From: supratik at stat.ucc.ie (Roy, Supratik)
Date: Wed, 18 Feb 2004 17:35:41 -0000
Subject: [R] Interesting feature
Message-ID: <F64493091FAC4D4DAC46261FEC1967995FDC05@xch4.ucc.ie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040218/1d1e7962/attachment.pl

From jeff.hamann at forestinformatics.com  Wed Feb 18 18:40:28 2004
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Wed, 18 Feb 2004 09:40:28 -0800
Subject: [R] return a list of vectors from C?
Message-ID: <03a101c3f646$55855190$0a00a8c0@rodan>

I've been working on a shared library that will be called from R. The
functions pass several vectors in and out (residuals, parameters, etc) and I
would like to be able to return a list of objects. I'm familiar with return
single objects (vectors, etc) from a C function, but need a little help for
returning a list of objects.

My code so far looks something like:

/* this function will perform the same tasks as the previous */
/* and return a list of the values rather than just the  */
/* optimal values. It should return the optimization info as */
/* well as the residual values from the flikam function  */
SEXP testfunc2(
   SEXP *pq,
   SEXP *obs )
{

   int  i;
   double *pq_vect;
   double *obs_vect;

   SEXP  ret_val;

   PROTECT( pq = coerceVector( pq, REALSXP ) );
   PROTECT( obs = coerceVector( obs, REALSXP ) );

   pq_vect = REAL( pq );
   obs_vect = REAL( obs );


   /* call my functions for the results */


   /* generate the output list */
   PROTECT( ret_val = allocVector( VECSXP, NPQ ) );
   for( i = 0; i < NPQ; i++ )
   {
      //REAL(ret_val)[i] = XMIN[i];
      //PROTECT( ret_val = allocVector( VECSXP, NPQ ) );
      //SET_VECTOR_ELT( ret_val, i, 3.14159 );

      //SET_VECTOR_ELT( ret_val, i, pq );


      /* generate the output vector */
/*       PROTECT( ret_val = allocVector( REALSXP, NPQ ) ); */
/*       for( i = 0; i < NPQ; i++ ) */
/*       { */
/*   REAL(ret_val)[i] = XMIN[i]; */
/*       } */

   }

   UNPROTECT( 3 );

   return ret_val;

}


What package would be a good example of how to do this?

Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
(office) 541-754-1428
(cell) 541-740-5988
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From p.pagel at gsf.de  Wed Feb 18 18:40:04 2004
From: p.pagel at gsf.de (Philipp Pagel)
Date: Wed, 18 Feb 2004 18:40:04 +0100
Subject: [R] interesting feature
In-Reply-To: <20040218104523.223796e9.svetlana.eden@vanderbilt.edu>
References: <20040218104523.223796e9.svetlana.eden@vanderbilt.edu>
Message-ID: <20040218174002.GA10321@porcupine.gsf.de>

	Hi!

On Wed, Feb 18, 2004 at 10:45:23AM -0600, Svetlana Eden wrote:
> > d <- rbind(d, add)
> > d
>     x  y
> 1   1 99
> 2  10 55
> 11 14 99
> ######### it would be more natural to index the rows: 1,2,3 instead of
> #1,2,11  ?!

What you see in the first column are row-names not indexes. Since both
data frames had a row named '1' there was a conflict which R is trying
to resolve by appending '1'.

> ######### especially if index '11' is not functioning...
...
> ######### now I would think that the next index should be 21, BUT:
...
> ######### so what is the intuition of such indexing?

I think it all becomes clear if you try this:

> a <- data.frame(foo=1:5, bar=10:6, row.names=LETTERS[1:5])
> a
  foo bar
A   1  10
B   2   9
C   3   8
D   4   7
E   5   6
> b <- data.frame(foo=c(9,10), bar=c(99,98), row.names=c('A','B'))
> b
  foo bar
A   9  99
B  10  98
> rbind(a,b)
   foo bar
A    1  10
B    2   9
C    3   8
D    4   7
E    5   6
A1   9  99
B1  10  98

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany
http://mips.gsf.de/~pagel



From rossini at blindglobe.net  Wed Feb 18 19:01:41 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 18 Feb 2004 10:01:41 -0800
Subject: [R] building the development version
In-Reply-To: <Pine.LNX.4.44.0402181652490.1418-100000@gannet.stats> (Brian
	Ripley's message of "Wed, 18 Feb 2004 16:56:03 +0000 (GMT)")
References: <Pine.LNX.4.44.0402181652490.1418-100000@gannet.stats>
Message-ID: <85wu6kxo56.fsf@servant.blindglobe.net>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Wed, 18 Feb 2004, Deborah Swayne wrote:
>
>> I'm trying to build the current development version of R on an SGI
>> running IRIX6.5.  Everything proceeds merrily until I reach the eda
>> package.  This is the error message I get if I cd to the appropriate
>> directory and type 'make' or 'make all.'  Does this make sense to
>> anyone?  -- Thanks, Debby
>
> There should be no such directory.  Did you do this in a clean build 
> directory, as this is what would happen if you try to rebuild over 
> sources from a couple of months ago?  Please try again starting in an 
> empty build directory.

This directory exists on a clean anonCVS checkout, cvs co, followed
with a cvs update -Pd.  Done AFTER Debbie's post, on a new machine.

I verified Debbie's results, and the solution I suggested (2
incantations, with a weird incantation and the removal of the eda
subdir) got me most of the way there.  The second incantation was
needed to cope with a problem in the ctest directory.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From femke at geog.umd.edu  Wed Feb 18 19:03:32 2004
From: femke at geog.umd.edu (femke)
Date: Wed, 18 Feb 2004 13:03:32 -0500
Subject: [R] overlay points on plot
Message-ID: <00ad01c3f649$8ec2c340$72180281@jawks2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040218/e3667c92/attachment.pl

From ripley at stats.ox.ac.uk  Wed Feb 18 19:08:32 2004
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 18 Feb 2004 18:08:32 +0000 (GMT Standard Time)
Subject: [R] building the development version
In-Reply-To: <85wu6kxo56.fsf@servant.blindglobe.net>
References: <Pine.LNX.4.44.0402181652490.1418-100000@gannet.stats>
	<85wu6kxo56.fsf@servant.blindglobe.net>
Message-ID: <Pine.WNT.4.58.0402181801260.2428@auk>

On Wed, 18 Feb 2004, A.J. Rossini wrote:

> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
>
> > On Wed, 18 Feb 2004, Deborah Swayne wrote:
> >
> >> I'm trying to build the current development version of R on an SGI
> >> running IRIX6.5.  Everything proceeds merrily until I reach the eda
> >> package.  This is the error message I get if I cd to the appropriate
> >> directory and type 'make' or 'make all.'  Does this make sense to
> >> anyone?  -- Thanks, Debby
> >
> > There should be no such directory.  Did you do this in a clean build
> > directory, as this is what would happen if you try to rebuild over
> > sources from a couple of months ago?  Please try again starting in an
> > empty build directory.
>
> This directory exists on a clean anonCVS checkout, cvs co, followed
> with a cvs update -Pd.  Done AFTER Debbie's post, on a new machine.

Looks like there is a problem with anonCVS.  That directory is empty
in the master CVS tree and hence does not appear in the daily snapshots.
I've just checked: it is not there in R-devel_2004-02-18.tar.bz2.

What is in it under anonCVS?

> I verified Debbie's results, and the solution I suggested (2
> incantations, with a weird incantation and the removal of the eda
> subdir) got me most of the way there.  The second incantation was
> needed to cope with a problem in the ctest directory.

Looks like we need to take some preventative measures in any case ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pburns at pburns.seanet.com  Wed Feb 18 19:09:16 2004
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Wed, 18 Feb 2004 18:09:16 +0000
Subject: [R] How to repeat a procedure
References: <OF5F33C567.A1B22A84-ON85256E3E.0055D43D@health.state.ny.us>
	<Pine.A41.4.58.0402180833480.132464@homer05.u.washington.edu>
Message-ID: <4033AA4C.70407@pburns.seanet.com>

I believe that Thomas got "mu" wrong.  If I understand
correctly, the line:

x3 <- rpois(50 * 100, rep(mu, each=100))

should read:

x3 <- rpois(50 * 100, rep(mu, 50))

or just

x3 <- rpois(50 * 100, mu)

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Thomas Lumley wrote:

>On Wed, 18 Feb 2004, Haiyan Chen wrote:
>
>  
>
>>Hello,
>>
>>1. After I generate a 100x50 matrix by x3<-matrix(0,100,50);for (i in
>>1:100) {x1<-rpois(50, mu[i]);x2<-x1; x2[runif(50)<.01]<-0; x3[i,]<-x2},
>>    
>>
>
>YOu can do this without the loop, eg
>
>x3<-rpois(50*100, rep(mu,each=100))
>x3<-ifelse(runif(50*100)<0.01, 0, x3)
>x3<-matrix(x3, ncol=50)
>
>  
>
>>2. I want to calculate means and sample variances of each row and create a
>>new matrix 100x2;
>>    
>>
>
>means<-apply(x3,2,mean)
>vars<-apply(x3,2,var)
>cbind(means,vars)
>
>  
>
>>3. I then want to repeat above procedure 500 times so that eventually I
>>will have 500 100x2 matrices.
>>    
>>
>
>make.a.matrix<-function(...){
>	x3<-rpois(50*100, rep(mu,each=100))
>	x3<-ifelse(runif(50*100)<0.01, 0, x3)
>	x3<-matrix(x3, ncol=50)
>	cbind(apply(x3,2,mean), apply(x3,2, var))
>}
>
>many.matrices<-lapply(1:500, make.a.matrix)
>
>gives a list of 500 matrices.  This isn't quite the most efficient
>solution, but it's not bad.
>
>
>	-thomas
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From isen at molbio.mgh.harvard.edu  Wed Feb 18 19:30:34 2004
From: isen at molbio.mgh.harvard.edu (Thomas Isenbarger)
Date: Wed, 18 Feb 2004 13:30:34 -0500
Subject: [R] (no subject)
Message-ID: <8A512C5D-6240-11D8-AA66-000A9598473A@molbio.mgh.harvard.edu>

R folks:

this is my first posting, so please forgive me if i have missed 
something on this in the archives or other documentation.

I have been trying to use gplot to draw a network diagram.  can anyone 
suggest a method to minimise the number of edges that cross?  do i need 
to use the stringrepulse mode and tweak some of the parameters?

Cheers,
Tom I.
--
dr tom isenbarger phd
isen at molbio.mgh.harvard.edu
harvard medical school department of genetics
massachusetts general hospital department of molecular biology
telephone:  617.726.5973
facsimile:   617.726.6893



From p.dalgaard at biostat.ku.dk  Wed Feb 18 19:31:41 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Feb 2004 19:31:41 +0100
Subject: [R] building the development version
In-Reply-To: <85wu6kxo56.fsf@servant.blindglobe.net>
References: <Pine.LNX.4.44.0402181652490.1418-100000@gannet.stats>
	<85wu6kxo56.fsf@servant.blindglobe.net>
Message-ID: <x24qtos0he.fsf@biostat.ku.dk>

rossini at blindglobe.net (A.J. Rossini) writes:

> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> 
> > On Wed, 18 Feb 2004, Deborah Swayne wrote:
> >
> >> I'm trying to build the current development version of R on an SGI
> >> running IRIX6.5.  Everything proceeds merrily until I reach the eda
> >> package.  This is the error message I get if I cd to the appropriate
> >> directory and type 'make' or 'make all.'  Does this make sense to
> >> anyone?  -- Thanks, Debby
> >
> > There should be no such directory.  Did you do this in a clean build 
> > directory, as this is what would happen if you try to rebuild over 
> > sources from a couple of months ago?  Please try again starting in an 
> > empty build directory.
> 
> This directory exists on a clean anonCVS checkout, cvs co, followed
> with a cvs update -Pd.  Done AFTER Debbie's post, on a new machine.

There should actually be an eda directory. On my system, with a fresh
checkout from the developer CVS, it ends up building a package
containing only

.noGenerics <- TRUE

.First.lib <- function(lib, pkg)
{
    have.stats <- "package:stats" %in% search()
    if(!have.stats) require("stats")
    warning("package ", sQuote("eda"), " has been merged into ",
            sQuote("stats"), call. = FALSE)
}

I can't reproduce Debbie's problem though...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From andy_liaw at merck.com  Wed Feb 18 19:00:15 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 18 Feb 2004 13:00:15 -0500
Subject: [R] interesting feature
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77EC@usrymx25.merck.com>

> From: Svetlana Eden
> 
> Hi, everybody.
> This was an interesting discussion last time and it helped me a lot.
> 
> Could you please have a look at some feature and tell me
> why it was designed this way
> (my questions are under #########)

I give it a shot...
 
> > x = c(1, 10)
> > y = c(99, 55)
> > d <- data.frame(x = x, y = y)
> > d
>    x  y
> 1  1 99
> 2 10 55
> > add <- data.frame(x = 14, y = 99)
> > add
>    x  y
> 1 14 99
> > d <- rbind(d, add)
> > d
>     x  y
> 1   1 99
> 2  10 55
> 11 14 99
> ######### it would be more natural to index the rows: 1,2,3 instead of
> #1,2,11  ?!

rownames for data.frame need not be 1, 2, ..., and we need something that's
going to work regardless.

> > d[3,1]
> [1] 14
> > d[11,1]
> [1] NA
> ######### especially if index '11' is not functioning...

This one seems curious to me.  Trying to access non-existing column result
in error:

> d[1,11]
Error in "[.data.frame"(d, 1, 11) : undefined columns selected

OTOH, try:

> d[11,1] <- 1
> dim(d)
[1] 11  2
> d
Error in data.frame(x = c(" 1", "10", "14", "NA", "NA", "NA", "NA", "NA",  :

        duplicate row.names: 11

so that destroys the integrity of the data frame!

> > add1 <- data.frame(x = 10, y = 87)
> > d <- rbind(d, add)
> ######### now I would think that the next index should be 21, BUT:
> > d
>     x  y
> 1   1 99
> 2  10 55
> 11 14 99
> 12 10 87
> ######### so what is the intuition of such indexing?

I believe the rationale is explained in ?make.unique (which
rbind.data.frame() calls to create the rownames).
 
HTH,
Andy

 
> -- 
> Svetlana Eden        Biostatistician II            School of Medicine
>                      Department of Biostatistics   Vanderbilt 
> University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ripley at stats.ox.ac.uk  Wed Feb 18 19:38:35 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Feb 2004 18:38:35 +0000 (GMT)
Subject: [R] building the development version
In-Reply-To: <x24qtos0he.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0402181838030.1651-100000@gannet.stats>

On 18 Feb 2004, Peter Dalgaard wrote:

> rossini at blindglobe.net (A.J. Rossini) writes:
> 
> > Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> > 
> > > On Wed, 18 Feb 2004, Deborah Swayne wrote:
> > >
> > >> I'm trying to build the current development version of R on an SGI
> > >> running IRIX6.5.  Everything proceeds merrily until I reach the eda
> > >> package.  This is the error message I get if I cd to the appropriate
> > >> directory and type 'make' or 'make all.'  Does this make sense to
> > >> anyone?  -- Thanks, Debby
> > >
> > > There should be no such directory.  Did you do this in a clean build 
> > > directory, as this is what would happen if you try to rebuild over 
> > > sources from a couple of months ago?  Please try again starting in an 
> > > empty build directory.
> > 
> > This directory exists on a clean anonCVS checkout, cvs co, followed
> > with a cvs update -Pd.  Done AFTER Debbie's post, on a new machine.
> 
> There should actually be an eda directory. On my system, with a fresh

Yes, but no eda/src nor eda/man.

> checkout from the developer CVS, it ends up building a package
> containing only
> 
> .noGenerics <- TRUE
> 
> .First.lib <- function(lib, pkg)
> {
>     have.stats <- "package:stats" %in% search()
>     if(!have.stats) require("stats")
>     warning("package ", sQuote("eda"), " has been merged into ",
>             sQuote("stats"), call. = FALSE)
> }
> 
> I can't reproduce Debbie's problem though...
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From greenberg at ucdavis.edu  Wed Feb 18 19:39:46 2004
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Wed, 18 Feb 2004 10:39:46 -0800
Subject: [R] NAs introduced by coercion warning?
Message-ID: <BC58F172.19A70%greenberg@ucdavis.edu>

I'm running a decision tree on a large dataset, and I'm getting multiple
instances of "NAs introduced by coercion" (> 50).  What does this mean?

--j

-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From p.dalgaard at biostat.ku.dk  Wed Feb 18 19:52:17 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Feb 2004 19:52:17 +0100
Subject: [R] building the development version
In-Reply-To: <Pine.LNX.4.44.0402181838030.1651-100000@gannet.stats>
References: <Pine.LNX.4.44.0402181838030.1651-100000@gannet.stats>
Message-ID: <x2znbgqkym.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On 18 Feb 2004, Peter Dalgaard wrote:
> > > > There should be no such directory.  Did you do this in a clean build 
> > > > directory, as this is what would happen if you try to rebuild over 
> > > > sources from a couple of months ago?  Please try again starting in an 
> > > > empty build directory.
> > > 
> > > This directory exists on a clean anonCVS checkout, cvs co, followed
> > > with a cvs update -Pd.  Done AFTER Debbie's post, on a new machine.
> > 
> > There should actually be an eda directory. On my system, with a fresh
> 
> Yes, but no eda/src nor eda/man.

OK, that I can confirm. They do turn up on a checkout without the -P
option, but disappear after "cvs up -Pd". Tony, Debbie, did you
perhaps configure before attempting to prune the empty dirs? Could you
try 

cvs -d ...blabla... co -P R

        -p

BTW: Make dist appears to be broken?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From femke at geog.umd.edu  Wed Feb 18 20:00:10 2004
From: femke at geog.umd.edu (femke)
Date: Wed, 18 Feb 2004 14:00:10 -0500
Subject: [R] overlay points on plot
References: <OFF5027367.99652D55-ON85256E3E.00682681@nd.convergys.com>
Message-ID: <00c401c3f651$6ef8d150$72180281@jawks2>

Brilliant!   Why the double brackets though?

thanks

femke


----- Original Message ----- 
From: <james.holtman at convergys.com>
To: "femke" <femke at geog.umd.edu>
Sent: Wednesday, February 18, 2004 1:58 PM
Subject: Re: [R] overlay points on plot


>
>
>
>
> have you tried:
>
>  points(v[[2]],v[[3]])
> __________________________________________________________
> James Holtman        "What is the problem you are trying to solve?"
> Executive Consultant  --  Office of Technology, Convergys
> james.holtman at convergys.com
> +1 (513) 723-2929
>
>
>
>                       "femke"
>                       <femke at geog.umd.edu>         To:
<r-help at stat.math.ethz.ch>
>                       Sent by:                     cc:
>                       r-help-bounces at stat.m        Subject:  [R] overlay
points on plot
>                       ath.ethz.ch
>
>
>                       02/18/2004 13:03
>
>
>
>
>
>
>
> Dear R-help list,
>
> I'm trying to overlay a number of data objects in a plot.  Following an
> earlier example on the list I've created an empty plot as follows
>
> > xlim <- range(as.numeric(c("0","10000")))
> > ylim <- range(as.numeric(c("0","25")) )
> > plot(NA, xlim=xlim, ylim=ylim, xlab="distance", ylab="semivariance")
>
> However when I try to plot something on it, I get the following error:
>
> > points(v[2],v[3])
> Error in as.double.default(x) : (list) object cannot be coerced to double
>
> A sample of my data looks like the following V[2]:
>
>        gamma
> 1   0.040000
> 2   0.582500
> 3   1.574545
> 4   7.126500
> .....
>
> and V[3]:
>
>         dist
> 1   470.0426
> 2  1045.6365
> 3  1607.1936
> ....
>
>
> Does anyone have any idea how to fix this?
>
> Thanks very much,
>
> femke
>              [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>
>



From ripley at stats.ox.ac.uk  Wed Feb 18 20:09:13 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Feb 2004 19:09:13 +0000 (GMT)
Subject: [R] overlay points on plot
In-Reply-To: <00ad01c3f649$8ec2c340$72180281@jawks2>
Message-ID: <Pine.LNX.4.44.0402181908400.1758-100000@gannet.stats>

Is v a data frame?  In that case you need v[[2]] and v[[3]], as v[2] is a 
data frame.

On Wed, 18 Feb 2004, femke wrote:

> 
> Dear R-help list,
> 
> I'm trying to overlay a number of data objects in a plot.  Following an earlier example on the list I've created an empty plot as follows
> 
> > xlim <- range(as.numeric(c("0","10000")))
> > ylim <- range(as.numeric(c("0","25")) )
> > plot(NA, xlim=xlim, ylim=ylim, xlab="distance", ylab="semivariance")
> 
> However when I try to plot something on it, I get the following error:
> 
> > points(v[2],v[3])
> Error in as.double.default(x) : (list) object cannot be coerced to double
> 
> A sample of my data looks like the following V[2]:
> 
>        gamma
> 1   0.040000
> 2   0.582500
> 3   1.574545
> 4   7.126500
> .....
> 
> and V[3]:
> 
>         dist
> 1   470.0426
> 2  1045.6365
> 3  1607.1936
> ....
> 
> 
> Does anyone have any idea how to fix this?  
> 
> Thanks very much,
> 
> femke
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ray at mcs.vuw.ac.nz  Wed Feb 18 20:10:24 2004
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Thu, 19 Feb 2004 08:10:24 +1300 (NZDT)
Subject: [R] parse error in GLMM function
Message-ID: <200402181910.i1IJAOcY014833@tahi.mcs.vuw.ac.nz>

"CENDOYA, Gabriela" <gcendoya at balcarce.inta.gov.ar> writes:
> I'm trying to use the function GLMM from lme4 package, (R-1.8.1, Windows
> 98),and I get the following error:
> > pd5 = GLMM(nplant~sitio+
> + fert+
> + remo+
> + sitio:fert+
> + remo:sitio+
> + remo:fert+
> + remo:fert:sitio
> + data=datos,
> + family=binomial,
> + random=~repe:sitio)
> Error in parse(file, n, text, prompt) : parse error

Isn't the problem that you really do have a syntax error?

Note there is no comma before the data=.

Ray



From DJNordlund at aol.com  Wed Feb 18 20:12:08 2004
From: DJNordlund at aol.com (DJNordlund@aol.com)
Date: Wed, 18 Feb 2004 14:12:08 EST
Subject: [R] overlay points on plot
Message-ID: <15c.2d665ffc.2d651308@aol.com>

In a message dated 2/18/2004 10:13:53 AM Pacific Standard Time, 
femke at geog.umd.edu writes:

>Dear R-help list,
>
>I'm trying to overlay a number of data objects in a plot.  Following an 
earlier example on the >list I've created an empty plot as follows
>
>> xlim <- range(as.numeric(c("0","10000")))
>> ylim <- range(as.numeric(c("0","25")) )
>> plot(NA, xlim=xlim, ylim=ylim, xlab="distance", ylab="semivariance")
>
>However when I try to plot something on it, I get the following error:
>
>> points(v[2],v[3])
>Error in as.double.default(x) : (list) object cannot be coerced to double

Try 

points(v[, 2], v[, 3]) ?

Dan Nordlund



From tblackw at umich.edu  Wed Feb 18 20:14:10 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Wed, 18 Feb 2004 14:14:10 -0500 (EST)
Subject: [R] overlay points on plot
In-Reply-To: <00ad01c3f649$8ec2c340$72180281@jawks2>
References: <00ad01c3f649$8ec2c340$72180281@jawks2>
Message-ID: <Pine.SOL.4.58.0402181405120.20643@tetris.gpcc.itd.umich.edu>


The solution is found in  help("Subscript").
The subscripting you show inside the function  points()
returns a data frame of one column.  This is indeed a
list and not a vector.  There are several ways to subscript
a data frame that will return one column as a vector.
If you use one of them, this should all work.

The 40 page document "An Introduction to R" may also be
helpful.  In other words, this is pretty thoroughly covered
in the documentation.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 18 Feb 2004, femke wrote:

>
> Dear R-help list,
>
> I'm trying to overlay a number of data objects in a plot.  Following an earlier example on the list I've created an empty plot as follows
>
> > xlim <- range(as.numeric(c("0","10000")))
> > ylim <- range(as.numeric(c("0","25")) )
> > plot(NA, xlim=xlim, ylim=ylim, xlab="distance", ylab="semivariance")
>
> However when I try to plot something on it, I get the following error:
>
> > points(v[2],v[3])
> Error in as.double.default(x) : (list) object cannot be coerced to double
>
> A sample of my data looks like the following V[2]:
>
>        gamma
> 1   0.040000
> 2   0.582500
> 3   1.574545
> 4   7.126500
> .....
>
> and V[3]:
>
>         dist
> 1   470.0426
> 2  1045.6365
> 3  1607.1936
> ....
>
>
> Does anyone have any idea how to fix this?
>
> Thanks very much,
>
> femke
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Wed Feb 18 20:15:48 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 18 Feb 2004 11:15:48 -0800
Subject: [R] overlay points on plot
In-Reply-To: <00ad01c3f649$8ec2c340$72180281@jawks2>
References: <00ad01c3f649$8ec2c340$72180281@jawks2>
Message-ID: <4033B9E4.5060809@pdf.com>

      What do you get from the following: 

      class(v)
      class(v[2])

      If class(v) is "list", then class(v[2]) will also be "list".  In 
that case try the following: 

	points(v[[2]],v[[3]])

    
      hope this helps.  spencer graves

femke wrote:

>Dear R-help list,
>
>I'm trying to overlay a number of data objects in a plot.  Following an earlier example on the list I've created an empty plot as follows
>
>  
>
>>xlim <- range(as.numeric(c("0","10000")))
>>ylim <- range(as.numeric(c("0","25")) )
>>plot(NA, xlim=xlim, ylim=ylim, xlab="distance", ylab="semivariance")
>>    
>>
>
>However when I try to plot something on it, I get the following error:
>
>  
>
>>points(v[2],v[3])
>>    
>>
>Error in as.double.default(x) : (list) object cannot be coerced to double
>
>A sample of my data looks like the following V[2]:
>
>       gamma
>1   0.040000
>2   0.582500
>3   1.574545
>4   7.126500
>.....
>
>and V[3]:
>
>        dist
>1   470.0426
>2  1045.6365
>3  1607.1936
>....
>
>
>Does anyone have any idea how to fix this?  
>
>Thanks very much,
>
>femke
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From hdoran at nasdc.org  Wed Feb 18 20:21:12 2004
From: hdoran at nasdc.org (Harold Doran)
Date: Wed, 18 Feb 2004 14:21:12 -0500
Subject: [R] Area between CDFs
Message-ID: <66578BFC0BA55348B5907A0F798EE9307A2CC9@ernesto.NASDC.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040218/86d1844d/attachment.pl

From hxc05 at health.state.ny.us  Wed Feb 18 20:14:08 2004
From: hxc05 at health.state.ny.us (Haiyan Chen)
Date: Wed, 18 Feb 2004 14:14:08 -0500
Subject: [R] How to repeat a procedure
Message-ID: <OF0B41662E.67668DE9-ON85256E3E.0063F95B@health.state.ny.us>


Thanks, Patrick. I was aware of that and was able to fix it.

Thanks Tom, Wayne and Peter for all your help.

Heyen



                                                                                                                                       
                      Patrick Burns                                                                                                    
                      <pburns at pburns.se        To:       Thomas Lumley <tlumley at u.washington.edu>                                      
                      anet.com>                cc:       Haiyan Chen <hxc05 at health.state.ny.us>, R-help at stat.math.ethz.ch              
                                               Subject:  Re: [R] How to repeat a procedure                                             
                      02/18/2004 01:09                                                                                                 
                      PM                                                                                                               
                                                                                                                                       
                                                                                                                                       




I believe that Thomas got "mu" wrong.  If I understand
correctly, the line:

x3 <- rpois(50 * 100, rep(mu, each=100))

should read:

x3 <- rpois(50 * 100, rep(mu, 50))

or just

x3 <- rpois(50 * 100, mu)

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Thomas Lumley wrote:

>On Wed, 18 Feb 2004, Haiyan Chen wrote:
>
>
>
>>Hello,
>>
>>1. After I generate a 100x50 matrix by x3<-matrix(0,100,50);for (i in
>>1:100) {x1<-rpois(50, mu[i]);x2<-x1; x2[runif(50)<.01]<-0; x3[i,]<-x2},
>>
>>
>
>YOu can do this without the loop, eg
>
>x3<-rpois(50*100, rep(mu,each=100))
>x3<-ifelse(runif(50*100)<0.01, 0, x3)
>x3<-matrix(x3, ncol=50)
>
>
>
>>2. I want to calculate means and sample variances of each row and create
a
>>new matrix 100x2;
>>
>>
>
>means<-apply(x3,2,mean)
>vars<-apply(x3,2,var)
>cbind(means,vars)
>
>
>
>>3. I then want to repeat above procedure 500 times so that eventually I
>>will have 500 100x2 matrices.
>>
>>
>
>make.a.matrix<-function(...){
>     x3<-ifelse(runif(50*100)<0.01, 0, x3)
>     x3<-matrix(x3, ncol=50)
>     cbind(apply(x3,2,mean), apply(x3,2, var))
>}
>
>many.matrices<-lapply(1:500, make.a.matrix)
>
>gives a list of 500 matrices.  This isn't quite the most efficient
>solution, but it's not bad.
>
>
>     -thomas
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>
>
>



From abunn at montana.edu  Wed Feb 18 20:38:38 2004
From: abunn at montana.edu (Andy Bunn)
Date: Wed, 18 Feb 2004 12:38:38 -0700
Subject: [R] Complex conjugate?
Message-ID: <004801c3f656$dfeeb7d0$78f05a99@msu.montana.edu>

Is there a function in R that returns the complex conjugate of a matrix
(a la 'CONJ' in IDL or 'Conjugate' in Mathmatica)?



From dfs at research.att.com  Wed Feb 18 21:17:09 2004
From: dfs at research.att.com (Deborah Swayne)
Date: Wed, 18 Feb 2004 15:17:09 -0500
Subject: [R] building the development version
In-Reply-To: <x2znbgqkym.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0402181838030.1651-100000@gannet.stats>
	<x2znbgqkym.fsf@biostat.ku.dk>
Message-ID: <16435.51269.373330.463741@fry.research.att.com>

Peter Dalgaard writes:
 > 
 > OK, that I can confirm. They do turn up on a checkout without the -P
 > option, but disappear after "cvs up -Pd". Tony, Debbie, did you
 > perhaps configure before attempting to prune the empty dirs? Could you
 > try 
 > 
 > cvs -d ...blabla... co -P R

I've use rsync; I don't know if that makes any difference:
   rsync -rC rsync.r-project.org::r-devel R

In any case, I deleted all the old source code and started over,
and the development version emerged without any difficulty.

Thanks for helping me think about this.

Debby



From femke at geog.umd.edu  Wed Feb 18 21:44:59 2004
From: femke at geog.umd.edu (femke)
Date: Wed, 18 Feb 2004 15:44:59 -0500
Subject: [R] using names() as a variable in a formula
Message-ID: <011a01c3f660$13466660$72180281@jawks2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040218/85237d77/attachment.pl

From huamanr at mef.gob.pe  Wed Feb 18 21:59:48 2004
From: huamanr at mef.gob.pe (Ricardo Huaman)
Date: Wed, 18 Feb 2004 15:59:48 -0500
Subject: [R] boostrapping at R
Message-ID: <007501c3f662$2526bef0$ea09000a@W00RHUAMAN>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040218/9e26d0d5/attachment.pl

From FWS4 at CDRH.FDA.GOV  Wed Feb 18 21:59:55 2004
From: FWS4 at CDRH.FDA.GOV (Samuelson, Frank*)
Date: Wed, 18 Feb 2004 15:59:55 -0500
Subject: [R] Area between CDFs
Message-ID: <644D9337A02FC24689647BF9E48EC39E08ABB771@drm556>


mf<-c(male,female)
ord<-order(mf);
v<-c(rep(1/length(male),length(male)),rep(-1/length(female),length(female)))
;
mf<-mf[ord];
v<-v[ord];
sum(diff(mf)*(cumsum(v)[1:(length(v)-1)]))

You may not want to integrate cdfs.  They're already probabilities.  :)
Nice analytic statistics exist for just the maximum distance between
the cdfs, for example.

-Frank


-----Original Message-----
From: Harold Doran [mailto:hdoran at nasdc.org] 
Sent: Wednesday, February 18, 2004 2:21 PM
To: R Help
Subject: [R] Area between CDFs


Dear List:
 
I am trying to find the area between two ECDFs. I am examining the gap in
performance between two groups, males and females on a student achievement
test in math, which is a continuous metric.
 
I start by creating a subset of the dataframe 
 
male<-subset(datafile, female="Male")
female<-subset(datafile, female="Female")
 
I then plot the two CDFs via
 
plot.ecdf(male$math)
plot.ecdf(female$math, add=TRUE)
 
This produces the visual display that reveals a gap in performance. What I
would like to do is learn to perform the integration between the two ECDFs
to examine the size of this gap. 
 
I would also like to try and examine the horizontal distance between the two
CDFs via another visual display. In other words, the distance between, say
the 50th percentile, from each CDF (or, the distance along the x-axis from
cdf1 to cdf2 at each percentile. Ideally, I would like to plot this
horizontal gap at each percentile.
 
Secondly, I would like to try and measure and plot the vertical gap, i.e.,
the distance along the y-axis from cdf 1 to cdf2 at each value along the
x-axis.
 
I am not sure if I first need to smooth the ECDFs before performing these
operations.
 
Any help would be appreciated. I hope this makes sense.
 
Harold 
 
 
 
 
 
------
Harold C. Doran
Director of Research and Evaluation
New American Schools
675 N. Washington Street, Suite 220
Alexandria, Virginia 22314
703.647.1628
 <http://www.edperform.net/>  
 
 
 

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at pdf.com  Wed Feb 18 22:00:48 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 18 Feb 2004 15:00:48 -0600
Subject: [R] using names() as a variable in a formula
In-Reply-To: <011a01c3f660$13466660$72180281@jawks2>
References: <011a01c3f660$13466660$72180281@jawks2>
Message-ID: <4033D280.3010109@pdf.com>



femke wrote:

> Greetings List,
> 
> I'm having some trouble with the use of the names function in a formula.  Below is an example of something that works (i.e first line), and the second line is the same formula which doesn't.  I want to be able to reference the column of the dataC table so I can run the variogram iteratively with a loop.
> 
> 
>>v<-variogram(A1~1,loc=~x+y, dataC)
>>v<-variogram(names(dataC[3])~1,loc=~x+y, dataC)
> 
> Error in model.frame(formula, rownames, variables, varnames, extras, extranames,  : 
>         invalid variable type
> 
> Where dataC looks like:
> 
>         x       y   A1   A2  A3
> 1  514030 4793587  0.0  7.9 0.1
> 2  517995 4792516  5.8  5.1 0.0
> 3  514232 4792210  0.0  6.5 0.0
> 
> I though initially that it might need some escape character if quotes are added, and tried the following, but it looks ok.
> 
> 
>>names(dataC[3])
> 
> [1] "A1"
> 
>>mode(names(dataC[3]))
> 
> [1] "character"
> 
>>v<-variogram(as.character(names(dataC[3]))~1,loc=~x+y, dataC)
> 
> Error in model.frame(formula, rownames, variables, varnames, extras, extranames,  : 
>         invalid variable type
> 
>>v<-variogram(as.formula((names(dataC[3]))~1),loc=~x+y, dataC)
> 
> Error in model.frame(formula, rownames, variables, varnames, extras, extranames,  : 
>         invalid variable type
> 
> I'd greatly appreciate any suggestions for fixing this.
> 
> Thanks again,
> 
> femke
> 	[[alternative HTML version deleted]]
> 

You're not building a valid formula. Try this:

v <- list()
for(i in 3:5) {
   gr <- names(dataC[i])
   f <- formula(paste(gr, "1", sep = " ~ "))
   v[[gr]] <- variogram(f, loc = ~ x + y, dataC)
}

BTW, since variogram is not in the base package it would also be helpful 
in the future if you add that you are using the spatial package.

HTH,
Sundar



From dmurdoch at pair.com  Wed Feb 18 22:14:13 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 18 Feb 2004 16:14:13 -0500
Subject: [R] using names() as a variable in a formula
In-Reply-To: <011a01c3f660$13466660$72180281@jawks2>
References: <011a01c3f660$13466660$72180281@jawks2>
Message-ID: <mlk730pt31ovhpcuill9srv1a3dba7blfs@4ax.com>

On Wed, 18 Feb 2004 15:44:59 -0500, "femke" <femke at geog.umd.edu> wrote
>> v<-variogram(A1~1,loc=~x+y, dataC)


What package is variogram in?  The one in spatial takes different
args.

>> v<-variogram(names(dataC[3])~1,loc=~x+y, dataC)

Doing this sort of thing is tricky.  Your names(dataC[3]) is a
character string; you want something there that would be interpreted
as a name instead.  However, as.name(names(dataC[3])) isn't enough.

I think you need to build up the formula using fairly low level stuff,
something like this:

   formula <- as.call(list(as.name('~'), as.name(names(dataC[3])),
quote(1)))

and then do

  variogram(formula, ....)

but a formula constructed this way doesn't work in lm(), so it may not
work in variogram either.

Duncan Murdoch



From sundar.dorai-raj at pdf.com  Wed Feb 18 23:25:13 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 18 Feb 2004 16:25:13 -0600
Subject: [R] NAs introduced by coercion warning?
In-Reply-To: <BC58F172.19A70%greenberg@ucdavis.edu>
References: <BC58F172.19A70%greenberg@ucdavis.edu>
Message-ID: <4033E649.80601@pdf.com>



Jonathan Greenberg wrote:

> I'm running a decision tree on a large dataset, and I'm getting multiple
> instances of "NAs introduced by coercion" (> 50).  What does this mean?
> 
> --j
> 

My guess would be you're trying to convert from character to numeric and 
are unable to do so. As in,

 > as.numeric("A")
[1] NA
Warning message:
NAs introduced by coercion
 > as.numeric("1")
[1] 1
 >

But without more information from you it's impossible to tell.

See the posting guide at

http://www.R-project.org/posting-guide.html

Regards,
Sundar



From abunn at montana.edu  Wed Feb 18 23:29:19 2004
From: abunn at montana.edu (Andy Bunn)
Date: Wed, 18 Feb 2004 15:29:19 -0700
Subject: [R] Conjugate function found disregard pervious posting...
Message-ID: <004a01c3f66e$b9fd5a50$a0a00ecf@simATE>

Sorry for the previous posting. I found the function in ?complex. My
apologies. -Andy



From alistair.campbell at jcu.edu.au  Wed Feb 18 23:41:53 2004
From: alistair.campbell at jcu.edu.au (Alistair Campbell)
Date: Thu, 19 Feb 2004 08:41:53 +1000
Subject: [R] citation() doesn?t work
Message-ID: <4033EA31.3030901@jcu.edu.au>

Hi,

I am using R 1.8.1 on Windows XP and get the following from calling 
citation():

> To cite R in publications, use
>
>   R Development Core Team (2004). R: A language and environment for
>   statistical computing. R Foundation for Statistical Computing,
>   Vienna, Austria. ISBN 3-900051-00-3, URL http://www.R-project.org.
>
> We have invested a lot of effort in creating R, please cite it when
> using it for data analysis.
>
> A BibTeX entry for LaTeX users is
>
>   @Manual{,
>      title        = {R: A language and environment for
>                      statistical computing},
>      author       = {{R Development Core Team}},
>      organization = {R Foundation for Statistical Computing},
>      address      = {Vienna, Austria},
>      year         = 2004,
>      note         = {ISBN 3-900051-00-3},
>      url          = {http://www.R-project.org}
>    }


Seems to work.

Alistair Campbell
James Cook University



From greenberg at ucdavis.edu  Wed Feb 18 23:46:20 2004
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Wed, 18 Feb 2004 14:46:20 -0800
Subject: [R] NAs introduced by coercion warning?
In-Reply-To: <4033E649.80601@pdf.com>
Message-ID: <BC592B3C.19AB2%greenberg@ucdavis.edu>

Its hard for me to pinpoint where this is happening, since I'm working on an
image that?s about 10000 x 20000 pixels, and 12 bands deep and I'm using a
set of for-next loops to pull out subsections of data.  I can guarantee the
input values are all floating point values.

To be more specific, I have created a classification tree, and I want to
apply it to that large floating point image (all the band names match up)
and write the prediction (probability) values to a file.  What happens if a
decision tree tries to classify a set of input values that are completely
outside of the range of the input tree?

Here's the code I was using.  I should mention that this worked on a small
subset (400 x 400 pixels) that wouldn't have any "weird" values (negative or
zero).  The output file from this is turning out to be slightly smaller than
it should given the samples,lines,bands and number type, which I why I'm
wondering if the tree is simply dropping those "bad" values rather than
giving them some value (e.g. 0):

## Creating the tree
library(tree)
bands=12
bandnames<-paste(c("B"),1:bands,sep="")
treetraindata=read.csv("classtrainshad040205.csv",header=TRUE)
names(treetraindata)[2:6]<-bandnames[1:5]
names(treetraindata)[8:14]<-bandnames[6:12]
treetraindata$Class_Name<-as.factor(treetraindata$Class_Name)

## Create an overfit tree
treetrain<-tree(Class_Name ~ B1 + B2 + B3 +
B4+B5+B6+B7+B8+B9+B10+B11+B12,treetraindata,mincut=1,minsize=2,mindev=0)

## Extracts a slice of data out of an ENVI BSQ file
envigetslice<-function(fileconnection,samples,lines,bands,interleave,datatyp
e,maxpixels) {
    currentloc=seek(fileconnection,where=NA,origin="current")
    ## If data is integer
    if(datatype==3) {
        numbersize=2
        datatype=integer()
        if ((samples*lines)-(currentloc/numbersize) < maxpixels)
maxpixels=(samples*lines)-(currentloc/numbersize)
        envislice <-
readBin(fileconnection,integer(),maxpixels,size=numbersize)
        newloc=seek(fileconnection,where=NA,origin="current")
        if (bands > 1) {
            for (i in 1:(bands-1)) {
                
seek(fileconnection,where=currentloc+(samples*lines*numbersize*i),origin="st
art")
                currentslice <-
readBin(fileconnection,integer(),maxpixels,size=numbersize)
                envislice=data.frame(envislice,currentslice)
            }
        }
    }
    ## If data is floating point
    if(datatype==4) {
        numbersize=4
        if ((samples*lines)-(currentloc/numbersize) < maxpixels)
maxpixels=(samples*lines)-(currentloc/numbersize)
        envislice <-
readBin(fileconnection,double(),maxpixels,size=numbersize)
        newloc=seek(fileconnection,where=NA,origin="current")
        if (bands > 1) {
            for (i in 1:(bands-1)) {
                
seek(fileconnection,where=currentloc+(samples*lines*numbersize*i),origin="st
art")
                currentslice <-
readBin(fileconnection,double(),maxpixels,size=numbersize)
                envislice=data.frame(envislice,currentslice)
            }
        }
    }
    seek(fileconnection,where=newloc,origin="start")
    envislice
}

## Read ENVI files in subsets
## interleave: 1=bsq
## datatype: (follows ENVI format):
##    3: long integer
##    4:floating point


## Apply the classifier
imageclasstree<-function(infile,outfile,dectree,samples,lines,bands,interlea
ve,datatype,maxpixels) {

fileconnection<-file(infile,open="rb")
outfileconnection=file(outfile,open="wb")

numpixels = samples * lines
numslices=ceiling(numpixels/maxpixels)
if (numslices == floor(numpixels/maxpixels)) numslices=numslices-1

bandnames<-paste(c("B"),1:bands,sep="")

## Loop for processing images
for(j in 0:numslices) {
    print((j/numslices)*100)
    
envislice<-envigetslice(fileconnection,samples,lines,bands,interleave,dataty
pe,maxpixels)
    names(envislice)<-bandnames
    predictslice<-predict(treetrain,envislice,type=c("vector"))
    
predictslice<-as.integer(round(as.vector(t(predictslice*10000)),digits=0))
    predictslice
    writeBin(predictslice,outfileconnection,size=2)
}
close(fileconnection)
close(outfileconnection)
}

imageclasstree("flt4aall","flt4adt", treetrain,11216,18173,12,1,4,25000)

On 2/18/04 2:25 PM, "Sundar Dorai-Raj" <sundar.dorai-raj at PDF.COM> wrote:

> 
> 
> Jonathan Greenberg wrote:
> 
>> I'm running a decision tree on a large dataset, and I'm getting multiple
>> instances of "NAs introduced by coercion" (> 50).  What does this mean?
>> 
>> --j
>> 
> 
> My guess would be you're trying to convert from character to numeric and
> are unable to do so. As in,
> 
>> as.numeric("A")
> [1] NA
> Warning message:
> NAs introduced by coercion
>> as.numeric("1")
> [1] 1
>> 
> 
> But without more information from you it's impossible to tell.
> 
> See the posting guide at
> 
> http://www.R-project.org/posting-guide.html
> 
> Regards,
> Sundar
> 


-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From spencer.graves at pdf.com  Wed Feb 18 23:49:23 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 18 Feb 2004 14:49:23 -0800
Subject: [R] overlay points on plot
In-Reply-To: <00c401c3f651$6ef8d150$72180281@jawks2>
References: <OFF5027367.99652D55-ON85256E3E.00682681@nd.convergys.com>
	<00c401c3f651$6ef8d150$72180281@jawks2>
Message-ID: <4033EBF3.8000605@pdf.com>

      Checking the documentation on lists:  help.start() -> "An 
Introduction to R" -> "Lists and data frames" -> ... "It is very 
important to distinguish Lst[[1]] from Lst[1]. [[...]] is the operator 
used to select a single element, whereas [...] is a general subscripting 
operator. Thus the former is the first object in the list Lst, and if it 
is a named list the name is not included. The latter is a sublist of the 
list Lst consisting of the first entry only. If it is a named list, the 
name is transferred to the sublist."

      hope this helps.  spencer graves

femke wrote:

>Brilliant!   Why the double brackets though?
>
>thanks
>
>femke
>
>
>----- Original Message ----- 
>From: <james.holtman at convergys.com>
>To: "femke" <femke at geog.umd.edu>
>Sent: Wednesday, February 18, 2004 1:58 PM
>Subject: Re: [R] overlay points on plot
>
>
>  
>
>>
>>
>>have you tried:
>>
>> points(v[[2]],v[[3]])
>>__________________________________________________________
>>James Holtman        "What is the problem you are trying to solve?"
>>Executive Consultant  --  Office of Technology, Convergys
>>james.holtman at convergys.com
>>+1 (513) 723-2929
>>
>>
>>
>>                      "femke"
>>                      <femke at geog.umd.edu>         To:
>>    
>>
><r-help at stat.math.ethz.ch>
>  
>
>>                      Sent by:                     cc:
>>                      r-help-bounces at stat.m        Subject:  [R] overlay
>>    
>>
>points on plot
>  
>
>>                      ath.ethz.ch
>>
>>
>>                      02/18/2004 13:03
>>
>>
>>
>>
>>
>>
>>
>>Dear R-help list,
>>
>>I'm trying to overlay a number of data objects in a plot.  Following an
>>earlier example on the list I've created an empty plot as follows
>>
>>    
>>
>>>xlim <- range(as.numeric(c("0","10000")))
>>>ylim <- range(as.numeric(c("0","25")) )
>>>plot(NA, xlim=xlim, ylim=ylim, xlab="distance", ylab="semivariance")
>>>      
>>>
>>However when I try to plot something on it, I get the following error:
>>
>>    
>>
>>>points(v[2],v[3])
>>>      
>>>
>>Error in as.double.default(x) : (list) object cannot be coerced to double
>>
>>A sample of my data looks like the following V[2]:
>>
>>       gamma
>>1   0.040000
>>2   0.582500
>>3   1.574545
>>4   7.126500
>>.....
>>
>>and V[3]:
>>
>>        dist
>>1   470.0426
>>2  1045.6365
>>3  1607.1936
>>....
>>
>>
>>Does anyone have any idea how to fix this?
>>
>>Thanks very much,
>>
>>femke
>>             [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
>>
>>
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From davison at uchicago.edu  Thu Feb 19 01:19:48 2004
From: davison at uchicago.edu (Dan Davison)
Date: Wed, 18 Feb 2004 18:19:48 -0600 (CST)
Subject: [R] latex problem with Sweave output file under Debian
Message-ID: <Pine.GSO.4.21.0402181745410.2279-100000@harper.uchicago.edu>

Could someone tell me how to end the trouble I'm encountering when
running latex on the .tex file produced by Sweave()? Sweave() seems to
process the example file
(http://www.ci.tuwien.ac.at/~leisch/Sweave/example-1.Snw) without
problems, and the file example-1.tex produced is the same as in the Sweave
manual. However, when I run latex on example-1.tex, many error messages
and requests for user input are generated (below). And when I view the
.dvi that eventually results with xdvi it is empty apart from a small
graphic containing the box plot that shouldbe there; there is no text.
latex produces apparently perfect .dvi files when the .tex files are 
not produced by Sweave.

Some of the error messages (log file pasted below) that result from the
command latex include: 

kpathsea: Running mktexmf  ecrm1000
! I can't find file `ecrm1000'.
! Font T1/cmr/m/n/10=ecrm1000 at 10.0pt not loadable: Metric (TFM) file 
not found.
! LaTeX Error: File `ae.sty' not found. 
! LaTeX Error: File `fancyvrb.sty' not found. 
! LaTeX Error: Missing \begin{document}.

I downloaded the missing files and tried (I had no idea) putting them in
/usr/share/texmf/tex/latex/graphics/ and /usr/lib/R/share/texmf/ with no
apparent effect. I am using R Version 1.8.1 under Debian linux, with the
tetex Debian-stable package.

Thanks (and apologies if this is OT or if this is too much text),
Dan

Here is the contents of the example-1.log file, with some similar repeated
lines cut out:

This is TeX, Version 3.14159 (Web2C 7.4.5) (format=latex 2004.2.3)  18 FEB
2004 13:01
**example-1.tex
(./example-1.tex
LaTeX2e <2001/06/01>
Babel <v3.7h> and hyphenation patterns for american, french, ngerman,
portuges,
 nohyphenation, loaded.
(/usr/share/texmf/tex/latex/base/article.cls
Document Class: article 2001/04/21 v1.4e Standard LaTeX document class
(/usr/share/texmf/tex/latex/base/size10.clo
File: size10.clo 2001/04/21 v1.4e Standard LaTeX file (size option)
)
\c at part=\count79
\c at section=\count80
\c at subsection=\count81
\c at subsubsection=\count82
\c at paragraph=\count83
\c at subparagraph=\count84
\c at figure=\count85
\c at table=\count86
\abovecaptionskip=\skip41
\belowcaptionskip=\skip42
\bibindent=\dimen102
)
(/usr/lib/R/share/texmf/Sweave.sty
(/usr/share/texmf/tex/latex/base/fontenc.sty
Package: fontenc 2001/06/05 v1.94 Standard LaTeX package
(/usr/share/texmf/tex/latex/base/t1enc.def
File: t1enc.def 2001/06/05 v1.94 Standard LaTeX file
LaTeX Font Info:    Redeclaring font encoding T1 on input line 38.
)
! Font T1/cmr/m/n/10=ecrm1000 at 10.0pt not loadable: Metric (TFM) file
not fou
nd.
<to be read again> 
                   relax 
l.95 \fontencoding\encodingdefault\selectfont
                                             
? ^^[[2;5~
Type <return> to proceed, S to scroll future error messages,
R to run without stopping, Q to run quietly,
I to insert something, E to edit your file,
1 or ... or 9 to ignore the next 1 to 9 tokens of input,
H for help, X to quit.
? 
) (/usr/share/texmf/tex/latex/graphics/graphicx.sty
Package: graphicx 1999/02/16 v1.0f Enhanced LaTeX Graphics (DPC,SPQR)

(/usr/share/texmf/tex/latex/graphics/keyval.sty
Package: keyval 1999/03/16 v1.13 key=value parser (DPC)
\KV at toks@=\toks14
)
(/usr/share/texmf/tex/latex/graphics/graphics.sty
Package: graphics 2001/07/07 v1.0n Standard LaTeX Graphics (DPC,SPQR)

(/usr/share/texmf/tex/latex/graphics/trig.sty
Package: trig 1999/03/16 v1.09 sin cos tan (DPC)
)
(/usr/share/texmf/tex/latex/config/graphics.cfg
File: graphics.cfg 2001/08/31 v1.1 graphics configuration of teTeX/TeXLive
)
Package graphics Info: Driver file: dvips.def on input line 80.

(/usr/share/texmf/tex/latex/graphics/dvips.def
File: dvips.def 1999/02/16 v3.0i Driver-dependant file (DPC,SPQR)
))
\Gin at req@height=\dimen103
\Gin at req@width=\dimen104
)

! LaTeX Error: File `ae.sty' not found.

Type X to quit or <RETURN> to proceed,
or enter new name. (Default extension: sty)

Enter file name: 

! LaTeX Error: File `fancyvrb.sty' not found.

Type X to quit or <RETURN> to proceed,
or enter new name. (Default extension: sty)

Enter file name: 
! Undefined control sequence.
l.6 \DefineVerbatimEnvironment
                              {Sinput}{Verbatim}{fontshape=sl}
? 

! LaTeX Error: Missing \begin{document}.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
 ...                                              
                                                  
l.6 \DefineVerbatimEnvironment{S
                                input}{Verbatim}{fontshape=sl}
? 
Missing character: There is no S in font nullfont!
{...similar lines...}


Missing character: There is no s in font nullfont!
Missing character: There is no l in font nullfont!
! Undefined control sequence.
l.7 \DefineVerbatimEnvironment
                              {Soutput}{Verbatim}{}
? 
Missing character: There is no S in font nullfont!
{...similar lines...}

Missing character: There is no i in font nullfont!
Missing character: There is no m in font nullfont!
! Undefined control sequence.
l.8 \DefineVerbatimEnvironment
                              {Scode}{Verbatim}{fontshape=sl}
? 
Missing character: There is no S in font nullfont!
{...many similar lines...}

Missing character: There is no l in font nullfont!
)
No file example-1.aux.
\openout1 = `example-1.aux'.

LaTeX Font Info:    Checking defaults for OML/cmm/m/it on input line 7.
LaTeX Font Info:    ... okay on input line 7.
LaTeX Font Info:    Checking defaults for T1/cmr/m/n on input line 7.
LaTeX Font Info:    ... okay on input line 7.
LaTeX Font Info:    Checking defaults for OT1/cmr/m/n on input line 7.
LaTeX Font Info:    ... okay on input line 7.
LaTeX Font Info:    Checking defaults for OMS/cmsy/m/n on input line 7.
LaTeX Font Info:    ... okay on input line 7.
LaTeX Font Info:    Checking defaults for OMX/cmex/m/n on input line 7.
LaTeX Font Info:    ... okay on input line 7.
LaTeX Font Info:    Checking defaults for U/cmr/m/n on input line 7.
LaTeX Font Info:    ... okay on input line 7.
Missing character: There is no 1 in font nullfont!
[1

]
! Font T1/cmr/m/n/17.28=ecrm1728 at 17.28pt not loadable: Metric
(TFM) file not
 found.
<to be read again> 
                   relax 
l.9 \maketitle
              
? 
Missing character: There is no S in font nullfont!

{...many similar lines...}

Missing character: There is no e in font nullfont!
Missing character: There is no 1 in font nullfont!
! Font T1/cmr/m/n/12=ecrm1200 at 12.0pt not loadable: Metric (TFM) file
not fou
nd.
<to be read again> 
                   relax 
l.9 \maketitle
              
? 
LaTeX Font Info:    External font `cmex10' loaded for size
(Font)              <12> on input line 9.
LaTeX Font Info:    External font `cmex10' loaded for size
(Font)              <8> on input line 9.
LaTeX Font Info:    External font `cmex10' loaded for size
(Font)              <6> on input line 9.
Missing character: There is no F in font nullfont!

{...many similar lines...}

Missing character: There is no h in font nullfont!
Missing character: There is no e in font nullfont!
LaTeX Font Info:    Try loading font information for T1+cmtt on input line
12.
(/usr/share/texmf/tex/latex/base/t1cmtt.fd
File: t1cmtt.fd 1999/05/25 v2.5h Standard LaTeX font definitions
)
! Font T1/cmtt/m/n/10=ectt1000 at 10.0pt not loadable: Metric (TFM) file
not fo
und.
<to be read again> 
                   relax 
l.12 \texttt{kruskal.test}
                           help page into a \LaTeX{} document:
? 
Missing character: There is no k in font nullfont!

{...many similar lines...}

Missing character: There is no L in font nullfont!
Missing character: There is no T in font nullfont!
LaTeX Font Info:    External font `cmex10' loaded for size
(Font)              <7> on input line 12.
LaTeX Font Info:    External font `cmex10' loaded for size
(Font)              <5> on input line 12.
! Font T1/cmr/m/n/7=ecrm0700 at 7.0pt not loadable: Metric (TFM) file not
found
.
<to be read again> 
                   relax 
l.12 \texttt{kruskal.test} help page into a \LaTeX
                                                  {} document:
? 
Missing character: There is no A in font nullfont!
{...many similar lines...}
Missing character: There is no : in font nullfont!

! LaTeX Error: Environment Sinput undefined.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
 ...                                              
                                                  
l.15 \begin{Sinput}
                   
? 
Missing character: There is no > in font nullfont!
{...many similar lines...}
Missing character: There is no y in font nullfont!
Missing character: There is no ) in font nullfont!

! LaTeX Error: \begin{Schunk} on input line 14 ended by \end{Sinput}.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
 ...                                              
                                                  
l.19 \end{Sinput}
                 
? 

! LaTeX Error: Environment Soutput undefined.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
 ...                                              
                                                  
l.20 \begin{Soutput}
                    
? 
Missing character: There is no K in font nullfont!
Missing character: There is no r in font nullfont!

{...many similar lines...}

Missing character: There is no 0 in font nullfont!
Missing character: There is no 6 in font nullfont!

! LaTeX Error: \begin{Schunk} on input line 14 ended by \end{Soutput}.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
 ...                                              
                                                  
l.25 \end{Soutput}
                  
? 
Missing character: There is no w in font nullfont!
Missing character: There is no h in font nullfont!

{...many similar lines...}

Missing character: There is no a in font nullfont!
Missing character: There is no : in font nullfont!
File: example-1-002.eps Graphic file (type eps)
<example-1-002.eps>
Missing character: There is no 2 in font nullfont!
 [2] (./example-1.aux) ) 
Here is how much of TeX's memory you used:
 783 strings out of 95848
 8517 string characters out of 1195973
 52319 words of memory out of 1000001
 3751 multiletter control sequences out of 10000+50000
 6376 words of font info for 23 fonts, out of 500000 for 1000
 16 hyphenation exceptions out of 1000
 32i,6n,21p,257b,222s stack positions out of
1500i,500n,5000p,200000b,5000s

Output written on example-1.dvi (2 pages, 324 bytes).



From Friedrich.Leisch at ci.tuwien.ac.at  Thu Feb 19 01:43:32 2004
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu, 19 Feb 2004 11:43:32 +1100
Subject: [R] latex problem with Sweave output file under Debian
In-Reply-To: <Pine.GSO.4.21.0402181745410.2279-100000@harper.uchicago.edu>
References: <Pine.GSO.4.21.0402181745410.2279-100000@harper.uchicago.edu>
Message-ID: <16436.1716.47556.646581@celebrian.ci.tuwien.ac.at>

>>>>> On Wed, 18 Feb 2004 18:19:48 -0600 (CST),
>>>>> Dan Davison (DD) wrote:

  > Could someone tell me how to end the trouble I'm encountering when
  > running latex on the .tex file produced by Sweave()? Sweave() seems to
  > process the example file
  > (http://www.ci.tuwien.ac.at/~leisch/Sweave/example-1.Snw) without
  > problems, and the file example-1.tex produced is the same as in the Sweave
  > manual. However, when I run latex on example-1.tex, many error messages
  > and requests for user input are generated (below). And when I view the
  > .dvi that eventually results with xdvi it is empty apart from a small
  > graphic containing the box plot that shouldbe there; there is no text.
  > latex produces apparently perfect .dvi files when the .tex files are 
  > not produced by Sweave.

[...]

  > ! LaTeX Error: File `ae.sty' not found.

  > Type X to quit or <RETURN> to proceed,
  > or enter new name. (Default extension: sty)

  > Enter file name: 

  > ! LaTeX Error: File `fancyvrb.sty' not found.

  > Type X to quit or <RETURN> to proceed,
  > or enter new name. (Default extension: sty)

  > Enter file name: 


Well, both ae.sty and fancyvrb.sty seem not to be installed on your
system ... probably you don't have the tetex-extra package installed.

.f

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From jasont at indigoindustrial.co.nz  Thu Feb 19 01:49:59 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 19 Feb 2004 13:49:59 +1300 (NZDT)
Subject: [R] Complex conjugate?
In-Reply-To: <004801c3f656$dfeeb7d0$78f05a99@msu.montana.edu>
References: <004801c3f656$dfeeb7d0$78f05a99@msu.montana.edu>
Message-ID: <43408.203.9.176.60.1077151799.squirrel@new-webmail.maxnet.co.nz>

> Is there a function in R that returns the complex conjugate of a matrix
> (a la 'CONJ' in IDL or 'Conjugate' in Mathmatica)?
>

?complex

Cheers

Jason



From m.okasha at palnet.com  Thu Feb 19 02:14:22 2004
From: m.okasha at palnet.com (Mahmoud K. Okasha)
Date: Thu, 19 Feb 2004 03:14:22 +0200
Subject: [R] boostrapping at R
References: <007501c3f662$2526bef0$ea09000a@W00RHUAMAN>
Message-ID: <004501c3f685$b5547440$2a334ed9@okasha>

Hi,

After reading your data you can use functions such as :
bts <- numeric (500)
for (i in 1:500) bts[i] <- sample(yourdata, replace=TRUE)

Regards

----- Original Message -----
From: "Ricardo Huaman" <huamanr at mef.gob.pe>
To: <R-help at stat.math.ethz.ch>
Sent: Wednesday, February 18, 2004 10:59 PM
Subject: [R] boostrapping at R


> Friends:
>
> How can I do boostrapping at R?
>
> Thanks
>
> Ricardo.
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>



From jasont at indigoindustrial.co.nz  Thu Feb 19 03:39:50 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 19 Feb 2004 15:39:50 +1300 (NZDT)
Subject: [R] boostrapping at R
In-Reply-To: <007501c3f662$2526bef0$ea09000a@W00RHUAMAN>
References: <007501c3f662$2526bef0$ea09000a@W00RHUAMAN>
Message-ID: <47853.203.9.176.60.1077158390.squirrel@new-webmail.maxnet.co.nz>

> Friends:
>
> How can I do boostrapping at R?
>
> Thanks

library(boot)
help(boot)

Cheers

Jason



From ririzarr at jhsph.edu  Thu Feb 19 04:28:39 2004
From: ririzarr at jhsph.edu (Rafael A. Irizarry)
Date: Wed, 18 Feb 2004 22:28:39 -0500 (EST)
Subject: [R] surprising revelation
Message-ID: <Pine.GSO.4.10.10402182216410.20562-100000@athena.biostat.jhsph.edu>

apologies for the off-topic mail but i cant resist sharing this:
>From CNN:
(http://www.cnn.com/2004/ALLPOLITICS/02/18/elec04.prez.bush.jobs.ap/index.html)

"The White House backed away Wednesday from its own prediction that the
economy will add 2.6 million new jobs before the end of this year, saying
the forecast was the work of number-crunchers and that President Bush was
not a statistician."

i thought i remembered him posting something on this list...
asking about fuzzy math.. and that someone suggested: "do read a
book on arithmetics"



From ripley at stats.ox.ac.uk  Thu Feb 19 08:30:56 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 19 Feb 2004 07:30:56 +0000 (GMT)
Subject: [R] Generalized Estimating Equations and log-likelihood
	calculation
In-Reply-To: <1077125378.4033a10213b47@webmail.telus.net>
Message-ID: <Pine.LNX.4.44.0402190727440.19592-100000@gannet.stats>

On Wed, 18 Feb 2004 treebc at telus.net wrote:

> I'm working with clustered data sets and trying to calculate log-likelihood 
> (and/or AIC, AICc) for my models.  In using the gee and geese packages one 
> gets Wald test output; but apparently there is no no applicable method 
> for "logLik" (log-likelihood)calculation.
> 
> Is anyone aware of a way to calculate log-likelihood for GEE models?

No (as with GLM quasi- models, it is not defined in general).  Even if
there were, you would have find the maximized log-likelihood to find AIC,
and by definition GEE is not ML fitting except in a few special cases.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From henric.nilsson at statisticon.se  Thu Feb 19 09:17:37 2004
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Thu, 19 Feb 2004 09:17:37 +0100
Subject: [R] Generalized Estimating Equations and log-likelihood
	calculation
In-Reply-To: <1077125378.4033a10213b47@webmail.telus.net>
References: <1077125378.4033a10213b47@webmail.telus.net>
Message-ID: <6.0.3.0.0.20040219085303.047d4de8@10.0.10.66>

At 18:29 2004-02-18, you wrote:

>Is anyone aware of a way to calculate log-likelihood for GEE models?

No. GEE fitting is based on quasi-likelihood.

However, it is possible to derive AIC-like measures based on the 
quasi-likelihood. Lebreton et al (1992) suggested a simple adjustment in 
the GLM case, i.e. when using family=quasibinomal or quasipoisson. For GEE 
models, Pan (2001) has introduced QIC. None of these measures are 
implemented in R or in any add-on package as far as I know.

Henric



From henric.nilsson at statisticon.se  Thu Feb 19 09:28:47 2004
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Thu, 19 Feb 2004 09:28:47 +0100
Subject: [R] Generalized Estimating Equations and log-likelihood
	calculation
In-Reply-To: <6.0.3.0.0.20040219085303.047d4de8@10.0.10.66>
References: <1077125378.4033a10213b47@webmail.telus.net>
	<6.0.3.0.0.20040219085303.047d4de8@10.0.10.66>
Message-ID: <6.0.3.0.0.20040219092552.03e476c0@10.0.10.66>

At 09:17 2004-02-19, you wrote:

>For GEE models, Pan (2001) has introduced QIC. None of these measures are 
>implemented in R or in any add-on package as far as I know.

Actually, take a look at 
http://hisdu.sph.uq.edu.au/lsu/SSAI%20course/course_tools.htm

Henric



From m.sutter at schweiz.ch  Thu Feb 19 09:30:18 2004
From: m.sutter at schweiz.ch (Marcel Sutter)
Date: Thu, 19 Feb 2004 08:30:18 +0000
Subject: [R] Setting ylim while plotting an 'its' object
Message-ID: <4034741A.1040007@schweiz.ch>

Hi,

I have an object 'sat' of class 'its'.
How do I have to set the ylim parameter to change the y Axis limits 
while plotting a time series?

Thanks very much for your help, Marcel

 > class(sat)
[1] "its"
attr(,"package")
[1] "its"
 > range(sat)
[1] -0.5908360386  0.0001541759
 > plot(sat,type="p",pch=3,cex=0.5,ylim=c(-1,0.5))
Error in plot.default(x, y, xaxt = "n", xlab = xlab, axes = axes, 
frame.plot = frame.plot,  :
    formal argument "ylim" matched by multiple actual arguments

 > R.version
         _               
platform i686-pc-linux-gnu
arch     i686            
os       linux-gnu       
system   i686, linux-gnu 
status                   
major    1               
minor    8.1             
year     2003            
month    11              
day      21              
language R               
 >



From samuel.bertrand at paris.ensam.fr  Thu Feb 19 09:48:37 2004
From: samuel.bertrand at paris.ensam.fr (Samuel Bertrand)
Date: Thu, 19 Feb 2004 09:48:37 +0100
Subject: [R] Summary - normality test
In-Reply-To: <5.1.0.14.0.20040217084610.02129d80@imap.rockefeller.edu>
References: <5.0.2.1.2.20040217092449.00b066a8@mailhost.paris.ensam.fr>
Message-ID: <5.0.2.1.2.20040219094104.00ae2ed8@mailhost.paris.ensam.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040219/aa65a0c2/attachment.pl

From Simon.Fear at synequanon.com  Thu Feb 19 11:11:50 2004
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Thu, 19 Feb 2004 10:11:50 -0000
Subject: [R] pass by reference -- how to do it
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F021ED@synequanon01>

For the record, be careful: <<- does not necessarily assign to 
the global environment. In R ` x <<- value` assigns `value` to 
the first instance of `x` it can find using lexical scoping. Only if it 
doesn't find any such variable, it will indeed create an `x` 
in .GlobalEnv.

Tricky for those brought up on S-Plus, where assignment <<- 
is guaranteed to assign to frame 1. 

HTH

> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at myway.com]
> Sent: 18 February 2004 04:19
> To: robert_dodier at yahoo.com; r-help at stat.math.ethz.ch
> Subject: RE: [R] pass by reference -- how to do it
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> 
> 
> If you don't mind NOT passing your arrays at all then you 
> can do this:
> 
> f <- function() a[1] <<- a[1] + 1
> a <- 1:5
> f()  # increments first element of a by 1
> a     # c(2,2,3,4,5)
> 
> The <<- causes the expression to take place in the global 
> environment.
> 
> If you want to actually pass your arrays by reference then the
> following works although its a bit messy:
> 
> g <- function(z) eval(eval(substitute(expression(z[1] <<- z[1]+1))))
> a <- 1:5
> g(a)  # increments first element of a by 1
> a     # c(2,2,3,4,5)
> 
> The <<- causes the expression to be evaluated in the global 
> environment. expression() turns its argument into an object
> of mode expression.  substitute() replaces z with the argument 
> passed to f in that expression and returns an object of mode 
> call.  The inner eval turns the object of mode call into an 
> object of mode expression and the outer eval evaluates that 
> expression.  
> 
> ---
> Date:   Tue, 17 Feb 2004 13:23:58 -0800 (PST) 
> From:   Robert Dodier <robert_dodier at yahoo.com>
> To:   <r-help at stat.math.ethz.ch> 
> Subject:   [R] pass by reference -- how to do it 
> 
>  
> Hello,
> 
> Pass by reference appears to be a topic which comes up
> from time to time, but I wasn't able to find something in
> the R-help archives which tells how to accomplish it.
> 
> I have a problem that you may have seen before -- R runs
> out of memory when processing large matrices. Part of the
> problem for me is that I am using some large matrices as
> function arguments, and these are modified, which leads 
> to allocating copies of the matrices. 
> 
> I would like to do the modification "in place" so that
> a copy is not required. Thanks for any light you can shed
> on this.
> 
> If you're tempted to tell me "you don't really want to do that" --
> let me save you the trouble. You are so very right! Indeed I
> don't want to have pass by reference variables. OTOH I don't
> want R to come to a dead halt at an inconvenient time either.
> 
> Thanks for your help,
> Robert Dodier
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From ripley at stats.ox.ac.uk  Thu Feb 19 11:20:09 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 19 Feb 2004 10:20:09 +0000 (GMT)
Subject: [R] Setting ylim while plotting an 'its' object
In-Reply-To: <4034741A.1040007@schweiz.ch>
Message-ID: <Pine.LNX.4.44.0402191018060.21746-100000@gannet.stats>

It looks like you need to set yrange, not ylim: see ?itsDisp.  I don't see 
a good reason for this.

On Thu, 19 Feb 2004, Marcel Sutter wrote:

> Hi,
> 
> I have an object 'sat' of class 'its'.
> How do I have to set the ylim parameter to change the y Axis limits 
> while plotting a time series?
> 
> Thanks very much for your help, Marcel
> 
>  > class(sat)
> [1] "its"
> attr(,"package")
> [1] "its"
>  > range(sat)
> [1] -0.5908360386  0.0001541759
>  > plot(sat,type="p",pch=3,cex=0.5,ylim=c(-1,0.5))
> Error in plot.default(x, y, xaxt = "n", xlab = xlab, axes = axes, 
> frame.plot = frame.plot,  :
>     formal argument "ylim" matched by multiple actual arguments
> 
>  > R.version
>          _               
> platform i686-pc-linux-gnu
> arch     i686            
> os       linux-gnu       
> system   i686, linux-gnu 
> status                   
> major    1               
> minor    8.1             
> year     2003            
> month    11              
> day      21              
> language R               
>  >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rene.eschen at unifr.ch  Thu Feb 19 12:05:33 2004
From: rene.eschen at unifr.ch (=?iso-8859-1?Q?Ren=E9_Eschen?=)
Date: Thu, 19 Feb 2004 12:05:33 +0100
Subject: [R] How to create a "nb" object?
Message-ID: <001e01c3f6d8$4bca64f0$4b14a8c0@tlinks>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040219/f7f4a1dc/attachment.pl

From Roger.Bivand at nhh.no  Thu Feb 19 13:20:18 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 19 Feb 2004 13:20:18 +0100 (CET)
Subject: [R] How to create a "nb" object?
In-Reply-To: <001e01c3f6d8$4bca64f0$4b14a8c0@tlinks>
Message-ID: <Pine.LNX.4.44.0402191309160.1038-100000@reclus.nhh.no>

On Thu, 19 Feb 2004, Ren? Eschen wrote:

> Hi group,
> 
> I'd like to do spatial analysis of my data using the spdep package. It
> appears that a file of class nb is necessary, but I do not find what
> that should look like and if there is a function that creates such file
> for me.

If you have points that represent your data observations, you can use
triangulation-based functions like: tri2nb, gabrielneigh, relativeneigh,
soi.graph, graph2nb; distance-based neighbours from dnearneigh; k-nearest
neighbours from knn2nb and knearneigh. If you have polygons, you can find
contiguous polygons with poly2nb;  and cell2nb will give you an nb object
for a regular grid.

Which you choose will depend on your research problem and how your data 
are structured. Some can generate observations with no neighbours 
(especially the distance-based schemes). You can also export neighbour 
lists in "GAL" format from programs like GeoDa for use in spdep in R.

Roger

> 
> How can I create a nb-object of my data points?
> 
> Thanks,
> 
> Ren? Eschen.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Econonic Geography Section, Department of Economics, Norwegian School of 
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen, 
Norway, voice: +47-55959355, fax: +47-55959393; Roger.Bivand at nhh.no



From jonathan.williams at pharmacology.oxford.ac.uk  Thu Feb 19 14:20:28 2004
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Thu, 19 Feb 2004 13:20:28 -0000
Subject: [R] suppressing non-integer labels for plot x-axis
Message-ID: <NGBBKJEMOMLJFCOIEGCEAEMCJKAA.jonathan.williams@pharm.ox.ac.uk>

Dear R-helpers,
I am having difficulty making R plot only integer labels on the x-axis
of a simple graph. I want to plot the median values of a score on each
of three occasions. Non-integer occasions are impossible. But, R keeps
labelling the x-axis with half-occasions, despite my attempts to stop
this using the "xaxs" and "xaxp" parameters of 'plot'.

p1=c(1,2,3); p2=c(5,15,25)
plot(p1,p2,xlab='Occasion', ylab='Score', xlim=c(1,3), ylim=c(0,30),
xaxp=c(1,3,3), xaxs='r')

Could someone let me know how to suppress the non-integer labels?

Thanks

Jonathan Williams
OPTIMA
Radcliffe Infirmary
Woodstock Road
OXFORD OX2 6HE
Tel +1865 (2)24356



From Joerg.Schaber at uv.es  Thu Feb 19 14:03:10 2004
From: Joerg.Schaber at uv.es (Joerg Schaber)
Date: Thu, 19 Feb 2004 14:03:10 +0100
Subject: [R] F Dist
Message-ID: <4034B40E.2040803@uv.es>

Hi,

why is it that in tables for the F distribution it is for example

F0.95[6,28]=2.45 or F0.95[10,20]=2.35

but

 > pf(6,28,2.45)
[1] 0.8854934
 > pf(10,20,2.35)
[1] 0.9300167

Thanks for clarifying,

jeorg



From ccleland at optonline.net  Thu Feb 19 14:15:35 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 19 Feb 2004 08:15:35 -0500
Subject: [R] suppressing non-integer labels for plot x-axis
In-Reply-To: <NGBBKJEMOMLJFCOIEGCEAEMCJKAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCEAEMCJKAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <4034B6F7.1070505@optonline.net>

Jonathan Williams wrote:
> I am having difficulty making R plot only integer labels on the x-axis
> of a simple graph. I want to plot the median values of a score on each
> of three occasions. Non-integer occasions are impossible. But, R keeps
> labelling the x-axis with half-occasions, despite my attempts to stop
> this using the "xaxs" and "xaxp" parameters of 'plot'.
> 
> p1=c(1,2,3); p2=c(5,15,25)
> plot(p1,p2,xlab='Occasion', ylab='Score', xlim=c(1,3), ylim=c(0,30),
> xaxp=c(1,3,3), xaxs='r')
> 
> Could someone let me know how to suppress the non-integer labels?

How about this instead?

plot(p1, p2, xlab='Occasion', ylab='Score', xlim=c(1,3), ylim=c(0,30), 
xaxt="n")

axis(side=1, at=1:3, 1:3)

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From andy_liaw at merck.com  Thu Feb 19 14:13:00 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 19 Feb 2004 08:13:00 -0500
Subject: [R] F Dist
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77F2@usrymx25.merck.com>

... because that should have been:

> pf(2.45, 6, 28)
[1] 0.9503618
> pf(2.35, 10, 20)
[1] 0.950176

When arguments are not named, the order is significant.

Andy

> From: Joerg Schaber
> 
> Hi,
> 
> why is it that in tables for the F distribution it is for example
> 
> F0.95[6,28]=2.45 or F0.95[10,20]=2.35
> 
> but
> 
>  > pf(6,28,2.45)
> [1] 0.8854934
>  > pf(10,20,2.35)
> [1] 0.9300167
> 
> Thanks for clarifying,
> 
> jeorg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ligges at statistik.uni-dortmund.de  Thu Feb 19 14:23:01 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 19 Feb 2004 14:23:01 +0100
Subject: [R] F Dist
In-Reply-To: <4034B40E.2040803@uv.es>
References: <4034B40E.2040803@uv.es>
Message-ID: <4034B8B5.3010208@statistik.uni-dortmund.de>

Joerg Schaber wrote:

> Hi,
> 
> why is it that in tables for the F distribution it is for example
> 
> F0.95[6,28]=2.45 or F0.95[10,20]=2.35
> 
> but
> 
>  > pf(6,28,2.45)
> [1] 0.8854934
>  > pf(10,20,2.35)
> [1] 0.9300167
> 
> Thanks for clarifying,
> 
> jeorg


What you are really going to do is:

pf(2.45, 6, 28)   # [1] 0.9503618
pf(2.35, 10, 20)  # [1] 0.950176

Uwe Ligges



From pac at uhb.fr  Thu Feb 19 14:21:09 2004
From: pac at uhb.fr (Pierre-Andre Cornillon)
Date: Thu, 19 Feb 2004 14:21:09 +0100 (CET)
Subject: [R] F Dist
In-Reply-To: <4034B40E.2040803@uv.es>
References: <4034B40E.2040803@uv.es>
Message-ID: <Pine.LNX.4.58.0402191419200.28904@sa2391.rec.uhb.fr>

Hello,

the order of argument is not the correct one:
p(2.45,6,28)
[1] 0.9503618

P.A.

On Thu, 19 Feb 2004, Joerg Schaber wrote:

> Hi,
>
> why is it that in tables for the F distribution it is for example
>
> F0.95[6,28]=2.45 or F0.95[10,20]=2.35
>
> but
>
>  > pf(6,28,2.45)
> [1] 0.8854934
>  > pf(10,20,2.35)
> [1] 0.9300167
>
> Thanks for clarifying,
>
> jeorg
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Thu Feb 19 14:24:24 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 19 Feb 2004 14:24:24 +0100
Subject: [R] suppressing non-integer labels for plot x-axis
In-Reply-To: <NGBBKJEMOMLJFCOIEGCEAEMCJKAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCEAEMCJKAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <4034B908.3060401@statistik.uni-dortmund.de>

Jonathan Williams wrote:

> Dear R-helpers,
> I am having difficulty making R plot only integer labels on the x-axis
> of a simple graph. I want to plot the median values of a score on each
> of three occasions. Non-integer occasions are impossible. But, R keeps
> labelling the x-axis with half-occasions, despite my attempts to stop
> this using the "xaxs" and "xaxp" parameters of 'plot'.
> 
> p1=c(1,2,3); p2=c(5,15,25)
> plot(p1,p2,xlab='Occasion', ylab='Score', xlim=c(1,3), ylim=c(0,30),
> xaxp=c(1,3,3), xaxs='r')
> 
> Could someone let me know how to suppress the non-integer labels?

In this case supress the drawing of the x-axis and specify it 
explicitly, see ?axis:

plot(p1, p2, xlab='Occasion', ylab='Score', xlim=c(1,3), ylim=c(0,30), 
xaxt="n")
axis(1, at=1:3)

Uwe Ligges



From ahenningsen at email.uni-kiel.de  Thu Feb 19 14:26:55 2004
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Thu, 19 Feb 2004 14:26:55 +0100
Subject: R for economists (was: [R] Almost Ideal Demand System)
In-Reply-To: <20040215063137.GA10703@igidr.ac.in>
References: <20040215063137.GA10703@igidr.ac.in>
Message-ID: <200402191426.55242.ahenningsen@email.uni-kiel.de>

Hi,

I did not find any web page about using R in economics and econometrics so 
far. However, this does not mean that there is none (searching with google 
for "R" and "economics" gives many pages about economics and a name like 
Firstname R. Lastname on it ;-)). 
Does anybody in the list does know such a web page?
If not, I will be happy if you, Ajay, could build and maintaine one.

Best wishes,
Arne

On Sunday 15 February 2004 07:31, Ajay Shah wrote:
> Anne,
>
> Please do make progress on packaging and releasing your R code for
> demand analysis. Is there a web page titled "R for economists"! :-) If
> there isn't, I'll be happy to build and maintain one, and put a link
> to your code there.

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From ggrothendieck at myway.com  Thu Feb 19 14:33:05 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 19 Feb 2004 08:33:05 -0500 (EST)
Subject: [R] pass by reference -- how to do it
Message-ID: <20040219133305.CA2973979@mprdmxin.myway.com>


[sorry if this appears twice. I had an email problem and am
sending it out again]
 
As you and Andy correctly point out, <<- searches through
its environments and it may find a match prior to the Global
Environment.

On the other hand, while its possible to get into trouble,
I believe its actually not that likely since avoiding
nested functions is all you have to do.

For example, we can modify the previous example to make it
NOT work like this. With g nested in f, g's x refers to f's x,
not the global x:

f <- function(x) { g <- function() x[1] <<- x[1]+1; g() } # g nested 
x <- 1:5
f(x)
x # x unchanged since x in g matches x in f, not the global x

However, by simply defining g at the top level rather than
nesting it in f2, the code does work to modify the global x
despite the fact that f2 defines its own x:

g <- function() x[1] <<- x[1]+1 # g at not level, i.e. not nested
f2 <- function(x) g()
x <- 1:5
f2(x)
x # c(2,2,3,4,5)

The fact that its this easy to guarantee that it works seems to
be one of the advantages of R's lexical scoping.

---
Date: Thu, 19 Feb 2004 10:11:50 -0000 
From: Simon Fear <Simon.Fear at synequanon.com>
To: <ggrothendieck at myway.com>, <robert_dodier at yahoo.com>, <r-help at stat.math.ethz.ch> 
Subject: RE: [R] pass by reference -- how to do it 


For the record, be careful: <<- does not necessarily assign to 
the global environment. In R ` x <<- value` assigns `value` to 
the first instance of `x` it can find using lexical scoping. Only if it 
doesn't find any such variable, it will indeed create an `x` 
in .GlobalEnv.

Tricky for those brought up on S-Plus, where assignment <<- 
is guaranteed to assign to frame 1. 

HTH

> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at myway.com]
> Sent: 18 February 2004 04:19
> To: robert_dodier at yahoo.com; r-help at stat.math.ethz.ch
> Subject: RE: [R] pass by reference -- how to do it
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact 
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
> 
> 
> 
> If you don't mind NOT passing your arrays at all then you 
> can do this:
> 
> f <- function() a[1] <<- a[1] + 1
> a <- 1:5
> f() # increments first element of a by 1
> a # c(2,2,3,4,5)
> 
> The <<- causes the expression to take place in the global 
> environment.
> 
> If you want to actually pass your arrays by reference then the
> following works although its a bit messy:
> 
> g <- function(z) eval(eval(substitute(expression(z[1] <<- z[1]+1))))
> a <- 1:5
> g(a) # increments first element of a by 1
> a # c(2,2,3,4,5)
> 
> The <<- causes the expression to be evaluated in the global 
> environment. expression() turns its argument into an object
> of mode expression. substitute() replaces z with the argument 
> passed to f in that expression and returns an object of mode 
> call. The inner eval turns the object of mode call into an 
> object of mode expression and the outer eval evaluates that 
> expression. 
> 
> ---
> Date: Tue, 17 Feb 2004 13:23:58 -0800 (PST) 
> From: Robert Dodier <robert_dodier at yahoo.com>
> To: <r-help at stat.math.ethz.ch> 
> Subject: [R] pass by reference -- how to do it 
> 
> 
> Hello,
> 
> Pass by reference appears to be a topic which comes up
> from time to time, but I wasn't able to find something in
> the R-help archives which tells how to accomplish it.
> 
> I have a problem that you may have seen before -- R runs
> out of memory when processing large matrices. Part of the
> problem for me is that I am using some large matrices as
> function arguments, and these are modified, which leads 
> to allocating copies of the matrices. 
> 
> I would like to do the modification "in place" so that
> a copy is not required. Thanks for any light you can shed
> on this.
> 
> If you're tempted to tell me "you don't really want to do that" --
> let me save you the trouble. You are so very right! Indeed I
> don't want to have pass by reference variables. OTOH I don't
> want R to come to a dead halt at an inconvenient time either.
> 
> Thanks for your help,
> Robert Dodier



From Timur.Elzhov at jinr.ru  Thu Feb 19 14:38:03 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Thu, 19 Feb 2004 16:38:03 +0300
Subject: [R] Obtaining SE from the hessian matrix
Message-ID: <20040219133803.GA12760@nf034.jinr.ru>

Dear R experts,

In R-intro, under the 'Nonlinear least squares and maximum likelihood
models' there are ttwo examples considered how to use 'nlm' function.
In 'Least squares' the Standard Errors obtained as follows:

    After the fitting, out$minimum is the SSE, and out$estimates are the
    least squares estimates of the parameters. To obtain the approximate
    standard errors (SE) of the estimates we do:

    > sqrt(diag(2*out$minimum/(length(y) - 2) * solve(out$hessian)))

But under 'Maximum likelihood' section I've read:

    After the fitting, out$minimum is the negative log-likelihood, and
    out$estimates are the maximum likelihood estimates of the parameters.
    To obtain the approximate SEs of the estimates we do:

    > sqrt(diag(solve(out$hessian)))

As for me, I use MINPACK fortran library for NLS fitting in R, and there
I also get the hessian matrix. What formula should I use in _this_ case?
Well, some times ago I had a glance at gsl, GNU Scientific Library. It
use converted-to-C MINPACK for NLS fit too.  And, in the GSL ref. manual
example
    http://www.gnu.org/software/gsl/manual/html_node/gsl-ref_36.html#SEC475
SE calculated as
    #define ERR(i) sqrt(gsl_matrix_get(covar,i,i))

where covar = (J^T * J)^-1 (i.e. how in the second formulae above).
So, what is the _right_ way for obtatining SE? Why two those formulas above
differ?

Thank you!

--
WBR,
Timur.



From ajayshah at mayin.org  Thu Feb 19 14:36:08 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Thu, 19 Feb 2004 19:06:08 +0530
Subject: R for economists (was: [R] Almost Ideal Demand System)
In-Reply-To: <200402191426.55242.ahenningsen@email.uni-kiel.de>
References: <20040215063137.GA10703@igidr.ac.in>
	<200402191426.55242.ahenningsen@email.uni-kiel.de>
Message-ID: <20040219133608.GL781@igidr.ac.in>

On Thu, Feb 19, 2004 at 02:26:55PM +0100, Arne Henningsen wrote:
> Hi,
> 
> I did not find any web page about using R in economics and econometrics so 
> far. However, this does not mean that there is none (searching with google 
> for "R" and "economics" gives many pages about economics and a name like 
> Firstname R. Lastname on it ;-)). 
> Does anybody in the list does know such a web page?
> If not, I will be happy if you, Ajay, could build and maintaine one.

Okay, I made a start, with
      http://www.mayin.org/ajayshah/KB/R/more.html

Tell me what should go into it. :-)

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From MSchwartz at medanalytics.com  Thu Feb 19 14:36:42 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 19 Feb 2004 07:36:42 -0600
Subject: [R] suppressing non-integer labels for plot x-axis
In-Reply-To: <NGBBKJEMOMLJFCOIEGCEAEMCJKAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCEAEMCJKAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <1077197802.26976.121.camel@localhost.localdomain>

On Thu, 2004-02-19 at 07:20, Jonathan Williams wrote:
> Dear R-helpers,
> I am having difficulty making R plot only integer labels on the x-axis
> of a simple graph. I want to plot the median values of a score on each
> of three occasions. Non-integer occasions are impossible. But, R keeps
> labelling the x-axis with half-occasions, despite my attempts to stop
> this using the "xaxs" and "xaxp" parameters of 'plot'.
> 
> p1=c(1,2,3); p2=c(5,15,25)
> plot(p1,p2,xlab='Occasion', ylab='Score', xlim=c(1,3), ylim=c(0,30),
> xaxp=c(1,3,3), xaxs='r')
> 
> Could someone let me know how to suppress the non-integer labels?


If you want finer control over the axis labeling, it is generally best
to suppress the axis or axes in question and explicitly draw the axis
using the axis() function.

By default, the tick marks and labels will be the result of using the
pretty() function, based upon the range of values you provide. Thus you
get:

> pretty(1:3)
[1] 1.0 1.5 2.0 2.5 3.0


To avoid this and have more control, do something like:

p1=c(1, 2, 3)
p2=c(5, 15, 25)

# Use 'xaxt = "n"' to suppress the x axis
plot(p1, p2, xlab = 'Occasion', ylab = 'Score',
     xlim = c(1, 3), ylim = c(0, 30), xaxt = "n")

# Now call axis to draw tick marks and labels at 1:3
axis(1, at = 1:3)

See ?pretty, ?plot.default and ?axis for more information.

HTH,

Marc Schartz



From friendly at yorku.ca  Thu Feb 19 14:45:01 2004
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 19 Feb 2004 08:45:01 -0500
Subject: [R] ANOVA procedure on the sufficient statistics
Message-ID: <4034BDDD.3040903@yorku.ca>

>
>
>You can apply the trick that Prof. Dalgaard recently posted in response to a
>similar question (for one-way ANOVA).  For each cell, generate data as:
>
>y <- cell.mean + cell.sd * scale(rnorm(cell.count))
>
>Then generate the data frame to feed to aov.
>
>  
>
That will generate only approximately the same means and MSE, however.

Larsen's procedure generates a weighted data set that gives the same 
ANOVA table
as the raw data, but requires that the weight= argument be used in aov().
(weights are not supported in all related functions)

-Michael

-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From m.okasha at palnet.com  Thu Feb 19 15:14:17 2004
From: m.okasha at palnet.com (Mahmoud K. Okasha)
Date: Thu, 19 Feb 2004 16:14:17 +0200
Subject: R for economists (was: [R] Almost Ideal Demand System)
References: <20040215063137.GA10703@igidr.ac.in>
	<200402191426.55242.ahenningsen@email.uni-kiel.de>
Message-ID: <000b01c3f6f2$a9e85500$2e334ed9@okasha>

Hello,

I know a few papers in economics and econometrics using R. One of them in
the Journal of Applied Econometrics. You may have a look at the following
link:
http://netec.mcc.ac.uk/WoPEc/data/Articles/jaejapmetv:14:y:1999:i:3:p:319-29
.html
or you could download the paper from the R-project site:
http://www.r-project.org/nocvs/papers/Cribari-Neto+Zarkos:1999.pdf

Best regards


----- Original Message -----
From: "Arne Henningsen" <ahenningsen at email.uni-kiel.de>
To: "Ajay Shah" <ajayshah at mayin.org>
Cc: <r-help at stat.math.ethz.ch>
Sent: Thursday, February 19, 2004 3:26 PM
Subject: R for economists (was: [R] Almost Ideal Demand System)


> Hi,
>
> I did not find any web page about using R in economics and econometrics so
> far. However, this does not mean that there is none (searching with google
> for "R" and "economics" gives many pages about economics and a name like
> Firstname R. Lastname on it ;-)).
> Does anybody in the list does know such a web page?
> If not, I will be happy if you, Ajay, could build and maintaine one.
>
> Best wishes,
> Arne
>
> On Sunday 15 February 2004 07:31, Ajay Shah wrote:
> > Anne,
> >
> > Please do make progress on packaging and releasing your R code for
> > demand analysis. Is there a web page titled "R for economists"! :-) If
> > there isn't, I'll be happy to build and maintain one, and put a link
> > to your code there.
>
> --
> Arne Henningsen
> Department of Agricultural Economics
> University of Kiel
> Olshausenstr. 40
> D-24098 Kiel (Germany)
> Tel: +49-431-880 4445
> Fax: +49-431-880 1397
> ahenningsen at agric-econ.uni-kiel.de
> http://www.uni-kiel.de/agrarpol/ahenningsen/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>



From cs369 at cam.ac.uk  Thu Feb 19 15:22:14 2004
From: cs369 at cam.ac.uk (C. Spanou)
Date: 19 Feb 2004 14:22:14 +0000
Subject: [R] polr warning message optim
Message-ID: <E1Atp4A-00066h-T8.--7ee061b709af4b21cca95c8fd7b78598730cfb42@maroon.csi.cam.ac.uk>

Hello R-users,
I am using polr function in library(MASS). The code I use is the following:

polr(as.ordered(q23p)~.,data=as.data.frame(datapr2))

where datapr2 is a matrix of 63 columns (together with the dependent 
variable) and 1665 rows. But I am receiving the warning message Error in 
optim(start, fmin, gmin, method = "BFGS", hessian = Hess, ...)

I would be very greatfull if anyone could suggest something.
Thank you



From Rau at demogr.mpg.de  Thu Feb 19 15:28:50 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Thu, 19 Feb 2004 15:28:50 +0100
Subject: R for economists (was: [R] Almost Ideal Demand System)
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A06C4@hermes.demogr.mpg.de>

Hello,

> -----Original Message-----
> From:	Mahmoud K. Okasha [SMTP:m.okasha at palnet.com]
> Sent:	Thursday, February 19, 2004 3:14 PM
> To:	r-help at stat.math.ethz.ch
> Subject:	Re: R for economists (was: [R] Almost Ideal Demand System)
> 
> Hello,
> 
> I know a few papers in economics and econometrics using R. One of them in
> the Journal of Applied Econometrics. You may have a look at the following
> link:
> http://netec.mcc.ac.uk/WoPEc/data/Articles/jaejapmetv:14:y:1999:i:3:p:319-
> 29
> .html
> or you could download the paper from the R-project site:
> http://www.r-project.org/nocvs/papers/Cribari-Neto+Zarkos:1999.pdf
> 
	In the same journal (Journal of Applied Econometrics), there is a
more recent article entitled: 
	J. Racine, R. Hyndman (2002): "Using R to teach econometrics".
Journal of Applied Econometrics, Volume 17, Issue 2, p. 175-189

	Hopefully it is of any use for you!?!
	Best,
	Roland


+++++
This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked.   If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.



From Simon.Fear at synequanon.com  Thu Feb 19 15:26:20 2004
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Thu, 19 Feb 2004 14:26:20 -0000
Subject: [R] pass by reference -- how to do it
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572F021F1@synequanon01>

I don't disagree - it's just that I once spent a day trying
to work out why my old S-Plus library's <<- didn't work in R
as I thought it should - and then I read the FAQ ...

Especially in interactive work, <<- is very unlikely to cause
a problem. But it's definitely dodgy to trust to this
idiom within a package, say.

Simon

PS also for the record, I stand corrected about S-Plus using <<- to
assign to frame 1; it assigns to database 1. Sorry! 

> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at myway.com]
> Sent: 19 February 2004 13:33
> To: Simon Fear; robert_dodier at yahoo.com; andy_liaw at merck.com;
> andy_liaw at merck.com; R-help at stat.math.ethz.ch
> Subject: RE: [R] pass by reference -- how to do it
> 
> 
> Security Warning: 
> If you are not sure an attachment is safe to open please contact  
> Andy on x234. There are 0 attachments with this message. 
> ________________________________________________________________ 
>  
> 
> [sorry if this appears twice. I had an email problem and am
> 
> sending it out again]
> 
>  
> 
> As you and Andy correctly point out, <<- searches through
> 
> its environments and it may find a match prior to the Global
> 
> Environment.
> 
> 
> 
> On the other hand, while its possible to get into trouble,
> 
> I believe its actually not that likely since avoiding
> 
> nested functions is all you have to do.
> 
> 
> 
> For example, we can modify the previous example to make it
> 
> NOT work like this. With g nested in f, g's x refers to f's x,
> 
> not the global x:
> 
> 
> 
> f <- function(x) { g <- function() x[1] <<- x[1]+1; g() } # g nested 
> 
> x <- 1:5
> 
> f(x)
> 
> x # x unchanged since x in g matches x in f, not the global x
> 
> 
> 
> However, by simply defining g at the top level rather than
> 
> nesting it in f2, the code does work to modify the global x
> 
> despite the fact that f2 defines its own x:
> 
> 
> 
> g <- function() x[1] <<- x[1]+1 # g at not level, i.e. not nested
> 
> f2 <- function(x) g()
> 
> x <- 1:5
> 
> f2(x)
> 
> x # c(2,2,3,4,5)
> 
> 
> 
> The fact that its this easy to guarantee that it works seems to
> 
> be one of the advantages of R's lexical scoping.
> 
> 
> 
> ---
> 
> Date: Thu, 19 Feb 2004 10:11:50 -0000 
> 
> From: Simon Fear <Simon.Fear at synequanon.com>
> 
> To: <ggrothendieck at myway.com>, <robert_dodier at yahoo.com>, 
> <r-help at stat.math.ethz.ch> 
> 
> Subject: RE: [R] pass by reference -- how to do it 
> 
> 
> 
> 
> 
> For the record, be careful: <<- does not necessarily assign to 
> 
> the global environment. In R ` x <<- value` assigns `value` to 
> 
> the first instance of `x` it can find using lexical scoping. 
> Only if it 
> 
> doesn't find any such variable, it will indeed create an `x` 
> 
> in .GlobalEnv.
> 
> 
> 
> Tricky for those brought up on S-Plus, where assignment <<- 
> 
> is guaranteed to assign to frame 1. 
> 
> 
> 
> HTH
> 
> 
> 
> > -----Original Message-----
> 
> > From: Gabor Grothendieck [mailto:ggrothendieck at myway.com]
> 
> > Sent: 18 February 2004 04:19
> 
> > To: robert_dodier at yahoo.com; r-help at stat.math.ethz.ch
> 
> > Subject: RE: [R] pass by reference -- how to do it
> 
> > 
> 
> > 
> 
> > Security Warning: 
> 
> > If you are not sure an attachment is safe to open please contact 
> 
> > Andy on x234. There are 0 attachments with this message. 
> 
> > ________________________________________________________________ 
> 
> > 
> 
> > 
> 
> > 
> 
> > If you don't mind NOT passing your arrays at all then you 
> 
> > can do this:
> 
> > 
> 
> > f <- function() a[1] <<- a[1] + 1
> 
> > a <- 1:5
> 
> > f() # increments first element of a by 1
> 
> > a # c(2,2,3,4,5)
> 
> > 
> 
> > The <<- causes the expression to take place in the global 
> 
> > environment.
> 
> > 
> 
> > If you want to actually pass your arrays by reference then the
> 
> > following works although its a bit messy:
> 
> > 
> 
> > g <- function(z) eval(eval(substitute(expression(z[1] <<- z[1]+1))))
> 
> > a <- 1:5
> 
> > g(a) # increments first element of a by 1
> 
> > a # c(2,2,3,4,5)
> 
> > 
> 
> > The <<- causes the expression to be evaluated in the global 
> 
> > environment. expression() turns its argument into an object
> 
> > of mode expression. substitute() replaces z with the argument 
> 
> > passed to f in that expression and returns an object of mode 
> 
> > call. The inner eval turns the object of mode call into an 
> 
> > object of mode expression and the outer eval evaluates that 
> 
> > expression. 
> 
> > 
> 
> > ---
> 
> > Date: Tue, 17 Feb 2004 13:23:58 -0800 (PST) 
> 
> > From: Robert Dodier <robert_dodier at yahoo.com>
> 
> > To: <r-help at stat.math.ethz.ch> 
> 
> > Subject: [R] pass by reference -- how to do it 
> 
> > 
> 
> > 
> 
> > Hello,
> 
> > 
> 
> > Pass by reference appears to be a topic which comes up
> 
> > from time to time, but I wasn't able to find something in
> 
> > the R-help archives which tells how to accomplish it.
> 
> > 
> 
> > I have a problem that you may have seen before -- R runs
> 
> > out of memory when processing large matrices. Part of the
> 
> > problem for me is that I am using some large matrices as
> 
> > function arguments, and these are modified, which leads 
> 
> > to allocating copies of the matrices. 
> 
> > 
> 
> > I would like to do the modification "in place" so that
> 
> > a copy is not required. Thanks for any light you can shed
> 
> > on this.
> 
> > 
> 
> > If you're tempted to tell me "you don't really want to do that" --
> 
> > let me save you the trouble. You are so very right! Indeed I
> 
> > don't want to have pass by reference variables. OTOH I don't
> 
> > want R to come to a dead halt at an inconvenient time either.
> 
> > 
> 
> > Thanks for your help,
> 
> > Robert Dodier
> 
> 
> 
> _______________________________________________
> No banners. No pop-ups. No kidding.
> Introducing My Way - http://www.myway.com
>  
 
Simon Fear 
Senior Statistician 
Syne qua non Ltd 
Tel: +44 (0) 1379 644449 
Fax: +44 (0) 1379 644445 
email: Simon.Fear at synequanon.com 
web: http://www.synequanon.com 
  
Number of attachments included with this message: 0 
  
This message (and any associated files) is confidential and\...{{dropped}}



From Achim.Zeileis at wu-wien.ac.at  Thu Feb 19 15:32:04 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 19 Feb 2004 15:32:04 +0100
Subject: R for economists (was: [R] Almost Ideal Demand System)
In-Reply-To: <000b01c3f6f2$a9e85500$2e334ed9@okasha>
References: <20040215063137.GA10703@igidr.ac.in>
	<200402191426.55242.ahenningsen@email.uni-kiel.de>
	<000b01c3f6f2$a9e85500$2e334ed9@okasha>
Message-ID: <20040219153204.44350816.Achim.Zeileis@wu-wien.ac.at>

On Thu, 19 Feb 2004 16:14:17 +0200 Mahmoud K. Okasha wrote:

> Hello,
> 
> I know a few papers in economics and econometrics using R. One of them
> in the Journal of Applied Econometrics. You may have a look at the
> following link:
> http://netec.mcc.ac.uk/WoPEc/data/Articles/jaejapmetv:14:y:1999:i:3:p:319-29
> .html
> or you could download the paper from the R-project site:
> http://www.r-project.org/nocvs/papers/Cribari-Neto+Zarkos:1999.pdf

There was also another paper in the JAE in 2002 about econometrics and
R:

@Article{jae:Racine+Hyndman:2002,
  author    = {Jeff Racine and Rob Hyndman},
  title     = {Using \textsf{R} To Teach Econometrics},
  journal   = {Journal of Applied Econometrics},
  year      = {2002},
  volume    = {17},
  pages     = {175--189}
}

which gave a nice overview of what is (resp. was available at that time)
in R for doing basic econometrics.
Z

> Best regards
> 
> 
> ----- Original Message -----
> From: "Arne Henningsen" <ahenningsen at email.uni-kiel.de>
> To: "Ajay Shah" <ajayshah at mayin.org>
> Cc: <r-help at stat.math.ethz.ch>
> Sent: Thursday, February 19, 2004 3:26 PM
> Subject: R for economists (was: [R] Almost Ideal Demand System)
> 
> 
> > Hi,
> >
> > I did not find any web page about using R in economics and
> > econometrics so far. However, this does not mean that there is none
> > (searching with google for "R" and "economics" gives many pages
> > about economics and a name like Firstname R. Lastname on it ;-)).
> > Does anybody in the list does know such a web page?
> > If not, I will be happy if you, Ajay, could build and maintaine one.
> >
> > Best wishes,
> > Arne
> >
> > On Sunday 15 February 2004 07:31, Ajay Shah wrote:
> > > Anne,
> > >
> > > Please do make progress on packaging and releasing your R code for
> > > demand analysis. Is there a web page titled "R for economists"!
> > > :-) If there isn't, I'll be happy to build and maintain one, and
> > > put a link to your code there.
> >
> > --
> > Arne Henningsen
> > Department of Agricultural Economics
> > University of Kiel
> > Olshausenstr. 40
> > D-24098 Kiel (Germany)
> > Tel: +49-431-880 4445
> > Fax: +49-431-880 1397
> > ahenningsen at agric-econ.uni-kiel.de
> > http://www.uni-kiel.de/agrarpol/ahenningsen/
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From vaclav.petricek at mff.cuni.cz  Thu Feb 19 15:45:50 2004
From: vaclav.petricek at mff.cuni.cz (Vaclav Petricek)
Date: Thu, 19 Feb 2004 15:45:50 +0100 (CET)
Subject: [R] reshape direction=wide 
Message-ID: <Pine.BSF.4.50.0402191514350.64459-100000@sec.ms.mff.cuni.cz>


Hello

I am reshaping a data.frame bids --> reshaped as shown below.

I thought this should be possible with a single invocation of
reshape, but the only way I came up with is reshaping subsets for each
keyword and then joining them together. Does anyone have an idea how to
solve this in a more elegant way? Efficiency is a concern as the datasets
are very large.

Is there a way to specify multiple v.names?

bids
        batch     keyword rank        id  bid
1   312221627   Broadband    1 401173481 2.64
2   312221627   Broadband    2 236096320 2.63
3   312221627   Broadband    3 367411639 2.62
4   312221627   Broadband    4 188906982 2.61
5   312221627   Broadband    5 227691359 2.01
205 312221627 Outsourcing    1 406300683 3.68
206 312221627 Outsourcing    2  12862485 3.65
207 312221627 Outsourcing    3 237944232 3.65
208 312221627 Outsourcing    4  95867634 3.64

reshaped
       batch   keyword bid.1 bid.2 bid.3 bid.4 bid.5      id.1      id.2      id.3      id.4      id.5
1  312221608 Broadband  2.63  2.62  2.62  2.61  2.01 236096320 401173481 367411639 188906982 227691359
2  312221617 Broadband  2.64  2.63  2.62  2.61  2.01 401173481 236096320 367411639 188906982 227691359
3  312221627 Broadband  2.64  2.63  2.62  2.61  2.01 401173481 236096320 367411639 188906982 227691359
4  312221639 Broadband  2.65  2.64  2.63  2.62  2.01 188906982 401173481 236096320 367411639 227691359
5  312221649 Broadband  2.65  2.64  2.63  2.62  2.01 188906982 401173481 236096320 367411639 227691359
6  312221659 Broadband  2.65  2.64  2.63  2.62  2.01 188906982 401173481 236096320 367411639 227691359
7  312221708 Broadband  2.65  2.64  2.63  2.62  2.01 188906982 401173481 236096320 367411639 227691359
8  312221719 Broadband  2.65  2.64  2.63  2.62  2.01 188906982 401173481 236096320 367411639 227691359
9  312221729 Broadband  2.65  2.64  2.63  2.62  2.01 188906982 401173481 236096320 367411639 227691359
10 312221739 Broadband  2.65  2.64  2.63  2.62  2.01 188906982 401173481 236096320 367411639 227691359


keywords <- levels(bids[,'keyword'])

reshaped <<- NULL
for (key in keywords)
{
	keywordbid <- bids[bids[,'keyword']==key,]
	keywordbid[,'id'] = NULL
	keywordbid <- reshape(keywordbid, v.names='bid',
	                      timevar='rank',direction='wide',idvar='batch')
	keywordid <- bids[bids[,'keyword']==key,]
	keywordid[,'bid'] = NULL
	keywordid <- reshape(keywordid, v.names='id',
	                     timevar='rank',direction='wide',idvar='batch')
	if(is.null(reshaped))
	{
		reshaped <<- merge(keywordbid, keywordid)
	} else {
		reshaped <<- rbind(reshaped, merge(keywordbid, keywordid))
	}
	rm(keywordbid, keywordid)
}

Thank you very much for any comments,

--

Vaclav Petricek
http://kocour.ms.mff.cuni.cz/~petricek



From mzhang1208 at hotmail.com  Thu Feb 19 16:46:28 2004
From: mzhang1208 at hotmail.com (weidong zhang)
Date: Thu, 19 Feb 2004 15:46:28 +0000
Subject: [R] More variables on pca
Message-ID: <BAY1-F1373avgs7wlXP00035e78@hotmail.com>

Hi,

When I have more variables than units, e.g. a 10x20 data frame with 20 
variables. princomp can't do pca on variables. prcomp from mva package can 
do th etrick but gave 10 principal components. Should we expect 20 for this 
case?

Thanks in advance,
Weidong

_________________________________________________________________




From tlumley at u.washington.edu  Thu Feb 19 16:49:04 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 19 Feb 2004 07:49:04 -0800 (PST)
Subject: [R] Area between CDFs
In-Reply-To: <644D9337A02FC24689647BF9E48EC39E08ABB771@drm556>
References: <644D9337A02FC24689647BF9E48EC39E08ABB771@drm556>
Message-ID: <Pine.A41.4.58.0402190747020.53494@homer09.u.washington.edu>

On Wed, 18 Feb 2004, Samuelson, Frank* wrote:
>
> You may not want to integrate cdfs.  They're already probabilities.  :)
> Nice analytic statistics exist for just the maximum distance between
> the cdfs, for example.
>

And for the area between cdfs, which is perhaps better known as the
difference in means.

	-thomas



From wolski at molgen.mpg.de  Thu Feb 19 16:53:13 2004
From: wolski at molgen.mpg.de (wolski)
Date: Thu, 19 Feb 2004 16:53:13 +0100
Subject: [R] read.socket - Strange strings. How to force sub to remove all
 occurences of a pattern?
Message-ID: <200402191653130153.059AA4F6@harry.molgen.mpg.de>



I am opening a connection to an apache server sending a get and then I am reading from the socket.
All works finde except that I am getting some strange strings disrupting the html
e.g.

<FON\r\nffb\r\nT COLOR ...

\r\na48\r\n
  \r\nffb\r\n 

They are not frequent ( a few of them) but of course make live hard. 
I cant observe them with lynx --source they dont occure. 

I am trying a workaround with sub. But it removes only the first occurence.
How I can force sub to remove all occurences of a pattern and not only the first?

Eryk



From rxg218 at psu.edu  Thu Feb 19 16:56:04 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Thu, 19 Feb 2004 10:56:04 -0500
Subject: [R] filling the area between two curves in a plot
Message-ID: <1077206163.15820.3.camel@ra.chem.psu.edu>

Hi,
  does anybody know how I can color the area enclosed between two curves
on a plot?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
A debugged program is one for which you have not yet found the
conditions that make it fail.
-- Jerry Ogdin



From thpe at hhbio.wasser.tu-dresden.de  Thu Feb 19 17:12:37 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Thu, 19 Feb 2004 17:12:37 +0100
Subject: [R] Re: R for economists
In-Reply-To: <200402191426.55242.ahenningsen@email.uni-kiel.de>
References: <20040215063137.GA10703@igidr.ac.in>
	<200402191426.55242.ahenningsen@email.uni-kiel.de>
Message-ID: <4034E075.7000405@hhbio.wasser.tu-dresden.de>

Arne Henningsen wrote:

> Hi,
> 
> I did not find any web page about using R in economics and econometrics so 
> far. However, this does not mean that there is none (searching with google 
> for "R" and "economics" gives many pages about economics and a name like 
> Firstname R. Lastname on it ;-)). 
> Does anybody in the list does know such a web page?
> If not, I will be happy if you, Ajay, could build and maintaine one.

You can simply search for "econometrics" and "r-project" and you will 
find something.

Thomas P.



From dmurdoch at pair.com  Thu Feb 19 17:36:40 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 19 Feb 2004 11:36:40 -0500
Subject: [R] ANOVA procedure on the sufficient statistics
In-Reply-To: <4034BDDD.3040903@yorku.ca>
References: <4034BDDD.3040903@yorku.ca>
Message-ID: <hvo930das2krnemp61j1gdgn7cgs89c3g6@4ax.com>

On Thu, 19 Feb 2004 08:45:01 -0500, Michael Friendly
<friendly at yorku.ca> wrote :

>>
>>
>>You can apply the trick that Prof. Dalgaard recently posted in response to a
>>similar question (for one-way ANOVA).  For each cell, generate data as:
>>
>>y <- cell.mean + cell.sd * scale(rnorm(cell.count))
>>
>>Then generate the data frame to feed to aov.
>>
>>  
>>
>That will generate only approximately the same means and MSE, however.
>
>Larsen's procedure generates a weighted data set that gives the same 
>ANOVA table
>as the raw data, but requires that the weight= argument be used in aov().
>(weights are not supported in all related functions)

Are you sure about that?  I think the call to "scale()" makes them
come out identical.

In fact, the call to rnorm() is unnecessary; it would work just as
well with 

y <- cell.mean + cell.sd * scale(1:cell.count)

(unless I'm missing something...)

Duncan



From cullens at tcd.ie  Thu Feb 19 17:40:13 2004
From: cullens at tcd.ie (Simon Cullen)
Date: Thu, 19 Feb 2004 16:40:13 -0000
Subject: R for economists (was: [R] Almost Ideal Demand System)
In-Reply-To: <20040219133608.GL781@igidr.ac.in>
References: <20040215063137.GA10703@igidr.ac.in>
	<200402191426.55242.ahenningsen@email.uni-kiel.de>
	<20040219133608.GL781@igidr.ac.in>
Message-ID: <opr3mlxb0t1pelvz@smtp.tcd.ie>

On Thu, 19 Feb 2004 19:06:08 +0530, Ajay Shah <ajayshah at mayin.org> wrote:

<snip R for economists>

> Okay, I made a start, with
>       http://www.mayin.org/ajayshah/KB/R/more.html
>
> Tell me what should go into it. :-)

I think the most important thing for economists would be a list of the  
common econometric models and how they are accessed in R, for instance  
packages and the functions within those packages.

An example is what is known as a Tobit model to econometricians, which is  
one type of a survival model (to everybody else!). (This isn't that good  
an example as help.search("tobit") would probably turn up the right  
library.)

If you could produce a table with Econometrics to R translations that  
would be immensely helpful, as a start. I know someone suggested creating  
a facility for 'aliasing' econometrics-speak to R functions, but this got  
shot down for being unwieldy (rightly so, I think).

I'll let you know if I have any useful suggestions.

-- 
SC

Simon Cullen
Room 3030
Dept. Of Economics
Trinity College Dublin

Ph. (608)3477
Email cullens at tcd.ie



From Joerg.Schaber at uv.es  Thu Feb 19 17:40:25 2004
From: Joerg.Schaber at uv.es (Joerg Schaber)
Date: Thu, 19 Feb 2004 17:40:25 +0100
Subject: [R] Comparing two regression slopes
Message-ID: <4034E6F9.2020807@uv.es>

I would suggest the method of Sokal and Rholf (1995) S. 498, using the F 
test.
Below I repeat the analysis by Spencer Graves:

Spencer:
 > df1 <- data.frame(x=1:3, y=1:3+rnorm(3))
 > df2 <- data.frame(x=1:3, y=1:3+rnorm(3))
 > fit1 <- lm(y~x, df1)
 > s1 <- summary(fit1)$coefficients
 > fit2 <- lm(y~x, df2)
 > s2 <- summary(fit2)$coefficients
 > db <- (s2[2,1]-s1[2,1])
 > sd <- sqrt(s2[2,2]^2+s1[2,2]^2)
 > df <- (fit1$df.residual+fit2$df.residual)
 >  td <- db/sd
 > 2*pt(-abs(td), df)
[1] 0.8757552

Sokal & Rholf
 > n <- length(df1$x)      
 > ssx1 <- var(df1$x)*(n-1)      # sums of squares
 > ssx2 <- var(df2$x)*(n-1)
 > ssy1 <- var(df1$y)*(n-1)
 > ssy2 <- var(df2$y)*(n-1)
 > sxy1 <- cor(df1$x,df1$y)*(n-1)
 > sxy2 <- cor(df2$x,df2$y)*(n-1)
 > d2xy1 <- ssy1 - sxy1^2/ssx1         # unexplained
 > d2xy2 <- ssy2 - sxy2^2/ssx2
 > Fs <- db^2/((ssx1+ssx2)/(ssx1*ssx2)*(d2xy1+ d2xy2)/(2*n-4))  # F 
statistic
 > 1-pf(Fs,1,2*n-4)
[1] 0.8827102

slight differences, but can be MUCH larger with more data!

greetings,

joerg



From andy_liaw at merck.com  Thu Feb 19 17:46:25 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 19 Feb 2004 11:46:25 -0500
Subject: [R] filling the area between two curves in a plot
Message-ID: <3A822319EB35174CA3714066D590DCD504AF77F7@usrymx25.merck.com>

Assuming the coordinates for the two curves are x1, y1, x2 and y2, and that
the pairs are sorted by x1 and x2, respectively.  Then just do something
like:

polygon(c(x1, rev(x2)), c(y1, rev(y2), ...)

HTH,
Andy

> From: Rajarshi Guha
> 
> Hi,
>   does anybody know how I can color the area enclosed between 
> two curves
> on a plot?
> 
> Thanks,
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> A debugged program is one for which you have not yet found the
> conditions that make it fail.
> -- Jerry Ogdin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From sundar.dorai-raj at pdf.com  Thu Feb 19 18:02:07 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 19 Feb 2004 11:02:07 -0600
Subject: [R] NAs introduced by coercion warning?
In-Reply-To: <BC592B3C.19AB2%greenberg@ucdavis.edu>
References: <BC592B3C.19AB2%greenberg@ucdavis.edu>
Message-ID: <4034EC0F.6060203@pdf.com>

Jonathan,
   It's still hard to tell. Try this:

options(warn = 1) # see ?options for explanation

## RUN YOUR CODE

Regards,
Sundar


Jonathan Greenberg wrote:

> Its hard for me to pinpoint where this is happening, since I'm working on an
> image that?s about 10000 x 20000 pixels, and 12 bands deep and I'm using a
> set of for-next loops to pull out subsections of data.  I can guarantee the
> input values are all floating point values.
> 
> To be more specific, I have created a classification tree, and I want to
> apply it to that large floating point image (all the band names match up)
> and write the prediction (probability) values to a file.  What happens if a
> decision tree tries to classify a set of input values that are completely
> outside of the range of the input tree?
> 
> Here's the code I was using.  I should mention that this worked on a small
> subset (400 x 400 pixels) that wouldn't have any "weird" values (negative or
> zero).  The output file from this is turning out to be slightly smaller than
> it should given the samples,lines,bands and number type, which I why I'm
> wondering if the tree is simply dropping those "bad" values rather than
> giving them some value (e.g. 0):
> 
> ## Creating the tree
> library(tree)
> bands=12
> bandnames<-paste(c("B"),1:bands,sep="")
> treetraindata=read.csv("classtrainshad040205.csv",header=TRUE)
> names(treetraindata)[2:6]<-bandnames[1:5]
> names(treetraindata)[8:14]<-bandnames[6:12]
> treetraindata$Class_Name<-as.factor(treetraindata$Class_Name)
> 
> ## Create an overfit tree
> treetrain<-tree(Class_Name ~ B1 + B2 + B3 +
> B4+B5+B6+B7+B8+B9+B10+B11+B12,treetraindata,mincut=1,minsize=2,mindev=0)
> 
> ## Extracts a slice of data out of an ENVI BSQ file
> envigetslice<-function(fileconnection,samples,lines,bands,interleave,datatyp
> e,maxpixels) {
>     currentloc=seek(fileconnection,where=NA,origin="current")
>     ## If data is integer
>     if(datatype==3) {
>         numbersize=2
>         datatype=integer()
>         if ((samples*lines)-(currentloc/numbersize) < maxpixels)
> maxpixels=(samples*lines)-(currentloc/numbersize)
>         envislice <-
> readBin(fileconnection,integer(),maxpixels,size=numbersize)
>         newloc=seek(fileconnection,where=NA,origin="current")
>         if (bands > 1) {
>             for (i in 1:(bands-1)) {
>                 
> seek(fileconnection,where=currentloc+(samples*lines*numbersize*i),origin="st
> art")
>                 currentslice <-
> readBin(fileconnection,integer(),maxpixels,size=numbersize)
>                 envislice=data.frame(envislice,currentslice)
>             }
>         }
>     }
>     ## If data is floating point
>     if(datatype==4) {
>         numbersize=4
>         if ((samples*lines)-(currentloc/numbersize) < maxpixels)
> maxpixels=(samples*lines)-(currentloc/numbersize)
>         envislice <-
> readBin(fileconnection,double(),maxpixels,size=numbersize)
>         newloc=seek(fileconnection,where=NA,origin="current")
>         if (bands > 1) {
>             for (i in 1:(bands-1)) {
>                 
> seek(fileconnection,where=currentloc+(samples*lines*numbersize*i),origin="st
> art")
>                 currentslice <-
> readBin(fileconnection,double(),maxpixels,size=numbersize)
>                 envislice=data.frame(envislice,currentslice)
>             }
>         }
>     }
>     seek(fileconnection,where=newloc,origin="start")
>     envislice
> }
> 
> ## Read ENVI files in subsets
> ## interleave: 1=bsq
> ## datatype: (follows ENVI format):
> ##    3: long integer
> ##    4:floating point
> 
> 
> ## Apply the classifier
> imageclasstree<-function(infile,outfile,dectree,samples,lines,bands,interlea
> ve,datatype,maxpixels) {
> 
> fileconnection<-file(infile,open="rb")
> outfileconnection=file(outfile,open="wb")
> 
> numpixels = samples * lines
> numslices=ceiling(numpixels/maxpixels)
> if (numslices == floor(numpixels/maxpixels)) numslices=numslices-1
> 
> bandnames<-paste(c("B"),1:bands,sep="")
> 
> ## Loop for processing images
> for(j in 0:numslices) {
>     print((j/numslices)*100)
>     
> envislice<-envigetslice(fileconnection,samples,lines,bands,interleave,dataty
> pe,maxpixels)
>     names(envislice)<-bandnames
>     predictslice<-predict(treetrain,envislice,type=c("vector"))
>     
> predictslice<-as.integer(round(as.vector(t(predictslice*10000)),digits=0))
>     predictslice
>     writeBin(predictslice,outfileconnection,size=2)
> }
> close(fileconnection)
> close(outfileconnection)
> }
> 
> imageclasstree("flt4aall","flt4adt", treetrain,11216,18173,12,1,4,25000)
> 
> On 2/18/04 2:25 PM, "Sundar Dorai-Raj" <sundar.dorai-raj at PDF.COM> wrote:
> 
> 
>>
>>Jonathan Greenberg wrote:
>>
>>
>>>I'm running a decision tree on a large dataset, and I'm getting multiple
>>>instances of "NAs introduced by coercion" (> 50).  What does this mean?
>>>
>>>--j
>>>
>>
>>My guess would be you're trying to convert from character to numeric and
>>are unable to do so. As in,
>>
>>
>>>as.numeric("A")
>>
>>[1] NA
>>Warning message:
>>NAs introduced by coercion
>>
>>>as.numeric("1")
>>
>>[1] 1
>>
>>But without more information from you it's impossible to tell.
>>
>>See the posting guide at
>>
>>http://www.R-project.org/posting-guide.html
>>
>>Regards,
>>Sundar
>>
> 
> 
>



From thpe at hhbio.wasser.tu-dresden.de  Thu Feb 19 18:05:03 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Thu, 19 Feb 2004 18:05:03 +0100
Subject: [R] filling the area between two curves in a plot
In-Reply-To: <1077206163.15820.3.camel@ra.chem.psu.edu>
References: <1077206163.15820.3.camel@ra.chem.psu.edu>
Message-ID: <4034ECBF.6010802@hhbio.wasser.tu-dresden.de>

Rajarshi Guha wrote:

> Hi,
>   does anybody know how I can color the area enclosed between two curves
> on a plot?

This is possible with the polygon function. Try something like:

# create some data
x <- sort(runif(10, min=0, max=10))
y <- runif(10, min=2, max=5)

#Polygon-Plot
plot(x,y, type="n", ylim=c(0,5))
polygon(c(x[1], x, x[length(x)]), c(0, y, 0), col="green")


# ... alternatively you can construct a polygon
# from two separate curves with

# create some more data
x <- sort(runif(10, min=0, max=10))
y1 <- runif(10, min=2, max=5)
y2 <- runif(10, min=0, max=2)

#Polygon-Plot 2
polygon(c(x, rev(x)), c(y1, rev(y2)), density=20)


Hope it helps!

Thomas P.



From p.dalgaard at biostat.ku.dk  Thu Feb 19 18:19:38 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Feb 2004 18:19:38 +0100
Subject: [R] building the development version
In-Reply-To: <16435.51269.373330.463741@fry.research.att.com>
References: <Pine.LNX.4.44.0402181838030.1651-100000@gannet.stats>
	<x2znbgqkym.fsf@biostat.ku.dk>
	<16435.51269.373330.463741@fry.research.att.com>
Message-ID: <x24qtnhtqt.fsf@biostat.ku.dk>

Deborah Swayne <dfs at research.att.com> writes:

> Peter Dalgaard writes:
>  > 
>  > OK, that I can confirm. They do turn up on a checkout without the -P
>  > option, but disappear after "cvs up -Pd". Tony, Debbie, did you
>  > perhaps configure before attempting to prune the empty dirs? Could you
>  > try 
>  > 
>  > cvs -d ...blabla... co -P R
> 
> I've use rsync; I don't know if that makes any difference:
>    rsync -rC rsync.r-project.org::r-devel R

Hmm. It might mean that the rsync tree is built without the -P. If so,
we should probably fix it.
 
> In any case, I deleted all the old source code and started over,
> and the development version emerged without any difficulty.

Sounds like this was after Brian fixed the Makefiles.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tlumley at u.washington.edu  Thu Feb 19 18:19:39 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 19 Feb 2004 09:19:39 -0800 (PST)
Subject: [R] filling the area between two curves in a plot
In-Reply-To: <1077206163.15820.3.camel@ra.chem.psu.edu>
References: <1077206163.15820.3.camel@ra.chem.psu.edu>
Message-ID: <Pine.A41.4.58.0402190919250.44886@homer19.u.washington.edu>

On Thu, 19 Feb 2004, Rajarshi Guha wrote:

> Hi,
>   does anybody know how I can color the area enclosed between two curves
> on a plot?
>

There is an example of this in demo(graphics).

	-thomas



From tlumley at u.washington.edu  Thu Feb 19 18:22:09 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 19 Feb 2004 09:22:09 -0800 (PST)
Subject: [R] Obtaining SE from the hessian matrix
In-Reply-To: <20040219133803.GA12760@nf034.jinr.ru>
References: <20040219133803.GA12760@nf034.jinr.ru>
Message-ID: <Pine.A41.4.58.0402190920130.44886@homer19.u.washington.edu>

On Thu, 19 Feb 2004, Timur Elzhov wrote:
> So, what is the _right_ way for obtatining SE? Why two those formulas above
> differ?
>

If you are maximising a likelihood then the covariance matrix of the
estimates is (asymptotically) the inverse of the negative of the Hessian.

The standard errors are the square roots of the diagonal elements of the
covariance.

So if you have the Hessian you need to invert it, if you have the
covariance matrix, you don't.

	-thomas



From petzoldt at rcs.urz.tu-dresden.de  Thu Feb 19 18:29:27 2004
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Thu, 19 Feb 2004 18:29:27 +0100
Subject: [R] efficient matrix approx
Message-ID: <4034F277.20509@rcs.urz.tu-dresden.de>

Hello,

I am looking for a highly efficient matrix version of linear
interpolation (like approx). As an example I have data like follows:

x<-data.frame(time=1:20, x=(1:20)/10, y=runif(20))
t <- seq(1.5, 15.5 ,by=0.5)

# and I found the following solution:

nam <- names(x)
app <- lapply(x[2:3],approx,x=x$time, xout=t)
r <- c(1, 2*(1:(ncol(x)-1)))
x.new <- as.data.frame(unlist(app[1:2], recursive=F)[r])
names(x.new) <- nam


As this routine should be called several times during an optimization
procedure I wonder if there is a more direct one which I have overlooked?

Thank you in advance

Thomas P.



From spencer.graves at pdf.com  Thu Feb 19 18:40:57 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 19 Feb 2004 09:40:57 -0800
Subject: [R] Comparing two regression slopes
In-Reply-To: <4034E6F9.2020807@uv.es>
References: <4034E6F9.2020807@uv.es>
Message-ID: <4034F529.8020605@pdf.com>

      I missed the earlier thread, but if I had the data and not just 
the table of coefficients and standard errors, then I'd try combining 
the data sets as follows: 

 > set.seed(1)
 > df1 <- data.frame(x=1:3, y=1:3+rnorm(3))
 > df2 <- data.frame(x=1:3, y=1:3+rnorm(3))
 > DF. <- data.frame(source=rep(c(-1,1), each=3), rbind(df1, df2))
 >
 > anova(lm(y~x+I(source*x), DF.))
Analysis of Variance Table

Response: y
              Df  Sum Sq Mean Sq F value Pr(>F)
x              1 0.47271 0.47271  0.5696 0.5053
I(source * x)  1 0.23386 0.23386  0.2818 0.6323
Residuals      3 2.48964 0.82988              
 >
      hope this helps.  spencer graves

Joerg Schaber wrote:

> I would suggest the method of Sokal and Rholf (1995) S. 498, using the 
> F test.
> Below I repeat the analysis by Spencer Graves:
>
> Spencer:
> > df1 <- data.frame(x=1:3, y=1:3+rnorm(3))
> > df2 <- data.frame(x=1:3, y=1:3+rnorm(3))
> > fit1 <- lm(y~x, df1)
> > s1 <- summary(fit1)$coefficients
> > fit2 <- lm(y~x, df2)
> > s2 <- summary(fit2)$coefficients
> > db <- (s2[2,1]-s1[2,1])
> > sd <- sqrt(s2[2,2]^2+s1[2,2]^2)
> > df <- (fit1$df.residual+fit2$df.residual)
> >  td <- db/sd
> > 2*pt(-abs(td), df)
> [1] 0.8757552
>
> Sokal & Rholf
> > n <- length(df1$x)      > ssx1 <- var(df1$x)*(n-1)      # sums of 
> squares
> > ssx2 <- var(df2$x)*(n-1)
> > ssy1 <- var(df1$y)*(n-1)
> > ssy2 <- var(df2$y)*(n-1)
> > sxy1 <- cor(df1$x,df1$y)*(n-1)
> > sxy2 <- cor(df2$x,df2$y)*(n-1)
> > d2xy1 <- ssy1 - sxy1^2/ssx1         # unexplained
> > d2xy2 <- ssy2 - sxy2^2/ssx2
> > Fs <- db^2/((ssx1+ssx2)/(ssx1*ssx2)*(d2xy1+ d2xy2)/(2*n-4))  # F 
> statistic
> > 1-pf(Fs,1,2*n-4)
> [1] 0.8827102
>
> slight differences, but can be MUCH larger with more data!
>
> greetings,
>
> joerg
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From HankeA at mar.dfo-mpo.gc.ca  Thu Feb 19 18:27:08 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Thu, 19 Feb 2004 13:27:08 -0400
Subject: [R] reshape direction=wide
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE124942@msgmarsta01.bio.dfo.ca>


v.names=c("var1","var2") creates a separate column for each combination of
variables in v.names and level of variable identified by timevar.



I am reshaping a data.frame bids --> reshaped as shown below.

I thought this should be possible with a single invocation of
reshape, but the only way I came up with is reshaping subsets for each
keyword and then joining them together. Does anyone have an idea how to
solve this in a more elegant way? Efficiency is a concern as the datasets
are very large.

Is there a way to specify multiple v.names?



Alex Hanke
Department of Fisheries and Oceans
St. Andrews Biological Station
531 Brandy Cove Road
St. Andrews, NB
Canada
E5B 2L9



From dsmith at insightful.com  Thu Feb 19 18:48:15 2004
From: dsmith at insightful.com (David Smith)
Date: Thu, 19 Feb 2004 09:48:15 -0800
Subject: R for economists (was: [R] Almost Ideal Demand System)
Message-ID: <EDAC416B87ECCA44BEAB4D0CF48034EF4544DB@se2kexch01.insightful.com>

Not exactly R-related, but since there seems to be a lot of interest in this
topic, I'd also mention the book:

"Modeling Financial Time Series with S-PLUS", by Eric Zivot et al, which has
several chapers on econometric modeling with S. The book website is at:

http://faculty.washington.edu/ezivot/modelingFinancialTimeSeries.htm

The functions and examples in the book can be run with the S+FinMetrics
module for S-PLUS 6. Details at:
http://www.insightful.com/products/finmetrics/

# David Smith

-- 
David M Smith <dsmith at insightful.com>
Product Manager, Insightful Corp, Seattle WA
Tel: +1 (206) 802 2360
Fax: +1 (206) 283 6310

New Insightful Miner 3! Discover how Pfizer, Bank of America and others are
using Insightful Miner -- a highly scalable data analysis workbench. Learn
more at http://www.insightful.com/products/iminer

> -----Original Message-----
> From: Ajay Shah [mailto:ajayshah at mayin.org]
> Sent: Thursday, February 19, 2004 5:36 AM
> To: Arne Henningsen
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: R for economists (was: [R] Almost Ideal Demand System)
> 
> 
> On Thu, Feb 19, 2004 at 02:26:55PM +0100, Arne Henningsen wrote:
> > Hi,
> > 
> > I did not find any web page about using R in economics and 
> econometrics so 
> > far. However, this does not mean that there is none 
> (searching with google 
> > for "R" and "economics" gives many pages about economics 
> and a name like 
> > Firstname R. Lastname on it ;-)). 
> > Does anybody in the list does know such a web page?
> > If not, I will be happy if you, Ajay, could build and maintaine one.
> 
> Okay, I made a start, with
>       http://www.mayin.org/ajayshah/KB/R/more.html
> 
> Tell me what should go into it. :-)
> 
> -- 
> Ajay Shah                                                   Consultant
> ajayshah at mayin.org                      Department of Economic Affairs
> http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From hb at maths.lth.se  Thu Feb 19 18:57:42 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 19 Feb 2004 18:57:42 +0100
Subject: [R] read.socket - Strange strings. How to force sub to remove all
	occurences of a pattern?
In-Reply-To: <200402191653130153.059AA4F6@harry.molgen.mpg.de>
Message-ID: <006e01c3f711$dfc80c00$9b0040d5@maths.lth.se>

Hi, here's some classical questions to you; what's your system and
what version of R are you using? Could you give a workable code
example how you connect to the Apache server? Is the server public so
others can test your code?

About sub(): you're looking for gsub().

Cheers

Henrik Bengtsson

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of wolski
> Sent: den 19 februari 2004 16:53
> To: r-help at stat.math.ethz.ch
> Subject: [R] read.socket - Strange strings. How to force sub 
> to remove all occurences of a pattern?
> 
> 
> 
> 
> I am opening a connection to an apache server sending a get 
> and then I am reading from the socket. All works finde except 
> that I am getting some strange strings disrupting the html e.g.
> 
> <FON\r\nffb\r\nT COLOR ...
> 
> \r\na48\r\n
>   \r\nffb\r\n 
> 
> They are not frequent ( a few of them) but of course make live hard.

> I cant observe them with lynx --source they dont occure. 
> 
> I am trying a workaround with sub. But it removes only the 
> first occurence. How I can force sub to remove all occurences 
> of a pattern and not only the first?
> 
> Eryk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From wolski at molgen.mpg.de  Thu Feb 19 19:15:32 2004
From: wolski at molgen.mpg.de (wolski)
Date: Thu, 19 Feb 2004 19:15:32 +0100
Subject: [R] read.socket - Strange strings. How to force sub to
	remove all occurences of a pattern?
In-Reply-To: <Pine.LNX.4.44.0402191011400.27015-100000@echidna.fhcrc.org>
References: <Pine.LNX.4.44.0402191011400.27015-100000@echidna.fhcrc.org>
Message-ID: <200402191915320306.061CF4BA@harry.molgen.mpg.de>

Hallo Douglas, Henrik!

Thanks a lot for the help with sub and gsub.

Eryk.



*********** REPLY SEPARATOR  ***********

On 2/19/2004 at 10:12 AM Douglas Grove wrote:

>Did you look at the help page for sub?? 
>
>Read "Details:"
>
>
>On Thu, 19 Feb 2004, wolski wrote:
>
>> 
>> 
>> I am opening a connection to an apache server sending a get and then I
>am reading from the socket.
>> All works finde except that I am getting some strange strings disrupting
>the html
>> e.g.
>> 
>> <FON\r\nffb\r\nT COLOR ...
>> 
>> \r\na48\r\n
>>   \r\nffb\r\n 
>> 
>> They are not frequent ( a few of them) but of course make live hard. 
>> I cant observe them with lynx --source they dont occure. 
>> 
>> I am trying a workaround with sub. But it removes only the first
>occurence.
>> How I can force sub to remove all occurences of a pattern and not only
>the first?
>> 
>> Eryk
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>>



From bates at stat.wisc.edu  Thu Feb 19 19:50:54 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 19 Feb 2004 12:50:54 -0600
Subject: [R] building the development version
In-Reply-To: <x24qtnhtqt.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0402181838030.1651-100000@gannet.stats>
	<x2znbgqkym.fsf@biostat.ku.dk>
	<16435.51269.373330.463741@fry.research.att.com>
	<x24qtnhtqt.fsf@biostat.ku.dk>
Message-ID: <6rk72idhtd.fsf@bates4.stat.wisc.edu>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> Deborah Swayne <dfs at research.att.com> writes:
> 
> > Peter Dalgaard writes:
> >  > 
> >  > OK, that I can confirm. They do turn up on a checkout without the -P
> >  > option, but disappear after "cvs up -Pd". Tony, Debbie, did you
> >  > perhaps configure before attempting to prune the empty dirs? Could you
> >  > try 
> >  > 
> >  > cvs -d ...blabla... co -P R
> > 
> > I've use rsync; I don't know if that makes any difference:
> >    rsync -rC rsync.r-project.org::r-devel R
> 
> Hmm. It might mean that the rsync tree is built without the -P. If so,
> we should probably fix it.

I think it is rather that Deborah's rsync call did not include a
--delete option.  The crontab entries that update the rsync trees all
use -Pd (which I manage to remember because of your login).

11  *  * * *    (cd /spare1/R-src/r-patched; cvs -Q up -Pd -r R-1-8-patches; cd ../r-devel; cvs -Q up -Pd)

22 02 * * *     (cd /spare1/ggobi-src/RSggobi; cvs -Q up -Pd; cd ../ggobi; cvs -Q up -Pd)

22 05 * * *     (cd /spare1/R-project-web; cvs -Q up -Pd)

19 01 * * *     (cd /spare1/Bioconductor-devel/madman; cvs -Q up -Pd)



From hdoran at nasdc.org  Thu Feb 19 20:00:56 2004
From: hdoran at nasdc.org (Harold Doran)
Date: Thu, 19 Feb 2004 14:00:56 -0500
Subject: [R] Area between CDFs
Message-ID: <66578BFC0BA55348B5907A0F798EE9307A2CD1@ernesto.NASDC.ORG>

Thanks. I have been able to create the following simple function to examine the vertical gap between two CDFs at a value along the x-axis that I specify. For example,  

I create the ECDFs:
>male.ecdf<-ecdf(egmale$math)
>female.ecdf<-ecdf(egfemale$math)

I then define the following function:
>dif.cdf<-function(x){return(abs(female.ecdf(x)-male.ecdf(x)))}

Now, I can use the function to measure the gap at values along the x-axis (i.e., gap = F(x)-G(x). Also, the CDFs do not cross at any point):

>dif.cdf(0)

which returns a value that is the size of the gap at a specific score between males and females. 

What I would like to be able to do is measure the vertical gap at each point along the x-axis and then plot the gap. This would illustrate for how large differences in student achievement are at different score values into a nice visual display. 

The brute force way seems to use the function above for each score value. However, this is, of course, inefficient. Any ideas on how I might be able to create a function that would be more efficient?

Many thanks,

Harold
 
------
Harold C. Doran
Director of Research and Evaluation
New American Schools
675 N. Washington Street, Suite 220
Alexandria, Virginia 22314
703.647.1628
 
 
 


-----Original Message-----
From: Thomas Lumley [mailto:tlumley at u.washington.edu]
Sent: Thursday, February 19, 2004 10:49 AM
To: Samuelson, Frank*
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] Area between CDFs


On Wed, 18 Feb 2004, Samuelson, Frank* wrote:
>
> You may not want to integrate cdfs.  They're already probabilities.  :)
> Nice analytic statistics exist for just the maximum distance between
> the cdfs, for example.
>

And for the area between cdfs, which is perhaps better known as the
difference in means.

	-thomas

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From tlumley at u.washington.edu  Thu Feb 19 20:06:19 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 19 Feb 2004 11:06:19 -0800 (PST)
Subject: [R] reshape direction=wide
In-Reply-To: <E37EEC6DE3A0C5439B7E7B07406C24AE124942@msgmarsta01.bio.dfo.ca>
References: <E37EEC6DE3A0C5439B7E7B07406C24AE124942@msgmarsta01.bio.dfo.ca>
Message-ID: <Pine.A41.4.58.0402191104590.44886@homer19.u.washington.edu>

On Thu, 19 Feb 2004, Hanke, Alex wrote:

>
> v.names=c("var1","var2") creates a separate column for each combination of
> variables in v.names and level of variable identified by timevar.
>

yes, but that's not what he actually wants.

He needs to create a new id variable that combines ID and BID first

df$newid<-paste(df$ID,df$BID)


	-thomas

>
>
> I am reshaping a data.frame bids --> reshaped as shown below.
>
> I thought this should be possible with a single invocation of
> reshape, but the only way I came up with is reshaping subsets for each
> keyword and then joining them together. Does anyone have an idea how to
> solve this in a more elegant way? Efficiency is a concern as the datasets
> are very large.
>
> Is there a way to specify multiple v.names?
>
>
>
> Alex Hanke
> Department of Fisheries and Oceans
> St. Andrews Biological Station
> 531 Brandy Cove Road
> St. Andrews, NB
> Canada
> E5B 2L9
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From spencer.graves at pdf.com  Thu Feb 19 20:21:39 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 19 Feb 2004 11:21:39 -0800
Subject: [R] Obtaining SE from the hessian matrix
In-Reply-To: <Pine.A41.4.58.0402190920130.44886@homer19.u.washington.edu>
References: <20040219133803.GA12760@nf034.jinr.ru>
	<Pine.A41.4.58.0402190920130.44886@homer19.u.washington.edu>
Message-ID: <40350CC3.1030308@pdf.com>

      Minor correction:  Most likely, Prof. Lumley's statement is 
correct.  However, as I'm sure he knows, it depends on what you are 
maximizing or minimizing:  If you are maximizing the log(likelihood), 
then the NEGATIVE of the hessian is the "observed information".  This 
latter should be positive semi-definite, and if nonsingular, its inverse 
will be the covariance matrix of the standard normal approximation.  
Alternatively, if you MINIMIZE a "deviance" = (-2)*log(likelihood), then 
the HALF of the hessian is the observed information.  In the unlikely 
event that you are maximizing the likelihood itself, you need to divide 
the negative of the hessian by the likelihood to get the observed 
information. 

      hope this helps.  spencer graves

Thomas Lumley wrote:

>On Thu, 19 Feb 2004, Timur Elzhov wrote:
>  
>
>>So, what is the _right_ way for obtatining SE? Why two those formulas above
>>differ?
>>
>>    
>>
>
>If you are maximising a likelihood then the covariance matrix of the
>estimates is (asymptotically) the inverse of the negative of the Hessian.
>
>The standard errors are the square roots of the diagonal elements of the
>covariance.
>
>So if you have the Hessian you need to invert it, if you have the
>covariance matrix, you don't.
>
>	-thomas
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From pamartin at broadpark.no  Thu Feb 19 20:52:50 2004
From: pamartin at broadpark.no (=?iso-8859-1?Q?P=E5l_Anders_Martinussen?=)
Date: Thu, 19 Feb 2004 20:52:50 +0100
Subject: [R] R won't start
Message-ID: <000801c3f721$f4cf3eb0$0500000a@pilgrim>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040219/5754ee51/attachment.pl

From ftjhs2 at uaf.edu  Thu Feb 19 21:35:34 2004
From: ftjhs2 at uaf.edu (Josh Schmidt)
Date: Thu, 19 Feb 2004 11:35:34 -0900
Subject: [R] solving equations with several variables
Message-ID: <40354A60@webmail.uaf.edu>

I am relatively new to R, but I would like to use it find the values of b1 and 
b2 that maximize the following equation:

(sum(cos(x3+2.33474-2(atan(b1*x1+b2*x2)))))

Any help would be greatly appreciated.



From p.dalgaard at biostat.ku.dk  Thu Feb 19 21:41:32 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Feb 2004 21:41:32 +0100
Subject: [R] ANOVA procedure on the sufficient statistics
In-Reply-To: <hvo930das2krnemp61j1gdgn7cgs89c3g6@4ax.com>
References: <4034BDDD.3040903@yorku.ca>
	<hvo930das2krnemp61j1gdgn7cgs89c3g6@4ax.com>
Message-ID: <x2vfm2hkeb.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch at pair.com> writes:

> On Thu, 19 Feb 2004 08:45:01 -0500, Michael Friendly
> <friendly at yorku.ca> wrote :

> >That will generate only approximately the same means and MSE, however.
> >
> >Larsen's procedure generates a weighted data set that gives the same 
> >ANOVA table
> >as the raw data, but requires that the weight= argument be used in aov().
> >(weights are not supported in all related functions)
> 
> Are you sure about that?  I think the call to "scale()" makes them
> come out identical.
> 
> In fact, the call to rnorm() is unnecessary; it would work just as
> well with 
> 
> y <- cell.mean + cell.sd * scale(1:cell.count)
> 
> (unless I'm missing something...)

I don't think so, but residual plots etc. look better with the rnorm()
variant...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From k.wang at auckland.ac.nz  Thu Feb 19 21:53:36 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 20 Feb 2004 09:53:36 +1300
Subject: [R] R won't start
In-Reply-To: <000801c3f721$f4cf3eb0$0500000a@pilgrim>
Message-ID: <000101c3f72a$71e5ab70$6633d882@stat.auckland.ac.nz>

Hi,

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of P?l 
> Anders Martinussen
> Sent: Friday, February 20, 2004 8:53 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] R won't start
> 
> 
> Hi, 
> 
> I have a problem with R; it won't start! I've installed it 
> fine, no problems, but when I try to run it the mouse cursor 
> changes to an hourglass for 1 second and back to normal, and 
> that's it, it doesn't start up. 
> No error messages or nothing.
> 
> I run Windows XP Pro. by the way.
> 

What do you mean it won't start?  Can you be more specific?  Which icon
did you click?  Is it Rgui or Rterm (you should double click on Rgui)

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
Statistics Workshops Co-ordinator
Student Learning Centre
University of Auckland
New Zealand



From p.dalgaard at biostat.ku.dk  Thu Feb 19 22:01:34 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Feb 2004 22:01:34 +0100
Subject: [R] efficient matrix approx
In-Reply-To: <4034F277.20509@rcs.urz.tu-dresden.de>
References: <4034F277.20509@rcs.urz.tu-dresden.de>
Message-ID: <x2r7wqhjgx.fsf@biostat.ku.dk>

Thomas Petzoldt <petzoldt at rcs.urz.tu-dresden.de> writes:

> Hello,
> 
> I am looking for a highly efficient matrix version of linear
> interpolation (like approx). As an example I have data like follows:
> 
> x<-data.frame(time=1:20, x=(1:20)/10, y=runif(20))
> t <- seq(1.5, 15.5 ,by=0.5)
> 
> # and I found the following solution:
> 
> nam <- names(x)
> app <- lapply(x[2:3],approx,x=x$time, xout=t)
> r <- c(1, 2*(1:(ncol(x)-1)))
> x.new <- as.data.frame(unlist(app[1:2], recursive=F)[r])
> names(x.new) <- nam
> 
> 
> As this routine should be called several times during an optimization
> procedure I wonder if there is a more direct one which I have overlooked?

I wouldn't know about efficiency, but the last bit of code is
equivalent to

app <- lapply(x[-1], approx, x=x$time, xout=t)
data.frame(time=t,lapply(app,"[[","y"))

which should at least be somewhat easier to read...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Thu Feb 19 22:04:39 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 19 Feb 2004 13:04:39 -0800
Subject: [R] solving equations with several variables
In-Reply-To: <40354A60@webmail.uaf.edu>
References: <40354A60@webmail.uaf.edu>
Message-ID: <403524E7.3020404@pdf.com>

"optim"? 

Josh Schmidt wrote:

>I am relatively new to R, but I would like to use it find the values of b1 and 
>b2 that maximize the following equation:
>
>(sum(cos(x3+2.33474-2(atan(b1*x1+b2*x2)))))
>
>Any help would be greatly appreciated.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ftjhs2 at uaf.edu  Thu Feb 19 22:32:18 2004
From: ftjhs2 at uaf.edu (Josh Schmidt)
Date: Thu, 19 Feb 2004 12:32:18 -0900
Subject: [R] solving equations with several variables
Message-ID: <40356A63@webmail.uaf.edu>

>===== Original Message From Spencer Graves <spencer.graves at pdf.com> =====
>Please "reply to all".  Others on r-help may have more time than I do.
>spencer graves
>
>Josh Schmidt wrote:
>
>>I have tried optim, but I keep getting an error message.  I am quite new to
>>this, so perhaps I am inputting something incorrectly?
>>
>> f<-function
>>(max,b1,precip,b2){(sum(cos(theta+2.33474-2(atan(b1*max+b2*precip)))))}
>>
>>I used read.table to store the values for max, precip, and theta in those
>>variables.
>>
>>
>>
>>>optim(10, f, gr = NULL,
>>>
>>>
>>+ method = c(),
>>+ lower = -Inf, upper = Inf,
>>+ control = list(), hessian = FALSE)
>>
>>Error in sum(cos(theta + 2.33474 - 2(atan(b1 * max + b2 * precip)))) :
>>        attempt to apply non-function
>>In addition: Warning message:
>>one-diml optimization by Nelder-Mead is unreliable: use optimize in: 
optim(10,
>>f, gr = NULL, method = c(), lower = -Inf, upper = Inf,
>>
>>Josh Schmidt
>>Department of Biology and Wildlife
>>University of Alaska Fairbanks
>>474-7006 (office)
>>
>>
>>

Josh Schmidt
Department of Biology and Wildlife
University of Alaska Fairbanks
474-7006 (office)



From ligges at statistik.uni-dortmund.de  Thu Feb 19 22:36:43 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 19 Feb 2004 22:36:43 +0100
Subject: [R] solving equations with several variables
References: <40354A60@webmail.uaf.edu>
Message-ID: <40352C6B.E2650A@statistik.uni-dortmund.de>



Josh Schmidt wrote:
> 
> I am relatively new to R, but I would like to use it find the values of b1 and
> b2 that maximize the following equation:
> 
> (sum(cos(x3+2.33474-2(atan(b1*x1+b2*x2)))))
> 
> Any help would be greatly appreciated.



Given b1 and b2 are scalars (we are minimizing f, hence maximizing -f):

 f <- function(b, x) -sum(cos(x3 + 2.33474 - 2*(atan(b[1]*x1 +
b[2]*x2))))
 optim(c(0, 0), f, x1=x1, x2=x2, x3=x3)


Be careful: Do you know the solution is (a) unique and (b) without many
local extrema? 
The function cos() is extremly dangerous for optimization!!! If you
REALLY need it *and* you know optimization makes sense, you might want
to give method "SANN" a try ...

Uwe Ligges



From dmurdoch at pair.com  Thu Feb 19 22:39:51 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 19 Feb 2004 16:39:51 -0500
Subject: [R] R won't start
In-Reply-To: <000801c3f721$f4cf3eb0$0500000a@pilgrim>
References: <000801c3f721$f4cf3eb0$0500000a@pilgrim>
Message-ID: <97ba305fonh15tfvhaol2po2f8dbifo7el@4ax.com>

On Thu, 19 Feb 2004 20:52:50 +0100, P?l Anders Martinussen
<pamartin at broadpark.no> wrote :

>Hi, 
>
>I have a problem with R; it won't start! I've installed it fine, no problems, but when I try to run it the mouse cursor changes to an hourglass for 1 second and back to normal, and that's it, it doesn't start up. 
>No error messages or nothing.
>
>I run Windows XP Pro. by the way.

Try it from a command window, and you might see some error messages.
Let us know if there's any difference between running Rgui and running
Rterm.  And let us know the version number you're running.

Duncan Murdoch



From ftjhs2 at uaf.edu  Thu Feb 19 22:51:29 2004
From: ftjhs2 at uaf.edu (Josh Schmidt)
Date: Thu, 19 Feb 2004 12:51:29 -0900
Subject: [R] solving equations with several variables
Message-ID: <4035757E@webmail.uaf.edu>

I tried:
> f<-function(b,x)-sum(cos(x1+2.33474-2*(atan(b[1]*x2+b[2]*x3))))
> optim(c(0, 0), f, x1=x1, x2=x2, x3=x3)

and got this error.

Error in fn(par, ...) : unused argument(s) (x1 ...)

I am trying to solve for the circular-linear regression equation in Fisher 
(1993).


>===== Original Message From Uwe Ligges <ligges at statistik.uni-dortmund.de> 
=====
>Josh Schmidt wrote:
>>
>> I am relatively new to R, but I would like to use it find the values of b1 
and
>> b2 that maximize the following equation:
>>
>> (sum(cos(x3+2.33474-2(atan(b1*x1+b2*x2)))))
>>
>> Any help would be greatly appreciated.
>
>
>
>Given b1 and b2 are scalars (we are minimizing f, hence maximizing -f):
>
> f <- function(b, x) -sum(cos(x3 + 2.33474 - 2*(atan(b[1]*x1 +
>b[2]*x2))))
> optim(c(0, 0), f, x1=x1, x2=x2, x3=x3)
>
>
>Be careful: Do you know the solution is (a) unique and (b) without many
>local extrema?
>The function cos() is extremly dangerous for optimization!!! If you
>REALLY need it *and* you know optimization makes sense, you might want
>to give method "SANN" a try ...
>
>Uwe Ligges

Josh Schmidt
Department of Biology and Wildlife
University of Alaska Fairbanks
474-7006 (office)



From bill.shipley at usherbrooke.ca  Thu Feb 19 22:50:52 2004
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Thu, 19 Feb 2004 16:50:52 -0500
Subject: [R] controlling nls errors
Message-ID: <004201c3f732$720bd770$801ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040219/c1d9d14e/attachment.pl

From iwhite at staffmail.ed.ac.uk  Thu Feb 19 22:57:36 2004
From: iwhite at staffmail.ed.ac.uk (iwhite@staffmail.ed.ac.uk)
Date: Thu, 19 Feb 2004 21:57:36 +0000 (GMT)
Subject: [R] lme problem
Message-ID: <Pine.GSO.4.58.0402192149180.14823@holyrood.ed.ac.uk>

Exactly what rule has been broken when lme (package nlme) produces the
error message "Incompatible formulas for groups in random and
correlation"? Here is what I am trying to do:

lme(Y ~ trait-1, random = ~trait-1|sire,
    corr = corSymm(form = ~trait|cow))

Trait, sire and cow are factors (cow nested within sires). I want to
estimate a (genetic) covariance matrix at the sire level, plus a
residual covariance matrix, both matrices t x t, where t is the number of
levels in trait.

======================================
I.White
ICAPB, University of Edinburgh
Ashworth Laboratories, West Mains Road
Edinburgh EH9 3JT
Fax: 0131 650 6564  Tel: 0131 650 5490
E-mail: iwhite at staffmail.ed.ac.uk



From bates at stat.wisc.edu  Thu Feb 19 23:24:06 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 19 Feb 2004 16:24:06 -0600
Subject: [R] controlling nls errors
In-Reply-To: <004201c3f732$720bd770$801ad284@BIO041>
References: <004201c3f732$720bd770$801ad284@BIO041>
Message-ID: <6rk72ibtdl.fsf@bates4.stat.wisc.edu>

"Bill Shipley" <bill.shipley at usherbrooke.ca> writes:

> Hello.  I am using the nonlinear least squares function (nls).  The
> function that I am trying to fit seems to be very sensitive to the
> starting values and, if these are not chosen properly, the nls function
> stops and gives an error message:
> 
>  
> 
> Error in numericDeriv(form[[3]], names(ind), env) : 
> 
>         Missing value or an Infinity produced when evaluating the model
> 
> In addition: Warning message: 
> 
> NaNs produced in: sqrt((quantum.yeild * I + Amax)^2 - 4 * theta *
> quantum.yeild *  
> 
>  
> 
> I want to embed the nls function within a loop so that if it gives an
> error message I can automatically adjust the starting value and retry.
> To do this I have to be able to test if the function has converged
> within the loop.  I need something like an if.error(fit) function that
> will return true if there has been an error.  Does such a thing exist?

Recently this issue was discussed on this list - specifically related
to using try() to wrap the call the nls.  The nlsList function in
package nlme does exactly this.

BTW, if I were Google I would ask something like "did you mean to
search for Quantum.yield?"



From abunn at montana.edu  Thu Feb 19 23:22:07 2004
From: abunn at montana.edu (Andy Bunn)
Date: Thu, 19 Feb 2004 15:22:07 -0700
Subject: [R] importing ascii grids (for gstat)
In-Reply-To: <006101c3f732$d4d992c0$72180281@jawks2>
Message-ID: <000501c3f736$e11facf0$78f05a99@msu.montana.edu>

No problem. I'm glad it worked. It would be pretty easy to package as a
function for gstat.
-Andy

> -----Original Message-----
> From: femke [mailto:femke at geog.umd.edu] 
> Sent: Thursday, February 19, 2004 2:54 PM
> To: Andy Bunn
> Subject: Re: [R] importing ascii grids (for gstat)
> 
> 
> 
> Thanks very much for your help on this.  Your directions 
> worked beautifully. Now if only somone would put that in a 
> standard function for a package like gstat.
> 
> If you don't mind, I'll post it to the gstat list 
> (referencing you as the source).
> 
> Cheeers,
> 
> femke
> 
> ----- Original Message ----- 
> From: "Andy Bunn" <abunn at montana.edu>
> To: "'femke'" <femke at geog.umd.edu>; <r-help at stat.math.ethz.ch>
> Sent: Tuesday, February 17, 2004 12:00 PM
> Subject: RE: [R] importing ascii grids (for gstat)
> 
> 
> > If you have exported the grid from Arc using the asciigrid command 
> > then you can read it in with scan or read.table. You can tell R to 
> > skip the six lines of header info and to convert -9999 to NA e.g.,
> >
> > $ snep.tmin <- read.table(file = "tmin.asc", sep = " ", 
> na.strings = 
> > "-9999", skip = 6)
> >
> > Check the number of rows and columns to make sure it 
> matches your data 
> > (in Windows, Arc puts a space before the line return at the 
> end of a 
> > row making the resulting R object have one too many columns.)
> >
> > If that happens, then remove it:
> >
> > $ snep.tmin <- snep.tmin[,-ncol(snep.tmin)]
> >
> > (If there is a work around for the read.table command that somebody 
> > else uses then I'd love to hear it.)
> >
> > For gstat, it looks like it would be helpful to put the grid into a 
> > vector and attach the coordinate information in a data 
> frame? If so, 
> > from the header information take the lower left corner and 
> make your 
> > coordinate columns and join it to the grid data. e.g.,
> >
> > $ xLLcorner <- -1855500
> > $ yLLcorner <-  -944500
> > $ cellsize <- 1000
> > $
> > $ xURcorner <- xLLcorner + (cellsize * (ncol(snep.tmin) - 1)) $ 
> > xLRcorner <- xURcorner $ xULcorner <- xLLcorner
> > $
> > $ yULcorner <- yLLcorner + (cellsize * (nrow(snep.tmin) - 1))
> > $ yURcorner <- yULcorner
> > $ yLRcorner <- yLLcorner
> > $
> > $ coords <- expand.grid(y = seq(yULcorner, yLRcorner, by = -1000),
> > +                       x = seq(xULcorner, xLRcorner, by = 1000))
> > $
> > $ tmin.frame <- data.frame(coords, tmin = as.vector(c(snep.tmin, 
> > recursive = T))) $ $
> >
> > Watch your signs depends on the coordinate system. From 
> there you can 
> > krige or whatever easily.
> >
> > HTH, Andy
> >
> >
> >
> > $ version
> >          _
> > platform i386-pc-mingw32
> > arch     i386
> > os       mingw32
> > system   i386, mingw32
> > status
> > major    1
> > minor    8.1
> > year     2003
> > month    11
> > day      21
> > language R
> >
> 
>



From greenberg at ucdavis.edu  Fri Feb 20 00:14:36 2004
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Thu, 19 Feb 2004 15:14:36 -0800
Subject: [R] 1024GB max memory on R for Windows XP?
Message-ID: <BC5A835C.19BA9%greenberg@ucdavis.edu>

I have 2GB installed on my windows XP box running R 1.9.0, and after
performing a prune.tree(intree,newdata), I get an out of memory error within
R, but it says the maximum allowed is 1024gb (1/2 of what I have!)  Can R
not use more than 1GB on an XP box?  I noticed I had ~600mb left over after
R conked out, so clearly I had more memory...  What about virtual memory?

--j

-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From itayf at fhcrc.org  Fri Feb 20 00:45:36 2004
From: itayf at fhcrc.org (Itay Furman)
Date: Thu, 19 Feb 2004 15:45:36 -0800 (PST)
Subject: [R] piece wise application of functions
Message-ID: <Pine.LNX.4.44.0402191540260.32006-100000@cezanne.fhcrc.org>


Dear all,

After struggling for some time with *apply() and eva() without
success, I decided to ask for help.

I have 3 lists labeled with, each contains 3 different
interpolation functions with identical names:

> names(missgp0)
[1] "spl.1mb" "spl.2mb" "spl.5mb"
> 
> names(missgp1)
[1] "spl.1mb" "spl.2mb" "spl.5mb"
> 
> names(missgp2)
[1] "spl.1mb" "spl.2mb" "spl.5mb"
> 

(
In case it matters the functions accept and return one argument:
block.size <- spl.1mb(ic)
)

Then, I have 2 data frames with identical structure:

> snps.missgp
  intvl.mb    ic
1    1e+06 0.597
2    2e+06 0.504
3    5e+06 0.327
4    1e+07 0.204
> 

> strs.missgp
  intvl.mb      ic
1    1e+06 0.67200
2    2e+06 0.62325
3    5e+06 0.51000
4    1e+07 0.38775
> 

I would like to apply the functions on these data frames
piece-wise and create a data frame per function _list_.

So I am looking for a final output like this:

> case0
    gap	 snps	strs
1 1e+06  ..	..
2 2e+06  ..	..
3 5e+06  ..	..

Here, case0$snps[1] is, for example, the result of applying the
function in  missgp0[1] on the entry snps.missgp$ic[1];
and, case0$strs[1] is the result of applying the same function
on strs.missgp$ic[1].

Then, I want to repeat the whole thing with missgp1,2  instead
of missgp0, generating case1,2 data frames.

How should I do it?


	Thanks in advance,
	Itay Furman

--------------------------------------------------------------------
itayf at fhcrc.org			Fred Hutchinson Cancer Research Center



From adrian_humbert at yahoo.com  Fri Feb 20 01:49:00 2004
From: adrian_humbert at yahoo.com (Adi Humbert)
Date: Thu, 19 Feb 2004 16:49:00 -0800 (PST)
Subject: [R] Does pdf() not work on Trellis graphics?
Message-ID: <20040220004900.32636.qmail@web12101.mail.yahoo.com>

Hello, 

I have the following example. 

testpdf <- function(x,y){
  pdf()
  #plot(x,y)
  xyplot(x~y)
  dev.off()
}


source("testpdf.R")
x=1:1000
testpdf(x,x)

with "xyplot", the output is a file that can not be
read because it has no pages.  With "plot" it works
fine.  If I do it manually (from the GUI menu), it
works even for "xyplot".  How can I save it
automatically, without the GUI? 

I use R 1.8.0 on WinXP. 

Thank you, 
Adrian Dragulescu



From rpeng at jhsph.edu  Fri Feb 20 01:50:26 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 19 Feb 2004 19:50:26 -0500
Subject: [R] 1024GB max memory on R for Windows XP?
In-Reply-To: <BC5A835C.19BA9%greenberg@ucdavis.edu>
References: <BC5A835C.19BA9%greenberg@ucdavis.edu>
Message-ID: <403559D2.7070500@jhsph.edu>

See ?Memory.  Setting

memory.limit(2048)

in R may help

-roger

Jonathan Greenberg wrote:
> I have 2GB installed on my windows XP box running R 1.9.0, and after
> performing a prune.tree(intree,newdata), I get an out of memory error within
> R, but it says the maximum allowed is 1024gb (1/2 of what I have!)  Can R
> not use more than 1GB on an XP box?  I noticed I had ~600mb left over after
> R conked out, so clearly I had more memory...  What about virtual memory?
> 
> --j
>



From dmurdoch at pair.com  Fri Feb 20 01:58:51 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 19 Feb 2004 19:58:51 -0500
Subject: [R] 1024GB max memory on R for Windows XP?
In-Reply-To: <BC5A835C.19BA9%greenberg@ucdavis.edu>
References: <BC5A835C.19BA9%greenberg@ucdavis.edu>
Message-ID: <gtma30d9d97b604vgo6rqemo2l0mj96gq4@4ax.com>

On Thu, 19 Feb 2004 15:14:36 -0800, Jonathan Greenberg wrote:

>I have 2GB installed on my windows XP box running R 1.9.0, and after
>performing a prune.tree(intree,newdata), I get an out of memory error within
>R, but it says the maximum allowed is 1024gb (1/2 of what I have!)  Can R
>not use more than 1GB on an XP box?  I noticed I had ~600mb left over after
>R conked out, so clearly I had more memory...  What about virtual memory?

See the FAQ.  You can increase the limit, but not past 2GB (no matter
how much RAM or virtual memory you've got), and maybe not all the way
there.

Duncan Murdoch



From bhiggins at cs.washington.edu  Fri Feb 20 02:05:23 2004
From: bhiggins at cs.washington.edu (Benjamin T. Higgins)
Date: Thu, 19 Feb 2004 17:05:23 -0800
Subject: [R] Using R remotely on a Mac OS X machine
Message-ID: <005201c3f74d$9e23e1c0$6300a8c0@hilgard>

Hello,

I've recently installed R (RAqua I guess?) on a Mac OS X machine and it
works fine locally.  However, I want to run some things from the command
line remotely.  I can't seem to get this to work and have tried several
different things (i.e., --vanilla, --gui none, doing stuff in batch mode).
This is the error I always get:

kCGErrorIllegalArgument : initCGDisplayState: cannot map display interlocks.
kCGErrorIllegalArgument : CGSNewConnection cannot get connection port
kCGErrorInvalidConnection : CGSExtractEventRecordsFromMessage: Invalid
connection
kCGErrorIllegalArgument : CGSNewConnection cannot get connection port
INIT_Processeses(), could not establish the default connection to the
WindowServer.Abort trap

Anyone know what to do?

Has anyone gotten R to work remotely on a Mac OS X machine?

Thanks,
Ben



From jasont at indigoindustrial.co.nz  Fri Feb 20 02:24:15 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 20 Feb 2004 14:24:15 +1300 (NZDT)
Subject: [R] Does pdf() not work on Trellis graphics?
In-Reply-To: <20040220004900.32636.qmail@web12101.mail.yahoo.com>
References: <20040220004900.32636.qmail@web12101.mail.yahoo.com>
Message-ID: <28948.203.9.176.60.1077240255.squirrel@new-webmail.maxnet.co.nz>

See the FAQ, 7.24.

you need to

print(xyplot(x~y))


> Hello,
>
> I have the following example.
>
> testpdf <- function(x,y){
>   pdf()
>   #plot(x,y)
>   xyplot(x~y)
>   dev.off()
> }
>
>
> source("testpdf.R")
> x=1:1000
> testpdf(x,x)
>
> with "xyplot", the output is a file that can not be
> read because it has no pages.  With "plot" it works
> fine.  If I do it manually (from the GUI menu), it
> works even for "xyplot".  How can I save it
> automatically, without the GUI?
>
> I use R 1.8.0 on WinXP.
>
> Thank you,
> Adrian Dragulescu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From jeff.hamann at forestinformatics.com  Fri Feb 20 02:34:26 2004
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Thu, 19 Feb 2004 17:34:26 -0800
Subject: [R] Sweave not found from MikTeX?
Message-ID: <000d01c3f751$ad392180$0a00a8c0@rodan>

I've been working on a LaTeX document that contains Sweave code and cannot
get MikTeX to find the Sweave.sty file. I've added the c:\rw1081\share\texmf
path in the MikTeX roots (I've ven added the path in the environment
variables ) but to no avail. Is there a trick to getting Sweave installed
correctly when using MikTeX on Windows XP? Do I need to move/copy the
Sweave.sty file to the c:/textmf/?/?/? directory?

Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
(office) 541-754-1428
(cell) 541-740-5988
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From greenberg at ucdavis.edu  Fri Feb 20 02:52:44 2004
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Thu, 19 Feb 2004 17:52:44 -0800
Subject: [R] 1024GB max memory on R for Windows XP?
In-Reply-To: <gtma30d9d97b604vgo6rqemo2l0mj96gq4@4ax.com>
Message-ID: <BC5AA86C.19BCF%greenberg@ucdavis.edu>

Hmm, I went over to a unix box that should have had plenty of RAM and swap
space and running the same prune.tree process ended up causing R to be
"Killed" (e.g. It quit out).  Thoughts?

--j

On 2/19/04 4:58 PM, "Duncan Murdoch" <dmurdoch at pair.com> wrote:

> On Thu, 19 Feb 2004 15:14:36 -0800, Jonathan Greenberg wrote:
> 
>> I have 2GB installed on my windows XP box running R 1.9.0, and after
>> performing a prune.tree(intree,newdata), I get an out of memory error within
>> R, but it says the maximum allowed is 1024gb (1/2 of what I have!)  Can R
>> not use more than 1GB on an XP box?  I noticed I had ~600mb left over after
>> R conked out, so clearly I had more memory...  What about virtual memory?
> 
> See the FAQ.  You can increase the limit, but not past 2GB (no matter
> how much RAM or virtual memory you've got), and maybe not all the way
> there.
> 
> Duncan Murdoch


-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From rpeng at jhsph.edu  Fri Feb 20 03:31:06 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 19 Feb 2004 21:31:06 -0500
Subject: [R] 1024GB max memory on R for Windows XP?
In-Reply-To: <BC5AA86C.19BCF%greenberg@ucdavis.edu>
References: <BC5AA86C.19BCF%greenberg@ucdavis.edu>
Message-ID: <4035716A.9080805@jhsph.edu>

Was this by any chance a Linux on x86?  If so, I think there's roughly a 
2.5-3GB limit for a single process imposed by the architecture.

-roger

Jonathan Greenberg wrote:
> Hmm, I went over to a unix box that should have had plenty of RAM and swap
> space and running the same prune.tree process ended up causing R to be
> "Killed" (e.g. It quit out).  Thoughts?
> 
> --j
> 
> On 2/19/04 4:58 PM, "Duncan Murdoch" <dmurdoch at pair.com> wrote:
> 
> 
>>On Thu, 19 Feb 2004 15:14:36 -0800, Jonathan Greenberg wrote:
>>
>>
>>>I have 2GB installed on my windows XP box running R 1.9.0, and after
>>>performing a prune.tree(intree,newdata), I get an out of memory error within
>>>R, but it says the maximum allowed is 1024gb (1/2 of what I have!)  Can R
>>>not use more than 1GB on an XP box?  I noticed I had ~600mb left over after
>>>R conked out, so clearly I had more memory...  What about virtual memory?
>>
>>See the FAQ.  You can increase the limit, but not past 2GB (no matter
>>how much RAM or virtual memory you've got), and maybe not all the way
>>there.
>>
>>Duncan Murdoch
> 
> 
>



From jasjeet_sekhon at harvard.edu  Fri Feb 20 04:28:44 2004
From: jasjeet_sekhon at harvard.edu (Jasjeet Singh Sekhon)
Date: Thu, 19 Feb 2004 22:28:44 -0500
Subject: [R] [R-pkgs] New Package: multinomRob
Message-ID: <16437.32492.977572.998974@musil.localdomain>


We would like to announce the availability on CRAN of a new package
multinomRob.  It does robust estimation of overdispersed multinomial
regression models. The package is also able to estimate overdispersed
grouped multinomial logistic and multivariate-t logistic models.  The
code is relatively general; for example, it allows for equality
constraints across parameters and it can handle datasets in which the
number of categories varies by observation.

DESCRIPTION:

Package: multinomRob
Version: 1.0
Date: 2004/02/18
Title: Robust Estimation of Overdispersed Multinomial Regression Models
Author: Walter R. Mebane, Jr. <wrm1 at cornell.edu>, Jasjeet Singh Sekhon <jasjeet_sekhon at harvard.edu>
Maintainer: Jasjeet Singh Sekhon <jasjeet_sekhon at harvard.edu>
Description: overdispersed multinomial regression using robust (LQD and tanh) estimation
Depends: R (>= 1.7.0), rgenoud (>= 1.22), MASS (>= 7.1-8), mvtnorm (>= 0.6-3)
License: GPL version 2 or later
URL: http://jsekhon.fas.harvard.edu/robust/


We look forward to receiving questions, comments and suggestions.

Cheers,
Jas.

======================================
Jasjeet S. Sekhon
Associate Professor
Harvard University
Center for Basic Research in the 
  Social Sciences
jsekhon at fas.harvard.edu
http://jsekhon.fas.harvard.edu/
Office: 617.496.2426 Fax: 617.496.5149

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From mlevins at stat.purdue.edu  Fri Feb 20 05:23:48 2004
From: mlevins at stat.purdue.edu (Michael Levine)
Date: Thu, 19 Feb 2004 23:23:48 -0500
Subject: [R] Confidence intervals for logistic regression
Message-ID: <007901c3f769$5678f420$be8dd280@stat.purdue.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040219/398db18d/attachment.pl

From mvinic at unipacjf.com.br  Fri Feb 20 05:43:41 2004
From: mvinic at unipacjf.com.br (Marcus Vinicius)
Date: Fri, 20 Feb 2004 02:43:41 -0200
Subject: [R] (no subject)
Message-ID: <20040220054341.28072.qmail@hm47.locaweb.com.br>



From ligges at statistik.uni-dortmund.de  Fri Feb 20 08:24:36 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 20 Feb 2004 08:24:36 +0100
Subject: [R] solving equations with several variables
In-Reply-To: <4035757E@webmail.uaf.edu>
References: <4035757E@webmail.uaf.edu>
Message-ID: <4035B634.9040607@statistik.uni-dortmund.de>

Josh Schmidt wrote:

> I tried:
> 
>>f<-function(b,x)-sum(cos(x1+2.33474-2*(atan(b[1]*x2+b[2]*x3))))
>>optim(c(0, 0), f, x1=x1, x2=x2, x3=x3)


Sorry, should have been:

  f <- function(b, x1, x2, x3){
     -sum(cos(x1+2.33474-2*(atan(b[1]*x2+b[2]*x3))))
  }
  optim(c(0, 0), f, x1=x1, x2=x2, x3=x3)


Uwe Ligges



> and got this error.
> 
> Error in fn(par, ...) : unused argument(s) (x1 ...)
> 
> I am trying to solve for the circular-linear regression equation in Fisher 
> (1993).
> 
> 
> 
>>===== Original Message From Uwe Ligges <ligges at statistik.uni-dortmund.de> 
> 
> =====
> 
>>Josh Schmidt wrote:
>>
>>>I am relatively new to R, but I would like to use it find the values of b1 
> 
> and
> 
>>>b2 that maximize the following equation:
>>>
>>>(sum(cos(x3+2.33474-2(atan(b1*x1+b2*x2)))))
>>>
>>>Any help would be greatly appreciated.
>>
>>
>>
>>Given b1 and b2 are scalars (we are minimizing f, hence maximizing -f):
>>
>>f <- function(b, x) -sum(cos(x3 + 2.33474 - 2*(atan(b[1]*x1 +
>>b[2]*x2))))
>>optim(c(0, 0), f, x1=x1, x2=x2, x3=x3)
>>
>>
>>Be careful: Do you know the solution is (a) unique and (b) without many
>>local extrema?
>>The function cos() is extremly dangerous for optimization!!! If you
>>REALLY need it *and* you know optimization makes sense, you might want
>>to give method "SANN" a try ...
>>
>>Uwe Ligges
> 
> 
> Josh Schmidt
> Department of Biology and Wildlife
> University of Alaska Fairbanks
> 474-7006 (office)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Fri Feb 20 08:50:09 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Feb 2004 07:50:09 +0000 (GMT)
Subject: [R] Confidence intervals for logistic regression
In-Reply-To: <007901c3f769$5678f420$be8dd280@stat.purdue.edu>
Message-ID: <Pine.LNX.4.44.0402200742270.23095-100000@gannet.stats>

On Thu, 19 Feb 2004, Michael Levine wrote:

> I found myself trying to figure out the type of confidence interval used
> for the coefficients of the logistic regression fit by using
> glm(family=binomial)...

AFAIK, no confidence interval is given by that call: it does not even 
calculate standard errors for the coefs (the summary method does that).
I could guess what you meant, but the answer depends on the guess ....

> I suspect it is Wald confidence interval but am not sure...Does anybody
> know? Also, if so, how can I ask for likelihood ratio and/or score-based
> confidence intervals?

You can use confint() (whose glm method is in package MASS, which must be
attached) to give you profile-likelihood confidence intervals.  There
would be no point in trying to base confidence intervals on score tests,
as you would have to re-fit the model at all possible alternative values
and so the profile likelihood would be available.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From hb at maths.lth.se  Fri Feb 20 09:53:31 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 20 Feb 2004 09:53:31 +0100
Subject: [R] Sweave not found from MikTeX?
In-Reply-To: <000d01c3f751$ad392180$0a00a8c0@rodan>
Message-ID: <002a01c3f78f$0468d8f0$e502eb82@maths.lth.se>

Hi, I think about everyone asks the same question as you. A quick and
dirty way to fix it is to copy Sweave.sty from$R_HOME/share/texmf/ to
the same directory as your Sweave/R/TeX files. 

BTW: Would it be possible to add a comment about the above in the
Sweave() help page and maybe even have an argument "copySty=FALSE"
that finds $R_HOME/share/texmf/Sweave.sty and copies it automatically?


Personally, I actually prefer to copy the file this way, because then
I can be sure that the Sweave report will be generated without problem
if I send it to someone else.

About MikTeX: You want to update you TeX-database (or whatever it's
called). Did you go into "MikTeX Options" and did "Refresh Now" under
"File name database"? It's not enough do run "Add..." the path.

Cheers

Henrik Bengtsson


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jeff D.
Hamann
> Sent: den 20 februari 2004 02:34
> To: r-help at stat.math.ethz.ch
> Subject: [R] Sweave not found from MikTeX?
> 
> 
> I've been working on a LaTeX document that contains Sweave 
> code and cannot get MikTeX to find the Sweave.sty file. I've 
> added the c:\rw1081\share\texmf path in the MikTeX roots 
> (I've ven added the path in the environment variables ) but 
> to no avail. Is there a trick to getting Sweave installed 
> correctly when using MikTeX on Windows XP? Do I need to 
> move/copy the Sweave.sty file to the c:/textmf/?/?/? directory?
> 
> Jeff.
> 
> ---
> Jeff D. Hamann
> Forest Informatics, Inc.
> PO Box 1421
> Corvallis, Oregon USA 97339-1421
> (office) 541-754-1428
> (cell) 541-740-5988
> jeff.hamann at forestinformatics.com
> www.forestinformatics.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From Timur.Elzhov at jinr.ru  Fri Feb 20 10:34:23 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri, 20 Feb 2004 12:34:23 +0300
Subject: [R] Obtaining SE from the hessian matrix
In-Reply-To: <Pine.A41.4.58.0402190920130.44886@homer19.u.washington.edu>
References: <20040219133803.GA12760@nf034.jinr.ru>
	<Pine.A41.4.58.0402190920130.44886@homer19.u.washington.edu>
Message-ID: <20040220093423.GA1613@nf034.jinr.ru>

On Thu, Feb 19, 2004 at 09:22:09AM -0800, Thomas Lumley wrote:

>>  So, what is the _right_ way for obtatining SE? Why two those formulas above
>>  differ?
> 
> If you are maximising a likelihood then the covariance matrix of the
> estimates is (asymptotically) the inverse of the negative of the Hessian.
> 
> The standard errors are the square roots of the diagonal elements of the
> covariance.
> 
> So if you have the Hessian you need to invert it, if you have the
> covariance matrix, you don't.

Yes, the covariance matrix is inverse of the Hessian, that's clear.
But my queston is, why in the first example:

    > sqrt(diag(2*out$minimum/(length(y) - 2) * solve(out$hessian)))
	      
    The 2 in the line above represents the number of parameters. A 95%
    confidence interval would be the parameter estimate +/- 1.96 SE. We
    can superimpose the least squares fit on a new plot:

- we don _not_ use simply 'sqrt(diag(solve(out$hessian)))', how in the
second example, but also include in some way "number of parameters" == 2?
What does '2*out$minimum/(length(y) - 2)' multiplier mean?

Thanks!

--
WBR,
Timur.



From schnitzlerj at gmx.de  Fri Feb 20 10:56:46 2004
From: schnitzlerj at gmx.de (Johannes Schnitzler)
Date: Fri, 20 Feb 2004 10:56:46 +0100 (MET)
Subject: [R] PNG Problem on Windows 98   
Message-ID: <18831.1077271006@www16.gmx.net>

Thank you for the reply,

i tried it with the devel version 1090 (18.02.2004) but it is still the same
problem.

Is there any other solution. As said before it works on 1 Windows 98
Computer but not on the other's.
I can't change the operating system of the computers. Which files of windows
could i check?

Thank's again.

Johannes



From Achim.Zeileis at wu-wien.ac.at  Fri Feb 20 11:18:30 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 20 Feb 2004 11:18:30 +0100
Subject: [R] Sweave not found from MikTeX?
In-Reply-To: <002a01c3f78f$0468d8f0$e502eb82@maths.lth.se>
References: <000d01c3f751$ad392180$0a00a8c0@rodan>
	<002a01c3f78f$0468d8f0$e502eb82@maths.lth.se>
Message-ID: <20040220111830.565e01fc.Achim.Zeileis@wu-wien.ac.at>

On Fri, 20 Feb 2004 09:53:31 +0100 Henrik Bengtsson wrote:

> Hi, I think about everyone asks the same question as you. A quick and
> dirty way to fix it is to copy Sweave.sty from$R_HOME/share/texmf/ to
> the same directory as your Sweave/R/TeX files. 
> 
> BTW: Would it be possible to add a comment about the above in the
> Sweave() help page and maybe even have an argument "copySty=FALSE"
> that finds $R_HOME/share/texmf/Sweave.sty and copies it automatically?
> 
> Personally, I actually prefer to copy the file this way, because then
> I can be sure that the Sweave report will be generated without problem
> if I send it to someone else.

If I want to send the resulting TeX files to someone else, e.g., a
journal, then I usually just put the necessary declarations into the
header of the .Rnw (and resulting TeX) file:

-------------

\documentclass{article}
\usepackage{foo,bar}

%% instead of \usepackage{Sweave}
\RequirePackage[T1]{fontenc}
\RequirePackage{graphicx,ae,fancyvrb}
\IfFileExists{upquote.sty}{\RequirePackage{upquote}}{}
\setkeys{Gin}{width=0.8\textwidth}
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{}
\DefineVerbatimEnvironment{Scode}{Verbatim}{fontshape=sl}
\newenvironment{Schunk}{}{}

\begin{document}
...

-------------

When calling Sweave() it looks whether you already have included some
Sweave.sty into your document and only adds a line like
  \usepackage{path/to/Sweave.sty}
if you haven't. It doesn't mind that the line itself is escaped via %%.

Best,
Z

 
> About MikTeX: You want to update you TeX-database (or whatever it's
> called). Did you go into "MikTeX Options" and did "Refresh Now" under
> "File name database"? It's not enough do run "Add..." the path.
> 
> Cheers
> 
> Henrik Bengtsson
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jeff D.
> Hamann
> > Sent: den 20 februari 2004 02:34
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Sweave not found from MikTeX?
> > 
> > 
> > I've been working on a LaTeX document that contains Sweave 
> > code and cannot get MikTeX to find the Sweave.sty file. I've 
> > added the c:\rw1081\share\texmf path in the MikTeX roots 
> > (I've ven added the path in the environment variables ) but 
> > to no avail. Is there a trick to getting Sweave installed 
> > correctly when using MikTeX on Windows XP? Do I need to 
> > move/copy the Sweave.sty file to the c:/textmf/?/?/? directory?
> > 
> > Jeff.
> > 
> > ---
> > Jeff D. Hamann
> > Forest Informatics, Inc.
> > PO Box 1421
> > Corvallis, Oregon USA 97339-1421
> > (office) 541-754-1428
> > (cell) 541-740-5988
> > jeff.hamann at forestinformatics.com
> > www.forestinformatics.com
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> > PLEASE 
> > do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From pedro.aphalo at cc.jyu.fi  Fri Feb 20 12:38:55 2004
From: pedro.aphalo at cc.jyu.fi (Pedro J. Aphalo)
Date: Fri, 20 Feb 2004 13:38:55 +0200
Subject: [R] nlme and multiple comparisons
Message-ID: <4035F1CF.6050105@cc.jyu.fi>

This is only partly a question about R, as I am not quite sure about the 
underlying statistical theory either.

I have fitted a non-linear mixed-effects model with nlme. In the fixed 
part of the model I have a factor with three levels as explanatory 
variable. I would like to use Tukey HSD or a similar test to test for 
differences between these three levels.

I have two grouping factors: 'plant' to which the treatments were 
assigned at random, and 'leaf' which are subsamples.

With summary, with the default setting for contrasts I get two of the 
possible three comparisons. One possibility that I can think of is to 
change the order of the levels in the factor, repeat the fit, use 
summary again, and finally use p.adjust. Would this be valid?

Is there a more elegant solution?

If it matters, the data are slightly unbalanced (missing observations).

Sorry that this message became so long... Thanks in advance for any 
suggestions, and I hope I haven't missed the answer when looking at the 
help pages, FAQ, MASS(3ed) and Pinheiro and Bates' book.

Pedro.

-- 
==================================================================
Pedro J. Aphalo
Department of Biological and Environmental Science
University of Jyv?skyl?
P.O. Box 35, 40351 JYV?SKYL?, Finland
Phone  +358 14 260 2339
Mobile +358 50 3721504
Fax    +358 14 260 2321
mailto:pedro.aphalo at cc.jyu.fi
http://www.jyu.fi/~aphalo/                       ,,,^..^,,,



From agustin.perez at alu.umh.es  Fri Feb 20 15:01:25 2004
From: agustin.perez at alu.umh.es (AGUSTIN PEREZ MARTIN)
Date: Fri, 20 Feb 2004 15:01:25 +0100
Subject: [R] read.table with spaces
Message-ID: <200402201501.AA14155908@alu.umh.es>

DeaR useRs:

Excuses for my english. I am trying to read a file with my dats and the format is a number, 3 spaces, other number, etc...
When I use:
a<-read.table(file="c:/datos2.dat",sep="")
R sais:
Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  : 
        line 3 did not have 34 elements

And I see my dats and in line 3 the first number is an space (missing value)
SOS help me!!!!

Thanks.

--
                         
==============oOo============= 
Visit my website in: 
http://users.servicios.retecal.es/aperez2
Maybe you can find something interesting
==============================
--



From friendly at yorku.ca  Fri Feb 20 15:17:37 2004
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 20 Feb 2004 09:17:37 -0500
Subject: [R] problem with abline for x.y
Message-ID: <40361701.6030807@yorku.ca>

I'm trying to do a sunflowerplot of Galton's data, with both regression 
lines and data ellipses,
and I must be doing something wrong, because the lines do not intersect 
at \bar{x}, \bar{y}.
The problem is likely in the line for x.y, but I don't know how to 
specify that correctly.

The data is read in grouped form( galton), and then ungrouped (galton2):

galton <- read.table("~/sasuser/data/galton.txt", header=TRUE)
# ungroup
galton2<-galton[rep(1:nrow(galton), galton$frequency), 1:2]

attach(galton)
sunflowerplot(child, parent, number=frequency, xlim=c(61,75), 
ylim=c(61,75),
    xlab="Child height", ylab="Mid Parent height")

# both attempts plot the same, wrong regression lines
y.x <- lm(parent ~ child, weights=frequency)
abline(y.x)
x.y <- lm(child ~ parent, weights=frequency)
abline(x.y, col="gray")

attach(galton2)
y.x <- lm(parent ~ child)
abline(y.x, lwd=2)
x.y <- lm(child ~ parent)
abline(x.y, col="gray", lwd=2)

library(car)
data.ellipse(child, parent, plot.points=FALSE, levels=c(0.40, 0.68), lty=2)

The resulting figure may be seen at
http://euclid.psych.yorku.ca/SCS/Gallery/Private/galton.jpg

-Michael

-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From j.mcelwee at ucl.ac.uk  Fri Feb 20 15:34:13 2004
From: j.mcelwee at ucl.ac.uk (Joshua McElwee)
Date: Fri, 20 Feb 2004 14:34:13 +0000
Subject: [R] Stupid Limma question..
Message-ID: <BC5BCB65.921%j.mcelwee@ucl.ac.uk>

  Hi all.  I've got a really dumb question for anyone.  How do I write the
output of a limma analysis (basically the topTable) to a text file?  I want
to output the topTable for the entire microarray (not really a topTable
anymore I suppose..).  Thanks for any advice!
-Josh



From rbaer at atsu.edu  Fri Feb 20 15:38:25 2004
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Fri, 20 Feb 2004 08:38:25 -0600
Subject: [R] read.table with spaces
References: <200402201501.AA14155908@alu.umh.es>
Message-ID: <005301c3f7bf$32c1ed10$2e80010a@BigBaer>

You should make your missing value indicator something other than your
separator indicator:
1.  Use a text editor to indicate all missing values as NA     or
2.  Use a text editor to replace the 3 separator spaces with, for example, a
comma or semicolon and use the argument sep="," or sep=";" which won't
trigger on ANY whitespace.

HTH,
Rob

----- Original Message ----- 
From: "AGUSTIN PEREZ MARTIN" <agustin.perez at alu.umh.es>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, February 20, 2004 8:01 AM
Subject: [R] read.table with spaces


> DeaR useRs:
>
> Excuses for my english. I am trying to read a file with my dats and the
format is a number, 3 spaces, other number, etc...
> When I use:
> a<-read.table(file="c:/datos2.dat",sep="")
> R sais:
> Error in scan(file = file, what = what, sep = sep, quote = quote, dec =
dec,  :
>         line 3 did not have 34 elements
>
> And I see my dats and in line 3 the first number is an space (missing
value)
> SOS help me!!!!
>
> Thanks.
>
> --
>
> ==============oOo=============
> Visit my website in:
> http://users.servicios.retecal.es/aperez2
> Maybe you can find something interesting
> ==============================
> --
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Fri Feb 20 16:02:46 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Feb 2004 16:02:46 +0100
Subject: [R] problem with abline for x.y
In-Reply-To: <40361701.6030807@yorku.ca>
References: <40361701.6030807@yorku.ca>
Message-ID: <x2smh5n695.fsf@biostat.ku.dk>

Michael Friendly <friendly at yorku.ca> writes:

> The data is read in grouped form( galton), and then ungrouped (galton2):
> 
> galton <- read.table("~/sasuser/data/galton.txt", header=TRUE)
> # ungroup
> galton2<-galton[rep(1:nrow(galton), galton$frequency), 1:2]
> 
> attach(galton)
> sunflowerplot(child, parent, number=frequency, xlim=c(61,75),
> ylim=c(61,75),
>     xlab="Child height", ylab="Mid Parent height")
> 
> # both attempts plot the same, wrong regression lines

Not precisely, though.

> y.x <- lm(parent ~ child, weights=frequency)
> abline(y.x)
> x.y <- lm(child ~ parent, weights=frequency)
> abline(x.y, col="gray")
> 
> attach(galton2)
> y.x <- lm(parent ~ child)
> abline(y.x, lwd=2)
> x.y <- lm(child ~ parent)
> abline(x.y, col="gray", lwd=2)
> 
> library(car)
> data.ellipse(child, parent, plot.points=FALSE, levels=c(0.40, 0.68), lty=2)

The thing that you need in the x.y case  is that

x = a + by

implies

y = 1/b x  -  a/b

so you need 

cc <- coef(x.y)
abline(-cc[1]/cc[2], 1/cc[2], ....)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jfox at mcmaster.ca  Fri Feb 20 16:12:50 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 20 Feb 2004 10:12:50 -0500
Subject: [R] problem with abline for x.y
In-Reply-To: <40361701.6030807@yorku.ca>
Message-ID: <5.1.0.14.2.20040220100840.02014328@127.0.0.1>

Dear Mike,

I believe that the following is the problem: For the regression of x on y, 
you have to move y to the left-hand-side of the equation to plot the line 
in {x, y}; so if the regression equation from the model x.y is x = a + b y, 
you need abline(-a/b, 1/b).

I hope that this helps,
  John

At 09:17 AM 2/20/2004 -0500, Michael Friendly wrote:
>I'm trying to do a sunflowerplot of Galton's data, with both regression 
>lines and data ellipses,
>and I must be doing something wrong, because the lines do not intersect at 
>\bar{x}, \bar{y}.
>The problem is likely in the line for x.y, but I don't know how to specify 
>that correctly.
>
>The data is read in grouped form( galton), and then ungrouped (galton2):
>
>galton <- read.table("~/sasuser/data/galton.txt", header=TRUE)
># ungroup
>galton2<-galton[rep(1:nrow(galton), galton$frequency), 1:2]
>
>attach(galton)
>sunflowerplot(child, parent, number=frequency, xlim=c(61,75), ylim=c(61,75),
>    xlab="Child height", ylab="Mid Parent height")
>
># both attempts plot the same, wrong regression lines
>y.x <- lm(parent ~ child, weights=frequency)
>abline(y.x)
>x.y <- lm(child ~ parent, weights=frequency)
>abline(x.y, col="gray")
>
>attach(galton2)
>y.x <- lm(parent ~ child)
>abline(y.x, lwd=2)
>x.y <- lm(child ~ parent)
>abline(x.y, col="gray", lwd=2)
>
>library(car)
>data.ellipse(child, parent, plot.points=FALSE, levels=c(0.40, 0.68), lty=2)
>
>The resulting figure may be seen at
>http://euclid.psych.yorku.ca/SCS/Gallery/Private/galton.jpg
>
>-Michael
>
>--
>Michael Friendly     Email: friendly at yorku.ca Professor, Psychology Dept.
>York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
>4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
>Toronto, ONT  M3J 1P3 CANADA
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From deepayan at stat.wisc.edu  Fri Feb 20 16:11:53 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 20 Feb 2004 09:11:53 -0600
Subject: [R] problem with abline for x.y
In-Reply-To: <40361701.6030807@yorku.ca>
References: <40361701.6030807@yorku.ca>
Message-ID: <200402200911.53233.deepayan@stat.wisc.edu>

On Friday 20 February 2004 08:17, Michael Friendly wrote:
> I'm trying to do a sunflowerplot of Galton's data, with both regression
> lines and data ellipses,
> and I must be doing something wrong, because the lines do not intersect
> at \bar{x}, \bar{y}.
> The problem is likely in the line for x.y, but I don't know how to
> specify that correctly.

[...]

> # both attempts plot the same, wrong regression lines
> y.x <- lm(parent ~ child, weights=frequency)
> abline(y.x)
> x.y <- lm(child ~ parent, weights=frequency)
> abline(x.y, col="gray")
>
> attach(galton2)
> y.x <- lm(parent ~ child)
> abline(y.x, lwd=2)
> x.y <- lm(child ~ parent)
> abline(x.y, col="gray", lwd=2)

This looks like you are getting a line with equation of the form 

x = c0 + c1 y

and then plotting the line 

y = c0 + c1 y

You should probably do 

cx.y <- coef(x.y)
cx.y <- c(-cx.y[1], 1) / cx.y[2]

abline(cx.y)

[Code untested, though]

Deepayan



From hxc05 at health.state.ny.us  Fri Feb 20 16:30:17 2004
From: hxc05 at health.state.ny.us (Haiyan Chen)
Date: Fri, 20 Feb 2004 10:30:17 -0500
Subject: [R] How to make a plot to represent 500 repeated 95%CI
Message-ID: <OFE0D3EF61.4BAA98D2-ON85256E40.00549021@health.state.ny.us>

I have a data with 500 repeated 95%CI and I want to make a plot as the
following to present them:

      |--------+--------|
        |-----+-----|
          |-----------+-----------|
                     |---------+--------|
....
.....

Would anyone mind naming the plot and some suggestion about R code?

Thanks ahead of time.
Heyen



From hb at maths.lth.se  Fri Feb 20 16:53:06 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 20 Feb 2004 16:53:06 +0100
Subject: [R] Stupid Limma question..
In-Reply-To: <BC5BCB65.921%j.mcelwee@ucl.ac.uk>
Message-ID: <000501c3f7c9$a1b00360$e502eb82@maths.lth.se>

Hi, I think this question should asked on the Bioconductor mailing
list instead. I know Gordon Smyth is reading that one, but I don't
think he's reading this one regularly.

If I remember correctly df <- topTable() returns a data.frame, which
you can write to a file using write.table(df, "topTable.dat"). 

Also, in R you can catch *any* output using sink(). See ?sink.

Cheers

Henrik Bengtsson

> -----Original Message-----
> From: r-help-bounces+hb=maths.lth.se at stat.math.ethz.ch 
> [mailto:r-help-bounces+hb=maths.lth.se at stat.math.ethz.ch] On 
> Behalf Of Joshua McElwee
> Sent: den 20 februari 2004 15:34
> To: r-help
> Subject: [R] Stupid Limma question..
> 
> 
>   Hi all.  I've got a really dumb question for anyone.  How 
> do I write the output of a limma analysis (basically the 
> topTable) to a text file?  I want to output the topTable for 
> the entire microarray (not really a topTable anymore I 
> suppose..).  Thanks for any advice! -Josh
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailma> n/listinfo/r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From m.okasha at palnet.com  Fri Feb 20 16:54:33 2004
From: m.okasha at palnet.com (Mahmoud K. Okasha)
Date: Fri, 20 Feb 2004 17:54:33 +0200
Subject: [R] R: Including R plots in a Microsoft Word document
Message-ID: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040220/48b11f19/attachment.pl

From MSchwartz at medanalytics.com  Fri Feb 20 18:08:00 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 20 Feb 2004 11:08:00 -0600
Subject: [R] R: Including R plots in a Microsoft Word document
In-Reply-To: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>
References: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>
Message-ID: <1077296879.7357.97.camel@localhost.localdomain>

On Fri, 2004-02-20 at 09:54, Mahmoud K. Okasha wrote:
> Greetings List,
> 
> I am conducting some large simulations using R. As a result, I get
> many plots but I'm having some trouble with including some of them in
> a Microsoft Word document. Can any one tell me the easiest method of
> having copies of the R-graphs in the Word documents?
> 
> Best regards
> Mahmoud


A couple of different ways:

1. If you actually need to see the graphics within the document and/or
send the .doc file to someone who needs to be able to see the plots as
they appear, then you should use Windows Metafile format images. Since
these are vector format files, you can resize them as required on your
pages. Bitmapped images (ie .BMP/.PNG) will distort as you resize them.
You can generate these by plotting directly into an R plot window and
then copy (ie. right mouse click) and paste into the Word document using
the Windows clipboard, or generate the plot files directly using the
win.metafile() function.

2. If you will be generating hard copies of the documents using a PS
printer, you can generate the graphics as EPS files using the
postscript() function. Word can import EPS files, but you will see them
only as place holders in your document (ie. a frame box) since Word
cannot actually interpret the images for display. Keep in mind that the
function has very specific argument requirements to enable the
generation of EPS files. These include:

horizontal = FALSE, onefile = FALSE, paper = "special"

With these in place, you can then generate your plots to the EPS files
and import them into your Word documents.

See ?postscript for more information.

If this is something that you will be doing with a level of repetition,
you might want to look into using Sweave, which combines LaTeX and R to
automate formatted report generation. More information is here:

http://www.ci.tuwien.ac.at/~leisch/Sweave/

There were also a couple of articles in RNews:

Friedrich Leisch. Sweave, part I: Mixing R and LaTeX. R News,
2(3):28-31, December 2002.

Friedrich Leisch. Sweave, part II: Package vignettes. R News,
2(2):21-24, October 2003.


Frank Harrell also has a document at:

http://cran.r-project.org/doc/contrib/Harrell-statcomp-notes.pdf

HTH,

Marc Schwartz



From ggrothendieck at myway.com  Fri Feb 20 17:19:32 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 20 Feb 2004 11:19:32 -0500 (EST)
Subject: [R] R: Including R plots in a Microsoft Word document
Message-ID: <20040220161932.20BBC3B94@mprdmxin.myway.com>


Right click on the plot and choose copy as metafile.  Copying
it as a metafile copies it as a vector graphic rather than as
a bitmapped graphic so the elements of the graphic (e.g. axis
labels, points on the plot) stay intact allowing later editing 
in Word.

In your Word document move to the point where you want to the
plot and press ctrl-V (or Edit | Paste).

In Word you can right click the plot and choose Edit in which
case you will be thrown into an editor and can edit the elements
the graphic such as the axis labels, etc. To do that, right click 
on the plot in Word, choose Edit and now you can edit it.   For 
example, click on an axis label and then change its text, its 
font, etc. in the usual way.

---
Date:   Fri, 20 Feb 2004 17:54:33 +0200 
From:   Mahmoud K. Okasha <m.okasha at palnet.com>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] R: Including R plots in a Microsoft Word document 

 
Greetings List,

I am conducting some large simulations using R. As a result, I get many plots but I'm having some trouble with including some of them in a Microsoft Word document. Can any one tell me the easiest method of having copies of the R-graphs in the Word documents?

Best regards
Mahmoud

 

  
 

         




 --- On Fri 02/20, Mahmoud K. Okasha < m.okasha at palnet.com > wrote:
From: Mahmoud K. Okasha [mailto: m.okasha at palnet.com]
To: r-help at stat.math.ethz.ch
Date: Fri, 20 Feb 2004 17:54:33 +0200
Subject: [R] R: Including R plots in a Microsoft Word document

Greetings List,<br><br>I am conducting some large simulations using R. As a result, I get many plots but I'm having some trouble with including some of them in a Microsoft Word document. Can any one tell me the easiest method of having copies of the R-graphs in the Word documents?<br><br>Best regards<br>Mahmoud<br>	[[alternative HTML version deleted]]<br><br>______________________________________________<br>R-help at stat.math.ethz.ch mailing list<br>https://www.stat.math.ethz.ch/mailman/listinfo/r-help<br>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html<br>



From uaca at alumni.uv.es  Fri Feb 20 17:36:35 2004
From: uaca at alumni.uv.es (uaca@alumni.uv.es)
Date: Fri, 20 Feb 2004 17:36:35 +0100
Subject: [R] R: Including R plots in a Microsoft Word document
In-Reply-To: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>
References: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>
Message-ID: <20040220163635.GB26073@pusa.informat.uv.es>

On Fri, Feb 20, 2004 at 05:54:33PM +0200, Mahmoud K. Okasha wrote:
> Greetings List,
> 
> I am conducting some large simulations using R. As a result, I get many plots but I'm having some trouble with including some of them in a Microsoft Word document. Can any one tell me the easiest method of having copies of the R-graphs in the Word documents?

R can produce at least PostScript, PDF, png, jpeg/jpg

see:

	help(postscript)
	help(pdf)
	help(png)
	help(jpeg)

I don't use word, for me the PostScript format (more precisely Encapsulated
PostScript/.eps) is the best/more easy/powerful format if you don't have thousands of
points or lines :-)

por instance, to print a simple plot:

postscript(file="somefile.eps");

plot(whatever);

dev.off(); <<---- Important

other formats are similar

regards

	Ulisses


                Debian GNU/Linux: a dream come true
-----------------------------------------------------------------------------
"Computers are useless. They can only give answers."            Pablo Picasso

Humans are slow, innaccurate, and brilliant.
Computers are fast, acurrate, and dumb. 
Together they are unbeatable

--->	Visita http://www.valux.org/ para saber acerca de la	<---
--->	Asociaci?n Valenciana de Usuarios de Linux		<---



From wolski at molgen.mpg.de  Fri Feb 20 17:58:39 2004
From: wolski at molgen.mpg.de (wolski)
Date: Fri, 20 Feb 2004 17:58:39 +0100
Subject: [R] passing object names in a vector to save?
Message-ID: <200402201758390883.0AFD0B55@harry.molgen.mpg.de>

Hi!

Like to write quite a lot (ca 100) of objects from my envirovment with save.
The names of the objects are in  a list nam.

nam<-dir()
nam<-grep("E",nam,value=T)
length(nam)
20

for(x in nam)
{
	#reads the objects and assigns the names.
	assign(x,simFromEmboss(Simmatrix(),x))
	nnam<-paste(x,".rda",sep="")
	print(nnam)
	save(x,file=nnam)	
}


I knew that it fails. (It saves object x containing a char.) 
How to save the objects in separate files not typing each time save(myobj,save="myobj.rda")???

Is there a workaround.


Sincerely Eryk



From tblackw at umich.edu  Fri Feb 20 17:28:04 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Fri, 20 Feb 2004 11:28:04 -0500 (EST)
Subject: [R] piece wise application of functions
In-Reply-To: <Pine.LNX.4.44.0402191540260.32006-100000@cezanne.fhcrc.org>
References: <Pine.LNX.4.44.0402191540260.32006-100000@cezanne.fhcrc.org>
Message-ID: <Pine.SOL.4.58.0402201114420.18530@asteroids.gpcc.itd.umich.edu>

Itay  -

If it were my problem, I would re-structure the task around the
existing capabilities of  lapply().  In particular, I would
concatenate the three lists of functions, then write a wrapper
function which takes three arguments:  an index, a list of
functions and a data set.  Then I would call  lapply()  twice
to get the result you appear to be asking for.  Here's a rough
example, untested, which may not work exactly for your situation.

miss.all <- c(missgp0, missgp1, missgp2)
wrapper  <- function(i, ff, d)  {ff[[i]](d)}
result.1 <- unlist(lapply(seq(9), wrapper, miss.all, snps.missgp[["ic"]]))
result.2 <- unlist(lapply(seq(9), wrapper, miss.all, strs.missgp[["ic"]]))
gaps     <- c(  #  nine multiples of 1e+6 which describe the nine functions )
result   <- cbind(gaps=gaps, snps=result.1, strs=result.2)

In this case,  result  is a matrix, not a data frame, but you can
easily convert between the two.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 19 Feb 2004, Itay Furman wrote:

>
> Dear all,
>
> After struggling for some time with *apply() and eva() without
> success, I decided to ask for help.
>
> I have 3 lists labeled with, each contains 3 different
> interpolation functions with identical names:
>
> > names(missgp0)
> [1] "spl.1mb" "spl.2mb" "spl.5mb"
> >
> > names(missgp1)
> [1] "spl.1mb" "spl.2mb" "spl.5mb"
> >
> > names(missgp2)
> [1] "spl.1mb" "spl.2mb" "spl.5mb"
> >
>
> (
> In case it matters the functions accept and return one argument:
> block.size <- spl.1mb(ic)
> )
>
> Then, I have 2 data frames with identical structure:
>
> > snps.missgp
>   intvl.mb    ic
> 1    1e+06 0.597
> 2    2e+06 0.504
> 3    5e+06 0.327
> 4    1e+07 0.204
> >
>
> > strs.missgp
>   intvl.mb      ic
> 1    1e+06 0.67200
> 2    2e+06 0.62325
> 3    5e+06 0.51000
> 4    1e+07 0.38775
> >
>
> I would like to apply the functions on these data frames
> piece-wise and create a data frame per function _list_.
>
> So I am looking for a final output like this:
>
> > case0
>     gap	 snps	strs
> 1 1e+06  ..	..
> 2 2e+06  ..	..
> 3 5e+06  ..	..
>
> Here, case0$snps[1] is, for example, the result of applying the
> function in  missgp0[1] on the entry snps.missgp$ic[1];
> and, case0$strs[1] is the result of applying the same function
> on strs.missgp$ic[1].
>
> Then, I want to repeat the whole thing with missgp1,2  instead
> of missgp0, generating case1,2 data frames.
>
> How should I do it?
>
>
> 	Thanks in advance,
> 	Itay Furman
>
> --------------------------------------------------------------------
> itayf at fhcrc.org			Fred Hutchinson Cancer Research Center
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From pgilbert at bank-banque-canada.ca  Fri Feb 20 17:55:43 2004
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 20 Feb 2004 11:55:43 -0500
Subject: [R] Re: R for economists
In-Reply-To: <20040219133608.GL781@igidr.ac.in>
References: <20040215063137.GA10703@igidr.ac.in>	<200402191426.55242.ahenningsen@email.uni-kiel.de>
	<20040219133608.GL781@igidr.ac.in>
Message-ID: <40363C0F.7000301@bank-banque-canada.ca>

Ajay Shah wrote:

>On Thu, Feb 19, 2004 at 02:26:55PM +0100, Arne Henningsen wrote:
>  
>
>>Hi,
>>
>>I did not find any web page about using R in economics and econometrics so 
>>far. However, this does not mean that there is none (searching with google 
>>for "R" and "economics" gives many pages about economics and a name like 
>>Firstname R. Lastname on it ;-)). 
>>Does anybody in the list does know such a web page?
>>If not, I will be happy if you, Ajay, could build and maintaine one.
>>    
>>
>
>Okay, I made a start, with
>      http://www.mayin.org/ajayshah/KB/R/more.html
>
>Tell me what should go into it. :-)
>
 You might consider:

- some economics topic areas  and mention packages that would be useful 
within those areas for different kinds of analysis that are commonly 
done. (There are several packages related to time series.)

- economics data sources that are easily accessible from R.

- papers where the analysis is known to have been done with R (and 
mention availability of code and data?)

- teaching material.

- translation of econometrics terminology to R and statistics terminology.

- a list of economic/financial institutions known to be using R.

This topic has been discussed on r-help a few times before, so I think 
once you get a bit more structure set up then you will get lots of 
additional input.

Paul Gilbert



From jfox at mcmaster.ca  Fri Feb 20 17:33:42 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 20 Feb 2004 11:33:42 -0500
Subject: [R] R: Including R plots in a Microsoft Word document
In-Reply-To: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>
Message-ID: <5.1.0.14.2.20040220112957.02079400@127.0.0.1>

Dear Mahmoud,

There are several ways to do this. I find the following the simplest: Right 
click on the graphics-device window in R and select "Copy as metafile" from 
the pop-up menu. Then right-click in the Word document where you want the 
graph to appear and select "Paste."

Perhaps if you could indicate what trouble you're experiencing, there would 
be something more to say.

That's it.
  John

At 05:54 PM 2/20/2004 +0200, Mahmoud K. Okasha wrote:
>Greetings List,
>
>I am conducting some large simulations using R. As a result, I get many 
>plots but I'm having some trouble with including some of them in a 
>Microsoft Word document. Can any one tell me the easiest method of having 
>copies of the R-graphs in the Word documents?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From zhu at stat.tamu.edu  Fri Feb 20 18:22:41 2004
From: zhu at stat.tamu.edu (Zonghui Hu)
Date: Fri, 20 Feb 2004 11:22:41 -0600
Subject: [R] A question on lme in R
Message-ID: <40364261.2000005@stat.tamu.edu>

Hi, everyone,

I have a question on using lme on a mixed effects model with nested 
error structure. After applying lme to the data, and put the outcome in, 
say TR.lme. I can extract the fixed effects by TR.lme$coef$fixed. 
However, when I use TR.lme$coef$random.effects, it does not give the 
variance components that I need, but a vector of values at each nested 
level. What I want are the estimated variance components that show up 
with summary(TR.lme), but I can not extract them from TR.lme.

Could you please give any suggestion? I have tried ranef( ), but it 
seems not to be the right function.

Thank you very much!

Zonghui



From feh3k at spamcop.net  Fri Feb 20 18:29:24 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Fri, 20 Feb 2004 12:29:24 -0500
Subject: [R] R: Including R plots in a Microsoft Word document
In-Reply-To: <1077296879.7357.97.camel@localhost.localdomain>
References: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>
	<1077296879.7357.97.camel@localhost.localdomain>
Message-ID: <20040220122924.26dce46b.feh3k@spamcop.net>

On Fri, 20 Feb 2004 11:08:00 -0600
Marc Schwartz <MSchwartz at medanalytics.com> wrote:

> On Fri, 2004-02-20 at 09:54, Mahmoud K. Okasha wrote:
> > Greetings List,
> > 
> > I am conducting some large simulations using R. As a result, I get
> > many plots but I'm having some trouble with including some of them in
> > a Microsoft Word document. Can any one tell me the easiest method of
> > having copies of the R-graphs in the Word documents?
> > 
> > Best regards
> > Mahmoud
> 
> 
> A couple of different ways:
> 
> 1. If you actually need to see the graphics within the document and/or
> send the .doc file to someone who needs to be able to see the plots as
> they appear, then you should use Windows Metafile format images. Since
> these are vector format files, you can resize them as required on your
> pages. Bitmapped images (ie .BMP/.PNG) will distort as you resize them.
> You can generate these by plotting directly into an R plot window and
> then copy (ie. right mouse click) and paste into the Word document using
> the Windows clipboard, or generate the plot files directly using the
> win.metafile() function.
> 
> 2. If you will be generating hard copies of the documents using a PS
> printer, you can generate the graphics as EPS files using the
> postscript() function. Word can import EPS files, but you will see them
> only as place holders in your document (ie. a frame box) since Word
> cannot actually interpret the images for display. Keep in mind that the
> function has very specific argument requirements to enable the
> generation of EPS files. These include:

Newer versions of Word will display postscript and pdf images on-screen,
so I think these are the way to go. -Frank

> 
> horizontal = FALSE, onefile = FALSE, paper = "special"
> 
> With these in place, you can then generate your plots to the EPS files
> and import them into your Word documents.
> 
> See ?postscript for more information.
> 
> If this is something that you will be doing with a level of repetition,
> you might want to look into using Sweave, which combines LaTeX and R to
> automate formatted report generation. More information is here:
> 
> http://www.ci.tuwien.ac.at/~leisch/Sweave/
> 
> There were also a couple of articles in RNews:
> 
> Friedrich Leisch. Sweave, part I: Mixing R and LaTeX. R News,
> 2(3):28-31, December 2002.
> 
> Friedrich Leisch. Sweave, part II: Package vignettes. R News,
> 2(2):21-24, October 2003.
> 
> 
> Frank Harrell also has a document at:
> 
> http://cran.r-project.org/doc/contrib/Harrell-statcomp-notes.pdf
> 
> HTH,
> 
> Marc Schwartz



From ajayshah at mayin.org  Fri Feb 20 14:19:48 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Fri, 20 Feb 2004 18:49:48 +0530
Subject: R for economists (was: [R] Almost Ideal Demand System)
In-Reply-To: <opr3mlxb0t1pelvz@smtp.tcd.ie>
References: <20040215063137.GA10703@igidr.ac.in>
	<200402191426.55242.ahenningsen@email.uni-kiel.de>
	<20040219133608.GL781@igidr.ac.in> <opr3mlxb0t1pelvz@smtp.tcd.ie>
Message-ID: <20040220131948.GR781@igidr.ac.in>

On Thu, Feb 19, 2004 at 04:40:13PM -0000, Simon Cullen wrote:
> On Thu, 19 Feb 2004 19:06:08 +0530, Ajay Shah <ajayshah at mayin.org> wrote:
> 
> <snip R for economists>
> 
> >Okay, I made a start, with
> >      http://www.mayin.org/ajayshah/KB/R/more.html
> >
> >Tell me what should go into it. :-)
> 
> I think the most important thing for economists would be a list of the  
> common econometric models and how they are accessed in R, for instance  
> packages and the functions within those packages.
> 
> An example is what is known as a Tobit model to econometricians, which is  
> one type of a survival model (to everybody else!). (This isn't that good  
> an example as help.search("tobit") would probably turn up the right  
> library.)
> 
> If you could produce a table with Econometrics to R translations that  
> would be immensely helpful, as a start. I know someone suggested creating  
> a facility for 'aliasing' econometrics-speak to R functions, but this got  
> shot down for being unwieldy (rightly so, I think).

This sounds like a good idea. It'd be neat to have a TeX document
where "many" mainstream econometrics models are written in
mathematics, and then fragments of R code are shown for the purpose.

In addition, I see rolling-your-own-likelihood-function as being a
very common thing in economics today. So I'd just put a lot of focus
on exposition of R facilities for doing MLE, with functionality
comparable with the maxlik and co libraries of gauss. I am not yet
fluent in R, but my early sense is that maxlik+co of gauss are a bit
ahead of what we have in R.

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From wolski at molgen.mpg.de  Fri Feb 20 19:11:41 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 20 Feb 2004 19:11:41 +0100
Subject: [R] passing object names in a vector to save?
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7805@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7805@usrymx25.merck.com>
Message-ID: <200402201911410685.01B5D686@harry.molgen.mpg.de>

Hallo!

Thanks a lot!
Its exactly what I was looking for.

Sincerely
Eryk

*********** REPLY SEPARATOR  ***********

On 2/20/2004 at 12:57 PM Liaw, Andy wrote:

>Is the `list=' argument for save() what you're looking for?
>
>Andy
>
>> Hi!
>> 
>> Like to write quite a lot (ca 100) of objects from my 
>> envirovment with save.
>> The names of the objects are in  a list nam.
>> 
>> nam<-dir()
>> nam<-grep("E",nam,value=T)
>> length(nam)
>> 20
>> 
>> for(x in nam)
>> {
>> 	#reads the objects and assigns the names.
>> 	assign(x,simFromEmboss(Simmatrix(),x))
>> 	nnam<-paste(x,".rda",sep="")
>> 	print(nnam)
>> 	save(x,file=nnam)	
>> }
>> 
>> 
>> I knew that it fails. (It saves object x containing a char.) 
>> How to save the objects in separate files not typing each 
>> time save(myobj,save="myobj.rda")???
>> 
>> Is there a workaround.
>> 
>> 
>> Sincerely Eryk
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments, contains
>information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New
>Jersey, USA 08889), and/or its affiliates (which may be known outside the
>United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as
>Banyu) that may be confidential, proprietary copyrighted and/or legally
>privileged. It is intended solely for the use of the individual or entity
>named on this message.  If you are not the intended recipient, and have
>received this message in error, please notify us immediately by reply
>e-mail
>and then delete it from your system.
>------------------------------------------------------------------------------



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics   
Ihnestrasse 73 14195 Berlin          'v'    
tel: 0049-30-84131285               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From macq at llnl.gov  Fri Feb 20 19:39:28 2004
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 20 Feb 2004 10:39:28 -0800
Subject: [R] R: Including R plots in a Microsoft Word document
In-Reply-To: <1077296879.7357.97.camel@localhost.localdomain>
References: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>
	<1077296879.7357.97.camel@localhost.localdomain>
Message-ID: <p06002009bc5c0371a84c@[128.115.153.6]>

At 11:08 AM -0600 2/20/04, Marc Schwartz wrote:
>On Fri, 2004-02-20 at 09:54, Mahmoud K. Okasha wrote:
>>  Greetings List,
>>
>>  I am conducting some large simulations using R. As a result, I get
>>  many plots but I'm having some trouble with including some of them in
>>  a Microsoft Word document. Can any one tell me the easiest method of
>>  having copies of the R-graphs in the Word documents?
>>
>>  Best regards
>>  Mahmoud
>
>
>A couple of different ways:
>
>1. If you actually need to see the graphics within the document and/or
>send the .doc file to someone who needs to be able to see the plots as
>they appear, then you should use Windows Metafile format images. Since
>these are vector format files, you can resize them as required on your
>pages. Bitmapped images (ie .BMP/.PNG) will distort as you resize them.
>You can generate these by plotting directly into an R plot window and
>then copy (ie. right mouse click) and paste into the Word document using
>the Windows clipboard, or generate the plot files directly using the
>win.metafile() function.

If you open the EPS file created as in (2) below with Adobe 
Illustrator, then save it as "Illustrator EPS", then a preview image 
will be added, and displayed on-screen when the file is imported into 
Word. This would of course be prohibitively tedious if there are too 
many files. pdf is the format I would try next, depending on how good 
Word is at importing, displaying, and printing an inserted pdf.

>2. If you will be generating hard copies of the documents using a PS
>printer, you can generate the graphics as EPS files using the
>postscript() function. Word can import EPS files, but you will see them
>only as place holders in your document (ie. a frame box) since Word
>cannot actually interpret the images for display. Keep in mind that the
>function has very specific argument requirements to enable the
>generation of EPS files. These include:
>
>horizontal = FALSE, onefile = FALSE, paper = "special"
>
>With these in place, you can then generate your plots to the EPS files
>and import them into your Word documents.
>
>See ?postscript for more information.
>
>If this is something that you will be doing with a level of repetition,
>you might want to look into using Sweave, which combines LaTeX and R to
>automate formatted report generation. More information is here:
>
>http://www.ci.tuwien.ac.at/~leisch/Sweave/
>
>There were also a couple of articles in RNews:
>
>Friedrich Leisch. Sweave, part I: Mixing R and LaTeX. R News,
>2(3):28-31, December 2002.
>
>Friedrich Leisch. Sweave, part II: Package vignettes. R News,
>2(2):21-24, October 2003.
>
>
>Frank Harrell also has a document at:
>
>http://cran.r-project.org/doc/contrib/Harrell-statcomp-notes.pdf
>
>HTH,
>
>Marc Schwartz
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From bates at stat.wisc.edu  Fri Feb 20 19:49:14 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 20 Feb 2004 12:49:14 -0600
Subject: [R] A question on lme in R
In-Reply-To: <40364261.2000005@stat.tamu.edu>
References: <40364261.2000005@stat.tamu.edu>
Message-ID: <6rfzd51t91.fsf@bates4.stat.wisc.edu>

Zonghui Hu <zhu at stat.tamu.edu> writes:

> I have a question on using lme on a mixed effects model with nested
> error structure. After applying lme to the data, and put the outcome
> in, say TR.lme. I can extract the fixed effects by
> TR.lme$coef$fixed. However, when I use TR.lme$coef$random.effects, it
> does not give the variance components that I need, but a vector of
> values at each nested level. What I want are the estimated variance
> components that show up with summary(TR.lme), but I can not extract
> them from TR.lme.

It is better to use the extractor functions fixef (or fixed.effects)
and ranef (of random.effects) to extract the estimated coefficients.
You should not depend on a particular internal representation of the
object returned from a model-fitting function.  For example, objects
returned by the version of lme in the lme4 package uses a different
internal representation.

As indicated in the output from
 help(package = "nlme")
the function VarCorr returns the variance and correlation components.

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From tlumley at u.washington.edu  Fri Feb 20 19:54:15 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 20 Feb 2004 10:54:15 -0800 (PST)
Subject: [R] passing object names in a vector to save?
In-Reply-To: <200402201758390883.0AFD0B55@harry.molgen.mpg.de>
References: <200402201758390883.0AFD0B55@harry.molgen.mpg.de>
Message-ID: <Pine.A41.4.58.0402201050060.109002@homer04.u.washington.edu>

On Fri, 20 Feb 2004, wolski wrote:

> for(x in nam)
> {
> 	#reads the objects and assigns the names.
> 	assign(x,simFromEmboss(Simmatrix(),x))
> 	nnam<-paste(x,".rda",sep="")
> 	print(nnam)
> 	save(x,file=nnam)
> }
>
>
> I knew that it fails. (It saves object x containing a char.)

There are at least two possibilities.  The specialised one is to look at
the help for save() and notice that you can specify a vector of names of
objects with the list= argument
  save(list=x,file=nnam)

The more general one is to use substitute() or do.call(). For example
  do.call("save",list(as.name(x),file=nnam))

	-thomas



From MSchwartz at medanalytics.com  Fri Feb 20 19:58:17 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 20 Feb 2004 12:58:17 -0600
Subject: [R] R: Including R plots in a Microsoft Word document
In-Reply-To: <20040220122924.26dce46b.feh3k@spamcop.net>
References: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>
	<1077296879.7357.97.camel@localhost.localdomain>
	<20040220122924.26dce46b.feh3k@spamcop.net>
Message-ID: <1077303496.7016.17.camel@localhost.localdomain>

On Fri, 2004-02-20 at 11:29, Frank E Harrell Jr wrote:

> Newer versions of Word will display postscript and pdf images on-screen,
> so I think these are the way to go. -Frank


Frank is correct on the postscript images. I just tried this with Word
2000, 2002 and 2003.

Word 2002 and 2003 will generate a PS preview image and display that
image on the screen. This is the case with PowerPoint for these versions
as well.

Word 2000 however does not generate the preview on import and only shows
a placeholder and PS file title/header information.

The one possible downside is that if you are only reviewing this on the
screen, which might be a scenario with PowerPoint for example, the fonts
that are generated with the preview image are pretty rough. Presumably,
the preview image is a bitmap. If you are only displaying the image, you
may be better off with the Metafile option.

However, if you print to a PS printer, print to a PS file or have Adobe
or other software to generate a PDF file, this is a non-issue and I
agree with Frank that this would clearly be the way to go.

I could not however find a PDF import filter and upon checking the MS
web site and Knowledge Base, did not see anything listed there.

There is a program called PSToEdit which does have a Word PDF import
filter available, however it is not free as I recall.

Frank, if you know of an alternate PDF import filter or if I missed
something in Word, please correct me.

Thanks for the clarifications Frank.

Regards,

Marc Schwartz



From sam.kemp2 at ntlworld.com  Fri Feb 20 20:03:47 2004
From: sam.kemp2 at ntlworld.com (Samuel Kemp)
Date: Fri, 20 Feb 2004 19:03:47 +0000
Subject: [R] Installing OmegaHat OOP package
Message-ID: <40365A13.4040209@ntlworld.com>

Hi,

I am trying to install the OOP package (v0.4-2) from Omega Hat using the 
R CMD INSTALL (I have also tried untarring the package an using R 
INSTALL) but no joy. Here is the following error...

$] R CMD INSTALL OOP_*

* Installing *source* package 'OOP' ...
** libs
gcc -I/usr/local/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -g -O2 -c RtreeApply.c -o RtreeApply.o
gcc -shared -L/usr/local/lib -o OOP.so RtreeApply.o
** R
** inst
** save image
[1] TRUE
Initializing OOP objects in database 1
[1] "initialize"
Error in .identC(class(Class), "classRepresentation") :
        couldn't find function ".traceClassName"
Execution halted
ERROR: execution of package source for 'OOP' failed
** Removing '/usr/local/lib/R/library/OOP'

Anyone got a fix?

Cheers,

Sam.



From ggrothendieck at myway.com  Fri Feb 20 20:04:37 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 20 Feb 2004 14:04:37 -0500 (EST)
Subject: [R] R: Including R plots in a Microsoft Word document
Message-ID: <20040220190437.D20263950@mprdmxin.myway.com>



However, 

1. the editing of .ps files once they have been inserted
into Word seems to be limited compared to using Windows metafiles.

2. R on Windows does not provide the capability to do right 
click copy with a .ps file so you have to right click save the 
file and then insert it into Word which is a bit less convenient
than using the clipboard and it leaves a file around that you
still have to delete.

---

Date:   Fri, 20 Feb 2004 12:29:24 -0500 
From:   Frank E Harrell Jr <feh3k at spamcop.net>
To:   <MSchwartz at medanalytics.com> 
Cc:   <r-help at stat.math.ethz.ch> 
Subject:   Re: [R] R: Including R plots in a Microsoft Word document 

 
On Fri, 20 Feb 2004 11:08:00 -0600
Marc Schwartz <MSchwartz at medanalytics.com> wrote:

> On Fri, 2004-02-20 at 09:54, Mahmoud K. Okasha wrote:
> > Greetings List,
> > 
> > I am conducting some large simulations using R. As a result, I get
> > many plots but I'm having some trouble with including some of them in
> > a Microsoft Word document. Can any one tell me the easiest method of
> > having copies of the R-graphs in the Word documents?
> > 
> > Best regards
> > Mahmoud
> 
> 
> A couple of different ways:
> 
> 1. If you actually need to see the graphics within the document and/or
> send the .doc file to someone who needs to be able to see the plots as
> they appear, then you should use Windows Metafile format images. Since
> these are vector format files, you can resize them as required on your
> pages. Bitmapped images (ie .BMP/.PNG) will distort as you resize them.
> You can generate these by plotting directly into an R plot window and
> then copy (ie. right mouse click) and paste into the Word document using
> the Windows clipboard, or generate the plot files directly using the
> win.metafile() function.
> 
> 2. If you will be generating hard copies of the documents using a PS
> printer, you can generate the graphics as EPS files using the
> postscript() function. Word can import EPS files, but you will see them
> only as place holders in your document (ie. a frame box) since Word
> cannot actually interpret the images for display. Keep in mind that the
> function has very specific argument requirements to enable the
> generation of EPS files. These include:

Newer versions of Word will display postscript and pdf images on-screen,
so I think these are the way to go. -Frank



From vim-return- at vim.org  Fri Feb 20 20:07:42 2004
From: vim-return- at vim.org (vim-return-@vim.org)
Date: 20 Feb 2004 19:07:42 -0000
Subject: [R] ezmlm response
Message-ID: <1077304062.1425.ezmlm@vim.org>

Hi! This is the ezmlm program. I'm managing the
vim at vim.org mailing list.

This is a generic help message. The message I received wasn't sent to
any of my command addresses.


--- Administrative commands for the vim list ---

I can handle administrative requests automatically. Please
do not send them to the list address! Instead, send
your message to the correct command address:

To subscribe to the list, send a message to:
   <vim-subscribe at vim.org>

To remove your address from the list, send a message to:
   <vim-unsubscribe at vim.org>

Send mail to the following for info and FAQ for this list:
   <vim-info at vim.org>
   <vim-faq at vim.org>

Similar addresses exist for the digest list:
   <vim-digest-subscribe at vim.org>
   <vim-digest-unsubscribe at vim.org>

To get messages 123 through 145 (a maximum of 100 per request), mail:
   <vim-get.123_145 at vim.org>

To get an index with subject and author for messages 123-456 , mail:
   <vim-index.123_456 at vim.org>

They are always returned as sets of 100, max 2000 per request,
so you'll actually get 100-499.

To receive all messages with the same subject as message 12345,
send an empty message to:
   <vim-thread.12345 at vim.org>

The messages do not really need to be empty, but I will ignore
their content. Only the ADDRESS you send to is important.

You can start a subscription for an alternate address,
for example "john at host.domain", just add a hyphen and your
address (with '=' instead of '@') after the command word:
<vim-subscribe-john=host.domain at vim.org>

To stop subscription for this address, mail:
<vim-unsubscribe-john=host.domain at vim.org>

In both cases, I'll send a confirmation message to that address. When
you receive it, simply reply to it to complete your subscription.

If despite following these instructions, you do not get the
desired results, please contact my owner at
vim-owner at vim.org. Please be patient, my owner is a
lot slower than I am ;-)

--- Enclosed is a copy of the request I received.

Return-Path: <r-help at lists.r-project.org>
Received: (qmail 1420 invoked from network); 20 Feb 2004 19:07:42 -0000
Received: from eccr235pc64.colorado.edu (HELO vim.org) (128.138.177.64)
  by foobar.math.fu-berlin.de with SMTP; 20 Feb 2004 19:07:42 -0000
From: r-help at lists.r-project.org
To: vim-help at vim.org
Subject: warning
Date: Fri, 20 Feb 2004 12:07:25 -0700
MIME-Version: 1.0
Content-Type: multipart/mixed; boundary="72183615"

--72183615
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

you feel the same

--72183615
Content-Type: application/x-zip-compressed; name="textfile.zip"
Content-Transfer-Encoding: base64
Content-Disposition: attachment; filename="textfile.zip"


--72183615--



From HankeA at mar.dfo-mpo.gc.ca  Fri Feb 20 19:43:55 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Fri, 20 Feb 2004 14:43:55 -0400
Subject: [R] strptime() behaviour
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE124943@msgmarsta01.bio.dfo.ca>

Is it normal behaviour for strptime("29-Jan-01","%d-%b-%y")$mon to return a
value of 0?
strptime("29-Jan-01","%d-%b-%y")$year #works ok
101 
strptime("29-Jan-01","%d-%b-%y")$mday #works ok
29
Regards,
Alex

Alex Hanke
Department of Fisheries and Oceans
St. Andrews Biological Station
531 Brandy Cove Road
St. Andrews, NB
Canada
E5B 2L9



From dominicb at cvs.rochester.edu  Fri Feb 20 20:48:37 2004
From: dominicb at cvs.rochester.edu (Dominic Barraclough)
Date: Fri, 20 Feb 2004 14:48:37 -0500
Subject: [R] setting options when using eval
Message-ID: <4.3.1.2.20040220140438.00bff710@cvs.rochester.edu>

Hi All,

I'm using a call to eval to evaluate a linear model, however, I have found 
that despite calling
options (contrasts=c("contr.sum", "contr.poly"))

prior  to evaluation, my model factors are coded using  the indicator 
coding associated with the "contr.treatment" contrast option

As an inelegant work around I am setting the contrast option explicitly in 
the model, but I'm hoping that somebody could be me some help with how to 
set  options (contrasts=c("contr.sum", "contr.poly"))
in the correct environment so that I don't need my hack. Some insights to 
what in the enviroments are in the context of eval would also be most helpful.

here is the version of the lm parameters that does what I want.

model
next.choice ~ Lag0 , data = the.matrix,   contrasts =list( Lag0 =contr.sum )

I don't want to have to add the last parameter
contrasts =list( Lag0 =contr.sum )
if possible.


Lag0 is a factor with 4 levels 0,1,2,3

the following is the function that I call to evaluate models
the.model <- function(the.matrix, model)
   {
     options(contrasts=c("contr.sum", "contr.poly"))  # this does not cause 
factors to be code using contr.sum is subsequent
     expr <- paste("lm(", model,")")
     rc <-    eval(parse(text=expr))
     return (rc)
   }


          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    8.1
year     2003
month    11
day      21
language R


Dominic



From pauljohn at ku.edu  Fri Feb 20 20:47:51 2004
From: pauljohn at ku.edu (Paul Johnson)
Date: Fri, 20 Feb 2004 13:47:51 -0600
Subject: [R] R: Including R plots in a Microsoft Word document
In-Reply-To: <20040220163635.GB26073@pusa.informat.uv.es>
References: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>
	<20040220163635.GB26073@pusa.informat.uv.es>
Message-ID: <40366467.20709@ku.edu>

I have wrestled with this problem a lot. I use Linux, coauthors use 
Windows, and the eps files I make from R don't work with MS Word.  Well, 
the don't ever have "previews" and they sometimes won't print at all 
when I use CrossOver Office with MS Office 2000 in Linux.  My coauthor 
says he can often wrestle my eps files into word on his system with 
Office 2003.  People keep telling me to use gsview to insert the preview 
panes into eps files, and that does work, but more than one half of the 
time my system creates eps files that look significantly worse than the 
originals.  Sometimes it inserts a blank page at the top of the eps or 
it reshapes a figure.  I don't care enough about MS to try to track that 
down.  It just pisses me off.


As a result, I think the answer is more complicated than other people 
make it seem.

I don't think it does any good to output a pdf file because, as  I 
learned yesterday, MS Word users can't import a pdf file into a doc.

Clearly, if you are an MS windows user of R, you can save graphics in 
the windows meta format (wmf)  (or is it enhanced meta format, emf?). 
That will go more or less seamlessly into Word.  If you have a chance to 
boot into Windows, and you really must make an image that works well 
with Word, then you should boot into Windows, run your R in there and 
make the wmf file.

If you are a Linux/Unix user, and you are too proud to use Windows,  the 
problem is much more difficult to deal with.

If you are ABSOLUTELY SURE that your image does not need to be resized 
in any way, you could output from R into a picture type format, such as 
png.  As long as the image does not need to resized in any way, that 
will be fine.  If it is resized, then all bets are off.

I find that the R output to the xfig format is quite good and I can edit 
files in xfig.  You can edit those files, add text, so its very very 
handy.  So right now I'm looking for a good bridge from xfig format to 
Word.  But I just started investigating that.

uaca at alumni.uv.es wrote:

>On Fri, Feb 20, 2004 at 05:54:33PM +0200, Mahmoud K. Okasha wrote:
>  
>
>>Greetings List,
>>
>>I am conducting some large simulations using R. As a result, I get many plots but I'm having some trouble with including some of them in a Microsoft Word document. Can any one tell me the easiest method of having copies of the R-graphs in the Word documents?
>>    
>>
>
>R can produce at least PostScript, PDF, png, jpeg/jpg
>
>see:
>
>	help(postscript)
>	help(pdf)
>	help(png)
>	help(jpeg)
>
>I don't use word, for me the PostScript format (more precisely Encapsulated
>PostScript/.eps) is the best/more easy/powerful format if you don't have thousands of
>points or lines :-)
>
>por instance, to print a simple plot:
>
>postscript(file="somefile.eps");
>
>plot(whatever);
>
>dev.off(); <<---- Important
>
>other formats are similar
>
>regards
>
>	Ulisses
>
>
>                Debian GNU/Linux: a dream come true
>-----------------------------------------------------------------------------
>"Computers are useless. They can only give answers."            Pablo Picasso
>
>Humans are slow, innaccurate, and brilliant.
>Computers are fast, acurrate, and dumb. 
>Together they are unbeatable
>
>--->	Visita http://www.valux.org/ para saber acerca de la	<---
>--->	Asociaci?n Valenciana de Usuarios de Linux		<---
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>


-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504                              
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From rossini at blindglobe.net  Fri Feb 20 21:18:19 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 20 Feb 2004 12:18:19 -0800
Subject: [R] Re: R for economists
In-Reply-To: <20040220131948.GR781@igidr.ac.in> (Ajay Shah's message of
	"Fri, 20 Feb 2004 18:49:48 +0530")
References: <20040215063137.GA10703@igidr.ac.in>
	<200402191426.55242.ahenningsen@email.uni-kiel.de>
	<20040219133608.GL781@igidr.ac.in> <opr3mlxb0t1pelvz@smtp.tcd.ie>
	<20040220131948.GR781@igidr.ac.in>
Message-ID: <851xopsdx0.fsf@servant.blindglobe.net>

Ajay Shah <ajayshah at mayin.org> writes:


>> If you could produce a table with Econometrics to R translations that  
>> would be immensely helpful, as a start. I know someone suggested creating  
>> a facility for 'aliasing' econometrics-speak to R functions, but this got  
>> shot down for being unwieldy (rightly so, I think).
>
> This sounds like a good idea. It'd be neat to have a TeX document
> where "many" mainstream econometrics models are written in
> mathematics, and then fragments of R code are shown for the purpose.

Even better would be an Sweave vignette (i.e. actual workable code,
not just displayed fragments).

> In addition, I see rolling-your-own-likelihood-function as being a
> very common thing in economics today. So I'd just put a lot of focus
> on exposition of R facilities for doing MLE, with functionality
> comparable with the maxlik and co libraries of gauss. I am not yet
> fluent in R, but my early sense is that maxlik+co of gauss are a bit
> ahead of what we have in R.

optim is pretty good for most things -- very comparable to Gauss last
I checked Gauss (a few years back).

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From ggrothendieck at myway.com  Fri Feb 20 21:28:59 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 20 Feb 2004 15:28:59 -0500 (EST)
Subject: [R] strptime() behaviour
Message-ID: <20040220202859.6557C3963@mprdmxin.myway.com>



Yes, its normal.

See ?DateTimeClasses

---
Date:   Fri, 20 Feb 2004 14:43:55 -0400 
From:   Hanke, Alex <HankeA at mar.dfo-mpo.gc.ca>
[ Add to Address Book | Block Address | Report as Spam ] 
To:   'r-help at stat.math.ethz.ch' <r-help at stat.math.ethz.ch> 
Subject:   [R] strptime() behaviour 

 
Is it normal behaviour for strptime("29-Jan-01","%d-%b-%y")$mon to return a
value of 0?
strptime("29-Jan-01","%d-%b-%y")$year #works ok
101 
strptime("29-Jan-01","%d-%b-%y")$mday #works ok
29
Regards,
Alex

Alex Hanke
Department of Fisheries and Oceans
St. Andrews Biological Station
531 Brandy Cove Road
St. Andrews, NB
Canada
E5B 2L9



From greenberg at ucdavis.edu  Fri Feb 20 21:42:17 2004
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Fri, 20 Feb 2004 12:42:17 -0800
Subject: [R] 1024GB max memory on R for Windows XP?
In-Reply-To: <s035c824.057@med-gwia-01a.med.umich.edu>
Message-ID: <BC5BB129.19C3C%greenberg@ucdavis.edu>

Does UNIX R have a similar command, or does it just take as much memory as
it needs?  On a related note, does the memory have to be contiguous on
either type of system?  I am not hitting my max memory even with the 2gb max
mem set (I'm not even hitting 1.5gb) -- it is giving me errors such as:

Error: cannot allocate vector of size 387873 Kb (I should point out that
this value changes when I simply rerun the previous line).

There isn't really an easy way of getting around this, since I'm using the
prune.tree function -- seeing as how its 1 line of code, I don't see how to
optimize this.

--j

On 2/20/04 5:40 AM, "James MacDonald" <jmacdon at med.umich.edu> wrote:

> --max-mem-size=2000M


-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From dliu at jhsph.edu  Fri Feb 20 22:14:51 2004
From: dliu at jhsph.edu (Dongmei Liu)
Date: Fri, 20 Feb 2004 16:14:51 -0500
Subject: [R] run R BATCH job in PHP
Message-ID: <9d5a7e9da978.9da9789d5a7e@jhsph.edu>

Hello,

Does anyone know how to run R BATCH job in PHP? I tried the PHP function
exec(), shell_exec, passthru() to run R script, however, none of them
worked. If someone ever had experince to run R in PHP, could I ask for
an example code? 

Thanks a lot!
Dongmei



From wanqing.wen at Vanderbilt.Edu  Fri Feb 20 22:19:11 2004
From: wanqing.wen at Vanderbilt.Edu (Wen, Wanqing)
Date: Fri, 20 Feb 2004 15:19:11 -0600
Subject: [R] (no subject)
Message-ID: <F7BF99CC7F0E174DBCF8C6175B0325FF019E7999@mailbe01>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040220/e265214f/attachment.pl

From andy_liaw at merck.com  Fri Feb 20 22:19:32 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 20 Feb 2004 16:19:32 -0500
Subject: [R] 1024GB max memory on R for Windows XP?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF780A@usrymx25.merck.com>

For vectors and matrices (which are vectors with dim attributes), I believe
the memory need to be contiguous, but not for lists.

You still have not indicated which particular "UNIX" you are using.  On the
64-bit Linux we have here with 16GB RAM, the R (compiled as 64-bit
application) process can use nearly all the physical RAM available, without
any setting.

Andy

> From: Jonathan Greenberg
> 
> 
> Does UNIX R have a similar command, or does it just take as 
> much memory as
> it needs?  On a related note, does the memory have to be contiguous on
> either type of system?  I am not hitting my max memory even 
> with the 2gb max
> mem set (I'm not even hitting 1.5gb) -- it is giving me 
> errors such as:
> 
> Error: cannot allocate vector of size 387873 Kb (I should 
> point out that
> this value changes when I simply rerun the previous line).
> 
> There isn't really an easy way of getting around this, since 
> I'm using the
> prune.tree function -- seeing as how its 1 line of code, I 
> don't see how to
> optimize this.
> 
> --j
> 
> On 2/20/04 5:40 AM, "James MacDonald" <jmacdon at med.umich.edu> wrote:
> 
> > --max-mem-size=2000M
> 
> 
> -- 
> Jonathan Greenberg
> Graduate Group in Ecology, U.C. Davis
> http://www.cstars.ucdavis.edu/~jongreen
> http://www.cstars.ucdavis.edu
> AIM: jgrn307 or jgrn3007
> MSN: jgrn307 at msn.com or jgrn3007 at msn.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From clandry at fas.harvard.edu  Fri Feb 20 22:30:16 2004
From: clandry at fas.harvard.edu (Christian Landry)
Date: Fri, 20 Feb 2004 16:30:16 -0500
Subject: [R] BATCH files
Message-ID: <5.1.0.14.2.20040220162838.00b52350@fas.harvard.edu>

Could someone tell me where I could find some instructions for running R in 
BATCH mode? Especially regarding the format of the program or command file,

Thanks a lot



From andy_liaw at merck.com  Fri Feb 20 22:33:07 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 20 Feb 2004 16:33:07 -0500
Subject: [R] run R BATCH job in PHP
Message-ID: <3A822319EB35174CA3714066D590DCD504AF780D@usrymx25.merck.com>

The bottom of every post to this list says:

PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

which, among other things, tells you to search in the archive.  If you do
that, you will see that this question has been asked numerous times, and had
been answered.  The last relevant thread was quite recent.

Andy

> From: Dongmei Liu
> 
> Hello,
> 
> Does anyone know how to run R BATCH job in PHP? I tried the 
> PHP function
> exec(), shell_exec, passthru() to run R script, however, none of them
> worked. If someone ever had experince to run R in PHP, could I ask for
> an example code? 
> 
> Thanks a lot!
> Dongmei
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From feh3k at spamcop.net  Fri Feb 20 22:44:33 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Fri, 20 Feb 2004 16:44:33 -0500
Subject: [R] R: Including R plots in a Microsoft Word document
In-Reply-To: <40366467.20709@ku.edu>
References: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>
	<20040220163635.GB26073@pusa.informat.uv.es>
	<40366467.20709@ku.edu>
Message-ID: <20040220164433.34895083.feh3k@spamcop.net>

On Fri, 20 Feb 2004 13:47:51 -0600
Paul Johnson <pauljohn at ku.edu> wrote:

> I have wrestled with this problem a lot. I use Linux, coauthors use 
> Windows, and the eps files I make from R don't work with MS Word.  Well,
> 
> the don't ever have "previews" and they sometimes won't print at all 
> when I use CrossOver Office with MS Office 2000 in Linux.  My coauthor 
> says he can often wrestle my eps files into word on his system with 
> Office 2003.  People keep telling me to use gsview to insert the preview
> 
> panes into eps files, and that does work, but more than one half of the 
> time my system creates eps files that look significantly worse than the 
> originals.  Sometimes it inserts a blank page at the top of the eps or 
> it reshapes a figure.  I don't care enough about MS to try to track that
> 
> down.  It just pisses me off.
> 
> 
> As a result, I think the answer is more complicated than other people 
> make it seem.
> 
> I don't think it does any good to output a pdf file because, as  I 
> learned yesterday, MS Word users can't import a pdf file into a doc.

Word XP does handle pdf and does not require previews, so the first
problem also vanishes.

eps and pdf are the most likely formats to render well.  Also, has anyone
tried creating a Word document using OpenOffice with figures imported from
R?

The real solution is LaTeX.

Frank Harrell

> 
> Clearly, if you are an MS windows user of R, you can save graphics in 
> the windows meta format (wmf)  (or is it enhanced meta format, emf?). 
> That will go more or less seamlessly into Word.  If you have a chance to
> 
> boot into Windows, and you really must make an image that works well 
> with Word, then you should boot into Windows, run your R in there and 
> make the wmf file.
> 
> If you are a Linux/Unix user, and you are too proud to use Windows,  the
> 
> problem is much more difficult to deal with.
> 
> If you are ABSOLUTELY SURE that your image does not need to be resized 
> in any way, you could output from R into a picture type format, such as 
> png.  As long as the image does not need to resized in any way, that 
> will be fine.  If it is resized, then all bets are off.
> 
> I find that the R output to the xfig format is quite good and I can edit
> 
> files in xfig.  You can edit those files, add text, so its very very 
> handy.  So right now I'm looking for a good bridge from xfig format to 
> Word.  But I just started investigating that.
> 
> uaca at alumni.uv.es wrote:
> 
> >On Fri, Feb 20, 2004 at 05:54:33PM +0200, Mahmoud K. Okasha wrote:
> >  
> >
> >>Greetings List,
> >>
> >>I am conducting some large simulations using R. As a result, I get
> >many plots but I'm having some trouble with including some of them in a
> >Microsoft Word document. Can any one tell me the easiest method of
> >having copies of the R-graphs in the Word documents?>    
> >>
> >
> >R can produce at least PostScript, PDF, png, jpeg/jpg
> >
> >see:
> >
> >	help(postscript)
> >	help(pdf)
> >	help(png)
> >	help(jpeg)
> >
> >I don't use word, for me the PostScript format (more precisely
> >Encapsulated PostScript/.eps) is the best/more easy/powerful format if
> >you don't have thousands of points or lines :-)
> >
> >por instance, to print a simple plot:
> >
> >postscript(file="somefile.eps");
> >
> >plot(whatever);
> >
> >dev.off(); <<---- Important
> >
> >other formats are similar
> >
> >regards
> >
> >	Ulisses
> >
> >
> >                Debian GNU/Linux: a dream come true
> >----------------------------------------------------------------------
> >-------"Computers are useless. They can only give answers."           
> >Pablo Picasso
> >
> >Humans are slow, innaccurate, and brilliant.
> >Computers are fast, acurrate, and dumb. 
> >Together they are unbeatable
> >
> >--->	Visita http://www.valux.org/ para saber acerca de la	<---
> >--->	Asociaci?n Valenciana de Usuarios de Linux		<---
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> >http://www.R-project.org/posting-guide.html
> >  
> >
> 
> 
> -- 
> Paul E. Johnson                       email: pauljohn at ku.edu
> Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
> 1541 Lilac Lane, Rm 504                              
> University of Kansas                  Office: (785) 864-9086
> Lawrence, Kansas 66044-3177           FAX: (785) 864-5700
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html


---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From m.okasha at palnet.com  Fri Feb 20 23:38:37 2004
From: m.okasha at palnet.com (Mahmoud K. Okasha)
Date: Sat, 21 Feb 2004 00:38:37 +0200
Subject: [R] R: Including R plots in a Microsoft Word document
References: <005901c3f7c9$d7dd5640$0d00a8c0@okasha><20040220163635.GB26073@pusa.informat.uv.es>
	<40366467.20709@ku.edu>
Message-ID: <001701c3f802$4861d520$32334ed9@okasha>

Hello,

I first would like to thank all of you for your great ideas. However, I
agree with Paul particularly in that the answer is more complicated than
other people make it seem when you have many graphs. I am trying all the
ideas. It seems that all of them work but with some difficulties. I have
Windows 2000 and MS Office 200. It seems to me that the easiest way of
solving the problem is through saving the file in Bmp or Jpeg format and
edit it in a graphic program such as Photoshop then insert it in the file. I
will continue trying all methods to find the easiest.

Best regards
Mahmoud


----- Original Message -----
From: "Paul Johnson" <pauljohn at ku.edu>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, February 20, 2004 9:47 PM
Subject: Re: [R] R: Including R plots in a Microsoft Word document


> I have wrestled with this problem a lot. I use Linux, coauthors use
> Windows, and the eps files I make from R don't work with MS Word.  Well,
> the don't ever have "previews" and they sometimes won't print at all
> when I use CrossOver Office with MS Office 2000 in Linux.  My coauthor
> says he can often wrestle my eps files into word on his system with
> Office 2003.  People keep telling me to use gsview to insert the preview
> panes into eps files, and that does work, but more than one half of the
> time my system creates eps files that look significantly worse than the
> originals.  Sometimes it inserts a blank page at the top of the eps or
> it reshapes a figure.  I don't care enough about MS to try to track that
> down.  It just pisses me off.
>
>
> As a result, I think the answer is more complicated than other people
> make it seem.
>
> I don't think it does any good to output a pdf file because, as  I
> learned yesterday, MS Word users can't import a pdf file into a doc.
>
> Clearly, if you are an MS windows user of R, you can save graphics in
> the windows meta format (wmf)  (or is it enhanced meta format, emf?).
> That will go more or less seamlessly into Word.  If you have a chance to
> boot into Windows, and you really must make an image that works well
> with Word, then you should boot into Windows, run your R in there and
> make the wmf file.
>
> If you are a Linux/Unix user, and you are too proud to use Windows,  the
> problem is much more difficult to deal with.
>
> If you are ABSOLUTELY SURE that your image does not need to be resized
> in any way, you could output from R into a picture type format, such as
> png.  As long as the image does not need to resized in any way, that
> will be fine.  If it is resized, then all bets are off.
>
> I find that the R output to the xfig format is quite good and I can edit
> files in xfig.  You can edit those files, add text, so its very very
> handy.  So right now I'm looking for a good bridge from xfig format to
> Word.  But I just started investigating that.
>
> uaca at alumni.uv.es wrote:
>
> >On Fri, Feb 20, 2004 at 05:54:33PM +0200, Mahmoud K. Okasha wrote:
> >
> >
> >>Greetings List,
> >>
> >>I am conducting some large simulations using R. As a result, I get many
plots but I'm having some trouble with including some of them in a Microsoft
Word document. Can any one tell me the easiest method of having copies of
the R-graphs in the Word documents?
> >>
> >>
> >
> >R can produce at least PostScript, PDF, png, jpeg/jpg
> >
> >see:
> >
> > help(postscript)
> > help(pdf)
> > help(png)
> > help(jpeg)
> >
> >I don't use word, for me the PostScript format (more precisely
Encapsulated
> >PostScript/.eps) is the best/more easy/powerful format if you don't have
thousands of
> >points or lines :-)
> >
> >por instance, to print a simple plot:
> >
> >postscript(file="somefile.eps");
> >
> >plot(whatever);
> >
> >dev.off(); <<---- Important
> >
> >other formats are similar
> >
> >regards
> >
> > Ulisses
> >
> >
> >                Debian GNU/Linux: a dream come true
>
>---------------------------------------------------------------------------
--
> >"Computers are useless. They can only give answers."            Pablo
Picasso
> >
> >Humans are slow, innaccurate, and brilliant.
> >Computers are fast, acurrate, and dumb.
> >Together they are unbeatable
> >
> >---> Visita http://www.valux.org/ para saber acerca de la <---
> >---> Asociaci?n Valenciana de Usuarios de Linux <---
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> >
> >
>
>
> --
> Paul E. Johnson                       email: pauljohn at ku.edu
> Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
> 1541 Lilac Lane, Rm 504
> University of Kansas                  Office: (785) 864-9086
> Lawrence, Kansas 66044-3177           FAX: (785) 864-5700
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>



From andy_liaw at merck.com  Sat Feb 21 00:23:46 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 20 Feb 2004 18:23:46 -0500
Subject: [R] BATCH files
Message-ID: <3A822319EB35174CA3714066D590DCD504AF780F@usrymx25.merck.com>

RTFM: see ?BATCH, or in case you are using Windoze, Help -> FAQ on R for
Windows, click on Q 2.10.

Andy

> From: Christian Landry
> 
> Could someone tell me where I could find some instructions 
> for running R in 
> BATCH mode? Especially regarding the format of the program or 
> command file,
> 
> Thanks a lot
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From Jason.L.Higbee at stls.frb.org  Sat Feb 21 00:31:06 2004
From: Jason.L.Higbee at stls.frb.org (Jason.L.Higbee@stls.frb.org)
Date: Fri, 20 Feb 2004 17:31:06 -0600
Subject: [R] M-Plots in R
Message-ID: <20040220233107.A9D12864ED@p3fed1.frb.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040220/e7906b53/attachment.pl

From itayf at fhcrc.org  Sat Feb 21 00:38:46 2004
From: itayf at fhcrc.org (Itay Furman)
Date: Fri, 20 Feb 2004 15:38:46 -0800 (PST)
Subject: Solved: [R] piece wise application of functions
In-Reply-To: <Pine.SOL.4.58.0402201114420.18530@asteroids.gpcc.itd.umich.edu>
Message-ID: <Pine.LNX.4.44.0402201503200.1587-100000@cezanne.fhcrc.org>


Thanks!  Especially for pointing out the usage of a 'wrapper' 
function in conjunction to lapply. In addition, data 
re-organization was important, too, as you pointed out.

My final solution was slightly different than your proposition.
See below.

	Thanks again,
	Itay


On Fri, 20 Feb 2004, Tom Blackwell wrote:

> If it were my problem, I would re-structure the task around the
> existing capabilities of  lapply().  In particular, I would
> concatenate the three lists of functions, then write a wrapper
> function which takes three arguments:  an index, a list of
> functions and a data set.  Then I would call  lapply()  twice
> to get the result you appear to be asking for.  Here's a rough
> example, untested, which may not work exactly for your situation.
> 
> miss.all <- c(missgp0, missgp1, missgp2)
> wrapper  <- function(i, ff, d)  {ff[[i]](d)}
> result.1 <- unlist(lapply(seq(9), wrapper, miss.all, snps.missgp[["ic"]]))
> result.2 <- unlist(lapply(seq(9), wrapper, miss.all, strs.missgp[["ic"]]))
> gaps     <- c(  #  nine multiples of 1e+6 which describe the nine functions )
> result   <- cbind(gaps=gaps, snps=result.1, strs=result.2)
> 

# Make skeleton d.f. for the results
gaps <- data.frame(gap=paste(c(1, 2, 5), "+06", sep="e")
# Re-organize data :-)
# Each interpolation function will operate on a single row
markers <- ( markers <- cbind(strs.missgp[["ic"]], 
			      snps.missgp[["ic"]]) )[1:3,]
# A slight different definition: makes explicit the application 
# to rows
wrapper <- function(i, ff, d) {ff[[i]](d[i,])}

# Compute. Note the use of sapply()
case0 <- cbind(gaps, t(sapply(seq(3), wrapper, missgp0, 
		markers)))
case1 <- cbind(gaps, t(sapply(seq(3), wrapper, missgp1, 
		markers)))
case2 <- cbind(gaps, t(sapply(seq(3), wrapper, missgp2, 
		markers)))

gaps was a d.f.; therefore, cbind() coerces the result to d.f.
For example:
case0
    gap      strs     snps
1 1e+06 46145.218 374.3882
2 2e+06  2547.841 494.0718
3 5e+06  1372.235 402.9667


> In this case,  result  is a matrix, not a data frame, but you can
> easily convert between the two.
> 

> HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 

I tried to loop over the indices of case and missgp, 0,1,2,
using assign() but some how failed; and really wanted to go on 
with the analysis.

Later, it occured to me that I might have used some wrapper 
function in combination with outer(); and the result would be in 
the diag()onal. That is because what in fact I was looking for 
was an inner prodcut of a vector of functions, with a vector of 
arguments.

	Thanks again,
	Itay

> On Thu, 19 Feb 2004, Itay Furman wrote:
> 
> >
> > Dear all,
> >
> > After struggling for some time with *apply() and eva() without
> > success, I decided to ask for help.
> >
> > I have 3 lists labeled with, each contains 3 different
> > interpolation functions with identical names:
> >
> > > names(missgp0)
> > [1] "spl.1mb" "spl.2mb" "spl.5mb"
> > >
> > > names(missgp1)
> > [1] "spl.1mb" "spl.2mb" "spl.5mb"
> > >
> > > names(missgp2)
> > [1] "spl.1mb" "spl.2mb" "spl.5mb"
> > >
> >
> > (
> > In case it matters the functions accept and return one argument:
> > block.size <- spl.1mb(ic)
> > )
> >
> > Then, I have 2 data frames with identical structure:
> >
> > > snps.missgp
> >   intvl.mb    ic
> > 1    1e+06 0.597
> > 2    2e+06 0.504
> > 3    5e+06 0.327
> > 4    1e+07 0.204
> > >
> >
> > > strs.missgp
> >   intvl.mb      ic
> > 1    1e+06 0.67200
> > 2    2e+06 0.62325
> > 3    5e+06 0.51000
> > 4    1e+07 0.38775
> > >
> >
> > I would like to apply the functions on these data frames
> > piece-wise and create a data frame per function _list_.
> >
> > So I am looking for a final output like this:
> >
> > > case0
> >     gap	 snps	strs
> > 1 1e+06  ..	..
> > 2 2e+06  ..	..
> > 3 5e+06  ..	..
> >
> > Here, case0$snps[1] is, for example, the result of applying the
> > function in  missgp0[1] on the entry snps.missgp$ic[1];
> > and, case0$strs[1] is the result of applying the same function
> > on strs.missgp$ic[1].
> >
> > Then, I want to repeat the whole thing with missgp1,2  instead
> > of missgp0, generating case1,2 data frames.
> >
> > How should I do it?
> >
> >
> > 	Thanks in advance,
> > 	Itay Furman
> >
> > --------------------------------------------------------------------
> > itayf at fhcrc.org			Fred Hutchinson Cancer Research Center
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From JGPorzak at loyaltymatrix.com  Sat Feb 21 00:54:07 2004
From: JGPorzak at loyaltymatrix.com (Jim Porzak)
Date: Fri, 20 Feb 2004 15:54:07 -0800
Subject: [R] Data Analyst Intern position in San Francisco
Message-ID: <5.1.1.6.0.20040220154144.02a07da0@pop3.norton.antivirus>


   We've sent this position out to SF Bay Area schools. Since we have
   standardized on R as our preferred analytics platform it seemed
   appropriate to post here.
   We also have a full time Data Analyst position open. Search for
   "Loyalty Matrix" on [1]www.craigslist.org   Jim Porzak
   Director of Analytics
   Loyalty Matrix, Inc.
   [2]www.LoyaltyMatrix.com
   ------------------------
   Data Analyst Intern
   Loyalty Matrix is a successful & profitable two-year-old start-up   company based in downtown San Francisco. We are seeking a bright,   organized, and motivated team player who appreciates the challenges
   and   Primary Responsibilities:
   ?       Brainstorm with   OLAP models on customer   ?       Conduct customer   statistical models
   ?       Perform gap   customer intelligence
   ?       Report directly   Qualifications:
   ?       Graduating   Science, Engineering, Math   ?       Basic knowledge   techniques
   ?       Intermediate   Preferred Qualifications:
   ?       Knowledge of   ?       Experience doing   ?       Experience in   ?       Microsoft SQL   What You Will Learn:
   ?       Statistical   ?       OLAP concepts   ?       Microsoft SQL   ?       Implementing   techniques, including audience   extractions and manipulation, and program   ?       CRM systems   ?       Reporting tools   ?       ETL (Extraction,   Please note that this is a three-month internship that may lead to a   permanent position. Submit your resume to hr at loyaltymatrix.com with   "[R] Internship"  in the subject heading.
   ---------------------

References

   1. 3D"http://www.craigslist.org/"
   2. 3D"http://www.loyaltymatrix.com/"

From ggrothendieck at myway.com  Sat Feb 21 01:04:11 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 20 Feb 2004 19:04:11 -0500 (EST)
Subject: [R] R: Including R plots in a Microsoft Word document
Message-ID: <20040221000411.C14FC397E@mprdmxin.myway.com>



Perhaps some additional explanation is in order.  There are 
two basic classes of format:

- vector graphics such as windows metafile (wmf) and svg where 
the actual structure of the drawing is stored.    Editing these 
can be done with no loss of resolution and you can access  
the individual components of the plot, the titles, the points, 
etc. directly.

- bitmapped (also called raster) graphics such as jpg and png
where the drawing is stored as a sequence of pixels.  You can't
access the individual objects in a plot with raster graphics since
the image is just a set of pixels.  Resizing involves a loss of
resolution.

Windows metafiles are the preferred format for Word.  They
are vector graphics, not raster, and they can be edited from
within Word directly -- you don't need another editing program.
This should be much easier than using bmp or jpg together with
Photoshop.

You can either generate wmf files by right clicking the plot and
copying to the clipboard or using R code like this:

win.metafile("/myfile.wmf")
plot(1:10)
dev.off()

followed by   Insert | Picture | File   in Word.

In Paul's case he is generating his images in Linux, where I gather
Windows metafiles are not available, but in your case everything
is on Windows so you should not have that problem.

---
Date:   Sat, 21 Feb 2004 00:38:37 +0200 
From:   Mahmoud K. Okasha <m.okasha at palnet.com>
[ Add to Address Book | Block Address | Report as Spam ] 
To:   Paul Johnson <pauljohn at ku.edu>, <r-help at stat.math.ethz.ch> 
Subject:   Re: [R] R: Including R plots in a Microsoft Word document 

 
Hello,

I first would like to thank all of you for your great ideas. However, I
agree with Paul particularly in that the answer is more complicated than
other people make it seem when you have many graphs. I am trying all the
ideas. It seems that all of them work but with some difficulties. I have
Windows 2000 and MS Office 200. It seems to me that the easiest way of
solving the problem is through saving the file in Bmp or Jpeg format and
edit it in a graphic program such as Photoshop then insert it in the file. I
will continue trying all methods to find the easiest.

Best regards
Mahmoud


----- Original Message -----
From: "Paul Johnson" <pauljohn at ku.edu>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, February 20, 2004 9:47 PM
Subject: Re: [R] R: Including R plots in a Microsoft Word document


> I have wrestled with this problem a lot. I use Linux, coauthors use
> Windows, and the eps files I make from R don't work with MS Word. Well,
> the don't ever have "previews" and they sometimes won't print at all
> when I use CrossOver Office with MS Office 2000 in Linux. My coauthor
> says he can often wrestle my eps files into word on his system with
> Office 2003. People keep telling me to use gsview to insert the preview
> panes into eps files, and that does work, but more than one half of the
> time my system creates eps files that look significantly worse than the
> originals. Sometimes it inserts a blank page at the top of the eps or
> it reshapes a figure. I don't care enough about MS to try to track that
> down. It just pisses me off.
>
>
> As a result, I think the answer is more complicated than other people
> make it seem.
>
> I don't think it does any good to output a pdf file because, as I
> learned yesterday, MS Word users can't import a pdf file into a doc.
>
> Clearly, if you are an MS windows user of R, you can save graphics in
> the windows meta format (wmf) (or is it enhanced meta format, emf?).
> That will go more or less seamlessly into Word. If you have a chance to
> boot into Windows, and you really must make an image that works well
> with Word, then you should boot into Windows, run your R in there and
> make the wmf file.
>
> If you are a Linux/Unix user, and you are too proud to use Windows, the
> problem is much more difficult to deal with.
>
> If you are ABSOLUTELY SURE that your image does not need to be resized
> in any way, you could output from R into a picture type format, such as
> png. As long as the image does not need to resized in any way, that
> will be fine. If it is resized, then all bets are off.
>
> I find that the R output to the xfig format is quite good and I can edit
> files in xfig. You can edit those files, add text, so its very very
> handy. So right now I'm looking for a good bridge from xfig format to
> Word. But I just started investigating that.
>
> uaca at alumni.uv.es wrote:
>
> >On Fri, Feb 20, 2004 at 05:54:33PM +0200, Mahmoud K. Okasha wrote:
> >
> >
> >>Greetings List,
> >>
> >>I am conducting some large simulations using R. As a result, I get many
plots but I'm having some trouble with including some of them in a Microsoft
Word document. Can any one tell me the easiest method of having copies of
the R-graphs in the Word documents?
> >>
> >>
> >
> >R can produce at least PostScript, PDF, png, jpeg/jpg
> >
> >see:
> >
> > help(postscript)
> > help(pdf)
> > help(png)
> > help(jpeg)
> >
> >I don't use word, for me the PostScript format (more precisely
Encapsulated
> >PostScript/.eps) is the best/more easy/powerful format if you don't have
thousands of
> >points or lines :-)
> >
> >por instance, to print a simple plot:
> >
> >postscript(file="somefile.eps");
> >
> >plot(whatever);
> >
> >dev.off(); <<---- Important
> >
> >other formats are similar
> >
> >regards
> >
> > Ulisses
> >
> >
> > Debian GNU/Linux: a dream come true
>
>---------------------------------------------------------------------------
--
> >"Computers are useless. They can only give answers." Pablo
Picasso
> >
> >Humans are slow, innaccurate, and brilliant.
> >Computers are fast, acurrate, and dumb.
> >Together they are unbeatable
> >
> >---> Visita http://www.valux.org/ para saber acerca de la <---
> >---> Asociacin Valenciana de Usuarios de Linux <---
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> >
> >
>
>
> --
> Paul E. Johnson email: pauljohn at ku.edu
> Dept. of Political Science http://lark.cc.ku.edu/~pauljohn
> 1541 Lilac Lane, Rm 504
> University of Kansas Office: (785) 864-9086
> Lawrence, Kansas 66044-3177 FAX: (785) 864-5700
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From m.okasha at palnet.com  Sat Feb 21 01:15:15 2004
From: m.okasha at palnet.com (Mahmoud K. Okasha)
Date: Sat, 21 Feb 2004 02:15:15 +0200
Subject: [R] R: Including R plots in a Microsoft Word document
References: <20040221000411.C14FC397E@mprdmxin.myway.com>
Message-ID: <004d01c3f80f$c91377c0$32334ed9@okasha>

Greetings,

Thank you Gabor for your great explanation. I feel ok with it.

Best regards..
Mahmoud
.
----- Original Message -----
From: "Gabor Grothendieck" <ggrothendieck at myway.com>
To: <m.okasha at palnet.com>; <pauljohn at ku.edu>; <r-help at stat.math.ethz.ch>
Sent: Saturday, February 21, 2004 2:04 AM
Subject: Re: [R] R: Including R plots in a Microsoft Word document


>
>
> Perhaps some additional explanation is in order.  There are
> two basic classes of format:
>
> - vector graphics such as windows metafile (wmf) and svg where
> the actual structure of the drawing is stored.    Editing these
> can be done with no loss of resolution and you can access
> the individual components of the plot, the titles, the points,
> etc. directly.
>
> - bitmapped (also called raster) graphics such as jpg and png
> where the drawing is stored as a sequence of pixels.  You can't
> access the individual objects in a plot with raster graphics since
> the image is just a set of pixels.  Resizing involves a loss of
> resolution.
>
> Windows metafiles are the preferred format for Word.  They
> are vector graphics, not raster, and they can be edited from
> within Word directly -- you don't need another editing program.
> This should be much easier than using bmp or jpg together with
> Photoshop.
>
> You can either generate wmf files by right clicking the plot and
> copying to the clipboard or using R code like this:
>
> win.metafile("/myfile.wmf")
> plot(1:10)
> dev.off()
>
> followed by   Insert | Picture | File   in Word.
>
> In Paul's case he is generating his images in Linux, where I gather
> Windows metafiles are not available, but in your case everything
> is on Windows so you should not have that problem.
>
> ---
> Date:   Sat, 21 Feb 2004 00:38:37 +0200
> From:   Mahmoud K. Okasha <m.okasha at palnet.com>
> [ Add to Address Book | Block Address | Report as Spam ]
> To:   Paul Johnson <pauljohn at ku.edu>, <r-help at stat.math.ethz.ch>
> Subject:   Re: [R] R: Including R plots in a Microsoft Word document
>
>
> Hello,
>
> I first would like to thank all of you for your great ideas. However, I
> agree with Paul particularly in that the answer is more complicated than
> other people make it seem when you have many graphs. I am trying all the
> ideas. It seems that all of them work but with some difficulties. I have
> Windows 2000 and MS Office 200. It seems to me that the easiest way of
> solving the problem is through saving the file in Bmp or Jpeg format and
> edit it in a graphic program such as Photoshop then insert it in the file.
I
> will continue trying all methods to find the easiest.
>
> Best regards
> Mahmoud
>
>
> ----- Original Message -----
> From: "Paul Johnson" <pauljohn at ku.edu>
> To: <r-help at stat.math.ethz.ch>
> Sent: Friday, February 20, 2004 9:47 PM
> Subject: Re: [R] R: Including R plots in a Microsoft Word document
>
>
> > I have wrestled with this problem a lot. I use Linux, coauthors use
> > Windows, and the eps files I make from R don't work with MS Word. Well,
> > the don't ever have "previews" and they sometimes won't print at all
> > when I use CrossOver Office with MS Office 2000 in Linux. My coauthor
> > says he can often wrestle my eps files into word on his system with
> > Office 2003. People keep telling me to use gsview to insert the preview
> > panes into eps files, and that does work, but more than one half of the
> > time my system creates eps files that look significantly worse than the
> > originals. Sometimes it inserts a blank page at the top of the eps or
> > it reshapes a figure. I don't care enough about MS to try to track that
> > down. It just pisses me off.
> >
> >
> > As a result, I think the answer is more complicated than other people
> > make it seem.
> >
> > I don't think it does any good to output a pdf file because, as I
> > learned yesterday, MS Word users can't import a pdf file into a doc.
> >
> > Clearly, if you are an MS windows user of R, you can save graphics in
> > the windows meta format (wmf) (or is it enhanced meta format, emf?).
> > That will go more or less seamlessly into Word. If you have a chance to
> > boot into Windows, and you really must make an image that works well
> > with Word, then you should boot into Windows, run your R in there and
> > make the wmf file.
> >
> > If you are a Linux/Unix user, and you are too proud to use Windows, the
> > problem is much more difficult to deal with.
> >
> > If you are ABSOLUTELY SURE that your image does not need to be resized
> > in any way, you could output from R into a picture type format, such as
> > png. As long as the image does not need to resized in any way, that
> > will be fine. If it is resized, then all bets are off.
> >
> > I find that the R output to the xfig format is quite good and I can edit
> > files in xfig. You can edit those files, add text, so its very very
> > handy. So right now I'm looking for a good bridge from xfig format to
> > Word. But I just started investigating that.
> >
> > uaca at alumni.uv.es wrote:
> >
> > >On Fri, Feb 20, 2004 at 05:54:33PM +0200, Mahmoud K. Okasha wrote:
> > >
> > >
> > >>Greetings List,
> > >>
> > >>I am conducting some large simulations using R. As a result, I get
many
> plots but I'm having some trouble with including some of them in a
Microsoft
> Word document. Can any one tell me the easiest method of having copies of
> the R-graphs in the Word documents?
> > >>
> > >>
> > >
> > >R can produce at least PostScript, PDF, png, jpeg/jpg
> > >
> > >see:
> > >
> > > help(postscript)
> > > help(pdf)
> > > help(png)
> > > help(jpeg)
> > >
> > >I don't use word, for me the PostScript format (more precisely
> Encapsulated
> > >PostScript/.eps) is the best/more easy/powerful format if you don't
have
> thousands of
> > >points or lines :-)
> > >
> > >por instance, to print a simple plot:
> > >
> > >postscript(file="somefile.eps");
> > >
> > >plot(whatever);
> > >
> > >dev.off(); <<---- Important
> > >
> > >other formats are similar
> > >
> > >regards
> > >
> > > Ulisses
> > >
> > >
> > > Debian GNU/Linux: a dream come true
> >
>
>---------------------------------------------------------------------------
> --
> > >"Computers are useless. They can only give answers." Pablo
> Picasso
> > >
> > >Humans are slow, innaccurate, and brilliant.
> > >Computers are fast, acurrate, and dumb.
> > >Together they are unbeatable
> > >
> > >---> Visita http://www.valux.org/ para saber acerca de la <---
> > >---> Asociaci?n Valenciana de Usuarios de Linux <---
> > >
> > >______________________________________________
> > >R-help at stat.math.ethz.ch mailing list
> > >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> > >
> > >
> >
> >
> > --
> > Paul E. Johnson email: pauljohn at ku.edu
> > Dept. of Political Science http://lark.cc.ku.edu/~pauljohn
> > 1541 Lilac Lane, Rm 504
> > University of Kansas Office: (785) 864-9086
> > Lawrence, Kansas 66044-3177 FAX: (785) 864-5700
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
>
>
> _______________________________________________
> No banners. No pop-ups. No kidding.
> Introducing My Way - http://www.myway.com
>
>



From greenberg at ucdavis.edu  Sat Feb 21 03:55:51 2004
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Fri, 20 Feb 2004 18:55:51 -0800
Subject: [R] Stratified random sampling in R?
Message-ID: <BC5C08B7.19C71%greenberg@ucdavis.edu>

Is there an easy way to do a stratified random sampling based on a factor
column in R?  E.g. I want to extract a random 10% of the data from dataset
for each class (so each class may have a different number of entries,
depending on its size).  On a related note, if this is easily doable, is
there an easy way to extract TWO non-overlapping strat. random samples
datasets (e.g. If I want to have a training and test dataset).  Thanks!

--j

-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From ggrothendieck at myway.com  Sat Feb 21 05:30:12 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 20 Feb 2004 23:30:12 -0500 (EST)
Subject: [R] Stratified random sampling in R?
Message-ID: <20040221043012.102A2399B@mprdmxin.myway.com>



Try this.  ptrain and ptest and proportions in the training
and test samples.  The next line generates a random test
vector of factors, f, for testing purposes.


ptrain <- 0.3; ptest <- 0.2
set.seed(1); f <- cut(runif(100),3,lab=F)

first <- function(x, p) x[seq( ceiling(p * length(x) ) )]

perms <- lapply(split( seq(f), f ), sample)

train <- lapply( perms, function(x) first(x, ptrain) )
test <- lapply( perms, function(x) first(rev(x), ptest) )


first takes a vector and a proportion and returns that proportion
of elements from the beginning of the vector.  Assuming p > 0
it always returns at least one.   perms is a random 
permutation of the cases at each level.  Finally, in the last
two statements, we take elements off the beginning of 
the permutations for our training set and off the end for 
our test set.

At the end, train and test are each lists of vectors of case
numbers representing the training and testing samples.

---
Date:   Fri, 20 Feb 2004 18:55:51 -0800 
From:   Jonathan Greenberg <greenberg at ucdavis.edu>
To:   R-help <r-help at stat.math.ethz.ch> 
Subject:   [R] Stratified random sampling in R? 

 
Is there an easy way to do a stratified random sampling based on a factor
column in R? E.g. I want to extract a random 10% of the data from dataset
for each class (so each class may have a different number of entries,
depending on its size). On a related note, if this is easily doable, is
there an easy way to extract TWO non-overlapping strat. random samples
datasets (e.g. If I want to have a training and test dataset). Thanks!

-- 
Jonathan Greenberg
Graduate Group in Ecology, U.C. Davis
http://www.cstars.ucdavis.edu/~jongreen
http://www.cstars.ucdavis.edu
AIM: jgrn307 or jgrn3007
MSN: jgrn307 at msn.com or jgrn3007 at msn.com



From copellifulvio at yahoo.it  Sat Feb 21 11:07:00 2004
From: copellifulvio at yahoo.it (=?iso-8859-1?q?Fulvio=20Copex?=)
Date: Sat, 21 Feb 2004 11:07:00 +0100 (CET)
Subject: [R] saving variables created by functions in the workspace 
Message-ID: <20040221100700.32797.qmail@web25208.mail.ukl.yahoo.com>

Hello ,

just a simple question from  a beginner:

I write the function:
plotsinx <- function()
{
x<-seq(0,2*pi,0.01)
sinx<-sin(x)
plot(sinx)
}
I recall it:
plotsinx()
and the plot works properly.
but then in the workspace if I want to look at the
values of sinx the following error is displayed:
Error: Object "sinx" not found.
How to save the variables created by the function on
the workspace?
Thank you very much, it seems to be very trivial...
Copex.



______________________________________________________________________

http://it.yahoo.com/mail_it/foot/?http://it.mail.yahoo.com/



From copellifulvio at yahoo.it  Sat Feb 21 11:15:55 2004
From: copellifulvio at yahoo.it (=?iso-8859-1?q?Fulvio=20Copex?=)
Date: Sat, 21 Feb 2004 11:15:55 +0100 (CET)
Subject: [R] RE:Including R plots in a Microsoft Word document
Message-ID: <20040221101555.99751.qmail@web25204.mail.ukl.yahoo.com>

Sorry Gabor,
in which package can I found the function:
win.metafile() ?

______________________________________________________________________

http://it.yahoo.com/mail_it/foot/?http://it.mail.yahoo.com/



From copellifulvio at yahoo.it  Sat Feb 21 11:16:10 2004
From: copellifulvio at yahoo.it (=?iso-8859-1?q?Fulvio=20Copex?=)
Date: Sat, 21 Feb 2004 11:16:10 +0100 (CET)
Subject: [R] RE:Including R plots in a Microsoft Word document
Message-ID: <20040221101610.99824.qmail@web25204.mail.ukl.yahoo.com>

Sorry Gabor,
in which package can I found the function:
win.metafile() ?

______________________________________________________________________

http://it.yahoo.com/mail_it/foot/?http://it.mail.yahoo.com/



From ligges at statistik.uni-dortmund.de  Sat Feb 21 11:53:27 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 21 Feb 2004 11:53:27 +0100
Subject: [R] saving variables created by functions in the workspace
References: <20040221100700.32797.qmail@web25208.mail.ukl.yahoo.com>
Message-ID: <403738A7.563BEC26@statistik.uni-dortmund.de>



Fulvio Copex wrote:
> 
> Hello ,
> 
> just a simple question from  a beginner:
> 
> I write the function:
> plotsinx <- function()
> {
> x<-seq(0,2*pi,0.01)
> sinx<-sin(x)
> plot(sinx)
> }
> I recall it:
> plotsinx()
> and the plot works properly.
> but then in the workspace if I want to look at the
> values of sinx the following error is displayed:
> Error: Object "sinx" not found.
> How to save the variables created by the function on
> the workspace?
> Thank you very much, it seems to be very trivial...
> Copex.

Please read the manual "An Introduction to R", in particular Chapter 10
and Sectoin 10.5, and the help page help("function").

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Sat Feb 21 11:54:09 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 21 Feb 2004 11:54:09 +0100
Subject: [R] RE:Including R plots in a Microsoft Word document
References: <20040221101610.99824.qmail@web25204.mail.ukl.yahoo.com>
Message-ID: <403738D1.12939E87@statistik.uni-dortmund.de>



Fulvio Copex wrote:
> 
> Sorry Gabor,
> in which package can I found the function:
> win.metafile() ?

It's available in the base package of R for Windows.

Uwe Ligges



From g.death at aims.gov.au  Tue Feb 17 19:28:22 2004
From: g.death at aims.gov.au (Glenn Death)
Date: Tue, 17 Feb 2004 10:28:22 -0800
Subject: [R] [R-pkgs] New package -- mvpart
Message-ID: <5.1.1.6.2.20040217102016.01d808f8@mail.aims.gov.au>

The package mvpart is now available.
mvpart includes partitioning based on (1) multivariate numeric responses and
(2) dissimilarity matrices.

The package mvpart is a modification of rpart --
  -- authors of original: Terry M Therneau and Beth Atkinson 
<atkinson at mayo.edu>, and
  R port of rpart Brian Ripley <ripley at stats.ox.ac.uk>.
Includes some modified routines from vegan -- Jari Oksanen 
<jari.oksanen at oulu.fi>

Thanks and credit to all the above.

Modifications of rpart to mvpart by Glenn De'ath <g.death at aims.gov.au>.

It was not possible to simply build a separate packge which required RPART due
to the modifications to the rpart C-code necessary to include the 2 new
partitioning methods.

As few changes as possible have been made to rpart.

In addition to the changes in the C-code, the following changes and 
additions in
R-functions have been made.

(1) A wrapper function for rpart called mvpart supports selection of trees 
by x-validation,
         interactive display, printing of results etc.

(2) Some multivariate methods to deal with representation and 
interpretation of multivariate
         partitioning objects have been added. These include PCA plots and 
tree-cluster comparisons.

(3) Methods for calculating increased forms of dissimilarities and for 
scaling matrices
         have been added. These are designed in particluar for community 
ecology.

(3) text.rpart has been modified to include graphical annotation of nodes.

Glenn De'ath


===============================================
Glenn De'ath
Australian Institute of Marine Science
PMB No 3, Townsville Mail Centre
Qld 4810, Australia
Ph: +61-7-4753-4314 or  +61-7-4758-1979

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From Ted.Harding at nessie.mcc.ac.uk  Sat Feb 21 13:54:13 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 21 Feb 2004 12:54:13 -0000 (GMT)
Subject: [R] R/SigmaStat
Message-ID: <XFMail.040221125413.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

I have run a linear regression analysis in R on some data for which
I also have a printout of a similar analysis carried out by someone else.

The results (intercept, coefficient, SEs etc.) differ somewhat, though
not greatly.

>From the printout of the other analysis, it seems that it may have
been produced by software called SigmaStat.

(I'm going by the clue

 "Power of performed test with alpha = 0.0500: 1.000"

 in the printout, which on a google search throws up a lot of SigmaStat
 and sometimes SigmaPlot; the web pages illustrate tabulations by
 SigmaStat which are very similar in layout to the printout I have)

I'm not familiar with SigmaStat. I'm a bit concerned by the numerical
discrepancies (and somewhat puzzled by the "1.000" power against an
unstated alternative!).

If any of you have experience with SigmaStat, especially in comparison
with R, I would be interested in your comments. If you would prefer to
email me off-list, please feel free to do so!

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 21-Feb-04                                       Time: 12:54:13
------------------------------ XFMail ------------------------------



From maechler at stat.math.ethz.ch  Sat Feb 21 14:35:16 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 21 Feb 2004 14:35:16 +0100
Subject: [R] references on cluster analysis
In-Reply-To: <Pine.LNX.4.58.0402071927360.819@bayes.speech.kth.se>
References: <Pine.LNX.4.58.0402071927360.819@bayes.speech.kth.se>
Message-ID: <16439.24212.848934.835200@gargle.gargle.HOWL>

Back from my vacation, I haven't seen an R-help answer on this
  (Christian, where have you been ? ;-)

>>>>> "GiampS" == Giampiero Salvi <giampi at speech.kth.se>
>>>>>     on Sat, 7 Feb 2004 23:40:36 +0100 (CET) writes:

    GiampS> Hi all, I'm doing a study on predicting the "true"
    GiampS> number of clusters in a hierarchical clustering
    GiampS> scheme. My main reference is at the moment

    GiampS> Milligan GW and Cooper MC (1985) "An examination of
    GiampS> procedures for determining the number of clusters in
    GiampS> a data set" Psychometrika vol 50 no 2 pp 159-179

    GiampS> and all the references included in that paper.

(not available to me)

    GiampS> I'm planning to perform a similar comparison on a
    GiampS> number of indexes, but on a much larger data set (in
    GiampS> the order of 3000 points), and with a much higher
    GiampS> "true" number of clusters (in the order of some
    GiampS> hundreds), to see if the properties of the indexes
    GiampS> scale accordingly.

    GiampS> I was wondering if the set of indexes described in
    GiampS> the reference are still "state of the art" (most of
    GiampS> them were introduced in the '60s and '70s), or if
    GiampS> there are new indexes and methods I could include in
    GiampS> my study. I would really appreciate if you could
    GiampS> point me to some newer references addressing this problem.

Gordon's 2nd edition,

  author =	 {A. D. Gordon},
  title = 	 {Classification, 2nd Edition},
  publisher = 	 {Chappman \& Hall/CRC},
  year = 	 1999,
  series =	 {Monographs on Statistics and Applied Probability 82},
  edition =	 {2nd edition}

has a whole chapter (one of the last ones in the book) on this.

R's cluster package has a generic silhouette() function (with 2 methods),
and plot.silhouette() method --- all are improvements from
Kaufman & Rousseeuw's original code.

A recent research paper using "CLEST" (Fridyland & Dudoit),
mentioning "GAP" (Tibshirani) etc etc  still find silhouette
among the best "indices" for determining the number of clusters.

A student's (master) thesis here seems to point in the same
direction.

    GiampS> I also read Milligan's chapter in the book
    GiampS> "Clustering and Classification" from 1995, 
(which book? author?)

    GiampS> but didn't find information on this subject that wasn't
    GiampS> included in the previous paper.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ggrothendieck at myway.com  Sat Feb 21 14:47:54 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 21 Feb 2004 08:47:54 -0500 (EST)
Subject: [R] saving variables created by functions in the workspace 
Message-ID: <20040221134754.1ED8839AA@mprdmxin.myway.com>



sinx is local to your function so it is only known within
the function, not outside it.  The reason its like that is
to promote modularity.

You can do one of the following:

1. Return it explicitly from your function:
       plotsinx <- function(x) { sinx <- sin(x); plot(sinx); sinx }
Now call it like this:
       sinx <- plotsinx(x) 

2. Use assign and explicitly assign it in the global   
environment rather than the local environment of the function:       
   plotsinx <- function(x) { 
       assign("sinx",sin(x),.GlobalEnv)
       plot(sinx)
    }
See ?assign

3. Use <<- as in:
   plotsinx <- function(x) { 
       sinx <- sin(x)
       plot(sinx)
    }
If you use this one be sure that you don't nest the 
definition of plotsinx in another function since it actually
searches through the environments of the definition's
parents.  See ?"<<-"

If you just want to look at it but not manipulate it outside
of the function you could try these:

4. Use print.   See ?print

   plotsinx <- function(x) { 
       sinx <- sin(x)
       print(sinx)
       plot(sinx)
    }


5. Use debug
     debug(plotsinx)
   Now when you run the function you can step through it line
   by line displaying each of the local variables if you like.
   See ?debug

Date:   Sat, 21 Feb 2004 11:07:00 +0100 (CET) 
From:   =?iso-8859-1?q?Fulvio=20Copex?= <copellifulvio at yahoo.it>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] saving variables created by functions in the workspace  

 
Hello ,

just a simple question from a beginner:

I write the function:
plotsinx <- function()
{
x<-seq(0,2*pi,0.01)
sinx<-sin(x)
plot(sinx)
}
I recall it:
plotsinx()
and the plot works properly.
but then in the workspace if I want to look at the
values of sinx the following error is displayed:
Error: Object "sinx" not found.
How to save the variables created by the function on
the workspace?
Thank you very much, it seems to be very trivial...
Copex.



From rbaer at atsu.edu  Sat Feb 21 15:41:37 2004
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Sat, 21 Feb 2004 08:41:37 -0600
Subject: [R] RE:Including R plots in a Microsoft Word document
References: <20040221101610.99824.qmail@web25204.mail.ukl.yahoo.com>
Message-ID: <00c401c3f888$d013dff0$6401a8c0@meadow>

For documentation type: ?win.metafile

It is in the base package with the following layout:
  win.metafile(filename = "", width = 7, height = 7, pointsize = 12)

Rob
----- Original Message ----- 
From: "Fulvio Copex" <copellifulvio at yahoo.it>
To: <ggrothendieck at myway.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Saturday, February 21, 2004 4:16 AM
Subject: [R] RE:Including R plots in a Microsoft Word document


> Sorry Gabor,
> in which package can I found the function:
> win.metafile() ?
>
> ______________________________________________________________________
>
> http://it.yahoo.com/mail_it/foot/?http://it.mail.yahoo.com/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From ggrothendieck at myway.com  Sat Feb 21 17:06:22 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 21 Feb 2004 11:06:22 -0500 (EST)
Subject: [R] saving variables created by functions in the workspace 
Message-ID: <20040221160622.D1E8839B2@mprdmxin.myway.com>


[There was an error in #3.  I had omitted the <<-.  Here it 
is again. 


sinx is local to your function so it is only known within
the function, not outside it. The reason its like that is
to promote modularity.

You can do one of the following:

1. Return it explicitly from your function:
plotsinx <- function(x) { sinx <- sin(x); plot(sinx); sinx }
Now call it like this:
sinx <- plotsinx(x) 

2. Use assign and explicitly assign it in the global 
environment rather than the local environment of the function: 
   plotsinx <- function(x) { 
      assign("sinx",sin(x),.GlobalEnv)
      plot(sinx)
    }
See ?assign

3. Use <<- as in:
   plotsinx <- function(x) { 
      sinx <<- sin(x)
      plot(sinx)
    }
If you use this one be sure that you don't nest the 
definition of plotsinx in another function since it actually
searches through the environments of the definition's
parents. See ?"<<-"

If you just want to look at it but not manipulate it outside
of the function you could try these:

4. Use print. See ?print

   plotsinx <- function(x) { 
      sinx <- sin(x)
      print(sinx)
      plot(sinx)
   }


5. Use debug
     debug(plotsinx)
Now when you run the function you can step through it line
by line displaying each of the local variables if you like.
See ?debug

Date: Sat, 21 Feb 2004 11:07:00 +0100 (CET) 
From: =?iso-8859-1?q?Fulvio=20Copex?= <copellifulvio at yahoo.it>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] saving variables created by functions in the workspace 


Hello ,

just a simple question from a beginner:

I write the function:
plotsinx <- function()
{
x<-seq(0,2*pi,0.01)
sinx<-sin(x)
plot(sinx)
}
I recall it:
plotsinx()
and the plot works properly.
but then in the workspace if I want to look at the
values of sinx the following error is displayed:
Error: Object "sinx" not found.
How to save the variables created by the function on
the workspace?
Thank you very much, it seems to be very trivial...
Copex.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

 
 
 
    As AttachmentAs Inline Text Move to Folder----- Folders ------InboxDraftsSentTrashBulk Mail---- My Folders ----RRcomRtmpSaved
 
 
< Prev Next >   Back to Inbox Print View  Full Header 
 
 



    
 
 




Make My Way Your Home Page  |  Spread the Word

My Settings: Overview | Search | Email | Chat | Portfolio | Calendar | Groups | Profile 
 

IMPORTANT: We do not present our users with pop-ups, banners or any other non-text advertising. Nor do we send email
to our users. If you see or receive one of these items, it is coming from an outside source, either as a result of something you
have previously downloaded or as an "exit" pop-up from the site you just visited. It is not coming from our site.

Privacy Policy   Terms of Service   Partner with Us   Our Mission   Sign In   Sign Out   Help Center

 2002-2004 My Way



From zhuw at mail.smu.edu  Sun Feb 22 05:54:04 2004
From: zhuw at mail.smu.edu (zhu wang)
Date: 21 Feb 2004 22:54:04 -0600
Subject: [R] butterworth filter code?
In-Reply-To: <200402211104.i1LB4Ogr004025@hypatia.math.ethz.ch>
References: <200402211104.i1LB4Ogr004025@hypatia.math.ethz.ch>
Message-ID: <1077425644.2044.2.camel@zwang.stat.smu.edu>

Hello,

Does anybody have butterworth filter code in R?

Thanks,

-- 
Zhu Wang

Statistical Science Department
Southern Methodist University
Dallas, TX 75275-0332
Phone: (214)768-2453
Fax: (214)768-4035
Email: zhuw at mail.smu.edu



From sluque at mun.ca  Sun Feb 22 06:23:45 2004
From: sluque at mun.ca (Sebastian Luque)
Date: Sat, 21 Feb 2004 23:23:45 -0600
Subject: [R] nested loop
Message-ID: <40383CE1.6050707@mun.ca>

Hi all,

Does anybody know whether one can nest an 'if' statement in a 'for' 
loop. According to the results of my code, the for loop is performed 
first, but I'm not sure I got something else wrong with my code. I'm 
trying to perform the if statement for each step of the for loop. Thanks 
in advance.

Best regards,
Sebastian



From gmpowers at terra.com.br  Sun Feb 22 07:42:09 2004
From: gmpowers at terra.com.br (Graciliano M. P.)
Date: Sun, 22 Feb 2004 03:42:09 -0300
Subject: [R] New Perl module Statistics::R
References: <4035A7C0.2020303@math2.org>
	<20040221164421.GE7385@chrome.sixears.co.uk>
Message-ID: <004201c3f90e$febccbb0$098cb0c8@main>

I have released the new module Statistics::R and need some feedback of it's
status.
This will permit the control of the the R (R-project) interpreter through
Perl in different architectures and OS.

You can for example, start only one instance of the R interpreter and have
different Perl process accessing it. What will save the initiation time of R
and memory.

Soo, I will appreciate if some one can test it in different OS. Tested with
Win32 and Linux.

http://search.cpan.org/~gmpassos/Statistics-R-0.01/

Thanks in advance.

Regards,
Graciliano M. P.



From ggrothendieck at myway.com  Sun Feb 22 13:04:26 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 22 Feb 2004 07:04:26 -0500 (EST)
Subject: [R] nested loop
Message-ID: <20040222120426.C5C4139B0@mprdmxin.myway.com>


Here is an example:

> for(i in 1:10) if (i %% 2) print(i) else print("even")
[1] 1
[1] "even"
[1] 3
[1] "even"
[1] 5
[1] "even"
[1] 7
[1] "even"
[1] 9
[1] "even"


Date:   Sat, 21 Feb 2004 23:23:45 -0600 
From:   Sebastian Luque <sluque at mun.ca>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] nested loop 

 
Hi all,

Does anybody know whether one can nest an 'if' statement in a 'for' 
loop. According to the results of my code, the for loop is performed 
first, but I'm not sure I got something else wrong with my code. I'm 
trying to perform the if statement for each step of the for loop. Thanks 
in advance.

Best regards,
Sebastian

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

 
 
 
    As AttachmentAs Inline Text Move to Folder----- Folders ------InboxDraftsSentTrashBulk Mail---- My Folders ----RRcomRtmpSaved
 
 
< Prev Next >   Back to Inbox Print View  Full Header 
 
 



    
 
 




Make My Way Your Home Page  |  Spread the Word

My Settings: Overview | Search | Email | Chat | Portfolio | Calendar | Groups | Profile 
 

IMPORTANT: We do not present our users with pop-ups, banners or any other non-text advertising. Nor do we send email
to our users. If you see or receive one of these items, it is coming from an outside source, either as a result of something you
have previously downloaded or as an "exit" pop-up from the site you just visited. It is not coming from our site.

Privacy Policy   Terms of Service   Partner with Us   Our Mission   Sign In   Sign Out   Help Center

 2002-2004 My Way



From dmurdoch at pair.com  Sun Feb 22 13:10:16 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 22 Feb 2004 07:10:16 -0500
Subject: [R] nested loop
In-Reply-To: <40383CE1.6050707@mun.ca>
References: <40383CE1.6050707@mun.ca>
Message-ID: <7p6h30lmelj6262e0qpbvo6bckppugaj1c@4ax.com>

On Sat, 21 Feb 2004 23:23:45 -0600, you wrote:

>Hi all,
>
>Does anybody know whether one can nest an 'if' statement in a 'for' 
>loop. According to the results of my code, the for loop is performed 
>first, but I'm not sure I got something else wrong with my code. I'm 
>trying to perform the if statement for each step of the for loop. Thanks 
>in advance.

Yes, no problem:

> for (i in 1:10) {
+ if (i %% 2 == 0) cat(i, ' is even!\n')
+ }
2  is even!
4  is even!
6  is even!
8  is even!
10  is even!

If you leave off the braces ("{ }"), my example will still work, but
multi-line examples won't:  only the first line will be repeated in
the for loop.

Duncan Murdoch



From ajayshah at mayin.org  Sun Feb 22 16:43:37 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Sun, 22 Feb 2004 21:13:37 +0530
Subject: [R] R: Including R plots in a Microsoft Word document
Message-ID: <20040222154337.GA21980@igidr.ac.in>

It was pointed out that while 

win.metafile("/myfile.wmf")

is useful, it only works on windows.

Here's a path which would work on Unix:

1) Write an xfig file using R. I use something like :

   xfig(file="created.fig", onefile=TRUE, bg="LightSkyBlue", width=5, height=3)
   plot()

   This is a very smart path to take if you want to manually touch up
   the picture in xfig (leave aside the Windows problem).

2) The program fig2dev converts .fig files into many file formats,
   including one "cgm" which is reputed to feed well into Microsoft
   software. I have no Windows here, however, and can't try this out.


Now for a (perhaps trivial) question: Several people said you have to
do

  win.metafile("/myfile.wmf")
  plot(1:10)
  dev.off()                 <--------  this is essential

Why is the 3rd line essential? I have been feeding R programs into R
using the command

$ R --vanilla < file.R

and I find things work just fine without having a dev.off()
command. E.g. I have this program which seems to work fine:

  A <- read.table(
         file="datafile.2",
         na.strings=".",
         col.names=c("date","dlinrchf","dlusdchf","dljpychf","dldemchf")
       )
  xfig(file="created.fig", onefile=TRUE, bg="LightSkyBlue", width=5, height=3)
  plot(A$dlusdchf, A$dlinrchf,
                   xlab="USD/CHF returns",
                   ylab="INR/CHF returns",
                   col = "dark red")

     -ans.

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From andy_liaw at merck.com  Sun Feb 22 16:56:25 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 22 Feb 2004 10:56:25 -0500
Subject: [R] R: Including R plots in a Microsoft Word document
Message-ID: <3A822319EB35174CA3714066D590DCD504AF781E@usrymx25.merck.com>

> From: Ajay Shah

[snip] 
 
> Now for a (perhaps trivial) question: Several people said you have to
> do
> 
>   win.metafile("/myfile.wmf")
>   plot(1:10)
>   dev.off()                 <--------  this is essential
> 
> Why is the 3rd line essential? I have been feeding R programs into R
> using the command
> 
> $ R --vanilla < file.R
> 
> and I find things work just fine without having a dev.off()
> command. E.g. I have this program which seems to work fine:

Without closing the device explicitly with dev.off(), the file is not
closed.  If this is done in an interactive session, then

win.metafile("try.wmf")
plot(1:10)
[import the file into some application]

will give you empty graph.  This works for you inside a script because any
opened graphic devices are closed at the end of the execution.

HTH,
Andy

>   A <- read.table(
>          file="datafile.2",
>          na.strings=".",
>          
> col.names=c("date","dlinrchf","dlusdchf","dljpychf","dldemchf")
>        )
>   xfig(file="created.fig", onefile=TRUE, bg="LightSkyBlue", 
> width=5, height=3)
>   plot(A$dlusdchf, A$dlinrchf,
>                    xlab="USD/CHF returns",
>                    ylab="INR/CHF returns",
>                    col = "dark red")
> 
>      -ans.
> 
> -- 
> Ajay Shah                                                   Consultant
> ajayshah at mayin.org                      Department of Economic Affairs
> http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From jonathan_wang at sbcglobal.net  Sun Feb 22 18:18:17 2004
From: jonathan_wang at sbcglobal.net (jonathan_wang@sbcglobal.net)
Date: Sun, 22 Feb 2004 11:18:17 -0600
Subject: [R] Simulation help
Message-ID: <000c01c3f967$e1ab6640$4bc41644@undine>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040222/3cedb2ab/attachment.pl

From rpugh at mango-solutions.com  Sun Feb 22 18:40:31 2004
From: rpugh at mango-solutions.com (Richard Pugh)
Date: Sun, 22 Feb 2004 17:40:31 -0000
Subject: [R] Simulation help
In-Reply-To: <000c01c3f967$e1ab6640$4bc41644@undine>
Message-ID: <000501c3f96a$f92c1050$5304fc3e@vsn.local>

Try this ...

poisNums <- rpois(100000, 3) # Calculate 100,000 poissons (mean 3)
normNums <- sapply(poisNums, rnorm, mean=3) # Calculate N random normals

	# for each simulated poisson.  Normal distribution is mean 3, sd
1
sumNums <- sapply(normNums, sum)
mySeq <- seq(0.85, 1, length=50)
plot(seq(0.85, 1, length=50)*100, quantile(sumNums, mySeq), type="l",
main="Quantiles of simulated data", xlab="Quantiles", ylab="")
abline(h=quantile(sumNums, c(0.95, 0.99)), col=2, lwd=2)

R does this for me in about 20 seconds ...

Rich.

Mango Solutions
Tel : (01628) 418134
Mob : (07967) 808091


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
jonathan_wang at sbcglobal.net
Sent: 22 February 2004 17:18
To: r-help at stat.math.ethz.ch
Subject: [R] Simulation help

I am a new R user.  As a test, I want to write a simple code that does
the following simulation:

1. Randomly generate a number from a distribution, say, Poisson.  Let's
say that number is 3.
2. Randomly generate 3 numbers from another distribution, say, Normal.
3. Compute the sum of the numbers generated in step 2 and read it into a
vector, V.
4. Repeat steps 1 through 3 for 100,000 times.
5. Derive quantiles (e.g., 0.95th, 0.99th) of V.

Any help in getting me going would be greatly appreciated.

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

---
Incoming mail is certified Virus Free.



From spencer.graves at pdf.com  Sun Feb 22 18:42:49 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 22 Feb 2004 09:42:49 -0800
Subject: [R] Simulation help
In-Reply-To: <000c01c3f967$e1ab6640$4bc41644@undine>
References: <000c01c3f967$e1ab6640$4bc41644@undine>
Message-ID: <4038EA19.9020200@pdf.com>

      How about the following: 

 > set.seed(5)
 > N <- 8 # later 100000
 > (nPois <- rpois(N, 2))
[1] 1 3 4 1 0 3 2 3
 > z <- rnorm(sum(nPois))
 > V <- tapply(z, rep(1:N, nPois), sum)
 > quantile(V, c(0, .05, .25, .5, .75, .95, 1))
        0%         5%        25%        50%        75%        95%       
100%
-2.7812799 -2.4600296 -1.5393631 -1.0803926  0.5800796  1.4626007  
1.7114409

      The same code works in S-Plus 6.2 and R 1.8.1 under Windows 2000, 
though the answers different as S-Plus and R use different random number 
generators. 

      hope this helps.  spencer graves

jonathan_wang at sbcglobal.net wrote:

>I am a new R user.  As a test, I want to write a simple code that does the following simulation:
>
>1. Randomly generate a number from a distribution, say, Poisson.  Let's say that number is 3.
>2. Randomly generate 3 numbers from another distribution, say, Normal.
>3. Compute the sum of the numbers generated in step 2 and read it into a vector, V.
>4. Repeat steps 1 through 3 for 100,000 times.
>5. Derive quantiles (e.g., 0.95th, 0.99th) of V.
>
>Any help in getting me going would be greatly appreciated.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From spencer.graves at pdf.com  Sun Feb 22 18:59:45 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 22 Feb 2004 09:59:45 -0800
Subject: [R] Simulation help
In-Reply-To: <000501c3f96a$f92c1050$5304fc3e@vsn.local>
References: <000501c3f96a$f92c1050$5304fc3e@vsn.local>
Message-ID: <4038EE11.4060203@pdf.com>

      I just noticed that my "solution" contained an error absent from 
Richard's code, below:  Any 0's in nPois (= poisNums below) are dropped, 
not summing to 0. 

      Best Wishes,
      spencer graves

Richard Pugh wrote:

>Try this ...
>
>poisNums <- rpois(100000, 3) # Calculate 100,000 poissons (mean 3)
>normNums <- sapply(poisNums, rnorm, mean=3) # Calculate N random normals
>
>	# for each simulated poisson.  Normal distribution is mean 3, sd
>1
>sumNums <- sapply(normNums, sum)
>mySeq <- seq(0.85, 1, length=50)
>plot(seq(0.85, 1, length=50)*100, quantile(sumNums, mySeq), type="l",
>main="Quantiles of simulated data", xlab="Quantiles", ylab="")
>abline(h=quantile(sumNums, c(0.95, 0.99)), col=2, lwd=2)
>
>R does this for me in about 20 seconds ...
>
>Rich.
>
>Mango Solutions
>Tel : (01628) 418134
>Mob : (07967) 808091
>
>
>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
>jonathan_wang at sbcglobal.net
>Sent: 22 February 2004 17:18
>To: r-help at stat.math.ethz.ch
>Subject: [R] Simulation help
>
>I am a new R user.  As a test, I want to write a simple code that does
>the following simulation:
>
>1. Randomly generate a number from a distribution, say, Poisson.  Let's
>say that number is 3.
>2. Randomly generate 3 numbers from another distribution, say, Normal.
>3. Compute the sum of the numbers generated in step 2 and read it into a
>vector, V.
>4. Repeat steps 1 through 3 for 100,000 times.
>5. Derive quantiles (e.g., 0.95th, 0.99th) of V.
>
>Any help in getting me going would be greatly appreciated.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>
>---
>Incoming mail is certified Virus Free.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From edwardweisun at hotmail.com  Sun Feb 22 20:10:45 2004
From: edwardweisun at hotmail.com (Edward Sun)
Date: Sun, 22 Feb 2004 20:10:45 +0100
Subject: [R] help for MLE
Message-ID: <BAY14-F10FcN6TQ4WJb00005057@hotmail.com>

Dear Sir/Madam,

I am using R version 1.8.1. I am doing following tast:

First generate 100 Gaussion(3,1) numbers, then write the likelihood function 
to estimate the parameters of Gaussian distribution by direct maximizing the 
likelihood function.

My likelihood function is:
>fn<-function(x) 
>(-50*log((sd(x))^2))-50*log(sqrt(2*pi))-(1/2*((mean(x))^2))*(sum((x-(mean(x))^2))

After I input above function, the '' >'' turned to be '' + ''. and it did 
not work.

I am looking for the help to solve this tast by writting a likelihood 
function.

Thanks a lot.

Best regards.
edward sun



From edwardweisun at hotmail.com  Sun Feb 22 20:12:13 2004
From: edwardweisun at hotmail.com (Edward Sun)
Date: Sun, 22 Feb 2004 20:12:13 +0100
Subject: [R] help for MLE
Message-ID: <BAY14-F57C5YJO9v6de00004b1c@hotmail.com>

Dear Sir/Madam,

I am using R version 1.8.1. I am doing following tast:

First generate 100 Gaussion(3,1) numbers, then write the likelihood function 
to estimate the parameters of Gaussian distribution by direct maximizing the 
likelihood function.

My likelihood function is:
>fn<-function(x) 
>(-50*log((sd(x))^2))-50*log(sqrt(2*pi))-(1/2*((mean(x))^2))*(sum((x-(mean(x))^2))

After I input above function, the '' >'' turned to be '' + ''. and it did 
not work.

I am looking for the help to solve this tast by writting a likelihood 
function.

Thanks a lot.

Best regards.
edward sun
p.s
>x=rnorm(100, mean=3, sd=1)
library(MASS)
fitdistr(x, "normal")

and

>fitdistr(x, "normal", list(mean=0, sd=1))

do not work.



From abunn at montana.edu  Sun Feb 22 20:20:26 2004
From: abunn at montana.edu (Andy Bunn)
Date: Sun, 22 Feb 2004 12:20:26 -0700
Subject: [R] help for MLE
In-Reply-To: <BAY14-F10FcN6TQ4WJb00005057@hotmail.com>
Message-ID: <002201c3f978$f04b6310$78f05a99@msu.montana.edu>

I fear you have a problem with your parentheses. The '>' sign turns to a
'+' when the line is incomplete. See the R-FAQ for information. This
evaluates but I'm not sure if it's what you want....

fn < -function(x){
 
(-50*log((sd(x))^2))-50*log(sqrt(2*pi))-(1/2*((mean(x))^2))*(sum((x-(mea
n(x))^2)))
}


fn(1:10)


HTH, Andy



From andy_liaw at merck.com  Sun Feb 22 20:23:59 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 22 Feb 2004 14:23:59 -0500
Subject: [R] help for MLE
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7820@usrymx25.merck.com>

A likelihood function is the pdf or pmf as a function of parameters given
the data.  The function you wrote is purely a function of the data, not
parameters.  You need to write the function as a likelihood before you can
get the MLE.

Andy

> From: Edward Sun
> 
> Dear Sir/Madam,
> 
> I am using R version 1.8.1. I am doing following tast:
> 
> First generate 100 Gaussion(3,1) numbers, then write the 
> likelihood function 
> to estimate the parameters of Gaussian distribution by direct 
> maximizing the 
> likelihood function.
> 
> My likelihood function is:
> >fn<-function(x) 
> >(-50*log((sd(x))^2))-50*log(sqrt(2*pi))-(1/2*((mean(x))^2))*(
> sum((x-(mean(x))^2))
> 
> After I input above function, the '' >'' turned to be '' + 
> ''. and it did 
> not work.
> 
> I am looking for the help to solve this tast by writting a likelihood 
> function.
> 
> Thanks a lot.
> 
> Best regards.
> edward sun


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From spencer.graves at pdf.com  Sun Feb 22 20:31:16 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 22 Feb 2004 11:31:16 -0800
Subject: [R] help for MLE
In-Reply-To: <BAY14-F10FcN6TQ4WJb00005057@hotmail.com>
References: <BAY14-F10FcN6TQ4WJb00005057@hotmail.com>
Message-ID: <40390384.3060208@pdf.com>

      Is this a homework problem? 

      The "+" means the statement is not syntactically complete.  
Perhaps you have more "(" than ")"? 

      Also, have you read "the posting guide! 
http://www.R-project.org/posting-guide.html"?  Many people answer their 
own questions just following that guide. 

      spencer graves

Edward Sun wrote:

> Dear Sir/Madam,
>
> I am using R version 1.8.1. I am doing following tast:
>
> First generate 100 Gaussion(3,1) numbers, then write the likelihood 
> function to estimate the parameters of Gaussian distribution by direct 
> maximizing the likelihood function.
>
> My likelihood function is:
>
>> fn<-function(x) 
>> (-50*log((sd(x))^2))-50*log(sqrt(2*pi))-(1/2*((mean(x))^2))*(sum((x-(mean(x))^2)) 
>>
>
>
> After I input above function, the '' >'' turned to be '' + ''. and it 
> did not work.
>
> I am looking for the help to solve this tast by writting a likelihood 
> function.
>
> Thanks a lot.
>
> Best regards.
> edward sun
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From rpugh at mango-solutions.com  Sun Feb 22 20:46:50 2004
From: rpugh at mango-solutions.com (Richard Pugh)
Date: Sun, 22 Feb 2004 19:46:50 -0000
Subject: [R] Simulation help
In-Reply-To: <000501c3f96a$f92c1050$5304fc3e@vsn.local>
Message-ID: <001c01c3f97c$9f89b950$5304fc3e@vsn.local>

Sorry - looks like the text wrapped when I sent this ... am resending
with better format, so you can read the code!

# This bit does the work ...
> poisNums <- rpois(100000, 3)
> normNums <- sapply(poisNums, rnorm, mean=3)
> sumNums <- sapply(normNums, sum)

# Produce a plot with quantiles ...
> mySeq <- seq(0.85, 1, length=50)
> plot(seq(0.85, 1, length=50)*100, quantile(sumNums, mySeq), type="l",
+ main="Quantiles of simulated data", xlab="Quantiles", ylab="")
> abline(h=quantile(sumNums, c(0.95, 0.99)), col=2, lwd=2)

Rich.

Mango Solutions
Tel : (01628) 418134
Mob : (07967) 808091


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
jonathan_wang at sbcglobal.net
Sent: 22 February 2004 17:18
To: r-help at stat.math.ethz.ch
Subject: [R] Simulation help

I am a new R user.  As a test, I want to write a simple code that does
the following simulation:

1. Randomly generate a number from a distribution, say, Poisson.  Let's
say that number is 3.
2. Randomly generate 3 numbers from another distribution, say, Normal.
3. Compute the sum of the numbers generated in step 2 and read it into a
vector, V.
4. Repeat steps 1 through 3 for 100,000 times.
5. Derive quantiles (e.g., 0.95th, 0.99th) of V.

Any help in getting me going would be greatly appreciated.

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

---
Incoming mail is certified Virus Free.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

---
Incoming mail is certified Virus Free.



From liuqincn at yahoo.com  Sun Feb 22 20:58:49 2004
From: liuqincn at yahoo.com (liu qin)
Date: Sun, 22 Feb 2004 11:58:49 -0800 (PST)
Subject: [R] how to plot multi- lines on one diagram
Message-ID: <20040222195849.11945.qmail@web12309.mail.yahoo.com>

Hello there:

I got a matrix as data1, I do need to plot each column
and illustrate them as 4 lines on the same screen.

Would anybody help me out please?

> data1
       [,1]  [,2]  [,3]   [,4]
 [1,] 94.35 60.89 33.12 0.1001     	
 [2,] 94.17 60.53 32.76 0.1003			
 [3,] 94.35 61.80 34.74 0.0980
 [4,] 95.45 65.99 38.74 0.0910
 [5,] 95.82 69.44 38.38 0.0859
 [6,] 95.64 68.72 42.19 0.0903
 [7,] 94.35 69.28 43.11 0.2931
 [8,] 94.19 68.73 43.27 0.0980
 [9,] 93.82 65.81 38.36 0.1357
 [10,] 92.90 63.81 39.28 0.1353	

Thank you very much indeed,

Qin Liu

Northumbria University



From ccleland at optonline.net  Sun Feb 22 21:18:51 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Sun, 22 Feb 2004 15:18:51 -0500
Subject: [R] how to plot multi- lines on one diagram
In-Reply-To: <20040222195849.11945.qmail@web12309.mail.yahoo.com>
References: <20040222195849.11945.qmail@web12309.mail.yahoo.com>
Message-ID: <40390EAB.9040102@optonline.net>

liu qin wrote:
> I got a matrix as data1, I do need to plot each column
> and illustrate them as 4 lines on the same screen.
> 
> Would anybody help me out please?
> 
>>data1
> 
>        [,1]  [,2]  [,3]   [,4]
>  [1,] 94.35 60.89 33.12 0.1001     	
>  [2,] 94.17 60.53 32.76 0.1003			
>  [3,] 94.35 61.80 34.74 0.0980
>  [4,] 95.45 65.99 38.74 0.0910
>  [5,] 95.82 69.44 38.38 0.0859
>  [6,] 95.64 68.72 42.19 0.0903
>  [7,] 94.35 69.28 43.11 0.2931
>  [8,] 94.19 68.73 43.27 0.0980
>  [9,] 93.82 65.81 38.36 0.1357
>  [10,] 92.90 63.81 39.28 0.1353	
> 

matplot(data1, type="l")

See ?matplot

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From lixian7001 at yahoo.com  Sun Feb 22 21:20:54 2004
From: lixian7001 at yahoo.com (li xian)
Date: Sun, 22 Feb 2004 12:20:54 -0800 (PST)
Subject: [R] For loop help
Message-ID: <20040222202054.70499.qmail@web11509.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040222/fdb3a891/attachment.pl

From MSchwartz at medanalytics.com  Sun Feb 22 21:25:50 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 22 Feb 2004 14:25:50 -0600
Subject: [R] how to plot multi- lines on one diagram
In-Reply-To: <20040222195849.11945.qmail@web12309.mail.yahoo.com>
References: <20040222195849.11945.qmail@web12309.mail.yahoo.com>
Message-ID: <1077481550.16414.10.camel@localhost.localdomain>

On Sun, 2004-02-22 at 13:58, liu qin wrote:
> Hello there:
> 
> I got a matrix as data1, I do need to plot each column
> and illustrate them as 4 lines on the same screen.
> 
> Would anybody help me out please?
> 
> > data1
>        [,1]  [,2]  [,3]   [,4]
>  [1,] 94.35 60.89 33.12 0.1001     	
>  [2,] 94.17 60.53 32.76 0.1003			
>  [3,] 94.35 61.80 34.74 0.0980
>  [4,] 95.45 65.99 38.74 0.0910
>  [5,] 95.82 69.44 38.38 0.0859
>  [6,] 95.64 68.72 42.19 0.0903
>  [7,] 94.35 69.28 43.11 0.2931
>  [8,] 94.19 68.73 43.27 0.0980
>  [9,] 93.82 65.81 38.36 0.1357
>  [10,] 92.90 63.81 39.28 0.1353	
> 
> Thank you very much indeed,
> 
> Qin Liu

See ?matplot

Example:

# create a 4 column matrix
data1 <- matrix(1:40, ncol = 4)
> data1
      [,1] [,2] [,3] [,4]
 [1,]    1   11   21   31
 [2,]    2   12   22   32
 [3,]    3   13   23   33
 [4,]    4   14   24   34
 [5,]    5   15   25   35
 [6,]    6   16   26   36
 [7,]    7   17   27   37
 [8,]    8   18   28   38
 [9,]    9   19   29   39
[10,]   10   20   30   40

# Now plot the four columns as lines
matplot(data1, type = "l")

HTH,

Marc Schwartz



From tblackw at umich.edu  Sun Feb 22 21:53:02 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Sun, 22 Feb 2004 15:53:02 -0500 (EST)
Subject: [R] For loop help
In-Reply-To: <20040222202054.70499.qmail@web11509.mail.yahoo.com>
References: <20040222202054.70499.qmail@web11509.mail.yahoo.com>
Message-ID: <Pine.SOL.4.58.0402221548510.7163@zektor.gpcc.itd.umich.edu>

Xian  -

I interpret this as a question about subscripting.
Read  help("Subscript"), help("Control").  Perhaps
the roughly 40 page pdf document "An Introduction to R"
(or something like that) found under "Manuals" on the
R home page would be helpful in getting started.

I don't understand enough of your question to give
a more specific answer.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Sun, 22 Feb 2004, li xian wrote:

> hello,
>
> I would like to do a for loop for matrix:
>
> Xm             Xm-1   ......      X1
> Xm+1         Xm      ......      X2
> .......................................
> .....................................
> Xn              Xn-1    ......      Xn-m+1
>
> How can I do  it in R?
>
> Thanks!!!
>
>
>
>
> ---------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From w.vervoort at acss.usyd.edu.au  Sun Feb 22 23:28:58 2004
From: w.vervoort at acss.usyd.edu.au (Willem Vervoort)
Date: Mon, 23 Feb 2004 09:28:58 +1100
Subject: [R] contourplots
Message-ID: <40392D2A.1000908@acss.usyd.edu.au>

Hi
Silly question maybe, but I am only a novice.
How do I make the background of contourplot white? I have tried bg, 
canvas, and all other possible option suggested under par and xyplot. 
But nothing seems to work. Since my plot is of data in x-y space maybe I 
could use another function (i.e. contour), but than x and y should be 
ordered and I haven't figured out how to do that yet.

Any suggestions?
Willem

-- 
Dr R.W. Vervoort
McCaughey Senior Lecturer Hydrology and Catchment Management			
Faculty of Agriculture, Food and Natural Resources
Rm 503, Watt Bldg.
http://www.agric.usyd.edu.au/mccaughey

Postal:
Bldg A03
The University of Sydney, NSW, 2006

phone: +61 (2) 9351 8744
fax:   +61 (2) 9351 5108
e-mail: w.vervoort at acss.usyd.edu.au



From w.vervoort at acss.usyd.edu.au  Sun Feb 22 23:46:58 2004
From: w.vervoort at acss.usyd.edu.au (Willem Vervoort)
Date: Mon, 23 Feb 2004 09:46:58 +1100
Subject: [R] countourplot background
Message-ID: <40393162.1070409@acss.usyd.edu.au>

Hi,
Found the answer to the background myself: 'trellis.par.get' and 
'trellis.par.set'
background<-trellis.par.get("background")
background$col<-"white"
trellis.par.set("background", background)

Willem

-- 
Dr R.W. Vervoort
McCaughey Senior Lecturer Hydrology and Catchment Management			
Faculty of Agriculture, Food and Natural Resources
Rm 503, Watt Bldg.
http://www.agric.usyd.edu.au/mccaughey

Postal:
Bldg A03
The University of Sydney, NSW, 2006

phone: +61 (2) 9351 8744
fax:   +61 (2) 9351 5108
e-mail: w.vervoort at acss.usyd.edu.au



From lixian7001 at yahoo.com  Sun Feb 22 23:55:36 2004
From: lixian7001 at yahoo.com (li xian)
Date: Sun, 22 Feb 2004 14:55:36 -0800 (PST)
Subject: [R] a simple question about a matrix
Message-ID: <20040222225536.34825.qmail@web11504.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040222/8ae3ed1d/attachment.pl

From andy_liaw at merck.com  Mon Feb 23 00:13:29 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 22 Feb 2004 18:13:29 -0500
Subject: [R] a simple question about a matrix
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7824@usrymx25.merck.com>

If the matrix is real, then isn't that just
sqrt(eigen(crossprod(x))$values[1]) ??

Andy

> From: li xian
> 
> suppose x is a matrix.
> how to define ||x|| in R?
>  
> thank you!
> 
> 
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From spencer.graves at pdf.com  Mon Feb 23 00:34:56 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 22 Feb 2004 15:34:56 -0800
Subject: [R] a simple question about a matrix
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7824@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7824@usrymx25.merck.com>
Message-ID: <40393CA0.9060605@pdf.com>

      There are many matrix norms.  The Mathematica web site 
(http://mathworld.wolfram.com/MatrixNorm.html) says the one Andy just 
gave 'is often referred to as "the" matrix norm.'  However, there many 
others.  For some purposes, any matrix norm will do.  For other 
purposes, you need to know the purpose. 

      Please excuse me if this seems like a picky, pedantic rant.  
spencer graves

Liaw, Andy wrote:

>If the matrix is real, then isn't that just
>sqrt(eigen(crossprod(x))$values[1]) ??
>
>Andy
>
>  
>
>>From: li xian
>>
>>suppose x is a matrix.
>>how to define ||x|| in R?
>> 
>>thank you!
>>
>>
>>---------------------------------
>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
>>    
>>
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments,...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From bates at stat.wisc.edu  Mon Feb 23 00:44:21 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 22 Feb 2004 17:44:21 -0600
Subject: [R] a simple question about a matrix
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7824@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7824@usrymx25.merck.com>
Message-ID: <6rfzd2vfvu.fsf@bates4.stat.wisc.edu>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> If the matrix is real, then isn't that just
> sqrt(eigen(crossprod(x))$values[1]) ??
> 
> Andy
> 
> > From: li xian
> > 
> > suppose x is a matrix.
> > how to define ||x|| in R?
> >  

The symbol ||x|| could mean many different things when x is a matrix.
I presume that you mean some kind of matrix norm.  Could you be more
specific about which norm you want?  (There are several.)

The one-norm, the Frobenius norm, and the infinity norm are all
available in the new version of the Matrix package, which is currently
available only for the development version of R (to be R-1.9.0).

> mm = Matrix(rnorm(9), nrow = 3)
> mm
           [,1]       [,2]      [,3]
[1,] -1.0210873  0.9941221  2.363475
[2,] -0.5171302 -0.3243187 -1.455873
[3,] -2.3793565  0.5223258 -1.034270
> norm(mm, '1')
[1] 4.853617
> norm(mm, 'O')   # the one norm
[1] 4.853617
> norm(mm, 'I')   # the infinity norm
[1] 4.378684
> norm(mm, 'F')   # the Frobenius norm
[1] 4.136781
> norm(mm, 'M')   # the Maximum modulus (not really a norm)
[1] 2.379356



From liuqincn at yahoo.com  Mon Feb 23 01:45:39 2004
From: liuqincn at yahoo.com (liu qin)
Date: Sun, 22 Feb 2004 16:45:39 -0800 (PST)
Subject: [R] Nearest Neighbour for prediction
Message-ID: <20040223004539.91701.qmail@web12310.mail.yahoo.com>

Does anybody know how to use nearest neighbour in R to
predict anything? I am stuck here. I would be really
really grateful if anyone could help. Thank you for
the help.

Qin 

Ph.D. Student
U.K.



From andy_liaw at merck.com  Mon Feb 23 01:51:48 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 22 Feb 2004 19:51:48 -0500
Subject: [R] Nearest Neighbour for prediction
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7828@usrymx25.merck.com>

Try:

library(class)
?knn
example(knn)

Andy

> From: liu qin
> 
> Does anybody know how to use nearest neighbour in R to
> predict anything? I am stuck here. I would be really
> really grateful if anyone could help. Thank you for
> the help.
> 
> Qin 
> 
> Ph.D. Student
> U.K.


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From maj at stats.waikato.ac.nz  Mon Feb 23 01:56:31 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Mon, 23 Feb 2004 13:56:31 +1300
Subject: [R] references on cluster analysis
In-Reply-To: <16439.24212.848934.835200@gargle.gargle.HOWL>
References: <Pine.LNX.4.58.0402071927360.819@bayes.speech.kth.se>
	<16439.24212.848934.835200@gargle.gargle.HOWL>
Message-ID: <40394FBF.2070306@stats.waikato.ac.nz>

I don't really believe that there is any satisfactory definition of the 
"true number of clusters" let along a procedure that would reliably find it.

Murray Jorgensen


Martin Maechler wrote:

> Back from my vacation, I haven't seen an R-help answer on this
>   (Christian, where have you been ? ;-)
> 
> 
>>>>>>"GiampS" == Giampiero Salvi <giampi at speech.kth.se>
>>>>>>    on Sat, 7 Feb 2004 23:40:36 +0100 (CET) writes:
> 
> 
>     GiampS> Hi all, I'm doing a study on predicting the "true"
>     GiampS> number of clusters in a hierarchical clustering
>     GiampS> scheme. My main reference is at the moment
> 
>     GiampS> Milligan GW and Cooper MC (1985) "An examination of
>     GiampS> procedures for determining the number of clusters in
>     GiampS> a data set" Psychometrika vol 50 no 2 pp 159-179
> 
>     GiampS> and all the references included in that paper.
> 
> (not available to me)
> 
>     GiampS> I'm planning to perform a similar comparison on a
>     GiampS> number of indexes, but on a much larger data set (in
>     GiampS> the order of 3000 points), and with a much higher
>     GiampS> "true" number of clusters (in the order of some
>     GiampS> hundreds), to see if the properties of the indexes
>     GiampS> scale accordingly.
> 
>     GiampS> I was wondering if the set of indexes described in
>     GiampS> the reference are still "state of the art" (most of
>     GiampS> them were introduced in the '60s and '70s), or if
>     GiampS> there are new indexes and methods I could include in
>     GiampS> my study. I would really appreciate if you could
>     GiampS> point me to some newer references addressing this problem.
> 
> Gordon's 2nd edition,
> 
>   author =	 {A. D. Gordon},
>   title = 	 {Classification, 2nd Edition},
>   publisher = 	 {Chappman \& Hall/CRC},
>   year = 	 1999,
>   series =	 {Monographs on Statistics and Applied Probability 82},
>   edition =	 {2nd edition}
> 
> has a whole chapter (one of the last ones in the book) on this.
> 
> R's cluster package has a generic silhouette() function (with 2 methods),
> and plot.silhouette() method --- all are improvements from
> Kaufman & Rousseeuw's original code.
> 
> A recent research paper using "CLEST" (Fridyland & Dudoit),
> mentioning "GAP" (Tibshirani) etc etc  still find silhouette
> among the best "indices" for determining the number of clusters.
> 
> A student's (master) thesis here seems to point in the same
> direction.
> 
>     GiampS> I also read Milligan's chapter in the book
>     GiampS> "Clustering and Classification" from 1995, 
> (which book? author?)
> 
>     GiampS> but didn't find information on this subject that wasn't
>     GiampS> included in the previous paper.
> 
> Regards,
> Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
> ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
> phone: x-41-1-632-3408		fax: ...-1228			<><
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From liuqincn at yahoo.com  Mon Feb 23 02:13:04 2004
From: liuqincn at yahoo.com (liu qin)
Date: Sun, 22 Feb 2004 17:13:04 -0800 (PST)
Subject: [R] Nearest Neighbour for prediction
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7828@usrymx25.merck.com>
Message-ID: <20040223011304.11365.qmail@web12305.mail.yahoo.com>

Andy:

So, what do you think about Gest{spatstat} or
knearneigh{spdep} as
they both claimed they are the functions to calculate
the nearest
neighbour distance?

Qin
--- "Liaw, Andy" <andy_liaw at merck.com> wrote:
> Try:
> 
> library(class)
> ?knn
> example(knn)
> 
> Andy
> 
> > From: liu qin
> > 
> > Does anybody know how to use nearest neighbour in
> R to
> > predict anything? I am stuck here. I would be
> really
> > really grateful if anyone could help. Thank you
> for
> > the help.
> > 
> > Qin 
> > 
> > Ph.D. Student
> > U.K.
> 
> 
>
------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any
> attachments, contains
> information of Merck & Co., Inc. (One Merck Drive,
> Whitehouse Station, New
> Jersey, USA 08889), and/or its affiliates (which may
> be known outside the
> United States as Merck Frosst, Merck Sharp & Dohme
> or MSD and in Japan, as
> Banyu) that may be confidential, proprietary
> copyrighted and/or legally
> privileged. It is intended solely for the use of the
> individual or entity
> named on this message.  If you are not the intended
> recipient, and have
> received this message in error, please notify us
> immediately by reply e-mail
> and then delete it from your system.
>



From Lisa.Holman at npws.nsw.gov.au  Mon Feb 23 03:03:47 2004
From: Lisa.Holman at npws.nsw.gov.au (Lisa.Holman@npws.nsw.gov.au)
Date: Mon, 23 Feb 2004 13:03:47 +1100
Subject: [R] (no subject)
Message-ID: <OFE2D148B1.863AB137-ONCA256E43.00093E64@npws.nsw.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040223/421698fd/attachment.pl

From Lisa.Holman at npws.nsw.gov.au  Mon Feb 23 03:37:11 2004
From: Lisa.Holman at npws.nsw.gov.au (Lisa.Holman@npws.nsw.gov.au)
Date: Mon, 23 Feb 2004 13:37:11 +1100
Subject: [R] dendrogram ultrametrics
Message-ID: <OFFBE0607A.D141A865-ONCA256E43.000B50BF@npws.nsw.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040223/c0f323c3/attachment.pl

From alistair.campbell at jcu.edu.au  Mon Feb 23 03:39:48 2004
From: alistair.campbell at jcu.edu.au (Alistair Campbell)
Date: Mon, 23 Feb 2004 12:39:48 +1000
Subject: [R] MiceR
Message-ID: <403967F4.1090900@jcu.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040223/7a7ef0d2/attachment.pl

From ggrothendieck at myway.com  Mon Feb 23 04:05:43 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 22 Feb 2004 22:05:43 -0500 (EST)
Subject: [R] R: Including R plots in a Microsoft Word document
Message-ID: <20040223030543.CE32B3993@mprdmxin.myway.com>



Another way to transfer plots is to transfer the display list.  
This is a list of the low level plot commands that R produces.

For example, on Linux do this:

   dev.control(displaylist="enable") # enable display list
   plot(1:10)
   myplot <- recordPlot()  # load displaylist into variable
   save(myplot, file="myplot", ascii=TRUE)

Send the ascii file, myplot, to the Windows machine and on Windows do this:

   dev.control(displaylist="enable") # enable display list
   load("myplot")
   myplot # displays the plot
   savePlot("myplot", type="wmf")  # saves current plot as wmf

I don't have Linux to actually try this out but perhaps someone
with both can try it out.

---
Date:   Sun, 22 Feb 2004 21:13:37 +0530 
From:   Ajay Shah <ajayshah at mayin.org>
To:   <r-help at stat.math.ethz.ch> 
Subject:   Re: [R] R: Including R plots in a Microsoft Word document 

 
It was pointed out that while 

win.metafile("/myfile.wmf")

is useful, it only works on windows.

Here's a path which would work on Unix:

1) Write an xfig file using R. I use something like :

xfig(file="created.fig", onefile=TRUE, bg="LightSkyBlue", width=5, height=3)
plot()

This is a very smart path to take if you want to manually touch up
the picture in xfig (leave aside the Windows problem).

2) The program fig2dev converts .fig files into many file formats,
including one "cgm" which is reputed to feed well into Microsoft
software. I have no Windows here, however, and can't try this out.


Now for a (perhaps trivial) question: Several people said you have to
do

win.metafile("/myfile.wmf")
plot(1:10)
dev.off() <-------- this is essential

Why is the 3rd line essential? I have been feeding R programs into R
using the command

$ R --vanilla < file.R

and I find things work just fine without having a dev.off()
command. E.g. I have this program which seems to work fine:

A <- read.table(
file="datafile.2",
na.strings=".",
col.names=c("date","dlinrchf","dlusdchf","dljpychf","dldemchf")
)
xfig(file="created.fig", onefile=TRUE, bg="LightSkyBlue", width=5, height=3)
plot(A$dlusdchf, A$dlinrchf,
xlab="USD/CHF returns",
ylab="INR/CHF returns",
col = "dark red")

-ans.

-- 
Ajay Shah Consultant
ajayshah at mayin.org Department of Economic Affairs
http://www.mayin.org/ajayshah Ministry of Finance, New Delhi

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Mon Feb 23 05:05:47 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 22 Feb 2004 23:05:47 -0500
Subject: [R] Nearest Neighbour for prediction
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7829@usrymx25.merck.com>

I guess it depends on what you want to estimate.  knn in the VR bundle does
classification.  The two functions you mentioned are quite specifically for
spatial statistics, and do quite different things (especially Gest).  

Andy

> From: liu qin [mailto:liuqincn at yahoo.com] 
> 
> Andy:
> 
> So, what do you think about Gest{spatstat} or
> knearneigh{spdep} as
> they both claimed they are the functions to calculate
> the nearest
> neighbour distance?
> 
> Qin
> --- "Liaw, Andy" <andy_liaw at merck.com> wrote:
> > Try:
> > 
> > library(class)
> > ?knn
> > example(knn)
> > 
> > Andy
> > 
> > > From: liu qin
> > > 
> > > Does anybody know how to use nearest neighbour in
> > R to
> > > predict anything? I am stuck here. I would be
> > really
> > > really grateful if anyone could help. Thank you
> > for
> > > the help.
> > > 
> > > Qin 
> > > 
> > > Ph.D. Student
> > > U.K.
> > 
> > 
> >
> --------------------------------------------------------------
> ----------------
> > Notice:  This e-mail message, together with any
> > attachments, contains
> > information of Merck & Co., Inc. (One Merck Drive,
> > Whitehouse Station, New
> > Jersey, USA 08889), and/or its affiliates (which may
> > be known outside the
> > United States as Merck Frosst, Merck Sharp & Dohme
> > or MSD and in Japan, as
> > Banyu) that may be confidential, proprietary
> > copyrighted and/or legally
> > privileged. It is intended solely for the use of the
> > individual or entity
> > named on this message.  If you are not the intended
> > recipient, and have
> > received this message in error, please notify us
> > immediately by reply e-mail
> > and then delete it from your system.
> >
> --------------------------------------------------------------
> ----------------
> 
> 
> __________________________________


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From jasont at indigoindustrial.co.nz  Mon Feb 23 05:12:11 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 23 Feb 2004 17:12:11 +1300 (NZDT)
Subject: [R] MiceR
In-Reply-To: <403967F4.1090900@jcu.edu.au>
References: <403967F4.1090900@jcu.edu.au>
Message-ID: <13453.203.9.176.60.1077509531.squirrel@new-webmail.maxnet.co.nz>


> has anyone got some advise about loading MiceR,
...
> I note from the web page that MiceR is described as a package for Unix
> and I am running R on Windows XP. Does it make a difference to the
> package?

Rather a lot.  You can

 1) compile it yourself and build a binary for windows
 2) ask the MiceR maintainers to do it for you
 3) do the analyses under Unix or a Unix-like system

Since I know nothing about MiceR, I've no idea if this is easy or
impossible.  What you've got now Just Won't Work (tm).

Cheers

Jason



From ripley at stats.ox.ac.uk  Mon Feb 23 09:22:14 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Feb 2004 08:22:14 +0000 (GMT)
Subject: [R] MiceR
In-Reply-To: <13453.203.9.176.60.1077509531.squirrel@new-webmail.maxnet.co.nz>
Message-ID: <Pine.LNX.4.44.0402230819020.9265-100000@gannet.stats>

On Mon, 23 Feb 2004, Jason Turner wrote:

> 
> > has anyone got some advise about loading MiceR,
> ...
> > I note from the web page that MiceR is described as a package for Unix
> > and I am running R on Windows XP. Does it make a difference to the
> > package?
> 
> Rather a lot.  You can
> 
>  1) compile it yourself and build a binary for windows

Worked.

>  2) ask the MiceR maintainers to do it for you
>  3) do the analyses under Unix or a Unix-like system
> 
> Since I know nothing about MiceR, I've no idea if this is easy or
> impossible.  What you've got now Just Won't Work (tm).

Note that this is a rather old R package (from 2000) and is not going 
to work correctly even under Unix.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fm3a004 at math.uni-hamburg.de  Mon Feb 23 10:30:23 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Mon, 23 Feb 2004 10:30:23 +0100 (MET)
Subject: [R] references on cluster analysis
In-Reply-To: <40394FBF.2070306@stats.waikato.ac.nz>
Message-ID: <Pine.GSO.3.95q.1040223101951.21012A-100000@sun11.math.uni-hamburg.de>

Hi,

> Martin Maechler wrote:
> 
> > Back from my vacation, I haven't seen an R-help answer on this
> >   (Christian, where have you been ? ;-)

(Uh, I missed this one. Too much spam?)

I would add information based criteria (AIC, BIC and so on)
together with a normal mixture model (implemented in package mclust). Four
of these criteria are compared in Celeux and Soromenho, An Entropy
Criterion for Assessing the Number of Clusters in a Mixture Model, Journal
of Classification 13, 195-212 (1996) along with more references.

Note that there are also a number of clustering approaches in the recent
literature that decide about the number of clusters implicitly (not via
optimizing over all cluster numbers), e.g., DBSCAN. 

Christian

> >>>>>>"GiampS" == Giampiero Salvi <giampi at speech.kth.se>
> >>>>>>    on Sat, 7 Feb 2004 23:40:36 +0100 (CET) writes:
> > 
> > 
> >     GiampS> Hi all, I'm doing a study on predicting the "true"
> >     GiampS> number of clusters in a hierarchical clustering
> >     GiampS> scheme. My main reference is at the moment
> > 
> >     GiampS> Milligan GW and Cooper MC (1985) "An examination of
> >     GiampS> procedures for determining the number of clusters in
> >     GiampS> a data set" Psychometrika vol 50 no 2 pp 159-179
> > 
> >     GiampS> and all the references included in that paper.
> > 
> >     GiampS> I'm planning to perform a similar comparison on a
> >     GiampS> number of indexes, but on a much larger data set (in
> >     GiampS> the order of 3000 points), and with a much higher
> >     GiampS> "true" number of clusters (in the order of some
> >     GiampS> hundreds), to see if the properties of the indexes
> >     GiampS> scale accordingly.
> > 
> >     GiampS> I was wondering if the set of indexes described in
> >     GiampS> the reference are still "state of the art" (most of
> >     GiampS> them were introduced in the '60s and '70s), or if
> >     GiampS> there are new indexes and methods I could include in
> >     GiampS> my study. I would really appreciate if you could
> >     GiampS> point me to some newer references addressing this problem.

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From f.calboli at ucl.ac.uk  Mon Feb 23 11:40:35 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 23 Feb 2004 10:40:35 +0000
Subject: [R] plot(my.procrustes.model) from library {vegan}
Message-ID: <1077532835.2960.18.camel@monkey>

Dear All,

I would like to ask how to customize the graph corresponding to a
procrustes analysis.

I have to distance matrices, that I transform to two set of coordinates
by means of muti dimensional scaling:

library(mva)

c1<-cmdscale(mat.dist1)
c2<-cmdscale(mat.dist2) 

I vant to rotate c2 on c1, and I use the "procrustes" analysis from the
{vegan} library.

library(vegan)

mod.pro<-procrustes(c1,c2)

plot(mod.pro)

My problem is that I need to change the graphical output of
plot(mod.pro). The standard output gives empty circles for the rotated
c2 matrix and arrows pointing to the target c1 matrix. 

I would like to have two set of symbols, one for c1 and the other for
c2, with a line connecting the corresponding points or at worst I would
like to have circles for the point of the target matix and the arrows
pointing to the rotated matrix.

I tried some manipulations based on the standard "plot" function, but I
was quite unsucessful. Can anyone give advice? I am happy to give a toy
example if needed.

Regards,

Federico Calboli 
-- 



=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 251 208

f.calboli at ucl.ac.uk



From fm3a004 at math.uni-hamburg.de  Mon Feb 23 10:50:55 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Mon, 23 Feb 2004 10:50:55 +0100 (MET)
Subject: [R] dendrogram ultrametrics
In-Reply-To: <OFFBE0607A.D141A865-ONCA256E43.000B50BF@npws.nsw.gov.au>
Message-ID: <Pine.GSO.3.95q.1040223104142.21012B-100000@sun11.math.uni-hamburg.de>

Dear Lisa,

as far as I know, there is no implementation of dendrogram ultrametrics,
but it could be easily computed from the output of hclust (package mva)
or agnes (package cluster) in the following manner:
1) Generate the desired dendrogram by hclust or agnes.
2) Generate partitions for all levels by cutree.
3) For a given pair of objects, determine the level on which they are
joined.
4) Take the height component of the output object of hclust or agnes
at this level.

Perhaps it can be done faster by intelligent use of the merge component
of the output object. (Note that I didn't try it, so all this assumes that
the help pages are correct and I understood them...)

Best,
Christian

On Mon, 23 Feb 2004 Lisa.Holman at npws.nsw.gov.au wrote:

> Dear R-help listers,
> Is anyone aware of a function that outputs dendrogram ultrametrics?
> Cheers, Lisa.
> 
> PS please reply to me personally as well as to the list because the 
> website wasn't letting me subscribe for some reason.  thanks...
> 
> Lisa Holman
> Research Officer, Vegetation Dynamics
> Policy & Science Division
> NSW Department of Environment & Conservation
> PO Box 1967, Hurstville 2220.
> ph 02 9585 6507    fax 02 9585 6606
> email lisa.holman at npws.nsw.gov.au
> 
> The NPWS is part of the new Department of Environment & Conservation
> 
> This message is intended for the addressee named and may contain
> confidential information. 
> 
> If you are not the intended recipient, please notify the sender and then delete the message. Views expressed in this message may be those of the individual sender, and are not necessarily the views of the NSW Department of Environment and Conservation.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From cg.pettersson at evp.slu.se  Mon Feb 23 10:52:34 2004
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Mon, 23 Feb 2004 10:52:34 +0100
Subject: [R] lme - problems with model
Message-ID: <200402230952.i1N9qYAA018106@mail1.slu.se>

Hello all!

I?m working with some training datasets in a SAS-based course, trying
to do the same things in lme that I do in PROC MIXED. 

Why don?t lme do an analysis on this dataset when I use the model
water*temp?
The trouble comes from the water:temp term, as it works with
water+temp.
The data are, indeed, assymetric but lm accepts the water:temp term
giving results in the F-test near what PROC MIXED produces. MIXED
accepts the model.

The water:temp term can be removed from the model according to the
F-test in SAS (and to the lm model without any random term). Doing so
in both MIXED and lme gives reasonably similar results for both
systems.

What do the error message mean, and how can I get around this?

/CG


The dataset:
> milk
   water temp rep maill4 maill6 maill8 taste4 taste6 taste8
1      1  100   1   2.90   2.13   2.39   10.1   10.0    9.6
2      1  100   2   2.19   2.20   2.27   11.0    9.3   11.0
3      1  100   3   2.13   2.20   2.41   10.1    7.0    9.6
4      1  110   1   2.13   2.34   2.41   11.0   10.5    9.8
5      1  110   2   2.32   2.27   2.25   11.0   11.3   11.2
6      1  110   3   2.13   2.34   2.42    9.4   10.7    9.0
7      1  120   1   2.00   2.49   2.71   11.1   11.2   11.4
8      1  120   2   2.41   2.49   2.46   11.6   11.7    9.6
9      1  120   3   2.22   2.49   2.73   10.7   10.3   10.2
10     2  100   1   2.13   2.41   2.49   11.1   10.8   11.2
11     2  100   2   2.49   2.34   2.53   11.1   11.2    9.2
12     2  100   3   2.80   2.63   3.33    8.3    9.7    7.8
13     2  120   1   2.38   2.85   2.06   11.9   11.2   11.2
14     2  120   2   2.61   2.70   2.70   11.7   10.8   11.0
15     2  120   3   2.77   3.06   3.25   10.9    9.0    9.4
16     2  140   1   2.56   2.84   3.10   10.7   11.2    9.8
17     2  140   2   2.63   2.61   2.81   10.8   11.0   11.6
18     2  140   3   2.99   3.28   3.75    9.2    9.6    9.6
19     3  100   1   2.60   2.24   2.32   10.8    8.4   10.8
20     3  100   2   2.06   2.11   2.20   11.0   11.2   11.8
21     3  100   3   1.98   2.34   2.80   10.3   10.2   10.6
22     3  110   1   1.91   2.06   2.29   11.0   11.4    9.4
23     3  110   2   1.98   1.98   2.15   10.0   11.8   10.6
24     3  110   3   1.98   2.51   2.81    9.3    9.2   10.2
25     3  140   1   2.27   2.42   2.72   10.8   11.6   12.0
26     3  140   2   2.27   2.20   2.41   11.2   11.0   11.4
27     3  140   3   2.20   2.77   3.06   10.5   10.2   10.0

The failing model:
> lme(maill6 ~ water * temp  , random= ~1|rep, data = milk)
Error in MEEM(object, conLin, control$niterEM) : 
        Singularity in backsolve at level 0, block 1

The smaller (working) model:
> lme(maill6 ~ water + temp  , random= ~1|rep, data = milk)
Linear mixed-effects model fit by REML
  Data: milk 
  Log-restricted-likelihood: 4.922178
  Fixed: maill6 ~ water + temp 
(Intercept)      water2      water3     temp110     temp120    
temp140 
 2.19466667  0.32800000 -0.04533333  0.07800000  0.32133333 
0.35066667 

Random effects:
 Formula: ~1 | rep
        (Intercept)  Residual
StdDev:   0.1477760 0.1323057

Number of Observations: 27
Number of Groups: 3 
> 




CG Pettersson, MSci, PhD Stud.
Swedish University of Agricultural Sciences
Dep. of Ecology and Crop Production. Box 7043
SE-750 07 Uppsala



From cg.pettersson at evp.slu.se  Mon Feb 23 10:55:21 2004
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Mon, 23 Feb 2004 10:55:21 +0100
Subject: [R] Is there a /ddfm=satterth for R?
Message-ID: <200402230955.i1N9tLAA020120@mail1.slu.se>

Hello all!

When you are working with a little more complicated models in 
SAS PROC MIXED, you often use the /ddfm=satterth call to make sure 
the df decomposition is done the best way possible.

Running the same models in lme, without any special calls, results
in warning messages about the df handling. 

Is anybody out there working with something like the /ddfm=satterth?
It would be handy, or are there any reasons not to use it? 

/CG


CG Pettersson, MSci, PhD Stud.
Swedish University of Agricultural Sciences
Dep. of Ecology and Crop Production. Box 7043
SE-750 07 Uppsala



From gavin.simpson at ucl.ac.uk  Mon Feb 23 11:37:34 2004
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 23 Feb 2004 10:37:34 +0000
Subject: [R] plot(my.procrustes.model) from library {vegan}
In-Reply-To: <1077532835.2960.18.camel@monkey>
References: <1077532835.2960.18.camel@monkey>
Message-ID: <4039D7EE.90800@ucl.ac.uk>

Federico Calboli wrote:
> Dear All,
> 
> I would like to ask how to customize the graph corresponding to a
> procrustes analysis.
> 

<SNIP>

The object returned by procrustes() contains Yrot and X, the rotated 
matrix and the target matrix respectively. You could plot both of these 
using standard plotting tools. You'll need to make the axes have the 
same scale.

plot(mod.pro$Yrot, asp = 1)
points(mod.pro$X, col = "red", pch = 16)

Which seems to get you a similar plot to the one plot(mod.pro) produces.

> 
> Regards,
> 
> Federico Calboli 

HTH

Gavin



From f.calboli at ucl.ac.uk  Mon Feb 23 13:11:01 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 23 Feb 2004 12:11:01 +0000
Subject: [R] plot(my.procrustes.model) from library {vegan}
In-Reply-To: <1077533272.5671.6.camel@biol102145.oulu.fi>
References: <1077532835.2960.18.camel@monkey>
	<1077533272.5671.6.camel@biol102145.oulu.fi>
Message-ID: <1077538261.2960.44.camel@monkey>


> The `plot.procrustes' function really should be more user-friendly and
> flexible. You should contact its author and ask for amendments.

I honestly though my problem was too trival to bother the author in
person, and I thought that getting an answer would leave it in a public
database, as future reference. I hope I did not cause undue
inconvenience.

>  However,
> you have access to the internal results of the Procrustes analysis, and
> you can produce any kind of plots with them. The needed matrices are
> stored as items mod.pro$X and mod.pro$Yrot in your result object
> mod.pro. The  following should do what you asked for:
> 
> plot(mod.pro$X, asp=1, pch=1)
> points(mod.pro$Yrot, pch=2)
> segments(mod.pro$X[,1], mod.pro$X[,2], mod.pro$Yrot[,1],
> mod.pro$Yrot[,2])

The above solves my problem. Thanks for your help.

Best regards,

Federico Calboli


-- 



=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 251 208

f.calboli at ucl.ac.uk



From patrick.giraudoux at univ-fcomte.fr  Mon Feb 23 13:43:53 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Mon, 23 Feb 2004 13:43:53 +0100
Subject: [R] border of a polygon  in contour.kriging - geoR
Message-ID: <000e01c3fa0a$d59b7d60$4355fb51@PC728329681112>

Dear all,

When a conventional kriging and then a contour plot is limited with a polygon (as possible with krige.conv and contour.kriging), the
polygon border is displayed in black by default.

> kc<-krige.conv(CZdata,loc=pred.grid,borders=czpoly,krige=krige.control(obj.m=ls))
> plot(CZcoord,xlab="x",ylab="y",type="n",asp=1)
> contour(kc,loc=pred.grid,add=T)

I would like to be capable to get the contour lines only (limited by the polygon, but without the polygon border displayed). I tried
to pass the argument border=NULL, unsuccessfully:

> contour(kc,loc=pred.grid,add=T,border=NULL)
Error in contour(as.double(x), as.double(y), z, as.double(levels), labels,  :
        dimension mismatch
In addition: Warning message:
Replacement length not a multiple of the elements to replace in matrix(...)
>

Any hint?

Thanks in advance,

Patrick Giraudoux



From q.liu at unn.ac.uk  Mon Feb 23 13:49:19 2004
From: q.liu at unn.ac.uk (Qin Liu)
Date: Mon, 23 Feb 2004 12:49:19 -0000
Subject: [R] outputs of KNN prediction
Message-ID: <61B1A61B4F4AD711B3450008C791F6FA01BA1FF0@clearwater.unn.ac.uk>

Hello there:

I got 13 variables in my training/target set, the first 12 variables are
mixture of numerical and categorical variables. The last one is the one I
need
to predict, and it is a numerical variable.

>train<-read.table("train.txt")
>test<-read.table("test.txt")
>cl<-factor(train[,13])
>pred<-knn(train, test, clk=3, prob=TRUE)
>pred
I got output on the screen as following

 8.10832229  8.831127635 7.592870288 8.521782644 6.376726948 6.914730893
 9.71534911  8.658171785 6.104793232 7.247080585 6.298949247 5.105945474
 7.508238775 7.65396918  8.831127635 7.912056888 6.381816017 7.211556733

 276 levels ............

Then I tried to calculate a formula:(actual-pred)/actual, which includes
pred
values. However, I cannot do this even I convert the factors in pred to
vectors. Can anybody help??

Thank you very much indeed,

Qin



From anet-acqu-owner at mail.anet.ua.ac.be  Mon Feb 23 14:01:18 2004
From: anet-acqu-owner at mail.anet.ua.ac.be (anet-acqu-owner@mail.anet.ua.ac.be)
Date: Mon, 23 Feb 2004 14:01:18 +0100
Subject: [R] fake
Message-ID: <mailman.3.1077541278.1147.anet-acqu@mail.anet.ua.ac.be>

You are not allowed to post to this mailing list, and your message has
been automatically rejected.  If you think that your messages are
being rejected in error, contact the mailing list owner at
anet-acqu-owner at mail.anet.ua.ac.be.
-------------- next part --------------
An embedded message was scrubbed...
From: r-help at hypatia.math.ethz.ch
Subject: fake
Date: Mon, 23 Feb 2004 14:01:17 +0100
Size: 942
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040223/dc2890c7/attachment.mht

From tblackw at umich.edu  Mon Feb 23 14:01:45 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Mon, 23 Feb 2004 08:01:45 -0500 (EST)
Subject: [R] outputs of KNN prediction
In-Reply-To: <61B1A61B4F4AD711B3450008C791F6FA01BA1FF0@clearwater.unn.ac.uk>
References: <61B1A61B4F4AD711B3450008C791F6FA01BA1FF0@clearwater.unn.ac.uk>
Message-ID: <Pine.SOL.4.58.0402230758420.11898@robotron.gpcc.itd.umich.edu>

Qin  -

If you do  str(pred),  I think you will find that pred is
now a factor with 276 levels.  to convert it back into an
ordinary numeric vector, do

values <- as.numeric(as.character(pred))

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 23 Feb 2004, Qin Liu wrote:

> Hello there:
>
> I got 13 variables in my training/target set, the first 12 variables are
> mixture of numerical and categorical variables. The last one is the one I
> need
> to predict, and it is a numerical variable.
>
> >train<-read.table("train.txt")
> >test<-read.table("test.txt")
> >cl<-factor(train[,13])
> >pred<-knn(train, test, clk=3, prob=TRUE)
> >pred
> I got output on the screen as following
>
>  8.10832229  8.831127635 7.592870288 8.521782644 6.376726948 6.914730893
>  9.71534911  8.658171785 6.104793232 7.247080585 6.298949247 5.105945474
>  7.508238775 7.65396918  8.831127635 7.912056888 6.381816017 7.211556733
>
>  276 levels ............
>
> Then I tried to calculate a formula:(actual-pred)/actual, which includes
> pred
> values. However, I cannot do this even I convert the factors in pred to
> vectors. Can anybody help??
>
> Thank you very much indeed,
>
> Qin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Mon Feb 23 14:19:49 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 23 Feb 2004 08:19:49 -0500
Subject: [R] outputs of KNN prediction
Message-ID: <3A822319EB35174CA3714066D590DCD504AF782E@usrymx25.merck.com>

Sounds like you are trying to do k-NN regression (i.e., predict numeric
variable given others) with 12 predictors, some of which are categorical.
If so, you're quite possibly out of luck.  k-NN methods depend on distances,
and you need to have a distance that make sense for your problem and works
for mix of both numeric and categorical variables.  There are some (I
believe in the daisy() function in the `cluster' package has one), but no
knn functions that use anything but Euclidean distances (which only make
sense if all variables are numeric).

Even if all your predictors are numeric, you're probably going to have a
hard time finding a k-NN regressor that works in 12 dimensions (at least I
don't know of any implementation, in any language).

Cheers,
Andy

> From: Qin Liu
> 
> Hello there:
> 
> I got 13 variables in my training/target set, the first 12 
> variables are
> mixture of numerical and categorical variables. The last one 
> is the one I
> need
> to predict, and it is a numerical variable.
> 
> >train<-read.table("train.txt")
> >test<-read.table("test.txt")
> >cl<-factor(train[,13])
> >pred<-knn(train, test, clk=3, prob=TRUE)
> >pred
> I got output on the screen as following
> 
>  8.10832229  8.831127635 7.592870288 8.521782644 6.376726948 
> 6.914730893
>  9.71534911  8.658171785 6.104793232 7.247080585 6.298949247 
> 5.105945474
>  7.508238775 7.65396918  8.831127635 7.912056888 6.381816017 
> 7.211556733
> 
>  276 levels ............
> 
> Then I tried to calculate a formula:(actual-pred)/actual, 
> which includes
> pred
> values. However, I cannot do this even I convert the factors 
> in pred to
> vectors. Can anybody help??
> 
> Thank you very much indeed,
> 
> Qin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From bates at stat.wisc.edu  Mon Feb 23 14:26:39 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 23 Feb 2004 07:26:39 -0600
Subject: [R] lme - problems with model
In-Reply-To: <200402230952.i1N9qYAA018106@mail1.slu.se>
References: <200402230952.i1N9qYAA018106@mail1.slu.se>
Message-ID: <6rsmh2ylio.fsf@bates4.stat.wisc.edu>

CG Pettersson <cg.pettersson at evp.slu.se> writes:

> Hello all!
> 
> I?m working with some training datasets in a SAS-based course, trying
> to do the same things in lme that I do in PROC MIXED. 
> 
> Why don?t lme do an analysis on this dataset when I use the model
> water*temp?
> The trouble comes from the water:temp term, as it works with
> water+temp.
> The data are, indeed, assymetric but lm accepts the water:temp term
> giving results in the F-test near what PROC MIXED produces. MIXED
> accepts the model.
> 
> The water:temp term can be removed from the model according to the
> F-test in SAS (and to the lm model without any random term). Doing so
> in both MIXED and lme gives reasonably similar results for both
> systems.
> 
> What do the error message mean, and how can I get around this?

Because of missing cells in the design

> xtabs(~water + temp, milk)
     temp
water 100 110 120 140
    1 3   3   3   0  
    2 3   0   3   3  
    3 3   3   0   3  

the model matrix for the fixed effects is rank deficient.  In lm the
rank deficiency is detected and appropriate adjustments made

> coef(summary(lm(maill6 ~ water * temp, milk)))
                  Estimate Std. Error    t value     Pr(>|t|)
(Intercept)     2.17666667  0.1142339 19.0544730 2.218661e-13
water2          0.28333333  0.1615511  1.7538308 9.647013e-02
water3          0.05333333  0.1615511  0.3301329 7.451108e-01
temp110         0.14000000  0.1615511  0.8665987 3.975669e-01
temp120         0.31333333  0.1615511  1.9395305 6.827304e-02
temp140         0.23333333  0.1615511  1.4443312 1.658280e-01
water3:temp110 -0.18666667  0.2284678 -0.8170371 4.245898e-01
water2:temp120  0.09666667  0.2284678  0.4231085 6.772282e-01
water2:temp140  0.21666667  0.2284678  0.9483467 3.555125e-01

Notice that you would expect 6 degrees of freedom for the interaction
term but only three coefficients are estimated.

In lme it is much more difficult to compensate for such rank
deficiencies because they could be systematic, like this, or they
could be due to relative precision parameters approaching zero during
the iterations.  Because of this we just report the error (although
admittedly we could be a bit more explicit about the nature of the
problem - we are reporting the symptom that we detect, not the
probable cause).


> The dataset:
> > milk
>    water temp rep maill4 maill6 maill8 taste4 taste6 taste8
> 1      1  100   1   2.90   2.13   2.39   10.1   10.0    9.6
> 2      1  100   2   2.19   2.20   2.27   11.0    9.3   11.0
> 3      1  100   3   2.13   2.20   2.41   10.1    7.0    9.6
> 4      1  110   1   2.13   2.34   2.41   11.0   10.5    9.8
> 5      1  110   2   2.32   2.27   2.25   11.0   11.3   11.2
> 6      1  110   3   2.13   2.34   2.42    9.4   10.7    9.0
> 7      1  120   1   2.00   2.49   2.71   11.1   11.2   11.4
> 8      1  120   2   2.41   2.49   2.46   11.6   11.7    9.6
> 9      1  120   3   2.22   2.49   2.73   10.7   10.3   10.2
> 10     2  100   1   2.13   2.41   2.49   11.1   10.8   11.2
> 11     2  100   2   2.49   2.34   2.53   11.1   11.2    9.2
> 12     2  100   3   2.80   2.63   3.33    8.3    9.7    7.8
> 13     2  120   1   2.38   2.85   2.06   11.9   11.2   11.2
> 14     2  120   2   2.61   2.70   2.70   11.7   10.8   11.0
> 15     2  120   3   2.77   3.06   3.25   10.9    9.0    9.4
> 16     2  140   1   2.56   2.84   3.10   10.7   11.2    9.8
> 17     2  140   2   2.63   2.61   2.81   10.8   11.0   11.6
> 18     2  140   3   2.99   3.28   3.75    9.2    9.6    9.6
> 19     3  100   1   2.60   2.24   2.32   10.8    8.4   10.8
> 20     3  100   2   2.06   2.11   2.20   11.0   11.2   11.8
> 21     3  100   3   1.98   2.34   2.80   10.3   10.2   10.6
> 22     3  110   1   1.91   2.06   2.29   11.0   11.4    9.4
> 23     3  110   2   1.98   1.98   2.15   10.0   11.8   10.6
> 24     3  110   3   1.98   2.51   2.81    9.3    9.2   10.2
> 25     3  140   1   2.27   2.42   2.72   10.8   11.6   12.0
> 26     3  140   2   2.27   2.20   2.41   11.2   11.0   11.4
> 27     3  140   3   2.20   2.77   3.06   10.5   10.2   10.0
> 
> The failing model:
> > lme(maill6 ~ water * temp  , random= ~1|rep, data = milk)
> Error in MEEM(object, conLin, control$niterEM) : 
>         Singularity in backsolve at level 0, block 1
> 
> The smaller (working) model:
> > lme(maill6 ~ water + temp  , random= ~1|rep, data = milk)
> Linear mixed-effects model fit by REML
>   Data: milk 
>   Log-restricted-likelihood: 4.922178
>   Fixed: maill6 ~ water + temp 
> (Intercept)      water2      water3     temp110     temp120    
> temp140 
>  2.19466667  0.32800000 -0.04533333  0.07800000  0.32133333 
> 0.35066667 
> 
> Random effects:
>  Formula: ~1 | rep
>         (Intercept)  Residual
> StdDev:   0.1477760 0.1323057
> 
> Number of Observations: 27
> Number of Groups: 3 
> > 
> 
> 
> 
> 
> CG Pettersson, MSci, PhD Stud.
> Swedish University of Agricultural Sciences
> Dep. of Ecology and Crop Production. Box 7043
> SE-750 07 Uppsala
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From steve.roberts at man.ac.uk  Mon Feb 23 14:37:21 2004
From: steve.roberts at man.ac.uk (Steve Roberts)
Date: Mon, 23 Feb 2004 13:37:21 +0000
Subject: [R] DLLs and the Floating Point Control Word.
Message-ID: <403A0211.10600.431AB9@localhost>

Greetings. 

One for the developers I guess...  I am having problems in using a 
(non-recommended) Fortran compiler (Salford ftn95 Windoze), and 
the crashes do seem to be associated with the ftn95-dervived DLL 
changing the Floating Point Control Word. The compiler people are 
suggesting (and I paraphrase!) that if R minds what the FPCW is it 
is up to R to make sure it is the value it wants and R should 
check/reset on returning from the DLL call. There seems to me to 
be some logic in this position - if only to make life easier for those 
of us who don't really know what a FPCW is! Having to add 
unintelligable code to reset the FPCW at the end of each fortran 
routine is inelegant. It probably isn't as easy as it sounds  - I guess 
there are multi-platform issues? Is this a sensible suggestion to 
add to the wish list?

Keep up the good work

Steve.
  Dr Steve Roberts 
  steve.roberts at man.ac.uk

Senior Lecturer in Medical Statistics,
CMMCH NHS Trust and University of Manchester Biostatistics Group,
0161 275 5192 / 0161 276 5785



From Jens_Praestgaard at hgsi.com  Mon Feb 23 14:38:18 2004
From: Jens_Praestgaard at hgsi.com (Jens_Praestgaard@hgsi.com)
Date: Mon, 23 Feb 2004 08:38:18 -0500
Subject: [R] Question concerning functions nlsList and nlme from nlme R
	library. 
Message-ID: <OFF3BF2666.456D40D7-ON85256E43.004A4AE4-85256E43.004AEAF0@hgsi.com>

I hope that the mailing list is the correct forum for the question below. I
have trouble calling functions nlsList and nlme from
another function. Any help would be greatly appreciated.

Jens Praestgaard
Human Genome Sciences
Rockville MD.



I have a data set v with two components, v$mixeddat and v$init. They are
listed below:

> v$mixeddat
           conc result rep sample z
11  20.00000000  11141   1 vial 1 0
12   5.00000000  11446   1 vial 1 0
13   1.25000000  13377   1 vial 1 0
14   0.31250000  20267   1 vial 1 0
15   0.07812500  48852   1 vial 1 0
16   0.01953125 118507   1 vial 1 0

(and so on)

> v$init
           a            b            d            c        cdiff
1.045617e+04 2.408045e+05 9.296929e-01 1.490621e-02 4.874540e-03

The following two lines of code fits first a nonlinear regression for each
level of rep, next a model with a random effect in one parameter.

> fit<-nlsList(result~a+(b-a)/(1+(conc/(c+z*cdiff))^d)
|rep,start=v$init,data=v$mixeddat)
> nlme(fit,random=(b~1))


However, when I try to run the same code  from within a function, with this
call :

> testfunc
function(dat=v) {
test<-nlsList(result~a+(b-a)/(1+(conc/(c+z*cdiff))^d)
|rep,start=dat$init,data=dat$mixeddat)
return(nlme(test,random=b~1))
}

testfunc()

then I get the error message

Error in eval(expr, envir, enclos) : Object "result" not found



 Any help would be appreciated



From paulojus at est.ufpr.br  Mon Feb 23 14:51:05 2004
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Mon, 23 Feb 2004 10:51:05 -0300 (BRT)
Subject: [R] border of a polygon  in contour.kriging - geoR
In-Reply-To: <000e01c3fa0a$d59b7d60$4355fb51@PC728329681112>
References: <000e01c3fa0a$d59b7d60$4355fb51@PC728329681112>
Message-ID: <Pine.LNX.4.58L0.0402231049350.23803@est.ufpr.br>

Dear Patrick

border=NULL should work but there is a bug.
I'm fixing this right now and a new version will be available later today

P.J.

On Mon, 23 Feb 2004, Patrick Giraudoux wrote:

> Dear all,
>
> When a conventional kriging and then a contour plot is limited with a polygon (as possible with krige.conv and contour.kriging), the
> polygon border is displayed in black by default.
>
> > kc<-krige.conv(CZdata,loc=pred.grid,borders=czpoly,krige=krige.control(obj.m=ls))
> > plot(CZcoord,xlab="x",ylab="y",type="n",asp=1)
> > contour(kc,loc=pred.grid,add=T)
>
> I would like to be capable to get the contour lines only (limited by the polygon, but without the polygon border displayed). I tried
> to pass the argument border=NULL, unsuccessfully:
>
> > contour(kc,loc=pred.grid,add=T,border=NULL)
> Error in contour(as.double(x), as.double(y), z, as.double(levels), labels,  :
>         dimension mismatch
> In addition: Warning message:
> Replacement length not a multiple of the elements to replace in matrix(...)
> >
>
> Any hint?
>
> Thanks in advance,
>
> Patrick Giraudoux
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From Anthony_Lancaster at brown.edu  Mon Feb 23 15:25:16 2004
From: Anthony_Lancaster at brown.edu (Tony Lancaster)
Date: Mon, 23 Feb 2004 09:25:16 -0500
Subject: [R] Re: R for economists
Message-ID: <000b01c3fa18$db5a8e90$e43d9480@econ.brown.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040223/2afbe529/attachment.pl

From dmurdoch at pair.com  Mon Feb 23 15:47:16 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 23 Feb 2004 09:47:16 -0500
Subject: [R] DLLs and the Floating Point Control Word.
In-Reply-To: <403A0211.10600.431AB9@localhost>
References: <403A0211.10600.431AB9@localhost>
Message-ID: <kf3k30hbak1trkmrtq2o2p538j30vus31h@4ax.com>

On Mon, 23 Feb 2004 13:37:21 +0000, "Steve Roberts"
<steve.roberts at man.ac.uk> wrote :

>Greetings. 
>
>One for the developers I guess...  I am having problems in using a 
>(non-recommended) Fortran compiler (Salford ftn95 Windoze), and 
>the crashes do seem to be associated with the ftn95-dervived DLL 
>changing the Floating Point Control Word. The compiler people are 
>suggesting (and I paraphrase!) that if R minds what the FPCW is it 
>is up to R to make sure it is the value it wants and R should 
>check/reset on returning from the DLL call. 

I doubt if the FPCW would be enough to cause a crash, but there are
other assumptions R makes that would cause a crash if they were
violated.  In particular, if your compiler sometimes messes up some of
the other registers that are assumed to be preserved, then there would
be trouble.

These kind of crashes are hard to diagnose, because they need someone
familiar with both R and the compiler in question at a very low level.
If the Salford people aren't willing to help with it, then you should
probably look for a different compiler.

>There seems to me to 
>be some logic in this position - if only to make life easier for those 
>of us who don't really know what a FPCW is! Having to add 
>unintelligable code to reset the FPCW at the end of each fortran 
>routine is inelegant. It probably isn't as easy as it sounds  - I guess 
>there are multi-platform issues? Is this a sensible suggestion to 
>add to the wish list?

Most compilers can produce libraries that are compliant with R's
needs, so this would be a pretty low priority.  If you know someone
who wants to write the code, and it doesn't impact on compliant users,
I'd be willing to take a look.  

Duncan Murdoch



From cg.pettersson at evp.slu.se  Mon Feb 23 16:20:10 2004
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Mon, 23 Feb 2004 16:20:10 +0100
Subject: [R] lme - problems with model
In-Reply-To: <6rsmh2ylio.fsf@bates4.stat.wisc.edu>
Message-ID: <200402231520.i1NFKBAA015816@mail1.slu.se>

Thanks a lot for the answer!

Now, I only have the last one left - How do I get round it?
I knew about the missing cells in the design, but didn?t know how lme
would react on them.

In this case, I can remove the water:temp term, but how can I be sure
that this is the right thing to do?

Is the lm run without the random term enough for removing water:temp
from the lme model, or do I have to do a PROC MIXED run with the
random term to make that decision in a case like this? 

Is it possible (for me)  to understand why MIXED accepts the design
but not lme? They ought to get the same sort of problems, or have I
missed something?

/CG

-------------------
> CG Pettersson <cg.pettersson at evp.slu.se> writes:
> 
> > Hello all!
> > 
> > I?m working with some training datasets in a SAS-based course,
trying
> > to do the same things in lme that I do in PROC MIXED. 
> > 
> > Why don?t lme do an analysis on this dataset when I use the model
> > water*temp?
> > The trouble comes from the water:temp term, as it works with
> > water+temp.
> > The data are, indeed, assymetric but lm accepts the water:temp
term
> > giving results in the F-test near what PROC MIXED produces. MIXED
> > accepts the model.
> > 
> > The water:temp term can be removed from the model according to the
> > F-test in SAS (and to the lm model without any random term). Doing
so
> > in both MIXED and lme gives reasonably similar results for both
> > systems.
> > 
> > What do the error message mean, and how can I get around this?
> 
> Because of missing cells in the design
> 
> > xtabs(~water + temp, milk)
>      temp
> water 100 110 120 140
>     1 3   3   3   0  
>     2 3   0   3   3  
>     3 3   3   0   3  
> 
> the model matrix for the fixed effects is rank deficient.  In lm the
> rank deficiency is detected and appropriate adjustments made
> 
> > coef(summary(lm(maill6 ~ water * temp, milk)))
>                   Estimate Std. Error    t value     Pr(>|t|)
> (Intercept)     2.17666667  0.1142339 19.0544730 2.218661e-13
> water2          0.28333333  0.1615511  1.7538308 9.647013e-02
> water3          0.05333333  0.1615511  0.3301329 7.451108e-01
> temp110         0.14000000  0.1615511  0.8665987 3.975669e-01
> temp120         0.31333333  0.1615511  1.9395305 6.827304e-02
> temp140         0.23333333  0.1615511  1.4443312 1.658280e-01
> water3:temp110 -0.18666667  0.2284678 -0.8170371 4.245898e-01
> water2:temp120  0.09666667  0.2284678  0.4231085 6.772282e-01
> water2:temp140  0.21666667  0.2284678  0.9483467 3.555125e-01
> 
> Notice that you would expect 6 degrees of freedom for the
interaction
> term but only three coefficients are estimated.
> 
> In lme it is much more difficult to compensate for such rank
> deficiencies because they could be systematic, like this, or they
> could be due to relative precision parameters approaching zero
during
> the iterations.  Because of this we just report the error (although
> admittedly we could be a bit more explicit about the nature of the
> problem - we are reporting the symptom that we detect, not the
> probable cause).
> 
> 
> > The dataset:
> > > milk
> >    water temp rep maill4 maill6 maill8 taste4 taste6 taste8
> > 1      1  100   1   2.90   2.13   2.39   10.1   10.0    9.6
> > 2      1  100   2   2.19   2.20   2.27   11.0    9.3   11.0
> > 3      1  100   3   2.13   2.20   2.41   10.1    7.0    9.6
> > 4      1  110   1   2.13   2.34   2.41   11.0   10.5    9.8
> > 5      1  110   2   2.32   2.27   2.25   11.0   11.3   11.2
> > 6      1  110   3   2.13   2.34   2.42    9.4   10.7    9.0
> > 7      1  120   1   2.00   2.49   2.71   11.1   11.2   11.4
> > 8      1  120   2   2.41   2.49   2.46   11.6   11.7    9.6
> > 9      1  120   3   2.22   2.49   2.73   10.7   10.3   10.2
> > 10     2  100   1   2.13   2.41   2.49   11.1   10.8   11.2
> > 11     2  100   2   2.49   2.34   2.53   11.1   11.2    9.2
> > 12     2  100   3   2.80   2.63   3.33    8.3    9.7    7.8
> > 13     2  120   1   2.38   2.85   2.06   11.9   11.2   11.2
> > 14     2  120   2   2.61   2.70   2.70   11.7   10.8   11.0
> > 15     2  120   3   2.77   3.06   3.25   10.9    9.0    9.4
> > 16     2  140   1   2.56   2.84   3.10   10.7   11.2    9.8
> > 17     2  140   2   2.63   2.61   2.81   10.8   11.0   11.6
> > 18     2  140   3   2.99   3.28   3.75    9.2    9.6    9.6
> > 19     3  100   1   2.60   2.24   2.32   10.8    8.4   10.8
> > 20     3  100   2   2.06   2.11   2.20   11.0   11.2   11.8
> > 21     3  100   3   1.98   2.34   2.80   10.3   10.2   10.6
> > 22     3  110   1   1.91   2.06   2.29   11.0   11.4    9.4
> > 23     3  110   2   1.98   1.98   2.15   10.0   11.8   10.6
> > 24     3  110   3   1.98   2.51   2.81    9.3    9.2   10.2
> > 25     3  140   1   2.27   2.42   2.72   10.8   11.6   12.0
> > 26     3  140   2   2.27   2.20   2.41   11.2   11.0   11.4
> > 27     3  140   3   2.20   2.77   3.06   10.5   10.2   10.0
> > 
> > The failing model:
> > > lme(maill6 ~ water * temp  , random= ~1|rep, data = milk)
> > Error in MEEM(object, conLin, control$niterEM) : 
> >         Singularity in backsolve at level 0, block 1
> > 
> > The smaller (working) model:
> > > lme(maill6 ~ water + temp  , random= ~1|rep, data = milk)
> > Linear mixed-effects model fit by REML
> >   Data: milk 
> >   Log-restricted-likelihood: 4.922178
> >   Fixed: maill6 ~ water + temp 
> > (Intercept)      water2      water3     temp110     temp120    
> > temp140 
> >  2.19466667  0.32800000 -0.04533333  0.07800000  0.32133333 
> > 0.35066667 
> > 
> > Random effects:
> >  Formula: ~1 | rep
> >         (Intercept)  Residual
> > StdDev:   0.1477760 0.1323057
> > 
> > Number of Observations: 27
> > Number of Groups: 3 
> > > 
> > 
> > 
> > 
> > 
> > CG Pettersson, MSci, PhD Stud.
> > Swedish University of Agricultural Sciences
> > Dep. of Ecology and Crop Production. Box 7043
> > SE-750 07 Uppsala
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> 
> -- 
> Douglas Bates                            bates at stat.wisc.edu
> Statistics Department                    608/262-2598
> University of Wisconsin - Madison       
http://www.stat.wisc.edu/~bates/
> 
CG Pettersson, MSci, PhD Stud.
Swedish University of Agricultural Sciences
Dep. of Ecology and Crop Production. Box 7043
SE-750 07 Uppsala



From spencer.graves at pdf.com  Mon Feb 23 16:41:07 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 23 Feb 2004 07:41:07 -0800
Subject: [R] lme - problems with model
In-Reply-To: <200402231520.i1NFKBAA015816@mail1.slu.se>
References: <200402231520.i1NFKBAA015816@mail1.slu.se>
Message-ID: <403A1F13.7000008@pdf.com>

      If you want to try to get the same answers as PROC MIXED, I 
suggest you try to figure out how SAS codes interactions and which ones 
it retains.  Then you can try code those manually and include them as 
separate explanatory variables, e.g., I((water=="2")&(temp==110)).  You 
could work this out in "lm" then try the result on "lme". 

      An alternative would be to convert "temp" from a factor to a 
continuous variable.  I would make plots of the response variables vs. 
"temp" with different lines and symbols for "water" and "rep" to make 
sure I had something that was mostly linear in some transformation of 
"temp". 

      hope this helps. 
      spencer graves

CG Pettersson wrote:

>Thanks a lot for the answer!
>
>Now, I only have the last one left - How do I get round it?
>I knew about the missing cells in the design, but didn?t know how lme
>would react on them.
>
>In this case, I can remove the water:temp term, but how can I be sure
>that this is the right thing to do?
>
>Is the lm run without the random term enough for removing water:temp
>from the lme model, or do I have to do a PROC MIXED run with the
>random term to make that decision in a case like this? 
>
>Is it possible (for me)  to understand why MIXED accepts the design
>but not lme? They ought to get the same sort of problems, or have I
>missed something?
>
>/CG
>
>-------------------
>  
>
>>CG Pettersson <cg.pettersson at evp.slu.se> writes:
>>
>>    
>>
>>>Hello all!
>>>
>>>I?m working with some training datasets in a SAS-based course,
>>>      
>>>
>trying
>  
>
>>>to do the same things in lme that I do in PROC MIXED. 
>>>
>>>Why don?t lme do an analysis on this dataset when I use the model
>>>water*temp?
>>>The trouble comes from the water:temp term, as it works with
>>>water+temp.
>>>The data are, indeed, assymetric but lm accepts the water:temp
>>>      
>>>
>term
>  
>
>>>giving results in the F-test near what PROC MIXED produces. MIXED
>>>accepts the model.
>>>
>>>The water:temp term can be removed from the model according to the
>>>F-test in SAS (and to the lm model without any random term). Doing
>>>      
>>>
>so
>  
>
>>>in both MIXED and lme gives reasonably similar results for both
>>>systems.
>>>
>>>What do the error message mean, and how can I get around this?
>>>      
>>>
>>Because of missing cells in the design
>>
>>    
>>
>>>xtabs(~water + temp, milk)
>>>      
>>>
>>     temp
>>water 100 110 120 140
>>    1 3   3   3   0  
>>    2 3   0   3   3  
>>    3 3   3   0   3  
>>
>>the model matrix for the fixed effects is rank deficient.  In lm the
>>rank deficiency is detected and appropriate adjustments made
>>
>>    
>>
>>>coef(summary(lm(maill6 ~ water * temp, milk)))
>>>      
>>>
>>                  Estimate Std. Error    t value     Pr(>|t|)
>>(Intercept)     2.17666667  0.1142339 19.0544730 2.218661e-13
>>water2          0.28333333  0.1615511  1.7538308 9.647013e-02
>>water3          0.05333333  0.1615511  0.3301329 7.451108e-01
>>temp110         0.14000000  0.1615511  0.8665987 3.975669e-01
>>temp120         0.31333333  0.1615511  1.9395305 6.827304e-02
>>temp140         0.23333333  0.1615511  1.4443312 1.658280e-01
>>water3:temp110 -0.18666667  0.2284678 -0.8170371 4.245898e-01
>>water2:temp120  0.09666667  0.2284678  0.4231085 6.772282e-01
>>water2:temp140  0.21666667  0.2284678  0.9483467 3.555125e-01
>>
>>Notice that you would expect 6 degrees of freedom for the
>>    
>>
>interaction
>  
>
>>term but only three coefficients are estimated.
>>
>>In lme it is much more difficult to compensate for such rank
>>deficiencies because they could be systematic, like this, or they
>>could be due to relative precision parameters approaching zero
>>    
>>
>during
>  
>
>>the iterations.  Because of this we just report the error (although
>>admittedly we could be a bit more explicit about the nature of the
>>problem - we are reporting the symptom that we detect, not the
>>probable cause).
>>
>>
>>    
>>
>>>The dataset:
>>>      
>>>
>>>>milk
>>>>        
>>>>
>>>   water temp rep maill4 maill6 maill8 taste4 taste6 taste8
>>>1      1  100   1   2.90   2.13   2.39   10.1   10.0    9.6
>>>2      1  100   2   2.19   2.20   2.27   11.0    9.3   11.0
>>>3      1  100   3   2.13   2.20   2.41   10.1    7.0    9.6
>>>4      1  110   1   2.13   2.34   2.41   11.0   10.5    9.8
>>>5      1  110   2   2.32   2.27   2.25   11.0   11.3   11.2
>>>6      1  110   3   2.13   2.34   2.42    9.4   10.7    9.0
>>>7      1  120   1   2.00   2.49   2.71   11.1   11.2   11.4
>>>8      1  120   2   2.41   2.49   2.46   11.6   11.7    9.6
>>>9      1  120   3   2.22   2.49   2.73   10.7   10.3   10.2
>>>10     2  100   1   2.13   2.41   2.49   11.1   10.8   11.2
>>>11     2  100   2   2.49   2.34   2.53   11.1   11.2    9.2
>>>12     2  100   3   2.80   2.63   3.33    8.3    9.7    7.8
>>>13     2  120   1   2.38   2.85   2.06   11.9   11.2   11.2
>>>14     2  120   2   2.61   2.70   2.70   11.7   10.8   11.0
>>>15     2  120   3   2.77   3.06   3.25   10.9    9.0    9.4
>>>16     2  140   1   2.56   2.84   3.10   10.7   11.2    9.8
>>>17     2  140   2   2.63   2.61   2.81   10.8   11.0   11.6
>>>18     2  140   3   2.99   3.28   3.75    9.2    9.6    9.6
>>>19     3  100   1   2.60   2.24   2.32   10.8    8.4   10.8
>>>20     3  100   2   2.06   2.11   2.20   11.0   11.2   11.8
>>>21     3  100   3   1.98   2.34   2.80   10.3   10.2   10.6
>>>22     3  110   1   1.91   2.06   2.29   11.0   11.4    9.4
>>>23     3  110   2   1.98   1.98   2.15   10.0   11.8   10.6
>>>24     3  110   3   1.98   2.51   2.81    9.3    9.2   10.2
>>>25     3  140   1   2.27   2.42   2.72   10.8   11.6   12.0
>>>26     3  140   2   2.27   2.20   2.41   11.2   11.0   11.4
>>>27     3  140   3   2.20   2.77   3.06   10.5   10.2   10.0
>>>
>>>The failing model:
>>>      
>>>
>>>>lme(maill6 ~ water * temp  , random= ~1|rep, data = milk)
>>>>        
>>>>
>>>Error in MEEM(object, conLin, control$niterEM) : 
>>>        Singularity in backsolve at level 0, block 1
>>>
>>>The smaller (working) model:
>>>      
>>>
>>>>lme(maill6 ~ water + temp  , random= ~1|rep, data = milk)
>>>>        
>>>>
>>>Linear mixed-effects model fit by REML
>>>  Data: milk 
>>>  Log-restricted-likelihood: 4.922178
>>>  Fixed: maill6 ~ water + temp 
>>>(Intercept)      water2      water3     temp110     temp120    
>>>temp140 
>>> 2.19466667  0.32800000 -0.04533333  0.07800000  0.32133333 
>>>0.35066667 
>>>
>>>Random effects:
>>> Formula: ~1 | rep
>>>        (Intercept)  Residual
>>>StdDev:   0.1477760 0.1323057
>>>
>>>Number of Observations: 27
>>>Number of Groups: 3 
>>>      
>>>
>>>
>>>
>>>CG Pettersson, MSci, PhD Stud.
>>>Swedish University of Agricultural Sciences
>>>Dep. of Ecology and Crop Production. Box 7043
>>>SE-750 07 Uppsala
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>>      
>>>
>http://www.R-project.org/posting-guide.html
>  
>
>>-- 
>>Douglas Bates                            bates at stat.wisc.edu
>>Statistics Department                    608/262-2598
>>University of Wisconsin - Madison       
>>    
>>
>http://www.stat.wisc.edu/~bates/
>  
>
>CG Pettersson, MSci, PhD Stud.
>Swedish University of Agricultural Sciences
>Dep. of Ecology and Crop Production. Box 7043
>SE-750 07 Uppsala
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From heberto.ghezzo at mcgill.ca  Mon Feb 23 16:55:50 2004
From: heberto.ghezzo at mcgill.ca (r.ghezzo)
Date: Mon, 23 Feb 2004 10:55:50 -0500
Subject: [R] problem with unlist
Message-ID: <403A2286.6000600@mcgill.ca>

Hello, I try to compute means,sd,n from a variable y according to some 
categoricals g1,g2... I wrote the following function:
msd<-function(y,...) {
    print(match.call())
    funy<-function(x) list(mean(x,na.rm=T),sd(x,na.rm=T),table(is.na(x))[1])
    gg <- list(...)
    aa<-by(y,gg,funy)
    bb<-matrix(unlist(aa),nrow=3)
    bb
}
this works OK so far there is no empty cell in the crosstab, if there 
is, the unlist statement just run over it and I do not know which cell 
is missing, any attempt to label the columns in matrix bb then fail.
Can somebody suggest a method to retrive the list names from aa to label 
the columns of the matrix bb?
Thanks for any help
Heberto Ghezzo
McGill University
Montreal Canada



From rodrigo.abt at sii.cl  Mon Feb 23 16:57:15 2004
From: rodrigo.abt at sii.cl (Rodrigo Abt)
Date: Mon, 23 Feb 2004 12:57:15 -0300
Subject: [R] Error in multiple xyplots
Message-ID: <000001c3fa25$b5dd77b0$2a01240a@rodrigoabt>

Dear R-listers,

I got an error when I try to plot two grouped data into a single
win.metafile device:

library(lattice)
trellis.device(device="win.metafile",color=F,filename="Profiles-Var1.wmf")
par(mfrow=c(1,2))

# First plot
xyplot(log(v)~t|id,data=Con.20,
main="Group A: Control, Var-1",
xlab="ocasion",ylab="var1",
panel=function(x,y) {
	m<-sort.list(x)
	panel.grid()
	panel.xyplot(x[m],y[m],type="b",cex=0.8)
	}
)

# Second plot
xyplot(log(v)~t|id,data=Trt.20,
main="Group B: Treat, Var-1",
xlab="ocasion",ylab="var1",
panel=function(x,y) {
	m<-sort.list(x)
	panel.grid()
	panel.xyplot(x[m],y[m],type="b",cex=0.8)
	}
)

When then last plot is entered, a messagebox pops up an says "Unable to
create metafile", and R shutdowns. However, if I use simple plots instead of
xyplots, then it works:

trellis.device(device="win.metafile",color=F,filename="Simple-Plots.wmf")
par(mfrow=c(1,2))

# First plot
plot(1:10,rnorm(10),main="Plot 1")

# Second plot
plot(1:10,rnorm(10),main="Plot 2")

No error, so I call dev.off() and the file generated is OK.

I tried plotting the data in separate 'win.metafile' devices (files) and
worked perfect. I've read the R help, googled around and searched the R-list
for a similar problem and found nothing...any clues ?

I'm working with win2K and R-1.8.1.

Regards,

Rodrigo Abt B,
Analyst,
Dept. Economic Studies,
SII, Chile.



From andy_liaw at merck.com  Mon Feb 23 17:03:14 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 23 Feb 2004 11:03:14 -0500
Subject: [R] problem with unlist
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7835@usrymx25.merck.com>

Why not just do:

tapply(y, list(g1, g2, ...), function(x) c(mean=mean(x, na.rm=TRUE),
sd=sd(x, na.rm=TRUE), n=sum(!is.na(x))))

??

Andy

> From: r.ghezzo
> 
> Hello, I try to compute means,sd,n from a variable y 
> according to some 
> categoricals g1,g2... I wrote the following function:
> msd<-function(y,...) {
>     print(match.call())
>     funy<-function(x) 
> list(mean(x,na.rm=T),sd(x,na.rm=T),table(is.na(x))[1])
>     gg <- list(...)
>     aa<-by(y,gg,funy)
>     bb<-matrix(unlist(aa),nrow=3)
>     bb
> }
> this works OK so far there is no empty cell in the crosstab, if there 
> is, the unlist statement just run over it and I do not know 
> which cell 
> is missing, any attempt to label the columns in matrix bb then fail.
> Can somebody suggest a method to retrive the list names from 
> aa to label 
> the columns of the matrix bb?
> Thanks for any help
> Heberto Ghezzo
> McGill University
> Montreal Canada
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From rpeng at jhsph.edu  Mon Feb 23 17:16:12 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 23 Feb 2004 11:16:12 -0500
Subject: [R] Error in multiple xyplots
In-Reply-To: <000001c3fa25$b5dd77b0$2a01240a@rodrigoabt>
References: <000001c3fa25$b5dd77b0$2a01240a@rodrigoabt>
Message-ID: <403A274C.2070707@jhsph.edu>

You cannot use par(), which is part of the base graphics system, with 
xyplot(), which is part of the lattice/grid system.  If you want to 
combine base-graphics with lattice/grid you need to use the `gridBase' 
package on CRAN.

-roger

Rodrigo Abt wrote:
> Dear R-listers,
> 
> I got an error when I try to plot two grouped data into a single
> win.metafile device:
> 
> library(lattice)
> trellis.device(device="win.metafile",color=F,filename="Profiles-Var1.wmf")
> par(mfrow=c(1,2))
> 
> # First plot
> xyplot(log(v)~t|id,data=Con.20,
> main="Group A: Control, Var-1",
> xlab="ocasion",ylab="var1",
> panel=function(x,y) {
> 	m<-sort.list(x)
> 	panel.grid()
> 	panel.xyplot(x[m],y[m],type="b",cex=0.8)
> 	}
> )
> 
> # Second plot
> xyplot(log(v)~t|id,data=Trt.20,
> main="Group B: Treat, Var-1",
> xlab="ocasion",ylab="var1",
> panel=function(x,y) {
> 	m<-sort.list(x)
> 	panel.grid()
> 	panel.xyplot(x[m],y[m],type="b",cex=0.8)
> 	}
> )
> 
> When then last plot is entered, a messagebox pops up an says "Unable to
> create metafile", and R shutdowns. However, if I use simple plots instead of
> xyplots, then it works:
> 
> trellis.device(device="win.metafile",color=F,filename="Simple-Plots.wmf")
> par(mfrow=c(1,2))
> 
> # First plot
> plot(1:10,rnorm(10),main="Plot 1")
> 
> # Second plot
> plot(1:10,rnorm(10),main="Plot 2")
> 
> No error, so I call dev.off() and the file generated is OK.
> 
> I tried plotting the data in separate 'win.metafile' devices (files) and
> worked perfect. I've read the R help, googled around and searched the R-list
> for a similar problem and found nothing...any clues ?
> 
> I'm working with win2K and R-1.8.1.
> 
> Regards,
> 
> Rodrigo Abt B,
> Analyst,
> Dept. Economic Studies,
> SII, Chile.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From deepayan at stat.wisc.edu  Mon Feb 23 17:17:58 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 23 Feb 2004 10:17:58 -0600
Subject: [R] Error in multiple xyplots
In-Reply-To: <000001c3fa25$b5dd77b0$2a01240a@rodrigoabt>
References: <000001c3fa25$b5dd77b0$2a01240a@rodrigoabt>
Message-ID: <200402231017.58237.deepayan@stat.wisc.edu>


On Monday 23 February 2004 09:57, Rodrigo Abt wrote:
> Dear R-listers,
>
> I got an error when I try to plot two grouped data into a single
> win.metafile device:
>
> library(lattice)
> trellis.device(device="win.metafile",color=F,filename="Profiles-Var1.wmf
>") par(mfrow=c(1,2))

par() settings have (mostly) no effect in lattice plots. In particular, 
mfrow is ignored. Read help(print.trellis) and run example(print.trellis) 
to learn how to do what you want to do.

Deepayan



From jonathan_wang at sbcglobal.net  Mon Feb 23 18:12:25 2004
From: jonathan_wang at sbcglobal.net (Jonathan Wang)
Date: Mon, 23 Feb 2004 09:12:25 -0800 (PST)
Subject: [R] Simulation Help
Message-ID: <20040223171225.35369.qmail@web80605.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040223/95c4b6fe/attachment.pl

From bates at stat.wisc.edu  Mon Feb 23 18:30:26 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 23 Feb 2004 11:30:26 -0600
Subject: [R] lme - problems with model
In-Reply-To: <200402231520.i1NFKBAA015816@mail1.slu.se>
References: <200402231520.i1NFKBAA015816@mail1.slu.se>
Message-ID: <6r3c91itzh.fsf@bates4.stat.wisc.edu>

CG Pettersson <cg.pettersson at evp.slu.se> writes:

> Thanks a lot for the answer!

> Now, I only have the last one left - How do I get round it?
> I knew about the missing cells in the design, but didn?t know how lme
> would react on them.

> In this case, I can remove the water:temp term, but how can I be sure
> that this is the right thing to do?

Others may be able to come up with inventive ways of creating the
model matrix to do this but I would simply compare the additive model
to the cell means model.

> milk = read.table("/tmp/milk.txt", header = TRUE)
> milk$water = factor(milk$water)
> milk$temp = factor(milk$temp)
> milk$WaterTemp = factor(paste(milk$water, milk$temp, sep = '/'))
> xtabs(~ water + temp, milk)
     temp
water 100 110 120 140
    1 3   3   3   0  
    2 3   0   3   3  
    3 3   3   0   3  
> xtabs(~ WaterTemp, milk)
WaterTemp
1/100 1/110 1/120 2/100 2/120 2/140 3/100 3/110 3/140 
    3     3     3     3     3     3     3     3     3 
> library(lme4)
Loading required package: stats4 
Loading required package: lattice 
> summary(fm1 <- lme(maill6 ~ water + temp, milk, ~ 1 | rep))
Linear mixed-effects model fit by REML
 Data: milk 
      AIC      BIC   logLik
 6.155644 14.51182 4.922178

Random effects:
 Groups   Name        Variance Std.Dev.
 rep      (Intercept) 0.021838 0.14778 
 Residual             0.017505 0.13231 

Fixed effects: maill6 ~ water + temp 
             Estimate Std. Error DF t value  Pr(>|t|)    
(Intercept)  2.194667   0.103828 19 21.1376 1.162e-14 ***
water2       0.328000   0.068322 19  4.8008 0.0001243 ***
water3      -0.045333   0.068322 19 -0.6635 0.5149678    
temp110      0.078000   0.072467 19  1.0764 0.2952465    
temp120      0.321333   0.072467 19  4.4342 0.0002847 ***
temp140      0.350667   0.072467 19  4.8390 0.0001140 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Correlation of Fixed Effects:
        (Intr) water2 water3 tmp110 tmp120
water2  -0.329                            
water3  -0.329  0.500                     
temp110 -0.310  0.236  0.000              
temp120 -0.310  0.000  0.236  0.333       
temp140 -0.155 -0.236 -0.236  0.333  0.333

Number of Observations: 27
Number of Groups: 3 
> summary(fm2 <- lme(maill6 ~ WaterTemp, milk, ~ 1 | rep))
Linear mixed-effects model fit by REML
 Data: milk 
      AIC      BIC   logLik
 14.96052 24.75461 3.519738

Random effects:
 Groups   Name        Variance Std.Dev.
 rep      (Intercept) 0.021862 0.14786 
 Residual             0.017286 0.13148 

Fixed effects: maill6 ~ WaterTemp 
                 Estimate Std. Error DF t value  Pr(>|t|)    
(Intercept)     2.1766667  0.1142339 16 19.0545 2.016e-12 ***
WaterTemp1/110  0.1400000  0.1073502 16  1.3041   0.21064    
WaterTemp1/120  0.3133333  0.1073502 16  2.9188   0.01004 *  
WaterTemp2/100  0.2833333  0.1073502 16  2.6393   0.01785 *  
WaterTemp2/120  0.6933333  0.1073502 16  6.4586 7.897e-06 ***
WaterTemp2/140  0.7333333  0.1073502 16  6.8312 4.035e-06 ***
WaterTemp3/100  0.0533333  0.1073502 16  0.4968   0.62608    
WaterTemp3/110  0.0066667  0.1073502 16  0.0621   0.95125    
WaterTemp3/140  0.2866667  0.1073502 16  2.6704   0.01676 *  
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Correlation of Fixed Effects:
            (Intr) WT1/11 WT1/12 WT2/10 WT2/12 WT2/14 WT3/10 WT3/11
WtrTmp1/110 -0.470                                                 
WtrTmp1/120 -0.470  0.500                                          
WtrTmp2/100 -0.470  0.500  0.500                                   
WtrTmp2/120 -0.470  0.500  0.500  0.500                            
WtrTmp2/140 -0.470  0.500  0.500  0.500  0.500                     
WtrTmp3/100 -0.470  0.500  0.500  0.500  0.500  0.500              
WtrTmp3/110 -0.470  0.500  0.500  0.500  0.500  0.500  0.500       
WtrTmp3/140 -0.470  0.500  0.500  0.500  0.500  0.500  0.500  0.500

Number of Observations: 27
Number of Groups: 3 

Both AIC and BIC, which are on the scale of "smaller is better",
indicate strong preference for the additive model.  A likelihood ratio
test would not show significant improvement in the fit of the cell
means model relative to the additive model.

In general one should be cautious when using likelihood ratio tests on
the fixed-effects terms but in this case it is probably ok because the
estimates for the random effects are nearly identical for the two
models.

> Is the lm run without the random term enough for removing water:temp
> from the lme model, or do I have to do a PROC MIXED run with the
> random term to make that decision in a case like this? 

I would use this analysis instead.

> Is it possible (for me)  to understand why MIXED accepts the design
> but not lme? They ought to get the same sort of problems, or have I
> missed something?

Because of the way that model matrices are created in SAS, the
computational methods *must* detect rank deficiencies and compensate
for them.  Whenever there is a categorical factor in the model the SAS
model matrix will be rank deficient.  You may be aware that SAS always
uses a parameterization of a factor where the last level of the factor
is the "reference" level.  That is not a choice - it is a necessary
consequence of the way in which the computation is carried out.  It is
the detection of the rank deficiency and elimination of the column
where that is detected that causes SAS to eliminate the coefficient
for the last level in a factor.

The approach used in the S language is to use a set of k-1 "contrasts"
to generate the columns for terms involving a factor with k levels.
This automatically creates a full rank model matrix unless you have
missing cells.  The lm code check for rank deficiency and compensates
for it.  However we did not build that capability into lme (from the
nlme package or from the lme4 package) because there are two possible
explanations for the rank deficiency and in the one case we want to
circumvent it and in the other case we don't.  It is difficult to
distinguish between those two cases so we don't even try.


> -------------------
> > CG Pettersson <cg.pettersson at evp.slu.se> writes:
> > 
> > > Hello all!
> > > 
> > > I?m working with some training datasets in a SAS-based course,
> trying
> > > to do the same things in lme that I do in PROC MIXED. 
> > > 
> > > Why don?t lme do an analysis on this dataset when I use the model
> > > water*temp?
> > > The trouble comes from the water:temp term, as it works with
> > > water+temp.
> > > The data are, indeed, assymetric but lm accepts the water:temp
> term
> > > giving results in the F-test near what PROC MIXED produces. MIXED
> > > accepts the model.
> > > 
> > > The water:temp term can be removed from the model according to the
> > > F-test in SAS (and to the lm model without any random term). Doing
> so
> > > in both MIXED and lme gives reasonably similar results for both
> > > systems.
> > > 
> > > What do the error message mean, and how can I get around this?
> > 
> > Because of missing cells in the design
> > 
> > > xtabs(~water + temp, milk)
> >      temp
> > water 100 110 120 140
> >     1 3   3   3   0  
> >     2 3   0   3   3  
> >     3 3   3   0   3  
> > 
> > the model matrix for the fixed effects is rank deficient.  In lm the
> > rank deficiency is detected and appropriate adjustments made
> > 
> > > coef(summary(lm(maill6 ~ water * temp, milk)))
> >                   Estimate Std. Error    t value     Pr(>|t|)
> > (Intercept)     2.17666667  0.1142339 19.0544730 2.218661e-13
> > water2          0.28333333  0.1615511  1.7538308 9.647013e-02
> > water3          0.05333333  0.1615511  0.3301329 7.451108e-01
> > temp110         0.14000000  0.1615511  0.8665987 3.975669e-01
> > temp120         0.31333333  0.1615511  1.9395305 6.827304e-02
> > temp140         0.23333333  0.1615511  1.4443312 1.658280e-01
> > water3:temp110 -0.18666667  0.2284678 -0.8170371 4.245898e-01
> > water2:temp120  0.09666667  0.2284678  0.4231085 6.772282e-01
> > water2:temp140  0.21666667  0.2284678  0.9483467 3.555125e-01
> > 
> > Notice that you would expect 6 degrees of freedom for the
> interaction
> > term but only three coefficients are estimated.
> > 
> > In lme it is much more difficult to compensate for such rank
> > deficiencies because they could be systematic, like this, or they
> > could be due to relative precision parameters approaching zero
> during
> > the iterations.  Because of this we just report the error (although
> > admittedly we could be a bit more explicit about the nature of the
> > problem - we are reporting the symptom that we detect, not the
> > probable cause).
> > 
> > 
> > > The dataset:
> > > > milk
> > >    water temp rep maill4 maill6 maill8 taste4 taste6 taste8
> > > 1      1  100   1   2.90   2.13   2.39   10.1   10.0    9.6
> > > 2      1  100   2   2.19   2.20   2.27   11.0    9.3   11.0
> > > 3      1  100   3   2.13   2.20   2.41   10.1    7.0    9.6
> > > 4      1  110   1   2.13   2.34   2.41   11.0   10.5    9.8
> > > 5      1  110   2   2.32   2.27   2.25   11.0   11.3   11.2
> > > 6      1  110   3   2.13   2.34   2.42    9.4   10.7    9.0
> > > 7      1  120   1   2.00   2.49   2.71   11.1   11.2   11.4
> > > 8      1  120   2   2.41   2.49   2.46   11.6   11.7    9.6
> > > 9      1  120   3   2.22   2.49   2.73   10.7   10.3   10.2
> > > 10     2  100   1   2.13   2.41   2.49   11.1   10.8   11.2
> > > 11     2  100   2   2.49   2.34   2.53   11.1   11.2    9.2
> > > 12     2  100   3   2.80   2.63   3.33    8.3    9.7    7.8
> > > 13     2  120   1   2.38   2.85   2.06   11.9   11.2   11.2
> > > 14     2  120   2   2.61   2.70   2.70   11.7   10.8   11.0
> > > 15     2  120   3   2.77   3.06   3.25   10.9    9.0    9.4
> > > 16     2  140   1   2.56   2.84   3.10   10.7   11.2    9.8
> > > 17     2  140   2   2.63   2.61   2.81   10.8   11.0   11.6
> > > 18     2  140   3   2.99   3.28   3.75    9.2    9.6    9.6
> > > 19     3  100   1   2.60   2.24   2.32   10.8    8.4   10.8
> > > 20     3  100   2   2.06   2.11   2.20   11.0   11.2   11.8
> > > 21     3  100   3   1.98   2.34   2.80   10.3   10.2   10.6
> > > 22     3  110   1   1.91   2.06   2.29   11.0   11.4    9.4
> > > 23     3  110   2   1.98   1.98   2.15   10.0   11.8   10.6
> > > 24     3  110   3   1.98   2.51   2.81    9.3    9.2   10.2
> > > 25     3  140   1   2.27   2.42   2.72   10.8   11.6   12.0
> > > 26     3  140   2   2.27   2.20   2.41   11.2   11.0   11.4
> > > 27     3  140   3   2.20   2.77   3.06   10.5   10.2   10.0
> > > 
> > > The failing model:
> > > > lme(maill6 ~ water * temp  , random= ~1|rep, data = milk)
> > > Error in MEEM(object, conLin, control$niterEM) : 
> > >         Singularity in backsolve at level 0, block 1
> > > 
> > > The smaller (working) model:
> > > > lme(maill6 ~ water + temp  , random= ~1|rep, data = milk)
> > > Linear mixed-effects model fit by REML
> > >   Data: milk 
> > >   Log-restricted-likelihood: 4.922178
> > >   Fixed: maill6 ~ water + temp 
> > > (Intercept)      water2      water3     temp110     temp120    
> > > temp140 
> > >  2.19466667  0.32800000 -0.04533333  0.07800000  0.32133333 
> > > 0.35066667 
> > > 
> > > Random effects:
> > >  Formula: ~1 | rep
> > >         (Intercept)  Residual
> > > StdDev:   0.1477760 0.1323057
> > > 
> > > Number of Observations: 27
> > > Number of Groups: 3 
> > > > 
> > > 
> > > 
> > > 
> > > 
> > > CG Pettersson, MSci, PhD Stud.
> > > Swedish University of Agricultural Sciences
> > > Dep. of Ecology and Crop Production. Box 7043
> > > SE-750 07 Uppsala
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> > 
> > -- 
> > Douglas Bates                            bates at stat.wisc.edu
> > Statistics Department                    608/262-2598
> > University of Wisconsin - Madison       
> http://www.stat.wisc.edu/~bates/
> > 
> CG Pettersson, MSci, PhD Stud.
> Swedish University of Agricultural Sciences
> Dep. of Ecology and Crop Production. Box 7043
> SE-750 07 Uppsala

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From H.Andersson at nioo.knaw.nl  Mon Feb 23 18:36:47 2004
From: H.Andersson at nioo.knaw.nl (Andersson, Henrik)
Date: Mon, 23 Feb 2004 18:36:47 +0100
Subject: [R] Reference to use of MLR in industry and biology
Message-ID: <65F6E1EC64DCA6489800C09A2007FC6E147EAA@cememail1.nioo.int>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040223/d9024b3a/attachment.pl

From copellifulvio at yahoo.it  Mon Feb 23 18:40:22 2004
From: copellifulvio at yahoo.it (=?iso-8859-1?q?Fulvio=20Copex?=)
Date: Mon, 23 Feb 2004 18:40:22 +0100 (CET)
Subject: [R] deleting elements from an array/object
Message-ID: <20040223174022.19643.qmail@web25206.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040223/aecd1573/attachment.pl

From joehl at gmx.de  Mon Feb 23 17:16:51 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Mon, 23 Feb 2004 17:16:51 +0100 (MET)
Subject: [R] [R-pkgs] Package "ref" implements references and referenceable
	data.frames for the S-language
Message-ID: <17540.1077553011@www6.gmx.net>


Repeatedly people have asked how to pass arguments by reference in R.

Now package "ref"  is on CRAN, which provides two referencing methods:

Functions ref(), deref() and friends conveniently allow to pass parameters
"by reference" instead of  "by value". This can be useful in memory critical
applications but requires a more careful programming style to track the
implications of functions changing their parameters. However, package ref is
written in pure S and attaching this package does not change any standard S
behaviour. 

Class refdata is a transparent wrapper to matrices and data.frames which
allows for memory efficient nested subsetting. I.e. you can create a subset
of a
subset ... of a data.frame without duplicating the data in memory, instead
only indexing information is duplicated. Indexing information is represented
as positive or negative integers, whatever is shorter, thus the length of
the
index is granted to be <=nrows/2 resp. <=ncol/2. Memory savings in case of a
square data.frame is roughly n^2-n elements per level of nested subsetting.

This code is offered "as is" under the GPL, usage is completely at your own
risk. (Some efforts has been put in the included regression tests to make
shure
the code does what it is intended to do).

Feedback about problems or successful example uses is welcome.
Please use the email address given in the package DESCRIPTION and please
don't cc to lists for spam prevention.

Best regards


Jens Oehlschl?gel

-- 
GMX ProMail (250 MB Mailbox, 50 FreeSMS, Virenschutz, 2,99 EUR/Monat...)
jetzt 3 Monate GRATIS + 3x DER SPIEGEL +++ http://www.gmx.net/derspiegel +++

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From spencer.graves at pdf.com  Mon Feb 23 18:55:41 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 23 Feb 2004 09:55:41 -0800
Subject: [R] lme - problems with model
In-Reply-To: <6r3c91itzh.fsf@bates4.stat.wisc.edu>
References: <200402231520.i1NFKBAA015816@mail1.slu.se>
	<6r3c91itzh.fsf@bates4.stat.wisc.edu>
Message-ID: <403A3E9D.3000309@pdf.com>

      Doug's "xtabs" suggests to me that the following might be 
estimable, with data.$Temp <- as.numeric(as.character(data.$temp))

      water*(Temp+I(Temp^2))

      It looks like it should be estimable in "lm", and depending on the 
noise model, it should also be estimable in "lme".  ???

      hope this helps.  spencer graves

Douglas Bates wrote:

>CG Pettersson <cg.pettersson at evp.slu.se> writes:
>
>  
>
>>Thanks a lot for the answer!
>>    
>>
>
>  
>
>>Now, I only have the last one left - How do I get round it?
>>I knew about the missing cells in the design, but didn?t know how lme
>>would react on them.
>>    
>>
>
>  
>
>>In this case, I can remove the water:temp term, but how can I be sure
>>that this is the right thing to do?
>>    
>>
>
>Others may be able to come up with inventive ways of creating the
>model matrix to do this but I would simply compare the additive model
>to the cell means model.
>
>  
>
>>milk = read.table("/tmp/milk.txt", header = TRUE)
>>milk$water = factor(milk$water)
>>milk$temp = factor(milk$temp)
>>milk$WaterTemp = factor(paste(milk$water, milk$temp, sep = '/'))
>>xtabs(~ water + temp, milk)
>>    
>>
>     temp
>water 100 110 120 140
>    1 3   3   3   0  
>    2 3   0   3   3  
>    3 3   3   0   3  
>  
>
>>xtabs(~ WaterTemp, milk)
>>    
>>
>WaterTemp
>1/100 1/110 1/120 2/100 2/120 2/140 3/100 3/110 3/140 
>    3     3     3     3     3     3     3     3     3 
>  
>
>>library(lme4)
>>    
>>
>Loading required package: stats4 
>Loading required package: lattice 
>  
>
>>summary(fm1 <- lme(maill6 ~ water + temp, milk, ~ 1 | rep))
>>    
>>
>Linear mixed-effects model fit by REML
> Data: milk 
>      AIC      BIC   logLik
> 6.155644 14.51182 4.922178
>
>Random effects:
> Groups   Name        Variance Std.Dev.
> rep      (Intercept) 0.021838 0.14778 
> Residual             0.017505 0.13231 
>
>Fixed effects: maill6 ~ water + temp 
>             Estimate Std. Error DF t value  Pr(>|t|)    
>(Intercept)  2.194667   0.103828 19 21.1376 1.162e-14 ***
>water2       0.328000   0.068322 19  4.8008 0.0001243 ***
>water3      -0.045333   0.068322 19 -0.6635 0.5149678    
>temp110      0.078000   0.072467 19  1.0764 0.2952465    
>temp120      0.321333   0.072467 19  4.4342 0.0002847 ***
>temp140      0.350667   0.072467 19  4.8390 0.0001140 ***
>---
>Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
>
>Correlation of Fixed Effects:
>        (Intr) water2 water3 tmp110 tmp120
>water2  -0.329                            
>water3  -0.329  0.500                     
>temp110 -0.310  0.236  0.000              
>temp120 -0.310  0.000  0.236  0.333       
>temp140 -0.155 -0.236 -0.236  0.333  0.333
>
>Number of Observations: 27
>Number of Groups: 3 
>  
>
>>summary(fm2 <- lme(maill6 ~ WaterTemp, milk, ~ 1 | rep))
>>    
>>
>Linear mixed-effects model fit by REML
> Data: milk 
>      AIC      BIC   logLik
> 14.96052 24.75461 3.519738
>
>Random effects:
> Groups   Name        Variance Std.Dev.
> rep      (Intercept) 0.021862 0.14786 
> Residual             0.017286 0.13148 
>
>Fixed effects: maill6 ~ WaterTemp 
>                 Estimate Std. Error DF t value  Pr(>|t|)    
>(Intercept)     2.1766667  0.1142339 16 19.0545 2.016e-12 ***
>WaterTemp1/110  0.1400000  0.1073502 16  1.3041   0.21064    
>WaterTemp1/120  0.3133333  0.1073502 16  2.9188   0.01004 *  
>WaterTemp2/100  0.2833333  0.1073502 16  2.6393   0.01785 *  
>WaterTemp2/120  0.6933333  0.1073502 16  6.4586 7.897e-06 ***
>WaterTemp2/140  0.7333333  0.1073502 16  6.8312 4.035e-06 ***
>WaterTemp3/100  0.0533333  0.1073502 16  0.4968   0.62608    
>WaterTemp3/110  0.0066667  0.1073502 16  0.0621   0.95125    
>WaterTemp3/140  0.2866667  0.1073502 16  2.6704   0.01676 *  
>---
>Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
>
>Correlation of Fixed Effects:
>            (Intr) WT1/11 WT1/12 WT2/10 WT2/12 WT2/14 WT3/10 WT3/11
>WtrTmp1/110 -0.470                                                 
>WtrTmp1/120 -0.470  0.500                                          
>WtrTmp2/100 -0.470  0.500  0.500                                   
>WtrTmp2/120 -0.470  0.500  0.500  0.500                            
>WtrTmp2/140 -0.470  0.500  0.500  0.500  0.500                     
>WtrTmp3/100 -0.470  0.500  0.500  0.500  0.500  0.500              
>WtrTmp3/110 -0.470  0.500  0.500  0.500  0.500  0.500  0.500       
>WtrTmp3/140 -0.470  0.500  0.500  0.500  0.500  0.500  0.500  0.500
>
>Number of Observations: 27
>Number of Groups: 3 
>
>Both AIC and BIC, which are on the scale of "smaller is better",
>indicate strong preference for the additive model.  A likelihood ratio
>test would not show significant improvement in the fit of the cell
>means model relative to the additive model.
>
>In general one should be cautious when using likelihood ratio tests on
>the fixed-effects terms but in this case it is probably ok because the
>estimates for the random effects are nearly identical for the two
>models.
>
>  
>
>>Is the lm run without the random term enough for removing water:temp
>>from the lme model, or do I have to do a PROC MIXED run with the
>>random term to make that decision in a case like this? 
>>    
>>
>
>I would use this analysis instead.
>
>  
>
>>Is it possible (for me)  to understand why MIXED accepts the design
>>but not lme? They ought to get the same sort of problems, or have I
>>missed something?
>>    
>>
>
>Because of the way that model matrices are created in SAS, the
>computational methods *must* detect rank deficiencies and compensate
>for them.  Whenever there is a categorical factor in the model the SAS
>model matrix will be rank deficient.  You may be aware that SAS always
>uses a parameterization of a factor where the last level of the factor
>is the "reference" level.  That is not a choice - it is a necessary
>consequence of the way in which the computation is carried out.  It is
>the detection of the rank deficiency and elimination of the column
>where that is detected that causes SAS to eliminate the coefficient
>for the last level in a factor.
>
>The approach used in the S language is to use a set of k-1 "contrasts"
>to generate the columns for terms involving a factor with k levels.
>This automatically creates a full rank model matrix unless you have
>missing cells.  The lm code check for rank deficiency and compensates
>for it.  However we did not build that capability into lme (from the
>nlme package or from the lme4 package) because there are two possible
>explanations for the rank deficiency and in the one case we want to
>circumvent it and in the other case we don't.  It is difficult to
>distinguish between those two cases so we don't even try.
>
>
>  
>
>>-------------------
>>    
>>
>>>CG Pettersson <cg.pettersson at evp.slu.se> writes:
>>>
>>>      
>>>
>>>>Hello all!
>>>>
>>>>I?m working with some training datasets in a SAS-based course,
>>>>        
>>>>
>>trying
>>    
>>
>>>>to do the same things in lme that I do in PROC MIXED. 
>>>>
>>>>Why don?t lme do an analysis on this dataset when I use the model
>>>>water*temp?
>>>>The trouble comes from the water:temp term, as it works with
>>>>water+temp.
>>>>The data are, indeed, assymetric but lm accepts the water:temp
>>>>        
>>>>
>>term
>>    
>>
>>>>giving results in the F-test near what PROC MIXED produces. MIXED
>>>>accepts the model.
>>>>
>>>>The water:temp term can be removed from the model according to the
>>>>F-test in SAS (and to the lm model without any random term). Doing
>>>>        
>>>>
>>so
>>    
>>
>>>>in both MIXED and lme gives reasonably similar results for both
>>>>systems.
>>>>
>>>>What do the error message mean, and how can I get around this?
>>>>        
>>>>
>>>Because of missing cells in the design
>>>
>>>      
>>>
>>>>xtabs(~water + temp, milk)
>>>>        
>>>>
>>>     temp
>>>water 100 110 120 140
>>>    1 3   3   3   0  
>>>    2 3   0   3   3  
>>>    3 3   3   0   3  
>>>
>>>the model matrix for the fixed effects is rank deficient.  In lm the
>>>rank deficiency is detected and appropriate adjustments made
>>>
>>>      
>>>
>>>>coef(summary(lm(maill6 ~ water * temp, milk)))
>>>>        
>>>>
>>>                  Estimate Std. Error    t value     Pr(>|t|)
>>>(Intercept)     2.17666667  0.1142339 19.0544730 2.218661e-13
>>>water2          0.28333333  0.1615511  1.7538308 9.647013e-02
>>>water3          0.05333333  0.1615511  0.3301329 7.451108e-01
>>>temp110         0.14000000  0.1615511  0.8665987 3.975669e-01
>>>temp120         0.31333333  0.1615511  1.9395305 6.827304e-02
>>>temp140         0.23333333  0.1615511  1.4443312 1.658280e-01
>>>water3:temp110 -0.18666667  0.2284678 -0.8170371 4.245898e-01
>>>water2:temp120  0.09666667  0.2284678  0.4231085 6.772282e-01
>>>water2:temp140  0.21666667  0.2284678  0.9483467 3.555125e-01
>>>
>>>Notice that you would expect 6 degrees of freedom for the
>>>      
>>>
>>interaction
>>    
>>
>>>term but only three coefficients are estimated.
>>>
>>>In lme it is much more difficult to compensate for such rank
>>>deficiencies because they could be systematic, like this, or they
>>>could be due to relative precision parameters approaching zero
>>>      
>>>
>>during
>>    
>>
>>>the iterations.  Because of this we just report the error (although
>>>admittedly we could be a bit more explicit about the nature of the
>>>problem - we are reporting the symptom that we detect, not the
>>>probable cause).
>>>
>>>
>>>      
>>>
>>>>The dataset:
>>>>        
>>>>
>>>>>milk
>>>>>          
>>>>>
>>>>   water temp rep maill4 maill6 maill8 taste4 taste6 taste8
>>>>1      1  100   1   2.90   2.13   2.39   10.1   10.0    9.6
>>>>2      1  100   2   2.19   2.20   2.27   11.0    9.3   11.0
>>>>3      1  100   3   2.13   2.20   2.41   10.1    7.0    9.6
>>>>4      1  110   1   2.13   2.34   2.41   11.0   10.5    9.8
>>>>5      1  110   2   2.32   2.27   2.25   11.0   11.3   11.2
>>>>6      1  110   3   2.13   2.34   2.42    9.4   10.7    9.0
>>>>7      1  120   1   2.00   2.49   2.71   11.1   11.2   11.4
>>>>8      1  120   2   2.41   2.49   2.46   11.6   11.7    9.6
>>>>9      1  120   3   2.22   2.49   2.73   10.7   10.3   10.2
>>>>10     2  100   1   2.13   2.41   2.49   11.1   10.8   11.2
>>>>11     2  100   2   2.49   2.34   2.53   11.1   11.2    9.2
>>>>12     2  100   3   2.80   2.63   3.33    8.3    9.7    7.8
>>>>13     2  120   1   2.38   2.85   2.06   11.9   11.2   11.2
>>>>14     2  120   2   2.61   2.70   2.70   11.7   10.8   11.0
>>>>15     2  120   3   2.77   3.06   3.25   10.9    9.0    9.4
>>>>16     2  140   1   2.56   2.84   3.10   10.7   11.2    9.8
>>>>17     2  140   2   2.63   2.61   2.81   10.8   11.0   11.6
>>>>18     2  140   3   2.99   3.28   3.75    9.2    9.6    9.6
>>>>19     3  100   1   2.60   2.24   2.32   10.8    8.4   10.8
>>>>20     3  100   2   2.06   2.11   2.20   11.0   11.2   11.8
>>>>21     3  100   3   1.98   2.34   2.80   10.3   10.2   10.6
>>>>22     3  110   1   1.91   2.06   2.29   11.0   11.4    9.4
>>>>23     3  110   2   1.98   1.98   2.15   10.0   11.8   10.6
>>>>24     3  110   3   1.98   2.51   2.81    9.3    9.2   10.2
>>>>25     3  140   1   2.27   2.42   2.72   10.8   11.6   12.0
>>>>26     3  140   2   2.27   2.20   2.41   11.2   11.0   11.4
>>>>27     3  140   3   2.20   2.77   3.06   10.5   10.2   10.0
>>>>
>>>>The failing model:
>>>>        
>>>>
>>>>>lme(maill6 ~ water * temp  , random= ~1|rep, data = milk)
>>>>>          
>>>>>
>>>>Error in MEEM(object, conLin, control$niterEM) : 
>>>>        Singularity in backsolve at level 0, block 1
>>>>
>>>>The smaller (working) model:
>>>>        
>>>>
>>>>>lme(maill6 ~ water + temp  , random= ~1|rep, data = milk)
>>>>>          
>>>>>
>>>>Linear mixed-effects model fit by REML
>>>>  Data: milk 
>>>>  Log-restricted-likelihood: 4.922178
>>>>  Fixed: maill6 ~ water + temp 
>>>>(Intercept)      water2      water3     temp110     temp120    
>>>>temp140 
>>>> 2.19466667  0.32800000 -0.04533333  0.07800000  0.32133333 
>>>>0.35066667 
>>>>
>>>>Random effects:
>>>> Formula: ~1 | rep
>>>>        (Intercept)  Residual
>>>>StdDev:   0.1477760 0.1323057
>>>>
>>>>Number of Observations: 27
>>>>Number of Groups: 3 
>>>>        
>>>>
>>>>
>>>>
>>>>CG Pettersson, MSci, PhD Stud.
>>>>Swedish University of Agricultural Sciences
>>>>Dep. of Ecology and Crop Production. Box 7043
>>>>SE-750 07 Uppsala
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide!
>>>>        
>>>>
>>http://www.R-project.org/posting-guide.html
>>    
>>
>>>-- 
>>>Douglas Bates                            bates at stat.wisc.edu
>>>Statistics Department                    608/262-2598
>>>University of Wisconsin - Madison       
>>>      
>>>
>>http://www.stat.wisc.edu/~bates/
>>    
>>
>>CG Pettersson, MSci, PhD Stud.
>>Swedish University of Agricultural Sciences
>>Dep. of Ecology and Crop Production. Box 7043
>>SE-750 07 Uppsala
>>    
>>
>
>  
>



From ggrothendieck at myway.com  Mon Feb 23 19:02:24 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 23 Feb 2004 13:02:24 -0500 (EST)
Subject: [R] Reference to use of MLR in industry and biology
Message-ID: <20040223180224.8BD4839BD@mprdmxin.myway.com>



Chemists refer to regression as QSAR so googling for that
should find you lots of examples.

Date:   Mon, 23 Feb 2004 18:36:47 +0100 
From:   Andersson, Henrik <H.Andersson at nioo.knaw.nl>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] Reference to use of MLR in industry and biology 

 

I apologize in advance for posting a question not related to R.

I need references to papers that use multiple linear regression in an industrial application and also in a biological experiment. 

This is aimed to biologists/chemists (non-statisticans) so if anyone has written a brilliant paper where the use of multiple regression is important and also understandable to people with little knowledge of statistics and you like to be cited, please email me the reference off the list.

To show the wide range of application I would like to have an example from industry and one from science of a (biological) field experiment.

Thanks in advance, Henrik Andersson

Netherlands Institute of Ecology -
Centre for Estuarine and Marine Ecology

h.andersson at nioo.knaw.nl



From ggrothendieck at myway.com  Mon Feb 23 19:16:46 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 23 Feb 2004 13:16:46 -0500 (EST)
Subject: [R] deleting elements from an array/object
Message-ID: <20040223181646.1C269398F@mprdmxin.myway.com>



You can create a new data frame and subset it:

myHist.df <- data.frame(counts = myHist$counts, mids = myHist$mids )
myHist.df <- subset( myHist, counts > 0 )
lm( mids ~ log(counts), data = myHist.df )

---
Date:   Mon, 23 Feb 2004 18:40:22 +0100 (CET) 
From:   =?iso-8859-1?q?Fulvio=20Copex?= <copellifulvio at yahoo.it>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] deleting elements from an array/object 

 
Hello,
I created a simple histogram with:
myHist<-hist(myData)
the object myHist now has two arrays (among the others):

myHist$mids
myHist$counts

Since myHist$counts contains some "0", and I want to calculate the linear fit among myHist$mids and log(myHist$counts), I want remove the elements of both arrays where these "0" occurs.

which are the possible solutions to this problem?
(I'd like to avoid getting the indexes...)

Thanks a lot,
copex



From ripley at stats.ox.ac.uk  Mon Feb 23 19:51:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Feb 2004 18:51:38 +0000 (GMT)
Subject: [R] deleting elements from an array/object
In-Reply-To: <20040223174022.19643.qmail@web25206.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.44.0402231846520.1480-100000@gannet.stats>

It would be better to have a data frame for this purpose, so

myHist2 <- as.data.frame(myhist[c("counts", mids")])
myHist2 <- myHist2[myHist2$counts > 0, ]
lm(log(counts) ~ mids, data=myHist2)

should set this up for you, or even you could use

myHist2 <- as.data.frame(myhist[c("counts", mids")])
lm(log(counts) ~ mids, data=myHist2, subset=counts > 0)


On Mon, 23 Feb 2004, Fulvio Copex wrote:

> Hello,
> I created a simple histogram with:
> myHist<-hist(myData)
> the object myHist now has two arrays (among the others):

vectors not arrays, I believe.

> myHist$mids
> myHist$counts

>  Since myHist$counts contains some "0", and I want to calculate the
> linear fit among myHist$mids and log(myHist$counts), I want remove the
> elements of both arrays where these "0" occurs.
>  
> which are the possible solutions to this problem?
> (I'd like to avoid getting the indexes...)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From zduan1 at uthouston.edu  Mon Feb 23 20:49:52 2004
From: zduan1 at uthouston.edu (Duan Zhigang)
Date: Mon, 23 Feb 2004 13:49:52 -0600
Subject: [R] parameters' value
Message-ID: <76E50A283589324FA6A1999EEFBB134127D25B@UTHEVS1.mail.uthouston.edu>

Hi, I am a new user of R. I am trying to use R to do some nonlinear modeling. However, I can not find how to get the parameters's value back.

Here is the code in S-plus: 

ycos1.nl <- nls(y ~ m +ac*cos(2*pi*f*t) +as*sin(2*pi*f*t), start=nl.st, trace=T)

## store model info after satisfactory model has been found
cNL1 <- c(ycos1.nl$parameters[1:3],0)

What is same code in R? 

Thanks a lot.

Duan



From ajayshah at mayin.org  Mon Feb 23 21:07:23 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Tue, 24 Feb 2004 01:37:23 +0530
Subject: [R] Need help on parsing dates
Message-ID: <20040223200723.GO781@igidr.ac.in>

I know this:

  > library(date)
  > x="1979-04-04"
  > try=as.date(x, "ymd")
  > print(try)
  [1] 4Apr79

and that `x' here has to be a string, e.g.:

  > x=1979-04-04
  > print(x)
  [1] 1971

I'm stuck in reading from a file. I say:  

  > A <- read.table(file="try")
  > print(A)
             V1          V2
  1  1979-04-04 -1.04712042
  2  1979-04-06  0.54538055
  3  1979-04-09  0.09663392
  4  1979-04-11  0.57119871
  5  1979-04-12  0.73594112
  6  1979-04-17 -1.54422087
  7  1979-04-18 -0.20595691
  8  1979-04-19  0.12700429
  9  1979-04-20  0.42016807
  10 1979-04-23 -1.46838241

I am confused - is V1 a number or a string? Looking at it, it must be
a string. But yet:

  > library(date)
  > try=as.date(A$V1, "ymd")
  Error in as.date(A$V1, "ymd") : Cannot coerce to date format

In short, how do I parse in dates of the format yyyy-mm-dd (the ISO
8601 format) or the yyyymmdd format.

And if I may ask the next step: How do I tell R that I have a file
full of data all of which is time-series data, where V1 is the
datetime vector, and all the other columns are time-series, to do
things like ARMA models and ts plots with?

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From nlwhitehouse at yahoo.com  Mon Feb 23 21:13:40 2004
From: nlwhitehouse at yahoo.com (Nathan Whitehouse)
Date: Mon, 23 Feb 2004 12:13:40 -0800 (PST)
Subject: [R] HTTP Post connections in R
Message-ID: <20040223201340.26608.qmail@web12404.mail.yahoo.com>

Hi,

  Is there any existing functions to open an HTTP
connection and HTTP POST some R data?

  like
  <form method="post" enctype="multipart/form-data">
    etc.
  </form>
  but within R.

  Thanks,
  

  

=====
Nathan Whitehouse
Statistics/Programming
Baylor College of Medicine
Houston, TX, USA
nlwhitehouse at yahoo.com

http://rho-project.org: rho- open source web services for R.
http://franklin.imgen.bcm.tmc.edu: Shaw laboratory, bcm.



From ripley at stats.ox.ac.uk  Mon Feb 23 21:16:02 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Feb 2004 20:16:02 +0000 (GMT)
Subject: [R] Need help on parsing dates
In-Reply-To: <20040223200723.GO781@igidr.ac.in>
Message-ID: <Pine.LNX.4.44.0402232015170.1672-100000@gannet.stats>

On Tue, 24 Feb 2004, Ajay Shah wrote:

> I know this:
> 
>   > library(date)
>   > x="1979-04-04"
>   > try=as.date(x, "ymd")
>   > print(try)
>   [1] 4Apr79
> 
> and that `x' here has to be a string, e.g.:
> 
>   > x=1979-04-04
>   > print(x)
>   [1] 1971
> 
> I'm stuck in reading from a file. I say:  
> 
>   > A <- read.table(file="try")
>   > print(A)
>              V1          V2
>   1  1979-04-04 -1.04712042
>   2  1979-04-06  0.54538055
>   3  1979-04-09  0.09663392
>   4  1979-04-11  0.57119871
>   5  1979-04-12  0.73594112
>   6  1979-04-17 -1.54422087
>   7  1979-04-18 -0.20595691
>   8  1979-04-19  0.12700429
>   9  1979-04-20  0.42016807
>   10 1979-04-23 -1.46838241
> 
> I am confused - is V1 a number or a string? Looking at it, it must be
> a string. But yet:

It is a factor.  See ?read.table.
>   > library(date)
>   > try=as.date(A$V1, "ymd")
>   Error in as.date(A$V1, "ymd") : Cannot coerce to date format
> 
> In short, how do I parse in dates of the format yyyy-mm-dd (the ISO
> 8601 format) or the yyyymmdd format.
> 
> And if I may ask the next step: How do I tell R that I have a file
> full of data all of which is time-series data, where V1 is the
> datetime vector, and all the other columns are time-series, to do
> things like ARMA models and ts plots with?

You can't with an irregular series like this one.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sundar.dorai-raj at pdf.com  Mon Feb 23 21:16:30 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 23 Feb 2004 14:16:30 -0600
Subject: [R] Need help on parsing dates
In-Reply-To: <20040223200723.GO781@igidr.ac.in>
References: <20040223200723.GO781@igidr.ac.in>
Message-ID: <403A5F9E.40103@pdf.com>



Ajay Shah wrote:

> I know this:
> 
>   > library(date)
>   > x="1979-04-04"
>   > try=as.date(x, "ymd")
>   > print(try)
>   [1] 4Apr79
> 
> and that `x' here has to be a string, e.g.:
> 
>   > x=1979-04-04
>   > print(x)
>   [1] 1971
> 
> I'm stuck in reading from a file. I say:  
> 
>   > A <- read.table(file="try")
>   > print(A)
>              V1          V2
>   1  1979-04-04 -1.04712042
>   2  1979-04-06  0.54538055
>   3  1979-04-09  0.09663392
>   4  1979-04-11  0.57119871
>   5  1979-04-12  0.73594112
>   6  1979-04-17 -1.54422087
>   7  1979-04-18 -0.20595691
>   8  1979-04-19  0.12700429
>   9  1979-04-20  0.42016807
>   10 1979-04-23 -1.46838241
> 
> I am confused - is V1 a number or a string? Looking at it, it must be
> a string. But yet:
> 
>   > library(date)
>   > try=as.date(A$V1, "ymd")
>   Error in as.date(A$V1, "ymd") : Cannot coerce to date format
> 
> In short, how do I parse in dates of the format yyyy-mm-dd (the ISO
> 8601 format) or the yyyymmdd format.
> 
> And if I may ask the next step: How do I tell R that I have a file
> full of data all of which is time-series data, where V1 is the
> datetime vector, and all the other columns are time-series, to do
> things like ARMA models and ts plots with?
> 

To see what class a column in a data.frame is the best way is to try:

sapply(A, data.class)

My guess is that "V1" is being read in as a factor (default). To convert 
to character to use with as.date, then use

as.date(as.character(A$V1), "ymd")

BTW, I would avoid using "try" as a variable name since "try" is a 
function in the base package.

As for you second question, see the package ts for ARIMA
modeling.

-sundar



From macq at llnl.gov  Mon Feb 23 21:28:29 2004
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 23 Feb 2004 12:28:29 -0800
Subject: [R] Need help on parsing dates
In-Reply-To: <20040223200723.GO781@igidr.ac.in>
References: <20040223200723.GO781@igidr.ac.in>
Message-ID: <p0600200cbc60123d2438@[128.115.153.6]>

At 1:37 AM +0530 2/24/04, Ajay Shah wrote:
>I know this:
>
>   > library(date)
>   > x="1979-04-04"
>   > try=as.date(x, "ymd")
>   > print(try)
>   [1] 4Apr79
>
>and that `x' here has to be a string, e.g.:
>
>   > x=1979-04-04
>   > print(x)
>   [1] 1971
>
>I'm stuck in reading from a file. I say: 
>
>   > A <- read.table(file="try")
>   > print(A)
>              V1          V2
>   1  1979-04-04 -1.04712042
>   2  1979-04-06  0.54538055
>   3  1979-04-09  0.09663392
>   4  1979-04-11  0.57119871
>   5  1979-04-12  0.73594112
>   6  1979-04-17 -1.54422087
>   7  1979-04-18 -0.20595691
>   8  1979-04-19  0.12700429
>   9  1979-04-20  0.42016807
>   10 1979-04-23 -1.46838241
>
>I am confused - is V1 a number or a string? Looking at it, it must be
>a string. But yet:

You can find out what it is by asking:
   mode(A$V1)
   class(A$V1)
   str(A$V1)
and there are no doubt some other ways to ask.

>
>   > library(date)
>   > try=as.date(A$V1, "ymd")
>   Error in as.date(A$V1, "ymd") : Cannot coerce to date format
>
>In short, how do I parse in dates of the format yyyy-mm-dd (the ISO
>8601 format) or the yyyymmdd format.
>
>And if I may ask the next step: How do I tell R that I have a file
>full of data all of which is time-series data, where V1 is the
>datetime vector, and all the other columns are time-series, to do
>things like ARMA models and ts plots with?
>
>--
>Ajay Shah                                                   Consultant
>ajayshah at mayin.org                      Department of Economic Affairs
>http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From bates at stat.wisc.edu  Mon Feb 23 21:24:10 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 23 Feb 2004 14:24:10 -0600
Subject: [R] parameters' value
In-Reply-To: <76E50A283589324FA6A1999EEFBB134127D25B@UTHEVS1.mail.uthouston.edu>
References: <76E50A283589324FA6A1999EEFBB134127D25B@UTHEVS1.mail.uthouston.edu>
Message-ID: <6rn079fst1.fsf@bates4.stat.wisc.edu>

"Duan Zhigang" <zduan1 at uthouston.edu> writes:

> Hi, I am a new user of R. I am trying to use R to do some nonlinear
> modeling. However, I can not find how to get the parameters's value
> back.

> Here is the code in S-plus: 
> 
> ycos1.nl <- nls(y ~ m +ac*cos(2*pi*f*t) +as*sin(2*pi*f*t), start=nl.st, trace=T)
> 
> ## store model info after satisfactory model has been found
> cNL1 <- c(ycos1.nl$parameters[1:3],0)
> 
> What is same code in R? 

The preferred approach is to use the coef extractor function.  This
works in both R and S-PLUS.

coef(ycos1.nl)



From agustin.perez at umh.es  Mon Feb 23 21:30:57 2004
From: agustin.perez at umh.es (Perez Martin, Agustin)
Date: Mon, 23 Feb 2004 21:30:57 +0100
Subject: [R] library nnet
Message-ID: <5AFDDD57E2771B409224CD858CC6DE0D02DAB3A1@mailer-e051.umh.es>

DeaR useRs:

I am looking for a function which fits a multinomial model and in Baron?s
page I find the function "multinom" in package "nnet" but this package is
deprecated.

I suppose that this function is now in other package but I can't find it.

Can you help me?

Thanks.



From wolski at molgen.mpg.de  Mon Feb 23 21:34:13 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 23 Feb 2004 21:34:13 +0100
Subject: [R] HTTP Post connections in R
In-Reply-To: <20040223201340.26608.qmail@web12404.mail.yahoo.com>
References: <20040223201340.26608.qmail@web12404.mail.yahoo.com>
Message-ID: <200402232134130640.027691D4@harry.molgen.mpg.de>

Hi!

Yes! There is a httpRequest0.0.1 package on cran.

Uploaded today version 0.0.2 correcting a bug. Will be on cran soon.

Comments are welcome.

Salutations.
Eryk


*********** REPLY SEPARATOR  ***********

On 2/23/2004 at 12:13 PM Nathan Whitehouse wrote:

>Hi,
>
>  Is there any existing functions to open an HTTP
>connection and HTTP POST some R data?
>
>  like
>  <form method="post" enctype="multipart/form-data">
>    etc.
>  </form>
>  but within R.
>
>  Thanks,
>  
>
>  
>
>=====
>Nathan Whitehouse
>Statistics/Programming
>Baylor College of Medicine
>Houston, TX, USA
>nlwhitehouse at yahoo.com
>
>http://rho-project.org: rho- open source web services for R.
>http://franklin.imgen.bcm.tmc.edu: Shaw laboratory, bcm.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics   
Ihnestrasse 73 14195 Berlin          'v'    
tel: 0049-30-84131285               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski 

From andy_liaw at merck.com  Mon Feb 23 21:47:29 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 23 Feb 2004 15:47:29 -0500
Subject: [R] library nnet
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7849@usrymx25.merck.com>

Are you sure?  I just checked on CRAN (US mirror) and it says:

VR: 
Functions and datasets to support Venables and Ripley, 'Modern Applied
Statistics with S' (4th edition). Bundle of: MASS class nnet spatial 
Version: 7.1-14 
Priority: recommended 
Depends: R (>= 1.8.0), lattice, nlme (>= 3.1-40), survival 
Date: 2004-01-21 
Author: S original by Venables & Ripley. R port by Brian Ripley
<ripley at stats.ox.ac.uk>, following earlier work by Kurt Hornik and Albrecht
Gebhardt. 
Maintainer: Brian Ripley <ripley at stats.ox.ac.uk> 
License: GPL (version 2 or later) 
URL: http://www.stats.ox.ac.uk/pub/MASS4/ 


Andy

> From: Perez Martin, Agustin
> 
> DeaR useRs:
> 
> I am looking for a function which fits a multinomial model 
> and in Baron?s
> page I find the function "multinom" in package "nnet" but 
> this package is
> deprecated.
> 
> I suppose that this function is now in other package but I 
> can't find it.
> 
> Can you help me?
> 
> Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ripley at stats.ox.ac.uk  Mon Feb 23 22:37:50 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Feb 2004 21:37:50 +0000 (GMT)
Subject: [R] library nnet
In-Reply-To: <5AFDDD57E2771B409224CD858CC6DE0D02DAB3A1@mailer-e051.umh.es>
Message-ID: <Pine.LNX.4.44.0402232136350.1747-100000@gannet.stats>

`Recommended' not `deprecated'.

nnet is part of the VR bundle that should be in all complete R 
installations.  Did you actually look in yours?

On Mon, 23 Feb 2004, Perez Martin, Agustin wrote:

> DeaR useRs:
> 
> I am looking for a function which fits a multinomial model and in Baron?s
> page I find the function "multinom" in package "nnet" but this package is
> deprecated.
> 
> I suppose that this function is now in other package but I can't find it.

Why do you suppose so?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mmiller3 at iupui.edu  Mon Feb 23 22:42:49 2004
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Mon, 23 Feb 2004 16:42:49 -0500
Subject: [R] R: Including R plots in a Microsoft Word document
References: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>
	<20040220163635.GB26073@pusa.informat.uv.es> <40366467.20709@ku.edu>
	<20040220164433.34895083.feh3k@spamcop.net>
Message-ID: <873c91wjza.fsf@lumen.indyrad.iupui.edu>

>>>>> "Frank" == Frank E Harrell <feh3k at spamcop.net> writes:

    > Also, has anyone tried creating a Word document using
    > OpenOffice with figures imported from R?

I've tried that.  It works fine with openoffice, but not with
word.  For example, create a postscript file with R like this:

> postscript('tmp.eps',  paper = "special", width=5,height=5, horizontal=F, onefile=F)
> plot(seq(20))
> dev.off()

Then add a preview with epstool -tg --device tiffg3 tmp.eps tmp-tiff.eps

If I insert this figure into an openoffice text document, I see
the bitmap preview and it prints nicely on a postscript printer.

If I save the openoffice document as "Microsoft Word 97/2000/XP",
the figure looks the same on the screen in word as openoffice,
but when I print with word, I just get the bitmap preview, not
the nice postscript.  If I print the doc file with openoffice, it
works fine too. 

Note that this is all for OpenOffice 1.0.3 and Word 2000 on
windows 2000 pro.  I get similar results for openoffice 1.1 on
windows and various linuxes too.

Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine



From thpe at hhbio.wasser.tu-dresden.de  Mon Feb 23 22:44:54 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Mon, 23 Feb 2004 22:44:54 +0100
Subject: [R] library nnet
In-Reply-To: <5AFDDD57E2771B409224CD858CC6DE0D02DAB3A1@mailer-e051.umh.es>
References: <5AFDDD57E2771B409224CD858CC6DE0D02DAB3A1@mailer-e051.umh.es>
Message-ID: <403A7456.8080003@hhbio.wasser.tu-dresden.de>

Perez Martin, Agustin wrote:
> DeaR useRs:
> 
> I am looking for a function which fits a multinomial model and in Baron?s
> page I find the function "multinom" in package "nnet" but this package is
> deprecated.

Really? What do you mean with deprecated?

> I suppose that this function is now in other package but I can't find it.

AFAIK "multinom" is still in "nnet" and "nnet" is still part of the 
package bundle "MASS".

Hope it helps.

Thomas P.



From rxg218 at psu.edu  Mon Feb 23 23:18:33 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Mon, 23 Feb 2004 17:18:33 -0500
Subject: [R] intersection points of two functions
Message-ID: <1077574713.12359.7.camel@ra.chem.psu.edu>

Hi,
  I have two functions (which are basically fouriers series) and I would
like to find the points of intersection (in general there will be more
than one). Is there any function in R which would allow me to solve the
equations? Or should I be looking at packages like octave/mathematica?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
A bug in the code is worth two in the documentation.



From ggrothendieck at myway.com  Mon Feb 23 23:22:42 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 23 Feb 2004 17:22:42 -0500 (EST)
Subject: [R] Need help on parsing dates
Message-ID: <20040223222242.B9E0D3975@mprdmxin.myway.com>



There are a number of ways to do this.  First read in the data 
using the as.is=1 argument to ensure that the date is read 
in as character:

   z <- read.table(myfile, as.is=1, sep=" ", col.names=c("Date", "Data"))

Now you can create a date column using date, POSIXct, chron or irts:

   # date
   require(date)  
   z$Date <- as.date(z$Date,format="ymd"))

   # POSIXct
   z$Date <- as.POSIXct(z$Date))

   # chron
   require(chron)
   z$Date <- chron(z$Date, "y-m-d")

You can create a ts timeseries (which is regular) by ignoring t
he dates altogether:

   z.ts <- ts(z$Data)

Or an irts irregular time series using package tseries:

   require(tseries)
   z.irts <- irts(as.POSIXct(z$Date), z$Data)

Or an its irregular time series using package its:

   require(its)
   z.its <- readcsvIts(myfile, sep=" ", col.names=c("Date", "Data"))

Assuming z.ts was used you can do this:

ar(z.ts, order=1)
etc.

---
Date:   Tue, 24 Feb 2004 01:37:23 +0530 
From:   Ajay Shah <ajayshah at mayin.org>
To:   r-help <r-help at stat.math.ethz.ch> 
Subject:   [R] Need help on parsing dates 

 
I know this:

> library(date)
> x="1979-04-04"
> try=as.date(x, "ymd")
> print(try)
[1] 4Apr79

and that `x' here has to be a string, e.g.:

> x=1979-04-04
> print(x)
[1] 1971

I'm stuck in reading from a file. I say: 

> A <- read.table(file="try")
> print(A)
V1 V2
1 1979-04-04 -1.04712042
2 1979-04-06 0.54538055
3 1979-04-09 0.09663392
4 1979-04-11 0.57119871
5 1979-04-12 0.73594112
6 1979-04-17 -1.54422087
7 1979-04-18 -0.20595691
8 1979-04-19 0.12700429
9 1979-04-20 0.42016807
10 1979-04-23 -1.46838241

I am confused - is V1 a number or a string? Looking at it, it must be
a string. But yet:

> library(date)
> try=as.date(A$V1, "ymd")
Error in as.date(A$V1, "ymd") : Cannot coerce to date format

In short, how do I parse in dates of the format yyyy-mm-dd (the ISO
8601 format) or the yyyymmdd format.

And if I may ask the next step: How do I tell R that I have a file
full of data all of which is time-series data, where V1 is the
datetime vector, and all the other columns are time-series, to do
things like ARMA models and ts plots with?



From andy_liaw at merck.com  Mon Feb 23 23:58:06 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 23 Feb 2004 17:58:06 -0500
Subject: [R] intersection points of two functions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF784F@usrymx25.merck.com>

If both functions are univariate, you can define the difference between the
two as the objective function and use uniroot() to find the intersection
(where the difference is 0).  If the functions are multivariate, you can use
optim() to minimize the squared or absolute difference between the two
functions, instead of uniroot().

HTH,
Andy

> From: Rajarshi Guha
> 
> Hi,
>   I have two functions (which are basically fouriers series) 
> and I would
> like to find the points of intersection (in general there will be more
> than one). Is there any function in R which would allow me to 
> solve the
> equations? Or should I be looking at packages like octave/mathematica?
> 
> Thanks,
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> A bug in the code is worth two in the documentation.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From cbarrera at umich.edu  Tue Feb 24 00:33:39 2004
From: cbarrera at umich.edu (cbarrera@umich.edu)
Date: Mon, 23 Feb 2004 18:33:39 -0500
Subject: [R] (2) Questions
Message-ID: <1077579219.403a8dd35ba87@mail.umich.edu>

Hi Fellows from R-Help List!

My questions are basic since i an new with R. I am very acquainted with Matlab &
Gauss (the compentence, I guess). Anyhow, 

(1) I am trying to get R execute comands made or built as text, so that one can
feed a particular option with many variations coming from a text file. Is this
possible with the free version? For instance, there exists the eval comand in
Matlab, which executes the matlab comand in the text argument incoming thru
eval.

(2) Is there any way to avoid the automatic stop of a redundant NL estimation,
like for instance, the one behind arima()? Usually, when the NL problem has
spikes or the like, even the global optimizer procedures stop. If many models
are supposed to be estimated and you just want to bypass those badly-behaved
models (and store the many statistic values just as NAs), such a stop makes you
correct the loop indexes and re-run the program. How to avoid it?

Best

Carlos



From stephane.dray at umontreal.ca  Tue Feb 24 00:46:34 2004
From: stephane.dray at umontreal.ca (Stephane DRAY)
Date: Mon, 23 Feb 2004 18:46:34 -0500
Subject: [R] orthonormalization with weights
Message-ID: <5.2.1.1.0.20040223182453.00b81ff8@magellan.umontreal.ca>

Hello List,
I would like to orthonormalize vectors contained in a matrix X  taking into 
account row weights (matrix diagonal D). ie, I want to obtain Z=XA with 
t(Z)%*%D%*%Z=diag(1)

I can do the Gram-Schmidt orthogonalization with subsequent weighted 
regressions. I know that in the case of uniform weights, qr can do the 
trick. I wonder if there is a way to do it in the case of non uniform 
weights by qr or svd ?

Thanks in advances.
St?phane DRAY
-------------------------------------------------------------------------------------------------- 

D?partement des Sciences Biologiques
Universit? de Montr?al, C.P. 6128, succursale centre-ville
Montr?al, Qu?bec H3C 3J7, Canada

Tel : 514 343 6111 poste 1233
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From k.wang at auckland.ac.nz  Tue Feb 24 00:49:53 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 24 Feb 2004 12:49:53 +1300
Subject: [R] (2) Questions
In-Reply-To: <1077579219.403a8dd35ba87@mail.umich.edu>
Message-ID: <000001c3fa67$bbbbd310$6633d882@stat.auckland.ac.nz>

Hi,

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> cbarrera at umich.edu
> Sent: Tuesday, February 24, 2004 12:34 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] (2) Questions
> 
> 
> Hi Fellows from R-Help List!
> 
> My questions are basic since i an new with R. I am very 
> acquainted with Matlab &
> Gauss (the compentence, I guess). Anyhow, 
> 
> (1) I am trying to get R execute comands made or built as 
> text, so that one can
> feed a particular option with many variations coming from a 
> text file. Is this
> possible with the free version? For instance, there exists 
> the eval comand in
> Matlab, which executes the matlab comand in the text argument 
> incoming thru
> eval.
> 

I think what you need to do first is to read the manuals.  "An
Introduction to R" would be a good start.  There is no "free version" vs
"commercial version".  R is open-sourced and you don't have to pay for
it -- of course, "donations" are welcome by the R Foundation ;D.

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
Statistics Workshops Co-ordinator
Student Learning Centre
University of Auckland
New Zealand



From andy_liaw at merck.com  Tue Feb 24 00:54:59 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 23 Feb 2004 18:54:59 -0500
Subject: [R] (2) Questions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7850@usrymx25.merck.com>

> From: cbarrera at umich.edu
> 
> Hi Fellows from R-Help List!
> 
> My questions are basic since i an new with R. I am very 
> acquainted with Matlab &
> Gauss (the compentence, I guess). Anyhow, 
> 
> (1) I am trying to get R execute comands made or built as 
> text, so that one can
> feed a particular option with many variations coming from a 
> text file. Is this
> possible with the free version? For instance, there exists 
> the eval comand in
> Matlab, which executes the matlab comand in the text argument 
> incoming thru
> eval.

I guess you are looking for... eval():

> cmd <- "x <- rnorm(30); summary(x)"
> eval(parse(text=cmd))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-1.6040 -0.3406  0.1896  0.1868  0.8361  1.8930 

Not sure what you mean by `free version'.  Do you know of a non-free
version?

> (2) Is there any way to avoid the automatic stop of a 
> redundant NL estimation,
> like for instance, the one behind arima()? Usually, when the 
> NL problem has
> spikes or the like, even the global optimizer procedures 
> stop. If many models
> are supposed to be estimated and you just want to bypass 
> those badly-behaved
> models (and store the many statistic values just as NAs), 
> such a stop makes you
> correct the loop indexes and re-run the program. How to avoid it?

I guess you are looking for try() or tryCatch().

HTH,
Andy
 
> Best
> 
> Carlos
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From lixian7001 at yahoo.com  Tue Feb 24 01:53:25 2004
From: lixian7001 at yahoo.com (li xian)
Date: Mon, 23 Feb 2004 16:53:25 -0800 (PST)
Subject: [R] quesion on diag of matrix
Message-ID: <20040224005325.29578.qmail@web11509.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040223/5aa03b6a/attachment.pl

From jeaneid at chass.utoronto.ca  Tue Feb 24 02:06:11 2004
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Mon, 23 Feb 2004 20:06:11 -0500
Subject: [R] Need help on parsing dates
In-Reply-To: <20040223200723.GO781@igidr.ac.in>
Message-ID: <Pine.SGI.4.40.0402232005150.18692008-100000@origin.chass.utoronto.ca>

 ?as.POSIXlt

On Tue, 24 Feb 2004, Ajay Shah wrote:

> I know this:
>
>   > library(date)
>   > x="1979-04-04"
>   > try=as.date(x, "ymd")
>   > print(try)
>   [1] 4Apr79
>
> and that `x' here has to be a string, e.g.:
>
>   > x=1979-04-04
>   > print(x)
>   [1] 1971
>
> I'm stuck in reading from a file. I say:
>
>   > A <- read.table(file="try")
>   > print(A)
>              V1          V2
>   1  1979-04-04 -1.04712042
>   2  1979-04-06  0.54538055
>   3  1979-04-09  0.09663392
>   4  1979-04-11  0.57119871
>   5  1979-04-12  0.73594112
>   6  1979-04-17 -1.54422087
>   7  1979-04-18 -0.20595691
>   8  1979-04-19  0.12700429
>   9  1979-04-20  0.42016807
>   10 1979-04-23 -1.46838241
>
> I am confused - is V1 a number or a string? Looking at it, it must be
> a string. But yet:
>
>   > library(date)
>   > try=as.date(A$V1, "ymd")
>   Error in as.date(A$V1, "ymd") : Cannot coerce to date format
>
> In short, how do I parse in dates of the format yyyy-mm-dd (the ISO
> 8601 format) or the yyyymmdd format.
>
> And if I may ask the next step: How do I tell R that I have a file
> full of data all of which is time-series data, where V1 is the
> datetime vector, and all the other columns are time-series, to do
> things like ARMA models and ts plots with?
>
> --
> Ajay Shah                                                   Consultant
> ajayshah at mayin.org                      Department of Economic Affairs
> http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jeaneid at chass.utoronto.ca  Tue Feb 24 02:24:03 2004
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Mon, 23 Feb 2004 20:24:03 -0500
Subject: [R] parameters' value
In-Reply-To: <76E50A283589324FA6A1999EEFBB134127D25B@UTHEVS1.mail.uthouston.edu>
Message-ID: <Pine.SGI.4.40.0402232022380.18692008-100000@origin.chass.utoronto.ca>



On Mon, 23 Feb 2004, Duan Zhigang wrote:

> Hi, I am a new user of R. I am trying to use R to do some nonlinear modeling. However, I can not find how to get the parameters's value back.
>
> Here is the code in S-plus:
>
> ycos1.nl <- nls(y ~ m +ac*cos(2*pi*f*t) +as*sin(2*pi*f*t), start=nl.st, trace=T)
>
> ## store model info after satisfactory model has been found
> cNL1 <- c(ycos1.nl$parameters[1:3],0)

   cNL1 <- c(ycos1.nl$m$getPars()[1:3],0)



>
> What is same code in R?
>
> Thanks a lot.
>
> Duan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Tue Feb 24 02:29:46 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 23 Feb 2004 17:29:46 -0800
Subject: [R] quesion on diag of matrix
In-Reply-To: <20040224005325.29578.qmail@web11509.mail.yahoo.com>
References: <20040224005325.29578.qmail@web11509.mail.yahoo.com>
Message-ID: <403AA90A.6030105@pdf.com>

 > A <- array(1:4, dim=c(2,2))
 > sum(diag(A))
[1] 5

      Is that what you want? 
      spencer graves

li xian wrote:

>How to get the sum of the diag of matrix?
>Thanks!
>
>
>---------------------------------
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From MSchwartz at medanalytics.com  Tue Feb 24 02:30:30 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 23 Feb 2004 19:30:30 -0600
Subject: [R] quesion on diag of matrix
In-Reply-To: <20040224005325.29578.qmail@web11509.mail.yahoo.com>
References: <20040224005325.29578.qmail@web11509.mail.yahoo.com>
Message-ID: <1077586229.16414.79.camel@localhost.localdomain>

On Mon, 2004-02-23 at 18:53, li xian wrote:
> How to get the sum of the diag of matrix?
> Thanks!


If 'm' is your matrix:

sum(diag(m))

See ?sum and ?diag, the latter of which will extract the diagonal of the
matrix. 

Be sure to read the help for diag() fully for some of the usage caveats.

HTH,

Marc Schwartz



From jeaneid at chass.utoronto.ca  Tue Feb 24 02:59:49 2004
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Mon, 23 Feb 2004 20:59:49 -0500
Subject: [R] quesion on diag of matrix
In-Reply-To: <20040224005325.29578.qmail@web11509.mail.yahoo.com>
Message-ID: <Pine.SGI.4.40.0402232058460.20300409-100000@origin.chass.utoronto.ca>

sum(diag(X))

On Mon, 23 Feb 2004, li xian wrote:

> How to get the sum of the diag of matrix?
> Thanks!
>
>
> ---------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at myway.com  Tue Feb 24 03:38:15 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 23 Feb 2004 21:38:15 -0500 (EST)
Subject: [R] orthonormalization with weights
Message-ID: <20040224023815.C0BCC39F1@mprdmxin.myway.com>



Let QR be such that sqrt(D)X = QR. Then letting
solve(...) denote the inverse of ... we have
X = solve(sqrt(D))QR  which is of the form ZR 
and Z has the desired weighted orthoginality 
property.  

Since D is diagonal, solve(sqrt(D)) equals 
diag(1/sqrt(diag(D))) so we get this for Z:

   diag(1/sqrt(diag(D))) %*% qr.Q(qr(X))

---
Date:   Mon, 23 Feb 2004 18:46:34 -0500 
From:   Stephane DRAY <stephane.dray at umontreal.ca>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] orthonormalization with weights 

 
Hello List,
I would like to orthonormalize vectors contained in a matrix X taking into 
account row weights (matrix diagonal D). ie, I want to obtain Z=XA with 
t(Z)%*%D%*%Z=diag(1)

I can do the Gram-Schmidt orthogonalization with subsequent weighted 
regressions. I know that in the case of uniform weights, qr can do the 
trick. I wonder if there is a way to do it in the case of non uniform 
weights by qr or svd ?

Thanks in advances.
Stphane DRAY
-------------------------------------------------------------------------------------------------- 

Dpartement des Sciences Biologiques
Universit de Montral, C.P. 6128, succursale centre-ville
Montral, Qubec H3C 3J7, Canada

Tel : 514 343 6111 poste 1233
E-mail : stephane.dray at umontreal.ca



From ggrothendieck at myway.com  Tue Feb 24 04:00:37 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 23 Feb 2004 22:00:37 -0500 (EST)
Subject: [R] orthonormalization with weights
Message-ID: <20040224030037.A0420395E@mprdmxin.myway.com>


Obviously the R code does not match the 
description I gave since we should be taking
the QR decomp of sqrt(D)X, not X.  Z should be:

 diag(1/sqrt(diag(D))) %*% qr.Q(qr(sqrt(D)%*%X))

---
Date:   Mon, 23 Feb 2004 21:38:15 -0500 (EST) 
From:   Gabor Grothendieck <ggrothendieck at myway.com>
To:   <stephane.dray at umontreal.ca>, <r-help at stat.math.ethz.ch> 
Subject:   RE: [R] orthonormalization with weights 

 diag(1/sqrt(diag(D))) %*% qr.Q(qr(X))



Let QR be such that sqrt(D)X = QR. Then letting
solve(...) denote the inverse of ... we have
X = solve(sqrt(D))QR which is of the form ZR 
and Z has the desired weighted orthoginality 
property. 

Since D is diagonal, solve(sqrt(D)) equals 
diag(1/sqrt(diag(D))) so we get this for Z:

diag(1/sqrt(diag(D))) %*% qr.Q(qr(X))

---
Date: Mon, 23 Feb 2004 18:46:34 -0500 
From: Stephane DRAY <stephane.dray at umontreal.ca>
To: <r-help at stat.math.ethz.ch> 
Subject: [R] orthonormalization with weights 


Hello List,
I would like to orthonormalize vectors contained in a matrix X taking into 
account row weights (matrix diagonal D). ie, I want to obtain Z=XA with 
t(Z)%*%D%*%Z=diag(1)

I can do the Gram-Schmidt orthogonalization with subsequent weighted 
regressions. I know that in the case of uniform weights, qr can do the 
trick. I wonder if there is a way to do it in the case of non uniform 
weights by qr or svd ?

Thanks in advances.
Stphane DRAY



From maj at stats.waikato.ac.nz  Tue Feb 24 04:24:27 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue, 24 Feb 2004 16:24:27 +1300
Subject: [R] Sweave and sep = "\t"
Message-ID: <403AC3EB.40200@stats.waikato.ac.nz>

In my .Snw file:

<<>>=
fyle <- choose.files()
fyle
f <- count.fields(fyle, sep = "\t")
f
@

and in the .tex file:

\begin{Schunk}
\begin{Sinput}
 > fyle <- choose.files()
 > fyle
\end{Sinput}
\begin{Soutput}
[1] "C:\\Files\\Data\\Cars03\\Rover.txt"
\end{Soutput}
\begin{Sinput}
 > f <- count.fields(fyle, sep = "   ")
 > f
\end{Sinput}
\begin{Soutput}
[1] 8 8 8 8 8
\end{Soutput}
\end{Schunk}

But I want the sep = "\t" to be left as is.

Murray
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From Don.Driscoll at flinders.edu.au  Tue Feb 24 07:04:53 2004
From: Don.Driscoll at flinders.edu.au (Don Driscoll)
Date: Tue, 24 Feb 2004 16:34:53 +1030
Subject: [R] (no subject)
Message-ID: <6.0.1.1.1.20040224163024.01b3d1b8@mail.flinders.edu.au>

G'day,

I'm fitting a simple one-way nested anova and would like to obtain standard 
errors or confidence limits.  I'm using se.contrast to try to get se for 
the contrast between the two levels of the main effect, but I get an error 
message (see below).  What is going on?

Don

 > shp<-factor(rep(c("reserve","strip"),each=96))
 > site<-factor(rep(c("1g","1p", 
"1t","2g","2p","2t","3g","3p","3t","4g","4p","4t"),each=16))
 > pit<-factor(rep(1:16,12))
 > 
reptsp<-c(4,5,6,4,6,6,6,7,3,5,2,2,4,8,5,4,2,4,2,2,4,5,2,4,4,4,3,2,3,2,5,3,5,3,4,4,4,3,4,3,4,4,4,3,4,3,6,3,3,5,4,6,4,4,2,4,2,6,5,5,5,7,4,4,5,1,4,5,6,5,5,2,6,3,5,6,4,5,4,8,2,4,2,4,2,4,3,3,4,4,3,2,1,3,4,4,2,2,3,2,4,1,2,2,3,4,5,5,3,5,5,4,1,1,2,1,3,1,4,1,6,1,2,3,2,2,2,1,1,2,2,6,5,3,2,3,5,3,2,3,2,1,3,2,4,4,3,3,3,1,2,4,3,4,5,6,5,2,3,2,2,5,5,5,2,2,5,2,4,4,3,2,2,3,2,2,2,2,5,4,3,3,5,2,5,4,3,2,2,2,1,2)
 > ddata<-data.frame(shp,pit,site,reptsp)
 > #Fit a Standard Nested Anova Model
 > repmod1<-aov(reptsp~shp/site/pit+ Error(shp/site/pit))
 > summary(repmod1)

Error: shp
     Df Sum Sq Mean Sq
shp  1  53.13   53.13

Error: shp:site
          Df Sum Sq Mean Sq
shp:site 10 61.885   6.189

Error: shp:site:pit
               Df Sum Sq Mean Sq
shp:site:pit 180 318.56    1.77
 > se.contrast(repmod1, list(shp=="strip", shp=="reserve"),data=ddata)
Error in rep.int(n.object - 1, nrow(c.qr) - length(e.assign)) :
         invalid number of copies in "rep"



From Don.Driscoll at flinders.edu.au  Tue Feb 24 07:05:53 2004
From: Don.Driscoll at flinders.edu.au (Don Driscoll)
Date: Tue, 24 Feb 2004 16:35:53 +1030
Subject: [R] se.contrast
Message-ID: <6.0.1.1.1.20040224163539.01b46b38@mail.flinders.edu.au>

G'day,

I'm fitting a simple one-way nested anova and would like to obtain standard 
errors or confidence limits.  I'm using se.contrast to try to get se for 
the contrast between the two levels of the main effect, but I get an error 
message (see below).  What is going on?

Don

 > shp<-factor(rep(c("reserve","strip"),each=96))
 > site<-factor(rep(c("1g","1p", 
"1t","2g","2p","2t","3g","3p","3t","4g","4p","4t"),each=16))
 > pit<-factor(rep(1:16,12))
 > 
reptsp<-c(4,5,6,4,6,6,6,7,3,5,2,2,4,8,5,4,2,4,2,2,4,5,2,4,4,4,3,2,3,2,5,3,5,3,4,4,4,3,4,3,4,4,4,3,4,3,6,3,3,5,4,6,4,4,2,4,2,6,5,5,5,7,4,4,5,1,4,5,6,5,5,2,6,3,5,6,4,5,4,8,2,4,2,4,2,4,3,3,4,4,3,2,1,3,4,4,2,2,3,2,4,1,2,2,3,4,5,5,3,5,5,4,1,1,2,1,3,1,4,1,6,1,2,3,2,2,2,1,1,2,2,6,5,3,2,3,5,3,2,3,2,1,3,2,4,4,3,3,3,1,2,4,3,4,5,6,5,2,3,2,2,5,5,5,2,2,5,2,4,4,3,2,2,3,2,2,2,2,5,4,3,3,5,2,5,4,3,2,2,2,1,2)
 > ddata<-data.frame(shp,pit,site,reptsp)
 > #Fit a Standard Nested Anova Model
 > repmod1<-aov(reptsp~shp/site/pit+ Error(shp/site/pit))
 > summary(repmod1)

Error: shp
     Df Sum Sq Mean Sq
shp  1  53.13   53.13

Error: shp:site
          Df Sum Sq Mean Sq
shp:site 10 61.885   6.189

Error: shp:site:pit
               Df Sum Sq Mean Sq
shp:site:pit 180 318.56    1.77
 > se.contrast(repmod1, list(shp=="strip", shp=="reserve"),data=ddata)
Error in rep.int(n.object - 1, nrow(c.qr) - length(e.assign)) :
         invalid number of copies in "rep"



From erich.neuwirth at univie.ac.at  Tue Feb 24 09:16:37 2004
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Tue, 24 Feb 2004 09:16:37 +0100
Subject: [R] R: Including R plots in a Microsoft Word document
In-Reply-To: <873c91wjza.fsf@lumen.indyrad.iupui.edu>
References: <005901c3f7c9$d7dd5640$0d00a8c0@okasha>	<20040220163635.GB26073@pusa.informat.uv.es>
	<40366467.20709@ku.edu>	<20040220164433.34895083.feh3k@spamcop.net>
	<873c91wjza.fsf@lumen.indyrad.iupui.edu>
Message-ID: <403B0865.9090005@univie.ac.at>

Saving as a metafile should to the trick.
emf files work nicely in Word.


Michael A. Miller wrote:

>>>>>>"Frank" == Frank E Harrell <feh3k at spamcop.net> writes:
> 
> 
>     > Also, has anyone tried creating a Word document using
>     > OpenOffice with figures imported from R?
> 
> I've tried that.  It works fine with openoffice, but not with
> word.  For example, create a postscript file with R like this:

-- 
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386



From ozric at web.de  Tue Feb 24 09:30:37 2004
From: ozric at web.de (Christian Schulz)
Date: Tue, 24 Feb 2004 09:30:37 +0100
Subject: [R] Filter out some levels?
Message-ID: <200402240930.37537.ozric@web.de>

Hi ,

how is it possible t cut some levels from one factor to  subsetting  a 
data.frame on?

subdata <- subset(data, data$FACTOR="1" | 
data$FACTOR="BETA" | data$FACTOR="XY")
???

Maybe a modifcation here is better, but how?
mergex[mergex$PLZX %in% levels(mergex$PLZX) ,]


Many thanks and regards,
Christian



From deleeuw at stat.ucla.edu  Tue Feb 24 09:52:51 2004
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Tue, 24 Feb 2004 00:52:51 -0800
Subject: [R] would be nice ... 
Message-ID: <D4389EED-66A6-11D8-8997-000A95A67E82@stat.ucla.edu>

if R had something like

 > python -c "print(sum([1,2,3]));print(3*2)"
6
6

but I guess the only way to do this is by writing the string to
a tmp file and then doing something like "R CMD BATCH --quiet"
on the tmp file

I would like to use this for an R service, which allows you to
select any string in any application and replace it by its
R evaluation

===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au



From maechler at stat.math.ethz.ch  Tue Feb 24 10:07:32 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 24 Feb 2004 10:07:32 +0100
Subject: [R] would be nice ... 
In-Reply-To: <D4389EED-66A6-11D8-8997-000A95A67E82@stat.ucla.edu>
References: <D4389EED-66A6-11D8-8997-000A95A67E82@stat.ucla.edu>
Message-ID: <16443.5204.413726.233082@gargle.gargle.HOWL>

>>>>> "Jan" == Jan de Leeuw <deleeuw at stat.ucla.edu>
>>>>>     on Tue, 24 Feb 2004 00:52:51 -0800 writes:

    Jan> if R had something like
    >> python -c "print(sum([1,2,3]));print(3*2)"
    Jan> 6 6

    Jan> but I guess the only way to do this is by writing the
    Jan> string to a tmp file and then doing something like "R
    Jan> CMD BATCH --quiet" on the tmp file

Well, a bit better (with a shell prompt "%") is

    % echo "print(sum(c(1,2,3)));print(3*2)" | R --quiet --vanilla

    > print(sum(c(1,2,3)));print(3*2)
    [1] 6
    [1] 6
    > 

or (slightly nicer)

    % echo "sum(c(1,2,3)); 3*2" | R --quiet --vanilla
    > sum(c(1,2,3)); 3*2
    [1] 6
    [1] 6
    > 

but it still echoes the input by default

    Jan> I would like to use this for an R service, which allows
    Jan> you to select any string in any application and replace
    Jan> it by its R evaluation



From ccleland at optonline.net  Tue Feb 24 11:12:51 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 24 Feb 2004 05:12:51 -0500
Subject: [R] Filter out some levels?
In-Reply-To: <200402240930.37537.ozric@web.de>
References: <200402240930.37537.ozric@web.de>
Message-ID: <403B23A3.30509@optonline.net>

Christian Schulz wrote:
> how is it possible t cut some levels from one factor to  subsetting  a 
> data.frame on?
> 
> subdata <- subset(data, data$FACTOR="1" | 
> data$FACTOR="BETA" | data$FACTOR="XY")
> ???
> 
> Maybe a modifcation here is better, but how?
> mergex[mergex$PLZX %in% levels(mergex$PLZX) ,]

Christian:

You need element by element comparison.  Does this help?

mydata <- data.frame(FACTOR = c("1", "BETA", "XY", "DROP"), Y = 
runif(4))

mydata[mydata$FACTOR=="1" | mydata$FACTOR=="XY" | 
mydata$FACTOR=="BETA",]

   FACTOR         Y
1      1 0.5111390
2   BETA 0.7219460
3     XY 0.1346707

mydata[mydata$FACTOR!="DROP",]

   FACTOR         Y
1      1 0.5111390
2   BETA 0.7219460
3     XY 0.1346707

See ?"=="

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From aurora at ebi.ac.uk  Tue Feb 24 12:01:48 2004
From: aurora at ebi.ac.uk (Aurora Torrente)
Date: Tue, 24 Feb 2004 11:01:48 +0000
Subject: [R] Computing the mode
Message-ID: <403B2F1C.8080601@ebi.ac.uk>

Hi all,
I think this question could be quite trivial, but I can?t find out the 
solution... How can you compute the statistic "mode" of a sample, in 
case it exists (as mode() returns the mode of an object)? I tried 
help.search("mode") but I couldn't find a clue...
Any help would be much appreciated. Regards,

        Aurora



From Ulrich.Halekoh at agrsci.dk  Tue Feb 24 12:37:04 2004
From: Ulrich.Halekoh at agrsci.dk (Ulrich Halekoh)
Date: Tue, 24 Feb 2004 12:37:04 +0100
Subject: [R] rstandard does not produce standardized residuals
Message-ID: <EA09C4B2B0F16E44B8F3311629493C0DF219D9@DJFPOST01.djf.agrsci.dk>

Dear all,


the application of the function rstandard() in the base package
 to a glm object does not produce  residuals standardized to 
have variance one:

the reason is that the deviance residuals are  divided
by the dispersion estimate and not by the
square root of the estimate for the dispersion.

Should the function not be changed to produce residuals
with a variance about 1?


R 1.8.1 on windows 2000

ulrich


==============================================================
Ulrich Halekoh,  PhD                         Phone: +45 8999 1825
Biometry Research Unit                       Fax:   +45 8999 1300
Danish Institute of Agricultural Sciences    E-mail: ulrich.halekoh at agrsci.dk
Research Centre Foulum, DK-8830 Tjele, Denmark



From ripley at stats.ox.ac.uk  Tue Feb 24 13:13:11 2004
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 24 Feb 2004 12:13:11 +0000 (GMT Standard Time)
Subject: [R] rstandard does not produce standardized residuals
In-Reply-To: <EA09C4B2B0F16E44B8F3311629493C0DF219D9@DJFPOST01.djf.agrsci.dk>
Message-ID: <Pine.WNT.4.44.0402241211370.2720-100000@gannet.stats.ox.ac.uk>

This has laready been changed in the R-devel version (1.9.0 to be).
Pre-test versions of that for Windows are available on CRAN.

>From the NEWS file


    o	rstandard() was wrongly scaled for cases where
	summary(model)$dispersion != 1.

and that ought to mention glm somewhere ....


On Tue, 24 Feb 2004, Ulrich Halekoh wrote:

> Dear all,
>
>
> the application of the function rstandard() in the base package
>  to a glm object does not produce  residuals standardized to
> have variance one:
>
> the reason is that the deviance residuals are  divided
> by the dispersion estimate and not by the
> square root of the estimate for the dispersion.
>
> Should the function not be changed to produce residuals
> with a variance about 1?
>
>
> R 1.8.1 on windows 2000
>
> ulrich
>
>
> ==============================================================
> Ulrich Halekoh,  PhD                         Phone: +45 8999 1825
> Biometry Research Unit                       Fax:   +45 8999 1300
> Danish Institute of Agricultural Sciences    E-mail: ulrich.halekoh at agrsci.dk
> Research Centre Foulum, DK-8830 Tjele, Denmark
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Tue Feb 24 13:12:17 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 24 Feb 2004 04:12:17 -0800
Subject: [R] Computing the mode
In-Reply-To: <403B2F1C.8080601@ebi.ac.uk>
References: <403B2F1C.8080601@ebi.ac.uk>
Message-ID: <403B3FA1.2050306@pdf.com>

      The problem is that 'the statistic "mode" of a sample' has no 
clear definition.  If the distribution is highly discrete, then the 
following will do the job: 

 > set.seed(1)
 > X <- rpois(11,1)
 > (nX <- table(X))
X
0 1 2 3
4 4 2 1
 > names(nX)[nX==max(nX)]
[1] "0" "1"

      However, if the data are continuous with no 2 numbers exactly 
equal, then the "mode" depends on the procedure, e.g., the specific 
selection of breakpoints for a histogram.  If you insist on finding 
something, you can try "www.r-project.org" -> search -> "R site search" 
for something like ""nonparametric density estimation" and / or "kernel 
density estimator". 

      hope this helps. 
      spencer graves
      p.s.  This has been discussed recently on this list, but I could 
not easily find it in the archives. 

Aurora Torrente wrote:

> Hi all,
> I think this question could be quite trivial, but I can?t find out the 
> solution... How can you compute the statistic "mode" of a sample, in 
> case it exists (as mode() returns the mode of an object)? I tried 
> help.search("mode") but I couldn't find a clue...
> Any help would be much appreciated. Regards,
>
>        Aurora
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From allan at stats.uct.ac.za  Tue Feb 24 13:44:47 2004
From: allan at stats.uct.ac.za (allan clark)
Date: Tue, 24 Feb 2004 14:44:47 +0200
Subject: [R] r: plots
Message-ID: <403B473F.EAF9A4E7@stats.uct.ac.za>

hi all

i have another probably simple question.

I have three variables say x, y and z. x and y are quite large and z is
relative small.
how can one plot the three variables on the same graph with two separate
axis?
(one for x and y and the other for z)

e.g.
x<-c(101,110,150,167,120)
y<-c(120,135,175,95,200)
z<-c(0.001, 0.15, 0.6, 0.8, 1)

regards
Allan



From edd at debian.org  Tue Feb 24 13:49:10 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 24 Feb 2004 06:49:10 -0600
Subject: [R] would be nice ...
In-Reply-To: <16443.5204.413726.233082@gargle.gargle.HOWL>
References: <D4389EED-66A6-11D8-8997-000A95A67E82@stat.ucla.edu>
	<16443.5204.413726.233082@gargle.gargle.HOWL>
Message-ID: <20040224124910.GA10007@sonny.eddelbuettel.com>

On Tue, Feb 24, 2004 at 10:07:32AM +0100, Martin Maechler wrote:
> >>>>> "Jan" == Jan de Leeuw <deleeuw at stat.ucla.edu>
> >>>>>     on Tue, 24 Feb 2004 00:52:51 -0800 writes:
> 
>     Jan> if R had something like
>     >> python -c "print(sum([1,2,3]));print(3*2)"
>     Jan> 6 6
> 
>     Jan> but I guess the only way to do this is by writing the
>     Jan> string to a tmp file and then doing something like "R
>     Jan> CMD BATCH --quiet" on the tmp file
> 
> Well, a bit better (with a shell prompt "%") is
> 
>     % echo "print(sum(c(1,2,3)));print(3*2)" | R --quiet --vanilla
> 
>     > print(sum(c(1,2,3)));print(3*2)
>     [1] 6
>     [1] 6
>     > 
> 
> or (slightly nicer)
> 
>     % echo "sum(c(1,2,3)); 3*2" | R --quiet --vanilla
>     > sum(c(1,2,3)); 3*2
>     [1] 6
>     [1] 6
>     > 
> 
> but it still echoes the input by default

Not with --slave:

edd at chibud:~> echo "sum(c(1,2,3)); 3*2" | R --slave
[1] 6
[1] 6

I would be pretty trivial to filter the "^[1] " out.

Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From claudiapaladini at web.de  Tue Feb 24 14:34:35 2004
From: claudiapaladini at web.de (Claudia Paladini)
Date: Tue, 24 Feb 2004 14:34:35 +0100
Subject: [R] <no subject>
Message-ID: <200402241334.i1ODYZQ25352@mailgate5.cinetic.de>

Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit
X-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on hypatia.math.ethz.ch
X-Spam-Status: No, hits=3.5 required=5.0 tests=BAYES_44,RCVD_IN_BL_SPAMCOP_NET autolearn=no version=2.63
X-Spam-Level: ***

Dear ladies and gentlmen,
I want to import a directory with about 400 files (.dat) in R. I know how to import a single file (with scan...) but I've good no idea how to import 400 at once. Can you help me ?
Thanks a lot!
Claudia 





From thpe at hhbio.wasser.tu-dresden.de  Tue Feb 24 14:34:44 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Tue, 24 Feb 2004 14:34:44 +0100
Subject: [R] Computing the mode
In-Reply-To: <403B2F1C.8080601@ebi.ac.uk>
References: <403B2F1C.8080601@ebi.ac.uk>
Message-ID: <403B52F4.8010107@hhbio.wasser.tu-dresden.de>

Aurora Torrente wrote:
> Hi all,
> I think this question could be quite trivial, but I can?t find out the 
> solution... How can you compute the statistic "mode" of a sample, in 
> case it exists (as mode() returns the mode of an object)? I tried 
> help.search("mode") but I couldn't find a clue...
> Any help would be much appreciated. Regards,

There are several possibilities, e.g for *discrete* data:

  x <- floor(runif(100, min=10, max=20)) # some discrete data

Half a year ago it was proposed to use e.g.:

  x[rev(order(table(x)))[1]]

another possibility is:

  f <- table(x)
  as.numeric(names(f[max(f)==f])) # extracts mode(s) from vector names

For *continuous data* you can use class frequencies (from hist) together
with an interpolation formula. Another approximative solution uses
kernel density estimates (the density function):

  x <- rnorm(100, mean=5, sd=1)  # generate some data
  hist(x, prob=TRUE)
  dens <- density(x)
  lines(dens)
  dens$x[dens$y == max(dens$y)] # gives the mode


The precision depends on the parameters of the density() function. If
the distribution is multi-modal, I use a small function peaks() to
extract several maxima (a generalized version of the one in R-news 
2003/3 p. 9).

Thomas P.

-- 
Thomas Petzoldt
Dresden University of Technology
Institute of Hydrobiology          petzoldt at rcs.urz.tu-dresden.de
01062 Dresden                      http://www.tu-dresden.de/fghhihb/



From lecoutre at stat.ucl.ac.be  Tue Feb 24 14:51:15 2004
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Tue, 24 Feb 2004 14:51:15 +0100
Subject: [R] would be nice ...
In-Reply-To: <20040224124910.GA10007@sonny.eddelbuettel.com>
References: <D4389EED-66A6-11D8-8997-000A95A67E82@stat.ucla.edu>
	<16443.5204.413726.233082@gargle.gargle.HOWL>
	<20040224124910.GA10007@sonny.eddelbuettel.com>
Message-ID: <6.0.1.1.2.20040224142659.01e9cb58@stat4ux.stat.ucl.ac.be>


Hi,

What about using cat()?
Here is a piece of code that allows to bypass standard output to produce 
such a result.
Be carefull: it is dangerous: it replaces output by calling 'cat()', which 
is not allowed on all objects...

-----
EatOutput <- function(start=TRUE,stop=!start){
         if (start)
         {

                 ToCat <- function()
                 {
                         function(expr,value,ok,visible){
                         if (visible) {
                                 sink()
                                 cat(value,file="")
                                 cat("\n",file="")
                                 on.exit(sink("tmp"),add=TRUE)
                         }
                         invisible(return(TRUE))
                         }
                 }

                 on.exit(sink("tmp"),add=TRUE)   # To create the first sink
                 on.exit(.out<<-addTaskCallback(ToCat()),add=TRUE)
         }
         else
         {
                 test <- try(removeTaskCallback(.out))
                 if(!inherits(test,"try-error")) sink()

         }
}

-----

Now suppose this piece of code is put in file "eat.r", ending with a call 
to the function EatOutput()

Then:

 > echo "source('eat.r');sum(1:10)" | R --slave
55

If you explain more clearly your needs, maybe we we could propose something 
more accurate.

Eric


 > echo "cat(sum(c(1,2,3)));cat("\n");cat(3*2)" | R --slave
66

At 13:49 24/02/2004, Dirk Eddelbuettel wrote:
>On Tue, Feb 24, 2004 at 10:07:32AM +0100, Martin Maechler wrote:
> > >>>>> "Jan" == Jan de Leeuw <deleeuw at stat.ucla.edu>
> > >>>>>     on Tue, 24 Feb 2004 00:52:51 -0800 writes:
> >
> >     Jan> if R had something like
> >     >> python -c "print(sum([1,2,3]));print(3*2)"
> >     Jan> 6 6
> >
> >     Jan> but I guess the only way to do this is by writing the
> >     Jan> string to a tmp file and then doing something like "R
> >     Jan> CMD BATCH --quiet" on the tmp file
> >
> > Well, a bit better (with a shell prompt "%") is
> >
> >     % echo "print(sum(c(1,2,3)));print(3*2)" | R --quiet --vanilla
> >
> >     > print(sum(c(1,2,3)));print(3*2)
> >     [1] 6
> >     [1] 6
> >     >
> >
> > or (slightly nicer)
> >
> >     % echo "sum(c(1,2,3)); 3*2" | R --quiet --vanilla
> >     > sum(c(1,2,3)); 3*2
> >     [1] 6
> >     [1] 6
> >     >
> >
> > but it still echoes the input by default
>
>Not with --slave:
>
>edd at chibud:~> echo "sum(c(1,2,3)); 3*2" | R --slave
>[1] 6
>[1] 6
>
>I would be pretty trivial to filter the "^[1] " out.
>
>Dirk
>
>--
>The relationship between the computed price and reality is as yet unknown.
>                                              -- From the pac(8) manual page
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Eric Lecoutre
UCL /  Institut de Statistique
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
Belgium

tel: (+32)(0)10473050
lecoutre at stat.ucl.ac.be
http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

If the statistics are boring, then you've got the wrong numbers. -Edward 
Tufte



From m.mader at gsf.de  Tue Feb 24 14:56:29 2004
From: m.mader at gsf.de (Michael Mader)
Date: Tue, 24 Feb 2004 14:56:29 +0100
Subject: [R] <no subject> [list.files]
References: <200402241334.i1ODYZQ25352@mailgate5.cinetic.de>
Message-ID: <403B580D.6B65E2A9@gsf.de>

Hi,

have a look at list.files() and import them in a loop or similar.

Regards

Michael
Claudia Paladini wrote:
> 
> Content-Type: text/plain; charset="iso-8859-1"
> Content-Transfer-Encoding: 7bit
> X-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on hypatia.math.ethz.ch
> X-Spam-Status: No, hits=3.5 required=5.0 tests=BAYES_44,RCVD_IN_BL_SPAMCOP_NET autolearn=no version=2.63
> X-Spam-Level: ***
> 
> Dear ladies and gentlmen,
> I want to import a directory with about 400 files (.dat) in R. I know how to import a single file (with scan...) but I've good no idea how to import 400 at once. Can you help me ?
> Thanks a lot!
> Claudia
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Michael T. Mader
Institute for Bioinformatics/MIPS, GSF
Ingolstaedter Landstrasse 1
D-85764 Neuherberg
0049-89-3187-3576

response time (n.) An unbounded, random variable Tr associated with a
given TIMESHARING system and representing the putative time which
elapses between Ts, the time of sending a message, and Te, the time when
the resulting error diagnostic is received.	
	S. Kelly-Bootle, The Devil's DP Dictionary



From thpe at hhbio.wasser.tu-dresden.de  Tue Feb 24 15:03:48 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Tue, 24 Feb 2004 15:03:48 +0100
Subject: [R] r: plots
In-Reply-To: <403B473F.EAF9A4E7@stats.uct.ac.za>
References: <403B473F.EAF9A4E7@stats.uct.ac.za>
Message-ID: <403B59C4.60502@hhbio.wasser.tu-dresden.de>

allan clark wrote:

> hi all
> 
> i have another probably simple question.
> 
> I have three variables say x, y and z. x and y are quite large and z is
> relative small.
> how can one plot the three variables on the same graph with two separate
> axis?
> (one for x and y and the other for z)
> 
> e.g.

x<-c(101,110,150,167,120)
y<-c(120,135,175,95,200)
z<-c(0.001, 0.15, 0.6, 0.8, 1)


## Try something like:

fac <- 200

par(mar=c(5,4,4,5)+.1)

plot(x, ylim=range(c(x, y, fac * z)), col="blue", ylab="x, y")
points(y, col="green")
points(z*fac, col="red")

axis(4, at=pretty(z*fac), label=pretty(z*fac)/fac, ylab="z")
mtext("z", side=4, line=2.5)

# more about this see ?axis, ?pretty and ?mtext

Thomas P.

-- 
Thomas Petzoldt
Dresden University of Technology
Institute of Hydrobiology          petzoldt at rcs.urz.tu-dresden.de
01062 Dresden                      http://www.tu-dresden.de/fghhihb/



From ligges at statistik.uni-dortmund.de  Tue Feb 24 15:08:22 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 24 Feb 2004 15:08:22 +0100
Subject: [R] <no subject>
In-Reply-To: <200402241334.i1ODYZQ25352@mailgate5.cinetic.de>
References: <200402241334.i1ODYZQ25352@mailgate5.cinetic.de>
Message-ID: <403B5AD6.2090608@statistik.uni-dortmund.de>

Claudia Paladini wrote:

> 
> Dear ladies and gentlmen,
> I want to import a directory with about 400 files (.dat) in R. I know how to import a single file (with scan...) but I've good no idea how to import 400 at once. Can you help me ?
> Thanks a lot!
> Claudia 

> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Inn order to get a list "dat" containing all the data:

  setwd("path")
  files <- dir(pattern="dat$")
  dat <- lapply(files, scan)

Uwe Ligges



From MSchwartz at medanalytics.com  Tue Feb 24 15:08:38 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 24 Feb 2004 08:08:38 -0600
Subject: [R] r: plots
In-Reply-To: <403B473F.EAF9A4E7@stats.uct.ac.za>
References: <403B473F.EAF9A4E7@stats.uct.ac.za>
Message-ID: <1077631717.16414.143.camel@localhost.localdomain>

On Tue, 2004-02-24 at 06:44, allan clark wrote:
> hi all
> 
> i have another probably simple question.
> 
> I have three variables say x, y and z. x and y are quite large and z is
> relative small.
> how can one plot the three variables on the same graph with two separate
> axis?
> (one for x and y and the other for z)
> 
> e.g.
> x<-c(101,110,150,167,120)
> y<-c(120,135,175,95,200)
> z<-c(0.001, 0.15, 0.6, 0.8, 1)
> 
> regards
> Allan


You could do something like this:

x<-c(101, 110, 150, 167, 120)
y<-c(120, 135, 175, 95, 200)
z<-c(0.001, 0.15, 0.6, 0.8, 1)

# Create a matrix with all three columns
# "Normalize" z against the range of the other two
m <- cbind(x, y, z * 100)

# Now use matplot() to create the plot, which also
# helps to ensure that the y axis covers the range
# of the three vectors
matplot(m, type = "p", pch = c("x", "y", "z"))

# Now annotate axis 4 (the right hand y axis)
# adjusting the labels back to the original z vector 
# scaling. Use axTicks() to get the default tick mark
# locations and divide the values by 100
axis(4, labels = axTicks(4) / 100)

See ?cbind, ?matplot and ?axis and ?axTicks for more information.

HTH,

Marc Schwartz



From Timur.Elzhov at jinr.ru  Tue Feb 24 15:11:08 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Tue, 24 Feb 2004 17:11:08 +0300
Subject: [R] <no subject>
In-Reply-To: <200402241334.i1ODYZQ25352@mailgate5.cinetic.de>
References: <200402241334.i1ODYZQ25352@mailgate5.cinetic.de>
Message-ID: <20040224141107.GA22417@nf034.jinr.ru>

On Tue, Feb 24, 2004 at 02:34:35PM +0100, Claudia Paladini wrote:
> Dear ladies and gentlmen,
> I want to import a directory with about 400 files (.dat) in R. I know
> how to import a single file (with scan...) but I've good no idea how
> to import 400 at once. Can you help me ?

You can get list of the files you need:
  flist <- system("ls", intern = TRUE)

Then run on that list:
  for (fname in flist) {
      get(fname, scan(file = fname, ...))
      ...
  }

--
WBR,
Timur



From dmurdoch at pair.com  Tue Feb 24 15:09:37 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 24 Feb 2004 09:09:37 -0500
Subject: [R] r: plots
In-Reply-To: <403B473F.EAF9A4E7@stats.uct.ac.za>
References: <403B473F.EAF9A4E7@stats.uct.ac.za>
Message-ID: <o7mm30tlsldhm1cobbrfba7llc6cbd63h6@4ax.com>

On Tue, 24 Feb 2004 14:44:47 +0200, allan clark
<allan at stats.uct.ac.za> wrote :

>hi all
>
>i have another probably simple question.
>
>I have three variables say x, y and z. x and y are quite large and z is
>relative small.
>how can one plot the three variables on the same graph with two separate
>axis?
>(one for x and y and the other for z)
>
>e.g.
>x<-c(101,110,150,167,120)
>y<-c(120,135,175,95,200)
>z<-c(0.001, 0.15, 0.6, 0.8, 1)

You need to do most of the work yourself:

par(mar=par('mar')+c(0,0,0,2))  # make room for the extra axis 
plot(1:5, x, ylim = c(0, 200)) # plot x with room for the others
points(1:5, y, pch=2) # plot y
points(1:5, 200*z, pch=3) # plot z, magnified 200 times
zticks <- pretty(z) # choose ticks for z
axis(4, at=200*zticks, labels=zticks) # plot them
mtext('z',side=4, line=3) # add the z label

You'll also want to add a legend, but I'll let you figure that out.

Duncan Murdoch



From Timur.Elzhov at jinr.ru  Tue Feb 24 15:14:17 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Tue, 24 Feb 2004 17:14:17 +0300
Subject: [R] <no subject>
In-Reply-To: <20040224141107.GA22417@nf034.jinr.ru>
References: <200402241334.i1ODYZQ25352@mailgate5.cinetic.de>
	<20040224141107.GA22417@nf034.jinr.ru>
Message-ID: <20040224141417.GA22487@nf034.jinr.ru>

On Tue, Feb 24, 2004 at 05:11:07PM +0300, Timur Elzhov wrote:

>>  Dear ladies and gentlmen,
>>  I want to import a directory with about 400 files (.dat) in R. I know
>>  how to import a single file (with scan...) but I've good no idea how
>>  to import 400 at once. Can you help me ?
> You can get list of the files you need:
>   flist <- system("ls", intern = TRUE)
  flist <- system("ls *.dat", intern = TRUE)
in your case, you see :)

--
WBR,
Timur



From thpe at hhbio.wasser.tu-dresden.de  Tue Feb 24 15:11:55 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Tue, 24 Feb 2004 15:11:55 +0100
Subject: [R] Re: (read many files)
In-Reply-To: <200402241334.i1ODYZQ25352@mailgate5.cinetic.de>
References: <200402241334.i1ODYZQ25352@mailgate5.cinetic.de>
Message-ID: <403B5BAB.1030704@hhbio.wasser.tu-dresden.de>

Claudia Paladini wrote:
> 
> Dear ladies and gentlmen, I want to import a directory with about 400
> files (.dat) in R. I know how to import a single file (with scan...)
> but I've good no idea how to import 400 at once. Can you help me ? 
> Thanks a lot! Claudia 

setwd("c:/myfiles/")
## list.files uses regular expressions.
## For reading all files which start with "S" use for example:

files <-  list.files(pattern="^S.*")

## then read the data within a loop, e.g.:
dat2 <- NULL
for (f in files) {
   dat  <- read.table(f)
   dat2 <- rbind(dat2, dat)
}



Thomas P.



From robert.kissell at citigroup.com  Tue Feb 24 15:21:49 2004
From: robert.kissell at citigroup.com (Kissell, Robert [EQRE])
Date: Tue, 24 Feb 2004 09:21:49 -0500
Subject: [R] Nonlinear Optimization
Message-ID: <4115749EFC8862458D6FE4F04F5F7DE701E82EBC@EXCHNY37.ny.ssmb.com>

Hi,

I have been brought back to the "R-Side" from MatLab. I have used R in
graduate econometrics but only for statistics and regression (linear and
nonlinear). But now I need to run general nonlinear optimization. 

I know about the add-in quadprog but my problem is not QP. My problem is a
general nonlinear (obj funct) with linear constraints.I know about the "ms"
and "nls" functions, but these seem only for nonlinear regression, not
nonlinear minimization. I am looking for a pure non-linear optimization
module.

The nonlinear optimization functions I used in MatLab are "fmincon" and
"fminunc"

Is there any nonlinear optimization algorithm for R?


Thanks.


Rob



From ivo.welch at yale.edu  Tue Feb 24 15:30:21 2004
From: ivo.welch at yale.edu (ivo welch)
Date: Tue, 24 Feb 2004 09:30:21 -0500
Subject: [R] Suggestions ?!?!
In-Reply-To: <402BAC57.6060600@yale.edu>
References: <200402121155.i1CBshwg005875@hypatia.math.ethz.ch>
	<402BAC57.6060600@yale.edu>
Message-ID: <403B5FFD.3040406@yale.edu>


hi chaps:

* I have some suggestion, the first of which is about suggestions, R 
tells me who the contributors() are, but this should also tell me where 
I should email suggestions to.  Is it this mailing address/list?  a 
repository of suggestions?  an individual?

this came up because i wanted to suggest enhancements:


* the first is for the summary() method for plain data frames.  it would 
seem to me that the number of "NA" observations should be printed as an 
integer, not necessarily in scientific notation.  I have also yet to 
determine when summary() likes to give means and when it does not. 
(maybe it was an older version that sometimes did not give means). 
summary does not seem to have optional parameters to specify what 
statistics I would like. this could be useful, too.


* another small enhancement:  there are four elementary data frame 
operations that bedevil novices, so they really should have named 
function wrappers:

     delrow( dataframe d, index=45);
     insrow( dataframe d, (row)vector v);
     delcol( dataframe d, "name");
     inscol( dataframe d, (col)vector v);

Even a simple alias would do (maybe named row.delete, column.delete).  I 
looked at my R "bible" (venables&ripley), too, but here too it is not as 
clear as it needs to be.  yes, these operations are programmable, but it 
ain't as obvious as it should be for beginners.  these are elementary.


* Finally, a more complex question: I have a historical rate of stock 
return series (yes, I teach finance).  I would like to make a ts plot on 
the left (plot(date,returns,type="h")), and a plot(density(returns)) on 
the right.  works nicely with par(mfrow=c(1,2)), but it would be even 
nicer if I could rotate the density plot 90 degrees, so that it is more 
apparent that the density plot is an aggregation of the points at the 
same y coordinates.  (if need be, a histogram could replace the density 
plot.)  Is it possible to rotate an entire subpanel figure.  if there 
was a "horizontal" parameter to ps.options for plot(), it would do the 
trick, but this does not work.   So, this may be a suggestion, too.

regards,

/iaw



From bates at stat.wisc.edu  Tue Feb 24 15:42:32 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 24 Feb 2004 08:42:32 -0600
Subject: [R] orthonormalization with weights
In-Reply-To: <20040224030037.A0420395E@mprdmxin.myway.com>
References: <20040224030037.A0420395E@mprdmxin.myway.com>
Message-ID: <6rptc4bktj.fsf@bates4.stat.wisc.edu>

"Gabor Grothendieck" <ggrothendieck at myway.com> writes:

> Obviously the R code does not match the 
> description I gave since we should be taking
> the QR decomp of sqrt(D)X, not X.  Z should be:
> 
>  diag(1/sqrt(diag(D))) %*% qr.Q(qr(sqrt(D)%*%X))

Because R stores matrices in column-major order and repeats shorter
vectors in arithmetic operations, you can avoid the matrix
multiplications.

What you have written is equivalent to

sqrtD = sqrt(diag(D))
qr.Q(qr(sqrtD*X))/sqrtD

Also, you don't really need to store a diagonal matrix as a matrix.

> 
> ---
> Date:   Mon, 23 Feb 2004 21:38:15 -0500 (EST) 
> From:   Gabor Grothendieck <ggrothendieck at myway.com>
> To:   <stephane.dray at umontreal.ca>, <r-help at stat.math.ethz.ch> 
> Subject:   RE: [R] orthonormalization with weights 
> 
>  diag(1/sqrt(diag(D))) %*% qr.Q(qr(X))
> 
> 
> 
> Let QR be such that sqrt(D)X = QR. Then letting
> solve(...) denote the inverse of ... we have
> X = solve(sqrt(D))QR which is of the form ZR 
> and Z has the desired weighted orthoginality 
> property. 
> 
> Since D is diagonal, solve(sqrt(D)) equals 
> diag(1/sqrt(diag(D))) so we get this for Z:
> 
> diag(1/sqrt(diag(D))) %*% qr.Q(qr(X))
> 
> ---
> Date: Mon, 23 Feb 2004 18:46:34 -0500 
> From: Stephane DRAY <stephane.dray at umontreal.ca>
> To: <r-help at stat.math.ethz.ch> 
> Subject: [R] orthonormalization with weights 
> 
> 
> Hello List,
> I would like to orthonormalize vectors contained in a matrix X taking into 
> account row weights (matrix diagonal D). ie, I want to obtain Z=XA with 
> t(Z)%*%D%*%Z=diag(1)
> 
> I can do the Gram-Schmidt orthogonalization with subsequent weighted 
> regressions. I know that in the case of uniform weights, qr can do the 
> trick. I wonder if there is a way to do it in the case of non uniform 
> weights by qr or svd ?
> 
> Thanks in advances.
> St?phane DRAY
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From bates at stat.wisc.edu  Tue Feb 24 15:45:29 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 24 Feb 2004 08:45:29 -0600
Subject: [R] Filter out some levels?
In-Reply-To: <200402240930.37537.ozric@web.de>
References: <200402240930.37537.ozric@web.de>
Message-ID: <6rk72cbkom.fsf@bates4.stat.wisc.edu>

Christian Schulz <ozric at web.de> writes:

> how is it possible to cut some levels from one factor to  subsetting  a 
> data.frame on?
> 
> subdata <- subset(data, data$FACTOR="1" | 
> data$FACTOR="BETA" | data$FACTOR="XY")
> ???
> 
> Maybe a modifcation here is better, but how?
> mergex[mergex$PLZX %in% levels(mergex$PLZX) ,]

Use %in%

subdata <- subset(data, FACTOR %in% c("1", "BETA", "XY"))



From jeaneid at chass.utoronto.ca  Tue Feb 24 15:56:09 2004
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Tue, 24 Feb 2004 09:56:09 -0500
Subject: [R] <no subject>
In-Reply-To: <200402241334.i1ODYZQ25352@mailgate5.cinetic.de>
Message-ID: <Pine.SGI.4.40.0402240946090.18853472-100000@origin.chass.utoronto.ca>

I don't know what these files are. so depending on whether you want to
call them with 400 different names or just have one data set for the 400
files. but in either case you can do a for loops on the directory. i.e.
put the 400 files in a seperate directory and setwd("to that directory")
do this

for (i %in% dir()){
assign(gsub(".dat", "", i), scan(....))}

this will create the 400 files with names without the .dat at the end.
note if you want to merge theem or rbind them, just replace the the
command assign above by rbind or merge.



On Tue, 24 Feb 2004, Claudia Paladini wrote:


> Dear ladies and gentlmen,
> I want to import a directory with about 400 files (.dat) in R. I know how to import a single file (with scan...) but I've good no idea how to import 400 at once. Can you help me ?
> Thanks a lot!
> Claudia
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dsheuman at rogers.com  Tue Feb 24 15:58:45 2004
From: dsheuman at rogers.com (dsheuman@rogers.com)
Date: Tue, 24 Feb 2004 9:58:45 -0500
Subject: [R] Calculate Distance and Aggregate Data?
Message-ID: <20040224145845.VRVT96949.web01-imail.rogers.com@localhost>

Hi all,

I've been struggling learning R and need to turn to the list again.

I've got a dataset (comma-delimited file) with the following fields:  recid, latitude, longitude, population, dwelling and age.  For each observation, I'd like to calculate the total number of people and dwellings and average age within 2 k.m.  Distance could be Euclidean, however, a proper distance calculation (great circle route) is best.

Any assistance would be appreciated.

Thanks,

Danny


--------------
Sample Data
--------------
recid,lat,long,pop,dwell,age
10010265,47.5971174,-52.7039227,584,219,38
10010260,47.5846616,-52.7039147,488,188,34
10010263,47.5936538,-52.7037037,605,232,43
10010287,47.5739426,-52.7035365,548,256,29
10010290,47.5703333,-52.703182,559,336,36
10010284,47.5800199,-52.7013245,394,261,61
10010191,47.5322617,-52.7010442,892,323,23
10010291,47.57004,-52.7009,0,0,0
10010289,47.57141,-52.70023,0,0,0
10010285,47.5832183,-52.6995828,469,239,44
10010273,47.6006838,-52.6984875,855,283,28
10010190,47.472353,-52.697991,0,0,0
10010274,47.6018197,-52.6978362,344,117,51
10010288,47.5755249,-52.6978207,33,0,19
10010275,47.6005037,-52.6968299,232,93,43
10010279,47.5915368,-52.6954916,983,437,33
10010276,47.5993086,-52.6954808,329,131,28
10010278,47.5958782,-52.6934253,251,107,27
10010354,47.6165839,-52.6934037,27,14,47
10010277,47.5975113,-52.6914148,515,194,37
10010293,47.5778754,-52.6910827,58,0,40
10010292,47.5722183,-52.6899332,1112,523,28
10010353,47.6356972,-52.6896838,1387,471,32
10010283,47.5873992,-52.6884621,531,296,41
10010281,47.5983891,-52.6880528,307,113,52
10010280,47.5958439,-52.6878177,374,129,18
10010282,47.5999645,-52.6874407,637,226,22
10010286,47.5797909,-52.6872042,446,280,32
10010355,47.6210282,-52.6777189,197,72,39



From HankeA at mar.dfo-mpo.gc.ca  Tue Feb 24 16:04:28 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Tue, 24 Feb 2004 11:04:28 -0400
Subject: [R] r: plots
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE124949@msgmarsta01.bio.dfo.ca>

How about:
x<-c(101,110,150,167,120)
y<-c(120,135,175,95,200)
z<-c(0.001, 0.15, 0.6, 0.8, 1)
plot(x,y,axes=T,xlab="",ylab="",pch="+")
par(new=T)
plot(x,z,axes=F,ylim=c(0,1))
axis(4, at=seq(0,1,.1), labels=seq(0,1,.1)) 
box()

> -----Original Message-----
> From:	Duncan Murdoch [SMTP:dmurdoch at pair.com]
> Sent:	Tuesday, February 24, 2004 6:10 AM
> To:	allan clark
> Cc:	Rhelp
> Subject:	Re: [R] r: plots
> 
> On Tue, 24 Feb 2004 14:44:47 +0200, allan clark
> <allan at stats.uct.ac.za> wrote :
> 
> >hi all
> >
> >i have another probably simple question.
> >
> >I have three variables say x, y and z. x and y are quite large and z is
> >relative small.
> >how can one plot the three variables on the same graph with two separate
> >axis?
> >(one for x and y and the other for z)
> >
> >e.g.
> >x<-c(101,110,150,167,120)
> >y<-c(120,135,175,95,200)
> >z<-c(0.001, 0.15, 0.6, 0.8, 1)
> 
> You need to do most of the work yourself:
> 
> par(mar=par('mar')+c(0,0,0,2))  # make room for the extra axis 
> plot(1:5, x, ylim = c(0, 200)) # plot x with room for the others
> points(1:5, y, pch=2) # plot y
> points(1:5, 200*z, pch=3) # plot z, magnified 200 times
> zticks <- pretty(z) # choose ticks for z
> axis(4, at=200*zticks, labels=zticks) # plot them
> mtext('z',side=4, line=3) # add the z label
> 
> You'll also want to add a legend, but I'll let you figure that out.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From dmurdoch at pair.com  Tue Feb 24 16:23:24 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 24 Feb 2004 10:23:24 -0500
Subject: [R] <no subject>
In-Reply-To: <20040224141417.GA22487@nf034.jinr.ru>
References: <200402241334.i1ODYZQ25352@mailgate5.cinetic.de>
	<20040224141107.GA22417@nf034.jinr.ru>
	<20040224141417.GA22487@nf034.jinr.ru>
Message-ID: <53rm30prqcp0tu8t5959lc4noo0u7cvpk8@4ax.com>

On Tue, 24 Feb 2004 17:14:17 +0300, Timur Elzhov
<Timur.Elzhov at jinr.ru> wrote :

>  flist <- system("ls *.dat", intern = TRUE)

That's not portable (Windows doesn't necessarily have ls).
list.files() is the portable function to do this.

If you want to be Windows-only non-portable, then choose.files() is a
bit more friendly than list.files().

Duncan Murdoch



From tlumley at u.washington.edu  Tue Feb 24 16:28:30 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 24 Feb 2004 07:28:30 -0800 (PST)
Subject: [R] would be nice ... 
In-Reply-To: <16443.5204.413726.233082@gargle.gargle.HOWL>
References: <D4389EED-66A6-11D8-8997-000A95A67E82@stat.ucla.edu>
	<16443.5204.413726.233082@gargle.gargle.HOWL>
Message-ID: <Pine.A41.4.58.0402240727350.64298@homer07.u.washington.edu>

On Tue, 24 Feb 2004, Martin Maechler wrote:

>
> or (slightly nicer)
>
>     % echo "sum(c(1,2,3)); 3*2" | R --quiet --vanilla
>     > sum(c(1,2,3)); 3*2
>     [1] 6
>     [1] 6
>     >
>
> but it still echoes the input by default
>

You can use --slave to suppress the input

[al:~] thomas% echo "print(sum(1:3))" | R --slave
[1] 6



	-thomas



From ldf at math.pku.edu.cn  Tue Feb 24 16:32:00 2004
From: ldf at math.pku.edu.cn (li dongfeng)
Date: Tue, 24 Feb 2004 23:32:0 +0800
Subject: [R] be careful: using attach in R functions
Message-ID: <HTLGB800.51G@mail.math.pku.edu.cn>

Hi there,

  I have just found that the ``attach'' function
can get you into trouble when called many times.
For example, you have a simulation routine called ``f()'',
in which you used ``attach'' and no corresponding ``detach''.
Then you call this function many times. You will find that
the system performance get slower and slower,
because you are making the R search path longer and longer.
So be careful when you use attach in a function!

  Below is a demonstration of this performance loss,
you will see a linear growth in CPU time usage.
Adding a ``detach()'' call at the end of ``f''
will get rid of this problem.

###############################
f <- function(){
  theta <- list(one=2.0, two=0.3, three=0.4)
  attach(theta)
  x  <- c(one, two, three)
  sample(x, 1)
}

test <- function(n=400){
  timeu <- numeric(n)
  for(i in seq(n)){
    timeu[i] <-
      system.time({
        resi <- f()
      })[3]
  }
  plot(timeu)
}
test()
##############################


Li Dongfeng
ldf-nospacm at math.pku.edu.cn
2004-02-24



From cs369 at cam.ac.uk  Tue Feb 24 16:30:17 2004
From: cs369 at cam.ac.uk (C. Spanou)
Date: 24 Feb 2004 15:30:17 +0000
Subject: [R] convergence in polr
Message-ID: <E1AveVl-0007bj-S2.--f0ba82e08b449983e2dcc7e478c2eea13f9f6a36@maroon.csi.cam.ac.uk>

Hello splus-users, I am trying to fit a regression model for an ordered 
response factor. So I am using the function polr in library(MASS). My data 
is a matrix of 1665 rows and 63 columns (one of the column is the dependent 
variable). The code I use is polr(as.ordered(q23p)~.,data=newdatap)
 but I am getting the following warning message singularity encountered in: 
nlminb.1(temp, p, liv, lv, objective, gradient, bounds, scale)

I looked in the MASS help for nlminb and I found that for the function
nlminb(start, objective, gradient=NULL, hessian=NULL,  
       scale=1, control=NULL, lower=-Inf, upper=Inf) 
 

when returning a warning message of singularity means that the optimization 
algorithm thinks it can't make any further progress because it has too many 
degrees of freedom. It usually means that the objective function is either 
not differentiable, or it may not have an optimum.

So for my data an optimum can't be obtained.
Is this true?

Can I ignore this warning message since what I want to find is values for 
the boundaries? Will the values for the boundaries be accurate even though 
I get the warning message?



From macq at llnl.gov  Tue Feb 24 16:32:23 2004
From: macq at llnl.gov (Don MacQueen)
Date: Tue, 24 Feb 2004 07:32:23 -0800
Subject: [R] New Perl module Statistics::R
In-Reply-To: <004201c3f90e$febccbb0$098cb0c8@main>
References: <4035A7C0.2020303@math2.org>
	<20040221164421.GE7385@chrome.sixears.co.uk>
	<004201c3f90e$febccbb0$098cb0c8@main>
Message-ID: <p06002000bc611e63fe51@[128.115.153.6]>

In a small amount of testing on Solaris, SunOS  5.8, it is working. 
Installed via cpan.

-Don

At 3:42 AM -0300 2/22/04, Graciliano M. P. wrote:
>I have released the new module Statistics::R and need some feedback of it's
>status.
>This will permit the control of the the R (R-project) interpreter through
>Perl in different architectures and OS.
>
>You can for example, start only one instance of the R interpreter and have
>different Perl process accessing it. What will save the initiation time of R
>and memory.
>
>Soo, I will appreciate if some one can test it in different OS. Tested with
>Win32 and Linux.
>
>http://search.cpan.org/~gmpassos/Statistics-R-0.01/
>
>Thanks in advance.
>
>Regards,
>Graciliano M. P.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From henric.nilsson at statisticon.se  Tue Feb 24 16:51:31 2004
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Tue, 24 Feb 2004 16:51:31 +0100
Subject: [R] Blue book
Message-ID: <6.0.3.0.0.20040224162846.03b61358@10.0.10.66>

Hi everyone,

Has the Blue book been revised? When googling for something completely 
different I happened to stumble upon http://isbn.nu/0412741504, claiming 
that a revised edition was published by CRC Press in 1998. Is this true? If 
so, in what way was it revised?

//Henric



From ggrothendieck at myway.com  Tue Feb 24 17:01:49 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 24 Feb 2004 11:01:49 -0500 (EST)
Subject: [R] Suggestions ?!?!
Message-ID: <20040224160149.E5A0A39B3@mprdmxin.myway.com>


For the question at the end, try barplot with the 
horiz=TRUE argument.

Date:   Tue, 24 Feb 2004 09:30:21 -0500 
From:   ivo welch <ivo.welch at yale.edu>
To:   <r-help at stat.math.ethz.ch> 
Cc:   <r-help-owner at stat.math.ethz.ch>,ivo welch <ivo.welch at yale.edu> 
Subject:   [R] Suggestions ?!?! 

 

hi chaps:

* I have some suggestion, the first of which is about suggestions, R 
tells me who the contributors() are, but this should also tell me where 
I should email suggestions to. Is it this mailing address/list? a 
repository of suggestions? an individual?

this came up because i wanted to suggest enhancements:


* the first is for the summary() method for plain data frames. it would 
seem to me that the number of "NA" observations should be printed as an 
integer, not necessarily in scientific notation. I have also yet to 
determine when summary() likes to give means and when it does not. 
(maybe it was an older version that sometimes did not give means). 
summary does not seem to have optional parameters to specify what 
statistics I would like. this could be useful, too.


* another small enhancement: there are four elementary data frame 
operations that bedevil novices, so they really should have named 
function wrappers:

delrow( dataframe d, index=45);
insrow( dataframe d, (row)vector v);
delcol( dataframe d, "name");
inscol( dataframe d, (col)vector v);

Even a simple alias would do (maybe named row.delete, column.delete). I 
looked at my R "bible" (venables&ripley), too, but here too it is not as 
clear as it needs to be. yes, these operations are programmable, but it 
ain't as obvious as it should be for beginners. these are elementary.


* Finally, a more complex question: I have a historical rate of stock 
return series (yes, I teach finance). I would like to make a ts plot on 
the left (plot(date,returns,type="h")), and a plot(density(returns)) on 
the right. works nicely with par(mfrow=c(1,2)), but it would be even 
nicer if I could rotate the density plot 90 degrees, so that it is more 
apparent that the density plot is an aggregation of the points at the 
same y coordinates. (if need be, a histogram could replace the density 
plot.) Is it possible to rotate an entire subpanel figure. if there 
was a "horizontal" parameter to ps.options for plot(), it would do the 
trick, but this does not work. So, this may be a suggestion, too.

regards,

/iaw



From P.Lemmens at nici.kun.nl  Tue Feb 24 17:13:43 2004
From: P.Lemmens at nici.kun.nl (Paul Lemmens)
Date: Tue, 24 Feb 2004 17:13:43 +0100
Subject: [R] Accessing columns in data.frame using formula
Message-ID: <32007046.1077642823@lemmens.socsci.kun.nl>

Hello!

I'm trying the hard way to use a formula, in a function, to specify the 
names of several important columns in a data.frame. Maybe I'm just battling 
to figure out the right search terms :-( This is on XP, R 1.8.1.

So, for instance,

wery[1:5,]

   V1 V2   V3  V4    V5 congr V7 V8 V9 ok  RT
1   1  1  960 520  1483     c  1  r  r  1 760
2   1  2 1060 450  3753     c  1  r  r  1 555
3   1  3  980 470  5758     c  2  l  l  1 432
4   1  4 1060 440  7693     c  1  r  r  1 424
5   1  5 1020 440  9578     i  1  l  l  1 369

I already figured out how to get to the parts of the formula,

tst <- function(f=RT~congr+ok, data=wery) {
thingy <- all.vars(f)
resp <- thingy[1]
facts <- thingy[-1]

# and how to get data from the data.frame.
eval(parse(text=resp), env=data)

# But now, I would like to do here what I'd do on the console as
# wery$ok <- factor(wery$ok), so here data$facts[2] <- factor(data$facts[2])
# This won't work here. How do I continu?

# Or perhaps also
# data.tmp <- data$resp[data$facts[1] == 'i']
}


thank you,
Paul Lemmens

P.S:
str(wery)
`data.frame':   150 obs. of  11 variables:
 $ V1   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ V2   : int  1 2 3 4 5 6 7 8 9 10 ...
 $ V3   : int  960 1060 980 1060 1020 1010 1060 1010 1090 1090 ...
 $ V4   : int  520 450 470 440 440 530 580 530 560 540 ...
 $ V5   : int  1483 3753 5758 7693 9578 11488 13423 15368 17548 19678 ...
 $ congr: Factor w/ 2 levels "c","i": 1 1 1 1 2 2 2 1 1 2 ...
 $ V7   : int  1 1 2 1 1 1 1 2 2 2 ...
 $ V8   : Factor w/ 2 levels "l","r": 2 2 1 2 1 1 1 1 1 2 ...
 $ V9   : Factor w/ 2 levels "l","r": 2 2 1 2 1 2 1 1 1 2 ...
 $ ok   : int  1 1 1 1 1 0 1 1 1 1 ...
 $ RT   : int  760 555 432 424 369 291 403 526 500 458 ...




-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.05)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066



From edd at debian.org  Tue Feb 24 17:15:43 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 24 Feb 2004 10:15:43 -0600
Subject: [R] Nonlinear Optimization
In-Reply-To: <4115749EFC8862458D6FE4F04F5F7DE701E82EBC@EXCHNY37.ny.ssmb.com>
References: <4115749EFC8862458D6FE4F04F5F7DE701E82EBC@EXCHNY37.ny.ssmb.com>
Message-ID: <20040224161543.GA12843@sonny.eddelbuettel.com>

On Tue, Feb 24, 2004 at 09:21:49AM -0500, Kissell, Robert [EQRE] wrote:
> nonlinear). But now I need to run general nonlinear optimization. 
> 
> I know about the add-in quadprog but my problem is not QP. My problem is a
> general nonlinear (obj funct) with linear constraints.I know about the "ms"
> and "nls" functions, but these seem only for nonlinear regression, not
> nonlinear minimization. I am looking for a pure non-linear optimization
> module.
> 
> The nonlinear optimization functions I used in MatLab are "fmincon" and
> "fminunc"
> 
> Is there any nonlinear optimization algorithm for R?

You did try 
    help(optim)
didn't you?

Hth, Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From spencer.graves at pdf.com  Tue Feb 24 17:28:10 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 24 Feb 2004 08:28:10 -0800
Subject: [R] Nonlinear Optimization
In-Reply-To: <4115749EFC8862458D6FE4F04F5F7DE701E82EBC@EXCHNY37.ny.ssmb.com>
References: <4115749EFC8862458D6FE4F04F5F7DE701E82EBC@EXCHNY37.ny.ssmb.com>
Message-ID: <403B7B9A.2060809@pdf.com>

      "optim"? 

Kissell, Robert [EQRE] wrote:

>Hi,
>
>I have been brought back to the "R-Side" from MatLab. I have used R in
>graduate econometrics but only for statistics and regression (linear and
>nonlinear). But now I need to run general nonlinear optimization. 
>
>I know about the add-in quadprog but my problem is not QP. My problem is a
>general nonlinear (obj funct) with linear constraints.I know about the "ms"
>and "nls" functions, but these seem only for nonlinear regression, not
>nonlinear minimization. I am looking for a pure non-linear optimization
>module.
>
>The nonlinear optimization functions I used in MatLab are "fmincon" and
>"fminunc"
>
>Is there any nonlinear optimization algorithm for R?
>
>
>Thanks.
>
>
>Rob
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ligges at statistik.uni-dortmund.de  Tue Feb 24 17:39:59 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 24 Feb 2004 17:39:59 +0100
Subject: [R] Nonlinear Optimization
In-Reply-To: <4115749EFC8862458D6FE4F04F5F7DE701E82EBC@EXCHNY37.ny.ssmb.com>
References: <4115749EFC8862458D6FE4F04F5F7DE701E82EBC@EXCHNY37.ny.ssmb.com>
Message-ID: <403B7E5F.2010803@statistik.uni-dortmund.de>

Kissell, Robert [EQRE] wrote:

> Hi,
> 
> I have been brought back to the "R-Side" from MatLab. I have used R in
> graduate econometrics but only for statistics and regression (linear and
> nonlinear). But now I need to run general nonlinear optimization. 
> 
> I know about the add-in quadprog but my problem is not QP. My problem is a
> general nonlinear (obj funct) with linear constraints.I know about the "ms"
> and "nls" functions, but these seem only for nonlinear regression, not
> nonlinear minimization. I am looking for a pure non-linear optimization
> module.
> 
> The nonlinear optimization functions I used in MatLab are "fmincon" and
> "fminunc"
> 
> Is there any nonlinear optimization algorithm for R?
> 

See ?optim

Uwe Ligges


> Thanks.
> 
> 
> Rob
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From mrufino at cmima.csic.es  Tue Feb 24 17:36:39 2004
From: mrufino at cmima.csic.es (mrufino@cmima.csic.es)
Date: Tue, 24 Feb 2004 17:36:39 +0100
Subject: [R] problem of install.packages in windows (R 1.81)
Message-ID: <1077640599.403b7d97caee0@webmail.cmima.csic.es>

Dear R users,

I have a problem in the configuration of R:
I just changed university, and my conection to the net is via a password, which 
permits me to access the packages with no problem via the internet explorer 
(version 6).
I just updated R to R 1.81, and I cannot download nether upgrade packages (and 
many are not working with the update!!!).
I have been looking in the help and emails, and saw that many people had the 
similar problems. 
By what I understood, I have to set up the proxy, and do something about 
the 'path'... but although I read RFAQ and R for windows, I could not do it, 
because I dont know where do I go (I looked in the control panel, internet 
options, etc. nothing worked, than also I tried changing the name of the dll 
file (internet2.dll), as recommended and makes R crash, as soon as it is 
conected.

I think I am very lost in the 'proxy' and 'path'... probably because I am a 
Windows user. By the way I use Win xp and 98.

I am sorry for the basic question....

could you help e pleeeeease :-) ?
thank you
Marta



From sebastiendurand at videotron.ca  Tue Feb 24 17:45:06 2004
From: sebastiendurand at videotron.ca (Sebastien Durand)
Date: Tue, 24 Feb 2004 11:45:06 -0500
Subject: [R] Legends text
Message-ID: <a06020410bc612f903765@[192.168.2.3]>

Hi,

Is there a way to change the color of the text inside a legend, let 
say I would like to use a black background in my legend, how can I 
get the text to show up, it is black!!!
So for example how could I change it to white...?

Sebastien



From jonathan_wang at sbcglobal.net  Tue Feb 24 17:51:49 2004
From: jonathan_wang at sbcglobal.net (Jonathan Wang)
Date: Tue, 24 Feb 2004 08:51:49 -0800 (PST)
Subject: [R] matrix() Help
Message-ID: <20040224165149.425.qmail@web80603.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040224/0e7bc954/attachment.pl

From bates at stat.wisc.edu  Tue Feb 24 17:58:43 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 24 Feb 2004 10:58:43 -0600
Subject: [R] Suggestions ?!?!
In-Reply-To: <403B5FFD.3040406@yale.edu>
References: <200402121155.i1CBshwg005875@hypatia.math.ethz.ch>
	<402BAC57.6060600@yale.edu> <403B5FFD.3040406@yale.edu>
Message-ID: <6rr7wk9zy4.fsf@bates4.stat.wisc.edu>

ivo welch <ivo.welch at yale.edu> writes:

> * the first is for the summary() method for plain data frames.  it
> would seem to me that the number of "NA" observations should be
> printed as an integer, not necessarily in scientific notation.  I have
> also yet to determine when summary() likes to give means and when it
> does not. (maybe it was an older version that sometimes did not give
> means). summary does not seem to have optional parameters to specify
> what statistics I would like. this could be useful, too.

The form of the output from summary depends on the mode or class of
the column.  A numeric column is summarized by a 'five-number' summary
(min, first quartile, median, third quartile, maximum) and the mean.
If there are NA's in the column the number of NA's is reported.  The
reason that it is sometimes reported to several decimal places is
because all the values in that part of the summary are being printed
in the same format.  If the mean requires four decimal places to get
the desired number of significant digits then the number of NA's will
also be given to four decimal places.

A column that is a factor or an ordered factor will be summarized by a
(possibly truncated) frequency table.  Means, medians, etc. are not
meaningful for factors.

> * another small enhancement:  there are four elementary data frame
> operations that bedevil novices, so they really should have named
> function wrappers:
> 
> 
>      delrow( dataframe d, index=45);
>      insrow( dataframe d, (row)vector v);
>      delcol( dataframe d, "name");
>      inscol( dataframe d, (col)vector v);

Three of the "secrets of the S masters" are:
  - indexing is particularly flexible and powerful in S
  - the "%in%" function is versatile and often overlooked
  - you can add a column to a data frame by assigning to that name
so three of these operations can be written as

 d[ -45, ]                     # delrow( dataframe d, index=45)
 d[ , !(names(d) %in% "name")] # delcol( dataframe d, "name")
 d[ , -col]                    # alternative form is you know the column number
 d$newcol = v                  # inscol( dataframe d, (col)vector v)

> Even a simple alias would do (maybe named row.delete, column.delete).
> I looked at my R "bible" (venables&ripley), too, but here too it is
> not as clear as it needs to be.  yes, these operations are
> programmable, but it ain't as obvious as it should be for beginners.
> these are elementary.

P.S. How many other people think that the next edition of MASS should
be renamed "Secrets of The S Masters"?   :-)



From tlumley at u.washington.edu  Tue Feb 24 18:00:28 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 24 Feb 2004 09:00:28 -0800 (PST)
Subject: [R] Nonlinear Optimization
In-Reply-To: <4115749EFC8862458D6FE4F04F5F7DE701E82EBC@EXCHNY37.ny.ssmb.com>
References: <4115749EFC8862458D6FE4F04F5F7DE701E82EBC@EXCHNY37.ny.ssmb.com>
Message-ID: <Pine.A41.4.58.0402240858040.103282@homer05.u.washington.edu>

On Tue, 24 Feb 2004, Kissell, Robert [EQRE] wrote:

> Hi,
>
> I have been brought back to the "R-Side" from MatLab. I have used R in
> graduate econometrics but only for statistics and regression (linear and
> nonlinear). But now I need to run general nonlinear optimization.
>
> I know about the add-in quadprog but my problem is not QP. My problem is a
> general nonlinear (obj funct) with linear constraints.I know about the "ms"
> and "nls" functions, but these seem only for nonlinear regression, not
> nonlinear minimization. I am looking for a pure non-linear optimization
> module.
>
> The nonlinear optimization functions I used in MatLab are "fmincon" and
> "fminunc"
>
> Is there any nonlinear optimization algorithm for R?
>

There are three:

nlm(), using a Newton-type algorithm, unconstrained
optim(), with a palette of algorithms including the box-constrained
	L-BFGS-B
constrOptim(), using an adaptive log-barrier for linear constraints, with
	optim() used for the actual optimisation.

and probably more in add-on packages.

	-thomas



From andy_liaw at merck.com  Tue Feb 24 18:24:37 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 24 Feb 2004 12:24:37 -0500
Subject: [R] <no subject>
Message-ID: <3A822319EB35174CA3714066D590DCD504AF785A@usrymx25.merck.com>

> From: Jean Eid
> 
> I don't know what these files are. so depending on whether you want to
> call them with 400 different names or just have one data set 
> for the 400
> files. but in either case you can do a for loops on the 
> directory. i.e.
> put the 400 files in a seperate directory and setwd("to that 
> directory")
> do this
> 
> for (i %in% dir()){
> assign(gsub(".dat", "", i), scan(....))}

1. I guess you meant "in" rather than "%in%" inside the for()?

2. It is probably easier to store the results in a list in such situations;
e.g.,

fList <- list.files()
datList <- vector(mode="list", length=length(fList))
names(datList) <- fList
for (f in fList) datList[[f]] <- scan(f)

Cheers,
Andy

 
> this will create the 400 files with names without the .dat at the end.
> note if you want to merge theem or rbind them, just replace the the
> command assign above by rbind or merge.
> 
> 
> 
> On Tue, 24 Feb 2004, Claudia Paladini wrote:
> 
> >
> > Dear ladies and gentlmen,
> > I want to import a directory with about 400 files (.dat) in 
> R. I know how to import a single file (with scan...) but I've 
> good no idea how to import 400 at once. Can you help me ?
> > Thanks a lot!
> > Claudia
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From Roger.Bivand at nhh.no  Tue Feb 24 18:26:27 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 24 Feb 2004 18:26:27 +0100 (CET)
Subject: [R] Calculate Distance and Aggregate Data?
In-Reply-To: <20040224145845.VRVT96949.web01-imail.rogers.com@localhost>
Message-ID: <Pine.LNX.4.44.0402241802190.6722-100000@reclus.nhh.no>

On Tue, 24 Feb 2004 dsheuman at rogers.com wrote:

> Hi all,
> 
> I've been struggling learning R and need to turn to the list again.
> 
> I've got a dataset (comma-delimited file) with the following fields:  
> recid, latitude, longitude, population, dwelling and age.  For each
> observation, I'd like to calculate the total number of people and
> dwellings and average age within 2 k.m.  Distance could be Euclidean,
> however, a proper distance calculation (great circle route) is best.

One possibility using the spdep package is:

> names(sds)
[1] "recid" "lat"   "long"  "pop"   "dwell" "age"  
> library(spdep)
> sds.nb2 <- dnearneigh(as.matrix(sds[,2:3]), 0, 2, lonlat=TRUE)
> unlist(lapply(sds.nb2, function(x) ifelse(any(x==0), 0, 
+ sum(sds$pop[x]))))+sds$pop
 [1]  9123 10017  9123  8821  6279 10017   892  7061  8245 10654  9010 0
[13]  9010 10017  9010 10681 10122 10122  7627  9574 10654  8034  1611 10095
[25]  9771  9574  8856  9465  2555

using dnearneigh() with the lonlat argument to build up a list of 
neighbouring points. There are also functions for lonlat distances in the 
fields package.

Roger


> 
> Any assistance would be appreciated.
> 
> Thanks,
> 
> Danny
> 
> 
> --------------
> Sample Data
> --------------
> recid,lat,long,pop,dwell,age
> 10010265,47.5971174,-52.7039227,584,219,38
> 10010260,47.5846616,-52.7039147,488,188,34
> 10010263,47.5936538,-52.7037037,605,232,43
> 10010287,47.5739426,-52.7035365,548,256,29
> 10010290,47.5703333,-52.703182,559,336,36
> 10010284,47.5800199,-52.7013245,394,261,61
> 10010191,47.5322617,-52.7010442,892,323,23
> 10010291,47.57004,-52.7009,0,0,0
> 10010289,47.57141,-52.70023,0,0,0
> 10010285,47.5832183,-52.6995828,469,239,44
> 10010273,47.6006838,-52.6984875,855,283,28
> 10010190,47.472353,-52.697991,0,0,0
> 10010274,47.6018197,-52.6978362,344,117,51
> 10010288,47.5755249,-52.6978207,33,0,19
> 10010275,47.6005037,-52.6968299,232,93,43
> 10010279,47.5915368,-52.6954916,983,437,33
> 10010276,47.5993086,-52.6954808,329,131,28
> 10010278,47.5958782,-52.6934253,251,107,27
> 10010354,47.6165839,-52.6934037,27,14,47
> 10010277,47.5975113,-52.6914148,515,194,37
> 10010293,47.5778754,-52.6910827,58,0,40
> 10010292,47.5722183,-52.6899332,1112,523,28
> 10010353,47.6356972,-52.6896838,1387,471,32
> 10010283,47.5873992,-52.6884621,531,296,41
> 10010281,47.5983891,-52.6880528,307,113,52
> 10010280,47.5958439,-52.6878177,374,129,18
> 10010282,47.5999645,-52.6874407,637,226,22
> 10010286,47.5797909,-52.6872042,446,280,32
> 10010355,47.6210282,-52.6777189,197,72,39
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From ripley at stats.ox.ac.uk  Tue Feb 24 18:20:03 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 24 Feb 2004 17:20:03 +0000 (GMT)
Subject: [R] Nonlinear Optimization
In-Reply-To: <4115749EFC8862458D6FE4F04F5F7DE701E82EBC@EXCHNY37.ny.ssmb.com>
Message-ID: <Pine.LNX.4.44.0402241717390.1718-100000@gannet.stats>

I found

> help.search("optimization")

gave

constrOptim(base)       Linearly constrained optimisation
optim(base)             General-purpose Optimization
optimize(base)          One Dimensional Optimization

and there is also nlm which is not showing up there.

optim() provides several algorithms in a single wrapper.


On Tue, 24 Feb 2004, Kissell, Robert [EQRE] wrote:

> Hi,
> 
> I have been brought back to the "R-Side" from MatLab. I have used R in
> graduate econometrics but only for statistics and regression (linear and
> nonlinear). But now I need to run general nonlinear optimization. 
> 
> I know about the add-in quadprog but my problem is not QP. My problem is a
> general nonlinear (obj funct) with linear constraints.I know about the "ms"
> and "nls" functions, but these seem only for nonlinear regression, not
> nonlinear minimization. I am looking for a pure non-linear optimization
> module.
> 
> The nonlinear optimization functions I used in MatLab are "fmincon" and
> "fminunc"
> 
> Is there any nonlinear optimization algorithm for R?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at medanalytics.com  Tue Feb 24 18:32:08 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 24 Feb 2004 11:32:08 -0600
Subject: [R] Legends text
In-Reply-To: <a06020410bc612f903765@[192.168.2.3]>
References: <a06020410bc612f903765@[192.168.2.3]>
Message-ID: <1077643928.16414.188.camel@localhost.localdomain>

On Tue, 2004-02-24 at 10:45, Sebastien Durand wrote:
> Hi,
> 
> Is there a way to change the color of the text inside a legend, let 
> say I would like to use a black background in my legend, how can I 
> get the text to show up, it is black!!!
> So for example how could I change it to white...?
> 
> Sebastien


legend() does not support an argument to change the text color, so you
have to change the plot parameters prior to calling legend():

# Draw a quick plot
plot(1:5)

# Save the old text color value
col.old <- par("col")

# Set the text color to white
par("col" = "white")

# Draw the legend
legend(1, 5, legend = "Text Goes Here", bg = "black")

# Restore the original text color
par("col" = col.old)


HTH,

Marc Schwartz



From MSchwartz at medanalytics.com  Tue Feb 24 18:50:20 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 24 Feb 2004 11:50:20 -0600
Subject: [R] matrix() Help
In-Reply-To: <20040224165149.425.qmail@web80603.mail.yahoo.com>
References: <20040224165149.425.qmail@web80603.mail.yahoo.com>
Message-ID: <1077645020.16414.198.camel@localhost.localdomain>

On Tue, 2004-02-24 at 10:51, Jonathan Wang wrote:
> I have a question related to matrix().
> 
> The code below randomly generates 3 Poisson numbers into a 3 by 1
> matrix:
> 
> > matrix1 <- matrix(rpois(3,lambda=2),nrow=3,ncol=1)
> 
> And I use list() to see what they are:
> 
>      [,1]
> 
> [1,]  3
> 
> [2,]  1
> 
> [3,]  4
> 
> , which is what I had intended.
> 
> I then I want to randomly generate y Normal numbers into a 3 by 8
> matrix. y in this case would be 3, 1, and 4; so the resulting matrix
> should be such that the first row has three different Normal numbers;
> the second row has 1 Normal number; and the third row has four
> different Normal numbers. I have the following code to do that:
> 
> > matrix2 <- matrix(rnorm(poisNums),nrow=3,ncol=8)
> 
> To my surprise, matrix2 does not look anything like what I had
> intended. Instead, it repeats the values in the first column (of the
> matrix2) eight times. What part of the code do I need to fix?


See the help for rnorm(), which says:

n: number of observations. If 'length(n) > 1', the length is
          taken to be the number required.

Thus, by using rnorm(matrix1), you get 3 numbers back, which is the
length of matrix1. Since 3 is less than 24 (3 x 8), the vector from
rnorm is cycled to fill in the matrix.

Use lapply() and have the final result be a 'list', since the number of
values in each component will vary:

matrix1 <- matrix(rpois(3, lambda = 2), nrow = 3, ncol = 1)
> matrix1
     [,1]
[1,]    5
[2,]    3
[3,]    1

list2 <- lapply(matrix1, rnorm)

> list2
[[1]]
[1] -1.186458639  1.096777044 -0.005344028  0.707310667  1.034107735

[[2]]
[1]  0.2234804 -0.8787076  1.1629646

[[3]]
[1] -2.000165

See ?lapply

Watch out for situations where an element in matrix1 is a zero. You will
get a numeric(0) as a result in that list element.

HTH,

Marc Schwartz



From Torsten.Steuernagel at gmx.de  Tue Feb 24 18:59:05 2004
From: Torsten.Steuernagel at gmx.de (Torsten Steuernagel)
Date: Tue, 24 Feb 2004 18:59:05 +0100
Subject: [R] Inheriting from factors + co.
Message-ID: <403B9EF9.16486.2DC31517@localhost>

I'm trying to create a formal class that does the following:

1) accept objects of arbitrary class as .Data slot

2) provide a set of other slots that are of fixed type (as usual)

The following two approaches came to my mind:

A)

setClass("myclass", representation("ANY", x = "numeric", y 
="numeric"))

new("myclass", 1:10)		# works 
new("myclass", "Test")		# works
new("myclass", factor(1:10))	# fails

While I'm able to specify any object that has a formal class as data part 
it won't work with factors or other non-formal classes.

B)

Since it is sufficient to use anything that inherits from "vector" and 
"factor", I also tried the following one which seems to be cleaner than 
using "ANY" directly.

setClassUnion("myunion", representation("vector", "factor"))	# 
works
setClass("myclass", representation("myunion", x="numeric", 
y="numeric"))

new("myclass", 1:10)		# fails

Now it isn't possible to assign anything as data part at all, as long as 
the union contains any non-formal classes such as "factor". Replacing 
"factor" with a formal class will do, of course.

I wonder if there is some way that does the trick because other 
approaches aren't very straightforward. The obvious solution would be 
a list as .Data part which can store anything but that isn't easy to 
maintain. My goal is to have a formal class whose objects (i.e. .Data 
part) can either be anything derived from "vector" or a factor (ordered). 
I already played around with setIs() for implicit coercion but that doesn't 
do anything as long as one of the classes is an S3 class.

Thanks for your help,

Torsten



From ligges at statistik.uni-dortmund.de  Tue Feb 24 19:05:46 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 24 Feb 2004 19:05:46 +0100
Subject: [R] Legends text
In-Reply-To: <a06020410bc612f903765@[192.168.2.3]>
References: <a06020410bc612f903765@[192.168.2.3]>
Message-ID: <403B927A.3000909@statistik.uni-dortmund.de>

Sebastien Durand wrote:

> Hi,
> 
> Is there a way to change the color of the text inside a legend, let say 
> I would like to use a black background in my legend, how can I get the 
> text to show up, it is black!!!
> So for example how could I change it to white...?
> 
> Sebastien
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

By setting par(fg = "white"):

  plot(1:10)
  par(fg="white")
  legend(2,2, col="white", legend="A", bg="black")

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Tue Feb 24 19:09:43 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 24 Feb 2004 19:09:43 +0100
Subject: [R] matrix() Help
In-Reply-To: <20040224165149.425.qmail@web80603.mail.yahoo.com>
References: <20040224165149.425.qmail@web80603.mail.yahoo.com>
Message-ID: <403B9367.90502@statistik.uni-dortmund.de>

Jonathan Wang wrote:

> I have a question related to matrix().
> 
> The code below randomly generates 3 Poisson numbers into a 3 by 1 matrix:
> 
> 
>>matrix1 <- matrix(rpois(3,lambda=2),nrow=3,ncol=1)
> 
> 
> And I use list() to see what they are:
> 
>      [,1]
> 
> [1,]  3
> 
> [2,]  1
> 
> [3,]  4
> 
> , which is what I had intended.


For sure you used print(), but not list() ...



> I then I want to randomly generate y Normal numbers into a 3 by 8 matrix. y in this case would be 3, 1, and 4; so the resulting matrix should be such that the first row has three different Normal numbers; the second row has 1 Normal number; and the third row has four different Normal numbers. I have the following code to do that:
> 
> 
>>matrix2 <- matrix(rnorm(poisNums),nrow=3,ncol=8)
> 
> 
> To my surprise, matrix2 does not look anything like what I had intended. Instead, it repeats the values in the first column (of the matrix2) eight times. What part of the code do I need to fix?

You don't want to use a matrix here, but a list:

list2 <- apply(matrix1, 1, rnorm)

Please read "An Introduction to R" and learn a bit more on data 
structures in R ...

Uwe Ligges




> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dbeyer at u.washington.edu  Tue Feb 24 19:45:35 2004
From: dbeyer at u.washington.edu (Dick Beyer)
Date: Tue, 24 Feb 2004 10:45:35 -0800 (PST)
Subject: [R] lme - problems with model
In-Reply-To: <200402241107.i1OB5Egw027529@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.43.0402241045350.15751@hymn11.u.washington.edu>

As Spencer Graves suggested, I tried this with continuous variables.  Seems to work ok:

> lme(maill6 ~ water * temp  , random= ~1|rep, data = milk)
Linear mixed-effects model fit by REML
  Data: milk 
  Log-restricted-likelihood: -10.57237
  Fixed: maill6 ~ water * temp 
 (Intercept)        water         temp   water:temp 
-1.107227891  0.928965420  0.032507653 -0.008792517 

Random effects:
 Formula: ~1 | rep
        (Intercept)  Residual
StdDev:   0.1358565 0.2189339

Number of Observations: 27
Number of Groups: 3

For the smaller model, I get:

> lme(maill6 ~ water + temp  , random= ~1|rep, data = milk)
Linear mixed-effects model fit by REML
  Data: milk 
  Log-restricted-likelihood: -8.068963
  Fixed: maill6 ~ water + temp 
(Intercept)       water        temp 
 1.17083333 -0.05819444  0.01212500 

Random effects:
 Formula: ~1 | rep
        (Intercept)  Residual
StdDev:   0.1328748 0.2348303

Number of Observations: 27
Number of Groups: 3 

Cheers,
Dick
*******************************************************************************
Richard P. Beyer, Ph.D.	University of Washington
Tel.:(206) 616 7378	Env. & Occ. Health Sci. , Box 354695
Fax: (206) 685 4696	4225 Roosevelt Way NE, # 100
			Seattle, WA 98105-6099
http://depts.washington.edu/ceeh/ServiceCores/FC5/FC5.html
*******************************************************************************

Message: 14
Date: Mon, 23 Feb 2004 07:41:07 -0800
From: Spencer Graves <spencer.graves at pdf.com>
Subject: Re: [R] lme - problems with model
To: CG Pettersson <cg.pettersson at evp.slu.se>
Cc: Douglas Bates <bates at stat.wisc.edu>, r-help at stat.math.ethz.ch
Message-ID: <403A1F13.7000008 at pdf.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

      If you want to try to get the same answers as PROC MIXED, I 
suggest you try to figure out how SAS codes interactions and which ones 
it retains.  Then you can try code those manually and include them as 
separate explanatory variables, e.g., I((water=="2")&(temp==110)).  You 
could work this out in "lm" then try the result on "lme". 

      An alternative would be to convert "temp" from a factor to a 
continuous variable.  I would make plots of the response variables vs. 
"temp" with different lines and symbols for "water" and "rep" to make 
sure I had something that was mostly linear in some transformation of 
"temp". 

      hope this helps. 
      spencer graves

CG Pettersson wrote:

>Thanks a lot for the answer!
>
>Now, I only have the last one left - How do I get round it?
>I knew about the missing cells in the design, but didnt know how lme
>would react on them.
>
>In this case, I can remove the water:temp term, but how can I be sure
>that this is the right thing to do?
>
>Is the lm run without the random term enough for removing water:temp
>from the lme model, or do I have to do a PROC MIXED run with the
>random term to make that decision in a case like this? 
>
>Is it possible (for me)  to understand why MIXED accepts the design
>but not lme? They ought to get the same sort of problems, or have I
>missed something?
>
>/CG
>
>-------------------
>  
>
>>CG Pettersson <cg.pettersson at evp.slu.se> writes:
>>
>>    
>>
>>>Hello all!
>>>
>>>Im working with some training datasets in a SAS-based course,
>>>      
>>>
>trying
>  
>
>>>to do the same things in lme that I do in PROC MIXED. 
>>>
>>>Why dont lme do an analysis on this dataset when I use the model
>>>water*temp?
>>>The trouble comes from the water:temp term, as it works with
>>>water+temp.
>>>The data are, indeed, assymetric but lm accepts the water:temp
>>>      
>>>
>term
>  
>
>>>giving results in the F-test near what PROC MIXED produces. MIXED
>>>accepts the model.
>>>
>>>The water:temp term can be removed from the model according to the
>>>F-test in SAS (and to the lm model without any random term). Doing
>>>      
>>>
>so
>  
>
>>>in both MIXED and lme gives reasonably similar results for both
>>>systems.
>>>
>>>What do the error message mean, and how can I get around this?
>>>      
>>>
>>Because of missing cells in the design
>>
>>    
>>
>>>xtabs(~water + temp, milk)
>>>      
>>>
>>     temp
>>water 100 110 120 140
>>    1 3   3   3   0  
>>    2 3   0   3   3  
>>    3 3   3   0   3  
>>
>>the model matrix for the fixed effects is rank deficient.  In lm the
>>rank deficiency is detected and appropriate adjustments made
>>
>>    
>>
>>>coef(summary(lm(maill6 ~ water * temp, milk)))
>>>      
>>>
>>                  Estimate Std. Error    t value     Pr(>|t|)
>>(Intercept)     2.17666667  0.1142339 19.0544730 2.218661e-13
>>water2          0.28333333  0.1615511  1.7538308 9.647013e-02
>>water3          0.05333333  0.1615511  0.3301329 7.451108e-01
>>temp110         0.14000000  0.1615511  0.8665987 3.975669e-01
>>temp120         0.31333333  0.1615511  1.9395305 6.827304e-02
>>temp140         0.23333333  0.1615511  1.4443312 1.658280e-01
>>water3:temp110 -0.18666667  0.2284678 -0.8170371 4.245898e-01
>>water2:temp120  0.09666667  0.2284678  0.4231085 6.772282e-01
>>water2:temp140  0.21666667  0.2284678  0.9483467 3.555125e-01
>>
>>Notice that you would expect 6 degrees of freedom for the
>>    
>>
>interaction
>  
>
>>term but only three coefficients are estimated.
>>
>>In lme it is much more difficult to compensate for such rank
>>deficiencies because they could be systematic, like this, or they
>>could be due to relative precision parameters approaching zero
>>    
>>
>during
>  
>
>>the iterations.  Because of this we just report the error (although
>>admittedly we could be a bit more explicit about the nature of the
>>problem - we are reporting the symptom that we detect, not the
>>probable cause).
>>
>>
>>    
>>
>>>The dataset:
>>>      
>>>
>>>>milk
>>>>        
>>>>
>>>   water temp rep maill4 maill6 maill8 taste4 taste6 taste8
>>>1      1  100   1   2.90   2.13   2.39   10.1   10.0    9.6
>>>2      1  100   2   2.19   2.20   2.27   11.0    9.3   11.0
>>>3      1  100   3   2.13   2.20   2.41   10.1    7.0    9.6
>>>4      1  110   1   2.13   2.34   2.41   11.0   10.5    9.8
>>>5      1  110   2   2.32   2.27   2.25   11.0   11.3   11.2
>>>6      1  110   3   2.13   2.34   2.42    9.4   10.7    9.0
>>>7      1  120   1   2.00   2.49   2.71   11.1   11.2   11.4
>>>8      1  120   2   2.41   2.49   2.46   11.6   11.7    9.6
>>>9      1  120   3   2.22   2.49   2.73   10.7   10.3   10.2
>>>10     2  100   1   2.13   2.41   2.49   11.1   10.8   11.2
>>>11     2  100   2   2.49   2.34   2.53   11.1   11.2    9.2
>>>12     2  100   3   2.80   2.63   3.33    8.3    9.7    7.8
>>>13     2  120   1   2.38   2.85   2.06   11.9   11.2   11.2
>>>14     2  120   2   2.61   2.70   2.70   11.7   10.8   11.0
>>>15     2  120   3   2.77   3.06   3.25   10.9    9.0    9.4
>>>16     2  140   1   2.56   2.84   3.10   10.7   11.2    9.8
>>>17     2  140   2   2.63   2.61   2.81   10.8   11.0   11.6
>>>18     2  140   3   2.99   3.28   3.75    9.2    9.6    9.6
>>>19     3  100   1   2.60   2.24   2.32   10.8    8.4   10.8
>>>20     3  100   2   2.06   2.11   2.20   11.0   11.2   11.8
>>>21     3  100   3   1.98   2.34   2.80   10.3   10.2   10.6
>>>22     3  110   1   1.91   2.06   2.29   11.0   11.4    9.4
>>>23     3  110   2   1.98   1.98   2.15   10.0   11.8   10.6
>>>24     3  110   3   1.98   2.51   2.81    9.3    9.2   10.2
>>>25     3  140   1   2.27   2.42   2.72   10.8   11.6   12.0
>>>26     3  140   2   2.27   2.20   2.41   11.2   11.0   11.4
>>>27     3  140   3   2.20   2.77   3.06   10.5   10.2   10.0
>>>
>>>The failing model:
>>>      
>>>
>>>>lme(maill6 ~ water * temp  , random= ~1|rep, data = milk)
>>>>        
>>>>
>>>Error in MEEM(object, conLin, control$niterEM) : 
>>>        Singularity in backsolve at level 0, block 1
>>>
>>>The smaller (working) model:
>>>      
>>>
>>>>lme(maill6 ~ water + temp  , random= ~1|rep, data = milk)
>>>>        
>>>>
>>>Linear mixed-effects model fit by REML
>>>  Data: milk 
>>>  Log-restricted-likelihood: 4.922178
>>>  Fixed: maill6 ~ water + temp 
>>>(Intercept)      water2      water3     temp110     temp120    
>>>temp140 
>>> 2.19466667  0.32800000 -0.04533333  0.07800000  0.32133333 
>>>0.35066667 
>>>
>>>Random effects:
>>> Formula: ~1 | rep
>>>        (Intercept)  Residual
>>>StdDev:   0.1477760 0.1323057
>>>
>>>Number of Observations: 27
>>>Number of Groups: 3 
>>>      
>>>
>>>
>>>
>>>CG Pettersson, MSci, PhD Stud.
>>>Swedish University of Agricultural Sciences
>>>Dep. of Ecology and Crop Production. Box 7043
>>>SE-750 07 Uppsala
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>>      
>>>
>http://www.R-project.org/posting-guide.html
>  
>
>>-- 
>>Douglas Bates                            bates at stat.wisc.edu
>>Statistics Department                    608/262-2598
>>University of Wisconsin - Madison       
>>    
>>
>http://www.stat.wisc.edu/~bates/
>  
>
>CG Pettersson, MSci, PhD Stud.
>Swedish University of Agricultural Sciences
>Dep. of Ecology and Crop Production. Box 7043
>SE-750 07 Uppsala
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From MSchwartz at medanalytics.com  Tue Feb 24 19:48:27 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 24 Feb 2004 12:48:27 -0600
Subject: [R] be careful: using attach in R functions
In-Reply-To: <HTLGB800.51G@mail.math.pku.edu.cn>
References: <HTLGB800.51G@mail.math.pku.edu.cn>
Message-ID: <1077648507.16414.215.camel@localhost.localdomain>

On Tue, 2004-02-24 at 09:32, li dongfeng wrote:
> Hi there,
> 
>   I have just found that the ``attach'' function
> can get you into trouble when called many times.
> For example, you have a simulation routine called ``f()'',
> in which you used ``attach'' and no corresponding ``detach''.
> Then you call this function many times. You will find that
> the system performance get slower and slower,
> because you are making the R search path longer and longer.
> So be careful when you use attach in a function!
> 
>   Below is a demonstration of this performance loss,
> you will see a linear growth in CPU time usage.
> Adding a ``detach()'' call at the end of ``f''
> will get rid of this problem.
> 
> ###############################
> f <- function(){
>   theta <- list(one=2.0, two=0.3, three=0.4)
>   attach(theta)
>   x  <- c(one, two, three)
>   sample(x, 1)
> }
> 
> test <- function(n=400){
>   timeu <- numeric(n)
>   for(i in seq(n)){
>     timeu[i] <-
>       system.time({
>         resi <- f()
>       })[3]
>   }
>   plot(timeu)
> }
> test()
> ##############################


A better general and more efficient solution, without getting into the
details of the above functions, would be to use with() instead of
attach()/detach().

Change your function 'f' to:

f <- function(){
  theta <- list(one = 2.0, two = 0.3, three = 0.4)
  x  <- with(theta, c(one, two, three))
  sample(x, 1)
}

Now run test() using with() versus attach()/detach() and note the time
savings. Even with the detach() it is not "efficient".

For example using:

f <- function(){
  theta <- list(one = 2.0, two = 0.3, three = 0.4)
  attach(theta)
  x  <- c(one, two, three)
  sample(x, 1)
  detach(theta)
}

> system.time(test())
[1] 38.54  0.02 38.92  0.00  0.00

versus using:

f <- function(){
  theta <- list(one = 2.0, two = 0.3, three = 0.4)
  x  <- with(theta, c(one, two, three))
  sample(x, 1)
}

> system.time(test())
[1] 0.16 0.00 0.16 0.00 0.00
 

Those are on a 3.2 Ghz P4 Dell 5150 laptop with 2 GB of RAM for
comparison.

See ?with for more information. You will find relatively recent posts on
this in the list archives as a preferred approach.

HTH,

Marc Schwartz



From ripley at stats.ox.ac.uk  Tue Feb 24 19:50:18 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 24 Feb 2004 18:50:18 +0000 (GMT)
Subject: [R] convergence in polr
In-Reply-To: <E1AveVl-0007bj-S2.--f0ba82e08b449983e2dcc7e478c2eea13f9f6a36@maroon.csi.cam.ac.uk>
Message-ID: <Pine.LNX.4.44.0402241848560.1970-100000@gannet.stats>

Why have you sent a message about S-PLUS to R-help, one that has already 
been answered on S-news?

There is no function nlminb in R.

On 24 Feb 2004, C. Spanou wrote:

> Hello splus-users, I am trying to fit a regression model for an ordered 
> response factor. So I am using the function polr in library(MASS). My data 
> is a matrix of 1665 rows and 63 columns (one of the column is the dependent 
> variable). The code I use is polr(as.ordered(q23p)~.,data=newdatap)
>  but I am getting the following warning message singularity encountered in: 
> nlminb.1(temp, p, liv, lv, objective, gradient, bounds, scale)
> 
> I looked in the MASS help for nlminb and I found that for the function
> nlminb(start, objective, gradient=NULL, hessian=NULL,  
>        scale=1, control=NULL, lower=-Inf, upper=Inf) 
>  
> 
> when returning a warning message of singularity means that the optimization 
> algorithm thinks it can't make any further progress because it has too many 
> degrees of freedom. It usually means that the objective function is either 
> not differentiable, or it may not have an optimum.
> 
> So for my data an optimum can't be obtained.
> Is this true?
> 
> Can I ignore this warning message since what I want to find is values for 
> the boundaries? Will the values for the boundaries be accurate even though 
> I get the warning message?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From cs369 at cam.ac.uk  Tue Feb 24 20:03:27 2004
From: cs369 at cam.ac.uk (C. Spanou)
Date: 24 Feb 2004 19:03:27 +0000
Subject: [R] convergence in polr
Message-ID: <E1Avhq3-0007a3-Ca.--2657543e3823e044fbc384f69b336f03d1187295@maroon.csi.cam.ac.uk>

I am really sorry. I was supposed to send it to the Splus users but by 
mistake I sent to the R-users. Sorry once again



On Feb 24 2004, Prof Brian Ripley wrote:

> Why have you sent a message about S-PLUS to R-help, one that has already 
> been answered on S-news?
> 
> There is no function nlminb in R.
> 
> On 24 Feb 2004, C. Spanou wrote:
> 
> > Hello splus-users, I am trying to fit a regression model for an 
> > ordered response factor. So I am using the function polr in 
> > library(MASS). My data is a matrix of 1665 rows and 63 columns (one of 
> > the column is the dependent variable). The code I use is 
> > polr(as.ordered(q23p)~.,data=newdatap)
> >  but I am getting the following warning message singularity 
> > encountered in: nlminb.1(temp, p, liv, lv, objective, gradient, bounds, 
> > scale)
> > 
> > I looked in the MASS help for nlminb and I found that for the function
> > nlminb(start, objective, gradient=NULL, hessian=NULL,  
> >        scale=1, control=NULL, lower=-Inf, upper=Inf) 
> >  
> > 
> > when returning a warning message of singularity means that the 
> > optimization algorithm thinks it can't make any further progress 
> > because it has too many degrees of freedom. It usually means that the 
> > objective function is either not differentiable, or it may not have an 
> > optimum.
> > 
> > So for my data an optimum can't be obtained.
> > Is this true?
> > 
> > Can I ignore this warning message since what I want to find is values 
> > for the boundaries? Will the values for the boundaries be accurate even 
> > though I get the warning message?
> > 
> > ______________________________________________ 
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help PLEASE do read 
> > the posting guide! http://www.R-project.org/posting-guide.html
> > 
> > 
> 
>



From ggrothendieck at myway.com  Tue Feb 24 20:08:18 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 24 Feb 2004 14:08:18 -0500 (EST)
Subject: [R] be careful: using attach in R functions
Message-ID: <20040224190818.01A113A06@mprdmxin.myway.com>



An alternative to attach is with:

x <- with( theta, c(one,two,three) )

---
Date:   Tue, 24 Feb 2004 23:32:0 +0800 
From:   li dongfeng <ldf at math.pku.edu.cn>
To:   r-help at stat.math.ethz.ch <r-help at stat.math.ethz.ch> 
Subject:   [R] be careful: using attach in R functions 

 
Hi there,

I have just found that the ``attach'' function
can get you into trouble when called many times.
For example, you have a simulation routine called ``f()'',
in which you used ``attach'' and no corresponding ``detach''.
Then you call this function many times. You will find that
the system performance get slower and slower,
because you are making the R search path longer and longer.
So be careful when you use attach in a function!

Below is a demonstration of this performance loss,
you will see a linear growth in CPU time usage.
Adding a ``detach()'' call at the end of ``f''
will get rid of this problem.

###############################
f <- function(){
theta <- list(one=2.0, two=0.3, three=0.4)
attach(theta)
x <- c(one, two, three)
sample(x, 1)
}

test <- function(n=400){
timeu <- numeric(n)
for(i in seq(n)){
timeu[i] <-
system.time({
resi <- f()
})[3]
}
plot(timeu)
}
test()
##############################


Li Dongfeng
ldf-nospacm at math.pku.edu.cn
2004-02-24



From andy_liaw at merck.com  Tue Feb 24 20:13:40 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 24 Feb 2004 14:13:40 -0500
Subject: [R] be careful: using attach in R functions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF785D@usrymx25.merck.com>

You can write your code more defensively.  There are a few ways to do that:

1. Right after the attach(object), do on.exit(detach(object)).
2. If you know the function will be call repeatedly, it might be a good idea
to check whether the object has been attached.  This way you only need to
attach once.  I can think of a couple of way to do that. The simplest is
probably to check and see if the object name appear in the search list. 

Andy

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of li dongfeng
> Sent: Monday, February 23, 2004 1:00 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] be careful: using attach in R functions
> 
> 
> Hi there,
> 
>   I have just found that the ``attach'' function
> can get you into trouble when called many times.
> For example, you have a simulation routine called ``f()'',
> in which you used ``attach'' and no corresponding ``detach''.
> Then you call this function many times. You will find that
> the system performance get slower and slower,
> because you are making the R search path longer and longer.
> So be careful when you use attach in a function!
> 
>   Below is a demonstration of this performance loss,
> you will see a linear growth in CPU time usage.
> Adding a ``detach()'' call at the end of ``f''
> will get rid of this problem.
> 
> ###############################
> f <- function(){
>   theta <- list(one=2.0, two=0.3, three=0.4)
>   attach(theta)
>   x  <- c(one, two, three)
>   sample(x, 1)
> }
> 
> test <- function(n=400){
>   timeu <- numeric(n)
>   for(i in seq(n)){
>     timeu[i] <-
>       system.time({
>         resi <- f()
>       })[3]
>   }
>   plot(timeu)
> }
> test()
> ##############################
> 
> 
> ????????Li Dongfeng
> ????????ldf-nospacm at math.pku.edu.cn
> ??????????2004-02-24
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ggrothendieck at myway.com  Tue Feb 24 20:21:09 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 24 Feb 2004 14:21:09 -0500 (EST)
Subject: [R] Calculate Distance and Aggregate Data?
Message-ID: <20040224192109.BBF473979@mprdmxin.myway.com>




Assume that gcirc(x,y) takes two 2-vectors which are the latitude and
longitude of x and the latitude and longitude of y and produces the
the greatest circle distance in kilometers between them.

# read in the data as a matrix
d <- as.matrix( read.csv(myfile) )

# vectorize gcirc, i.e. allow it to have args which are matrices
# with one coordinate per row.  The first two lines of this
# function optionally allow either arg to have 1 row even when the
# other does not
gcirc.vec <- function(x,y) {
   if (nrow(x) == 1) x <- matrix(x, nrow(y), ncol(x), byrow=T)
   if (nrow(y) == 1) y <- matrix(y, nrow(x), ncol(y), byrow=T)
   mapply(function(ii,jj) gcirc(x[ii,],y[ii,]), 1:nrow(x), 1:nrow(y))
}

# and perform two applies:

f <- function(x, v) sum( d[ gcirc.vec(t(x[2:3]),d[,2:3]) < 2, v ] )

apply(d,1,f,"pop")
apply(d,1,f,"dwell")

---
Date:   Tue, 24 Feb 2004 9:58:45 -0500 
From:   <dsheuman at rogers.com>
To:   <R-help at stat.math.ethz.ch> 
Subject:   [R] Calculate Distance and Aggregate Data? 

 
Hi all,

I've been struggling learning R and need to turn to the list again.

I've got a dataset (comma-delimited file) with the following fields: recid, latitude, longitude, population, dwelling and age. For each observation, I'd like to calculate the total number of people and dwellings and average age within 2 k.m. Distance could be Euclidean, however, a proper distance calculation (great circle route) is best.

Any assistance would be appreciated.

Thanks,

Danny


--------------
Sample Data
--------------
recid,lat,long,pop,dwell,age
10010265,47.5971174,-52.7039227,584,219,38
10010260,47.5846616,-52.7039147,488,188,34
10010263,47.5936538,-52.7037037,605,232,43
10010287,47.5739426,-52.7035365,548,256,29
10010290,47.5703333,-52.703182,559,336,36
10010284,47.5800199,-52.7013245,394,261,61
10010191,47.5322617,-52.7010442,892,323,23
10010291,47.57004,-52.7009,0,0,0
10010289,47.57141,-52.70023,0,0,0
10010285,47.5832183,-52.6995828,469,239,44
10010273,47.6006838,-52.6984875,855,283,28
10010190,47.472353,-52.697991,0,0,0
10010274,47.6018197,-52.6978362,344,117,51
10010288,47.5755249,-52.6978207,33,0,19
10010275,47.6005037,-52.6968299,232,93,43
10010279,47.5915368,-52.6954916,983,437,33
10010276,47.5993086,-52.6954808,329,131,28
10010278,47.5958782,-52.6934253,251,107,27
10010354,47.6165839,-52.6934037,27,14,47
10010277,47.5975113,-52.6914148,515,194,37
10010293,47.5778754,-52.6910827,58,0,40
10010292,47.5722183,-52.6899332,1112,523,28
10010353,47.6356972,-52.6896838,1387,471,32
10010283,47.5873992,-52.6884621,531,296,41
10010281,47.5983891,-52.6880528,307,113,52
10010280,47.5958439,-52.6878177,374,129,18
10010282,47.5999645,-52.6874407,637,226,22
10010286,47.5797909,-52.6872042,446,280,32
10010355,47.6210282,-52.6777189,197,72,39



From Blake.Holton at dynea.com  Tue Feb 24 20:23:22 2004
From: Blake.Holton at dynea.com (Holton, Blake)
Date: Tue, 24 Feb 2004 21:23:22 +0200
Subject: [R] Statistical Quality Control
Message-ID: <E5F693155C10D61195EA00065B3815B77E96CD@computer.nestechemicals.com>

Greetings,

I've been familiarizing myself with the features of R over the past few
days. I'm impressed with the quality and quantity of the features and
packages. One feature that I would be interested in would be a package for
statistical quality control. Does a package for statistical quality control
exist that I've been unable to locate? 

If not, is anyone aware of efforts to develop a statistical quality control
package? It has been awhile since I've coded in C, but I would be willing to
contribute. 

Regards,

Blake

--------------------------------
Blake Holton
Technical Service Representative
Dynea
475 28th Street
Springfield, OR 97477-5100

Desk: 541.744.7238
Toll Free: 800.547.9525
FAX: 541.744.7249
Cell: 541.954.2696



From thpe at hhbio.wasser.tu-dresden.de  Tue Feb 24 20:47:47 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Tue, 24 Feb 2004 20:47:47 +0100
Subject: [R] be careful: using attach in R functions
In-Reply-To: <HTLGB800.51G@mail.math.pku.edu.cn>
References: <HTLGB800.51G@mail.math.pku.edu.cn>
Message-ID: <403BAA63.2040100@hhbio.wasser.tu-dresden.de>

li dongfeng wrote:
> Hi there,
> 
>   I have just found that the ``attach'' function
> can get you into trouble when called many times.
[..]
>   Below is a demonstration of this performance loss,
> you will see a linear growth in CPU time usage.
> Adding a ``detach()'' call at the end of ``f''
> will get rid of this problem.

Yes, this behaviour is well known (to me using attach for differential
equation models long ago). Detaching ist absolutely required. As an
alternative one can use the with() function.

Thomas P.



From elvis at xlsolutions-corp.com  Tue Feb 24 20:56:48 2004
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 24 Feb 2004 12:56:48 -0700
Subject: [R] Course***Advanced R/Splus Programming @ 5 locations, March 2004
Message-ID: <20040224195648.11404.qmail@webmail-2-3.mesa1.secureserver.net>


   XSolutions Corp ([1]www.xlsolutions-corp.com) is proud to announce
   a 2-day "Advanced R/Splus programming" taught by R Development
   Core Team Guru.

   *********San Francisco ----- March 22-23

   *********Washington DC ----  March 22-23
   *********Chicago -----------  March 25-26
   *********New York ---------  March 22-23
   *********Atlanta -----------  March 25-26
   *********Boston ------------  TBD

   If your location of choice isn't listed, please let us know!

   Reserve your seat Now  at earlybird rates (payment due AFTER the
   class)
   Registration:
   Email Sue Turner: [2]sue at xlsolutions-corp.com
   Phone: 206-686-1578
   Visit us: [3]www.xlsolutions-corp.com/training.htm
   Course outline:
   - Overview of R/S fundamentals: Syntax and Semantics
   - Class and Inheritance in R/S-Plus
   - Concepts, Construction and good use of language objects
   - Coercion and efficiency
   - Object-oriented programming in R and S-Plus
   - Advanced manipulation tools: Parse, Deparse, Substitute, etc.
   - How to fully take advantage of Vectorization
   - Generic and Method Functions; S4 (S-Plus 6)
   - Search path, databases and frames Visibility
   - Working with large objects
   - Handling Properly Recursion and iterative calculations
   - Managing loops; For (S-Plus) and for() loops
   - Consequences of Lazy Evaluation
   - Efficient Code practices for large computations
   - Memory management and Resource monitoring
   - Writing R/S-Plus functions to call compiled code
   - Writing and debugging compiled code for R/S-Plus system
   - Connecting R/S-Plus to External Data Sources
   - Understanding the structure of model fitting functions in R/S-Plus
   - Designing and Packaging efficiently
    Early-bird group research fee: $995!
   This course will also deal with lots of S-Plus efficiency issues and
   any special topics from participants is welcome.
   Please let us know if you and your colleagues are interested in this
   class to take advantage of group discount. Register now to secure
   your seat!
   Cheers,
   Elvis Miller, PhD
   Manager Training.
   XLSolutions Corporation
   206 686 1578
   [4]www.xlsolutions-corp.com

References

   1. http://www.xlsolutions-corp.com/
   2. mailto:sue at xlsolutions-corp.com
   3. http://www.xlsolutions-corp.com/training.htm
   4. http://www.xlsolutions-corp.com/


From ligges at statistik.uni-dortmund.de  Tue Feb 24 21:32:24 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 24 Feb 2004 21:32:24 +0100
Subject: [R] be careful: using attach in R functions
References: <HTLGB800.51G@mail.math.pku.edu.cn>
Message-ID: <403BB4D8.594BDBA3@statistik.uni-dortmund.de>



li dongfeng wrote:
> 
> Hi there,
> 
>   I have just found that the ``attach'' function
> can get you into trouble when called many times.
> For example, you have a simulation routine called ``f()'',
> in which you used ``attach'' and no corresponding ``detach''.

Well, attach() may be useful for convenient interactive data analysis.
I'd never use it in a simulation, since you can access all objects
without attaching anything. 
(Well, I suggest not to use it at all, at least to our students ... and
I'm using it only in very rare cases myself.)

Uwe Ligges



> Then you call this function many times. You will find that
> the system performance get slower and slower,
> because you are making the R search path longer and longer.
> So be careful when you use attach in a function!
> 
>   Below is a demonstration of this performance loss,
> you will see a linear growth in CPU time usage.
> Adding a ``detach()'' call at the end of ``f''
> will get rid of this problem.
> 
> ###############################
> f <- function(){
>   theta <- list(one=2.0, two=0.3, three=0.4)
>   attach(theta)
>   x  <- c(one, two, three)
>   sample(x, 1)
> }
> 
> test <- function(n=400){
>   timeu <- numeric(n)
>   for(i in seq(n)){
>     timeu[i] <-
>       system.time({
>         resi <- f()
>       })[3]
>   }
>   plot(timeu)
> }
> test()
> ##############################
> 
> ????????????????Li Dongfeng
> ????????????????ldf-nospacm at math.pku.edu.cn
> ????????????????????2004-02-24
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Feb 24 21:38:00 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 24 Feb 2004 21:38:00 +0100
Subject: [R] Inheriting from factors + co.
References: <403B9EF9.16486.2DC31517@localhost>
Message-ID: <403BB628.A6DD265C@statistik.uni-dortmund.de>

Torsten Steuernagel wrote:
> 
> I'm trying to create a formal class that does the following:
> 
> 1) accept objects of arbitrary class as .Data slot
> 
> 2) provide a set of other slots that are of fixed type (as usual)
> 
> The following two approaches came to my mind:
> 
> A)
> 
> setClass("myclass", representation("ANY", x = "numeric", y
> ="numeric"))
> 
> new("myclass", 1:10)            # works
> new("myclass", "Test")          # works
> new("myclass", factor(1:10))    # fails


Why do you think it fails?

It works perfectly for me with R-1.8.1 for Windows.
You haven't told anything about your R version, I suspect your are using
an outdated one.

Uwe Ligges






> While I'm able to specify any object that has a formal class as data part
> it won't work with factors or other non-formal classes.
> 
> B)
> 
> Since it is sufficient to use anything that inherits from "vector" and
> "factor", I also tried the following one which seems to be cleaner than
> using "ANY" directly.
> 
> setClassUnion("myunion", representation("vector", "factor"))    #
> works
> setClass("myclass", representation("myunion", x="numeric",
> y="numeric"))
> 
> new("myclass", 1:10)            # fails
> 
> Now it isn't possible to assign anything as data part at all, as long as
> the union contains any non-formal classes such as "factor". Replacing
> "factor" with a formal class will do, of course.
> 
> I wonder if there is some way that does the trick because other
> approaches aren't very straightforward. The obvious solution would be
> a list as .Data part which can store anything but that isn't easy to
> maintain. My goal is to have a formal class whose objects (i.e. .Data
> part) can either be anything derived from "vector" or a factor (ordered).
> I already played around with setIs() for implicit coercion but that doesn't
> do anything as long as one of the classes is an S3 class.
> 
> Thanks for your help,
> 
> Torsten
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Feb 24 21:54:49 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 24 Feb 2004 21:54:49 +0100
Subject: [R] Accessing columns in data.frame using formula
References: <32007046.1077642823@lemmens.socsci.kun.nl>
Message-ID: <403BBA19.C41F437F@statistik.uni-dortmund.de>



Paul Lemmens wrote:
> 
> Hello!
> 
> I'm trying the hard way to use a formula, in a function, to specify the
> names of several important columns in a data.frame. Maybe I'm just battling
> to figure out the right search terms :-( This is on XP, R 1.8.1.
> 
> So, for instance,
> 
> wery[1:5,]
> 
>    V1 V2   V3  V4    V5 congr V7 V8 V9 ok  RT
> 1   1  1  960 520  1483     c  1  r  r  1 760
> 2   1  2 1060 450  3753     c  1  r  r  1 555
> 3   1  3  980 470  5758     c  2  l  l  1 432
> 4   1  4 1060 440  7693     c  1  r  r  1 424
> 5   1  5 1020 440  9578     i  1  l  l  1 369
> 
> I already figured out how to get to the parts of the formula,
> 
> tst <- function(f=RT~congr+ok, data=wery) {
> thingy <- all.vars(f)
> resp <- thingy[1]
> facts <- thingy[-1]

I guess you are really looking for model.frame() and friends, but not
for the stuff written down below.  I may be wrong ... so here we go:


> # and how to get data from the data.frame.
> eval(parse(text=resp), env=data)

Why not   data[[resp]] 


> # But now, I would like to do here what I'd do on the console as
> # wery$ok <- factor(wery$ok), so here data$facts[2] <- factor(data$facts[2])
> # This won't work here. How do I continu?


data[[facts[2]]] <- factor(data[[facts[2]]])

 
> # Or perhaps also
> # data.tmp <- data$resp[data$facts[1] == 'i']

data.tmp <- data[[resp]][data[[facts[1]]] == 'i']


Uwe Ligges

> }
> 
> thank you,
> Paul Lemmens
> 
> P.S:
> str(wery)
> `data.frame':   150 obs. of  11 variables:
>  $ V1   : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ V2   : int  1 2 3 4 5 6 7 8 9 10 ...
>  $ V3   : int  960 1060 980 1060 1020 1010 1060 1010 1090 1090 ...
>  $ V4   : int  520 450 470 440 440 530 580 530 560 540 ...
>  $ V5   : int  1483 3753 5758 7693 9578 11488 13423 15368 17548 19678 ...
>  $ congr: Factor w/ 2 levels "c","i": 1 1 1 1 2 2 2 1 1 2 ...
>  $ V7   : int  1 1 2 1 1 1 1 2 2 2 ...
>  $ V8   : Factor w/ 2 levels "l","r": 2 2 1 2 1 1 1 1 1 2 ...
>  $ V9   : Factor w/ 2 levels "l","r": 2 2 1 2 1 2 1 1 1 2 ...
>  $ ok   : int  1 1 1 1 1 0 1 1 1 1 ...
>  $ RT   : int  760 555 432 424 369 291 403 526 500 458 ...
> 
> --
> Paul Lemmens
> NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
> Montessorilaan 3 (B.01.05)                    Against HTML Mail \ /
> NL-6525 HR Nijmegen                                              X
> The Netherlands                                                 / \
> Phonenumber    +31-24-3612648
> Fax            +31-24-3616066
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dmurdoch at pair.com  Tue Feb 24 21:57:53 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 24 Feb 2004 15:57:53 -0500
Subject: [R] problem of install.packages in windows (R 1.81)
In-Reply-To: <1077640599.403b7d97caee0@webmail.cmima.csic.es>
References: <1077640599.403b7d97caee0@webmail.cmima.csic.es>
Message-ID: <1jen305o564tnt0vllgpc9is2sf30ul0o9@4ax.com>

On Tue, 24 Feb 2004 17:36:39 +0100, mrufino at cmima.csic.es wrote :

>Dear R users,
>
>I have a problem in the configuration of R:
>I just changed university, and my conection to the net is via a password, which 
>permits me to access the packages with no problem via the internet explorer 
>(version 6).

If you can get to CRAN and download packages, then you can just
download the .zip files (the compiled versions of the packages) to a
directory on your computer, and ask R to install them from there using
the menu option

 Packages | Install packages from local zip file

Duncan Murdoch



From ligges at statistik.uni-dortmund.de  Tue Feb 24 22:14:12 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 24 Feb 2004 22:14:12 +0100
Subject: [R] problem of install.packages in windows (R 1.81)
References: <1077640599.403b7d97caee0@webmail.cmima.csic.es>
Message-ID: <403BBEA4.B48CC067@statistik.uni-dortmund.de>



mrufino at cmima.csic.es wrote:
> 
> Dear R users,
> 
> I have a problem in the configuration of R:
> I just changed university, and my conection to the net is via a password, which
> permits me to access the packages with no problem via the internet explorer
> (version 6).
> I just updated R to R 1.81, and I cannot download nether upgrade packages (and
> many are not working with the update!!!).
> I have been looking in the help and emails, and saw that many people had the
> similar problems.
> By what I understood, I have to set up the proxy, and do something about
> the 'path'... but although I read RFAQ and R for windows, I could not do it,
> because I dont know where do I go (I looked in the control panel, internet
> options, etc. nothing worked, than also I tried changing the name of the dll
> file (internet2.dll), as recommended and makes R crash, as soon as it is
> conected.
> 
> I think I am very lost in the 'proxy' and 'path'... probably because I am a
> Windows user. By the way I use Win xp and 98.
> 
> I am sorry for the basic question....
> 
> could you help e pleeeeease :-) ?
> thank you
> Marta

Let's study the R for Windows FAQ together:

  "2.17 The internet download functions fail.

  [...]

  (a) Use the alternative internet2.dll [...]
  Note that this does not work  with proxies that 
  need authentication."

OK. You do need authentication, so (a) is nothing for you ...

  "(b) A proxy needs to be set up: see ?download.file. 
  Here are two versions of an example (a real one, but 
  from a machine that is only available locally) of a
  command-line in a short cut:

  /R/rw1081/bin/RGui.exe http_proxy=http://user:pass at gannet:80/
  /R/rw1081/bin/RGui.exe http_proxy=http://gannet/ http_proxy_user=ask

  The second version will prompt the user for the proxy 
  username and password when HTTP downloads are first used."

And here we got it. Just modify your shortcut to start R. 
Right-click the shortcut, select Properties and modify the target as
given above,
where you have to replace "gannet" by your proxy server, and (for the
first version) user by your username and pass by your password. That's
it.

If you don't know what that means, it is the easiest way to ask someone
from your department's computer staff.

Also, you might want to look into ?download.file for more details, as
mentioned in the FAQs.

Uwe Ligges



From rpeng at jhsph.edu  Tue Feb 24 22:20:42 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 24 Feb 2004 16:20:42 -0500
Subject: [R] be careful: using attach in R functions
In-Reply-To: <HTLGB800.51G@mail.math.pku.edu.cn>
References: <HTLGB800.51G@mail.math.pku.edu.cn>
Message-ID: <403BC02A.50300@jhsph.edu>

Using attach() in this context may not be wise.  I tend to only use 
attach() when working interactively.  It might be better to use with() 
in this situation, such as

f <- function() {
	theta <- list(one=2.0, two=0.3, three=0.4)
	x <- with(theta, c(one, two, three))
	sample(x, 1)
}

-roger

li dongfeng wrote:
> Hi there,
> 
>   I have just found that the ``attach'' function
> can get you into trouble when called many times.
> For example, you have a simulation routine called ``f()'',
> in which you used ``attach'' and no corresponding ``detach''.
> Then you call this function many times. You will find that
> the system performance get slower and slower,
> because you are making the R search path longer and longer.
> So be careful when you use attach in a function!
> 
>   Below is a demonstration of this performance loss,
> you will see a linear growth in CPU time usage.
> Adding a ``detach()'' call at the end of ``f''
> will get rid of this problem.
> 
> ###############################
> f <- function(){
>   theta <- list(one=2.0, two=0.3, three=0.4)
>   attach(theta)
>   x  <- c(one, two, three)
>   sample(x, 1)
> }
> 
> test <- function(n=400){
>   timeu <- numeric(n)
>   for(i in seq(n)){
>     timeu[i] <-
>       system.time({
>         resi <- f()
>       })[3]
>   }
>   plot(timeu)
> }
> test()
> ##############################
> 
> 
> Li Dongfeng
> ldf-nospacm at math.pku.edu.cn
> 2004-02-24
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From rvaradha at jhsph.edu  Tue Feb 24 22:23:20 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Tue, 24 Feb 2004 16:23:20 -0500
Subject: [R] Computing the mode
Message-ID: <2e4ba82e47c2.2e47c22e4ba8@jhsph.edu>

I remember Prof. Ripley suggesting the "taut springs" approach to 
estimating the modes, sometime ago in a posting to this group. I would 
be interested in knowing whether there is any R implementation of this 
approach (developed by Davies (1995)), for both non-parametric 
regression and density estimation.

Ravi.

----- Original Message -----
From: Spencer Graves <spencer.graves at pdf.com>
Date: Tuesday, February 24, 2004 7:12 am
Subject: Re: [R] Computing the mode

>      The problem is that 'the statistic "mode" of a sample' has 
> no 
> clear definition.  If the distribution is highly discrete, then 
> the 
> following will do the job: 
> 
> > set.seed(1)
> > X <- rpois(11,1)
> > (nX <- table(X))
> X
> 0 1 2 3
> 4 4 2 1
> > names(nX)[nX==max(nX)]
> [1] "0" "1"
> 
>      However, if the data are continuous with no 2 numbers 
> exactly 
> equal, then the "mode" depends on the procedure, e.g., the 
> specific 
> selection of breakpoints for a histogram.  If you insist on 
> finding 
> something, you can try "www.r-project.org" -> search -> "R site 
> search" 
> for something like ""nonparametric density estimation" and / or 
> "kernel 
> density estimator". 
> 
>      hope this helps. 
>      spencer graves
>      p.s.  This has been discussed recently on this list, but I 
> could 
> not easily find it in the archives. 
> 
> Aurora Torrente wrote:
> 
> > Hi all,
> > I think this question could be quite trivial, but I can?t find 
> out the 
> > solution... How can you compute the statistic "mode" of a 
> sample, in 
> > case it exists (as mode() returns the mode of an object)? I 
> tried 
> > help.search("mode") but I couldn't find a clue...
> > Any help would be much appreciated. Regards,
> >
> >        Aurora
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From Torsten.Steuernagel at gmx.de  Tue Feb 24 22:34:13 2004
From: Torsten.Steuernagel at gmx.de (Torsten Steuernagel)
Date: Tue, 24 Feb 2004 22:34:13 +0100
Subject: [R] Inheriting from factors + co.
In-Reply-To: <403BB628.A6DD265C@statistik.uni-dortmund.de>
Message-ID: <403BD165.17496.2E880922@localhost>

On 24 Feb 2004 at 21:38, Uwe Ligges wrote:

> > setClass("myclass", representation("ANY", x = "numeric", y
> > ="numeric"))
> > 
> > new("myclass", 1:10)            # works
> > new("myclass", "Test")          # works
> > new("myclass", factor(1:10))    # fails
>
> Why do you think it fails?

I was typing faster than thinking. It doesn't actually fail but what I get is 
a numeric vector with a levels attribute. If I specify a factor as .Data 
part I expect that the created object IS a factor and 
is.factor(new("myclass", factor(1:10))) returns TRUE.
 
> It works perfectly for me with R-1.8.1 for Windows.
> You haven't told anything about your R version, I suspect your are
> using an outdated one.

Sorry, forgot that one. I'm also using R 1.8.1 on Windows.

Thanks,

Torsten



From rvaradha at jhsph.edu  Tue Feb 24 22:51:16 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Tue, 24 Feb 2004 16:51:16 -0500
Subject: [R] Computing the mode
Message-ID: <9255cb63.cb639255@jhsph.edu>

Forgive me for not following the "posting guidelines" and posting 
before doing my homework!  I checked CRAN website and found that there 
is a package developed by Davies and Kovac, called "ftnonpar" that 
implements the "taut spring" approach that I mentioned in my previous 
posting. 

# For example:
library(ftnonpar)
plot(dclaw(seq(-3,3,len=1000)),type="l")
xx <- rclaw(500)
pmden(xx,verbose=T)

Best,
Ravi.

----- Original Message -----
From: Ravi Varadhan <rvaradha at jhsph.edu>
Date: Tuesday, February 24, 2004 4:23 pm
Subject: Re: [R] Computing the mode

> I remember Prof. Ripley suggesting the "taut springs" approach to 
> estimating the modes, sometime ago in a posting to this group. I 
> would 
> be interested in knowing whether there is any R implementation of 
> this 
> approach (developed by Davies (1995)), for both non-parametric 
> regression and density estimation.
> 
> Ravi.
> 
> ----- Original Message -----
> From: Spencer Graves <spencer.graves at pdf.com>
> Date: Tuesday, February 24, 2004 7:12 am
> Subject: Re: [R] Computing the mode
> 
> >      The problem is that 'the statistic "mode" of a sample' has 
> > no 
> > clear definition.  If the distribution is highly discrete, then 
> > the 
> > following will do the job: 
> > 
> > > set.seed(1)
> > > X <- rpois(11,1)
> > > (nX <- table(X))
> > X
> > 0 1 2 3
> > 4 4 2 1
> > > names(nX)[nX==max(nX)]
> > [1] "0" "1"
> > 
> >      However, if the data are continuous with no 2 numbers 
> > exactly 
> > equal, then the "mode" depends on the procedure, e.g., the 
> > specific 
> > selection of breakpoints for a histogram.  If you insist on 
> > finding 
> > something, you can try "www.r-project.org" -> search -> "R site 
> > search" 
> > for something like ""nonparametric density estimation" and / or 
> > "kernel 
> > density estimator". 
> > 
> >      hope this helps. 
> >      spencer graves
> >      p.s.  This has been discussed recently on this list, but I 
> > could 
> > not easily find it in the archives. 
> > 
> > Aurora Torrente wrote:
> > 
> > > Hi all,
> > > I think this question could be quite trivial, but I can?t find 
> > out the 
> > > solution... How can you compute the statistic "mode" of a 
> > sample, in 
> > > case it exists (as mode() returns the mode of an object)? I 
> > tried 
> > > help.search("mode") but I couldn't find a clue...
> > > Any help would be much appreciated. Regards,
> > >
> > >        Aurora
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-
> project.org/posting-
> > guide.html
>



From ripley at stats.ox.ac.uk  Tue Feb 24 23:09:37 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 24 Feb 2004 22:09:37 +0000 (GMT)
Subject: [R] problem of install.packages in windows (R 1.81)
In-Reply-To: <1077640599.403b7d97caee0@webmail.cmima.csic.es>
Message-ID: <Pine.LNX.4.44.0402242203460.2550-100000@gannet.stats>

Do read the rw-FAQ, Q2.17, which gives examples.  If following them does 
not work, you should seek local advice about your system.

You can always download the zip files and install them from the Packages 
menu too.

BTW, you do need to be accurate: it is R 1.8.1, not 1.81 and the proxy 
instructions need to be followed exactly.

On Tue, 24 Feb 2004 mrufino at cmima.csic.es wrote:

> Dear R users,
> 
> I have a problem in the configuration of R:
> I just changed university, and my conection to the net is via a password, which 
> permits me to access the packages with no problem via the internet explorer 
> (version 6).
> I just updated R to R 1.81, and I cannot download nether upgrade packages (and 
> many are not working with the update!!!).
> I have been looking in the help and emails, and saw that many people had the 
> similar problems. 

Not so: very few people have proxies that need passwords.

> By what I understood, I have to set up the proxy, and do something about 
> the 'path'... but although I read RFAQ and R for windows, I could not do it, 
> because I dont know where do I go (I looked in the control panel, internet 
> options, etc. nothing worked, than also I tried changing the name of the dll 
> file (internet2.dll), as recommended and makes R crash, as soon as it is 
> conected.

That is *not* recommended in the FAQ, so why did you do it?  Please 
uninstall and reinstall R to undo the damage that you caused.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jasont at indigoindustrial.co.nz  Tue Feb 24 23:27:45 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 25 Feb 2004 11:27:45 +1300 (NZDT)
Subject: [R] Suggestions ?!?!
In-Reply-To: <403B5FFD.3040406@yale.edu>
References: <200402121155.i1CBshwg005875@hypatia.math.ethz.ch><402BAC57.6060600@yale.edu>
	<403B5FFD.3040406@yale.edu>
Message-ID: <33488.203.9.176.60.1077661665.squirrel@new-webmail.maxnet.co.nz>

"ivo welch" <ivo.welch at yale.edu> said...
> * Finally, a more complex question: I have a historical rate of stock
> return series (yes, I teach finance).  I would like to make a ts plot on
> the left (plot(date,returns,type="h")), and a plot(density(returns)) on
> the right.  works nicely with par(mfrow=c(1,2)), but it would be even
> nicer if I could rotate the density plot 90 degrees, so that it is more
> apparent that the density plot is an aggregation of the points at the
> same y coordinates.  (if need be, a histogram could replace the density
> plot.)  Is it possible to rotate an entire subpanel figure.  if there
> was a "horizontal" parameter to ps.options for plot(), it would do the
> trick, but this does not work.   So, this may be a suggestion, too.

There might be a more natural way to do this using grid graphics, but I'm
still not familiar with grid.  This type of plot is one I do enough of
that I rolled by own the old-fashioned way.

Try

zz <- ts(rnorm(100))
DenTSplot(zz)

## ts and density
DenTSplot <- function(x, ylim=NULL,main=NULL,...) {
	# data sanity check
	if(!is.ts(x))
		x <- ts(x)
	if(!is.null(dim(x))) {
		stop("can only handle univariate time series\n")
	}

	# set layout - FIXME - should this be user-setable?
	layout(matrix(c(1,1,1,2),nrow=1))

	# find x density.  FIXME - need to take arguments about
	# bandwidth selector, etc.
	x.d <- density(x)

	if(is.null(ylim)) {
		ylim <- range(x.d$x)
	}
	if(is.null(main))
		main <- "Series"

	opar <- par(no.readonly=TRUE)
	on.exit(par(opar))
	mai <- par("mai")
	mai.ts <- c(mai[1:3],0)
	par(mai=mai.ts)
	plot(x,ylim=ylim,main=main,...)

	mai.den <- c(mai[1],0,mai[3:4])
	par(mai=mai.den)
	plot(x.d$y, x.d$x,
		ylim=ylim, type="l", yaxt="n",
		ylab="",xlab="",main="Density")
}



From jcjorgensen at wisc.edu  Wed Feb 25 01:03:51 2004
From: jcjorgensen at wisc.edu (Jeff Jorgensen)
Date: Tue, 24 Feb 2004 18:03:51 -0600
Subject: [R] levelplot add line
Message-ID: <5.2.1.1.2.20040224175530.02213810@wiscmail.wisc.edu>

R folks,

I can't seem to find the instructions in the help files for the lattice 
package that explain how to add lines, such as with lines() or ?, to a 
levelplot.  I'd be grateful if someone could point me in the proper direction.

Cheers,

Jeff

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Jeff Jorgensen

Center for Limnology                             jcjorgensen at wisc.edu
University of Wisconsin Madison           ph (608) 263-2304
680 North Park Street                           fx (608) 265-2340
Madison, Wisconsin 53706                http://limnology.wisc.edu

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From deepayan at stat.wisc.edu  Wed Feb 25 01:51:48 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 24 Feb 2004 18:51:48 -0600
Subject: [R] levelplot add line
In-Reply-To: <5.2.1.1.2.20040224175530.02213810@wiscmail.wisc.edu>
References: <5.2.1.1.2.20040224175530.02213810@wiscmail.wisc.edu>
Message-ID: <200402241851.48772.deepayan@stat.wisc.edu>

On Tuesday 24 February 2004 18:03, Jeff Jorgensen wrote:
> R folks,
>
> I can't seem to find the instructions in the help files for the lattice
> package that explain how to add lines, such as with lines() or ?, to a
> levelplot.  I'd be grateful if someone could point me in the proper
> direction.

The general rule for all lattice functions is to write your own panel 
function. For example, 

data(volcano)
levelplot(volcano, 
          panel = function(...) {
              panel.levelplot(...)
              panel.abline(c(0,1))
          })

lines() will not work for lattice, but you can use llines() instead. 

Of course, for anything more useful than this example, your panel function 
should make use of the data that's passed to the panel function. Exactly 
what would be passed depends on the function in question. For levelplot, 
the best place to look will be panel.levelplot, and similarly for other 
functions.

Hth,

Deepayan



From N.L.Pace at m.cc.utah.edu  Wed Feb 25 02:06:17 2004
From: N.L.Pace at m.cc.utah.edu (Nathan Leon Pace, MD, MStat)
Date: Tue, 24 Feb 2004 18:06:17 -0700
Subject: [R] (no subject)
Message-ID: <D0C11FB0-672E-11D8-B2BC-000393B3E9D0@utah.edu>

Hi All,

I'm new at programming in R.

Some functions create objects for which extractor functions are written 
to pull out some partial result.

I wish to extract partial results from functions without extractor 
functions:
for example, to pass a vector of results to another function.

Even after looking at V&R S Programming I don't see a general approach.

Specifically, how would I extract just the contingency table from 
ftable.

Thanks,

Nathan


Nathan Leon Pace, MD, MStat	Work:n.l.pace at utah.edu
Department of Anesthesiology	Home:nlpaces at comcast.net
University of Utah			Work:801.581.6393
Salt Lake City, Utah			    Home:801.467.2925
					Fax:801.581.4367										Cell:801.558.3987



From jasont at indigoindustrial.co.nz  Wed Feb 25 02:27:21 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 25 Feb 2004 14:27:21 +1300 (NZDT)
Subject: [R] (no subject)
In-Reply-To: <D0C11FB0-672E-11D8-B2BC-000393B3E9D0@utah.edu>
References: <D0C11FB0-672E-11D8-B2BC-000393B3E9D0@utah.edu>
Message-ID: <46655.203.9.176.60.1077672441.squirrel@new-webmail.maxnet.co.nz>

> Some functions create objects for which extractor functions are written
> to pull out some partial result.
>
> I wish to extract partial results from functions without extractor
> functions:
> for example, to pass a vector of results to another function.

There isn't a general solution to this problem - it's like saying "I'd
like to remove a part from my car engine that doesn't require a special
tool.  How do I do this?"

> Specifically, how would I extract just the contingency table from
> ftable.

The command str() is your friend for finding how in particular to approach
a problem.  See ?str, then try:

> data(Titanic)
> zz <- ftable(Titanic)
> str(zz)
 ftable [1:16, 1:2] 0 118 0 4 0 154 0 13 35 387 ...
 - attr(*, "row.vars")=List of 3
  ..$ Class: chr [1:4] "1st" "2nd" "3rd" "Crew"
  ..$ Sex  : chr [1:2] "Male" "Female"
  ..$ Age  : chr [1:2] "Child" "Adult"
 - attr(*, "col.vars")=List of 1
  ..$ Survived: chr [1:2] "No" "Yes"
 - attr(*, "class")= chr "ftable"

This tells you that the ftable object is a matrix-like structure: [1:16,
1:2] with row and column name attributes.  To strip the attributes, I'd
coerce to a matrix (in this case).

> matrix(zz,ncol=ncol(zz))


> I'm new at programming in R.
...
> Even after looking at V&R S Programming I don't see a general approach.

Get V&R "Modern Applied Statistics with S".  It's more what you need to
learn R/S.  "S Programming" is for when you start seriously programming
(as opposed to using) R/S.  It's not a beginning book at all.

Hope that helps

Jason



From christof.bigler at colorado.edu  Wed Feb 25 03:47:48 2004
From: christof.bigler at colorado.edu (Christof Bigler)
Date: Tue, 24 Feb 2004 19:47:48 -0700
Subject: [R] circular filter
Message-ID: <FEFFCD39-673C-11D8-9B4B-00039376D216@colorado.edu>

I try to find a circular filter that I can export to be used in a 
spatial software.
Assuming, we have a matrix, representing 9x9 regularly spaced points  
with the center point 'filter[5, 5]'. In this example, I want to find a 
function that weighs all neighbor points within a distance of d=4 units 
with 1:

 > filter <- matrix(0, 9, 9)
 > filter <- function() ...
 > filter
       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
  [1,]    0    0    0    0    1    0    0    0    0
  [2,]    0    0    1    1    1    1    1    0    0
  [3,]    0    1    1    1    1    1    1    1    0
  [4,]    0    1    1    1    1    1    1    1    0
  [5,]    1    1    1    1    1    1    1    1    1
  [6,]    0    1    1    1    1    1    1    1    0
  [7,]    0    1    1    1    1    1    1    1    0
  [8,]    0    0    1    1    1    1    1    0    0
  [9,]    0    0    0    0    1    0    0    0    0

Finally, I want to use a larger matrix, e.g. with 61x61 points. Is 
there a simple function around that I could use to this end?

Thanks!
Christof



From ok at cs.otago.ac.nz  Wed Feb 25 04:06:07 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Wed, 25 Feb 2004 16:06:07 +1300 (NZDT)
Subject: [R] would be nice ...
Message-ID: <200402250306.i1P367Ax273328@atlas.otago.ac.nz>

Jan de Leeuw <deleeuw at stat.ucla.edu> wrote:
	if R had something like
	
	 > python -c "print(sum([1,2,3]));print(3*2)"
	6
	6
	
What's wrong with

    % echo "print(sum(c(1,2,3))); print(3*2)" | R --no-save -q
    > print(sum(c(1,2,3))); print(3*2)
    [1] 6
    [1] 6
    >



From cottenie at nceas.ucsb.edu  Wed Feb 25 04:03:49 2004
From: cottenie at nceas.ucsb.edu (karl cottenie)
Date: Tue, 24 Feb 2004 19:03:49 -0800
Subject: [R] lapack routine dgesdd, error code 1
Message-ID: <1077678228.28752.11.camel@dhcp108.nceas.ucsb.edu>

Hello R-users,

during one of my analyses that involve a SVD, I get the following error
message:

Error in La.svd(x, nu, nv, method) : error code 1 from Lapack routine
dgesdd

With a search on the R web site, I only found references to error codes
17 and 3 for this particular routine. I also found the Lapack web site,
but could not find a list of the possible error messages. If somebody
knows what this error message means, or where I can find more
information, that would be great.

thanks in advance,

Karl
-- 

------------------------------------------------------------------------
Karl Cottenie
Postdoctoral Fellow
National Center for Ecological Analysis and Synthesis - UC Santa Barbara
735 State Street, Suite 300
Santa Barbara, CA 93101
e-mail: cottenie at nceas.ucsb.edu
http://www.nceas.ucsb.edu/~cottenie
phone: 	805 892 2520
fax: 	805 892 2510



From bitwrit at ozemail.com.au  Wed Feb 25 08:00:11 2004
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Wed, 25 Feb 2004 18:00:11 +1100
Subject: [R] Calculate Distance and Aggregate Data?
In-Reply-To: <20040224145845.VRVT96949.web01-imail.rogers.com@localhost>
References: <20040224145845.VRVT96949.web01-imail.rogers.com@localhost>
Message-ID: <20040225070312.EBZY13349.smta07.mail.ozemail.net@there>

dsheuman at rogers.com wrote:
> Hi all,
>
> I've been struggling learning R and need to turn to the list again.
>
> I've got a dataset (comma-delimited file) with the following fields: 
> recid, latitude, longitude, population, dwelling and age.  For each
> observation, I'd like to calculate the total number of people and dwellings
> and average age within 2 k.m.  Distance could be Euclidean, however, a
> proper distance calculation (great circle route) is best.
>
A good approximation is the haversine formula, see:

http://www.census.gov/cgi-bin/geo/gisfaq?Q5.1

for the spherical approximation and various corrections to account for the 
earth's departure from sphericity.

Jim



From s-plus at wiwi.uni-bielefeld.de  Wed Feb 25 08:46:16 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Wed, 25 Feb 2004 08:46:16 +0100
Subject: [R] circular filter
References: <FEFFCD39-673C-11D8-9B4B-00039376D216@colorado.edu>
Message-ID: <403C52C8.9080608@wiwi.uni-bielefeld.de>


try:

filter.matrix.center<-function(n=9,size=5){
  x<-matrix(1,n,n)
  center<-(n+1)/2
  (abs(row(x)-center)+abs(col(x)-center)) < size
}
filter.matrix.center()

some tests:

 > 0+filter.matrix.center(5,2)
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    0
[2,]    0    0    1    0    0
[3,]    0    1    1    1    0
[4,]    0    0    1    0    0
[5,]    0    0    0    0    0

 > 0+filter.matrix.center()
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
 [1,]    0    0    0    0    1    0    0    0    0
 [2,]    0    0    0    1    1    1    0    0    0
 [3,]    0    0    1    1    1    1    1    0    0
 [4,]    0    1    1    1    1    1    1    1    0
 [5,]    1    1    1    1    1    1    1    1    1
 [6,]    0    1    1    1    1    1    1    1    0
 [7,]    0    0    1    1    1    1    1    0    0
 [8,]    0    0    0    1    1    1    0    0    0
 [9,]    0    0    0    0    1    0    0    0    0

Peter Wolf

--------------------------------------------------------------------------------------------------------

Christof Bigler wrote:
I try to find a circular filter that I can export to be used in a 
spatial software.
Assuming, we have a matrix, representing 9x9 regularly spaced points  
with the center point 'filter[5, 5]'. In this example, I want to find a 
function that weighs all neighbor points within a distance of d=4 units 
with 1:

 > filter <- matrix(0, 9, 9)
 > filter <- function() ...
 > filter
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
 [1,]    0    0    0    0    1    0    0    0    0
 [2,]    0    0    1    1    1    1    1    0    0
 [3,]    0    1    1    1    1    1    1    1    0
 [4,]    0    1    1    1    1    1    1    1    0
 [5,]    1    1    1    1    1    1    1    1    1
 [6,]    0    1    1    1    1    1    1    1    0
 [7,]    0    1    1    1    1    1    1    1    0
 [8,]    0    0    1    1    1    1    1    0    0
 [9,]    0    0    0    0    1    0    0    0    0

Finally, I want to use a larger matrix, e.g. with 61x61 points. Is there 
a simple function around that I could use to this end?

Thanks!
Christof

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Feb 25 08:49:05 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 25 Feb 2004 08:49:05 +0100
Subject: [R] circular filter
In-Reply-To: <FEFFCD39-673C-11D8-9B4B-00039376D216@colorado.edu>
References: <FEFFCD39-673C-11D8-9B4B-00039376D216@colorado.edu>
Message-ID: <403C5371.1000803@statistik.uni-dortmund.de>

Christof Bigler wrote:
> I try to find a circular filter that I can export to be used in a 
> spatial software.
> Assuming, we have a matrix, representing 9x9 regularly spaced points  
> with the center point 'filter[5, 5]'. In this example, I want to find a 
> function that weighs all neighbor points within a distance of d=4 units 
> with 1:
> 
>  > filter <- matrix(0, 9, 9)
>  > filter <- function() ...
>  > filter
>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
>  [1,]    0    0    0    0    1    0    0    0    0
>  [2,]    0    0    1    1    1    1    1    0    0
>  [3,]    0    1    1    1    1    1    1    1    0
>  [4,]    0    1    1    1    1    1    1    1    0
>  [5,]    1    1    1    1    1    1    1    1    1
>  [6,]    0    1    1    1    1    1    1    1    0
>  [7,]    0    1    1    1    1    1    1    1    0
>  [8,]    0    0    1    1    1    1    1    0    0
>  [9,]    0    0    0    0    1    0    0    0    0
> 
> Finally, I want to use a larger matrix, e.g. with 61x61 points. Is there 
> a simple function around that I could use to this end?

I don't know whether there is a function makeYourFilter(), but I'm 
pretty sure it's easy to write it. Unfortunately, I don't know which 
distance you are talking about.

Uwe Ligges



> Thanks!
> Christof
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Wed Feb 25 08:48:10 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 25 Feb 2004 02:48:10 -0500 (EST)
Subject: [R] Need help on parsing dates
Message-ID: <20040225074810.02D9A399C@mprdmxin.myway.com>



I just came across another package for irregular dates, zoo,
giving another alternative.

It can be used together with dates, chron or POSIXct.  For
example, using chron:

require(zoo)
require(chron)
z.zoo <- zoo(z$Data, chron(z$Date, format="y-m-d"))

---
Date:   Mon, 23 Feb 2004 17:22:42 -0500 (EST) 
From:   Gabor Grothendieck <ggrothendieck at myway.com>
To:   <ajayshah at mayin.org>, <r-help at stat.math.ethz.ch> 
Subject:   RE: [R] Need help on parsing dates 

 


There are a number of ways to do this. First read in the data 
using the as.is=1 argument to ensure that the date is read 
in as character:

z <- read.table(myfile, as.is=1, sep=" ", col.names=c("Date", "Data"))

Now you can create a date column using date, POSIXct, chron or irts:

# date
require(date) 
z$Date <- as.date(z$Date,format="ymd"))

# POSIXct
z$Date <- as.POSIXct(z$Date))

# chron
require(chron)
z$Date <- chron(z$Date, "y-m-d")

You can create a ts timeseries (which is regular) by ignoring t
he dates altogether:

z.ts <- ts(z$Data)

Or an irts irregular time series using package tseries:

require(tseries)
z.irts <- irts(as.POSIXct(z$Date), z$Data)

Or an its irregular time series using package its:

require(its)
z.its <- readcsvIts(myfile, sep=" ", col.names=c("Date", "Data"))

Assuming z.ts was used you can do this:

ar(z.ts, order=1)
etc.

---
Date: Tue, 24 Feb 2004 01:37:23 +0530 
From: Ajay Shah <ajayshah at mayin.org>
To: r-help <r-help at stat.math.ethz.ch> 
Subject: [R] Need help on parsing dates 


I know this:

> library(date)
> x="1979-04-04"
> try=as.date(x, "ymd")
> print(try)
[1] 4Apr79

and that `x' here has to be a string, e.g.:

> x=1979-04-04
> print(x)
[1] 1971

I'm stuck in reading from a file. I say: 

> A <- read.table(file="try")
> print(A)
V1 V2
1 1979-04-04 -1.04712042
2 1979-04-06 0.54538055
3 1979-04-09 0.09663392
4 1979-04-11 0.57119871
5 1979-04-12 0.73594112
6 1979-04-17 -1.54422087
7 1979-04-18 -0.20595691
8 1979-04-19 0.12700429
9 1979-04-20 0.42016807
10 1979-04-23 -1.46838241

I am confused - is V1 a number or a string? Looking at it, it must be
a string. But yet:

> library(date)
> try=as.date(A$V1, "ymd")
Error in as.date(A$V1, "ymd") : Cannot coerce to date format

In short, how do I parse in dates of the format yyyy-mm-dd (the ISO
8601 format) or the yyyymmdd format.

And if I may ask the next step: How do I tell R that I have a file
full of data all of which is time-series data, where V1 is the
datetime vector, and all the other columns are time-series, to do
things like ARMA models and ts plots with?



From ripley at stats.ox.ac.uk  Wed Feb 25 09:22:13 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 25 Feb 2004 08:22:13 +0000 (GMT)
Subject: [R] lapack routine dgesdd, error code 1
In-Reply-To: <1077678228.28752.11.camel@dhcp108.nceas.ucsb.edu>
Message-ID: <Pine.LNX.4.44.0402250815520.3233-100000@gannet.stats>

You have to read the LAPACK code.  It says

*  INFO    (output) INTEGER
*          = 0:  successful exit.
*          < 0:  if INFO = -i, the i-th argument had an illegal value.
*          > 0:  DBDSDC did not converge, updating process failed.

and 1 > 0 so this was a convergence failure inside the SVD code.

Such things are almost impossible to reproduce elsewhere as they depend on
the BLAS and the optimizations done by the compiler.

On Tue, 24 Feb 2004, karl cottenie wrote:

> Hello R-users,
> 
> during one of my analyses that involve a SVD, I get the following error
> message:
> 
> Error in La.svd(x, nu, nv, method) : error code 1 from Lapack routine
> dgesdd
> 
> With a search on the R web site, I only found references to error codes
> 17 and 3 for this particular routine. I also found the Lapack web site,
> but could not find a list of the possible error messages. If somebody
> knows what this error message means, or where I can find more
> information, that would be great.
> 
> thanks in advance,
> 
> Karl
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From s-plus at wiwi.uni-bielefeld.de  Wed Feb 25 09:22:24 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Wed, 25 Feb 2004 09:22:24 +0100
Subject: [R] circular filter
References: <FEFFCD39-673C-11D8-9B4B-00039376D216@colorado.edu>
	<403C52C8.9080608@wiwi.uni-bielefeld.de>
Message-ID: <403C5B40.5000907@wiwi.uni-bielefeld.de>

filter.matrix.center  implements Manhattan or L 1 distance.
If you want to define neighbor points
by Euklidean distances (L 2) use filter.matrix.center(p=2):

filter.matrix.center.p <- function(n=9,size=5,p=2){
   x<-matrix(1,n,n)
   center<-(n+1)/2
   (abs(row(x)-center)^p+abs(col(x)-center)^p)^(1/p) < size
}

example:

 > 0+filter.matrix.center.p(9,4.1)
    [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
[1,]    0    0    0    0    1    0    0    0    0
[2,]    0    0    1    1    1    1    1    0    0
[3,]    0    1    1    1    1    1    1    1    0
[4,]    0    1    1    1    1    1    1    1    0
[5,]    1    1    1    1    1    1    1    1    1
[6,]    0    1    1    1    1    1    1    1    0
[7,]    0    1    1    1    1    1    1    1    0
[8,]    0    0    1    1    1    1    1    0    0
[9,]    0    0    0    0    1    0    0    0    0

Peter Wolf



--------------------------------------------------

Peter Wolf wrote:

>
> try:
>
> filter.matrix.center<-function(n=9,size=5){
>  x<-matrix(1,n,n)
>  center<-(n+1)/2
>  (abs(row(x)-center)+abs(col(x)-center)) < size
> }
> filter.matrix.center()
>
> some tests:
>
> > 0+filter.matrix.center(5,2)
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    0    0    0    0    0
> [2,]    0    0    1    0    0
> [3,]    0    1    1    1    0
> [4,]    0    0    1    0    0
> [5,]    0    0    0    0    0
>
> > 0+filter.matrix.center()
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
> [1,]    0    0    0    0    1    0    0    0    0
> [2,]    0    0    0    1    1    1    0    0    0
> [3,]    0    0    1    1    1    1    1    0    0
> [4,]    0    1    1    1    1    1    1    1    0
> [5,]    1    1    1    1    1    1    1    1    1
> [6,]    0    1    1    1    1    1    1    1    0
> [7,]    0    0    1    1    1    1    1    0    0
> [8,]    0    0    0    1    1    1    0    0    0
> [9,]    0    0    0    0    1    0    0    0    0
>
> Peter Wolf
>
> -------------------------------------------------------------------------------------------------------- 
>
>
> Christof Bigler wrote:
> I try to find a circular filter that I can export to be used in a 
> spatial software.
> Assuming, we have a matrix, representing 9x9 regularly spaced points  
> with the center point 'filter[5, 5]'. In this example, I want to find 
> a function that weighs all neighbor points within a distance of d=4 
> units with 1:
>
> > filter <- matrix(0, 9, 9)
> > filter <- function() ...
> > filter
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
> [1,]    0    0    0    0    1    0    0    0    0
> [2,]    0    0    1    1    1    1    1    0    0
> [3,]    0    1    1    1    1    1    1    1    0
> [4,]    0    1    1    1    1    1    1    1    0
> [5,]    1    1    1    1    1    1    1    1    1
> [6,]    0    1    1    1    1    1    1    1    0
> [7,]    0    1    1    1    1    1    1    1    0
> [8,]    0    0    1    1    1    1    1    0    0
> [9,]    0    0    0    0    1    0    0    0    0
>
> Finally, I want to use a larger matrix, e.g. with 61x61 points. Is 
> there a simple function around that I could use to this end?
>
> Thanks!
> Christof
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Feb 25 10:00:24 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 25 Feb 2004 10:00:24 +0100
Subject: [R] Inheriting from factors + co.
In-Reply-To: <403BD165.17496.2E880922@localhost>
References: <403BD165.17496.2E880922@localhost>
Message-ID: <403C6428.4060205@statistik.uni-dortmund.de>

Torsten Steuernagel wrote:

> On 24 Feb 2004 at 21:38, Uwe Ligges wrote:
> 
> 
>>>setClass("myclass", representation("ANY", x = "numeric", y
>>>="numeric"))
>>>
>>>new("myclass", 1:10)            # works
>>>new("myclass", "Test")          # works
>>>new("myclass", factor(1:10))    # fails
>>
>>Why do you think it fails?
> 
> 
> I was typing faster than thinking. It doesn't actually fail but what I get is 
> a numeric vector with a levels attribute. If I specify a factor as .Data 
> part I expect that the created object IS a factor and 
> is.factor(new("myclass", factor(1:10))) returns TRUE.


So you are going to handle/mix the S4 class like/with S3 classes?
Hmm. It can be either of class "myclass" or of class "factor".
I'd define a separate explicit slot for such a class:

   setClass("myclass", representation(mainSlot = "ANY",
       x = "numeric", y = "numeric"))

John Chambers might want to correct me...

Uwe



> 
>>It works perfectly for me with R-1.8.1 for Windows.
>>You haven't told anything about your R version, I suspect your are
>>using an outdated one.
> 
> 
> Sorry, forgot that one. I'm also using R 1.8.1 on Windows.
> 
> Thanks,
> 
> Torsten
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Isabelle.ZABALZA-MEZGHANI at ifp.fr  Wed Feb 25 10:01:41 2004
From: Isabelle.ZABALZA-MEZGHANI at ifp.fr (ZABALZA-MEZGHANI Isabelle)
Date: Wed, 25 Feb 2004 10:01:41 +0100
Subject: [R] structure of mlm objects ?
Message-ID: <488C02265C6AD611BF200002A542182F05B5934B@irnts22.ifp.fr>

Hello,

I am using the function "lm" to fit several responses at the same time (100
responses). At the end of the fit, I get an object of class "mlm".
I would like to know if there is a way to access to each of the 100
underlying models separately (is it a list, ... ?). Which syntax should I
use to see and use the 15th model (for instance) just like it is possible
for classical "lm" objects.

Thanks in advance,

Isabelle Zabalza.



From sechet_b at yahoo.com  Wed Feb 25 10:58:25 2004
From: sechet_b at yahoo.com (=?iso-8859-1?Q?Beno=EEt_SECHET?=)
Date: Wed, 25 Feb 2004 10:58:25 +0100
Subject: [R] RExcel and statistical tests
Message-ID: <000701c3fb85$eccc9b00$0cf8fea9@equus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040225/36a4e4c5/attachment.pl

From ripley at stats.ox.ac.uk  Wed Feb 25 11:34:27 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 25 Feb 2004 10:34:27 +0000 (GMT)
Subject: [R] structure of mlm objects ?
In-Reply-To: <488C02265C6AD611BF200002A542182F05B5934B@irnts22.ifp.fr>
Message-ID: <Pine.LNX.4.44.0402251026090.7367-100000@gannet.stats>

On Wed, 25 Feb 2004, ZABALZA-MEZGHANI Isabelle wrote:

> I am using the function "lm" to fit several responses at the same time (100
> responses). At the end of the fit, I get an object of class "mlm".

Actually of class c("mlm", "lm").

> I would like to know if there is a way to access to each of the 100
> underlying models separately (is it a list, ... ?). Which syntax should I
> use to see and use the 15th model (for instance) just like it is possible
> for classical "lm" objects.

You don't have 100 underlying fits.  All the information is for one set 
of x's and 100 sets of y, and that relating only to x is stored only once.
The following simple function will extract the i'th fit.

mlm2lm <- function(fit, i)
{
    for(k in c("coefficients", "residuals", "effects", "fitted.values"))
        fit[[k]] <- fit[[k]][, i]
    class(fit) <- "lm"
    fit
}

albeit with the wrong call, so use carefully.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Torsten.Steuernagel at gmx.de  Wed Feb 25 11:43:34 2004
From: Torsten.Steuernagel at gmx.de (Torsten Steuernagel)
Date: Wed, 25 Feb 2004 11:43:34 +0100
Subject: [R] Inheriting from factors + co.
In-Reply-To: <403C6428.4060205@statistik.uni-dortmund.de>
References: <403BD165.17496.2E880922@localhost>
Message-ID: <403C8A66.17651.315AB4A7@localhost>

On 25 Feb 2004 at 10:00, Uwe Ligges wrote:

> So you are going to handle/mix the S4 class like/with S3 classes? Hmm.

Yes, and there is the problem. With S4 classes, it works. Now I would 
expect that is(factor(S3object, "ANY") will be FALSE for factor and any 
other S3 class, but is(S3object, "ANY") always gives TRUE.

> It can be either of class "myclass" or of class "factor". I'd define a
> separate explicit slot for such a class:

It is of class "myclass" but it should inherit from "factor" by the .Data 
part if I specify a factor. That's what it does with S4 classes:

my1 <- new("myclass", 1:10)
class(my1)			#  "myclass"
is.numeric(my1)		# TRUE

my2 <- new("myclass", "abc")
class(my2)			#  "myclass"
is.character(my2)		# TRUE

In those cases the object actually is a numeric or a character and thus 
can be treated accordingly.
 
>    setClass("myclass", representation(mainSlot = "ANY",
>        x = "numeric", y = "numeric"))

That works, of course. But that's not what I'm looking for. This requires 
using the slot explicitly (not impossible, but I'd really prefer to have it in 
the .Data part). One main drawback is that R just doesn't accept S3 
classes as .Data part:

setClass("myclass", representation("factor"))

It creates a new class (although a warning is issued) and also extends 
from "factor" but doesn't create the .Data slot. That's also the reason 
why my second approach with setClassUnion() doesn't work as soon as 
an S3 class is part of the union. I just don't understand why S3 classes 
in explicit slots work perfectly well whereas it seems impossible to have 
them in the .Data slot. 

Torsten



From angel_lul at hotmail.com  Wed Feb 25 11:58:20 2004
From: angel_lul at hotmail.com (Angel)
Date: Wed, 25 Feb 2004 11:58:20 +0100
Subject: [R] k nearest neighbours between two matrix
Message-ID: <Law11-OE56c7Rgj7FGt00013b85@hotmail.com>

I have two dataframes A and B consisting of latitude longitude coordinates
of points. For each point in A I want to find the k-nearest neighbours in B.
Currently, I calculate the distance from each point in A to all the points
in B (using rdist.earth() in fields package), sort the points of B by
distance and select the k nearest ones.
Is there a more efficient way to do this?
Function knearneigh {spdep} (using knn() of VR) does something similar but
for a matrix with itself and not with another matrix.
Is there a function that already does what I want and I could not find?
Thanks
Angel



From p.dalgaard at biostat.ku.dk  Wed Feb 25 11:59:42 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 25 Feb 2004 11:59:42 +0100
Subject: [R] Simulation help
In-Reply-To: <4038EA19.9020200@pdf.com>
References: <000c01c3f967$e1ab6640$4bc41644@undine> <4038EA19.9020200@pdf.com>
Message-ID: <x2znb7l90h.fsf@biostat.ku.dk>

Spencer Graves <spencer.graves at pdf.com> writes:

>       How about the following: > set.seed(5)
>  > N <- 8 # later 100000
>  > (nPois <- rpois(N, 2))
> [1] 1 3 4 1 0 3 2 3
>  > z <- rnorm(sum(nPois))

? 

I read the original request as simulating the sum of a
Poisson distributed number of Normals. So I'd suggest

 V <- replicate(100000,sum(rnorm(rpois(1,3))))

(Which is obviously a strange distribution since the sum may be empty)

Older versions of R, and Splus want

 V <- sapply(1:100000, function(i) sum(rnorm(rpois(1,3))))

>  > V <- tapply(z, rep(1:N, nPois), sum)
>  > quantile(V, c(0, .05, .25, .5, .75, .95, 1))
>         0%         5%        25%        50%        75%        95%
> 100%
> -2.7812799 -2.4600296 -1.5393631 -1.0803926  0.5800796  1.4626007
> 1.7114409
> 
>       The same code works in S-Plus 6.2 and R 1.8.1 under Windows
> 2000, though the answers different as S-Plus and R use different
> random number generators.     hope this helps.  spencer graves
> 
> jonathan_wang at sbcglobal.net wrote:
> 
> >I am a new R user.  As a test, I want to write a simple code that does the following simulation:
> >
> >1. Randomly generate a number from a distribution, say, Poisson.  Let's say that number is 3.
> >2. Randomly generate 3 numbers from another distribution, say, Normal.
> >3. Compute the sum of the numbers generated in step 2 and read it into a vector, V.
> >4. Repeat steps 1 through 3 for 100,000 times.
> >5. Derive quantiles (e.g., 0.95th, 0.99th) of V.
> >
> >Any help in getting me going would be greatly appreciated.
> >
> >	[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From pascal.dessaux at noos.fr  Wed Feb 25 13:02:45 2004
From: pascal.dessaux at noos.fr (pascal dessaux)
Date: Wed, 25 Feb 2004 13:02:45 +0100
Subject: [R] Pb with RODBC installation
Message-ID: <OEEGKALHOGJEPCDLIEDNOEGECBAA.pascal.dessaux@noos.fr>

Hello

I'm starting to use R on a Windows XP Pro machine which is not connected to
the internet;

I want to use database connection so I downloaded the file "RODBC_1.0-4.tar"
from CRAN;

this file is not accepted by the
"Packages->Install Packages from local zip file" menu function of R!!!

I would like to know why it doesn't work and if it's possible to get
database connection on a windows machine?

Thanks you very much for your help

Pascal



From H.RINNER at tirol.gv.at  Wed Feb 25 13:09:05 2004
From: H.RINNER at tirol.gv.at (RINNER Heinrich)
Date: Wed, 25 Feb 2004 13:09:05 +0100
Subject: [R] Pb with RODBC installation
Message-ID: <6A6B3B547E312840A98A9DD31516B3211804E0@mxs1.tirol.local>

You need the precompiled binaries of packages for that:

http://cran.at.r-project.org/bin/windows/contrib/1.8/RODBC_1.0-4.zip

-Heinrich.

> -----Urspr?ngliche Nachricht-----
> Von: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] Im Auftrag von 
> pascal dessaux
> Gesendet: Mittwoch, 25. Februar 2004 13:03
> An: r-help at stat.math.ethz.ch
> Betreff: [R] Pb with RODBC installation
> 
> 
> Hello
> 
> I'm starting to use R on a Windows XP Pro machine which is 
> not connected to
> the internet;
> 
> I want to use database connection so I downloaded the file 
> "RODBC_1.0-4.tar"
> from CRAN;
> 
> this file is not accepted by the
> "Packages->Install Packages from local zip file" menu function of R!!!
> 
> I would like to know why it doesn't work and if it's possible to get
> database connection on a windows machine?
> 
> Thanks you very much for your help
> 
> Pascal
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From petr.pikal at precheza.cz  Wed Feb 25 14:07:16 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 25 Feb 2004 14:07:16 +0100
Subject: [R] r: plots
In-Reply-To: <403B473F.EAF9A4E7@stats.uct.ac.za>
Message-ID: <403CAC14.4997.1640D3B@localhost>

Hallo

I use following function to produce graph of yright and yleft against x with 
additional options (like smoothing the lines, colour, line and point type choice and 
an options for some axes formating.


Cheers
Petr


#----------------------------------------------------------------------------------------------
# graf na 2 osach y

plot.yy<-function(x,yright,yleft, yleftlim=NULL, yrightlim = NULL, xlab = 
NULL ,yylab=c("",""),pch=c(1,2),col=c(1,2), linky=F, smooth=0, lwds=1, 
length=10, format="%d-%H:%M", ...)

{

par(mar=c(5,4,4,2),oma=c(0,0,0,3))
plot(x, yright, ylim=yrightlim, axes=F,ylab="", xlab=xlab, pch=pch[1],col=col[1], 
...)
axis(4,pretty(range(yright,na.rm=T),10),col=col[1])

if (linky) lines(x,yright,col=col[1], ...)

if (smooth!=0) lines(supsmu(x,yright,span=smooth),col=col[1], lwd=lwds, ...)

if(yylab[1]=="") 
mtext(deparse(substitute(yright)),side=4,outer=T,line=1, col=col[1], ...)
else 
mtext(yylab[1],side=4,outer=T,line=1, col=col[1], ...)

par(new=T)
plot(x,yleft, ylim=yleftlim, ylab="", axes=F ,xlab=xlab, pch=pch[2],col=col[2], ...)
box()
axis(2,pretty(range(yleft,na.rm=T),10),col=col[2], col.axis=col[2])

#if (is.null(class(x))) axis(1,pretty(range(x,na.rm=T),10)) else axis.POSIXct(1, x)

if (is.null(class(x))) axis(1,pretty(range(x,na.rm=T),10)) else 
{
l<-length(x)
axis(1,at=x[seq(1,l,length=length)],labels=format(as.POSIXct(x[seq(1,l,length=le
ngth)]),format=format))
}


#if (xDatum) 
axis(1,dates(pretty(range(datum,na.rm=T),10)),labels=as.character(chron(pretty(r
ange(datum,na.rm=T),10)),format=c("d/m/y")))
#else axis(1,pretty(range(x,na.rm=T),10))

if(yylab[2]=="")
mtext(deparse(substitute(yleft)),side=2,line=2, col=col[2], ...)
else
mtext(yylab[2],side=2,line=2, col=col[2], ...)


if (linky) lines(x,yleft,col=col[2], lty=2, ...)
if (smooth!=0) lines(supsmu(x,yleft,span=smooth),col=col[2], lty=2, lwd=lwds, 
...)

}


On 24 Feb 2004 at 14:44, allan clark wrote:

> hi all
> 
> i have another probably simple question.
> 
> I have three variables say x, y and z. x and y are quite large and z
> is relative small. how can one plot the three variables on the same
> graph with two separate axis? (one for x and y and the other for z)
> 
> e.g.
> x<-c(101,110,150,167,120)
> y<-c(120,135,175,95,200)
> z<-c(0.001, 0.15, 0.6, 0.8, 1)
> 
> regards
> Allan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From l.houdusse at cerep.fr  Wed Feb 25 14:49:55 2004
From: l.houdusse at cerep.fr (Laurent Houdusse)
Date: Wed, 25 Feb 2004 14:49:55 +0100
Subject: [R] simtest for Dunnett
Message-ID: <BA420EFAAC96D311A7A0006097D37BDB04515A70@EOLE>


Hi all

I use the function "simtest" for execute a Dunnett's test
See:

y<-c(6.5,1.60E+01,1.05E+01,6.7,1.78E+01,6.6,4.7,7.5,1.63E+01,4.2,1.15E+01,2.
79E+01,9,1.07E+01,3.00E+01,9.5,1.42E+01,1.40E+01,9.4,6.1,3.00E+01,8.4,3.00E+
01,3.00E+01,1.32E+01,3.00E+01,1.58E+01,3.00E+01,1.73E+01,1.51E+01,1.01E+01,6
.1,8,3.00E+01,2.20E+01,6.5,9,3.00E+01,1.36E+01,1.67E+01)
f1<- factor(c(rep("A", 10),rep("B", 10),rep("C", 10),rep("D", 10)))
m<-matrix(0,3,4)
m[1,1]<-1
m[2,2]<-1
m[3,4]<-1
m[1,3]<--1
m[2,3]<--1
m[3,3]<--1
result<-summary(simtest(y ~ f1,type="Dunnett",cmatrix=cbind(0,m)))

I retrieve result$p.value.adj as an array but how to know which groups are
compared by row
Because it seem that the array is ordered by result$estimate

Thanks

Laurent Houdusse 
Analyste Programmeur



From jcjorgensen at wisc.edu  Wed Feb 25 15:13:10 2004
From: jcjorgensen at wisc.edu (Jeff Jorgensen)
Date: Wed, 25 Feb 2004 08:13:10 -0600
Subject: [R] levelplot add line
In-Reply-To: <200402241851.48772.deepayan@stat.wisc.edu>
References: <5.2.1.1.2.20040224175530.02213810@wiscmail.wisc.edu>
	<5.2.1.1.2.20040224175530.02213810@wiscmail.wisc.edu>
Message-ID: <5.2.1.1.2.20040225075631.01eec910@wiscmail.wisc.edu>

Deepayan,

Thanks for the quick response.  Just to make sure I understand, let me 
explain in a bit more detail what I am trying to do.

I have created a levelplot (with contour lines and colored regions), and 
what I am trying to figure out now is how to add a series of horizontal 
lines across the levelplot and also assign values or labels to the lines on 
the alternative y-axis.  Would I do this with the route you suggest below?


Thanks so much for the help,

Jeff


At 06:51 PM 2/24/2004 -0600, you wrote:
>On Tuesday 24 February 2004 18:03, Jeff Jorgensen wrote:
> > R folks,
> >
> > I can't seem to find the instructions in the help files for the lattice
> > package that explain how to add lines, such as with lines() or ?, to a
> > levelplot.  I'd be grateful if someone could point me in the proper
> > direction.
>
>The general rule for all lattice functions is to write your own panel
>function. For example,
>
>data(volcano)
>levelplot(volcano,
>           panel = function(...) {
>               panel.levelplot(...)
>               panel.abline(c(0,1))
>           })
>
>lines() will not work for lattice, but you can use llines() instead.
>
>Of course, for anything more useful than this example, your panel function
>should make use of the data that's passed to the panel function. Exactly
>what would be passed depends on the function in question. For levelplot,
>the best place to look will be panel.levelplot, and similarly for other
>functions.
>
>Hth,
>
>Deepayan



From deepayan at stat.wisc.edu  Wed Feb 25 15:34:13 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 25 Feb 2004 08:34:13 -0600
Subject: [R] levelplot add line
In-Reply-To: <5.2.1.1.2.20040225075631.01eec910@wiscmail.wisc.edu>
References: <5.2.1.1.2.20040224175530.02213810@wiscmail.wisc.edu>
	<5.2.1.1.2.20040225075631.01eec910@wiscmail.wisc.edu>
Message-ID: <200402250834.13915.deepayan@stat.wisc.edu>

On Wednesday 25 February 2004 08:13, Jeff Jorgensen wrote:
> Deepayan,
>
> Thanks for the quick response.  Just to make sure I understand, let me
> explain in a bit more detail what I am trying to do.
>
> I have created a levelplot (with contour lines and colored regions), and
> what I am trying to figure out now is how to add a series of horizontal
> lines across the levelplot and also assign values or labels to the lines
> on the alternative y-axis.  Would I do this with the route you suggest
> below?

For adding the lines, yes. Take a look at ?panel.functions and ?llines.

I'm not sure what you mean by 'assign values or labels to the lines on the 
alternative y-axis'. As a general rule, panel regions are 'clipped', i.e., 
any attempt by the panel function to draw outside the panel has no effect. 
This can be overridden by with lset(list(clip = list(panel = FALSE))), but 
I wouldn't recommend using it unless you know what you are doing.

Deepayan



From patrick.giraudoux at univ-fcomte.fr  Wed Feb 25 16:32:06 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Wed, 25 Feb 2004 16:32:06 +0100
Subject: [R] writing polygons/segments to shapefiles (.shp) or other ArCGIS
	compatible file
Message-ID: <002001c3fbb4$885e1ca0$e5653351@PC728329681112>

I am not sure a previous e-mail reached the list (no mail aknowledgement from R-boundle etc.). The question was how to write polygon
or segment coordinates into a shapefile set or any other ArcGIS supported format. The library shapefiles seems to do something but
the documentation is a bit beyond of my mind.... and I cannot get the meaning of the functions write**** and its application to the
case below:

In simple words, is there a somewhere a function taking polygon coordinates (or simple segments) within R to a "ready to read" set
of files ***.shp, ***.shx, etc...

Thanks in advance for any hint

Patrick



----- Original Message ----- 
From: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
To: "r-help" <r-help at stat.math.ethz.ch>
Sent: Wednesday, February 25, 2004 1:08 PM
Subject: writing polygons/segments to shapefiles (.shp)


> Dear all,
>
> The library maptools offers a fantastic support for shapefile reading.
>
> Is there a R library available permitting the writing of polygon or segment coordinates into shapefile?
>
> Thanks for any hint,
>
> Patrick Giraudoux
>
>
>
>



From edwardweisun at hotmail.com  Wed Feb 25 16:40:30 2004
From: edwardweisun at hotmail.com (Edward Sun)
Date: Wed, 25 Feb 2004 16:40:30 +0100
Subject: [R] help for MLE
Message-ID: <BAY14-F63hZYNX6Mma0000126ab@hotmail.com>

Hi,
when I write the likelihood function as

>fn<-function(x) -50*log(2*pi)-100*log(sigma)-(1/2*(sum((x-mu)/sigma)^2))

then what should I do since it shows that Error in log(sigma) : Object 
"sigma" not found.

Thanks
edward




>
> > From: Edward Sun
> >
> > Dear Sir/Madam,
> >
> > I am using R version 1.8.1. I am doing following tast:
> >
> > First generate 100 Gaussion(3,1) numbers, then write the
> > likelihood function
> > to estimate the parameters of Gaussian distribution by direct
> > maximizing the
> > likelihood function.
> >
> > My likelihood function is:
> > >fn<-function(x)
> > >(-50*log((sd(x))^2))-50*log(sqrt(2*pi))-(1/2*((mean(x))^2))*(
> > sum((x-(mean(x))^2))
> >
> > After I input above function, the '' >'' turned to be '' +
> > ''. and it did
> > not work.
> >
> > I am looking for the help to solve this tast by writting a likelihood
> > function.
> >
> > Thanks a lot.
> >
> > Best regards.
> > edward sun
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments, contains
>information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New
>Jersey, USA 08889), and/or its affiliates (which may be known outside the
>United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan as
>Banyu) that may be confidential, proprietary copyrighted and/or legally
>privileged. It is intended solely for the use of the individual or entity
>named on this message.  If you are not the intended recipient, and have
>received this message in error, please notify us immediately by reply 
>e-mail
>and then delete it from your system.
>------------------------------------------------------------------------------



From tblackw at umich.edu  Wed Feb 25 16:54:56 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Wed, 25 Feb 2004 10:54:56 -0500 (EST)
Subject: [R] help for MLE
In-Reply-To: <BAY14-F63hZYNX6Mma0000126ab@hotmail.com>
References: <BAY14-F63hZYNX6Mma0000126ab@hotmail.com>
Message-ID: <Pine.SOL.4.58.0402251052340.3752@asteroids.gpcc.itd.umich.edu>

Edward  -

Either  optim()  or  fitdistr()  has an additional required
argument which specifies the names (and incidentally starting
values) for the parameters to be estimated.  Did you supply
that argument ?  See  help("optim"), help("fitdistr").

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 25 Feb 2004, Edward Sun wrote:

> Hi,
> when I write the likelihood function as
>
> >fn<-function(x) -50*log(2*pi)-100*log(sigma)-(1/2*(sum((x-mu)/sigma)^2))
>
> then what should I do since it shows that Error in log(sigma) : Object
> "sigma" not found.
>
> Thanks
> edward
>
>
>
>
> >
> > > From: Edward Sun
> > >
> > > Dear Sir/Madam,
> > >
> > > I am using R version 1.8.1. I am doing following tast:
> > >
> > > First generate 100 Gaussion(3,1) numbers, then write the
> > > likelihood function
> > > to estimate the parameters of Gaussian distribution by direct
> > > maximizing the
> > > likelihood function.
> > >
> > > My likelihood function is:
> > > >fn<-function(x)
> > > >(-50*log((sd(x))^2))-50*log(sqrt(2*pi))-(1/2*((mean(x))^2))*(
> > > sum((x-(mean(x))^2))
> > >
> > > After I input above function, the '' >'' turned to be '' +
> > > ''. and it did
> > > not work.
> > >
> > > I am looking for the help to solve this tast by writting a likelihood
> > > function.
> > >
> > > Thanks a lot.
> > >
> > > Best regards.
> > > edward sun
> >
> >
> >------------------------------------------------------------------------------
> >Notice:  This e-mail message, together with any attachments, contains
> >information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New
> >Jersey, USA 08889), and/or its affiliates (which may be known outside the
> >United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan as
> >Banyu) that may be confidential, proprietary copyrighted and/or legally
> >privileged. It is intended solely for the use of the individual or entity
> >named on this message.  If you are not the intended recipient, and have
> >received this message in error, please notify us immediately by reply
> >e-mail
> >and then delete it from your system.
> >------------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Wed Feb 25 17:00:40 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 25 Feb 2004 08:00:40 -0800
Subject: [R] help for MLE
In-Reply-To: <BAY14-F63hZYNX6Mma0000126ab@hotmail.com>
References: <BAY14-F63hZYNX6Mma0000126ab@hotmail.com>
Message-ID: <403CC6A8.60004@pdf.com>

      Have you worked through the "posting guide" at the end of each 
r-help email?  In particular, have you worked the examples in 
"help('fitdistr')" in library MASS and "optim"? 

      hope this helps.  spencer graves

Edward Sun wrote:

> Hi,
> when I write the likelihood function as
>
>> fn<-function(x) -50*log(2*pi)-100*log(sigma)-(1/2*(sum((x-mu)/sigma)^2))
>
>
> then what should I do since it shows that Error in log(sigma) : Object 
> "sigma" not found.
>
> Thanks
> edward
>
>
>
>
>>
>> > From: Edward Sun
>> >
>> > Dear Sir/Madam,
>> >
>> > I am using R version 1.8.1. I am doing following tast:
>> >
>> > First generate 100 Gaussion(3,1) numbers, then write the
>> > likelihood function
>> > to estimate the parameters of Gaussian distribution by direct
>> > maximizing the
>> > likelihood function.
>> >
>> > My likelihood function is:
>> > >fn<-function(x)
>> > >(-50*log((sd(x))^2))-50*log(sqrt(2*pi))-(1/2*((mean(x))^2))*(
>> > sum((x-(mean(x))^2))
>> >
>> > After I input above function, the '' >'' turned to be '' +
>> > ''. and it did
>> > not work.
>> >
>> > I am looking for the help to solve this tast by writting a likelihood
>> > function.
>> >
>> > Thanks a lot.
>> >
>> > Best regards.
>> > edward sun
>>
>>
>> ------------------------------------------------------------------------------ 
>>
>> Notice:  This e-mail message, together with any attachments, contains
>> information of Merck & Co., Inc. (One Merck Drive, Whitehouse 
>> Station, New
>> Jersey, USA 08889), and/or its affiliates (which may be known outside 
>> the
>> United States as Merck Frosst, Merck Sharp & Dohme or MSD and in 
>> Japan as
>> Banyu) that may be confidential, proprietary copyrighted and/or legally
>> privileged. It is intended solely for the use of the individual or 
>> entity
>> named on this message.  If you are not the intended recipient, and have
>> received this message in error, please notify us immediately by reply 
>> e-mail
>> and then delete it from your system.
>> ------------------------------------------------------------------------------ 
>>
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From dray at biomserv.univ-lyon1.fr  Wed Feb 25 17:15:42 2004
From: dray at biomserv.univ-lyon1.fr (Stephane DRAY)
Date: Wed, 25 Feb 2004 11:15:42 -0500
Subject: [R] writing polygons/segments to shapefiles (.shp) or
	other ArCGIS compatible file
In-Reply-To: <002001c3fbb4$885e1ca0$e5653351@PC728329681112>
Message-ID: <5.2.1.1.0.20040225111517.00b69e28@biomserv.univ-lyon1.fr>

I think It could not be done for the moment .. Perhaps, I am wrong !

In the package maptools, there is  read.shape shape2poly, shape2line... 
These functions allow to read shapefiles files but not to write it.
With the shapefiles package you can write shape object to files. I think 
that one solution is to write poly2shape, lines2shape,....or perhaps a more 
general write.Maps (to save Maps in GIS file format).
Another and provisory solution exist. I have write an arcview 3.x extension 
(AVADE) to allow the interface between Arc-View and ADE-4 software. You can 
download the extension at www.steph280.freesurf.fr. If you have a poly object,
you can convert it to an area object (poly2area in the ade4 library)
save the area object within a file with write.table
and convert this text file to a shapefile with the AVADE extension in Arcview.

Hope this helps,


At 10:32 25/02/2004, Patrick Giraudoux wrote:
>I am not sure a previous e-mail reached the list (no mail aknowledgement 
>from R-boundle etc.). The question was how to write polygon
>or segment coordinates into a shapefile set or any other ArcGIS supported 
>format. The library shapefiles seems to do something but
>the documentation is a bit beyond of my mind.... and I cannot get the 
>meaning of the functions write**** and its application to the
>case below:
>
>In simple words, is there a somewhere a function taking polygon 
>coordinates (or simple segments) within R to a "ready to read" set
>of files ***.shp, ***.shx, etc...
>
>Thanks in advance for any hint
>
>Patrick
>
>
>
>----- Original Message -----
>From: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
>To: "r-help" <r-help at stat.math.ethz.ch>
>Sent: Wednesday, February 25, 2004 1:08 PM
>Subject: writing polygons/segments to shapefiles (.shp)
>
>
> > Dear all,
> >
> > The library maptools offers a fantastic support for shapefile reading.
> >
> > Is there a R library available permitting the writing of polygon or 
> segment coordinates into shapefile?
> >
> > Thanks for any hint,
> >
> > Patrick Giraudoux
> >
> >
> >
> >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

St?phane DRAY
-------------------------------------------------------------------------------------------------- 

D?partement des Sciences Biologiques
Universit? de Montr?al, C.P. 6128, succursale centre-ville
Montr?al, Qu?bec H3C 3J7, Canada

Tel : 514 343 6111 poste 1233
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From andy_liaw at merck.com  Wed Feb 25 17:27:16 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 25 Feb 2004 11:27:16 -0500
Subject: [R] help for MLE
Message-ID: <3A822319EB35174CA3714066D590DCD504AF786F@usrymx25.merck.com>

Do:

library(mle)
?mle

and read the documentation and the example.  That should get you on the
right track.

Andy


> From: Edward Sun
> 
> Hi,
> when I write the likelihood function as
> 
> >fn<-function(x) 
> -50*log(2*pi)-100*log(sigma)-(1/2*(sum((x-mu)/sigma)^2))
> 
> then what should I do since it shows that Error in log(sigma) 
> : Object 
> "sigma" not found.
> 
> Thanks
> edward
> 
> 
> 
> 
> >
> > > From: Edward Sun
> > >
> > > Dear Sir/Madam,
> > >
> > > I am using R version 1.8.1. I am doing following tast:
> > >
> > > First generate 100 Gaussion(3,1) numbers, then write the
> > > likelihood function
> > > to estimate the parameters of Gaussian distribution by direct
> > > maximizing the
> > > likelihood function.
> > >
> > > My likelihood function is:
> > > >fn<-function(x)
> > > >(-50*log((sd(x))^2))-50*log(sqrt(2*pi))-(1/2*((mean(x))^2))*(
> > > sum((x-(mean(x))^2))
> > >
> > > After I input above function, the '' >'' turned to be '' +
> > > ''. and it did
> > > not work.
> > >
> > > I am looking for the help to solve this tast by writting 
> a likelihood
> > > function.
> > >
> > > Thanks a lot.
> > >
> > > Best regards.
> > > edward sun
> >
> >
> >-------------------------------------------------------------
> -----------------
> >Notice:  This e-mail message, together with any attachments, contains
> >information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New
> >Jersey, USA 08889), and/or its affiliates (which may be 
> known outside the
> >United States as Merck Frosst, Merck Sharp & Dohme or MSD 
> and in Japan as
> >Banyu) that may be confidential, proprietary copyrighted 
> and/or legally
> >privileged. It is intended solely for the use of the 
> individual or entity
> >named on this message.  If you are not the intended 
> recipient, and have
> >received this message in error, please notify us immediately 
> by reply 
> >e-mail
> >and then delete it from your system.
> >-------------------------------------------------------------
> -----------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From dray at biomserv.univ-lyon1.fr  Wed Feb 25 17:35:55 2004
From: dray at biomserv.univ-lyon1.fr (Stephane DRAY)
Date: Wed, 25 Feb 2004 11:35:55 -0500
Subject: [R] writing polygons/segments to shapefiles (.shp) or
	other ArCGIS compatible file
In-Reply-To: <002001c3fbb4$885e1ca0$e5653351@PC728329681112>
Message-ID: <5.2.1.1.0.20040225113256.03b0d970@biomserv.univ-lyon1.fr>

There is a little problem with the approach I described in my previous email.
In ADE-4, coordinates are given in pixel and so Y are inverted. You must 
invert your Y coordinates to obtain the good representation in ArcView. An 
example:

 > library(ade4)
 > library(shapefiles)
 > library(maptools)
 > try1 <- read.shapefile(paste(ShapeDir, "columbus", sep="/"))
 > shppolys <- shape2poly(try1, as.character(try1$dbf$dbf$NEIGNO))
 > obj=poly2area(shppolys)
 > obj[,3]=-obj[,3]
 > write.table(obj,"try.area",col.names=F,quote=F,row.names=F)
 >

Then, use the 'From AREA' function in AVADE.



At 10:32 25/02/2004, Patrick Giraudoux wrote:
>I am not sure a previous e-mail reached the list (no mail aknowledgement 
>from R-boundle etc.). The question was how to write polygon
>or segment coordinates into a shapefile set or any other ArcGIS supported 
>format. The library shapefiles seems to do something but
>the documentation is a bit beyond of my mind.... and I cannot get the 
>meaning of the functions write**** and its application to the
>case below:
>
>In simple words, is there a somewhere a function taking polygon 
>coordinates (or simple segments) within R to a "ready to read" set
>of files ***.shp, ***.shx, etc...
>
>Thanks in advance for any hint
>
>Patrick
>
>
>
>----- Original Message -----
>From: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
>To: "r-help" <r-help at stat.math.ethz.ch>
>Sent: Wednesday, February 25, 2004 1:08 PM
>Subject: writing polygons/segments to shapefiles (.shp)
>
>
> > Dear all,
> >
> > The library maptools offers a fantastic support for shapefile reading.
> >
> > Is there a R library available permitting the writing of polygon or 
> segment coordinates into shapefile?
> >
> > Thanks for any hint,
> >
> > Patrick Giraudoux
> >
> >
> >
> >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

St?phane DRAY
-------------------------------------------------------------------------------------------------- 

D?partement des Sciences Biologiques
Universit? de Montr?al, C.P. 6128, succursale centre-ville
Montr?al, Qu?bec H3C 3J7, Canada

Tel : 514 343 6111 poste 1233
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From rbaer at atsu.edu  Wed Feb 25 18:00:21 2004
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Wed, 25 Feb 2004 11:00:21 -0600
Subject: [R] read.spss defaults
Message-ID: <003f01c3fbc0$daa75d80$2e80010a@BigBaer>

The read.spss parameter defaults are:
   use.value.labels=TRUE,
   to.data.frame=FALSE,

Is there some reasoning other than historical for this choice?  In most
instances, it seems that the opposite default choice
(use.value.labels=FALSE, to.data.frame=TRUE,) would better preserve any
existing structure of the underlying SPSS dataset as it is imported in to R.
I feel especially strongly about the to.data.frame=TRUE being the desirable
default given the central role of data frames in R.

Of course, I guess a user could always write a wrapper function, but the
instances where you wouldn't find the wrapper function useful seem minimal..

Any insights?

Rob Baer



From jonathan_wang at sbcglobal.net  Wed Feb 25 18:33:57 2004
From: jonathan_wang at sbcglobal.net (Jonathan Wang)
Date: Wed, 25 Feb 2004 09:33:57 -0800 (PST)
Subject: [R] PWM Help
Message-ID: <20040225173357.99027.qmail@web80606.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040225/3cc13ea6/attachment.pl

From tlumley at u.washington.edu  Wed Feb 25 19:09:37 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 25 Feb 2004 10:09:37 -0800 (PST)
Subject: [R] read.spss defaults
In-Reply-To: <003f01c3fbc0$daa75d80$2e80010a@BigBaer>
References: <003f01c3fbc0$daa75d80$2e80010a@BigBaer>
Message-ID: <Pine.A41.4.58.0402251008190.32606@homer01.u.washington.edu>

On Wed, 25 Feb 2004, Robert W. Baer, Ph.D. wrote:

> The read.spss parameter defaults are:
>    use.value.labels=TRUE,
>    to.data.frame=FALSE,
>
> Is there some reasoning other than historical for this choice?  In most
> instances, it seems that the opposite default choice
> (use.value.labels=FALSE, to.data.frame=TRUE,) would better preserve any
> existing structure of the underlying SPSS dataset as it is imported in to R.
> I feel especially strongly about the to.data.frame=TRUE being the desirable
> default given the central role of data frames in R.
>

I think the reason for to.data.frame=FALSE is that for a large dataset the
conversion to data frame takes a lot longer than the reading.

In particular, if you want to use just a subset of variables it will be
quicker to subset before you construct the data frame.


	-thomas



From tlumley at u.washington.edu  Wed Feb 25 19:10:57 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 25 Feb 2004 10:10:57 -0800 (PST)
Subject: [R] PWM Help
In-Reply-To: <20040225173357.99027.qmail@web80606.mail.yahoo.com>
References: <20040225173357.99027.qmail@web80606.mail.yahoo.com>
Message-ID: <Pine.A41.4.58.0402251009450.32606@homer01.u.washington.edu>

On Wed, 25 Feb 2004, Jonathan Wang wrote:

> I saw a Help e-mail related to MLE.  Does R have a probability weighted
> method (PWM) estimator function?  I can't seem to find anything on PWM,
> unless my eyes are playing trick on me.
>

The survey package has a function for maximising inverse-probability
weighted likelihoods.  This isn't (typically) a maximum likelihood
procedure, though.


	-thomas



From sheth at economics.rutgers.edu  Wed Feb 25 19:16:47 2004
From: sheth at economics.rutgers.edu (Arnav Sheth)
Date: Wed, 25 Feb 2004 13:16:47 -0500
Subject: [R] Computing very large distance matrix
Message-ID: <002201c3fbcb$8837b170$722617ac@arnav>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040225/71bb1fb1/attachment.pl

From tblackw at umich.edu  Wed Feb 25 19:48:00 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Wed, 25 Feb 2004 13:48:00 -0500 (EST)
Subject: [R] Computing very large distance matrix
In-Reply-To: <002201c3fbcb$8837b170$722617ac@arnav>
References: <002201c3fbcb$8837b170$722617ac@arnav>
Message-ID: <Pine.SOL.4.58.0402251342520.22082@asteroids.gpcc.itd.umich.edu>

Arnav  -

A suggestion I have made in the past is to run Chris Fraley
and Adrian Raftery's  mclust()  procedure instead of Rousseuw's
agnes(), if you are willing to use a different clustering method.

The pdf instruction manual for the mclust package includes
explicit suggestions for how to use mclust with large data sets.
Naive attempts are guaranteed to fail, so DO read the manual.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 25 Feb 2004, Arnav Sheth wrote:

>
> Hello All,
>
> I have a 131072x132 matrix for which I need to compute a regular euclidean distance matrix, which I then need to transform and run agnes() on this transformed matrix. I am having trouble computing the distance matrix as it is fairly large and I am sure I have gone over the max.
>
> The specific error I am getting is:
> Error in vector("double", length) : negative length vectors are not allowed
>
> I have increased the memory limit to the maximum capacity of my hard drive (which is around 20gb), with no success.
>
> I am running the RGUI on Windows XP with 512 mb of RAM.
>
> Would anyone have any suggestions as to how I can overcome this problem? I would be most grateful for any help.
>
> Thanks,
> Arnav
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Wed Feb 25 19:51:58 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 25 Feb 2004 13:51:58 -0500
Subject: [R] Computing very large distance matrix
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7875@usrymx25.merck.com>

If that's 131072 points, not 132 points, the memory needed to store that is:

> 131072^2 * 8 / 1024^3
[1] 128

That's in gigabytes.  When you have a Windows machine that has at least that
much memory, you can try to do that.  Before then, try something else.

Andy

> From: Arnav Sheth
> 
> 
> Hello All,
> 
> I have a 131072x132 matrix for which I need to compute a 
> regular euclidean distance matrix, which I then need to 
> transform and run agnes() on this transformed matrix. I am 
> having trouble computing the distance matrix as it is fairly 
> large and I am sure I have gone over the max. 
> 
> The specific error I am getting is:
> Error in vector("double", length) : negative length vectors 
> are not allowed
> 
> I have increased the memory limit to the maximum capacity of 
> my hard drive (which is around 20gb), with no success. 
> 
> I am running the RGUI on Windows XP with 512 mb of RAM.
> 
> Would anyone have any suggestions as to how I can overcome 
> this problem? I would be most grateful for any help.
> 
> Thanks,
> Arnav
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ripley at stats.ox.ac.uk  Wed Feb 25 20:12:25 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 25 Feb 2004 19:12:25 +0000 (GMT)
Subject: [R] Computing very large distance matrix
In-Reply-To: <002201c3fbcb$8837b170$722617ac@arnav>
Message-ID: <Pine.LNX.4.44.0402251910070.9635-100000@gannet.stats>

On Wed, 25 Feb 2004, Arnav Sheth wrote:

> 
> Hello All,
> 
> I have a 131072x132 matrix for which I need to compute a regular euclidean distance matrix, which I then need to transform and run agnes() on this transformed matrix. I am having trouble computing the distance matrix as it is fairly large and I am sure I have gone over the max. 
> 
> The specific error I am getting is:
> Error in vector("double", length) : negative length vectors are not allowed

We've improved that message for the next release.

> I have increased the memory limit to the maximum capacity of my hard
> drive (which is around 20gb), with no success.

You'd need to increase the 32-bit limit of Windows, too ....

> I am running the RGUI on Windows XP with 512 mb of RAM.
> 
> Would anyone have any suggestions as to how I can overcome this problem?
> I would be most grateful for any help.

No. The distance matrix is 8Gb all by itself.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From patrick.giraudoux at univ-fcomte.fr  Wed Feb 25 20:20:09 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Wed, 25 Feb 2004 20:20:09 +0100
Subject: [R] writing polygons/segments to shapefiles (.shp) or other
	ArCGIS compatible file
References: <5.2.1.1.0.20040225113256.03b0d970@biomserv.univ-lyon1.fr>
Message-ID: <004301c3fbd4$6a931b10$e6eafb51@PC728329681112>

Thanks a lot for the hints. I will try.  Actually I was focusing (in a first stage) on simple segments (small mammal traplines...).
I turned the problem out writing some lines to export the coordinates into a "simple" GRASS ascii file, imported it into GRASS as
vector file and then used the export tool to get  shapefiles...  Not that direct: needs to have GRASS installed and an elementary
knowledge on the export/import commands in this open source GIS.

It would be fantastic to have the reverse functions of Map2poly(Map), Map2lines(Map), Map2points(Map) read.shape (eg poly2map,
lines2map, points2map, and write.map) to write shapefiles.... I must however admit that I don't know enough about shapefile formats
and R programming to do this by myself... and I would unfortunately be really out of my current job in the university...


----- Original Message ----- 
From: "Stephane DRAY" <dray at biomserv.univ-lyon1.fr>
To: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>; "r-help" <r-help at stat.math.ethz.ch>
Sent: Wednesday, February 25, 2004 5:35 PM
Subject: Re: [R] writing polygons/segments to shapefiles (.shp) or other ArCGIS compatible file


> There is a little problem with the approach I described in my previous email.
> In ADE-4, coordinates are given in pixel and so Y are inverted. You must
> invert your Y coordinates to obtain the good representation in ArcView. An
> example:
>
>  > library(ade4)
>  > library(shapefiles)
>  > library(maptools)
>  > try1 <- read.shapefile(paste(ShapeDir, "columbus", sep="/"))
>  > shppolys <- shape2poly(try1, as.character(try1$dbf$dbf$NEIGNO))
>  > obj=poly2area(shppolys)
>  > obj[,3]=-obj[,3]
>  > write.table(obj,"try.area",col.names=F,quote=F,row.names=F)
>  >
>
> Then, use the 'From AREA' function in AVADE.
>
>
>
> At 10:32 25/02/2004, Patrick Giraudoux wrote:
> >I am not sure a previous e-mail reached the list (no mail aknowledgement
> >from R-boundle etc.). The question was how to write polygon
> >or segment coordinates into a shapefile set or any other ArcGIS supported
> >format. The library shapefiles seems to do something but
> >the documentation is a bit beyond of my mind.... and I cannot get the
> >meaning of the functions write**** and its application to the
> >case below:
> >
> >In simple words, is there a somewhere a function taking polygon
> >coordinates (or simple segments) within R to a "ready to read" set
> >of files ***.shp, ***.shx, etc...
> >
> >Thanks in advance for any hint
> >
> >Patrick
> >
> >
> >
> >----- Original Message -----
> >From: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
> >To: "r-help" <r-help at stat.math.ethz.ch>
> >Sent: Wednesday, February 25, 2004 1:08 PM
> >Subject: writing polygons/segments to shapefiles (.shp)
> >
> >
> > > Dear all,
> > >
> > > The library maptools offers a fantastic support for shapefile reading.
> > >
> > > Is there a R library available permitting the writing of polygon or
> > segment coordinates into shapefile?
> > >
> > > Thanks for any hint,
> > >
> > > Patrick Giraudoux
> > >
> > >
> > >
> > >
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> St?phane DRAY
> -------------------------------------------------------------------------------------------------- 
>
> D?partement des Sciences Biologiques
> Universit? de Montr?al, C.P. 6128, succursale centre-ville
> Montr?al, Qu?bec H3C 3J7, Canada
>
> Tel : 514 343 6111 poste 1233
> E-mail : stephane.dray at umontreal.ca
> -------------------------------------------------------------------------------------------------- 
>
> Web                                          http://www.steph280.freesurf.fr/
> -------------------------------------------------------------------------------------------------- 
>
>



From jcjorgensen at wisc.edu  Wed Feb 25 21:00:37 2004
From: jcjorgensen at wisc.edu (Jeff Jorgensen)
Date: Wed, 25 Feb 2004 14:00:37 -0600
Subject: [R] levelplot add line
In-Reply-To: <200402250834.13915.deepayan@stat.wisc.edu>
References: <5.2.1.1.2.20040225075631.01eec910@wiscmail.wisc.edu>
	<5.2.1.1.2.20040224175530.02213810@wiscmail.wisc.edu>
	<5.2.1.1.2.20040225075631.01eec910@wiscmail.wisc.edu>
Message-ID: <5.2.1.1.2.20040225115041.02010558@wiscmail.wisc.edu>

Thanks for putting me on the right track.  Sorry to be bothersome with 
another follow-up, but the code that calls the panel function (see below) 
doesn't seem to be working.  What am I doing wrong?

Thanks,

Jeff

levelplot(matrix,contour=T, cuts=15,at=seq(...), labels=T, region=T,
                             scales=list(x=list(at=xlocations,labels=as.character(xlabels)),
                                         y=list(at=ylocations, 
labels=as.character(ylabels))),
                             xlim=c(1:368), ylim=c(1:31),
                             colorkey = list(space = "bottom",
                                             labels = list(at = 
seq(0,2000,200),
                                             lab = seq(0,2000,200))), #If I 
cut it off here, it works fine
         panel=function(x,y,z){
                             panel.levelplot(x=c(...), y=c(...), z=matrix,
                             cuts=15,at=seq(...), contour=T, labels=T,
                             region=T,
                             subscripts=seq(...),
                             col.regions=cm.colors(100),
                             zcol=c(1:100),
                             panel.abline(h=200))
             })



At 08:34 AM 2/25/2004 -0600, you wrote:
>On Wednesday 25 February 2004 08:13, Jeff Jorgensen wrote:
> > Deepayan,
> >
> > Thanks for the quick response.  Just to make sure I understand, let me
> > explain in a bit more detail what I am trying to do.
> >
> > I have created a levelplot (with contour lines and colored regions), and
> > what I am trying to figure out now is how to add a series of horizontal
> > lines across the levelplot and also assign values or labels to the lines
> > on the alternative y-axis.  Would I do this with the route you suggest
> > below?
>
>For adding the lines, yes. Take a look at ?panel.functions and ?llines.
>
>I'm not sure what you mean by 'assign values or labels to the lines on the
>alternative y-axis'. As a general rule, panel regions are 'clipped', i.e.,
>any attempt by the panel function to draw outside the panel has no effect.
>This can be overridden by with lset(list(clip = list(panel = FALSE))), but
>I wouldn't recommend using it unless you know what you are doing.
>
>Deepayan



From David.Verbel at aureon.com  Wed Feb 25 21:06:20 2004
From: David.Verbel at aureon.com (David Verbel)
Date: Wed, 25 Feb 2004 15:06:20 -0500
Subject: [R] LOOCV using R
Message-ID: <02B94838FFDA8D428EE14254678C0D0F2578D5@aureon-ex01.universe.aureon.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040225/83d419bd/attachment.pl

From andy_liaw at merck.com  Wed Feb 25 21:21:20 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 25 Feb 2004 15:21:20 -0500
Subject: [R] LOOCV using R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7877@usrymx25.merck.com>

You can try and see if the errorest function in the `ipred' package can do
the job.

HTH,
Andy

> From: David Verbel
> 
> Can someone help me with performing leave-out-one cross 
> validation using
> R (model built is a Cox model)?  Thanks.
> 
>  
> 
> ---------------------------------------------
> 
> David Verbel, MPH
> 
> Senior Biostatistician
> 
> Aureon Biosciences
> 
> 28 Wells Avenue
> 
> Yonkers, NY 10701
> 
> Phone: (914) 377-4021
> 
> Fax: (914) 377-4001
> 
> ---------------------------------------------
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From vograno at evafunds.com  Wed Feb 25 21:42:13 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed, 25 Feb 2004 12:42:13 -0800
Subject: [R] books: "Programming with Data: A Guide to the S Language" vs."
	S Programming"
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A50C3A73@phost015.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040225/20316465/attachment.pl

From tblackw at umich.edu  Wed Feb 25 21:44:07 2004
From: tblackw at umich.edu (Tom Blackwell)
Date: Wed, 25 Feb 2004 15:44:07 -0500 (EST)
Subject: [R] LOOCV using R
In-Reply-To: <02B94838FFDA8D428EE14254678C0D0F2578D5@aureon-ex01.universe.aureon.com>
References: <02B94838FFDA8D428EE14254678C0D0F2578D5@aureon-ex01.universe.aureon.com>
Message-ID: <Pine.SOL.4.58.0402251541500.22082@asteroids.gpcc.itd.umich.edu>


library("survival")
library("boot")
help("coxph")
help("boot")

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 25 Feb 2004, David Verbel wrote:

> Can someone help me with performing leave-out-one cross validation using
> R (model built is a Cox model)?  Thanks.
>
>
>
> ---------------------------------------------
>
> David Verbel, MPH
>
> Senior Biostatistician
>
> Aureon Biosciences
>
> 28 Wells Avenue
>
> Yonkers, NY 10701
>
> Phone: (914) 377-4021
>
> Fax: (914) 377-4001
>
> ---------------------------------------------
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at myway.com  Wed Feb 25 23:34:26 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 25 Feb 2004 17:34:26 -0500 (EST)
Subject: [R] books: 
Message-ID: <20040225223426.5553139C1@mprdmxin.myway.com>



Not precisely an answer to your question but here are some
OO R links that I have collected over time.  Not sure if 
all these links still work.

<a href="http://www.stat.wisc.edu/~st771-1/slides/wk2-4.pdf">Bates</a> | 

<a href="http://www.maths.lth.se/help/R/">Bengtsson</a> | 

<a href="http://cm.bell-labs.com/cm/ms/departments/sia/Sbook/">Chambers</a> | 

<a href="http://biosun1.harvard.edu/courses/individual/bio271/">Gentleman</a>
 | 

<a href="http://faculty.washington.edu/tlumley/Rcourse/objects.pdf">Lumley</a> | 

<a href="http://maths.newcastle.edu.au/~rking/R/devel/03a/0969.html">Symth</a>

---
Date:   Wed, 25 Feb 2004 12:42:13 -0800 
From:   Vadim Ogranovich <vograno at evafunds.com>
To:   R Help List <r-help at stat.math.ethz.ch> 
Subject:   [R] books: "Programming with Data: A Guide to the S Language" vs." S Programming" 

 
Hi,

Could someone please compare "Programming with Data: A Guide to the S
Language" by J. Chambers and " S Programming" by W. Venables and B.
Ripley? Ideally, I need a "guide" for writing R OO-style packages that
intensively interact with C/C++ libraries.

The specific project I have in mind is to write a thin and limited
DB-connectivity package that would interact with Oracle via its OCCI
interface (it's an intention subject to time availability and project
complexity). If you've been there or somehow think this is a daunting
task I'd love to hear from you.

Thanks,
Vadim



From lixian7001 at yahoo.com  Thu Feb 26 00:11:48 2004
From: lixian7001 at yahoo.com (li xian)
Date: Wed, 25 Feb 2004 15:11:48 -0800 (PST)
Subject: [R] distinct random number 
Message-ID: <20040225231148.64564.qmail@web11508.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040225/c36cf104/attachment.pl

From sundar.dorai-raj at pdf.com  Thu Feb 26 00:18:30 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 25 Feb 2004 17:18:30 -0600
Subject: [R] distinct random number
In-Reply-To: <20040225231148.64564.qmail@web11508.mail.yahoo.com>
References: <20040225231148.64564.qmail@web11508.mail.yahoo.com>
Message-ID: <403D2D46.9070707@pdf.com>

?sample

sample(0:m, n)

-sd

li xian wrote:

> How to express n distinct numbers between 0 and m? ( In R )
> Thanks!
> 
> 
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sheth at economics.rutgers.edu  Thu Feb 26 01:22:08 2004
From: sheth at economics.rutgers.edu (Arnav Sheth)
Date: Wed, 25 Feb 2004 19:22:08 -0500
Subject: [R] Computing very large distance matrix
References: <Pine.LNX.4.44.0402251910070.9635-100000@gannet.stats>
Message-ID: <004601c3fbfe$92979b20$722617ac@arnav>


Hello,

Thank you all for your replies.

I have just discovered that now, for some reason, R does not let me increase
its memory limit beyond 4095 Mb.

Also, I get a different error message when computing the matrix using
daisy() as opposed to dist():

Error: Cannot allocate vector of size 135168 Kb

Does this mean that there is no way in which I can compute this distance
matrix on the machine I described below?

Is there any possible solution to this problem?

Thanks again to all,
Arnav.



----- Original Message -----
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Arnav Sheth" <sheth at economics.rutgers.edu>
Cc: "R-Help" <R-help at stat.math.ethz.ch>
Sent: Wednesday, February 25, 2004 2:12 PM
Subject: Re: [R] Computing very large distance matrix


> On Wed, 25 Feb 2004, Arnav Sheth wrote:
>
> >
> > Hello All,
> >
> > I have a 131072x132 matrix for which I need to compute a regular
euclidean distance matrix, which I then need to transform and run agnes() on
this transformed matrix. I am having trouble computing the distance matrix
as it is fairly large and I am sure I have gone over the max.
> >
> > The specific error I am getting is:
> > Error in vector("double", length) : negative length vectors are not
allowed
>
> We've improved that message for the next release.
>
> > I have increased the memory limit to the maximum capacity of my hard
> > drive (which is around 20gb), with no success.
>
> You'd need to increase the 32-bit limit of Windows, too ....
>
> > I am running the RGUI on Windows XP with 512 mb of RAM.
> >
> > Would anyone have any suggestions as to how I can overcome this problem?
> > I would be most grateful for any help.
>
> No. The distance matrix is 8Gb all by itself.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From Duncan.Mackay at flinders.edu.au  Thu Feb 26 02:02:23 2004
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Thu, 26 Feb 2004 11:32:23 +1030
Subject: [R] se.contrast ???????????
Message-ID: <000201c3fc04$3129d640$91e66081@duncanlt>


Hi all,

Just to follow up Don Driscoll's earlier post, can anyone please explain
why "se.contrast" fails here??

> shp<-factor(rep(c("reserve","strip"),each=96))
> 
> 
>
site<-factor(rep(c("1g","1p","1t","2g","2p","2t","3g","3p","3t","4g","4p
","4t"),each=16))
> 
> pit<-factor(rep(1:16,12))
> 
>
reptsp<-c(4,5,6,4,6,6,6,7,3,5,2,2,4,8,5,4,2,4,2,2,4,5,2,4,4,4,3,2,3,2,5,
3,5,3,4,4,4,3,4,
+
3,4,4,4,3,4,3,6,3,3,5,4,6,4,4,2,4,2,6,5,5,5,7,4,4,5,1,4,5,6,5,5,2,6,3,5,
6,4,5,
+
4,8,2,4,2,4,2,4,3,3,4,4,3,2,1,3,4,4,2,2,3,2,4,1,2,2,3,4,5,5,3,5,5,4,1,1,
2,1,3,
+
1,4,1,6,1,2,3,2,2,2,1,1,2,2,6,5,3,2,3,5,3,2,3,2,1,3,2,4,4,3,3,3,1,2,4,3,
4,5,6,
+
5,2,3,2,2,5,5,5,2,2,5,2,4,4,3,2,2,3,2,2,2,2,5,4,3,3,5,2,5,4,3,2,2,2,1,2)
> 
> ddata<-data.frame(shp,pit,site,reptsp)
> 
> repmod2<-aov(reptsp~shp/site+ Error(shp/site))
> summary(repmod2)

Error: shp
    Df Sum Sq Mean Sq
shp  1  53.13   53.13

Error: shp:site
         Df Sum Sq Mean Sq
shp:site 10 61.885   6.189

Error: Within
           Df Sum Sq Mean Sq F value Pr(>F)
Residuals 180 318.56    1.77               
> 
> table(ddata$shp)

reserve   strip 
     96      96 
> 
> se.contrast(repmod2, list(shp=="strip", shp=="reserve"),data=ddata)
Error in qr.qty(strata$qr, scontrast) : qr and y must have the same
number of rows
> 
?????????????????????

Thanks,
Duncan

**********************************************

R, me bucko

*****************************************
Dr. Duncan Mackay
School of Biological Sciences
Flinders University
GPO Box 2100
Adelaide
S.A.    5001
AUSTRALIA

Ph (08) 8201 2627    FAX (08) 8201 3015

http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html



From rpeng at jhsph.edu  Thu Feb 26 02:28:24 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 25 Feb 2004 20:28:24 -0500
Subject: [R] Computing very large distance matrix
In-Reply-To: <004601c3fbfe$92979b20$722617ac@arnav>
References: <Pine.LNX.4.44.0402251910070.9635-100000@gannet.stats>
	<004601c3fbfe$92979b20$722617ac@arnav>
Message-ID: <403D4BB8.9000408@jhsph.edu>

The problem is not with R; the problem is with Windows, as well 
as the x86 architecture.  You'll never really be able to access 
more than 3GB of physical memory (for a single process). 
Accessing more than 4GB requires a 64 bit processor.

-roger

Arnav Sheth wrote:
> Hello,
> 
> Thank you all for your replies.
> 
> I have just discovered that now, for some reason, R does not let me increase
> its memory limit beyond 4095 Mb.
> 
> Also, I get a different error message when computing the matrix using
> daisy() as opposed to dist():
> 
> Error: Cannot allocate vector of size 135168 Kb
> 
> Does this mean that there is no way in which I can compute this distance
> matrix on the machine I described below?
> 
> Is there any possible solution to this problem?
> 
> Thanks again to all,
> Arnav.
> 
> 
> 
> ----- Original Message -----
> From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> To: "Arnav Sheth" <sheth at economics.rutgers.edu>
> Cc: "R-Help" <R-help at stat.math.ethz.ch>
> Sent: Wednesday, February 25, 2004 2:12 PM
> Subject: Re: [R] Computing very large distance matrix
> 
> 
> 
>>On Wed, 25 Feb 2004, Arnav Sheth wrote:
>>
>>
>>>Hello All,
>>>
>>>I have a 131072x132 matrix for which I need to compute a regular
> 
> euclidean distance matrix, which I then need to transform and run agnes() on
> this transformed matrix. I am having trouble computing the distance matrix
> as it is fairly large and I am sure I have gone over the max.
> 
>>>The specific error I am getting is:
>>>Error in vector("double", length) : negative length vectors are not
> 
> allowed
> 
>>We've improved that message for the next release.
>>
>>
>>>I have increased the memory limit to the maximum capacity of my hard
>>>drive (which is around 20gb), with no success.
>>
>>You'd need to increase the 32-bit limit of Windows, too ....
>>
>>
>>>I am running the RGUI on Windows XP with 512 mb of RAM.
>>>
>>>Would anyone have any suggestions as to how I can overcome this problem?
>>>I would be most grateful for any help.
>>
>>No. The distance matrix is 8Gb all by itself.
>>
>>--
>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>1 South Parks Road,                     +44 1865 272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From extropy at paradise.net.nz  Thu Feb 26 02:51:00 2004
From: extropy at paradise.net.nz (Joel Pitt)
Date: Thu, 26 Feb 2004 14:51:00 +1300
Subject: [R] Computing very large distance matrix
In-Reply-To: <403D4BB8.9000408@jhsph.edu>
References: <Pine.LNX.4.44.0402251910070.9635-100000@gannet.stats>	<004601c3fbfe$92979b20$722617ac@arnav>
	<403D4BB8.9000408@jhsph.edu>
Message-ID: <403D5104.7080503@paradise.net.nz>

Roger D. Peng wrote:

> The problem is not with R; the problem is with Windows, as well as the 
> x86 architecture.  You'll never really be able to access more than 3GB 
> of physical memory (for a single process). Accessing more than 4GB 
> requires a 64 bit processor.
> 
> -roger

Alternatively, if you move to Linux you could compile a kernel with
support for large amounts memory (>4GB) which doesn't require
a 64 bit processor.

Joel



From andy_liaw at merck.com  Thu Feb 26 03:00:02 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 25 Feb 2004 21:00:02 -0500
Subject: [R] Computing very large distance matrix
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7880@usrymx25.merck.com>

> From: Joel Pitt
> 
> Roger D. Peng wrote:
> 
> > The problem is not with R; the problem is with Windows, as 
> well as the 
> > x86 architecture.  You'll never really be able to access 
> more than 3GB 
> > of physical memory (for a single process). Accessing more than 4GB 
> > requires a 64 bit processor.
> > 
> > -roger
> 
> Alternatively, if you move to Linux you could compile a kernel with
> support for large amounts memory (>4GB) which doesn't require
> a 64 bit processor.

I don't think so.  We have a Xeon with 8GB of RAM running a custom-compiled
kernel with the large memory support.  The kernel does see 8GB, but a single
R process cannot go beyond 3GB.

OTOH our Opteron box has no such problem.

Andy

 
> Joel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From lixian7001 at yahoo.com  Thu Feb 26 04:02:23 2004
From: lixian7001 at yahoo.com (li xian)
Date: Wed, 25 Feb 2004 19:02:23 -0800 (PST)
Subject: [R] return value in function
Message-ID: <20040226030223.13994.qmail@web11504.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040225/5c3aef24/attachment.pl

From jasont at indigoindustrial.co.nz  Thu Feb 26 04:21:19 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 26 Feb 2004 16:21:19 +1300 (NZDT)
Subject: [R] return value in function
In-Reply-To: <20040226030223.13994.qmail@web11504.mail.yahoo.com>
References: <20040226030223.13994.qmail@web11504.mail.yahoo.com>
Message-ID: <13501.203.9.176.60.1077765679.squirrel@new-webmail.maxnet.co.nz>

> suppose I have a function example:
>
> getMatrix <- function(a,b){
>
>      A1<-diag(1,2,2)
>
> }
>
> If I want to get the both the A1 and dim(A1) from the function, Can I do
>
> return(A1,dim(A1)) inside the function ? And how can I access A1 and
> dim(A1) later on?

The general approach for this is to use a list

getMatrix <- function(a,b){
    A1<-diag(1,2,2)
    list(diag=A1,dim=dim(A1))
}

foo <- getMatrix(something)
foo$diag
foo$dim

Cheers

Jason



From andy_liaw at merck.com  Thu Feb 26 04:25:00 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 25 Feb 2004 22:25:00 -0500
Subject: [R] return value in function
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7883@usrymx25.merck.com>

In general, one would use a list to wrap all objects to be returned into one
object; e.g.,

getMatrix <- function(a, b) {
    A1 <- diag(1,2,2)
    return(list(matrix=A1, dim=dim(A1)))
}

You can then access them as:

mat <- getMatrix(1,1)
mat$matrix
mat$dim

My question is, why do you need to return the dim of the matrix?  The
dimension is already stored in the matrix object as an attribute.  Why store
it yet again?

Andy

> From: li xian
> 
> suppose I have a function example:
>  
> getMatrix <- function(a,b){
>  
>      A1<-diag(1,2,2)
>  
> }
>  
> If I want to get the both the A1 and dim(A1) from the 
> function, Can I do 
>  
> return(A1,dim(A1)) inside the function ? And how can I access 
> A1 and dim(A1) later on? 
>  
>      
> 
> 
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From lixian7001 at yahoo.com  Thu Feb 26 04:46:05 2004
From: lixian7001 at yahoo.com (li xian)
Date: Wed, 25 Feb 2004 19:46:05 -0800 (PST)
Subject: [R] minimum value
Message-ID: <20040226034605.91820.qmail@web11502.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040225/6cd2e032/attachment.pl

From abunn at montana.edu  Thu Feb 26 04:52:52 2004
From: abunn at montana.edu (Andy Bunn)
Date: Wed, 25 Feb 2004 20:52:52 -0700
Subject: [R] minimum value
In-Reply-To: <20040226034605.91820.qmail@web11502.mail.yahoo.com>
Message-ID: <002e01c3fc1c$06d1ea50$a0a00ecf@simATE>


min(v)

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of li xian
Sent: Wednesday, February 25, 2004 8:46 PM
To: R-help at stat.math.ethz.ch
Subject: [R] minimum value


suppose I have a vector called v,
how can I get the index of the minimum element of vector v?
 
Thanks!


---------------------------------


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From MSchwartz at medanalytics.com  Thu Feb 26 04:57:04 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 25 Feb 2004 21:57:04 -0600
Subject: [R] Gnumeric - 1   Excel - ?
Message-ID: <1077767824.7691.51.camel@localhost.localdomain>

Hi all,

As happens from time to time, discussions on this list appear regarding
the use of popular spreadsheets for statistical analysis. One such
thread (post of mine) is here:

http://maths.newcastle.edu.au/~rking/R/help/03a/6326.html

While not advocating such use, these discussions have referenced
articles that provide independent reviews of these applications and
issues of accuracy, etc.

Based upon a posting to Linux Today
(http://linuxtoday.com/news/2004022600226OSBZGN), I became aware this
evening of a new paper by the well known B.D. McCullough, who has
published many such reviews of both spreadsheets and other statistical
applications.

In the latest paper (pdf available from
http://www.csdassn.org/software_reports.html), Prof. McCullough reviews
Gnumeric as an example of how an open source project has responded to
prior criticism of issues, while raising well known issues with Excel,
at least through XP. He leaves open to further research, any
improvements to Excel 2003.

One lingering criticism is Gnumeric's RNG, however Prof. McCullough (who
references Prof. Ripley's 1990 PRNG paper) indicates in this article
that the Gnumeric team has incorporated the Mersenne Twister to a beta
version of Gnumeric, which may already have been released by now. This
modification ameliorates this concern.

For those wishing to stay abreast of such issues, this new paper may be
of interest. It puts the open source efforts of the Gnumeric team
(http://www.gnome.org/projects/gnumeric/) in a very favorable light.

Best regards,

Marc Schwartz



From jasont at indigoindustrial.co.nz  Thu Feb 26 05:03:26 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 26 Feb 2004 17:03:26 +1300 (NZDT)
Subject: [R] minimum value
In-Reply-To: <002e01c3fc1c$06d1ea50$a0a00ecf@simATE>
References: <20040226034605.91820.qmail@web11502.mail.yahoo.com>
	<002e01c3fc1c$06d1ea50$a0a00ecf@simATE>
Message-ID: <21191.203.9.176.60.1077768206.squirrel@new-webmail.maxnet.co.nz>

I almost said the same.  But he wanted the index.

which.min(v)

>
> min(v)
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of li xian
> Sent: Wednesday, February 25, 2004 8:46 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] minimum value
>
>
> suppose I have a vector called v,
> how can I get the index of the minimum element of vector v?
>
> Thanks!
>
>



From dsheuman at rogers.com  Thu Feb 26 06:50:51 2004
From: dsheuman at rogers.com (Danny Heuman)
Date: Thu, 26 Feb 2004 00:50:51 -0500
Subject: [R] Distance and Aggregate Data - Again...
Message-ID: <d42r3053l83mo9u3aedurrp2vrn22a0c84@4ax.com>

I appreciate the help I've been given so far.  The issue I face is
that the data I'm working with has 53000 rows, so in calculating
distance, finding all recids that fall within 2km and summing the
population, etc. - a) takes too long and b) have no sense of progress.

Below is a loop that reads each recid one at a time, calculates the
distance and identifies the recids that fall within 2 km.  It iterates
through all records successfully.

Where I'm stuck is how to get the sum of population and dwellings and
the mean age for the records that are selected.  Also, the desired
output should have the following fields:  recid, sum(pop), sum(dwell),
mean(age).  I don't know how to write only those fields out to the
file.

Any suggestions?

Thank you for your help,

Danny


#####
library(fields)

d <- as.matrix( read.csv("filein.csv") )

for(i in 1:nrow(d)){
	lonlat1 <- d[i,2:3]
	lonlat2 <- d[,2:3]
	distval <- d[,1] [which(rdist.earth( t( as.matrix(lonlat1) ),
as.matrix(lonlat2), miles=F ) < 2)]
	write(distval,file="C:\\outfile.out",ncol=1, append=TRUE)
}
#####


--------------
Sample Input Data
--------------
recid,lat,long,pop,dwell,age
10010265,47.5971174,-52.7039227,584,219,38
10010260,47.5971574,-52.7039147,488,188,34
10010263,47.5936538,-52.7037037,605,232,43
10010287,47.5739426,-52.7035365,548,256,29
10010290,47.5703333,-52.703182,559,336,36
10010284,47.5958782,-52.7013245,394,261,61
10010191,47.5322617,-52.7037037,892,323,23
10010291,47.5700412,-52.7009,0,0,0
10010289,47.5714152,-52.70023,0,0,0
10010285,47.5832183,-52.6995828,469,239,44
10010273,47.5800199,-52.6984875,855,283,28
10010190,47.472353,-52.697991,0,0,0
10010274,47.6018197,-52.6978362,344,117,51
10010288,47.5755249,-52.6978207,33,0,19
10010275,47.6005037,-52.697991,232,93,43
10010279,47.5915368,-52.6954916,983,437,33
10010276,47.5993086,-52.6954808,329,131,28
10010278,47.5958782,-52.6934253,251,107,27
10010354,47.5991086,-52.6934037,27,14,47
10010277,47.5968782,-52.6914148,515,194,37
10010293,47.5778754,-52.6954808,58,0,40
10010292,47.5722183,-52.6899332,1112,523,28
10010353,47.6356972,-52.6896838,1387,471,32
10010283,47.5958439,-52.6884621,531,296,41
10010281,47.5983891,-52.6880528,307,113,52
10010280,47.5958439,-52.6878177,374,129,18
10010282,47.5999645,-52.6880528,637,226,22
10010286,47.5797909,-52.6872042,446,280,32
10010355,47.5797609,-52.6872055,197,72,39



From patrick.giraudoux at univ-fcomte.fr  Thu Feb 26 09:52:48 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Thu, 26 Feb 2004 09:52:48 +0100
Subject: [R] Memory limitation in GeoR - Windows or R?
Message-ID: <002d01c3fc45$f93d8f50$56703051@PC728329681112>

Dear all,

I a read with great interest the e-mails related to Arnav Sheth about memory limitation when computing a distance matrix. I suspect
that I will also meet some memory limitation using GeoR. I am currently running GeoR on a geodata object including 2686 geographical
coordinates.

krige.conv() can handle it (it takes 10-15 mn of computing) but requests an increased memory.

> memory.limit(size=500000000)

When the computing is completed, the computer speed is considerably slowed down for any application. It is thus most necessary to
shut it down and restart. I will probably have to handle a set of 5000-6000 coordinates in once in the next few months. I wonder if
it will go through it on my plateform (Windows XP and compaq nx7000). If not, will the limitation due to R or to Windows? Does an
alternate solution exist?

Thanks for any hint,

Patrick Giraudoux



From sam.kemp2 at ntlworld.com  Thu Feb 26 09:55:31 2004
From: sam.kemp2 at ntlworld.com (Samuel Kemp)
Date: Thu, 26 Feb 2004 08:55:31 +0000
Subject: [R] linking other C++ libraries 
Message-ID: <403DB483.2040808@ntlworld.com>

Hi,

I have written a little C++ program, which uses a third party library 
called ANN (approximate nearest neighbours)....

#include "/home/sekemp/ann_0.2/include/ANN/ANN.h"

I have tried R CMD SHLIB ann.h myProgram.cc, although this compiles when 
I load it into R I get the following message..

dyn.load("/home/sekemp/ann_0.2/ann.so")
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library "/home/sekemp/ann_0.2/GammaTest.so":
  /home/sekemp/ann_0.2/GammaTest.so: undefined symbol: 
_ZN10ANNkd_treeC1EPPdiii12ANNsplitRule

I get the same error when I dyn.load the myProgram.so aswell.

There is nothing wrong with the ann library as I have used it directly 
in C++ using the compiler-linker thingy....

g++ myProgram.cc -I/home/sekemp/ann_0.2/include 
-L/home/sekemp/ann_0.2/lib -lANN

Does anyone have any ideas?

Cheers,

Sam.



From e.pebesma at geog.uu.nl  Thu Feb 26 10:05:27 2004
From: e.pebesma at geog.uu.nl (Edzer J. Pebesma)
Date: Thu, 26 Feb 2004 10:05:27 +0100
Subject: [R] Memory limitation in GeoR - Windows or R?
Message-ID: <403DB6D7.2070709@geog.uu.nl>

Usually, with that many observations, you use
kriging in a local neighbourhood, i.e. use only the
n nearest observations in a kriging system. If n is
pretty large, this is practically equivalent to kriging
with a global neighbourhood.

There are several other R packages that provide kriging,
some of which provide local kriging, e.g. gstat does
not require calculation of the full distance matrix.
--
Edzer



From maechler at stat.math.ethz.ch  Thu Feb 26 11:36:45 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 26 Feb 2004 11:36:45 +0100
Subject: [R] system.time(), sys.time() etc
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF77D4@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF77D4@usrymx25.merck.com>
Message-ID: <16445.52285.165869.280806@gargle.gargle.HOWL>

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Tue, 17 Feb 2004 13:03:36 -0500 writes:

    AndyL> Just do 
    AndyL> system.time <- sys.time

    AndyL> and you're good to go in S-PLUS (at least in 6.x).

yes.  This is yet another instance of S-Plus following R behind
and doing it incompatibly [with a reason ?]
{the first one I know being sd() vs stdev()}.

The historical names in S and S-PLUS where
unix.time() , then came dos.time()
whereas in R we've used system.time() from the very beginning.

Martin



From ian at all.info  Thu Feb 26 11:05:50 2004
From: ian at all.info (Ian Lenzen)
Date: Thu, 26 Feb 2004 04:05:50 -0600 (CST)
Subject: [R] Machine Learning category
Message-ID: <1733150835.1077789950553.JavaMail.jwu@atlas>


Hello,

We're creating a directory focused on web site credibility. We included:
http://www.r-project.org/ in the Machine Learning section of the All.info
directory.

Descriptive information provided by you and our editors helps our users
choose sites. Our editors have already selected starter keyterms and a
category for your web site.

To review their work, add information and gain editorial control over
your site's record in our system, please update your information here:

http://all.info/s?a=l&z=16th2kuyt6gphgvmjrrny4

More information about All.info is available at: http://www.all.info

Thanks in advance.

Ian Lenzen Editor, All.info - the Directory of Topics


Note: If you are NOT the proper site contact or you would like to provide
a corrected site contact, please update it here:
http://all.info/s?a=nl&z=16th2kuyt6gphgvmjrrny4&x=r-help%40lists.r-project.org

If you have other questions, please email: priority at all.info



From marcos.sanches at ipsos-opinion.com.br  Thu Feb 26 12:33:22 2004
From: marcos.sanches at ipsos-opinion.com.br (Marcos Sanches)
Date: Thu, 26 Feb 2004 08:33:22 -0300
Subject: [R] Structural Equation Model
Message-ID: <000201c3fc5c$56f0ac70$d297a8c0@opinionserver>


	Hello all!

 I want to estimate parameters in a MIMIC model. I have one latent
variable (ksi), four reflexive indicators (y1, y2, y3 and y4) and four
formative indicators (x1, x2, x3, x4). Is there a way to do it in R? I
know there is the SEM library, but it seems not to be possible to
specify formative indicators, that is, observed exogenous variables
which causes the latent variable. 

 Thanks,

Marcos



From wolski at molgen.mpg.de  Thu Feb 26 12:58:40 2004
From: wolski at molgen.mpg.de (wolski)
Date: Thu, 26 Feb 2004 12:58:40 +0100
Subject: [R] Sweave and Xemacs on Windows2000?
Message-ID: <200402261258400969.0DE6D2A0@harry.molgen.mpg.de>

Hallo!

Trying to configure Xemacs to work with .snw files on windows 2000.  Tried to do it how it is described in the FAQ for Sweaves.


When starting xemacs with and Snw file
*ESS* buffer contains hundrets of lines and the few last ones.

 (ess-loop-timeout . 500000) (inferior-ess-primary-prompt . ^) (inferior-ess-secondary-prompt . ^) (comint-use-prompt-regexp-instead-of-fields . t) (inferior-ess-start-file) (inferior-ess-start-args . inferior-SAS-args-temp) (ess-local-process-name)) 

And no syntax highlighting in the *.Snw buffer
?? 

Eryk



The xemacs files in my home in .xemacs directory look like

init.el
(load "D:/prog/XEmacs/xemacs-packages/lisp/auctex/tex-site")
(load "D:/prog/XEmacs/xemacs-packages/sweave-site.el")

.emacs (either in home or in home/.xemacs/ does not matter.)
(defun Rnw-mode ()
  (require 'ess-noweb)
  (noweb-mode)
  (if (fboundp 'R-mode)
      (setq noweb-default-code-mode 'R-mode)))
(add-to-list 'auto-mode-alist '("\\.Rnw\\'" . Rnw-mode))
(add-to-list 'auto-mode-alist '("\\.Snw\\'" . Rnw-mode))

(setq reftex-file-extensions
      '(("Snw" "Rnw" "nw" "tex" ".tex" ".ltx") ("bib" ".bib")))
(setq TeX-file-extensions
      '("Snw" "Rnw" "nw" "tex" "sty" "cls" "ltx" "texi" "texinfo"))



From jfox at mcmaster.ca  Thu Feb 26 13:00:25 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 26 Feb 2004 07:00:25 -0500
Subject: [R] Structural Equation Model
In-Reply-To: <000201c3fc5c$56f0ac70$d297a8c0@opinionserver>
Message-ID: <20040226120024.DSLK17655.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Marcos,

I don't see why you can't specify a MIMIC model using sem(), though you
might have to supply your own start values. When I have a chance, but
possibly not today, I'll check.

Regards,
 John


--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
--------------------------------
-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marcos Sanches
Sent: Thursday, February 26, 2004 6:33 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Structural Equation Model


	Hello all!

 I want to estimate parameters in a MIMIC model. I have one latent variable
(ksi), four reflexive indicators (y1, y2, y3 and y4) and four formative
indicators (x1, x2, x3, x4). Is there a way to do it in R? I know there is
the SEM library, but it seems not to be possible to specify formative
indicators, that is, observed exogenous variables which causes the latent
variable. 

 Thanks,

Marcos

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From f.calboli at ucl.ac.uk  Thu Feb 26 14:05:51 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 26 Feb 2004 13:05:51 +0000
Subject: [R] Multidimensional scaling and distance matrices
Message-ID: <1077800750.2958.153.camel@monkey>

Dear All,

I am in the somewhat unfortunate position of having to reproduce the
results previously obtained from (non-metric?) MDS on a "kinship" matrix
using Statistica. A kinship matrix measures affinity between groups, and
has its maximum values on the diagonal. 

Apparently, starting with a nxn kinship matrix, all it was needed to do
was to feed it to Statistica flagging that the matrix was NOT a distance
matrix but a kinship one. If Statistica transformed the kinship matrix
into a distance one (how?) is anybody's guess. 

A quick search immediately showed that a multidimensional scaling is
done on a distance matrix. See for instance:
MASS4, pg 304
"Elements of computational statistics", Jentle, pg 122
Edwards and Oman's article, page 2-7 R-News 3/3 

The fact that Statistica happily perform MDS on a "kinship" matrix is
puzzling. Indeed, I would expect errors, as in the following toy
example, without transforming the kinship matrix to distances:

> test
           V1          V2          V3          V4          V5
1 0.198716340 0.003612042 0.011926851 0.019737349 0.015021053
2 0.003612042 0.066742885 0.013809924 0.005121996 0.011175845
3 0.011926851 0.013809924 0.197337389 0.013893087 0.006405424
4 0.019737349 0.005121996 0.013893087 0.216047450 0.006218477
5 0.015021053 0.011175845 0.006405424 0.006218477 0.118812936

cmdscale(test)
   [,1] [,2]
V1  NaN  NaN
V2  NaN  NaN
V3  NaN  NaN
V4  NaN  NaN
V5  NaN  NaN
Warning messages:
1: some of the first 2 eigenvalues are < 0 in: cmdscale(test)
2: NaNs produced in: sqrt(ev)
> isoMDS(test)
Error in isoMDS(test) : NAs/Infs not allowed in d
> sammon(test)
Error in sammon(test) : initial configuration must be complete
In addition: Warning messages:
1: some of the first 2 eigenvalues are < 0 in: cmdscale(d, k)
2: NaNs produced in: sqrt(ev)


The colleagues who used the above routine are unable to tell me with
certainty whether Statistica used metric/non metric scaling, and if non
metric whether a Kruskall or a Sammon scaling. 

In any case, I would simply like to ask the memebers of the list if I am
correct in thinking that MDS can ONLY be performed on a distance matrix,
and I can therefore reasonably expect that some form of transformation
to a distance matrix has been performed by Statistica prior to the MDS.
It would at least be a first step to understand what exactly Statistica
did with the data.

Regards,

Federico Calboli
-- 



=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 251 208

f.calboli at ucl.ac.uk



From wolski at molgen.mpg.de  Thu Feb 26 13:21:03 2004
From: wolski at molgen.mpg.de (wolski)
Date: Thu, 26 Feb 2004 13:21:03 +0100
Subject: [R] Sweave and Xemacs on Windows2000?
In-Reply-To: <200402261258400969.0DE6D2A0@harry.molgen.mpg.de>
References: <200402261258400969.0DE6D2A0@harry.molgen.mpg.de>
Message-ID: <200402261321030653.0DFB507D@harry.molgen.mpg.de>


Hi!

Sorry for bothering. Got it working.

Eryk



From fm3a004 at math.uni-hamburg.de  Thu Feb 26 13:35:54 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Thu, 26 Feb 2004 13:35:54 +0100 (MET)
Subject: [R] Multidimensional scaling and distance matrices
In-Reply-To: <1077800750.2958.153.camel@monkey>
Message-ID: <Pine.GSO.3.95q.1040226132531.25753E-100000@sun11.math.uni-hamburg.de>

Hi,

usually the term MDS is used for methods which operate only on
dissimilarity matrices. A similarity matrix s can be easily transformed
into a dissimilarity matrix d by taking d <- max(s)-s, which could be
considered as kind of a canonical standard to do this.

It seems like the R-MDS methods give errors because your diagonals are
larger and should be smaller than anything else for dissimilarities.

I am not familiar with kinship matrices. You may try MDS on
max(test)-test, but because the diagonals in your matrix are not equal I
presume that there is another a bit more subtle standard routine to
convert kinship matrices into dissimilarities, maybe something like  
(raw, not R) d(i,j)=1-s(i,j)^2/(s(i,i)s(j,j)).

Did you consider the Statistica manual? It should tell you...

Hope this is of any help,
Christian

On 26 Feb 2004, Federico Calboli wrote:

> Dear All,
> 
> I am in the somewhat unfortunate position of having to reproduce the
> results previously obtained from (non-metric?) MDS on a "kinship" matrix
> using Statistica. A kinship matrix measures affinity between groups, and
> has its maximum values on the diagonal. 
> 
> Apparently, starting with a nxn kinship matrix, all it was needed to do
> was to feed it to Statistica flagging that the matrix was NOT a distance
> matrix but a kinship one. If Statistica transformed the kinship matrix
> into a distance one (how?) is anybody's guess. 
> 
> A quick search immediately showed that a multidimensional scaling is
> done on a distance matrix. See for instance:
> MASS4, pg 304
> "Elements of computational statistics", Jentle, pg 122
> Edwards and Oman's article, page 2-7 R-News 3/3 
> 
> The fact that Statistica happily perform MDS on a "kinship" matrix is
> puzzling. Indeed, I would expect errors, as in the following toy
> example, without transforming the kinship matrix to distances:
> 
> > test
>            V1          V2          V3          V4          V5
> 1 0.198716340 0.003612042 0.011926851 0.019737349 0.015021053
> 2 0.003612042 0.066742885 0.013809924 0.005121996 0.011175845
> 3 0.011926851 0.013809924 0.197337389 0.013893087 0.006405424
> 4 0.019737349 0.005121996 0.013893087 0.216047450 0.006218477
> 5 0.015021053 0.011175845 0.006405424 0.006218477 0.118812936
> 
> cmdscale(test)
>    [,1] [,2]
> V1  NaN  NaN
> V2  NaN  NaN
> V3  NaN  NaN
> V4  NaN  NaN
> V5  NaN  NaN
> Warning messages:
> 1: some of the first 2 eigenvalues are < 0 in: cmdscale(test)
> 2: NaNs produced in: sqrt(ev)
> > isoMDS(test)
> Error in isoMDS(test) : NAs/Infs not allowed in d
> > sammon(test)
> Error in sammon(test) : initial configuration must be complete
> In addition: Warning messages:
> 1: some of the first 2 eigenvalues are < 0 in: cmdscale(d, k)
> 2: NaNs produced in: sqrt(ev)
> 
> 
> The colleagues who used the above routine are unable to tell me with
> certainty whether Statistica used metric/non metric scaling, and if non
> metric whether a Kruskall or a Sammon scaling. 
> 
> In any case, I would simply like to ask the memebers of the list if I am
> correct in thinking that MDS can ONLY be performed on a distance matrix,
> and I can therefore reasonably expect that some form of transformation
> to a distance matrix has been performed by Statistica prior to the MDS.
> It would at least be a first step to understand what exactly Statistica
> did with the data.
> 
> Regards,
> 
> Federico Calboli
> -- 
> 
> 
> 
> =================================
> 
> Federico C. F. Calboli
> 
> Dipartimento di Biologia
> Via Selmi 3
> 40126 Bologna
> Italy
> 
> tel (+39) 051 209 4187
> fax (+39) 051 251 208
> 
> f.calboli at ucl.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From thpe at hhbio.wasser.tu-dresden.de  Thu Feb 26 13:41:40 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Thu, 26 Feb 2004 13:41:40 +0100
Subject: [R] Sweave and Xemacs on Windows2000?
In-Reply-To: <200402261258400969.0DE6D2A0@harry.molgen.mpg.de>
References: <200402261258400969.0DE6D2A0@harry.molgen.mpg.de>
Message-ID: <403DE984.1080708@hhbio.wasser.tu-dresden.de>

wolski wrote:
> Hallo!
> 
> Trying to configure Xemacs to work with .snw files on windows 2000.
> Tried to do it how  it is described in the FAQ for Sweaves.
> 
> 
> When starting xemacs with and Snw file *ESS* buffer contains hundrets
>  of lines and the few last ones.

[...]

> And no syntax highlighting in the *.Snw buffer ??

Hello,

on Linux it works out of the box, but on Windows I had similar problems
(Xemacs-21.4.13 and Win2k). First, you must be sure, that .xemacs is in your
home directory. I don't use the standards of win2k and set the
environment variable HOME=D:\

My simple .xemacs/init.el file looks as follows.

Thomas P.


;; Auctex
(require 'tex-site)

;; ESS
(require 'ess-site)
(setq-default inferior-R-program-name "F:/src/R-1.8.1/bin/Rterm")

;; Sweave
(defun Rnw-mode ()
   (require 'ess-noweb)
   (noweb-mode)
   (if (fboundp 'R-mode)
       (setq noweb-default-code-mode 'R-mode)))

(add-to-list 'auto-mode-alist '("\\.Rnw\\'" . Rnw-mode))
(add-to-list 'auto-mode-alist '("\\.Snw\\'" . Rnw-mode))
(add-to-list 'auto-mode-alist '("\\.Stex\\'" . tex-mode))
(add-to-list 'auto-mode-alist '("\\.Rtex\\'" . tex-mode))

(setq reftex-file-extensions
       '(("Snw" "Rnw" "nw" "tex" ".tex" ".ltx") ("bib" ".bib")))
(setq tex-file-extensions
       '("Snw" "Rnw" "nw" "tex" "Stex" "sty" "cls" "ltx" "texi" "texinfo"))



From B.Rowlingson at lancaster.ac.uk  Thu Feb 26 13:43:53 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 26 Feb 2004 12:43:53 +0000
Subject: [R] writing polygons/segments to shapefiles (.shp) or other	ArCGIS
	compatible file
In-Reply-To: <004301c3fbd4$6a931b10$e6eafb51@PC728329681112>
References: <5.2.1.1.0.20040225113256.03b0d970@biomserv.univ-lyon1.fr>
	<004301c3fbd4$6a931b10$e6eafb51@PC728329681112>
Message-ID: <403DEA09.7010409@lancaster.ac.uk>

Patrick Giraudoux wrote:
> Thanks a lot for the hints. I will try.  Actually I was focusing (in a first stage) on simple segments (small mammal traplines...).
> I turned the problem out writing some lines to export the coordinates into a "simple" GRASS ascii file, imported it into GRASS as
> vector file and then used the export tool to get  shapefiles...  Not that direct: needs to have GRASS installed and an elementary
> knowledge on the export/import commands in this open source GIS.
> 
> It would be fantastic to have the reverse functions of Map2poly(Map), Map2lines(Map), Map2points(Map) read.shape (eg poly2map,
> lines2map, points2map, and write.map) to write shapefiles.... I must however admit that I don't know enough about shapefile formats
> and R programming to do this by myself... and I would unfortunately be really out of my current job in the university...
> 

The  shapelib library comes with command-line utilities for creating 
shapefiles, so at a stretch you could use those:

  % shpcreate fnord polygon             # creates new shapefile
  % shpadd fnord  0 0  1 0  1 1  0 1    # adds a unit square polygon

  % shpdump fnord
Shapefile Type: Polygon   # of Shapes: 1

File Bounds: (       0.000,       0.000,0,0)
          to  (       1.000,       1.000,0,0)

Shape:0 (Polygon)  nVertices=4, nParts=1
   Bounds:(       0.000,       0.000, 0, 0)
       to (       1.000,       1.000, 0, 0)
      (       0.000,       0.000, 0, 0) Ring
      (       1.000,       0.000, 0, 0)
      (       1.000,       1.000, 0, 0)
      (       0.000,       1.000, 0, 0)

  So you could quite easily create shapefiles from some text format with 
a bit of R that calls 'system' (on Unix at least). You wouldn't have to 
deal with C and the shapelib directly. This might be a bit slow though. 
You can also create the dbf library on the command line.

  Shapefile creation is on my list of things that would be nice for my 
Rmap library...

Baz



From ccleland at optonline.net  Thu Feb 26 14:10:00 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 26 Feb 2004 08:10:00 -0500
Subject: [R] Structural Equation Model
In-Reply-To: <000201c3fc5c$56f0ac70$d297a8c0@opinionserver>
References: <000201c3fc5c$56f0ac70$d297a8c0@opinionserver>
Message-ID: <403DF028.6010402@optonline.net>

Marcos Sanches wrote:
>  I want to estimate parameters in a MIMIC model. I have one latent
> variable (ksi), four reflexive indicators (y1, y2, y3 and y4) and four
> formative indicators (x1, x2, x3, x4). Is there a way to do it in R? I
> know there is the SEM library, but it seems not to be possible to
> specify formative indicators, that is, observed exogenous variables
> which causes the latent variable. 

Marcos:
   A MIMIC model seems to work fine in sem().  Here is an example of a 
MIMIC model which also has 4 indicators of a single latent variable and 
4 covariates:

 > S.sch <- var(school)
 > S.sch[upper.tri(var(school))] <- 0

 > round(S.sch, 4)
         Y1      Y2      Y3      Y4      X1      X2      X3     X4
Y1  1.3586  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000 0.0000
Y2  1.0586  1.3815  0.0000  0.0000  0.0000  0.0000  0.0000 0.0000
Y3  0.6709  0.6937  1.8192  0.0000  0.0000  0.0000  0.0000 0.0000
Y4  1.0452  1.1185  0.6584  3.6370  0.0000  0.0000  0.0000 0.0000
X1  0.4891  0.4929  0.3406  0.5244  1.1984  0.0000  0.0000 0.0000
X2  0.0011  0.0246  0.0236  0.0545  0.0177  0.2500  0.0000 0.0000
X3 -0.7325 -0.8166 -0.4524 -0.8481 -0.8759 -0.0017  4.5451 0.0000
X4  0.0614  0.0644  0.0110  0.0781  0.1070 -0.0009 -0.3961 0.1605

 > # n = 5198

 > model.sch <- matrix(c(
+         'Eta1 ->    Y1',         NA,  1,
+         'Eta1 ->    Y2', 'lambda21', NA,
+         'Eta1 ->    Y3', 'lambda31', NA,
+         'Eta1 ->    Y4', 'lambda41', NA,
+         'X1 ->    Eta1',  'gamma11', NA,
+         'X2 ->    Eta1',  'gamma12', NA,
+         'X3 ->    Eta1',  'gamma13', NA,
+         'X4 ->    Eta1',  'gamma14', NA,
+         'Eta1 <-> Eta1',     'psi1', NA,
+         'Y1 <->     Y1',   'theta1', NA,
+         'Y2 <->     Y2',   'theta2', NA,
+         'Y3 <->     Y3',   'theta3', NA,
+         'Y4 <->     Y4',   'theta4', NA,
+         'X1 <->     X1',    'phi11', NA,
+         'X2 <->     X2',    'phi22', NA,
+         'X3 <->     X3',    'phi33', NA,
+         'X4 <->     X4',    'phi44', NA,
+         'X1 <->     X2',    'phi12', NA,
+         'X1 <->     X3',    'phi13', NA,
+         'X1 <->     X4',    'phi14', NA,
+         'X2 <->     X3',    'phi23', NA,
+         'X2 <->     X4',    'phi24', NA,
+         'X3 <->     X4',    'phi34', NA), ncol=3, byrow=TRUE)

 > obs.vars.sch <- c('Y1', 'Y2', 'Y3', 'Y4', 'X1', 'X2', 'X3', 'X4')

 > sem.sch <- sem(model.sch, S.sch, 5198)

 > summary(sem.sch)

  Model Chisquare =  77.445   Df =  14 Pr(>Chisq) = 8.4002e-11
  Goodness-of-fit index =  0.99628
  Adjusted goodness-of-fit index =  0.99044
  RMSEA index =  0.029530   90 % CI: (0.0011724, 0.0011724)
  BIC =  -71.451

  Normalized Residuals
      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
-3.82e+00 -4.27e-02  1.44e-05  6.41e-02  5.52e-01  2.74e+00

  Parameter Estimates
             Estimate Std Error   z value   Pr(>|z|)
lambda21  1.05267671 0.0156238  67.37643 0.00000000   Y2 <--- Eta1
lambda31  0.65931621 0.0184649  35.70637 0.00000000   Y3 <--- Eta1
lambda41  1.04965996 0.0257337  40.78937 0.00000000   Y4 <--- Eta1
gamma11   0.32691518 0.0134334  24.33606 0.00000000   Eta1 <--- X1
gamma12   0.04487985 0.0263389   1.70394 0.08839245   Eta1 <--- X2
gamma13  -0.11473656 0.0073527 -15.60472 0.00000000   Eta1 <--- X3
gamma14  -0.12574905 0.0371760  -3.38253 0.00071822   Eta1 <--- X4
psi1      0.76836697 0.0218450  35.17364 0.00000000 Eta1 <--> Eta1
theta1    0.35328543 0.0131454  26.87518 0.00000000     Y1 <--> Y1
theta2    0.26742302 0.0133470  20.03617 0.00000000     Y2 <--> Y2
theta3    1.38220283 0.0282621  48.90661 0.00000000     Y3 <--> Y3
theta4    2.52933440 0.0525526  48.12959 0.00000000     Y4 <--> Y4
phi11     1.19841396 0.0235177  50.95794 0.00000000     X1 <--> X1
phi22     0.24998279 0.0049079  50.93426 0.00000000     X2 <--> X2
phi33     4.54509222 0.0891715  50.97021 0.00000000     X3 <--> X3
phi44     0.16053813 0.0031543  50.89539 0.00000000     X4 <--> X4
phi12     0.01769075 0.0075963   2.32886 0.01986650     X2 <--> X1
phi13    -0.87588544 0.0345801 -25.32916 0.00000000     X3 <--> X1
phi14     0.10701444 0.0062625  17.08800 0.00000000     X4 <--> X1
phi23    -0.00173226 0.0147860  -0.11716 0.90673658     X3 <--> X2
phi24    -0.00087825 0.0027789  -0.31604 0.75197217     X4 <--> X2
phi34    -0.39612152 0.0130628 -30.32432 0.00000000     X4 <--> X3

  Iterations =  24

   This example was taken from

http://statmodel.com/mplus/examples/continuous/cont2.html

and the results agree fairly closely.  However, there does seem to be a 
problem with the RMSEA 90% confidence interval above.  Thanks to John 
Fox for providing this package.

hope it helps,

Chuck Cleland

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From marcos.sanches at ipsos-opinion.com.br  Thu Feb 26 14:40:46 2004
From: marcos.sanches at ipsos-opinion.com.br (Marcos Sanches)
Date: Thu, 26 Feb 2004 10:40:46 -0300
Subject: RES: [R] Structural Equation Model
In-Reply-To: <403DF028.6010402@optonline.net>
Message-ID: <001701c3fc6e$23c326e0$d297a8c0@opinionserver>

Thanks Chuck and John,

I guess the problem is that I was specifying the error terms in the
'ram' matrix. I am not familiarized with this type of model
specification as I am used to work with AMOS. Now I think it will work!

 Thanks very much!

Marcos




-----Mensagem original-----
De: Chuck Cleland [mailto:ccleland at optonline.net] 
Enviada em: quinta-feira, 26 de fevereiro de 2004 10:10
Para: marcos.sanches at ipsos-opinion.com.br
Cc: r-help at stat.math.ethz.ch; John Fox
Assunto: Re: [R] Structural Equation Model


Marcos Sanches wrote:
>  I want to estimate parameters in a MIMIC model. I have one latent 
> variable (ksi), four reflexive indicators (y1, y2, y3 and y4) and four

> formative indicators (x1, x2, x3, x4). Is there a way to do it in R? I

> know there is the SEM library, but it seems not to be possible to 
> specify formative indicators, that is, observed exogenous variables 
> which causes the latent variable.

Marcos:
   A MIMIC model seems to work fine in sem().  Here is an example of a 
MIMIC model which also has 4 indicators of a single latent variable and 
4 covariates:

 > S.sch <- var(school)
 > S.sch[upper.tri(var(school))] <- 0

 > round(S.sch, 4)
         Y1      Y2      Y3      Y4      X1      X2      X3     X4
Y1  1.3586  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000 0.0000 Y2
1.0586  1.3815  0.0000  0.0000  0.0000  0.0000  0.0000 0.0000 Y3  0.6709
0.6937  1.8192  0.0000  0.0000  0.0000  0.0000 0.0000 Y4  1.0452  1.1185
0.6584  3.6370  0.0000  0.0000  0.0000 0.0000 X1  0.4891  0.4929  0.3406
0.5244  1.1984  0.0000  0.0000 0.0000 X2  0.0011  0.0246  0.0236  0.0545
0.0177  0.2500  0.0000 0.0000 X3 -0.7325 -0.8166 -0.4524 -0.8481 -0.8759
-0.0017  4.5451 0.0000 X4  0.0614  0.0644  0.0110  0.0781  0.1070
-0.0009 -0.3961 0.1605

 > # n = 5198

 > model.sch <- matrix(c(
+         'Eta1 ->    Y1',         NA,  1,
+         'Eta1 ->    Y2', 'lambda21', NA,
+         'Eta1 ->    Y3', 'lambda31', NA,
+         'Eta1 ->    Y4', 'lambda41', NA,
+         'X1 ->    Eta1',  'gamma11', NA,
+         'X2 ->    Eta1',  'gamma12', NA,
+         'X3 ->    Eta1',  'gamma13', NA,
+         'X4 ->    Eta1',  'gamma14', NA,
+         'Eta1 <-> Eta1',     'psi1', NA,
+         'Y1 <->     Y1',   'theta1', NA,
+         'Y2 <->     Y2',   'theta2', NA,
+         'Y3 <->     Y3',   'theta3', NA,
+         'Y4 <->     Y4',   'theta4', NA,
+         'X1 <->     X1',    'phi11', NA,
+         'X2 <->     X2',    'phi22', NA,
+         'X3 <->     X3',    'phi33', NA,
+         'X4 <->     X4',    'phi44', NA,
+         'X1 <->     X2',    'phi12', NA,
+         'X1 <->     X3',    'phi13', NA,
+         'X1 <->     X4',    'phi14', NA,
+         'X2 <->     X3',    'phi23', NA,
+         'X2 <->     X4',    'phi24', NA,
+         'X3 <->     X4',    'phi34', NA), ncol=3, byrow=TRUE)

 > obs.vars.sch <- c('Y1', 'Y2', 'Y3', 'Y4', 'X1', 'X2', 'X3', 'X4')

 > sem.sch <- sem(model.sch, S.sch, 5198)

 > summary(sem.sch)

  Model Chisquare =  77.445   Df =  14 Pr(>Chisq) = 8.4002e-11
  Goodness-of-fit index =  0.99628
  Adjusted goodness-of-fit index =  0.99044
  RMSEA index =  0.029530   90 % CI: (0.0011724, 0.0011724)
  BIC =  -71.451

  Normalized Residuals
      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
-3.82e+00 -4.27e-02  1.44e-05  6.41e-02  5.52e-01  2.74e+00

  Parameter Estimates
             Estimate Std Error   z value   Pr(>|z|)
lambda21  1.05267671 0.0156238  67.37643 0.00000000   Y2 <--- Eta1
lambda31  0.65931621 0.0184649  35.70637 0.00000000   Y3 <--- Eta1
lambda41  1.04965996 0.0257337  40.78937 0.00000000   Y4 <--- Eta1
gamma11   0.32691518 0.0134334  24.33606 0.00000000   Eta1 <--- X1
gamma12   0.04487985 0.0263389   1.70394 0.08839245   Eta1 <--- X2
gamma13  -0.11473656 0.0073527 -15.60472 0.00000000   Eta1 <--- X3
gamma14  -0.12574905 0.0371760  -3.38253 0.00071822   Eta1 <--- X4
psi1      0.76836697 0.0218450  35.17364 0.00000000 Eta1 <--> Eta1
theta1    0.35328543 0.0131454  26.87518 0.00000000     Y1 <--> Y1
theta2    0.26742302 0.0133470  20.03617 0.00000000     Y2 <--> Y2
theta3    1.38220283 0.0282621  48.90661 0.00000000     Y3 <--> Y3
theta4    2.52933440 0.0525526  48.12959 0.00000000     Y4 <--> Y4
phi11     1.19841396 0.0235177  50.95794 0.00000000     X1 <--> X1
phi22     0.24998279 0.0049079  50.93426 0.00000000     X2 <--> X2
phi33     4.54509222 0.0891715  50.97021 0.00000000     X3 <--> X3
phi44     0.16053813 0.0031543  50.89539 0.00000000     X4 <--> X4
phi12     0.01769075 0.0075963   2.32886 0.01986650     X2 <--> X1
phi13    -0.87588544 0.0345801 -25.32916 0.00000000     X3 <--> X1
phi14     0.10701444 0.0062625  17.08800 0.00000000     X4 <--> X1
phi23    -0.00173226 0.0147860  -0.11716 0.90673658     X3 <--> X2
phi24    -0.00087825 0.0027789  -0.31604 0.75197217     X4 <--> X2
phi34    -0.39612152 0.0130628 -30.32432 0.00000000     X4 <--> X3

  Iterations =  24

   This example was taken from

http://statmodel.com/mplus/examples/continuous/cont2.html

and the results agree fairly closely.  However, there does seem to be a 
problem with the RMSEA 90% confidence interval above.  Thanks to John 
Fox for providing this package.

hope it helps,

Chuck Cleland

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From rossini at blindglobe.net  Thu Feb 26 14:42:01 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu, 26 Feb 2004 05:42:01 -0800
Subject: [R] Gnumeric - 1   Excel - ?
In-Reply-To: <1077767824.7691.51.camel@localhost.localdomain> (Marc
	Schwartz's message of "Wed, 25 Feb 2004 21:57:04 -0600")
References: <1077767824.7691.51.camel@localhost.localdomain>
Message-ID: <85eksi2c0m.fsf@servant.blindglobe.net>

Marc Schwartz <MSchwartz at medanalytics.com> writes:

> For those wishing to stay abreast of such issues, this new paper may be
> of interest. It puts the open source efforts of the Gnumeric team
> (http://www.gnome.org/projects/gnumeric/) in a very favorable light.

Thanks.  

For those using gnumeric to munge excel data, be careful.  Very
careful.  Just found a spreadsheet with "missing" columns (exist in
excel, and do not display in gnumeric).

If I'd known they were there, I'd not have had to recopy from an older
dataset.  Realigning/merging at 4am isn't fun.

Alternatively, if I had exported first into R (via CSV), I'd have
found them.

Not sure what the lesson is, but at 5am, I'm just not too sure about
anything except that I've now got a clean and validated dataset.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From jfox at mcmaster.ca  Thu Feb 26 14:41:03 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 26 Feb 2004 08:41:03 -0500
Subject: [R] Structural Equation Model
In-Reply-To: <403DF028.6010402@optonline.net>
Message-ID: <20040226134103.HMGE27950.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Chuck,

Thanks for saving me the trouble of checking this out. When I have a chance,
I'll take a look at what's going on with the RMSEA confidence interval.
Though it's been awhile, I recall checking this against several examples;
obviously something is wrong here.

Thanks again,
 John 


--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
--------------------------------
-----Original Message-----
From: Chuck Cleland [mailto:ccleland at optonline.net] 
Sent: Thursday, February 26, 2004 8:10 AM
To: marcos.sanches at ipsos-opinion.com.br
Cc: r-help at stat.math.ethz.ch; John Fox
Subject: Re: [R] Structural Equation Model

Marcos Sanches wrote:
>  I want to estimate parameters in a MIMIC model. I have one latent 
> variable (ksi), four reflexive indicators (y1, y2, y3 and y4) and four 
> formative indicators (x1, x2, x3, x4). Is there a way to do it in R? I 
> know there is the SEM library, but it seems not to be possible to 
> specify formative indicators, that is, observed exogenous variables 
> which causes the latent variable.

Marcos:
   A MIMIC model seems to work fine in sem().  Here is an example of a MIMIC
model which also has 4 indicators of a single latent variable and
4 covariates:

 > S.sch <- var(school)
 > S.sch[upper.tri(var(school))] <- 0

 > round(S.sch, 4)
         Y1      Y2      Y3      Y4      X1      X2      X3     X4
Y1  1.3586  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000 0.0000
Y2  1.0586  1.3815  0.0000  0.0000  0.0000  0.0000  0.0000 0.0000
Y3  0.6709  0.6937  1.8192  0.0000  0.0000  0.0000  0.0000 0.0000
Y4  1.0452  1.1185  0.6584  3.6370  0.0000  0.0000  0.0000 0.0000
X1  0.4891  0.4929  0.3406  0.5244  1.1984  0.0000  0.0000 0.0000
X2  0.0011  0.0246  0.0236  0.0545  0.0177  0.2500  0.0000 0.0000
X3 -0.7325 -0.8166 -0.4524 -0.8481 -0.8759 -0.0017  4.5451 0.0000
X4  0.0614  0.0644  0.0110  0.0781  0.1070 -0.0009 -0.3961 0.1605

 > # n = 5198

 > model.sch <- matrix(c(
+         'Eta1 ->    Y1',         NA,  1,
+         'Eta1 ->    Y2', 'lambda21', NA,
+         'Eta1 ->    Y3', 'lambda31', NA,
+         'Eta1 ->    Y4', 'lambda41', NA,
+         'X1 ->    Eta1',  'gamma11', NA,
+         'X2 ->    Eta1',  'gamma12', NA,
+         'X3 ->    Eta1',  'gamma13', NA,
+         'X4 ->    Eta1',  'gamma14', NA,
+         'Eta1 <-> Eta1',     'psi1', NA,
+         'Y1 <->     Y1',   'theta1', NA,
+         'Y2 <->     Y2',   'theta2', NA,
+         'Y3 <->     Y3',   'theta3', NA,
+         'Y4 <->     Y4',   'theta4', NA,
+         'X1 <->     X1',    'phi11', NA,
+         'X2 <->     X2',    'phi22', NA,
+         'X3 <->     X3',    'phi33', NA,
+         'X4 <->     X4',    'phi44', NA,
+         'X1 <->     X2',    'phi12', NA,
+         'X1 <->     X3',    'phi13', NA,
+         'X1 <->     X4',    'phi14', NA,
+         'X2 <->     X3',    'phi23', NA,
+         'X2 <->     X4',    'phi24', NA,
+         'X3 <->     X4',    'phi34', NA), ncol=3, byrow=TRUE)

 > obs.vars.sch <- c('Y1', 'Y2', 'Y3', 'Y4', 'X1', 'X2', 'X3', 'X4')

 > sem.sch <- sem(model.sch, S.sch, 5198)

 > summary(sem.sch)

  Model Chisquare =  77.445   Df =  14 Pr(>Chisq) = 8.4002e-11
  Goodness-of-fit index =  0.99628
  Adjusted goodness-of-fit index =  0.99044
  RMSEA index =  0.029530   90 % CI: (0.0011724, 0.0011724)
  BIC =  -71.451

  Normalized Residuals
      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
-3.82e+00 -4.27e-02  1.44e-05  6.41e-02  5.52e-01  2.74e+00

  Parameter Estimates
             Estimate Std Error   z value   Pr(>|z|)
lambda21  1.05267671 0.0156238  67.37643 0.00000000   Y2 <--- Eta1
lambda31  0.65931621 0.0184649  35.70637 0.00000000   Y3 <--- Eta1
lambda41  1.04965996 0.0257337  40.78937 0.00000000   Y4 <--- Eta1
gamma11   0.32691518 0.0134334  24.33606 0.00000000   Eta1 <--- X1
gamma12   0.04487985 0.0263389   1.70394 0.08839245   Eta1 <--- X2
gamma13  -0.11473656 0.0073527 -15.60472 0.00000000   Eta1 <--- X3
gamma14  -0.12574905 0.0371760  -3.38253 0.00071822   Eta1 <--- X4
psi1      0.76836697 0.0218450  35.17364 0.00000000 Eta1 <--> Eta1
theta1    0.35328543 0.0131454  26.87518 0.00000000     Y1 <--> Y1
theta2    0.26742302 0.0133470  20.03617 0.00000000     Y2 <--> Y2
theta3    1.38220283 0.0282621  48.90661 0.00000000     Y3 <--> Y3
theta4    2.52933440 0.0525526  48.12959 0.00000000     Y4 <--> Y4
phi11     1.19841396 0.0235177  50.95794 0.00000000     X1 <--> X1
phi22     0.24998279 0.0049079  50.93426 0.00000000     X2 <--> X2
phi33     4.54509222 0.0891715  50.97021 0.00000000     X3 <--> X3
phi44     0.16053813 0.0031543  50.89539 0.00000000     X4 <--> X4
phi12     0.01769075 0.0075963   2.32886 0.01986650     X2 <--> X1
phi13    -0.87588544 0.0345801 -25.32916 0.00000000     X3 <--> X1
phi14     0.10701444 0.0062625  17.08800 0.00000000     X4 <--> X1
phi23    -0.00173226 0.0147860  -0.11716 0.90673658     X3 <--> X2
phi24    -0.00087825 0.0027789  -0.31604 0.75197217     X4 <--> X2
phi34    -0.39612152 0.0130628 -30.32432 0.00000000     X4 <--> X3

  Iterations =  24

   This example was taken from

http://statmodel.com/mplus/examples/continuous/cont2.html

and the results agree fairly closely.  However, there does seem to be a
problem with the RMSEA 90% confidence interval above.  Thanks to John Fox
for providing this package.

hope it helps,

Chuck Cleland

--
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From Melania.Pintilie at uhn.on.ca  Thu Feb 26 14:47:48 2004
From: Melania.Pintilie at uhn.on.ca (Pintilie, Melania)
Date: Thu, 26 Feb 2004 08:47:48 -0500
Subject: [R] variance estimator for the cumulative incidence function
Message-ID: <877CB986CDC7D5118C6000805FA7C70904DE53CD@uhnmail307.torhosp.toronto.on.ca>


Hi everyone,
I am using the package cmprsk in R to estimate the cumulative incidence
function and its variance. In the manual it is mentioned that the variance
is calculated based on Dr. Aalen's paper (1978, Nonparametric estimation of
partial transition probabilities in multiple decrement models). 

I would appreciate if someone could provide me with a source where the
variance is expressed in a more readable way, for example as a sum. 

I appreciate your help. 
Thank you. 



Melania
Rm 15-433, ext 4886

Fax: (416) 946-2048






This e-mail may contain confidential and/or privileged infor...{{dropped}}



From pascal.dessaux at noos.fr  Thu Feb 26 15:06:49 2004
From: pascal.dessaux at noos.fr (pascal dessaux)
Date: Thu, 26 Feb 2004 15:06:49 +0100
Subject: [R] Handling R Objects  in C
Message-ID: <OEEGKALHOGJEPCDLIEDNAEGHCBAA.pascal.dessaux@noos.fr>

Hello

I want to handle R from a C/C++ project developped with Microsoft Visual
C++.Net

I put a multiproject solution,and one project is a win32 and dedicated for R
manipulation;

When I put in this project the example code from "Written R extension" 4.7
Handling R objects in C p39:
#include <R.h>
#include <Rdefines.h>
SEXP ab;
PROTECT(ab=NEW_NUMERIC(2)) ;
....

I got an unresolved external in the link, because I don't know what I need
to declare as an external library,I searched in the documentation but I
didn't find


Could you please help me


Thank a lot by advance

Pascal



From f.calboli at ucl.ac.uk  Thu Feb 26 16:05:02 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 26 Feb 2004 15:05:02 +0000
Subject: [R] Multidimensional scaling and distance matrices
In-Reply-To: <Pine.GSO.3.95q.1040226132531.25753E-100000@sun11.math.uni-hamburg.de>
References: <Pine.GSO.3.95q.1040226132531.25753E-100000@sun11.math.uni-hamburg.de>
Message-ID: <1077807902.2957.177.camel@monkey>

On Thu, 2004-02-26 at 12:35, Christian Hennig wrote:
> Hi,
> 
> usually the term MDS is used for methods which operate only on
> dissimilarity matrices. A similarity matrix s can be easily transformed
> into a dissimilarity matrix d by taking d <- max(s)-s, which could be
> considered as kind of a canonical standard to do this.
> 
> It seems like the R-MDS methods give errors because your diagonals are
> larger and should be smaller than anything else for dissimilarities.
> 
> I am not familiar with kinship matrices. You may try MDS on
> max(test)-test, but because the diagonals in your matrix are not equal I
> presume that there is another a bit more subtle standard routine to
> convert kinship matrices into dissimilarities, maybe something like  
> (raw, not R) d(i,j)=1-s(i,j)^2/(s(i,i)s(j,j)).
> 
I am happy with the function "dist" in {mva}, and I know there are other
functions in {cluster}, but it's besides the point. The question that is
nagging me is: is it justified to do a form of MDS on a matrix other
than a distance matrix? the reference I pointed out to do say to use a
distance matrix, but do not explicitely say "all else is wrong", so I
could call it a day.

> Did you consider the Statistica manual? It should tell you...

If I had it... in any case I hoped that the people that used Statistica
in the first place did read the manual before going forth in their
analysis. Now we are stuck in a situation where we do not know what
Statistica is actually doing, and I have to convince people that doing
things with R is going to be a better (= more sensible) option. 
 
Regards,

Federico Calboli

-- 



=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 251 208

f.calboli at ucl.ac.uk



From ripley at stats.ox.ac.uk  Thu Feb 26 15:10:07 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 26 Feb 2004 14:10:07 +0000 (GMT)
Subject: [R] Multidimensional scaling and distance matrices
In-Reply-To: <1077800750.2958.153.camel@monkey>
Message-ID: <Pine.LNX.4.44.0402261353530.1263-100000@gannet.stats>

A few comments:

MDS is normally done on a dissimilarity matrix, not necessarily a distance 
matrix (no need for the triangle inequality to be enforced).

Some MDS software will autmatically map similarity matrices to
corresponding dissimilarity matrices if told to do so (but not all by the
same mapping, usually D = 1-S or D = sqrt(1-S)).  It looks like a
`kinship' matrix is a cousin of a similarity matrix, which usually have
entries between 0 and 1 and with 1 on the diagonal.

The description of MDS in Statistica at

http://www.statsoftinc.com/textbook/stmulsca.html

is entirely in terms of `observed distances', and Kruskal-type MDS.

Note that non-metric MDS is almost impossible to reproduce due to local 
minima, although hopefully one could get a similar solution in a different 
implementation of the same method.

Faced with your example, I would treat it as a covariance matrix, turn it 
into a correlation matrix and take the distances as 1 - correlations, and 
cross my fingers.

On 26 Feb 2004, Federico Calboli wrote:

> Dear All,
> 
> I am in the somewhat unfortunate position of having to reproduce the
> results previously obtained from (non-metric?) MDS on a "kinship" matrix
> using Statistica. A kinship matrix measures affinity between groups, and
> has its maximum values on the diagonal. 
> 
> Apparently, starting with a nxn kinship matrix, all it was needed to do
> was to feed it to Statistica flagging that the matrix was NOT a distance
> matrix but a kinship one. If Statistica transformed the kinship matrix
> into a distance one (how?) is anybody's guess. 
> 
> A quick search immediately showed that a multidimensional scaling is
> done on a distance matrix. See for instance:
> MASS4, pg 304
> "Elements of computational statistics", Jentle, pg 122
> Edwards and Oman's article, page 2-7 R-News 3/3 
> 
> The fact that Statistica happily perform MDS on a "kinship" matrix is
> puzzling. Indeed, I would expect errors, as in the following toy
> example, without transforming the kinship matrix to distances:
> 
> > test
>            V1          V2          V3          V4          V5
> 1 0.198716340 0.003612042 0.011926851 0.019737349 0.015021053
> 2 0.003612042 0.066742885 0.013809924 0.005121996 0.011175845
> 3 0.011926851 0.013809924 0.197337389 0.013893087 0.006405424
> 4 0.019737349 0.005121996 0.013893087 0.216047450 0.006218477
> 5 0.015021053 0.011175845 0.006405424 0.006218477 0.118812936
> 
> cmdscale(test)
>    [,1] [,2]
> V1  NaN  NaN
> V2  NaN  NaN
> V3  NaN  NaN
> V4  NaN  NaN
> V5  NaN  NaN
> Warning messages:
> 1: some of the first 2 eigenvalues are < 0 in: cmdscale(test)
> 2: NaNs produced in: sqrt(ev)
> > isoMDS(test)
> Error in isoMDS(test) : NAs/Infs not allowed in d
> > sammon(test)
> Error in sammon(test) : initial configuration must be complete
> In addition: Warning messages:
> 1: some of the first 2 eigenvalues are < 0 in: cmdscale(d, k)
> 2: NaNs produced in: sqrt(ev)
> 
> 
> The colleagues who used the above routine are unable to tell me with
> certainty whether Statistica used metric/non metric scaling, and if non
> metric whether a Kruskall or a Sammon scaling. 
> 
> In any case, I would simply like to ask the memebers of the list if I am
> correct in thinking that MDS can ONLY be performed on a distance matrix,
> and I can therefore reasonably expect that some form of transformation
> to a distance matrix has been performed by Statistica prior to the MDS.
> It would at least be a first step to understand what exactly Statistica
> did with the data.
> 
> Regards,
> 
> Federico Calboli
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Thu Feb 26 15:41:54 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 26 Feb 2004 06:41:54 -0800
Subject: [R] Re: system.time(), sys.time() etc
In-Reply-To: <16445.52285.165869.280806@gargle.gargle.HOWL>
References: <3A822319EB35174CA3714066D590DCD504AF77D4@usrymx25.merck.com>
	<16445.52285.165869.280806@gargle.gargle.HOWL>
Message-ID: <403E05B2.8010007@pdf.com>

      Martin says, "This is another instance of S-Plus following R 
behind and doing it incompatibly [with a reason?] ... ."

      This is one example of a major issue in "how to wage and win a 
standards war", discussed by Shapiro and Varian (1998) Information Rules 
(Harvard Business School Press).  Whether you're Bill Gates or Larry 
Ellison, you want to make it easy for people to move to your product 
from a competitor but expensive for your current customers to escape to 
the competition. 

      Spencer Graves

Martin Maechler wrote:

>>>>>>"AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>>    on Tue, 17 Feb 2004 13:03:36 -0500 writes:
>>>>>>            
>>>>>>
>
>    AndyL> Just do 
>    AndyL> system.time <- sys.time
>
>    AndyL> and you're good to go in S-PLUS (at least in 6.x).
>
>yes.  This is yet another instance of S-Plus following R behind
>and doing it incompatibly [with a reason ?]
>{the first one I know being sd() vs stdev()}.
>
>The historical names in S and S-PLUS where
>unix.time() , then came dos.time()
>whereas in R we've used system.time() from the very beginning.
>
>Martin
>  
>



From sundar.dorai-raj at pdf.com  Thu Feb 26 15:43:54 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 26 Feb 2004 08:43:54 -0600
Subject: [R] linking other C++ libraries
In-Reply-To: <403DB483.2040808@ntlworld.com>
References: <403DB483.2040808@ntlworld.com>
Message-ID: <403E062A.9090500@pdf.com>


Samuel Kemp wrote:

> Hi,
> 
> I have written a little C++ program, which uses a third party library 
> called ANN (approximate nearest neighbours)....
> 
> #include "/home/sekemp/ann_0.2/include/ANN/ANN.h"
> 
> I have tried R CMD SHLIB ann.h myProgram.cc, although this compiles when 
> I load it into R I get the following message..
> 
> dyn.load("/home/sekemp/ann_0.2/ann.so")
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>        unable to load shared library "/home/sekemp/ann_0.2/GammaTest.so":
>  /home/sekemp/ann_0.2/GammaTest.so: undefined symbol: 
> _ZN10ANNkd_treeC1EPPdiii12ANNsplitRule
> 
> I get the same error when I dyn.load the myProgram.so aswell.
> 
> There is nothing wrong with the ann library as I have used it directly 
> in C++ using the compiler-linker thingy....
> 
> g++ myProgram.cc -I/home/sekemp/ann_0.2/include 
> -L/home/sekemp/ann_0.2/lib -lANN
> 
> Does anyone have any ideas?
> 

Looks like C++ name mangling. Did you wrap your code in extern "C" {}?

Regards,
Sundar



From jarioksa at sun3.oulu.fi  Thu Feb 26 16:08:23 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 26 Feb 2004 17:08:23 +0200
Subject: [R] Multidimensional scaling and distance matrices
In-Reply-To: <1077807902.2957.177.camel@monkey>
References: <Pine.GSO.3.95q.1040226132531.25753E-100000@sun11.math.uni-hamburg.de>
	<1077807902.2957.177.camel@monkey>
Message-ID: <1077808103.17604.49.camel@biol102145.oulu.fi>

On Thu, 2004-02-26 at 17:05, Federico Calboli wrote:
> On Thu, 2004-02-26 at 12:35, Christian Hennig wrote:

> I am happy with the function "dist" in {mva}, and I know there are other
> functions in {cluster}, but it's besides the point. The question that is
> nagging me is: is it justified to do a form of MDS on a matrix other
> than a distance matrix? the reference I pointed out to do say to use a
> distance matrix, but do not explicitely say "all else is wrong", so I
> could call it a day.
> 
No. You can write a program for NMDS that accepts either similarities or
dissimilarities. This was an option already in KYST (Kruskal - Young -
Shepard - Torgeson) programme that was one of the first available pieces
of software for running NMDS (from early 1970s or late 1960s).
Technically this means that you have either monotone decrease of
monotone increase in your Shepard plot. It doesn't matter. Of course,
you do not need that option, since you can change your similarities into
dissimilarities. Typically this is easy, and you can do something like 1
- similarity or 1 - sqrt(similarity) (the latter is metric for some
cases where the former is semimetric). This translations is trickier in
case like yours where the diagonals vary. However, I guess that
Statistica (or KYST) would not look at the diagonals: if the translation
into dissimilarities is tricky, the handling of similarities is probably
wrong in the software. That is, the software uses only off-diagonal
values at their face value, implying it thinks the diagonal values are
all equal. So it is better that you have to change your similarities
into dissimilarities since then you know how to do that -- NMDS may not
know or even care.

Actually, I think you could port KYST to R if you want to get a function
that accepts similarities, too. However, I think this is not worthwhile,
but Ripley's isoMDS (in MASS) is a better alternative. (It might be
worthwhile, and even easier, to port SINDSCAL, but I am not sure if its
licence allows this.)

Finally, Sammon and Kruskal scaling do not exhaust the alternatives for
NMDS. Actually, I think that the method used in Statistica may be ALSCAL
(many years since I used Statistica), like in the software used as a
model of Statistica. I am pretty sure it wasn't Sammon.

cheers, jari oksanen 
-- 
J.Oksanen, Oulu, Finland.
"Object-oriented programming is an exceptionally bad idea which could
only have originated in California." E. Dijkstra



From andy_liaw at merck.com  Thu Feb 26 16:08:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 26 Feb 2004 10:08:36 -0500
Subject: [R] RE: system.time(), sys.time() etc
Message-ID: <3A822319EB35174CA3714066D590DCD504AF788D@usrymx25.merck.com>

> From: Spencer Graves [mailto:spencer.graves at pdf.com] 
> 
>       Martin says, "This is another instance of S-Plus following R 
> behind and doing it incompatibly [with a reason?] ... ."
> 
>       This is one example of a major issue in "how to wage and win a 
> standards war", discussed by Shapiro and Varian (1998) 
> Information Rules 
> (Harvard Business School Press).  Whether you're Bill Gates or Larry 
> Ellison, you want to make it easy for people to move to your product 
> from a competitor but expensive for your current customers to 
> escape to 
> the competition. 
> 
>       Spencer Graves

But I believe neither Insightful nor R-core would want to see each other as
competitor.  (Reality might be quite different.)  It would not be in the
best interest of either party.

(Apologies for putting words in R-Core's mouth.  As for Insightful, at least
that's David Smith's word when he talked about `Future of S-PLUs' at the
2002 Insightful Technology Conference.)

Andy


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From SuzieBlatt at netscape.net  Thu Feb 26 16:15:07 2004
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Thu, 26 Feb 2004 10:15:07 -0500
Subject: [R] limit to complex plots?
Message-ID: <2ED3D11D.0809F47A.0D1322AF@netscape.net>


Hello all.

I am trying to create one figure, divided into 6 graphs/plots each with an inset sub-figure.  I can use to layout command to generate one figure with one inset sub-figure, but cannot seem to do it for multiple figures on one page.

I've tried a test with the following code:

layout(matrix(c(1,2,3,4), nrow=2, byrow=TRUE))
plot(rnorm(10), rnorm(10))
plot(rnorm(10), rnorm(10))
plot(rnorm(30), rnorm(30))
plot(rnotm(40), rnorm(40))
layout.show(4)

#this works and gives me my one page with 4 figures on it

layout(matrix(c(0,0,0,0,0,1,0,2,0,0,0,0,0,3,0,4), nrow=4, byrow=TRUE))
par(new=TRUE)
plot(rnorm(10), rnorm(10))

par(new=TRUE)
plot(rnorm(20), rnorm(20))

par(new=TRUE)
plot(rnorm(30), rnorm(30))

par(new=TRUE)
plot(rnorm(40), rnorm(40))

# this is the part that doesn't.  I've tried only one 'par(new=TRUE)' command before ALL the plot commands and as written above.  The best I can get is 3 sub-figures #2,3 and 4, in positions 1,2 and 3.

Has anyone figured this out?

thanks,
Suzanne Blatt

__________________________________________________________________
Introducing the New Netscape Internet Service.



From tlumley at u.washington.edu  Thu Feb 26 16:48:40 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 26 Feb 2004 07:48:40 -0800 (PST)
Subject: [R] variance estimator for the cumulative incidence function
In-Reply-To: <877CB986CDC7D5118C6000805FA7C70904DE53CD@uhnmail307.torhosp.toronto.on.ca>
References: <877CB986CDC7D5118C6000805FA7C70904DE53CD@uhnmail307.torhosp.toronto.on.ca>
Message-ID: <Pine.A41.4.58.0402260746350.26046@homer19.u.washington.edu>

On Thu, 26 Feb 2004, Pintilie, Melania wrote:

>
> Hi everyone,
> I am using the package cmprsk in R to estimate the cumulative incidence
> function and its variance. In the manual it is mentioned that the variance
> is calculated based on Dr. Aalen's paper (1978, Nonparametric estimation of
> partial transition probabilities in multiple decrement models).
>
> I would appreciate if someone could provide me with a source where the
> variance is expressed in a more readable way, for example as a sum.
>

It may well be that the simplest thing is to read the source code.
Survival analysis has pretty much moved to counting process notation.

	-thomas



From ripley at stats.ox.ac.uk  Thu Feb 26 17:06:07 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 26 Feb 2004 16:06:07 +0000 (GMT)
Subject: [R] Handling R Objects  in C
In-Reply-To: <OEEGKALHOGJEPCDLIEDNAEGHCBAA.pascal.dessaux@noos.fr>
Message-ID: <Pine.LNX.4.44.0402261604220.1439-100000@gannet.stats>

On Thu, 26 Feb 2004, pascal dessaux wrote:

> Hello
> 
> I want to handle R from a C/C++ project developped with Microsoft Visual
> C++.Net
> 
> I put a multiproject solution,and one project is a win32 and dedicated for R
> manipulation;
> 
> When I put in this project the example code from "Written R extension" 4.7
> Handling R objects in C p39:

(Note: page numbers are useless as they depend on the page size you used 
when producing the manual.)

> #include <R.h>
> #include <Rdefines.h>
> SEXP ab;
> PROTECT(ab=NEW_NUMERIC(2)) ;
> ....
> 
> I got an unresolved external in the link, because I don't know what I need
> to declare as an external library,I searched in the documentation but I
> didn't find

It is in readme.packages in the Windows distribution.  You need to make an 
import library for R.dll, and that tells you how to do so.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From stauber at biomed.ee.ethz.ch  Thu Feb 26 17:09:53 2004
From: stauber at biomed.ee.ethz.ch (Martin Stauber)
Date: Thu, 26 Feb 2004 17:09:53 +0100
Subject: [R] R on VMS
Message-ID: <403E1A51.9000007@biomed.ee.ethz.ch>

Dear R-Community,

I would like to compile R on VMS. Is there anybody out there who has 
already tried to do that? I am grateful for any hint. Thanks in advance.

Best regards,
Martin Stauber

-- 
===============================================
Martin Stauber
Institute for Biomedical Engineering
Swiss Federal Institute of Technology (ETH)
and University of Zurich
Moussonstrasse 18, CH-8044 Zurich, Switzerland
_______________________________________________
Tel.: +41 1 632 45 82    Fax.: +41 1 632 12 14
E-mail:         stauber at biomed.ee.ethz.ch
Web:            www.bioelectronics.ethz.ch



From dthibault at esperion.com  Thu Feb 26 17:13:18 2004
From: dthibault at esperion.com (David Thibault)
Date: Thu, 26 Feb 2004 11:13:18 -0500
Subject: [R] Help with multicolored points in one plot
Message-ID: <45B255AB58EB904C840B6D0AF4E3A1CC01E5FA37@independence.esperion.com>

Hello all,

I have a situation where I'd like to plot points from multiple groups of
data in one plot.  I'd like each group's points to be colored a different
color.  I've seen people comment on how you can alternate colors by
providing a range of colors and then it will loop through each color as it
plots individual points.  However, that just goes by individual points and
not by group.  

Next I thought if, for example, I had 2 groups, I could make a 2 color
vector.  Then I could merge the data from my two groups alternating into an
X and Y vector, but that doesn't work either because the 2 groups may not
have equal numbers of members.  For example
-------------------------------
Group1_Xdata <- c(1,2,3,4,5)
Group2_Xdata <- c(10,20,30,40,50)

Colors <- c("red","blue")
Merged_XData <- c(1,10,2,10,3,30,4,40,5,50)

(SAME MERGE FOR Y DATA)
-----------------------------
That would work to make group1 red and group2 blue, but if Group 2 had 6
members instead of 5, then the 6th member would come out red.

Any thoughts?  Also, I want to be able to code this generically enough that
I can have any number of groups and colors.

Best Regards,
Dave



From dthibault at esperion.com  Thu Feb 26 17:27:40 2004
From: dthibault at esperion.com (David Thibault)
Date: Thu, 26 Feb 2004 11:27:40 -0500
Subject: [R] RE: Help with multicolored points in one plot
Message-ID: <45B255AB58EB904C840B6D0AF4E3A1CC01E5FA38@independence.esperion.com>

Hello again,

I think this will help me:
http://www.math.montana.edu/Rweb/Rhelp/points.html

I'll email again if it doesn't.

Dave

-----Original Message-----
From: David Thibault 
Sent: Thursday, February 26, 2004 11:13 AM
To: R-help at r-project.org
Subject: Help with multicolored points in one plot

Hello all,

I have a situation where I'd like to plot points from multiple groups of
data in one plot.  I'd like each group's points to be colored a different
color.  I've seen people comment on how you can alternate colors by
providing a range of colors and then it will loop through each color as it
plots individual points.  However, that just goes by individual points and
not by group.  

Next I thought if, for example, I had 2 groups, I could make a 2 color
vector.  Then I could merge the data from my two groups alternating into an
X and Y vector, but that doesn't work either because the 2 groups may not
have equal numbers of members.  For example
-------------------------------
Group1_Xdata <- c(1,2,3,4,5)
Group2_Xdata <- c(10,20,30,40,50)

Colors <- c("red","blue")
Merged_XData <- c(1,10,2,10,3,30,4,40,5,50)

(SAME MERGE FOR Y DATA)
-----------------------------
That would work to make group1 red and group2 blue, but if Group 2 had 6
members instead of 5, then the 6th member would come out red.

Any thoughts?  Also, I want to be able to code this generically enough that
I can have any number of groups and colors.

Best Regards,
Dave



From tlumley at u.washington.edu  Thu Feb 26 17:36:51 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 26 Feb 2004 08:36:51 -0800 (PST)
Subject: [R] Help with multicolored points in one plot
In-Reply-To: <45B255AB58EB904C840B6D0AF4E3A1CC01E5FA37@independence.esperion.com>
References: <45B255AB58EB904C840B6D0AF4E3A1CC01E5FA37@independence.esperion.com>
Message-ID: <Pine.A41.4.58.0402260832360.60142@homer10.u.washington.edu>

On Thu, 26 Feb 2004, David Thibault wrote:

> Hello all,
>
> I have a situation where I'd like to plot points from multiple groups of
> data in one plot.  I'd like each group's points to be colored a different
> color.  I've seen people comment on how you can alternate colors by
> providing a range of colors and then it will loop through each color as it
> plots individual points.  However, that just goes by individual points and
> not by group.
>

Concatenate the groups into a single x vector and y vector, together with
a vector of group identifiers (eg  1,1,1,1,1,2,2,2,2,2,2,2,3,3), then

plot(y~x, col=group)

or to get more control

prettycolors<- c("forestgreen","goldenrod","sienna")

plot(y~x, col=prettycolors[group])

There are examples in demo(graphics).

	-thomas



From deepayan at stat.wisc.edu  Thu Feb 26 17:55:42 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 26 Feb 2004 10:55:42 -0600
Subject: [R] Help with multicolored points in one plot
In-Reply-To: <45B255AB58EB904C840B6D0AF4E3A1CC01E5FA37@independence.esperion.com>
References: <45B255AB58EB904C840B6D0AF4E3A1CC01E5FA37@independence.esperion.com>
Message-ID: <200402261055.42809.deepayan@stat.wisc.edu>

On Thursday 26 February 2004 10:13, David Thibault wrote:
> Hello all,
>
> I have a situation where I'd like to plot points from multiple groups of
> data in one plot.  I'd like each group's points to be colored a
> different color.  I've seen people comment on how you can alternate
> colors by providing a range of colors and then it will loop through each
> color as it plots individual points.  However, that just goes by
> individual points and not by group.
>
> Next I thought if, for example, I had 2 groups, I could make a 2 color
> vector.  Then I could merge the data from my two groups alternating into
> an X and Y vector, but that doesn't work either because the 2 groups may
> not have equal numbers of members.  For example
> -------------------------------
> Group1_Xdata <- c(1,2,3,4,5)
> Group2_Xdata <- c(10,20,30,40,50)
>
> Colors <- c("red","blue")
> Merged_XData <- c(1,10,2,10,3,30,4,40,5,50)
>
> (SAME MERGE FOR Y DATA)
> -----------------------------
> That would work to make group1 red and group2 blue, but if Group 2 had 6
> members instead of 5, then the 6th member would come out red.
>
> Any thoughts?  Also, I want to be able to code this generically enough
> that I can have any number of groups and colors.

Trellis graphics (using the lattice package in R) has a fairly systematic 
approach for doing this. See example(xyplot) for some examples. For your 
data, a possible usage could be:

x <- c(Group1_Xdata, Group2_Xdata)
y <- c(Group1_Ydata, Group2_Ydata)
g <- c(rep(1, length(Group1_Xdata)), rep(2, length(Group2_Xdata)))

xyplot(y ~ x, groups = g)

or if you want to control the colors

xyplot(y ~ x, groups = g, col = c("red", "blue"))


With base graphics, something similar could be achieved with 

plot(x, y, col = c("red", "blue")[g])

lattice is more systematic in the sense that it has globally modifiable 
settings to control various graphical parameters (not only color) used to 
distinguish between groups, with reasonable defaults.

Hth,

Deepayan



From spencer.graves at pdf.com  Thu Feb 26 18:09:56 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 26 Feb 2004 09:09:56 -0800
Subject: [R] Re: system.time(), sys.time() etc
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF788D@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF788D@usrymx25.merck.com>
Message-ID: <403E2864.5090802@pdf.com>

Hi, Andy:  That's great.  I hope it stays that way.  Spencer Graves

Liaw, Andy wrote:

>>From: Spencer Graves [mailto:spencer.graves at pdf.com] 
>>
>>      Martin says, "This is another instance of S-Plus following R 
>>behind and doing it incompatibly [with a reason?] ... ."
>>
>>      This is one example of a major issue in "how to wage and win a 
>>standards war", discussed by Shapiro and Varian (1998) 
>>Information Rules 
>>(Harvard Business School Press).  Whether you're Bill Gates or Larry 
>>Ellison, you want to make it easy for people to move to your product 
>>from a competitor but expensive for your current customers to 
>>escape to 
>>the competition. 
>>
>>      Spencer Graves
>>    
>>
>
>But I believe neither Insightful nor R-core would want to see each other as
>competitor.  (Reality might be quite different.)  It would not be in the
>best interest of either party.
>
>(Apologies for putting words in R-Core's mouth.  As for Insightful, at least
>that's David Smith's word when he talked about `Future of S-PLUs' at the
>2002 Insightful Technology Conference.)
>
>Andy
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New Jersey, USA 08889), and/or its affiliates (which may be known outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be confidential, proprietary copyrighted and/or legally privileged. It is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please notify us immediately by reply e-mail and then delete it from your system.
>------------------------------------------------------------------------------
>
>  
>



From christoph.lehmann at gmx.ch  Thu Feb 26 18:39:13 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Thu, 26 Feb 2004 18:39:13 +0100
Subject: [R] my own function given to lapply
Message-ID: <1077817153.4292.57.camel@christophl>


Hi 

It seems, I just miss something. I defined 

treshold <- function(pred) {
if (pred < 0.5) pred <- 0 else pred <- 1
return(pred)
}

and want to use apply it on a vector

sapply(mylist[,,3],threshold)

but I get:

Error in match.fun(FUN) : Object "threshold" not found

thanks for help
cheers

chris




-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From sam.kemp2 at ntlworld.com  Thu Feb 26 19:08:02 2004
From: sam.kemp2 at ntlworld.com (Samuel Kemp)
Date: Thu, 26 Feb 2004 18:08:02 +0000
Subject: [R] Compiling third party C++ libraries
Message-ID: <403E3602.5030506@ntlworld.com>

Hi,

Does anyone know how to compile C++ code that uses 3rd party C++ 
libraries, so that the .so file can be used in R?

I keep getting errors when using dyn.load which say undefined reference 
to KdSpiltRule, which is in my third party library.

Here is the entire code......

// Computes a rapid Gamma test using ANN (Approximate Near Neighbour) 
library

#include <stdio.h>                                                    
                    // C I/O
#include <string.h>                                                    
                    // string manipulation
#include <math.h>                                                        
                // math routines
#include "/home/sekemp/ann_0.2/include/ANN/ANN.h"            // ANN 
declarations

extern "C"
{
void rapidGammaTest(double *inputs, double *outputs, int *dim, int 
*n_pts, int *k, double *sum)
{
    ANNpointArray    data_pts;        // data points
    ANNpoint                query_pt;        // query point
    ANNidxArray        nn_idx;            // near neighbor indices
    ANNdistArray        dists;            // near neighbor distances
    ANNkd_tree        *the_tree;        // search structure

    query_pt = annAllocPt(*dim);            // allocate query point
    data_pts = annAllocPts(*n_pts, *dim);        // allocate data points
    nn_idx = new ANNidx[*k];            // allocate near neigh indices
    dists = new ANNdist[*k];            // allocate near neighbor dists
   
    int inc = 0;
    for(int i = 0; i < *n_pts; i++)
    {
        ANNpoint p;
        for(int j = 0; j < *dim; j++)
        {
            p[j] = inputs[inc];
            inc++;
        }
        data_pts[i] = p;
    }
   
    int bs    =    32;
    int M      = *n_pts;
    int n_NN         = *k;
    the_tree = new ANNkd_tree(        // build search structure
            data_pts,                                // the data points
            M,                                        // number of points
            n_NN,                                    // dimension of space
            bs);                                        // bucket size
   
    for(int t = 0; t < n_NN; t++)
    {
        sum[t] = 0.00;
    }
   
    for(int j = 0; j < M; j++)
    {
        the_tree->annkSearch(            // search
                        data_pts[j],                    // query point
                        n_NN,                                // number 
of near neighbors
                        nn_idx,                        // nearest 
neighbors (returned)
                         dists);                        // distance 
(returned)

        for (int g = 0; g < n_NN; g++)
        {
                sum[g] += pow(sqrt(dists[g]), 2);
        }
    }
}
}



From ripley at stats.ox.ac.uk  Thu Feb 26 19:09:29 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 26 Feb 2004 18:09:29 +0000 (GMT)
Subject: [R] linking other C++ libraries
In-Reply-To: <403E062A.9090500@pdf.com>
Message-ID: <Pine.LNX.4.44.0402261806540.1649-100000@gannet.stats>

On Thu, 26 Feb 2004, Sundar Dorai-Raj wrote:

> 
> Samuel Kemp wrote:
> 
> > Hi,
> > 
> > I have written a little C++ program, which uses a third party library 
> > called ANN (approximate nearest neighbours)....
> > 
> > #include "/home/sekemp/ann_0.2/include/ANN/ANN.h"
> > 
> > I have tried R CMD SHLIB ann.h myProgram.cc, although this compiles when 
> > I load it into R I get the following message..
> > 
> > dyn.load("/home/sekemp/ann_0.2/ann.so")
> > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> >        unable to load shared library "/home/sekemp/ann_0.2/GammaTest.so":
> >  /home/sekemp/ann_0.2/GammaTest.so: undefined symbol: 
> > _ZN10ANNkd_treeC1EPPdiii12ANNsplitRule
> > 
> > I get the same error when I dyn.load the myProgram.so aswell.
> > 
> > There is nothing wrong with the ann library as I have used it directly 
> > in C++ using the compiler-linker thingy....
> > 
> > g++ myProgram.cc -I/home/sekemp/ann_0.2/include 
> > -L/home/sekemp/ann_0.2/lib -lANN
> > 
> > Does anyone have any ideas?
> > 
> 
> Looks like C++ name mangling. Did you wrap your code in extern "C" {}?

Yes, but there is a missing library with the mangled symbol (which 
contains `ANN').  It needs to be

   R CMD SHLIB ann.h myProgram.cc -L/home/sekemp/ann_0.2/lib -lANN

I believe, if the .h file really is to be compiled ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Benjamin.STABLER at odot.state.or.us  Thu Feb 26 19:11:40 2004
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Thu, 26 Feb 2004 10:11:40 -0800
Subject: [R] writing polygons/segments to shapefiles (.shp) or other A
	rcGIS compatible file
Message-ID: <76A000A82289D411952F001083F9DD06047FE4E8@exsalem4-bu.odot.state.or.us>

The main limitation of the shapefiles package that I put together is that it
does not create shapefiles from R objects - rather it only writes shapefiles
that have been read into R and manipulated within the constraints of the
existing file structure.  By this I mean that for example you can change the
coordinates of points and write them back out.  Or you can add a bunch of
blank columns in the DBF outside of R and then fill them in with R.  But I
did not write any code to calculate byte offsets and such and that are
needed when creating a shapefile from scratch.  

So what I do when I want to create a new shapefile from within R is write
out the format required by the ASCII Tool ArcView (Avenue) script.  This
script is available at: http://arcscripts.esri.com/details.asp?dbid=11442
The format is simple: 

Works for space delimited ascii to point, polygon and polyline. The format
for point ascii file is id, x, y (no comma for real data, space delimited).
For polygon & polyline ascii files, the format is code (1 for start point, 2
for middle points, 3 for end point), x, y (no comma for real data, space
delimited). Export shapefile to ascii file works for point, polyline and
polygon shapefiles. The output format file is id, x, y. For polygon and
polyline, the id is the sequence id of vertices.

Thus all you have to do is write a text file, install the script in ArcView
and then use the ArcView extension to create a shapefile from the ASCII
file.  Unfortunately ASCII tool only works with the geography - you have to
add the attributes later.  

With all of that said, I would like to add to the shapefiles package the
ability to write out shapefiles from scratch.  Since the shapefiles format
is rather unique, I think it would be best to use the maptools ShapeList/Map
class format (or r-spatial's classes).  For starters the package would just
write out the geography (like the ASCII tool Avenue script).  Later would be
added the ability to write the dbf data out from the att.data element of the
Map object.

Unfortunately I don't know when I will have the time to do this.  If anyone
else wants to do then please go ahead and I can help via email if needed.
But adding the ability to write out shapefiles from scratch is on my list.
Once I finish coding our travel demand model and we enter the application
phase (probably in a few months) then will our demand to output shapefiles
from R increase and I can justify spending the time to write the code.  

I apologize that I have not paid much attention to the r-sig-geo discussion
or Edzer's r-spatial project.  If there is an effort underway to write out
shapefiles then can someone please inform me of its status.  If not, then
maybe I can help.  Thanks.

Benjamin Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
555 13th Street NE, Suite 2
Salem, OR 97301  Ph: 503-986-4104



From HankeA at mar.dfo-mpo.gc.ca  Thu Feb 26 19:55:18 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Thu, 26 Feb 2004 14:55:18 -0400
Subject: [R] limit to complex plots?
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE12494D@msgmarsta01.bio.dfo.ca>


try:
	layout(matrix(c(0,0,0,0,0,1,0,2,0,0,0,0,0,3,0,4), nrow=4,
byrow=TRUE))
	plot(rnorm(10), rnorm(10))
	plot(rnorm(20), rnorm(20))
	plot(rnorm(30), rnorm(30))
	plot(rnorm(40), rnorm(40))

> -----Original Message-----
> From:	SuzieBlatt at netscape.net [SMTP:SuzieBlatt at netscape.net]
> Sent:	Thursday, February 26, 2004 7:15 AM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] limit to complex plots?
> 
> 
> Hello all.
> 
> I am trying to create one figure, divided into 6 graphs/plots each with an
> inset sub-figure.  I can use to layout command to generate one figure with
> one inset sub-figure, but cannot seem to do it for multiple figures on one
> page.
> 
> I've tried a test with the following code:
> 
> layout(matrix(c(1,2,3,4), nrow=2, byrow=TRUE))
> plot(rnorm(10), rnorm(10))
> plot(rnorm(10), rnorm(10))
> plot(rnorm(30), rnorm(30))
> plot(rnotm(40), rnorm(40))
> layout.show(4)
> 
> #this works and gives me my one page with 4 figures on it
> 
> layout(matrix(c(0,0,0,0,0,1,0,2,0,0,0,0,0,3,0,4), nrow=4, byrow=TRUE))
> par(new=TRUE)
> plot(rnorm(10), rnorm(10))
> 
> par(new=TRUE)
> plot(rnorm(20), rnorm(20))
> 
> par(new=TRUE)
> plot(rnorm(30), rnorm(30))
> 
> par(new=TRUE)
> plot(rnorm(40), rnorm(40))
> 
> # this is the part that doesn't.  I've tried only one 'par(new=TRUE)'
> command before ALL the plot commands and as written above.  The best I can
> get is 3 sub-figures #2,3 and 4, in positions 1,2 and 3.
> 
> Has anyone figured this out?
> 
> thanks,
> Suzanne Blatt
> 
> __________________________________________________________________
> Introducing the New Netscape Internet Service.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From jgentry at jimmy.harvard.edu  Thu Feb 26 20:34:48 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu, 26 Feb 2004 14:34:48 -0500 (EST)
Subject: [R] my own function given to lapply
In-Reply-To: <1077817153.4292.57.camel@christophl>
Message-ID: <Pine.SOL.4.20.0402261434140.16987-100000@santiam.dfci.harvard.edu>

> treshold <- function(pred) {
  ^^^^^^^^

> Error in match.fun(FUN) : Object "threshold" not found
                                    ^^^^^^^^^

If this is a direct cut & paste, you have a typo as you've defined the
function as "treshold".



From MSchwartz at medanalytics.com  Thu Feb 26 20:38:44 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 26 Feb 2004 13:38:44 -0600
Subject: [R] my own function given to lapply
In-Reply-To: <1077817153.4292.57.camel@christophl>
References: <1077817153.4292.57.camel@christophl>
Message-ID: <1077824324.24396.4.camel@localhost.localdomain>

On Thu, 2004-02-26 at 11:39, Christoph Lehmann wrote:
> Hi 
> 
> It seems, I just miss something. I defined 
> 
> treshold <- function(pred) {
> if (pred < 0.5) pred <- 0 else pred <- 1
> return(pred)
> }
> 
> and want to use apply it on a vector
> 
> sapply(mylist[,,3],threshold)
> 
> but I get:
> 
> Error in match.fun(FUN) : Object "threshold" not found
> 
> thanks for help
> cheers
> 
> chris


Perhaps the missing first 'h' in the 'treshold' function definition
would be the problem?

Alternativey, you need to use:

sapply(mylist[, , 3], treshold)

HTH,

Marc Schwartz



From andy_liaw at merck.com  Thu Feb 26 20:39:16 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 26 Feb 2004 14:39:16 -0500
Subject: [R] my own function given to lapply
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7895@usrymx25.merck.com>

That should be `threshold', not `treshold'.  Is that the problem?

In any case, why not just use ifelse(); e.g., ifelse(mylist[,,3] < .5, 0,
1)?  Or even just round(mylist[,,3])?

Andy

> From: Christoph Lehmann
> 
> 
> Hi 
> 
> It seems, I just miss something. I defined 
> 
> treshold <- function(pred) {
> if (pred < 0.5) pred <- 0 else pred <- 1
> return(pred)
> }
> 
> and want to use apply it on a vector
> 
> sapply(mylist[,,3],threshold)
> 
> but I get:
> 
> Error in match.fun(FUN) : Object "threshold" not found
> 
> thanks for help
> cheers
> 
> chris
> 
> 
> 
> 
> -- 
> Christoph Lehmann <christoph.lehmann at gmx.ch>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From patrick.giraudoux at univ-fcomte.fr  Thu Feb 26 20:44:56 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Thu, 26 Feb 2004 20:44:56 +0100
Subject: [R] writing polygons/segments to shapefiles (.shp) or other
	ArcGIS compatible file
References: <76A000A82289D411952F001083F9DD06047FE4E8@exsalem4-bu.odot.state.or.us>
Message-ID: <001c01c3fca1$46d38f70$7aa3fb51@PC728329681112>

Hi,

Thanks for all those information and the most valuable library you have developed.

If somebody is to develop something to write shapefiles from polygon coordinates within R (most welcome), I don't think that the
attribute file (dbf) will be an important issue. If we have got an output with the index to link the dbf records to each shape of a
shapefile, any text file can be handled in R or Excel to create a dbf. The real issue is the encoding of the *.shp and *.shx  etc..
(and an index file for the dbf)

Most important is to consider that ESRI has stopped developping ArcView and AVENUE. They have moved to ArGIS and Visual Basic. In
this new generation framework, importation is managed with ArcToolBox which, to my knowledge, is very limited considering
importation of text objects (actually I even wonder if one can import something but attribute tables without ArcInfo). For instance,
the way I found to solve the problem I met was to write a programme in R to wrap the polygon coordinates in a text file readable in
GRASS (an opensource GIS), to import it into GRASS and to export the shapefile from GRASS. This shapefile was finally imported to
ArcGIS.  I would not insist on ESRI client policy. I just want to say that the more I know corporates the more I love opensource...

Anyway, there are many things that can be made in R which may deserve not only importation to R, but also exportation to many kinds
of GIS. To write shapefiles from polygon, points or lines created in R would be most useful.

Many thanks for your interest and support,

Patrick Giraudoux


Universit? de Franche-Comt?
Laboratoire de Biologie environnementale
EA3184 usc INRA
F-25030 Besan?on Cedex

t?l.: +33 381 665 745
fax.: +33 381 665 797
http://lbe.univ-fcomte.fr

"Ce n'est pas en am?liorant la bougie que l'on a invent? l'?lectricit?", la recherche fondamentale est indispensable !




----- Original Message ----- 
From: <Benjamin.STABLER at odot.state.or.us>
To: <patrick.giraudoux at univ-fcomte.fr>
Cc: <r-help at stat.math.ethz.ch>; <r-sig-geo at stat.math.ethz.ch>
Sent: Thursday, February 26, 2004 7:11 PM
Subject: Re: [R] writing polygons/segments to shapefiles (.shp) or other ArcGIS compatible file


> The main limitation of the shapefiles package that I put together is that it
> does not create shapefiles from R objects - rather it only writes shapefiles
> that have been read into R and manipulated within the constraints of the
> existing file structure.  By this I mean that for example you can change the
> coordinates of points and write them back out.  Or you can add a bunch of
> blank columns in the DBF outside of R and then fill them in with R.  But I
> did not write any code to calculate byte offsets and such and that are
> needed when creating a shapefile from scratch.
>
> So what I do when I want to create a new shapefile from within R is write
> out the format required by the ASCII Tool ArcView (Avenue) script.  This
> script is available at: http://arcscripts.esri.com/details.asp?dbid=11442
> The format is simple:
>
> Works for space delimited ascii to point, polygon and polyline. The format
> for point ascii file is id, x, y (no comma for real data, space delimited).
> For polygon & polyline ascii files, the format is code (1 for start point, 2
> for middle points, 3 for end point), x, y (no comma for real data, space
> delimited). Export shapefile to ascii file works for point, polyline and
> polygon shapefiles. The output format file is id, x, y. For polygon and
> polyline, the id is the sequence id of vertices.
>
> Thus all you have to do is write a text file, install the script in ArcView
> and then use the ArcView extension to create a shapefile from the ASCII
> file.  Unfortunately ASCII tool only works with the geography - you have to
> add the attributes later.
>
> With all of that said, I would like to add to the shapefiles package the
> ability to write out shapefiles from scratch.  Since the shapefiles format
> is rather unique, I think it would be best to use the maptools ShapeList/Map
> class format (or r-spatial's classes).  For starters the package would just
> write out the geography (like the ASCII tool Avenue script).  Later would be
> added the ability to write the dbf data out from the att.data element of the
> Map object.
>
> Unfortunately I don't know when I will have the time to do this.  If anyone
> else wants to do then please go ahead and I can help via email if needed.
> But adding the ability to write out shapefiles from scratch is on my list.
> Once I finish coding our travel demand model and we enter the application
> phase (probably in a few months) then will our demand to output shapefiles
> from R increase and I can justify spending the time to write the code.
>
> I apologize that I have not paid much attention to the r-sig-geo discussion
> or Edzer's r-spatial project.  If there is an effort underway to write out
> shapefiles then can someone please inform me of its status.  If not, then
> maybe I can help.  Thanks.
>
> Benjamin Stabler
> Transportation Planning Analysis Unit
> Oregon Department of Transportation
> 555 13th Street NE, Suite 2
> Salem, OR 97301  Ph: 503-986-4104



From Jim_Garrett at bd.com  Thu Feb 26 21:00:11 2004
From: Jim_Garrett at bd.com (Jim_Garrett@bd.com)
Date: Thu, 26 Feb 2004 15:00:11 -0500
Subject: [R] Loading SparseM on Win2K
Message-ID: <OF91AE1018.21B3466F-ON85256E46.006D1A8D@bd.com>

I'm having trouble loading the package SparseM in R 1.8.1, OS = Windows
2000.

Installing appeared to go well; I saw no error messages, html documentation
was installed, and "installed.packages()" lists SparseM among the installed
packages.

When I try to load the library, however, I get the following:

> library(SparseM)
Error in slot(mlist, "argument") : Can't get a slot ("argument") from an
object of type "NULL"
Error in print("SparseM library loaded") :
        S language method selection got an error when called from internal
dispatch for function "print"
Error in library(SparseM) : .First.lib failed

Does anyone have an idea what could be wrong?  Or what I should do next to
diagnose the problem?

Thanks,

Jim Garrett

**********************************************************************
This message is intended only for the designated recipient(s...{{dropped}}



From rxg218 at psu.edu  Thu Feb 26 21:47:14 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Thu, 26 Feb 2004 15:47:14 -0500
Subject: [R] saving plots as objects?
Message-ID: <1077828434.506.9.camel@ra.chem.psu.edu>

Hi I had two questions regarding plots:

* Is there are way to save a plot in the form of an object such that it
could be displayed/modified later?

* I've been using Minitab for some work and I found the burshing
capability very handy (it allows me to choose a point on the graph and
displays the data associated with it - x,y and other user associated
data).

I know that this feature is available in XGobi but I was wondering if a
simplified form of brushing would be possible in R. I know there are
GUI's for R but I was rather thinking of a small Tk based function which
would basically work with a plot and somehow recieve mouse clicks on the
plot and use identify to get the X,Y data.

Does anybody know whether this has been done (or is indeed possible)?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
A beer delayed is a beer denied.



From femke at geog.umd.edu  Thu Feb 26 22:15:53 2004
From: femke at geog.umd.edu (femke)
Date: Thu, 26 Feb 2004 16:15:53 -0500
Subject: [R] adding header info to write.table
Message-ID: <006a01c3fcad$b85202b0$72180281@jawks2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040226/6d7dda03/attachment.pl

From andy_liaw at merck.com  Thu Feb 26 22:21:58 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 26 Feb 2004 16:21:58 -0500
Subject: [R] adding header info to write.table
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7896@usrymx25.merck.com>

I suppose one way to do it is to write the header info to the file first
(e.g., through connections, or sink(), etc.), then do write.table(...,
append=TRUE).

HTH,
Andy

> From: femke
> 
> Hello,
> 
> Could someone please tell if there is a way to append header 
> info to the top of an exported dataframe (exported with 
> write.table).  I want to append the following, which are the 
> defininitions for an asciigrid:
> 
> ncols         532
> nrows         999
> xllcorner     510465
> yllcorner     4766375
> cellsize      30
> NODATA_value  -9999
> 
> 
> Thanks very much,
> 
> femke
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From abunn at montana.edu  Thu Feb 26 22:27:56 2004
From: abunn at montana.edu (Andy Bunn)
Date: Thu, 26 Feb 2004 14:27:56 -0700
Subject: [R] adding header info to write.table
In-Reply-To: <006a01c3fcad$b85202b0$72180281@jawks2>
Message-ID: <002701c3fcaf$69af0520$78f05a99@msu.montana.edu>

You know...I almost added this to your original post because I thought
you might want to read something back into ArcInfro when you were done!

Look at ?files

The easiest thing to do in R is to keep your header as a text file in
the working directory and then append it to your output file using
'file.append'

write.table(your output file)
file.copy("header.txt", "final.output.txt")
file.append("final.output.txt", "output.dat")

Using 'paste' for the file names makes this easy and flexible.

HTH, Andy

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of femke
> Sent: Thursday, February 26, 2004 2:16 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] adding header info to write.table
> 
> 
> Hello,
> 
> Could someone please tell if there is a way to append header 
> info to the top of an exported dataframe (exported with 
> write.table).  I want to append the following, which are the 
> defininitions for an asciigrid:
> 
> ncols         532
> nrows         999
> xllcorner     510465
> yllcorner     4766375
> cellsize      30
> NODATA_value  -9999
> 
> 
> Thanks very much,
> 
> femke
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From Roger.Bivand at nhh.no  Thu Feb 26 22:31:12 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Feb 2004 22:31:12 +0100 (CET)
Subject: [R] adding header info to write.table
In-Reply-To: <006a01c3fcad$b85202b0$72180281@jawks2>
Message-ID: <Pine.LNX.4.44.0402262226110.13398-100000@reclus.nhh.no>

On Thu, 26 Feb 2004, femke wrote:

> Hello,
> 
> Could someone please tell if there is a way to append header info to the
> top of an exported dataframe (exported with write.table).  I want to
> append the following, which are the defininitions for an asciigrid:
> 
> ncols         532
> nrows         999
> xllcorner     510465
> yllcorner     4766375
> cellsize      30
> NODATA_value  -9999
> 

zz <- file("myraster", "w")
cat("ncols         532\nnrows         999\n", file=zz)
cat("xllcorner     510465\nyllcorner     4766375\n", file=zz)
cat("cellsize      30\nNODATA_value  -9999\n", file=zz)
write.table(data, file=zz, append=TRUE, col.names=FALSE, row.names=FALSE)
close(zz)

using connections (see help(connections)) and the append= argument in 
write.table. Is everybody writing ArcGIS ASCII rasters recently?

> 
> Thanks very much,
> 
> femke
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From p.connolly at hortresearch.co.nz  Thu Feb 26 22:40:30 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Fri, 27 Feb 2004 10:40:30 +1300
Subject: [R] adding header info to write.table
In-Reply-To: <006a01c3fcad$b85202b0$72180281@jawks2>;
	from femke@geog.umd.edu on Thu, Feb 26, 2004 at 04:15:53PM -0500
References: <006a01c3fcad$b85202b0$72180281@jawks2>
Message-ID: <20040227104030.A2137@hortresearch.co.nz>

On Thu, 26-Feb-2004 at 04:15PM -0500, femke wrote:

|> Hello,
|> 

|> Could someone please tell if there is a way to append header info
|> to the top of an exported dataframe (exported with write.table).  I
|> want to append the following, which are the defininitions for an
|> asciigrid:


|> ncols         532
|> nrows         999
|> xllcorner     510465
|> yllcorner     4766375
|> cellsize      30
|> NODATA_value  -9999

?write

then use append = TRUE when using write.table

HTH

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From spencer.graves at pdf.com  Thu Feb 26 22:55:59 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 26 Feb 2004 13:55:59 -0800
Subject: [R] adding header info to write.table
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7896@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7896@usrymx25.merck.com>
Message-ID: <403E6B6F.9090007@pdf.com>

      A minor variant is to use "cat" for the initial headers: 

DF <- data.frame(a=1:2, b=c("a","B"))
cat("header1\nheader2\n", file="filename.csv")
cat("header3\n", file="filename.csv", append=TRUE)
write.table(DF, file="filename.csv", append=TRUE)

      In S-Plus 6.2 and R 1.8.2, this produces the following: 

header1
header2
header3
"a" "b"
"1" 1 "a"
"2" 2 "B"

      hope this helps.  spencer graves

Liaw, Andy wrote:

>I suppose one way to do it is to write the header info to the file first
>(e.g., through connections, or sink(), etc.), then do write.table(...,
>append=TRUE).
>
>HTH,
>Andy
>
>  
>
>>From: femke
>>
>>Hello,
>>
>>Could someone please tell if there is a way to append header 
>>info to the top of an exported dataframe (exported with 
>>write.table).  I want to append the following, which are the 
>>defininitions for an asciigrid:
>>
>>ncols         532
>>nrows         999
>>xllcorner     510465
>>yllcorner     4766375
>>cellsize      30
>>NODATA_value  -9999
>>
>>
>>Thanks very much,
>>
>>femke
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
>>    
>>
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments,...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From gb at stat.umu.se  Thu Feb 26 22:59:03 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 26 Feb 2004 22:59:03 +0100
Subject: [R] variance estimator for the cumulative incidence function
In-Reply-To: <Pine.A41.4.58.0402260746350.26046@homer19.u.washington.edu>
References: <877CB986CDC7D5118C6000805FA7C70904DE53CD@uhnmail307.torhosp.toronto.on.ca>
	<Pine.A41.4.58.0402260746350.26046@homer19.u.washington.edu>
Message-ID: <20040226215903.GA19633@stat.umu.se>

On Thu, Feb 26, 2004 at 07:48:40AM -0800, Thomas Lumley wrote:
> On Thu, 26 Feb 2004, Pintilie, Melania wrote:
> 
> >
> > Hi everyone,
> > I am using the package cmprsk in R to estimate the cumulative incidence
> > function and its variance. In the manual it is mentioned that the variance
> > is calculated based on Dr. Aalen's paper (1978, Nonparametric estimation of
> > partial transition probabilities in multiple decrement models).
> >
> > I would appreciate if someone could provide me with a source where the
> > variance is expressed in a more readable way, for example as a sum.
> >
> 
> It may well be that the simplest thing is to read the source code.
> Survival analysis has pretty much moved to counting process notation.

One option is to check the old classic, Kalbfleisch & Prentice (1980),
"The Statistical Analysis of Failure Time Data", Wiley. If I remember
correctly, you'll find Greenwood's formula there for the log survivor 
function, which is what you want.

> 	-thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From abunn at montana.edu  Thu Feb 26 23:21:11 2004
From: abunn at montana.edu (Andy Bunn)
Date: Thu, 26 Feb 2004 15:21:11 -0700
Subject: [R] adding header info to write.table
In-Reply-To: <Pine.LNX.4.44.0402262226110.13398-100000@reclus.nhh.no>
Message-ID: <002e01c3fcb6$d9d1ab30$78f05a99@msu.montana.edu>

> Is everybody writing ArcGIS ASCII rasters recently?

The GIS community is hopelessly tied to ESRI. So many people have
invested their careers in learning Arc that switching to GRASS is an
institutional nightmare. Most of what I do now is outside of Arc! And
certainly outside of their almost useless GUI.



From Friedrich.Leisch at ci.tuwien.ac.at  Thu Feb 26 23:39:43 2004
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Fri, 27 Feb 2004 09:39:43 +1100
Subject: [R] RE: system.time(), sys.time() etc
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF788D@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF788D@usrymx25.merck.com>
Message-ID: <16446.30127.928434.372089@celebrian.ci.tuwien.ac.at>

>>>>> On Thu, 26 Feb 2004 10:08:36 -0500,
>>>>> Liaw, Andy (LA) wrote:

  >> From: Spencer Graves [mailto:spencer.graves at pdf.com] 
  >> 
  >> Martin says, "This is another instance of S-Plus following R 
  >> behind and doing it incompatibly [with a reason?] ... ."
  >> 
  >> This is one example of a major issue in "how to wage and win a 
  >> standards war", discussed by Shapiro and Varian (1998) 
  >> Information Rules 
  >> (Harvard Business School Press).  Whether you're Bill Gates or Larry 
  >> Ellison, you want to make it easy for people to move to your product 
  >> from a competitor but expensive for your current customers to 
  >> escape to 
  >> the competition. 
  >> 
  >> Spencer Graves

  > But I believe neither Insightful nor R-core would want to see each other as
  > competitor.  (Reality might be quite different.)  It would not be in the
  > best interest of either party.

  > (Apologies for putting words in R-Core's mouth.  As for Insightful, at least
  > that's David Smith's word when he talked about `Future of S-PLUs' at the
  > 2002 Insightful Technology Conference.)


I never saw R about trying to be a competition or replacement for
Splus, in fact many of us in R Core think that it is an advantage for
R that there also is a commercially supported version of S. I
personally would rather like to see if S (i.e. R and Splus combined)
gain market share at the cost of certain other statistical software
packages (e.g., ones matching the regular expression S..?S :-)

Best,
Fritz



From ealaca at ucdavis.edu  Thu Feb 26 23:42:57 2004
From: ealaca at ucdavis.edu (Emilio A. Laca)
Date: Thu, 26 Feb 2004 14:42:57 -0800 (PST)
Subject: [R] unable to install dse in mac OS X 10.3
Message-ID: <200402262242.i1QMgv33011775@andrena.ucdavis.edu>


I would like to request help with the installation of dse in raqua in mac
os x 10.3. I get the following error message after the messages indicating
that parts were successfully installed.

I would be most grateful for a solution.

-----------------------------------------

* Installing *source* package 'setRNG' ...

** R

** inst

** help

 >>> Building/Updating help pages for package 'setRNG'

     Formats: text html latex example 

  00Intro.setRNG                    text    html    latex   example

  getRNG                            text    html    latex   example

  setRNG                            text    html    latex   example

* DONE (setRNG)



* Installing *source* package 'tframe' ...

** R

** inst

** help

 >>> Building/Updating help pages for package 'tframe'

     Formats: text html latex example 

  00Intro.tframe                    text    html    latex

 <snip>
  trimNA                            text    html    latex   example

* DONE (tframe)



* Installing *source* package 'dse1' ...

** libs

g77   -fno-common  -g -O2 -c dsefor.f -o dsefor.o

gcc -bundle -flat_namespace -undefined suppress -L/usr/local/lib -o dse1.so
dsefor.o  -L/usr/local/lib -L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4
-L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/../../.. -lfrtbegin -lg2c
-lSystem -lcc_dynamic 

/usr/bin/ld: -undefined: unknown argument: -lbundle1.o

make: *** [dse1.so] Error 1

ERROR: compilation failed for package 'dse1'

** Removing '/Users/el/Library/RAqua/library/dse1'


Emilio A. Laca
Agronomy and Range Science
UC Davis
One Shields Ave.
Davis CA 95616
(530) 754-4083



From ru68y7s at myrealbox.com  Thu Feb 26 23:50:59 2004
From: ru68y7s at myrealbox.com (s viswanath)
Date: Thu, 26 Feb 2004 15:50:59 -0700
Subject: [R] boot and sample question
Message-ID: <1077835859.bd6a547cru68y7s@myrealbox.com>

I am new to R enviorns & greatly recommend the Venables Ripley "Modern Applied stats with S".


I am interested in a sampling say 5 day continuous windows of stock returns from a population and not applying a function to it. Is this avaiable in the 'boot' or the 'sample' function, and if it is, how? 

I have been able to sample single days returns, but not multiple continuous days.


Thank you in advance,

Sri Viswanath
Senior Portfolio Manager
Welton Investment Corporation



From ggrothendieck at myway.com  Fri Feb 27 00:11:37 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 26 Feb 2004 18:11:37 -0500 (EST)
Subject: [R] saving plots as objects?
Message-ID: <20040226231137.8BEA039AD@mprdmxin.myway.com>



First question:

dev.control(displayList = "enable") # turn on displaylist
plot(1:3)
myplot <- recordPlot()
plot(1:4)
myplot
# plot(1:3) is back up

Second question:

?identify 
?locator

---
Date:   Thu, 26 Feb 2004 15:47:14 -0500 
From:   Rajarshi Guha <rxg218 at psu.edu>
To:   R <r-help at stat.math.ethz.ch> 
Subject:   [R] saving plots as objects? 

 
Hi I had two questions regarding plots:

* Is there are way to save a plot in the form of an object such that it
could be displayed/modified later?

* I've been using Minitab for some work and I found the burshing
capability very handy (it allows me to choose a point on the graph and
displays the data associated with it - x,y and other user associated
data).

I know that this feature is available in XGobi but I was wondering if a
simplified form of brushing would be possible in R. I know there are
GUI's for R but I was rather thinking of a small Tk based function which
would basically work with a plot and somehow recieve mouse clicks on the
plot and use identify to get the X,Y data.

Does anybody know whether this has been done (or is indeed possible)?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>;
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
A beer delayed is a beer denied.



From k.wang at auckland.ac.nz  Fri Feb 27 00:25:08 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 27 Feb 2004 12:25:08 +1300
Subject: [R] Collapsing Categorical Variables
Message-ID: <001501c3fcbf$c61d54f0$6633d882@stat.auckland.ac.nz>

Hi,

Suppose I have a categorical variable called STREET, and I have 30
levels for it (i.e. 30 different streets).  I want to find all those
streets with only 15 observations or below then collapse them into a
level called OTHER.  Is there a quick way, other than using a for()
loop, to do it?  Currently what I'm doing is something like:
  ### Collapse STREET (those < 15)
  st <- c()
  STREET <- as.vector(STREET)
  for(i in 1:length(STREET)) {
    if(STREET[i] == "BOYNE AVE" ||
       STREET[i] == "CHAPEL ST" ||
       STREET[i] == "CONE PL" ||
       STREET[i] == "LACEBARK LANE" ||
       STREET[i] == "PRUDHOE LANE" ||
       STREET[i] == "VIRGIL PL" ||
       STREET[i] == "WILMOT ST" ) st[i] <- "Other"
    else st[i] <- STREET[i]
  }

But I'm sure there is a better way....

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
Statistics Workshops Co-ordinator
Student Learning Centre
University of Auckland
New Zealand



From sundar.dorai-raj at pdf.com  Fri Feb 27 00:40:23 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 26 Feb 2004 17:40:23 -0600
Subject: [R] Collapsing Categorical Variables
In-Reply-To: <001501c3fcbf$c61d54f0$6633d882@stat.auckland.ac.nz>
References: <001501c3fcbf$c61d54f0$6633d882@stat.auckland.ac.nz>
Message-ID: <403E83E7.6030200@pdf.com>


Ko-Kang Kevin Wang wrote:

> Hi,
> 
> Suppose I have a categorical variable called STREET, and I have 30
> levels for it (i.e. 30 different streets).  I want to find all those
> streets with only 15 observations or below then collapse them into a
> level called OTHER.  Is there a quick way, other than using a for()
> loop, to do it?  Currently what I'm doing is something like:
>   ### Collapse STREET (those < 15)
>   st <- c()
>   STREET <- as.vector(STREET)
>   for(i in 1:length(STREET)) {
>     if(STREET[i] == "BOYNE AVE" ||
>        STREET[i] == "CHAPEL ST" ||
>        STREET[i] == "CONE PL" ||
>        STREET[i] == "LACEBARK LANE" ||
>        STREET[i] == "PRUDHOE LANE" ||
>        STREET[i] == "VIRGIL PL" ||
>        STREET[i] == "WILMOT ST" ) st[i] <- "Other"
>     else st[i] <- STREET[i]
>   }
> 
> But I'm sure there is a better way....
> 
> Kevin

How about:

tab <- table(STREET)
small <- names(tab[tab < 15])
st <- ifelse(STREET %in% small, "Other", STREET)

/untested

-sundar



From andrewr at uidaho.edu  Fri Feb 27 00:49:34 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Thu, 26 Feb 2004 15:49:34 -0800
Subject: [R] Collapsing Categorical Variables
In-Reply-To: <001501c3fcbf$c61d54f0$6633d882@stat.auckland.ac.nz>
References: <001501c3fcbf$c61d54f0$6633d882@stat.auckland.ac.nz>
Message-ID: <200402261549.34037.andrewr@uidaho.edu>

Kevin,

something like ....

table(STREET)
STREET <- as.character(STREET)
STREET[as.numeric(factor(STREET)) %in% which(table(STREET) < 15)] <- "Other"
STREET <- factor(STREET)
table(STREET)


Andrew

On Thursday 26 February 2004 15:25, Ko-Kang Kevin Wang wrote:
> Hi,
>
> Suppose I have a categorical variable called STREET, and I have 30
> levels for it (i.e. 30 different streets).  I want to find all those
> streets with only 15 observations or below then collapse them into a
> level called OTHER.  Is there a quick way, other than using a for()
> loop, to do it?  Currently what I'm doing is something like:
>   ### Collapse STREET (those < 15)
>   st <- c()
>   STREET <- as.vector(STREET)
>   for(i in 1:length(STREET)) {
>     if(STREET[i] == "BOYNE AVE" ||
>        STREET[i] == "CHAPEL ST" ||
>        STREET[i] == "CONE PL" ||
>        STREET[i] == "LACEBARK LANE" ||
>        STREET[i] == "PRUDHOE LANE" ||
>        STREET[i] == "VIRGIL PL" ||
>        STREET[i] == "WILMOT ST" ) st[i] <- "Other"
>     else st[i] <- STREET[i]
>   }
>
> But I'm sure there is a better way....
>
> Kevin
>
> --------------------------------------------
> Ko-Kang Kevin Wang, MSc(Hon)
> Statistics Workshops Co-ordinator
> Student Learning Centre
> University of Auckland
> New Zealand
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson                      Ph: 208 885 7115
Department of Forest Resources       Fa: 208 885 6226
University of Idaho                  E : andrewr at uidaho.edu
PO Box 441133                        W : http://www.uidaho.edu/~andrewr
Moscow ID 83843                      Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From k.wang at auckland.ac.nz  Fri Feb 27 00:51:02 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 27 Feb 2004 12:51:02 +1300
Subject: [R] Collapsing Categorical Variables
In-Reply-To: <Pine.SOL.4.50.0402261537160.515-100000@springer.Berkeley.EDU>
Message-ID: <001701c3fcc3$64295b00$6633d882@stat.auckland.ac.nz>

> -----Original Message-----
> From: Phil Spector [mailto:spector at stat.Berkeley.EDU] 
> 
> How about something like:
> 
> tstreet = table(STREET)
> collapsestreets = names(tstreet[tstreet <= 15])
> STREET[STREET %in% collapsestreets] = 'OTHER'

Thanks a lot!

This is exactly what I want.  I had a feeling my way to use a for() loop
was rather silly....;D

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
Statistics Workshops Co-ordinator
Student Learning Centre
University of Auckland
New Zealand



From deepayan at stat.wisc.edu  Fri Feb 27 02:00:44 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 26 Feb 2004 19:00:44 -0600
Subject: [R] levelplot add line
In-Reply-To: <5.2.1.1.2.20040225115041.02010558@wiscmail.wisc.edu>
References: <5.2.1.1.2.20040225075631.01eec910@wiscmail.wisc.edu>
	<5.2.1.1.2.20040225115041.02010558@wiscmail.wisc.edu>
Message-ID: <200402261900.44968.deepayan@stat.wisc.edu>

On Wednesday 25 February 2004 14:00, Jeff Jorgensen wrote:
> Thanks for putting me on the right track.  Sorry to be bothersome with
> another follow-up, but the code that calls the panel function (see
> below) doesn't seem to be working.  What am I doing wrong?

You are using this wrong. In particular I'm completely confused by the 
c(...) usage.

You probably want something like

          panel = function(...) {
              panel.levelplot(...)
              panel.abline(h = 200)
          }

since you are not using any of the arguments passed to the panel function 
for the panel.abline call. If you do need to use something, say x, y, and 
z, your usege should be:


          panel = function(x, y, z, ...) {
              panel.levelplot(x = x, y = y, z = z, ...)

              ## do something with x,y,z
              hloc = foo(x, y, z)
              panel.abline(h = hloc)
          })


Deepayan



> Thanks,
>
> Jeff
>
> levelplot(matrix,contour=T, cuts=15,at=seq(...), labels=T, region=T,
>                             
> scales=list(x=list(at=xlocations,labels=as.character(xlabels)),
> y=list(at=ylocations,
> labels=as.character(ylabels))),
>                              xlim=c(1:368), ylim=c(1:31),
>                              colorkey = list(space = "bottom",
>                                              labels = list(at =
> seq(0,2000,200),
>                                              lab = seq(0,2000,200))),
> #If I cut it off here, it works fine
>          panel=function(x,y,z){
>                              panel.levelplot(x=c(...), y=c(...),
> z=matrix, cuts=15,at=seq(...), contour=T, labels=T, region=T,
>                              subscripts=seq(...),
>                              col.regions=cm.colors(100),
>                              zcol=c(1:100),
>                              panel.abline(h=200))
>              })



From wviechtb at cyrus.psych.uiuc.edu  Fri Feb 27 03:26:32 2004
From: wviechtb at cyrus.psych.uiuc.edu (Wolfgang Viechtbauer)
Date: Thu, 26 Feb 2004 20:26:32 -0600 (CST)
Subject: [R] Outer with Three Vectors
Message-ID: <Pine.SOL.4.58.0402262021290.29627@stat.psych.uiuc.edu>

Hello,

outer() is great for avoiding things like:

for (val1 in val1s) {
  for (val2 in val2s)) {
    x[i,j] <- somefunction(val1, val2)
  }
}

The same can be obtained with:

outer(val1s, val2s, somefunction)

But what if there are three (or more) sets of values to loop over? Any
way of avoiding the loops then?

Thanks,

-- 
Wolfgang Viechtbauer



From ray at mcs.vuw.ac.nz  Fri Feb 27 03:31:43 2004
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Fri, 27 Feb 2004 15:31:43 +1300 (NZDT)
Subject: [R] Distance and Aggregate Data - Again...
Message-ID: <200402270231.i1R2Vhsl005654@cafe-rozo.mcs.vuw.ac.nz>

dsheuman at rogers.com wrote:

> I appreciate the help I've been given so far.  The issue I face is
> that the data I'm working with has 53000 rows, so in calculating
> distance, finding all recids that fall within 2km and summing the
> population, etc. - a) takes too long and b) have no sense of progress.
>
Well, there are ways to speed this up.

> Below is a loop that reads each recid one at a time, calculates the
> distance and identifies the recids that fall within 2 km.  It iterates
> through all records successfully.
>
But you don't need to subset d[, 2:3] every time, e.g.  Also, my
experience is that writing a single line appended to a file every time
around the loop is very inefficient.

> Where I'm stuck is how to get the sum of population and dwellings and
> the mean age for the records that are selected.  Also, the desired
> output should have the following fields:  recid, sum(pop), sum(dwell),
> mean(age).  I don't know how to write only those fields out to the
> file.
>
Well, that part is easy, essentially, you have to save the indices, then
extract the relevant rows of pop, dwell and age. So I would modify your
code as follows:

library(fields)
d <- as.matrix( read.csv("filein.csv") )

lonlat2 <- d[,2:3]
results <- matrix(0, nrow=nrow(d), ncol=4)
for(i in 1:nrow(d)){
        lonlat1 <- d[i, 2:3]
        whichdist <- which(rdist.earth(t(as.matrix(lonlat1)),
                as.matrix(lonlat2), miles=F) < 2)
        distval <- d[, 1][whichdist]
        sumpop <- sum(data[, "pop"][whichdist])
        sumdwell <- sum(data[, "dwell"][whichdist])
        meanage <- mean(data[, "age"][whichdist])
        results[i, ] <- c(d[i, "recid"], sumpop, sumdwell, meanage)
}
write(t(results), file="C:\\outfile.out", ncol=ncol(results))

Then there is a trick you can use to speed up the process.  Essentially
you reduce the 'inner loop' which is inside rdist.earth().  This is
achieved by initially computing a single distance vector with reference
to a fixed point [(0, 0) seems reasonable since it is in the Atlantic
Ocean].  Then you select a subset of your points that are the same
distance is your circle centre from the fixed point plus or minus the
radius you want (and a bit of tolerance).  This will generate an
annulus of points rather than a circle, but in particular all the
points within the circle of interest will also be within this annulus.
Then you apply rdist.earth() to find the distance of each of these
points from your circle centre.

This is what I have used to process a 52000 length matrix in about 40
minutes (and ~50MB memory):

DistAgg <-
function(data, dist=2) {
  results <- matrix(0, nrow=nrow(data), ncol=4)
  colnames(results) <- c("recid", "sumpop", "sumdwell", "meanage")
  lonlat2 <- data[, 2:3]
  basedist <- rdist.earth(t(as.matrix(c(0, 0))), as.matrix(lonlat2))
  for(i in 1:nrow(data)){
    lonlat1 <- data[i, 2:3]
    approxval <- which(abs(basedist - basedist[i]) < dist*1.001)
    if (length(approxval) > 1) {
      whichval <- approxval[which(rdist.earth(t(as.matrix(lonlat1)),
        as.matrix(lonlat2[approxval, ]), miles=F) < dist)]
    } else {
      whichval <- approxval
    }
    sumpop <- sum(data[, "pop"][whichval])
    sumdwell <- sum(data[, "dwell"][whichval])
    meanage <- mean(data[, "age"][whichval])
    results[i, ] <- c(data[i, "recid"], sumpop, sumdwell, meanage)
  }
  write(t(results), file="C:\\outfile.out", ncol=ncol(results))
}

The data I used was based on yours, but randomised latitude and
longitude (in restricted ranges).

Hope this helps,
Ray Brownrigg



From andy_liaw at merck.com  Fri Feb 27 03:53:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 26 Feb 2004 21:53:36 -0500
Subject: [R] Outer with Three Vectors
Message-ID: <3A822319EB35174CA3714066D590DCD504AF789D@usrymx25.merck.com>

Here's my shot at it.  The gouter function can be enhanced further (e.g., as
outer() does with dimnames), but I think the basic functionality is there.
You can basically pass in any number of vectors you want, but you need to
wrap them in a single list.  outer() allows arrays, but gouter() below will
only work with list of vectors.

gouter <- function(x, FUN, ...) {
  xgrid <- as.list(do.call("expand.grid", x))
  names(xgrid) <- NULL
  xdim <- sapply(x, length)
  array(do.call(deparse(substitute(FUN)), c(xgrid, list(...))),
                dim=sapply(x, length), dimnames=x)
}

Here's a simple test:

> f <- function(x, y, z) x + y + z
> x1 <- 1:3
> x2 <- 4:5
> x3 <- 6:9
> gouter(list(x1, x2, x3), f)
, , 6

   4  5
1 11 12
2 12 13
3 13 14

, , 7

   4  5
1 12 13
2 13 14
3 14 15

, , 8

   4  5
1 13 14
2 14 15
3 15 16

, , 9

   4  5
1 14 15
2 15 16
3 16 17

HTH,
Andy

> From: Wolfgang Viechtbauer
> 
> Hello,
> 
> outer() is great for avoiding things like:
> 
> for (val1 in val1s) {
>   for (val2 in val2s)) {
>     x[i,j] <- somefunction(val1, val2)
>   }
> }
> 
> The same can be obtained with:
> 
> outer(val1s, val2s, somefunction)
> 
> But what if there are three (or more) sets of values to loop over? Any
> way of avoiding the loops then?
> 
> Thanks,
> 
> -- 
> Wolfgang Viechtbauer
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From deepayan at stat.wisc.edu  Fri Feb 27 06:58:51 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 26 Feb 2004 23:58:51 -0600
Subject: [R] saving plots as objects?
In-Reply-To: <1077828434.506.9.camel@ra.chem.psu.edu>
References: <1077828434.506.9.camel@ra.chem.psu.edu>
Message-ID: <200402262358.51156.deepayan@stat.wisc.edu>

On Thursday 26 February 2004 14:47, Rajarshi Guha wrote:
> Hi I had two questions regarding plots:
>
> * Is there are way to save a plot in the form of an object such that it
> could be displayed/modified later?

Depends on what you want to do. Probably not for regular (base) plots. The 
grid package has a concept of objects that can be edited (before and/or 
after plotting them). Functions in the lattice package produce objects 
that may be close to what you want. They are not plots themselves, but 
rather a self-contained description of a plot (in the sense that they 
contain the data as well as instructions on how to plot it). The data part 
cannot be easily changed, but almost everything else can be manipulated 
before plotting.

Deepayan



From ripley at stats.ox.ac.uk  Fri Feb 27 08:22:52 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 27 Feb 2004 07:22:52 +0000 (GMT)
Subject: [R] saving plots as objects?
In-Reply-To: <200402262358.51156.deepayan@stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0402270713390.2910-100000@gannet.stats>

On Thu, 26 Feb 2004, Deepayan Sarkar wrote:

> On Thursday 26 February 2004 14:47, Rajarshi Guha wrote:
> > Hi I had two questions regarding plots:
> >
> > * Is there are way to save a plot in the form of an object such that it
> > could be displayed/modified later?
> 
> Depends on what you want to do. Probably not for regular (base) plots. 

I think ?recordPlot does this, at least to allow plots to be saved, 
displayed again and added to.

> The 
> grid package has a concept of objects that can be edited (before and/or 
> after plotting them). Functions in the lattice package produce objects 
> that may be close to what you want. They are not plots themselves, but 
> rather a self-contained description of a plot (in the sense that they 
> contain the data as well as instructions on how to plot it). The data part 
> cannot be easily changed, but almost everything else can be manipulated 
> before plotting.

AFAIK that internal description is not documented and there are no
end-user tools for doing the manipulation.  Can you please point us to
details?   I suspect nothing can _easily_ be changed by end-users at 
present.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Fri Feb 27 08:36:49 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 27 Feb 2004 08:36:49 +0100
Subject: [R] Loading SparseM on Win2K
In-Reply-To: <OF91AE1018.21B3466F-ON85256E46.006D1A8D@bd.com>
References: <OF91AE1018.21B3466F-ON85256E46.006D1A8D@bd.com>
Message-ID: <403EF391.8030505@statistik.uni-dortmund.de>

Jim_Garrett at bd.com wrote:

> I'm having trouble loading the package SparseM in R 1.8.1, OS = Windows
> 2000.
> 
> Installing appeared to go well; I saw no error messages, html documentation
> was installed, and "installed.packages()" lists SparseM among the installed
> packages.
> 
> When I try to load the library, however, I get the following:
> 
> 
>>library(SparseM)
> 
> Error in slot(mlist, "argument") : Can't get a slot ("argument") from an
> object of type "NULL"
> Error in print("SparseM library loaded") :
>         S language method selection got an error when called from internal
> dispatch for function "print"
> Error in library(SparseM) : .First.lib failed
> 
> Does anyone have an idea what could be wrong?  Or what I should do next to
> diagnose the problem?

Hmm. SparseM-0.34 passes Rcmd check (R-1.8.1 for Windows) and loads on 
my machine.

Possible solutions:

1. Try to reinstall the package.
2. Try to start R with option --vanilla and try again (something may be 
strange with your Workspace or Startup files)
3. Reinstall R, something might be wrong with package methods.

Uwe Ligges




> Thanks,
> 
> Jim Garrett
> 
> **********************************************************************
> This message is intended only for the designated recipient(s...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From deepayan at stat.wisc.edu  Fri Feb 27 08:50:19 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 27 Feb 2004 01:50:19 -0600
Subject: [R] saving plots as objects?
In-Reply-To: <Pine.LNX.4.44.0402270713390.2910-100000@gannet.stats>
References: <Pine.LNX.4.44.0402270713390.2910-100000@gannet.stats>
Message-ID: <200402270150.19565.deepayan@stat.wisc.edu>

On Friday 27 February 2004 01:22, Prof Brian Ripley wrote:
> On Thu, 26 Feb 2004, Deepayan Sarkar wrote:
> > On Thursday 26 February 2004 14:47, Rajarshi Guha wrote:
> > > Hi I had two questions regarding plots:
> > >
> > > * Is there are way to save a plot in the form of an object such that
> > > it could be displayed/modified later?
> >
> > Depends on what you want to do. Probably not for regular (base) plots.
>
> I think ?recordPlot does this, at least to allow plots to be saved,
> displayed again and added to.

Ah, I didn't know that.

> > The
> > grid package has a concept of objects that can be edited (before
> > and/or after plotting them). Functions in the lattice package produce
> > objects that may be close to what you want. They are not plots
> > themselves, but rather a self-contained description of a plot (in the
> > sense that they contain the data as well as instructions on how to
> > plot it). The data part cannot be easily changed, but almost
> > everything else can be manipulated before plotting.
>
> AFAIK that internal description is not documented and there are no
> end-user tools for doing the manipulation.  Can you please point us to
> details?   I suspect nothing can _easily_ be changed by end-users at
> present.


There has always been an update() method that's supposed to be used for 
this. No one uses it much, and it probably has a few bugs (but should be 
improved in time for R 1.9.0). From ?xyplot:

Value:

     An object of class ``trellis''. The `update' method can be used to
     update components of the object and the `print' method (usually
     called by default) will plot it on an appropriate plotting device.

Deepayan



From ripley at stats.ox.ac.uk  Fri Feb 27 08:59:53 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 27 Feb 2004 07:59:53 +0000 (GMT)
Subject: [R] saving plots as objects?
In-Reply-To: <200402270150.19565.deepayan@stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0402270757280.3118-100000@gannet.stats>

On Fri, 27 Feb 2004, Deepayan Sarkar wrote:

> On Friday 27 February 2004 01:22, Prof Brian Ripley wrote:
> > On Thu, 26 Feb 2004, Deepayan Sarkar wrote:
> > > On Thursday 26 February 2004 14:47, Rajarshi Guha wrote:
> > > > Hi I had two questions regarding plots:
> > > >
> > > > * Is there are way to save a plot in the form of an object such that
> > > > it could be displayed/modified later?
> > >
> > > Depends on what you want to do. Probably not for regular (base) plots.
> >
> > I think ?recordPlot does this, at least to allow plots to be saved,
> > displayed again and added to.
> 
> Ah, I didn't know that.
> 
> > > The
> > > grid package has a concept of objects that can be edited (before
> > > and/or after plotting them). Functions in the lattice package produce
> > > objects that may be close to what you want. They are not plots
> > > themselves, but rather a self-contained description of a plot (in the
> > > sense that they contain the data as well as instructions on how to
> > > plot it). The data part cannot be easily changed, but almost
> > > everything else can be manipulated before plotting.
> >
> > AFAIK that internal description is not documented and there are no
> > end-user tools for doing the manipulation.  Can you please point us to
> > details?   I suspect nothing can _easily_ be changed by end-users at
> > present.
> 
> 
> There has always been an update() method that's supposed to be used for 
> this. No one uses it much, and it probably has a few bugs (but should be 
> improved in time for R 1.9.0). From ?xyplot:
> 
> Value:
> 
>      An object of class ``trellis''. The `update' method can be used to
>      update components of the object and the `print' method (usually
>      called by default) will plot it on an appropriate plotting device.

Ah, I see.  It cannot change the panel function, for example, indeed none 
of the things I was thinking about.  I had thought update() recalculated 
the plot, so I've learned something, thank you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From deepayan at stat.wisc.edu  Fri Feb 27 09:13:28 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 27 Feb 2004 02:13:28 -0600
Subject: [R] saving plots as objects?
In-Reply-To: <Pine.LNX.4.44.0402270757280.3118-100000@gannet.stats>
References: <Pine.LNX.4.44.0402270757280.3118-100000@gannet.stats>
Message-ID: <200402270213.28072.deepayan@stat.wisc.edu>

On Friday 27 February 2004 01:59, Prof Brian Ripley wrote:
> On Fri, 27 Feb 2004, Deepayan Sarkar wrote:

> > There has always been an update() method that's supposed to be used
> > for this. No one uses it much, and it probably has a few bugs (but
> > should be improved in time for R 1.9.0). From ?xyplot:
> >
> > Value:
> >
> >      An object of class ``trellis''. The `update' method can be used
> > to update components of the object and the `print' method (usually
> > called by default) will plot it on an appropriate plotting device.
>
> Ah, I see.  It cannot change the panel function, for example, indeed
> none of the things I was thinking about.  I had thought update()
> recalculated the plot, so I've learned something, thank you.

Well, there's really no reason why the panel function could not be changed, 
and the fact that it cannot is one of the bugs I mentioned. The update 
method should be much better overall in 1.9.0.

Deepayan



From pwolf at wiwi.uni-bielefeld.de  Fri Feb 27 10:16:54 2004
From: pwolf at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Fri, 27 Feb 2004 10:16:54 +0100
Subject: [R] locator(n=0)
Message-ID: <403F0B06.2000600@wiwi.uni-bielefeld.de>

locator(n=1) returns the coordinates of the position of the mouse.
But you have to click the left button of the mouse.
How can I determine the mouse position without any click?
Is it possible to extend locator in a way that  
locator(n=0) outputs the coordinates at once, without any click event?

TclTk allows us to define very nice animations and demonstrations,
see for example:  demo(tkdensity). But sometimes it is much better
to have output and control in one window and to be able to respond
to changes of the cursor position (e.g. to that a bandwidth).

Thanks!

---------------------------------------------------------------------------
Peter Wolf,  pwolf at wiwi.uni-bielefeld.de
Department of economics, University of Bielefeld, Germany



From pascal.dessaux at noos.fr  Fri Feb 27 11:34:11 2004
From: pascal.dessaux at noos.fr (pascal dessaux)
Date: Fri, 27 Feb 2004 11:34:11 +0100
Subject: [R] Get R.lib , how to generate it
Message-ID: <OEEGKALHOGJEPCDLIEDNAEGNCBAA.pascal.dessaux@noos.fr>

Hello

I want to use R as a library in a C/C++ ANSI ISO project

I don't understand how can I generate R.lib with visual C++6 or C++.net;

All libraires I've already used gave the two files: X.lib + X.dll
then I 'am familiar to declare in the compiler:
Project Properties->Linker->Input->Additional Dependencies:X.lib
and put the X.dll closed to the executable program;

how can I generate or get R.lib? what are the precise steps to follow?
(I don't understand where I put what is written in the documentation 
	"First build the import library R.lib by 	
	 lib /def:R.exp /out:Rdll.lib"
in a visual C++ compiler)


thanks

Pascal



From ripley at stats.ox.ac.uk  Fri Feb 27 11:40:16 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 27 Feb 2004 10:40:16 +0000 (GMT)
Subject: [R] locator(n=0)
In-Reply-To: <403F0B06.2000600@wiwi.uni-bielefeld.de>
Message-ID: <Pine.LNX.4.44.0402271032130.3356-100000@gannet.stats>

There is nothing in the design of R base graphics to report the current 
position of the mouse without clicking.  Indeed, the graphics model does 
not presume a mouse and pointer (and probably dates from the days of 
cross-hairs manipulated with thumb wheels), and could conceivably use a 
touchscreen, for example.

The current graphics driver model is not really extensible either,
although Paul Murrell is working on improving this. We can't add features
to one or two graphical devices without changing the API and all the
devices (not all of which are in the R sources).

On Fri, 27 Feb 2004, Peter Wolf wrote:

> locator(n=1) returns the coordinates of the position of the mouse.
> But you have to click the left button of the mouse.
> How can I determine the mouse position without any click?
> Is it possible to extend locator in a way that  
> locator(n=0) outputs the coordinates at once, without any click event?
> 
> TclTk allows us to define very nice animations and demonstrations,
> see for example:  demo(tkdensity). But sometimes it is much better
> to have output and control in one window and to be able to respond
> to changes of the cursor position (e.g. to that a bandwidth).

But Tcl/Tk is a different sort of system, designed for interactive windows 
not plotting graphs.  You could do all this in Tcl/Tk (and there is no 
reason not to have an R graphics device in a Tcl/Tk canvas), or in a 
Java-based graphics device.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From B.Rowlingson at lancaster.ac.uk  Fri Feb 27 12:04:03 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 27 Feb 2004 11:04:03 +0000
Subject: [R] locator(n=0)
In-Reply-To: <403F0B06.2000600@wiwi.uni-bielefeld.de>
References: <403F0B06.2000600@wiwi.uni-bielefeld.de>
Message-ID: <403F2423.9090602@lancaster.ac.uk>

Peter Wolf wrote:
> locator(n=1) returns the coordinates of the position of the mouse.
> But you have to click the left button of the mouse.
> How can I determine the mouse position without any click?
> Is it possible to extend locator in a way that  locator(n=0) outputs the 
> coordinates at once, without any click event?
> 

  I just took twenty minutes to bash devX11.c newX11_Locator routine 
into using XQueryPointer instead of waiting for a mouse event. That 
breaks the 'click to enter point' behaviour though. I couldn't figure 
out how to quickly modify things to just do this for n=0. I cant do 
everything in the twenty mins before morning tea break.

  Its a gross hack, and as Brian says, there's nothing in the design 
that lets you do this, but then since you have the source there's 
nothing on the planet to stop you doing this. The design is not a law :)

  The beauty of open-source code eh? If you really want to do this its 
quite easy. Mail me for more details.

Baz



From subianto at cs.uu.nl  Fri Feb 27 12:28:20 2004
From: subianto at cs.uu.nl (Muhammad Subianto)
Date: Fri, 27 Feb 2004 12:28:20 +0100
Subject: [R] Change the result data
Message-ID: <403F29D4.6070407@cs.uu.nl>

Dear R-helper,

I have a data like:

 > hec.data <-array(c(5,15,20,68,29,54,84,119,14,14,17,26,16,10,94,7),
+            dim=c(4,4),
+            dimnames=list(eye=c("Green","Hazel", "Blue", "Brown"),
+            hair=c("Black", "Brown", "Red", "Blond")))
 > hec.data
       hair
eye     Black Brown Red Blond
  Green     5    29  14    16
  Hazel    15    54  14    10
  Blue     20    84  17    94
  Brown    68   119  26     7
 >

but I want the result like below.:

hair   eye counts
Black Green    5
Black Hazel   15
Black  Blue   20
Black Brown   68
Brown Green   29
Brown Hazel   54
Brown  Blue   84
Brown Brown  119
Red Green     14
Red Hazel     14
Red  Blue     17
Red Brown     26
Blond Green   16
Blond Hazel   10
Blond  Blue   94
Blond Brown    7

How can I do it. Thanks you for your help.

Best regards,
Muhammad Subianto



From pedro.aphalo at cc.jyu.fi  Fri Feb 27 13:07:54 2004
From: pedro.aphalo at cc.jyu.fi (Pedro J. Aphalo)
Date: Fri, 27 Feb 2004 14:07:54 +0200
Subject: [R] nlme and multiple comparisons
In-Reply-To: <4035F1CF.6050105@cc.jyu.fi>
References: <4035F1CF.6050105@cc.jyu.fi>
Message-ID: <403F331A.1080806@cc.jyu.fi>

I received some suggestions about how to do multiple comparisons,
between levels of a factor used as explanatory variable in the
fixed part of a model in an nlme fit. Many thanks!

I also received a request to summarize. So, here is a summary of my 
attempts at following the suggestions, and further questions...

FIRST SUGGESTION

Use the L argument to anova to compute the contrasts.
Then use p.adjust.

Works just fine with nlme objects.

(And results are consistent when changing the
order of levels in the factor used as explanatory variable.)

SECOND SUGGESTION

Use fit.contrast from package gregmisc.

 > library(nlme)
 > library(gregmisc)
 > fit.contrast(fm5bPrun.nlme, "factor(soil.temp)", c(0,-1,1))
Error in nlme.formula(model = log.area ~ fPrunty(day, Asym, Slope, 
Curve,  :
         unused argument(s) (contrasts ...)
 >
nlme does not have a contrasts argument as lme has.
fit.contrast has a method for lme, not for nlme.

Does not work with nlme objects.

THIRD SUGGESTION (actually pointing to an old thread from May 2003)

http://maths.newcastle.edu.au/~rking/R/help/03a/5046.html

Based on the example given by Torsten Hothorn for glm,
and suggested to be adaptable to lme. I tried the following
example, based on an example in chapter 6 of Pinheiro and
Bates (2000): (please note that the model used here is not the
final model described in the book and can be improved, but
it is good enough, I think, for this example.)

##begin R code

library(nlme)
library(multcomp)

data(Soybean)

fm1Soy.lis <- nlsList( weight ~ SSlogis(Time, Asym, xmid, scal),
   data = Soybean )
#fm1Soy.lis
fm1Soy.nlme <- nlme( fm1Soy.lis )
#fm1Soy.nlme
fm2Soy.nlme <- update( fm1Soy.nlme, weights = varPower() )
soyFix <- fixef( fm2Soy.nlme )
options( contrasts = c("contr.treatment", "contr.poly") )
fm3Soy.nlme <- update( fm2Soy.nlme,
   fixed = Asym + xmid + scal ~ Year,
   start = c(soyFix[1], 0, 0, soyFix[2], 0, 0, soyFix[3], 0, 0) )

Soybean$YearTuk <- Soybean$Year
contrasts(Soybean$YearTuk) <- 
mginv(contrMat(table(Soybean$YearTuk),type="Tukey"))

fm3SoyTuk.nlme <- update( fm2Soy.nlme,
   fixed = Asym + xmid + scal ~ YearTuk,
   start = c(soyFix[1], 0, 0, soyFix[2], 0, 0, soyFix[3], 0, 0) )

# and the following for the first parameter Asym:

summary(csimtest(fixef(fm3SoyTuk.nlme)[2:3],fm3SoyTuk.nlme$varFix[2:3,2:3],cmatrix=diag(2),df=477))

#This does not give all the pairwise contrasts, so I
#rearange the order of the levels in the factor, and redo.

Soybean$YearTukRev <- factor(Soybean$Year, levels=c(1990,1989,1988))
contrasts(Soybean$YearTukRev) <- 
mginv(contrMat(table(Soybean$YearTukRev),type="Tukey"))

fm3SoyTukRev.nlme <- update( fm2Soy.nlme,
   fixed = Asym + xmid + scal ~ YearTukRev,
   start = c(soyFix[1], 0, 0, soyFix[2], 0, 0, soyFix[3], 0, 0) )

#and the following for the first parameter Asym:

summary(csimtest(fixef(fm3SoyTukRev.nlme)[2:3],fm3SoyTukRev.nlme$varFix[2:3,2:3],cmatrix=diag(2),df=477))

##end R

But now we have two pairs of simultaneous tests, and the test that
is common gives a totally different P-value for the 1988-1990, versus
1990-1988 comparisons. This difference can be clearly seen
with summary directly on the fitted model objects, where it is easier
to find the coefficient estimates for the tests than in the output of
csimtest. Also note that the estimate of the intercept does not change
when reordering the levels, so what does this represent? And the second
coefficient has not changed either, although at least the name of the
coefficient indicates that it represents a different comparison...

 > summary(fm3SoyTuk.nlme)
(edited)
[...]
Fixed effects: Asym + xmid + scal ~ YearTuk
                          Value Std.Error  DF   t-value p-value
Asym.(Intercept)      16.95143 0.5407434 356  31.34839  0.0000
Asym.YearTuk1989-1988 -9.14093 2.1797271 356  -4.19361  0.0000
Asym.YearTuk1990-1988 -0.62722 2.2891767 356  -0.27400  0.7842
xmid.(Intercept)      51.65615 0.3881693 356 133.07636  0.0000
xmid.YearTuk1989-1988 -0.11277 1.6095886 356  -0.07006  0.9442
xmid.YearTuk1990-1988 -7.21578 1.6281871 356  -4.43179  0.0000
scal.(Intercept)       7.52005 0.0844056 356  89.09412  0.0000
scal.YearTuk1989-1988 -1.20229 0.3470370 356  -3.46444  0.0006
scal.YearTuk1990-1988 -0.39143 0.3667542 356  -1.06727  0.2866
[...]

 > summary(fm3SoyTukRev.nlme)
(edited)
[...]
Fixed effects: Asym + xmid + scal ~ YearTukRev
                             Value Std.Error  DF   t-value p-value
Asym.(Intercept)         16.95152 0.5407411 356  31.34867  0.0000
Asym.YearTukRev1989-1990 -9.14090 2.1797162 356  -4.19362  0.0000
Asym.YearTukRev1988-1990  9.76819 2.4079472 356   4.05665  0.0001
xmid.(Intercept)         51.65625 0.3881701 356 133.07634  0.0000
xmid.YearTukRev1989-1990 -0.11268 1.6095926 356  -0.07001  0.9442
xmid.YearTukRev1988-1990  7.32858 1.7013868 356   4.30742  0.0000
scal.(Intercept)          7.52006 0.0844060 356  89.09388  0.0000
scal.YearTukRev1989-1990 -1.20228 0.3470388 356  -3.46439  0.0006
scal.YearTukRev1988-1990  1.59373 0.3602370 356   4.42411  0.0000
[...]

So I think that I am doing something wrong with the contrasts, but
I do not know what...
So I ask again for help. (I think I can follow the first suggestion
above with my own data, but I am curious about what is going on here...)

Once again, many thanks in advance.

Pedro.


Pedro J. Aphalo wrote:
> This is only partly a question about R, as I am not quite sure about the 
> underlying statistical theory either.
> 
> I have fitted a non-linear mixed-effects model with nlme. In the fixed 
> part of the model I have a factor with three levels as explanatory 
> variable. I would like to use Tukey HSD or a similar test to test for 
> differences between these three levels.
> 
> I have two grouping factors: 'plant' to which the treatments were 
> assigned at random, and 'leaf' which are subsamples.
> 
> With summary, with the default setting for contrasts I get two of the 
> possible three comparisons. One possibility that I can think of is to 
> change the order of the levels in the factor, repeat the fit, use 
> summary again, and finally use p.adjust. Would this be valid?
> 
> Is there a more elegant solution?
> 
> If it matters, the data are slightly unbalanced (missing observations).
> 
> Sorry that this message became so long... Thanks in advance for any 
> suggestions, and I hope I haven't missed the answer when looking at the 
> help pages, FAQ, MASS(3ed) and Pinheiro and Bates' book.
> 
I did miss the L argument to anova...

> Pedro.
> 

-- 
==================================================================
Pedro J. Aphalo
Department of Biological and Environmental Science
University of Jyv?skyl?
P.O. Box 35, 40351 JYV?SKYL?, Finland
Phone  +358 14 260 2339
Mobile +358 50 3721504
Fax    +358 14 260 2321
mailto:pedro.aphalo at cc.jyu.fi
http://www.jyu.fi/~aphalo/                       ,,,^..^,,,



From vito.muggeo at giustizia.it  Fri Feb 27 13:17:13 2004
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Fri, 27 Feb 2004 13:17:13 +0100
Subject: R: [R] Change the result data
References: <403F29D4.6070407@cs.uu.nl>
Message-ID: <001301c3fd2b$a4f5d060$5c13070a@PROCGEN>

as.vector is a possible, simple solution
Also use rep() on dimnames(hec.data)[[1]] to get the names vector with
correct length

> a<-matrix(1:15,ncol=5)
> a
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    4    7   10   13
[2,]    2    5    8   11   14
[3,]    3    6    9   12   15
> as.vector(a)
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15
> as.vector(t(a))
 [1]  1  4  7 10 13  2  5  8 11 14  3  6  9 12 15


hope this helps,
vito


----- Original Message -----
From: Muhammad Subianto <subianto at cs.uu.nl>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, February 27, 2004 12:28 PM
Subject: [R] Change the result data


> Dear R-helper,
>
> I have a data like:
>
>  > hec.data <-array(c(5,15,20,68,29,54,84,119,14,14,17,26,16,10,94,7),
> +            dim=c(4,4),
> +            dimnames=list(eye=c("Green","Hazel", "Blue", "Brown"),
> +            hair=c("Black", "Brown", "Red", "Blond")))
>  > hec.data
>        hair
> eye     Black Brown Red Blond
>   Green     5    29  14    16
>   Hazel    15    54  14    10
>   Blue     20    84  17    94
>   Brown    68   119  26     7
>  >
>
> but I want the result like below.:
>
> hair   eye counts
> Black Green    5
> Black Hazel   15
> Black  Blue   20
> Black Brown   68
> Brown Green   29
> Brown Hazel   54
> Brown  Blue   84
> Brown Brown  119
> Red Green     14
> Red Hazel     14
> Red  Blue     17
> Red Brown     26
> Blond Green   16
> Blond Hazel   10
> Blond  Blue   94
> Blond Brown    7
>
> How can I do it. Thanks you for your help.
>
> Best regards,
> Muhammad Subianto
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.pagel at gsf.de  Fri Feb 27 13:14:43 2004
From: p.pagel at gsf.de (Philipp Pagel)
Date: Fri, 27 Feb 2004 13:14:43 +0100
Subject: [R] Change the result data
In-Reply-To: <403F29D4.6070407@cs.uu.nl>
References: <403F29D4.6070407@cs.uu.nl>
Message-ID: <20040227121443.GA3931@porcupine.gsf.de>


Using stack() would be a possibility:

> a <- stack(as.data.frame(hec.data))
> a$eye=rownames(hec.data)
> a
   values   ind   eye
1       5 Black Green
2      15 Black Hazel
3      20 Black  Blue
4      68 Black Brown
5      29 Brown Green
6      54 Brown Hazel
7      84 Brown  Blue
8     119 Brown Brown
9      14   Red Green
10     14   Red Hazel
11     17   Red  Blue
12     26   Red Brown
13     16 Blond Green
14     10 Blond Hazel
15     94 Blond  Blue
16      7 Blond Brown


Also have a look at reshape().

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany
http://mips.gsf.de/~pagel



From jfox at mcmaster.ca  Fri Feb 27 13:27:05 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 27 Feb 2004 07:27:05 -0500
Subject: [R] Change the result data
In-Reply-To: <403F29D4.6070407@cs.uu.nl>
Message-ID: <20040227122705.KNUF25409.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Muhammad,

One approach is:

	class(hec.data) <- "table"
	as.data.frame(hec.data)

I hope that this helps,
 John
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Muhammad Subianto
> Sent: Friday, February 27, 2004 6:28 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Change the result data
> 
> Dear R-helper,
> 
> I have a data like:
> 
>  > hec.data <-array(c(5,15,20,68,29,54,84,119,14,14,17,26,16,10,94,7),
> +            dim=c(4,4),
> +            dimnames=list(eye=c("Green","Hazel", "Blue", "Brown"),
> +            hair=c("Black", "Brown", "Red", "Blond")))
>  > hec.data
>        hair
> eye     Black Brown Red Blond
>   Green     5    29  14    16
>   Hazel    15    54  14    10
>   Blue     20    84  17    94
>   Brown    68   119  26     7
>  >
> 
> but I want the result like below.:
> 
> hair   eye counts
> Black Green    5
> Black Hazel   15
> Black  Blue   20
> Black Brown   68
> Brown Green   29
> Brown Hazel   54
> Brown  Blue   84
> Brown Brown  119
> Red Green     14
> Red Hazel     14
> Red  Blue     17
> Red Brown     26
> Blond Green   16
> Blond Hazel   10
> Blond  Blue   94
> Blond Brown    7
> 
> How can I do it. Thanks you for your help.
> 
> Best regards,
> Muhammad Subianto



From joehl at gmx.de  Fri Feb 27 14:10:49 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Fri, 27 Feb 2004 14:10:49 +0100 (MET)
Subject: [R] Is there a way to deactivate partial matching in R?
Message-ID: <20329.1077887449@www21.gmx.net>


Dear R-experts,

I just tracked down a nasty bug in a dynamically parametrized function to
wrong argument matching. As we get more and more complex applications build on
top of R (like bioconductor) partial matching gets more and more dangerous. I
would like to deactivate partial matching in R (partial argument matching as
well as partial matching of list elements), e.g. using an environment
variable. If this is currently not possible this would be my current most important
wishlist topic. 

Best regards


Jens Oehlschl?gel

--



From subianto at cs.uu.nl  Fri Feb 27 14:35:13 2004
From: subianto at cs.uu.nl (Muhammad Subianto)
Date: Fri, 27 Feb 2004 14:35:13 +0100
Subject: [R] Change the result data (thanks you)
In-Reply-To: <x2llmoenxf.fsf@biostat.ku.dk>
References: <403F29D4.6070407@cs.uu.nl> <x2llmoenxf.fsf@biostat.ku.dk>
Message-ID: <403F4791.1040409@cs.uu.nl>

Dear R-helper,
I use like this below (from Prof. Peter Dalgaard) and thanks to other 
R-helper for your help.

Best regard,

Muhammad Subianto

>>as.data.frame(as.table(hec.data))
>>    
>>
>     eye  hair Freq
>1  Green Black    5
>2  Hazel Black   15
>3   Blue Black   20
>....
>
>  
>



From MSchwartz at medanalytics.com  Fri Feb 27 14:51:02 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 27 Feb 2004 07:51:02 -0600
Subject: [R] Is there a way to deactivate partial matching in R?
In-Reply-To: <20329.1077887449@www21.gmx.net>
References: <20329.1077887449@www21.gmx.net>
Message-ID: <1077889862.24396.83.camel@localhost.localdomain>

On Fri, 2004-02-27 at 07:10, "Jens Oehlschl?gel" wrote:
> Dear R-experts,
> 
> I just tracked down a nasty bug in a dynamically parametrized function to
> wrong argument matching. As we get more and more complex applications build on
> top of R (like bioconductor) partial matching gets more and more dangerous. I
> would like to deactivate partial matching in R (partial argument matching as
> well as partial matching of list elements), e.g. using an environment
> variable. If this is currently not possible this would be my current most important
> wishlist topic. 


As a temporary solution for the argument matching issue, you could
modify the code for match.arg() and add a T/F 'exact' argument, thus
using either match() or pmatch(), the latter of which is the present
default. match.arg() is a fairly short function.

my.match.arg <- function (arg, choices, exact = FALSE) 
{
    if (missing(choices)) {
        formal.args <- formals(sys.function(sys.parent()))
        choices <- eval(formal.args[[deparse(substitute(arg))]])
    }
    if (all(arg == choices)) 
        return(choices[1])

    # HERE IS THE MODIFIED CODE
    if (exact)
      i <- match(arg, choices)
    else
      i <- pmatch(arg, choices)
    # END MODIFIED CODE

    if (is.na(i)) 
        stop(paste("ARG should be one of", 
             paste(choices, collapse = ", "), sep = " "))
    if (length(i) > 1) 
        stop("there is more than one match in match.arg")
    choices[i]
}

I did not add any additional error checking code here or how you want to
handle non-matches, since that maybe unique to your application. 

I am not sure what you are using for list element matching (charmatch?),
but a similar approach can feasibly be taken there, keeping in mind that
charmatch() is a .Internal.

In terms of global variables, you can always add one to your environment
(ie. using .Rprofile). In that case, you could use the following in
place of the four lines above, after setting options(exact) to a default
value (ie.  options(exact = TRUE) ):

    if (options()$exact)
      i <- match(arg, choices)
    else
      i <- pmatch(arg, choices)

You would of course need to ensure that options()$exact is unique based
upon the addition of non-base packages and then leave off the 'exact'
argument as I have the function defined above.

I hope that this helps, keeping in mind I am only on my first cup of
coffee so far this morning...  :-)

Marc Schwartz



From claudiapaladini at web.de  Fri Feb 27 16:15:12 2004
From: claudiapaladini at web.de (Claudia Paladini)
Date: Fri, 27 Feb 2004 16:15:12 +0100
Subject: [R] <no subject>
Message-ID: <200402271515.i1RFFCQ28589@mailgate5.cinetic.de>

Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit
X-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on hypatia.math.ethz.ch
X-Spam-Status: No, hits=1.7 required=5.0 tests=AWL,BAYES_44,RCVD_IN_BL_SPAMCOP_NET autolearn=no version=2.63
X-Spam-Level: *

Dear Ladies and gentlemen,
I'm looking for a means in R to test whether a timese series is stationary or not.
Can somebody help me?
Kind regards
Claudia
______________________________________________________________________________
Nachrichten, Musik und Spiele schnell und einfach per Quickstart im



From svetlana.eden at vanderbilt.edu  Fri Feb 27 16:56:30 2004
From: svetlana.eden at vanderbilt.edu (Svetlana Eden)
Date: Fri, 27 Feb 2004 09:56:30 -0600
Subject: [R] question
Message-ID: <20040227095630.59042268.svetlana.eden@vanderbilt.edu>

Hi everybody.

The question:
I get two vectors 'iFalseFalse' and 'i2'.
I think they should be the same but they are not.
Is it because 
R does not handle complicated logical expressions in such cases 
or I do something wrong?


> z1 = c(NA, "", 3, NA, "", 3)
> z2 = c("", "", 3, NA, 3, NA)
> cV = (as.character(z1)==as.character(z2))
> cV
[1]    NA  TRUE  TRUE    NA FALSE    NA
>
> iFalse = (c(1:(length(z1))))[(cV==FALSE)]
> iNonNA = (c(1:(length(z1))))[(!(is.na(cV)))]
> iFalse
[1] NA NA  5 NA
>
> iNonNA
[1] 2 3 5
>
> iFalseFalse = intersect(iFalse, iNonNA)
> iFalseFalse
[1] 5
> i2 = (c(1:(length(z1))))[( (cV==FALSE)&&(!(is.na(cV))) )]
> i2
numeric(0)
>

-- 
Svetlana Eden        Biostatistician II            School of Medicine
                     Department of Biostatistics   Vanderbilt University



From edd at debian.org  Fri Feb 27 17:00:17 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 27 Feb 2004 10:00:17 -0600
Subject: [R] locator(n=0)
In-Reply-To: <403F0B06.2000600@wiwi.uni-bielefeld.de>
References: <403F0B06.2000600@wiwi.uni-bielefeld.de>
Message-ID: <20040227160017.GA16022@sonny.eddelbuettel.com>


Peter,

On Fri, Feb 27, 2004 at 10:16:54AM +0100, Peter Wolf wrote:
> locator(n=1) returns the coordinates of the position of the mouse.
> But you have to click the left button of the mouse.
> How can I determine the mouse position without any click?
> Is it possible to extend locator in a way that  
> locator(n=0) outputs the coordinates at once, without any click event?
> 
> TclTk allows us to define very nice animations and demonstrations,
> see for example:  demo(tkdensity). But sometimes it is much better
> to have output and control in one window and to be able to respond
> to changes of the cursor position (e.g. to that a bandwidth).

James Wettenhall has an example of how to do that using tcltk. The window
manager gives us back x,y pixel coordinates, which can be converted back to
plot coordinates using par("usr") and par("plt") -- it's pretty much all
there on James' example page at
  http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/InteractiveTkrPlot.html
  
Hth, Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From andy_liaw at merck.com  Fri Feb 27 17:02:35 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 27 Feb 2004 11:02:35 -0500
Subject: [R] question
Message-ID: <3A822319EB35174CA3714066D590DCD504AF78AB@usrymx25.merck.com>

You need know about the difference between & and && (and between | and ||).

Andy

> From: Svetlana Eden
> 
> Hi everybody.
> 
> The question:
> I get two vectors 'iFalseFalse' and 'i2'.
> I think they should be the same but they are not.
> Is it because 
> R does not handle complicated logical expressions in such cases 
> or I do something wrong?
> 
> 
> > z1 = c(NA, "", 3, NA, "", 3)
> > z2 = c("", "", 3, NA, 3, NA)
> > cV = (as.character(z1)==as.character(z2))
> > cV
> [1]    NA  TRUE  TRUE    NA FALSE    NA
> >
> > iFalse = (c(1:(length(z1))))[(cV==FALSE)]
> > iNonNA = (c(1:(length(z1))))[(!(is.na(cV)))]
> > iFalse
> [1] NA NA  5 NA
> >
> > iNonNA
> [1] 2 3 5
> >
> > iFalseFalse = intersect(iFalse, iNonNA)
> > iFalseFalse
> [1] 5
> > i2 = (c(1:(length(z1))))[( (cV==FALSE)&&(!(is.na(cV))) )]
> > i2
> numeric(0)
> >
> 
> -- 
> Svetlana Eden        Biostatistician II            School of Medicine
>                      Department of Biostatistics   Vanderbilt 
> University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From susan_lin99 at yahoo.com  Fri Feb 27 17:05:10 2004
From: susan_lin99 at yahoo.com (Susan Lin)
Date: Fri, 27 Feb 2004 08:05:10 -0800 (PST)
Subject: [R] How to save images?
Message-ID: <20040227160510.80591.qmail@web21207.mail.yahoo.com>

After I use function plot() to get an image, how can I
save the image or export it to .gif or other digital
formats?


Thanks a lot.



From maustin at amgen.com  Fri Feb 27 17:05:09 2004
From: maustin at amgen.com (Austin, Matt)
Date: Fri, 27 Feb 2004 08:05:09 -0800
Subject: [R] question
Message-ID: <E7D5AB4811D20B489622AABA9C538591A32344@teal-exch.amgen.com>

You want to use & instead of &&.

--Matt

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Svetlana Eden
Sent: Friday, February 27, 2004 7:57 AM
To: r-help
Subject: [R] question


Hi everybody.

The question:
I get two vectors 'iFalseFalse' and 'i2'.
I think they should be the same but they are not.
Is it because 
R does not handle complicated logical expressions in such cases 
or I do something wrong?


> z1 = c(NA, "", 3, NA, "", 3)
> z2 = c("", "", 3, NA, 3, NA)
> cV = (as.character(z1)==as.character(z2))
> cV
[1]    NA  TRUE  TRUE    NA FALSE    NA
>
> iFalse = (c(1:(length(z1))))[(cV==FALSE)]
> iNonNA = (c(1:(length(z1))))[(!(is.na(cV)))]
> iFalse
[1] NA NA  5 NA
>
> iNonNA
[1] 2 3 5
>
> iFalseFalse = intersect(iFalse, iNonNA)
> iFalseFalse
[1] 5
> i2 = (c(1:(length(z1))))[( (cV==FALSE)&&(!(is.na(cV))) )]
> i2
numeric(0)
>

-- 
Svetlana Eden        Biostatistician II            School of Medicine
                     Department of Biostatistics   Vanderbilt University

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From pcampbell at econ.bbk.ac.uk  Fri Feb 27 17:09:42 2004
From: pcampbell at econ.bbk.ac.uk (Phineas Campbell)
Date: Fri, 27 Feb 2004 16:09:42 -0000
Subject: [R] <no subject>
In-Reply-To: <200402271515.i1RFFCQ28589@mailgate5.cinetic.de>
Message-ID: <NGECIFANPOJAGABBAEAPGENFCKAA.pcampbell@econ.bbk.ac.uk>

The function PP.test in the ts library will test the null that the series
has a unit root vs the series is stationary.

HTH Phineas Campbell



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Claudia Paladini
Sent: Friday, February 27, 2004 3:15 PM
To: R-help at stat.math.ethz.ch
Subject: [R] <no subject>


Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit
X-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on
hypatia.math.ethz.ch
X-Spam-Status: No, hits=1.7 required=5.0
tests=AWL,BAYES_44,RCVD_IN_BL_SPAMCOP_NET autolearn=no version=2.63
X-Spam-Level: *

Dear Ladies and gentlemen,
I'm looking for a means in R to test whether a timese series is stationary
or not.
Can somebody help me?
Kind regards
Claudia
____________________________________________________________________________
__
Nachrichten, Musik und Spiele schnell und einfach per Quickstart im

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Feb 27 17:22:31 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 27 Feb 2004 17:22:31 +0100
Subject: [R] question
In-Reply-To: <20040227095630.59042268.svetlana.eden@vanderbilt.edu>
References: <20040227095630.59042268.svetlana.eden@vanderbilt.edu>
Message-ID: <403F6EC7.1070809@statistik.uni-dortmund.de>

Svetlana Eden wrote:

> Hi everybody.
> 
> The question:
> I get two vectors 'iFalseFalse' and 'i2'.
> I think they should be the same but they are not.
> Is it because 
> R does not handle complicated logical expressions in such cases 
> or I do something wrong?
> 
> 
> 
>>z1 = c(NA, "", 3, NA, "", 3)
>>z2 = c("", "", 3, NA, 3, NA)
>>cV = (as.character(z1)==as.character(z2))
>>cV
> 
> [1]    NA  TRUE  TRUE    NA FALSE    NA
> 
>>iFalse = (c(1:(length(z1))))[(cV==FALSE)]
>>iNonNA = (c(1:(length(z1))))[(!(is.na(cV)))]
>>iFalse
> 
> [1] NA NA  5 NA
> 
>>iNonNA
> 
> [1] 2 3 5
> 
>>iFalseFalse = intersect(iFalse, iNonNA)
>>iFalseFalse
> 
> [1] 5
> 
>>i2 = (c(1:(length(z1))))[( (cV==FALSE)&&(!(is.na(cV))) )]
>>i2
> 
> numeric(0)
> 
> 

Each line's results as expected.
In the last line, you are going to use "&" instead of "&&"!

Uwe Ligges



From andy_liaw at merck.com  Fri Feb 27 17:24:07 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 27 Feb 2004 11:24:07 -0500
Subject: [R] How to save images?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF78AC@usrymx25.merck.com>

On Windows, use the `File' menu.  On other platforms, see the help page for
dev.copy, png, jpeg, and bitmap.

HTH,
Andy

> From: Susan Lin
> 
> After I use function plot() to get an image, how can I
> save the image or export it to .gif or other digital
> formats?
> 
> 
> Thanks a lot.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From prodrigues at dcc.fc.up.pt  Fri Feb 27 17:17:22 2004
From: prodrigues at dcc.fc.up.pt (Pedro Rodrigues)
Date: 27 Feb 2004 16:17:22 +0000
Subject: [R] How to save images?
In-Reply-To: <20040227160510.80591.qmail@web21207.mail.yahoo.com>
References: <20040227160510.80591.qmail@web21207.mail.yahoo.com>
Message-ID: <1077898642.3632.2.camel@atlantic.ocean>

Maybe you could just PrintScreen or use the pdf() function which uses
one or several pdf files instead of the default graphical device.

> After I use function plot() to get an image, how can I
> save the image or export it to .gif or other digital
> formats?
> 
> 
> Thanks a lot.
> 
-- 
-------------------------------------------------------
                Pedro Pereira Rodrigues
          http://www.dcc.fc.up.pt/~prodrigues/

    Artificial Intelligence and Data Analysis Group
Artificial Intelligence and Computer Science Laboratory
(+351)226078830 - Ext: 121          University of Porto



From paulojus at est.ufpr.br  Fri Feb 27 17:26:45 2004
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Fri, 27 Feb 2004 13:26:45 -0300 (BRT)
Subject: [R] How to save images?
In-Reply-To: <20040227160510.80591.qmail@web21207.mail.yahoo.com>
References: <20040227160510.80591.qmail@web21207.mail.yahoo.com>
Message-ID: <Pine.LNX.4.58L0.0402271324580.8620@est.ufpr.br>

Try this:

jpeg("file1.jpg")
plot(rnorm(20))
dev.off()

and check the jpg file created by this.
Also, check help files:
?jpeg
?postscript
?png



On Fri, 27 Feb 2004, Susan Lin wrote:

> After I use function plot() to get an image, how can I
> save the image or export it to .gif or other digital
> formats?
>
>
> Thanks a lot.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From Timur.Elzhov at jinr.ru  Fri Feb 27 17:28:53 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri, 27 Feb 2004 19:28:53 +0300
Subject: [R] How to save images?
In-Reply-To: <20040227160510.80591.qmail@web21207.mail.yahoo.com>
References: <20040227160510.80591.qmail@web21207.mail.yahoo.com>
Message-ID: <20040227162853.GA4187@nf034.jinr.ru>

On Fri, Feb 27, 2004 at 08:05:10AM -0800, Susan Lin wrote:

> After I use function plot() to get an image, how can I
> save the image or export it to .gif or other digital
> formats?

?device

--
WBR,
Timur



From Sinnwell.Jason at mayo.edu  Fri Feb 27 17:26:48 2004
From: Sinnwell.Jason at mayo.edu (Jason Sinnwell)
Date: Fri, 27 Feb 2004 10:26:48 -0600 (CST)
Subject: [R] load data for mypkg-Ex.R
Message-ID: <200402271626.i1RGQm522011@rocky.mayo.edu>

Using R 1.7.1 in Solaris

I'm developing a package for both Splus and R, and I'm trying to use all the 
same files for R and Splus, both function files and help files.  I have two 
questions.

1) The file made by R CMD check to run .Rd-examples posts examples from files in 
alphabetical order.  Is it okay/recommended/common-practice to set up all the 
example data in the first two (alphabetically-sorted) examples and assume that 
data exists for the rest of the examples?  

2)  Since data() is not understood by Splus, I don't want to put a 
	     > data(example.data) 
in the sgml file because then the Splus example would not run as data() doesn't 
exist there.  Is there a spot I can make sure this data is loaded when running 
the examples, but not to load the data every time you load the library, as it 
would take up unnecessary space.  It is a ~~220 x 25 data.frame, is that enough 
size to worry about this? 
I'm considering using the NAMESPACE or .First.lib() within zzz.R but that would 
load the data every time the library is loaded.  Also considering something 
like:
>if (<check for R using is.R()>)
>  data(example.data)
> <run example>

In the example but that would create confusion for users.  

Thanks for your suggestions.

+--------------------------+
|Jason Sinnwell, M.S.   |
|Mayo Clinic, Rochester    |



From abunn at montana.edu  Fri Feb 27 17:39:35 2004
From: abunn at montana.edu (Andy Bunn)
Date: Fri, 27 Feb 2004 09:39:35 -0700
Subject: [R] How to save images?
In-Reply-To: <20040227160510.80591.qmail@web21207.mail.yahoo.com>
Message-ID: <003101c3fd50$4bd4e3c0$78f05a99@msu.montana.edu>

Try the FAQ
http://cran.r-project.org/faqs.html
Or one of the manuals
http://cran.r-project.org/faqs.html
But first read the posting guide
http://www.R-project.org/posting-guide.html


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Susan Lin
> Sent: Friday, February 27, 2004 9:05 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] How to save images?
> 
> 
> After I use function plot() to get an image, how can I
> save the image or export it to .gif or other digital
> formats?
> 
> 
> Thanks a lot.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From svetlana.eden at vanderbilt.edu  Fri Feb 27 18:18:26 2004
From: svetlana.eden at vanderbilt.edu (Svetlana Eden)
Date: Fri, 27 Feb 2004 11:18:26 -0600
Subject: [R] question about setdiff()
Message-ID: <20040227111826.26aec73e.svetlana.eden@vanderbilt.edu>


Thank you for your answers,
I have another question:

the behaviour of setdiff(indicesFalse, indicesNA)
does not seem predictable to me.


> indices
[1] 1 2 3 4 5 6
> compareVector
[1]    NA  TRUE  TRUE  TRUE FALSE    NA
>   indicesNA = indices[is.na(compareVector)]
>   indicesNA
[1] 1 6
>   indicesFalse = indices[compareVector == FALSE]
>   indicesFalse
[1] NA  5 NA
>   setdiff(indicesNA, indicesFalse) ######################## OK
[1] 1 6
>   setdiff(indicesFalse, indicesNA) ######################## I would
>   expect here 'NA 5 NA'
[1] NA  5
>


-- 
Svetlana Eden        Biostatistician II            School of Medicine
                     Department of Biostatistics   Vanderbilt University



From svetlana.eden at vanderbilt.edu  Fri Feb 27 19:12:21 2004
From: svetlana.eden at vanderbilt.edu (Svetlana Eden)
Date: Fri, 27 Feb 2004 12:12:21 -0600
Subject: [R] question about if else
Message-ID: <20040227121221.3050a40d.svetlana.eden@vanderbilt.edu>


Today is a good day for asking question, I guess.

> c()
NULL
>
> length(c())==0
[1] TRUE
>
> r = ifelse(length(c())!=0, c(), c(1,2))  ### OK
> r = c()                                  ### OK
> r = ifelse(length(c())==0, c(), c(1,2))  ### why this is not OK (given
> the previous two)?       
Error in "[<-"(`*tmp*`, test, value = rep(yes, length =
length(ans))[test]) :
        incompatible types
>
> c() == NULL
logical(0)
>
> r = ifelse(c()==NULL, c(), c(1,2))       ### why this line does not 
> r                                        ### result in error -
logical(0)                                 ### 'c()==NULL' is not TRUE
and not FALSE ?
>
>

-- 
Svetlana Eden        Biostatistician II            School of Medicine
                     Department of Biostatistics   Vanderbilt University



From tlumley at u.washington.edu  Fri Feb 27 19:20:50 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 27 Feb 2004 10:20:50 -0800 (PST)
Subject: [R] load data for mypkg-Ex.R
In-Reply-To: <200402271626.i1RGQm522011@rocky.mayo.edu>
References: <200402271626.i1RGQm522011@rocky.mayo.edu>
Message-ID: <Pine.A41.4.58.0402271013260.127932@homer04.u.washington.edu>

On Fri, 27 Feb 2004, Jason Sinnwell wrote:

> Using R 1.7.1 in Solaris
>
> I'm developing a package for both Splus and R, and I'm trying to use all the
> same files for R and Splus, both function files and help files.  I have two
> questions.
>
> 1) The file made by R CMD check to run .Rd-examples posts examples from files in
> alphabetical order.  Is it okay/recommended/common-practice to set up all the
> example data in the first two (alphabetically-sorted) examples and assume that
> data exists for the rest of the examples?

No.  In fact, it is specifically disallowed.

> 2)  Since data() is not understood by Splus, I don't want to put a
> 	     > data(example.data)
> in the sgml file because then the Splus example would not run as data() doesn't
> exist there.  Is there a spot I can make sure this data is loaded when running
> the examples, but not to load the data every time you load the library, as it
> would take up unnecessary space.  It is a ~~220 x 25 data.frame, is that enough
> size to worry about this?

I wouldn't think it was big enough to worry seriously about

> I'm considering using the NAMESPACE or .First.lib() within zzz.R but that would
> load the data every time the library is loaded.  Also considering something
> like:
> >if (<check for R using is.R()>)
> >  data(example.data)
> > <run example>
>
> In the example but that would create confusion for users.

You could define a function

if (is.R())
  setupData<-data
else
  setupData<-function(...) invisible(NULL)

and then use setupData() instead of data(), or you could look at what MASS
does using delay() to autoload data as needed.


	-thomas



From ripley at stats.ox.ac.uk  Fri Feb 27 19:25:57 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 27 Feb 2004 18:25:57 +0000 (GMT)
Subject: [R] load data for mypkg-Ex.R
In-Reply-To: <200402271626.i1RGQm522011@rocky.mayo.edu>
Message-ID: <Pine.LNX.4.44.0402271822550.16912-100000@gannet.stats>

On Fri, 27 Feb 2004, Jason Sinnwell wrote:

> Using R 1.7.1 in Solaris
> 
> I'm developing a package for both Splus and R, and I'm trying to use all the 
> same files for R and Splus, both function files and help files.  I have two 
> questions.
> 
> 1) The file made by R CMD check to run .Rd-examples posts examples from files in 
> alphabetical order.  Is it okay/recommended/common-practice to set up all the 
> example data in the first two (alphabetically-sorted) examples and assume that 
> data exists for the rest of the examples?  

That does not work: the workspace is cleared after each help file.  As 
from the next release, the search path is restored too.

> 2)  Since data() is not understood by Splus, I don't want to put a 
> 	     > data(example.data) 
> in the sgml file because then the Splus example would not run as data() doesn't 
> exist there.  Is there a spot I can make sure this data is loaded when running 
> the examples, but not to load the data every time you load the library, as it 
> would take up unnecessary space.  It is a ~~220 x 25 data.frame, is that enough 
> size to worry about this?

Probably not: but use object.size() to find out.
 
> I'm considering using the NAMESPACE or .First.lib() within zzz.R but that would 
> load the data every time the library is loaded.  Also considering something 
> like:
> >if (<check for R using is.R()>)
> >  data(example.data)
> > <run example>
> 
> In the example but that would create confusion for users.  

Take a look at how package MASS does this, via a promise.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Fri Feb 27 19:35:37 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 27 Feb 2004 13:35:37 -0500
Subject: [R] question about setdiff()
Message-ID: <3A822319EB35174CA3714066D590DCD504AF78AF@usrymx25.merck.com>

`Same' object appearing more than once do not count, I guess.  As an
example:

> setdiff(c(1,2,2), c(3,4))
[1] 1 2

The second `2' does not show up, because

> setdiff
function (x, y) 
unique(if (length(x) || length(y)) x[match(x, y, 0) == 0] else x)
<environment: namespace:base>

Note the unique().

Andy

> From: Svetlana Eden
> 
> 
> Thank you for your answers,
> I have another question:
> 
> the behaviour of setdiff(indicesFalse, indicesNA)
> does not seem predictable to me.
> 
> 
> > indices
> [1] 1 2 3 4 5 6
> > compareVector
> [1]    NA  TRUE  TRUE  TRUE FALSE    NA
> >   indicesNA = indices[is.na(compareVector)]
> >   indicesNA
> [1] 1 6
> >   indicesFalse = indices[compareVector == FALSE]
> >   indicesFalse
> [1] NA  5 NA
> >   setdiff(indicesNA, indicesFalse) ######################## OK
> [1] 1 6
> >   setdiff(indicesFalse, indicesNA) ######################## I would
> >   expect here 'NA 5 NA'
> [1] NA  5
> >
> 
> 
> -- 
> Svetlana Eden        Biostatistician II            School of Medicine
>                      Department of Biostatistics   Vanderbilt 
> University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From andy_liaw at merck.com  Fri Feb 27 20:05:33 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 27 Feb 2004 14:05:33 -0500
Subject: [R] question about if else
Message-ID: <3A822319EB35174CA3714066D590DCD504AF78B0@usrymx25.merck.com>

You need to (re-)read ?ifelse.  In ifelse(L, v1, v2), L is suppose to be a
vector of logicals (or an expression that evaluates to one), and v1 and v2
are vectors of same length as L; i.e., ifelse() vectorizes if ... else ....
In the first case:

  r = ifelse(length(c())!=0, c(), c(1,2)) 

length(c()) != 0 is FALSE, so you just get 1 as the answer.  In the second
case,

  r = ifelse(length(c())==0, c(), c(1,2))

length(c()) == 0 is TRUE, so ifelse tries to return the first element of
c(), which does not exist.

I suspect you really want if ... else ....

Andy

> From: Svetlana Eden
> 
> Today is a good day for asking question, I guess.
> 
> > c()
> NULL
> >
> > length(c())==0
> [1] TRUE
> >
> > r = ifelse(length(c())!=0, c(), c(1,2))  ### OK
> > r = c()                                  ### OK
> > r = ifelse(length(c())==0, c(), c(1,2))  ### why this is 
> not OK (given
> > the previous two)?       
> Error in "[<-"(`*tmp*`, test, value = rep(yes, length =
> length(ans))[test]) :
>         incompatible types
> >
> > c() == NULL
> logical(0)
> >
> > r = ifelse(c()==NULL, c(), c(1,2))       ### why this line does not 
> > r                                        ### result in error -
> logical(0)                                 ### 'c()==NULL' is not TRUE
> and not FALSE ?
> >
> >
> 
> -- 
> Svetlana Eden        Biostatistician II            School of Medicine
>                      Department of Biostatistics   Vanderbilt 
> University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From macq at llnl.gov  Fri Feb 27 20:12:47 2004
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 27 Feb 2004 11:12:47 -0800
Subject: [R] question about if else
In-Reply-To: <20040227121221.3050a40d.svetlana.eden@vanderbilt.edu>
References: <20040227121221.3050a40d.svetlana.eden@vanderbilt.edu>
Message-ID: <p06002007bc654610996d@[128.115.153.6]>


ifelse() has three arguments, named 'test', 'yes', and 'no'.

In both of your two examples, you gave it a test argument of length equal to 1.
That is, both
   length(c())!=0
and
   length(c())==0
are expressions which when evaluated have length equal to 1.

Therefore, the ifelse() function wants to return an object of length 
1. So, it wants to return the first element of either the 'yes' 
argument, or the 'no' argument, depending on whether test is true or 
false. But c() has length zero, there is no first element available 
to return. So you get an error message.

-Don

At 12:12 PM -0600 2/27/04, Svetlana Eden wrote:
>Today is a good day for asking question, I guess.
>
>>  c()
>NULL
>>
>>  length(c())==0
>[1] TRUE
>>
>  > r = ifelse(length(c())!=0, c(), c(1,2))  ### OK
>>  r = c()                                  ### OK
>>  r = ifelse(length(c())==0, c(), c(1,2))  ### why this is not OK (given
>>  the previous two)?      
>Error in "[<-"(`*tmp*`, test, value = rep(yes, length =
>length(ans))[test]) :
>         incompatible types
>>
>>  c() == NULL
>logical(0)
>>
>>  r = ifelse(c()==NULL, c(), c(1,2))       ### why this line does not
>>  r                                        ### result in error -
>logical(0)                                 ### 'c()==NULL' is not TRUE
>and not FALSE ?
>>
>>
>
>--
>Svetlana Eden        Biostatistician II            School of Medicine
>                      Department of Biostatistics   Vanderbilt University
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From jjgazaille at yahoo.ca  Fri Feb 27 20:16:20 2004
From: jjgazaille at yahoo.ca (Joseph J. Gazaille)
Date: Fri, 27 Feb 2004 14:16:20 -0500 (EST)
Subject: [R] How to recover t-statistics?
Message-ID: <20040227191620.6561.qmail@web60909.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040227/24cce379/attachment.pl

From sundar.dorai-raj at pdf.com  Fri Feb 27 20:51:04 2004
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 27 Feb 2004 13:51:04 -0600
Subject: [R] How to recover t-statistics?
In-Reply-To: <20040227191620.6561.qmail@web60909.mail.yahoo.com>
References: <20040227191620.6561.qmail@web60909.mail.yahoo.com>
Message-ID: <403F9FA8.3060306@pdf.com>


Joseph J. Gazaille wrote:

> Hi!
>  
> I'm doing Monte Carlo analyses of the distribution 
> of the t-statistics of the parameters of models evaluated 
> with the lm( ) function.
>  
> Is there an easy way to recover the t-statistics
> (similarly to using coef to recover the coefficients)?
>  
> Thanks,
>  
> joseph

Try

tstat <- summary(fit)$coef[, "t value"]

or

tstat <- coef(fit)/sqrt(diag(vcov(fit)))

-sundar



From ripley at stats.ox.ac.uk  Fri Feb 27 20:57:02 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 27 Feb 2004 19:57:02 +0000 (GMT)
Subject: [R] How to recover t-statistics?
In-Reply-To: <20040227191620.6561.qmail@web60909.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0402271956120.17067-100000@gannet.stats>

On Fri, 27 Feb 2004, Joseph J. Gazaille wrote:

> Hi!
>  
> I'm doing Monte Carlo analyses of the distribution 
> of the t-statistics of the parameters of models evaluated 
> with the lm( ) function.
>  
> Is there an easy way to recover the t-statistics
> (similarly to using coef to recover the coefficients)?

Try coef(summary(myfit))

and see what you get ...  ?summary.lm may help you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rnews at kernstat.com  Fri Feb 27 21:08:24 2004
From: rnews at kernstat.com (Remington, Richard)
Date: Fri, 27 Feb 2004 13:08:24 -0700
Subject: [R] How to recover t-statistics?
In-Reply-To: <20040227191620.6561.qmail@web60909.mail.yahoo.com>
References: <20040227191620.6561.qmail@web60909.mail.yahoo.com>
Message-ID: <403FA3B8.6090305@kernstat.com>

Joseph J. Gazaille wrote:

> Hi!
>  
> I'm doing Monte Carlo analyses of the distribution 
> of the t-statistics of the parameters of models evaluated 
> with the lm( ) function.
>  
> Is there an easy way to recover the t-statistics
> (similarly to using coef to recover the coefficients)?
>  
> Thanks,
>  
> joseph


Joseph

One option is

out <- lm(y~x)
summary(out)$coef
#              Estimate Std. Error  t value  Pr(>|t|)
# (Intercept)         ?          ?        ?         ?
#          x          ?          ?        ?         ?

# now you want the 3rd column
summary(out)$coef[,3]


Richard

-- 

Richard E. Remington III
Statistician
KERN Statistical Services, Inc.
PO Box 1046
Boise, ID 83701
Tel: 208.426.0113
KernStat.com



From roger at ysidro.econ.uiuc.edu  Fri Feb 27 22:00:30 2004
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Fri, 27 Feb 2004 15:00:30 -0600 (CST)
Subject: [R] load data for mypkg-Ex.R
In-Reply-To: <Pine.LNX.4.44.0402271822550.16912-100000@gannet.stats>
Message-ID: <Pine.SOL.4.30.0402271426340.8106-100000@ysidro.econ.uiuc.edu>


On a related note.... is there a convention for cleaning up the detritus
after running

	example(foo)

I suppose sometimes users would like to have access to the objects
that were created in the course of this, but perhaps more likely they
would prefer that they were vaporized.   I'm finding this also an issue
in writing vignettes,  but my main concern is finding a good way to
handle this in writing .Rd files.


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Fri, 27 Feb 2004, Prof Brian Ripley wrote:

> On Fri, 27 Feb 2004, Jason Sinnwell wrote:
>
> > Using R 1.7.1 in Solaris
> >
> > I'm developing a package for both Splus and R, and I'm trying to use all the
> > same files for R and Splus, both function files and help files.  I have two
> > questions.
> >
> > 1) The file made by R CMD check to run .Rd-examples posts examples from files in
> > alphabetical order.  Is it okay/recommended/common-practice to set up all the
> > example data in the first two (alphabetically-sorted) examples and assume that
> > data exists for the rest of the examples?
>
> That does not work: the workspace is cleared after each help file.  As
> from the next release, the search path is restored too.
>
> > 2)  Since data() is not understood by Splus, I don't want to put a
> > 	     > data(example.data)
> > in the sgml file because then the Splus example would not run as data() doesn't
> > exist there.  Is there a spot I can make sure this data is loaded when running
> > the examples, but not to load the data every time you load the library, as it
> > would take up unnecessary space.  It is a ~~220 x 25 data.frame, is that enough
> > size to worry about this?
>
> Probably not: but use object.size() to find out.
>
> > I'm considering using the NAMESPACE or .First.lib() within zzz.R but that would
> > load the data every time the library is loaded.  Also considering something
> > like:
> > >if (<check for R using is.R()>)
> > >  data(example.data)
> > > <run example>
> >
> > In the example but that would create confusion for users.
>
> Take a look at how package MASS does this, via a promise.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Erik.B.Johnson at colorado.edu  Fri Feb 27 22:04:52 2004
From: Erik.B.Johnson at colorado.edu (Erik Johnson)
Date: Fri, 27 Feb 2004 14:04:52 -0700
Subject: [R] Johansen Procedure
Message-ID: <1077915892.403fb0f45b335@webmail.colorado.edu>

I noticed a post about the Johansen procedure for cointegration.(or lack there
of) from Nov 2003.  Is anyone aware of any implemenation of this in R at this
time?  If not, could someone please send me in a specific direction for
creating/implementing a new procedure.  Thanks alot.
--



From susan_lin99 at yahoo.com  Fri Feb 27 22:09:40 2004
From: susan_lin99 at yahoo.com (Susan Lin)
Date: Fri, 27 Feb 2004 13:09:40 -0800 (PST)
Subject: [R] a loop question
Message-ID: <20040227210940.723.qmail@web21205.mail.yahoo.com>

I want to get three .gif image files test.1.gif,
test.2.gif, & test.3.gif by using a loop. The code I
tried  is like this:
      x=c(0, 1, 2, 3, 4)
      y=c(1, 2, 3, 4)
      for(i in 1:3)
      {
        x11()
        jpeg("test.i.gif")
        plot(x, y)
        dev.off()

      } 
but I only could get one image file, test.i.gif. How
can I get three image files?

Thanks.



From rossini at blindglobe.net  Fri Feb 27 22:15:01 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 27 Feb 2004 13:15:01 -0800
Subject: [R] load data for mypkg-Ex.R
In-Reply-To: <Pine.SOL.4.30.0402271426340.8106-100000@ysidro.econ.uiuc.edu>
	(Roger
	Koenker's message of "Fri, 27 Feb 2004 15:00:30 -0600 (CST)")
References: <Pine.SOL.4.30.0402271426340.8106-100000@ysidro.econ.uiuc.edu>
Message-ID: <85fzcwusve.fsf@servant.blindglobe.net>


You mean, 

    example(foo,local=TRUE) 

?

Roger Koenker <roger at ysidro.econ.uiuc.edu> writes:

> On a related note.... is there a convention for cleaning up the detritus
> after running
>
> 	example(foo)
>
> I suppose sometimes users would like to have access to the objects
> that were created in the course of this, but perhaps more likely they
> would prefer that they were vaporized.   I'm finding this also an issue
> in writing vignettes,  but my main concern is finding a good way to
> handle this in writing .Rd files.
>
>
> url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
> email	rkoenker at uiuc.edu			Department of Economics
> vox: 	217-333-4558				University of Illinois
> fax:   	217-244-6678				Champaign, IL 61820
>
> On Fri, 27 Feb 2004, Prof Brian Ripley wrote:
>
>> On Fri, 27 Feb 2004, Jason Sinnwell wrote:
>>
>> > Using R 1.7.1 in Solaris
>> >
>> > I'm developing a package for both Splus and R, and I'm trying to use all the
>> > same files for R and Splus, both function files and help files.  I have two
>> > questions.
>> >
>> > 1) The file made by R CMD check to run .Rd-examples posts examples from files in
>> > alphabetical order.  Is it okay/recommended/common-practice to set up all the
>> > example data in the first two (alphabetically-sorted) examples and assume that
>> > data exists for the rest of the examples?
>>
>> That does not work: the workspace is cleared after each help file.  As
>> from the next release, the search path is restored too.
>>
>> > 2)  Since data() is not understood by Splus, I don't want to put a
>> > 	     > data(example.data)
>> > in the sgml file because then the Splus example would not run as data() doesn't
>> > exist there.  Is there a spot I can make sure this data is loaded when running
>> > the examples, but not to load the data every time you load the library, as it
>> > would take up unnecessary space.  It is a ~~220 x 25 data.frame, is that enough
>> > size to worry about this?
>>
>> Probably not: but use object.size() to find out.
>>
>> > I'm considering using the NAMESPACE or .First.lib() within zzz.R but that would
>> > load the data every time the library is loaded.  Also considering something
>> > like:
>> > >if (<check for R using is.R()>)
>> > >  data(example.data)
>> > > <run example>
>> >
>> > In the example but that would create confusion for users.
>>
>> Take a look at how package MASS does this, via a promise.
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From pgilbert at bank-banque-canada.ca  Fri Feb 27 22:13:37 2004
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 27 Feb 2004 16:13:37 -0500
Subject: [R] unable to install dse in mac OS X 10.3
In-Reply-To: <200402262242.i1QMgv33011775@andrena.ucdavis.edu>
References: <200402262242.i1QMgv33011775@andrena.ucdavis.edu>
Message-ID: <403FB301.8090605@bank-banque-canada.ca>

I'm not familiar with mac, but I think this is a problem with your 
compiler or its configuration.  I expect you will have the difficulty 
with all packages that need compiled fortran. Another user with a 
similar (but not the same) problem reported getting better errror 
messages by running the installation again but not within RAqua (started 
R from the command line within an Xterminal). It seems there was a g77 
prolem in that case.

Paul Gilbert

Emilio A. Laca wrote:

>I would like to request help with the installation of dse in raqua in mac
>os x 10.3. I get the following error message after the messages indicating
>that parts were successfully installed.
>
>I would be most grateful for a solution.
>
>-----------------------------------------
>
>* Installing *source* package 'setRNG' ...
>
>** R
>
>** inst
>
>** help
>
> >>> Building/Updating help pages for package 'setRNG'
>
>     Formats: text html latex example 
>
>  00Intro.setRNG                    text    html    latex   example
>
>  getRNG                            text    html    latex   example
>
>  setRNG                            text    html    latex   example
>
>* DONE (setRNG)
>
>
>
>* Installing *source* package 'tframe' ...
>
>** R
>
>** inst
>
>** help
>
> >>> Building/Updating help pages for package 'tframe'
>
>     Formats: text html latex example 
>
>  00Intro.tframe                    text    html    latex
>
> <snip>
>  trimNA                            text    html    latex   example
>
>* DONE (tframe)
>
>
>
>* Installing *source* package 'dse1' ...
>
>** libs
>
>g77   -fno-common  -g -O2 -c dsefor.f -o dsefor.o
>
>gcc -bundle -flat_namespace -undefined suppress -L/usr/local/lib -o dse1.so
>dsefor.o  -L/usr/local/lib -L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4
>-L/usr/local/lib/gcc/powerpc-apple-darwin6.6/3.4/../../.. -lfrtbegin -lg2c
>-lSystem -lcc_dynamic 
>
>/usr/bin/ld: -undefined: unknown argument: -lbundle1.o
>
>make: *** [dse1.so] Error 1
>
>ERROR: compilation failed for package 'dse1'
>
>** Removing '/Users/el/Library/RAqua/library/dse1'
>
>
>Emilio A. Laca
>Agronomy and Range Science
>UC Davis
>One Shields Ave.
>Davis CA 95616
>(530) 754-4083
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From Achim.Zeileis at wu-wien.ac.at  Fri Feb 27 22:45:09 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 27 Feb 2004 22:45:09 +0100
Subject: [R] a loop question
In-Reply-To: <20040227210940.723.qmail@web21205.mail.yahoo.com>
References: <20040227210940.723.qmail@web21205.mail.yahoo.com>
Message-ID: <20040227224509.7becbc34.Achim.Zeileis@wu-wien.ac.at>

On Fri, 27 Feb 2004 13:09:40 -0800 (PST) Susan Lin wrote:

> I want to get three .gif image files test.1.gif,
> test.2.gif, & test.3.gif by using a loop. The code I
> tried  is like this:
>       x=c(0, 1, 2, 3, 4)
>       y=c(1, 2, 3, 4)
>       for(i in 1:3)
>       {
>         x11()
>         jpeg("test.i.gif")

This should be

jpeg(paste("test.", i, ".gif", sep = ""))

also look at help(paste).

hth,
Z

>         plot(x, y)
>         dev.off()
> 
>       } 
> but I only could get one image file, test.i.gif. How
> can I get three image files?
> 
> Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From k.wang at auckland.ac.nz  Fri Feb 27 22:53:41 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 28 Feb 2004 10:53:41 +1300
Subject: [R] a loop question
In-Reply-To: <20040227210940.723.qmail@web21205.mail.yahoo.com>
Message-ID: <20040227215353.MYQB9867.web2-rme.xtra.co.nz@kevinlpt>


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Susan Lin
> Sent: Saturday, February 28, 2004 10:10 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] a loop question
>
> I want to get three .gif image files test.1.gif,
> test.2.gif, & test.3.gif by using a loop. The code I
> tried  is like this:
>       x=c(0, 1, 2, 3, 4)
>       y=c(1, 2, 3, 4)
>       for(i in 1:3)
>       {
>         x11()
>         jpeg("test.i.gif")
>         plot(x, y)
>         dev.off()
>
>       }
> but I only could get one image file, test.i.gif. How
> can I get three image files?

How about (I haven't tried it) something like:
  jpeg(paste("test.", i, ".gif", sep = "")

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
SLC Stats Workshops Co-ordinator
The University of Auckland
New Zealand


--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
SLC Stats Workshops Co-ordinator
The University of Auckland
New Zealand



From jtleek at u.washington.edu  Fri Feb 27 23:39:17 2004
From: jtleek at u.washington.edu (jtleek@u.washington.edu)
Date: Fri, 27 Feb 2004 14:39:17 -0800 (PST)
Subject: [R] browseURL question
Message-ID: <Pine.LNX.4.43.0402271439170.27915@hymn07.u.washington.edu>

I have a quick question about the browseURL function. When I use the function in a UNIX environment, I have to use two sets of quotations if I have the & symbol in the URL. For Windows I only need to use the first set. For example, on Windows:
browseURL("http://search.yahoo.com/search?p=Bioconductor&ei=UTF-8&fr=fp-tab-web-t&n=20&fl=0&x=wrt")

will call up the appropriate website. However, if I use the same command under UNIX, the website will be truncated after the first &, but the call will work if I use:
browseURL("'http://search.yahoo.com/search?p=Bioconductor&ei=UTF-8&fr=fp-tab-web-t&n=20&fl=0&x=wrt'")

Where I have added single quotes around the URL.Is there any quick method for solving this problem? Thank you very much for your help.


Jeff Leek
Graduate Student
University of Washington
jtleek at u.washington.edu



From alex_s_42 at yahoo.com  Sat Feb 28 00:15:23 2004
From: alex_s_42 at yahoo.com (Demiurg [at Yahoo])
Date: Sat, 28 Feb 2004 01:15:23 +0200
Subject: [R] importing S-Plus data files
Message-ID: <403FCF8B.3010204@yahoo.com>

I have some data in the Linux version of S-Plus, which I can not use
anymore. The program is just broken and won't run. I'm trying to
find a way to import that data to either Windows version of S-Plus
(which I have running on my other machine) or R (Linux or Windows,
it doesn't matter).

Unfortunately, nothing seems to work.
Windows S-Plus seem to ignore files from Linux .Data directory
and non of the import ruotines available in R can handle my data.

Any suggestions would be appreciated.



From andy_liaw at merck.com  Sat Feb 28 01:07:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 27 Feb 2004 19:07:36 -0500
Subject: [R] importing S-Plus data files
Message-ID: <3A822319EB35174CA3714066D590DCD504AF78B9@usrymx25.merck.com>

You can help yourself to help us by at least telling us what versions of
S-PLUS on Linux the data were created from, the version of S-PLUS you are
using under Windows (which version of Windows?) and the version of R you are
using.

I believe starting in S-PLUS 6.1, the data created by S-PLUS is binary
compatible between Linux and Windows versions.

Andy

> From: Demiurg [at Yahoo]
> 
> I have some data in the Linux version of S-Plus, which I can not use
> anymore. The program is just broken and won't run. I'm trying to
> find a way to import that data to either Windows version of S-Plus
> (which I have running on my other machine) or R (Linux or Windows,
> it doesn't matter).
> 
> Unfortunately, nothing seems to work.
> Windows S-Plus seem to ignore files from Linux .Data directory
> and non of the import ruotines available in R can handle my data.
> 
> Any suggestions would be appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From kimai at princeton.edu  Sat Feb 28 04:36:51 2004
From: kimai at princeton.edu (Kosuke Imai)
Date: Fri, 27 Feb 2004 22:36:51 -0500 (EST)
Subject: [R] matrix inverse in C
Message-ID: <Pine.LNX.4.44.0402272227490.7073-100000@wws-6qcbw21.Princeton.EDU>

Hi,
  I'm writing an R package using the C code i've written. I'm wondering if
anyone knows an easy way to calculate an inverse and cholesky factor of a
matrix using the Fortran/C library of R: and how to call them from C. My
code is based on the Numerical Reciepe code, and I'm trying to use
something that is already in R.
Thanks for your help in advance,
Kosuke

---------------------------------------------------------
Kosuke Imai               Office: Corwin Hall 041
Assistant Professor       Phone: 609-258-6601 (Direct)
Department of Politics    Fax: 609-258-1110 (Department)
Princeton University      Email: kimai at Princeton.Edu
Princeton, NJ 08544-1012  http://www.princeton.edu/~kimai



From nielssteenkrogh at hotmail.com  Sat Feb 28 08:22:57 2004
From: nielssteenkrogh at hotmail.com (Niels Steen Krogh)
Date: Sat, 28 Feb 2004 08:22:57 +0100
Subject: [R] logististic regression (GLM). How to get 95 pct. confidence
	limits? 
Message-ID: <BAY7-F43QSvWjinEjli000245a6@hotmail.com>

Dear R-list.
I'm doing af logistic analyses using gml.
The model explaines variations in  Adverse events infections (0 og 1) using 
age as explanatory variable.

model2d<-glm(formula=AEorSAEInfecBac~Age,family=binomial("logit"),data=emrisk)

I want to get predictions with 95% confidence limits for age 30 and age 60.
I've been reading the "google" and "search r-project" for suggestions but 
could only find solutions for lm: predict(model,data.frame(Age=30),level=.95 
..............)
?predict.glm or ?glm did'nt give me hints either.


Using R1.8.1. Windows





Cand. Polit.
Niels Steen Krogh
Solsortvej 44
2000 F.

Tlf: 3888 8613

ZiteLab / EmpoweR youR data with R, Zope and SOAP



From alex_s_42 at yahoo.com  Sat Feb 28 08:38:56 2004
From: alex_s_42 at yahoo.com (Alexander Sirotkin [at Yahoo])
Date: Fri, 27 Feb 2004 23:38:56 -0800 (PST)
Subject: [R] importing S-Plus data files
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF78B9@usrymx25.merck.com>
Message-ID: <20040228073856.65695.qmail@web60003.mail.yahoo.com>

S-Plus version is 6.1 (on both Linux and Windows), R
is 1.8.1. 

It's Win2K, although I don't think it matters.

Thanks.

--- "Liaw, Andy" <andy_liaw at merck.com> wrote:
> You can help yourself to help us by at least telling
> us what versions of
> S-PLUS on Linux the data were created from, the
> version of S-PLUS you are
> using under Windows (which version of Windows?) and
> the version of R you are
> using.
> 
> I believe starting in S-PLUS 6.1, the data created
> by S-PLUS is binary
> compatible between Linux and Windows versions.
> 
> Andy
> 
> > From: Demiurg [at Yahoo]
> > 
> > I have some data in the Linux version of S-Plus,
> which I can not use
> > anymore. The program is just broken and won't run.
> I'm trying to
> > find a way to import that data to either Windows
> version of S-Plus
> > (which I have running on my other machine) or R
> (Linux or Windows,
> > it doesn't matter).
> > 
> > Unfortunately, nothing seems to work.
> > Windows S-Plus seem to ignore files from Linux
> .Data directory
> > and non of the import ruotines available in R can
> handle my data.
> > 
> > Any suggestions would be appreciated.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> >
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
>
------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any
> attachments, contains
> information of Merck & Co., Inc. (One Merck Drive,
> Whitehouse Station, New
> Jersey, USA 08889), and/or its affiliates (which may
> be known outside the
> United States as Merck Frosst, Merck Sharp & Dohme
> or MSD and in Japan, as
> Banyu) that may be confidential, proprietary
> copyrighted and/or legally
> privileged. It is intended solely for the use of the
> individual or entity
> named on this message.  If you are not the intended
> recipient, and have
> received this message in error, please notify us
> immediately by reply e-mail
> and then delete it from your system.
>



From wang at galton.uchicago.edu  Sat Feb 28 08:48:20 2004
From: wang at galton.uchicago.edu (Yong Wang)
Date: Sat, 28 Feb 2004 01:48:20 -0600 (CST)
Subject: [R] LME, where is the package?
In-Reply-To: <200402271102.i1RB0rgx023459@hypatia.math.ethz.ch>
References: <200402271102.i1RB0rgx023459@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0402280144420.10790@galton.uchicago.edu>

Hi, all
My R 1.7.1 can not find lme, I just downloaded and installed the file 
lme4 from Crane, is this the same as lme? the problem is R still print no 
function 
named lme, how should I do.
thank you



From ripley at stats.ox.ac.uk  Sat Feb 28 09:00:54 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 28 Feb 2004 08:00:54 +0000 (GMT)
Subject: [R] browseURL question
In-Reply-To: <Pine.LNX.4.43.0402271439170.27915@hymn07.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0402280756040.17994-100000@gannet.stats>

The problem is the interpretation by the shell used on Unix: on Windows no
shell is used. It seems to me that the Unix version of browseURl should be
quoting `url' in

    remoteCmd <- if (isLocal)
        switch(basename(browser), "gnome-moz-remote" = , open = url,
            galeon = paste("-x", url), kfmclient = paste("openURL",
                url), netscape = , mozilla = , opera = , {
                paste("-remote \"openURL(", gsub("([,)])", "%\\1",
                  url), ")\"", sep = "")
            })
    else url

either by escaping & by \ or surrounding it by single quotes.

I can't see a simple solution for you with the present R codebase.

On Fri, 27 Feb 2004 jtleek at u.washington.edu wrote:

> I have a quick question about the browseURL function. When I use the
> function in a UNIX environment, I have to use two sets of quotations if
> I have the & symbol in the URL. For Windows I only need to use the first
> set. For example, on Windows:
> browseURL("http://search.yahoo.com/search?p=Bioconductor&ei=UTF-8&fr=fp-tab-web-t&n=20&fl=0&x=wrt")
> 
> will call up the appropriate website. However, if I use the same command
> under UNIX, the website will be truncated after the first &, but the
> call will work if I use:
> browseURL("'http://search.yahoo.com/search?p=Bioconductor&ei=UTF-8&fr=fp-tab-web-t&n=20&fl=0&x=wrt'")
> 
> Where I have added single quotes around the URL.Is there any quick method for solving this problem? Thank you very much for your help.
> 
> 
> Jeff Leek
> Graduate Student
> University of Washington
> jtleek at u.washington.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From k.wang at auckland.ac.nz  Sat Feb 28 09:04:40 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 28 Feb 2004 21:04:40 +1300
Subject: [R] LME, where is the package?
In-Reply-To: <Pine.LNX.4.58.0402280144420.10790@galton.uchicago.edu>
Message-ID: <20040228080453.XCCP20103.mta2-rme.xtra.co.nz@kevinlpt>

Hi,

> -----Original Message-----
> From: r-help-bounces+k.wang=auckland.ac.nz at stat.math.ethz.ch
> [mailto:r-help-bounces+k.wang=auckland.ac.nz at stat.math.ethz.ch
> ] On Behalf Of Yong Wang
> Sent: Saturday, February 28, 2004 8:48 PM
> To: r-help-request at stat.math.ethz.ch
> Cc: r-help at stat.math.ethz.ch
> Subject: [R] LME, where is the package?
>
> Hi, all
> My R 1.7.1 can not find lme, I just downloaded and installed the
file
> lme4 from Crane, is this the same as lme? the problem is R
> still print no
> function
> named lme, how should I do.

I believe you are looking for nlme package.  Try to load it.

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
SLC Stats Workshops Co-ordinator
The University of Auckland
New Zealand



From ripley at stats.ox.ac.uk  Sat Feb 28 09:09:11 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 28 Feb 2004 08:09:11 +0000 (GMT)
Subject: [R] importing S-Plus data files
In-Reply-To: <20040228073856.65695.qmail@web60003.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0402280804460.17994-100000@gannet.stats>

By `data files' do you mean objects stored in the .Data directory?

If so I think your only real hope is to use S-PLUS to read those files. 
Presumably you have technical support with your S-PLUS licenses, and the 
simplest solution may be to get your S-PLUS for Linux running again with 
the help of S-PLUS technical support.

On Fri, 27 Feb 2004, Alexander Sirotkin [at Yahoo] wrote:

> S-Plus version is 6.1 (on both Linux and Windows), R
> is 1.8.1. 
> 
> It's Win2K, although I don't think it matters.
> 
> Thanks.
> 
> --- "Liaw, Andy" <andy_liaw at merck.com> wrote:
> > You can help yourself to help us by at least telling
> > us what versions of
> > S-PLUS on Linux the data were created from, the
> > version of S-PLUS you are
> > using under Windows (which version of Windows?) and
> > the version of R you are
> > using.
> > 
> > I believe starting in S-PLUS 6.1, the data created
> > by S-PLUS is binary
> > compatible between Linux and Windows versions.
> > 
> > Andy
> > 
> > > From: Demiurg [at Yahoo]
> > > 
> > > I have some data in the Linux version of S-Plus,
> > which I can not use
> > > anymore. The program is just broken and won't run.
> > I'm trying to
> > > find a way to import that data to either Windows
> > version of S-Plus
> > > (which I have running on my other machine) or R
> > (Linux or Windows,
> > > it doesn't matter).
> > > 
> > > Unfortunately, nothing seems to work.
> > > Windows S-Plus seem to ignore files from Linux
> > .Data directory
> > > and non of the import ruotines available in R can
> > handle my data.
> > > 
> > > Any suggestions would be appreciated.
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > >
> >
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > > 
> > > 
> > 
> > 
> >
> ------------------------------------------------------------------------------
> > Notice:  This e-mail message, together with any
> > attachments, contains
> > information of Merck & Co., Inc. (One Merck Drive,
> > Whitehouse Station, New
> > Jersey, USA 08889), and/or its affiliates (which may
> > be known outside the
> > United States as Merck Frosst, Merck Sharp & Dohme
> > or MSD and in Japan, as
> > Banyu) that may be confidential, proprietary
> > copyrighted and/or legally
> > privileged. It is intended solely for the use of the
> > individual or entity
> > named on this message.  If you are not the intended
> > recipient, and have
> > received this message in error, please notify us
> > immediately by reply e-mail
> > and then delete it from your system.
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Feb 28 09:17:22 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 28 Feb 2004 08:17:22 +0000 (GMT)
Subject: [R] logististic regression (GLM). How to get 95 pct. confidence
	limits? 
In-Reply-To: <BAY7-F43QSvWjinEjli000245a6@hotmail.com>
Message-ID: <Pine.LNX.4.44.0402280809510.17994-100000@gannet.stats>

On Sat, 28 Feb 2004, Niels Steen Krogh wrote:

> Dear R-list.
> I'm doing af logistic analyses using gml.
> The model explaines variations in  Adverse events infections (0 og 1) using 
> age as explanatory variable.
> 
> model2d<-glm(formula=AEorSAEInfecBac~Age,family=binomial("logit"),data=emrisk)
> 
> I want to get predictions with 95% confidence limits for age 30 and age 60.
> I've been reading the "google" and "search r-project" for suggestions but 
> could only find solutions for lm: predict(model,data.frame(Age=30),level=.95 
> ..............)
> ?predict.glm or ?glm did'nt give me hints either.

95% confidence limits for what?  I guess you mean either the linear 
predictor or the mean, and it is preferable to find CIs for the linear 
predictor and transforms the CIs if needed.

preds <- predict(model2d, data.frame(Age=c(30, 60)), se.fit=TRUE)

will give a list with means and ses for the linear predictor.  There is no 
exact sampling theory, so you can use something like

cbind(lower=pred$fit-1.96*preds$se, upper=pred$fit+1.96*preds$se)

and transform by family(model2d)$linkinv() to response scale.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ozric at web.de  Sat Feb 28 09:32:34 2004
From: ozric at web.de (Christian Schulz)
Date: Sat, 28 Feb 2004 09:32:34 +0100
Subject: [R] logististic regression (GLM). How to get 95 pct. confidence
	limits?
In-Reply-To: <BAY7-F43QSvWjinEjli000245a6@hotmail.com>
References: <BAY7-F43QSvWjinEjli000245a6@hotmail.com>
Message-ID: <200402280932.35976.ozric@web.de>

Hi,

in library(MASS) the function  profile.glm  should help you.

christian



Am Samstag, 28. Februar 2004 08:22 schrieb Niels Steen Krogh:
> Dear R-list.
> I'm doing af logistic analyses using gml.
> The model explaines variations in  Adverse events infections (0 og 1) using
> age as explanatory variable.
>
> model2d<-glm(formula=AEorSAEInfecBac~Age,family=binomial("logit"),data=emri
>sk)
>
> I want to get predictions with 95% confidence limits for age 30 and age 60.
> I've been reading the "google" and "search r-project" for suggestions but
> could only find solutions for lm:
> predict(model,data.frame(Age=30),level=.95 ..............)
> ?predict.glm or ?glm did'nt give me hints either.
>
>
> Using R1.8.1. Windows
>
>
>
>
>
> Cand. Polit.
> Niels Steen Krogh
> Solsortvej 44
> 2000 F.
>
> Tlf: 3888 8613
>
> ZiteLab / EmpoweR youR data with R, Zope and SOAP
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat Feb 28 09:35:49 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 28 Feb 2004 09:35:49 +0100
Subject: [R] LME, where is the package?
In-Reply-To: <20040228080453.XCCP20103.mta2-rme.xtra.co.nz@kevinlpt>
References: <20040228080453.XCCP20103.mta2-rme.xtra.co.nz@kevinlpt>
Message-ID: <404052E5.5060602@statistik.uni-dortmund.de>

Ko-Kang Kevin Wang wrote:

> Hi,
> 
> 
>>-----Original Message-----
>>From: r-help-bounces+k.wang=auckland.ac.nz at stat.math.ethz.ch
>>[mailto:r-help-bounces+k.wang=auckland.ac.nz at stat.math.ethz.ch
>>] On Behalf Of Yong Wang
>>Sent: Saturday, February 28, 2004 8:48 PM
>>To: r-help-request at stat.math.ethz.ch
>>Cc: r-help at stat.math.ethz.ch
>>Subject: [R] LME, where is the package?
>>
>>Hi, all
>>My R 1.7.1 can not find lme, I just downloaded and installed the
> 
> file
> 
>>lme4 from Crane, is this the same as lme? the problem is R
>>still print no
>>function
>>named lme, how should I do.
> 
> 
> I believe you are looking for nlme package.  Try to load it.
> 

Well, there is also a function lme() in "lme4".
It works for me (even on the outdated R-1.7.1):

  install.packages("lme4")
  library(lme4)
  lme            # yes, the function is there ...

What happens when you type the above lines? Which version of lme4 are 
you using? Have you compiled from sources yourself?

Note that the CRAN binary version for R-1.7.x of lme4 is 0.4-4 whereas 
the recent version is 0.4-7 which no longer prints

  "This package is in development.  For production work use
  lme from package nlme or glmmPQL from package MASS."

So it's a good idea to upgrade to R-1.8.1 and use a recent version of 
the package, if nlme is not what you are looking for ...

Uwe Ligges



From t.wille at vannas.net  Sat Feb 28 09:42:28 2004
From: t.wille at vannas.net (Tomas Willebrand)
Date: Sat, 28 Feb 2004 09:42:28 +0100
Subject: [R] Stepwise regression and partial correlation for wildlife census
	time series
In-Reply-To: <005c01c3fd2b$8d5ba380$93640ac1@szooek.slu.se>
Message-ID: <20040228083912.A97F9189A5@mail.hem.net>

Dear List;

We are doing a time series analysis of wildlife census data. We use a
stepwise regression of the annual per capita rate of increase against
pervious years population size (log transformed) as suggested by Berryman &
Turchin (2001, Oikos 92:265-270). 

How can we obtain the partial correlation coefficients in R to make a plot
of them against the lag as in a standard PACF?

Yours Sincerely

Tomas Willebrand



From ripley at stats.ox.ac.uk  Sat Feb 28 10:02:53 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 28 Feb 2004 09:02:53 +0000 (GMT)
Subject: [R] load data for mypkg-Ex.R
In-Reply-To: <Pine.SOL.4.30.0402271426340.8106-100000@ysidro.econ.uiuc.edu>
Message-ID: <Pine.LNX.4.44.0402280858440.27363-100000@gannet.stats>

On Fri, 27 Feb 2004, Roger Koenker wrote:

> 
> On a related note.... is there a convention for cleaning up the detritus
> after running
> 
> 	example(foo)
> 
> I suppose sometimes users would like to have access to the objects
> that were created in the course of this, but perhaps more likely they
> would prefer that they were vaporized.   I'm finding this also an issue
> in writing vignettes,  but my main concern is finding a good way to
> handle this in writing .Rd files.

We tend only to clean up temporary objects, and the search path.
As Tony says, users can call example() with local=TRUE, and the checking 
code tidies up after each help file.  There are several examples of one 
help file calling example() on another and working further with the same 
objects.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From vograno at evafunds.com  Sat Feb 28 10:26:06 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Sat, 28 Feb 2004 01:26:06 -0800
Subject: [R] when .Call can safely modify its arguments
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A50C3A7C@phost015.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040228/e8216425/attachment.pl

From ripley at stats.ox.ac.uk  Sat Feb 28 10:49:43 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 28 Feb 2004 09:49:43 +0000 (GMT)
Subject: [R] when .Call can safely modify its arguments
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A50C3A7C@phost015.intermedia.net>
Message-ID: <Pine.LNX.4.44.0402280944020.8850-100000@gannet.stats>

On Sat, 28 Feb 2004, Vadim Ogranovich wrote:

> Hi,
>  
> "Writing R Extensions Guide" clearly states that a C-function interfaced
> via .Call() should not modify any of its arguments. However I wonder if
> there are exceptions to this rule, i.e. when .Call can safely modify the
> arguments. For example when a function creates a list that is then
> populated by a call to a C function:
>  
> getData <- function() {
>     data <- list(a=double(2), b=character(3))
>  
>     # now populate_list modifies data
>     .Call("populate_list", data) 
>  
>     data
> }
>  
>  
> What can go wrong in this example?

I don't think anything can, but there is no advantage over using

data <- .Call("populate_list", data)

which makes the intention much clearer.

We would rather you didn't name objects the same as R system functions, 
though.

> And while we are here I wonder what happens to 'data' when getData()
> returns it. Is it copied or some more efficient mechanism is used?

Nothing.  If the call to getData is of the form

foo <- getData()
bar <- foo

then foo and bar are still the same object, but if either is subsequently 
changed (at R level) it will be copied before being changed.


The way to understand internal details like this is to study the current
source code.  They do change from time to time, and we do find errors from 
time to time.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From copellifulvio at yahoo.it  Sat Feb 28 11:34:23 2004
From: copellifulvio at yahoo.it (=?iso-8859-1?q?Fulvio=20Copex?=)
Date: Sat, 28 Feb 2004 11:34:23 +0100 (CET)
Subject: [R] Basic general statistical problem.
Message-ID: <20040228103423.68549.qmail@web25206.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040228/0827a344/attachment.pl

From ripley at stats.ox.ac.uk  Sat Feb 28 12:21:33 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 28 Feb 2004 11:21:33 +0000 (GMT)
Subject: [R] Basic general statistical problem.
In-Reply-To: <20040228103423.68549.qmail@web25206.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.44.0402281059440.17210-100000@gannet.stats>

On Sat, 28 Feb 2004, Fulvio Copex wrote:

> Hello everyone,
> I'd like to have suggestions about a common basic statistical approach, 
> hope to be useful also for other R beginners.

Isn't this about statistics beginners?  You seem to be assuming univariate 
data and a very specific distribution form.  There are standard 
procedures, but yours seems erroneous.

> When you first get some data (i.e length of river) you may want to look at its distribution.
> Then you probably want to find which law follows this distribution, 
> and to test the goodness of the fit.
>  
> For doing this simple analysis I am writing some code schematically represented below: 
> 1)calculate the histogram:
> myhist<-hist(myData, breaks=....)
> Question: how to calculate the standard deviation of each class of the hist? I have not seen it in the output of hist

The counts are jointly multinomial.  Approximately each count is 
Poisson-distributed, so the standard deviation is approximately the square 
root of the count.  (You seem to be assuming that at 3).)

> 2)Looking at the graph it seems to follow a linear model:

What does that mean?  The histogram is a density estimate, and 
theoretically a pdf cannot be linear unless you restrict the range, and 
even then you would want to constrain the estimation.  You want to the fit 
the pdf to the actual data, not grouped data, if you can.

> I plot the points: points(myhist$mids,myhist$counts)
> Question: How to plot also the weights (vertical segments)?

> 3)I Calculate the linear equation using "lm" (in the case of linear
> model) knowing the weights computed in points 2).

> 4)To test the goodness of the fit, a simply way is to use the reduced
> chi squared test which I haven't found on the base package. But it is
> simple to calculate like this
> chisq.reduced<-(1/N)*sum((e-o)/w^2)
> where e=expected values from fit
> o=observed values
> w=weights

That is not a correct test, as the counts are not independent (they must 
sum to one).  I presume you have a typo: it is (o-e)^2/e, where I think e 
and w are probably the same thing.

You can use chisq.test to do the correct test.

> 5) Conclusion: If my chisq is lower than 1 I can conclude the model
> approximate well my data distribution.

No, you need to refer the correct statistic to a proper chi-squared
distribution.  If you fit parameters of the distribution, the theory
assumes that you fitted them by maximum-likelihood (to the grouped data).

> Is it a good analysys of the problem?

No.

> Any answers to my questions or a better standard procedure (or package)
> where this work can be done easily, for the basic kind of distribution
> types?

?fitdistr (in MASS) for how to fit univariate distributions, and ?density
for how to find non-parametric density estimates.  ?chisq.test for
Chi-squared test of goodness of fit.  library(stepfun); ?ecdf for other
ways to examine data, and ?ks.test for other fit statistics which may be
more appropriate for continuous univariate measurements.

> Any kind of answer should be appreciated, including documentations or
> tutorial.

This sort of thing is covered in most introductory statistics classes and 
texts.   I think you need to seek the advice of a local statistical 
consultant.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ozric at web.de  Sat Feb 28 14:07:42 2004
From: ozric at web.de (Christian Schulz)
Date: Sat, 28 Feb 2004 14:07:42 +0100
Subject: [R] cluster-gruop-match with other attributes after na.omit
Message-ID: <200402281407.42710.ozric@web.de>

Hi,

i want a cluster-analysis with clara, but getting an 
error because in cldat are NA's.

Error in clara(cldat[, 1:3], 4) : Each of the random samples contains objects 
between which
 no distance can be computed.

cldatx <- subset(cldat,select=c(A,B,C))
cldaty <-  na.omit(cldatx)

Now , clara works but cldat has ~193.000 obs
and cldatx without NA's ~75.000 obs.

How could i match back the clara result (cluster group)
to check associations with other attributes in the 193.000 obs
in the cldat.frame ?


Many thanks 
Christian



From ozric at web.de  Sat Feb 28 14:21:11 2004
From: ozric at web.de (Christian Schulz)
Date: Sat, 28 Feb 2004 14:21:11 +0100
Subject: [R] Re: cluster-gruop-match with other attributes after na.omit
In-Reply-To: <200402281407.42710.ozric@web.de>
References: <200402281407.42710.ozric@web.de>
Message-ID: <200402281421.11695.ozric@web.de>

i get an idea:


cldatx1 <- subset(cldat,select=c(ID,A,B,C))
cldatx2 <- subset(cldat,select=c(A,B,C))

The id didn't cause na.omit , so 
both have same obs.

cl1 <- clara(cldatx2,4)
cluster <- cl1$clustering
match1 <- cbind(cldatx1,cluster)
resultdata <- merge(cldat,macth1,by.x="ID",by.y="ID",all.x=T)

Sure there is an easier way???
Thanks,Christian



Am Samstag, 28. Februar 2004 14:07 schrieb Christian Schulz:
> Hi,
>
> i want a cluster-analysis with clara, but getting an
> error because in cldat are NA's.
>
> Error in clara(cldat[, 1:3], 4) : Each of the random samples contains
> objects between which
>  no distance can be computed.
>
> cldatx <- subset(cldat,select=c(A,B,C))
> cldaty <-  na.omit(cldatx)
>
> Now , clara works but cldat has ~193.000 obs
> and cldatx without NA's ~75.000 obs.
>
> How could i match back the clara result (cluster group)
> to check associations with other attributes in the 193.000 obs
> in the cldat.frame ?
>
>
> Many thanks
> Christian



From andy_liaw at merck.com  Sat Feb 28 14:40:41 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 28 Feb 2004 08:40:41 -0500
Subject: [R] matrix inverse in C
Message-ID: <3A822319EB35174CA3714066D590DCD504AF78C1@usrymx25.merck.com>

In section 5.7 of the `Writing R Extensions' manual, it mentions the
interface to numerical linear algebra routines (LINPACK, etc.).  You will
need to figure out which are the ones you need and how to call them.  As
these are expressed as Fortran routines, you can call them from C using the
F77_CALL() macro mentioned in that manual.

I believe many would say that routines in Numerical Recipes are not really
`industrial strength'...

HTH,
Andy

> From: Kosuke Imai
> 
> Hi,
>   I'm writing an R package using the C code i've written. I'm 
> wondering if
> anyone knows an easy way to calculate an inverse and cholesky 
> factor of a
> matrix using the Fortran/C library of R: and how to call them 
> from C. My
> code is based on the Numerical Reciepe code, and I'm trying to use
> something that is already in R.
> Thanks for your help in advance,
> Kosuke
> 
> ---------------------------------------------------------
> Kosuke Imai               Office: Corwin Hall 041
> Assistant Professor       Phone: 609-258-6601 (Direct)
> Department of Politics    Fax: 609-258-1110 (Department)
> Princeton University      Email: kimai at Princeton.Edu
> Princeton, NJ 08544-1012  http://www.princeton.edu/~kimai
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From pjw at rhyme.com.au  Sat Feb 28 14:47:03 2004
From: pjw at rhyme.com.au (Philip Warner)
Date: Sun, 29 Feb 2004 00:47:03 +1100
Subject: [R] SVD/Eigenvector confusion
Message-ID: <6.0.0.22.0.20040229002806.084975e8@203.8.195.10>


My understanding of SVD is that, for A an mxn matrix, m > n:

     A = UWV*

where W is square root diagonal eigenvalues of A*A extended with zero 
valued rows, and U and V are the left & right eigen vectors of A. But this 
does not seem to be strictly true and seems to require specific 
eigenvectors, and I am not at all sure how these are computed.

Since W should have a zero row at the bottom, which when multiplied by U 
will just remove the last column of U, I have just omitted the last row of 
u from the outset:

eg, in R:

     a <- matrix(c(c(1,2,3),c(5,14,11)),3,2)
     u <- eigen(a %*% t(a))$vectors[,1:2]
     v <- eigen(t(a) %*% a)$vectors
     w <- sqrt(diag(eigen(t(a) %*% a)$values))
     u %*% w %*% t(v)

gives:
            [,1]       [,2]
[1,] -0.9390078  -5.011812
[2,] -3.3713773 -13.734403
[3,] -1.3236615 -11.324660

which seems a little off the mark. The value for v is:

           [,1]       [,2]
[1,] 0.1901389  0.9817572
[2,] 0.9817572 -0.1901389

Where as svd(a)$v is:

            [,1]       [,2]
[1,] -0.1901389  0.9817572
[2,] -0.9817572 -0.1901389

If I substitute this in the above, I get:

     u %*% w %*% t(svd(a)$v)

which returns:

      [,1] [,2]
[1,]    1    5
[2,]    2   14
[3,]    3   11

which is what the SVD should do. I assume there is some rule about setting 
the signs on eigenvectors for SVD, and would appreciate any help.



----------------------------------------------------------------
Philip Warner                    |     __---_____
Albatross Consulting Pty. Ltd.   |----/       -  \
(A.B.N. 75 008 659 498)          |          /(@)   ______---_
Tel: (+61) 0500 83 82 81         |                 _________  \
Fax: (+61) 03 5330 3172          |                 ___________ |
Http://www.rhyme.com.au          |                /           \|
                                  |    --________--
PGP key available upon request,  |  /
and from pgp.mit.edu:11371       |/



From andy_liaw at merck.com  Sat Feb 28 14:48:01 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 28 Feb 2004 08:48:01 -0500
Subject: [R] importing S-Plus data files
Message-ID: <3A822319EB35174CA3714066D590DCD504AF78C2@usrymx25.merck.com>

As I said, I believe at least in S-PLUS 6.1, the files in _Data are binary
compatible across platforms.  (As Prof. Ripley says, if that's the `data'
you meant.)  If the S-PLUS on Linux is so broken, and the Windows version
can't read the data, then there's a good chance the data is corrupted
somehow.

And as BDR said, your best bet is Insightful Tech Support.  Short of that,
try S-news.  You're not likely to get useful help on R-help.  The
capabilities of reading S-PLUS files in R are limited to those available in
the `foreign' package, and mentioned in the R Data Import/Export manual.

Andy

> From: Alexander Sirotkin [at Yahoo] [mailto:alex_s_42 at yahoo.com] 
> 
> S-Plus version is 6.1 (on both Linux and Windows), R
> is 1.8.1. 
> 
> It's Win2K, although I don't think it matters.
> 
> Thanks.
> 
> --- "Liaw, Andy" <andy_liaw at merck.com> wrote:
> > You can help yourself to help us by at least telling
> > us what versions of
> > S-PLUS on Linux the data were created from, the
> > version of S-PLUS you are
> > using under Windows (which version of Windows?) and
> > the version of R you are
> > using.
> > 
> > I believe starting in S-PLUS 6.1, the data created
> > by S-PLUS is binary
> > compatible between Linux and Windows versions.
> > 
> > Andy
> > 
> > > From: Demiurg [at Yahoo]
> > > 
> > > I have some data in the Linux version of S-Plus,
> > which I can not use
> > > anymore. The program is just broken and won't run.
> > I'm trying to
> > > find a way to import that data to either Windows
> > version of S-Plus
> > > (which I have running on my other machine) or R
> > (Linux or Windows,
> > > it doesn't matter).
> > > 
> > > Unfortunately, nothing seems to work.
> > > Windows S-Plus seem to ignore files from Linux
> > .Data directory
> > > and non of the import ruotines available in R can
> > handle my data.
> > > 
> > > Any suggestions would be appreciated.
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > >
> >
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > > 
> > > 
> > 
> > 
> >
> --------------------------------------------------------------
> ----------------
> > Notice:  This e-mail message, together with any
> > attachments, contains
> > information of Merck & Co., Inc. (One Merck Drive,
> > Whitehouse Station, New
> > Jersey, USA 08889), and/or its affiliates (which may
> > be known outside the
> > United States as Merck Frosst, Merck Sharp & Dohme
> > or MSD and in Japan, as
> > Banyu) that may be confidential, proprietary
> > copyrighted and/or legally
> > privileged. It is intended solely for the use of the
> > individual or entity
> > named on this message.  If you are not the intended
> > recipient, and have
> > received this message in error, please notify us
> > immediately by reply e-mail
> > and then delete it from your system.
> >
> --------------------------------------------------------------
> ----------------
> 
> 
> __________________________________
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From bates at stat.wisc.edu  Sat Feb 28 15:01:19 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 28 Feb 2004 08:01:19 -0600
Subject: [R] SVD/Eigenvector confusion
In-Reply-To: <6.0.0.22.0.20040229002806.084975e8@203.8.195.10>
References: <6.0.0.22.0.20040229002806.084975e8@203.8.195.10>
Message-ID: <6rsmgv2ths.fsf@bates4.stat.wisc.edu>

Philip Warner <pjw at rhyme.com.au> writes:

> My understanding of SVD is that, for A an mxn matrix, m > n:
> 
>      A = UWV*
> 
> where W is square root diagonal eigenvalues of A*A extended with zero
> valued rows, and U and V are the left & right eigen vectors of A. But
> this does not seem to be strictly true and seems to require specific
> eigenvectors, and I am not at all sure how these are computed.
> 
> 
> Since W should have a zero row at the bottom, which when multiplied by
> U will just remove the last column of U, I have just omitted the last
> row of u from the outset:
> 
> 
> eg, in R:
> 
>      a <- matrix(c(c(1,2,3),c(5,14,11)),3,2)
>      u <- eigen(a %*% t(a))$vectors[,1:2]
>      v <- eigen(t(a) %*% a)$vectors
>      w <- sqrt(diag(eigen(t(a) %*% a)$values))
>      u %*% w %*% t(v)
> 
> gives:
>             [,1]       [,2]
> [1,] -0.9390078  -5.011812
> [2,] -3.3713773 -13.734403
> [3,] -1.3236615 -11.324660
> 
> which seems a little off the mark. The value for v is:
> 
>            [,1]       [,2]
> [1,] 0.1901389  0.9817572
> [2,] 0.9817572 -0.1901389
> 
> Where as svd(a)$v is:
> 
>             [,1]       [,2]
> [1,] -0.1901389  0.9817572
> [2,] -0.9817572 -0.1901389
> 
> If I substitute this in the above, I get:
> 
>      u %*% w %*% t(svd(a)$v)
> 
> which returns:
> 
>       [,1] [,2]
> [1,]    1    5
> [2,]    2   14
> [3,]    3   11
> 
> which is what the SVD should do. I assume there is some rule about
> setting the signs on eigenvectors for SVD, and would appreciate any
> help.

Eigenvectors are only known up to changes in sign.  If you want to be
more precise you can say that you determine a one-dimensional
eigenspace.  Generally we normalize the eigenvectors of a symmetric
matrix to have unit length but that still leaves you with two choices.

Is there a reason you are doing the SVD in such a complicated way?
Why not use the svd function directly?



From pjw at rhyme.com.au  Sat Feb 28 15:06:49 2004
From: pjw at rhyme.com.au (Philip Warner)
Date: Sun, 29 Feb 2004 01:06:49 +1100
Subject: [R] SVD/Eigenvector confusion
In-Reply-To: <6rsmgv2ths.fsf@bates4.stat.wisc.edu>
References: <6.0.0.22.0.20040229002806.084975e8@203.8.195.10>
	<6rsmgv2ths.fsf@bates4.stat.wisc.edu>
Message-ID: <6.0.0.22.0.20040229010300.0848a578@203.8.195.10>

At 01:01 AM 29/02/2004, Douglas Bates wrote:
>Is there a reason you are doing the SVD in such a complicated way?
>Why not use the svd function directly?

I am using it to debug other code that is deigned to compute SVDs, so I 
actually want to understand the intermediate steps in constricting the SVD.

Nothing I have seen in the various books & net sources I have read seem to 
indicate that the eigenvectors for U & V have any special requirements 
other than being of unit length, but the experimentation in R seems to 
indicate otherwise, hence my confusion.






>

----------------------------------------------------------------
Philip Warner                    |     __---_____
Albatross Consulting Pty. Ltd.   |----/       -  \
(A.B.N. 75 008 659 498)          |          /(@)   ______---_
Tel: (+61) 0500 83 82 81         |                 _________  \
Fax: (+61) 03 5330 3172          |                 ___________ |
Http://www.rhyme.com.au          |                /           \|
                                  |    --________--
PGP key available upon request,  |  /
and from pgp.mit.edu:11371       |/



From ripley at stats.ox.ac.uk  Sat Feb 28 15:17:00 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 28 Feb 2004 14:17:00 +0000 (GMT)
Subject: [R] SVD/Eigenvector confusion
In-Reply-To: <6.0.0.22.0.20040229002806.084975e8@203.8.195.10>
Message-ID: <Pine.LNX.4.44.0402281400250.17376-100000@gannet.stats>

On Sun, 29 Feb 2004, Philip Warner wrote:

> My understanding of SVD is that, for A an mxn matrix, m > n:
> 
>      A = UWV*
> 
> where W is square root diagonal eigenvalues of A*A extended with zero 
> valued rows, and U and V are the left & right eigen vectors of A. But this 
> does not seem to be strictly true and seems to require specific 
> eigenvectors, and I am not at all sure how these are computed.

(A %*% t(A) is required, BTW.)  That is not the definition of the SVD.  
It is true that U are eigenvectors of A %*% t(A) and V of t(A) %*% A, but
that does not make them left/right eigenvectors of A (unless that is your
private definition).  Since eigenvectors are not unique, it does mean that
you cannot reverse the process, as you seem to be trying to do.

Eigenvectors are only defined up to a sign (and more if there are 
duplicate eigenvalues) and singular vectors are only defined up to a sign 
(changing both U and V).  You will find both vary by sign depending on the 
exact version of R used (including which BLAS and which compiler 
optimization level).  Singular vectors have unit length, but eigenvectors 
do not have to (although they do in the code you have used).

> Since W should have a zero row at the bottom, which when multiplied by U 
> will just remove the last column of U, I have just omitted the last row of 
> u from the outset:
> 
> eg, in R:
> 
>      a <- matrix(c(c(1,2,3),c(5,14,11)),3,2)
>      u <- eigen(a %*% t(a))$vectors[,1:2]
>      v <- eigen(t(a) %*% a)$vectors
>      w <- sqrt(diag(eigen(t(a) %*% a)$values))
>      u %*% w %*% t(v)
> 
> gives:
>             [,1]       [,2]
> [1,] -0.9390078  -5.011812
> [2,] -3.3713773 -13.734403
> [3,] -1.3236615 -11.324660
> 
> which seems a little off the mark. 

It is not expected to work.

> The value for v is:
> 
>            [,1]       [,2]
> [1,] 0.1901389  0.9817572
> [2,] 0.9817572 -0.1901389
> 
> Where as svd(a)$v is:
> 
>             [,1]       [,2]
> [1,] -0.1901389  0.9817572
> [2,] -0.9817572 -0.1901389

> If I substitute this in the above, I get:
> 
>      u %*% w %*% t(svd(a)$v)
> 
> which returns:
> 
>       [,1] [,2]
> [1,]    1    5
> [2,]    2   14
> [3,]    3   11
> 
> which is what the SVD should do. I assume there is some rule about setting 
> the signs on eigenvectors for SVD, and would appreciate any help.

There is no rule: the SVD is computed by a different algorithm.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Sat Feb 28 15:44:03 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 28 Feb 2004 09:44:03 -0500 (EST)
Subject: [R] browseURL question
Message-ID: <20040228144403.99F053977@mprdmxin.myway.com>



One way to avoid this problem is to create a one line javascript
file which redirects to your url.  That way the shell never 
gets its hands on your url.  After setting the url:

url <- "http://search.yahoo.com/search?p=Bioconductor&ei=UTF-8&fr=fp-tab-web-t&n=20&fl=0&x=wrt"

Run these three lines of code (only tested on Windows/IE):

cat( "<script language=", "javascript", ">location=", 
            url, "</script>\n", sep="\"", file="temp.htm" )
browseURL("temp.htm")
unlink("temp.htm")


---
Date:   Sat, 28 Feb 2004 08:00:54 +0000 (GMT) 
From:   Prof Brian Ripley <ripley at stats.ox.ac.uk>
To:   <jtleek at u.washington.edu> 
Cc:   <r-help at stat.math.ethz.ch> 
Subject:   Re: [R] browseURL question 

 
The problem is the interpretation by the shell used on Unix: on Windows no
shell is used. It seems to me that the Unix version of browseURl should be
quoting `url' in

remoteCmd <- if (isLocal)
switch(basename(browser), "gnome-moz-remote" = , open = url,
galeon = paste("-x", url), kfmclient = paste("openURL",
url), netscape = , mozilla = , opera = , {
paste("-remote \"openURL(", gsub("([,)])", "%\\1",
url), ")\"", sep = "")
})
else url

either by escaping & by \ or surrounding it by single quotes.

I can't see a simple solution for you with the present R codebase.

On Fri, 27 Feb 2004 jtleek at u.washington.edu wrote:

> I have a quick question about the browseURL function. When I use the
> function in a UNIX environment, I have to use two sets of quotations if
> I have the & symbol in the URL. For Windows I only need to use the first
> set. For example, on Windows:
> browseURL("http://search.yahoo.com/search?p=Bioconductor&ei=UTF-8&fr=fp-tab-web-t&n=20&fl=0&x=wrt";)
> 
> will call up the appropriate website. However, if I use the same command
> under UNIX, the website will be truncated after the first &, but the
> call will work if I use:
> browseURL("'http://search.yahoo.com/search?p=Bioconductor&ei=UTF-8&fr=fp-tab-web-t&n=20&fl=0&x=wrt'";)
> 
> Where I have added single quotes around the URL.Is there any quick method for solving this problem? Thank you very much for your help.
> 
> 
> Jeff Leek
> Graduate Student
> University of Washington
> jtleek at u.washington.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley, ripley at stats.ox.ac.uk
Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
University of Oxford, Tel: +44 1865 272861 (self)
1 South Parks Road, +44 1865 272866 (PA)
Oxford OX1 3TG, UK Fax: +44 1865 272595



From spencer.graves at pdf.com  Sat Feb 28 15:51:32 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 28 Feb 2004 06:51:32 -0800
Subject: [R] SVD/Eigenvector confusion
In-Reply-To: <6.0.0.22.0.20040229010300.0848a578@203.8.195.10>
References: <6.0.0.22.0.20040229002806.084975e8@203.8.195.10>	<6rsmgv2ths.fsf@bates4.stat.wisc.edu>
	<6.0.0.22.0.20040229010300.0848a578@203.8.195.10>
Message-ID: <4040AAF4.8090300@pdf.com>

The documentation ?svd says U and V are orthogonal, i.e., that the 
transpose is the inverse.  hope this helps.  spencer graves

Philip Warner wrote:

> At 01:01 AM 29/02/2004, Douglas Bates wrote:
>
>> Is there a reason you are doing the SVD in such a complicated way?
>> Why not use the svd function directly?
>
>
> I am using it to debug other code that is deigned to compute SVDs, so 
> I actually want to understand the intermediate steps in constricting 
> the SVD.
>
> Nothing I have seen in the various books & net sources I have read 
> seem to indicate that the eigenvectors for U & V have any special 
> requirements other than being of unit length, but the experimentation 
> in R seems to indicate otherwise, hence my confusion.
>
>
>
>
>
>
>>
>
> ----------------------------------------------------------------
> Philip Warner                    |     __---_____
> Albatross Consulting Pty. Ltd.   |----/       -  \
> (A.B.N. 75 008 659 498)          |          /(@)   ______---_
> Tel: (+61) 0500 83 82 81         |                 _________  \
> Fax: (+61) 03 5330 3172          |                 ___________ |
> Http://www.rhyme.com.au          |                /           \|
>                                  |    --________--
> PGP key available upon request,  |  /
> and from pgp.mit.edu:11371       |/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From pjw at rhyme.com.au  Sat Feb 28 15:54:16 2004
From: pjw at rhyme.com.au (Philip Warner)
Date: Sun, 29 Feb 2004 01:54:16 +1100
Subject: [R] SVD/Eigenvector confusion
In-Reply-To: <Pine.LNX.4.44.0402281400250.17376-100000@gannet.stats>
References: <6.0.0.22.0.20040229002806.084975e8@203.8.195.10>
	<Pine.LNX.4.44.0402281400250.17376-100000@gannet.stats>
Message-ID: <6.0.0.22.0.20040229014452.03cb1ab8@203.8.195.10>

At 01:17 AM 29/02/2004, Prof Brian Ripley wrote:
>On Sun, 29 Feb 2004, Philip Warner wrote:
>
> > My understanding of SVD is that, for A an mxn matrix, m > n:
> >
> >      A = UWV*
> >
> > where W is square root diagonal eigenvalues of A*A extended with zero
> > valued rows, and U and V are the left & right eigen vectors of A. But this
> > does not seem to be strictly true and seems to require specific
> > eigenvectors, and I am not at all sure how these are computed.
>
>(A %*% t(A) is required, BTW.)  That is not the definition of the SVD.
>It is true that U are eigenvectors of A %*% t(A) and V of t(A) %*% A, but
>that does not make them left/right eigenvectors of A (unless that is your
>private definition).

Sorry, that should have read 'left & right singular vectors', and I'm 
beginning to suspect that they are only the starting point for deriving the 
singular vectors (based on 
http://www.cs.utk.edu/~dongarra/etemplates/node191.html)


>   Since eigenvectors are not unique, it does mean that
>you cannot reverse the process, as you seem to be trying to do.
...cut...
> >
> > which seems a little off the mark.
>
>It is not expected to work.

Maybe not by you... 8-}



>There is no rule: the SVD is computed by a different algorithm.

So I assume my approach will not give me the singular vectors, and I need a 
different way of deriving them, is that right?


Thanks for your help, it is much appreciated.




----------------------------------------------------------------
Philip Warner                    |     __---_____
Albatross Consulting Pty. Ltd.   |----/       -  \
(A.B.N. 75 008 659 498)          |          /(@)   ______---_
Tel: (+61) 0500 83 82 81         |                 _________  \
Fax: (+61) 03 5330 3172          |                 ___________ |
Http://www.rhyme.com.au          |                /           \|
                                  |    --________--
PGP key available upon request,  |  /
and from pgp.mit.edu:11371       |/



From ripley at stats.ox.ac.uk  Sat Feb 28 15:57:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 28 Feb 2004 14:57:59 +0000 (GMT)
Subject: [R] SVD/Eigenvector confusion
In-Reply-To: <6.0.0.22.0.20040229014452.03cb1ab8@203.8.195.10>
Message-ID: <Pine.LNX.4.44.0402281456090.17514-100000@gannet.stats>

On Sun, 29 Feb 2004, Philip Warner wrote:

> At 01:17 AM 29/02/2004, Prof Brian Ripley wrote:
> >On Sun, 29 Feb 2004, Philip Warner wrote:
> >
> > > My understanding of SVD is that, for A an mxn matrix, m > n:
> > >
> > >      A = UWV*
> > >
> > > where W is square root diagonal eigenvalues of A*A extended with zero
> > > valued rows, and U and V are the left & right eigen vectors of A. But this
> > > does not seem to be strictly true and seems to require specific
> > > eigenvectors, and I am not at all sure how these are computed.
> >
> >(A %*% t(A) is required, BTW.)  That is not the definition of the SVD.
> >It is true that U are eigenvectors of A %*% t(A) and V of t(A) %*% A, but
> >that does not make them left/right eigenvectors of A (unless that is your
> >private definition).
> 
> Sorry, that should have read 'left & right singular vectors', and I'm 
> beginning to suspect that they are only the starting point for deriving the 
> singular vectors (based on 
> http://www.cs.utk.edu/~dongarra/etemplates/node191.html)
> 
> 
> >   Since eigenvectors are not unique, it does mean that
> >you cannot reverse the process, as you seem to be trying to do.
> ...cut...
> > >
> > > which seems a little off the mark.
> >
> >It is not expected to work.
> 
> Maybe not by you... 8-}
> 
> 
> 
> >There is no rule: the SVD is computed by a different algorithm.
> 
> So I assume my approach will not give me the singular vectors, and I need a 
> different way of deriving them, is that right?

I think there are ways to derive the correct signs, but your approach is a 
poor way to do the calculations as it squares the condition number of A.

There are standard algorithms for computing the SVD from A alone.

> 
> 
> Thanks for your help, it is much appreciated.
> 
> 
> 
> 
> ----------------------------------------------------------------
> Philip Warner                    |     __---_____
> Albatross Consulting Pty. Ltd.   |----/       -  \
> (A.B.N. 75 008 659 498)          |          /(@)   ______---_
> Tel: (+61) 0500 83 82 81         |                 _________  \
> Fax: (+61) 03 5330 3172          |                 ___________ |
> Http://www.rhyme.com.au          |                /           \|
>                                   |    --________--
> PGP key available upon request,  |  /
> and from pgp.mit.edu:11371       |/ 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tomas.willebrand at szooek.slu.se  Sat Feb 28 19:52:33 2004
From: tomas.willebrand at szooek.slu.se (tomas.willebrand@szooek.slu.se)
Date: Sat, 28 Feb 2004 19:52:33 +0100
Subject: [R] Stepwise regression and partial correlation for wildlife census
	time series
Message-ID: <4040F181.585.6C98DAB@localhost>

Dear List;

We are doing a time series analysis of wildlife census data. We use a 
stepwise regression of the annual per capita rate of increase against 
pervious years population size (log transformed) as suggested by 
Berryman & Turchin (2001, Oikos 92:265-270). 

How can we obtain the partial correlation coefficients in R to make a 
plot of them against the lag as in a standard PACF?

Yours Sincerely

Tomas Willebrand



From guano at usp.br  Sat Feb 28 20:54:29 2004
From: guano at usp.br (Carlos Henrique Grohmann)
Date: Sat, 28 Feb 2004 16:54:29 -0300
Subject: [R] questions about anova
Message-ID: <1077998069.4040f1f51f727@webmail.usp.br>

Hello all,

I have two questions about anova (one is probably VERY basic...)

1 - when one asks for a summary of a trend surface created with surf.ls, he/she
gets:

> summary(g3r)
Analysis of Variance Table
 Model: surf.ls(np = 3, x = gradiente$east, y = gradiente$north, z =
gradiente$num1)
             Sum Sq    Df      Mean Sq  F value     Pr(>F)
Regression 215.7182     9 23.968693976 2686.508 < 2.22e-16
Deviation  480.1218 53814  0.008921876
Total      695.8401 53823
Multiple R-Squared: 0.31,       Adjusted R-squared: 0.3099
AIC: (df = 53814) -146390.9
Fitted:
     Min       1Q   Median       3Q      Max
0.007852 0.075619 0.100498 0.139042 0.338186
Residuals:
     Min       1Q   Median       3Q      Max
-0.29758 -0.04418 -0.01411  0.02536  0.51484
>

So, what's the meaning of the "Pr(>F)?



2 - I have six trend surfaces, and I like to make a anova for the significance
of increasing the degree of polynomial (like in Davis, 1986, p.422, Statistics
and data analysis in geology).

is there a way I can do it automatically or should I do it manually?


Thanks all.


-- 
+-------------------------------------------------+
        Carlos Henrique Grohmann - Guano  
    Geologist - MSc Student at IGc-USP - Brazil
       Linux User #89721  ICQ: 214752832
+-------------------------------------------------+



From spencer.graves at pdf.com  Sat Feb 28 21:31:04 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 28 Feb 2004 12:31:04 -0800
Subject: [R] questions about anova
In-Reply-To: <1077998069.4040f1f51f727@webmail.usp.br>
References: <1077998069.4040f1f51f727@webmail.usp.br>
Message-ID: <4040FA88.4000108@pdf.com>

      "Pr(>F)" = probability of obtaining by chance alone an "F value" 
at least as large as what was computed.  If this probability is small 
(as in this case), it is not credible to believe the null hypothesis.  
That is typically taken as evidence that there is a "statistically 
significant" trend surface.  However, it could also mean that some other 
assumption, such as independent observations, is violated.  I don't know 
"surf.ls", but from my cursory review of the documentation, it may 
assume independence, which may not be realistic in this case. 

      I'm not familiar with Davis, but to test increasing orders of 
trend surfaces, consider the following: 

 > data(topo, package="MASS")
 > topo.kr <- surf.ls(2, topo)
 > topo.kr3 <- surf.ls(3, topo)
 > anova(topo.kr, topo.kr3)
Analysis of Variance Table

Model 1: surf.ls(np = 2, x = topo)
Model 2: surf.ls(np = 3, x = topo)
  Res.Df Res.Sum Sq Df Sum Sq F value    Pr(>F)
1     46      39958                           
2     42      21577  4  18381  8.9447 2.558e-05
 > p.23 <- anova(topo.kr, topo.kr3)[2, "Pr(>F)"]
Analysis of Variance Table

Model 1: surf.ls(np = 2, x = topo)
Model 2: surf.ls(np = 3, x = topo)
  Res.Df Res.Sum Sq Df Sum Sq F value    Pr(>F)
1     46      39958                           
2     42      21577  4  18381  8.9447 2.558e-05
 > p.23
[1] 2.558186e-05

      You can put this in a "for" loop to fit and evaluate increasing 
orders of surfaces and put that inside a function.  If you need help 
with that, please consult the substantial documentation provided with R 
or downloadable from "www.r-project.org" or in other references such as 
Venables and Ripley (2002) Modern Applied Statistics with S, 4th ed. 
(Springer). 

      Hope this helps.  spencer graves

Carlos Henrique Grohmann wrote:

>Hello all,
>
>I have two questions about anova (one is probably VERY basic...)
>
>1 - when one asks for a summary of a trend surface created with surf.ls, he/she
>gets:
>
>  
>
>>summary(g3r)
>>    
>>
>Analysis of Variance Table
> Model: surf.ls(np = 3, x = gradiente$east, y = gradiente$north, z =
>gradiente$num1)
>             Sum Sq    Df      Mean Sq  F value     Pr(>F)
>Regression 215.7182     9 23.968693976 2686.508 < 2.22e-16
>Deviation  480.1218 53814  0.008921876
>Total      695.8401 53823
>Multiple R-Squared: 0.31,       Adjusted R-squared: 0.3099
>AIC: (df = 53814) -146390.9
>Fitted:
>     Min       1Q   Median       3Q      Max
>0.007852 0.075619 0.100498 0.139042 0.338186
>Residuals:
>     Min       1Q   Median       3Q      Max
>-0.29758 -0.04418 -0.01411  0.02536  0.51484
>  
>
>
>So, what's the meaning of the "Pr(>F)?
>
>
>
>2 - I have six trend surfaces, and I like to make a anova for the significance
>of increasing the degree of polynomial (like in Davis, 1986, p.422, Statistics
>and data analysis in geology).
>
>is there a way I can do it automatically or should I do it manually?
>
>
>Thanks all.
>
>
>  
>



From Roger.Bivand at nhh.no  Sat Feb 28 22:09:36 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 28 Feb 2004 22:09:36 +0100 (CET)
Subject: [R] questions about anova
In-Reply-To: <1077998069.4040f1f51f727@webmail.usp.br>
Message-ID: <Pine.LNX.4.44.0402282158250.14627-100000@reclus.nhh.no>

On Sat, 28 Feb 2004, Carlos Henrique Grohmann wrote:

> Hello all,
> 
> I have two questions about anova (one is probably VERY basic...)
> 

About surf.ls() in the spatial package, and documented in Venables & 
Ripley Modern Applied Statistics with S ...

> 1 - when one asks for a summary of a trend surface created with surf.ls,
> he/she gets:
> 
> > summary(g3r)
> Analysis of Variance Table
>  Model: surf.ls(np = 3, x = gradiente$east, y = gradiente$north, z =
> gradiente$num1)
>              Sum Sq    Df      Mean Sq  F value     Pr(>F)
> Regression 215.7182     9 23.968693976 2686.508 < 2.22e-16
> Deviation  480.1218 53814  0.008921876
> Total      695.8401 53823
> Multiple R-Squared: 0.31,       Adjusted R-squared: 0.3099
> AIC: (df = 53814) -146390.9
> Fitted:
>      Min       1Q   Median       3Q      Max
> 0.007852 0.075619 0.100498 0.139042 0.338186
> Residuals:
>      Min       1Q   Median       3Q      Max
> -0.29758 -0.04418 -0.01411  0.02536  0.51484
> >
> 
> So, what's the meaning of the "Pr(>F)?
> 

Roughly here that, if the model assumptions are met, that the reduction of 
sum of squares from total to deviation could have occurred at random, and 
that the reduction represented by the cubic trend surface does make a 
difference. Note that the observations are probably not independent, so 
the assumptions may not be met, and with the number of observations you 
have here, almost anything will appear to be significant.

> 
> 
> 2 - I have six trend surfaces, and I like to make a anova for the significance
> of increasing the degree of polynomial (like in Davis, 1986, p.422, Statistics
> and data analysis in geology).
> 
> is there a way I can do it automatically or should I do it manually?
> 

See the example in help(anova.trls):

anova(topo0, topo1, topo2, topo3, topo4)

which compares the trend surfaces from 0 to 4th order. There are concerns 
about trying to fit higher-order surfaces because of co-linearity.

> 
> Thanks all.
> 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From hodgess at gator.uhd.edu  Sat Feb 28 22:13:11 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Sat, 28 Feb 2004 15:13:11 -0600
Subject: [R] Stepwise regression and pacf
Message-ID: <200402282113.i1SLDBD17078@gator.dt.uh.edu>

Hello Tomas!

There are functions for pacf and plot.acf.

They are in library(ts)

Hope this helps!

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu

To: R-help at stat.math.ethz.ch
Date: Sat, 28 Feb 2004 19:52:33 +0100
Subject: [R] Stepwise regression and partial correlation for wildlife census
	time series

Dear List;

We are doing a time series analysis of wildlife census data. We use a 
stepwise regression of the annual per capita rate of increase against 
pervious years population size (log transformed) as suggested by 
Berryman & Turchin (2001, Oikos 92:265-270). 

How can we obtain the partial correlation coefficients in R to make a 
plot of them against the lag as in a standard PACF?

Yours Sincerely

Tomas Willebrand



From p.murrell at auckland.ac.nz  Sat Feb 28 22:15:23 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Sun, 29 Feb 2004 10:15:23 +1300
Subject: [R] limit to complex plots?
References: <2ED3D11D.0809F47A.0D1322AF@netscape.net>
Message-ID: <404104EB.8060808@stat.auckland.ac.nz>

Hi

You could do this sort of thing easily using viewports in the grid 
package.  And you can combine "base" plots with grid viewports using the 
gridBase package.  Take a look at Volume 3(2) of R News for some 
examples and feel free to contact me directly if you have more 
questions;  I'm always interested to see examples of complex plots.

Paul


Suzanne E. Blatt wrote:
> Hello all.
> 
> I am trying to create one figure, divided into 6 graphs/plots each with an inset sub-figure.  I can use to layout command to generate one figure with one inset sub-figure, but cannot seem to do it for multiple figures on one page.
> 
> I've tried a test with the following code:
> 
> layout(matrix(c(1,2,3,4), nrow=2, byrow=TRUE))
> plot(rnorm(10), rnorm(10))
> plot(rnorm(10), rnorm(10))
> plot(rnorm(30), rnorm(30))
> plot(rnotm(40), rnorm(40))
> layout.show(4)
> 
> #this works and gives me my one page with 4 figures on it
> 
> layout(matrix(c(0,0,0,0,0,1,0,2,0,0,0,0,0,3,0,4), nrow=4, byrow=TRUE))
> par(new=TRUE)
> plot(rnorm(10), rnorm(10))
> 
> par(new=TRUE)
> plot(rnorm(20), rnorm(20))
> 
> par(new=TRUE)
> plot(rnorm(30), rnorm(30))
> 
> par(new=TRUE)
> plot(rnorm(40), rnorm(40))
> 
> # this is the part that doesn't.  I've tried only one 'par(new=TRUE)' command before ALL the plot commands and as written above.  The best I can get is 3 sub-figures #2,3 and 4, in positions 1,2 and 3.
> 
> Has anyone figured this out?
> 
> thanks,
> Suzanne Blatt
> 
> __________________________________________________________________
> Introducing the New Netscape Internet Service.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From p.murrell at auckland.ac.nz  Sat Feb 28 22:28:16 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Sun, 29 Feb 2004 10:28:16 +1300
Subject: [R] writing polygons/segments to shapefiles (.shp) or other	ArcGIS
	compatible file
References: <76A000A82289D411952F001083F9DD06047FE4E8@exsalem4-bu.odot.state.or.us>
	<001c01c3fca1$46d38f70$7aa3fb51@PC728329681112>
Message-ID: <404107F0.2010903@stat.auckland.ac.nz>

Hi


Patrick Giraudoux wrote:
> Hi,
> 
> Thanks for all those information and the most valuable library you have developed.
> 
> If somebody is to develop something to write shapefiles from polygon coordinates within R (most welcome), I don't think that the
> attribute file (dbf) will be an important issue. If we have got an output with the index to link the dbf records to each shape of a
> shapefile, any text file can be handled in R or Excel to create a dbf. The real issue is the encoding of the *.shp and *.shx  etc..
> (and an index file for the dbf)
> 
> Most important is to consider that ESRI has stopped developping ArcView and AVENUE. They have moved to ArGIS and Visual Basic. In
> this new generation framework, importation is managed with ArcToolBox which, to my knowledge, is very limited considering
> importation of text objects (actually I even wonder if one can import something but attribute tables without ArcInfo). For instance,
> the way I found to solve the problem I met was to write a programme in R to wrap the polygon coordinates in a text file readable in
> GRASS (an opensource GIS), to import it into GRASS and to export the shapefile from GRASS. This shapefile was finally imported to
> ArcGIS.  I would not insist on ESRI client policy. I just want to say that the more I know corporates the more I love opensource...
> 
> Anyway, there are many things that can be made in R which may deserve not only importation to R, but also exportation to many kinds
> of GIS. To write shapefiles from polygon, points or lines created in R would be most useful.


I don't know anything about shapefiles, but that's starting to sound 
like a "shapefile" graphics device (c.f. the gtkDevice, RSvgDevice 
packages).

Paul


> Many thanks for your interest and support,
> 
> Patrick Giraudoux
> 
> 
> Universit? de Franche-Comt?
> Laboratoire de Biologie environnementale
> EA3184 usc INRA
> F-25030 Besan?on Cedex
> 
> t?l.: +33 381 665 745
> fax.: +33 381 665 797
> http://lbe.univ-fcomte.fr
> 
> "Ce n'est pas en am?liorant la bougie que l'on a invent? l'?lectricit?", la recherche fondamentale est indispensable !
> 
> 
> 
> 
> ----- Original Message ----- 
> From: <Benjamin.STABLER at odot.state.or.us>
> To: <patrick.giraudoux at univ-fcomte.fr>
> Cc: <r-help at stat.math.ethz.ch>; <r-sig-geo at stat.math.ethz.ch>
> Sent: Thursday, February 26, 2004 7:11 PM
> Subject: Re: [R] writing polygons/segments to shapefiles (.shp) or other ArcGIS compatible file
> 
> 
> 
>>The main limitation of the shapefiles package that I put together is that it
>>does not create shapefiles from R objects - rather it only writes shapefiles
>>that have been read into R and manipulated within the constraints of the
>>existing file structure.  By this I mean that for example you can change the
>>coordinates of points and write them back out.  Or you can add a bunch of
>>blank columns in the DBF outside of R and then fill them in with R.  But I
>>did not write any code to calculate byte offsets and such and that are
>>needed when creating a shapefile from scratch.
>>
>>So what I do when I want to create a new shapefile from within R is write
>>out the format required by the ASCII Tool ArcView (Avenue) script.  This
>>script is available at: http://arcscripts.esri.com/details.asp?dbid=11442
>>The format is simple:
>>
>>Works for space delimited ascii to point, polygon and polyline. The format
>>for point ascii file is id, x, y (no comma for real data, space delimited).
>>For polygon & polyline ascii files, the format is code (1 for start point, 2
>>for middle points, 3 for end point), x, y (no comma for real data, space
>>delimited). Export shapefile to ascii file works for point, polyline and
>>polygon shapefiles. The output format file is id, x, y. For polygon and
>>polyline, the id is the sequence id of vertices.
>>
>>Thus all you have to do is write a text file, install the script in ArcView
>>and then use the ArcView extension to create a shapefile from the ASCII
>>file.  Unfortunately ASCII tool only works with the geography - you have to
>>add the attributes later.
>>
>>With all of that said, I would like to add to the shapefiles package the
>>ability to write out shapefiles from scratch.  Since the shapefiles format
>>is rather unique, I think it would be best to use the maptools ShapeList/Map
>>class format (or r-spatial's classes).  For starters the package would just
>>write out the geography (like the ASCII tool Avenue script).  Later would be
>>added the ability to write the dbf data out from the att.data element of the
>>Map object.
>>
>>Unfortunately I don't know when I will have the time to do this.  If anyone
>>else wants to do then please go ahead and I can help via email if needed.
>>But adding the ability to write out shapefiles from scratch is on my list.
>>Once I finish coding our travel demand model and we enter the application
>>phase (probably in a few months) then will our demand to output shapefiles
>>from R increase and I can justify spending the time to write the code.
>>
>>I apologize that I have not paid much attention to the r-sig-geo discussion
>>or Edzer's r-spatial project.  If there is an effort underway to write out
>>shapefiles then can someone please inform me of its status.  If not, then
>>maybe I can help.  Thanks.
>>
>>Benjamin Stabler
>>Transportation Planning Analysis Unit
>>Oregon Department of Transportation
>>555 13th Street NE, Suite 2
>>Salem, OR 97301  Ph: 503-986-4104
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From eraheem at hotmail.com  Sun Feb 29 04:27:27 2004
From: eraheem at hotmail.com (Enayetur Raheem)
Date: Sun, 29 Feb 2004 03:27:27 +0000
Subject: [R] LCG with modulo 2^30
Message-ID: <Sea2-F24tYFVvqzGt4D000334bd@hotmail.com>


I can't run a function which generates random numbrers using linear 
congruential generator. My multiplier is a=5+8^6, increment is b=1 and 
modulo is m=2^30.

the code I have written works for modulo upto  m=2^28.

For m= 2^29 , it says, can not allocate memory for the vector or something 
like that.
For m= 2^31 or more, its says the argument  "for i in 1:m "  is too large in 
magnitude.

I tried to increase the memory size but it did not  work.

Any help will be appreciated.

Thanks.
Raheem



From hodgess at gator.uhd.edu  Sun Feb 29 05:32:28 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Sat, 28 Feb 2004 22:32:28 -0600
Subject: [R] Phase Plane
Message-ID: <200402290432.i1T4WS928204@gator.dt.uh.edu>

Dear R People:

Is there a function available to for phase plane plotting,
please?

Thanks,

Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu

PS R 1.8.1 on Windows XP 2000



From seanpor at acm.org  Sun Feb 29 07:17:23 2004
From: seanpor at acm.org (Sean O'Riordain)
Date: Sun, 29 Feb 2004 06:17:23 +0000
Subject: [R] LCG with modulo 2^30
In-Reply-To: <Sea2-F24tYFVvqzGt4D000334bd@hotmail.com>
References: <Sea2-F24tYFVvqzGt4D000334bd@hotmail.com>
Message-ID: <404183F3.8070202@acm.org>

Hi Raheem,

Firstly - fair warning...I'm not an R expert at all!  However it is my 
understanding that the expression "for i in 1:m" creates a full vector 
in memory of all the consecutive numbers 1 to m... (i presume these are 
4-byte ints here otherwise it would have fallen over before 2^29), but 
taking the minimal assumption of ints these take 4 bytes... 1:2^29 
requires (2^29)*4 bytes of memory - running on a 32-bit platform you 
have an absolute maximum of about 2^32 bytes of addressable memory (some 
memory will be taken by the os...).

if you start R and say "gc()" it'll tell you about memory allocated... 
then try k<-c(1:2^24); gc() and you might get a response something like...
 > gc()
         used (Mb) gc trigger (Mb)
Ncells 208431  5.6     407500 10.9
Vcells  73157  0.6     786432  6.0
 > k <- c(1:2^24)
 > gc()
          used (Mb) gc trigger  (Mb)
Ncells  208431  5.6     407500  10.9
Vcells 8428997 64.4   17108043 130.6

if you REALLY want to interate to 2^32 without allocating a huge memory 
vector like that try using your own counter and a while loop instead 
which won't allocate more memory than you have - but this will likely be 
SLOW... something along the lines of
i <- 0
while (i < 2^32) {
    # now we do stuff
    i <- i+1
}

i'm quite sure that there are more 'R-ish' ways of doing things...

btw. what are you trying to achieve?

Sean

Enayetur Raheem wrote:

>
> I can't run a function which generates random numbrers using linear 
> congruential generator. My multiplier is a=5+8^6, increment is b=1 and 
> modulo is m=2^30.
>
> the code I have written works for modulo upto  m=2^28.
>
> For m= 2^29 , it says, can not allocate memory for the vector or 
> something like that.
> For m= 2^31 or more, its says the argument  "for i in 1:m "  is too 
> large in magnitude.
>
> I tried to increase the memory size but it did not  work.
>
> Any help will be appreciated.
>
> Thanks.
> Raheem
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>



From gagongabe at earthlink.net  Sun Feb 29 07:49:17 2004
From: gagongabe at earthlink.net (Gabriel Lawson)
Date: Sat, 28 Feb 2004 22:49:17 -0800
Subject: [R] Rcmd SHLIB
Message-ID: <007d01c3fe90$26c164a0$6501a8c0@lankhmar>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040228/0d33f530/attachment.pl

From ripley at stats.ox.ac.uk  Sun Feb 29 08:48:11 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 29 Feb 2004 07:48:11 +0000 (GMT)
Subject: [R] LCG with modulo 2^30
In-Reply-To: <404183F3.8070202@acm.org>
Message-ID: <Pine.LNX.4.44.0402290739140.29606-100000@gannet.stats>

One quick addition:

1:2^31 fails because it is trying to create a sequence of integers, and
the largest integer in R is 2^31-1.  For the same sort of reason, the
largest vector you can create is 2^31-1 elements, but on a 32-bit machine
you will run out of address space at 2^29 doubles, and very likely out of
memory before that (as on most 32-bit OSes allow a user process to access
2 or 3Gb rather than the theoretical maximum of 4Gb, to allow for a 
stack, for example).

On Sun, 29 Feb 2004, Sean O'Riordain wrote:

> Hi Raheem,
> 
> Firstly - fair warning...I'm not an R expert at all!  However it is my 
> understanding that the expression "for i in 1:m" creates a full vector 
> in memory of all the consecutive numbers 1 to m... (i presume these are 
> 4-byte ints here otherwise it would have fallen over before 2^29), but 
> taking the minimal assumption of ints these take 4 bytes... 1:2^29 
> requires (2^29)*4 bytes of memory - running on a 32-bit platform you 
> have an absolute maximum of about 2^32 bytes of addressable memory (some 
> memory will be taken by the os...).
> 
> if you start R and say "gc()" it'll tell you about memory allocated... 
> then try k<-c(1:2^24); gc() and you might get a response something like...
>  > gc()
>          used (Mb) gc trigger (Mb)
> Ncells 208431  5.6     407500 10.9
> Vcells  73157  0.6     786432  6.0
>  > k <- c(1:2^24)
>  > gc()
>           used (Mb) gc trigger  (Mb)
> Ncells  208431  5.6     407500  10.9
> Vcells 8428997 64.4   17108043 130.6
> 
> if you REALLY want to interate to 2^32 without allocating a huge memory 
> vector like that try using your own counter and a while loop instead 
> which won't allocate more memory than you have - but this will likely be 
> SLOW... something along the lines of
> i <- 0
> while (i < 2^32) {
>     # now we do stuff
>     i <- i+1
> }
> 
> i'm quite sure that there are more 'R-ish' ways of doing things...
> 
> btw. what are you trying to achieve?
> 
> Sean
> 
> Enayetur Raheem wrote:
> 
> >
> > I can't run a function which generates random numbrers using linear 
> > congruential generator. My multiplier is a=5+8^6, increment is b=1 and 
> > modulo is m=2^30.
> >
> > the code I have written works for modulo upto  m=2^28.
> >
> > For m= 2^29 , it says, can not allocate memory for the vector or 
> > something like that.
> > For m= 2^31 or more, its says the argument  "for i in 1:m "  is too 
> > large in magnitude.
> >
> > I tried to increase the memory size but it did not  work.
> >
> > Any help will be appreciated.
> >
> > Thanks.
> > Raheem
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Feb 29 08:54:32 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 29 Feb 2004 07:54:32 +0000 (GMT)
Subject: [R] Rcmd SHLIB
In-Reply-To: <007d01c3fe90$26c164a0$6501a8c0@lankhmar>
Message-ID: <Pine.LNX.4.44.0402290748330.29606-100000@gannet.stats>

Most likely you don't have dlltool in your path.  Further, I suspect you 
don't have the correct make in your path since AFAIK that does not use 
CreateProcess.

Please check and check again that you have followed exactly all the 
instructions in the file readme.packages.  See Q3.1 in the rw-FAQ.

On Sat, 28 Feb 2004, Gabriel Lawson wrote:

> Ok, I think I may have a path or permissions problem (below).  Anyone
> know which settings I should check?
> 
> When I use 
> 
> "Rcmd SHLIB <filename>"
> 
> I get:  
> 
> C:\Program Files\R\rw1081\bin>Rcmd SHLIB info.diffusion.c
> process_begin: CreateProcess((null), dlltool -k --as as --dllname R.dll --def R.
> exp --output-lib libR.a, ...) failed.
> make (e=2): The system cannot find the file specified.
> make[1]: *** [libR.a] Error 2
> make: *** [libR] Error 2

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From FMGCFMGC at terra.es  Sun Feb 29 13:38:54 2004
From: FMGCFMGC at terra.es (FMGCFMGC)
Date: Sun, 29 Feb 2004 12:38:54 GMT
Subject: [R] matrix inverse in C
Message-ID: <ee599ee826.ee826ee599@teleline.es>

Hello!

For calculating the Choleski factor, you should look at:

LINPACK: dpofa, dchdc, (dppfa, although i think this one is not 
included with R)

The R code of function chol() is a good starting point. It is located at
%RHOME%/library/base/R/base (line 4115 on the windows version of R 
1.8.1 patched)

LAPACK: dpotrf, dpotf2, dpptrf

For matrix inversion you have:

LAPACK: dgesv, dposv, dsysv for general, positive definite or symmetric 
matrices, respectively.

For instructions on how to use this subroutines, look at the comments 
in the code, available at:

LINPACK: http://www.netlib.org/linpack/
LAPACK:  http://www.netlib.org/lapack/

Good luck!
Francisco

----- Mensaje Original -----
De  "Liaw, Andy" <andy_liaw at merck.com> 
Fecha  Sat, 28 Feb 2004 08:40:41 -0500 
A  "'Kosuke Imai'" <kimai at princeton.edu>, r-help at stat.math.ethz.ch 
Asunto  RE: [R] matrix inverse in C 


In section 5.7 of the `Writing R Extensions' manual, it mentions the
interface to numerical linear algebra routines (LINPACK, etc.).  You 
will
need to figure out which are the ones you need and how to call them.  As
these are expressed as Fortran routines, you can call them from C using 
the
F77_CALL() macro mentioned in that manual.

I believe many would say that routines in Numerical Recipes are not 
really
`industrial strength'...

HTH,
Andy

> From: Kosuke Imai
> 
> Hi,
>   I'm writing an R package using the C code i've written. I'm 
> wondering if
> anyone knows an easy way to calculate an inverse and cholesky 
> factor of a
> matrix using the Fortran/C library of R: and how to call them 
> from C. My
> code is based on the Numerical Reciepe code, and I'm trying to use
> something that is already in R.
> Thanks for your help in advance,
> Kosuke
> 
> ---------------------------------------------------------
> Kosuke Imai               Office: Corwin Hall 041
> Assistant Professor       Phone: 609-258-6601 (Direct)
> Department of Politics    Fax: 609-258-1110 (Department)
> Princeton University      Email: kimai at Princeton.Edu
> Princeton, NJ 08544-1012  http://www.princeton.edu/~kimai



From ligges at statistik.uni-dortmund.de  Sun Feb 29 15:27:03 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 29 Feb 2004 15:27:03 +0100
Subject: [R] Phase Plane
In-Reply-To: <200402290432.i1T4WS928204@gator.dt.uh.edu>
References: <200402290432.i1T4WS928204@gator.dt.uh.edu>
Message-ID: <4041F6B7.4020808@statistik.uni-dortmund.de>

Erin Hodgess wrote:

> Dear R People:
> 
> Is there a function available to for phase plane plotting,
> please?
> 
> Thanks,
> 
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
> 
> PS R 1.8.1 on Windows XP 2000
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

What about
   plot(x[-length(x)], x[-1])
(for lag 1; easily extendable to arbitrary lags). Or do I miss anything?

Uwe Ligges



From mcardeal at atarde.com.br  Sun Feb 29 15:35:06 2004
From: mcardeal at atarde.com.br (Carlos Mauricio Cardeal Mendes)
Date: Sun, 29 Feb 2004 11:35:06 -0300
Subject: [R] Proportions again
Message-ID: <007f01c3fed1$3a237c90$91f3fea9@quem>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040229/c877fa38/attachment.pl

From andrewr at uidaho.edu  Sun Feb 29 15:44:15 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Sun, 29 Feb 2004 06:44:15 -0800
Subject: [R] Proportions again
In-Reply-To: <007f01c3fed1$3a237c90$91f3fea9@quem>
References: <007f01c3fed1$3a237c90$91f3fea9@quem>
Message-ID: <200402290644.15390.andrewr@uidaho.edu>

table(sex)/length(sex)

Andrew

On Sunday 29 February 2004 06:35, Carlos Mauricio Cardeal Mendes wrote:
> Hello.
>
> I asked before and it was great, cause as a beginner I learned a lot. But, 
if I have this in R (1 and 2 are codes for sex):
> > sex<-c(1,2,2,1,1,2,2,2)
> > sex
>
> [1] 1 2 2 1 1 2 2 2
>
> I?d like to obtain the proportion according to sex.So I type:
> > prop.table(sex)
>
> [1] 0.07692308 0.15384615 0.15384615 0.07692308 0.07692308 0.15384615
> 0.15384615 [8] 0.15384615
>
> The result is OK, but I expected to see a simple frequency table or
> something like that:
>
> 1   0.375
> 2   0.625
>      1.0
>
> How can I get this ?
>
> Thank you very much
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson                      Ph: 208 885 7115
Department of Forest Resources       Fa: 208 885 6226
University of Idaho                  E : andrewr at uidaho.edu
PO Box 441133                        W : http://www.uidaho.edu/~andrewr
Moscow ID 83843                      Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From ccleland at optonline.net  Sun Feb 29 15:50:43 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Sun, 29 Feb 2004 09:50:43 -0500
Subject: [R] Proportions again
In-Reply-To: <200402290644.15390.andrewr@uidaho.edu>
References: <007f01c3fed1$3a237c90$91f3fea9@quem>
	<200402290644.15390.andrewr@uidaho.edu>
Message-ID: <4041FC43.7030503@optonline.net>

> Carlos Mauricio Cardeal Mendes wrote:
> I asked before and it was great, cause as a beginner I learned a lot. But, 
> 
> if I have this in R (1 and 2 are codes for sex):
> 
>> sex<-c(1,2,2,1,1,2,2,2)
>> sex
>
> [1] 1 2 2 1 1 2 2 2
>
> I?d like to obtain the proportion according to sex.So I type:
>
>> prop.table(sex)
>
> [1] 0.07692308 0.15384615 0.15384615 0.07692308 0.07692308 0.15384615
> 0.15384615 [8] 0.15384615
>
> The result is OK, but I expected to see a simple frequency table or
> something like that:
>
> 1   0.375
> 2   0.625
>      1.0
>
> How can I get this ?

prop.table(table(sex))

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From jfox at mcmaster.ca  Sun Feb 29 15:57:13 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 29 Feb 2004 09:57:13 -0500
Subject: [R] Proportions again
In-Reply-To: <007f01c3fed1$3a237c90$91f3fea9@quem>
Message-ID: <20040229145712.QYHN2607.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Carlos,

prop.table() takes a table as its argument, so you could specify
prop.table(table(sex)). See ?prop.table for more details.

John

> -----Original Message-----
> From: r-help-bounces+jfox=mcmaster.ca at stat.math.ethz.ch 
> [mailto:r-help-bounces+jfox=mcmaster.ca at stat.math.ethz.ch] On 
> Behalf Of Carlos Mauricio Cardeal Mendes
> Sent: Sunday, February 29, 2004 9:35 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Proportions again
> 
> Hello.
> 
> I asked before and it was great, cause as a beginner I 
> learned a lot. But, if I have this in R (1 and 2 are codes for sex):
> 
> > sex<-c(1,2,2,1,1,2,2,2)
> > sex
> [1] 1 2 2 1 1 2 2 2
> 
> I?d like to obtain the proportion according to sex.So I type:
> 
> > prop.table(sex)
> [1] 0.07692308 0.15384615 0.15384615 0.07692308 0.07692308 
> 0.15384615 0.15384615 [8] 0.15384615
> 
> The result is OK, but I expected to see a simple frequency 
> table or something like that:
> 
> 1   0.375
> 2   0.625
>      1.0
> 
> How can I get this ? 
>



From parkhurs at ariel.ucs.indiana.edu  Sun Feb 29 15:59:26 2004
From: parkhurs at ariel.ucs.indiana.edu (David Parkhurst)
Date: Sun, 29 Feb 2004 09:59:26 -0500
Subject: [R] graphics device problems
Message-ID: <002401c3fed4$a4f2c000$0a6cfea9@parkhursthome>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040229/c9251481/attachment.pl

From p.dalgaard at biostat.ku.dk  Sun Feb 29 16:14:13 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Feb 2004 16:14:13 +0100
Subject: [R] Proportions again
In-Reply-To: <200402290644.15390.andrewr@uidaho.edu>
References: <007f01c3fed1$3a237c90$91f3fea9@quem>
	<200402290644.15390.andrewr@uidaho.edu>
Message-ID: <x2znb1dika.fsf@biostat.ku.dk>

Andrew Robinson <andrewr at uidaho.edu> writes:

> table(sex)/length(sex)

or, as is the intended usage:

> prop.table(table(sex))
sex
    1     2
0.375 0.625


> > I asked before and it was great, cause as a beginner I learned a lot. But, 
> if I have this in R (1 and 2 are codes for sex):
> > > sex<-c(1,2,2,1,1,2,2,2)
> > > sex
> >
> > [1] 1 2 2 1 1 2 2 2
> >
> > I?d like to obtain the proportion according to sex.So I type:
> > > prop.table(sex)
> >
> > [1] 0.07692308 0.15384615 0.15384615 0.07692308 0.07692308 0.15384615
> > 0.15384615 [8] 0.15384615
> >
> > The result is OK, but I expected to see a simple frequency table or
> > something like that:
> >
> > 1   0.375
> > 2   0.625
> >      1.0
> >
> > How can I get this ?


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Sun Feb 29 16:38:12 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 29 Feb 2004 16:38:12 +0100
Subject: [R] graphics device problems
In-Reply-To: <002401c3fed4$a4f2c000$0a6cfea9@parkhursthome>
References: <002401c3fed4$a4f2c000$0a6cfea9@parkhursthome>
Message-ID: <40420764.9070201@statistik.uni-dortmund.de>

David Parkhurst wrote:

> I'm using R 1.8.0 under windows XP.  I can't get certain of the graphics devices set up.  For example, when I copy this line directly from the "postscript" help screen, I get the error messages that follow it:
> 
> 
>>postscript("foo.ps")
> 
> Error in PS(file, old$paper, old$family, old$encoding, old$bg, old$fg,  : 
>         unable to start device PostScript
> In addition: Warning message: 
> cannot read afm file hvo_____.afm 
> 
> I have a similar problem with the pdf device (which I think is my preferred device for my present job):
> 
> 
>>pdf("myfile.pdf")
> 
> Error in PDF(file, old$family, old$encoding, old$bg, old$fg, width, height,  : 
>         unable to start device pdf
> In addition: Warning message: 
> cannot read afm file hvo_____.afm 
> 
> Any suggestions would be welcome.  

Looks like your installation is broken.

Does the file ...\rw1080\afm\hvo_____.afm exist? If yes, do you have 
read permissions?

You might want to re-install R. Also, it's a good idea to upgrade to 
R-1.8.1, because R-1.8.0 is a bit buggy on Windows ...

Uwe Ligges


> Dave Parkhurst
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From henric.nilsson at statisticon.se  Sun Feb 29 19:32:34 2004
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Sun, 29 Feb 2004 19:32:34 +0100
Subject: [R] stripchart and axes
Message-ID: <6.0.3.0.0.20040228164316.0461b348@10.0.10.66>

Hi,

I'd like to remove the axes from a plot produced by stripchart(). However, 
when trying stripchart(..., axes = FALSE), I get the error meassage

Error in stripchart(hypokvot1 ~ treatment, "jitter", pch = 1, vert = TRUE,  :
	unused argument(s) (axes ...)

using R 1.8.1 on Windows. Can it be done some other way? If not, maybe this 
functionality can be added to a future version of R?

//Henric



From ggrothendieck at myway.com  Sun Feb 29 19:40:54 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 29 Feb 2004 13:40:54 -0500 (EST)
Subject: [R] Proportions again
Message-ID: <20040229184054.7BD273958@mprdmxin.myway.com>



Several people have alrady answered you by this time and
in addition to their answers you might also be interested
in CrossTable in package gregmisc.


---
Date:   Sun, 29 Feb 2004 11:35:06 -0300 
From:   Carlos Mauricio Cardeal Mendes <mcardeal at atarde.com.br>
To:   <r-help at stat.math.ethz.ch> 
Subject:   [R] Proportions again 

 
Hello.

I asked before and it was great, cause as a beginner I learned a lot. But, if I have this in R (1 and 2 are codes for sex):

> sex<-c(1,2,2,1,1,2,2,2)
> sex
[1] 1 2 2 1 1 2 2 2

Id like to obtain the proportion according to sex.So I type:

> prop.table(sex)
[1] 0.07692308 0.15384615 0.15384615 0.07692308 0.07692308 0.15384615 0.15384615
[8] 0.15384615

The result is OK, but I expected to see a simple frequency table or something like that:

1 0.375
2 0.625
1.0

How can I get this ? 

Thank you very much



From apv at capital.net  Sun Feb 29 20:38:52 2004
From: apv at capital.net (Arend P. van der Veen)
Date: Sun, 29 Feb 2004 14:38:52 -0500
Subject: [R] RMySQL Not Loading
Message-ID: <1078083531.2848.5.camel@freebsd>

Hi,

I am having a problem getting RMySQL to run under FreeBSD 4.9.  I am
using R 1.8.1 with latest patches, MySQL 4.0.17 and RMySQL_0.03.tar.gz. 
Everything does appear to compile properly.  However when I access the
library I get the following error:

> library(RMySQL)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"/usr/local/R/lib/R/library/RMySQL/libs/RMySQL.so":
  /usr/local/R/lib/R/library/RMySQL/libs/RMySQL.so: Undefined symbol
"getopt_long"
Error in library(RMySQL) : .First.lib failed
>

I have seen errors like this posted for OS X users.  In that case the
problem was related getopt.  I am running libgnugetopt-1.2.  I was going
to try and install a second private copy of gnugetopt but was not sure
what version I should install and where I should get it from.

Does anybody have any suggestions and what I can do to work around this
?  

Thanks in advance,
Arend



From MSchwartz at medanalytics.com  Sun Feb 29 20:40:00 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 29 Feb 2004 13:40:00 -0600
Subject: [R] stripchart and axes
In-Reply-To: <6.0.3.0.0.20040228164316.0461b348@10.0.10.66>
References: <6.0.3.0.0.20040228164316.0461b348@10.0.10.66>
Message-ID: <1078083600.7704.23.camel@localhost.localdomain>

On Sun, 2004-02-29 at 12:32, Henric Nilsson wrote:
> Hi,
> 
> I'd like to remove the axes from a plot produced by stripchart(). However, 
> when trying stripchart(..., axes = FALSE), I get the error meassage
> 
> Error in stripchart(hypokvot1 ~ treatment, "jitter", pch = 1, vert = TRUE,  :
> 	unused argument(s) (axes ...)
> 
> using R 1.8.1 on Windows. Can it be done some other way? If not, maybe this 
> functionality can be added to a future version of R?


stripchart() will not honor that argument, which is why you are getting
the error.

Try calling the following before calling stripchart():

 par(yaxt = "n", xaxt = "n", bty = "n")

This will result in the axes being suppressed and no surrounding box.

Example:

# Save parameters to restore them after the plot
old.par <- par(no.readonly = TRUE)

x <- rnorm(50)
par(yaxt = "n", xaxt = "n", bty = "n")
stripchart(x)

# Restore the pars back to initial settings
par(old.par)

See ?par for more information on the above graphic parameters.

HTH,

Marc Schwartz



From MSchwartz at medanalytics.com  Sun Feb 29 20:48:27 2004
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 29 Feb 2004 13:48:27 -0600
Subject: [R] Proportions again
In-Reply-To: <20040229184054.7BD273958@mprdmxin.myway.com>
References: <20040229184054.7BD273958@mprdmxin.myway.com>
Message-ID: <1078084107.7704.32.camel@localhost.localdomain>

On Sun, 2004-02-29 at 12:40, Gabor Grothendieck wrote:
> Several people have alrady answered you by this time and
> in addition to their answers you might also be interested
> in CrossTable in package gregmisc.

Gabor,

Thanks for pointing out CrossTable().

Just as a quick heads up/clarification for Carlos, CrossTable() is
designed to cross-tabulate two vectors and generate counts,
row/column/table proportions and other results from the 2 dimensional
cross-tab in a (hopefully) nicely formatted fashion.

It is not presently designed to handle generating proportions from the
tabulation of a single vector with repeating values (such as Carlos'
example) and will generate an error message if a single vector is
passed.

In that scenario, as many folks have already recommended, the
combination of table() and prop.table() would be preferred.

HTH,

Marc Schwartz



From ajayshah at mayin.org  Sun Feb 29 18:14:21 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Sun, 29 Feb 2004 22:44:21 +0530
Subject: [R] Confused in simplest-possible function
Message-ID: <20040229171421.GA25919@igidr.ac.in>

I wrote the following code:

  ---------------------------------------------------------------------------
  oneindex <- function(x) {
        summary(x)
  }

  A <- read.table("try.data",
                  col.names=c("date", "lNifty"))
  summary(A)
  oneindex(A$lNifty)
  ---------------------------------------------------------------------------

where I read in data, make a summary directly, and then call a
function `oneindex' which merely makes a summary.

I'm puzzled because the two summaries disagree :

> oneindex <- function(x) {
+       summary(x)
+ }
> 
> A <- read.table("try.data",
+                 col.names=c("date", "lNifty"))
> summary(A)
         date         lNifty      
 2000-06-12:  1   Min.   : 854.2  
 2000-06-13:  1   1st Qu.:1032.8  
 2000-06-15:  1   Median :1088.7  
 2000-06-16:  1   Mean   :1123.6  
 2000-06-19:  1   3rd Qu.:1178.7  
 2000-06-20:  1   Max.   :1533.3  
 (Other)   :780                   
> oneindex(A$lNifty)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  854.2  1033.0  1089.0  1124.0  1179.0  1533.0 

Here you see the median showing up as 1088.7 in the 1st case but
1089.0 in the 2nd case. How could that happen?

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



