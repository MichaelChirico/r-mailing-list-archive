From hastie at stanford.edu  Sun Dec  1 03:58:16 2013
From: hastie at stanford.edu (Trevor Hastie)
Date: Sat, 30 Nov 2013 18:58:16 -0800
Subject: [R] MOOC on Statistical Learning with R
Message-ID: <7A598211-2300-499E-8501-2D59E7D1B8D2@stanford.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131130/e611a97d/attachment.pl>

From umairdurrani at outlook.com  Sun Dec  1 05:11:36 2013
From: umairdurrani at outlook.com (umair durrani)
Date: Sun, 1 Dec 2013 09:11:36 +0500
Subject: [R] How to get the proportions of data with respect to two
 variables in R?
Message-ID: <BLU170-W137EECD68A02431DBB399C6C9EB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131201/27855bf1/attachment.pl>

From halim10-fes at sust.edu  Sun Dec  1 05:45:45 2013
From: halim10-fes at sust.edu (halim10-fes)
Date: Sun, 1 Dec 2013 10:45:45 +0600
Subject: [R] Problems dealing with matrices
In-Reply-To: <1385655080.66014.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <20131123181936.M40852@sust.edu>
	<1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<20131124051233.M87627@sust.edu>
	<1385281433.29640.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1385284698.38816.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<20131124103317.M34808@sust.edu>
	<1385307924.1089.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<20131127023716.M4379@sust.edu>
	<1385526074.98197.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<20131128042927.M43811@sust.edu>
	<1385655080.66014.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <20131201042939.M94893@sust.edu>

Hi Arun,

Thank you very much for your kind response. Sorry for my delayed response. 
Your solutions for the first two questions are quite good for my purpose. 
Since nobody responded, can you please have a look at the 3rd question? It'll 
be my great help, if you can give me suggestions.

Regards,

Halim


On Thu, 28 Nov 2013 08:11:20 -0800 (PST), arun wrote
> Hi Halim,
> 
> For the first two questions, you may try:
> colsum1 <- colSums(volyrdc1)
> min(which(colsum1>=18))
> #[1] 29
> #or
> ?head(which(colsum1>=18),1)
> #140 
> # 29?
> 
> colsum1[substr(colsum1,6,7)=="00"]? ## this is not very clear
> ???? 305 
> 45.37004?
> #or
> colsum1[colsum1>=18][substr(colsum1[colsum1>=18],6,7)=="00"]
> ???? 305 
> 45.37004
> 
> #because
> sprintf("%.4f",colsum1[colsum1>=18])
> colsum1[colsum1>=18][gsub(".*\\.\\d{2}","",sprintf("%.4f",
> colsum1[colsum1>=18]))=="00"] ???? 180????? 305 
> 32.88996 45.37004
> 
> A.K.
> 
> On Thursday, November 28, 2013 3:57 AM, halim10-fes <halim10-
> fes at sust.edu> wrote: Hi,
> 
> Sorry for continuous bothering. Continuum of the previous problem...
> 
> I have the following matrices and vectors,
> 
> dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5)
> 
> volini<-matrix(c(0,0,0,0,0),nrow=5,ncol=1)
> 
> volinp1<-c(0, 0.0004669094, 0.0027610861, 0.0086204692, 0.0200137754, 
> 0.0389069106 ,0.0670942588, 0.1060941424, 0.1570990708, 0.2209672605, 
> 0.2982420945, 0.3891882830, 0.4938361307, 0.6120278338, 0.7434618363, 
> 0.8877329008, 1.0443667375, 1.2128488387, 1.3926476912, 1.5832328410, 
> 1.7840884399, 1.9947229566, 2.2146757191, 2.4435209092, 2.6808695568, 
> 2.9263700050, 3.1797072430, 3.4406014299, 3.7088058696, 3.9841046430, 
> 4.2663100561, 4.5552600226, 4.8508154713, 5.1528578389, 5.4612866929,
> 5.7760175114, 6.0969796345, 6.4241143947, 6.7573734248, 7, 7 ,7, 7,
>  7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
>  7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
>  7, 7, 7, 7, 7, 7, 7, 7,? 7,? 7, 7, 7)
> 
> I've calculated the following matrices vol and volyrdc1 (obviously 
> with the help of Jeff and Arun):
> 
> #Blank matrices for dumping final values
> 
> vol <- matrix( NA, nrow=5, ncol=length(volinp1))
> 
> volyrdc1<-matrix(NA, nrow=5,ncol=length(volinp1),dimnames= 
> list(c("DC1","DC2","DC3","DC4","DC5"),c(seq(0,500,5))))
> 
> vol[ , 1 ] <- dcmat %*% (volini+(volinp1[1]*wt))
> 
> wt<-matrix(c(1,0,0,0,0),nrow=5)
> 
> for ( idx in seq_along(volinp1)[ -1 ] ) { 
> ? vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp1[idx] * wt ) 
> }?
> 
> vol
> 
> volyrdc1[,1]<-vol[,1]
> 
> for ( idx in seq_along(volinp1)[ -1 ] ) { 
> ? volyrdc1[ , idx ] <- vol[ , idx-1 ] + volinp1[idx] * wt
> ? }? 
> volyrdc1
> 
> My final matrix in 'volyrdc1' (kind of transition matrix model).
> 
> Now, what I want to do is to calculate when the colsum<-
> colSums(volyrdc1) reaches a certain value and I want to get the 
> index of the element in the 'colsum' vector at that point. For e.g. 
> when colsum[colsum>=18] ? It will give a series of cases where the 
> condition is true. But I want index of the element immediately when 
> the condition is met. In this case, the answer I want is 140 
> (colsum[29] returns both value (18.63) and the character ("140") 
> attributing the index). Actually, in my case 140 is year (age) when 
> the 'colsum' becomes 
> >=18. At is point it would be great if I can calculate when 'colsum' levels 
> off (up to two decimal place)? The answer is: 305 and at that point 
> colsum==45.37.?
> 
> I also want to calculate what should be the value in volini[1,1] to 
> get a certain value in 'colsum' at a certain year (age)(vector 
> element index explained earlier)? For e.g. I want to find out that 
> what should be the value in volini[1,1] if I want colsum==18 at 
> 100(charater attributing colsum[21])? The answer is: 15910 and the 
> 'volini' matrix will look like:
> 
> volini<-matrix(c(15910,0,0,0,0),nrow=5,ncol=1)
> 
> Any pointer, suggestions,... will be gratefully acknowledged.
> 
> P.S. Can you please suggest me any effective R programming book that 
> describe core elements of R programming?
> 
> Thanks in advance.
> 
> Regards,
> 
> Halim? ? ? ? ? ? ? ? 
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
> 
> On Tue, 26 Nov 2013 20:21:14 -0800 (PST), arun wrote
> > HI Halim,
> > 
> > No problem.
> > Regards,
> > Arun
> > 
> > On Tuesday, November 26, 2013 11:18 PM, halim10-fes <halim10-
> > fes at sust.edu> wrote: Hi Arun,
> > 
> > Thanks for your help. Sorry for my late response. Take care and stay 
> > fine.
> > 
> > Regards,
> > 
> > Halim
> > 
> > On Sun, 24 Nov 2013 07:45:24 -0800 (PST), arun wrote
> > > Hi Halim,
> > > I guess this works for you.? Modifying Jeff's solution:
> > > 
> > > volinp<-c(0,0.000467,0.002762,0.008621,0.020014,0.038907,0.067094)
> > > vol1 <- dcmat %*% (volmat +wt)
> > > for(idx in seq_along(volinp)[-1]){
> > > ?vol1 <- cbind(vol1,dcmat %*% (vol1[,idx-1] + volinp[idx] *wt))
> > > ?}
> > > 
> > > #or
> > > 
> > > vol <- matrix( NA, nrow=5, ncol=length( volinp ) )
> > > vol[ , 1 ] <- dcmat %*% ( volmat + wt )
> > > 
> > > for ( idx in seq_along(volinp)[ -1 ] ) {
> > > ? vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp[idx] * wt )
> > > }
> > > identical(vol,vol1)
> > > #[1] TRUE
> > > 
> > > A.K.
> > > 
> > > On Sunday, November 24, 2013 7:16 AM, halim10-fes <halim10-
> > > fes at sust.edu> wrote: Hi Arun,
> > > 
> > > OK, no problem. Thank you very much for your attention. I've posted 
> > > an annex to my previous problem. I will appreciate your 
> > > comments/suggestions on it.
> > > 
> > > Off-topic: You're a very helpful man. I like your attitude to 
> > > helping others.
> > > 
> > > Take care.
> > > 
> > > Halim
> > > 
> > > On Sun, 24 Nov 2013 01:18:18 -0800 (PST), arun wrote
> > > > Hi,
> > > > Please disregard my earlier message. Looks like Jeff understand it 
> > > > better and answered it. Regards, Arun
> > > > 
> > > > On Sunday, November 24, 2013 3:23 AM, arun <smartpink111 at yahoo.com> 
> wrote:
> > > > Hi,
> > > > I am finding some inconsistency with your description.
> > > > For example:
> > > > volinp[1]+volmat[1,1]
> > > > [1] 101
> > > > 
> > > > On Sunday, November 24, 2013 1:52 AM, halim10-fes <halim10-
> > > > fes at sust.edu> wrote:
> > > > 
> > > > Please apologize me! Earlier I've sent a message erroneously. 
> > > > Following is the original problem for which I'm seeking help. 
> > > > Extremely sorry...?
> > > > 
> > > > Hi Arun,
> > > > 
> > > > Thank you very much for your response. Sorry, if I couldn't explain 
> > > > clearly. I think, I should restate the problem to get exactly what I 
> > > > want. Here it goes:
> > > > 
> > > > I have 2 matrices and 1 vector, namely,
> > > > 
> > > > dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> > > > 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> > > > 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5)
> > > > 
> > > > volmat<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> > > > 
> > > > volinp<-c(1:40)
> > > > 
> > > > What I essentially want to do is to multiply 'dcmat' with 'volmat' 
> > > > and dump the output in a new matrix 'vol'. But before that, in the 
> > > > first step, I want to add volinp[1] with volmat[1,1]. So, the first 
> > > > column of the output matrix 'vol' matrix will be:
> > > > 
> > > > ? ? ? ? [,1]
> > > > [1,]?? 13.13
> > > > [2,]?? 61.61
> > > > [3,]?? 25.25
> > > > [4,]? ? 0.00
> > > > [5,]? ? 0.00
> > > > 
> > > > In the 2nd step, I want to replace 'volmat' with vol[,1] and add 
> > > > volinp[2] with vol[1,1]. The new 'volmat' will look like:
> > > > 
> > > > ? ? ? ? [,1]
> > > > [1,]?? 15.13
> > > > [2,]?? 61.61
> > > > [3,]?? 25.25
> > > > [4,]? ? 0.00
> > > > [5,]? ? 0.00
> > > > 
> > > > Then multiply 'dcmat' with the new 'volmat', and the 2nd column of 
> > > > output matrix 'vol' will look like:
> > > > 
> > > > ? ? ? ? [,2]
> > > > [1,]? 1.9669
> > > > [2,] 41.2665
> > > > [3,] 41.2232
> > > > [4,] 13.1199
> > > > [5,]? 2.7775
> > > > 
> > > > Then again, replace the 'volmat' with vol[,2], add volinp[3] with 
> > > > vol[1,2] and multiply the new 'volmat' with 'dcmat'. This 
> > > > replacement, addition, multiplication, and dumping will continue up 
> > > > to the length of 'volinp' and the final output matrix 'vol' will be 
> > > > something like:
> > > > 
> > > > ? ? ? [,1]? ? [,2]? ? ? [,3]? ? ...length(volinp)
> > > > [1,] 13.13?? 1.9669?? 0.645697? ...
> > > > [2,] 61.61? 41.2665? 24.488389? ...
> > > > [3,] 25.25? 41.2232? 40.419786? ...
> > > > [4,]? 0.00? 13.1199? 22.116099? ...
> > > > [5,]? 0.00?? 2.7775?? 7.670905? ...?
> > > > 
> > > > Within my limited capacity, I've tried to come up with a solution 
> > > > but failed.
> > > > 
> > > > I'll appreciate your/others' help with gratefulness.
> > > > 
> > > > Regards,
> > > > 
> > > > Halim
> > > > 
> > > > ---------------
> > > > Md. Abdul Halim
> > > > Assistant Professor
> > > > Department of Forestry and Environmental Science
> > > > Shahjalal University of Science and Technology,Sylhet-3114,
> > > > Bangladesh.
> > > > Cell: +8801714078386.
> > > > alt. e-mail: xou03 at yahoo.com
> > > > 
> > > > On Sat, 23 Nov 2013 14:10:12 -0800 (PST), arun wrote
> > > > > Hi,
> > > > > Could you show your expected output?? It is a bit unclear from the 
> > > > description.
> > > > > 
> > > > > On Saturday, November 23, 2013 2:00 PM, halim10-fes <halim10-
> > > > > fes at sust.edu> wrote: Dear R-friends,
> > > > > 
> > > > > Hope you doing well. I've been trying to deal with the following 
> > > > > problem for the couple of days but couldn't come up with a solution. 
> > > > > It would be great if any of you could give some insight into it.
> > > > > 
> > > > > I have three matrices like:
> > > > > 
> > > > > dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> > > > > 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> > > > > 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5) 
> > > > volinp<-
> > > > > matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> > > > > 
> > > > > scvol<-matrix(c(1:40),nrow=5,ncol=8)
> > > > > 
> > > > > What I essentially want to do is to add each value in scvol[1,] with 
> > > > > the volinp[1,1] and then multiply each new volinp with dcvol and 
> > > > > finally put the outputs in a new matrix.
> > > > > 
> > > > > Thanks in advance.
> > > > > 
> > > > > Halim? ? ? ? ? ? ? ? 
> > > > > ---------------
> > > > > Md. Abdul Halim
> > > > > Assistant Professor
> > > > > Department of Forestry and Environmental Science
> > > > > Shahjalal University of Science and Technology,Sylhet-3114,
> > > > > Bangladesh.
> > > > > Cell: +8801714078386.
> > > > > alt. e-mail: xou03 at yahoo.com
> > > > > 
> > > > > -- 
> > > > > This message has been scanned for viruses and
> > > > > dangerous content by MailScanner, and is
> > > > > believed to be clean.
> > > > > 
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > 
> > > > -- 
> > > > This message has been scanned for viruses and
> > > > dangerous content by MailScanner, and is
> > > > believed to be clean.
> > > > 
> > > > -- 
> > > > This message has been scanned for viruses and
> > > > dangerous content by MailScanner, and is
> > > > believed to be clean.
> 
> > 
> > > 
> > > ---------------
> > > Md. Abdul Halim
> > > Assistant Professor
> > > Department of Forestry and Environmental Science
> > > Shahjalal University of Science and Technology,Sylhet-3114,
> > > Bangladesh.
> > > Cell: +8801714078386.
> > > alt. e-mail: xou03 at yahoo.com
> > > 
> > > -- 
> > > This message has been scanned for viruses and
> > > dangerous content by MailScanner, and is
> > > believed to be clean.
> > > 
> > > -- 
> > > This message has been scanned for viruses and
> > > dangerous content by MailScanner, and is
> > > believed to be clean.
> > 
> > ---------------
> > Md. Abdul Halim
> > Assistant Professor
> > Department of Forestry and Environmental Science
> > Shahjalal University of Science and Technology,Sylhet-3114,
> > Bangladesh.
> > Cell: +8801714078386.
> > alt. e-mail: xou03 at yahoo.com
> > 
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> > 
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> 
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.


---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From gunter.berton at gene.com  Sun Dec  1 08:16:15 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 30 Nov 2013 23:16:15 -0800
Subject: [R] How to get the proportions of data with respect to two
 variables in R?
In-Reply-To: <BLU170-W137EECD68A02431DBB399C6C9EB0@phx.gbl>
References: <BLU170-W137EECD68A02431DBB399C6C9EB0@phx.gbl>
Message-ID: <CACk-te1OLCrQUQg3DspcsfmNWO0BfMzRbRNJAebH5eRGE7kWYQ@mail.gmail.com>

1. A nice example of why posting a small reproducible example would
help get you a useful reply. Your wordy description may not suffice.

2. You are requested not to post in HTML. This is a mailing list, not
a web application.

3. table(class$'Vehicle width') is not a function; it is a table
object returned by the table() function. You need to spend some
additional effort learning R (lots of good tutorials out there and
there's the Intro to R doc that shipes with R) so that you understand
the difference. It clearly matters, no?

4. A stab at an answer (**untested in the absence of data**):

Create a new variable, call it size, via:

b <- within(b,size <- paste0(length, width) ) ## Use simpler names to
avoid quotes
## Size is your unique model identifier -- maybe. Then

with(b,table(ID,class,size))

## should get you close, I think.

Others may have better insight if this is not what you're after.
Again, a small example  would probably be helpful.
Use data.frame() or dput() to include data in a post -- do NOT just
type the data in. See the posting guide for details.

Cheers,
Bert



On Sat, Nov 30, 2013 at 8:11 PM, umair durrani <umairdurrani at outlook.com> wrote:
> I have 4 columns: Vehicle ID, Vehicle Class, Vehicle Length and Vehicle Width. Every vehicle has a unique vehicle ID (e.g. 2, 4, 5,...) and the data was collected every 0.1 seconds which means that vehicle IDs are repeated in Vehicle ID column for the number of times they were observed. There are three vehicle classes i.e. 1=motorcycles, 2=cars, 3=trucks in the Vehicle Class column and the lengths and widths are in their respective columns against every vehicle ID. I want to subset the data by vehicle class and then find the proportions of each vehicle model (unique length and width) within every class. For example, for the Vehicle Class = 2 i.e. car, I want to find different models of cars (unique length and width) and their proportions with respect to total number of cars. Here is what I have done so far:To subset data by Vehicle Classcars <- subset(b, b$'Vehicle class'==2)
> trucks <- subset(b, b$'Vehicle class'==3)
> motorcycles <- subset(b, b$'Vehicle class'==1)To find the number of carsnumofcars <- length(unique(cars$'Vehicle ID')) # 2830
> numoftrucks <- length(unique(trucks$'Vehicle ID')) # 137
> numofmotorcycles <- length(unique(motorcycles$'Vehicle ID'))# 45The above code worked but I could not find the proportions by using the code below:by (cars, INDICES=cars$'Vehicle Length', FUN=table(class$'Vehicle width'))R gives an error stating that it could not find 'FUN'. Please help me in finding the proportions of each model within all classes of vehicles.
>
> Umair Durrani
>
> email: umairdurrani at outlook.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From smartpink111 at yahoo.com  Sun Dec  1 08:41:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 30 Nov 2013 23:41:28 -0800 (PST)
Subject: [R] How to get the proportions of data with respect to two
	variables in R?
In-Reply-To: <BLU170-W137EECD68A02431DBB399C6C9EB0@phx.gbl>
References: <BLU170-W137EECD68A02431DBB399C6C9EB0@phx.gbl>
Message-ID: <1385883688.25977.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
It is better to provide a reproducible example.
May be this helps:
set.seed(252)
dat1 <- data.frame(`Vehicle ID`=sample(150,150,replace=FALSE),`Vehicle Class`=rep(1:4,c(20,40,30,60)), `Vehicle length`= sample(15:25,150,replace=TRUE), `Vehicle width`= sample(4:10,150,replace=TRUE),check.names=FALSE)
cars <- subset(dat1,`Vehicle Class`==2)
?by(cars,INDICES=cars$`Vehicle length`,FUN=table(cars$`Vehicle width`))? 
#Error in FUN(X[[1L]], ...) : could not find function "FUN"

by(cars$`Vehicle width`,INDICES=cars$`Vehicle length`, table)
?by(dat1$`Vehicle width`,list(dat1$`Vehicle Class`,dat1$`Vehicle length`), table)


#Also, you may check

ftable(dat1[2:4])
prop.table(ftable(dat1[2:4]),1)


A.K.





On Sunday, December 1, 2013 12:08 AM, umair durrani <umairdurrani at outlook.com> wrote:
I have 4 columns: Vehicle ID, Vehicle Class, Vehicle Length and Vehicle Width. Every vehicle has a unique vehicle ID (e.g. 2, 4, 5,...) and the data was collected every 0.1 seconds which means that vehicle IDs are repeated in Vehicle ID column for the number of times they were observed. There are three vehicle classes i.e. 1=motorcycles, 2=cars, 3=trucks in the Vehicle Class column and the lengths and widths are in their respective columns against every vehicle ID. I want to subset the data by vehicle class and then find the proportions of each vehicle model (unique length and width) within every class. For example, for the Vehicle Class = 2 i.e. car, I want to find different models of cars (unique length and width) and their proportions with respect to total number of cars. Here is what I have done so far:To subset data by Vehicle Classcars <- subset(b, b$'Vehicle class'==2)
trucks <- subset(b, b$'Vehicle class'==3)
motorcycles <- subset(b, b$'Vehicle class'==1)To find the number of carsnumofcars <- length(unique(cars$'Vehicle ID')) # 2830
numoftrucks <- length(unique(trucks$'Vehicle ID')) # 137
numofmotorcycles <- length(unique(motorcycles$'Vehicle ID'))# 45The above code worked but I could not find the proportions by using the code below:by (cars, INDICES=cars$'Vehicle Length', FUN=table(class$'Vehicle width'))R gives an error stating that it could not find 'FUN'. Please help me in finding the proportions of each model within all classes of vehicles.

Umair Durrani

email: umairdurrani at outlook.com
??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From umairdurrani at outlook.com  Sun Dec  1 09:05:19 2013
From: umairdurrani at outlook.com (umair durrani)
Date: Sun, 1 Dec 2013 13:05:19 +0500
Subject: [R] How to get the proportions of data with respect to two
 variables in R?
In-Reply-To: <1385883688.25977.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <BLU170-W137EECD68A02431DBB399C6C9EB0@phx.gbl>,
	<1385883688.25977.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <BLU170-W199AAE8B91FA8399258F95C9EB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131201/d43d3dc8/attachment.pl>

From ashenkin at ufl.edu  Sun Dec  1 14:08:32 2013
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Sun, 01 Dec 2013 08:08:32 -0500
Subject: [R] How to vectorize plot graphic?
Message-ID: <529B34D0.80504@ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131201/da941206/attachment.pl>

From carl at witthoft.com  Sun Dec  1 16:39:10 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Sun, 1 Dec 2013 07:39:10 -0800 (PST)
Subject: [R] How to vectorize plot graphic?
In-Reply-To: <529B34D0.80504@ufl.edu>
References: <529B34D0.80504@ufl.edu>
Message-ID: <1385912350372-4681427.post@n4.nabble.com>

Off the top of my head,  I'd suggest trying ggsave()  with the extension
".svg" .  I realize that SVG files are not recognized by some image display
apps (Microsoft Windows I'm looking at YOU), but IMHO it's the best choice 
for vectorized images.


Alexander Shenkin wrote
> Hi Folks,
> 
> Using ggplot, I've produced the following graphic:
> http://i.imgur.com/39a139C.png
> 
> The graphics in the plot seem to be bitmapped and not vectorized.  That
> is, the vertical and horizontal lines jump rows of pixels instead of
> having just nice, angled lines.  Any thoughts about how to get these
> graphics vectorized?  Or am I misunderstanding something?
> 
> Another example:
> 
> The code:
> 
>     require(ggplot2)
>     df = data.frame(x = c(1:360), y = sin(seq(0,2*pi*3,length.out = 360)))
>     ggplot(df, aes(x=x, y=y)) + geom_line()
> 
> produces http://i.imgur.com/mjjSKih.png
> 
> Perhaps what I'm dealing with here is my screen resolution.  However, I
> use ggsave() to save .wmf files, and those also turn out to be bitmaps
> and not vectors.
> 
> Thanks,
> Allie
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/How-to-vectorize-plot-graphic-tp4681424p4681427.html
Sent from the R help mailing list archive at Nabble.com.


From stefanML at collocations.de  Sun Dec  1 16:42:32 2013
From: stefanML at collocations.de (Stefan Evert)
Date: Sun, 1 Dec 2013 16:42:32 +0100
Subject: [R] GotoBLAS2 with multiple cores
In-Reply-To: <CAJRSaT_6ZWNAdfUdrSvS_i5g6g0roq3TjFmkq3hALSLBGmhA4w@mail.gmail.com>
References: <CAJRSaT_6ZWNAdfUdrSvS_i5g6g0roq3TjFmkq3hALSLBGmhA4w@mail.gmail.com>
Message-ID: <C4DE5409-5FFB-4255-860C-7161EA1E4A11@collocations.de>

Your report sounds somewhat similar to problems I encountered with OpenBLAS on Ubuntu Linux (which is a maintained version of GotoBLAS; I couldn't get the latter to compile properly).

OpenBLAS uses OpenMP for parallelization.  Once linked into R, other OpenMP-based code would only use a single core any more. I have never used foreach, but I can imagine that something similar might be going on.

The workaround I found was to compile OpenBLAS with the setting NO_AFFINITY=1.  In addition, if you're running parallel code, I'd very much recommend to limit the number of threads within each parallel process by setting the OMP_NUM_THREADS environment variable (or in some other way).

Hope this helps,
Stefan


On 24 Nov 2013, at 10:03, Safiye Celik <safisce at gmail.com> wrote:

> So, is it possible to use many cores at the same time with GotoBLAS2, do
> you have any ideas?


From jholtman at gmail.com  Sun Dec  1 17:19:11 2013
From: jholtman at gmail.com (jim holtman)
Date: Sun, 1 Dec 2013 11:19:11 -0500
Subject: [R] How to get the proportions of data with respect to two
 variables in R?
In-Reply-To: <BLU170-W199AAE8B91FA8399258F95C9EB0@phx.gbl>
References: <BLU170-W137EECD68A02431DBB399C6C9EB0@phx.gbl>
	<1385883688.25977.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<BLU170-W199AAE8B91FA8399258F95C9EB0@phx.gbl>
Message-ID: <CAAxdm-7E1R33JFmgvj6N6_rpqU=msTZTAX=DY-KE_FPuu_Kocg@mail.gmail.com>

Here is an example using data.table to get the proportion for the Length/Width:

> input <- read.table(text = "'ID' 'Class' 'Length' 'Width'
+ 2 2 13.5 4.5
+ 2 2 13.5 4.5
+ 2 2 13.5 4.5
+ 2 2 13.5 4.5
+ 3 2 13.5 4.0
+ 3 2 13.5 4.0
+ 3 2 13.5 4.0
+ 3 2 13.5 4.0
+ 4 2 10.0 4.5
+ 4 2 10.0 4.5
+ 4 2 10.0 4.5
+ 4 2 10.0 4.5
+ 5 3 23.0 4.5
+ 5 3 23.0 4.5
+ 5 3 23.0 4.5
+ 5 3 23.0 4.5
+ 6 3 76.5 4.5
+ 6 3 76.5 4.5
+ 6 3 76.5 4.5
+ 6 3 76.5 4.5
+ 6 3 76.5 4.5
+ 7 1 10.0 3.0
+ 7 1 10.0 3.0
+ 7 1 10.0 3.0
+ 7 1 10.0 3.0
+ 8 2 13.5 5.5
+ 8 2 13.5 5.5
+ 8 2 13.5 5.5
+ 8 2 13.5 5.5", header = TRUE)
>
> # remove duplicates
> input <- subset(input, !duplicated(input))
> require(data.table)
> input <- data.table(input)
>
> # create counts by Length/Width
> counts <- input[
+     , list(count = .N)
+     , keyby = 'Class,Length,Width'
+     ]
>
> # add proportion
> counts$prop <- ave(counts$count
+             , counts$Class
+             , FUN = function(x) round(x / sum(x) * 100, 1)
+             )
>
> counts
   Class Length Width count prop
1:     1   10.0   3.0     1  100
2:     2   10.0   4.5     1   25
3:     2   13.5   4.0     1   25
4:     2   13.5   4.5     1   25
5:     2   13.5   5.5     1   25
6:     3   23.0   4.5     1   50
7:     3   76.5   4.5     1   50
>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sun, Dec 1, 2013 at 3:05 AM, umair durrani <umairdurrani at outlook.com> wrote:
> Thanks for your answers Arun. Unfortunately the code didn't work and I am getting the error: arguments must have same length. Here are sample input and output:
> INPUT:
> Vehicle ID Vehicle Class Vehicle Length Vehicle Width
> 2 2 13.5 4.5
> 2 2 13.5 4.5
> 2 2 13.5 4.5
> 2 2 13.5 4.5
> 3 2 13.5 4.0
> 3 2 13.5 4.0
> 3 2 13.5 4.0
> 3 2 13.5 4.0
> 4 2 10.0 4.5
> 4 2 10.0 4.5
> 4 2 10.0 4.5
> 4 2 10.0 4.5
> 5 3 23.0 4.5
> 5 3 23.0 4.5
> 5 3 23.0 4.5
> 5 3 23.0 4.5
> 6 3 76.5 4.5
> 6 3 76.5 4.5
> 6 3 76.5 4.5
> 6 3 76.5 4.5
> 6 3 76.5 4.5
> 7 1 10.0 3.0
> 7 1 10.0 3.0
> 7 1 10.0 3.0
> 7 1 10.0 3.0
> 8 2 13.5 5.5
> 8 2 13.5 5.5
> 8 2 13.5 5.5
> 8 2 13.5 5.5Note that in this input: Total number of cars=4, trucks=2, motorcycles=1
> Sample OutputGroup: cars
> VehicleLength VehicleWidth Proportion
> 13.5 4.5 0.25
> 13.5 4.0 0.25
> 13.5 5.5 0.25
> 23.0 4.5 0.25
>
> Group:trucks
> VehicleLength VehicleWidth Proportion
> 23.0 4.5 0.5
> 76.0 4.5 0.5
>
> Group: motorcycles
> VehicleLength VehicleWidth Proportion
> 10.0 3.0 1.0
>
> Umair Durrani
>
> email: umairdurrani at outlook.com
>
>
>> Date: Sat, 30 Nov 2013 23:41:28 -0800
>> From: smartpink111 at yahoo.com
>> Subject: Re: [R] How to get the proportions of data with respect to two variables in R?
>> To: r-help at r-project.org
>> CC: umairdurrani at outlook.com
>>
>> Hi,
>> It is better to provide a reproducible example.
>> May be this helps:
>> set.seed(252)
>> dat1 <- data.frame(`Vehicle ID`=sample(150,150,replace=FALSE),`Vehicle Class`=rep(1:4,c(20,40,30,60)), `Vehicle length`= sample(15:25,150,replace=TRUE), `Vehicle width`= sample(4:10,150,replace=TRUE),check.names=FALSE)
>> cars <- subset(dat1,`Vehicle Class`==2)
>>  by(cars,INDICES=cars$`Vehicle length`,FUN=table(cars$`Vehicle width`))
>> #Error in FUN(X[[1L]], ...) : could not find function "FUN"
>>
>> by(cars$`Vehicle width`,INDICES=cars$`Vehicle length`, table)
>>  by(dat1$`Vehicle width`,list(dat1$`Vehicle Class`,dat1$`Vehicle length`), table)
>>
>>
>> #Also, you may check
>>
>> ftable(dat1[2:4])
>> prop.table(ftable(dat1[2:4]),1)
>>
>>
>> A.K.
>>
>>
>>
>>
>>
>> On Sunday, December 1, 2013 12:08 AM, umair durrani <umairdurrani at outlook.com> wrote:
>> I have 4 columns: Vehicle ID, Vehicle Class, Vehicle Length and Vehicle Width. Every vehicle has a unique vehicle ID (e.g. 2, 4, 5,...) and the data was collected every 0.1 seconds which means that vehicle IDs are repeated in Vehicle ID column for the number of times they were observed. There are three vehicle classes i.e. 1=motorcycles, 2=cars, 3=trucks in the Vehicle Class column and the lengths and widths are in their respective columns against every vehicle ID. I want to subset the data by vehicle class and then find the proportions of each vehicle model (unique length and width) within every class. For example, for the Vehicle Class = 2 i.e. car, I want to find different models of cars (unique length and width) and their proportions with respect to total number of cars. Here is what I have done so far:To subset data by Vehicle Classcars <- subset(b, b$'Vehicle class'==2)
>> trucks <- subset(b, b$'Vehicle class'==3)
>> motorcycles <- subset(b, b$'Vehicle class'==1)To find the number of carsnumofcars <- length(unique(cars$'Vehicle ID')) # 2830
>> numoftrucks <- length(unique(trucks$'Vehicle ID')) # 137
>> numofmotorcycles <- length(unique(motorcycles$'Vehicle ID'))# 45The above code worked but I could not find the proportions by using the code below:by (cars, INDICES=cars$'Vehicle Length', FUN=table(class$'Vehicle width'))R gives an error stating that it could not find 'FUN'. Please help me in finding the proportions of each model within all classes of vehicles.
>>
>> Umair Durrani
>>
>> email: umairdurrani at outlook.com
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Dec  1 18:29:31 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 01 Dec 2013 09:29:31 -0800
Subject: [R] How to vectorize plot graphic?
In-Reply-To: <529B34D0.80504@ufl.edu>
References: <529B34D0.80504@ufl.edu>
Message-ID: <55d6f96e-c651-4282-853f-67d953e2a66d@email.android.com>

You have mentioned nothing about the device you are writing the plot to. If to the default and you are copying it from there as a bitmap, then what you are describing sounds as expected. Read the R Input/Output manual (again) for other output options.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Alexander Shenkin <ashenkin at ufl.edu> wrote:
>Hi Folks,
>
>Using ggplot, I've produced the following graphic:
>http://i.imgur.com/39a139C.png
>
>The graphics in the plot seem to be bitmapped and not vectorized.  That
>is, the vertical and horizontal lines jump rows of pixels instead of
>having just nice, angled lines.  Any thoughts about how to get these
>graphics vectorized?  Or am I misunderstanding something?
>
>Another example:
>
>The code:
>
>    require(ggplot2)
> df = data.frame(x = c(1:360), y = sin(seq(0,2*pi*3,length.out = 360)))
>    ggplot(df, aes(x=x, y=y)) + geom_line()
>
>produces http://i.imgur.com/mjjSKih.png
>
>Perhaps what I'm dealing with here is my screen resolution.  However, I
>use ggsave() to save .wmf files, and those also turn out to be bitmaps
>and not vectors.
>
>Thanks,
>Allie
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ashenkin at ufl.edu  Sun Dec  1 18:30:02 2013
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Sun, 01 Dec 2013 12:30:02 -0500
Subject: [R] How to vectorize plot graphic?
In-Reply-To: <1385912350372-4681427.post@n4.nabble.com>
References: <529B34D0.80504@ufl.edu> <1385912350372-4681427.post@n4.nabble.com>
Message-ID: <529B721A.4010803@ufl.edu>

Thanks Carl.  Yeah, I can get vectorized graphics out via
ggsave("temp.pdf") too.  But I need to add the graphic to a word doc on
windows.  Hence the desire to use wmf, which should induce a vector
format (shouldn't it?).

On 12/1/2013 10:39 AM, Carl Witthoft wrote:
> Off the top of my head,  I'd suggest trying ggsave()  with the extension
> ".svg" .  I realize that SVG files are not recognized by some image display
> apps (Microsoft Windows I'm looking at YOU), but IMHO it's the best choice 
> for vectorized images.
> 
> 
> Alexander Shenkin wrote
>> Hi Folks,
>>
>> Using ggplot, I've produced the following graphic:
>> http://i.imgur.com/39a139C.png
>>
>> The graphics in the plot seem to be bitmapped and not vectorized.  That
>> is, the vertical and horizontal lines jump rows of pixels instead of
>> having just nice, angled lines.  Any thoughts about how to get these
>> graphics vectorized?  Or am I misunderstanding something?
>>
>> Another example:
>>
>> The code:
>>
>>     require(ggplot2)
>>     df = data.frame(x = c(1:360), y = sin(seq(0,2*pi*3,length.out = 360)))
>>     ggplot(df, aes(x=x, y=y)) + geom_line()
>>
>> produces http://i.imgur.com/mjjSKih.png
>>
>> Perhaps what I'm dealing with here is my screen resolution.  However, I
>> use ggsave() to save .wmf files, and those also turn out to be bitmaps
>> and not vectors.
>>
>> Thanks,
>> Allie
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
> 
>> R-help@
> 
>>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-vectorize-plot-graphic-tp4681424p4681427.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ashenkin at ufl.edu  Sun Dec  1 18:39:24 2013
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Sun, 01 Dec 2013 12:39:24 -0500
Subject: [R] How to vectorize plot graphic?
In-Reply-To: <55d6f96e-c651-4282-853f-67d953e2a66d@email.android.com>
References: <529B34D0.80504@ufl.edu>
	<55d6f96e-c651-4282-853f-67d953e2a66d@email.android.com>
Message-ID: <529B744C.7030506@ufl.edu>

Thanks Jeff.  I'm not sure to which manual you are referring.  Nothing
like what you mention is found here:
http://cran.r-project.org/manuals.html .  Perhaps you're referring to
The Data Import/Export Manual, but that wouldn't make sense.  Googling
"R Input/Output manual" doesn't help.

Regarding the device, I'm in R-Studio, plotting to the standard device
there (I suppose).  In any case, I'm not totally sure what the interface
between R-Studio's plot window and the R instance is.  I think that, as
you say, what I'm getting is as expected.  I zoom and the plot zooms as
expected.  So, I guess that part is solved.  However, the writing to
.wmf as a bitmap instead of a vector is still a mystery to me.

Thanks,
Allie

On 12/1/2013 12:29 PM, Jeff Newmiller wrote:
> You have mentioned nothing about the device you are writing the plot to. If to the default and you are copying it from there as a bitmap, then what you are describing sounds as expected. Read the R Input/Output manual (again) for other output options.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> Alexander Shenkin <ashenkin at ufl.edu> wrote:
>> Hi Folks,
>>
>> Using ggplot, I've produced the following graphic:
>> http://i.imgur.com/39a139C.png
>>
>> The graphics in the plot seem to be bitmapped and not vectorized.  That
>> is, the vertical and horizontal lines jump rows of pixels instead of
>> having just nice, angled lines.  Any thoughts about how to get these
>> graphics vectorized?  Or am I misunderstanding something?
>>
>> Another example:
>>
>> The code:
>>
>>    require(ggplot2)
>> df = data.frame(x = c(1:360), y = sin(seq(0,2*pi*3,length.out = 360)))
>>    ggplot(df, aes(x=x, y=y)) + geom_line()
>>
>> produces http://i.imgur.com/mjjSKih.png
>>
>> Perhaps what I'm dealing with here is my screen resolution.  However, I
>> use ggsave() to save .wmf files, and those also turn out to be bitmaps
>> and not vectors.
>>
>> Thanks,
>> Allie
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From pdxgary163 at gmail.com  Sun Dec  1 18:48:50 2013
From: pdxgary163 at gmail.com (Gary Dong)
Date: Sun, 1 Dec 2013 09:48:50 -0800
Subject: [R] factor() in lm
Message-ID: <CAEVDvzXn6XU_gQk0z3jKbqznaJXTStmLawU8y2Aj-Lt5D88nsg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131201/e76cbc10/attachment.pl>

From amie_hunter at hotmail.com  Sun Dec  1 13:16:03 2013
From: amie_hunter at hotmail.com (Amie Hunter)
Date: Sun, 1 Dec 2013 12:16:03 +0000
Subject: [R] Removing NAs from matrix
Message-ID: <DUB124-W25B34E2307BBC5EF53F49180EB0@phx.gbl>

Hello R users,

I'm new to R so apologies if this question seems simple. I have a matrix which is 35000 columns by 35000 rows and I?m wanting to work out the mean of each row. I've tried using the code below on a smaller version of the matrix, but receive an error:

> mat
????? [,1]????? [,2] [,3]????? [,4]?????? [,5]????? [,6]????? [,7]????? [,8]????? [,9]???? [,10]???? [,11]
?[1,]?? NA 0.3904762? 0.2 0.4285714 0.04761905??????? NA??????? NA??????? NA??????? NA??????? NA??????? NA
?[2,]?? NA??????? NA? 0.2 0.2000000 0.23809524 0.2190476??????? NA??????? NA??????? NA??????? NA??????? NA
?[3,]?? NA??????? NA?? NA 0.5047619 0.27619048 0.2952381 0.1428571??????? NA??????? NA??????? NA??????? NA
?[4,]?? NA??????? NA?? NA??????? NA 0.42857143 0.3714286 0.3333333 0.2190476??????? NA??????? NA??????? NA
?[5,]?? NA??????? NA?? NA??????? NA???????? NA 0.8666667 0.6761905 0.4857143 0.6571429??????? NA??????? NA
?[6,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA 0.6190476 0.4285714 0.6761905 0.4857143??????? NA
?[7,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA??????? NA 0.6952381 0.6380952 0.6000000 0.2571429
?[8,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA??????? NA??????? NA 0.6761905 0.6000000 0.1809524
?[9,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA??????? NA??????? NA??????? NA 0.6190476 0.3142857
[10,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA??????? NA??????? NA??????? NA??????? NA 0.5809524
[11,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA??????? NA??????? NA??????? NA??????? NA??????? NA
> mean.matrix <- matrix(ncol=1, nrow=10)
> for (i in mat)
+ mean.matrix[,i] <- apply(mat,1,mean)
Error: NAs are not allowed in subscripted assignments

I have come across the na.omit() function however this completely removes the row. Is there any way I can either remove all the NAs from the matrix or pull out the values of each row to work out the mean? 

Thanks,

Amie 		 	   		  

From adel.daoud at sociology.gu.se  Sun Dec  1 12:46:44 2013
From: adel.daoud at sociology.gu.se (Adel)
Date: Sun, 1 Dec 2013 03:46:44 -0800 (PST)
Subject: [R] the wilcox.test() and pairwise.wilcox.test are producing
 different results
In-Reply-To: <1385753357.46286.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAEJCy7iDrz5kgc3Jj8GpiYr_7axo7j2goFA4W4YjJJPj2ATQRA@mail.gmail.com>
	<1385753357.46286.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1385898404919-4681423.post@n4.nabble.com>

Thanks Arun! It was simple as that. You suggestion solved it. 

Best
Adel



--
View this message in context: http://r.789695.n4.nabble.com/the-wilcox-test-and-pairwise-wilcox-test-are-producing-different-results-tp4681375p4681423.html
Sent from the R help mailing list archive at Nabble.com.


From jeet.chandvaniya at gmail.com  Sun Dec  1 15:04:22 2013
From: jeet.chandvaniya at gmail.com (jeet chandvaniya)
Date: Sun, 1 Dec 2013 19:34:22 +0530
Subject: [R] Code Help
Message-ID: <CAAJ33YPXi2xFg8rkHX+X4OAyhBHuFRyL0DjeaGrAn76qrjy94A@mail.gmail.com>

Hi, sir i want help to develop code  for outlier detection in r
language, so help me for this.

Thanks,
Jitendra R Chandvaniya
BE Computer,(M.TECH(Pursuing)).
RK University,
9824567443
Gujarat.


From smartpink111 at yahoo.com  Sun Dec  1 18:29:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 1 Dec 2013 09:29:23 -0800 (PST)
Subject: [R] Fw:  Problems dealing with matrices
In-Reply-To: <1385918234.74753.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <20131123181936.M40852@sust.edu>
	<1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<20131124051233.M87627@sust.edu>
	<1385281433.29640.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1385284698.38816.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<20131124103317.M34808@sust.edu>
	<1385307924.1089.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<20131127023716.M4379@sust.edu>
	<1385526074.98197.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<20131128042927.M43811@sust.edu>
	<1385655080.66014.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<20131201042939.M94893@sust.edu>
	<1385918234.74753.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1385918963.521.YahooMailNeo@web142604.mail.bf1.yahoo.com>





Hi Halim,

I tried, but couldn't come up with a solution.
Regards,
Arun





On Sunday, December 1, 2013 1:26 AM, halim10-fes <halim10-fes at sust.edu> wrote:
Hi Arun,

Thank you very much for your kind response. Sorry for my delayed response. 
Your solutions for the first two questions are quite good for my purpose. 
Since nobody responded, can you please have a look at the 3rd question? It'll 
be my great help, if you can give me suggestions.

Regards,

Halim


On Thu, 28 Nov 2013 08:11:20 -0800 (PST), arun wrote
> Hi Halim,
> 
> For the first two questions, you may try:
> colsum1 <- colSums(volyrdc1)
> min(which(colsum1>=18))
> #[1] 29
> #or
> ?head(which(colsum1>=18),1)
> #140 
> # 29?
> 
> colsum1[substr(colsum1,6,7)=="00"]? ## this is not very clear
> ???? 305 
> 45.37004?
> #or
> colsum1[colsum1>=18][substr(colsum1[colsum1>=18],6,7)=="00"]
> ???? 305 
> 45.37004
> 
> #because
> sprintf("%.4f",colsum1[colsum1>=18])
> colsum1[colsum1>=18][gsub(".*\\.\\d{2}","",sprintf("%.4f",
> colsum1[colsum1>=18]))=="00"] ???? 180????? 305 
> 32.88996 45.37004
> 
> A.K.
> 
> On Thursday, November 28, 2013 3:57 AM, halim10-fes <halim10-
> fes at sust.edu> wrote: Hi,
> 
> Sorry for continuous bothering. Continuum of the previous problem...
> 
> I have the following matrices and vectors,
> 
> dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5)
> 
> volini<-matrix(c(0,0,0,0,0),nrow=5,ncol=1)
> 
> volinp1<-c(0, 0.0004669094, 0.0027610861, 0.0086204692, 0.0200137754, 
> 0.0389069106 ,0.0670942588, 0.1060941424, 0.1570990708, 0.2209672605, 
> 0.2982420945, 0.3891882830, 0.4938361307, 0.6120278338, 0.7434618363, 
> 0.8877329008, 1.0443667375, 1.2128488387, 1.3926476912, 1.5832328410, 
> 1.7840884399, 1.9947229566, 2.2146757191, 2.4435209092, 2.6808695568, 
> 2.9263700050, 3.1797072430, 3.4406014299, 3.7088058696, 3.9841046430, 
> 4.2663100561, 4.5552600226, 4.8508154713, 5.1528578389, 5.4612866929,
> 5.7760175114, 6.0969796345, 6.4241143947, 6.7573734248, 7, 7 ,7, 7,
>? 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
>? 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
>? 7, 7, 7, 7, 7, 7, 7, 7,? 7,? 7, 7, 7)
> 
> I've calculated the following matrices vol and volyrdc1 (obviously 
> with the help of Jeff and Arun):
> 
> #Blank matrices for dumping final values
> 
> vol <- matrix( NA, nrow=5, ncol=length(volinp1))
> 
> volyrdc1<-matrix(NA, nrow=5,ncol=length(volinp1),dimnames= 
> list(c("DC1","DC2","DC3","DC4","DC5"),c(seq(0,500,5))))
> 
> vol[ , 1 ] <- dcmat %*% (volini+(volinp1[1]*wt))
> 
> wt<-matrix(c(1,0,0,0,0),nrow=5)
> 
> for ( idx in seq_along(volinp1)[ -1 ] ) { 
> ? vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp1[idx] * wt ) 
> }?
> 
> vol
> 
> volyrdc1[,1]<-vol[,1]
> 
> for ( idx in seq_along(volinp1)[ -1 ] ) { 
> ? volyrdc1[ , idx ] <- vol[ , idx-1 ] + volinp1[idx] * wt
> ? }? 
> volyrdc1
> 
> My final matrix in 'volyrdc1' (kind of transition matrix model).
> 
> Now, what I want to do is to calculate when the colsum<-
> colSums(volyrdc1) reaches a certain value and I want to get the 
> index of the element in the 'colsum' vector at that point. For e.g. 
> when colsum[colsum>=18] ? It will give a series of cases where the 
> condition is true. But I want index of the element immediately when 
> the condition is met. In this case, the answer I want is 140 
> (colsum[29] returns both value (18.63) and the character ("140") 
> attributing the index). Actually, in my case 140 is year (age) when 
> the 'colsum' becomes 
> >=18. At is point it would be great if I can calculate when 'colsum' levels 
> off (up to two decimal place)? The answer is: 305 and at that point 
> colsum==45.37.?
> 
> I also want to calculate what should be the value in volini[1,1] to 
> get a certain value in 'colsum' at a certain year (age)(vector 
> element index explained earlier)? For e.g. I want to find out that 
> what should be the value in volini[1,1] if I want colsum==18 at 
> 100(charater attributing colsum[21])? The answer is: 15910 and the 
> 'volini' matrix will look like:
> 
> volini<-matrix(c(15910,0,0,0,0),nrow=5,ncol=1)
> 
> Any pointer, suggestions,... will be gratefully acknowledged.
> 
> P.S. Can you please suggest me any effective R programming book that 
> describe core elements of R programming?
> 
> Thanks in advance.
> 
> Regards,
> 
> Halim? ? ? ? ? ? ? ? 
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
> 
> On Tue, 26 Nov 2013 20:21:14 -0800 (PST), arun wrote
> > HI Halim,
> > 
> > No problem.
> > Regards,
> > Arun
> > 
> > On Tuesday, November 26, 2013 11:18 PM, halim10-fes <halim10-
> > fes at sust.edu> wrote: Hi Arun,
> > 
> > Thanks for your help. Sorry for my late response. Take care and stay 
> > fine.
> > 
> > Regards,
> > 
> > Halim
> > 
> > On Sun, 24 Nov 2013 07:45:24 -0800 (PST), arun wrote
> > > Hi Halim,
> > > I guess this works for you.? Modifying Jeff's solution:
> > > 
> > > volinp<-c(0,0.000467,0.002762,0.008621,0.020014,0.038907,0.067094)
> > > vol1 <- dcmat %*% (volmat +wt)
> > > for(idx in seq_along(volinp)[-1]){
> > > ?vol1 <- cbind(vol1,dcmat %*% (vol1[,idx-1] + volinp[idx] *wt))
> > > ?}
> > > 
> > > #or
> > > 
> > > vol <- matrix( NA, nrow=5, ncol=length( volinp ) )
> > > vol[ , 1 ] <- dcmat %*% ( volmat + wt )
> > > 
> > > for ( idx in seq_along(volinp)[ -1 ] ) {
> > > ? vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp[idx] * wt )
> > > }
> > > identical(vol,vol1)
> > > #[1] TRUE
> > > 
> > > A.K.
> > > 
> > > On Sunday, November 24, 2013 7:16 AM, halim10-fes <halim10-
> > > fes at sust.edu> wrote: Hi Arun,
> > > 
> > > OK, no problem. Thank you very much for your attention. I've posted 
> > > an annex to my previous problem. I will appreciate your 
> > > comments/suggestions on it.
> > > 
> > > Off-topic: You're a very helpful man. I like your attitude to 
> > > helping others.
> > > 
> > > Take care.
> > > 
> > > Halim
> > > 
> > > On Sun, 24 Nov 2013 01:18:18 -0800 (PST), arun wrote
> > > > Hi,
> > > > Please disregard my earlier message. Looks like Jeff understand it 
> > > > better and answered it. Regards, Arun
> > > > 
> > > > On Sunday, November 24, 2013 3:23 AM, arun <smartpink111 at yahoo.com> 
> wrote:
> > > > Hi,
> > > > I am finding some inconsistency with your description.
> > > > For example:
> > > > volinp[1]+volmat[1,1]
> > > > [1] 101
> > > > 
> > > > On Sunday, November 24, 2013 1:52 AM, halim10-fes <halim10-
> > > > fes at sust.edu> wrote:
> > > > 
> > > > Please apologize me! Earlier I've sent a message erroneously. 
> > > > Following is the original problem for which I'm seeking help. 
> > > > Extremely sorry...?
> > > > 
> > > > Hi Arun,
> > > > 
> > > > Thank you very much for your response. Sorry, if I couldn't explain 
> > > > clearly. I think, I should restate the problem to get exactly what I 
> > > > want. Here it goes:
> > > > 
> > > > I have 2 matrices and 1 vector, namely,
> > > > 
> > > > dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> > > > 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> > > > 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5)
> > > > 
> > > > volmat<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> > > > 
> > > > volinp<-c(1:40)
> > > > 
> > > > What I essentially want to do is to multiply 'dcmat' with 'volmat' 
> > > > and dump the output in a new matrix 'vol'. But before that, in the 
> > > > first step, I want to add volinp[1] with volmat[1,1]. So, the first 
> > > > column of the output matrix 'vol' matrix will be:
> > > > 
> > > > ? ? ? ? [,1]
> > > > [1,]?? 13.13
> > > > [2,]?? 61.61
> > > > [3,]?? 25.25
> > > > [4,]? ? 0.00
> > > > [5,]? ? 0.00
> > > > 
> > > > In the 2nd step, I want to replace 'volmat' with vol[,1] and add 
> > > > volinp[2] with vol[1,1]. The new 'volmat' will look like:
> > > > 
> > > > ? ? ? ? [,1]
> > > > [1,]?? 15.13
> > > > [2,]?? 61.61
> > > > [3,]?? 25.25
> > > > [4,]? ? 0.00
> > > > [5,]? ? 0.00
> > > > 
> > > > Then multiply 'dcmat' with the new 'volmat', and the 2nd column of 
> > > > output matrix 'vol' will look like:
> > > > 
> > > > ? ? ? ? [,2]
> > > > [1,]? 1.9669
> > > > [2,] 41.2665
> > > > [3,] 41.2232
> > > > [4,] 13.1199
> > > > [5,]? 2.7775
> > > > 
> > > > Then again, replace the 'volmat' with vol[,2], add volinp[3] with 
> > > > vol[1,2] and multiply the new 'volmat' with 'dcmat'. This 
> > > > replacement, addition, multiplication, and dumping will continue up 
> > > > to the length of 'volinp' and the final output matrix 'vol' will be 
> > > > something like:
> > > > 
> > > > ? ? ? [,1]? ? [,2]? ? ? [,3]? ? ...length(volinp)
> > > > [1,] 13.13?? 1.9669?? 0.645697? ...
> > > > [2,] 61.61? 41.2665? 24.488389? ...
> > > > [3,] 25.25? 41.2232? 40.419786? ...
> > > > [4,]? 0.00? 13.1199? 22.116099? ...
> > > > [5,]? 0.00?? 2.7775?? 7.670905? ...?
> > > > 
> > > > Within my limited capacity, I've tried to come up with a solution 
> > > > but failed.
> > > > 
> > > > I'll appreciate your/others' help with gratefulness.
> > > > 
> > > > Regards,
> > > > 
> > > > Halim
> > > > 
> > > > ---------------
> > > > Md. Abdul Halim
> > > > Assistant Professor
> > > > Department of Forestry and Environmental Science
> > > > Shahjalal University of Science and Technology,Sylhet-3114,
> > > > Bangladesh.
> > > > Cell: +8801714078386.
> > > > alt. e-mail: xou03 at yahoo.com
> > > > 
> > > > On Sat, 23 Nov 2013 14:10:12 -0800 (PST), arun wrote
> > > > > Hi,
> > > > > Could you show your expected output?? It is a bit unclear from the 
> > > > description.
> > > > > 
> > > > > On Saturday, November 23, 2013 2:00 PM, halim10-fes <halim10-
> > > > > fes at sust.edu> wrote: Dear R-friends,
> > > > > 
> > > > > Hope you doing well. I've been trying to deal with the following 
> > > > > problem for the couple of days but couldn't come up with a solution. 
> > > > > It would be great if any of you could give some insight into it.
> > > > > 
> > > > > I have three matrices like:
> > > > > 
> > > > > dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> > > > > 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> > > > > 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5) 
> > > > volinp<-
> > > > > matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> > > > > 
> > > > > scvol<-matrix(c(1:40),nrow=5,ncol=8)
> > > > > 
> > > > > What I essentially want to do is to add each value in scvol[1,] with 
> > > > > the volinp[1,1] and then multiply each new volinp with dcvol and 
> > > > > finally put the outputs in a new matrix.
> > > > > 
> > > > > Thanks in advance.
> > > > > 
> > > > > Halim? ? ? ? ? ? ? ? 
> > > > > ---------------
> > > > > Md. Abdul Halim
> > > > > Assistant Professor
> > > > > Department of Forestry and Environmental Science
> > > > > Shahjalal University of Science and Technology,Sylhet-3114,
> > > > > Bangladesh.
> > > > > Cell: +8801714078386.
> > > > > alt. e-mail: xou03 at yahoo.com
> > > > > 
> > > > > -- 
> > > > > This message has been scanned for viruses and
> > > > > dangerous content by MailScanner, and is
> > > > > believed to be clean.
> > > > > 
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > 
> > > > -- 
> > > > This message has been scanned for viruses and
> > > > dangerous content by MailScanner, and is
> > > > believed to be clean.
> > > > 
> > > > -- 
> > > > This message has been scanned for viruses and
> > > > dangerous content by MailScanner, and is
> > > > believed to be clean.

> 
> > 
> > > 
> > > ---------------
> > > Md. Abdul Halim
> > > Assistant Professor
> > > Department of Forestry and Environmental Science
> > > Shahjalal University of Science and Technology,Sylhet-3114,
> > > Bangladesh.
> > > Cell: +8801714078386.
> > > alt. e-mail: xou03 at yahoo.com
> > > 
> > > -- 
> > > This message has been scanned for viruses and
> > > dangerous content by MailScanner, and is
> > > believed to be clean.
> > > 
> > > -- 
> > > This message has been scanned for viruses and
> > > dangerous content by MailScanner, and is
> > > believed to be clean.
> > 
> > ---------------
> > Md. Abdul Halim
> > Assistant Professor
> > Department of Forestry and Environmental Science
> > Shahjalal University of Science and Technology,Sylhet-3114,
> > Bangladesh.
> > Cell: +8801714078386.
> > alt. e-mail: xou03 at yahoo.com
> > 
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> > 
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> 
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.


---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From davbauman at gmail.com  Sun Dec  1 18:58:42 2013
From: davbauman at gmail.com (David Bauman)
Date: Sun, 1 Dec 2013 19:58:42 +0200
Subject: [R] How to create polygons representing sampled forest plots,
 and how to compute D1 matrix between these polygons ?
Message-ID: <CAGrRo0fkFxmmRcELJZsu2VRzM08LUw-P1-wB=arTwRwJ7NcQ1g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131201/0eaf3206/attachment.pl>

From gunter.berton at gene.com  Sun Dec  1 19:27:54 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 1 Dec 2013 10:27:54 -0800
Subject: [R] factor() in lm
In-Reply-To: <CAEVDvzXn6XU_gQk0z3jKbqznaJXTStmLawU8y2Aj-Lt5D88nsg@mail.gmail.com>
References: <CAEVDvzXn6XU_gQk0z3jKbqznaJXTStmLawU8y2Aj-Lt5D88nsg@mail.gmail.com>
Message-ID: <CACk-te1r3+0WTCfMU5hzwVjyk7oZ4OY51abmtunMbnKn+y=9sg@mail.gmail.com>

You may wish to talk to a local statistician or read up on linear
models, as you appear to not understand some basics. Anyway,  either

1. You have other covariates in your model that you haven't shown and
your model is overdetermined.
2. You have NA's in your data that causes 1) to occur.

As an example of the above:

x <- rep(letters[1:3],e=5)
y <- factor(rep(1:3,c(5,8,2)))
summary(lm(rnorm(15)~x+y))

Call:
lm(formula = rnorm(15) ~ x + y)

Residuals:
    Min      1Q  Median      3Q     Max
-1.6768 -0.3865 -0.1108  0.3090  1.9632

Coefficients: (1 not defined because of singularities)
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.04138    0.47160   0.088    0.932
xb           1.59259    1.17111   1.360    0.201
xc           0.36822    0.88228   0.417    0.684
y2          -1.58517    0.96264  -1.647    0.128
y3                NA         NA      NA       NA


Incidentally, I was surprised to find in R3.0.2 that if some levels of
a factor are missing either due to NA's in the response or otherwise,
R estimates the coefficients for the remaining factor levels quite
nicely. I expected it to complain, but it did not. Maybe it has always
been so nicely behaved -- I don't fit overdetermined models and take
care that my factor levels are actually present, so don't run into
trouble. But if this is newish behavior and you are using an oldish
version, you might try upgrading to the current version. Or (more
likely) both clauses of this conditional are false and should be
ignored, and I should preemptively apologize for my foolishness.

Cheers,
Bert

On Sun, Dec 1, 2013 at 9:48 AM, Gary Dong <pdxgary163 at gmail.com> wrote:
> Dear R users,
>
> I am running a linear regression in R. My observations are Census Tracts in
> several metropolitan areas (MSAs). In my data set, each MSA has at least 50
> observations. I use factor(msa_code) in the lm formula to control for
> metropolitan fixed effects. But I kept getting something like this:
>
> .....
> factor(msa_code)12420  4.910e-01  1.517e-01   3.237 0.001221 **
> factor(msa_code)12580  1.966e-01  6.861e-02   2.865 0.004194 **
> factor(msa_code)14460 -3.892e-02  1.653e-02  -2.355 0.018601 *
> factor(msa_code)16980 -2.873e-01  3.278e-02  -8.764  < 2e-16 ***
> factor(msa_code)17140  1.088e-01  6.771e-02   1.607 0.108127
> factor(msa_code)17460 -1.173e-01  4.380e-02  -2.678 0.007441 **
> factor(msa_code)19100  1.368e-01  5.550e-02   2.465 0.013753 *
> factor(msa_code)19740  5.819e-01  1.173e-01   4.962 7.33e-07 ***
> factor(msa_code)19820 -4.214e-01  6.641e-02  -6.346 2.51e-10 ***
> factor(msa_code)26420  1.258e-01  7.541e-02   1.668 0.095486 .
> factor(msa_code)28140  2.010e-01  3.847e-02   5.224 1.85e-07 ***
> factor(msa_code)29820  7.102e-02  6.593e-02   1.077 0.281435
> factor(msa_code)31100 -4.832e-01  1.088e-01  -4.440 9.28e-06 ***
> factor(msa_code)33100 -2.534e-01  6.391e-02  -3.965 7.49e-05 ***
> factor(msa_code)33460  5.229e-02  7.891e-02   0.663 0.507609
> factor(msa_code)35620 -3.197e-01  7.565e-02  -4.225 2.45e-05 ***
> factor(msa_code)36740  1.269e-01  6.948e-02   1.826 0.067868 .
> factor(msa_code)37980  1.394e-01  4.388e-02   3.178 0.001497 **
> factor(msa_code)38060 -6.935e-02  6.124e-02  -1.132 0.257540
> factor(msa_code)38300  1.647e-01  3.986e-02   4.133 3.67e-05 ***
> factor(msa_code)38900  2.605e-01  1.420e-01   1.835 0.066664 .
> factor(msa_code)39300 -9.612e-02  4.704e-02  -2.043 0.041103 *
> factor(msa_code)40140 -2.353e-01  3.562e-02  -6.605 4.59e-11 ***
> factor(msa_code)40900         NA         NA      NA       NA
> factor(msa_code)41740         NA         NA      NA       NA
> factor(msa_code)41860         NA         NA      NA       NA
> factor(msa_code)42660         NA         NA      NA       NA
> factor(msa_code)45300         NA         NA      NA       NA
> factor(msa_code)47900         NA         NA      NA       NA
>
>  I wonder why I kep getting those "NAs". Thank you!
>
> Gary
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From ruipbarradas at sapo.pt  Sun Dec  1 19:29:09 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 01 Dec 2013 18:29:09 +0000
Subject: [R] Removing NAs from matrix
In-Reply-To: <DUB124-W25B34E2307BBC5EF53F49180EB0@phx.gbl>
References: <DUB124-W25B34E2307BBC5EF53F49180EB0@phx.gbl>
Message-ID: <529B7FF5.4080606@sapo.pt>

Hello,

Your code corrected would be


mean.matrix[, 1] <- apply(mat, 1, mean, na.rm = TRUE)

(No need for the for loop).
Even better would be to avoid loops and use the base R function ?rowMeans.

mean.matrix[, 1] <- rowMeans(mat, na.rm = TRUE)

Hope this helps,

Rui Barradas

Em 01-12-2013 12:16, Amie Hunter escreveu:
> Hello R users,
>
> I'm new to R so apologies if this question seems simple. I have a matrix which is 35000 columns by 35000 rows and I?m wanting to work out the mean of each row. I've tried using the code below on a smaller version of the matrix, but receive an error:
>
>> mat
>        [,1]      [,2] [,3]      [,4]       [,5]      [,6]      [,7]      [,8]      [,9]     [,10]     [,11]
>   [1,]   NA 0.3904762  0.2 0.4285714 0.04761905        NA        NA        NA        NA        NA        NA
>   [2,]   NA        NA  0.2 0.2000000 0.23809524 0.2190476        NA        NA        NA        NA        NA
>   [3,]   NA        NA   NA 0.5047619 0.27619048 0.2952381 0.1428571        NA        NA        NA        NA
>   [4,]   NA        NA   NA        NA 0.42857143 0.3714286 0.3333333 0.2190476        NA        NA        NA
>   [5,]   NA        NA   NA        NA         NA 0.8666667 0.6761905 0.4857143 0.6571429        NA        NA
>   [6,]   NA        NA   NA        NA         NA        NA 0.6190476 0.4285714 0.6761905 0.4857143        NA
>   [7,]   NA        NA   NA        NA         NA        NA        NA 0.6952381 0.6380952 0.6000000 0.2571429
>   [8,]   NA        NA   NA        NA         NA        NA        NA        NA 0.6761905 0.6000000 0.1809524
>   [9,]   NA        NA   NA        NA         NA        NA        NA        NA        NA 0.6190476 0.3142857
> [10,]   NA        NA   NA        NA         NA        NA        NA        NA        NA        NA 0.5809524
> [11,]   NA        NA   NA        NA         NA        NA        NA        NA        NA        NA        NA
>> mean.matrix <- matrix(ncol=1, nrow=10)
>> for (i in mat)
> + mean.matrix[,i] <- apply(mat,1,mean)
> Error: NAs are not allowed in subscripted assignments
>
> I have come across the na.omit() function however this completely removes the row. Is there any way I can either remove all the NAs from the matrix or pull out the values of each row to work out the mean?
>
> Thanks,
>
> Amie 		 	   		
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdxgary163 at gmail.com  Sun Dec  1 19:35:02 2013
From: pdxgary163 at gmail.com (Gary Dong)
Date: Sun, 1 Dec 2013 10:35:02 -0800
Subject: [R] factor() in lm
In-Reply-To: <CACk-te1r3+0WTCfMU5hzwVjyk7oZ4OY51abmtunMbnKn+y=9sg@mail.gmail.com>
References: <CAEVDvzXn6XU_gQk0z3jKbqznaJXTStmLawU8y2Aj-Lt5D88nsg@mail.gmail.com>
	<CACk-te1r3+0WTCfMU5hzwVjyk7oZ4OY51abmtunMbnKn+y=9sg@mail.gmail.com>
Message-ID: <CAEVDvzVUbb1tyTr+_i+WSZo2KRJ3deM=hKJaYU4=W8sF3gg9GQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131201/14ecb3e4/attachment.pl>

From smartpink111 at yahoo.com  Sun Dec  1 19:26:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 1 Dec 2013 10:26:41 -0800 (PST)
Subject: [R] Removing NAs from matrix
In-Reply-To: <DUB124-W25B34E2307BBC5EF53F49180EB0@phx.gbl>
References: <DUB124-W25B34E2307BBC5EF53F49180EB0@phx.gbl>
Message-ID: <1385922401.87686.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
?rowMeans

rowMeans(mat,na.rm=TRUE)
A.K.


On Sunday, December 1, 2013 1:15 PM, Amie Hunter <amie_hunter at hotmail.com> wrote:
Hello R users,

I'm new to R so apologies if this question seems simple. I have a matrix which is 35000 columns by 35000 rows and I?m wanting to work out the mean of each row. I've tried using the code below on a smaller version of the matrix, but receive an error:

> mat
????? [,1]????? [,2] [,3]????? [,4]?????? [,5]????? [,6]????? [,7]????? [,8]????? [,9]???? [,10]???? [,11]
?[1,]?? NA 0.3904762? 0.2 0.4285714 0.04761905??????? NA??????? NA??????? NA??????? NA??????? NA??????? NA
?[2,]?? NA??????? NA? 0.2 0.2000000 0.23809524 0.2190476??????? NA??????? NA??????? NA??????? NA??????? NA
?[3,]?? NA??????? NA?? NA 0.5047619 0.27619048 0.2952381 0.1428571??????? NA??????? NA??????? NA??????? NA
?[4,]?? NA??????? NA?? NA??????? NA 0.42857143 0.3714286 0.3333333 0.2190476??????? NA??????? NA??????? NA
?[5,]?? NA??????? NA?? NA??????? NA???????? NA 0.8666667 0.6761905 0.4857143 0.6571429??????? NA??????? NA
?[6,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA 0.6190476 0.4285714 0.6761905 0.4857143??????? NA
?[7,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA??????? NA 0.6952381 0.6380952 0.6000000 0.2571429
?[8,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA??????? NA??????? NA 0.6761905 0.6000000 0.1809524
?[9,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA??????? NA??????? NA??????? NA 0.6190476 0.3142857
[10,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA??????? NA??????? NA??????? NA??????? NA 0.5809524
[11,]?? NA??????? NA?? NA??????? NA???????? NA??????? NA??????? NA??????? NA??????? NA??????? NA??????? NA
> mean.matrix <- matrix(ncol=1, nrow=10)
> for (i in mat)
+ mean.matrix[,i] <- apply(mat,1,mean)
Error: NAs are not allowed in subscripted assignments

I have come across the na.omit() function however this completely removes the row. Is there any way I can either remove all the NAs from the matrix or pull out the values of each row to work out the mean? 

Thanks,

Amie ??? ???  ??? ?  ??? ??? ? 
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sun Dec  1 22:08:48 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 02 Dec 2013 10:08:48 +1300
Subject: [R] Code Help
In-Reply-To: <CAAJ33YPXi2xFg8rkHX+X4OAyhBHuFRyL0DjeaGrAn76qrjy94A@mail.gmail.com>
References: <CAAJ33YPXi2xFg8rkHX+X4OAyhBHuFRyL0DjeaGrAn76qrjy94A@mail.gmail.com>
Message-ID: <529BA560.7080700@auckland.ac.nz>

On 12/02/13 03:04, jeet chandvaniya wrote:
> Hi, sir i want help to develop code  for outlier detection in r
> language, so help me for this.

I recall that Monty Python did a skit that seems relevant here.  The 
skit involved
instructions on how to learn to play the flute and how to solve all the 
problems
of the world (or something like that) and maybe one or two other things.

Your post should receive some sort of prize for consummate obtuseness.

     cheers,

     Rolf Turner


From dwinsemius at comcast.net  Sun Dec  1 23:50:06 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 1 Dec 2013 14:50:06 -0800
Subject: [R] Problems dealing with matrices
In-Reply-To: <20131201042939.M94893@sust.edu>
References: <20131123181936.M40852@sust.edu>
	<1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<20131124051233.M87627@sust.edu>
	<1385281433.29640.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1385284698.38816.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<20131124103317.M34808@sust.edu>
	<1385307924.1089.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<20131127023716.M4379@sust.edu>
	<1385526074.98197.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<20131128042927.M43811@sust.edu>
	<1385655080.66014.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<20131201042939.M94893@sust.edu>
Message-ID: <2E3115D1-255E-4DB3-9DA2-3B090706AAC0@comcast.net>


On Nov 30, 2013, at 8:45 PM, halim10-fes wrote:

> Hi Arun,
> 
> Thank you very much for your kind response. Sorry for my delayed response. 
> Your solutions for the first two questions are quite good for my purpose. 
> Since nobody responded, can you please have a look at the 3rd question?

After paging through this thread, I was unable to determine what the "3rd question" might have been. Why not post a question that restates the question or specifically refer to a date and time for the posting where the "3rd question" is to be found. Also post data and code that will construct the intermediates that might have been developed in the "1st and 2nd questions" and might be needed as input for a solution. Please use dput() to post reproducible examples.


> It'll 
> be my great help, if you can give me suggestions.
> 
> Regards,
> 
> Halim
> 
> 
> On Thu, 28 Nov 2013 08:11:20 -0800 (PST), arun wrote
>> Hi Halim,
>> 
>> For the first two questions, you may try:
>> colsum1 <- colSums(volyrdc1)
>> min(which(colsum1>=18))
>> #[1] 29
>> #or
>>  head(which(colsum1>=18),1)
>> #140 
>> # 29 
>> 
>> colsum1[substr(colsum1,6,7)=="00"]  ## this is not very clear
>>      305 
>> 45.37004 
>> #or
>> colsum1[colsum1>=18][substr(colsum1[colsum1>=18],6,7)=="00"]
>>      305 
>> 45.37004
>> 
>> #because
>> sprintf("%.4f",colsum1[colsum1>=18])
>> colsum1[colsum1>=18][gsub(".*\\.\\d{2}","",sprintf("%.4f",
>> colsum1[colsum1>=18]))=="00"]      180      305 
>> 32.88996 45.37004
>> 
>> A.K.
>> 
>> On Thursday, November 28, 2013 3:57 AM, halim10-fes <halim10-
>> fes at sust.edu> wrote: Hi,
>> 
>> Sorry for continuous bothering. Continuum of the previous problem...
>> 
>> I have the following matrices and vectors,
>> 
>> dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
>> 0.00,0.00,                 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
>> 0.00,0.00,0.00,0.00,                 0.09),nrow=5,ncol=5)
>> 
>> volini<-matrix(c(0,0,0,0,0),nrow=5,ncol=1)
>> 
>> volinp1<-c(0, 0.0004669094, 0.0027610861, 0.0086204692, 0.0200137754, 
>> 0.0389069106 ,0.0670942588, 0.1060941424, 0.1570990708, 0.2209672605, 
>> 0.2982420945, 0.3891882830, 0.4938361307, 0.6120278338, 0.7434618363, 
>> 0.8877329008, 1.0443667375, 1.2128488387, 1.3926476912, 1.5832328410, 
>> 1.7840884399, 1.9947229566, 2.2146757191, 2.4435209092, 2.6808695568, 
>> 2.9263700050, 3.1797072430, 3.4406014299, 3.7088058696, 3.9841046430, 
>> 4.2663100561, 4.5552600226, 4.8508154713, 5.1528578389, 5.4612866929,
>> 5.7760175114, 6.0969796345, 6.4241143947, 6.7573734248, 7, 7 ,7, 7,
>> 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
>> 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
>> 7, 7, 7, 7, 7, 7, 7, 7,  7,  7, 7, 7)
>> 
>> I've calculated the following matrices vol and volyrdc1 (obviously 
>> with the help of Jeff and Arun):
>> 
>> #Blank matrices for dumping final values
>> 
>> vol <- matrix( NA, nrow=5, ncol=length(volinp1))
>> 
>> volyrdc1<-matrix(NA, nrow=5,ncol=length(volinp1),dimnames= 
>> list(c("DC1","DC2","DC3","DC4","DC5"),c(seq(0,500,5))))
>> 
>> vol[ , 1 ] <- dcmat %*% (volini+(volinp1[1]*wt))
>> 
>> wt<-matrix(c(1,0,0,0,0),nrow=5)
>> 
>> for ( idx in seq_along(volinp1)[ -1 ] ) { 
>>   vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp1[idx] * wt ) 
>> } 
>> 
>> vol
>> 
>> volyrdc1[,1]<-vol[,1]
>> 
>> for ( idx in seq_along(volinp1)[ -1 ] ) { 
>>   volyrdc1[ , idx ] <- vol[ , idx-1 ] + volinp1[idx] * wt
>>   }  
>> volyrdc1
>> 
>> My final matrix in 'volyrdc1' (kind of transition matrix model).
>> 
>> Now, what I want to do is to calculate when the colsum<-
>> colSums(volyrdc1) reaches a certain value and I want to get the 
>> index of the element in the 'colsum' vector at that point. For e.g. 
>> when colsum[colsum>=18] ? It will give a series of cases where the 
>> condition is true. But I want index of the element immediately when 
>> the condition is met. In this case, the answer I want is 140 
>> (colsum[29] returns both value (18.63) and the character ("140") 
>> attributing the index). Actually, in my case 140 is year (age) when 
>> the 'colsum' becomes 
>>> =18. At is point it would be great if I can calculate when 'colsum' levels 
>> off (up to two decimal place)? The answer is: 305 and at that point 
>> colsum==45.37. 
>> 
>> I also want to calculate what should be the value in volini[1,1] to 
>> get a certain value in 'colsum' at a certain year (age)(vector 
>> element index explained earlier)? For e.g. I want to find out that 
>> what should be the value in volini[1,1] if I want colsum==18 at 
>> 100(charater attributing colsum[21])? The answer is: 15910 and the 
>> 'volini' matrix will look like:
>> 
>> volini<-matrix(c(15910,0,0,0,0),nrow=5,ncol=1)
>> 
>> Any pointer, suggestions,... will be gratefully acknowledged.
>> 
>> P.S. Can you please suggest me any effective R programming book that 
>> describe core elements of R programming?
>> 
>> Thanks in advance.
>> 
>> Regards,
>> 
>> Halim                
>> ---------------
>> Md. Abdul Halim
>> Assistant Professor
>> Department of Forestry and Environmental Science
>> Shahjalal University of Science and Technology,Sylhet-3114,
>> Bangladesh.
>> Cell: +8801714078386.
>> alt. e-mail: xou03 at yahoo.com
>> 
>> On Tue, 26 Nov 2013 20:21:14 -0800 (PST), arun wrote
>>> HI Halim,
>>> 
>>> No problem.
>>> Regards,
>>> Arun
>>> 
>>> On Tuesday, November 26, 2013 11:18 PM, halim10-fes <halim10-
>>> fes at sust.edu> wrote: Hi Arun,
>>> 
>>> Thanks for your help. Sorry for my late response. Take care and stay 
>>> fine.
>>> 
>>> Regards,
>>> 
>>> Halim
>>> 
>>> On Sun, 24 Nov 2013 07:45:24 -0800 (PST), arun wrote
>>>> Hi Halim,
>>>> I guess this works for you.  Modifying Jeff's solution:
>>>> 
>>>> volinp<-c(0,0.000467,0.002762,0.008621,0.020014,0.038907,0.067094)
>>>> vol1 <- dcmat %*% (volmat +wt)
>>>> for(idx in seq_along(volinp)[-1]){
>>>>  vol1 <- cbind(vol1,dcmat %*% (vol1[,idx-1] + volinp[idx] *wt))
>>>>  }
>>>> 
>>>> #or
>>>> 
>>>> vol <- matrix( NA, nrow=5, ncol=length( volinp ) )
>>>> vol[ , 1 ] <- dcmat %*% ( volmat + wt )
>>>> 
>>>> for ( idx in seq_along(volinp)[ -1 ] ) {
>>>>   vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp[idx] * wt )
>>>> }
>>>> identical(vol,vol1)
>>>> #[1] TRUE
>>>> 
>>>> A.K.
>>>> 
>>>> On Sunday, November 24, 2013 7:16 AM, halim10-fes <halim10-
>>>> fes at sust.edu> wrote: Hi Arun,
>>>> 
>>>> OK, no problem. Thank you very much for your attention. I've posted 
>>>> an annex to my previous problem. I will appreciate your 
>>>> comments/suggestions on it.
>>>> 
>>>> Off-topic: You're a very helpful man. I like your attitude to 
>>>> helping others.
>>>> 
>>>> Take care.
>>>> 
>>>> Halim
>>>> 
>>>> On Sun, 24 Nov 2013 01:18:18 -0800 (PST), arun wrote
>>>>> Hi,
>>>>> Please disregard my earlier message. Looks like Jeff understand it 
>>>>> better and answered it. Regards, Arun
>>>>> 
>>>>> On Sunday, November 24, 2013 3:23 AM, arun <smartpink111 at yahoo.com> 
>> wrote:
>>>>> Hi,
>>>>> I am finding some inconsistency with your description.
>>>>> For example:
>>>>> volinp[1]+volmat[1,1]
>>>>> [1] 101
>>>>> 
>>>>> On Sunday, November 24, 2013 1:52 AM, halim10-fes <halim10-
>>>>> fes at sust.edu> wrote:
>>>>> 
>>>>> Please apologize me! Earlier I've sent a message erroneously. 
>>>>> Following is the original problem for which I'm seeking help. 
>>>>> Extremely sorry... 
>>>>> 
>>>>> Hi Arun,
>>>>> 
>>>>> Thank you very much for your response. Sorry, if I couldn't explain 
>>>>> clearly. I think, I should restate the problem to get exactly what I 
>>>>> want. Here it goes:
>>>>> 
>>>>> I have 2 matrices and 1 vector, namely,
>>>>> 
>>>>> dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
>>>>> 0.00,0.00,                 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
>>>>> 0.00,0.00,0.00,0.00,                 0.09),nrow=5,ncol=5)
>>>>> 
>>>>> volmat<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)
>>>>> 
>>>>> volinp<-c(1:40)
>>>>> 
>>>>> What I essentially want to do is to multiply 'dcmat' with 'volmat' 
>>>>> and dump the output in a new matrix 'vol'. But before that, in the 
>>>>> first step, I want to add volinp[1] with volmat[1,1]. So, the first 
>>>>> column of the output matrix 'vol' matrix will be:
>>>>> 
>>>>>         [,1]
>>>>> [1,]   13.13
>>>>> [2,]   61.61
>>>>> [3,]   25.25
>>>>> [4,]    0.00
>>>>> [5,]    0.00
>>>>> 
>>>>> In the 2nd step, I want to replace 'volmat' with vol[,1] and add 
>>>>> volinp[2] with vol[1,1]. The new 'volmat' will look like:
>>>>> 
>>>>>         [,1]
>>>>> [1,]   15.13
>>>>> [2,]   61.61
>>>>> [3,]   25.25
>>>>> [4,]    0.00
>>>>> [5,]    0.00
>>>>> 
>>>>> Then multiply 'dcmat' with the new 'volmat', and the 2nd column of 
>>>>> output matrix 'vol' will look like:
>>>>> 
>>>>>         [,2]
>>>>> [1,]  1.9669
>>>>> [2,] 41.2665
>>>>> [3,] 41.2232
>>>>> [4,] 13.1199
>>>>> [5,]  2.7775
>>>>> 
>>>>> Then again, replace the 'volmat' with vol[,2], add volinp[3] with 
>>>>> vol[1,2] and multiply the new 'volmat' with 'dcmat'. This 
>>>>> replacement, addition, multiplication, and dumping will continue up 
>>>>> to the length of 'volinp' and the final output matrix 'vol' will be 
>>>>> something like:
>>>>> 
>>>>>       [,1]    [,2]      [,3]    ...length(volinp)
>>>>> [1,] 13.13   1.9669   0.645697  ...
>>>>> [2,] 61.61  41.2665  24.488389  ...
>>>>> [3,] 25.25  41.2232  40.419786  ...
>>>>> [4,]  0.00  13.1199  22.116099  ...
>>>>> [5,]  0.00   2.7775   7.670905  ... 
>>>>> 
>>>>> Within my limited capacity, I've tried to come up with a solution 
>>>>> but failed.
>>>>> 
>>>>> I'll appreciate your/others' help with gratefulness.
>>>>> 
>>>>> Regards,
>>>>> 
>>>>> Halim
>>>>> 
>>>>> ---------------
>>>>> Md. Abdul Halim
>>>>> Assistant Professor
>>>>> Department of Forestry and Environmental Science
>>>>> Shahjalal University of Science and Technology,Sylhet-3114,
>>>>> Bangladesh.
>>>>> Cell: +8801714078386.
>>>>> alt. e-mail: xou03 at yahoo.com
>>>>> 
>>>>> On Sat, 23 Nov 2013 14:10:12 -0800 (PST), arun wrote
>>>>>> Hi,
>>>>>> Could you show your expected output?  It is a bit unclear from the 
>>>>> description.
>>>>>> 
>>>>>> On Saturday, November 23, 2013 2:00 PM, halim10-fes <halim10-
>>>>>> fes at sust.edu> wrote: Dear R-friends,
>>>>>> 
>>>>>> Hope you doing well. I've been trying to deal with the following 
>>>>>> problem for the couple of days but couldn't come up with a solution. 
>>>>>> It would be great if any of you could give some insight into it.
>>>>>> 
>>>>>> I have three matrices like:
>>>>>> 
>>>>>> dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
>>>>>> 0.00,0.00,                 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
>>>>>> 0.00,0.00,0.00,0.00,                 0.09),nrow=5,ncol=5) 
>>>>> volinp<-
>>>>>> matrix(c(100,0,0,0,0),nrow=5,ncol=1)
>>>>>> 
>>>>>> scvol<-matrix(c(1:40),nrow=5,ncol=8)
>>>>>> 
>>>>>> What I essentially want to do is to add each value in scvol[1,] with 
>>>>>> the volinp[1,1] and then multiply each new volinp with dcvol and 
>>>>>> finally put the outputs in a new matrix.
>>>>>> 
>>>>>> Thanks in advance.
>>>>>> 
>>>>>> Halim                
>>>>>> ---------------
>>>>>> Md. Abdul Halim
>>>>>> 

David Winsemius
Alameda, CA, USA


From gerifalte28 at hotmail.com  Mon Dec  2 02:59:06 2013
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Mon, 2 Dec 2013 01:59:06 +0000
Subject: [R] (no subject)
Message-ID: <BAY002-M164237093EAA71F18D2ADE5A6EA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/a276b72e/attachment.pl>

From gerifalte28 at hotmail.com  Mon Dec  2 02:59:06 2013
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Mon, 2 Dec 2013 01:59:06 +0000
Subject: [R] (no subject)
Message-ID: <BAY002-M164237093EAA71F18D2ADE5A6EA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/a276b72e/attachment-0001.pl>

From nooldor at gmail.com  Mon Dec  2 04:28:35 2013
From: nooldor at gmail.com (nooldor)
Date: Mon, 2 Dec 2013 04:28:35 +0100
Subject: [R] Multiple regressions with changing dependent variable and
 time span
In-Reply-To: <1385954081.38979.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CAJ0Fr658HvcC1H4-QvZpVQAWrP5_hv5LCwvKJ2m2ucxaV0EN=Q@mail.gmail.com>
	<1385793753.75342.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAJ0Fr65P64FveOztRxhyJ166Qcnp1cKdbfZCYaFLsEz05xpsCg@mail.gmail.com>
	<1385824938.22462.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAJ0Fr65Y6zVuJE8mBoX__bfkvGxWwUsyA9ZS_kUWnaVdy0b2MA@mail.gmail.com>
	<1385833171.99079.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAJ0Fr65i-x80BLTAXBibQNt1nQg8J-RVPccFgBJmq9zSerczuA@mail.gmail.com>
	<1385835354.85727.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAJ0Fr6739v28rf7yNqFgguMMoqi8bav6D7Wn8Q0TUDoqjdzBPw@mail.gmail.com>
	<1385842363.40647.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CAJ0Fr67iCNgF-Eqr6_XpsUsa7eb0fjJSqK_CN=mtvbfuZWXPNQ@mail.gmail.com>
	<1385850498.46297.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAJ0Fr64fFceyV651WVdKWVAi9cc_QHbcf3O-rmM=at7FYhKy-Q@mail.gmail.com>
	<1385950576.57712.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1385950678.32116.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAJ0Fr67ot5XL1Ab8z7YSJ7fDSG6yGpj9NAqO81AH0bmqiCx9vw@mail.gmail.com>
	<1385954081.38979.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <CAJ0Fr66DNPmhPmVkAzAzu42RVE4G2K4MUC6H1oXHhGNHX0gQ1Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/5d39815c/attachment.pl>

From smartpink111 at yahoo.com  Mon Dec  2 03:16:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 1 Dec 2013 18:16:16 -0800 (PST)
Subject: [R] Multiple regressions with changing dependent variable and
	time span
In-Reply-To: <CAJ0Fr64fFceyV651WVdKWVAi9cc_QHbcf3O-rmM=at7FYhKy-Q@mail.gmail.com>
References: <CAJ0Fr658HvcC1H4-QvZpVQAWrP5_hv5LCwvKJ2m2ucxaV0EN=Q@mail.gmail.com>	<1385793753.75342.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<CAJ0Fr65P64FveOztRxhyJ166Qcnp1cKdbfZCYaFLsEz05xpsCg@mail.gmail.com>	<1385824938.22462.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAJ0Fr65Y6zVuJE8mBoX__bfkvGxWwUsyA9ZS_kUWnaVdy0b2MA@mail.gmail.com>	<1385833171.99079.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAJ0Fr65i-x80BLTAXBibQNt1nQg8J-RVPccFgBJmq9zSerczuA@mail.gmail.com>	<1385835354.85727.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAJ0Fr6739v28rf7yNqFgguMMoqi8bav6D7Wn8Q0TUDoqjdzBPw@mail.gmail.com>	<1385842363.40647.YahooMailNeo@web142602.mail.bf1.yahoo.com>	<CAJ0Fr67iCNgF-Eqr6_XpsUsa7eb0fjJSqK_CN=mtvbfuZWXPNQ@mail.gmail.com>	<1385850498.46297.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAJ0Fr64fFceyV651WVdKWVAi9cc_QHbcf3O-rmM=at7FYhKy-Q@mail.gmail.com>
Message-ID: <1385950576.57712.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
dat1 <- read.table(text="A??? B???? C???? D
r.1? x1??? x2?? x3
r.1? x4??? x5??? x6
r.2? x7??? x8??? x9
r.2? x10? x11 x12
r.3? x13? x14 x15
r.3? x16? x17 x18",header=TRUE,stringsAsFactors=FALSE)

?dat2 <- do.call(cbind,split(dat1,dat1$A))
colnames(dat2) <- gsub(".*\\.","",colnames(dat2))
A.K.






On Sunday, December 1, 2013 6:32 PM, nooldor <nooldor at gmail.com> wrote:

Hi,

could you also tell me how to reshape the res1 matrix like that:

[now]

A??? B???? C???? D
r.1? x1??? x2?? x3
r.1? x4 ?? x5??? x6
r.2? x7 ?? x8??? x9r.2? x10? x11 x12r.3? x13? x14 x15r.3? x16? x17 x18


[after]:
A??? B???? C???? D????? A??? B???? C???? D???? ? A??? B???? C???? D
r.1? x1??? x2?? x3? ? ? r.2? x7 ?? x8??? x9????? r.3? x13? x14 x15
r.1? x4 ?? x5?? x6? ? ? r.2? x10? x11 x12????? r.3? x16? x17 x18



big thanks!







On 30 November 2013 23:28, arun <smartpink111 at yahoo.com> wrote:

Hi,
>No problem.
>
>In that case, each column will be a list.? For example if I take the first element of `lst2`
>dW1 <- rollapply(lst2[[1]],width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); durbinWatsonTest(l1,max.lag=3) } else rep(NA,4)},by.column=FALSE,align="right")
>
>?tail(dW1[,1],1)
>#[[1]]
>#[1] -0.3602936? 0.1975667 -0.1740797
>
>
>You can store it by:
>resdW1 <- do.call(cbind,lapply(seq_len(ncol(dW1)),function(i) do.call(rbind,dW1[,i]))[1:3])
>
>
>Similarly, for more than one elements (using a subset of lst2- as it takes time)
>
>
>lst3 <- lapply(lst2[1:2],function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); durbinWatsonTest(l1,max.lag=3) } else rep(NA,4)},by.column=FALSE,align="right"))
>
>lst3New <- lapply(lst3,function(x) do.call(cbind,lapply(seq_len(ncol(x)),function(i) do.call(rbind,x[,i]))[1:3]))
>
>lst3New <- lapply(lst3New, function(x) {colnames(x) <- paste0(rep(c("r","dw","p"),each=3),1:3); x})
>
>A.K.
>
>
>On Saturday, November 30, 2013 5:03 PM, nooldor <nooldor at gmail.com> wrote:
>
>Hey!
>
>
>Yes,
>only the D-W test takes so much time, did not check it yet
>
>I checked results (estimates) with manually run regressions (in excel) and they are correct.
>
>
>I only change the "width" to 31 and "each=123" to 124, cause it should be ((154-31)+1) x 334 = 41416 matrix
>
>
>with the lag in D-W test I was wondering how to have table when I use durbinWatsonTest(l1,3) - with three lags instead of default 1.
>
>but I can manage it - just need to learn about functions used by you.
>
>
>Any way: BIG THANK to you!
>
>
>Best wishes,
>T.S.
>
>
>
>
>
>On 30 November 2013 21:12, arun <smartpink111 at yahoo.com> wrote:
>
>Hi,
>>
>>I was able to read the file after saving it as .csv.? It seems to work without any errors.
>>
>>dat1<-read.csv("Book2.csv", header=T)
>>###same as previous
>>
>>
>>lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>>lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>>?sapply(lst2,function(x) sum(!!rowSums(is.na(x))))
>>library(zoo)
>>
>>res1 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); c(coef(l1), pval=summary(l1)$coef[,4], rsquare=summary(l1)$r.squared) } else rep(NA,9)},by.column=FALSE,align="right")))
>>row.names(res1) <- rep(paste("r",1:334,sep="."),each=123)
>>?dim(res1)
>>#[1] 41082???? 9
>>
>>#vif
>>?library(car)
>>
>>res2 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); vif(l1) } else rep(NA,3)},by.column=FALSE,align="right")))
>>row.names(res2) <- rep(paste("r",1:334,sep="."),each=123)
>>dim(res2)
>>#[1] 41082???? 3
>>
>>#DW statistic:
>>?lst3 <- lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); durbinWatsonTest(l1) } else rep(NA,4)},by.column=FALSE,align="right"))
>>?res3 <- do.call(rbind,lapply(lst3,function(x) x[,-4]))
>>row.names(res3) <- rep(paste("r",1:334,sep="."),each=123)
>>?dim(res3)
>>#[1] 41082???? 3
>>##ncvTest()
>>f4 <- function(meanmod, dta, varmod) {
>>assign(".dta", dta, envir=.GlobalEnv)
>>assign(".meanmod", meanmod, envir=.GlobalEnv)
>>m1 <- lm(.meanmod, .dta)
>>ans <- ncvTest(m1, varmod)
>>remove(".dta", envir=.GlobalEnv)
>>remove(".meanmod", envir=.GlobalEnv)
>>ans
>>}
>>
>>?lst4 <- lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-f4(r~.,z1) } else NA},by.column=FALSE,align="right"))
>>names(lst4) <- paste("r",1:334,sep=".")
>>length(lst4)
>>#[1] 334
>>
>>
>>###jarque.bera.test
>>library(tseries)
>>res5 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); resid <- residuals(l1); unlist(jarque.bera.test(resid)[1:3]) } else rep(NA,3)},by.column=FALSE,align="right")))
>>?dim(res5)
>>#[1] 41082???? 3
>>
>>A.K.
>>
>>
>>
>>
>>
>>
>>
>>
>>On Saturday, November 30, 2013 1:44 PM, nooldor <nooldor at gmail.com> wrote:
>>
>>here is in .xlsx should be easy to open and eventually find&replace commas according to you excel settings (or maybe it will do it automatically)
>>
>>
>>
>>
>>
>>
>>On 30 November 2013 19:15, arun <smartpink111 at yahoo.com> wrote:
>>
>>I tried that, but:
>>>
>>>
>>>
>>>dat1<-read.table("Book2.csv", head=T, sep=";", dec=",")
>>>> str(dat1)
>>>'data.frame':??? 154 obs. of? 1 variable:
>>>
>>>Then I changed to:
>>>dat1<-read.table("Book2.csv", head=T, sep="\t", dec=",")
>>>> str(dat1)
>>>'data.frame':??? 154 obs. of? 661 variables:
>>>Both of them are wrong as the number of variables should be 337.
>>>A.K.
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>On Saturday, November 30, 2013 12:53 PM, nooldor <nooldor at gmail.com> wrote:
>>>
>>>Thank you,
>>>
>>>I got your reply. I am just testing your script. I will let you know how is it soon.
>>>
>>>.csv could be problematic as commas are used as dec separator (Eastern Europe excel settings) ... I read it in R with this:
>>>dat1<-read.table("Book2.csv", head=T, sep=";", dec=",")
>>>
>>>Thank you very much !!!
>>>
>>>T.S.
>>>
>>>
>>>
>>>
>>>On 30 November 2013 18:39, arun <smartpink111 at yahoo.com> wrote:
>>>
>>>I couldn't read the "Book.csv" as the format is completely messed up.? Anyway, I hope the solution works on your dataset.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>On Saturday, November 30, 2013 10:34 AM, nooldor <nooldor at gmail.com> wrote:
>>>>
>>>>
>>>>ok.
>>>>
>>>>
>>>>> dat1<-read.table("Book2.csv", head=T, sep=";", dec=",") > colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:2,sep=".")) > lst1 <- lapply(paste("r",1:2,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x])) > lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} ) > sum(!!rowSums(is.na(lst2[[1]]))) [1] 57 > #[1] 40 > sapply(lst2,function(x) sum(!!rowSums(is.na(x)))) [1] 57??0 > #[1] 40 46
>>>>in att you have the data file
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>On 30 November 2013 16:22, arun <smartpink111 at yahoo.com> wrote:
>>>>
>>>>Hi,
>>>>>The first point is not that clear.
>>>>>
>>>>>Could you show the expected results in this case?
>>>>>
>>>>>set.seed(432)
>>>>>dat1 <- as.data.frame(matrix(sample(c(1:10,NA),154*5,replace=TRUE),ncol=5))
>>>>>?colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:2,sep="."))
>>>>>lst1 <- lapply(paste("r",1:2,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>>>>>
>>>>>
>>>>>?lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>>>>>?sum(!!rowSums(is.na(lst2[[1]])))
>>>>>#[1] 40
>>>>>?sapply(lst2,function(x) sum(!!rowSums(is.na(x))))
>>>>>#[1] 40 46
>>>>>
>>>>>
>>>>>A.K.
>>>>>
>>>>>
>>>>>
>>>>>On Saturday, November 30, 2013 10:09 AM, nooldor <nooldor at gmail.com> wrote:
>>>>>
>>>>>Hi,
>>>>>
>>>>>Thanks for reply!
>>>>>
>>>>>
>>>>>Three things:
>>>>>1.
>>>>>I did not write that some of the data has more then 31 NA in the column and then it is not possible to run lm()
>>>>>
>>>>>Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :??0 (non-NA) casesIn this case program should return "NA" symbol and go further, in the case when length of the observations is shorter then 31 program should always return "NA" but go further .
>>>>>
>>>>>
>>>>>
>>>>>2. in your result matrix there are only 4 columns (for estimates of the coefficients), is it possible to put there 4 more columns with p-values and one column with R squared
>>>>>
>>>>>
>>>>>3. basic statistical test for the regressions:
>>>>>
>>>>>inflation factors can be captured by:
>>>>>res2 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z)
>>>>>? vif(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>>>
>>>>>and DW statistic:
>>>>>res3 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z)
>>>>>? durbinWatsonTest(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>>>
>>>>>
>>>>>3a)is that right?
>>>>>
>>>>>3b) how to do and have in user-friendly form durbinWatsonTest for more then 1 lag?
>>>>>
>>>>>3c) how to apply: jarque.bera.test from library(tseries) and ncvTest from library(car) ???
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>Pozdrowienia,
>>>>>
>>>>>Tomasz Schabek
>>>>>
>>>>>
>>>>>On 30 November 2013 07:42, arun <smartpink111 at yahoo.com> wrote:
>>>>>
>>>>>Hi,
>>>>>>The link seems to be not working.? From the description, it looks like:
>>>>>>set.seed(432)
>>>>>>dat1 <- as.data.frame(matrix(sample(200,154*337,replace=TRUE),ncol=337))
>>>>>>?colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:334,sep="."))
>>>>>>lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>>>>>>
>>>>>>?lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>>>>>>library(zoo)
>>>>>>
>>>>>>res <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) coef(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>>>>
>>>>>>row.names(res) <- rep(paste("r",1:334,sep="."),each=123)
>>>>>>?dim(res)
>>>>>>#[1] 41082???? 4
>>>>>>
>>>>>>coef(lm(r.1~F.1+F.2+F.3,data=dat1[1:32,]) )
>>>>>>#(Intercept)???????? F.1???????? F.2???????? F.3
>>>>>>#109.9168150? -0.1705361? -0.1028231?? 0.2027911
>>>>>>coef(lm(r.1~F.1+F.2+F.3,data=dat1[2:33,]) )
>>>>>>#(Intercept)???????? F.1???????? F.2???????? F.3
>>>>>>#119.3718949? -0.1660709? -0.2059830?? 0.1338608
>>>>>>res[1:2,]
>>>>>>#??? (Intercept)??????? F.1??????? F.2?????? F.3
>>>>>>#r.1??? 109.9168 -0.1705361 -0.1028231 0.2027911
>>>>>>#r.1??? 119.3719 -0.1660709 -0.2059830 0.1338608
>>>>>>
>>>>>>A.K.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>On Friday, November 29, 2013 6:43 PM, nooldor <nooldor at gmail.com> wrote:
>>>>>>Hi all!
>>>>>>
>>>>>>
>>>>>>I am just starting my adventure with R, so excuse me naive questions.
>>>>>>
>>>>>>My data look like that:
>>>>>>
>>>>>><http://r.789695.n4.nabble.com/file/n4681391/data_descr_img.jpg>
>>>>>>
>>>>>>I have 3 independent variables (F.1, F.2 and F.3) and 334 other variables
>>>>>>(r.1, r.2, ... r.334) - each one of these will be dependent variable in my
>>>>>>regression.
>>>>>>
>>>>>>Total span of the time is 154 observations. But I would like to have rolling
>>>>>>window regression with length of 31 observations.
>>>>>>
>>>>>>I would like to run script like that:
>>>>>>
>>>>>>summary(lm(r.1~F.1+F.2+F.3, data=data))
>>>>>>vif(lm(r.1~F.1+F.2+F.3, data=data))
>>>>>>
>>>>>>But for each of 334 (r.1 to r.334) dependent variables separately and with
>>>>>>rolling-window of the length 31obs.
>>>>>>
>>>>>>Id est:
>>>>>>summary(lm(r.1~F.1+F.2+F.3, data=data)) would be run 123 (154 total obs -
>>>>>>31. for the first regression) times for rolling-fixed period of 31 obs.
>>>>>>
>>>>>>The next regression would be:
>>>>>>summary(lm(r.2~F.1+F.2+F.3, data=data)) also 123 times ... and so on till
>>>>>>summary(lm(r.334~F.1+F.2+F.3, data=data))
>>>>>>
>>>>>>It means it would be 123 x 334 regressions (=41082 regressions)
>>>>>>
>>>>>>I would like to save results (summary + vif test) of all those 41082
>>>>>>regressions in one read-user-friendly file like this given by e.g command
>>>>>>capture.output()
>>>>>>
>>>>>>Could you help with it?
>>>>>>
>>>>>>Regards,
>>>>>>
>>>>>>T.S.
>>>>>>
>>>>>>??? [[alternative HTML version deleted]]
>>>>>>
>>>>>>______________________________________________
>>>>>>R-help at r-project.org mailing list
>>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>


From smartpink111 at yahoo.com  Mon Dec  2 04:14:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 1 Dec 2013 19:14:41 -0800 (PST)
Subject: [R] Multiple regressions with changing dependent variable and
	time span
In-Reply-To: <CAJ0Fr67ot5XL1Ab8z7YSJ7fDSG6yGpj9NAqO81AH0bmqiCx9vw@mail.gmail.com>
References: <CAJ0Fr658HvcC1H4-QvZpVQAWrP5_hv5LCwvKJ2m2ucxaV0EN=Q@mail.gmail.com>	<1385793753.75342.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<CAJ0Fr65P64FveOztRxhyJ166Qcnp1cKdbfZCYaFLsEz05xpsCg@mail.gmail.com>	<1385824938.22462.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAJ0Fr65Y6zVuJE8mBoX__bfkvGxWwUsyA9ZS_kUWnaVdy0b2MA@mail.gmail.com>	<1385833171.99079.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAJ0Fr65i-x80BLTAXBibQNt1nQg8J-RVPccFgBJmq9zSerczuA@mail.gmail.com>	<1385835354.85727.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAJ0Fr6739v28rf7yNqFgguMMoqi8bav6D7Wn8Q0TUDoqjdzBPw@mail.gmail.com>	<1385842363.40647.YahooMailNeo@web142602.mail.bf1.yahoo.com>	<CAJ0Fr67iCNgF-Eqr6_XpsUsa7eb0fjJSqK_CN=mtvbfuZWXPNQ@mail.gmail.com>	<1385850498.46297.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAJ0Fr64fFceyV651WVdKWVAi9cc_QHbcf3O-rmM=at7FYhKy-Q@mail.gmail.com>	<1385950576.57712.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<1385950678.32116.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAJ0Fr67ot5XL1Ab8z7YSJ7fDSG6yGpj9NAqO81AH0bmqiCx9vw@mail.gmail.com>
Message-ID: <1385954081.38979.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
I guess you wanted something like this:

res2 <- do.call(cbind,lapply(lst2,
?function(x)
rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); 
if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); 
c(coef(l1), pval=summary(l1)$coef[,4], rsquare=summary(l1)$r.squared) } 
else rep(NA,9)},by.column=FALSE,align="right")))
dim(res2)
#[1]? 123 3006
?334*9
#[1] 3006

lst2New <- lapply(split(seq(3006),((seq(3006)-1)%%9)+1),function(x) {x1 <- res2[,x]; colnames(x1) <- paste(colnames(x1),1:334,sep="_");x1})
sapply(lst2New,ncol)
#? 1?? 2?? 3?? 4?? 5?? 6?? 7?? 8?? 9 
#334 334 334 334 334 334 334 334 334 
lst2New[[1]][1:4,1:4]
#???? (Intercept)_1 (Intercept)_2 (Intercept)_3 (Intercept)_4
#[1,]??????????? NA??? -0.3295765??? -0.7025259??????????? NA
#[2,]??????????? NA???? 0.1217360??? -1.5221660??????????? NA
#[3,]??????????? NA???? 0.3192466??? -1.3586341??????????? NA
#[4,]??????????? NA???? 0.2618476??? -0.9698798??????????? NA


A.K.














On Sunday, December 1, 2013 9:33 PM, nooldor <nooldor at gmail.com> wrote:

Hi,

actually, do you remember yesterday code you build for me?
it was:

dat1<-read.csv("Book2.csv", header=T)
>###same as previous
>
>
>lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>?sapply(lst2,function(x) sum(!!rowSums(is.na(x))))
>library(zoo)
>res1 <- do.call(rbind,lapply(lst2,
>function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); c(coef(l1), 
pval=summary(l1)$coef[,4], rsquare=summary(l1)$r.squared) } else 
rep(NA,9)},by.column=FALSE,align="right")))
>row.names(res1) <- rep(paste("r",1:334,sep="."),each=123)
>?dim(res1)
>#[1] 41082???? 9

(boo2.xls is? attached in this e-mail previously, just need to open it in excel and save as csv)
then we have result res1 as matrix 41082 x 9
(this 41082 = 123observations in time x 334objects)
now I need to separate this matrix res1 into 9 different matrices each one containing 123 obs x 334 variables 



maybe reshape() would be useful ...

... let me know if I described it clearly 





On 2 December 2013 03:17, arun <smartpink111 at yahoo.com> wrote:

#or
>
>data.frame(split(dat1,dat1$A))
>
>
>
>
>
>On Sunday, December 1, 2013 9:16 PM, arun <smartpink111 at yahoo.com> wrote:
>Hi,
>Try:
>dat1 <- read.table(text="A??? B???? C???? D
>r.1? x1??? x2?? x3
>r.1? x4??? x5??? x6
>r.2? x7??? x8??? x9
>r.2? x10? x11 x12
>r.3? x13? x14 x15
>r.3? x16? x17 x18",header=TRUE,stringsAsFactors=FALSE)
>
>?dat2 <- do.call(cbind,split(dat1,dat1$A))
>colnames(dat2) <- gsub(".*\\.","",colnames(dat2))
>A.K.
>
>
>
>
>
>
>
>On Sunday, December 1, 2013 6:32 PM, nooldor <nooldor at gmail.com> wrote:
>
>Hi,
>
>could you also tell me how to reshape the res1 matrix like that:
>
>[now]
>
>A??? B???? C???? D
>r.1? x1??? x2?? x3
>r.1? x4 ?? x5??? x6
>r.2? x7 ?? x8??? x9r.2? x10? x11 x12r.3? x13? x14 x15r.3? x16? x17 x18
>
>
>[after]:
>A??? B???? C???? D????? A??? B???? C???? D???? ? A??? B???? C???? D
>r.1? x1??? x2?? x3? ? ? r.2? x7 ?? x8??? x9????? r.3? x13? x14 x15
>r.1? x4 ?? x5?? x6? ? ? r.2? x10? x11 x12????? r.3? x16? x17 x18
>
>
>
>big thanks!
>
>
>
>
>
>
>
>On 30 November 2013 23:28, arun <smartpink111 at yahoo.com> wrote:
>
>Hi,
>>No problem.
>>
>>In that case, each column will be a list.? For example if I take the first element of `lst2`
>>dW1 <- rollapply(lst2[[1]],width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); durbinWatsonTest(l1,max.lag=3) } else rep(NA,4)},by.column=FALSE,align="right")
>>
>>?tail(dW1[,1],1)
>>#[[1]]
>>#[1] -0.3602936? 0.1975667 -0.1740797
>>
>>
>>You can store it by:
>>resdW1 <- do.call(cbind,lapply(seq_len(ncol(dW1)),function(i) do.call(rbind,dW1[,i]))[1:3])
>>
>>
>>Similarly, for more than one elements (using a subset of lst2- as it takes time)
>>
>>
>>lst3 <- lapply(lst2[1:2],function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); durbinWatsonTest(l1,max.lag=3) } else rep(NA,4)},by.column=FALSE,align="right"))
>>
>>lst3New <- lapply(lst3,function(x) do.call(cbind,lapply(seq_len(ncol(x)),function(i) do.call(rbind,x[,i]))[1:3]))
>>
>>lst3New <- lapply(lst3New, function(x) {colnames(x) <- paste0(rep(c("r","dw","p"),each=3),1:3); x})
>>
>>A.K.
>>
>>
>>On Saturday, November 30, 2013 5:03 PM, nooldor <nooldor at gmail.com> wrote:
>>
>>Hey!
>>
>>
>>Yes,
>>only the D-W test takes so much time, did not check it yet
>>
>>I checked results (estimates) with manually run regressions (in excel) and they are correct.
>>
>>
>>I only change the "width" to 31 and "each=123" to 124, cause it should be ((154-31)+1) x 334 = 41416 matrix
>>
>>
>>with the lag in D-W test I was wondering how to have table when I use durbinWatsonTest(l1,3) - with three lags instead of default 1.
>>
>>but I can manage it - just need to learn about functions used by you.
>>
>>
>>Any way: BIG THANK to you!
>>
>>
>>Best wishes,
>>T.S.
>>
>>
>>
>>
>>
>>On 30 November 2013 21:12, arun <smartpink111 at yahoo.com> wrote:
>>
>>Hi,
>>>
>>>I was able to read the file after saving it as .csv.? It seems to work without any errors.
>>>
>>>dat1<-read.csv("Book2.csv", header=T)
>>>###same as previous
>>>
>>>
>>>lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>>>lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>>>?sapply(lst2,function(x) sum(!!rowSums(is.na(x))))
>>>library(zoo)
>>>
>>>res1 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); c(coef(l1), pval=summary(l1)$coef[,4], rsquare=summary(l1)$r.squared) } else rep(NA,9)},by.column=FALSE,align="right")))
>>>row.names(res1) <- rep(paste("r",1:334,sep="."),each=123)
>>>?dim(res1)
>>>#[1] 41082???? 9
>>>
>>>#vif
>>>?library(car)
>>>
>>>res2 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); vif(l1) } else rep(NA,3)},by.column=FALSE,align="right")))
>>>row.names(res2) <- rep(paste("r",1:334,sep="."),each=123)
>>>dim(res2)
>>>#[1] 41082???? 3
>>>
>>>#DW statistic:
>>>?lst3 <- lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); durbinWatsonTest(l1) } else rep(NA,4)},by.column=FALSE,align="right"))
>>>?res3 <- do.call(rbind,lapply(lst3,function(x) x[,-4]))
>>>row.names(res3) <- rep(paste("r",1:334,sep="."),each=123)
>>>?dim(res3)
>>>#[1] 41082???? 3
>>>##ncvTest()
>>>f4 <- function(meanmod, dta, varmod) {
>>>assign(".dta", dta, envir=.GlobalEnv)
>>>assign(".meanmod", meanmod, envir=.GlobalEnv)
>>>m1 <- lm(.meanmod, .dta)
>>>ans <- ncvTest(m1, varmod)
>>>remove(".dta", envir=.GlobalEnv)
>>>remove(".meanmod", envir=.GlobalEnv)
>>>ans
>>>}
>>>
>>>?lst4 <- lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-f4(r~.,z1) } else NA},by.column=FALSE,align="right"))
>>>names(lst4) <- paste("r",1:334,sep=".")
>>>length(lst4)
>>>#[1] 334
>>>
>>>
>>>###jarque.bera.test
>>>library(tseries)
>>>res5 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); resid <- residuals(l1); unlist(jarque.bera.test(resid)[1:3]) } else rep(NA,3)},by.column=FALSE,align="right")))
>>>?dim(res5)
>>>#[1] 41082???? 3
>>>
>>>A.K.
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>On Saturday, November 30, 2013 1:44 PM, nooldor <nooldor at gmail.com> wrote:
>>>
>>>here is in .xlsx should be easy to open and eventually find&replace commas according to you excel settings (or maybe it will do it automatically)
>>>
>>>
>>>
>>>
>>>
>>>
>>>On 30 November 2013 19:15, arun <smartpink111 at yahoo.com> wrote:
>>>
>>>I tried that, but:
>>>>
>>>>
>>>>
>>>>dat1<-read.table("Book2.csv", head=T, sep=";", dec=",")
>>>>> str(dat1)
>>>>'data.frame':??? 154 obs. of? 1 variable:
>>>>
>>>>Then I changed to:
>>>>dat1<-read.table("Book2.csv", head=T, sep="\t", dec=",")
>>>>> str(dat1)
>>>>'data.frame':??? 154 obs. of? 661 variables:
>>>>Both of them are wrong as the number of variables should be 337.
>>>>A.K.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>On Saturday, November 30, 2013 12:53 PM, nooldor <nooldor at gmail.com> wrote:
>>>>
>>>>Thank you,
>>>>
>>>>I got your reply. I am just testing your script. I will let you know how is it soon.
>>>>
>>>>.csv could be problematic as commas are used as dec separator (Eastern Europe excel settings) ... I read it in R with this:
>>>>dat1<-read.table("Book2.csv", head=T, sep=";", dec=",")
>>>>
>>>>Thank you very much !!!
>>>>
>>>>T.S.
>>>>
>>>>
>>>>
>>>>
>>>>On 30 November 2013 18:39, arun <smartpink111 at yahoo.com> wrote:
>>>>
>>>>I couldn't read the "Book.csv" as the format is completely messed up.? Anyway, I hope the solution works on your dataset.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>On Saturday, November 30, 2013 10:34 AM, nooldor <nooldor at gmail.com> wrote:
>>>>>
>>>>>
>>>>>ok.
>>>>>
>>>>>
>>>>>> dat1<-read.table("Book2.csv", head=T, sep=";", dec=",") > colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:2,sep=".")) > lst1 <- lapply(paste("r",1:2,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x])) > lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} ) > sum(!!rowSums(is.na(lst2[[1]]))) [1] 57 > #[1] 40 > sapply(lst2,function(x) sum(!!rowSums(is.na(x)))) [1] 57??0 > #[1] 40 46
>>>>>in att you have the data file
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>On 30 November 2013 16:22, arun <smartpink111 at yahoo.com> wrote:
>>>>>
>>>>>Hi,
>>>>>>The first point is not that clear.
>>>>>>
>>>>>>Could you show the expected results in this case?
>>>>>>
>>>>>>set.seed(432)
>>>>>>dat1 <- as.data.frame(matrix(sample(c(1:10,NA),154*5,replace=TRUE),ncol=5))
>>>>>>?colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:2,sep="."))
>>>>>>lst1 <- lapply(paste("r",1:2,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>>>>>>
>>>>>>
>>>>>>?lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>>>>>>?sum(!!rowSums(is.na(lst2[[1]])))
>>>>>>#[1] 40
>>>>>>?sapply(lst2,function(x) sum(!!rowSums(is.na(x))))
>>>>>>#[1] 40 46
>>>>>>
>>>>>>
>>>>>>A.K.
>>>>>>
>>>>>>
>>>>>>
>>>>>>On Saturday, November 30, 2013 10:09 AM, nooldor <nooldor at gmail.com> wrote:
>>>>>>
>>>>>>Hi,
>>>>>>
>>>>>>Thanks for reply!
>>>>>>
>>>>>>
>>>>>>Three things:
>>>>>>1.
>>>>>>I did not write that some of the data has more then 31 NA in the column and then it is not possible to run lm()
>>>>>>
>>>>>>Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :??0 (non-NA) casesIn this case program should return "NA" symbol and go further, in the case when length of the observations is shorter then 31 program should always return "NA" but go further .
>>>>>>
>>>>>>
>>>>>>
>>>>>>2. in your result matrix there are only 4 columns (for estimates of the coefficients), is it possible to put there 4 more columns with p-values and one column with R squared
>>>>>>
>>>>>>
>>>>>>3. basic statistical test for the regressions:
>>>>>>
>>>>>>inflation factors can be captured by:
>>>>>>res2 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z)
>>>>>>? vif(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>>>>
>>>>>>and DW statistic:
>>>>>>res3 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z)
>>>>>>? durbinWatsonTest(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>>>>
>>>>>>
>>>>>>3a)is that right?
>>>>>>
>>>>>>3b) how to do and have in user-friendly form durbinWatsonTest for more then 1 lag?
>>>>>>
>>>>>>3c) how to apply: jarque.bera.test from library(tseries) and ncvTest from library(car) ???
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>Pozdrowienia,
>>>>>>
>>>>>>Tomasz Schabek
>>>>>>
>>>>>>
>>>>>>On 30 November 2013 07:42, arun <smartpink111 at yahoo.com> wrote:
>>>>>>
>>>>>>Hi,
>>>>>>>The link seems to be not working.? From the description, it looks like:
>>>>>>>set.seed(432)
>>>>>>>dat1 <- as.data.frame(matrix(sample(200,154*337,replace=TRUE),ncol=337))
>>>>>>>?colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:334,sep="."))
>>>>>>>lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>>>>>>>
>>>>>>>?lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>>>>>>>library(zoo)
>>>>>>>
>>>>>>>res <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) coef(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>>>>>
>>>>>>>row.names(res) <- rep(paste("r",1:334,sep="."),each=123)
>>>>>>>?dim(res)
>>>>>>>#[1] 41082???? 4
>>>>>>>
>>>>>>>coef(lm(r.1~F.1+F.2+F.3,data=dat1[1:32,]) )
>>>>>>>#(Intercept)???????? F.1???????? F.2???????? F.3
>>>>>>>#109.9168150? -0.1705361? -0.1028231?? 0.2027911
>>>>>>>coef(lm(r.1~F.1+F.2+F.3,data=dat1[2:33,]) )
>>>>>>>#(Intercept)???????? F.1???????? F.2???????? F.3
>>>>>>>#119.3718949? -0.1660709? -0.2059830?? 0.1338608
>>>>>>>res[1:2,]
>>>>>>>#??? (Intercept)??????? F.1??????? F.2?????? F.3
>>>>>>>#r.1??? 109.9168 -0.1705361 -0.1028231 0.2027911
>>>>>>>#r.1??? 119.3719 -0.1660709 -0.2059830 0.1338608
>>>>>>>
>>>>>>>A.K.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>On Friday, November 29, 2013 6:43 PM, nooldor <nooldor at gmail.com> wrote:
>>>>>>>Hi all!
>>>>>>>
>>>>>>>
>>>>>>>I am just starting my adventure with R, so excuse me naive questions.
>>>>>>>
>>>>>>>My data look like that:
>>>>>>>
>>>>>>><http://r.789695.n4.nabble.com/file/n4681391/data_descr_img.jpg>
>>>>>>>
>>>>>>>I have 3 independent variables (F.1, F.2 and F.3) and 334 other variables
>>>>>>>(r.1, r.2, ... r.334) - each one of these will be dependent variable in my
>>>>>>>regression.
>>>>>>>
>>>>>>>Total span of the time is 154 observations. But I would like to have rolling
>>>>>>>window regression with length of 31 observations.
>>>>>>>
>>>>>>>I would like to run script like that:
>>>>>>>
>>>>>>>summary(lm(r.1~F.1+F.2+F.3, data=data))
>>>>>>>vif(lm(r.1~F.1+F.2+F.3, data=data))
>>>>>>>
>>>>>>>But for each of 334 (r.1 to r.334) dependent variables separately and with
>>>>>>>rolling-window of the length 31obs.
>>>>>>>
>>>>>>>Id est:
>>>>>>>summary(lm(r.1~F.1+F.2+F.3, data=data)) would be run 123 (154 total obs -
>>>>>>>31. for the first regression) times for rolling-fixed period of 31 obs.
>>>>>>>
>>>>>>>The next regression would be:
>>>>>>>summary(lm(r.2~F.1+F.2+F.3, data=data)) also 123 times ... and so on till
>>>>>>>summary(lm(r.334~F.1+F.2+F.3, data=data))
>>>>>>>
>>>>>>>It means it would be 123 x 334 regressions (=41082 regressions)
>>>>>>>
>>>>>>>I would like to save results (summary + vif test) of all those 41082
>>>>>>>regressions in one read-user-friendly file like this given by e.g command
>>>>>>>capture.output()
>>>>>>>
>>>>>>>Could you help with it?
>>>>>>>
>>>>>>>Regards,
>>>>>>>
>>>>>>>T.S.
>>>>>>>
>>>>>>>??? [[alternative HTML version deleted]]
>>>>>>>
>>>>>>>______________________________________________
>>>>>>>R-help at r-project.org mailing list
>>>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>


From white.232 at wright.edu  Mon Dec  2 07:26:50 2013
From: white.232 at wright.edu (White, William Patrick)
Date: Mon, 2 Dec 2013 06:26:50 +0000
Subject: [R] Days to solstice calculation
Message-ID: <0369b6856f3e4e1fa19994d3fd82d026@BN1PR01MB023.prod.exchangelabs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/3288640a/attachment.pl>

From kridox at ymail.com  Mon Dec  2 08:22:43 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 2 Dec 2013 16:22:43 +0900
Subject: [R] Days to solstice calculation
In-Reply-To: <0369b6856f3e4e1fa19994d3fd82d026@BN1PR01MB023.prod.exchangelabs.com>
References: <0369b6856f3e4e1fa19994d3fd82d026@BN1PR01MB023.prod.exchangelabs.com>
Message-ID: <CAAcyNCwK4qHutOCr2jy_uqxWwzH_3BxZ=L42DNt7gHtfFXwnpw@mail.gmail.com>

Hello,

It seems that this kind of calculations are done in package 'insol'.

Regards,
Pascal


On 2 December 2013 15:26, White, William Patrick <white.232 at wright.edu> wrote:
> Hello,
> I've come across a problem in developing a set of custom functions to calculate the number of hours of daylight at a given latitude, and the number of days a date precedes or secedes the summer solstice. I discovered an inconsistency concerning leap years between my derived values and those from the US naval databases. It seems as far as I can figure that my inconsistency arises either in the calculation I used derived from an ecological modeling study in the 90's, in my understanding of the way R itself handles dates, or in my code. I feel like I must be missing something fundamental here and could use a little guidance. The first function returns the hours of daylight given a latitude, and the Julian day of the year (ie Jan 1 = 1 and so on). This appears to be very accurate. The second function takes a given date, extracts the year, determines the number of days in it, and uses the first function to calculate the hours of daylight in each day, and returns the longest or sh!
>  ortest one (Summer or Winter Solstice). But, in the case of leap years and non leap years, the date returned is identical, as is evidenced by Jan 1 in the provided examples being 170 days from summer solstice in both 2008 and 2007. This was not the case, the solstice should vary by one day between these years. Code is provided below and any help is appreciated.
> Patrick
> ps. apologies to you southern ducks your summer and winter solstices are reversed of my code nomenclature. I'm working with a northern dataset.
>
> Daylength <- function(J,L){
> #Amount of daylight
> #Ecological Modeling, volume 80 (1995) pp. 87-95, "A Model Comparison for Daylength as a Function of Latitude and Day of the Year."
> #D = Daylight length
> #L = Latitude in Degrees
> #J = Day of the year (Julian)
> P <- asin(.39795*cos(.2163108 + 2*atan(.9671396*tan(.00860*(J-186)))))
> A <- sin(0.8333*pi/180)+sin(L*pi/180)*sin(P)
> B <- cos(L*pi/180)*cos(P)
> D <- 24 - (24/pi)* acos(A/B)
> return(D)
> }
>
> #Example today and here
> Daylength(2,39.7505)
>
> TillSolstice <- function(date,solstice){
> Yr <- as.POSIXlt(date)$year+1900
> a <- as.Date(paste(as.character(Yr),as.character(rep("-01-01", length(Yr))),sep = ""))
> b <- as.Date(paste(as.character(Yr),as.character(rep("-12-31", length(Yr))),sep = ""))
> Winter <- NA
> Summer <- NA
> for (g in 1: length(a)){
> if(is.na(a[g])== FALSE){
> if(is.na(b[g])== FALSE){
>   cc <- seq.int(a[g],b[g], by = '1 day')
>   d <- length(cc)
>   e <- strptime(cc, "%Y-%m-%d")$yday+2
>   f <- Daylength(e,39.6981478)
>   Winter[g] <- which.min(f)
>   Summer[g] <- which.max(f)
> }
> }
> if(is.na(a[g])== TRUE){
>  Winter[g] <- NA
>   Summer[g] <- NA
> }
> if(is.na(b[g])== TRUE){
>  Winter[g] <- NA
>   Summer[g] <- NA
> }
>
>
> }
> #Days until solstice
> if (solstice =='S'){Countdown <- Summer - (strptime(date, "%Y-%m-%d")$yday+2)}
> if (solstice =='W'){Countdown <- Winter - (strptime(a, "%Y-%m-%d")$yday+2)}
> return(Countdown)
> }
>
> Nonleap <- TillSolstice(seq(as.Date("2007/1/1"), as.Date("2007/12/31"), by = "1 day"), solstice = 'S')
> Leap <- TillSolstice(seq(as.Date("2008/1/1"), as.Date("2008/12/31"), by = "1 day"), solstice = 'S')
> head(Nonleap)
> tail(Nonleap)
> length(Nonleap)
> head(Leap)
> tail(Leap)
> length(Leap)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From rh at knut-krueger.de  Mon Dec  2 10:17:34 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Mon, 2 Dec 2013 10:17:34 +0100
Subject: [R] XLConnect readWorksheet   comma decimal sign
In-Reply-To: <33144A60-5037-4C76-B950-3376B4B14902@comcast.net>
References: <52931410.4080102@knut-krueger.de>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA05B8@SRVEXCHMBX.precheza.cz>
	<52933D4B.90803@knut-krueger.de> <5298A218.2090303@knut-krueger.de>
	<5422DC5C-24A7-4BA6-A43A-44340703398A@comcast.net>
	<5298DD4C.1080404@knut-krueger.de>
	<33144A60-5037-4C76-B950-3376B4B14902@comcast.net>
Message-ID: <529C502E.2080903@knut-krueger.de>

Am 29.11.2013 20:39, schrieb David Winsemius:
>> Thats impossible, we are used to hit the comma
> I don't know what that means.
it is common here, that the decimal sign is commy
All computer in the cip-pools are using the "comma" ( an I think 99.9% 
of all other computers here)
Can you imagine what would happen after  changing  this to dot?
Or in the other way, try to get the people in your country to use the 
,comma as separator. It would cause a big jumble.

> Until you show a reproducible example, we will not be able to offer 
> further advice: 
That*s the problem ... I am still trying to find out  what happened. It 
was definitely wrong in two cases
I was sure that I found the reason when starting this tread...

Knut


From teresamarso at hotmail.com  Mon Dec  2 12:03:26 2013
From: teresamarso at hotmail.com (=?Windows-1252?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Mon, 2 Dec 2013 11:03:26 +0000
Subject: [R] Confidence interval, multiple imputation
In-Reply-To: <DUB125-W1108F7613E140D206A8FC6B9FF0@phx.gbl>
References: <DUB125-W1108F7613E140D206A8FC6B9FF0@phx.gbl>
Message-ID: <DUB125-W150C744CE23456C04CAFBEB9EA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/d0435c15/attachment.pl>

From william108 at gmail.com  Mon Dec  2 12:24:12 2013
From: william108 at gmail.com (Bill)
Date: Mon, 2 Dec 2013 03:24:12 -0800
Subject: [R] why change days of the week from a factor to an ordered factor?
Message-ID: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/eb79a6da/attachment.pl>

From mbressan at arpa.veneto.it  Mon Dec  2 12:33:38 2013
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Mon, 02 Dec 2013 12:33:38 +0100
Subject: [R] interpretation of MDS plot in random forest
Message-ID: <529C7012.2000507@arpa.veneto.it>

Given this general example:

set.seed(1)

data(iris)

iris.rf <- randomForest(Species ~ ., iris, proximity=TRUE, keep.forest=TRUE)

#varImpPlot(iris.rf)

#varUsed(iris.rf)

MDSplot(iris.rf, iris$Species)

I?ve been reading the documentation about random forest (at best of my - 
poor - knowledge) but I?m in trouble with the correct interpretation of 
the MDS plot and I hope someone can give me some clues

What is intended for ?the scaling coordinates of the proximity matrix??


I think to understand that the objective is here to present the distance 
among species in a parsimonious and visual way (of lower dimensionality)

Is therefore a parallelism to what are intended the principal components 
in a classical PCA?

Are the scaling coordinates DIM 1 and DIM2 the eigenvectors of the 
proximity matrix?

If that is correct, how would you find the eigenvalues for that 
eigenvectors? And what are the eigenvalues repreenting?


What are saying these two dimensions in the plot about the different 
iris species? Their relative distance in terms of proximity within the 
space DIM1 and DIM2?

How to choose for the k parameter (number of dimensions for the scaling 
coordinates)?

And finally how would you explain the plot in simple terms?

Thank you for any feedback
Best regards


From friendly at yorku.ca  Mon Dec  2 15:47:58 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 02 Dec 2013 09:47:58 -0500
Subject: [R] generate multiple probability distributions
Message-ID: <529C9D9E.1080604@yorku.ca>

I want to generate a collection of probability distributions in a data 
frame, with
varying parameters.  There must be some simpler way than what I have below
(avoiding rbind and cbind), but I can't quite see it.

x <- seq(0,12)
bin.df <- as.data.frame(
     rbind( cbind(x, prob=dbinom(x,12,1/6), p=1/6),
            cbind(x, prob=dbinom(x,12,1/3), p=1/3),
            cbind(x, prob=dbinom(x,12,1/2), p=1/2),
            cbind(x, prob=dbinom(x,12,2/3), p=2/3)
           ))
bin.df$p <- factor(bin.df$p, labels=c("1/6", "1/3", "1/2", "2/3"))
str(bin.df)

 > str(bin.df)
'data.frame':   52 obs. of  3 variables:
  $ x   : num  0 1 2 3 4 5 6 7 8 9 ...
  $ prob: num  0.1122 0.2692 0.2961 0.1974 0.0888 ...
  $ p   : Factor w/ 4 levels "1/6","1/3","1/2",..: 1 1 1 1 1 1 1 1 1 1 ...
 >

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From murdoch.duncan at gmail.com  Mon Dec  2 16:12:36 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Dec 2013 10:12:36 -0500
Subject: [R] generate multiple probability distributions
In-Reply-To: <529C9D9E.1080604@yorku.ca>
References: <529C9D9E.1080604@yorku.ca>
Message-ID: <529CA364.4040707@gmail.com>

On 02/12/2013 9:47 AM, Michael Friendly wrote:
> I want to generate a collection of probability distributions in a data
> frame, with
> varying parameters.  There must be some simpler way than what I have below
> (avoiding rbind and cbind), but I can't quite see it.
>
> x <- seq(0,12)
> bin.df <- as.data.frame(
>       rbind( cbind(x, prob=dbinom(x,12,1/6), p=1/6),
>              cbind(x, prob=dbinom(x,12,1/3), p=1/3),
>              cbind(x, prob=dbinom(x,12,1/2), p=1/2),
>              cbind(x, prob=dbinom(x,12,2/3), p=2/3)
>             ))
> bin.df$p <- factor(bin.df$p, labels=c("1/6", "1/3", "1/2", "2/3"))
> str(bin.df)
>
>   > str(bin.df)
> 'data.frame':   52 obs. of  3 variables:
>    $ x   : num  0 1 2 3 4 5 6 7 8 9 ...
>    $ prob: num  0.1122 0.2692 0.2961 0.1974 0.0888 ...
>    $ p   : Factor w/ 4 levels "1/6","1/3","1/2",..: 1 1 1 1 1 1 1 1 1 1 ...
>   >
>

dbinom can take vector inputs for the parameters, so this would be a bit 
simpler:

x <- seq(0,12)
x <- rep(x, 4)
p <- rep(c(1/6, 1/3, 1/2, 2/3), each=13)
bin.df <- data.frame(x, prob = dbinom(x, 12, p), p)

Duncan Murdoch


From gunter.berton at gene.com  Mon Dec  2 16:21:38 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 2 Dec 2013 07:21:38 -0800
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
Message-ID: <CACk-te27GOCmZihjwLwoT7b7so8i9UNXHsEAvZgYRXvYm4wOaQ@mail.gmail.com>

"BIll" :

(Sorry -- Doubt that this will be helpful, but I couln't resist)

"I don't understand why the author of the code decided to make the factor
days_of_week into an ordered factor. Anyone know why this should be done?"

A definitive answer would require either psychic abilities or asking
the author/maintainer of the code. I suggest you try the latter.

However, insight might be gained by **you** answering the following
question: What is the difference between ordered and unordered
factors? Note that one might expect some results that change with day
of week to do so in an "orderly" way.  For example, I would imagine
that grocery purchases are at more or less one level on M-TH and at a
higher level on Fri-Sun in the U.S . Ordered factors would be better
at capturing this sort of thing I would think (with fewer df).

Cheers,
Bert

On Mon, Dec 2, 2013 at 3:24 AM, Bill <william108 at gmail.com> wrote:
> I am reading the code below. It acts on a csv file called dodgers.csv with
> the following variables.
>
>
>> print(str(dodgers))  # check the structure of the data frame
> 'data.frame':   81 obs. of  12 variables:
>  $ month      : Factor w/ 7 levels "APR","AUG","JUL",..: 1 1 1 1 1 1 1 1 1
> 1 ...
>  $ day        : int  10 11 12 13 14 15 23 24 25 27 ...
>  $ attend     : int  56000 29729 28328 31601 46549 38359 26376 44014 26345
> 44807 ...
>  $ day_of_week: Factor w/ 7 levels "Friday","Monday",..: 6 7 5 1 3 4 2 6 7
> 1 ...
>  $ opponent   : Factor w/ 17 levels "Angels","Astros",..: 13 13 13 11 11 11
> 3 3 3 10 ...
>  $ temp       : int  67 58 57 54 57 65 60 63 64 66 ...
>  $ skies      : Factor w/ 2 levels "Clear ","Cloudy": 1 2 2 2 2 1 2 2 2 1
> ...
>  $ day_night  : Factor w/ 2 levels "Day","Night": 1 2 2 2 2 1 2 2 2 2 ...
>  $ cap        : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>  $ shirt      : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>  $ fireworks  : Factor w/ 2 levels "NO","YES": 1 1 1 2 1 1 1 1 1 2 ...
>  $ bobblehead : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
> NULL
>>
>
> I don't understand why the author of the code decided to make the factor
> days_of_week into an ordered factor. Anyone know why this should be done?
> Thank you.
>
> Here is the code:
>
> # Predictive Model for Los Angeles Dodgers Promotion and Attendance
>
> library(car)  # special functions for linear regression
> library(lattice)  # graphics package
>
> # read in data and create a data frame called dodgers
> dodgers <- read.csv("dodgers.csv")
> print(str(dodgers))  # check the structure of the data frame
>
> # define an ordered day-of-week variable
> # for plots and data summaries
> dodgers$ordered_day_of_week <- with(data=dodgers,
>   ifelse ((day_of_week == "Monday"),1,
>   ifelse ((day_of_week == "Tuesday"),2,
>   ifelse ((day_of_week == "Wednesday"),3,
>   ifelse ((day_of_week == "Thursday"),4,
>   ifelse ((day_of_week == "Friday"),5,
>   ifelse ((day_of_week == "Saturday"),6,7)))))))
> dodgers$ordered_day_of_week <- factor(dodgers$ordered_day_of_week,
> levels=1:7,
> labels=c("Mon", "Tue", "Wed", "Thur", "Fri", "Sat", "Sun"))
>
> # exploratory data analysis with standard graphics: attendance by day of
> week
> with(data=dodgers,plot(ordered_day_of_week, attend/1000,
> xlab = "Day of Week", ylab = "Attendance (thousands)",
> col = "violet", las = 1))
>
> # when do the Dodgers use bobblehead promotions
> with(dodgers, table(bobblehead,ordered_day_of_week)) # bobbleheads on
> Tuesday
>
> # define an ordered month variable
> # for plots and data summaries
> dodgers$ordered_month <- with(data=dodgers,
>   ifelse ((month == "APR"),4,
>   ifelse ((month == "MAY"),5,
>   ifelse ((month == "JUN"),6,
>   ifelse ((month == "JUL"),7,
>   ifelse ((month == "AUG"),8,
>   ifelse ((month == "SEP"),9,10)))))))
> dodgers$ordered_month <- factor(dodgers$ordered_month, levels=4:10,
> labels = c("April", "May", "June", "July", "Aug", "Sept", "Oct"))
>
> # exploratory data analysis with standard R graphics: attendance by month
> with(data=dodgers,plot(ordered_month,attend/1000, xlab = "Month",
> ylab = "Attendance (thousands)", col = "light blue", las = 1))
>
> # exploratory data analysis displaying many variables
> # looking at attendance and conditioning on day/night
> # the skies and whether or not fireworks are displayed
> library(lattice) # used for plotting
> # let us prepare a graphical summary of the dodgers data
> group.labels <- c("No Fireworks","Fireworks")
> group.symbols <- c(21,24)
> group.colors <- c("black","black")
> group.fill <- c("black","red")
> xyplot(attend/1000 ~ temp | skies + day_night,
>     data = dodgers, groups = fireworks, pch = group.symbols,
>     aspect = 1, cex = 1.5, col = group.colors, fill = group.fill,
>     layout = c(2, 2), type = c("p","g"),
>     strip=strip.custom(strip.levels=TRUE,strip.names=FALSE, style=1),
>     xlab = "Temperature (Degrees Fahrenheit)",
>     ylab = "Attendance (thousands)",
>     key = list(space = "top",
>         text = list(rev(group.labels),col = rev(group.colors)),
>         points = list(pch = rev(group.symbols), col = rev(group.colors),
>         fill = rev(group.fill))))
>
> # attendance by opponent and day/night game
> group.labels <- c("Day","Night")
> group.symbols <- c(1,20)
> group.symbols.size <- c(2,2.75)
> bwplot(opponent ~ attend/1000, data = dodgers, groups = day_night,
>     xlab = "Attendance (thousands)",
>     panel = function(x, y, groups, subscripts, ...)
>        {panel.grid(h = (length(levels(dodgers$opponent)) - 1), v = -1)
>         panel.stripplot(x, y, groups = groups, subscripts = subscripts,
>         cex = group.symbols.size, pch = group.symbols, col = "darkblue")
>        },
>     key = list(space = "top",
>     text = list(group.labels,col = "black"),
>     points = list(pch = group.symbols, cex = group.symbols.size,
>     col = "darkblue")))
>
> # specify a simple model with bobblehead entered last
> my.model <- {attend ~ ordered_month + ordered_day_of_week + bobblehead}
>
> # employ a training-and-test regimen
> set.seed(1234) # set seed for repeatability of training-and-test split
> training_test <- c(rep(1,length=trunc((2/3)*nrow(dodgers))),
> rep(2,length=(nrow(dodgers) - trunc((2/3)*nrow(dodgers)))))
> dodgers$training_test <- sample(training_test) # random permutation
> dodgers$training_test <- factor(dodgers$training_test,
>   levels=c(1,2), labels=c("TRAIN","TEST"))
> dodgers.train <- subset(dodgers, training_test == "TRAIN")
> print(str(dodgers.train)) # check training data frame
> dodgers.test <- subset(dodgers, training_test == "TEST")
> print(str(dodgers.test)) # check test data frame
>
> # fit the model to the training set
> train.model.fit <- lm(my.model, data = dodgers.train)
> # obtain predictions from the training set
> dodgers.train$predict_attend <- predict(train.model.fit)
>
> # evaluate the fitted model on the test set
> dodgers.test$predict_attend <- predict(train.model.fit,
>   newdata = dodgers.test)
>
> # compute the proportion of response variance
> # accounted for when predicting out-of-sample
> cat("\n","Proportion of Test Set Variance Accounted for: ",
> round((with(dodgers.test,cor(attend,predict_attend)^2)),
>   digits=3),"\n",sep="")
>
> # merge the training and test sets for plotting
> dodgers.plotting.frame <- rbind(dodgers.train,dodgers.test)
>
> # generate predictive modeling visual for management
> group.labels <- c("No Bobbleheads","Bobbleheads")
> group.symbols <- c(21,24)
> group.colors <- c("black","black")
> group.fill <- c("black","red")
> xyplot(predict_attend/1000 ~ attend/1000 | training_test,
>        data = dodgers.plotting.frame, groups = bobblehead, cex = 2,
>        pch = group.symbols, col = group.colors, fill = group.fill,
>        layout = c(2, 1), xlim = c(20,65), ylim = c(20,65),
>        aspect=1, type = c("p","g"),
>        panel=function(x,y, ...)
>             {panel.xyplot(x,y,...)
>              panel.segments(25,25,60,60,col="black",cex=2)
>             },
>        strip=function(...) strip.default(..., style=1),
>        xlab = "Actual Attendance (thousands)",
>        ylab = "Predicted Attendance (thousands)",
>        key = list(space = "top",
>               text = list(rev(group.labels),col = rev(group.colors)),
>               points = list(pch = rev(group.symbols),
>               col = rev(group.colors),
>               fill = rev(group.fill))))
>
> # use the full data set to obtain an estimate of the increase in
> # attendance due to bobbleheads, controlling for other factors
> my.model.fit <- lm(my.model, data = dodgers)  # use all available data
> print(summary(my.model.fit))
> # tests statistical significance of the bobblehead promotion
> # type I anova computes sums of squares for sequential tests
> print(anova(my.model.fit))
>
> cat("\n","Estimated Effect of Bobblehead Promotion on Attendance: ",
> round(my.model.fit$coefficients[length(my.model.fit$coefficients)],
> digits = 0),"\n",sep="")
>
> # standard graphics provide diagnostic plots
> plot(my.model.fit)
>
> # additional model diagnostics drawn from the car package
> library(car)
> residualPlots(my.model.fit)
> marginalModelPlots(my.model.fit)
> print(outlierTest(my.model.fit))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From rmh at temple.edu  Mon Dec  2 16:24:08 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 2 Dec 2013 10:24:08 -0500
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
Message-ID: <CAGx1TMAM_76tbOr2cDPWhV7HuP-2xKhGHDS7UrVxUMfNQons4g@mail.gmail.com>

If days of the week is not an Ordered Factor, then it will be sorted
alphabetically.
Fr Mo Sa Su Th Tu We

Rich

On Mon, Dec 2, 2013 at 6:24 AM, Bill <william108 at gmail.com> wrote:
> I am reading the code below. It acts on a csv file called dodgers.csv with
> the following variables.
>
>
>> print(str(dodgers))  # check the structure of the data frame
> 'data.frame':   81 obs. of  12 variables:
>  $ month      : Factor w/ 7 levels "APR","AUG","JUL",..: 1 1 1 1 1 1 1 1 1
> 1 ...
>  $ day        : int  10 11 12 13 14 15 23 24 25 27 ...
>  $ attend     : int  56000 29729 28328 31601 46549 38359 26376 44014 26345
> 44807 ...
>  $ day_of_week: Factor w/ 7 levels "Friday","Monday",..: 6 7 5 1 3 4 2 6 7
> 1 ...
>  $ opponent   : Factor w/ 17 levels "Angels","Astros",..: 13 13 13 11 11 11
> 3 3 3 10 ...
>  $ temp       : int  67 58 57 54 57 65 60 63 64 66 ...
>  $ skies      : Factor w/ 2 levels "Clear ","Cloudy": 1 2 2 2 2 1 2 2 2 1
> ...
>  $ day_night  : Factor w/ 2 levels "Day","Night": 1 2 2 2 2 1 2 2 2 2 ...
>  $ cap        : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>  $ shirt      : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>  $ fireworks  : Factor w/ 2 levels "NO","YES": 1 1 1 2 1 1 1 1 1 2 ...
>  $ bobblehead : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
> NULL
>>
>
> I don't understand why the author of the code decided to make the factor
> days_of_week into an ordered factor. Anyone know why this should be done?
> Thank you.
>
> Here is the code:
>
> # Predictive Model for Los Angeles Dodgers Promotion and Attendance
>
> library(car)  # special functions for linear regression
> library(lattice)  # graphics package
>
> # read in data and create a data frame called dodgers
> dodgers <- read.csv("dodgers.csv")
> print(str(dodgers))  # check the structure of the data frame
>
> # define an ordered day-of-week variable
> # for plots and data summaries
> dodgers$ordered_day_of_week <- with(data=dodgers,
>   ifelse ((day_of_week == "Monday"),1,
>   ifelse ((day_of_week == "Tuesday"),2,
>   ifelse ((day_of_week == "Wednesday"),3,
>   ifelse ((day_of_week == "Thursday"),4,
>   ifelse ((day_of_week == "Friday"),5,
>   ifelse ((day_of_week == "Saturday"),6,7)))))))
> dodgers$ordered_day_of_week <- factor(dodgers$ordered_day_of_week,
> levels=1:7,
> labels=c("Mon", "Tue", "Wed", "Thur", "Fri", "Sat", "Sun"))
>
> # exploratory data analysis with standard graphics: attendance by day of
> week
> with(data=dodgers,plot(ordered_day_of_week, attend/1000,
> xlab = "Day of Week", ylab = "Attendance (thousands)",
> col = "violet", las = 1))
>
> # when do the Dodgers use bobblehead promotions
> with(dodgers, table(bobblehead,ordered_day_of_week)) # bobbleheads on
> Tuesday
>
> # define an ordered month variable
> # for plots and data summaries
> dodgers$ordered_month <- with(data=dodgers,
>   ifelse ((month == "APR"),4,
>   ifelse ((month == "MAY"),5,
>   ifelse ((month == "JUN"),6,
>   ifelse ((month == "JUL"),7,
>   ifelse ((month == "AUG"),8,
>   ifelse ((month == "SEP"),9,10)))))))
> dodgers$ordered_month <- factor(dodgers$ordered_month, levels=4:10,
> labels = c("April", "May", "June", "July", "Aug", "Sept", "Oct"))
>
> # exploratory data analysis with standard R graphics: attendance by month
> with(data=dodgers,plot(ordered_month,attend/1000, xlab = "Month",
> ylab = "Attendance (thousands)", col = "light blue", las = 1))
>
> # exploratory data analysis displaying many variables
> # looking at attendance and conditioning on day/night
> # the skies and whether or not fireworks are displayed
> library(lattice) # used for plotting
> # let us prepare a graphical summary of the dodgers data
> group.labels <- c("No Fireworks","Fireworks")
> group.symbols <- c(21,24)
> group.colors <- c("black","black")
> group.fill <- c("black","red")
> xyplot(attend/1000 ~ temp | skies + day_night,
>     data = dodgers, groups = fireworks, pch = group.symbols,
>     aspect = 1, cex = 1.5, col = group.colors, fill = group.fill,
>     layout = c(2, 2), type = c("p","g"),
>     strip=strip.custom(strip.levels=TRUE,strip.names=FALSE, style=1),
>     xlab = "Temperature (Degrees Fahrenheit)",
>     ylab = "Attendance (thousands)",
>     key = list(space = "top",
>         text = list(rev(group.labels),col = rev(group.colors)),
>         points = list(pch = rev(group.symbols), col = rev(group.colors),
>         fill = rev(group.fill))))
>
> # attendance by opponent and day/night game
> group.labels <- c("Day","Night")
> group.symbols <- c(1,20)
> group.symbols.size <- c(2,2.75)
> bwplot(opponent ~ attend/1000, data = dodgers, groups = day_night,
>     xlab = "Attendance (thousands)",
>     panel = function(x, y, groups, subscripts, ...)
>        {panel.grid(h = (length(levels(dodgers$opponent)) - 1), v = -1)
>         panel.stripplot(x, y, groups = groups, subscripts = subscripts,
>         cex = group.symbols.size, pch = group.symbols, col = "darkblue")
>        },
>     key = list(space = "top",
>     text = list(group.labels,col = "black"),
>     points = list(pch = group.symbols, cex = group.symbols.size,
>     col = "darkblue")))
>
> # specify a simple model with bobblehead entered last
> my.model <- {attend ~ ordered_month + ordered_day_of_week + bobblehead}
>
> # employ a training-and-test regimen
> set.seed(1234) # set seed for repeatability of training-and-test split
> training_test <- c(rep(1,length=trunc((2/3)*nrow(dodgers))),
> rep(2,length=(nrow(dodgers) - trunc((2/3)*nrow(dodgers)))))
> dodgers$training_test <- sample(training_test) # random permutation
> dodgers$training_test <- factor(dodgers$training_test,
>   levels=c(1,2), labels=c("TRAIN","TEST"))
> dodgers.train <- subset(dodgers, training_test == "TRAIN")
> print(str(dodgers.train)) # check training data frame
> dodgers.test <- subset(dodgers, training_test == "TEST")
> print(str(dodgers.test)) # check test data frame
>
> # fit the model to the training set
> train.model.fit <- lm(my.model, data = dodgers.train)
> # obtain predictions from the training set
> dodgers.train$predict_attend <- predict(train.model.fit)
>
> # evaluate the fitted model on the test set
> dodgers.test$predict_attend <- predict(train.model.fit,
>   newdata = dodgers.test)
>
> # compute the proportion of response variance
> # accounted for when predicting out-of-sample
> cat("\n","Proportion of Test Set Variance Accounted for: ",
> round((with(dodgers.test,cor(attend,predict_attend)^2)),
>   digits=3),"\n",sep="")
>
> # merge the training and test sets for plotting
> dodgers.plotting.frame <- rbind(dodgers.train,dodgers.test)
>
> # generate predictive modeling visual for management
> group.labels <- c("No Bobbleheads","Bobbleheads")
> group.symbols <- c(21,24)
> group.colors <- c("black","black")
> group.fill <- c("black","red")
> xyplot(predict_attend/1000 ~ attend/1000 | training_test,
>        data = dodgers.plotting.frame, groups = bobblehead, cex = 2,
>        pch = group.symbols, col = group.colors, fill = group.fill,
>        layout = c(2, 1), xlim = c(20,65), ylim = c(20,65),
>        aspect=1, type = c("p","g"),
>        panel=function(x,y, ...)
>             {panel.xyplot(x,y,...)
>              panel.segments(25,25,60,60,col="black",cex=2)
>             },
>        strip=function(...) strip.default(..., style=1),
>        xlab = "Actual Attendance (thousands)",
>        ylab = "Predicted Attendance (thousands)",
>        key = list(space = "top",
>               text = list(rev(group.labels),col = rev(group.colors)),
>               points = list(pch = rev(group.symbols),
>               col = rev(group.colors),
>               fill = rev(group.fill))))
>
> # use the full data set to obtain an estimate of the increase in
> # attendance due to bobbleheads, controlling for other factors
> my.model.fit <- lm(my.model, data = dodgers)  # use all available data
> print(summary(my.model.fit))
> # tests statistical significance of the bobblehead promotion
> # type I anova computes sums of squares for sequential tests
> print(anova(my.model.fit))
>
> cat("\n","Estimated Effect of Bobblehead Promotion on Attendance: ",
> round(my.model.fit$coefficients[length(my.model.fit$coefficients)],
> digits = 0),"\n",sep="")
>
> # standard graphics provide diagnostic plots
> plot(my.model.fit)
>
> # additional model diagnostics drawn from the car package
> library(car)
> residualPlots(my.model.fit)
> marginalModelPlots(my.model.fit)
> print(outlierTest(my.model.fit))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Mon Dec  2 16:35:33 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 2 Dec 2013 07:35:33 -0800
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <CAGx1TMAM_76tbOr2cDPWhV7HuP-2xKhGHDS7UrVxUMfNQons4g@mail.gmail.com>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
	<CAGx1TMAM_76tbOr2cDPWhV7HuP-2xKhGHDS7UrVxUMfNQons4g@mail.gmail.com>
Message-ID: <CACk-te3Em8pSH6PuA0zq0EzP76LiAiQ+AjGvY76c4ju0DNef8Q@mail.gmail.com>

Not true, Rich.

> z <-factor(letters[1:3],lev=letters[3:1])
> sort(z)
[1] c b a
Levels: c b a

What you say is true only for the **default** sort order.

(Although maybe the code author didn't realize this either)

-- Bert


On Mon, Dec 2, 2013 at 7:24 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
> If days of the week is not an Ordered Factor, then it will be sorted
> alphabetically.
> Fr Mo Sa Su Th Tu We
>
> Rich
>
> On Mon, Dec 2, 2013 at 6:24 AM, Bill <william108 at gmail.com> wrote:
>> I am reading the code below. It acts on a csv file called dodgers.csv with
>> the following variables.
>>
>>
>>> print(str(dodgers))  # check the structure of the data frame
>> 'data.frame':   81 obs. of  12 variables:
>>  $ month      : Factor w/ 7 levels "APR","AUG","JUL",..: 1 1 1 1 1 1 1 1 1
>> 1 ...
>>  $ day        : int  10 11 12 13 14 15 23 24 25 27 ...
>>  $ attend     : int  56000 29729 28328 31601 46549 38359 26376 44014 26345
>> 44807 ...
>>  $ day_of_week: Factor w/ 7 levels "Friday","Monday",..: 6 7 5 1 3 4 2 6 7
>> 1 ...
>>  $ opponent   : Factor w/ 17 levels "Angels","Astros",..: 13 13 13 11 11 11
>> 3 3 3 10 ...
>>  $ temp       : int  67 58 57 54 57 65 60 63 64 66 ...
>>  $ skies      : Factor w/ 2 levels "Clear ","Cloudy": 1 2 2 2 2 1 2 2 2 1
>> ...
>>  $ day_night  : Factor w/ 2 levels "Day","Night": 1 2 2 2 2 1 2 2 2 2 ...
>>  $ cap        : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>>  $ shirt      : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>>  $ fireworks  : Factor w/ 2 levels "NO","YES": 1 1 1 2 1 1 1 1 1 2 ...
>>  $ bobblehead : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>> NULL
>>>
>>
>> I don't understand why the author of the code decided to make the factor
>> days_of_week into an ordered factor. Anyone know why this should be done?
>> Thank you.
>>
>> Here is the code:
>>
>> # Predictive Model for Los Angeles Dodgers Promotion and Attendance
>>
>> library(car)  # special functions for linear regression
>> library(lattice)  # graphics package
>>
>> # read in data and create a data frame called dodgers
>> dodgers <- read.csv("dodgers.csv")
>> print(str(dodgers))  # check the structure of the data frame
>>
>> # define an ordered day-of-week variable
>> # for plots and data summaries
>> dodgers$ordered_day_of_week <- with(data=dodgers,
>>   ifelse ((day_of_week == "Monday"),1,
>>   ifelse ((day_of_week == "Tuesday"),2,
>>   ifelse ((day_of_week == "Wednesday"),3,
>>   ifelse ((day_of_week == "Thursday"),4,
>>   ifelse ((day_of_week == "Friday"),5,
>>   ifelse ((day_of_week == "Saturday"),6,7)))))))
>> dodgers$ordered_day_of_week <- factor(dodgers$ordered_day_of_week,
>> levels=1:7,
>> labels=c("Mon", "Tue", "Wed", "Thur", "Fri", "Sat", "Sun"))
>>
>> # exploratory data analysis with standard graphics: attendance by day of
>> week
>> with(data=dodgers,plot(ordered_day_of_week, attend/1000,
>> xlab = "Day of Week", ylab = "Attendance (thousands)",
>> col = "violet", las = 1))
>>
>> # when do the Dodgers use bobblehead promotions
>> with(dodgers, table(bobblehead,ordered_day_of_week)) # bobbleheads on
>> Tuesday
>>
>> # define an ordered month variable
>> # for plots and data summaries
>> dodgers$ordered_month <- with(data=dodgers,
>>   ifelse ((month == "APR"),4,
>>   ifelse ((month == "MAY"),5,
>>   ifelse ((month == "JUN"),6,
>>   ifelse ((month == "JUL"),7,
>>   ifelse ((month == "AUG"),8,
>>   ifelse ((month == "SEP"),9,10)))))))
>> dodgers$ordered_month <- factor(dodgers$ordered_month, levels=4:10,
>> labels = c("April", "May", "June", "July", "Aug", "Sept", "Oct"))
>>
>> # exploratory data analysis with standard R graphics: attendance by month
>> with(data=dodgers,plot(ordered_month,attend/1000, xlab = "Month",
>> ylab = "Attendance (thousands)", col = "light blue", las = 1))
>>
>> # exploratory data analysis displaying many variables
>> # looking at attendance and conditioning on day/night
>> # the skies and whether or not fireworks are displayed
>> library(lattice) # used for plotting
>> # let us prepare a graphical summary of the dodgers data
>> group.labels <- c("No Fireworks","Fireworks")
>> group.symbols <- c(21,24)
>> group.colors <- c("black","black")
>> group.fill <- c("black","red")
>> xyplot(attend/1000 ~ temp | skies + day_night,
>>     data = dodgers, groups = fireworks, pch = group.symbols,
>>     aspect = 1, cex = 1.5, col = group.colors, fill = group.fill,
>>     layout = c(2, 2), type = c("p","g"),
>>     strip=strip.custom(strip.levels=TRUE,strip.names=FALSE, style=1),
>>     xlab = "Temperature (Degrees Fahrenheit)",
>>     ylab = "Attendance (thousands)",
>>     key = list(space = "top",
>>         text = list(rev(group.labels),col = rev(group.colors)),
>>         points = list(pch = rev(group.symbols), col = rev(group.colors),
>>         fill = rev(group.fill))))
>>
>> # attendance by opponent and day/night game
>> group.labels <- c("Day","Night")
>> group.symbols <- c(1,20)
>> group.symbols.size <- c(2,2.75)
>> bwplot(opponent ~ attend/1000, data = dodgers, groups = day_night,
>>     xlab = "Attendance (thousands)",
>>     panel = function(x, y, groups, subscripts, ...)
>>        {panel.grid(h = (length(levels(dodgers$opponent)) - 1), v = -1)
>>         panel.stripplot(x, y, groups = groups, subscripts = subscripts,
>>         cex = group.symbols.size, pch = group.symbols, col = "darkblue")
>>        },
>>     key = list(space = "top",
>>     text = list(group.labels,col = "black"),
>>     points = list(pch = group.symbols, cex = group.symbols.size,
>>     col = "darkblue")))
>>
>> # specify a simple model with bobblehead entered last
>> my.model <- {attend ~ ordered_month + ordered_day_of_week + bobblehead}
>>
>> # employ a training-and-test regimen
>> set.seed(1234) # set seed for repeatability of training-and-test split
>> training_test <- c(rep(1,length=trunc((2/3)*nrow(dodgers))),
>> rep(2,length=(nrow(dodgers) - trunc((2/3)*nrow(dodgers)))))
>> dodgers$training_test <- sample(training_test) # random permutation
>> dodgers$training_test <- factor(dodgers$training_test,
>>   levels=c(1,2), labels=c("TRAIN","TEST"))
>> dodgers.train <- subset(dodgers, training_test == "TRAIN")
>> print(str(dodgers.train)) # check training data frame
>> dodgers.test <- subset(dodgers, training_test == "TEST")
>> print(str(dodgers.test)) # check test data frame
>>
>> # fit the model to the training set
>> train.model.fit <- lm(my.model, data = dodgers.train)
>> # obtain predictions from the training set
>> dodgers.train$predict_attend <- predict(train.model.fit)
>>
>> # evaluate the fitted model on the test set
>> dodgers.test$predict_attend <- predict(train.model.fit,
>>   newdata = dodgers.test)
>>
>> # compute the proportion of response variance
>> # accounted for when predicting out-of-sample
>> cat("\n","Proportion of Test Set Variance Accounted for: ",
>> round((with(dodgers.test,cor(attend,predict_attend)^2)),
>>   digits=3),"\n",sep="")
>>
>> # merge the training and test sets for plotting
>> dodgers.plotting.frame <- rbind(dodgers.train,dodgers.test)
>>
>> # generate predictive modeling visual for management
>> group.labels <- c("No Bobbleheads","Bobbleheads")
>> group.symbols <- c(21,24)
>> group.colors <- c("black","black")
>> group.fill <- c("black","red")
>> xyplot(predict_attend/1000 ~ attend/1000 | training_test,
>>        data = dodgers.plotting.frame, groups = bobblehead, cex = 2,
>>        pch = group.symbols, col = group.colors, fill = group.fill,
>>        layout = c(2, 1), xlim = c(20,65), ylim = c(20,65),
>>        aspect=1, type = c("p","g"),
>>        panel=function(x,y, ...)
>>             {panel.xyplot(x,y,...)
>>              panel.segments(25,25,60,60,col="black",cex=2)
>>             },
>>        strip=function(...) strip.default(..., style=1),
>>        xlab = "Actual Attendance (thousands)",
>>        ylab = "Predicted Attendance (thousands)",
>>        key = list(space = "top",
>>               text = list(rev(group.labels),col = rev(group.colors)),
>>               points = list(pch = rev(group.symbols),
>>               col = rev(group.colors),
>>               fill = rev(group.fill))))
>>
>> # use the full data set to obtain an estimate of the increase in
>> # attendance due to bobbleheads, controlling for other factors
>> my.model.fit <- lm(my.model, data = dodgers)  # use all available data
>> print(summary(my.model.fit))
>> # tests statistical significance of the bobblehead promotion
>> # type I anova computes sums of squares for sequential tests
>> print(anova(my.model.fit))
>>
>> cat("\n","Estimated Effect of Bobblehead Promotion on Attendance: ",
>> round(my.model.fit$coefficients[length(my.model.fit$coefficients)],
>> digits = 0),"\n",sep="")
>>
>> # standard graphics provide diagnostic plots
>> plot(my.model.fit)
>>
>> # additional model diagnostics drawn from the car package
>> library(car)
>> residualPlots(my.model.fit)
>> marginalModelPlots(my.model.fit)
>> print(outlierTest(my.model.fit))
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dcarlson at tamu.edu  Mon Dec  2 16:41:33 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 2 Dec 2013 09:41:33 -0600
Subject: [R] generate multiple probability distributions
In-Reply-To: <529C9D9E.1080604@yorku.ca>
References: <529C9D9E.1080604@yorku.ca>
Message-ID: <064f01ceef74$fa0f8910$ee2e9b30$@tamu.edu>

You can use recycling to simplify things:

> set.seed(42)
> x <- seq(0,12)
> bin.df <- as.data.frame(
+     rbind( cbind(x, prob=dbinom(x,12,1/6), p=1/6),
+            cbind(x, prob=dbinom(x,12,1/3), p=1/3),
+            cbind(x, prob=dbinom(x,12,1/2), p=1/2),
+            cbind(x, prob=dbinom(x,12,2/3), p=2/3)
+      ))
> bin.df$p <- factor(bin.df$p, labels=c("1/6", "1/3", "1/2",
"2/3"))
> str(bin.df)
'data.frame':   52 obs. of  3 variables:
 $ x   : num  0 1 2 3 4 5 6 7 8 9 ...
 $ prob: num  0.1122 0.2692 0.2961 0.1974 0.0888 ...
 $ p   : Factor w/ 4 levels "1/6","1/3","1/2",..: 1 1 1 1 1 1 1
1 1 1 ...
> 
> bin.df.2 <- data.frame( x, 
+     prob = c(dbinom(x,12,1/6), dbinom(x,12,1/3),
+            dbinom(x,12,1/2), dbinom(x,12,2/3)),
+     p = rep(c(1/6, 1/3, 1/2, 2/3), each=length(x))
+ )
> bin.df.2$p <- factor(bin.df$p, labels=c("1/6", "1/3", "1/2",
"2/3"))
> str(bin.df.2)
'data.frame':   52 obs. of  3 variables:
 $ x   : int  0 1 2 3 4 5 6 7 8 9 ...
 $ prob: num  0.1122 0.2692 0.2961 0.1974 0.0888 ...
 $ p   : Factor w/ 4 levels "1/6","1/3","1/2",..: 1 1 1 1 1 1 1
1 1 1 ...
> all.equal(bin.df, bin.df.2)
[1] TRUE

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Michael
Friendly
Sent: Monday, December 2, 2013 8:48 AM
To: R-help
Subject: [R] generate multiple probability distributions

I want to generate a collection of probability distributions in
a data 
frame, with
varying parameters.  There must be some simpler way than what I
have below
(avoiding rbind and cbind), but I can't quite see it.

x <- seq(0,12)
bin.df <- as.data.frame(
     rbind( cbind(x, prob=dbinom(x,12,1/6), p=1/6),
            cbind(x, prob=dbinom(x,12,1/3), p=1/3),
            cbind(x, prob=dbinom(x,12,1/2), p=1/2),
            cbind(x, prob=dbinom(x,12,2/3), p=2/3)
           ))
bin.df$p <- factor(bin.df$p, labels=c("1/6", "1/3", "1/2",
"2/3"))
str(bin.df)

 > str(bin.df)
'data.frame':   52 obs. of  3 variables:
  $ x   : num  0 1 2 3 4 5 6 7 8 9 ...
  $ prob: num  0.1122 0.2692 0.2961 0.1974 0.0888 ...
  $ p   : Factor w/ 4 levels "1/6","1/3","1/2",..: 1 1 1 1 1 1 1
1 1 1 ...
 >

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416
736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From markleeds2 at gmail.com  Mon Dec  2 17:04:30 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Mon, 2 Dec 2013 11:04:30 -0500
Subject: [R] ordered factor question
Message-ID: <CAHz+bWZwHBAAq51xUGexDmkdOprZLCftxCYdMOwfuKJYPM2VVw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/a37c7dd0/attachment.pl>

From white.232 at wright.edu  Mon Dec  2 17:32:22 2013
From: white.232 at wright.edu (White, William Patrick)
Date: Mon, 2 Dec 2013 16:32:22 +0000
Subject: [R] Days to solstice calculation
In-Reply-To: <CAAcyNCwK4qHutOCr2jy_uqxWwzH_3BxZ=L42DNt7gHtfFXwnpw@mail.gmail.com>
References: <0369b6856f3e4e1fa19994d3fd82d026@BN1PR01MB023.prod.exchangelabs.com>,
	<CAAcyNCwK4qHutOCr2jy_uqxWwzH_3BxZ=L42DNt7gHtfFXwnpw@mail.gmail.com>
Message-ID: <1fde126133df43e89f3dadabf0d7422c@CO1PR01MB030.prod.exchangelabs.com>

Thank you for your response. I looked at the insol package and it does seem to contain a daylength function, but it would be more informative and aid in my growth as an R user to trace the source of the current problem rather than use a package as a work around.  Understanding that an alternate solution exists and understanding why the alternate solution works are not the same thing in this case.
________________________________________
From: skalp.oettli at gmail.com <skalp.oettli at gmail.com> on behalf of Pascal Oettli <kridox at ymail.com>
Sent: Monday, December 2, 2013 2:22 AM
To: White, William Patrick
Cc: r-help at R-project.org
Subject: Re: [R] Days to solstice calculation

Hello,

It seems that this kind of calculations are done in package 'insol'.

Regards,
Pascal


On 2 December 2013 15:26, White, William Patrick <white.232 at wright.edu> wrote:
> Hello,
> I've come across a problem in developing a set of custom functions to calculate the number of hours of daylight at a given latitude, and the number of days a date precedes or secedes the summer solstice. I discovered an inconsistency concerning leap years between my derived values and those from the US naval databases. It seems as far as I can figure that my inconsistency arises either in the calculation I used derived from an ecological modeling study in the 90's, in my understanding of the way R itself handles dates, or in my code. I feel like I must be missing something fundamental here and could use a little guidance. The first function returns the hours of daylight given a latitude, and the Julian day of the year (ie Jan 1 = 1 and so on). This appears to be very accurate. The second function takes a given date, extracts the year, determines the number of days in it, and uses the first function to calculate the hours of daylight in each day, and returns the longest or sh!
>  ortest one (Summer or Winter Solstice). But, in the case of leap years and non leap years, the date returned is identical, as is evidenced by Jan 1 in the provided examples being 170 days from summer solstice in both 2008 and 2007. This was not the case, the solstice should vary by one day between these years. Code is provided below and any help is appreciated.
> Patrick
> ps. apologies to you southern ducks your summer and winter solstices are reversed of my code nomenclature. I'm working with a northern dataset.
>
> Daylength <- function(J,L){
> #Amount of daylight
> #Ecological Modeling, volume 80 (1995) pp. 87-95, "A Model Comparison for Daylength as a Function of Latitude and Day of the Year."
> #D = Daylight length
> #L = Latitude in Degrees
> #J = Day of the year (Julian)
> P <- asin(.39795*cos(.2163108 + 2*atan(.9671396*tan(.00860*(J-186)))))
> A <- sin(0.8333*pi/180)+sin(L*pi/180)*sin(P)
> B <- cos(L*pi/180)*cos(P)
> D <- 24 - (24/pi)* acos(A/B)
> return(D)
> }
>
> #Example today and here
> Daylength(2,39.7505)
>
> TillSolstice <- function(date,solstice){
> Yr <- as.POSIXlt(date)$year+1900
> a <- as.Date(paste(as.character(Yr),as.character(rep("-01-01", length(Yr))),sep = ""))
> b <- as.Date(paste(as.character(Yr),as.character(rep("-12-31", length(Yr))),sep = ""))
> Winter <- NA
> Summer <- NA
> for (g in 1: length(a)){
> if(is.na(a[g])== FALSE){
> if(is.na(b[g])== FALSE){
>   cc <- seq.int(a[g],b[g], by = '1 day')
>   d <- length(cc)
>   e <- strptime(cc, "%Y-%m-%d")$yday+2
>   f <- Daylength(e,39.6981478)
>   Winter[g] <- which.min(f)
>   Summer[g] <- which.max(f)
> }
> }
> if(is.na(a[g])== TRUE){
>  Winter[g] <- NA
>   Summer[g] <- NA
> }
> if(is.na(b[g])== TRUE){
>  Winter[g] <- NA
>   Summer[g] <- NA
> }
>
>
> }
> #Days until solstice
> if (solstice =='S'){Countdown <- Summer - (strptime(date, "%Y-%m-%d")$yday+2)}
> if (solstice =='W'){Countdown <- Winter - (strptime(a, "%Y-%m-%d")$yday+2)}
> return(Countdown)
> }
>
> Nonleap <- TillSolstice(seq(as.Date("2007/1/1"), as.Date("2007/12/31"), by = "1 day"), solstice = 'S')
> Leap <- TillSolstice(seq(as.Date("2008/1/1"), as.Date("2008/12/31"), by = "1 day"), solstice = 'S')
> head(Nonleap)
> tail(Nonleap)
> length(Nonleap)
> head(Leap)
> tail(Leap)
> length(Leap)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From andy_liaw at merck.com  Mon Dec  2 17:39:52 2013
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 2 Dec 2013 11:39:52 -0500
Subject: [R] How do I extract Random Forest Terms and Probabilities?
In-Reply-To: <1385510212.89885.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <56180B40A4F72A4083C75B30DA86297333DB5643@PRDEXMBX-05.the-lab.llnl.gov>
	<1385510212.89885.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <D5FA03935F7418419332B61CA255F65FA5B8B32C6C@USCTMXP51012.merck.com>

#2 can be done simply with predict(fmi, type="prob").  See the help page for predict.randomForest().

Best,
Andy


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of arun
Sent: Tuesday, November 26, 2013 6:57 PM
To: R help
Subject: Re: [R] How do I extract Random Forest Terms and Probabilities?



Hi,
For the first part, you could do:

fmi2 <- fmi 
attributes(fmi2$terms) <- NULL
capture.output(fmi2$terms)
#[1] "Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width"

A.k.

On Tuesday, November 26, 2013 3:55 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:
Hi R Experts,

I need your help with two question regarding randomForest.


1.? ? ?  When I run a Random Forest model how do I extract the formula I used so that I can store it in a character vector in a dataframe?
For example the dataframe might look like this if I am running models using the IRIS dataset
#ModelID,Type,

#001,RF,Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width

fmi<-randomForest(Species~.,iris,mtry=3,ntry=500)
#I know one place where the information is in fmi$terms but not sure how to extract just the formula info. Or perhaps there is somewhere else in fmi that I could get this?


2.? ? ?  How do I get the probabilities (probability-like values) from the model that was run? I know for the test set I can use predict. And I know to extract the classifications from the model I use fmi$predicted. But where are the probabilities?


Dan
Workforce Analyst
HRIM - Workforce Analytics & Metrics
LLNL


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachme...{{dropped:13}}


From f.calboli at imperial.ac.uk  Mon Dec  2 17:59:37 2013
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 2 Dec 2013 16:59:37 +0000
Subject: [R] vcf, plink and other files in the /demo of a package
Message-ID: <BDB80489-DFF0-43D1-A067-01557BBD3EA6@imperial.ac.uk>

Hi All,

together with colleagues we are planning to submit a 2.0 version of a package we have on CRAN.  Because the package deals with high throughput genomic data we though it would be nice to have some sort of guidance for the users.  This should ideally mean a 'vignette', but as the time of writing nobody had time to set one up.  What we have is three scripts that are heavily commented and a bunch of files (plink binary files and vcd files) that provide the 'example' data for these scripts.  I was wondering whether the /demo directory would be an appropriate place where to put these scripts and the relative data.  

I ask because I am checking the package build and I get:

checking index information ... WARNING
Demo index entries without corresponding demo:
[1] "/plink/MultiPhen_plink" "/simul/MultiPhen_simul" "/vcf/MultiPhen_vcf"
See the information on INDEX files and package subdirectories in the
chapter ?Creating R packages? of the ?Writing R Extensions? manual.

despite the fact I did create a 00Index file in /demo:

/demo$ cat 00Index
/plink/MultiPhen_plink     MultiPhen demo of how to use PLINK BED files
/simul/MultiPhen_simul     MultiPhen demo of how to run a simulation with MultiPhen
/vcf/MultiPhen_vcf     MultiPhen demo of how to use data in vcf format

What am I missing?  Given the state of the documentation (i.e. no vignette and demo scripts that rely on data that is not in .rda format) would we be better off removing this stuff altogether?


BW

F



-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 881 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/229ce698/attachment.bin>

From pdalgd at gmail.com  Mon Dec  2 18:37:50 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 2 Dec 2013 18:37:50 +0100
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <CACk-te3Em8pSH6PuA0zq0EzP76LiAiQ+AjGvY76c4ju0DNef8Q@mail.gmail.com>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
	<CAGx1TMAM_76tbOr2cDPWhV7HuP-2xKhGHDS7UrVxUMfNQons4g@mail.gmail.com>
	<CACk-te3Em8pSH6PuA0zq0EzP76LiAiQ+AjGvY76c4ju0DNef8Q@mail.gmail.com>
Message-ID: <E5180D66-0FF5-472A-B053-00018487F35C@gmail.com>


On 02 Dec 2013, at 16:35 , Bert Gunter <gunter.berton at gene.com> wrote:

> Not true, Rich.
> 
>> z <-factor(letters[1:3],lev=letters[3:1])
>> sort(z)
> [1] c b a
> Levels: c b a
> 
> What you say is true only for the **default** sort order.
> 
> (Although maybe the code author didn't realize this either)

The coding is certainly clunky (the phrase about writing FORTRAN in any language springs to mind, only with SAS instead of FORTRAN):
>>> 
>>> dodgers$ordered_day_of_week <- with(data=dodgers,
>>>  ifelse ((day_of_week == "Monday"),1,
>>>  ifelse ((day_of_week == "Tuesday"),2,
>>>  ifelse ((day_of_week == "Wednesday"),3,
>>>  ifelse ((day_of_week == "Thursday"),4,
>>>  ifelse ((day_of_week == "Friday"),5,
>>>  ifelse ((day_of_week == "Saturday"),6,7)))))))
>>> dodgers$ordered_day_of_week <- factor(dodgers$ordered_day_of_week,
>>> levels=1:7,
>>> labels=c("Mon", "Tue", "Wed", "Thur", "Fri", "Sat", "Sun"))
>>> 

This'll do:

dodgers$ordered_day_of_week <- factor(dodgers$ordered_day_of_week,
levels=c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"),
labels=c("Mon", "Tue", "Wed", "Thur", "Fri", "Sat", "Sun"))

And BTW, it doesn't (and didn't) create an ordered factor, just a factor with a different level ordering.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gerifalte28 at hotmail.com  Mon Dec  2 18:50:05 2013
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Mon, 2 Dec 2013 17:50:05 +0000
Subject: [R] (no subject)
Message-ID: <BAY002-M260E22060001C91E159CED6A6EA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/88c26a46/attachment.pl>

From gerifalte28 at hotmail.com  Mon Dec  2 18:50:05 2013
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Mon, 2 Dec 2013 17:50:05 +0000
Subject: [R] (no subject)
Message-ID: <BAY002-M260E22060001C91E159CED6A6EA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/88c26a46/attachment-0001.pl>

From rmh at temple.edu  Mon Dec  2 18:51:00 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 2 Dec 2013 12:51:00 -0500
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <CACk-te3Em8pSH6PuA0zq0EzP76LiAiQ+AjGvY76c4ju0DNef8Q@mail.gmail.com>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
	<CAGx1TMAM_76tbOr2cDPWhV7HuP-2xKhGHDS7UrVxUMfNQons4g@mail.gmail.com>
	<CACk-te3Em8pSH6PuA0zq0EzP76LiAiQ+AjGvY76c4ju0DNef8Q@mail.gmail.com>
Message-ID: <CAGx1TMDpAJuuY8UWqrbVeD85A705BJk+w-HB7j6hvwJ+c1ACuQ@mail.gmail.com>

Bert,
the issue is the sort order of the levels.  Time series graphs in the
alphabetical sort
order will be uninterpretable.  I show the three sets of contrasts for
factors, factors
with specified levels, and ordered factors.

week <- c("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday")
class(week)

week.f <- factor(week)
levels(week.f)

week.l <- factor(week, levels=week)
levels(week.l)

week.o <- ordered(week, levels=week)
levels(week.o)

contrasts(week.f)

contrasts(week.l)

contrasts(week.o)

Rich

On Mon, Dec 2, 2013 at 10:35 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> Not true, Rich.
>
>> z <-factor(letters[1:3],lev=letters[3:1])
>> sort(z)
> [1] c b a
> Levels: c b a
>
> What you say is true only for the **default** sort order.
>
> (Although maybe the code author didn't realize this either)
>
> -- Bert
>
>
> On Mon, Dec 2, 2013 at 7:24 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> If days of the week is not an Ordered Factor, then it will be sorted
>> alphabetically.
>> Fr Mo Sa Su Th Tu We
>>
>> Rich
>>
>> On Mon, Dec 2, 2013 at 6:24 AM, Bill <william108 at gmail.com> wrote:
>>> I am reading the code below. It acts on a csv file called dodgers.csv with
>>> the following variables.
>>>
>>>
>>>> print(str(dodgers))  # check the structure of the data frame
>>> 'data.frame':   81 obs. of  12 variables:
>>>  $ month      : Factor w/ 7 levels "APR","AUG","JUL",..: 1 1 1 1 1 1 1 1 1
>>> 1 ...
>>>  $ day        : int  10 11 12 13 14 15 23 24 25 27 ...
>>>  $ attend     : int  56000 29729 28328 31601 46549 38359 26376 44014 26345
>>> 44807 ...
>>>  $ day_of_week: Factor w/ 7 levels "Friday","Monday",..: 6 7 5 1 3 4 2 6 7
>>> 1 ...
>>>  $ opponent   : Factor w/ 17 levels "Angels","Astros",..: 13 13 13 11 11 11
>>> 3 3 3 10 ...
>>>  $ temp       : int  67 58 57 54 57 65 60 63 64 66 ...
>>>  $ skies      : Factor w/ 2 levels "Clear ","Cloudy": 1 2 2 2 2 1 2 2 2 1
>>> ...
>>>  $ day_night  : Factor w/ 2 levels "Day","Night": 1 2 2 2 2 1 2 2 2 2 ...
>>>  $ cap        : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>>>  $ shirt      : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>>>  $ fireworks  : Factor w/ 2 levels "NO","YES": 1 1 1 2 1 1 1 1 1 2 ...
>>>  $ bobblehead : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>>> NULL
>>>>
>>>
>>> I don't understand why the author of the code decided to make the factor
>>> days_of_week into an ordered factor. Anyone know why this should be done?
>>> Thank you.
>>>
>>> Here is the code:
>>>
>>> # Predictive Model for Los Angeles Dodgers Promotion and Attendance
>>>
>>> library(car)  # special functions for linear regression
>>> library(lattice)  # graphics package
>>>
>>> # read in data and create a data frame called dodgers
>>> dodgers <- read.csv("dodgers.csv")
>>> print(str(dodgers))  # check the structure of the data frame
>>>
>>> # define an ordered day-of-week variable
>>> # for plots and data summaries
>>> dodgers$ordered_day_of_week <- with(data=dodgers,
>>>   ifelse ((day_of_week == "Monday"),1,
>>>   ifelse ((day_of_week == "Tuesday"),2,
>>>   ifelse ((day_of_week == "Wednesday"),3,
>>>   ifelse ((day_of_week == "Thursday"),4,
>>>   ifelse ((day_of_week == "Friday"),5,
>>>   ifelse ((day_of_week == "Saturday"),6,7)))))))
>>> dodgers$ordered_day_of_week <- factor(dodgers$ordered_day_of_week,
>>> levels=1:7,
>>> labels=c("Mon", "Tue", "Wed", "Thur", "Fri", "Sat", "Sun"))
>>>
>>> # exploratory data analysis with standard graphics: attendance by day of
>>> week
>>> with(data=dodgers,plot(ordered_day_of_week, attend/1000,
>>> xlab = "Day of Week", ylab = "Attendance (thousands)",
>>> col = "violet", las = 1))
>>>
>>> # when do the Dodgers use bobblehead promotions
>>> with(dodgers, table(bobblehead,ordered_day_of_week)) # bobbleheads on
>>> Tuesday
>>>
>>> # define an ordered month variable
>>> # for plots and data summaries
>>> dodgers$ordered_month <- with(data=dodgers,
>>>   ifelse ((month == "APR"),4,
>>>   ifelse ((month == "MAY"),5,
>>>   ifelse ((month == "JUN"),6,
>>>   ifelse ((month == "JUL"),7,
>>>   ifelse ((month == "AUG"),8,
>>>   ifelse ((month == "SEP"),9,10)))))))
>>> dodgers$ordered_month <- factor(dodgers$ordered_month, levels=4:10,
>>> labels = c("April", "May", "June", "July", "Aug", "Sept", "Oct"))
>>>
>>> # exploratory data analysis with standard R graphics: attendance by month
>>> with(data=dodgers,plot(ordered_month,attend/1000, xlab = "Month",
>>> ylab = "Attendance (thousands)", col = "light blue", las = 1))
>>>
>>> # exploratory data analysis displaying many variables
>>> # looking at attendance and conditioning on day/night
>>> # the skies and whether or not fireworks are displayed
>>> library(lattice) # used for plotting
>>> # let us prepare a graphical summary of the dodgers data
>>> group.labels <- c("No Fireworks","Fireworks")
>>> group.symbols <- c(21,24)
>>> group.colors <- c("black","black")
>>> group.fill <- c("black","red")
>>> xyplot(attend/1000 ~ temp | skies + day_night,
>>>     data = dodgers, groups = fireworks, pch = group.symbols,
>>>     aspect = 1, cex = 1.5, col = group.colors, fill = group.fill,
>>>     layout = c(2, 2), type = c("p","g"),
>>>     strip=strip.custom(strip.levels=TRUE,strip.names=FALSE, style=1),
>>>     xlab = "Temperature (Degrees Fahrenheit)",
>>>     ylab = "Attendance (thousands)",
>>>     key = list(space = "top",
>>>         text = list(rev(group.labels),col = rev(group.colors)),
>>>         points = list(pch = rev(group.symbols), col = rev(group.colors),
>>>         fill = rev(group.fill))))
>>>
>>> # attendance by opponent and day/night game
>>> group.labels <- c("Day","Night")
>>> group.symbols <- c(1,20)
>>> group.symbols.size <- c(2,2.75)
>>> bwplot(opponent ~ attend/1000, data = dodgers, groups = day_night,
>>>     xlab = "Attendance (thousands)",
>>>     panel = function(x, y, groups, subscripts, ...)
>>>        {panel.grid(h = (length(levels(dodgers$opponent)) - 1), v = -1)
>>>         panel.stripplot(x, y, groups = groups, subscripts = subscripts,
>>>         cex = group.symbols.size, pch = group.symbols, col = "darkblue")
>>>        },
>>>     key = list(space = "top",
>>>     text = list(group.labels,col = "black"),
>>>     points = list(pch = group.symbols, cex = group.symbols.size,
>>>     col = "darkblue")))
>>>
>>> # specify a simple model with bobblehead entered last
>>> my.model <- {attend ~ ordered_month + ordered_day_of_week + bobblehead}
>>>
>>> # employ a training-and-test regimen
>>> set.seed(1234) # set seed for repeatability of training-and-test split
>>> training_test <- c(rep(1,length=trunc((2/3)*nrow(dodgers))),
>>> rep(2,length=(nrow(dodgers) - trunc((2/3)*nrow(dodgers)))))
>>> dodgers$training_test <- sample(training_test) # random permutation
>>> dodgers$training_test <- factor(dodgers$training_test,
>>>   levels=c(1,2), labels=c("TRAIN","TEST"))
>>> dodgers.train <- subset(dodgers, training_test == "TRAIN")
>>> print(str(dodgers.train)) # check training data frame
>>> dodgers.test <- subset(dodgers, training_test == "TEST")
>>> print(str(dodgers.test)) # check test data frame
>>>
>>> # fit the model to the training set
>>> train.model.fit <- lm(my.model, data = dodgers.train)
>>> # obtain predictions from the training set
>>> dodgers.train$predict_attend <- predict(train.model.fit)
>>>
>>> # evaluate the fitted model on the test set
>>> dodgers.test$predict_attend <- predict(train.model.fit,
>>>   newdata = dodgers.test)
>>>
>>> # compute the proportion of response variance
>>> # accounted for when predicting out-of-sample
>>> cat("\n","Proportion of Test Set Variance Accounted for: ",
>>> round((with(dodgers.test,cor(attend,predict_attend)^2)),
>>>   digits=3),"\n",sep="")
>>>
>>> # merge the training and test sets for plotting
>>> dodgers.plotting.frame <- rbind(dodgers.train,dodgers.test)
>>>
>>> # generate predictive modeling visual for management
>>> group.labels <- c("No Bobbleheads","Bobbleheads")
>>> group.symbols <- c(21,24)
>>> group.colors <- c("black","black")
>>> group.fill <- c("black","red")
>>> xyplot(predict_attend/1000 ~ attend/1000 | training_test,
>>>        data = dodgers.plotting.frame, groups = bobblehead, cex = 2,
>>>        pch = group.symbols, col = group.colors, fill = group.fill,
>>>        layout = c(2, 1), xlim = c(20,65), ylim = c(20,65),
>>>        aspect=1, type = c("p","g"),
>>>        panel=function(x,y, ...)
>>>             {panel.xyplot(x,y,...)
>>>              panel.segments(25,25,60,60,col="black",cex=2)
>>>             },
>>>        strip=function(...) strip.default(..., style=1),
>>>        xlab = "Actual Attendance (thousands)",
>>>        ylab = "Predicted Attendance (thousands)",
>>>        key = list(space = "top",
>>>               text = list(rev(group.labels),col = rev(group.colors)),
>>>               points = list(pch = rev(group.symbols),
>>>               col = rev(group.colors),
>>>               fill = rev(group.fill))))
>>>
>>> # use the full data set to obtain an estimate of the increase in
>>> # attendance due to bobbleheads, controlling for other factors
>>> my.model.fit <- lm(my.model, data = dodgers)  # use all available data
>>> print(summary(my.model.fit))
>>> # tests statistical significance of the bobblehead promotion
>>> # type I anova computes sums of squares for sequential tests
>>> print(anova(my.model.fit))
>>>
>>> cat("\n","Estimated Effect of Bobblehead Promotion on Attendance: ",
>>> round(my.model.fit$coefficients[length(my.model.fit$coefficients)],
>>> digits = 0),"\n",sep="")
>>>
>>> # standard graphics provide diagnostic plots
>>> plot(my.model.fit)
>>>
>>> # additional model diagnostics drawn from the car package
>>> library(car)
>>> residualPlots(my.model.fit)
>>> marginalModelPlots(my.model.fit)
>>> print(outlierTest(my.model.fit))
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374


From andy_liaw at merck.com  Mon Dec  2 19:15:18 2013
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 2 Dec 2013 13:15:18 -0500
Subject: [R] interpretation of MDS plot in random forest
In-Reply-To: <529C7012.2000507@arpa.veneto.it>
References: <529C7012.2000507@arpa.veneto.it>
Message-ID: <D5FA03935F7418419332B61CA255F65FA5B8B32D6E@USCTMXP51012.merck.com>

Yes, that's part of the intention anyway.  One can also use them to do clustering.

Best,
Andy

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Massimo Bressan
Sent: Monday, December 02, 2013 6:34 AM
To: r-help at r-project.org
Subject: [R] interpretation of MDS plot in random forest

Given this general example:

set.seed(1)

data(iris)

iris.rf <- randomForest(Species ~ ., iris, proximity=TRUE, keep.forest=TRUE)

#varImpPlot(iris.rf)

#varUsed(iris.rf)

MDSplot(iris.rf, iris$Species)

I?ve been reading the documentation about random forest (at best of my - 
poor - knowledge) but I?m in trouble with the correct interpretation of 
the MDS plot and I hope someone can give me some clues

What is intended for ?the scaling coordinates of the proximity matrix??


I think to understand that the objective is here to present the distance 
among species in a parsimonious and visual way (of lower dimensionality)

Is therefore a parallelism to what are intended the principal components 
in a classical PCA?

Are the scaling coordinates DIM 1 and DIM2 the eigenvectors of the 
proximity matrix?

If that is correct, how would you find the eigenvalues for that 
eigenvectors? And what are the eigenvalues repreenting?


What are saying these two dimensions in the plot about the different 
iris species? Their relative distance in terms of proximity within the 
space DIM1 and DIM2?

How to choose for the k parameter (number of dimensions for the scaling 
coordinates)?

And finally how would you explain the plot in simple terms?

Thank you for any feedback
Best regards

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
New Jersey, USA 08889), and/or its affiliates Direct contact information
for affiliates is available at 
http://www.merck.com/contact/contacts.html) that may be confidential,
proprietary copyrighted and/or legally privileged. It is intended solely
for the use of the individual or entity named on this message. If you are
not the intended recipient, and have received this message in error,
please notify us immediately by reply e-mail and then delete it from 
your system.

From murdoch.duncan at gmail.com  Mon Dec  2 19:35:33 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 2 Dec 2013 13:35:33 -0500
Subject: [R] vcf, plink and other files in the /demo of a package
In-Reply-To: <BDB80489-DFF0-43D1-A067-01557BBD3EA6@imperial.ac.uk>
References: <BDB80489-DFF0-43D1-A067-01557BBD3EA6@imperial.ac.uk>
Message-ID: <529CD2F5.3060708@gmail.com>

On 02/12/2013 11:59 AM, Federico Calboli wrote:
> Hi All,
>
> together with colleagues we are planning to submit a 2.0 version of a package we have on CRAN.  Because the package deals with high throughput genomic data we though it would be nice to have some sort of guidance for the users.  This should ideally mean a 'vignette', but as the time of writing nobody had time to set one up.  What we have is three scripts that are heavily commented and a bunch of files (plink binary files and vcd files) that provide the 'example' data for these scripts.  I was wondering whether the /demo directory would be an appropriate place where to put these scripts and the relative data.
>
> I ask because I am checking the package build and I get:
>
> checking index information ... WARNING
> Demo index entries without corresponding demo:
> [1] "/plink/MultiPhen_plink" "/simul/MultiPhen_simul" "/vcf/MultiPhen_vcf"
> See the information on INDEX files and package subdirectories in the
> chapter ?Creating R packages? of the ?Writing R Extensions? manual.
>
> despite the fact I did create a 00Index file in /demo:
>
> /demo$ cat 00Index
> /plink/MultiPhen_plink     MultiPhen demo of how to use PLINK BED files
> /simul/MultiPhen_simul     MultiPhen demo of how to run a simulation with MultiPhen
> /vcf/MultiPhen_vcf     MultiPhen demo of how to use data in vcf format
>
> What am I missing?  Given the state of the documentation (i.e. no vignette and demo scripts that rely on data that is not in .rda format) would we be better off removing this stuff altogether?

Those index entries should be filenames of the demo files. The leading 
slash likely means R will interpret them as absolute paths, not relative 
paths, and that won't work.

A more usual way to do it would be to give them simple names, e.g. 
MultiPhen_plink (corresponding to MultiPhen_plink.R).

Since your demos refer to data files that are not embedded in the R 
code, you need to put those data files somewhere. They should go into 
the data directory if they are data a user can read (and then you need 
to follow the restrictions on things in that directory), or into your 
own directory below inst, to just be installed and available for use. In 
the latter case use system.file() to refer to them from within your demo 
code.

Duncan Murdoch


From dcarlson at tamu.edu  Mon Dec  2 19:47:25 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 2 Dec 2013 12:47:25 -0600
Subject: [R] Days to solstice calculation
In-Reply-To: <1fde126133df43e89f3dadabf0d7422c@CO1PR01MB030.prod.exchangelabs.com>
References: <0369b6856f3e4e1fa19994d3fd82d026@BN1PR01MB023.prod.exchangelabs.com>,
	<CAAcyNCwK4qHutOCr2jy_uqxWwzH_3BxZ=L42DNt7gHtfFXwnpw@mail.gmail.com>
	<1fde126133df43e89f3dadabf0d7422c@CO1PR01MB030.prod.exchangelabs.com>
Message-ID: <06e001ceef8e$f15691a0$d403b4e0$@tamu.edu>

They are a day apart. Summer solstice is day 172 in both cases
so the calendar dates should be one day apart and they are (June
22 in 2007 and June 21 in 2008):

> strptime("2007-06-22", format="%Y-%m-%d")$yday
[1] 172
> strptime("2008-06-21", format="%Y-%m-%d")$yday
[1] 172

Your Daylength() function gives the same values for days 1-365.
So it will always give 172 as the summer solstice and 355 as the
winter solstice. The leap year just adds a calculation for day
366. No need to calculate them over and over.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of White,
William Patrick
Sent: Monday, December 2, 2013 10:32 AM
To: Pascal Oettli
Cc: r-help at R-project.org
Subject: Re: [R] Days to solstice calculation

Thank you for your response. I looked at the insol package and
it does seem to contain a daylength function, but it would be
more informative and aid in my growth as an R user to trace the
source of the current problem rather than use a package as a
work around.  Understanding that an alternate solution exists
and understanding why the alternate solution works are not the
same thing in this case.
________________________________________
From: skalp.oettli at gmail.com <skalp.oettli at gmail.com> on behalf
of Pascal Oettli <kridox at ymail.com>
Sent: Monday, December 2, 2013 2:22 AM
To: White, William Patrick
Cc: r-help at R-project.org
Subject: Re: [R] Days to solstice calculation

Hello,

It seems that this kind of calculations are done in package
'insol'.

Regards,
Pascal


On 2 December 2013 15:26, White, William Patrick
<white.232 at wright.edu> wrote:
> Hello,
> I've come across a problem in developing a set of custom
functions to calculate the number of hours of daylight at a
given latitude, and the number of days a date precedes or
secedes the summer solstice. I discovered an inconsistency
concerning leap years between my derived values and those from
the US naval databases. It seems as far as I can figure that my
inconsistency arises either in the calculation I used derived
from an ecological modeling study in the 90's, in my
understanding of the way R itself handles dates, or in my code.
I feel like I must be missing something fundamental here and
could use a little guidance. The first function returns the
hours of daylight given a latitude, and the Julian day of the
year (ie Jan 1 = 1 and so on). This appears to be very accurate.
The second function takes a given date, extracts the year,
determines the number of days in it, and uses the first function
to calculate the hours of daylight in each day, and returns the
longest or !
 sh!
>  ortest one (Summer or Winter Solstice). But, in the case of
leap years and non leap years, the date returned is identical,
as is evidenced by Jan 1 in the provided examples being 170 days
from summer solstice in both 2008 and 2007. This was not the
case, the solstice should vary by one day between these years.
Code is provided below and any help is appreciated.
> Patrick
> ps. apologies to you southern ducks your summer and winter
solstices are reversed of my code nomenclature. I'm working with
a northern dataset.
>
> Daylength <- function(J,L){
> #Amount of daylight
> #Ecological Modeling, volume 80 (1995) pp. 87-95, "A Model
Comparison for Daylength as a Function of Latitude and Day of
the Year."
> #D = Daylight length
> #L = Latitude in Degrees
> #J = Day of the year (Julian)
> P <- asin(.39795*cos(.2163108 +
2*atan(.9671396*tan(.00860*(J-186)))))
> A <- sin(0.8333*pi/180)+sin(L*pi/180)*sin(P)
> B <- cos(L*pi/180)*cos(P)
> D <- 24 - (24/pi)* acos(A/B)
> return(D)
> }
>
> #Example today and here
> Daylength(2,39.7505)
>
> TillSolstice <- function(date,solstice){
> Yr <- as.POSIXlt(date)$year+1900
> a <- as.Date(paste(as.character(Yr),as.character(rep("-01-01",
length(Yr))),sep = ""))
> b <- as.Date(paste(as.character(Yr),as.character(rep("-12-31",
length(Yr))),sep = ""))
> Winter <- NA
> Summer <- NA
> for (g in 1: length(a)){
> if(is.na(a[g])== FALSE){
> if(is.na(b[g])== FALSE){
>   cc <- seq.int(a[g],b[g], by = '1 day')
>   d <- length(cc)
>   e <- strptime(cc, "%Y-%m-%d")$yday+2
>   f <- Daylength(e,39.6981478)
>   Winter[g] <- which.min(f)
>   Summer[g] <- which.max(f)
> }
> }
> if(is.na(a[g])== TRUE){
>  Winter[g] <- NA
>   Summer[g] <- NA
> }
> if(is.na(b[g])== TRUE){
>  Winter[g] <- NA
>   Summer[g] <- NA
> }
>
>
> }
> #Days until solstice
> if (solstice =='S'){Countdown <- Summer - (strptime(date,
"%Y-%m-%d")$yday+2)}
> if (solstice =='W'){Countdown <- Winter - (strptime(a,
"%Y-%m-%d")$yday+2)}
> return(Countdown)
> }
>
> Nonleap <- TillSolstice(seq(as.Date("2007/1/1"),
as.Date("2007/12/31"), by = "1 day"), solstice = 'S')
> Leap <- TillSolstice(seq(as.Date("2008/1/1"),
as.Date("2008/12/31"), by = "1 day"), solstice = 'S')
> head(Nonleap)
> tail(Nonleap)
> length(Nonleap)
> head(Leap)
> tail(Leap)
> length(Leap)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.



--
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From white.232 at wright.edu  Mon Dec  2 19:55:45 2013
From: white.232 at wright.edu (White, William Patrick)
Date: Mon, 2 Dec 2013 18:55:45 +0000
Subject: [R] Days to solstice calculation
In-Reply-To: <06e001ceef8e$f15691a0$d403b4e0$@tamu.edu>
References: <0369b6856f3e4e1fa19994d3fd82d026@BN1PR01MB023.prod.exchangelabs.com>
	<CAAcyNCwK4qHutOCr2jy_uqxWwzH_3BxZ=L42DNt7gHtfFXwnpw@mail.gmail.com>
	<1fde126133df43e89f3dadabf0d7422c@CO1PR01MB030.prod.exchangelabs.com>,
	<06e001ceef8e$f15691a0$d403b4e0$@tamu.edu>
Message-ID: <091e14ac1cae4415a44a3b103ec5ca15@CO1PR01MB030.prod.exchangelabs.com>

Thank you. I can't believe I didn't notice that. What a relief.
________________________________________
From: David Carlson <dcarlson at tamu.edu>
Sent: Monday, December 2, 2013 1:47 PM
To: White, William Patrick; 'Pascal Oettli'
Cc: 'r-help at R-project.org'
Subject: RE: [R] Days to solstice calculation

They are a day apart. Summer solstice is day 172 in both cases
so the calendar dates should be one day apart and they are (June
22 in 2007 and June 21 in 2008):

> strptime("2007-06-22", format="%Y-%m-%d")$yday
[1] 172
> strptime("2008-06-21", format="%Y-%m-%d")$yday
[1] 172

Your Daylength() function gives the same values for days 1-365.
So it will always give 172 as the summer solstice and 355 as the
winter solstice. The leap year just adds a calculation for day
366. No need to calculate them over and over.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of White,
William Patrick
Sent: Monday, December 2, 2013 10:32 AM
To: Pascal Oettli
Cc: r-help at R-project.org
Subject: Re: [R] Days to solstice calculation

Thank you for your response. I looked at the insol package and
it does seem to contain a daylength function, but it would be
more informative and aid in my growth as an R user to trace the
source of the current problem rather than use a package as a
work around.  Understanding that an alternate solution exists
and understanding why the alternate solution works are not the
same thing in this case.
________________________________________
From: skalp.oettli at gmail.com <skalp.oettli at gmail.com> on behalf
of Pascal Oettli <kridox at ymail.com>
Sent: Monday, December 2, 2013 2:22 AM
To: White, William Patrick
Cc: r-help at R-project.org
Subject: Re: [R] Days to solstice calculation

Hello,

It seems that this kind of calculations are done in package
'insol'.

Regards,
Pascal


On 2 December 2013 15:26, White, William Patrick
<white.232 at wright.edu> wrote:
> Hello,
> I've come across a problem in developing a set of custom
functions to calculate the number of hours of daylight at a
given latitude, and the number of days a date precedes or
secedes the summer solstice. I discovered an inconsistency
concerning leap years between my derived values and those from
the US naval databases. It seems as far as I can figure that my
inconsistency arises either in the calculation I used derived
from an ecological modeling study in the 90's, in my
understanding of the way R itself handles dates, or in my code.
I feel like I must be missing something fundamental here and
could use a little guidance. The first function returns the
hours of daylight given a latitude, and the Julian day of the
year (ie Jan 1 = 1 and so on). This appears to be very accurate.
The second function takes a given date, extracts the year,
determines the number of days in it, and uses the first function
to calculate the hours of daylight in each day, and returns the
longest or !
 sh!
>  ortest one (Summer or Winter Solstice). But, in the case of
leap years and non leap years, the date returned is identical,
as is evidenced by Jan 1 in the provided examples being 170 days
from summer solstice in both 2008 and 2007. This was not the
case, the solstice should vary by one day between these years.
Code is provided below and any help is appreciated.
> Patrick
> ps. apologies to you southern ducks your summer and winter
solstices are reversed of my code nomenclature. I'm working with
a northern dataset.
>
> Daylength <- function(J,L){
> #Amount of daylight
> #Ecological Modeling, volume 80 (1995) pp. 87-95, "A Model
Comparison for Daylength as a Function of Latitude and Day of
the Year."
> #D = Daylight length
> #L = Latitude in Degrees
> #J = Day of the year (Julian)
> P <- asin(.39795*cos(.2163108 +
2*atan(.9671396*tan(.00860*(J-186)))))
> A <- sin(0.8333*pi/180)+sin(L*pi/180)*sin(P)
> B <- cos(L*pi/180)*cos(P)
> D <- 24 - (24/pi)* acos(A/B)
> return(D)
> }
>
> #Example today and here
> Daylength(2,39.7505)
>
> TillSolstice <- function(date,solstice){
> Yr <- as.POSIXlt(date)$year+1900
> a <- as.Date(paste(as.character(Yr),as.character(rep("-01-01",
length(Yr))),sep = ""))
> b <- as.Date(paste(as.character(Yr),as.character(rep("-12-31",
length(Yr))),sep = ""))
> Winter <- NA
> Summer <- NA
> for (g in 1: length(a)){
> if(is.na(a[g])== FALSE){
> if(is.na(b[g])== FALSE){
>   cc <- seq.int(a[g],b[g], by = '1 day')
>   d <- length(cc)
>   e <- strptime(cc, "%Y-%m-%d")$yday+2
>   f <- Daylength(e,39.6981478)
>   Winter[g] <- which.min(f)
>   Summer[g] <- which.max(f)
> }
> }
> if(is.na(a[g])== TRUE){
>  Winter[g] <- NA
>   Summer[g] <- NA
> }
> if(is.na(b[g])== TRUE){
>  Winter[g] <- NA
>   Summer[g] <- NA
> }
>
>
> }
> #Days until solstice
> if (solstice =='S'){Countdown <- Summer - (strptime(date,
"%Y-%m-%d")$yday+2)}
> if (solstice =='W'){Countdown <- Winter - (strptime(a,
"%Y-%m-%d")$yday+2)}
> return(Countdown)
> }
>
> Nonleap <- TillSolstice(seq(as.Date("2007/1/1"),
as.Date("2007/12/31"), by = "1 day"), solstice = 'S')
> Leap <- TillSolstice(seq(as.Date("2008/1/1"),
as.Date("2008/12/31"), by = "1 day"), solstice = 'S')
> head(Nonleap)
> tail(Nonleap)
> length(Nonleap)
> head(Leap)
> tail(Leap)
> length(Leap)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.



--
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.



From dan.abner99 at gmail.com  Mon Dec  2 20:08:44 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Mon, 2 Dec 2013 14:08:44 -0500
Subject: [R] Question about ifelse() XXXX
Message-ID: <CAPRGo-kej3p7sH7Bgnzq5YS9aWJ-VOMTfRu1=BUJ_wByneh72Q@mail.gmail.com>

 Hi all,

Can anyone explain what is happening with element 4,4 of c1? ifelse()
is not recongizing it as value 1:

> c1
          q1        q2        q3        q4
q1 1.0000000 0.6668711 0.6948419 0.5758860
q2 0.6668711 1.0000000 0.6040746 0.4917447
q3 0.6948419 0.6040746 1.0000000 0.4730732
q4 0.5758860 0.4917447 0.4730732 1.0000000
> ifelse(c1==1,1,0)
   q1 q2 q3 q4
q1  1  0  0  0
q2  0  1  0  0
q3  0  0  1  0
q4  0  0  0  0
> c1[4,4]
[1] 1


From murdoch.duncan at gmail.com  Mon Dec  2 20:12:48 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Dec 2013 14:12:48 -0500
Subject: [R] Question about ifelse() XXXX
In-Reply-To: <CAPRGo-kej3p7sH7Bgnzq5YS9aWJ-VOMTfRu1=BUJ_wByneh72Q@mail.gmail.com>
References: <CAPRGo-kej3p7sH7Bgnzq5YS9aWJ-VOMTfRu1=BUJ_wByneh72Q@mail.gmail.com>
Message-ID: <529CDBB0.2060403@gmail.com>

On 02/12/2013 2:08 PM, Dan Abner wrote:
>   Hi all,
>
> Can anyone explain what is happening with element 4,4 of c1? ifelse()
> is not recongizing it as value 1:

FAQ 7.31.

Duncan Murdoch

>
> > c1
>            q1        q2        q3        q4
> q1 1.0000000 0.6668711 0.6948419 0.5758860
> q2 0.6668711 1.0000000 0.6040746 0.4917447
> q3 0.6948419 0.6040746 1.0000000 0.4730732
> q4 0.5758860 0.4917447 0.4730732 1.0000000
> > ifelse(c1==1,1,0)
>     q1 q2 q3 q4
> q1  1  0  0  0
> q2  0  1  0  0
> q3  0  0  1  0
> q4  0  0  0  0
> > c1[4,4]
> [1] 1
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Mon Dec  2 20:20:05 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 02 Dec 2013 14:20:05 -0500
Subject: [R] generate multiple probability distributions
In-Reply-To: <529CA364.4040707@gmail.com>
References: <529C9D9E.1080604@yorku.ca> <529CA364.4040707@gmail.com>
Message-ID: <529CDD65.9060700@yorku.ca>

On 12/2/2013 10:12 AM, Duncan Murdoch wrote:
> dbinom can take vector inputs for the parameters, so this would be a 
> bit simpler:
>
> x <- seq(0,12)
> x <- rep(x, 4)
> p <- rep(c(1/6, 1/3, 1/2, 2/3), each=13)
> bin.df <- data.frame(x, prob = dbinom(x, 12, p), p)
>
Thanks, Duncan

What I was missing was how dbinom() could use vector inputs for both x & p.
Using expand.grid() gives me what I want and is more
general for my purposes.  The main purpose of making p a factor is to 
facilitate
plots of prob ~ x|p.


XP <-expand.grid(x=0:12, p=c(1/6, 1/3, 1/2, 2/3))
bin.df <- data.frame(XP, prob=dbinom(XP[,"x"], 12, XP[,"p"]))
bin.df$p <- factor(bin.df$p, labels=c("1/6", "1/3", "1/2", "2/3"))
str(bin.df)

-Michael


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From pmassicotte at hotmail.com  Mon Dec  2 20:21:41 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Mon, 2 Dec 2013 19:21:41 +0000
Subject: [R] legend position
Message-ID: <COL127-W49FAE92665FA25D94AC36DB3EA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/f070fd9a/attachment.pl>

From jacobwegelin at fastmail.fm  Mon Dec  2 20:22:24 2013
From: jacobwegelin at fastmail.fm (Jacob Wegelin)
Date: Mon, 2 Dec 2013 14:22:24 -0500
Subject: [R] plus/minus +/- in factor; not plotmath not expression
Message-ID: <alpine.OSX.2.02.1311301947560.29767@qqt.local>


I want to put the "plus or minus" symbol into a character variable, so that this can be turned into a factor and be displayed in the "strip" of a faceted ggplot2 plot.

A very nice solution, thanks to Professor Ripley's post of Nov 16, 2008; 3:13pm, visible at http://r.789695.n4.nabble.com/Symbols-to-use-in-text-td874239.html and subsequently http://www.fileformat.info/info/unicode/char/00b1/index.htm, is:

junk<- "\u00B1"
print(junk)

#	This works very nicely. For instance:

junk<-data.frame(gug=c(
 	rep( "\u00B1 1.2", 10)
 		,
 	rep( "\u00B1 2.3", 10)
 	)
)
junk$eks<-1:nrow(junk)
junk$why<-with(junk, as.numeric(gug) + eks)
print(summary(junk))
library(ggplot2)
print(
 	ggplot(data=junk, mapping=aes(x=eks, y=why))
 	+ geom_point()
 	+ facet_grid(. ~ gug)
)

This works very nicely on my system, but I just wanted to enquire:

Is this machine-independent and stable?

Is there a "native R" way to do this?

I did this in:

> sessionInfo()
R version 2.15.3 (2013-03-01)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ggplot2_0.9.3.1

loaded via a namespace (and not attached):
  [1] colorspace_1.2-0   dichromat_1.2-4    digest_0.6.0       grid_2.15.3        gtable_0.1.2       labeling_0.1
  [7] MASS_7.3-23        munsell_0.4        plyr_1.8           proto_0.3-10       psych_1.2.8        RColorBrewer_1.0-5
[13] reshape2_1.2.2     scales_0.2.3       stringr_0.6.2 
>

Incidentally (and for the sake of keyword searches): Although a google search initially led me to posts about expression() and plotmath, those eventually had nothing to do with the solution.

Jacob A. Wegelin
Assistant Professor
Department of Biostatistics
Virginia Commonwealth University
830 E. Main St., Seventh Floor
P. O. Box 980032
Richmond VA 23298-0032
U.S.A. 
CTSA grant: UL1TR000058
URL: http://www.people.vcu.edu/~jwegelin


From wdunlap at tibco.com  Mon Dec  2 20:31:18 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 2 Dec 2013 19:31:18 +0000
Subject: [R] Question about ifelse() XXXX
In-Reply-To: <CAPRGo-kej3p7sH7Bgnzq5YS9aWJ-VOMTfRu1=BUJ_wByneh72Q@mail.gmail.com>
References: <CAPRGo-kej3p7sH7Bgnzq5YS9aWJ-VOMTfRu1=BUJ_wByneh72Q@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1A326@PA-MBX01.na.tibco.com>

What is the value of
  diag(c1) - 1
?

(Or, use digits=16 when printing c1.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Dan Abner
> Sent: Monday, December 02, 2013 11:09 AM
> To: r-help at r-project.org
> Subject: [R] Question about ifelse() XXXX
> 
>  Hi all,
> 
> Can anyone explain what is happening with element 4,4 of c1? ifelse()
> is not recongizing it as value 1:
> 
> > c1
>           q1        q2        q3        q4
> q1 1.0000000 0.6668711 0.6948419 0.5758860
> q2 0.6668711 1.0000000 0.6040746 0.4917447
> q3 0.6948419 0.6040746 1.0000000 0.4730732
> q4 0.5758860 0.4917447 0.4730732 1.0000000
> > ifelse(c1==1,1,0)
>    q1 q2 q3 q4
> q1  1  0  0  0
> q2  0  1  0  0
> q3  0  0  1  0
> q4  0  0  0  0
> > c1[4,4]
> [1] 1
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From carl at witthoft.com  Mon Dec  2 20:49:19 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Mon, 2 Dec 2013 11:49:19 -0800 (PST)
Subject: [R] legend position
In-Reply-To: <COL127-W49FAE92665FA25D94AC36DB3EA0@phx.gbl>
References: <COL127-W49FAE92665FA25D94AC36DB3EA0@phx.gbl>
Message-ID: <1386013759955-4681492.post@n4.nabble.com>

See ?legend .   you can add a legend directly to an existing plot.  An
example:

legend('topright',c('hot','cold'),lty=1,col=c('red','green'),bg='white')

Now if you're trying to place the legend outside the plot area (i.e. in some
other part of the window),
you'll need to invoke par(xpd=TRUE) . See the help at ?par .


Filoche wrote
> Hi all. 
> I'm ploting a raster and I can't find the proper way to move the legend.
> For example,
> r = raster(system.file("external/test.grd", package="raster"))plot(r)
> How can I put the legend at the desired position?
> Thank in advance,Phil 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/legend-position-tp4681489p4681492.html
Sent from the R help mailing list archive at Nabble.com.


From rbaer at atsu.edu  Mon Dec  2 20:51:23 2013
From: rbaer at atsu.edu (Robert Baer)
Date: Mon, 02 Dec 2013 13:51:23 -0600
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <CACk-te3Em8pSH6PuA0zq0EzP76LiAiQ+AjGvY76c4ju0DNef8Q@mail.gmail.com>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>	<CAGx1TMAM_76tbOr2cDPWhV7HuP-2xKhGHDS7UrVxUMfNQons4g@mail.gmail.com>
	<CACk-te3Em8pSH6PuA0zq0EzP76LiAiQ+AjGvY76c4ju0DNef8Q@mail.gmail.com>
Message-ID: <529CE4BB.5000004@atsu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/f172a3f1/attachment.pl>

From pmassicotte at hotmail.com  Mon Dec  2 20:53:44 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Mon, 2 Dec 2013 19:53:44 +0000
Subject: [R] legend position
In-Reply-To: <1386013759955-4681492.post@n4.nabble.com>
References: <COL127-W49FAE92665FA25D94AC36DB3EA0@phx.gbl>,
	<1386013759955-4681492.post@n4.nabble.com>
Message-ID: <COL127-W76657D8BF00B102908630B3EA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/aa25175b/attachment.pl>

From gunter.berton at gene.com  Mon Dec  2 21:00:36 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 2 Dec 2013 12:00:36 -0800
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <529CE4BB.5000004@atsu.edu>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
	<CAGx1TMAM_76tbOr2cDPWhV7HuP-2xKhGHDS7UrVxUMfNQons4g@mail.gmail.com>
	<CACk-te3Em8pSH6PuA0zq0EzP76LiAiQ+AjGvY76c4ju0DNef8Q@mail.gmail.com>
	<529CE4BB.5000004@atsu.edu>
Message-ID: <CACk-te166EpD+vqHnQd4GU9ycALZ08YARDkJ3Bx_KNTFVD7=kg@mail.gmail.com>

Did you not see Mark Leeds's post?

The OP apparently did not really mean R's "ordered factors" as
produced by the R ordered() constructor; rather, he meant "factors
with levels ordered differently than the default", for which Rich's
answer was apropos. Mine -- and now yours -- in which we wrongly
assumed the OP knew what he was saying by "ordered factor", was not.

-- Bert

On Mon, Dec 2, 2013 at 11:51 AM, Robert Baer <rbaer at atsu.edu> wrote:
>
> On 12/2/2013 9:35 AM, Bert Gunter wrote:
>
> Not true, Rich.
>
> The point about alphabetical ordering explains why the author likely
> explicitly set the levels for the factor, though.
>
> As to why ordered factors, we may never know, but one possible explanation
> is that at some point he was going to use statistics where he wanted to use
> polynomial contrasts. See
>
> options()$contrasts
>
> Note that the default contrast type differs for normal factors and ordered
> factors.
>
>
>
> z <-factor(letters[1:3],lev=letters[3:1])
> sort(z)
>
> [1] c b a
> Levels: c b a
>
> What you say is true only for the **default** sort order.
>
> (Although maybe the code author didn't realize this either)
>
> -- Bert
>
>
> On Mon, Dec 2, 2013 at 7:24 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
>
> If days of the week is not an Ordered Factor, then it will be sorted
> alphabetically.
> Fr Mo Sa Su Th Tu We
>
> Rich
>
> On Mon, Dec 2, 2013 at 6:24 AM, Bill <william108 at gmail.com> wrote:
>
> I am reading the code below. It acts on a csv file called dodgers.csv with
> the following variables.
>
>
> print(str(dodgers))  # check the structure of the data frame
>
> 'data.frame':   81 obs. of  12 variables:
>  $ month      : Factor w/ 7 levels "APR","AUG","JUL",..: 1 1 1 1 1 1 1 1 1
> 1 ...
>  $ day        : int  10 11 12 13 14 15 23 24 25 27 ...
>  $ attend     : int  56000 29729 28328 31601 46549 38359 26376 44014 26345
> 44807 ...
>  $ day_of_week: Factor w/ 7 levels "Friday","Monday",..: 6 7 5 1 3 4 2 6 7
> 1 ...
>  $ opponent   : Factor w/ 17 levels "Angels","Astros",..: 13 13 13 11 11 11
> 3 3 3 10 ...
>  $ temp       : int  67 58 57 54 57 65 60 63 64 66 ...
>  $ skies      : Factor w/ 2 levels "Clear ","Cloudy": 1 2 2 2 2 1 2 2 2 1
> ...
>  $ day_night  : Factor w/ 2 levels "Day","Night": 1 2 2 2 2 1 2 2 2 2 ...
>  $ cap        : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>  $ shirt      : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>  $ fireworks  : Factor w/ 2 levels "NO","YES": 1 1 1 2 1 1 1 1 1 2 ...
>  $ bobblehead : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
> NULL
>
> I don't understand why the author of the code decided to make the factor
> days_of_week into an ordered factor. Anyone know why this should be done?
> Thank you.
>
> Here is the code:
>
> # Predictive Model for Los Angeles Dodgers Promotion and Attendance
>
> library(car)  # special functions for linear regression
> library(lattice)  # graphics package
>
> # read in data and create a data frame called dodgers
> dodgers <- read.csv("dodgers.csv")
> print(str(dodgers))  # check the structure of the data frame
>
> # define an ordered day-of-week variable
> # for plots and data summaries
> dodgers$ordered_day_of_week <- with(data=dodgers,
>   ifelse ((day_of_week == "Monday"),1,
>   ifelse ((day_of_week == "Tuesday"),2,
>   ifelse ((day_of_week == "Wednesday"),3,
>   ifelse ((day_of_week == "Thursday"),4,
>   ifelse ((day_of_week == "Friday"),5,
>   ifelse ((day_of_week == "Saturday"),6,7)))))))
> dodgers$ordered_day_of_week <- factor(dodgers$ordered_day_of_week,
> levels=1:7,
> labels=c("Mon", "Tue", "Wed", "Thur", "Fri", "Sat", "Sun"))
>
> # exploratory data analysis with standard graphics: attendance by day of
> week
> with(data=dodgers,plot(ordered_day_of_week, attend/1000,
> xlab = "Day of Week", ylab = "Attendance (thousands)",
> col = "violet", las = 1))
>
> # when do the Dodgers use bobblehead promotions
> with(dodgers, table(bobblehead,ordered_day_of_week)) # bobbleheads on
> Tuesday
>
> # define an ordered month variable
> # for plots and data summaries
> dodgers$ordered_month <- with(data=dodgers,
>   ifelse ((month == "APR"),4,
>   ifelse ((month == "MAY"),5,
>   ifelse ((month == "JUN"),6,
>   ifelse ((month == "JUL"),7,
>   ifelse ((month == "AUG"),8,
>   ifelse ((month == "SEP"),9,10)))))))
> dodgers$ordered_month <- factor(dodgers$ordered_month, levels=4:10,
> labels = c("April", "May", "June", "July", "Aug", "Sept", "Oct"))
>
> # exploratory data analysis with standard R graphics: attendance by month
> with(data=dodgers,plot(ordered_month,attend/1000, xlab = "Month",
> ylab = "Attendance (thousands)", col = "light blue", las = 1))
>
> # exploratory data analysis displaying many variables
> # looking at attendance and conditioning on day/night
> # the skies and whether or not fireworks are displayed
> library(lattice) # used for plotting
> # let us prepare a graphical summary of the dodgers data
> group.labels <- c("No Fireworks","Fireworks")
> group.symbols <- c(21,24)
> group.colors <- c("black","black")
> group.fill <- c("black","red")
> xyplot(attend/1000 ~ temp | skies + day_night,
>     data = dodgers, groups = fireworks, pch = group.symbols,
>     aspect = 1, cex = 1.5, col = group.colors, fill = group.fill,
>     layout = c(2, 2), type = c("p","g"),
>     strip=strip.custom(strip.levels=TRUE,strip.names=FALSE, style=1),
>     xlab = "Temperature (Degrees Fahrenheit)",
>     ylab = "Attendance (thousands)",
>     key = list(space = "top",
>         text = list(rev(group.labels),col = rev(group.colors)),
>         points = list(pch = rev(group.symbols), col = rev(group.colors),
>         fill = rev(group.fill))))
>
> # attendance by opponent and day/night game
> group.labels <- c("Day","Night")
> group.symbols <- c(1,20)
> group.symbols.size <- c(2,2.75)
> bwplot(opponent ~ attend/1000, data = dodgers, groups = day_night,
>     xlab = "Attendance (thousands)",
>     panel = function(x, y, groups, subscripts, ...)
>        {panel.grid(h = (length(levels(dodgers$opponent)) - 1), v = -1)
>         panel.stripplot(x, y, groups = groups, subscripts = subscripts,
>         cex = group.symbols.size, pch = group.symbols, col = "darkblue")
>        },
>     key = list(space = "top",
>     text = list(group.labels,col = "black"),
>     points = list(pch = group.symbols, cex = group.symbols.size,
>     col = "darkblue")))
>
> # specify a simple model with bobblehead entered last
> my.model <- {attend ~ ordered_month + ordered_day_of_week + bobblehead}
>
> # employ a training-and-test regimen
> set.seed(1234) # set seed for repeatability of training-and-test split
> training_test <- c(rep(1,length=trunc((2/3)*nrow(dodgers))),
> rep(2,length=(nrow(dodgers) - trunc((2/3)*nrow(dodgers)))))
> dodgers$training_test <- sample(training_test) # random permutation
> dodgers$training_test <- factor(dodgers$training_test,
>   levels=c(1,2), labels=c("TRAIN","TEST"))
> dodgers.train <- subset(dodgers, training_test == "TRAIN")
> print(str(dodgers.train)) # check training data frame
> dodgers.test <- subset(dodgers, training_test == "TEST")
> print(str(dodgers.test)) # check test data frame
>
> # fit the model to the training set
> train.model.fit <- lm(my.model, data = dodgers.train)
> # obtain predictions from the training set
> dodgers.train$predict_attend <- predict(train.model.fit)
>
> # evaluate the fitted model on the test set
> dodgers.test$predict_attend <- predict(train.model.fit,
>   newdata = dodgers.test)
>
> # compute the proportion of response variance
> # accounted for when predicting out-of-sample
> cat("\n","Proportion of Test Set Variance Accounted for: ",
> round((with(dodgers.test,cor(attend,predict_attend)^2)),
>   digits=3),"\n",sep="")
>
> # merge the training and test sets for plotting
> dodgers.plotting.frame <- rbind(dodgers.train,dodgers.test)
>
> # generate predictive modeling visual for management
> group.labels <- c("No Bobbleheads","Bobbleheads")
> group.symbols <- c(21,24)
> group.colors <- c("black","black")
> group.fill <- c("black","red")
> xyplot(predict_attend/1000 ~ attend/1000 | training_test,
>        data = dodgers.plotting.frame, groups = bobblehead, cex = 2,
>        pch = group.symbols, col = group.colors, fill = group.fill,
>        layout = c(2, 1), xlim = c(20,65), ylim = c(20,65),
>        aspect=1, type = c("p","g"),
>        panel=function(x,y, ...)
>             {panel.xyplot(x,y,...)
>              panel.segments(25,25,60,60,col="black",cex=2)
>             },
>        strip=function(...) strip.default(..., style=1),
>        xlab = "Actual Attendance (thousands)",
>        ylab = "Predicted Attendance (thousands)",
>        key = list(space = "top",
>               text = list(rev(group.labels),col = rev(group.colors)),
>               points = list(pch = rev(group.symbols),
>               col = rev(group.colors),
>               fill = rev(group.fill))))
>
> # use the full data set to obtain an estimate of the increase in
> # attendance due to bobbleheads, controlling for other factors
> my.model.fit <- lm(my.model, data = dodgers)  # use all available data
> print(summary(my.model.fit))
> # tests statistical significance of the bobblehead promotion
> # type I anova computes sums of squares for sequential tests
> print(anova(my.model.fit))
>
> cat("\n","Estimated Effect of Bobblehead Promotion on Attendance: ",
> round(my.model.fit$coefficients[length(my.model.fit$coefficients)],
> digits = 0),"\n",sep="")
>
> # standard graphics provide diagnostic plots
> plot(my.model.fit)
>
> # additional model diagnostics drawn from the car package
> library(car)
> residualPlots(my.model.fit)
> marginalModelPlots(my.model.fit)
> print(outlierTest(my.model.fit))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From carl at witthoft.com  Mon Dec  2 21:06:50 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Mon, 2 Dec 2013 12:06:50 -0800 (PST)
Subject: [R] legend position
In-Reply-To: <COL127-W49FAE92665FA25D94AC36DB3EA0@phx.gbl>
References: <COL127-W49FAE92665FA25D94AC36DB3EA0@phx.gbl>
Message-ID: <1386014810614-4681497.post@n4.nabble.com>

It occurs to me that perhaps you're referring to the 'color bar' on the right
of the plot.  AFAIK you cannot get at that from the raster::plot method.  
However  lattice::levelplot does allow you to manipulate or remove that
colorbar.




--
View this message in context: http://r.789695.n4.nabble.com/legend-position-tp4681489p4681497.html
Sent from the R help mailing list archive at Nabble.com.


From pmassicotte at hotmail.com  Mon Dec  2 21:10:38 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Mon, 2 Dec 2013 20:10:38 +0000
Subject: [R] legend position
In-Reply-To: <1386014810614-4681497.post@n4.nabble.com>
References: <COL127-W49FAE92665FA25D94AC36DB3EA0@phx.gbl>,
	<1386014810614-4681497.post@n4.nabble.com>
Message-ID: <COL127-W29B7189031C03BBB0715C2B3EA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/ec9177cf/attachment.pl>

From dwinsemius at comcast.net  Mon Dec  2 21:28:38 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 2 Dec 2013 12:28:38 -0800
Subject: [R] XLConnect readWorksheet   comma decimal sign
In-Reply-To: <529C502E.2080903@knut-krueger.de>
References: <52931410.4080102@knut-krueger.de>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA05B8@SRVEXCHMBX.precheza.cz>
	<52933D4B.90803@knut-krueger.de> <5298A218.2090303@knut-krueger.de>
	<5422DC5C-24A7-4BA6-A43A-44340703398A@comcast.net>
	<5298DD4C.1080404@knut-krueger.de>
	<33144A60-5037-4C76-B950-3376B4B14902@comcast.net>
	<529C502E.2080903@knut-krueger.de>
Message-ID: <0F58841C-E5E0-4DB5-AD6E-8696E908D08D@comcast.net>


On Dec 2, 2013, at 1:17 AM, Knut Krueger wrote:

> Am 29.11.2013 20:39, schrieb David Winsemius:
>>> Thats impossible, we are used to hit the comma
>> I don't know what that means.
> it is common here, that the decimal sign is commy

Believe me, I _do_ understand that in Europe it is common to use a comma as a decimal-sign. I told you how to adjust that for data input using `read.table` at the time of data input. R uses the period internally in all locales as the decimal separator. There is no mechanism that I know of that allows the console output to be with the period. For output with `write.table` you can again specify the use of the comma as the decimal separator and some other character as the field separator. In fact you can set that globally with:

?options

> options()$OutDec  # my setting
[1] "."

 If you continue having difficulty using XLConnect, then you should contact the authors of that package.

> All computer in the cip-pools are using the "comma" ( an I think 99.9% of all other computers here)
> Can you imagine what would happen after  changing  this to dot?
> Or in the other way, try to get the people in your country to use the ,comma as separator. It would cause a big jumble.
> 
>> Until you show a reproducible example, we will not be able to offer further advice: 
> That*s the problem ... I am still trying to find out  what happened. It was definitely wrong in two cases
> I was sure that I found the reason when starting this tread...
> 
> Knut
> 

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Mon Dec  2 21:29:06 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 2 Dec 2013 14:29:06 -0600
Subject: [R] legend position
In-Reply-To: <COL127-W49FAE92665FA25D94AC36DB3EA0@phx.gbl>
References: <COL127-W49FAE92665FA25D94AC36DB3EA0@phx.gbl>
Message-ID: <06f001ceef9d$262d73e0$72885ba0$@tamu.edu>

It is not straightforward unless you want the legend in the
right or the bottom margins. To put the legend inside the plot
region it is simplest to use image() to plot the raster file and
then image.plot(legend.only=TRUE) to add the legend. In addition
to reading the help page for plot{raster}, you also need the
pages for image{raster} and image.plot{fields}. Here are two
simple examples.

image(r,  col=rev(terrain.colors(255)))
plot(r, horizontal=TRUE, smallplot=c(.15, .5, .84, .86),
legend.only=TRUE)

image(r,  col=rev(terrain.colors(255)))
plot(r, smallplot=c(.15, .17, .5, .85), legend.only=TRUE)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of philippe
massicotte
Sent: Monday, December 2, 2013 1:22 PM
To: r-help at r-project.org
Subject: [R] legend position

Hi all. 
I'm ploting a raster and I can't find the proper way to move the
legend. For example,
r = raster(system.file("external/test.grd",
package="raster"))plot(r)
How can I put the legend at the desired position?
Thank in advance,Phil 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From pmassicotte at hotmail.com  Mon Dec  2 21:40:50 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Mon, 2 Dec 2013 20:40:50 +0000
Subject: [R] legend position
In-Reply-To: <06f001ceef9d$262d73e0$72885ba0$@tamu.edu>
References: <COL127-W49FAE92665FA25D94AC36DB3EA0@phx.gbl>,
	<06f001ceef9d$262d73e0$72885ba0$@tamu.edu>
Message-ID: <COL127-W362EEB1FF90DA475960F82B3EA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/1f008c29/attachment.pl>

From murdoch.duncan at gmail.com  Mon Dec  2 22:01:42 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 2 Dec 2013 16:01:42 -0500
Subject: [R] plus/minus +/- in factor; not plotmath not expression
In-Reply-To: <alpine.OSX.2.02.1311301947560.29767@qqt.local>
References: <alpine.OSX.2.02.1311301947560.29767@qqt.local>
Message-ID: <529CF536.2080602@gmail.com>

On 02/12/2013 2:22 PM, Jacob Wegelin wrote:
> I want to put the "plus or minus" symbol into a character variable, so that this can be turned into a factor and be displayed in the "strip" of a faceted ggplot2 plot.
>
> A very nice solution, thanks to Professor Ripley's post of Nov 16, 2008; 3:13pm, visible at http://r.789695.n4.nabble.com/Symbols-to-use-in-text-td874239.html and subsequently http://www.fileformat.info/info/unicode/char/00b1/index.htm, is:
>
> junk<- "\u00B1"
> print(junk)
>
> #	This works very nicely. For instance:
>
> junk<-data.frame(gug=c(
>   	rep( "\u00B1 1.2", 10)
>   		,
>   	rep( "\u00B1 2.3", 10)
>   	)
> )
> junk$eks<-1:nrow(junk)
> junk$why<-with(junk, as.numeric(gug) + eks)
> print(summary(junk))
> library(ggplot2)
> print(
>   	ggplot(data=junk, mapping=aes(x=eks, y=why))
>   	+ geom_point()
>   	+ facet_grid(. ~ gug)
> )
>
> This works very nicely on my system, but I just wanted to enquire:
>
> Is this machine-independent and stable?

It is machine-independent and stable because \u00B1 means "Unicode 
PLUS-MINUS SIGN", but it is not device-independent.  There may be a 
graphics device that does not support all Unicode characters.   I'd 
guess it is pretty widely available though.
>
> Is there a "native R" way to do this?

That is native R.

Duncan Murdoch
>
> I did this in:
>
> > sessionInfo()
> R version 2.15.3 (2013-03-01)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] ggplot2_0.9.3.1
>
> loaded via a namespace (and not attached):
>    [1] colorspace_1.2-0   dichromat_1.2-4    digest_0.6.0       grid_2.15.3        gtable_0.1.2       labeling_0.1
>    [7] MASS_7.3-23        munsell_0.4        plyr_1.8           proto_0.3-10       psych_1.2.8        RColorBrewer_1.0-5
> [13] reshape2_1.2.2     scales_0.2.3       stringr_0.6.2
> >
>
> Incidentally (and for the sake of keyword searches): Although a google search initially led me to posts about expression() and plotmath, those eventually had nothing to do with the solution.
>
> Jacob A. Wegelin
> Assistant Professor
> Department of Biostatistics
> Virginia Commonwealth University
> 830 E. Main St., Seventh Floor
> P. O. Box 980032
> Richmond VA 23298-0032
> U.S.A.
> CTSA grant: UL1TR000058
> URL: http://www.people.vcu.edu/~jwegelin
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Dec  2 22:12:20 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 2 Dec 2013 13:12:20 -0800
Subject: [R] plus/minus +/- in factor; not plotmath not expression
In-Reply-To: <alpine.OSX.2.02.1311301947560.29767@qqt.local>
References: <alpine.OSX.2.02.1311301947560.29767@qqt.local>
Message-ID: <3C1A2B00-166E-48ED-8A18-487EE7B5B088@comcast.net>


On Dec 2, 2013, at 11:22 AM, Jacob Wegelin wrote:

> 
> I want to put the "plus or minus" symbol into a character variable, so that this can be turned into a factor and be displayed in the "strip" of a faceted ggplot2 plot.
> 
> A very nice solution, thanks to Professor Ripley's post of Nov 16, 2008; 3:13pm, visible at http://r.789695.n4.nabble.com/Symbols-to-use-in-text-td874239.html and subsequently http://www.fileformat.info/info/unicode/char/00b1/index.htm, is:
> 
> junk<- "\u00B1"
> print(junk)
> 
> #	This works very nicely. For instance:
> 
snipped code
> 
> This works very nicely on my system, but I just wanted to enquire:
> 
> Is this machine-independent and stable?

It is font-_dependent_. It displays fine on a Mac console if that's any help, but it seems you probably already know that. I tested it on a 2.15.3 version of R on a Windows XP machine which probably has the default font settings for that ancient OS and it displayed fine there, too. It really depends on whether the default font for you OS has a glyph in that position in its font table.

> 
> Is there a "native R" way to do this?
> 
> I did this in:
> 
>> sessionInfo()
> R version 2.15.3 (2013-03-01)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>> 
> 
> Incidentally (and for the sake of keyword searches): Although a google search initially led me to posts about expression() and plotmath, those eventually had nothing to do with the solution.

That's not entirely true. The links on the ?plotmath page in the "Other symbols" section send you to ?points which has very instructive examples. I keep an annotated version of the output of TestChars(font=5) on the side of my desktop machine.

TestChars <- function(sign = 1, font = 1, ...)
{
   MB <- l10n_info()$MBCS
   r <- if(font == 5) { sign <- 1; c(32:126, 160:254)
       } else if(MB) 32:126 else 32:255
   if (sign == -1) r <- c(32:126, 160:255)
   par(pty = "s")
   plot(c(-1,16), c(-1,16), type = "n", xlab = "", ylab = "",
        xaxs = "i", yaxs = "i",
        main = sprintf("sign = %d, font = %d", sign, font))
   grid(17, 17, lty = 1) ; mtext(paste("MBCS:", MB))
   for(i in r) try( points(i%%16, i%/%16, pch = sign*i, font = font,...))
   for(i in r) try( text( (i%%16)-0.2, (i%/%16)-0.2,  as.character(i), font = 1, cex=0.5))
}

TestChars(font = 5)

You can see on that graphic that "?" is 177 and:
> strtoi(0x00B1)
[1] 177
> as.hexmode(177)
[1] "b1

-- 
David.
> 
> Jacob A. Wegelin


David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Dec  2 22:22:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 2 Dec 2013 13:22:26 -0800
Subject: [R] plus/minus +/- in factor; not plotmath not expression
In-Reply-To: <529CF536.2080602@gmail.com>
References: <alpine.OSX.2.02.1311301947560.29767@qqt.local>
	<529CF536.2080602@gmail.com>
Message-ID: <02882DE9-FCB4-49B6-954D-CBD2B782EB53@comcast.net>


On Dec 2, 2013, at 1:01 PM, Duncan Murdoch wrote:

> On 02/12/2013 2:22 PM, Jacob Wegelin wrote:
>> I want to put the "plus or minus" symbol into a character variable, so that this can be turned into a factor and be displayed in the "strip" of a faceted ggplot2 plot.
>> 
>> A very nice solution, thanks to Professor Ripley's post of Nov 16, 2008; 3:13pm, visible at http://r.789695.n4.nabble.com/Symbols-to-use-in-text-td874239.html and subsequently http://www.fileformat.info/info/unicode/char/00b1/index.htm, is:
>> 
>> junk<- "\u00B1"
>> print(junk)
>> 
snipped
>> Is there a "native R" way to do this?
> 
> That is native R.

There is also plotmath's '%+-%' operator:

plot(1,1, ylab = expression( A %+-% B ), xlab=expression( C%+-% D ) )

I noticed that Jacob was using ggplot2. Generally one can eventually find ways to label ggplot2 output with R expressions (used in the strict R language sense of the word), although sometimes it has been difficult for me to find the methods in the help pages.

-- 
David.
> 
> Duncan Murdoch
>> 
>> I did this in:
>> 
>> > sessionInfo()
>> R version 2.15.3 (2013-03-01)
>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>> 
>> 
>> 
>> Incidentally (and for the sake of keyword searches): Although a google search initially led me to posts about expression() and plotmath, those eventually had nothing to do with the solution.
>> 
>> Jacob A. Wegelin
> 


David Winsemius
Alameda, CA, USA


From mbressan at arpa.veneto.it  Mon Dec  2 22:20:18 2013
From: mbressan at arpa.veneto.it (mbressan at arpa.veneto.it)
Date: Mon, 2 Dec 2013 22:20:18 +0100
Subject: [R] interpretation of MDS plot in random forest
In-Reply-To: <D5FA03935F7418419332B61CA255F65FA5B8B32D6E@USCTMXP51012.merck.com>
References: <529C7012.2000507@arpa.veneto.it>
	<D5FA03935F7418419332B61CA255F65FA5B8B32D6E@USCTMXP51012.merck.com>
Message-ID: <700701132a38208cfeeb08ebd3cb4888.squirrel@89.96.234.216>

thanks andy

it's a real honour form me to get a reply by you;
I'm still a bit faraway from a proper grasp of the purpose of the plot...

may I ask you for a more technical (trivial) issue?
is it possible to add a legend in the MDS plot?
my problem is to link the color points in the chart to the factor that was
used as response to train rf, how to?

best

max

> Yes, that's part of the intention anyway.  One can also use them to do
> clustering.
>
> Best,
> Andy
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Massimo Bressan
> Sent: Monday, December 02, 2013 6:34 AM
> To: r-help at r-project.org
> Subject: [R] interpretation of MDS plot in random forest
>
> Given this general example:
>
> set.seed(1)
>
> data(iris)
>
> iris.rf <- randomForest(Species ~ ., iris, proximity=TRUE,
> keep.forest=TRUE)
>
> #varImpPlot(iris.rf)
>
> #varUsed(iris.rf)
>
> MDSplot(iris.rf, iris$Species)
>
> I?ve been reading the documentation about random forest (at best of my -
> poor - knowledge) but I?m in trouble with the correct interpretation of
> the MDS plot and I hope someone can give me some clues
>
> What is intended for ?the scaling coordinates of the proximity matrix??
>
>
> I think to understand that the objective is here to present the distance
> among species in a parsimonious and visual way (of lower dimensionality)
>
> Is therefore a parallelism to what are intended the principal components
> in a classical PCA?
>
> Are the scaling coordinates DIM 1 and DIM2 the eigenvectors of the
> proximity matrix?
>
> If that is correct, how would you find the eigenvalues for that
> eigenvectors? And what are the eigenvalues repreenting?
>
>
> What are saying these two dimensions in the plot about the different
> iris species? Their relative distance in terms of proximity within the
> space DIM1 and DIM2?
>
> How to choose for the k parameter (number of dimensions for the scaling
> coordinates)?
>
> And finally how would you explain the plot in simple terms?
>
> Thank you for any feedback
> Best regards
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> Notice:  This e-mail message, together with any attach...{{dropped:12}}


From jsdroyster at nc.rr.com  Mon Dec  2 21:38:48 2013
From: jsdroyster at nc.rr.com (Julie Royster)
Date: Mon, 2 Dec 2013 15:38:48 -0500
Subject: [R] names error message
Message-ID: <000101ceef9e$81201e00$83605a00$@rr.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/836e3c05/attachment.pl>

From smartpink111 at yahoo.com  Mon Dec  2 22:03:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Dec 2013 13:03:38 -0800 (PST)
Subject: [R] How to reconvert binary matrix back to original numeric?
Message-ID: <1386018218.27463.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
I couldn't reproduce the first part.
Lines1 <- readLines(textConnection("2 5 7 11
1 2 5
5 7 10 12 13")) 

?Max1 <- max(as.numeric(unlist(strsplit(Lines1," "))))
t(sapply(strsplit(Lines1," "), function(x) {x1<- as.numeric(x); x2 <- numeric(Max1); x2[x1]<- 1; x2}))

#or

mat1<- as.matrix(read.table(text=Lines1,header=FALSE,fill=TRUE))
indx <- cbind(as.vector(t(row(mat1))),as.vector(t(mat1)))
indx1 <- indx[!is.na(indx[,2]),]
Binary <- matrix(0,nrow(mat1),max(mat1,na.rm=TRUE))
Binary[indx1] <- 1

apply(!!Binary,1,which)
A.K.






Hi 
When you have data in text file has different length, for example: 
2 5 7 11 
1 2 5 
5 7 10 12 13 

Then you convert them to binary by: 
BinaryI<- as(data, "matrix") 
And you got: 
0 1 0 0 1 0 1 0 0 0 1 0 0 
1 1 0 0 1 0 0 0 0 0 0 0 0 
0 0 0 0 1 0 1 0 0 1 0 1 1 

How to convert them back to 
2 5 7 11 
1 2 5 
5 7 10 12 13 

I tried as.numeric and it didn?t work, and I tried that also with 
as(unlist(mydata), "numeric") 

thanks


From smartpink111 at yahoo.com  Mon Dec  2 23:22:46 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Dec 2013 14:22:46 -0800 (PST)
Subject: [R] How to reconvert binary matrix back to original numeric?
In-Reply-To: <1386018218.27463.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1386018218.27463.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1386022966.27340.YahooMailNeo@web142605.mail.bf1.yahoo.com>





Hi,
I couldn't reproduce the first part.
Lines1 <- readLines(textConnection("2 5 7 11
1 2 5
5 7 10 12 13")) 

?Max1 <- max(as.numeric(unlist(strsplit(Lines1," "))))
t(sapply(strsplit(Lines1," "), function(x) {x1<- as.numeric(x); x2 <- numeric(Max1); x2[x1]<- 1; x2}))

#or

mat1<- as.matrix(read.table(text=Lines1,header=FALSE,fill=TRUE))
indx <- cbind(as.vector(t(row(mat1))),as.vector(t(mat1)))
indx1 <- indx[!is.na(indx[,2]),]
Binary <- matrix(0,nrow(mat1),max(mat1,na.rm=TRUE))
Binary[indx1] <- 1

apply(!!Binary,1,which)
A.K.


Hi 
When you have data in text file has different length, for example: 
2 5 7 11 
1 2 5 
5 7 10 12 13 

Then you convert them to binary by: 
BinaryI<- as(data, "matrix") 
And you got: 
0 1 0 0 1 0 1 0 0 0 1 0 0 
1 1 0 0 1 0 0 0 0 0 0 0 0 
0 0 0 0 1 0 1 0 0 1 0 1 1 

How to convert them back to 
2 5 7 11 
1 2 5 
5 7 10 12 13 

I tried as.numeric and it didn?t work, and I tried that also with 
as(unlist(mydata), "numeric") 

thanks


From sarah.goslee at gmail.com  Tue Dec  3 00:19:28 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 2 Dec 2013 18:19:28 -0500
Subject: [R] names error message
In-Reply-To: <000101ceef9e$81201e00$83605a00$@rr.com>
References: <000101ceef9e$81201e00$83605a00$@rr.com>
Message-ID: <CAM_vjunDNaNX+uM70J2Pg_1DUMT8x-PvEzTOntj3aSeCM_R2xQ@mail.gmail.com>

Hi Julie,

On Mon, Dec 2, 2013 at 3:38 PM, Julie Royster <jsdroyster at nc.rr.com> wrote:
> Hello wise R folks,
>
> I ran a job to combine 2 dataframes using rbind.
> I received this error message that the names were not the same
>
> Error in match.names(clabs,names(xi)): names do not match previous names
>
> BUT when I entered this statement
>
> Identical (names(data1[[1]]),names(data2[[2]]) )

I'm not sure what you think you're comparing here:
> data1 <- data.frame(a=1:3, b=4:6, c=7:9)
> data2 <- data.frame(A=11:13, B=14:16, C=17:19)
> row.names(data1) <- c("A", "B", "C")

> identical (names(data1[[1]]),names(data2[[2]]) )
[1] TRUE

I initially thought you were comparing row names to column names, but
that's also not right. Instead you're taking the first list element of
data1 and comparing its name to that of the second list element of
data2, but extracting them in a way that removes the names:

> data1[[1]]
[1] 1 2 3
> data2[[2]]
[1] 14 15 16

> names(data1[[1]])
NULL
> names(data2[[2]])
NULL

Compared to:
> names(data1[1])
[1] "a"
> names(data2[2])
[1] "B"

Instead, you need to look at the column names of each, which
are most conveniently accessed with
colnames(data1) and colnames(data2)

> R responded TRUE to this query, indicating the names are identical
>
> So I am baffled.  visually checking each dataset using str they look the
> same, and R says they are the same when queried,
> But I still get the error when I give this command
>
> newname <- rbind (data1,data2)
>
> Any ideas?

Best idea of all: provide a reproducible example, because otherwise
there's no way to tell.

dput(head(data1))

and

dput(head(data2))

and paste that into your email.

Sarha

-- 
Sarah Goslee
http://www.functionaldiversity.org


From wdunlap at tibco.com  Tue Dec  3 00:47:42 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 2 Dec 2013 23:47:42 +0000
Subject: [R] names error message
In-Reply-To: <000101ceef9e$81201e00$83605a00$@rr.com>
References: <000101ceef9e$81201e00$83605a00$@rr.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1A419@PA-MBX01.na.tibco.com>

> I ran a job to combine 2 dataframes using rbind.
> I received this error message that the names were not the same
> Error in match.names(clabs,names(xi)): names do not match previous names

The column names of the data.frames given to rbind must all be
permutations of one another.   E.g.,
    > rbind(data.frame(A=1:3,B=11:13), data.frame(B=14:17, A=4:7))
      A  B
    1 1 11
    2 2 12
    3 3 13
    4 4 14
    5 5 15
    6 6 16
    7 7 17
but not
    > rbind(data.frame(A=1:3,B=11:13), data.frame(B=14:17, C=104:107))
    Error in match.names(clabs, names(xi)) : 
      names do not match previous names

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Julie Royster
> Sent: Monday, December 02, 2013 12:39 PM
> To: r-help at r-project.org
> Subject: [R] names error message
> 
> Hello wise R folks,
> 
> I ran a job to combine 2 dataframes using rbind.
> I received this error message that the names were not the same
> 
> Error in match.names(clabs,names(xi)): names do not match previous names
> 
> BUT when I entered this statement
> 
> Identical (names(data1[[1]]),names(data2[[2]]) )
> 
> R responded TRUE to this query, indicating the names are identical
> 
> So I am baffled.  visually checking each dataset using str they look the
> same, and R says they are the same when queried,
> But I still get the error when I give this command
> 
> newname <- rbind (data1,data2)
> 
> Any ideas?
> THANKS!
> Julie
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From william108 at gmail.com  Tue Dec  3 01:32:25 2013
From: william108 at gmail.com (Bill)
Date: Mon, 2 Dec 2013 16:32:25 -0800
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <CACk-te166EpD+vqHnQd4GU9ycALZ08YARDkJ3Bx_KNTFVD7=kg@mail.gmail.com>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
	<CAGx1TMAM_76tbOr2cDPWhV7HuP-2xKhGHDS7UrVxUMfNQons4g@mail.gmail.com>
	<CACk-te3Em8pSH6PuA0zq0EzP76LiAiQ+AjGvY76c4ju0DNef8Q@mail.gmail.com>
	<529CE4BB.5000004@atsu.edu>
	<CACk-te166EpD+vqHnQd4GU9ycALZ08YARDkJ3Bx_KNTFVD7=kg@mail.gmail.com>
Message-ID: <CAJnbHtLZB8ZjasU3mVPwbURctnc7ke2TC32ezEfy3BGknJwfqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/d557d245/attachment.pl>

From william108 at gmail.com  Tue Dec  3 01:33:46 2013
From: william108 at gmail.com (Bill)
Date: Mon, 2 Dec 2013 16:33:46 -0800
Subject: [R] ifelse -does it "manage the indexing"?
Message-ID: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/3676caca/attachment.pl>

From murdoch.duncan at gmail.com  Tue Dec  3 01:48:55 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Dec 2013 19:48:55 -0500
Subject: [R] ifelse -does it "manage the indexing"?
In-Reply-To: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>
References: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>
Message-ID: <529D2A77.9010107@gmail.com>

On 13-12-02 7:33 PM, Bill wrote:
> ifelse ((day_of_week == "Monday"),1,
>    ifelse ((day_of_week == "Tuesday"),2,
>    ifelse ((day_of_week == "Wednesday"),3,
>    ifelse ((day_of_week == "Thursday"),4,
>    ifelse ((day_of_week == "Friday"),5,
>    ifelse ((day_of_week == "Saturday"),6,7)))))))
>
>
>    In code like the above, day_of_week is a vector and so day_of_week ==
> "Monday" will result in a boolean vector. Suppose day_of_week is Monday,
> Thursday, Friday, Tuesday. So day_of_week == "Monday" will be
> True,False,False,False. I think that ifelse will test the first element and
> it will generate a 1. At this point it will not have run day_of_week ==
> "Tuesday" yet. Then it will test the second element of day_of_week and it
> will be false and this will cause it to evaluate day_of_week == "Tuesday".
> My question would be, does the evaluation of day_of_week == "Tuesday"
> result in the generation of an entire boolean vector (which would be in
> this case False,False,False,True) or does the ifelse "manage the indexing"
> so that it only tests the second element of the original vector (which is
> Thursday) and for that matter does it therefore not even bother to generate
> the first boolean vector I mentioned above (True,False,False,False) but
> rather just checks the first element?
>    Not sure if I have explained this well but if you understand I would
> appreciate a reply.

See the help for the function.  If any element of the test is true, the 
full first vector will be evaluated.  If any element is false, the 
second one will be evaluated.  There are no shortcuts of the kind you 
describe.

Duncan Murdoch


From william108 at gmail.com  Tue Dec  3 01:49:59 2013
From: william108 at gmail.com (Bill)
Date: Mon, 2 Dec 2013 16:49:59 -0800
Subject: [R] ifelse -does it "manage the indexing"?
In-Reply-To: <529D2A77.9010107@gmail.com>
References: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>
	<529D2A77.9010107@gmail.com>
Message-ID: <CAJnbHtK4kW3nNxjoNtZQ9oZ_=FXW+p4PGi0+=hEnh+QQ9OmsCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/c0923532/attachment.pl>

From murdoch.duncan at gmail.com  Tue Dec  3 02:09:17 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Dec 2013 20:09:17 -0500
Subject: [R] ifelse -does it "manage the indexing"?
In-Reply-To: <CAJnbHtK4kW3nNxjoNtZQ9oZ_=FXW+p4PGi0+=hEnh+QQ9OmsCA@mail.gmail.com>
References: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>
	<529D2A77.9010107@gmail.com>
	<CAJnbHtK4kW3nNxjoNtZQ9oZ_=FXW+p4PGi0+=hEnh+QQ9OmsCA@mail.gmail.com>
Message-ID: <529D2F3D.50600@gmail.com>

On 13-12-02 7:49 PM, Bill wrote:
> It seems so inefficient. I mean the whole first vector will be
> evaluated. Then if the second if is run the whole vector will be
> evaluated again. Then if the next if is run the whole vector will be
> evaluted again. And so on. And this could be only to test the first
> element (if it is false for each if statement). Then this would be
> repeated again and again. Is that really the way it works? Or am I not
> thinking clearly?

Read the manual.

Duncan Murdoch

>
>
> On Mon, Dec 2, 2013 at 4:48 PM, Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 13-12-02 7:33 PM, Bill wrote:
>
>         ifelse ((day_of_week == "Monday"),1,
>             ifelse ((day_of_week == "Tuesday"),2,
>             ifelse ((day_of_week == "Wednesday"),3,
>             ifelse ((day_of_week == "Thursday"),4,
>             ifelse ((day_of_week == "Friday"),5,
>             ifelse ((day_of_week == "Saturday"),6,7)))))))
>
>
>             In code like the above, day_of_week is a vector and so
>         day_of_week ==
>         "Monday" will result in a boolean vector. Suppose day_of_week is
>         Monday,
>         Thursday, Friday, Tuesday. So day_of_week == "Monday" will be
>         True,False,False,False. I think that ifelse will test the first
>         element and
>         it will generate a 1. At this point it will not have run
>         day_of_week ==
>         "Tuesday" yet. Then it will test the second element of
>         day_of_week and it
>         will be false and this will cause it to evaluate day_of_week ==
>         "Tuesday".
>         My question would be, does the evaluation of day_of_week ==
>         "Tuesday"
>         result in the generation of an entire boolean vector (which
>         would be in
>         this case False,False,False,True) or does the ifelse "manage the
>         indexing"
>         so that it only tests the second element of the original vector
>         (which is
>         Thursday) and for that matter does it therefore not even bother
>         to generate
>         the first boolean vector I mentioned above
>         (True,False,False,False) but
>         rather just checks the first element?
>             Not sure if I have explained this well but if you understand
>         I would
>         appreciate a reply.
>
>
>     See the help for the function.  If any element of the test is true,
>     the full first vector will be evaluated.  If any element is false,
>     the second one will be evaluated.  There are no shortcuts of the
>     kind you describe.
>
>     Duncan Murdoch
>
>


From william108 at gmail.com  Tue Dec  3 02:10:14 2013
From: william108 at gmail.com (Bill)
Date: Mon, 2 Dec 2013 17:10:14 -0800
Subject: [R] ifelse -does it "manage the indexing"?
In-Reply-To: <529D2F3D.50600@gmail.com>
References: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>
	<529D2A77.9010107@gmail.com>
	<CAJnbHtK4kW3nNxjoNtZQ9oZ_=FXW+p4PGi0+=hEnh+QQ9OmsCA@mail.gmail.com>
	<529D2F3D.50600@gmail.com>
Message-ID: <CAJnbHtKVFOsGDiBux5_-MwEWR+vD3s3jOaJz7+dz9GnWscVHbw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/76468c66/attachment.pl>

From wdunlap at tibco.com  Tue Dec  3 02:16:23 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 3 Dec 2013 01:16:23 +0000
Subject: [R] ifelse -does it "manage the indexing"?
In-Reply-To: <CAJnbHtK4kW3nNxjoNtZQ9oZ_=FXW+p4PGi0+=hEnh+QQ9OmsCA@mail.gmail.com>
References: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>
	<529D2A77.9010107@gmail.com>
	<CAJnbHtK4kW3nNxjoNtZQ9oZ_=FXW+p4PGi0+=hEnh+QQ9OmsCA@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1A49A@PA-MBX01.na.tibco.com>

> It seems so inefficient.

But ifelse knows nothing about the expressions given
as its second and third arguments -- it only sees their
values after they are evaluated.  Even if it could see the
expressions, it would not be able to assume that f(x[i])
is the same as f(x)[i] or things like
   ifelse(x>0, cumsum(x), cumsum(-x))
would not work.

You can avoid the computing all of f(x) and then extracting
a few elements from it by doing something like
   x <- c("Wednesday", "Monday", "Wednesday")
   z1 <- character(length(x))
   z1[x=="Monday"] <- "Mon"
   z1[x=="Tuesday"] <- "Tue"
   z1[x=="Wednesday"] <- "Wed"
or
   LongDayNames <- c("Monday","Tuesday","Wednesday")
   ShortDayNames <- c("Mon", "Tue", "Wed")
   z2 <- character(length(x))
   for(i in seq_along(LongDayNames)) {
      z2[x==LongDayNames[i]] <- ShortDayNames[i]
   }

To avoid the repeated x==value[i] you can use match(x, values).
   z3 <- ShortDayNames[match(x, LongDayNames)]

z1, z2, and z3 are identical  character vectors.

Or, you can use factors.
   > factor(x, levels=LongDayNames, labels=ShortDayNames)
   [1] Wed Mon Wed
   Levels: Mon Tue Wed

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Bill
> Sent: Monday, December 02, 2013 4:50 PM
> To: Duncan Murdoch
> Cc: r-help at r-project.org
> Subject: Re: [R] ifelse -does it "manage the indexing"?
> 
> It seems so inefficient. I mean the whole first vector will be evaluated.
> Then if the second if is run the whole vector will be evaluated again. Then
> if the next if is run the whole vector will be evaluted again. And so on.
> And this could be only to test the first element (if it is false for each
> if statement). Then this would be repeated again and again. Is that really
> the way it works? Or am I not thinking clearly?
> 
> 
> On Mon, Dec 2, 2013 at 4:48 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com>wrote:
> 
> > On 13-12-02 7:33 PM, Bill wrote:
> >
> >> ifelse ((day_of_week == "Monday"),1,
> >>    ifelse ((day_of_week == "Tuesday"),2,
> >>    ifelse ((day_of_week == "Wednesday"),3,
> >>    ifelse ((day_of_week == "Thursday"),4,
> >>    ifelse ((day_of_week == "Friday"),5,
> >>    ifelse ((day_of_week == "Saturday"),6,7)))))))
> >>
> >>
> >>    In code like the above, day_of_week is a vector and so day_of_week ==
> >> "Monday" will result in a boolean vector. Suppose day_of_week is Monday,
> >> Thursday, Friday, Tuesday. So day_of_week == "Monday" will be
> >> True,False,False,False. I think that ifelse will test the first element
> >> and
> >> it will generate a 1. At this point it will not have run day_of_week ==
> >> "Tuesday" yet. Then it will test the second element of day_of_week and it
> >> will be false and this will cause it to evaluate day_of_week == "Tuesday".
> >> My question would be, does the evaluation of day_of_week == "Tuesday"
> >> result in the generation of an entire boolean vector (which would be in
> >> this case False,False,False,True) or does the ifelse "manage the indexing"
> >> so that it only tests the second element of the original vector (which is
> >> Thursday) and for that matter does it therefore not even bother to
> >> generate
> >> the first boolean vector I mentioned above (True,False,False,False) but
> >> rather just checks the first element?
> >>    Not sure if I have explained this well but if you understand I would
> >> appreciate a reply.
> >>
> >
> > See the help for the function.  If any element of the test is true, the
> > full first vector will be evaluated.  If any element is false, the second
> > one will be evaluated.  There are no shortcuts of the kind you describe.
> >
> > Duncan Murdoch
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tahfounasousou at rocketmail.com  Tue Dec  3 02:11:30 2013
From: tahfounasousou at rocketmail.com (krys22)
Date: Mon, 2 Dec 2013 17:11:30 -0800 (PST)
Subject: [R] big matrix in r
Message-ID: <1386033090151-4681524.post@n4.nabble.com>

i have a problem with big matix, in fact, after th matrix's creation many
rows ans colomuns are invisble because the big dimension of the matix 
could you help me to get may complete matrix, have you any fonctions or any
solution to resolve this problem




--
View this message in context: http://r.789695.n4.nabble.com/big-matrix-in-r-tp4681524.html
Sent from the R help mailing list archive at Nabble.com.


From dgwenzi at gmail.com  Tue Dec  3 01:08:56 2013
From: dgwenzi at gmail.com (David Gwenzi)
Date: Mon, 2 Dec 2013 17:08:56 -0700
Subject: [R] Fwd: Intepreting lm() results with factor
In-Reply-To: <CA+g3nKQPcxMqu8hjTO=GFaNN=c7Vi=zx-JFFpvJFkcDt7+EAjQ@mail.gmail.com>
References: <CA+g3nKQPcxMqu8hjTO=GFaNN=c7Vi=zx-JFFpvJFkcDt7+EAjQ@mail.gmail.com>
Message-ID: <CA+g3nKQbx3cZ7oW5tR69_04tSy1j=Ls-2-qes_27QwjjeSpefw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/86ff2221/attachment.pl>

From David.Howell at uvm.edu  Tue Dec  3 02:41:26 2013
From: David.Howell at uvm.edu (David C. Howell)
Date: Mon, 02 Dec 2013 18:41:26 -0700
Subject: [R] Setting contrasts
Message-ID: <529D36C6.4000905@uvm.edu>

I have been having trouble understanding the difference between 
"contrasts(Group) <- contr.sum" and options(contrasts = 
c("contr.sum","contr.poly"). They both seem to say that they have done 
what I want, but only the latter works.

The reason why the question arises is tha,t using Fox's Anova, it is 
important to use sum contrasts. So I wrote the following code, with the 
result commented in.


# Start R from scratch in case old contrasts are left over  --They aren't
#removed with rm()
# Note that the data are balanced, so almost any solution SHOULD give 
the same
#result.
Eysenck <- 
read.table("http://www.uvm.edu/~dhowell/methods7/DataFiles/Tab13-2.dat",
  header = TRUE)
Eysenck$subj <- factor(1:100)
Eysenck$Condition <- factor(Eysenck$Condition, levels = 1:5, labels = 
c("Counting",
      "Rhyming", "Adjective", "Imagery","Intention"))
Eysenck$Age <- factor(Eysenck$Age, levels = 1:2, labels = c("Old","Young"))
attach(Eysenck)
result <- anova(aov(Recall~Condition*Age, data = Eysenck))
print(result)      # This is the correct result
             #Analysis of Variance Table
#
       #      Response: Recall
       #                                 Df  Sum Sq Mean Sq F value Pr(>F)
       #      Condition           4 1514.94  378.73 47.1911 < 2.2e-16 ***
       #      Age                     1  240.25  240.25 29.9356 
3.981e-07 ***
       #      Condition:Age   4  190.30   47.57  5.9279 0.0002793 ***
       #      Residuals         90  722.30 8.03
getOption("contrasts")
       #              unordered ordered
       #      "contr.treatment" "contr.poly"
#Note that these are the default treatment contrasts--bad, bad, but OK 
here.

# Leave the contrasts alone for now
library(car)
resultsCar1 <- lm(Recall~Age*Condition, data = Eysenck )
type2 <- Anova(resultsCar1, type = "II")     #This is OK, but the next 
is very  wrong
print(type2)
       #Anova Table (Type II tests)
       #type2 <- Anova(resultsCar1, type = "III")
       #Response: Recallprint(type2)
       #               Sum Sq Df F value Pr(>F)
       #Age                 240.25  1 29.9356 3.981e-07 ***
       #Condition     1514.94  4 47.1911 < 2.2e-16 ***
       #Age:Condition 190.30  4  5.9279 0.0002793 ***
       #Residuals      722.30 90

resultsCar2 <- lm(Recall~Age*Condition, data = Eysenck )
type3 <- Anova(resultsCar1, type = "III")
print(type3)   #  This is still wrong --Fox says I need sum contrasts
         #Anova Table (Type III tests)
       #  contrasts(Condition) <- contr.sum
       #  Response: Recallcontrasts(Age) <- contr.sum
       #                        Sum Sq Df F value Pr(>F)
       #  (Intercept)    490.00  1 61.0550  9.85e-12 ***
       #  Age                     1.25  1  0.1558 0.6940313
       #  Condition      351.52  4 10.9500  2.80e-07 ***    # Hmmm! why 
do we still have treatment contrasts
       #  Age:Condition 190.30  4  5.9279 0.0002793 ***## No LUCK!!
       #  Residuals    722.30 90
getOption("contrasts")
       #  unordered ordered
       #"contr.treatment" "contr.poly"
contrasts(Condition) <- contr.sum
contrasts(Age) <- contr.sum
contrasts(Condition); contrasts(Age)
    #Yup, we see sum contrasts!
       #          [,1] [,2] [,3] [,4]
       #Counting     1    0    0 0
       #Rhyming      0    1    0 0
       #Adjective    0    0    1 0
       #Imagery      0    0    0 1
       #Intention   -1   -1   -1 -1
       # [,1]
       #Old 1
       #Young -1
# BUT!!
resultsCar3 <- lm(Recall~Age*Condition, data = Eysenck )
type3 <- Anova(resultsCar3, type = "III")
print(type3)
       #Anova Table (Type III tests)
#
       #Response: Recall
       #                       Sum Sq Df F value Pr(>F)
       #(Intercept)     490.00  1 61.0550  9.85e-12 ***
       #Age                     1.25  1  0.1558 0.6940313
       #Condition      351.52  4 10.9500  2.80e-07 ***
       #Age:Condition 190.30  4  5.9279 0.0002793 ***
       #Residuals    722.30 90

##Damn! We are still wrong even though the above shows sum contrasts

## So we do it another way
options(contrasts = c("contr.sum","contr.poly"))
getOption("contrasts")
      #[1] "contr.sum" "contr.poly"
resutsCar4 <- lm(Recall~Age*Condition, data = Eysenck )
type4 <- Anova(resultsCar4, type = "III")
       #print(type4)  # Now we're back where we should be
       #Anova Table (Type III tests)
#
       #Response: Recall
       #                      Sum Sq Df   F value Pr(>F)
       #(Intercept)   13479.2  1 1679.5361 < 2.2e-16 ***
       #Age               240.2  1   29.9356 3.981e-07 ***
       #Condition      1514.9  4   47.1911 < 2.2e-16 ***
       #Age:Condition  190.3  4    5.9279 0.0002793 ***
       #Residuals       722.3 90
## Now it works just fine.
##So what is the difference between setting contrasts individuall and 
setting
##them through the options?

I get similar results if I use drop1, but perhaps that is what Fox did 
also.


From jwiley.psych at gmail.com  Tue Dec  3 02:55:12 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 2 Dec 2013 17:55:12 -0800
Subject: [R] Setting contrasts
In-Reply-To: <529D36C6.4000905@uvm.edu>
References: <529D36C6.4000905@uvm.edu>
Message-ID: <CANz9Z_+EeLKaVmZj68e_wSEZ=N18jfTWmSWRm88fsLNBS0V5Aw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/4866b2fd/attachment.pl>

From william108 at gmail.com  Tue Dec  3 03:00:57 2013
From: william108 at gmail.com (Bill)
Date: Mon, 2 Dec 2013 18:00:57 -0800
Subject: [R] ifelse -does it "manage the indexing"?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1A49A@PA-MBX01.na.tibco.com>
References: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>
	<529D2A77.9010107@gmail.com>
	<CAJnbHtK4kW3nNxjoNtZQ9oZ_=FXW+p4PGi0+=hEnh+QQ9OmsCA@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1A49A@PA-MBX01.na.tibco.com>
Message-ID: <CAJnbHtKV9m7VSF6y6GKZ2cUAEZCShZ_JHcgGN67VFP-ULwJaJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/02364614/attachment.pl>

From william108 at gmail.com  Tue Dec  3 03:02:37 2013
From: william108 at gmail.com (Bill)
Date: Mon, 2 Dec 2013 18:02:37 -0800
Subject: [R] ifelse -does it "manage the indexing"?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1A49A@PA-MBX01.na.tibco.com>
References: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>
	<529D2A77.9010107@gmail.com>
	<CAJnbHtK4kW3nNxjoNtZQ9oZ_=FXW+p4PGi0+=hEnh+QQ9OmsCA@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1A49A@PA-MBX01.na.tibco.com>
Message-ID: <CAJnbHt+Gh7+0SVd8HHQjnVmwEBSAL6eQmigt1rcR-JZBxi2Hqg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/39126ccb/attachment.pl>

From dulcalma at bigpond.com  Tue Dec  3 03:29:32 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 3 Dec 2013 12:29:32 +1000
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
Message-ID: <001801ceefcf$809d3c20$81d7b460$@bigpond.com>

Hi Bill

eg

> colours =  1:8
> coloursf =  factor(1:8)
> colourso =  ordered(1:8)
> str(coloursf)
 Factor w/ 8 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8
> str(colourso)
 Ord.factor w/ 8 levels "1"<"2"<"3"<"4"<..: 1 2 3 4 5 6 7 8

coloursf2 <- factor(1:8, levels = 8:1)
str(coloursf2)

Duncan

Duncan
Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


ordered used in 
used in MASS::polr and GEE for polytomous logistic regression

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Bill
Sent: Monday, 2 December 2013 21:24
To: r-help at r-project.org
Subject: [R] why change days of the week from a factor to an ordered factor?

I am reading the code below. It acts on a csv file called dodgers.csv with
the following variables.


> print(str(dodgers))  # check the structure of the data frame
'data.frame':   81 obs. of  12 variables:
 $ month      : Factor w/ 7 levels "APR","AUG","JUL",..: 1 1 1 1 1 1 1 1 1
1 ...
 $ day        : int  10 11 12 13 14 15 23 24 25 27 ...
 $ attend     : int  56000 29729 28328 31601 46549 38359 26376 44014 26345
44807 ...
 $ day_of_week: Factor w/ 7 levels "Friday","Monday",..: 6 7 5 1 3 4 2 6 7
1 ...
 $ opponent   : Factor w/ 17 levels "Angels","Astros",..: 13 13 13 11 11 11
3 3 3 10 ...
 $ temp       : int  67 58 57 54 57 65 60 63 64 66 ...
 $ skies      : Factor w/ 2 levels "Clear ","Cloudy": 1 2 2 2 2 1 2 2 2 1
...
 $ day_night  : Factor w/ 2 levels "Day","Night": 1 2 2 2 2 1 2 2 2 2 ...
 $ cap        : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
 $ shirt      : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
 $ fireworks  : Factor w/ 2 levels "NO","YES": 1 1 1 2 1 1 1 1 1 2 ...
 $ bobblehead : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
NULL
>

I don't understand why the author of the code decided to make the factor
days_of_week into an ordered factor. Anyone know why this should be done?
Thank you.

Here is the code:

# Predictive Model for Los Angeles Dodgers Promotion and Attendance

library(car)  # special functions for linear regression
library(lattice)  # graphics package

# read in data and create a data frame called dodgers dodgers <-
read.csv("dodgers.csv")
print(str(dodgers))  # check the structure of the data frame

# define an ordered day-of-week variable # for plots and data summaries
dodgers$ordered_day_of_week <- with(data=dodgers,
  ifelse ((day_of_week == "Monday"),1,
  ifelse ((day_of_week == "Tuesday"),2,
  ifelse ((day_of_week == "Wednesday"),3,
  ifelse ((day_of_week == "Thursday"),4,
  ifelse ((day_of_week == "Friday"),5,
  ifelse ((day_of_week == "Saturday"),6,7))))))) dodgers$ordered_day_of_week
<- factor(dodgers$ordered_day_of_week,
levels=1:7,
labels=c("Mon", "Tue", "Wed", "Thur", "Fri", "Sat", "Sun"))

# exploratory data analysis with standard graphics: attendance by day of
week with(data=dodgers,plot(ordered_day_of_week, attend/1000, xlab = "Day of
Week", ylab = "Attendance (thousands)", col = "violet", las = 1))

# when do the Dodgers use bobblehead promotions with(dodgers,
table(bobblehead,ordered_day_of_week)) # bobbleheads on Tuesday

# define an ordered month variable
# for plots and data summaries
dodgers$ordered_month <- with(data=dodgers,
  ifelse ((month == "APR"),4,
  ifelse ((month == "MAY"),5,
  ifelse ((month == "JUN"),6,
  ifelse ((month == "JUL"),7,
  ifelse ((month == "AUG"),8,
  ifelse ((month == "SEP"),9,10)))))))
dodgers$ordered_month <- factor(dodgers$ordered_month, levels=4:10, labels =
c("April", "May", "June", "July", "Aug", "Sept", "Oct"))

# exploratory data analysis with standard R graphics: attendance by month
with(data=dodgers,plot(ordered_month,attend/1000, xlab = "Month", ylab =
"Attendance (thousands)", col = "light blue", las = 1))

# exploratory data analysis displaying many variables # looking at
attendance and conditioning on day/night # the skies and whether or not
fireworks are displayed
library(lattice) # used for plotting
# let us prepare a graphical summary of the dodgers data group.labels <-
c("No Fireworks","Fireworks") group.symbols <- c(21,24) group.colors <-
c("black","black") group.fill <- c("black","red")
xyplot(attend/1000 ~ temp | skies + day_night,
    data = dodgers, groups = fireworks, pch = group.symbols,
    aspect = 1, cex = 1.5, col = group.colors, fill = group.fill,
    layout = c(2, 2), type = c("p","g"),
    strip=strip.custom(strip.levels=TRUE,strip.names=FALSE, style=1),
    xlab = "Temperature (Degrees Fahrenheit)",
    ylab = "Attendance (thousands)",
    key = list(space = "top",
        text = list(rev(group.labels),col = rev(group.colors)),
        points = list(pch = rev(group.symbols), col = rev(group.colors),
        fill = rev(group.fill))))

# attendance by opponent and day/night game group.labels <- c("Day","Night")
group.symbols <- c(1,20) group.symbols.size <- c(2,2.75) bwplot(opponent ~
attend/1000, data = dodgers, groups = day_night,
    xlab = "Attendance (thousands)",
    panel = function(x, y, groups, subscripts, ...)
       {panel.grid(h = (length(levels(dodgers$opponent)) - 1), v = -1)
        panel.stripplot(x, y, groups = groups, subscripts = subscripts,
        cex = group.symbols.size, pch = group.symbols, col = "darkblue")
       },
    key = list(space = "top",
    text = list(group.labels,col = "black"),
    points = list(pch = group.symbols, cex = group.symbols.size,
    col = "darkblue")))

# specify a simple model with bobblehead entered last my.model <- {attend ~
ordered_month + ordered_day_of_week + bobblehead}

# employ a training-and-test regimen
set.seed(1234) # set seed for repeatability of training-and-test split
training_test <- c(rep(1,length=trunc((2/3)*nrow(dodgers))),
rep(2,length=(nrow(dodgers) - trunc((2/3)*nrow(dodgers)))))
dodgers$training_test <- sample(training_test) # random permutation
dodgers$training_test <- factor(dodgers$training_test,
  levels=c(1,2), labels=c("TRAIN","TEST")) dodgers.train <- subset(dodgers,
training_test == "TRAIN")
print(str(dodgers.train)) # check training data frame dodgers.test <-
subset(dodgers, training_test == "TEST")
print(str(dodgers.test)) # check test data frame

# fit the model to the training set
train.model.fit <- lm(my.model, data = dodgers.train) # obtain predictions
from the training set dodgers.train$predict_attend <-
predict(train.model.fit)

# evaluate the fitted model on the test set dodgers.test$predict_attend <-
predict(train.model.fit,
  newdata = dodgers.test)

# compute the proportion of response variance # accounted for when
predicting out-of-sample cat("\n","Proportion of Test Set Variance Accounted
for: ", round((with(dodgers.test,cor(attend,predict_attend)^2)),
  digits=3),"\n",sep="")

# merge the training and test sets for plotting dodgers.plotting.frame <-
rbind(dodgers.train,dodgers.test)

# generate predictive modeling visual for management group.labels <- c("No
Bobbleheads","Bobbleheads") group.symbols <- c(21,24) group.colors <-
c("black","black") group.fill <- c("black","red")
xyplot(predict_attend/1000 ~ attend/1000 | training_test,
       data = dodgers.plotting.frame, groups = bobblehead, cex = 2,
       pch = group.symbols, col = group.colors, fill = group.fill,
       layout = c(2, 1), xlim = c(20,65), ylim = c(20,65),
       aspect=1, type = c("p","g"),
       panel=function(x,y, ...)
            {panel.xyplot(x,y,...)
             panel.segments(25,25,60,60,col="black",cex=2)
            },
       strip=function(...) strip.default(..., style=1),
       xlab = "Actual Attendance (thousands)",
       ylab = "Predicted Attendance (thousands)",
       key = list(space = "top",
              text = list(rev(group.labels),col = rev(group.colors)),
              points = list(pch = rev(group.symbols),
              col = rev(group.colors),
              fill = rev(group.fill))))

# use the full data set to obtain an estimate of the increase in #
attendance due to bobbleheads, controlling for other factors my.model.fit <-
lm(my.model, data = dodgers)  # use all available data
print(summary(my.model.fit))
# tests statistical significance of the bobblehead promotion # type I anova
computes sums of squares for sequential tests
print(anova(my.model.fit))

cat("\n","Estimated Effect of Bobblehead Promotion on Attendance: ",
round(my.model.fit$coefficients[length(my.model.fit$coefficients)],
digits = 0),"\n",sep="")

# standard graphics provide diagnostic plots
plot(my.model.fit)

# additional model diagnostics drawn from the car package
library(car)
residualPlots(my.model.fit)
marginalModelPlots(my.model.fit)
print(outlierTest(my.model.fit))

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From william108 at gmail.com  Tue Dec  3 03:58:52 2013
From: william108 at gmail.com (Bill)
Date: Mon, 2 Dec 2013 18:58:52 -0800
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <001801ceefcf$809d3c20$81d7b460$@bigpond.com>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
	<001801ceefcf$809d3c20$81d7b460$@bigpond.com>
Message-ID: <CAJnbHtL39GT+DkK4Q_vwcAjSh540XNxq7Frh8SkqheOwjPAVMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/fd446018/attachment.pl>

From floridmercutio at yahoo.com  Tue Dec  3 05:02:30 2013
From: floridmercutio at yahoo.com (Mercutio Florid)
Date: Mon, 2 Dec 2013 20:02:30 -0800 (PST)
Subject: [R] What is the easiest way to interpolate vertical values on a
	square section of a nearly-planar 3D surface
Message-ID: <1386043350.1849.YahooMailNeo@web121005.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131202/8cd43093/attachment.pl>

From smartpink111 at yahoo.com  Tue Dec  3 04:14:53 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Dec 2013 19:14:53 -0800 (PST)
Subject: [R] Generating numbers with time-dependent upperbound
Message-ID: <1386040493.98850.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this helps:
m <- 0.01
?T <- 90
?t <- 0:T
set.seed(42)
res1 <- sapply(t,function(.t) runif(1,0,m*(T-.t)))

#or
?set.seed(42)
?res2 <- runif(91,rep(0,91),m*(rep(T,91)-t))
identical(res1,res2)
#[1] TRUE

A.K.


Hi, 

I need to generate a sequence that consists of random numbers. 
My first idea was runif with the condition m(T-t), but i couldn't 
achieve. 

Given: m=0.01 , T=90, t={0,1,...,T} 

Sequence: s={p_0, p_1,..., p_T}, where p_t is chosen from the time-dependent interval [0, m(T-t)] ? 


I appreciate if someone helps me.


From smartpink111 at yahoo.com  Tue Dec  3 06:52:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Dec 2013 21:52:08 -0800 (PST)
Subject: [R] repeating a function and combining the results
Message-ID: <1386049928.30602.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
May be this helps:

example <- function(X,n){
lst1 <- list()
for(i in 1:n){
cell1 <- sample(X,1)
cell2 <- sample(X,1)
table1 <- cbind(cell1,cell2)
lst1[[i]] <- table1
}
do.call(rbind,lst1)
}

#or


example1 <- function(X,n){
table1 <- vector()
for(i in 1:n){
cell1 <- sample(X,1)
cell2 <- sample(X,1)
table1 <- rbind(table1,c(cell1=cell1,cell2=cell2))
}
table1
}

set.seed(24)
res1 <- example(1:10,3)

set.seed(24)
res2 <- example1(1:10,3)
?identical(res1,res2)
#[1] TRUE

#or
?set.seed(24)
res3 <- t(replicate(3,c(sample(10,1),sample(10,1))))
colnames(res3) <- colnames(res2)
?identical(res2,res3)
#[1] TRUE



A.K.


I have written a lengthy function that conducts a simulated 
mark/recapture study using random numbers. The output from the program 
is a matrix with a single row and nine columns (each column contains the results of a different calculation). Because of the random numbers, 
each time that I run the program, I get a different result. I need to be able to run it a fixed number of times and have all the results in a 
single matrix. I have written a second function that repeats the first 
and combines the results into a single table. Each time that I use that 
line of code, it reruns the first program, generating a new row of data, and combines it with the previous rows. How do I repeat that line 100 
times so that I get a table will 100 rows of data (each row should be 
unique). 

Here is a simplistic example of what I have so far 

example <- function(X){ 
cell1 <- sample(X,1) 
cell2 <- sample(X,1) 
table1 <- cbind(cell1,cell2)} 
table2 <- example(1:10) 
example2 <- function(test){rbind(table2,example(1:10))} 
table2 <- example2(table2) 

Every time that you enter the line table2 <- example2(table2)
 it will add a new line of data to the table, but I don't want to have 
to enter that line 100 times. So how do I get that line/function to 
repeat a specified number of times? 


I have tried both repeat and replicate and neither of them worked. 

Thanks for the help


From r.turner at auckland.ac.nz  Tue Dec  3 10:03:06 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 3 Dec 2013 22:03:06 +1300
Subject: [R] International phonetic symbols in R.
Message-ID: <529D9E4A.3060407@auckland.ac.nz>


This is a very vague and badly formed question. Also long-winded.
My apologies --- it's the best I can do, currently.

The scenario:
=============

I have (unwisely!) agreed to (try to) give some statistical
help/advice to a graduate student in linguistics.  He has sent me a couple
of Excel (yeeeeeuuuuchhhh!) files --- *.xlsx files --- with some data.

Basically, as I understand it so far, the data consist *essentially* of a
"target sound" and the sound actually produced by a (school-age) child who
is trying to make that sound.  (The sounds are from Mandarin Chinese.)

I can read in the *.xlsx file --- sort of --- using read.xls() from the 
gdata
package.  But the result is useless since the sounds are rendered in 
international
phonetic alphabet symbols.  So it is an incomprehensible mess.

Here is a dput() of the head of a file that I read in:

dput(head(E))
structure(list(Test.items. = c("El at f@nt", "", "Vmb\302\243El@",
"", "t\302\243eIn", "swIN"), Initial. = c("", "", "", "", "",
""), X. = c(NA, NA, NA, NA, NA, NA), Medial. = c("l   ", "f",
"m   ", "l", "", ""), X = c(NA, NA, NA, NA, NA, NA), Final. = c("",
"", "", "", "n", "N"), X.1 = c(NA, NA, NA, NA, NA, NA), Vowel. = c(NA,
NA, NA, NA, NA, NA), I.Cluster = c("", "", "", "", "t\302\243",
"sw"), X.2 = c("", "", "", "", "t at w", "s at w"), M.Cluster. = c("",
"", "b\302\243", "", "", ""), X.3 = c("", "", "b@\302\243", "",
"", ""), F.Cluster. = c("nt", "", "", "", "", ""), X.4 = c("nt\302\254",
"", "", "", "", "")), .Names = c("Test.items.", "Initial.", "X.",
"Medial.", "X", "Final.", "X.1", "Vowel.", "I.Cluster", "X.2",
"M.Cluster.", "X.3", "F.Cluster.", "X.4"), row.names = c(NA,
6L), class = "data.frame")

I have attempted to attach a screen shot of what the *.xlsx file looks like
when I try to "open" it with "LibreOffice Calc".  The attachment is actually
a *.png file, but I renamed it "Screenshot.txt" in the hope that the list
software will not then strip off the attachment.  It is not very 
enlightening
anyway.  Be that as it may, I guess if you want to look at it, save it and
rename it "Screenshot.png" --- given that it comes through at all.  Note 
that
column H (now empty) and column I (after the string "F cluster") initially
contained kids' names.  Same name in the two columns.  (Don't ask *me*!!!) I
stripped out these names lest there be some confidentiality issues.

Ill-posed question:
===================

I am totally flummoxed by this mess.  Can anyone give me any
guidance as to how I might proceed so as to get a data frame with
meaningful column names and visible symbols in the columns, such that
I might be able to, e.g., cross-tabulate the "target" and "actual"
columns?

What do I need to do?  Do I need to install a font (or fonts)? Where
do I get them?  How do I install them?  (I am --- still --- running
Fedora 17.  If I have to upgrade to Fedora 18 to get anywhere, I guess
I will bite the bullet and do so.  Hate to mess with a system that is
working comfortably, but.)

I did an RSiteSearch() on "IPA font" which turned up 5 hits, relating
to plotting functions from the phonTools and phonR packages, but they
might as well have been written in Mandarin for all that I understood
of them.

I would be ever-so-humbly grateful for any advice, guidance, recipes,
assistance, whatever.  If more info is needed, I can *try* to provide
it, but I've told pretty well everything that I know at the present
time.

     cheers,

     Rolf Turner
-------------- next part --------------
?PNG


IHDR
3??d????? ?_/0??:?rq??	(???+r	?Q???W?i?????P??F"?b/?ru?
B"????w??N ?n??_??S????N8$?*?i:??????? 
?&????????z???O>??????a3?????H??@?????L???????????}?~;??
??23??
????????s????y???T*?????`l??A?q?


R>?',@5??!$??N???4?????%~????W?????#G??;(m???IMM??????????????????????r?????????555???o????.\?P?q??IV
?C??/??????rrr>???w??=x????K0)
I?????????<w?????O??/????

???????g????????oT
????????W??????j}E? ????or?T?,--??>??3???$??????? ?O?+?3}?`? u?????????+??????3??7?`?????8q????:;?????_????g?|??.J???*
N*?????e?????7F???=???1??*
????ckk?=??

n8AN$??0????@z?J?????n?45??vL}?
B?F?EDD<|?P??h???~?????(????v?????



]?t????????_??????B?????????????r?\}?u???????????????;w?;

;????uww????d?~?A?A

?=?????/_?b???V???fff?;w????????/?`0?
??????G????.\???q??1}?S???Q??
??
?3-????????
???'3??`?????

????^<?w?Th?-?L?!???L??????????un????<<<<??????77l???(t?k? ???.??f??
0,0?????ysx8_?v.???M?a?

w???????A????A[[??/_j??zI?tj???ivt??B*?
?????
?????D#?????w8ZY^^?\~??????y???>??Q??0??m?Bz}s0??"`\40)?r?Juu???`??????
5r??qMy?+Z2v??QZZ?\^\\
??x??iot
??d??

9;;?d2????S$a?U???????({{{//??/j??dUVVz{{[ZZ.[?L!N??W?%??UP??v?l`'?????????????M???V`???H
??Y???7n???;55??????,//????T[[???}??????'N(,?	???x??qMMMgggVV?V;?&.???????}?????q??o2??DGG?MB	???X??P(???-**???)**??????BEDD???


a???;???_VV?=???z?????k???k?.?{??I????B?L???????
:???]]]???D~?	???WQ??Vu6???233;;;?r?F;?
????dsE
?
?fu?????????????[ZZ"?^?~??????fee?
`?X????^B????????!//???T&????{????????s!???>|XPP?T?xB,X ????t???^??{?*_???W??X2Y??{??F]]?????;I?B6?
?
L*W????SK?}?`???/U]?!+j?A?????B???l
?WPPp??Q?C?P?Z[[w??????????????O?????????????>??H?WF
?????i?N????????+?2(
??(--MJJB???c3r?P{{;?????KHH?
GFFVTT0????:?????'O???VUU???`?T??={?l????`xzz-\?p?P??(?D?????}I??????5kT
E{??rt+0?\?l??S?j0??q1??+&?)??b?????o???U.?K?R?%???S???


???=

~???????]?{?3??_&??B(::_,^\\
Of/?q???7o???|l???????%??M??jdN???%K?TUU?^????p?#j5Qs??!_y||???d?h?l??A??W=??x????&D?@?'?!3336?
r??I?)????X,??$rww?v??|???Q?Nss????haa?=mhh?h??c?
qqq??hMMM?f?

??q#qSss??m??????????c''??K??????6???m????A`` ?"Y??AD???/?<y????}l?Kt:??????E???J*?Z[[cO?o8a????ccc??]HfC?T?n&?+2 E
?????00PQQ??_h*f
3??DGG?>}Z (?	??b???666??]ZZ???`ddd???b?q???111aaax
'.,,???+r?\&?]?|???I?}??????????;?L????????7??????O.?_?z?3Y?????????p?dC_T?n??)A?
a2?????~???]?????????OLL???ILL?p8?7
???333??all,?J??e^????%&&r??E????????wq?%???
????agg?p???c?(????mmm?l??ul????????L?????d?a? WS??&D?@h??+???3??}?Dh?r]c?5e??i?tM?}(?AtF?w_1?=
0)
??????xt
/?4??2L?2??)?lL?kZ?BO??M?lO~?????+


?l0===//O?P#???????%c??
????????qqq?????F7
??????G?
?%???w?????!V?????????pqq9s?q???g?/_N??V?X!?r??????,?????????o??U3l?#???p??????????Cll??W??j????????CKK????[###????S?@???N?????KJJ?B
??d2?]??????e2^???)???*NLGGGTT????????????5?K?*++???---?-[????+??	??*(E;Y6?????w???s???|?&Art+0?\M?


???????????R3l??r?999???7o?
g?X?&??Htt4??$??@ ????
???????????????????*?PDDD]]
?2???s???eee?????????]??<1p?v?????w??T*-,,??????:))???C??????MMM???0~?{??hUg#+++33???S.?k?s???
L6W?A?
	?JmiiY?r%V.?JW?Z???????;B????1:?~??uKKK??????????????B,+44?K(
?~???
!???????d2????????q???;w? ??|????uS*N<!,??vvv:??d???????{??z??+?E,?,~??Tg??????g??$M!S?n&?+D??A?????>e0???h???.???? R?E??H$?????g0#WF?P?l6??+((8z?(???P(?
???;w?T?{p??}?i?????~fffuuu__?C?
?+#?m?Nv??F???????????
??`???&%%!????????9B?????z???%$$`?###+**?Lf]]???Mxx???'??????RRR?j*N??={6l??`0<==???.\8a?ZM?D"??????$?GSec??5*????O9??r?H?f?)@5D??h`?????????p?.]?~k&?)??b?????o???U.?K?R?%???S???


???=

~???????]?{?3??_&??B(::_,^\\
Of/?q???7o???|l???????%??M??jdN???%K?TUU?^????p?#j5Qs??!_y||???d?h?l??A??W=??x????&D?@??I???????3''g??	cff?f?CBBN?<?<%????????D?????]???466*?inn???-,,??


?\???#...4???i??Y???7n$njnn??m???????{????t?R>?????U??m[zz?@ ?W$?81??t:????'O<==???u?N?_?z5<<|??VVVR????{?|??	?777#~?B2??zt+0?\?)@M0???P??r>????????????????????+?????K????,???ryCC?Hk??}iiiMMM2????q??}????t
?????00PQQ??_h$`?3??DGG?>}Z (?	??b???666??]ZZ???`ddd???b?q???111aaax
'.,,???+r?\&?]?|???I?}??????????;?L????????7??????O.?_?z?3Y?????????p?dC_T?n??)A?
????mmm??????t??KJJ??????


?\nvv???#?????????ow??E,

??bb???Mbb"?????@EDD????
ccc?T??-[?'.11???.Z???????
???.????x???;;????+?
;F?P??_okk?f??c?,??????d??/=$?
????
???A6??5-p?'P????N?'??a???
???T%??D?
!#00pppP?|pp???????Z=?^2?????A?
?v???7?-h#0
P?A?D????P???*?H?l?0
???????????r???????7O?!}H??????n????????

??q???s?TjXXX{{??
??????G?
?%???w?????!V?????????pqq9s?q???g?/_N??V?X!?r??????,?????????o??U3l?#???p??????????Cll??W??j????????CKK????[###????S?@???N?????KJJ?B
??d2?]??????e2^???)???*NLGGGTT????????????5?K?*++???---?-[????+??	??*(E;Y6?????w???s???|?&Art+0?\M?
&  ???????555???YYYj??U\.7''??????????,?d\
???&???????c?P???[TT???STT???]UU??????????;w??????{????????k?"?'n??]>>>????J????z??WWW'%%
:t??????????????}?????ldeeeffvvv??r?vN2?[????<H
?????????????????YK?R????????[w??????}???`?D"
??mE?????????D????k??!??l?????m
?QQQ????>00??????u4?????????H?TjKK???+?r?T?j????
?fu?????????????[ZZ"?^?~??????fee?
??O??
??????Gyyy???2?????{xxddd
>|???;!>????????????`??Xlgg???N?*??????W??G???^????W?Ku6???|||f?I??1??V`R?B??
?Z??`?P????~<??YQk"?_????????~?PXXX????fk
??f?x?????G?r8

?B?????s?N?]????'??~~~?????gffVWW???a?D???2????d?Lk???????+?2(
??(--MJJB???c3r?P{{;?????KHH?
GFFVTT0????:?????'O???VUU???`?T??={?l????`xzz-\?p?P??(?D?????}I??????5kT
E{??rt+0?\?l??S?j0??q???????????????????L?H$???o???}??V?\.?J??TWO)..nttT(>{?lxx???ccc?w??
R??&~???#???h|?xqqq||<????????y?????zBB??

?H$?6m???91?c?,YRUU?z?????	???D??3?|???q?S??????:?v_??V`??"R??`???<77???stt???eee+V??LXffl6;$$??f+OI=<<?b??;???c_a??477gff.]?


?Y???#...4??????ettt????M???????FWWW???????K?|~[[??m?B??mkmm?????d'?Ng?X?????_??*|:?~?????ZYYI?R????'????\?_2???=??[????H
???Y&??????|???}???????d2Ycc??}??w??DW?
???``?????/??T?:f?
???>}??@ P?"??JMMmll?_???4|+???????????377?????????81paaaW?\???2?????NNN????
<?????w??d????<l??y???}}}r?????????????????'~?C&??bt+?\M	R??`???|??M?O???_?"???c???Z@@@nn??#G


????\nrr2?i???
g????????yzz???%%%mmmnnn???\.W?E??b?
a2?????~???]?????????OLL???ILL?p8?????333??all,?J??e^????%&&r??E????????wq?%???
????agg?p???c?(????mmm?l??ul????????L?????d?a? WS??&D?@h??+###???3??}?Dh?r]c?5e??i?tM?}(?AtF?w_????
X?

[[[%???????w8ZY^^?\~??????y???>??Q??0??m?Bz}s0??"`\43)/--????4?Tzzz^^?B?F.?7?)?qEK??
;JKK????????t?=??n
=?K??????C?VYY???iaa???r?????g?._??F??X?B ???[{{{Y,??????????}???5??????^^^???????^???~GpVVV---??[?n??????bO???;?Fsww/))?
y<
???wrvv??dx????H$?
?810


QQQ???^^^/^?h/??????????\?l?B????K&?????d??N*__??????;W???????4s5-?"
L?O?<????f????7??={6??????K???9
??Y???7n???;55??????,//????T[[???}??????'N(,?	???x??qMMMgggVV?F??.???????}?????q??o2??DGG?MB	???X??P(???-**???)**??????BEDD???


a???;???_VV?=???z?????k???k?.?{??I????B?L???????
:???]]]???D~?	???WQ??Vu6???233;;;?r?F;?
????dsE
?
???6???7~t<*?????r?J?\*??Z????G?Y?w?$??ccct:??????????_??????YYY!?X,Vhh(??P(<~?x}}=B???+55??d?????###????w??A???? ?'????b;;;
?w?W???????W=b???"?L??^??QWW???3?N????)G???"?????RDk??2D at g4??A~??Z{)??????????>?H??p
??f?x?????G?r8

?B?????s?N?]????'??~~~?????gffVWW???a?D???2????d?Lkt:
lmm?/_1???A?PFiiiRRB???<88??#?????????_BB?822?????d??????????<y???>00???*%%????????g??
???3((h??????DI$???K2~4U6??Y??(?????[?)??dk??"
?~?w???>????Fn??b2?"?H,??}{???
[?r?T*%^RM\a<??????Q?P???????/^?????E?7H13??e2?? ?????????????d?b0?/_~??
???f?			|>ppP"?l??	?F?????Y?dIUU????'<?V5g?
??????OI????????}??[????H


?Y???#...4???i??Y???7n$njnn??m???????{????t?R>?????U??m[zz?@ ?W$?81??t:????'O<==???u?N?_?zu??`????R???5?T?v??onn>66F???d6tO??V`??"R??`aX?
D?????0&???/9
Nss?L&???


?"?}?????555?d????}??)?N??y<^???@EE?_|???h??v$::?????@?N?,+55?????????####66{?377?????????81paaaW?\???2?????NNN????
<?????w??d????<l??y???}}}r?????????????????'~?C&??bt+?\M	R??`??I??>&?R@@@nn??#G


????\nrr2?i???
g????????yzz???%%%mmmnnn???\.7;;[7ak??v??d???~????v?"????????11???&11?????x ?"""?????????T*u??-x???????r-Z???Z__???E????x<^FF???]HH?????
?P(??????e??
??MNNNrr2?F??
?????\M	R??`???W0?????}?Dh?r]c?5e??i?tM?}(?AtF?w_1??+
???A6??5-p?'P????N?'??a???
???T%??D?
!#00pppP?|pp???????Z=?^2?????A?
?v???7?-h#0
?-;v?(--U./..????}<@??7?
??d2?]??????e2^???)???*NLGGGTT????????????5?K?*++???---?-[??????	??*(E;Y6?????w???s???|?&Art+0?\M?
??Y???7n???;55??????,//????T[[???}??????'N(,?	???x??qMMMgggVV??ak?????????y????8???7WG?????&!?All,?X(??????eggWUU!?"""???????j??????/++??vuu=?|???H?????k?????{??Riaa?^&????III?
??????njj"????c???
VSu6???233;;;?r?F;?
????dsE
?
=*..vvv??Rggg????`????[????K?/~??)???D
_??_4&?RRR?]????eKJJJHH?I(FEEW>????????T??,?n????G?#?R?---?2\?T?j????
?fu?????????????[ZZ"?^?~??????fee?
`?X????^B????????!//???T&????{????????s!???>|XPP?T?xB,X ????t???^??{?*_???W??X2Y??{??F]]?????;I?B6?
?
L*W????SK?}?`????]?!+j?A?????Y?f9;;????????>?B???l
?WPPp??Q?C?P?Z[[w??????????????O?????????????>??H?WF
?????i?N????????+?2(
??(--MJJB???c3r?P{{;???????
??????`2?uuu666???'O???????JII???81p{????a?????

Z?p???j5Q????f???M??5k??8??????V`??"??)?
?)??????
??g??
?x?bllL?.?cM?3j33??e2?? ?????????????d?b0?/_~??
???f?			|>ppP"?l??	?F?????Y?dIUU????'<?V5g?
??????M?
?1h???G???"
y?????hww???GM}?bff?f?CBB?l??????C,O????;?e???Q?Nsssff???K?1??????u?;???B?????ZZZFGG7n?H??????mlltuu?
;99-]???????m??
!?m????V?@??+??? ???,???????zY?O???^?:?V+++?T??U?]??????+?KF2??zt+0?\?)@M0???PwR??????
q???e???????F?B???????+?????K????,???ryCC?Hk??}iiiMMM2????q??}????t
?????00PQQ??_h*f
3??DGG?>}Z (?tb?X???????k????oe0?????}???111aaax
'.,,???+r?\&?]?|???I?}??????????;?L????????7??????O.?_?z?3Y?????????p?dC_T?n??)A?


????\nrr2?i???
g????????yzz???%%%mmmnnn???\.7;;[1k??v??d???~????v?"????????11???&11?????"?"""?????????T*u??-x???????r-Z???Z__???E????x<^FF???]HH?????
?P(??????e??
??MNNNrr2?F??
?????\M	R??`???????`?~????u????A6??5-p?????}??~<
?????1?d}??Wj???R?8?)|R??2`f????{%??q4/?
??e?v
???A6??5-p?'
?,_

???T%??D?
!#00pppP?|pp???????Z=?^2?????A?
?v???7?-h#0
????XR?j0??qQwRN?????B5N?=???\5LOO???S(??%??5?5?h???cGii?ryqqq\\???????

=?K??????C?VYY???iaa???r?????g?._??F??X?B ???[{{{Y,??????????}?f?G\us??///KKK????W?^???#8+++???b??[?FFF|}}???????F???????`?<
??d??

9;;?d2??????^???????????????????x??F{IVee????????e??T?|?X2a?X??h'?vR????????????$H?n???i??&D??;)?x?B??O??}??'???jn6[?g???f????????|?3k?,?????w?NMM???*++???????6???fgg?:u????????a<<<
?~\SS???????N????rsrr???o??9>>?b??M?????h??I!?@?=
????EEE===EEE???UUU?????????!???s?????????]]]???_?v-Ryb?v?????s??=?TZXX??IyuuuRR??C????????????;a???*
_???FVVVfffgg?\.?h?T!3??l????&D?@??=???t?_e??#?Q??;??????????e?O??V#/?
|?-!D?R????????[w??????}???`?D"
??mE?????????D????k??!??l?????m
?QQQ?^??
???<x???f?????7~t<*?????r??]?/?JW?Z???????;B????1:?~??uKKK??????????????B,+44?K(
?~???
!???????d2????????q???;w? ??|???

??O???b?????;??????w?^??
???{K&?_y/?????????y'IS????[?I?
?{sP`j)"??O@~?h?H?h?dS???dE?=???????w?(s??kt|????W?n??X????\?Ba??<
???????
?B?+??????Sa???????????r??????????}}}???#?>????d?Lkt:
lmm?/_1???A?PFiiiRRB???<88??#?????????_BB?822?????d??????????<y???>00???*%%????????g??
???3((h??????DI$???K2~4U6??Y??(?????[?)??dk??"
?={6<<??????1????)ff?LF??Ptt4?X???8>>??^????o??????L=!!???J$?M?6a?????1K?,???Z?zuaa??G?j????C????8?)???T?P
?V??zt+0?\?)@M0???PwR?W?c??"K7s????kBO_??@Xffl6;$$??f+OI=<<?b??;???c_a??477gff.]?


???????????2::?q?F????f?icc???+????i???|>???m??m?m?????
???@|E????N??X????????e>?N?z??d[????R)?T?v??onn??/?l???????sE?
aaa????
c?/?????477?d2?\????/???o_ZZZSS?L&kll??o???t:??????TTT|??	X???#????O?
wBd?X???????k????oe0?????}???111aaax
'.,,???+r?\&?]?|???I?}??????????;?L????????7??????O.?_?z?3Y?????????p?dC_T?n??)A?
qtt????r???????[?r8???w???~?????????????????9::r????lm?%F?&?Y[[????????X
?????D???D??_?????033#????R??-[??%*N\bb"??]?h???k}}=~]?????xvvv!!!
W>
;v?B??_??????f+\?6Y?999???4
_zH&?r5%H
1

?O&?-?z?????7?uh???~?L???A6??E?????
???T%??D?
!#00pppP?|pp???????Z=?^2?????A?
?v???7?-h#0

?w:Y^^????P~??????y???%??J5?s?@F?Q?
????XR?j0??qQ???+W?\?r?????o????
V???????<?B?\bo\????%c??
????????qqq?????F7
?%???w?????!V?????????pqq9s?q???g?/_N??V?X!?r??P???,?????????o??U3l?#???p??????????Cll??W??j????????CKK????[###????S?@???N?????KJJ?B
??d2?]??????e2^????m????tttDEE???[XXxyy]?xQ??$?????????r??e
q*aJ,?0~???W??e;?|}}????w?\?wo$G?????@?
??Y???7n???;55??????,//????T[[???}??????'N(,?	???x??qMMMgggVV??ak?????????y????8???7WG?????&!?All,?X(??????eggWUU!?"""???????j??????/++??vuu=?|???H?????k?????{??Riaa?^&????III?
??????njj"????c???
VSu6???233;;;?r?F;?
????dsE
?
????
		????/?D)))??]Cm??%%%%$$?$
?????+}``??????*?h~U???????P????|?T*]?jUOO?r???Ix????t????---B?_?vsskkk???B?X???Pl/?Px?????z????Wjj*??|?????GFF???????????>,((@*O<!,??vvv:??d???????{??z??+?E,?,~??Tg??????g??$M!S?n&?+D??A?????>e0???h???~??Z{i?????????f6#WF?P?l6??+((8z?(???P(?
???;w?T?{p??}?i?????~fffuuu__?C?
?+#?m?Nv??F???????????
??`???&%%!????????9B?????z????W?FFFVTT0????:?????'O???VUU???`?T??={?l????`xzz-\?p?P??(?D?????}I??????5kT
E{??rt+0?\?l??S?j0??q????.DDDh?)???Db???????oW?*???R?0q??????FGG?B??g????_?x166?z???????M?2]GB????b??????x2{1???/?y????c3???>??88(?H6m??U#sb`??,Y????j??????
Q???3g???????$?GSeCuZ???????sE?
F?K??????4k??????77577o??
{???????=vrrZ?t)??okk?*l??-==] ?+?U?Dt:
?????'???????D???^?

>?V+++?Tjmm?=U?]??????????w!?
?S=??x????&D?@h??????)?????????^|?1??_~??p???e2?\.ohh?i???/--???I&?566???Oyw:???????***?????F???????O?;!?X??????F??KKK??2??????X?=???<&&&###,,????????]?rE.??d???/;99i??;x?`ZZ?w?}'??:::??y????????????W???b&??????????l?????


????\nrr2?i???
g????????yzz???%%%mmmnnn???\.7;;[??k??v??d???~????v?"????????11???&11?????x ?"""?????????T*u??-x???????r-Z???Z__???E????x<^FF???]HH?????
?P(??????e??
??MNNNrr2?F??
?????\M	R??`???????`?~????u????A6??5-p?????}Ec?)


???S??=M??S??k? ?????(?AtFS'????v`?

?T?
?ME????888?\>88hkk???K?
]/	??A
?U? ???;WH????
?????7o?^??`P?T???dtE??^?
?%E
?????bY[[???
8p????j??q?U7.\??????tpp???}??^??;????rpphii!??ukdd???{*???i4???{II	V????L&????????L&?K<==E"?X???????????????????x??F{IVee????????e??T???X2a?X??h'?vR????????????$H?n???i??&D??;)??a????g?\.??????5k????????lv~~>^?????pf??????qc??????]]]eeeyyy555????????S?N????8qB?c9L@@???????kjj:;;????[??\nNNNww???7???Y,???:

M?7	!$bcc??B?077?????????(;;???
!QWW744?U;w?\YY????????k??E*O??]?|||???'?J?2)???NJJ:t?PwwwuuuSS?}'??^e?o?????????????)??5?9U??n&?+? E
????\????tqvv??Zl
?????u?.]??x???O?2?HD?P?Z!!!????Ec"?(%%???k?-[???????`??BaTT?q??x{{?x?@E
???6???7~t<*?????/??J??V????QnV?
!	?????N?~????%B????nnnmmm?9?b?BCC???B???????B^^^???L&????


??s?B????|????
???{??U??????d????R????:??w?4?lL9??T??7??""X??? :????CV???H?=?\nPPPDD??w?.]?TPP?????j?I?P?l6??+((8z?(???P(?
???;w?T?{p??}?i?????~fffuuu__?C?
?+#?m?Nv??F???????????
??`???&%%!??????????????????~UhdddEE????????	?y?d}}}```UUUJJ
VM?????g??
???gPP???'U???H$???3??d?h?l??RK{??rt+0?\?l??S?j0??qQw?????w????)???F?b2?"?H,??}{???
[?r?T*
& ?0?R\\????P(|???????/???T?B<??;?63??_&??B(::_,^\\
Of/?q???7o???|l???????%??M??jdN???%K?TUU?^????p?#j5Qs??!_y||???d?h?l??A??W=??x????&D?@?;)wrr?p??????b??%?	????f?????l?)????X,?pGwww?? Lcc?r????????K?bc???A#1??1v????F?555??????n??????????????=vrrZ?t)??ok??????&?|q?G??Yw???
h	
???OAw?K?X???qQ
???????k??4Z?+??{]??`P?!????????1*??Z,??]???@h???????s???s??'?9?m?????????V?P??H?ra?h4?U^^~??-?????h???c?utt????K???Z[[[??d$?a|?{?+?"
??db?????????x???H<??YWW?T*
EMM????d?ut???OKK?z??B????P????322????Jecc#?3V?]]]????_?????h??j V???'?D?L?;(?;wn^^??K????????C?l*
???;|?????]]]??????????e??MLLtqq????2335/))ikk?????~~~~NN??<,?!??????????;???????????\._????????!?5d2?T*u??Mx??????????W_yyy????wq1??? >?????????????c
e???...
Gm
?X??????g???
>??L4??j\"

T
????BFHH????f?????????o'??&	?DOj????w??c???q _?dT
}?
?"???????ccc????[?
?d???V????V?L??f??/??:?h????????.\??y???3?_?_???a&??"b?L???RB?v???e?wP~??????O????????UWW?g????j?YboYC^??-??o/--?L/..???7~}??M^?



?O????H$?????????joo?????%????????k?:88,Z?H?????SF???A?'????]T????f??1c???7??[?u?jB D
=???EEE&?WWW???
8p???????????????]E?'Z???????????T*?m?6dz???y"

??y????D?????Z*????'?J?j????/??7????t:]"?P(l/B(,,,!!_4&?HRSSo?????iSjjjXX?K$????<??????k?<y?%?a?w??????
?	?JmiiY?t)?.???-[????Y??B?^?JE??n??????z?????w[[???#B(88??bEDD`G?D???????#?????l6????????/??;t???B????????H???d???R?t???Fh?X???
????????y1e??k
?=????7?4?h????XU???j?-DD0?	h?N??P?x/;f?~??DO
??????(11???6<<???G?W?B?p8
>?_XXx??Q.?K?P?Z[[w???v????c?e
?Y~VVVuuu__? R??5??a?dJ??h????>}??B?B??????)))??????7c#r?P{{;??


JJJ???n?ZQQ?`0jkk??????N?:U__RUU????e?ra?v???f?:????:g??Q?:????d6l??X??G?Ec??Z?2y??w???X?,??C?v???e?w???~??}?????????gg??A
>???`H$?Tz???m????U*?r?????8?x\??????"????W?>}z???J??~?io?bc3??dq
A??????????
E??kjj>~?(??zRR?@ 

??d???????0??1,???Z?|yQQ??g??@M?>?|????K??G?EC{
&???{?+?"
NXX???
????J??Q????~???b?<???YYY.??@CC?A?l|??OOO;;??????????u??w577?/?b????????p?B?@???

?
omm
?!!!??d-?Fc?X????n?2?,|????8?^GGG?\????]??????U?HF2???w???X?!@O?????wP????{????????n??}???????0&:x? ??mnnV(J????????????????P(?bqzz???4??????TTT????Pu62mHll??3g?B???Y,?????{????????<
??db?????????x???H<??YWW?T*
EMM????d?ut???OKK?z??B????P????322????Jecc#?3V?]]]????_?????h??j V???'?D?L?;(????????W?\??x,0H??

???w?????????????????e?.?????????w?effj
^RR??????=???????
?T??,?!??????????;???????????\._????????!?5d2?T*u??Mx??????????W_yyy????wq1??? >?????????????c
e???...
Gm
?X??????g???
>??L4??j\"
??

???1???/??_????_?????????/:?,??Z[[?[[[e2?nU5s?~????D[?n-//?L?p?????g??i?*??X??3??+d???"
=??????Z
J???,((PK4?{??ZVm???}{ii?fzqqq||????o?z7
?t?????^????????o??????P?IE?us??E777&????;<??7?????????BL?{????P`` ?R(????????????`?|>??`??|?????C?P?)~~~???ra`:::bbb\]]??????/]?d?V?UYY?v?Z?E???S??b????2h?D;V4??*00p??Y3f?0|??@?w???XM?
9??
9r???N?:O?}?vbb"?????*+++((?v??????999?O????=y????r???`__????_?v???3;;[??M~~~nnnww??;wFFFX,???K???
?L&??Dyyy'N????9q?DNNNUUB(::??????X??????????a/????
!?R?FEE?r<<<???J?~??I?R?Z????????{??%?N?H$
??
KHH??I$?????7o"?6m???????D111??5?>00?v??'O?h?cX???5??g?kB?R[ZZ?.]?????e?????hk?????W?R?h?[?n988 ?????????????
f?X?Q"???????-???l6??`|????????
:t???!?@??????B????2{?l?T:w?\#?w?wa??
{???\????<??2V?5??
??????
?r?R{????T?R????C)?J?W9P(?????
=??r??>???u??
j?`??&^?AAA?????geeUWW???a"U+_?-?
??)?F???NNN???j
?N??????? ????7o????B?????+((())	???ukEE?????uvv???:u?T}}}HHHUUUjj*?M?????k??5k?t???_hh??9sF???J&?m??A?cI???+Vh9??5?????cE?4k
A??????????
E??kjj>~?(??zRR?@ 

??d???????0??1,???Z?|yQQ??g??@M?>?|????K??G?EC{
&???{?+?"


\VV???SVV?o??o:ecc??p???N?:?9$????J???@"??7o??W?b?f?????~????
{????s=M????igg???4u?????u??w577???c/?b????????p?B?@????e???
?!!!??d-?F?~|x????????1?h???????Q?:::??r'''????G?????J?"~?B2???w???X?!@O??????>??
???-[??_???f????K?n??Q??EFF????3??
<??r???
?R?lhh?'i??????555)
?X????y8?F???????w????&d?
???=s??P(T?"??b??b???????t:???1?L?o???m\\
???????h?0p???uuuJ?R?P??????Of[G???????W?*????8l??1##???O?T666?a1c??????????h?????b5.
l??-[?\nbb????w?}????yxIII[[??????????srr&????B?`0?_?????????
??????????????r?_<B???666???L&?J?n??	O?ra??????????+//???z?..????y<???s????V>
;v?B??^?????????c?????{???????
?????X?B???3???Wp??Wt?~?+a?????k? ????
??????b???
??


???t:
,?D?T? ??8?U#7???????A????A??o?N??M?????52l??u?
i??@????
e?u???????$??.l??y???&????J5?k?Lz?E?
??????
?c233

?
??????e?????????j?????>??&?w



?O????H$?????????joo?????%????????k?:88,Z?H?????SF???A?'????]T????f??1c???7??[?u?jB D
=???EEE&?WWW???
8p???????????????]???a9?G#;;;++???S?T?q????j?6V?A?
>C+,,,!!_4&?HRSSo?????iSjjjXX?K$????<??????k?<y?%?a?w??????
?	?Jmii??????e?????hk?????W?R?h?[?n988 ?????????????
f?X?Q"????????!6??`0?|???????
:?????@ x??iaa!?za??={?T*?;w??;???a???{?j?z??k
EL???Gi?Fmmm@@???$M-??n5V+D???k?}???1???.???Y????sRQ(?????
=??r)
1Ckk??
;??6
?~L?????4??????????????>K??????
;?%S?F???????+f?2(
?N/--MIIA???o???#??????WPP?*t?????????9**???S???!!!UUU???X6-n??]k?????~~~???s?????(?L?a???%Y4^4V?X??,???q{?k????9D
?????g
!?$Y4^4??aR???w???X?!@O????0?o?B666
',,???S?CR___?T??$????y?&>}E,k?inn?????????


???XbC<==???????N?:<<?n?:???????p??X,????????.\(??????????B?0$$????? ??h??/^???????7&???????T????\.wrr?^j?.p??????T*??.$?a|?{?+?"
?)

?nU?o`???????Ydddoo/>??????\.???Y?P(????|?VzzzZZZSS?B?????????h4>?????00PQQ?{?n}?iB?????3g??B?;!?X,6?-???.--
?K??y<
????????????x???H<??YWW?T*
EMM????d?ut???OKK?z??B????P????322????Jecc#?3V?]]]????_?????h??j V???'?D?L??M??M?????
=oRNRppp^^???????722?z?j|???-[?\nbbboo???[ff????%%%l6??????????999$'Q?m??8p???)S?w?@EDD??????????nnn\.??!

???C?k?d2???i?&<E???KNN????H$3f?X?n
~c


???<
??tvv?????{?
;????z????Aooo??????{??nn??={???T*??&?h????? D

??T?XO????T*U?2?6?d6?C???
!#$$dppP3}pp????????zv?d?'5?w??????BZ?8?/a2*???N,???YF?m?????
<?r????Og???b??o???w???DK??d???K?.%&????d2??j???Q?[?n-//OJJRK?p?????g??i?Z?jP?T?????w[D??I?8XJ?
?cD"QTT??s???N?P
u(933???@-? K?-?{XVm???}{ii?fzqqq||????o?z7

b/?B?????????OII	????~??<<<
????'?H?m-???#&&????????????Km%Y???k??uppX?h?Z=50%??Z,??O?cE??g??5c??7o${?????@?
???#x??#G?\???S????o'&&????????????k??a??_????s???????'Oj~-?	???}????k?:;;???u?????????vww??sgdd??b??,?!?????I!?P?d2?m?H???w??????'N???TUU!????kkk?|??e;?|YY????????+W?DZ/???;
=z$?????L2(???NII9p?@wwwuuuSS?cG???????rj?FvvvVVVgg?R?4h??!???Xm????'?D?L????}xPhh(6?E??A??????????...d??????Zl?J?Z?j??????????K:?.?H(
>C+,,,!!_4&?HRSSo?????iSjjjXX?K$????<??????k?<y?%?a?w??????
?	?Jmii??????e?????hk?????W?R?h?[?n988 ?????????????
f?X?Q"????????!6??`0?|???????
:?????@ x??)6WJ???d???R?t???Fh?X???
????????y1e??k
?=????7?4?h????XU???j?-DD0?	h?N??P?x/;f?~??BO-???
333I??5Q(?????
=??r)
1Ckk??
;??6
?~L?????4??????????????>K??????
;?%S?F???????+f?2(
?N/--MIIA???o???#??????WPP?*t?????????9**???S???!!!UUU???X6-n??]k?????~~~???s?????(?L?a???%Y4^4V?X??,???q{?k????9D
<x???677+
?R????O?JOOOKKkjjR(b?8==]?p???????***v???s%M?B{???P?v'D??f??b1??????{?t:??c2???8[[???8
????ra?"##????J?B????qww????n???iiiW?^U(


jq??qcFFF__?R?lll??b?????k}}=?+
2?0-?[
?j\"
?)W?I???B???+?	???yyy??w??????????>[?l?r???????nnn???????????loo????{zz?????Dan,?!???S?L!??!????'''wvv???q?\??PtttNN??!??<~???M??-.999??_"???1c??u?]\?)((????x?????????'?=v?XFF???????9
???~??
?????{?????R?T???d?a? V???'?D?L?u????W&
????0?r]K??f?	?pM?}h?N???w_????
??

2?????P51rC?		

?L

tqqy??????$??I??]3 ???_w?????K???`)??c;~?????buuux????+**?={???????766???a?%?d?????K?[[[e2?nU5s??(??[????'%%??_?pa???3g?4I?~5?T??_Kf??-"V??
,%D
?)???#?1W?\???x????'O???????:????YPP??h?%???=,??dl?????T3???8>>????7y?


????L??w??l????????[KK1????CCC????K?P???cgg???SRR?%??|??????B?????I$l[?????????quu???????t??A[IVee???k


-Z?VO?L?)??????X??.????Y?f??1???????:c5!"
?S?
9??r?N?????};11??fwuu???\?v
?u????????O????<yR?k9Lpp????????]????????CU?&???77??????;###,?eY
???%~LB	?B&??m?D????'N????8q"''???
!

][[???,????????????]]]?_?^?r%?za?v?????#?\^TTd?AyuuuJJ????????????;j???U>??S{4??????:;;?J?A?
????jcE
?
,?J?j????/??7????t:]"?P(|?VXXXBB?hL"??????y!?i???????0l?H$???!?y?????k?>y?DK
???6????;^*?????O??????-????,??
!	o?J???h?n?????????????!

?b?"""??D"???????B???l6??`|????????
:t???!?@??????B????2{?l?T:w?\#?w?wa??
{???\????<??2V?5??
??????
?r??y??W?\????H$***?????
???p?|~aa???G?\.?B!fhmm??c??!???????uPP?f????YYY???}}}?g	??5??a?dJ#??????O_1???A?P?tziiiJJ
B???|?????
!???N|?????U?[?n???`0??????QQQ?N????		???JMM??i?0p?v?Z?f
?N???

?3g??U??@?d?
6?v,??????b?
-g???????Xs?H?f?!@;?D??L??????7???u.??`H$?Tz???m????U*?r??q?????????E"??W?>}?????J???
l????$e2?????ld.?c??????/_^TT4?'5P??O'?ydd???d??x??^?Im??????cE?
?????????y??????.\???????iZ??OOO;;??????????u??w577?/?b????????p?B?@???

?
omm
?!!!??d-?Fc?X????n?2?,|????8?^GGG?\????]??????U?HF2???w???X?!@O?????qP
???
?@?Z??????cbb?\???0>?@7???????c??r????f?B?T*?IZ???iiiMMM
?B,???k
N???|~???@EE???????	YhCbcc??9#
????b??l?X,?????4|/?N??xL&?????6..???EFF?y?\??????:?R?P(jjj???'?????ZZ???W
EGG?Z
6n????????T*?????????Z__O?
?L4LEK?V??
sc?
a0
?2e
?.
??????999??????????vB???999???L&?????6m?S?\??????|?D2c??u???wq1??? >????~??Ggg?????????c?W?


????p8?~?-?w???????????K?Ra?o?????X?B???3???Wp????

+????&?b
?D???8(?'?]???			QQQ??,??Z[[?[[[e2?n??O?d??L??[????k?_?pa???3g?4~?~M,?????n??2?K	
eff?%d??e
y-??dl?????T3???8>>????7y?
?x:?ckoo/??rrr?????o????u??$!???x????????????|??
????stttsskii!&??{whh(00{)
}||???|||JJJ?D>??`0?C>|?????P(?????D?mk?00


111??????????.]2h+????\?v?????E??????
1e??c4?
+?E8k??3f?yc ???Xg?&B???s`?A?_???
;vL?6M??M???p?
9??
9r???N?:O?}?vbb"?????*+++((?v??????999?O????=y????r???`__????_?v???3;;[?
A~~~nnnww??;wFFFX,???K???
?L&??Dyyy'N????9q?DNNNUUB(::??????X??????????a/???^?~?r?J???????3  ???Gr?????$????????twwWWW755??v??c????D?=???YYY???J??????L?Vc??"B???3??'zN??A????$??A>???)S?DEE]?r?d9


?UK?R?}??R?V?Zu???y???|??N?K$
???E???%$$???$Ijj???7B?6mJMM
?v?D???b??gX?v??'O??1,?n???????5?R?---K?.???r??e?zzz4?5~CH???R?h4??[?


B??????nkksttD?X????(?Ht?????z???????f0_?|?????x?
z??BH <}????i?0????=[*???;??
?]??a???{5W=b?5?"??U???G???6  @?F???q{???"??A?????>M??????A?e????????????/IIIS?L??

???p?|~aa???G?\.?B!fhmm??c??!???????uPP?f????YYY???}}}??H???D???
??)?F???NNN???j
?N??????? ????7o????B?????+((())	???ukEE?????uvv???:u?T}}}HHHUUUjj*?M?????k??5k?t???_hh??9sF???J&?m??A?cI???+Vh9??5?????cE?4k
?F???>?,X????j???EEE??qR5}?t??GFF?/I??
?u???k??j?<Vd@?
????J?R|u ??????7??+b?X3Oss?O??doo??lhh????e?
??????kjj?:u?????u???????????b?????vww_?p?@ hkk?2???gff
????|F????F?a?>?x????????h4Zcc?X?Z


?r????R?v??????V?R?w!
?????Xy????'?D?L?u?r???EFF????3??
<??r???
?R?lhh?'i??????555)
?X????y8?F???????w??????6$66???3B?P?N?,??f??b??KKK????t
??d2??q???qqq<
/22?????EFF???)?J?BQSS???>?m
????????^??P(:::???q???????>?R????/???UWW???z?W8d?a*Zz???? D
??A????

???w?????????????????e?.?????????w?effj
^RR??????=???????????????0???????;w?$?GDDddd$'';;;'''s?\??Ptt???
??!???R??6m?S?\????????????????
???1??|
?7w????0????
?P(?W?vqq?p8j????nn??={??????d?a? V???'?D?L?u?
v??+??}?Jj?????Z3???@?&??4A'Fc????>?
??

?????b999yyy?????????
]g?\?x???????????d?{??f?
?9::?????????;44??
?>>>vvv>>>%%%X"??g0?!>|???P(x????D"???\??????WWW{{{?K?.??dUVV?]????a??Ej??????2j??????
??
?5k??3??1???j?3V!@O???90??<666&&f??=???###:?0m?4?s??<???#\.w???x?????lvWWWYYYAA??k??]??_???9}?too???'5??????>????k??????:T?h???sss??????322?b??]?????X??$??P(d2???H$???;q?DOO??'rrr???B??????>|??????????{????????+W"?n????
=???EEE&?WWW???
8p???????????????]???a9?G#;;;++???S?T?q????j?6V?A?
,?J?j????/??7????t:]"?P(|?VXXXBB?hL"??????y!?i???????0l?H$???!?y?????k?>y?DK
???6????;^*?????O??????-????,??
!	o?J???h?n?rpp@???????????!

?b?"""??D"???????B???l6??`|????????
:t???!?@??????B????2{?l?T:w?\#?w?wa??
{???\????<??2V?5??
??????
?r??y??S?N???`????????P(
???
=z???R(b????
;v?
?m<~??xYi???????U]]????}?P+_?ov?K?4??o;99??W??!dP(:?^ZZ????*//??y36"G??????? |U???[+**Fmm???sTT??S????CBB???RSS?lZ.??]???YC?????BCC???3jU'5P2?l??
?
K??h?h?X?B?Y&????n5?
+??Ys?
?????gV?F??h?hh???6_{?Vc??"B???3a?A???G;;;????????????C???
??	?p8?CR___?T:??>>>??A?X?????9++k???Xhhh????e?
??????kjjjii

^?n
qWss3?R,{yya????.mmm?????????V?P???ra?h4?U^^~??-?????h???c?utt????K???Z[[[??d$?a|?{?+?"
????????
????????}????-Z??7??S??????^|?1????\nss?B?P*?


?$?????????&?B!????5??h|>???``???b???????,?!???g??
?j??X,?????{????????<
??db?????????x???H<??YWW?T*
EMM????d?ut???OKK?z??B????P????322????Jecc#?3V?]]]????_?????h??j V???'?D?L?8?\?&?CCC???
?~|??Mx????????/?Hf???n?:?..????y<????????????
;v,##c?????????
??o????U????={?tuu?T*??M2?0?qA?
?x?
?w_??Z?k)????1!?	???
?
T
????BFHH????f?????????o'??&	?DOj????w??c???q _?dT
????&44????#??x?????O?>??o~?c???7N?d?L????t?Rbbkk?L&???f?z
e?u???????$??.l??y???&????J5?k?Lz?E?
??????
1[ee????????????g????;?x?b;;?%K??B<??;Too/??rrr?????o????u???"???x????????????|??
????stttsskii!&??{whh(00{)
}||???|||JJJ?D>??`0?C>|?????P(?????D?mk?00


111??????????.]2h+????\?v?????E??????)1e??c4?
+?E8k??3f?yc ???Xg?&B???s`?A??G????v??YXX?T*u(d??i
???#x??#G?\???S????o'&&????????????k??a??_????s???????'Oj~-?	???}????k?:;;???u?????????vww??sgdd??b??,?!?????I!?P?d2?m?H???w??????'N???TUU!????kkk?|??e;?|YY????????+W?DZ/???;
=z$?????L2(???NII9p?@wwwuuuSS?cG???????rj?FvvvVVVgg?n?T7dz???y"


?&?`???

???
?S?N??g?r<<<?????R?V?Zu???y???|??N?K$
????
KHH??I$?????7o"?6m???????D111??5?>00?v??'O?h?cX???5??g?kB?R[ZZ?i?r?|??e===???!$??U?T4???[????{{{???9::"????Y,VDDv?H$:~?x}}=B?????f3?/_?????x?C?=x?
???GS????Q??Q[[?{#IS????[?U?
??????BDs??&?D?h??????cV?G:/?
?????L???
B(!!!%%E?r(
????????G?
?r?
?????u??
j?`??&^?AAA?????geeUWW???a"U+_?ov?K?4??o;99??W??!dP(:?^ZZ?]????7o?F????v????
??ukEE?????uvv???:u?T}}}HHHUUUjj*?M?????k??5k?t???_hh??9sF???J&?m??A?cI???+Vh9??5?????cE?4k
???H$R???????mS??T*?r?'??q????D?W?^}?????7*?J?!?sM?1z???m??? ?bcc??????			d????555?~?H=))I ?d????c??\???TUU-_????h?3Nj??O?N>????%?????????|??[????
??	?p8?CR___?T:??>>>??A?X?????9++k???Xhhh????e?
??????kjjjii

^?n
qWss3?R,{yya????.mmm?????????V?P??H?ra?h4?U^^~??-?????h???c?utt????K???Z[[[??d$?a|?{?+?"
????????
???????????{?n
??/??Mdddoo/>??????\.???Y?P(????|?VzzzZZZSS?B?????????h4>?????00PQQ?{?n}?iB?????3g??B?;!?X,6?-????x:?????L&?{???m\\
???????h?0p???uuuJ?R?P??????Of[G???????W?*????8l??1##???O?T666????????Z__O?
?L4LEK?V??
???
X?!C?j?32
?v??FX???(?1S1&>,D????O?C??b?@qS
?b??7???^(??????A??
?IDAT?=??{????????Sw???H$????F?b??A???????d2YWWWxx?B??v	!YYY????OC?T?{????T?b???d2?J???t????7o
]????j?R??????????K??]?v??????GGG???U?V???????"//????h42?o????C?F?????M??P??+V????%?5]?S??????e??\hD?4v_}??c?
??
???
? \?DO?B#????????9??
>??C?a??8?"|$''???s????CBB?={????$ ?^?
?5;?o??o????p?G?S????
9?PRRR????:??d?v?w?}?????3????????1????????nUI????????K?????_o?~???????????T?B????%7i?
+??O	?yhD?Y?|R^WW???3?c?J?iiiV????d??
&?v?b?Y???J??????
;?M?|??????_
p>??n
?m??`<z?(;;;,,????!!????v?%_????3gN@@??~hRN????!??d??D;\4??j???&L7n???7????w??"?????
8?S???0}?t?$???;r?|???4e???
?b???4???k??-,,???>q???
;.]????r?Jyy???{zz????},?HJJ??????_/]????UVVfEQ?F?RUTT<~????[o??)((??<?"999??I??F#?J??????????????'???+//???!?deei???/_2??????w??	?eww???9{?lb???V?\9w??{?????????%??????7???>~??????????C???]e??????QVV?m????.??`?????u???X????????????JIIa???<????6l??y??I?x?g????]???2????s?&O???o???b?N'?????5k??Ic:?.???????????????????????f??{?/^??3???f??]m????^??D(??y??????9s??'O??u~Ex??5?"??????????;::???#00????TPP????
U]]?{????zBHBBBaa?D"y??mll?R???u???@??????????C??4 'Nlmm


uB}?{,X??_pg=2??G?S?+??(???j?s???????Dc??m??bE?}8????a?p???????N}_?={?z??---????{?\?@.????={?|??7
?B ?3????X???f??????:11?{????m?????>}???.ar~.v??og???D"?

??W??"|?X|????7B???????
9!??????+11??
]?t???g%?V?
^?d????????kjj????lfnj??u?|??X,???OIIy????,?C????`????Y~2R4>??#3Wq\?Gl?&?9V<???!0?<?????9s&++???H$?N???z???e????5???,??#Z?z???`uu????>00??_?F????eqel??3???q!????????^?f
???b????_?zUYY?????__YY??????????2???????????f??Y{??
??
???c?g~??
?%?????a?????m??c?B`#4"pv~R~???1c?DGG?x
?\???~??n?466?????d???iii??W?y??????eCC???uO?Hdd???_SS?????????????x?b?ecccTT?=e??>??????????x?????F???LG$??1?D"??Cggg||<????D"??k?L??{{{????????,?????hd?w?
?3??Mxy??@?
?R`???????
:tH?????XPPPXX???H????"?W,+?J?T?|???????*????L????Aeff????^???)S?8??C??eKQQ????z??G?L??p??????O??k????????V__?~??'?b?u?@?F?????M??S4???"..?NeVRR?????????????0?J?????Z?h?B?X?vmHH???^RR?=???#


???*??????v??D"?r???V?\?N???(..??d???2?L?P?_<!YYY>>>?OC?T*
SSSi?????d*?j??IQQQ???tgJLLT??J?2444==?d???]?A\\\HH?\.7??6\?+**????????C>?p???"
? \??+??FNc??W
?N9
?n9B

From Cynthia.Tedore at biol.lu.se  Tue Dec  3 10:43:09 2013
From: Cynthia.Tedore at biol.lu.se (Cynthia Tedore)
Date: Tue, 3 Dec 2013 10:43:09 +0100
Subject: [R] R lmer debugging: Error in [[<-.data.frame(*tmp*, i,
 value = integer(0)) : replacement has 0 rows, data has 117
Message-ID: <CAEB9s5ZvfH3KN3naAXr7TOLSDMAVCH2SBRVvBffmsBjM8ntmUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/8874d4fb/attachment.pl>

From careyshan at gmail.com  Tue Dec  3 10:52:59 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 3 Dec 2013 09:52:59 +0000
Subject: [R] What is the easiest way to interpolate vertical values on a
 square section of a nearly-planar 3D surface
In-Reply-To: <1386043350.1849.YahooMailNeo@web121005.mail.ne1.yahoo.com>
References: <1386043350.1849.YahooMailNeo@web121005.mail.ne1.yahoo.com>
Message-ID: <CA+jRDxCgj2_ECRz=Q8XJCr7EnWRGUPB33vF6t3s_b1kBAF4=Fg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/53f432a5/attachment.pl>

From kridox at ymail.com  Tue Dec  3 11:25:23 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 3 Dec 2013 19:25:23 +0900
Subject: [R] R lmer debugging: Error in [[<-.data.frame(*tmp*, i,
 value = integer(0)) : replacement has 0 rows, data has 117
In-Reply-To: <CAEB9s5ZvfH3KN3naAXr7TOLSDMAVCH2SBRVvBffmsBjM8ntmUQ@mail.gmail.com>
References: <CAEB9s5ZvfH3KN3naAXr7TOLSDMAVCH2SBRVvBffmsBjM8ntmUQ@mail.gmail.com>
Message-ID: <CAAcyNCw3wn+5qKXAnbs9LVr16X-en4FZ-kcC+vDG2W7im9Mupw@mail.gmail.com>

Hello,

I get a result if I change 'as.factor(males)' to 'males'.

Hope this helps,
Pascal

On 3 December 2013 18:43, Cynthia Tedore <Cynthia.Tedore at biol.lu.se> wrote:
> I am able to use lmer on an older computer without this error, but the new
> version (downloaded yesterday) gives me this error message:
>
> Error in [[<-.data.frame(*tmp*, i, value = integer(0)) : replacement has 0
> rows, data has 117
>
> in response to this function:
>
> model1<-lmer(threatened~as.numeric(focal.chel)+as.numeric(opponent.chel)+(1|as.factor(males)),na.action=na.omit,data=spiders)
>
> I would really like to be able to use the newer version, as I've read that
> it has fewer problems with false convergence than older versions. Any help
> anyone can offer as to how to get this to run without the above error would
> be greatly appreciated.
>
> My data can be found here:
> https://dl.dropboxusercontent.com/u/16881915/Rfile.txt
>
> Thanks!!!
> Cynthia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From gunter.berton at gene.com  Tue Dec  3 11:25:35 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 3 Dec 2013 02:25:35 -0800
Subject: [R] repeating a function and combining the results
In-Reply-To: <1386049928.30602.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1386049928.30602.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CACk-te1DazikA3X6=sjau+imWsHmen=5BFyesaQyFLgfCJxigg@mail.gmail.com>

Arun has given you a number of ways to do what you (seem to) want. If
this is fast enough, then you're done.

If not, then the key to speeding things up is to do things
differently. Note that a 1 x 9 matrix is a just a vector. Since each
element of the vector is a "different computation", apparently
independent of the others, what you want to do is vectorize the
computation to calculate the whole column, not just a single value.
Whether and how you do this depends on the specific nature of the
computation, of course.

Cheers,
Bert

On Mon, Dec 2, 2013 at 9:52 PM, arun <smartpink111 at yahoo.com> wrote:
> HI,
> May be this helps:
>
> example <- function(X,n){
> lst1 <- list()
> for(i in 1:n){
> cell1 <- sample(X,1)
> cell2 <- sample(X,1)
> table1 <- cbind(cell1,cell2)
> lst1[[i]] <- table1
> }
> do.call(rbind,lst1)
> }
>
> #or
>
>
> example1 <- function(X,n){
> table1 <- vector()
> for(i in 1:n){
> cell1 <- sample(X,1)
> cell2 <- sample(X,1)
> table1 <- rbind(table1,c(cell1=cell1,cell2=cell2))
> }
> table1
> }
>
> set.seed(24)
> res1 <- example(1:10,3)
>
> set.seed(24)
> res2 <- example1(1:10,3)
>  identical(res1,res2)
> #[1] TRUE
>
> #or
>  set.seed(24)
> res3 <- t(replicate(3,c(sample(10,1),sample(10,1))))
> colnames(res3) <- colnames(res2)
>  identical(res2,res3)
> #[1] TRUE
>
>
>
> A.K.
>
>
> I have written a lengthy function that conducts a simulated
> mark/recapture study using random numbers. The output from the program
> is a matrix with a single row and nine columns (each column contains the results of a different calculation). Because of the random numbers,
> each time that I run the program, I get a different result. I need to be able to run it a fixed number of times and have all the results in a
> single matrix. I have written a second function that repeats the first
> and combines the results into a single table. Each time that I use that
> line of code, it reruns the first program, generating a new row of data, and combines it with the previous rows. How do I repeat that line 100
> times so that I get a table will 100 rows of data (each row should be
> unique).
>
> Here is a simplistic example of what I have so far
>
> example <- function(X){
> cell1 <- sample(X,1)
> cell2 <- sample(X,1)
> table1 <- cbind(cell1,cell2)}
> table2 <- example(1:10)
> example2 <- function(test){rbind(table2,example(1:10))}
> table2 <- example2(table2)
>
> Every time that you enter the line table2 <- example2(table2)
>  it will add a new line of data to the table, but I don't want to have
> to enter that line 100 times. So how do I get that line/function to
> repeat a specified number of times?
>
>
> I have tried both repeat and replicate and neither of them worked.
>
> Thanks for the help
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From olivier.crouzet at univ-nantes.fr  Tue Dec  3 11:49:02 2013
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Tue, 3 Dec 2013 11:49:02 +0100
Subject: [R] International phonetic symbols in R.
In-Reply-To: <529D9E4A.3060407@auckland.ac.nz>
References: <529D9E4A.3060407@auckland.ac.nz>
Message-ID: <20131203114902.dce79e93adc6d1164327aff6@univ-nantes.fr>

Dear Rolf,

I've started trying to understand your issue but it may take me some
time as I'm rather busy within the next few days. However, if you can
put the screen capture on an external web site, that would be great as
it would help decipher what kind of system the student used for
representing IPA characters as my first investigations on your data
lead me to assume he/she (or you when reading the data) may not use an
adequate unicode encoding... But depending on what the data actually
look like, it would help locating the issue...

Anyway, that is something "standard" in R. I use these fonts regularly
within R so I'll help you as much as I can and obviously you do not
need to upgrade your distrib.

Olivier.



-- 
  Olivier Crouzet, PhD
  Laboratoire de Linguistique -- EA3827
  Universit? de Nantes
  Chemin de la Censive du Tertre - BP 81227
  44312 Nantes cedex 3
  France

     phone:        (+33) 02 40 14 14 05 (lab.)
                   (+33) 02 40 14 14 36 (office)
     fax:          (+33) 02 40 14 13 27
     e-mail:       olivier.crouzet at univ-nantes.fr
 		
  http://www.lling.univ-nantes.fr/


From mbressan at arpa.veneto.it  Tue Dec  3 12:15:58 2013
From: mbressan at arpa.veneto.it (mbressan at arpa.veneto.it)
Date: Tue, 3 Dec 2013 12:15:58 +0100 (CET)
Subject: [R] interpretation of MDS plot in random forest
In-Reply-To: <700701132a38208cfeeb08ebd3cb4888.squirrel@89.96.234.216>
References: <529C7012.2000507@arpa.veneto.it>
	<D5FA03935F7418419332B61CA255F65FA5B8B32D6E@USCTMXP51012.merck.com>
	<700701132a38208cfeeb08ebd3cb4888.squirrel@89.96.234.216>
Message-ID: <54568.192.168.101.5.1386069358.squirrel@mailbe>

sorry, in fact it was a trivial question!

by just peeping into the function I've worked out this simple solution:

MDSplot(iris.rf, iris$Species)
legend("topleft", legend=levels(iris$Species), fill=brewer.pal(3, "Set1"))

thank you

> thanks andy
>
> it's a real honour form me to get a reply by you;
> I'm still a bit faraway from a proper grasp of the purpose of the plot...
>
> may I ask you for a more technical (trivial) issue?
> is it possible to add a legend in the MDS plot?
> my problem is to link the color points in the chart to the factor that was
> used as response to train rf, how to?
>
> best
>
> max
>
>> Yes, that's part of the intention anyway.  One can also use them to do
>> clustering.
>>
>> Best,
>> Andy
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Massimo Bressan
>> Sent: Monday, December 02, 2013 6:34 AM
>> To: r-help at r-project.org
>> Subject: [R] interpretation of MDS plot in random forest
>>
>> Given this general example:
>>
>> set.seed(1)
>>
>> data(iris)
>>
>> iris.rf <- randomForest(Species ~ ., iris, proximity=TRUE,
>> keep.forest=TRUE)
>>
>> #varImpPlot(iris.rf)
>>
>> #varUsed(iris.rf)
>>
>> MDSplot(iris.rf, iris$Species)
>>
>> I???ve been reading the documentation about random forest (at best of my
>> -
>> poor - knowledge) but I???m in trouble with the correct interpretation
>> of
>> the MDS plot and I hope someone can give me some clues
>>
>> What is intended for ???the scaling coordinates of the proximity
>> matrix????
>>
>>
>> I think to understand that the objective is here to present the distance
>> among species in a parsimonious and visual way (of lower dimensionality)
>>
>> Is therefore a parallelism to what are intended the principal components
>> in a classical PCA?
>>
>> Are the scaling coordinates DIM 1 and DIM2 the eigenvectors of the
>> proximity matrix?
>>
>> If that is correct, how would you find the eigenvalues for that
>> eigenvectors? And what are the eigenvalues repreenting?
>>
>>
>> What are saying these two dimensions in the plot about the different
>> iris species? Their relative distance in terms of proximity within the
>> space DIM1 and DIM2?
>>
>> How to choose for the k parameter (number of dimensions for the scaling
>> coordinates)?
>>
>> And finally how would you explain the plot in simple terms?
>>
>> Thank you for any feedback
>> Best regards
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> Notice:  This e-mail message, together with any attachments, contains
>> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
>> New Jersey, USA 08889), and/or its affiliates Direct contact information
>> for affiliates is available at
>> http://www.merck.com/contact/contacts.html) that may be confidential,
>> proprietary copyrighted and/or legally privileged. It is intended solely
>> for the use of the individual or entity named on this message. If you
>> are
>> not the intended recipient, and have received this message in error,
>> please notify us immediately by reply e-mail and then delete it from
>> your system.
>>
>
>


From tcmuigai at gmail.com  Tue Dec  3 12:42:42 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Tue, 3 Dec 2013 14:42:42 +0300
Subject: [R] purpose of the set.seed(function)
Message-ID: <CAAJc=rO0oZwBpVEDo3kkA486yiK1+wGGPVyy8Cb9eJ1X3vXx-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/3498a017/attachment.pl>

From spyqqqdia at yahoo.com  Tue Dec  3 13:24:51 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Tue, 3 Dec 2013 20:24:51 +0800 (SGT)
Subject: [R] triangular matrix inverse
Message-ID: <1386073491.81775.YahooMailNeo@web193402.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/6b4b153b/attachment.pl>

From Martyn.Byng at nag.co.uk  Tue Dec  3 13:37:33 2013
From: Martyn.Byng at nag.co.uk (Martyn Byng)
Date: Tue, 3 Dec 2013 12:37:33 -0000
Subject: [R] triangular matrix inverse
References: <1386073491.81775.YahooMailNeo@web193402.mail.sg3.yahoo.com>
Message-ID: <49E76DF37649DC48A4CE882BC8CE51C9034FDD66@nagmail2.nag.co.uk>

Hi,

backsolve() is probably what you are looking for.

Martyn

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Meyer
Sent: 03 December 2013 12:25
To: r-help at r-project.org
Subject: [R] triangular matrix inverse

Greetings,
?
is there an algorithm which computes the inverse of a triangular matrix while being aware of its triangular form?
?
I know about solve() but this is probably not efficient on a triangular matrix.
?
Thanks,

Michael Meyer
	[[alternative HTML version deleted]]

________________________________________________________________________
The Numerical Algorithms Group Ltd is a company registered in England
and Wales with company number 1249803. The registered office is:
Wilkinson House, Jordan Hill Road, Oxford OX2 8DR, United Kingdom.

This e-mail has been scanned for all viruses by Star. Th...{{dropped:4}}


From highstat at highstat.com  Tue Dec  3 13:57:58 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 03 Dec 2013 12:57:58 +0000
Subject: [R] Stats course in Coimbra, Portugal
Message-ID: <529DD556.7050505@highstat.com>

There are a few remaining places on the following course:

Data exploration, regression, GLM and GAM with introduction to R

When:  3 - 7 February, 2014
Where: University of Coimbra, Coimbra, Portugal

Further information: http://www.highstat.com/statscourse.htm
Flyer: http://www.highstat.com/Courses/Flyer2014FebCoimbraV2.pdf

Kind regards,

Alain Zuur



-- 
Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007)
2. Mixed effects models and extensions in ecology with R (2009)
3. A Beginner's Guide to R (2009)
4. Zero Inflated Models and GLMM with R (2012)
5. A Beginner's Guide to GAM (2012)
6. A Beginner's Guide to GLM and GLMM (2013)

Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From carl at witthoft.com  Tue Dec  3 14:03:44 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Tue, 3 Dec 2013 05:03:44 -0800 (PST)
Subject: [R] Any R packages support conversion from PDF to XLS ?
In-Reply-To: <1386062759767-4681545.post@n4.nabble.com>
References: <1386062759767-4681545.post@n4.nabble.com>
Message-ID: <1386075824455-4681558.post@n4.nabble.com>

Pretty much nothing can convert arbitrary PDF files to unicode.  It depends a
lot on what is in the PDF to begin with -- properly encoded text or just
bitmapped images, for example.  
I would recommend you search around to see whether  there's a related
archive in a different format.
And in any case, this has nothing to do with "XLS" , as Excel can read any
unicode file.


woof wrote
> Hi!
> Is there any packages support conversion from PDF to XLS ? 
> My raw data is from government website with PDF format only and updated
> every month around hundreds files, so I need automated conversion.
> The PDF is composed with Asian characters so I hope the packages could
> process unicode content.
> 
> Thank you!
> Woof





--
View this message in context: http://r.789695.n4.nabble.com/Any-R-packages-support-conversion-from-PDF-to-XLS-tp4681545p4681558.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Tue Dec  3 14:05:01 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Tue, 3 Dec 2013 05:05:01 -0800 (PST)
Subject: [R] purpose of the set.seed(function)
In-Reply-To: <CAAJc=rO0oZwBpVEDo3kkA486yiK1+wGGPVyy8Cb9eJ1X3vXx-w@mail.gmail.com>
References: <CAAJc=rO0oZwBpVEDo3kkA486yiK1+wGGPVyy8Cb9eJ1X3vXx-w@mail.gmail.com>
Message-ID: <1386075901826-4681559.post@n4.nabble.com>

Seriously?  
You should be ashamed of yourself for even considering posting a question
like this.


Charles Thuo wrote
> what is the purpose of the subject function
> 
> Charles
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/purpose-of-the-set-seed-function-tp4681554p4681559.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Tue Dec  3 14:12:26 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 03 Dec 2013 08:12:26 -0500
Subject: [R] purpose of the set.seed(function)
In-Reply-To: <CAAJc=rO0oZwBpVEDo3kkA486yiK1+wGGPVyy8Cb9eJ1X3vXx-w@mail.gmail.com>
References: <CAAJc=rO0oZwBpVEDo3kkA486yiK1+wGGPVyy8Cb9eJ1X3vXx-w@mail.gmail.com>
Message-ID: <4520b879-e68a-4a23-9051-6f060606be42@email.android.com>

To start a random sequence that can be reproduced later. The particular seed value used should not be important unless either the random number generator or the computations that use the random numbers are flawed.

?set.seed

http://en.m.wikipedia.org/wiki/Pseudorandom_number_generator

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Charles Thuo <tcmuigai at gmail.com> wrote:
>what is the purpose of the subject function
>
>Charles
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jttkim at googlemail.com  Tue Dec  3 15:14:22 2013
From: jttkim at googlemail.com (Jan Kim)
Date: Tue, 3 Dec 2013 14:14:22 +0000
Subject: [R] purpose of the set.seed(function)
In-Reply-To: <CAAJc=rO0oZwBpVEDo3kkA486yiK1+wGGPVyy8Cb9eJ1X3vXx-w@mail.gmail.com>
References: <CAAJc=rO0oZwBpVEDo3kkA486yiK1+wGGPVyy8Cb9eJ1X3vXx-w@mail.gmail.com>
Message-ID: <20131203141421.GB24704@LIN-2F308X1.iah.ac.uk>

On Tue, Dec 03, 2013 at 02:42:42PM +0300, Charles Thuo wrote:
> what is the purpose of the subject function

please see rule #6 of "Ten Simple Rules for Reproducible Computational
Research" [Sandve et.al., PLoS Comput Biol 9(10): e1003285
doi:10.1371/journal.pcbi.1003285]

Can't resist this opportunity to spread the word about this article.

Best regards, Jan

> Charles
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
 +- Jan T. Kim -------------------------------------------------------+
 |             email: jttkim at gmail.com                                |
 |             WWW:   http://www.jtkim.dreamhosters.com/              |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*


From mbressan at arpa.veneto.it  Tue Dec  3 14:27:54 2013
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Tue, 03 Dec 2013 14:27:54 +0100
Subject: [R] interpretation of MDS plot in random forest
In-Reply-To: <54568.192.168.101.5.1386069358.squirrel@mailbe>
References: <529C7012.2000507@arpa.veneto.it>
	<D5FA03935F7418419332B61CA255F65FA5B8B32D6E@USCTMXP51012.merck.com>
	<700701132a38208cfeeb08ebd3cb4888.squirrel@89.96.234.216>
	<54568.192.168.101.5.1386069358.squirrel@mailbe>
Message-ID: <529DDC5A.1090703@arpa.veneto.it>

here it is an amended (more general) version

library(randomForest)
set.seed(1)
data(iris)
iris.rf <- randomForest(Species ~ ., iris, proximity=TRUE, keep.forest=TRUE)

x<-MDSplot(iris.rf, iris$Species)
#add legend
legend("topleft", legend=levels(iris.rf$predicted), 
fill=brewer.pal(length(levels(iris.rf$predicted)), "Set1"))
#str(x)
# need to identify points?
text(x$points,labels=attr(x$points,"dimnames")[[1]], cex=0.5)

bye

m


Il 03/12/2013 12:15, mbressan at arpa.veneto.it ha scritto:
> sorry, in fact it was a trivial question!
>
> by just peeping into the function I've worked out this simple solution:
>
> MDSplot(iris.rf, iris$Species)
> legend("topleft", legend=levels(iris$Species), fill=brewer.pal(3, "Set1"))
>
> thank you
>
>> thanks andy
>>
>> it's a real honour form me to get a reply by you;
>> I'm still a bit faraway from a proper grasp of the purpose of the plot...
>>
>> may I ask you for a more technical (trivial) issue?
>> is it possible to add a legend in the MDS plot?
>> my problem is to link the color points in the chart to the factor that was
>> used as response to train rf, how to?
>>
>> best
>>
>> max
>>
>>> Yes, that's part of the intention anyway.  One can also use them to do
>>> clustering.
>>>
>>> Best,
>>> Andy
>>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>>> On Behalf Of Massimo Bressan
>>> Sent: Monday, December 02, 2013 6:34 AM
>>> To: r-help at r-project.org
>>> Subject: [R] interpretation of MDS plot in random forest
>>>
>>> Given this general example:
>>>
>>> set.seed(1)
>>>
>>> data(iris)
>>>
>>> iris.rf <- randomForest(Species ~ ., iris, proximity=TRUE,
>>> keep.forest=TRUE)
>>>
>>> #varImpPlot(iris.rf)
>>>
>>> #varUsed(iris.rf)
>>>
>>> MDSplot(iris.rf, iris$Species)
>>>
>>> I???ve been reading the documentation about random forest (at best of my
>>> -
>>> poor - knowledge) but I???m in trouble with the correct interpretation
>>> of
>>> the MDS plot and I hope someone can give me some clues
>>>
>>> What is intended for ???the scaling coordinates of the proximity
>>> matrix????
>>>
>>>
>>> I think to understand that the objective is here to present the distance
>>> among species in a parsimonious and visual way (of lower dimensionality)
>>>
>>> Is therefore a parallelism to what are intended the principal components
>>> in a classical PCA?
>>>
>>> Are the scaling coordinates DIM 1 and DIM2 the eigenvectors of the
>>> proximity matrix?
>>>
>>> If that is correct, how would you find the eigenvalues for that
>>> eigenvectors? And what are the eigenvalues repreenting?
>>>
>>>
>>> What are saying these two dimensions in the plot about the different
>>> iris species? Their relative distance in terms of proximity within the
>>> space DIM1 and DIM2?
>>>
>>> How to choose for the k parameter (number of dimensions for the scaling
>>> coordinates)?
>>>
>>> And finally how would you explain the plot in simple terms?
>>>
>>> Thank you for any feedback
>>> Best regards
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> Notice:  This e-mail message, together with any attachments, contains
>>> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
>>> New Jersey, USA 08889), and/or its affiliates Direct contact information
>>> for affiliates is available at
>>> http://www.merck.com/contact/contacts.html) that may be confidential,
>>> proprietary copyrighted and/or legally privileged. It is intended solely
>>> for the use of the individual or entity named on this message. If you
>>> are
>>> not the intended recipient, and have received this message in error,
>>> please notify us immediately by reply e-mail and then delete it from
>>> your system.
>>>
>>
>
>


From h.wickham at gmail.com  Tue Dec  3 14:37:28 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 3 Dec 2013 07:37:28 -0600
Subject: [R] ifelse -does it "manage the indexing"?
In-Reply-To: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>
References: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>
Message-ID: <CABdHhvH92Y35sFdFfiFvAEa7v_N18UEyMgbtNj-6M+5gFrj0sw@mail.gmail.com>

A better solution to this problem is to use character indexing:

x <- c("Tuesday", "Thursday", "Sunday")
c(Monday = 1, Tuesday = 2, Wednesday = 3, Thursday = 4, Friday = 5,
Saturday = 6, Sunday = 7)[x]

http://adv-r.had.co.nz/Subsetting.html#lookup-tables-character-subsetting

Hadley

On Mon, Dec 2, 2013 at 6:33 PM, Bill <william108 at gmail.com> wrote:
> ifelse ((day_of_week == "Monday"),1,
>   ifelse ((day_of_week == "Tuesday"),2,
>   ifelse ((day_of_week == "Wednesday"),3,
>   ifelse ((day_of_week == "Thursday"),4,
>   ifelse ((day_of_week == "Friday"),5,
>   ifelse ((day_of_week == "Saturday"),6,7)))))))
>
>
>   In code like the above, day_of_week is a vector and so day_of_week ==
> "Monday" will result in a boolean vector. Suppose day_of_week is Monday,
> Thursday, Friday, Tuesday. So day_of_week == "Monday" will be
> True,False,False,False. I think that ifelse will test the first element and
> it will generate a 1. At this point it will not have run day_of_week ==
> "Tuesday" yet. Then it will test the second element of day_of_week and it
> will be false and this will cause it to evaluate day_of_week == "Tuesday".
> My question would be, does the evaluation of day_of_week == "Tuesday"
> result in the generation of an entire boolean vector (which would be in
> this case False,False,False,True) or does the ifelse "manage the indexing"
> so that it only tests the second element of the original vector (which is
> Thursday) and for that matter does it therefore not even bother to generate
> the first boolean vector I mentioned above (True,False,False,False) but
> rather just checks the first element?
>   Not sure if I have explained this well but if you understand I would
> appreciate a reply.
>   Thanks.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From rh at knut-krueger.de  Tue Dec  3 14:38:06 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Tue, 3 Dec 2013 14:38:06 +0100
Subject: [R] XLConnect readWorksheet   comma decimal sign
In-Reply-To: <0F58841C-E5E0-4DB5-AD6E-8696E908D08D@comcast.net>
References: <52931410.4080102@knut-krueger.de>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA05B8@SRVEXCHMBX.precheza.cz>
	<52933D4B.90803@knut-krueger.de> <5298A218.2090303@knut-krueger.de>
	<5422DC5C-24A7-4BA6-A43A-44340703398A@comcast.net>
	<5298DD4C.1080404@knut-krueger.de>
	<33144A60-5037-4C76-B950-3376B4B14902@comcast.net>
	<529C502E.2080903@knut-krueger.de>
	<0F58841C-E5E0-4DB5-AD6E-8696E908D08D@comcast.net>
Message-ID: <529DDEBE.7050103@knut-krueger.de>

Am 02.12.2013 21:28, schrieb David Winsemius:
> In fact you can set that globally with: ?options
>> options()$OutDec  # my setting
> [1] "."

Oh sorry I thought you mentioned to set excel globally to dot.

no change when setting it to dot. I seems that XLConnect is not able to 
deal with NA in Excel, means its string instead an number after importing.

>
>   If you continue having difficulty using XLConnect, then you should contact the authors of that package.
I tried - no answer yet.

Thank you Knut


From pdalgd at gmail.com  Tue Dec  3 14:46:59 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 3 Dec 2013 14:46:59 +0100
Subject: [R] Intepreting lm() results with factor
In-Reply-To: <CA+g3nKQbx3cZ7oW5tR69_04tSy1j=Ls-2-qes_27QwjjeSpefw@mail.gmail.com>
References: <CA+g3nKQPcxMqu8hjTO=GFaNN=c7Vi=zx-JFFpvJFkcDt7+EAjQ@mail.gmail.com>
	<CA+g3nKQbx3cZ7oW5tR69_04tSy1j=Ls-2-qes_27QwjjeSpefw@mail.gmail.com>
Message-ID: <AB090A27-4CBB-4AC7-9808-AF82A20B9A23@gmail.com>


On 03 Dec 2013, at 01:08 , David Gwenzi <dgwenzi at gmail.com> wrote:

> Dear all
> 
> I have observations done in 4 different classes and the between classes
> *variance* is too high that I decided to run a model without pooling the
> *variance*. I used the following code first :
>                   model<-lm(y~x+factor(class))
> and got the following output:
> Coefficients:
>                Estimate Std. Error t value Pr(>|t|)
> (Intercept)     52.41405   17.38161   3.015  0.00658 **
> x                0.27679    0.07387   3.747  0.00119 **
> factor(class)2  92.68083   32.26645   2.872  0.00912 **
> factor(class)3 197.82029   33.24916   5.950 6.63e-06 ***
> factor(class)4 105.61266   55.18373   1.914  0.06937 .
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 43.07 on 21 degrees of freedom
> Multiple R-squared:  0.9206,    Adjusted R-squared:  0.9055
> F-statistic: 60.91 on 4 and 21 DF,  p-value: 2.976e-11
> 
> My understanding of this output is that class 1 is used as a baseline
> (constant) and each other class's p values means for example the dependent
> value in class 2 is significantly different from that of class 1.
> Now I ran the model again, but without using a constant i.e
>                    model<-lm(y~x+factor(class)-1)
> and got the following output:
> Coefficients:
>                Estimate Std. Error t value Pr(>|t|)
> x                0.27679    0.07387   3.747  0.00119 **
> factor(class)1  52.41405   17.38161   3.015  0.00658 **
> factor(class)2 145.09488   39.42651   3.680  0.00139 **
> factor(class)3 250.23434   40.61189   6.162 4.11e-06 ***
> factor(class)4 158.02672   64.09549   2.465  0.02238 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 43.07 on 21 degrees of freedom
> Multiple R-squared:  0.9801,    Adjusted R-squared:  0.9754
> F-statistic: 207.1 on 5 and 21 DF,  p-value: < 2.2e-16
> 
> Can somebody please tell me how to interpret this one now? what do the
> classes' P values mean ? Do they merely show if they significantly
> contribute to the model or whether they are significantly different from
> the overall mean or not? Does it mean if one class had a p value > 0.05 it
> would mean the observations from that class are not significantly
> contributing to the model?

The estimates are of the per-class intercept and the P-value corresponds to a test that said intercept is zero (which is very rarely a relevant hypothesis).

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bbolker at gmail.com  Tue Dec  3 15:18:18 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Dec 2013 14:18:18 +0000
Subject: [R] R lmer debugging: Error in [[<-.data.frame(*tmp*, i,
	value = integer(0)) : replacement has 0 rows, data has 117
References: <CAEB9s5ZvfH3KN3naAXr7TOLSDMAVCH2SBRVvBffmsBjM8ntmUQ@mail.gmail.com>
	<CAAcyNCw3wn+5qKXAnbs9LVr16X-en4FZ-kcC+vDG2W7im9Mupw@mail.gmail.com>
Message-ID: <loom.20131203T150410-247@post.gmane.org>

Pascal Oettli <kridox <at> ymail.com> writes:

> 
> Hello,
> 
> I get a result if I change 'as.factor(males)' to 'males'.
> 
> Hope this helps,
> Pascal
> 
> On 3 December 2013 18:43, Cynthia Tedore <Cynthia.Tedore <at> biol.lu.se> 
> wrote:
> > I am able to use lmer on an older computer without this error, but the new
> > version (downloaded yesterday) gives me this error message:
> >
> > Error in [[<-.data.frame(*tmp*, i, value = integer(0)) : replacement has 0
> > rows, data has 117
> >
> > in response to this function:
> >
> > model1<-lmer(threatened~as.numeric(focal.chel)+
> as.numeric(opponent.chel)+(1|as.factor(males)),na.action=na.omit,data=spiders)

This was cross-posted to StackOverflow and has an answer there

http://stackoverflow.com/questions/19749313/
  lme4-upgrade-produces-error-message-even-after-grouping-variables-
   within-the-dat/20353535#20353535

(broken URL to make Gmane happy)

  These questions are probably more appropriate for
r-sig-mixed-models at r-project.org ...

  Ben Bolker


From santomecjl at gmail.com  Tue Dec  3 13:28:29 2013
From: santomecjl at gmail.com (=?ISO-8859-1?Q?Luis_Santom=E9_Collazo?=)
Date: Tue, 03 Dec 2013 13:28:29 +0100
Subject: [R] Replace empty cels in multiple dataframes
Message-ID: <529DCE6D.2090907@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/378757cd/attachment.pl>

From ashende at ascentius.com  Tue Dec  3 15:00:39 2013
From: ashende at ascentius.com (Alok Shende)
Date: Tue, 3 Dec 2013 19:30:39 +0530
Subject: [R] why change days of the week from a factor to an ordered factor?
Message-ID: <CA+v8G_3pSozqRWY=-z3MPE-FTKY-0rUdLLydmizX1D0Rf9Gmrg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/6dc072f6/attachment.pl>

From Cynthia.Tedore at biol.lu.se  Tue Dec  3 11:51:32 2013
From: Cynthia.Tedore at biol.lu.se (Cynthia Tedore)
Date: Tue, 3 Dec 2013 11:51:32 +0100
Subject: [R] R lmer debugging: Error in [[<-.data.frame(*tmp*, i,
 value = integer(0)) : replacement has 0 rows, data has 117
In-Reply-To: <CAAcyNCw3wn+5qKXAnbs9LVr16X-en4FZ-kcC+vDG2W7im9Mupw@mail.gmail.com>
References: <CAEB9s5ZvfH3KN3naAXr7TOLSDMAVCH2SBRVvBffmsBjM8ntmUQ@mail.gmail.com>
	<CAAcyNCw3wn+5qKXAnbs9LVr16X-en4FZ-kcC+vDG2W7im9Mupw@mail.gmail.com>
Message-ID: <CAEB9s5bpL1EUOredxa=0DcSPezTgJVdtvfT6GTVeZyeMfayqjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/cbff1a46/attachment.pl>

From srdjan.santic at gmail.com  Tue Dec  3 12:43:39 2013
From: srdjan.santic at gmail.com (Srdjan Santic)
Date: Tue, 03 Dec 2013 12:43:39 +0100
Subject: [R] Generating a matrix
Message-ID: <529DC3EB.2020607@gmail.com>

I'm trying to write a function that will generate a NxN matrix that has 
the value K on both diagonals, while the values outside the diagonals 
(up and down) are 1's (for conflicting positions such as [4,5] and [5,4] 
the larger value is written in the matrix). Basically, I'm trying to 
replicate this matrix (where N = 8 and K = 5):

5  1  0  0  0  0  1  5
1  5  1  0  0  1  5  1
0  1  5  1  1  5  1  0
0  0  1  5  5  1  0  0
0  0  1  5  5  1  0  0
0  1  5  1  1  5  1  0
1  5  1  0  0  1  5  1
5  1  0  0  0  0  1  5

Any ideas? Thank you!

Srdjan Santic, M.Sc.
Graduate Student
Faclty of Economics
University of Belgrade
Serbia

---
This email is free from viruses and malware because avast! Antivirus protection is active.


From mayer at iiasa.ac.at  Tue Dec  3 16:11:58 2013
From: mayer at iiasa.ac.at (MAYER Hans)
Date: Tue, 3 Dec 2013 16:11:58 +0100
Subject: [R] httpuv_1.2.0 : websockets-hybi03.cpp
Message-ID: <AEB6E9807EE5E04BA2F4A6CD4CE9DB198EDB2054BF@rhine.iiasa.ac.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/89862722/attachment.pl>

From dcarlson at tamu.edu  Tue Dec  3 17:20:01 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 3 Dec 2013 10:20:01 -0600
Subject: [R] Generating a matrix
In-Reply-To: <529DC3EB.2020607@gmail.com>
References: <529DC3EB.2020607@gmail.com>
Message-ID: <019a01cef043$847e5530$8d7aff90$@tamu.edu>

We don't do homework assignments on the list, but one answer
requires no loops and an understanding of the various ways R
uses vectors for indexing:

?"["

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Srdjan Santic
Sent: Tuesday, December 3, 2013 5:44 AM
To: r-help at r-project.org
Subject: [R] Generating a matrix

I'm trying to write a function that will generate a NxN matrix
that has 
the value K on both diagonals, while the values outside the
diagonals 
(up and down) are 1's (for conflicting positions such as [4,5]
and [5,4] 
the larger value is written in the matrix). Basically, I'm
trying to 
replicate this matrix (where N = 8 and K = 5):

5  1  0  0  0  0  1  5
1  5  1  0  0  1  5  1
0  1  5  1  1  5  1  0
0  0  1  5  5  1  0  0
0  0  1  5  5  1  0  0
0  1  5  1  1  5  1  0
1  5  1  0  0  1  5  1
5  1  0  0  0  0  1  5

Any ideas? Thank you!

Srdjan Santic, M.Sc.
Graduate Student
Faclty of Economics
University of Belgrade
Serbia

---
This email is free from viruses and malware because avast!
Antivirus protection is active.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From bbolker at gmail.com  Tue Dec  3 17:31:56 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Dec 2013 16:31:56 +0000
Subject: [R] R lmer debugging: Error in [[<-.data.frame(*tmp*, i,
	value = integer(0)) : replacement has 0 rows, data has 117
References: <CAEB9s5ZvfH3KN3naAXr7TOLSDMAVCH2SBRVvBffmsBjM8ntmUQ@mail.gmail.com>
	<CAAcyNCw3wn+5qKXAnbs9LVr16X-en4FZ-kcC+vDG2W7im9Mupw@mail.gmail.com>
	<CAEB9s5bpL1EUOredxa=0DcSPezTgJVdtvfT6GTVeZyeMfayqjQ@mail.gmail.com>
Message-ID: <loom.20131203T172924-752@post.gmane.org>

Cynthia Tedore <Cynthia.Tedore <at> biol.lu.se> writes:

> 
> males is a factor. If I don't specify that, then it
> treats it as a numeric.
> any other suggestions?

transform(spiders,focal.chel=as.numeric(focal.chel),
        opponent.chel=as.numeric(opponent.chel),fmales=factor(males))

model1<-lmer(threatened~focal.chelopponent.chel+(1|fmales),
   na.action=na.omit,data=spiders)

  I'm quite surprised (and a little skeptical) that `lmer` treats
males as a numeric in that particular context (i.e., when specified
as a grouping variable).  Can you provide evidence (i.e., what specific
error/incorrect results do you get if you follow Pascal's advice) ?


From S.Ellison at LGCGroup.com  Tue Dec  3 18:29:16 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 3 Dec 2013 17:29:16 +0000
Subject: [R] why change days of the week from a factor to an ordered
 factor?
In-Reply-To: <CA+v8G_3pSozqRWY=-z3MPE-FTKY-0rUdLLydmizX1D0Rf9Gmrg@mail.gmail.com>
References: <CA+v8G_3pSozqRWY=-z3MPE-FTKY-0rUdLLydmizX1D0Rf9Gmrg@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED56C98AFB65@GOLD.corp.lgc-group.com>

> There are two reasons. First is that in the "day_of_week", the starting day is
> Friday so if you plot a graph, the left most column will start with Friday. You
> may like to start the column with Monday. 

Plotting levels in a particular order by default does not usually require an ordered factor. It only requires that the levels are specified in the desired plotting order. without ...,ordered=TRUE  that does not generate an ordered factor.

But specifying an ordered factor changes default contrasts in modelling; see ?contrasts for details. That in turn changes the fitted model rather considerably. It isn't generally sensible to specify ordered factors unless there really is order that you want to explore.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From hmvstoreaddict at gmail.com  Tue Dec  3 16:22:19 2013
From: hmvstoreaddict at gmail.com (Sandra Stankowski)
Date: Tue, 3 Dec 2013 16:22:19 +0100
Subject: [R] Retrieving data from rotated netCDF-file
Message-ID: <78B91D12-5A13-4FBD-89D9-BE0709C76096@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/a07d3871/attachment.pl>

From smartpink111 at yahoo.com  Tue Dec  3 16:54:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 3 Dec 2013 07:54:43 -0800 (PST)
Subject: [R] Generating a matrix
In-Reply-To: <529DC3EB.2020607@gmail.com>
References: <529DC3EB.2020607@gmail.com>
Message-ID: <1386086083.97978.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,

You could try:
?mat1 <- matrix(0,8,8)
?diag(mat1) <- 5
?mat2 <- apply(mat1,2,rev)
?diag(mat2) <- 5
?indx<- which(mat2==5)
?mat2[indx[indx%%8==1]+1] <-1
mat2[indx[indx%%8==0]-1] <-1
?mat2[indx[!(indx%%8==0 |? indx%%8==1)]-1][mat2[indx[!(indx%%8==0 |indx%%8==1)]-1]==0] <- 1
?mat2[indx[!(indx%%8==0 |? indx%%8==1)]+1][mat2[indx[!(indx%%8==0 |indx%%8==1)]+1]==0] <- 1

A.K.




On Tuesday, December 3, 2013 10:07 AM, Srdjan Santic <srdjan.santic at gmail.com> wrote:
I'm trying to write a function that will generate a NxN matrix that has 
the value K on both diagonals, while the values outside the diagonals 
(up and down) are 1's (for conflicting positions such as [4,5] and [5,4] 
the larger value is written in the matrix). Basically, I'm trying to 
replicate this matrix (where N = 8 and K = 5):

5? 1? 0? 0? 0? 0? 1? 5
1? 5? 1? 0? 0? 1? 5? 1
0? 1? 5? 1? 1? 5? 1? 0
0? 0? 1? 5? 5? 1? 0? 0
0? 0? 1? 5? 5? 1? 0? 0
0? 1? 5? 1? 1? 5? 1? 0
1? 5? 1? 0? 0? 1? 5? 1
5? 1? 0? 0? 0? 0? 1? 5

Any ideas? Thank you!

Srdjan Santic, M.Sc.
Graduate Student
Faclty of Economics
University of Belgrade
Serbia

---
This email is free from viruses and malware because avast! Antivirus protection is active.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From minilith at gmail.com  Tue Dec  3 18:56:33 2013
From: minilith at gmail.com (Tom Li)
Date: Tue, 3 Dec 2013 09:56:33 -0800 (PST)
Subject: [R] Any R packages support conversion from PDF to XLS ?
In-Reply-To: <1386075824455-4681558.post@n4.nabble.com>
References: <1386062759767-4681545.post@n4.nabble.com>
	<1386075824455-4681558.post@n4.nabble.com>
Message-ID: <0600be55-5ec2-43ca-ab5b-ebda62f25ea3@googlegroups.com>



> Pretty much nothing can convert arbitrary PDF files to unicode.  It 
> depends a 
> lot on what is in the PDF to begin with -- properly encoded text or just 
> bitmapped images, for example.   
> I would recommend you search around to see whether  there's a related 
> archive in a different format.


If that isn't available, one could use tabula[1] to extract tables from 
pdfs as csv.

HTH

[1] http://tabula.nerdpower.org

From zilefacelvis at yahoo.com  Tue Dec  3 19:26:39 2013
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 3 Dec 2013 10:26:39 -0800 (PST)
Subject: [R] Spatial Correlation Map using R
Message-ID: <1386095199.84635.YahooMailNeo@web160601.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/c04013bd/attachment.pl>

From wshadish at ucmerced.edu  Tue Dec  3 20:09:23 2013
From: wshadish at ucmerced.edu (William Shadish)
Date: Tue, 3 Dec 2013 11:09:23 -0800
Subject: [R] significance of random effect in mgcv gam
Message-ID: <529E2C63.5070308@ucmerced.edu>

Dear R-helpers,

I would like to test whether a random effect is significant when 
implemented with bs="re" in mgcv gam. For example, if I run:

M3b <- gam(DVY  ~ s(SessIDX, fTX, bs = "re") + factor(TX),
            data = PCP,
            family = quasipoisson(link="log"), method="REML")
summary(M3b,all.p=TRUE)
gam.vcomp(M3b)

I obtain the the following output:

 > summary(M3b,all.p=TRUE)

Family: quasipoisson
Link function: log

Formula:
DVY ~ s(SessIDX, fTX, bs = "re") + factor(TX)

Parametric coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept)   1.3282     0.2244   5.920 2.74e-07 ***
factor(TX)1  -1.0546     0.7210  -1.463     0.15
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Approximate significance of smooth terms:
                  edf Ref.df     F p-value
s(SessIDX,fTX) 1.052      2 1.138   0.126

R-sq.(adj) =  0.388   Deviance explained = 39.5%
REML score =  37.67  Scale est. = 1.4172    n = 54
 > gam.vcomp(M3b)

Standard deviations and 0.95 confidence intervals:

                   std.dev      lower     upper
s(SessIDX,fTX) 0.07842742 0.01095655 0.5613865
scale          1.19029872 0.97816911 1.4484316

Rank: 2/2

Question. Am I correct that p = .126 above can be taken as the p-value 
associated with the random effect?

Thanks.

Will Shadish

-- 
William R. Shadish
Distinguished Professor
Founding Faculty

Mailing Address:
William R. Shadish
University of California
School of Social Sciences, Humanities and Arts
5200 North Lake Rd
Merced CA  95343

Physical/Delivery Address:
University of California Merced
ATTN: William Shadish
School of Social Sciences, Humanities and Arts
Facilities Services Building A
5200 North Lake Rd.
Merced, CA 95343

209-228-4372 voice
209-228-4007 fax (communal fax: be sure to include cover sheet)
wshadish at ucmerced.edu
http://faculty.ucmerced.edu/wshadish/index.htm
http://psychology.ucmerced.edu


From kristi.glover at hotmail.com  Tue Dec  3 20:31:37 2013
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Tue, 3 Dec 2013 15:31:37 -0400
Subject: [R] interaction plot with SE bar
Message-ID: <COL129-W72B6F5CBAC14A8C6B9A480FAD50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/1ea2f052/attachment.pl>

From jim at bitwrit.com.au  Tue Dec  3 22:59:45 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 04 Dec 2013 08:59:45 +1100
Subject: [R] Spatial Correlation Map using R
In-Reply-To: <1386095199.84635.YahooMailNeo@web160601.mail.bf1.yahoo.com>
References: <1386095199.84635.YahooMailNeo@web160601.mail.bf1.yahoo.com>
Message-ID: <529E5451.5010405@bitwrit.com.au>

On 12/04/2013 05:26 AM, Zilefac Elvis wrote:
> Hi,
> I have rainfall data from 100 locations, with coordinates  for each location available.
> Now, I have a correlation matrix showing the correlation between rainfall at a single location against all other locations and so on for the 100 locations.
> How can I visualize this correlation matrix using XY coordinate system instead of the correlogram in R.

Hi Zilefac,
Have a look at the color2D.matplot function in plotrix. See the first 
example.

Jim


From kellerp.l at gmail.com  Tue Dec  3 23:06:51 2013
From: kellerp.l at gmail.com (Peter Keller)
Date: Tue, 03 Dec 2013 17:06:51 -0500
Subject: [R] XLConnect readWorksheet comma decimal sign
In-Reply-To: <16728772.2905.1386062093021.JavaMail.nabble@joe.nabble.com>
References: <16728772.2905.1386062093021.JavaMail.nabble@joe.nabble.com>
Message-ID: <529E55FB.8010805@gmail.com>

I can't tell since you didn't post any code, so forgive me if you've 
tried this.  XLConnect has a colTypes parameter so you could try 
specifying the relevant columns to be read in as character, set 
forceConversion = TRUE, and then use as.numeric.  Something like this: 
as.numeric(sub(",", ".", Input, fixed = TRUE)) from 
http://stackoverflow.com/questions/15236440/as-numeric-with-comma-decimal-separators. 
  That will change the commas to dots and should eliminate the 
conversion to NA problem you were having.


From jim at bitwrit.com.au  Tue Dec  3 23:16:00 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 04 Dec 2013 09:16:00 +1100
Subject: [R] Spatial Correlation Map using R
In-Reply-To: <529E5451.5010405@bitwrit.com.au>
References: <1386095199.84635.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<529E5451.5010405@bitwrit.com.au>
Message-ID: <529E5820.90509@bitwrit.com.au>

On 12/04/2013 08:59 AM, Jim Lemon wrote:
> On 12/04/2013 05:26 AM, Zilefac Elvis wrote:
>> Hi,
>> I have rainfall data from 100 locations, with coordinates for each
>> location available.
>> Now, I have a correlation matrix showing the correlation between
>> rainfall at a single location against all other locations and so on
>> for the 100 locations.
>> How can I visualize this correlation matrix using XY coordinate system
>> instead of the correlogram in R.
>
> Hi Zilefac,
> Have a look at the color2D.matplot function in plotrix. See the first
> example.
>
On reading your message more carefully, I think you want a choropleth 
map, so use color.scale to get the fill colors and the maps package to 
plot them.

Jim


From smartpink111 at yahoo.com  Tue Dec  3 20:53:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 3 Dec 2013 11:53:45 -0800 (PST)
Subject: [R] Replace empty cels in multiple dataframes
In-Reply-To: <529DCE6D.2090907@gmail.com>
References: <529DCE6D.2090907@gmail.com>
Message-ID: <1386100425.33156.YahooMailNeo@web142603.mail.bf1.yahoo.com>






On Tuesday, December 3, 2013 2:31 PM, Luis Santom? Collazo <santomecjl at gmail.com> wrote:
Hi everyone,
HI,


##Creating a reproducible example
set.seed(45)
lst1 <- lapply(1:3,function(i) data.frame(AAA=sample(c(NA,1:10),20,replace=TRUE),BBB=sample(40,20,replace=TRUE)))
lapply(seq_along(lst1),function(i) write.table(lst1[[i]],paste0("file",i,".tab"),quote=FALSE))
dataset <- list.files(pattern="*.tab") 
dataset
[1] "file1.tab" "file2.tab" "file3.tab"

?replace_empty <- llply(dataset,function(x) {x1 <- read.table(x,header=TRUE); x1$AAA[is.na(x1$AAA)]<- 0; x1})##no errors here

A.K.




I'd like to replace the empty cells from a numerical variable (let's say 
variable "AAA") with zero in multiple dataframes using "plyr" package. 
Of course all the dataframes have the same structure but different 
number of lines.

I've been trying variations of:

|dataset <- list.files(pattern = "*.tab")

replace_empty <- llply(dataset,function(x){x$AAA[is.na(x$AAA)] <-0; return(x)})
|

But I always get the same error message:

? ? unexpected numeric constant in "llply(dataframes,function(x){x$AAA"

Any suggestion?

Thank you in advance!

Regards,

-- 


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Dec  3 21:10:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 3 Dec 2013 12:10:06 -0800 (PST)
Subject: [R] How to access data frame column name using variable ??
Message-ID: <1386101406.56125.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
comb[,as.numeric(temp[1])]
#[1] "V1" "V2"
?comb[,as.numeric(temp[3])]
#[1] "V1" "V3"



A.K.


i have two data frame 

>comb 
? ? ? ? ?[,1] ? [,2] ? ?[,3] ? [,4] ? [,5] ? ?[,6] 
[1,] ? ?"V1" ? "V1" ? "V1" ? "V1" ? "V1" ? "V1" 
[2,] ? ?"V2" ? "V2" ? "V2" ? "V3" ? "V3" ? "V4" 


>table 

? ? V1 ? ? ? ? ? V2 
1 V1V2 ? ? ? ? ?3 
2 V1V3 ? ? ? ? ?3 
5 V2V3 ? ? ? ? ?3 


i select row name by function 
rownames(table) and stored it in a data frame 

temp<-data.frame() 
temp<-rowname(table) 

i want to selcect column of other data frame using this reference. 

comb[,temp[1]]..but its not working.. 

because temp[1] is "1" 
comb[,"1"] 
is not vaild. 

who to over come this??


From elgriego777 at gmail.com  Tue Dec  3 21:45:19 2013
From: elgriego777 at gmail.com (Juan Manuel Reyes S)
Date: Tue, 3 Dec 2013 15:45:19 -0500
Subject: [R] Calculate external validation
Message-ID: <CACY5Zse4gGSK-cAAX_ugQnCfn=GHhmr8tNEiKuPYJzCWapkQ8Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/856a2e01/attachment.pl>

From zilefacelvis at yahoo.com  Tue Dec  3 23:58:06 2013
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 3 Dec 2013 14:58:06 -0800 (PST)
Subject: [R] Spatial Correlation Map using R
In-Reply-To: <529E5820.90509@bitwrit.com.au>
References: <1386095199.84635.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<529E5451.5010405@bitwrit.com.au> <529E5820.90509@bitwrit.com.au>
Message-ID: <1386111486.7007.YahooMailNeo@web160603.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/da0221de/attachment.pl>

From dwinsemius at comcast.net  Wed Dec  4 00:20:09 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 3 Dec 2013 15:20:09 -0800
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <CAJnbHtL39GT+DkK4Q_vwcAjSh540XNxq7Frh8SkqheOwjPAVMA@mail.gmail.com>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
	<001801ceefcf$809d3c20$81d7b460$@bigpond.com>
	<CAJnbHtL39GT+DkK4Q_vwcAjSh540XNxq7Frh8SkqheOwjPAVMA@mail.gmail.com>
Message-ID: <43814116-AF2A-4741-B21E-11AA082CDA17@comcast.net>


On Dec 2, 2013, at 6:58 PM, Bill wrote:

> Duncan,
> Thanks. Why doesn't
> coloursf2 <- factor(1:8, levels = 8:1)
> 
> give an ordering when you do str(coloursf2) like
> "8"<"7"<"6" ...

Because the default for 'ordered' in factor is FALSE:

>  coloursf2 <- factor(1:8, levels = 8:1, ordered=TRUE)
> coloursf2
[1] 1 2 3 4 5 6 7 8
Levels: 8 < 7 < 6 < 5 < 4 < 3 < 2 < 1

> 
> Bill
> 
> 
> On Mon, Dec 2, 2013 at 6:29 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> 
>> Hi Bill
>> 
>> eg
>> 
>>> colours =  1:8
>>> coloursf =  factor(1:8)
>>> colourso =  ordered(1:8)
>>> str(coloursf)
>> Factor w/ 8 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8
>>> str(colourso)
>> Ord.factor w/ 8 levels "1"<"2"<"3"<"4"<..: 1 2 3 4 5 6 7 8
>> 
>> coloursf2 <- factor(1:8, levels = 8:1)
>> str(coloursf2)
>> 
>> Duncan
>> 
>> Duncan
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>> 
>> 
>> ordered used in
>> used in MASS::polr and GEE for polytomous logistic regression
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On
>> Behalf Of Bill
>> Sent: Monday, 2 December 2013 21:24
>> To: r-help at r-project.org
>> Subject: [R] why change days of the week from a factor to an ordered
>> factor?
>> 
>> I am reading the code below. It acts on a csv file called dodgers.csv with
>> the following variables.
>> 
>> 
>>> print(str(dodgers))  # check the structure of the data frame
>> 'data.frame':   81 obs. of  12 variables:
>> $ month      : Factor w/ 7 levels "APR","AUG","JUL",..: 1 1 1 1 1 1 1 1 1
>> 1 ...
>> $ day        : int  10 11 12 13 14 15 23 24 25 27 ...
>> $ attend     : int  56000 29729 28328 31601 46549 38359 26376 44014 26345
>> 44807 ...
>> $ day_of_week: Factor w/ 7 levels "Friday","Monday",..: 6 7 5 1 3 4 2 6 7
>> 1 ...
>> $ opponent   : Factor w/ 17 levels "Angels","Astros",..: 13 13 13 11 11 11
>> 3 3 3 10 ...
>> $ temp       : int  67 58 57 54 57 65 60 63 64 66 ...
>> $ skies      : Factor w/ 2 levels "Clear ","Cloudy": 1 2 2 2 2 1 2 2 2 1
>> ...
>> $ day_night  : Factor w/ 2 levels "Day","Night": 1 2 2 2 2 1 2 2 2 2 ...
>> $ cap        : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>> $ shirt      : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>> $ fireworks  : Factor w/ 2 levels "NO","YES": 1 1 1 2 1 1 1 1 1 2 ...
>> $ bobblehead : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>> NULL
>>> 
>> 
>> I don't understand why the author of the code decided to make the factor
>> days_of_week into an ordered factor. Anyone know why this should be done?
>> Thank you.
>> 
>> Here is the code:
>> 
>> # Predictive Model for Los Angeles Dodgers Promotion and Attendance
>> 
>> library(car)  # special functions for linear regression
>> library(lattice)  # graphics package
>> 
>> # read in data and create a data frame called dodgers dodgers <-
>> read.csv("dodgers.csv")
>> print(str(dodgers))  # check the structure of the data frame
>> 
>> # define an ordered day-of-week variable # for plots and data summaries
>> dodgers$ordered_day_of_week <- with(data=dodgers,
>>  ifelse ((day_of_week == "Monday"),1,
>>  ifelse ((day_of_week == "Tuesday"),2,
>>  ifelse ((day_of_week == "Wednesday"),3,
>>  ifelse ((day_of_week == "Thursday"),4,
>>  ifelse ((day_of_week == "Friday"),5,
>>  ifelse ((day_of_week == "Saturday"),6,7)))))))
>> dodgers$ordered_day_of_week
>> <- factor(dodgers$ordered_day_of_week,
>> levels=1:7,
>> labels=c("Mon", "Tue", "Wed", "Thur", "Fri", "Sat", "Sun"))
>> 
>> # exploratory data analysis with standard graphics: attendance by day of
>> week with(data=dodgers,plot(ordered_day_of_week, attend/1000, xlab = "Day
>> of
>> Week", ylab = "Attendance (thousands)", col = "violet", las = 1))
>> 
>> # when do the Dodgers use bobblehead promotions with(dodgers,
>> table(bobblehead,ordered_day_of_week)) # bobbleheads on Tuesday
>> 
>> # define an ordered month variable
>> # for plots and data summaries
>> dodgers$ordered_month <- with(data=dodgers,
>>  ifelse ((month == "APR"),4,
>>  ifelse ((month == "MAY"),5,
>>  ifelse ((month == "JUN"),6,
>>  ifelse ((month == "JUL"),7,
>>  ifelse ((month == "AUG"),8,
>>  ifelse ((month == "SEP"),9,10)))))))
>> dodgers$ordered_month <- factor(dodgers$ordered_month, levels=4:10, labels
>> =
>> c("April", "May", "June", "July", "Aug", "Sept", "Oct"))
>> 
>> # exploratory data analysis with standard R graphics: attendance by month
>> with(data=dodgers,plot(ordered_month,attend/1000, xlab = "Month", ylab =
>> "Attendance (thousands)", col = "light blue", las = 1))
>> 
>> # exploratory data analysis displaying many variables # looking at
>> attendance and conditioning on day/night # the skies and whether or not
>> fireworks are displayed
>> library(lattice) # used for plotting
>> # let us prepare a graphical summary of the dodgers data group.labels <-
>> c("No Fireworks","Fireworks") group.symbols <- c(21,24) group.colors <-
>> c("black","black") group.fill <- c("black","red")
>> xyplot(attend/1000 ~ temp | skies + day_night,
>>    data = dodgers, groups = fireworks, pch = group.symbols,
>>    aspect = 1, cex = 1.5, col = group.colors, fill = group.fill,
>>    layout = c(2, 2), type = c("p","g"),
>>    strip=strip.custom(strip.levels=TRUE,strip.names=FALSE, style=1),
>>    xlab = "Temperature (Degrees Fahrenheit)",
>>    ylab = "Attendance (thousands)",
>>    key = list(space = "top",
>>        text = list(rev(group.labels),col = rev(group.colors)),
>>        points = list(pch = rev(group.symbols), col = rev(group.colors),
>>        fill = rev(group.fill))))
>> 
>> # attendance by opponent and day/night game group.labels <-
>> c("Day","Night")
>> group.symbols <- c(1,20) group.symbols.size <- c(2,2.75) bwplot(opponent ~
>> attend/1000, data = dodgers, groups = day_night,
>>    xlab = "Attendance (thousands)",
>>    panel = function(x, y, groups, subscripts, ...)
>>       {panel.grid(h = (length(levels(dodgers$opponent)) - 1), v = -1)
>>        panel.stripplot(x, y, groups = groups, subscripts = subscripts,
>>        cex = group.symbols.size, pch = group.symbols, col = "darkblue")
>>       },
>>    key = list(space = "top",
>>    text = list(group.labels,col = "black"),
>>    points = list(pch = group.symbols, cex = group.symbols.size,
>>    col = "darkblue")))
>> 
>> # specify a simple model with bobblehead entered last my.model <- {attend ~
>> ordered_month + ordered_day_of_week + bobblehead}
>> 
>> # employ a training-and-test regimen
>> set.seed(1234) # set seed for repeatability of training-and-test split
>> training_test <- c(rep(1,length=trunc((2/3)*nrow(dodgers))),
>> rep(2,length=(nrow(dodgers) - trunc((2/3)*nrow(dodgers)))))
>> dodgers$training_test <- sample(training_test) # random permutation
>> dodgers$training_test <- factor(dodgers$training_test,
>>  levels=c(1,2), labels=c("TRAIN","TEST")) dodgers.train <- subset(dodgers,
>> training_test == "TRAIN")
>> print(str(dodgers.train)) # check training data frame dodgers.test <-
>> subset(dodgers, training_test == "TEST")
>> print(str(dodgers.test)) # check test data frame
>> 
>> # fit the model to the training set
>> train.model.fit <- lm(my.model, data = dodgers.train) # obtain predictions
>> from the training set dodgers.train$predict_attend <-
>> predict(train.model.fit)
>> 
>> # evaluate the fitted model on the test set dodgers.test$predict_attend <-
>> predict(train.model.fit,
>>  newdata = dodgers.test)
>> 
>> # compute the proportion of response variance # accounted for when
>> predicting out-of-sample cat("\n","Proportion of Test Set Variance
>> Accounted
>> for: ", round((with(dodgers.test,cor(attend,predict_attend)^2)),
>>  digits=3),"\n",sep="")
>> 
>> # merge the training and test sets for plotting dodgers.plotting.frame <-
>> rbind(dodgers.train,dodgers.test)
>> 
>> # generate predictive modeling visual for management group.labels <- c("No
>> Bobbleheads","Bobbleheads") group.symbols <- c(21,24) group.colors <-
>> c("black","black") group.fill <- c("black","red")
>> xyplot(predict_attend/1000 ~ attend/1000 | training_test,
>>       data = dodgers.plotting.frame, groups = bobblehead, cex = 2,
>>       pch = group.symbols, col = group.colors, fill = group.fill,
>>       layout = c(2, 1), xlim = c(20,65), ylim = c(20,65),
>>       aspect=1, type = c("p","g"),
>>       panel=function(x,y, ...)
>>            {panel.xyplot(x,y,...)
>>             panel.segments(25,25,60,60,col="black",cex=2)
>>            },
>>       strip=function(...) strip.default(..., style=1),
>>       xlab = "Actual Attendance (thousands)",
>>       ylab = "Predicted Attendance (thousands)",
>>       key = list(space = "top",
>>              text = list(rev(group.labels),col = rev(group.colors)),
>>              points = list(pch = rev(group.symbols),
>>              col = rev(group.colors),
>>              fill = rev(group.fill))))
>> 
>> # use the full data set to obtain an estimate of the increase in #
>> attendance due to bobbleheads, controlling for other factors my.model.fit
>> <-
>> lm(my.model, data = dodgers)  # use all available data
>> print(summary(my.model.fit))
>> # tests statistical significance of the bobblehead promotion # type I anova
>> computes sums of squares for sequential tests
>> print(anova(my.model.fit))
>> 
>> cat("\n","Estimated Effect of Bobblehead Promotion on Attendance: ",
>> round(my.model.fit$coefficients[length(my.model.fit$coefficients)],
>> digits = 0),"\n",sep="")
>> 
>> # standard graphics provide diagnostic plots
>> plot(my.model.fit)
>> 
>> # additional model diagnostics drawn from the car package
>> library(car)
>> residualPlots(my.model.fit)
>> marginalModelPlots(my.model.fit)
>> print(outlierTest(my.model.fit))
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Wed Dec  4 00:33:03 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 3 Dec 2013 15:33:03 -0800
Subject: [R] why change days of the week from a factor to an ordered
	factor?
In-Reply-To: <43814116-AF2A-4741-B21E-11AA082CDA17@comcast.net>
References: <CAJnbHtLCr7chZRG4ZNvQ5Wof3+Twrm-FB25HkkkOE=NGWkcMRQ@mail.gmail.com>
	<001801ceefcf$809d3c20$81d7b460$@bigpond.com>
	<CAJnbHtL39GT+DkK4Q_vwcAjSh540XNxq7Frh8SkqheOwjPAVMA@mail.gmail.com>
	<43814116-AF2A-4741-B21E-11AA082CDA17@comcast.net>
Message-ID: <CACk-te1_SAc_9VPP6zb=2q9cB4TXvOVQC-B710GA-s53iZwAWQ@mail.gmail.com>

But I think Bill continues to confuse the sort order of factor levels
with the order of an ordered factor.

?ordered
## and some time with an R tutorial might help!

Note:

> f1 <- factor(1:5, lev = 5:1)
> f2 <- factor(1:5,lev=5:1,ordered=TRUE)
> identical(f1,f2)
[1] FALSE
> ## They are different classes!!
> f1
[1] 1 2 3 4 5
Levels: 5 4 3 2 1
> f2
[1] 1 2 3 4 5
Levels: 5 < 4 < 3 < 2 < 1
> sort(f1)
[1] 5 4 3 2 1
Levels: 5 4 3 2 1
> sort(f2)
[1] 5 4 3 2 1
Levels: 5 < 4 < 3 < 2 < 1

Cheers,
Bert


On Tue, Dec 3, 2013 at 3:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Dec 2, 2013, at 6:58 PM, Bill wrote:
>
>> Duncan,
>> Thanks. Why doesn't
>> coloursf2 <- factor(1:8, levels = 8:1)
>>
>> give an ordering when you do str(coloursf2) like
>> "8"<"7"<"6" ...
>
> Because the default for 'ordered' in factor is FALSE:
>
>>  coloursf2 <- factor(1:8, levels = 8:1, ordered=TRUE)
>> coloursf2
> [1] 1 2 3 4 5 6 7 8
> Levels: 8 < 7 < 6 < 5 < 4 < 3 < 2 < 1
>
>>
>> Bill
>>
>>
>> On Mon, Dec 2, 2013 at 6:29 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>>
>>> Hi Bill
>>>
>>> eg
>>>
>>>> colours =  1:8
>>>> coloursf =  factor(1:8)
>>>> colourso =  ordered(1:8)
>>>> str(coloursf)
>>> Factor w/ 8 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8
>>>> str(colourso)
>>> Ord.factor w/ 8 levels "1"<"2"<"3"<"4"<..: 1 2 3 4 5 6 7 8
>>>
>>> coloursf2 <- factor(1:8, levels = 8:1)
>>> str(coloursf2)
>>>
>>> Duncan
>>>
>>> Duncan
>>> Duncan Mackay
>>> Department of Agronomy and Soil Science
>>> University of New England
>>> Armidale NSW 2351
>>> Email: home: mackay at northnet.com.au
>>>
>>>
>>> ordered used in
>>> used in MASS::polr and GEE for polytomous logistic regression
>>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>>> On
>>> Behalf Of Bill
>>> Sent: Monday, 2 December 2013 21:24
>>> To: r-help at r-project.org
>>> Subject: [R] why change days of the week from a factor to an ordered
>>> factor?
>>>
>>> I am reading the code below. It acts on a csv file called dodgers.csv with
>>> the following variables.
>>>
>>>
>>>> print(str(dodgers))  # check the structure of the data frame
>>> 'data.frame':   81 obs. of  12 variables:
>>> $ month      : Factor w/ 7 levels "APR","AUG","JUL",..: 1 1 1 1 1 1 1 1 1
>>> 1 ...
>>> $ day        : int  10 11 12 13 14 15 23 24 25 27 ...
>>> $ attend     : int  56000 29729 28328 31601 46549 38359 26376 44014 26345
>>> 44807 ...
>>> $ day_of_week: Factor w/ 7 levels "Friday","Monday",..: 6 7 5 1 3 4 2 6 7
>>> 1 ...
>>> $ opponent   : Factor w/ 17 levels "Angels","Astros",..: 13 13 13 11 11 11
>>> 3 3 3 10 ...
>>> $ temp       : int  67 58 57 54 57 65 60 63 64 66 ...
>>> $ skies      : Factor w/ 2 levels "Clear ","Cloudy": 1 2 2 2 2 1 2 2 2 1
>>> ...
>>> $ day_night  : Factor w/ 2 levels "Day","Night": 1 2 2 2 2 1 2 2 2 2 ...
>>> $ cap        : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>>> $ shirt      : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>>> $ fireworks  : Factor w/ 2 levels "NO","YES": 1 1 1 2 1 1 1 1 1 2 ...
>>> $ bobblehead : Factor w/ 2 levels "NO","YES": 1 1 1 1 1 1 1 1 1 1 ...
>>> NULL
>>>>
>>>
>>> I don't understand why the author of the code decided to make the factor
>>> days_of_week into an ordered factor. Anyone know why this should be done?
>>> Thank you.
>>>
>>> Here is the code:
>>>
>>> # Predictive Model for Los Angeles Dodgers Promotion and Attendance
>>>
>>> library(car)  # special functions for linear regression
>>> library(lattice)  # graphics package
>>>
>>> # read in data and create a data frame called dodgers dodgers <-
>>> read.csv("dodgers.csv")
>>> print(str(dodgers))  # check the structure of the data frame
>>>
>>> # define an ordered day-of-week variable # for plots and data summaries
>>> dodgers$ordered_day_of_week <- with(data=dodgers,
>>>  ifelse ((day_of_week == "Monday"),1,
>>>  ifelse ((day_of_week == "Tuesday"),2,
>>>  ifelse ((day_of_week == "Wednesday"),3,
>>>  ifelse ((day_of_week == "Thursday"),4,
>>>  ifelse ((day_of_week == "Friday"),5,
>>>  ifelse ((day_of_week == "Saturday"),6,7)))))))
>>> dodgers$ordered_day_of_week
>>> <- factor(dodgers$ordered_day_of_week,
>>> levels=1:7,
>>> labels=c("Mon", "Tue", "Wed", "Thur", "Fri", "Sat", "Sun"))
>>>
>>> # exploratory data analysis with standard graphics: attendance by day of
>>> week with(data=dodgers,plot(ordered_day_of_week, attend/1000, xlab = "Day
>>> of
>>> Week", ylab = "Attendance (thousands)", col = "violet", las = 1))
>>>
>>> # when do the Dodgers use bobblehead promotions with(dodgers,
>>> table(bobblehead,ordered_day_of_week)) # bobbleheads on Tuesday
>>>
>>> # define an ordered month variable
>>> # for plots and data summaries
>>> dodgers$ordered_month <- with(data=dodgers,
>>>  ifelse ((month == "APR"),4,
>>>  ifelse ((month == "MAY"),5,
>>>  ifelse ((month == "JUN"),6,
>>>  ifelse ((month == "JUL"),7,
>>>  ifelse ((month == "AUG"),8,
>>>  ifelse ((month == "SEP"),9,10)))))))
>>> dodgers$ordered_month <- factor(dodgers$ordered_month, levels=4:10, labels
>>> =
>>> c("April", "May", "June", "July", "Aug", "Sept", "Oct"))
>>>
>>> # exploratory data analysis with standard R graphics: attendance by month
>>> with(data=dodgers,plot(ordered_month,attend/1000, xlab = "Month", ylab =
>>> "Attendance (thousands)", col = "light blue", las = 1))
>>>
>>> # exploratory data analysis displaying many variables # looking at
>>> attendance and conditioning on day/night # the skies and whether or not
>>> fireworks are displayed
>>> library(lattice) # used for plotting
>>> # let us prepare a graphical summary of the dodgers data group.labels <-
>>> c("No Fireworks","Fireworks") group.symbols <- c(21,24) group.colors <-
>>> c("black","black") group.fill <- c("black","red")
>>> xyplot(attend/1000 ~ temp | skies + day_night,
>>>    data = dodgers, groups = fireworks, pch = group.symbols,
>>>    aspect = 1, cex = 1.5, col = group.colors, fill = group.fill,
>>>    layout = c(2, 2), type = c("p","g"),
>>>    strip=strip.custom(strip.levels=TRUE,strip.names=FALSE, style=1),
>>>    xlab = "Temperature (Degrees Fahrenheit)",
>>>    ylab = "Attendance (thousands)",
>>>    key = list(space = "top",
>>>        text = list(rev(group.labels),col = rev(group.colors)),
>>>        points = list(pch = rev(group.symbols), col = rev(group.colors),
>>>        fill = rev(group.fill))))
>>>
>>> # attendance by opponent and day/night game group.labels <-
>>> c("Day","Night")
>>> group.symbols <- c(1,20) group.symbols.size <- c(2,2.75) bwplot(opponent ~
>>> attend/1000, data = dodgers, groups = day_night,
>>>    xlab = "Attendance (thousands)",
>>>    panel = function(x, y, groups, subscripts, ...)
>>>       {panel.grid(h = (length(levels(dodgers$opponent)) - 1), v = -1)
>>>        panel.stripplot(x, y, groups = groups, subscripts = subscripts,
>>>        cex = group.symbols.size, pch = group.symbols, col = "darkblue")
>>>       },
>>>    key = list(space = "top",
>>>    text = list(group.labels,col = "black"),
>>>    points = list(pch = group.symbols, cex = group.symbols.size,
>>>    col = "darkblue")))
>>>
>>> # specify a simple model with bobblehead entered last my.model <- {attend ~
>>> ordered_month + ordered_day_of_week + bobblehead}
>>>
>>> # employ a training-and-test regimen
>>> set.seed(1234) # set seed for repeatability of training-and-test split
>>> training_test <- c(rep(1,length=trunc((2/3)*nrow(dodgers))),
>>> rep(2,length=(nrow(dodgers) - trunc((2/3)*nrow(dodgers)))))
>>> dodgers$training_test <- sample(training_test) # random permutation
>>> dodgers$training_test <- factor(dodgers$training_test,
>>>  levels=c(1,2), labels=c("TRAIN","TEST")) dodgers.train <- subset(dodgers,
>>> training_test == "TRAIN")
>>> print(str(dodgers.train)) # check training data frame dodgers.test <-
>>> subset(dodgers, training_test == "TEST")
>>> print(str(dodgers.test)) # check test data frame
>>>
>>> # fit the model to the training set
>>> train.model.fit <- lm(my.model, data = dodgers.train) # obtain predictions
>>> from the training set dodgers.train$predict_attend <-
>>> predict(train.model.fit)
>>>
>>> # evaluate the fitted model on the test set dodgers.test$predict_attend <-
>>> predict(train.model.fit,
>>>  newdata = dodgers.test)
>>>
>>> # compute the proportion of response variance # accounted for when
>>> predicting out-of-sample cat("\n","Proportion of Test Set Variance
>>> Accounted
>>> for: ", round((with(dodgers.test,cor(attend,predict_attend)^2)),
>>>  digits=3),"\n",sep="")
>>>
>>> # merge the training and test sets for plotting dodgers.plotting.frame <-
>>> rbind(dodgers.train,dodgers.test)
>>>
>>> # generate predictive modeling visual for management group.labels <- c("No
>>> Bobbleheads","Bobbleheads") group.symbols <- c(21,24) group.colors <-
>>> c("black","black") group.fill <- c("black","red")
>>> xyplot(predict_attend/1000 ~ attend/1000 | training_test,
>>>       data = dodgers.plotting.frame, groups = bobblehead, cex = 2,
>>>       pch = group.symbols, col = group.colors, fill = group.fill,
>>>       layout = c(2, 1), xlim = c(20,65), ylim = c(20,65),
>>>       aspect=1, type = c("p","g"),
>>>       panel=function(x,y, ...)
>>>            {panel.xyplot(x,y,...)
>>>             panel.segments(25,25,60,60,col="black",cex=2)
>>>            },
>>>       strip=function(...) strip.default(..., style=1),
>>>       xlab = "Actual Attendance (thousands)",
>>>       ylab = "Predicted Attendance (thousands)",
>>>       key = list(space = "top",
>>>              text = list(rev(group.labels),col = rev(group.colors)),
>>>              points = list(pch = rev(group.symbols),
>>>              col = rev(group.colors),
>>>              fill = rev(group.fill))))
>>>
>>> # use the full data set to obtain an estimate of the increase in #
>>> attendance due to bobbleheads, controlling for other factors my.model.fit
>>> <-
>>> lm(my.model, data = dodgers)  # use all available data
>>> print(summary(my.model.fit))
>>> # tests statistical significance of the bobblehead promotion # type I anova
>>> computes sums of squares for sequential tests
>>> print(anova(my.model.fit))
>>>
>>> cat("\n","Estimated Effect of Bobblehead Promotion on Attendance: ",
>>> round(my.model.fit$coefficients[length(my.model.fit$coefficients)],
>>> digits = 0),"\n",sep="")
>>>
>>> # standard graphics provide diagnostic plots
>>> plot(my.model.fit)
>>>
>>> # additional model diagnostics drawn from the car package
>>> library(car)
>>> residualPlots(my.model.fit)
>>> marginalModelPlots(my.model.fit)
>>> print(outlierTest(my.model.fit))
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dwinsemius at comcast.net  Wed Dec  4 01:21:16 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 3 Dec 2013 16:21:16 -0800
Subject: [R] What is the easiest way to interpolate vertical values on a
	square section of a nearly-planar 3D surface
In-Reply-To: <1386043350.1849.YahooMailNeo@web121005.mail.ne1.yahoo.com>
References: <1386043350.1849.YahooMailNeo@web121005.mail.ne1.yahoo.com>
Message-ID: <6ED4B09D-D1E0-4227-871C-1F1E6607AC3E@comcast.net>


On Dec 2, 2013, at 8:02 PM, Mercutio Florid wrote:

> I want to map out a mostly flat area of land, 300 meters on a side.  
> 
> 
> I want to make (x,y,z) triples where x and y vary between -150 and 150 and there is just one z value.
> 
> 
> Eventually I will try to use graphics to actually draw this, but my first problem is that I need to get 90601 values by interpolating just 13 actual measurements.  The measurements are currently unsorted, which might cause errors with some functions, and they are in a matrix that looks like this:
>       X    Y Value
> 1    20  135   105
> 2  -127   69   106
> 3   -98   47   107
> 4   -39   69   105
> 5    49   47   105
> 6   108   69   107
> 7    -9    3   106
> 8   -39    3   106
> 9  -127  -63   105
> 10  -39  -41   108
> 11  -39 -107   106
> 12   79  -63   107
> 13   20 -129   107

I have no idea what sort of "interpolation would make sense here. There is an 'akima' package that does interpretation at irregularly located x-y coordinates, but after doing a planar fit with scatter3d (which also lets you look at the points in 3d,  I think your points have a rather irregular cliff-like structure.

rd.txt <- function (txt, header = TRUE, ...) 
{
    rd <- read.table(textConnection(txt), header = header, ...)
    closeAllConnections()
    rd
}
dat <- rd.txt("     X    Y Value
1    20  135   105
2  -127   69   106
3   -98   47   107
4   -39   69   105
5    49   47   105
6   108   69   107
7    -9    3   106
8   -39    3   106
9  -127  -63   105
10  -39  -41   108
11  -39 -107   106
12   79  -63   107
13   20 -129   107")

library(car)
# will also need rgl
scatter3d(dat$X, dat$Y, dat$Value)

library(akima)
akima.li <- interp(dat$X, dat$Y, dat$Value, 
                   xo=seq(min(dat$X), max(dat$X), length = 100),
                   yo=seq(min(dat$Y), max(dat$Y), length = 100))

persp(akima.li$z)
 persp(akima.li$z, theta=30)
 persp(akima.li$z, theta=45)
 persp(akima.li$z, theta=60)

-- 
David.

> 
> 
> The syntax for the output seems pretty easy:
> x_coord<-seq(from=-150,to=150)
> y_coord<-seq(from=-150,to=150)
> planebreadth=301
> spaceArray<-array(0,c(planebreadth, planebreadth,1))
> 
> But what I need to do is somehow interpolate 90601 values into spaceArray, based on just 13 measurements.
> 
> I looked through some introductory R tutorials such as
> 
> cran.r-project.org/doc/manuals/R-intro.html
> 
> and I didn't see any examples that seemed to cover this kind of problem.
> 
> 
> 
> I did some web searches and there seem to be many, many ways to do interpolation.  There are packages like mgcv and DiceKriging.  There are various packages that mention splines in their descriptions, such as cobs.   
> 
> What is the easiest way to interpolate this kind of data?  Thanks.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From olivier.crouzet at univ-nantes.fr  Wed Dec  4 01:30:37 2013
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Wed, 4 Dec 2013 01:30:37 +0100
Subject: [R] International phonetic symbols in R.
In-Reply-To: <529E2F36.6020307@auckland.ac.nz>
References: <529D9E4A.3060407@auckland.ac.nz>
	<20131203114615.853ee42d725b58baad33019d@univ-nantes.fr>
	<529E2F36.6020307@auckland.ac.nz>
Message-ID: <20131204013037.5f5432883d16f4c1017c2a81@univ-nantes.fr>

Well, thanks for sending me the files but I'm sorry to be rather
pessimistic as for now...

that's exactly what I was suspecting after a first look at the data
in your first email... The short answer is: an obsolete IPA
transcription system is used in the files so the student should rework
the data.

The long answer follows...

To summarize, there are (were, only 2 are still conventional) 3 ways of
displaying phonetic transcriptions (well there are several other
systems but no need to complicate things and these conceptually fall
into either of these 3 categories):

- the old one consists in using specific fonts that would display
specific characters from the same range (256 positions in the font
table) as regular fonts. So one had to change font in order to display
phonetics AND if one didn't own the specific font used by the
original author, one could never be sure that a replacement font would
do the job as the same characters may sometimes correspond to different
positions in the encoding when using different fonts...

- the current one (since at least 10 years I would say) consists in
using unicode fonts, and to take advantage of the IPA range for which
several fonts provide glyphs (among which Sil Doulos and DejaVu which
respectively provide serif and sanserif IPA fonts along with the
"standard" (=lots of) characters.

- an alternate solution (especially good for computer manipulation)
stands in SAMPA and X-SAMPA (http://www.phon.ucl.ac.uk/home/sampa/), two
related solutions using only characters in the ascii range and,
provided one knows the conventions for coding, will let anyone
transcribe phonetics even with a typewriter! This is often a good
choice for analysing data by computer as one does not need to know the
Unicode hexadecimal number to type when manipulating the characters.
But it is sometimes desirable to have both SAMPA and Unicode coding in
the same file (automatic generations from one to the other are rather
easy) as SAMPA is easier to use when manipulating character strings on
the keyboard but IPA unicode glyphs are easier to interpret for most
linguists when reading / looking at the data.

Depending on what you plan to do with the phonetic transcripts in the
analysis process, there may be arguments in favor of either
SAMPA/X-SAMPA or IPA or both.


So... Apart from the fact that the tabulated data will be a real pain to
organize due to what seems to be incoherent data coding with
statistical analysis in mind (but that was not part of the question), I
see that the font which is used to display phonetic characters is:
"Ipa-samd Uclphon1 SILDoulosL" (no technical relationship at all with
the Sil Doulos mentionned above). Here, libreoffice does not display
anything else than "squares". Though obviously I haven't got this font
on my computer, I can read the expected font name, so I had a quick
look on the net and found this page:

http://www.phon.ucl.ac.uk/shop/fonts.php (where it obsiously  from
as this was, years ago, a font that was disseminated by the
speech community at UCL, as its name may imply).

which states, with clear warnings that:

"Please note: These fonts are now "legacy fonts": obsolete,
symbol-encoded fonts. Their use in new documents is discouraged. If you
decide to download and use these, please note there is no user
support for them. If your university or organization requires the use
of these fonts, please request they change their requirement to one of
the Unicode-encoded font which contains the complete IPA repertoire.
Many such fonts are now available, and several are supplied with all
new computers. Others are available from SIL."

Unfortunately, this clearly corresponds to the first case
mentionned above: usage of an obsolete IPA transcription system
requiring a specific font, but most of all, making data transfer
particularly difficult if not impossible due to discrepancies between
positions in the font encoding and "standard" glyph (or shape)
representations.

I'm certain that this message has been on UCL web site for several
years now! Though one may discuss the opportunity of keeping such fonts
available for download, one cannot say it's not clear from their
web page that it should not be used.

So, first step... tell the student to use "state-of-the-art" font
coding for phonetic transcriptions (which is either IPA with unicode
encoding, either SAMPA) which means that he/she must rework all
the transcriptions in his/her files.

Perhaps, while doing that, tell him/her to think about a better
solution for storing data than these tables where 90% of the cells
are empty...

Sorry to be of no help here but I really see no point at trying to
solve issues when obsolete solutions are the main reason of these
issues...

Of course someone on the list may be more optimistic than I am.

Anyway, once the student has come back with either SAMPA or unicode
encoding, I would happily provide advice to working with IPA
characters within R.

Yours sincerely.
Olivier.



-- 
  Olivier Crouzet, PhD
  Laboratoire de Linguistique -- EA3827
  Universit? de Nantes
  Chemin de la Censive du Tertre - BP 81227
  44312 Nantes cedex 3
  France

     phone:        (+33) 02 40 14 14 05 (lab.)
                   (+33) 02 40 14 14 36 (office)
     fax:          (+33) 02 40 14 13 27
     e-mail:       olivier.crouzet at univ-nantes.fr
 		
  http://www.lling.univ-nantes.fr/


From dwinsemius at comcast.net  Wed Dec  4 02:28:52 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 3 Dec 2013 17:28:52 -0800
Subject: [R] ifelse -does it "manage the indexing"?
In-Reply-To: <CABdHhvH92Y35sFdFfiFvAEa7v_N18UEyMgbtNj-6M+5gFrj0sw@mail.gmail.com>
References: <CAJnbHtKUkBX-Q5eUXYdqYnnwR29AJE-B6J8+nUjhh1yygrh7rg@mail.gmail.com>
	<CABdHhvH92Y35sFdFfiFvAEa7v_N18UEyMgbtNj-6M+5gFrj0sw@mail.gmail.com>
Message-ID: <C24873B1-F11B-49D6-B9B9-E0E9E00C6949@comcast.net>


On Dec 3, 2013, at 5:37 AM, Hadley Wickham wrote:

> A better solution to this problem is to use character indexing:
> 
> x <- c("Tuesday", "Thursday", "Sunday")
> c(Monday = 1, Tuesday = 2, Wednesday = 3, Thursday = 4, Friday = 5,
> Saturday = 6, Sunday = 7)[x]
> 
> http://adv-r.had.co.nz/Subsetting.html#lookup-tables-character-subsetting

That does seem more expressive than using match:

x <- c("Tuesday", "Thursday", "Sunday")
match(x, c('Monday', 'Tuesday', 'Wednesday' ,'Thursday' ,
                   'Friday',  'Saturday', 'Sunday') ) 
[1] 2 4 7

It would also lend itself well to grouping operations

x <- c("Tuesday", "Thursday", "Sunday")
c(Monday = 'first half', Tuesday = 'first half',
  Wednesday = "hump", 
  Thursday = 'second half', Friday = 'second half',
  Saturday = "weekend", Sunday = "weekend")[x]

      Tuesday      Thursday        Sunday 
 "first half" "second half"     "weekend" 

The corresponding use case with match would be:

c(rep('first half',2),"hump", rep('second half',2), rep("weekend",2) )[
           match(x, c('Monday', 'Tuesday', 'Wednesday' ,'Thursday' ,
                    'Friday',  'Saturday', 'Sunday') ) ]
[1] "first half"  "second half" "weekend"    

And your recommended method has the virtue of performing the same partial matching allowed by charmatch:

 x2 <- substr(x, 1,3)
 charmatch(x2, c('Monday', 'Tuesday', 'Wednesday' ,'Thursday' ,
                    'Friday',  'Saturday', 'Sunday') )
#[1] 2 4 7
 c(Monday = 1, Tuesday = 2, Wednesday = 3, Thursday = 4, Friday = 5,
     Saturday = 6, Sunday = 7)[x]
# Tuesday Thursday   Sunday 
#       2        4        7 

-- 
David.

> 
> Hadley
> 
> On Mon, Dec 2, 2013 at 6:33 PM, Bill <william108 at gmail.com> wrote:
>> ifelse ((day_of_week == "Monday"),1,
>>  ifelse ((day_of_week == "Tuesday"),2,
>>  ifelse ((day_of_week == "Wednesday"),3,
>>  ifelse ((day_of_week == "Thursday"),4,
>>  ifelse ((day_of_week == "Friday"),5,
>>  ifelse ((day_of_week == "Saturday"),6,7)))))))
>> 
>> 
>>  In code like the above, day_of_week is a vector and so day_of_week ==
>> "Monday" will result in a boolean vector. Suppose day_of_week is Monday,
>> Thursday, Friday, Tuesday. So day_of_week == "Monday" will be
>> True,False,False,False. I think that ifelse will test the first element and
>> it will generate a 1. At this point it will not have run day_of_week ==
>> "Tuesday" yet. Then it will test the second element of day_of_week and it
>> will be false and this will cause it to evaluate day_of_week == "Tuesday".
>> My question would be, does the evaluation of day_of_week == "Tuesday"
>> result in the generation of an entire boolean vector (which would be in
>> this case False,False,False,True) or does the ifelse "manage the indexing"
>> so that it only tests the second element of the original vector (which is
>> Thursday) and for that matter does it therefore not even bother to generate
>> the first boolean vector I mentioned above (True,False,False,False) but
>> rather just checks the first element?
>>  Not sure if I have explained this well but if you understand I would
>> appreciate a reply.
>>  Thanks.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> http://had.co.nz/
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwarnold45 at suddenlink.net  Wed Dec  4 02:48:32 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Tue, 3 Dec 2013 17:48:32 -0800 (PST)
Subject: [R] Sizing axis labels in ggplot2
Message-ID: <1386121712304-4681605.post@n4.nabble.com>

All,

Say I do:

require(ggplot2)
names(PlantGrowth)
bp <- ggplot(PlantGrowth,aes(x=group,y=weight))+geom_boxplot()

But the default axis labels and tick labels are just too small for me to
read.

What is the easiest was to enlarge the font size of axis labels and tick
labels?

Thanks.

D.



--
View this message in context: http://r.789695.n4.nabble.com/Sizing-axis-labels-in-ggplot2-tp4681605.html
Sent from the R help mailing list archive at Nabble.com.


From haenlein at escpeurope.eu  Wed Dec  4 04:10:52 2013
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Wed, 4 Dec 2013 04:10:52 +0100
Subject: [R] Looking for consultant in mathematics/ statistics
Message-ID: <CAOyz9G4793jNVpCDDpAF_0WnUOrUi_bGMWYe9ty70pevzY=9HA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/118c1494/attachment.pl>

From erinm.hodgess at gmail.com  Wed Dec  4 04:33:07 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 3 Dec 2013 21:33:07 -0600
Subject: [R] persp and Response surface models
Message-ID: <CACxE24k+tUei4ZcKi4a7tMF4jNHeW48xf+_59nocKx_bEjYjEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/802a221f/attachment.pl>

From erinm.hodgess at gmail.com  Wed Dec  4 05:07:17 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 3 Dec 2013 22:07:17 -0600
Subject: [R] persp and Response surface models
In-Reply-To: <CACxE24k+tUei4ZcKi4a7tMF4jNHeW48xf+_59nocKx_bEjYjEw@mail.gmail.com>
References: <CACxE24k+tUei4ZcKi4a7tMF4jNHeW48xf+_59nocKx_bEjYjEw@mail.gmail.com>
Message-ID: <CACxE24nD2nqn=RB=2ES7ad4jbRxK37f1GsNs7TjiRe-=+CFVwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131203/8201277a/attachment.pl>

From kristi.glover at hotmail.com  Wed Dec  4 05:29:45 2013
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 4 Dec 2013 00:29:45 -0400
Subject: [R] how to replace a text in a table by another text in R?
Message-ID: <COL129-W6775420AB90B12A4B49000FAD40@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/4981b612/attachment.pl>

From floridmercutio at yahoo.com  Wed Dec  4 04:09:48 2013
From: floridmercutio at yahoo.com (Nerd of Darkness)
Date: Wed, 04 Dec 2013 11:09:48 +0800
Subject: [R] What is the easiest way to interpolate vertical values on a
 square section of a nearly-planar 3D surface
In-Reply-To: <6ED4B09D-D1E0-4227-871C-1F1E6607AC3E@comcast.net>
References: <1386043350.1849.YahooMailNeo@web121005.mail.ne1.yahoo.com>
	<6ED4B09D-D1E0-4227-871C-1F1E6607AC3E@comcast.net>
Message-ID: <529E9CFC.103@yahoo.com>



On 2013?12?04? 08:21, David Winsemius wrote:
> library(car)
> # will also need rgl
> scatter3d(dat$X, dat$Y, dat$Value)
> 
> library(akima)
> akima.li <- interp(dat$X, dat$Y, dat$Value, 
>                    xo=seq(min(dat$X), max(dat$X), length = 100),
>                    yo=seq(min(dat$Y), max(dat$Y), length = 100))
> 
> persp(akima.li$z)
>  persp(akima.li$z, theta=30)
>  persp(akima.li$z, theta=45)
>  persp(akima.li$z, theta=60)
> 

The scatter3d was very impressive; in case other folks are following
along, I should note that I had to do

sudo apt-get install libglu1-mesa-dev

in order to get rgl to install x11 properly, but after that, the
animated interactive graphics were amazing, so thank you very much for
introducing me to that.

The akima package appears to be the best way to move forward on
interpolating the data.  I will try to use akima to make a slightly more
detailed grid and then try to put the output into contour.

Thanks!


From smartpink111 at yahoo.com  Wed Dec  4 04:29:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 3 Dec 2013 19:29:30 -0800 (PST)
Subject: [R] Sizing axis labels in ggplot2
In-Reply-To: <1386121712304-4681605.post@n4.nabble.com>
References: <1386121712304-4681605.post@n4.nabble.com>
Message-ID: <1386127770.55467.YahooMailNeo@web142605.mail.bf1.yahoo.com>



Hi,
Try:
bp+theme(axis.text=element_text(size=14),axis.title=element_text(size=16,face="bold"))

A.K.


On Tuesday, December 3, 2013 9:41 PM, David Arnold <dwarnold45 at suddenlink.net> wrote:
All,

Say I do:

require(ggplot2)
names(PlantGrowth)
bp <- ggplot(PlantGrowth,aes(x=group,y=weight))+geom_boxplot()

But the default axis labels and tick labels are just too small for me to
read.

What is the easiest was to enlarge the font size of axis labels and tick
labels?

Thanks.

D.



--
View this message in context: http://r.789695.n4.nabble.com/Sizing-axis-labels-in-ggplot2-tp4681605.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Dec  4 05:38:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 3 Dec 2013 20:38:32 -0800 (PST)
Subject: [R] how to replace a text in a table by another text in R?
In-Reply-To: <COL129-W6775420AB90B12A4B49000FAD40@phx.gbl>
References: <COL129-W6775420AB90B12A4B49000FAD40@phx.gbl>
Message-ID: <1386131912.11589.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Use ?paste()
dat1<- read.table(text="name????? value
central??? -10.91699497
western??? -10.16521404
upper??? -6.915860837
lower??? -6.546794281
southern -6.382722608",sep="",header=TRUE,stringsAsFactors=FALSE)

?number1 <- c(1,3,2,4,5) 

dat1[,1] <- paste0(number1,dat1[,1])
A.K.


On Tuesday, December 3, 2013 11:31 PM, Kristi Glover <kristi.glover at hotmail.com> wrote:
Hi R user, 
I have been struggling to add number in front of text. It mus t be easy. but I could not figure it out.
example
I have this data:
name? ? ? value
central? ?  -10.91699497
western? ?  -10.16521404
upper? ?  -6.915860837
lower? ?  -6.546794281
southern -6.382722608

I want to following. I want to add number in front of text. The number are not in sequence. 
name? ? ? ? value
1central? ? -10.91699497
3western? ? -10.16521404
2upper? ? ? ? -6.915860837
4lower? ? ? ? -6.546794281
5southern? ? -6.382722608
How can we find something in a table and replace by something in R? It could be easy in R but my data is so big so that Excel does not open the file. 
I would really appreciate your help. 



??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From sjtuliuli at gmail.com  Wed Dec  4 08:19:25 2013
From: sjtuliuli at gmail.com (Li Liu)
Date: Wed, 4 Dec 2013 15:19:25 +0800
Subject: [R] R sendmail ASPMX.L.GOOGLE.COM:25 cannot be opened
Message-ID: <CADnvbW4Zj48LLROJpRWYAzPw3pruWhjbnmQrkTpkTc--Ynz8iQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/9823f043/attachment.pl>

From martin.remo.studer at gmail.com  Wed Dec  4 08:46:26 2013
From: martin.remo.studer at gmail.com (Martin Studer)
Date: Wed, 4 Dec 2013 08:46:26 +0100
Subject: [R] XLConnect readWorksheet comma decimal sign
Message-ID: <CAD6FUO85KfaDOxr9Lg-dNsaWyEuC_N+T+mNsDeMHQbwW9P9qYA@mail.gmail.com>

Hi,

XLConnect can very well deal with missing values. By default, only
blank cells (cells not containing any values) will be treated as
missing values. Cells containing the text "NA" are not automatically
treated as missing values as "NA" is a valid non-missing text string.
If you want to treat the text "NA" as missing value identifier, you
can use the method setMissingValue.

Generally, XLConnect determines the column type based on the cell
types of the containing cells (yes, Excel cells are typed!).
Therefore, if there are cells with text, XLConnect will decide to read
that column in as text (treating missing value identifiers
accordingly, as described above). You may also use the arguments
colTypes and forceConversion for further controlling how cell values
should be interpreted.

Please see the reference manual for more detailed information.

Regards,
Martin


> no change when setting it to dot. I seems that XLConnect is not able to
> deal with NA in Excel, means its string instead an number after importing.


From 7146781 at qq.com  Wed Dec  4 07:52:50 2013
From: 7146781 at qq.com (=?gb18030?B?c25vdw==?=)
Date: Wed, 4 Dec 2013 14:52:50 +0800
Subject: [R] Problems with intersections between two charcter vectors
Message-ID: <tencent_68E5A1C1415362DF0DE6E8C5@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/1557dfde/attachment.pl>

From dwinsemius at comcast.net  Wed Dec  4 08:59:47 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 3 Dec 2013 23:59:47 -0800
Subject: [R] Calculate external validation
In-Reply-To: <CACY5Zse4gGSK-cAAX_ugQnCfn=GHhmr8tNEiKuPYJzCWapkQ8Q@mail.gmail.com>
References: <CACY5Zse4gGSK-cAAX_ugQnCfn=GHhmr8tNEiKuPYJzCWapkQ8Q@mail.gmail.com>
Message-ID: <383F3578-9E06-450D-BB4C-67EEE2D2E3EA@comcast.net>


On Dec 3, 2013, at 12:45 PM, Juan Manuel Reyes S wrote:

> Dear R-project
> 
> I could not validate one logistic model because when I used the function
> lrm.fit of the package rms the program showed a error message. It said that
> the variable Clam and offset must have same length.

Giving arguments of the same length to a regression function would certainly seem to be appropriate.

> 
> ext <- lrm.fit( ,Clam, offset="X")

"X" would be a one-element character vector. Cannot tell what the object `Clam` might be. I certainly hope you have not been using the `attach` function. That way lies madness.

The three first arguments to `lrm.fit` are:

x:
design matrix with no column for an intercept

y:
response vector, numeric, categorical, or character

offset:	
optional numeric vector containing an offset on the logit scale


> 
> In this case, Clam is variable depend or variable that we want to
> predictive and X is linear predictor of the other logistic model.

Other model?

> 
> We want to evaluate a logistic model in new data set.

Evaluate? Please explain in more detail what procedure you propose. The `validate` function in pkg:rms would need a fit object that has been created with  x=TRUE and y=TRUE.

> However, we don't
> have the development data set of logistic model, only we have the equation.
> We are using the function lrm.fit because it allows to use offset.

`lrm` does allow an offset by way of its formula argument. See Arguments section of ?lrm

> 
> What do you recommend me?
> 

I recommend that you give a more complete example of your data, your "model", and your code that presents what you actually do have in hand. 

-- 
David.

> Thank you member of R-project
> 
> Juan Manuel Reyes
> 
> 	[[alternative HTML version deleted]]
> 
> 


David Winsemius
Alameda, CA, USA


From jholtman at gmail.com  Wed Dec  4 09:00:39 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Wed, 4 Dec 2013 03:00:39 -0500
Subject: [R] Problems with intersections between two charcter vectors
In-Reply-To: <tencent_68E5A1C1415362DF0DE6E8C5@qq.com>
References: <tencent_68E5A1C1415362DF0DE6E8C5@qq.com>
Message-ID: <D47C1027-954C-4C0D-8E70-5262C7EF15B9@gmail.com>

the vectors in you first example look like a long character string since I only see quote marks at the beginning and end and notbon the individual objects, but it is hard to tell since it appears to be in HTML.

Sent from my iPad

On Dec 4, 2013, at 1:52, "snow" <7146781 at qq.com> wrote:

> I'm a beginner with R.
> 
> I have two vectors in character format. I tried to get the intersection of these two vectors using intersect????. But there is no result. The process is below:
>> a<-c("CREB2?? ,??ELK1?? ,??ELK4?? ,??MYC?? ,??NR4A1?? ,??FOS?? ,??SRF?? ,??TAU?? ,??STMN1?? ,??CPLA2")> a[1] "CREB2?? ,??ELK1?? ,??ELK4?? ,??MYC?? ,??NR4A1?? ,??FOS?? ,??SRF?? ,??TAU?? ,??STMN1?? ,??CPLA2"> b<-c("CAMK2??,??CPKC??,??CBL??,??STAT5A??,??FAK??,??ABL1??,??JUN??,??ELK1??,??MYC")> b[1] "CAMK2??,??CPKC??,??CBL??,??STAT5A??,??FAK??,??ABL1??,??JUN??,??ELK1??,??MYC"> intersect(a,b)character(0) 
> However when I tried intersect????with another two vectors, it works. The example is like this:
>> c<-c("a", "b", "e", "c", "e", "f")> c[1] "a" "b" "e" "c" "e" "f"> d<-c("a", "g", "f", "b", "e")> d[1] "a" "g" "f" "b" "e"> intersect(c,d)[1] "a" "b" "e" "f" 
> I think something must be wrong in my way with first two vectors(a,b). Could anyone give me a kind help to tell me the reason for that? Thank you very much.
> 
> 
> 
> Hui Xue
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Wed Dec  4 09:14:37 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 4 Dec 2013 09:14:37 +0100
Subject: [R] Problems with intersections between two charcter vectors
In-Reply-To: <tencent_68E5A1C1415362DF0DE6E8C5@qq.com>
References: <tencent_68E5A1C1415362DF0DE6E8C5@qq.com>
Message-ID: <8E0D7F77-9A87-4B9E-A0C8-4B3EA1015AFA@xs4all.nl>


On 04-12-2013, at 07:52, snow <7146781 at qq.com> wrote:

> I'm a beginner with R.
> 
> I have two vectors in character format. I tried to get the intersection of these two vectors using intersect??. But there is no result. The process is below:
>> a<-c("CREB2? ,?ELK1? ,?ELK4? ,?MYC? ,?NR4A1? ,?FOS? ,?SRF? ,?TAU? ,?STMN1? ,?CPLA2")> a[1] "CREB2? ,?ELK1? ,?ELK4? ,?MYC? ,?NR4A1? ,?FOS? ,?SRF? ,?TAU? ,?STMN1? ,?CPLA2"> b<-c("CAMK2?,?CPKC?,?CBL?,?STAT5A?,?FAK?,?ABL1?,?JUN?,?ELK1?,?MYC")> b[1] "CAMK2?,?CPKC?,?CBL?,?STAT5A?,?FAK?,?ABL1?,?JUN?,?ELK1?,?MYC"> intersect(a,b)character(0) 
> However when I tried intersect??with another two vectors, it works. The example is like this:
>> c<-c("a", "b", "e", "c", "e", "f")> c[1] "a" "b" "e" "c" "e" "f"> d<-c("a", "g", "f", "b", "e")> d[1] "a" "g" "f" "b" "e"> intersect(c,d)[1] "a" "b" "e" "f" 
> I think something must be wrong in my way with first two vectors(a,b). Could anyone give me a kind help to tell me the reason for that? Thank you very much.
> 

What is displayed in Apple Mail is a mess since you posted in html.

It seems that some of your double quotes ? have been converted somewhere to typographic double quotes (or however they should be called).
Some of your output is weird: a[1] would display ?CREB2? only and not what you show in your mail.

Doing it like this using proper ascii double quotes:

a<-c("CREB2" ,"ELK1" ,"ELK4" ,"MYC" ,"NR4A1" ,"FOS" ,"SRF" ,"TAU" ,"STMN1" ,"CPLA2")
b<-c("CAMK2","CPKC","CBL","STAT5A","FAK","ABL1","JUN","ELK1","MYC")

intersect(a,b)

displays:

[1] "ELK1" ?MYC"

which is what you expected?

Berend


> 
> Hui Xue
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From s.wood at bath.ac.uk  Wed Dec  4 10:02:46 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Wed, 04 Dec 2013 10:02:46 +0100
Subject: [R] significance of random effect in mgcv gam
In-Reply-To: <529E2C63.5070308@ucmerced.edu>
References: <529E2C63.5070308@ucmerced.edu>
Message-ID: <529EEFB6.4020606@bath.ac.uk>

 > Question. Am I correct that p = .126 above can be taken as the
 > p-value  associated with the random effect?

- Yes. See

http://biomet.oxfordjournals.org/content/100/4/1005.abstract

for details of the approximate test used.


On 03/12/13 20:09, William Shadish wrote:
> Dear R-helpers,
>
> I would like to test whether a random effect is significant when
> implemented with bs="re" in mgcv gam. For example, if I run:
>
> M3b <- gam(DVY  ~ s(SessIDX, fTX, bs = "re") + factor(TX),
>             data = PCP,
>             family = quasipoisson(link="log"), method="REML")
> summary(M3b,all.p=TRUE)
> gam.vcomp(M3b)
>
> I obtain the the following output:
>
>  > summary(M3b,all.p=TRUE)
>
> Family: quasipoisson
> Link function: log
>
> Formula:
> DVY ~ s(SessIDX, fTX, bs = "re") + factor(TX)
>
> Parametric coefficients:
>              Estimate Std. Error t value Pr(>|t|)
> (Intercept)   1.3282     0.2244   5.920 2.74e-07 ***
> factor(TX)1  -1.0546     0.7210  -1.463     0.15
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Approximate significance of smooth terms:
>                   edf Ref.df     F p-value
> s(SessIDX,fTX) 1.052      2 1.138   0.126
>
> R-sq.(adj) =  0.388   Deviance explained = 39.5%
> REML score =  37.67  Scale est. = 1.4172    n = 54
>  > gam.vcomp(M3b)
>
> Standard deviations and 0.95 confidence intervals:
>
>                    std.dev      lower     upper
> s(SessIDX,fTX) 0.07842742 0.01095655 0.5613865
> scale          1.19029872 0.97816911 1.4484316
>
> Rank: 2/2
>
> Question. Am I correct that p = .126 above can be taken as the p-value
> associated with the random effect?
>
> Thanks.
>
> Will Shadish
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From cscherb1 at gwdg.de  Wed Dec  4 11:16:27 2013
From: cscherb1 at gwdg.de (Scherber, Christoph)
Date: Wed, 4 Dec 2013 11:16:27 +0100
Subject: [R] Self-starting nonlinear power law function
Message-ID: <529F00FB.3030707@gwdg.de>

Dear all,

Has anyone written a self-starting power law function of the form

mypower=function(x,a,b,c){a+b*x^c}

?

Or is there a nonlinear regression package containing more selfStart() functions than nlme?

Thank you very much for your help!

Best wishes
Christoph

[running R 3.0.1 on Windows 7 32-Bit]


From mayer at iiasa.ac.at  Wed Dec  4 11:20:56 2013
From: mayer at iiasa.ac.at (MAYER Hans)
Date: Wed, 4 Dec 2013 11:20:56 +0100
Subject: [R] httpuv_1.2.0 : websockets-hybi03.cpp
Message-ID: <AEB6E9807EE5E04BA2F4A6CD4CE9DB198EDB2054C2@rhine.iiasa.ac.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/52be29b1/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Wed Dec  4 11:25:39 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 4 Dec 2013 11:25:39 +0100 (MET)
Subject: [R] interaction plot with SE bar
In-Reply-To: <COL129-W72B6F5CBAC14A8C6B9A480FAD50@phx.gbl>
References: <COL129-W72B6F5CBAC14A8C6B9A480FAD50@phx.gbl>
Message-ID: <Pine.SOC.4.64.1312041114270.12898@solcom.hrz.uni-giessen.de>

Hi, Kristi,

I have adapted the interaction plot example of function panel.average() of 
the lattice package and modified the code of panel.average() to a new 
function panel.loc_and_scale(). See below. (There might be a much simpler 
solution, though.)

Remark on the side: I can't resist to point you to Tatsuki Koyama's very 
instructive explanation on why plots of SE bars are not quite 
recommendable: 
http://biostat.mc.vanderbilt.edu/wiki/pub/Main/TatsukiRcode/Poster3.pdf


Nevertheless, here's the code (note that it also allows to graph other 
location +/- scale bars if you provide fun1 and fun2 with respective 
functions):

  Regards  --  Gerrit


panel.loc_and_scale <- function(x, y, fun1 = mean, fun2 = sd,
                                  horizontal = TRUE,
                                  lwd = add.line$lwd, lty = add.line$lty,
                                  col, col.line = add.line$col, ...) {
     x <- as.numeric(x)
     y <- as.numeric(y)
     add.line <- trellis.par.get( "add.line")
     if (!missing(col)) {
         if (missing(col.line))
             col.line <- col
     }
     if (horizontal) {
         vals <- unique(sort(y))
         yy <- seq_along(vals)
         xx1 <- xx2 <- numeric(length(yy))
         for (i in yy) {
          xx1[i] <- fun1(x[y == vals[i]])
          xx2[i] <- fun2(x[y == vals[i]])
          }
         panel.arrows( x0 = xx1 - xx2, y0 = vals[yy],
                       x1 = xx1 + xx2, y1 = vals[yy],
                       code = 3, angle = 90, length = 0.1,
                       col = col.line, lty = lty, lwd = lwd)
         panel.points( x = xx1, y = vals[yy], col = col, pch = 18)

     }
     else {
         vals <- unique(sort(x))
         xx <- seq_along(vals)
         yy1 <- yy2 <- numeric(length(xx))
         for (i in xx) {
          yy1[i] <- fun1(y[x == vals[i]])
          yy2[i] <- fun2(y[x == vals[i]])
          }
         panel.arrows( x0 = vals[xx], y0 = yy1 - yy2,
                       x1 = vals[xx], y1 = yy1 + yy2,
                       code = 3, angle = 90, length = 0.1,
                       col = col.line, lty = lty, lwd = lwd)
         panel.points( x = vals[xx], y = yy1, col = col, pch = 18)
     }
}


stripplot(yield ~ site, barley, groups = year,  # fun1 = median, fun2 = IQR,
        panel = function(x, y, groups, subscripts, ...) {
            panel.grid(h = -1, v = 0)
            panel.stripplot(x, y, ..., jitter.data = TRUE,
                            groups = groups, subscripts = subscripts)
            panel.superpose(x, y, ..., panel.groups = panel.loc_and_scale,
                            groups = groups, subscripts = subscripts)
            panel.superpose(x, y, ..., panel.groups = panel.average,
                            groups = groups, subscripts = subscripts)
        },
        auto.key = list(points = FALSE, lines = TRUE, columns = 2))



> Hi R user,
> I am just wondering how I can add Standard error bar in the interaction 
> plot. I used the following code but I don't know how i can edit this to 
> put a started error's bar on the mean.
> Would you give me some hints? or do other packages provide the 
> information about plotting the SE bar for interaction.plot?
>
> require(graphics)
> with(OrchardSprays, {
>  interaction.plot(treatment, rowpos, decrease)
>  interaction.plot(rowpos, treatment, decrease, cex.axis = 0.8)
>  ## order the rows by their mean effect
>  rowpos <- factor(rowpos,
>                   levels = sort.list(tapply(decrease, rowpos, mean)))
>  interaction.plot(rowpos, treatment, decrease, col = 2:9, lty = 1)
> })
>
> thanks


From 7146781 at qq.com  Wed Dec  4 11:53:42 2013
From: 7146781 at qq.com (=?utf-8?B?c25vdw==?=)
Date: Wed, 4 Dec 2013 18:53:42 +0800
Subject: [R] =?utf-8?q?reply=EF=BC=9A__Problems_with_intersections_between?=
 =?utf-8?q?_two_charcter_vectors?=
Message-ID: <tencent_5D8C35111C65AE285D560AC7@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/8d38d020/attachment.pl>

From cscherb1 at gwdg.de  Wed Dec  4 12:03:19 2013
From: cscherb1 at gwdg.de (Scherber, Christoph)
Date: Wed, 4 Dec 2013 12:03:19 +0100
Subject: [R] Self-starting nonlinear power law function
Message-ID: <529F0BF7.50309@gwdg.de>

Dear all,

I have just written the self-starting power law function myself. Here it is:

##
# Self-starting power law function written by C. Scherber

powermodel=function(x,a,b,c)
{a+b*x^c}

powermodelInit=function(mCall,LHS,data){
xy=sortedXyData(mCall[["x"]],LHS,data)
lmFit1=lm(xy[,"y"]~1) #for "intercept", a
lmFit2=lm(log(xy[,"y"])~log(xy[,"x"])) #for b and c
coefs1=coef(lmFit1)
coefs2=coef(lmFit2)
a=coefs1
b=exp(coefs2[1])
c=coefs2[2]
value=c(a,b,c)
names(value)=mCall[c("a","b","c")]
value
}

SSpower=selfStart(powermodel,powermodelInit,c("a","b","c"))

##

# make sure that x and y are positive when using the function.

Best wishes,
Christoph


From philipp.grueber at ebs.edu  Wed Dec  4 14:43:15 2013
From: philipp.grueber at ebs.edu (Philipp Grueber)
Date: Wed, 4 Dec 2013 05:43:15 -0800 (PST)
Subject: [R] Calculate Adjusted vcov Matrix acc. to Shanken(1992)
 (Generated Regressor Problem)
In-Reply-To: <1385820218832-4681404.post@n4.nabble.com>
References: <1385820218832-4681404.post@n4.nabble.com>
Message-ID: <1386164595443-4681631.post@n4.nabble.com>

Dear R Users, 

please find attached what I believe to be the solution to my problem. Note
that I am still not 100% sure if my approach really does what it is intended
to do and if it is applicable to my case at all. 

Any comment or correction is highly appreciated.

Best wishes,
Philipp




##################################################################
##################################################################
##################################################################


#packages
library(lmtest)

#Data
y<-rnorm(100)
x1<-rnorm(100)
x2<-x1+rnorm(100)/5
x3<-rnorm(100)

#Simulated multicollinearity in the data
plot(x1,x2)
cor(x1,x2)

#I wish to estimate y=c+x1+x2+x3+u but cor(x1,x2) is high. Therefore twostep
procedure: (1) x2~c1+x1+u1 (2) y=c2+x1+u1+x3+u2.
res1<-lm(x2~x1)
coeftest(res1,vcov.=vcov(res1))
vcov(res1)
#I am able to calculate this manually.
X1<-as.matrix(data.frame(A=rep(1,100),B=x1),stringsAsFactors=FALSE)
betas<-solve(crossprod(X1,X1))%*%t(X1)%*%x2
round(coef(res1),digits=10)==round(betas,digits=10)
betas
u1<-resid(res1)
n1<-length(y)
k1<-ncol(X1)
vcov1 = 1/(n1-k1) * as.numeric(t(u1)%*%u1) * solve(t(X1)%*%X1) #= 1/T
vcov1

#Now I do my second regression:
Y<-as.matrix(y)
X2<-as.matrix(data.frame(A=1,B=x1,C=u1,D=x3))
res2<-lm(y~x1+u1+x3)
coeftest(res2,vcov.=vcov(res2))
vcov(res2)
#This is the (biased) variance-covariance matrix:
u2<-resid(res2)
n2<-length(y)
k2<-ncol(X2)
vcov2 = 1/(n2-k2) * as.numeric(t(u2)%*%u2) * solve(t(X2)%*%X2) #= 1/T 
vcov2


#In order to implement the Shanken(1992) adjustment, I need to calculate the
variance-covariance matrix manually in the following way: (See Chochrane
(2005) Asset Pricing Ch.12):  
var_coef<-function(x){
x_mm<-model.matrix(x)
x_s2<-summary(x)$sigma^2
solve(t(x_mm)%*%x_mm)%*%t(x_mm)%*%(x_s2*diag(nobs(x)))%*%x_mm%*%solve(t(x_mm)%*%x_mm)
}
vcov_manual<-var_coef(x=res1)
vcov1
round(vcov1,digits=10)==round(vcov_manual,digits=10)
#I calculate the covariance matrix of the residuals cov(u,u').
cov_resid<-function(x){
x_mm<-model.matrix(x)
x_s2<-summary(x)$sigma^2
(diag(nobs(x))-x_mm%*%solve(t(x_mm)%*%x_mm)%*%t(x_mm))%*%(x_s2*diag(nobs(x)))%*%t(diag(nobs(x))-x_mm%*%solve(t(x_mm)%*%x_mm)%*%t(x_mm))
}
cov_resid<-cov_resid(x=res1)
cov_resid[95:100,95:100] #to show only a part
#Another way to go to:
H1<-X1%*%solve(t(X1)%*%X1)%*%t(X1)
((diag(100)-H1)*summary(res1)$sigma^2)[95:100,95:100]
#Seems to be correct
round(((diag(100)-H1)*summary(res1)$sigma^2)[95:100,95:100],digits=10)==round(cov_resid[95:100,95:100],digits=10)

#Now I include the Shanken adjustment:
...*(1+t(lambdas)%*%solve(sig_f)%*%lambdas)...
var_coef_adj<-function(x_1,x_2){
lambdas<-coef(x_2)
x_mm<-model.matrix(x_2)
x_s<-((diag(100)-H1)*summary(x_1)$sigma^2)
x_s_f<-vcov(x_2)
1/1*(solve(t(x_mm)%*%x_mm)%*%t(x_mm)%*%(x_s)%*%x_mm%*%solve(t(x_mm)%*%x_mm)*as.numeric(1+t(lambdas)%*%solve(x_s_f)%*%lambdas)+x_s_f)
}
vcov2_adj<-var_coef_adj(x_1=res1, x_2=res2)
var_coef_adj(x_1=res1, x_2=res2)

coeftest(res2)
coeftest(res2,vcov.=vcov2_adj)






-----
____________________________________
EBS Universitaet fuer Wirtschaft und Recht
FARE Department
Wiesbaden/ Germany
http://www.ebs.edu/index.php?id=finacc&L=0
--
View this message in context: http://r.789695.n4.nabble.com/Calculate-Adjusted-vcov-Matrix-acc-to-Shanken-1992-Generated-Regressor-Problem-tp4681404p4681631.html
Sent from the R help mailing list archive at Nabble.com.


From giulia.dilauro at gmail.com  Wed Dec  4 12:41:31 2013
From: giulia.dilauro at gmail.com (Giulia Di Lauro)
Date: Wed, 4 Dec 2013 12:41:31 +0100
Subject: [R] Variable importance - ANN
Message-ID: <CA+0e6--fFUUV8BtSTLuTgzK=3LfJxpTXimo=9ncf3oduevjMyQ@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/f7d13496/attachment.pl>

From smartpink111 at yahoo.com  Wed Dec  4 14:33:12 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 4 Dec 2013 05:33:12 -0800 (PST)
Subject: [R] how to replace a text in a table by another text in R?
In-Reply-To: <COL129-W22388DEB4B04CC03BC49E8FAD40@phx.gbl>
References: <COL129-W6775420AB90B12A4B49000FAD40@phx.gbl>,
	<1386131912.11589.YahooMailNeo@web142603.mail.bf1.yahoo.com>,
	<1386132003.5053.YahooMailNeo@web142601.mail.bf1.yahoo.com>,
	<COL129-W2116AC55609582590ACD29FAD40@phx.gbl>
	<COL129-W2003DC4933ADD128F84DA3FAD40@phx.gbl>,
	<1386134190.22573.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<COL129-W22388DEB4B04CC03BC49E8FAD40@phx.gbl>
Message-ID: <1386163992.42664.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi Kristi,
No problem.
Try:
library(stringr)

dat1[,1] <- factor(str_trim(dat1[,1]),labels=paste0(c(4,2,6,7,1,5,3),? levels(factor(str_trim(dat1[,1])))) )
?dat1[,1]
# [1] 1south???? 2north???? 3west????? 4east????? 1south???? 2north??? 
# [7] 5southeast 4east????? 6northeast 7northwest 1south???? 4east???? 
#[13] 3west????? 6northeast 1south??? 
Levels: 4east 2north 6northeast 7northwest 1south 5southeast 3west
A.K.






On Wednesday, December 4, 2013 2:49 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:

Hi Arun, 
Thank you so much for the message. I am very sorry for bothering you. I have attached an example of what I have and what I wanted (dat2). I have about 2500 rows. but here is only a portion of the data. 

Thanks once again for your help, Arun.
Thanks 

dat1<-structure(list(class = structure(c(5L, 2L, 8L, 1L, 5L, 2L, 7L, 
1L, 3L, 4L, 5L, 1L, 8L, 3L, 6L), .Label = c("east", "north", 
"northeast", "northwest", "south", "south ", "southeast", "west"
), class = "factor"), value = c(0.241084211, 0.95445978, 0.144307515, 
0.43654453, 0.92909045, 0.7824522, 0.649447435, 0.639809128, 
0.645497554, 0.761954955, 0.399209118, 0.335850182, 0.751427831, 
0.548944398, 0.406230898)), .Names = c("class", "value"), class = "data.frame", row.names = c(NA, 
-15L))

output
dat2<-structure(list(class = structure(c(1L, 3L, 4L, 5L, 1L, 3L, 6L,
5L, 7L, 8L, 1L, 5L, 4L, 7L, 2L), .Label = c("1south", "1south ",
"2north", "3west", "4east", "5southeast", "6northeast", "7northwest"
), class = "factor"), value = c(0.241084211, 0.95445978, 0.144307515,
0.43654453, 0.92909045, 0.7824522, 0.649447435, 0.639809128,
0.645497554, 0.761954955, 0.399209118, 0.335850182, 0.751427831,
0.548944398, 0.406230898)), .Names = c("class", "value"), class = "data.frame", row.names = c(NA,
-15L))


From lorenzo.isella at gmail.com  Wed Dec  4 15:07:55 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Wed, 4 Dec 2013 15:07:55 +0100
Subject: [R] 3D Strip Packing and R
Message-ID: <op.w7kmvhmazqkd1e@enea>

Dear All,
I am struggling with a 3D Strip Packing problem.
Briefly: you have a set of boxes (cuboids of variable sizes) that you want  
to put inside a (large) container of finite width and length (which are  
larger than those of any of the boxes) and infinite depth.
The goal is to minimize the final depth of my pile of boxes inside the  
container.
The boxes are allowed to float in mid air, but they cannot overlap and,  
although they can be rotated, their faces need always to be parallel or  
orthogonal to the container's walls. The boxes cannot overlap.
It is a hard optimization problem and I found a lot of literature about  
it, but I wonder if there is anything already implemented (or easily  
implementable) in R to tackle this kind of problems.
Any suggestion is welcome.
Cheers

Lorenzo


From imanchambari at gmail.com  Wed Dec  4 15:22:41 2013
From: imanchambari at gmail.com (Iman Chambari)
Date: Wed, 4 Dec 2013 06:22:41 -0800
Subject: [R] predict.arfima
Message-ID: <CADLvCGRvr-v48k3ZYB_g71+TmMRdtEXy7F-eekOwwGbSppyybg@mail.gmail.com>

hi all,
i have a question about R
this code for me not work: predict.arfima(x)
error: could not find function predict.arfima
i test other same code that error again : pred.arfima  predict.arima
 pred.arima
i installed packages: afmtools 1.0.5 1.0.8 arfima fracdiff longmemo
 tseries timeseries and other  needed packages! and run them.
my R version :3.0.2
i search internet very much but no answer!
please help me!!
i think that amftools1.0.4 is not compatible with R 3.0.2 and pred.arfima
just run in afmtools 1.0.4 and not afmtools 1.0.8
take a look on attachments
thank
regards!
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Untitled.png
Type: image/png
Size: 237636 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/d4f8141c/attachment.png>

From wshadish at ucmerced.edu  Wed Dec  4 15:56:02 2013
From: wshadish at ucmerced.edu (William Shadish)
Date: Wed, 4 Dec 2013 06:56:02 -0800
Subject: [R] significance of random effect in mgcv gam
In-Reply-To: <529EEFB6.4020606@bath.ac.uk>
References: <529E2C63.5070308@ucmerced.edu> <529EEFB6.4020606@bath.ac.uk>
Message-ID: <529F4282.8040900@ucmerced.edu>

Thank you, Simon.

On 12/4/2013 1:02 AM, Simon Wood wrote:
>  > Question. Am I correct that p = .126 above can be taken as the
>  > p-value  associated with the random effect?
>
> - Yes. See
>
> http://biomet.oxfordjournals.org/content/100/4/1005.abstract
>
> for details of the approximate test used.
>
>
> On 03/12/13 20:09, William Shadish wrote:
>> Dear R-helpers,
>>
>> I would like to test whether a random effect is significant when
>> implemented with bs="re" in mgcv gam. For example, if I run:
>>
>> M3b <- gam(DVY  ~ s(SessIDX, fTX, bs = "re") + factor(TX),
>>             data = PCP,
>>             family = quasipoisson(link="log"), method="REML")
>> summary(M3b,all.p=TRUE)
>> gam.vcomp(M3b)
>>
>> I obtain the the following output:
>>
>>  > summary(M3b,all.p=TRUE)
>>
>> Family: quasipoisson
>> Link function: log
>>
>> Formula:
>> DVY ~ s(SessIDX, fTX, bs = "re") + factor(TX)
>>
>> Parametric coefficients:
>>              Estimate Std. Error t value Pr(>|t|)
>> (Intercept)   1.3282     0.2244   5.920 2.74e-07 ***
>> factor(TX)1  -1.0546     0.7210  -1.463     0.15
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Approximate significance of smooth terms:
>>                   edf Ref.df     F p-value
>> s(SessIDX,fTX) 1.052      2 1.138   0.126
>>
>> R-sq.(adj) =  0.388   Deviance explained = 39.5%
>> REML score =  37.67  Scale est. = 1.4172    n = 54
>>  > gam.vcomp(M3b)
>>
>> Standard deviations and 0.95 confidence intervals:
>>
>>                    std.dev      lower     upper
>> s(SessIDX,fTX) 0.07842742 0.01095655 0.5613865
>> scale          1.19029872 0.97816911 1.4484316
>>
>> Rank: 2/2
>>
>> Question. Am I correct that p = .126 above can be taken as the p-value
>> associated with the random effect?
>>
>> Thanks.
>>
>> Will Shadish
>>
>
>

-- 
William R. Shadish
Distinguished Professor
Founding Faculty

Mailing Address:
William R. Shadish
University of California
School of Social Sciences, Humanities and Arts
5200 North Lake Rd
Merced CA  95343

Physical/Delivery Address:
University of California Merced
ATTN: William Shadish
School of Social Sciences, Humanities and Arts
Facilities Services Building A
5200 North Lake Rd.
Merced, CA 95343

209-228-4372 voice
209-228-4007 fax (communal fax: be sure to include cover sheet)
wshadish at ucmerced.edu
http://faculty.ucmerced.edu/wshadish/index.htm
http://psychology.ucmerced.edu


From andy_liaw at merck.com  Wed Dec  4 17:19:26 2013
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 4 Dec 2013 11:19:26 -0500
Subject: [R] Variable importance - ANN
In-Reply-To: <CA+0e6--fFUUV8BtSTLuTgzK=3LfJxpTXimo=9ncf3oduevjMyQ@mail.gmail.com>
References: <CA+0e6--fFUUV8BtSTLuTgzK=3LfJxpTXimo=9ncf3oduevjMyQ@mail.gmail.com>
Message-ID: <D5FA03935F7418419332B61CA255F65FA5B8C8160A@USCTMXP51012.merck.com>

You can try something like this:
http://pubs.acs.org/doi/abs/10.1021/ci050022a

Basically similar idea to what is done in random forests: permute predictor variable one at a time and see how much that degrades prediction performance.

Cheers,
Andy

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Giulia Di Lauro
Sent: Wednesday, December 04, 2013 6:42 AM
To: r-help at r-project.org
Subject: [R] Variable importance - ANN

Hi everybody,
I created a neural network for a regression analysis with package ANN, but
now I need to know which is the significance of each predictor variable in
explaining the dependent variable. I thought to analyze the weight, but I
don't know how to do it.

Thanks in advance,
Giulia Di Lauro.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From jun.shen.ut at gmail.com  Wed Dec  4 17:36:39 2013
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Wed, 4 Dec 2013 11:36:39 -0500
Subject: [R] How to generate a smoothed surface for a three dimensional
	dataset?
Message-ID: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/390d3f08/attachment.pl>

From federico.andreis at gmail.com  Wed Dec  4 17:46:36 2013
From: federico.andreis at gmail.com (Federico Andreis)
Date: Wed, 4 Dec 2013 17:46:36 +0100
Subject: [R] How to generate a smoothed surface for a three dimensional
	dataset?
In-Reply-To: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
Message-ID: <CAOEqqmB5eVjD_L4ek3CmcqTLrBrrrhfJKYJyJw66yM3RiG1HJw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/ee8a470a/attachment.pl>

From murdoch.duncan at gmail.com  Wed Dec  4 17:56:35 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 4 Dec 2013 11:56:35 -0500
Subject: [R] How to generate a smoothed surface for a three dimensional
 dataset?
In-Reply-To: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
Message-ID: <529F5EC3.5010309@gmail.com>

On 04/12/2013 11:36 AM, Jun Shen wrote:
> Hi,
>
> I have a dataset with two independent variables (x, y) and a response
> variable (z). I was hoping to generate a response surface by plotting x, y,
> z on a three dimensional plot. I can plot the data with rgl.points(x, y,
> z). I understand I may not have enough data to generate a surface. Is there
> a way to smooth out the data points to generate a surface? Thanks a lot.

There are many ways to do that.  You need to fit a model that predicts z 
from (x, y), and then plot the predictions from that model.
An example below follows yours.
>
> Jun
>
> ===========================
>
> An example:
>
> x<-runif(20)
> y<-runif(20)
> z<-runif(20)
>
> library(rgl)
> rgl.points(x,y,z)

Don't use rgl.points, use points3d() or plot3d().  Here's the full script:


x<-runif(20)
y<-runif(20)
z<-runif(20)

library(rgl)
plot3d(x,y,z)

fit <- lm(z ~ x + y + x*y + x^2 + y^2)

xnew <- seq(min(x), max(x), len=20)
ynew <- seq(min(y), max(y), len=20)
df <- expand.grid(x = xnew,
                   y = ynew)

df$z <- predict(fit, newdata=df)

surface3d(xnew, ynew, df$z, col="red")


Duncan Murdoch
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kevinod at bu.edu  Wed Dec  4 16:49:35 2013
From: kevinod at bu.edu (kevinod)
Date: Wed, 4 Dec 2013 07:49:35 -0800 (PST)
Subject: [R] R survAUC Package
Message-ID: <1386172175431-4681638.post@n4.nabble.com>

I have a concern about the survAUC package option AUC.cd.  

I am exploring package functionality, specifically AUC statistics for Cox
Regression, for a small academic project

When utilizing this package on the ovarian data set within that package I
obtain an AUC statistic of 0.3322928.  When AUC calculations use a
dichotomous outcome such as this, see included R code, the result should lie
between 0.5 and 1, not 0.33.

Please explain this, I am not certain that the algorithm that is being
utilized for this package is correct.

Thank you

Kevin O?Donnell, MS Work Environment, MS Env Eng.,  MS Const Project Mgmt
Graduate Student
Department of Biostatistics
Boston University School of Public Health
715 Albany Street Boston, MA

617-480-1677

x11(h=8,w=11)
fit = survfit(Surv(futime,fustat) ~ rx)
plot(fit, mark.time=FALSE, xscale=365.25,main="Plot of Survival Curves by
Prescription Status",
        xlab='Length of Survival', ylab='Proportion of Individuals who have
Survived')
lines(fit[1], lwd=3,lty=2:3, xscale=365.24,col=2)
lines(fit[2], lwd=2,lty=2:2, xscale=365.24,col=3)
legend(.2,.2, c("No treatment", "treatment"), lwd=3,lty = 2:3) 


TR2 = ovarian[1:16,]
TE2 = ovarian[17:26,]
train.fit2  = coxph(Surv(futime, fustat) ~ rx,
                    x=TRUE, y=TRUE, method="efron", data=TR)
lp2 = predict(train.fit) 
lpnew2 = predict(train.fit2, newdata=TE2)
Surv.rsp2 = Surv(TR2$futime, TR2$fustat)
Surv.rsp.new2 = Surv(TE2$futime, TE2$fustat)
times2 = seq(10, 1000, 10)                  
 
AUC_CD2 = AUC.cd(Surv.rsp2, Surv.rsp.new2, lp2, lpnew2, times2)


AUC_hc2 = AUC.hc(Surv.rsp2, Surv.rsp.new2, lpnew2, times2)


AUC_sh2 = AUC.sh(Surv.rsp2, Surv.rsp.new2, lp2, lpnew2, times2)


AUC_Uno2 = AUC.uno(Surv.rsp2, Surv.rsp.new2, lpnew2, times2)




--
View this message in context: http://r.789695.n4.nabble.com/R-survAUC-Package-tp4681638.html
Sent from the R help mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Wed Dec  4 19:37:59 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 4 Dec 2013 13:37:59 -0500
Subject: [R] How to generate a smoothed surface for a three dimensional
 dataset?
In-Reply-To: <D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
	<529F5EC3.5010309@gmail.com>
	<D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>
Message-ID: <529F7687.2040200@gmail.com>

On 04/12/2013 1:30 PM, David Winsemius wrote:
>
> On Dec 4, 2013, at 8:56 AM, Duncan Murdoch wrote:
>
>> On 04/12/2013 11:36 AM, Jun Shen wrote:
>>> Hi,
>>>
>>> I have a dataset with two independent variables (x, y) and a response
>>> variable (z). I was hoping to generate a response surface by 
>>> plotting x, y,
>>> z on a three dimensional plot. I can plot the data with rgl.points(x, y,
>>> z). I understand I may not have enough data to generate a surface. 
>>> Is there
>>> a way to smooth out the data points to generate a surface? Thanks a lot.
>>
>> There are many ways to do that.  You need to fit a model that 
>> predicts z from (x, y), and then plot the predictions from that model.
>> An example below follows yours.
>>>
>>> Jun
>>>
>>> ===========================
>>>
>>> An example:
>>>
>>> x<-runif(20)
>>> y<-runif(20)
>>> z<-runif(20)
>>>
>>> library(rgl)
>>> rgl.points(x,y,z)
>>
>> Don't use rgl.points, use points3d() or plot3d().  Here's the full 
>> script:
>>
>>
>> x<-runif(20)
>> y<-runif(20)
>> z<-runif(20)
>>
>> library(rgl)
>> plot3d(x,y,z)
>>
>> fit <- lm(z ~ x + y + x*y + x^2 + y^2)
>>
>
>  Newcomers to R may think they would be getting a quadratic in x and 
> y. But R's formula interpretation will collapse x^2 to just x and then 
> it becomes superfluous and is discarded. The same result is obtained 
> with z ~ (x + y)^2).   I would have thought that this would have been 
> the code:
>
> fit <- lm(z ~ poly(x,2) +poly(y,2) + x:y )

Oops, thanks for the correction.  I had intended the full 2nd order 
polynomial.

Duncan Murdoch
>
>
>> xnew <- seq(min(x), max(x), len=20)
>> ynew <- seq(min(y), max(y), len=20)
>> df <- expand.grid(x = xnew,
>>                  y = ynew)
>>
>> df$z <- predict(fit, newdata=df)
>>
>> surface3d(xnew, ynew, df$z, col="red")
>
> With the modified fitting formula one sees a nice saddle (for that 
> particular random draw) using rgl.snapshot().
>
> The result with the earlier formula is a more restrained:
>
>
>
> Continued thanks to you Duncan for making this great tool available.
>
> -- 
> David.
>
>
>> Duncan Murdoch
>>>
>
> David Winsemius
> Alameda, CA, USA
>


From vigibos at eio.upv.es  Wed Dec  4 20:09:26 2013
From: vigibos at eio.upv.es (Vicent Giner-Bosch)
Date: Wed, 4 Dec 2013 20:09:26 +0100
Subject: [R] Repeated me
Message-ID: <CAHfSo7iJAjLghxukfBfY=pUVRDQD7f7BRp4fnfzCf+1Ybx81Og@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/2d555135/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Wed Dec  4 20:36:24 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 04 Dec 2013 14:36:24 -0500
Subject: [R] Repeated me
In-Reply-To: <CAHfSo7iJAjLghxukfBfY=pUVRDQD7f7BRp4fnfzCf+1Ybx81Og@mail.gmail.com>
References: <CAHfSo7iJAjLghxukfBfY=pUVRDQD7f7BRp4fnfzCf+1Ybx81Og@mail.gmail.com>
Message-ID: <abdc676d-bbfa-40cb-9970-0e90a735bf2b@email.android.com>

a) Cross posting is not something to apologize for... it is something to not do.

b) This message is off topic here. Please read the Posting Guide mentioned in the footer of this or any other any R-help message before posting here again.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Vicent Giner-Bosch <vigibos at eio.upv.es> wrote:
>[ I've also sent this message to other lists. Sorry for multiple
>messaging ]
>
>Dear colleagues,
>
>I want to perform a repeated measures two-way ANOVA (two fixed crossed
>factors). I've found the way to do it (in SPSS, and also in R), but
>anyway
>I think my data don't meet the requirements for that analysis (that is,
>normality, sphericity and so on).
>
>Anyway, I was told (here in this list and also in person) to consider
>the
>subjects IDs as a third factor, and to perform a classical ANOVA
>(because
>if I do that I will have one single observation for each combination of
>the
>three factors). That way, I wouldn't need to check for "sphericity" but
>for
>the usual ANOVA assumptions.
>
>My first question is related to that:
>
>(1) Just for checking if I understood this right: are both (parametric)
>approaches equivalent? I mean: is "pure" repeated measures ANOVA (the
>one
>available in SPSS, for instance) equivalent to by-passing it by making
>subjects work as a factor and then applying "classical" ANOVA?
>
>Another different approach is using non-parametric alternatives. I've
>found
>ONE-way non-parametric tests both for repeated measures comparisons and
>for
>independent sets of observations. And also I've been told about the
>existence of multiple-factor non-parametric ANOVA (based on ranks, and
>also
>based on permutation exact tests).
>
>My research is not about ANOVA; I just want to use it as a way to
>compare
>results in a more sophisticated and scientific way than just saying
>which
>combination is better. So I am looking for the easiest approach.
>
>And because of that, I am thinking of performing an exact
>(permutation-based, non-parametric) ANOVA, using subjects as a factor.
>
>(2) I know that I didn't tell you anything about my data or my context,
>but
>do you think that approach can be appropriate?
>
>Looking forward to your answers,
>
>
>--
>vicent
>@vginer_upv
>about.me/vginer_upv
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From elvis at xlsolutions-corp.com  Wed Dec  4 21:34:34 2013
From: elvis at xlsolutions-corp.com (elvis at xlsolutions-corp.com)
Date: Wed, 04 Dec 2013 13:34:34 -0700
Subject: [R] R course in Boston December 19-20
Message-ID: <20131204133434.aa8924c5d28ca71e2a043bb294e795eb.dab086d70f.wbe@email22.secureserver.net>

XLSolutions R course in Boston December 19-20. Please email me for
registration.

Check out other cities at 
http://www.xlsolutions-corp.com/courselistlisting.aspx

Ask for group discount and reserve your seat Now - Earlybird Rates.
 Payment due after the class! Email Sue Turner: sue at
xlsolutions-corp.com

 Phone: 206-686-1578


 Please let us know if you and your colleagues are interested in this
 class to take advantage of group discount. Register now to secure your
 seat.

 Cheers,
 Elvis Miller, PhD
 Manager Training.
 XLSolutions Corporation
 206 686 1578
www.xlsolutions-corp.com
 elvis at xlsolutions-corp.com


From aanas at feps.edu.eg  Wed Dec  4 21:07:04 2013
From: aanas at feps.edu.eg (Aya Anas)
Date: Wed, 4 Dec 2013 23:07:04 +0300
Subject: [R] Double Infinite Integration
Message-ID: <CAB=y=yM=1Oqbm3d3Msdeoq7ORvSaxEo8jkLf=HNeNViw8AFXVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/1aecf7d0/attachment.pl>

From dwinsemius at comcast.net  Wed Dec  4 19:30:45 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 4 Dec 2013 10:30:45 -0800
Subject: [R] How to generate a smoothed surface for a three dimensional
	dataset?
In-Reply-To: <529F5EC3.5010309@gmail.com>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
	<529F5EC3.5010309@gmail.com>
Message-ID: <D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>


On Dec 4, 2013, at 8:56 AM, Duncan Murdoch wrote:

> On 04/12/2013 11:36 AM, Jun Shen wrote:
>> Hi,
>> 
>> I have a dataset with two independent variables (x, y) and a response
>> variable (z). I was hoping to generate a response surface by plotting x, y,
>> z on a three dimensional plot. I can plot the data with rgl.points(x, y,
>> z). I understand I may not have enough data to generate a surface. Is there
>> a way to smooth out the data points to generate a surface? Thanks a lot.
> 
> There are many ways to do that.  You need to fit a model that predicts z from (x, y), and then plot the predictions from that model.
> An example below follows yours.
>> 
>> Jun
>> 
>> ===========================
>> 
>> An example:
>> 
>> x<-runif(20)
>> y<-runif(20)
>> z<-runif(20)
>> 
>> library(rgl)
>> rgl.points(x,y,z)
> 
> Don't use rgl.points, use points3d() or plot3d().  Here's the full script:
> 
> 
> x<-runif(20)
> y<-runif(20)
> z<-runif(20)
> 
> library(rgl)
> plot3d(x,y,z)
> 
> fit <- lm(z ~ x + y + x*y + x^2 + y^2)
> 

 Newcomers to R may think they would be getting a quadratic in x and y. But R's formula interpretation will collapse x^2 to just x and then it becomes superfluous and is discarded. The same result is obtained with z ~ (x + y)^2).   I would have thought that this would have been the code:

fit <- lm(z ~ poly(x,2) +poly(y,2) + x:y )


> xnew <- seq(min(x), max(x), len=20)
> ynew <- seq(min(y), max(y), len=20)
> df <- expand.grid(x = xnew,
>                  y = ynew)
> 
> df$z <- predict(fit, newdata=df)
> 
> surface3d(xnew, ynew, df$z, col="red")

With the modified fitting formula one sees a nice saddle (for that particular random draw) using rgl.snapshot().


The result with the earlier formula is a more restrained:




Continued thanks to you Duncan for making this great tool available.

-- 
David.


> Duncan Murdoch
>> 

David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Wed Dec  4 22:37:16 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 4 Dec 2013 13:37:16 -0800
Subject: [R] How to generate a smoothed surface for a three dimensional
	dataset?
In-Reply-To: <D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
	<529F5EC3.5010309@gmail.com>
	<D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>
Message-ID: <CACk-te1TNCT-WcH8-wnYD5p+8erLOTB=5B=p1WZZAzmggc__MQ@mail.gmail.com>

... or, more simply

lm(z ~ polym(x,y, degree=2) )

?polym

Cheers,
Bert





On Wed, Dec 4, 2013 at 10:30 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Dec 4, 2013, at 8:56 AM, Duncan Murdoch wrote:
>
>> On 04/12/2013 11:36 AM, Jun Shen wrote:
>>> Hi,
>>>
>>> I have a dataset with two independent variables (x, y) and a response
>>> variable (z). I was hoping to generate a response surface by plotting x, y,
>>> z on a three dimensional plot. I can plot the data with rgl.points(x, y,
>>> z). I understand I may not have enough data to generate a surface. Is there
>>> a way to smooth out the data points to generate a surface? Thanks a lot.
>>
>> There are many ways to do that.  You need to fit a model that predicts z from (x, y), and then plot the predictions from that model.
>> An example below follows yours.
>>>
>>> Jun
>>>
>>> ===========================
>>>
>>> An example:
>>>
>>> x<-runif(20)
>>> y<-runif(20)
>>> z<-runif(20)
>>>
>>> library(rgl)
>>> rgl.points(x,y,z)
>>
>> Don't use rgl.points, use points3d() or plot3d().  Here's the full script:
>>
>>
>> x<-runif(20)
>> y<-runif(20)
>> z<-runif(20)
>>
>> library(rgl)
>> plot3d(x,y,z)
>>
>> fit <- lm(z ~ x + y + x*y + x^2 + y^2)
>>
>
>  Newcomers to R may think they would be getting a quadratic in x and y. But R's formula interpretation will collapse x^2 to just x and then it becomes superfluous and is discarded. The same result is obtained with z ~ (x + y)^2).   I would have thought that this would have been the code:
>
> fit <- lm(z ~ poly(x,2) +poly(y,2) + x:y )
>
>
>> xnew <- seq(min(x), max(x), len=20)
>> ynew <- seq(min(y), max(y), len=20)
>> df <- expand.grid(x = xnew,
>>                  y = ynew)
>>
>> df$z <- predict(fit, newdata=df)
>>
>> surface3d(xnew, ynew, df$z, col="red")
>
> With the modified fitting formula one sees a nice saddle (for that particular random draw) using rgl.snapshot().
>
>
> The result with the earlier formula is a more restrained:
>
>
>
>
> Continued thanks to you Duncan for making this great tool available.
>
> --
> David.
>
>
>> Duncan Murdoch
>>>
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From r.turner at auckland.ac.nz  Wed Dec  4 22:58:12 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 05 Dec 2013 10:58:12 +1300
Subject: [R] predict.arfima
In-Reply-To: <CADLvCGRvr-v48k3ZYB_g71+TmMRdtEXy7F-eekOwwGbSppyybg@mail.gmail.com>
References: <CADLvCGRvr-v48k3ZYB_g71+TmMRdtEXy7F-eekOwwGbSppyybg@mail.gmail.com>
Message-ID: <529FA574.1040103@auckland.ac.nz>



?RSiteSearch

     cheers,

     Rolf Turner

On 12/05/13 03:22, Iman Chambari wrote:
> hi all,
> i have a question about R
> this code for me not work: predict.arfima(x)
> error: could not find function predict.arfima
> i test other same code that error again : pred.arfima  predict.arima
>   pred.arima
> i installed packages: afmtools 1.0.5 1.0.8 arfima fracdiff longmemo
>   tseries timeseries and other  needed packages! and run them.
> my R version :3.0.2
> i search internet very much but no answer!
> please help me!!
> i think that amftools1.0.4 is not compatible with R 3.0.2 and pred.arfima
> just run in afmtools 1.0.4 and not afmtools 1.0.8
> take a look on attachments


From smartpink111 at yahoo.com  Thu Dec  5 00:03:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 4 Dec 2013 15:03:57 -0800 (PST)
Subject: [R] ggplot2 font size and bold
Message-ID: <1386198237.13980.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Try:?theme(axis.title=element_text(face="bold",size="14",color="brown"),axis.text=element_text(size=14,face="bold")) 

A.K.


How can I increase the size and make bold of the items named under 
outcome in the example data set? I can make changes to label outcome, 
but not to individual components(alcohol, coffee etc.. ). ?Likewise, I 
?want to make similar changes in the vertical y axis numbers. 

ggplot(df2, aes(x = exp, y = pinc, ymin = lcinc, ymax = ucinc)) + 
? geom_linerange(position=position_dodge(width=0.70)) + geom_point( size = 4.5) ?+ 
? ylab("Percent Increase in Mortality") + ? geom_hline(aes(yintercept = 0)) + xlab("Outcome") + 
? theme(axis.title=element_text(face="bold",size="14", color="brown")) 



structure(list(pinc = c(0.456634704861525, -0.0917186505511203, 
0.0521212509666302, 0.123917574729071, -0.0152774251113263, 0.414372936947638 
), lcinc = c(0.0652757441790275, -0.51362763597802, -0.365701941999952, 
-0.293047384315104, -0.430895718383173, -0.00366607270897434), 
? ? ucinc = c(0.849524284781999, 0.331979596940069, 0.471696613858441, 
? ? 0.542626241433619, 0.402075729259721, 0.83415957680959), 
? ? exp = c("smoke", "diabetes", "hyper", "coffee", "alcohol", 
? ? "stress")), .Names = c("pinc", "lcinc", "ucinc", "exp"), class = "data.frame", row.names = c("1", 
"2", "3", "4", "5", "6"))


From wshadish at ucmerced.edu  Thu Dec  5 01:48:08 2013
From: wshadish at ucmerced.edu (William Shadish)
Date: Wed, 4 Dec 2013 16:48:08 -0800
Subject: [R] mgcv gam modeling trend variation over cases
Message-ID: <529FCD48.5050301@ucmerced.edu>

Dear R-Helpers,

I posted two days ago on testing significance of random effects in mgcv, 
but realize I did not make my overall purpose clear. I have a series of 
N short time series, where N might range from 3-10 and short means a 
median of 20 time points. The sample data below (PCP) has N = 4 cases 
with 9, 13, 16 and 16 observations over time respectively. The data set 
contains four variables: PID = case number, SessIDX = time (x axis), DVY 
= the outcome (y axis) and TX is treatment is applied = 1 or not = 0.

My goal is to determine (a) is trend present in each case, (b) is it 
linear or nonlinear in each case, and (c) does trend vary significantly 
over cases (PID), the latter presumably to be measured with a random 
effect. I can do the first two (not shown here), but am not sure about 
the third. I am using generalized additive models, either mgcv gam or 
gamm4. For example, using mgcv gam my syntax is

M1 <- gam(DVY  ~ s(SessIDX, bs = "re") + factor(TX),
            data = PCP,
            family = quasipoisson(link="log"), method="REML")
summary(M1,all.p=TRUE)
gam.vcomp(M1)

Using gamm4, my syntax is

PCP$fPID <- factor(PCP$PID)
M2 <- gamm4(DVY ~ factor(TX) + s(SessIDX, by = factor(PID)),
            data = PCP,
            random =~ (1|fPID),
            family = poisson (link="log"))
summary(M2$gam)
summary(M2$mer)

It is not clear to me whether either of these gives me what I want. In 
generalized linear mixed models, I am accustomed to the HLM approach 
(e.g., Raudenbush & Bryk) where each case would have a trend 
coefficient, and the random effect would tell me if those four 
coefficients varied significantly. So that is what I am looking for, but 
adding the nonlinearity modeling of GAM. Is either of these formulations 
giving me what I want--a test of whether trend differs significantly 
over cases or not.

Thanks for any help you can offer. I have worked very hard to solve this 
on my own, and just can't seem to do so.

Will Shadish

 > PCP
    PID SessIDX DVY TX
1    1       1   4  0
2    1       2   5  0
3    1       3   5  0
4    1       4   8  0
5    1       5   3  1
6    1       6   0  1
7    1       7   0  1
8    1       8   0  1
9    1       9   0  1
10   2       1   2  0
11   2       2   2  0
12   2       3   4  0
13   2       4   4  0
14   2       5   4  0
15   2       6   2  0
16   2       7   3  0
17   2       8   1  1
18   2       9   2  1
19   2      10   3  1
20   2      11   1  1
21   2      12   0  1
22   2      13   0  1
23   3       1   7  0
24   3       2   3  0
25   3       3   2  0
26   3       4   5  0
27   3       5   3  0
28   3       6   4  0
29   3       7   3  0
30   3       8   0  1
31   3       9   3  1
32   3      10   2  1
33   3      11   0  1
34   3      12   0  1
35   3      13   2  1
36   3      14   0  1
37   3      15   1  1
38   3      16   1  1
39   4       1   3  0
40   4       2   1  0
41   4       3   1  0
42   4       4   0  0
43   4       5   1  0
44   4       6   2  0
45   4       7   3  0
46   4       8   0  0
47   4       9   1  0
48   4      10   0  1
49   4      11   0  1
50   4      12   0  1
51   4      13   0  1
52   4      14   0  1
53   4      15   0  1
54   4      16   0  1
 >


-- 
William R. Shadish
Distinguished Professor
Founding Faculty

Mailing Address:
William R. Shadish
University of California
School of Social Sciences, Humanities and Arts
5200 North Lake Rd
Merced CA  95343

Physical/Delivery Address:
University of California Merced
ATTN: William Shadish
School of Social Sciences, Humanities and Arts
Facilities Services Building A
5200 North Lake Rd.
Merced, CA 95343

209-228-4372 voice
209-228-4007 fax (communal fax: be sure to include cover sheet)
wshadish at ucmerced.edu
http://faculty.ucmerced.edu/wshadish/index.htm
http://psychology.ucmerced.edu


From mxkuhn at gmail.com  Thu Dec  5 02:35:59 2013
From: mxkuhn at gmail.com (Max Kuhn)
Date: Wed, 4 Dec 2013 20:35:59 -0500
Subject: [R] Variable importance - ANN
In-Reply-To: <CA+0e6--fFUUV8BtSTLuTgzK=3LfJxpTXimo=9ncf3oduevjMyQ@mail.gmail.com>
References: <CA+0e6--fFUUV8BtSTLuTgzK=3LfJxpTXimo=9ncf3oduevjMyQ@mail.gmail.com>
Message-ID: <CAJ9CoW=8NadS311AS4M4KcvLwSxJvTLdWDh-dYzzR+1sfLpvYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/c7864c42/attachment.pl>

From lopez235 at llnl.gov  Thu Dec  5 03:10:24 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Thu, 5 Dec 2013 02:10:24 +0000
Subject: [R] pROC plot.roc - Plotting more than two curves - Is it possible
Message-ID: <56180B40A4F72A4083C75B30DA86297333DB72B4@PRDEXMBX-05.the-lab.llnl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/2f32bbcc/attachment.pl>

From mmuurr at gmail.com  Thu Dec  5 03:18:10 2013
From: mmuurr at gmail.com (Murat Tasan)
Date: Wed, 4 Dec 2013 21:18:10 -0500
Subject: [R] pROC plot.roc - Plotting more than two curves - Is it
	possible
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DB72B4@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DB72B4@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <CA+YV+HyL9Mmq9O6TG5j56Szb_aj-hjukVn57jERH4k-veesuwg@mail.gmail.com>

have you looked at the ROCR package?
there are at least a few ways to plot multiple ROC curves with the
ROCR functions that come to mind.
e.g. if you pass lists of 'scores' and 'labels' in to the
prediction(...) method, the default plot(...) method will display all
of the ROC (or precision-recall, or whichever measure you like)
curves.
another method is to run the prediction(...) and performance(...)
functions separately for your cases, then use the plot(..., add =
TRUE) command.
or you could even extract the x,y coordinates from the performance
objects themselves and use lines(...) and/or points(...).

cheers,

-murat

On Wed, Dec 4, 2013 at 9:10 PM, Lopez, Dan <lopez235 at llnl.gov> wrote:
> Hi R Experts,
>
> The info in this link suggests that plot in the pROC package can only compare two ROC curves at one time.
> https://stat.ethz.ch/pipermail/r-packages/2011/001220.html
>
> But this is from a couple of years ago. Curious if that has changed and if anyone knows how to plot more than one ROC curve using this package?
> If not can you please point me to good link/example on how to plot multiple ROC curves on one plot using another package?
>
> Thanks
> Dan Lopez
> Workforce Analyst
> LLNL
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Thu Dec  5 03:53:25 2013
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 4 Dec 2013 19:53:25 -0700
Subject: [R] importing many csv files into separate matrices
In-Reply-To: <1385591991.65178.YahooMailBasic@web184301.mail.ne1.yahoo.com>
References: <1385591991.65178.YahooMailBasic@web184301.mail.ne1.yahoo.com>
Message-ID: <CAFEqCdwkYxfppiaZRfZT2_R1o=MeUdnqFE=GMiJ30NQd6acTzQ@mail.gmail.com>

As you have noticed, using assign is not simple, and your approach has
potential to cause even more problems even if you get it working.
Here is another approach:

loadCSVfiles <- function(path) {
  x <- list.files(path, full.names=TRUE)
  out <- lapply( x, read.csv )
  names(out) <- sub(pattern="\\.csv$", replacement="", x)
  out
}

then run:

mydata <- loadCSVfiles("/my/path")

and mydata will be a list with all of your data objects with the
desired names.  You can do things like:

plot(mydata$alaska)

or

with(mydata, plot(alaska))

or

lapply( mydata, plot )

etc.

This approach does not place the individual objects into the global
workspace, but that is a good thing.

On Wed, Nov 27, 2013 at 3:39 PM, yetik serbest <yserbest at prodigy.net> wrote:
> Hi Everyone,
>
> I am trying to import many CSV files to their own matrices. Example, alaska_93.csv to alaska. When I execute the following, for each csv.file separately it is successful.
>
> singleCSVFile2Matrix <- function(x,path) {
>  assign(gsub(pattern=".csv",x,replacement=""),read.csv(paste(path,x,sep="")))
> }
>
> when I try to include it in a loop in another function (I have so many csv files to import), it doesn't work. I mean the following function doesn't do it.
>
> loadCSVFiles_old <- function(path) {
>  x <- list.files(path)
>  for (i in 1:length(x)) {
>   assign(gsub(pattern=".csv",x[i],replacement=""),read.csv(paste(path,x[i],sep="")))
>   }
> }
>
> Instead, if I execute the foor loop in the command line, it works. I am puzzled. Appreciate any help.
>
> thanks
> yetik
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From hb at biostat.ucsf.edu  Thu Dec  5 05:55:28 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 4 Dec 2013 20:55:28 -0800
Subject: [R] importing many csv files into separate matrices
In-Reply-To: <CAFEqCdwkYxfppiaZRfZT2_R1o=MeUdnqFE=GMiJ30NQd6acTzQ@mail.gmail.com>
References: <1385591991.65178.YahooMailBasic@web184301.mail.ne1.yahoo.com>
	<CAFEqCdwkYxfppiaZRfZT2_R1o=MeUdnqFE=GMiJ30NQd6acTzQ@mail.gmail.com>
Message-ID: <CAFDcVCRdhrEOsO19p4Z6PxMVXtzViFdSZJa1vtObyoWSRQyayA@mail.gmail.com>

On Wed, Dec 4, 2013 at 6:53 PM, Greg Snow <538280 at gmail.com> wrote:
> As you have noticed, using assign is not simple, and your approach has
> potential to cause even more problems even if you get it working.
> Here is another approach:
>
> loadCSVfiles <- function(path) {
>   x <- list.files(path, full.names=TRUE)
>   out <- lapply( x, read.csv )
>   names(out) <- sub(pattern="\\.csv$", replacement="", x)
>   out
> }
>
> then run:
>
> mydata <- loadCSVfiles("/my/path")

I fully agree with this; instead of messing around with assign() -
ending up using assign() is often a good indicator that there is
another better way to do it.

BTW, read.csv() returns a data.frame (not a matrix) just as read.table() do.

An alternative to the above loadCSVfiles() function, is to use the
R.filesets package, e.g.

library("R.filesets")
ds <- TabularTextFileSet$byPath("/my/path", pattern="[.]csv$")
mydata <- lapply(ds, FUN=readDataFrame)

That also sets the names by the filenames w/out the extension.  If one
don't like that style, the same thing can be achieved by:

library("R.filesets")
files <- dir(path="/my/path", pattern="[.]csv$", full.names=TRUE)
mydata <- readDataFrame(files, combineBy=NULL)

/Henrik

>
> and mydata will be a list with all of your data objects with the
> desired names.  You can do things like:
>
> plot(mydata$alaska)
>
> or
>
> with(mydata, plot(alaska))
>
> or
>
> lapply( mydata, plot )
>
> etc.
>
> This approach does not place the individual objects into the global
> workspace, but that is a good thing.
>
> On Wed, Nov 27, 2013 at 3:39 PM, yetik serbest <yserbest at prodigy.net> wrote:
>> Hi Everyone,
>>
>> I am trying to import many CSV files to their own matrices. Example, alaska_93.csv to alaska. When I execute the following, for each csv.file separately it is successful.
>>
>> singleCSVFile2Matrix <- function(x,path) {
>>  assign(gsub(pattern=".csv",x,replacement=""),read.csv(paste(path,x,sep="")))
>> }
>>
>> when I try to include it in a loop in another function (I have so many csv files to import), it doesn't work. I mean the following function doesn't do it.
>>
>> loadCSVFiles_old <- function(path) {
>>  x <- list.files(path)
>>  for (i in 1:length(x)) {
>>   assign(gsub(pattern=".csv",x[i],replacement=""),read.csv(paste(path,x[i],sep="")))
>>   }
>> }
>>
>> Instead, if I execute the foor loop in the command line, it works. I am puzzled. Appreciate any help.
>>
>> thanks
>> yetik
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hb at biostat.ucsf.edu  Thu Dec  5 06:20:07 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 4 Dec 2013 21:20:07 -0800
Subject: [R] Error: C stack usage is too close to the limit when using
	list.files()
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C3469D5@PA-MBX01.na.tibco.com>
References: <CABG0rftp4J29ETAtx2phZS587CmKv7xDsgz=aM6Z74E+NOBf3w@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C346757@PA-MBX01.na.tibco.com>
	<E66794E69CFDE04D9A70842786030B931C34677F@PA-MBX01.na.tibco.com>
	<CABG0rfuzFa6-6fEX5Ckmd_cGEyndeff7+2Ug5+BWJzVG8ewJiw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C3469D5@PA-MBX01.na.tibco.com>
Message-ID: <CAFDcVCScFPkCDeifZC83xARMkZed4Rt6P9s1v97RTW_fVCU00g@mail.gmail.com>

FYI, in R.utils (>= 1.28.4) you can use listDirectory() to control how
deep the recursion goes, which would give you protection against your
problem, e.g.

  R.utils::listDirectory("dir", recursive=5L)

where recursive=0L is equivalent to recursive=FALSE.  Using
recursive=TRUE corresponds to recursive=+Inf, that is infinite depth.
listDirectory() accepts similar arguments that list.files() does.

/Henrik

On Sat, Sep 28, 2013 at 5:06 PM, William Dunlap <wdunlap at tibco.com> wrote:
> The issue is not symbolic links per se, but ones that form loops.
> Note that you can detect such loops by running 'find -L ...' and
> looking for the error messages.  (find by default does not follow
> any symbolic links, which can be a problem also.)
>
> It is a shortcoming of the current version of list.files().
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: jgrn307 at gmail.com [mailto:jgrn307 at gmail.com] On Behalf Of Jonathan
>> Greenberg
>> Sent: Saturday, September 28, 2013 10:51 AM
>> To: William Dunlap
>> Cc: r-help
>> Subject: Re: [R] Error: C stack usage is too close to the limit when using list.files()
>>
>> Thanks all -- ok, so the symbolic link issue is a distinct
>> possibility, but fundamentally doesn't solve the issue since most
>> users will have symbolic links on their machines SOMEPLACE, so a full
>> drive scan will run into these issues --  is list.files calling find,
>> or is it using a different algorithm?  This seems like a shortcoming
>> in the list.files algorithm -- is there a better solution (short of a
>> System call, which I'm still not sure will work on Macs without Xcode
>> -- a colleague of mine did NOT have Xcode, and reported not being able
>> to run find from the command line) -- perhaps a different package?
>>
>> --j
>>
>> On Fri, Sep 27, 2013 at 3:08 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> > Toss a couple of extra files in there and you will see the output grow exponentially.
>> >
>> > % touch dir/IMPORTANT_1 dir/subdir/IMPORTANT_2
>> >
>> > and in R those two new files cause 82 more strings to appear in list.file's output:
>> >
>> >> nchar(list.files("dir", recursive=TRUE))
>> >  [1]  11  18  33  40  55  62  77  84  99 106 121 128 143 150 165 172 187 194 209
>> > [20] 216 231 238 253 260 275 282 297 304 319 326 341 348 363 370 385 392 407 414
>> > [39] 429 436 451 458 473 480 495 502 517 524 539 546 561 568 583 590 605 612 627
>> > [58] 634 649 656 671 678 693 700 715 722 737 744 759 766 781 788 803 810 825 832
>> > [77] 847 854 869 876 891 898 901
>> >
>> > 'find', by default, does not following symbolic links.
>> >
>> > % find dir
>> > dir
>> > dir/subdir
>> > dir/subdir/IMPORTANT_2
>> > dir/subdir/linkToUpperDir
>> > dir/IMPORTANT_1
>> >
>> > The -L option makes it follow them, but it won't follow loops:
>> >
>> > % find -L dir
>> > dir
>> > dir/subdir
>> > dir/subdir/IMPORTANT_2
>> > find: File system loop detected; `dir/subdir/linkToUpperDir' is part of the same file
>> system loop as `dir'.
>> > dir/IMPORTANT_1
>> >
>> > Bill Dunlap
>> > Spotfire, TIBCO Software
>> > wdunlap tibco.com
>> >
>> >
>> >> -----Original Message-----
>> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
>> Behalf
>> >> Of William Dunlap
>> >> Sent: Friday, September 27, 2013 12:56 PM
>> >> To: Jonathan Greenberg; r-help
>> >> Subject: Re: [R] Error: C stack usage is too close to the limit when using list.files()
>> >>
>> >> Do you have some symbolic links that make loops in your file system?
>> >> list.files() has problems with such loops and find does not.  E.g.,  on a Linux box:
>> >>
>> >> % cd /tmp
>> >> % mkdir dir dir/subdir
>> >> % cd dir/subdir
>> >> % ln -s ../../dir linkToUpperDir
>> >> % cd /tmp
>> >> % R --quiet
>> >> > list.files("dir", recursive=TRUE, full=TRUE)
>> >> [1]
>> >>
>> "dir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToU
>> >>
>> pperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkT
>> >>
>> oUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/li
>> >>
>> nkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdi
>> >>
>> r/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/su
>> >>
>> bdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir
>> >>
>> /subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpper
>> >>
>> Dir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUp
>> >>
>> perDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkTo
>> >>
>> UpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/lin
>> >> kToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir"
>> >> > system("find dir")
>> >> dir
>> >> dir/subdir
>> >> dir/subdir/linkToUpperDir
>> >>
>> >> Bill Dunlap
>> >> Spotfire, TIBCO Software
>> >> wdunlap tibco.com
>> >>
>> >>
>> >> > -----Original Message-----
>> >> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
>> Behalf
>> >> > Of Jonathan Greenberg
>> >> > Sent: Friday, September 27, 2013 12:13 PM
>> >> > To: r-help
>> >> > Subject: [R] Error: C stack usage is too close to the limit when using list.files()
>> >> >
>> >> > R-helpers:
>> >> >
>> >> > I'm running a file search on my entire drive (Mac OS X) using:
>> >> >
>> >> > files_found <-
>> list.files(dir="/",pattern=somepattern,recursive=TRUE,full.names=TRUE)
>> >> > where somepattern is a search pattern (which I have confirmed via a
>> >> > unix "find / -name somepattern" only returns ~ 3 results).
>> >> >
>> >> > I keep getting an error:
>> >> >
>> >> > Error: C stack usage is too close to the limit
>> >> >
>> >> > when running this command.  Any ideas on 1) how to fix this or 2) if
>> >> > there is an alternative to using list.files() to accomplish this
>> >> > search without resorting to an external package?
>> >> >
>> >> > Cheers!
>> >> >
>> >> > --jonathan
>> >> >
>> >> >
>> >> > --
>> >> > Jonathan A. Greenberg, PhD
>> >> > Assistant Professor
>> >> > Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> >> > Department of Geography and Geographic Information Science
>> >> > University of Illinois at Urbana-Champaign
>> >> > 259 Computing Applications Building, MC-150
>> >> > 605 East Springfield Avenue
>> >> > Champaign, IL  61820-6371
>> >> > Phone: 217-300-1924
>> >> > http://www.geog.illinois.edu/~jgrn/
>> >> > AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Jonathan A. Greenberg, PhD
>> Assistant Professor
>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> Department of Geography and Geographic Information Science
>> University of Illinois at Urbana-Champaign
>> 259 Computing Applications Building, MC-150
>> 605 East Springfield Avenue
>> Champaign, IL  61820-6371
>> Phone: 217-300-1924
>> http://www.geog.illinois.edu/~jgrn/
>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ml-node+s789695n4681662h38 at n4.nabble.com  Thu Dec  5 05:19:18 2013
From: ml-node+s789695n4681662h38 at n4.nabble.com (tlw1987 [via R])
Date: Wed, 4 Dec 2013 20:19:18 -0800 (PST)
Subject: [R] question about how to install package "rjava" in R 3.02
Message-ID: <1386217158087-4681662.post@n4.nabble.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131204/f807a494/attachment.pl>

From kridox at ymail.com  Thu Dec  5 07:40:34 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 5 Dec 2013 15:40:34 +0900
Subject: [R] question about how to install package "rjava" in R 3.02
In-Reply-To: <1386217158087-4681662.post@n4.nabble.com>
References: <1386217158087-4681662.post@n4.nabble.com>
Message-ID: <CAAcyNCyfn-cZcXKi9+SUgSA_P_kdDh9UsdTDutJ+y+sr+Eg24g@mail.gmail.com>

Hello,

Please read carefully the message. It says you three times that the
name is "rJava", not "rjava".

Regards,
Pascal

On 5 December 2013 13:19, tlw1987 [via R]
<ml-node+s789695n4681662h38 at n4.nabble.com> wrote:
> Hello, everybody , recently , I want to install the package "rjava" in
> windows 7 64bt. But it can not success.This error messages is as follow:
> install.packages("rjava")
> Warning in install.packages :
>   package ?rjava? is not available (for R version 3.0.2)
> Warning in install.packages :
>   Perhaps you meant ?rJava? ?
> Warning in install.packages :
>   package ?rjava? is not available (for R version 3.0.2)
> Warning in install.packages :
>   Perhaps you meant ?rJava? ?
> Warning messages:
> 1: package ?rjava? is not available (for R version 3.0.2)
> 2: Perhaps you meant ?rJava? ?
>
> Can anyone tell me how to solve this problem?
>
>
>
>
>
> ______________________________________
> If you reply to this email, your message will be added to the discussion below:
> http://r.789695.n4.nabble.com/question-about-how-to-install-package-rjava-in-R-3-02-tp4681662.html
> This email was sent by tlw1987 (via Nabble)
> To receive all replies by email, subscribe to this discussion: http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=subscribe_by_code&node=4681662&code=ci1oZWxwQHItcHJvamVjdC5vcmd8NDY4MTY2MnwtNzg0MjM1NTA4
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From ydingcaf at gmail.com  Thu Dec  5 08:35:21 2013
From: ydingcaf at gmail.com (DingYi)
Date: Thu, 5 Dec 2013 15:35:21 +0800
Subject: [R]  O-ring statistic
Message-ID: <DDA72D21-C9A8-4841-9E1E-9F88891BFA00@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/4c141778/attachment.pl>

From r.turner at auckland.ac.nz  Thu Dec  5 10:04:14 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 5 Dec 2013 22:04:14 +1300
Subject: [R] O-ring statistic
In-Reply-To: <DDA72D21-C9A8-4841-9E1E-9F88891BFA00@gmail.com>
References: <DDA72D21-C9A8-4841-9E1E-9F88891BFA00@gmail.com>
Message-ID: <52A0418E.6040201@auckland.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/36ebaccd/attachment.pl>

From mbressan at arpa.veneto.it  Thu Dec  5 11:49:39 2013
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Thu, 05 Dec 2013 11:49:39 +0100
Subject: [R] plot of a bagging tree
Message-ID: <52A05A43.9000903@arpa.veneto.it>

by considering this general example

##start code

library(ipred)
data("Ionosphere", package = "mlbench")
Ionosphere$V2 <- NULL # constant within groups
iono<-bagging(Class ~ ., data=Ionosphere, coob=TRUE)
print(iono)

##end code

does anybody knows any possibility to plot the (average) plot of the 
bagging?
does it make any sense at least for a visual presentation?
how to *visually* convey the information provided by the bagging model?

thank you for any feedback

best

max


From michael.lang at tum.de  Thu Dec  5 10:15:32 2013
From: michael.lang at tum.de (Mike.lang)
Date: Thu, 5 Dec 2013 01:15:32 -0800 (PST)
Subject: [R] GAM Assumption Tests
Message-ID: <1386234932688-4681670.post@n4.nabble.com>

Dear all, 

currently I set up a GAM for my dataset (~32k records). I assume a normal
distribution, constant variance and no correlation effects. 

With gam.check() it is possible to check those assumptions graphically. But
is there also any option to do quantitative tests like the Wald-Test,
shapiro-wilk test or VIF? 


Looking forward to your responses! 

Best
Mike



--
View this message in context: http://r.789695.n4.nabble.com/GAM-Assumption-Tests-tp4681670.html
Sent from the R help mailing list archive at Nabble.com.


From M.Rosario.Garcia at slu.se  Thu Dec  5 11:50:36 2013
From: M.Rosario.Garcia at slu.se (Rosario Garcia Gil)
Date: Thu, 5 Dec 2013 10:50:36 +0000
Subject: [R] p value for mu: anova()
Message-ID: <A1C4DF829DB4AE45BF8447F83C7EAFFE168BD5F0@exchange2-3>

Hello

I have run an anova analysis for the fallowing model:  H_obs=mu+REGION+MANAGEMENT + e

When I run it in ASRelm I get the p-value for mu, and, of course also for the two dependent variables (REGION and MANAGEMENT)

When I run it in R, I do not get the pvalue for mu.

Can some one help me to understand why? and if it is possible to estimate the pvalue for mu in anova() in R?

I attach the file.

Thanks




From tcmuigai at gmail.com  Thu Dec  5 14:15:50 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Thu, 5 Dec 2013 16:15:50 +0300
Subject: [R] how to link different versions of R
Message-ID: <CAAJc=rOdcPtiJFdRcFSjCNKQoEXeYXBDxNjojKNU0UiQ3BLnFA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/0820d0b7/attachment.pl>

From Rainer at krugs.de  Thu Dec  5 15:56:41 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 05 Dec 2013 15:56:41 +0100
Subject: [R] Merging two data frames, but keeping NAs
Message-ID: <52A09429.3050905@krugs.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi

My brain is giving up on this...

I have the following two data.frames:

  x <-  data.frame(ref=c(NA, NA, NA, 10:5, NA, 1:5))
  y <-  data.frame(id = c(2, 3, 4, 6, 7, 9, 8), val = 101:107)

Which look as follow:

> x
   ref
1   NA
2   NA
3   NA
4   10
5    9
6    8
7    7
8    6
9    5
10  NA
11   1
12   2
13   3
14   4
15   5
> y
  id val
1  2 101
2  3 102
3  4 103
4  6 104
5  7 105
6  9 106
7  8 107
> 

Now I want to merge y into x, but that

a) the sort order of x stays the same (sort=FALSE in merge()) and
b) the NAs stay

The result should look as follow (column id only here for clarity):

> result
   ref  id  val
1   NA  NA  NA
2   NA  NA  NA
3   NA  NA  NA
4   10  NA  NA
5    9   9   106
6    8   8   107
7    7   7   105
8    6   6   104
9    5  NA  NA
10  NA  NA  NA
11   1  NA  NA
12   2   2  101
13   3   3  102
14   4   4  103
15   5  NA  NA

merge(x, y, by.x="ref", by.y="id", sort=FALSE) leaves out the NA, but
otherwise it works:

> merge(x, y, by.x=1, by.y="id", sort=FALSE)
  ref val
1   9 106
2   8 107
3   7 105
4   6 104
5   2 101
6   3 102
7   4 103

Is there any way that I can tell merge() to keep the NA, or how can I
achieve what I want?

Thanks,

Rainer

- -- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSoJQpAAoJENvXNx4PUvmCW2oH/A9s2HbZ16PZRmFcQsxH3uYC
T20b1HXQu8iVqVkfD1D1tbPnogU5QJF1+tJMVzwkg+enhDtop6qpS5Vm5RV9KFnk
eJxmwdIQI3sZOkpReH9cPCnG0bHGO5f+iW3fA7mx95jQTm8WHaU+7zo7Ueb62oeX
/Toc4cVKI2qljzRfJkJCyKZclXbTe0YRv/EKqHDjyI1k/1/1jYVxALm/CqvSZTQQ
SE7nhDVvKHbuBfvrH4A5iy0X/TyHTYgP5eVV7/W4D4OcBYgQDJMwm1z0JTKeF37Z
e1gaUEkDbbJrNIOvB5Bl9EWaym0FFyv7w9XUV/FtqJy7QgQ6qoNxUAo1CfXkx/s=
=hX0S
-----END PGP SIGNATURE-----


From S.Ellison at LGCGroup.com  Thu Dec  5 16:00:14 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 5 Dec 2013 15:00:14 +0000
Subject: [R] how to link different versions of R
In-Reply-To: <CAAJc=rOdcPtiJFdRcFSjCNKQoEXeYXBDxNjojKNU0UiQ3BLnFA@mail.gmail.com>
References: <CAAJc=rOdcPtiJFdRcFSjCNKQoEXeYXBDxNjojKNU0UiQ3BLnFA@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED56C9BDB3A3@GOLD.corp.lgc-group.com>

> -----Original Message-----
> I had downloaded the package zoo under R version 3.0.0. Afterwards i
> downloaded R version 3.0.2 on the same workstation. Is it possible to  use
> the zoo package from 3.0.0. in 3.0.2.
Usually a slightly older package version will work with a more recent version of R and vice versa, though you will get warnings at load time unless you build from source yourself against the relevant installation. So yes, in the restricted sense that if you are lucky and the version changes have not resulted in incompatibility, it can be done. You may be able to get away with simply copying the old library from the previous installations library directory to the new one.
But it sounds decidedly unwise and in general packages built for one version of R are not guaranteed to run correctly, or at all, for another version. Most folk would, I guess, recommend very strongly that you don't do that.

> Is it possible to upgrade from version 3.0.1 to 3.0.2 for example   without
> downloading afresh and retain  the packages already installed in an earlier
> version.
Yes, in the sense that it is possible to shoot yourself in the foot and hope you miss and can walk afterwards. 
See above: broadly, not a good idea.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From sarah.goslee at gmail.com  Thu Dec  5 16:11:22 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 5 Dec 2013 10:11:22 -0500
Subject: [R] Merging two data frames, but keeping NAs
In-Reply-To: <52A09429.3050905@krugs.de>
References: <52A09429.3050905@krugs.de>
Message-ID: <CAM_vjukFLsux04FK--qiR-CnviqdJ67NDgxAv8CXGDjrT8pgVg@mail.gmail.com>

Adding the argument all.x=TRUE to merge() will retain the NA values,
but the only reliable way I've found to preserve order with NA values
in a merge is to add an index column to x, merge the data, sort on the
index column, then delete it.

Sarah

On Thu, Dec 5, 2013 at 9:56 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Hi
>
> My brain is giving up on this...
>
> I have the following two data.frames:
>
>   x <-  data.frame(ref=c(NA, NA, NA, 10:5, NA, 1:5))
>   y <-  data.frame(id = c(2, 3, 4, 6, 7, 9, 8), val = 101:107)
>
> Which look as follow:
>
>> x
>    ref
> 1   NA
> 2   NA
> 3   NA
> 4   10
> 5    9
> 6    8
> 7    7
> 8    6
> 9    5
> 10  NA
> 11   1
> 12   2
> 13   3
> 14   4
> 15   5
>> y
>   id val
> 1  2 101
> 2  3 102
> 3  4 103
> 4  6 104
> 5  7 105
> 6  9 106
> 7  8 107
>>
>
> Now I want to merge y into x, but that
>
> a) the sort order of x stays the same (sort=FALSE in merge()) and
> b) the NAs stay
>
> The result should look as follow (column id only here for clarity):
>
>> result
>    ref  id  val
> 1   NA  NA  NA
> 2   NA  NA  NA
> 3   NA  NA  NA
> 4   10  NA  NA
> 5    9   9   106
> 6    8   8   107
> 7    7   7   105
> 8    6   6   104
> 9    5  NA  NA
> 10  NA  NA  NA
> 11   1  NA  NA
> 12   2   2  101
> 13   3   3  102
> 14   4   4  103
> 15   5  NA  NA
>
> merge(x, y, by.x="ref", by.y="id", sort=FALSE) leaves out the NA, but
> otherwise it works:
>
>> merge(x, y, by.x=1, by.y="id", sort=FALSE)
>   ref val
> 1   9 106
> 2   8 107
> 3   7 105
> 4   6 104
> 5   2 101
> 6   3 102
> 7   4 103
>
> Is there any way that I can tell merge() to keep the NA, or how can I
> achieve what I want?
>
> Thanks,
>
> Rainer
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From S.Ellison at lgcgroup.com  Thu Dec  5 16:28:37 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Thu, 5 Dec 2013 15:28:37 +0000
Subject: [R] Double Infinite Integration
In-Reply-To: <CAB=y=yM=1Oqbm3d3Msdeoq7ORvSaxEo8jkLf=HNeNViw8AFXVg@mail.gmail.com>
References: <CAB=y=yM=1Oqbm3d3Msdeoq7ORvSaxEo8jkLf=HNeNViw8AFXVg@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED56C9BDB3E0@GOLD.corp.lgc-group.com>


> -----Original Message-----
> I need to perform the following integration where the integrand is the
> product of three functions:
> f(x)g(y)z(x,y)
> 
> the limits of x are(0,inf) and the limits of y are(-inf,inf).
> 
> Could this be done using R? I tried using the function integrate 2 times, but it
> didn't work:
> z<- function(x,y) {
> 
> 
> }
.....
> 
>    I didn't get any output at all!!!


The function z() you provided is not doing anything; it is defined in your post as z<-function(x,y){}

Surprised you didn't get at least NULL, though.








*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jun.shen.ut at gmail.com  Thu Dec  5 16:33:55 2013
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Thu, 5 Dec 2013 10:33:55 -0500
Subject: [R] How to generate a smoothed surface for a three dimensional
	dataset?
In-Reply-To: <CACk-te1TNCT-WcH8-wnYD5p+8erLOTB=5B=p1WZZAzmggc__MQ@mail.gmail.com>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
	<529F5EC3.5010309@gmail.com>
	<D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>
	<CACk-te1TNCT-WcH8-wnYD5p+8erLOTB=5B=p1WZZAzmggc__MQ@mail.gmail.com>
Message-ID: <CAMCXXmq1N9SnTG=947LmPQsg4URWsOY4FZZ7N4tO27APPw-HVA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/964f8363/attachment.pl>

From gunter.berton at gene.com  Thu Dec  5 16:52:51 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 5 Dec 2013 07:52:51 -0800
Subject: [R] How to generate a smoothed surface for a three dimensional
	dataset?
In-Reply-To: <CAMCXXmq1N9SnTG=947LmPQsg4URWsOY4FZZ7N4tO27APPw-HVA@mail.gmail.com>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
	<529F5EC3.5010309@gmail.com>
	<D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>
	<CACk-te1TNCT-WcH8-wnYD5p+8erLOTB=5B=p1WZZAzmggc__MQ@mail.gmail.com>
	<CAMCXXmq1N9SnTG=947LmPQsg4URWsOY4FZZ7N4tO27APPw-HVA@mail.gmail.com>
Message-ID: <CACk-te1ZugfsLaVs1V9KNzkn_cYHv=9kwi=MVkSXKwd2BpkoKA@mail.gmail.com>

Jun:

You need to:

1. Read the docs
2. Consult a local statistician, as you seem to be out of your depth
statistically here.

Re: 1:

?predict.loess explicitly says:

"If newdata was the result of a call to expand.grid, the predictions
(and s.e.'s if requested) will be an **array** of the appropriate
dimensions." (emphasis added)

So change your assignment to:

df$z <- as.vector(predict(fit.loess,
newdata=df))


## or maybe if plot3d accepts a matrix argument (I don't do 3d plots),
more directly:

plot3d(predict(fit.loess,newdata = df))  ## May Not Work!!

Re: 2

Your comment that:

" I can see the critical point here is to find a right function to
make the prediction. "

is what indicates to me that your "critical point" is that you have
insufficient knowledge and need help. Feel free to disagree, of
course.

Cheers,
Bert

On Thu, Dec 5, 2013 at 7:33 AM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Hi Federico/Duncan/David/Bert,
>
> Thank you for your thoughtful comments and it's a great learning experience.
> I can see the critical point here is to find a right function to make the
> prediction. So I was thinking to start with "loess". However the
> predict.loess gave me an error as follows
>
> Error in `$<-.data.frame`(`*tmp*`, "z", value = c(0.417071766265867,
> 0.433916401753023,  :
>   replacement has 20 rows, data has 400
>
> Here is the code I tried. Thank you for your help again!
>
> Jun
> =====================================
>
> x<-runif(20)
> y<-runif(20)
> z<-runif(20)
>
> library(rgl)
> plot3d(x,y,z)
>
> loess(z~x+y,control=loess.control(surface='direct'),span=.5,degree=2)->fit.loess
>
> xnew <- seq(min(x), max(x), len=20)
> ynew <- seq(min(y), max(y), len=20)
>
> df <- expand.grid(x = xnew, y = ynew)
>
> df$z<-predict(fit.loess,newdata=df)
>
>
>
> On Wed, Dec 4, 2013 at 4:37 PM, Bert Gunter <gunter.berton at gene.com> wrote:
>>
>> ... or, more simply
>>
>> lm(z ~ polym(x,y, degree=2) )
>>
>> ?polym
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>>
>> On Wed, Dec 4, 2013 at 10:30 AM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>> >
>> > On Dec 4, 2013, at 8:56 AM, Duncan Murdoch wrote:
>> >
>> >> On 04/12/2013 11:36 AM, Jun Shen wrote:
>> >>> Hi,
>> >>>
>> >>> I have a dataset with two independent variables (x, y) and a response
>> >>> variable (z). I was hoping to generate a response surface by plotting
>> >>> x, y,
>> >>> z on a three dimensional plot. I can plot the data with rgl.points(x,
>> >>> y,
>> >>> z). I understand I may not have enough data to generate a surface. Is
>> >>> there
>> >>> a way to smooth out the data points to generate a surface? Thanks a
>> >>> lot.
>> >>
>> >> There are many ways to do that.  You need to fit a model that predicts
>> >> z from (x, y), and then plot the predictions from that model.
>> >> An example below follows yours.
>> >>>
>> >>> Jun
>> >>>
>> >>> ===========================
>> >>>
>> >>> An example:
>> >>>
>> >>> x<-runif(20)
>> >>> y<-runif(20)
>> >>> z<-runif(20)
>> >>>
>> >>> library(rgl)
>> >>> rgl.points(x,y,z)
>> >>
>> >> Don't use rgl.points, use points3d() or plot3d().  Here's the full
>> >> script:
>> >>
>> >>
>> >> x<-runif(20)
>> >> y<-runif(20)
>> >> z<-runif(20)
>> >>
>> >> library(rgl)
>> >> plot3d(x,y,z)
>> >>
>> >> fit <- lm(z ~ x + y + x*y + x^2 + y^2)
>> >>
>> >
>> >  Newcomers to R may think they would be getting a quadratic in x and y.
>> > But R's formula interpretation will collapse x^2 to just x and then it
>> > becomes superfluous and is discarded. The same result is obtained with z ~
>> > (x + y)^2).   I would have thought that this would have been the code:
>> >
>> > fit <- lm(z ~ poly(x,2) +poly(y,2) + x:y )
>> >
>> >
>> >> xnew <- seq(min(x), max(x), len=20)
>> >> ynew <- seq(min(y), max(y), len=20)
>> >> df <- expand.grid(x = xnew,
>> >>                  y = ynew)
>> >>
>> >> df$z <- predict(fit, newdata=df)
>> >>
>> >> surface3d(xnew, ynew, df$z, col="red")
>> >
>> > With the modified fitting formula one sees a nice saddle (for that
>> > particular random draw) using rgl.snapshot().
>> >
>> >
>> > The result with the earlier formula is a more restrained:
>> >
>> >
>> >
>> >
>> > Continued thanks to you Duncan for making this great tool available.
>> >
>> > --
>> > David.
>> >
>> >
>> >> Duncan Murdoch
>> >>>
>> >
>> > David Winsemius
>> > Alameda, CA, USA
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (650) 467-7374
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From smartpink111 at yahoo.com  Thu Dec  5 16:02:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 5 Dec 2013 07:02:52 -0800 (PST)
Subject: [R] how to store multiple data frame name and print in R?
Message-ID: <1386255772.82747.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,

May be this helps:
i<-1
li<-list()
while(i<3)
{
li[[i]]<-get(paste("L", i, sep = ""))
print(li[[i]])
i<-i+1
} 

li[[1]]
#?? A? B
#1 V1 v2
#2 V2 V3



#you can also store it by:

l2 <- list(L1=L1,L2=L2,L3=L3)


A.K.




I have 3 data frame 

L1<-data.frame(A=c("V1","V2"),B=c("v2","V3")) 

L2<-data.frame(A=c("V1V2")) 

L3<-data.frame(A=c("V1V2V3")) 

is it possible to store it name in list ? 

i mean 
i<-1 
li<-list() 
while(i<3) 
{ 
li[i]<-paste("L", i, sep = "") 
print(li[i]) 
i<-i+1 
} 

expected output is 
if print li[i] 
get the value 
? ? ? ? ? ? ?A ? ? ? ? ? ? ? B 
1 ? ? ? ? ? ?V1 ? ? ? ? ? ?v2 
2 ? ? ? ? ? ?V2 ? ? ? ? ? ?V3 



From smartpink111 at yahoo.com  Thu Dec  5 16:37:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 5 Dec 2013 07:37:30 -0800 (PST)
Subject: [R] Merging two data frames, but keeping NAs
In-Reply-To: <52A09429.3050905@krugs.de>
References: <52A09429.3050905@krugs.de>
Message-ID: <1386257850.59764.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try ?join() 

library(plyr)
y$ref <- y$id
> join(x,y,by="ref")
?? ref id val
1?? NA NA? NA
2?? NA NA? NA
3?? NA NA? NA
4?? 10 NA? NA
5??? 9? 9 106
6??? 8? 8 107
7??? 7? 7 105
8??? 6? 6 104
9??? 5 NA? NA
10? NA NA? NA
11?? 1 NA? NA
12?? 2? 2 101
13?? 3? 3 102
14?? 4? 4 103
15?? 5 NA? NA


A.K.


On Thursday, December 5, 2013 9:58 AM, Rainer M Krug <Rainer at krugs.de> wrote:
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi

My brain is giving up on this...

I have the following two data.frames:

? x <-? data.frame(ref=c(NA, NA, NA, 10:5, NA, 1:5))
? y <-? data.frame(id = c(2, 3, 4, 6, 7, 9, 8), val = 101:107)

Which look as follow:

> x
?  ref
1?  NA
2?  NA
3?  NA
4?  10
5? ? 9
6? ? 8
7? ? 7
8? ? 6
9? ? 5
10? NA
11?  1
12?  2
13?  3
14?  4
15?  5
> y
? id val
1? 2 101
2? 3 102
3? 4 103
4? 6 104
5? 7 105
6? 9 106
7? 8 107
> 

Now I want to merge y into x, but that

a) the sort order of x stays the same (sort=FALSE in merge()) and
b) the NAs stay

The result should look as follow (column id only here for clarity):

> result
?  ref? id? val
1?  NA? NA? NA
2?  NA? NA? NA
3?  NA? NA? NA
4?  10? NA? NA
5? ? 9?  9?  106
6? ? 8?  8?  107
7? ? 7?  7?  105
8? ? 6?  6?  104
9? ? 5? NA? NA
10? NA? NA? NA
11?  1? NA? NA
12?  2?  2? 101
13?  3?  3? 102
14?  4?  4? 103
15?  5? NA? NA

merge(x, y, by.x="ref", by.y="id", sort=FALSE) leaves out the NA, but
otherwise it works:

> merge(x, y, by.x=1, by.y="id", sort=FALSE)
? ref val
1?  9 106
2?  8 107
3?  7 105
4?  6 104
5?  2 101
6?  3 102
7?  4 103

Is there any way that I can tell merge() to keep the NA, or how can I
achieve what I want?

Thanks,

Rainer

- -- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :? ? ?  +33 - (0)9 53 10 27 44
Cell:? ? ?  +33 - (0)6 85 62 59 98
Fax :? ? ?  +33 - (0)9 58 10 27 44

Fax (D):? ? +49 - (0)3 21 21 25 22 44

email:? ? ? Rainer at krugs.de

Skype:? ? ? RMkrug
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSoJQpAAoJENvXNx4PUvmCW2oH/A9s2HbZ16PZRmFcQsxH3uYC
T20b1HXQu8iVqVkfD1D1tbPnogU5QJF1+tJMVzwkg+enhDtop6qpS5Vm5RV9KFnk
eJxmwdIQI3sZOkpReH9cPCnG0bHGO5f+iW3fA7mx95jQTm8WHaU+7zo7Ueb62oeX
/Toc4cVKI2qljzRfJkJCyKZclXbTe0YRv/EKqHDjyI1k/1/1jYVxALm/CqvSZTQQ
SE7nhDVvKHbuBfvrH4A5iy0X/TyHTYgP5eVV7/W4D4OcBYgQDJMwm1z0JTKeF37Z
e1gaUEkDbbJrNIOvB5Bl9EWaym0FFyv7w9XUV/FtqJy7QgQ6qoNxUAo1CfXkx/s=
=hX0S
-----END PGP SIGNATURE-----

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From murdoch.duncan at gmail.com  Thu Dec  5 17:08:16 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 5 Dec 2013 11:08:16 -0500
Subject: [R] How to generate a smoothed surface for a three dimensional
 dataset?
In-Reply-To: <CAMCXXmq1N9SnTG=947LmPQsg4URWsOY4FZZ7N4tO27APPw-HVA@mail.gmail.com>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>	<529F5EC3.5010309@gmail.com>	<D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>	<CACk-te1TNCT-WcH8-wnYD5p+8erLOTB=5B=p1WZZAzmggc__MQ@mail.gmail.com>
	<CAMCXXmq1N9SnTG=947LmPQsg4URWsOY4FZZ7N4tO27APPw-HVA@mail.gmail.com>
Message-ID: <52A0A4F0.80001@gmail.com>

On 05/12/2013 10:33 AM, Jun Shen wrote:
> Hi Federico/Duncan/David/Bert,
>
> Thank you for your thoughtful comments and it's a great learning
> experience. I can see the critical point here is to find a right function
> to make the prediction. So I was thinking to start with "loess". However
> the predict.loess gave me an error as follows
>
> Error in `$<-.data.frame`(`*tmp*`, "z", value = c(0.417071766265867,
> 0.433916401753023,  :
>    replacement has 20 rows, data has 400
>
> Here is the code I tried. Thank you for your help again!
>
> Jun
> =====================================
>
> x<-runif(20)
> y<-runif(20)
> z<-runif(20)
>
> library(rgl)
> plot3d(x,y,z)
>
> loess(z~x+y,control=loess.control(surface='direct'),span=.5,degree=2)->fit.loess
>
> xnew <- seq(min(x), max(x), len=20)
> ynew <- seq(min(y), max(y), len=20)
>
> df <- expand.grid(x = xnew, y = ynew)
>
> df$z<-predict(fit.loess,newdata=df)

After the error, use traceback() to find which function called 
`$<-.data.frame`.  It shows that it was your final assignment

df$z<-predict(fit.loess,newdata=df)


which causes the error, because the predict function returns a matrix.  
So you can get the plot using

surface3d(xnew, ynew, predict(fit.loess,newdata=df), col="gray")

You may want

aspect3d(1,1,1)

afterwards; loess isn't so good at extrapolation.  Or you may want to 
set predictions to NA outside the convex hull of your data.  (I'm not 
sure which function is easiest to calculate that, but here's one way:

hullx <- x[chull(x,y)]
hully <- y[chull(x,y)]
keep <- sp::point.in.polygon(df$x, df$y, hullx, hully)
znew <- predict(fit.loess,newdata=df)
znew[!keep] <- NA
plot3d(x,y,z)
surface3d(xnew, ynew, znew, col="gray")
aspect3d(1,1,1)


From lopez235 at llnl.gov  Thu Dec  5 17:32:49 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Thu, 5 Dec 2013 16:32:49 +0000
Subject: [R] How do I extract Random Forest Terms and Probabilities?
In-Reply-To: <D5FA03935F7418419332B61CA255F65FA5B8B32C6C@USCTMXP51012.merck.com>
References: <56180B40A4F72A4083C75B30DA86297333DB5643@PRDEXMBX-05.the-lab.llnl.gov>
	<1385510212.89885.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<D5FA03935F7418419332B61CA255F65FA5B8B32C6C@USCTMXP51012.merck.com>
Message-ID: <56180B40A4F72A4083C75B30DA86297333DB7544@PRDEXMBX-05.the-lab.llnl.gov>

Hi Andy,

I have used predict before and in fact when I do that to the train set I get a perfect model (i.e. ROC right angle curve in upper left quadrant) which just looks like it overfit the data. 
This is not the case with the test set were I get auc of .77.

I wanted to attempt a couple of calibration techniques I learned from Max Kuhn's Applied Predictive Modeling book. He uses a train set to do this. But with what I have now with the train set there is nothing to calibrate.

That's why I thought I would use the original probabilities from the randomForest model that was used to create fm$predicted (fm is my randomForest model).

I am still fairly new at predictive modeling and it could be the case that maybe I am not understanding something basic here.

Thanks.
Dan

-----Original Message-----
From: Liaw, Andy [mailto:andy_liaw at merck.com] 
Sent: Monday, December 02, 2013 8:40 AM
To: arun; R help; Lopez, Dan
Subject: RE: [R] How do I extract Random Forest Terms and Probabilities?

#2 can be done simply with predict(fmi, type="prob").  See the help page for predict.randomForest().

Best,
Andy


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of arun
Sent: Tuesday, November 26, 2013 6:57 PM
To: R help
Subject: Re: [R] How do I extract Random Forest Terms and Probabilities?



Hi,
For the first part, you could do:

fmi2 <- fmi
attributes(fmi2$terms) <- NULL
capture.output(fmi2$terms)
#[1] "Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width"

A.k.

On Tuesday, November 26, 2013 3:55 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:
Hi R Experts,

I need your help with two question regarding randomForest.


1.? ? ?  When I run a Random Forest model how do I extract the formula I used so that I can store it in a character vector in a dataframe?
For example the dataframe might look like this if I am running models using the IRIS dataset #ModelID,Type,

#001,RF,Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width

fmi<-randomForest(Species~.,iris,mtry=3,ntry=500)
#I know one place where the information is in fmi$terms but not sure how to extract just the formula info. Or perhaps there is somewhere else in fmi that I could get this?


2.? ? ?  How do I get the probabilities (probability-like values) from the model that was run? I know for the test set I can use predict. And I know to extract the classifications from the model I use fmi$predicted. But where are the probabilities?


Dan
Workforce Analyst
HRIM - Workforce Analytics & Metrics
LLNL


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachme...{{dropped:10}}


From collinl at cs.pitt.edu  Thu Dec  5 17:51:00 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Thu, 05 Dec 2013 11:51:00 -0500 (EST)
Subject: [R] GAM Assumption Tests
In-Reply-To: <1386234932688-4681670.post@n4.nabble.com>
Message-ID: <Pine.LNX.4.44.1312051148520.29463-100000@hydrogen.cs.pitt.edu>

Hi Mike, I recently had this issue and didn't find any package that
implemented these tests directly for the gam object.  I found it simplest
just to pull the residuals from it and run tests like shapiro.test
directly.

	Best,
	Collin.

On Thu, 5 Dec 2013, Mike.lang wrote:

> Dear all,
>
> currently I set up a GAM for my dataset (~32k records). I assume a normal
> distribution, constant variance and no correlation effects.
>
> With gam.check() it is possible to check those assumptions graphically. But
> is there also any option to do quantitative tests like the Wald-Test,
> shapiro-wilk test or VIF?
>
>
> Looking forward to your responses!
>
> Best
> Mike
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/GAM-Assumption-Tests-tp4681670.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gunter.berton at gene.com  Thu Dec  5 18:01:00 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 5 Dec 2013 09:01:00 -0800
Subject: [R] How do I extract Random Forest Terms and Probabilities?
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DB7544@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DB5643@PRDEXMBX-05.the-lab.llnl.gov>
	<1385510212.89885.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<D5FA03935F7418419332B61CA255F65FA5B8B32C6C@USCTMXP51012.merck.com>
	<56180B40A4F72A4083C75B30DA86297333DB7544@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <CACk-te2wTpVZa-1thFLDW5r8oUbDQ_ubeUHjuk8+ecGwdyxrrg@mail.gmail.com>

Gents:

This discussion is now off-topic here, I believe. Please take it
private or move to somewhere else more appropriate (SO, maybe).

Cheers,
Bert

On Thu, Dec 5, 2013 at 8:32 AM, Lopez, Dan <lopez235 at llnl.gov> wrote:
> Hi Andy,
>
> I have used predict before and in fact when I do that to the train set I get a perfect model (i.e. ROC right angle curve in upper left quadrant) which just looks like it overfit the data.
> This is not the case with the test set were I get auc of .77.
>
> I wanted to attempt a couple of calibration techniques I learned from Max Kuhn's Applied Predictive Modeling book. He uses a train set to do this. But with what I have now with the train set there is nothing to calibrate.
>
> That's why I thought I would use the original probabilities from the randomForest model that was used to create fm$predicted (fm is my randomForest model).
>
> I am still fairly new at predictive modeling and it could be the case that maybe I am not understanding something basic here.
>
> Thanks.
> Dan
>
> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com]
> Sent: Monday, December 02, 2013 8:40 AM
> To: arun; R help; Lopez, Dan
> Subject: RE: [R] How do I extract Random Forest Terms and Probabilities?
>
> #2 can be done simply with predict(fmi, type="prob").  See the help page for predict.randomForest().
>
> Best,
> Andy
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of arun
> Sent: Tuesday, November 26, 2013 6:57 PM
> To: R help
> Subject: Re: [R] How do I extract Random Forest Terms and Probabilities?
>
>
>
> Hi,
> For the first part, you could do:
>
> fmi2 <- fmi
> attributes(fmi2$terms) <- NULL
> capture.output(fmi2$terms)
> #[1] "Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width"
>
> A.k.
>
> On Tuesday, November 26, 2013 3:55 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:
> Hi R Experts,
>
> I need your help with two question regarding randomForest.
>
>
> 1.       When I run a Random Forest model how do I extract the formula I used so that I can store it in a character vector in a dataframe?
> For example the dataframe might look like this if I am running models using the IRIS dataset #ModelID,Type,
>
> #001,RF,Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width
>
> fmi<-randomForest(Species~.,iris,mtry=3,ntry=500)
> #I know one place where the information is in fmi$terms but not sure how to extract just the formula info. Or perhaps there is somewhere else in fmi that I could get this?
>
>
> 2.       How do I get the probabilities (probability-like values) from the model that was run? I know for the test set I can use predict. And I know to extract the classifications from the model I use fmi$predicted. But where are the probabilities?
>
>
> Dan
> Workforce Analyst
> HRIM - Workforce Analytics & Metrics
> LLNL
>
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> Notice:  This e-mail message, together with any attachme...{{dropped:10}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dwinsemius at comcast.net  Thu Dec  5 18:30:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Dec 2013 09:30:26 -0800
Subject: [R] how to link different versions of R
In-Reply-To: <CAAJc=rOdcPtiJFdRcFSjCNKQoEXeYXBDxNjojKNU0UiQ3BLnFA@mail.gmail.com>
References: <CAAJc=rOdcPtiJFdRcFSjCNKQoEXeYXBDxNjojKNU0UiQ3BLnFA@mail.gmail.com>
Message-ID: <A02E473B-A574-47C6-B687-55EC59A18D10@comcast.net>


On Dec 5, 2013, at 5:15 AM, Charles Thuo wrote:

> Hi,
> 
> I had downloaded the package zoo under R version 3.0.0. Afterwards i
> downloaded R version 3.0.2 on the same workstation. Is it possible to  use
> the zoo package from 3.0.0. in 3.0.2.
> 
Should be not only possible but trivial. 

> Is is possible to upgrade from version 3.0.1 to 3.0.2 for example   without
> downloading afresh and retain  the packages already installed in an earlier
> version.

The packages are by default kept in the same location on the basis of major version which they share,  and there should be no major design changes between R versions that share the first two numbers in the version hierarchy.

But why not just do this? ...

update.packages()         # fast; easy; automatic; ...  what's not to like?

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Dec  5 18:35:34 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Dec 2013 09:35:34 -0800
Subject: [R] Double Infinite Integration
In-Reply-To: <CAB=y=yM=1Oqbm3d3Msdeoq7ORvSaxEo8jkLf=HNeNViw8AFXVg@mail.gmail.com>
References: <CAB=y=yM=1Oqbm3d3Msdeoq7ORvSaxEo8jkLf=HNeNViw8AFXVg@mail.gmail.com>
Message-ID: <E1987BD4-6D52-4ED6-AC2A-751C3696B97D@comcast.net>


On Dec 4, 2013, at 12:07 PM, Aya Anas wrote:

> Hello all,
> 
> I need to perform the following integration where the integrand is the
> product of three functions:
> f(x)g(y)z(x,y)

Since f(x) does not depend on y, could you not do:

Int( f(x) * Int( Int( g(y)*z(x,y).dy)).dx)   # not R code

Then use the standard approaches described in several postings to R-help over the years. I'm not a mathematician so anyone is free to correct this.
> 
> the limits of x are(0,inf) and the limits of y are(-inf,inf).
> 
> Could this be done using R? I tried using the function integrate 2 times,
> but it didn't work:
> z<- function(x,y) {
> 
> 
> }

What we see above is empty space where a body of a function should be.

> f<-function(x){
> rr<-"put here the function in x" *integrate(function(y) z(x, y),
> -Inf,Inf)$value
> return(rr)
> }

Surely you didn't enter that!

> 
> rr2<-integrate(function(x) f(x), 0, Inf)$value
> print(rr2)

Perhaps using a more modern tool would be quicker than learning how to do multiple integration with `integrate()`:

http://cran.r-project.org/web/packages/cubature/index.html

> 
>   I didn't get any output at all!!!

Rather that send extraneous exclamation marks, please read the Posting Guide and learn how to get your mail client to send plain text so that the full R code can flow freely onto our devices from yours.

> 
> Thanks,
> Aya
> 
> 
> -- 
> Best Regards

> 
> 	[[alternative HTML version deleted]]

No, no, no.

> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help

\/\/\/\/\/\/\/
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
/\/\/\/\/\/\/\
> and provide commented, minimal, self-contained, reproducible code.

-- 

David Winsemius
Alameda, CA, USA


From ahoerner at rprogress.org  Thu Dec  5 19:16:50 2013
From: ahoerner at rprogress.org (Andrew Hoerner)
Date: Thu, 5 Dec 2013 10:16:50 -0800
Subject: [R] Can I find the number of subscribers to r-help and r SIG
	mailing lists?
Message-ID: <CA+t4QRrwCb3qbWYVcBm+G_7N5eT92gEKRThonVC_WaOmeaHrcw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/d903555b/attachment.pl>

From AARTI.MUNJAL at ucdenver.edu  Thu Dec  5 18:07:35 2013
From: AARTI.MUNJAL at ucdenver.edu (Munjal, Aarti)
Date: Thu, 5 Dec 2013 10:07:35 -0700
Subject: [R] ASA Stat. Computing & Stat. Graphics Student Paper Competition
	2014
Message-ID: <3BEB1DEA-8CEB-4F97-A1F0-44F688F3996E@ucdenver.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/667eeb1f/attachment.pl>

From AARTI.MUNJAL at ucdenver.edu  Thu Dec  5 18:51:20 2013
From: AARTI.MUNJAL at ucdenver.edu (Munjal, Aarti)
Date: Thu, 5 Dec 2013 10:51:20 -0700
Subject: [R] ASA John M. Chambers Statistical Software Award - 2014
Message-ID: <C858ECB7-D84F-4C0A-AFE8-1A4B5AE2233B@ucdenver.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/f5813ac0/attachment.pl>

From gcamcu at gmail.com  Thu Dec  5 18:20:34 2013
From: gcamcu at gmail.com (Gregory Camilli)
Date: Thu, 5 Dec 2013 10:20:34 -0700
Subject: [R] ML factor analysis
Message-ID: <CAAGoT5mEy-JJASCSGx4YHT7Q01WoewgD4uajKD=B-hojYe3M=Q@mail.gmail.com>

Does anyone know how to get standard errors for factor loadings from factanal?

Thanks, Greg


From ahoerner at rprogress.org  Thu Dec  5 19:40:23 2013
From: ahoerner at rprogress.org (Andrew Hoerner)
Date: Thu, 5 Dec 2013 10:40:23 -0800
Subject: [R] r SIG birth, life and death
Message-ID: <CA+t4QRrOLo8ykyNmTGPJtDf=i2ufEbHPYFbE--NbzBCWH0UgTg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/75f21f4b/attachment.pl>

From dwinsemius at comcast.net  Thu Dec  5 20:32:06 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Dec 2013 11:32:06 -0800
Subject: [R] Can I find the number of subscribers to r-help and r SIG
	mailing lists?
In-Reply-To: <CA+t4QRrwCb3qbWYVcBm+G_7N5eT92gEKRThonVC_WaOmeaHrcw@mail.gmail.com>
References: <CA+t4QRrwCb3qbWYVcBm+G_7N5eT92gEKRThonVC_WaOmeaHrcw@mail.gmail.com>
Message-ID: <DD335843-FB4F-4B80-B0FC-DC694CED265E@comcast.net>


On Dec 5, 2013, at 10:16 AM, Andrew Hoerner wrote:

> Dear Folks--
> Is there a reasonably straightforward way for me to find the number of
> subscribers

That's not easily accessed by any publicly avaiable method I know but I can give the current count:

7783 Non-digested Members of R-help:
7563 Digested Members of R-help:


> or distinct posters to the r-help list

Perhaps look at MarkMail or do some work with the various Archives.

> and the various r SIG
> lists? Ideally I would like a time series from founding, but unadorned
> current membership numbers would still be useful, as would founding dates
> for active SIGs.

Have you done any searching?  I believe earlier figures have been offered in prior postings and blogs about R and remember a recently published article cited here: "How Social Q&A Sites are Changing Knowledge Sharing in Open Source Software Communities". 

You should send private inquiries to the moderators or owners of those lists. (You should not expect them to all be reading R-help.)

http://www.r-project.org/mail.html

> 

There was recently a discussion about StackOverflow's impact. SO gives the number of its registered users that are "following" [r] = 5.3K.


> Peace, andrewH
> -- 
> J. Andrew Hoerner
> Director, Sustainable Economics Program
> Redefining Progress
> (510) 507-4820
> 
> 	[[alternative HTML version deleted]]______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From alma_anima at yahoo.com  Thu Dec  5 22:05:39 2013
From: alma_anima at yahoo.com (Alma Wilflinger)
Date: Thu, 5 Dec 2013 13:05:39 -0800 (PST)
Subject: [R]  How do I print predicted effect sizes in forest plot?
Message-ID: <1386277539.51368.YahooMailNeo@web141101.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/1a13b419/attachment.pl>

From jun.shen.ut at gmail.com  Fri Dec  6 01:02:12 2013
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Thu, 5 Dec 2013 19:02:12 -0500
Subject: [R] How to generate a smoothed surface for a three dimensional
	dataset?
In-Reply-To: <52A0A4F0.80001@gmail.com>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
	<529F5EC3.5010309@gmail.com>
	<D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>
	<CACk-te1TNCT-WcH8-wnYD5p+8erLOTB=5B=p1WZZAzmggc__MQ@mail.gmail.com>
	<CAMCXXmq1N9SnTG=947LmPQsg4URWsOY4FZZ7N4tO27APPw-HVA@mail.gmail.com>
	<52A0A4F0.80001@gmail.com>
Message-ID: <CAMCXXmpC8dK13tR4Z8uquzOWDPmskp_cmtG=bJrD2bpvEHD24w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/4d9be09d/attachment.pl>

From robert.b.lynch at gmail.com  Fri Dec  6 01:30:37 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Thu, 5 Dec 2013 16:30:37 -0800
Subject: [R] help with the nested anova formulas
In-Reply-To: <CACYeG1jETa=hTGmod0naCz2qf-CTVORjqiwDm+iyzobX_9C=yA@mail.gmail.com>
References: <CACYeG1jETa=hTGmod0naCz2qf-CTVORjqiwDm+iyzobX_9C=yA@mail.gmail.com>
Message-ID: <CACYeG1i_TNqUFUPurCG=gpYDJ_ZGtc=ReE+xj9e77BajLZfJYg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/ee37d5dc/attachment.pl>

From dwinsemius at comcast.net  Fri Dec  6 01:56:05 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Dec 2013 16:56:05 -0800
Subject: [R] How to generate a smoothed surface for a three dimensional
	dataset?
In-Reply-To: <CAMCXXmpC8dK13tR4Z8uquzOWDPmskp_cmtG=bJrD2bpvEHD24w@mail.gmail.com>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
	<529F5EC3.5010309@gmail.com>
	<D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>
	<CACk-te1TNCT-WcH8-wnYD5p+8erLOTB=5B=p1WZZAzmggc__MQ@mail.gmail.com>
	<CAMCXXmq1N9SnTG=947LmPQsg4URWsOY4FZZ7N4tO27APPw-HVA@mail.gmail.com>
	<52A0A4F0.80001@gmail.com>
	<CAMCXXmpC8dK13tR4Z8uquzOWDPmskp_cmtG=bJrD2bpvEHD24w@mail.gmail.com>
Message-ID: <C7285B00-EC9F-4602-9495-40EC681FD054@comcast.net>


On Dec 5, 2013, at 4:02 PM, Jun Shen wrote:

> Thanks again, Duncan. Please allow me to ask one more question. Is it
> possible to generate a contour plot overlaying with the plot3d() plot?
> 

This is not going to give you the kewl rotation capabilities  that `rgl` offers but you might be interested in the potential of the 'plot3d' package from Karline Soetaert of NIOZ-Yerseke, The Netherlands. (She also is also part of the team that gave us the very nice ODE package, 'deSolve' and co-wrote the accompanying book. I found it interesting to read that she is a biologist, while co-authors are mathematicians.)

http://cran.rstudio.com/web/packages/plot3D/vignettes/plot3D.pdf 

See Figures 2 and 8

http://cran.rstudio.com/web/packages/plot3D/vignettes/volcano.pdf 

The second one has the catchy title: "Fifty ways to draw a volcano using package plot3D"
You may find that the examples that drew the 4 examples in Figure 7 would give you something useful.

> Jun
> 
> 
> On Thu, Dec 5, 2013 at 11:08 AM, Duncan Murdoch <murdoch.duncan at gmail.com>wrote:
> 
>> On 05/12/2013 10:33 AM, Jun Shen wrote:
>> 
>>> Hi Federico/Duncan/David/Bert,
>>> 
>>> Thank you for your thoughtful comments and it's a great learning
>>> experience. I can see the critical point here is to find a right function
>>> to make the prediction. So I was thinking to start with "loess". However
>>> the predict.loess gave me an error as follows
>>> 
>>> Error in `$<-.data.frame`(`*tmp*`, "z", value = c(0.417071766265867,
>>> 0.433916401753023,  :
>>>   replacement has 20 rows, data has 400
>>> 
>>> Here is the code I tried. Thank you for your help again!
>>> 
>>> Jun
>>> =====================================
>>> 
>>> x<-runif(20)
>>> y<-runif(20)
>>> z<-runif(20)
>>> 
>>> library(rgl)
>>> plot3d(x,y,z)
>>> 
>>> loess(z~x+y,control=loess.control(surface='direct'),
>>> span=.5,degree=2)->fit.loess
>>> 
>>> xnew <- seq(min(x), max(x), len=20)
>>> ynew <- seq(min(y), max(y), len=20)
>>> 
>>> df <- expand.grid(x = xnew, y = ynew)
>>> 
>>> df$z<-predict(fit.loess,newdata=df)
>>> 
>> 
>> After the error, use traceback() to find which function called
>> `$<-.data.frame`.  It shows that it was your final assignment
>> 
>> df$z<-predict(fit.loess,newdata=df)
>> 
>> 
>> which causes the error, because the predict function returns a matrix.  So
>> you can get the plot using
>> 
>> surface3d(xnew, ynew, predict(fit.loess,newdata=df), col="gray")
>> 
>> You may want
>> 
>> aspect3d(1,1,1)
>> 
>> afterwards; loess isn't so good at extrapolation.  Or you may want to set
>> predictions to NA outside the convex hull of your data.  (I'm not sure
>> which function is easiest to calculate that, but here's one way:
>> 
>> hullx <- x[chull(x,y)]
>> hully <- y[chull(x,y)]
>> keep <- sp::point.in.polygon(df$x, df$y, hullx, hully)
>> znew <- predict(fit.loess,newdata=df)
>> znew[!keep] <- NA
>> plot3d(x,y,z)
>> surface3d(xnew, ynew, znew, col="gray")
>> aspect3d(1,1,1)
>> 
>> 
>> 

David Winsemius
Alameda, CA, USA


From nooldor at gmail.com  Fri Dec  6 00:18:26 2013
From: nooldor at gmail.com (nooldor)
Date: Fri, 6 Dec 2013 00:18:26 +0100
Subject: [R] Test ADF differences in R and Eviews
Message-ID: <CAJ0Fr65RWRaHpmyk1+Kddgd5v_WG_=1m2RwQwZ64fRVo0G=2WA@mail.gmail.com>

Hi,


In attachment you can find source data on which I run adf.test() and
print-screen with results in R and Eviews.

Results are very different. Did I missed something?

Best,
T.S.

From smartpink111 at yahoo.com  Thu Dec  5 21:11:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 5 Dec 2013 12:11:41 -0800 (PST)
Subject: [R] How to graph categorical data by percent
Message-ID: <1386274301.975.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
dat1 <- structure(list(Site = c("Downstream", "Downstream", "Downstream", 
"Downstream", "Downstream", "Downstream", "Downstream", "Downstream", 
"Downstream", "Midstream", "Midstream", "Midstream", "Midstream", 
"Midstream", "Upstream", "Upstream", "Upstream", "Upstream", 
"Upstream", "Upstream", "Upstream", "Upstream", "Upstream", "Upstream", 
"Upstream", "Upstream", "Upstream", "Upstream"), Intersex = c("no", 
"no", "no", "no", "yes", "no", "yes", "no", "no", "yes", "no", 
"no", "no", "no", "yes", "yes", "yes", "yes", "yes", "no", "no", 
"yes", "yes", "no", "yes", "no", "yes", "yes")), .Names = c("Site", 
"Intersex"), class = "data.frame", row.names = c("1", "2", "3", 
"4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", 
"16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", 
"27", "28"))


res1 <- aggregate(Intersex~Site,data=dat1,function(x) (table(x)/length(x))*100)
?res1New <- do.call(`data.frame`,res1)
#or
library(plyr)
res2 <- ddply(dat1,.(Site),summarize, Percent=(table(Intersex)/length(Intersex))*100)
?

plot(Intersex.yes~as.numeric(Site),data=res1New,xaxt="n",xlab="Site",ylim=c(0,100),type="b")
axis(1,at=as.numeric(res1New$Site),levels(res1New$Site))


A.K.

Hi I have the following dataset: 

?Site Intersex 
1 ?Downstream ? ? ? no 
2 ?Downstream ? ? ? no 
3 ?Downstream ? ? ? no 
4 ?Downstream ? ? ? no 
5 ?Downstream ? ? ?yes 
6 ?Downstream ? ? ? no 
7 ?Downstream ? ? ?yes 
8 ?Downstream ? ? ? no 
9 ?Downstream ? ? ? no 
10 ?Midstream ? ? ?yes 
11 ?Midstream ? ? ? no 
12 ?Midstream ? ? ? no 
13 ?Midstream ? ? ? no 
14 ?Midstream ? ? ? no 
15 ? Upstream ? ? ?yes 
16 ? Upstream ? ? ?yes 
17 ? Upstream ? ? ?yes 
18 ? Upstream ? ? ?yes 
19 ? Upstream ? ? ?yes 
20 ? Upstream ? ? ? no 
21 ? Upstream ? ? ? no 
22 ? Upstream ? ? ?yes 
23 ? Upstream ? ? ?yes 
24 ? Upstream ? ? ? no 
25 ? Upstream ? ? ?yes 
26 ? Upstream ? ? ? no 
27 ? Upstream ? ? ?yes 
28 ? Upstream ? ? ?yes 

I want to group the sites and calculate the percent of "yes" 
"no" for Intersex. ?Then I want to plot the prevalence of intersex 
(basically plot the percent of "yes" for each site. ?I'm stumped! 
?Thanks


From smartpink111 at yahoo.com  Thu Dec  5 23:04:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 5 Dec 2013 14:04:23 -0800 (PST)
Subject: [R] convert factor to numeric in bulk
Message-ID: <1386281063.52541.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
library(XML)
x1 <- readHTMLTable('http://www.fns.usda.gov/pd/15SNAPpartPP.htm',skip.rows=c(1:2,4,58:60),colClasses=c("character",rep("FormattedNumber",5)),stringsAsFactors=FALSE)[[1]]
colnames(x1) <- gsub("NULL\\.","",colnames(x1))
?str(x1)
#'data.frame':??? 53 obs. of? 6 variables:
# $ State/Territory: chr? "Alabama" "Alaska" "Arizona" "Arkansas" ...
# $ FY 2008??????? : num? 571591 56977 627660 377883 2220127 ...
# $ FY 2009??????? : num? 679138 64385 813987 411153 2670341 ...
# $ FY 2010??????? : num? 805095 76445 1018171 466598 3238548 ...
# $ FY 2011??????? : num? 920365 86044 1067617 486451 3672980 ...
# $ FY 2012??????? : num? 910244 91298 1123974 502125 3964221 ...

A.K.

Hello I am trying to import a html table as data.frame and the columns
 come in as factors. I need to convert them to numeric, which I can do 
but when I use the single method it would take long and converting them 
to matrix trims the numbers. ?Can someone explain how to convert all the
 numbers in columns 2:6 into numerics that hold up the right numeric 
length? 

nms = c("State/Territory" , "FY 2008" ?,"FY 2009",	"FY 2010",	"FY 2011",	"FY 2012") 
x <- data.frame(readHTMLTable('http://www.fns.usda.gov/pd/15SNAPpartPP.htm'), stringsAsFactors = F) 
x <- x[5:57,] 
names(x) <- nms 
snap.partpp <- x 
# this is what i have tried to do to solve this problem but it does the conversion but changes the values of the numbers 

x <- data.frame(readHTMLTable('http://www.fns.usda.gov/pd/15SNAPpartPP.htm'), stringsAsFactors = F) 
y <- x[5:57, 1] 
x <- data.matrix(x[5:57,2:6]) 
xy <- data.frame(y, x) 
names(xy) <- nms 
snap.avghh <- xy


From smartpink111 at yahoo.com  Thu Dec  5 23:11:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 5 Dec 2013 14:11:11 -0800 (PST)
Subject: [R] convert factor to numeric in bulk
In-Reply-To: <1386281063.52541.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1386281063.52541.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1386281471.63905.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
colnames(x1) <- gsub("NULL\\.","",colnames(x1)) ##not needed.


A.K.


On Thursday, December 5, 2013 5:04 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
library(XML)
x1 <- readHTMLTable('http://www.fns.usda.gov/pd/15SNAPpartPP.htm',skip.rows=c(1:2,4,58:60),colClasses=c("character",rep("FormattedNumber",5)),stringsAsFactors=FALSE)[[1]]
colnames(x1) <- gsub("NULL\\.","",colnames(x1))
?str(x1)
#'data.frame':??? 53 obs. of? 6 variables:
# $ State/Territory: chr? "Alabama" "Alaska" "Arizona" "Arkansas" ...
# $ FY 2008??????? : num? 571591 56977 627660 377883 2220127 ...
# $ FY 2009??????? : num? 679138 64385 813987 411153 2670341 ...
# $ FY 2010??????? : num? 805095 76445 1018171 466598 3238548 ...
# $ FY 2011??????? : num? 920365 86044 1067617 486451 3672980 ...
# $ FY 2012??????? : num? 910244 91298 1123974 502125 3964221 ...

A.K.

Hello I am trying to import a html table as data.frame and the columns
come in as factors. I need to convert them to numeric, which I can do 
but when I use the single method it would take long and converting them 
to matrix trims the numbers. ?Can someone explain how to convert all the
numbers in columns 2:6 into numerics that hold up the right numeric 
length? 

nms = c("State/Territory" , "FY 2008" ?,"FY 2009",??? "FY 2010",??? "FY 2011",??? "FY 2012") 
x <- data.frame(readHTMLTable('http://www.fns.usda.gov/pd/15SNAPpartPP.htm'), stringsAsFactors = F) 
x <- x[5:57,] 
names(x) <- nms 
snap.partpp <- x 
# this is what i have tried to do to solve this problem but it does the conversion but changes the values of the numbers 

x <- data.frame(readHTMLTable('http://www.fns.usda.gov/pd/15SNAPpartPP.htm'), stringsAsFactors = F) 
y <- x[5:57, 1] 
x <- data.matrix(x[5:57,2:6]) 
xy <- data.frame(y, x) 
names(xy) <- nms 
snap.avghh <- xy


From robert.b.lynch at gmail.com  Thu Dec  5 23:52:34 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Thu, 5 Dec 2013 14:52:34 -0800
Subject: [R] help with the nested anova formulas
Message-ID: <CACYeG1jETa=hTGmod0naCz2qf-CTVORjqiwDm+iyzobX_9C=yA@mail.gmail.com>

I am modeling grade as a function of membership in various cohorts.  There
are four "cohorts".  (NONE, ISE07,ISE08,ISE09) and two times of cohorts
coded as ISE = TRUE (ISE0#) or FALSE (NONE).  There is clear co-linearity
but that is to be expected.

running the following code

CutOff <-0
fit.base <- lme(fixed= zGrade ~ Rep + COHORT/ISE + P7APrior + Female +
White + HSGPA + MATH + AP_TOTAL + Years + EOP + Course,
                random= ~1|SID,
                data = share[share$GRADE >= CutOff,])


I get the following error

Error in MEEM(object, conLin, control$niterEM) :
  Singularity in backsolve at level 0, block 1

but if I take out the /ISE I get no error, simmilarly if I take out the
COHORT/.

I want to test for the effects of the different cohorts within the ISE
subset and across ISE & NONE.

Robert

From murdoch.duncan at gmail.com  Fri Dec  6 03:03:55 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 5 Dec 2013 21:03:55 -0500
Subject: [R] How to generate a smoothed surface for a three dimensional
 dataset?
In-Reply-To: <CAMCXXmpC8dK13tR4Z8uquzOWDPmskp_cmtG=bJrD2bpvEHD24w@mail.gmail.com>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>	<529F5EC3.5010309@gmail.com>	<D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>	<CACk-te1TNCT-WcH8-wnYD5p+8erLOTB=5B=p1WZZAzmggc__MQ@mail.gmail.com>	<CAMCXXmq1N9SnTG=947LmPQsg4URWsOY4FZZ7N4tO27APPw-HVA@mail.gmail.com>	<52A0A4F0.80001@gmail.com>
	<CAMCXXmpC8dK13tR4Z8uquzOWDPmskp_cmtG=bJrD2bpvEHD24w@mail.gmail.com>
Message-ID: <52A1308B.1030204@gmail.com>

On 13-12-05 7:02 PM, Jun Shen wrote:
> Thanks again, Duncan. Please allow me to ask one more question. Is it
> possible to generate a contour plot overlaying with the plot3d() plot?

Yes, the contourLines function from grDevices can calculate the lines, 
then you can use rgl::lines3d to draw them.

Duncan Murdoch

>
> Jun
>
>
> On Thu, Dec 5, 2013 at 11:08 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 05/12/2013 10:33 AM, Jun Shen wrote:
>
>         Hi Federico/Duncan/David/Bert,
>
>         Thank you for your thoughtful comments and it's a great learning
>         experience. I can see the critical point here is to find a right
>         function
>         to make the prediction. So I was thinking to start with "loess".
>         However
>         the predict.loess gave me an error as follows
>
>         Error in `$<-.data.frame`(`*tmp*`, "z", value = c(0.417071766265867,
>         0.433916401753023,  :
>             replacement has 20 rows, data has 400
>
>         Here is the code I tried. Thank you for your help again!
>
>         Jun
>         ==============================__=======
>
>         x<-runif(20)
>         y<-runif(20)
>         z<-runif(20)
>
>         library(rgl)
>         plot3d(x,y,z)
>
>         loess(z~x+y,control=loess.__control(surface='direct'),__span=.5,degree=2)->fit.loess
>
>         xnew <- seq(min(x), max(x), len=20)
>         ynew <- seq(min(y), max(y), len=20)
>
>         df <- expand.grid(x = xnew, y = ynew)
>
>         df$z<-predict(fit.loess,__newdata=df)
>
>
>     After the error, use traceback() to find which function called
>     `$<-.data.frame`.  It shows that it was your final assignment
>
>     df$z<-predict(fit.loess,__newdata=df)
>
>
>     which causes the error, because the predict function returns a
>     matrix.  So you can get the plot using
>
>     surface3d(xnew, ynew, predict(fit.loess,newdata=df), col="gray")
>
>     You may want
>
>     aspect3d(1,1,1)
>
>     afterwards; loess isn't so good at extrapolation.  Or you may want
>     to set predictions to NA outside the convex hull of your data.  (I'm
>     not sure which function is easiest to calculate that, but here's one
>     way:
>
>     hullx <- x[chull(x,y)]
>     hully <- y[chull(x,y)]
>     keep <- sp::point.in.polygon(df$x, df$y, hullx, hully)
>     znew <- predict(fit.loess,newdata=df)
>     znew[!keep] <- NA
>     plot3d(x,y,z)
>     surface3d(xnew, ynew, znew, col="gray")
>     aspect3d(1,1,1)
>
>
>
>


From dwinsemius at comcast.net  Fri Dec  6 03:12:12 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Dec 2013 18:12:12 -0800
Subject: [R] Test ADF differences in R and Eviews
In-Reply-To: <CAJ0Fr65RWRaHpmyk1+Kddgd5v_WG_=1m2RwQwZ64fRVo0G=2WA@mail.gmail.com>
References: <CAJ0Fr65RWRaHpmyk1+Kddgd5v_WG_=1m2RwQwZ64fRVo0G=2WA@mail.gmail.com>
Message-ID: <987DEBCF-F601-4F68-91AB-381DC2CAA202@comcast.net>


On Dec 5, 2013, at 3:18 PM, nooldor wrote:

> Hi,
> 
> 
> In attachment you can find source data on which I run adf.test() and
> print-screen with results in R and Eviews.
> 
> Results are very different. Did I missed something?

Yes. You missed the list of acceptable file types for r-help.

-- 
David Winsemius
Alameda, CA, USA


From mohan.radhakrishnan at polarisft.com  Fri Dec  6 06:16:53 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 6 Dec 2013 10:46:53 +0530
Subject: [R] Simple Error Bar
Message-ID: <OF0B06921B.1AC5F574-ON65257C39.001CA525-65257C39.001CFF0B@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131206/a2d87ed0/attachment.pl>

From jim at bitwrit.com.au  Fri Dec  6 08:26:45 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 06 Dec 2013 18:26:45 +1100
Subject: [R] Simple Error Bar
In-Reply-To: <OF0B06921B.1AC5F574-ON65257C39.001CA525-65257C39.001CFF0B@polarisft.com>
References: <OF0B06921B.1AC5F574-ON65257C39.001CA525-65257C39.001CFF0B@polarisft.com>
Message-ID: <52A17C35.5030007@bitwrit.com.au>

On 12/06/2013 04:16 PM, mohan.radhakrishnan at polarisft.com wrote:
> Hi,
>                Basic question with basic code.   I am simulating a set of
> 'y' values for a standard 'x' value measurement. So here the error bars
> are very long because the
> number of samples are very small. Is that correct ? I am plotting the mean
> of 'y' on the 'y' axis.
>
>
> Thanks,
> Mohan
>
> x<- data.frame(c(5,10,15,20,25,30,35,40,50,60))
>   colnames(x)<- c("x")
>
>   y<- sample(5:60,10,replace=T)
>   y1<- sample(5:60,10,replace=T)
>   y2<- sample(5:60,10,replace=T)
>   y3<- sample(5:60,10,replace=T)
>   y4<- sample(5:60,10,replace=T)
>
>   z<- data.frame(cbind(x,y,y1,y2,y3,y4))
>   z$mean<- apply(z[,c(2,3,4,5,6)],2,mean)
>   z$sd<- apply(z[,c(2,3,4,5,6)],2,sd)
>   z$se<- z$sd / sqrt(5)
>
>
Hi Mohan,
As your samples seem to follow a discrete uniform distribution, the 
standard deviation is approximately the number of integers in the range 
(56) divided by the number of observations (10).

Jim


From Rainer at krugs.de  Fri Dec  6 09:34:47 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 06 Dec 2013 09:34:47 +0100
Subject: [R] Merging two data frames, but keeping NAs
In-Reply-To: <CAM_vjukFLsux04FK--qiR-CnviqdJ67NDgxAv8CXGDjrT8pgVg@mail.gmail.com>
References: <52A09429.3050905@krugs.de>
	<CAM_vjukFLsux04FK--qiR-CnviqdJ67NDgxAv8CXGDjrT8pgVg@mail.gmail.com>
Message-ID: <52A18C27.2090604@krugs.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/05/13, 16:11 , Sarah Goslee wrote:
> Adding the argument all.x=TRUE to merge() will retain the NA
> values, but the only reliable way I've found to preserve order with
> NA values in a merge is to add an index column to x, merge the
> data, sort on the index column, then delete it.

Thanks Sarah - that works nicely, although it is a not so nice
workaround 0 there should be an argument in merge to keep NA...

Cheers,

Rainer

> 
> Sarah
> 
> On Thu, Dec 5, 2013 at 9:56 AM, Rainer M Krug <Rainer at krugs.de>
> wrote:
>> -----BEGIN PGP SIGNED MESSAGE----- Hash: SHA1
>> 
>> Hi
>> 
>> My brain is giving up on this...
>> 
>> I have the following two data.frames:
>> 
>> x <-  data.frame(ref=c(NA, NA, NA, 10:5, NA, 1:5)) y <-
>> data.frame(id = c(2, 3, 4, 6, 7, 9, 8), val = 101:107)
>> 
>> Which look as follow:
>> 
>>> x
>> ref 1   NA 2   NA 3   NA 4   10 5    9 6    8 7    7 8    6 9
>> 5 10  NA 11   1 12   2 13   3 14   4 15   5
>>> y
>> id val 1  2 101 2  3 102 3  4 103 4  6 104 5  7 105 6  9 106 7  8
>> 107
>>> 
>> 
>> Now I want to merge y into x, but that
>> 
>> a) the sort order of x stays the same (sort=FALSE in merge())
>> and b) the NAs stay
>> 
>> The result should look as follow (column id only here for
>> clarity):
>> 
>>> result
>> ref  id  val 1   NA  NA  NA 2   NA  NA  NA 3   NA  NA  NA 4   10
>> NA  NA 5    9   9   106 6    8   8   107 7    7   7   105 8    6
>> 6   104 9    5  NA  NA 10  NA  NA  NA 11   1  NA  NA 12   2   2
>> 101 13   3   3  102 14   4   4  103 15   5  NA  NA
>> 
>> merge(x, y, by.x="ref", by.y="id", sort=FALSE) leaves out the NA,
>> but otherwise it works:
>> 
>>> merge(x, y, by.x=1, by.y="id", sort=FALSE)
>> ref val 1   9 106 2   8 107 3   7 105 4   6 104 5   2 101 6   3
>> 102 7   4 103
>> 
>> Is there any way that I can tell merge() to keep the NA, or how
>> can I achieve what I want?
>> 
>> Thanks,
>> 
>> Rainer
>> 
> 

- -- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSoYwnAAoJENvXNx4PUvmCTjwH/2s8NdixLDI7uWvZ0p90wFxK
OMq9IcOTQ/VEK6ksYzN5e8Q6ukGCgMPW2OKqrLkqr9xhtt49toWR64CgXGgqnKYu
Vu5BT8MldwvtLYLWjyGGlrsz4VXFBixTQxfPPltSXakT742Wno7T0OLIL7V8FBgk
AqdRZpN6+QfBiQGFO7doXWndvnvXXD3uOqEAe89xwV3PBNHLCNDcMKY74HQ+t4F+
RrBzKZRvBOrwyfHFGFGfvEluewpcsPY2ooR/TqcO1XaLz94A5F2RcHdedqkIcdln
tEcOWZq9j9RWQo/9Af4pdxv9CClt8molP3rG4JRYA4x9JiSj4GNYNNF5wnofTAw=
=nxjF
-----END PGP SIGNATURE-----


From Rainer at krugs.de  Fri Dec  6 09:35:57 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 06 Dec 2013 09:35:57 +0100
Subject: [R] Merging two data frames, but keeping NAs
In-Reply-To: <1386257850.59764.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <52A09429.3050905@krugs.de>
	<1386257850.59764.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <52A18C6D.2070700@krugs.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



On 12/05/13, 16:37 , arun wrote:
> Hi, Try ?join()
> 
> library(plyr)

Well - what would we do without Hadley ...

He solved many problems we didn't know we would have soon...

Cheers,

Rainer

> y$ref <- y$id
>> join(x,y,by="ref")
> ref id val 1   NA NA  NA 2   NA NA  NA 3   NA NA  NA 4   10 NA  NA 
> 5    9  9 106 6    8  8 107 7    7  7 105 8    6  6 104 9    5 NA
> NA 10  NA NA  NA 11   1 NA  NA 12   2  2 101 13   3  3 102 14   4
> 4 103 15   5 NA  NA
> 
> 
> A.K.
> 
> 
> On Thursday, December 5, 2013 9:58 AM, Rainer M Krug
> <Rainer at krugs.de> wrote: Hi
> 
> My brain is giving up on this...
> 
> I have the following two data.frames:
> 
> x <-  data.frame(ref=c(NA, NA, NA, 10:5, NA, 1:5)) y <-
> data.frame(id = c(2, 3, 4, 6, 7, 9, 8), val = 101:107)
> 
> Which look as follow:
> 
>> x
> ref 1   NA 2   NA 3   NA 4   10 5    9 6    8 7    7 8    6 9    5 
> 10  NA 11   1 12   2 13   3 14   4 15   5
>> y
> id val 1  2 101 2  3 102 3  4 103 4  6 104 5  7 105 6  9 106 7  8
> 107
> 
> 
> Now I want to merge y into x, but that
> 
> a) the sort order of x stays the same (sort=FALSE in merge()) and 
> b) the NAs stay
> 
> The result should look as follow (column id only here for
> clarity):
> 
>> result
> ref  id  val 1   NA  NA  NA 2   NA  NA  NA 3   NA  NA  NA 4   10
> NA  NA 5    9   9   106 6    8   8   107 7    7   7   105 8    6
> 6   104 9    5  NA  NA 10  NA  NA  NA 11   1  NA  NA 12   2   2
> 101 13   3   3  102 14   4   4  103 15   5  NA  NA
> 
> merge(x, y, by.x="ref", by.y="id", sort=FALSE) leaves out the NA,
> but otherwise it works:
> 
>> merge(x, y, by.x=1, by.y="id", sort=FALSE)
> ref val 1   9 106 2   8 107 3   7 105 4   6 104 5   2 101 6   3
> 102 7   4 103
> 
> Is there any way that I can tell merge() to keep the NA, or how can
> I achieve what I want?
> 
> Thanks,
> 
> Rainer
> 
> 
> ______________________________________________ R-help at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
> read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
> 

- -- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSoYxtAAoJENvXNx4PUvmC8JMIANWUXBhCFgKv+wZs2oKv1jMm
qGLcd31a55j8NSoZZRf5v6coG+UEdVGhBu4cLlt1+0BRAhYIK9AnLvV9KXbt5zbI
PKySevB3box1ILbwsr8JH2YyOtlgjjint4LcGuEr4doNy0uo7a3G9J3ctxZgDFeE
QrmDH8EFc55lX76gzp41xUaAxvBP72GlgwK9O4jyO4f19LFcJ87C68s7Gwm2Qs4x
Ysc3JmZ8tC4BlD4H5FV/Pf6cLCxoX3CgQERGD+NNe5HCW/XSXOYsKzreamPr7ayd
bAuTDLRpPqUSYKG/nbcvjj0HMs06YNTYP4LTnwp08QUJ2VH98viQkTBF8OxDGgI=
=mK8w
-----END PGP SIGNATURE-----


From dataquerent at gmail.com  Fri Dec  6 06:46:51 2013
From: dataquerent at gmail.com (A Xi Ma)
Date: Fri, 6 Dec 2013 13:46:51 +0800
Subject: [R] How to generate a smoothed surface for a three dimensional
	dataset?
In-Reply-To: <CACk-te1ZugfsLaVs1V9KNzkn_cYHv=9kwi=MVkSXKwd2BpkoKA@mail.gmail.com>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
	<529F5EC3.5010309@gmail.com>
	<D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>
	<CACk-te1TNCT-WcH8-wnYD5p+8erLOTB=5B=p1WZZAzmggc__MQ@mail.gmail.com>
	<CAMCXXmq1N9SnTG=947LmPQsg4URWsOY4FZZ7N4tO27APPw-HVA@mail.gmail.com>
	<CACk-te1ZugfsLaVs1V9KNzkn_cYHv=9kwi=MVkSXKwd2BpkoKA@mail.gmail.com>
Message-ID: <CA+iL=vzDKnZsBwaQ8Pry2hkiuPzdzo0KsEWvgM8rT9Zqrou6qg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131206/d03babae/attachment.pl>

From guncelduzgun at hotmail.com  Fri Dec  6 05:19:35 2013
From: guncelduzgun at hotmail.com (gncl dzgn)
Date: Fri, 6 Dec 2013 06:19:35 +0200
Subject: [R] Generating restricted numbers
Message-ID: <DUB110-W98F1BEDE93FA28250C3D41CED60@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131206/8a770f8d/attachment.pl>

From keatingk at ksu.edu  Fri Dec  6 06:27:15 2013
From: keatingk at ksu.edu (Karen Keating)
Date: Thu, 5 Dec 2013 23:27:15 -0600
Subject: [R] model selection with step()
Message-ID: <CAK_OPMLBoNRA+-qVEEwTFrFu7KCAwb2xu_JJUWzyoJnRR90wbg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/1efa6245/attachment.pl>

From jairajs at gmail.com  Fri Dec  6 08:27:51 2013
From: jairajs at gmail.com (Jairaj Sathyanarayana)
Date: Thu, 5 Dec 2013 23:27:51 -0800
Subject: [R] How to concatenate the results from parallelized nested foreach
	loops
Message-ID: <CAJmwvqPdc=ds2KA6_KhB2KAPG2bd-fuv_SPC+jOCnhWqPeb9Wg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131205/dad8efe0/attachment.pl>

From r.turner at auckland.ac.nz  Fri Dec  6 10:23:27 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 06 Dec 2013 22:23:27 +1300
Subject: [R] Simple Error Bar
In-Reply-To: <52A17C35.5030007@bitwrit.com.au>
References: <OF0B06921B.1AC5F574-ON65257C39.001CA525-65257C39.001CFF0B@polarisft.com>
	<52A17C35.5030007@bitwrit.com.au>
Message-ID: <52A1978F.9080606@auckland.ac.nz>


Uh, no.  You are forgetting to take the square root of 10, and to divide 
by the square root of 12.

The variance of Y is (exactly) (56^2 - 1)/12, so the variance of Y-bar 
is this quantity over 10,
so the standard deviation of Y-bar is sqrt((56^2 - 1)/12)/sqrt(10).  
Which is approximately
(ignoring the -1) 56/sqrt(12) * 1/sqrt(10).

     cheers,

     Rolf

On 12/06/13 20:26, Jim Lemon wrote:
> On 12/06/2013 04:16 PM, mohan.radhakrishnan at polarisft.com wrote:
>> Hi,
>>                Basic question with basic code.   I am simulating a 
>> set of
>> 'y' values for a standard 'x' value measurement. So here the error bars
>> are very long because the
>> number of samples are very small. Is that correct ? I am plotting the 
>> mean
>> of 'y' on the 'y' axis.
>>
>>
>> Thanks,
>> Mohan
>>
>> x<- data.frame(c(5,10,15,20,25,30,35,40,50,60))
>>   colnames(x)<- c("x")
>>
>>   y<- sample(5:60,10,replace=T)
>>   y1<- sample(5:60,10,replace=T)
>>   y2<- sample(5:60,10,replace=T)
>>   y3<- sample(5:60,10,replace=T)
>>   y4<- sample(5:60,10,replace=T)
>>
>>   z<- data.frame(cbind(x,y,y1,y2,y3,y4))
>>   z$mean<- apply(z[,c(2,3,4,5,6)],2,mean)
>>   z$sd<- apply(z[,c(2,3,4,5,6)],2,sd)
>>   z$se<- z$sd / sqrt(5)
>>
>>
> Hi Mohan,
> As your samples seem to follow a discrete uniform distribution, the 
> standard deviation is approximately the number of integers in the 
> range (56) divided by the number of observations (10).


From mohan.radhakrishnan at polarisft.com  Fri Dec  6 10:33:15 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 6 Dec 2013 15:03:15 +0530
Subject: [R] Simple Error Bar
In-Reply-To: <52A1978F.9080606@auckland.ac.nz>
References: <OF0B06921B.1AC5F574-ON65257C39.001CA525-65257C39.001CFF0B@polarisft.com>
	<52A17C35.5030007@bitwrit.com.au> <52A1978F.9080606@auckland.ac.nz>
Message-ID: <OF1C576906.ADDD9A1A-ON65257C39.00341C10-65257C39.0034737C@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131206/cd5a3fef/attachment.pl>

From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri Dec  6 11:43:53 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 6 Dec 2013 11:43:53 +0100
Subject: [R] How do I print predicted effect sizes in forest plot?
In-Reply-To: <1386277539.51368.YahooMailNeo@web141101.mail.bf1.yahoo.com>
References: <1386277539.51368.YahooMailNeo@web141101.mail.bf1.yahoo.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D99C93B7E@UM-MAIL4112.unimaas.nl>

The model you are fitting is a random-effects model and does not include any potential moderators/covariates. Therefore, the estimated intercept of that model is *the* estimated/predicted (average) effect and it applies to each study. That is why the predict function also just gives you that value. That value is also included in the forest plot (at the bottom). The predicted (average) effect will no longer be the same for each study only if you include covariates in the model.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Alma Wilflinger
> Sent: Thursday, December 05, 2013 22:06
> To: R help <r-help at r-project.org>
> Subject: [R] How do I print predicted effect sizes in forest plot?
> 
> Hi,
> 
> I am struggling a bit with creating a forest plot containing the predicted
> effect size. As seen in other studies these effect sizes are shown per
> study usually as a light grey diamond - which is what I want to achieve.
> 
> The calls I use are:
> iat_result = rma(yi=Mean, vi=Variance_rounded, ni=N, sei=Std_error,
> slab=Study_Name, subset=(Country == "AUT"), data=cma_iat, method="HS")
> 
> summary.rma(iat_result)
> 
> 
> #not sure how to use it or if needed
> #predict(iat_result)
> 
> forest(iat_result)
> 
> 
> At the end I am getting the forest plot as is without the predicted
> values.
> 
> I am not sure if I need the predict function and how to use it? - the
> predict function deliveres the same values as already computed in the rma
> object.
> 
> 
> I checked the manual for package metafor but was not able to find out how
> to print the predicted values per study.
> 
> 
> kind regards, Alma
> 	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri Dec  6 12:00:09 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 6 Dec 2013 12:00:09 +0100
Subject: [R] How do I print predicted effect sizes in forest plot?
In-Reply-To: <1386277539.51368.YahooMailNeo@web141101.mail.bf1.yahoo.com>
References: <1386277539.51368.YahooMailNeo@web141101.mail.bf1.yahoo.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D99C93B95@UM-MAIL4112.unimaas.nl>

One more thing ... You used the command:

iat_result = rma(yi=Mean, vi=Variance_rounded, ni=N, sei=Std_error, slab=Study_Name, subset=(Country == "AUT"), data=cma_iat, method="HS")

This probably does not do what you want it to do. First of all, if you specify vi, there is no need to specify sei (or vice-versa). One is sufficient. But more crucially, I assume 'Mean' is what it says it is - a mean of a certain variable X. And I assume that 'Variance_rounded' is the variance of said variable X. But vi is used to specify the *sampling variance* of yi (or sei is used to specify the standard error), which, for a mean, is the variance divided by N (and the standard error is the SD divided by the square root of N):

http://en.wikipedia.org/wiki/Standard_error_of_the_mean#Standard_error_of_the_mean

So, my hunch is that you are not supplying the right information to the rma() function.

Best,
Wolfgang 

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Alma Wilflinger
> Sent: Thursday, December 05, 2013 22:06
> To: R help <r-help at r-project.org>
> Subject: [R] How do I print predicted effect sizes in forest plot?
> 
> Hi,
> 
> I am struggling a bit with creating a forest plot containing the predicted
> effect size. As seen in other studies these effect sizes are shown per
> study usually as a light grey diamond - which is what I want to achieve.
> 
> The calls I use are:
> iat_result = rma(yi=Mean, vi=Variance_rounded, ni=N, sei=Std_error,
> slab=Study_Name, subset=(Country == "AUT"), data=cma_iat, method="HS")
> 
> summary.rma(iat_result)
> 
> 
> #not sure how to use it or if needed
> #predict(iat_result)
> 
> forest(iat_result)
> 
> 
> At the end I am getting the forest plot as is without the predicted
> values.
> 
> I am not sure if I need the predict function and how to use it? - the
> predict function deliveres the same values as already computed in the rma
> object.
> 
> 
> I checked the manual for package metafor but was not able to find out how
> to print the predicted values per study.
> 
> 
> kind regards, Alma
> 	[[alternative HTML version deleted]]


From balu555 at gmx.de  Fri Dec  6 14:06:26 2013
From: balu555 at gmx.de (Uwe Bohne)
Date: Fri, 6 Dec 2013 14:06:26 +0100 (CET)
Subject: [R] tune an support vector machine
Message-ID: <trinity-8375f7d9-f741-497b-b4be-87454a51d780-1386335186604@3capp-gmx-bs34>


   Hej all,

   actually i try to tune a SVM in R and use the package "e1071" wich works
   pretty well.
   I do some gridsearch in the parameters and get the best possible parameters
   for classification.
   Here is my sample code

   type<-sample(c(-1,1) , 20, replace = TRUE )
   weight<-sample(c(20:50),20, replace=TRUE)
   height<-sample(c(100:200),20, replace=TRUE)
   width<-sample(c(30:50),20,replace=TRUE)
   volume<-sample(c(1000:5000),20,replace=TRUE)

   data<-cbind(type,weight,height,width,volume)
   train<-as.data.frame(data)
   library("e1071")

   features <- c("weight","height","width","volume")
   (formula<-as.formula(paste("type ~ ", paste(features, collapse= "+"))))

   svmtune=tune.svm(formula,  data=train, kernel="radial", cost=2^(-2:5),
   gamma=2^(-2:1),cross=10)
   summary(svmtune)

   My question is if there is a way to tune the features.

   So in other words - what i wanna do is to try all possible combinations of
   features : for example use only (volume) or use (weight, height) or use
   (height,volume,width) and so on for the SVM  and to get the best combination
   back.


   Best wishes

   Uwe

From jvadams at usgs.gov  Fri Dec  6 14:55:15 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 6 Dec 2013 07:55:15 -0600
Subject: [R] Generating restricted numbers
In-Reply-To: <DUB110-W98F1BEDE93FA28250C3D41CED60@phx.gbl>
References: <DUB110-W98F1BEDE93FA28250C3D41CED60@phx.gbl>
Message-ID: <CAN5YmCGNirbQaPKLqUrZGzQsd5j7O5Vo4xmb3q45JKrO5i2kRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131206/dfc14f39/attachment.pl>

From info at aghmed.fsnet.co.uk  Fri Dec  6 15:10:15 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 06 Dec 2013 14:10:15 +0000
Subject: [R] How do I print predicted effect sizes in forest plot?
In-Reply-To: <1386277539.51368.YahooMailNeo@web141101.mail.bf1.yahoo.com
 >
References: <1386277539.51368.YahooMailNeo@web141101.mail.bf1.yahoo.com>
Message-ID: <Zen-1Vow6o-0006iI-Co@smarthost01a.mail.zen.net.uk>

At 21:05 05/12/2013, Alma Wilflinger wrote:
>Hi,
>
>I am struggling a bit with creating a forest plot containing the 
>predicted effect size. As seen in other studies these effect sizes 
>are shown per study usually as a light grey diamond - which is what 
>I want to achieve.
>
>The calls I use are:
>iat_result = rma(yi=Mean, vi=Variance_rounded, ni=N, sei=Std_error, 
>slab=Study_Name, subset=(Country == "AUT"), data=cma_iat, method="HS")

Alma
You do not need to specify both vi and sei as one is sufficient and 
you do not need ni as well.
I realise that is not the question you asked (which Wolfgang has 
already answered).


>summary.rma(iat_result)
>
>
>#not sure how to use it or if needed
>#predict(iat_result)
>
>forest(iat_result)
>
>
>At the end I am getting the forest plot as is without the predicted values.
>
>I am not sure if I need the predict function and how to use it? - 
>the predict function deliveres the same values as already computed 
>in the rma object.
>
>
>I checked the manual for package metafor but was not able to find 
>out how to print the predicted values per study.
>
>
>kind regards, Alma
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From hwborchers at googlemail.com  Fri Dec  6 16:00:18 2013
From: hwborchers at googlemail.com (Hans W Borchers)
Date: Fri, 6 Dec 2013 15:00:18 +0000
Subject: [R] Double Infinite Integration
References: <CAB=y=yM=1Oqbm3d3Msdeoq7ORvSaxEo8jkLf=HNeNViw8AFXVg@mail.gmail.com>
Message-ID: <loom.20131206T153245-295@post.gmane.org>

Aya Anas <aanas <at> feps.edu.eg> writes:

> Hello all,
> 
> I need to perform the following integration where the integrand is the
> product of three functions:
> f(x)g(y)z(x,y)
> 
> the limits of x are(0,inf) and the limits of y are(-inf,inf).
> 
> Could this be done using R?

There is a saying: Don't ask Can this be done in R?, ask How is it done?

Extracting function f(x) from the inner integral may not always be the best 
idea. And applying package 'cubature' will not work as adaptIntegrate() does 
not really handle non-finite interval limits.

As an example, let us assume the functions are

    f <- function(x) x
    g <- function(y) y^2
    h <- function(x, y) exp(-(x^2+y^2))

Define a function that calculates the inner integral:

    F1 <- function(x) {
        fun <- function(y) f(x) * g(y) * h(x, y)
        integrate(fun, -Inf, Inf)$value
    }
    F1 <- Vectorize(F1)  # requested when using integrate()

We have to check that integrate() is indeed capable of computing this integrand 
over an infinite interval.

    F1(c(0:4))           # looks good
    ## [1] 0.000000e+00 3.260247e-01 3.246362e-02 3.281077e-04 3.989274e-07

Now integrate this function over the second (infinite) interval.
    
    integrate(F1, 0, Inf)
    ## 0.4431135 with absolute error < 2.4e-06

Correct, as the integral is equal to sqrt(pi)/4 ~ 0.44311346...

If we extract f(x) from the inner integral the value of the integral and the
computation times will be the same, but the overall handling will be slightly 
more complicated.

> I tried using the function integrate 2 times, but it didn't work:
> z<- function(x,y) {
> 
> }
> f<-function(x){
> rr<-"put here the function in x" *integrate(function(y) z(x, y),
> -Inf,Inf)$value
> return(rr)
> }
> 
> rr2<-integrate(function(x) f(x), 0, Inf)$value
> print(rr2)
> 
>    I didn't get any output at all!!!
> 
> Thanks,
> Aya
>


From smartpink111 at yahoo.com  Fri Dec  6 16:36:14 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 6 Dec 2013 07:36:14 -0800 (PST)
Subject: [R] Merging different columns in one matrix
Message-ID: <1386344174.85886.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this helps:

dat1 <- read.table(text="
a???? a???? b???? b???? c???? c
x???? y???? x???? y???? x???? y
12?? 34?? 256? 25??? 5?? 32
5??? 45??? 23?? 452?? 21?? 45",sep="",header=TRUE,stringsAsFactors=FALSE,check.names=FALSE) 


?mat1 <- matrix(0,5,5,dimnames=list(NULL,c("x",letters[1:4])))
?mat1[,1]<- sort(unique(as.numeric(unlist(dat1[-1,which(dat1=="x",arr.ind=TRUE)[,2]]))))

dat1New <- dat1[-1,which(dat1=="x",arr.ind=TRUE)[,2]]
dat2New <- dat1[-1,which(dat1=="y",arr.ind=TRUE)[,2]]
mat1[,2:4] <-sapply(seq_len(ncol(dat1New)),function(i) {x1 <-dat2New[match(mat1[,1],dat1New[,i]),i]
x1[is.na(x1)] <-0
as.numeric(x1)})
?mat1
#?????? x? a?? b? c d
#[1,]?? 5 45?? 0 32 0
#[2,]? 12 34?? 0? 0 0
#[3,]? 21? 0?? 0 45 0
#[4,]? 23? 0 452? 0 0
#[5,] 256? 0? 25? 0 0


A.K.


Hello everyone, 

I have a dataframe made as follows: 

a ? ? a ? ? b ? ? b ? ? c ? ? c 
x ? ? y ? ? x ? ? y ? ? x ? ? y 
12 ? 34 ? 256 ?25 ? ?5 ? 32 
5 ? ?45 ? ?23 ? 452 ? 21 ? 45 
... ? ... ? ?... ? ... ? ?... ? ?... 

My intention is to create just one matrix made as follows 

x ? ? a ? ? b ? ? c ? ? d 
5 ? ? 45 ? 0 ? ? 32 ? ?0 
12 ? 34 ? 0 ? ? 0 ? ? ?0 
21 ? 0 ? ? 0 ? ? 45 ? ?0 
23 ? 0 ? ?452 ? 0 ? ? 0 
256 ?... ?... ? ? ... ? ... 
... 

As you can see I want on the first column all the values 
collected from all the x columns and ordered. On the other columns I 
want the y-values related to every letter (a-b-c...). For example the 
first value on the x column is 5 (the smallest). It is present in the a 
x-values (first matrix) so in the second table I report its related 
y-value (45). However 5 is not present in the b x-values so I report a 0
 on the second table. And so on. 

I don't know if it's a difficult task but I had several problems
 with the double header handling and the data. I looked for some clues 
on the internet but documentation is very fragmented and lacking. 

(So, in addition, any recommendation for good R books?)


From wandrson01 at gmail.com  Fri Dec  6 16:44:22 2013
From: wandrson01 at gmail.com (Walter Anderson)
Date: Fri, 06 Dec 2013 09:44:22 -0600
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
Message-ID: <52A1F0D6.9080108@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131206/2d67133f/attachment.pl>

From petr.pikal at precheza.cz  Fri Dec  6 16:59:24 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 6 Dec 2013 15:59:24 +0000
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <52A1F0D6.9080108@gmail.com>
References: <52A1F0D6.9080108@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA52E5@SRVEXCHMBX.precheza.cz>

Hi

The warning is due to fact that "if" takes only single scalar value not an entire vector.

Maybe you shall explain more clearly what result do you expect.

I bet that there is vectorised solution to your problem but I am lost in your ifs and cannot follow what shall be the output.

Please use 

dput(head(df))

when showing input data and clearly describe intended result.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Walter Anderson
> Sent: Friday, December 06, 2013 4:44 PM
> To: r-help at r-project.org
> Subject: [R] Need help figuring out sapply (and similar functions) with
> multiple parameter user defined function
> 
> I am having trouble understanding how to use sapply (or similar
> functions) with a user defined function with multiple parameters.
> 
> I have the following functions defined
> 
>     q1.ans <- function(x)
>     {
>        retVal = 0
>        if (x == 1) {
>          retVal = 1
>        } else if (x ==2) {
>          retVal = 2
>        }
>        return (retVal)
>     }
>     q2.ans <- function(x)
>     {
>        retVal = 0
>        if (x == 1) {
>          retVal = 1
>        } else if (x ==2) {
>          retVal = 3
>        }
>        return (retVal)
>     }
>     q3.ans <- function(x)
>     {
>        retVal = 0
>        if (x == 1) {
>          retVal = 2
>        } else if (x ==2) {
>          retVal = 3
>        }
>        return (retVal)
>     }
> 
>     evaluate.questions <- function(q.1,q.2,q.3)
>     {
>        a <- q1.ans(q.1)
>        b <- q2.ans(q.2)
>        c <- q3.ans(q.3)
>        retVal = 0   # Set default value to be no preference
>        # The following code only implements those values from the state
>     machine that show a preference (ID's 5,9,11,13-15,17-18,21,23-27)
>        if (a == 0) {
>          if (b == 1) {
>            if (c == 1) {
>              retVal = 1  # State machine ID 5
>            }
>          } else if (b == 2) {
>            if (c == 2) {
>              retVal = 2  # State machine ID 9
>            }
>          }
>        } else if (a == 1) {
>          if (b == 0) {
>            if (c == 1) {
>              retVal = 1  # State machine ID 11
>            }
>          } else if (b == 1) {
>            retVal = 1    # State machine ID's 13-15, value of C doesn't
>     matter
>          } else if (b == 2) {
>            if (c == 1) {
>              retVal = 1  # State machine ID 17
>            } else if (c == 2) {
>              retVal = 2  # State machine ID 18
>            }
>          }
>        } else if (a == 2) {
>          if (b == 0) {
>            if (c == 2) {
>              retVal = 2  # State machine ID 21
>            }
>          } else if (b == 1) {
>            if (c == 1) {
>              retVal = 1  # State machine ID 23
>            } else if (c == 2) {
>              retVal = 2  # State machine ID 24
>            }
>          } else if (b == 2) {
>            retVal = 2    # State machine ID's 25-27, value of C doesn't
>     matter
>          }
>        }
>        return (retVal)
>     }
> 
> And a data set that looks like this:
> 
>     ID,Q1,Q2,Q3
>     1,2,2,2
>     2,2,1,1
>     3,1,1,1
>     4,1,2,2
>     5,2,2,1
>     6,1,2,1
>     ...
> 
> 
> I have been researching and it appears that I should be using the
> sapply function to apply the evaluate.question function above to each
> row in the data frame like this
> 
> preferences <- sapply(df, evaluate.questions, function(x,y,z)
> evaluate.questions(df['Q1'],df['Q2'],df['Q3']))
> 
> Unfortunately this doesn't work and the problem appears that the sapply
> function is not feeding the parameters to the evaluate.questions
> function as I expect.  Can someone provide some guidance on what I am
> doing wrong?
> 
> This is the error message I am getting:
> 
> Error in x --1 :
>    Comparison (1) is possible only for atomic and list types In
> addition: warning messages:
> In if (x == 1) { :
>    the condition has length > 1 and only the first element will be used
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wandrson01 at gmail.com  Fri Dec  6 17:11:21 2013
From: wandrson01 at gmail.com (Walter Anderson)
Date: Fri, 06 Dec 2013 10:11:21 -0600
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA52E5@SRVEXCHMBX.precheza.cz>
References: <52A1F0D6.9080108@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA52E5@SRVEXCHMBX.precheza.cz>
Message-ID: <52A1F729.9070302@gmail.com>

Thank you for your response!

I am attempting to determine a preference from the answers to three 
binomial questions;

q.1) 1 or 2    q.2) 1 or 3    q.3) 2 or 3

However, the questions are coded with either a 1 or 2 (though no answer 
is also possible) and the first three functions (q#.ans) convert those 
values to the 1,2,or 3 shown above

and generate one of the following result for each row of the table; 0 - 
no preference, or 1,2,3 which indicates the preference indicated by the 
question

The if's implement the following state conditions:

   # ID A  B  C  Preference
   # 1  0  0  0  None
   # 2  0  0  1  None
   # 3  0  0  2  None
   # 4  0  1  0  None
   # 5  0  1  1  Option 1
   # 6  0  1  2  None
   # 7  0  2  0  None
   # 8  0  2  1  None
   # 9  0  2  2  Option 2
   # 10 1  0  0  None
   # 11 1  0  1  Option 1
   # 12 1  0  2  None
   # 13 1  1  0  Option 1
   # 14 1  1  1  Option 1
   # 15 1  1  2  Option 1
   # 16 1  2  0  None
   # 17 1  2  1  Option 1
   # 18 1  2  2  Option 2
   # 19 2  0  0  None
   # 20 2  0  1  None
   # 21 2  0  2  Option 2
   # 22 2  1  0  None
   # 23 2  1  1  Option 1
   # 24 2  1  2  Option 2
   # 25 2  2  0  Option 2
   # 26 2  2  1  Option 2
   # 27 2  2  2  Option 2

The if statement only implements those values from the state machine 
that show a preference (ID's 5,9,11,13-15,17-18,21,23-27)

On 12/06/2013 09:59 AM, PIKAL Petr wrote:
> Hi
>
> The warning is due to fact that "if" takes only single scalar value not an entire vector.
>
> Maybe you shall explain more clearly what result do you expect.
>
> I bet that there is vectorised solution to your problem but I am lost in your ifs and cannot follow what shall be the output.
>
> Please use
>
> dput(head(df))
>
> when showing input data and clearly describe intended result.
>
> Regards
> Petr
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Walter Anderson
>> Sent: Friday, December 06, 2013 4:44 PM
>> To: r-help at r-project.org
>> Subject: [R] Need help figuring out sapply (and similar functions) with
>> multiple parameter user defined function
>>
>> I am having trouble understanding how to use sapply (or similar
>> functions) with a user defined function with multiple parameters.
>>
>> I have the following functions defined
>>
>>      q1.ans <- function(x)
>>      {
>>         retVal = 0
>>         if (x == 1) {
>>           retVal = 1
>>         } else if (x ==2) {
>>           retVal = 2
>>         }
>>         return (retVal)
>>      }
>>      q2.ans <- function(x)
>>      {
>>         retVal = 0
>>         if (x == 1) {
>>           retVal = 1
>>         } else if (x ==2) {
>>           retVal = 3
>>         }
>>         return (retVal)
>>      }
>>      q3.ans <- function(x)
>>      {
>>         retVal = 0
>>         if (x == 1) {
>>           retVal = 2
>>         } else if (x ==2) {
>>           retVal = 3
>>         }
>>         return (retVal)
>>      }
>>
>>      evaluate.questions <- function(q.1,q.2,q.3)
>>      {
>>         a <- q1.ans(q.1)
>>         b <- q2.ans(q.2)
>>         c <- q3.ans(q.3)
>>         retVal = 0   # Set default value to be no preference
>>         # The following code only implements those values from the state
>>      machine that show a preference (ID's 5,9,11,13-15,17-18,21,23-27)
>>         if (a == 0) {
>>           if (b == 1) {
>>             if (c == 1) {
>>               retVal = 1  # State machine ID 5
>>             }
>>           } else if (b == 2) {
>>             if (c == 2) {
>>               retVal = 2  # State machine ID 9
>>             }
>>           }
>>         } else if (a == 1) {
>>           if (b == 0) {
>>             if (c == 1) {
>>               retVal = 1  # State machine ID 11
>>             }
>>           } else if (b == 1) {
>>             retVal = 1    # State machine ID's 13-15, value of C doesn't
>>      matter
>>           } else if (b == 2) {
>>             if (c == 1) {
>>               retVal = 1  # State machine ID 17
>>             } else if (c == 2) {
>>               retVal = 2  # State machine ID 18
>>             }
>>           }
>>         } else if (a == 2) {
>>           if (b == 0) {
>>             if (c == 2) {
>>               retVal = 2  # State machine ID 21
>>             }
>>           } else if (b == 1) {
>>             if (c == 1) {
>>               retVal = 1  # State machine ID 23
>>             } else if (c == 2) {
>>               retVal = 2  # State machine ID 24
>>             }
>>           } else if (b == 2) {
>>             retVal = 2    # State machine ID's 25-27, value of C doesn't
>>      matter
>>           }
>>         }
>>         return (retVal)
>>      }
>>
>> And a data set that looks like this:
>>
>>      ID,Q1,Q2,Q3
>>      1,2,2,2
>>      2,2,1,1
>>      3,1,1,1
>>      4,1,2,2
>>      5,2,2,1
>>      6,1,2,1
>>      ...
>>
>>
>> I have been researching and it appears that I should be using the
>> sapply function to apply the evaluate.question function above to each
>> row in the data frame like this
>>
>> preferences <- sapply(df, evaluate.questions, function(x,y,z)
>> evaluate.questions(df['Q1'],df['Q2'],df['Q3']))
>>
>> Unfortunately this doesn't work and the problem appears that the sapply
>> function is not feeding the parameters to the evaluate.questions
>> function as I expect.  Can someone provide some guidance on what I am
>> doing wrong?
>>
>> This is the error message I am getting:
>>
>> Error in x --1 :
>>     Comparison (1) is possible only for atomic and list types In
>> addition: warning messages:
>> In if (x == 1) { :
>>     the condition has length > 1 and only the first element will be used
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri Dec  6 17:30:54 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 6 Dec 2013 16:30:54 +0000
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <52A1F729.9070302@gmail.com>
References: <52A1F0D6.9080108@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA52E5@SRVEXCHMBX.precheza.cz>
	<52A1F729.9070302@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5408@SRVEXCHMBX.precheza.cz>

Hi

So first step is over. Anyway, is there any problem with using dput as I suggested?

Instead of using your date I need to generate my own.

A<-sample(0:2, 10, replace=T)
B<-sample(0:2, 10, replace=T)
C<-sample(0:2, 10, replace=T)
df<-data.frame(A,B,C)

df[df[,2]==2,2]<-3
df$C<-as.numeric(as.character(factor(df$C, labels=c(0,2,3))))

df
   A B C
1  0 3 3
2  0 1 2
3  0 3 2
4  1 0 3
5  1 0 3
6  2 3 2
7  1 3 2
8  2 3 3
9  1 1 0
10 0 0 3

> -----Original Message-----
> From: Walter Anderson [mailto:wandrson01 at gmail.com]
> Sent: Friday, December 06, 2013 5:11 PM
> To: PIKAL Petr; r-help at r-project.org
> Subject: Re: [R] Need help figuring out sapply (and similar functions)
> with multiple parameter user defined function
> 
> Thank you for your response!
> 
> I am attempting to determine a preference from the answers to three
> binomial questions;
> 
> q.1) 1 or 2    q.2) 1 or 3    q.3) 2 or 3
> 
> However, the questions are coded with either a 1 or 2 (though no answer
> is also possible) and the first three functions (q#.ans) convert those
> values to the 1,2,or 3 shown above

Instead of those tricky ifs (uff uff) you can use either of these

df[df[,2]==2,2]<-3
df$C<-as.numeric(as.character(factor(df$C, labels=c(0,2,3))))

df
   A B C
1  0 3 3
2  0 1 2
3  0 3 2
4  1 0 3
5  1 0 3
6  2 3 2
7  1 3 2
8  2 3 3
9  1 1 0
10 0 0 3

And here I am lost again.

Please, can you clearly state the way how do you want to choose preferences based on values in those three columns.

Regards
Petr

> 
> and generate one of the following result for each row of the table; 0 -
> no preference, or 1,2,3 which indicates the preference indicated by the
> question
> 
> The if's implement the following state conditions:
> 
>    # ID A  B  C  Preference
>    # 1  0  0  0  None
>    # 2  0  0  1  None
>    # 3  0  0  2  None
>    # 4  0  1  0  None
>    # 5  0  1  1  Option 1
>    # 6  0  1  2  None
>    # 7  0  2  0  None
>    # 8  0  2  1  None
>    # 9  0  2  2  Option 2
>    # 10 1  0  0  None
>    # 11 1  0  1  Option 1
>    # 12 1  0  2  None
>    # 13 1  1  0  Option 1
>    # 14 1  1  1  Option 1
>    # 15 1  1  2  Option 1
>    # 16 1  2  0  None
>    # 17 1  2  1  Option 1
>    # 18 1  2  2  Option 2
>    # 19 2  0  0  None
>    # 20 2  0  1  None
>    # 21 2  0  2  Option 2
>    # 22 2  1  0  None
>    # 23 2  1  1  Option 1
>    # 24 2  1  2  Option 2
>    # 25 2  2  0  Option 2
>    # 26 2  2  1  Option 2
>    # 27 2  2  2  Option 2
> 
> The if statement only implements those values from the state machine
> that show a preference (ID's 5,9,11,13-15,17-18,21,23-27)
> 
> On 12/06/2013 09:59 AM, PIKAL Petr wrote:
> > Hi
> >
> > The warning is due to fact that "if" takes only single scalar value
> not an entire vector.
> >
> > Maybe you shall explain more clearly what result do you expect.
> >
> > I bet that there is vectorised solution to your problem but I am lost
> in your ifs and cannot follow what shall be the output.
> >
> > Please use
> >
> > dput(head(df))
> >
> > when showing input data and clearly describe intended result.
> >
> > Regards
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of Walter Anderson
> >> Sent: Friday, December 06, 2013 4:44 PM
> >> To: r-help at r-project.org
> >> Subject: [R] Need help figuring out sapply (and similar functions)
> >> with multiple parameter user defined function
> >>
> >> I am having trouble understanding how to use sapply (or similar
> >> functions) with a user defined function with multiple parameters.
> >>
> >> I have the following functions defined
> >>
> >>      q1.ans <- function(x)
> >>      {
> >>         retVal = 0
> >>         if (x == 1) {
> >>           retVal = 1
> >>         } else if (x ==2) {
> >>           retVal = 2
> >>         }
> >>         return (retVal)
> >>      }
> >>      q2.ans <- function(x)
> >>      {
> >>         retVal = 0
> >>         if (x == 1) {
> >>           retVal = 1
> >>         } else if (x ==2) {
> >>           retVal = 3
> >>         }
> >>         return (retVal)
> >>      }
> >>      q3.ans <- function(x)
> >>      {
> >>         retVal = 0
> >>         if (x == 1) {
> >>           retVal = 2
> >>         } else if (x ==2) {
> >>           retVal = 3
> >>         }
> >>         return (retVal)
> >>      }
> >>
> >>      evaluate.questions <- function(q.1,q.2,q.3)
> >>      {
> >>         a <- q1.ans(q.1)
> >>         b <- q2.ans(q.2)
> >>         c <- q3.ans(q.3)
> >>         retVal = 0   # Set default value to be no preference
> >>         # The following code only implements those values from the
> state
> >>      machine that show a preference (ID's 5,9,11,13-15,17-18,21,23-
> 27)
> >>         if (a == 0) {
> >>           if (b == 1) {
> >>             if (c == 1) {
> >>               retVal = 1  # State machine ID 5
> >>             }
> >>           } else if (b == 2) {
> >>             if (c == 2) {
> >>               retVal = 2  # State machine ID 9
> >>             }
> >>           }
> >>         } else if (a == 1) {
> >>           if (b == 0) {
> >>             if (c == 1) {
> >>               retVal = 1  # State machine ID 11
> >>             }
> >>           } else if (b == 1) {
> >>             retVal = 1    # State machine ID's 13-15, value of C
> doesn't
> >>      matter
> >>           } else if (b == 2) {
> >>             if (c == 1) {
> >>               retVal = 1  # State machine ID 17
> >>             } else if (c == 2) {
> >>               retVal = 2  # State machine ID 18
> >>             }
> >>           }
> >>         } else if (a == 2) {
> >>           if (b == 0) {
> >>             if (c == 2) {
> >>               retVal = 2  # State machine ID 21
> >>             }
> >>           } else if (b == 1) {
> >>             if (c == 1) {
> >>               retVal = 1  # State machine ID 23
> >>             } else if (c == 2) {
> >>               retVal = 2  # State machine ID 24
> >>             }
> >>           } else if (b == 2) {
> >>             retVal = 2    # State machine ID's 25-27, value of C
> doesn't
> >>      matter
> >>           }
> >>         }
> >>         return (retVal)
> >>      }
> >>
> >> And a data set that looks like this:
> >>
> >>      ID,Q1,Q2,Q3
> >>      1,2,2,2
> >>      2,2,1,1
> >>      3,1,1,1
> >>      4,1,2,2
> >>      5,2,2,1
> >>      6,1,2,1
> >>      ...
> >>
> >>
> >> I have been researching and it appears that I should be using the
> >> sapply function to apply the evaluate.question function above to
> each
> >> row in the data frame like this
> >>
> >> preferences <- sapply(df, evaluate.questions, function(x,y,z)
> >> evaluate.questions(df['Q1'],df['Q2'],df['Q3']))
> >>
> >> Unfortunately this doesn't work and the problem appears that the
> >> sapply function is not feeding the parameters to the
> >> evaluate.questions function as I expect.  Can someone provide some
> >> guidance on what I am doing wrong?
> >>
> >> This is the error message I am getting:
> >>
> >> Error in x --1 :
> >>     Comparison (1) is possible only for atomic and list types In
> >> addition: warning messages:
> >> In if (x == 1) { :
> >>     the condition has length > 1 and only the first element will be
> >> used
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html and provide commented, minimal, self-contained,
> >> reproducible code.


From wdunlap at tibco.com  Fri Dec  6 17:43:31 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 6 Dec 2013 16:43:31 +0000
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <52A1F0D6.9080108@gmail.com>
References: <52A1F0D6.9080108@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1AEE0@PA-MBX01.na.tibco.com>

> I have been researching and it appears that I should be using the sapply
> function to apply the evaluate.question function above to each row in
> the data frame like this

Read the documentation more closely: sapply(dataFrame, func)
applies func() to each column, not row, of dataFrame.

> preferences <- sapply(df, evaluate.questions, function(x,y,z)
> evaluate.questions(df['Q1'],df['Q2'],df['Q3']))

Furthermore,
    sapply(X = dataFrame, FUN = func, extraArgument)
calls
    func(dataFrame[, i], extraArgument)
for i in seq_len(ncol(dataFrame).

One problem is that FUN=evaluate.questions takes 3 arguments and
you give it only 2.  Another problem is that the third argument you
pass to sapply is a function (of 3 arguments) and FUN is not expecting
any of its arguments to be functions.

It may be easier for you to not use sapply here, but to use for-loops and
come up with something that works.  (Write tests that will indicate whether
it works or not in a variety of situations.)  Then transform it to use things
like ifelse() and sapply() to make it more readable and run faster.

> Unfortunately this doesn't work and the problem appears that the sapply
> function is not feeding the parameters to the evaluate.questions
> function as I expect.  Can someone provide some guidance on what I am
> doing wrong?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Walter Anderson
> Sent: Friday, December 06, 2013 7:44 AM
> To: r-help at r-project.org
> Subject: [R] Need help figuring out sapply (and similar functions) with multiple parameter
> user defined function
> 
> I am having trouble understanding how to use sapply (or similar
> functions) with a user defined function with multiple parameters.
> 
> I have the following functions defined
> 
>     q1.ans <- function(x)
>     {
>        retVal = 0
>        if (x == 1) {
>          retVal = 1
>        } else if (x ==2) {
>          retVal = 2
>        }
>        return (retVal)
>     }
>     q2.ans <- function(x)
>     {
>        retVal = 0
>        if (x == 1) {
>          retVal = 1
>        } else if (x ==2) {
>          retVal = 3
>        }
>        return (retVal)
>     }
>     q3.ans <- function(x)
>     {
>        retVal = 0
>        if (x == 1) {
>          retVal = 2
>        } else if (x ==2) {
>          retVal = 3
>        }
>        return (retVal)
>     }
> 
>     evaluate.questions <- function(q.1,q.2,q.3)
>     {
>        a <- q1.ans(q.1)
>        b <- q2.ans(q.2)
>        c <- q3.ans(q.3)
>        retVal = 0   # Set default value to be no preference
>        # The following code only implements those values from the state
>        # machine that show a preference (ID's 5,9,11,13-15,17-18,21,23-27)
>        if (a == 0) {
>          if (b == 1) {
>            if (c == 1) {
>              retVal = 1  # State machine ID 5
>            }
>          } else if (b == 2) {
>            if (c == 2) {
>              retVal = 2  # State machine ID 9
>            }
>          }
>        } else if (a == 1) {
>          if (b == 0) {
>            if (c == 1) {
>              retVal = 1  # State machine ID 11
>            }
>          } else if (b == 1) {
>            retVal = 1    # State machine ID's 13-15, value of C doesn't matter
>          } else if (b == 2) {
>            if (c == 1) {
>              retVal = 1  # State machine ID 17
>            } else if (c == 2) {
>              retVal = 2  # State machine ID 18
>            }
>          }
>        } else if (a == 2) {
>          if (b == 0) {
>            if (c == 2) {
>              retVal = 2  # State machine ID 21
>            }
>          } else if (b == 1) {
>            if (c == 1) {
>              retVal = 1  # State machine ID 23
>            } else if (c == 2) {
>              retVal = 2  # State machine ID 24
>            }
>          } else if (b == 2) {
>            retVal = 2    # State machine ID's 25-27, value of C doesn't matter
>          }
>        }
>        return (retVal)
>     }
> 
> And a data set that looks like this:
> 
>     ID,Q1,Q2,Q3
>     1,2,2,2
>     2,2,1,1
>     3,1,1,1
>     4,1,2,2
>     5,2,2,1
>     6,1,2,1
>     ...
> 
> 
> I have been researching and it appears that I should be using the sapply
> function to apply the evaluate.question function above to each row in
> the data frame like this
> 
> preferences <- sapply(df, evaluate.questions, function(x,y,z)
> evaluate.questions(df['Q1'],df['Q2'],df['Q3']))
> 
> Unfortunately this doesn't work and the problem appears that the sapply
> function is not feeding the parameters to the evaluate.questions
> function as I expect.  Can someone provide some guidance on what I am
> doing wrong?
> 
> This is the error message I am getting:
> 
> Error in x --1 :
>    Comparison (1) is possible only for atomic and list types
> In addition: warning messages:
> In if (x == 1) { :
>    the condition has length > 1 and only the first element will be used
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lauriebayet at gmail.com  Fri Dec  6 15:46:02 2013
From: lauriebayet at gmail.com (laurie bayet)
Date: Fri, 6 Dec 2013 15:46:02 +0100
Subject: [R] mixed model ANCOVA
Message-ID: <CAGHpV7x_wkAnuA_sK4FHvdNft3nyPr31y+zYLLYaYpDaOi8Xyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131206/ec381b35/attachment.pl>

From Sarah.Pohl at helmholtz-hzi.de  Fri Dec  6 14:44:40 2013
From: Sarah.Pohl at helmholtz-hzi.de (Sarah Pohl)
Date: Fri, 6 Dec 2013 13:44:40 +0000
Subject: [R] Gene Ontology Profiling on Single Data Set with Different
	Species?
Message-ID: <17901613767ACB4ABD1C49D932B802011FA3B232@Exchange03.helmholtz-hzi.de>

Hey everyone,

I have a list of genes for which I would like to get Gene Ontology profiles (i.e. what are the most common GO terms). First I had a look at topGO, but since that compares two data sets, which I don?t have, it wasn?t right for this purpose. I then found goProfiles, which seems to do exactly what I wanted, but there is one problem: the genes I have don?t all come from the same organism, so there?s no organism annotation package.
Do you know of any other R package that would do the trick if I give it my list of genes and their GO terms? Or do I have to create my own annotation package and then use goProfiles?

Regards,
Sarah

-----

Sarah Pohl
PhD student

Helmholtz Centre for Infection Research

eMail: sarah.pohl at helmholtz-hzi.de


________________________________

Helmholtz-Zentrum f?r Infektionsforschung GmbH | Inhoffenstra?e 7 | 38124 Braunschweig | www.helmholtz-hzi.de
Das HZI ist seit 2007 zertifiziertes Mitglied im "audit berufundfamilie"

Vorsitzende des Aufsichtsrates: MinDir?in B?rbel Brumme-Bothe, Bundesministerium f?r Bildung und Forschung
Stellvertreter: MinDirig R?diger Eichel, Nieders?chsisches Ministerium f?r Wissenschaft und Kultur
Gesch?ftsf?hrung: Prof. Dr. Dirk Heinz
Gesellschaft mit beschr?nkter Haftung (GmbH)
Sitz der Gesellschaft: Braunschweig
Handelsregister: Amtsgericht Braunschweig, HRB 477

From wbonat at gmail.com  Fri Dec  6 18:01:49 2013
From: wbonat at gmail.com (Wagner Bonat)
Date: Fri, 6 Dec 2013 15:01:49 -0200
Subject: [R] Help - Trace of matrices
Message-ID: <CANt=4Mj8ihh9+QEZocWH=rJsFcUcOy=wVkYCfQNTmsp8dS6Jsw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131206/ffb5abd2/attachment.pl>

From b_miner at live.com  Fri Dec  6 18:25:54 2013
From: b_miner at live.com (Brian)
Date: Fri, 6 Dec 2013 12:25:54 -0500
Subject: [R] Easy Uplift Tree Classify Error
Message-ID: <BLU0-SMTP205975BED51B825A411DD58E3D60@phx.gbl>

Does anyone know if the error being generated when trying to predict 
test set data in the Easy Uplift Tree package is something fixable by 
the user or is this a bug in the program making the package essentially 
non-operable?
This is from the package documentation and fails on the last step of 
applying the model to the test set:


install.packages("EasyUpliftTree")
library(EasyUpliftTree)
library(survival)
data(colon)


#APPEARS TO WORK

sample.data <- na.omit(colon[colon$rx != "Lev" & colon$etype == 2, ])
treat <- ifelse(sample.data$rx == "Lev+5FU", 1, 0)
y <- ifelse(sample.data$status == 0, 1, 0)
x <- sample.data[, c(4:9, 11:14)]
x$v1 <- factor(x$sex)
x$v2 <- factor(x$obstruct)
x$v3 <- factor(x$perfor)
x$v4 <- factor(x$adhere)
x$v5 <- factor(x$differ)
x$v6 <- factor(x$extent)
x$v7 <- factor(x$surg)
x$v8 <- factor(x$node4)


index <- 1:nrow(x)
train.index <- index[(index%%2 == 0)]
test.index <- index[index%%2 != 0]
y.train <- y[train.index]
x.train <- x[train.index, ]
treat.train <- treat[train.index]
y.test <- y[test.index]
x.test <- x[test.index, ]
treat.test <- treat[test.index]
uplift.tree <- buildUpliftTree(y.train, treat.train, x.train)
print(uplift.tree)


#FAILS

apply(1:nrow(x.test), function(i) classify(uplift.tree, x.test[i, ]))

#Error in match.fun(FUN) : argument "FUN" is missing, with no default


From HDoran at air.org  Fri Dec  6 18:43:40 2013
From: HDoran at air.org (Doran, Harold)
Date: Fri, 6 Dec 2013 17:43:40 +0000
Subject: [R] Help - Trace of matrices
In-Reply-To: <CANt=4Mj8ihh9+QEZocWH=rJsFcUcOy=wVkYCfQNTmsp8dS6Jsw@mail.gmail.com>
References: <CANt=4Mj8ihh9+QEZocWH=rJsFcUcOy=wVkYCfQNTmsp8dS6Jsw@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686794B3EFC@DC1VEX10MB001.air.org>

A fast computation I use is based on the following:

A <- matrix(rnorm(16), ncol = 4)
B <- matrix(rnorm(16), ncol = 4)
C <- A %*% B
sum(diag(C))

### This is less expensive to compute when the matrix multiplication is expensive
sum(A * t(B))

So, it just uses the elementwise calculations and sums over all cels

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Wagner Bonat
Sent: Friday, December 06, 2013 12:02 PM
To: r-help at r-project.org
Subject: [R] Help - Trace of matrices

Dear,

I need to calculate the following equation

tr(Sigma^-1 %*% D.Sigma)

I know only Sigma (positive definite) and D.Sigma (derivative of Sigma), a naive code is

sum(diag(solve(Sigma,D.Sigma)))

but these matrices are dense and big dimension (10000 x 10000), and I need to evaluate this equation many times.
What is the better way to evaluate this equation in R ?
Note that I need only the diagonal, I think is possible to calculate only the diagnonal, but how ??

--
Wagner Hugo Bonat
LEG - Laborat?rio de Estat?stica e Geoinforma??o UFPR - Universidade Federal do Paran?

	[[alternative HTML version deleted]]


From wandrson01 at gmail.com  Fri Dec  6 18:57:46 2013
From: wandrson01 at gmail.com (Walter Anderson)
Date: Fri, 06 Dec 2013 11:57:46 -0600
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1AEE0@PA-MBX01.na.tibco.com>
References: <52A1F0D6.9080108@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1AEE0@PA-MBX01.na.tibco.com>
Message-ID: <52A2101A.6030202@gmail.com>

On 12/06/2013 10:43 AM, William Dunlap wrote:
>> I have been researching and it appears that I should be using the sapply
>> function to apply the evaluate.question function above to each row in
>> the data frame like this
> Read the documentation more closely: sapply(dataFrame, func)
> applies func() to each column, not row, of dataFrame.
I misunderstood.  I thought it was apply the func to each row...  My mistake
>> preferences <- sapply(df, evaluate.questions, function(x,y,z)
>> evaluate.questions(df['Q1'],df['Q2'],df['Q3']))
> Furthermore,
>      sapply(X = dataFrame, FUN = func, extraArgument)
> calls
>      func(dataFrame[, i], extraArgument)
> for i in seq_len(ncol(dataFrame).
>
> One problem is that FUN=evaluate.questions takes 3 arguments and
> you give it only 2.  Another problem is that the third argument you
> pass to sapply is a function (of 3 arguments) and FUN is not expecting
> any of its arguments to be functions.
I will need to think about this, I am not sure I understand.  I really 
don't seem to understand how any of the apply functions seem to work.
> It may be easier for you to not use sapply here, but to use for-loops and
> come up with something that works.  (Write tests that will indicate whether
> it works or not in a variety of situations.)  Then transform it to use things
> like ifelse() and sapply() to make it more readable and run faster.
I already have tested my functions by using a for loop, and they work.  
Here is the for loop I use.

for (indx in 1:length(df$ID)) {
     df$Preference <- 
evaluate.questions(df$Q1[indx],df$Q2[indx],df$Q3[indx])
}

I understand that such for loops aren't 'best practice' in R and am 
trying to learn its approach.  Thank you for the suggestions!
>> Unfortunately this doesn't work and the problem appears that the sapply
>> function is not feeding the parameters to the evaluate.questions
>> function as I expect.  Can someone provide some guidance on what I am
>> doing wrong?
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>


From bbolker at gmail.com  Fri Dec  6 18:58:00 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 6 Dec 2013 17:58:00 +0000
Subject: [R] mixed model ANCOVA
References: <CAGHpV7x_wkAnuA_sK4FHvdNft3nyPr31y+zYLLYaYpDaOi8Xyg@mail.gmail.com>
Message-ID: <loom.20131206T185033-631@post.gmane.org>

laurie bayet <lauriebayet <at> gmail.com> writes:

> 
> Hi,
> 
> I want to set up a mixed model ANCOVA but cannot find a way to do it.
> 
> There is:
> 
> * 1 subject factor (random, between subjects) called Subject
> * 3 categorical within subjects factors called Emotion, Sex, Race
> * 1 continuous covariate (**WITHIN subjects**) called Score
> and
> * a continuous dependent variable called logRT
> 
> I need a nice and clean table with p-values and effect sizes for each
> factors and relevant interactions.
> 
> Which function should I use?
> 
> I am guessing lmer from lme4 but could not find any example on the forums
> or on my manual from Ga?l Millot.
> 
> Here is a wild guess :
> 
>      ModelRT <- lmer(logRT ~ Race + Sex+ Emotion + Score + Race*Sex +
> Race*Emotion + Sex*Emotion + Race*Sex*Emotion + (1 | Subject))
> 
> Would that be correct ?
> 
> Thank you,
> 
> laurie
> 

* This might be better on r-sig-mixed-models at r-project.org
* In R '*' indicates "main effects plus all interactions" (':' is
for an interaction only), so you can abbreviate your formula to

ModelRT <- lmer(logRT ~ Race*Sex*Emotion + (1 | Subject))

or using lme from the nlme package:

ModelRT <- lme(logRT~Race*Sex*Emotion, random=~1|Subject)

* You should strongly consider passing an explicit 'data' argument
rather than picking up the variables from the workspace
* See ?pvalues in lme4 for some of your choices about getting
tables of p-values and effect sizes (e.g. with auxiliary functions
from the car, lmerTest, or pbkrtest packages). Beware that lme
will give you denominator and degrees of freedom, but the degrees
of freedom may very likely be miscalculated for your within-subject
continuous covariate
* You should strongly consider whether you need to include
among-subject variance in the within-subject factors in your model
[see the two refs below]

@article{barr_random_2013,
title = {Random effects structure for confirmatory hypothesis testing: Keep
it maximal},
volume = {68},
issn = {0749-{596X}},
shorttitle = {Random effects structure for confirmatory hypothesis testing},
url = {http://www.sciencedirect.com/science/article/pii/S0749596X12001180},
doi = {10.1016/j.jml.2012.11.001},
abstract = {Linear mixed-effects models ({LMEMs)} have become increasingly
prominent in psycholinguistics and related areas. However, many researchers
do not seem to appreciate how random effects structures affect the
generalizability of an analysis. Here, we argue that researchers using
{LMEMs} for confirmatory hypothesis testing should minimally adhere to the
standards that have been in place for many decades. Through theoretical
arguments and Monte Carlo simulation, we show that {LMEMs} generalize best
when they include the maximal random effects structure justified by the
design. The generalization performance of {LMEMs} including data-driven
random effects structures strongly depends upon modeling criteria and sample
size, yielding reasonable results on moderately-sized samples when
conservative criteria are used, but with little or no power advantage over
maximal models. Finally, random-intercepts-only {LMEMs} used on
within-subjects and/or within-items data from populations where subjects
and/or items vary in their sensitivity to experimental manipulations always
generalize worse than separate F1 and F2 tests, and in many cases, even
worse than F1 alone. Maximal {LMEMs} should be the ?gold standard? for
confirmatory hypothesis testing in psycholinguistics and beyond.},
number = {3},
urldate = {2013-09-26},
journal = {Journal of Memory and Language},
author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily,
Harry J.},
month = apr,
year = {2013},
keywords = {Generalization, Linear mixed-effects models, Monte Carlo
simulation, statistics},
pages = {255--278}
}

@article{schielzeth_conclusions_2009,
title = {Conclusions beyond support: overconfident estimates in mixed models},
volume = {20},
issn = {1045-2249, 1465-7279},
shorttitle = {Conclusions beyond support},
url = {http://beheco.oxfordjournals.org/content/20/2/416},
doi = {10.1093/beheco/arn145},
abstract = {Mixed-effect models are frequently used to control for the
nonindependence of data points, for example, when repeated measures from the
same individuals are available. The aim of these models is often to estimate
fixed effects and to test their significance. This is usually done by
including random intercepts, that is, intercepts that are allowed to vary
between individuals. The widespread belief is that this controls for all
types of pseudoreplication within individuals. Here we show that this is not
the case, if the aim is to estimate effects that vary within individuals and
individuals differ in their response to these effects. In these cases,
random intercept models give overconfident estimates leading to conclusions
that are not supported by the data. By allowing individuals to differ in the
slopes of their responses, it is possible to account for the nonindependence
of data points that pseudoreplicate slope information. Such random slope
models give appropriate standard errors and are easily implemented in
standard statistical software. Because random slope models are not always
used where they are essential, we suspect that many published findings have
too narrow confidence intervals and a substantially inflated type I error
rate. Besides reducing type I errors, random slope models have the potential
to reduce residual variance by accounting for between-individual variation
in slopes, which makes it easier to detect treatment effects that are
applied between individuals, hence reducing type {II} errors as well.},
language = {en},
number = {2},
urldate = {2012-07-27},
journal = {Behavioral Ecology},
author = {Schielzeth, Holger and Forstmeier, Wolfgang},
month = mar,
year = {2009},
keywords = {experimental design, maternal effects, mixed-effect models,
random regression, repeated measures, type I error},
pages = {416--420}
}


From smartpink111 at yahoo.com  Fri Dec  6 19:01:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 6 Dec 2013 10:01:33 -0800 (PST)
Subject: [R] Open multiple files using a loop
Message-ID: <1386352893.43392.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi Chris,

May be this helps.

#Suppose the working directory is `FirstLevel`
D <- dir(recursive=TRUE)
?D
#[1] "S1/S1data.txt" "S2/S2data.txt" "S3/S3data.txt"
sapply(D,function(x) nrow(read.table(x,sep="",header=TRUE)))
#S1/S1data.txt S2/S2data.txt S3/S3data.txt 
#?????????? 20??????????? 20??????????? 20 

res <- do.call(rbind,lapply(D,function(x) read.table(x,sep="",header=TRUE)))
?dim(res)
#[1] 60? 2
A.K.


Dear R/Arun 

I would like to open 50 text different files (S1data; S2data; 
S3data etc.) and rbind() them into a single data.frame or matrix. Is 
there a way doing this with a loop or in some other time-saving manner? 

`S1data` <- read.table("~/fmridata/FirstLevel/S1/S1data", header=T, quote="\"") 
`S2data` <- read.table("~/fmridata/FirstLevel/S2/S2data", header=T, quote="\"") 
`S3data` <- read.table("~/fmridata/FirstLevel/S3/S3data", header=T, quote="\"") 

etc? to S50 

alldata <- rbind(S1data, S2data, S3data etc? to 50) 


This type of idea (assuming each file has 10 rows (x50=500) and 25 columns): 

subjects <- c(S1,S2,S3 etc? to S50) 
alldata <- matrix(nrow = 500, ncol=25, byrow=TRUE) 

for(i in 1:50) { 
`<subject[i]>data` <- read.table("~/fmridata/FirstLevel/(subject[i])/<subject[i]>data", header=T, quote="\"") 

alldata[i,] <- <subject[i]>data 

} 

Thanks, 
Chris


From bbolker at gmail.com  Fri Dec  6 19:01:47 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 6 Dec 2013 18:01:47 +0000
Subject: [R] help with the nested anova formulas
References: <CACYeG1jETa=hTGmod0naCz2qf-CTVORjqiwDm+iyzobX_9C=yA@mail.gmail.com>
	<CACYeG1i_TNqUFUPurCG=gpYDJ_ZGtc=ReE+xj9e77BajLZfJYg@mail.gmail.com>
Message-ID: <loom.20131206T185837-307@post.gmane.org>

Robert Lynch <robert.b.lynch <at> gmail.com> writes:

>  I am modeling grade as a function of membership in
>  various cohorts.  There
> are four "cohorts".  (NONE, ISE07,ISE08,ISE09) and two times of cohorts
> coded as ISE = TRUE (ISE0#) or FALSE (NONE).  There is clear co-linearity
> but that is to be expected.
> 
>  running the following code
> 
>  CutOff <-0
>  fit.base <- lme(fixed= zGrade ~ Rep + COHORT/ISE + P7APrior + Female +
> White + HSGPA + MATH + AP_TOTAL + Years + EOP + Course,
>                  random= ~1|SID,
>                  data = share[share$GRADE >= CutOff,])
> 
>  I get the following error
> 
>  Error in MEEM(object, conLin, control$niterEM) :
>    Singularity in backsolve at level 0, block 1
> 
>  but if I take out the /ISE I get no error, simmilarly if I take out the
> COHORT/.
> 
>  I want to test for the effects of the different cohorts within the ISE
> subset and across ISE & NONE
> 
> I can send the data (the whole is too large) if you wish.

  Please send this to r-sig-mixed-models at r-project.org for more
discussion.

  The short answer is that lme can't fit models with rank-deficient
fixed effect model matrices -- in other words, there are redundant
parameters in your model because COHORT and ISE between them use
6 parameters to model 4 independent quantities.

http://stats.stackexchange.com/questions/35071/
  what-is-rank-deficiency-and-how-to-deal-with-it


From bbolker at gmail.com  Fri Dec  6 19:05:05 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 6 Dec 2013 18:05:05 +0000
Subject: [R] p value for mu: anova()
References: <A1C4DF829DB4AE45BF8447F83C7EAFFE168BD5F0@exchange2-3>
Message-ID: <loom.20131206T190245-674@post.gmane.org>

Rosario Garcia Gil <M.Rosario.Garcia <at> slu.se> writes:

> 
> Hello
> 
> I have run an anova analysis for
> the fallowing model:  H_obs=mu+REGION+MANAGEMENT + e
> 
> When I run it in ASRelm I get the p-value for mu, and,
> of course also for the two dependent variables (REGION
> and MANAGEMENT)
> 
> When I run it in R, I do not get the pvalue for mu.
> 
> Can some one help me to understand why? 
> and if it is possible to estimate the pvalue for mu in anova() in R?

   You may be wondering why no-one has answered your question ...
(1) it's way too vague and (2) the attached file probably got
stripped by the mailing list software before anyone saw it.
(Even if #2 weren't true, people are unlikely to take the time
to answer a really vague question if it means digging into a
data file to figure out what's going on.)

  See for example http://tinyurl.com/reproducible-000
  What *exact* code are you running?  "an anova analysis" is too vague.
 
  Ben Bolker


From wdunlap at tibco.com  Fri Dec  6 19:23:06 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 6 Dec 2013 18:23:06 +0000
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <52A2101A.6030202@gmail.com>
References: <52A1F0D6.9080108@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1AEE0@PA-MBX01.na.tibco.com>
	<52A2101A.6030202@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1B031@PA-MBX01.na.tibco.com>

> I understand that such for loops aren't 'best practice' in R and am
> trying to learn its approach. 

sapply() is an encapsulated loop and loops have their place in R.
'Best practice' is a nebulous term, but explicit loops can make
code that is hard to understand (by a compiler or by a human)
and any loop at the R-code level will generally make code run
more slowly.  However, depending on your background, explicit
loops may be easier for you to write and understand, so you
may get an answer faster by using loops.

> >Then transform it to use things
> > like ifelse() and sapply() to make it more readable and run faster.

Changing your 'if' statements to calls to the vectorized 'ifelse' will
probably make looping unneeded.  E.g., your q1.ans() only works
on a scalar, forcing you to use sapply (or the superior vapply) to
work on vectors:

    q1.ans <- function(x)
    {
       retVal = 0
       if (x == 1) {
         retVal = 1
       } else if (x ==2) {
         retVal = 2
       }
       return (retVal)
    }
as in
    > q1.ans(1:3)
   [1] 1 
   Warning message:
   In if (x == 1) { :
     the condition has length > 1 and only the first element will be used
   > sapply(1:3, q1.ans)
   [1] 1 2 0

You can change it to work on a vector by using ifelse:
   q1a.ans <- function(x) {
      ifelse(x==1,
                 1,  # return 1's where x had 1's
                 ifelse(x==2,
                           2, # return 2's where x had 2's
                           0)) # return 0 where x had something else
    }
used as
    > q1a.ans(1:3)
   [1] 1 2 0

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Walter Anderson [mailto:wandrson01 at gmail.com]
> Sent: Friday, December 06, 2013 9:58 AM
> To: William Dunlap; r-help at r-project.org
> Subject: Re: [R] Need help figuring out sapply (and similar functions) with multiple
> parameter user defined function
> 
> On 12/06/2013 10:43 AM, William Dunlap wrote:
> >> I have been researching and it appears that I should be using the sapply
> >> function to apply the evaluate.question function above to each row in
> >> the data frame like this
> > Read the documentation more closely: sapply(dataFrame, func)
> > applies func() to each column, not row, of dataFrame.
> I misunderstood.  I thought it was apply the func to each row...  My mistake
> >> preferences <- sapply(df, evaluate.questions, function(x,y,z)
> >> evaluate.questions(df['Q1'],df['Q2'],df['Q3']))
> > Furthermore,
> >      sapply(X = dataFrame, FUN = func, extraArgument)
> > calls
> >      func(dataFrame[, i], extraArgument)
> > for i in seq_len(ncol(dataFrame).
> >
> > One problem is that FUN=evaluate.questions takes 3 arguments and
> > you give it only 2.  Another problem is that the third argument you
> > pass to sapply is a function (of 3 arguments) and FUN is not expecting
> > any of its arguments to be functions.
> I will need to think about this, I am not sure I understand.  I really
> don't seem to understand how any of the apply functions seem to work.
> > It may be easier for you to not use sapply here, but to use for-loops and
> > come up with something that works.  (Write tests that will indicate whether
> > it works or not in a variety of situations.)  Then transform it to use things
> > like ifelse() and sapply() to make it more readable and run faster.
> I already have tested my functions by using a for loop, and they work.
> Here is the for loop I use.
> 
> for (indx in 1:length(df$ID)) {
>      df$Preference <-
> evaluate.questions(df$Q1[indx],df$Q2[indx],df$Q3[indx])
> }
> 
> I understand that such for loops aren't 'best practice' in R and am
> trying to learn its approach.  Thank you for the suggestions!
> >> Unfortunately this doesn't work and the problem appears that the sapply
> >> function is not feeding the parameters to the evaluate.questions
> >> function as I expect.  Can someone provide some guidance on what I am
> >> doing wrong?
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> >


From jvadams at usgs.gov  Fri Dec  6 19:51:02 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 6 Dec 2013 12:51:02 -0600
Subject: [R] model selection with step()
In-Reply-To: <CAK_OPMLBoNRA+-qVEEwTFrFu7KCAwb2xu_JJUWzyoJnRR90wbg@mail.gmail.com>
References: <CAK_OPMLBoNRA+-qVEEwTFrFu7KCAwb2xu_JJUWzyoJnRR90wbg@mail.gmail.com>
Message-ID: <CAN5YmCEPcyVPcZPujUwRPf0KcR=qc8PPXmg1EfKGi_2e1Zhe2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131206/7d8b0867/attachment.pl>

From anika.masters at gmail.com  Fri Dec  6 20:47:51 2013
From: anika.masters at gmail.com (Anika Masters)
Date: Fri, 6 Dec 2013 11:47:51 -0800
Subject: [R] quantiles with approximately the same number of data points
 within each quantile?
Message-ID: <CAOQRPaabC6hGntGAD+m03n1wS6Sa2pgJhn5T2K7ybFR6p140JQ@mail.gmail.com>

What is a "good" way to create quantiles with approximately the same
number of data points within each quantile?


From wandrson01 at gmail.com  Fri Dec  6 20:54:24 2013
From: wandrson01 at gmail.com (Walter Anderson)
Date: Fri, 06 Dec 2013 13:54:24 -0600
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1B031@PA-MBX01.na.tibco.com>
References: <52A1F0D6.9080108@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1AEE0@PA-MBX01.na.tibco.com>
	<52A2101A.6030202@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1B031@PA-MBX01.na.tibco.com>
Message-ID: <52A22B70.9020308@gmail.com>

Thanks again!

Can the ifelse statement be nested like

ifelse(condition1,
     ifelse(condition2,yes,no)
     ifelse(condition3,yes,no)
)

?
On 12/06/2013 12:23 PM, William Dunlap wrote:
>> I understand that such for loops aren't 'best practice' in R and am
>> trying to learn its approach.
> sapply() is an encapsulated loop and loops have their place in R.
> 'Best practice' is a nebulous term, but explicit loops can make
> code that is hard to understand (by a compiler or by a human)
> and any loop at the R-code level will generally make code run
> more slowly.  However, depending on your background, explicit
> loops may be easier for you to write and understand, so you
> may get an answer faster by using loops.
>
>>> Then transform it to use things
>>> like ifelse() and sapply() to make it more readable and run faster.
> Changing your 'if' statements to calls to the vectorized 'ifelse' will
> probably make looping unneeded.  E.g., your q1.ans() only works
> on a scalar, forcing you to use sapply (or the superior vapply) to
> work on vectors:
>
>      q1.ans <- function(x)
>      {
>         retVal = 0
>         if (x == 1) {
>           retVal = 1
>         } else if (x ==2) {
>           retVal = 2
>         }
>         return (retVal)
>      }
> as in
>      > q1.ans(1:3)
>     [1] 1
>     Warning message:
>     In if (x == 1) { :
>       the condition has length > 1 and only the first element will be used
>     > sapply(1:3, q1.ans)
>     [1] 1 2 0
>
> You can change it to work on a vector by using ifelse:
>     q1a.ans <- function(x) {
>        ifelse(x==1,
>                   1,  # return 1's where x had 1's
>                   ifelse(x==2,
>                             2, # return 2's where x had 2's
>                             0)) # return 0 where x had something else
>      }
> used as
>      > q1a.ans(1:3)
>     [1] 1 2 0
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: Walter Anderson [mailto:wandrson01 at gmail.com]
>> Sent: Friday, December 06, 2013 9:58 AM
>> To: William Dunlap; r-help at r-project.org
>> Subject: Re: [R] Need help figuring out sapply (and similar functions) with multiple
>> parameter user defined function
>>
>> On 12/06/2013 10:43 AM, William Dunlap wrote:
>>>> I have been researching and it appears that I should be using the sapply
>>>> function to apply the evaluate.question function above to each row in
>>>> the data frame like this
>>> Read the documentation more closely: sapply(dataFrame, func)
>>> applies func() to each column, not row, of dataFrame.
>> I misunderstood.  I thought it was apply the func to each row...  My mistake
>>>> preferences <- sapply(df, evaluate.questions, function(x,y,z)
>>>> evaluate.questions(df['Q1'],df['Q2'],df['Q3']))
>>> Furthermore,
>>>       sapply(X = dataFrame, FUN = func, extraArgument)
>>> calls
>>>       func(dataFrame[, i], extraArgument)
>>> for i in seq_len(ncol(dataFrame).
>>>
>>> One problem is that FUN=evaluate.questions takes 3 arguments and
>>> you give it only 2.  Another problem is that the third argument you
>>> pass to sapply is a function (of 3 arguments) and FUN is not expecting
>>> any of its arguments to be functions.
>> I will need to think about this, I am not sure I understand.  I really
>> don't seem to understand how any of the apply functions seem to work.
>>> It may be easier for you to not use sapply here, but to use for-loops and
>>> come up with something that works.  (Write tests that will indicate whether
>>> it works or not in a variety of situations.)  Then transform it to use things
>>> like ifelse() and sapply() to make it more readable and run faster.
>> I already have tested my functions by using a for loop, and they work.
>> Here is the for loop I use.
>>
>> for (indx in 1:length(df$ID)) {
>>       df$Preference <-
>> evaluate.questions(df$Q1[indx],df$Q2[indx],df$Q3[indx])
>> }
>>
>> I understand that such for loops aren't 'best practice' in R and am
>> trying to learn its approach.  Thank you for the suggestions!
>>>> Unfortunately this doesn't work and the problem appears that the sapply
>>>> function is not feeding the parameters to the evaluate.questions
>>>> function as I expect.  Can someone provide some guidance on what I am
>>>> doing wrong?
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>


From dmck at u.washington.edu  Fri Dec  6 21:07:07 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Fri, 6 Dec 2013 12:07:07 -0800
Subject: [R] quantiles with approximately the same number of data points
	within each quantile?
In-Reply-To: <CAOQRPaabC6hGntGAD+m03n1wS6Sa2pgJhn5T2K7ybFR6p140JQ@mail.gmail.com>
References: <CAOQRPaabC6hGntGAD+m03n1wS6Sa2pgJhn5T2K7ybFR6p140JQ@mail.gmail.com>
Message-ID: <F089E739-D656-4C32-A475-0610EBD77977@u.washington.edu>

By default I believe.  See

http://en.wikipedia.org/wiki/Quantile

Others more erudite may correct me.

On Dec 6, 2013, at 11:47 AM, Anika Masters <anika.masters at gmail.com> wrote:

> What is a "good" way to create quantiles with approximately the same
> number of data points within each quantile?
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific Wildland Fire Science Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From ruipbarradas at sapo.pt  Fri Dec  6 21:25:12 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 06 Dec 2013 20:25:12 +0000
Subject: [R] quantiles with approximately the same number of data points
 within each quantile?
In-Reply-To: <CAOQRPaabC6hGntGAD+m03n1wS6Sa2pgJhn5T2K7ybFR6p140JQ@mail.gmail.com>
References: <CAOQRPaabC6hGntGAD+m03n1wS6Sa2pgJhn5T2K7ybFR6p140JQ@mail.gmail.com>
Message-ID: <52A232A8.5030307@sapo.pt>

Hello,

Use function ?quantile.
See this example, each group has exactly, not approximately, 25 elements.

x <- rnorm(100)

qnt <- quantile(x)
tapply(x, findInterval(x, qnt, rightmost.closed = TRUE), length)

Hope this helps,

Rui Barradas

Em 06-12-2013 19:47, Anika Masters escreveu:
> What is a "good" way to create quantiles with approximately the same
> number of data points within each quantile?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Fri Dec  6 21:28:01 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 6 Dec 2013 12:28:01 -0800
Subject: [R] How to generate a smoothed surface for a three dimensional
	dataset?
In-Reply-To: <CA+iL=vzDKnZsBwaQ8Pry2hkiuPzdzo0KsEWvgM8rT9Zqrou6qg@mail.gmail.com>
References: <CAMCXXmpc3kvbv6qJ9Z0K=c66tNAa789LOR1hKQHt8LKSAD+avQ@mail.gmail.com>
	<529F5EC3.5010309@gmail.com>
	<D2426757-1349-47F2-B4F9-51E4CE7735EC@comcast.net>
	<CACk-te1TNCT-WcH8-wnYD5p+8erLOTB=5B=p1WZZAzmggc__MQ@mail.gmail.com>
	<CAMCXXmq1N9SnTG=947LmPQsg4URWsOY4FZZ7N4tO27APPw-HVA@mail.gmail.com>
	<CACk-te1ZugfsLaVs1V9KNzkn_cYHv=9kwi=MVkSXKwd2BpkoKA@mail.gmail.com>
	<CA+iL=vzDKnZsBwaQ8Pry2hkiuPzdzo0KsEWvgM8rT9Zqrou6qg@mail.gmail.com>
Message-ID: <3F3DB04A-B18F-4330-B8A1-43E506B4E1C2@comcast.net>


On Dec 5, 2013, at 9:46 PM, A Xi Ma wrote:

> The following question is inspired by Jun's problem, which resembles some
> of my own problems, but goes off on a tangent about applying plot3D from
> Karline Soetart.
> 
> 
> On Thu, Dec 5, 2013 at 11:52 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> 
>> 
>> Your comment that:
>> 
>> " I can see the critical point here is to find a right function to
>> make the prediction. "
>> 
>> is what indicates to me that your "critical point" is that you have
>> insufficient knowledge and need help. Feel free to disagree, of
>> course.
>> 
> 
> I don't know if it's true for Jun, but it's definitely true for me - I have
> insufficient knowledge! I'm out of my depth with surface estimation, but I
> have to learn how to do it, one way or the other.

> 
> Currently I'm reading the docs for plot3d.
> 
> I loaded the package into rstudio and ran some of the examples.  The
> image2D example seems to get its data from a data.frame called "volcano"
> with a small "v."

Right. the 'volcano'-object is a standard data object for demonstration of R graphics. It resides in the datasets package and has a help file:

help(volcano)

> 
> imag2D>  nr <- nrow(volcano)
> 
> imag2D>  nc <- ncol(volcano)
> 
> imag2D>  image2D(volcano, x = 1:nr, y = 1:nc, lighting = TRUE,
> imag2D+        main = "volcano", clab = "height, m")
> 

> 
> The objects() command shows a "Volcano" with a big "V."  The small-v and
> big-V volcanoes are not the same, because the str command shows:
> 
snipped superfluous output from an objects()-command.

>> str(Volcano)
> num [1:29, 1:21] 100 103 105 108 110 116 120 122 123 118 ...
>> str(volcano)
> num [1:87, 1:61] 100 101 102 103 104 105 105 106 107 108 ...

They are both matrices. The Volcano matrix has only one-ninth the number of values.

The first small section of the volcano vignette reads:
------------------------------------------------------------------------
1. Intro

To make this vignette smaller, the size of volcano is reduced:

 # Reduce the resolution
 Volcano <- volcano[seq(1, nrow(volcano), by = 3),

                     seq(1, ncol(volcano), by = 3)]
-------------------------------------------------------------------------
So that code just selects every third of the values of the 'volcano' matrix.



> 
> I don't understand how the "volcano" object works well enough to power the
> image2D command, but doesn't show up in "objects()".

It is accessible by functions although it is not visible in the workspace.

> str(volcano)
 num [1:87, 1:61] 100 101 102 103 104 105 105 106 107 108 ...
> 'volcano' %in% ls()
[1] FALSE

If you want to get it into the workspace, you just use the data() function:

> data('volcano')
> 'volcano' %in% ls()
[1] TRUE    # now "visible"



>  At first I thought
> there was some kind of secret smuggling compartment in memory space, and
> "nr" and "nc" and "volcano" were all hidden in that secret place.  But in
> fact, "nr" and "nc" show up in "objects()".
> 
> So ... I am even less educated than the other newbies on the list, and I'm
> following along, and I really don't see how R is doing what it's doing.
> Should I be reading the plot3D .pdf textbooks, or should I give up and go
> back to some much more basic textbook?

I'm thinking you are not yet ready for plot3D. It's unclear what level of effort you have put in to reading and mastering the "Introduction to R" or whatever text you are using to educate yourself. I certainly do not think that a beginning tutorial in R was the goal that the authors of the plot3D package had in mind. Even before posting to Rhelp you are expected to have studied the available documentation and learned enough R to be able to answer all the questions you posed. So I suggest studying your copy of Introduction to R that is shipped with every binary of R.

> 
> Thanks.
> 
> 	[[alternative HTML version deleted]]

And you should learn to post in plain text. Please do read the Posting Guide.

> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From f.harrell at vanderbilt.edu  Fri Dec  6 22:14:42 2013
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Fri, 6 Dec 2013 15:14:42 -0600
Subject: [R] [R-pkgs] rms 4.1-0
Message-ID: <52A23E42.7050802@vanderbilt.edu>

The rms package has had several updates in version 4.1-0:

    * Fixed orm.fit to not create penalty matrix if not needed 
(penalties are not yet implemented anyway)
    * Added yscale argument to plot.Predict
    * Added Wald test simulation to orm help file
    * Added example in help file for plot.anova.rms of adding a line 
combining the effects of two predictors in dot chart
    * Fixed grid interpretation error in survplot.survfit
    * Changed plot.anova.rms to use dotchart3 instead of dotchart2
    * Fixed bug in summary.rms - was taking reciprocal of effect ratio 
with orm even if not loglog family (thanks: Yong Hao Pua 
<puayonghao at gmail.com>
    * Removed link to print.lm, summary.lm in ols.Rd
    * Added ntrans argument to plot.anova.rms
    * Fixed handling of intercepts in Rq, validate.Rq
    * Removed residuals.Glm, residuals.rms (also from Rd, NAMESPACE)
    * Removed other .rms methods and other remnants from fooling S+ 
dispatcher
    * Fixed bug in lm.pfit when penalty used (thanks: Yong Hao Pua 
<puayonghao at gmail.com>)
    * Fixed bug in calibrate.default for ols (thanks: Andy Bush)
    * Change print.contrast.rms to insert NA for SE if fun is not the 
identity function
    * Added margin argument to plot.anova.rms to print selected stats in 
right margin of dot chart
    * Added anova argument to plot.Predict to allow overall association 
test statistics to be added to panels
    * Fixed bug in val.prob in which the logistic model was re-fitted 
instead of fixing coefficients at 0,1.  This resulted in model 
statistics (including c-index) to always be favorable even when 
predictions were worse than change.  Thanks: Kirsen Van Hoorde 
<Kirsten.VanHoorde at esat.kuleuven.be>
    * Fixed bug in survdiffplot where conf.int was always overridden by 
value from survfit.  Thanks: Kamil Fijorek <kamilfijorek at gmail.com>
    * Fixed bug in grid= for survplot.* and survdiffplot.  Thanks: Kamil 
Fijorek
    * Fixed rms.s to account for possible offset in names(nmiss). 
Thanks: Larry Hunsicker
    * Fixed psm.s to not compute Dxy if simple right censoring is not in 
effect.  Thanks: I.M. Nolte
    * rcs: respect system option fractied, passed to rcspline.eval; can 
be used to get old behavior
    * Gls: as nlme 3.1-113 exports more functions, removed nlme:::

-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dwinsemius at comcast.net  Sat Dec  7 00:48:01 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 6 Dec 2013 15:48:01 -0800
Subject: [R] R survAUC Package
In-Reply-To: <1386172175431-4681638.post@n4.nabble.com>
References: <1386172175431-4681638.post@n4.nabble.com>
Message-ID: <D372C34D-4EC7-4CE0-8E36-F3C446D2A70B@comcast.net>


On Dec 4, 2013, at 7:49 AM, kevinod wrote:

> I have a concern about the survAUC package option AUC.cd.  
> 

So shouldn't you be sending this to the package authors? They may or may not be regular readers of R help. It's apackage I have never heard of.

> I am exploring package functionality, specifically AUC statistics for Cox
> Regression, for a small academic project
> 
> When utilizing this package on the ovarian data set within that package I
> obtain an AUC statistic of 0.3322928.  When AUC calculations use a
> dichotomous outcome such as this, see included R code, the result should lie
> between 0.5 and 1, not 0.33.
> 
> Please explain this, I am not certain that the algorithm that is being
> utilized for this package is correct.
> 
> Thank you
> 
> Kevin O?Donnell, MS Work Environment, MS Env Eng.,  MS Const Project Mgmt
> Graduate Student
> Department of Biostatistics
> Boston University School of Public Health
> 715 Albany Street Boston, MA
> 
> 617-480-1677
> 
> x11(h=8,w=11)
> fit = survfit(Surv(futime,fustat) ~ rx)
> plot(fit, mark.time=FALSE, xscale=365.25,main="Plot of Survival Curves by
> Prescription Status",
>        xlab='Length of Survival', ylab='Proportion of Individuals who have
> Survived')
> lines(fit[1], lwd=3,lty=2:3, xscale=365.24,col=2)
> lines(fit[2], lwd=2,lty=2:2, xscale=365.24,col=3)
> legend(.2,.2, c("No treatment", "treatment"), lwd=3,lty = 2:3) 
> 
> 
> TR2 = ovarian[1:16,]
> TE2 = ovarian[17:26,]
> train.fit2  = coxph(Surv(futime, fustat) ~ rx,
>                    x=TRUE, y=TRUE, method="efron", data=TR)
> lp2 = predict(train.fit) 
> lpnew2 = predict(train.fit2, newdata=TE2)
> Surv.rsp2 = Surv(TR2$futime, TR2$fustat)
> Surv.rsp.new2 = Surv(TE2$futime, TE2$fustat)
> times2 = seq(10, 1000, 10)                  
> 
> AUC_CD2 = AUC.cd(Surv.rsp2, Surv.rsp.new2, lp2, lpnew2, times2)
> 
> 
> AUC_hc2 = AUC.hc(Surv.rsp2, Surv.rsp.new2, lpnew2, times2)
> 
> 
> AUC_sh2 = AUC.sh(Surv.rsp2, Surv.rsp.new2, lp2, lpnew2, times2)
> 
> 
> AUC_Uno2 = AUC.uno(Surv.rsp2, Surv.rsp.new2, lpnew2, times2)
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/R-survAUC-Package-tp4681638.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From juliosergio at gmail.com  Fri Dec  6 20:27:10 2013
From: juliosergio at gmail.com (Julio Sergio Santana)
Date: Fri, 6 Dec 2013 19:27:10 +0000
Subject: [R] Using assign with mapply
Message-ID: <loom.20131206T200836-152@post.gmane.org>

I have a data frame whose first colum contains the names of the variables 
and whose second colum contains the values to assign to them:

   : kkk <- data.frame(vars=c("var1", "var2", "var3"), 
                     vals=c(10, 20, 30), stringsAsFactors=F)

If I do 

   : assign(kkk$vars[1], kkk$vals[1])

it works

   : var1
   [1] 10

However, if I try with mapply this is what I get:

   : mapply(assign, kkk$vars, kkk$vals)
   var1 var2 var3 
     10   20   30 
   : var2
   Error: object 'var2' not found

Maybe I have not undestand how mapply and assign work. Do you have
any comments?

Thanks,

  -Sergio.


From smartpink111 at yahoo.com  Sat Dec  7 00:11:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 6 Dec 2013 15:11:18 -0800 (PST)
Subject: [R] Wrong date fromat?
Message-ID: <1386371478.50401.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try
vec1 <- 10958:10963 
?as.Date(vec1,origin="1960-01-01")
#[1] "1990-01-01" "1990-01-02" "1990-01-03" "1990-01-04" "1990-01-05"
#[6] "1990-01-06"

A.K.



I have imported a stata data into R and wanted to convert the date. 
?The format went OK, but the output doesn't represent my data. The head 
of the imported data is this one 

> head(df$date) 
[1] 10958 10959 10960 10961 10962 10963 

I tried to convert the date using the zoo package: 

library("zoo") 
df$date<-as.Date(df$date) 
head(df$date) 

> head(df$date) 
[1] "2000-01-02" "2000-01-03" "2000-01-04" "2000-01-05" "2000-01-06" "2000-01-07" 

However my date starts with January 1, 1990 and the converted data starts from January 2, 2000. 

What have I done wrong?


From dwinsemius at comcast.net  Sat Dec  7 01:11:25 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 6 Dec 2013 16:11:25 -0800
Subject: [R] Using assign with mapply
In-Reply-To: <loom.20131206T200836-152@post.gmane.org>
References: <loom.20131206T200836-152@post.gmane.org>
Message-ID: <B8148731-8E6B-41D7-8391-134D30CCFB03@comcast.net>


On Dec 6, 2013, at 11:27 AM, Julio Sergio Santana wrote:

> I have a data frame whose first colum contains the names of the variables 
> and whose second colum contains the values to assign to them:
> 
>   : kkk <- data.frame(vars=c("var1", "var2", "var3"), 
>                     vals=c(10, 20, 30), stringsAsFactors=F)
> 
> If I do 
> 
>   : assign(kkk$vars[1], kkk$vals[1])
> 
> it works
> 
>   : var1
>   [1] 10
> 
> However, if I try with mapply this is what I get:
> 
>   : mapply(assign, kkk$vars, kkk$vals)
>   var1 var2 var3 
>     10   20   30 
>   : var2
>   Error: object 'var2' not found
> 
> Maybe I have not undestand how mapply and assign work. Do you have
> any comments?

I think you will find that the value returned from the mapply call was a three element list with the desired names and values  ... except you then gave that enclosing list no name and it will be garbage-collected. If you want to have 'assign' do its magic into the global environment, then you need to supply 'mapply' a MoreArgs argument on the other side of the ellipsis:

Usage:
mapply(FUN, ..., MoreArgs = NULL, SIMPLIFY = TRUE,
       USE.NAMES = TRUE)

So what happens if you try this:

mapply(assign,  kkk$vars, kkk$vals, MoreArgs = list(envir = .GlobalEnv)

-- 

David Winsemius
Alameda, CA, USA


From djnordlund at frontier.com  Sat Dec  7 01:48:57 2013
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Fri, 6 Dec 2013 16:48:57 -0800
Subject: [R] Wrong date fromat?
In-Reply-To: <1386371478.50401.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1386371478.50401.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <5B916484312E491E94FE69A5A2EF8BDE@Aragorn>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of arun
> Sent: Friday, December 06, 2013 3:11 PM
> To: R help
> Subject: Re: [R] Wrong date fromat?
> 
> Hi,
> Try
> vec1 <- 10958:10963
>  as.Date(vec1,origin="1960-01-01")
> #[1] "1990-01-01" "1990-01-02" "1990-01-03" "1990-01-04" "1990-01-05"
> #[6] "1990-01-06"
> 
> A.K.
> 
> 
> 
> I have imported a stata data into R and wanted to convert the date.
>  The format went OK, but the output doesn't represent my data. The head
> of the imported data is this one
> 
> > head(df$date)
> [1] 10958 10959 10960 10961 10962 10963
> 
> I tried to convert the date using the zoo package:
> 
> library("zoo")
> df$date<-as.Date(df$date)
> head(df$date)
> 
> > head(df$date)
> [1] "2000-01-02" "2000-01-03" "2000-01-04" "2000-01-05" "2000-01-06"
> "2000-01-07"
> 
> However my date starts with January 1, 1990 and the converted data starts
> from January 2, 2000.
> 
> What have I done wrong?
> 

You need to specify an appropriate value for the origin parameter.  It looks like as.Date in the zoo package (which masks the as.Date in base) defaults to the Unix epoch value, origin='1970-01-01'.  Your Stata values are based on origin='1960-01-01' as your first example specified.

Hope this is helpful,

Dan

Daniel Nordlund
Bothell, WA USA
 


From gongx030 at umn.edu  Sat Dec  7 07:34:42 2013
From: gongx030 at umn.edu (Wuming Gong)
Date: Sat, 7 Dec 2013 00:34:42 -0600
Subject: [R] kmeans clustering on large but sparse matrix
In-Reply-To: <CAMkvp6LnuMYfdkqRwS4q04m4ruKV+Tkhp7qokSyVCehd9jp7=g@mail.gmail.com>
References: <CAMkvp6LnuMYfdkqRwS4q04m4ruKV+Tkhp7qokSyVCehd9jp7=g@mail.gmail.com>
Message-ID: <CAFhv9SnJwjnUcqC-4OFwKb86XAu7XOm8UJKp5eSD42WJTJgC2g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131207/5db38483/attachment.pl>

From gongx030 at umn.edu  Sat Dec  7 08:26:57 2013
From: gongx030 at umn.edu (Wuming Gong)
Date: Sat, 7 Dec 2013 01:26:57 -0600
Subject: [R] tune an support vector machine
In-Reply-To: <trinity-8375f7d9-f741-497b-b4be-87454a51d780-1386335186604@3capp-gmx-bs34>
References: <trinity-8375f7d9-f741-497b-b4be-87454a51d780-1386335186604@3capp-gmx-bs34>
Message-ID: <CAFhv9SkGmRTm1iPBW0gyQnmg7pRs-9SxqKVYgrTpzvOkxxnKYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131207/2a51e8c7/attachment.pl>

From balu555 at gmx.de  Sat Dec  7 09:15:32 2013
From: balu555 at gmx.de (Uwe Bohne)
Date: Sat, 7 Dec 2013 09:15:32 +0100 (CET)
Subject: [R] tune an support vector machine
In-Reply-To: <CAFhv9SkGmRTm1iPBW0gyQnmg7pRs-9SxqKVYgrTpzvOkxxnKYA@mail.gmail.com>
References: <trinity-8375f7d9-f741-497b-b4be-87454a51d780-1386335186604@3capp-gmx-bs34>,
	<CAFhv9SkGmRTm1iPBW0gyQnmg7pRs-9SxqKVYgrTpzvOkxxnKYA@mail.gmail.com>
Message-ID: <trinity-ee5023de-8b36-4514-89ce-e1b0b413d4b0-1386404132570@3capp-gmx-bs43>


   Thank you very much,

   your proposal is one practical way to check for significant features.
   I tried to check for all combination in a loop, but unfortunately there is a
   problem with NA values.
   Maybe anybody has an idea.

   This is my expansion of the former code:

   namen<-expand.grid(c("weight",NA),
   c("height",NA),c("width",NA),c("volume",NA), stringsAsFactors=FALSE)
   namen2<-as.data.frame(namen)
   for(i in 1:nrow(namen2)){
     assign(paste("a", i, sep = ""), namen2[i,])
   }

   This generates vectors containing the features.
   If i pick one of them i can produce a formula that i can use for svm tuning.
   For example

   a7
   a7q<-t(as.data.frame(a7[!is.na(a7)]))
   a7q
   a7f<-as.formula(paste("type~",paste(a7q,collapse="+")))
   a7f

   and

   svmtune_a7=tune.svm(a7f,  data=train,  kernel="radial", cost=2^(-2:5),
   gamma=2^(-2:1),cross=10)

   works as desired.
   So my key idea was to tune SVM with every possibel "a...f" formula and
   choose  the  best one according to the best performance measure in the
   summary.
   Unfortunately I just have problems to make it in a loop.
   I tried

   for(iin1:nrow(namen2)){paste("a",i,"q",sep="")<-t(as.data.frame(paste("a",
   i,"[!is.na(a",i,")]", sep="")))}

   and produced error. Probably i didnt paste correctly.
   Any ideas?
   Thanks a lot!
   Uwe
   Gesendet: Samstag, 07. Dezember 2013 um 08:26 Uhr
   Von: "Wuming Gong" <gongx030 at umn.edu>
   An: "Uwe Bohne" <balu555 at gmx.de>
   Cc: "r-help mailinglist" <r-help at r-project.org>
   Betreff: Re: [R] tune an support vector machine
   Hi Uwe,

   It looks SVM in e1071 and Kernlab does not support feature selection, but
   you can take a look at package penalizedSVM
   ([1]http://cran.r-project.org/web/packages/penalizedSVM/penalizedSVM.pdf).

   Or you can implement a SVM-RFE
   ([2]http://axon.cs.byu.edu/Dan/778/papers/Feature%20Selection/guyon*.pdf)by
   the alpha values returned by svm() in e1071 or ksvm() in Kernlab.

   Wuming

   On Fri, Dec 6, 2013 at 7:06 AM, Uwe Bohne <[3]balu555 at gmx.de> wrote:

        Hej all,
        actually i try to tune a SVM in R and use the package "e1071" wich
     works
        pretty well.
        I do some gridsearch in the parameters and get the best possible
     parameters
        for classification.
        Here is my sample code
        type<-sample(c(-1,1) , 20, replace = TRUE )
        weight<-sample(c(20:50),20, replace=TRUE)
        height<-sample(c(100:200),20, replace=TRUE)
        width<-sample(c(30:50),20,replace=TRUE)
        volume<-sample(c(1000:5000),20,replace=TRUE)
        data<-cbind(type,weight,height,width,volume)
        train<-as.data.frame(data)
        library("e1071")
        features <- c("weight","height","width","volume")
        (formula<-as.formula(paste("type ~ ", paste(features, collapse= "+"))))
        svmtune=tune.svm(formula,  data=train, kernel="radial", cost=2^(-2:5),
        gamma=2^(-2:1),cross=10)
        summary(svmtune)
        My question is if there is a way to tune the features.
        So in other words - what i wanna do is to try all possible combinations
     of
        features : for example use only (volume) or use (weight, height) or use
        (height,volume,width) and so on for the SVM  and to get the best
     combination
        back.
        Best wishes
        Uwe
     ______________________________________________
     [4]R-help at r-project.org mailing list
     [5]https://stat.ethz.ch/mailman/listinfo/r-help
     PLEASE do read the posting guide
     [6]http://www.R-project.org/posting-guide.html
     and provide commented, minimal, self-contained, reproducible code.

References

   1. http://cran.r-project.org/web/packages/penalizedSVM/penalizedSVM.pdf
   2. http://axon.cs.byu.edu/Dan/778/papers/Feature%20Selection/guyon*.pdf
   3. file://localhost/tmp/balu555 at gmx.de
   4. file://localhost/tmp/R-help at r-project.org
   5. https://stat.ethz.ch/mailman/listinfo/r-help
   6. http://www.R-project.org/posting-guide.html

From balu555 at gmx.de  Sat Dec  7 10:54:51 2013
From: balu555 at gmx.de (Uwe Bohne)
Date: Sat, 7 Dec 2013 10:54:51 +0100 (CET)
Subject: [R] tune an support vector machine
In-Reply-To: <trinity-ee5023de-8b36-4514-89ce-e1b0b413d4b0-1386404132570@3capp-gmx-bs43>
References: <trinity-8375f7d9-f741-497b-b4be-87454a51d780-1386335186604@3capp-gmx-bs34>,
	<CAFhv9SkGmRTm1iPBW0gyQnmg7pRs-9SxqKVYgrTpzvOkxxnKYA@mail.gmail.com>,
	<trinity-ee5023de-8b36-4514-89ce-e1b0b413d4b0-1386404132570@3capp-gmx-bs43>
Message-ID: <trinity-2d1be4ec-0f42-4dab-9e04-5024255c7577-1386410091437@3capp-gmx-bs43>


   UPDATE

   This line of code will produce what i desired, i will check if the tuning of
   the svm works as i planed and post the solution asap

   l <- apply(head(namen, -1), 1, function(x)
                  reformulate(paste(na.omit(x), collapse = "+"), response =
   "type"))
   l[[1]]
   svmtune=tune.svm(l[[2]],  data=train,  kernel="radial", cost=2^(-2:5),
   gamma=2^(-2:1),cross=10)

   Gesendet: Samstag, 07. Dezember 2013 um 09:15 Uhr
   Von: "Uwe Bohne" <balu555 at gmx.de>
   An: "Wuming Gong" <gongx030 at umn.edu>
   Cc: "r-help mailinglist" <r-help at r-project.org>
   Betreff: Re: [R] tune an support vector machine
   Thank you very much,
   your proposal is one practical way to check for significant features.
   I tried to check for all combination in a loop, but unfortunately there is a
   problem with NA values.
   Maybe anybody has an idea.
   This is my expansion of the former code:
   namen<-expand.grid(c("weight",NA),
   c("height",NA),c("width",NA),c("volume",NA), stringsAsFactors=FALSE)
   namen2<-as.data.frame(namen)
   for(i in 1:nrow(namen2)){
   assign(paste("a", i, sep = ""), namen2[i,])
   }
   This generates vectors containing the features.
   If i pick one of them i can produce a formula that i can use for svm tuning.
   For example
   a7
   a7q<-t(as.data.frame(a7[!is.na(a7)]))
   a7q
   a7f<-as.formula(paste("type~",paste(a7q,collapse="+")))
   a7f
   and
   svmtune_a7=tune.svm(a7f, data=train, kernel="radial", cost=2^(-2:5),
   gamma=2^(-2:1),cross=10)
   works as desired.
   So my key idea was to tune SVM with every possibel "a...f" formula and
   choose the best one according to the best performance measure in the
   summary.
   Unfortunately I just have problems to make it in a loop.
   I tried
   for(iin1:nrow(namen2)){paste("a",i,"q",sep="")<-t(as.data.frame(paste("a",
   i,"[!is.na(a",i,")]", sep="")))}
   and produced error. Probably i didnt paste correctly.
   Any ideas?
   Thanks a lot!
   Uwe
   Gesendet: Samstag, 07. Dezember 2013 um 08:26 Uhr
   Von: "Wuming Gong" <gongx030 at umn.edu>
   An: "Uwe Bohne" <balu555 at gmx.de>
   Cc: "r-help mailinglist" <r-help at r-project.org>
   Betreff: Re: [R] tune an support vector machine
   Hi Uwe,
   It looks SVM in e1071 and Kernlab does not support feature selection, but
   you can take a look at package penalizedSVM
   ([1][1]http://cran.r-project.org/web/packages/penalizedSVM/penalizedSVM.pdf)
   .
   Or you can implement a SVM-RFE
   ([2][2]http://axon.cs.byu.edu/Dan/778/papers/Feature%20Selection/guyon*.pdf)
   by
   the alpha values returned by svm() in e1071 or ksvm() in Kernlab.
   Wuming
   On Fri, Dec 6, 2013 at 7:06 AM, Uwe Bohne <[3]balu555 at gmx.de> wrote:
   Hej all,
   actually i try to tune a SVM in R and use the package "e1071" wich
   works
   pretty well.
   I do some gridsearch in the parameters and get the best possible
   parameters
   for classification.
   Here is my sample code
   type<-sample(c(-1,1) , 20, replace = TRUE )
   weight<-sample(c(20:50),20, replace=TRUE)
   height<-sample(c(100:200),20, replace=TRUE)
   width<-sample(c(30:50),20,replace=TRUE)
   volume<-sample(c(1000:5000),20,replace=TRUE)
   data<-cbind(type,weight,height,width,volume)
   train<-as.data.frame(data)
   library("e1071")
   features <- c("weight","height","width","volume")
   (formula<-as.formula(paste("type ~ ", paste(features, collapse= "+"))))
   svmtune=tune.svm(formula, data=train, kernel="radial", cost=2^(-2:5),
   gamma=2^(-2:1),cross=10)
   summary(svmtune)
   My question is if there is a way to tune the features.
   So in other words - what i wanna do is to try all possible combinations
   of
   features : for example use only (volume) or use (weight, height) or use
   (height,volume,width) and so on for the SVM and to get the best
   combination
   back.
   Best wishes
   Uwe
   ______________________________________________
   [4]R-help at r-project.org mailing list
   [5][3]https://stat.ethz.ch/mailman/listinfo/r-help
   PLEASE do read the posting guide
   [6][4]http://www.R-project.org/posting-guide.html
   and provide commented, minimal, self-contained, reproducible code.
   References
   1. [5]http://cran.r-project.org/web/packages/penalizedSVM/penalizedSVM.pdf
   2. [6]http://axon.cs.byu.edu/Dan/778/papers/Feature%20Selection/guyon*.pdf
   3. file://localhost/tmp/balu555 at gmx.de
   4. file://localhost/tmp/R-help at r-project.org
   5. [7]https://stat.ethz.ch/mailman/listinfo/r-help
   6. [8]http://www.R-project.org/posting-guide.html
   ______________________________________________
   R-help at r-project.org mailing list
   [9]https://stat.ethz.ch/mailman/listinfo/r-help
   PLEASE do read the posting guide
   [10]http://www.R-project.org/posting-guide.html
   and provide commented, minimal, self-contained, reproducible code.

References

   1. http://cran.r-project.org/web/packages/penalizedSVM/penalizedSVM.pdf
   2. http://axon.cs.byu.edu/Dan/778/papers/Feature%20Selection/guyon*.pdf)by
   3. https://stat.ethz.ch/mailman/listinfo/r-help
   4. http://www.R-project.org/posting-guide.html
   5. http://cran.r-project.org/web/packages/penalizedSVM/penalizedSVM.pdf
   6. http://axon.cs.byu.edu/Dan/778/papers/Feature%20Selection/guyon*.pdf
   7. https://stat.ethz.ch/mailman/listinfo/r-help
   8. http://www.R-project.org/posting-guide.html
   9. https://stat.ethz.ch/mailman/listinfo/r-help
  10. http://www.R-project.org/posting-guide.html

From tvkarthik05 at gmail.com  Sat Dec  7 13:46:50 2013
From: tvkarthik05 at gmail.com (Venkat Karthik)
Date: Sat, 7 Dec 2013 18:16:50 +0530
Subject: [R] wmf screen resolution problem!!!
Message-ID: <CACT+FieveiZCK7LVf29QfZ9iYWr=VyJHiM4nnK4zCiGmhaVHgQ@mail.gmail.com>

Dear colleagues,

For the past two weeks we have been struggling to create a proper image
with stable pixels, height & width from R for various screen resolutions.

We are trying to generate a wmf image with fixed pixels, fixed height &
fixed width. But the problem we are facing is that when the same code is
run on a different screen resolution the dimensions of the image are no
longer the same.

We would like to generate an image with height=16.6 cm and width=25 cm.
Example code:
##Width & height in inches
height <- 6.53
width  <- 9.84
h <- height + (height*0.128)  #Correcting the height so that when inserted
into word doc height in the Original size is 16.6cm
w <- width  + (width*0.0570) #Correcting the width so that when inserted
into word doc width in the Original size is 25cm
win.metafile("path to save\\test.wmf", height=h, width=w, restoreConsole =
TRUE)
boxplot(1:100)
dev.off()

When this image is generated on a screen resolution
*1280x1024* ==> height =16.6cm   ; width=25cm   ;  pixels=999x708
*1920x1080 *==> height =15.73cm ; width=16.6cm ; pixels=999x708

Is it possible to keep all the 3 things fixed across different screen
resolutions?

Please find attached the images generated in the 2 resolutions.

It would be of great help if anyone could suggest what could be done.

Thanks in advance!!!

Regards,
Karthik

From gundalav at gmail.com  Sat Dec  7 15:28:46 2013
From: gundalav at gmail.com (Gundala Viswanath)
Date: Sat, 7 Dec 2013 23:28:46 +0900
Subject: [R] How to perform clustering without removing rows where NA is
 present in R
Message-ID: <CADVKSzyppiYTi-8+fjf6XDSdQje-9aw-zjZqFY2UNv+OBUXcBA@mail.gmail.com>

I have a data which contain some NA value in their elements.
What I want to do is to **perform clustering without removing rows**
where the NA is present.

I understand that `gower` distance measure in `daisy` allow such situation.
But why my code below doesn't work?

__BEGIN__
    # plot heat map with dendogram together.

    library("gplots")
    library("cluster")


    # Arbitrarily assigning NA to some elements
    mtcars[2,2] <- "NA"
    mtcars[6,7]  <- "NA"

     mydata <- mtcars

    hclustfunc <- function(x) hclust(x, method="complete")

    # Initially I wanted to use this but it didn't take NA
    #distfunc <- function(x) dist(x,method="euclidean")

    # Try using daisy GOWER function
    # which suppose to work with NA value
    distfunc <- function(x) daisy(x,metric="gower")

    d <- distfunc(mydata)
    fit <- hclustfunc(d)

    # Perform clustering heatmap
    heatmap.2(as.matrix(mydata),dendrogram="row",trace="none",
margin=c(8,9), hclust=hclustfunc,distfun=distfunc);
__END__

   The error message I got is this:

        Error in which(is.na) : argument to 'which' is not logical
    Calls: distfunc.g -> daisy
    In addition: Warning messages:
    1: In data.matrix(x) : NAs introduced by coercion
    2: In data.matrix(x) : NAs introduced by coercion
    3: In daisy(x, metric = "gower") :
      binary variable(s) 8, 9 treated as interval scaled
    Execution halted


At the end of the day, I'd like to perform hierarchical clustering
with the NA allowed data.

G.V.


From gundalav at gmail.com  Sat Dec  7 15:28:46 2013
From: gundalav at gmail.com (Gundala Viswanath)
Date: Sat, 7 Dec 2013 23:28:46 +0900
Subject: [R] How to perform clustering without removing rows where NA is
 present in R
Message-ID: <CADVKSzyppiYTi-8+fjf6XDSdQje-9aw-zjZqFY2UNv+OBUXcBA@mail.gmail.com>

I have a data which contain some NA value in their elements.
What I want to do is to **perform clustering without removing rows**
where the NA is present.

I understand that `gower` distance measure in `daisy` allow such situation.
But why my code below doesn't work?

__BEGIN__
    # plot heat map with dendogram together.

    library("gplots")
    library("cluster")


    # Arbitrarily assigning NA to some elements
    mtcars[2,2] <- "NA"
    mtcars[6,7]  <- "NA"

     mydata <- mtcars

    hclustfunc <- function(x) hclust(x, method="complete")

    # Initially I wanted to use this but it didn't take NA
    #distfunc <- function(x) dist(x,method="euclidean")

    # Try using daisy GOWER function
    # which suppose to work with NA value
    distfunc <- function(x) daisy(x,metric="gower")

    d <- distfunc(mydata)
    fit <- hclustfunc(d)

    # Perform clustering heatmap
    heatmap.2(as.matrix(mydata),dendrogram="row",trace="none",
margin=c(8,9), hclust=hclustfunc,distfun=distfunc);
__END__

   The error message I got is this:

        Error in which(is.na) : argument to 'which' is not logical
    Calls: distfunc.g -> daisy
    In addition: Warning messages:
    1: In data.matrix(x) : NAs introduced by coercion
    2: In data.matrix(x) : NAs introduced by coercion
    3: In daisy(x, metric = "gower") :
      binary variable(s) 8, 9 treated as interval scaled
    Execution halted


At the end of the day, I'd like to perform hierarchical clustering
with the NA allowed data.

G.V.


From robinmjelle at gmail.com  Sat Dec  7 17:30:23 2013
From: robinmjelle at gmail.com (Robin Mjelle)
Date: Sat, 7 Dec 2013 17:30:23 +0100
Subject: [R] ANOVA in R
Message-ID: <CAK-gKJvWyKdW1A+VvtvLJ5gMHE-s6KAFtkqVrrH+MY972snk8A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131207/49d0f435/attachment.pl>

From gunter.berton at gene.com  Sat Dec  7 19:36:01 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 7 Dec 2013 10:36:01 -0800
Subject: [R] ANOVA in R
In-Reply-To: <CAK-gKJvWyKdW1A+VvtvLJ5gMHE-s6KAFtkqVrrH+MY972snk8A@mail.gmail.com>
References: <CAK-gKJvWyKdW1A+VvtvLJ5gMHE-s6KAFtkqVrrH+MY972snk8A@mail.gmail.com>
Message-ID: <CACk-te2b_smdBbDHWLpzg4rg96AfAXxHY9FSKreh1BrVz8Tw-A@mail.gmail.com>

I think you start by doing your homework:

1. Read "An Inroduction to R" (ships with R) or other R online
tutorial. There are many good ones.

2. Use R's Help system:
?aov
?lm
?anova

there will be relevant links in these docs that you should follow,
especially to the use of formulas for model specification and
summary() for printing results (including anova tables).

3. Alternatively, have a look at the Rcmdr package for a GUI interface
to R that may meet your needs while allowing you to skip the homework.

Cheers,
Bert




On Sat, Dec 7, 2013 at 8:30 AM, Robin Mjelle <robinmjelle at gmail.com> wrote:
> ID
>
> a_t1    a_t2    b_t1    b_t2
> CACCCGTAGAACCGACCTTGCG_mmu-miR-99b-5p    1578    1941    2348    10941
> CACCCGTAGAACCGACCTTGC_mmu-miR-99b-5p    442    426    564    3839
> CACCCGTAGAACCGACCTTG_mmu-miR-99b-5p    54    43    66    253
> CCGTAGAACCGACCTTGCG_mmu-miR-99b-5p    26    33    33    157
> CGTAGAACCGACCTTGCG_mmu-miR-99b-5p    23    22    38    187
> CACCCGTAGAACCGACCT_mmu-miR-99b-5p    17    27    31    189
> ACCCGTAGAACCGACCTTGCG_mmu-miR-99b-5p    14    19    30    94
>
> I want to run an ANOVA test on the rows above. I have two conditions with
> two replicates each. I assume that there is no difference between a and b
> for the different rows. I want to get which rows a different between a and
> b.
> How do I approach this in R?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From jieyueli82 at gmail.com  Sun Dec  8 00:45:51 2013
From: jieyueli82 at gmail.com (Jieyue Li)
Date: Sat, 7 Dec 2013 15:45:51 -0800
Subject: [R] combine glmnet and coxph (and survfit) with strata()
Message-ID: <CALYjA0TFu68tRPyJxGOUg8kMAvQ1Rsdb0Hbo4tA3=Coah_7gjA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131207/6ee31009/attachment.pl>

From jieyueli82 at gmail.com  Sun Dec  8 00:52:34 2013
From: jieyueli82 at gmail.com (Jieyue Li)
Date: Sat, 7 Dec 2013 15:52:34 -0800
Subject: [R] computational cost of the survpack or survival support vector
	machine package
Message-ID: <CALYjA0ShbiB4XoXhyBC53jX8W4yvO-L4_SUszZwbjT6D59wcmQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131207/f37f5a99/attachment.pl>

From ripley at stats.ox.ac.uk  Sun Dec  8 06:38:52 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 08 Dec 2013 05:38:52 +0000
Subject: [R] wmf screen resolution problem!!!
In-Reply-To: <CACT+FieveiZCK7LVf29QfZ9iYWr=VyJHiM4nnK4zCiGmhaVHgQ@mail.gmail.com>
References: <CACT+FieveiZCK7LVf29QfZ9iYWr=VyJHiM4nnK4zCiGmhaVHgQ@mail.gmail.com>
Message-ID: <52A405EC.4000604@stats.ox.ac.uk>

On 07/12/2013 12:46, Venkat Karthik wrote:
> Dear colleagues,
>
> For the past two weeks we have been struggling to create a proper image
> with stable pixels, height & width from R for various screen resolutions.

You cannot do that: it is a function of the format and how Microsoft's 
GDI works.

> We are trying to generate a wmf image with fixed pixels, fixed height &
> fixed width. But the problem we are facing is that when the same code is

Why?  .wmf is only useful if it is a vector file, and 'pixels' then do 
not matter.

> run on a different screen resolution the dimensions of the image are no
> longer the same.
>
> We would like to generate an image with height=16.6 cm and width=25 cm.
> Example code:
> ##Width & height in inches
> height <- 6.53
> width  <- 9.84
> h <- height + (height*0.128)  #Correcting the height so that when inserted
> into word doc height in the Original size is 16.6cm
> w <- width  + (width*0.0570) #Correcting the width so that when inserted
> into word doc width in the Original size is 25cm
> win.metafile("path to save\\test.wmf", height=h, width=w, restoreConsole =
> TRUE)
> boxplot(1:100)
> dev.off()
>
> When this image is generated on a screen resolution
> *1280x1024* ==> height =16.6cm   ; width=25cm   ;  pixels=999x708
> *1920x1080 *==> height =15.73cm ; width=16.6cm ; pixels=999x708
>
> Is it possible to keep all the 3 things fixed across different screen
> resolutions?
>
> Please find attached the images generated in the 2 resolutions.
>
> It would be of great help if anyone could suggest what could be done.
>
> Thanks in advance!!!
>
> Regards,
> Karthik
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gundalav at gmail.com  Sun Dec  8 08:11:12 2013
From: gundalav at gmail.com (Gundala Viswanath)
Date: Sun, 8 Dec 2013 16:11:12 +0900
Subject: [R] Why daisy() in cluster library failed to exclude NA when
	computing dissimilarity
Message-ID: <CADVKSzyEaJRNgPCBYQTpPL=7QK+Kw2YrrQrfaJtfdxs303Jivg@mail.gmail.com>

Hi,


According to daisy function from cluster documentation, it can compute
dissimilarity when NA (missing) value(s) is present.

http://stat.ethz.ch/R-manual/R-devel/library/cluster/html/daisy.html

But why when I tried this code

library(cluster)
x <- c(1.115,NA,NA,0.971,NA)
y <- c(NA,1.006,NA,NA,0.645)
df <- as.data.frame(rbind(x,y))
daisy(df,metric="gower")

It gave this message:

Dissimilarities :
   x
y NA

Metric :  mixed ;  Types = I, I, I, I, I
Number of objects : 2
Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf

I welcome other alternative than gower.

I expect the dissimilarity output gives a non-NA value e.g. 0. What's
the right way to do it?

G.V.


From gundalav at gmail.com  Sun Dec  8 08:11:12 2013
From: gundalav at gmail.com (Gundala Viswanath)
Date: Sun, 8 Dec 2013 16:11:12 +0900
Subject: [R] Why daisy() in cluster library failed to exclude NA when
	computing dissimilarity
Message-ID: <CADVKSzyEaJRNgPCBYQTpPL=7QK+Kw2YrrQrfaJtfdxs303Jivg@mail.gmail.com>

Hi,


According to daisy function from cluster documentation, it can compute
dissimilarity when NA (missing) value(s) is present.

http://stat.ethz.ch/R-manual/R-devel/library/cluster/html/daisy.html

But why when I tried this code

library(cluster)
x <- c(1.115,NA,NA,0.971,NA)
y <- c(NA,1.006,NA,NA,0.645)
df <- as.data.frame(rbind(x,y))
daisy(df,metric="gower")

It gave this message:

Dissimilarities :
   x
y NA

Metric :  mixed ;  Types = I, I, I, I, I
Number of objects : 2
Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf

I welcome other alternative than gower.

I expect the dissimilarity output gives a non-NA value e.g. 0. What's
the right way to do it?

G.V.


From ecokingsly at yahoo.co.in  Sun Dec  8 12:22:04 2013
From: ecokingsly at yahoo.co.in (kingsly)
Date: Sun, 8 Dec 2013 03:22:04 -0800 (PST)
Subject: [R] How to evaluate sequence of strings like this
Message-ID: <1386501696.10821.YahooMailNeo@web190502.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131208/8e56ba28/attachment.pl>

From tolga.uzuner at gmail.com  Sun Dec  8 15:03:35 2013
From: tolga.uzuner at gmail.com (Tolga Uzuner)
Date: Sun, 08 Dec 2013 09:03:35 -0500
Subject: [R] rJava problems
Message-ID: <52A47C37.6000003@gmail.com>

Dear R Users
Have run into a problem with the rJava package recently. I do not seem 
to be able to load the package. I am on R 3.0.2 and updated the rJava 
package this morning from the Pennsylvania mirrors. I get the following 
error:

----
package ?mnormt? successfully unpacked and MD5 sums checked
package ?rJava? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
C:\Users\t_uzu_000\AppData\Local\Temp\RtmpOC9zec\downloaded_packages
 > library(rJava)
Error in get(Info[i, 1], envir = env) :
cannot allocate memory block of size 2.8 Gb
Error: package or namespace load failed for ?rJava?
 >
----

Any pointers ?

Thanks in advance


From sarah.goslee at gmail.com  Sun Dec  8 15:15:02 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 8 Dec 2013 09:15:02 -0500
Subject: [R] Why daisy() in cluster library failed to exclude NA when
 computing dissimilarity
In-Reply-To: <CADVKSzyEaJRNgPCBYQTpPL=7QK+Kw2YrrQrfaJtfdxs303Jivg@mail.gmail.com>
References: <CADVKSzyEaJRNgPCBYQTpPL=7QK+Kw2YrrQrfaJtfdxs303Jivg@mail.gmail.com>
Message-ID: <CAM_vjun=vU+oyRPdLTG9dz3ChkKtSiDm+tcvq3sOy++mEvYCqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131208/97978bfd/attachment.pl>

From Peter.Alspach at plantandfood.co.nz  Sun Dec  8 15:50:26 2013
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Mon, 9 Dec 2013 03:50:26 +1300
Subject: [R] How to evaluate sequence of strings like this
In-Reply-To: <1386501696.10821.YahooMailNeo@web190502.mail.sg3.yahoo.com>
References: <1386501696.10821.YahooMailNeo@web190502.mail.sg3.yahoo.com>
Message-ID: <ED8CD182D432434485C7D1787FB06DDC0CDC3D3B8D@AKLEXM01.PFR.CO.NZ>

Tena koe

Try

apply(mydat, 1, paste, collapse='')

HTH ....

Peter Alspach
________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] On Behalf Of kingsly [ecokingsly at yahoo.co.in]
Sent: Monday, December 09, 2013 12:22 AM
To: r-help at r-project.org
Subject: [R] How to evaluate sequence of strings like this

Hello Dear R community,
 This is my problem.  I have a data set (dataframe) called "mydat". It consist of 3 numerical variable.  They are Centrecode, FSUSN and Round. I want to create unique ID by combining these 3 variables.
Follwing commands gives me what I need.

mydat1 <- paste(mydat$Centrecode, mydat$FSUSN,mydat$Round,sep="")
newds <- data.frame(mydat1)

 For a large data set, I don't want to write like this ...    "mydat$Centrecode, mydat$FSUSN,mydat$Round". So,  I tried to automate using following code.

nvar <- paste("mydat","$",names(mydat)[1:3],sep="")
mydat1 <- paste(eval(parse(text=nvar)))
newds <- data.frame(mydat1_u)

I am finding problem in the second line. Please help me.
Thank you for your kind help.



--
View this message in context: http://r.789695.n4.nabble.com/How-to-evaluate-sequence-of-strings-like-this-tp4681823.html
Sent from the R help mailing list archive at Nabble.com.
        [[alternative HTML version deleted]]

The contents of this e-mail are confidential and may be ...{{dropped:14}}


From tolga.uzuner at gmail.com  Sun Dec  8 15:55:02 2013
From: tolga.uzuner at gmail.com (Tolga Uzuner)
Date: Sun, 08 Dec 2013 09:55:02 -0500
Subject: [R] rJava problems
In-Reply-To: <52A47C37.6000003@gmail.com>
References: <52A47C37.6000003@gmail.com>
Message-ID: <52A48846.3050104@gmail.com>

A small follow-on to this: I uninstalled the package, restarted my 
machine, and reinstalled the package. Now, when I try and load the 
package, I get an entirely different error message:

 > library("rJava")
Error : .onLoad failed in loadNamespace() for 'rJava', details:
   call: inDL(x, as.logical(local), as.logical(now), ...)
   error: unable to load shared object 
'C:/Users/t_uzu_000/Documents/R/win-library/3.0/rJava/libs/i386/rJava.dll':
   LoadLibrary failure:  %1 is not a valid Win32 application.

Error: package or namespace load failed for ?rJava?

Any thoughts appreciated.

Kind regards

On 08/12/2013 09:03, Tolga Uzuner wrote:
> Dear R Users
> Have run into a problem with the rJava package recently. I do not seem 
> to be able to load the package. I am on R 3.0.2 and updated the rJava 
> package this morning from the Pennsylvania mirrors. I get the 
> following error:
>
> ----
> package ?mnormt? successfully unpacked and MD5 sums checked
> package ?rJava? successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
> C:\Users\t_uzu_000\AppData\Local\Temp\RtmpOC9zec\downloaded_packages
> > library(rJava)
> Error in get(Info[i, 1], envir = env) :
> cannot allocate memory block of size 2.8 Gb
> Error: package or namespace load failed for ?rJava?
> >
> ----
>
> Any pointers ?
>
> Thanks in advance


From tolga.uzuner at gmail.com  Sun Dec  8 16:37:09 2013
From: tolga.uzuner at gmail.com (Tolga Uzuner)
Date: Sun, 08 Dec 2013 10:37:09 -0500
Subject: [R] Problems updating packages
Message-ID: <52A49225.2030701@gmail.com>

Dear R Users
Ive just uninstalled R and reinstalled from scratch. I then hit Update 
Packages and get the following message:

 > update.packages(ask='graphics',checkBuilt=TRUE)
--- Please select a CRAN mirror for use in this session ---
Warning: package 'foreign' in library 'C:/Program 
Files/R/R-3.0.2/library' will not be updated
Warning: package 'lattice' in library 'C:/Program 
Files/R/R-3.0.2/library' will not be updated
Warning: package 'Matrix' in library 'C:/Program 
Files/R/R-3.0.2/library' will not be updated
Warning: package 'mgcv' in library 'C:/Program Files/R/R-3.0.2/library' 
will not be updated
Warning: package 'nlme' in library 'C:/Program Files/R/R-3.0.2/library' 
will not be updated
 >

Why would this be the case ?

Thanks in advance


From kehld at ktk.pte.hu  Sun Dec  8 16:45:38 2013
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?D=E1niel_Kehl?=)
Date: Sun, 8 Dec 2013 15:45:38 +0000
Subject: [R] growth curve estimation
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B90662B@EMAIL.ktkdom.pte.hu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131208/8b1e5dca/attachment.pl>

From smartpink111 at yahoo.com  Sun Dec  8 17:59:51 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 8 Dec 2013 08:59:51 -0800 (PST)
Subject: [R] How to evaluate sequence of strings like this
In-Reply-To: <1386501696.10821.YahooMailNeo@web190502.mail.sg3.yahoo.com>
References: <1386501696.10821.YahooMailNeo@web190502.mail.sg3.yahoo.com>
Message-ID: <1386521991.56294.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You could do without "eval(parse(.."

mydat <- data.frame(Centercode=letters[1:5],FSUSN=letters[6:10],Round=letters[11:15],stringsAsFactors=FALSE)
mydat1 <- paste(mydat$Centercode, mydat$FSUSN,mydat$Round,sep="")
?mydat2 <- as.character(interaction(mydat,sep=""))
?identical(mydat1,mydat2)
#[1] TRUE
#or
mydat3 <- do.call(paste0,mydat)
identical(mydat1,mydat2)
#[1] TRUE
A.K.


On Sunday, December 8, 2013 8:58 AM, kingsly <ecokingsly at yahoo.co.in> wrote:
Hello Dear R community,
?This is my problem.? I have a data set (dataframe)?called "mydat". It consist of 3 numerical variable.? They are Centrecode, FSUSN and?Round. I want to create unique ID by combining these 3 variables.
Follwing commands gives me what I need.

mydat1 <- paste(mydat$Centrecode, mydat$FSUSN,mydat$Round,sep="")
newds <- data.frame(mydat1)
?
?For a large data set, I don't want to write like this ...??? "mydat$Centrecode, mydat$FSUSN,mydat$Round". So,? I tried to automate using following code.
?
nvar <- paste("mydat","$",names(mydat)[1:3],sep="")
mydat1 <- paste(eval(parse(text=nvar)))
newds <- data.frame(mydat1_u)
?
I am finding problem in the second line.?Please help me.?
Thank you for your kind help.



--
View this message in context: http://r.789695.n4.nabble.com/How-to-evaluate-sequence-of-strings-like-this-tp4681823.html
Sent from the R help mailing list archive at Nabble.com.
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From patrick.toche at usj.edu.mo  Sun Dec  8 18:18:10 2013
From: patrick.toche at usj.edu.mo (patrick.toche at usj.edu.mo)
Date: Sun, 8 Dec 2013 09:18:10 -0800 (PST)
Subject: [R] rJava problems
In-Reply-To: <52A48846.3050104@gmail.com>
References: <52A47C37.6000003@gmail.com>
 <52A48846.3050104@gmail.com>
Message-ID: <837da2c1-6830-419e-a2c2-edd4c5810f2e@googlegroups.com>

same problem I'm having...

https://groups.google.com/forum/#!topic/shiny-discuss/ivJzaaUIZcQ



On Sunday, December 8, 2013 10:55:02 PM UTC+8, neo wrote:
>
> A small follow-on to this: I uninstalled the package, restarted my 
> machine, and reinstalled the package. Now, when I try and load the 
> package, I get an entirely different error message: 
>
>  > library("rJava") 
> Error : .onLoad failed in loadNamespace() for 'rJava', details: 
>    call: inDL(x, as.logical(local), as.logical(now), ...) 
>    error: unable to load shared object 
> 'C:/Users/t_uzu_000/Documents/R/win-library/3.0/rJava/libs/i386/rJava.dll': 
>
>    LoadLibrary failure:  %1 is not a valid Win32 application. 
>
> Error: package or namespace load failed for ?rJava? 
>
> Any thoughts appreciated. 
>
> Kind regards 
>
> On 08/12/2013 09:03, Tolga Uzuner wrote: 
> > Dear R Users 
> > Have run into a problem with the rJava package recently. I do not seem 
> > to be able to load the package. I am on R 3.0.2 and updated the rJava 
> > package this morning from the Pennsylvania mirrors. I get the 
> > following error: 
> > 
> > ---- 
> > package ?mnormt? successfully unpacked and MD5 sums checked 
> > package ?rJava? successfully unpacked and MD5 sums checked 
> > 
> > The downloaded binary packages are in 
> > C:\Users\t_uzu_000\AppData\Local\Temp\RtmpOC9zec\downloaded_packages 
> > > library(rJava) 
> > Error in get(Info[i, 1], envir = env) : 
> > cannot allocate memory block of size 2.8 Gb 
> > Error: package or namespace load failed for ?rJava? 
> > > 
> > ---- 
> > 
> > Any pointers ? 
> > 
> > Thanks in advance 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From tbfowler4 at gmail.com  Sun Dec  8 18:35:20 2013
From: tbfowler4 at gmail.com (Thell Fowler)
Date: Sun, 8 Dec 2013 11:35:20 -0600
Subject: [R] R, RStudio, Rcpp Appreciation
Message-ID: <CAAJPTXjmk9L1NFQ8=jRukCfQwMbeauYeofjSMyOxuWAXKyRv+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131208/a4928591/attachment.pl>

From rbaer at atsu.edu  Sun Dec  8 18:50:20 2013
From: rbaer at atsu.edu (Robert Baer)
Date: Sun, 08 Dec 2013 11:50:20 -0600
Subject: [R] rJava problems
In-Reply-To: <52A47C37.6000003@gmail.com>
References: <52A47C37.6000003@gmail.com>
Message-ID: <52A4B15C.2050802@atsu.edu>

You don't really provide enough information like
  R.Version()

but my guess is that you are running 64-bit R either directly or through 
R Studio but that you have only 32-bit Java installed.   I am doing fine 
on Windows with Java 7 update 45 but had some 64-bit run issues with 
only Java 7 update 40 64-bit JDK.

HTH,
Rob


On 12/8/2013 8:03 AM, Tolga Uzuner wrote:
> Dear R Users
> Have run into a problem with the rJava package recently. I do not seem 
> to be able to load the package. I am on R 3.0.2 and updated the rJava 
> package this morning from the Pennsylvania mirrors. I get the 
> following error:
>
> ----
> package ?mnormt? successfully unpacked and MD5 sums checked
> package ?rJava? successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
> C:\Users\t_uzu_000\AppData\Local\Temp\RtmpOC9zec\downloaded_packages
> > library(rJava)
> Error in get(Info[i, 1], envir = env) :
> cannot allocate memory block of size 2.8 Gb
> Error: package or namespace load failed for ?rJava?
> >
> ----
>
> Any pointers ?
>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Dec  8 18:49:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 8 Dec 2013 09:49:26 -0800 (PST)
Subject: [R] subest a data set on two conditions
Message-ID: <1386524966.59075.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
#Eitherindx <- which(df$pvalue <0.05)
?indx1 <- sort(c(indx,ifelse(!indx%%2,indx-1,indx+1)))
df[indx1,]

#or
?df[!!with(df,ave(pvalue,((seq-1)%/%2)+1,FUN= function(x) any(x <0.05))),]
A.K.


How can I subset the example data set based on pvalue ( <0.05) and also include the set of each pairs? 
I could subset with this code a<-subset(df, pvalue <0.05) whcih would give me this output 

? ? Estimate ? ? ?pvalue seq pairs 
10 0.01133065 0.004946311 ?10 ? ? 2 
12 0.02026090 0.039022875 ?12 ? ? 2 
17 0.01621716 0.022891429 ?17 ? ? 1 
19 0.01555321 0.033382339 ?19 ? ? 1 

But I also want to include seq 9, 11, 18 and 20 which are sets of the variable pairs in the output 




> dput(df) 
structure(list(Estimate = c(0.00485470080131958, 0.0017750187497085, 
0.00335445588953967, -0.000584531421758813, 0.00606953408663915, 
-0.00528701750277387, 0.00566389678093939, -0.0157431826077494, 
0.00797445327627353, 0.0113306462560471, 0.00458009238873928, 
0.0202609029566437, 0.000973530938029486, -0.00183247733386492, 
0.00115028173291761, -0.00743448971374577, 0.016217161692567, 
-0.000945376803907414, 0.0155532095509903, -0.00617109741106529 
), pvalue = c(0.171288761250697, 0.507252376337703, 0.328418897915535, 
0.924674871720598, 0.254431502614107, 0.212506044108723, 0.274117055540994, 
0.0963539806017105, 0.156704628343227, 0.00494631086965616, 0.401874172161139, 
0.0390228749596093, 0.817093606803661, 0.581289013427265, 0.776977123239984, 
0.318257277798551, 0.0228914288352906, 0.86659585959993, 0.0333823392712699, 
0.639843703507484), seq = 1:20, pairs = c(1L, 2L, 1L, 2L, 1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L)), 
datalabel = "", time.stamp = " 8 Dec 2013 12:55", .Names = c("Estimate", 
"pvalue", "seq", "pairs"), formats = c("%9.0g", "%9.0g", "%9.0g", 
"%9.0g"), types = c(255L, 255L, 253L, 253L), val.labels = c("", 
"", "", ""), var.labels = c("Estimate", "pvalue", "seq", "pairs" 
), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9", 
"10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20" 
), version = 12L, class = "data.frame")


From ligges at statistik.tu-dortmund.de  Sun Dec  8 19:07:39 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 08 Dec 2013 19:07:39 +0100
Subject: [R] Problems updating packages
In-Reply-To: <52A49225.2030701@gmail.com>
References: <52A49225.2030701@gmail.com>
Message-ID: <52A4B56B.4080703@statistik.tu-dortmund.de>



On 08.12.2013 16:37, Tolga Uzuner wrote:
> Dear R Users
> Ive just uninstalled R and reinstalled from scratch. I then hit Update
> Packages and get the following message:
>
>  > update.packages(ask='graphics',checkBuilt=TRUE)
> --- Please select a CRAN mirror for use in this session ---
> Warning: package 'foreign' in library 'C:/Program
> Files/R/R-3.0.2/library' will not be updated
> Warning: package 'lattice' in library 'C:/Program
> Files/R/R-3.0.2/library' will not be updated
> Warning: package 'Matrix' in library 'C:/Program
> Files/R/R-3.0.2/library' will not be updated
> Warning: package 'mgcv' in library 'C:/Program Files/R/R-3.0.2/library'
> will not be updated
> Warning: package 'nlme' in library 'C:/Program Files/R/R-3.0.2/library'
> will not be updated
>  >
>
> Why would this be the case ?

You do not have permissions to update packages in that library.

Best,
Uwe Ligges




>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tolga.uzuner at gmail.com  Sun Dec  8 19:12:14 2013
From: tolga.uzuner at gmail.com (Tolga Uzuner)
Date: Sun, 8 Dec 2013 13:12:14 -0500
Subject: [R] Problems updating packages
In-Reply-To: <52A4B56B.4080703@statistik.tu-dortmund.de>
References: <52A49225.2030701@gmail.com>
	<52A4B56B.4080703@statistik.tu-dortmund.de>
Message-ID: <899C9E39-34F6-4EE7-9357-F7E41C753F72@gmail.com>

OK thanks. The odd thing is, this just started happening. And I am an Admin on my machine.

Or I think I am...hmm, let me check, maybe I did something to my own privileges recently by mistake.

Sent from my iPhone

> On 8 Dec 2013, at 01:07 pm, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
> 
> 
> 
>> On 08.12.2013 16:37, Tolga Uzuner wrote:
>> Dear R Users
>> Ive just uninstalled R and reinstalled from scratch. I then hit Update
>> Packages and get the following message:
>> 
>> > update.packages(ask='graphics',checkBuilt=TRUE)
>> --- Please select a CRAN mirror for use in this session ---
>> Warning: package 'foreign' in library 'C:/Program
>> Files/R/R-3.0.2/library' will not be updated
>> Warning: package 'lattice' in library 'C:/Program
>> Files/R/R-3.0.2/library' will not be updated
>> Warning: package 'Matrix' in library 'C:/Program
>> Files/R/R-3.0.2/library' will not be updated
>> Warning: package 'mgcv' in library 'C:/Program Files/R/R-3.0.2/library'
>> will not be updated
>> Warning: package 'nlme' in library 'C:/Program Files/R/R-3.0.2/library'
>> will not be updated
>> >
>> 
>> Why would this be the case ?
> 
> You do not have permissions to update packages in that library.
> 
> Best,
> Uwe Ligges
> 
> 
> 
> 
>> 
>> Thanks in advance
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Sun Dec  8 19:13:44 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 08 Dec 2013 19:13:44 +0100
Subject: [R] Problems updating packages
In-Reply-To: <899C9E39-34F6-4EE7-9357-F7E41C753F72@gmail.com>
References: <52A49225.2030701@gmail.com>
	<52A4B56B.4080703@statistik.tu-dortmund.de>
	<899C9E39-34F6-4EE7-9357-F7E41C753F72@gmail.com>
Message-ID: <52A4B6D8.1010503@statistik.tu-dortmund.de>



On 08.12.2013 19:12, Tolga Uzuner wrote:
> OK thanks. The odd thing is, this just started happening. And I am an Admin on my machine.
>
> Or I think I am...hmm, let me check, maybe I did something to my own privileges recently by mistake.


Right click R and "start as Administrator"?

Best,
Uwe Ligges

> Sent from my iPhone
>
>> On 8 Dec 2013, at 01:07 pm, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>>
>>
>>
>>> On 08.12.2013 16:37, Tolga Uzuner wrote:
>>> Dear R Users
>>> Ive just uninstalled R and reinstalled from scratch. I then hit Update
>>> Packages and get the following message:
>>>
>>>> update.packages(ask='graphics',checkBuilt=TRUE)
>>> --- Please select a CRAN mirror for use in this session ---
>>> Warning: package 'foreign' in library 'C:/Program
>>> Files/R/R-3.0.2/library' will not be updated
>>> Warning: package 'lattice' in library 'C:/Program
>>> Files/R/R-3.0.2/library' will not be updated
>>> Warning: package 'Matrix' in library 'C:/Program
>>> Files/R/R-3.0.2/library' will not be updated
>>> Warning: package 'mgcv' in library 'C:/Program Files/R/R-3.0.2/library'
>>> will not be updated
>>> Warning: package 'nlme' in library 'C:/Program Files/R/R-3.0.2/library'
>>> will not be updated
>>>>
>>>
>>> Why would this be the case ?
>>
>> You do not have permissions to update packages in that library.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>
>>>
>>> Thanks in advance
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From tolga.uzuner at gmail.com  Sun Dec  8 19:15:37 2013
From: tolga.uzuner at gmail.com (Tolga Uzuner)
Date: Sun, 8 Dec 2013 13:15:37 -0500
Subject: [R] rJava problems
In-Reply-To: <52A4B15C.2050802@atsu.edu>
References: <52A47C37.6000003@gmail.com> <52A4B15C.2050802@atsu.edu>
Message-ID: <A63BB1FA-53F0-4C86-BF73-68BE6EFAFC62@gmail.com>

Thank you Rob. I used to have the 64-bit R also installed, but removed it and did not reinstall it. I also cleared out all rJava.dll files on my computer before reinstalling R fresh. I am running R through Rgui,  not Rstudio. I will post RVersion data later once I return to my PC, apologies.

Sent from my iPhone

> On 8 Dec 2013, at 12:50 pm, Robert Baer <rbaer at atsu.edu> wrote:
> 
> You don't really provide enough information like
> R.Version()
> 
> but my guess is that you are running 64-bit R either directly or through R Studio but that you have only 32-bit Java installed.   I am doing fine on Windows with Java 7 update 45 but had some 64-bit run issues with only Java 7 update 40 64-bit JDK.
> 
> HTH,
> Rob
> 
> 
>> On 12/8/2013 8:03 AM, Tolga Uzuner wrote:
>> Dear R Users
>> Have run into a problem with the rJava package recently. I do not seem to be able to load the package. I am on R 3.0.2 and updated the rJava package this morning from the Pennsylvania mirrors. I get the following error:
>> 
>> ----
>> package ?mnormt? successfully unpacked and MD5 sums checked
>> package ?rJava? successfully unpacked and MD5 sums checked
>> 
>> The downloaded binary packages are in
>> C:\Users\t_uzu_000\AppData\Local\Temp\RtmpOC9zec\downloaded_packages
>> > library(rJava)
>> Error in get(Info[i, 1], envir = env) :
>> cannot allocate memory block of size 2.8 Gb
>> Error: package or namespace load failed for ?rJava?
>> >
>> ----
>> 
>> Any pointers ?
>> 
>> Thanks in advance
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From ecokingsly at yahoo.co.in  Sun Dec  8 19:20:31 2013
From: ecokingsly at yahoo.co.in (kingsly)
Date: Sun, 8 Dec 2013 10:20:31 -0800 (PST)
Subject: [R] How to evaluate sequence of strings like this
In-Reply-To: <1386521991.56294.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1386501696.10821.YahooMailNeo@web190502.mail.sg3.yahoo.com>
	<1386521991.56294.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1386526799.96861.YahooMailNeo@web190503.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131208/07a10ed1/attachment.pl>

From xiaogangsu at gmail.com  Sun Dec  8 20:38:32 2013
From: xiaogangsu at gmail.com (Xiaogang Su)
Date: Sun, 8 Dec 2013 12:38:32 -0700
Subject: [R] rJava problems
In-Reply-To: <A63BB1FA-53F0-4C86-BF73-68BE6EFAFC62@gmail.com>
References: <52A47C37.6000003@gmail.com> <52A4B15C.2050802@atsu.edu>
	<A63BB1FA-53F0-4C86-BF73-68BE6EFAFC62@gmail.com>
Message-ID: <CAKRWT8-vX_RXvJ6jfQv+7ePQE2BGQCYoj38AdynPBAhkvf5osw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131208/76aba423/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sun Dec  8 21:28:06 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 08 Dec 2013 12:28:06 -0800
Subject: [R] Problems updating packages
In-Reply-To: <899C9E39-34F6-4EE7-9357-F7E41C753F72@gmail.com>
References: <52A49225.2030701@gmail.com>
	<52A4B56B.4080703@statistik.tu-dortmund.de>
	<899C9E39-34F6-4EE7-9357-F7E41C753F72@gmail.com>
Message-ID: <56b09253-aafa-402a-966b-436c3655e3df@email.android.com>

I recommend using a personal library directory unless you really are an administrator of a computer that multiple users of R use (very unusual for Windows). The install program offers you the opportunity to create an R/win-library/ directory. If you do this and make a habit of never updating "As Administrator" then you won't have to worry about permissions getting screwed up. This strategy actually works quite well on Linux as well, and I imagine would be a good strategy on any OS. The only thing you would need to elevate permissions for is to upgrade R, and Windows UAE will prompt you for that when you run the install.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Tolga Uzuner <tolga.uzuner at gmail.com> wrote:
>OK thanks. The odd thing is, this just started happening. And I am an
>Admin on my machine.
>
>Or I think I am...hmm, let me check, maybe I did something to my own
>privileges recently by mistake.
>
>Sent from my iPhone
>
>> On 8 Dec 2013, at 01:07 pm, Uwe Ligges
><ligges at statistik.tu-dortmund.de> wrote:
>> 
>> 
>> 
>>> On 08.12.2013 16:37, Tolga Uzuner wrote:
>>> Dear R Users
>>> Ive just uninstalled R and reinstalled from scratch. I then hit
>Update
>>> Packages and get the following message:
>>> 
>>> > update.packages(ask='graphics',checkBuilt=TRUE)
>>> --- Please select a CRAN mirror for use in this session ---
>>> Warning: package 'foreign' in library 'C:/Program
>>> Files/R/R-3.0.2/library' will not be updated
>>> Warning: package 'lattice' in library 'C:/Program
>>> Files/R/R-3.0.2/library' will not be updated
>>> Warning: package 'Matrix' in library 'C:/Program
>>> Files/R/R-3.0.2/library' will not be updated
>>> Warning: package 'mgcv' in library 'C:/Program
>Files/R/R-3.0.2/library'
>>> will not be updated
>>> Warning: package 'nlme' in library 'C:/Program
>Files/R/R-3.0.2/library'
>>> will not be updated
>>> >
>>> 
>>> Why would this be the case ?
>> 
>> You do not have permissions to update packages in that library.
>> 
>> Best,
>> Uwe Ligges
>> 
>> 
>> 
>> 
>>> 
>>> Thanks in advance
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Mon Dec  9 00:11:12 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Sun, 8 Dec 2013 23:11:12 +0000
Subject: [R] wmf screen resolution problem!!!
In-Reply-To: <CACT+FieveiZCK7LVf29QfZ9iYWr=VyJHiM4nnK4zCiGmhaVHgQ@mail.gmail.com>
References: <CACT+FieveiZCK7LVf29QfZ9iYWr=VyJHiM4nnK4zCiGmhaVHgQ@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED56C9B5A001@GOLD.corp.lgc-group.com>


________________________________________
> From:Venkat Karthik [tvkarthik05 at gmail.com]
> We are trying to generate a wmf image with fixed pixels, fixed height &
> fixed width. But the problem we are facing is that when the same code is
> run on a different screen resolution the dimensions of the image are no
> longer the same.

In what medium are you measuring the size of the image?

If you're reading on screen, try reading the help page for ?windows, where it says 
   "The size of a window is computed from information provided about
     the display: it depends on the system being configured accurately.
     By default a screen device asks Windows for the number of pixels
     per inch.  This can be overridden (it is often wrong) by
     specifying ?xpinch? and ?ypinch?"
... and rather more.

Broadly, though, you are generating a vector image of defined size in some medium. There is no meaningful pixel count until you use a raster device to display it, and when you do, the size depends entirely on what the device thinks its pixel size is. And it seems that windows is not often right about it.

S






*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From michel.arnaud at cirad.fr  Mon Dec  9 08:04:31 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Mon, 09 Dec 2013 08:04:31 +0100
Subject: [R] To transform a vector
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED56C9B5A001@GOLD.corp.lgc-group.com>
References: <CACT+FieveiZCK7LVf29QfZ9iYWr=VyJHiM4nnK4zCiGmhaVHgQ@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED56C9B5A001@GOLD.corp.lgc-group.com>
Message-ID: <52A56B7F.7000305@cirad.fr>

Dear R Users

I have the vector
X <- c( 6 , 4 ,12 , 3)

I would like to build a new vector by to transform it into
Y <- c(rep(X[1], X[1]), rep(X[2], X[2]), rep(X[3], X[3]), rep(X[4], X[4]))

Have you a more elegant answer ?

PS : Sorry for this basic question

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From bhh at xs4all.nl  Mon Dec  9 08:14:14 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 9 Dec 2013 08:14:14 +0100
Subject: [R] To transform a vector
In-Reply-To: <52A56B7F.7000305@cirad.fr>
References: <CACT+FieveiZCK7LVf29QfZ9iYWr=VyJHiM4nnK4zCiGmhaVHgQ@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED56C9B5A001@GOLD.corp.lgc-group.com>
	<52A56B7F.7000305@cirad.fr>
Message-ID: <D5AECFB5-88E8-49B5-8816-6122BF094088@xs4all.nl>


On 09-12-2013, at 08:04, Arnaud Michel <michel.arnaud at cirad.fr> wrote:

> Dear R Users
> 
> I have the vector
> X <- c( 6 , 4 ,12 , 3)
> 
> I would like to build a new vector by to transform it into
> Y <- c(rep(X[1], X[1]), rep(X[2], X[2]), rep(X[3], X[3]), rep(X[4], X[4]))
> 
> Have you a more elegant answer ?


Have a good read of ?rep.

Try this:

rep(X,times=X)

Berend


From kridox at ymail.com  Mon Dec  9 08:14:46 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 9 Dec 2013 16:14:46 +0900
Subject: [R] To transform a vector
In-Reply-To: <52A56B7F.7000305@cirad.fr>
References: <CACT+FieveiZCK7LVf29QfZ9iYWr=VyJHiM4nnK4zCiGmhaVHgQ@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED56C9B5A001@GOLD.corp.lgc-group.com>
	<52A56B7F.7000305@cirad.fr>
Message-ID: <CAAcyNCzQsJ-rQOypA4uuBZ4V6wkRuikHXqWwrkvF2YGViASQ1Q@mail.gmail.com>

Hello,

Are you looking for Y <- rep(X, X) ?

Regards,
Pascal

On 9 December 2013 16:04, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
> Dear R Users
>
> I have the vector
> X <- c( 6 , 4 ,12 , 3)
>
> I would like to build a new vector by to transform it into
> Y <- c(rep(X[1], X[1]), rep(X[2], X[2]), rep(X[3], X[3]), rep(X[4], X[4]))
>
> Have you a more elegant answer ?
>
> PS : Sorry for this basic question
>
> --
> Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From michel.arnaud at cirad.fr  Mon Dec  9 08:36:51 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Mon, 09 Dec 2013 08:36:51 +0100
Subject: [R] To transform a vector
In-Reply-To: <D5AECFB5-88E8-49B5-8816-6122BF094088@xs4all.nl>
References: <CACT+FieveiZCK7LVf29QfZ9iYWr=VyJHiM4nnK4zCiGmhaVHgQ@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED56C9B5A001@GOLD.corp.lgc-group.com>
	<52A56B7F.7000305@cirad.fr>
	<D5AECFB5-88E8-49B5-8816-6122BF094088@xs4all.nl>
Message-ID: <52A57313.9060407@cirad.fr>

Thank you
Michel
Le 09/12/2013 08:14, Berend Hasselman a ?crit :
> On 09-12-2013, at 08:04, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
>
>> Dear R Users
>>
>> I have the vector
>> X <- c( 6 , 4 ,12 , 3)
>>
>> I would like to build a new vector by to transform it into
>> Y <- c(rep(X[1], X[1]), rep(X[2], X[2]), rep(X[3], X[3]), rep(X[4], X[4]))
>>
>> Have you a more elegant answer ?
>
> Have a good read of ?rep.
>
> Try this:
>
> rep(X,times=X)
>
> Berend
>
>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From k.moon at student.unimelb.edu.au  Mon Dec  9 10:07:30 2013
From: k.moon at student.unimelb.edu.au (kmmoon100)
Date: Mon, 9 Dec 2013 01:07:30 -0800 (PST)
Subject: [R] =?utf-8?q?How_can_I_apply_=E2=80=9CSapply=E2=80=9D_in_R_with_?=
 =?utf-8?q?multiple_codes_in_one_function=3F?=
Message-ID: <1386580050366-4681852.post@n4.nabble.com>

Hello everybody,

I am a new R user..(still;;;). I have a simple "sapply" function example for
calculating mean and sd of splited data scale. My data contains half hourly
wind speed with direction. I want to know daily weibull distribution for my
study  for 13 years. That is why my dataset is splited based on time.

My data looks like this:

               Time    windspeed direction           Date	        day_index
1	24/07/2000 13:00	31	310	2000-07-24 13:00:00	2000_206
2	24/07/2000 13:30	41	320	2000-07-24 13:30:00	2000_206
3	24/07/2000 14:30	37	290	2000-07-24 14:30:00	2000_206
4	24/07/2000 15:00	30	300	2000-07-24 15:00:00	2000_206
5	24/07/2000 15:30	24	320	2000-07-24 15:30:00	2000_206
6	24/07/2000 16:00	22	330	2000-07-24 16:00:00	2000_206
7	24/07/2000 16:30	37	270	2000-07-24 16:30:00	2000_206  

The example R code I have for the split-apply to look over the days is :

my.summary <- sapply(split(ballarat_alldata[1:200, ],
ballarat_alldata$day_index[1:200]), function(x) {return(c(my.mean =
mean(x$windspeed), 
                       my.sd   = sd(x$windspeed)))})

The weibull distribution code to calculate shape and scale is:

set1 <- createSet(height=10, v.avg=ballarat_alldata[,2],
dir.avg=ballarat_alldata[,3])
time_ballarat <- strptime(ballarat_alldata[,1], "%d/%m/%Y %H:%M")
ballarat <- createMast(time.stamp=time_ballarat, set1)
ballarat <- clean(mast=ballarat)
ballarat.wb <- weibull(mast=ballarat, v.set=1, print=FALSE)

How can I combine these two set of R codes to calculate weibull parameters
each day rather than mean and sd, and store in a matrix? I tried many ways
but it doesn't work out well.. (apology to my poor understanding of R!!!)
If these two sets of R codes are combined, should I change wind speed and
direction range in "set1 <- createSet(height=10, v.avg=ballarat_alldata[,2],
dir.avg=ballarat_alldata[,3])" too?

Thank you.



--
View this message in context: http://r.789695.n4.nabble.com/How-can-I-apply-Sapply-in-R-with-multiple-codes-in-one-function-tp4681852.html
Sent from the R help mailing list archive at Nabble.com.


From vito.muggeo at unipa.it  Mon Dec  9 10:45:47 2013
From: vito.muggeo at unipa.it (Vito M. R. Muggeo)
Date: Mon, 09 Dec 2013 10:45:47 +0100
Subject: [R] growth curve estimation
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D0B90662B@EMAIL.ktkdom.pte.hu>
References: <33D76D77E9AC4B438DA38B348ED6890D0B90662B@EMAIL.ktkdom.pte.hu>
Message-ID: <52A5914B.2010107@unipa.it>

dear Daniel,
yet another package performing growth modelling is quantregGrowth. It 
uses quantile regressions with B-splines and quadratic penalties to 
ensure flexible estimation with additional noncrossing and monotonicity 
(optional) constraints.

The paper underlying the package is here:

http://link.springer.com/article/10.1007/s10651-012-0232-1

best,
vito



Il 08/12/2013 16.45, D?niel Kehl ha scritto:
> Dear Community,
>
> I am struggling with a growth curve estimation problem. It is a classic BMI change with age calculation. I am not an expert of this field but have some statistical experience in other fields.
> Of course I started reading classical papers related to the topic and understood the concept of the LMS method. After that I thought it will be a "piece of cake", R must have a package related to the topic, so I just need the data and I am just a few lines of code from the results.
>
> I encountered some problems:
> - found at least three packages related to LMS: gamlss, VGAM and an old one lmsqreg (I did not try this because it does not support my R version (3.0.1.))
> - it was relatively easy to get plots of percentiles in both packages, although they were far not the same (I also tried an other software, LMSchartmaker it gave different results from the previous ones)
> - I tried to get tables of predicted values (with the predict function in VGAM and with centiles.pre in gamlss) but without any success.
> - I tried to use the function gamlss() instead of lms() in gamlss but I could not force them to give the same (or very similar results), but the centiles.pred() function did work as expected for the model resulted from galmss()
> - lms gives really different results if k is specified different ways, which is "best"?
>
> Also I have a general question: some publications state they estimated the centiles so that aroun 18 years of age the curves pass through certain points. How is that possible?
>
> Thank you for any suggestions or insights about the methods or preferred package!
>
> Here is my code (without data):
>
> #####gamlss
> library(gamlss)
> library(VGAM)
> library(foreign)
> adatok <- read.spss("MDSZ adatok.sav", to.data.frame=TRUE)
>
> adatok_fiu <- subset(adatok, adatok$gender == "Fi??k")[,2:3]
> row.names(adatok_fiu) <- NULL
> adatok_lany <- subset(adatok, adatok$gender == "L??nyok")[,2:3]
> row.names(adatok_lany) <- NULL
>
> m1 <- lms(BMI,age,data=adatok_fiu, cent=c(3,10,25,50,75,90,97), families="BCCG")
> fittedPlot(m1, x=adatok_fiu$age)
> m1 <- lms(BMI,age,data=adatok_fiu, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC", k=log(1455))
> fittedPlot(m1, x=adatok_fiu$age)
> m1 <- lms(BMI,age,data=adatok_fiu, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC")
> fittedPlot(m1, x=adatok_fiu$age)
>
> m2 <- lms(BMI,age,data=adatok_lany, cent=c(3,10,25,50,75,90,97), families="BCCG")
> m2 <- lms(BMI,age,data=adatok_lany, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC", k=log(1144))
> m2 <- lms(BMI,age,data=adatok_lany, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC")
>
> m3 <- gamlss(BMI~age, family=BCT, data=adatok_fiu)
> centiles(m3,xvar=adatok_fiu$age, cent=c(3,10,25,50,75,90,97))
>
> newx <- seq(12,20,.5)
>
> centiles.pred(m1, xname="age", xvalues=newx)
> centiles.pred(m3, xname="age", xvalues=newx)
> centiles(m1,adatok_fiu$age)
>
> #####VGAM
> library(foreign)
> library(VGAM)
> library(VGAMdata)
>
> adatok <- read.spss("MDSZ adatok.sav", to.data.frame=TRUE)
>
> adatok_fiu <- subset(adatok, adatok$gender == "Fi??k")
> adatok_lany <- subset(adatok, adatok$gender == "L??nyok")
>
> fit1 <- vgam(BMI ~ s(age), lms.bcn(percentiles = c(3, 10, 25, 50, 75, 90, 97)), adatok_fiu)
> fit2 <- vgam(BMI ~ s(age), lms.bcn(percentiles = c(3, 10, 25, 50, 75, 90, 97)), adatok_lany)
>
> qtplot(fit1, percentiles = c(3, 10, 25, 50, 75, 90, 97), xlim = c(10.5, 20.5), ylim=c(13,34),
>         las = 1, ylab = "BMI", lcol = 4, pch=NA)
>
> qtplot(fit2, percentiles = c(3, 10, 25, 50, 75, 90, 97), xlim = c(10.5, 20.5), ylim=c(13,34),
>         las = 1, ylab = "BMI", lcol = 3, add=TRUE, pch=NA, label=FALSE)
>
>
> Thank you:
> Daniel
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
==============================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 23895240
fax: 091 485726
http://dssm.unipa.it/vmuggeo

28th IWSM
International Workshop on Statistical Modelling
July 8-12, 2013, Palermo
http://iwsm2013.unipa.it


From balu555 at gmx.de  Mon Dec  9 10:57:56 2013
From: balu555 at gmx.de (Uwe Bohne)
Date: Mon, 9 Dec 2013 10:57:56 +0100 (CET)
Subject: [R] tune an support vector machine
In-Reply-To: <trinity-ee5023de-8b36-4514-89ce-e1b0b413d4b0-1386404132570@3capp-gmx-bs43>
References: <trinity-8375f7d9-f741-497b-b4be-87454a51d780-1386335186604@3capp-gmx-bs34>,
	<CAFhv9SkGmRTm1iPBW0gyQnmg7pRs-9SxqKVYgrTpzvOkxxnKYA@mail.gmail.com>,
	<trinity-ee5023de-8b36-4514-89ce-e1b0b413d4b0-1386404132570@3capp-gmx-bs43>
Message-ID: <trinity-fb720d69-e9ce-4ec1-a9ac-295d1cf971ea-1386583076099@3capp-gmx-bs56>


   This is the solution fpr the problem.
   Its not the cleanest one i guess but it works just the way i wanted.
   If anybody has better performing or cleaner code, please send it to me.

   best regards
   Uwe

   type<-sample(c(-1,1) , 20, replace = TRUE )
   weight<-sample(c(20:50),20, replace=TRUE)
   height<-sample(c(100:200),20, replace=TRUE)
   width<-sample(c(30:50),20,replace=TRUE)
   volume<-sample(c(1000:5000),20,replace=TRUE)
   data<-cbind(type,weight,height,width,volume)
   train<-as.data.frame(data)
   train$type<-as.factor(train$type)
   library("e1071")
   features <- c("weight","height","width","volume")
   (formula<-as.formula(paste("type ~ ", paste(features, collapse= "+"))))
   svmtune=tune.svm(formula,         data=train,         kernel="radial",
   type="C-classification",cost=2^(-2:5), gamma=2^(-2:1),cross=10)
   summary(svmtune)
   
   namen<-expand.grid(c("weight",NA),
   c("height",NA),c("width",NA),c("volume",NA), stringsAsFactors=FALSE)
   l <- apply(head(namen, -1), 1, function(x)
                  reformulate(paste(na.omit(x), collapse = "+"), response =
   "type"))
   for (i in (1:(nrow(namen)-1)))
   {assign(paste("svmtune",i,sep=""),tune.svm(l[[i]],         data=train,
   kernel="radial",type="C-classification",                cost=2^(-2:1),
   gamma=2^(-2:1),cross=10))}
   for (i in (1:(nrow(namen)-1)))
   {Modell[i]<-eval(parse(text=paste("svmtune",i,"$best.performance",sep="")))}
   Modell2<-as.data.frame(Modell)
   bestesModell_Index<-which(Modell2==max(Modell2))[1]
   bestesModell_Gamma<-eval(parse(text=paste("svmtune",bestesModell_Index,"$bes
   t.parameters$gamma",sep="")))
   bestesModell_Cost<-eval(parse(text=paste("svmtune",bestesModell_Index,"$best
   .parameters$cost",sep="")))
   bestesModell_Formel<-l[[bestesModell_Index]]
   #bestesModell_Parameter
   bestesModell<-c(bestesModell_Index,bestesModell_Gamma,bestesModell_Cost,
   bestesModell_Formel)
   bestesModell_SVM<-svm(bestesModell_Formel, data=train, kernel="radial",
   gamma=bestesModell_Gamma, cost=bestesModell_Cost, type="C-classification")
   test<-data[1:10 ,]
   pred<-predict(bestesModell_SVM, test)
   test[, 1]
   pred
   table(pred, test[, 1])


   Gesendet: Samstag, 07. Dezember 2013 um 09:15 Uhr
   Von: "Uwe Bohne" <balu555 at gmx.de>
   An: "Wuming Gong" <gongx030 at umn.edu>
   Cc: "r-help mailinglist" <r-help at r-project.org>
   Betreff: Re: [R] tune an support vector machine
   Thank you very much,
   your proposal is one practical way to check for significant features.
   I tried to check for all combination in a loop, but unfortunately there is a
   problem with NA values.
   Maybe anybody has an idea.
   This is my expansion of the former code:
   namen<-expand.grid(c("weight",NA),
   c("height",NA),c("width",NA),c("volume",NA), stringsAsFactors=FALSE)
   namen2<-as.data.frame(namen)
   for(i in 1:nrow(namen2)){
   assign(paste("a", i, sep = ""), namen2[i,])
   }
   This generates vectors containing the features.
   If i pick one of them i can produce a formula that i can use for svm tuning.
   For example
   a7
   a7q<-t(as.data.frame(a7[!is.na(a7)]))
   a7q
   a7f<-as.formula(paste("type~",paste(a7q,collapse="+")))
   a7f
   and
   svmtune_a7=tune.svm(a7f, data=train, kernel="radial", cost=2^(-2:5),
   gamma=2^(-2:1),cross=10)
   works as desired.
   So my key idea was to tune SVM with every possibel "a...f" formula and
   choose the best one according to the best performance measure in the
   summary.
   Unfortunately I just have problems to make it in a loop.
   I tried
   for(iin1:nrow(namen2)){paste("a",i,"q",sep="")<-t(as.data.frame(paste("a",
   i,"[!is.na(a",i,")]", sep="")))}
   and produced error. Probably i didnt paste correctly.
   Any ideas?
   Thanks a lot!
   Uwe
   Gesendet: Samstag, 07. Dezember 2013 um 08:26 Uhr
   Von: "Wuming Gong" <gongx030 at umn.edu>
   An: "Uwe Bohne" <balu555 at gmx.de>
   Cc: "r-help mailinglist" <r-help at r-project.org>
   Betreff: Re: [R] tune an support vector machine
   Hi Uwe,
   It looks SVM in e1071 and Kernlab does not support feature selection, but
   you can take a look at package penalizedSVM
   ([1][1]http://cran.r-project.org/web/packages/penalizedSVM/penalizedSVM.pdf)
   .
   Or you can implement a SVM-RFE
   ([2][2]http://axon.cs.byu.edu/Dan/778/papers/Feature%20Selection/guyon*.pdf)
   by
   the alpha values returned by svm() in e1071 or ksvm() in Kernlab.
   Wuming
   On Fri, Dec 6, 2013 at 7:06 AM, Uwe Bohne <[3]balu555 at gmx.de> wrote:
   Hej all,
   actually i try to tune a SVM in R and use the package "e1071" wich
   works
   pretty well.
   I do some gridsearch in the parameters and get the best possible
   parameters
   for classification.
   Here is my sample code
   type<-sample(c(-1,1) , 20, replace = TRUE )
   weight<-sample(c(20:50),20, replace=TRUE)
   height<-sample(c(100:200),20, replace=TRUE)
   width<-sample(c(30:50),20,replace=TRUE)
   volume<-sample(c(1000:5000),20,replace=TRUE)
   data<-cbind(type,weight,height,width,volume)
   train<-as.data.frame(data)
   library("e1071")
   features <- c("weight","height","width","volume")
   (formula<-as.formula(paste("type ~ ", paste(features, collapse= "+"))))
   svmtune=tune.svm(formula, data=train, kernel="radial", cost=2^(-2:5),
   gamma=2^(-2:1),cross=10)
   summary(svmtune)
   My question is if there is a way to tune the features.
   So in other words - what i wanna do is to try all possible combinations
   of
   features : for example use only (volume) or use (weight, height) or use
   (height,volume,width) and so on for the SVM and to get the best
   combination
   back.
   Best wishes
   Uwe
   ______________________________________________
   [4]R-help at r-project.org mailing list
   [5][3]https://stat.ethz.ch/mailman/listinfo/r-help
   PLEASE do read the posting guide
   [6][4]http://www.R-project.org/posting-guide.html
   and provide commented, minimal, self-contained, reproducible code.
   References
   1. [5]http://cran.r-project.org/web/packages/penalizedSVM/penalizedSVM.pdf
   2. [6]http://axon.cs.byu.edu/Dan/778/papers/Feature%20Selection/guyon*.pdf
   3. file://localhost/tmp/balu555 at gmx.de
   4. file://localhost/tmp/R-help at r-project.org
   5. [7]https://stat.ethz.ch/mailman/listinfo/r-help
   6. [8]http://www.R-project.org/posting-guide.html
   ______________________________________________
   R-help at r-project.org mailing list
   [9]https://stat.ethz.ch/mailman/listinfo/r-help
   PLEASE do read the posting guide
   [10]http://www.R-project.org/posting-guide.html
   and provide commented, minimal, self-contained, reproducible code.

References

   1. http://cran.r-project.org/web/packages/penalizedSVM/penalizedSVM.pdf
   2. http://axon.cs.byu.edu/Dan/778/papers/Feature%20Selection/guyon*.pdf)by
   3. https://stat.ethz.ch/mailman/listinfo/r-help
   4. http://www.R-project.org/posting-guide.html
   5. http://cran.r-project.org/web/packages/penalizedSVM/penalizedSVM.pdf
   6. http://axon.cs.byu.edu/Dan/778/papers/Feature%20Selection/guyon*.pdf
   7. https://stat.ethz.ch/mailman/listinfo/r-help
   8. http://www.R-project.org/posting-guide.html
   9. https://stat.ethz.ch/mailman/listinfo/r-help
  10. http://www.R-project.org/posting-guide.html

From maechler at stat.math.ethz.ch  Mon Dec  9 11:36:04 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 9 Dec 2013 11:36:04 +0100
Subject: [R] Why daisy() in cluster library failed to exclude NA
	when	computing dissimilarity
In-Reply-To: <CADVKSzyEaJRNgPCBYQTpPL=7QK+Kw2YrrQrfaJtfdxs303Jivg@mail.gmail.com>
References: <CADVKSzyEaJRNgPCBYQTpPL=7QK+Kw2YrrQrfaJtfdxs303Jivg@mail.gmail.com>
Message-ID: <21157.40212.340205.578669@stat.math.ethz.ch>

>>>>> Gundala Viswanath <gundalav at gmail.com>
>>>>>     on Sun, 8 Dec 2013 16:11:12 +0900 writes:

    > Hi, According to daisy function from cluster
    > documentation, it can compute dissimilarity when NA
    > (missing) value(s) is present.

    > http://stat.ethz.ch/R-manual/R-devel/library/cluster/html/daisy.html

    > But why when I tried this code

    > library(cluster)
    > x <- c(1.115,NA,NA,0.971,NA)
    > y <- c(NA,1.006,NA,NA,0.645)
    > df <- as.data.frame(rbind(x,y))
    > daisy(df,metric="gower")

    > It gave this message:

    > Dissimilarities :
    > x
    > y NA

    > Metric :  mixed ;  Types = I, I, I, I, I
    > Number of objects : 2
    > Warning messages:
    > 1: In min(x) : no non-missing arguments to min; returning Inf
    > 2: In max(x) : no non-missing arguments to max; returning -Inf

    > I welcome other alternative than gower.

    > I expect the dissimilarity output gives a non-NA value e.g. 0. What's
    > the right way to do it?

Thank you, Gundala, for using a simple reproducible example.

Reading the documentation about Gower's distance a bit more,
you'd have found that it works by basically giving weight zero
to *pairs* of variable values where one of the two values is
missing.

In situations like yours, *all* pairs have at least one missing,
so there's no way to get a non-NA distance.

*AND* the documentation already contains  this, at the very end
 of the section 'Details' :

  If all weights w_k delta(ij;k) are zero, the dissimilarity is set to ?NA?.

I.e., we have

> install.packages("fortunes")
> fortune("WTFM")

This is all documented in TFM. Those who WTFM don't want to have to WTFM again
on the mailing list. RTFM.
   -- Barry Rowlingson
      R-help (October 2003)

... which I now did in spite of Barry's excellent point
... let's say it's because of approaching Christmas !

Martin Maechler,
ETH Zurich


From ajmackey at gmail.com  Mon Dec  9 14:39:38 2013
From: ajmackey at gmail.com (Aaron Mackey)
Date: Mon, 9 Dec 2013 14:39:38 +0100
Subject: [R] combine glmnet and coxph (and survfit) with strata()
In-Reply-To: <CALYjA0TFu68tRPyJxGOUg8kMAvQ1Rsdb0Hbo4tA3=Coah_7gjA@mail.gmail.com>
References: <CALYjA0TFu68tRPyJxGOUg8kMAvQ1Rsdb0Hbo4tA3=Coah_7gjA@mail.gmail.com>
Message-ID: <CAErFSogKSO6kbqpYpzRmd+5r3jf5oC2oPVPdezx0Jo_CanrTqg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/02ccb1f7/attachment.pl>

From adelessafi at gmail.com  Mon Dec  9 15:19:28 2013
From: adelessafi at gmail.com (Adel ESSAFI)
Date: Mon, 9 Dec 2013 15:19:28 +0100
Subject: [R] multiple bar for barchart
Message-ID: <CAF=-T0h+n8zARj4Ue2uctL3xpZN+UH+qsH3pH2bqORkjJJKwUw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/e32dfc59/attachment.pl>

From soerengroettrup at web.de  Mon Dec  9 14:49:42 2013
From: soerengroettrup at web.de (Soeren Groettrup)
Date: Mon, 09 Dec 2013 14:49:42 +0100
Subject: [R] notch filter in R
Message-ID: <52A5CA76.5060905@web.de>

Hi everybody,

I am dealing with a time series of eeg data and I need to filter them 
with a notch filter. However, I could only find the function notch() in 
the RTisean package. Unfortunately, this function is not implemented 
yet. Is there another package/function in R which performs such a filtering?

Thanks in advance for your help.

With best regards,

Soeren Groettrup


From bretschr at xs4all.nl  Mon Dec  9 15:48:57 2013
From: bretschr at xs4all.nl (Bretschneider (R))
Date: Mon, 9 Dec 2013 15:48:57 +0100
Subject: [R] notch filter in R
In-Reply-To: <52A5CA76.5060905@web.de>
References: <52A5CA76.5060905@web.de>
Message-ID: <772D51DB-0591-481F-AFFA-12A4BC5524D6@xs4all.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/0bec54f2/attachment.pl>

From rmh at temple.edu  Mon Dec  9 16:13:36 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 9 Dec 2013 10:13:36 -0500
Subject: [R] multiple bar for barchart
In-Reply-To: <CAF=-T0h+n8zARj4Ue2uctL3xpZN+UH+qsH3pH2bqORkjJJKwUw@mail.gmail.com>
References: <CAF=-T0h+n8zARj4Ue2uctL3xpZN+UH+qsH3pH2bqORkjJJKwUw@mail.gmail.com>
Message-ID: <CAGx1TMDVoh6tt_o5tnJeY_5vzsi8aW1WktSqSrvw9Bu_5GfgVQ@mail.gmail.com>

Start here

dm <- read.table(text="
   Group.1 V1   V2      V3        V4         V5      V6      V7         V8
1      C/L NA 15.5  732179  875270.6 -143091.46 1107270 1088300   18964.40
2      C/S NA 15.5  803926  850352.1  -46426.03 1395710 1312310   83403.30
3      D/D NA 15.5  751660  857828.2 -106168.17 1340360 1322790   17569.30
4      D/F NA 15.5  724924  969418.7 -244494.67 1181280 1160760   20519.20
5      D/I NA 15.5  755841  842130.5  -86289.48 1264250 1241750   22495.20
6      D/L NA 15.5  731904  875340.0 -143435.84 1107600 1087940   19657.30
7      D/S NA 15.5  798289  844102.0  -45812.85 1399840 1305000   94832.10
8      I/F NA 15.5  871670 1074136.3 -202466.58 1304290 1249006   55286.59
9      I/I NA 15.5  897718 1029579.0 -131861.35 1542810 1398716  144100.07
10     I/L NA 15.5 2628110  862466.8 1765645.67 2628110 1073510 1554610.00
11     I/S NA 15.5 2628110  831486.8 1796627.33 2475450 1282100 1193350.00
", header=TRUE)

library(reshape)
dm.melt <- melt(dm[,c(1,4,5,6,7)], id="Group.1")
barchart(value ~ variable | Group.1, data=dm.melt, origin=0)


On Mon, Dec 9, 2013 at 9:19 AM, Adel ESSAFI <adelessafi at gmail.com> wrote:
> Hello list,
> I have the following data on "dm" table
>
>> dm
>    Group.1 V1   V2      V3        V4         V5      V6      V7         V8
> 1      C/L NA 15.5  732179  875270.6 -143091.46 1107270 1088300   18964.40
> 2      C/S NA 15.5  803926  850352.1  -46426.03 1395710 1312310   83403.30
> 3      D/D NA 15.5  751660  857828.2 -106168.17 1340360 1322790   17569.30
> 4      D/F NA 15.5  724924  969418.7 -244494.67 1181280 1160760   20519.20
> 5      D/I NA 15.5  755841  842130.5  -86289.48 1264250 1241750   22495.20
> 6      D/L NA 15.5  731904  875340.0 -143435.84 1107600 1087940   19657.30
> 7      D/S NA 15.5  798289  844102.0  -45812.85 1399840 1305000   94832.10
> 8      I/F NA 15.5  871670 1074136.3 -202466.58 1304290 1249006   55286.59
> 9      I/I NA 15.5  897718 1029579.0 -131861.35 1542810 1398716  144100.07
> 10     I/L NA 15.5 2628110  862466.8 1765645.67 2628110 1073510 1554610.00
> 11     I/S NA 15.5 2628110  831486.8 1796627.33 2475450 1282100 1193350.00
>> barchart (dm[,4] ~ dm[,1])
>
> For each value of Group.1 I want to draw 4 bars (v3,v4, v6 and v7).
>
> Can you suggest me a solution please
>
> barchat draws only one value.
> regards
>
>
>
> --
> PhD candidate in Computer Science
> Address
> 3 avenue lamine, cit? ezzahra, Sousse 4000
> Tunisia
> tel: +216 97 246 706 (+33640302046 jusqu'au 15/6)
> fax: +216 71 391 166
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Mon Dec  9 16:23:01 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 9 Dec 2013 15:23:01 +0000
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <CAEN-PDBrJ=ST-Z8Vt8t2-PHdxgZ8VHyLZvjqM_YH+RGLW+SCqw@mail.gmail.com>
References: <52A1F0D6.9080108@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA52E5@SRVEXCHMBX.precheza.cz>
	<52A1F729.9070302@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5408@SRVEXCHMBX.precheza.cz>
	<CAEN-PDBrJ=ST-Z8Vt8t2-PHdxgZ8VHyLZvjqM_YH+RGLW+SCqw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5A8F@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/b224f59b/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Mon Dec  9 17:05:24 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 09 Dec 2013 08:05:24 -0800
Subject: [R]
	=?utf-8?q?How_can_I_apply_=E2=80=9CSapply=E2=80=9D_in_R_with_?=
	=?utf-8?q?multiple_codes_in_one_function=3F?=
In-Reply-To: <1386580050366-4681852.post@n4.nabble.com>
References: <1386580050366-4681852.post@n4.nabble.com>
Message-ID: <e160afa5-80a7-48a9-8145-d8371b2b1260@email.android.com>

There is a no-homework policy on this mailing list (see the Posting Guide mentioned at the bottom of every email). If this is not assigned homework then at the very least you need to understand R and your problem well enough to provide a reproducible example [1] before we can communicate about your problem on this list.

As a start, you should be able to execute each line of each of your examples one at a time. R is interactive and scriptable, so you can always give one line at a time to to R and examine the results. Some results may be printed to the console and then forgotten, while others are stored in objects for use in subsequent lines of code. Try reading and following along with the Introduction to R document that comes with R to learn how R works.

If you do all this, you should come to understand that most of the code in your weibull example seems to be about cleaning up the input data in memory, but I don't know where the functions it references are so you need to get more input from whoever supplied the example about how to use it. It may be as simple as loading a package at the beginning of the code. You would not normally clean the data repeatedly, so most of that code should probably precede your use of sapply.

The weibull function returns an object, and your example code just prints it and discards it. If you want to transfer information from that object into a vector that sapply can bind with a bunch of other vectors to make a matrix, then you will have to assign it into an object and extract those values one at a time as you create that vector.

I highly recommend using the str function on the various objects created by each line of example code at the R console in between execution of the example lines. Use the help facility to learn more:

?str

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

kmmoon100 <k.moon at student.unimelb.edu.au> wrote:
>Hello everybody,
>
>I am a new R user..(still;;;). I have a simple "sapply" function
>example for
>calculating mean and sd of splited data scale. My data contains half
>hourly
>wind speed with direction. I want to know daily weibull distribution
>for my
>study  for 13 years. That is why my dataset is splited based on time.
>
>My data looks like this:
>
>           Time    windspeed direction           Date	        day_index
>1	24/07/2000 13:00	31	310	2000-07-24 13:00:00	2000_206
>2	24/07/2000 13:30	41	320	2000-07-24 13:30:00	2000_206
>3	24/07/2000 14:30	37	290	2000-07-24 14:30:00	2000_206
>4	24/07/2000 15:00	30	300	2000-07-24 15:00:00	2000_206
>5	24/07/2000 15:30	24	320	2000-07-24 15:30:00	2000_206
>6	24/07/2000 16:00	22	330	2000-07-24 16:00:00	2000_206
>7	24/07/2000 16:30	37	270	2000-07-24 16:30:00	2000_206  
>
>The example R code I have for the split-apply to look over the days is
>:
>
>my.summary <- sapply(split(ballarat_alldata[1:200, ],
>ballarat_alldata$day_index[1:200]), function(x) {return(c(my.mean =
>mean(x$windspeed), 
>                       my.sd   = sd(x$windspeed)))})
>
>The weibull distribution code to calculate shape and scale is:
>
>set1 <- createSet(height=10, v.avg=ballarat_alldata[,2],
>dir.avg=ballarat_alldata[,3])
>time_ballarat <- strptime(ballarat_alldata[,1], "%d/%m/%Y %H:%M")
>ballarat <- createMast(time.stamp=time_ballarat, set1)
>ballarat <- clean(mast=ballarat)
>ballarat.wb <- weibull(mast=ballarat, v.set=1, print=FALSE)
>
>How can I combine these two set of R codes to calculate weibull
>parameters
>each day rather than mean and sd, and store in a matrix? I tried many
>ways
>but it doesn't work out well.. (apology to my poor understanding of
>R!!!)
>If these two sets of R codes are combined, should I change wind speed
>and
>direction range in "set1 <- createSet(height=10,
>v.avg=ballarat_alldata[,2],
>dir.avg=ballarat_alldata[,3])" too?
>
>Thank you.
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/How-can-I-apply-Sapply-in-R-with-multiple-codes-in-one-function-tp4681852.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Dec  9 17:21:25 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 9 Dec 2013 16:21:25 +0000
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <52A5E390.4090106@gmail.com>
References: <52A1F0D6.9080108@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA52E5@SRVEXCHMBX.precheza.cz>
	<52A1F729.9070302@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5408@SRVEXCHMBX.precheza.cz>
	<CAEN-PDBrJ=ST-Z8Vt8t2-PHdxgZ8VHyLZvjqM_YH+RGLW+SCqw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5A8F@SRVEXCHMBX.precheza.cz>
	<52A5E390.4090106@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5B2D@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/a427aee7/attachment.pl>

From michael.lang at tum.de  Mon Dec  9 11:14:43 2013
From: michael.lang at tum.de (Mike.lang)
Date: Mon, 9 Dec 2013 02:14:43 -0800 (PST)
Subject: [R] GAM Assumption Tests
In-Reply-To: <Pine.LNX.4.44.1312051148520.29463-100000@hydrogen.cs.pitt.edu>
References: <1386234932688-4681670.post@n4.nabble.com>
	<Pine.LNX.4.44.1312051148520.29463-100000@hydrogen.cs.pitt.edu>
Message-ID: <1386584083659-4681857.post@n4.nabble.com>

it's a pity, but thanks anyway! 



--
View this message in context: http://r.789695.n4.nabble.com/GAM-Assumption-Tests-tp4681670p4681857.html
Sent from the R help mailing list archive at Nabble.com.


From jmacdon at uw.edu  Mon Dec  9 15:57:18 2013
From: jmacdon at uw.edu (James W. MacDonald)
Date: Mon, 09 Dec 2013 09:57:18 -0500
Subject: [R] [BioC] Why daisy() in cluster library failed to exclude NA
 when computing dissimilarity
In-Reply-To: <CADVKSzyEaJRNgPCBYQTpPL=7QK+Kw2YrrQrfaJtfdxs303Jivg@mail.gmail.com>
References: <CADVKSzyEaJRNgPCBYQTpPL=7QK+Kw2YrrQrfaJtfdxs303Jivg@mail.gmail.com>
Message-ID: <52A5DA4E.2020104@uw.edu>

Hi Gundala,

This question isn't about a Bioconductor package, so should be asked on 
R-help instead.

Best,

Jim

On Sunday, December 08, 2013 2:11:12 AM, Gundala Viswanath wrote:
> Hi,
>
>
> According to daisy function from cluster documentation, it can compute
> dissimilarity when NA (missing) value(s) is present.
>
> http://stat.ethz.ch/R-manual/R-devel/library/cluster/html/daisy.html
>
> But why when I tried this code
>
> library(cluster)
> x <- c(1.115,NA,NA,0.971,NA)
> y <- c(NA,1.006,NA,NA,0.645)
> df <- as.data.frame(rbind(x,y))
> daisy(df,metric="gower")
>
> It gave this message:
>
> Dissimilarities :
>     x
> y NA
>
> Metric :  mixed ;  Types = I, I, I, I, I
> Number of objects : 2
> Warning messages:
> 1: In min(x) : no non-missing arguments to min; returning Inf
> 2: In max(x) : no non-missing arguments to max; returning -Inf
>
> I welcome other alternative than gower.
>
> I expect the dissimilarity output gives a non-NA value e.g. 0. What's
> the right way to do it?
>
> G.V.
>
> _______________________________________________
> Bioconductor mailing list
> Bioconductor at r-project.org
> https://stat.ethz.ch/mailman/listinfo/bioconductor
> Search the archives: http://news.gmane.org/gmane.science.biology.informatics.conductor

--
James W. MacDonald, M.S.
Biostatistician
University of Washington
Environmental and Occupational Health Sciences
4225 Roosevelt Way NE, # 100
Seattle WA 98105-6099


From indrajitsg2013 at gmail.com  Mon Dec  9 17:33:32 2013
From: indrajitsg2013 at gmail.com (Indrajit Sengupta)
Date: Mon, 9 Dec 2013 22:03:32 +0530
Subject: [R] Problem with Barplots on Map
Message-ID: <CA+Lnj2uWmyfAcU_vK=LKD=x=RfbvEXeOmT8Y2=F+rKxK-VLwnQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/fadee523/attachment.pl>

From wandrson01 at gmail.com  Mon Dec  9 17:47:17 2013
From: wandrson01 at gmail.com (Walter Anderson)
Date: Mon, 09 Dec 2013 10:47:17 -0600
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5B2D@SRVEXCHMBX.precheza.cz>
References: <52A1F0D6.9080108@gmail.com>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA52E5@SRVEXCHMBX.precheza.cz>	<52A1F729.9070302@gmail.com>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5408@SRVEXCHMBX.precheza.cz>
	<CAEN-PDBrJ=ST-Z8Vt8t2-PHdxgZ8VHyLZvjqM_YH+RGLW+SCqw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5A8F@SRVEXCHMBX.precheza.cz>
	<52A5E390.4090106@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5B2D@SRVEXCHMBX.precheza.cz>
Message-ID: <52A5F415.8050500@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/caf1410b/attachment.pl>

From r.rigby at londonmet.ac.uk  Mon Dec  9 18:57:04 2013
From: r.rigby at londonmet.ac.uk (Robert Rigby)
Date: Mon, 9 Dec 2013 17:57:04 +0000
Subject: [R] growth curve estimation
Message-ID: <CAKmh6oG2c-L0JVXSTbwjNUnrOjmDC4mEw9zf5eyDnAHtC0zfyQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/a30b6a1e/attachment.pl>

From manzhang at ymail.com  Mon Dec  9 19:25:34 2013
From: manzhang at ymail.com (Man Zhang)
Date: Mon, 9 Dec 2013 10:25:34 -0800 (PST)
Subject: [R] Model selection exponential and gamma distribution using cross
	validation
Message-ID: <1386613534.74197.YahooMailNeo@web125804.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/3100df88/attachment.pl>

From jieyueli82 at gmail.com  Mon Dec  9 19:36:38 2013
From: jieyueli82 at gmail.com (Jieyue Li)
Date: Mon, 9 Dec 2013 10:36:38 -0800
Subject: [R] combine glmnet and coxph (and survfit) with strata()
In-Reply-To: <CAErFSogKSO6kbqpYpzRmd+5r3jf5oC2oPVPdezx0Jo_CanrTqg@mail.gmail.com>
References: <CALYjA0TFu68tRPyJxGOUg8kMAvQ1Rsdb0Hbo4tA3=Coah_7gjA@mail.gmail.com>
	<CAErFSogKSO6kbqpYpzRmd+5r3jf5oC2oPVPdezx0Jo_CanrTqg@mail.gmail.com>
Message-ID: <CALYjA0Q7RavnuJR5G8H46bJDSO_s8S_4uEJzQPuM3aV9qJ66iw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/762cee54/attachment.pl>

From elham.shaarbaf at gmail.com  Mon Dec  9 18:58:31 2013
From: elham.shaarbaf at gmail.com (Elham Shaarbaf)
Date: Mon, 9 Dec 2013 21:28:31 +0330
Subject: [R] (no subject)
Message-ID: <CAD-W18DWpz_r2XR3Xe2db_tsAae00boNO9YmCFUzm5iqwtDTGw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/bcf3b21f/attachment.pl>

From lefebvrf at gmail.com  Mon Dec  9 19:28:12 2013
From: lefebvrf at gmail.com (=?ISO-8859-1?Q?Fran=E7ois_Lefebvre?=)
Date: Mon, 9 Dec 2013 13:28:12 -0500
Subject: [R] roxygen2 and install.packages()
Message-ID: <CAPZGMX=evXdZ+DN4811zZOXjir6Ph81jvqZNce4hs4qHqFfxfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/f1b8f7a1/attachment.pl>

From u99802003 at cc.kmu.edu.tw  Mon Dec  9 18:46:56 2013
From: u99802003 at cc.kmu.edu.tw (celebrex)
Date: Mon, 9 Dec 2013 09:46:56 -0800 (PST)
Subject: [R] How to use multiple test for trend in proportions?
Message-ID: <1386611216718-4681879.post@n4.nabble.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/6a4000c3/attachment.pl>

From kw.stat at gmail.com  Mon Dec  9 19:45:33 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 9 Dec 2013 12:45:33 -0600
Subject: [R] (no subject)
In-Reply-To: <CAD-W18DWpz_r2XR3Xe2db_tsAae00boNO9YmCFUzm5iqwtDTGw@mail.gmail.com>
References: <CAD-W18DWpz_r2XR3Xe2db_tsAae00boNO9YmCFUzm5iqwtDTGw@mail.gmail.com>
Message-ID: <CAKFxdiTwovV8EaBtnyi_jWHWZAnLxCUTKDpLwWyhfoE5m9geqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/0ddaa3d4/attachment.pl>

From h.wickham at gmail.com  Mon Dec  9 19:47:23 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 9 Dec 2013 12:47:23 -0600
Subject: [R] roxygen2 and install.packages()
In-Reply-To: <CAPZGMX=evXdZ+DN4811zZOXjir6Ph81jvqZNce4hs4qHqFfxfg@mail.gmail.com>
References: <CAPZGMX=evXdZ+DN4811zZOXjir6Ph81jvqZNce4hs4qHqFfxfg@mail.gmail.com>
Message-ID: <CABdHhvE9qE12WW+kYnpvyDAicX+ef98op9ee1qc1PL0a6U8Z4Q@mail.gmail.com>

Unfortunately roxygen2 3.0.0 now requires R 3.0.2. See
https://github.com/klutometis/roxygen/issues/163 for some discussion
as to why.

Hadley

On Mon, Dec 9, 2013 at 12:28 PM, Fran?ois Lefebvre <lefebvrf at gmail.com> wrote:
> Hi, I am unable to install roxygen2 on R<3.0.2. Any idea why?
>
>
>
>> install.packages("roxygen2")
> Installing package into
> ?/home/lefebvr3/R/x86_64-unknown-linux-gnu-library/3.0?
> (as ?lib? is unspecified)
> Warning message:
> package ?roxygen2? is not available (for R version 3.0.1)
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>  [7] LC_PAPER=C                 LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.1
>
>
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
http://had.co.nz/


From david at revolutionanalytics.com  Mon Dec  9 19:59:05 2013
From: david at revolutionanalytics.com (David Smith)
Date: Mon, 9 Dec 2013 10:59:05 -0800
Subject: [R] Revolutions blog: November roundup
Message-ID: <CABgvEC9VSz7-3xjN141q7pGBj_Nw3uLNhnw+3nQx++xzzKAP3Q@mail.gmail.com>

Revolution Analytics staff write about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of November:

A recap of the Strata Hadoop World conference, including presentations
from Monsanto and eHarmony on their use of R: http://bit.ly/1gTdWDy

How to rank and chart the most frequent hashtags of Twitter users with
R: http://bit.ly/1gTdYeo

What?s new in Revolution R Enterprise 7 (webinar replay): http://bit.ly/1gTdWDz

Using Plotly?s new interface with R, plus reports from R user groups:
http://bit.ly/1gTdYep

An analysis of World Series Baseball strikeout rates using R:
http://bit.ly/1gTdWDA

CRAN surpasses the milestone of 5,000 R packages, thanks to the
volunteers who maintain the system: http://bit.ly/1gTdYeq

A detailed guide to memory usage in R, from Hadley Wickham:
http://bit.ly/1gTdYer

Running R inside Teradata Database with Revolution R Enterprise
(webinar replay): http://bit.ly/1gTdWDB

The Human Rights Data Analysis Group uses R to estimate the number of
casualties in Syria: http://bit.ly/1gTdWTO

Data Scientists coming from computer science backgrounds can learn
from the small-data techniques of Statistics ? even with Big Data:
http://bit.ly/1gTdYes

A tutorial on using iterators in R: http://bit.ly/1gTdYet

A Princeton University guide translates common Stata commands into R
code: http://bit.ly/1gTdYeu

Joseph Rickert surveys the available packages for Bayesian analysis
with R: http://bit.ly/1gTdWTS

In an interview with DataInformed, I discussed the rise of R as the
lingua franca of data science, and how the Big Data revolution has led
companies to adopt statistical decision making: http://bit.ly/1gTdYev

DataMind?s www.r-fiddle.org is an online scratchpad GUI for R
programmers: http://bit.ly/1gTdWTU

The new RFacebook package makes it possible to download and analyze
your Facebook social network: http://bit.ly/1gTdYey

R connections to startups Domino, Plotly and Quandl: http://bit.ly/1gTdWTW

A Thanksgiving greeting from Revolution Analytics (with an assist from
the cowsay package): http://bit.ly/1gTdYeA

Some non-R stories in the past month included: Virgin?s safety dance
(http://bit.ly/1gTdYez), a mouse perseveres (http://bit.ly/1gTdWTY),
sonification of sorting algorithms (http://bit.ly/1gTdYeB), a marked
rise in data scientist job postings (http://bit.ly/1gTdYeC), real-life
Mario (http://bit.ly/1gTdWTZ), and comet ISON rounds the sun
(http://bit.ly/1gTdWU0).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com . Don't forget you can also
follow the blog using an RSS reader, or by following me on Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
VP of Marketing, Revolution Analytics  http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Seattle WA, USA)
Twitter: @revodavid
We're hiring! www.revolutionanalytics.com/careers


From jdnewmil at dcn.davis.CA.us  Mon Dec  9 19:59:29 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 09 Dec 2013 10:59:29 -0800
Subject: [R] roxygen2 and install.packages()
In-Reply-To: <CAPZGMX=evXdZ+DN4811zZOXjir6Ph81jvqZNce4hs4qHqFfxfg@mail.gmail.com>
References: <CAPZGMX=evXdZ+DN4811zZOXjir6Ph81jvqZNce4hs4qHqFfxfg@mail.gmail.com>
Message-ID: <20a01d92-f942-4e73-9eea-732625a0df82@email.android.com>

The package specifies it. Either because the package author has used some feature that is only available in that version, or he did not test it in any earlier version. You can contact the maintainer (?maintainer) or try modifying the package dependencies and finding out yourself if it is a real problem. Or, you could upgrade to the current version of R...
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"Fran?ois Lefebvre" <lefebvrf at gmail.com> wrote:
>Hi, I am unable to install roxygen2 on R<3.0.2. Any idea why?
>
>
>
>> install.packages("roxygen2")
>Installing package into
>?/home/lefebvr3/R/x86_64-unknown-linux-gnu-library/3.0?
>(as ?lib? is unspecified)
>Warning message:
>package ?roxygen2? is not available (for R version 3.0.1)
>> sessionInfo()
>R version 3.0.1 (2013-05-16)
>Platform: x86_64-unknown-linux-gnu (64-bit)
>
>locale:
> [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
> [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
> [7] LC_PAPER=C                 LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>loaded via a namespace (and not attached):
>[1] tools_3.0.1
>
>
>
>Thank you.
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From motyocska at yahoo.com  Mon Dec  9 21:27:03 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Mon, 9 Dec 2013 12:27:03 -0800 (PST)
Subject: [R] data frame question
Message-ID: <1386620823.59554.YahooMailNeo@web161605.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/0511e01f/attachment.pl>

From dwinsemius at comcast.net  Mon Dec  9 21:40:33 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 9 Dec 2013 12:40:33 -0800
Subject: [R] growth curve estimation
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D0B90662B@EMAIL.ktkdom.pte.hu>
References: <33D76D77E9AC4B438DA38B348ED6890D0B90662B@EMAIL.ktkdom.pte.hu>
Message-ID: <18A873B2-92FE-461A-8713-DCDE4213CB4F@comcast.net>


On Dec 8, 2013, at 7:45 AM, D?niel Kehl wrote:

> Dear Community,
> 
> I am struggling with a growth curve estimation problem. It is a classic BMI change with age calculation. I am not an expert of this field but have some statistical experience in other fields.
> Of course I started reading classical papers related to the topic and understood the concept of the LMS method. After that I thought it will be a "piece of cake", R must have a package related to the topic, so I just need the data and I am just a few lines of code from the results.
> 

You might want to look at a more recent discussion:

http://www.who.int/entity/childgrowth/standards/velocity/tr3chap_2.pdf

(The WHO centre has published their R code.)


> I encountered some problems:
> - found at least three packages related to LMS: gamlss, VGAM and an old one lmsqreg (I did not try this because it does not support my R version (3.0.1.))
> - it was relatively easy to get plots of percentiles in both packages, although they were far not the same (I also tried an other software, LMSchartmaker it gave different results from the previous ones)
> - I tried to get tables of predicted values (with the predict function in VGAM and with centiles.pre in gamlss) but without any success.

Don't see any code or error messages.

> - I tried to use the function gamlss() instead of lms() in gamlss but I could not force them to give the same (or very similar results), but the centiles.pred() function did work as expected for the model resulted from galmss()
> - lms gives really different results if k is specified different ways, which is "best"?

Won't that depend on the amount and distribution of the data?

> 
> Also I have a general question: some publications state they estimated the centiles so that aroun 18 years of age the curves pass through certain points. How is that possible?
> 
> Thank you for any suggestions or insights about the methods or preferred package!
> 
> Here is my code (without data):
> 
> #####gamlss
> library(gamlss)
> library(VGAM)
> library(foreign)
> adatok <- read.spss("MDSZ adatok.sav", to.data.frame=TRUE)
> 
> adatok_fiu <- subset(adatok, adatok$gender == "Fi?k")[,2:3]
> row.names(adatok_fiu) <- NULL
> adatok_lany <- subset(adatok, adatok$gender == "L?nyok")[,2:3]
> row.names(adatok_lany) <- NULL
> 
> m1 <- lms(BMI,age,data=adatok_fiu, cent=c(3,10,25,50,75,90,97), families="BCCG")
> fittedPlot(m1, x=adatok_fiu$age)
> m1 <- lms(BMI,age,data=adatok_fiu, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC", k=log(1455))
> fittedPlot(m1, x=adatok_fiu$age)
> m1 <- lms(BMI,age,data=adatok_fiu, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC")
> fittedPlot(m1, x=adatok_fiu$age)
> 
> m2 <- lms(BMI,age,data=adatok_lany, cent=c(3,10,25,50,75,90,97), families="BCCG")
> m2 <- lms(BMI,age,data=adatok_lany, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC", k=log(1144))
> m2 <- lms(BMI,age,data=adatok_lany, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC")
> 
> m3 <- gamlss(BMI~age, family=BCT, data=adatok_fiu)
> centiles(m3,xvar=adatok_fiu$age, cent=c(3,10,25,50,75,90,97))
> 
> newx <- seq(12,20,.5)
> 
> centiles.pred(m1, xname="age", xvalues=newx)
> centiles.pred(m3, xname="age", xvalues=newx)
> centiles(m1,adatok_fiu$age)
> 
> #####VGAM
> library(foreign)
> library(VGAM)
> library(VGAMdata)
> 
> adatok <- read.spss("MDSZ adatok.sav", to.data.frame=TRUE)
> 
> adatok_fiu <- subset(adatok, adatok$gender == "Fi?k")
> adatok_lany <- subset(adatok, adatok$gender == "L?nyok")
> 
> fit1 <- vgam(BMI ~ s(age), lms.bcn(percentiles = c(3, 10, 25, 50, 75, 90, 97)), adatok_fiu)
> fit2 <- vgam(BMI ~ s(age), lms.bcn(percentiles = c(3, 10, 25, 50, 75, 90, 97)), adatok_lany)
> 
> qtplot(fit1, percentiles = c(3, 10, 25, 50, 75, 90, 97), xlim = c(10.5, 20.5), ylim=c(13,34),
>       las = 1, ylab = "BMI", lcol = 4, pch=NA)
> 
> qtplot(fit2, percentiles = c(3, 10, 25, 50, 75, 90, 97), xlim = c(10.5, 20.5), ylim=c(13,34),
>       las = 1, ylab = "BMI", lcol = 3, add=TRUE, pch=NA, label=FALSE)
> 
> 
> Thank you:
> Daniel
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From wandrson01 at gmail.com  Mon Dec  9 21:40:39 2013
From: wandrson01 at gmail.com (Walter Anderson)
Date: Mon, 09 Dec 2013 14:40:39 -0600
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <CAK_OPMJeH6BFobu9rLFFf4OmC4APnD4tAc549BM-8H9BFWVHtA@mail.gmail.com>
References: <52A1F0D6.9080108@gmail.com>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA52E5@SRVEXCHMBX.precheza.cz>	<52A1F729.9070302@gmail.com>
	<CAK_OPMJeH6BFobu9rLFFf4OmC4APnD4tAc549BM-8H9BFWVHtA@mail.gmail.com>
Message-ID: <52A62AC7.8080901@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/b912b56c/attachment.pl>

From sarah.goslee at gmail.com  Mon Dec  9 21:45:00 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 9 Dec 2013 15:45:00 -0500
Subject: [R] data frame question
In-Reply-To: <1386620823.59554.YahooMailNeo@web161605.mail.bf1.yahoo.com>
References: <1386620823.59554.YahooMailNeo@web161605.mail.bf1.yahoo.com>
Message-ID: <CAM_vjumgXti0QcH24Wi2uLYrRgk=_omAVrnbRjAwz0+jaNOwdw@mail.gmail.com>

Thank you for providing a reproducible example. I tweaked it a little
bit to make it actually a data frame problem.

There are lots of ways to do this; here's one approach.

On second thought, this looks a lot like homework, so perhaps instead
I'll just suggest using subset() with more than one condition.

Sarah

On Mon, Dec 9, 2013 at 3:27 PM, Andras Farkas <motyocska at yahoo.com> wrote:
> Dear All
>
> please help with the following:
>
> I have:
>
> a <-seq(0,10,by=1)
> b <-c(10:20)
> d <-cbind(a,b)
> f <-16
>
> I would like to select the value in column a based on a value in column b, where the value in column b is the 1st value that is smaller then f. Thus I should end up with the number 5 because the 1st value that is below 16 would be 15, and in the same row column a has the number 5....
>
> appreciate your insights,
>
> andras

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Mon Dec  9 21:49:46 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 9 Dec 2013 15:49:46 -0500
Subject: [R] How to perform clustering without removing rows where NA is
 present in R
In-Reply-To: <CADVKSzyppiYTi-8+fjf6XDSdQje-9aw-zjZqFY2UNv+OBUXcBA@mail.gmail.com>
References: <CADVKSzyppiYTi-8+fjf6XDSdQje-9aw-zjZqFY2UNv+OBUXcBA@mail.gmail.com>
Message-ID: <CAM_vju=MH+1ZE6jTJ1nCdDsHJpbWSnZk3s8Yd8nPwRW5mAAnsA@mail.gmail.com>

Though your second question, restating this, has already been
answered, it might be worth you taking another look at your code in
this one as well.

In particular note that NA and "NA" are NOT the same thing.

data(mtcars)
str(mtcars)

# from your code
mtcars[2,2] <- "NA"
mtcars[6,7]  <- "NA"

str(mtcars)

I'm pretty sure that's not what you want.

Thanks for providing a reproducible example: otherwise it would have
been impossible to catch this. If you run into unexpected errors, it's
always a good plan to start by using str() and similar functions to
check whether your data are as you intend.

Sarah


On Sat, Dec 7, 2013 at 9:28 AM, Gundala Viswanath <gundalav at gmail.com> wrote:
> I have a data which contain some NA value in their elements.
> What I want to do is to **perform clustering without removing rows**
> where the NA is present.
>
> I understand that `gower` distance measure in `daisy` allow such situation.
> But why my code below doesn't work?
>
> __BEGIN__
>     # plot heat map with dendogram together.
>
>     library("gplots")
>     library("cluster")
>
>
>     # Arbitrarily assigning NA to some elements
>     mtcars[2,2] <- "NA"
>     mtcars[6,7]  <- "NA"
>
>      mydata <- mtcars
>
>     hclustfunc <- function(x) hclust(x, method="complete")
>
>     # Initially I wanted to use this but it didn't take NA
>     #distfunc <- function(x) dist(x,method="euclidean")
>
>     # Try using daisy GOWER function
>     # which suppose to work with NA value
>     distfunc <- function(x) daisy(x,metric="gower")
>
>     d <- distfunc(mydata)
>     fit <- hclustfunc(d)
>
>     # Perform clustering heatmap
>     heatmap.2(as.matrix(mydata),dendrogram="row",trace="none",
> margin=c(8,9), hclust=hclustfunc,distfun=distfunc);
> __END__
>
>    The error message I got is this:
>
>         Error in which(is.na) : argument to 'which' is not logical
>     Calls: distfunc.g -> daisy
>     In addition: Warning messages:
>     1: In data.matrix(x) : NAs introduced by coercion
>     2: In data.matrix(x) : NAs introduced by coercion
>     3: In daisy(x, metric = "gower") :
>       binary variable(s) 8, 9 treated as interval scaled
>     Execution halted
>
>
> At the end of the day, I'd like to perform hierarchical clustering
> with the NA allowed data.
>
> G.V.
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Mon Dec  9 21:51:55 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 9 Dec 2013 15:51:55 -0500
Subject: [R] data frame question
In-Reply-To: <1386622255.99051.YahooMailNeo@web161605.mail.bf1.yahoo.com>
References: <1386620823.59554.YahooMailNeo@web161605.mail.bf1.yahoo.com>
	<CAM_vjumgXti0QcH24Wi2uLYrRgk=_omAVrnbRjAwz0+jaNOwdw@mail.gmail.com>
	<1386622255.99051.YahooMailNeo@web161605.mail.bf1.yahoo.com>
Message-ID: <CAM_vjunvb0JwwngeQizkq3fTo0oVHCcm7DVQQ_9Eyd6bBiqoTw@mail.gmail.com>

If it's not homework, then I'm happy to provide more help:


a <-seq(0,10,by=1)
b <-c(10:20)
d <-data.frame(a=a,b=b)
f <-16

subset(d, b < f & b == max(b[b < f]))$a

# I'd turn it into a function
getVal <- function(d, f) {
    subset(d, b < f & b == max(b[b < f]))$a
}


Sarah


On Mon, Dec 9, 2013 at 3:50 PM, Andras Farkas <motyocska at yahoo.com> wrote:
> Sarah,
>
> thank you, not homework though, I guess it just looks like it.... I will
> look into subset()
>
> Andras
>
>
> On Monday, December 9, 2013 3:45 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
> Thank you for providing a reproducible example. I tweaked it a little
> bit to make it actually a data frame problem.
>
> There are lots of ways to do this; here's one approach.
>
> On second thought, this looks a lot like homework, so perhaps instead
> I'll just suggest using subset() with more than one condition.
>
> Sarah
>
> On Mon, Dec 9, 2013 at 3:27 PM, Andras Farkas <motyocska at yahoo.com> wrote:
>> Dear All
>>
>> please help with the following:
>>
>> I have:
>>
>> a <-seq(0,10,by=1)
>> b <-c(10:20)
>> d <-cbind(a,b)
>> f <-16
>>
>> I would like to select the value in column a based on a value in column b,
>> where the value in column b is the 1st value that is smaller then f. Thus I
>> should end up with the number 5 because the 1st value that is below 16 would
>> be 15, and in the same row column a has the number 5....
>>
>> appreciate your insights,
>>
>> andras
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From ahoerner at rprogress.org  Mon Dec  9 22:14:49 2013
From: ahoerner at rprogress.org (andrewH)
Date: Mon, 9 Dec 2013 13:14:49 -0800 (PST)
Subject: [R] How can I find nonstandard or control characters in a large
	file?
Message-ID: <1386623689473-4681896.post@n4.nabble.com>

I have a humongous csv file containing census data, far too big to read into
RAM. I have been trying to extract individual columns from this file using
the colbycol package. This works for certain subsets of the columns, but not
for others. I have not yet been able to precisely identify the problem
columns, as there are 731 columns and running colbycol on the file on my old
slow machine takes about 6 hours. 

However, my suspicion is that there are some funky characters, either
control characters or characters with some non-standard encoding, somewhere
in this 14 gig file. Moreover, I am concerned that these characters may
cause me trouble down the road even if I use a different approach to getting
columns out of the file.

Is there an r utility will search through my file without trying to read it
all into memory at one time and find non-standard characters or misplaced
(non-end-of-line) control characters? Or some R code to the same end?  Even
if the real problem ultimately proves top be different, it would be helpful
to eliminate this possibility. And this is also something I would routinely
run on files from external sources if I had it. 

 I am working in a windows XP environment, in case that makes a difference.

Any help anyone could offer would be greatly appreciated.

Sincerely, andrewH



--
View this message in context: http://r.789695.n4.nabble.com/How-can-I-find-nonstandard-or-control-characters-in-a-large-file-tp4681896.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Mon Dec  9 22:27:20 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 9 Dec 2013 13:27:20 -0800
Subject: [R] How to use multiple test for trend in proportions?
In-Reply-To: <1386611216718-4681879.post@n4.nabble.com>
References: <1386611216718-4681879.post@n4.nabble.com>
Message-ID: <70F96420-3626-412A-A3CE-BCC4CDE78756@comcast.net>


On Dec 9, 2013, at 9:46 AM, celebrex wrote:

> dataorder.csv <http://r.789695.n4.nabble.com/file/n4681879/dataorder.csv>

>  I have a set of data as attached.Like (181,246,378).....(180,228,378). And I
> want to use test for trend in proportions using (400,500,600) as denominator
> and get 119 p-values. So I use the code as
> below:

Reformatted:
> 
> data=read.table("dataorder.csv", sep=",",  stringsAsFactors=F)
> 
> i<-1:nrow(data)
> n <- c(400,500,600)
> e <- data[i,c(1,2,3)]

What is your intent with that command?


> prop.trend.test(e, n)
> 
> allpvalue = apply(data, 1, function(x) { prop.trend.test(e, n)$p.value})

In the function body there is no reference to "x". Did you intend this:

   allpvalue = apply(data, 1, function(x) { prop.trend.test(x, n)$p.value})


> However, there is something wrong but I can't figure out, can anybody
> help? Thanks

Posting from Nabble often screws up formatting,  as it did big-time in your case. It is possible to post in plain text from Nabble, so you should now take the time to learn how to do that.

> View this message in context: http://r.789695.n4.nabble.com/How-to-use-multiple-test-for-trend-in-proportions-tp4681879.html
> Sent from the R help mailing list archive at Nabble.com.

Nabble is NOT the Rhelp Mailing List!

> 	[[alternative HTML version deleted]]

And Nabble also deletes this very important message which you should now read and heed:
> 

> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
David Winsemius
Alameda, CA, USA


From rmh at temple.edu  Mon Dec  9 22:30:19 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 9 Dec 2013 16:30:19 -0500
Subject: [R] multiple bar for barchart
In-Reply-To: <CAF=-T0h+pthEOst4FtPNVLjqERNtxbrOcpbAKX7yE-PRGOS5VA@mail.gmail.com>
References: <CAF=-T0h+n8zARj4Ue2uctL3xpZN+UH+qsH3pH2bqORkjJJKwUw@mail.gmail.com>
	<CAGx1TMDVoh6tt_o5tnJeY_5vzsi8aW1WktSqSrvw9Bu_5GfgVQ@mail.gmail.com>
	<CAF=-T0h+pthEOst4FtPNVLjqERNtxbrOcpbAKX7yE-PRGOS5VA@mail.gmail.com>
Message-ID: <CAGx1TMDd2NUk5yEBSskxE6ZhmRJtiJNH58ZQLCcrwFzFWqK8pA@mail.gmail.com>

The etiquette of this email list is to stay on the list.
I am returning this email to the entire list.

The line I sent earlier prints one Figure, with a different set of 4
bars in each panel.

Here are three more options (and I repeat the first as well).
Basic documentation for barchart is in ?xyplot.
More detail is available in ?panel.barchart

barchart(value ~ variable | Group.1, data=dm.melt, origin=0)
barchart(value ~ Group.1 | variable, data=dm.melt, origin=0)
barchart(value ~ variable, groups=Group.1, data=dm.melt, origin=0)
barchart(value ~ Group.1, groups=variable, data=dm.melt, origin=0)

On Mon, Dec 9, 2013 at 2:45 PM, Adel ESSAFI <adel.safi at imag.fr> wrote:
> Thank you, it worked. However I want the bars to be displayed in the same
> figure .
> Actually, it prints each 4 bars in separates figures.
> Regards
>
>
>
>
> 2013/12/9 Richard M. Heiberger <rmh at temple.edu>
>
>> Start here
>>
>> dm <- read.table(text="
>>    Group.1 V1   V2      V3        V4         V5      V6      V7         V8
>> 1      C/L NA 15.5  732179  875270.6 -143091.46 1107270 1088300   18964.40
>> 2      C/S NA 15.5  803926  850352.1  -46426.03 1395710 1312310   83403.30
>> 3      D/D NA 15.5  751660  857828.2 -106168.17 1340360 1322790   17569.30
>> 4      D/F NA 15.5  724924  969418.7 -244494.67 1181280 1160760   20519.20
>> 5      D/I NA 15.5  755841  842130.5  -86289.48 1264250 1241750   22495.20
>> 6      D/L NA 15.5  731904  875340.0 -143435.84 1107600 1087940   19657.30
>> 7      D/S NA 15.5  798289  844102.0  -45812.85 1399840 1305000   94832.10
>> 8      I/F NA 15.5  871670 1074136.3 -202466.58 1304290 1249006   55286.59
>> 9      I/I NA 15.5  897718 1029579.0 -131861.35 1542810 1398716  144100.07
>> 10     I/L NA 15.5 2628110  862466.8 1765645.67 2628110 1073510 1554610.00
>> 11     I/S NA 15.5 2628110  831486.8 1796627.33 2475450 1282100 1193350.00
>> ", header=TRUE)
>>
>> library(reshape)
>> dm.melt <- melt(dm[,c(1,4,5,6,7)], id="Group.1")
>> barchart(value ~ variable | Group.1, data=dm.melt, origin=0)
>>
>>
>> On Mon, Dec 9, 2013 at 9:19 AM, Adel ESSAFI <adelessafi at gmail.com> wrote:
>> > Hello list,
>> > I have the following data on "dm" table
>> >
>> >> dm
>> >    Group.1 V1   V2      V3        V4         V5      V6      V7
>> > V8
>> > 1      C/L NA 15.5  732179  875270.6 -143091.46 1107270 1088300
>> > 18964.40
>> > 2      C/S NA 15.5  803926  850352.1  -46426.03 1395710 1312310
>> > 83403.30
>> > 3      D/D NA 15.5  751660  857828.2 -106168.17 1340360 1322790
>> > 17569.30
>> > 4      D/F NA 15.5  724924  969418.7 -244494.67 1181280 1160760
>> > 20519.20
>> > 5      D/I NA 15.5  755841  842130.5  -86289.48 1264250 1241750
>> > 22495.20
>> > 6      D/L NA 15.5  731904  875340.0 -143435.84 1107600 1087940
>> > 19657.30
>> > 7      D/S NA 15.5  798289  844102.0  -45812.85 1399840 1305000
>> > 94832.10
>> > 8      I/F NA 15.5  871670 1074136.3 -202466.58 1304290 1249006
>> > 55286.59
>> > 9      I/I NA 15.5  897718 1029579.0 -131861.35 1542810 1398716
>> > 144100.07
>> > 10     I/L NA 15.5 2628110  862466.8 1765645.67 2628110 1073510
>> > 1554610.00
>> > 11     I/S NA 15.5 2628110  831486.8 1796627.33 2475450 1282100
>> > 1193350.00
>> >> barchart (dm[,4] ~ dm[,1])
>> >
>> > For each value of Group.1 I want to draw 4 bars (v3,v4, v6 and v7).
>> >
>> > Can you suggest me a solution please
>> >
>> > barchat draws only one value.
>> > regards
>> >
>> >
>> >
>> > --
>> > PhD candidate in Computer Science
>> > Address
>> > 3 avenue lamine, cit? ezzahra, Sousse 4000
>> > Tunisia
>> > tel: +216 97 246 706 (+33640302046 jusqu'au 15/6)
>> > fax: +216 71 391 166
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>
>
>
>
> --
> PhD in Computer Science
> Address
>
> Avenue Taha Hussein Montfleury, 1008 Tunis
>
> t?l : +216 71 49 60 66
> fax: +216 71 39 11 66


From kmill117 at alaska.edu  Mon Dec  9 23:12:17 2013
From: kmill117 at alaska.edu (Katharine Miller)
Date: Mon, 9 Dec 2013 13:12:17 -0900
Subject: [R] Problem with R colors
Message-ID: <CAJkbZWTKiwrKgAVt3-0azxgHKK+XfF9mv3rnJzYuKD2sZK-mEQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/51659f2f/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Mon Dec  9 23:17:42 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Mon, 9 Dec 2013 23:17:42 +0100 (MET)
Subject: [R] lattice: superposed boxplots with same colors for rectanglesand
	umbrellas and filled boxes
Message-ID: <Pine.SOC.4.64.1312092244180.13779@solcom.hrz.uni-giessen.de>

Dear R-list,

I've been trying to produce a sort of an interaction plot wherein colored 
stripplots and boxplots are superposed. In particular, I want the colors 
of the (transparently) filled boxes to be the same as the colors of the 
box borders (rectangle) and their whiskers (umbrella). Below I'm going to 
create an artificial data set and provide the code with which I've come up 
so far, and which is a fusion and adaptation of a few pieces of code I've 
found in the help pages and the mail archives. It does almost what I want, 
but still colors the rectangles and the umbrellas in black (of course, 
because it is the setting in the example presented below). However, the 
latter is what I want to change.

x <- c( rep( 1:4, each = 10), rep( -2, 40))
Data <- data.frame( F1 = gl( 4, 10, length = 80, labels = LETTERS[ 1:4]),
                     F2 = gl( 2, 40), Y = x + rnorm( length( x)))

mycolors <- c( "red", "blue")
myalpha <- 0.33
bwplot( Y ~ F1, groups = F2, data = Data,
         col = mycolors, fill = mycolors, jitter.data = TRUE,
         panel = panel.superpose,
         panel.groups = function(..., pch, col, alpha){
             panel.stripplot(...)
             panel.bwplot(..., do.out = FALSE)
         },
         par.settings = list( box.dot = list( alpha = myalpha),
                              box.rectangle = list( col = "black",
                                                    alpha = myalpha),
                              box.umbrella = list( col = "black",
                                                   alpha = myalpha))
         )


If I'd provide mycolors instead of "black" to the col-component of the 
(sub-)lists given to par.settings, the coloring of the respective 
components of the boxplots would not be what I want. Having studied the 
code of panel.superpose() and panel.bwplot() it appears to me that 
panel.bwplot() cannot access the settings created by panel.supperpose when 
it comes to drawing the rectangle and umbrella of a boxplot. It only 
accesses box.[dot, rectangle, umbrella], which does not give what I need.

I may have overlooked the obvious and would be quite grateful if somebody 
could give me a hint where to look further. Or is a workaround necessary 
(and available)?

Thanks a lot in advance!

  Best Regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner


From sarah.goslee at gmail.com  Mon Dec  9 23:21:23 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 9 Dec 2013 17:21:23 -0500
Subject: [R] Problem with R colors
In-Reply-To: <CAJkbZWTKiwrKgAVt3-0azxgHKK+XfF9mv3rnJzYuKD2sZK-mEQ@mail.gmail.com>
References: <CAJkbZWTKiwrKgAVt3-0azxgHKK+XfF9mv3rnJzYuKD2sZK-mEQ@mail.gmail.com>
Message-ID: <CAM_vjunDrAVohbVkV9EnCekUUcgG==qJtsq4UcyhsA_3mxhWJg@mail.gmail.com>

Hi,

col=552 isn't the same as colors()[552] - I think the former is drawn
from your current palette, with recycling of indices. The default
color palette has only eight colors.

You need instead

col=colors()[552]

It's very difficult to get 20-30 readily distinguishable colors. You
might try the RColorBrewer package for smaller tasks, though.


Sarah


On Mon, Dec 9, 2013 at 5:12 PM, Katharine Miller <kmill117 at alaska.edu> wrote:
> Hello,
>
> I am having difficulty obtaining the correct colors in my R charts.
>
>> colors()[c(552, 254, 26)]
> [1] "red"   "green" "blue"
>
> But, if I specify col=552 in my barplot, I get gray bars.  Likewise,
> col=254 gives bright pink, and col=26 is a red-orange.   I get accurate
> results when I spell out the names, but I am making a pallet with 20- 30
> colors and it is a real pain to have to do that.  Can anyone help me figure
> out what I am doing wrong?
>
> Thanks

-- 
Sarah Goslee
http://www.functionaldiversity.org


From kumsaa at hotmail.com  Mon Dec  9 21:53:30 2013
From: kumsaa at hotmail.com (Norbi Gurracho)
Date: Mon, 9 Dec 2013 20:53:30 +0000
Subject: [R] Plot mortality data and show trend
Message-ID: <DUB122-W469028C64C7CEC9CF7A0C6CFD30@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/c6232026/attachment.pl>

From a-morkovin at yandex.ru  Mon Dec  9 22:14:38 2013
From: a-morkovin at yandex.ru (=?koi8-r?B?4c7Uz84g7c/Sy8/Xyc4=?=)
Date: Tue, 10 Dec 2013 01:14:38 +0400
Subject: [R] How to coerce an object name to character vector?
Message-ID: <70061386623678@web1g.yandex.ru>


   For example, I have a numeric vector named "d" (without any attributes) and
   I want to coerce it to character vector "d". Is there any such functions? I
   need  it  to make a function which applies other functions to objects,
   something like this:

   do<-function(x,fun, ...) {
   fun<-match.fun(fun)
   assign(as.character(quote(x)),fun(x, ...))
   }

   But, of course, quote(x) always return just "x", not the name of object.

   Thanks for help!

   ______

   ?? ??????????????????,
   ??.??. ????????????????

From toth.denes at ttk.mta.hu  Mon Dec  9 22:15:11 2013
From: toth.denes at ttk.mta.hu (Toth, Denes)
Date: Mon, 9 Dec 2013 22:15:11 +0100
Subject: [R] data frame question
In-Reply-To: <CAM_vjunvb0JwwngeQizkq3fTo0oVHCcm7DVQQ_9Eyd6bBiqoTw@mail.gmail.com>
References: <1386620823.59554.YahooMailNeo@web161605.mail.bf1.yahoo.com>
	<CAM_vjumgXti0QcH24Wi2uLYrRgk=_omAVrnbRjAwz0+jaNOwdw@mail.gmail.com>
	<1386622255.99051.YahooMailNeo@web161605.mail.bf1.yahoo.com>
	<CAM_vjunvb0JwwngeQizkq3fTo0oVHCcm7DVQQ_9Eyd6bBiqoTw@mail.gmail.com>
Message-ID: <00bbfdb354643c3b8f90ee83ad43bcdd.squirrel@webmail.cogpsyphy.hu>


Hi Andras,

here is an other solution which also works if b contains missing values:

a <-seq(0,10,by=1)
b <-c(NA, 11:20)
f <-16
#
a[which.max(b[b<f])]
#

However, your question seems a bit artificial. Maybe you converted your
original question to a suboptimal problem.

HTH,
  Denes


> If it's not homework, then I'm happy to provide more help:
>
>
> a <-seq(0,10,by=1)
> b <-c(10:20)
> d <-data.frame(a=a,b=b)
> f <-16
>
> subset(d, b < f & b == max(b[b < f]))$a
>
> # I'd turn it into a function
> getVal <- function(d, f) {
>     subset(d, b < f & b == max(b[b < f]))$a
> }
>
>
> Sarah
>
>
> On Mon, Dec 9, 2013 at 3:50 PM, Andras Farkas <motyocska at yahoo.com> wrote:
>> Sarah,
>>
>> thank you, not homework though, I guess it just looks like it.... I will
>> look into subset()
>>
>> Andras
>>
>>
>> On Monday, December 9, 2013 3:45 PM, Sarah Goslee
>> <sarah.goslee at gmail.com>
>> wrote:
>> Thank you for providing a reproducible example. I tweaked it a little
>> bit to make it actually a data frame problem.
>>
>> There are lots of ways to do this; here's one approach.
>>
>> On second thought, this looks a lot like homework, so perhaps instead
>> I'll just suggest using subset() with more than one condition.
>>
>> Sarah
>>
>> On Mon, Dec 9, 2013 at 3:27 PM, Andras Farkas <motyocska at yahoo.com>
>> wrote:
>>> Dear All
>>>
>>> please help with the following:
>>>
>>> I have:
>>>
>>> a <-seq(0,10,by=1)
>>> b <-c(10:20)
>>> d <-cbind(a,b)
>>> f <-16
>>>
>>> I would like to select the value in column a based on a value in column
>>> b,
>>> where the value in column b is the 1st value that is smaller then f.
>>> Thus I
>>> should end up with the number 5 because the 1st value that is below 16
>>> would
>>> be 15, and in the same row column a has the number 5....
>>>
>>> appreciate your insights,
>>>
>>> andras
>>
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From katharine.miller at noaa.gov  Mon Dec  9 23:08:52 2013
From: katharine.miller at noaa.gov (Katharine Miller - NOAA Federal)
Date: Mon, 9 Dec 2013 13:08:52 -0900
Subject: [R] Chart colors
Message-ID: <CACnUi68Q=MYfsB-iLUj66egZbUnkY-impd61RPbqO3uFWRfHOg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/7959aecd/attachment.pl>

From alma_anima at yahoo.com  Mon Dec  9 23:34:42 2013
From: alma_anima at yahoo.com (Alma Wilflinger)
Date: Mon, 9 Dec 2013 14:34:42 -0800 (PST)
Subject: [R] How do I print predicted effect sizes in forest plot?
In-Reply-To: <Zen-1Vow6o-0006iI-Co@smarthost01a.mail.zen.net.uk>
References: <1386277539.51368.YahooMailNeo@web141101.mail.bf1.yahoo.com>
	<Zen-1Vow6o-0006iI-Co@smarthost01a.mail.zen.net.uk>
Message-ID: <1386628482.62420.YahooMailNeo@web141106.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/be31c9ab/attachment.pl>

From dcarlson at tamu.edu  Mon Dec  9 23:46:55 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 9 Dec 2013 16:46:55 -0600
Subject: [R] Problem with R colors
In-Reply-To: <CAJkbZWTKiwrKgAVt3-0azxgHKK+XfF9mv3rnJzYuKD2sZK-mEQ@mail.gmail.com>
References: <CAJkbZWTKiwrKgAVt3-0azxgHKK+XfF9mv3rnJzYuKD2sZK-mEQ@mail.gmail.com>
Message-ID: <011d01cef530$8f92a1f0$aeb7e5d0$@tamu.edu>

The full details on the col= argument can be found in the
section titled "Color Specification" on the help page for par -
?par.

Basically, col= accepts color names, hexadecimal RGB, or an
integer designating a position on the current palette. You can
get the current palette using

> palette()
[1] "black"   "red"     "green3"  "blue"    "cyan"    "magenta"
"yellow" 
[8] "gray" 

Any of these will give you red

col="red"
col="#FF0000"
col=2

You can change the palette colors with the palette() function,
but some graphics functions draw axes, text, etc assuming the
first color in the palette is black so it may be better to
create a vector of the colors you want, eg. 

mc <- colors()[c(552, 254, 26)]

and then use 

col=mc[1]

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Katharine
Miller
Sent: Monday, December 9, 2013 4:12 PM
To: r-help at r-project.org
Subject: [R] Problem with R colors

Hello,

I am having difficulty obtaining the correct colors in my R
charts.

> colors()[c(552, 254, 26)]
[1] "red"   "green" "blue"

But, if I specify col=552 in my barplot, I get gray bars.
Likewise,
col=254 gives bright pink, and col=26 is a red-orange.   I get
accurate
results when I spell out the names, but I am making a pallet
with 20- 30
colors and it is a real pain to have to do that.  Can anyone
help me figure
out what I am doing wrong?

Thanks

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From rmh at temple.edu  Mon Dec  9 23:52:38 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 9 Dec 2013 17:52:38 -0500
Subject: [R] lattice: superposed boxplots with same colors for
 rectanglesand umbrellas and filled boxes
In-Reply-To: <Pine.SOC.4.64.1312092244180.13779@solcom.hrz.uni-giessen.de>
References: <Pine.SOC.4.64.1312092244180.13779@solcom.hrz.uni-giessen.de>
Message-ID: <CAGx1TMAGaJo2w1fCq7WRQ1u+98GXyv9DQUvnUwVN8M_iVhbBcg@mail.gmail.com>

Gerrit,

Thank you for the opportunity to illustrate this.  I solved this
problem last week
and it will be included in the next version of the HH package (about a
month away).

 panel.bwplot.constantColor <- function(..., col, fill, cex, pch) {
  ## to be included in next version of the HH package
  box.save <- list(box.dot=trellis.par.get("box.dot"),
                   box.rectangle=trellis.par.get("box.rectangle"),
                   box.umbrella=trellis.par.get("box.umbrella"),
                   plot.symbol=trellis.par.get("plot.symbol"))
  trellis.par.set(box.dot=list(col=col),
                  box.rectangle=list(col=col),
                  box.umbrella=list(col=col),
                  plot.symbol=list(col=col))
  panel.bwplot(..., fill=col, cex=cex, pch=pch)
  trellis.par.set(box.save)
}

bwplot( Y ~ F1, groups = F2, data = Data,
        col = mycolors, fill = mycolors, jitter.data = TRUE, pch=19,
        panel = panel.superpose,
        panel.groups = function(..., pch, col, alpha){
            panel.stripplot(...)
            panel.bwplot.constantColor(..., pch=pch, col=col,
alpha=alpha, do.out = FALSE)
        },
        par.settings = list( box.dot = list( alpha = myalpha),
                             box.rectangle = list( col = mycolors,
                                                   alpha = myalpha),
                             box.umbrella = list( col = mycolors,
                                                  alpha = myalpha))
        )


Rich

On Mon, Dec 9, 2013 at 5:17 PM, Gerrit Eichner
<Gerrit.Eichner at math.uni-giessen.de> wrote:
> Dear R-list,
>
> I've been trying to produce a sort of an interaction plot wherein colored
> stripplots and boxplots are superposed. In particular, I want the colors of
> the (transparently) filled boxes to be the same as the colors of the box
> borders (rectangle) and their whiskers (umbrella). Below I'm going to create
> an artificial data set and provide the code with which I've come up so far,
> and which is a fusion and adaptation of a few pieces of code I've found in
> the help pages and the mail archives. It does almost what I want, but still
> colors the rectangles and the umbrellas in black (of course, because it is
> the setting in the example presented below). However, the latter is what I
> want to change.
>
> x <- c( rep( 1:4, each = 10), rep( -2, 40))
> Data <- data.frame( F1 = gl( 4, 10, length = 80, labels = LETTERS[ 1:4]),
>                     F2 = gl( 2, 40), Y = x + rnorm( length( x)))
>
> mycolors <- c( "red", "blue")
> myalpha <- 0.33
> bwplot( Y ~ F1, groups = F2, data = Data,
>         col = mycolors, fill = mycolors, jitter.data = TRUE,
>         panel = panel.superpose,
>         panel.groups = function(..., pch, col, alpha){
>             panel.stripplot(...)
>             panel.bwplot(..., do.out = FALSE)
>         },
>         par.settings = list( box.dot = list( alpha = myalpha),
>                              box.rectangle = list( col = "black",
>                                                    alpha = myalpha),
>                              box.umbrella = list( col = "black",
>                                                   alpha = myalpha))
>         )
>
>
> If I'd provide mycolors instead of "black" to the col-component of the
> (sub-)lists given to par.settings, the coloring of the respective components
> of the boxplots would not be what I want. Having studied the code of
> panel.superpose() and panel.bwplot() it appears to me that panel.bwplot()
> cannot access the settings created by panel.supperpose when it comes to
> drawing the rectangle and umbrella of a boxplot. It only accesses box.[dot,
> rectangle, umbrella], which does not give what I need.
>
> I may have overlooked the obvious and would be quite grateful if somebody
> could give me a hint where to look further. Or is a workaround necessary
> (and available)?
>
> Thanks a lot in advance!
>
>  Best Regards  --  Gerrit
>
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
> Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mdsumner at gmail.com  Mon Dec  9 23:56:11 2013
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 10 Dec 2013 09:56:11 +1100
Subject: [R] Chart colors
In-Reply-To: <CACnUi68Q=MYfsB-iLUj66egZbUnkY-impd61RPbqO3uFWRfHOg@mail.gmail.com>
References: <CACnUi68Q=MYfsB-iLUj66egZbUnkY-impd61RPbqO3uFWRfHOg@mail.gmail.com>
Message-ID: <CAAcGz9-9nmnY+89SHMTZn-OSPOuGQyMfqPiKTNW59ErBKuZ6yg@mail.gmail.com>

Those numbers that you pass to col = ... correspond to the current
sessions palette, not to the names of colors() that R knows about. You
can either set up your own palette:

## see current palette
 palette()
[1] "black"   "red"     "green3"  "blue"    "cyan"    "magenta" "yellow"
[8] "gray"

## set up new palette
palette(grey(seq(0, 0.9, length = 25)))
plot(1:25, col = 1:25, pch = 16)

or give a direct set of colours to col = as either character names or
hex values.

See "Color Specification" under ?par and ?palette for an overview and
pointers to other functions.

Cheers, MIke.

On Tue, Dec 10, 2013 at 9:08 AM, Katharine Miller - NOAA Federal
<katharine.miller at noaa.gov> wrote:
> Hello,
>
> I am having difficulty obtaining the correct colors in my R charts.
>
>> colors()[c(552, 254, 26)]
> [1] "red"   "green" "blue"
>
> But, if I specify col=552 in my barplot, I get gray bars.  Likewise,
> col=254 gives bright pink, and col=26 is a red-orange.   I get accurate
> results when I spell out the names, but I am making a pallet with 20- 30
> colors and it is a real pain to have to do that.  Can anyone help me figure
> out what I am doing wrong?
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Michael Sumner
Hobart, Australia
e-mail: mdsumner at gmail.com


From peter.langfelder at gmail.com  Mon Dec  9 23:57:53 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Mon, 9 Dec 2013 14:57:53 -0800
Subject: [R] Chart colors
In-Reply-To: <CACnUi68Q=MYfsB-iLUj66egZbUnkY-impd61RPbqO3uFWRfHOg@mail.gmail.com>
References: <CACnUi68Q=MYfsB-iLUj66egZbUnkY-impd61RPbqO3uFWRfHOg@mail.gmail.com>
Message-ID: <CA+hbrhUSC-fBFD=jKekV-GLvQxJ1+R2CYuJK1EV-iO2_ziw=HA@mail.gmail.com>

On Mon, Dec 9, 2013 at 2:08 PM, Katharine Miller - NOAA Federal
<katharine.miller at noaa.gov> wrote:
> Hello,
>
> I am having difficulty obtaining the correct colors in my R charts.
>
>> colors()[c(552, 254, 26)]
> [1] "red"   "green" "blue"
>
> But, if I specify col=552 in my barplot, I get gray bars.  Likewise,
> col=254 gives bright pink, and col=26 is a red-orange.   I get accurate
> results when I spell out the names, but I am making a pallet with 20- 30
> colors and it is a real pain to have to do that.  Can anyone help me figure
> out what I am doing wrong?

I believe there are two different color specifications. When you write
col=<number>, you get one of 8 "basic" colors: black, red, green,
blue, turquoise, magenta, yellow, and grey. See this example:

plot(c(1:30), pch = 21, bg = c(1:30), col = c(1:30))

 If the number is higher than 8, you get the (number-1) mod 8 + 1
color. That would explain why you get grey for 552, "bright pink"
(really magenta) for 254, and red for 26.

If you want to get the colors listed by colors(), simply specify col =
colors()[c(552, 254, 26)].

Add as many numbers to the 552, 254, 26 as you need.

Hope this helps,

Peter


From kmill117 at alaska.edu  Tue Dec 10 00:05:26 2013
From: kmill117 at alaska.edu (Katharine Miller)
Date: Mon, 9 Dec 2013 14:05:26 -0900
Subject: [R] Problem with R colors
In-Reply-To: <011d01cef530$8f92a1f0$aeb7e5d0$@tamu.edu>
References: <CAJkbZWTKiwrKgAVt3-0azxgHKK+XfF9mv3rnJzYuKD2sZK-mEQ@mail.gmail.com>
	<011d01cef530$8f92a1f0$aeb7e5d0$@tamu.edu>
Message-ID: <CAJkbZWR-BxoNWfxs-cpXM-GBhRD0WjyLp3Zxk0HT1QK8QcGoNQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/cebb4a58/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue Dec 10 00:09:00 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 09 Dec 2013 15:09:00 -0800
Subject: [R] Chart colors
In-Reply-To: <CACnUi68Q=MYfsB-iLUj66egZbUnkY-impd61RPbqO3uFWRfHOg@mail.gmail.com>
References: <CACnUi68Q=MYfsB-iLUj66egZbUnkY-impd61RPbqO3uFWRfHOg@mail.gmail.com>
Message-ID: <1513de73-d94c-47ea-b4e0-c1f7dae7744f@email.android.com>

Not reading the documentation for color specification? Integers do not specify offsets in the colors() table.

?par

If you do want offsets into the colors table, perhaps you should do just that?

..., col=colors()[ c( 552, 254, 26 )], ...

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Katharine Miller - NOAA Federal <katharine.miller at noaa.gov> wrote:
>Hello,
>
>I am having difficulty obtaining the correct colors in my R charts.
>
>> colors()[c(552, 254, 26)]
>[1] "red"   "green" "blue"
>
>But, if I specify col=552 in my barplot, I get gray bars.  Likewise,
>col=254 gives bright pink, and col=26 is a red-orange.   I get accurate
>results when I spell out the names, but I am making a pallet with 20-
>30
>colors and it is a real pain to have to do that.  Can anyone help me
>figure
>out what I am doing wrong?
>
>Thanks
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Tue Dec 10 00:25:17 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 10 Dec 2013 10:25:17 +1100
Subject: [R] multiple bar for barchart
In-Reply-To: <CAF=-T0h+n8zARj4Ue2uctL3xpZN+UH+qsH3pH2bqORkjJJKwUw@mail.gmail.com>
References: <CAF=-T0h+n8zARj4Ue2uctL3xpZN+UH+qsH3pH2bqORkjJJKwUw@mail.gmail.com>
Message-ID: <52A6515D.1030001@bitwrit.com.au>

On 12/10/2013 01:19 AM, Adel ESSAFI wrote:
> Hello list,
> I have the following data on "dm" table
>
>> dm
>     Group.1 V1   V2      V3        V4         V5      V6      V7         V8
> 1      C/L NA 15.5  732179  875270.6 -143091.46 1107270 1088300   18964.40
> 2      C/S NA 15.5  803926  850352.1  -46426.03 1395710 1312310   83403.30
> 3      D/D NA 15.5  751660  857828.2 -106168.17 1340360 1322790   17569.30
> 4      D/F NA 15.5  724924  969418.7 -244494.67 1181280 1160760   20519.20
> 5      D/I NA 15.5  755841  842130.5  -86289.48 1264250 1241750   22495.20
> 6      D/L NA 15.5  731904  875340.0 -143435.84 1107600 1087940   19657.30
> 7      D/S NA 15.5  798289  844102.0  -45812.85 1399840 1305000   94832.10
> 8      I/F NA 15.5  871670 1074136.3 -202466.58 1304290 1249006   55286.59
> 9      I/I NA 15.5  897718 1029579.0 -131861.35 1542810 1398716  144100.07
> 10     I/L NA 15.5 2628110  862466.8 1765645.67 2628110 1073510 1554610.00
> 11     I/S NA 15.5 2628110  831486.8 1796627.33 2475450 1282100 1193350.00
>> barchart (dm[,4] ~ dm[,1])
>
> For each value of Group.1 I want to draw 4 bars (v3,v4, v6 and v7).
>
> Can you suggest me a solution please
>
Hi Adel,
If you have no repeated values in Group.1, this might work:

dmmat<-as.matrix(dm[,c(3,4,6,7)])
rownames(dmmat)<-as.character(dm$Group.1)
library(plotrix)
barp(t(dmmat),names.arg=rownames(dmmat))

Jim


From macqueen1 at llnl.gov  Tue Dec 10 00:34:22 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 9 Dec 2013 23:34:22 +0000
Subject: [R] How to coerce an object name to character vector?
In-Reply-To: <70061386623678@web1g.yandex.ru>
References: <70061386623678@web1g.yandex.ru>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D5D548C@PRDEXMBX-08.the-lab.llnl.gov>

Not tested, but I think you may want this:

do <- function(x,fun, ...) {
  fun <- match.fun(fun)
  obj.name <- deparse(substitute(x))
  assign(obj.name,fun(x, ...))
}



-Don




-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 12/9/13 1:14 PM, "????? ????????" <a-morkovin at yandex.ru> wrote:

>
>   For example, I have a numeric vector named "d" (without any
>attributes) and
>   I want to coerce it to character vector "d". Is there any such
>functions? I
>   need  it  to make a function which applies other functions to objects,
>   something like this:
>
>   do<-function(x,fun, ...) {
>   fun<-match.fun(fun)
>   assign(as.character(quote(x)),fun(x, ...))
>   }
>
>   But, of course, quote(x) always return just "x", not the name of
>object.
>
>   Thanks for help!
>
>   ______
>
>   ?? ??????????????????,
>   ??.??. ????????????????
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Tue Dec 10 00:40:53 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 10 Dec 2013 10:40:53 +1100
Subject: [R] Plot mortality data and show trend
In-Reply-To: <DUB122-W469028C64C7CEC9CF7A0C6CFD30@phx.gbl>
References: <DUB122-W469028C64C7CEC9CF7A0C6CFD30@phx.gbl>
Message-ID: <52A65505.2030106@bitwrit.com.au>

On 12/10/2013 07:53 AM, Norbi Gurracho wrote:
> I have a mortality data over many years  and I wish to plot the data and also add some smoother to clearly highlight the trend. How could I do that in R with base graphics or ggplot? I have the following sample data: require(lubridate) mdate<-seq(ymd('2000-01-01'),ymd('2010-12-31'), by = '1 day') death<- rnorm(4018, 80, 45) df<-cbind(mdate,death)  		 	   		

Hi Norbi,
One way is:

plot(mdate,death,type="l",col="lightgray")
lines(supsmu(mdate,death))

Jim


From ross at biostat.ucsf.edu  Tue Dec 10 00:59:59 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 09 Dec 2013 15:59:59 -0800
Subject: [R] adding tables
Message-ID: <1386633599.28779.33.camel@localhost>

Can anyone recommend a good way to add tables?
Ideally I would like
t1 <- table(x1)
t2 <- table(x2)
t1+t2

It t1 and t2 have the same levels this works fine, but I need something
that will work even if they differ, e.g.,
 > t1

 1 2 4 5
 2 1 1 1
 > t2 <- table(c(10, 11, 12, 13))
 > t1+t2  # apparently does simple vector addition

 1 2 4 5
 3 2 2 2
whereas I want
1 2 4 5 10 11 12 13
2 1 1 1  1  1  1  1


From ross at biostat.ucsf.edu  Tue Dec 10 01:09:06 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 09 Dec 2013 16:09:06 -0800
Subject: [R] adding tables [partial solution]
In-Reply-To: <1386633599.28779.33.camel@localhost>
References: <1386633599.28779.33.camel@localhost>
Message-ID: <1386634146.28779.37.camel@localhost>

Answering myself...
On Mon, 2013-12-09 at 15:59 -0800, Ross Boylan wrote:
> Can anyone recommend a good way to add tables?
For count data, which were my main concern, it looks as if tabulate with
nbins will work.  I'm not sure how this works with a cross-classifying
factor, which I will also need.  It's possible the factor may have
missing values in some tabulations as well.

For the one dimensional case
 > t1 <- tabulate(c(1, 2, 2, 4), nbins=5)
 > t2 <- tabulate(c(2, 3, 5), nbins=5)
 > t1
 [1] 1 2 0 1 0
 > t2
 [1] 0 1 1 0 1
 > t1+t2
 [1] 1 3 1 1 1

> Ideally I would like
> t1 <- table(x1)
> t2 <- table(x2)
> t1+t2
> 
> It t1 and t2 have the same levels this works fine, but I need something
> that will work even if they differ, e.g.,
>  > t1
> 
>  1 2 4 5
>  2 1 1 1
>  > t2 <- table(c(10, 11, 12, 13))
>  > t1+t2  # apparently does simple vector addition
> 
>  1 2 4 5
>  3 2 2 2
> whereas I want
> 1 2 4 5 10 11 12 13
> 2 1 1 1  1  1  1  1
>


From roy.mendelssohn at noaa.gov  Tue Dec 10 01:20:43 2013
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn)
Date: Mon, 9 Dec 2013 16:20:43 -0800
Subject: [R] adding tables [partial solution]
In-Reply-To: <1386634146.28779.37.camel@localhost>
References: <1386633599.28779.33.camel@localhost>
	<1386634146.28779.37.camel@localhost>
Message-ID: <B788834A-3E86-49C0-847A-AA67596EC757@noaa.gov>

Is this what you are after?

http://www.statmethods.net/management/merging.html

-Roy
On Dec 9, 2013, at 4:09 PM, Ross Boylan <ross at biostat.ucsf.edu> wrote:

> Answering myself...
> On Mon, 2013-12-09 at 15:59 -0800, Ross Boylan wrote:
>> Can anyone recommend a good way to add tables?
> For count data, which were my main concern, it looks as if tabulate with
> nbins will work.  I'm not sure how this works with a cross-classifying
> factor, which I will also need.  It's possible the factor may have
> missing values in some tabulations as well.
> 
> For the one dimensional case
>> t1 <- tabulate(c(1, 2, 2, 4), nbins=5)
>> t2 <- tabulate(c(2, 3, 5), nbins=5)
>> t1
> [1] 1 2 0 1 0
>> t2
> [1] 0 1 1 0 1
>> t1+t2
> [1] 1 3 1 1 1
> 
>> Ideally I would like
>> t1 <- table(x1)
>> t2 <- table(x2)
>> t1+t2
>> 
>> It t1 and t2 have the same levels this works fine, but I need something
>> that will work even if they differ, e.g.,
>>> t1
>> 
>> 1 2 4 5
>> 2 1 1 1
>>> t2 <- table(c(10, 11, 12, 13))
>>> t1+t2  # apparently does simple vector addition
>> 
>> 1 2 4 5
>> 3 2 2 2
>> whereas I want
>> 1 2 4 5 10 11 12 13
>> 2 1 1 1  1  1  1  1
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
1352 Lighthouse Avenue
Pacific Grove, CA 93950-2097

e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
voice: (831)-648-9029
fax: (831)-648-8440
www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From ross at biostat.ucsf.edu  Tue Dec 10 01:39:53 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 09 Dec 2013 16:39:53 -0800
Subject: [R] adding tables [partial solution]
In-Reply-To: <B788834A-3E86-49C0-847A-AA67596EC757@noaa.gov>
References: <1386633599.28779.33.camel@localhost>
	<1386634146.28779.37.camel@localhost>
	<B788834A-3E86-49C0-847A-AA67596EC757@noaa.gov>
Message-ID: <1386635993.28779.61.camel@localhost>

On Mon, 2013-12-09 at 16:20 -0800, Roy Mendelssohn wrote:
> Is this what you are after?
> 
> http://www.statmethods.net/management/merging.html
Not directly.  Something could probably be fashioned using it and
as.data.frame on the result of table(), but merge doesn't sum values.

Ross
> 
> -Roy
> On Dec 9, 2013, at 4:09 PM, Ross Boylan <ross at biostat.ucsf.edu> wrote:
> 
> > Answering myself...
> > On Mon, 2013-12-09 at 15:59 -0800, Ross Boylan wrote:
> >> Can anyone recommend a good way to add tables?
> > For count data, which were my main concern, it looks as if tabulate with
> > nbins will work.  I'm not sure how this works with a cross-classifying
> > factor, which I will also need.  It's possible the factor may have
> > missing values in some tabulations as well.
> > 
> > For the one dimensional case
> >> t1 <- tabulate(c(1, 2, 2, 4), nbins=5)
> >> t2 <- tabulate(c(2, 3, 5), nbins=5)
> >> t1
> > [1] 1 2 0 1 0
> >> t2
> > [1] 0 1 1 0 1
> >> t1+t2
> > [1] 1 3 1 1 1
> > 
> >> Ideally I would like
> >> t1 <- table(x1)
> >> t2 <- table(x2)
> >> t1+t2
> >> 
> >> It t1 and t2 have the same levels this works fine, but I need something
> >> that will work even if they differ, e.g.,
> >>> t1
> >> 
> >> 1 2 4 5
> >> 2 1 1 1
> >>> t2 <- table(c(10, 11, 12, 13))
> >>> t1+t2  # apparently does simple vector addition
> >> 
> >> 1 2 4 5
> >> 3 2 2 2
> >> whereas I want
> >> 1 2 4 5 10 11 12 13
> >> 2 1 1 1  1  1  1  1
> >> 
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> 1352 Lighthouse Avenue
> Pacific Grove, CA 93950-2097
> 
> e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
> voice: (831)-648-9029
> fax: (831)-648-8440
> www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>


From patcostabr at yahoo.com.br  Tue Dec 10 01:19:34 2013
From: patcostabr at yahoo.com.br (Patricia Costa)
Date: Mon, 9 Dec 2013 16:19:34 -0800 (PST)
Subject: [R] Multiple Lorenz curves in one diagram - populations with
	different "n"
Message-ID: <1386634774.94686.YahooMailNeo@web125002.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131209/5d7d5a93/attachment.pl>

From gunter.berton at gene.com  Tue Dec 10 01:55:33 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 9 Dec 2013 16:55:33 -0800
Subject: [R] How to coerce an object name to character vector?
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A521910D5D548C@PRDEXMBX-08.the-lab.llnl.gov>
References: <70061386623678@web1g.yandex.ru>
	<5E1B812FAC2C4A49B3D99593B5A521910D5D548C@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <CACk-te036JucUSDoqO=Yb7BfZN=twAq6G-ex-b=cWKu_gTQFOQ@mail.gmail.com>

Don:

I defer to your judgment as to whether this was what the OP wanted,
but I think you would agree that the idiom of assign()ing to the
global workspace from within a function is almost always a bad idea in
R. Unfortunately, a better alternative, which frequently involves
building up a list structure of some sort, depends on context and, in
particular, on what further is to be done with the assigned objects,
which usually we (and sometimes the poster) don't know.

While assign() and friends certainly exist and allow script-like
programming if that is how one wishes to proceed, my understanding is
that it circumvents the functional-style programming paradigm that R
naturally supports. So I would urge those who wish to partake of the
"zen" of R to expunge get() and assign() from their R programming
vocabulary and perhaps read up a bit on functional programming, which
is really kinda cool.

Contrary opinions most definitely welcome! The stock awaits me in the
public squaRe.

Best,
Bert

On Mon, Dec 9, 2013 at 3:34 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> Not tested, but I think you may want this:
>
> do <- function(x,fun, ...) {
>   fun <- match.fun(fun)
>   obj.name <- deparse(substitute(x))
>   assign(obj.name,fun(x, ...))
> }
>
>
>
> -Don
>
>
>
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 12/9/13 1:14 PM, "????? ????????" <a-morkovin at yandex.ru> wrote:
>
>>
>>   For example, I have a numeric vector named "d" (without any
>>attributes) and
>>   I want to coerce it to character vector "d". Is there any such
>>functions? I
>>   need  it  to make a function which applies other functions to objects,
>>   something like this:
>>
>>   do<-function(x,fun, ...) {
>>   fun<-match.fun(fun)
>>   assign(as.character(quote(x)),fun(x, ...))
>>   }
>>
>>   But, of course, quote(x) always return just "x", not the name of
>>object.
>>
>>   Thanks for help!
>>
>>   ______
>>
>>   ?? ??????????????????,
>>   ??.??. ????????????????
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dwinsemius at comcast.net  Tue Dec 10 02:01:07 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 9 Dec 2013 17:01:07 -0800
Subject: [R] adding tables
In-Reply-To: <1386633599.28779.33.camel@localhost>
References: <1386633599.28779.33.camel@localhost>
Message-ID: <C60707D2-2AF6-476F-A503-1D607F2113D1@comcast.net>


On Dec 9, 2013, at 3:59 PM, Ross Boylan wrote:

> Can anyone recommend a good way to add tables?
> Ideally I would like
> t1 <- table(x1)
> t2 <- table(x2)
> t1+t2
> 
> It t1 and t2 have the same levels this works fine, but I need something
> that will work even if they differ, e.g.,
>> t1
> 
> 1 2 4 5
> 2 1 1 1
>> t2 <- table(c(10, 11, 12, 13))
>> t1+t2  # apparently does simple vector addition
> 
> 1 2 4 5
> 3 2 2 2
> whereas I want
> 1 2 4 5 10 11 12 13
> 2 1 1 1  1  1  1  1

R contingency tables are really matrices, so the `cbind` matrix-method appears to be what you want: 

cbind(t1,t2)

> 

David Winsemius
Alameda, CA, USA


From ross at biostat.ucsf.edu  Tue Dec 10 03:34:47 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 09 Dec 2013 18:34:47 -0800
Subject: [R] adding tables [solution]
In-Reply-To: <1386634146.28779.37.camel@localhost>
References: <1386633599.28779.33.camel@localhost>
	<1386634146.28779.37.camel@localhost>
Message-ID: <1386642887.28779.65.camel@localhost>

On Mon, 2013-12-09 at 16:09 -0800, Ross Boylan wrote:
> Answering myself...
> On Mon, 2013-12-09 at 15:59 -0800, Ross Boylan wrote:
> > Can anyone recommend a good way to add tables?
> For count data, which were my main concern, it looks as if tabulate with
> nbins will work.  I'm not sure how this works with a cross-classifying
> factor, which I will also need.  It's possible the factor may have
> missing values in some tabulations as well.

By using the levels argument to factor one can ensure that all possible
levels are present.  Then table() will do the right thing.

An example with numbers:
 > t1 <- factor(c(3, 2), levels=1:5)
 > t1
 [1] 3 2
 Levels: 1 2 3 4 5
 > table(t1)
 t1
 1 2 3 4 5
 0 1 1 0 0
This works in arbitrary dimensions.

I figured this out after looking at the code for table, which does the
hard part when there is more than one dimension.

Ross
> 
> For the one dimensional case
>  > t1 <- tabulate(c(1, 2, 2, 4), nbins=5)
>  > t2 <- tabulate(c(2, 3, 5), nbins=5)
>  > t1
>  [1] 1 2 0 1 0
>  > t2
>  [1] 0 1 1 0 1
>  > t1+t2
>  [1] 1 3 1 1 1
> 
> > Ideally I would like
> > t1 <- table(x1)
> > t2 <- table(x2)
> > t1+t2
> > 
> > It t1 and t2 have the same levels this works fine, but I need something
> > that will work even if they differ, e.g.,
> >  > t1
> > 
> >  1 2 4 5
> >  2 1 1 1
> >  > t2 <- table(c(10, 11, 12, 13))
> >  > t1+t2  # apparently does simple vector addition
> > 
> >  1 2 4 5
> >  3 2 2 2
> > whereas I want
> > 1 2 4 5 10 11 12 13
> > 2 1 1 1  1  1  1  1
> > 
> 
>


From kridox at ymail.com  Tue Dec 10 03:42:12 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 10 Dec 2013 11:42:12 +0900
Subject: [R] Multiple Lorenz curves in one diagram - populations with
 different "n"
In-Reply-To: <1386634774.94686.YahooMailNeo@web125002.mail.ne1.yahoo.com>
References: <1386634774.94686.YahooMailNeo@web125002.mail.ne1.yahoo.com>
Message-ID: <CAAcyNCyv3jBfkZ3eOhY7-7FUd4KC96JgHfF1e4AomWrtgbOMaw@mail.gmail.com>

Hello,

Please read:

library(fortune)
fortune('TFM')

Then:
?plot.Lc

HTH,
Pascal


On 10 December 2013 09:19, Patricia Costa <patcostabr at yahoo.com.br> wrote:
>
> Dear R users,
>
> I'm using the "ineq" package to calculate the values of Gini and Lorenz coefficients and to and plot Lorenz graph.
>
> I want to plot on the same diagram, curves from two different populations, that have different "n".
>
> How can I do this?
>
> Best regards,
>
> Patricia
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From smartpink111 at yahoo.com  Tue Dec 10 03:38:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 9 Dec 2013 18:38:30 -0800 (PST)
Subject: [R] adding tables
In-Reply-To: <1386633599.28779.33.camel@localhost>
References: <1386633599.28779.33.camel@localhost> 
Message-ID: <1386643110.66386.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,
May be this helps:
t2 <- table(c(10,11,12,13))
?t1 <-table(c(1,1,2,4,5))
t <- c(t1,t2)
tapply(t,sort(as.numeric(names(t))),sum)

A.K.





On Monday, December 9, 2013 7:01 PM, Ross Boylan <ross at biostat.ucsf.edu> wrote:
Can anyone recommend a good way to add tables?
Ideally I would like
t1 <- table(x1)
t2 <- table(x2)
t1+t2

It t1 and t2 have the same levels this works fine, but I need something
that will work even if they differ, e.g.,
> t1

1 2 4 5
2 1 1 1
> t2 <- table(c(10, 11, 12, 13))
> t1+t2? # apparently does simple vector addition

1 2 4 5
3 2 2 2
whereas I want
1 2 4 5 10 11 12 13
2 1 1 1? 1? 1? 1? 1

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From long_vo_hai at yahoo.com.vn  Tue Dec 10 05:19:53 2013
From: long_vo_hai at yahoo.com.vn (Long Vo)
Date: Mon, 9 Dec 2013 20:19:53 -0800 (PST)
Subject: [R] Splitting a vector
Message-ID: <1386649193293-4681930.post@n4.nabble.com>

Hi, I am quite new to R so I know that this probably is very basic , but how
can I split a sequence of number into multiple parts with equal length?
For example I have a vector

X=c(1:12)
I simply need to split it into sub-vectors with the same length N . Say N=3
then I need the output to be like 
1 2 3
4 5 6
7 8 9
10 11 12

And better if the sub-vectors can be named so that I can use them later for
individual study, probably a do-loop in which a function can be applied to
them.
I just want them to be in consecutive order so really no fancy conditions
here.  

Any helps to this amateur is greatly appreciated,
Long



--
View this message in context: http://r.789695.n4.nabble.com/Splitting-a-vector-tp4681930.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Tue Dec 10 05:51:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 9 Dec 2013 20:51:33 -0800 (PST)
Subject: [R] Splitting a vector
Message-ID: <1386651093.85766.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
split(X,as.numeric(gl(length(X),3,length(X))))
A.K.


Hi, I am quite new to R so I know that this probably is very basic , but how can I split a sequence of number into multiple parts with equal 
length? 
For example I have a vector 

X=c(1:12) 
I simply need to split it into sub-vectors with the same length N . Say N=3 then I need the output to be like 
1 2 3 
4 5 6 
7 8 9 
10 11 12 

And better if the sub-vectors can be named so that I can use 
them later for individual study, probably a do-loop in which a function 
can be applied to them. 
I just want them to be in consecutive order so really no fancy conditions here. ? 

Any helps to this amateur is greatly appreciated, 
Long

From es at enricoschumann.net  Tue Dec 10 08:11:21 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Tue, 10 Dec 2013 08:11:21 +0100
Subject: [R] How can I find nonstandard or control characters in a large
	file?
In-Reply-To: <1386623689473-4681896.post@n4.nabble.com> (andrewH's message of
	"Mon, 9 Dec 2013 13:14:49 -0800 (PST)")
References: <1386623689473-4681896.post@n4.nabble.com>
Message-ID: <87wqjd89k6.fsf@enricoschumann.net>

On Mon, 09 Dec 2013, andrewH <ahoerner at rprogress.org> writes:

> I have a humongous csv file containing census data, far too big to read into
> RAM. I have been trying to extract individual columns from this file using
> the colbycol package. This works for certain subsets of the columns, but not
> for others. I have not yet been able to precisely identify the problem
> columns, as there are 731 columns and running colbycol on the file on my old
> slow machine takes about 6 hours. 
>
> However, my suspicion is that there are some funky characters, either
> control characters or characters with some non-standard encoding, somewhere
> in this 14 gig file. Moreover, I am concerned that these characters may
> cause me trouble down the road even if I use a different approach to getting
> columns out of the file.
>
> Is there an r utility will search through my file without trying to read it
> all into memory at one time and find non-standard characters or misplaced
> (non-end-of-line) control characters? Or some R code to the same end?  Even
> if the real problem ultimately proves top be different, it would be helpful
> to eliminate this possibility. And this is also something I would routinely
> run on files from external sources if I had it. 
>
>  I am working in a windows XP environment, in case that makes a difference.
>
> Any help anyone could offer would be greatly appreciated.
>
> Sincerely, andrewH

You could process your file in chunks:

  f <- file("myfile.csv", open = "r")
  lines <- readLines(f, n = 10000)
  ## do something with lines
  lines <- readLines(f, n = 10000)
  ## do something with lines
  ## ....

To find 'non-standard characters' you will need to define what
'non-standard characters' are.  But perhaps ?tools:::showNonASCII, which
uses ?iconv, can help you.  (Please note the warnings and caveats on the
functions' help pages.)


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From jdnewmil at dcn.davis.CA.us  Tue Dec 10 09:02:39 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 10 Dec 2013 00:02:39 -0800
Subject: [R] Splitting a vector
In-Reply-To: <1386649193293-4681930.post@n4.nabble.com>
References: <1386649193293-4681930.post@n4.nabble.com>
Message-ID: <d1d2a1bf-62d9-4f22-b369-c0883b7c2d57@email.android.com>

You don't need to wrap 1:12 in c().

 Since matrices are just folded vectors, you can convert vector X to a matrix Xm:

Xm <- matrix( X, nrow=3 )

and access columns to get your your sub-vectors:

Xm[,1]
Xm[,2]

and so on.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Long Vo <long_vo_hai at yahoo.com.vn> wrote:
>Hi, I am quite new to R so I know that this probably is very basic ,
>but how
>can I split a sequence of number into multiple parts with equal length?
>For example I have a vector
>
>X=c(1:12)
>I simply need to split it into sub-vectors with the same length N . Say
>N=3
>then I need the output to be like 
>1 2 3
>4 5 6
>7 8 9
>10 11 12
>
>And better if the sub-vectors can be named so that I can use them later
>for
>individual study, probably a do-loop in which a function can be applied
>to
>them.
>I just want them to be in consecutive order so really no fancy
>conditions
>here.  
>
>Any helps to this amateur is greatly appreciated,
>Long
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Splitting-a-vector-tp4681930.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From william108 at gmail.com  Tue Dec 10 10:19:27 2013
From: william108 at gmail.com (Bill)
Date: Tue, 10 Dec 2013 01:19:27 -0800
Subject: [R] read.csv interpreting numbers as factors
Message-ID: <CAJnbHt+bzKkRKoP7p-bDm5N_Xukmw+LZpW47YPewSsWcOdmuLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/6c3731fd/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue Dec 10 11:06:47 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 10 Dec 2013 02:06:47 -0800
Subject: [R] read.csv interpreting numbers as factors
In-Reply-To: <CAJnbHt+bzKkRKoP7p-bDm5N_Xukmw+LZpW47YPewSsWcOdmuLA@mail.gmail.com>
References: <CAJnbHt+bzKkRKoP7p-bDm5N_Xukmw+LZpW47YPewSsWcOdmuLA@mail.gmail.com>
Message-ID: <263bf519-e8f6-4d6d-b399-8adf602e0da2@email.android.com>

It is bad netiquette to hijack an existing thread for a new topic. Please start a new email thread when changing topics.

If your data really consists of what you show, then read.csv won't behave that way. I suggest that you open the file in a text editor and look for odd characters. They may be invisible.

Going out on a limb, you may be trying to read a tab separated file, and if so then you need to use the sep=?\t" argument to read.csv.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Bill <william108 at gmail.com> wrote:
>Why does R interpret a column of numbers in a csv file as a factor when
>using read.csv() and how can I prevent that. The data looks like
>
>9928
>3502
>146
>404
>1831
>686
>249
>
>I tried kick=read.csv("kick.csv",stringsAsFactors =FALSE)
>as well as
>kick=read.csv("kick.csv")
>
>Thanks
>
>
>On Mon, Dec 2, 2013 at 5:16 PM, William Dunlap <wdunlap at tibco.com>
>wrote:
>
>> > It seems so inefficient.
>>
>> But ifelse knows nothing about the expressions given
>> as its second and third arguments -- it only sees their
>> values after they are evaluated.  Even if it could see the
>> expressions, it would not be able to assume that f(x[i])
>> is the same as f(x)[i] or things like
>>    ifelse(x>0, cumsum(x), cumsum(-x))
>> would not work.
>>
>> You can avoid the computing all of f(x) and then extracting
>> a few elements from it by doing something like
>>    x <- c("Wednesday", "Monday", "Wednesday")
>>    z1 <- character(length(x))
>>    z1[x=="Monday"] <- "Mon"
>>    z1[x=="Tuesday"] <- "Tue"
>>    z1[x=="Wednesday"] <- "Wed"
>> or
>>    LongDayNames <- c("Monday","Tuesday","Wednesday")
>>    ShortDayNames <- c("Mon", "Tue", "Wed")
>>    z2 <- character(length(x))
>>    for(i in seq_along(LongDayNames)) {
>>       z2[x==LongDayNames[i]] <- ShortDayNames[i]
>>    }
>>
>> To avoid the repeated x==value[i] you can use match(x, values).
>>    z3 <- ShortDayNames[match(x, LongDayNames)]
>>
>> z1, z2, and z3 are identical  character vectors.
>>
>> Or, you can use factors.
>>    > factor(x, levels=LongDayNames, labels=ShortDayNames)
>>    [1] Wed Mon Wed
>>    Levels: Mon Tue Wed
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>>
>> > -----Original Message-----
>> > From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org]
>> On Behalf
>> > Of Bill
>> > Sent: Monday, December 02, 2013 4:50 PM
>> > To: Duncan Murdoch
>> > Cc: r-help at r-project.org
>> > Subject: Re: [R] ifelse -does it "manage the indexing"?
>> >
>> > It seems so inefficient. I mean the whole first vector will be
>evaluated.
>> > Then if the second if is run the whole vector will be evaluated
>again.
>> Then
>> > if the next if is run the whole vector will be evaluted again. And
>so on.
>> > And this could be only to test the first element (if it is false
>for each
>> > if statement). Then this would be repeated again and again. Is that
>> really
>> > the way it works? Or am I not thinking clearly?
>> >
>> >
>> > On Mon, Dec 2, 2013 at 4:48 PM, Duncan Murdoch
>> > <murdoch.duncan at gmail.com>wrote:
>> >
>> > > On 13-12-02 7:33 PM, Bill wrote:
>> > >
>> > >> ifelse ((day_of_week == "Monday"),1,
>> > >>    ifelse ((day_of_week == "Tuesday"),2,
>> > >>    ifelse ((day_of_week == "Wednesday"),3,
>> > >>    ifelse ((day_of_week == "Thursday"),4,
>> > >>    ifelse ((day_of_week == "Friday"),5,
>> > >>    ifelse ((day_of_week == "Saturday"),6,7)))))))
>> > >>
>> > >>
>> > >>    In code like the above, day_of_week is a vector and so
>day_of_week
>> ==
>> > >> "Monday" will result in a boolean vector. Suppose day_of_week is
>> Monday,
>> > >> Thursday, Friday, Tuesday. So day_of_week == "Monday" will be
>> > >> True,False,False,False. I think that ifelse will test the first
>> element
>> > >> and
>> > >> it will generate a 1. At this point it will not have run
>day_of_week
>> ==
>> > >> "Tuesday" yet. Then it will test the second element of
>day_of_week
>> and it
>> > >> will be false and this will cause it to evaluate day_of_week ==
>> "Tuesday".
>> > >> My question would be, does the evaluation of day_of_week ==
>"Tuesday"
>> > >> result in the generation of an entire boolean vector (which
>would be
>> in
>> > >> this case False,False,False,True) or does the ifelse "manage the
>> indexing"
>> > >> so that it only tests the second element of the original vector
>> (which is
>> > >> Thursday) and for that matter does it therefore not even bother
>to
>> > >> generate
>> > >> the first boolean vector I mentioned above
>(True,False,False,False)
>> but
>> > >> rather just checks the first element?
>> > >>    Not sure if I have explained this well but if you understand
>I
>> would
>> > >> appreciate a reply.
>> > >>
>> > >
>> > > See the help for the function.  If any element of the test is
>true, the
>> > > full first vector will be evaluated.  If any element is false,
>the
>> second
>> > > one will be evaluated.  There are no shortcuts of the kind you
>> describe.
>> > >
>> > > Duncan Murdoch
>> > >
>> > >
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From b.rowlingson at lancaster.ac.uk  Tue Dec 10 11:48:11 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 10 Dec 2013 10:48:11 +0000
Subject: [R] read.csv interpreting numbers as factors
In-Reply-To: <2a202d445e0c4903b12bf853491b488c@EX-0-HT0.lancs.local>
References: <CAJnbHt+bzKkRKoP7p-bDm5N_Xukmw+LZpW47YPewSsWcOdmuLA@mail.gmail.com>
	<2a202d445e0c4903b12bf853491b488c@EX-0-HT0.lancs.local>
Message-ID: <CANVKczM584EvF05G8W9f9FOkqmy-+ZRtv-8s47uwXh6Fd_G8Kg@mail.gmail.com>

On Tue, Dec 10, 2013 at 10:06 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> It is bad netiquette to hijack an existing thread for a new topic. Please start a new email thread when changing topics.
>
> If your data really consists of what you show, then read.csv won't behave that way. I suggest that you open the file in a text editor and look for odd characters. They may be invisible.
>
> Going out on a limb, you may be trying to read a tab separated file, and if so then you need to use the sep=?\t" argument to read.csv.

Or something in the data isn't a valid number. Try:

as.numeric(as.character(factorthingyouthinkshouldbenumbers))

and if you get any NA values then those things aren't valid number
formats. You need as.numeric(as.character(..)) because otherwise
as.numeric just gets the underlying number codes for the factor
levels.


 > f=factor(c("1","1","2","three","4","69"))
 > f
[1] 1     1     2     three 4     69
Levels: 1 2 4 69 three

 > as.numeric(f)
[1] 1 1 2 5 3 4

 > as.numeric(as.character(f))
[1]  1  1  2 NA  4 69
Warning message:
NAs introduced by coercion


From petr.pikal at precheza.cz  Tue Dec 10 12:02:03 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 10 Dec 2013 11:02:03 +0000
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <52A5F415.8050500@gmail.com>
References: <52A1F0D6.9080108@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA52E5@SRVEXCHMBX.precheza.cz>
	<52A1F729.9070302@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5408@SRVEXCHMBX.precheza.cz>
	<CAEN-PDBrJ=ST-Z8Vt8t2-PHdxgZ8VHyLZvjqM_YH+RGLW+SCqw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5A8F@SRVEXCHMBX.precheza.cz>
	<52A5E390.4090106@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5B2D@SRVEXCHMBX.precheza.cz>
	<52A5F415.8050500@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5CAC@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/a737f952/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Tue Dec 10 12:25:59 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 10 Dec 2013 12:25:59 +0100 (MET)
Subject: [R] lattice: superposed boxplots with same colors
	forrectanglesandumbrellas and filled boxes
In-Reply-To: <CAGx1TMAGaJo2w1fCq7WRQ1u+98GXyv9DQUvnUwVN8M_iVhbBcg@mail.gmail.com>
References: <Pine.SOC.4.64.1312092244180.13779@solcom.hrz.uni-giessen.de>
	<CAGx1TMAGaJo2w1fCq7WRQ1u+98GXyv9DQUvnUwVN8M_iVhbBcg@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1312101212160.20839@solcom.hrz.uni-giessen.de>

Thank you very much, Rich, for the fast and very helpful reply! It helped 
me to reach my goal.

  Regards -- Gerrit

PS: I extended your solution to a version that allows slightly finer 
control over the components of the boxplots, in particular if one wants to 
combine it with, e.g., panel.stripplot() or panel.average(). It was also 
possible to simplify my call of bwplot() a bit. The code is certainly not 
perfect and fully tested, but does work (for me ;-)), and follows as a 
little 'thank you':


panel.bwplot.constantColor <- function( ..., col, fill, cex, pch,
                                         dot.pch, umbrella.lty, box.alpha) {
  ## Date: Mon, 9 Dec 2013 17:52:38 -0500
  ## From: Richard M. Heiberger <rmh at temple.edu>
  ## Subject: Re: [R] lattice: superposed boxplots with same colors
  ##          for rectangles and umbrellas and filled boxes

  ## to be included in next version of the HH package
  box.save <- list( box.dot = trellis.par.get( "box.dot"),
                    box.rectangle = trellis.par.get( "box.rectangle"),
                    box.umbrella = trellis.par.get( "box.umbrella"),
                    plot.symbol = trellis.par.get( "plot.symbol"))
  trellis.par.set( box.dot = list( col = col),
                   box.rectangle = list( col = col, alpha = box.alpha),
                   box.umbrella = list( col = col, lty = umbrella.lty,
                                        alpha = box.alpha),
                   plot.symbol = list( col = col))
  panel.bwplot( ..., fill = col, cex = cex, pch = dot.pch)
  trellis.par.set( box.save)
  }


bwplot( Y ~ F1, groups = F2, data = Data, jitter.data = TRUE,
         col = c( "red", "blue"), box.alpha = 1/4,
         dot.pch = 17, umbrella.lty = 1, do.out = FALSE,
         panel = panel.superpose,
         panel.groups = panel.bwplot.constantColor)




> Thank you for the opportunity to illustrate this.  I solved this problem 
> last week and it will be included in the next version of the HH package 
> (about a month away).
>
> panel.bwplot.constantColor <- function(..., col, fill, cex, pch) {
>  ## to be included in next version of the HH package
>  box.save <- list(box.dot=trellis.par.get("box.dot"),
>                   box.rectangle=trellis.par.get("box.rectangle"),
>                   box.umbrella=trellis.par.get("box.umbrella"),
>                   plot.symbol=trellis.par.get("plot.symbol"))
>  trellis.par.set(box.dot=list(col=col),
>                  box.rectangle=list(col=col),
>                  box.umbrella=list(col=col),
>                  plot.symbol=list(col=col))
>  panel.bwplot(..., fill=col, cex=cex, pch=pch)
>  trellis.par.set(box.save)
> }
>
> bwplot( Y ~ F1, groups = F2, data = Data,
>        col = mycolors, fill = mycolors, jitter.data = TRUE, pch=19,
>        panel = panel.superpose,
>        panel.groups = function(..., pch, col, alpha){
>            panel.stripplot(...)
>            panel.bwplot.constantColor(..., pch=pch, col=col,
> alpha=alpha, do.out = FALSE)
>        },
>        par.settings = list( box.dot = list( alpha = myalpha),
>                             box.rectangle = list( col = mycolors,
>                                                   alpha = myalpha),
>                             box.umbrella = list( col = mycolors,
>                                                  alpha = myalpha))
>        )
>
>
> Rich
>
> On Mon, Dec 9, 2013 at 5:17 PM, Gerrit Eichner
> <Gerrit.Eichner at math.uni-giessen.de> wrote:
>> Dear R-list,
>>
>> I've been trying to produce a sort of an interaction plot wherein colored
>> stripplots and boxplots are superposed. In particular, I want the colors of
>> the (transparently) filled boxes to be the same as the colors of the box
>> borders (rectangle) and their whiskers (umbrella). Below I'm going to create
>> an artificial data set and provide the code with which I've come up so far,
>> and which is a fusion and adaptation of a few pieces of code I've found in
>> the help pages and the mail archives. It does almost what I want, but still
>> colors the rectangles and the umbrellas in black (of course, because it is
>> the setting in the example presented below). However, the latter is what I
>> want to change.
>>
>> x <- c( rep( 1:4, each = 10), rep( -2, 40))
>> Data <- data.frame( F1 = gl( 4, 10, length = 80, labels = LETTERS[ 1:4]),
>>                     F2 = gl( 2, 40), Y = x + rnorm( length( x)))
>>
>> mycolors <- c( "red", "blue")
>> myalpha <- 0.33
>> bwplot( Y ~ F1, groups = F2, data = Data,
>>         col = mycolors, fill = mycolors, jitter.data = TRUE,
>>         panel = panel.superpose,
>>         panel.groups = function(..., pch, col, alpha){
>>             panel.stripplot(...)
>>             panel.bwplot(..., do.out = FALSE)
>>         },
>>         par.settings = list( box.dot = list( alpha = myalpha),
>>                              box.rectangle = list( col = "black",
>>                                                    alpha = myalpha),
>>                              box.umbrella = list( col = "black",
>>                                                   alpha = myalpha))
>>         )
>>
>>
>> If I'd provide mycolors instead of "black" to the col-component of the
>> (sub-)lists given to par.settings, the coloring of the respective components
>> of the boxplots would not be what I want. Having studied the code of
>> panel.superpose() and panel.bwplot() it appears to me that panel.bwplot()
>> cannot access the settings created by panel.supperpose when it comes to
>> drawing the rectangle and umbrella of a boxplot. It only accesses box.[dot,
>> rectangle, umbrella], which does not give what I need.
>>
>> I may have overlooked the obvious and would be quite grateful if somebody
>> could give me a hint where to look further. Or is a workaround necessary
>> (and available)?
>>
>> Thanks a lot in advance!
>>
>>  Best Regards  --  Gerrit


From welma.pereira at gmail.com  Tue Dec 10 12:41:39 2013
From: welma.pereira at gmail.com (Welma Pereira)
Date: Tue, 10 Dec 2013 12:41:39 +0100
Subject: [R] Problem to predict new data with mclust
Message-ID: <CAKYukkfygWyyf-6tUfvgrKOuw338sUBt+CSkHigCMjZ0eGQ6Tg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/234ac869/attachment.pl>

From S.Ellison at lgcgroup.com  Tue Dec 10 14:33:21 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Tue, 10 Dec 2013 13:33:21 +0000
Subject: [R] Multiple Lorenz curves in one diagram - populations
	with	different "n"
In-Reply-To: <1386634774.94686.YahooMailNeo@web125002.mail.ne1.yahoo.com>
References: <1386634774.94686.YahooMailNeo@web125002.mail.ne1.yahoo.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED56C9B5A006@GOLD.corp.lgc-group.com>


>I want to plot on the same diagram, curves from two different populations, that have different "n".
>
>How can I do this?

Use lines() as well as plot()

S

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ghoermann at hydrology.uni-kiel.de  Tue Dec 10 14:55:07 2013
From: ghoermann at hydrology.uni-kiel.de (=?ISO-8859-1?Q?Georg_H=F6rmann?=)
Date: Tue, 10 Dec 2013 14:55:07 +0100
Subject: [R] rbind/timestamp problem
Message-ID: <52A71D3B.3050107@hydrology.uni-kiel.de>

Hello world,

I am stuck somehow...
I am trying to add a timestamp to a sensitivity matrix:

#this code works:

sensitivity=data.frame(mtype=1,cdate=2)
sensitivity=rbind(sensitivity,c(mtype=2,cdate=2))

# this code does not work - no idea why

sensitivity=data.frame(mtype=1,cdate=as.POSIXct(Sys.time(), 
origin="1970-01-01"))
sensitivity=rbind(sensitivity,c(mtype=2,cdate=as.POSIXct(Sys.time(), 
origin="1970-01-01")))

Error message:
"Error in as.POSIXct.numeric(value) : 'origin' must be supplied"

Any hints why the second part does not work?

Greetings,
Georg

-- 
Georg Hoermann, Dep. of Hydrology, Ecology, Kiel University, Germany
+49/431/2190916, mo: +49/176/64335754, icq:348340729, skype: ghoermann


From jholtman at gmail.com  Tue Dec 10 15:40:08 2013
From: jholtman at gmail.com (jim holtman)
Date: Tue, 10 Dec 2013 09:40:08 -0500
Subject: [R] rbind/timestamp problem
In-Reply-To: <52A71D3B.3050107@hydrology.uni-kiel.de>
References: <52A71D3B.3050107@hydrology.uni-kiel.de>
Message-ID: <CAAxdm-7wf9S0wp7wTAOZNWaLbGRS7FG0e4bcQuxYvg2ZDajT3A@mail.gmail.com>

try this:

> sensitivity=rbind(sensitivity,data.frame(mtype=2,cdate=as.POSIXct(Sys.time(), origin="1970-01-01")))
> sensitivity
  mtype               cdate
1     1 2013-12-10 09:35:53
2     2 2013-12-10 09:37:02

The 'c' function is coercing to numeric.  If you want to 'rbind' rows
to a dataframe, then make sure you use a dataframe.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Dec 10, 2013 at 8:55 AM, Georg H?rmann
<ghoermann at hydrology.uni-kiel.de> wrote:
> Hello world,
>
> I am stuck somehow...
> I am trying to add a timestamp to a sensitivity matrix:
>
> #this code works:
>
> sensitivity=data.frame(mtype=1,cdate=2)
> sensitivity=rbind(sensitivity,c(mtype=2,cdate=2))
>
> # this code does not work - no idea why
>
> sensitivity=data.frame(mtype=1,cdate=as.POSIXct(Sys.time(),
> origin="1970-01-01"))
> sensitivity=rbind(sensitivity,c(mtype=2,cdate=as.POSIXct(Sys.time(),
> origin="1970-01-01")))
>
> Error message:
> "Error in as.POSIXct.numeric(value) : 'origin' must be supplied"
>
> Any hints why the second part does not work?
>
> Greetings,
> Georg
>
> --
> Georg Hoermann, Dep. of Hydrology, Ecology, Kiel University, Germany
> +49/431/2190916, mo: +49/176/64335754, icq:348340729, skype: ghoermann
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Dec 10 16:02:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 10 Dec 2013 07:02:09 -0800 (PST)
Subject: [R] Add column to DF based on 2 columns in another DF
Message-ID: <1386687729.32530.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
library(reshape2)
m1 <- melt(LookupTable,id.vars="Str")
m2 <- m1

res <- merge(MainDataFrame,m1,by.x=c("Str","index"),by.y=c("Str","variable"))
res[order(res$Str),c(3:6,1:2,7)]

#or
library(plyr)
colnames(m2)[-1] <- c("index","index_num")
?m2$index <- as.character(m2$index)
?join(MainDataFrame,m2,by=c("Str","index"))


A.K.


LookupTable <- read.table(header = TRUE, 
? ? ? ? ? ? ? ? ? ?stringsAsFactors = FALSE, 
? ? ? ? ? ? ? ? ? ?text="Str IND13 IND12 IND11 IND07 IND06 
? ? ? ? ? ? ? ? ? ? ? ? ?1 ? 517 ? 529 ? 562 ? 562 ? 567 
? ? ? ? ? ? ? ? ? ? ? ? ?2 ? 517 ? 529 ? 562 ? 562 ? 568 
? ? ? ? ? ? ? ? ? ? ? ? ?3 ? 517 ? 529 ? 562 ? 562 ? 567 
? ? ? ? ? ? ? ? ? ? ? ? ?4 ? 517 ? 529 ? 562 ? 562 ? 569 
? ? ? ? ? ? ? ? ? ? ? ? ?5 ? 517 ? 529 ? 562 ? 562 ? 567 
? ? ? ? ? ? ? ? ? ? ? ? ?6 ? 517 ? 529 ? 562 ? 562 ? 567 
? ? ? ? ? ? ? ? ? ? ? ? ?7 ? 517 ? 529 ? 562 ? 562 ? 560 
? ? ? ? ? ? ? ? ? ? ? ? ?8 ? 517 ? 529 ? 562 ? 562 ? 567 
? ? ? ? ? ? ? ? ? ? ? ? ?9 ? 517 ? 529 ? 562 ? 562 ? 567 
? ? ? ? ? ? ? ? ? ? ? ? ?10 ? 517 ? 529 ? 562 ? 562 ? 567") 


MainDataFrame <- read.table(header = TRUE, 
? ? ? ? ? ? ? ? ? ? ? ? ? stringsAsFactors = FALSE, 
? ? ? ? ? ? ? ? ? ? ? ? ? text="Pid YEAR MONTH ?Fips Str index 
? ? ? ? ? ? ? ? ? ? ? ? ? ? 600250 2006 ? ? 7 ?6037 ?1 IND06 
? ? ? ? ? ? ? ? ? ? ? ? ? ? 600250 2006 ? ? 7 ?6037 ?2 IND06 
? ? ? ? ? ? ? ? ? ? ? ? ? ? 600250 2006 ? ? 7 ?6037 ?3 IND06 
? ? ? ? ? ? ? ? ? ? ? ? ? ? 600250 2006 ? ? 7 ?6037 ?4 IND06 
? ? ? ? ? ? ? ? ? ? ? ? ? ? 600250 2006 ? ? 7 ?6037 ?5 IND06 
? ? ? ? ? ? ? ? ? ? ? ? ? ? 600353 2007 ? ? 9 48097 ?6 IND07 
? ? ? ? ? ? ? ? ? ? ? ? ? ? 600772 2006 ? ? 2 ?6039 ?7 IND06 
? ? ? ? ? ? ? ? ? ? ? ? ? ? 600947 2007 ? ? 1 13207 ?7 IND07 
? ? ? ? ? ? ? ? ? ? ? ? ? ? 601055 2007 ? ? 9 13315 ?8 IND07 
? ? ? ? ? ? ? ? ? ? ? ? ? ? 601103 2006 ? ? 5 21093 ?10 IND06") 

MainDataFrame_New <- ?? 

#What is the best way to add a new column "index_num" to MainDataFrame that is populated with the 
#number corresponding to 'Str' and 'index' in LookupTable: 

# ? ? ? ? ? ? ? ? ? ? ? ? ? ? Pid YEAR MONTH ?Fips Str index index_num 
# ? ? ? ? ? ? ? ? ? ? ? ? ? ? 600250 2006 ? ? 7 ?6037 ?1 IND06 567 
# ? ? ? ? ? ? ? ? ? ? ? ? ? ? 600250 2006 ? ? 7 ?6037 ?2 IND06 568 
# ? ? ? ? ? ? ? ? ? ? ? ? ? ? 600250 2006 ? ? 7 ?6037 ?3 IND06 567 
# ? ? ? ? ? ? ? ? ? ? ? ? ? ? 600250 2006 ? ? 7 ?6037 ?4 IND06 569 
# ? ? ? ? ? ? ? ? ? ? ? ? ? ? 600250 2006 ? ? 7 ?6037 ?5 IND06 567 
# ? ? ? ? ? ? ? ? ? ? ? ? ? ? 600353 2007 ? ? 9 48097 ?6 IND07 562 
# ? ? ? ? ? ? ? ? ? ? ? ? ? ? 600772 2006 ? ? 2 ?6039 ?7 IND06 560 
# ? ? ? ? ? ? ? ? ? ? ? ? ? ? 600947 2007 ? ? 1 13207 ?7 IND07 562 
# ? ? ? ? ? ? ? ? ? ? ? ? ? ? 601055 2007 ? ? 9 13315 ?8 IND07 562 
# ? ? ? ? ? ? ? ? ? ? ? ? ? ? 601103 2006 ? ? 5 21093 ?10 IND06 567


From efglynn at gmail.com  Tue Dec 10 16:27:02 2013
From: efglynn at gmail.com (Earl F Glynn)
Date: Tue, 10 Dec 2013 09:27:02 -0600
Subject: [R] How can I find nonstandard or control characters in a large
	file?
In-Reply-To: <1386623689473-4681896.post@n4.nabble.com>
References: <1386623689473-4681896.post@n4.nabble.com>
Message-ID: <l87brs$5lq$1@ger.gmane.org>

andrewH wrote:

> However, my suspicion is that there are some funky characters, either
> control characters or characters with some non-standard encoding, somewhere
> in this 14 gig file. Moreover, I am concerned that these characters may
> cause me trouble down the road even if I use a different approach to getting
> columns out of the file.

This is not an R solution, but here's a Windows utility I wrote to 
produce a table of frequency counts for all hex characters x00 to xFF in 
a file.

http://www.efg2.com/Lab/OtherProjects/CharCount.ZIP

Normally, you'll want to scrutinize anything below x20 or above x7F, 
since ASCII printable characters are in the range x20 to x7E. You can 
see how many tab (x09) characters are in the file, and whether the line 
endings are from Linux (x0A) or Windows (paired x0A and x0D).


The ZIP includes Delphi source code, but provides a Windows executable. 
  I made a change several months ago to allow drag-and-drop, so you can 
just drop the file on the application to have the characters counted. 
Just run the EXE after unzipping.  No installation is needed.

Once you find problems characters in the file, you can read the file as 
character data and use sub/gsub or other tools to remove or alter 
problem characters.

efg
Earl F Glynn
UMKC School of Medicine
Center for Health Insights


From sarah.goslee at gmail.com  Tue Dec 10 16:30:06 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 10 Dec 2013 10:30:06 -0500
Subject: [R] Problem to predict new data with mclust
In-Reply-To: <CAKYukkfygWyyf-6tUfvgrKOuw338sUBt+CSkHigCMjZ0eGQ6Tg@mail.gmail.com>
References: <CAKYukkfygWyyf-6tUfvgrKOuw338sUBt+CSkHigCMjZ0eGQ6Tg@mail.gmail.com>
Message-ID: <CAM_vjunS8MKm-6K_cTRb5TGBo8AiKAwmCx-s-T8s14FN9xE5Kg@mail.gmail.com>

Hi,

It's unlikely that anyone will be able to see your problem without a
reproducible example.

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Are you using the mclust package? That would be the first thing we need to know.

Then, have you worked through the examples in ?predict.Mclust, and do
you understand them?

Then, what do your data look like? str() and such are useful, but the
best option is to use dput() to create a reproducible subset, or to
reproduce your problem using one of the built-in datasets in R, as is
done in the above documentation examples.

Sarah

On Tue, Dec 10, 2013 at 6:41 AM, Welma Pereira <welma.pereira at gmail.com> wrote:
> Hi,
>
> I am trying to use mclust to cluster some data (train_pca_10), I get the
> clusters, but when I try to use the model to predict new data (test1) I get
> this error
>
>
>
> mClust2 <- Mclust(train_pca_10,G=2)
> pred<-predict.Mclust(mClust2,test1)
>
> Error in if (warn) warning(WARNING) : argument is of length zero
>
> Can anyone see the problem here?
>
> Thanks,
> Pereira.
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From juliosergio at gmail.com  Tue Dec 10 16:32:36 2013
From: juliosergio at gmail.com (Julio Sergio Santana)
Date: Tue, 10 Dec 2013 15:32:36 +0000
Subject: [R] Using assign with mapply
References: <loom.20131206T200836-152@post.gmane.org>
	<B8148731-8E6B-41D7-8391-134D30CCFB03@comcast.net>
Message-ID: <loom.20131210T161915-741@post.gmane.org>

David Winsemius <dwinsemius <at> comcast.net> writes:

> So what happens if you try this:
> 
> mapply(assign,  kkk$vars, kkk$vals, MoreArgs = list(envir = .GlobalEnv)
> 

Yes, it works in certain situations, as well as the equivalent code:

     kkk <- data.frame(vars=c("var1", "var2", "var3"), 
                  vals=c(10, 20, 30), stringsAsFactors=F)

     mapply(assign,  kkk$vars, kkk$vals, MoreArgs = list(pos = 1))
     var1
    [1] 10

See, however, the following example

    : example <- function () {
        var1 <- 250
        kkk <- data.frame(vars=c("var1", "var2", "var3"), 
                      vals=c(10, 20, 30), stringsAsFactors=F)
        mapply(assign,  kkk$vars, kkk$vals, MoreArgs = list(pos = 1))
        print (var2)
        print (var1)
      }
 
      example()
     [1] 20
     [1] 250

My question is: how to get the combination of mapply and assign to affect 
the variables defined in the block where the construction is executed?

Maybe there is still something I don't understand.


Thanks,

  -Sergio.


From careyshan at gmail.com  Tue Dec 10 16:35:48 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 10 Dec 2013 15:35:48 +0000
Subject: [R] 3-D interpretation
Message-ID: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/7d1d3983/attachment.pl>

From sarah.goslee at gmail.com  Tue Dec 10 16:41:21 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 10 Dec 2013 10:41:21 -0500
Subject: [R] 3-D interpretation
In-Reply-To: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
Message-ID: <CAM_vjum7vCCfPBJkNeCt_2gP5nT2TEeBXUwdUD-6xf9ZyPWtxg@mail.gmail.com>

Hi Shane,

On Tue, Dec 10, 2013 at 10:35 AM, Shane Carey <careyshan at gmail.com> wrote:
> Hi,
>
> im trying to create a 3-D interpretation of a geological fault using
> the akima package. But my code fails below highlighted in red:
> Does anyone have any ideas why this is.

This is a plain-text email list, so no highlighting in red is available.

More importantly, you should take a look at:

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

and provide a simple example with data that demonstrates your problem.

Sarah

>
> Thanks
>
> dat<-read.delim("D:\\fault.txt",header=T,sep=",")
> library(rgl)
> # data
> rgl.spheres(dat$X,dat$Z , dat$Y,1,color="red")
> rgl.bbox()
> # bivariate linear interpolation
> # interp:
> akima.li <- interp(dat$X, dat$Y, dat$Z,
>                    xo=seq(min(dat$X), max(dat$X), length = 100),
>                    yo=seq(min(dat$Y), max(dat$Y), length = 100))
>
> This is my error:
> Error in interp.old(x, y, z, xo = xo, yo = yo, ncp = 0, extrap = extrap,  :
> duplicate data points: need to set 'duplicate = ..'
>
> # interp surface:
> rgl.surface(akima.li$X,akima.li$Y,akima.li$Z,color="green",alpha=c(0.5))
> # interpp:
> akima.p <- interpp(dat$X, dat$Y, dat$Z,
>                    runif(200,min(dat$X),max(dat$X)),
>                    runif(200,min(dat$Y),max(dat$Y)))
> # interpp points:
> rgl.points(akima.p$X,akima.p$Z , akima.p$Y,size=4,color="yellow")
> # bivariate spline interpolation
> # data
> rgl.spheres(dat$X,dat$Z ,dat$Y,0.5,color="red")
> rgl.bbox()
> # bivariate cubic spline interpolation
> # interp:
> akima.si <- interp(dat$X, dat$Y, dat$Z,
>                    xo=seq(min(dat$X), max(dat$X), length = 100),
>                    yo=seq(min(dat$Y), max(dat$Y), length = 100),
>                    linear = FALSE, extrap = TRUE)
>
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From careyshan at gmail.com  Tue Dec 10 16:42:16 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 10 Dec 2013 15:42:16 +0000
Subject: [R] 3-D interpretation
In-Reply-To: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
Message-ID: <CA+jRDxBdj=CAd=7v8NFVJF+YOa3E4zBYrZ0VZHeLhU+mmP457A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/8e4ef4f0/attachment.pl>

From sarah.goslee at gmail.com  Tue Dec 10 16:48:37 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 10 Dec 2013 10:48:37 -0500
Subject: [R] 3-D interpretation
In-Reply-To: <CA+jRDxBdj=CAd=7v8NFVJF+YOa3E4zBYrZ0VZHeLhU+mmP457A@mail.gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
	<CA+jRDxBdj=CAd=7v8NFVJF+YOa3E4zBYrZ0VZHeLhU+mmP457A@mail.gmail.com>
Message-ID: <CAM_vju=sT0-1RO_Hxt8upSGDTqBLz5J3TT=KmeaUAPA=-1ME3g@mail.gmail.com>

Hi,

On Tue, Dec 10, 2013 at 10:42 AM, Shane Carey <careyshan at gmail.com> wrote:
> Hi, I have since solved that problem,

It would be useful to post the solution, for the archives, so that
others with the same problem can benefit from your insight.


> but now R keeps crashing. I have over 20,000 points. Can R handle that
> amount?

R can. Your computer may not be able to.

But again, we don't have enough information to answer you, since that
depends on OS, available RAM, etc.

Sarah

>
> Cheers
>
>
> On Tue, Dec 10, 2013 at 3:35 PM, Shane Carey <careyshan at gmail.com> wrote:
>
>> Hi,
>>
>> im trying to create a 3-D interpretation of a geological fault using
>> the akima package. But my code fails below highlighted in red:
>> Does anyone have any ideas why this is.
>>
>> Thanks
>>
>> dat<-read.delim("D:\\fault.txt",header=T,sep=",")
>> library(rgl)
>> # data
>> rgl.spheres(dat$X,dat$Z , dat$Y,1,color="red")
>> rgl.bbox()
>> # bivariate linear interpolation
>> # interp:
>> akima.li <- interp(dat$X, dat$Y, dat$Z,
>>                    xo=seq(min(dat$X), max(dat$X), length = 100),
>>                    yo=seq(min(dat$Y), max(dat$Y), length = 100))
>>
>> This is my error:
>> Error in interp.old(x, y, z, xo = xo, yo = yo, ncp = 0, extrap = extrap,
>>  :
>> duplicate data points: need to set 'duplicate = ..'
>>
>> # interp surface:
>> rgl.surface(akima.li$X,akima.li$Y,akima.li$Z,color="green",alpha=c(0.5))
>> # interpp:
>> akima.p <- interpp(dat$X, dat$Y, dat$Z,
>>                    runif(200,min(dat$X),max(dat$X)),
>>                    runif(200,min(dat$Y),max(dat$Y)))
>> # interpp points:
>> rgl.points(akima.p$X,akima.p$Z , akima.p$Y,size=4,color="yellow")
>> # bivariate spline interpolation
>> # data
>> rgl.spheres(dat$X,dat$Z ,dat$Y,0.5,color="red")
>> rgl.bbox()
>> # bivariate cubic spline interpolation
>> # interp:
>> akima.si <- interp(dat$X, dat$Y, dat$Z,
>>                    xo=seq(min(dat$X), max(dat$X), length = 100),
>>                    yo=seq(min(dat$Y), max(dat$Y), length = 100),
>>                    linear = FALSE, extrap = TRUE)
>>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From careyshan at gmail.com  Tue Dec 10 17:17:55 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 10 Dec 2013 16:17:55 +0000
Subject: [R] 3-D interpretation
In-Reply-To: <CAM_vju=sT0-1RO_Hxt8upSGDTqBLz5J3TT=KmeaUAPA=-1ME3g@mail.gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
	<CA+jRDxBdj=CAd=7v8NFVJF+YOa3E4zBYrZ0VZHeLhU+mmP457A@mail.gmail.com>
	<CAM_vju=sT0-1RO_Hxt8upSGDTqBLz5J3TT=KmeaUAPA=-1ME3g@mail.gmail.com>
Message-ID: <CA+jRDxCY3YGzp8H_T6xemXACagwGuVQPXGL2UCJF8fNQOhwcyA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/fd14545d/attachment.pl>

From dcarlson at tamu.edu  Tue Dec 10 17:28:14 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 10 Dec 2013 10:28:14 -0600
Subject: [R] 3-D interpretation
In-Reply-To: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
Message-ID: <021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>

The error says you have duplicate points in dat so you need to
set duplicate= to tell interp() how to handle them.

?interp

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Shane Carey
Sent: Tuesday, December 10, 2013 9:36 AM
To: r-help at r-project.org
Subject: [R] 3-D interpretation

Hi,

im trying to create a 3-D interpretation of a geological fault
using
the akima package. But my code fails below highlighted in red:
Does anyone have any ideas why this is.

Thanks

dat<-read.delim("D:\\fault.txt",header=T,sep=",")
library(rgl)
# data
rgl.spheres(dat$X,dat$Z , dat$Y,1,color="red")
rgl.bbox()
# bivariate linear interpolation
# interp:
akima.li <- interp(dat$X, dat$Y, dat$Z,
                   xo=seq(min(dat$X), max(dat$X), length = 100),
                   yo=seq(min(dat$Y), max(dat$Y), length = 100))

This is my error:
Error in interp.old(x, y, z, xo = xo, yo = yo, ncp = 0, extrap =
extrap,  :
duplicate data points: need to set 'duplicate = ..'

# interp surface:
rgl.surface(akima.li$X,akima.li$Y,akima.li$Z,color="green",alpha
=c(0.5))
# interpp:
akima.p <- interpp(dat$X, dat$Y, dat$Z,
                   runif(200,min(dat$X),max(dat$X)),
                   runif(200,min(dat$Y),max(dat$Y)))
# interpp points:
rgl.points(akima.p$X,akima.p$Z ,
akima.p$Y,size=4,color="yellow")
# bivariate spline interpolation
# data
rgl.spheres(dat$X,dat$Z ,dat$Y,0.5,color="red")
rgl.bbox()
# bivariate cubic spline interpolation
# interp:
akima.si <- interp(dat$X, dat$Y, dat$Z,
                   xo=seq(min(dat$X), max(dat$X), length = 100),
                   yo=seq(min(dat$Y), max(dat$Y), length = 100),
                   linear = FALSE, extrap = TRUE)






-- 
Shane

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From careyshan at gmail.com  Tue Dec 10 17:29:54 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 10 Dec 2013 16:29:54 +0000
Subject: [R] 3-D interpretation
In-Reply-To: <021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
	<021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>
Message-ID: <CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/302c8d10/attachment.pl>

From dcarlson at tamu.edu  Tue Dec 10 17:32:52 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 10 Dec 2013 10:32:52 -0600
Subject: [R] 3-D interpretation
In-Reply-To: <CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>	<021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>
	<CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>
Message-ID: <024301cef5c5$78fa6000$6aef2000$@tamu.edu>

I guess you will have to give us a reproducible example. 
Are you still getting the same error message?

David

From: Shane Carey [mailto:careyshan at gmail.com] 
Sent: Tuesday, December 10, 2013 10:30 AM
To: dcarlson at tamu.edu
Cc: r-help at r-project.org
Subject: Re: [R] 3-D interpretation

Hey David,

I set it equal to the mean.?duplicate="mean"

but still no joy,
Thanks

On Tue, Dec 10, 2013 at 4:28 PM, David Carlson
<dcarlson at tamu.edu> wrote:
The error says you have duplicate points in dat so you need to
set duplicate= to tell interp() how to handle them.

?interp

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Shane Carey
Sent: Tuesday, December 10, 2013 9:36 AM
To: r-help at r-project.org
Subject: [R] 3-D interpretation

Hi,

im trying to create a 3-D interpretation of a geological fault
using
the akima package. But my code fails below highlighted in red:
Does anyone have any ideas why this is.

Thanks

dat<-read.delim("D:\\fault.txt",header=T,sep=",")
library(rgl)
# data
rgl.spheres(dat$X,dat$Z , dat$Y,1,color="red")
rgl.bbox()
# bivariate linear interpolation
# interp:
akima.li <- interp(dat$X, dat$Y, dat$Z,
? ? ? ? ? ? ? ? ? ?xo=seq(min(dat$X), max(dat$X), length = 100),
? ? ? ? ? ? ? ? ? ?yo=seq(min(dat$Y), max(dat$Y), length = 100))

This is my error:
Error in interp.old(x, y, z, xo = xo, yo = yo, ncp = 0, extrap =
extrap, ?:
duplicate data points: need to set 'duplicate = ..'

# interp surface:
rgl.surface(akima.li$X,akima.li$Y,akima.li$Z,color="green",alpha
=c(0.5))
# interpp:
akima.p <- interpp(dat$X, dat$Y, dat$Z,
? ? ? ? ? ? ? ? ? ?runif(200,min(dat$X),max(dat$X)),
? ? ? ? ? ? ? ? ? ?runif(200,min(dat$Y),max(dat$Y)))
# interpp points:
rgl.points(akima.p$X,akima.p$Z ,
akima.p$Y,size=4,color="yellow")
# bivariate spline interpolation
# data
rgl.spheres(dat$X,dat$Z ,dat$Y,0.5,color="red")
rgl.bbox()
# bivariate cubic spline interpolation
# interp:
akima.si <- interp(dat$X, dat$Y, dat$Z,
? ? ? ? ? ? ? ? ? ?xo=seq(min(dat$X), max(dat$X), length = 100),
? ? ? ? ? ? ? ? ? ?yo=seq(min(dat$Y), max(dat$Y), length = 100),
? ? ? ? ? ? ? ? ? ?linear = FALSE, extrap = TRUE)






--
Shane
? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.




-- 
Shane 


From careyshan at gmail.com  Tue Dec 10 17:34:15 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 10 Dec 2013 16:34:15 +0000
Subject: [R] 3-D interpretation
In-Reply-To: <024301cef5c5$78fa6000$6aef2000$@tamu.edu>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
	<021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>
	<CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>
	<024301cef5c5$78fa6000$6aef2000$@tamu.edu>
Message-ID: <CA+jRDxBuxxASSkRk2uCZ0F+N1YaXpfKhGanWf7xdBSfnW1uSMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/a59cd82e/attachment.pl>

From ghoermann at hydrology.uni-kiel.de  Tue Dec 10 17:57:04 2013
From: ghoermann at hydrology.uni-kiel.de (=?ISO-8859-1?Q?Georg_H=F6rmann?=)
Date: Tue, 10 Dec 2013 17:57:04 +0100
Subject: [R] rbind/timestamp problem
In-Reply-To: <CAAxdm-7wf9S0wp7wTAOZNWaLbGRS7FG0e4bcQuxYvg2ZDajT3A@mail.gmail.com>
References: <52A71D3B.3050107@hydrology.uni-kiel.de>
	<CAAxdm-7wf9S0wp7wTAOZNWaLbGRS7FG0e4bcQuxYvg2ZDajT3A@mail.gmail.com>
Message-ID: <52A747E0.6020308@hydrology.uni-kiel.de>

Thank you,

now it works. I would never have never found the source of the problem. 
I am trying
to build a data frame with results from a sensitivity analysis
for a model. I use rbind because the number of rows is
unkown and i use the timestamp as a hint for the students
that they do not analyse data from last week :-).
Anyway, thank you very much, it helped a lot.

Greetings,
Georg


On 10.12.2013 15:40, jim holtman wrote:
> try this:
>
>> sensitivity=rbind(sensitivity,data.frame(mtype=2,cdate=as.POSIXct(Sys.time(), origin="1970-01-01")))
>> sensitivity
>    mtype               cdate
> 1     1 2013-12-10 09:35:53
> 2     2 2013-12-10 09:37:02
>
> The 'c' function is coercing to numeric.  If you want to 'rbind' rows
> to a dataframe, then make sure you use a dataframe.
>
> Jim Holtman
> Data Munger Guru


-- 
Georg Hoermann,
Department of Hydrology and Water Resources Management
Kiel University, Germany
+49/431/2190916, mo: +49/176/64335754, icq:348340729, skype: ghoermann


From kehld at ktk.pte.hu  Tue Dec 10 19:27:45 2013
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?D=E1niel_Kehl?=)
Date: Tue, 10 Dec 2013 18:27:45 +0000
Subject: [R] growth curve estimation
In-Reply-To: <18A873B2-92FE-461A-8713-DCDE4213CB4F@comcast.net>
References: <33D76D77E9AC4B438DA38B348ED6890D0B90662B@EMAIL.ktkdom.pte.hu>,
	<18A873B2-92FE-461A-8713-DCDE4213CB4F@comcast.net>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B90B0A3@EMAIL.ktkdom.pte.hu>

Dear Vito, Robert and David,

thank you for your replies, although I made some step forward on my own, your answers helped a lot and gave me more insight.
The only question I have left is why this code gives me an error (and that is what David asked for):

m1 <- lms(BMI,age,data=adatok_fiu, cent=c(3,10,25,50,75,90,97), families="BCCG")
centiles.pred(m1, xname="age", xvalues=seq(10,20,.5), cent=c(3,10,25,50,75,90,97))
Error in X[onlydata, , drop = FALSE] : 
  (subscript) logical subscript too long

but

m3 <- gamlss(BMI~pb(age), sigma.formula=~pb(age), nu.formula = ~pb(age), tau.formula = ~pb(age), family=BCT, data=adatok_fiu)
centiles.pred(m3, xname="age", xvalues=seq(10,20,.5), cent=c(3,10,25,50,75,90,97))

works as expected (although I get a warning message
Warning message:
In predict.gamlss(obj, what = "tau", newdata = newx, type = "response",  :
  There is a discrepancy  between the original and the re-fit 
 used to achieve 'safe' predictions 


I had the feeling centiles.pred should work for the result of an lms() function just like in case of gamlss().

Thank you all again!

daniel

________________________________________
Felad?: David Winsemius [dwinsemius at comcast.net]
K?ldve: 2013. december 9. 21:40
To: D?niel Kehl
Cc: r-help at r-project.org
T?rgy: Re: [R] growth curve estimation

On Dec 8, 2013, at 7:45 AM, D?niel Kehl wrote:

> Dear Community,
>
> I am struggling with a growth curve estimation problem. It is a classic BMI change with age calculation. I am not an expert of this field but have some statistical experience in other fields.
> Of course I started reading classical papers related to the topic and understood the concept of the LMS method. After that I thought it will be a "piece of cake", R must have a package related to the topic, so I just need the data and I am just a few lines of code from the results.
>

You might want to look at a more recent discussion:

http://www.who.int/entity/childgrowth/standards/velocity/tr3chap_2.pdf

(The WHO centre has published their R code.)


> I encountered some problems:
> - found at least three packages related to LMS: gamlss, VGAM and an old one lmsqreg (I did not try this because it does not support my R version (3.0.1.))
> - it was relatively easy to get plots of percentiles in both packages, although they were far not the same (I also tried an other software, LMSchartmaker it gave different results from the previous ones)
> - I tried to get tables of predicted values (with the predict function in VGAM and with centiles.pre in gamlss) but without any success.

Don't see any code or error messages.

> - I tried to use the function gamlss() instead of lms() in gamlss but I could not force them to give the same (or very similar results), but the centiles.pred() function did work as expected for the model resulted from galmss()
> - lms gives really different results if k is specified different ways, which is "best"?

Won't that depend on the amount and distribution of the data?

>
> Also I have a general question: some publications state they estimated the centiles so that aroun 18 years of age the curves pass through certain points. How is that possible?
>
> Thank you for any suggestions or insights about the methods or preferred package!
>
> Here is my code (without data):
>
> #####gamlss
> library(gamlss)
> library(VGAM)
> library(foreign)
> adatok <- read.spss("MDSZ adatok.sav", to.data.frame=TRUE)
>
> adatok_fiu <- subset(adatok, adatok$gender == "Fi?k")[,2:3]
> row.names(adatok_fiu) <- NULL
> adatok_lany <- subset(adatok, adatok$gender == "L?nyok")[,2:3]
> row.names(adatok_lany) <- NULL
>
> m1 <- lms(BMI,age,data=adatok_fiu, cent=c(3,10,25,50,75,90,97), families="BCCG")
> fittedPlot(m1, x=adatok_fiu$age)
> m1 <- lms(BMI,age,data=adatok_fiu, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC", k=log(1455))
> fittedPlot(m1, x=adatok_fiu$age)
> m1 <- lms(BMI,age,data=adatok_fiu, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC")
> fittedPlot(m1, x=adatok_fiu$age)
>
> m2 <- lms(BMI,age,data=adatok_lany, cent=c(3,10,25,50,75,90,97), families="BCCG")
> m2 <- lms(BMI,age,data=adatok_lany, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC", k=log(1144))
> m2 <- lms(BMI,age,data=adatok_lany, cent=c(3,10,25,50,75,90,97), families="BCCG", method.pb="GAIC")
>
> m3 <- gamlss(BMI~age, family=BCT, data=adatok_fiu)
> centiles(m3,xvar=adatok_fiu$age, cent=c(3,10,25,50,75,90,97))
>
> newx <- seq(12,20,.5)
>
> centiles.pred(m1, xname="age", xvalues=newx)
> centiles.pred(m3, xname="age", xvalues=newx)
> centiles(m1,adatok_fiu$age)
>
> #####VGAM
> library(foreign)
> library(VGAM)
> library(VGAMdata)
>
> adatok <- read.spss("MDSZ adatok.sav", to.data.frame=TRUE)
>
> adatok_fiu <- subset(adatok, adatok$gender == "Fi?k")
> adatok_lany <- subset(adatok, adatok$gender == "L?nyok")
>
> fit1 <- vgam(BMI ~ s(age), lms.bcn(percentiles = c(3, 10, 25, 50, 75, 90, 97)), adatok_fiu)
> fit2 <- vgam(BMI ~ s(age), lms.bcn(percentiles = c(3, 10, 25, 50, 75, 90, 97)), adatok_lany)
>
> qtplot(fit1, percentiles = c(3, 10, 25, 50, 75, 90, 97), xlim = c(10.5, 20.5), ylim=c(13,34),
>       las = 1, ylab = "BMI", lcol = 4, pch=NA)
>
> qtplot(fit2, percentiles = c(3, 10, 25, 50, 75, 90, 97), xlim = c(10.5, 20.5), ylim=c(13,34),
>       las = 1, ylab = "BMI", lcol = 3, add=TRUE, pch=NA, label=FALSE)
>
>
> Thank you:
> Daniel
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From guncelduzgun at hotmail.com  Tue Dec 10 20:08:11 2013
From: guncelduzgun at hotmail.com (gncl dzgn)
Date: Tue, 10 Dec 2013 21:08:11 +0200
Subject: [R] If-statement in for-loop
Message-ID: <DUB110-W1186D29CC73B6767F3582AFCED20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/0e138e82/attachment.pl>

From E.Vettorazzi at uke.de  Tue Dec 10 20:10:04 2013
From: E.Vettorazzi at uke.de (Eik Vettorazzi)
Date: Tue, 10 Dec 2013 20:10:04 +0100
Subject: [R] adding tables
In-Reply-To: <1386633599.28779.33.camel@localhost>
References: <1386633599.28779.33.camel@localhost>
Message-ID: <52A7670C.3040808@uke.de>

How about this:
t2 <- table(c(10,11,12,13))
t1 <-table(c(1,1,2,4,5))
t12<-(rbind(as.data.frame(t1),as.data.frame(t2)))
xtabs(Freq~.,t12)

it works for "overlapping" tables

t2 <- table(c(10,11,12,13,1,2))
t1 <-table(c(1,1,2,4,5,11,12))
t12<-(rbind(as.data.frame(t1),as.data.frame(t2)))
xtabs(Freq~.,t12)

and it will work for two-dimensional tables as well:

t2 <- table(c(10,11,12,13),letters[rep(1:2,each=2)])
t1 <-table(c(1,1,2,4,5),letters[rep(c(1,3),length.out=5)])
t12a<-(rbind(as.data.frame(t1),as.data.frame(t2)))
xtabs(Freq~.,t12a)

cheers.

Am 10.12.2013 00:59, schrieb Ross Boylan:
> Can anyone recommend a good way to add tables?
> Ideally I would like
> t1 <- table(x1)
> t2 <- table(x2)
> t1+t2
> 
> It t1 and t2 have the same levels this works fine, but I need something
> that will work even if they differ, e.g.,
>  > t1
> 
>  1 2 4 5
>  2 1 1 1
>  > t2 <- table(c(10, 11, 12, 13))
>  > t1+t2  # apparently does simple vector addition
> 
>  1 2 4 5
>  3 2 2 2
> whereas I want
> 1 2 4 5 10 11 12 13
> 2 1 1 1  1  1  1  1
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790
--

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From welma.pereira at gmail.com  Tue Dec 10 21:26:01 2013
From: welma.pereira at gmail.com (Welma Pereira)
Date: Tue, 10 Dec 2013 21:26:01 +0100
Subject: [R] Problem to predict new data with mclust
In-Reply-To: <CAKYukkc_xTvdqVqeGfOXFkKoa2FTbYqNmvP0xNsvf2V0g6ywjQ@mail.gmail.com>
References: <CAKYukkfygWyyf-6tUfvgrKOuw338sUBt+CSkHigCMjZ0eGQ6Tg@mail.gmail.com>
	<CAM_vjunS8MKm-6K_cTRb5TGBo8AiKAwmCx-s-T8s14FN9xE5Kg@mail.gmail.com>
	<CAKYukkc_xTvdqVqeGfOXFkKoa2FTbYqNmvP0xNsvf2V0g6ywjQ@mail.gmail.com>
Message-ID: <CAKYukkeRyKO3z95p8Ff+3XS7yKGr9-axghAVWm_+xeFSe5terw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/4fc6e48d/attachment.pl>

From sarah.goslee at gmail.com  Tue Dec 10 21:27:26 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 10 Dec 2013 15:27:26 -0500
Subject: [R] Problem to predict new data with mclust
In-Reply-To: <CAKYukkc_xTvdqVqeGfOXFkKoa2FTbYqNmvP0xNsvf2V0g6ywjQ@mail.gmail.com>
References: <CAKYukkfygWyyf-6tUfvgrKOuw338sUBt+CSkHigCMjZ0eGQ6Tg@mail.gmail.com>
	<CAM_vjunS8MKm-6K_cTRb5TGBo8AiKAwmCx-s-T8s14FN9xE5Kg@mail.gmail.com>
	<CAKYukkc_xTvdqVqeGfOXFkKoa2FTbYqNmvP0xNsvf2V0g6ywjQ@mail.gmail.com>
Message-ID: <CAM_vjukQLgBE-Ar69BuNj8YkJAjHUQY-4Ri_9Jfe8cM2MvnTAw@mail.gmail.com>

Many people do not want to download and open random attachments.
That's why I suggested dput() with part of your data.

dput(head(yourdata, 20))

is enough for many problems, though it's good to try it out.

Or use one of the datasets built into R.

Sarah


On Tue, Dec 10, 2013 at 3:23 PM, Welma Pereira <welma.pereira at gmail.com> wrote:
> Hi,
>
> Thanks for the hint Sarah. So here is my problem again: (files train_pca is
> in train_pca and test is in test_pca attached)
>
> mclust2_pca <- Mclust(train_pca,G=2, modelNames= c("EII", "VII", "EEI",
> "EVI", "VEI", "VVI"))
> pred<-predict.Mclust(mclust2_pca,test)
> Warning message:
> In cdensVVI(data = c(2.80217508052409, 2.75071740560707, 2.6175058179515,  :
>   cannot compute E-step
>
> Thanks!
>
>
> On 10 December 2013 16:30, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> It's unlikely that anyone will be able to see your problem without a
>> reproducible example.
>>
>>
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>
>> Are you using the mclust package? That would be the first thing we need to
>> know.
>>
>> Then, have you worked through the examples in ?predict.Mclust, and do
>> you understand them?
>>
>> Then, what do your data look like? str() and such are useful, but the
>> best option is to use dput() to create a reproducible subset, or to
>> reproduce your problem using one of the built-in datasets in R, as is
>> done in the above documentation examples.
>>
>> Sarah
>>
>> On Tue, Dec 10, 2013 at 6:41 AM, Welma Pereira <welma.pereira at gmail.com>
>> wrote:
>> > Hi,
>> >
>> > I am trying to use mclust to cluster some data (train_pca_10), I get the
>> > clusters, but when I try to use the model to predict new data (test1) I
>> > get
>> > this error
>> >
>> >
>> >
>> > mClust2 <- Mclust(train_pca_10,G=2)
>> > pred<-predict.Mclust(mClust2,test1)
>> >
>> > Error in if (warn) warning(WARNING) : argument is of length zero
>> >
>> > Can anyone see the problem here?
>> >
>> > Thanks,
>> > Pereira.
>> >


From catferreira at gmail.com  Tue Dec 10 21:44:28 2013
From: catferreira at gmail.com (Catarina Ferreira)
Date: Tue, 10 Dec 2013 15:44:28 -0500
Subject: [R] Get average model after dredge function ran in a loop
Message-ID: <CAAiga1sKpKS9aQHYs+RNrBWJxmxhRf3qn6DgaEN1P8QSt-293w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/fd14cab0/attachment.pl>

From wandrson01 at gmail.com  Tue Dec 10 22:39:45 2013
From: wandrson01 at gmail.com (Walter Anderson)
Date: Tue, 10 Dec 2013 15:39:45 -0600
Subject: [R] Need help figuring out sapply (and similar functions) with
 multiple parameter user defined function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5CAC@SRVEXCHMBX.precheza.cz>
References: <52A1F0D6.9080108@gmail.com>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA52E5@SRVEXCHMBX.precheza.cz>	<52A1F729.9070302@gmail.com>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5408@SRVEXCHMBX.precheza.cz>
	<CAEN-PDBrJ=ST-Z8Vt8t2-PHdxgZ8VHyLZvjqM_YH+RGLW+SCqw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5A8F@SRVEXCHMBX.precheza.cz>
	<52A5E390.4090106@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5B2D@SRVEXCHMBX.precheza.cz>
	<52A5F415.8050500@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA5CAC@SRVEXCHMBX.precheza.cz>
Message-ID: <52A78A21.8050504@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/620a26f6/attachment.pl>

From bcrombie at utk.edu  Tue Dec 10 15:46:02 2013
From: bcrombie at utk.edu (bcrombie)
Date: Tue, 10 Dec 2013 06:46:02 -0800 (PST)
Subject: [R] Add column to DF based on 2 columns in another DF
Message-ID: <1386686762723-4681950.post@n4.nabble.com>

LookupTable <- read.table(header = TRUE, 
                   stringsAsFactors = FALSE, 
                   text="Str IND13 IND12 IND11 IND07 IND06
                         1   517   529   562   562   567
                         2   517   529   562   562   568
                         3   517   529   562   562   567
                         4   517   529   562   562   569
                         5   517   529   562   562   567
                         6   517   529   562   562   567
                         7   517   529   562   562   560
                         8   517   529   562   562   567
                         9   517   529   562   562   567
                         10   517   529   562   562   567")


MainDataFrame <- read.table(header = TRUE, 
                          stringsAsFactors = FALSE, 
                          text="Pid YEAR MONTH  Fips Str index
                            600250 2006     7  6037  1 IND06
                            600250 2006     7  6037  2 IND06
                            600250 2006     7  6037  3 IND06
                            600250 2006     7  6037  4 IND06
                            600250 2006     7  6037  5 IND06
                            600353 2007     9 48097  6 IND07
                            600772 2006     2  6039  7 IND06
                            600947 2007     1 13207  7 IND07
                            601055 2007     9 13315  8 IND07
                            601103 2006     5 21093  10 IND06")

MainDataFrame_New <- ??

#What is the best way to add a new column "index_num" to MainDataFrame that
is populated with the
#number corresponding to 'Str' and 'index' in LookupTable:

#                             Pid YEAR MONTH  Fips Str index index_num
#                             600250 2006     7  6037  1 IND06 567
#                             600250 2006     7  6037  2 IND06 568
#                             600250 2006     7  6037  3 IND06 567
#                             600250 2006     7  6037  4 IND06 569
#                             600250 2006     7  6037  5 IND06 567
#                             600353 2007     9 48097  6 IND07 562
#                             600772 2006     2  6039  7 IND06 560
#                             600947 2007     1 13207  7 IND07 562
#                             601055 2007     9 13315  8 IND07 562
#                             601103 2006     5 21093  10 IND06 567



--
View this message in context: http://r.789695.n4.nabble.com/Add-column-to-DF-based-on-2-columns-in-another-DF-tp4681950.html
Sent from the R help mailing list archive at Nabble.com.


From bcrombie at utk.edu  Tue Dec 10 20:32:47 2013
From: bcrombie at utk.edu (bcrombie)
Date: Tue, 10 Dec 2013 11:32:47 -0800 (PST)
Subject: [R] Add column to DF based on 2 columns in another DF
In-Reply-To: <1386687729.32530.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1386686762723-4681950.post@n4.nabble.com>
	<1386687729.32530.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1386703967243-4681969.post@n4.nabble.com>

Thanks, AK. That gets the job done and I learned 2 ways to do it. Much
appreciated as always.



--
View this message in context: http://r.789695.n4.nabble.com/Add-column-to-DF-based-on-2-columns-in-another-DF-tp4681950p4681969.html
Sent from the R help mailing list archive at Nabble.com.


From nitisha999 at gmail.com  Tue Dec 10 12:54:10 2013
From: nitisha999 at gmail.com (Nitisha jha)
Date: Tue, 10 Dec 2013 17:24:10 +0530
Subject: [R] Fwd:  Datatable manipulation
In-Reply-To: <1385128657.10818.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <21642760.204077.1384901008484.JavaMail.nabble@joe.nabble.com>
	<CAOdnBQfu9cDF45XBVR6NzC3nkxd4vFrCAO+15OqtLT5TEVE3Gw@mail.gmail.com>
	<1384920898.83429.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAOdnBQe17qqWG0KAsG+KFeXpJTe7WQTtjFdKqCJQGGCk2OdZVQ@mail.gmail.com>
	<CADv2QyEekzWiFg_PAOtM+YsKDiVRkZVCMcD=9BGCOU1fzzWyAA@mail.gmail.com>
	<CAOdnBQeUj990vBUk3y0qDgb+UKJkQbDxQQc+_0-rrrKwTt7mmA@mail.gmail.com>
	<CADv2QyFp0nu6NsxorwcPVwCS0F=5bJu0Sun=DhzNo8yaf-U+Ow@mail.gmail.com>
	<CAOdnBQeM+X_sUPwPGZZF2Cx0qoEsYhQS9xoXGVuRMtsA9qdNOA@mail.gmail.com>
	<CAOdnBQe-oSCqC5gd4OzbSo6Ti=xp+vV6PEDPSpPE6idQV3dN5w@mail.gmail.com>
	<1385060911.77793.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAOdnBQcjkyZ6b9hM1cvE+omBRSgJaC-f3Of3xPneB0N1HWTW3w@mail.gmail.com>
	<1385093979.31906.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAOdnBQffCL257uYm-z+U3Hs4uAnpt7_QMngZPZA+9u-_5fdwOg@mail.gmail.com>
	<1385103858.90641.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAOdnBQcrKOdf-sLfo=Bz-w5bA+4TRr9i4aMkpctYorH6OBksjw@mail.gmail.com>
	<CAOdnBQeaoEJ1+oChvSz_OSPcNeeNdi1SavuZ=RXVHExb9tiXXA@mail.gmail.com>
	<1385128657.10818.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CAOdnBQcGVAeD_7S_6VmDZicHj2s_iuPPLJPdjUWaES=7vttmgw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/ec3ba9fc/attachment.pl>

From smartpink111 at yahoo.com  Tue Dec 10 15:00:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 10 Dec 2013 06:00:25 -0800 (PST)
Subject: [R] Fwd:  Datatable manipulation
In-Reply-To: <CAOdnBQcGVAeD_7S_6VmDZicHj2s_iuPPLJPdjUWaES=7vttmgw@mail.gmail.com>
References: <21642760.204077.1384901008484.JavaMail.nabble@joe.nabble.com>	<CAOdnBQfu9cDF45XBVR6NzC3nkxd4vFrCAO+15OqtLT5TEVE3Gw@mail.gmail.com>	<1384920898.83429.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAOdnBQe17qqWG0KAsG+KFeXpJTe7WQTtjFdKqCJQGGCk2OdZVQ@mail.gmail.com>	<CADv2QyEekzWiFg_PAOtM+YsKDiVRkZVCMcD=9BGCOU1fzzWyAA@mail.gmail.com>	<CAOdnBQeUj990vBUk3y0qDgb+UKJkQbDxQQc+_0-rrrKwTt7mmA@mail.gmail.com>	<CADv2QyFp0nu6NsxorwcPVwCS0F=5bJu0Sun=DhzNo8yaf-U+Ow@mail.gmail.com>	<CAOdnBQeM+X_sUPwPGZZF2Cx0qoEsYhQS9xoXGVuRMtsA9qdNOA@mail.gmail.com>	<CAOdnBQe-oSCqC5gd4OzbSo6Ti=xp+vV6PEDPSpPE6idQV3dN5w@mail.gmail.com>	<1385060911.77793.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CAOdnBQcjkyZ6b9hM1cvE+omBRSgJaC-f3Of3xPneB0N1HWTW3w@mail.gmail.com>	<1385093979.31906.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<CAOdnBQffCL257uYm-z+U3Hs4uAnpt7_QMngZPZA+9u-_5fdwOg@mail.gmail.com>	<1385103858.90641.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAOdnBQcrKOdf-sLfo=Bz-w5bA+4TRr9i4aMkpctYorH6OBksjw@mail.gmail.com>	<CAOdnBQeaoEJ1+oChvSz_OSPcNeeNdi1SavuZ=RXVHExb9tiXXA@mail.gmail.com>	<1385128657.10818.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAOdnBQcGVAeD_7S_6VmDZicHj2s_iuPPLJPdjUWaES=7vttmgw@mail.gmail.com>
Message-ID: <1386684025.92326.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

Check these links:
http://stackoverflow.com/questions/19626534/r-issue-error-in-sqliteexecstatementcon-statement-bind-data-no-such-tabl


http://r.789695.n4.nabble.com/Problem-with-SQLDF-Error-in-sqliteExecStatement-con-statement-bind-data-RS-DBI-driver-error-in-state-td4621931.html


A.K.






On Tuesday, December 10, 2013 6:54 AM, Nitisha jha <nitisha999 at gmail.com> wrote:

Hi,
I have a doubt after a long time :) . I have a function which has sqldf statements and it works fine when I call it from console but when I am calling that function within another function, it gives me the error that?
Error in sqliteExecStatement(con, statement, bind.data) :?
? RS-DBI driver: (error in statement: no such table: table_name)

What is wrong here?



On Fri, Nov 22, 2013 at 7:27 PM, arun <smartpink111 at yahoo.com> wrote:


>
>Hi,
>Assuming that this is the case:
>
>dat1 <- read.table(text="a???? b???? c???? d?????? e
>1???? 2???? 3???? 4???? 5
>10???? 9???? 8???? 7???? 6",sep="",header=TRUE)
>
>Names1<- read.table(text="Original????? New??
>e???? ee
>g??? gg
>a???? aa
>c???? cc
>f???? ff",sep="",header=TRUE,stringsAsFactors=FALSE)
>?
>?indx <- match(names(dat1),Names1[,1])
>?names(dat1)[names(dat1) %in% Names1[,1]] <- Names1[,2][indx[!is.na(indx)]]
>?dat1
>#? aa b cc d ee
>
>#1? 1 2? 3 4? 5
>#2 10 9? 8 7? 6
>
>
>A.K.
>
>
>On Friday, November 22, 2013 4:46 AM, Nitisha jha <nitisha999 at gmail.com> wrote:
>
>Hey! I got this one. :)
>For the match function, actually I just want the ones that are matching to be replaced. Rest should stay the same. How do I do that? When I tried your command, if there is no match, it writes var2 or something.?
>
>
>
>
>>>>On Fri, Nov 22, 2013 at 12:38 AM, arun <smartpink111 at yahoo.com> wrote:
>>>>
>>>>
>>>>>
>>>>>Hi,
>>>>>Try:
>>>>>
>>>>>dat1 <- read.table(text="a ??? b ??? c ??? d?????? e
>>>>>
>>>>>1 ??? 2 ??? 3 ??? 4 ??? 5
>>>>>10 ??? 9 ??? 8 ??? 7 ??? 6",sep="",header=TRUE)
>>>>>
>>>>>Names1<- read.table(text="Original? ??? New???
>>>>>
>>>>>e ??? ee
>>>>>b ??? bb???
>>>>>a ??? aa
>>>>>c ??? cc
>>>>>d ??? dd",sep="",header=TRUE,stringsAsFactors=FALSE)
>>>>>
>>>>>It is better to dput() your dataset.? For example:
>>>>>?dput(Names1)
>>>>>structure(list(Original = c("e", "b", "a", "c", "d"), New = c("ee",
>>>>>"bb", "aa", "cc", "dd")), .Names = c("Original", "New"), class = "data.frame", row.names = c(NA,
>>>>>-5L))
>>>>>
>>>>>
>>>>>?names(dat1) <- Names1[,2][match(names(dat1), Names1[,1])] ##
>>>>>?dat1
>>>>>#? aa bb cc dd ee
>>>>>#1? 1? 2? 3? 4? 5
>>>>>#2 10? 9? 8? 7? 6
>>>>>A.K.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>On Thursday, November 21, 2013 1:45 PM, Nitisha jha <nitisha999 at gmail.com> wrote:
>>>>>
>>>>>Hi,
>>>>>
>>>>>Thanks. I used as.character() and got the right strings.
>>>>>
>>>>>Btw, I have lots of handicaps regarding R.
>>>>>
>>>>>I have to rename the columns(I have 22 columns here). I have the new names along with the original names in another dataset. Right now, I am going hardcoding all the? 19 name changes(tedious and not optimum). 1st 3 names remain the same. I will give u a sample dataset. Let me know if there is any easy way of doing this.? Pardon the displaced column labels.
>>>>>
>>>>>
>>>>>
>>>>>Original dataset.
>>>>>
>>>>>
>>>>>
>>>>>?? a b c d??????????? ?
>>>>>e
>>>>>1 2 3 4 5
>>>>>10 9 8 7 6
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>Dataset for name change
>>>>>
>>>>>
>>>>>Original? New
>>>>>
>>>>>
>>>>>
>>>>>e ee
>>>>>
>>>>>
>>>>>
>>>>>b bb
>>>>>
>>>>>
>>>>>
>>>>>a aa
>>>>>
>>>>>
>>>>>
>>>>>c cc
>>>>>
>>>>>
>>>>>
>>>>>d dd
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>I want my final dataset to be like this:
>>>>>
>>>>>aa bb cc dd ee
>>>>>1 2 3 4 5
>>>>>10 9 8 7 6
>>>>>
>>>>>
>>>>>
>>>>>?Could u tell me an optimal way to do it. My method is tedious and not good.
>>>>>
>>>>>Also, is there a way to import .xls without perl (windows)?
>>>>>
>>>>>
>>>>>Thanks for being patient. :)
>>>>>
>>>>
>>>
>>
>


From bakerwl at uwyo.edu  Tue Dec 10 23:04:33 2013
From: bakerwl at uwyo.edu (bakerwl)
Date: Tue, 10 Dec 2013 14:04:33 -0800 (PST)
Subject: [R] fisher.test - can I use non-integer expected values?
Message-ID: <1386713073003-4681976.post@n4.nabble.com>

I seem to be able to use expected values that are decimal (e.g., 1.33) when
using chisq.test but not when using fisher.test. This happens when using an
array/matrix as input. Fisher.test returns: Error in sprintf(gettext(fmt,
domain = domain), ...) : invalid format '%d'; use format %s for character
objects.

Thus, it appears fisher.test is looking for integers only.

I tried putting the data in x and y factor objects, but that does not work
either.

Is there another way to use non-integer expected values with fisher.test or
is that a limitation of fisher.test?

If I must use integer expected values, I suppose one option would be round
the expected value down or up to an integer. But, which? I tried that, but
they produce different p values.

Thanks for any help!



--
View this message in context: http://r.789695.n4.nabble.com/fisher-test-can-I-use-non-integer-expected-values-tp4681976.html
Sent from the R help mailing list archive at Nabble.com.


From zirak.p at gmail.com  Tue Dec 10 15:55:55 2013
From: zirak.p at gmail.com (peyman)
Date: Tue, 10 Dec 2013 15:55:55 +0100
Subject: [R] data distribution for lme
Message-ID: <52A72B7B.1010304@gmail.com>

Hi folks,

I am using the lme package of R, and am wondering if it is assumed that
the dependent factor (what we fit for; y in many relevant texts) has to
have a normal Gaussian distribution? Is there any margins where some
skewness in the data is accepted and how within R itself one could check
distribution of the data?

Thanks,
Peyman


From gunter.berton at gene.com  Tue Dec 10 23:28:22 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 10 Dec 2013 14:28:22 -0800
Subject: [R] data distribution for lme
In-Reply-To: <52A72B7B.1010304@gmail.com>
References: <52A72B7B.1010304@gmail.com>
Message-ID: <CACk-te3HMhEDGr=7OQ7KHWO4_dkBi6vM2iQjL+KkUEuvko3EDA@mail.gmail.com>

This is not really an R question -- it is statistics.
In any case, you should do better posting this on the
R-Sig-Mixed-Models list, which concerns itself with matters like this.

However, I'll hazard a guess at an answer: maybe.  (Vague questions
elicit vague answers).

Cheers,
Bert

On Tue, Dec 10, 2013 at 6:55 AM, peyman <zirak.p at gmail.com> wrote:
> Hi folks,
>
> I am using the lme package of R, and am wondering if it is assumed that
> the dependent factor (what we fit for; y in many relevant texts) has to
> have a normal Gaussian distribution? Is there any margins where some
> skewness in the data is accepted and how within R itself one could check
> distribution of the data?
>
> Thanks,
> Peyman
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From Steven.Hodge at umassmed.edu  Wed Dec 11 00:33:23 2013
From: Steven.Hodge at umassmed.edu (Hodge, Steven)
Date: Tue, 10 Dec 2013 18:33:23 -0500
Subject: [R] radial.plot shaded region
Message-ID: <AEE7BE1B8BD7C645B75328C8D702F94B177BBC8210@UMMSCSMAIL02.ad.umassmed.edu>

I'm working with radial.plot in the plotrix package.

Is there a way to show a shaded region for a specific range of values in radial.lim?

For example:
# test data from radial.plot{plotrix}
testlen<-c(sin(seq(0,1.98*pi,length=100))+2+rnorm(100)/10)
testpos<-seq(0,1.98*pi,length=100)

# the original plot
radial.plot(testlen,testpos,rp.type="p",main="Test Polygon",line.col="blue")

# my attempt to shade the region between 3 and 3.5:
radial.plot(
	matrix(c(3.5, 3), byrow = TRUE),
	matrix(c(testpos, testpos), byrow = TRUE, nrow = 2),
	rp.type="p",
	main="Test Polygon",
	poly.col = c('light blue', 'white'),
	radial.lim = c(0, 3.5)
	)
# In effect, draw a polygon at 3.5 filled with light blue, then another at 3 filled with white.
# Now overplot the values of interest:
radial.plot(testlen,testpos,rp.type="p",main="Test Polygon",line.col="blue", radial.lim = c(0, 3.5), add = TRUE)

Is there an easier way? How can I re-draw the grid lines that are in the original plot?

Thanks,

Steve

. . . . . . . . . . . . . . .
Steven M. Hodge
Child and Adolescent Neurodevelopment Initiative S3-301
University of Massachusetts Medical School
55 Lake Avenue North
Worcester, MA 01655
Steven.Hodge at umassmed.edu


From jim at bitwrit.com.au  Wed Dec 11 01:24:03 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 11 Dec 2013 11:24:03 +1100
Subject: [R] radial.plot shaded region
In-Reply-To: <AEE7BE1B8BD7C645B75328C8D702F94B177BBC8210@UMMSCSMAIL02.ad.umassmed.edu>
References: <AEE7BE1B8BD7C645B75328C8D702F94B177BBC8210@UMMSCSMAIL02.ad.umassmed.edu>
Message-ID: <52A7B0A3.5060303@bitwrit.com.au>

On 12/11/2013 10:33 AM, Hodge, Steven wrote:
> I'm working with radial.plot in the plotrix package.
>
> Is there a way to show a shaded region for a specific range of values in radial.lim?
>
> For example:
> # test data from radial.plot{plotrix}
> testlen<-c(sin(seq(0,1.98*pi,length=100))+2+rnorm(100)/10)
> testpos<-seq(0,1.98*pi,length=100)
>
> # the original plot
> radial.plot(testlen,testpos,rp.type="p",main="Test Polygon",line.col="blue")
>
> # my attempt to shade the region between 3 and 3.5:
> radial.plot(
> 	matrix(c(3.5, 3), byrow = TRUE),
> 	matrix(c(testpos, testpos), byrow = TRUE, nrow = 2),
> 	rp.type="p",
> 	main="Test Polygon",
> 	poly.col = c('light blue', 'white'),
> 	radial.lim = c(0, 3.5)
> 	)
> # In effect, draw a polygon at 3.5 filled with light blue, then another at 3 filled with white.
> # Now overplot the values of interest:
> radial.plot(testlen,testpos,rp.type="p",main="Test Polygon",line.col="blue", radial.lim = c(0, 3.5), add = TRUE)
>
> Is there an easier way? How can I re-draw the grid lines that are in the original plot?
>
Hi Steve,
That is a tricky one. The best I can do at the moment is to suggest the 
following be added:

radial.grid(radial.lim=c(0,3.5),
  grid.pos=seq(0,3.5,length.out=8))
radial.plot(testlen,testpos,rp.type="p",
  main="",line.col="blue",add=TRUE)

There may be a solution using the radial.pie function, and if I find it, 
I'll post it.

Jim


From A.Robinson at ms.unimelb.edu.au  Wed Dec 11 01:27:23 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 11 Dec 2013 11:27:23 +1100
Subject: [R] data distribution for lme
In-Reply-To: <52A72B7B.1010304@gmail.com>
References: <52A72B7B.1010304@gmail.com>
Message-ID: <CAHyGmd5HHG81H610HtiJySfM8qzX5=bLuJgiY=Sz_Y5Tq4ze_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131211/b8dc29c0/attachment.pl>

From dwinsemius at comcast.net  Wed Dec 11 02:23:44 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 10 Dec 2013 17:23:44 -0800
Subject: [R] fisher.test - can I use non-integer expected values?
In-Reply-To: <1386713073003-4681976.post@n4.nabble.com>
References: <1386713073003-4681976.post@n4.nabble.com>
Message-ID: <27F74B6B-FB26-40EE-9103-FE5787BB81A1@comcast.net>


On Dec 10, 2013, at 2:04 PM, bakerwl wrote:

> I seem to be able to use expected values that are decimal (e.g., 1.33) when
> using chisq.test but not when using fisher.test.

There are no expected values in the input to fisher.test. 

> This happens when using an
> array/matrix as input. Fisher.test returns: Error in sprintf(gettext(fmt,
> domain = domain), ...) : invalid format '%d'; use format %s for character
> objects.
> 
> Thus, it appears fisher.test is looking for integers only.

That would seem to be a very reasonable assumption.

> 
> I tried putting the data in x and y factor objects, but that does not work
> either.
> 
> Is there another way to use non-integer expected values with fisher.test or
> is that a limitation of fisher.test?

> If I must use integer expected values, I suppose one option would be round
> the expected value down or up to an integer. But, which? I tried that, but
> they produce different p values.

Well, of course. First, you tell us why you need `fisher.test` at all. It says very clearly it is for count data and you clearly want to do something with input that is not counts. `prop.test` will test a distribution of counts against expected proportions and `binom.test` will do an exact test of a Bernoulli experiment against (one) proportion. 

> 
> Thanks for any help!
> 
> View this message in context: http://r.789695.n4.nabble.com/fisher-test-can-I-use-non-integer-expected-values-tp4681976.html
> Sent from the R help mailing list archive at Nabble.com.
> 
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 
David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Wed Dec 11 02:33:30 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 11 Dec 2013 14:33:30 +1300
Subject: [R] data distribution for lme
In-Reply-To: <CACk-te3HMhEDGr=7OQ7KHWO4_dkBi6vM2iQjL+KkUEuvko3EDA@mail.gmail.com>
References: <52A72B7B.1010304@gmail.com>
	<CACk-te3HMhEDGr=7OQ7KHWO4_dkBi6vM2iQjL+KkUEuvko3EDA@mail.gmail.com>
Message-ID: <52A7C0EA.6020207@auckland.ac.nz>


See inline below.

On 12/11/13 11:28, Bert Gunter wrote:
> This is not really an R question -- it is statistics.
> In any case, you should do better posting this on the
> R-Sig-Mixed-Models list, which concerns itself with matters like this.
>
> However, I'll hazard a guess at an answer: maybe.  (Vague questions
> elicit vague answers).

No! Nay! Never!  Well, hardly ever.   The ***y*** values will rarely be 
Gaussian.
(Think about a simple one-way anova, with 3 levels, and N(0,sigma^2) errors.
The y values will have a distribution which is a mixture of 3 
independent Gaussian
distributions.)

You *may* wish to worry about whether the ***errors*** have a Gaussian
distribution.  Some inferential results depend on this, but in many cases
these results are quite robust to non-Gaussianity.

There.  I have exhausted my knowledge of the subject.

     cheers,

     Rolf
>
> Cheers,
> Bert
>
> On Tue, Dec 10, 2013 at 6:55 AM, peyman <zirak.p at gmail.com> wrote:
>> Hi folks,
>>
>> I am using the lme package of R, and am wondering if it is assumed that
>> the dependent factor (what we fit for; y in many relevant texts) has to
>> have a normal Gaussian distribution? Is there any margins where some
>> skewness in the data is accepted and how within R itself one could check
>> distribution of the data?


From dwinsemius at comcast.net  Wed Dec 11 02:39:40 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 10 Dec 2013 17:39:40 -0800
Subject: [R] radial.plot shaded region
In-Reply-To: <52A7B0A3.5060303@bitwrit.com.au>
References: <AEE7BE1B8BD7C645B75328C8D702F94B177BBC8210@UMMSCSMAIL02.ad.umassmed.edu>
	<52A7B0A3.5060303@bitwrit.com.au>
Message-ID: <E3118240-1EDB-444F-8FB4-B4244099352D@comcast.net>


On Dec 10, 2013, at 4:24 PM, Jim Lemon wrote:

> On 12/11/2013 10:33 AM, Hodge, Steven wrote:
>> I'm working with radial.plot in the plotrix package.
>> 
>> Is there a way to show a shaded region for a specific range of values in radial.lim?
>> 
>> For example:
>> # test data from radial.plot{plotrix}
>> testlen<-c(sin(seq(0,1.98*pi,length=100))+2+rnorm(100)/10)
>> testpos<-seq(0,1.98*pi,length=100)
>> 
>> # the original plot
>> radial.plot(testlen,testpos,rp.type="p",main="Test Polygon",line.col="blue")
>> 
>> # my attempt to shade the region between 3 and 3.5:
>> radial.plot(
>> 	matrix(c(3.5, 3), byrow = TRUE),
>> 	matrix(c(testpos, testpos), byrow = TRUE, nrow = 2),
>> 	rp.type="p",
>> 	main="Test Polygon",
>> 	poly.col = c('light blue', 'white'),
>> 	radial.lim = c(0, 3.5)
>> 	)
>> # In effect, draw a polygon at 3.5 filled with light blue, then another at 3 filled with white.
>> # Now overplot the values of interest:
>> radial.plot(testlen,testpos,rp.type="p",main="Test Polygon",line.col="blue", radial.lim = c(0, 3.5), add = TRUE)
>> 
>> Is there an easier way? How can I re-draw the grid lines that are in the original plot?
>> 
> Hi Steve,
> That is a tricky one. The best I can do at the moment is to suggest the following be added:
> 
> radial.grid(radial.lim=c(0,3.5),
> grid.pos=seq(0,3.5,length.out=8))
> radial.plot(testlen,testpos,rp.type="p",
> main="",line.col="blue",add=TRUE)
> 
> There may be a solution using the radial.pie function, and if I find it, I'll post it.

Looking at the code I would have thought it would not be too difficult to "de-couple" the plot setup and the grid plotting in this section:

if (!add) {
        par(mar = mar, pty = "s")
        plot(c(-maxlength, maxlength), c(-maxlength, maxlength), 
            type = "n", axes = FALSE, main = main, xlab = xlab, 
            ylab = ylab)
        if (show.grid) {
            for (i in seq(length(grid.pos), 1, by = -1)) {
                xpos <- cos(angles) * (grid.pos[i] - radial.lim[1])
                ypos <- sin(angles) * (grid.pos[i] - radial.lim[1])
                polygon(xpos, ypos, border = grid.col, col = grid.bg)
            }
        }

But you are the Plotmeister and I am a humble Student.

-- 

David Winsemius
Alameda, CA, USA


From bakerwl at uwyo.edu  Wed Dec 11 03:55:09 2013
From: bakerwl at uwyo.edu (bakerwl)
Date: Tue, 10 Dec 2013 18:55:09 -0800 (PST)
Subject: [R] fisher.test - can I use non-integer expected values?
In-Reply-To: <27F74B6B-FB26-40EE-9103-FE5787BB81A1@comcast.net>
References: <1386713073003-4681976.post@n4.nabble.com>
	<27F74B6B-FB26-40EE-9103-FE5787BB81A1@comcast.net>
Message-ID: <1386730509852-4681989.post@n4.nabble.com>

David,

Thanks for your reply--I appreciate your thoughts. I will look at prop.test.

The reason I chose fisher.test over chisq.test is that fisher.test is more
appropriate when observed counts are not numerous--empty cells and cells
with counts < 5 are less a problem. 

Expected values are needed to test a null hypothesis against observed
counts, but if total observed counts are 20 for 3 categories, then a null
hypothesis of a random effect would use expected values = 6.67 in each of
the 3 categories (20/3). 

Yes, fisher.test is for count data and so is chisq.test, but chisq.test
allows 6.67 to be input as expected values in each of 3 categories, while
fisher.test does not seem to allow this? 

I don't think it is inherent in Fisher's exact test itself that expected
values must be integers, but not sure.





--
View this message in context: http://r.789695.n4.nabble.com/fisher-test-can-I-use-non-integer-expected-values-tp4681976p4681989.html
Sent from the R help mailing list archive at Nabble.com.


From jim at bitwrit.com.au  Wed Dec 11 03:57:19 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 11 Dec 2013 13:57:19 +1100
Subject: [R] radial.plot shaded region
In-Reply-To: <52A7B0A3.5060303@bitwrit.com.au>
References: <AEE7BE1B8BD7C645B75328C8D702F94B177BBC8210@UMMSCSMAIL02.ad.umassmed.edu>
	<52A7B0A3.5060303@bitwrit.com.au>
Message-ID: <52A7D48F.6030705@bitwrit.com.au>

On 12/11/2013 11:24 AM, Jim Lemon wrote:
> ...
> There may be a solution using the radial.pie function, and if I find it,
> I'll post it.
>
Hi Steve,
Here it is. Just call radial.pie twice to get the annulus, then call 
radial.grid with the appropriate arguments, and then you can add 
whatever radial.plot you want, using the "add" argument.

radial.pie(3.5,sector.colors="lightblue")
radial.pie(3,sector.colors="white",add=TRUE)
radial.grid(radial.lim=c(0,3.5),grid.pos=seq(0,3.5,length.out=8))

Jim


From gunter.berton at gene.com  Wed Dec 11 05:18:13 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 10 Dec 2013 20:18:13 -0800
Subject: [R] data distribution for lme
In-Reply-To: <52A7C0EA.6020207@auckland.ac.nz>
References: <52A72B7B.1010304@gmail.com>
	<CACk-te3HMhEDGr=7OQ7KHWO4_dkBi6vM2iQjL+KkUEuvko3EDA@mail.gmail.com>
	<52A7C0EA.6020207@auckland.ac.nz>
Message-ID: <CACk-te28GcuXWCchuOxoqfbXAKa_sK=2U2VordNy1-pJBRnjDA@mail.gmail.com>

Thanks Rolf and Andrew. I was entirely too careless and should take a
trip to the woodshed (google "David Stockman woodshed"  for the
reference).

The correct answer therefore is: maybe for the residuals, for the
"right" model, of course.

But I still think the crowd on r-sig-mixed-models is the right place
to hash it out, if anything meaningful can indeed be made of it.

Cheers,
Bert

On Tue, Dec 10, 2013 at 5:33 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> See inline below.
>
> On 12/11/13 11:28, Bert Gunter wrote:
>>
>> This is not really an R question -- it is statistics.
>> In any case, you should do better posting this on the
>> R-Sig-Mixed-Models list, which concerns itself with matters like this.
>>
>> However, I'll hazard a guess at an answer: maybe.  (Vague questions
>> elicit vague answers).
>
>
> No! Nay! Never!  Well, hardly ever.   The ***y*** values will rarely be
> Gaussian.
> (Think about a simple one-way anova, with 3 levels, and N(0,sigma^2) errors.
> The y values will have a distribution which is a mixture of 3 independent
> Gaussian
> distributions.)
>
> You *may* wish to worry about whether the ***errors*** have a Gaussian
> distribution.  Some inferential results depend on this, but in many cases
> these results are quite robust to non-Gaussianity.
>
> There.  I have exhausted my knowledge of the subject.
>
>     cheers,
>
>     Rolf
>>
>>
>> Cheers,
>> Bert
>>
>> On Tue, Dec 10, 2013 at 6:55 AM, peyman <zirak.p at gmail.com> wrote:
>>>
>>> Hi folks,
>>>
>>> I am using the lme package of R, and am wondering if it is assumed that
>>> the dependent factor (what we fit for; y in many relevant texts) has to
>>> have a normal Gaussian distribution? Is there any margins where some
>>> skewness in the data is accepted and how within R itself one could check
>>> distribution of the data?



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dwinsemius at comcast.net  Wed Dec 11 05:21:57 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 10 Dec 2013 20:21:57 -0800
Subject: [R] fisher.test - can I use non-integer expected values?
In-Reply-To: <1386730509852-4681989.post@n4.nabble.com>
References: <1386713073003-4681976.post@n4.nabble.com>
	<27F74B6B-FB26-40EE-9103-FE5787BB81A1@comcast.net>
	<1386730509852-4681989.post@n4.nabble.com>
Message-ID: <765672D1-8647-46CE-9A83-00A77FA39FAA@comcast.net>


On Dec 10, 2013, at 6:55 PM, bakerwl wrote:

> David,
> 
> Thanks for your reply--I appreciate your thoughts. I will look at prop.test.
> 
> The reason I chose fisher.test over chisq.test is that fisher.test is more
> appropriate when observed counts are not numerous--empty cells and cells
> with counts < 5 are less a problem. 
> 
> Expected values are needed to test a null hypothesis against observed
> counts, but if total observed counts are 20 for 3 categories, then a null
> hypothesis of a random effect would use expected values = 6.67 in each of
> the 3 categories (20/3). 
> 
> Yes, fisher.test is for count data and so is chisq.test, but chisq.test
> allows 6.67 to be input as expected values in each of 3 categories, while
> fisher.test does not seem to allow this? 
> 
> I don't think it is inherent in Fisher's exact test itself that expected
> values must be integers, but not sure.

I see it differently, although I could be further educated on the subject and I've been wrong on Rhelp before. I think it _is_ inherent in Fisher's Exact Test. FET is essentially a permutation test built on the hypergeometric distribution (a discrete distribution)  and it is unclear what to do with 1.33 of an entity under conditions of permutation.

The "chi-square test" (one of many so-called chi-square tests) is a pretty good approximation to the discrete counterparts despite the fact that the chi-square distribution takes continuous arguments and generally holds well down to expected counts of 5. The link between the chi-square and binomial distributions is through there variances: npq vs sum(o-e)^2/n. You can develop arguments "in the limit" that converge fairly quickly.

> --
> View this message in context: http://r.789695.n4.nabble.com/fisher-test-can-I-use-non-integer-expected-values-tp4681976p4681989.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Dec 11 05:33:34 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 10 Dec 2013 20:33:34 -0800
Subject: [R] fisher.test - can I use non-integer expected values?
In-Reply-To: <765672D1-8647-46CE-9A83-00A77FA39FAA@comcast.net>
References: <1386713073003-4681976.post@n4.nabble.com>
	<27F74B6B-FB26-40EE-9103-FE5787BB81A1@comcast.net>
	<1386730509852-4681989.post@n4.nabble.com>
	<765672D1-8647-46CE-9A83-00A77FA39FAA@comcast.net>
Message-ID: <2224FE81-FA41-4875-8CD4-7F9B185A4EE1@comcast.net>


On Dec 10, 2013, at 8:21 PM, David Winsemius wrote:

> 
> On Dec 10, 2013, at 6:55 PM, bakerwl wrote:
> 
>> David,
>> 
>> Thanks for your reply--I appreciate your thoughts. I will look at prop.test.
>> 
>> The reason I chose fisher.test over chisq.test is that fisher.test is more
>> appropriate when observed counts are not numerous--empty cells and cells
>> with counts < 5 are less a problem. 
>> 
>> Expected values are needed to test a null hypothesis against observed
>> counts, but if total observed counts are 20 for 3 categories, then a null
>> hypothesis of a random effect would use expected values = 6.67 in each of
>> the 3 categories (20/3). 
>> 
>> Yes, fisher.test is for count data and so is chisq.test, but chisq.test
>> allows 6.67 to be input as expected values in each of 3 categories, while
>> fisher.test does not seem to allow this? 
>> 
>> I don't think it is inherent in Fisher's exact test itself that expected
>> values must be integers, but not sure.
> 
> I see it differently, although I could be further educated on the subject and I've been wrong on Rhelp before. I think it _is_ inherent in Fisher's Exact Test. FET is essentially a permutation test built on the hypergeometric distribution (a discrete distribution)  and it is unclear what to do with 1.33 of an entity under conditions of permutation.
> 
> The "chi-square test" (one of many so-called chi-square tests) is a pretty good approximation to the discrete counterparts despite the fact that the chi-square distribution takes continuous arguments and generally holds well down to expected counts of 5. The link between the chi-square and binomial distributions is through there variances: npq vs sum(o-e)^2/n. You can develop arguments "in the limit" that converge fairly quickly.
> 

I was careless there, both in the spelling of 'their' and in the connection of chi-square distributions to binomial. You should consult more authoritative source for the mathematics of similarities in their large sample features.

-- 
David


>> --
>> View this message in context: http://r.789695.n4.nabble.com/fisher-test-can-I-use-non-integer-expected-values-tp4681976p4681989.html
>> Sent from the R help mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From peter.langfelder at gmail.com  Wed Dec 11 06:37:10 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 10 Dec 2013 21:37:10 -0800
Subject: [R] fisher.test - can I use non-integer expected values?
In-Reply-To: <1386730509852-4681989.post@n4.nabble.com>
References: <1386713073003-4681976.post@n4.nabble.com>
	<27F74B6B-FB26-40EE-9103-FE5787BB81A1@comcast.net>
	<1386730509852-4681989.post@n4.nabble.com>
Message-ID: <CA+hbrhUL=3EyOLFxJj-_Un4eTN+rQrZiACcybysun2LBxwCEHQ@mail.gmail.com>

On Tue, Dec 10, 2013 at 6:55 PM, bakerwl <bakerwl at uwyo.edu> wrote:

> Expected values are needed to test a null hypothesis against observed
> counts, but if total observed counts are 20 for 3 categories, then a null
> hypothesis of a random effect would use expected values = 6.67 in each of
> the 3 categories (20/3).
>
> Yes, fisher.test is for count data and so is chisq.test, but chisq.test
> allows 6.67 to be input as expected values in each of 3 categories, while
> fisher.test does not seem to allow this?

To the best of my knowledge (which may be limited) you never put
expected counts as input in Fisher Exact Test, you need to put actual
observed counts. Fisher test tests the independence of two different
random variables, each of which has a set of categorical outcomes.

>From what you wrote it appears that you have only one random variable
that can take 3 different values, and you want a statistical test for
whether the frequencies are the same. You can use chisq.test for this
by specifying the probabilities (argument p) and running it as a
goodness-of-fit test. I am not aware of goodness-of-fit way of using
fisher.test.

If you actually have two different variables, one of which can take
two values and the other one can take 3 values, you need the actual
observed counts for each of the 6 combinations of the two variables.
You put these counts into a 2x3 table and supply that to fisher.test
or chisq.test.

>
> I don't think it is inherent in Fisher's exact test itself that expected
> values must be integers, but not sure.

I think it is inherent in Fisher's Exact test. The test makes certain
assumptions about the distribution of the numbers you put in. If you
put in non-integers, you necessarily  violate those assumptions and
the test is then not applicable.

Peter


From pmaclean2011 at yahoo.com  Wed Dec 11 07:26:11 2013
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Tue, 10 Dec 2013 22:26:11 -0800 (PST)
Subject: [R] Stochastic Dominance Analysis
Message-ID: <1386743171.29150.YahooMailNeo@web121706.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131210/c207974a/attachment.pl>

From long_vo_hai at yahoo.com.vn  Wed Dec 11 03:03:56 2013
From: long_vo_hai at yahoo.com.vn (Long Vo)
Date: Tue, 10 Dec 2013 18:03:56 -0800 (PST)
Subject: [R] Splitting a vector
In-Reply-To: <1386651093.85766.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1386649193293-4681930.post@n4.nabble.com>
	<1386651093.85766.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1386727436255-4681987.post@n4.nabble.com>

This does what I needed. However, as the output is a list object, is there
any way to apply a function to such object? For example if I want to compute
the mean for the 4th subvectors, I can't simply use:
#####
Y=split(X,as.numeric(gl(length(X),3,length(X))))
mean(Y[4])
##### 
as the error message shows "argument is not numeric or logical"



--
View this message in context: http://r.789695.n4.nabble.com/Splitting-a-vector-tp4681930p4681987.html
Sent from the R help mailing list archive at Nabble.com.


From Malcolm.OToole at utas.edu.au  Wed Dec 11 05:24:59 2013
From: Malcolm.OToole at utas.edu.au (otoolem)
Date: Wed, 11 Dec 2013 15:24:59 +1100
Subject: [R] setting effect plot parameters
Message-ID: <fb68e69223507.52a883cb@utas.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131211/d99c87b7/attachment.pl>

From lma243 at nau.edu  Wed Dec 11 05:22:12 2013
From: lma243 at nau.edu (lindsiebug9)
Date: Tue, 10 Dec 2013 20:22:12 -0800 (PST)
Subject: [R] SDM using BIOMOD2 error message
Message-ID: <1386735732170-4681993.post@n4.nabble.com>

Hi 

I am working on Species Distribution Modeling in R using BIOMOD2. When
picking my algorithms to model I keep getting an error message about length
(pred) 

this is the code that I'm using 

library(knitr) 
library(markdown) 
library(rgdal) 
library(raster) 
library(shapefiles) 
library(biomod2) 
library(dismo) 
library(sp) 
library(rgeos) 
library(maptools) 
library(MigClim) 

setwd("V:/BIOCLIM") 
bio2 <- raster("bio_2.bil") 
bio5 <- raster("bio_5.bil") 
bio6 <- raster("bio_6.bil") 
bio15 <- raster ("bio_15.bil") 
bio18 <- raster ("bio_18.bil") 
bio19 <- raster ("bio_19.bil") 

bio2 <- crop (bio2, extent (-112,-105,34,39)) 
bio5 <- crop (bio5, extent (-112,-105,34,39)) 
bio6 <- crop (bio6, extent (-112,-105,34,39)) 
bio15 <- crop (bio15, extent (-112,-105,34,39)) 
bio18 <- crop (bio18, extent (-112,-105,34,39)) 
bio19 <- crop (bio19, extent (-112,-105,34,39)) 

envStack <-stack (bio2, bio5,bio6,bio15,bio18, bio19) 

rm 

#bring in your presence or presence/absence data 
setwd("C:/Users/Lindsie/Documents/R") 
BH <- read.csv("occurrence_BH.csv") 
head(BH) 

myBiomodData=BIOMOD_FormatingData(resp.var=as.matrix(BH[,3]),expl.var=envStack,resp.xy=BH[,1:2],resp.name="Huntii",
PA.nb.rep=2, PA.nb.absences=909, PA.strategy="random",na.rm=TRUE) 

myBiomodOption <- BIOMOD_ModelingOptions() 

*myBiomodModelOut <- BIOMOD_Modeling(myBiomodData, models =
c("GLM","GBM","GAM","CTA","ANN","SRE","FDA","MARS","RF"), models.options =
myBiomodOption, NbRunEval = 1, DataSplit = 70, Yweights = NULL, VarImport =
3, models.eval.meth = c("ROC", "TSS", "KAPPA"), SaveObj = TRUE,
rescal.all.models = TRUE)*


at this point I get an error message that says 

*Error in length(pred) : 'pred' is missing
*
any suggestions?   

Thanks



--
View this message in context: http://r.789695.n4.nabble.com/SDM-using-BIOMOD2-error-message-tp4681993.html
Sent from the R help mailing list archive at Nabble.com.


From Gerrit.Eichner at math.uni-giessen.de  Wed Dec 11 10:14:58 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 11 Dec 2013 10:14:58 +0100 (MET)
Subject: [R] If-statement in for-loop
In-Reply-To: <DUB110-W1186D29CC73B6767F3582AFCED20@phx.gbl>
References: <DUB110-W1186D29CC73B6767F3582AFCED20@phx.gbl>
Message-ID: <Pine.SOC.4.64.1312110954150.2991@solcom.hrz.uni-giessen.de>

Hello, "gncl dzgn",

your problem has a flavor of homework which is usually not delt with on 
this list. However, a few comments:

0. The description of your problem is rather vague, in particular, the 
meaning of "input" in the description of your "conditions" is unclear! (By 
the way, your main problem is probably not the inclusion of the 
conditions; see 2.)

Note: "PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html and provide commented, 
minimal, self-contained, reproducible code."
^^^^^^^

1. Do not use variable names like t, T, c, s because they already exist as 
R-objects.

2. Have you noticed the warnings "In s >= d : longer object length is not 
a multiple of shorter object length" and "In s + b * (0:T) : longer object 
length is not a multiple of shorter object length"? Apparently the 
involved objects (s, d, b and T) do not "fit together". Hint: Compare the 
lenght of s with the lengths of d and 0:T!

3. Do not run the code all at once, but either without the for-loops line 
by line with j and i set to approriate values (like i = 1 and j = 2), or 
with the for-loops, but with N and T very small, e. g. N = 1 and T = 2 to 
start with. Alternatively, you could also take a look at the function 
browser() (and include it in the bodies of your for-loops).

4. Another hint: Your if-else-statement

   if(x < minx) {
     s[i] <- minx
    } else {
     if(x > maxx) {
       s[i] <- maxx
      } else s[i] <- x
    }

appears be simplifiable to

   s[i] <- min( max( x, minx), maxx)


  Hth  --  Gerrit


> Hi everyone,
>
> you might find my question elementary but I am a beginner and 
> unfortunately I can't fix the problem.
>
> So, I simulate this following algorithm and some values of c are NA. 
> Therefore, I should add these following two if-statements but I don't 
> know how I should do it in a for-loop.
>
> Thank in advance if someone helps me!
>
> The conditions:
>
> If there is no input greater or equal to d, then ALG = b*T
> If  max(s +  b*(0:T)) < b*T , then OPT = b*T
>
>
> The algorithm:
>
> a <- 0.0008
> b <- 0.0001
> T <- 100
> t <- 0:T
> alpha <- 1
>
> d<- sqrt(a * b) * T - b * t
>
> N <- 100
> c <- rep(0, N)
> for (j in 1:N) {
>
> e <- rnorm(T, mean = 0, sd = 0.001)
> s<- c( runif(1,0, a*T), rep(0, T-1) )
> minx <- 0
> for(i in 2:T) {
>    x <- alpha * s[i-1] + e[i]
> maxx <- a*(T-i)
> if(x < minx) {
> s[i] <- minx
> } else {
> if(x > maxx) {
> s[i] <- maxx
> } else s[i] <- x
> }
> }
>
> p<- which(s >= d)[1]
> ALG<- s[p] + b*(p-1)
> OPT <- max(s +  b*(0:T))
>
> c[j] <-  OPT / ALG
>
> }
>
> head(c)
> mean(c)
> plot(c)
>


From Gerrit.Eichner at math.uni-giessen.de  Wed Dec 11 10:19:02 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 11 Dec 2013 10:19:02 +0100 (MET)
Subject: [R] Splitting a vector
In-Reply-To: <1386727436255-4681987.post@n4.nabble.com>
References: <1386649193293-4681930.post@n4.nabble.com>
	<1386651093.85766.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1386727436255-4681987.post@n4.nabble.com>
Message-ID: <Pine.SOC.4.64.1312111016590.2991@solcom.hrz.uni-giessen.de>

Hello, Long Vo,

take a look at the help page of split or directly at

str(Y)

They tell you that Y is a list, and list components are indexed using 
"[[":

mean(Y[[4]])

should do what you want.

   Regards  --  Gerrit


> This does what I needed. However, as the output is a list object, is there
> any way to apply a function to such object? For example if I want to compute
> the mean for the 4th subvectors, I can't simply use:
> #####
> Y=split(X,as.numeric(gl(length(X),3,length(X))))
> mean(Y[4])
> #####
> as the error message shows "argument is not numeric or logical"
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Splitting-a-vector-tp4681930p4681987.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ameenzhao at gmail.com  Wed Dec 11 10:48:45 2013
From: ameenzhao at gmail.com (Yin Zhao)
Date: Wed, 11 Dec 2013 17:48:45 +0800
Subject: [R] How to deal with multiple class ROC analysis in R (pROC
	package)?
Message-ID: <CA+WGA9TqYi_y-GUWRarQhZ98AKCKzcAKSrHZbja3=2oTLQ0LoA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131211/14c5d533/attachment.pl>

From eliza_botto at hotmail.com  Wed Dec 11 12:16:52 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Wed, 11 Dec 2013 11:16:52 +0000
Subject: [R] solving simultaneous Equations in R
Message-ID: <BLU170-W1148EF2454A33B20811FA1B89DD0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131211/2bdc6804/attachment.pl>

From bhh at xs4all.nl  Wed Dec 11 12:43:02 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 11 Dec 2013 12:43:02 +0100
Subject: [R] solving simultaneous Equations in R
In-Reply-To: <BLU170-W1148EF2454A33B20811FA1B89DD0@phx.gbl>
References: <BLU170-W1148EF2454A33B20811FA1B89DD0@phx.gbl>
Message-ID: <794DC044-7B8D-4892-B3FE-DCB5C7AE6AC8@xs4all.nl>


On 11-12-2013, at 12:16, eliza botto <eliza_botto at hotmail.com> wrote:

> Dear users of R,
> I'm trying to solve the following 2 equations simultaneously in R for "x" and "y". I couldn't get through due to my limited knowledge of R.
> 
> 3=1-[(x-1)!(2x-y-1)!/(2x-1)!(x-y-1)!] 
> 
> 6={[(x-y-1)!/(x-1)!]-[3(2x-y-1)!/(2x-1)!]+[2(3x-y-1)!/(3x-1)!]}/{[(x-y-1)!/(x-1)!]-[(2x-y-1)!/(2x-1)!]}
> 
> obviously, ! is factorial.
> kindly help me out on it or at least suggest something.
> I'll be extremely grateful.

There are several packages that solve a system of equations.
ktsolve, nleqslv, BB, which you can find in CRAN Task views: "Numerical Mathematics? and ?Optimization?.

You will have to write your equations in standard R notation.
I can?t tell if your system is solvable.

Berend

> Eliza
> 
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Dec 11 13:33:06 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 11 Dec 2013 13:33:06 +0100
Subject: [R] fisher.test - can I use non-integer expected values?
In-Reply-To: <CA+hbrhUL=3EyOLFxJj-_Un4eTN+rQrZiACcybysun2LBxwCEHQ@mail.gmail.com>
References: <1386713073003-4681976.post@n4.nabble.com>
	<27F74B6B-FB26-40EE-9103-FE5787BB81A1@comcast.net>
	<1386730509852-4681989.post@n4.nabble.com>
	<CA+hbrhUL=3EyOLFxJj-_Un4eTN+rQrZiACcybysun2LBxwCEHQ@mail.gmail.com>
Message-ID: <F694EC60-1AA5-4D04-B372-2BB977B1117A@gmail.com>


On 11 Dec 2013, at 06:37 , Peter Langfelder <peter.langfelder at gmail.com> wrote:

>> 
>> Expected values are needed to test a null hypothesis against observed
>> counts, but if total observed counts are 20 for 3 categories, then a null
>> hypothesis of a random effect would use expected values = 6.67 in each of
>> the 3 categories (20/3).
>> 
>> Yes, fisher.test is for count data and so is chisq.test, but chisq.test
>> allows 6.67 to be input as expected values in each of 3 categories, while
>> fisher.test does not seem to allow this?
> 
> To the best of my knowledge (which may be limited) you never put
> expected counts as input in Fisher Exact Test, you need to put actual
> observed counts. Fisher test tests the independence of two different
> random variables, each of which has a set of categorical outcomes.

> From what you wrote it appears that you have only one random variable
> that can take 3 different values, and you want a statistical test for
> whether the frequencies are the same. You can use chisq.test for this
> by specifying the probabilities (argument p) and running it as a
> goodness-of-fit test. I am not aware of goodness-of-fit way of using
> fisher.test.

A couple of additional notes: 

(a) If you think you can feed expected values like 6.67 to chisq.test anywhere, I think you are doing it wrong. It might give you an answer, but not likely a correct one.

(b) There is an exact test for equidistribution or goodness of fit in general, but that is not what fisher.test does. You can "cheat" and get an approximation by claiming that you are comparing your data to a much larger set of equidistributed data, e.g.:

> fisher.test(cbind(c(1,10,9),c(10000,10000,10000)))

	Fisher's Exact Test for Count Data

data:  cbind(c(1, 10, 9), c(10000, 10000, 10000))
p-value = 0.01465
alternative hypothesis: two.sided

(c) It's not massively hard to generate the ~200 configurations of 20 items into 3 groups and use that to calculate the exact test exactly:

tab <- outer(0:20,0:20,
	Vectorize(function(i,j)
	  if (i+j <= 20)
              dmultinom(c(i, j, 20 - i - j), p=c(1, 1, 1)/3)
          else 0
	))
pp <- dmultinom(c(1, 10, 9), p=c(1, 1, 1)/3)
sum(tab[tab<=pp])

## [1] 0.01468422

(d) Another option is to use the simulate.p.value option to chisq.test():

> chisq.test(c(1, 10, 9), simulate=TRUE, B=10000)

	Chi-squared test for given probabilities with simulated p-value (based
	on 10000 replicates)

data:  c(1, 10, 9)
X-squared = 7.3, df = NA, p-value = 0.0252

(The p-values _will_ differ because chi-square critical regions are slightly different from those based on the point probabilities.)

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jfox at mcmaster.ca  Wed Dec 11 13:41:07 2013
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 11 Dec 2013 07:41:07 -0500
Subject: [R] setting effect plot parameters
In-Reply-To: <fb68e69223507.52a883cb@utas.edu.au>
References: <fb68e69223507.52a883cb@utas.edu.au>
Message-ID: <000001cef66e$44317350$cc9459f0$@mcmaster.ca>

Dear Malcolm,

You can't specify some trellis arguments to plot.eff() because some of them,
such as scales, will conflict with trellis arguments that are already set by
plot.eff(), the plot() method for objects of class "eff" produced by
effect(). Likewise arguments that you specify via trellis.par.set() may be
overridden by plot.eff().

You should be able to do some of what you want by specifying arguments such
as ticks.x to plot.eff() -- see ?plot.eff. Also, plot.eff() returns an
object that inherits from "trellis" and consequently you should be able to
manipulate it with the update() method for "trellis" objects. For example,

library(effects)
mod <- lm(prestige ~ type*(income + education), data=Prestige)
(eff <- effect("type*income", mod))
(p <- plot(eff))
update(p, scales=list(x=list(at=seq(10000, 20000, 5000), 
                             labels=seq(10000, 20000, 5000))))

Finally the object returned by effect() has a reasonably simple structure
and you should be able to construct a customized plot by using the
information in the object, e.g., with xyplot().

I hope that this helps,
 John

-------------------------------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario, Canada



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of otoolem
> Sent: December-10-13 11:25 PM
> To: r-help at r-project.org
> Subject: [R] setting effect plot parameters
> 
> I have tried to set parameters of an effects plot with moderate success,
but
> I'm finding that although the plot(effect()) method uses trellis graphics
(via
> the lattice package), not all aspects of the plot can be controlled by
standard
> trellis graphics.
> I am able to set any parameters that are given in trellis.par.get() easily
> enough, for example:
> axis.components <- trellis.par.get("axis.components")
> axis.components$right$tck <- 0 axis.components$top$tck <- 0
> axis.components$left$pad1 <- 2 axis.components$left$pad2 <- 2
> trellis.par.set("axis.components", axis.components) but I have been unable
> to change other axis parameters such as setting the number of ticks on the
> bottom and left axes. I can do this in a conventional lattice plot such as
xyplot
> xyplot(lar~mdep, data=m1, scales=list(     x=list(tck=c(1,0),
> at=seq(100,max(m1$mdep),100)),     y=list(tck=c(1,0),
> at=seq(0,max(m1$lar)+0.1,0.05))))
> but this does not work for effects plots.
> Any help would be much appreciated.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email is free from viruses and malware because avast! Antivirus protection is active.
http://www.avast.com


From michel.arnaud at cirad.fr  Wed Dec 11 14:00:41 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 11 Dec 2013 14:00:41 +0100
Subject: [R] To transform a vector of qualitatives values into a dataframe
 of quantitatives values
Message-ID: <52A861F9.1050401@cirad.fr>

Hi

 From the vector
X <- c(A, A, B, C, B, A, C)

I would like to build the Dataframe :
data.frame( A=c(1,1,0,0,0,1,0), B=c(0,0,1,0,1,0,0), C=c(0,0,0,1,0,0,1))

Any ideas ?


-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From petr.pikal at precheza.cz  Wed Dec 11 14:22:20 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 11 Dec 2013 13:22:20 +0000
Subject: [R] To transform a vector of qualitatives values into a
 dataframe of quantitatives values
In-Reply-To: <52A861F9.1050401@cirad.fr>
References: <52A861F9.1050401@cirad.fr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA6007@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Arnaud Michel
> Sent: Wednesday, December 11, 2013 2:01 PM
> To: R help
> Subject: [R] To transform a vector of qualitatives values into a
> dataframe of quantitatives values
> 
> Hi
> 
>  From the vector
> X <- c(A, A, B, C, B, A, C)

What is A, B and C? If you expect them to be letters, they need to be in parentheses.

> 
> I would like to build the Dataframe :
> data.frame( A=c(1,1,0,0,0,1,0), B=c(0,0,1,0,1,0,0), C=c(0,0,0,1,0,0,1))
> 
> Any ideas ?

X <- sample(letters[1:3], 10, replace=T)
X
 [1] "c" "c" "a" "b" "c" "c" "a" "a" "a" "a"
data.frame(A=(X=="a"), B=(X=="b"), C=(X=="c"))

Petr


> 
> 
> --
> Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Dec 11 14:43:11 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Dec 2013 08:43:11 -0500
Subject: [R] To transform a vector of qualitatives values into a
 dataframe of quantitatives values
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA6007@SRVEXCHMBX.precheza.cz>
References: <52A861F9.1050401@cirad.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA6007@SRVEXCHMBX.precheza.cz>
Message-ID: <52A86BEF.9060300@gmail.com>

On 13-12-11 8:22 AM, PIKAL Petr wrote:
> Hi
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Arnaud Michel
>> Sent: Wednesday, December 11, 2013 2:01 PM
>> To: R help
>> Subject: [R] To transform a vector of qualitatives values into a
>> dataframe of quantitatives values
>>
>> Hi
>>
>>   From the vector
>> X <- c(A, A, B, C, B, A, C)
>
> What is A, B and C? If you expect them to be letters, they need to be in parentheses.

You mean "quotes", not parentheses.

>
>>
>> I would like to build the Dataframe :
>> data.frame( A=c(1,1,0,0,0,1,0), B=c(0,0,1,0,1,0,0), C=c(0,0,0,1,0,0,1))
>>
>> Any ideas ?
>
> X <- sample(letters[1:3], 10, replace=T)
> X
>   [1] "c" "c" "a" "b" "c" "c" "a" "a" "a" "a"
> data.frame(A=(X=="a"), B=(X=="b"), C=(X=="c"))

A simpler way is to use model.matrix.  With your example,

X <- factor(X)
m <- model.matrix( ~ X - 1)

(The names of the columns may need adjusting.)

Duncan Murdoch


From r at quantide.com  Wed Dec 11 15:18:54 2013
From: r at quantide.com (Andrea Spano)
Date: Wed, 11 Dec 2013 15:18:54 +0100
Subject: [R] To transform a vector of qualitatives values into a
 dataframe of quantitatives values
In-Reply-To: <52A86BEF.9060300@gmail.com>
References: <52A861F9.1050401@cirad.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA6007@SRVEXCHMBX.precheza.cz>
	<52A86BEF.9060300@gmail.com>
Message-ID: <CAOtXCoCsx_9QwK0wsOY9XLNXnwFaSyN2ZQ_dGfiwdzE3+rj4LQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131211/739fafb3/attachment.pl>

From bakerwl at uwyo.edu  Wed Dec 11 16:19:45 2013
From: bakerwl at uwyo.edu (bakerwl)
Date: Wed, 11 Dec 2013 07:19:45 -0800 (PST)
Subject: [R] fisher.test - can I use non-integer expected values?
In-Reply-To: <F694EC60-1AA5-4D04-B372-2BB977B1117A@gmail.com>
References: <1386713073003-4681976.post@n4.nabble.com>
	<27F74B6B-FB26-40EE-9103-FE5787BB81A1@comcast.net>
	<1386730509852-4681989.post@n4.nabble.com>
	<CA+hbrhUL=3EyOLFxJj-_Un4eTN+rQrZiACcybysun2LBxwCEHQ@mail.gmail.com>
	<F694EC60-1AA5-4D04-B372-2BB977B1117A@gmail.com>
Message-ID: <1386775185063-4682013.post@n4.nabble.com>

Thank you David, Peter, and Peter,

I understand now that I would be misusing fisher.test to use it for a
goodness-of-fit test and that non-integer data are inappropriate since it is
for testing two sets of observed counts.

Peter D., it does not seem like a good idea for me to "cheat" fisher.test to
produce a goodness-of-fit outcome by using a larger set of expected data or
by generating all the configurations behind the fisher.test approach.
Wouldn't it be statistically inappropriate to turn fisher.test into a
goodness-of-fit test when it was not designed for this? Perhaps this is a
statistical question, not an R question, though. 

What is the R function that does an exact test for goodness-of-fit for
categorical data with > 2 categories?





--
View this message in context: http://r.789695.n4.nabble.com/fisher-test-can-I-use-non-integer-expected-values-tp4681976p4682013.html
Sent from the R help mailing list archive at Nabble.com.


From bbolker at gmail.com  Wed Dec 11 16:24:26 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Dec 2013 15:24:26 +0000
Subject: [R] 3-D interpretation
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
	<021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>
	<CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>
	<024301cef5c5$78fa6000$6aef2000$@tamu.edu>
	<CA+jRDxBuxxASSkRk2uCZ0F+N1YaXpfKhGanWf7xdBSfnW1uSMA@mail.gmail.com>
Message-ID: <loom.20131211T161018-956@post.gmane.org>

Shane Carey <careyshan <at> gmail.com> writes:

> 
> it just keeps crashing on me,
> 
> It seems to crash on this line
> 
> rgl.surface(akima.li$x,akima.li$y,akima.li$z,color="green",alpha=c(0.5))

  When I run the code you gave us along with the data you gave us,
I get

Error in rgl.surface(akima.li$X, akima.li$Y, akima.li$Z, color = "green",  : 
  rows < 2

  Maybe this is what you mean by "crashing"?  (On this list, "crash"
is usually reserved to mean that your instance of R stops abruptly ...
the behaviour above would be called an "error").

  Looking at the plot generated from the data you sent, all of
the (X,Y) points lie on a 1-dimensional curve in the (X,Y) plane --
it's not surprising that it's going to be hard to generate an
interpolated surface from these points.

  Or maybe I'm misunderstanding something.

rgl.spheres(dat$X,dat$Z , dat$Y,1,color="red")
rgl.bbox()
# bivariate linear interpolation
# interp:
akima.li <- interp(dat$X, dat$Y, dat$Z,
                   xo=seq(min(dat$X), max(dat$X), length = 100),
                   yo=seq(min(dat$Y), max(dat$Y), length = 100))
# interp surface:
rgl.surface(akima.li$X,akima.li$Y,akima.li$Z,color="green",alpha=c(0.5))


From bakerwl at uwyo.edu  Wed Dec 11 16:55:31 2013
From: bakerwl at uwyo.edu (bakerwl)
Date: Wed, 11 Dec 2013 07:55:31 -0800 (PST)
Subject: [R] fisher.test - can I use non-integer expected values?
In-Reply-To: <1386775185063-4682013.post@n4.nabble.com>
References: <1386713073003-4681976.post@n4.nabble.com>
	<27F74B6B-FB26-40EE-9103-FE5787BB81A1@comcast.net>
	<1386730509852-4681989.post@n4.nabble.com>
	<CA+hbrhUL=3EyOLFxJj-_Un4eTN+rQrZiACcybysun2LBxwCEHQ@mail.gmail.com>
	<F694EC60-1AA5-4D04-B372-2BB977B1117A@gmail.com>
	<1386775185063-4682013.post@n4.nabble.com>
Message-ID: <1386777331744-4682015.post@n4.nabble.com>

I think that I can answer my own question, which was which R function is
appropriate for the test I need. It looks like the EMT package and the exact
multinomial test is appropriate for goodness-of-fit to test a null
hypothesis of equal proportions, given at least 3 categories. Unless I am
wrong, I think this can end this discussion. I appreciate the help!



--
View this message in context: http://r.789695.n4.nabble.com/fisher-test-can-I-use-non-integer-expected-values-tp4681976p4682015.html
Sent from the R help mailing list archive at Nabble.com.


From kw.stat at gmail.com  Wed Dec 11 17:11:04 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 11 Dec 2013 10:11:04 -0600
Subject: [R] data distribution for lme
In-Reply-To: <52A7C0EA.6020207@auckland.ac.nz>
References: <52A72B7B.1010304@gmail.com>
	<CACk-te3HMhEDGr=7OQ7KHWO4_dkBi6vM2iQjL+KkUEuvko3EDA@mail.gmail.com>
	<52A7C0EA.6020207@auckland.ac.nz>
Message-ID: <CAKFxdiQ6tWjy1wwUSHVw1jffX-vA04gt7oE=Vb3PDgezcAP_KA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131211/23e152aa/attachment.pl>

From careyshan at gmail.com  Wed Dec 11 17:13:35 2013
From: careyshan at gmail.com (Shane Carey)
Date: Wed, 11 Dec 2013 16:13:35 +0000
Subject: [R] 3-D interpretation
In-Reply-To: <loom.20131211T161018-956@post.gmane.org>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
	<021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>
	<CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>
	<024301cef5c5$78fa6000$6aef2000$@tamu.edu>
	<CA+jRDxBuxxASSkRk2uCZ0F+N1YaXpfKhGanWf7xdBSfnW1uSMA@mail.gmail.com>
	<loom.20131211T161018-956@post.gmane.org>
Message-ID: <CA+jRDxBFsfGndvxvjjJcQqVt=nNCmDawVNgVd6cv1gcG05VOSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131211/667e4767/attachment.pl>

From bbolker at gmail.com  Wed Dec 11 17:24:15 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Dec 2013 11:24:15 -0500
Subject: [R] 3-D interpretation
In-Reply-To: <CA+jRDxBFsfGndvxvjjJcQqVt=nNCmDawVNgVd6cv1gcG05VOSQ@mail.gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>	<021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>	<CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>	<024301cef5c5$78fa6000$6aef2000$@tamu.edu>	<CA+jRDxBuxxASSkRk2uCZ0F+N1YaXpfKhGanWf7xdBSfnW1uSMA@mail.gmail.com>	<loom.20131211T161018-956@post.gmane.org>
	<CA+jRDxBFsfGndvxvjjJcQqVt=nNCmDawVNgVd6cv1gcG05VOSQ@mail.gmail.com>
Message-ID: <52A891AF.3080207@gmail.com>

On 13-12-11 11:13 AM, Shane Carey wrote:
> Hey,
> 
> Nope, it crashes. R stops abruptly. I sent just 500 points to show the
> structure of the data. There is in fact over 22,000 points and it is 3-D
> data composing of x,y,z data
> 
> Cheers

  We really, really need a reproducible example to be able to help
further.  Since the 'akima.li' object is the one causing the trouble
perhaps you could post the results of save() somewhere publicly accessible?

  Do you have the same problem if you skip the rgl.spheres() and
rgl.bbox() steps?

  I'm able to plot a 100x100 random surface, even one with lots of NAs,
without any trouble.  So there must be something special about akima.li
, and guessing is going to be very hard ...

  (At some point it might be useful to know your platform, version of R,
etc., but that will only really become useful if it turns out that other
people can plot your akima.li surface without any trouble ...)

  Ben Bolker

> 
> 
> On Wed, Dec 11, 2013 at 3:24 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> Shane Carey <careyshan <at> gmail.com> writes:
>>
>>>
>>> it just keeps crashing on me,
>>>
>>> It seems to crash on this line
>>>
>>> rgl.surface(akima.li$x,akima.li$y,akima.li$z,color="green",alpha=c(0.5))
>>
>>   When I run the code you gave us along with the data you gave us,
>> I get
>>
>> Error in rgl.surface(akima.li$X, akima.li$Y, akima.li$Z, color = "green",
>>  :
>>   rows < 2
>>
>>   Maybe this is what you mean by "crashing"?  (On this list, "crash"
>> is usually reserved to mean that your instance of R stops abruptly ...
>> the behaviour above would be called an "error").
>>
>>   Looking at the plot generated from the data you sent, all of
>> the (X,Y) points lie on a 1-dimensional curve in the (X,Y) plane --
>> it's not surprising that it's going to be hard to generate an
>> interpolated surface from these points.
>>
>>   Or maybe I'm misunderstanding something.
>>
>> rgl.spheres(dat$X,dat$Z , dat$Y,1,color="red")
>> rgl.bbox()
>> # bivariate linear interpolation
>> # interp:
>> akima.li <- interp(dat$X, dat$Y, dat$Z,
>>                    xo=seq(min(dat$X), max(dat$X), length = 100),
>>                    yo=seq(min(dat$Y), max(dat$Y), length = 100))
>> # interp surface:
>> rgl.surface(akima.li$X,akima.li$Y,akima.li$Z,color="green",alpha=c(0.5))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 
>


From careyshan at gmail.com  Wed Dec 11 17:41:02 2013
From: careyshan at gmail.com (Shane Carey)
Date: Wed, 11 Dec 2013 16:41:02 +0000
Subject: [R] 3-D interpretation
In-Reply-To: <52A891AF.3080207@gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
	<021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>
	<CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>
	<024301cef5c5$78fa6000$6aef2000$@tamu.edu>
	<CA+jRDxBuxxASSkRk2uCZ0F+N1YaXpfKhGanWf7xdBSfnW1uSMA@mail.gmail.com>
	<loom.20131211T161018-956@post.gmane.org>
	<CA+jRDxBFsfGndvxvjjJcQqVt=nNCmDawVNgVd6cv1gcG05VOSQ@mail.gmail.com>
	<52A891AF.3080207@gmail.com>
Message-ID: <CA+jRDxAA5h2gVLCYgxBhtsH7QkSwehB7FDO_Pyu+81Ne_4mp+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131211/9db4cfd3/attachment.pl>

From careyshan at gmail.com  Wed Dec 11 17:44:32 2013
From: careyshan at gmail.com (Shane Carey)
Date: Wed, 11 Dec 2013 16:44:32 +0000
Subject: [R] 3-D interpretation
In-Reply-To: <CA+jRDxAA5h2gVLCYgxBhtsH7QkSwehB7FDO_Pyu+81Ne_4mp+w@mail.gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
	<021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>
	<CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>
	<024301cef5c5$78fa6000$6aef2000$@tamu.edu>
	<CA+jRDxBuxxASSkRk2uCZ0F+N1YaXpfKhGanWf7xdBSfnW1uSMA@mail.gmail.com>
	<loom.20131211T161018-956@post.gmane.org>
	<CA+jRDxBFsfGndvxvjjJcQqVt=nNCmDawVNgVd6cv1gcG05VOSQ@mail.gmail.com>
	<52A891AF.3080207@gmail.com>
	<CA+jRDxAA5h2gVLCYgxBhtsH7QkSwehB7FDO_Pyu+81Ne_4mp+w@mail.gmail.com>
Message-ID: <CA+jRDxBogfM-ZWz3VT7DR6w41u3zBOx+UavhBazdXt3LpK9q-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131211/b2546f7c/attachment.pl>

From bbolker at gmail.com  Wed Dec 11 19:35:00 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Dec 2013 13:35:00 -0500
Subject: [R] 3-D interpretation
In-Reply-To: <CA+jRDxBogfM-ZWz3VT7DR6w41u3zBOx+UavhBazdXt3LpK9q-w@mail.gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>	<021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>	<CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>	<024301cef5c5$78fa6000$6aef2000$@tamu.edu>	<CA+jRDxBuxxASSkRk2uCZ0F+N1YaXpfKhGanWf7xdBSfnW1uSMA@mail.gmail.com>	<loom.20131211T161018-956@post.gmane.org>	<CA+jRDxBFsfGndvxvjjJcQqVt=nNCmDawVNgVd6cv1gcG05VOSQ@mail.gmail.com>	<52A891AF.3080207@gmail.com>	<CA+jRDxAA5h2gVLCYgxBhtsH7QkSwehB7FDO_Pyu+81Ne_4mp+w@mail.gmail.com>
	<CA+jRDxBogfM-ZWz3VT7DR6w41u3zBOx+UavhBazdXt3LpK9q-w@mail.gmail.com>
Message-ID: <52A8B054.9040700@gmail.com>


    I got a little bit farther.  The results are still very ugly, jagged
for linear interpolation and with a huge range of values for cubic
spline extrapolation.  I still don't know about the crash (can't
reproduce it), but don't know how you expect to be able to extrapolate a
sensible 3-D surface from points measured along a single narrow 1-D
curve in the X-Y plane ...  Can you propose *any* software tool/method
that can do a reasonable job of this?

source("akimatmp2.R")  ## BMB: contents from your data dump below,
   ## assigned to "dat2"
dat <- dat2
nrow(dat)  ## 1500

## BMB: this makes things a little prettier, but just cosmetic
dat <- transform(dat,X=X-min(X),Y=Y-min(Y))
library(rgl)
library(akima)
rgl.spheres(dat$X,dat$Z , dat$Y,1,color="red")
rgl.bbox()
# bivariate linear interpolation
# interp:

akima.li <- interp(dat$X, dat$Y, dat$Z,
                   xo=seq(min(dat$X), max(dat$X), length = 100),
                   yo=seq(min(dat$Y), max(dat$Y), length = 100),
                   duplicate="mean")
# interp surface:

## BMB: this worked for me once I specified *lowercase* (x,y,z)
## rather than *uppercase* (X,Y,Z) elements.

with(akima.li,rgl.surface(x,y,z,color="green",alpha=c(0.5)))

akima.ci0 <- interp(dat$X, dat$Y, dat$Z,
                   xo=seq(min(dat$X), max(dat$X), length = 100),
                   yo=seq(min(dat$Y), max(dat$Y), length = 100),
                   linear=FALSE,
                   duplicate="mean")
akima.ci0$z[!is.finite(akima.ci0$z)] <- NA
with(akima.ci0,image(x,y,z))
range(na.omit(c(akima.ci0$z)))  ## c() to treat as vector
## -250000 to 101000
range(dat$Z)  ## 3500 to 4400
summary(na.omit(c(akima.ci0$z)))
points(dat$X,dat$Y)

rgl.close()
rgl.spheres(dat$X,dat$Z , dat$Y,1,color="red")
rgl.bbox()
with(akima.ci0,rgl.surface(x,y,z,color="green",alpha=c(0.5)))


# bivariate cubic spline interpolation
# interp:
akima.si <- interp(dat$X, dat$Y, dat$Z,
                   xo=seq(min(dat$X), max(dat$X), length = 100),
                   yo=seq(min(dat$Y), max(dat$Y), length = 100),
                   linear = FALSE, extrap = TRUE,
                   duplicate="mean")
with(akima.si,rgl.surface(x,y,z,color="blue",alpha=c(0.5)))
with(akima.si,image(x,y,z))
filled.contour(akima.si$x,akima.si$y,akima.si$z)


On 13-12-11 11:44 AM, Shane Carey wrote:
> I want it as one block, if you know what I mean. Like the akima example.
> 
> Thanks
> 
> 
> On Wed, Dec 11, 2013 at 4:41 PM, Shane Carey <careyshan at gmail.com> wrote:
> 
>> Ok, here is the first 1500 points, but Im giving up hope on it to be
>> honest.
>> It seems to be going crazy, creating triangles everywhere. Do the points
>> need to be evenly spaced?
>> Thanks for your help.
>>
>> structure(list(X = c(9816966.951, 9816963.08, 9816947.516, 9816939.51,
>> 9816924.005, 9816916.096, 9816901.984, 9816896.967, 9816892.928,
>> 9816890.743, 9816886.427, 9816884.006, 9816879.185, 9816876.468,
>> 9816871.027, 9816868.276, 9816863.404, 9816860.712, 9816855.409,
>> 9816852.487, 9816846.77, 9816843.635, 9816837.53, 9816834.196,
>> 9816827.733, 9816824.214, 9816817.419, 9816811.926, 9816797.531,
>> 9816789.588, 9816774.134, 9816765.716, 9816749.492, 9816740.717,
>> 9816723.946, 9816714.931, 9816697.836, 9816675.781, 9816606.59,
>> 9816578.983, 9816544.487, 9816531.179, 9816514.376, 9816505.891,
>> 9816489.52, 9816481.288, 9816465.377, 9816457.374, 9816441.836,
>> 9816434.026, 9816418.807, 9816411.161, 9816396.205, 9816385.052,
>> 9816355.719, 9816341.037, 9816312.075, 9816304.796, 9816304.784,
>> 9816916.962, 9816917.365, 9816918.982, 9816919.414, 9816919.519,
>> 9816919.545, 9816599.694, 9816615.198, 9816677.27, 9816697.31,
>> 9816714.671, 9816723.431, 9816740.464, 9816748.995, 9816765.474,
>> 9816773.661, 9816789.36, 9816797.089, 9816811.764, 9816817.212,
>> 9816824.113, 9816827.536, 9816834.1, 9816837.345, 9816843.545,
>> 9816846.596, 9816852.404, 9816855.248, 9816860.635, 9816863.257,
>> 9816868.198, 9816870.861, 9816876.39, 9816879.039, 9816883.937,
>> 9816886.296, 9816890.68, 9816892.809, 9816896.829, 9816901.555,
>> 9816915.878, 9816921.977, 9816931.382, 9816933.721, 9816619.581,
>> 9816631.77, 9816680.572, 9816697.262, 9816714.648, 9816723.385,
>> 9816740.441, 9816748.95, 9816765.452, 9816773.618, 9816789.339,
>> 9816797.049, 9816811.749, 9816817.193, 9816824.103, 9816827.518,
>> 9816834.092, 9816837.328, 9816843.537, 9816846.58, 9816852.396,
>> 9816855.233, 9816860.628, 9816863.244, 9816868.191, 9816870.846,
>> 9816876.383, 9816879.025, 9816883.93, 9816886.284, 9816890.674,
>> 9816892.798, 9816896.817, 9816901.516, 9816915.859, 9816921.464,
>> 9816929.009, 9816930.886, 9816639.468, 9816648.343, 9816683.875,
>> 9816697.215, 9816714.624, 9816723.338, 9816740.418, 9816748.905,
>> 9816765.43, 9816773.575, 9816789.318, 9816797.009, 9816811.734,
>> 9816817.175, 9816824.094, 9816827.5, 9816834.083, 9816837.311,
>> 9816843.528, 9816846.565, 9816852.389, 9816855.218, 9816860.621,
>> 9816863.23, 9816868.184, 9816870.831, 9816876.376, 9816879.012,
>> 9816883.924, 9816886.272, 9816890.669, 9816892.787, 9816896.805,
>> 9816901.477, 9816915.839, 9816920.952, 9816926.637, 9816928.05,
>> 9816659.354, 9816664.915, 9816687.177, 9816697.167, 9816714.6,
>> 9816723.291, 9816740.395, 9816748.859, 9816765.407, 9816773.532,
>> 9816789.298, 9816796.969, 9816811.719, 9816817.156, 9816824.085,
>> 9816827.482, 9816834.074, 9816837.294, 9816843.52, 9816846.549,
>> 9816852.381, 9816855.204, 9816860.614, 9816863.217, 9816868.176,
>> 9816870.816, 9816876.369, 9816878.999, 9816883.918, 9816886.26,
>> 9816890.663, 9816892.777, 9816896.792, 9816901.438, 9816915.819,
>> 9816920.439, 9816924.264, 9816925.215, 9816679.241, 9816681.487,
>> 9816690.48, 9816697.119, 9816714.577, 9816723.244, 9816740.372,
>> 9816748.814, 9816765.385, 9816773.489, 9816789.277, 9816796.929,
>> 9816811.705, 9816817.137, 9816824.076, 9816827.464, 9816834.065,
>> 9816837.277, 9816843.512, 9816846.533, 9816852.373, 9816855.189,
>> 9816860.607, 9816863.203, 9816868.169, 9816870.801, 9816876.362,
>> 9816878.985, 9816883.911, 9816886.248, 9816890.657, 9816892.766,
>> 9816896.78, 9816901.399, 9816915.799, 9816919.926, 9816921.892,
>> 9816922.38, 9816541.016, 9816548.667, 9816579.391, 9816605.021,
>> 9816675.293, 9816697.454, 9816714.742, 9816723.572, 9816740.533,
>> 9816749.131, 9816765.54, 9816773.79, 9816789.422, 9816797.21,
>> 9816811.808, 9816817.269, 9816824.14, 9816827.589, 9816834.126,
>> 9816837.395, 9816843.569, 9816846.643, 9816852.427, 9816855.292,
>> 9816860.656, 9816863.297, 9816868.219, 9816870.906, 9816876.411,
>> 9816879.078, 9816883.956, 9816886.331, 9816890.697, 9816892.842,
>> 9816896.867, 9816901.672, 9816915.938, 9816923.514, 9816938.5,
>> 9816942.226, 9816560.486, 9816564.893, 9816582.587, 9816604.825,
>> 9816675.232, 9816697.406, 9816714.719, 9816723.525, 9816740.51,
>> 9816749.085, 9816765.518, 9816773.747, 9816789.401, 9816797.17,
>> 9816811.793, 9816817.25, 9816824.131, 9816827.572, 9816834.118,
>> 9816837.378, 9816843.561, 9816846.628, 9816852.419, 9816855.277,
>> 9816860.649, 9816863.284, 9816868.212, 9816870.891, 9816876.404,
>> 9816879.065, 9816883.949, 9816886.32, 9816890.692, 9816892.831,
>> 9816896.854, 9816901.633, 9816915.918, 9816923.002, 9816936.127,
>> 9816939.391, 9816579.957, 9816581.118, 9816585.783, 9816604.629,
>> 9816675.171, 9816697.358, 9816714.695, 9816723.478, 9816740.487,
>> 9816749.04, 9816765.496, 9816773.704, 9816789.381, 9816797.13,
>> 9816811.778, 9816817.231, 9816824.122, 9816827.554, 9816834.109,
>> 9816837.361, 9816843.553, 9816846.612, 9816852.411, 9816855.262,
>> 9816860.642, 9816863.27, 9816868.205, 9816870.876, 9816876.397,
>> 9816879.052, 9816883.943, 9816886.308, 9816890.686, 9816892.82,
>> 9816896.842, 9816901.594, 9816915.898, 9816922.489, 9816933.755,
>> 9816936.556, 9816521.879, 9816524.089, 9816532.945, 9816543.835,
>> 9816578.476, 9816605.217, 9816675.354, 9816697.501, 9816714.766,
>> 9816723.618, 9816740.556, 9816749.176, 9816765.562, 9816773.833,
>> 9816789.443, 9816797.25, 9816811.823, 9816817.287, 9816824.149,
>> 9816827.607, 9816834.135, 9816837.412, 9816843.577, 9816846.659,
>> 9816852.434, 9816855.306, 9816860.663, 9816863.311, 9816868.226,
>> 9816870.922, 9816876.419, 9816879.092, 9816883.962, 9816886.343,
>> 9816890.703, 9816892.852, 9816896.879, 9816901.711, 9816915.958,
>> 9816923.725, 9816939.367, 9816943.604, 9816944.908, 9816945.232,
>> 9816503.043, 9816504.183, 9816508.745, 9816514.107, 9816530.972,
>> 9816543.928, 9816578.549, 9816605.413, 9816675.415, 9816697.549,
>> 9816714.79, 9816723.665, 9816740.579, 9816749.221, 9816765.584,
>> 9816773.876, 9816789.464, 9816797.29, 9816811.837, 9816817.306,
>> 9816824.158, 9816827.625, 9816834.144, 9816837.429, 9816843.586,
>> 9816846.675, 9816852.442, 9816855.321, 9816860.67, 9816863.324,
>> 9816868.233, 9816870.937, 9816876.426, 9816879.105, 9816883.968,
>> 9816886.355, 9816890.709, 9816892.863, 9816896.892, 9816901.75,
>> 9816915.977, 9816923.765, 9816939.387, 9816944.163, 9816947.504,
>> 9816948.335, 9816483.505, 9816483.785, 9816484.906, 9816489.303,
>> 9816505.781, 9816514.152, 9816531.007, 9816544.021, 9816578.621,
>> 9816605.61, 9816675.476, 9816697.597, 9816714.813, 9816723.712,
>> 9816740.602, 9816749.266, 9816765.606, 9816773.919, 9816789.485,
>> 9816797.33, 9816811.852, 9816817.325, 9816824.168, 9816827.643,
>> 9816834.152, 9816837.446, 9816843.594, 9816846.691, 9816852.449,
>> 9816855.336, 9816860.677, 9816863.337, 9816868.24, 9816870.952,
>> 9816876.433, 9816879.118, 9816883.975, 9816886.367, 9816890.714,
>> 9816892.874, 9816896.904, 9816901.789, 9816915.997, 9816923.805,
>> 9816939.407, 9816944.722, 9816950.1, 9816951.437, 9816440.173,
>> 9816443.676, 9816457.692, 9816465.209, 9816481.202, 9816489.346,
>> 9816505.803, 9816514.197, 9816531.041, 9816544.114, 9816578.693,
>> 9816605.806, 9816675.537, 9816697.645, 9816714.837, 9816723.759,
>> 9816740.625, 9816749.311, 9816765.628, 9816773.962, 9816789.505,
>> 9816797.37, 9816811.867, 9816817.344, 9816824.177, 9816827.661,
>> 9816834.161, 9816837.463, 9816843.602, 9816846.707, 9816852.457,
>> 9816855.35, 9816860.684, 9816863.351, 9816868.247, 9816870.967,
>> 9816876.44, 9816879.132, 9816883.981, 9816886.379, 9816890.72,
>> 9816892.885, 9816896.917, 9816901.828, 9816916.017, 9816923.845,
>> 9816939.428, 9816945.281, 9816952.696, 9816954.54, 9816398.533,
>> 9816401.252, 9816412.135, 9816418.687, 9816433.966, 9816441.714,
>> 9816457.312, 9816465.251, 9816481.224, 9816489.39, 9816505.825,
>> 9816514.241, 9816531.076, 9816544.207, 9816578.766, 9816606.002,
>> 9816675.598, 9816697.693, 9816714.86, 9816723.806, 9816740.648,
>> 9816749.356, 9816765.65, 9816774.005, 9816789.526, 9816797.41,
>> 9816811.882, 9816817.363, 9816824.186, 9816827.679, 9816834.17,
>> 9816837.48, 9816843.61, 9816846.722, 9816852.465, 9816855.365,
>> 9816860.691, 9816863.364, 9816868.255, 9816870.982, 9816876.447,
>> 9816879.145, 9816883.987, 9816886.391, 9816890.726, 9816892.896,
>> 9816896.929, 9816901.867, 9816916.037, 9816923.885, 9816939.448,
>> 9816945.84, 9816955.292, 9816957.643, 9816358.103, 9816363.81,
>> 9816386.643, 9816396.126, 9816411.121, 9816418.727, 9816433.986,
>> 9816441.755, 9816457.333, 9816465.293, 9816481.245, 9816489.433,
>> 9816505.847, 9816514.286, 9816531.11, 9816544.301, 9816578.838,
>> 9816606.198, 9816675.659, 9816697.74, 9816714.884, 9816723.852,
>> 9816740.671, 9816749.402, 9816765.672, 9816774.048, 9816789.547,
>> 9816797.45, 9816811.896, 9816817.382, 9816824.195, 9816827.697,
>> 9816834.178, 9816837.496, 9816843.618, 9816846.738, 9816852.472,
>> 9816855.379, 9816860.698, 9816863.378, 9816868.262, 9816870.997,
>> 9816876.454, 9816879.158, 9816883.993, 9816886.403, 9816890.731,
>> 9816892.907, 9816896.942, 9816901.906, 9816916.056, 9816923.925,
>> 9816939.469, 9816946.399, 9816957.888, 9816960.745, 9816318.255,
>> 9816323.251, 9816343.25, 9816355.642, 9816385.023, 9816396.165,
>> 9816411.141, 9816418.767, 9816434.006, 9816441.796, 9816457.353,
>> 9816465.335, 9816481.266, 9816489.477, 9816505.869, 9816514.331,
>> 9816531.145, 9816544.394, 9816578.91, 9816606.394, 9816675.72,
>> 9816697.788, 9816714.908, 9816723.899, 9816740.694, 9816749.447,
>> 9816765.694, 9816774.091, 9816789.568, 9816797.491, 9816811.911,
>> 9816817.4, 9816824.204, 9816827.715, 9816834.187, 9816837.513,
>> 9816843.626, 9816846.754, 9816852.48, 9816855.394, 9816860.705,
>> 9816863.391, 9816868.269, 9816871.012, 9816876.461, 9816879.172,
>> 9816884, 9816886.415, 9816890.737, 9816892.917, 9816896.954,
>> 9816901.945, 9816916.076, 9816923.965, 9816939.489, 9816946.958,
>> 9816960.484, 9816963.848, 9816969.359, 9816969.355, 9816969.279,
>> 9816969.038, 9816968.979, 9816969.359, 9816969.345, 9816969.078,
>> 9816968.233, 9816968.025, 9816969.359, 9816969.334, 9816968.878,
>> 9816967.428, 9816967.071, 9816969.359, 9816969.324, 9816968.677,
>> 9816966.622, 9816966.118, 9816969.359, 9816969.313, 9816968.476,
>> 9816965.817, 9816965.164, 9816969.359, 9816969.303, 9816968.275,
>> 9816965.012, 9816964.21, 9816969.359, 9816969.292, 9816968.074,
>> 9816964.207, 9816963.256, 9816969.359, 9816969.282, 9816967.874,
>> 9816963.401, 9816962.303, 9816969.359, 9816969.271, 9816967.673,
>> 9816962.596, 9816961.349, 9816969.359, 9816969.261, 9816967.472,
>> 9816961.791, 9816960.395, 9816969.359, 9816969.25, 9816967.271,
>> 9816960.985, 9816959.441, 9816969.359, 9816969.24, 9816967.07,
>> 9816960.18, 9816958.488, 9816969.359, 9816969.23, 9816966.87,
>> 9816959.375, 9816957.534, 9816969.359, 9816969.219, 9816966.669,
>> 9816958.57, 9816956.58, 9816969.359, 9816969.209, 9816966.468,
>> 9816957.764, 9816955.626, 9816969.359, 9816969.198, 9816966.267,
>> 9816956.959, 9816954.672, 9816969.359, 9816969.188, 9816966.066,
>> 9816956.154, 9816953.719, 9816969.359, 9816969.177, 9816965.865,
>> 9816955.349, 9816952.765, 9816969.359, 9816969.167, 9816965.665,
>> 9816954.543, 9816951.811, 9816969.359, 9816969.156, 9816965.464,
>> 9816953.738, 9816950.857, 9816969.359, 9816969.146, 9816965.263,
>> 9816952.933, 9816949.904, 9816969.359, 9816969.135, 9816965.062,
>> 9816952.128, 9816948.95, 9816969.359, 9816969.125, 9816964.861,
>> 9816951.322, 9816947.996, 9816969.359, 9816969.114, 9816964.661,
>> 9816950.517, 9816947.042, 9816969.359, 9816969.104, 9816964.46,
>> 9816949.712, 9816946.089, 9816969.359, 9816969.094, 9816964.259,
>> 9816948.907, 9816945.135, 9816969.359, 9816969.083, 9816964.058,
>> 9816948.101, 9816944.181, 9816969.359, 9816969.073, 9816963.861,
>> 9816947.311, 9816943.242, 9816943.232, 9816943.229, 9816969.359,
>> 9816969.062, 9816963.819, 9816947.291, 9816943.057, 9816942.495,
>> 9816942.357, 9816969.359, 9816969.052, 9816963.777, 9816947.27,
>> 9816942.872, 9816941.759, 9816941.486, 9816969.359, 9816969.041,
>> 9816963.735, 9816947.25, 9816942.686, 9816941.023, 9816940.614,
>> 9816969.359, 9816969.031, 9816963.693, 9816947.229, 9816942.501,
>> 9816940.286, 9816939.743, 9816969.359, 9816969.02, 9816963.651,
>> 9816947.209, 9816942.316, 9816939.55, 9816938.871, 9816969.359,
>> 9816969.01, 9816963.609, 9816947.189, 9816942.13, 9816938.814,
>> 9816938, 9816969.359, 9816968.999, 9816963.568, 9816947.168,
>> 9816941.945, 9816938.078, 9816937.128, 9816969.359, 9816968.989,
>> 9816963.526, 9816947.148, 9816941.76, 9816937.341, 9816936.257,
>> 9816969.359, 9816968.978, 9816963.484, 9816947.127, 9816941.575,
>> 9816936.605, 9816935.385, 9816969.359, 9816968.968, 9816963.442,
>> 9816947.107, 9816941.389, 9816935.869, 9816934.514, 9816969.359,
>> 9816968.958, 9816963.4, 9816947.086, 9816941.204, 9816935.133,
>> 9816933.642, 9816969.359, 9816968.947, 9816963.358, 9816947.066,
>> 9816941.019, 9816934.396, 9816932.771, 9816969.359, 9816968.937,
>> 9816963.317, 9816947.045, 9816940.833, 9816933.66, 9816931.899,
>> 9816969.359, 9816968.926, 9816963.275, 9816947.025, 9816940.648,
>> 9816932.924, 9816931.028, 9816969.359, 9816968.916, 9816963.233,
>> 9816947.004, 9816940.463, 9816932.187, 9816930.156, 9816969.359,
>> 9816968.905, 9816963.191, 9816946.984, 9816940.277, 9816931.451,
>> 9816929.285, 9816969.359, 9816968.895, 9816963.149, 9816946.963,
>> 9816940.092, 9816930.715, 9816928.413, 9816969.359, 9816968.884,
>> 9816963.107, 9816946.943, 9816939.907, 9816929.979, 9816927.542,
>> 9816969.359, 9816968.874, 9816963.066, 9816946.922, 9816939.721,
>> 9816929.242, 9816926.67, 9816969.359, 9816968.863, 9816963.024,
>> 9816946.902, 9816939.536, 9816928.506, 9816925.799, 9816969.359,
>> 9816968.853, 9816962.982, 9816946.881, 9816939.351, 9816927.77,
>> 9816924.927, 9816969.359, 9816968.842, 9816962.94, 9816946.861,
>> 9816939.165, 9816927.034, 9816924.056, 9816969.359, 9816968.832,
>> 9816962.898, 9816946.84, 9816938.98, 9816926.297, 9816923.184,
>> 9816969.359, 9816968.822, 9816962.856, 9816946.82, 9816938.795,
>> 9816925.561, 9816922.313, 9816969.359, 9816968.811, 9816962.814,
>> 9816946.799, 9816938.61, 9816924.825, 9816921.441, 9816969.359,
>> 9816968.801, 9816962.773, 9816946.779, 9816938.424, 9816924.089,
>> 9816920.57, 9816969.359, 9816968.79, 9816962.731, 9816946.759,
>> 9816938.239, 9816923.352, 9816919.698, 9816969.359, 9816968.78,
>> 9816962.689, 9816946.738, 9816938.147, 9816923.075, 9816915.758,
>> 9816901.367, 9816896.756, 9816892.751, 9816890.633, 9816886.232,
>> 9816883.882, 9816878.967, 9816876.326, 9816870.783, 9816868.135,
>> 9816863.186, 9816860.574, 9816855.172, 9816852.344, 9816846.518,
>> 9816843.488, 9816837.264, 9816834.046, 9816827.453, 9816824.063,
>> 9816817.127, 9816814.573, 9816811.312, 9816810.498, 9816969.359,
>> 9816968.769, 9816962.647, 9816946.718, 9816938.107, 9816923.055,
>> 9816915.719, 9816901.355, 9816896.745, 9816892.746, 9816890.621,
>> 9816886.226, 9816883.869, 9816878.96, 9816876.311, 9816870.776,
>> 9816868.121, 9816863.179, 9816860.56, 9816855.165, 9816852.329,
>> 9816846.509, 9816843.471, 9816837.255, 9816834.028, 9816827.444,
>> 9816824.044, 9816817.112, 9816811.653, 9816796.899, 9816791.307,
>> 9816783.741, 9816781.85, 9816969.359, 9816968.759, 9816962.605,
>> 9816946.697, 9816938.067, 9816923.035, 9816915.68, 9816901.342,
>> 9816896.734, 9816892.74, 9816890.61, 9816886.219, 9816883.856,
>> 9816878.953, 9816876.296, 9816870.769, 9816868.108, 9816863.172,
>> 9816860.545, 9816855.157, 9816852.313, 9816846.501, 9816843.454,
>> 9816837.246, 9816834.01, 9816827.434, 9816824.025, 9816817.098,
>> 9816811.612, 9816796.878, 9816789.209, 9816773.449, 9816766.432,
>> 9816754.204, 9816751.148, 9816969.359, 9816968.748, 9816962.563,
>> 9816946.677, 9816938.026, 9816923.016, 9816915.641, 9816901.33,
>> 9816896.723, 9816892.734, 9816890.598, 9816886.213, 9816883.842,
>> 9816878.946, 9816876.281, 9816870.762, 9816868.094, 9816863.165,
>> 9816860.53, 9816855.15, 9816852.297, 9816846.493, 9816843.437,
>> 9816837.237, 9816833.992, 9816827.425, 9816824.006, 9816817.083,
>> 9816811.572, 9816796.857, 9816789.166, 9816773.427, 9816765.303,
>> 9816748.764, 9816740.333, 9816723.262, 9816718.996, 9816969.359,
>> 9816968.738, 9816962.522, 9816946.656, 9816937.986, 9816922.996,
>> 9816915.602, 9816901.317, 9816896.712, 9816892.728, 9816890.586,
>> 9816886.207, 9816883.829, 9816878.939, 9816876.266, 9816870.755,
>> 9816868.081, 9816863.158, 9816860.516, 9816855.142, 9816852.281,
>> 9816846.485, 9816843.42, 9816837.229, 9816833.975, 9816827.416,
>> 9816823.987, 9816817.068, 9816811.532, 9816796.836, 9816789.123,
>> 9816773.405, 9816765.258, 9816748.741, 9816740.275, 9816723.183,
>> 9816714.514, 9816697.065, 9816675.046, 9816604.224, 9816576.996,
>> 9816543.212, 9816529.997, 9816513.594, 9816504.709, 9816488.747,
>> 9816480.024, 9816464.605, 9816456.114, 9816441.085, 9816432.766,
>> 9816418.074, 9816409.898, 9816395.185, 9816382.56, 9816354.343,
>> 9816338.456, 9816311.391, 9816304.784, 9816969.359, 9816968.727,
>> 9816962.48, 9816946.636, 9816937.946, 9816922.976, 9816915.563,
>> 9816901.305, 9816896.702, 9816892.723, 9816890.574, 9816886.201,
>> 9816883.816, 9816878.932, 9816876.251, 9816870.748, 9816868.068,
>> 9816863.151, 9816860.501, 9816855.134, 9816852.265, 9816846.477,
>> 9816843.403, 9816837.22, 9816833.957, 9816827.407, 9816823.969,
>> 9816817.053, 9816811.492, 9816796.815, 9816789.08, 9816773.383,
>> 9816765.213, 9816748.718, 9816740.228, 9816723.16, 9816714.466,
>> 9816697.004, 9816674.85, 9816604.151, 9816576.903, 9816543.177,
>> 9816529.952, 9816513.572, 9816504.666, 9816488.725, 9816479.982,
>> 9816464.584, 9816456.073, 9816441.065, 9816432.726, 9816418.054,
>> 9816409.858, 9816395.156, 9816382.483, 9816354.304, 9816338.38,
>> 9816311.372, 9816304.784, 9816969.359, 9816968.717, 9816962.438,
>> 9816946.615, 9816937.906, 9816922.956, 9816915.524, 9816901.292,
>> 9816896.691, 9816892.717, 9816890.562, 9816886.194, 9816883.802,
>> 9816878.925, 9816876.236, 9816870.741, 9816868.054, 9816863.144,
>> 9816860.486, 9816855.127, 9816852.25, 9816846.469, 9816843.386,
>> 9816837.211, 9816833.939, 9816827.398, 9816823.95, 9816817.039,
>> 9816811.452, 9816796.795, 9816789.037, 9816773.361, 9816765.168,
>> 9816748.695, 9816740.182, 9816723.136, 9816714.418, 9816696.943,
>> 9816674.654, 9816604.079, 9816576.81, 9816543.143, 9816529.907,
>> 9816513.549, 9816504.622, 9816488.704, 9816479.94, 9816464.564,
>> 9816456.032, 9816441.045, 9816432.686, 9816418.034, 9816409.819,
>> 9816395.127, 9816382.407, 9816354.266, 9816338.305, 9816311.353,
>> 9816304.784, 9816969.359, 9816968.706, 9816962.396, 9816946.595,
>> 9816937.866, 9816922.936, 9816915.485, 9816901.28, 9816896.68,
>> 9816892.711, 9816890.55, 9816886.188, 9816883.789, 9816878.918,
>> 9816876.221, 9816870.734, 9816868.041, 9816863.137, 9816860.472,
>> 9816855.119, 9816852.234, 9816846.46, 9816843.369, 9816837.203,
>> 9816833.921, 9816827.389, 9816823.931, 9816817.024, 9816811.412,
>> 9816796.774, 9816788.994, 9816773.339, 9816765.122, 9816748.672,
>> 9816740.135, 9816723.112, 9816714.371, 9816696.882, 9816674.458,
>> 9816604.007, 9816576.717, 9816543.109, 9816529.863, 9816513.527,
>> 9816504.579, 9816488.682, 9816479.898, 9816464.543, 9816455.991,
>> 9816441.025, 9816432.646, 9816418.015, 9816409.78, 9816395.098,
>> 9816382.33, 9816354.228, 9816338.229, 9816311.335, 9816304.784,
>> 9816969.359, 9816968.696, 9816962.354, 9816946.574, 9816937.826,
>> 9816922.917, 9816915.446, 9816901.267, 9816896.669, 9816892.706,
>> 9816890.538, 9816886.182, 9816883.776, 9816878.911, 9816876.206,
>> 9816870.727, 9816868.027, 9816863.13, 9816860.457, 9816855.112,
>> 9816852.218, 9816846.452, 9816843.353, 9816837.194, 9816833.903,
>> 9816827.379, 9816823.912, 9816817.009, 9816811.372, 9816796.753,
>> 9816788.951, 9816773.317, 9816765.077, 9816748.649, 9816740.088,
>> 9816723.089, 9816714.323, 9816696.821, 9816674.262, 9816603.934,
>> 9816576.623, 9816543.074, 9816529.818, 9816513.505, 9816504.535,
>> 9816488.661, 9816479.856, 9816464.522, 9816455.95, 9816441.005,
>> 9816432.606, 9816417.995, 9816409.741, 9816395.069, 9816382.253,
>> 9816354.19, 9816338.153, 9816311.316, 9816304.784, 9816969.359,
>> 9816968.686, 9816962.312, 9816946.554, 9816937.786, 9816922.897,
>> 9816915.407), Y = c(6685246.262, 6685259.661, 6685313.533, 6685342.653,
>> 6685402.003, 6685433.827, 6685494.079, 6685515.065, 6685530.452,
>> 6685538.336, 6685553.068, 6685560.845, 6685575.358, 6685583.002,
>> 6685597.245, 6685604.053, 6685615.247, 6685621.127, 6685632.091,
>> 6685637.868, 6685648.642, 6685654.322, 6685664.913, 6685670.499,
>> 6685680.917, 6685686.414, 6685696.667, 6685704.514, 6685724.452,
>> 6685734.976, 6685754.466, 6685764.715, 6685783.716, 6685793.726,
>> 6685812.306, 6685822.114, 6685840.341, 6685863.242, 6685934.549,
>> 6685963.196, 6685999.539, 6686013.753, 6686032.223, 6686041.737,
>> 6686060.477, 6686070.119, 6686089.207, 6686099.015, 6686118.482,
>> 6686128.449, 6686148.244, 6686158.343, 6686178.415, 6686193.73,
>> 6686234.484, 6686255.141, 6686296.412, 6686306.785, 6686306.803,
>> 6685430.056, 6685428.329, 6685421.421, 6685419.586, 6685419.183,
>> 6685419.082, 6685941.655, 6685925.678, 6685861.712, 6685840.901,
>> 6685822.396, 6685812.876, 6685794.014, 6685784.297, 6685765.009,
>> 6685755.061, 6685735.277, 6685725.063, 6685704.745, 6685696.98,
>> 6685686.572, 6685681.234, 6685670.659, 6685665.235, 6685654.484,
>> 6685648.969, 6685638.033, 6685632.423, 6685621.294, 6685615.585,
>> 6685604.246, 6685597.676, 6685583.22, 6685575.798, 6685561.067,
>> 6685553.515, 6685538.561, 6685530.905, 6685515.637, 6685495.914,
>> 6685434.708, 6685409.771, 6685373.751, 6685364.795, 6685921.162,
>> 6685908.601, 6685858.31, 6685840.952, 6685822.422, 6685812.928,
>> 6685794.04, 6685784.35, 6685765.036, 6685755.115, 6685735.305,
>> 6685725.118, 6685704.766, 6685697.008, 6685686.586, 6685681.263,
>> 6685670.673, 6685665.264, 6685654.499, 6685648.999, 6685638.048,
>> 6685632.454, 6685621.31, 6685615.616, 6685604.263, 6685597.715,
>> 6685583.24, 6685575.838, 6685561.087, 6685553.555, 6685538.581,
>> 6685530.946, 6685515.689, 6685496.08, 6685434.788, 6685411.734,
>> 6685382.838, 6685375.652, 6685900.669, 6685891.523, 6685854.907,
>> 6685841.003, 6685822.448, 6685812.98, 6685794.066, 6685784.403,
>> 6685765.063, 6685755.169, 6685735.332, 6685725.174, 6685704.787,
>> 6685697.036, 6685686.6, 6685681.292, 6685670.688, 6685665.293,
>> 6685654.513, 6685649.029, 6685638.063, 6685632.484, 6685621.325,
>> 6685615.646, 6685604.281, 6685597.755, 6685583.259, 6685575.878,
>> 6685561.107, 6685553.596, 6685538.602, 6685530.987, 6685515.741,
>> 6685496.247, 6685434.868, 6685413.697, 6685391.924, 6685386.51,
>> 6685880.176, 6685874.446, 6685851.504, 6685841.054, 6685822.473,
>> 6685813.031, 6685794.093, 6685784.456, 6685765.09, 6685755.224,
>> 6685735.36, 6685725.229, 6685704.808, 6685697.065, 6685686.615,
>> 6685681.321, 6685670.702, 6685665.323, 6685654.528, 6685649.058,
>> 6685638.078, 6685632.514, 6685621.34, 6685615.677, 6685604.298,
>> 6685597.794, 6685583.279, 6685575.918, 6685561.127, 6685553.637,
>> 6685538.622, 6685531.028, 6685515.793, 6685496.414, 6685434.948,
>> 6685415.66, 6685401.01, 6685397.367, 6685859.683, 6685857.368,
>> 6685848.101, 6685841.105, 6685822.499, 6685813.083, 6685794.119,
>> 6685784.509, 6685765.116, 6685755.278, 6685735.387, 6685725.285,
>> 6685704.829, 6685697.093, 6685686.629, 6685681.349, 6685670.717,
>> 6685665.352, 6685654.543, 6685649.088, 6685638.093, 6685632.544,
>> 6685621.355, 6685615.708, 6685604.316, 6685597.833, 6685583.299,
>> 6685575.958, 6685561.148, 6685553.677, 6685538.643, 6685531.069,
>> 6685515.845, 6685496.581, 6685435.028, 6685417.623, 6685410.096,
>> 6685408.225, 6686003.197, 6685995.133, 6685962.757, 6685936.166,
>> 6685863.748, 6685840.748, 6685822.319, 6685812.72, 6685793.936,
>> 6685784.139, 6685764.929, 6685754.899, 6685735.195, 6685724.896,
>> 6685704.682, 6685696.895, 6685686.529, 6685681.148, 6685670.615,
>> 6685665.147, 6685654.44, 6685648.88, 6685637.988, 6685632.333,
>> 6685621.249, 6685615.493, 6685604.193, 6685597.558, 6685583.16,
>> 6685575.678, 6685561.007, 6685553.393, 6685538.5, 6685530.781,
>> 6685515.481, 6685495.413, 6685434.468, 6685403.881, 6685346.492,
>> 6685332.222, 6685982.677, 6685978.033, 6685959.387, 6685936.368,
>> 6685863.811, 6685840.799, 6685822.345, 6685812.772, 6685793.962,
>> 6685784.192, 6685764.956, 6685754.953, 6685735.223, 6685724.952,
>> 6685704.703, 6685696.923, 6685686.543, 6685681.177, 6685670.63,
>> 6685665.176, 6685654.454, 6685648.91, 6685638.003, 6685632.363,
>> 6685621.264, 6685615.524, 6685604.211, 6685597.598, 6685583.18,
>> 6685575.718, 6685561.027, 6685553.434, 6685538.52, 6685530.822,
>> 6685515.533, 6685495.58, 6685434.548, 6685405.845, 6685355.579,
>> 6685343.08, 6685962.158, 6685960.933, 6685956.018, 6685936.57,
>> 6685863.874, 6685840.85, 6685822.371, 6685812.824, 6685793.988,
>> 6685784.245, 6685764.983, 6685755.007, 6685735.25, 6685725.007,
>> 6685704.724, 6685696.951, 6685686.557, 6685681.205, 6685670.644,
>> 6685665.206, 6685654.469, 6685648.939, 6685638.018, 6685632.393,
>> 6685621.279, 6685615.554, 6685604.228, 6685597.637, 6685583.2,
>> 6685575.758, 6685561.047, 6685553.474, 6685538.541, 6685530.864,
>> 6685515.585, 6685495.747, 6685434.628, 6685407.808, 6685364.665,
>> 6685353.937, 6686023.971, 6686021.541, 6686011.804, 6686000.226,
>> 6685963.722, 6685935.964, 6685863.685, 6685840.697, 6685822.293,
>> 6685812.669, 6685793.909, 6685784.086, 6685764.902, 6685754.845,
>> 6685735.168, 6685724.84, 6685704.661, 6685696.866, 6685686.514,
>> 6685681.119, 6685670.601, 6685665.118, 6685654.425, 6685648.85,
>> 6685637.973, 6685632.303, 6685621.233, 6685615.462, 6685604.176,
>> 6685597.519, 6685583.141, 6685575.638, 6685560.986, 6685553.352,
>> 6685538.479, 6685530.74, 6685515.429, 6685495.246, 6685434.388,
>> 6685403.077, 6685343.175, 6685327.077, 6685322.563, 6685321.44,
>> 6686044.994, 6686043.689, 6686038.466, 6686032.518, 6686013.974,
>> 6686000.128, 6685963.647, 6685935.762, 6685863.621, 6685840.646,
>> 6685822.268, 6685812.617, 6685793.883, 6685784.033, 6685764.876,
>> 6685754.791, 6685735.14, 6685724.785, 6685704.64, 6685696.838,
>> 6685686.5, 6685681.09, 6685670.586, 6685665.089, 6685654.41,
>> 6685648.82, 6685637.958, 6685632.272, 6685621.218, 6685615.431,
>> 6685604.158, 6685597.48, 6685583.121, 6685575.598, 6685560.966,
>> 6685553.312, 6685538.459, 6685530.699, 6685515.377, 6685495.08,
>> 6685434.308, 6685402.923, 6685343.1, 6685325.142, 6685313.577,
>> 6685310.7, 6686067.455, 6686067.12, 6686065.775, 6686060.726,
>> 6686041.86, 6686032.469, 6686013.937, 6686000.03, 6685963.571,
>> 6685935.559, 6685863.558, 6685840.595, 6685822.242, 6685812.565,
>> 6685793.857, 6685783.98, 6685764.849, 6685754.737, 6685735.113,
>> 6685724.729, 6685704.619, 6685696.809, 6685686.486, 6685681.061,
>> 6685670.572, 6685665.059, 6685654.395, 6685648.791, 6685637.943,
>> 6685632.242, 6685621.203, 6685615.401, 6685604.141, 6685597.441,
>> 6685583.101, 6685575.558, 6685560.946, 6685553.271, 6685538.438,
>> 6685530.658, 6685515.325, 6685494.913, 6685434.228, 6685402.77,
>> 6685343.026, 6685323.207, 6685304.591, 6685299.961, 6686120.566,
>> 6686116.177, 6686098.614, 6686089.408, 6686070.22, 6686060.676,
>> 6686041.836, 6686032.42, 6686013.9, 6685999.932, 6685963.496,
>> 6685935.357, 6685863.495, 6685840.545, 6685822.216, 6685812.513,
>> 6685793.831, 6685783.927, 6685764.822, 6685754.682, 6685735.086,
>> 6685724.674, 6685704.598, 6685696.781, 6685686.472, 6685681.032,
>> 6685670.557, 6685665.03, 6685654.381, 6685648.761, 6685637.928,
>> 6685632.212, 6685621.188, 6685615.37, 6685604.123, 6685597.401,
>> 6685583.081, 6685575.518, 6685560.926, 6685553.23, 6685538.418,
>> 6685530.617, 6685515.273, 6685494.746, 6685434.148, 6685402.617,
>> 6685342.951, 6685321.272, 6685295.605, 6685289.221, 6686175.29,
>> 6686171.64, 6686157.035, 6686148.4, 6686128.526, 6686118.635,
>> 6686099.091, 6686089.358, 6686070.194, 6686060.626, 6686041.811,
>> 6686032.371, 6686013.864, 6685999.833, 6685963.421, 6685935.155,
>> 6685863.431, 6685840.494, 6685822.191, 6685812.461, 6685793.805,
>> 6685783.875, 6685764.795, 6685754.628, 6685735.058, 6685724.618,
>> 6685704.577, 6685696.753, 6685686.457, 6685681.004, 6685670.543,
>> 6685665.001, 6685654.366, 6685648.731, 6685637.913, 6685632.182,
>> 6685621.172, 6685615.339, 6685604.106, 6685597.362, 6685583.061,
>> 6685575.478, 6685560.906, 6685553.19, 6685538.397, 6685530.576,
>> 6685515.221, 6685494.579, 6685434.068, 6685402.463, 6685342.877,
>> 6685319.338, 6685286.619, 6685278.481, 6686231.171, 6686223.242,
>> 6686191.517, 6686178.52, 6686158.396, 6686148.348, 6686128.5,
>> 6686118.584, 6686099.066, 6686089.307, 6686070.169, 6686060.576,
>> 6686041.786, 6686032.321, 6686013.827, 6685999.735, 6685963.346,
>> 6685934.953, 6685863.368, 6685840.443, 6685822.165, 6685812.41,
>> 6685793.779, 6685783.822, 6685764.769, 6685754.574, 6685735.031,
>> 6685724.563, 6685704.556, 6685696.724, 6685686.443, 6685680.975,
>> 6685670.528, 6685664.972, 6685654.351, 6685648.702, 6685637.898,
>> 6685632.151, 6685621.157, 6685615.308, 6685604.088, 6685597.323,
>> 6685583.042, 6685575.438, 6685560.886, 6685553.149, 6685538.377,
>> 6685530.535, 6685515.169, 6685494.412, 6685433.988, 6685402.31,
>> 6685342.802, 6685317.403, 6685277.633, 6685267.741, 6686287.605,
>> 6686280.486, 6686251.986, 6686234.591, 6686193.769, 6686178.467,
>> 6686158.369, 6686148.296, 6686128.475, 6686118.533, 6686099.04,
>> 6686089.257, 6686070.144, 6686060.526, 6686041.761, 6686032.272,
>> 6686013.79, 6685999.637, 6685963.271, 6685934.751, 6685863.305,
>> 6685840.392, 6685822.139, 6685812.358, 6685793.752, 6685783.769,
>> 6685764.742, 6685754.52, 6685735.003, 6685724.507, 6685704.535,
>> 6685696.696, 6685686.429, 6685680.946, 6685670.514, 6685664.942,
>> 6685654.336, 6685648.672, 6685637.883, 6685632.121, 6685621.142,
>> 6685615.278, 6685604.071, 6685597.284, 6685583.022, 6685575.398,
>> 6685560.865, 6685553.108, 6685538.357, 6685530.493, 6685515.117,
>> 6685494.246, 6685433.908, 6685402.156, 6685342.728, 6685315.468,
>> 6685268.647, 6685257.001, 6685237.925, 6685237.939, 6685238.202,
>> 6685239.036, 6685239.241, 6685237.925, 6685237.975, 6685238.897,
>> 6685241.824, 6685242.543, 6685237.925, 6685238.012, 6685239.592,
>> 6685244.611, 6685245.844, 6685237.925, 6685238.048, 6685240.287,
>> 6685247.398, 6685249.145, 6685237.925, 6685238.084, 6685240.982,
>> 6685250.186, 6685252.447, 6685237.925, 6685238.12, 6685241.677,
>> 6685252.973, 6685255.748, 6685237.925, 6685238.156, 6685242.372,
>> 6685255.761, 6685259.05, 6685237.925, 6685238.193, 6685243.067,
>> 6685258.548, 6685262.351, 6685237.925, 6685238.229, 6685243.763,
>> 6685261.336, 6685265.653, 6685237.925, 6685238.265, 6685244.458,
>> 6685264.123, 6685268.954, 6685237.925, 6685238.301, 6685245.153,
>> 6685266.91, 6685272.256, 6685237.925, 6685238.337, 6685245.848,
>> 6685269.698, 6685275.557, 6685237.925, 6685238.374, 6685246.543,
>> 6685272.485, 6685278.858, 6685237.925, 6685238.41, 6685247.238,
>> 6685275.273, 6685282.16, 6685237.925, 6685238.446, 6685247.933,
>> 6685278.06, 6685285.461, 6685237.925, 6685238.482, 6685248.628,
>> 6685280.847, 6685288.763, 6685237.925, 6685238.519, 6685249.323,
>> 6685283.635, 6685292.064, 6685237.925, 6685238.555, 6685250.018,
>> 6685286.422, 6685295.366, 6685237.925, 6685238.591, 6685250.713,
>> 6685289.21, 6685298.667, 6685237.925, 6685238.627, 6685251.408,
>> 6685291.997, 6685301.969, 6685237.925, 6685238.663, 6685252.104,
>> 6685294.784, 6685305.27, 6685237.925, 6685238.7, 6685252.799,
>> 6685297.572, 6685308.571, 6685237.925, 6685238.736, 6685253.494,
>> 6685300.359, 6685311.873, 6685237.925, 6685238.772, 6685254.189,
>> 6685303.147, 6685315.174, 6685237.925, 6685238.808, 6685254.884,
>> 6685305.934, 6685318.476, 6685237.925, 6685238.844, 6685255.579,
>> 6685308.722, 6685321.777, 6685237.925, 6685238.881, 6685256.274,
>> 6685311.509, 6685325.079, 6685237.925, 6685238.917, 6685256.958,
>> 6685314.243, 6685328.329, 6685328.371, 6685328.381, 6685237.925,
>> 6685238.953, 6685257.103, 6685314.318, 6685329.039, 6685331.19,
>> 6685331.718, 6685237.925, 6685238.989, 6685257.248, 6685314.392,
>> 6685329.749, 6685334.01, 6685335.056, 6685237.925, 6685239.025,
>> 6685257.393, 6685314.467, 6685330.458, 6685336.83, 6685338.394,
>> 6685237.925, 6685239.062, 6685257.538, 6685314.541, 6685331.168,
>> 6685339.65, 6685341.731, 6685237.925, 6685239.098, 6685257.683,
>> 6685314.616, 6685331.878, 6685342.469, 6685345.069, 6685237.925,
>> 6685239.134, 6685257.827, 6685314.691, 6685332.587, 6685345.289,
>> 6685348.407, 6685237.925, 6685239.17, 6685257.972, 6685314.765,
>> 6685333.297, 6685348.109, 6685351.744, 6685237.925, 6685239.207,
>> 6685258.117, 6685314.84, 6685334.007, 6685350.928, 6685355.082,
>> 6685237.925, 6685239.243, 6685258.262, 6685314.914, 6685334.717,
>> 6685353.748, 6685358.419, 6685237.925, 6685239.279, 6685258.407,
>> 6685314.989, 6685335.426, 6685356.568, 6685361.757, 6685237.925,
>> 6685239.315, 6685258.552, 6685315.063, 6685336.136, 6685359.387,
>> 6685365.095, 6685237.925, 6685239.351, 6685258.696, 6685315.138,
>> 6685336.846, 6685362.207, 6685368.432, 6685237.925, 6685239.388,
>> 6685258.841, 6685315.213, 6685337.555, 6685365.027, 6685371.77,
>> 6685237.925, 6685239.424, 6685258.986, 6685315.287, 6685338.265,
>> 6685367.847, 6685375.108, 6685237.925, 6685239.46, 6685259.131,
>> 6685315.362, 6685338.975, 6685370.666, 6685378.445, 6685237.925,
>> 6685239.496, 6685259.276, 6685315.436, 6685339.684, 6685373.486,
>> 6685381.783, 6685237.925, 6685239.532, 6685259.421, 6685315.511,
>> 6685340.394, 6685376.306, 6685385.12, 6685237.925, 6685239.569,
>> 6685259.566, 6685315.585, 6685341.104, 6685379.125, 6685388.458,
>> 6685237.925, 6685239.605, 6685259.71, 6685315.66, 6685341.813,
>> 6685381.945, 6685391.796, 6685237.925, 6685239.641, 6685259.855,
>> 6685315.735, 6685342.523, 6685384.765, 6685395.133, 6685237.925,
>> 6685239.677, 6685260, 6685315.809, 6685343.233, 6685387.585,
>> 6685398.471, 6685237.925, 6685239.713, 6685260.145, 6685315.884,
>> 6685343.943, 6685390.404, 6685401.808, 6685237.925, 6685239.75,
>> 6685260.29, 6685315.958, 6685344.652, 6685393.224, 6685405.146,
>> 6685237.925, 6685239.786, 6685260.435, 6685316.033, 6685345.362,
>> 6685396.044, 6685408.484, 6685237.925, 6685239.822, 6685260.579,
>> 6685316.107, 6685346.072, 6685398.863, 6685411.821, 6685237.925,
>> 6685239.858, 6685260.724, 6685316.182, 6685346.781, 6685401.683,
>> 6685415.159, 6685237.925, 6685239.895, 6685260.869, 6685316.256,
>> 6685347.491, 6685404.503, 6685418.497, 6685237.925, 6685239.931,
>> 6685261.014, 6685316.331, 6685347.844, 6685405.568, 6685435.199,
>> 6685496.716, 6685515.938, 6685531.122, 6685538.725, 6685553.729,
>> 6685561.236, 6685576.008, 6685583.392, 6685597.877, 6685604.396,
>> 6685615.747, 6685621.422, 6685632.578, 6685638.148, 6685649.116,
>> 6685654.585, 6685665.375, 6685670.748, 6685681.367, 6685686.649,
>> 6685697.108, 6685700.858, 6685705.372, 6685706.5, 6685237.925,
>> 6685239.967, 6685261.159, 6685316.406, 6685347.998, 6685405.648,
>> 6685435.365, 6685496.768, 6685515.979, 6685531.142, 6685538.766,
>> 6685553.749, 6685561.276, 6685576.028, 6685583.432, 6685597.895,
>> 6685604.426, 6685615.762, 6685621.452, 6685632.593, 6685638.178,
>> 6685649.131, 6685654.615, 6685665.39, 6685670.777, 6685681.382,
>> 6685686.677, 6685697.129, 6685704.901, 6685725.326, 6685732.83,
>> 6685742.362, 6685744.744, 6685237.925, 6685240.003, 6685261.304,
>> 6685316.48, 6685348.151, 6685405.728, 6685435.532, 6685496.82,
>> 6685516.02, 6685531.163, 6685538.806, 6685553.769, 6685561.316,
>> 6685576.048, 6685583.471, 6685597.912, 6685604.457, 6685615.777,
>> 6685621.483, 6685632.608, 6685638.207, 6685649.146, 6685654.644,
>> 6685665.404, 6685670.806, 6685681.396, 6685686.706, 6685697.15,
>> 6685704.957, 6685725.354, 6685735.473, 6685755.328, 6685763.892,
>> 6685778.202, 6685781.778, 6685237.925, 6685240.039, 6685261.448,
>> 6685316.555, 6685348.305, 6685405.808, 6685435.699, 6685496.872,
>> 6685516.061, 6685531.183, 6685538.847, 6685553.789, 6685561.356,
>> 6685576.068, 6685583.51, 6685597.93, 6685604.488, 6685615.792,
>> 6685621.513, 6685632.623, 6685638.237, 6685649.16, 6685654.673,
>> 6685665.419, 6685670.835, 6685681.41, 6685686.734, 6685697.171,
>> 6685705.012, 6685725.381, 6685735.527, 6685755.355, 6685765.213,
>> 6685784.568, 6685794.162, 6685813.063, 6685817.786, 6685237.925,
>> 6685240.076, 6685261.593, 6685316.629, 6685348.458, 6685405.888,
>> 6685435.866, 6685496.924, 6685516.102, 6685531.204, 6685538.887,
>> 6685553.81, 6685561.396, 6685576.088, 6685583.549, 6685597.947,
>> 6685604.519, 6685615.808, 6685621.543, 6685632.638, 6685638.267,
>> 6685649.175, 6685654.702, 6685665.433, 6685670.863, 6685681.425,
>> 6685686.762, 6685697.192, 6685705.068, 6685725.409, 6685735.581,
>> 6685755.381, 6685765.266, 6685784.594, 6685794.226, 6685813.15,
>> 6685822.566, 6685841.162, 6685864.006, 6685936.995, 6685965.278,
>> 6686000.893, 6686015.045, 6686033.095, 6686043.087, 6686061.378,
>> 6686071.633, 6686090.149, 6686100.591, 6686119.437, 6686130.086,
>> 6686149.209, 6686160.037, 6686179.812, 6686197.19, 6686236.419,
>> 6686258.818, 6686297.386, 6686306.803, 6685237.925, 6685240.112,
>> 6685261.738, 6685316.704, 6685348.612, 6685405.968, 6685436.033,
>> 6685496.976, 6685516.143, 6685531.224, 6685538.928, 6685553.83,
>> 6685561.436, 6685576.107, 6685583.588, 6685597.965, 6685604.549,
>> 6685615.823, 6685621.573, 6685632.653, 6685638.296, 6685649.19,
>> 6685654.732, 6685665.448, 6685670.892, 6685681.439, 6685686.791,
>> 6685697.213, 6685705.123, 6685725.436, 6685735.635, 6685755.408,
>> 6685765.319, 6685784.62, 6685794.278, 6685813.176, 6685822.617,
>> 6685841.226, 6685864.208, 6685937.07, 6685965.376, 6686000.93,
>> 6686015.094, 6686033.119, 6686043.136, 6686061.403, 6686071.684,
>> 6686090.174, 6686100.643, 6686119.463, 6686130.138, 6686149.235,
>> 6686160.09, 6686179.852, 6686197.297, 6686236.472, 6686258.926,
>> 6686297.413, 6686306.803, 6685237.925, 6685240.148, 6685261.883,
>> 6685316.778, 6685348.765, 6685406.048, 6685436.199, 6685497.028,
>> 6685516.184, 6685531.244, 6685538.969, 6685553.85, 6685561.476,
>> 6685576.127, 6685583.628, 6685597.982, 6685604.58, 6685615.838,
>> 6685621.604, 6685632.668, 6685638.326, 6685649.205, 6685654.761,
>> 6685665.462, 6685670.921, 6685681.453, 6685686.819, 6685697.234,
>> 6685705.179, 6685725.464, 6685735.689, 6685755.435, 6685765.372,
>> 6685784.646, 6685794.33, 6685813.201, 6685822.668, 6685841.289,
>> 6685864.41, 6685937.145, 6685965.474, 6686000.967, 6686015.144,
>> 6686033.144, 6686043.186, 6686061.429, 6686071.734, 6686090.2,
>> 6686100.694, 6686119.488, 6686130.19, 6686149.262, 6686160.142,
>> 6686179.891, 6686197.403, 6686236.526, 6686259.033, 6686297.44,
>> 6686306.803, 6685237.925, 6685240.184, 6685262.028, 6685316.853,
>> 6685348.918, 6685406.128, 6685436.366, 6685497.08, 6685516.226,
>> 6685531.265, 6685539.009, 6685553.87, 6685561.516, 6685576.147,
>> 6685583.667, 6685598, 6685604.611, 6685615.853, 6685621.634,
>> 6685632.683, 6685638.356, 6685649.219, 6685654.79, 6685665.477,
>> 6685670.95, 6685681.468, 6685686.848, 6685697.255, 6685705.234,
>> 6685725.491, 6685735.743, 6685755.462, 6685765.425, 6685784.672,
>> 6685794.382, 6685813.227, 6685822.719, 6685841.352, 6685864.612,
>> 6685937.22, 6685965.572, 6686001.004, 6686015.193, 6686033.169,
>> 6686043.236, 6686061.454, 6686071.784, 6686090.225, 6686100.745,
>> 6686119.514, 6686130.242, 6686149.288, 6686160.195, 6686179.931,
>> 6686197.51, 6686236.58, 6686259.141, 6686297.467, 6686306.803,
>> 6685237.925, 6685240.22, 6685262.173, 6685316.928, 6685349.072,
>> 6685406.208, 6685436.533, 6685497.132, 6685516.267, 6685531.285,
>> 6685539.05, 6685553.89, 6685561.556, 6685576.167, 6685583.706,
>> 6685598.017, 6685604.641, 6685615.869, 6685621.664, 6685632.698,
>> 6685638.386, 6685649.234, 6685654.82, 6685665.491, 6685670.979,
>> 6685681.482, 6685686.876, 6685697.276, 6685705.29, 6685725.518,
>> 6685735.798, 6685755.488, 6685765.477, 6685784.698, 6685794.433,
>> 6685813.253, 6685822.77, 6685841.415, 6685864.814, 6685937.295,
>> 6685965.67, 6686001.041, 6686015.242, 6686033.194, 6686043.286,
>> 6686061.479, 6686071.835, 6686090.25, 6686100.796, 6686119.54,
>> 6686130.294, 6686149.314, 6686160.248, 6686179.971, 6686197.617,
>> 6686236.633, 6686259.249, 6686297.494, 6686306.803, 6685237.925,
>> 6685240.257, 6685262.318, 6685317.002, 6685349.225, 6685406.288,
>> 6685436.7), Z = c(3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L,
>> 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L,
>> 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L,
>> 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L,
>> 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L,
>> 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L,
>> 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3600L, 3568L, 3568L,
>> 3568L, 3568L, 3568L, 3568L, 3578L, 3578L, 3578L, 3578L, 3578L,
>> 3578L, 3578L, 3578L, 3578L, 3578L, 3578L, 3578L, 3578L, 3578L,
>> 3578L, 3578L, 3578L, 3578L, 3578L, 3578L, 3578L, 3578L, 3578L,
>> 3578L, 3578L, 3578L, 3578L, 3578L, 3578L, 3578L, 3578L, 3578L,
>> 3578L, 3578L, 3578L, 3578L, 3578L, 3578L, 3576L, 3576L, 3576L,
>> 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3576L,
>> 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3576L,
>> 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3576L,
>> 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3576L, 3574L,
>> 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L,
>> 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L,
>> 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L,
>> 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L, 3574L,
>> 3574L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L,
>> 3572L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L,
>> 3572L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L,
>> 3572L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L, 3572L,
>> 3572L, 3572L, 3572L, 3570L, 3570L, 3570L, 3570L, 3570L, 3570L,
>> 3570L, 3570L, 3570L, 3570L, 3570L, 3570L, 3570L, 3570L, 3570L,
>> 3570L, 3570L, 3570L, 3570L, 3570L, 3570L, 3570L, 3570L, 3570L,
>> 3570L, 3570L, 3570L, 3570L, 3570L, 3570L, 3570L, 3570L, 3570L,
>> 3570L, 3570L, 3570L, 3570L, 3570L, 3584L, 3584L, 3584L, 3584L,
>> 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L,
>> 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L,
>> 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L,
>> 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L, 3584L,
>> 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L,
>> 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L,
>> 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L,
>> 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L, 3582L,
>> 3582L, 3582L, 3582L, 3582L, 3580L, 3580L, 3580L, 3580L, 3580L,
>> 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3580L,
>> 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3580L,
>> 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3580L,
>> 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3580L, 3586L,
>> 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L,
>> 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L,
>> 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L,
>> 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L,
>> 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3586L, 3588L, 3588L,
>> 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L,
>> 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L,
>> 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L,
>> 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L,
>> 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3588L, 3590L,
>> 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L,
>> 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L,
>> 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L,
>> 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L,
>> 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L, 3590L,
>> 3590L, 3590L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L,
>> 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L,
>> 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L,
>> 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L,
>> 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L,
>> 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3592L, 3594L, 3594L,
>> 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L,
>> 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L,
>> 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L,
>> 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L,
>> 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L,
>> 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3594L, 3596L, 3596L,
>> 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L,
>> 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L,
>> 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L,
>> 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L,
>> 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L,
>> 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L, 3596L,
>> 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L,
>> 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L,
>> 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L,
>> 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L,
>> 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L,
>> 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L, 3598L,
>> 3598L, 3598L, 3598L, 3598L, 4416L, 4416L, 4416L, 4416L, 4416L,
>> 4414L, 4414L, 4414L, 4414L, 4414L, 4412L, 4412L, 4412L, 4412L,
>> 4412L, 4410L, 4410L, 4410L, 4410L, 4410L, 4408L, 4408L, 4408L,
>> 4408L, 4408L, 4406L, 4406L, 4406L, 4406L, 4406L, 4404L, 4404L,
>> 4404L, 4404L, 4404L, 4402L, 4402L, 4402L, 4402L, 4402L, 4400L,
>> 4400L, 4400L, 4400L, 4400L, 4398L, 4398L, 4398L, 4398L, 4398L,
>> 4396L, 4396L, 4396L, 4396L, 4396L, 4394L, 4394L, 4394L, 4394L,
>> 4394L, 4392L, 4392L, 4392L, 4392L, 4392L, 4390L, 4390L, 4390L,
>> 4390L, 4390L, 4388L, 4388L, 4388L, 4388L, 4388L, 4386L, 4386L,
>> 4386L, 4386L, 4386L, 4384L, 4384L, 4384L, 4384L, 4384L, 4382L,
>> 4382L, 4382L, 4382L, 4382L, 4380L, 4380L, 4380L, 4380L, 4380L,
>> 4378L, 4378L, 4378L, 4378L, 4378L, 4376L, 4376L, 4376L, 4376L,
>> 4376L, 4374L, 4374L, 4374L, 4374L, 4374L, 4372L, 4372L, 4372L,
>> 4372L, 4372L, 4370L, 4370L, 4370L, 4370L, 4370L, 4368L, 4368L,
>> 4368L, 4368L, 4368L, 4366L, 4366L, 4366L, 4366L, 4366L, 4364L,
>> 4364L, 4364L, 4364L, 4364L, 4362L, 4362L, 4362L, 4362L, 4362L,
>> 4362L, 4362L, 4360L, 4360L, 4360L, 4360L, 4360L, 4360L, 4360L,
>> 4358L, 4358L, 4358L, 4358L, 4358L, 4358L, 4358L, 4356L, 4356L,
>> 4356L, 4356L, 4356L, 4356L, 4356L, 4354L, 4354L, 4354L, 4354L,
>> 4354L, 4354L, 4354L, 4352L, 4352L, 4352L, 4352L, 4352L, 4352L,
>> 4352L, 4350L, 4350L, 4350L, 4350L, 4350L, 4350L, 4350L, 4348L,
>> 4348L, 4348L, 4348L, 4348L, 4348L, 4348L, 4346L, 4346L, 4346L,
>> 4346L, 4346L, 4346L, 4346L, 4344L, 4344L, 4344L, 4344L, 4344L,
>> 4344L, 4344L, 4342L, 4342L, 4342L, 4342L, 4342L, 4342L, 4342L,
>> 4340L, 4340L, 4340L, 4340L, 4340L, 4340L, 4340L, 4338L, 4338L,
>> 4338L, 4338L, 4338L, 4338L, 4338L, 4336L, 4336L, 4336L, 4336L,
>> 4336L, 4336L, 4336L, 4334L, 4334L, 4334L, 4334L, 4334L, 4334L,
>> 4334L, 4332L, 4332L, 4332L, 4332L, 4332L, 4332L, 4332L, 4330L,
>> 4330L, 4330L, 4330L, 4330L, 4330L, 4330L, 4328L, 4328L, 4328L,
>> 4328L, 4328L, 4328L, 4328L, 4326L, 4326L, 4326L, 4326L, 4326L,
>> 4326L, 4326L, 4324L, 4324L, 4324L, 4324L, 4324L, 4324L, 4324L,
>> 4322L, 4322L, 4322L, 4322L, 4322L, 4322L, 4322L, 4320L, 4320L,
>> 4320L, 4320L, 4320L, 4320L, 4320L, 4318L, 4318L, 4318L, 4318L,
>> 4318L, 4318L, 4318L, 4316L, 4316L, 4316L, 4316L, 4316L, 4316L,
>> 4316L, 4314L, 4314L, 4314L, 4314L, 4314L, 4314L, 4314L, 4312L,
>> 4312L, 4312L, 4312L, 4312L, 4312L, 4312L, 4310L, 4310L, 4310L,
>> 4310L, 4310L, 4310L, 4310L, 4308L, 4308L, 4308L, 4308L, 4308L,
>> 4308L, 4308L, 4306L, 4306L, 4306L, 4306L, 4306L, 4306L, 4306L,
>> 4306L, 4306L, 4306L, 4306L, 4306L, 4306L, 4306L, 4306L, 4306L,
>> 4306L, 4306L, 4306L, 4306L, 4306L, 4306L, 4306L, 4306L, 4306L,
>> 4306L, 4306L, 4306L, 4306L, 4306L, 4306L, 4304L, 4304L, 4304L,
>> 4304L, 4304L, 4304L, 4304L, 4304L, 4304L, 4304L, 4304L, 4304L,
>> 4304L, 4304L, 4304L, 4304L, 4304L, 4304L, 4304L, 4304L, 4304L,
>> 4304L, 4304L, 4304L, 4304L, 4304L, 4304L, 4304L, 4304L, 4304L,
>> 4304L, 4304L, 4304L, 4302L, 4302L, 4302L, 4302L, 4302L, 4302L,
>> 4302L, 4302L, 4302L, 4302L, 4302L, 4302L, 4302L, 4302L, 4302L,
>> 4302L, 4302L, 4302L, 4302L, 4302L, 4302L, 4302L, 4302L, 4302L,
>> 4302L, 4302L, 4302L, 4302L, 4302L, 4302L, 4302L, 4302L, 4302L,
>> 4302L, 4302L, 4300L, 4300L, 4300L, 4300L, 4300L, 4300L, 4300L,
>> 4300L, 4300L, 4300L, 4300L, 4300L, 4300L, 4300L, 4300L, 4300L,
>> 4300L, 4300L, 4300L, 4300L, 4300L, 4300L, 4300L, 4300L, 4300L,
>> 4300L, 4300L, 4300L, 4300L, 4300L, 4300L, 4300L, 4300L, 4300L,
>> 4300L, 4300L, 4300L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L,
>> 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L,
>> 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L,
>> 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L,
>> 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L,
>> 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L,
>> 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4298L, 4296L,
>> 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L,
>> 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L,
>> 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L,
>> 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L,
>> 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L,
>> 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L, 4296L,
>> 4296L, 4296L, 4296L, 4296L, 4294L, 4294L, 4294L, 4294L, 4294L,
>> 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L,
>> 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L,
>> 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L,
>> 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L,
>> 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L,
>> 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L, 4294L,
>> 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L,
>> 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L,
>> 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L,
>> 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L,
>> 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L,
>> 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L, 4292L,
>> 4292L, 4292L, 4292L, 4292L, 4292L, 4290L, 4290L, 4290L, 4290L,
>> 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L,
>> 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L,
>> 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L,
>> 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L,
>> 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L,
>> 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L, 4290L,
>> 4290L, 4288L, 4288L, 4288L, 4288L, 4288L, 4288L, 4288L)), .Names = c("X",
>> "Y", "Z"), row.names = c(NA, 1500L), class = "data.frame")
>>
>>
>> On Wed, Dec 11, 2013 at 4:24 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>> On 13-12-11 11:13 AM, Shane Carey wrote:
>>>> Hey,
>>>>
>>>> Nope, it crashes. R stops abruptly. I sent just 500 points to show the
>>>> structure of the data. There is in fact over 22,000 points and it is 3-D
>>>> data composing of x,y,z data
>>>>
>>>> Cheers
>>>
>>>   We really, really need a reproducible example to be able to help
>>> further.  Since the 'akima.li' object is the one causing the trouble
>>> perhaps you could post the results of save() somewhere publicly
>>> accessible?
>>>
>>>   Do you have the same problem if you skip the rgl.spheres() and
>>> rgl.bbox() steps?
>>>
>>>   I'm able to plot a 100x100 random surface, even one with lots of NAs,
>>> without any trouble.  So there must be something special about akima.li
>>> , and guessing is going to be very hard ...
>>>
>>>   (At some point it might be useful to know your platform, version of R,
>>> etc., but that will only really become useful if it turns out that other
>>> people can plot your akima.li surface without any trouble ...)
>>>
>>>   Ben Bolker
>>>
>>>>
>>>>
>>>> On Wed, Dec 11, 2013 at 3:24 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>>>
>>>>> Shane Carey <careyshan <at> gmail.com> writes:
>>>>>
>>>>>>
>>>>>> it just keeps crashing on me,
>>>>>>
>>>>>> It seems to crash on this line
>>>>>>
>>>>>> rgl.surface(akima.li$x,akima.li$y,akima.li
>>> $z,color="green",alpha=c(0.5))
>>>>>
>>>>>   When I run the code you gave us along with the data you gave us,
>>>>> I get
>>>>>
>>>>> Error in rgl.surface(akima.li$X, akima.li$Y, akima.li$Z, color =
>>> "green",
>>>>>  :
>>>>>   rows < 2
>>>>>
>>>>>   Maybe this is what you mean by "crashing"?  (On this list, "crash"
>>>>> is usually reserved to mean that your instance of R stops abruptly ...
>>>>> the behaviour above would be called an "error").
>>>>>
>>>>>   Looking at the plot generated from the data you sent, all of
>>>>> the (X,Y) points lie on a 1-dimensional curve in the (X,Y) plane --
>>>>> it's not surprising that it's going to be hard to generate an
>>>>> interpolated surface from these points.
>>>>>
>>>>>   Or maybe I'm misunderstanding something.
>>>>>
>>>>> rgl.spheres(dat$X,dat$Z , dat$Y,1,color="red")
>>>>> rgl.bbox()
>>>>> # bivariate linear interpolation
>>>>> # interp:
>>>>> akima.li <- interp(dat$X, dat$Y, dat$Z,
>>>>>                    xo=seq(min(dat$X), max(dat$X), length = 100),
>>>>>                    yo=seq(min(dat$Y), max(dat$Y), length = 100))
>>>>> # interp surface:
>>>>> rgl.surface(akima.li$X,akima.li$Y,akima.li
>>> $Z,color="green",alpha=c(0.5))
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>>
>>>
>>>
>>
>>
>> --
>> Shane
>>
> 
> 
>


From smartpink111 at yahoo.com  Wed Dec 11 21:06:37 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 11 Dec 2013 12:06:37 -0800 (PST)
Subject: [R] Covert many lines in a specific line
Message-ID: <1386792397.39891.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

May be this helps:

dat1 <- read.table(text="Sample? Genotype? Region
??? sample1??? A????? Region1
??? sample1??? B????? Region1
??? sample1??? A????? Region1
??? sample2??? A????? Region1
??? sample2??? A????? Region1
??? sample3??? A????? Region1
??? sample4??? B????? Region1",sep="",header=TRUE,stringsAsFactors=FALSE)
library(plyr)
?unique(ddply(dat1,.(Sample),mutate, Genotype=if(length(unique(Genotype))>1) {"E"} else Genotype))


dat2 <- read.table(text="Sample? Genotype? Region
??? sample1??? A????? Region1
??? sample1??? B????? Region1
??? sample1??? A????? Region1
??? sample2??? A????? Region1
??? sample2??? A????? Region1
??? sample3??? A????? Region1
??? sample4??? B????? Region1
??? sample1??? A????? Region2
??? sample1??? B????? Region2
??? sample1??? A????? Region2
??? sample2??? A????? Region2
??? sample2??? A????? Region2",sep="",header=TRUE,stringsAsFactors=FALSE)

?unique(ddply(dat2,.(Region,Sample),mutate, Genotype=if(length(unique(Genotype))>1) {"E"} else Genotype))

#or
aggregate(Genotype~.,data=dat2,function(x) x <- if(length(unique(x))>1) "E" else unique(x))



A.K.


I would like to transform this data: 

? ? Sample ?Genotype ?Region 
? ? sample1 ? ?A ? ? ?Region1 
? ? sample1 ? ?B ? ? ?Region1 
? ? sample1 ? ?A ? ? ?Region1 
? ? sample2 ? ?A ? ? ?Region1 
? ? sample2 ? ?A ? ? ?Region1 
? ? sample3 ? ?A ? ? ?Region1 
? ? sample4 ? ?B ? ? ?Region1 

In that format, tagging with "E" samples with more than one genotype and unifying samples with the same genotype 2 times: 

? ? Sample ?Genotype ?Region ? 
? ? sample1 ? ?E ? ? ?Region1 
? ? sample2 ? ?A ? ? ?Region1 
? ? sample3 ? ?A ? ? ?Region1 
? ? sample4 ? ?B ? ? ?Region1 

I have one list with many regions (Region1 - Regionx). It is possible to do in R software? Thanks a lot.


From gaurav.pandey789 at gmail.com  Wed Dec 11 20:31:32 2013
From: gaurav.pandey789 at gmail.com (Gaurav Pandey)
Date: Thu, 12 Dec 2013 01:01:32 +0530
Subject: [R] Heatmap Help
Message-ID: <CADB9r+KZd8T5ts_BWQUi2=hnwCxT-rUG1g-W3AnLWSWtG+AQ3g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/eacf8779/attachment.pl>

From berryboessenkool at hotmail.com  Wed Dec 11 19:03:49 2013
From: berryboessenkool at hotmail.com (Berry Boessenkool)
Date: Wed, 11 Dec 2013 19:03:49 +0100
Subject: [R] Leap hours?
Message-ID: <DUB123-W34D3957446EEB9F3268BB8D5DD0@phx.gbl>

Hi there,

If you want to show off just how good R handles dates+times, forward this.

I showed some colleagues difftime today, and encountered something interesting:
difftime(ISOdatetime(1936:1947+1,1,1, 0,0,0), ISOdatetime(1936:1947,1,1, 0,0,0))
which returns the values
366, 365, 365, 365, 365.958333, 365, 365.041667, 365, 366, 365, 365, 365

1940 is missing one hour! (1/24 = 0.041667)
1942 has one hour too much.

I first thought of leap hours, and after reading about leap seconds, clock drift, timing attacks, GPS, random number generators and Turing machines, I thought of dailight saving time, and indeed, there were some issues in Germany back then.
http://de.wikipedia.org/wiki/Sommerzeit#Deutschland
http://www.horlogeparlante.com/history.html?city=2950159

R even covers all that - I'm once again amazed!

Sys.getlocale() gives me German_Germany.1252, by the way.

regards,
Berry 		 	   		  

From sarah.goslee at gmail.com  Wed Dec 11 21:39:24 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 11 Dec 2013 15:39:24 -0500
Subject: [R] Heatmap Help
In-Reply-To: <CADB9r+KZd8T5ts_BWQUi2=hnwCxT-rUG1g-W3AnLWSWtG+AQ3g@mail.gmail.com>
References: <CADB9r+KZd8T5ts_BWQUi2=hnwCxT-rUG1g-W3AnLWSWtG+AQ3g@mail.gmail.com>
Message-ID: <CAM_vjukNmG+8HgOfmOh0A23Wo9oeiYdpNOg9Pk8kaZWyB5g4mA@mail.gmail.com>

You have some randomly doubled quotation marks and parentheses.

A text editor with syntax highlighting is wonderful for catching that
sort of problem.

Beyond that, see:

?heatmap

A "very urgent" request suggests homework to me, which this list doesn't do.

Though sometimes someone will offer a hint or two...

Sarah

On Wed, Dec 11, 2013 at 2:31 PM, Gaurav Pandey
<gaurav.pandey789 at gmail.com> wrote:
> Hello,
> I want a help, i have to make heat map.And i am using the following command
> In R for generating a matrix, but its returning an error,and i am not able
> to figure it out.
> Can you please tell me what is wrong?
> And please also suggest me how to generate a heat map.
> Its very urgent.
>
> Thanks a lot.
>
> mat <-
> matrix(c(100,49.3,45.71,54.29,97.22,68.57,49.3,100,22.54,26.76,50.7,33.8,45.71,22.54,100,84.21,44.44,66.67,54.29,26.76,84.21,100,52.78,79.17,97.22,50.7,44.44,52.78,100,66.67,68.57,33.8,66.67,79.17,66.67,100),
> nrow = 6, ncol = 6, byrow = TRUE,dimnames =
> list(c(""A_1HJO","B_2L1W","C_1MHS","D_1HQY","E_1XU4","F_1JNB""),c(("A_1HJO","B_2L1W","C_1MHS","D_1HQY","E_1XU4","F_1JNB"))))
>
> Error: unexpected symbol in
> "49.3,45.71,54.29,97.22,68.57,49.3,100,22.54,26.76,50.7,33.8,45.71,22.54,100,84.21,44.44,66.67,54.29,26.76,84.21,100,52.78,79.17,97.22,50.7,44.44,52.78,100,66.67,68.57,33.8,66.67,79.17,66.67,10"
>
> Gaurav Pandey
> PhD Scholar
> Department of Biotechnology,
> Indian Institute of Technology Guwahati.
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From Yuanzhi.Li at USherbrooke.ca  Wed Dec 11 23:06:42 2013
From: Yuanzhi.Li at USherbrooke.ca (Yuanzhi Li)
Date: Wed, 11 Dec 2013 17:06:42 -0500
Subject: [R] bargraph.CI
Message-ID: <20131211170642.20755b5fkpjufo4c@www.usherbrooke.ca>

hello,

I had a problem with the function "bargraph.CI". "bargraph.CI" draws a  
figure according to the alphabet sequence of the factor used. For  
example, I have a factor with for levels "CK", "N5", "N10", "N15", but  
the bars appear in "CK","N10","N15","N5" order(alphabet sequence), but  
I want the bars to appear  "CK", "N5", "N10", "N15"(treat level  
sequence). Do you have any ideas to realize the goal?

Thank you!


Yuanzhi


From jwiley.psych at gmail.com  Wed Dec 11 23:21:46 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 11 Dec 2013 14:21:46 -0800
Subject: [R] useR! 2014 cal for tutorials
Message-ID: <CANz9Z_KNJ47o5WtQ=EwS2SN4=18fiOEgJY=2x57AJaM9PFq7Cw@mail.gmail.com>

The R User Conference, useR! 2014 is scheduled for July 1-3, 2014 at
the University of California, Los Angeles.  Before the official
program, half-day tutorials will be offered on Monday, June 30.

We invite R users to submit proposals for three hour tutorials on
special topics regarding R. The proposals should include:

1) A brief description (abstract) of the tutorial
2) Goals
3) Detailed outline
4) Justification of why the tutorial is important
5) Background knowledge required and potential attendees

The deadline for tutorial submission is January 5, 2014.

Please email all tutorial proposals to useR-2014_at_R-project.org.

A web page offering more information on the useR! conference is
available at http://www.R-project.org/useR-2014

We look forward to your submissions,

The organizing committee:

   Yunyun Dai, Phil Ender, Jan de Leeuw, David McArthur,
   Amelia McNamara, Sanjog Misra, Katharine Mullen, Jeroen Ooms,
   Szilard Pafka, Tim Triche, Joshua Wiley


From sarah.goslee at gmail.com  Wed Dec 11 23:23:52 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 11 Dec 2013 17:23:52 -0500
Subject: [R] bargraph.CI
In-Reply-To: <20131211170642.20755b5fkpjufo4c@www.usherbrooke.ca>
References: <20131211170642.20755b5fkpjufo4c@www.usherbrooke.ca>
Message-ID: <CAM_vjukRz+=JU3jK=U5aLRmnfHw1cKa9=jRbsb5VrX2XTUd-MA@mail.gmail.com>

Without knowing where you got bargraph.CI() I can't answer that part,
since it isn't part of base R, but the most likely cause is that you
did not specify the desired levels of your factor.
You can check with str().

Compare:

> testdata <- factor(c("a", "b", "a", "c", "b"))
> str(testdata)
 Factor w/ 3 levels "a","b","c": 1 2 1 3 2
>
> testdata <- factor(c("a", "b", "a", "c", "b"), levels=c("c", "b", "a"))
> str(testdata)
 Factor w/ 3 levels "c","b","a": 3 2 3 1 2

Sarah

On Wed, Dec 11, 2013 at 5:06 PM, Yuanzhi Li <Yuanzhi.Li at usherbrooke.ca> wrote:
> hello,
>
> I had a problem with the function "bargraph.CI". "bargraph.CI" draws a
> figure according to the alphabet sequence of the factor used. For example, I
> have a factor with for levels "CK", "N5", "N10", "N15", but the bars appear
> in "CK","N10","N15","N5" order(alphabet sequence), but I want the bars to
> appear  "CK", "N5", "N10", "N15"(treat level sequence). Do you have any
> ideas to realize the goal?
>
> Thank you!
>
>
> Yuanzhi
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From careyshan at gmail.com  Wed Dec 11 23:43:02 2013
From: careyshan at gmail.com (Shane Carey)
Date: Wed, 11 Dec 2013 22:43:02 +0000
Subject: [R] 3-D interpretation
In-Reply-To: <52A8B054.9040700@gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
	<021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>
	<CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>
	<024301cef5c5$78fa6000$6aef2000$@tamu.edu>
	<CA+jRDxBuxxASSkRk2uCZ0F+N1YaXpfKhGanWf7xdBSfnW1uSMA@mail.gmail.com>
	<loom.20131211T161018-956@post.gmane.org>
	<CA+jRDxBFsfGndvxvjjJcQqVt=nNCmDawVNgVd6cv1gcG05VOSQ@mail.gmail.com>
	<52A891AF.3080207@gmail.com>
	<CA+jRDxAA5h2gVLCYgxBhtsH7QkSwehB7FDO_Pyu+81Ne_4mp+w@mail.gmail.com>
	<CA+jRDxBogfM-ZWz3VT7DR6w41u3zBOx+UavhBazdXt3LpK9q-w@mail.gmail.com>
	<52A8B054.9040700@gmail.com>
Message-ID: <CA+jRDxCmHs0UhZ1BNOdQSoDimh4+bw==S7OqNJH8W=TpS5R7og@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131211/cec80109/attachment.pl>

From eliza_botto at hotmail.com  Wed Dec 11 23:56:40 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Wed, 11 Dec 2013 22:56:40 +0000
Subject: [R] solving simultaneous Equations in R
In-Reply-To: <794DC044-7B8D-4892-B3FE-DCB5C7AE6AC8@xs4all.nl>
References: <BLU170-W1148EF2454A33B20811FA1B89DD0@phx.gbl>,
	<794DC044-7B8D-4892-B3FE-DCB5C7AE6AC8@xs4all.nl>
Message-ID: <BLU170-W1370DCFF5AD3BAB481330AE89DD0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131211/b9c9529a/attachment.pl>

From sarah.goslee at gmail.com  Wed Dec 11 23:59:32 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 11 Dec 2013 17:59:32 -0500
Subject: [R] bargraph.CI
In-Reply-To: <20131211174015.98334q1h6zmssx0k@www.usherbrooke.ca>
References: <20131211170642.20755b5fkpjufo4c@www.usherbrooke.ca>
	<CAM_vjukRz+=JU3jK=U5aLRmnfHw1cKa9=jRbsb5VrX2XTUd-MA@mail.gmail.com>
	<20131211174015.98334q1h6zmssx0k@www.usherbrooke.ca>
Message-ID: <CAM_vjum9LoVzeg=Jyq2RN9on7vkN6uz2Xns_H12HjVCxPYsUnw@mail.gmail.com>

Did you try what I suggested, which was to check your factor levels with str()?

And no, pasting your data into an email is not helpful, because it
does not tell me how R sees it. Using str() to provide that
information, or dput() to provide the data itself, is necessary.

Sarah

On Wed, Dec 11, 2013 at 5:40 PM, Yuanzhi Li <Yuanzhi.Li at usherbrooke.ca> wrote:
> Hello, The function bargraph.CI() is from the package "sciplot". with this
> function. I have a data like this:
>
> level  richness
> CK     34
> ...    ...
> N5     25
> ...    ...
> N10    20
> ...    ...
> N15    27
> ...    ...
>
> When I draw bargraph with this function, the bar sequence is
> "CK","N10","N15","N5" but not  "CK", "N5", "N10", "N15".
> Do you know how to deal with it now?
>
>
> Sarah Goslee <sarah.goslee at gmail.com> a ?crit :
>
>> Without knowing where you got bargraph.CI() I can't answer that part,
>> since it isn't part of base R, but the most likely cause is that you
>> did not specify the desired levels of your factor.
>> You can check with str().
>>
>> Compare:
>>
>>> testdata <- factor(c("a", "b", "a", "c", "b"))
>>> str(testdata)
>>
>>  Factor w/ 3 levels "a","b","c": 1 2 1 3 2
>>>
>>>
>>> testdata <- factor(c("a", "b", "a", "c", "b"), levels=c("c", "b", "a"))
>>> str(testdata)
>>
>>  Factor w/ 3 levels "c","b","a": 3 2 3 1 2
>>
>> Sarah
>>
>> On Wed, Dec 11, 2013 at 5:06 PM, Yuanzhi Li <Yuanzhi.Li at usherbrooke.ca>
>> wrote:
>>>
>>> hello,
>>>
>>> I had a problem with the function "bargraph.CI". "bargraph.CI" draws a
>>> figure according to the alphabet sequence of the factor used. For
>>> example, I
>>> have a factor with for levels "CK", "N5", "N10", "N15", but the bars
>>> appear
>>> in "CK","N10","N15","N5" order(alphabet sequence), but I want the bars to
>>> appear  "CK", "N5", "N10", "N15"(treat level sequence). Do you have any
>>> ideas to realize the goal?
>>>
>>> Thank you!
>>>
>>>
>>> Yuanzhi
>>>
>>



-- 
Sarah Goslee
http://www.functionaldiversity.org


From heimnikki at gmail.com  Wed Dec 11 21:38:52 2013
From: heimnikki at gmail.com (Nicole Heim)
Date: Wed, 11 Dec 2013 13:38:52 -0700
Subject: [R] "getRank" ?
Message-ID: <4289853D-E56B-4A41-A097-80572D9F4201@gmail.com>

Hello,

I am trying to use the model.avg function after installing MuMIn for a list of models but an error arises each time stating that R could not find ".getRank".  I am using a mac but not sure if this is the problem?

My code is as follows: model.avg(model.list), where model.list was the object created from a list of glm models.

Any help or suggestions to correcting my code to resolve this issue would be greatly appreciated!

Thanks,
Nikki Heim.

From wdunlap at tibco.com  Thu Dec 12 00:20:25 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 11 Dec 2013 23:20:25 +0000
Subject: [R] bargraph.CI
In-Reply-To: <CAM_vjukRz+=JU3jK=U5aLRmnfHw1cKa9=jRbsb5VrX2XTUd-MA@mail.gmail.com>
References: <20131211170642.20755b5fkpjufo4c@www.usherbrooke.ca>
	<CAM_vjukRz+=JU3jK=U5aLRmnfHw1cKa9=jRbsb5VrX2XTUd-MA@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1C4AF@PA-MBX01.na.tibco.com>

Furthermore, if you have a factor z with the levels in an undesirable order
or missing some levels you can call
  z <- factor(z, levels=betterOrderedLevels)
to get them in the order you want.  E.g.,

  > z <- factor(c("High", "Low", "High"))
  > table(z) # levels are in alphabetical order
  z
  High  Low 
     2    1 
  > # put them in semantically increasing order and add Medium
  > z <- factor(z, levels=c("Low", "Medium", "High"))
  > table(z)
  z
     Low Medium   High 
       1      0      2 
You can also rename them by adding the labels argument:
  > z2 <- factor(z, levels=c("Low", "Medium", "High"), labels=c("L","M","H"))
  > table(z2)
  z2
  L M H 
  1 0 2

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Sarah Goslee
> Sent: Wednesday, December 11, 2013 2:24 PM
> To: Yuanzhi Li
> Cc: r-help
> Subject: Re: [R] bargraph.CI
> 
> Without knowing where you got bargraph.CI() I can't answer that part,
> since it isn't part of base R, but the most likely cause is that you
> did not specify the desired levels of your factor.
> You can check with str().
> 
> Compare:
> 
> > testdata <- factor(c("a", "b", "a", "c", "b"))
> > str(testdata)
>  Factor w/ 3 levels "a","b","c": 1 2 1 3 2
> >
> > testdata <- factor(c("a", "b", "a", "c", "b"), levels=c("c", "b", "a"))
> > str(testdata)
>  Factor w/ 3 levels "c","b","a": 3 2 3 1 2
> 
> Sarah
> 
> On Wed, Dec 11, 2013 at 5:06 PM, Yuanzhi Li <Yuanzhi.Li at usherbrooke.ca> wrote:
> > hello,
> >
> > I had a problem with the function "bargraph.CI". "bargraph.CI" draws a
> > figure according to the alphabet sequence of the factor used. For example, I
> > have a factor with for levels "CK", "N5", "N10", "N15", but the bars appear
> > in "CK","N10","N15","N5" order(alphabet sequence), but I want the bars to
> > appear  "CK", "N5", "N10", "N15"(treat level sequence). Do you have any
> > ideas to realize the goal?
> >
> > Thank you!
> >
> >
> > Yuanzhi
> >
> 
> --
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yuanzhi.li at usherbrooke.ca  Thu Dec 12 05:15:09 2013
From: yuanzhi.li at usherbrooke.ca (yuanzhi)
Date: Wed, 11 Dec 2013 20:15:09 -0800 (PST)
Subject: [R] bargraph.CI
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1C4AF@PA-MBX01.na.tibco.com>
References: <20131211170642.20755b5fkpjufo4c@www.usherbrooke.ca>
	<CAM_vjukRz+=JU3jK=U5aLRmnfHw1cKa9=jRbsb5VrX2XTUd-MA@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1C4AF@PA-MBX01.na.tibco.com>
Message-ID: <1386821709857-4682040.post@n4.nabble.com>

 
William Dunlap wrote
> Furthermore, if you have a factor z with the levels in an undesirable
> order
> or missing some levels you can call
>   z <- factor(z, levels=betterOrderedLevels)
> to get them in the order you want.  E.g.,
> 
>   > z <- factor(c("High", "Low", "High"))
>   > table(z) # levels are in alphabetical order
>   z
>   High  Low 
>      2    1 
>   > # put them in semantically increasing order and add Medium
>   > z <- factor(z, levels=c("Low", "Medium", "High"))
>   > table(z)
>   z
>      Low Medium   High 
>        1      0      2 
> You can also rename them by adding the labels argument:
>   > z2 <- factor(z, levels=c("Low", "Medium", "High"),
> labels=c("L","M","H"))
>   > table(z2)
>   z2
>   L M H 
>   1 0 2
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
>> -----Original Message-----
>> From: 

> r-help-bounces@

>  [mailto:

> r-help-bounces@

> ] On Behalf
>> Of Sarah Goslee
>> Sent: Wednesday, December 11, 2013 2:24 PM
>> To: Yuanzhi Li
>> Cc: r-help
>> Subject: Re: [R] bargraph.CI
>> 
>> Without knowing where you got bargraph.CI() I can't answer that part,
>> since it isn't part of base R, but the most likely cause is that you
>> did not specify the desired levels of your factor.
>> You can check with str().
>> 
>> Compare:
>> 
>> > testdata <- factor(c("a", "b", "a", "c", "b"))
>> > str(testdata)
>>  Factor w/ 3 levels "a","b","c": 1 2 1 3 2
>> >
>> > testdata <- factor(c("a", "b", "a", "c", "b"), levels=c("c", "b", "a"))
>> > str(testdata)
>>  Factor w/ 3 levels "c","b","a": 3 2 3 1 2
>> 
>> Sarah
>> 
>> On Wed, Dec 11, 2013 at 5:06 PM, Yuanzhi Li &lt;

> Yuanzhi.Li@

> &gt; wrote:
>> > hello,
>> >
>> > I had a problem with the function "bargraph.CI". "bargraph.CI" draws a
>> > figure according to the alphabet sequence of the factor used. For
>> example, I
>> > have a factor with for levels "CK", "N5", "N10", "N15", but the bars
>> appear
>> > in "CK","N10","N15","N5" order(alphabet sequence), but I want the bars
>> to
>> > appear  "CK", "N5", "N10", "N15"(treat level sequence). Do you have any
>> > ideas to realize the goal?
>> >
>> > Thank you!
>> >
>> >
>> > Yuanzhi
>> >
>> 
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>> 
>> ______________________________________________
>> 

> R-help@

>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Hello, I make it according to your suggestion. Thank you!



--
View this message in context: http://r.789695.n4.nabble.com/bargraph-CI-tp4682029p4682040.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Thu Dec 12 06:41:44 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 11 Dec 2013 21:41:44 -0800 (PST)
Subject: [R] R problem: Error in data[2:4] : object of type 'closure' is
	not subsettable
Message-ID: <1386826904.61147.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
May be this helps:

dat1 <- read.csv("Human_Rights_Excel_Data.csv") #converted .xlsx to .csv

mat1 <- log10(t(as.matrix(dat1[,2:4])))
mat1[!is.finite(mat1)] <- 0

par(mar=c(5,22,4,0.2))
COLOR<-c('red','brown4','black')
barplot(mat1,beside=T,horiz=T,las=2,col=COLOR,main='KilingsinGaza,\nWestBank,andIsrael',names.arg=t(dat1$X),xlab='Base10totheNnumberofKillings') 
par(new=T,mar=c(0,0,0,0))
plot(0,0,type="n")
legend("bottomleft",legend=c("Gaza","West Bank","Israel"),text.col=COLOR,bty="n",cex=1.5) 

A.K.




Human_Rights_Excel_Data.xlsx

Above is the attachment for my excel data. 

I am having this problem: Error in data[2:4] : object of type 'closure' is not subsettable 

Here is my code 
#data<-readcsv("HumanRightsExcelData") 
par(mar=c(5,22,4,0.2)) 
COLOR<-c('red','brown4','black') 
barplot(log10(t(as.matrix(data[,2:4]))),beside=T,horiz=T,las=2,names.arg=t(data$X),col=COLOR,main='KilingsinGaza,\nWestBank,andIsrael',xlab='Base10totheNnumberofKillings') 
par(new=T,mar=c(0,0,0,0)) 
plot(0,0,type="n") 
legend("bottomleft",legend=c("Gaza","West Bank","Israel"),text.col=COLOR,bty="n",cex=1.5) 

When ever I type in this code 

barplot(log10(t(as.matrix(data[,2:4]))),beside=T,horiz=T,las=2,names.arg=t(data$X),col=COLOR,main='KilingsinGaza,\nWestBank,andIsrael',xlab='Base10totheNnumberofKillings') 

I get this message 

Error in data[2:4] : object of type 'closure' is not subsettable 

Can someone please help me out? Also I am terrible with R so please try and make your responses idiot proof hahahaha.


From mdsumner at gmail.com  Thu Dec 12 07:41:07 2013
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 12 Dec 2013 17:41:07 +1100
Subject: [R] R problem: Error in data[2:4] : object of type 'closure' is
 not subsettable
In-Reply-To: <1386826904.61147.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1386826904.61147.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CAAcGz994X_ojRE34_-KpzQFVCEhBi0OP3T_XN2UYFBrF_GbzKA@mail.gmail.com>

That message refers to the function (closure) "data", which is a
function in R and that you have not overwritten with a data.frame in
that session. Note how you two versions of the code:

dat1 <- read.csv("Human_Rights_Excel_Data.csv") #converted .xlsx to .csv

and

#data<-readcsv("HumanRightsExcelData")

Just makes sure you use dat1[,2:4] instead, or rename your variable to
suit. Working up a reproducible example in a fresh session (even if
only you can run it) will catch problems like this.

(And in future, when you see that error message think "ah it means I'm
trying to index a function (probably) rather than my data object". )

HTH






On Thu, Dec 12, 2013 at 4:41 PM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> May be this helps:
>
> dat1 <- read.csv("Human_Rights_Excel_Data.csv") #converted .xlsx to .csv
>
> mat1 <- log10(t(as.matrix(dat1[,2:4])))
> mat1[!is.finite(mat1)] <- 0
>
> par(mar=c(5,22,4,0.2))
> COLOR<-c('red','brown4','black')
> barplot(mat1,beside=T,horiz=T,las=2,col=COLOR,main='KilingsinGaza,\nWestBank,andIsrael',names.arg=t(dat1$X),xlab='Base10totheNnumberofKillings')
> par(new=T,mar=c(0,0,0,0))
> plot(0,0,type="n")
> legend("bottomleft",legend=c("Gaza","West Bank","Israel"),text.col=COLOR,bty="n",cex=1.5)
>
> A.K.
>
>
>
>
> Human_Rights_Excel_Data.xlsx
>
> Above is the attachment for my excel data.
>
> I am having this problem: Error in data[2:4] : object of type 'closure' is not subsettable
>
> Here is my code
> #data<-readcsv("HumanRightsExcelData")
> par(mar=c(5,22,4,0.2))
> COLOR<-c('red','brown4','black')
> barplot(log10(t(as.matrix(data[,2:4]))),beside=T,horiz=T,las=2,names.arg=t(data$X),col=COLOR,main='KilingsinGaza,\nWestBank,andIsrael',xlab='Base10totheNnumberofKillings')
> par(new=T,mar=c(0,0,0,0))
> plot(0,0,type="n")
> legend("bottomleft",legend=c("Gaza","West Bank","Israel"),text.col=COLOR,bty="n",cex=1.5)
>
> When ever I type in this code
>
> barplot(log10(t(as.matrix(data[,2:4]))),beside=T,horiz=T,las=2,names.arg=t(data$X),col=COLOR,main='KilingsinGaza,\nWestBank,andIsrael',xlab='Base10totheNnumberofKillings')
>
> I get this message
>
> Error in data[2:4] : object of type 'closure' is not subsettable
>
> Can someone please help me out? Also I am terrible with R so please try and make your responses idiot proof hahahaha.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Michael Sumner
Hobart, Australia
e-mail: mdsumner at gmail.com


From htl10 at users.sourceforge.net  Thu Dec 12 04:30:31 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 12 Dec 2013 03:30:31 +0000
Subject: [R] freetype 2.5.2, problem with the survival package,
 build R 2.15.x with gcc 4.8.x
In-Reply-To: <52948B3C.8020801@users.sourceforge.net>
References: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>
	<5225B120.8050406@users.sourceforge.net>
	<52948B3C.8020801@users.sourceforge.net>
Message-ID: <52A92DD7.2050905@users.sourceforge.net>

Here is a rather long discussion etc about freetype 2.5.2, problem with the 
survival package, and build R 2.15.x with gcc 4.8.x. Please feel free to skip 
forward.

- freetype 2.5.2:

the fix to cope with one of the Mac OS X's system fonts just before the release 
of freetype 2.5.1 caused a regression, crashing over one of Microsoft windows' 
system fonts. So there is a 2.5.2. There are new 2.5.2 bundles for windows & Mac 
OS X. The official win/mac binaries of R were built statically with 2+-years-old 
freetype with a few known problems. Most should upgrade/rebuild.

http://sourceforge.net/projects/outmodedbonsai/files/R/

- problem with the survival package:

Trying to re-run a vignette to get the same result as two years ago
reveal a strange change. I went and bisected it down to
r11513 and r11516 of the survival package.

-------------- r11513 --------------------
clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))


                    coef exp(coef) se(coef)     z      p
addContr(A)2     -0.620     0.538    0.217 -2.86 0.0043
addContr(C)2      0.482     1.620    0.217  2.22 0.0270
addContr(A.C)1-2 -0.778     0.459    0.275 -2.83 0.0047
addContr(A.C)2-1     NA        NA    0.000    NA     NA
addContr(A.C)2-2     NA        NA    0.000    NA     NA

Likelihood ratio test=26  on 3 df, p=9.49e-06  n= 13110, number of events= 3524
------------------------------------------

------------- r11516 ---------------------
clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))


                      coef exp(coef) se(coef)         z  p
addContr(A)2     -0.14250     0.867   110812 -1.29e-06  1
addContr(C)2      0.00525     1.005   110812  4.74e-08  1
addContr(A.C)1-2 -0.30097     0.740   110812 -2.72e-06  1
addContr(A.C)2-1 -0.47712     0.621   110812 -4.31e-06  1
addContr(A.C)2-2       NA        NA        0        NA NA

Likelihood ratio test=26  on 4 df, p=3.15e-05  n= 13110, number of events= 3524
------------------------------------------

r11514 does not build, and r11515 have serious memory hogs, so the survival
package broke somewhere between r11513 and r11516. Anyway, here is the diff in
the vignette, and the data, etc is in the directory above. If somebody want to
fix this before I spend any more time on this particular matter, please feel 
free to do so.

http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical8_survival-clogit-diff.pdf/download

That's the one problem from David's 10 practicals which are not due to bugs in 
snpStats. Some might find it reassuring that only 3 of the 4 problems with the 
practicals are due to snpStats bugs.

http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical7_snpStatsBug-diff.pdf/download
http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical6_snpStatsBug-diff.pdf/download
http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical3_snpStatsBug-diff.pdf/download

- build R 2.15.x with gcc 4.8.x

I wish the R commit log was a bit more detailed with r62430 than just
"tweak needed for gcc 4.8.x". Anyway, building R 2.15.x with gcc 4.8.x
could result in segfaults in usage as innocent and essential
as running summary() on a data.frame:

--------------------------------
  *** caught segfault ***
address 0x2f8e6a00, cause 'memory not mapped'

Traceback:
  1: sort.list(y)
  2: factor(a, exclude = exclude)
  3: table(object, exclude = NULL)
  4: summary.default(X[[3L]], ...)
  5: FUN(X[[3L]], ...)
  6: lapply(X = as.list(object), FUN = summary, maxsum = maxsum, digits = 12, 
   ...)
  7: summary.data.frame(support)
...
--------------------------------

r62430 needs a bit of adapting to apply to R 2.15.x , but you get the idea.
I hope this info is useful to somebody else who is still using R 2.15.x , no 
doubt for very good reasons.

Hin-Tak Leung wrote:
> The freetype people fixed the 2nd set of issues with system fonts shipped with
> Mac OS X, and released 2.5.1 almost immediately after that. So there are
> new bundles under http://sourceforge.net/projects/outmodedbonsai/files/R/ .
>
> Just a reminder that the official R binaries for windows/mac OS X are statically
> linked with rather dated versions of freetype with a few known issues. This
> affects the cairo-based functionalities in R. So a rebuild is needed.
>
> Most unix users should just upgrade their system's libfreetype, and
> dynamic-linking should take care of the rest.


From avi5032 at psu.edu  Thu Dec 12 05:50:56 2013
From: avi5032 at psu.edu (andrepavlik)
Date: Wed, 11 Dec 2013 20:50:56 -0800 (PST)
Subject: [R] R problem: Error in data[2:4] : object of type 'closure' is not
 subsettable
Message-ID: <1386823856130-4682042.post@n4.nabble.com>

Human_Rights_Excel_Data.xlsx
<http://r.789695.n4.nabble.com/file/n4682042/Human_Rights_Excel_Data.xlsx>  

Above is the attachment for my excel data. 

I am having this problem: Error in data[2:4] : object of type 'closure' is
not subsettable

Here is my code
#data<-readcsv("HumanRightsExcelData")
par(mar=c(5,22,4,0.2))
COLOR<-c('red','brown4','black')
barplot(log10(t(as.matrix(data[,2:4]))),beside=T,horiz=T,las=2,names.arg=t(data$X),col=COLOR,main='KilingsinGaza,\nWestBank,andIsrael',xlab='Base10totheNnumberofKillings')
par(new=T,mar=c(0,0,0,0))
plot(0,0,type="n")
legend("bottomleft",legend=c("Gaza","West
Bank","Israel"),text.col=COLOR,bty="n",cex=1.5)

When ever I type in this code

barplot(log10(t(as.matrix(data[,2:4]))),beside=T,horiz=T,las=2,names.arg=t(data$X),col=COLOR,main='KilingsinGaza,\nWestBank,andIsrael',xlab='Base10totheNnumberofKillings')

I get this message

Error in data[2:4] : object of type 'closure' is not subsettable

Can someone please help me out? Also I am terrible with R so please try and
make your responses idiot proof hahahaha. 



--
View this message in context: http://r.789695.n4.nabble.com/R-problem-Error-in-data-2-4-object-of-type-closure-is-not-subsettable-tp4682042.html
Sent from the R help mailing list archive at Nabble.com.


From johnwilliams at fas.harvard.edu  Thu Dec 12 06:49:30 2013
From: johnwilliams at fas.harvard.edu (johnwilliams at fas.harvard.edu)
Date: Thu, 12 Dec 2013 00:49:30 -0500
Subject: [R] refline in forest() {metafor}
Message-ID: <1386827370.52a94e6ad09ad@webmail.fas.harvard.edu>

Hello all,

I am using forest.rma to plot a random effects model meta-analysis. I noticed
that refline sets a vertical line indicating the null hypothesis.

Is there a way to draw another vertical line, possibly dashed, centered on the
summary estimate?

Prof. Viechtbauer, if you happen to read this, I'd like to thank you for making
an excellent package. I have been using the metafor package to do my first
meta-analysis, having never used R before. The documentation is thorough and
intuitive.

Thanks,

John

John Williams
ALB Candidate
Harvard University Extension School
johnwilliams at fas.harvard.edu


From bhh at xs4all.nl  Thu Dec 12 09:01:02 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 12 Dec 2013 09:01:02 +0100
Subject: [R] solving simultaneous Equations in R
In-Reply-To: <BLU170-W1370DCFF5AD3BAB481330AE89DD0@phx.gbl>
References: <BLU170-W1148EF2454A33B20811FA1B89DD0@phx.gbl>,
	<794DC044-7B8D-4892-B3FE-DCB5C7AE6AC8@xs4all.nl>
	<BLU170-W1370DCFF5AD3BAB481330AE89DD0@phx.gbl>
Message-ID: <1CF9124A-80EB-4E79-B573-608D8F6C61FC@xs4all.nl>


On 11-12-2013, at 23:56, eliza botto <eliza_botto at hotmail.com> wrote:

> Dear Berend,
> 
> Thankyou very much indeed for you reply. By taking help from your previous reply @ http://r.789695.n4.nabble.com/Simultaneous-equations-td2524645.html i was able to generate the following loop for the calculation of x=x[1] and y=x[2]. 
> 
> 
> fun <- function(x) {
> 
>                 f <- numeric(length(x))                                                                                 # read as:
> 
> 
> f[1] <- 1-0.514-(gamma(1/x[1])*gamma(2/x[1]-1/x[2]))/(gamma(2/x[1])*gamma(1/x[1]-1/x[2]))
> 
>                 f[2] <- 0.57-
> 
> (gamma(1/x[1]-1/x[2])/gamma(1/x[1])-3*gamma(2/x[1]-1/x[2])/gamma(2/x[1])+2*gamma(3/x[1]-1/x[2])/gamma(3/x[1]))/(gamma(1/x[1]-1/x[2])/gamma(1
> 
> /x[1])-gamma(2/x[1]-1/x[2])/gamma(2/x[1]))
> 
>                 f
> 
> }
> 
> 
> startx <- c(0.1,0.15) # start the answer search here
> 
> answers<-as.data.frame(nleqslv(startx,fun))
> 
> answers
> 
> What i cant understand is the concept involved for setting "startx". my x[1] should always be smaller than x[2] and they both should be less than 1. how can i demonstrate it to startx command line?
> 

I don?t quite understand what you you mean.
Your starting values obey the restrictions you specify (if that is what you meant).
The solution vector has all elements > 1. But it is a solution.

Do you mean that you want a solution satisfying the constraints you mention?
I cannot tell if that is possible.

Generally speaking a square system of equations is solved or not.

Sometimes you can vary the starting values to get a different solution that obeys the specified constraints.
If these constraints  are necessary you are not solving a system of equations but trying to find a  parameter set that satisfies certain criteria. Together with a criterion (sum of squares of function values for example) you could use an optimizing algorithm (optim, nlmin, constrOptim to name a few).

Berend


> thanks for your help. I m grateful.
> 
>   Eliza
> 
> 
> 
> 
> > Subject: Re: [R] solving simultaneous Equations in R
> > From: bhh at xs4all.nl
> > Date: Wed, 11 Dec 2013 12:43:02 +0100
> > CC: r-help at r-project.org
> > To: eliza_botto at hotmail.com
> > 
> > 
> > On 11-12-2013, at 12:16, eliza botto <eliza_botto at hotmail.com> wrote:
> > 
> > > Dear users of R,
> > > I'm trying to solve the following 2 equations simultaneously in R for "x" and "y". I couldn't get through due to my limited knowledge of R.
> > > 
> > > 3=1-[(x-1)!(2x-y-1)!/(2x-1)!(x-y-1)!] 
> > > 
> > > 6={[(x-y-1)!/(x-1)!]-[3(2x-y-1)!/(2x-1)!]+[2(3x-y-1)!/(3x-1)!]}/{[(x-y-1)!/(x-1)!]-[(2x-y-1)!/(2x-1)!]}
> > > 
> > > obviously, ! is factorial.
> > > kindly help me out on it or at least suggest something.
> > > I'll be extremely grateful.
> > 
> > There are several packages that solve a system of equations.
> > ktsolve, nleqslv, BB, which you can find in CRAN Task views: "Numerical Mathematics? and ?Optimization?.
> > 
> > You will have to write your equations in standard R notation.
> > I can?t tell if your system is solvable.
> > 
> > Berend
> > 
> > > Eliza
> > > 
> > > 
> > > 
> > > [[alternative HTML version deleted]]
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Dec 12 09:26:11 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 12 Dec 2013 09:26:11 +0100
Subject: [R] refline in forest() {metafor}
In-Reply-To: <1386827370.52a94e6ad09ad@webmail.fas.harvard.edu>
References: <1386827370.52a94e6ad09ad@webmail.fas.harvard.edu>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D99665CEA@UM-MAIL4112.unimaas.nl>

Regarding your question: Do you want *another* line or do you just want to move the reference line to the value of the summary estimate? The latter can be done by passing the value of the summary estimate to the 'refline' argument. If you want another line, you could just use the abline function, or, for finer control, the segments function. Something like:

segments(coef(res), 0, coef(res), res$k, lty="dashed")

where 'res' is the name of the fitted model object. You may have to play around with the 0 and res$k values, so that the line has the 'correct' length.

Thanks for the positive feedback about the package.

Best,
Wolfgang

--
Wolfgang Viechtbauer, Ph.D., Statistician
Department of Psychiatry and Psychology
School for Mental Health and Neuroscience
Faculty of Health, Medicine, and Life Sciences
Maastricht University, P.O. Box 616 (VIJV1)
6200 MD Maastricht, The Netherlands
+31 (43) 388-4170 | http://www.wvbauer.com
________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] On Behalf Of johnwilliams at fas.harvard.edu [johnwilliams at fas.harvard.edu]
Sent: Thursday, December 12, 2013 6:49 AM
To: r-help at r-project.org
Subject: [R] refline in forest() {metafor}

Hello all,

I am using forest.rma to plot a random effects model meta-analysis. I noticed
that refline sets a vertical line indicating the null hypothesis.

Is there a way to draw another vertical line, possibly dashed, centered on the
summary estimate?

Prof. Viechtbauer, if you happen to read this, I'd like to thank you for making
an excellent package. I have been using the metafor package to do my first
meta-analysis, having never used R before. The documentation is thorough and
intuitive.

Thanks,

John

John Williams
ALB Candidate
Harvard University Extension School
johnwilliams at fas.harvard.edu

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From johnwilliams at fas.harvard.edu  Thu Dec 12 09:50:31 2013
From: johnwilliams at fas.harvard.edu (johnwilliams at fas.harvard.edu)
Date: Thu, 12 Dec 2013 03:50:31 -0500
Subject: [R] refline in forest() {metafor}
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730D99665CEA@UM-MAIL4112.unimaas.nl>
References: <1386827370.52a94e6ad09ad@webmail.fas.harvard.edu>
	<077E31A57DA26E46AB0D493C9966AC730D99665CEA@UM-MAIL4112.unimaas.nl>
Message-ID: <1386838231.52a978d7f240d@webmail.fas.harvard.edu>

I would like another line, and the solution below will work great. Thank you.

- John

Quoting "Viechtbauer Wolfgang (STAT)"
<wolfgang.viechtbauer at maastrichtuniversity.nl>:

> Regarding your question: Do you want *another* line or do you just want to
> move the reference line to the value of the summary estimate? The latter can
> be done by passing the value of the summary estimate to the 'refline'
> argument. If you want another line, you could just use the abline function,
> or, for finer control, the segments function. Something like:
>
> segments(coef(res), 0, coef(res), res$k, lty="dashed")
>
> where 'res' is the name of the fitted model object. You may have to play
> around with the 0 and res$k values, so that the line has the 'correct'
> length.
>
> Thanks for the positive feedback about the package.
>
> Best,
> Wolfgang
>
> --
> Wolfgang Viechtbauer, Ph.D., Statistician
> Department of Psychiatry and Psychology
> School for Mental Health and Neuroscience
> Faculty of Health, Medicine, and Life Sciences
> Maastricht University, P.O. Box 616 (VIJV1)
> 6200 MD Maastricht, The Netherlands
> +31 (43) 388-4170 | http://www.wvbauer.com
> ________________________________________
> From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] On Behalf
> Of johnwilliams at fas.harvard.edu [johnwilliams at fas.harvard.edu]
> Sent: Thursday, December 12, 2013 6:49 AM
> To: r-help at r-project.org
> Subject: [R] refline in forest() {metafor}
>
> Hello all,
>
> I am using forest.rma to plot a random effects model meta-analysis. I noticed
> that refline sets a vertical line indicating the null hypothesis.
>
> Is there a way to draw another vertical line, possibly dashed, centered on
> the
> summary estimate?
>
> Prof. Viechtbauer, if you happen to read this, I'd like to thank you for
> making
> an excellent package. I have been using the metafor package to do my first
> meta-analysis, having never used R before. The documentation is thorough and
> intuitive.
>
> Thanks,
>
> John
>
> John Williams
> ALB Candidate
> Harvard University Extension School
> johnwilliams at fas.harvard.edu
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From romeo.kienzler at gmail.com  Thu Dec 12 09:00:18 2013
From: romeo.kienzler at gmail.com (Romeo Kienzler)
Date: Thu, 12 Dec 2013 09:00:18 +0100
Subject: [R] Logistic Regression with 200K features in R?
Message-ID: <52A96D12.5070408@gmail.com>

Dear List,

I'm quite new to R and want to do logistic regression with a 200K 
feature data set (around 150 training examples).

I'm aware that I should use Naive Bayes but I have a more general 
question about the capability of R handling very high dimensional data.

Please consider the following R code where "mygenestrain.tab" is a 150 
by 200000 matrix:

traindata <- read.table('mygenestrain.tab');
mylogit <- glm(V1 ~ ., data = traindata, family = "binomial");

When executing this code I get the following error:

Error in terms.formula(formula, data = data) :
   allocMatrix: too many elements specified
Calls: glm ... model.frame -> model.frame.default -> terms -> terms.formula
Execution halted

Is this because R can't handle 200K features or am I doing something 
completely wrong here?

Thanks a lot for your help!

best Regards,

Romeo


From E.Vettorazzi at uke.de  Thu Dec 12 12:12:16 2013
From: E.Vettorazzi at uke.de (Eik Vettorazzi)
Date: Thu, 12 Dec 2013 12:12:16 +0100
Subject: [R] Logistic Regression with 200K features in R?
In-Reply-To: <52A96D12.5070408@gmail.com>
References: <52A96D12.5070408@gmail.com>
Message-ID: <52A99A10.4010805@uke.de>

it is simply because you can't do a regression with more predictors than
observations.

Cheers.

Am 12.12.2013 09:00, schrieb Romeo Kienzler:
> Dear List,
> 
> I'm quite new to R and want to do logistic regression with a 200K
> feature data set (around 150 training examples).
> 
> I'm aware that I should use Naive Bayes but I have a more general
> question about the capability of R handling very high dimensional data.
> 
> Please consider the following R code where "mygenestrain.tab" is a 150
> by 200000 matrix:
> 
> traindata <- read.table('mygenestrain.tab');
> mylogit <- glm(V1 ~ ., data = traindata, family = "binomial");
> 
> When executing this code I get the following error:
> 
> Error in terms.formula(formula, data = data) :
>   allocMatrix: too many elements specified
> Calls: glm ... model.frame -> model.frame.default -> terms -> terms.formula
> Execution halted
> 
> Is this because R can't handle 200K features or am I doing something
> completely wrong here?
> 
> Thanks a lot for your help!
> 
> best Regards,
> 
> Romeo
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790
--

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From eliza_botto at hotmail.com  Thu Dec 12 12:41:21 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Thu, 12 Dec 2013 11:41:21 +0000
Subject: [R] solving simultaneous Equations in R
In-Reply-To: <1CF9124A-80EB-4E79-B573-608D8F6C61FC@xs4all.nl>
References: <BLU170-W1148EF2454A33B20811FA1B89DD0@phx.gbl>,
	<794DC044-7B8D-4892-B3FE-DCB5C7AE6AC8@xs4all.nl>
	<BLU170-W1370DCFF5AD3BAB481330AE89DD0@phx.gbl>,
	<1CF9124A-80EB-4E79-B573-608D8F6C61FC@xs4all.nl>
Message-ID: <BLU170-W130329FDAF13A5E7BBAA08A89DC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/7529fc90/attachment.pl>

From E.Vettorazzi at uke.de  Thu Dec 12 12:51:10 2013
From: E.Vettorazzi at uke.de (Eik Vettorazzi)
Date: Thu, 12 Dec 2013 12:51:10 +0100
Subject: [R] Logistic Regression with 200K features in R?
In-Reply-To: <52A99F41.50401@gmail.com>
References: <52A96D12.5070408@gmail.com> <52A99A10.4010805@uke.de>
	<52A99F41.50401@gmail.com>
Message-ID: <52A9A32E.4010509@uke.de>

I thought so (with all the limitations due to collinearity and so on),
but actually there is a limit for the maximum size of an array which is
independent of your memory size and is due to the way arrays are
indexed. You can't create an object with more than 2^31-1 = 2147483647
elements.

https://stat.ethz.ch/pipermail/r-help/2007-June/133238.html

cheers

Am 12.12.2013 12:34, schrieb Romeo Kienzler:
> ok, so 200K predictors an 10M observations would work?
> 
> 
> On 12/12/2013 12:12 PM, Eik Vettorazzi wrote:
>> it is simply because you can't do a regression with more predictors than
>> observations.
>>
>> Cheers.
>>
>> Am 12.12.2013 09:00, schrieb Romeo Kienzler:
>>> Dear List,
>>>
>>> I'm quite new to R and want to do logistic regression with a 200K
>>> feature data set (around 150 training examples).
>>>
>>> I'm aware that I should use Naive Bayes but I have a more general
>>> question about the capability of R handling very high dimensional data.
>>>
>>> Please consider the following R code where "mygenestrain.tab" is a 150
>>> by 200000 matrix:
>>>
>>> traindata <- read.table('mygenestrain.tab');
>>> mylogit <- glm(V1 ~ ., data = traindata, family = "binomial");
>>>
>>> When executing this code I get the following error:
>>>
>>> Error in terms.formula(formula, data = data) :
>>>    allocMatrix: too many elements specified
>>> Calls: glm ... model.frame -> model.frame.default -> terms ->
>>> terms.formula
>>> Execution halted
>>>
>>> Is this because R can't handle 200K features or am I doing something
>>> completely wrong here?
>>>
>>> Thanks a lot for your help!
>>>
>>> best Regards,
>>>
>>> Romeo
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790
--

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From murdoch.duncan at gmail.com  Thu Dec 12 13:00:11 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Dec 2013 07:00:11 -0500
Subject: [R] Logistic Regression with 200K features in R?
In-Reply-To: <52A9A32E.4010509@uke.de>
References: <52A96D12.5070408@gmail.com>
	<52A99A10.4010805@uke.de>	<52A99F41.50401@gmail.com>
	<52A9A32E.4010509@uke.de>
Message-ID: <52A9A54B.6040203@gmail.com>

On 13-12-12 6:51 AM, Eik Vettorazzi wrote:
> I thought so (with all the limitations due to collinearity and so on),
> but actually there is a limit for the maximum size of an array which is
> independent of your memory size and is due to the way arrays are
> indexed. You can't create an object with more than 2^31-1 = 2147483647
> elements.
>
> https://stat.ethz.ch/pipermail/r-help/2007-June/133238.html

That post is from 2007.  The limits were raised considerably when R 
3.0.0 was released, and it is now 2^48 for disk-based operations, 2^52 
for working in memory.

Duncan Murdoch


>
> cheers
>
> Am 12.12.2013 12:34, schrieb Romeo Kienzler:
>> ok, so 200K predictors an 10M observations would work?
>>
>>
>> On 12/12/2013 12:12 PM, Eik Vettorazzi wrote:
>>> it is simply because you can't do a regression with more predictors than
>>> observations.
>>>
>>> Cheers.
>>>
>>> Am 12.12.2013 09:00, schrieb Romeo Kienzler:
>>>> Dear List,
>>>>
>>>> I'm quite new to R and want to do logistic regression with a 200K
>>>> feature data set (around 150 training examples).
>>>>
>>>> I'm aware that I should use Naive Bayes but I have a more general
>>>> question about the capability of R handling very high dimensional data.
>>>>
>>>> Please consider the following R code where "mygenestrain.tab" is a 150
>>>> by 200000 matrix:
>>>>
>>>> traindata <- read.table('mygenestrain.tab');
>>>> mylogit <- glm(V1 ~ ., data = traindata, family = "binomial");
>>>>
>>>> When executing this code I get the following error:
>>>>
>>>> Error in terms.formula(formula, data = data) :
>>>>     allocMatrix: too many elements specified
>>>> Calls: glm ... model.frame -> model.frame.default -> terms ->
>>>> terms.formula
>>>> Execution halted
>>>>
>>>> Is this because R can't handle 200K features or am I doing something
>>>> completely wrong here?
>>>>
>>>> Thanks a lot for your help!
>>>>
>>>> best Regards,
>>>>
>>>> Romeo
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From E.Vettorazzi at uke.de  Thu Dec 12 13:08:26 2013
From: E.Vettorazzi at uke.de (Eik Vettorazzi)
Date: Thu, 12 Dec 2013 13:08:26 +0100
Subject: [R] Logistic Regression with 200K features in R?
In-Reply-To: <52A9A54B.6040203@gmail.com>
References: <52A96D12.5070408@gmail.com>
	<52A99A10.4010805@uke.de>	<52A99F41.50401@gmail.com>
	<52A9A32E.4010509@uke.de> <52A9A54B.6040203@gmail.com>
Message-ID: <52A9A73A.9070209@uke.de>

thanks Duncan for this clarification.
A double precision matrix with 2e11 elements (as the op wanted) would
need about 1.5 TB memory, that's more than a standard (windows 64bit)
computer can handle.

Cheers.

Am 12.12.2013 13:00, schrieb Duncan Murdoch:
> On 13-12-12 6:51 AM, Eik Vettorazzi wrote:
>> I thought so (with all the limitations due to collinearity and so on),
>> but actually there is a limit for the maximum size of an array which is
>> independent of your memory size and is due to the way arrays are
>> indexed. You can't create an object with more than 2^31-1 = 2147483647
>> elements.
>>
>> https://stat.ethz.ch/pipermail/r-help/2007-June/133238.html
> 
> That post is from 2007.  The limits were raised considerably when R
> 3.0.0 was released, and it is now 2^48 for disk-based operations, 2^52
> for working in memory.
> 
> Duncan Murdoch
> 
> 
>>
>> cheers
>>
>> Am 12.12.2013 12:34, schrieb Romeo Kienzler:
>>> ok, so 200K predictors an 10M observations would work?
>>>
>>>
>>> On 12/12/2013 12:12 PM, Eik Vettorazzi wrote:
>>>> it is simply because you can't do a regression with more predictors
>>>> than
>>>> observations.
>>>>
>>>> Cheers.
>>>>
>>>> Am 12.12.2013 09:00, schrieb Romeo Kienzler:
>>>>> Dear List,
>>>>>
>>>>> I'm quite new to R and want to do logistic regression with a 200K
>>>>> feature data set (around 150 training examples).
>>>>>
>>>>> I'm aware that I should use Naive Bayes but I have a more general
>>>>> question about the capability of R handling very high dimensional
>>>>> data.
>>>>>
>>>>> Please consider the following R code where "mygenestrain.tab" is a 150
>>>>> by 200000 matrix:
>>>>>
>>>>> traindata <- read.table('mygenestrain.tab');
>>>>> mylogit <- glm(V1 ~ ., data = traindata, family = "binomial");
>>>>>
>>>>> When executing this code I get the following error:
>>>>>
>>>>> Error in terms.formula(formula, data = data) :
>>>>>     allocMatrix: too many elements specified
>>>>> Calls: glm ... model.frame -> model.frame.default -> terms ->
>>>>> terms.formula
>>>>> Execution halted
>>>>>
>>>>> Is this because R can't handle 200K features or am I doing something
>>>>> completely wrong here?
>>>>>
>>>>> Thanks a lot for your help!
>>>>>
>>>>> best Regards,
>>>>>
>>>>> Romeo
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790
--

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From johannesradinger at gmail.com  Thu Dec 12 14:56:03 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Thu, 12 Dec 2013 14:56:03 +0100
Subject: [R] Solving a normal distribution pnorm for q
Message-ID: <CABsGe_xr8LnKbFA+M7aRV0nbm8=Ebi=j=h7pmuNR=Dk5iOHUfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/22e54a47/attachment.pl>

From bhh at xs4all.nl  Thu Dec 12 15:07:34 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 12 Dec 2013 15:07:34 +0100
Subject: [R] Solving a normal distribution pnorm for q
In-Reply-To: <CABsGe_xr8LnKbFA+M7aRV0nbm8=Ebi=j=h7pmuNR=Dk5iOHUfg@mail.gmail.com>
References: <CABsGe_xr8LnKbFA+M7aRV0nbm8=Ebi=j=h7pmuNR=Dk5iOHUfg@mail.gmail.com>
Message-ID: <A9F62F56-59A4-44D5-82E8-0C1F6B6AE2ED@xs4all.nl>


On 12-12-2013, at 14:56, Johannes Radinger <johannesradinger at gmail.com> wrote:

> Hi,
> 
> 
> 
> I found follwowing example of pnorm here:
> 
> http://www.r-tutor.com/elementary-statistics/probability-distributions/normal-distribution
> 
> 
> 
> Problem
> 
> Assume that the test scores of a college entrance exam fits a normal
> distribution. Furthermore, the mean test score is 72, and the standard
> deviation is 15.2. What is the percentage of students scoring 84 or more in
> the exam?
> 
> 
> 
> Solution
> 
>> pnorm(84, mean=72, sd=15.2, lower.tail=FALSE)
> 
> [1] 0.21492
> 
> 
> 
> That is straight forward, however what if I want to know the score the best
> 30% students are reaching at least. So I know the solution of pnorm but
> want to know its q. How can that be achieved in R?
> 
> 
> 
> Any suggestions?


Do

?pnorm

in R. You are directed to a help page where you will also see ?qnorm?.
Then try qnorm.

Berend


From kehld at ktk.pte.hu  Thu Dec 12 15:09:24 2013
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?D=E1niel_Kehl?=)
Date: Thu, 12 Dec 2013 14:09:24 +0000
Subject: [R] Solving a normal distribution pnorm for q
In-Reply-To: <CABsGe_xr8LnKbFA+M7aRV0nbm8=Ebi=j=h7pmuNR=Dk5iOHUfg@mail.gmail.com>
References: <CABsGe_xr8LnKbFA+M7aRV0nbm8=Ebi=j=h7pmuNR=Dk5iOHUfg@mail.gmail.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B90C555@EMAIL.ktkdom.pte.hu>

Looks like homework.

Try ?qnorm
________________________________________
Felad?: r-help-bounces at r-project.org [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Johannes Radinger [johannesradinger at gmail.com]
K?ldve: 2013. december 12. 14:56
To: R help
T?rgy: [R] Solving a normal distribution pnorm for q

Hi,



I found follwowing example of pnorm here:

http://www.r-tutor.com/elementary-statistics/probability-distributions/normal-distribution



Problem

Assume that the test scores of a college entrance exam fits a normal
distribution. Furthermore, the mean test score is 72, and the standard
deviation is 15.2. What is the percentage of students scoring 84 or more in
the exam?



Solution

> pnorm(84, mean=72, sd=15.2, lower.tail=FALSE)

[1] 0.21492



That is straight forward, however what if I want to know the score the best
30% students are reaching at least. So I know the solution of pnorm but
want to know its q. How can that be achieved in R?



Any suggestions?



/Johannes

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Thu Dec 12 15:20:41 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 12 Dec 2013 06:20:41 -0800
Subject: [R] Solving a normal distribution pnorm for q
In-Reply-To: <CABsGe_xr8LnKbFA+M7aRV0nbm8=Ebi=j=h7pmuNR=Dk5iOHUfg@mail.gmail.com>
References: <CABsGe_xr8LnKbFA+M7aRV0nbm8=Ebi=j=h7pmuNR=Dk5iOHUfg@mail.gmail.com>
Message-ID: <5d4539c0-ca9a-475f-bddf-dd9556e186dc@email.android.com>

?pnorm ... carefully...
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Johannes Radinger <johannesradinger at gmail.com> wrote:
>Hi,
>
>
>
>I found follwowing example of pnorm here:
>
>http://www.r-tutor.com/elementary-statistics/probability-distributions/normal-distribution
>
>
>
>Problem
>
>Assume that the test scores of a college entrance exam fits a normal
>distribution. Furthermore, the mean test score is 72, and the standard
>deviation is 15.2. What is the percentage of students scoring 84 or
>more in
>the exam?
>
>
>
>Solution
>
>> pnorm(84, mean=72, sd=15.2, lower.tail=FALSE)
>
>[1] 0.21492
>
>
>
>That is straight forward, however what if I want to know the score the
>best
>30% students are reaching at least. So I know the solution of pnorm but
>want to know its q. How can that be achieved in R?
>
>
>
>Any suggestions?
>
>
>
>/Johannes
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From fisher at plessthan.com  Thu Dec 12 15:32:26 2013
From: fisher at plessthan.com (Fisher Dennis)
Date: Thu, 12 Dec 2013 06:32:26 -0800
Subject: [R] labels on right y-axis
Message-ID: <3814E80B-39AE-43A1-8B99-24D71097FBBE@plessthan.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/2f24b8ea/attachment.pl>

From johannesradinger at gmail.com  Thu Dec 12 15:58:13 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Thu, 12 Dec 2013 15:58:13 +0100
Subject: [R] Solving a normal distribution pnorm for q
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D0B90C555@EMAIL.ktkdom.pte.hu>
References: <CABsGe_xr8LnKbFA+M7aRV0nbm8=Ebi=j=h7pmuNR=Dk5iOHUfg@mail.gmail.com>
	<33D76D77E9AC4B438DA38B348ED6890D0B90C555@EMAIL.ktkdom.pte.hu>
Message-ID: <CABsGe_wNT9UBiL=3NsvfUJdNK6R0ps7XL-UdKs5rFa37DPKJoA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/21668632/attachment.pl>

From Steven.Hodge at umassmed.edu  Thu Dec 12 16:22:29 2013
From: Steven.Hodge at umassmed.edu (Hodge, Steven)
Date: Thu, 12 Dec 2013 10:22:29 -0500
Subject: [R] radial.plot shaded region
In-Reply-To: <52A7D48F.6030705@bitwrit.com.au>
References: <AEE7BE1B8BD7C645B75328C8D702F94B177BBC8210@UMMSCSMAIL02.ad.umassmed.edu>
	<52A7B0A3.5060303@bitwrit.com.au>,<52A7D48F.6030705@bitwrit.com.au>
Message-ID: <AEE7BE1B8BD7C645B75328C8D702F94B177BBC8221@UMMSCSMAIL02.ad.umassmed.edu>

From: Jim Lemon [jim at bitwrit.com.au]
Sent: Tuesday, December 10, 2013 21:57
To: Hodge, Steven
Cc: r-help at r-project.org
Subject: Re: [R] radial.plot shaded region

On 12/11/2013 11:24 AM, Jim Lemon wrote:
>> ...
>> There may be a solution using the radial.pie function, and if I find it,
>> I'll post it.
>>
> Hi Steve,
> Here it is. Just call radial.pie twice to get the annulus, then call
> radial.grid with the appropriate arguments, and then you can add
> whatever radial.plot you want, using the "add" argument.
> 
> radial.pie(3.5,sector.colors="lightblue")
> radial.pie(3,sector.colors="white",add=TRUE)
> radial.grid(radial.lim=c(0,3.5),grid.pos=seq(0,3.5,length.out=8))
> 
> Jim

Thank you very much! Both of your solutions work for me.

Steve

From E.Vettorazzi at uke.de  Thu Dec 12 16:27:18 2013
From: E.Vettorazzi at uke.de (Eik Vettorazzi)
Date: Thu, 12 Dec 2013 16:27:18 +0100
Subject: [R] Solving a normal distribution pnorm for q
In-Reply-To: <CABsGe_wNT9UBiL=3NsvfUJdNK6R0ps7XL-UdKs5rFa37DPKJoA@mail.gmail.com>
References: <CABsGe_xr8LnKbFA+M7aRV0nbm8=Ebi=j=h7pmuNR=Dk5iOHUfg@mail.gmail.com>	<33D76D77E9AC4B438DA38B348ED6890D0B90C555@EMAIL.ktkdom.pte.hu>
	<CABsGe_wNT9UBiL=3NsvfUJdNK6R0ps7XL-UdKs5rFa37DPKJoA@mail.gmail.com>
Message-ID: <52A9D5D6.1020302@uke.de>

Assuming r, sd1 and sd2 as known(fixed) components, this works:

X <- pnorm(q=q,sd=sd1)*r+pnorm(q=q,sd=sd2)*(1-r)
uniroot(function(x)pnorm(q=x,sd=sd1)*r+pnorm(q=x,sd=sd2)*(1-r)-X,c(-1e6,1e6))


Cheers

Am 12.12.2013 15:58, schrieb Johannes Radinger:
> Thanks for the fast response. Of course I totally overlooked qnorm as I had
> a more complex task in my head.
> 
> I wanted to reverse following equation:
> r=0.67
> q=-150
> sd1=100
> sd2=1000
> 
> X <- pnorm(q=q,sd=sd1)*r+pnorm(q=q,sd=sd2)*(1-r)
> 
> Maybe its mathematically really easy, but somehow I don't get it how to do
> reverse and provide X and
> get q especially with the presence of r respectively as weighting factors
> for the two distributions.
> 
> /J
> 
> 
> On Thu, Dec 12, 2013 at 3:09 PM, D?niel Kehl <kehld at ktk.pte.hu> wrote:
> 
>> Looks like homework.
>>
>> Try ?qnorm
>> ________________________________________
>> Felad?: r-help-bounces at r-project.org [r-help-bounces at r-project.org] ;
>> meghatalmaz&#243;: Johannes Radinger [johannesradinger at gmail.com]
>> K?ldve: 2013. december 12. 14:56
>> To: R help
>> T?rgy: [R] Solving a normal distribution pnorm for q
>>
>> Hi,
>>
>>
>>
>> I found follwowing example of pnorm here:
>>
>>
>> http://www.r-tutor.com/elementary-statistics/probability-distributions/normal-distribution
>>
>>
>>
>> Problem
>>
>> Assume that the test scores of a college entrance exam fits a normal
>> distribution. Furthermore, the mean test score is 72, and the standard
>> deviation is 15.2. What is the percentage of students scoring 84 or more in
>> the exam?
>>
>>
>>
>> Solution
>>
>>> pnorm(84, mean=72, sd=15.2, lower.tail=FALSE)
>>
>> [1] 0.21492
>>
>>
>>
>> That is straight forward, however what if I want to know the score the best
>> 30% students are reaching at least. So I know the solution of pnorm but
>> want to know its q. How can that be achieved in R?
>>
>>
>>
>> Any suggestions?
>>
>>
>>
>> /Johannes
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi
Institut f?r Medizinische Biometrie und Epidemiologie
Universit?tsklinikum Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790
--

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From Eric.Elguero at ird.fr  Thu Dec 12 16:41:07 2013
From: Eric.Elguero at ird.fr (Eric Elguero)
Date: Thu, 12 Dec 2013 16:41:07 +0100
Subject: [R] censored counts and glmer/glmmADMB
Message-ID: <52A9D913.5070503@ird.fr>

dear R-users,

I have to model counts where all counts above some threshold
have been censored. In the same dataset I have too many zeroes for
a Poisson or even a negative binomial distribution to make
sense, so I would need a zero-inflated-censored negative binomial
family for use in glmer (or glmmADMB?). That seems not to exist.

my question is :
how could I add a custom-built family of distributions that
I could call in glmer/glmmADMM ?

if it's not possible, I am considering imputing fake values
to replace the censored ones, but I am unsure whether this
is bad or very bad...

Eric Elguero
MIVEGEC (UM1- UM2 -CNRS 5290-IRD 224)
Maladies infectieuses et vecteurs :
?cologie, g?n?tique, ?volution et contr?le
Centre IRD de Montpellier
911 Av Agropolis - BP 64501
34394 Montpellier Cedex


From johannesradinger at gmail.com  Thu Dec 12 16:55:54 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Thu, 12 Dec 2013 16:55:54 +0100
Subject: [R] Solving a normal distribution pnorm for q
In-Reply-To: <52A9D5D6.1020302@uke.de>
References: <CABsGe_xr8LnKbFA+M7aRV0nbm8=Ebi=j=h7pmuNR=Dk5iOHUfg@mail.gmail.com>
	<33D76D77E9AC4B438DA38B348ED6890D0B90C555@EMAIL.ktkdom.pte.hu>
	<CABsGe_wNT9UBiL=3NsvfUJdNK6R0ps7XL-UdKs5rFa37DPKJoA@mail.gmail.com>
	<52A9D5D6.1020302@uke.de>
Message-ID: <CABsGe_zdZJ7Nn6HF2mozwjz2PNx-_aaUxXTg_x9zgerrn9pG7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/03ef367d/attachment.pl>

From gunter.berton at gene.com  Thu Dec 12 16:58:05 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 12 Dec 2013 07:58:05 -0800
Subject: [R] censored counts and glmer/glmmADMB
In-Reply-To: <52A9D913.5070503@ird.fr>
References: <52A9D913.5070503@ird.fr>
Message-ID: <CACk-te2CoJN3AN=2EHsVZ1GgLdvtwrrNpwbhYteuf7s5ho01UQ@mail.gmail.com>

This post should go the r-sig-mixed-models list, where you are much
more likely to get useful help than here, which is a general R
programming help list.

Cheers,
Bert

On Thu, Dec 12, 2013 at 7:41 AM, Eric Elguero <Eric.Elguero at ird.fr> wrote:
> dear R-users,
>
> I have to model counts where all counts above some threshold
> have been censored. In the same dataset I have too many zeroes for
> a Poisson or even a negative binomial distribution to make
> sense, so I would need a zero-inflated-censored negative binomial
> family for use in glmer (or glmmADMB?). That seems not to exist.
>
> my question is :
> how could I add a custom-built family of distributions that
> I could call in glmer/glmmADMM ?
>
> if it's not possible, I am considering imputing fake values
> to replace the censored ones, but I am unsure whether this
> is bad or very bad...
>
> Eric Elguero
> MIVEGEC (UM1- UM2 -CNRS 5290-IRD 224)
> Maladies infectieuses et vecteurs :
> ?cologie, g?n?tique, ?volution et contr?le
> Centre IRD de Montpellier
> 911 Av Agropolis - BP 64501
> 34394 Montpellier Cedex
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dcarlson at tamu.edu  Thu Dec 12 17:02:00 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 12 Dec 2013 10:02:00 -0600
Subject: [R] labels on right y-axis
In-Reply-To: <3814E80B-39AE-43A1-8B99-24D71097FBBE@plessthan.com>
References: <3814E80B-39AE-43A1-8B99-24D71097FBBE@plessthan.com>
Message-ID: <02e301cef753$7d830d90$788928b0$@tamu.edu>

I don't see an alternative to text(), but the positioning is not
that difficult:

oldpar <- par(mar=c(5.1, 4.1, 4.1, 4.1))
plot(0)
axis(4)
text(par("usr")[2], mean(par("usr")[3:4]), "TEXT", 
     srt=-90, adj=c(.5,-4), xpd=TRUE)
par(oldpar)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Fisher Dennis
Sent: Thursday, December 12, 2013 8:32 AM
To: r-help at stat.math.ethz.ch
Subject: [R] labels on right y-axis

OS X
R 3.0.2

Colleagues,

I am displaying two sets of values changing over time; as a
result, I have two y-axes.  I add a label for the right-side Y
axis with mtext(side=3, line=1.2, TEXT).  The text is parallel
to the axis -- so far, so good.  However, the text is rotated
counterclockwise from horizontal, whereas I would like it
rotated clockwise.

Neither srt nor las fixes this.  I guess that one convoluted
approach would be to use "text" rather than "mtext".  However,
positioning would be a nuisance and the xpd option would be
needed.  Is there any simpler approach?

Dennis 


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com




	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From murdoch.duncan at gmail.com  Thu Dec 12 17:09:37 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Dec 2013 11:09:37 -0500
Subject: [R] Logistic Regression with 200K features in R?
In-Reply-To: <52A9A73A.9070209@uke.de>
References: <52A96D12.5070408@gmail.com>	<52A99A10.4010805@uke.de>	<52A99F41.50401@gmail.com>	<52A9A32E.4010509@uke.de>
	<52A9A54B.6040203@gmail.com> <52A9A73A.9070209@uke.de>
Message-ID: <52A9DFC1.6030808@gmail.com>

On 12/12/2013 7:08 AM, Eik Vettorazzi wrote:
> thanks Duncan for this clarification.
> A double precision matrix with 2e11 elements (as the op wanted) would
> need about 1.5 TB memory, that's more than a standard (windows 64bit)
> computer can handle.

According to Microsoft's "Memory Limits" web page (currently at 
http://msdn.microsoft.com/en-us/library/windows/desktop/aa366778%28v=vs.85%29.aspx#memory_limits, 
but these things tend to move around), the limit is 8 TB for virtual 
memory.    (The same page lists a variety of smaller physical memory 
limits, depending on the Windows version, but R doesn't need physical 
memory, virtual is good enough. )

R would be very slow if it was working with objects bigger than physical 
memory, but it could conceivably work.

Duncan Murdoch

> Cheers.
>
> Am 12.12.2013 13:00, schrieb Duncan Murdoch:
> > On 13-12-12 6:51 AM, Eik Vettorazzi wrote:
> >> I thought so (with all the limitations due to collinearity and so on),
> >> but actually there is a limit for the maximum size of an array which is
> >> independent of your memory size and is due to the way arrays are
> >> indexed. You can't create an object with more than 2^31-1 = 2147483647
> >> elements.
> >>
> >> https://stat.ethz.ch/pipermail/r-help/2007-June/133238.html
> >
> > That post is from 2007.  The limits were raised considerably when R
> > 3.0.0 was released, and it is now 2^48 for disk-based operations, 2^52
> > for working in memory.
> >
> > Duncan Murdoch
> >
> >
> >>
> >> cheers
> >>
> >> Am 12.12.2013 12:34, schrieb Romeo Kienzler:
> >>> ok, so 200K predictors an 10M observations would work?
> >>>
> >>>
> >>> On 12/12/2013 12:12 PM, Eik Vettorazzi wrote:
> >>>> it is simply because you can't do a regression with more predictors
> >>>> than
> >>>> observations.
> >>>>
> >>>> Cheers.
> >>>>
> >>>> Am 12.12.2013 09:00, schrieb Romeo Kienzler:
> >>>>> Dear List,
> >>>>>
> >>>>> I'm quite new to R and want to do logistic regression with a 200K
> >>>>> feature data set (around 150 training examples).
> >>>>>
> >>>>> I'm aware that I should use Naive Bayes but I have a more general
> >>>>> question about the capability of R handling very high dimensional
> >>>>> data.
> >>>>>
> >>>>> Please consider the following R code where "mygenestrain.tab" is a 150
> >>>>> by 200000 matrix:
> >>>>>
> >>>>> traindata <- read.table('mygenestrain.tab');
> >>>>> mylogit <- glm(V1 ~ ., data = traindata, family = "binomial");
> >>>>>
> >>>>> When executing this code I get the following error:
> >>>>>
> >>>>> Error in terms.formula(formula, data = data) :
> >>>>>     allocMatrix: too many elements specified
> >>>>> Calls: glm ... model.frame -> model.frame.default -> terms ->
> >>>>> terms.formula
> >>>>> Execution halted
> >>>>>
> >>>>> Is this because R can't handle 200K features or am I doing something
> >>>>> completely wrong here?
> >>>>>
> >>>>> Thanks a lot for your help!
> >>>>>
> >>>>> best Regards,
> >>>>>
> >>>>> Romeo
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >
>


From eliza_botto at hotmail.com  Thu Dec 12 17:10:50 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Thu, 12 Dec 2013 16:10:50 +0000
Subject: [R] function inside a function
Message-ID: <BLU170-W38E3848CC1367510AD411289DC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/8bc4376c/attachment.pl>

From gunter.berton at gene.com  Thu Dec 12 17:12:26 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 12 Dec 2013 08:12:26 -0800
Subject: [R] labels on right y-axis
In-Reply-To: <02e301cef753$7d830d90$788928b0$@tamu.edu>
References: <3814E80B-39AE-43A1-8B99-24D71097FBBE@plessthan.com>
	<02e301cef753$7d830d90$788928b0$@tamu.edu>
Message-ID: <CACk-te0eYSh=P6RnAYJHSmPhV44ku9oW530+mdxLZ=dJ=r6H4w@mail.gmail.com>

Might axis() be useful here?

?axis

Cheers,
Bert

On Thu, Dec 12, 2013 at 8:02 AM, David Carlson <dcarlson at tamu.edu> wrote:
> I don't see an alternative to text(), but the positioning is not
> that difficult:
>
> oldpar <- par(mar=c(5.1, 4.1, 4.1, 4.1))
> plot(0)
> axis(4)
> text(par("usr")[2], mean(par("usr")[3:4]), "TEXT",
>      srt=-90, adj=c(.5,-4), xpd=TRUE)
> par(oldpar)
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Fisher Dennis
> Sent: Thursday, December 12, 2013 8:32 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] labels on right y-axis
>
> OS X
> R 3.0.2
>
> Colleagues,
>
> I am displaying two sets of values changing over time; as a
> result, I have two y-axes.  I add a label for the right-side Y
> axis with mtext(side=3, line=1.2, TEXT).  The text is parallel
> to the axis -- so far, so good.  However, the text is rotated
> counterclockwise from horizontal, whereas I would like it
> rotated clockwise.
>
> Neither srt nor las fixes this.  I guess that one convoluted
> approach would be to use "text" rather than "mtext".  However,
> positioning would be a nuisance and the xpd option would be
> needed.  Is there any simpler approach?
>
> Dennis
>
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
> code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From capricyg at yahoo.com  Thu Dec 12 16:45:09 2013
From: capricyg at yahoo.com (capricy gao)
Date: Thu, 12 Dec 2013 07:45:09 -0800 (PST)
Subject: [R] Heatmap,
	and heatmap.2 gave different figures for the same dataset
Message-ID: <1386863109.99336.YahooMailNeo@web125002.mail.ne1.yahoo.com>

I have a huge dataset(15k X 18) and tried to use the heatmap in R to examine the patterns. However, I found that heatmap and heatmap.2 gave me completely different outputs.

Here are the codes:

------------

> dim(as.matrix(data.dcpm))
[1] 15462??? 18
> 
> heatmap(as.matrix(data.dcpm), col=topo.colors(100))
> heatmap.2(as.matrix(data.dcpm), col=topo.colors(100), key=TRUE, density.inf="none",trace="none", scale="none")
-------

The outputs are attached here.

Could anyone help me figure out why?

Thanks a lot:)

From dc347 at cam.ac.uk  Thu Dec 12 13:12:17 2013
From: dc347 at cam.ac.uk (dc347)
Date: Thu, 12 Dec 2013 04:12:17 -0800 (PST)
Subject: [R] Wilcoxon test output as a table
In-Reply-To: <AANLkTilgv2lmH-1JJE6_jrorvO_QMuiedt7nWDWuxt30@mail.gmail.com>
References: <AANLkTilgv2lmH-1JJE6_jrorvO_QMuiedt7nWDWuxt30@mail.gmail.com>
Message-ID: <1386850337693-4682058.post@n4.nabble.com>

Hello there

Was looking up a similar problem yesterday and came across the gMWT package
(Generalized Mann-Whitney Type Tests). It addresses your problem, although I
am still trying to figure out how it works.

Kind regards,

David



--
View this message in context: http://r.789695.n4.nabble.com/Wilcoxon-test-output-as-a-table-tp2244565p4682058.html
Sent from the R help mailing list archive at Nabble.com.


From romeo.kienzler at gmail.com  Thu Dec 12 12:34:25 2013
From: romeo.kienzler at gmail.com (Romeo Kienzler)
Date: Thu, 12 Dec 2013 12:34:25 +0100
Subject: [R] Logistic Regression with 200K features in R?
In-Reply-To: <52A99A10.4010805@uke.de>
References: <52A96D12.5070408@gmail.com> <52A99A10.4010805@uke.de>
Message-ID: <52A99F41.50401@gmail.com>

ok, so 200K predictors an 10M observations would work?


On 12/12/2013 12:12 PM, Eik Vettorazzi wrote:
> it is simply because you can't do a regression with more predictors than
> observations.
>
> Cheers.
>
> Am 12.12.2013 09:00, schrieb Romeo Kienzler:
>> Dear List,
>>
>> I'm quite new to R and want to do logistic regression with a 200K
>> feature data set (around 150 training examples).
>>
>> I'm aware that I should use Naive Bayes but I have a more general
>> question about the capability of R handling very high dimensional data.
>>
>> Please consider the following R code where "mygenestrain.tab" is a 150
>> by 200000 matrix:
>>
>> traindata <- read.table('mygenestrain.tab');
>> mylogit <- glm(V1 ~ ., data = traindata, family = "binomial");
>>
>> When executing this code I get the following error:
>>
>> Error in terms.formula(formula, data = data) :
>>    allocMatrix: too many elements specified
>> Calls: glm ... model.frame -> model.frame.default -> terms -> terms.formula
>> Execution halted
>>
>> Is this because R can't handle 200K features or am I doing something
>> completely wrong here?
>>
>> Thanks a lot for your help!
>>
>> best Regards,
>>
>> Romeo
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From romeo.kienzler at gmail.com  Thu Dec 12 12:55:03 2013
From: romeo.kienzler at gmail.com (Romeo Kienzler)
Date: Thu, 12 Dec 2013 12:55:03 +0100
Subject: [R] Logistic Regression with 200K features in R?
In-Reply-To: <52A9A32E.4010509@uke.de>
References: <52A96D12.5070408@gmail.com> <52A99A10.4010805@uke.de>
	<52A99F41.50401@gmail.com> <52A9A32E.4010509@uke.de>
Message-ID: <52A9A417.5050405@gmail.com>

Dear Eik,

thank you so much for your help!

best Regards,

Romeo

On 12/12/2013 12:51 PM, Eik Vettorazzi wrote:
> I thought so (with all the limitations due to collinearity and so on),
> but actually there is a limit for the maximum size of an array which is
> independent of your memory size and is due to the way arrays are
> indexed. You can't create an object with more than 2^31-1 = 2147483647
> elements.
>
> https://stat.ethz.ch/pipermail/r-help/2007-June/133238.html
>
> cheers
>
> Am 12.12.2013 12:34, schrieb Romeo Kienzler:
>> ok, so 200K predictors an 10M observations would work?
>>
>>
>> On 12/12/2013 12:12 PM, Eik Vettorazzi wrote:
>>> it is simply because you can't do a regression with more predictors than
>>> observations.
>>>
>>> Cheers.
>>>
>>> Am 12.12.2013 09:00, schrieb Romeo Kienzler:
>>>> Dear List,
>>>>
>>>> I'm quite new to R and want to do logistic regression with a 200K
>>>> feature data set (around 150 training examples).
>>>>
>>>> I'm aware that I should use Naive Bayes but I have a more general
>>>> question about the capability of R handling very high dimensional data.
>>>>
>>>> Please consider the following R code where "mygenestrain.tab" is a 150
>>>> by 200000 matrix:
>>>>
>>>> traindata <- read.table('mygenestrain.tab');
>>>> mylogit <- glm(V1 ~ ., data = traindata, family = "binomial");
>>>>
>>>> When executing this code I get the following error:
>>>>
>>>> Error in terms.formula(formula, data = data) :
>>>>     allocMatrix: too many elements specified
>>>> Calls: glm ... model.frame -> model.frame.default -> terms ->
>>>> terms.formula
>>>> Execution halted
>>>>
>>>> Is this because R can't handle 200K features or am I doing something
>>>> completely wrong here?
>>>>
>>>> Thanks a lot for your help!
>>>>
>>>> best Regards,
>>>>
>>>> Romeo
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From ykhedikar at gmail.com  Thu Dec 12 19:00:38 2013
From: ykhedikar at gmail.com (Yogendra)
Date: Thu, 12 Dec 2013 10:00:38 -0800 (PST)
Subject: [R] boxcox transformations
Message-ID: <CAC2v03njh=GBxr7W+3D88pb3kfYjXupq0DWELSGnY=+a7p-wzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/657a5c01/attachment.pl>

From bhh at xs4all.nl  Thu Dec 12 19:35:58 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 12 Dec 2013 19:35:58 +0100
Subject: [R] function inside a function
In-Reply-To: <BLU170-W38E3848CC1367510AD411289DC0@phx.gbl>
References: <BLU170-W38E3848CC1367510AD411289DC0@phx.gbl>
Message-ID: <EAF723A3-9091-4065-91FF-4959D38ED2ED@xs4all.nl>


On 12-12-2013, at 17:10, eliza botto <eliza_botto at hotmail.com> wrote:

> Dear users of R,
> I am trying to inculcate a function inside a function. For that to be done, i copied following function from internet. 
> 
> library(nleqslv) fun <- function(x) { 
>     f <- numeric(length(x)) 
>     f[1] <-  A[,1]+x[2] - 1/x[1] 
>     f[2] <-  A[,2]+x[2] - sin(x[1]) 
>     f 
> } 
> x.start <- c(1,1) 
> nleqslv(x.start,fun) 
> I have a matrix "A" with dimension 124 rows and 2 columns. In f[1] line, in place of A[,1] i want to inculcate each value (each row) of 
> column 1 of matrix A. while doing it, In f[2] line, in place of A[,2] i want to inculcate each value (each row) of column 2 of matrix A.  
> For suppose A has following rows
> 0.6772941                              0.5962983
> 0.4348938                              0.4563702
> 0.4481236                              0.4418828
> 0.4213013                              0.3944993
> 0.4682232                              0.4485623
> 0.4798529                              0.4477387
> 0.7029005                              0.5533228
> While using 0.66772941 in f[1], use 0.5962983 in f[2]. 
> How can i do this in R.
> Thanks in advance,


It is not clear what you actually want. 
Maybe something like this

library(nleqslv)

A <- matrix(c(0.6772941,  0.5962983,
              0.4348938,  0.4563702,
              0.4481236,  0.4418828,
              0.4213013,  0.3944993,
              0.4682232,  0.4485623,
              0.4798529,  0.4477387,
              0.7029005,  0.5533228), byrow=TRUE,ncol=2)

fun <- function(x, krow) {
    f <- numeric(length(x))
    f[1] <- A[krow,1] + x[2]- 1/x[1]
    f[2] <- A[krow,2] +x[2] - sin(x[1])
    f
}

x.start <- c(1,1)
nleqslv(x.start, fun, krow=1)
nleqslv(x.start, fun, krow=2)


> Eliza 		 	   		  
> 	[[alternative HTML version deleted]]
> 

Please do not post in HTML. You should know by now.

Berend

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From eliza_botto at hotmail.com  Thu Dec 12 19:52:40 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Thu, 12 Dec 2013 18:52:40 +0000
Subject: [R] function inside a function
In-Reply-To: <EAF723A3-9091-4065-91FF-4959D38ED2ED@xs4all.nl>
References: <BLU170-W38E3848CC1367510AD411289DC0@phx.gbl>,
	<EAF723A3-9091-4065-91FF-4959D38ED2ED@xs4all.nl>
Message-ID: <BLU170-W387B8E9E7BD5FB01EA618789DC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/b5b9de17/attachment.pl>

From kehld at ktk.pte.hu  Thu Dec 12 19:56:43 2013
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?D=E1niel_Kehl?=)
Date: Thu, 12 Dec 2013 18:56:43 +0000
Subject: [R] boxcox transformations
In-Reply-To: <CAC2v03njh=GBxr7W+3D88pb3kfYjXupq0DWELSGnY=+a7p-wzQ@mail.gmail.com>
References: <CAC2v03njh=GBxr7W+3D88pb3kfYjXupq0DWELSGnY=+a7p-wzQ@mail.gmail.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B90C62D@EMAIL.ktkdom.pte.hu>

Dear Yogi,

try the powerTransform function in the car package and boxcox function in the MASS package.
there are nice examples for both functions.

HTH,
daniel
________________________________________
Felad?: r-help-bounces at r-project.org [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Yogendra [ykhedikar at gmail.com]
K?ldve: 2013. december 12. 19:00
To: r-help at r-project.org
T?rgy: [R] boxcox transformations

Hi,
I am new to R.
I need help with regards to box cox transformation.
I have phenotypic data for e.g. plant height.
data is non-normal. Skewness is 0.34.

Could you please help me?

Regards,
Yogi




--
View this message in context: http://r.789695.n4.nabble.com/boxcox-transformations-tp4682077.html
Sent from the R help mailing list archive at Nabble.com.
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kw.stat at gmail.com  Thu Dec 12 21:08:00 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 12 Dec 2013 14:08:00 -0600
Subject: [R] Heatmap,
	and heatmap.2 gave different figures for the same dataset
In-Reply-To: <1386863109.99336.YahooMailNeo@web125002.mail.ne1.yahoo.com>
References: <1386863109.99336.YahooMailNeo@web125002.mail.ne1.yahoo.com>
Message-ID: <CAKFxdiREvPWq3n3AhTAbz6yz8Rgpd8h-JRAxnwEa5bdYJvvbfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/48573946/attachment.pl>

From jim at bitwrit.com.au  Thu Dec 12 21:31:44 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 13 Dec 2013 07:31:44 +1100
Subject: [R] labels on right y-axis
In-Reply-To: <3814E80B-39AE-43A1-8B99-24D71097FBBE@plessthan.com>
References: <3814E80B-39AE-43A1-8B99-24D71097FBBE@plessthan.com>
Message-ID: <52AA1D30.1050206@bitwrit.com.au>

On 12/13/2013 01:32 AM, Fisher Dennis wrote:
> OS X
> R 3.0.2
>
> Colleagues,
>
> I am displaying two sets of values changing over time; as a result, I have two y-axes.  I add a label for the right-side Y axis with mtext(side=3, line=1.2, TEXT).  The text is parallel to the axis -- so far, so good.  However, the text is rotated counterclockwise from horizontal, whereas I would like it rotated clockwise.
>
> Neither srt nor las fixes this.  I guess that one convoluted approach would be to use "text" rather than "mtext".  However, positioning would be a nuisance and the xpd option would be needed.  Is there any simpler approach?
>
> Dennis
>
Hi Dennis,
This sounds like a job for twoord.plot (plotrix). I think I can leave 
the warnings, disclaimers and miscellaneous dissuasion to others.

Jim


From eliza_botto at hotmail.com  Fri Dec 13 00:02:17 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Thu, 12 Dec 2013 23:02:17 +0000
Subject: [R] function inside a function
In-Reply-To: <1386880578.95248.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <BLU170-W38E3848CC1367510AD411289DC0@phx.gbl>,
	<EAF723A3-9091-4065-91FF-4959D38ED2ED@xs4all.nl>
	<BLU170-W387B8E9E7BD5FB01EA618789DC0@phx.gbl>,
	<1386874907.57896.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<BLU170-W3389CD174B5067DB74BFD489DC0@phx.gbl>,
	<1386880578.95248.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <BLU170-W4116F9582070EEFB884DD689DC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/d3512fee/attachment.pl>

From capricyg at yahoo.com  Fri Dec 13 00:09:19 2013
From: capricyg at yahoo.com (capricy gao)
Date: Thu, 12 Dec 2013 15:09:19 -0800 (PST)
Subject: [R] method default for hclust function
Message-ID: <1386889759.97673.YahooMailNeo@web125002.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/362e49ff/attachment.pl>

From eliza_botto at hotmail.com  Fri Dec 13 00:15:08 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Thu, 12 Dec 2013 23:15:08 +0000
Subject: [R] method default for hclust function
In-Reply-To: <1386889759.97673.YahooMailNeo@web125002.mail.ne1.yahoo.com>
References: <1386889759.97673.YahooMailNeo@web125002.mail.ne1.yahoo.com>
Message-ID: <BLU170-W950335A4C017BDEEE73F6E89DC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/e7dfde3f/attachment.pl>

From peter.langfelder at gmail.com  Fri Dec 13 00:56:02 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Thu, 12 Dec 2013 15:56:02 -0800
Subject: [R] method default for hclust function
In-Reply-To: <1386889759.97673.YahooMailNeo@web125002.mail.ne1.yahoo.com>
References: <1386889759.97673.YahooMailNeo@web125002.mail.ne1.yahoo.com>
Message-ID: <CA+hbrhXg7sazRM8LHq=o7i=cu6AQGdPjqQGrO4mXpod_3Oc5xw@mail.gmail.com>

On Thu, Dec 12, 2013 at 3:09 PM, capricy gao <capricyg at yahoo.com> wrote:
> I could not figure out what was the default when I ran hclust() without specifying the method.

According to help("hclust"), the default method is complete linkage.

HTH,

Peter


From capricyg at yahoo.com  Fri Dec 13 00:03:13 2013
From: capricyg at yahoo.com (capricy gao)
Date: Thu, 12 Dec 2013 15:03:13 -0800 (PST)
Subject: [R] Heatmap,
	and heatmap.2 gave different figures for the same dataset
In-Reply-To: <CAKFxdiREvPWq3n3AhTAbz6yz8Rgpd8h-JRAxnwEa5bdYJvvbfg@mail.gmail.com>
References: <1386863109.99336.YahooMailNeo@web125002.mail.ne1.yahoo.com>
	<CAKFxdiREvPWq3n3AhTAbz6yz8Rgpd8h-JRAxnwEa5bdYJvvbfg@mail.gmail.com>
Message-ID: <1386889393.79032.YahooMailNeo@web125001.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/578b5e33/attachment.pl>

From smartpink111 at yahoo.com  Thu Dec 12 20:01:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 12 Dec 2013 11:01:47 -0800 (PST)
Subject: [R] function inside a function
In-Reply-To: <BLU170-W387B8E9E7BD5FB01EA618789DC0@phx.gbl>
References: <BLU170-W38E3848CC1367510AD411289DC0@phx.gbl>,
	<EAF723A3-9091-4065-91FF-4959D38ED2ED@xs4all.nl>
	<BLU170-W387B8E9E7BD5FB01EA618789DC0@phx.gbl>
Message-ID: <1386874907.57896.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this helps:
t(sapply(seq_len(nrow(A)),function(i) nleqslv(x.start,fun,krow=i)$x))


A.K.


On Thursday, December 12, 2013 1:54 PM, eliza botto <eliza_botto at hotmail.com> wrote:
Dear Berend,Thankyou very much for your reply. I actually wanted to inserts each row value of A in f[1] anf f[2], with column 1 value in f[1] and column 2 values in f[2]. Once that been done, i should have in the end, 124 vaues of x[1] for column 1 and 124 for column 2.I hope i am clear this time.Thanks for your help.Eliza

> Subject: Re: [R] function inside a function
> From: bhh at xs4all.nl
> Date: Thu, 12 Dec 2013 19:35:58 +0100
> CC: r-help at r-project.org
> To: eliza_botto at hotmail.com
> 
> 
> On 12-12-2013, at 17:10, eliza botto <eliza_botto at hotmail.com> wrote:
> 
> > Dear users of R,
> > I am trying to inculcate a function inside a function. For that to be done, i copied following function from internet. 
> > 
> > library(nleqslv) fun <- function(x) { 
> >? ?  f <- numeric(length(x)) 
> >? ?  f[1] <-? A[,1]+x[2] - 1/x[1] 
> >? ?  f[2] <-? A[,2]+x[2] - sin(x[1]) 
> >? ?  f 
> > } 
> > x.start <- c(1,1) 
> > nleqslv(x.start,fun) 
> > I have a matrix "A" with dimension 124 rows and 2 columns. In f[1] line, in place of A[,1] i want to inculcate each value (each row) of 
> > column 1 of matrix A. while doing it, In f[2] line, in place of A[,2] i want to inculcate each value (each row) of column 2 of matrix A.? 
> > For suppose A has following rows
> > 0.6772941? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.5962983
> > 0.4348938? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.4563702
> > 0.4481236? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.4418828
> > 0.4213013? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.3944993
> > 0.4682232? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.4485623
> > 0.4798529? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.4477387
> > 0.7029005? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.5533228
> > While using 0.66772941 in f[1], use 0.5962983 in f[2]. 
> > How can i do this in R.
> > Thanks in advance,
> 
> 
> It is not clear what you actually want. 
> Maybe something like this
> 
> library(nleqslv)
> 
> A <- matrix(c(0.6772941,? 0.5962983,
>? ? ? ? ? ? ?  0.4348938,? 0.4563702,
>? ? ? ? ? ? ?  0.4481236,? 0.4418828,
>? ? ? ? ? ? ?  0.4213013,? 0.3944993,
>? ? ? ? ? ? ?  0.4682232,? 0.4485623,
>? ? ? ? ? ? ?  0.4798529,? 0.4477387,
>? ? ? ? ? ? ?  0.7029005,? 0.5533228), byrow=TRUE,ncol=2)
> 
> fun <- function(x, krow) {
>? ?  f <- numeric(length(x))
>? ?  f[1] <- A[krow,1] + x[2]- 1/x[1]
>? ?  f[2] <- A[krow,2] +x[2] - sin(x[1])
>? ?  f
> }
> 
> x.start <- c(1,1)
> nleqslv(x.start, fun, krow=1)
> nleqslv(x.start, fun, krow=2)
> 
> 
> > Eliza ??? ???  ??? ?  ??? ??? ? 
> > ??? [[alternative HTML version deleted]]
> > 
> 
> Please do not post in HTML. You should know by now.
> 
> Berend
> 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jared.f.duquette at gmail.com  Fri Dec 13 01:53:27 2013
From: jared.f.duquette at gmail.com (Jared Duquette)
Date: Thu, 12 Dec 2013 18:53:27 -0600
Subject: [R] Coxme time-dependent covariate
Message-ID: <CAH18Qe3eVPxcOAOagTyGZkTWoXejGC18eGnZkwkw4qngoUWJtA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131212/c67fe084/attachment.pl>

From 1248283536 at qq.com  Fri Dec 13 08:03:59 2013
From: 1248283536 at qq.com (=?utf-8?B?5rC06Z2Z5rWB5rex?=)
Date: Fri, 13 Dec 2013 15:03:59 +0800
Subject: [R] =?utf-8?q?charToRaw=28=22=C5=92=22=29_is_not_8C_in_R_console?=
Message-ID: <tencent_2760AA6767F679DD32E1FC82@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/5b1b565f/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Dec 13 08:59:09 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 13 Dec 2013 07:59:09 +0000
Subject: [R]
 =?utf-8?q?charToRaw=28=22=C5=92=22=29_is_not_8C_in_R_console?=
In-Reply-To: <tencent_2760AA6767F679DD32E1FC82@qq.com>
References: <tencent_2760AA6767F679DD32E1FC82@qq.com>
Message-ID: <52AABE4D.5010500@stats.ox.ac.uk>

On 13/12/2013 07:03, ???? wrote:
> in http://www.ascii-code.com/, you can see the the hex value of ?? is 8C,

I don't see that: that is two characters and they are C5 and 92 in that 
table.  8C is a AE ligature, there.

And what the 'hex value' is depends on the locale: see the preamble of 
that table (which seems to assume everyone uses CP1252): you have not 
stated yours.

> why in my R console ?
> charToRaw("??")
>   [1] c5 92
>   is not 8C ?

Because R is better at looking up hex values than you are.

I get

 > charToRaw("??")
[1] c3 85 e2 80 99

in UTF-8 (as will almost everyone not using Windows).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Dec 13 09:08:40 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 13 Dec 2013 08:08:40 +0000
Subject: [R]
 =?utf-8?q?charToRaw=28=22=C5=92=22=29_is_not_8C_in_R_console?=
In-Reply-To: <52AABE4D.5010500@stats.ox.ac.uk>
References: <tencent_2760AA6767F679DD32E1FC82@qq.com>
	<52AABE4D.5010500@stats.ox.ac.uk>
Message-ID: <52AAC088.6070306@stats.ox.ac.uk>

On 13/12/2013 07:59, Prof Brian Ripley wrote:
> On 13/12/2013 07:03, ???? wrote:
>> in http://www.ascii-code.com/, you can see the the hex value of ?? is 8C,
>
> I don't see that: that is two characters and they are C5 and 92 in that
> table.  8C is a AE ligature, there.

Typo: OE as in your subject line.

>
> And what the 'hex value' is depends on the locale: see the preamble of
> that table (which seems to assume everyone uses CP1252): you have not
> stated yours.
>
>> why in my R console ?
>> charToRaw("??")
>>   [1] c5 92
>>   is not 8C ?
>
> Because R is better at looking up hex values than you are.
>
> I get
>
>  > charToRaw("??")
> [1] c3 85 e2 80 99
>
> in UTF-8 (as will almost everyone not using Windows).
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Fri Dec 13 10:07:56 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 13 Dec 2013 10:07:56 +0100
Subject: [R]
 =?utf-8?q?charToRaw=28=22=C5=92=22=29_is_not_8C_in_R_console?=
In-Reply-To: <tencent_2760AA6767F679DD32E1FC82@qq.com>
References: <tencent_2760AA6767F679DD32E1FC82@qq.com>
Message-ID: <18FD4F4C-9752-4723-AAEF-BD6143DEBCD8@gmail.com>


On 13 Dec 2013, at 08:03 , ???? <1248283536 at qq.com> wrote:

> in http://www.ascii-code.com/, you can see the the hex value of ? is 8C,
> 

(Looks like Brian got his version mangled in transmission.)

Anything above 7F is not ASCII.

Various "8-bit extensions" put various non-ASCII characters at various places in the range 80-FF. Your reference shows the Latin-1 encoding which covers the Western European languages. That was useful for a while [*], until the West and the East began talking to eachother and found that the other party's documents were putting different characters in the same places of different encodings.

UTF-8 uses multibyte sequences like c5 92 to represent extra characters, which allows you to have more than 128 of them.

http://www.utf8-chartable.de/unicode-utf8-table.pl?start=256
http://www.joelonsoftware.com/articles/Unicode.html

-pd

[*] A short while, actually, because it was preceded by another encoding mess known as IBM Code Pages. Famously, in this country, IBM computers (and many 3rd party printers!) shipped with a code page missing the O-slash Danish character which got printed as "cent"/"Yen"!


> 
> 
> 
> 
> 
> why in my R console ?
> charToRaw("?")
> [1] c5 92
> is not 8C ?
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From 1248283536 at qq.com  Fri Dec 13 12:08:59 2013
From: 1248283536 at qq.com (=?utf-8?B?5rC06Z2Z5rWB5rex?=)
Date: Fri, 13 Dec 2013 19:08:59 +0800
Subject: [R] how to use the readBin ?
Message-ID: <tencent_19B88BF0542F44FF0B7CD432@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/9c6fd218/attachment.pl>

From 1248283536 at qq.com  Fri Dec 13 12:16:10 2013
From: 1248283536 at qq.com (=?gb18030?B?y66+ssH3ye4=?=)
Date: Fri, 13 Dec 2013 19:16:10 +0800
Subject: [R] how can i write the function into a file c:/mytest.R with cat
	function?
Message-ID: <tencent_3A82DB05585DDBD410796665@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/9a6dd53b/attachment.pl>

From k.barton at abdn.ac.uk  Fri Dec 13 13:56:09 2013
From: k.barton at abdn.ac.uk (=?UTF-8?B?S2FtaWwgQmFydG/FhA==?=)
Date: Fri, 13 Dec 2013 12:56:09 +0000
Subject: [R] Get average model after dredge function ran in a loop
In-Reply-To: <mailman.19.1386759607.32678.r-help@r-project.org>
References: <mailman.19.1386759607.32678.r-help@r-project.org>
Message-ID: <52AB03E9.1000200@abdn.ac.uk>

You are trying to average coefficients from models fitted to different
data (as you have manipulated Lat+Long values), you cannot do it using
AIC weights.

kamil



On 2013-12-11 11:00, r-help-request at r-project.org wrote:
> Message: 26
> Date: Tue, 10 Dec 2013 15:44:28 -0500
> From: Catarina Ferreira<catferreira at gmail.com>
> To: r-help<r-help at r-project.org>
> Subject: [R] Get average model after dredge function ran in a loop
> Message-ID:
>       <CAAiga1sKpKS9aQHYs+RNrBWJxmxhRf3qn6DgaEN1P8QSt-293w at mail.gmail.com>
> Content-Type: text/plain
>
> Dear all
>
> I'm a beginner in R and I'm trying to get the final model after I run the
> dredge function for 10 times (with a loop):
>
> ###Building the Model
> Coy.glm0<-glm(pa ~  shrub + snowdep + tree + bio5 + bio6 + bio12 +
> log(human+1), data=Coy.pa, family=binomial)
> summary(Coy.glm0)
>
> install.packages('MuMIn')
> library(MuMIn)
> Coy.dredge<-dredge(Coy.glm0)
> head(Coy.dredge) ######################Look in which colum is AIC
> ###Building a simulation
> Coy.models<-Coy.dredge[1,c(1:13)]
> Coy.models
>
>
> ###Turn a loop who will create 10 models
> run=1
> while(run<11) #<11 means 10 models.
> {
>    Coy.abs$Long<-runif(300,498,2579440)
>    Coy.abs$Lat<-runif(300,-51483,1377669)
>    Coy.pa<-rbind(Coy.train, Coy.abs)    ####???? train ou prSS
>    Coy.ppp<-ppp(Coy.pa$Long,Coy.pa$Lat, window=win, unitname="meters")
>    Coy.pa$snowdep<-snowdepz.im[Coy.ppp, drop=F]
>    Coy.pa$tree<-treez.im[Coy.ppp, drop=F]
>    Coy.pa$bio5<-bio5z.im[Coy.ppp, drop=F]
>    Coy.pa$bio6<-bio6z.im[Coy.ppp, drop=F]
>    Coy.pa$bio12<-bio12z.im[Coy.ppp, drop=F]
>    Coy.pa$human<-humanz.im[Coy.ppp, drop=F]
>    Coy.pa$shrub<-shrub.im[Coy.ppp, drop=F]
>
>    Coy.glm0<-glm(pa ~ shrub + snowdep + tree + bio5 +  bio6 + bio12+
> log(human+1), data=Coy.pa, family=binomial)
>    Coy.dredge<-dredge(Coy.glm0)
>    Coy.models<-rbind(Coy.models, Coy.dredge[1,c(1:13)])
>    run=run+1
> }
>
> I do get a best model for each run which I then hand pick and add to a
> table. The problem is that I have 11 models now in this table and I want
> their average to get the final model. I don't know how to do it from the
> table (as the model.avg() will tell me I only have one model in the table,
> because it's not recognizing the different rows as different models), but
> on the other hand there must be a way to do it directly in the loop, only
> I'm not sure at what point of the script I should be asking for it and how
> the code should be written.
>
> I would very much appreciate any help you can give me.
>
> Thank you.
>
> Cat





The University of Aberdeen is a charity registered in Scotland, No SC013683.


From therneau at mayo.edu  Fri Dec 13 14:01:20 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 13 Dec 2013 07:01:20 -0600
Subject: [R] freetype 2.5.2, problem with the survival package,
 build R 2.15.x with gcc 4.8.x
In-Reply-To: <52A92DD7.2050905@users.sourceforge.net>
References: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>
	<5225B120.8050406@users.sourceforge.net>
	<52948B3C.8020801@users.sourceforge.net>
	<52A92DD7.2050905@users.sourceforge.net>
Message-ID: <52AB0520.9000304@mayo.edu>

I was sent a copy of the data, and this is what I get on a different machine:
> fit <- clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set),
          data=pscc)
Warning messages:
1: In fitter(X, Y, strats, offset, init, control, weights = weights,  :
   Loglik converged before variable  1,2,3,4 ; beta may be infinite.
2: In coxph(formula = Surv(rep(1, 13110L), cc) ~ addContr(A) + addContr(C) +  :
   X matrix deemed to be singular; variable 5

> fit
                      coef exp(coef) se(coef)         z  p
addContr(A)2     -0.14250     0.867   110812 -1.29e-06  1
addContr(C)2      0.00525     1.005   110812  4.74e-08  1
addContr(A.C)1-2 -0.30097     0.740   110812 -2.72e-06  1
addContr(A.C)2-1 -0.47712     0.621   110812 -4.31e-06  1
addContr(A.C)2-2       NA        NA        0        NA NA

> xmat <- model.matrix(fit)
> svd(xmat)$d
[1] 1.932097e+02 2.700101e+01 1.624731e+01 6.049630e-15 2.031334e-15

The primary issue is that the covariates matrix is singular, having rank 3 instead of rank 5.
The coxph routine prints two warning messages that things are not good about the matrix. 
Warning messages should not be ignored!  The insane se(coef) values in the printed result 
are an even bigger clue that the model fit is suspect. Unfortunately, some small change in 
the iteration path or numerics has put this data set over the edge from being seen as rank 
3 (old run) to rank 4 (new run).  Moral: coxph does pretty well at detecting redundat 
variables, but if you know of some it never hurts to help the routine out by removing them 
before the fit.

Singularity of the X matrix in a Cox model is very difficult to detect reliably; the 
current threshold is the result of long experience and experiment to give as few false 
messages as possible.  (The RMS package in particular used truncated power basis functions 
for the splines, which lead to X matrices that look almost singular numerically, but are 
not.)  Setting a little less stringent threshold for declaring singularity in the cholesky 
decompostion sufficies for this data set.

fit2 <- clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set),
          data=pscc, toler.chol=1e-10)

I'll certainly add this to my list of test problems that I use to tune those constants.

Terry Therneau

On 12/11/2013 09:30 PM, Hin-Tak Leung wrote:
> Here is a rather long discussion etc about freetype 2.5.2, problem with the survival
> package, and build R 2.15.x with gcc 4.8.x. Please feel free to skip forward.
>
> - freetype 2.5.2:
>
> the fix to cope with one of the Mac OS X's system fonts just before the release of
> freetype 2.5.1 caused a regression, crashing over one of Microsoft windows' system fonts.
> So there is a 2.5.2. There are new 2.5.2 bundles for windows & Mac OS X. The official
> win/mac binaries of R were built statically with 2+-years-old freetype with a few known
> problems. Most should upgrade/rebuild.
>
> http://sourceforge.net/projects/outmodedbonsai/files/R/
>
> - problem with the survival package:
>
> Trying to re-run a vignette to get the same result as two years ago
> reveal a strange change. I went and bisected it down to
> r11513 and r11516 of the survival package.
>
> -------------- r11513 --------------------
> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
>
>
>                     coef exp(coef) se(coef)     z      p
> addContr(A)2     -0.620     0.538    0.217 -2.86 0.0043
> addContr(C)2      0.482     1.620    0.217  2.22 0.0270
> addContr(A.C)1-2 -0.778     0.459    0.275 -2.83 0.0047
> addContr(A.C)2-1     NA        NA    0.000    NA     NA
> addContr(A.C)2-2     NA        NA    0.000    NA     NA
>
> Likelihood ratio test=26  on 3 df, p=9.49e-06  n= 13110, number of events= 3524
> ------------------------------------------
>
> ------------- r11516 ---------------------
> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
>
>
>                       coef exp(coef) se(coef)         z  p
> addContr(A)2     -0.14250     0.867   110812 -1.29e-06  1
> addContr(C)2      0.00525     1.005   110812  4.74e-08  1
> addContr(A.C)1-2 -0.30097     0.740   110812 -2.72e-06  1
> addContr(A.C)2-1 -0.47712     0.621   110812 -4.31e-06  1
> addContr(A.C)2-2       NA        NA        0        NA NA
>
> Likelihood ratio test=26  on 4 df, p=3.15e-05  n= 13110, number of events= 3524
> ------------------------------------------
>


From matthias.weber at fnt.de  Fri Dec 13 13:59:42 2013
From: matthias.weber at fnt.de (Mat)
Date: Fri, 13 Dec 2013 04:59:42 -0800 (PST)
Subject: [R] filter a data.frame
Message-ID: <1386939582235-4682118.post@n4.nabble.com>

hello together, i want to filter a data.frame. My problem is, that i want to
filter 2 numbers.

My data.frame look like this one.

No.   text
1      abc
2      def
3      ee
4      ff
5      gg

I want now to filter No. 2 and 3, so my solution should be look like this
one.

No.   text
2     def
3     ee

i tried it like this one:
out1<-out[(out$No==no.ind),]

in no.ind i have the 2 numbers: c("2","3")

but this doesn't work.

Maybe anyone can help me.

Thank you.

Mat



--
View this message in context: http://r.789695.n4.nabble.com/filter-a-data-frame-tp4682118.html
Sent from the R help mailing list archive at Nabble.com.


From therneau at mayo.edu  Fri Dec 13 14:09:08 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 13 Dec 2013 07:09:08 -0600
Subject: [R] Coxme time dependent
In-Reply-To: <mailman.23.1386932407.8862.r-help@r-project.org>
References: <mailman.23.1386932407.8862.r-help@r-project.org>
Message-ID: <52AB06F4.9080204@mayo.edu>



On 12/13/2013 05:00 AM, r-help-request at r-project.org wrote:
> i all,
>
>
>
> I am using the coxme function to fit random effects survival models.  The
> base survival models show a typical "J" shaped curve where survival drops
> sharply then plateaus over time interval.  I want to include a time
> covariate which could account for this non-linear decrease in survival over
> time.  However, I have not found a clear way to do this in the coxme
> models.  Any suggestions would be greatly appreciated.  Below is some
> sample code and data.
>
>
>
> -Jared
>

I don't understand what you need.  One of the advantages of the Cox model is that the 
baseline hazard function automatically accommodates such features, for both coxph and coxme.

Terry Therneau

PS: I can't make out the pattern of your sample data.  Perhaps you were depending on the 
html formatting?  R-help uses simple text only.


From sarah.goslee at gmail.com  Fri Dec 13 15:36:27 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 13 Dec 2013 09:36:27 -0500
Subject: [R] filter a data.frame
In-Reply-To: <1386939582235-4682118.post@n4.nabble.com>
References: <1386939582235-4682118.post@n4.nabble.com>
Message-ID: <CAM_vjun-pjwj5Ra4vnyMHM7VgGmFOMUZfERchRown3iTU+GP1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/37909f51/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Fri Dec 13 15:16:30 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Fri, 13 Dec 2013 15:16:30 +0100 (MET)
Subject: [R] how can i write the function into a file c:/mytest.R
	withcatfunction?
In-Reply-To: <tencent_3A82DB05585DDBD410796665@qq.com>
References: <tencent_3A82DB05585DDBD410796665@qq.com>
Message-ID: <Pine.SOC.4.64.1312131507090.1492@solcom.hrz.uni-giessen.de>

Hello, ????????!

> mytest<-function(x,f){
>        sum(x*f)/sum(f)
>        }
>    cat(mytest,file="c:/mytest.R")
>    Error in cat(list(...), file, sep, fill, labels, append) :
>    argument 1 (type 'closure') cannot be handled by 'cat'
>
> how can i write the mytest function into a file c:/mytest.R with cat function?

Maybe by replacing cat(), e.g., by the use of sink():

sink( "c:/mytest.R")
mytest
sink()


You may want to look at ?dput and ?dget.


However, I doubt that that produces what you really want because only the 
body of your function mytest() will be stored in the file, but not the 
assignment that created it. Maybe you should store your R-code, i.e., the 
assignment in a text file (e.g., using R's editor) to -- later again -- 
use source() to read that file in and have it executed? See ?source.

  Hth  --  Gerrit

From Gerrit.Eichner at math.uni-giessen.de  Fri Dec 13 15:21:42 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Fri, 13 Dec 2013 15:21:42 +0100 (MET)
Subject: [R] filter a data.frame
In-Reply-To: <1386939582235-4682118.post@n4.nabble.com>
References: <1386939582235-4682118.post@n4.nabble.com>
Message-ID: <Pine.SOC.4.64.1312131517030.1492@solcom.hrz.uni-giessen.de>

Hello, Mat,

see below.

> hello together, i want to filter a data.frame. My problem is, that i 
> want to filter 2 numbers.
>
> My data.frame look like this one.
>
> No.   text
> 1      abc
> 2      def
> 3      ee
> 4      ff
> 5      gg
>
> I want now to filter No. 2 and 3, so my solution should be look like this
> one.
>
> No.   text
> 2     def
> 3     ee
>
> i tried it like this one:
> out1<-out[(out$No==no.ind),]
>
> in no.ind i have the 2 numbers: c("2","3")
>
> but this doesn't work.

You should not expect a vector (of two elements), here no.ind, equal 
elementwise any of the elements of another (longer) vector, here out$No. 
You probably actually want to check for each element of out$No if it is 
contained in the set of elements in no.ind. So, use, e.g.,

> out1 <- out[(out$No %in% no.ind),]

See ?is.element.


  Hth  --  Gerrit


From dcarlson at tamu.edu  Fri Dec 13 15:54:41 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 13 Dec 2013 08:54:41 -0600
Subject: [R] method default for hclust function
In-Reply-To: <BLU170-W950335A4C017BDEEE73F6E89DC0@phx.gbl>
References: <1386889759.97673.YahooMailNeo@web125002.mail.ne1.yahoo.com>
	<BLU170-W950335A4C017BDEEE73F6E89DC0@phx.gbl>
Message-ID: <008c01cef813$407f8890$c17e99b0$@tamu.edu>

I think the OP was asking about the agglomeration method in
hclust(), not the distance measure in dist(). And the default in
dist() is not absolute distance which is not an option, but
Euclidean distance:

> dist(cbind(v, v))
         1        2        3        4        5
2 1.414214                                    
3 2.828427 1.414214                           
4 4.242641 2.828427 1.414214                  
5 5.656854 4.242641 2.828427 1.414214         
6 7.071068 5.656854 4.242641 2.828427 1.414214

For a single vector (column) such as v <- 1:6, Euclidean,
Manhattan, Maximum, and Minkowski will all give the same result.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of eliza botto
Sent: Thursday, December 12, 2013 5:15 PM
To: capricy gao; r-help at r-project.org
Subject: Re: [R] method default for hclust function

Absolute distance is the default distance in hclust.
v<-c(1,2,3,4,5,6)
dist(v)
2 1        
3 2 1      
4 3 2 1    
5 4 3 2 1  
6 5 4 3 2 1

Eliza

> Date: Thu, 12 Dec 2013 15:09:19 -0800
> From: capricyg at yahoo.com
> To: r-help at r-project.org
> Subject: [R] method default for hclust function
> 
> I could not figure out what was the default when I ran
hclust() without specifying the method.
> 
> For example:
> 
> I just have a code like:
> 
> hclust(dist(data))
> 
> Any input would be appreciated:)
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From wdunlap at tibco.com  Fri Dec 13 16:24:39 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 13 Dec 2013 15:24:39 +0000
Subject: [R] how can i write the function into a file c:/mytest.R with
 cat	function?
In-Reply-To: <tencent_3A82DB05585DDBD410796665@qq.com>
References: <tencent_3A82DB05585DDBD410796665@qq.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1C8E8@PA-MBX01.na.tibco.com>

If you need to use cat() (why?) try using deparse() or format() on the function
   cat("mytest <- ", deparse(mytest), sep="\n", file=file)
but dump() is easier
   dump("mytest",file=file)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of ????
> Sent: Friday, December 13, 2013 3:16 AM
> To: r-help
> Subject: [R] how can i write the function into a file c:/mytest.R with cat function?
> 
> mytest<-function(x,f){
>         sum(x*f)/sum(f)
>         }
>     cat(mytest,file="c:/mytest.R")
>     Error in cat(list(...), file, sep, fill, labels, append) :
>     argument 1 (type 'closure') cannot be handled by 'cat'
> 
> how can i write the mytest function into a file c:/mytest.R with cat function?
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From matthias.weber at fnt.de  Fri Dec 13 16:41:11 2013
From: matthias.weber at fnt.de (Mat)
Date: Fri, 13 Dec 2013 07:41:11 -0800 (PST)
Subject: [R] filter a data.frame
In-Reply-To: <CAM_vjun-pjwj5Ra4vnyMHM7VgGmFOMUZfERchRown3iTU+GP1w@mail.gmail.com>
References: <1386939582235-4682118.post@n4.nabble.com>
	<CAM_vjun-pjwj5Ra4vnyMHM7VgGmFOMUZfERchRown3iTU+GP1w@mail.gmail.com>
Message-ID: <1386949271995-4682131.post@n4.nabble.com>

thanks together, 

out1 <- out[(out$No %in% no.ind),] 

works perfectly :-)



--
View this message in context: http://r.789695.n4.nabble.com/filter-a-data-frame-tp4682118p4682131.html
Sent from the R help mailing list archive at Nabble.com.


From htl10 at users.sourceforge.net  Fri Dec 13 16:20:39 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Fri, 13 Dec 2013 15:20:39 +0000 (GMT)
Subject: [R] freetype 2.5.2, problem with the survival package,
	build R 2.15.x with gcc 4.8.x
Message-ID: <1386948039.5791.BPMail_high_noncarrier@web172303.mail.ir2.yahoo.com>


Thanks for taking the time to look at this issue with changes in the survival package. 

There are warnings (different ones) with any of the versions mentioned - so it is difficult to tell what to not ignore; -). In fact it is somewhat central and essential to the surrounding text 's argument that the matrices are expected to be singular, but the rank is used as an indicator to explore interaction - and lacking there of - of parameters. As far as I know this is also a stripped down version of a published paper. 

Scientific discovery which relies on tuning of numbers sounds "wonderful" - perhaps it is just bad science & bad use of statistics. This sounds like picking one's tuning number to fit one's desired conclusions. 

Would it be appropriate to generate an error with stop(), or something more visible? Yes, it would br nice to "hand-hold" the fitting, but at least in the outlined usage in that vignette, a large number of models are thrown in with a lot of data to see "what sticks", hand-holding individual fits is neither feasible nor appropriate. 

(I didn't write that vignette - I am just checking through it as a small part of a bigger task.)

Hin-tak 

------------------------------
On Fri, Dec 13, 2013 13:01 GMT Terry Therneau wrote:

>I was sent a copy of the data, and this is what I get on a different machine:
> fit <- clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set),
>         data=pscc)
>Warning messages:
>1: In fitter(X, Y, strats, offset, init, control, weights = weights,  :
>  Loglik converged before variable  1,2,3,4 ; beta may be infinite.
>2: In coxph(formula = Surv(rep(1, 13110L), cc) ~ addContr(A) + addContr(C) +  :
>  X matrix deemed to be singular; variable 5
>
> fit
>                     coef exp(coef) se(coef)         z  p
>addContr(A)2     -0.14250     0.867   110812 -1.29e-06  1
>addContr(C)2      0.00525     1.005   110812  4.74e-08  1
>addContr(A.C)1-2 -0.30097     0.740   110812 -2.72e-06  1
>addContr(A.C)2-1 -0.47712     0.621   110812 -4.31e-06  1
>addContr(A.C)2-2       NA        NA        0        NA NA
>
> xmat <- model.matrix(fit)
> svd(xmat)$d
>[1] 1.932097e+02 2.700101e+01 1.624731e+01 6.049630e-15 2.031334e-15
>
>The primary issue is that the covariates matrix is singular, having rank 3 instead of rank 5.
>The coxph routine prints two warning messages that things are not good about the matrix. Warning messages should not be ignored!  The insane se(coef) values in the printed result are an even bigger clue that the model fit is suspect. Unfortunately, some small change in the iteration path or numerics has put this data set over the edge from being seen as rank 3 (old run) to rank 4 (new run).  Moral: coxph does pretty well at detecting redundat variables, but if you know of some it never hurts to help the routine out by removing them before the fit.
>
>Singularity of the X matrix in a Cox model is very difficult to detect reliably; the current threshold is the result of long experience and experiment to give as few false messages as possible.  (The RMS package in particular used truncated power basis functions for the splines, which lead to X matrices that look almost singular numerically, but are not.)  Setting a little less stringent threshold for declaring singularity in the cholesky decompostion sufficies for this data set.
>
>fit2 <- clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set),
>         data=pscc, toler.chol=1e-10)
>
>I'll certainly add this to my list of test problems that I use to tune those constants.
>
>Terry Therneau
>
>On 12/11/2013 09:30 PM, Hin-Tak Leung wrote:
> Here is a rather long discussion etc about freetype 2.5.2, problem with the survival
> package, and build R 2.15.x with gcc 4.8.x. Please feel free to skip forward.
> 
> - freetype 2.5.2:
> 
> the fix to cope with one of the Mac OS X's system fonts just before the release of
> freetype 2.5.1 caused a regression, crashing over one of Microsoft windows' system fonts.
> So there is a 2.5.2. There are new 2.5.2 bundles for windows & Mac OS X. The official
> win/mac binaries of R were built statically with 2+-years-old freetype with a few known
> problems. Most should upgrade/rebuild.
> 
> http://sourceforge.net/projects/outmodedbonsai/files/R/
> 
> - problem with the survival package:
> 
> Trying to re-run a vignette to get the same result as two years ago
> reveal a strange change. I went and bisected it down to
> r11513 and r11516 of the survival package.
> 
> -------------- r11513 --------------------
> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
> 
> 
>                     coef exp(coef) se(coef)     z      p
> addContr(A)2     -0.620     0.538    0.217 -2.86 0.0043
> addContr(C)2      0.482     1.620    0.217  2.22 0.0270
> addContr(A.C)1-2 -0.778     0.459    0.275 -2.83 0.0047
> addContr(A.C)2-1     NA        NA    0.000    NA     NA
> addContr(A.C)2-2     NA        NA    0.000    NA     NA
> 
> Likelihood ratio test=26  on 3 df, p=9.49e-06  n= 13110, number of events= 3524
> ------------------------------------------
> 
> ------------- r11516 ---------------------
> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
> 
> 
>                       coef exp(coef) se(coef)         z  p
> addContr(A)2     -0.14250     0.867   110812 -1.29e-06  1
> addContr(C)2      0.00525     1.005   110812  4.74e-08  1
> addContr(A.C)1-2 -0.30097     0.740   110812 -2.72e-06  1
> addContr(A.C)2-1 -0.47712     0.621   110812 -4.31e-06  1
> addContr(A.C)2-2       NA        NA        0        NA NA
> 
> Likelihood ratio test=26  on 4 df, p=3.15e-05  n= 13110, number of events= 3524
> ------------------------------------------
> 


From sophie.thiebaut at tse-fr.eu  Fri Dec 13 14:16:55 2013
From: sophie.thiebaut at tse-fr.eu (Sophie Thiebaut)
Date: Fri, 13 Dec 2013 13:16:55 +0000
Subject: [R] Constrained model of linear regression
Message-ID: <7E3B88A4D8F5F24389113A97B4136CFEAA66EC86@gremaq-exchange.gremaq2.univ-tlse1.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/73591573/attachment.pl>

From smartpink111 at yahoo.com  Fri Dec 13 14:18:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 13 Dec 2013 05:18:48 -0800 (PST)
Subject: [R] filter a data.frame
In-Reply-To: <1386939582235-4682118.post@n4.nabble.com>
References: <1386939582235-4682118.post@n4.nabble.com>
Message-ID: <1386940728.62124.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Try:

?out[out$No%in% no.ind,]
#? No. text
#2?? 2? def
#3?? 3?? ee
A.K.



On Friday, December 13, 2013 8:03 AM, Mat <matthias.weber at fnt.de> wrote:
hello together, i want to filter a data.frame. My problem is, that i want to
filter 2 numbers.

My data.frame look like this one.

No.?  text
1? ? ? abc
2? ? ? def
3? ? ? ee
4? ? ? ff
5? ? ? gg

I want now to filter No. 2 and 3, so my solution should be look like this
one.

No.?  text
2? ?  def
3? ?  ee

i tried it like this one:
out1<-out[(out$No==no.ind),]

in no.ind i have the 2 numbers: c("2","3")

but this doesn't work.

Maybe anyone can help me.

Thank you.

Mat



--
View this message in context: http://r.789695.n4.nabble.com/filter-a-data-frame-tp4682118.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From elham_h763 at yahoo.com  Fri Dec 13 16:34:20 2013
From: elham_h763 at yahoo.com (Patty Haaem)
Date: Fri, 13 Dec 2013 07:34:20 -0800 (PST)
Subject: [R] how do I separete coloumns by comma?
Message-ID: <1386948860.68821.YahooMailNeo@web141102.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/8d5a2dc6/attachment.pl>

From ruipbarradas at sapo.pt  Fri Dec 13 16:39:41 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 13 Dec 2013 15:39:41 +0000
Subject: [R] filter a data.frame
In-Reply-To: <1386939582235-4682118.post@n4.nabble.com>
References: <1386939582235-4682118.post@n4.nabble.com>
Message-ID: <52AB2A3D.2060707@sapo.pt>

Hello,

Try instead



no.ind <- c(2, 3)

out1 <- out[out$No %in% no.ind, ]


Hope this helps,

Rui Barradas

Em 13-12-2013 12:59, Mat escreveu:
> hello together, i want to filter a data.frame. My problem is, that i want to
> filter 2 numbers.
>
> My data.frame look like this one.
>
> No.   text
> 1      abc
> 2      def
> 3      ee
> 4      ff
> 5      gg
>
> I want now to filter No. 2 and 3, so my solution should be look like this
> one.
>
> No.   text
> 2     def
> 3     ee
>
> i tried it like this one:
> out1<-out[(out$No==no.ind),]
>
> in no.ind i have the 2 numbers: c("2","3")
>
> but this doesn't work.
>
> Maybe anyone can help me.
>
> Thank you.
>
> Mat
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/filter-a-data-frame-tp4682118.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Dec 13 17:29:41 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Dec 2013 08:29:41 -0800
Subject: [R] freetype 2.5.2, problem with the survival package,
	build R 2.15.x with gcc 4.8.x
In-Reply-To: <52A92DD7.2050905@users.sourceforge.net>
References: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>
	<5225B120.8050406@users.sourceforge.net>
	<52948B3C.8020801@users.sourceforge.net>
	<52A92DD7.2050905@users.sourceforge.net>
Message-ID: <B2B90DBE-B988-44BF-ACB9-764F30F8E6E5@comcast.net>


On Dec 11, 2013, at 7:30 PM, Hin-Tak Leung wrote:

> Here is a rather long discussion etc about freetype 2.5.2, problem with the survival package, and build R 2.15.x with gcc 4.8.x. Please feel free to skip forward.
> 
> - freetype 2.5.2:
> 
> the fix to cope with one of the Mac OS X's system fonts just before the release of freetype 2.5.1 caused a regression, crashing over one of Microsoft windows' system fonts. So there is a 2.5.2. There are new 2.5.2 bundles for windows & Mac OS X. The official win/mac binaries of R were built statically with 2+-years-old freetype with a few known problems. Most should upgrade/rebuild.
> 
> http://sourceforge.net/projects/outmodedbonsai/files/R/
> 
> - problem with the survival package:
> 
> Trying to re-run a vignette to get the same result as two years ago
> reveal a strange change. I went and bisected it down to
> r11513 and r11516 of the survival package.
> 
> -------------- r11513 --------------------
> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
> 
> 
>                   coef exp(coef) se(coef)     z      p
> addContr(A)2     -0.620     0.538    0.217 -2.86 0.0043
> addContr(C)2      0.482     1.620    0.217  2.22 0.0270
> addContr(A.C)1-2 -0.778     0.459    0.275 -2.83 0.0047
> addContr(A.C)2-1     NA        NA    0.000    NA     NA
> addContr(A.C)2-2     NA        NA    0.000    NA     NA
> 
> Likelihood ratio test=26  on 3 df, p=9.49e-06  n= 13110, number of events= 3524
> ------------------------------------------
> 
> ------------- r11516 ---------------------
> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
> 
> 
>                     coef exp(coef) se(coef)         z  p
> addContr(A)2     -0.14250     0.867   110812 -1.29e-06  1
> addContr(C)2      0.00525     1.005   110812  4.74e-08  1
> addContr(A.C)1-2 -0.30097     0.740   110812 -2.72e-06  1
> addContr(A.C)2-1 -0.47712     0.621   110812 -4.31e-06  1
> addContr(A.C)2-2       NA        NA        0        NA NA
> 
> Likelihood ratio test=26  on 4 df, p=3.15e-05  n= 13110, number of events= 3524
> ------------------------------------------
> 
> r11514 does not build, and r11515 have serious memory hogs, so the survival
> package broke somewhere between r11513 and r11516. Anyway, here is the diff in
> the vignette, and the data, etc is in the directory above. If somebody want to
> fix this before I spend any more time on this particular matter, please feel free to do so.
> 
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical8_survival-clogit-diff.pdf/download
> 
> That's the one problem from David's 10 practicals which are not due to bugs in snpStats. Some might find it reassuring that only 3 of the 4 problems with the practicals are due to snpStats bugs.
> 
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical7_snpStatsBug-diff.pdf/download
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical6_snpStatsBug-diff.pdf/download
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical3_snpStatsBug-diff.pdf/download
> 
> - build R 2.15.x with gcc 4.8.x
> 
> I wish the R commit log was a bit more detailed with r62430 than just
> "tweak needed for gcc 4.8.x". Anyway, building R 2.15.x with gcc 4.8.x
> could result in segfaults in usage as innocent and essential
> as running summary() on a data.frame:
> 
> --------------------------------
> *** caught segfault ***
> address 0x2f8e6a00, cause 'memory not mapped'
> 
> Traceback:
> 1: sort.list(y)
> 2: factor(a, exclude = exclude)
> 3: table(object, exclude = NULL)
> 4: summary.default(X[[3L]], ...)
> 5: FUN(X[[3L]], ...)
> 6: lapply(X = as.list(object), FUN = summary, maxsum = maxsum, digits = 12,   ...)
> 7: summary.data.frame(support)
> ...
> --------------------------------
> 
> r62430 needs a bit of adapting to apply to R 2.15.x , but you get the idea.
> I hope this info is useful to somebody else who is still using R 2.15.x , no doubt for very good reasons.

First: Sorry for the blank message. Need more coffee.

Second: Does this mean that only Mac users who are still using 2.15.x need to worry about this issue?

Third: I'm reading this (and Terry's comment about singularity conditions)  to mean that a numerical  discrepancy between vignette output when code was run being from what was expected was causing a segfault under some situation that I cannot quite reconstruct. Was the implication that Mac users (of 2.15.x) need to build from sources only if they wanted to build the survival package from source? Does this have any implications for those of us who use the survival package as the binary? (And I'm using 3.0.2, so a split answer might be needed to cover 2.15.x and the current versions separately)

-- 
David.
> 
> Hin-Tak Leung wrote:
>> The freetype people fixed the 2nd set of issues with system fonts shipped with
>> Mac OS X, and released 2.5.1 almost immediately after that. So there are
>> new bundles under http://sourceforge.net/projects/outmodedbonsai/files/R/ .
>> 
>> Just a reminder that the official R binaries for windows/mac OS X are statically
>> linked with rather dated versions of freetype with a few known issues. This
>> affects the cairo-based functionalities in R. So a rebuild is needed.
>> 
>> Most unix users should just upgrade their system's libfreetype, and
>> dynamic-linking should take care of the rest.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From richardkwock at gmail.com  Fri Dec 13 18:08:15 2013
From: richardkwock at gmail.com (Richard Kwock)
Date: Fri, 13 Dec 2013 09:08:15 -0800
Subject: [R] how do I separete coloumns by comma?
In-Reply-To: <1386948860.68821.YahooMailNeo@web141102.mail.bf1.yahoo.com>
References: <1386948860.68821.YahooMailNeo@web141102.mail.bf1.yahoo.com>
Message-ID: <CAJU8Py2ik6=g7UAxVdyrTRSmDaUYKX2_fniXkoBe45Js_9avOg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/9d3eb57a/attachment.pl>

From r.rigby at londonmet.ac.uk  Fri Dec 13 18:33:03 2013
From: r.rigby at londonmet.ac.uk (Robert Rigby)
Date: Fri, 13 Dec 2013 17:33:03 +0000
Subject: [R] growth curve estimation
Message-ID: <CAKmh6oF5Ts=DGkqeo2eHLRgs0S3-fjTZqZBSjsYRpFGMsCdGaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/6f770a53/attachment.pl>

From coachman7777 at yahoo.com  Fri Dec 13 18:37:33 2013
From: coachman7777 at yahoo.com (Stephen Jane)
Date: Fri, 13 Dec 2013 09:37:33 -0800 (PST)
Subject: [R] MuMIn Random Effects Variance
Message-ID: <1386956253.10972.YahooMailBasic@web164604.mail.gq1.yahoo.com>

Hello,

I am using a negative binomial distribution in glmmADMB to fit a mixed model and then using the MuMIn package to get model averaged coefficients.? As far as I can tell, this approach gives no estimates for the variance of the random effects.? I have been taking these from the top model according to AIC.? Is there a preferred approach to getting these?

I would be grateful for any insights.

Stephen Jane


From zirak.p at gmail.com  Fri Dec 13 18:43:22 2013
From: zirak.p at gmail.com (peyman)
Date: Fri, 13 Dec 2013 18:43:22 +0100
Subject: [R] data point labeling in xyplot
Message-ID: <52AB473A.6060600@gmail.com>

Hi Folks,

I have data with a format like:

ID    y    param1    param2    groupingFactor1    groupingFactor2.....
1    ...   
1
1
1
2
2
2
2
3
3
3

so several grouping factors and repeated measures. I am using trellis
and xyplot to get plot with several grouping factors.
something like xyplot(y~x|grouping1*grouping2, data=na.omit(mydata),
panel=function{panel.xyplot(x,y);....}); Lets say x is the x axis
parameter and y the one for y.
So this will produce a plot with 4 windows which groups data according
to all combinations of groupingFactor1 and groupingFactor2.

Now I want to label the data points in each of these four plot windows
with the "ID" (ID is an integer representing the subject number). I used
the ltext(x=x,y=y,...), but then it uses the superscripts for the all
data set and dose not mark the data correctly. It only works if I ignore
the grouping and have all my data in one single plot window. It seems
that I should somehow pass the correct subscripts for the data in each
plot window (or group), but I could not figure it out.

thanks,


From cadeb at usgs.gov  Fri Dec 13 19:07:31 2013
From: cadeb at usgs.gov (Cade, Brian)
Date: Fri, 13 Dec 2013 11:07:31 -0700
Subject: [R] MuMIn Random Effects Variance
In-Reply-To: <1386956253.10972.YahooMailBasic@web164604.mail.gq1.yahoo.com>
References: <1386956253.10972.YahooMailBasic@web164604.mail.gq1.yahoo.com>
Message-ID: <CAM5M9BTS05nj61EkHrFzUBKsrS=Ly9gWYu-eDPUZYDX2gEDxdA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/63550853/attachment.pl>

From friendly at yorku.ca  Fri Dec 13 20:41:58 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 13 Dec 2013 14:41:58 -0500
Subject: [R] extracting non-NA entries from a two-way frequency table
Message-ID: <52AB6306.7000308@yorku.ca>

I have data in the form of a two-way table recording the number of 
families with varying numbers
of boys (rows) and girls (columns: g0 -- g12) below, also given in 
dput() format.

I want to convert this to a data frame containing only the non-NA 
entries, with columns
boys, girls, Freq, where Freq is the table entry.  Can anyone help with 
this?
I suppose that the steps are to transpose each row to a column 
identifying the number of
girls, and then delete the NAs, but I can't quite see how to do this.


 > Geissler
    boys     g0     g1    g2    g3    g4   g5   g6   g7  g8 g9 g10 g11 g12
1    12      7     NA    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
2    11     24     45    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
3    10     30     93   181    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
4     9     90    287   492   478    NA   NA   NA   NA  NA NA  NA  NA  NA
5     8    264    713  1027  1077   829   NA   NA   NA  NA NA  NA  NA  NA
6     7    631   1655  2418  2309  1801 1112   NA   NA  NA NA  NA  NA  NA
7     6   1579   3725  4948  4757  3470 2310 1343   NA  NA NA  NA  NA  NA
8     5   3666   7908  9547  8498  6436 3878 2161 1033  NA NA  NA  NA  NA
9     4   8628  16340 17332 14479 10263 5917 3072 1540 670 NA  NA  NA  NA
10    3  20540  31611 30175 22221 13972 7603 3895 1783 837 286  NA  NA  NA
11    2  47819  57179 44793 28630 15700 8171 3951 1776 722 275 104  NA  NA
12    1 114609  89213 53789 28101 13740 6233 2719 1152 432 151  72  24  NA
13    0     NA 108719 42860 17395  7004 2839 1096  436 161 66  30   8   3

Geissler <-
structure(list(boys = c(12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L,
3L, 2L, 1L, 0L), g0 = c(7L, 24L, 30L, 90L, 264L, 631L, 1579L,
3666L, 8628L, 20540L, 47819L, 114609L, NA), g1 = c(NA, 45L, 93L,
287L, 713L, 1655L, 3725L, 7908L, 16340L, 31611L, 57179L, 89213L,
108719L), g2 = c(NA, NA, 181L, 492L, 1027L, 2418L, 4948L, 9547L,
17332L, 30175L, 44793L, 53789L, 42860L), g3 = c(NA, NA, NA, 478L,
1077L, 2309L, 4757L, 8498L, 14479L, 22221L, 28630L, 28101L, 17395L
), g4 = c(NA, NA, NA, NA, 829L, 1801L, 3470L, 6436L, 10263L,
13972L, 15700L, 13740L, 7004L), g5 = c(NA, NA, NA, NA, NA, 1112L,
2310L, 3878L, 5917L, 7603L, 8171L, 6233L, 2839L), g6 = c(NA,
NA, NA, NA, NA, NA, 1343L, 2161L, 3072L, 3895L, 3951L, 2719L,
1096L), g7 = c(NA, NA, NA, NA, NA, NA, NA, 1033L, 1540L, 1783L,
1776L, 1152L, 436L), g8 = c(NA, NA, NA, NA, NA, NA, NA, NA, 670L,
837L, 722L, 432L, 161L), g9 = c(NA, NA, NA, NA, NA, NA, NA, NA,
NA, 286L, 275L, 151L, 66L), g10 = c(NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, 104L, 72L, 30L), g11 = c(NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, 24L, 8L), g12 = c(NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, 3L)), .Names = c("boys", "g0", "g1",
"g2", "g3", "g4", "g5", "g6", "g7", "g8", "g9", "g10", "g11",
"g12"), class = "data.frame", row.names = c(NA, -13L))


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From rmailbox at justemail.net  Fri Dec 13 21:01:35 2013
From: rmailbox at justemail.net (rmailbox at justemail.net)
Date: Fri, 13 Dec 2013 12:01:35 -0800
Subject: [R] extracting non-NA entries from a two-way frequency table
In-Reply-To: <52AB6306.7000308@yorku.ca>
References: <52AB6306.7000308@yorku.ca>
Message-ID: <1386964895.27485.59344777.0EFDA5B8@webmail.messagingengine.com>

Perhaps this?

library(reshape2)
library(stringr)

GeisslerLong <- melt (Geissler, id.vars = c("boys"))
GeisslerLong <- transform ( GeisslerLong, girls = as.numeric ( str_replace( variable, "g", '' )) )
GeisslerLong <- rename ( GeisslerLong, c( value = "Freq"))
GeisslerLong <- arrange ( GeisslerLong, boys, girls)
GeisslerLong <- subset ( GeisslerLong, !is.na ( Freq), select = c( boys, girls, Freq))


Eric


----- Original message -----
From: Michael Friendly <friendly at yorku.ca>
To: "R-help" <r-help at r-project.org>
Subject: [R] extracting non-NA entries from a two-way frequency table
Date: Fri, 13 Dec 2013 14:41:58 -0500

I have data in the form of a two-way table recording the number of 
families with varying numbers
of boys (rows) and girls (columns: g0 -- g12) below, also given in 
dput() format.

I want to convert this to a data frame containing only the non-NA 
entries, with columns
boys, girls, Freq, where Freq is the table entry.  Can anyone help with 
this?
I suppose that the steps are to transpose each row to a column 
identifying the number of
girls, and then delete the NAs, but I can't quite see how to do this.


 > Geissler
    boys     g0     g1    g2    g3    g4   g5   g6   g7  g8 g9 g10 g11 g12
1    12      7     NA    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
2    11     24     45    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
3    10     30     93   181    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
4     9     90    287   492   478    NA   NA   NA   NA  NA NA  NA  NA  NA
5     8    264    713  1027  1077   829   NA   NA   NA  NA NA  NA  NA  NA
6     7    631   1655  2418  2309  1801 1112   NA   NA  NA NA  NA  NA  NA
7     6   1579   3725  4948  4757  3470 2310 1343   NA  NA NA  NA  NA  NA
8     5   3666   7908  9547  8498  6436 3878 2161 1033  NA NA  NA  NA  NA
9     4   8628  16340 17332 14479 10263 5917 3072 1540 670 NA  NA  NA  NA
10    3  20540  31611 30175 22221 13972 7603 3895 1783 837 286  NA  NA  NA
11    2  47819  57179 44793 28630 15700 8171 3951 1776 722 275 104  NA  NA
12    1 114609  89213 53789 28101 13740 6233 2719 1152 432 151  72  24  NA
13    0     NA 108719 42860 17395  7004 2839 1096  436 161 66  30   8   3

Geissler <-
structure(list(boys = c(12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L,
3L, 2L, 1L, 0L), g0 = c(7L, 24L, 30L, 90L, 264L, 631L, 1579L,
3666L, 8628L, 20540L, 47819L, 114609L, NA), g1 = c(NA, 45L, 93L,
287L, 713L, 1655L, 3725L, 7908L, 16340L, 31611L, 57179L, 89213L,
108719L), g2 = c(NA, NA, 181L, 492L, 1027L, 2418L, 4948L, 9547L,
17332L, 30175L, 44793L, 53789L, 42860L), g3 = c(NA, NA, NA, 478L,
1077L, 2309L, 4757L, 8498L, 14479L, 22221L, 28630L, 28101L, 17395L
), g4 = c(NA, NA, NA, NA, 829L, 1801L, 3470L, 6436L, 10263L,
13972L, 15700L, 13740L, 7004L), g5 = c(NA, NA, NA, NA, NA, 1112L,
2310L, 3878L, 5917L, 7603L, 8171L, 6233L, 2839L), g6 = c(NA,
NA, NA, NA, NA, NA, 1343L, 2161L, 3072L, 3895L, 3951L, 2719L,
1096L), g7 = c(NA, NA, NA, NA, NA, NA, NA, 1033L, 1540L, 1783L,
1776L, 1152L, 436L), g8 = c(NA, NA, NA, NA, NA, NA, NA, NA, 670L,
837L, 722L, 432L, 161L), g9 = c(NA, NA, NA, NA, NA, NA, NA, NA,
NA, 286L, 275L, 151L, 66L), g10 = c(NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, 104L, 72L, 30L), g11 = c(NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, 24L, 8L), g12 = c(NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, 3L)), .Names = c("boys", "g0", "g1",
"g2", "g3", "g4", "g5", "g6", "g7", "g8", "g9", "g10", "g11",
"g12"), class = "data.frame", row.names = c(NA, -13L))


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Dec 13 21:06:38 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 13 Dec 2013 20:06:38 +0000
Subject: [R] extracting non-NA entries from a two-way frequency table
In-Reply-To: <52AB6306.7000308@yorku.ca>
References: <52AB6306.7000308@yorku.ca>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1CA4E@PA-MBX01.na.tibco.com>

The following puts the data.frame into 'long' format and then drops
rows with NA's for 'n'.

f <- function(data){
    df <- data.frame(
        expand.grid(
            boys = data[["boys"]],
            girls = as.integer(sub("^g", "", colnames(data)[-1]))
        ),
        n = unlist(data[, -1])) # n is all but the 'boys', the first, column
    df[!is.na(df[["n"]]), ]
}

E.g.,

> f(Geissler)[c(2,30,75),]
    boys girls    n
2     11     0   24
34     5     2 9547
104    0     7  436
> Geissler[Geissler["boys"]==5, "g2"]
[1] 9547

reshape() can probably do this but I always get lost in its argument list.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Michael Friendly
> Sent: Friday, December 13, 2013 11:42 AM
> To: R-help
> Subject: [R] extracting non-NA entries from a two-way frequency table
> 
> I have data in the form of a two-way table recording the number of
> families with varying numbers
> of boys (rows) and girls (columns: g0 -- g12) below, also given in
> dput() format.
> 
> I want to convert this to a data frame containing only the non-NA
> entries, with columns
> boys, girls, Freq, where Freq is the table entry.  Can anyone help with
> this?
> I suppose that the steps are to transpose each row to a column
> identifying the number of
> girls, and then delete the NAs, but I can't quite see how to do this.
> 
> 
>  > Geissler
>     boys     g0     g1    g2    g3    g4   g5   g6   g7  g8 g9 g10 g11 g12
> 1    12      7     NA    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 2    11     24     45    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 3    10     30     93   181    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 4     9     90    287   492   478    NA   NA   NA   NA  NA NA  NA  NA  NA
> 5     8    264    713  1027  1077   829   NA   NA   NA  NA NA  NA  NA  NA
> 6     7    631   1655  2418  2309  1801 1112   NA   NA  NA NA  NA  NA  NA
> 7     6   1579   3725  4948  4757  3470 2310 1343   NA  NA NA  NA  NA  NA
> 8     5   3666   7908  9547  8498  6436 3878 2161 1033  NA NA  NA  NA  NA
> 9     4   8628  16340 17332 14479 10263 5917 3072 1540 670 NA  NA  NA  NA
> 10    3  20540  31611 30175 22221 13972 7603 3895 1783 837 286  NA  NA  NA
> 11    2  47819  57179 44793 28630 15700 8171 3951 1776 722 275 104  NA  NA
> 12    1 114609  89213 53789 28101 13740 6233 2719 1152 432 151  72  24  NA
> 13    0     NA 108719 42860 17395  7004 2839 1096  436 161 66  30   8   3
> 
> Geissler <-
> structure(list(boys = c(12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L,
> 3L, 2L, 1L, 0L), g0 = c(7L, 24L, 30L, 90L, 264L, 631L, 1579L,
> 3666L, 8628L, 20540L, 47819L, 114609L, NA), g1 = c(NA, 45L, 93L,
> 287L, 713L, 1655L, 3725L, 7908L, 16340L, 31611L, 57179L, 89213L,
> 108719L), g2 = c(NA, NA, 181L, 492L, 1027L, 2418L, 4948L, 9547L,
> 17332L, 30175L, 44793L, 53789L, 42860L), g3 = c(NA, NA, NA, 478L,
> 1077L, 2309L, 4757L, 8498L, 14479L, 22221L, 28630L, 28101L, 17395L
> ), g4 = c(NA, NA, NA, NA, 829L, 1801L, 3470L, 6436L, 10263L,
> 13972L, 15700L, 13740L, 7004L), g5 = c(NA, NA, NA, NA, NA, 1112L,
> 2310L, 3878L, 5917L, 7603L, 8171L, 6233L, 2839L), g6 = c(NA,
> NA, NA, NA, NA, NA, 1343L, 2161L, 3072L, 3895L, 3951L, 2719L,
> 1096L), g7 = c(NA, NA, NA, NA, NA, NA, NA, 1033L, 1540L, 1783L,
> 1776L, 1152L, 436L), g8 = c(NA, NA, NA, NA, NA, NA, NA, NA, 670L,
> 837L, 722L, 432L, 161L), g9 = c(NA, NA, NA, NA, NA, NA, NA, NA,
> NA, 286L, 275L, 151L, 66L), g10 = c(NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, 104L, 72L, 30L), g11 = c(NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, 24L, 8L), g12 = c(NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, 3L)), .Names = c("boys", "g0", "g1",
> "g2", "g3", "g4", "g5", "g6", "g7", "g8", "g9", "g10", "g11",
> "g12"), class = "data.frame", row.names = c(NA, -13L))
> 
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Dec 13 21:38:01 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 13 Dec 2013 14:38:01 -0600
Subject: [R] extracting non-NA entries from a two-way frequency table
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1CA4E@PA-MBX01.na.tibco.com>
References: <52AB6306.7000308@yorku.ca>
	<E66794E69CFDE04D9A70842786030B933FA1CA4E@PA-MBX01.na.tibco.com>
Message-ID: <017301cef843$37323e60$a596bb20$@tamu.edu>

This will also work:

rownames(Geissler) <- paste0("b", Geissler$boys)
Geissler2 <-
na.omit(as.data.frame(as.table(as.matrix(Geissler[,-1]))))
names(Geissler2) <- c("Boys", "Girls", "Freq")
Geissler2$Boys <-
as.numeric(substr(as.character(Geissler2$Boys), 2,
     nchar(as.character(Geissler2$Boys))))
Geissler2$Girls <-
as.numeric(substr(as.character(Geissler2$Girls), 2,
     nchar(as.character(Geissler2$Girls))))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of William
Dunlap
Sent: Friday, December 13, 2013 2:07 PM
To: Michael Friendly; R-help
Subject: Re: [R] extracting non-NA entries from a two-way
frequency table

The following puts the data.frame into 'long' format and then
drops
rows with NA's for 'n'.

f <- function(data){
    df <- data.frame(
        expand.grid(
            boys = data[["boys"]],
            girls = as.integer(sub("^g", "",
colnames(data)[-1]))
        ),
        n = unlist(data[, -1])) # n is all but the 'boys', the
first, column
    df[!is.na(df[["n"]]), ]
}

E.g.,

> f(Geissler)[c(2,30,75),]
    boys girls    n
2     11     0   24
34     5     2 9547
104    0     7  436
> Geissler[Geissler["boys"]==5, "g2"]
[1] 9547

reshape() can probably do this but I always get lost in its
argument list.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf
> Of Michael Friendly
> Sent: Friday, December 13, 2013 11:42 AM
> To: R-help
> Subject: [R] extracting non-NA entries from a two-way
frequency table
> 
> I have data in the form of a two-way table recording the
number of
> families with varying numbers
> of boys (rows) and girls (columns: g0 -- g12) below, also
given in
> dput() format.
> 
> I want to convert this to a data frame containing only the
non-NA
> entries, with columns
> boys, girls, Freq, where Freq is the table entry.  Can anyone
help with
> this?
> I suppose that the steps are to transpose each row to a column
> identifying the number of
> girls, and then delete the NAs, but I can't quite see how to
do this.
> 
> 
>  > Geissler
>     boys     g0     g1    g2    g3    g4   g5   g6   g7  g8 g9
g10 g11 g12
> 1    12      7     NA    NA    NA    NA   NA   NA   NA  NA NA
NA  NA  NA
> 2    11     24     45    NA    NA    NA   NA   NA   NA  NA NA
NA  NA  NA
> 3    10     30     93   181    NA    NA   NA   NA   NA  NA NA
NA  NA  NA
> 4     9     90    287   492   478    NA   NA   NA   NA  NA NA
NA  NA  NA
> 5     8    264    713  1027  1077   829   NA   NA   NA  NA NA
NA  NA  NA
> 6     7    631   1655  2418  2309  1801 1112   NA   NA  NA NA
NA  NA  NA
> 7     6   1579   3725  4948  4757  3470 2310 1343   NA  NA NA
NA  NA  NA
> 8     5   3666   7908  9547  8498  6436 3878 2161 1033  NA NA
NA  NA  NA
> 9     4   8628  16340 17332 14479 10263 5917 3072 1540 670 NA
NA  NA  NA
> 10    3  20540  31611 30175 22221 13972 7603 3895 1783 837 286
NA  NA  NA
> 11    2  47819  57179 44793 28630 15700 8171 3951 1776 722 275
104  NA  NA
> 12    1 114609  89213 53789 28101 13740 6233 2719 1152 432 151
72  24  NA
> 13    0     NA 108719 42860 17395  7004 2839 1096  436 161 66
30   8   3
> 
> Geissler <-
> structure(list(boys = c(12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L,
> 3L, 2L, 1L, 0L), g0 = c(7L, 24L, 30L, 90L, 264L, 631L, 1579L,
> 3666L, 8628L, 20540L, 47819L, 114609L, NA), g1 = c(NA, 45L,
93L,
> 287L, 713L, 1655L, 3725L, 7908L, 16340L, 31611L, 57179L,
89213L,
> 108719L), g2 = c(NA, NA, 181L, 492L, 1027L, 2418L, 4948L,
9547L,
> 17332L, 30175L, 44793L, 53789L, 42860L), g3 = c(NA, NA, NA,
478L,
> 1077L, 2309L, 4757L, 8498L, 14479L, 22221L, 28630L, 28101L,
17395L
> ), g4 = c(NA, NA, NA, NA, 829L, 1801L, 3470L, 6436L, 10263L,
> 13972L, 15700L, 13740L, 7004L), g5 = c(NA, NA, NA, NA, NA,
1112L,
> 2310L, 3878L, 5917L, 7603L, 8171L, 6233L, 2839L), g6 = c(NA,
> NA, NA, NA, NA, NA, 1343L, 2161L, 3072L, 3895L, 3951L, 2719L,
> 1096L), g7 = c(NA, NA, NA, NA, NA, NA, NA, 1033L, 1540L,
1783L,
> 1776L, 1152L, 436L), g8 = c(NA, NA, NA, NA, NA, NA, NA, NA,
670L,
> 837L, 722L, 432L, 161L), g9 = c(NA, NA, NA, NA, NA, NA, NA,
NA,
> NA, 286L, 275L, 151L, 66L), g10 = c(NA, NA, NA, NA, NA, NA,
NA,
> NA, NA, NA, 104L, 72L, 30L), g11 = c(NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, 24L, 8L), g12 = c(NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, 3L)), .Names = c("boys", "g0", "g1",
> "g2", "g3", "g4", "g5", "g6", "g7", "g8", "g9", "g10", "g11",
> "g12"), class = "data.frame", row.names = c(NA, -13L))
> 
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416
736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From silvano at uel.br  Fri Dec 13 22:14:34 2013
From: silvano at uel.br (Silvano Cesar da Costa)
Date: Fri, 13 Dec 2013 19:14:34 -0200 (BRST)
Subject: [R] Problems with xtable?
Message-ID: <febed888796af81df31e39caf085222b.squirrel@webmail.uel.br>

Hi,

I'm using Sweave to create some tables. My code is:

<<label=Q1, echo=FALSE, results=tex>>=
tab1 = table(DISCIPLINA, Q1)
tab1.prop = round(addmargins(100*prop.table(tab1, 1),
FUN=list(Total=sum)), 2)
tab1.txt = xtable(tab1.prop, align="l|rrrrrr", label='Q1',
caption=c("Apresenta??o da proposta de programa a ser desenvolvida na
disciplina", "Q1"))
print(tab1.txt, format.args=list(big.mark = ".", decimal.mark = ","),
caption.placement='top', table.placement='H')
@


but, the output is

Margins computed over dimensions
in the following order:
1: DISCIPLINA
2: Q1
% latex table generated in R 3.0.0 by xtable 1.7-1 package
% Fri Dec 13 19:00:35 2013
\begin{table}[H]
\centering
\caption[Q1]{Apresenta??o da proposta de programa a ser desenvolvida na
disciplina}
\label{Q1}
\begin{tabular}{l|rrrrrr}
  \hline
 & 1 & 2 & 3 & 4 & 5 & Total \\
  \hline
6BAV039 & 5,45 & 20,00 & 40,00 & 29,09 & 5,45 & 100,00 \\
  6BIO029 & 1,85 & 1,85 & 31,48 & 37,04 & 27,78 & 100,00 \\
  6BIO030 & 0,00 & 0,00 & 5,45 & 45,45 & 49,09 & 100,00 \\
  6BIO031 & 0,00 & 1,89 & 45,28 & 30,19 & 22,64 & 100,00 \\
  6BIQ014 & 0,00 & 0,00 & 9,26 & 42,59 & 48,15 & 100,00 \\
  6CIF023 & 1,85 & 3,70 & 20,37 & 42,59 & 31,48 & 100,00 \\
  6EMA024 & 1,85 & 9,26 & 25,93 & 38,89 & 24,07 & 100,00 \\
  6HIT011 & 0,00 & 0,00 & 3,70 & 27,78 & 68,52 & 100,00 \\
  6MOR012 & 0,00 & 0,00 & 41,82 & 47,27 & 10,91 & 100,00 \\
  6PAT013 & 0,00 & 5,56 & 29,63 & 44,44 & 20,37 & 100,00 \\
  6SOC016 & 3,64 & 9,09 & 38,18 & 29,09 & 20,00 & 100,00 \\
  Total & 14,65 & 51,35 & 291,11 & 414,43 & 328,47 & 1.100,00 \\
   \hline
\end{tabular}
\end{table}


and I don't want this output

Margins computed over dimensions
in the following order:
1: DISCIPLINA
2: Q1


How can I get out it?


Thanks,


---------------------------------------------
Silvano Cesar da Costa

Universidade Estadual de Londrina
Centro de Ci?ncias Exatas
Departamento de Estat?stica

Fone: (43) 3371-4346


From gangchen6 at gmail.com  Fri Dec 13 22:15:18 2013
From: gangchen6 at gmail.com (Gang Chen)
Date: Fri, 13 Dec 2013 16:15:18 -0500
Subject: [R] dataframe manipulation
Message-ID: <CAHmzXO5Wth05HDt=YxbEAXoG9Jy3+PMaaxWjzQ52OTwPG_9XwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/3e6b6c2d/attachment.pl>

From davies.trevor at gmail.com  Fri Dec 13 22:34:07 2013
From: davies.trevor at gmail.com (Trevor Davies)
Date: Fri, 13 Dec 2013 13:34:07 -0800
Subject: [R] Minutes after midnight to time
Message-ID: <CAJhyqVhKk=X6_UBwpOcnWUVRQrM7kWXJfUQiDxPBq3VNUTZusA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/ed707ce9/attachment.pl>

From gangchen6 at gmail.com  Fri Dec 13 22:35:16 2013
From: gangchen6 at gmail.com (Gang Chen)
Date: Fri, 13 Dec 2013 16:35:16 -0500
Subject: [R] dataframe manipulation
In-Reply-To: <1386969677.50085.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CAHmzXO5Wth05HDt=YxbEAXoG9Jy3+PMaaxWjzQ52OTwPG_9XwQ@mail.gmail.com>
	<1386969677.50085.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CAHmzXO6z91kOASDSzZe2+Kbptwy6dyzid-F6rSeht883p=2oxQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/d93ab9d7/attachment.pl>

From sarah.goslee at gmail.com  Fri Dec 13 22:35:50 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 13 Dec 2013 16:35:50 -0500
Subject: [R] dataframe manipulation
In-Reply-To: <CAHmzXO5Wth05HDt=YxbEAXoG9Jy3+PMaaxWjzQ52OTwPG_9XwQ@mail.gmail.com>
References: <CAHmzXO5Wth05HDt=YxbEAXoG9Jy3+PMaaxWjzQ52OTwPG_9XwQ@mail.gmail.com>
Message-ID: <CAM_vjumLQCrrnDo_1D+QS0mc4vPZW5oW7O5S2i1Zn=W3GKs3Wg@mail.gmail.com>

What about:

lapply(levels(d$fac), function(x)head(d[d$fac == x,], 1))


Thanks for the reproducible example. If you put set.seed(123) before
the call to sample, then everyone who tries it will get the same data
frame d.

Sarah


On Fri, Dec 13, 2013 at 4:15 PM, Gang Chen <gangchen6 at gmail.com> wrote:
> Suppose I have a dataframe defined as
>
>      L3 <- LETTERS[1:3]
>      (d <- data.frame(cbind(x = 1, y = 1:10), fac = sample(L3, 10, replace
> = TRUE)))
>
>    x  y fac
> 1  1  1   C
> 2  1  2   A
> 3  1  3   B
> 4  1  4   C
> 5  1  5   B
> 6  1  6   B
> 7  1  7   A
> 8  1  8   A
> 9  1  9   B
> 10 1 10   A
>
> I want to extract those rows that are the first occurrences for each level
> of factor 'fac', which are basically the first three rows above. How can I
> achieve that? The real dataframe is more complicated than the example
> above, and I can't simply list all the levels of factor 'fac' by
> exhaustibly listing all the levels like the following
>
> d[d$fac=='A' | d$fac=='B' | d$fac=='C', ]
>
> Thanks,
> Gang

-- 
Sarah Goslee
http://www.functionaldiversity.org


From gangchen6 at gmail.com  Fri Dec 13 22:38:40 2013
From: gangchen6 at gmail.com (Gang Chen)
Date: Fri, 13 Dec 2013 16:38:40 -0500
Subject: [R] dataframe manipulation
In-Reply-To: <CAM_vjumLQCrrnDo_1D+QS0mc4vPZW5oW7O5S2i1Zn=W3GKs3Wg@mail.gmail.com>
References: <CAHmzXO5Wth05HDt=YxbEAXoG9Jy3+PMaaxWjzQ52OTwPG_9XwQ@mail.gmail.com>
	<CAM_vjumLQCrrnDo_1D+QS0mc4vPZW5oW7O5S2i1Zn=W3GKs3Wg@mail.gmail.com>
Message-ID: <CAHmzXO4J9AOQGJNxYPfmWU=nLDzdFHXaghL91oGFxg=XOBfVXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/c5921981/attachment.pl>

From brian.s.diggs at gmail.com  Fri Dec 13 22:58:29 2013
From: brian.s.diggs at gmail.com (Brian Diggs)
Date: Fri, 13 Dec 2013 13:58:29 -0800
Subject: [R] Problems with xtable?
In-Reply-To: <febed888796af81df31e39caf085222b.squirrel@webmail.uel.br>
References: <febed888796af81df31e39caf085222b.squirrel@webmail.uel.br>
Message-ID: <52AB8305.5050709@ohsu.edu>

On 12/13/2013 1:14 PM, Silvano Cesar da Costa wrote:
> Hi,
>
> I'm using Sweave to create some tables. My code is:
>
> <<label=Q1, echo=FALSE, results=tex>>=
> tab1 = table(DISCIPLINA, Q1)
> tab1.prop = round(addmargins(100*prop.table(tab1, 1),
> FUN=list(Total=sum)), 2)
> tab1.txt = xtable(tab1.prop, align="l|rrrrrr", label='Q1',
> caption=c("Apresenta??o da proposta de programa a ser desenvolvida na
> disciplina", "Q1"))
> print(tab1.txt, format.args=list(big.mark = ".", decimal.mark = ","),
> caption.placement='top', table.placement='H')
> @
>
>
> but, the output is
>
> Margins computed over dimensions
> in the following order:
> 1: DISCIPLINA
> 2: Q1
> % latex table generated in R 3.0.0 by xtable 1.7-1 package
> % Fri Dec 13 19:00:35 2013
> \begin{table}[H]
> \centering
> \caption[Q1]{Apresenta??o da proposta de programa a ser desenvolvida na
> disciplina}
> \label{Q1}
> \begin{tabular}{l|rrrrrr}
>    \hline
>   & 1 & 2 & 3 & 4 & 5 & Total \\
>    \hline
> 6BAV039 & 5,45 & 20,00 & 40,00 & 29,09 & 5,45 & 100,00 \\
>    6BIO029 & 1,85 & 1,85 & 31,48 & 37,04 & 27,78 & 100,00 \\
>    6BIO030 & 0,00 & 0,00 & 5,45 & 45,45 & 49,09 & 100,00 \\
>    6BIO031 & 0,00 & 1,89 & 45,28 & 30,19 & 22,64 & 100,00 \\
>    6BIQ014 & 0,00 & 0,00 & 9,26 & 42,59 & 48,15 & 100,00 \\
>    6CIF023 & 1,85 & 3,70 & 20,37 & 42,59 & 31,48 & 100,00 \\
>    6EMA024 & 1,85 & 9,26 & 25,93 & 38,89 & 24,07 & 100,00 \\
>    6HIT011 & 0,00 & 0,00 & 3,70 & 27,78 & 68,52 & 100,00 \\
>    6MOR012 & 0,00 & 0,00 & 41,82 & 47,27 & 10,91 & 100,00 \\
>    6PAT013 & 0,00 & 5,56 & 29,63 & 44,44 & 20,37 & 100,00 \\
>    6SOC016 & 3,64 & 9,09 & 38,18 & 29,09 & 20,00 & 100,00 \\
>    Total & 14,65 & 51,35 & 291,11 & 414,43 & 328,47 & 1.100,00 \\
>     \hline
> \end{tabular}
> \end{table}
>
>
> and I don't want this output
>
> Margins computed over dimensions
> in the following order:
> 1: DISCIPLINA
> 2: Q1
>
>
> How can I get out it?

The message is coming from the addmargins function. You can add the 
argument quiet=FALSE to the addmargins call (see the help page for 
addmargins).

Despite the help page referring to it as a "message", it is not really a 
message (in the sense of reported via message()) but is written out with 
cat(). Therefore the typical ways to suppress a message 
(suppressMessages(), etc.) won't work. The quiet argument to addmargins 
is the most straightforward way.

> Thanks,
>
>
> ---------------------------------------------
> Silvano Cesar da Costa
>
> Universidade Estadual de Londrina
> Centro de Ci?ncias Exatas
> Departamento de Estat?stica
>
> Fone: (43) 3371-4346
>


-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From wdunlap at tibco.com  Fri Dec 13 23:14:05 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 13 Dec 2013 22:14:05 +0000
Subject: [R] dataframe manipulation
In-Reply-To: <CAHmzXO6z91kOASDSzZe2+Kbptwy6dyzid-F6rSeht883p=2oxQ@mail.gmail.com>
References: <CAHmzXO5Wth05HDt=YxbEAXoG9Jy3+PMaaxWjzQ52OTwPG_9XwQ@mail.gmail.com>
	<1386969677.50085.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAHmzXO6z91kOASDSzZe2+Kbptwy6dyzid-F6rSeht883p=2oxQ@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1CAF1@PA-MBX01.na.tibco.com>

> >  d[match(unique(d$fac),d$fac),]

The following does the same thing a little more directly (and quickly)
   d[ !duplicated(d$fac), ]

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Gang Chen
> Sent: Friday, December 13, 2013 1:35 PM
> To: arun
> Cc: R help
> Subject: Re: [R] dataframe manipulation
> 
> Perfect! Thanks a lot, A.K!
> 
> 
> On Fri, Dec 13, 2013 at 4:21 PM, arun <smartpink111 at yahoo.com> wrote:
> 
> >
> >
> > Hi,
> > Try:
> >  d[match(unique(d$fac),d$fac),]
> > A.K.
> >
> >
> > On Friday, December 13, 2013 4:17 PM, Gang Chen <gangchen6 at gmail.com>
> > wrote:
> > Suppose I have a dataframe defined as
> >
> >      L3 <- LETTERS[1:3]
> >      (d <- data.frame(cbind(x = 1, y = 1:10), fac = sample(L3, 10, replace
> > = TRUE)))
> >
> >    x  y fac
> > 1  1  1   C
> > 2  1  2   A
> > 3  1  3   B
> > 4  1  4   C
> > 5  1  5   B
> > 6  1  6   B
> > 7  1  7   A
> > 8  1  8   A
> > 9  1  9   B
> > 10 1 10   A
> >
> > I want to extract those rows that are the first occurrences for each level
> > of factor 'fac', which are basically the first three rows above. How can I
> > achieve that? The real dataframe is more complicated than the example
> > above, and I can't simply list all the levels of factor 'fac' by
> > exhaustibly listing all the levels like the following
> >
> > d[d$fac=='A' | d$fac=='B' | d$fac=='C', ]
> >
> > Thanks,
> > Gang
> >
> >     [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ahoerner at rprogress.org  Sat Dec 14 01:13:19 2013
From: ahoerner at rprogress.org (Andrew Hoerner)
Date: Fri, 13 Dec 2013 16:13:19 -0800
Subject: [R] The Stoppa distribution
Message-ID: <CA+t4QRqu4iqQ3cvncT7QWmqUSVwWSDxWdAUS3CwdKdshBg516w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/bca604fb/attachment.pl>

From dwinsemius at comcast.net  Sat Dec 14 01:35:24 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Dec 2013 16:35:24 -0800
Subject: [R] colClasses does not cause read.table to coerce to numeric;
	anymore?
Message-ID: <1807A00B-1687-48F7-BF97-5C1B8C237281@comcast.net>


I thought that setting colClasses to numeric would coerce errant data to NA. Instead read.table is throwing
errors. This is not what I remember from prior experience with read.table and it is not how I read the help page as promising:

BE<-
c("   1841       96           42.26        31.50        73.75 ", 
"   1841       97           29.56        20.78        50.34 ", 
"   1841       98           18.71        10.59        29.30 ", 
"   1841       99           10.48         6.23        16.71 ", 
"   1841      100            6.14         4.23        10.37 ", 
"   1841      101            3.31         2.06         5.38 ", 
"   1841      102            1.50         0.83         2.34 ", 
"   1841      103            0.33         0.05         0.38 ", 
"   1841      104            0.00         0.00         0.00 ", 
"   1841      105            0.00         0.00         0.00 ", 
"   1841      106            0.00         0.00         0.00 ", 
"   1841      107            0.00         0.00         0.00 ", 
"   1841      108            0.00         0.00         0.00 ", 
"   1841      109            0.00         0.00         0.00 ", 
"   1841      110+           0.00         0.00         0.00 ", 
"   1842        0        60290.60     62238.19    122528.79 ", 
"   1842        1        54893.31     55849.06    110742.37 ", 
"   1842        2        51991.87     53033.62    105025.49 ", 
"   1842        3        49697.90     50789.01    100486.91 ", 
"   1842        4        47598.24     48414.78     96013.02 ", 
"   1842        5        46202.38     47106.34     93308.72 "
)
#-----------
 BELe<-read.table(text=BE,
                  header=FALSE, colClasses="numeric", as.is=TRUE)
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  : 
  scan() expected 'a real', got '110+'

I originally got this when reading from a file, but the error is from scan(). Was this an unfortunate side-effect of adding the `text` argument to read.table? It does still persist when the character string is pass through textConnection tot he file argument:

BELe<-read.table(file=textConnection(BE),
                 header=FALSE, colClasses="numeric")
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  : 
  scan() expected 'a real', got '110+'

My memory was that such coercion was effective in past years.

-- 


David Winsemius
Alameda, CA, USA


From btupper at bigelow.org  Sat Dec 14 02:32:18 2013
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 13 Dec 2013 20:32:18 -0500
Subject: [R] Minutes after midnight to time
In-Reply-To: <CAJhyqVhKk=X6_UBwpOcnWUVRQrM7kWXJfUQiDxPBq3VNUTZusA@mail.gmail.com>
References: <CAJhyqVhKk=X6_UBwpOcnWUVRQrM7kWXJfUQiDxPBq3VNUTZusA@mail.gmail.com>
Message-ID: <F307AD9A-8337-4F52-9D14-91C378136350@bigelow.org>

Hi,

On Dec 13, 2013, at 4:34 PM, Trevor Davies <davies.trevor at gmail.com> wrote:

> Is there a quick function that can convert minutes (seconds) after midnight
> to a time?
> 
> i.e 670.93 (minutes after midnight) --> 11:10:56.**
> 
> I know it can be done by hand but I thought there must be a function for
> this already.
> 

I'm not sure what you mean by doing it by hand, but do the following do the trick for you?

# convert seconds to hours
s2h <- function(x=670.93*60) {
   h <- floor(x/3600)
   m <- floor((x - h*3600)/60)
   s <- x - h*3600 - m*60
   sprintf("%0.2d:%0.2d:%6.3f", h, m, s)

}
# convert minutes to hours
m2h <- function(x=670.93) {
   h <- floor(x/60)
   m <- floor(x - h*60)
   s <- (x - h*60 - m) * 60
   sprintf("%0.2d:%0.2d:%6.3f", h, m, s)
}


> s2h() ; m2h()
[1] "11:10:55.800"
[1] "11:10:55.800"

Cheers,
Ben

> Thank you.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From smartpink111 at yahoo.com  Fri Dec 13 22:21:17 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 13 Dec 2013 13:21:17 -0800 (PST)
Subject: [R] dataframe manipulation
In-Reply-To: <CAHmzXO5Wth05HDt=YxbEAXoG9Jy3+PMaaxWjzQ52OTwPG_9XwQ@mail.gmail.com>
References: <CAHmzXO5Wth05HDt=YxbEAXoG9Jy3+PMaaxWjzQ52OTwPG_9XwQ@mail.gmail.com>
Message-ID: <1386969677.50085.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi,
Try:
?d[match(unique(d$fac),d$fac),]
A.K.


On Friday, December 13, 2013 4:17 PM, Gang Chen <gangchen6 at gmail.com> wrote:
Suppose I have a dataframe defined as

? ?  L3 <- LETTERS[1:3]
? ?  (d <- data.frame(cbind(x = 1, y = 1:10), fac = sample(L3, 10, replace
= TRUE)))

?  x? y fac
1? 1? 1?  C
2? 1? 2?  A
3? 1? 3?  B
4? 1? 4?  C
5? 1? 5?  B
6? 1? 6?  B
7? 1? 7?  A
8? 1? 8?  A
9? 1? 9?  B
10 1 10?  A

I want to extract those rows that are the first occurrences for each level
of factor 'fac', which are basically the first three rows above. How can I
achieve that? The real dataframe is more complicated than the example
above, and I can't simply list all the levels of factor 'fac' by
exhaustibly listing all the levels like the following

d[d$fac=='A' | d$fac=='B' | d$fac=='C', ]

Thanks,
Gang

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From CRoe at go2uti.com  Sat Dec 14 00:01:15 2013
From: CRoe at go2uti.com (Roe, Colleen)
Date: Fri, 13 Dec 2013 23:01:15 +0000
Subject: [R] ggplot question: how to have two y-axis guide on one plot?
Message-ID: <81059F081DF11149B441AACDB54B7BE3330F1D39@sinmpt10.corp.go2uti.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131213/656b4a14/attachment.pl>

From smartpink111 at yahoo.com  Fri Dec 13 18:10:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 13 Dec 2013 09:10:33 -0800 (PST)
Subject: [R] how do I separete coloumns by comma?
Message-ID: <1386954633.45929.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
mydata <- read.table("data.txt") #or read.table("data.txt",sep="")
?str(mydata)
#'data.frame':??? 6 obs. of? 6 variables:
# $ V1: int? 1 1 1 1 1 1
# $ V2: int? 4 4 4 2 2 2
# $ V3: int? 4 2 5 3 3 3
# $ V4: int? 1 2 1 1 1 1
# $ V5: int? 6 3 2 1 2 4
# $ V6: int? 23 28 24 24 40 22


?write.table(mydata,"dataNew.txt",sep=",",row.names=FALSE,quote=FALSE)
##dataNew.txt
V1,V2,V3,V4,V5,V6
1,4,4,1,6,23
1,4,2,2,3,28
1,4,5,1,2,24
1,2,3,1,1,24
1,2,3,1,2,40
1,2,3,1,4,22
#or

?Lines1 <- readLines("data.txt")
?gsub(" +",",",Lines1)
#[1] "1,4,4,1,6,23" "1,4,2,2,3,28" "1,4,5,1,2,24" "1,2,3,1,1,24" "1,2,3,1,2,40"
#[6] "1,2,3,1,4,22"

A.K.




Hi every one, 


I have a text file like this: 
1??? 4?? 4??? 1??? 6 ?? 23 
1?? 4??? 2??? 2??? 3??? 28 
1??? 4??? 5??? 1??? 2??? 24 
1??? 2??? 3??? 1??? 1??? 24 
1?? 2??? 3??? 1??? 2?? ? 40 
1?? 2?? 3??? 1??? 4? ? ? 22 

I want to separate columns by comma, like this: 
1,4,4,1,6,23 
1,4,2,2,3,28 
1,4,5,1,2,24 
1,2,3,1,1,24 
1,2,3,1,2,40 
1,2,3,1,4,22?? 

I used this code: 
mydata=read.table("data.txt",sep=",") 
but I see this output: 
1\t4\t4\t1\t6\t231\t4\t2\t2\t3\t28 
...? 
please correct my code 
Thanks in advance 
Elham


From npgraham1 at gmail.com  Fri Dec 13 18:23:52 2013
From: npgraham1 at gmail.com (Nathaniel Graham)
Date: Fri, 13 Dec 2013 12:23:52 -0500
Subject: [R] disabling sparse Matrix index checking during assignment
Message-ID: <CALhihUh67x99O=Q5pWnMxOtz2mJEJP_L43zmoV0VEWtyM3UgGg@mail.gmail.com>

The project I'm working on requires producing a number of large
(250,000x250,000) sparse logical matrices.  I'm currently doing this
by updating the elements (turning FALSE to TRUE) of a matrix in
batches as they're identified like so:

x[idx.matrix] <- TRUE

where x is created via Matrix(nrow = n, ncol = n, data = FALSE) and
n is approximately 250,000.  The idx.matrix is a two column matrix of
indices to be assigned to.  This is done many times.  After profiling,
I've found that the lion's share of the work is taking place in the
internal calls to check for duplicates, etc in the indices passed to
[.  For instance, anyDuplicated.default is one of the most
time-consuming portions of my code according to Rprof.

This makes the whole process quite slow as there are frequently
thousands of index pairs in each call.  I'd like to disable as many of
these checks as possible; I can guarantee that aren't any duplicates,
and even if there are I don't especially care, since that would only
mean that a value is assigned TRUE twice instead of once.

I've tried a number of other approaches, such as creating a data.table
of all the indices to be changed and doing the assignment once, but
the temporary memory usage becomes enormous (I run out of memory on a
32GB machine).
I've also tried creating a temporary sparseMatrix and using '|' like so:

# a, b are numeric vectors of indices
x <- x | sparseMatrix(a, b, x = TRUE, dims = x at Dim, check = FALSE)

but this turns out to be slower than assignment; most of its time is
spent in the logical OR command.

Is there a way to speed this process up substantially?  Thanks in
advance for your help.
-------
Nathaniel Graham
npgraham1 at gmail.com
npgraham1 at uky.edu


From jkaron at earthlink.net  Fri Dec 13 20:11:09 2013
From: jkaron at earthlink.net (J Karon)
Date: Fri, 13 Dec 2013 11:11:09 -0800 (PST)
Subject: [R] Invalid connection error message when trying to write a file
Message-ID: <1386961869720-4682149.post@n4.nabble.com>

I get an invalid connection method error message when trying to write an R
object from a user-defined function to my hard drive (running Windows 7)
using write.csv.  I have previously not had this problem with the same
user-defined function.  The error message is

Error in isOpen(file, "w") : invalid connection
In addition: Warning message:
In if (file == "") file <- stdout() else if (is.character(file)) { :
  the condition has length > 1 and only the first element will be used

Using 
zz<-file(description="path","w")
write.csv(  )
close(zz)

creates an empty file but yields the same error message when I execute
write.csv.




--
View this message in context: http://r.789695.n4.nabble.com/Invalid-connection-error-message-when-trying-to-write-a-file-tp4682149.html
Sent from the R help mailing list archive at Nabble.com.


From cjohnst at uga.edu  Fri Dec 13 20:55:57 2013
From: cjohnst at uga.edu (cjohnst)
Date: Fri, 13 Dec 2013 11:55:57 -0800 (PST)
Subject: [R] Fisher's LSD problem
Message-ID: <1386964557092-4682153.post@n4.nabble.com>

I have been trying to run a Fisher's LSD for quite some time now, however the
output I am receiving only ranks the means of each treatment in terms of
significant difference, and will not give me the actual value of "Least
Significant Difference" I am looking for.  I am using a data set that has
four replications and two factors ("Ratio" and "Species"), however for this
particular dataset "Species" was not a significant factor so I am only
interested in the LSD value for comparing the "Ratio" factor.  Note that the
response variable for two of the ratios only has three values (the fourth
rep had to be deleted due to impossibility), and I do not know if this may
be the source of my problem.  Regardless, here is my script:

f <- file.choose()
svs30dayshoot <- read.csv(f)
svs30dayshoot
str(svs30dayshoot)
svs30dayshoot$Ratio<-factor(svs30dayshoot$Ratio)

aov30dayshoot <- aov(RY ~ Species*Ratio, data=svs30dayshoot)
summary(aov30dayshoot)

install.packages('agricolae')
library(agricolae)
LSD<-LSD.test(aov30dayshoot,"Ratio", p.adj="bonferroni") 
LSD


And the resulting output is below.  Note there is no "Least Significant
Difference" value given.  In fact, this output looks nothing like the output
I'm used to seeing when running Fisher's LSD with a one-way ANOVA (in my
class):

$statistics
       Mean       CV   MSerror
  0.6804658 107.7707 0.5377916

$parameters
  Df ntr bonferroni
  28   5   3.046929

$means
           RY   std.err r        LCL       UCL   Min.   Max.
0   0.0000000 0.2592758 8 -0.5311024 0.5311024 0.0000 0.0000
100 1.0000000 0.2592758 8  0.4688976 1.5311024 1.0000 1.0000
25  0.3140571 0.2771775 7 -0.2537152 0.8818295 0.0200 0.5069
50  0.8016875 0.2592758 8  0.2705851 1.3327899 0.3800 1.5952
75  1.3208286 0.2771775 7  0.7530562 1.8886010 0.3864 4.8889

$comparison
NULL

$groups
  trt     means  M
1 75  1.3208286  a
2 100 1.0000000 ab
3 50  0.8016875 ab
4 25  0.3140571 ab
5 0   0.0000000  b

Any help would be greatly appreciated!



--
View this message in context: http://r.789695.n4.nabble.com/Fisher-s-LSD-problem-tp4682153.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Sat Dec 14 03:23:24 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Dec 2013 18:23:24 -0800
Subject: [R] ggplot question: how to have two y-axis guide on one plot?
In-Reply-To: <81059F081DF11149B441AACDB54B7BE3330F1D39@sinmpt10.corp.go2uti.com>
References: <81059F081DF11149B441AACDB54B7BE3330F1D39@sinmpt10.corp.go2uti.com>
Message-ID: <CD6621D7-4748-4208-BBCE-2B5E6E6B0FD8@comcast.net>


On Dec 13, 2013, at 3:01 PM, Roe, Colleen wrote:

> I have a plot I'd like to do wherein I plot to different y data sets and want to have two different y axis's appear (perhaps one on right side and one on left).   I searched R help with all the key phrases I could think of and I have three books covering ggplot but I can't find an example of doing this.   It seems a natural thing to do with ggplot.
> 
> Anyone out there have a small example of doing this sort of thing?

Here is why Hadley says it's not a feature:

http://stackoverflow.com/questions/3099219/how-to-use-ggplot2-make-plot-with-2-y-axes-one-y-axis-on-the-left-and-another

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Dec 14 03:33:27 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Dec 2013 18:33:27 -0800
Subject: [R] ggplot question: how to have two y-axis guide on one plot?
In-Reply-To: <CD6621D7-4748-4208-BBCE-2B5E6E6B0FD8@comcast.net>
References: <81059F081DF11149B441AACDB54B7BE3330F1D39@sinmpt10.corp.go2uti.com>
	<CD6621D7-4748-4208-BBCE-2B5E6E6B0FD8@comcast.net>
Message-ID: <04FA80D5-02D3-4780-8744-2D0233443E83@comcast.net>


On Dec 13, 2013, at 6:23 PM, David Winsemius wrote:

> 
> On Dec 13, 2013, at 3:01 PM, Roe, Colleen wrote:
> 
>> I have a plot I'd like to do wherein I plot to different y data sets and want to have two different y axis's appear (perhaps one on right side and one on left).   I searched R help with all the key phrases I could think of and I have three books covering ggplot but I can't find an example of doing this.   It seems a natural thing to do with ggplot.
>> 
>> Anyone out there have a small example of doing this sort of thing?
> 
> Here is why Hadley says it's not a feature:
> 
> http://stackoverflow.com/questions/3099219/how-to-use-ggplot2-make-plot-with-2-y-axes-one-y-axis-on-the-left-and-another

However;  @kohske has provided a strategy and it's on the RStudio server.

http://rpubs.com/kohske/dual_axis_in_ggplot2

I found it linked from one of the other questions on SO with a search string of: 

[r] two y axes ggplot2



-- 


David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Sat Dec 14 03:50:48 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 14 Dec 2013 02:50:48 +0000
Subject: [R] The Stoppa distribution
In-Reply-To: <CA+t4QRqu4iqQ3cvncT7QWmqUSVwWSDxWdAUS3CwdKdshBg516w@mail.gmail.com>
References: <CA+t4QRqu4iqQ3cvncT7QWmqUSVwWSDxWdAUS3CwdKdshBg516w@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1CB89@PA-MBX01.na.tibco.com>

Try the following, which have the usual lower.tail and log.p arguments to make
it easier to get accurate results in the tails.  logspace_sub() is an R version of
the R C-API function Rf_logspace_sub().  I haven't tested the [pq]stoppa functions
much.

logspace_sub <- function (logx, logy)
{
    # log(exp(logx) - exp(logy)), avoiding unnecessary floating point error
    dxy <- logx - logy
    # log(2) looks like best breakpoint
    logx + ifelse(dxy < 0.693147180559945, log(-expm1(-dxy)), log1p(-exp(-dxy)))
}

pstoppa <- function(q, y0, alpha, theta = 1, lower.tail = TRUE, log.p = FALSE)
{
    logp <- theta * logspace_sub(0, -alpha * log(q/y0))
    if (!lower.tail) {
        logp <- logspace_sub(0, logp)
    }
    if (log.p) logp else exp(logp)
}

qstoppa <- function(p, y0, alpha, theta = 1, lower.tail = TRUE, log.p = FALSE)
{
    logp <- if (log.p) {
                if (lower.tail) p else logspace_sub(0, p)
            } else {
                if (lower.tail) log(p) else log1p(-p)
            }
    logq <- log(y0) - 1/alpha * logspace_sub(0, logp/theta)
    exp(logq)
}

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Andrew Hoerner
> Sent: Friday, December 13, 2013 4:13 PM
> To: r-help
> Subject: [R] The Stoppa distribution
> 
> The Stoppa distribution is a 3-parameter distribution that generalizes the
> Pareto distribution, adding a second shape parameter but no location term.
> The CDF is
> 
>                                     F(x) =  [1-(x/x0)-?]?    0 < x0 < x
> 
> Kleiber & Kotz (2003). *Statistical Size Distributions in Economics and
> Actuarial Sciences.*    I do not believe that the Stoppa distribution has
> been implemented in R under that name.
> 
> 
> Does anyone know if the Stoppa distribution has been implimented in R under
> a different name, or if there is a more generalized distribution containing
> the Stoppa as a special case which has been implemented in R? (The
> generalized beta of the second kind, maybe?) And if so, how you need to set
> the parameters of the more general distribution to collapse it to the
> Stoppa?
> 
> Any help anyone could offer would be greatly appreciated.
> 
> Sincerely, andrewH
> 
> 	[[alternative HTML version deleted]]


From 1248283536 at qq.com  Sat Dec 14 04:11:38 2013
From: 1248283536 at qq.com (=?gb18030?B?y66+ssH3ye4=?=)
Date: Sat, 14 Dec 2013 11:11:38 +0800
Subject: [R] Converting decimal to binary in R
Message-ID: <tencent_6AD3882132EDA8B24335FC09@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131214/425dadfe/attachment.pl>

From jdnewmil at dcn.davis.ca.us  Sat Dec 14 05:36:04 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 13 Dec 2013 20:36:04 -0800 (PST)
Subject: [R] Minutes after midnight to time
In-Reply-To: <CAJhyqVhKk=X6_UBwpOcnWUVRQrM7kWXJfUQiDxPBq3VNUTZusA@mail.gmail.com>
References: <CAJhyqVhKk=X6_UBwpOcnWUVRQrM7kWXJfUQiDxPBq3VNUTZusA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1312132008020.41733@pedal.dcn.davis.ca.us>

On Fri, 13 Dec 2013, Trevor Davies wrote:

> Is there a quick function that can convert minutes (seconds) after midnight
> to a time?
>
> i.e 670.93 (minutes after midnight) --> 11:10:56.**
>
> I know it can be done by hand but I thought there must be a function for
> this already.

Sort of.  There isn't really a "time-of-day" datatype in R in the way you 
are thinking about it, so naturally there are no functions associated with 
that data type. (This is actually how Excel does it also.) There is the 
difftime data type, but it does not print to your desired format.

However, you can ignore the date portion of a POSIXt type:

strftime( as.POSIXct( "1970-01-01" ) + as.difftime( 670.93, units="mins" 
), "%H:%M:%OS3" )

[1] "11:10:55.799"

However, this is not a particularly computationally efficient route to 
your goal (a large vector of minutes values converts quickly to difftime, 
and that adds quickly to the POSIXct value, but then strftime converts it 
to POSIXlt for putting pieces into the string which is not so "quick"), so 
if you are looking for "quick" execution you might want to go ahead and do 
it, as you say, "by hand".

On the other hand, I find it quite "quick" to remember how to do this, so 
in that sense it could be described as "quick".

> Thank you.
>
> 	[[alternative HTML version deleted]]

Per the Posting Guide, please don't post in HTML.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From yuanzhi.li at usherbrooke.ca  Sat Dec 14 06:22:01 2013
From: yuanzhi.li at usherbrooke.ca (yuanzhi)
Date: Fri, 13 Dec 2013 21:22:01 -0800 (PST)
Subject: [R] Chinese Garbled
Message-ID: <1386998521870-4682184.post@n4.nabble.com>

Hello, I met a problem which needs your help. I reinstalled the R and Rstudio
recently. After that, I found there was a problem that the Chinese character
was garbled in Rstudio sometimes. 

example 1
"richness.csv" is a file containing three columns and the names of the three
columns are "????"??????"???"? But when I read this file with function
"read.csv" and displayed, these Chinese characters are garbled like the
followings?
> x<-read.csv("richness.csv")
> x[1:5,]
  X..??? X.?? ???
1        CK    ?     34
2        CK    ?     43
3        CK    ?     45
4        CK    ?     41
5        CK    ?     33

example2

Sometimes the prompting message also contains garabled Chinese characters.
For example, when I run "?bargraph.CI"(which is a function in package
"sciplot") before I use the cammand "library(sciplot)", it will appear the
following message with garbled Chinese characters:
> ?bargraph.CI
No documentation for ?argraph.CI?in specified packages and libraries:
you could try ??bargraph.CI?

So, what can I do to solve the problem. Thank you!
Yuanzhi



--
View this message in context: http://r.789695.n4.nabble.com/Chinese-Garbled-tp4682184.html
Sent from the R help mailing list archive at Nabble.com.


From rmh at temple.edu  Sat Dec 14 07:17:30 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 14 Dec 2013 01:17:30 -0500
Subject: [R] Converting decimal to binary in R
In-Reply-To: <tencent_6AD3882132EDA8B24335FC09@qq.com>
References: <tencent_6AD3882132EDA8B24335FC09@qq.com>
Message-ID: <CAGx1TMDC0qWXh_MdxnHtP2vVnzdUwyi3r8zj5CX41zOWmFV+7Q@mail.gmail.com>

I recommend
?sprintf

(4^(1/3))^3 != 4
(4^(1/3))^3 == 4
(4^(1/3))^3 - 4
format(c((4^(1/3))^3 , 4), digits=17)
sprintf("%+13.13a", c((4^(1/3))^3 , 4))

On Fri, Dec 13, 2013 at 10:11 PM, ???? <1248283536 at qq.com> wrote:
> i  have write a function to convert decimal number into binary number in R.
>
> dectobin<-function(x){
>   as.numeric(intToBits(x))->x1
>   paste(x1,collapse="")->x2
>   as.numeric(gsub("0+$","",x2))->x3
>   return(as.character(x3))}
>
> dectobin can get right result ,it is so long ,is there a  build-in function to do ?
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Dec 14 07:40:44 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 13 Dec 2013 22:40:44 -0800 (PST)
Subject: [R] Converting decimal to binary in R
In-Reply-To: <tencent_6AD3882132EDA8B24335FC09@qq.com>
References: <tencent_6AD3882132EDA8B24335FC09@qq.com>
Message-ID: <alpine.BSF.2.00.1312132228050.67315@pedal.dcn.davis.ca.us>

On Sat, 14 Dec 2013, ???????? wrote:

> i  have write a function to convert decimal number into binary number in R.
>
> dectobin<-function(x){
>  as.numeric(intToBits(x))->x1
>  paste(x1,collapse="")->x2
>  as.numeric(gsub("0+$","",x2))->x3
>  return(as.character(x3))}
>
> dectobin can get right result ,it is so long ,is there a build-in
> function to do ?

I don't know of one. The below function is roughly twice as fast as yours 
and it works on an entire vector of values at once (but it still uses a 
for loop to do so).

decToBinStr <- function(x) {
   l <- floor( log( x, 2 ) ) + 1
   v <- as.logical( intToBits( x ) )
   vc <- rep( "0", length( v ) )
   vc[ v ] <- "1"
   m <- matrix( vc, ncol=length( x ) )
   result <- rep( NA, length( x ) )
   for ( idx in seq.int( length( x ) ) ) {
     result[ idx ] <- paste( m[ seq.int( l[ idx ], 1 ), idx ], collapse="" )
   }
   result
}

> 	[[alternative HTML version deleted]]

Per the Posting Guide, please post in plain text.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From michel.arnaud at cirad.fr  Sat Dec 14 08:01:35 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sat, 14 Dec 2013 08:01:35 +0100
Subject: [R] to replace the for loop
Message-ID: <52AC024F.9010409@cirad.fr>

Hello

I would like to replace the for loop this below

T <- as.matrix(T)
for(i in 1: nrow(TEMP)){
for(j in 1: nrow(TEMP)){if (i <= j) T[i, j] <- 0 }}

I don't find the function in the doc.
Thanks in advance for your help.

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From bhh at xs4all.nl  Sat Dec 14 08:51:35 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 14 Dec 2013 08:51:35 +0100
Subject: [R] to replace the for loop
In-Reply-To: <52AC024F.9010409@cirad.fr>
References: <52AC024F.9010409@cirad.fr>
Message-ID: <D6AB8EE8-F451-4114-BDF6-D7E18F3061D0@xs4all.nl>


On 14-12-2013, at 08:01, Arnaud Michel <michel.arnaud at cirad.fr> wrote:

> Hello
> 
> I would like to replace the for loop this below
> 
> T <- as.matrix(T)
> for(i in 1: nrow(TEMP)){
> for(j in 1: nrow(TEMP)){if (i <= j) T[i, j] <- 0 }}
> 

Your code is mangled.
We don?t know what T is.
You refer to TEMP in the for loop but you most likely meant T.

Shouldn?t the second nrow in your for loop be ncol?

> I don't find the function in the doc.

Search with ??uppertri and you?ll find lower.tri in base with sufficient description to have a look at that entry.
Depending on what packages you have, you may find more.


> Thanks in advance for your help.
> 

T[col(T)>=row(T)] <- 0
T[upper.tri(T,diag=TRUE) ] <- 0

Berend


> -- 
> Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Dec 14 08:34:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 13 Dec 2013 23:34:27 -0800 (PST)
Subject: [R] to replace the for loop
Message-ID: <1387006467.91861.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this helps:

set.seed(42)
?T <- matrix(sample(1:20,20,replace=TRUE),ncol=5)
?TEMP <- T
T1 <- T
?for(i in 1: nrow(TEMP)){
?for(j in 1: nrow(TEMP)){if (i <= j) T[i, j] <- 0 }}
?
indx <- expand.grid(rep(list(1:nrow(TEMP)),2))[,2:1]
T1[as.matrix(indx[indx[,1] <= indx[,2],])] <- 0

#or 
library(gtools)
indx <- permutations(nrow(TEMP),2,1:nrow(TEMP),repeats=TRUE)
T1[indx[indx[,1] <= indx[,2],]] <- 0

?identical(T,T1)
#[1] TRUE
A.K.

Hello 

I would like to replace the for loop this below 

T <- as.matrix(T) 
for(i in 1: nrow(TEMP)){ 
for(j in 1: nrow(TEMP)){if (i <= j) T[i, j] <- 0 }} 

I don't find the function in the doc. 
Thanks in advance for your help.


From 1248283536 at qq.com  Sat Dec 14 11:46:10 2013
From: 1248283536 at qq.com (=?gb18030?B?y66+ssH3ye4=?=)
Date: Sat, 14 Dec 2013 18:46:10 +0800
Subject: [R] iterated sum
Message-ID: <tencent_4EACA09A7136C89765BAF0BB@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131214/f3d672a1/attachment.pl>

From Ted.Harding at wlandres.net  Sat Dec 14 11:50:06 2013
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Sat, 14 Dec 2013 10:50:06 -0000 (GMT)
Subject: [R] Converting decimal to binary in R
In-Reply-To: <CAGx1TMDC0qWXh_MdxnHtP2vVnzdUwyi3r8zj5CX41zOWmFV+7Q@mail.gmail.com>
Message-ID: <XFMail.20131214105006.Ted.Harding@wlandres.net>

> On Fri, Dec 13, 2013 at 10:11 PM, ???????????? <1248283536 at qq.com> wrote:
>> i  have write a function to convert decimal number into binary number in R.
>>
>> dectobin<-function(x){
>>   as.numeric(intToBits(x))->x1
>>   paste(x1,collapse="")->x2
>>   as.numeric(gsub("0+$","",x2))->x3
>>   return(as.character(x3))}
>>
>> dectobin can get right result ,it is so long ,is there a  build-in function
>> to do ?

On 14-Dec-2013 06:17:30 Richard M. Heiberger wrote:
> I recommend
> ?sprintf
> 
> (4^(1/3))^3 != 4
> (4^(1/3))^3 == 4
> (4^(1/3))^3 - 4
> format(c((4^(1/3))^3 , 4), digits=17)
> sprintf("%+13.13a", c((4^(1/3))^3 , 4))

The above generates a hexadecinal representation, not binary!
So it needs further substitutions to get the binary representation.

Can I add a tip which I have very often found useful for this kind
of global substitution? Not just binary -- I first cooked it up
in text-editing when faced with replacing "European" numbers by
"Anglo-Saxon" numbers -- e.g. "1.234.567,89" needs to be converted
into "1,234,567.89", therefore swapping "." and ",". But you don't
want to do "." --> "," and then "," --> "." since you would then
end up with  "1.234.567,89" --> "1,234,567,89" --> "1.234.567.89"

There, the trick was to use a character such as "#", which does
not appear in the text, as a marker for the first substitution while
the second is being made. Then substitute the desired character for "#":
"1.234.567,89" --> "1#234#567,89" --> "1#234#567.89" --> "1,234,567.89"
(first replacing "." by "#", then finally "#" by ",").

You need to replace, for instance, "0" in hex by "0000" in binary,
"1" by "0001", "2" by "0010", ... , "A" by "1010", and so on.
However, you need to avoid replacing already-replaced symbols.

So I suggest using, in a first round, "U" for "1" and "Z" for "0"
(or whatever you prefer, provided it avoids "0" and "1").
So 0 -> ZZZZ, 1 -> ZZZU, ... , A -> UZUZ, etc.
Then, finally, replace each "Z" by "0" and each "U" by "1".

Hence (using a truncated representation), sqrt(pi) in hex is:

  sprintf("%+8.8A", sqrt(pi))
  # [1] "+0X1.C5BF891BP+0"

Then the successive substitutions (which can of course be programmed)
would be:

"+0X1.C5BF891BP+0"

0: "+ZZZZX1.C5BF891BP+ZZZZ"
1: "+ZZZZXZZZU.C5BF89ZZZUBP+ZZZZ"
2: "+ZZZZXZZZU.C5BF89ZZZUBP+ZZZZ"
3: "+ZZZZXZZZU.C5BF89ZZZUBP+ZZZZ"
4: "+ZZZZXZZZU.C5BF89ZZZUBP+ZZZZ"
5: "+ZZZZXZZZU.CZUZUBF89ZZZUBP+ZZZZ"
6: "+ZZZZXZZZU.CZUZUBF89ZZZUBP+ZZZZ"
7: "+ZZZZXZZZU.CZUZUBF89ZZZUBP+ZZZZ"
8: "+ZZZZXZZZU.CZUZUBFUZZZ9ZZZUBP+ZZZZ"
9: "+ZZZZXZZZU.CZUZUBFUZZZUZZUZZZUBP+ZZZZ"
A: "+ZZZZXZZZU.CZUZUBFUZZZUZZUZZZUBP+ZZZZ"
B: "+ZZZZXZZZU.CZUZUUZUUFUZZZUZZUZZZUUZUUP+ZZZZ"
C: "+ZZZZXZZZU.UUZZZUZUUZUUFUZZZUZZUZZZUUZUUP+ZZZZ"
D: "+ZZZZXZZZU.UUZZZUZUUZUUFUZZZUZZUZZZUUZUUP+ZZZZ"
E: "+ZZZZXZZZU.UUZZZUZUUZUUFUZZZUZZUZZZUUZUUP+ZZZZ"
F: "+ZZZZXZZZU.UUZZZUZUUZUUUUUUUZZZUZZUZZZUUZUUP+ZZZZ"

Z: "+0000X000U.UU000U0UU0UUUUUUU000U00U000UU0UUP+0000"
U: "+0000X0001.11000101101111111000100100011011P+0000"

The final result probably needs tidying up in accordance with
the needs of subsequent uses!

Hoping this helps,
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 14-Dec-2013  Time: 10:50:03
This message was sent by XFMail


From Ted.Harding at wlandres.net  Sat Dec 14 11:54:04 2013
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Sat, 14 Dec 2013 10:54:04 -0000 (GMT)
Subject: [R] iterated sum
In-Reply-To: <tencent_4EACA09A7136C89765BAF0BB@qq.com>
Message-ID: <XFMail.20131214105404.Ted.Harding@wlandres.net>

On 14-Dec-2013 10:46:10 ???????? wrote:
> x<-c(1,4,9,20,3,7)
> i want to get a serie c(5,13,29,23,10).
>  y <- c()
>  for (i in 2:length(x)){
>      y[i-1] <- x[i-1]+x[i]}
> 
> is there more simple way to get?

  x <- c(1,4,9,20,3,7)
  N <- length(x)

  x[1:(N-1)] + x[2:N]
  # [1]  5 13 29 23 10

Best wishes,
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 14-Dec-2013  Time: 10:54:00
This message was sent by XFMail


From 1248283536 at qq.com  Sat Dec 14 12:22:58 2013
From: 1248283536 at qq.com (=?gb18030?B?y66+ssH3ye4=?=)
Date: Sat, 14 Dec 2013 19:22:58 +0800
Subject: [R] how to read file into terminal?
Message-ID: <tencent_00B1E7AC4371BF9A7EECD3A7@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131214/c9bedace/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sat Dec 14 12:58:30 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 14 Dec 2013 12:58:30 +0100
Subject: [R] how to read file into terminal?
In-Reply-To: <tencent_00B1E7AC4371BF9A7EECD3A7@qq.com>
References: <tencent_00B1E7AC4371BF9A7EECD3A7@qq.com>
Message-ID: <52AC47E6.7010205@statistik.tu-dortmund.de>

See ?source

Uwe Ligges


On 14.12.2013 12:22, ???? wrote:
> there is a file which contain such lines:
>
> test <-function(x,f){
>     n<- length(x);
>     sum(f*(x[1:(n-1)]+x[2:n])/2)/sum(f) -> result;
>     return(result);
>     }
>
> i can read it into terminal , cat test.R
> how can i do it in R?
>
>> readLines("c:/test.R",n=-1)
> [1] "test <-function(x,f){"                             "   n<- length(x);"
> [3] "   sum(f*(x[1:(n-1)]+x[2:n])/2)/sum(f) -> result;" "   return(result);"
> [5] "   }"
>>   paste(readLines("c:/test.R",n=-1),collapse="")
> [1] "test <-function(x,f){   n<- length(x);   sum(f*(x[1:(n-1)]+x[2:n])/2)/sum(f) -> result;   return(result);   }"
>>
>
> is there better way to do ?can i get better format ?
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From eliza_botto at hotmail.com  Sat Dec 14 15:30:18 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Sat, 14 Dec 2013 14:30:18 +0000
Subject: [R] plot two columns against one
Message-ID: <BLU170-W124EAA2E54DEE694C5EDF1189DE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131214/b67c7ae4/attachment.pl>

From dcarlson at tamu.edu  Sat Dec 14 16:34:58 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Sat, 14 Dec 2013 09:34:58 -0600
Subject: [R] plot two columns against one
In-Reply-To: <BLU170-W124EAA2E54DEE694C5EDF1189DE0@phx.gbl>
References: <BLU170-W124EAA2E54DEE694C5EDF1189DE0@phx.gbl>
Message-ID: <01c601cef8e2$0bc41420$234c3c60$@tamu.edu>

Please do not send emails using html. Please use dput() to send
your data to the list

> st <- read.table(text=s, header=TRUE)
> plot(B~A, st, type="n")
> with(st, text(A, B, C))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of eliza botto
Sent: Saturday, December 14, 2013 8:30 AM
To: r-help at r-project.org
Subject: [R] plot two columns against one

Dear users of R,
How can i plot the values in column "C" with "A" on x-axis and
"B" on y-axis?s <-
"A       B        C     0.451   0.333   1134           
0.491   0.270   1433       
0.389   0.249   7784       
0.425   0.819   6677   
0.457   0.429   99053       
0.436   0.524   111049      0.423   0.270   121093       0.463
0.315   131019 Thankyou very much in advance,
Eliza
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From smartpink111 at yahoo.com  Sat Dec 14 16:48:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 14 Dec 2013 07:48:52 -0800 (PST)
Subject: [R] plot two columns against one
In-Reply-To: <BLU170-W124EAA2E54DEE694C5EDF1189DE0@phx.gbl>
References: <BLU170-W124EAA2E54DEE694C5EDF1189DE0@phx.gbl>
Message-ID: <1387036132.85326.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,

Using ?ggplot()

s <-read.table(text="A????? B??????? C
0.451? 0.333? 1134???????? 
0.491? 0.270? 1433???? 
0.389? 0.249? 7784???? 
0.425? 0.819? 6677 
0.457? 0.429? 99053???? 
0.436? 0.524? 111049
0.423? 0.270? 121093
0.463? 0.315? 131019",sep="",header=TRUE)
library(ggplot2)
ggplot(s,aes(x=A,y=B,colour=C))+geom_text(label=s$C) + theme_bw()
A.K.


On Saturday, December 14, 2013 9:30 AM, eliza botto <eliza_botto at hotmail.com> wrote:
Dear users of R,
How can i plot the values in column "C" with "A" on x-axis and "B" on y-axis?s <-
"A? ? ?  B? ? ? ? C? ?  0.451?  0.333?  1134? ? ? ? ? 
0.491?  0.270?  1433? ? ? 
0.389?  0.249?  7784? ? ? 
0.425?  0.819?  6677? 
0.457?  0.429?  99053? ? ? 
0.436?  0.524?  111049? ? ? 0.423?  0.270?  121093? ? ?  0.463?  0.315?  131019 Thankyou very much in advance,
Eliza
??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ligges at statistik.tu-dortmund.de  Sat Dec 14 16:53:01 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 14 Dec 2013 16:53:01 +0100
Subject: [R] colClasses does not cause read.table to coerce to numeric;
 anymore?
In-Reply-To: <1807A00B-1687-48F7-BF97-5C1B8C237281@comcast.net>
References: <1807A00B-1687-48F7-BF97-5C1B8C237281@comcast.net>
Message-ID: <52AC7EDD.1050602@statistik.tu-dortmund.de>

David,

how should R interpret "110+"? It cannot be numeric, perhaps you have 
not recognized the "+" there?

Uwe




On 14.12.2013 01:35, David Winsemius wrote:
>
> I thought that setting colClasses to numeric would coerce errant data to NA. Instead read.table is throwing
> errors. This is not what I remember from prior experience with read.table and it is not how I read the help page as promising:
>
> BE<-
> c("   1841       96           42.26        31.50        73.75 ",
> "   1841       97           29.56        20.78        50.34 ",
> "   1841       98           18.71        10.59        29.30 ",
> "   1841       99           10.48         6.23        16.71 ",
> "   1841      100            6.14         4.23        10.37 ",
> "   1841      101            3.31         2.06         5.38 ",
> "   1841      102            1.50         0.83         2.34 ",
> "   1841      103            0.33         0.05         0.38 ",
> "   1841      104            0.00         0.00         0.00 ",
> "   1841      105            0.00         0.00         0.00 ",
> "   1841      106            0.00         0.00         0.00 ",
> "   1841      107            0.00         0.00         0.00 ",
> "   1841      108            0.00         0.00         0.00 ",
> "   1841      109            0.00         0.00         0.00 ",
> "   1841      110+           0.00         0.00         0.00 ",
> "   1842        0        60290.60     62238.19    122528.79 ",
> "   1842        1        54893.31     55849.06    110742.37 ",
> "   1842        2        51991.87     53033.62    105025.49 ",
> "   1842        3        49697.90     50789.01    100486.91 ",
> "   1842        4        47598.24     48414.78     96013.02 ",
> "   1842        5        46202.38     47106.34     93308.72"
> )
> #-----------
>   BELe<-read.table(text=BE,
>                    header=FALSE, colClasses="numeric", as.is=TRUE)
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>    scan() expected 'a real', got '110+'
>
> I originally got this when reading from a file, but the error is from scan(). Was this an unfortunate side-effect of adding the `text` argument to read.table? It does still persist when the character string is pass through textConnection tot he file argument:
>
> BELe<-read.table(file=textConnection(BE),
>                   header=FALSE, colClasses="numeric")
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>    scan() expected 'a real', got '110+'
>
> My memory was that such coercion was effective in past years.
>


From smartpink111 at yahoo.com  Sat Dec 14 16:53:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 14 Dec 2013 07:53:16 -0800 (PST)
Subject: [R] iterated sum
In-Reply-To: <tencent_4EACA09A7136C89765BAF0BB@qq.com>
References: <tencent_4EACA09A7136C89765BAF0BB@qq.com>
Message-ID: <1387036396.93461.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:

?x[-1]+x[-length(x)]

A.K.


On Saturday, December 14, 2013 5:46 AM, ???? <1248283536 at qq.com> wrote:
x<-c(1,4,9,20,3,7)
i want to get a serie c(5,13,29,23,10).
y <- c()
for (i in 2:length(x)){
? ?  y[i-1] <- x[i-1]+x[i]}

is there more simple way to get?
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Sat Dec 14 17:43:07 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 14 Dec 2013 08:43:07 -0800
Subject: [R] Minutes after midnight to time
In-Reply-To: <CAJhyqVhKk=X6_UBwpOcnWUVRQrM7kWXJfUQiDxPBq3VNUTZusA@mail.gmail.com>
References: <CAJhyqVhKk=X6_UBwpOcnWUVRQrM7kWXJfUQiDxPBq3VNUTZusA@mail.gmail.com>
Message-ID: <D5F94B0B-9046-4AAA-80BF-A4A42269C855@comcast.net>


On Dec 13, 2013, at 1:34 PM, Trevor Davies wrote:

> Is there a quick function that can convert minutes (seconds) after midnight
> to a time?
> 
> i.e 670.93 (minutes after midnight) --> 11:10:56.**
> 
> I know it can be done by hand but I thought there must be a function for
> this already.

format( as.POSIXct(Sys.Date()) + 670.93*60,
        format="%H:%M:%S", tz="UCT")

[1] "11:10:55"

> 
> Thank you.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Dec 14 17:50:19 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 14 Dec 2013 08:50:19 -0800
Subject: [R] colClasses does not cause read.table to coerce to numeric;
	anymore?
In-Reply-To: <52AC7EDD.1050602@statistik.tu-dortmund.de>
References: <1807A00B-1687-48F7-BF97-5C1B8C237281@comcast.net>
	<52AC7EDD.1050602@statistik.tu-dortmund.de>
Message-ID: <41E805A6-A6CB-432C-88ED-2756D323F57E@comcast.net>


On Dec 14, 2013, at 7:53 AM, Uwe Ligges wrote:

> David,
> 
> how should R interpret "110+"? It cannot be numeric, perhaps you have not recognized the "+" there?
> 

I specifically included the fragment ofthe much longer file that was throwing the error. If this behavior doesn't appear flawed to you, Uwe, then am apparently under the misapprehension that it in the past it would have been coerced to NA.

-- 
David.



> Uwe
> 
> 
> 
> 
> On 14.12.2013 01:35, David Winsemius wrote:
>> 
>> I thought that setting colClasses to numeric would coerce errant data to NA. Instead read.table is throwing
>> errors. This is not what I remember from prior experience with read.table and it is not how I read the help page as promising:
>> 
>> BE<-
>> c("   1841       96           42.26        31.50        73.75 ",
>> "   1841       97           29.56        20.78        50.34 ",
>> "   1841       98           18.71        10.59        29.30 ",
>> "   1841       99           10.48         6.23        16.71 ",
>> "   1841      100            6.14         4.23        10.37 ",
>> "   1841      101            3.31         2.06         5.38 ",
>> "   1841      102            1.50         0.83         2.34 ",
>> "   1841      103            0.33         0.05         0.38 ",
>> "   1841      104            0.00         0.00         0.00 ",
>> "   1841      105            0.00         0.00         0.00 ",
>> "   1841      106            0.00         0.00         0.00 ",
>> "   1841      107            0.00         0.00         0.00 ",
>> "   1841      108            0.00         0.00         0.00 ",
>> "   1841      109            0.00         0.00         0.00 ",
>> "   1841      110+           0.00         0.00         0.00 ",
>> "   1842        0        60290.60     62238.19    122528.79 ",
>> "   1842        1        54893.31     55849.06    110742.37 ",
>> "   1842        2        51991.87     53033.62    105025.49 ",
>> "   1842        3        49697.90     50789.01    100486.91 ",
>> "   1842        4        47598.24     48414.78     96013.02 ",
>> "   1842        5        46202.38     47106.34     93308.72"
>> )
>> #-----------
>>  BELe<-read.table(text=BE,
>>                   header=FALSE, colClasses="numeric", as.is=TRUE)
>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>   scan() expected 'a real', got '110+'
>> 
>> I originally got this when reading from a file, but the error is from scan(). Was this an unfortunate side-effect of adding the `text` argument to read.table? It does still persist when the character string is pass through textConnection tot he file argument:
>> 
>> BELe<-read.table(file=textConnection(BE),
>>                  header=FALSE, colClasses="numeric")
>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>   scan() expected 'a real', got '110+'
>> 
>> My memory was that such coercion was effective in past years.
>> 

David Winsemius
Alameda, CA, USA


From elham_h763 at yahoo.com  Sat Dec 14 15:34:27 2013
From: elham_h763 at yahoo.com (Patty Haaem)
Date: Sat, 14 Dec 2013 06:34:27 -0800 (PST)
Subject: [R] converting a coloumn in a data set to a vector
Message-ID: <1387031667.79756.YahooMailNeo@web141102.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131214/5f1c6f7d/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sat Dec 14 18:05:46 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 14 Dec 2013 18:05:46 +0100
Subject: [R] Invalid connection error message when trying to write a file
In-Reply-To: <1386961869720-4682149.post@n4.nabble.com>
References: <1386961869720-4682149.post@n4.nabble.com>
Message-ID: <52AC8FEA.2090905@statistik.tu-dortmund.de>



On 13.12.2013 20:11, J Karon wrote:
> I get an invalid connection method error message when trying to write an R
> object from a user-defined function to my hard drive (running Windows 7)
> using write.csv.  I have previously not had this problem with the same
> user-defined function.  The error message is
>
> Error in isOpen(file, "w") : invalid connection
> In addition: Warning message:
> In if (file == "") file <- stdout() else if (is.character(file)) { :
>    the condition has length > 1 and only the first element will be used
>
> Using
> zz<-file(description="path","w")
> write.csv(  )
> close(zz)
>
> creates an empty file but yields the same error message when I execute
> write.csv.


Please tell us what you actually did.

This works for me:

zz <- file(description="path", "w")
write.csv(iris, zz)
close(zz)

Best,
Uwe Ligges


From ligges at statistik.tu-dortmund.de  Sat Dec 14 18:13:05 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 14 Dec 2013 18:13:05 +0100
Subject: [R] colClasses does not cause read.table to coerce to numeric;
 anymore?
In-Reply-To: <41E805A6-A6CB-432C-88ED-2756D323F57E@comcast.net>
References: <1807A00B-1687-48F7-BF97-5C1B8C237281@comcast.net>
	<52AC7EDD.1050602@statistik.tu-dortmund.de>
	<41E805A6-A6CB-432C-88ED-2756D323F57E@comcast.net>
Message-ID: <52AC91A1.8060205@statistik.tu-dortmund.de>



On 14.12.2013 17:50, David Winsemius wrote:
>
> On Dec 14, 2013, at 7:53 AM, Uwe Ligges wrote:
>
>> David,
>>
>> how should R interpret "110+"? It cannot be numeric, perhaps you have not recognized the "+" there?
>>
>
> I specifically included the fragment ofthe much longer file that was throwing the error. If this behavior doesn't appear flawed to you, Uwe, then am apparently under the misapprehension that it in the past it would have been coerced to NA.
>


It is the behaviour since R-1.7.1 at least, and I have no older versions 
installed...

Best,
Uwe


From istazahn at gmail.com  Sat Dec 14 18:24:02 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 14 Dec 2013 12:24:02 -0500
Subject: [R] Chinese Garbled
In-Reply-To: <1386998521870-4682184.post@n4.nabble.com>
References: <1386998521870-4682184.post@n4.nabble.com>
Message-ID: <CA+vqiLHsytJAT8sXkbbGvzML0fcKuvdGjLALLm4WCa6JLiOJRA@mail.gmail.com>

This is the R-help mailing list. If your problem persists when using R
from the command line or with the GUI shipped with R on your
(unspecified) platform post back here. Otherwise the RStudio support
forum is at https://support.rstudio.com

Best,
Ista

On Sat, Dec 14, 2013 at 12:22 AM, yuanzhi <yuanzhi.li at usherbrooke.ca> wrote:
> Hello, I met a problem which needs your help. I reinstalled the R and Rstudio
> recently. After that, I found there was a problem that the Chinese character
> was garbled in Rstudio sometimes.
>
> example 1
> "richness.csv" is a file containing three columns and the names of the three
> columns are "????"??????"???"? But when I read this file with function
> "read.csv" and displayed, these Chinese characters are garbled like the
> followings?
>> x<-read.csv("richness.csv")
>> x[1:5,]
>   X..??? X.?? ???
> 1        CK    ?     34
> 2        CK    ?     43
> 3        CK    ?     45
> 4        CK    ?     41
> 5        CK    ?     33
>
> example2
>
> Sometimes the prompting message also contains garabled Chinese characters.
> For example, when I run "?bargraph.CI"(which is a function in package
> "sciplot") before I use the cammand "library(sciplot)", it will appear the
> following message with garbled Chinese characters:
>> ?bargraph.CI
> No documentation for ?argraph.CI?in specified packages and libraries:
> you could try ??bargraph.CI?
>
> So, what can I do to solve the problem. Thank you!
> Yuanzhi
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Chinese-Garbled-tp4682184.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From eliza_botto at hotmail.com  Sat Dec 14 18:29:06 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Sat, 14 Dec 2013 17:29:06 +0000
Subject: [R] plot two columns against one
In-Reply-To: <1387036132.85326.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <BLU170-W124EAA2E54DEE694C5EDF1189DE0@phx.gbl>,
	<1387036132.85326.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <BLU170-W152D9827056CB1A2B9999589DE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131214/c2bb8728/attachment.pl>

From dwinsemius at comcast.net  Sat Dec 14 18:37:20 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 14 Dec 2013 09:37:20 -0800
Subject: [R] converting a coloumn in a data set to a vector
In-Reply-To: <1387031667.79756.YahooMailNeo@web141102.mail.bf1.yahoo.com>
References: <1387031667.79756.YahooMailNeo@web141102.mail.bf1.yahoo.com>
Message-ID: <F572EBA1-F837-4F21-AB8B-CA333C9BBA08@comcast.net>


On Dec 14, 2013, at 6:34 AM, Patty Haaem wrote:

> Hi every one,
> I have a simple question. I want to make a vector from one of  the colomns in a data set. for example I have this data:
> x1 x2 x3
> 1   5   7
> 4   8   9
> 8    6  12
> 4   8   13
>  I want to convert x1 to a vector such as:
> x1= c(1,4,8,4)
> How I can do it?

?Extract

-- 

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Sat Dec 14 19:20:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 14 Dec 2013 10:20:33 -0800 (PST)
Subject: [R] converting a coloumn in a data set to a vector
In-Reply-To: <1387031667.79756.YahooMailNeo@web141102.mail.bf1.yahoo.com>
References: <1387031667.79756.YahooMailNeo@web141102.mail.bf1.yahoo.com>
Message-ID: <1387045233.81502.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:

dat1 <- read.table(text="x1 x2 x3
?1?? 5?? 7
?4?? 8?? 9
?8??? 6? 12
?4?? 8?? 13",sep="",header=TRUE)
?vec1 <- dat1[,1]
?vec1
#[1] 1 4 8 4
A.K.


On Saturday, December 14, 2013 12:55 PM, Patty Haaem <elham_h763 at yahoo.com> wrote:
Hi every one,
I have a simple question. I want to make a vector from one of? the colomns in a data set. for example I have this data:
x1 x2 x3
1?? 5? ?7
4?? 8?? 9
8??? 6??12
4?? 8?? 13
?I want to convert x1 to a vector such as:
x1= c(1,4,8,4)
How I can do it?
Thanks
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Dec 14 19:29:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 14 Dec 2013 10:29:48 -0800 (PST)
Subject: [R] plot two columns against one
In-Reply-To: <BLU170-W152D9827056CB1A2B9999589DE0@phx.gbl>
References: <BLU170-W124EAA2E54DEE694C5EDF1189DE0@phx.gbl>,
	<1387036132.85326.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<BLU170-W152D9827056CB1A2B9999589DE0@phx.gbl>
Message-ID: <1387045788.66358.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi Eliza,
Try:


ggplot(s,aes(x=A,y=B))+geom_point(colour="white",shape=21,size=4,aes(fill=factor(C)))+theme_bw()+theme(legend.position="none")
A.K.






On Saturday, December 14, 2013 12:29 PM, eliza botto <eliza_botto at hotmail.com> wrote:

Dear Arun and david,
Thanks for your reply. If instead of text i want to add points, what change in code should occur?

eliza


> Date: Sat, 14 Dec 2013 07:48:52 -0800
> From: smartpink111 at yahoo.com
> Subject: Re: [R] plot two columns against one
> To: r-help at r-project.org
> CC: eliza_botto at hotmail.com
> 
> HI,
> 
> Using ?ggplot()
> 
> s <-read.table(text="A????? B??????? C
> 0.451? 0.333? 1134???????? 
> 0.491? 0.270? 1433???? 
> 0.389? 0.249? 7784???? 
> 0.425? 0.819? 6677 
> 0.457? 0.429? 99053???? 
> 0.436? 0.524? 111049
> 0.423? 0.270? 121093
> 0.463? 0.315? 131019",sep="",header=TRUE)
> library(ggplot2)
> ggplot(s,aes(x=A,y=B,colour=C))+geom_text(label=s$C) + theme_bw()
> A.K.
> 
> 
> On Saturday, December 14, 2013 9:30 AM, eliza botto <eliza_botto at hotmail.com> wrote:
> Dear users of R,
> How can i plot the values in column "C" with "A" on x-axis and "B" on y-axis?s <-
> "A? ? ???B? ? ? ? C? ???0.451???0.333???1134? ? ? ? ? 
> 0.491???0.270???1433? ? ? 
> 0.389???0.249???7784? ? ? 
> 0.425???0.819???6677? 
> 0.457???0.429???99053? ? ? 
> 0.436???0.524???111049? ? ? 0.423???0.270???121093? ? ???0.463???0.315???131019 Thankyou very much in advance,
> Eliza
> ??? ???????? ?????? ??? ? 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gangchen6 at gmail.com  Sat Dec 14 21:09:05 2013
From: gangchen6 at gmail.com (Gang Chen)
Date: Sat, 14 Dec 2013 15:09:05 -0500
Subject: [R] Change factor levels
Message-ID: <CAHmzXO5RriQDPOHMqn=3FTyo7dS=x_aQXOovCBx0_86St6DXQw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131214/81c2968d/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sat Dec 14 21:30:37 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 14 Dec 2013 21:30:37 +0100
Subject: [R] Change factor levels
In-Reply-To: <CAHmzXO5RriQDPOHMqn=3FTyo7dS=x_aQXOovCBx0_86St6DXQw@mail.gmail.com>
References: <CAHmzXO5RriQDPOHMqn=3FTyo7dS=x_aQXOovCBx0_86St6DXQw@mail.gmail.com>
Message-ID: <52ACBFED.1070306@statistik.tu-dortmund.de>

On 14.12.2013 21:09, Gang Chen wrote:
> Suppose I have a dataframe 'd' defined as
>
>       L3 <- LETTERS[1:3]
>       d0 <- data.frame(cbind(x = 1, y = 1:10), fac = sample(L3, 10, replace
> = TRUE))
>       (d <- d0[d0$fac %in% c('A', 'B'),])
>
>    x y fac
> 2 1 2   B
> 3 1 3   A
> 4 1 4   A
> 5 1 5   A
> 6 1 6   B
> 8 1 8   A
>
> Even though factor 'fac' in 'd' only has 2 levels, but it seems to bear the
> birthmark of 3 levels from its parent 'd0':
>
> str(d)
>
> 'data.frame': 6 obs. of  3 variables:
>   $ x  : num  1 1 1 1 1 1
>   $ y  : num  2 3 4 5 6 8
>   $ fac: Factor w/ 3 levels "A","B","C": 2 1 1 1 2 1

d$fac <- factor(d$fac)
or
d$fac <- d$fac[,drop=TRUE]

Best,
Uwe Ligges

> How can I cut the umbilical cord so that factor 'fac' in 'd' would have an
> accurate birth certificate with the correct number of levels? Apparently
> the following does not work:
>
> levels(d$fac) <- c('A', 'B')
>
> Also any reason for this heritage?
>
> Thanks,
> Gang
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kehld at ktk.pte.hu  Sat Dec 14 21:30:54 2013
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?D=E1niel_Kehl?=)
Date: Sat, 14 Dec 2013 20:30:54 +0000
Subject: [R] Change factor levels
In-Reply-To: <CAHmzXO5RriQDPOHMqn=3FTyo7dS=x_aQXOovCBx0_86St6DXQw@mail.gmail.com>
References: <CAHmzXO5RriQDPOHMqn=3FTyo7dS=x_aQXOovCBx0_86St6DXQw@mail.gmail.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B90CA5C@EMAIL.ktkdom.pte.hu>

Dear Gang,

this seem to solve your problem.

http://stackoverflow.com/questions/1195826/dropping-factor-levels-in-a-subsetted-data-frame-in-r


best
daniel
________________________________________
Felad?: r-help-bounces at r-project.org [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Gang Chen [gangchen6 at gmail.com]
K?ldve: 2013. december 14. 21:09
To: r-help
T?rgy: [R] Change factor levels

Suppose I have a dataframe 'd' defined as

     L3 <- LETTERS[1:3]
     d0 <- data.frame(cbind(x = 1, y = 1:10), fac = sample(L3, 10, replace
= TRUE))
     (d <- d0[d0$fac %in% c('A', 'B'),])

  x y fac
2 1 2   B
3 1 3   A
4 1 4   A
5 1 5   A
6 1 6   B
8 1 8   A

Even though factor 'fac' in 'd' only has 2 levels, but it seems to bear the
birthmark of 3 levels from its parent 'd0':

str(d)

'data.frame': 6 obs. of  3 variables:
 $ x  : num  1 1 1 1 1 1
 $ y  : num  2 3 4 5 6 8
 $ fac: Factor w/ 3 levels "A","B","C": 2 1 1 1 2 1

How can I cut the umbilical cord so that factor 'fac' in 'd' would have an
accurate birth certificate with the correct number of levels? Apparently
the following does not work:

levels(d$fac) <- c('A', 'B')

Also any reason for this heritage?

Thanks,
Gang

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gangchen6 at gmail.com  Sat Dec 14 22:05:14 2013
From: gangchen6 at gmail.com (Gang Chen)
Date: Sat, 14 Dec 2013 16:05:14 -0500
Subject: [R] Change factor levels
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D0B90CA5C@EMAIL.ktkdom.pte.hu>
References: <CAHmzXO5RriQDPOHMqn=3FTyo7dS=x_aQXOovCBx0_86St6DXQw@mail.gmail.com>
	<33D76D77E9AC4B438DA38B348ED6890D0B90CA5C@EMAIL.ktkdom.pte.hu>
Message-ID: <CAHmzXO464Ei6T4EVMG3SS4WxP24j3YhTQX3AqaUPE6Q1r0zVnw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131214/d30764b9/attachment.pl>

From davidmarino838 at gmail.com  Sat Dec 14 22:06:21 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Sat, 14 Dec 2013 13:06:21 -0800
Subject: [R] How to use variables whose names are with number at end in R
	loop
Message-ID: <CABmD0bF=wxpth0LP_qKjUJRfnp57MEm=4=vaB2tyDz9VtMYDXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131214/f0aee0d5/attachment.pl>

From smartpink111 at yahoo.com  Sat Dec 14 22:22:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 14 Dec 2013 13:22:45 -0800 (PST)
Subject: [R] How to use variables whose names are with number at end in
	R	loop
In-Reply-To: <CABmD0bF=wxpth0LP_qKjUJRfnp57MEm=4=vaB2tyDz9VtMYDXw@mail.gmail.com>
References: <CABmD0bF=wxpth0LP_qKjUJRfnp57MEm=4=vaB2tyDz9VtMYDXw@mail.gmail.com>
Message-ID: <1387056165.44117.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,

If the variables described are the columns in a data.frame,

? set.seed(24)
?dat1 <- as.data.frame(matrix(sample(100,100*10,replace=TRUE),ncol=100))
?f1 <- function(x) mean(x,na.rm=TRUE) 
?sapply(1:100,function(i) f1(dat1[,i]))
#or
?sapply(colnames(dat1),function(x) f1(dat1[,x]))

#IF these are standalone vectors
V1 <- dat1[,1]
?V2 <- dat1[,2]
sapply(1:2,function(i) f1(get(paste0("V",i))))

A.K.



On Saturday, December 14, 2013 4:07 PM, Marino David <davidmarino838 at gmail.com> wrote:
Hi all:

Assume that I have variables, say v1, v2,...,v100 and I want to use one
variable in each roop. How can I do this? See below

for (i in 1:100){
f(vi)
}


Thanks

David

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From hpages at fhcrc.org  Sat Dec 14 22:43:55 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Sat, 14 Dec 2013 13:43:55 -0800
Subject: [R] How to use variables whose names are with number at end in
 R loop
In-Reply-To: <CABmD0bF=wxpth0LP_qKjUJRfnp57MEm=4=vaB2tyDz9VtMYDXw@mail.gmail.com>
References: <CABmD0bF=wxpth0LP_qKjUJRfnp57MEm=4=vaB2tyDz9VtMYDXw@mail.gmail.com>
Message-ID: <52ACD11B.3050408@fhcrc.org>

Hi David,

On 12/14/2013 01:06 PM, Marino David wrote:
> Hi all:
>
> Assume that I have variables, say v1, v2,...,v100 and I want to use one
> variable in each roop. How can I do this? See below
>
> for (i in 1:100){
> f(vi)
> }

for (i in 1:100){
   f(get(paste0("v", i)))
}

Cheers,
H.

>
>
> Thanks
>
> David
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From dulcalma at bigpond.com  Sat Dec 14 23:29:45 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 15 Dec 2013 08:29:45 +1000
Subject: [R] plot two columns against one
In-Reply-To: <1387045788.66358.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <BLU170-W124EAA2E54DEE694C5EDF1189DE0@phx.gbl>,
	<1387036132.85326.YahooMailNeo@web142602.mail.bf1.yahoo.com>	<BLU170-W152D9827056CB1A2B9999589DE0@phx.gbl>
	<1387045788.66358.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <000c01cef91b$fdca9b70$f95fd250$@bigpond.com>

or for a different view

library(lattice)

xyplot(B+C ~A, data = s, 
            outer = T, 
           scales = list(relation = "free"), 
          pch = as.numeric(rownames(s)), 
          col = as.numeric(rownames(s)))

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of arun
Sent: Sunday, 15 December 2013 04:30
To: R help
Subject: Re: [R] plot two columns against one

Hi Eliza,
Try:


ggplot(s,aes(x=A,y=B))+geom_point(colour="white",shape=21,size=4,aes(fill=fa
ctor(C)))+theme_bw()+theme(legend.position="none")
A.K.






On Saturday, December 14, 2013 12:29 PM, eliza botto
<eliza_botto at hotmail.com> wrote:

Dear Arun and david,
Thanks for your reply. If instead of text i want to add points, what change
in code should occur?

eliza


> Date: Sat, 14 Dec 2013 07:48:52 -0800
> From: smartpink111 at yahoo.com
> Subject: Re: [R] plot two columns against one
> To: r-help at r-project.org
> CC: eliza_botto at hotmail.com
> 
> HI,
> 
> Using ?ggplot()
> 
> s <-read.table(text="A????? B??????? C
> 0.451? 0.333? 1134
> 0.491? 0.270? 1433
> 0.389? 0.249? 7784
> 0.425? 0.819? 6677
> 0.457? 0.429? 99053
> 0.436? 0.524? 111049
> 0.423? 0.270? 121093
> 0.463? 0.315? 131019",sep="",header=TRUE)
> library(ggplot2)
> ggplot(s,aes(x=A,y=B,colour=C))+geom_text(label=s$C) + theme_bw() A.K.
> 
> 
> On Saturday, December 14, 2013 9:30 AM, eliza botto
<eliza_botto at hotmail.com> wrote:
> Dear users of R,
> How can i plot the values in column "C" with "A" on x-axis and "B" on 
> y-axis?s <- "A? ? ???B? ? ? ? C? ???0.451???0.333???1134
> 0.491???0.270???1433
> 0.389???0.249???7784
> 0.425???0.819???6677
> 0.457???0.429???99053
> 0.436???0.524???111049? ? ? 0.423???0.270???121093? ? ???0.463???0.315???
> 131019 Thankyou very much in advance, Eliza
> ??? ???????? ?????? ??? ? 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Sat Dec 14 23:39:17 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 15 Dec 2013 08:39:17 +1000
Subject: [R] data point labeling in xyplot
In-Reply-To: <52AB473A.6060600@gmail.com>
References: <52AB473A.6060600@gmail.com>
Message-ID: <000d01cef91d$52bbcbd0$f8336370$@bigpond.com>

Hi 

have a look at the latticeExtra package

library(latticeExtra)
? useOuterStrips

or
xyplot(y~x| paste(grouping1, grouping2), data=na.omit(mydata), layout =
c(...

HTH

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of peyman
Sent: Saturday, 14 December 2013 03:43
To: r-help at r-project.org
Subject: [R] data point labeling in xyplot

Hi Folks,

I have data with a format like:

ID    y    param1    param2    groupingFactor1    groupingFactor2.....
1    ...   
1
1
1
2
2
2
2
3
3
3

so several grouping factors and repeated measures. I am using trellis and
xyplot to get plot with several grouping factors.
something like xyplot(y~x|grouping1*grouping2, data=na.omit(mydata),
panel=function{panel.xyplot(x,y);....}); Lets say x is the x axis parameter
and y the one for y.
So this will produce a plot with 4 windows which groups data according to
all combinations of groupingFactor1 and groupingFactor2.

Now I want to label the data points in each of these four plot windows with
the "ID" (ID is an integer representing the subject number). I used the
ltext(x=x,y=y,...), but then it uses the superscripts for the all data set
and dose not mark the data correctly. It only works if I ignore the grouping
and have all my data in one single plot window. It seems that I should
somehow pass the correct subscripts for the data in each plot window (or
group), but I could not figure it out.

thanks,

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From davidmarino838 at gmail.com  Sat Dec 14 23:47:09 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Sat, 14 Dec 2013 14:47:09 -0800
Subject: [R] How to use variables whose names are with number at end in
	R loop
In-Reply-To: <52ACD11B.3050408@fhcrc.org>
References: <CABmD0bF=wxpth0LP_qKjUJRfnp57MEm=4=vaB2tyDz9VtMYDXw@mail.gmail.com>
	<52ACD11B.3050408@fhcrc.org>
Message-ID: <CABmD0bEEPKTeyqJMkHtATXKteRw8Xy75xd808G4_CNWmG0cxwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131214/4a57f070/attachment.pl>

From friendly at yorku.ca  Sat Dec 14 23:50:00 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 14 Dec 2013 17:50:00 -0500
Subject: [R] extracting non-NA entries from a two-way frequency table
In-Reply-To: <1386964895.27485.59344777.0EFDA5B8@webmail.messagingengine.com>
References: <52AB6306.7000308@yorku.ca>
	<1386964895.27485.59344777.0EFDA5B8@webmail.messagingengine.com>
Message-ID: <52ACE098.6030104@yorku.ca>

Very elegant! Thank you Eric.

(You omitted library(plyr), so I had to search for arrange())

-Michael

On 12/13/2013 3:01 PM, rmailbox at justemail.net wrote:
> Perhaps this?
>
> library(reshape2)
> library(stringr)
>
> GeisslerLong <- melt (Geissler, id.vars = c("boys"))
> GeisslerLong <- transform ( GeisslerLong, girls = as.numeric ( str_replace( variable, "g", '' )) )
> GeisslerLong <- rename ( GeisslerLong, c( value = "Freq"))
> GeisslerLong <- arrange ( GeisslerLong, boys, girls)
> GeisslerLong <- subset ( GeisslerLong, !is.na ( Freq), select = c( boys, girls, Freq))
>
>
> Eric
>
>
> ----- Original message -----
> From: Michael Friendly <friendly at yorku.ca>
> To: "R-help" <r-help at r-project.org>
> Subject: [R] extracting non-NA entries from a two-way frequency table
> Date: Fri, 13 Dec 2013 14:41:58 -0500
>
> I have data in the form of a two-way table recording the number of
> families with varying numbers
> of boys (rows) and girls (columns: g0 -- g12) below, also given in
> dput() format.
>
> I want to convert this to a data frame containing only the non-NA
> entries, with columns
> boys, girls, Freq, where Freq is the table entry.  Can anyone help with
> this?
> I suppose that the steps are to transpose each row to a column
> identifying the number of
> girls, and then delete the NAs, but I can't quite see how to do this.
>
>
>   > Geissler
>      boys     g0     g1    g2    g3    g4   g5   g6   g7  g8 g9 g10 g11 g12
> 1    12      7     NA    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 2    11     24     45    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 3    10     30     93   181    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 4     9     90    287   492   478    NA   NA   NA   NA  NA NA  NA  NA  NA
> 5     8    264    713  1027  1077   829   NA   NA   NA  NA NA  NA  NA  NA
> 6     7    631   1655  2418  2309  1801 1112   NA   NA  NA NA  NA  NA  NA
> 7     6   1579   3725  4948  4757  3470 2310 1343   NA  NA NA  NA  NA  NA
> 8     5   3666   7908  9547  8498  6436 3878 2161 1033  NA NA  NA  NA  NA
> 9     4   8628  16340 17332 14479 10263 5917 3072 1540 670 NA  NA  NA  NA
> 10    3  20540  31611 30175 22221 13972 7603 3895 1783 837 286  NA  NA  NA
> 11    2  47819  57179 44793 28630 15700 8171 3951 1776 722 275 104  NA  NA
> 12    1 114609  89213 53789 28101 13740 6233 2719 1152 432 151  72  24  NA
> 13    0     NA 108719 42860 17395  7004 2839 1096  436 161 66  30   8   3
>
> Geissler <-
> structure(list(boys = c(12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L,
> 3L, 2L, 1L, 0L), g0 = c(7L, 24L, 30L, 90L, 264L, 631L, 1579L,
> 3666L, 8628L, 20540L, 47819L, 114609L, NA), g1 = c(NA, 45L, 93L,
> 287L, 713L, 1655L, 3725L, 7908L, 16340L, 31611L, 57179L, 89213L,
> 108719L), g2 = c(NA, NA, 181L, 492L, 1027L, 2418L, 4948L, 9547L,
> 17332L, 30175L, 44793L, 53789L, 42860L), g3 = c(NA, NA, NA, 478L,
> 1077L, 2309L, 4757L, 8498L, 14479L, 22221L, 28630L, 28101L, 17395L
> ), g4 = c(NA, NA, NA, NA, 829L, 1801L, 3470L, 6436L, 10263L,
> 13972L, 15700L, 13740L, 7004L), g5 = c(NA, NA, NA, NA, NA, 1112L,
> 2310L, 3878L, 5917L, 7603L, 8171L, 6233L, 2839L), g6 = c(NA,
> NA, NA, NA, NA, NA, 1343L, 2161L, 3072L, 3895L, 3951L, 2719L,
> 1096L), g7 = c(NA, NA, NA, NA, NA, NA, NA, 1033L, 1540L, 1783L,
> 1776L, 1152L, 436L), g8 = c(NA, NA, NA, NA, NA, NA, NA, NA, 670L,
> 837L, 722L, 432L, 161L), g9 = c(NA, NA, NA, NA, NA, NA, NA, NA,
> NA, 286L, 275L, 151L, 66L), g10 = c(NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, 104L, 72L, 30L), g11 = c(NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, 24L, 8L), g12 = c(NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, 3L)), .Names = c("boys", "g0", "g1",
> "g2", "g3", "g4", "g5", "g6", "g7", "g8", "g9", "g10", "g11",
> "g12"), class = "data.frame", row.names = c(NA, -13L))
>
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From friendly at yorku.ca  Sat Dec 14 23:50:00 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 14 Dec 2013 17:50:00 -0500
Subject: [R] extracting non-NA entries from a two-way frequency table
In-Reply-To: <1386964895.27485.59344777.0EFDA5B8@webmail.messagingengine.com>
References: <52AB6306.7000308@yorku.ca>
	<1386964895.27485.59344777.0EFDA5B8@webmail.messagingengine.com>
Message-ID: <52ACE098.6030104@yorku.ca>

Very elegant! Thank you Eric.

(You omitted library(plyr), so I had to search for arrange())

-Michael

On 12/13/2013 3:01 PM, rmailbox at justemail.net wrote:
> Perhaps this?
>
> library(reshape2)
> library(stringr)
>
> GeisslerLong <- melt (Geissler, id.vars = c("boys"))
> GeisslerLong <- transform ( GeisslerLong, girls = as.numeric ( str_replace( variable, "g", '' )) )
> GeisslerLong <- rename ( GeisslerLong, c( value = "Freq"))
> GeisslerLong <- arrange ( GeisslerLong, boys, girls)
> GeisslerLong <- subset ( GeisslerLong, !is.na ( Freq), select = c( boys, girls, Freq))
>
>
> Eric
>
>
> ----- Original message -----
> From: Michael Friendly <friendly at yorku.ca>
> To: "R-help" <r-help at r-project.org>
> Subject: [R] extracting non-NA entries from a two-way frequency table
> Date: Fri, 13 Dec 2013 14:41:58 -0500
>
> I have data in the form of a two-way table recording the number of
> families with varying numbers
> of boys (rows) and girls (columns: g0 -- g12) below, also given in
> dput() format.
>
> I want to convert this to a data frame containing only the non-NA
> entries, with columns
> boys, girls, Freq, where Freq is the table entry.  Can anyone help with
> this?
> I suppose that the steps are to transpose each row to a column
> identifying the number of
> girls, and then delete the NAs, but I can't quite see how to do this.
>
>
>   > Geissler
>      boys     g0     g1    g2    g3    g4   g5   g6   g7  g8 g9 g10 g11 g12
> 1    12      7     NA    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 2    11     24     45    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 3    10     30     93   181    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 4     9     90    287   492   478    NA   NA   NA   NA  NA NA  NA  NA  NA
> 5     8    264    713  1027  1077   829   NA   NA   NA  NA NA  NA  NA  NA
> 6     7    631   1655  2418  2309  1801 1112   NA   NA  NA NA  NA  NA  NA
> 7     6   1579   3725  4948  4757  3470 2310 1343   NA  NA NA  NA  NA  NA
> 8     5   3666   7908  9547  8498  6436 3878 2161 1033  NA NA  NA  NA  NA
> 9     4   8628  16340 17332 14479 10263 5917 3072 1540 670 NA  NA  NA  NA
> 10    3  20540  31611 30175 22221 13972 7603 3895 1783 837 286  NA  NA  NA
> 11    2  47819  57179 44793 28630 15700 8171 3951 1776 722 275 104  NA  NA
> 12    1 114609  89213 53789 28101 13740 6233 2719 1152 432 151  72  24  NA
> 13    0     NA 108719 42860 17395  7004 2839 1096  436 161 66  30   8   3
>
> Geissler <-
> structure(list(boys = c(12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L,
> 3L, 2L, 1L, 0L), g0 = c(7L, 24L, 30L, 90L, 264L, 631L, 1579L,
> 3666L, 8628L, 20540L, 47819L, 114609L, NA), g1 = c(NA, 45L, 93L,
> 287L, 713L, 1655L, 3725L, 7908L, 16340L, 31611L, 57179L, 89213L,
> 108719L), g2 = c(NA, NA, 181L, 492L, 1027L, 2418L, 4948L, 9547L,
> 17332L, 30175L, 44793L, 53789L, 42860L), g3 = c(NA, NA, NA, 478L,
> 1077L, 2309L, 4757L, 8498L, 14479L, 22221L, 28630L, 28101L, 17395L
> ), g4 = c(NA, NA, NA, NA, 829L, 1801L, 3470L, 6436L, 10263L,
> 13972L, 15700L, 13740L, 7004L), g5 = c(NA, NA, NA, NA, NA, 1112L,
> 2310L, 3878L, 5917L, 7603L, 8171L, 6233L, 2839L), g6 = c(NA,
> NA, NA, NA, NA, NA, 1343L, 2161L, 3072L, 3895L, 3951L, 2719L,
> 1096L), g7 = c(NA, NA, NA, NA, NA, NA, NA, 1033L, 1540L, 1783L,
> 1776L, 1152L, 436L), g8 = c(NA, NA, NA, NA, NA, NA, NA, NA, 670L,
> 837L, 722L, 432L, 161L), g9 = c(NA, NA, NA, NA, NA, NA, NA, NA,
> NA, 286L, 275L, 151L, 66L), g10 = c(NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, 104L, 72L, 30L), g11 = c(NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, 24L, 8L), g12 = c(NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, 3L)), .Names = c("boys", "g0", "g1",
> "g2", "g3", "g4", "g5", "g6", "g7", "g8", "g9", "g10", "g11",
> "g12"), class = "data.frame", row.names = c(NA, -13L))
>
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From 1248283536 at qq.com  Sun Dec 15 09:17:42 2013
From: 1248283536 at qq.com (=?gb18030?B?y66+ssH3ye4=?=)
Date: Sun, 15 Dec 2013 16:17:42 +0800
Subject: [R] how can i add Qtr1 Qtr2 Qtr3 Qtr4  on the x axis?
Message-ID: <tencent_7EEF3A62178563412F5FFC26@qq.com>

> x<-ts(sales,frequency=4,start=c(2010,1))
> x
     Qtr1 Qtr2 Qtr3 Qtr4
2010  1.8  8.0  6.0  3.0
2011  2.0 11.0  7.0  3.5
2012  2.5 14.0  8.0  4.2
2013  3.0 15.2  9.5  5.0
> plot.ts(x)

From kehld at ktk.pte.hu  Sun Dec 15 10:50:31 2013
From: kehld at ktk.pte.hu (=?gb2312?B?RKiibmllbCBLZWhs?=)
Date: Sun, 15 Dec 2013 09:50:31 +0000
Subject: [R] [Probable spam] RE: how can i add Qtr1 Qtr2 Qtr3 Qtr4 on the x
 axis?
In-Reply-To: <tencent_7EEF3A62178563412F5FFC26@qq.com>
References: <tencent_7EEF3A62178563412F5FFC26@qq.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B92DE19@EMAIL.ktkdom.pte.hu>

Hi,

try

?axis.Date

works similar to the axis function.

I hope that helps!
daniel
________________________________________
Felad?: r-help-bounces at r-project.org [r-help-bounces at r-project.org] ; meghatalmaz&#243;: ???? [1248283536 at qq.com]
K?ldve: 2013. december 15. 9:17
To: r-help
T?rgy: [R] how can i add Qtr1 Qtr2 Qtr3 Qtr4  on the x axis?

> x<-ts(sales,frequency=4,start=c(2010,1))
> x
     Qtr1 Qtr2 Qtr3 Qtr4
2010  1.8  8.0  6.0  3.0
2011  2.0 11.0  7.0  3.5
2012  2.5 14.0  8.0  4.2
2013  3.0 15.2  9.5  5.0
> plot.ts(x)

From 1248283536 at qq.com  Sun Dec 15 12:43:57 2013
From: 1248283536 at qq.com (=?gb18030?B?y66+ssH3ye4=?=)
Date: Sun, 15 Dec 2013 19:43:57 +0800
Subject: [R] why there is no quarters?
Message-ID: <tencent_75A9BC3969069B6F741B44C2@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131215/5b80c62b/attachment.pl>

From 1248283536 at qq.com  Sun Dec 15 12:48:45 2013
From: 1248283536 at qq.com (=?gb18030?B?y66+ssH3ye4=?=)
Date: Sun, 15 Dec 2013 19:48:45 +0800
Subject: [R] why  as.vector can't make x to be a vector?
Message-ID: <tencent_6AC1349A6FF2F3F876117AEA@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131215/679a750f/attachment.pl>

From murdoch.duncan at gmail.com  Sun Dec 15 13:11:25 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 15 Dec 2013 07:11:25 -0500
Subject: [R] why there is no quarters?
In-Reply-To: <tencent_75A9BC3969069B6F741B44C2@qq.com>
References: <tencent_75A9BC3969069B6F741B44C2@qq.com>
Message-ID: <52AD9C6D.9050807@gmail.com>

On 13-12-15 6:43 AM, ???? wrote:
> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"years")
> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"weeks")
> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"days")
>
> why there is no
> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"quarters")  ?

There's no need for it.  Just use months, and take every 3rd one:
	
x <- seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"months")
x[seq_along(x) %% 3 == 1]


From murdoch.duncan at gmail.com  Sun Dec 15 13:12:13 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 15 Dec 2013 07:12:13 -0500
Subject: [R] why  as.vector can't make x to be a vector?
In-Reply-To: <tencent_6AC1349A6FF2F3F876117AEA@qq.com>
References: <tencent_6AC1349A6FF2F3F876117AEA@qq.com>
Message-ID: <52AD9C9D.1030007@gmail.com>

On 13-12-15 6:48 AM, ???? wrote:
>> x=read.table(text="
> +   Qtr1 Qtr2 Qtr3 Qtr4
> + 2010  1.8  8.0  6.0  3.0
> + 2011  2.0 11.0  7.0  3.5
> + 2012  2.5 14.0  8.0  4.2
> + 2013  3.0 15.2  9.5  5.0",sep="",header=TRUE)
>> x
>       Qtr1 Qtr2 Qtr3 Qtr4
> 2010  1.8  8.0  6.0  3.0
> 2011  2.0 11.0  7.0  3.5
> 2012  2.5 14.0  8.0  4.2
> 2013  3.0 15.2  9.5  5.0
>> as.vector(x)
>       Qtr1 Qtr2 Qtr3 Qtr4
> 2010  1.8  8.0  6.0  3.0
> 2011  2.0 11.0  7.0  3.5
> 2012  2.5 14.0  8.0  4.2
> 2013  3.0 15.2  9.5  5.0
>> class(as.vector(x))
> [1] "data.frame"

Data frames are lists, which are already vectors.

Duncan Murdoch


From 1248283536 at qq.com  Sun Dec 15 13:46:12 2013
From: 1248283536 at qq.com (=?gb18030?B?y66+ssH3ye4=?=)
Date: Sun, 15 Dec 2013 20:46:12 +0800
Subject: [R] how to  add a line in the graph?
Message-ID: <tencent_3BA8C4D2179533E50A5E6DDB@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131215/9b120f1e/attachment.pl>

From kehld at ktk.pte.hu  Sun Dec 15 14:02:57 2013
From: kehld at ktk.pte.hu (=?gb2312?B?RKiibmllbCBLZWhs?=)
Date: Sun, 15 Dec 2013 13:02:57 +0000
Subject: [R] [Probable spam]RE:  how to  add a line in the graph?
In-Reply-To: <tencent_3BA8C4D2179533E50A5E6DDB@qq.com>
References: <tencent_3BA8C4D2179533E50A5E6DDB@qq.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B92DE63@EMAIL.ktkdom.pte.hu>

t<- -4:4
y<-c(5,7,10,13,15,16,14,12,11)
plot(t,y,type="l", ylim=c(-20,20))

curve(0.83*x-0.44*x^2, add=TRUE)

I added ylim to plot so that your curve is on the graph. Maybe you wanted to use different parameters.

Try going through a basic manual of R!

daniel
________________________________________
Felad?: r-help-bounces at r-project.org [r-help-bounces at r-project.org] ; meghatalmaz&#243;: ???? [1248283536 at qq.com]
K?ldve: 2013. december 15. 13:46
To: r-help
T?rgy: [R] how to  add a line in the graph?

t<--4:4
y<-c(5,7,10,13,15,16,14,12,11)
plot(t,y,type="l")

how can i add a curve  y=0.83*t-0.44*t^2  in the graph?
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From ishaqbaba at yahoo.com  Sun Dec 15 15:53:24 2013
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Sun, 15 Dec 2013 06:53:24 -0800 (PST)
Subject: [R] RSM
Message-ID: <1387119204.40791.YahooMailNeo@web142506.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131215/ba172648/attachment.pl>

From kehld at ktk.pte.hu  Sun Dec 15 17:06:29 2013
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?D=E1niel_Kehl?=)
Date: Sun, 15 Dec 2013 16:06:29 +0000
Subject: [R] RSM
In-Reply-To: <1387119204.40791.YahooMailNeo@web142506.mail.bf1.yahoo.com>
References: <1387119204.40791.YahooMailNeo@web142506.mail.bf1.yahoo.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B92DEAA@EMAIL.ktkdom.pte.hu>

There is no variable called x1 in the chem dataframe.
Did you mean 

gg1=rsm(yield~ FO(x1,x2),data=ggg,subset = (Block == "B1"))

hth.
daniel
________________________________________
Felad?: r-help-bounces at r-project.org [r-help-bounces at r-project.org] ; meghatalmaz&#243;: IZHAK shabsogh [ishaqbaba at yahoo.com]
K?ldve: 2013. december 15. 15:53
To: r-help at r-project.org
T?rgy: [R] RSM

kindly help find out why the following code is given me error


time<-c(80,80,90,90,85,85,85,85,85,85,92,77,85,85)
> tem<-c(170,180,170,180,175,175,175,175,175,175,175,175,182.07,167.93)
> yield<-c(80.5,81.5,82,83.5,83.9,84.3,84,79.7,79.8,79.5,78.4,75.6,78.6,77)
> Block<-c("B1","B1","B1","B1","B1","B1","B1","B2","B2","B2","B2","B2","B2","B2")
> chem<-data.frame(time,tem,Block,yield)
> ggg<-coded.data(chem, x1 ~ (time - 85)/5, x2 ~ (tem - 175)/5)
> gg1=rsm(yield~ FO(x1,x2),data=chem,subset = (Block == "B1"))
Error in lapply(X = X, FUN = FUN, ...) : object 'x1' not found
> gg1=rsm(yield~ SO(x1,x2),data=chem,subset = (Block == "B1"))
Error in lapply(X = X, FUN = FUN, ...) : object 'x1' not found

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From f.harrell at Vanderbilt.Edu  Sun Dec 15 19:08:46 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Sun, 15 Dec 2013 12:08:46 -0600
Subject: [R] Simple way to define a function to be used in a formula object
 inside another function
Message-ID: <52ADF02E.6090101@vanderbilt.edu>

I would like to do this:

f <- function(formula, data=NULL) {
  gg <- sqrt
  model.frame(formula, data=data)
  }
x <- y <- 1:10
f(y ~ gg(x))
Error in eval(expr, envir, enclos) : could not find function "gg"

Is there a simple way to get access to gg from within the model.frame 
invocation inside f?

Thanks
Frank


From wdunlap at tibco.com  Sun Dec 15 19:46:48 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 15 Dec 2013 18:46:48 +0000
Subject: [R] Simple way to define a function to be used in a formula
 object inside another function
In-Reply-To: <52ADF02E.6090101@vanderbilt.edu>
References: <52ADF02E.6090101@vanderbilt.edu>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1D813@PA-MBX01.na.tibco.com>

The following works because model.frame looks for things in environment(formula)
and ancestral environments thereof.  It puts the new things in a child environment
of the original environment(formula) so it does not alter the original environment.

f2 <- function (formula, data = NULL) 
{
    environment(formula) <- new.env(parent = environment(formula))
    assign(envir = environment(formula), "gg", sqrt)
    model.frame(formula, data = data)
}

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Frank Harrell
> Sent: Sunday, December 15, 2013 10:09 AM
> To: RHELP
> Subject: [R] Simple way to define a function to be used in a formula object inside another
> function
> 
> I would like to do this:
> 
> f <- function(formula, data=NULL) {
>   gg <- sqrt
>   model.frame(formula, data=data)
>   }
> x <- y <- 1:10
> f(y ~ gg(x))
> Error in eval(expr, envir, enclos) : could not find function "gg"
> 
> Is there a simple way to get access to gg from within the model.frame
> invocation inside f?
> 
> Thanks
> Frank
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jkaron at earthlink.net  Sun Dec 15 20:13:31 2013
From: jkaron at earthlink.net (John Karon)
Date: Sun, 15 Dec 2013 12:13:31 -0700
Subject: [R] Invalid connection error message when trying to write a file
In-Reply-To: <52AC8FEA.2090905@statistik.tu-dortmund.de>
References: <1386961869720-4682149.post@n4.nabble.com>
	<52AC8FEA.2090905@statistik.tu-dortmund.de>
Message-ID: <84534FFA466443F391A41E56E6E45B27@JohnKaronHP>

The response below asks what I actually did.

I defined a function (details omitted; it computes the data frame 
LRtest.out); arguments include "path\\filename.csv" to which I want to write 
a data frame using write.csv(  ).  Repeated executions of the function 
(without the file(  ) and close(  ) instructions) were successful until 2 
days ago, when I received the error message below.  I simplified the code to 
write a file and received the error message below (same message as before) 
in response to the commands

zz<-file(description="c:\\LRtest.txt","w")
write.table(LRtest.out, file="c:\\LRtest.txt", sep="\t")
close(zz)

Error in file(description = "c:\\LRtest.txt", "w") :
  cannot open the connection
In addition: Warning message:
In file(description = "c:\\LRtest.txt", "w") :
  cannot open file 'c:\LRtest.txt': Permission denied

This happens whether there is no previous file with that name or an 
essentially empty file with that name.  In previous executions of code with 
a path to a folder, executing the file(  )  command would create an empty 
file.  Now no empty file is created.  The problem persists after rebooting 
the computer.

I also tried writing to the clipboard (description ="clipboard" in the 
file(  ) command); that was unsuccessful, with file="clipboard" or no file 
statement in the write.table(  ) command (Word showed there was something to 
paste, but pasting into an empty Word document did not put text into the 
document; with no file statement, the data frame was written to the 
console).

I question whether there is a setting that forbids writing to a file. 
Information on putting the data frame on the clipboard would also help. 
Thanks for any help.  John Karon

-----Original Message----- 
From: Uwe Ligges
Sent: Saturday, December 14, 2013 10:05 AM
To: J Karon ; r-help at r-project.org
Subject: Re: [R] Invalid connection error message when trying to write a 
file



On 13.12.2013 20:11, J Karon wrote:
> I get an invalid connection method error message when trying to write an R
> object from a user-defined function to my hard drive (running Windows 7)
> using write.csv.  I have previously not had this problem with the same
> user-defined function.  The error message is
>
> Error in isOpen(file, "w") : invalid connection
> In addition: Warning message:
> In if (file == "") file <- stdout() else if (is.character(file)) { :
>    the condition has length > 1 and only the first element will be used
>
> Using
> zz<-file(description="path","w")
> write.csv(  )
> close(zz)
>
> creates an empty file but yields the same error message when I execute
> write.csv.


Please tell us what you actually did.

This works for me:

zz <- file(description="path", "w")
write.csv(iris, zz)
close(zz)

Best,
Uwe Ligges


From ligges at statistik.tu-dortmund.de  Sun Dec 15 20:30:43 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 15 Dec 2013 20:30:43 +0100
Subject: [R] Invalid connection error message when trying to write a file
In-Reply-To: <84534FFA466443F391A41E56E6E45B27@JohnKaronHP>
References: <1386961869720-4682149.post@n4.nabble.com>	<52AC8FEA.2090905@statistik.tu-dortmund.de>
	<84534FFA466443F391A41E56E6E45B27@JohnKaronHP>
Message-ID: <52AE0363.2010705@statistik.tu-dortmund.de>



On 15.12.2013 20:13, John Karon wrote:
> The response below asks what I actually did.
>
> I defined a function (details omitted; it computes the data frame
> LRtest.out); arguments include "path\\filename.csv" to which I want to
> write a data frame using write.csv(  ).  Repeated executions of the
> function (without the file(  ) and close(  ) instructions) were
> successful until 2 days ago, when I received the error message below.  I
> simplified the code to write a file and received the error message below
> (same message as before) in response to the commands
>
> zz<-file(description="c:\\LRtest.txt","w")
> write.table(LRtest.out, file="c:\\LRtest.txt", sep="\t")
> close(zz)

Wrong, *either* use

write.table(LRtest.out, file="c:\\LRtest.txt", sep="\t")

or

zz <- file(description="c:\\LRtest.txt","w")
write.table(LRtest.out, file=zz, sep="\t")
close(zz)

Best,
Uwe Ligges







>
> Error in file(description = "c:\\LRtest.txt", "w") :
>   cannot open the connection
> In addition: Warning message:
> In file(description = "c:\\LRtest.txt", "w") :
>   cannot open file 'c:\LRtest.txt': Permission denied
>
> This happens whether there is no previous file with that name or an
> essentially empty file with that name.  In previous executions of code
> with a path to a folder, executing the file(  )  command would create an
> empty file.  Now no empty file is created.  The problem persists after
> rebooting the computer.
>
> I also tried writing to the clipboard (description ="clipboard" in the
> file(  ) command); that was unsuccessful, with file="clipboard" or no
> file statement in the write.table(  ) command (Word showed there was
> something to paste, but pasting into an empty Word document did not put
> text into the document; with no file statement, the data frame was
> written to the console).
>
> I question whether there is a setting that forbids writing to a file.
> Information on putting the data frame on the clipboard would also help.
> Thanks for any help.  John Karon
>
> -----Original Message----- From: Uwe Ligges
> Sent: Saturday, December 14, 2013 10:05 AM
> To: J Karon ; r-help at r-project.org
> Subject: Re: [R] Invalid connection error message when trying to write a
> file
>
>
>
> On 13.12.2013 20:11, J Karon wrote:
>> I get an invalid connection method error message when trying to write
>> an R
>> object from a user-defined function to my hard drive (running Windows 7)
>> using write.csv.  I have previously not had this problem with the same
>> user-defined function.  The error message is
>>
>> Error in isOpen(file, "w") : invalid connection
>> In addition: Warning message:
>> In if (file == "") file <- stdout() else if (is.character(file)) { :
>>    the condition has length > 1 and only the first element will be used
>>
>> Using
>> zz<-file(description="path","w")
>> write.csv(  )
>> close(zz)
>>
>> creates an empty file but yields the same error message when I execute
>> write.csv.
>
>
> Please tell us what you actually did.
>
> This works for me:
>
> zz <- file(description="path", "w")
> write.csv(iris, zz)
> close(zz)
>
> Best,
> Uwe Ligges
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sun Dec 15 20:35:28 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Sun, 15 Dec 2013 13:35:28 -0600
Subject: [R] why  as.vector can't make x to be a vector?
In-Reply-To: <52AD9C9D.1030007@gmail.com>
References: <tencent_6AC1349A6FF2F3F876117AEA@qq.com>
	<52AD9C9D.1030007@gmail.com>
Message-ID: <029501cef9cc$cf3b2ed0$6db18c70$@tamu.edu>

According to the documentation (?as.vector), "All attributes are removed from the result if it is of an atomic mode, but not in general for a list result."

data.frames are lists so

> is.vector(as.vector(x))
[1] FALSE

However if you convert using unlist() or as.matrix(), you will get a vector:

> is.vector(unlist(x))
[1] TRUE
> is.vector(as.vector(as.matrix(x)))
[1] TRUE


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: Sunday, December 15, 2013 6:12 AM
To: ????; r-help
Subject: Re: [R] why as.vector can't make x to be a vector?

On 13-12-15 6:48 AM, ???? wrote:
>> x=read.table(text="
> +   Qtr1 Qtr2 Qtr3 Qtr4
> + 2010  1.8  8.0  6.0  3.0
> + 2011  2.0 11.0  7.0  3.5
> + 2012  2.5 14.0  8.0  4.2
> + 2013  3.0 15.2  9.5  5.0",sep="",header=TRUE)
>> x
>       Qtr1 Qtr2 Qtr3 Qtr4
> 2010  1.8  8.0  6.0  3.0
> 2011  2.0 11.0  7.0  3.5
> 2012  2.5 14.0  8.0  4.2
> 2013  3.0 15.2  9.5  5.0
>> as.vector(x)
>       Qtr1 Qtr2 Qtr3 Qtr4
> 2010  1.8  8.0  6.0  3.0
> 2011  2.0 11.0  7.0  3.5
> 2012  2.5 14.0  8.0  4.2
> 2013  3.0 15.2  9.5  5.0
>> class(as.vector(x))
> [1] "data.frame"

Data frames are lists, which are already vectors.

Duncan Murdoch

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From f.harrell at Vanderbilt.Edu  Sun Dec 15 21:58:59 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Sun, 15 Dec 2013 14:58:59 -0600
Subject: [R] Simple way to define a function to be used in a formula
 object inside another function
Message-ID: <52AE1813.2070507@vanderbilt.edu>

Thank you Bill, that worked perfectly.
Frank


From j.david.hamer at gmail.com  Mon Dec 16 00:00:31 2013
From: j.david.hamer at gmail.com (david hamer)
Date: Sun, 15 Dec 2013 16:00:31 -0700
Subject: [R] Exporting R graphics into Word without losing graph quality
Message-ID: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131215/1f531d3d/attachment.pl>

From hb at biostat.ucsf.edu  Mon Dec 16 00:13:04 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 15 Dec 2013 15:13:04 -0800
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
Message-ID: <CAFDcVCSCGzuV85b8rmfCtfA_dn=++5gGfO8fDYk2xFVkODzaiw@mail.gmail.com>

See ?png and argument 'pointsize'.  You can increase that as you
increase the dimensions of the output image.

/Henrik

On Sun, Dec 15, 2013 at 3:00 PM, david hamer <j.david.hamer at gmail.com> wrote:
> Hello,
>
> My x-y scatterplot produces a very ragged best-fit line when imported into
> Word.
>
>
>
> * >plot (data.file$x, data.file$y, type = "p", las=1, pch=20,        ylab =
> expression("Cover of Species y" ~ (m^{2}~ha^{-1} )),        xlab =
> expression("Cover of Species x" ~ (m^{2}~ha^{-1}))  )    >lines  (
> data.file$x,   fitted ( model.x )  )*
>
>  A suggestion from the internet is to use .png at high (1200) resolution.
>    * >dev.print  ( device = png,  file = "R.graph.png",  width = 1200,
> height = 700)*
> This gives a high?quality graph, but the titles and tick?mark labels become
> very tiny when exported into Word.
>
> I therefore increased the size of the titles and tick?mark labels with cex.
>    * >plot (......cex =1.8, cex.lab = 1.8, cex.axis = 1.25,....)*
> But this causes the x?axis title to lie on top of the tick?mark labels.
> (This problem does not occur with the y?axis, where the title lies well
> away from the y?axis tick?mark labels.)
> Changing margins     * >par ( mai = c ( 1.3, 1.35, 1, .75 ) )*    does not
> seem to have any effect on this.
>
> A suggestion from the internet is to delete the titles from plot, and use
> mtext with line=4 to drop the title lower on the graph.
>
> * >plot (.......  ylab = " ", xlab = " ".....)    >mtext(side = 1, "Cover
> of Species x (superscripts??)", line = 4)*
> This works, but with mtext I have now lost the ability to have the
> superscripts in the axis title.
>
> And I am back full circle, having to lower the resolution of the graph to
> keep the x?axis title away from the axis, and thus reverting to a ragged,
> segmented ?line? when exported to Word......
>
> Final note:  The R graphics window version of the graph becomes very
> distorted, even though the graph may be of high quality (other than the
> problem of the x-axis title overlaying the x-axis tick-mark labels) once in
> Word.  I guess this is because of using ?tricks? to try to get a desired
> end-product in Word....
>
> Thanks for any suggestions,
>          David.
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hb at biostat.ucsf.edu  Mon Dec 16 00:15:16 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 15 Dec 2013 15:15:16 -0800
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <CAFDcVCSCGzuV85b8rmfCtfA_dn=++5gGfO8fDYk2xFVkODzaiw@mail.gmail.com>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
	<CAFDcVCSCGzuV85b8rmfCtfA_dn=++5gGfO8fDYk2xFVkODzaiw@mail.gmail.com>
Message-ID: <CAFDcVCTfaxZeku6jPsEVRA3z-DVxMOPqcSmJbdYX-6hO8wHing@mail.gmail.com>

And possibly better, argument 'res', e.g.

png("R.graph.png",  width=1200, height = 700, res=144)
plot(...)
dev.off()

Default corresponds to res=72.

/Henrik

On Sun, Dec 15, 2013 at 3:13 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> See ?png and argument 'pointsize'.  You can increase that as you
> increase the dimensions of the output image.
>
> /Henrik
>
> On Sun, Dec 15, 2013 at 3:00 PM, david hamer <j.david.hamer at gmail.com> wrote:
>> Hello,
>>
>> My x-y scatterplot produces a very ragged best-fit line when imported into
>> Word.
>>
>>
>>
>> * >plot (data.file$x, data.file$y, type = "p", las=1, pch=20,        ylab =
>> expression("Cover of Species y" ~ (m^{2}~ha^{-1} )),        xlab =
>> expression("Cover of Species x" ~ (m^{2}~ha^{-1}))  )    >lines  (
>> data.file$x,   fitted ( model.x )  )*
>>
>>  A suggestion from the internet is to use .png at high (1200) resolution.
>>    * >dev.print  ( device = png,  file = "R.graph.png",  width = 1200,
>> height = 700)*
>> This gives a high?quality graph, but the titles and tick?mark labels become
>> very tiny when exported into Word.
>>
>> I therefore increased the size of the titles and tick?mark labels with cex.
>>    * >plot (......cex =1.8, cex.lab = 1.8, cex.axis = 1.25,....)*
>> But this causes the x?axis title to lie on top of the tick?mark labels.
>> (This problem does not occur with the y?axis, where the title lies well
>> away from the y?axis tick?mark labels.)
>> Changing margins     * >par ( mai = c ( 1.3, 1.35, 1, .75 ) )*    does not
>> seem to have any effect on this.
>>
>> A suggestion from the internet is to delete the titles from plot, and use
>> mtext with line=4 to drop the title lower on the graph.
>>
>> * >plot (.......  ylab = " ", xlab = " ".....)    >mtext(side = 1, "Cover
>> of Species x (superscripts??)", line = 4)*
>> This works, but with mtext I have now lost the ability to have the
>> superscripts in the axis title.
>>
>> And I am back full circle, having to lower the resolution of the graph to
>> keep the x?axis title away from the axis, and thus reverting to a ragged,
>> segmented ?line? when exported to Word......
>>
>> Final note:  The R graphics window version of the graph becomes very
>> distorted, even though the graph may be of high quality (other than the
>> problem of the x-axis title overlaying the x-axis tick-mark labels) once in
>> Word.  I guess this is because of using ?tricks? to try to get a desired
>> end-product in Word....
>>
>> Thanks for any suggestions,
>>          David.
>>
>>         [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From murdoch.duncan at gmail.com  Mon Dec 16 00:23:35 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 15 Dec 2013 18:23:35 -0500
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
Message-ID: <52AE39F7.8000702@gmail.com>

On 13-12-15 6:00 PM, david hamer wrote:
> Hello,
>
> My x-y scatterplot produces a very ragged best-fit line when imported into
> Word.

Don't use a bitmap format (png).

Don't produce your graph in one format (screen display), then convert to 
another (png).  Open the device in the format you want for the final file.

Use a vector format for output.  I don't know what kinds Word supports, 
but EPS or PDF would likely be best; if it can't read those, then 
Windows metafile (via windows() to open the device) would be best. 
(Don't trust the preview to tell you the quality of the graph, try 
printing the document.  Word isn't quite as bad as it appears.)

Don't use Word.

Duncan Murdoch

>
>
>
> * >plot (data.file$x, data.file$y, type = "p", las=1, pch=20,        ylab =
> expression("Cover of Species y" ~ (m^{2}~ha^{-1} )),        xlab =
> expression("Cover of Species x" ~ (m^{2}~ha^{-1}))  )    >lines  (
> data.file$x,   fitted ( model.x )  )*
>
>   A suggestion from the internet is to use .png at high (1200) resolution.
>     * >dev.print  ( device = png,  file = "R.graph.png",  width = 1200,
> height = 700)*
> This gives a high?quality graph, but the titles and tick?mark labels become
> very tiny when exported into Word.
>
> I therefore increased the size of the titles and tick?mark labels with cex.
>     * >plot (......cex =1.8, cex.lab = 1.8, cex.axis = 1.25,....)*
> But this causes the x?axis title to lie on top of the tick?mark labels.
> (This problem does not occur with the y?axis, where the title lies well
> away from the y?axis tick?mark labels.)
> Changing margins     * >par ( mai = c ( 1.3, 1.35, 1, .75 ) )*    does not
> seem to have any effect on this.
>
> A suggestion from the internet is to delete the titles from plot, and use
> mtext with line=4 to drop the title lower on the graph.
>
> * >plot (.......  ylab = " ", xlab = " ".....)    >mtext(side = 1, "Cover
> of Species x (superscripts??)", line = 4)*
> This works, but with mtext I have now lost the ability to have the
> superscripts in the axis title.
>
> And I am back full circle, having to lower the resolution of the graph to
> keep the x?axis title away from the axis, and thus reverting to a ragged,
> segmented ?line? when exported to Word......
>
> Final note:  The R graphics window version of the graph becomes very
> distorted, even though the graph may be of high quality (other than the
> problem of the x-axis title overlaying the x-axis tick-mark labels) once in
> Word.  I guess this is because of using ?tricks? to try to get a desired
> end-product in Word....
>
> Thanks for any suggestions,
>           David.
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r.turner at auckland.ac.nz  Mon Dec 16 01:26:55 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 16 Dec 2013 13:26:55 +1300
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <52AE39F7.8000702@gmail.com>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
	<52AE39F7.8000702@gmail.com>
Message-ID: <52AE48CF.5070501@auckland.ac.nz>

On 16/12/13 12:23, Duncan Murdoch wrote:

     <SNIP>

     [After a number of other "Don'ts"]
> Don't trust the preview to tell you the quality of the graph, try 
> printing the document.
> Word isn't quite as bad as it appears.
>
> Don't use Word. 

Fortune?

     cheers,

     Rolf Turner


From floridmercutio at yahoo.com  Mon Dec 16 02:04:27 2013
From: floridmercutio at yahoo.com (Nerd of Darkness)
Date: Mon, 16 Dec 2013 09:04:27 +0800
Subject: [R] possible overflow/underflow error causing NaN in .trval when
 invoking trmat with degree 4
Message-ID: <52AE519B.1090800@yahoo.com>

Hello all,
I have two copies of the same data; I want to compare trend matrices for
degrees 3 and 4, so I name the copies "triplo" and "quatro".
> triploSurface<-surf.ls(3,triplo)
> triploMat<-trmat(triploSurface,-150.0000,150.0000,-150.0000,150.0000, 300)

[This produces the expected triploSurface and triploMat results and can
be graphed.]


> quatroSurface<-surf.ls(4,quatro)
> quatroMat<-trmat(quatroSurface, -150,150,-150,150, 300)
Error in .trval(object, x, y) :
  NA/NaN/Inf in foreign function call (arg 5)

[This produces an apparently correct quatroSurface result but does not
produce any quatroMat result, just an error message.]

I think this is an overflow or underflow - i.e. I think I'm demanding
too much precision from the numbers.

The tail of the quatroSurface looks like this:
0.0238192479364594, NaN, -0.785397268575074,
0.258979557395067, 0.416633191734089, 0.48818709354019, 0.303158973109538,
0.0976576257799269, 0.0203250815697912, -0.24213596942919,
-0.0892132957309183,
0.975147904903443, 0.176878824295857, 0.0452657395908427,
0.0635179944972253,
NaN, NaN), beta = c(NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,
NaN, NaN, NaN, NaN, NaN, NaN), wz = c(NaN, NaN, NaN, NaN, NaN,
NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN), rx = c(-126.5463, 108.6537
), ry = c(-128.3801, 135.6199), call = quote(surf.ls(np = 4,
    x = quatro))), .Names = c("x", "y", "z", "np", "f", "r",
"beta", "wz", "rx", "ry", "call"), class = "trls")


The tail of the triploSurface looks similar, but all its values are
well-behaved without any NaN problems

 0.0351979976095227, -1.36626369439296, -0.280695994275675,
0.40206378062954, 0.0633634395824397, 0.00569741981675165,
-0.513420054181769
), beta = c(106.769396311982, -2.24615036637542, 0.156526774285082,
1.80159305847556, -3.09710659318204, -0.524195072882179, 2.70901190859632,
-1.02836821322134, 4.80130168312262, 2.37977833647081), wz =
c(-0.0728849622348235,
-0.186585406288444, 0.415603707564799, 0.233806471348331,
0.330715976834796,
-0.0613265591678669, -0.242396311982404, -1.18446693543041,
-0.0285404338742694,
1.01075743539955, -0.210496969514736, -0.0515734891310018,
0.0473874764761177
), rx = c(-126.5463, 108.6537), ry = c(-128.3801, 135.6199),
    call = quote(surf.ls(np = 3, x = triplo))), .Names = c("x",
"y", "z", "np", "f", "r", "beta", "wz", "rx", "ry", "call"), class = "trls")


There seem to be two obvious possibilities:

A - I could get a well-behaved result with degree 4 if only I could
manage to use the correct commands.

B - This data doesn't have the right characteristics to support a degree
4 trend and thus I should limit myself to degree 3.

Any comments are welcome. Thanks.


From frans.marcelissen at digipsy.nl  Sun Dec 15 15:22:41 2013
From: frans.marcelissen at digipsy.nl (Frans Marcelissen)
Date: Sun, 15 Dec 2013 15:22:41 +0100
Subject: [R] how to add a line in the graph?
In-Reply-To: <tencent_3BA8C4D2179533E50A5E6DDB@qq.com>
References: <tencent_3BA8C4D2179533E50A5E6DDB@qq.com>
Message-ID: <CAFFQM6YGPMn2in2R+Y+ojSKzn3ibWF=CaygTqVUpqQ8jSvqfzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131215/37140540/attachment.pl>

From marcos.takahashi at mobly.com.br  Sun Dec 15 23:52:16 2013
From: marcos.takahashi at mobly.com.br (marcos.takahashi)
Date: Sun, 15 Dec 2013 14:52:16 -0800 (PST)
Subject: [R] Rows to Column
Message-ID: <1387147936631-4682245.post@n4.nabble.com>

Hi all,
I'm kinda new in R programming and I need some help preparing a database to
run logistic regression.

I have data in a tuple form:

*id cat val*
1   A   2
1   C   4
3   B   1
5   A   2
6   A   3
6   B   5
6   C   2
8   B   5
8   D   2
9   D   3

and would like to have it like:

*id	catA	catB	catC	catD*
1    2    0      4      0
3    0    1      0      0
5    2    0      0      0
6    3    5      2      0
8    0    5      0      2
9    0    0      0      3

Could someone help me?
I have already tried table function, but it doesn't return row and column
names.



--
View this message in context: http://r.789695.n4.nabble.com/Rows-to-Column-tp4682245.html
Sent from the R help mailing list archive at Nabble.com.


From ahoerner at rprogress.org  Mon Dec 16 04:05:47 2013
From: ahoerner at rprogress.org (andrewH)
Date: Sun, 15 Dec 2013 19:05:47 -0800 (PST)
Subject: [R] The Stoppa distribution
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1CB89@PA-MBX01.na.tibco.com>
References: <CA+t4QRqu4iqQ3cvncT7QWmqUSVwWSDxWdAUS3CwdKdshBg516w@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1CB89@PA-MBX01.na.tibco.com>
Message-ID: <1387163147914-4682254.post@n4.nabble.com>

Thanks enormously, Bill!  I'll run with this for a while, and let you know
how it works for me.

 Yours,  andrewH



--
View this message in context: http://r.789695.n4.nabble.com/The-Stoppa-distribution-tp4682171p4682254.html
Sent from the R help mailing list archive at Nabble.com.


From ahoerner at rprogress.org  Mon Dec 16 05:23:56 2013
From: ahoerner at rprogress.org (Andrew Hoerner)
Date: Sun, 15 Dec 2013 20:23:56 -0800
Subject: [R] How can I find nonstandard or control characters in a large
	file?
In-Reply-To: <87wqjd89k6.fsf@enricoschumann.net>
References: <1386623689473-4681896.post@n4.nabble.com>
	<87wqjd89k6.fsf@enricoschumann.net>
Message-ID: <CA+t4QRokpwFf+6s671ni6dFOZceK8TiW_1G=FSpyHQ5Xm16UxA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131215/ee2fc4ce/attachment.pl>

From ahoerner at rprogress.org  Mon Dec 16 05:27:02 2013
From: ahoerner at rprogress.org (andrewH)
Date: Sun, 15 Dec 2013 20:27:02 -0800 (PST)
Subject: [R] How can I find nonstandard or control characters in a large
 file?
In-Reply-To: <l87brs$5lq$1@ger.gmane.org>
References: <1386623689473-4681896.post@n4.nabble.com>
	<l87brs$5lq$1@ger.gmane.org>
Message-ID: <CA+t4QRpL1M9BY-Zh3m+XkK_+37WUKeZgtH0oxzw_bN-NmTAe+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131215/4fb91129/attachment.pl>

From davidmarino838 at gmail.com  Mon Dec 16 08:16:52 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Sun, 15 Dec 2013 23:16:52 -0800
Subject: [R] How to choose data from two sets of data to ensure that the
 choosed data has a better normal feature?
Message-ID: <CABmD0bHqsQ_+kT6ai2kfh-piLm7CaLR+WNfspVK19sU8OZa9yw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131215/9319c211/attachment.pl>

From 1248283536 at qq.com  Mon Dec 16 08:52:49 2013
From: 1248283536 at qq.com (=?gb18030?B?y66+ssH3ye4=?=)
Date: Mon, 16 Dec 2013 15:52:49 +0800
Subject: [R] how to fit  exponential curve  such as a*b^t  in r?
Message-ID: <tencent_5AB9F3BE76C50CCF5D6BF7AD@qq.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/5e3347ae/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Mon Dec 16 08:59:15 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 15 Dec 2013 23:59:15 -0800
Subject: [R] How to choose data from two sets of data to ensure that the
	choosed data has a better normal feature?
In-Reply-To: <CABmD0bHqsQ_+kT6ai2kfh-piLm7CaLR+WNfspVK19sU8OZa9yw@mail.gmail.com>
References: <CABmD0bHqsQ_+kT6ai2kfh-piLm7CaLR+WNfspVK19sU8OZa9yw@mail.gmail.com>
Message-ID: <dfde9ba9-35d5-4c72-946a-c9ba096877e0@email.android.com>

Your question as posed is incomplete, because you have not specified what the mean and standard deviation are of the distribution that you wish to use as the target. Two histograms may each have an excellent fit to different distributions, such that neither can be faulted as a poor fit to a normal distribution, yet mixing the two would only make things worse. Nor does picking and choosing bins make sense to me even if they are from the same distribution (normally you pool all the data if they are from the same distribution).

This is not a statistics theory forum, but posting a solution to this nonsensical problem would be irresponsible.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Marino David <davidmarino838 at gmail.com> wrote:
>Hi R mailing listers:
>
>Assume that there are two sets of data  (denoted as A and B) with the
>same
>size, say 100X1. And I try to select a new set of data (100X1) that has
>a
>better normal feature  from these two sets. Better normal feature means
>that the histogram shape of the constructed set of data is more normal
>bell-shaped.  The choose rule is that the i-th element of new set is
>from
>i-th element of A or B.
>
>Any suggest is greatly appreciated.
>
>Thank you!
>
>David
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Mon Dec 16 09:03:31 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 16 Dec 2013 09:03:31 +0100
Subject: [R] how to fit  exponential curve  such as a*b^t  in r?
In-Reply-To: <tencent_5AB9F3BE76C50CCF5D6BF7AD@qq.com>
References: <tencent_5AB9F3BE76C50CCF5D6BF7AD@qq.com>
Message-ID: <1A5A308B-BF6E-4FF1-828E-4E8B5F9CBE17@xs4all.nl>


On 16-12-2013, at 08:52, ???? <1248283536 at qq.com> wrote:

> input <- "    
>      t    y    
>     1  5.3    
>     2  7.2    
>     3  9.6    
>     4 12.9    
>     5 17.1    
>     6 23.2"         
>    dat<-read.table(textConnection(input),header=TRUE,sep="")    
>    t<-dat[,1]    
>    y<-dat[,2]   
> 
> `y=3.975*(1.341^t)` is the resule of fit,how can i use `nls` function to get it?


Have you looked at ?nls.
Have you simply tried

nls(y~a*b^t,data=dat)

You can also do a linear regression  on  log(y) ~ A + B* t.
And afterwards transform to the original coefficients.

Berend

> 	[[alternative HTML version deleted]]
> 

Please do not post in html.

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Dec 16 09:25:41 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 16 Dec 2013 00:25:41 -0800
Subject: [R] how to fit  exponential curve  such as a*b^t  in r?
In-Reply-To: <tencent_5AB9F3BE76C50CCF5D6BF7AD@qq.com>
References: <tencent_5AB9F3BE76C50CCF5D6BF7AD@qq.com>
Message-ID: <7a8ee52d-9b54-447e-96ae-d9b2fbb15af7@email.android.com>

Read the examples section of

?nls

You probably need to provide a start list of values.

There are some points you should note from the Posting Guide mentioned in the footer of emails on this list: this is not a homework help forum, you should provide a reproducible example, and you should not post in HTML format.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"????" <1248283536 at qq.com> wrote:
>input <- "    
>      t    y    
>     1  5.3    
>     2  7.2    
>     3  9.6    
>     4 12.9    
>     5 17.1    
>     6 23.2"         
>    dat<-read.table(textConnection(input),header=TRUE,sep="")    
>    t<-dat[,1]    
>    y<-dat[,2]   
>
>`y=3.975*(1.341^t)` is the resule of fit,how can i use `nls` function
>to get it?
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Dec 16 02:49:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 15 Dec 2013 17:49:25 -0800 (PST)
Subject: [R] Rows to Column
In-Reply-To: <1387147936631-4682245.post@n4.nabble.com>
References: <1387147936631-4682245.post@n4.nabble.com>
Message-ID: <1387158565.53834.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
dat1 <- read.table(text="id cat val
1? A? 2
1? C? 4
3? B? 1
5? A? 2
6? A? 3
6? B? 5
6? C? 2
8? B? 5
8? D? 2
9? D? 3",sep="",header=TRUE,stringsAsFactors=FALSE)


library(reshape2)
?res1 <- dcast(dat1,id~cat,value.var="val",fill=0)
colnames(res1)[-1] <- paste0("cat",colnames(res1)[-1])


#or
?xtabs(val~id+cat,data=dat1)
A.K.


On Sunday, December 15, 2013 8:38 PM, marcos.takahashi <marcos.takahashi at mobly.com.br> wrote:
Hi all,
I'm kinda new in R programming and I need some help preparing a database to
run logistic regression.

I have data in a tuple form:

*id cat val*
1?  A?  2
1?  C?  4
3?  B?  1
5?  A?  2
6?  A?  3
6?  B?  5
6?  C?  2
8?  B?  5
8?  D?  2
9?  D?  3

and would like to have it like:

*id??? catA??? catB??? catC??? catD*
1? ? 2? ? 0? ? ? 4? ? ? 0
3? ? 0? ? 1? ? ? 0? ? ? 0
5? ? 2? ? 0? ? ? 0? ? ? 0
6? ? 3? ? 5? ? ? 2? ? ? 0
8? ? 0? ? 5? ? ? 0? ? ? 2
9? ? 0? ? 0? ? ? 0? ? ? 3

Could someone help me?
I have already tried table function, but it doesn't return row and column
names.



--
View this message in context: http://r.789695.n4.nabble.com/Rows-to-Column-tp4682245.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From pmitch at deakin.edu.au  Mon Dec 16 04:54:09 2013
From: pmitch at deakin.edu.au (PETER MITCHELL)
Date: Mon, 16 Dec 2013 03:54:09 +0000
Subject: [R] log transforming predictor variables in a binomial GAM?
Message-ID: <7E512447FC05A44D877BD8B82172DFDB34A39231@MBOX-F-7.du.deakin.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/6cb2f7a3/attachment.pl>

From s.wood at bath.ac.uk  Mon Dec 16 10:08:09 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Mon, 16 Dec 2013 10:08:09 +0100
Subject: [R] log transforming predictor variables in a binomial GAM?
In-Reply-To: <7E512447FC05A44D877BD8B82172DFDB34A39231@MBOX-F-7.du.deakin.edu.au>
References: <7E512447FC05A44D877BD8B82172DFDB34A39231@MBOX-F-7.du.deakin.edu.au>
Message-ID: <52AEC2F9.6040102@bath.ac.uk>


It doesn't break anything - you can transform the predictors pretty much
any way you like, and it is often sensible as a way of tackling very
uneven leverage. By transforming predictors, all you are changing in the
model is what "smooth" means. e.g. smooth w.r.t. log(x) is somewhat
different to sooth w.r.t. x.

best,
Simon

On 16/12/13 04:54, PETER MITCHELL wrote:
> Hi all,
>
> I am applying a Presence/absence Generalized additive model to model
> the distribution of marine algae species in R. I have found that log
> transforming the environmental variables improves the explained
> deviance of the model considerably. While log transforming is common
> practice in GLM, I have been unable to find any papers where this is
> performed in a GAM. Im wondering whether this breaks any of the rules
> of GAMs and is statistically acceptable?
>
> Thanks all Peter
>
> [[alternative HTML version deleted]]
>
> ______________________________________________ R-help at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
> read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From p.mulongeni at namibia.pharmaccess.org  Mon Dec 16 13:05:30 2013
From: p.mulongeni at namibia.pharmaccess.org (Pancho Mulongeni)
Date: Mon, 16 Dec 2013 12:05:30 +0000
Subject: [R] why there is no quarters?
Message-ID: <91d1c056e9544bfe99d424cf099e521f@DBXPR03MB509.eurprd03.prod.outlook.com>

Hi,
I also would like to use quarters. I think a work around would be to just label each record in the dataframe by its quarter.
i.e. you add a factor called 'Quarter' with four levels (Q1 to Q4) for each row and you assign the level based on the month of the date.
You can easily do this with as.Date and as.character.

Pancho Mulongeni
Research Assistant
PharmAccess Foundation
1 Fouch? Street
Windhoek West
Windhoek
Namibia
?
Tel:?? +264 61 419 000
Fax:? +264 61 419 001/2
Mob: +264 81 4456 286


From kehld at ktk.pte.hu  Mon Dec 16 13:35:43 2013
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?D=E1niel_Kehl?=)
Date: Mon, 16 Dec 2013 12:35:43 +0000
Subject: [R] why there is no quarters?
In-Reply-To: <91d1c056e9544bfe99d424cf099e521f@DBXPR03MB509.eurprd03.prod.outlook.com>
References: <91d1c056e9544bfe99d424cf099e521f@DBXPR03MB509.eurprd03.prod.outlook.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B92DFD7@EMAIL.ktkdom.pte.hu>

Hi,

try

x <- seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"3 months")

best,
daniel
________________________________________
Felad?: r-help-bounces at r-project.org [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Pancho Mulongeni [p.mulongeni at namibia.pharmaccess.org]
K?ldve: 2013. december 16. 13:05
To: 1248283536 at qq.com
Cc: r-help at r-project.org
T?rgy: Re: [R] why there is no quarters?

Hi,
I also would like to use quarters. I think a work around would be to just label each record in the dataframe by its quarter.
i.e. you add a factor called 'Quarter' with four levels (Q1 to Q4) for each row and you assign the level based on the month of the date.
You can easily do this with as.Date and as.character.

Pancho Mulongeni
Research Assistant
PharmAccess Foundation
1 Fouch? Street
Windhoek West
Windhoek
Namibia

Tel:   +264 61 419 000
Fax:  +264 61 419 001/2
Mob: +264 81 4456 286

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Mon Dec 16 13:59:20 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 16 Dec 2013 06:59:20 -0600
Subject: [R] why there is no quarters?
In-Reply-To: <52AD9C6D.9050807@gmail.com>
References: <tencent_75A9BC3969069B6F741B44C2@qq.com>
	<52AD9C6D.9050807@gmail.com>
Message-ID: <4B7FE54B-BAFE-4146-80AA-FD34A16FD414@me.com>


On Dec 15, 2013, at 6:11 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 13-12-15 6:43 AM, ???? wrote:
>> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"years")
>> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"weeks")
>> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"days")
>> 
>> why there is no
>> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"quarters")  ?
> 
> There's no need for it.  Just use months, and take every 3rd one:
> 	
> x <- seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"months")
> x[seq_along(x) %% 3 == 1]


Alternatively, ?cut.Date has "quarter" for the 'breaks' argument:

x <- seq(as.Date("2001/1/1"), as.Date("2010/1/1"), "months")

xq <- cut(x, breaks = "quarter")

> head(xq, 10)
 [1] 2001-01-01 2001-01-01 2001-01-01 2001-04-01 2001-04-01 2001-04-01
 [7] 2001-07-01 2001-07-01 2001-07-01 2001-10-01
37 Levels: 2001-01-01 2001-04-01 2001-07-01 2001-10-01 ... 2010-01-01


If you want to change the values to use "2001-Q2" or variants, you can do something like:

S <- c("01-01", "04-01", "07-01", "10-01")

xqq <- paste(substr(xq, 1, 5), "Q", match(substr(xq, 6, 10), S), sep = "") 

> head(xqq, 10)
 [1] "2001-Q1" "2001-Q1" "2001-Q1" "2001-Q2" "2001-Q2" "2001-Q2"
 [7] "2001-Q3" "2001-Q3" "2001-Q3" "2001-Q4"



See ?match, ?substr and ?paste


Regards,

Marc Schwartz


From marc_schwartz at me.com  Mon Dec 16 14:12:12 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 16 Dec 2013 07:12:12 -0600
Subject: [R] why there is no quarters?
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D0B92DFD7@EMAIL.ktkdom.pte.hu>
References: <91d1c056e9544bfe99d424cf099e521f@DBXPR03MB509.eurprd03.prod.outlook.com>
	<33D76D77E9AC4B438DA38B348ED6890D0B92DFD7@EMAIL.ktkdom.pte.hu>
Message-ID: <2ECCC716-4A25-468D-AAD3-E7E3B1FCE828@me.com>

That will only work if your starting date happens to be the first day of the year:

x <- seq(as.Date("2001/1/1"), as.Date("2010/1/1"), "3 months")

> head(x)
[1] "2001-01-01" "2001-04-01" "2001-07-01" "2001-10-01" "2002-01-01"
[6] "2002-04-01"


Compare that to:

x2 <- seq(as.Date("2001/2/3"), as.Date("2010/1/1"), "3 months")

> head(x2, 10)
 [1] "2001-02-03" "2001-05-03" "2001-08-03" "2001-11-03" "2002-02-03"
 [6] "2002-05-03" "2002-08-03" "2002-11-03" "2003-02-03" "2003-05-03"


The "3 months" is literally 3 months from the defined start date, not 3 months from the first of the year. So you are not going to get calendar quarter starting dates in that case.


On the other hand:

> cut(x2, breaks = "quarter")
 [1] 2001-01-01 2001-04-01 2001-07-01 2001-10-01 2002-01-01 2002-04-01
 [7] 2002-07-01 2002-10-01 2003-01-01 2003-04-01 2003-07-01 2003-10-01
[13] 2004-01-01 2004-04-01 2004-07-01 2004-10-01 2005-01-01 2005-04-01
[19] 2005-07-01 2005-10-01 2006-01-01 2006-04-01 2006-07-01 2006-10-01
[25] 2007-01-01 2007-04-01 2007-07-01 2007-10-01 2008-01-01 2008-04-01
[31] 2008-07-01 2008-10-01 2009-01-01 2009-04-01 2009-07-01 2009-10-01
36 Levels: 2001-01-01 2001-04-01 2001-07-01 2001-10-01 ... 2009-10-01


Regards,

Marc Schwartz


On Dec 16, 2013, at 6:35 AM, D?niel Kehl <kehld at ktk.pte.hu> wrote:

> Hi,
> 
> try
> 
> x <- seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"3 months")
> 
> best,
> daniel
> ________________________________________
> Felad?: r-help-bounces at r-project.org [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Pancho Mulongeni [p.mulongeni at namibia.pharmaccess.org]
> K?ldve: 2013. december 16. 13:05
> To: 1248283536 at qq.com
> Cc: r-help at r-project.org
> T?rgy: Re: [R] why there is no quarters?
> 
> Hi,
> I also would like to use quarters. I think a work around would be to just label each record in the dataframe by its quarter.
> i.e. you add a factor called 'Quarter' with four levels (Q1 to Q4) for each row and you assign the level based on the month of the date.
> You can easily do this with as.Date and as.character.
> 
> Pancho Mulongeni
> Research Assistant
> PharmAccess Foundation
> 1 Fouch? Street
> Windhoek West
> Windhoek
> Namibia
> 
> Tel:   +264 61 419 000
> Fax:  +264 61 419 001/2
> Mob: +264 81 4456 286


From smartpink111 at yahoo.com  Mon Dec 16 14:21:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 16 Dec 2013 05:21:24 -0800 (PST)
Subject: [R] why there is no quarters?
In-Reply-To: <4B7FE54B-BAFE-4146-80AA-FD34A16FD414@me.com>
References: <tencent_75A9BC3969069B6F741B44C2@qq.com>	<52AD9C6D.9050807@gmail.com>
	<4B7FE54B-BAFE-4146-80AA-FD34A16FD414@me.com> 
Message-ID: <1387200084.88142.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Also,

library(zoo)
format.yearqtr(x)
identical(gsub("\\-"," ",xqq),format.yearqtr(x))
#[1] TRUE
A.K.





On Monday, December 16, 2013 8:01 AM, Marc Schwartz <marc_schwartz at me.com> wrote:

On Dec 15, 2013, at 6:11 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 13-12-15 6:43 AM, ???? wrote:
>> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"years")
>> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"weeks")
>> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"days")
>> 
>> why there is no
>> seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"quarters")? ?
> 
> There's no need for it.? Just use months, and take every 3rd one:
> ??? 
> x <- seq(as.Date("2001/1/1"),as.Date("2010/1/1"),"months")
> x[seq_along(x) %% 3 == 1]


Alternatively, ?cut.Date has "quarter" for the 'breaks' argument:

x <- seq(as.Date("2001/1/1"), as.Date("2010/1/1"), "months")

xq <- cut(x, breaks = "quarter")

> head(xq, 10)
[1] 2001-01-01 2001-01-01 2001-01-01 2001-04-01 2001-04-01 2001-04-01
[7] 2001-07-01 2001-07-01 2001-07-01 2001-10-01
37 Levels: 2001-01-01 2001-04-01 2001-07-01 2001-10-01 ... 2010-01-01


If you want to change the values to use "2001-Q2" or variants, you can do something like:

S <- c("01-01", "04-01", "07-01", "10-01")

xqq <- paste(substr(xq, 1, 5), "Q", match(substr(xq, 6, 10), S), sep = "") 

> head(xqq, 10)
[1] "2001-Q1" "2001-Q1" "2001-Q1" "2001-Q2" "2001-Q2" "2001-Q2"
[7] "2001-Q3" "2001-Q3" "2001-Q3" "2001-Q4"



See ?match, ?substr and ?paste


Regards,

Marc Schwartz


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From efglynn at gmail.com  Mon Dec 16 15:36:28 2013
From: efglynn at gmail.com (Earl F Glynn)
Date: Mon, 16 Dec 2013 08:36:28 -0600
Subject: [R] Converting decimal to binary in R
In-Reply-To: <tencent_6AD3882132EDA8B24335FC09@qq.com>
References: <tencent_6AD3882132EDA8B24335FC09@qq.com>
Message-ID: <l8n351$8nd$1@ger.gmane.org>

???? wrote:
> i  have write a function to convert decimal number into binary number in R.
>
> dectobin can get right result ,it is so long ,is there a  build-in function to do ?

Try the R.utils package:

 > library(R.utils)

 > intToBin(12)
[1] "1100"
 > intToBin(255)
[1] "11111111"
 > intToBin(65535)
[1] "1111111111111111"
 > intToBin(65536)
[1] "10000000000000000"

Earl F Glynn
Principal Programmer/Analyst
Center for Health Insights ? University of Missouri ? Kansas City


From dcarlson at tamu.edu  Mon Dec 16 15:39:43 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 16 Dec 2013 08:39:43 -0600
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <52AE39F7.8000702@gmail.com>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
	<52AE39F7.8000702@gmail.com>
Message-ID: <001101cefa6c$a8fb5a60$faf20f20$@tamu.edu>

This will create a simple plot using Windows enhanced metafile
format:

> win.metafile("TestFigure.emf")
> plot(rnorm(25), rnorm(25))
> dev.off()
null device 
          1 
>

Windows does not read pdf. It will offer to import an eps
(encapsulated postscript) file, but it only imports the bitmap
thumbnail image of the figure so it is completely useless. You
can edit a metafile in Word, but different versions seem to have
different issues. Earlier versions would lose clipping if you
tried to edit the file, but World 2013 works reasonably well.
Text labels can jump if you edit the figure in Word (especially
rotated text) although it is simple to drag them back to where
you want them. I haven't tried 2010 or 2007 recently.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Duncan
Murdoch
Sent: Sunday, December 15, 2013 5:24 PM
To: david hamer; r-help at r-project.org
Subject: Re: [R] Exporting R graphics into Word without losing
graph quality

On 13-12-15 6:00 PM, david hamer wrote:
> Hello,
>
> My x-y scatterplot produces a very ragged best-fit line when
imported into
> Word.

Don't use a bitmap format (png).

Don't produce your graph in one format (screen display), then
convert to 
another (png).  Open the device in the format you want for the
final file.

Use a vector format for output.  I don't know what kinds Word
supports, 
but EPS or PDF would likely be best; if it can't read those,
then 
Windows metafile (via windows() to open the device) would be
best. 
(Don't trust the preview to tell you the quality of the graph,
try 
printing the document.  Word isn't quite as bad as it appears.)

Don't use Word.

Duncan Murdoch

>
>
>
> * >plot (data.file$x, data.file$y, type = "p", las=1, pch=20,
ylab =
> expression("Cover of Species y" ~ (m^{2}~ha^{-1} )),
xlab =
> expression("Cover of Species x" ~ (m^{2}~ha^{-1}))  )
>lines  (
> data.file$x,   fitted ( model.x )  )*
>
>   A suggestion from the internet is to use .png at high (1200)
resolution.
>     * >dev.print  ( device = png,  file = "R.graph.png",
width = 1200,
> height = 700)*
> This gives a high-quality graph, but the titles and tick-mark
labels become
> very tiny when exported into Word.
>
> I therefore increased the size of the titles and tick-mark
labels with cex.
>     * >plot (......cex =1.8, cex.lab = 1.8, cex.axis =
1.25,....)*
> But this causes the x-axis title to lie on top of the
tick-mark labels.
> (This problem does not occur with the y-axis, where the title
lies well
> away from the y-axis tick-mark labels.)
> Changing margins     * >par ( mai = c ( 1.3, 1.35, 1, .75 ) )*
does not
> seem to have any effect on this.
>
> A suggestion from the internet is to delete the titles from
plot, and use
> mtext with line=4 to drop the title lower on the graph.
>
> * >plot (.......  ylab = " ", xlab = " ".....)    >mtext(side
= 1, "Cover
> of Species x (superscripts??)", line = 4)*
> This works, but with mtext I have now lost the ability to have
the
> superscripts in the axis title.
>
> And I am back full circle, having to lower the resolution of
the graph to
> keep the x-axis title away from the axis, and thus reverting
to a ragged,
> segmented "line" when exported to Word......
>
> Final note:  The R graphics window version of the graph
becomes very
> distorted, even though the graph may be of high quality (other
than the
> problem of the x-axis title overlaying the x-axis tick-mark
labels) once in
> Word.  I guess this is because of using "tricks" to try to get
a desired
> end-product in Word....
>
> Thanks for any suggestions,
>           David.
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From rasulasudeh at gmail.com  Mon Dec 16 13:25:29 2013
From: rasulasudeh at gmail.com (Rasool Asoodeh)
Date: Mon, 16 Dec 2013 15:55:29 +0330
Subject: [R] Question
Message-ID: <CAMFFGWhVK1ENTPhwAxufA0KATMTB7mx0Jb6DjJ+Me85RmSzwnA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/c347f312/attachment.pl>

From dcarlson at tamu.edu  Mon Dec 16 15:53:36 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 16 Dec 2013 08:53:36 -0600
Subject: [R] Rows to Column
In-Reply-To: <1387158565.53834.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1387147936631-4682245.post@n4.nabble.com>
	<1387158565.53834.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <001301cefa6e$99431520$cbc93f60$@tamu.edu>

Also
> tbl <- xtabs(val~id+cat, dat1)
> tbl
   cat
id  A B C D
  1 2 0 4 0
  3 0 1 0 0
  5 2 0 0 0
  6 3 5 2 0
  8 0 5 0 2
  9 0 0 0 3

To get your column names
> dimnames(tbl)$cat <- paste0("cat", dimnames(tbl)$cat)
> tbl
   cat
id  catA catB catC catD
  1    2    0    4    0
  3    0    1    0    0
  5    2    0    0    0
  6    3    5    2    0
  8    0    5    0    2

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of arun
Sent: Sunday, December 15, 2013 7:49 PM
To: r-help at r-project.org
Cc: marcos.takahashi
Subject: Re: [R] Rows to Column

Hi,
Try:
dat1 <- read.table(text="id cat val
1? A? 2
1? C? 4
3? B? 1
5? A? 2
6? A? 3
6? B? 5
6? C? 2
8? B? 5
8? D? 2
9? D? 3",sep="",header=TRUE,stringsAsFactors=FALSE)


library(reshape2)
?res1 <- dcast(dat1,id~cat,value.var="val",fill=0)
colnames(res1)[-1] <- paste0("cat",colnames(res1)[-1])


#or
?xtabs(val~id+cat,data=dat1)
A.K.


On Sunday, December 15, 2013 8:38 PM, marcos.takahashi
<marcos.takahashi at mobly.com.br> wrote:
Hi all,
I'm kinda new in R programming and I need some help preparing a
database to
run logistic regression.

I have data in a tuple form:

*id cat val*
1?  A?  2
1?  C?  4
3?  B?  1
5?  A?  2
6?  A?  3
6?  B?  5
6?  C?  2
8?  B?  5
8?  D?  2
9?  D?  3

and would like to have it like:

*id??? catA??? catB??? catC??? catD*
1? ? 2? ? 0? ? ? 4? ? ? 0
3? ? 0? ? 1? ? ? 0? ? ? 0
5? ? 2? ? 0? ? ? 0? ? ? 0
6? ? 3? ? 5? ? ? 2? ? ? 0
8? ? 0? ? 5? ? ? 0? ? ? 2
9? ? 0? ? 0? ? ? 0? ? ? 3

Could someone help me?
I have already tried table function, but it doesn't return row
and column
names.



--
View this message in context:
http://r.789695.n4.nabble.com/Rows-to-Column-tp4682245.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From azzalini at stat.unipd.it  Mon Dec 16 16:09:46 2013
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Mon, 16 Dec 2013 16:09:46 +0100
Subject: [R] convergence=0 in optim and nlminb is real?
Message-ID: <20131216160946.91858ff279db26bd65e187bc@stat.unipd.it>

It must be the case that this issue has already been rised before,
but I did not manage to find it in past posting. 

In some cases, optim() and nlminb() declare a successful convergence,
but the corresponding Hessian is not positive-definite.  A simplified
version of the original problem is given in the code which for
readability is placed below this text.  The example is built making use
of package 'sn', but this is only required to set-up the example: the
question is about the outcome of the optimizers. At the end of the run,
a certain point is declared to correspont to a minimum since
'convergence=0' is reported, but the eigenvalues of the (numerically
evaluated) Hessian matrix at that point are not all positive.

Any views on the cause of the problem? (i) the point does not
correspong to a real minimum, (ii) it does dive a minimum but the
Hessian matrix is wrong, (iii) the eigenvalues are not right. 
...and, in case, how to get the real solution. 


Adelchi Azzalini

#------------------
library(sn) # version 0.4-18
data(ais, package="sn")
attach(ais)
X <- cbind(1,Ht,Wt) 
y <- cbind(bmi, lbm)
dettach(ais)
negLogLik <- function(vdp, x, y)
{
  d <- ncol(y)
  p <- ncol(x)
  beta <- matrix(vdp[1:(d*p)], p, d)
  Omega <- matrix(0, d, d)
  Omega[lower.tri(Omega, TRUE)] <- vdp[(p*d+1):(p*d+d*(d+1)/2)]
  Omega <- Omega + t(Omega) - diag(diag(Omega), d)
  if(any(eigen(Omega)$values <= 0)) return(Inf)
  omega <- sqrt(diag(Omega))
  alpha <- vdp[(p*d+d*(d+1)/2+1):(p*d+d*(d+1)/2+d)]
  nu <- vdp[p*d+d*(d+1)/2+d+1]
  if(nu <= 0) return(Inf)
  logL <- sum(dmst(y, x %*% beta, Omega, alpha, nu, log=TRUE))
  return(-logL)
}
# run 1
vdp <-  c(44, 0, 0, -4, 0, 0, 0.05, -0.5, 35, 0.5, -20, 3.5)
opt <- optim(vdp, negLogLik, method="BFGS", hessian=TRUE, x=X, y=y)
opt$value
# [1] 625.3
opt$convergence
# [1] 0
eigen(opt$hessian)$values
# [1]  7.539e+07  1.523e+06 .... 5.684e-02 -4.516e-01
#---
# run 2
vdp <-  c(44.17,  -0.2441,  0.303, -3.620, 0.04044, 0.8906, 
         0.0487, -0.5072, 36.33, 0.4445, -20.87, 3.5)
opt <- optim(vdp, negLogLik, method="BFGS", hessian=TRUE, x=X, y=y)
opt$value
# [1] 599.7
opt$convergence
# [1] 0
eigen(opt$hessian)$values
# [1]  1.235e+08  ....  3.845e-02 -1.311e-03 -6.701e+02
#---
# run 3
vdp <-  c(44.17,  -0.2441,  0.303, -3.620, 0.04044, 0.8906, 
         0.0487, -0.5072, 36.33, 0.4445, -20.87, 3.5)
opt <- optim(vdp, negLogLik, method="SANN", hessian=TRUE, x=X, y=y)
opt$value
# [1] 599.8
opt$convergence
# [1] 0
eigen(opt$hessian)$values
# [1]  1.232e+08  ....    3.225e-02 -6.681e-02 -7.513e+02
#--
# run 4
vdp <-  c(44.17,  -0.2441,  0.303, -3.620, 0.04044, 0.8906, 
         0.0487, -0.5072, 36.33, 0.4445, -20.87, 3.5)
opt <- optim(vdp, negLogLik, method="Nelder", hessian=TRUE, x=X, y=y)
opt$value
# [1] 599.7
opt$convergence
# [1] 1
#--
# run 5
vdp <-  c(44.17,  -0.2441,  0.303, -3.620, 0.04044, 0.8906, 
         0.0487, -0.5072, 36.33, 0.4445, -20.87, 3.5)
opt <- optim(vdp, negLogLik, method="CG", hessian=TRUE, x=X, y=y)
opt$value
# [1] 599.7
opt$convergence
# [1] 0
eigen(opt$hessian)$values
# [1]  1.236e+08  3.026e+06  .... 3.801e-02 -2.348e-04 -7.344e+02

#--
# run 6
vdp <-  c(44.17,  -0.2441,  0.303, -3.620, 0.04044, 0.8906, 
         0.0487, -0.5072, 36.33, 0.4445, -20.87, 3.5)
opt <- nlminb(vdp, negLogLik, x=X, y=y)
opt$obj
# [1] 599.7
H <- optimHess(opt$par, negLogLik, x=X, y=y)
eigen(H)$values
# [1]  1.236e+08  3.041e+06 ... 4.090e-05 -7.176e+02
=============
            _                           
platform       x86_64-unknown-linux-gnu    
arch           x86_64                      
os             linux-gnu                   
system         x86_64, linux-gnu           
status                                     
major          3                           
minor          0.2                         
year           2013                        
month          09                          
day            25                          
svn rev        63987                       
language       R                           
version.string R version 3.0.2 (2013-09-25)
nickname       Frisbee Sailing


From jun.shen.ut at gmail.com  Mon Dec 16 16:11:25 2013
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Mon, 16 Dec 2013 10:11:25 -0500
Subject: [R] How to plug in characters as object names in a formula (recast
 from package reshape2 specifically)
Message-ID: <CAMCXXmogBE9YrJ0=bK08b+QcAUWntaYusDVkS5EGed98iS8LQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/3bc9267a/attachment.pl>

From jkaron at earthlink.net  Mon Dec 16 16:40:27 2013
From: jkaron at earthlink.net (John Karon)
Date: Mon, 16 Dec 2013 08:40:27 -0700
Subject: [R] Invalid connection error message when trying to write a file
In-Reply-To: <52AE0363.2010705@statistik.tu-dortmund.de>
References: <1386961869720-4682149.post@n4.nabble.com>	<52AC8FEA.2090905@statistik.tu-dortmund.de>
	<84534FFA466443F391A41E56E6E45B27@JohnKaronHP>
	<52AE0363.2010705@statistik.tu-dortmund.de>
Message-ID: <9827DBC6D3BD4D07813E1DE403F14909@JohnKaronHP>

Thanks for pointing out my error after specifying the destination in the 
file(  ) function.  What you proposed also did not work.
It turns out the solution is to give the file name but not include the path; 
the resulting file is written in the working directory.
The mystery is that including the path had previously work.
John Karon

-----Original Message----- 
From: Uwe Ligges
Sent: Sunday, December 15, 2013 12:30 PM
To: John Karon ; r-help at r-project.org
Subject: Re: [R] Invalid connection error message when trying to write a 
file



On 15.12.2013 20:13, John Karon wrote:
> The response below asks what I actually did.
>
> I defined a function (details omitted; it computes the data frame
> LRtest.out); arguments include "path\\filename.csv" to which I want to
> write a data frame using write.csv(  ).  Repeated executions of the
> function (without the file(  ) and close(  ) instructions) were
> successful until 2 days ago, when I received the error message below.  I
> simplified the code to write a file and received the error message below
> (same message as before) in response to the commands
>
> zz<-file(description="c:\\LRtest.txt","w")
> write.table(LRtest.out, file="c:\\LRtest.txt", sep="\t")
> close(zz)

Wrong, *either* use

write.table(LRtest.out, file="c:\\LRtest.txt", sep="\t")

or

zz <- file(description="c:\\LRtest.txt","w")
write.table(LRtest.out, file=zz, sep="\t")
close(zz)

Best,
Uwe Ligges







>
> Error in file(description = "c:\\LRtest.txt", "w") :
>   cannot open the connection
> In addition: Warning message:
> In file(description = "c:\\LRtest.txt", "w") :
>   cannot open file 'c:\LRtest.txt': Permission denied
>
> This happens whether there is no previous file with that name or an
> essentially empty file with that name.  In previous executions of code
> with a path to a folder, executing the file(  )  command would create an
> empty file.  Now no empty file is created.  The problem persists after
> rebooting the computer.
>
> I also tried writing to the clipboard (description ="clipboard" in the
> file(  ) command); that was unsuccessful, with file="clipboard" or no
> file statement in the write.table(  ) command (Word showed there was
> something to paste, but pasting into an empty Word document did not put
> text into the document; with no file statement, the data frame was
> written to the console).
>
> I question whether there is a setting that forbids writing to a file.
> Information on putting the data frame on the clipboard would also help.
> Thanks for any help.  John Karon
>
> -----Original Message----- From: Uwe Ligges
> Sent: Saturday, December 14, 2013 10:05 AM
> To: J Karon ; r-help at r-project.org
> Subject: Re: [R] Invalid connection error message when trying to write a
> file
>
>
>
> On 13.12.2013 20:11, J Karon wrote:
>> I get an invalid connection method error message when trying to write
>> an R
>> object from a user-defined function to my hard drive (running Windows 7)
>> using write.csv.  I have previously not had this problem with the same
>> user-defined function.  The error message is
>>
>> Error in isOpen(file, "w") : invalid connection
>> In addition: Warning message:
>> In if (file == "") file <- stdout() else if (is.character(file)) { :
>>    the condition has length > 1 and only the first element will be used
>>
>> Using
>> zz<-file(description="path","w")
>> write.csv(  )
>> close(zz)
>>
>> creates an empty file but yields the same error message when I execute
>> write.csv.
>
>
> Please tell us what you actually did.
>
> This works for me:
>
> zz <- file(description="path", "w")
> write.csv(iris, zz)
> close(zz)
>
> Best,
> Uwe Ligges
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Mon Dec 16 16:41:31 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 16 Dec 2013 16:41:31 +0100
Subject: [R] Invalid connection error message when trying to write a file
In-Reply-To: <9827DBC6D3BD4D07813E1DE403F14909@JohnKaronHP>
References: <1386961869720-4682149.post@n4.nabble.com>	<52AC8FEA.2090905@statistik.tu-dortmund.de>
	<84534FFA466443F391A41E56E6E45B27@JohnKaronHP>
	<52AE0363.2010705@statistik.tu-dortmund.de>
	<9827DBC6D3BD4D07813E1DE403F14909@JohnKaronHP>
Message-ID: <52AF1F2B.30108@statistik.tu-dortmund.de>

I guess your problem is that you cannot write toplevel into "c:\" with 
your permissions?

Best,
Uwe Ligges


On 16.12.2013 16:40, John Karon wrote:
> Thanks for pointing out my error after specifying the destination in the
> file(  ) function.  What you proposed also did not work.
> It turns out the solution is to give the file name but not include the
> path; the resulting file is written in the working directory.
> The mystery is that including the path had previously work.
> John Karon
>
> -----Original Message----- From: Uwe Ligges
> Sent: Sunday, December 15, 2013 12:30 PM
> To: John Karon ; r-help at r-project.org
> Subject: Re: [R] Invalid connection error message when trying to write a
> file
>
>
>
> On 15.12.2013 20:13, John Karon wrote:
>> The response below asks what I actually did.
>>
>> I defined a function (details omitted; it computes the data frame
>> LRtest.out); arguments include "path\\filename.csv" to which I want to
>> write a data frame using write.csv(  ).  Repeated executions of the
>> function (without the file(  ) and close(  ) instructions) were
>> successful until 2 days ago, when I received the error message below.  I
>> simplified the code to write a file and received the error message below
>> (same message as before) in response to the commands
>>
>> zz<-file(description="c:\\LRtest.txt","w")
>> write.table(LRtest.out, file="c:\\LRtest.txt", sep="\t")
>> close(zz)
>
> Wrong, *either* use
>
> write.table(LRtest.out, file="c:\\LRtest.txt", sep="\t")
>
> or
>
> zz <- file(description="c:\\LRtest.txt","w")
> write.table(LRtest.out, file=zz, sep="\t")
> close(zz)
>
> Best,
> Uwe Ligges
>
>
>
>
>
>
>
>>
>> Error in file(description = "c:\\LRtest.txt", "w") :
>>   cannot open the connection
>> In addition: Warning message:
>> In file(description = "c:\\LRtest.txt", "w") :
>>   cannot open file 'c:\LRtest.txt': Permission denied
>>
>> This happens whether there is no previous file with that name or an
>> essentially empty file with that name.  In previous executions of code
>> with a path to a folder, executing the file(  )  command would create an
>> empty file.  Now no empty file is created.  The problem persists after
>> rebooting the computer.
>>
>> I also tried writing to the clipboard (description ="clipboard" in the
>> file(  ) command); that was unsuccessful, with file="clipboard" or no
>> file statement in the write.table(  ) command (Word showed there was
>> something to paste, but pasting into an empty Word document did not put
>> text into the document; with no file statement, the data frame was
>> written to the console).
>>
>> I question whether there is a setting that forbids writing to a file.
>> Information on putting the data frame on the clipboard would also help.
>> Thanks for any help.  John Karon
>>
>> -----Original Message----- From: Uwe Ligges
>> Sent: Saturday, December 14, 2013 10:05 AM
>> To: J Karon ; r-help at r-project.org
>> Subject: Re: [R] Invalid connection error message when trying to write a
>> file
>>
>>
>>
>> On 13.12.2013 20:11, J Karon wrote:
>>> I get an invalid connection method error message when trying to write
>>> an R
>>> object from a user-defined function to my hard drive (running Windows 7)
>>> using write.csv.  I have previously not had this problem with the same
>>> user-defined function.  The error message is
>>>
>>> Error in isOpen(file, "w") : invalid connection
>>> In addition: Warning message:
>>> In if (file == "") file <- stdout() else if (is.character(file)) { :
>>>    the condition has length > 1 and only the first element will be used
>>>
>>> Using
>>> zz<-file(description="path","w")
>>> write.csv(  )
>>> close(zz)
>>>
>>> creates an empty file but yields the same error message when I execute
>>> write.csv.
>>
>>
>> Please tell us what you actually did.
>>
>> This works for me:
>>
>> zz <- file(description="path", "w")
>> write.csv(iris, zz)
>> close(zz)
>>
>> Best,
>> Uwe Ligges
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Mon Dec 16 16:49:47 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 16 Dec 2013 07:49:47 -0800
Subject: [R] how to  add a line in the graph?
In-Reply-To: <tencent_3BA8C4D2179533E50A5E6DDB@qq.com>
References: <tencent_3BA8C4D2179533E50A5E6DDB@qq.com>
Message-ID: <6CBC9BB4-8FE0-4B61-8912-19432B566BF8@comcast.net>


On Dec 15, 2013, at 4:46 AM, ???? wrote:

> t<--4:4
> y<-c(5,7,10,13,15,16,14,12,11)
> plot(t,y,type="l")
> 
> how can i add a curve  y=0.83*t-0.44*t^2  in the graph?
> 	[[alternative HTML version deleted]]

t<--4:4
y<-c(5,7,10,13,15,16,14,12,11)
plot(t,y,type="l", ylim=c(-4,16))

curve( 0.83*x-0.44*x^2 , add=TRUE, col="red")

-- 

David Winsemius
Alameda, CA, USA


From juliosergio at gmail.com  Mon Dec 16 16:55:52 2013
From: juliosergio at gmail.com (Julio Sergio Santana)
Date: Mon, 16 Dec 2013 15:55:52 +0000
Subject: [R] Using assign with mapply
References: <loom.20131206T200836-152@post.gmane.org>
Message-ID: <loom.20131216T163956-835@post.gmane.org>

Julio Sergio Santana <juliosergio <at> gmail.com> writes:

> 
> I have a data frame whose first colum contains the names of the variables 
> and whose second colum contains the values to assign to them:
> 
>    : kkk <- data.frame(vars=c("var1", "var2", "var3"), 
>                      vals=c(10, 20, 30), stringsAsFactors=F)
> 

For those interested in the problem this is how I solved the problem:


I want to have something similar to:
#
#   var1 <- 10
#   var2 <- 20
#   var3 <- 30

my first trial was:

   mapply(assign,  kkk$vars, kkk$vals)
## var1 var2 var3 
## 10   20   30 
#

This is, however, what I got:

   var1
## Error: object 'var1' not found

David Winsemius suggested me something similar to 


   mapply(assign,  kkk$vars, kkk$vals, MoreArgs = list(pos = 1))
# or:
   mapply(assign,  kkk$vars, kkk$vals, MoreArgs = list(envir = .GlobalEnv))

var1
## [1] 10

This almost works, but what if this construction is used inside a function?

   example <- function () {
      var1 <- 250
      kkk <- data.frame(vars=c("var1", "var2", "var3"), 
                        vals=c(10, 20, 30), stringsAsFactors=F)
     mapply(assign,  kkk$vars, kkk$vals, MoreArgs = list(pos = 1))
     print (var2)
     print (var1)
   }

   example()
## [1] 20
## [1] 250

var1, which was defined inside the function, isn't modified

To fix this, I defined the function as follows: 

   example <- function () {
     var1 <- 250
     kkk <- data.frame(vars=c("var1", "var2", "var3"), 
                       vals=c(10, 20, 30), stringsAsFactors=F)
     mapply(assign,  kkk$vars, kkk$vals, 
            MoreArgs = list(pos = sys.frame(sys.nframe())))
     # sys.nframe() is the number of the frame created inside the function
     # and sys.frame() establishes it as the one assign uses to set values
     print (var2)
     print (var1)
   }

   example()
## [1] 20
## [1] 10

And the purpose is got

Thanks,

  -Sergio.


From marc_schwartz at me.com  Mon Dec 16 17:02:51 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 16 Dec 2013 10:02:51 -0600
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <001101cefa6c$a8fb5a60$faf20f20$@tamu.edu>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
	<52AE39F7.8000702@gmail.com> <001101cefa6c$a8fb5a60$faf20f20$@tamu.edu>
Message-ID: <3D6A905E-B6A6-4FA9-8999-40F35F494540@me.com>


On Dec 16, 2013, at 8:39 AM, David Carlson <dcarlson at tamu.edu> wrote:

> This will create a simple plot using Windows enhanced metafile
> format:
> 
>> win.metafile("TestFigure.emf")
>> plot(rnorm(25), rnorm(25))
>> dev.off()
> null device 
>          1 
>> 
> 
> Windows does not read pdf.


This is correct for Office on Windows, not for Office on OSX. However, if you share the Office document created on OSX that has a PDF embedded with Windows Office users, they will see a bitmapped version of the graphic, rather than the PDF.


> It will offer to import an eps
> (encapsulated postscript) file, but it only imports the bitmap
> thumbnail image of the figure so it is completely useless.


Regarding EPS imports, this is NOT correct.

Word and the other Office apps will import the EPS file. It cannot render the postscript however, thus it will **display** a bitmapped preview image.

If you print the Word document using a PS compatible printer driver, you will get the full high quality vector based graphic output. If you print to a non-PS compatible printer, the bitmapped preview is what will be printed.

You may need to install EPS import filters for Office if they were not installed during the initial Office installation.

That being said, while it has been years since I was on Windows, I used to use the WMF/EMF format to import or just copy/paste into Word, when I needed a document containing an R plot that could be shared with others. In most cases, the image quality was fine.

Regards,

Marc Schwartz


> You
> can edit a metafile in Word, but different versions seem to have
> different issues. Earlier versions would lose clipping if you
> tried to edit the file, but World 2013 works reasonably well.
> Text labels can jump if you edit the figure in Word (especially
> rotated text) although it is simple to drag them back to where
> you want them. I haven't tried 2010 or 2007 recently.
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan
> Murdoch
> Sent: Sunday, December 15, 2013 5:24 PM
> To: david hamer; r-help at r-project.org
> Subject: Re: [R] Exporting R graphics into Word without losing
> graph quality
> 
> On 13-12-15 6:00 PM, david hamer wrote:
>> Hello,
>> 
>> My x-y scatterplot produces a very ragged best-fit line when
> imported into
>> Word.
> 
> Don't use a bitmap format (png).
> 
> Don't produce your graph in one format (screen display), then
> convert to 
> another (png).  Open the device in the format you want for the
> final file.
> 
> Use a vector format for output.  I don't know what kinds Word
> supports, 
> but EPS or PDF would likely be best; if it can't read those,
> then 
> Windows metafile (via windows() to open the device) would be
> best. 
> (Don't trust the preview to tell you the quality of the graph,
> try 
> printing the document.  Word isn't quite as bad as it appears.)
> 
> Don't use Word.
> 
> Duncan Murdoch
> 
>> 
>> 
>> 
>> * >plot (data.file$x, data.file$y, type = "p", las=1, pch=20,
> ylab =
>> expression("Cover of Species y" ~ (m^{2}~ha^{-1} )),
> xlab =
>> expression("Cover of Species x" ~ (m^{2}~ha^{-1}))  )
>> lines  (
>> data.file$x,   fitted ( model.x )  )*
>> 
>>  A suggestion from the internet is to use .png at high (1200)
> resolution.
>>    * >dev.print  ( device = png,  file = "R.graph.png",
> width = 1200,
>> height = 700)*
>> This gives a high-quality graph, but the titles and tick-mark
> labels become
>> very tiny when exported into Word.
>> 
>> I therefore increased the size of the titles and tick-mark
> labels with cex.
>>    * >plot (......cex =1.8, cex.lab = 1.8, cex.axis =
> 1.25,....)*
>> But this causes the x-axis title to lie on top of the
> tick-mark labels.
>> (This problem does not occur with the y-axis, where the title
> lies well
>> away from the y-axis tick-mark labels.)
>> Changing margins     * >par ( mai = c ( 1.3, 1.35, 1, .75 ) )*
> does not
>> seem to have any effect on this.
>> 
>> A suggestion from the internet is to delete the titles from
> plot, and use
>> mtext with line=4 to drop the title lower on the graph.
>> 
>> * >plot (.......  ylab = " ", xlab = " ".....)    >mtext(side
> = 1, "Cover
>> of Species x (superscripts??)", line = 4)*
>> This works, but with mtext I have now lost the ability to have
> the
>> superscripts in the axis title.
>> 
>> And I am back full circle, having to lower the resolution of
> the graph to
>> keep the x-axis title away from the axis, and thus reverting
> to a ragged,
>> segmented "line" when exported to Word......
>> 
>> Final note:  The R graphics window version of the graph
> becomes very
>> distorted, even though the graph may be of high quality (other
> than the
>> problem of the x-axis title overlaying the x-axis tick-mark
> labels) once in
>> Word.  I guess this is because of using "tricks" to try to get
> a desired
>> end-product in Word....
>> 
>> Thanks for any suggestions,
>>          David.


From collinl at cs.pitt.edu  Mon Dec 16 17:27:27 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Mon, 16 Dec 2013 11:27:27 -0500
Subject: [R] Power calculations for Wilcox.test
Message-ID: <Pine.LNX.4.44.1312161115130.16473-100000@hydrogen.cs.pitt.edu>

Greetings, I'm working on some analyses where I need to calculate wilcox
tests for paired samples.  In my current literature search I've found a
few papers on sample size determination for the wilcox test notably:

Sample Size Determination for Some Common Nonparametric Tests
Gottfried E. Noether
Journal of the American Statistical Association

http://www.jstor.org.pitt.idm.oclc.org/stable/2289477

My question is: are there any implementations of power calculations for
the wilcox test in R based either on Noether's methods for sample size or
another method?

	Thanks,
	Collin.


From c-w.hoffmann at sunrise.ch  Mon Dec 16 17:39:36 2013
From: c-w.hoffmann at sunrise.ch (Christian Hoffmann)
Date: Mon, 16 Dec 2013 17:39:36 +0100
Subject: [R] history ?? 2 no readline ?
Message-ID: <52AF2CC8.7050109@sunrise.ch>

Hi,

What could the cause of

> history()
Error in savehistory(file) : no history available to save
> savehistory(file="myhist")
Error in savehistory(file) : no history available to save
> save.image()

be?

I have the information in the attached gif

Cheers   Christian
-- 
Christian W. Hoffmann,
CH - 8915 Hausen am Albis, Switzerland
Rigiblickstrasse 15 b, Tel.+41-44-7640853
c-w.hoffmann at sunrise.ch,
christian at echoffmann.ch,
www.echoffmann.ch


From valentina.lauria at nuigalway.ie  Mon Dec 16 16:14:24 2013
From: valentina.lauria at nuigalway.ie (Lauria, Valentina)
Date: Mon, 16 Dec 2013 15:14:24 +0000
Subject: [R] error with as.factor raster
Message-ID: <B11DE93D7F439D4BA1E942572BA75030A3EDA831@UDSMBX02.uds.nuigalway.ie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/ffe9ead7/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Dec 16 18:28:36 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 16 Dec 2013 17:28:36 +0000
Subject: [R] error with as.factor raster
In-Reply-To: <B11DE93D7F439D4BA1E942572BA75030A3EDA831@UDSMBX02.uds.nuigalway.ie>
References: <B11DE93D7F439D4BA1E942572BA75030A3EDA831@UDSMBX02.uds.nuigalway.ie>
Message-ID: <52AF3844.8080706@stats.ox.ac.uk>

On 16/12/2013 15:14, Lauria, Valentina wrote:
> Dear List members,
>
> I am trying to map the habitat suitability of Nephrops and one of my predictor is a categorical variable.
>
> However when I utilised the command "as.factor" (before to create my rasters stack) I get the error message "Error in 1:ncol(r) : argument of length 0".
>
> Could anyone help me?

Yes.  This is a bug in package raster.  So please follow the posting 
guide and report to the maintainer, with the 'at a minimum' information 
missing here (a crucial part being the version of raster).

Using 1:ncol() is bad practice (seq_len is designed for that purpose), 
but the raster maintainer misuses it ca 100x.

>
>> r4 <- raster("C:/POSTDOC/NEPHROPS_Habitat_Mapping/NEPHROPS_HabMod_PAPER1/Scotland/IN_eunis_sed.tif")
>> plot(r4)
>> is.factor(r4)
> [1] TRUE
>> as.factor(r4)
> class       : RasterLayer
> dimensions  : 250, 413, 103250  (nrow, ncol, ncell)
> resolution  : 0.01484784, 0.01484784  (x, y)
> extent      : -7.774709, -1.642552, 54.95371, 58.66567  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
> data source : C:\POSTDOC\NEPHROPS_Habitat_Mapping\NEPHROPS_HabMod_PAPER1\Scotland\IN_eunis_sed.tif
> names       : IN_eunis_sed
> values      : 1, 6  (min, max)
> attributes  :
> Error in 1:ncol(r) : argument of length 0
>> levels(r4)
> [[1]]
>    ID    OBJECTID Value Count sediment
>    0           1               1         2716        R
>     1           2               2         2249       CS
>     2           3               3         2647       MS
>     3           4              4         6819        M
>     4            5             5          889      MXS
>     5            6             6         3647        S
>
>
> Thank you very much in advance.
> Best Regards,
> Valentina
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ahoerner at rprogress.org  Mon Dec 16 18:31:07 2013
From: ahoerner at rprogress.org (Andrew Hoerner)
Date: Mon, 16 Dec 2013 09:31:07 -0800
Subject: [R] Assigning default function arguments to themselves: Why?
Message-ID: <CA+t4QRpSs_1NYVNrMwqsHhPB==tjuA6F6dSzU76L0AhU_kHyFw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/42fed361/attachment.pl>

From wdunlap at tibco.com  Mon Dec 16 18:52:57 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 16 Dec 2013 17:52:57 +0000
Subject: [R] Assigning default function arguments to themselves: Why?
In-Reply-To: <CA+t4QRpSs_1NYVNrMwqsHhPB==tjuA6F6dSzU76L0AhU_kHyFw@mail.gmail.com>
References: <CA+t4QRpSs_1NYVNrMwqsHhPB==tjuA6F6dSzU76L0AhU_kHyFw@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1DA29@PA-MBX01.na.tibco.com>

> I have noticed that many functions contain arguments with defaults of
> the form X=X.

Can you show us one (one that 'works')?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Andrew Hoerner
> Sent: Monday, December 16, 2013 9:31 AM
> To: r-help at r-project.org
> Subject: [R] Assigning default function arguments to themselves: Why?
> 
> Let us suppose that we have a function foo(X) which is called inside
> another function, bar(). Suppose, moreover, that the name "X" has been
> assigned a value when foo is called.
> 
> I have noticed that many functions contain arguments with defaults of
> the form X=X. Call this reflexive assignment. How is foo(X=X)
> different from foo(X)? Isn't the environment from which X is located
> the parent environment of foo() in either case? Or if it looks first
> in the environment of foo, will it not immediately pop up to the
> parent frame if it is not found in foo? Are reflexive assignments just
> to keep X from being positionaly assigned accidentally, or are They
> doing something deeper?
> 
> A question which is (I think) related: Is it good or bad practice,
> when defining a function inside another function, to use the name of a
> variable from the calling function as the argument of the called
> function?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From careyshan at gmail.com  Mon Dec 16 20:58:41 2013
From: careyshan at gmail.com (Shane Carey)
Date: Mon, 16 Dec 2013 19:58:41 +0000
Subject: [R] 3-D interpretation
In-Reply-To: <CA+jRDxCmHs0UhZ1BNOdQSoDimh4+bw==S7OqNJH8W=TpS5R7og@mail.gmail.com>
References: <CA+jRDxCTx5qhTeT+CAD8qSzjvdB_+s6Zk-2BDuN6N7WU_kLEpg@mail.gmail.com>
	<021701cef5c4$d36cef90$7a46ceb0$@tamu.edu>
	<CA+jRDxD6aX2ZmUyw9EjmTqYrh=FwZLKxX9ATWk922ruvyf=SsQ@mail.gmail.com>
	<024301cef5c5$78fa6000$6aef2000$@tamu.edu>
	<CA+jRDxBuxxASSkRk2uCZ0F+N1YaXpfKhGanWf7xdBSfnW1uSMA@mail.gmail.com>
	<loom.20131211T161018-956@post.gmane.org>
	<CA+jRDxBFsfGndvxvjjJcQqVt=nNCmDawVNgVd6cv1gcG05VOSQ@mail.gmail.com>
	<52A891AF.3080207@gmail.com>
	<CA+jRDxAA5h2gVLCYgxBhtsH7QkSwehB7FDO_Pyu+81Ne_4mp+w@mail.gmail.com>
	<CA+jRDxBogfM-ZWz3VT7DR6w41u3zBOx+UavhBazdXt3LpK9q-w@mail.gmail.com>
	<52A8B054.9040700@gmail.com>
	<CA+jRDxCmHs0UhZ1BNOdQSoDimh4+bw==S7OqNJH8W=TpS5R7og@mail.gmail.com>
Message-ID: <CA+jRDxBY1_wH4bkyhn45wAzNf_9DuE4=erTX=RYkHjb-TLwoBQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/dc64b678/attachment.pl>

From dwinsemius at comcast.net  Mon Dec 16 21:09:23 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 16 Dec 2013 12:09:23 -0800
Subject: [R] Power calculations for Wilcox.test
In-Reply-To: <Pine.LNX.4.44.1312161115130.16473-100000@hydrogen.cs.pitt.edu>
References: <Pine.LNX.4.44.1312161115130.16473-100000@hydrogen.cs.pitt.edu>
Message-ID: <CE296029-2C79-4F58-8C80-752EA49A49B4@comcast.net>


On Dec 16, 2013, at 8:27 AM, Collin Lynch wrote:

> Greetings, I'm working on some analyses where I need to calculate wilcox
> tests for paired samples.  In my current literature search I've found a
> few papers on sample size determination for the wilcox test notably:
> 
> Sample Size Determination for Some Common Nonparametric Tests
> Gottfried E. Noether
> Journal of the American Statistical Association
> 
> http://www.jstor.org.pitt.idm.oclc.org/stable/2289477
> 
> My question is: are there any implementations of power calculations for
> the wilcox test in R based either on Noether's methods for sample size or
> another method?
> 

You've offered a citation that is perhaps only accessible from computers within your own institution: at any rate it's not accessible to this non-academic viewer. Doing a tiny bit of searching shows it to be found on an alternate website:

www.stat.purdue.edu/~jennings/stat582/notes/docs3-9-10/noether.pdf?

Paired tests are really one-sample tests against a location parameter of 0.

The equations presented in that article are fairly simple. It should be easy to implement with basic R programming methods.

These days statisticians would approach the problem by setting up a simulation. It allows investiagation of more complex analysis strategies.

To look for pre-canned approaches.
To search R functions, the sos package is useful:

library(sos)

 findFn("power nonparametric")

findFn("sample size power wilcox")
found 25 matches;  retrieving 2 pages
2 
Downloaded 12 links in 10 packages.

I'm not sure why ciNparN {EnvStats} didn't show up in that set of links since the title of the help page is "Sample Size for Nonparametric Confidence Interval for a Quantile". That should be able to estimate a sample size for a specified width of CI for the median. That's a precision oriented determination which I suspect should be the same as a method that were based on sampling properties of a distribution, since you are working with ranks.

-- 

David Winsemius
Alameda, CA, USA


From rmailbox at justemail.net  Mon Dec 16 22:12:54 2013
From: rmailbox at justemail.net (rmailbox at justemail.net)
Date: Mon, 16 Dec 2013 13:12:54 -0800
Subject: [R] extracting non-NA entries from a two-way frequency table
In-Reply-To: <52ACE098.6030104@yorku.ca>
References: <52AB6306.7000308@yorku.ca>
	<1386964895.27485.59344777.0EFDA5B8@webmail.messagingengine.com>
	<52ACE098.6030104@yorku.ca>
Message-ID: <1387228374.8211.60375201.01962266@webmail.messagingengine.com>

Sorry about omitting library(plyr).
It's really thanks to Hadley, of course. His contributions make us all (capable of being) better.
Eric


----- Original message -----
From: Michael Friendly <friendly at yorku.ca>
To: rmailbox at justemail.net, r-help at r-project.org
Subject: Re: extracting non-NA entries from a two-way frequency table
Date: Sat, 14 Dec 2013 17:50:00 -0500

Very elegant! Thank you Eric.

(You omitted library(plyr), so I had to search for arrange())

-Michael

On 12/13/2013 3:01 PM, rmailbox at justemail.net wrote:
> Perhaps this?
>
> library(reshape2)
> library(stringr)
>
> GeisslerLong <- melt (Geissler, id.vars = c("boys"))
> GeisslerLong <- transform ( GeisslerLong, girls = as.numeric ( str_replace( variable, "g", '' )) )
> GeisslerLong <- rename ( GeisslerLong, c( value = "Freq"))
> GeisslerLong <- arrange ( GeisslerLong, boys, girls)
> GeisslerLong <- subset ( GeisslerLong, !is.na ( Freq), select = c( boys, girls, Freq))
>
>
> Eric
>
>
> ----- Original message -----
> From: Michael Friendly <friendly at yorku.ca>
> To: "R-help" <r-help at r-project.org>
> Subject: [R] extracting non-NA entries from a two-way frequency table
> Date: Fri, 13 Dec 2013 14:41:58 -0500
>
> I have data in the form of a two-way table recording the number of
> families with varying numbers
> of boys (rows) and girls (columns: g0 -- g12) below, also given in
> dput() format.
>
> I want to convert this to a data frame containing only the non-NA
> entries, with columns
> boys, girls, Freq, where Freq is the table entry.  Can anyone help with
> this?
> I suppose that the steps are to transpose each row to a column
> identifying the number of
> girls, and then delete the NAs, but I can't quite see how to do this.
>
>
>   > Geissler
>      boys     g0     g1    g2    g3    g4   g5   g6   g7  g8 g9 g10 g11 g12
> 1    12      7     NA    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 2    11     24     45    NA    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 3    10     30     93   181    NA    NA   NA   NA   NA  NA NA  NA  NA  NA
> 4     9     90    287   492   478    NA   NA   NA   NA  NA NA  NA  NA  NA
> 5     8    264    713  1027  1077   829   NA   NA   NA  NA NA  NA  NA  NA
> 6     7    631   1655  2418  2309  1801 1112   NA   NA  NA NA  NA  NA  NA
> 7     6   1579   3725  4948  4757  3470 2310 1343   NA  NA NA  NA  NA  NA
> 8     5   3666   7908  9547  8498  6436 3878 2161 1033  NA NA  NA  NA  NA
> 9     4   8628  16340 17332 14479 10263 5917 3072 1540 670 NA  NA  NA  NA
> 10    3  20540  31611 30175 22221 13972 7603 3895 1783 837 286  NA  NA  NA
> 11    2  47819  57179 44793 28630 15700 8171 3951 1776 722 275 104  NA  NA
> 12    1 114609  89213 53789 28101 13740 6233 2719 1152 432 151  72  24  NA
> 13    0     NA 108719 42860 17395  7004 2839 1096  436 161 66  30   8   3
>
> Geissler <-
> structure(list(boys = c(12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L,
> 3L, 2L, 1L, 0L), g0 = c(7L, 24L, 30L, 90L, 264L, 631L, 1579L,
> 3666L, 8628L, 20540L, 47819L, 114609L, NA), g1 = c(NA, 45L, 93L,
> 287L, 713L, 1655L, 3725L, 7908L, 16340L, 31611L, 57179L, 89213L,
> 108719L), g2 = c(NA, NA, 181L, 492L, 1027L, 2418L, 4948L, 9547L,
> 17332L, 30175L, 44793L, 53789L, 42860L), g3 = c(NA, NA, NA, 478L,
> 1077L, 2309L, 4757L, 8498L, 14479L, 22221L, 28630L, 28101L, 17395L
> ), g4 = c(NA, NA, NA, NA, 829L, 1801L, 3470L, 6436L, 10263L,
> 13972L, 15700L, 13740L, 7004L), g5 = c(NA, NA, NA, NA, NA, 1112L,
> 2310L, 3878L, 5917L, 7603L, 8171L, 6233L, 2839L), g6 = c(NA,
> NA, NA, NA, NA, NA, 1343L, 2161L, 3072L, 3895L, 3951L, 2719L,
> 1096L), g7 = c(NA, NA, NA, NA, NA, NA, NA, 1033L, 1540L, 1783L,
> 1776L, 1152L, 436L), g8 = c(NA, NA, NA, NA, NA, NA, NA, NA, 670L,
> 837L, 722L, 432L, 161L), g9 = c(NA, NA, NA, NA, NA, NA, NA, NA,
> NA, 286L, 275L, 151L, 66L), g10 = c(NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, 104L, 72L, 30L), g11 = c(NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, 24L, 8L), g12 = c(NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, 3L)), .Names = c("boys", "g0", "g1",
> "g2", "g3", "g4", "g5", "g6", "g7", "g8", "g9", "g10", "g11",
> "g12"), class = "data.frame", row.names = c(NA, -13L))
>
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From yuanzhi.li at usherbrooke.ca  Mon Dec 16 23:08:28 2013
From: yuanzhi.li at usherbrooke.ca (yuanzhi)
Date: Mon, 16 Dec 2013 14:08:28 -0800 (PST)
Subject: [R] Chinese Garbled
In-Reply-To: <CA+vqiLHsytJAT8sXkbbGvzML0fcKuvdGjLALLm4WCa6JLiOJRA@mail.gmail.com>
References: <1386998521870-4682184.post@n4.nabble.com>
	<CA+vqiLHsytJAT8sXkbbGvzML0fcKuvdGjLALLm4WCa6JLiOJRA@mail.gmail.com>
Message-ID: <1387231708577-4682302.post@n4.nabble.com>

Ista Zahn wrote
> This is the R-help mailing list. If your problem persists when using R
> from the command line or with the GUI shipped with R on your
> (unspecified) platform post back here. Otherwise the RStudio support
> forum is at https://support.rstudio.com
> 
> Best,
> Ista
> 
> On Sat, Dec 14, 2013 at 12:22 AM, yuanzhi &lt;

> yuanzhi.li@

> &gt; wrote:
>> Hello, I met a problem which needs your help. I reinstalled the R and
>> Rstudio
>> recently. After that, I found there was a problem that the Chinese
>> character
>> was garbled in Rstudio sometimes.
>>
>> example 1
>> "richness.csv" is a file containing three columns and the names of the
>> three
>> columns are "????"??????"???"? But when I read this file with function
>> "read.csv" and displayed, these Chinese characters are garbled like the
>> followings?
>>> x<-read.csv("richness.csv")
>>> x[1:5,]
>>   X..??? X.?? ???
>> 1        CK    ?     34
>> 2        CK    ?     43
>> 3        CK    ?     45
>> 4        CK    ?     41
>> 5        CK    ?     33
>>
>> example2
>>
>> Sometimes the prompting message also contains garabled Chinese
>> characters.
>> For example, when I run "?bargraph.CI"(which is a function in package
>> "sciplot") before I use the cammand "library(sciplot)", it will appear
>> the
>> following message with garbled Chinese characters:
>>> ?bargraph.CI
>> No documentation for ?argraph.CI?in specified packages and libraries:
>> you could try ??bargraph.CI?
>>
>> So, what can I do to solve the problem. Thank you!
>> Yuanzhi
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Chinese-Garbled-tp4682184.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> 

> R-help@

>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Hi, I am sorry to reply so late. Actually, When I run these codes directly
in R(not Rstudio), it also appears the problem but in a different type:

> x<-read.csv("richness.csv")
> x[1:5,]
  X..???.?. X.?.? ??????
1        CK    ??     34
2        CK    ??     43
3        CK    ??     45
4        CK    ??     41
5        CK    ??     33

So, what should I do solve this problem?




--
View this message in context: http://r.789695.n4.nabble.com/Chinese-Garbled-tp4682184p4682302.html
Sent from the R help mailing list archive at Nabble.com.


From wdunlap at tibco.com  Tue Dec 17 00:09:33 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 16 Dec 2013 23:09:33 +0000
Subject: [R] Chinese Garbled
In-Reply-To: <1387231708577-4682302.post@n4.nabble.com>
References: <1386998521870-4682184.post@n4.nabble.com>
	<CA+vqiLHsytJAT8sXkbbGvzML0fcKuvdGjLALLm4WCa6JLiOJRA@mail.gmail.com>
	<1387231708577-4682302.post@n4.nabble.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1DB8F@PA-MBX01.na.tibco.com>

>> columns are "????"??????"???"? But when I read this file with function
>> "read.csv" and displayed, these Chinese characters are garbled like the
>> followings?
>>> x<-read.csv("richness.csv")
>>> x[1:5,]
>>   X..??? X.?? ???
>> 1        CK    ?     34

You have to, at least, use the check.names=FALSE argument to read.csv.

E.g.,
  > str(read.csv(text="%*,&*,$\n1,2,4\n2,3,5"))
  'data.frame':   2 obs. of  3 variables:
   $ X..  : int  1 2
   $ X...1: int  2 3
   $ X.   : int  4 5
  > str(read.csv(text="%*,&*,$\n1,2,4\n2,3,5", check.names=FALSE))
  'data.frame':   2 obs. of  3 variables:
   $ %*: int  1 2
   $ &*: int  2 3
   $ $ : int  4 5

There may be more you have to do.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of yuanzhi
> Sent: Monday, December 16, 2013 2:08 PM
> To: r-help at r-project.org
> Subject: Re: [R] Chinese Garbled
> 
> Ista Zahn wrote
> > This is the R-help mailing list. If your problem persists when using R
> > from the command line or with the GUI shipped with R on your
> > (unspecified) platform post back here. Otherwise the RStudio support
> > forum is at https://support.rstudio.com
> >
> > Best,
> > Ista
> >
> > On Sat, Dec 14, 2013 at 12:22 AM, yuanzhi &lt;
> 
> > yuanzhi.li@
> 
> > &gt; wrote:
> >> Hello, I met a problem which needs your help. I reinstalled the R and
> >> Rstudio
> >> recently. After that, I found there was a problem that the Chinese
> >> character
> >> was garbled in Rstudio sometimes.
> >>
> >> example 1
> >> "richness.csv" is a file containing three columns and the names of the
> >> three
> >> columns are "????"??????"???"? But when I read this file with
> function
> >> "read.csv" and displayed, these Chinese characters are garbled like the
> >> followings?
> >>> x<-read.csv("richness.csv")
> >>> x[1:5,]
> >>   X..??? X.?? ???
> >> 1        CK    ?     34
> >> 2        CK    ?     43
> >> 3        CK    ?     45
> >> 4        CK    ?     41
> >> 5        CK    ?     33
> >>
> >> example2
> >>
> >> Sometimes the prompting message also contains garabled Chinese
> >> characters.
> >> For example, when I run "?bargraph.CI"(which is a function in package
> >> "sciplot") before I use the cammand "library(sciplot)", it will appear
> >> the
> >> following message with garbled Chinese characters:
> >>> ?bargraph.CI
> >> No documentation for ?argraph.CI?in specified packages and libraries:
> >> you could try ??bargraph.CI?
> >>
> >> So, what can I do to solve the problem. Thank you!
> >> Yuanzhi
> >>
> >>
> >>
> >> --
> >> View this message in context:
> >> http://r.789695.n4.nabble.com/Chinese-Garbled-tp4682184.html
> >> Sent from the R help mailing list archive at Nabble.com.
> >>
> >> ______________________________________________
> >>
> 
> > R-help@
> 
> >  mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> 
> > R-help@
> 
> >  mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> Hi, I am sorry to reply so late. Actually, When I run these codes directly
> in R(not Rstudio), it also appears the problem but in a different type:
> 
> > x<-read.csv("richness.csv")
> > x[1:5,]
>   X..???.?. X.?.? ??????
> 1        CK    ??     34
> 2        CK    ??     43
> 3        CK    ??     45
> 4        CK    ??     41
> 5        CK    ??     33
> 
> So, what should I do solve this problem?
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Chinese-Garbled-
> tp4682184p4682302.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From santosh2005 at gmail.com  Tue Dec 17 00:10:47 2013
From: santosh2005 at gmail.com (Santosh)
Date: Mon, 16 Dec 2013 15:10:47 -0800
Subject: [R] read ".slk" file
Message-ID: <CAN_e6XvqBmk26ubOP-852LwGDEx_PgY4=Z0Fu6XakWVffFBDaQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/862794fd/attachment.pl>

From jkaron at earthlink.net  Tue Dec 17 00:38:02 2013
From: jkaron at earthlink.net (J Karon)
Date: Mon, 16 Dec 2013 15:38:02 -0800 (PST)
Subject: [R] Invalid connection error message when trying to write a file
In-Reply-To: <52AF1F2B.30108@statistik.tu-dortmund.de>
References: <1386961869720-4682149.post@n4.nabble.com>
	<52AC8FEA.2090905@statistik.tu-dortmund.de>
	<84534FFA466443F391A41E56E6E45B27@JohnKaronHP>
	<52AE0363.2010705@statistik.tu-dortmund.de>
	<9827DBC6D3BD4D07813E1DE403F14909@JohnKaronHP>
	<52AF1F2B.30108@statistik.tu-dortmund.de>
Message-ID: <0A775826F28543A79C8820268B976ADC@JohnKaronHP>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/e1356b84/attachment.pl>

From r.turner at auckland.ac.nz  Tue Dec 17 01:47:42 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 17 Dec 2013 13:47:42 +1300
Subject: [R] How to choose data from two sets of data to ensure that the
 choosed data has a better normal feature?
In-Reply-To: <dfde9ba9-35d5-4c72-946a-c9ba096877e0@email.android.com>
References: <CABmD0bHqsQ_+kT6ai2kfh-piLm7CaLR+WNfspVK19sU8OZa9yw@mail.gmail.com>
	<dfde9ba9-35d5-4c72-946a-c9ba096877e0@email.android.com>
Message-ID: <52AF9F2E.5060109@auckland.ac.nz>

On 16/12/13 20:59, Jeff Newmiller wrote:

         <SNIP>
> This is not a statistics theory forum, but posting a solution to this nonsensical problem would be irresponsible.

Fortune?

     cheers,

     Rolf


From steve.taylor at aut.ac.nz  Tue Dec 17 03:02:36 2013
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Tue, 17 Dec 2013 02:02:36 +0000
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <3D6A905E-B6A6-4FA9-8999-40F35F494540@me.com>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
	<52AE39F7.8000702@gmail.com> <001101cefa6c$a8fb5a60$faf20f20$@tamu.edu>
	<3D6A905E-B6A6-4FA9-8999-40F35F494540@me.com>
Message-ID: <CCE952776B6679469977532BD863C39C7E7AF5CB@Lewis.autuni.aut.ac.nz>

Unfortunately the win.metafile() device does not support semi-transparent colours, which I like using.

In my experience, the best way to get R graphics into Word is to use compressed high-resolution tiff, like this:

word.tif = function(filename="Word_Figure_%03d.tif", zoom=4, width=17, height=10, pointsize=10, ...) {
  if (!grepl("[.]ti[f]+$", filename, ignore.case=TRUE))
      filename = paste0(filename,".tif")
  tiff(filename=filename, compression="lzw", res=96*zoom, 
       width=width, height=height, units='cm', pointsize=pointsize, ...)
}
word.tif('test')
plot(rnorm(100))
dev.off()

Now drag the file test.tif into your Word document.

Sure, it's a bitmap format rather than a vector format, but the quality is excellent and the file sizes are still quite small.  None of the vector formats works as well as this.

cheers,
    Steve


From steve.taylor at aut.ac.nz  Tue Dec 17 03:23:07 2013
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Tue, 17 Dec 2013 02:23:07 +0000
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <52AE39F7.8000702@gmail.com>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
	<52AE39F7.8000702@gmail.com>
Message-ID: <CCE952776B6679469977532BD863C39C7E7AF623@Lewis.autuni.aut.ac.nz>

> From: Duncan Murdoch...
 
> Don't use a bitmap format (png).
I disagree.  Each vector format comes with its own problems.

> Don't produce your graph in one format (screen display), then convert to
> another (png).  Open the device in the format you want for the final file.
Agreed.
 
> Use a vector format for output.  
Why?  Sure, that's good advice in the ideal (pdflatex) world, but not necessarily the best of advice for Word users.

> I don't know what kinds Word supports, but
> EPS or PDF would likely be best; if it can't read those, then Windows metafile
> (via windows() to open the device) would be best.
None of these works well, if at all, in my experience with Word.

> Don't use Word.
Some of us don't really have a choice.


From j.david.hamer at gmail.com  Tue Dec 17 05:33:41 2013
From: j.david.hamer at gmail.com (david hamer)
Date: Mon, 16 Dec 2013 21:33:41 -0700
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <CCE952776B6679469977532BD863C39C7E7AF623@Lewis.autuni.aut.ac.nz>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
	<52AE39F7.8000702@gmail.com>
	<CCE952776B6679469977532BD863C39C7E7AF623@Lewis.autuni.aut.ac.nz>
Message-ID: <CAEEpX7q4MTHCfMUTXWGkgcbTjKjN1oGMTjBxHVAFDHXx9tq07g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/b1c9e6ad/attachment.pl>

From davidmarino838 at gmail.com  Tue Dec 17 06:41:03 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Mon, 16 Dec 2013 21:41:03 -0800
Subject: [R] How to choose data from two sets of data to ensure that the
 choosed data has a better normal feature?
In-Reply-To: <52AF9F2E.5060109@auckland.ac.nz>
References: <CABmD0bHqsQ_+kT6ai2kfh-piLm7CaLR+WNfspVK19sU8OZa9yw@mail.gmail.com>
	<dfde9ba9-35d5-4c72-946a-c9ba096877e0@email.android.com>
	<52AF9F2E.5060109@auckland.ac.nz>
Message-ID: <CABmD0bGVMK+9LZTQhEjdU0HB1x+pL02wTs2eFFHXia-XA048nw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/c3a3e0f6/attachment.pl>

From 1248283536 at qq.com  Tue Dec 17 07:50:21 2013
From: 1248283536 at qq.com (=?gb18030?B?y66+ssH3ye4=?=)
Date: Tue, 17 Dec 2013 14:50:21 +0800
Subject: [R] result
Message-ID: <tencent_76E7414F3F22E93208771496@qq.com>

Mydata is as under.
dat="  salary   ex
+ 1   1856 1799
+ 2   1856 1800
+ 3   1858 1800
+ 4   1858 1801
+ 5   1862 1803
+ 6   1862 1805
+ 7   1862 1810
+ 8   1865 1805
+ 9   1865 1808
+ 10  1865 1815
+ 11  1865 1820
+ 12  1870 1810
+ 13  1870 1830
+ 14  1880 1840
+ 15  1880 1845
+ 16  1880 1851
+ 17  1880 1853
+ 18  1880 1855
+ 19  1885 1850
+ 20  1885 1852
+ 21  1885 1857
+ 22  1885 1860
+ 23  1898 1855
+ 24  1898 1858
+ 25  1898 1861
+ 26  1898 1863
+ 27  1898 1866
+ 28  1898 1867
+ 29  1898 1890
+ 30  1902 1850
+ 31  1902 1853
+ 32  1902 1869
+ 33  1902 1872
+ 34  1902 1873
+ 35  1915 1850
+ 36  1915 1859
+ 37  1915 1863
+ 38  1915 1868
+ 39  1915 1875
+ 40  1915 1898
+ "
 
data<-read.table(text=dat,header=TRUE)
 
I want to get the result(please see the attatchment),the header is salary,the rownames is ex.
I only can get the "total column"
rev(table(cut(data[,2],breaks=seq(1795,1905,10),right=F))) 

How can I get the other data  by some code,not by hand?

From dwinsemius at comcast.net  Tue Dec 17 08:49:35 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 16 Dec 2013 23:49:35 -0800
Subject: [R] result
In-Reply-To: <tencent_76E7414F3F22E93208771496@qq.com>
References: <tencent_76E7414F3F22E93208771496@qq.com>
Message-ID: <BB82E4B7-F65D-42F5-950A-3E3E418812AA@comcast.net>


On Dec 16, 2013, at 10:50 PM, ???? wrote:

> Mydata is as under.
> dat="  salary   ex
> + 1   1856 1799
> + 2   1856 1800
> + 3   1858 1800
> + 4   1858 1801
> 
snipped
> + "
> 
> data<-read.table(text=dat,header=TRUE)
> 
> I want to get the result(please see the attatchment),the header is salary,the rownames is ex.
> I only can get the "total column"
> rev(table(cut(data[,2],breaks=seq(1795,1905,10),right=F))) 
> 
> How can I get the other data  by some code,not by hand?

Please do not crosspost to StackOverflow and Rhelp.
-- 


David Winsemius
Alameda, CA, USA


From mahboobe.akhlaghi at ymail.com  Mon Dec 16 11:31:07 2013
From: mahboobe.akhlaghi at ymail.com (Mahboobe Akhlaghi)
Date: Mon, 16 Dec 2013 10:31:07 +0000 (GMT)
Subject: [R] (no subject)
Message-ID: <1387189867.33894.YahooMailNeo@web171905.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/44c9a13f/attachment.pl>

From guayabitogirl at gmail.com  Tue Dec 17 05:56:57 2013
From: guayabitogirl at gmail.com (Kristen Ross)
Date: Mon, 16 Dec 2013 22:56:57 -0600
Subject: [R] What is the formula of Pseudo-F statistic in capscale in
	vegan?
Message-ID: <005801cefae4$6a87b850$3f9728f0$@com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131216/ec4396e4/attachment.pl>

From wasili at goutas.de  Tue Dec 17 08:41:26 2013
From: wasili at goutas.de (Wasili Goutas)
Date: Tue, 17 Dec 2013 08:41:26 +0100 (CET)
Subject: [R] unable to install XML package on Windows7
Message-ID: <108154502.175039.1387266086619.open-xchange@email.1und1.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/0f6c3e69/attachment.pl>

From jim at bitwrit.com.au  Tue Dec 17 09:13:57 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 17 Dec 2013 19:13:57 +1100
Subject: [R] result
In-Reply-To: <tencent_76E7414F3F22E93208771496@qq.com>
References: <tencent_76E7414F3F22E93208771496@qq.com>
Message-ID: <52B007C5.2030608@bitwrit.com.au>

On 12/17/2013 05:50 PM, ???? wrote:
> Mydata is as under.
> dat="  salary   ex
> + 1   1856 1799
> + 2   1856 1800
> + 3   1858 1800
> + 4   1858 1801
> + 5   1862 1803
> + 6   1862 1805
> + 7   1862 1810
> + 8   1865 1805
> + 9   1865 1808
> + 10  1865 1815
> + 11  1865 1820
> + 12  1870 1810
> + 13  1870 1830
> + 14  1880 1840
> + 15  1880 1845
> + 16  1880 1851
> + 17  1880 1853
> + 18  1880 1855
> + 19  1885 1850
> + 20  1885 1852
> + 21  1885 1857
> + 22  1885 1860
> + 23  1898 1855
> + 24  1898 1858
> + 25  1898 1861
> + 26  1898 1863
> + 27  1898 1866
> + 28  1898 1867
> + 29  1898 1890
> + 30  1902 1850
> + 31  1902 1853
> + 32  1902 1869
> + 33  1902 1872
> + 34  1902 1873
> + 35  1915 1850
> + 36  1915 1859
> + 37  1915 1863
> + 38  1915 1868
> + 39  1915 1875
> + 40  1915 1898
> + "
>
> data<-read.table(text=dat,header=TRUE)
>
> I want to get the result(please see the attatchment),the header is salary,the rownames is ex.
> I only can get the "total column"
> rev(table(cut(data[,2],breaks=seq(1795,1905,10),right=F)))
>
> How can I get the other data  by some code,not by hand?
>
Hi ????,
Your attachment didn't make it to the list, so we don't know exactly 
what you want to do. The code above produces a table of the frequencies 
of the categories you have defined:

rev(table(cut(dat[,2],breaks=seq(1795,1905,10),right=FALSE)))

[1895,1905) [1885,1895) [1875,1885) [1865,1875) [1855,1865) [1845,1855)
           1           1           1           6           9           8
[1835,1845) [1825,1835) [1815,1825) [1805,1815) [1795,1805)
           1           1           2           5           5

Do you want a summary function applied to the first column?

dat$cats<-cut(dat[,2],breaks=seq(1795,1905,10),right=FALSE)
by(dat$salary,dat$cats,mean)

or some other sort of result?

Jim


From jari.oksanen at oulu.fi  Tue Dec 17 10:10:26 2013
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Tue, 17 Dec 2013 09:10:26 +0000
Subject: [R]
	=?utf-8?q?What_is_the_formula_of_Pseudo-F_statistic_in_capsca?=
	=?utf-8?q?le_in=09vegan=3F?=
References: <005801cefae4$6a87b850$3f9728f0$@com>
Message-ID: <loom.20131217T094928-869@post.gmane.org>

Dear Kristen Ross,

Kristen Ross <guayabitogirl <at> gmail.com> writes:

>tion; and (3) the R code used for this analysis.  

Sorry that I have to remove most of your original message: gmane won't
allow me to post if I add too little compared to the cited text.

This is now wild guessing, since there is nothing I would be able to
reproduce, in particular as I cannot afford buying PRIMER licence and
cannot even see its manual. I have one guess, though. Look at the first
and last item of your table:
> 
> (1) Table
> 
>
> 
> PRIMER pseudo-F
> 
> R pseudo-F
> 
> SEQUENTIAL TESTS
> 
> GroupSize
> 
> 1.1904
> 
> 1.5528
>
...
> VolAuton
> 
> 2.2923
> 
> 2.2925
> 

I am not quite sure how to read this table, but I *assume* that one
of the numbers comes PRIMER and one from vegan:::capscale (this whole
answer is based on that assumption). As you see, the first two numbers
are very different, and the last two numerically fairly equal. I cannot
decipher the PRIMER formula for pseudo-F you give below, but I guess that
PRIMER changes the denominator of the pseudo-F at every step. I guess
it uses residual SS and residual df after the current term, and that 
would include variation explained by later variables in the sequential
tests as well as their df's. In vegan we always use the same denominator
in all cases with the same degrees of freedom. This denominator, or
scale, is the residual variation and residual df's after all 
explanatory variables (constraints). The vegan way is similar to the
one you get from ordinary anova of lm(). We refuse (and have refused
earlier) to implement anything else. However, using add1(<capscale-result>,
..., test = "perm") can give you tests that pretend that later 
variables in the sequence are not in the model. 


> (2) pseudo-F formula
> 
> We know that PRIMER uses the following formula to calculate the pseudo-F for
> a sequential test of significance (equation 4.3, Anderson, Gorley, and
> Clarke 2008, Chapter 4. Pg. 129, and based on pseudo-F equation in Legendre
> and Anderson (1999), Ecological Monographs vol. 69):
> 
> F= (SSFull - SSReduced)/(qFull-qReduced)
> 
>         (SSTotal-SSFull)/(N - qFull - 1)
> 
>  (3) R code
> 
> ## creating Bray-Curtis of Biodiversity data
> 
> H.BC <- vegdist(H.Full [,14:211], "bray")
> 
> ## Distance based redundancy analysis (dbRDA)
> 
> m1<-capscale(H.BC ~ GroupSize + Board + MtgStyle + DmStyle + DifView +
> VolAuton, SScomp [,14:19], distance = "euclidean", add = TRUE)
> 
> ### NOTE: pseudo-F values are the same with or without correcting for
> negative eigenvalues (although they are different from other programs).
>
If you here claim that the pseudo-F values are the same in
vegan:::capscale with add=FALSE and add=TRUE, I claim that you are wrong,
or that you made an error. One source of error may be that in the
example above you set 'distance = "euclidean"' in which case 'add'
argument has no effect since you have no negative eigenvalues with
Euclidean distances. However, the example above should *still* give
you negative eigenvalues and change in pseudo-F, because you did two
contradictory things: you supplied non-Euclidean dissimilarities in
input, and you asked for Euclidean distances in the command. In this case,
the 'distance' argument will be silently ignored and input dissimilarities
will be used. Please check this.

I have no idea what you mean with "correcting" for negative eigenvalues.
You can have transformation that removes them, but I cannot see 
how that would be a "correction".

Cheers, Jari Oksanen


From ripley at stats.ox.ac.uk  Tue Dec 17 10:41:44 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Dec 2013 09:41:44 +0000
Subject: [R] unable to install XML package on Windows7
In-Reply-To: <108154502.175039.1387266086619.open-xchange@email.1und1.de>
References: <108154502.175039.1387266086619.open-xchange@email.1und1.de>
Message-ID: <52B01C58.9090609@stats.ox.ac.uk>

Well, on Windows binary packages are available on CRAN.

And get the source package from CRAN, not Omegahat.  CRAN has had to 
apply corrections to get package XML to work on Windows.

That said, http://www.omegahat.org/R/src/contrib/XML_3.98-1.tar.gz 
downloads and unpacks for me, so the problem seems to be local to you.

On 17/12/2013 07:41, Wasili Goutas wrote:
> Hi,
>
>   I try to install the XML package, but unfortunatelly I get an erroron
> uncompressing it
>
> 'Fehler in untar2(tarfile, files, list, exdir, restore_times) :
> incomplete block on file'
>
> I tried it manually using WinZip and tra in a Cygwin shell and get also errors
> there.
>
>    gzip: stdin: unexpected end of file
>    tar: Unerwartetes Dateiende im Archiv.
>    tar: Error is not recoverable: exiting now
>
> I tried to extract the versions XML_3.9-0.tar.gz, XML_3.98-0.tar.gz and
> XML_3.98-1.tar.gz in Cygwin and got always the same error.
>
> To take care, that the reason is not any download problem since I sit behind a
> firewall and proxy I checked if also other packages from
> <http://www.omegahat.org/R/src/contrib/>  behave the same, but I was able to
> untar
>
> R2GoogleMaps_0.2-0.tar.gz  RCUDA_0.4-0.tar.gz  RCurl_1.95-4.tar.gz
>   RGraphicsDevice_0.5-0.tar.gz
>
> in a Cygwin shell with ???tar tvzf ?????? without any problems.
>
> I can't believe that the XML package basically always is broken but I also don't
> understand what I'm doing wrong.
>
>   Do you have an idea?
>
> Regards
>
> Wasili
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From petr.pikal at precheza.cz  Tue Dec 17 11:20:22 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 17 Dec 2013 10:20:22 +0000
Subject: [R] (no subject)
In-Reply-To: <1387189867.33894.YahooMailNeo@web171905.mail.ir2.yahoo.com>
References: <1387189867.33894.YahooMailNeo@web171905.mail.ir2.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA6F81@SRVEXCHMBX.precheza.cz>

Hi

?lm

but for dose response evaluation package drc is maybe more apropriate.

Regards
Petr



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Mahboobe Akhlaghi
> Sent: Monday, December 16, 2013 11:31 AM
> To: R-help at r-project.org
> Subject: [R] (no subject)
> 
> hello,
> I?have a project in dose response and?I should fit some models on my
> data.
> how can?I fit linear and quadritic models on my data?
> many thanks,
> mahboobe
> 
> 	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Tue Dec 17 11:25:36 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 17 Dec 2013 10:25:36 +0000
Subject: [R] (no subject)
In-Reply-To: <1387189867.33894.YahooMailNeo@web171905.mail.ir2.yahoo.com>
References: <1387189867.33894.YahooMailNeo@web171905.mail.ir2.yahoo.com>
Message-ID: <52B026A0.3060602@sapo.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/57d44f70/attachment.pl>

From nashjc at uottawa.ca  Tue Dec 17 14:27:36 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Tue, 17 Dec 2013 08:27:36 -0500
Subject: [R]  convergence=0 in optim and nlminb is real?
Message-ID: <52B05148.5080201@uottawa.ca>

If you run all methods in package optimx, you will see results all over 
the western hemisphere. I suspect a problem with some nasty 
computational issues. Possibly the replacement of the function with Inf 
when any eigenvalues < 0 or  nu < 0 is one source of this.

Note that Hessian eigenvalues are not used to determine convergence in 
optimization methods. If they did, nobody would ever get promoted from 
junior lecturer who was under 100 if they needed to do this, because 
determining the Hessian from just the function requires two levels of 
approximate derivatives.

If you want to get this problem reliably solved, I think you will need to
1) sort out a way to avoid the Inf values -- can you constrain the 
parameters away from such areas, or at least not use Inf. This messes up 
the gradient computation and hence the optimizers and also the final 
Hessian.
2) work out an analytic gradient function.

JN





> Date: Mon, 16 Dec 2013 16:09:46 +0100
> From: Adelchi Azzalini <azzalini at stat.unipd.it>
> To: r-help at r-project.org
> Subject: [R] convergence=0 in optim and nlminb is real?
> Message-ID: <20131216160946.91858ff279db26bd65e187bc at stat.unipd.it>
> Content-Type: text/plain; charset=US-ASCII
>
> It must be the case that this issue has already been rised before,
> but I did not manage to find it in past posting.
>
> In some cases, optim() and nlminb() declare a successful convergence,
> but the corresponding Hessian is not positive-definite.  A simplified
> version of the original problem is given in the code which for
> readability is placed below this text.  The example is built making use
> of package 'sn', but this is only required to set-up the example: the
> question is about the outcome of the optimizers. At the end of the run,
> a certain point is declared to correspont to a minimum since
> 'convergence=0' is reported, but the eigenvalues of the (numerically
> evaluated) Hessian matrix at that point are not all positive.
>
> Any views on the cause of the problem? (i) the point does not
> correspong to a real minimum, (ii) it does dive a minimum but the
> Hessian matrix is wrong, (iii) the eigenvalues are not right.
> ...and, in case, how to get the real solution.
>
>
> Adelchi Azzalini


From friendly at yorku.ca  Tue Dec 17 14:57:35 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 17 Dec 2013 08:57:35 -0500
Subject: [R] ggplot2: stat_smooth for family=binomial with cbind(Y,
	N) formula
Message-ID: <52B0584F.40608@yorku.ca>

With ggplot2, I can plot the glm stat_smooth for binomial data when the 
response is binary or
a two-level factor as follows:

data("Donner", package="vcdExtra")
ggplot(Donner, aes(age, survived)) +
geom_point(position = position_jitter(height = 0.02, width = 0)) +
stat_smooth(method = "glm", family = binomial, formula = y ~ x,
alpha = 0.2, size=2)

But how can I specify the formula for stat_smooth when the response is 
cbind(successes, failures)?
The equivalent with plot (minus the confidence band) for the example I 
want is:

data("SpaceShuttle", package="vcd")

 > head(SpaceShuttle, 5)
   FlightNumber Temperature Pressure Fail nFailures Damage
1            1          66       50   no         0      0
2            2          70       50  yes         1      4
3            3          69       50   no         0      0
4            4          80       50 <NA>        NA     NA
5            5          68       50   no         0      0
 >

plot(nFailures/6 ~ Temperature, data = SpaceShuttle,
      xlim = c(30, 81), ylim = c(0,1),
      main = "NASA Space Shuttle O-Ring Failures",
      ylab = "Estimated failure probability",
      xlab = "Temperature (degrees F)",
      pch = 19, col = "blue", cex=1.2)
fm <- glm(cbind(nFailures, 6 - nFailures) ~ Temperature,
           data = SpaceShuttle,
           family = binomial)
pred <- predict(fm, data.frame(Temperature = 30 : 81), se=TRUE)
lines(30 : 81,
       predict(fm, data.frame(Temperature = 30 : 81), type = "response"),
       lwd = 3)

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jrkrideau at inbox.com  Tue Dec 17 16:00:47 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 17 Dec 2013 07:00:47 -0800
Subject: [R] OdfWeave problem
Message-ID: <90CD8B2144B.000001A0jrkrideau@inbox.com>

I am trying to get odfWeave to work and I seem to be doing something stupid. Straightforward inline statements and plain code chunks are working fine but when I try to use an actual odfWeave statement I get what appears to be the xml and not odt format.  I am using Apache OpenOffice 3. 4.0.  Sys.Info() at bottom.
Suggestions/ pointers appreciated.

In an odt file I tried the following:  The inline statements work, the dat1 chunk works the iris chunk gives me the following.


> odfItemize(levels(iris$Species))
     <text:list text:style-name="Rbullet" > 
     <text:list-item>
      <text:p text:style-name="RbulletParagraph" > setosa     </text:p>
     </text:list-item>
     <text:list-item>
      <text:p text:style-name="RbulletParagraph" > versicolor </text:p>
     </text:list-item>
     <text:list-item>
      <text:p text:style-name="RbulletParagraph" > virginica  </text:p>
     </text:list-item>
    </text:list>

######--------------------------text in AOO file ------------------------------------

 \Sexpr{paste(letters[1:5], collapse = ",")}. Okay so far, so good and ? =  \Sexpr{round(pi, 4)}.


<<dat1, echo=FALSE >>=
Participant  <-  c(1,2,3,4,5,6,7,8,9,10)
Condition <-factor(c(1,1,1,1,1,2,2,2,2,2))
Score <- c(4,3,5,4,4,2,2,6,5,6)
Data <- data.frame(Participant,Condition,Score)
Data
@

<<iris , echo = TRUE>>=
odfItemize(levels(iris$Species))
 @
###----------------------------end text in AOO file---------------

##----------------------------------R program----------------
library(odfWeave)
inFile <- "odfWeave.example.odt"
outFile <- "outfile.odt"

odfWeave(inFile, outFile)
#===================================
     
 Sys.info()
                                      sysname                                       release 
                                      "Linux"                           "3.11.0-14-generic" 
                                      version                                      nodename 
"#21-Ubuntu SMP Tue Nov 12 17:07:40 UTC 2013"                                   "john-K53U" 
                                      machine                                         login 
                                       "i686"                                     "unknown" 
                                         user                                effective_user 
                                       "john"                                        "john" 




John Kane
Kingston ON Canada

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From murdoch.duncan at gmail.com  Tue Dec 17 16:26:01 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Dec 2013 10:26:01 -0500
Subject: [R] OdfWeave problem
In-Reply-To: <90CD8B2144B.000001A0jrkrideau@inbox.com>
References: <90CD8B2144B.000001A0jrkrideau@inbox.com>
Message-ID: <52B06D09.2020509@gmail.com>

On 17/12/2013 10:00 AM, John Kane wrote:
> I am trying to get odfWeave to work and I seem to be doing something stupid. Straightforward inline statements and plain code chunks are working fine but when I try to use an actual odfWeave statement I get what appears to be the xml and not odt format.  I am using Apache OpenOffice 3. 4.0.  Sys.Info() at bottom.
> Suggestions/ pointers appreciated.
>
> In an odt file I tried the following:  The inline statements work, the dat1 chunk works the iris chunk gives me the following.
>
>
> > odfItemize(levels(iris$Species))
>       <text:list text:style-name="Rbullet" >
>       <text:list-item>
>        <text:p text:style-name="RbulletParagraph" > setosa     </text:p>
>       </text:list-item>
>       <text:list-item>
>        <text:p text:style-name="RbulletParagraph" > versicolor </text:p>
>       </text:list-item>
>       <text:list-item>
>        <text:p text:style-name="RbulletParagraph" > virginica  </text:p>
>       </text:list-item>
>      </text:list>
>
> ######--------------------------text in AOO file ------------------------------------
>
>   \Sexpr{paste(letters[1:5], collapse = ",")}. Okay so far, so good and ? =  \Sexpr{round(pi, 4)}.
>
>
> <<dat1, echo=FALSE >>=
> Participant  <-  c(1,2,3,4,5,6,7,8,9,10)
> Condition <-factor(c(1,1,1,1,1,2,2,2,2,2))
> Score <- c(4,3,5,4,4,2,2,6,5,6)
> Data <- data.frame(Participant,Condition,Score)
> Data
> @
>
> <<iris , echo = TRUE>>=
> odfItemize(levels(iris$Species))
>   @

I don't use odfWeave, but by analogy with Sweave you probably need some 
"result=" or "output=" option in the header to this code chunk, to tell 
it not to escape everything, but just to include it as XML code to be 
processed.

Duncan Murdoch

> ###----------------------------end text in AOO file---------------
>
> ##----------------------------------R program----------------
> library(odfWeave)
> inFile <- "odfWeave.example.odt"
> outFile <- "outfile.odt"
>
> odfWeave(inFile, outFile)
> #===================================
>       
>   Sys.info()
>                                        sysname                                       release
>                                        "Linux"                           "3.11.0-14-generic"
>                                        version                                      nodename
> "#21-Ubuntu SMP Tue Nov 12 17:07:40 UTC 2013"                                   "john-K53U"
>                                        machine                                         login
>                                         "i686"                                     "unknown"
>                                           user                                effective_user
>                                         "john"                                        "john"
>
>
>
>
> John Kane
> Kingston ON Canada
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Tue Dec 17 16:41:57 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 17 Dec 2013 07:41:57 -0800
Subject: [R] OdfWeave problem
In-Reply-To: <52B06D09.2020509@gmail.com>
References: <90cd8b2144b.000001a0jrkrideau@inbox.com>
Message-ID: <91299160217.00000239jrkrideau@inbox.com>

Thanks Duncan.
It sounds  logical but neither seem to work.  
The code below and with output = gives the same result.
<<iris , echo = TRUE, result =TRUE>>=
odfItemize(levels(iris$Species))
 @

I am beginning to wonder if I have something wrong with my installation.

The worst of this is I have not used odfWeave in at least a year as I like LyX/knitr better but I recommended that an AOO user try it and figured I should at least be able to answer a few simple questions.


John Kane
Kingston ON Canada


> -----Original Message-----
> From: murdoch.duncan at gmail.com
> Sent: Tue, 17 Dec 2013 10:26:01 -0500
> To: jrkrideau at inbox.com, r-help at r-project.org
> Subject: Re: [R] OdfWeave problem
> 
> On 17/12/2013 10:00 AM, John Kane wrote:
>> I am trying to get odfWeave to work and I seem to be doing something
>> stupid. Straightforward inline statements and plain code chunks are
>> working fine but when I try to use an actual odfWeave statement I get
>> what appears to be the xml and not odt format.  I am using Apache
>> OpenOffice 3. 4.0.  Sys.Info() at bottom.
>> Suggestions/ pointers appreciated.
>> 
>> In an odt file I tried the following:  The inline statements work, the
>> dat1 chunk works the iris chunk gives me the following.
>> 
>> 
>>> odfItemize(levels(iris$Species))
>>       <text:list text:style-name="Rbullet" >
>>       <text:list-item>
>>        <text:p text:style-name="RbulletParagraph" > setosa     </text:p>
>>       </text:list-item>
>>       <text:list-item>
>>        <text:p text:style-name="RbulletParagraph" > versicolor </text:p>
>>       </text:list-item>
>>       <text:list-item>
>>        <text:p text:style-name="RbulletParagraph" > virginica  </text:p>
>>       </text:list-item>
>>      </text:list>
>> 
>> ######--------------------------text in AOO file
>> ------------------------------------
>> 
>>   \Sexpr{paste(letters[1:5], collapse = ",")}. Okay so far, so good and
>> ? =  \Sexpr{round(pi, 4)}.
>> 
>> 
>> <<dat1, echo=FALSE >>=
>> Participant  <-  c(1,2,3,4,5,6,7,8,9,10)
>> Condition <-factor(c(1,1,1,1,1,2,2,2,2,2))
>> Score <- c(4,3,5,4,4,2,2,6,5,6)
>> Data <- data.frame(Participant,Condition,Score)
>> Data
>> @
>> 
>> <<iris , echo = TRUE>>=
>> odfItemize(levels(iris$Species))
>>   @
> 
> I don't use odfWeave, but by analogy with Sweave you probably need some
> "result=" or "output=" option in the header to this code chunk, to tell
> it not to escape everything, but just to include it as XML code to be
> processed.
> 
> Duncan Murdoch
> 
>> ###----------------------------end text in AOO file---------------
>> 
>> ##----------------------------------R program----------------
>> library(odfWeave)
>> inFile <- "odfWeave.example.odt"
>> outFile <- "outfile.odt"
>> 
>> odfWeave(inFile, outFile)
>> #===================================
>> 
>>   Sys.info()
>>                                        sysname
>> release
>>                                        "Linux"
>> "3.11.0-14-generic"
>>                                        version
>> nodename
>> "#21-Ubuntu SMP Tue Nov 12 17:07:40 UTC 2013"
>> "john-K53U"
>>                                        machine
>> login
>>                                         "i686"
>> "unknown"
>>                                           user
>> effective_user
>>                                         "john"
>> "john"
>> 
>> 
>> 
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> ____________________________________________________________
>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From murdoch.duncan at gmail.com  Tue Dec 17 17:08:54 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Dec 2013 11:08:54 -0500
Subject: [R] OdfWeave problem
In-Reply-To: <91299160217.00000239jrkrideau@inbox.com>
References: <90cd8b2144b.000001a0jrkrideau@inbox.com>
	<91299160217.00000239jrkrideau@inbox.com>
Message-ID: <52B07716.40303@gmail.com>

On 17/12/2013 10:41 AM, John Kane wrote:
> Thanks Duncan.
> It sounds  logical but neither seem to work.
> The code below and with output = gives the same result.
> <<iris , echo = TRUE, result =TRUE>>=
> odfItemize(levels(iris$Species))
>   @
>
> I am beginning to wonder if I have something wrong with my installation.

I think it's an RTFM problem.  In odfWeave, you want results=xml to 
embed XML in the output.

Duncan Murdoch
>
> The worst of this is I have not used odfWeave in at least a year as I like LyX/knitr better but I recommended that an AOO user try it and figured I should at least be able to answer a few simple questions.
>
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: murdoch.duncan at gmail.com
> > Sent: Tue, 17 Dec 2013 10:26:01 -0500
> > To: jrkrideau at inbox.com, r-help at r-project.org
> > Subject: Re: [R] OdfWeave problem
> >
> > On 17/12/2013 10:00 AM, John Kane wrote:
> >> I am trying to get odfWeave to work and I seem to be doing something
> >> stupid. Straightforward inline statements and plain code chunks are
> >> working fine but when I try to use an actual odfWeave statement I get
> >> what appears to be the xml and not odt format.  I am using Apache
> >> OpenOffice 3. 4.0.  Sys.Info() at bottom.
> >> Suggestions/ pointers appreciated.
> >>
> >> In an odt file I tried the following:  The inline statements work, the
> >> dat1 chunk works the iris chunk gives me the following.
> >>
> >>
> >>> odfItemize(levels(iris$Species))
> >>       <text:list text:style-name="Rbullet" >
> >>       <text:list-item>
> >>        <text:p text:style-name="RbulletParagraph" > setosa     </text:p>
> >>       </text:list-item>
> >>       <text:list-item>
> >>        <text:p text:style-name="RbulletParagraph" > versicolor </text:p>
> >>       </text:list-item>
> >>       <text:list-item>
> >>        <text:p text:style-name="RbulletParagraph" > virginica  </text:p>
> >>       </text:list-item>
> >>      </text:list>
> >>
> >> ######--------------------------text in AOO file
> >> ------------------------------------
> >>
> >>   \Sexpr{paste(letters[1:5], collapse = ",")}. Okay so far, so good and
> >> ? =  \Sexpr{round(pi, 4)}.
> >>
> >>
> >> <<dat1, echo=FALSE >>=
> >> Participant  <-  c(1,2,3,4,5,6,7,8,9,10)
> >> Condition <-factor(c(1,1,1,1,1,2,2,2,2,2))
> >> Score <- c(4,3,5,4,4,2,2,6,5,6)
> >> Data <- data.frame(Participant,Condition,Score)
> >> Data
> >> @
> >>
> >> <<iris , echo = TRUE>>=
> >> odfItemize(levels(iris$Species))
> >>   @
> >
> > I don't use odfWeave, but by analogy with Sweave you probably need some
> > "result=" or "output=" option in the header to this code chunk, to tell
> > it not to escape everything, but just to include it as XML code to be
> > processed.
> >
> > Duncan Murdoch
> >
> >> ###----------------------------end text in AOO file---------------
> >>
> >> ##----------------------------------R program----------------
> >> library(odfWeave)
> >> inFile <- "odfWeave.example.odt"
> >> outFile <- "outfile.odt"
> >>
> >> odfWeave(inFile, outFile)
> >> #===================================
> >>
> >>   Sys.info()
> >>                                        sysname
> >> release
> >>                                        "Linux"
> >> "3.11.0-14-generic"
> >>                                        version
> >> nodename
> >> "#21-Ubuntu SMP Tue Nov 12 17:07:40 UTC 2013"
> >> "john-K53U"
> >>                                        machine
> >> login
> >>                                         "i686"
> >> "unknown"
> >>                                           user
> >> effective_user
> >>                                         "john"
> >> "john"
> >>
> >>
> >>
> >>
> >> John Kane
> >> Kingston ON Canada
> >>
> >> ____________________________________________________________
> >> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Dec 17 17:20:50 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 17 Dec 2013 08:20:50 -0800
Subject: [R] OdfWeave problem
In-Reply-To: <91299160217.00000239jrkrideau@inbox.com>
References: <90cd8b2144b.000001a0jrkrideau@inbox.com>
	<91299160217.00000239jrkrideau@inbox.com>
Message-ID: <7517b7c7-6d5f-4d70-8232-c20a64fb7ccf@email.android.com>

I, like Duncan have not used odfweave, but with knitr you would not use result=TRUE, rather you would use result='asis'.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

John Kane <jrkrideau at inbox.com> wrote:
>Thanks Duncan.
>It sounds  logical but neither seem to work.  
>The code below and with output = gives the same result.
><<iris , echo = TRUE, result =TRUE>>=
>odfItemize(levels(iris$Species))
> @
>
>I am beginning to wonder if I have something wrong with my
>installation.
>
>The worst of this is I have not used odfWeave in at least a year as I
>like LyX/knitr better but I recommended that an AOO user try it and
>figured I should at least be able to answer a few simple questions.
>
>
>John Kane
>Kingston ON Canada
>
>
>> -----Original Message-----
>> From: murdoch.duncan at gmail.com
>> Sent: Tue, 17 Dec 2013 10:26:01 -0500
>> To: jrkrideau at inbox.com, r-help at r-project.org
>> Subject: Re: [R] OdfWeave problem
>> 
>> On 17/12/2013 10:00 AM, John Kane wrote:
>>> I am trying to get odfWeave to work and I seem to be doing something
>>> stupid. Straightforward inline statements and plain code chunks are
>>> working fine but when I try to use an actual odfWeave statement I
>get
>>> what appears to be the xml and not odt format.  I am using Apache
>>> OpenOffice 3. 4.0.  Sys.Info() at bottom.
>>> Suggestions/ pointers appreciated.
>>> 
>>> In an odt file I tried the following:  The inline statements work,
>the
>>> dat1 chunk works the iris chunk gives me the following.
>>> 
>>> 
>>>> odfItemize(levels(iris$Species))
>>>       <text:list text:style-name="Rbullet" >
>>>       <text:list-item>
>>>        <text:p text:style-name="RbulletParagraph" > setosa    
></text:p>
>>>       </text:list-item>
>>>       <text:list-item>
>>>        <text:p text:style-name="RbulletParagraph" > versicolor
></text:p>
>>>       </text:list-item>
>>>       <text:list-item>
>>>        <text:p text:style-name="RbulletParagraph" > virginica 
></text:p>
>>>       </text:list-item>
>>>      </text:list>
>>> 
>>> ######--------------------------text in AOO file
>>> ------------------------------------
>>> 
>>>   \Sexpr{paste(letters[1:5], collapse = ",")}. Okay so far, so good
>and
>>> ? =  \Sexpr{round(pi, 4)}.
>>> 
>>> 
>>> <<dat1, echo=FALSE >>=
>>> Participant  <-  c(1,2,3,4,5,6,7,8,9,10)
>>> Condition <-factor(c(1,1,1,1,1,2,2,2,2,2))
>>> Score <- c(4,3,5,4,4,2,2,6,5,6)
>>> Data <- data.frame(Participant,Condition,Score)
>>> Data
>>> @
>>> 
>>> <<iris , echo = TRUE>>=
>>> odfItemize(levels(iris$Species))
>>>   @
>> 
>> I don't use odfWeave, but by analogy with Sweave you probably need
>some
>> "result=" or "output=" option in the header to this code chunk, to
>tell
>> it not to escape everything, but just to include it as XML code to be
>> processed.
>> 
>> Duncan Murdoch
>> 
>>> ###----------------------------end text in AOO file---------------
>>> 
>>> ##----------------------------------R program----------------
>>> library(odfWeave)
>>> inFile <- "odfWeave.example.odt"
>>> outFile <- "outfile.odt"
>>> 
>>> odfWeave(inFile, outFile)
>>> #===================================
>>> 
>>>   Sys.info()
>>>                                        sysname
>>> release
>>>                                        "Linux"
>>> "3.11.0-14-generic"
>>>                                        version
>>> nodename
>>> "#21-Ubuntu SMP Tue Nov 12 17:07:40 UTC 2013"
>>> "john-K53U"
>>>                                        machine
>>> login
>>>                                         "i686"
>>> "unknown"
>>>                                           user
>>> effective_user
>>>                                         "john"
>>> "john"
>>> 
>>> 
>>> 
>>> 
>>> John Kane
>>> Kingston ON Canada
>>> 
>>> ____________________________________________________________
>>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>____________________________________________________________
>FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>and family!
>Visit http://www.inbox.com/photosharing to find out more!
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From csardi.gabor at gmail.com  Tue Dec 17 17:26:08 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Tue, 17 Dec 2013 11:26:08 -0500
Subject: [R] install.packages and dependencies=TRUE
Message-ID: <CABtg=KkAWJk6XTdxEGrGu6i25ChUmRyoNkTotd-MSPykVnrudA@mail.gmail.com>

Dear all,

I am trying to install a private package, with its dependencies. However, both

install.packages("sand_1.0.tar.gz", dependencies=TRUE, repos=NULL,
type="source")

and

install.packages("sand_1.0.tar.gz", dependencies="Suggests",
repos=NULL, type="source")

fail to install suggested packages:

> packageDescription("sand")$Suggests
[1] "network, sna, ape, ergm, mixer, vioplot, ROCR, fdrtool, huge"

Based on the docs, I got the (obviously wrong) impression, that it was
possible to install suggested packages. From ?install.packages,
dependencies argument:

          ?TRUE? means to use ?c("Depends", "Imports", "LinkingTo",
          "Suggests")? for ?pkgs? and ?c("Depends", "Imports",
          "LinkingTo")? for added dependencies: this installs all the
          packages needed to run ?pkgs?, their examples, tests and
          vignettes (if the package author specified them correctly).

> library(ergm)
Error in library(ergm) : there is no package called ?ergm?
> library(huge)
Error in library(huge) : there is no package called ?huge?

What am I doing wrong, and more importantly, what is the correct way
to install _all_ dependencies of a package?

Thanks, Best,
Gabor


From Thierry.ONKELINX at inbo.be  Tue Dec 17 17:26:38 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 17 Dec 2013 16:26:38 +0000
Subject: [R] ggplot2: stat_smooth for family=binomial with cbind(Y,
 N) formula
In-Reply-To: <52B0584F.40608@yorku.ca>
References: <52B0584F.40608@yorku.ca>
Message-ID: <AA818EAD2576BC488B4F623941DA7427DFBCA602@inbomail.inbo.be>

Dear Michael,

Calculate the propotions. Then it is easy to use the weight option of glm

data("SpaceShuttle", package="vcd")
SpaceShuttle$trials <- 6

fm <- glm(cbind(nFailures, 6 - nFailures) ~ Temperature, data = SpaceShuttle, family = binomial)
fm2 <- glm(nFailures/trials ~ Temperature, data = SpaceShuttle, family = binomial, weight = trials)
all.equal(coef(fm), coef(fm2))

ggplot(SpaceShuttle, aes(x = Temperature, y = nFailures / trials)) + geom_point() + geom_smooth(method = "glm", family = binomial, aes(weight = trials))

Best regards,

Thierry

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Michael Friendly
Verzonden: dinsdag 17 december 2013 14:58
Aan: R-help
Onderwerp: [R] ggplot2: stat_smooth for family=binomial with cbind(Y, N) formula

With ggplot2, I can plot the glm stat_smooth for binomial data when the response is binary or a two-level factor as follows:

data("Donner", package="vcdExtra")
ggplot(Donner, aes(age, survived)) +
geom_point(position = position_jitter(height = 0.02, width = 0)) + stat_smooth(method = "glm", family = binomial, formula = y ~ x, alpha = 0.2, size=2)

But how can I specify the formula for stat_smooth when the response is cbind(successes, failures)?
The equivalent with plot (minus the confidence band) for the example I want is:

data("SpaceShuttle", package="vcd")

 > head(SpaceShuttle, 5)
   FlightNumber Temperature Pressure Fail nFailures Damage
1            1          66       50   no         0      0
2            2          70       50  yes         1      4
3            3          69       50   no         0      0
4            4          80       50 <NA>        NA     NA
5            5          68       50   no         0      0
 >

plot(nFailures/6 ~ Temperature, data = SpaceShuttle,
      xlim = c(30, 81), ylim = c(0,1),
      main = "NASA Space Shuttle O-Ring Failures",
      ylab = "Estimated failure probability",
      xlab = "Temperature (degrees F)",
      pch = 19, col = "blue", cex=1.2)
fm <- glm(cbind(nFailures, 6 - nFailures) ~ Temperature,
           data = SpaceShuttle,
           family = binomial)
pred <- predict(fm, data.frame(Temperature = 30 : 81), se=TRUE)
lines(30 : 81,
       predict(fm, data.frame(Temperature = 30 : 81), type = "response"),
       lwd = 3)

--
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From azzalini at stat.unipd.it  Tue Dec 17 17:32:06 2013
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Tue, 17 Dec 2013 17:32:06 +0100
Subject: [R] convergence=0 in optim and nlminb is real?
In-Reply-To: <52B05148.5080201@uottawa.ca>
References: <52B05148.5080201@uottawa.ca>
Message-ID: <20131217173206.9f814f7d178433e81167487a@stat.unipd.it>

On Tue, 17 Dec 2013 08:27:36 -0500, Prof J C Nash (U30A) wrote:

PJCN> If you run all methods in package optimx, you will see results
PJCN> all over the western hemisphere. I suspect a problem with some
PJCN> nasty computational issues. Possibly the replacement of the
PJCN> function with Inf when any eigenvalues < 0 or  nu < 0 is one
PJCN> source of this.

A value Inf is allowed, as indicated in this passage from the
documentation of optim:

  Function fn can return NA or Inf if the function cannot be evaluated
  at the supplied value, but the initial value must have a computable
  finite value of fn.

Incidentally, the documentation of optimx includes the same sentence. 

However, this aspect is not crucial anyway, since the point selected by
optim is within the feasible space (by a good margin), and evaluation of
the Hessian matrix occurs at this point.

PJCN> 
PJCN> Note that Hessian eigenvalues are not used to determine
PJCN> convergence in optimization methods. If they did, nobody would
PJCN> ever get promoted from junior lecturer who was under 100 if they
PJCN> needed to do this, because determining the Hessian from just the
PJCN> function requires two levels of approximate derivatives.

At the end of the optimization process, when a point is going to be
declared a minimum point, I expect that an optimizer  checks that it
really *is* a minimum. It may do this in other ways other than
computing the eigenvalues, but it must be done somehow. Actually, I
first realized the problem by attempting inversion (to get standard
errors) under the assumption of positive definiteness, and it failed.
For instance 

  mnormt:::pd.solve(opt$hessian)

says  "x appears to be not positive definite". This check does not
involve a further level of approximation.

PJCN> 
PJCN> If you want to get this problem reliably solved, I think you will
PJCN> need to
PJCN> 1) sort out a way to avoid the Inf values -- can you constrain
PJCN> the parameters away from such areas, or at least not use Inf.
PJCN> This messes up the gradient computation and hence the optimizers
PJCN> and also the final Hessian.
PJCN> 2) work out an analytic gradient function.
PJCN> 

In my ealier message, I have indicated that this is a semplified
version of the real thing, which is function mst.mle of pkg 'sn'.
What mst.mle does is exactly what you indicated, that is, it
re-parameterizes the problem so that we always stay within the
feasible region and works with analytic gradient function (of the
transformed parameters). The final outcome is the same: we land on
the same point.

However, once the (supposed) point of minimum has been found, the
Hessian matrix must be computed on the original parameterization,
to get standard errors.

Adelchi Azzalini

PJCN> 
PJCN> 
PJCN> > Date: Mon, 16 Dec 2013 16:09:46 +0100
PJCN> > From: Adelchi Azzalini <azzalini at stat.unipd.it>
PJCN> > To: r-help at r-project.org
PJCN> > Subject: [R] convergence=0 in optim and nlminb is real?
PJCN> > Message-ID:
PJCN> > <20131216160946.91858ff279db26bd65e187bc at stat.unipd.it>
PJCN> > Content-Type: text/plain; charset=US-ASCII
PJCN> >
PJCN> > It must be the case that this issue has already been rised
PJCN> > before, but I did not manage to find it in past posting.
PJCN> >
PJCN> > In some cases, optim() and nlminb() declare a successful
PJCN> > convergence, but the corresponding Hessian is not
PJCN> > positive-definite.  A simplified version of the original
PJCN> > problem is given in the code which for readability is placed
PJCN> > below this text.  The example is built making use of package
PJCN> > 'sn', but this is only required to set-up the example: the
PJCN> > question is about the outcome of the optimizers. At the end of
PJCN> > the run, a certain point is declared to correspont to a minimum
PJCN> > since 'convergence=0' is reported, but the eigenvalues of the
PJCN> > (numerically evaluated) Hessian matrix at that point are not
PJCN> > all positive.
PJCN> >
PJCN> > Any views on the cause of the problem? (i) the point does not
PJCN> > correspong to a real minimum, (ii) it does dive a minimum but
PJCN> > the Hessian matrix is wrong, (iii) the eigenvalues are not
PJCN> > right. ...and, in case, how to get the real solution.
PJCN> >
PJCN> >
PJCN> > Adelchi Azzalini
PJCN>


From csardi.gabor at gmail.com  Tue Dec 17 17:33:02 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Tue, 17 Dec 2013 11:33:02 -0500
Subject: [R] install.packages and dependencies=TRUE
In-Reply-To: <CABtg=KkAWJk6XTdxEGrGu6i25ChUmRyoNkTotd-MSPykVnrudA@mail.gmail.com>
References: <CABtg=KkAWJk6XTdxEGrGu6i25ChUmRyoNkTotd-MSPykVnrudA@mail.gmail.com>
Message-ID: <CABtg=KmJrSkyLS-Jaqx8_0zHfgFmr_t+gCo+AJGixp7VSdX+nw@mail.gmail.com>

Answer to myself. 'dependencies' are

Not used if ?repos = NULL?.

Sorry for the noise.

Gabor

On Tue, Dec 17, 2013 at 11:26 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> Dear all,
>
> I am trying to install a private package, with its dependencies. However, both
>
> install.packages("sand_1.0.tar.gz", dependencies=TRUE, repos=NULL,
> type="source")
>
> and
>
> install.packages("sand_1.0.tar.gz", dependencies="Suggests",
> repos=NULL, type="source")
>
> fail to install suggested packages:
>
>> packageDescription("sand")$Suggests
> [1] "network, sna, ape, ergm, mixer, vioplot, ROCR, fdrtool, huge"
>
> Based on the docs, I got the (obviously wrong) impression, that it was
> possible to install suggested packages. From ?install.packages,
> dependencies argument:
>
>           ?TRUE? means to use ?c("Depends", "Imports", "LinkingTo",
>           "Suggests")? for ?pkgs? and ?c("Depends", "Imports",
>           "LinkingTo")? for added dependencies: this installs all the
>           packages needed to run ?pkgs?, their examples, tests and
>           vignettes (if the package author specified them correctly).
>
>> library(ergm)
> Error in library(ergm) : there is no package called ?ergm?
>> library(huge)
> Error in library(huge) : there is no package called ?huge?
>
> What am I doing wrong, and more importantly, what is the correct way
> to install _all_ dependencies of a package?
>
> Thanks, Best,
> Gabor


From murdoch.duncan at gmail.com  Tue Dec 17 17:36:28 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Dec 2013 11:36:28 -0500
Subject: [R] install.packages and dependencies=TRUE
In-Reply-To: <CABtg=KkAWJk6XTdxEGrGu6i25ChUmRyoNkTotd-MSPykVnrudA@mail.gmail.com>
References: <CABtg=KkAWJk6XTdxEGrGu6i25ChUmRyoNkTotd-MSPykVnrudA@mail.gmail.com>
Message-ID: <52B07D8C.4060508@gmail.com>

On 17/12/2013 11:26 AM, G?bor Cs?rdi wrote:
> Dear all,
>
> I am trying to install a private package, with its dependencies. However, both
>
> install.packages("sand_1.0.tar.gz", dependencies=TRUE, repos=NULL,
> type="source")
>
> and
>
> install.packages("sand_1.0.tar.gz", dependencies="Suggests",
> repos=NULL, type="source")
>
> fail to install suggested packages:
>
> > packageDescription("sand")$Suggests
> [1] "network, sna, ape, ergm, mixer, vioplot, ROCR, fdrtool, huge"
>
> Based on the docs, I got the (obviously wrong) impression, that it was
> possible to install suggested packages. From ?install.packages,
> dependencies argument:
>
>            ?TRUE? means to use ?c("Depends", "Imports", "LinkingTo",
>            "Suggests")? for ?pkgs? and ?c("Depends", "Imports",
>            "LinkingTo")? for added dependencies: this installs all the
>            packages needed to run ?pkgs?, their examples, tests and
>            vignettes (if the package author specified them correctly).
>
> > library(ergm)
> Error in library(ergm) : there is no package called ?ergm?
> > library(huge)
> Error in library(huge) : there is no package called ?huge?
>
> What am I doing wrong, and more importantly, what is the correct way
> to install _all_ dependencies of a package?

The problem is with repos=NULL (i.e. a local install).  Since none of 
those dependencies are local, they aren't found and won't be installed.

I imagine some package has a function that does what you want, but I 
don't know it.  It wouldn't be hard to put one together as follows:

1.  install your package without its dependencies.
2.  use tools::package_dependencies() to find the (non-recursive) 
dependencies.
3.  install those, with their dependencies.

You could add a step to filter the list in 2 so that you don't 
re-install something that is already there.

Duncan Murdoch


From csardi.gabor at gmail.com  Tue Dec 17 17:38:41 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Tue, 17 Dec 2013 11:38:41 -0500
Subject: [R] install.packages and dependencies=TRUE
In-Reply-To: <52B07D8C.4060508@gmail.com>
References: <CABtg=KkAWJk6XTdxEGrGu6i25ChUmRyoNkTotd-MSPykVnrudA@mail.gmail.com>
	<52B07D8C.4060508@gmail.com>
Message-ID: <CABtg=KkemPKnyn1P6HV85wkwvmJuYCFbFoGyNYc419Ejj82VTA@mail.gmail.com>

Thanks!

Btw, install() from the devtools package can do this in theory, but
not in practice, because of a bug (it silently ignores "Suggests").
This is fixed in their github version.

Just to add something useful here.

Gabor

On Tue, Dec 17, 2013 at 11:36 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 17/12/2013 11:26 AM, G?bor Cs?rdi wrote:
>>
>> Dear all,
>>
>> I am trying to install a private package, with its dependencies. However,
>> both
>>
>> install.packages("sand_1.0.tar.gz", dependencies=TRUE, repos=NULL,
>> type="source")
>>
>> and
>>
>> install.packages("sand_1.0.tar.gz", dependencies="Suggests",
>> repos=NULL, type="source")
>>
>> fail to install suggested packages:
>>
>> > packageDescription("sand")$Suggests
>> [1] "network, sna, ape, ergm, mixer, vioplot, ROCR, fdrtool, huge"
>>
>> Based on the docs, I got the (obviously wrong) impression, that it was
>> possible to install suggested packages. From ?install.packages,
>> dependencies argument:
>>
>>            ?TRUE? means to use ?c("Depends", "Imports", "LinkingTo",
>>            "Suggests")? for ?pkgs? and ?c("Depends", "Imports",
>>            "LinkingTo")? for added dependencies: this installs all the
>>            packages needed to run ?pkgs?, their examples, tests and
>>            vignettes (if the package author specified them correctly).
>>
>> > library(ergm)
>> Error in library(ergm) : there is no package called ?ergm?
>> > library(huge)
>> Error in library(huge) : there is no package called ?huge?
>>
>> What am I doing wrong, and more importantly, what is the correct way
>> to install _all_ dependencies of a package?
>
>
> The problem is with repos=NULL (i.e. a local install).  Since none of those
> dependencies are local, they aren't found and won't be installed.
>
> I imagine some package has a function that does what you want, but I don't
> know it.  It wouldn't be hard to put one together as follows:
>
> 1.  install your package without its dependencies.
> 2.  use tools::package_dependencies() to find the (non-recursive)
> dependencies.
> 3.  install those, with their dependencies.
>
> You could add a step to filter the list in 2 so that you don't re-install
> something that is already there.
>
> Duncan Murdoch


From azzalini at stat.unipd.it  Tue Dec 17 17:51:36 2013
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Tue, 17 Dec 2013 17:51:36 +0100
Subject: [R] convergence=0 in optim and nlminb is real?
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C30E202016@DOM-EB-MAIL1.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C30E202016@DOM-EB-MAIL1.win.ad.jhu.edu>
Message-ID: <20131217175136.e4ad028ae6835d3ebb603d46@stat.unipd.it>

On Tue, 17 Dec 2013 15:21:57 +0000, Ravi Varadhan wrote:

RV> The optimization algorithms did converge to a limit point.  But,
RV> not to a stationary point, i.e. a point in parameter space where
RV> the first and second order KKT conditions are satisfied.  If you
RV> check the gradient at the solution, you will see that it is quite
RV> large in magnitude relative to 0.  So, why did the algorithms
RV> declare convergence?  Convergence is based on absolute change in
RV> function value and/or relative change in parameter values between
RV> consecutive iterations.  This does not ensure that the KKT
RV> conditions are satisfied.

This makes sense to me. Although I have indicated other possible
explanations, the most plausable was that the selected point is not
at a minimum, as you confirmed.

As in many other cases, the stopping rule of an optimizer can be a
delicate issue. However, since optim computes (on request) the Hessian
matrix, a check on its positive-definiteness seems to me a reasonable
check to be made by optim before declaring successful convergence.

RV> 
RV> Now, to the real issue:  your problem is ill-posed.  As you can
RV> tell from the eigenvalues of the hessian, they vary over 9 orders
RV> of magnitude.  This may indicate a problem with the data in that
RV> the log-likelihood is over-parametrized relative to the information
RV> in the data set.  Get a better data set or formulate a simpler
RV> model, and the problem will disappear.
RV>  

I had noticed this aspect of the relative order of magnitudes of the
eigenvalues. The model is not over-parameterized (in a formal sense),
but in some cases maximization of the log-likelihood can be a delicate
issue, yes. 

I am not specifically interested in fitting these data, nor any other
data. I am working on an update of package 'sn'. 

Thanks for your informative reply.

Adelchi
-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit? di Padova, Italia
tel. +39 049 8274147,  http://azzalini.stat.unipd.it/


From aurelien.philippot at gmail.com  Tue Dec 17 17:53:24 2013
From: aurelien.philippot at gmail.com (=?ISO-8859-1?Q?Aur=E9lien_Philippot?=)
Date: Tue, 17 Dec 2013 08:53:24 -0800
Subject: [R] Problem to solve an integral equation
Message-ID: <CAOwh97th8yrmPviMGUFYQJTHzwC6Din8KYbCY_ihEXdFd3=+xw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/53889974/attachment.pl>

From jvadams at usgs.gov  Tue Dec 17 17:57:43 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 17 Dec 2013 10:57:43 -0600
Subject: [R] How to plug in characters as object names in a formula
 (recast from package reshape2 specifically)
In-Reply-To: <CAMCXXmogBE9YrJ0=bK08b+QcAUWntaYusDVkS5EGed98iS8LQg@mail.gmail.com>
References: <CAMCXXmogBE9YrJ0=bK08b+QcAUWntaYusDVkS5EGed98iS8LQg@mail.gmail.com>
Message-ID: <CAN5YmCEMf9fg=1OPJNJQXSdnuT1pj8aQ1x72mte1yMWsKZ3P8Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/825a8f73/attachment.pl>

From david.croll at gmx.ch  Tue Dec 17 17:59:09 2013
From: david.croll at gmx.ch (David Croll)
Date: Tue, 17 Dec 2013 17:59:09 +0100
Subject: [R] barely readable "autocomplete" text
Message-ID: <52B082DD.3020309@gmx.ch>



Dear R users and R friends,




I have one question I wish to have answered.

I have RKWard installed on Ubuntu (12.04 LTS), and it works like a 
charm. The only problem is that the "autocomplete" function is barely 
readable.

Here, you see the parameters of "scan()" written in white, on a 
salmon-coloured background.

http://oi40.tinypic.com/20uu4r9.jpg

How and where can I change this?


Kind regards,


David


From jrkrideau at inbox.com  Tue Dec 17 18:05:25 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 17 Dec 2013 09:05:25 -0800
Subject: [R] OdfWeave problem
In-Reply-To: <7517b7c7-6d5f-4d70-8232-c20a64fb7ccf@email.android.com>
References: <90cd8b2144b.000001a0jrkrideau@inbox.com>
	<91299160217.00000239jrkrideau@inbox.com>
Message-ID: <91E42047DCC.000003CCjrkrideau@inbox.com>

Thanks. As you will see from my reply I misread the manual and it shoud have been results = xml and I had tried XML. 

And result = 'asis'  works too.  I had thought it was unique to knitr and never thought to try it.

Thanks
John Kane
Kingston ON Canada


> -----Original Message-----
> From: jdnewmil at dcn.davis.ca.us
> Sent: Tue, 17 Dec 2013 08:20:50 -0800
> To: jrkrideau at inbox.com, r-help at r-project.org
> Subject: Re: [R] OdfWeave problem
> 
> I, like Duncan have not used odfweave, but with knitr you would not use
> result=TRUE, rather you would use result='asis'.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
> 
> John Kane <jrkrideau at inbox.com> wrote:
> >Thanks Duncan.
> >It sounds  logical but neither seem to work.
> >The code below and with output = gives the same result.
> ><<iris , echo = TRUE, result =TRUE>>=
> >odfItemize(levels(iris$Species))
>> @
>> 
> >I am beginning to wonder if I have something wrong with my
> >installation.
>> 
> >The worst of this is I have not used odfWeave in at least a year as I
> >like LyX/knitr better but I recommended that an AOO user try it and
> >figured I should at least be able to answer a few simple questions.
>> 
>> 
> >John Kane
> >Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: murdoch.duncan at gmail.com
>>> Sent: Tue, 17 Dec 2013 10:26:01 -0500
>>> To: jrkrideau at inbox.com, r-help at r-project.org
>>> Subject: Re: [R] OdfWeave problem
>>> 
>>> On 17/12/2013 10:00 AM, John Kane wrote:
>>>> I am trying to get odfWeave to work and I seem to be doing something
>>>> stupid. Straightforward inline statements and plain code chunks are
>>>> working fine but when I try to use an actual odfWeave statement I
> >get
>>>> what appears to be the xml and not odt format.  I am using Apache
>>>> OpenOffice 3. 4.0.  Sys.Info() at bottom.
>>>> Suggestions/ pointers appreciated.
>>>> 
>>>> In an odt file I tried the following:  The inline statements work,
> >the
>>>> dat1 chunk works the iris chunk gives me the following.
>>>> 
>>>> 
>>>>> odfItemize(levels(iris$Species))
>>>>       <text:list text:style-name="Rbullet" >
>>>>       <text:list-item>
>>>>        <text:p text:style-name="RbulletParagraph" > setosa
> ></text:p>
>>>>       </text:list-item>
>>>>       <text:list-item>
>>>>        <text:p text:style-name="RbulletParagraph" > versicolor
> ></text:p>
>>>>       </text:list-item>
>>>>       <text:list-item>
>>>>        <text:p text:style-name="RbulletParagraph" > virginica
> ></text:p>
>>>>       </text:list-item>
>>>>      </text:list>
>>>> 
>>>> ######--------------------------text in AOO file
>>>> ------------------------------------
>>>> 
>>>>   \Sexpr{paste(letters[1:5], collapse = ",")}. Okay so far, so good
> >and
>>>> ? =  \Sexpr{round(pi, 4)}.
>>>> 
>>>> 
>>>> <<dat1, echo=FALSE >>=
>>>> Participant  <-  c(1,2,3,4,5,6,7,8,9,10)
>>>> Condition <-factor(c(1,1,1,1,1,2,2,2,2,2))
>>>> Score <- c(4,3,5,4,4,2,2,6,5,6)
>>>> Data <- data.frame(Participant,Condition,Score)
>>>> Data
>>>> @
>>>> 
>>>> <<iris , echo = TRUE>>=
>>>> odfItemize(levels(iris$Species))
>>>>   @
>>> 
>>> I don't use odfWeave, but by analogy with Sweave you probably need
> >some
>>> "result=" or "output=" option in the header to this code chunk, to
> >tell
>>> it not to escape everything, but just to include it as XML code to be
>>> processed.
>>> 
>>> Duncan Murdoch
>>> 
>>>> ###----------------------------end text in AOO file---------------
>>>> 
>>>> ##----------------------------------R program----------------
>>>> library(odfWeave)
>>>> inFile <- "odfWeave.example.odt"
>>>> outFile <- "outfile.odt"
>>>> 
>>>> odfWeave(inFile, outFile)
>>>> #===================================
>>>> 
>>>>   Sys.info()
>>>>                                        sysname
>>>> release
>>>>                                        "Linux"
>>>> "3.11.0-14-generic"
>>>>                                        version
>>>> nodename
>>>> "#21-Ubuntu SMP Tue Nov 12 17:07:40 UTC 2013"
>>>> "john-K53U"
>>>>                                        machine
>>>> login
>>>>                                         "i686"
>>>> "unknown"
>>>>                                           user
>>>> effective_user
>>>>                                         "john"
>>>> "john"
>>>> 
>>>> 
>>>> 
>>>> 
>>>> John Kane
>>>> Kingston ON Canada
>>>> 
>>>> ____________________________________________________________
>>>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> >____________________________________________________________
> >FREE ONLINE PHOTOSHARING - Share your photos online with your friends
> >and family!
> >Visit http://www.inbox.com/photosharing to find out more!
>> 
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From sarah.goslee at gmail.com  Tue Dec 17 18:10:54 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 17 Dec 2013 12:10:54 -0500
Subject: [R] barely readable "autocomplete" text
In-Reply-To: <52B082DD.3020309@gmx.ch>
References: <52B082DD.3020309@gmx.ch>
Message-ID: <CAM_vjukAYWJSbDj0eaHHnE262J+114OWy7KT5OKCCCkog3uV_w@mail.gmail.com>

Hi David,

There are lots of places to get help for rkward, but this isn't one of
them. Please try:

http://sourceforge.net/apps/mediawiki/rkward/index.php?title=User_Documentation

Sarah


On Tue, Dec 17, 2013 at 11:59 AM, David Croll <david.croll at gmx.ch> wrote:
>
>
> Dear R users and R friends,
>
>
>
>
> I have one question I wish to have answered.
>
> I have RKWard installed on Ubuntu (12.04 LTS), and it works like a charm.
> The only problem is that the "autocomplete" function is barely readable.
>
> Here, you see the parameters of "scan()" written in white, on a
> salmon-coloured background.
>
> http://oi40.tinypic.com/20uu4r9.jpg
>
> How and where can I change this?
>
>
> Kind regards,
>
>
> David
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From csardi.gabor at gmail.com  Tue Dec 17 18:15:05 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Tue, 17 Dec 2013 12:15:05 -0500
Subject: [R] install.packages and dependencies=TRUE
In-Reply-To: <CABtg=KkemPKnyn1P6HV85wkwvmJuYCFbFoGyNYc419Ejj82VTA@mail.gmail.com>
References: <CABtg=KkAWJk6XTdxEGrGu6i25ChUmRyoNkTotd-MSPykVnrudA@mail.gmail.com>
	<52B07D8C.4060508@gmail.com>
	<CABtg=KkemPKnyn1P6HV85wkwvmJuYCFbFoGyNYc419Ejj82VTA@mail.gmail.com>
Message-ID: <CABtg=KmFv+qEwR9+DFgb5_SRxHbOPrmUkFGL1qes4jZk2qNO9g@mail.gmail.com>

> On Tue, Dec 17, 2013 at 11:36 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
[...]
>> I imagine some package has a function that does what you want, but I don't
>> know it.  It wouldn't be hard to put one together as follows:
>>
>> 1.  install your package without its dependencies.

This does not seem to work if the package had 'Depends' or 'Imports'
as well. What is the correct way to install a local package, so that
its dependencies are pulled from CRAN?

>> 2.  use tools::package_dependencies() to find the (non-recursive)
>> dependencies.

This does not seem to work, because the dependencies are only checked on CRAN.

>> 3.  install those, with their dependencies.

In summary, it is not quite trivial to do this correctly, if you look
at devtools:::install_deps and and devtools:::parse_deps, it is not 10
lines of code.

Anyway, I can just take the code from devtools or use their unreleased version.

Thanks again,
Gabor

[...]


From nashjc at uottawa.ca  Tue Dec 17 18:18:25 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Tue, 17 Dec 2013 12:18:25 -0500
Subject: [R] convergence=0 in optim and nlminb is real?
In-Reply-To: <20131217173206.9f814f7d178433e81167487a@stat.unipd.it>
References: <52B05148.5080201@uottawa.ca>
	<20131217173206.9f814f7d178433e81167487a@stat.unipd.it>
Message-ID: <52B08761.9030609@uottawa.ca>

As indicated, if optimizers check Hessians on every occasion, R would
enrich all the computer manufacturers. In this case it is not too large
a problem, so worth doing.

However, for this problem, the Hessian is being evaluated by doing
numerical approximations to second partial derivatives, so the Hessian
may be almost a fiction of the analytic Hessian. I've seen plenty of
Hessian approximations that are not positive definite, when the answers
were OK.

That Inf is allowed does not mean that it is recommended. R is very
tolerant of many things that are not generally good ideas. That can be
helpful for some computations, but still cause trouble. It seems that it
is not the problem here.

I did not look at all the results for this problem from optimx, but it
appeared that several results were lower than the optim(BFGS) one. Is
any of the optimx results acceptable? Note that optimx DOES offer to
check the KKT conditions, and defaults to doing so unless the problem is
large. That was included precisely because the optimizers generally
avoid this very expensive computation. But given the range of results
from the optimx answers using "all methods", I'd still want to do a lot
of testing of the results.

This may be a useful case to point out that nonlinear optimization is
not a calculation that should be taken for granted. It is much less
reliable than most users think. I rarely find ANY problem for which all
the optimx methods return the same answer. You really do need to look at
the answers and make sure that they are meaningful.

JN

On 13-12-17 11:32 AM, Adelchi Azzalini wrote:
> On Tue, 17 Dec 2013 08:27:36 -0500, Prof J C Nash (U30A) wrote:
> 
> PJCN> If you run all methods in package optimx, you will see results
> PJCN> all over the western hemisphere. I suspect a problem with some
> PJCN> nasty computational issues. Possibly the replacement of the
> PJCN> function with Inf when any eigenvalues < 0 or  nu < 0 is one
> PJCN> source of this.
> 
> A value Inf is allowed, as indicated in this passage from the
> documentation of optim:
> 
>   Function fn can return NA or Inf if the function cannot be evaluated
>   at the supplied value, but the initial value must have a computable
>   finite value of fn.
> 
> Incidentally, the documentation of optimx includes the same sentence. 
> 
> However, this aspect is not crucial anyway, since the point selected by
> optim is within the feasible space (by a good margin), and evaluation of
> the Hessian matrix occurs at this point.
> 
> PJCN> 
> PJCN> Note that Hessian eigenvalues are not used to determine
> PJCN> convergence in optimization methods. If they did, nobody would
> PJCN> ever get promoted from junior lecturer who was under 100 if they
> PJCN> needed to do this, because determining the Hessian from just the
> PJCN> function requires two levels of approximate derivatives.
> 
> At the end of the optimization process, when a point is going to be
> declared a minimum point, I expect that an optimizer  checks that it
> really *is* a minimum. It may do this in other ways other than
> computing the eigenvalues, but it must be done somehow. Actually, I
> first realized the problem by attempting inversion (to get standard
> errors) under the assumption of positive definiteness, and it failed.
> For instance 
> 
>   mnormt:::pd.solve(opt$hessian)
> 
> says  "x appears to be not positive definite". This check does not
> involve a further level of approximation.
> 
> PJCN> 
> PJCN> If you want to get this problem reliably solved, I think you will
> PJCN> need to
> PJCN> 1) sort out a way to avoid the Inf values -- can you constrain
> PJCN> the parameters away from such areas, or at least not use Inf.
> PJCN> This messes up the gradient computation and hence the optimizers
> PJCN> and also the final Hessian.
> PJCN> 2) work out an analytic gradient function.
> PJCN> 
> 
> In my ealier message, I have indicated that this is a semplified
> version of the real thing, which is function mst.mle of pkg 'sn'.
> What mst.mle does is exactly what you indicated, that is, it
> re-parameterizes the problem so that we always stay within the
> feasible region and works with analytic gradient function (of the
> transformed parameters). The final outcome is the same: we land on
> the same point.
> 
> However, once the (supposed) point of minimum has been found, the
> Hessian matrix must be computed on the original parameterization,
> to get standard errors.
> 
> Adelchi Azzalini
> 
> PJCN> 
> PJCN> 
> PJCN> > Date: Mon, 16 Dec 2013 16:09:46 +0100
> PJCN> > From: Adelchi Azzalini <azzalini at stat.unipd.it>
> PJCN> > To: r-help at r-project.org
> PJCN> > Subject: [R] convergence=0 in optim and nlminb is real?
> PJCN> > Message-ID:
> PJCN> > <20131216160946.91858ff279db26bd65e187bc at stat.unipd.it>
> PJCN> > Content-Type: text/plain; charset=US-ASCII
> PJCN> >
> PJCN> > It must be the case that this issue has already been rised
> PJCN> > before, but I did not manage to find it in past posting.
> PJCN> >
> PJCN> > In some cases, optim() and nlminb() declare a successful
> PJCN> > convergence, but the corresponding Hessian is not
> PJCN> > positive-definite.  A simplified version of the original
> PJCN> > problem is given in the code which for readability is placed
> PJCN> > below this text.  The example is built making use of package
> PJCN> > 'sn', but this is only required to set-up the example: the
> PJCN> > question is about the outcome of the optimizers. At the end of
> PJCN> > the run, a certain point is declared to correspont to a minimum
> PJCN> > since 'convergence=0' is reported, but the eigenvalues of the
> PJCN> > (numerically evaluated) Hessian matrix at that point are not
> PJCN> > all positive.
> PJCN> >
> PJCN> > Any views on the cause of the problem? (i) the point does not
> PJCN> > correspong to a real minimum, (ii) it does dive a minimum but
> PJCN> > the Hessian matrix is wrong, (iii) the eigenvalues are not
> PJCN> > right. ...and, in case, how to get the real solution.
> PJCN> >
> PJCN> >
> PJCN> > Adelchi Azzalini
> PJCN> 
>


From mbhpathak at gmail.com  Tue Dec 17 18:33:30 2013
From: mbhpathak at gmail.com (bibek sharma)
Date: Tue, 17 Dec 2013 09:33:30 -0800
Subject: [R] Hello R user!
Message-ID: <CAGC2kj59staO+SyWX3JGfH9viYj+T-YYJKZvmJKY5fLOLhQV6w@mail.gmail.com>

Hello R user,

I have created two plots (attached!) using the codes below
and would like to merge these figures in one. any suggestions are highly
appreciated!
Thanks,

plot(graph1$yod,graph1$xod,data=graph1)
dfx = data.frame(ev1=graph1$xod, ev2=graph1$yod, ev3=abs(graph1$dif))
symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
bg="black", fg=NULL,xlim=c(-35,35),ylim=c(-35,35))
abline(h=0,v=0)

plot(graph2$yod,graph2$xod,data=graph2)
dfx = data.frame(ev1=graph2$xod, ev2=graph2$yod, ev3=abs(graph2$dif))
lines(symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
bg="blue", fg=NULL,xlim=c(-35,35),ylim=c(-35,35)))
abline(h=0,v=0)

Best,
Bibek

From jrkrideau at inbox.com  Tue Dec 17 18:45:31 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 17 Dec 2013 09:45:31 -0800
Subject: [R] Hello R user!
In-Reply-To: <CAGC2kj59staO+SyWX3JGfH9viYj+T-YYJKZvmJKY5fLOLhQV6w@mail.gmail.com>
Message-ID: <923DC0AB209.00000465jrkrideau@inbox.com>

The plots did not arrive. The R-help list is fussy about what it allows to go through.

Actually the best way of doing things is to use dput() to provide sample data.  See https://github.com/hadley/devtools/wiki/Reproducibility or  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

To answer your question probably you want to have a look a "mfcol" or "mfrow" under ?par.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: mbhpathak at gmail.com
> Sent: Tue, 17 Dec 2013 09:33:30 -0800
> To: r-help at r-project.org
> Subject: [R] Hello R user!
> 
> Hello R user,
> 
> I have created two plots (attached!) using the codes below
> and would like to merge these figures in one. any suggestions are highly
> appreciated!
> Thanks,
> 
> plot(graph1$yod,graph1$xod,data=graph1)
> dfx = data.frame(ev1=graph1$xod, ev2=graph1$yod, ev3=abs(graph1$dif))
> symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
> bg="black", fg=NULL,xlim=c(-35,35),ylim=c(-35,35))
> abline(h=0,v=0)
> 
> plot(graph2$yod,graph2$xod,data=graph2)
> dfx = data.frame(ev1=graph2$xod, ev2=graph2$yod, ev3=abs(graph2$dif))
> lines(symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
> bg="blue", fg=NULL,xlim=c(-35,35),ylim=c(-35,35)))
> abline(h=0,v=0)
> 
> Best,
> Bibek
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From sarah.goslee at gmail.com  Tue Dec 17 18:45:30 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 17 Dec 2013 12:45:30 -0500
Subject: [R] Hello R user!
In-Reply-To: <CAGC2kj59staO+SyWX3JGfH9viYj+T-YYJKZvmJKY5fLOLhQV6w@mail.gmail.com>
References: <CAGC2kj59staO+SyWX3JGfH9viYj+T-YYJKZvmJKY5fLOLhQV6w@mail.gmail.com>
Message-ID: <CAM_vjumy4k2LOuuv8hTmtPd7Ov0xmF-nvJWOGvZUnCv0Lhc90Q@mail.gmail.com>

What do you mean by "merge these figures in one"? If you want two
figures on one page, see ?par - specifically mfrow and mfcol.

If you want both sets of data in one figure, maybe ?points or ?lines
though I see you're already familiar with at least ?lines.

The list doesn't take most attachments, and you might also take a look at:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Asking intelligible questions is the best strategy for receiving
intelligible answers.

Sarah

On Tue, Dec 17, 2013 at 12:33 PM, bibek sharma <mbhpathak at gmail.com> wrote:
> Hello R user,
>
> I have created two plots (attached!) using the codes below
> and would like to merge these figures in one. any suggestions are highly
> appreciated!
> Thanks,
>
> plot(graph1$yod,graph1$xod,data=graph1)
> dfx = data.frame(ev1=graph1$xod, ev2=graph1$yod, ev3=abs(graph1$dif))
> symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
> bg="black", fg=NULL,xlim=c(-35,35),ylim=c(-35,35))
> abline(h=0,v=0)
>
> plot(graph2$yod,graph2$xod,data=graph2)
> dfx = data.frame(ev1=graph2$xod, ev2=graph2$yod, ev3=abs(graph2$dif))
> lines(symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
> bg="blue", fg=NULL,xlim=c(-35,35),ylim=c(-35,35)))
> abline(h=0,v=0)
>
> Best,
> Bibek


-- 
Sarah Goslee
http://www.functionaldiversity.org


From cryan at binghamton.edu  Tue Dec 17 18:47:57 2013
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Tue, 17 Dec 2013 12:47:57 -0500
Subject: [R] Hello R user!
In-Reply-To: <CAGC2kj59staO+SyWX3JGfH9viYj+T-YYJKZvmJKY5fLOLhQV6w@mail.gmail.com>
References: <CAGC2kj59staO+SyWX3JGfH9viYj+T-YYJKZvmJKY5fLOLhQV6w@mail.gmail.com>
Message-ID: <CAM+rpYk=zMo26ueW5Nn-LqwDL9ntVh70xeX5QSXk5yaumeNOvw@mail.gmail.com>

What do you mean by "merge" them into one?  Make both graphs appear on
the same page of a document? Make a single figure containing both
graphs?  Plot data from both dataframes on the same set of axes?

--Chris Ryan

On Tue, Dec 17, 2013 at 12:33 PM, bibek sharma <mbhpathak at gmail.com> wrote:
> Hello R user,
>
> I have created two plots (attached!) using the codes below
> and would like to merge these figures in one. any suggestions are highly
> appreciated!
> Thanks,
>
> plot(graph1$yod,graph1$xod,data=graph1)
> dfx = data.frame(ev1=graph1$xod, ev2=graph1$yod, ev3=abs(graph1$dif))
> symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
> bg="black", fg=NULL,xlim=c(-35,35),ylim=c(-35,35))
> abline(h=0,v=0)
>
> plot(graph2$yod,graph2$xod,data=graph2)
> dfx = data.frame(ev1=graph2$xod, ev2=graph2$yod, ev3=abs(graph2$dif))
> lines(symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
> bg="blue", fg=NULL,xlim=c(-35,35),ylim=c(-35,35)))
> abline(h=0,v=0)
>
> Best,
> Bibek
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ghoshm2010 at gmail.com  Tue Dec 17 16:14:55 2013
From: ghoshm2010 at gmail.com (ghoshm ghosh)
Date: Tue, 17 Dec 2013 20:44:55 +0530
Subject: [R] Query regarding solution of delay differential equations with
 distributed delay (volterra type)
Message-ID: <CAEkBU+WKSFfROS7ZkFzhD11wVyjc=pzjmpRmsXzBP=JLdfucKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/2b8edb41/attachment.pl>

From murdoch.duncan at gmail.com  Tue Dec 17 19:08:04 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Dec 2013 13:08:04 -0500
Subject: [R] install.packages and dependencies=TRUE
In-Reply-To: <CABtg=KmFv+qEwR9+DFgb5_SRxHbOPrmUkFGL1qes4jZk2qNO9g@mail.gmail.com>
References: <CABtg=KkAWJk6XTdxEGrGu6i25ChUmRyoNkTotd-MSPykVnrudA@mail.gmail.com>	<52B07D8C.4060508@gmail.com>	<CABtg=KkemPKnyn1P6HV85wkwvmJuYCFbFoGyNYc419Ejj82VTA@mail.gmail.com>
	<CABtg=KmFv+qEwR9+DFgb5_SRxHbOPrmUkFGL1qes4jZk2qNO9g@mail.gmail.com>
Message-ID: <52B09304.9030807@gmail.com>

So apparently not as simple as I thought it would be.  So I'll tell you 
what I actually do:

I have a number of packages under development, some on CRAN, some not.  
I also work in multiple builds of R pretty frequently, so I like to 
install all my packages and commonly used ones from other people.  So I 
put together a little script that I can run that will install or update 
a list of about 20 packages.  Here it is, with the names deleted.

# Script to install current versions of commonly used packages

installed <- rownames(installed.packages())
old <- old.packages()

oldoptions <- options(repos = 
c(CRAN="http://probability.ca/cran",CRANextra="http://www.stats.ox.ac.uk/pub/RWin"))
pkgs <-    ------ a character vector of packages on CRAN ------
oldPkgs <- old[intersect(pkgs, rownames(old)),,drop=FALSE]
if (length(oldPkgs))
   update.packages(oldPkgs = oldPkgs)
pkgs <- setdiff(pkgs, installed)
if (length(pkgs))
   install.packages(pkgs, dep=c("Depends", "Imports"))

options(repos = c(options("repos"), 
"R-forge"="http://R-Forge.R-project.org"))
pkgs <- ------ packages to install from R-forge ------
oldPkgs <- old[intersect(pkgs, rownames(old)),,drop=FALSE]
if (length(oldPkgs))
   update.packages(oldPkgs = oldPkgs)
pkgs <- setdiff("patchDVI", installed)
if (length(pkgs))
   install.packages(pkgs)

MyR <- ------ the source directory where I keep my own packages ------
pkgs <- ------ packages to install from local source ------
pkgs <- setdiff(pkgs, installed)
if (length(pkgs))
   install.packages(file.path(MyR, pkgs), type="source", repos=NULL)

options(oldoptions)


From pquack at gmail.com  Tue Dec 17 18:37:04 2013
From: pquack at gmail.com (Peter Quackenbush)
Date: Tue, 17 Dec 2013 11:37:04 -0600
Subject: [R] RDCOMClient Help
Message-ID: <CAGiLp7taz9bDZ4n=gz9vQuASFSNbP0J67WRAMuUP74tWa7cpQw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/e0999f7e/attachment.pl>

From ravi.varadhan at jhu.edu  Tue Dec 17 16:21:57 2013
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Tue, 17 Dec 2013 15:21:57 +0000
Subject: [R] convergence=0 in optim and nlminb is real?
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C30E202016@DOM-EB-MAIL1.win.ad.jhu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/4b014080/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Dec 17 19:18:12 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Dec 2013 18:18:12 +0000
Subject: [R] install.packages and dependencies=TRUE
In-Reply-To: <52B09304.9030807@gmail.com>
References: <CABtg=KkAWJk6XTdxEGrGu6i25ChUmRyoNkTotd-MSPykVnrudA@mail.gmail.com>	<52B07D8C.4060508@gmail.com>	<CABtg=KkemPKnyn1P6HV85wkwvmJuYCFbFoGyNYc419Ejj82VTA@mail.gmail.com>	<CABtg=KmFv+qEwR9+DFgb5_SRxHbOPrmUkFGL1qes4jZk2qNO9g@mail.gmail.com>
	<52B09304.9030807@gmail.com>
Message-ID: <52B09564.5090204@stats.ox.ac.uk>

The obvious idea to set up a local repository works.  It takes 5 mins at 
most.

On 17/12/2013 18:08, Duncan Murdoch wrote:
> So apparently not as simple as I thought it would be.  So I'll tell you
> what I actually do:
>
> I have a number of packages under development, some on CRAN, some not. I
> also work in multiple builds of R pretty frequently, so I like to
> install all my packages and commonly used ones from other people.  So I
> put together a little script that I can run that will install or update
> a list of about 20 packages.  Here it is, with the names deleted.
>
> # Script to install current versions of commonly used packages
>
> installed <- rownames(installed.packages())
> old <- old.packages()
>
> oldoptions <- options(repos =
> c(CRAN="http://probability.ca/cran",CRANextra="http://www.stats.ox.ac.uk/pub/RWin"))
>
> pkgs <-    ------ a character vector of packages on CRAN ------
> oldPkgs <- old[intersect(pkgs, rownames(old)),,drop=FALSE]
> if (length(oldPkgs))
>    update.packages(oldPkgs = oldPkgs)
> pkgs <- setdiff(pkgs, installed)
> if (length(pkgs))
>    install.packages(pkgs, dep=c("Depends", "Imports"))
>
> options(repos = c(options("repos"),
> "R-forge"="http://R-Forge.R-project.org"))
> pkgs <- ------ packages to install from R-forge ------
> oldPkgs <- old[intersect(pkgs, rownames(old)),,drop=FALSE]
> if (length(oldPkgs))
>    update.packages(oldPkgs = oldPkgs)
> pkgs <- setdiff("patchDVI", installed)
> if (length(pkgs))
>    install.packages(pkgs)
>
> MyR <- ------ the source directory where I keep my own packages ------
> pkgs <- ------ packages to install from local source ------
> pkgs <- setdiff(pkgs, installed)
> if (length(pkgs))
>    install.packages(file.path(MyR, pkgs), type="source", repos=NULL)
>
> options(oldoptions)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sarah.goslee at gmail.com  Tue Dec 17 19:24:16 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 17 Dec 2013 13:24:16 -0500
Subject: [R] Hello R user!
In-Reply-To: <CAGC2kj6ofTWA=88y5K2z+e9EHgQEW5y=A25yD-BY4Bj8vpdwYA@mail.gmail.com>
References: <CAGC2kj59staO+SyWX3JGfH9viYj+T-YYJKZvmJKY5fLOLhQV6w@mail.gmail.com>
	<CAM_vjumy4k2LOuuv8hTmtPd7Ov0xmF-nvJWOGvZUnCv0Lhc90Q@mail.gmail.com>
	<CAGC2kj6ofTWA=88y5K2z+e9EHgQEW5y=A25yD-BY4Bj8vpdwYA@mail.gmail.com>
Message-ID: <CAM_vjunUny93avnuePhP4io_h-d+HP_69VHPK8CiZzfp4njJsQ@mail.gmail.com>

On Tue, Dec 17, 2013 at 1:04 PM, bibek sharma <mbhpathak at gmail.com> wrote:
> Hi Sarah,
> It is not about mfrow or mfcol.  I would like to see both sets of data in
> one figure.
> All I want was combining these two plots  to one.
> Any suggestions?
> Bibek

Suggestions? Yes. Read the link I and others provided about
reproducible questions.

Then there's the suggestion I already provided, using points() or
lines() to add more data, possibly with xlim or ylim specified (see
?par for details). Without a reproducible example, I can't give
specific details.

> Also, size of the circle in the plots represents  rates and so should be
> shown in different sizes.
> I tried using plots and points but this did  not give me different sizes.

If you want to use base graphics, then cex is what you need (see, you
guessed it, ?par). You can pass a vector of sizes for your plotting
character.

For more sophisticated approaches, you might google "bubble plot R" for ideas.

Sarah

>
>
> On Tue, Dec 17, 2013 at 9:45 AM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> What do you mean by "merge these figures in one"? If you want two
>> figures on one page, see ?par - specifically mfrow and mfcol.
>>
>> If you want both sets of data in one figure, maybe ?points or ?lines
>> though I see you're already familiar with at least ?lines.
>>
>> The list doesn't take most attachments, and you might also take a look at:
>>
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>
>> Asking intelligible questions is the best strategy for receiving
>> intelligible answers.
>>
>> Sarah
>>
>> On Tue, Dec 17, 2013 at 12:33 PM, bibek sharma <mbhpathak at gmail.com>
>> wrote:
>> > Hello R user,
>> >
>> > I have created two plots (attached!) using the codes below
>> > and would like to merge these figures in one. any suggestions are highly
>> > appreciated!
>> > Thanks,
>> >
>> > plot(graph1$yod,graph1$xod,data=graph1)
>> > dfx = data.frame(ev1=graph1$xod, ev2=graph1$yod, ev3=abs(graph1$dif))
>> > symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
>> > bg="black", fg=NULL,xlim=c(-35,35),ylim=c(-35,35))
>> > abline(h=0,v=0)
>> >
>> > plot(graph2$yod,graph2$xod,data=graph2)
>> > dfx = data.frame(ev1=graph2$xod, ev2=graph2$yod, ev3=abs(graph2$dif))
>> > lines(symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
>> > bg="blue", fg=NULL,xlim=c(-35,35),ylim=c(-35,35)))
>> > abline(h=0,v=0)
>> >
>> > Best,
>> > Bibek
>>
>>



-- 
Sarah Goslee
http://www.functionaldiversity.org


From friendly at yorku.ca  Tue Dec 17 19:42:21 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 17 Dec 2013 13:42:21 -0500
Subject: [R] ggplot2: stat_smooth for family=binomial with cbind(Y,
 N) formula
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427DFBCA602@inbomail.inbo.be>
References: <52B0584F.40608@yorku.ca>
	<AA818EAD2576BC488B4F623941DA7427DFBCA602@inbomail.inbo.be>
Message-ID: <52B09B0D.8000301@yorku.ca>

Thanks very much for this helpful reply, Thierry

Using aes(weight=trials) in stat_smooth() was part of what I was missing 
and solves my main
question.
However, for this data, I want to show the extrapolated prediction over 
a wider range than in
the data.  Adding xlim() doesn't help here-- the plot annotations are 
cut off at the lowest
value of Temperature in the data. Is there another way?

ggplot(SpaceShuttle, aes(x = Temperature, y = nFailures / trials)) +
     xlim(30, 81) +
     geom_point() +
     geom_smooth(method = "glm", family = binomial, aes(weight = trials))

Below is the complete (but messy) code for the plot() I would like to 
more or less replicate using
ggplot()

data("SpaceShuttle", package="vcd")
logit2p <- function(logit) 1/(1 + exp(-logit))

plot(nFailures/6 ~ Temperature, data = SpaceShuttle,
      xlim = c(30, 81), ylim = c(0,1),
      main = "NASA Space Shuttle O-Ring Failures",
      ylab = "Estimated failure probability",
      xlab = "Temperature (degrees F)",
      type="n")  # painters model: add points last

fm <- glm(cbind(nFailures, 6 - nFailures) ~ Temperature,
           data = SpaceShuttle,
           family = binomial)
pred <- predict(fm, data.frame(Temperature = 30 : 81), se=TRUE)

predicted <- data.frame(
     Temperature = 30 : 81,
     prob = logit2p(pred$fit),
     lower = logit2p(pred$fit - 2*pred$se),
     upper = logit2p(pred$fit + 2*pred$se)
     )

with(predicted, {
     polygon(c(Temperature, rev(Temperature)),
             c(lower, rev(upper)), col="lightpink", border=NA)
     lines(Temperature, prob, lwd=3)
     }
     )
with(SpaceShuttle,
     points(Temperature, nFailures/6, col="blue", pch=19, cex=1.3)
     )

I also tried following the example in given in ?geom_smooth, to supply 
the predicted
values over my range of x values, and lower/upper limits in a separate 
data frame:

pred <- predict(fm, data.frame(Temperature = 30 : 81), se=TRUE)
predicted <- data.frame(
     Temperature = 30 : 81,
     prob = logit2p(pred$fit),
     lower = logit2p(pred$fit - 2*pred$se),
     upper = logit2p(pred$fit + 2*pred$se)
     )
ggplot(SpaceShuttle, aes(x = Temperature, y = nFailures / trials)) +
   geom_smooth(aes(ymin = lower, ymax = upper), data=predicted, 
stat="identity")

but this gives an error:

 > ggplot(SpaceShuttle, aes(x = Temperature, y = nFailures / trials)) +
+   geom_smooth(aes(ymin = lower, ymax = upper), data=predicted, 
stat="identity")
Error in eval(expr, envir, enclos) : object 'nFailures' not found
 >

-Michael


On 12/17/2013 11:26 AM, ONKELINX, Thierry wrote:
> Dear Michael,
>
> Calculate the propotions. Then it is easy to use the weight option of glm
>
> data("SpaceShuttle", package="vcd")
> SpaceShuttle$trials <- 6
>
> fm <- glm(cbind(nFailures, 6 - nFailures) ~ Temperature, data = SpaceShuttle, family = binomial)
> fm2 <- glm(nFailures/trials ~ Temperature, data = SpaceShuttle, family = binomial, weight = trials)
> all.equal(coef(fm), coef(fm2))
>
> ggplot(SpaceShuttle, aes(x = Temperature, y = nFailures / trials)) + geom_point() + geom_smooth(method = "glm", family = binomial, aes(weight = trials))
>
> Best regards,
>
> Thierry
>
> -----Oorspronkelijk bericht-----
> Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Michael Friendly
> Verzonden: dinsdag 17 december 2013 14:58
> Aan: R-help
> Onderwerp: [R] ggplot2: stat_smooth for family=binomial with cbind(Y, N) formula
>
> With ggplot2, I can plot the glm stat_smooth for binomial data when the response is binary or a two-level factor as follows:
>
> data("Donner", package="vcdExtra")
> ggplot(Donner, aes(age, survived)) +
> geom_point(position = position_jitter(height = 0.02, width = 0)) + stat_smooth(method = "glm", family = binomial, formula = y ~ x, alpha = 0.2, size=2)
>
> But how can I specify the formula for stat_smooth when the response is cbind(successes, failures)?
> The equivalent with plot (minus the confidence band) for the example I want is:
>
> data("SpaceShuttle", package="vcd")
>
>   > head(SpaceShuttle, 5)
>     FlightNumber Temperature Pressure Fail nFailures Damage
> 1            1          66       50   no         0      0
> 2            2          70       50  yes         1      4
> 3            3          69       50   no         0      0
> 4            4          80       50 <NA>        NA     NA
> 5            5          68       50   no         0      0
>   >
>
> plot(nFailures/6 ~ Temperature, data = SpaceShuttle,
>        xlim = c(30, 81), ylim = c(0,1),
>        main = "NASA Space Shuttle O-Ring Failures",
>        ylab = "Estimated failure probability",
>        xlab = "Temperature (degrees F)",
>        pch = 19, col = "blue", cex=1.2)
> fm <- glm(cbind(nFailures, 6 - nFailures) ~ Temperature,
>             data = SpaceShuttle,
>             family = binomial)
> pred <- predict(fm, data.frame(Temperature = 30 : 81), se=TRUE)
> lines(30 : 81,
>         predict(fm, data.frame(Temperature = 30 : 81), type = "response"),
>         lwd = 3)
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
>

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From cryan at binghamton.edu  Tue Dec 17 19:46:09 2013
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Tue, 17 Dec 2013 13:46:09 -0500
Subject: [R] Hello R user!
In-Reply-To: <CAM_vjunUny93avnuePhP4io_h-d+HP_69VHPK8CiZzfp4njJsQ@mail.gmail.com>
References: <CAGC2kj59staO+SyWX3JGfH9viYj+T-YYJKZvmJKY5fLOLhQV6w@mail.gmail.com>
	<CAM_vjumy4k2LOuuv8hTmtPd7Ov0xmF-nvJWOGvZUnCv0Lhc90Q@mail.gmail.com>
	<CAGC2kj6ofTWA=88y5K2z+e9EHgQEW5y=A25yD-BY4Bj8vpdwYA@mail.gmail.com>
	<CAM_vjunUny93avnuePhP4io_h-d+HP_69VHPK8CiZzfp4njJsQ@mail.gmail.com>
Message-ID: <CAM+rpYnLNjk0wfHToh3Zx3AUSb7+8M5xoOd+pC+KPnzhUo-J5g@mail.gmail.com>

Here is a simple example (without the proportional size
bubbles--you've been given some references on that) using the lattice
package:

# one dataframe holds the data from both "sources" I call them.
# they would be data from your two separate dataframes,
# that you call graph1 and graph2
dd <- data.frame(x=rnorm(10), y=rnorm(10), source=sample(c("A","B"),
10, replace=TRUE))
dd
library(lattice)
xyplot(y~x | source, data=dd)
# or another way
xyplot(y~x, groups=source, data=dd,  auto.key=TRUE)

You'll want to think about how you are storing your data. Certain ways
of doing it lend themselves to certain ways of graphing. Some ways
make things difficult . . .

--Chris Ryan

On Tue, Dec 17, 2013 at 1:24 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> On Tue, Dec 17, 2013 at 1:04 PM, bibek sharma <mbhpathak at gmail.com> wrote:
>> Hi Sarah,
>> It is not about mfrow or mfcol.  I would like to see both sets of data in
>> one figure.
>> All I want was combining these two plots  to one.
>> Any suggestions?
>> Bibek
>
> Suggestions? Yes. Read the link I and others provided about
> reproducible questions.
>
> Then there's the suggestion I already provided, using points() or
> lines() to add more data, possibly with xlim or ylim specified (see
> ?par for details). Without a reproducible example, I can't give
> specific details.
>
>> Also, size of the circle in the plots represents  rates and so should be
>> shown in different sizes.
>> I tried using plots and points but this did  not give me different sizes.
>
> If you want to use base graphics, then cex is what you need (see, you
> guessed it, ?par). You can pass a vector of sizes for your plotting
> character.
>
> For more sophisticated approaches, you might google "bubble plot R" for ideas.
>
> Sarah
>
>>
>>
>> On Tue, Dec 17, 2013 at 9:45 AM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>>
>>> What do you mean by "merge these figures in one"? If you want two
>>> figures on one page, see ?par - specifically mfrow and mfcol.
>>>
>>> If you want both sets of data in one figure, maybe ?points or ?lines
>>> though I see you're already familiar with at least ?lines.
>>>
>>> The list doesn't take most attachments, and you might also take a look at:
>>>
>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>
>>> Asking intelligible questions is the best strategy for receiving
>>> intelligible answers.
>>>
>>> Sarah
>>>
>>> On Tue, Dec 17, 2013 at 12:33 PM, bibek sharma <mbhpathak at gmail.com>
>>> wrote:
>>> > Hello R user,
>>> >
>>> > I have created two plots (attached!) using the codes below
>>> > and would like to merge these figures in one. any suggestions are highly
>>> > appreciated!
>>> > Thanks,
>>> >
>>> > plot(graph1$yod,graph1$xod,data=graph1)
>>> > dfx = data.frame(ev1=graph1$xod, ev2=graph1$yod, ev3=abs(graph1$dif))
>>> > symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
>>> > bg="black", fg=NULL,xlim=c(-35,35),ylim=c(-35,35))
>>> > abline(h=0,v=0)
>>> >
>>> > plot(graph2$yod,graph2$xod,data=graph2)
>>> > dfx = data.frame(ev1=graph2$xod, ev2=graph2$yod, ev3=abs(graph2$dif))
>>> > lines(symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
>>> > bg="blue", fg=NULL,xlim=c(-35,35),ylim=c(-35,35)))
>>> > abline(h=0,v=0)
>>> >
>>> > Best,
>>> > Bibek
>>>
>>>
>
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Dec 17 19:58:16 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 17 Dec 2013 10:58:16 -0800
Subject: [R] Problem to solve an integral equation
In-Reply-To: <CAOwh97th8yrmPviMGUFYQJTHzwC6Din8KYbCY_ihEXdFd3=+xw@mail.gmail.com>
References: <CAOwh97th8yrmPviMGUFYQJTHzwC6Din8KYbCY_ihEXdFd3=+xw@mail.gmail.com>
Message-ID: <5D1258CB-DC0F-4F10-AC25-C24C98A737B5@comcast.net>


On Dec 17, 2013, at 8:53 AM, Aur?lien Philippot wrote:

> Dear R experts,
> 
> I am trying to find numerical solutions for an integral equation.
> 
> 
> Here is an example:
> 
> I started by defining the integrand, as a function of x and C, where x is
> the variable of integration and C is the parameter I am interested in:
> 
> 
> integrand<- function(C,x){-((100000*x)^(-1)-(1000*x+C)^(-1))*
> 1/(0.20*sqrt(2*pi))*exp(-0.5*(x-0.10)/(0.20))^2)}

Error: unexpected ')' in:
"integrand<- function(C,x){-((100000*x)^(-1)-(1000*x+C)^(-1))*
1/(0.20*sqrt(2*pi))*exp(-0.5*(x-0.10)/(0.20))^2)"

Taking out the last parenthesis resulted in a variety of error messages including:

> output(0)
Error in integrate(integrand, C = C, lower = 0, upper = Inf) : 
  extremely bad integrand behaviour
> output(-10)
Error in integrate(integrand, C = C, lower = 0, upper = Inf) : 
  the integral is probably divergent



> Then, I integrate with respect to x, and define an objective function
> (output) with respect to C:
> 
> 
> output<- function(C) integrate(integrand, C=C, lower=0, upper=Inf)$value
> 
> 

Generally these problems are solved with the use of something along the lines of 

    sapply( seq(...), output)  # across an appropriate domain

Or using the `Vectorize` function.

But since you did not supply tested code for the integrand, I am not proceeding further.

-- 
david.


> I would like all the values of C (if any) for which the integral is equal
> to 0.
> 
> I did the following:
> 
> 
> library(rootSolve)
> 
> uniroot.all(output, c(0,1000000))
> 
> 
> but that does not work ("evaluation of function gave a result of wrong
> length"). I cannot either plot the function using plot or curve. I don't
> understand what is going on?
> 
> Thanks in advance for any advice!
> 
> Aurelien
-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Dec 17 20:05:29 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 17 Dec 2013 11:05:29 -0800
Subject: [R] Query regarding solution of delay differential equations
	with distributed delay (volterra type)
In-Reply-To: <CAEkBU+WKSFfROS7ZkFzhD11wVyjc=pzjmpRmsXzBP=JLdfucKA@mail.gmail.com>
References: <CAEkBU+WKSFfROS7ZkFzhD11wVyjc=pzjmpRmsXzBP=JLdfucKA@mail.gmail.com>
Message-ID: <024BA9B0-1528-4F72-8044-9C5F4E9B201C@comcast.net>


On Dec 17, 2013, at 7:14 AM, ghoshm ghosh wrote:

> Dear R-user,
> 
> Please let me know whether there is any package in R, which can solve delay
> differential equations with distributed delay (volterra type).

library(sos)
findFn(volterra:)

http://finzi.psych.upenn.edu/R/library/deSolve/html/lsoda.html

> 
> Thanks and best regards,
> Mini Ghosh
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From cryan at binghamton.edu  Tue Dec 17 20:13:53 2013
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Tue, 17 Dec 2013 14:13:53 -0500
Subject: [R] a better method than a long expression with many OR clauses
Message-ID: <CAM+rpYmgOA3FrK9AhAyvqp=W58CAkubcvH3ocUux7_7-Bqu_Yg@mail.gmail.com>

dd <- data.frame(longVariableName1=sample(1:4, 10, replace=TRUE),
longVariableName2=sample(1:4, 10, replace=TRUE))
dd
# define who is a case and who is not
transform(dd, case=(longVariableName1==3 | longVariableName2==3))

But in reality I have 9 of those longVariableName variables,
all of this pattern: alphaCauseX, where X is an integer 1:9.
For any given observation, if any of them == 3, then case=TRUE
Is there a shorter or more elegant way of doing this than
typing out that long string of 9 OR clauses?

I read about any(), but couldn't quite make that do what I want. Maybe
I was using it wrong.

Thanks.

--Chris Ryan


From aurelien.philippot at gmail.com  Tue Dec 17 20:25:36 2013
From: aurelien.philippot at gmail.com (=?ISO-8859-1?Q?Aur=E9lien_Philippot?=)
Date: Tue, 17 Dec 2013 11:25:36 -0800
Subject: [R] Problem to solve an integral equation
In-Reply-To: <5D1258CB-DC0F-4F10-AC25-C24C98A737B5@comcast.net>
References: <CAOwh97th8yrmPviMGUFYQJTHzwC6Din8KYbCY_ihEXdFd3=+xw@mail.gmail.com>
	<5D1258CB-DC0F-4F10-AC25-C24C98A737B5@comcast.net>
Message-ID: <CAOwh97s046faeJfWbqkATGUnFvQL0T1BVrr8rqL889ZRgrGeJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/a39ae36b/attachment.pl>

From lianoglou.steve at gene.com  Tue Dec 17 21:13:36 2013
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Tue, 17 Dec 2013 12:13:36 -0800
Subject: [R] a better method than a long expression with many OR clauses
In-Reply-To: <CAM+rpYmgOA3FrK9AhAyvqp=W58CAkubcvH3ocUux7_7-Bqu_Yg@mail.gmail.com>
References: <CAM+rpYmgOA3FrK9AhAyvqp=W58CAkubcvH3ocUux7_7-Bqu_Yg@mail.gmail.com>
Message-ID: <CAHA9McNU3vmXHg3+r1F1SX67LhQeSE9Vs7Zo8Y=z5ZQr2ydj=Q@mail.gmail.com>

Hi Chris,

(extra compelled to answer a Q from my undergrad alma mater :-)

see below:

On Tue, Dec 17, 2013 at 11:13 AM, Christopher W Ryan
<cryan at binghamton.edu> wrote:
> dd <- data.frame(longVariableName1=sample(1:4, 10, replace=TRUE),
> longVariableName2=sample(1:4, 10, replace=TRUE))
> dd
> # define who is a case and who is not
> transform(dd, case=(longVariableName1==3 | longVariableName2==3))
>
> But in reality I have 9 of those longVariableName variables,
> all of this pattern: alphaCauseX, where X is an integer 1:9.
> For any given observation, if any of them == 3, then case=TRUE
> Is there a shorter or more elegant way of doing this than
> typing out that long string of 9 OR clauses?
>
> I read about any(), but couldn't quite make that do what I want. Maybe
> I was using it wrong.

There are many ways to approach this,here is but one. The general idea is to:

(1) Crate a logical matrix from the appropriate columns in `dd`
(2) Check to see which rows have any vals == 3

Let's say columns 3:11 have the variable you want to check. The code
below will return a vector as long as there are rows in `dd` which are
TRUE if any value in the row == 3:

R> is.case <- rowSums(as.matrix(dd[, 3:11]) == 3) > 0)

Unwind that one liner into it's individual parts to see who is doing
what there.

HTH,
-steve

-- 
Steve Lianoglou
Computational Biologist
Genentech


From pmaclean2011 at yahoo.com  Tue Dec 17 21:18:31 2013
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Tue, 17 Dec 2013 12:18:31 -0800 (PST)
Subject: [R] Polychoric Principal Component Analysis (pPCA)
Message-ID: <1387311511.22377.YahooMailNeo@web121705.mail.ne1.yahoo.com>

I have data set with binary responses. I would like to
conduct polychoric principal component analysis (pPCA). I know there are several packages used in PCA but I could not find one that directly estimate pPCA and graph the individuals and variables maps. I will appreciate any help that expand these reproducible scripts.
#How to conduct polychoric principal component analysis pPCA using 
#either of these packages
library(psych) 
library(FactoMineR)
library(nsprcomp)

#Bock and Liberman (1970) data set of 1000 observations of the LSAT
#from psych

data(bock)
responses <- table2df(bock.table[,2:6],count=bock.table[,7],
??????????????? labs= paste ("lsat6.",1:5,sep=""))
fix(responses) 
describe(responses)
#Estimate the polychoric correlation matrix to be used in 
#PCA using psych 
W <- polychoric(responses, smooth=TRUE,global=TRUE,polycor=F, 
??????????? ML = FALSE,??std.err=FALSE,progress=TRUE) 
#Regular PCA using stat, psych and FactoMiner, respectively
#There is no option for?including the matrix
princomp(responses, cor=TRUE) #What kind of correlation is used here?
?
principal(r = responses, nfactors = 3, rotate = "Promax")
principal(r = W, nfactors = 3, rotate = "Promax") #Do not work

PCA(responses, scale.unit=TRUE, ncp=3, graph=T) 
#How to conduct polychoric principal component analysis using either of #the above package and producing individual and variable factor maps as #above

Peter Maclean
Department of Economics
UDSM


From marlinkcox at gmail.com  Tue Dec 17 21:49:22 2013
From: marlinkcox at gmail.com (Marlin Keith Cox)
Date: Tue, 17 Dec 2013 11:49:22 -0900
Subject: [R] Time series and lm
Message-ID: <CAHskWAVLe-jBUQXkw0D1EM2M_4gufzRrvK8z6jf_up3zhDts4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/a660f25e/attachment.pl>

From 538280 at gmail.com  Tue Dec 17 22:22:53 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 17 Dec 2013 14:22:53 -0700
Subject: [R] How to coerce an object name to character vector?
In-Reply-To: <CACk-te036JucUSDoqO=Yb7BfZN=twAq6G-ex-b=cWKu_gTQFOQ@mail.gmail.com>
References: <70061386623678@web1g.yandex.ru>
	<5E1B812FAC2C4A49B3D99593B5A521910D5D548C@PRDEXMBX-08.the-lab.llnl.gov>
	<CACk-te036JucUSDoqO=Yb7BfZN=twAq6G-ex-b=cWKu_gTQFOQ@mail.gmail.com>
Message-ID: <CAFEqCdwQYGNi24sK4-7yPPsVAnwNZVdMkdV1evjxBBmyiOVcUw@mail.gmail.com>

Bert,

Save some room in the stocks for me, If arguing against the use of
'assign' is worthy of being sent to the stocks then fortune(236) is
probably enough evidence to put me next to you.

To the original author, can you tell us more of what you are trying to
accomplish?
Replacement functions are one option for doing what your function
above does without the mess of using 'assign' and some of the other
steps.  For example:

> `do<-` <- function(x,value) value
>
> test <- NULL
> do(test) <- mean
>
> test( 1:10 )
[1] 5.5





On Mon, Dec 9, 2013 at 5:55 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> Don:
>
> I defer to your judgment as to whether this was what the OP wanted,
> but I think you would agree that the idiom of assign()ing to the
> global workspace from within a function is almost always a bad idea in
> R. Unfortunately, a better alternative, which frequently involves
> building up a list structure of some sort, depends on context and, in
> particular, on what further is to be done with the assigned objects,
> which usually we (and sometimes the poster) don't know.
>
> While assign() and friends certainly exist and allow script-like
> programming if that is how one wishes to proceed, my understanding is
> that it circumvents the functional-style programming paradigm that R
> naturally supports. So I would urge those who wish to partake of the
> "zen" of R to expunge get() and assign() from their R programming
> vocabulary and perhaps read up a bit on functional programming, which
> is really kinda cool.
>
> Contrary opinions most definitely welcome! The stock awaits me in the
> public squaRe.
>
> Best,
> Bert
>
> On Mon, Dec 9, 2013 at 3:34 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>> Not tested, but I think you may want this:
>>
>> do <- function(x,fun, ...) {
>>   fun <- match.fun(fun)
>>   obj.name <- deparse(substitute(x))
>>   assign(obj.name,fun(x, ...))
>> }
>>
>>
>>
>> -Don
>>
>>
>>
>>
>> --
>> Don MacQueen
>>
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>>
>>
>>
>>
>>
>> On 12/9/13 1:14 PM, "????? ????????" <a-morkovin at yandex.ru> wrote:
>>
>>>
>>>   For example, I have a numeric vector named "d" (without any
>>>attributes) and
>>>   I want to coerce it to character vector "d". Is there any such
>>>functions? I
>>>   need  it  to make a function which applies other functions to objects,
>>>   something like this:
>>>
>>>   do<-function(x,fun, ...) {
>>>   fun<-match.fun(fun)
>>>   assign(as.character(quote(x)),fun(x, ...))
>>>   }
>>>
>>>   But, of course, quote(x) always return just "x", not the name of
>>>object.
>>>
>>>   Thanks for help!
>>>
>>>   ______
>>>
>>>   ?? ??????????????????,
>>>   ??.??. ????????????????
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From wdunlap at tibco.com  Tue Dec 17 22:50:00 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 17 Dec 2013 21:50:00 +0000
Subject: [R] Time series and lm
In-Reply-To: <CAHskWAVLe-jBUQXkw0D1EM2M_4gufzRrvK8z6jf_up3zhDts4w@mail.gmail.com>
References: <CAHskWAVLe-jBUQXkw0D1EM2M_4gufzRrvK8z6jf_up3zhDts4w@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1DE19@PA-MBX01.na.tibco.com>

Use as.POSIXct instead of as.POSIXlt if you want to use lm() on the dates.
(The data.frame() function makes this transformation for you, but you
evaded data.frame() by adding the column with $<-(), which does not
do the checks and transformations that data.frame() does.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Marlin Keith Cox
> Sent: Tuesday, December 17, 2013 12:49 PM
> To: r-help at r-project.org
> Subject: [R] Time series and lm
> 
> Hello all, I have a time series defined by
> 
> chum$Time1<-as.POSIXlt(chum$Time, format= "%m/%d/%y %H:%M")
> 
> and a measured parameter
> 
> pa.s
> 
> When I create a linear model
> 
> with(chum.skin, lm(Time1~pa.s))
> 
> I get the following error.
> 
> Error in model.frame.default(formula = Time1 ~ pa.s, drop.unused.levels =
> TRUE) : invalid type (list) for variable 'Time1'
> I cannot figure it out.
> 
> Keith
> 
> 
> 
> 
> M. Keith Cox, Ph.D.
> Principal
> MKConsulting
> 17105 Glacier Hwy
> Juneau, AK 99801
> U.S. 907.957.4606
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From azzalini at stat.unipd.it  Tue Dec 17 22:54:03 2013
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Tue, 17 Dec 2013 22:54:03 +0100
Subject: [R] convergence=0 in optim and nlminb is real?
In-Reply-To: <52B08761.9030609@uottawa.ca>
References: <52B05148.5080201@uottawa.ca>
	<20131217173206.9f814f7d178433e81167487a@stat.unipd.it>
	<52B08761.9030609@uottawa.ca>
Message-ID: <B4C24A11-5D9F-4DF6-9AF1-393D682EB606@stat.unipd.it>

It was not my suggestion that an optimizer should check the Hessian on  
every occasion (this would be both time consuming and meaningless),  
but I expected it to do so before claiming that a point is at a  
minimum, that is, only for the candidate final point.

Neither I have ever thought that nonlinear optimization is a cursory  
operation, especially when the dimensionality is not small. Exactly  
for this reason I expect that an optimizer takes stringent precautions  
before claiming to have completed its job successfully.

AA



On 17 Dec 2013, at 18:18, Prof J C Nash (U30A) wrote:

> As indicated, if optimizers check Hessians on every occasion, R would
> enrich all the computer manufacturers. In this case it is not too  
> large
> a problem, so worth doing.
>
> However, for this problem, the Hessian is being evaluated by doing
> numerical approximations to second partial derivatives, so the Hessian
> may be almost a fiction of the analytic Hessian. I've seen plenty of
> Hessian approximations that are not positive definite, when the  
> answers
> were OK.
>
> That Inf is allowed does not mean that it is recommended. R is very
> tolerant of many things that are not generally good ideas. That can be
> helpful for some computations, but still cause trouble. It seems  
> that it
> is not the problem here.
>
> I did not look at all the results for this problem from optimx, but it
> appeared that several results were lower than the optim(BFGS) one. Is
> any of the optimx results acceptable? Note that optimx DOES offer to
> check the KKT conditions, and defaults to doing so unless the  
> problem is
> large. That was included precisely because the optimizers generally
> avoid this very expensive computation. But given the range of results
> from the optimx answers using "all methods", I'd still want to do a  
> lot
> of testing of the results.
>
> This may be a useful case to point out that nonlinear optimization is
> not a calculation that should be taken for granted. It is much less
> reliable than most users think. I rarely find ANY problem for which  
> all
> the optimx methods return the same answer. You really do need to  
> look at
> the answers and make sure that they are meaningful.
>
> JN
>
> On 13-12-17 11:32 AM, Adelchi Azzalini wrote:
>> On Tue, 17 Dec 2013 08:27:36 -0500, Prof J C Nash (U30A) wrote:
>>
>> PJCN> If you run all methods in package optimx, you will see results
>> PJCN> all over the western hemisphere. I suspect a problem with some
>> PJCN> nasty computational issues. Possibly the replacement of the
>> PJCN> function with Inf when any eigenvalues < 0 or  nu < 0 is one
>> PJCN> source of this.
>>
>> A value Inf is allowed, as indicated in this passage from the
>> documentation of optim:
>>
>>  Function fn can return NA or Inf if the function cannot be evaluated
>>  at the supplied value, but the initial value must have a computable
>>  finite value of fn.
>>
>> Incidentally, the documentation of optimx includes the same sentence.
>>
>> However, this aspect is not crucial anyway, since the point  
>> selected by
>> optim is within the feasible space (by a good margin), and  
>> evaluation of
>> the Hessian matrix occurs at this point.
>>
>> PJCN>
>> PJCN> Note that Hessian eigenvalues are not used to determine
>> PJCN> convergence in optimization methods. If they did, nobody would
>> PJCN> ever get promoted from junior lecturer who was under 100 if  
>> they
>> PJCN> needed to do this, because determining the Hessian from just  
>> the
>> PJCN> function requires two levels of approximate derivatives.
>>
>> At the end of the optimization process, when a point is going to be
>> declared a minimum point, I expect that an optimizer  checks that it
>> really *is* a minimum. It may do this in other ways other than
>> computing the eigenvalues, but it must be done somehow. Actually, I
>> first realized the problem by attempting inversion (to get standard
>> errors) under the assumption of positive definiteness, and it failed.
>> For instance
>>
>>  mnormt:::pd.solve(opt$hessian)
>>
>> says  "x appears to be not positive definite". This check does not
>> involve a further level of approximation.
>>
>> PJCN>
>> PJCN> If you want to get this problem reliably solved, I think you  
>> will
>> PJCN> need to
>> PJCN> 1) sort out a way to avoid the Inf values -- can you constrain
>> PJCN> the parameters away from such areas, or at least not use Inf.
>> PJCN> This messes up the gradient computation and hence the  
>> optimizers
>> PJCN> and also the final Hessian.
>> PJCN> 2) work out an analytic gradient function.
>> PJCN>
>>
>> In my ealier message, I have indicated that this is a semplified
>> version of the real thing, which is function mst.mle of pkg 'sn'.
>> What mst.mle does is exactly what you indicated, that is, it
>> re-parameterizes the problem so that we always stay within the
>> feasible region and works with analytic gradient function (of the
>> transformed parameters). The final outcome is the same: we land on
>> the same point.
>>
>> However, once the (supposed) point of minimum has been found, the
>> Hessian matrix must be computed on the original parameterization,
>> to get standard errors.
>>
>> Adelchi Azzalini
>>
>> PJCN>
>> PJCN>
>> PJCN> > Date: Mon, 16 Dec 2013 16:09:46 +0100
>> PJCN> > From: Adelchi Azzalini <azzalini at stat.unipd.it>
>> PJCN> > To: r-help at r-project.org
>> PJCN> > Subject: [R] convergence=0 in optim and nlminb is real?
>> PJCN> > Message-ID:
>> PJCN> > <20131216160946.91858ff279db26bd65e187bc at stat.unipd.it>
>> PJCN> > Content-Type: text/plain; charset=US-ASCII
>> PJCN> >
>> PJCN> > It must be the case that this issue has already been rised
>> PJCN> > before, but I did not manage to find it in past posting.
>> PJCN> >
>> PJCN> > In some cases, optim() and nlminb() declare a successful
>> PJCN> > convergence, but the corresponding Hessian is not
>> PJCN> > positive-definite.  A simplified version of the original
>> PJCN> > problem is given in the code which for readability is placed
>> PJCN> > below this text.  The example is built making use of package
>> PJCN> > 'sn', but this is only required to set-up the example: the
>> PJCN> > question is about the outcome of the optimizers. At the end  
>> of
>> PJCN> > the run, a certain point is declared to correspont to a  
>> minimum
>> PJCN> > since 'convergence=0' is reported, but the eigenvalues of the
>> PJCN> > (numerically evaluated) Hessian matrix at that point are not
>> PJCN> > all positive.
>> PJCN> >
>> PJCN> > Any views on the cause of the problem? (i) the point does not
>> PJCN> > correspong to a real minimum, (ii) it does dive a minimum but
>> PJCN> > the Hessian matrix is wrong, (iii) the eigenvalues are not
>> PJCN> > right. ...and, in case, how to get the real solution.
>> PJCN> >
>> PJCN> >
>> PJCN> > Adelchi Azzalini
>> PJCN>
>>
>


From murdoch.duncan at gmail.com  Tue Dec 17 23:02:04 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Dec 2013 17:02:04 -0500
Subject: [R] install.packages and dependencies=TRUE
In-Reply-To: <52B09564.5090204@stats.ox.ac.uk>
References: <CABtg=KkAWJk6XTdxEGrGu6i25ChUmRyoNkTotd-MSPykVnrudA@mail.gmail.com>	<52B07D8C.4060508@gmail.com>	<CABtg=KkemPKnyn1P6HV85wkwvmJuYCFbFoGyNYc419Ejj82VTA@mail.gmail.com>	<CABtg=KmFv+qEwR9+DFgb5_SRxHbOPrmUkFGL1qes4jZk2qNO9g@mail.gmail.com>	<52B09304.9030807@gmail.com>
	<52B09564.5090204@stats.ox.ac.uk>
Message-ID: <52B0C9DC.2080302@gmail.com>

On 13-12-17 1:18 PM, Prof Brian Ripley wrote:
> The obvious idea to set up a local repository works.  It takes 5 mins at
> most.

That makes a lot of sense to do on Unix-alikes, but less so on Windows. 
  A local repository of tarballs needs to be in src/contrib below the 
URL of the repository.  On Unix setting that up as a soft link to the 
real location would be trivial, but on Windows you'd probably want that 
to be the only path to the files, and that's not very convenient when 
you're already used to keeping them elsewhere.

Duncan Murdoch

>
> On 17/12/2013 18:08, Duncan Murdoch wrote:
>> So apparently not as simple as I thought it would be.  So I'll tell you
>> what I actually do:
>>
>> I have a number of packages under development, some on CRAN, some not. I
>> also work in multiple builds of R pretty frequently, so I like to
>> install all my packages and commonly used ones from other people.  So I
>> put together a little script that I can run that will install or update
>> a list of about 20 packages.  Here it is, with the names deleted.
>>
>> # Script to install current versions of commonly used packages
>>
>> installed <- rownames(installed.packages())
>> old <- old.packages()
>>
>> oldoptions <- options(repos =
>> c(CRAN="http://probability.ca/cran",CRANextra="http://www.stats.ox.ac.uk/pub/RWin"))
>>
>> pkgs <-    ------ a character vector of packages on CRAN ------
>> oldPkgs <- old[intersect(pkgs, rownames(old)),,drop=FALSE]
>> if (length(oldPkgs))
>>     update.packages(oldPkgs = oldPkgs)
>> pkgs <- setdiff(pkgs, installed)
>> if (length(pkgs))
>>     install.packages(pkgs, dep=c("Depends", "Imports"))
>>
>> options(repos = c(options("repos"),
>> "R-forge"="http://R-Forge.R-project.org"))
>> pkgs <- ------ packages to install from R-forge ------
>> oldPkgs <- old[intersect(pkgs, rownames(old)),,drop=FALSE]
>> if (length(oldPkgs))
>>     update.packages(oldPkgs = oldPkgs)
>> pkgs <- setdiff("patchDVI", installed)
>> if (length(pkgs))
>>     install.packages(pkgs)
>>
>> MyR <- ------ the source directory where I keep my own packages ------
>> pkgs <- ------ packages to install from local source ------
>> pkgs <- setdiff(pkgs, installed)
>> if (length(pkgs))
>>     install.packages(file.path(MyR, pkgs), type="source", repos=NULL)
>>
>> options(oldoptions)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From nashjc at uottawa.ca  Tue Dec 17 23:03:34 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Tue, 17 Dec 2013 17:03:34 -0500
Subject: [R] convergence=0 in optim and nlminb is real?
In-Reply-To: <B4C24A11-5D9F-4DF6-9AF1-393D682EB606@stat.unipd.it>
References: <52B05148.5080201@uottawa.ca>
	<20131217173206.9f814f7d178433e81167487a@stat.unipd.it>
	<52B08761.9030609@uottawa.ca>
	<B4C24A11-5D9F-4DF6-9AF1-393D682EB606@stat.unipd.it>
Message-ID: <52B0CA36.9080905@uottawa.ca>

I actually agree with the sentiments below -- the optimizer should
support its claims. The reality is sadly otherwise, in my view largely
because of the difficulties in computing the Hessian.

This exchange has been useful, as it highlights user expectations.
Without such dialog, we won't improve our R tools.

JN


On 13-12-17 04:54 PM, Adelchi Azzalini wrote:
> It was not my suggestion that an optimizer should check the Hessian on
> every occasion (this would be both time consuming and meaningless), but
> I expected it to do so before claiming that a point is at a minimum,
> that is, only for the candidate final point.
> 
> Neither I have ever thought that nonlinear optimization is a cursory
> operation, especially when the dimensionality is not small. Exactly for
> this reason I expect that an optimizer takes stringent precautions
> before claiming to have completed its job successfully.
> 
> AA
> 
> 
> 
> On 17 Dec 2013, at 18:18, Prof J C Nash (U30A) wrote:
> 
>> As indicated, if optimizers check Hessians on every occasion, R would
>> enrich all the computer manufacturers. In this case it is not too large
>> a problem, so worth doing.
>>
>> However, for this problem, the Hessian is being evaluated by doing
>> numerical approximations to second partial derivatives, so the Hessian
>> may be almost a fiction of the analytic Hessian. I've seen plenty of
>> Hessian approximations that are not positive definite, when the answers
>> were OK.
>>
>> That Inf is allowed does not mean that it is recommended. R is very
>> tolerant of many things that are not generally good ideas. That can be
>> helpful for some computations, but still cause trouble. It seems that it
>> is not the problem here.
>>
>> I did not look at all the results for this problem from optimx, but it
>> appeared that several results were lower than the optim(BFGS) one. Is
>> any of the optimx results acceptable? Note that optimx DOES offer to
>> check the KKT conditions, and defaults to doing so unless the problem is
>> large. That was included precisely because the optimizers generally
>> avoid this very expensive computation. But given the range of results
>> from the optimx answers using "all methods", I'd still want to do a lot
>> of testing of the results.
>>
>> This may be a useful case to point out that nonlinear optimization is
>> not a calculation that should be taken for granted. It is much less
>> reliable than most users think. I rarely find ANY problem for which all
>> the optimx methods return the same answer. You really do need to look at
>> the answers and make sure that they are meaningful.
>>
>> JN
>>
>> On 13-12-17 11:32 AM, Adelchi Azzalini wrote:
>>> On Tue, 17 Dec 2013 08:27:36 -0500, Prof J C Nash (U30A) wrote:
>>>
>>> PJCN> If you run all methods in package optimx, you will see results
>>> PJCN> all over the western hemisphere. I suspect a problem with some
>>> PJCN> nasty computational issues. Possibly the replacement of the
>>> PJCN> function with Inf when any eigenvalues < 0 or  nu < 0 is one
>>> PJCN> source of this.
>>>
>>> A value Inf is allowed, as indicated in this passage from the
>>> documentation of optim:
>>>
>>>  Function fn can return NA or Inf if the function cannot be evaluated
>>>  at the supplied value, but the initial value must have a computable
>>>  finite value of fn.
>>>
>>> Incidentally, the documentation of optimx includes the same sentence.
>>>
>>> However, this aspect is not crucial anyway, since the point selected by
>>> optim is within the feasible space (by a good margin), and evaluation of
>>> the Hessian matrix occurs at this point.
>>>
>>> PJCN>
>>> PJCN> Note that Hessian eigenvalues are not used to determine
>>> PJCN> convergence in optimization methods. If they did, nobody would
>>> PJCN> ever get promoted from junior lecturer who was under 100 if they
>>> PJCN> needed to do this, because determining the Hessian from just the
>>> PJCN> function requires two levels of approximate derivatives.
>>>
>>> At the end of the optimization process, when a point is going to be
>>> declared a minimum point, I expect that an optimizer  checks that it
>>> really *is* a minimum. It may do this in other ways other than
>>> computing the eigenvalues, but it must be done somehow. Actually, I
>>> first realized the problem by attempting inversion (to get standard
>>> errors) under the assumption of positive definiteness, and it failed.
>>> For instance
>>>
>>>  mnormt:::pd.solve(opt$hessian)
>>>
>>> says  "x appears to be not positive definite". This check does not
>>> involve a further level of approximation.
>>>
>>> PJCN>
>>> PJCN> If you want to get this problem reliably solved, I think you will
>>> PJCN> need to
>>> PJCN> 1) sort out a way to avoid the Inf values -- can you constrain
>>> PJCN> the parameters away from such areas, or at least not use Inf.
>>> PJCN> This messes up the gradient computation and hence the optimizers
>>> PJCN> and also the final Hessian.
>>> PJCN> 2) work out an analytic gradient function.
>>> PJCN>
>>>
>>> In my ealier message, I have indicated that this is a semplified
>>> version of the real thing, which is function mst.mle of pkg 'sn'.
>>> What mst.mle does is exactly what you indicated, that is, it
>>> re-parameterizes the problem so that we always stay within the
>>> feasible region and works with analytic gradient function (of the
>>> transformed parameters). The final outcome is the same: we land on
>>> the same point.
>>>
>>> However, once the (supposed) point of minimum has been found, the
>>> Hessian matrix must be computed on the original parameterization,
>>> to get standard errors.
>>>
>>> Adelchi Azzalini
>>>
>>> PJCN>
>>> PJCN>
>>> PJCN> > Date: Mon, 16 Dec 2013 16:09:46 +0100
>>> PJCN> > From: Adelchi Azzalini <azzalini at stat.unipd.it>
>>> PJCN> > To: r-help at r-project.org
>>> PJCN> > Subject: [R] convergence=0 in optim and nlminb is real?
>>> PJCN> > Message-ID:
>>> PJCN> > <20131216160946.91858ff279db26bd65e187bc at stat.unipd.it>
>>> PJCN> > Content-Type: text/plain; charset=US-ASCII
>>> PJCN> >
>>> PJCN> > It must be the case that this issue has already been rised
>>> PJCN> > before, but I did not manage to find it in past posting.
>>> PJCN> >
>>> PJCN> > In some cases, optim() and nlminb() declare a successful
>>> PJCN> > convergence, but the corresponding Hessian is not
>>> PJCN> > positive-definite.  A simplified version of the original
>>> PJCN> > problem is given in the code which for readability is placed
>>> PJCN> > below this text.  The example is built making use of package
>>> PJCN> > 'sn', but this is only required to set-up the example: the
>>> PJCN> > question is about the outcome of the optimizers. At the end of
>>> PJCN> > the run, a certain point is declared to correspont to a minimum
>>> PJCN> > since 'convergence=0' is reported, but the eigenvalues of the
>>> PJCN> > (numerically evaluated) Hessian matrix at that point are not
>>> PJCN> > all positive.
>>> PJCN> >
>>> PJCN> > Any views on the cause of the problem? (i) the point does not
>>> PJCN> > correspong to a real minimum, (ii) it does dive a minimum but
>>> PJCN> > the Hessian matrix is wrong, (iii) the eigenvalues are not
>>> PJCN> > right. ...and, in case, how to get the real solution.
>>> PJCN> >
>>> PJCN> >
>>> PJCN> > Adelchi Azzalini
>>> PJCN>
>>>
>>
>


From ripley at stats.ox.ac.uk  Tue Dec 17 23:04:41 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Dec 2013 22:04:41 +0000
Subject: [R] install.packages and dependencies=TRUE
In-Reply-To: <52B0C9DC.2080302@gmail.com>
References: <CABtg=KkAWJk6XTdxEGrGu6i25ChUmRyoNkTotd-MSPykVnrudA@mail.gmail.com>	<52B07D8C.4060508@gmail.com>	<CABtg=KkemPKnyn1P6HV85wkwvmJuYCFbFoGyNYc419Ejj82VTA@mail.gmail.com>	<CABtg=KmFv+qEwR9+DFgb5_SRxHbOPrmUkFGL1qes4jZk2qNO9g@mail.gmail.com>	<52B09304.9030807@gmail.com>
	<52B09564.5090204@stats.ox.ac.uk> <52B0C9DC.2080302@gmail.com>
Message-ID: <52B0CA79.8050607@stats.ox.ac.uk>

On 17/12/2013 22:02, Duncan Murdoch wrote:
> On 13-12-17 1:18 PM, Prof Brian Ripley wrote:
>> The obvious idea to set up a local repository works.  It takes 5 mins at
>> most.
>
> That makes a lot of sense to do on Unix-alikes, but less so on Windows.
>   A local repository of tarballs needs to be in src/contrib below the
> URL of the repository.  On Unix setting that up as a soft link to the
> real location would be trivial, but on Windows you'd probably want that
> to be the only path to the files, and that's not very convenient when
> you're already used to keeping them elsewhere.

On Linux/OS X/Solaris I do use a soft link.

I have used junctions on Windows.  (I know they do not always work on 
Windows, but they do on the Win 7 systems I use.)

>
> Duncan Murdoch
>
>>
>> On 17/12/2013 18:08, Duncan Murdoch wrote:
>>> So apparently not as simple as I thought it would be.  So I'll tell you
>>> what I actually do:
>>>
>>> I have a number of packages under development, some on CRAN, some not. I
>>> also work in multiple builds of R pretty frequently, so I like to
>>> install all my packages and commonly used ones from other people.  So I
>>> put together a little script that I can run that will install or update
>>> a list of about 20 packages.  Here it is, with the names deleted.
>>>
>>> # Script to install current versions of commonly used packages
>>>
>>> installed <- rownames(installed.packages())
>>> old <- old.packages()
>>>
>>> oldoptions <- options(repos =
>>> c(CRAN="http://probability.ca/cran",CRANextra="http://www.stats.ox.ac.uk/pub/RWin"))
>>>
>>>
>>> pkgs <-    ------ a character vector of packages on CRAN ------
>>> oldPkgs <- old[intersect(pkgs, rownames(old)),,drop=FALSE]
>>> if (length(oldPkgs))
>>>     update.packages(oldPkgs = oldPkgs)
>>> pkgs <- setdiff(pkgs, installed)
>>> if (length(pkgs))
>>>     install.packages(pkgs, dep=c("Depends", "Imports"))
>>>
>>> options(repos = c(options("repos"),
>>> "R-forge"="http://R-Forge.R-project.org"))
>>> pkgs <- ------ packages to install from R-forge ------
>>> oldPkgs <- old[intersect(pkgs, rownames(old)),,drop=FALSE]
>>> if (length(oldPkgs))
>>>     update.packages(oldPkgs = oldPkgs)
>>> pkgs <- setdiff("patchDVI", installed)
>>> if (length(pkgs))
>>>     install.packages(pkgs)
>>>
>>> MyR <- ------ the source directory where I keep my own packages ------
>>> pkgs <- ------ packages to install from local source ------
>>> pkgs <- setdiff(pkgs, installed)
>>> if (length(pkgs))
>>>     install.packages(file.path(MyR, pkgs), type="source", repos=NULL)
>>>
>>> options(oldoptions)
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dwinsemius at comcast.net  Tue Dec 17 23:19:49 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 17 Dec 2013 14:19:49 -0800
Subject: [R] Problem to solve an integral equation
In-Reply-To: <CAOwh97s046faeJfWbqkATGUnFvQL0T1BVrr8rqL889ZRgrGeJA@mail.gmail.com>
References: <CAOwh97th8yrmPviMGUFYQJTHzwC6Din8KYbCY_ihEXdFd3=+xw@mail.gmail.com>
	<5D1258CB-DC0F-4F10-AC25-C24C98A737B5@comcast.net>
	<CAOwh97s046faeJfWbqkATGUnFvQL0T1BVrr8rqL889ZRgrGeJA@mail.gmail.com>
Message-ID: <81BAB3CF-DD1E-41F8-9CF8-0AAF386C8239@comcast.net>


On Dec 17, 2013, at 11:25 AM, Aur?lien Philippot wrote:

> thanks David for your answer.
> 
> Sorry for the integrand; as you noticed, a parenthesis was missing. 
> Here is another integrand which is properly defined:
> 
> integrand<- function(C,x){-((5000000+100000*x+10000*max(0,x-50))^(-1)-(5000000+100000*x+C)^(-1))*
>                             1/(x*0.20*sqrt(10)*sqrt(2*pi))*exp(-0.5*((log(x/50)-0.10*10)/(0.20*sqrt(10)))^2)}
> 
> 
> In the general line of the solution that you propose, I guess you start by generating a sequence of values for C for which you evaluate the objective function. Do you then generate a new sequence between any two numbers of the first sequence for which the output function changes sign? 
> 

As I said, the usual route is to use sapply or Vectorize and it is up to you to provide an approportiate domain,

Vout <- Vectorize(output)

# Your function does not appear to have a solution in the domain you are investigating:

which ( Vout(seq(0, 1000000, by=10000)  ) < 0  )
integer(0)

# So the output of uniroot.all seems appropriate:

uniroot.all(Vout, c(0,1000000))
numeric(0)

-- 
David.
> 
> 
> 
> 
> 2013/12/17 David Winsemius <dwinsemius at comcast.net>
> 
> On Dec 17, 2013, at 8:53 AM, Aur?lien Philippot wrote:
> 
> > Dear R experts,
> >
> > I am trying to find numerical solutions for an integral equation.
> >
> >
> > Here is an example:
> >
> > I started by defining the integrand, as a function of x and C, where x is
> > the variable of integration and C is the parameter I am interested in:
> >
> >
> > integrand<- function(C,x){-((100000*x)^(-1)-(1000*x+C)^(-1))*
> > 1/(0.20*sqrt(2*pi))*exp(-0.5*(x-0.10)/(0.20))^2)}
> 
> Error: unexpected ')' in:
> "integrand<- function(C,x){-((100000*x)^(-1)-(1000*x+C)^(-1))*
> 1/(0.20*sqrt(2*pi))*exp(-0.5*(x-0.10)/(0.20))^2)"
> 
> Taking out the last parenthesis resulted in a variety of error messages including:
> 
> > output(0)
> Error in integrate(integrand, C = C, lower = 0, upper = Inf) :
>   extremely bad integrand behaviour
> > output(-10)
> Error in integrate(integrand, C = C, lower = 0, upper = Inf) :
>   the integral is probably divergent
> 
> 
> 
> > Then, I integrate with respect to x, and define an objective function
> > (output) with respect to C:
> >
> >
> > output<- function(C) integrate(integrand, C=C, lower=0, upper=Inf)$value
> >
> >
> 
> Generally these problems are solved with the use of something along the lines of
> 
>     sapply( seq(...), output)  # across an appropriate domain
> 
> Or using the `Vectorize` function.
> 
> But since you did not supply tested code for the integrand, I am not proceeding further.
> 
> --
> david.
> 
> 
> > I would like all the values of C (if any) for which the integral is equal
> > to 0.
> >
> > I did the following:
> >
> >
> > library(rootSolve)
> >
> > uniroot.all(output, c(0,1000000))
> >
> >
> > but that does not work ("evaluation of function gave a result of wrong
> > length"). I cannot either plot the function using plot or curve. I don't
> > understand what is going on?
> >
> > Thanks in advance for any advice!
> >
> > Aurelien
> --
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From jim at bitwrit.com.au  Tue Dec 17 23:46:43 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 18 Dec 2013 09:46:43 +1100
Subject: [R] Hello R user!
In-Reply-To: <CAGC2kj59staO+SyWX3JGfH9viYj+T-YYJKZvmJKY5fLOLhQV6w@mail.gmail.com>
References: <CAGC2kj59staO+SyWX3JGfH9viYj+T-YYJKZvmJKY5fLOLhQV6w@mail.gmail.com>
Message-ID: <52B0D453.3040509@bitwrit.com.au>

On 12/18/2013 04:33 AM, bibek sharma wrote:
> Hello R user,
>
> I have created two plots (attached!) using the codes below
> and would like to merge these figures in one. any suggestions are highly
> appreciated!
> Thanks,
>
> plot(graph1$yod,graph1$xod,data=graph1)
> dfx = data.frame(ev1=graph1$xod, ev2=graph1$yod, ev3=abs(graph1$dif))
> symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
> bg="black", fg=NULL,xlim=c(-35,35),ylim=c(-35,35))
> abline(h=0,v=0)
>
> plot(graph2$yod,graph2$xod,data=graph2)
> dfx = data.frame(ev1=graph2$xod, ev2=graph2$yod, ev3=abs(graph2$dif))
> lines(symbols(x=dfx$ev1, y=dfx$ev2, circles=dfx$ev3,inches=1/8, ann=F,
> bg="blue", fg=NULL,xlim=c(-35,35),ylim=c(-35,35)))
> abline(h=0,v=0)
>
Hi Bibek,
 From what I can guess of the above, you might be interested in the 
size_n_color plot (plotrix).

Jim


From Thierry.ONKELINX at inbo.be  Wed Dec 18 00:11:29 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 17 Dec 2013 23:11:29 +0000
Subject: [R] ggplot2: stat_smooth for family=binomial with cbind(Y,
 N) formula
In-Reply-To: <52B09B0D.8000301@yorku.ca>
References: <52B0584F.40608@yorku.ca>
	<AA818EAD2576BC488B4F623941DA7427DFBCA602@inbomail.inbo.be>,
	<52B09B0D.8000301@yorku.ca>
Message-ID: <AA818EAD2576BC488B4F623941DA7427DFBCF753@inbomail.inbo.be>

Dear Michael,

have you tried the fullrange argument of stat_smooth?

ggplot(SpaceShuttle, aes(x = Temperature, y = nFailures / trials)) +
     geom_point() +
     geom_smooth(method = "glm", family = binomial, aes(weight = trials), fullrange = TRUE)

Best regrads,

Thierry
________________________________________
Van: Michael Friendly [friendly at yorku.ca]
Verzonden: dinsdag 17 december 2013 19:42
Aan: ONKELINX, Thierry; R-help
Onderwerp: Re: [R] ggplot2: stat_smooth for family=binomial with cbind(Y,       N) formula

Thanks very much for this helpful reply, Thierry

Using aes(weight=trials) in stat_smooth() was part of what I was missing
and solves my main
question.
However, for this data, I want to show the extrapolated prediction over
a wider range than in
the data.  Adding xlim() doesn't help here-- the plot annotations are
cut off at the lowest
value of Temperature in the data. Is there another way?

ggplot(SpaceShuttle, aes(x = Temperature, y = nFailures / trials)) +
     xlim(30, 81) +
     geom_point() +
     geom_smooth(method = "glm", family = binomial, aes(weight = trials))

Below is the complete (but messy) code for the plot() I would like to
more or less replicate using
ggplot()

data("SpaceShuttle", package="vcd")
logit2p <- function(logit) 1/(1 + exp(-logit))

plot(nFailures/6 ~ Temperature, data = SpaceShuttle,
      xlim = c(30, 81), ylim = c(0,1),
      main = "NASA Space Shuttle O-Ring Failures",
      ylab = "Estimated failure probability",
      xlab = "Temperature (degrees F)",
      type="n")  # painters model: add points last

fm <- glm(cbind(nFailures, 6 - nFailures) ~ Temperature,
           data = SpaceShuttle,
           family = binomial)
pred <- predict(fm, data.frame(Temperature = 30 : 81), se=TRUE)

predicted <- data.frame(
     Temperature = 30 : 81,
     prob = logit2p(pred$fit),
     lower = logit2p(pred$fit - 2*pred$se),
     upper = logit2p(pred$fit + 2*pred$se)
     )

with(predicted, {
     polygon(c(Temperature, rev(Temperature)),
             c(lower, rev(upper)), col="lightpink", border=NA)
     lines(Temperature, prob, lwd=3)
     }
     )
with(SpaceShuttle,
     points(Temperature, nFailures/6, col="blue", pch=19, cex=1.3)
     )

I also tried following the example in given in ?geom_smooth, to supply
the predicted
values over my range of x values, and lower/upper limits in a separate
data frame:

pred <- predict(fm, data.frame(Temperature = 30 : 81), se=TRUE)
predicted <- data.frame(
     Temperature = 30 : 81,
     prob = logit2p(pred$fit),
     lower = logit2p(pred$fit - 2*pred$se),
     upper = logit2p(pred$fit + 2*pred$se)
     )
ggplot(SpaceShuttle, aes(x = Temperature, y = nFailures / trials)) +
   geom_smooth(aes(ymin = lower, ymax = upper), data=predicted,
stat="identity")

but this gives an error:

 > ggplot(SpaceShuttle, aes(x = Temperature, y = nFailures / trials)) +
+   geom_smooth(aes(ymin = lower, ymax = upper), data=predicted,
stat="identity")
Error in eval(expr, envir, enclos) : object 'nFailures' not found
 >

-Michael


On 12/17/2013 11:26 AM, ONKELINX, Thierry wrote:
> Dear Michael,
>
> Calculate the propotions. Then it is easy to use the weight option of glm
>
> data("SpaceShuttle", package="vcd")
> SpaceShuttle$trials <- 6
>
> fm <- glm(cbind(nFailures, 6 - nFailures) ~ Temperature, data = SpaceShuttle, family = binomial)
> fm2 <- glm(nFailures/trials ~ Temperature, data = SpaceShuttle, family = binomial, weight = trials)
> all.equal(coef(fm), coef(fm2))
>
> ggplot(SpaceShuttle, aes(x = Temperature, y = nFailures / trials)) + geom_point() + geom_smooth(method = "glm", family = binomial, aes(weight = trials))
>
> Best regards,
>
> Thierry
>
> -----Oorspronkelijk bericht-----
> Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Michael Friendly
> Verzonden: dinsdag 17 december 2013 14:58
> Aan: R-help
> Onderwerp: [R] ggplot2: stat_smooth for family=binomial with cbind(Y, N) formula
>
> With ggplot2, I can plot the glm stat_smooth for binomial data when the response is binary or a two-level factor as follows:
>
> data("Donner", package="vcdExtra")
> ggplot(Donner, aes(age, survived)) +
> geom_point(position = position_jitter(height = 0.02, width = 0)) + stat_smooth(method = "glm", family = binomial, formula = y ~ x, alpha = 0.2, size=2)
>
> But how can I specify the formula for stat_smooth when the response is cbind(successes, failures)?
> The equivalent with plot (minus the confidence band) for the example I want is:
>
> data("SpaceShuttle", package="vcd")
>
>   > head(SpaceShuttle, 5)
>     FlightNumber Temperature Pressure Fail nFailures Damage
> 1            1          66       50   no         0      0
> 2            2          70       50  yes         1      4
> 3            3          69       50   no         0      0
> 4            4          80       50 <NA>        NA     NA
> 5            5          68       50   no         0      0
>   >
>
> plot(nFailures/6 ~ Temperature, data = SpaceShuttle,
>        xlim = c(30, 81), ylim = c(0,1),
>        main = "NASA Space Shuttle O-Ring Failures",
>        ylab = "Estimated failure probability",
>        xlab = "Temperature (degrees F)",
>        pch = 19, col = "blue", cex=1.2)
> fm <- glm(cbind(nFailures, 6 - nFailures) ~ Temperature,
>             data = SpaceShuttle,
>             family = binomial)
> pred <- predict(fm, data.frame(Temperature = 30 : 81), se=TRUE)
> lines(30 : 81,
>         predict(fm, data.frame(Temperature = 30 : 81), type = "response"),
>         lwd = 3)
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
>

--
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From arrayprofile at yahoo.com  Wed Dec 18 00:53:33 2013
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 17 Dec 2013 15:53:33 -0800 (PST)
Subject: [R] estimating survival function from Cox model
Message-ID: <1387324413.81817.YahooMailNeo@web122906.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/88d22767/attachment.pl>

From arrayprofile at yahoo.com  Wed Dec 18 00:56:07 2013
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 17 Dec 2013 15:56:07 -0800 (PST)
Subject: [R] estimating survival function from Cox model
Message-ID: <1387324567.46950.YahooMailNeo@web122905.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/7a5d90d7/attachment.pl>

From arrayprofile at yahoo.com  Wed Dec 18 00:59:48 2013
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 17 Dec 2013 15:59:48 -0800 (PST)
Subject: [R] estimating survival function from Cox model
Message-ID: <1387324788.6520.YahooMailNeo@web122904.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131217/fdd88669/attachment.pl>

From htl10 at users.sourceforge.net  Wed Dec 18 01:06:30 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Wed, 18 Dec 2013 00:06:30 +0000 (GMT)
Subject: [R] freetype 2.5.2, problem with the survival package,
	build R 2.15.x with gcc 4.8.x
Message-ID: <1387325190.48859.YahooMailBasic@web133202.mail.ir2.yahoo.com>

------------------------------
On Fri, Dec 13, 2013 16:29 GMT David Winsemius wrote:

>
>On Dec 11, 2013, at 7:30 PM, Hin-Tak Leung wrote:
>
>> Here is a rather long discussion etc about freetype 2.5.2, problem with the survival package, and build R 2.15.x with gcc 4.8.x. Please feel free to skip forward.
>> 
>> - freetype 2.5.2:
>> 
>> the fix to cope with one of the Mac OS X's system fonts just before the release of freetype 2.5.1 caused a regression, crashing over one of Microsoft windows' system fonts. So there is a 2.5.2. There are new 2.5.2 bundles for windows & Mac OS X. The official win/mac binaries of R were built statically with 2+-years-old freetype with a few known problems. Most should upgrade/rebuild.
>> 
>> http://sourceforge.net/projects/outmodedbonsai/files/R/
>> 
>> - problem with the survival package:
>> 
>> Trying to re-run a vignette to get the same result as two years ago
>> reveal a strange change. I went and bisected it down to
>> r11513 and r11516 of the survival package.
>> 
>> -------------- r11513 --------------------
>> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
>> 
>> 
>>? ? ? ? ? ? ? ? ???coef exp(coef) se(coef)? ???z? ? ? p
>> addContr(A)2? ???-0.620? ???0.538? ? 0.217 -2.86 0.0043
>> addContr(C)2? ? ? 0.482? ???1.620? ? 0.217? 2.22 0.0270
>> addContr(A.C)1-2 -0.778? ???0.459? ? 0.275 -2.83 0.0047
>> addContr(A.C)2-1? ???NA? ? ? ? NA? ? 0.000? ? NA? ???NA
>> addContr(A.C)2-2? ???NA? ? ? ? NA? ? 0.000? ? NA? ???NA
>> 
>> Likelihood ratio test=26? on 3 df, p=9.49e-06? n= 13110, number of events= 3524
>> ------------------------------------------
>> 
>> ------------- r11516 ---------------------
>> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
>> 
>> 
>>? ? ? ? ? ? ? ? ? ???coef exp(coef) se(coef)? ? ? ???z? p
>> addContr(A)2? ???-0.14250? ???0.867???110812 -1.29e-06? 1
>> addContr(C)2? ? ? 0.00525? ???1.005???110812? 4.74e-08? 1
>> addContr(A.C)1-2 -0.30097? ???0.740???110812 -2.72e-06? 1
>> addContr(A.C)2-1 -0.47712? ???0.621???110812 -4.31e-06? 1
>> addContr(A.C)2-2? ? ???NA? ? ? ? NA? ? ? ? 0? ? ? ? NA NA
>> 
>> Likelihood ratio test=26? on 4 df, p=3.15e-05? n= 13110, number of events= 3524
>> ------------------------------------------
>> 
>> r11514 does not build, and r11515 have serious memory hogs, so the survival
>> package broke somewhere between r11513 and r11516. Anyway, here is the diff in
>> the vignette, and the data, etc is in the directory above. If somebody want to
>> fix this before I spend any more time on this particular matter, please feel free to do so.
>> 
>> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical8_survival-clogit-diff.pdf/download
>> 
>> That's the one problem from David's 10 practicals which are not due to bugs in snpStats. Some might find it reassuring that only 3 of the 4 problems with the practicals are due to snpStats bugs.
>> 
>> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical7_snpStatsBug-diff.pdf/download
>> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical6_snpStatsBug-diff.pdf/download
>> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical3_snpStatsBug-diff.pdf/download
>> 
>> - build R 2.15.x with gcc 4.8.x
>> 
>> I wish the R commit log was a bit more detailed with r62430 than just
>> "tweak needed for gcc 4.8.x". Anyway, building R 2.15.x with gcc 4.8.x
>> could result in segfaults in usage as innocent and essential
>> as running summary() on a data.frame:
>> 
>> --------------------------------
>> *** caught segfault ***
>> address 0x2f8e6a00, cause 'memory not mapped'
>> 
>> Traceback:
>> 1: sort.list(y)
>> 2: factor(a, exclude = exclude)
>> 3: table(object, exclude = NULL)
>> 4: summary.default(X[[3L]], ...)
>> 5: FUN(X[[3L]], ...)
>> 6: lapply(X = as.list(object), FUN = summary, maxsum = maxsum, digits = 12,???...)
>> 7: summary.data.frame(support)
>> ...
>> --------------------------------
>> 
>> r62430 needs a bit of adapting to apply to R 2.15.x , but you get the idea.
>> I hope this info is useful to somebody else who is still using R 2.15.x , no doubt for very good reasons.
>
>First: Sorry for the blank message. Need more coffee.
>
>Second: Does this mean that only Mac users who are still using 2.15.x need to worry about this issue?
>

The freetype issues affects both windows and mac users. Unix users have it easier, since R on unices (*excluding* Mac OS X) dynamically
links to the system's shared freetype, so upgrading at the system level would work. R for windows and Mac OS X are statically linked to
a rather out-dated version of freetype.

The survival package issues affects everybody using R more recent than survival package r11513 
Date:   Wed Feb 1 22:47:36 2012 +0000
    Remove "browser()" line from survobrien,
    add coxexact.fit

>Third: I'm reading this (and Terry's comment about singularity conditions)? to mean that a numerical? discrepancy between vignette output when code was run being from what was expected was causing a segfault under some situation that I cannot quite reconstruct. Was the implication that Mac users (of 2.15.x) need to build from sources only if they wanted to build the survival package from source? Does this have any implications for those of us who use the survival package as the binary? (And I'm using 3.0.2, so a split answer might be needed to cover 2.15.x and the current versions separately)
>

Your comprehension of the issue seem to be entirely wrong. Between r11513 and r11516, some tuning of internal parmeters were done, so the process of finding the rank of a singular matrix no longer converges (within the time/tolerance implicitly specified). There are warnings issued, but then there are misc warnings before and after (and one gets "desensitised" about them). Also the nature of the problem, which is to test for possibility of interactions - or lacking thereof -

outcome ~ factor A + factor B + factor A x factor B

or just extra terms in "outcome ~ factor A + factor B + ..." as an exploration of auxiliary effects, more often than not extra terms won't make
any difference and the matrix involved just isn't the nicest to manipulate; it is in the nature of that kind of exploratory work.

Professor Therneau replied that it is possible to get the older convergent behaviour by manual tuning of some of the convergence criteria parameters; I have responded that while that is possible, often one is simultaneously exploring many models with many possible auxiliary effects (and lacking thereof), manual tuning for each is neither feasible nor appropriate; and we sort of left it at that.

BTW, I trimmed the vignette and the data down - from a 70MB thing - to a 40k and about 20 lines of R code, and put it under *_trimmed.{Rcode/Rda}.
http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/

and with the outcomes (*.Rout.*) from R 3.1.0 (R dev trunk), R 2.15.x, and R 2.15.x with survival r11513.

There are also *_memoryhog.{Rcode,Rda}, for those who want to see what's the memory hog problem with r11515. Obviously there is no Rout files, since I had to kill the R process to stop it hogging my system :-).

As for the gcc 4.8.x issue, I rather think describing r62430 as "tweak needed for gcc 4.8.x" is unfortunate. For those who haven't got
R dev trunk history handy, r62430 put a zero at the end of an array of 16 to make it 17-element long. Without it, as I wrote,
R 2.15.x built that way would segfault at very innocent things like doing a summary() on a data.frame. (r62431 is part of R 3.0.0 RC).

However, if put a zero at the end of an array of 16 to make it 17-element long is a "fix" to a segmentation fault, it must mean that the code has always been wrong, and that it had relied on the C compiler to generously pad with nulls on uninitialized memory, for the code to work as intended beforehand. AFAIK, the Sun studio compiler behaves that way, and so does a few proprietary unix system's C compiler; It is notably not true for gcc (the gcc developers largerly think programmers should write good code where the i's are dotted and t's are crossed, instead of having the compiler protecting them from their own oversights); moreover, on recent redhat fedora systems (where gcc 4.8.x is likely the first to land), uninitialized memories are explicitly filled with random non-nulls to foil malwares which utilises and skips nulls (=no-ops) to jump to the next instruction the malware places in memory. So "tweak needed for gcc 4.8.x" just isn't a good
 description for that change.

>-- 
>David.
>> 
>> Hin-Tak Leung wrote:
>> The freetype people fixed the 2nd set of issues with system fonts shipped with
>> Mac OS X, and released 2.5.1 almost immediately after that. So there are
>> new bundles under http://sourceforge.net/projects/outmodedbonsai/files/R/ .
>> 
>> Just a reminder that the official R binaries for windows/mac OS X are statically
>> linked with rather dated versions of freetype with a few known issues. This
>> affects the cairo-based functionalities in R. So a rebuild is needed.
>> 
>> Most unix users should just upgrade their system's libfreetype, and
>> dynamic-linking should take care of the rest.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>David Winsemius
>Alameda, CA, USA
>


From sjkiss at gmail.com  Wed Dec 18 02:53:58 2013
From: sjkiss at gmail.com (Simon Kiss)
Date: Tue, 17 Dec 2013 20:53:58 -0500
Subject: [R] Help using mapply to run multiple models
Message-ID: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>

I think I'm missing something.  I have a data frame that looks below.  
sample.df<-data.frame(var1=rbinom(50, size=1, prob=0.5), var2=rbinom(50, size=2, prob=0.5), var3=rbinom(50, size=3, prob=0.5), var4=rbinom(50, size=2, prob=0.5), var5=rbinom(50, size=2, prob=0.5))

I'd like to run a series of univariate general linear models where var1 is always the dependent variable and each of the other variables is the independent. Then I'd like to summarize each in a table.
I've tried : 

sample.formula=list(var1~var2, var1 ~var3, var1 ~var4, var1~var5)
mapply(glm, formula=sample.formula, data=list(sample.df), family='binomial')

And that works pretty well, except, I'm left with a matrix that contains all the information I need. I can't figure out how to use summary() properly on this information to usefully report that information. 

Thank you for any suggestions. 

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9


From dwinsemius at comcast.net  Wed Dec 18 04:12:21 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 17 Dec 2013 19:12:21 -0800
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
Message-ID: <BA328A0C-AB0A-4DD8-8C9A-A949B6264EC0@comcast.net>


On Dec 17, 2013, at 5:53 PM, Simon Kiss wrote:

> I think I'm missing something.  I have a data frame that looks below.  
> sample.df<-data.frame(var1=rbinom(50, size=1, prob=0.5), var2=rbinom(50, size=2, prob=0.5), var3=rbinom(50, size=3, prob=0.5), var4=rbinom(50, size=2, prob=0.5), var5=rbinom(50, size=2, prob=0.5))
> 
> I'd like to run a series of univariate general linear models where var1 is always the dependent variable and each of the other variables is the independent. Then I'd like to summarize each in a table.
> I've tried : 
> 
> sample.formula=list(var1~var2, var1 ~var3, var1 ~var4, var1~var5)
> mapply(glm, formula=sample.formula, data=list(sample.df), family='binomial')
> 
> And that works pretty well, except, I'm left with a matrix that contains all the information I need. I can't figure out how to use summary() properly on this information to usefully report that information. 

The default for mapply's SIMPLIFY argument is TRUE. If you do not want a matrix, then set it to FALSE and the list items will retain their glm-object status.

(The summary function applied to the resulting list is still a bit strange, but it is recognizable as having class 'glm' at the end. You should be able to extract the bits that you want and ignore the strange $call item.)

-- 
David Winsemius
Alameda, CA, USA


From totangjie at gmail.com  Wed Dec 18 07:33:48 2013
From: totangjie at gmail.com (Jie Tang)
Date: Wed, 18 Dec 2013 14:33:48 +0800
Subject: [R] how to analysisi spectrum of a dataset with NA value
Message-ID: <CAMUSh4rGmUj_2j6Ne_Qsa+aH+YBMPyF3OcvqwSAh27C2oMj=OQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131218/76b08cfc/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Wed Dec 18 09:47:46 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 18 Dec 2013 00:47:46 -0800
Subject: [R] how to analysisi spectrum of a dataset with NA value
In-Reply-To: <CAMUSh4rGmUj_2j6Ne_Qsa+aH+YBMPyF3OcvqwSAh27C2oMj=OQ@mail.gmail.com>
References: <CAMUSh4rGmUj_2j6Ne_Qsa+aH+YBMPyF3OcvqwSAh27C2oMj=OQ@mail.gmail.com>
Message-ID: <a75b4f2c-b4c9-4487-a6f4-271b8a05b567@email.android.com>

This behavior is typical for "fast" Fourier Transform algorithms. You need to decide what theory you want to use in dealing with your missing data, and apply that yourself. There are some packages that can help you (e.g. Lomb-Scargle or discrete slow Fourier transform). Search with package sos or use the RSiteSearch function.

Please read the Posting Guide regarding not using HTML formatted email... your code fragment was unreadable as is common with non-plain text.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Jie Tang <totangjie at gmail.com> wrote:
>hi R users
>
>I have a large 1D dataset and some of them is NA value .
>
>I found I cound get the spectrum by such a command.
>
>ua=c??10??30 ??40??50??NA??
>spectrum(ua)
> and I could not use na.rm just like mean or sd function
>
>How could I get the spectrum of ua ?
>
> thank you .


From j.a.balbuena at uv.es  Wed Dec 18 09:28:41 2013
From: j.a.balbuena at uv.es (Juan Antonio Balbuena)
Date: Wed, 18 Dec 2013 09:28:41 +0100
Subject: [R] multicore and mclapply problem in calculation server
Message-ID: <52B15CB9.5040604@uv.es>


   Hello
   I am using package multicore for parallel computing in a Altix UltraViolet
   1000 server with 64 CPUs and 960 GB of RAM memory. Access is managed by
   means of a SGE queue system. This is the first time I am using parallel
   computing and my experience with supercomputers is quite limited. So any
   help will be much, much appreciated.
   My experiment consists of a number of runs (N.runs) each involving a number
   of permutations (N. perms). (An excerpt of the code is included below.) The
   permutations are very time consuming and I am using mclapply to distribute
   the job among a given number of cpus (usually 12 to 24). The problem is that
   the system administrators notice that threads keep increasing as the program
   is executed to the point that they compromise the functioning of the whole
   system and have to abort the job.
   I have tried to specify in the bash file sent to the queue RAM limits (using
   ulimit) and the number of cpus to be used but it doesn't help.
   An example of the code I am using may be
   #LOAD LIBRARIES NEEDED:
   library(ape)
   library(phytools)
   library(phangorn)
   library(multicore)
   #
   .... SOME 100 LINES HERE DEVOTED TO DEFINE FUNCTIONS -- OMITTED FOR BREVITY
   #######
   body  <-  function  (N.perm) {           #MAIN BODY = 1 RUN -- IT PUTS
   FUNCTIONS TOGETHER
     HP <- HPrandomizer(NH,NP,N.assoc)
     linH = readLines(conH, n= N.perm)
     linP = readLines(conP, n= N.perm)
     stat.matrix <- matrix((rep(NA, 6*N.perm)), ,6)
     #
     wrapper <- function (x) {           # THIS FUCNTION IS SUPPOSED TO BE
   PARALLELIZED (SEE BELOW)
       treeH <- read.tree(text=linH[x])
       treeP <- read.tree(text=linP[x])
       mrcaL <- MRCALink.simul (treeH, treeP, HP)
       stat.matrix[x,] <- three.stat(mrcaL)
       }
     x <- c(1: length(linH))            #NOTE THAT linH IS SUPPOSED TO BE =
   N.perm
     stat.matrix <- do.call(rbind, mclapply(x, wrapper, mc.cores= 6)) # USE OF
   MCLAPPLY
     Pstat <- apply(stat.matrix, 2, rank)[1,]/length(linH)
     write(c(stat.matrix[1,], Pstat), file =
   "/scratch/ba/balbuena/30H30P40.txt", sep ="\t", append =TRUE,ncolumns=12)
   }
   ptm <- proc.time()  # THE PROGRAM STARTS HERE
   NH= 30
   NP= 30
   N.assoc= 40
   N.runs = 1000
   N.perm = 999
   conH = file("/scratch/ba/balbuena/1MH_30.tre", open="rt") # READS TEXT DATA
   FROM EXTERNAL FILE
   conP  = file("/scratch/ba/balbuena/1MP_30.tre", open="rt") #    "    "
   "    "     "       "
   replicate (N.runs, body(N.perm))  # LOOPING body NUMBER OF RUNS
   close(conH)
   close(conP)
   proc.time() - ptm
   Than you very much for your attention
   Juan A. Balbuena

   --

   Dr. Juan A. Balbuena
   Marine Zoology Unit
   Cavanilles Institute of Biodiversity and Evolutionary Biology
   University of
   Valencia
   [1]http://www.uv.es/~balbuena
   P.O. Box 22085
   [2]http://www.uv.es/cavanilles/zoomarin/index.htm
   46071 Valencia, Spain
   [3]http://cetus.uv.es/mullpardb/index.html
   e-mail: [4]j.a.balbuena at uv.es    tel. +34 963 543 658    fax +34 963 543 733
   ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
   NOTE! For shipments by EXPRESS COURIER use the following street address:
   C/ Catedr??tico Jos?? Beltr??n 2, 46980 Paterna (Valencia), Spain.
   ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

References

   1. http://www.uv.es/%7Ebalbuena
   2. http://www.uv.es/cavanilles/zoomarin/index.htm
   3. http://cetus.uv.es/mullpardb/index.html
   4. mailto:j.a.balbuena at uv.es

From joseclaudio.faria at gmail.com  Wed Dec 18 13:13:06 2013
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Wed, 18 Dec 2013 10:13:06 -0200
Subject: [R] Tinn-R user list on Google groups
Message-ID: <CAN+Emd8V9_7oW2OkUSZFMNjBgUEFfrEHSbW9RUXWbg+yDmafbQ@mail.gmail.com>

Dears Tinn-R users,

Below a link to the new user list on Google groups:
https://groups.google.com/forum/#!forum/tinn-r

All the best,
-- 
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)9100.7351 - TIM
55(73)8817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\


From smartpink111 at yahoo.com  Wed Dec 18 15:32:04 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Dec 2013 06:32:04 -0800 (PST)
Subject: [R] ifelse statement with two vectors of different length
Message-ID: <1387377124.70686.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Please show a reproducible example.

countrydiff <- c("Albania", "Algeria", "Belarus", "Canada", "Germany")
long_df <- data.frame(country_name = c("Algeria", "Guyana", "Hungary", "Algeria", "Canada", "Iran", "Iran", "Norway","Uruguay", "Zimbabwe") )
?ifelse(long_df$country_name %in% countrydiff,1,0)
# [1] 1 0 0 1 1 0 0 0 0 0
#or
1*(long_df$country_name %in% countrydiff)
# [1] 1 0 0 1 1 0 0 0 0 0
A.K.




Dear list-members, 

I have the following problem: I have a vector (countrydiff) with
 length 72 and another vector (long_df$country_name) which is about 
12000 long. Basically what I want to do is to if the factor level (or 
string name) in long_df$country_name appears on the countrydiff, then 
long_df$povdat should be equal to 1, if it does not appear on the 
countrydiff vector then long_df$povdat should be equal to zero. I have 
tried different combinations and read some. The following code should in
 my mind do it, but it doesn?t: 

long_df$povdat<-ifelse(long_df$country_name == countrydiff, 1, 0) 

long_df$povdat<-ifelse(long_df$country_name %in% countrydiff, 1, 0) 

Additional information: the factor vector countrydiff contains 
unique country names (Albania, Zimbabwe etc.), whereas 
long_df$country_name also contains country names albeit not unique since
 it is in longform. The unique names that appear in long_df$country_name
 is around 200. 


Any suggestions? 
Thanks in advance. 

Best 
Adel


From adel.daoud at sociology.gu.se  Wed Dec 18 14:57:10 2013
From: adel.daoud at sociology.gu.se (Adel)
Date: Wed, 18 Dec 2013 05:57:10 -0800 (PST)
Subject: [R] ifelse statement with two vectors of different length
Message-ID: <1387375030961-4682401.post@n4.nabble.com>


Dear list-members,

I have the following problem: I have a vector (countrydiff) with length 72
and another vector (long_df$country_name) which is about 12000 long.
Basically what I want to do is to if the factor level (or string name) in
long_df$country_name appears on the countrydiff, then long_df$povdat should
be equal to 1, if it does not appear on the countrydiff vector then
long_df$povdat should be equal to zero. I have tried different combinations
and read some. The following code should in my mind do it, but it doesn?t:

long_df$povdat<-ifelse(long_df$country_name == countrydiff, 1, 0)

long_df$povdat<-ifelse(long_df$country_name %in% countrydiff, 1, 0)

Additional information: the factor vector countrydiff contains unique
country names (Albania, Zimbabwe etc.), whereas long_df$country_name also
contains country names albeit not unique since it is in longform. The unique
names that appear in long_df$country_name is around 200.


Any suggestions?
Thanks in advance.

Best
Adel




--
View this message in context: http://r.789695.n4.nabble.com/ifelse-statement-with-two-vectors-of-different-length-tp4682401.html
Sent from the R help mailing list archive at Nabble.com.


From simon.delay-fortier at mail.mcgill.ca  Wed Dec 18 15:52:37 2013
From: simon.delay-fortier at mail.mcgill.ca (Simon Delay-Fortier)
Date: Wed, 18 Dec 2013 14:52:37 +0000
Subject: [R]  3D Surface plot
Message-ID: <FCECE981A5D14046AA7444DC56070347116857@EXMBX2010-4.campus.MCGILL.CA>

Hi everyone,

I am a very new user of r (doing most of my previous stuff in vba). I am now mandated to draw a 3-d surface of a mine pit hole. I have all the location points (around 5000 points) of the pit in a CSV file under 3 column X, Y & Z. However, going from page to page on the web, I could not figure out how to code the figure. Something I noted is that most of the time X and Y  have to be in ascending order but the data I have are not (since they are finite points of the pit, if X gets  in ascending order, Y and Z are not). Also with the data, sometimes 2 rows fallowing each ohter have the same X and Y value with a different Z. That would be nice if things could be modeled with rgl function in order to have a rotating pit, but I would be glad to only have a 3d surface to start!

Hope you can help.
Sincerly,

Simon Delay-Fortier

From vera.kuehnl at uni-ulm.de  Wed Dec 18 13:30:15 2013
From: vera.kuehnl at uni-ulm.de (mb)
Date: Wed, 18 Dec 2013 04:30:15 -0800 (PST)
Subject: [R] calculating power function
Message-ID: <1387369815725-4682396.post@n4.nabble.com>

Hello,

i know there are several functions on r to calculate the power of a test.
f.e the functions of pwr packet. In this packet the use the power function
(1-\beta) to calculate. My question is how we get this function for anova
(pwr.anova.test)?
I know that 
1-\beta=P(H1|H1) = P(F>F_[1-\alpha,k-1,N-k]) = 1-P(F<F_[1-\alpha,k-1,N-k]) =
1-P(MQE/MQR<F_[1-\alpha,k-1,N-k]) = ??....?? = 
1-P(F[k-1,N-k]<F_[1-\alpha,k-1,N-k]-k*n*f^2) = 
p.body = pf(qf(\alpha,k-1,(n-1)k,low=F),k-1,(n-1)k,k*n*f^2,low=F)
With f^2 the effect
and k*n*f^2 ncp
but how does the function which has a F[k-1,N-k] distribution look like? It
has to be the (variance between groups/df)/(variance within
groups/df)-k*n*f^2, but how can I write these so that I see the
dirstribution.
I have never found the exact way how to get to this formula. So may you can
help.

Thanks a lot.



--
View this message in context: http://r.789695.n4.nabble.com/calculating-power-function-tp4682396.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Wed Dec 18 16:04:30 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 18 Dec 2013 10:04:30 -0500
Subject: [R] ifelse statement with two vectors of different length
In-Reply-To: <1387375030961-4682401.post@n4.nabble.com>
References: <1387375030961-4682401.post@n4.nabble.com>
Message-ID: <CAM_vjunN9UMRa3LzVakot8mXDj6twYCYbUUX0cumdEO=GuY_ag@mail.gmail.com>

Hi,

Suggestion 1: read
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
and bookmark it for future reference.

Suggestion 2:
set.seed(123)
countrydiff <- letters[1:5]
long_df <- data.frame(country_name = sample(letters[1:8], 20, replace=TRUE))

long_df$povdat <- as.numeric(long_df$country_name %in% countrydiff)

Sarah

On Wed, Dec 18, 2013 at 8:57 AM, Adel <adel.daoud at sociology.gu.se> wrote:
>
> Dear list-members,
>
> I have the following problem: I have a vector (countrydiff) with length 72
> and another vector (long_df$country_name) which is about 12000 long.
> Basically what I want to do is to if the factor level (or string name) in
> long_df$country_name appears on the countrydiff, then long_df$povdat should
> be equal to 1, if it does not appear on the countrydiff vector then
> long_df$povdat should be equal to zero. I have tried different combinations
> and read some. The following code should in my mind do it, but it doesn?t:
>
> long_df$povdat<-ifelse(long_df$country_name == countrydiff, 1, 0)
>
> long_df$povdat<-ifelse(long_df$country_name %in% countrydiff, 1, 0)
>
> Additional information: the factor vector countrydiff contains unique
> country names (Albania, Zimbabwe etc.), whereas long_df$country_name also
> contains country names albeit not unique since it is in longform. The unique
> names that appear in long_df$country_name is around 200.
>
>
> Any suggestions?
> Thanks in advance.
>
> Best
> Adel
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From teresamarso at hotmail.com  Wed Dec 18 16:16:40 2013
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Wed, 18 Dec 2013 15:16:40 +0000
Subject: [R] ANOVA repeated mesures
Message-ID: <DUB125-W37561264631AC919F39B98B9DA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131218/2eca0dad/attachment.pl>

From petr.pikal at precheza.cz  Wed Dec 18 16:36:17 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 18 Dec 2013 15:36:17 +0000
Subject: [R] read ".slk" file
In-Reply-To: <CAN_e6XvqBmk26ubOP-852LwGDEx_PgY4=Z0Fu6XakWVffFBDaQ@mail.gmail.com>
References: <CAN_e6XvqBmk26ubOP-852LwGDEx_PgY4=Z0Fu6XakWVffFBDaQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA7396@SRVEXCHMBX.precheza.cz>

Hi

Extension does not specify file format. You can rename any file with any extension without changing its nature. However slk stays for symbolic link and therefore it just brings actual file to Excel. 

Maybe you could start to play with

http://stat.ethz.ch/R-manual/R-devel/library/base/html/files.html

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Santosh
> Sent: Tuesday, December 17, 2013 12:11 AM
> To: r-help
> Subject: [R] read ".slk" file
> 
> Dear Rxperts..
> 
> I recently received a data file with the extension ".slk". If I save
> the file as MS Excel file, I am able to read in R without issues.  Is
> it possible to read this ".slk" file without converting into another R-
> readable data format?
> 
> Regards,
> Santosh
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From adel.daoud at sociology.gu.se  Wed Dec 18 16:04:33 2013
From: adel.daoud at sociology.gu.se (Adel)
Date: Wed, 18 Dec 2013 07:04:33 -0800 (PST)
Subject: [R] ifelse statement with two vectors of different length
In-Reply-To: <1387377124.70686.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1387375030961-4682401.post@n4.nabble.com>
	<1387377124.70686.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1387379073369-4682403.post@n4.nabble.com>


Dear Arun

Thanks for your reply, it made me realize that the problem was not in the
code but in the levels() of the factors. Some countries had some extra
spacing which made the ifelse() function not work. So if I modify your code
(added space to countrydiff), it will then look something like this:

countrydiff <- c("Albania    ", "Algeria    ", "Belarus    ", "Canada   ",
"Germany   ") 
long_df <- data.frame(country_name = c("Algeria", "Guyana", "Hungary",
"Algeria", "Canada", "Iran", "Iran", "Norway","Uruguay", "Zimbabwe") ) 

I had to use the gsub to fix this first.


Interestingly, the setdiff() function did not react on spacing difference
which I used before coming to the ifelse statement and therefore I did not
react on this in the first place

#no reaction from R on spacing diff.
setdiff(countrydiff, long_df$country_name)


Nevertheless, thanks again for being helpful!
Adel




--
View this message in context: http://r.789695.n4.nabble.com/ifelse-statement-with-two-vectors-of-different-length-tp4682401p4682403.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Wed Dec 18 16:18:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Dec 2013 07:18:38 -0800 (PST)
Subject: [R] ifelse statement with two vectors of different length
In-Reply-To: <1387375030961-4682401.post@n4.nabble.com>
References: <1387375030961-4682401.post@n4.nabble.com>
Message-ID: <1387379918.27548.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Adel,

If the problem is the spacing, then
library(stringr)
1*(long_df$country_name %in% str_trim(countrydiff))
# [1] 1 0 0 1 1 0 0 0 0 0
A.K.


Dear Arun 

Thanks for your reply, it made me realize that the problem was 
not in the code but in the levels() of the factors. Some countries had 
some extra spacing which made the ifelse() function not work. So if I 
modify your code (added space to countrydiff), it will then look 
something like this: 

countrydiff <- c("Albania ? ?", "Algeria ? ?", "Belarus ? ?", "Canada ? ", "Germany ? ") 
long_df <- data.frame(country_name = c("Algeria", "Guyana", 
"Hungary", "Algeria", "Canada", "Iran", "Iran", "Norway","Uruguay", 
"Zimbabwe") ) 

I had to use the gsub to fix this first. 


Interestingly, the setdiff() function did not react on 
spacing difference which I used before coming to the ifelse statement 
and therefore I did not react on this in the first place 

#no reaction from R on spacing diff. 
setdiff(countrydiff, long_df$country_name) 


Nevertheless, thanks again for being helpful! 
Adel 


On Wednesday, December 18, 2013 9:58 AM, Adel <adel.daoud at sociology.gu.se> wrote:

Dear list-members,

I have the following problem: I have a vector (countrydiff) with length 72
and another vector (long_df$country_name) which is about 12000 long.
Basically what I want to do is to if the factor level (or string name) in
long_df$country_name appears on the countrydiff, then long_df$povdat should
be equal to 1, if it does not appear on the countrydiff vector then
long_df$povdat should be equal to zero. I have tried different combinations
and read some. The following code should in my mind do it, but it doesn?t:

long_df$povdat<-ifelse(long_df$country_name == countrydiff, 1, 0)

long_df$povdat<-ifelse(long_df$country_name %in% countrydiff, 1, 0)

Additional information: the factor vector countrydiff contains unique
country names (Albania, Zimbabwe etc.), whereas long_df$country_name also
contains country names albeit not unique since it is in longform. The unique
names that appear in long_df$country_name is around 200.


Any suggestions?
Thanks in advance.

Best
Adel




--
View this message in context: http://r.789695.n4.nabble.com/ifelse-statement-with-two-vectors-of-different-length-tp4682401.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From b.rowlingson at lancaster.ac.uk  Wed Dec 18 16:42:12 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 18 Dec 2013 15:42:12 +0000
Subject: [R] 3D Surface plot
In-Reply-To: <8eefc7b84e0c422894b9da6acaf2c305@EX-1-HT0.lancs.local>
References: <8eefc7b84e0c422894b9da6acaf2c305@EX-1-HT0.lancs.local>
Message-ID: <CANVKczPA_fMfjqOj680Vq8J9H71xm5VNaASL5+gb0FM9pRoLxg@mail.gmail.com>

On Wed, Dec 18, 2013 at 2:52 PM, Simon Delay-Fortier
<simon.delay-fortier at mail.mcgill.ca> wrote:
> Hi everyone,
>
> I am a very new user of r (doing most of my previous stuff in vba). I am now mandated to draw a 3-d surface of a mine pit hole. I have all the location points (around 5000 points) of the pit in a CSV file under 3 column X, Y & Z. However, going from page to page on the web, I could not figure out how to code the figure. Something I noted is that most of the time X and Y  have to be in ascending order but the data I have are not (since they are finite points of the pit, if X gets  in ascending order, Y and Z are not). Also with the data, sometimes 2 rows fallowing each ohter have the same X and Y value with a different Z. That would be nice if things could be modeled with rgl function in order to have a rotating pit, but I would be glad to only have a 3d surface to start!

 How "3d" is your surface here? Because there's "3d" and there's
what's known as "2.5d"

 A 3d surface could be something like the surface of a sphere, or a
cave, or an overhanging cliff, whereas a 2.5d surface is a
single-valued function of x and y.

 If you have a true 3d surface then that's beyond me and involves
working out surface normals and all sorts of other clever stuff which
I don't know about.

 If its really 2.5d then yes, you do need to compute the values of
your surface on a grid in order to display it using rgl's surface3d
function. You can do this with some 2d interpolation code, such as
kriging or inverse distance weighting, using assorted packages such as
automap (which makes it easy but beware) or gstat.

 Since this seems to be a real-world geography problem, you might haul
over to the r-sig-geo mailing list and as there where the spatial guys
hang out.

Barry


From simon.delay-fortier at mail.mcgill.ca  Wed Dec 18 16:30:45 2013
From: simon.delay-fortier at mail.mcgill.ca (Simon Delay-Fortier)
Date: Wed, 18 Dec 2013 15:30:45 +0000
Subject: [R]  3D Surface Plot
Message-ID: <FCECE981A5D14046AA7444DC56070347116A9F@EXMBX2010-4.campus.MCGILL.CA>

Hi everyone,I am a very new user of r. I am now mandated to draw a 3-d surface (and possibly rotating) of a mine pit hole. I have all the location points (around 5000 points) of the pit in a CSV file under 3 column X, Y & Z. The fllowing gives a 3d scatter but i would like to have a surface.

attach(EASTPITCREST)
par(bg="grey6", col.lab="white", col.axis="white", col.main="white", col.sub="white")
scatterplot3d(X, Y, Z, color = "red", pch=19, main="Mine and Drilling Map")

I noted is that most of the time X and Y  have to be in ascending order but the data I have are not (since they are finite points of the pit, if X gets  in ascending order, Y and Z are not). Also with the data, sometimes 2 rows fallowing each ohter have the same X and Y value with a different Z.

Hope you can help.
Sincerly,

Simon Delay-Fortier

From sjkiss at gmail.com  Wed Dec 18 17:58:59 2013
From: sjkiss at gmail.com (Simon Kiss)
Date: Wed, 18 Dec 2013 11:58:59 -0500
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
Message-ID: <C3A34883-B12E-4A58-B460-25A3AC21A2CE@gmail.com>

Thanks! that works, more or less. Although the wonky behaviour of mapply that David pointed out is irritating. I tried deleting the $call item from the models produced and passing them to stargazer for reporting the results, but stargazer won't recognize the results even though the class is explicitly "glm lm".  
Does anyone know why mapply produces such weird results?
On 2013-12-18, at 3:29 AM, Dennis Murphy <djmuser at gmail.com> wrote:

> Hi:
> 
> Here's a way to generate a list of model objects. Once you have the
> list, you can write or call functions to extract useful pieces of
> information from each model object and use lapply() to call each list
> component recursively.
> 
> sample.df<-data.frame(var1=rbinom(50, size=1, prob=0.5),
>                      var2=rbinom(50, size=2, prob=0.5),
>                      var3=rbinom(50, size=3, prob=0.5),
>                      var4=rbinom(50, size=2, prob=0.5),
>                      var5=rbinom(50, size=2, prob=0.5))
> 
> # vector of x-variable names
> xvars <- names(sample.df)[-1]
> 
> # function to paste a variable x into a formula object and
> # then pass it to glm()
> f <- function(x)
> {
>    form <- as.formula(paste("var1", x, sep = " ~ "))
>    glm(form, data = sample.df)
> }
> 
> # Apply the function f to each variable in xvars
> modlist <- lapply(xvars, f)
> 
> To give you an idea of some of the things you can do with the list:
> 
> sapply(modlist, class)        # return class of each component
> lapply(modlist, summary)   # return the summary of each model
> 
> # combine the model coefficients into a two-column matrix
> do.call(rbind, lapply(modlist, coef))
> 
> 
> You'd probably want to rename the second column since the slopes are
> associated with different x variables.
> 
> Dennis
> 
> On Tue, Dec 17, 2013 at 5:53 PM, Simon Kiss <sjkiss at gmail.com> wrote:
>> I think I'm missing something.  I have a data frame that looks below.
>> sample.df<-data.frame(var1=rbinom(50, size=1, prob=0.5), var2=rbinom(50, size=2, prob=0.5), var3=rbinom(50, size=3, prob=0.5), var4=rbinom(50, size=2, prob=0.5), var5=rbinom(50, size=2, prob=0.5))
>> 
>> I'd like to run a series of univariate general linear models where var1 is always the dependent variable and each of the other variables is the independent. Then I'd like to summarize each in a table.
>> I've tried :
>> 
>> sample.formula=list(var1~var2, var1 ~var3, var1 ~var4, var1~var5)
>> mapply(glm, formula=sample.formula, data=list(sample.df), family='binomial')
>> 
>> And that works pretty well, except, I'm left with a matrix that contains all the information I need. I can't figure out how to use summary() properly on this information to usefully report that information.
>> 
>> Thank you for any suggestions.
>> 
>> *********************************
>> Simon J. Kiss, PhD
>> Assistant Professor, Wilfrid Laurier University
>> 73 George Street
>> Brantford, Ontario, Canada
>> N3T 2C9
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9
Cell: +1 905 746 7606


From sjkiss at gmail.com  Wed Dec 18 18:11:15 2013
From: sjkiss at gmail.com (Simon Kiss)
Date: Wed, 18 Dec 2013 12:11:15 -0500
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
Message-ID: <BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>

Dennis, how would your function be modified to allow it to be more flexible in future. 
I'm thinking like:
> f <- function(x='Dependent variable', y='List of Independent Variables', z='Data Frame')
> {
>    form <- as.formula(paste(x, y, sep = " ~ "))
>    glm(form, data =z)
> }

I tried that then using 
modlist <- lapply(xvars, f), but it didn't work. 

On 2013-12-18, at 3:29 AM, Dennis Murphy <djmuser at gmail.com> wrote:

> Hi:
> 
> Here's a way to generate a list of model objects. Once you have the
> list, you can write or call functions to extract useful pieces of
> information from each model object and use lapply() to call each list
> component recursively.
> 
> sample.df<-data.frame(var1=rbinom(50, size=1, prob=0.5),
>                      var2=rbinom(50, size=2, prob=0.5),
>                      var3=rbinom(50, size=3, prob=0.5),
>                      var4=rbinom(50, size=2, prob=0.5),
>                      var5=rbinom(50, size=2, prob=0.5))
> 
> # vector of x-variable names
> xvars <- names(sample.df)[-1]
> 
> # function to paste a variable x into a formula object and
> # then pass it to glm()
> f <- function(x)
> {
>    form <- as.formula(paste("var1", x, sep = " ~ "))
>    glm(form, data = sample.df)
> }
> 
> # Apply the function f to each variable in xvars
> modlist <- lapply(xvars, f)
> 
> To give you an idea of some of the things you can do with the list:
> 
> sapply(modlist, class)        # return class of each component
> lapply(modlist, summary)   # return the summary of each model
> 
> # combine the model coefficients into a two-column matrix
> do.call(rbind, lapply(modlist, coef))
> 
> 
> You'd probably want to rename the second column since the slopes are
> associated with different x variables.
> 
> Dennis
> 
> On Tue, Dec 17, 2013 at 5:53 PM, Simon Kiss <sjkiss at gmail.com> wrote:
>> I think I'm missing something.  I have a data frame that looks below.
>> sample.df<-data.frame(var1=rbinom(50, size=1, prob=0.5), var2=rbinom(50, size=2, prob=0.5), var3=rbinom(50, size=3, prob=0.5), var4=rbinom(50, size=2, prob=0.5), var5=rbinom(50, size=2, prob=0.5))
>> 
>> I'd like to run a series of univariate general linear models where var1 is always the dependent variable and each of the other variables is the independent. Then I'd like to summarize each in a table.
>> I've tried :
>> 
>> sample.formula=list(var1~var2, var1 ~var3, var1 ~var4, var1~var5)
>> mapply(glm, formula=sample.formula, data=list(sample.df), family='binomial')
>> 
>> And that works pretty well, except, I'm left with a matrix that contains all the information I need. I can't figure out how to use summary() properly on this information to usefully report that information.
>> 
>> Thank you for any suggestions.
>> 
>> *********************************
>> Simon J. Kiss, PhD
>> Assistant Professor, Wilfrid Laurier University
>> 73 George Street
>> Brantford, Ontario, Canada
>> N3T 2C9
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9
Cell: +1 905 746 7606


From gunter.berton at gene.com  Wed Dec 18 18:35:51 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 18 Dec 2013 09:35:51 -0800
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
	<BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
Message-ID: <CACk-te3YUO2-e=5S-XzpWGxZww+sm4ABDt6x3zsFox4x15XrAw@mail.gmail.com>

Folks:

1. Haven't closely followed the thread. I'm responding only to Simon's post.

2. ?formula ## Especially note the use of "."

So just make an appropriately constructed data frame for the data
argument of glm:

## example

> df <- data.frame(y=rnorm(9),x1=runif(9), x2=1:9)
> glm(y~.,data=df)
## y does not need to be in the data frame.

Another way to handle the OP is via substitute() or bquote(). I'll
leave that to thers to explain.

-- Bert




On Wed, Dec 18, 2013 at 9:11 AM, Simon Kiss <sjkiss at gmail.com> wrote:
> Dennis, how would your function be modified to allow it to be more flexible in future.
> I'm thinking like:
>> f <- function(x='Dependent variable', y='List of Independent Variables', z='Data Frame')
>> {
>>    form <- as.formula(paste(x, y, sep = " ~ "))
>>    glm(form, data =z)
>> }
>
> I tried that then using
> modlist <- lapply(xvars, f), but it didn't work.
>
> On 2013-12-18, at 3:29 AM, Dennis Murphy <djmuser at gmail.com> wrote:
>
>> Hi:
>>
>> Here's a way to generate a list of model objects. Once you have the
>> list, you can write or call functions to extract useful pieces of
>> information from each model object and use lapply() to call each list
>> component recursively.
>>
>> sample.df<-data.frame(var1=rbinom(50, size=1, prob=0.5),
>>                      var2=rbinom(50, size=2, prob=0.5),
>>                      var3=rbinom(50, size=3, prob=0.5),
>>                      var4=rbinom(50, size=2, prob=0.5),
>>                      var5=rbinom(50, size=2, prob=0.5))
>>
>> # vector of x-variable names
>> xvars <- names(sample.df)[-1]
>>
>> # function to paste a variable x into a formula object and
>> # then pass it to glm()
>> f <- function(x)
>> {
>>    form <- as.formula(paste("var1", x, sep = " ~ "))
>>    glm(form, data = sample.df)
>> }
>>
>> # Apply the function f to each variable in xvars
>> modlist <- lapply(xvars, f)
>>
>> To give you an idea of some of the things you can do with the list:
>>
>> sapply(modlist, class)        # return class of each component
>> lapply(modlist, summary)   # return the summary of each model
>>
>> # combine the model coefficients into a two-column matrix
>> do.call(rbind, lapply(modlist, coef))
>>
>>
>> You'd probably want to rename the second column since the slopes are
>> associated with different x variables.
>>
>> Dennis
>>
>> On Tue, Dec 17, 2013 at 5:53 PM, Simon Kiss <sjkiss at gmail.com> wrote:
>>> I think I'm missing something.  I have a data frame that looks below.
>>> sample.df<-data.frame(var1=rbinom(50, size=1, prob=0.5), var2=rbinom(50, size=2, prob=0.5), var3=rbinom(50, size=3, prob=0.5), var4=rbinom(50, size=2, prob=0.5), var5=rbinom(50, size=2, prob=0.5))
>>>
>>> I'd like to run a series of univariate general linear models where var1 is always the dependent variable and each of the other variables is the independent. Then I'd like to summarize each in a table.
>>> I've tried :
>>>
>>> sample.formula=list(var1~var2, var1 ~var3, var1 ~var4, var1~var5)
>>> mapply(glm, formula=sample.formula, data=list(sample.df), family='binomial')
>>>
>>> And that works pretty well, except, I'm left with a matrix that contains all the information I need. I can't figure out how to use summary() properly on this information to usefully report that information.
>>>
>>> Thank you for any suggestions.
>>>
>>> *********************************
>>> Simon J. Kiss, PhD
>>> Assistant Professor, Wilfrid Laurier University
>>> 73 George Street
>>> Brantford, Ontario, Canada
>>> N3T 2C9
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> Cell: +1 905 746 7606
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From nitisha999 at gmail.com  Wed Dec 18 18:06:40 2013
From: nitisha999 at gmail.com (Nitisha jha)
Date: Wed, 18 Dec 2013 22:36:40 +0530
Subject: [R] How to manipulate this data?
Message-ID: <CAOdnBQe51aUBWfTKVQNUHak35OZydN7gvKqxGHeHkEqENjs_sg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131218/191729ea/attachment.pl>

From therneau at mayo.edu  Wed Dec 18 18:53:05 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 18 Dec 2013 11:53:05 -0600
Subject: [R] estimating survival function from Cox model
In-Reply-To: <mailman.25.1387364407.19815.r-help@r-project.org>
References: <mailman.25.1387364407.19815.r-help@r-project.org>
Message-ID: <52B1E101.7010305@mayo.edu>

The standard error of the curve cannot be extracted from the summary information you have.
The variance is made up of two terms, one of which is a sum over all the death times, of a 
quadratic term per death time.  That term involves the variance matrix of the Cox model 
coefficients, the target value for x (the curve you want to calculate) and the average 
value of x at that time in the data set from which the Cox model was created.
   Just like linear regression, the se are higher when you predict "far from the center" 
of the original data set.

Terry Therneau


On 12/18/2013 05:00 AM, r-help-request at r-project.org wrote:
> Hi, I have some questions on how to estimate the survival function from a Cox model. I know how to do this in R using survfit().
>
>
> But let's say the model was done is another software, and I was only given the estimate of baseline cumulative hazard "A0(t=10)" at the specified time "t=10" (baseline cumulative hazard refers to when covariate X=0)and the beta estimate "b" for the covariate used in Cox model "X".
>
>
> So the survival function at time 10 for a given covariate value x can be calculated as:
>
> A(t=10|X=x) = exp(b*x)*A0(t=10) where A is cumulative hazard when X=x
> S(t=10|X=x) = exp(-A(t=10|X=x)) where S is survival function to be calculated
>
> Now I want to calculate confidence interval for S(t=10|X=x). I think I need to calculate the CI for cumulative hazard A(t=10|X=x) first and then exponentiate it to get CI for S, based on the relationship S = exp(-A).
>
> To get CI for A, I need to calculate the estimate of standard error of A. I know the other software can give me the standard error of A0, the baseline cumulative hazard. Based on the relationship A = exp(b*x)*A0, I guess I'll need the standard error for b. But how do I calculate the standard error for A based on standard errors for A0 and b?
>
> Any insights would be greatly appreciated!
>
> John


From smartpink111 at yahoo.com  Wed Dec 18 18:58:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Dec 2013 09:58:48 -0800 (PST)
Subject: [R] How to manipulate this data?
Message-ID: <1387389528.49555.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

Try:
dat1<- read.table(text="name Value
? abc BXR
? abc DHH
? abc DHK
? def DHK
? def DSL
? ghi DSL
? abc DSM
? def DSM
? ghi DSM
? def DSS
? ghi DSS
? ghi DST
? abc DIW
? abc DIL
? ghi DIL",sep="",header=TRUE,stringsAsFactors=FALSE) 


aggregate(name~Value,data=dat1,paste,collapse=" ")
#or
library(plyr)
?ddply(dat1,.(Value),summarize, name=lapply(list(Value),paste,collapse=" "))
A.K.


Hi, 

I want my output to be like this: 
?Value 
BXR 
abc 

?DHH abc 

?DHK abc def 
?DSL def ghi 
?DSM abc def ghi ?DSS def ghi 
?DST ghi 

?DIW abc 

?DIL abc ghi 

My input dataset is this with colnames name and Value: 

?name Value ?abc BXR ?abc DHH ?abc DHK ?def DHK ?def DSL ?ghi DSL ?abc DSM 
def DSM ?ghi DSM ?def DSS ?ghi DSS ?ghi DST ?abc DIW ?abc DIL ?ghi DIL 



From kinsham at verizon.net  Wed Dec 18 19:18:08 2013
From: kinsham at verizon.net (Chris Wilkinson)
Date: Wed, 18 Dec 2013 13:18:08 -0500
Subject: [R] Predicting response from fitted linear model with incomplete
 new sample data
Message-ID: <015001cefc1d$819ca160$84d5e420$@net>

I would like to predict a new response from a fitted linear model where the
new data is a single case with a missing value. My reading of the help on
predict() is inconclusive on whether this is possible.

Leaving out the missing value or setting it to NA both fail but differently,
see example code below.

> y <- runif(50)
> x1 <- rnorm(50)
> x2 <- rnorm(50)
> dat <- data.frame(y, x1, x2)
> mod <- lm(y~.,data=dat)
> summary(mod)

Call:
lm(formula = y ~ ., data = dat)
Residuals:
     Min       1Q   Median       3Q      Max 
-0.50467 -0.28997  0.01457  0.27970  0.47791 
Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.50098    0.04577  10.945  1.6e-14 ***
x1          -0.01762    0.04172  -0.422    0.675    
x2          -0.02753    0.04920  -0.560    0.578    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.3177 on 47 degrees of freedom
Multiple R-squared:  0.009301,  Adjusted R-squared:  -0.03286 
F-statistic: 0.2206 on 2 and 47 DF,  p-value: 0.8028

> predict(mod, newdata=data.frame(x1=0.1, x2=0.3))   #OK as expected
        1 
0.4909624 

> predict(mod, newdata=data.frame(x1=0.1))  # x2 missing
Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
object$xlevels) : 
  variable lengths differ (found for 'x2')
In addition: Warning message:
'newdata' had 1 row but variables found have 50 rows 
> predict(mod, newdata=data.frame(x1=0.1, x2=NA))   #x2=NA
Error: variable 'x2' was fitted with type "numeric" but type "logical" was
supplied
>

Thanks
Chris


From capricyg at yahoo.com  Wed Dec 18 20:08:47 2013
From: capricyg at yahoo.com (capricy gao)
Date: Wed, 18 Dec 2013 11:08:47 -0800 (PST)
Subject: [R] plot() function: color transparency
Message-ID: <1387393727.21144.YahooMailNeo@web125005.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131218/a7a20d16/attachment.pl>

From therneau at mayo.edu  Wed Dec 18 20:12:29 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 18 Dec 2013 13:12:29 -0600
Subject: [R] Coxph convergence
In-Reply-To: <52B1F282.8030709@mayo.edu>
References: <52B1F282.8030709@mayo.edu>
Message-ID: <52B1F39D.5050401@mayo.edu>

I'll re-enter the fray.
The data set is an example where coxph is incorrect; due to round off error it is treating
a 5 column rank 3 matrix as if it were rank 4.  This of course results in 0 digits of 
precision.
   Immediate fix, for the user, is to add "toler.chol= 1e-10" to their coxph call. It is
very likely that they will never ever have to change this value.

I will look into changing the default from its current value of .Machine$double.eps^.75.
However, I first have to check that this does not break anything else.  All "epsilon"
constants are a delicate dance between mutiple data sets, and anyone with long experience
in numerical anlysis will tell you that it is impossible to find constants that will work
for every data set.  This is true for linear models, logistic, Cox, ... you name it.

In summary:
I appreciate the example.
I'll add to my list of "nasty" problems.
I may be able to fix long term, and maybe not.  Changing the constant may break something 
else.
I've given a good short term fix.

Terry T.



On 12/18/2013 05:00 AM, r-help-request at r-project.org wrote:
> Your comprehension of the issue seem to be entirely wrong. Between r11513 and r11516, some tuning of internal parmeters were done, so the process of finding the rank of a singular matrix no longer converges (within the time/tolerance implicitly specified). There are warnings issued, but then there are misc warnings before and after (and one gets "desensitised" about them). Also the nature of the problem, which is to test for possibility of interactions - or lacking thereof -
>
> outcome ~ factor A + factor B + factor A x factor B
>
> or just extra terms in "outcome ~ factor A + factor B + ..." as an exploration of auxiliary effects, more often than not extra terms won't make
> any difference and the matrix involved just isn't the nicest to manipulate; it is in the nature of that kind of exploratory work.
>
> Professor Therneau replied that it is possible to get the older convergent behaviour by manual tuning of some of the convergence criteria parameters; I have responded that while that is possible, often one is simultaneously exploring many models with many possible auxiliary effects (and lacking thereof), manual tuning for each is neither feasible nor appropriate; and we sort of left it at that.


From murdoch.duncan at gmail.com  Wed Dec 18 20:22:45 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Dec 2013 14:22:45 -0500
Subject: [R] plot() function: color transparency
In-Reply-To: <1387393727.21144.YahooMailNeo@web125005.mail.ne1.yahoo.com>
References: <1387393727.21144.YahooMailNeo@web125005.mail.ne1.yahoo.com>
Message-ID: <52B1F605.1050404@gmail.com>

On 13-12-18 2:08 PM, capricy gao wrote:
> I found all the color transparency was defined with character color, or rgb color. What if I have number code and still try to modify the transparency?
>
> For example:
>
>> x=c(1:5)
>> color=c(2,2,3,4,5)
>> plot(x, col=color)
>> plot(x, col=color,pch=20)
>
> here I defined color by numbers, how can I modify the transparency?

See the examples for ?palette.

Duncan Murdoch


From r.turner at auckland.ac.nz  Wed Dec 18 21:04:19 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 19 Dec 2013 09:04:19 +1300
Subject: [R] Predicting response from fitted linear model with
 incomplete new sample data
In-Reply-To: <015001cefc1d$819ca160$84d5e420$@net>
References: <015001cefc1d$819ca160$84d5e420$@net>
Message-ID: <52B1FFC3.5070901@auckland.ac.nz>



As far as I can discern, your question makes no sense at all.

Suppose you *know* that y = 2 + 3*x1 + 4*x2.

Now what should you predict when x1 = 6 (with x2 "missing"/unknown)?

See fortune("magic").

On 19/12/13 07:18, Chris Wilkinson wrote:
> I would like to predict a new response from a fitted linear model where the
> new data is a single case with a missing value. My reading of the help on
> predict() is inconclusive on whether this is possible.
>
> Leaving out the missing value or setting it to NA both fail but differently,
> see example code below.
>
>> y <- runif(50)
>> x1 <- rnorm(50)
>> x2 <- rnorm(50)
>> dat <- data.frame(y, x1, x2)
>> mod <- lm(y~.,data=dat)
>> summary(mod)
> Call:
> lm(formula = y ~ ., data = dat)
> Residuals:
>       Min       1Q   Median       3Q      Max
> -0.50467 -0.28997  0.01457  0.27970  0.47791
> Coefficients:
>              Estimate Std. Error t value Pr(>|t|)
> (Intercept)  0.50098    0.04577  10.945  1.6e-14 ***
> x1          -0.01762    0.04172  -0.422    0.675
> x2          -0.02753    0.04920  -0.560    0.578
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Residual standard error: 0.3177 on 47 degrees of freedom
> Multiple R-squared:  0.009301,  Adjusted R-squared:  -0.03286
> F-statistic: 0.2206 on 2 and 47 DF,  p-value: 0.8028
>
>> predict(mod, newdata=data.frame(x1=0.1, x2=0.3))   #OK as expected
>          1
> 0.4909624
>
>> predict(mod, newdata=data.frame(x1=0.1))  # x2 missing
> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
> object$xlevels) :
>    variable lengths differ (found for 'x2')
> In addition: Warning message:
> 'newdata' had 1 row but variables found have 50 rows
>> predict(mod, newdata=data.frame(x1=0.1, x2=NA))   #x2=NA
> Error: variable 'x2' was fitted with type "numeric" but type "logical" was
> supplied


From 538280 at gmail.com  Wed Dec 18 21:07:10 2013
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 18 Dec 2013 13:07:10 -0700
Subject: [R] Using assign with mapply
In-Reply-To: <loom.20131216T163956-835@post.gmane.org>
References: <loom.20131206T200836-152@post.gmane.org>
	<loom.20131216T163956-835@post.gmane.org>
Message-ID: <CAFEqCdy2ci1MMKAU9fpRVS5Dr7S8Q1a9WmnOpomUu_A=-UJ2Ew@mail.gmail.com>

The take home message that you should be learning from your struggles
is to "Not Use The 'assign' Function!" and "Do Not Use Global
Variables Like This".

R has lists (and environments) that make working with objects that are
associated with each other much simpler and fits better with the
functional programming style of R.

For example you can create a list from your data frame quickly and
easily with code like:

mydata <- as.list(kkk$vals)
names(mydata) <- kkk$vars

or

mydata <- setNames( as.list(kkk$vals), kkk$vars )

then you will have you variables (with names) inside the list (mydata
in this example, but name it whatever you want)

This list can then be passed out of a function or otherwise used.

To access a specific variable by name you can do:

mydata$var1

or

mydata[['var2']]

or

with(mydata, var3)

but you can also do things like (and this is often a follow-up
question to questions like yours):

varname <- 'var3'
mydata[[ varname ]]

and you can also use lapply and sapply to do the same action on every
variable in your list:

sapply( mydata, function(x) x + 5 )

instead of having to loop through a bunch of global variables.

And if you want to save or delete these, now you just save or delete
the entire list rather than having to loop through the set of global
variables.

If you tell us more about how you want to use these variables we can
give more suggestions, but the main point is that in the long run you
will be happier learning to use lists (and possibly environments) in
place of trying to create and work with global variables like you
asked about.




On Mon, Dec 16, 2013 at 8:55 AM, Julio Sergio Santana
<juliosergio at gmail.com> wrote:
> Julio Sergio Santana <juliosergio <at> gmail.com> writes:
>
>>
>> I have a data frame whose first colum contains the names of the variables
>> and whose second colum contains the values to assign to them:
>>
>>    : kkk <- data.frame(vars=c("var1", "var2", "var3"),
>>                      vals=c(10, 20, 30), stringsAsFactors=F)
>>
>
> For those interested in the problem this is how I solved the problem:
>
>
> I want to have something similar to:
> #
> #   var1 <- 10
> #   var2 <- 20
> #   var3 <- 30
>
> my first trial was:
>
>    mapply(assign,  kkk$vars, kkk$vals)
> ## var1 var2 var3
> ## 10   20   30
> #
>
> This is, however, what I got:
>
>    var1
> ## Error: object 'var1' not found
>
> David Winsemius suggested me something similar to
>
>
>    mapply(assign,  kkk$vars, kkk$vals, MoreArgs = list(pos = 1))
> # or:
>    mapply(assign,  kkk$vars, kkk$vals, MoreArgs = list(envir = .GlobalEnv))
>
> var1
> ## [1] 10
>
> This almost works, but what if this construction is used inside a function?
>
>    example <- function () {
>       var1 <- 250
>       kkk <- data.frame(vars=c("var1", "var2", "var3"),
>                         vals=c(10, 20, 30), stringsAsFactors=F)
>      mapply(assign,  kkk$vars, kkk$vals, MoreArgs = list(pos = 1))
>      print (var2)
>      print (var1)
>    }
>
>    example()
> ## [1] 20
> ## [1] 250
>
> var1, which was defined inside the function, isn't modified
>
> To fix this, I defined the function as follows:
>
>    example <- function () {
>      var1 <- 250
>      kkk <- data.frame(vars=c("var1", "var2", "var3"),
>                        vals=c(10, 20, 30), stringsAsFactors=F)
>      mapply(assign,  kkk$vars, kkk$vals,
>             MoreArgs = list(pos = sys.frame(sys.nframe())))
>      # sys.nframe() is the number of the frame created inside the function
>      # and sys.frame() establishes it as the one assign uses to set values
>      print (var2)
>      print (var1)
>    }
>
>    example()
> ## [1] 20
> ## [1] 10
>
> And the purpose is got
>
> Thanks,
>
>   -Sergio.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From wdunlap at tibco.com  Wed Dec 18 21:07:18 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 18 Dec 2013 20:07:18 +0000
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
	<BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1E0F1@PA-MBX01.na.tibco.com>

Try something like the following.  Because lm() evaluates many
of its arguments in nonstandard ways, f() manipulates the call
and then evaluates it in the frame from which f() was called.
It also puts that environment on the formula that it creates so
it can refer to variables in that environment.
    f <- function (responseName, predictorNames, data, ..., envir = parent.frame())
    {
        call <- match.call()
        call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
            paste0("`", predictorNames, "`", collapse = " + ")))
                call[[1]] <- quote(glm) # 'f' -> 'glm'
        call$responseName <- NULL # omit responseName=
        call$predictorNames <- NULL # omit 'predictorNames='
                eval(call, envir = envir)
    }
as in
    z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("carb", preds, data=mtcars, family=poisson))
    lapply(z, summary)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Simon Kiss
> Sent: Wednesday, December 18, 2013 9:11 AM
> To: Dennis Murphy
> Cc: r-help at r-project.org
> Subject: Re: [R] Help using mapply to run multiple models
> 
> Dennis, how would your function be modified to allow it to be more flexible in future.
> I'm thinking like:
> > f <- function(x='Dependent variable', y='List of Independent Variables', z='Data Frame')
> > {
> >    form <- as.formula(paste(x, y, sep = " ~ "))
> >    glm(form, data =z)
> > }
> 
> I tried that then using
> modlist <- lapply(xvars, f), but it didn't work.
> 
> On 2013-12-18, at 3:29 AM, Dennis Murphy <djmuser at gmail.com> wrote:
> 
> > Hi:
> >
> > Here's a way to generate a list of model objects. Once you have the
> > list, you can write or call functions to extract useful pieces of
> > information from each model object and use lapply() to call each list
> > component recursively.
> >
> > sample.df<-data.frame(var1=rbinom(50, size=1, prob=0.5),
> >                      var2=rbinom(50, size=2, prob=0.5),
> >                      var3=rbinom(50, size=3, prob=0.5),
> >                      var4=rbinom(50, size=2, prob=0.5),
> >                      var5=rbinom(50, size=2, prob=0.5))
> >
> > # vector of x-variable names
> > xvars <- names(sample.df)[-1]
> >
> > # function to paste a variable x into a formula object and
> > # then pass it to glm()
> > f <- function(x)
> > {
> >    form <- as.formula(paste("var1", x, sep = " ~ "))
> >    glm(form, data = sample.df)
> > }
> >
> > # Apply the function f to each variable in xvars
> > modlist <- lapply(xvars, f)
> >
> > To give you an idea of some of the things you can do with the list:
> >
> > sapply(modlist, class)        # return class of each component
> > lapply(modlist, summary)   # return the summary of each model
> >
> > # combine the model coefficients into a two-column matrix
> > do.call(rbind, lapply(modlist, coef))
> >
> >
> > You'd probably want to rename the second column since the slopes are
> > associated with different x variables.
> >
> > Dennis
> >
> > On Tue, Dec 17, 2013 at 5:53 PM, Simon Kiss <sjkiss at gmail.com> wrote:
> >> I think I'm missing something.  I have a data frame that looks below.
> >> sample.df<-data.frame(var1=rbinom(50, size=1, prob=0.5), var2=rbinom(50, size=2,
> prob=0.5), var3=rbinom(50, size=3, prob=0.5), var4=rbinom(50, size=2, prob=0.5),
> var5=rbinom(50, size=2, prob=0.5))
> >>
> >> I'd like to run a series of univariate general linear models where var1 is always the
> dependent variable and each of the other variables is the independent. Then I'd like to
> summarize each in a table.
> >> I've tried :
> >>
> >> sample.formula=list(var1~var2, var1 ~var3, var1 ~var4, var1~var5)
> >> mapply(glm, formula=sample.formula, data=list(sample.df), family='binomial')
> >>
> >> And that works pretty well, except, I'm left with a matrix that contains all the
> information I need. I can't figure out how to use summary() properly on this information
> to usefully report that information.
> >>
> >> Thank you for any suggestions.
> >>
> >> *********************************
> >> Simon J. Kiss, PhD
> >> Assistant Professor, Wilfrid Laurier University
> >> 73 George Street
> >> Brantford, Ontario, Canada
> >> N3T 2C9
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> Cell: +1 905 746 7606
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Wed Dec 18 21:29:20 2013
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 18 Dec 2013 13:29:20 -0700
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <CAEEpX7q4MTHCfMUTXWGkgcbTjKjN1oGMTjBxHVAFDHXx9tq07g@mail.gmail.com>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
	<52AE39F7.8000702@gmail.com>
	<CCE952776B6679469977532BD863C39C7E7AF623@Lewis.autuni.aut.ac.nz>
	<CAEEpX7q4MTHCfMUTXWGkgcbTjKjN1oGMTjBxHVAFDHXx9tq07g@mail.gmail.com>
Message-ID: <CAFEqCdx5JQfPTQOk+APxYMTbPq-BrnGiYDhYrNe6nOnA0Q1=tg@mail.gmail.com>

Another option to consider if your goal is to create a word file with
1 or more plots in it (possibly intermingled with text and other
output) is to use the knitr or pander packages (or odfWeave or sweave
or ...).  This way you can create a script (or template file) that
sets a couple of options up front (width, height, resolution, file
type) and creates the graphs (and possibly other output to be
included), run the script (and maybe the external program pandoc) and
you have a word document with the plots without needing to copy/paste
or import.

This becomes a real time saver when the client comes back to you and
says there was a typo in the data, the 13 on line 27 needs to be an 18
and can you rerun everything with that change?  (if something along
those lines has not happened to you yet, it will).

On Mon, Dec 16, 2013 at 9:33 PM, david hamer <j.david.hamer at gmail.com> wrote:
> Thanks to everyone for the helpful suggestions.   --   David.
>
>
> On Mon, Dec 16, 2013 at 7:23 PM, Steve Taylor <steve.taylor at aut.ac.nz>wrote:
>
>> > From: Duncan Murdoch...
>>
>> > Don't use a bitmap format (png).
>> I disagree.  Each vector format comes with its own problems.
>>
>> > Don't produce your graph in one format (screen display), then convert to
>> > another (png).  Open the device in the format you want for the final
>> file.
>> Agreed.
>>
>> > Use a vector format for output.
>> Why?  Sure, that's good advice in the ideal (pdflatex) world, but not
>> necessarily the best of advice for Word users.
>>
>> > I don't know what kinds Word supports, but
>> > EPS or PDF would likely be best; if it can't read those, then Windows
>> metafile
>> > (via windows() to open the device) would be best.
>> None of these works well, if at all, in my experience with Word.
>>
>> > Don't use Word.
>> Some of us don't really have a choice.
>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From bdecicco2001 at yahoo.com  Wed Dec 18 22:43:46 2013
From: bdecicco2001 at yahoo.com (Barry DeCicco)
Date: Wed, 18 Dec 2013 13:43:46 -0800 (PST)
Subject: [R] Problems with Installing R ('failure to expand shell folder
	constant "userdocs")
Message-ID: <1387403026.40670.YahooMailNeo@web163004.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131218/8cd8a852/attachment.pl>

From capricyg at yahoo.com  Wed Dec 18 23:23:36 2013
From: capricyg at yahoo.com (capricy gao)
Date: Wed, 18 Dec 2013 14:23:36 -0800 (PST)
Subject: [R] plot() function: color transparency
In-Reply-To: <52B1F605.1050404@gmail.com>
References: <1387393727.21144.YahooMailNeo@web125005.mail.ne1.yahoo.com>
	<52B1F605.1050404@gmail.com>
Message-ID: <1387405416.51556.YahooMailNeo@web125005.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131218/1c983c5c/attachment.pl>

From cscherb1 at gwdg.de  Wed Dec 18 23:35:21 2013
From: cscherb1 at gwdg.de (Christoph Scherber)
Date: Wed, 18 Dec 2013 23:35:21 +0100
Subject: [R] plot() function: color transparency
In-Reply-To: <1387405416.51556.YahooMailNeo@web125005.mail.ne1.yahoo.com>
References: <1387393727.21144.YahooMailNeo@web125005.mail.ne1.yahoo.com>	<52B1F605.1050404@gmail.com>
	<1387405416.51556.YahooMailNeo@web125005.mail.ne1.yahoo.com>
Message-ID: <52B22329.7040006@gwdg.de>

you will need to specify colours as RGB values and then set transparency 
via the "alpha" argument.

e.g.: color=rgb(0,0,0,alpha=0.3)

# will  give black (0,0,0) and a transparency of 30%.

Best wishes
Christoph


On 18/12/2013 23:23, capricy gao wrote:
> I checked as you suggested. However, I found that the number in those functions are the number of colors. In contrast, my number here means a specific color, for example, 2 in my code means "red", 3 in my code means "green"....
>
>
>
>
>
> On Wednesday, December 18, 2013 1:18 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>   
> On 13-12-18 2:08 PM, capricy gao wrote:
>
>> I found all the color transparency was defined with character color, or rgb color. What if I have number code and still try to modify the transparency?
>>
>> For example:
>>
>>> x=c(1:5)
>>> color=c(2,2,3,4,5)
>>> plot(x, col=color)
>>> plot(x, col=color,pch=20)
>> here I defined color by numbers, how can I modify the transparency?
> See the examples for ?palette.
>
> Duncan Murdoch
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kw.stat at gmail.com  Wed Dec 18 23:46:46 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 18 Dec 2013 16:46:46 -0600
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <CCE952776B6679469977532BD863C39C7E7AF5CB@Lewis.autuni.aut.ac.nz>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
	<52AE39F7.8000702@gmail.com>
	<001101cefa6c$a8fb5a60$faf20f20$@tamu.edu>
	<3D6A905E-B6A6-4FA9-8999-40F35F494540@me.com>
	<CCE952776B6679469977532BD863C39C7E7AF5CB@Lewis.autuni.aut.ac.nz>
Message-ID: <CAKFxdiTOMPx4Ki3Ak1QTpUE1HNh8F=BAM-hZr8H14Pku2bTGvg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131218/34e18822/attachment.pl>

From richardkwock at gmail.com  Wed Dec 18 23:46:48 2013
From: richardkwock at gmail.com (Richard Kwock)
Date: Wed, 18 Dec 2013 14:46:48 -0800
Subject: [R] plot() function: color transparency
In-Reply-To: <52B22329.7040006@gwdg.de>
References: <1387393727.21144.YahooMailNeo@web125005.mail.ne1.yahoo.com>
	<52B1F605.1050404@gmail.com>
	<1387405416.51556.YahooMailNeo@web125005.mail.ne1.yahoo.com>
	<52B22329.7040006@gwdg.de>
Message-ID: <CAJU8Py38z4NdEm=LmcdrqzN4zv+1NdzLMGTgCvq0a7CnCrWobg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131218/17eab1ac/attachment.pl>

From murdoch.duncan at gmail.com  Thu Dec 19 01:34:07 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Dec 2013 19:34:07 -0500
Subject: [R] plot() function: color transparency
In-Reply-To: <1387405416.51556.YahooMailNeo@web125005.mail.ne1.yahoo.com>
References: <1387393727.21144.YahooMailNeo@web125005.mail.ne1.yahoo.com>
	<52B1F605.1050404@gmail.com>
	<1387405416.51556.YahooMailNeo@web125005.mail.ne1.yahoo.com>
Message-ID: <52B23EFF.6070208@gmail.com>

On 13-12-18 5:23 PM, capricy gao wrote:
> I checked as you suggested. However, I found that the number in those
> functions are the number of colors. In contrast, my number here means a
> specific color, for example, 2 in my code means "red", 3 in my code
> means "green"....
>

You didn't read very carefully.

Duncan Murdoch

>
>
> On Wednesday, December 18, 2013 1:18 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> On 13-12-18 2:08 PM, capricy gao wrote:
>
>  > I found all the color transparency was defined with character color,
> or rgb color. What if I have number code and still try to modify the
> transparency?
>  >
>  > For example:
>  >
>  >> x=c(1:5)
>  >> color=c(2,2,3,4,5)
>  >> plot(x, col=color)
>  >> plot(x, col=color,pch=20)
>  >
>  > here I defined color by numbers, how can I modify the transparency?
>
>
> See the examples for ?palette.
>
> Duncan Murdoch
>
>
>
>


From marongiu.luigi at gmail.com  Thu Dec 19 01:18:50 2013
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Thu, 19 Dec 2013 00:18:50 +0000
Subject: [R] plot different groups as factors
Message-ID: <CAMk+s2TGB4aCvbHPGvj2GK4N30DEchqD7q01U933UGbhc1iLLw@mail.gmail.com>

dear all,
i would like to plot the value of different response groups. when i simply
use  plot(y ~ x) i obtain a series of boxplots. i would rather use dots. i
also tried with stripchart(y ~ x), which gives better results but does not
place properly the labels since place them alphabetically.
in addition i actually have 6 response groups: 3 classes (low, medium,
high) and 2 sampling time (12 and 18 months).
how can i generate these individual groups and plot them in the correct
order (low, medium, high and 12, 18)? i believe is something to do with the
factors but i don't know how to implement them.
what i am looking for is to generate a figure such as the one i sketched in
the attached file. i also attached a dataframe version of my data. the
vectors containing the same data are:
time <-c(  18,    18,    18,    18,    18,    18,    18,    18,    18,
18,    18,    18,    18,    18,    18,    18,    18,    18,    18,
18,    18,    18,    18,    18,    18,    18,    18,    18,    12,
12,    12,    12,    12,    12,    12,    12,    12,    12,    12,
12,    12,    12,    12,    12,    12,    12,    12,    12,    12,
12,    12,    12,    12,    12,    12,    12,    12,    12,    12,
12,    12,    12,    12,    12,    12,    12)
class <-c(    medium,    medium,    medium,    medium,    medium,
medium,    medium,    medium,    medium,    medium,    medium,
medium,    medium,    medium,    high,    high,    high,    high,
high,    high,    high,    low,    low,    low,    low,    low,    low,
low,    medium,    medium,    medium,    medium,    medium,    medium,
medium,    medium,    medium,    medium,    medium,    medium,
medium,    medium,    medium,    medium,    medium,    medium,    high,
high,    high,    high,    high,    high,    high,    high,    high,
high,    low,    low,    low,    low,    low,    low,    low,    low,
low,    low)
value <-c(    2.92,    0.01,    0.36,    3.16,    0.99,    0.38,
0.01,    5.1,    0.04,    0.01,    1.33,    4.13,    0.15,    0.15,
14.18,    4290.14,    26.8,    5.33,    17.58,    14.29,    248.5,
0.01,    0,    0,    0,    0,    0,    0,    0.151395382,
5.327863403,    5.10096383,    1.32567787,    4.352404124,
0.458606982,    2.915908912,    0.011996374,    0.364710382,
0.033016026,    3.161701212,    0.381564497,    0.010971385,
0.035646472,    0.014781805,    4.129708296,    0.153094117,
0.018497847,    15.09178491,    17.58393041,    14.17643928,
4290.143561,    26.79730719,    294.6367065,    14.2888441,
248.495231,    209.3131795,    2014.506722,    0.010751273,
0.002325138,    0.000637473,    0.003984336,    0.006018154,
0.003620907,    0.0000745936,    0.000142311,    0.002460417,
0.001280189)

Thank you very much for any help you could provide!
regards
Luigi
-------------- next part --------------
	time	class	value
1	18	medium	2.92
2	18	medium	0.01
3	18	medium	0.36
4	18	medium	3.16
5	18	medium	0.99
6	18	medium	0.38
7	18	medium	0.01
8	18	medium	5.1
9	18	medium	0.04
10	18	medium	0.01
11	18	medium	1.33
12	18	medium	4.13
13	18	medium	0.15
14	18	medium	0.15
15	18	high	14.18
16	18	high	"4,290.14"
17	18	high	26.8
18	18	high	5.33
19	18	high	17.58
20	18	high	14.29
21	18	high	248.5
22	18	low	0.01
23	18	low	0
24	18	low	0
25	18	low	0
26	18	low	0
27	18	low	0
28	18	low	0
29	12	medium	0.151395382
30	12	medium	5.327863403
31	12	medium	5.10096383
32	12	medium	1.32567787
33	12	medium	4.352404124
34	12	medium	0.458606982
35	12	medium	2.915908912
36	12	medium	0.011996374
37	12	medium	0.364710382
38	12	medium	0.033016026
39	12	medium	3.161701212
40	12	medium	0.381564497
41	12	medium	0.010971385
42	12	medium	0.035646472
43	12	medium	0.014781805
44	12	medium	4.129708296
45	12	medium	0.153094117
46	12	medium	0.018497847
47	12	high	15.09178491
48	12	high	17.58393041
49	12	high	14.17643928
50	12	high	4290.143561
51	12	high	26.79730719
52	12	high	294.6367065
53	12	high	14.2888441
54	12	high	248.495231
55	12	high	209.3131795
56	12	high	2014.506722
57	12	low	0.010751273
58	12	low	0.002325138
59	12	low	0.000637473
60	12	low	0.003984336
61	12	low	0.006018154
62	12	low	0.003620907
63	12	low	7.46E-05
64	12	low	0.000142311
65	12	low	0.002460417
66	12	low	0.001280189

From smartpink111 at yahoo.com  Wed Dec 18 21:33:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Dec 2013 12:33:58 -0800 (PST)
Subject: [R] binary symmetric matrix combination
In-Reply-To: <CAEBi+_kKjtF7VQuqDAe9EYwYcb+irHGuvJOgT4PCxyRJ6mZPKQ@mail.gmail.com>
References: <18616451.21640.1379526255404.JavaMail.nabble@joe.nabble.com>	<CAEBi+_k-_oJg+Rq_A6V54MYm+Y8RdQRK+A9zjL=oVwsY-SOg3g@mail.gmail.com>	<1379862177.44860.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<CAEBi+_ng8mp=16tOTABCAbx7jCLUCONg8tzSKs0s_a_HE5M6fA@mail.gmail.com>	<1379887508.79364.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<CAEBi+_m5a2RaWKUEuBbmbUHbmXhurF8X3RN_Xx+1G2eqj3CYjg@mail.gmail.com>	<1379895577.95284.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAEBi+_kKjtF7VQuqDAe9EYwYcb+irHGuvJOgT4PCxyRJ6mZPKQ@mail.gmail.com>
Message-ID: <1387398838.30801.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
You could try:
Either:

dat1 <- read.table("Test.txt",header=TRUE)
dim(dat1)
#[1] 4735 4735
dat2 <- read.table("1991res.txt",header=TRUE)
dim(dat2)
#[1] 574 574
m1 <- as.matrix(dat1)
m2 <- as.matrix(dat2)
library(data.table)
d1 <- data.table(Name1=as.vector(outer(rownames(m1),colnames(m1),paste0)),value1=as.vector(m1),key='Name1')
d2 <- data.table(Name1=as.vector(outer(rownames(m2),colnames(m2),paste0)),value2=as.vector(m2),key='Name1')
res <- d2[d1]
res1 <- as.data.frame(res)
res1[,3][!is.na(res1[,2])] <- res1[,2][!is.na(res1[,2])]
vec1 <- as.vector(outer(rownames(m1),colnames(m1),paste0))
res2 <- res1[match(vec1,res1[,1]),-2]
res3 <- matrix(res2[,2],dimnames=list(rownames(m1),colnames(m1)),ncol=ncol(m1))


#or

vec1 <- paste0(rownames(m1)[row(m1)],colnames(m1)[col(m1)])
?vec2 <- paste0(rownames(m2)[row(m2)],colnames(m2)[col(m2)])
indx <- match(vec1,vec2)
indx1 <- indx[!is.na(indx)]
?indx2 <- match(vec2,vec1)
indx2N <- indx2[!is.na(indx2)]
?m1[indx2N] <- m2[indx1]



A.K.


On Monday, December 16, 2013 1:54 PM, Elio Shijaku <selius at gmail.com> wrote:

Hi Arun,

I hope you remember me. You helped me build several symmetrical matrices in R. I have one question though. I have now build all the matrices and I want to combine each of them to a larger one. To make the matter simpler to understand, I am attaching the text version of both files. What I would like is to merge the contents of 1991res (574x574 symmetric matrix) into the Test file (4703x4703, symmetric matrix which includes the row names of the 1991res. 

Could you help me by showing the steps I should take to merge the matrices?

Thank you in advance and sorry for disturbing.

Best,

Elio




On Mon, Sep 23, 2013 at 2:19 AM, arun <smartpink111 at yahoo.com> wrote:

Hi Elio,
>
>There was only one matrix with that error.? Glad you were able to correct it.
>
>I sent an linkedin request to you.
>Regards
>Arun
>
>
>
>
>
>
>
>________________________________
>From: Elio Shijaku <selius at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Sent: Sunday, September 22, 2013 7:21 PM
>
>Subject: Re: binary symmetric matrix combination
>
>
>
>Hi Arun,
>
>You are very right, that mistake which i corrected by removal fixed the issue, now the matrix works perfectly.
>
>Many thanks for all your help, please if you are in LinkedIn, I would be delighted to add you as a friend.
>
>Here is my profile in case you're interested:
>es.linkedin.com/pub/elio-shijaku/11/b7b/147/
>
>Hopefully I can "disturb" you in case I have further questions, I am just learning R and everything is new to me.
>
>All the best,
>
>Elio
>
>
>
>
>On Mon, Sep 23, 2013 at 12:05 AM, arun <smartpink111 at yahoo.com> wrote:
>
>Hi,
>>Actually, you have duplicate names.
>>
>>
>>"p226 p226 s112"?
>>
>>What do you need to do in those situations?? Looks like it is a mistake in the file.
>>
>>
>>
>>
>>________________________________
>>From: Elio Shijaku <selius at gmail.com>
>>To: arun <smartpink111 at yahoo.com>
>>Sent: Sunday, September 22, 2013 5:41 PM
>>
>>Subject: Re: binary symmetric matrix combination
>>
>>
>>
>>Hi Arun,
>>
>>Here is the file, I tried many options, once I enter the command
>>
>>lst2<- lapply(lst1[lapply(lst1,length)>0],function(x) as.matrix(read.table(text=x,row.name=1)))
>>
>>
>>I get:
>>
>>Error in read.table(text = x, row.name = 1) :??duplicate 'row.names' are not allowed
>>
>>
>>Any idea? Thanks a lot for the help.
>>
>>
>>Elio
>>
>>
>>
>>
>>
>>On Sun, Sep 22, 2013 at 5:02 PM, arun <smartpink111 at yahoo.com> wrote:
>>
>>Hi Elio,
>>>Check the new text file.? I used the first line:
>>>
>>>lines1<-str_trim(gsub("\t"," ",readLines("file.txt")))
>>>because the file was "\t" separated
>>>
>>>In the new file, it could be just space separated.? So, you may only need:
>>>lines1<- readLines("file.txt")
>>>
>>>If possible, could you email me the file.? I can take a look into it.
>>>A.K.
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>________________________________
>>>
>>>From: Elio Shijaku <selius at gmail.com>
>>>To: arun <smartpink111 at yahoo.com>
>>>Sent: Sunday, September 22, 2013 7:55 AM
>>>
>>>Subject: Re: binary symmetric matrix combination
>>>
>>>
>>>
>>>
>>>Hi Arun,
>>>
>>>I am replying to this e-mail address to not break the forum's rules. Everything worked great. However, when I use another text file called "file", I use the commands you gave me but I get this problem:
>>>
>>>library(stringr)
>>>
>>>lines1<-str_trim(gsub("\t"," ",readLines("file.txt")))
>>>?lst1<-lapply(split(lines1,
>>>cumsum(lines1=="")),function(x) x[x!=""])
>>>
>>>
>>>lst2<- lapply(lst1[lapply(lst1,length)>0],function(x) as.matrix(read.table(text=x,row.names=1)))
>>>
>>>Error in read.table(text = x, row.names = 1) :??duplicate 'row.names' are not allowed
>>>
>>>#I cannot then continue with the rest:
>>>
>>>
>>>names(lst2)<- paste0("m",seq_along(lst2))
>>>dat<- do.call(rbind,lapply(names(lst2),function(x) {x1<- lst2[[x]]; cbind(expand.grid(rep(list(colnames(x1)),2),stringsAsFactors=FALSE),value=as.vector(x1))}))
>>>library(reshape2)
>>>res<- dcast(dat,Var1~Var2,value.var="value",sum)
>>>?row.names(res)<- res[,1]
>>>?res<- as.matrix(res[,-1])
>>>?dim(res)
>>>
>>>
>>>Any idea on why such problem?
>>>
>>>Thanks yet again
>>>
>>>
>>>
>>>
>>>On Wed, Sep 18, 2013 at 7:44 PM, <smartpink111 at yahoo.com> wrote:
>>>
>>>Hi,
>>>>Forgot to comment about the second Error.
>>>>The error suggests 'Libro3.txt' is not found in your working directory. ?Change your working directory to where the file is present or copy and paste the file in the working directory. ?If you want to change the WD, use:
>>>>?setwd().
>>>>
>>>>
>>>>
>>>><quote author='supernovartis'>
>>>>Hi Arun,
>>>>
>>>>Thanks for the promt reply.
>>>>
>>>>Yes the data is tab delimited. When I tried to use the command:
>>>>
>>>>> lst1<-lapply(split(lines1,cumsum(lines1=="")),function(x)
>>>>> as.matrix(read.table(text=x[x!=""],sep="",row.names=1)))
>>>>
>>>>I get:
>>>>
>>>>Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
>>>>:
>>>>? line 1 did not have 6 elements
>>>>
>>>>I tried the second command: ?> lines2<- gsub("\t","",
>>>>readLines("Libro3.txt"))
>>>>
>>>>I get:
>>>>
>>>>Error in file(con, "r") : cannot open the connection
>>>>In addition: Warning message:
>>>>In file(con, "r") :
>>>>? cannot open file 'Libro3.txt': No such file or directory
>>>>
>>>>Obviously, the file is not in R directory, any option how to read it from
>>>>the desktop?
>>>>
>>>>Any help?
>>>>
>>>>Thanks again
>>>></quote>
>>>>Quoted from:
>>>>http://r.789695.n4.nabble.com/binary-symmetric-matrix-combination-tp4675440p4676437.html
>>>>
>>>>
>>>>_____________________________________
>>>>Sent from http://r.789695.n4.nabble.com
>>>>
>>>>
>>>
>>
>


From dx5212 at gmail.com  Wed Dec 18 22:12:38 2013
From: dx5212 at gmail.com (dx 5212)
Date: Wed, 18 Dec 2013 13:12:38 -0800
Subject: [R] assessment of validity of PLS predictions
Message-ID: <CABe3x7=1XGCqH-VgcsSeWFtsoh18XWTkc-Dc=Ju=V-VJToc5Tw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131218/b7c11a65/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Thu Dec 19 02:17:11 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 18 Dec 2013 17:17:11 -0800
Subject: [R] read ".slk" file
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA7396@SRVEXCHMBX.precheza.cz>
References: <CAN_e6XvqBmk26ubOP-852LwGDEx_PgY4=Z0Fu6XakWVffFBDaQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA7396@SRVEXCHMBX.precheza.cz>
Message-ID: <3f471806-4b5d-4b14-a95b-f5b1209cd891@email.android.com>

I suspect this could be SYLK format, a very old spreadsheet exchange format. The only hit that I get from RSiteSearch("sylk") is read.gnumeric.sheet, which depends on an external program "ssconvert" to extract CSV. In the plus department, it is a text-based format that has been implemented numerous times so you could roll your own reader based on open source code. In the minus department, there is no published specification, so if your files have quirks then you will have to work around them one by one, and it really is like Latin... a dead language.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Hi
>
>Extension does not specify file format. You can rename any file with
>any extension without changing its nature. However slk stays for
>symbolic link and therefore it just brings actual file to Excel. 
>
>Maybe you could start to play with
>
>http://stat.ethz.ch/R-manual/R-devel/library/base/html/files.html
>
>Regards
>Petr
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Santosh
>> Sent: Tuesday, December 17, 2013 12:11 AM
>> To: r-help
>> Subject: [R] read ".slk" file
>> 
>> Dear Rxperts..
>> 
>> I recently received a data file with the extension ".slk". If I save
>> the file as MS Excel file, I am able to read in R without issues.  Is
>> it possible to read this ".slk" file without converting into another
>R-
>> readable data format?
>> 
>> Regards,
>> Santosh
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Thu Dec 19 02:42:19 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 19 Dec 2013 12:42:19 +1100
Subject: [R] plot different groups as factors
In-Reply-To: <CAMk+s2TGB4aCvbHPGvj2GK4N30DEchqD7q01U933UGbhc1iLLw@mail.gmail.com>
References: <CAMk+s2TGB4aCvbHPGvj2GK4N30DEchqD7q01U933UGbhc1iLLw@mail.gmail.com>
Message-ID: <52B24EFB.1090505@bitwrit.com.au>

On 12/19/2013 11:18 AM, Luigi Marongiu wrote:
> dear all,
> i would like to plot the value of different response groups. when i simply
> use  plot(y ~ x) i obtain a series of boxplots. i would rather use dots. i
> also tried with stripchart(y ~ x), which gives better results but does not
> place properly the labels since place them alphabetically.
> in addition i actually have 6 response groups: 3 classes (low, medium,
> high) and 2 sampling time (12 and 18 months).
> how can i generate these individual groups and plot them in the correct
> order (low, medium, high and 12, 18)? i believe is something to do with the
> factors but i don't know how to implement them.

Hi Luigi,
Perhaps you want something like this:

lmdf<-read.table(text="time class value
18 medium 2.92
18 medium 0.01
18 medium 0.36
18 medium 3.16
18 medium 0.99
18 medium 0.38
18 medium 0.01
18 medium 5.1
18 medium 0.04
18 medium 0.01
18 medium 1.33
18 medium 4.13
18 medium 0.15
18 medium 0.15
18 high 14.18
18 high 4290.14
18 high 26.8
18 high 5.33
18 high 17.58
18 high 14.29
18 high 248.5
18 low 0.01
18 low 0
18 low 0
18 low 0
18 low 0
18 low 0
18 low 0
12 medium 0.151395382
12 medium 5.327863403
12 medium 5.10096383
12 medium 1.32567787
12 medium 4.352404124
12 medium 0.458606982
12 medium 2.915908912
12 medium 0.011996374
12 medium 0.364710382
12 medium 0.033016026
12 medium 3.161701212
12 medium 0.381564497
12 medium 0.010971385
12 medium 0.035646472
12 medium 0.014781805
12 medium 4.129708296
12 medium 0.153094117
12 medium 0.018497847
12 high 15.09178491
12 high 17.58393041
12 high 14.17643928
12 high 4290.143561
12 high 26.79730719
12 high 294.6367065
12 high 14.2888441
12 high 248.495231
12 high 209.3131795
12 high 2014.506722
12 low 0.010751273
12 low 0.002325138
12 low 0.000637473
12 low 0.003984336
12 low 0.006018154
12 low 0.003620907
12 low 7.46E-05
12 low 0.000142311
12 low 0.002460417
12 low 0.001280189",header=TRUE)

# get the factor levels in the correct order
lmdf$class<-factor(lmdf$class,levels=c("low","medium","high"))
library(plotrix)
brkdn.plot("value","class","time",lmdf,col=2:4)
legend(14,1200,c("low","medium","high"),col=2:4,lty=1)

Jim


From lydiakeppler at gmail.com  Thu Dec 19 03:24:10 2013
From: lydiakeppler at gmail.com (Lydia Keppler)
Date: Thu, 19 Dec 2013 15:24:10 +1300
Subject: [R] Welcome to the "R-help" mailing list
In-Reply-To: <mailman.305.1387419759.4546.r-help@r-project.org>
References: <mailman.305.1387419759.4546.r-help@r-project.org>
Message-ID: <CAJecWfwWpOthSAS+jKQ9qnsBSe3+zW3yBJmHNMfqgbCjzYVWCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/1813a1f2/attachment.pl>

From jholtman at gmail.com  Thu Dec 19 03:48:27 2013
From: jholtman at gmail.com (jim holtman)
Date: Wed, 18 Dec 2013 21:48:27 -0500
Subject: [R] Welcome to the "R-help" mailing list
In-Reply-To: <CAJecWfwWpOthSAS+jKQ9qnsBSe3+zW3yBJmHNMfqgbCjzYVWCA@mail.gmail.com>
References: <mailman.305.1387419759.4546.r-help@r-project.org>
	<CAJecWfwWpOthSAS+jKQ9qnsBSe3+zW3yBJmHNMfqgbCjzYVWCA@mail.gmail.com>
Message-ID: <CAAxdm-6ucxQetnHJYXan_mgoHiiwOAkE6_k=J8ikTaVBXdQE9w@mail.gmail.com>

use POSIXct instead of Date:


> x <- c("2013-12-12 12:00:00", "2013-12-15 03:15:23")
> # convert using as.POSIXct
>
> times <- as.POSIXct(x, format = "%Y-%m-%d %H:%M:%S")
> times
[1] "2013-12-12 12:00:00 EST" "2013-12-15 03:15:23 EST"
>
> difftime(times[2], times[1], units = 'secs')
Time difference of 227723 secs
>
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Dec 18, 2013 at 9:24 PM, Lydia Keppler <lydiakeppler at gmail.com> wrote:
> Hi there,
>
> I am new to R and programming in general and am looking for help with
> writing a function with dates and times. I have checked around but am still
> a bit stuck.
>
> Basically, I have data in the format "dd/mm/YYYY HH:MM" and I have to
> calculate how much time has passed between various events.
>
> I have given the following command ( where "date" is the column in my data
> frame that indicates the date and time)
> date=as.Date.factor(date,format="%d/%m/%Y %H:%M")
> However, this displays only the date, without the time.
>
> I also have tried:
> date=substr(argo1$date,1,907)
> And it shows the date and time.
>
> However, when I try to find the difference between two dates i.e.the time
> that has passed with the command: difftime(date[2],date[3],unit="secs"), it
> returns that 0 seconds have passed.
>
> When I try to find the difference with the command:
> date[3]-date[2]
> it tells me Error in date[3] - date[2] : non-numeric argument to binary
> operator
>
> The class(date) is "character".
>
> Any idea what I am doing wrong?
> Thank you very much in advance!
>
>
> On 19 December 2013 15:22, <r-help-request at r-project.org> wrote:
>
>> Welcome to the R-help at r-project.org mailing list!
>>
>> To post to this list, send your message to:
>>
>>   r-help at r-project.org
>>
>> General information about the mailing list is at:
>>
>>   https://stat.ethz.ch/mailman/listinfo/r-help
>>
>> If you ever want to unsubscribe or change your options (eg, switch to
>> or from digest mode, change your password, etc.), visit your
>> subscription page at:
>>
>>   https://stat.ethz.ch/mailman/options/r-help/lydiakeppler%40gmail.com
>>
>> You can also make such adjustments via email by sending a message to:
>>
>>   R-help-request at r-project.org
>>
>> with the word `help' in the subject or body (don't include the
>> quotes), and you will get back a message with instructions.
>>
>> You must know your password to change your options (including changing
>> the password, itself) or to unsubscribe without confirmation.  It is:
>>
>>   whaletail27
>>
>> Normally, Mailman will remind you of your r-project.org mailing list
>> passwords once every month, although you can disable this if you
>> prefer.  This reminder will also include instructions on how to
>> unsubscribe or change your account options.  There is also a button on
>> your options page that will email your current password to you.
>>
>
>
>
> --
> *Protect the environment: think before you print*
>><((((?>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From d.virkki at griffith.edu.au  Thu Dec 19 05:31:48 2013
From: d.virkki at griffith.edu.au (Diana Virkki)
Date: Thu, 19 Dec 2013 14:31:48 +1000
Subject: [R] GLMM parameter estimates giving opposite trends
Message-ID: <CAL6nRQeBsSqtG6qsEPAAsV=Fg0RWd6De_ck7i=au=hEQjXcPAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/f3d54652/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Dec 19 07:28:43 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 19 Dec 2013 06:28:43 +0000
Subject: [R] Problems with Installing R ('failure to expand shell folder
 constant "userdocs")
In-Reply-To: <1387403026.40670.YahooMailNeo@web163004.mail.bf1.yahoo.com>
References: <1387403026.40670.YahooMailNeo@web163004.mail.bf1.yahoo.com>
Message-ID: <52B2921B.5060007@stats.ox.ac.uk>

You didn't say what gave that message (and there is no 'R 3.02': did you 
mean  3.0.2?).

If this came from the installer, that is not part of R: look for info on 
'Inno Setup'.

On 18/12/2013 21:43, Barry DeCicco wrote:
> ?
> Hello,
> ?
> I???m trying to install R 3.02 for windows on a Windows 7 machine (we were just upgraded from Windows XP).
> It???s a networked machine in a work environment.?  I have administrator rights.
> Program files go on C; data is stored on D (it's a partitioned drive).
> ?
> I get the message 'failure to expand shell folder constant "userdocs"
> ?
> I searched, and found some stuff on the Microsoft website, which made me believe that?  I needed to unlock a folder with my user name.?  There are two, one in ???C:\Users???, which has a padlock symbol on it, and another in ???D:\???m which doesn???t have a padlock icon.?  Both had been set to read only; I removed that.?
> ?
> I???ve not been able to find anything on the CRAN website about this.
> ?
> Has anybody run into this problem before?
> ?
> ?
> Thank you very much,
> ?
> Barry DeCicco
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
Please do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From totangjie at gmail.com  Thu Dec 19 10:07:56 2013
From: totangjie at gmail.com (Jie Tang)
Date: Thu, 19 Dec 2013 17:07:56 +0800
Subject: [R] what is wrong with for and if cycle in R
Message-ID: <CAMUSh4p=amzsNsNO4j5HjuGRbrRkAf1ZTCkLqYi4GqHNsG-EWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/ad3d3928/attachment.pl>

From i.visser at uva.nl  Thu Dec 19 10:24:07 2013
From: i.visser at uva.nl (Ingmar Visser)
Date: Thu, 19 Dec 2013 10:24:07 +0100
Subject: [R] what is wrong with for and if cycle in R
In-Reply-To: <CAMUSh4p=amzsNsNO4j5HjuGRbrRkAf1ZTCkLqYi4GqHNsG-EWQ@mail.gmail.com>
References: <CAMUSh4p=amzsNsNO4j5HjuGRbrRkAf1ZTCkLqYi4GqHNsG-EWQ@mail.gmail.com>
Message-ID: <CABmqZHMQvGO=oZyX54Bvc5s7ashTeupRq2V8_9pi6S4PNOMMXw@mail.gmail.com>

I get this error below, there seems to be hidden character in your
input instead of a parenthesis:

> for(ity in 1:4)
+ {
+ if (ity==1?
Error: unexpected input in:
"{
if (ity==1?"
> {
+ print(ity)
+ }
Error in print(ity) : object 'ity' not found
> }
Error: unexpected '}' in "}"
>

hth, Ingmar


On Thu, Dec 19, 2013 at 10:07 AM, Jie Tang <totangjie at gmail.com> wrote:
> hi
>  I used a two nested cycle by if and for by such code
>
> for(ity in 1:4)
> {
> if (ity==1?
> {
> print(ity)
> }
> }
>
> when I run the code it failed and R tell me that
> "error: unrespected '}' in "}""
>
> and when I reduce a }
>
> for(ity in 1:4)
> {
> if (ity==2?
> {
> print(ity)
> }
>
> R will print 4 but not 2 as what I repect
>
> Could anyone tell me what is the matter with R and how to modify it?
>
> thank you .
> --
> TANG Jie
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kridox at ymail.com  Thu Dec 19 10:36:14 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 19 Dec 2013 18:36:14 +0900
Subject: [R] what is wrong with for and if cycle in R
In-Reply-To: <CAMUSh4p=amzsNsNO4j5HjuGRbrRkAf1ZTCkLqYi4GqHNsG-EWQ@mail.gmail.com>
References: <CAMUSh4p=amzsNsNO4j5HjuGRbrRkAf1ZTCkLqYi4GqHNsG-EWQ@mail.gmail.com>
Message-ID: <CAAcyNCyDh6vvhJ5insaM80V1XiVAYXawyWthzuSPpNbv7QA1Cg@mail.gmail.com>

Hi,

It seems the right prenthesis ")" in the "if" statement is in
different encoding.

>From your script:
> charToRaw('if (ity==1?')[11:13]
[1] ef bc 89

> charToRaw(')')
[1] 29

 By changing the right parenthesis, it works fine.

HTH,
Pascal

On 19 December 2013 18:07, Jie Tang <totangjie at gmail.com> wrote:
> hi
>  I used a two nested cycle by if and for by such code
>
> for(ity in 1:4)
> {
> if (ity==1?
> {
> print(ity)
> }
> }
>
> when I run the code it failed and R tell me that
> "error: unrespected '}' in "}""
>
> and when I reduce a }
>
> for(ity in 1:4)
> {
> if (ity==2?
> {
> print(ity)
> }
>
> R will print 4 but not 2 as what I repect
>
> Could anyone tell me what is the matter with R and how to modify it?
>
> thank you .
> --
> TANG Jie
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From bbolker at gmail.com  Thu Dec 19 13:18:09 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 19 Dec 2013 12:18:09 +0000
Subject: [R] GLMM parameter estimates giving opposite trends
References: <CAL6nRQeBsSqtG6qsEPAAsV=Fg0RWd6De_ck7i=au=hEQjXcPAA@mail.gmail.com>
Message-ID: <loom.20131219T131338-267@post.gmane.org>

Diana Virkki <d.virkki <at> griffith.edu.au> writes:

> 
> I apologize if this is a simple question.
> 
> I am running GLMM's using glmmML and model averaging with
>  MuMIn. One of the
> parameter estimates for a parameter (firefreq) in the
>  best model is giving
> a positive number, where in reality I know this to be a negative
> correlation.
> I have checked and double checked the data that has
> gone in and this is not
> the issue. This is occurring for numerous variables in my models.
> 
> As far as I was aware the parameter estimate is 
> indicative of the direction
> of the relationship? Is there any reason why this model would give me
> opposite trends?

  It's a little hard to guess without a reproducible example (see
http://tinyurl.com/reproducible-000), but one guess is that you have
one or more confounding variables
<http://en.wikipedia.org/wiki/Confounding> in your multivariate model;
that is, the _marginal_ effect of fire frequency is to decrease the
mean response, but the effect _conditional_ on all of the other
variables in the model is to increase it.  This phenomenon is most
common when the predictors are strongly correlated.

  Do you get a sensible sign when you fit a model with just the
focal parameter?

  Ben Bolker


From dulcalma at bigpond.com  Thu Dec 19 13:32:38 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 19 Dec 2013 22:32:38 +1000
Subject: [R] plot different groups as factors
In-Reply-To: <CAMk+s2TGB4aCvbHPGvj2GK4N30DEchqD7q01U933UGbhc1iLLw@mail.gmail.com>
References: <CAMk+s2TGB4aCvbHPGvj2GK4N30DEchqD7q01U933UGbhc1iLLw@mail.gmail.com>
Message-ID: <001e01cefcb6$67c00d10$37402730$@bigpond.com>

Hi Luigi

A quick guess with lattice

library(lattice)

structure(list(time = c(18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 
18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 
18, 18, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 
12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 
12, 12, 12, 12, 12, 12, 12, 12), clas = c("medium", "medium", 
"medium", "medium", "medium", "medium", "medium", "medium", "medium", 
"medium", "medium", "medium", "medium", "medium", "high", "high", 
"high", "high", "high", "high", "high", "low", "low", "low", 
"low", "low", "low", "low", "medium", "medium", "medium", "medium", 
"medium", "medium", "medium", "medium", "medium", "medium", "medium", 
"medium", "medium", "medium", "medium", "medium", "medium", "medium", 
"high", "high", "high", "high", "high", "high", "high", "high", 
"high", "high", "low", "low", "low", "low", "low", "low", "low", 
"low", "low", "low"), value = c(2.92, 0.01, 0.36, 3.16, 0.99, 
0.38, 0.01, 5.1, 0.04, 0.01, 1.33, 4.13, 0.15, 0.15, 14.18, 4290.14, 
26.8, 5.33, 17.58, 14.29, 248.5, 0.01, 0, 0, 0, 0, 0, 0, 0.151395382, 
5.327863403, 5.10096383, 1.32567787, 4.352404124, 0.458606982, 
2.915908912, 0.011996374, 0.364710382, 0.033016026, 3.161701212, 
0.381564497, 0.010971385, 0.035646472, 0.014781805, 4.129708296, 
0.153094117, 0.018497847, 15.09178491, 17.58393041, 14.17643928, 
4290.143561, 26.79730719, 294.6367065, 14.2888441, 248.495231, 
209.3131795, 2014.506722, 0.010751273, 0.002325138, 0.000637473, 
0.003984336, 0.006018154, 0.003620907, 7.45936e-05, 0.000142311, 
0.002460417, 0.001280189)), .Names = c("time", "clas", "value"
), row.names = c(NA, -66L), class = "data.frame")

bwplot(value~factor(time)|factor(dat$clas, levels =
c("low","medium","high")),dat, hor=F, layout = c(3,1),scales = list(relation
= "free") )

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au





-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Luigi Marongiu
Sent: Thursday, 19 December 2013 10:19
To: r-help at r-project.org
Subject: [R] plot different groups as factors

dear all,
i would like to plot the value of different response groups. when i simply
use  plot(y ~ x) i obtain a series of boxplots. i would rather use dots. i
also tried with stripchart(y ~ x), which gives better results but does not
place properly the labels since place them alphabetically.
in addition i actually have 6 response groups: 3 classes (low, medium,
high) and 2 sampling time (12 and 18 months).
how can i generate these individual groups and plot them in the correct
order (low, medium, high and 12, 18)? i believe is something to do with the
factors but i don't know how to implement them.
what i am looking for is to generate a figure such as the one i sketched in
the attached file. i also attached a dataframe version of my data. the
vectors containing the same data are:
time <-c(  18,    18,    18,    18,    18,    18,    18,    18,    18,
18,    18,    18,    18,    18,    18,    18,    18,    18,    18,
18,    18,    18,    18,    18,    18,    18,    18,    18,    12,
12,    12,    12,    12,    12,    12,    12,    12,    12,    12,
12,    12,    12,    12,    12,    12,    12,    12,    12,    12,
12,    12,    12,    12,    12,    12,    12,    12,    12,    12,
12,    12,    12,    12,    12,    12,    12)
class <-c(    medium,    medium,    medium,    medium,    medium,
medium,    medium,    medium,    medium,    medium,    medium,
medium,    medium,    medium,    high,    high,    high,    high,
high,    high,    high,    low,    low,    low,    low,    low,    low,
low,    medium,    medium,    medium,    medium,    medium,    medium,
medium,    medium,    medium,    medium,    medium,    medium,
medium,    medium,    medium,    medium,    medium,    medium,    high,
high,    high,    high,    high,    high,    high,    high,    high,
high,    low,    low,    low,    low,    low,    low,    low,    low,
low,    low)
value <-c(    2.92,    0.01,    0.36,    3.16,    0.99,    0.38,
0.01,    5.1,    0.04,    0.01,    1.33,    4.13,    0.15,    0.15,
14.18,    4290.14,    26.8,    5.33,    17.58,    14.29,    248.5,
0.01,    0,    0,    0,    0,    0,    0,    0.151395382,
5.327863403,    5.10096383,    1.32567787,    4.352404124,
0.458606982,    2.915908912,    0.011996374,    0.364710382,
0.033016026,    3.161701212,    0.381564497,    0.010971385,
0.035646472,    0.014781805,    4.129708296,    0.153094117,
0.018497847,    15.09178491,    17.58393041,    14.17643928,
4290.143561,    26.79730719,    294.6367065,    14.2888441,
248.495231,    209.3131795,    2014.506722,    0.010751273,
0.002325138,    0.000637473,    0.003984336,    0.006018154,
0.003620907,    0.0000745936,    0.000142311,    0.002460417,
0.001280189)

Thank you very much for any help you could provide!
regards
Luigi


From jvadams at usgs.gov  Thu Dec 19 14:28:23 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 19 Dec 2013 07:28:23 -0600
Subject: [R] 3D Surface Plot
In-Reply-To: <FCECE981A5D14046AA7444DC56070347116A9F@EXMBX2010-4.campus.MCGILL.CA>
References: <FCECE981A5D14046AA7444DC56070347116A9F@EXMBX2010-4.campus.MCGILL.CA>
Message-ID: <CAN5YmCEUoOYrgcQYw=O10SrR_RMX1kqyxN+MqhgqVsjJrg8CJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/789bae1f/attachment.pl>

From mar.lamack at hotmail.com  Thu Dec 19 14:32:03 2013
From: mar.lamack at hotmail.com (L... L...)
Date: Thu, 19 Dec 2013 11:32:03 -0200
Subject: [R] cure fraction model
Message-ID: <BLU175-W26729CEC35624EACADC7996C50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/6dd0d053/attachment.pl>

From nicholasehamilton at gmail.com  Thu Dec 19 15:45:04 2013
From: nicholasehamilton at gmail.com (Nicholas Hamilton)
Date: Thu, 19 Dec 2013 06:45:04 -0800 (PST)
Subject: [R] Ternary plot and filled contour
In-Reply-To: <DUB106-W229AC95FF9F1CC5C13B66CDF0F0@phx.gbl>
References: <DUB106-W229AC95FF9F1CC5C13B66CDF0F0@phx.gbl>
Message-ID: <a09e6804-f43a-476e-b3e7-10bfdb0fedd1@googlegroups.com>

Dear Francesco, 

I wanted to mention that I have just published on CRAN, a package for R, 
for the plotting of ternary diagrams. 

It is based off ggplot2, which is highly regarded, and, my website can be 
viewed at www.ggtern.com, including many examples, specifically including a 
case study at the following address: 

http://ggtern.com/case-study-zirconia-alumina-silica/ 

Hope you find it of value. 

Best Regards, 

Nicholas Hamilton 
School of Materials Science and Engineering 
Univesity of New South Wales 
Sydney Australia 
-- 
www.ggtern.com 

On Monday, June 4, 2012 10:52:10 PM UTC+10, Francesco Nutini wrote:
>
>
> Dear R-Users, I'd like to have some tips for a ternaryplot ("vcd"). 
> I have this dataframe: 
>     a<- c (0.1, 0.5, 0.5, 0.6, 0.2,        0, 0, 0.004166667, 0.45)     
> b<- c (0.75,0.5,0,0.1,0.2,0.951612903,0.918103448,0.7875,0.45)    c<- c 
> (0.15,0,0.5,0.3,0.6,0.048387097,0.081896552,0.208333333,0.1)     d<- c 
> (500,2324.90,2551.44,1244.50, 551.22,-644.20,-377.17,-100, 2493.04)     
> df<- data.frame (a, b, c, d) 
> and I'm building a ternary plot: 
>     ternaryplot(df[,1:3], df$d) 
> How can I map the continue variable "d", obtaining a result similar to 
> this one? [see the link] 
> > 
> http://www.pmel.noaa.gov/maillists/tmap/ferret_users/fu_2007/jpgCqrZqdDwYG.jpg 
> Many thanks! 
>
>                                                 
>         [[alternative HTML version deleted]] 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From nutini.francesco at gmail.com  Thu Dec 19 16:09:03 2013
From: nutini.francesco at gmail.com (Francesco Nutini)
Date: Thu, 19 Dec 2013 16:09:03 +0100
Subject: [R] Ternary plot and filled contour
In-Reply-To: <a09e6804-f43a-476e-b3e7-10bfdb0fedd1@googlegroups.com>
References: <DUB106-W229AC95FF9F1CC5C13B66CDF0F0@phx.gbl>,
	<a09e6804-f43a-476e-b3e7-10bfdb0fedd1@googlegroups.com>
Message-ID: <DUB122-W28D01231FCC6C98904AC6DDFC50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/3da9132b/attachment.pl>

From nicholasehamilton at gmail.com  Thu Dec 19 16:38:33 2013
From: nicholasehamilton at gmail.com (Nicholas Hamilton)
Date: Thu, 19 Dec 2013 07:38:33 -0800 (PST)
Subject: [R] ternary contour plot
In-Reply-To: <BAY131-W243EEBE37CE13E1333B893A8D30@phx.gbl>
References: <4D598B22.8060305@Bristol.ac.uk>
	<BAY131-W243EEBE37CE13E1333B893A8D30@phx.gbl>
Message-ID: <e67e6c21-5f06-4866-bab3-201adee6a4d9@googlegroups.com>

Dear Walmes, 

I wanted to mention that I have just published on CRAN, a package for R, 
for the plotting of ternary diagrams. 

It is based off ggplot2, which is highly regarded, and, my website can be 
viewed at www.ggtern.com, including many examples, specifically including a 
case study at the following address: 

http://ggtern.com/case-study-zirconia-alumina-silica/ 

Hope you find it of value. 

Best Regards, 

Nicholas Hamilton 
School of Materials Science and Engineering 
Univesity of New South Wales 
Sydney Australia 
-- 
www.ggtern.com 

On Wednesday, February 16, 2011 2:42:43 AM UTC+11, Walmes Marques Zeviani 
wrote:
>
>
> Colin,
>
> If your propose is to create a ternary plot with points and vectors, I 
> think easier do this with graphics based plots instead of trellis based 
> plots. Although, with little work you can do with trellis too. I gave you a 
> reproducible code to put an arrow in a ternary plot. I use the function 
> locator() to extract coordinates. The code is the following
>
>
> #------------------------------------------------------------------------------------------
> # package and related documentaion
>
> require(plotrix)
> help.search("triax")
> help(triax.plot, html=TRUE)
>
>
> #------------------------------------------------------------------------------------------
> # toy data
>
> data(soils)
> str(soils)
>
>
> #------------------------------------------------------------------------------------------
> # creating a ternary plot
>
> triax.plot(soils[1:10,], main="DEFAULT")
>
>
> #------------------------------------------------------------------------------------------
> # extracting coodinates by mouse click on the plot (cartesian coordinates, 
> x  and y axis)
>
> id <- locator(n=2) # click on the plot to extract 2 coodinates
>
>
> #------------------------------------------------------------------------------------------
> # draw an arrow with the coordinates extracted
>
> arrows(id$x[1], id$y[1], id$x[2], id$y[2])
>
>
> #------------------------------------------------------------------------------------------
>
> At your disposal.
> Walmes.
>
> ============================================================
>
>
> Walmes Marques Zeviani
>
>
> LEG (Laborat?rio de Estat?stica e Geoinforma??o)
>
>
> Departamento de Estat?stica - Universidade Federal do Paran?
>
>
> fone: (+55) 41 3361 3573
>
>
> VoIP: (3361 3600) 1053 1173
>
>
> e-mail: wal... at ufpr.br <javascript:> / @walmeszeviani
>
>
> homepage: http://www.leg.ufpr.br/~walmes
>
>
> ============================================================
>
>
> > Date: Mon, 14 Feb 2011 20:05:54 +0000
> > From: Colin... at bristol.ac.uk <javascript:>
> > To: walmes... at hotmail.com <javascript:>
> > Subject: ternary contour plot
> > 
> > Dear Walmes,
> > 
> > Firstly, thank you for distributing your ternary contour plot code.
> > 
> > could I ask you a question about it, hopefully you will be able to 
> > answer it quite simply and so save me some time trying to work out what 
> > it is that the function is actually doing.
> > 
> > Essentially I wish to overlay points and vectors onto the ternary 
> > contour plot. Now can I do this by:
> > 
> > a): extracting the adjusted x y coordinates and using it with triax.fill
> > 
> > or
> > 
> > b) can I plot my vectors (arrows) and points onto the grid that is 
> > created by levelplot.ternary
> > 
> > if either or both are true do you know how I would go about a) 
> > extracting or b) inputing the relevent data?
> > 
> > I would be grateful for your advice,
> > 
> > best regards,
> > 
> > colin
> > 
> > -- 
> > 
> **********************************************************************************
> > 
> **********************************************************************************
> > 
> > Dr Colin Bleay
> > Station d'Ecologie Experimentale du CNRS,
> > 09200 Moulis,
> > France.
> > 
> > Tel: +33 5 61 04 03 61
> > Fax: +33 5 61 96 08 51
> > email: Colin... at EcoEx-Moulis.cnrs.fr <javascript:>
> > Webpage: http://www.ecoex-moulis.cnrs.fr/Staffpages/ColinBleay.htm
> > 
>                                                
>         [[alternative HTML version deleted]]
>
>

From klebyn at yahoo.com.br  Thu Dec 19 18:23:12 2013
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Thu, 19 Dec 2013 15:23:12 -0200
Subject: [R] ternary contour plot
In-Reply-To: <e67e6c21-5f06-4866-bab3-201adee6a4d9@googlegroups.com>
References: <4D598B22.8060305@Bristol.ac.uk>	<BAY131-W243EEBE37CE13E1333B893A8D30@phx.gbl>
	<e67e6c21-5f06-4866-bab3-201adee6a4d9@googlegroups.com>
Message-ID: <52B32B80.2090802@yahoo.com.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/190a5903/attachment.pl>

From dwinsemius at comcast.net  Thu Dec 19 19:06:39 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Dec 2013 10:06:39 -0800
Subject: [R] read ".slk" file
In-Reply-To: <CAN_e6XvqBmk26ubOP-852LwGDEx_PgY4=Z0Fu6XakWVffFBDaQ@mail.gmail.com>
References: <CAN_e6XvqBmk26ubOP-852LwGDEx_PgY4=Z0Fu6XakWVffFBDaQ@mail.gmail.com>
Message-ID: <15657B13-A1D4-456B-8543-4EF1C69386F7@comcast.net>


On Dec 16, 2013, at 3:10 PM, Santosh wrote:

> Dear Rxperts..
> 
> I recently received a data file with the extension ".slk". If I save the
> file as MS Excel file, I am able to read in R without issues.  Is it
> possible to read this ".slk" file without converting into another
> R-readable data format?

Reading this I wondered if you could use sep=";" with read.* functions.
http://en.wikipedia.org/wiki/SYmbolic_LinK_%28SYLK%29

That is NOT going to give you a neat dataframe, but you didn't make your goals very clear so it seems possible that you might get what you needed from some selected input lines.

-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Dec 19 19:18:15 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Dec 2013 10:18:15 -0800
Subject: [R] cure fraction model
In-Reply-To: <BLU175-W26729CEC35624EACADC7996C50@phx.gbl>
References: <BLU175-W26729CEC35624EACADC7996C50@phx.gbl>
Message-ID: <12DC8DEB-EB59-47B4-B649-1C983C6A16DC@comcast.net>


On Dec 19, 2013, at 5:32 AM, L... L... wrote:

> Dear all, is there an R function to simulate random observations from a cure fraction model (random observations with long-term survivos). 
> Some references how can I do this will be welcome.
> 
Shouldn't be too hard to set up a mixture of weibull distributed event times with one component having a parameter less than "exponential" (to represent the cured fraction with survival typical of an average human population) and another with a hazard like an "exponential" or worse to represent the non-cured fraction. Watch out about how the shape parameters are defined. The survival package uses different parameterization than the rweibull definitions.

library(survival)
?survreg
?rweibull

-- 

David Winsemius
Alameda, CA, USA


From baccts at hotmail.com  Thu Dec 19 19:20:54 2013
From: baccts at hotmail.com (C Lin)
Date: Thu, 19 Dec 2013 13:20:54 -0500
Subject: [R] creating list of variables description
Message-ID: <COL129-W5029B786F6591CEBF60A3DCBC50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/33600f5b/attachment.pl>

From juliosergio at gmail.com  Thu Dec 19 18:17:06 2013
From: juliosergio at gmail.com (Julio Sergio Santana)
Date: Thu, 19 Dec 2013 17:17:06 +0000
Subject: [R] Using assign with mapply
References: <loom.20131206T200836-152@post.gmane.org>
	<loom.20131216T163956-835@post.gmane.org>
	<CAFEqCdy2ci1MMKAU9fpRVS5Dr7S8Q1a9WmnOpomUu_A=-UJ2Ew@mail.gmail.com>
Message-ID: <loom.20131219T175709-457@post.gmane.org>

Greg Snow <538280 <at> gmail.com> writes:

> 
> The take home message that you should be learning from your struggles
> is to "Not Use The 'assign' Function!" and "Do Not Use Global
> Variables Like This".
> 
> R has lists (and environments) that make working with objects that are
> associated with each other much simpler and fits better with the
> functional programming style of R.
> 

Thanks, Greg!

Yours is a very smart solution to the problem I posed. 

By the way, what I'm trying to do is reading from a file a set of user given 
parameters, in two paired columns: parameter-name, value; and then, managing 
these parameters inside my R program. Now I do understand a bit more about 
lists. What about environments? Are they similar to lists, and when, and how 
are they created?

Best regrards,

  -Sergio.


From aurelien.philippot at gmail.com  Thu Dec 19 19:37:42 2013
From: aurelien.philippot at gmail.com (=?ISO-8859-1?Q?Aur=E9lien_Philippot?=)
Date: Thu, 19 Dec 2013 10:37:42 -0800
Subject: [R] Inconsistent computation of an integral
Message-ID: <CAOwh97uY26SYAaHuhLW+B0Lk6Y4zjCFeQbdubP2zCnpFLTnZ-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/bcea832f/attachment.pl>

From baccts at hotmail.com  Thu Dec 19 19:43:15 2013
From: baccts at hotmail.com (C Lin)
Date: Thu, 19 Dec 2013 13:43:15 -0500
Subject: [R] creating list of variables description
In-Reply-To: <COL129-W5029B786F6591CEBF60A3DCBC50@phx.gbl>
References: <COL129-W5029B786F6591CEBF60A3DCBC50@phx.gbl>
Message-ID: <COL129-W563A4305D4D5EF41B30FD3CBC50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/b74f45b3/attachment.pl>

From sjkiss at gmail.com  Thu Dec 19 19:55:39 2013
From: sjkiss at gmail.com (Simon Kiss)
Date: Thu, 19 Dec 2013 13:55:39 -0500
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1E0F1@PA-MBX01.na.tibco.com>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
	<BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E0F1@PA-MBX01.na.tibco.com>
Message-ID: <6A1D5701-100E-4CF3-84E1-4681EF5641A6@gmail.com>

Hello Bill, that is fantastic and it's quite a bit above what I could write. Is there a way to make the model type an argument to the function so that you can specify whether one is running glm, lm and such? 
I tried to modify it by inserting an argument modelType below, but that doesn't work.
Yours, simon Kiss
>  f <- function (modelType, responseName, predictorNames, data, ..., envir = parent.frame())
>    {
>        call <- match.call()
>        call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
>            paste0("`", predictorNames, "`", collapse = " + ")))
>                call[[1]] <- quote(modelType) # '
>        call$responseName <- NULL # omit responseName=
>        call$predictorNames <- NULL # omit 'predictorNames='
>                eval(call, envir = envir)
>    }
On 2013-12-18, at 3:07 PM, William Dunlap <wdunlap at tibco.com> wrote:

>  f <- function (responseName, predictorNames, data, ..., envir = parent.frame())
>    {
>        call <- match.call()
>        call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
>            paste0("`", predictorNames, "`", collapse = " + ")))
>                call[[1]] <- quote(glm) # 'f' -> 'glm'
>        call$responseName <- NULL # omit responseName=
>        call$predictorNames <- NULL # omit 'predictorNames='
>                eval(call, envir = envir)
>    }
> as in
>    z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("carb", preds, data=mtcars, family=poisson))
>    lapply(z, summary)

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9
Cell: +1 905 746 7606


From dwinsemius at comcast.net  Thu Dec 19 19:53:06 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Dec 2013 10:53:06 -0800
Subject: [R] creating list of variables description
In-Reply-To: <COL129-W5029B786F6591CEBF60A3DCBC50@phx.gbl>
References: <COL129-W5029B786F6591CEBF60A3DCBC50@phx.gbl>
Message-ID: <B49B5FA7-7C16-4716-881C-2B0E73C749E1@comcast.net>


On Dec 19, 2013, at 10:20 AM, C Lin wrote:

> Dear R-users,
> 
> Can someone suggest a good way to keep a list of variables description in R? 
> Something to provide more detailed information on the variables that I have.
> Kind of like this list: 
> http://www.thearda.com/pals/researchers/VARIABLE_DESCRIPT_LIST%20-%20public.pdfI'd like to be able to output the variable list in a nice format.Thank you.

Do an RSiteSearch on "codebook" (Or use:

sos::findFn("codebook")

...  and look at the Hmisc package that does record variable descriptions from external datasets with some of its methods that import from SAS or SPSS files when they contain such information. 

help(package="Hmisc")

# especially
sas.codes	Convert a SAS Dataset to an S Data Frame
sas.get	Convert a SAS Dataset to an S Data Frame
sasdsLabels	Enhanced Importing of SAS Transport Files using read.xport
sasxport.get	Enhanced Importing of SAS Transport Files using read.xport

spss.get	Enhanced Importing of SPSS Files

> 		 	   		  
> 	[[alternative HTML version deleted]]
And do learn to post in plain text:


David Winsemius
Alameda, CA, USA


From onuruncu at gmail.com  Thu Dec 19 20:05:09 2013
From: onuruncu at gmail.com (Onur Uncu)
Date: Thu, 19 Dec 2013 19:05:09 +0000
Subject: [R] A function which is a sum of other functions...
Message-ID: <8F1C96F7-DBB7-4C6D-A998-E793A529F955@gmail.com>


Dear R Users

I have a list of functions. Each function in the list is a function of single variable. I would like to create a function (of one variable) which represents the sum of all the functions in the list. So, if the functions in my list are f1(x),..,f5(x) then I would like a new function f(x)=f1(x)+f2(x)+...f5(x)

Appreciate any suggestions on how to do this. 

I need the above f(x) function because I would like to minimise it with respect to x using the nlm function.

Thanks.

From wdunlap at tibco.com  Thu Dec 19 20:09:07 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 19 Dec 2013 19:09:07 +0000
Subject: [R] Inconsistent computation of an integral
In-Reply-To: <CAOwh97uY26SYAaHuhLW+B0Lk6Y4zjCFeQbdubP2zCnpFLTnZ-g@mail.gmail.com>
References: <CAOwh97uY26SYAaHuhLW+B0Lk6Y4zjCFeQbdubP2zCnpFLTnZ-g@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1E377@PA-MBX01.na.tibco.com>

I think you want to use pmax(x-50, 0), which returns a vector
the length of x, instead of max(x-50,0), which returns a scalar.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Aur?lien Philippot
> Sent: Thursday, December 19, 2013 10:38 AM
> To: R-help at r-project.org
> Subject: [R] Inconsistent computation of an integral
> 
> Dear R experts,
> I computed the same integral in two different ways, and find different
> values in R.
> The difference is due to the max function that is part of the integrand. In
> the first case, I keep it as such, in the second case, I split it in two
> depending on the values of the variable of integration.
> 
> 1) First computation
> 
> # Function g
> g<-
> function(x){1/(x*0.20*sqrt(10)*sqrt(2*pi))*exp(-0.5*((log(x/50)-
> 0.1*10)/(0.20*sqrt(10)))^2)}
> 
> ####### Function f1
> f1<- function(x) {1/(5000000+100000*x+10000*max(x-50,0))}
> 
> integrand1<- function(x) {
>   out<- f1(x)*g(x)
>   return(out)
> }
> 
> i2<- integrate(integrand1, lower=0, upper=Inf )$value
> 
> It gives me: i2=  3.819418e-08
> 
> 2) Second computation
> I break the max function in two, depending on the values of the variable of
> integration x (and I use the same density g as before):
> 
> f11<- function(x) {1/(5000000+100000*x)}
> f12<- function(x) {1/(5000000+100000*x+10000*(x-50))}
> 
> 
> integrand11<- function(x) {
>   out<- f11(x)*g(x)
>   return(out)
> }
> 
> integrand12<- function(x) {
>   out<- f12(x)*g(x)
>   return(out)
> }
> 
> 
> i21<- integrate(integrand11, lower=0, upper=50 )$value
> +integrate(integrand12, lower=50, upper=Inf)$value
> 
> I get i21=5.239735e-08
> 
> The difference makes a huge difference for the computations I do. Does
> anyone know where it comes from?
> Thanks in advance!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Dec 19 20:10:55 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 19 Dec 2013 19:10:55 +0000
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <6A1D5701-100E-4CF3-84E1-4681EF5641A6@gmail.com>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
	<BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E0F1@PA-MBX01.na.tibco.com>
	<6A1D5701-100E-4CF3-84E1-4681EF5641A6@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1E387@PA-MBX01.na.tibco.com>

> >                call[[1]] <- quote(modelType) # '

makes call[[1]] the same as as.name("modelType").  You want
as.name(modelType).

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Simon Kiss [mailto:sjkiss at gmail.com]
> Sent: Thursday, December 19, 2013 10:56 AM
> To: William Dunlap
> Cc: Dennis Murphy; r-help at r-project.org
> Subject: Re: [R] Help using mapply to run multiple models
> 
> Hello Bill, that is fantastic and it's quite a bit above what I could write. Is there a way to
> make the model type an argument to the function so that you can specify whether one is
> running glm, lm and such?
> I tried to modify it by inserting an argument modelType below, but that doesn't work.
> Yours, simon Kiss
> >  f <- function (modelType, responseName, predictorNames, data, ..., envir =
> parent.frame())
> >    {
> >        call <- match.call()
> >        call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
> >            paste0("`", predictorNames, "`", collapse = " + ")))
> >                call[[1]] <- quote(modelType) # '
> >        call$responseName <- NULL # omit responseName=
> >        call$predictorNames <- NULL # omit 'predictorNames='
> >                eval(call, envir = envir)
> >    }
> On 2013-12-18, at 3:07 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> >  f <- function (responseName, predictorNames, data, ..., envir = parent.frame())
> >    {
> >        call <- match.call()
> >        call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
> >            paste0("`", predictorNames, "`", collapse = " + ")))
> >                call[[1]] <- quote(glm) # 'f' -> 'glm'
> >        call$responseName <- NULL # omit responseName=
> >        call$predictorNames <- NULL # omit 'predictorNames='
> >                eval(call, envir = envir)
> >    }
> > as in
> >    z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("carb",
> preds, data=mtcars, family=poisson))
> >    lapply(z, summary)
> 
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> Cell: +1 905 746 7606
> 
> 


From wdunlap at tibco.com  Thu Dec 19 20:23:43 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 19 Dec 2013 19:23:43 +0000
Subject: [R] A function which is a sum of other functions...
In-Reply-To: <8F1C96F7-DBB7-4C6D-A998-E793A529F955@gmail.com>
References: <8F1C96F7-DBB7-4C6D-A998-E793A529F955@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1E3B4@PA-MBX01.na.tibco.com>

> List <- list(abs, function(x)x*10, function(x)x*100)
> f <- function(x)Reduce(`+`, lapply(List, function(func)func(x)))
> f(-1:2)
[1] -109    0  111  222

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Onur Uncu
> Sent: Thursday, December 19, 2013 11:05 AM
> To: r-help at r-project.org
> Subject: [R] A function which is a sum of other functions...
> 
> 
> Dear R Users
> 
> I have a list of functions. Each function in the list is a function of single variable. I would
> like to create a function (of one variable) which represents the sum of all the functions in
> the list. So, if the functions in my list are f1(x),..,f5(x) then I would like a new function
> f(x)=f1(x)+f2(x)+...f5(x)
> 
> Appreciate any suggestions on how to do this.
> 
> I need the above f(x) function because I would like to minimise it with respect to x using
> the nlm function.
> 
> Thanks.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Dec 19 20:24:38 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Dec 2013 11:24:38 -0800
Subject: [R] A function which is a sum of other functions...
In-Reply-To: <8F1C96F7-DBB7-4C6D-A998-E793A529F955@gmail.com>
References: <8F1C96F7-DBB7-4C6D-A998-E793A529F955@gmail.com>
Message-ID: <64EEA4E0-418A-4539-9F6C-C6D1731B02E5@comcast.net>


On Dec 19, 2013, at 11:05 AM, Onur Uncu wrote:

> 
> Dear R Users
> 
> I have a list of functions. Each function in the list is a function of single variable. I would like to create a function (of one variable) which represents the sum of all the functions in the list. So, if the functions in my list are f1(x),..,f5(x) then I would like a new function f(x)=f1(x)+f2(x)+...f5(x)
> 
> Appreciate any suggestions on how to do this. 
> 
> I need the above f(x) function because I would like to minimise it with respect to x using the nlm function.

> fbig <- function(x, f1=I, f2=I, f3=I, f4=I, f5=I){
                              f1(x)+f2(x)+f3(x)+f4(x)+f5(x)}
> fbig(2)
[1] 10
> fbig(2, exp)
[1] 15.38906

> fbig(2, exp, log)
[1] 14.0822

Since "+" is vectorized this should not need to be wrapped in sapply as long as each function is itself vectorized.


David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Dec 19 20:30:49 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Dec 2013 11:30:49 -0800
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1E387@PA-MBX01.na.tibco.com>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
	<BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E0F1@PA-MBX01.na.tibco.com>
	<6A1D5701-100E-4CF3-84E1-4681EF5641A6@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E387@PA-MBX01.na.tibco.com>
Message-ID: <8783FFD4-6696-4596-8184-2D488447EA7E@comcast.net>


On Dec 19, 2013, at 11:10 AM, William Dunlap wrote:

>>>               call[[1]] <- quote(modelType) # '
> 
> makes call[[1]] the same as as.name("modelType").  You want
> as.name(modelType).

Just so I can see if I understand ... that is because `as.name` will evaluate `modelType` whereas as.name("modelType") would look for the function `modelType` and not find such a name in the namespace? So modelType needs to be a language-object and `f` needs to be called with:

f(glm, ....) rather than f("glm", ...)


> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
>> -----Original Message-----
>> From: Simon Kiss [mailto:sjkiss at gmail.com]
>> Sent: Thursday, December 19, 2013 10:56 AM
>> To: William Dunlap
>> Cc: Dennis Murphy; r-help at r-project.org
>> Subject: Re: [R] Help using mapply to run multiple models
>> 
>> Hello Bill, that is fantastic and it's quite a bit above what I could write. Is there a way to
>> make the model type an argument to the function so that you can specify whether one is
>> running glm, lm and such?
>> I tried to modify it by inserting an argument modelType below, but that doesn't work.
>> Yours, simon Kiss
>>> f <- function (modelType, responseName, predictorNames, data, ..., envir =
>> parent.frame())
>>>   {
>>>       call <- match.call()
>>>       call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
>>>           paste0("`", predictorNames, "`", collapse = " + ")))
>>>               call[[1]] <- quote(modelType) # '
>>>       call$responseName <- NULL # omit responseName=
>>>       call$predictorNames <- NULL # omit 'predictorNames='
>>>               eval(call, envir = envir)
>>>   }
>> On 2013-12-18, at 3:07 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> 
>>> f <- function (responseName, predictorNames, data, ..., envir = parent.frame())
>>>   {
>>>       call <- match.call()
>>>       call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
>>>           paste0("`", predictorNames, "`", collapse = " + ")))
>>>               call[[1]] <- quote(glm) # 'f' -> 'glm'
>>>       call$responseName <- NULL # omit responseName=
>>>       call$predictorNames <- NULL # omit 'predictorNames='
>>>               eval(call, envir = envir)
>>>   }
>>> as in
>>>   z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("carb",
>> preds, data=mtcars, family=poisson))
>>>   lapply(z, summary)
>> 
>> *********************************
>> Simon J. Kiss, PhD
>> Assistant Professor, Wilfrid Laurier University
>> 73 George Street
>> Brantford, Ontario, Canada
>> N3T 2C9
>> Cell: +1 905 746 7606
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Dec 19 20:37:28 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Dec 2013 11:37:28 -0800
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <8783FFD4-6696-4596-8184-2D488447EA7E@comcast.net>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
	<BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E0F1@PA-MBX01.na.tibco.com>
	<6A1D5701-100E-4CF3-84E1-4681EF5641A6@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E387@PA-MBX01.na.tibco.com>
	<8783FFD4-6696-4596-8184-2D488447EA7E@comcast.net>
Message-ID: <380C4258-56B2-48C7-AF21-8D02F9AF0A74@comcast.net>


On Dec 19, 2013, at 11:30 AM, David Winsemius wrote:

> 
> On Dec 19, 2013, at 11:10 AM, William Dunlap wrote:
> 
>>>>              call[[1]] <- quote(modelType) # '
>> 
>> makes call[[1]] the same as as.name("modelType").  You want
>> as.name(modelType).
> 
> Just so I can see if I understand ... that is because `as.name` will evaluate `modelType` whereas as.name("modelType") would look for the function `modelType` and not find such a name in the namespace? So modelType needs to be a language-object and `f` needs to be called with:
> 
> f(glm, ....) rather than f("glm", ...)

Reading `?as.name` (again) I've decided that must be wrong. either one should return the same value if teh argument is first converted to a character value.

-- 
David.
> 
> 
>> 
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>> 
>> 
>>> -----Original Message-----
>>> From: Simon Kiss [mailto:sjkiss at gmail.com]
>>> Sent: Thursday, December 19, 2013 10:56 AM
>>> To: William Dunlap
>>> Cc: Dennis Murphy; r-help at r-project.org
>>> Subject: Re: [R] Help using mapply to run multiple models
>>> 
>>> Hello Bill, that is fantastic and it's quite a bit above what I could write. Is there a way to
>>> make the model type an argument to the function so that you can specify whether one is
>>> running glm, lm and such?
>>> I tried to modify it by inserting an argument modelType below, but that doesn't work.
>>> Yours, simon Kiss
>>>> f <- function (modelType, responseName, predictorNames, data, ..., envir =
>>> parent.frame())
>>>>  {
>>>>      call <- match.call()
>>>>      call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
>>>>          paste0("`", predictorNames, "`", collapse = " + ")))
>>>>              call[[1]] <- quote(modelType) # '
>>>>      call$responseName <- NULL # omit responseName=
>>>>      call$predictorNames <- NULL # omit 'predictorNames='
>>>>              eval(call, envir = envir)
>>>>  }
>>> On 2013-12-18, at 3:07 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> 
>>>> f <- function (responseName, predictorNames, data, ..., envir = parent.frame())
>>>>  {
>>>>      call <- match.call()
>>>>      call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
>>>>          paste0("`", predictorNames, "`", collapse = " + ")))
>>>>              call[[1]] <- quote(glm) # 'f' -> 'glm'
>>>>      call$responseName <- NULL # omit responseName=
>>>>      call$predictorNames <- NULL # omit 'predictorNames='
>>>>              eval(call, envir = envir)
>>>>  }
>>>> as in
>>>>  z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("carb",
>>> preds, data=mtcars, family=poisson))
>>>>  lapply(z, summary)
>>> 

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Thu Dec 19 20:45:09 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 19 Dec 2013 19:45:09 +0000
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <8783FFD4-6696-4596-8184-2D488447EA7E@comcast.net>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
	<BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E0F1@PA-MBX01.na.tibco.com>
	<6A1D5701-100E-4CF3-84E1-4681EF5641A6@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E387@PA-MBX01.na.tibco.com>
	<8783FFD4-6696-4596-8184-2D488447EA7E@comcast.net>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1E408@PA-MBX01.na.tibco.com>

> Just so I can see if I understand ... that is because `as.name` will evaluate `modelType`
> whereas as.name("modelType") would look for the function `modelType` and not find
> such a name in the namespace? 

Almost.  as.name(modelType) will evaluate modelType so modelType could be a
character string or a name.   as.name itself does not do any lookups - that is eval's job.
When eval() is given a name object it looks it up.

> So modelType needs to be a language-object and `f`
> needs to be called with:
> 
> f(glm, ....) rather than f("glm", ...)

If you use as.name(modelType) then you could call f("glm",...).

f(glm, ...) does not pass a name into the function f, it passes in the object
named "glm" (usually the function in package:stats by that name).
as.name(glm) returns garbage.  If you wanted to be able to call
   f(glm, predictors, response)
you could just use
   call[[1]] <- modelType
in f().  I didn't recommend that because then the call attributes of glm's output
does not look nice.  You can write code so that both f("glm",...) and f(glm,...) work
but I usually prefer not to load up functions with so much heuristic argument
processing (e.g., how should it deal with 'func<-"glm" ; f(func,...)' and the like).

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Thursday, December 19, 2013 11:31 AM
> To: William Dunlap
> Cc: Simon Kiss; r-help at r-project.org
> Subject: Re: [R] Help using mapply to run multiple models
> 
> 
> On Dec 19, 2013, at 11:10 AM, William Dunlap wrote:
> 
> >>>               call[[1]] <- quote(modelType) # '
> >
> > makes call[[1]] the same as as.name("modelType").  You want
> > as.name(modelType).
> 
> Just so I can see if I understand ... that is because `as.name` will evaluate `modelType`
> whereas as.name("modelType") would look for the function `modelType` and not find
> such a name in the namespace? So modelType needs to be a language-object and `f`
> needs to be called with:
> 
> f(glm, ....) rather than f("glm", ...)
> 
> 
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> >
> >> -----Original Message-----
> >> From: Simon Kiss [mailto:sjkiss at gmail.com]
> >> Sent: Thursday, December 19, 2013 10:56 AM
> >> To: William Dunlap
> >> Cc: Dennis Murphy; r-help at r-project.org
> >> Subject: Re: [R] Help using mapply to run multiple models
> >>
> >> Hello Bill, that is fantastic and it's quite a bit above what I could write. Is there a way
> to
> >> make the model type an argument to the function so that you can specify whether
> one is
> >> running glm, lm and such?
> >> I tried to modify it by inserting an argument modelType below, but that doesn't work.
> >> Yours, simon Kiss
> >>> f <- function (modelType, responseName, predictorNames, data, ..., envir =
> >> parent.frame())
> >>>   {
> >>>       call <- match.call()
> >>>       call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
> >>>           paste0("`", predictorNames, "`", collapse = " + ")))
> >>>               call[[1]] <- quote(modelType) # '
> >>>       call$responseName <- NULL # omit responseName=
> >>>       call$predictorNames <- NULL # omit 'predictorNames='
> >>>               eval(call, envir = envir)
> >>>   }
> >> On 2013-12-18, at 3:07 PM, William Dunlap <wdunlap at tibco.com> wrote:
> >>
> >>> f <- function (responseName, predictorNames, data, ..., envir = parent.frame())
> >>>   {
> >>>       call <- match.call()
> >>>       call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
> >>>           paste0("`", predictorNames, "`", collapse = " + ")))
> >>>               call[[1]] <- quote(glm) # 'f' -> 'glm'
> >>>       call$responseName <- NULL # omit responseName=
> >>>       call$predictorNames <- NULL # omit 'predictorNames='
> >>>               eval(call, envir = envir)
> >>>   }
> >>> as in
> >>>   z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("carb",
> >> preds, data=mtcars, family=poisson))
> >>>   lapply(z, summary)
> >>
> >> *********************************
> >> Simon J. Kiss, PhD
> >> Assistant Professor, Wilfrid Laurier University
> >> 73 George Street
> >> Brantford, Ontario, Canada
> >> N3T 2C9
> >> Cell: +1 905 746 7606
> >>
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA


From wdunlap at tibco.com  Thu Dec 19 20:58:26 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 19 Dec 2013 19:58:26 +0000
Subject: [R] A function which is a sum of other functions...
In-Reply-To: <01F2F7B0-FEDA-4E27-8DDA-034C4C49814C@gmail.com>
References: <8F1C96F7-DBB7-4C6D-A998-E793A529F955@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E3B4@PA-MBX01.na.tibco.com>
	<01F2F7B0-FEDA-4E27-8DDA-034C4C49814C@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1E421@PA-MBX01.na.tibco.com>

> >> List <- list(abs, function(x)x*10, function(x)x*100)
> >> f <- function(x)Reduce(`+`, lapply(List, function(func)func(x)))
> >> f(-1:2)
> > [1] -109    0  111  222

In that formulation lapply() applies each function in List to x, returning a list of vectors
containing the results (run it outside of Reduce to see this).  Reduce then adds those vectors together.

You can have Reduce evaluate the functions in List and sum the results without using
lapply.  This saves the memory it would take to have all the result vectors in memory
at once, but I find the syntax hard to remember.  
   > g <- function(x)Reduce(function(runningSum, func)runningSum + func(x), List[-1], init=List[[1]](x))
   > g(-1:2)
   [1] -109    0  111  222

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Onur Uncu [mailto:onuruncu at gmail.com]
> Sent: Thursday, December 19, 2013 11:43 AM
> To: William Dunlap
> Subject: Re: [R] A function which is a sum of other functions...
> 
> Thanks William. May I please ask why we needed to use lapply inside Reduce? It sounds
> like we took a list of functions and recreated the same list using lapply. So I couldnt
> follow why we did that...
> 
> Sent from my iPhone
> 
> On 19 Dec 2013, at 19:23, William Dunlap <wdunlap at tibco.com> wrote:
> 
> >> List <- list(abs, function(x)x*10, function(x)x*100)
> >> f <- function(x)Reduce(`+`, lapply(List, function(func)func(x)))
> >> f(-1:2)
> > [1] -109    0  111  222
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf
> >> Of Onur Uncu
> >> Sent: Thursday, December 19, 2013 11:05 AM
> >> To: r-help at r-project.org
> >> Subject: [R] A function which is a sum of other functions...
> >>
> >>
> >> Dear R Users
> >>
> >> I have a list of functions. Each function in the list is a function of single variable. I
> would
> >> like to create a function (of one variable) which represents the sum of all the functions
> in
> >> the list. So, if the functions in my list are f1(x),..,f5(x) then I would like a new function
> >> f(x)=f1(x)+f2(x)+...f5(x)
> >>
> >> Appreciate any suggestions on how to do this.
> >>
> >> I need the above f(x) function because I would like to minimise it with respect to x
> using
> >> the nlm function.
> >>
> >> Thanks.
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Dec 19 21:21:22 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Dec 2013 12:21:22 -0800
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1E408@PA-MBX01.na.tibco.com>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
	<BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E0F1@PA-MBX01.na.tibco.com>
	<6A1D5701-100E-4CF3-84E1-4681EF5641A6@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E387@PA-MBX01.na.tibco.com>
	<8783FFD4-6696-4596-8184-2D488447EA7E@comcast.net>
	<E66794E69CFDE04D9A70842786030B933FA1E408@PA-MBX01.na.tibco.com>
Message-ID: <51D18AD2-F1FA-4013-AD90-7B4BC9307F38@comcast.net>


On Dec 19, 2013, at 11:45 AM, William Dunlap wrote:

>> Just so I can see if I understand ... that is because `as.name` will evaluate `modelType`
>> whereas as.name("modelType") would look for the function `modelType` and not find
>> such a name in the namespace? 
> 
> Almost.  as.name(modelType) will evaluate modelType so modelType could be a
> character string or a name.   as.name itself does not do any lookups - that is eval's job.
> When eval() is given a name object it looks it up.
> 
>> So modelType needs to be a language-object and `f`
>> needs to be called with:
>> 
>> f(glm, ....) rather than f("glm", ...)
> 
> If you use as.name(modelType) then you could call f("glm",...).
> 
> f(glm, ...) does not pass a name into the function f, it passes in the object
> named "glm" (usually the function in package:stats by that name).
> as.name(glm) returns garbage.  If you wanted to be able to call
>   f(glm, predictors, response)
> you could just use
>   call[[1]] <- modelType
> in f().  I didn't recommend that because then the call attributes of glm's output
> does not look nice.  You can write code so that both f("glm",...) and f(glm,...) work
> but I usually prefer not to load up functions with so much heuristic argument
> processing (e.g., how should it deal with 'func<-"glm" ; f(func,...)' and the like).

So by the time the function `f` "saw" its arguments from a call:  `f(glm, ...) `, the name of the function would already have been removed and you would just be getting the argument list attached to the function body and as.name() would make a hash of it .... as we saw in the original portion of this question.


> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
>> -----Original Message-----
>> From: David Winsemius [mailto:dwinsemius at comcast.net]
>> Sent: Thursday, December 19, 2013 11:31 AM
>> To: William Dunlap
>> Cc: Simon Kiss; r-help at r-project.org
>> Subject: Re: [R] Help using mapply to run multiple models
>> 
>> 
>> On Dec 19, 2013, at 11:10 AM, William Dunlap wrote:
>> 
>>>>>              call[[1]] <- quote(modelType) # '
>>> 
>>> makes call[[1]] the same as as.name("modelType").  You want
>>> as.name(modelType).
>> 
>> Just so I can see if I understand ... that is because `as.name` will evaluate `modelType`
>> whereas as.name("modelType") would look for the function `modelType` and not find
>> such a name in the namespace? So modelType needs to be a language-object and `f`
>> needs to be called with:
>> 
>> f(glm, ....) rather than f("glm", ...)
>> 
>> 
>>> 
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> 
>>>> -----Original Message-----
>>>> From: Simon Kiss [mailto:sjkiss at gmail.com]
>>>> Sent: Thursday, December 19, 2013 10:56 AM
>>>> To: William Dunlap
>>>> Cc: Dennis Murphy; r-help at r-project.org
>>>> Subject: Re: [R] Help using mapply to run multiple models
>>>> 
>>>> Hello Bill, that is fantastic and it's quite a bit above what I could write. Is there a way
>> to
>>>> make the model type an argument to the function so that you can specify whether
>> one is
>>>> running glm, lm and such?
>>>> I tried to modify it by inserting an argument modelType below, but that doesn't work.
>>>> Yours, simon Kiss
>>>>> f <- function (modelType, responseName, predictorNames, data, ..., envir =
>>>> parent.frame())
>>>>>  {
>>>>>      call <- match.call()
>>>>>      call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
>>>>>          paste0("`", predictorNames, "`", collapse = " + ")))
>>>>>              call[[1]] <- quote(modelType) # '
>>>>>      call$responseName <- NULL # omit responseName=
>>>>>      call$predictorNames <- NULL # omit 'predictorNames='
>>>>>              eval(call, envir = envir)
>>>>>  }
>>>> On 2013-12-18, at 3:07 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>>> 
>>>>> f <- function (responseName, predictorNames, data, ..., envir = parent.frame())
>>>>>  {
>>>>>      call <- match.call()
>>>>>      call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
>>>>>          paste0("`", predictorNames, "`", collapse = " + ")))
>>>>>              call[[1]] <- quote(glm) # 'f' -> 'glm'
>>>>>      call$responseName <- NULL # omit responseName=
>>>>>      call$predictorNames <- NULL # omit 'predictorNames='
>>>>>              eval(call, envir = envir)
>>>>>  }
>>>>> as in
>>>>>  z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("carb",
>>>> preds, data=mtcars, family=poisson))
>>>>>  lapply(z, summary)
>>>> 
>>>> *********************************
>>>> Simon J. Kiss, PhD
>>>> Assistant Professor, Wilfrid Laurier University
>>>> 73 George Street
>>>> Brantford, Ontario, Canada
>>>> N3T 2C9
>>>> Cell: +1 905 746 7606
>>>> 
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From cgan at caesar.cs.umn.edu  Thu Dec 19 20:04:55 2013
From: cgan at caesar.cs.umn.edu (Colin Gan)
Date: Thu, 19 Dec 2013 13:04:55 -0600 (CDT)
Subject: [R] ATTN: Problem with Portfolio Optimization converging with
 Expected Shortfall as risk measure on Asymmetric Generalized Hyperbolic
 Distribution
Message-ID: <alpine.SOC.2.00.1312191253580.6781@caesar.cs.umn.edu>

Hi there, attached are the necessary code and data.  For me, the portfolio 
optimization with expected shortfall as risk measure only converges on 
gaussian not asymmetric generalized hyperbolic, normal inverse gaussian, 
variance gamma and student t distributions.  I like to know why.  Thank 
you.

Sincere Blessings,
--
Colin Gan Cheong Kiat
-------------- next part --------------
BACreturn,BRKBreturn,GEreturn,KOreturn,LOWreturn,MCDreturn,MMMreturn,RFreturn,TGTreturn,WMTreturn,TBillYield,EURUSDreturn,SPYReturn

0.0615128,0.050409396,0.02373628,0.007538838,0,0.007262196,0.006451073,0.008832865,0.028791648,0.018180683,0.00E+00,-0.012921829,0.014173553

0.022919261,-0.010416761,0.010165272,0.011641054,0.01262584,0.022274095,0.031991354,-0.00631714,0.03518713,-0.001089325,2.30E+00,-0.012126488,0.023426134

-0.031941879,-0.008063259,-0.019602272,-0.003820659,0.005663064,-0.011199063,-0.006660091,-0.037087069,0.004641816,-0.004345471,3.07E+00,0.018745023,-0.00287241

0.059378171,-0.008948606,-0.019668735,0.002952199,0.006139335,0.01033389,0.001081666,0.015883046,0.01244184,0.002709295,3.44E+00,0.001929744,0.005786383

-0.059378171,-0.017660503,0.022154752,-0.015570663,-0.011304878,-0.0122902,-0.016635747,-0.009804,-0.025646392,-0.012581043,3.66E+00,0.000572492,-0.010391503

-0.01975915,-0.004055535,-0.026406201,0.005163329,-0.054239769,0.017746111,-0.004425178,0.015980672,-0.048819217,0.004475081,3.81E+00,0.002149768,-0.012896042

-0.011527505,-0.020949626,0.033274789,-0.016739594,-0.007073416,-0.015952974,-0.001588282,-0.035304945,-0.028638842,0.005937939,3.91E+00,-0.047354414,-0.012395922

-0.046194357,-0.006079046,-0.085809736,-0.006618158,-0.012259348,-0.021627699,-0.032442779,-0.047878379,-0.00871404,0.003978305,3.98E+00,0.038854059,-0.018860111

-0.032304289,-0.008449054,-0.030022079,-0.021319058,0.019332764,-0.004619682,0.004448254,0.008013781,-0.011409613,-0.000905551,4.04E+00,0.026597121,-0.009733767

0.067810978,0.049902562,0.055649574,0.032596127,0.026980054,0.036085138,0.047222464,0.051898438,0.040948824,0.00964082,4.09E+00,0.013235487,0.045991515

-0.056488846,-0.023721462,-0.009395254,0.008934614,-0.00227635,0.001649077,-0.007343097,-0.070122177,-0.032613127,0.001463326,4.12E+00,0.012663111,-0.014032142

0.001340483,-0.029780384,0.003512884,0.007883812,0.021605069,-0.00461058,0.016190316,0.06529125,-0.04660879,-0.002924513,4.14E+00,0.009414492,0.01186924

-0.112777609,-0.030953097,-0.054221554,-0.024350583,-0.057339108,-0.01289498,-0.042257308,-0.077630161,-0.034034699,-0.008360645,4.16E+00,0.022189128,-0.024376382

-0.015458096,-0.028049921,0.012297528,0.010650201,0.031196826,0.032638467,0.024106032,-0.015487035,0.022648371,-0.010084724,4.19E+00,0.006753898,0.006792521

-0.051175293,0.000988352,-0.060028931,-0.025328961,-0.034263641,-0.020564572,-0.021669129,-0.091210379,-0.008912248,-0.030874817,4.20E+00,-0.001245524,-0.016620881

0.157519577,0.0520445,0.056099652,0,0.023009865,-0.029118848,-0.042145621,0.042995363,0.091767402,-0.011229279,4.21E+00,0.014812763,0.034318463

0.060870715,0.024097552,0.016949558,0.027115075,0.039256524,0.030432909,0.011933918,-0.015568555,0.026668247,0.054725973,4.21E+00,0.003559426,0.030366589

-0.048325156,-0.028700039,-0.032514075,-0.030588808,0.010294897,0.021431172,-0.026200915,-0.023410738,-0.012843142,0.013334749,4.20E+00,-0.00023769,-0.023405077

0.046235291,0.011770977,0.029101102,0.049082795,0.073673882,0.042888219,-0.002467715,0.071943469,0.089439972,0.017249802,4.18E+00,-0.005845198,0.023756839

0.111798889,0.016929062,0.127626899,-0.009064191,0.038714512,0.01554527,-0.024187528,0.088093043,0.065194196,0.008266062,4.17E+00,0.007034212,0.037762881

-0.234749097,-0.064633791,-0.102323651,-0.055716163,-0.083760485,-0.044908346,-0.070883625,-0.184876339,-0.133531393,-0.052725959,4.16E+00,-0.009394188,-0.092749359

0.051779242,0.040536239,0.058769907,0.032306333,-0.028627909,0.014573768,0.015357122,0.018821754,-0.039778797,-0.014391294,4.12E+00,-0.01350159,0.012509936

0.041686486,0.044424707,0.026284367,0.006854643,0.035914801,0.019005018,0.035047972,0.060812139,0.093007112,0.036099816,4.10E+00,0.009632639,0.037913262

0.014290818,0.085711097,0.032874375,-0.003543747,0.052551495,0.023149182,0.005988986,0.003193191,0.050290821,0.035555164,4.09E+00,0.002970609,0.007381837

0.240601431,0.012278463,0.084037132,0.02757095,0.126362903,0.006506439,0.031473375,0.165407834,0.080699954,-0.002838492,4.09E+00,0.013478037,0.066995573

0.019366802,0.10635239,0.088632596,0.068911706,0.019429519,0.041464389,0.076419589,0.037159945,0.002853069,0.043644695,4.12E+00,0.004772519,0.052538377

-0.149185995,-0.060355165,-0.118129116,-0.028799687,-0.07002286,-0.046708998,-0.034271267,-0.129607254,0.037850224,-0.006688988,4.10E+00,-0.00730858,-0.077132835

-0.151083193,-0.115904801,-0.105637294,-0.028453412,-0.05709682,-0.019116259,-0.056241048,-0.095101651,-0.108841098,-0.033169257,4.06E+00,-0.001502749,-0.066224216

0.010589113,-0.004788517,-0.003108489,-0.010976557,0.00577581,0.016054572,0.022282779,0.056851769,-0.052490183,0.017411709,4.02E+00,-0.000553076,0.018661799

-0.0884519,-0.076312093,0.005602256,-0.023599252,0.040843936,-0.009307388,-0.036496865,-0.065159189,-0.041730672,-0.01722201,4.00E+00,-0.001184133,-0.013365299

-0.040578359,-0.010566579,-0.051106011,-0.027603067,-0.079071731,-0.002135612,-0.021492709,-0.080440369,-0.067316222,-0.041254456,3.95E+00,0.011904903,-0.05119516

0.005865119,0.019160498,0.03439253,0.054391388,0.072510746,0.040451693,0.080611963,0.08354757,0.059775845,0.042963372,3.93E+00,-0.000399122,0.060473816

-0.094775277,-0.029327615,-0.089208675,-0.01382145,-0.037437527,-0.041162551,-0.048277311,-0.068162651,-0.074386951,-0.039681093,3.99E+00,-0.017170181,-0.044998764

-0.050548664,-0.040697658,-0.021978907,-0.007596347,-0.012282652,0.018044259,0.001849284,-0.025879448,-0.006317835,0.014420255,3.91E+00,0.010527644,-0.013191247

0.018222617,-0.00379096,0.02795881,0.038797019,0.02889778,0.023715084,0.038844415,0.030572089,0.029172787,0.016685593,3.86E+00,-0.001096921,0.03248445

-0.077899412,-0.050076338,-0.083141667,-0.005379973,-0.071224237,-0.033224441,-0.034051209,-0.0777969,-0.062298207,-0.01189384,3.86E+00,-0.007800352,-0.057005542

-0.120283101,-0.015306421,-0.041283504,-0.02864894,-0.05270624,-0.031291004,-0.01675287,-0.085051233,-0.091086946,-0.036281868,3.83E+00,0.00389257,-0.042936402

0.038226507,0.023048395,0.073404542,0.012680537,0.04396832,0.01306525,0.023127765,0.060974403,0.050339126,0.002854596,3.79E+00,-0.000155994,0.033417447

-0.023441844,0.005194817,-0.010822059,0.031060479,-0.047661769,-0.01565794,-0.002959273,0.05951012,-0.020141668,0.002862768,3.76E+00,0.005082305,0.002887493

0.059229237,0.029064133,0.008234735,-0.013525905,0.077587966,0.00103627,0.027593394,0.021878721,0.044077954,0.019175696,3.71E+00,-0.021557907,0.005488545

0.020399821,0.009427679,0.00778214,0.018303528,0.036515213,0.011994929,0.00079968,-0.045933333,-0.058922363,-0.004919387,3.68E+00,0.020539377,0.03400898

-0.030880266,0.051364517,-0.014991234,-0.031427951,-0.013849926,0.009841907,-0.028548583,-0.020906685,0.055801424,-0.002722572,3.64E+00,0.019292186,-0.007278987

0.114476172,-0.002844952,0.094643393,0.098386731,0.152708351,0.089744629,0.063222847,0.153432547,0.163848727,0.105018198,3.56E+00,0.005282971,0.110516942

-0.025962997,-0.053379186,-0.005624312,-0.014524584,-0.020558727,-0.024805699,0.012668948,0.107036962,-0.007011155,-0.034237043,3.52E+00,-0.01085579,-0.0361464

-0.087643988,-0.036232973,-0.052974438,-0.034253969,-0.051554888,-0.046400076,-0.031864025,-0.090825867,-0.030219203,-0.026115155,3.45E+00,-0.016846813,-0.052045539

0.01489296,-0.025262612,-0.008474627,-0.052476987,-0.013710113,0.025511588,0.055973851,-0.0916821,0.015444322,0.009330735,3.43E+00,-0.0025728,0.011517705

-0.056201793,-0.027847214,-0.070749415,-0.014221878,-0.045777018,-0.017382196,-0.031297488,-0.050873822,-0.120804838,-0.026431593,3.40E+00,-0.026205057,-0.055993177

-0.017780084,-0.016852273,0.010373025,-0.00929837,-0.027202088,-0.030546271,0.043052161,0.059296894,-0.009766476,-0.014061286,3.32E+00,-0.018040177,-0.03031002

0.0487082,0.037758958,0.025648879,0.049866938,0.022530395,0.054966836,0.017895214,-0.012144007,-0.033577535,0.012199782,3.34E+00,0.00149098,0.058343802

-0.042541685,0.054528428,-0.013158085,-0.035122525,0.050993522,-0.01219302,-0.013713295,-0.06209822,0.037789175,-0.015684425,3.54E+00,-0.0076549,-0.005989963

0.017891053,-0.008200019,0.032706032,0.034896307,0.01151013,0.054914277,0.046278915,-0.018158735,0.059504174,0.08737761,3.57E+00,-0.008698271,0.040813108

-0.107750604,-0.041790966,-0.079842888,0.010916642,-0.055227112,-0.083156559,-0.082291036,0.026043139,-0.107653517,-0.084076672,3.67E+00,-0.009277928,-0.103637192

0.151954325,0.003289893,-0.007168489,-0.077629906,-0.042385716,-0.021718873,-0.00420204,0.251691431,-0.025562876,-0.001101524,3.60E+00,0.008250932,-0.014910813

0.061253713,-0.019646997,0.123087779,-0.042459208,-0.019364367,0.02409298,0.014105653,0.184512138,-0.014222701,-0.008598841,3.66E+00,-0.007556619,-0.024554805

-0.1185186,-0.019268419,-0.082750163,-0.090680542,-0.046569828,-0.025216996,-0.069839865,-0.249119038,-0.095721887,-0.059674111,3.45E+00,-0.00357495,-0.07239758

-0.072846673,-0.048426594,0.017094433,-0.039090904,-0.021216837,-0.028789588,-0.044322919,-0.087353199,0.035489185,-0.005302142,3.48E+00,0.00723608,-0.025515204

-0.304163096,-0.062263207,-0.05183502,-0.032331693,-0.058181955,-0.038891808,-0.049290289,-0.131061239,-0.060595106,-0.05429753,3.48E+00,-0.000146703,-0.045819981

-0.067792068,-0.057537993,-0.008847555,-0.031889841,-0.038849035,-0.052491177,-0.025079684,-0.108488348,-0.03046393,-0.031117022,3.50E+00,-0.014562657,-0.052276386

-0.053364813,0.009073296,-0.026534036,-0.019403453,-0.041416613,-0.027026459,-0.015361285,0.131842203,-0.02354115,0.014842573,3.31E+00,-0.004975314,-0.01359218

-0.047257115,0.009375409,-0.100835621,-0.010393561,-0.035045198,-0.028359396,-0.026920943,0.125725889,-0.05526749,-0.013669945,3.26E+00,-0.012721727,-0.036948611

0.085653312,0.037950983,-0.040005335,0.023917433,-0.019608471,0.031272491,-0.01355953,0.08483888,-0.037599195,-0.003847767,3.01E+00,-0.015642935,0.000603318

0.145851877,-0.014232704,0.098845835,0.0356115,0.031299447,0.025276251,0.029564658,0.151549898,0.035273366,0.024337858,2.94E+00,-0.003210948,0.040556202

-0.193280571,0.007429957,-0.088993538,-0.02801845,-0.063285559,-0.049296622,-0.046115558,-0.528844129,-0.083432294,-0.037936741,3.08E+00,-0.020077255,-0.081602329

0.065592664,-0.003384098,-0.016886323,0.019627338,0.023997842,0.014824532,-0.004023572,0.010772097,0.02458576,0.009765864,2.84E+00,-0.004089985,0.000496607

0.038557564,-0.007851975,0.043372623,0.024989003,0.008832865,0.013581454,0.01677552,0.061798596,0.019300961,0.020161973,2.67E+00,0.000680504,0.015518416

-0.00693087,0.039891329,-0.014533966,-0.009715552,0.002114613,-0.005681372,-0.006251383,-0.052367986,-0.005062277,0.008864702,2.72E+00,-0.002787127,0.003200272

-0.025205189,-0.012709588,-0.046975368,-0.013717636,-0.007171514,-0.012706243,-0.024339068,-0.128416292,-0.005840315,-0.008355407,2.60E+00,0.010920865,-0.02301444

-0.093044871,-0.053644146,-0.017813622,-0.025745899,-0.070588907,-0.022284605,-0.027620671,-0.238411023,-0.068296511,-0.013660723,2.53E+00,0.023259284,-0.022899587

0.203461257,0.078049773,0.071222467,-0.012628572,0.058887979,0.000312647,0.030453534,0.304660409,-0.04061192,-0.029379898,2.48E+00,-0.018512603,0.033173934

0.117129227,0.020202707,0.058131765,0.013767308,0.059041953,0.022771382,0.023682485,0.295014828,0.035560932,0.030385429,2.99E+00,0.019355892,0.029239873

-0.082866771,-0.002398083,-0.068964369,-0.040746033,-0.072658834,-0.027917593,-0.012700416,-0.076995113,-0.076836632,-0.041063414,3.00E+00,-0.003018499,-0.046005348

0.107053996,0.039077011,0.018526507,0.001824818,-0.004905979,0.008905613,0.012264781,0.054256526,0.043619522,0.008241139,2.76E+00,0.008163885,0.016598919

-0.239654329,0.008755528,-0.08378803,0.004576667,-0.036047155,-0.005321659,-0.018269946,-0.049988487,-0.033022706,-0.012576754,2.81E+00,0.006024755,-0.048754476

0.020359985,0.017488724,-0.051368058,0.006442728,0.005522696,-0.00777488,0.002998075,0.049988487,-0.006440966,-0.012103986,2.37E+00,0.009428641,0.004610501

0.02016567,0.004099416,0.00248889,0.00629865,0.001979807,0.021290723,0.018179696,-0.010733556,0.015563836,0.018372591,2.36E+00,-0.011417278,0.014364489

-0.003696862,-0.014907583,-0.001067426,-0.001300028,-0.016509809,0.00015824,-0.011149033,-0.027206593,0.009206864,0.01445417,2.29E+00,-0.003541331,0.004049572

-0.065748582,-0.010692598,-0.033913406,0.009323208,-0.064538521,0.012260324,-0.024604811,-0.05802384,-0.029272093,-0.014131641,2.27E+00,-0.004936889,-0.030136968

0.074706171,0.021245109,0.042484887,0.027539486,0.060647466,0.034553633,0.028355537,0.098665476,0.050666167,0.020531925,2.18E+00,-0.002318964,0.020445404

0.051897687,-0.008653655,0.006477173,0.004245471,-0.000776398,0.004654264,-0.007917698,0.054668544,0.022047558,0.015931303,2.18E+00,-0.016774362,0.003139467

-0.074294696,-0.017210399,-0.030924803,0.000967399,-0.035827002,-0.027930187,-0.015508599,-0.046520016,-0.021684054,-0.000167266,2.19E+00,0.003249337,-0.030568852

0.010062594,0.003743453,0.001401051,-0.005790404,0.014329054,-0.019097106,-0.004085951,-0.004535155,-0.000545207,0.002344274,2.12E+00,-0.005180106,-0.000859812

0.046738944,0.024680111,0.015186589,-0.002114775,0.066337835,0.014570749,-0.006726483,0.175647048,0.037390993,0.009770967,2.06E+00,-0.007207362,-0.006231035

-0.009269684,-0.007150184,-0.025646935,-0.019964538,-0.010496665,-0.014252784,-0.012491488,0.038487433,-0.016090151,-0.013619378,1.91E+00,-0.002440183,-0.010811751

0.058300725,0.019268419,0.021385565,-0.012534071,0.012121361,0.012963293,0.024858144,0.051765438,0.019301639,0.009901902,1.87E+00,0.000270838,0.012054856

0.021476878,0.000778513,-0.001770225,0.00503216,0.00162734,-0.000805088,0,0.013072082,-0.00189036,0.004903214,1.88E+00,0.011510428,0.009686819

0.00206968,-0.003757211,-0.001767097,-0.000933794,0.017248888,0.000805088,-0.000141393,0.021766276,0.020607484,0.007656354,1.82E+00,-0.011510428,0.002908693

-0.042257428,-0.000904802,-0.027856955,-0.014823321,-0.02938987,-0.021355393,-0.021677655,-0.036018299,-0.015115566,-0.01508631,1.89E+00,-0.002772614,-0.020493958

0.039498805,0.009085072,0.012787456,0.015943979,0.0117339,0.017657343,0.019135998,0.039692523,0.030854742,0.015940646,1.76E+00,-0.000405104,0.01437197

-0.008571971,-0.005201572,0.003484324,-0.015576061,0.011049836,-0.001924003,0.003107347,-0.047913356,0.019180024,0.002396031,1.83E+00,0.005414931,0.001722923

0.042188582,-0.011605546,-0.002092051,0.000368053,0.018692133,-0.000480423,-0.00873245,0.030881314,0.007414121,0.002745369,1.87E+00,0.003876106,0.004635276

-0.042529937,-0.006134989,-0.022047052,0,-0.028520222,-0.013200987,-0.015860099,-0.019116472,-0.006615239,-0.010766574,1.78E+00,-0.001837923,-0.010964163

-0.046675139,-0.019182819,-0.015215847,-0.013346939,0.001631322,-0.005357718,-0.014252674,-0.074107972,-0.026615667,-0.009137119,1.71E+00,-0.001698774,-0.013768782

0.017083201,0.027114292,0.009440394,0.000726744,0.028567457,0.000471587,0.006142106,0.024472857,0.034639782,0.021623384,1.68E+00,-0.012012562,0.004851575

0.0447229,0.022864077,0.007139245,-0.003447341,0.031139219,0.012976919,0.001095891,0.06034313,0.032340109,0.003793762,1.63E+00,0.000268366,0.007516211

-0.075715431,-0.008635406,-0.014564186,0.007636401,-0.041584269,-0.018308592,-0.00873368,-0.080410693,-0.026482098,-0.023393878,1.54E+00,-0.000268366,-0.006048406

-0.069784934,-0.018585976,-0.007036384,-0.010168964,0.01044505,-0.030951736,-0.010542063,-0.09671397,-0.037184918,0.01171391,1.54E+00,-0.00701898,-0.01045922

0.034438875,0.015983841,0.010404524,-0.001083424,0.044222702,0.004254679,0.012173828,0.034661982,0.04982525,0.01202557,1.39E+00,-0.004121524,0.010304613

0.022895778,-0.001558037,0.036767584,0.025590868,0.084221753,0.059768433,0.03180138,0.017792201,0.063089701,0.015677032,1.44E+00,-0.025995898,0.018410692

-0.059429522,-0.006207987,-0.014938614,-0.024688097,-0.014224991,-0.004516137,-0.008811862,-0.068359091,-0.047998975,-0.064582411,1.44E+00,-0.000452357,-0.015003798

-0.003878865,0.007506183,-0.008583744,0.00816183,-0.009838449,-0.003052947,-0.00097432,0.02092752,0.000416667,0.006936444,1.29E+00,-0.000581301,0.004430805

0.029005054,0.005732168,0.037621992,0.018565003,0.04823088,0.028973381,0.030080641,0.055915185,0.064107969,0.032165777,1.27E+00,-0.005088086,0.026605082

-0.021532295,-0.015556445,-0.001418943,0.014200538,0.006872879,0.012965607,-0.005718386,-0.014799424,0.007358713,0.011706107,1.23E+00,-0.000513809,-0.009317209

0.012985235,0.015033979,-0.00283186,0.031348133,-0.000984737,-0.00033456,-0.003415401,0.005260401,-0.012234609,-0.014952586,1.20E+00,-0.002372937,-0.005296664

-0.021350984,0.006287681,-0.023752426,0.003696143,-0.009306949,-0.010978154,-0.01284512,-0.027056801,-0.014486645,0.001024066,1.14E+00,0.001410257,-0.013314733

0.042236264,0.023937313,0.019871667,-0.005054443,-0.010186845,0.012484557,0.011425472,0.022846269,0.004586663,0.019136865,1.03E+00,-0.007413596,0.017660676

0.138242303,-0.004029555,0.025317808,0.008177616,0.053531114,0.03251627,0.012275347,0.09237332,0.038380436,0.025206234,9.62E-01,-0.002607232,0.021127546

-0.052753383,-0.010666768,-0.036174157,-0.017634407,-0.01716347,-0.014771825,-0.018779895,-0.045052664,-0.013780857,-0.014355585,1.06E+00,0.000762389,-0.014772266

-0.035207888,-0.019958646,0,0.003849119,-0.020312811,0.004785516,-0.001408451,-0.11238425,-0.006931274,-0.002460458,8.84E-01,0.003629306,-0.000239053

-0.087446443,-0.020332704,-0.021365389,-0.012265389,-0.038956597,-0.02185972,0.003524854,-0.149641089,-0.029420344,-0.019468719,1.00E+00,-0.004074103,-0.020972071

0.033138767,-0.002798628,0.028706796,0.022148233,0.026770241,-0.007680786,0.007087202,0.034486176,0.005641152,-0.016560344,7.58E-01,-0.011244591,0.005398018

0.124606883,-0.000254033,0.02883275,0.034674103,0.044077449,0.006173374,0.022586014,0.091807549,0.006548812,0.030078748,8.46E-01,0.00383926,0.011280836

0.038184835,0.005859143,-0.011133173,-0.008631992,-0.009072643,-0.011481947,-0.003050776,0.028280773,-0.026155171,-0.01058762,8.71E-01,0.002652019,0.000555489

0.036677569,0.012598187,0,-0.006177164,-0.008493681,0.001158845,-0.007370508,0.032163576,-0.014824499,0.004152255,8.68E-01,-0.002084321,0.006210706

0.156102268,0.019595663,0.011494379,-0.038960907,0.039061522,0.003484613,0.011731614,0.200670695,0.029655507,0.012561226,8.46E-01,-0.0024577,0.009953526

0.202191235,-0.011020841,0.03792098,0.010563817,0.055850727,0.02695581,0.013936997,0.152072109,0.055656472,0.01272102,9.89E-01,-0.00639942,0.024251035

-0.084353059,-0.006502819,-0.019692258,0.016156069,-0.038631413,0.008058338,-0.019457859,-0.035692582,-0.005479466,-0.001243892,9.85E-01,0.008983319,-0.01419744

-0.072724527,-0.013391908,-0.017505918,0.013632534,0.005277057,0.013343929,0.00435604,-0.180449773,-0.018498159,0.00035524,8.29E-01,0.000757528,-0.009085072

-0.031344833,-0.016491557,0.000723327,0.004585792,-0.027141541,-0.019350984,-0.002906134,-0.104423308,-0.003347097,-0.016211809,6.44E-01,0.008052543,-0.011720452

0.013507634,-0.002764168,0.01641474,-0.016843755,-0.040368751,-0.013765193,0.004070956,-0.012578782,-0.052717986,-0.008008399,7.92E-01,-0.000445534,0.004078537

-0.064935088,0.004527171,-0.031495816,-0.011332673,-0.02924185,0.012397204,-0.034226868,-0.131576358,-0.028129785,-0.024663007,7.53E-01,0.001783326,-0.019442742

0.08925379,0.006575643,0.034811347,0.003503312,0.035691884,0.02002138,0.016752237,0.127418348,0.031304727,0.037929042,6.45E-01,0.002297531,0.017601342

-0.039613647,0.011740819,0.007035763,-0.003697581,-0.006450035,0.002968138,0.005599038,-0.067193189,0.005740422,0.005462087,6.22E-01,-0.001277058,-0.010265478

-0.00623055,-0.013515442,0.014975944,0.002139038,-0.000494438,-0.004187757,0.014209315,-0.026795862,0.004487666,0.001768347,4.61E-01,0.004985653,0.001029744

-0.054814152,-0.012835208,-0.022749443,0.007228712,-0.018609744,0.002440726,-0.018805704,-0.090232498,-0.017831082,-0.009336807,3.49E-01,0.001963206,-0.017285157

-0.00251678,-0.00324554,0.0159825,-0.019033396,-0.006769852,0.018853523,0.002726557,0.060462858,0.022123855,0.014660688,2.71E-01,0.000697549,0.003120614

-0.029717416,-0.001121007,0.016242095,0.002696977,-0.005766474,-0.004968073,0.001150252,0.011987234,-0.029251768,-0.001777778,2.84E-01,0.001015486,0.003522371

-0.008906941,-0.005214812,-0.010229299,-0.026272214,-0.015688461,0.000885348,-0.01073202,-0.032849669,0.004816259,-0.00936982,2.32E-01,0.001080085,-0.005473895

-0.070040287,-0.007279938,-0.053571135,-0.01639992,-0.042932972,-0.027949418,-0.032348966,-0.038737238,-0.045947376,-0.022445483,1.35E-01,0.008426478,-0.027535965

-0.000375728,-0.006128221,0.014393915,0.013585396,0.009991,0.017902625,0.001931035,0.019181059,0.014336439,0.013860236,-5.68E-02,0.001989284,0.004714838

0.028192343,0.006620105,0.006910375,0.00206321,0.005951036,0.000175392,-0.007290768,0.044091712,0.008783633,0.011934154,-1.75E-01,0.00302358,-0.001979897

-0.046063258,-0.021657982,0.000730194,-0.007482265,-0.047083343,-0.006817612,-0.00082203,-0.031691199,-0.025122877,0.006731646,-2.76E-01,-0.005717789,-0.00098848

-0.037658324,-0.002164243,-0.019172228,0.005606443,-0.031899256,-0.02051973,-0.014952025,0.003571432,-0.035767224,-0.025100045,-1.99E-01,0.008298269,-0.021354195

-0.008140197,-0.008610433,-0.010691477,0.003755168,0.017979936,0.006506872,-0.00242555,-0.019486888,0.018510027,0.000346741,-3.97E-01,-0.000774843,0.001265493

-0.030205386,-0.001903403,-0.022780028,-0.014936797,-0.012449184,-0.017033285,-0.008977082,-0.110348057,-0.030980212,-0.017532247,-3.26E-01,0.001033258,-0.009784379

-0.036269926,0.002141583,-0.003804258,-0.004068805,-0.025691032,-0.012253615,-0.003063197,-0.077077412,-0.012128252,-0.010508571,-4.48E-01,0.001163693,-0.004856522

0.017970534,-0.01160463,-0.006194101,-0.022628703,-0.003735219,-0.00016682,-0.012159811,0.03477968,-0.008440451,0.002194279,-6.69E-01,0.007988352,0.000587415

0.011482733,0.005193591,0.003436429,-0.030563857,0.036275593,0.010227267,0.007516354,-0.015689526,0.025154991,0.001183532,-6.70E-01,-0.005267791,0.012564836

0.020244301,0.001184133,-0.026496115,0,0.018643506,0.009992462,0.00371304,-0.014716969,0.011558595,0.010031539,-6.56E-01,-0.006336501,0.003800444

-0.026339816,-0.001184133,-0.016622723,-0.015111013,-0.019931336,-0.01721271,-0.009651691,-0.050562567,-0.030154957,-0.021302581,-3.81E-01,-0.00070874,-0.014821673

0.000337667,-0.004015595,0.008941937,0.037766849,0.003437906,0.007725937,0.00237123,0.004175371,0.014010074,0.003519065,-5.27E-01,-0.016480731,-0.004989737

-0.029614541,-0.010319041,0.001331558,0.001074691,-0.012406576,0.040604236,0.012742408,-0.074556168,-0.001333715,0.020350032,-6.60E-02,0.011918181,0.002418381

-0.04769667,-0.015970713,-0.034056992,-0.024605189,-0.045707998,-0.019131018,-0.034658234,-0.068172686,-0.039389133,-0.024203602,2.15E-01,0.012581217,-0.03241342

0,0.001148765,0.019834824,0.008604847,0.023840011,0.001206585,0.014818938,0.006672758,0.007902274,0.036095168,1.32E-01,-0.004146695,0.019799786

-0.040434298,-0.027212564,-0.000328353,0.005305052,0.002916061,0.007270241,0.001703913,-0.015101465,-0.014652277,-0.001559117,1.32E-01,-0.008178029,-0.000507044

-0.008072999,0.018059182,0.001642846,-0.010582109,-0.003747662,-0.017053208,-0.000262329,-0.035917903,0.040443278,0.009915711,1.10E-01,0.00462815,-0.005848603

-0.012723947,-0.024303626,-0.010142407,-0.004551032,0.00249688,-0.013065427,-0.017034415,-0.030193122,-0.010171495,-0.009396276,2.63E-02,0.000837926,-0.010385053

-0.017199083,0.021801066,0.002607563,-0.010596816,-0.016119382,-0.002693604,-0.00257533,-0.041225953,-0.007282265,-0.003457818,-1.45E-01,-0.002768925,0.00249688

0.021324015,0.014418375,0.002941659,0.007458191,0.009474839,0.013370767,0.011121284,0.02674102,0.02696496,0.014779022,-3.86E-02,-0.006729285,0.005012542

-0.008818399,0.009961857,0.004922077,-0.019823109,0.027272511,0.009931588,0.009538192,-0.051735674,0.003254526,0.012159811,-1.67E-01,-0.006620854,0.004604987

0.007048487,0.039174148,-0.000986355,-0.000682477,0.008972502,0.006560797,0.004737474,0.020159834,0.002111528,0.011591748,-5.99E-02,-6.34E-05,0.007383313

-0.023304288,0.005949869,-0.018880769,0.00615913,-0.006843483,-0.013762474,-0.010888924,-0.025398191,-0.018467921,-0.005366739,5.75E-02,-0.000825475,-0.013494702

0.002883508,0.011144565,0.000645161,0.028195394,0.003415887,-0.004262218,0.006808091,0.012618464,0.002644505,0.014737866,-1.67E-01,0.000126952,0.000143369

-0.021708936,-0.010047873,-0.023282825,-0.007736983,-0.016122538,-0.015195295,-0.018353916,-0.042978398,-0.026503978,-0.012952151,-1.09E-02,0.007263029,-0.017059195

-0.019863571,-0.00450095,-0.021211026,-0.007503743,-0.020413123,-0.012819621,-0.019415605,0.001014199,-0.011537533,-0.008010724,1.31E-02,0.003972327,-0.00814211

-0.001937181,0.010370373,0.00836825,0.007854129,-0.026049499,-0.001322533,0.004945797,-0.023070231,0.000728597,-0.011283618,-5.20E-02,0.005084484,0.002730043

-0.014819152,0.002947681,-0.007441895,0.001051894,-0.009994087,-0.005437035,0.010222425,-0.055449247,-0.004000733,-0.001401542,-1.59E-01,0.001549787,0.000911673

-0.002448648,-0.013318054,-0.004315666,0.008278339,0.0095924,0.006925007,0.001671059,0.007060514,0.022947313,-0.005760686,-1.57E-01,0.00226442,0.012425151

0.005176418,-0.006894494,0.005552143,0.000707714,0.020694591,-0.012005736,0.007100927,-0.012206724,0.011204599,0.014023017,-2.46E-01,-0.002199794,0.002062223

-0.022418224,0.012859573,-0.002162831,0.00177148,-0.012225091,0.004916431,-0.006328726,-0.014362072,-0.004309948,-0.023895791,-1.98E-01,0.002782903,0.000142379

0.021326223,-0.020305266,0.004020417,0.004442477,0.02004567,0.027143453,0.017534055,0.026568797,0.023459267,0.014583592,-5.77E-02,-0.001813002,0.011168501

-0.018383865,-0.023881026,-0.009867487,-0.002490218,0.002896754,-0.008906873,-0.008220833,-0.013605652,-0.001912412,0.000349834,1.16E-01,0.007206653,-0.001870101

-0.017788867,0.004097167,0.000613874,-0.013060546,-0.032616018,0.006546394,0.003514942,-0.020752416,-0.020798632,0.005789998,9.70E-02,-0.005393651,-0.00258361

-0.032110475,-0.019169916,-0.013115942,-0.021509936,-0.0190709,-0.018520593,-0.013986242,-0.042445505,0,0.008482115,7.32E-03,-0.006331179,-0.017971148

0.006904515,0.002650229,-0.005439723,-0.001885984,-0.001572946,-0.00626238,0.002704271,-0.001311476,0.00468912,-0.010942573,-5.93E-02,0.004388803,0.008625619

-0.020823505,-0.026079027,-0.004810593,-0.006658155,-0.026368337,-0.001313413,-0.012812475,-0.025022876,-0.013445581,-0.009260134,-1.26E-01,0.000129374,-0.004816897

0.010103647,-0.002694209,0.006620548,-0.005430185,-0.005343524,0.000492328,0.009079927,0.018491174,-0.006102654,-0.009864232,-1.61E-01,-0.005290676,0.002759794

-0.008488115,0.016742473,-0.003663008,0.002551239,-0.013015368,-0.010352405,0.000520291,-0.019426859,-0.018092445,-0.010807207,9.06E-02,-0.001992865,-0.005913337

-0.008416673,0.02588543,-0.010607767,-0.004418019,-0.004691174,0.010184578,-0.003506725,0.003136906,0.002961868,0.021732487,-1.47E-01,-0.003653967,-0.00394676

-0.003138078,0.009645999,-0.004812039,-0.005916677,-0.014711841,-0.001341607,-0.008906158,0.002696631,-0.00074129,-0.005217403,-1.91E-01,0.002049706,0.000214877

0.011290654,0.001182732,0.015724545,-0.015387492,0.039189968,0.001509434,-0.016693602,0.016334301,0.020210269,0.003475242,-2.98E-01,-0.011031516,0.009211349

0.02703229,-0.002600167,0.013810255,-0.001161151,0.02386362,0.015050593,-0.018778719,0.067654074,0.0098785,0.009268231,-1.69E-01,-0.010785686,0.004347203

-0.00379096,-0.001179663,0.0009275,0.007154177,0.004512828,0.005809996,-0.006798123,-0.018909654,-0.00476146,0.006521571,1.18E-02,0.000564777,-0.00159617

-0.01635206,-0.007985012,-0.00401297,-0.007651401,-0.020753542,-0.005469164,-0.014188105,-0.008132071,-0.035831413,0.003010717,-3.14E-02,0.002073581,-0.004412463

-0.024945497,-0.003036321,-0.007060659,0.00398473,-0.000805153,0.00632643,-0.006778046,-0.028647181,-0.00091617,0.001242346,-1.00E-01,0.00745,0.00050536

0.028674857,0.001400234,0.020708513,-0.009437937,0.012960894,0.016778046,0.027516258,-0.00415801,0.022035888,-0.006372831,-1.30E-01,-0.005813235,0.010380088

0.013163387,-0.008835212,-0.006536988,-0.007715708,0.002040401,0.00261986,-0.000495847,0.066230439,-0.004110619,-0.007033614,5.60E-02,-0.003522016,0.001460387

0.038593544,0.006968669,0.007786988,0.003440089,0.011503824,0.021567037,0.02319417,0.008906541,0.020533829,0.014117051,3.46E-01,0.006298043,0.026733422

0,0.000932836,0.007217982,-0.000984091,0.007049583,0.007533668,0.007383866,0.080705618,0.011100592,0.020104788,5.62E-01,-0.002586997,0.002329339

-0.037511293,-0.015741066,-0.009404458,0.011707612,0.001665973,0.002523888,-0.002679769,-0.06315691,-0.000192437,0.006366552,6.24E-01,0.002271151,-0.003379523

-0.020099833,-0.005725425,-0.136841042,-0.017102867,-0.022259781,-0.008089932,-0.023675706,-0.009564634,-0.022639605,0.002558013,6.04E-01,-0.002649175,-0.019599737

-0.006347548,-0.002508839,0.008471153,0.009008332,0.050156772,0.001971503,0.009503635,-0.010961744,0.015545337,0.009558896,3.53E-01,0.009430151,0.00139783

-0.011794135,-0.005678607,-0.013898575,0.004452147,-0.029146731,-0.002329541,-0.003637052,-0.016708005,-0.017424683,-0.005709565,3.63E-01,0.00203692,-0.007262089

-0.028764181,0.002267575,-0.008354718,0.002316348,-0.007878954,0.003945486,-0.00387331,-0.030239885,0.009242733,0.004048589,1.36E-01,6.37E-05,-0.001022719

0.002281081,0.008206109,-0.008019289,0.00198972,-0.002063133,-0.001257071,-0.004106782,0.011412392,0.001896814,-0.003129893,1.27E-02,-0.001846252,0.000511229

-0.024067344,0.006199079,-0.00742709,-0.005132037,-0.002470154,-0.009289099,0.004356221,-0.042141067,-0.010951771,-0.009695493,2.03E-01,0.012544967,-0.00109517

0.001735466,-0.005168564,-0.004745593,0.00165262,-0.010634047,-0.007440247,-0.009188046,0.004595596,-0.003748833,0.00859316,5.21E-02,-0.006804057,0.00248411

-0.01380012,-0.017150741,-0.010726068,-0.016079099,0.003668233,-0.004402578,-0.005054563,0.012048339,0.003373317,0.007002056,6.24E-02,-0.001789595,0.000658593

0.07493666,-0.007404948,0.037650258,0.009320646,0.065382759,0.020234982,0.027047202,0.082571154,0.049841965,0.026228555,1.82E-01,-0.009659455,0.034555527

-0.004211641,0.004705891,0.010866719,-0.001149331,0.011839647,0.005213495,0.015277191,0.005076153,0.01972765,0.010687125,3.56E-01,0.001012402,0.00349173

-0.014861439,0.018590424,-0.005991303,-0.006053188,-0.015320939,0.000540882,0.001155253,-0.045756365,-0.025629693,-0.004785156,2.82E-01,0.000633272,-0.009610729

-0.030583423,0.020342819,-0.008112538,0.0026131,-0.008219817,-0.002701487,-0.010222425,-0.029223637,-0.028045548,-0.010069431,2.39E-01,0.004826019,-0.003158135

-0.027968659,-0.004194833,-0.003763445,-0.004242826,-0.02004759,-0.010733556,-0.004059889,-0.042520268,-0.019080583,-0.002831526,2.51E-01,0.009015695,-0.012311291

-0.035486821,-0.009489714,-0.003481991,0.00375235,-0.025433933,0.007680666,0.00431418,-0.001808319,-0.003735529,-0.010873748,1.31E-02,0.009421856,0.000964499

0.082115247,0.019156562,0.052009531,0.017851714,0.054856742,0.014063888,-0.018927208,0.062698594,0.043132845,0.047119571,8.10E-01,-0.017291127,0.013414835

-0.009549692,-0.009333868,-0.015335586,0.009215111,-0.017132971,-0.021934342,-0.018452088,0.019302752,-0.016810442,-0.003930823,7.97E-01,-0.005021782,-0.025081822

0.079357952,0.014151455,0.051380678,0.029378714,0.085833544,0.010446352,0.030605675,0.025817683,0.050065737,0.020410894,5.84E-01,6.34E-05,0.040703515

0.007536672,-0.017050512,0.014967264,0.002777297,-0.028333228,-0.009169329,0.012561047,-0.037740328,-0.027053414,0.002605995,7.99E-01,0.013341617,-0.01015867

-0.039824018,-0.003698571,-0.012634221,-0.024043748,-0.025246783,-0.002006019,-0.01979504,-0.06036315,-0.014543538,-0.015535066,6.15E-01,-0.001027683,-0.015616945

0.002966161,-0.005292844,0.008503203,-0.00440231,-0.006901339,0.021918181,0.008381001,0.006529874,-0.010428034,0.006145326,1.08E-01,0.006440416,0.00220524

-0.018462063,-0.009820794,0.016627461,-0.004719375,-0.018174058,-0.010189991,0.006011401,-0.025411393,-0.009545217,0.000795703,-2.41E-02,0.006352108,-0.009395432

0.066024248,0.008444647,0.052239219,0.01371392,0.027386467,0.008329525,0.032199875,0.093669191,0.006808703,0.028256168,-3.03E-01,0.002539147,0.035306814

-0.03969987,-0.022437202,-0.016581015,-0.00323377,-0.035904788,0.028850874,-0.013553731,-0.019841921,-0.014918421,-0.021266624,2.97E-01,-0.005007001,-0.013270925

0.006006024,-0.013357278,-0.019358417,-0.004239091,-0.010215501,-0.014623753,-0.018646144,0.019341044,-0.005178874,-0.001601923,-1.38E-02,0.006376909,-0.010354044

-0.027813322,-0.01905654,-0.024351121,-0.009766031,-0.048306071,-0.016825972,-0.012493788,-0.047430058,-0.010088598,0.008640665,-1.48E-01,0.008061653,-0.020915104

-0.032231272,0.007404215,0.004464958,0.005207908,-0.013383721,0.005763705,0.006609913,0.006227565,-0.004912158,-0.006437359,-5.52E-01,-0.000657851,0.0062964

-0.010261763,0.014531299,0.003586376,0.005912679,-0.010743905,0.008802379,-0.001019758,0.010628119,0.002830992,-0.000400962,-5.69E-01,0.00019731,-0.00382754

-0.014191825,-0.036046806,0.007814888,0.00953361,0.014907108,-0.017712778,0.001147301,-0.029195661,0.005686141,0.006031381,-6.46E-01,0.002370762,-0.002394136

-0.041405619,0.003106757,-0.021197987,-0.016961058,-0.029190151,-0.009381104,-0.017699577,-0.034310273,-0.02273893,-0.02213671,-7.90E-01,0.003037509,-0.022535957

-0.034641661,-0.005136998,-0.005009588,-0.009873731,-0.032293019,-0.012915141,-0.008485202,-0.056702521,-0.018592344,-0.014295749,-1.26E+00,0.005105266,-0.009815048

0.003738322,0.012459882,0.002354327,0.008865158,0.019810474,-0.020040034,-0.010014301,0.001292825,-0.001093693,0.000583487,-1.59E+00,0.011364518,-0.001012365

-0.005136598,-0.006464147,-0.007923739,0.01268087,0.019802627,0.007111141,0.003573853,0.003455727,0.030333378,0.021036852,-1.76E+00,0.003839552,0.007472196

0.007949539,0.001719691,0.019481136,0.008715769,0.037850224,0.006443552,0.016556051,0,0.022408837,0.007178495,-1.97E+00,-0.002090006,0.012529931

0.009197093,-0.011338232,-0.004164194,0.00464517,0.015378347,0.008294314,0.008951708,0.027639399,0.013729308,0.003608665,-1.88E+00,0.007571697,0.006138846

-0.017845038,-0.015618722,-0.01969204,-0.004130104,-0.003437906,-0.017410473,-0.012334958,-0.032818522,-0.038951087,0.001809228,-1.80E+00,0.005443672,-0.008348466

0.007006101,-0.003136437,0.002331003,0.002235022,0.007319731,0.009475355,0.001126479,0.031484892,0.022345183,0.000805153,-2.17E+00,-0.005850755,0.002947246

-0.000702823,-0.001043297,-0.002621997,-0.011295687,-0.008177364,0.006668494,-0.001251565,-0.018486442,-0.016146234,0.004439967,-2.03E+00,0.007216316,0.002807953

0.010831281,0.005437069,-0.000581734,0.003580261,-0.009385734,-0.005050516,-0.004243641,0.004808752,-0.001318143,-0.010663012,-1.83E+00,0.003276453,-0.000221967

-0.025477596,0.00020971,-0.017010645,-0.014244772,-0.025986374,-0.018892025,-0.013484462,-0.033185549,-0.025454231,-0.013713819,-1.95E+00,0.002738602,-0.008838534

0.011839953,0.023126097,0.017592379,-0.008884477,-0.00082713,0.004778347,0.028416668,-0.005074007,0.011068182,0.008126098,-1.90E+00,0.003296253,0.010171078

0.016007875,0.003009461,0.010529492,0.007034027,-0.003301695,0.006942618,-0.002273015,0.029967996,-0.0051804,0.013019713,-2.02E+00,-0.000275103,0.009228316

-0.000474496,0.011475713,0.005011064,0.004210533,0.027570669,0.006092117,0.009123226,-0.008654316,0.03168322,0.017080529,-2.04E+00,0.001996215,0.00509708

-0.028296054,0.011829273,-0.011458918,0.013594092,-0.015549799,0.02143588,-0.007103023,-0.041769413,-0.030021016,-0.02190757,-2.07E+00,-0.003851184,-0.00644197

0.024271903,-0.000440626,0.000876808,0.012741219,0.013011726,0.013494983,-0.000758054,0.021299615,0.059008553,0.020472996,-2.19E+00,-0.003562868,0.006592278

-0.00094451,-0.001100716,-0.000292355,0.005386165,-0.017588393,-0.002045181,0.001137297,-0.022951143,-0.03373814,-0.014839179,-2.11E+00,-0.004571982,-0.008084481

-0.038430655,0.009728133,-0.033346004,-0.021202208,-0.02824006,-0.000742666,-0.018539927,-0.034863685,-0.024345772,-0.01023797,-2.16E+00,-0.009553889,-0.027139007

-0.022457715,-0.004875896,-0.022089532,-0.010688031,-0.03060044,-0.006290493,-0.007912021,-0.02478978,-0.054018532,-0.021926804,-2.54E+00,-0.004037962,-0.012689428

0.019736007,-0.005951742,0.022372298,0.004397098,-0.033862412,0.01187398,0.019396356,0.022004817,0.028987537,0.008634277,-2.48E+00,0.001276925,0.015959898

0.044935767,-0.014401296,0.011948933,0.021067834,0.042115554,0.049154172,0.018116667,0.033531722,0.0564157,0.031634269,-2.43E+00,0.004043132,0.018070126

0.006417134,-0.006262843,0.005165004,-0.01341148,-0.017602645,0.005110074,0.002560165,-0.02395081,-0.007986352,0.003055926,-3.09E+00,0.002501438,-0.007385013

0.017801769,0.027279378,0.001151411,-0.014581472,0.015237646,-0.006285623,0.007461761,0.046806573,-0.012609558,0.006140011,-3.21E+00,0.001219182,0.004941924

0.042644042,-0.024044874,0.020955365,0.016975454,0.027541154,-0.057636945,0.025238345,0.042943481,0.035599076,0.012810093,-3.13E+00,0.003394436,0.016401143

-0.010582109,0.002378637,-0.018937201,-0.024855451,-0.027934777,0.001850139,-0.002909285,0.014140757,-0.026958903,-0.016907619,-3.34E+00,0.002860258,-0.014550867

-0.016652553,0.004121928,0.001733103,0.017010937,-0.02449102,0.018503472,-0.004873882,0.028437935,-0.025699738,-0.025236022,-3.56E+00,0.006088195,0.008406224

0.081625588,0.006761941,0.01573459,0.001359851,0.059329378,0.01062024,0.01242909,0.081531911,0.010349381,0.019324273,-2.87E+00,0.005504349,0.023736847

0.038718031,0.036554103,-0.007606824,-0.032630687,0.100662702,0.000953744,0.003331782,0.04782193,0.071809924,0.033481119,-3.24E+00,0.000828272,-0.010198734

-0.025797259,0.01302429,0.032585821,-0.021176879,0.018190588,0.008047562,-0.000667245,-0.019608471,0.003198723,0.002103935,-4.71E+00,-0.001157841,-0.010320631

-0.047098652,0.028696708,-0.039845909,-0.009784343,0.007832337,-0.008238384,-0.030739318,-0.078114826,-0.004794256,-0.000210593,-5.15E+00,-0.006851433,-0.026257934

0.0211579,-0.009657359,0.000868433,-0.015207009,0.040109174,-0.025432283,0.001553599,0.039523216,0.006196921,0.010584349,-5.35E+00,-0.00633468,-0.008649881

-0.034763552,-0.014313388,-0.026576789,-0.010788941,-0.003364579,-0.022075952,-0.016958269,-0.003435586,-0.012355677,-0.014367456,-5.42E+00,-0.000604412,-0.022258926

0.018528579,-0.01137355,0.008211854,0.008276771,0.025760841,0.011713165,0.011788963,-0.002935423,0.010752792,-0.001048328,-5.55E+00,0.006939092,0.008030459

-0.020566278,-0.019009398,-0.021100797,-0.027682894,-0.02287761,-0.068477275,-0.033338533,0.020232617,-0.031529705,-0.014149216,-5.67E+00,0.008827381,-0.008101238

0.014351861,0.033275632,0.00334635,0.004433241,0.005791522,0.012106685,0.000249377,0.024219145,0.032130486,0.031482138,-6.16E+00,-0.00122691,0.006532722

0.008554816,-0.02291051,0.011236073,0.026390852,0.006799443,0.00680928,-0.000249377,0.004094172,0.019622355,0.020028666,-6.19E+00,-0.001701549,0.010455552

-0.038058482,-0.00519599,-0.02179466,0.004098366,-0.028346842,-0.016506326,-0.011158063,-0.066939483,-0.000816827,-0.012752794,-6.40E+00,-0.001223325,-0.01628026

0.001253919,-0.024923408,0.003877047,0.023331196,0.001422138,0.017032042,-0.007981868,0.002400962,0.018749905,0.018205964,-6.50E+00,-0.000271647,-0.000849558

-0.011229064,-0.021739987,-0.020868412,0.001942062,-0.031748698,-0.015307309,-0.011431476,-0.112641636,-0.030519522,-0.014332493,-6.42E+00,-0.001763908,-0.0248117

-0.00643089,0.00972455,0.001087548,0.01042185,-0.01911756,-0.002930279,-0.000120912,0,0.001211143,-0.011149344,-6.70E+00,0.004415618,-0.000483108

-------------- next part --------------
# check code again to ensure it is right

# bond return calculation is wrong except t-bill

# security market line should only have stocks

# Loading generalized hyperbolic distribution facilities

library(ghyp)

library(fPortfolio)

library(stats)

library(timeSeries) 

library(fBasics)

library(fAssets)

library(fCopulae)

library(timeDate)

library(robustbase)

library(stabledist)

library(mnormt)

library(sn)

library(quadprog)

library(Rglpk)

library(slam)

library(zoo)

library(PerformanceAnalytics)  

library(utils)

library(graphics)

library(ggplot2)

library(plyr)



mydata <- read.csv(file.choose(), header = TRUE, sep = ",") 

print(mydata, zero.print = ".")# nicer to read

View(mydata)



ghypmv.fit <- fit.ghypmv(data = mydata, opt.pars = c(lambda = FALSE), lambda = 2,

              control = list(rel.tol = 1e-5, abstol = 1e-5), reltol = 0.01)

summary(ghypmv.fit)



nigmv.fit <- fit.NIGmv(data = mydata, opt.pars = c(alpha.bar = T, mu = T, sigma = T, gamma = !0), symmetric = F)

summary(nigmv.fit)



vgmv.fit <- fit.VGmv(data = mydata, lambda = 1, opt.pars = c(lambda = T, mu = T, sigma = T, gamma = !0), symmetric = F)

summary(vgmv.fit)



tmv.fit <- fit.tmv(data = mydata, nu = 3.5, opt.pars = c(lambda = T, mu = T, sigma = T, gamma = !0), symmetric = F)

summary(tmv.fit)



# only this converges during portfolio optimization

gaussmv.fit <- fit.gaussmv(data = mydata, na.rm = T, save.data = T)

summary(gaussmv.fit)



# Using expected shortfall as risk measure with target return from 0.0001 to 0.0020

g1_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

    	   level = 0.95,

	   target.return = 0.0001,

  	   distr = "return")

print(g1_es)



g2_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0002,

  	   distr = "return")

print(g2_es)



g3_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0003,

  	   distr = "return")

print(g3_es)



g4_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0004,

  	   distr = "return")

print(g4_es)



g5_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0005,

  	   distr = "return")

print(g5_es)



g6_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0006,

  	   distr = "return")

print(g6_es)



g7_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

         level = 0.95,

	   target.return = 0.0007,

  	   distr = "return")

print(g7_es)



g8_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0008,

  	   distr = "return")

print(g8_es)



g9_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0009,

  	   distr = "return")

print(g9_es)



g10_es <- portfolio.optimize(ghypmv.fit,

  	    risk.measure = "expected.shortfall",

	    type = "target.return",

          level = 0.95,

	    target.return = 0.0010,

  	    distr = "return")

print(g10_es)



g11_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

    	   level = 0.95,

	   target.return = 0.0011,

  	   distr = "return")

print(g11_es)



g12_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0012,

  	   distr = "return")

print(g12_es)



g13_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0013,

  	   distr = "return")

print(g13_es)



g14_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0014,

  	   distr = "return")

print(g14_es)



g15_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0015,

  	   distr = "return")

print(g15_es)



g16_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0016,

  	   distr = "return")

print(g16_es)



g17_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

         level = 0.95,

	   target.return = 0.0017,

  	   distr = "return")

print(g17_es)



g18_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0018,

  	   distr = "return")

print(g18_es)



g19_es <- portfolio.optimize(ghypmv.fit,

 	   risk.measure = "expected.shortfall",

	   type = "target.return",

	   level = 0.95,

	   target.return = 0.0019,

  	   distr = "return")

print(g19_es)



g20_es <- portfolio.optimize(ghypmv.fit,

  	    risk.measure = "expected.shortfall",

	    type = "target.return",

          level = 0.95,

	    target.return = 0.0020,

  	    distr = "return")

print(g20_es)



plot(c(g1_es$risk, g2_es$risk, g3_es$risk, g4_es$risk, g5_es$risk, g6_es$risk, g7_es$risk, g8_es$risk, g9_es$risk, g10_es$risk, 

       g11_es$risk, g12_es$risk, g13_es$risk, g14_es$risk, g15_es$risk, g16_es$risk, g17_es$risk, g18_es$risk, g19_es$risk, g20_es$risk),

     c(mean(g1_es$portfolio.dist), mean(g2_es$portfolio.dist), mean(g3_es$portfolio.dist), mean(g4_es$portfolio.dist), mean(g5_es$portfolio.dist),

       mean(g6_es$portfolio.dist), mean(g7_es$portfolio.dist), mean(g8_es$portfolio.dist), mean(g9_es$portfolio.dist), mean(g10_es$portfolio.dist),

       mean(g11_es$portfolio.dist), mean(g12_es$portfolio.dist), mean(g13_es$portfolio.dist), mean(g14_es$portfolio.dist), mean(g15_es$portfolio.dist),

       mean(g16_es$portfolio.dist), mean(g17_es$portfolio.dist), mean(g18_es$portfolio.dist), mean(g19_es$portfolio.dist), mean(g20_es$portfolio.dist)),

	 type = "l",

       xlab = "Expected shortfall",

       ylab = "Expected portfolio return",

       main = "Efficient frontier for Gaussian Distribution")




From sean_parks at fs.fed.us  Thu Dec 19 21:33:39 2013
From: sean_parks at fs.fed.us (Parks, Sean -FS)
Date: Thu, 19 Dec 2013 20:33:39 +0000
Subject: [R] pixel based percentile among rasters
Message-ID: <5B458719A8371B438AFFDEBC5201C1F50221D8D9@001FSN2MPN1-021.001f.mgd2.msft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/ce4df554/attachment.pl>

From p_connolly at slingshot.co.nz  Thu Dec 19 22:03:20 2013
From: p_connolly at slingshot.co.nz (p_connolly)
Date: Fri, 20 Dec 2013 10:03:20 +1300
Subject: [R] multicore and mclapply problem in calculation server
Message-ID: <7ec1700803441f63d3506d934b91666c@slingshot.co.nz>

On Wed, 18-Dec-2013 at 09:28AM +0100, Juan Antonio Balbuena wrote:

|>
|>    Hello
|>    I am using package multicore for parallel computing in a Altix 
UltraViolet
|>    1000 server with 64 CPUs and 960 GB of RAM memory. Access is 
managed by
|>    means of a SGE queue system. This is the first time I am using 
parallel
|>    computing and my experience with supercomputers is quite limited. 
So any
|>    help will be much, much appreciated.
|>    My experiment consists of a number of runs (N.runs) each involving 
a number
|>    of permutations (N. perms). (An excerpt of the code is included 
below.) The
|>    permutations are very time consuming and I am using mclapply to 
distribute
|>    the job among a given number of cpus (usually 12 to 24). The 
problem is that
|>    the system administrators notice that threads keep increasing as 
the program
|>    is executed to the point that they compromise the functioning of 
the whole
|>    system and have to abort the job.

So, does that mean you get nothing written to 1MH_30.tre?  I'd be
surprised if you did get anything.  Though there's lots of stuff
happening I know nothing about, I'm pretty sure there's an issue with
your wrapper() function.

[...]

|>      wrapper <- function (x) {           # THIS FUCNTION IS SUPPOSED 
TO BE
|>    PARALLELIZED (SEE BELOW)
|>        treeH <- read.tree(text=linH[x])
|>        treeP <- read.tree(text=linP[x])
|>        mrcaL <- MRCALink.simul (treeH, treeP, HP)
|>        stat.matrix[x,] <- three.stat(mrcaL)
|>        }

Nothing is being returned, so your calls to rbind will have nothing to
put together.  So what they end up trying to do, I've no idea.  That
function probably needs a final line 'stat.matrix' before the '}'

One thing I discovered with mclapply is that to use the browser()
function, it's necessary to make what is x in your example of length 1
(and probably mc.cores to 1 also) before it's possible to examine
what's happening at various parts of the function being debugged.
Judicious use of cat() and Sys.time() to display what's happening at
various stages is also helpful.

HTH

--
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
    ___    Patrick Connolly
  {~._.~}                         Great minds discuss ideas
  _( Y )_                        Middle minds discuss events
(:_~*~_:)                        Small minds discuss people
  (_)-(_)                                   ..... Anon

~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From capricyg at yahoo.com  Thu Dec 19 22:19:15 2013
From: capricyg at yahoo.com (capricy gao)
Date: Thu, 19 Dec 2013 13:19:15 -0800 (PST)
Subject: [R] hist() : is there a way to change the border width?
Message-ID: <1387487955.31746.YahooMailNeo@web125002.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/27000702/attachment.pl>

From sjkiss at gmail.com  Thu Dec 19 22:49:23 2013
From: sjkiss at gmail.com (Simon Kiss)
Date: Thu, 19 Dec 2013 16:49:23 -0500
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <6A1D5701-100E-4CF3-84E1-4681EF5641A6@gmail.com>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
	<BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E0F1@PA-MBX01.na.tibco.com>
	<6A1D5701-100E-4CF3-84E1-4681EF5641A6@gmail.com>
Message-ID: <93BCBD4B-5A0A-4C94-A9ED-EF863D6670C0@gmail.com>

Hi there: Just to tie this altogether.

Here is the final function

f<- function (modelType, responseName, predictorNames, data, ..., envir = parent.frame())
{
  call <- match.call()
  call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
                                               paste0("`", predictorNames, "`", collapse = " + ")))
  call[[1]] <- as.name(modelType)
  call$responseName <- NULL # omit responseName=
  call$predictorNames <- NULL # omit 'predictorNames='
  eval(call, envir = envir)
}
  
Here I call the function to a list of predictor variables and one dependent variable. Note "glm" and not glm.
z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("glm", "carb", preds, data=mtcars, family='binomial'))

I do get this error:
Error in glm.control(modelType = "glm") : 
  unused argument(s) (modelType = "glm")

But 
lapply(z, summary)

does seem to return a list of model summaries. It looks like it worked.

I also tried. 
z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("lm", "mpg", preds, data=mtcars))

Here, I get:
1: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
  extra argument ?modelType? is disregarded.
2: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
  extra argument ?modelType? is disregarded.
3: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
  extra argument ?modelType? is disregarded.

But again, it actually looks like it worked.
So, thank you very much!
Yours, Simon Kiss

On 2013-12-19, at 1:55 PM, Simon Kiss <sjkiss at gmail.com> wrote:

> Hello Bill, that is fantastic and it's quite a bit above what I could write. Is there a way to make the model type an argument to the function so that you can specify whether one is running glm, lm and such? 
> I tried to modify it by inserting an argument modelType below, but that doesn't work.
> Yours, simon Kiss
>> f <- function (modelType, responseName, predictorNames, data, ..., envir = parent.frame())
>>   {
>>       call <- match.call()
>>       call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
>>           paste0("`", predictorNames, "`", collapse = " + ")))
>>               call[[1]] <- quote(modelType) # '
>>       call$responseName <- NULL # omit responseName=
>>       call$predictorNames <- NULL # omit 'predictorNames='
>>               eval(call, envir = envir)
>>   }
> On 2013-12-18, at 3:07 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
>> f <- function (responseName, predictorNames, data, ..., envir = parent.frame())
>>   {
>>       call <- match.call()
>>       call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
>>           paste0("`", predictorNames, "`", collapse = " + ")))
>>               call[[1]] <- quote(glm) # 'f' -> 'glm'
>>       call$responseName <- NULL # omit responseName=
>>       call$predictorNames <- NULL # omit 'predictorNames='
>>               eval(call, envir = envir)
>>   }
>> as in
>>   z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("carb", preds, data=mtcars, family=poisson))
>>   lapply(z, summary)
> 
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> Cell: +1 905 746 7606
> 
> 
> 

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9
Cell: +1 905 746 7606


From santosh2005 at gmail.com  Thu Dec 19 22:51:41 2013
From: santosh2005 at gmail.com (Santosh)
Date: Thu, 19 Dec 2013 13:51:41 -0800
Subject: [R] read ".slk" file
In-Reply-To: <15657B13-A1D4-456B-8543-4EF1C69386F7@comcast.net>
References: <CAN_e6XvqBmk26ubOP-852LwGDEx_PgY4=Z0Fu6XakWVffFBDaQ@mail.gmail.com>
	<15657B13-A1D4-456B-8543-4EF1C69386F7@comcast.net>
Message-ID: <CAN_e6XstN0xChaKkfqwGBqHFLkjK2KZHFTFLcFW9VzXm=UH5dg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/213109ee/attachment.pl>

From wdunlap at tibco.com  Thu Dec 19 22:51:36 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 19 Dec 2013 21:51:36 +0000
Subject: [R] Help using mapply to run multiple models
In-Reply-To: <93BCBD4B-5A0A-4C94-A9ED-EF863D6670C0@gmail.com>
References: <B7739A56-FC85-4BD9-A375-A317550EBC16@gmail.com>
	<CADv2QyGbnmhvRXHbjMd5BqS9BAv2yD7C6SsSTty9bmdU-4pvwg@mail.gmail.com>
	<BF7ECC6F-6ADA-4E4C-A708-96386BA02FBD@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E0F1@PA-MBX01.na.tibco.com>
	<6A1D5701-100E-4CF3-84E1-4681EF5641A6@gmail.com>
	<93BCBD4B-5A0A-4C94-A9ED-EF863D6670C0@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1E4DD@PA-MBX01.na.tibco.com>

> I do get this error:
> Error in glm.control(modelType = "glm") :
>   unused argument(s) (modelType = "glm")

Add the line
   call$modelType <- NULL # omit modelType argument
to your function.  Otherwise
   f("glm", ...)
makes the call
   glm(modelType="glm", ...)
where you want it to make the call
   glm(...)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Simon Kiss [mailto:sjkiss at gmail.com]
> Sent: Thursday, December 19, 2013 1:49 PM
> To: William Dunlap
> Cc: Dennis Murphy; r-help at r-project.org
> Subject: Re: [R] Help using mapply to run multiple models
> 
> Hi there: Just to tie this altogether.
> 
> Here is the final function
> 
> f<- function (modelType, responseName, predictorNames, data, ..., envir =
> parent.frame())
> {
>   call <- match.call()
>   call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
>                                                paste0("`", predictorNames, "`", collapse = " + ")))
>   call[[1]] <- as.name(modelType)
>   call$responseName <- NULL # omit responseName=
>   call$predictorNames <- NULL # omit 'predictorNames='
>   eval(call, envir = envir)
> }
> 
> Here I call the function to a list of predictor variables and one dependent variable. Note
> "glm" and not glm.
> z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("glm",
> "carb", preds, data=mtcars, family='binomial'))
> 
> I do get this error:
> Error in glm.control(modelType = "glm") :
>   unused argument(s) (modelType = "glm")
> 
> But
> lapply(z, summary)
> 
> does seem to return a list of model summaries. It looks like it worked.
> 
> I also tried.
> z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("lm", "mpg",
> preds, data=mtcars))
> 
> Here, I get:
> 1: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>   extra argument 'modelType' is disregarded.
> 2: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>   extra argument 'modelType' is disregarded.
> 3: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>   extra argument 'modelType' is disregarded.
> 
> But again, it actually looks like it worked.
> So, thank you very much!
> Yours, Simon Kiss
> 
> On 2013-12-19, at 1:55 PM, Simon Kiss <sjkiss at gmail.com> wrote:
> 
> > Hello Bill, that is fantastic and it's quite a bit above what I could write. Is there a way to
> make the model type an argument to the function so that you can specify whether one is
> running glm, lm and such?
> > I tried to modify it by inserting an argument modelType below, but that doesn't work.
> > Yours, simon Kiss
> >> f <- function (modelType, responseName, predictorNames, data, ..., envir =
> parent.frame())
> >>   {
> >>       call <- match.call()
> >>       call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
> >>           paste0("`", predictorNames, "`", collapse = " + ")))
> >>               call[[1]] <- quote(modelType) # '
> >>       call$responseName <- NULL # omit responseName=
> >>       call$predictorNames <- NULL # omit 'predictorNames='
> >>               eval(call, envir = envir)
> >>   }
> > On 2013-12-18, at 3:07 PM, William Dunlap <wdunlap at tibco.com> wrote:
> >
> >> f <- function (responseName, predictorNames, data, ..., envir = parent.frame())
> >>   {
> >>       call <- match.call()
> >>       call$formula <- formula(envir = envir, paste(responseName, sep = " ~ ",
> >>           paste0("`", predictorNames, "`", collapse = " + ")))
> >>               call[[1]] <- quote(glm) # 'f' -> 'glm'
> >>       call$responseName <- NULL # omit responseName=
> >>       call$predictorNames <- NULL # omit 'predictorNames='
> >>               eval(call, envir = envir)
> >>   }
> >> as in
> >>   z <- lapply(list(c("hp","drat"), c("cyl"), c("am","gear")), FUN=function(preds)f("carb",
> preds, data=mtcars, family=poisson))
> >>   lapply(z, summary)
> >
> > *********************************
> > Simon J. Kiss, PhD
> > Assistant Professor, Wilfrid Laurier University
> > 73 George Street
> > Brantford, Ontario, Canada
> > N3T 2C9
> > Cell: +1 905 746 7606
> >
> >
> >
> 
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> Cell: +1 905 746 7606
> 
> 


From ross at biostat.ucsf.edu  Fri Dec 20 00:37:02 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 19 Dec 2013 15:37:02 -0800
Subject: [R] spending most of my time in assignments?
Message-ID: <1387496222.10351.77.camel@localhost>

My code seems to be spending most of its time in assignment statements,
in some cases simple assignment of a model frame or model matrix.

Can anyone provide any insights into what's going on, or how to speed
things up?

For starters, is it possible that the reports are not accurate, or that
I am misreading them.  In R 3.0.1 (running under ESS):
 > Rprof(line.profiling=TRUE)
 > system.time(r <- totalEffect(dodata[[1]], dodata[[2]], 1:3, 4))
    user  system elapsed
  21.629   0.756  22.469
!> Rprof(NULL)                                                                                                                                                                                                                                                                 
 > summaryRprof(lines="both")
 $by.self
                            self.time self.pct total.time total.pct
 box.R#158                       6.74    29.56      13.06     57.28                                                                                                                                                                                                            
 simulator.multinomial.R#64      2.92    12.81       2.96     12.98                                                                                                                                                                                                            
 simulator.multinomial.R#63      2.76    12.11       2.76     12.11                                                                                                                                                                                                            
 box.R#171                       2.54    11.14       5.08     22.28                                                                                                                                                                                                            
 simulator.d1.R#70               0.98     4.30       0.98      4.30                                                                                                                                                                                                            
 simulator.d1.R#71               0.98     4.30       0.98      4.30                                                                                                                                                                                                            
 densMap.R#42                    0.72     3.16       0.86      3.77                                                                                                                                                                                                            
 "standardGeneric"               0.52     2.28      11.30     49.56
......

Here's some of the code, with comments at the line numbers
box.R:
                sp <- merge(sexpartner, data, by="studyidx")                                                                                                                                                                                                                   
                sp$y <- numFactor(sp$pEthnic)  #I think y is not used but must be present                                                                                                                                                                                      
                data(sims.c1[[k]]) <- sp    ###<<<<< line 158                                                                                                                                                                                                                                   
                sp0 <- sp                                                                                                                                                                                                                                                      
                sp <- sim(sims.c1[[k]], i)                                                                                                                                                                                                                                     
                ctable[[k]] <- update.c1(ctable[[k]], sp)                                                                                                                                                                                                                      
                if (is.null(i.c1.in)) {                                                                                                                                                                                                                                        
                    i.c1.in <- match("pEthnic", colnames(sp0))                                                                                                                                                                                                                 
                    i.c1.out <- match(c("studyidx", "n", "pEthnic"), colnames(sp))                                                                                                                                                                                             
                }                                                                                                                                                                                                                                                              
                sp0 <- merge(sp0[,-i.c1.in], sp[,i.c1.out], by=c("studyidx", "n"))                                                                                                                                                                                             
                # d1                                                                                                                                                                                                                                                           
                sp0 <- sp0[sp0$pIsMale == 1,]                                                                                                                                                                                                                                  
                # avoid lots of conversion warnings                                                                                                                                                                                                                            
                sp0$pEthnic <- factor(sp0$pEthnic, levels=partRaceLevels)                                                                                                                                                                                                      
                data(sims.d1[[k]]) <- sp0    ###<<<<< line 171                                                                                                                                                                                                                                
                sp <- sim(sims.d1[[k]], i)                                                                                                                                                                                                                                     
                dtable[[k]] <- update.d1(dtable[[k]], sp)                                                                                                                                                                                                                      
                rngstate[[k]] <- .Random.seed   
The timing seems odd since it doesn't appear there's anything to do at
the 2 lines except invoke data<-, but if that's slow I would expect the
time to go to the data<- function (in a different file) and not to the
call.

In fact the other big time items are inside the data<- functions.
simulator.multinomial.R:

   setMethod("data<-", c("simulator.multinomial", "data.frame"),
          function(obj, value) {
    mf <- model.frame(obj at dataFormula, data=value)
    mf$iCluster <- fromOrig(obj at idmap, as.character(mf$studyidx))
    if (any(is.na(mf$iCluster)))
        stop("New studyidx--need to draw from meta distn")
    mm <- model.matrix(obj at modelFormula, data=mf)
    obj at data <- mf  ##<<< line 63
    obj at mm <- mm    ##<<< line 64
    return(obj)
})

The mm and data slots have type restrictions, but no other validation
tests.
setClass("simulator.multinomial",
         representation(fit="stanfit", idmap="sIDMap",
                        modelFormula="formula",
                        categories="ANY",  # could be factor or character                                                                                                                                                                                                      
                                        # categories should be in the order of their numeric codes in y                                                                                                                                                                        
                        # cached results                                                                                                                                                                                                                                       
                        coef="list",
                        data="data.frame",
                        dataFormula="formula",
                        mm="matrix"))
Does it matter that, e.g., a model frame is more than a vanilla data frame?

I thought assignment, given R's lazy copying behavior, was essentially
resetting a pointer, and so should be fast.

Or maybe the time is going to garbage collecting the previous contents
of the slots?

Ross Boylan


From sjkiss at gmail.com  Fri Dec 20 00:44:34 2013
From: sjkiss at gmail.com (Simon Kiss)
Date: Thu, 19 Dec 2013 18:44:34 -0500
Subject: [R] Searching the help archives - 404 error?
Message-ID: <70991250-EBFD-429D-9657-83792AEDDF0F@gmail.com>

I'm using Mac OS 10.8.5, Chrome 31 and Safari 6.1. 
Recently, when entering anything into the search box here:
http://tolstoy.newcastle.edu.au/R/
I get this response when searching using either Chrome or Safari:

404. That?s an error.

The requested URL /u/newcastlemaths?q=rprofile&sa=Google+Search was not found on this server. That?s all we know.

Has the search engine for the help archives moved?
Yours, Simon Kiss
*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9


From fingermark at gmail.com  Fri Dec 20 00:38:11 2013
From: fingermark at gmail.com (bradford)
Date: Thu, 19 Dec 2013 18:38:11 -0500
Subject: [R] Color With a Function
Message-ID: <CAEbKVFQ80ryHPvd2-gv3bpGBi5cXUmeo=v-U-kgxprOqerH_Wg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/5e3a716a/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Fri Dec 20 02:19:28 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 19 Dec 2013 17:19:28 -0800
Subject: [R] Searching the help archives - 404 error?
In-Reply-To: <70991250-EBFD-429D-9657-83792AEDDF0F@gmail.com>
References: <70991250-EBFD-429D-9657-83792AEDDF0F@gmail.com>
Message-ID: <d238a0c5-79c1-443a-95d6-ace05b811169@email.android.com>

There is no "the help archives"... there are numerous archives, some of which are not of the same quality as others. You might have better luck following the link included in the footer of every email from this list:

https://stat.ethz.ch/mailman/listinfo/r-help

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Simon Kiss <sjkiss at gmail.com> wrote:
>I'm using Mac OS 10.8.5, Chrome 31 and Safari 6.1. 
>Recently, when entering anything into the search box here:
>http://tolstoy.newcastle.edu.au/R/
>I get this response when searching using either Chrome or Safari:
>
>404. That?s an error.
>
>The requested URL /u/newcastlemaths?q=rprofile&sa=Google+Search was not
>found on this server. That?s all we know.
>
>Has the search engine for the help archives moved?
>Yours, Simon Kiss
>*********************************
>Simon J. Kiss, PhD
>Assistant Professor, Wilfrid Laurier University
>73 George Street
>Brantford, Ontario, Canada
>N3T 2C9
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Dec 20 02:37:43 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 Dec 2013 20:37:43 -0500
Subject: [R] spending most of my time in assignments?
In-Reply-To: <1387496222.10351.77.camel@localhost>
References: <1387496222.10351.77.camel@localhost>
Message-ID: <52B39F67.8050905@gmail.com>

On 13-12-19 6:37 PM, Ross Boylan wrote:
> My code seems to be spending most of its time in assignment statements,
> in some cases simple assignment of a model frame or model matrix.
>
> Can anyone provide any insights into what's going on, or how to speed
> things up?

You are seeing a lot of time being spent on complex assignments.  For 
example, line 158 is

data(sims.c1[[k]]) <- sp

That makes a function call to `data<-` to do the assignment, and that 
could be slow.  Since it's an S4 method there's a bunch of machinery 
involved in dispatching it; most of that would not have line number 
information, so it'll be charged to that line.

I can't really suggest how to speed it up.

Duncan Murdoch

>
> For starters, is it possible that the reports are not accurate, or that
> I am misreading them.  In R 3.0.1 (running under ESS):
>   > Rprof(line.profiling=TRUE)
>   > system.time(r <- totalEffect(dodata[[1]], dodata[[2]], 1:3, 4))
>      user  system elapsed
>    21.629   0.756  22.469
> !> Rprof(NULL)
>   > summaryRprof(lines="both")
>   $by.self
>                              self.time self.pct total.time total.pct
>   box.R#158                       6.74    29.56      13.06     57.28
>   simulator.multinomial.R#64      2.92    12.81       2.96     12.98
>   simulator.multinomial.R#63      2.76    12.11       2.76     12.11
>   box.R#171                       2.54    11.14       5.08     22.28
>   simulator.d1.R#70               0.98     4.30       0.98      4.30
>   simulator.d1.R#71               0.98     4.30       0.98      4.30
>   densMap.R#42                    0.72     3.16       0.86      3.77
>   "standardGeneric"               0.52     2.28      11.30     49.56
> ......
>
> Here's some of the code, with comments at the line numbers
> box.R:
>                  sp <- merge(sexpartner, data, by="studyidx")
>                  sp$y <- numFactor(sp$pEthnic)  #I think y is not used but must be present
>                  data(sims.c1[[k]]) <- sp    ###<<<<< line 158
>                  sp0 <- sp
>                  sp <- sim(sims.c1[[k]], i)
>                  ctable[[k]] <- update.c1(ctable[[k]], sp)
>                  if (is.null(i.c1.in)) {
>                      i.c1.in <- match("pEthnic", colnames(sp0))
>                      i.c1.out <- match(c("studyidx", "n", "pEthnic"), colnames(sp))
>                  }
>                  sp0 <- merge(sp0[,-i.c1.in], sp[,i.c1.out], by=c("studyidx", "n"))
>                  # d1
>                  sp0 <- sp0[sp0$pIsMale == 1,]
>                  # avoid lots of conversion warnings
>                  sp0$pEthnic <- factor(sp0$pEthnic, levels=partRaceLevels)
>                  data(sims.d1[[k]]) <- sp0    ###<<<<< line 171
>                  sp <- sim(sims.d1[[k]], i)
>                  dtable[[k]] <- update.d1(dtable[[k]], sp)
>                  rngstate[[k]] <- .Random.seed
> The timing seems odd since it doesn't appear there's anything to do at
> the 2 lines except invoke data<-, but if that's slow I would expect the
> time to go to the data<- function (in a different file) and not to the
> call.
>
> In fact the other big time items are inside the data<- functions.
> simulator.multinomial.R:
>
>     setMethod("data<-", c("simulator.multinomial", "data.frame"),
>            function(obj, value) {
>      mf <- model.frame(obj at dataFormula, data=value)
>      mf$iCluster <- fromOrig(obj at idmap, as.character(mf$studyidx))
>      if (any(is.na(mf$iCluster)))
>          stop("New studyidx--need to draw from meta distn")
>      mm <- model.matrix(obj at modelFormula, data=mf)
>      obj at data <- mf  ##<<< line 63
>      obj at mm <- mm    ##<<< line 64
>      return(obj)
> })
>
> The mm and data slots have type restrictions, but no other validation
> tests.
> setClass("simulator.multinomial",
>           representation(fit="stanfit", idmap="sIDMap",
>                          modelFormula="formula",
>                          categories="ANY",  # could be factor or character
>                                          # categories should be in the order of their numeric codes in y
>                          # cached results
>                          coef="list",
>                          data="data.frame",
>                          dataFormula="formula",
>                          mm="matrix"))
> Does it matter that, e.g., a model frame is more than a vanilla data frame?
>
> I thought assignment, given R's lazy copying behavior, was essentially
> resetting a pointer, and so should be fast.
>
> Or maybe the time is going to garbage collecting the previous contents
> of the slots?
>
> Ross Boylan
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dzorig at gmail.com  Fri Dec 20 02:01:22 2013
From: dzorig at gmail.com (Zorig Davaanyam)
Date: Thu, 19 Dec 2013 17:01:22 -0800
Subject: [R] Fitting particle size analysis data
Message-ID: <CAM=4muR3PeYvvNsM4pGks0o0QwNWo=sXcTuPiHnTXDK89wmeCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131219/41cacded/attachment.pl>

From jdnewmil at dcn.davis.ca.us  Fri Dec 20 03:44:19 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 19 Dec 2013 18:44:19 -0800 (PST)
Subject: [R] Color With a Function
In-Reply-To: <CAEbKVFQ80ryHPvd2-gv3bpGBi5cXUmeo=v-U-kgxprOqerH_Wg@mail.gmail.com>
References: <CAEbKVFQ80ryHPvd2-gv3bpGBi5cXUmeo=v-U-kgxprOqerH_Wg@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1312191836580.70658@pedal.dcn.davis.ca.us>

Design questions ("why...") should go to the package maintainer.

You need to learn to ask complete questions [1] and post in plain text 
rather than HTML on this list.

I think that normal practice is to add a factor column that reflects the 
coloring you want, and then reference it. E.g.:

library(reshape2)
library(ggplot2)
set.seed(42)
df <- data.frame( matrix( rnorm(12*4,1,1), ncol=4 ) )
df$Month <- factor( 1:12 )
names( df ) <- c( paste0( "data", 1:4 ), "Month" )
dfm <- melt(df,measure.vars=c("data1", "data2", "data3", "data4" ) )
dfm$col <- "Nonnegative"
dfm$col[ dfm$value < 0 ] <- "Negative"
dfm$col <- as.factor( dfm$col )
ggplot(dfm, aes(x=Month,y=value,fill=col)) +
     geom_bar(stat = "identity",position="dodge") +
     facet_wrap(~variable,ncol=1, scales = "free_y") +
     scale_fill_manual( name="Sign", values=c( "red", "green" ) )

P.S.: Note that "df" is the name of a function provided in base R. In the 
long run you are better off using some other shorthand (I use "DF") 
variable name.

[1] 
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

On Thu, 19 Dec 2013, bradford wrote:

> I use ggplot2 a lot and am wondering why I can't just color with a
> function?  For example, if value < 0 then use red else use green.
>
> How would you guys suggest to color these bar graphs so that positive is
> green and negative is red?
>
> ggplot(melt(df,measure.vars=c("data1", "data2", "data3", "data4")),
> aes(x=Month,y=value)) + geom_bar(stat = "identity") + facet_wrap(~variable,
> ncol=1, scales = "free_y") + scale_y_continuous(labels=comma)
>
> Thanks,
> Bradford
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jim at bitwrit.com.au  Fri Dec 20 05:49:29 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 20 Dec 2013 15:49:29 +1100
Subject: [R] hist() : is there a way to change the border width?
In-Reply-To: <1387487955.31746.YahooMailNeo@web125002.mail.ne1.yahoo.com>
References: <1387487955.31746.YahooMailNeo@web125002.mail.ne1.yahoo.com>
Message-ID: <52B3CC59.5080005@bitwrit.com.au>

On 12/20/2013 08:19 AM, capricy gao wrote:
> I have played around with it and found that the only color could be changed. But I really would like to change the width...
>
Hi Capricy,
Try this on the first example for hist:

hist(islands)
par(lwd=3)
hist(islands)

Jim


From jim at bitwrit.com.au  Fri Dec 20 05:57:29 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 20 Dec 2013 15:57:29 +1100
Subject: [R] Color With a Function
In-Reply-To: <CAEbKVFQ80ryHPvd2-gv3bpGBi5cXUmeo=v-U-kgxprOqerH_Wg@mail.gmail.com>
References: <CAEbKVFQ80ryHPvd2-gv3bpGBi5cXUmeo=v-U-kgxprOqerH_Wg@mail.gmail.com>
Message-ID: <52B3CE39.3080406@bitwrit.com.au>

On 12/20/2013 10:38 AM, bradford wrote:
> I use ggplot2 a lot and am wondering why I can't just color with a
> function?  For example, if value<  0 then use red else use green.
>
> How would you guys suggest to color these bar graphs so that positive is
> green and negative is red?
>
> ggplot(melt(df,measure.vars=c("data1", "data2", "data3", "data4")),
> aes(x=Month,y=value)) + geom_bar(stat = "identity") + facet_wrap(~variable,
> ncol=1, scales = "free_y") + scale_y_continuous(labels=comma)
>
Hi Bradford,
If you are using numerically designated colors it is fairly easy. Using 
your example above:

col<-(value >= 0) + 2

As "red" is equivalent to "2" and "green" to "3" in the default palette, 
col will be a vector of 2s and 3s depending upon the sign of "value. 
This can be passed to whatever color argument you are using.

Jim


From gewart at biotron.com.au  Fri Dec 20 05:33:02 2013
From: gewart at biotron.com.au (Gewart)
Date: Thu, 19 Dec 2013 20:33:02 -0800 (PST)
Subject: [R] Strange subvector output --> x[n] != x[1:n][n]
Message-ID: <1387513982859-4682526.post@n4.nabble.com>

Hi, Can anyone explain what is going on...!?   For a vector
"x=seq(min,max,0.01)", when generating sub-vector "a" based on a starting
value "st", things go as expected as long as "st" is not too close to the
beginning of "x".  For example, if x starts at -5 and increments by 0.01,
whenever I try to generate the sub-vector "a" (as below) with a starting
value of 0.49 or less it does not generate the expected output: The initial
value of "a" is wrong.
 
Thanks in advance for any clarity you can shed.
Gary

...(please see two versions of code below).... 

#THIS WORKS...(st > -4.9)

	min = -5; max = 1;  x=seq(min,max,0.01)

	st= -4.8 ; end= 0    

	a=x[((st-min)/0.01+1):((end-min)/0.01+1)] 
	
			n=(st-min)/0.01+1
#compare	
	a[1:10]; c(x[n:(n+9)])

#test...
	n
	x[1:n]; x[n]           ### x[n]== x[1:n][n] ; As expected
##########################################################
#  BUT THIS IS WEIRD!!...(st <= -4.9)
	
	st= -4.90 ; end= 0     ### -> BUG in generation of a!!

	a=x[((st-min)/0.01+1):((end-min)/0.01+1)]; 
	
			n=(st-min)/0.01+1
#compare	
	a[1:10]; c(x[n:(n+9)])
#test
	n
	x[1:n]; x[n]  ### NOW x[n] != x[1:n][n]   !!?? What is going on!?





--
View this message in context: http://r.789695.n4.nabble.com/Strange-subvector-output-x-n-x-1-n-n-tp4682526.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Fri Dec 20 08:28:38 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 19 Dec 2013 23:28:38 -0800
Subject: [R] Strange subvector output --> x[n] != x[1:n][n]
In-Reply-To: <1387513982859-4682526.post@n4.nabble.com>
References: <1387513982859-4682526.post@n4.nabble.com>
Message-ID: <f399d1d1-4fcd-4364-8974-5de214c4a32d@email.android.com>

Sigh. Google couldn't help you?

Try FAQ 7.31 and then use non-fractions to generate sequences... scale as desired. This is not unique to R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Gewart <gewart at biotron.com.au> wrote:
>Hi, Can anyone explain what is going on...!?   For a vector
>"x=seq(min,max,0.01)", when generating sub-vector "a" based on a
>starting
>value "st", things go as expected as long as "st" is not too close to
>the
>beginning of "x".  For example, if x starts at -5 and increments by
>0.01,
>whenever I try to generate the sub-vector "a" (as below) with a
>starting
>value of 0.49 or less it does not generate the expected output: The
>initial
>value of "a" is wrong.
> 
>Thanks in advance for any clarity you can shed.
>Gary
>
>...(please see two versions of code below).... 
>
>#THIS WORKS...(st > -4.9)
>
>	min = -5; max = 1;  x=seq(min,max,0.01)
>
>	st= -4.8 ; end= 0    
>
>	a=x[((st-min)/0.01+1):((end-min)/0.01+1)] 
>	
>			n=(st-min)/0.01+1
>#compare	
>	a[1:10]; c(x[n:(n+9)])
>
>#test...
>	n
>	x[1:n]; x[n]           ### x[n]== x[1:n][n] ; As expected
>##########################################################
>#  BUT THIS IS WEIRD!!...(st <= -4.9)
>	
>	st= -4.90 ; end= 0     ### -> BUG in generation of a!!
>
>	a=x[((st-min)/0.01+1):((end-min)/0.01+1)]; 
>	
>			n=(st-min)/0.01+1
>#compare	
>	a[1:10]; c(x[n:(n+9)])
>#test
>	n
>	x[1:n]; x[n]  ### NOW x[n] != x[1:n][n]   !!?? What is going on!?
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Strange-subvector-output-x-n-x-1-n-n-tp4682526.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From j.a.balbuena at uv.es  Fri Dec 20 13:19:03 2013
From: j.a.balbuena at uv.es (Juan Antonio Balbuena)
Date: Fri, 20 Dec 2013 13:19:03 +0100
Subject: [R] multicore and mclapply problem in calculation server
In-Reply-To: <7ec1700803441f63d3506d934b91666c@slingshot.co.nz>
References: <7ec1700803441f63d3506d934b91666c@slingshot.co.nz>
Message-ID: <52B435B7.3030802@uv.es>


   Hi Patrick,
   Thanks for posting. The wrapper function works as it should. If you do not
   specify return the function returns the last object declared, and this is
   exactly what I intended. Doing some research on my own I found out that the
   problem was here:
   x <- c(1: length(linH))
   stat.matrix <- do.call(rbind, mclapply(x, wrapper, mc.cores= 6))
   Since  linH  =  readLines(conH,  n= N.perm) and N.perm was set to 999,
   apparently  mclapply  sends  _simultaneously_ the 999 jobs to the cpus
   specified in mc.cores. Even if you use more than 6, as in the example, the
   systems gets quickly overflowed. So the solution is to split length(linH)
   into blocks equal to the number of cpus and the message to end-users is "be
   careful with parallel processing functions in R".
   Cheers
   Juan Antonio Balbuena
   El 19/12/2013 22:03, p_connolly escribi?:

     On Wed, 18-Dec-2013 at 09:28AM +0100, Juan Antonio Balbuena wrote:
     |>
     |>    Hello
     |>    I am using package multicore for parallel computing in a Altix
     UltraViolet
     |>    1000 server with 64 CPUs and 960 GB of RAM memory. Access is managed
     by
     |>    means of a SGE queue system. This is the first time I am using
     parallel
     |>    computing and my experience with supercomputers is quite limited. So
     any
     |>    help will be much, much appreciated.
     |>    My experiment consists of a number of runs (N.runs) each involving a
     number
     |>    of permutations (N. perms). (An excerpt of the code is included
     below.) The
     |>    permutations are very time consuming and I am using mclapply to
     distribute
     |>    the job among a given number of cpus (usually 12 to 24). The problem
     is that
     |>    the system administrators notice that threads keep increasing as the
     program
     |>    is executed to the point that they compromise the functioning of the
     whole
     |>    system and have to abort the job.
     So, does that mean you get nothing written to 1MH_30.tre?  I'd be
     surprised if you did get anything.  Though there's lots of stuff
     happening I know nothing about, I'm pretty sure there's an issue with
     your wrapper() function.
     [...]
     |>      wrapper <- function (x) {           # THIS FUCNTION IS SUPPOSED TO
     BE
     |>    PARALLELIZED (SEE BELOW)
     |>        treeH <- read.tree(text=linH[x])
     |>        treeP <- read.tree(text=linP[x])
     |>        mrcaL <- MRCALink.simul (treeH, treeP, HP)
     |>        stat.matrix[x,] <- three.stat(mrcaL)
     |>        }
     Nothing is being returned, so your calls to rbind will have nothing to
     put together.  So what they end up trying to do, I've no idea.  That
     function probably needs a final line 'stat.matrix' before the '}'
     One thing I discovered with mclapply is that to use the browser()
     function, it's necessary to make what is x in your example of length 1
     (and probably mc.cores to 1 also) before it's possible to examine
     what's happening at various parts of the function being debugged.
     Judicious use of cat() and Sys.time() to display what's happening at
     various stages is also helpful.
     HTH
     --
     ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
        ___    Patrick Connolly
      {~._.~}                         Great minds discuss ideas
      _( Y )_                        Middle minds discuss events
     (:_~*~_:)                        Small minds discuss people
      (_)-(_)                                   ..... Anon
     ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.

   --

   Dr. Juan A. Balbuena
   Marine Zoology Unit
   Cavanilles Institute of Biodiversity and Evolutionary Biology
   University of
   Valencia
   [1]http://www.uv.es/~balbuena
   P.O. Box 22085
   [2]http://www.uv.es/cavanilles/zoomarin/index.htm
   46071 Valencia, Spain
   [3]http://cetus.uv.es/mullpardb/index.html
   e-mail: [4]j.a.balbuena at uv.es    tel. +34 963 543 658    fax +34 963 543 733
   ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
   NOTE! For shipments by EXPRESS COURIER use the following street address:
   C/ Catedr?tico Jos? Beltr?n 2, 46980 Paterna (Valencia), Spain.
   ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

References

   1. http://www.uv.es/%7Ebalbuena
   2. http://www.uv.es/cavanilles/zoomarin/index.htm
   3. http://cetus.uv.es/mullpardb/index.html
   4. mailto:j.a.balbuena at uv.es

From silvano at uel.br  Fri Dec 20 14:01:26 2013
From: silvano at uel.br (silvano at uel.br)
Date: Fri, 20 Dec 2013 11:01:26 -0200
Subject: [R] ftable and data.frame
Message-ID: <D5B598CE7BC64B7AABB700260084556A@uelHP>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20131220/d23ea19b/attachment.pl>

From petr.pikal at precheza.cz  Fri Dec 20 14:35:30 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 20 Dec 2013 13:35:30 +0000
Subject: [R] Fitting particle size analysis data
In-Reply-To: <CAM=4muR3PeYvvNsM4pGks0o0QwNWo=sXcTuPiHnTXDK89wmeCA@mail.gmail.com>
References: <CAM=4muR3PeYvvNsM4pGks0o0QwNWo=sXcTuPiHnTXDK89wmeCA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA7E2F@SRVEXCHMBX.precheza.cz>

Hi

I made a simple spredsheet for PSD using Rosin Rammler equation and I am lazy to transform it to R. However for single purpose you can use nls.

Reverse your cumulative values

PSD$cum<-cumsum(PSD$ret)

plot(PSD$size, PSD$cum)

fit<-nls(cum~ exp(-((size/r)^gama))*100, data=PSD, start=c(r=80, gama=2))

summary(fit)

Formula: cum ~ exp(-((size/r)^gama)) * 100

Parameters:
     Estimate Std. Error t value Pr(>|t|)    
r     88.9664     2.3360   38.09 2.35e-07 ***
gama   2.5435     0.2244   11.33 9.36e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.411  on  5  degrees of freedom

Number of iterations to convergence: 7 
Achieved convergence tolerance: 1.612e-06

lines(PSD$size, predict(fit))

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Zorig Davaanyam
> Sent: Friday, December 20, 2013 2:01 AM
> To: r-help at r-project.org
> Subject: [R] Fitting particle size analysis data
> 
> Hi all,
> 
> How do you fit a sieve analysis data to a statistical function?
> I have many sieve analysis data of crushed rocks and I'd like to find
> out which statistical distributions describe the particular particle
> size distributions (PSD) the best. So basically I need to find fitted
> parameters to statistical distributions (mostly weibull and truncated
> lognormal).
> Here is an example of particle size (in microns) versus percent weight
> retained.
> Sieve size   Wt%  Cumulative passing%
> +250           0.1         99.9
> -250+180    2.9         97
> -180+125    9.5          87.5
> -125+90      21.2        66.3
> -90+63        29.4        36.9
> -63+45         26          10.9
> -45               10.9
> 
> PSD<-
> data.frame(size=c(250,180,125,90,63,45,0),retained=c(0.1,2.9,9.5,21.2,2
> 9.4,26,10.9),cumulative=c(99.9,97,87.5,66.3,36.9,10.9,0))
> 
> The above example is truncated to 350micron and I can't have particles
> with minus dimension. Any help will be greatly appreciated.
> 
> Thank you,
> 
> Zorig
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mahboobe.akhlaghi at ymail.com  Fri Dec 20 07:52:22 2013
From: mahboobe.akhlaghi at ymail.com (Mahboobe Akhlaghi)
Date: Fri, 20 Dec 2013 06:52:22 +0000 (GMT)
Subject: [R] (no subject)
Message-ID: <1387522342.27364.YahooMailNeo@web171902.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131220/c4a0ed14/attachment.pl>

From win at comets.de  Fri Dec 20 09:34:50 2013
From: win at comets.de (Melwin)
Date: Fri, 20 Dec 2013 09:34:50 +0100
Subject: [R]  Estimating and predicting using "segmented" Package
Message-ID: <op.w8dt4cawyqqyib@mueggelsee.ad.geoecology.uni-potsdam.de>

I don't know if this is still relevant for you, but probably for someone  
else.
I ran into the same problem an found two dirty workarounds that can help  
in many cases (but not all). Both can also be combined:

1. repeat the call to "segmented" with different seeds and different  
initial estimates of the breakpoints (psi). Wrap this with "try" to catch  
the error:
<code>
	res= NULL
	while (class(res)[1]!="segmented")
	{	
		some_seed= runif(1) #you may also systematically vary this
		some_psi = runif(2) #you may also systematically vary this.
			#Better tailor this to the distribution of x values in your_data
		model_lm = lm(y~x, data=your_data)

		res = try(segmented(obj=model_lm, seg.Z=~x, model=TRUE,  
psi=list(x=some_psi),
                   control=seg.control(seed=some_seed)), silent=TRUE)
	}
</code>


2. insert dummy points between your actual data to reduce the chance of  
"only 1 datum in an interval". When you supply these dummy data with low  
weights, their effect on the outcome should be low:
<code>
	model_lm = lm(y~x, data=data_with_dummyentries,  
weights=data_with_dummyentries$weight)
	res=segmented(obj=model_lm, seg.Z=~x, model=TRUE, psi=list(x=c(10,20)))
</code>

Hope it helps,

Melwin


From antony.akkara at ge.com  Fri Dec 20 10:58:33 2013
From: antony.akkara at ge.com (R_Antony)
Date: Fri, 20 Dec 2013 01:58:33 -0800 (PST)
Subject: [R] Execute Excel-Macro using R
Message-ID: <1387533513005-4682533.post@n4.nabble.com>

Hi,

How to execute ms-Excel Macro(*.xlsm) using R function ? I tried but not
get. There are method to call from R function from Excel macro, but i need
Excel macro to execute from R. Is it possible ? I am using Excel-2010 macro.

Thanks in advance,
Antony.






--
View this message in context: http://r.789695.n4.nabble.com/Execute-Excel-Macro-using-R-tp4682533.html
Sent from the R help mailing list archive at Nabble.com.


From joseclaudio.faria at gmail.com  Fri Dec 20 14:48:23 2013
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Fri, 20 Dec 2013 11:48:23 -0200
Subject: [R] Classification of polynomial regression: simple or multiple
 (conceptual doubt)
Message-ID: <CAN+Emd-=Kyh2gN-vT=Dyc-34z0ENe+XJN1rgV2iP33+SHUPHaQ@mail.gmail.com>

Dear list,

I'm posting in the R-help list due to:
- Not knowing a better place for it;
- I would like to know the opinion of more specialized people.

What is the best place to classify polynomial regressions (Y = bo +
b1X + b2X^2 + ... + bnX^n): single or multiple linear regression?

Regards,
-- 
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)9100.7351 - TIM
55(73)8817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\


From smartpink111 at yahoo.com  Fri Dec 20 15:05:20 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 20 Dec 2013 06:05:20 -0800 (PST)
Subject: [R] ftable and data.frame
In-Reply-To: <D5B598CE7BC64B7AABB700260084556A@uelHP>
References: <D5B598CE7BC64B7AABB700260084556A@uelHP>
Message-ID: <1387548320.40758.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
library(reshape2)
dcast(as.data.frame(tab1), SEX+ESTCIV~Q1,value.var="Freq") ##not tested.

A.K.




On Friday, December 20, 2013 8:03 AM, "silvano at uel.br" <silvano at uel.br> wrote:
Hi,

I used this command to produce a table:

(tab1 = ftable(SEX, ESTCIV, Q1))

? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  Q1? B? L? M? N
SEXO? ? ESTCIV
? ? ? ? F? ? ? ? ?  A? ? ? ?  11 13? 4? 2
? ? ? ? ? ? ? ? ? ? ? E? ? ? ? ? 1? 0? 0? 0
? ? ? ? M? ? ? ? ?  A? ? ? ? ? 5? 0? 3? 1
? ? ? ? ? ? ? ? ? ? ? E? ? ? ? ? 0? 0? 0? 0

but I need something like:


SEXO? ? ESTCIV? ? ? ? B? L? M? N
? ? ? F? ? ? ? ? ? A? ? ? ?  11 13? 4? 2
? ? ? F? ? ? ? ? ? E? ? ? ? ? 1? 0? 0? 0
? ? ? M? ? ? ? ?  A? ? ? ? ? 5? 0? 3? 1
? ? ? M? ? ? ? ?  E? ? ? ? ? 0? 0? 0? 0

How can I get it?

I need this format to use ordinal logistic regression and I have many tables.

Thanks,

Silvano.

---
Este email est? limpo de v?rus e malwares porque a prote??o do avast! Antiv?rus est? ativa.


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jrkrideau at inbox.com  Fri Dec 20 15:08:29 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 20 Dec 2013 06:08:29 -0800
Subject: [R] ftable and data.frame
In-Reply-To: <D5B598CE7BC64B7AABB700260084556A@uelHP>
Message-ID: <B6109CB6B16.00000712jrkrideau@inbox.com>

What does your original data look like?  I seems to me that it would be better to give us that information since you may not want to use ftable() at all.
Ideally you should give us the original data or a sample of it. If it's confidential just replace the actual values with fake data.  The structure of the data is more important than the values.

Please use dput() (see ?dput for information) to supply the data.  Just do :  dput(mydata) and then paste the result into the email.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: silvano at uel.br
> Sent: Fri, 20 Dec 2013 11:01:26 -0200
> To: r-help at r-project.org
> Subject: [R] ftable and data.frame
> 
> Hi,
> 
> I used this command to produce a table:
> 
> (tab1 = ftable(SEX, ESTCIV, Q1))
> 
>                                Q1  B  L  M  N
> SEXO    ESTCIV
>         F           A         11 13  4  2
>                       E          1  0  0  0
>         M           A          5  0  3  1
>                       E          0  0  0  0
> 
> but I need something like:
> 
> 
> SEXO    ESTCIV        B  L  M  N
>       F            A         11 13  4  2
>       F            E          1  0  0  0
>       M           A          5  0  3  1
>       M           E          0  0  0  0
> 
> How can I get it?
> 
> I need this format to use ordinal logistic regression and I have many
> tables.
> 
> Thanks,
> 
> Silvano.
> 
> ---
> Este email esta limpo de vmrus e malwares porque a protegco do avast!
> Antivmrus esta ativa.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From biogilson at gmail.com  Fri Dec 20 16:59:14 2013
From: biogilson at gmail.com (Gilson Carvalho)
Date: Fri, 20 Dec 2013 13:59:14 -0200
Subject: [R] Classification of polynomial regression: simple or multiple
 (conceptual doubt)
In-Reply-To: <CAN+Emd-=Kyh2gN-vT=Dyc-34z0ENe+XJN1rgV2iP33+SHUPHaQ@mail.gmail.com>
References: <CAN+Emd-=Kyh2gN-vT=Dyc-34z0ENe+XJN1rgV2iP33+SHUPHaQ@mail.gmail.com>
Message-ID: <CAJ8F2HENCLJQHOqW5ZP=ijP=kYbkMtRCiE4aHEyWq+yhENULEQ@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20131220/9e247380/attachment.pl>

From smartpink111 at yahoo.com  Fri Dec 20 16:58:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 20 Dec 2013 07:58:56 -0800 (PST)
Subject: [R] Using cbind to merge different variables
Message-ID: <1387555136.35753.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,

May be this helps:
set.seed(45)
?dat1 <- as.data.frame(matrix(sample(0:1,100*5,replace=TRUE),ncol=5))

dat1$Newvar <- 1*(!!rowSums(dat1))

A.K.


Hello. 

I have a problem combining a number of variables. I have five 
columns with binary variables with the values 0 and 1. I would like to 
combine them into just one binary variable with 1 whenever just one of 
the other has value one, and 0 if none of them have value one. 

How can I do that? 

I tried to use cbind function, but for some reason I get results
 1 even though all of the varuables included = 0 and for some rows I get
 2. I tried changing the deparse.level but that doesn't seem to be the 
problem. 

I hope someone can help. 

Kind regards


From 538280 at gmail.com  Fri Dec 20 17:03:48 2013
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 20 Dec 2013 09:03:48 -0700
Subject: [R] Using assign with mapply
In-Reply-To: <loom.20131219T175709-457@post.gmane.org>
References: <loom.20131206T200836-152@post.gmane.org>
	<loom.20131216T163956-835@post.gmane.org>
	<CAFEqCdy2ci1MMKAU9fpRVS5Dr7S8Q1a9WmnOpomUu_A=-UJ2Ew@mail.gmail.com>
	<loom.20131219T175709-457@post.gmane.org>
Message-ID: <CAFEqCdwVvwOUXHi2LrXAswhi_FAmB3roGp3VHm3jPbpVL2GS-g@mail.gmail.com>

Trying to understand environments is not for the faint of heart.  If
lists do what you want then I would stick with a list and not worry
about the environments.  Most of the time that you deal with
environments everything happens automatically behind the scenes and
you don't need to worry about the details.

If you want to learn more about environments there here is a start.
Many of the ways of working with environments is the same as working
with lists (you can access and assign with `[[` etc.) and there are
`as.` functions to convert between them.  The biggest difference is
that environments use references instead of copies (powerful but
dangerous).  If you do something like

mylist2 <- mylist
mylist2$x <- 1

then mylist 2 will be a copy of mylist 1 and the value of x within
mylist2 will be created or modified (but mylist will remain
unchanged).  However if you do the same thing with an environment then
a copy is not made and the `x` variable in the original environment
will be created or changed.  This can be a big benefit when you have a
large data object that needs to be passed to multiple functions, with
an environment the data will never be copied, with a list or other
object you may end up with multiple copies (though R is really good at
not making copies when it does not need to, but sometimes you still
end up with more copies than needed when R cannot tell if a copy is
needed or not), but this is dangerous in that if you make any changes
then the original is changed as well (the regular mechanism of making
copies on changes protects the original).

Environments also use hashing for name look ups which can speed things
up when you have a large number of variables that you are accessing by
name (but most usual cases are quick enough that you will not notice
when using lists or other objects).

Hope that helps,

On Thu, Dec 19, 2013 at 10:17 AM, Julio Sergio Santana
<juliosergio at gmail.com> wrote:
> Greg Snow <538280 <at> gmail.com> writes:
>
>>
>> The take home message that you should be learning from your struggles
>> is to "Not Use The 'assign' Function!" and "Do Not Use Global
>> Variables Like This".
>>
>> R has lists (and environments) that make working with objects that are
>> associated with each other much simpler and fits better with the
>> functional programming style of R.
>>
>
> Thanks, Greg!
>
> Yours is a very smart solution to the problem I posed.
>
> By the way, what I'm trying to do is reading from a file a set of user given
> parameters, in two paired columns: parameter-name, value; and then, managing
> these parameters inside my R program. Now I do understand a bit more about
> lists. What about environments? Are they similar to lists, and when, and how
> are they created?
>
> Best regrards,
>
>   -Sergio.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From capricyg at yahoo.com  Fri Dec 20 17:12:43 2013
From: capricyg at yahoo.com (capricy gao)
Date: Fri, 20 Dec 2013 08:12:43 -0800 (PST)
Subject: [R] hist() : is there a way to change the border width?
In-Reply-To: <52B3CC59.5080005@bitwrit.com.au>
References: <1387487955.31746.YahooMailNeo@web125002.mail.ne1.yahoo.com>
	<52B3CC59.5080005@bitwrit.com.au>
Message-ID: <1387555963.30127.YahooMailNeo@web125002.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131220/eae95f7f/attachment.pl>

From 538280 at gmail.com  Fri Dec 20 17:15:01 2013
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 20 Dec 2013 09:15:01 -0700
Subject: [R] A function which is a sum of other functions...
In-Reply-To: <8F1C96F7-DBB7-4C6D-A998-E793A529F955@gmail.com>
References: <8F1C96F7-DBB7-4C6D-A998-E793A529F955@gmail.com>
Message-ID: <CAFEqCdw8AdN+hybrC9McVnA2T_3afHpwj-1T_PurnWkHEjsBow@mail.gmail.com>

My first thought was to use Reduce, but I think for this case that is
a bit of overkill.  You can have a vector or list of functions and
just use sapply/lapply on the list of functions then sum the result.
A quick example:

> funs <- c(sin,cos,tan)
> sapply( funs, function(f) f(pi/6) )
[1] 0.5000000 0.8660254 0.5773503
> sum(sapply( funs, function(f) f(pi/6) ))
[1] 1.943376

Just wrap the above in a function with whatever options you want to
use.  If you need the functions to return vectors (of the same length)
then you can still use sapply, but use rowSums, colSums, or apply on
the result instead of sum.

On Thu, Dec 19, 2013 at 12:05 PM, Onur Uncu <onuruncu at gmail.com> wrote:
>
> Dear R Users
>
> I have a list of functions. Each function in the list is a function of single variable. I would like to create a function (of one variable) which represents the sum of all the functions in the list. So, if the functions in my list are f1(x),..,f5(x) then I would like a new function f(x)=f1(x)+f2(x)+...f5(x)
>
> Appreciate any suggestions on how to do this.
>
> I need the above f(x) function because I would like to minimise it with respect to x using the nlm function.
>
> Thanks.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From aurelien.philippot at gmail.com  Fri Dec 20 17:58:49 2013
From: aurelien.philippot at gmail.com (=?ISO-8859-1?Q?Aur=E9lien_Philippot?=)
Date: Fri, 20 Dec 2013 08:58:49 -0800
Subject: [R] Inconsistent computation of an integral
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1E377@PA-MBX01.na.tibco.com>
References: <CAOwh97uY26SYAaHuhLW+B0Lk6Y4zjCFeQbdubP2zCnpFLTnZ-g@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E377@PA-MBX01.na.tibco.com>
Message-ID: <CAOwh97tEptaKTj7yjCFd3Q08SEZT_hPvXS7N2AoskA7vDS596A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131220/cd36adb8/attachment.pl>

From wdunlap at tibco.com  Fri Dec 20 18:28:13 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 20 Dec 2013 17:28:13 +0000
Subject: [R] Inconsistent computation of an integral
In-Reply-To: <CAOwh97tEptaKTj7yjCFd3Q08SEZT_hPvXS7N2AoskA7vDS596A@mail.gmail.com>
References: <CAOwh97uY26SYAaHuhLW+B0Lk6Y4zjCFeQbdubP2zCnpFLTnZ-g@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1E377@PA-MBX01.na.tibco.com>
	<CAOwh97tEptaKTj7yjCFd3Q08SEZT_hPvXS7N2AoskA7vDS596A@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1E6CF@PA-MBX01.na.tibco.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131220/1c63c072/attachment.pl>

From onuruncu at gmail.com  Fri Dec 20 18:30:12 2013
From: onuruncu at gmail.com (Onur Uncu)
Date: Fri, 20 Dec 2013 17:30:12 +0000
Subject: [R] A function which is a sum of other functions...
In-Reply-To: <CAFEqCdw8AdN+hybrC9McVnA2T_3afHpwj-1T_PurnWkHEjsBow@mail.gmail.com>
References: <8F1C96F7-DBB7-4C6D-A998-E793A529F955@gmail.com>
	<CAFEqCdw8AdN+hybrC9McVnA2T_3afHpwj-1T_PurnWkHEjsBow@mail.gmail.com>
Message-ID: <FCFA615F-A7BF-47C9-BBC1-5D7A4703DB73@gmail.com>

Makes sense. Simple and works. Thank you Greg.

Sent from my iPhone

> On 20 Dec 2013, at 16:15, Greg Snow <538280 at gmail.com> wrote:
> 
> My first thought was to use Reduce, but I think for this case that is
> a bit of overkill.  You can have a vector or list of functions and
> just use sapply/lapply on the list of functions then sum the result.
> A quick example:
> 
>> funs <- c(sin,cos,tan)
>> sapply( funs, function(f) f(pi/6) )
> [1] 0.5000000 0.8660254 0.5773503
>> sum(sapply( funs, function(f) f(pi/6) ))
> [1] 1.943376
> 
> Just wrap the above in a function with whatever options you want to
> use.  If you need the functions to return vectors (of the same length)
> then you can still use sapply, but use rowSums, colSums, or apply on
> the result instead of sum.
> 
>> On Thu, Dec 19, 2013 at 12:05 PM, Onur Uncu <onuruncu at gmail.com> wrote:
>> 
>> Dear R Users
>> 
>> I have a list of functions. Each function in the list is a function of single variable. I would like to create a function (of one variable) which represents the sum of all the functions in the list. So, if the functions in my list are f1(x),..,f5(x) then I would like a new function f(x)=f1(x)+f2(x)+...f5(x)
>> 
>> Appreciate any suggestions on how to do this.
>> 
>> I need the above f(x) function because I would like to minimise it with respect to x using the nlm function.
>> 
>> Thanks.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com


From onuruncu at gmail.com  Fri Dec 20 18:38:02 2013
From: onuruncu at gmail.com (Onur Uncu)
Date: Fri, 20 Dec 2013 17:38:02 +0000
Subject: [R] by class...
Message-ID: <C1F4E0C5-C806-43D4-97DA-84A1144D9725@gmail.com>

I used the by() function on a data.frame to get sums of the data grouped by 2 factors. The function worked however the output is in a class called 'by'. Not familiar with this class. How can I turn the output into a nice table where columns represent values of factor1, row represent values of factor2 and the entries in the table are the sums that were calculated using the by function?

I did some web search which suggested using do.call(rbind, datframe_object) but this command gave the following error:
"Second argument must be a list"...


Thank you.

From dwinsemius at comcast.net  Fri Dec 20 18:42:01 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 Dec 2013 09:42:01 -0800
Subject: [R] ftable and data.frame
In-Reply-To: <D5B598CE7BC64B7AABB700260084556A@uelHP>
References: <D5B598CE7BC64B7AABB700260084556A@uelHP>
Message-ID: <66E0FEC7-7514-4C27-AC50-7EC7883C8038@comcast.net>


On Dec 20, 2013, at 5:01 AM, <silvano at uel.br> wrote:

> Hi,
> 
> I used this command to produce a table:

It's not actually a 'table'.

> 
> (tab1 = ftable(SEX, ESTCIV, Q1))

is.table(tab1) # will return FALSE

> 
>                               Q1  B  L  M  N
> SEXO    ESTCIV
>        F           A         11 13  4  2
>                      E          1  0  0  0
>        M           A          5  0  3  1
>                      E          0  0  0  0
> 
> but I need something like:
> 
> 
> SEXO    ESTCIV        B  L  M  N
>      F            A         11 13  4  2
>      F            E          1  0  0  0
>      M           A          5  0  3  1
>      M           E          0  0  0  0
> 
> How can I get it?

You need to describe the purpose of this effort. 

If is for display, the answer will be to look at the code for `print.ftable` (which eventually passes its arguments to `format.ftable`.

If it is for creating something other than an ftable (such a data.frame or character-matrix), then you will probably need to coerce the ftable to a matrix to get the entry values and then extract the row labels from the 'tab1'-object with:   attr(tab1, "row.vars") and `rep` them approriately. Or you could work with the output from format(ftable(tab1))[ ,1:2].

cbind( format(ftable(Titanic), quote=FALSE)[ ,1:3], 
       format(ftable(Titanic), quote=FALSE)[ ,5:6])
      [,1]    [,2]     [,3]    [,4]  [,5] 
 [1,] "     " "      " "     " " No" "Yes"
 [2,] "Class" "Sex   " "Age  " "   " "   "
 [3,] "1st  " "Male  " "Child" "  0" "  5"
 [4,] "     " "      " "Adult" "118" " 57"
 [5,] "     " "Female" "Child" "  0" "  1"
 [6,] "     " "      " "Adult" "  4" "140"
 [7,] "2nd  " "Male  " "Child" "  0" " 11"
 [8,] "     " "      " "Adult" "154" " 14"
 [9,] "     " "Female" "Child" "  0" " 13"
[10,] "     " "      " "Adult" " 13" " 80"
[11,] "3rd  " "Male  " "Child" " 35" " 13"
[12,] "     " "      " "Adult" "387" " 75"
[13,] "     " "Female" "Child" " 17" " 14"
[14,] "     " "      " "Adult" " 89" " 76"
[15,] "Crew " "Male  " "Child" "  0" "  0"
[16,] "     " "      " "Adult" "670" "192"
[17,] "     " "Female" "Child" "  0" "  0"
[18,] "     " "      " "Adult" "  3" " 20"

> 
> I need this format to use ordinal logistic regression and I have many tables.

That makes me think using ftable is the completely misguided approach. You should describe in more detail you plans to use ordinal logistic regression. I'm also wondering if you have used attach(). It would make more sense to keep these variables in a dataframe. Almost all regression functions expect input in the form of a normalized dataframe rather than in separate variables of aggregated counts.


> (tab1 = ftable(SEX, ESTCIV, Q1))
> 
> Thanks,
> 
> Silvano.
> 
> ---
> Este email est? limpo de v?rus e malwares porque a prote??o do avast! Antiv?rus est? ativa.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Dec 20 18:45:28 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 Dec 2013 09:45:28 -0800
Subject: [R] by class...
In-Reply-To: <C1F4E0C5-C806-43D4-97DA-84A1144D9725@gmail.com>
References: <C1F4E0C5-C806-43D4-97DA-84A1144D9725@gmail.com>
Message-ID: <53409224-6597-42C3-AAEB-752C2CB2C39E@comcast.net>


On Dec 20, 2013, at 9:38 AM, Onur Uncu wrote:

> I used the by() function on a data.frame to get sums of the data grouped by 2 factors. The function worked however the output is in a class called 'by'. Not familiar with this class. How can I turn the output into a nice table where columns represent values of factor1, row represent values of factor2 and the entries in the table are the sums that were calculated using the by function?
> 
> I did some web search which suggested using do.call(rbind, datframe_object) but this command gave the following error:
> "Second argument must be a list"...

The output of by() is always a list, so I would have expected:

do.call(rbind, by.object) to have retruned a different error message that what you suggest.


> 
> 
> Thank you.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kw.stat at gmail.com  Fri Dec 20 18:53:12 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 20 Dec 2013 11:53:12 -0600
Subject: [R] The difference between SAS and R
Message-ID: <CAKFxdiSPY3wGOx52GwqUz=QHrrc6Zdxh2Lyn3MB817ipMeqJAg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131220/f76f6704/attachment.pl>

From smartpink111 at yahoo.com  Fri Dec 20 19:17:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 20 Dec 2013 10:17:48 -0800 (PST)
Subject: [R] by class...
In-Reply-To: <C1F4E0C5-C806-43D4-97DA-84A1144D9725@gmail.com>
References: <C1F4E0C5-C806-43D4-97DA-84A1144D9725@gmail.com>
Message-ID: <1387563468.74318.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
as.table(by(warpbreaks[,1],warpbreaks[,-1],sum))


#or to convert to data.frame

as.data.frame(as.table(by(warpbreaks[,1],warpbreaks[,-1],mean)))
A.K.




On Friday, December 20, 2013 12:39 PM, Onur Uncu <onuruncu at gmail.com> wrote:
I used the by() function on a data.frame to get sums of the data grouped by 2 factors. The function worked however the output is in a class called 'by'. Not familiar with this class. How can I turn the output into a nice table where columns represent values of factor1, row represent values of factor2 and the entries in the table are the sums that were calculated using the by function?

I did some web search which suggested using do.call(rbind, datframe_object) but this command gave the following error:
"Second argument must be a list"...


Thank you.
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Dec 20 19:20:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 20 Dec 2013 10:20:45 -0800 (PST)
Subject: [R] by class...
In-Reply-To: <1387563468.74318.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <C1F4E0C5-C806-43D4-97DA-84A1144D9725@gmail.com>
	<1387563468.74318.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1387563645.36051.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
You can also try:
library(reshape2)
dcast(as.data.frame(as.table(by(warpbreaks[,1],warpbreaks[,-1],sum))),wool~tension, value.var="Freq")


A.K.


On , arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
as.table(by(warpbreaks[,1],warpbreaks[,-1],sum))


#or to convert to data.frame

as.data.frame(as.table(by(warpbreaks[,1],warpbreaks[,-1],mean)))
A.K.





On Friday, December 20, 2013 12:39 PM, Onur Uncu <onuruncu at gmail.com> wrote:
I used the by() function on a data.frame to get sums of the data grouped by 2 factors. The function worked however the output is in a class called 'by'. Not familiar with this class. How can I turn the output into a nice table where columns represent values of factor1, row represent values of factor2 and the entries in the table are the sums that were calculated using the by function?

I did some web search which suggested using do.call(rbind, datframe_object) but this command gave the following error:
"Second argument must be a list"...


Thank you.
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Dec 20 19:27:56 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 Dec 2013 10:27:56 -0800
Subject: [R] by class...
In-Reply-To: <53409224-6597-42C3-AAEB-752C2CB2C39E@comcast.net>
References: <C1F4E0C5-C806-43D4-97DA-84A1144D9725@gmail.com>
	<53409224-6597-42C3-AAEB-752C2CB2C39E@comcast.net>
Message-ID: <5168EF9D-FB9A-4CDC-A8EF-9FECA855BC83@comcast.net>


On Dec 20, 2013, at 9:45 AM, David Winsemius wrote:

> 
> On Dec 20, 2013, at 9:38 AM, Onur Uncu wrote:
> 
>> I used the by() function on a data.frame to get sums of the data grouped by 2 factors. The function worked however the output is in a class called 'by'. Not familiar with this class. How can I turn the output into a nice table where columns represent values of factor1, row represent values of factor2 and the entries in the table are the sums that were calculated using the by function?
>> 
>> I did some web search which suggested using do.call(rbind, datframe_object) but this command gave the following error:
>> "Second argument must be a list"...
> 
> The output of by() is always a list, so I would have expected:

Or maybe my memories are false.

?by
"This is always a list if simplify is false, otherwise a list or array (see tapply)."

So maybe you need simplify=FALSE

> 
> do.call(rbind, by.object) to have retruned a different error message that what you suggest.
> 
> 
>> 
>> 
>> Thank you.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From marongiu.luigi at gmail.com  Fri Dec 20 20:03:12 2013
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Fri, 20 Dec 2013 19:03:12 +0000
Subject: [R] t test for multiple classes
Message-ID: <CAMk+s2QuHQK32cKXVQ4U93PT0n7d8p+S20TTTBCTquzrss7LrQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131220/d382a531/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Fri Dec 20 20:58:41 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 20 Dec 2013 11:58:41 -0800
Subject: [R] by class...
In-Reply-To: <C1F4E0C5-C806-43D4-97DA-84A1144D9725@gmail.com>
References: <C1F4E0C5-C806-43D4-97DA-84A1144D9725@gmail.com>
Message-ID: <e6890692-052c-4cf5-bfa7-ee95169bc4fc@email.android.com>

You seem to be falling prey to a common misconception that "R" is some monolithic tool, when in fact it is a herd of cats.

The "by" function, from the "base" package, returns a list of results returned by your function. One approach to making a data frame out of that is to use the simplify2array function, transpose, and convert to data frame.

However, there are many other ways to aggregate data as well. Packages plyr, sqldf, data.table all have strengths and weaknesses, but you must always keep in mind that they are contributed packages and you have to refer to the package name if you ask here about using functions from them.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Onur Uncu <onuruncu at gmail.com> wrote:
>I used the by() function on a data.frame to get sums of the data
>grouped by 2 factors. The function worked however the output is in a
>class called 'by'. Not familiar with this class. How can I turn the
>output into a nice table where columns represent values of factor1, row
>represent values of factor2 and the entries in the table are the sums
>that were calculated using the by function?
>
>I did some web search which suggested using do.call(rbind,
>datframe_object) but this command gave the following error:
>"Second argument must be a list"...
>
>
>Thank you.
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pburns at pburns.seanet.com  Fri Dec 20 21:19:24 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 20 Dec 2013 20:19:24 +0000
Subject: [R] Strange subvector output --> x[n] != x[1:n][n]
In-Reply-To: <1387513982859-4682526.post@n4.nabble.com>
References: <1387513982859-4682526.post@n4.nabble.com>
Message-ID: <52B4A64C.8000709@pburns.seanet.com>

You've found an interesting corner of Circle 1
of 'The R Inferno'.

http://www.burns-stat.com/documents/books/the-r-inferno/

The issue is that your 'n' in the final case is
slightly less than 11.  So:

 > n
[1] 11
 > as.integer(n)
[1] 10
 > 1:n
  [1]  1  2  3  4  5  6  7  8  9 10 11

The mystery to me is why `:` thinks it is doing
an integer sequence but ends in 11 rather than 10.

Most people are likely to think the mystery is
why as.integer(n) is 10.  The reason is that coercion
to integer is truncation (except if the number is
really close to the integer farther from 0).  Why that
and not round?  Well, just because.  (Actually probably
speed back in the day when it could matter.)

Pat


On 20/12/2013 04:33, Gewart wrote:
> Hi, Can anyone explain what is going on...!?   For a vector
> "x=seq(min,max,0.01)", when generating sub-vector "a" based on a starting
> value "st", things go as expected as long as "st" is not too close to the
> beginning of "x".  For example, if x starts at -5 and increments by 0.01,
> whenever I try to generate the sub-vector "a" (as below) with a starting
> value of 0.49 or less it does not generate the expected output: The initial
> value of "a" is wrong.
>
> Thanks in advance for any clarity you can shed.
> Gary
>
> ...(please see two versions of code below)....
>
> #THIS WORKS...(st > -4.9)
>
> 	min = -5; max = 1;  x=seq(min,max,0.01)
>
> 	st= -4.8 ; end= 0
>
> 	a=x[((st-min)/0.01+1):((end-min)/0.01+1)]
> 	
> 			n=(st-min)/0.01+1
> #compare	
> 	a[1:10]; c(x[n:(n+9)])
>
> #test...
> 	n
> 	x[1:n]; x[n]           ### x[n]== x[1:n][n] ; As expected
> ##########################################################
> #  BUT THIS IS WEIRD!!...(st <= -4.9)
> 	
> 	st= -4.90 ; end= 0     ### -> BUG in generation of a!!
>
> 	a=x[((st-min)/0.01+1):((end-min)/0.01+1)];
> 	
> 			n=(st-min)/0.01+1
> #compare	
> 	a[1:10]; c(x[n:(n+9)])
> #test
> 	n
> 	x[1:n]; x[n]  ### NOW x[n] != x[1:n][n]   !!?? What is going on!?
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Strange-subvector-output-x-n-x-1-n-n-tp4682526.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From dimitri.liakhovitski at gmail.com  Fri Dec 20 21:21:56 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 20 Dec 2013 15:21:56 -0500
Subject: [R] Grab multinomial coefficients
Message-ID: <CAN2xGJaew52UQoUo1wjwTqX6STSD7Wo5b2OFvnmo7h6+ziVFow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131220/aa812932/attachment.pl>

From ruipbarradas at sapo.pt  Fri Dec 20 22:18:59 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 20 Dec 2013 21:18:59 +0000
Subject: [R] Grab multinomial coefficients
In-Reply-To: <CAN2xGJaew52UQoUo1wjwTqX6STSD7Wo5b2OFvnmo7h6+ziVFow@mail.gmail.com>
References: <CAN2xGJaew52UQoUo1wjwTqX6STSD7Wo5b2OFvnmo7h6+ziVFow@mail.gmail.com>
Message-ID: <52B4B443.8070209@sapo.pt>

Hello,

Try

coef(mnl)

Hope this helps,

Rui Barradas

Em 20-12-2013 20:21, Dimitri Liakhovitski escreveu:
> Hello!
>
> I am using function multinom:
>
> library(nnet)
> library(MASS)
>
> mnl<-multinom(myDV~. ,data=mydata,na.action="na.omit", MaxNWts = 2000,
> maxit = 1000)
>
>
> I can see the resulting coefficients:
>
> print(mnl)
>
> But how could I grab them? I am not finding them when I do:
> str(mnl)
>
> Thank you!
>


From dimitri.liakhovitski at gmail.com  Fri Dec 20 22:27:05 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 20 Dec 2013 16:27:05 -0500
Subject: [R] Grab multinomial coefficients
In-Reply-To: <52B4B443.8070209@sapo.pt>
References: <CAN2xGJaew52UQoUo1wjwTqX6STSD7Wo5b2OFvnmo7h6+ziVFow@mail.gmail.com>
	<52B4B443.8070209@sapo.pt>
Message-ID: <CAN2xGJab3HzjB4JMxDjE=jK3Jo3KUe22W_SFX7esLoxfKwHvbw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131220/9366e836/attachment.pl>

From optionsraghu at gmail.com  Sat Dec 21 10:47:37 2013
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Sat, 21 Dec 2013 09:47:37 +0000
Subject: [R] Execute Excel-Macro using R
In-Reply-To: <1387533513005-4682533.post@n4.nabble.com>
References: <1387533513005-4682533.post@n4.nabble.com>
Message-ID: <CADgEnD=nGwb-1QX3voc9Anc9=Ui=JH00B4rS1327vQ8wfY4tGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131221/39ea08d3/attachment.pl>

From jrkrideau at inbox.com  Sat Dec 21 16:38:55 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 21 Dec 2013 07:38:55 -0800
Subject: [R] by class...
In-Reply-To: <e6890692-052c-4cf5-bfa7-ee95169bc4fc@email.android.com>
References: <c1f4e0c5-c806-43d4-97da-84a1144d9725@gmail.com>
Message-ID: <C36D628BAD9.00000329jrkrideau@inbox.com>

Nominate for a fortune.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jdnewmil at dcn.davis.ca.us
 You seem to be falling prey to a common misconception that "R" is some monolithic tool, when in fact it is a herd of cats.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From dgibbs7 at gatech.edu  Sat Dec 21 18:22:59 2013
From: dgibbs7 at gatech.edu (David Gibbs)
Date: Sat, 21 Dec 2013 12:22:59 -0500
Subject: [R] Simplifying coxme models
Message-ID: <CAKEo23bR4m+N9nrw_cW=Q=7DBChG=-yNpfdw78_CuumW9vdicw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131221/534a3b93/attachment.pl>

From gunter.berton at gene.com  Sat Dec 21 19:32:21 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 21 Dec 2013 10:32:21 -0800
Subject: [R] Simplifying coxme models
In-Reply-To: <CAKEo23bR4m+N9nrw_cW=Q=7DBChG=-yNpfdw78_CuumW9vdicw@mail.gmail.com>
References: <CAKEo23bR4m+N9nrw_cW=Q=7DBChG=-yNpfdw78_CuumW9vdicw@mail.gmail.com>
Message-ID: <CACk-te2fpNp2VLDi4Zs+egc3wOEKGZvSjWMGnp+e-wgOmoohPw@mail.gmail.com>

As you seem to be wandering in the wilderness here, it sounds like you
should really be seeking local statistical help that can provide a
fuller 1-1 discussion, rather than posting on the internet.
Alternatively, although you are working within R, your questions are
primarily about statistical matters, for which stats.stackexchange.com
is a better fit. We tend to be more focused on R programming and
features rather than statistics on this list, although they certainly
overlap.

Of course, you may get lucky -- Terry is often generous with his time
and advice -- but if you do not...

Cheers,
Bert



On Sat, Dec 21, 2013 at 9:22 AM, David Gibbs <dgibbs7 at gatech.edu> wrote:
> Hello all,
>
> I have some questions about specifying a coxme model and then simplifying
> it after reading the coxme documentation and posts here. The situation is
> this:
>
> I glued 4 pieces of small coral fragments onto small ceramic tiles, which I
> placed at 4 distances east and west of 10 large coral colonies (i.e. site).
> Thus, each tile represents one distance-direction-site combination. I
> checked the small coral fragments daily to see which had died overnight and
> at the end of the experiment some were still alive (thus, censored). I
> therefore had 4 fragments per tile*4 distances*2 directions*10 sites = 320
> small fragments. Distance and direction are fixed effects, while the tile
> that each fragment is on and the site are random effects. In addition, each
> large colony is a different size, so the size of the large colonies should
> be a random effect, too (SiteSize).
>
> The model I wrote to express this is:
> mefull<-coxme(Surv(death, censor) ~ Distance*Direction+(1|Site/Tile)
> +(1|SiteSize))
>
> First, can anyone tell me if this properly specifies the situation I
> described above?
>
> After running this model, I found that neither fixed effect nor their
> interaction was significant. Also, the standard deviation for Site and
> SiteSize are identical (~1.12), which seems strange to me. Is there a
> reason for that? The fact that they are both greater than 1 indicates to me
> that they contribute a lot of variation to survival. Is that correct?
>
> My next major question is how to simplify this model. My instinct (and
> based on reading Terry Therneau's manuals and other posts here) is to
> remove each random effect in turn and compare the AICs of the integrated
> log-likelihood of the resulting models; the higher AIC is the preferred
> model in this formulation. Is that correct?
>
> However, I'd also like to try to try to simplify the model through removal
> of the non-significant fixed effects, starting with their interaction. How
> can I do this while also removing random effects? What terms should I start
> with removing, or does the order not matter as long as I start with
> higher-order terms (i.e. interaction)? Can I try as many combinations as I
> like or do issues with multiple tests come into play?
>
> Some options are removing one of the random effects (me2) or removing the
> interaction between the fixed effects but keeping the random effects in
> place (me3).
> me2<-coxme(surv ~ Distance*Direction+(1|Site/Tile))
> me3<-coxme(surv ~ Distance+Direction+(1|Site/Tile)+(1|SiteSize))
>
> When I run these and other combinations of factors, their AIC is always
> lower than that of the full model, which suggests to me that the full model
> is best. Any guidance on how to simplify this model would be greatly
> appreciated.
>
> Finally, to compare the model with random effects to one without, can I
> compare the NULL log-likelihood with the integrated log-likelihood? From my
> understanding of the coxme manual, the one closer to 0 is the better model,
> so if the integrated one is closer to 0 then the model with random effects
> is preferred over the one without random effects.
>
> Thanks very much for your time and help.
>
> David Gibbs
> Georgia Institute of Technology
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From shanemcmahon at wisc.edu  Sat Dec 21 20:29:02 2013
From: shanemcmahon at wisc.edu (Shane McMahon)
Date: Sat, 21 Dec 2013 11:29:02 -0800
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
Message-ID: <52B5EBFE.2080203@wisc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131221/1ce81b4b/attachment.pl>

From goran.brostrom at umu.se  Sat Dec 21 23:57:36 2013
From: goran.brostrom at umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sat, 21 Dec 2013 23:57:36 +0100
Subject: [R] seq_len and loops
Message-ID: <52B61CE0.10805@umu.se>

I was recently reminded on this list that

"Using 1:ncol() is bad practice (seq_len is designed for that purpose)" 
(Ripley)

This triggers the following question: What is "good practice" for 
2:ncol(x)? (This is not a joke; in a recursive situation it often makes 
sense to perform the calculation for the start value i = 1, then 
continue with a loop over the rest, "the Fortran way";)

I usually use

if (ncol(x) > 1)
     for (i in 2:ncol(x)){
        ....

but I can think of

for (i in seq_len(x - 1)){
     I <- i + 1
    ....

and

i <- 1
while (i < ncol(x)){
     i <- i + 1
     ....

What is "good practice" (efficient and safe)?

G?ran Brostr?m


From f.harrell at Vanderbilt.Edu  Sun Dec 22 00:18:45 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Sat, 21 Dec 2013 17:18:45 -0600
Subject: [R] Possible to vary widths and/or heights of lattice panels?
Message-ID: <52B621D5.3000902@vanderbilt.edu>

Is it possible to vary the size of the panels in lattice within one 
page?  The examine I have in mind is a 3 row by 2 column display where I 
vary the y-axis scales in a dot plot and there are only a few levels on 
the y-axis for one of the rows.  I'd like to remove wasted space in that 
row.

On a related issue 
http://stackoverflow.com/questions/9654244/multipage-lattice-panel-arrangement 
has some good information.

Thanks for any pointers.
Frank


From murdoch.duncan at gmail.com  Sun Dec 22 00:50:13 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 21 Dec 2013 18:50:13 -0500
Subject: [R] seq_len and loops
In-Reply-To: <52B61CE0.10805@umu.se>
References: <52B61CE0.10805@umu.se>
Message-ID: <52B62935.50909@gmail.com>

On 13-12-21 5:57 PM, G?ran Brostr?m wrote:
> I was recently reminded on this list that
>
> "Using 1:ncol() is bad practice (seq_len is designed for that purpose)"
> (Ripley)
>
> This triggers the following question: What is "good practice" for
> 2:ncol(x)? (This is not a joke; in a recursive situation it often makes
> sense to perform the calculation for the start value i = 1, then
> continue with a loop over the rest, "the Fortran way";)
>
> I usually use
>
> if (ncol(x) > 1)
>       for (i in 2:ncol(x)){
>          ....
>
> but I can think of
>
> for (i in seq_len(x - 1)){
>       I <- i + 1
>      ....
>
> and
>
> i <- 1
> while (i < ncol(x)){
>       i <- i + 1
>       ....
>
> What is "good practice" (efficient and safe)?

for (i in seq_len(x - 1) + 1)

should be efficient and safe.  A little less efficient, but clearer would be

for (i in seq_len(x)[-1])

Duncan Murdoch


From murdoch.duncan at gmail.com  Sun Dec 22 00:51:44 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 21 Dec 2013 18:51:44 -0500
Subject: [R] seq_len and loops
In-Reply-To: <52B62935.50909@gmail.com>
References: <52B61CE0.10805@umu.se> <52B62935.50909@gmail.com>
Message-ID: <52B62990.6070404@gmail.com>

On 13-12-21 6:50 PM, Duncan Murdoch wrote:
> On 13-12-21 5:57 PM, G?ran Brostr?m wrote:
>> I was recently reminded on this list that
>>
>> "Using 1:ncol() is bad practice (seq_len is designed for that purpose)"
>> (Ripley)
>>
>> This triggers the following question: What is "good practice" for
>> 2:ncol(x)? (This is not a joke; in a recursive situation it often makes
>> sense to perform the calculation for the start value i = 1, then
>> continue with a loop over the rest, "the Fortran way";)
>>
>> I usually use
>>
>> if (ncol(x) > 1)
>>        for (i in 2:ncol(x)){
>>           ....
>>
>> but I can think of
>>
>> for (i in seq_len(x - 1)){
>>        I <- i + 1
>>       ....
>>
>> and
>>
>> i <- 1
>> while (i < ncol(x)){
>>        i <- i + 1
>>        ....
>>
>> What is "good practice" (efficient and safe)?
>
> for (i in seq_len(x - 1) + 1)
>
> should be efficient and safe.

Oops, not safe when x is 0.

 >
A little less efficient, but clearer would be
>
> for (i in seq_len(x)[-1])
>
> Duncan Murdoch
>


From rmh at temple.edu  Sun Dec 22 03:45:42 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 21 Dec 2013 21:45:42 -0500
Subject: [R] Possible to vary widths and/or heights of lattice panels?
In-Reply-To: <52B621D5.3000902@vanderbilt.edu>
References: <52B621D5.3000902@vanderbilt.edu>
Message-ID: <CAGx1TMCfzPKOF3m1g=Gduw30fn95xZRwkS8V3McMcBjkzWWZdQ@mail.gmail.com>

library(latticeExtra)
?resizePanels

On Sat, Dec 21, 2013 at 6:18 PM, Frank Harrell <f.harrell at vanderbilt.edu> wrote:
> Is it possible to vary the size of the panels in lattice within one page?
> The examine I have in mind is a 3 row by 2 column display where I vary the
> y-axis scales in a dot plot and there are only a few levels on the y-axis
> for one of the rows.  I'd like to remove wasted space in that row.
>
> On a related issue
> http://stackoverflow.com/questions/9654244/multipage-lattice-panel-arrangement
> has some good information.
>
> Thanks for any pointers.
> Frank
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hb at biostat.ucsf.edu  Sun Dec 22 04:13:13 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 21 Dec 2013 19:13:13 -0800
Subject: [R] seq_len and loops
In-Reply-To: <52B61CE0.10805@umu.se>
References: <52B61CE0.10805@umu.se>
Message-ID: <CAFDcVCSGG_cBEoWhQNew4mPY-BL2D6i1NN+TezRsYkCedMCMjg@mail.gmail.com>

What about

seq_len2 <- function(length.out, from=1L) {
  seq(from=from, length.out=max(0L, length.out-from+1L))
}

> lapply(0:4, FUN=seq_len2, from=2L)
[[1]]
integer(0)
[[2]]
integer(0)
[[3]]
[1] 2
[[4]]
[1] 2 3
[[5]]
[1] 2 3 4

/Henrik

On Sat, Dec 21, 2013 at 2:57 PM, G?ran Brostr?m <goran.brostrom at umu.se> wrote:
> I was recently reminded on this list that
>
> "Using 1:ncol() is bad practice (seq_len is designed for that purpose)"
> (Ripley)
>
> This triggers the following question: What is "good practice" for 2:ncol(x)?
> (This is not a joke; in a recursive situation it often makes sense to
> perform the calculation for the start value i = 1, then continue with a loop
> over the rest, "the Fortran way";)
>
> I usually use
>
> if (ncol(x) > 1)
>     for (i in 2:ncol(x)){
>        ....
>
> but I can think of
>
> for (i in seq_len(x - 1)){
>     I <- i + 1
>    ....
>
> and
>
> i <- 1
> while (i < ncol(x)){
>     i <- i + 1
>     ....
>
> What is "good practice" (efficient and safe)?
>
> G?ran Brostr?m
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Sun Dec 22 04:17:51 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 22 Dec 2013 13:17:51 +1000
Subject: [R] Possible to vary widths and/or heights of lattice panels?
In-Reply-To: <52B621D5.3000902@vanderbilt.edu>
References: <52B621D5.3000902@vanderbilt.edu>
Message-ID: <000001cefec4$65e51480$31af3d80$@bigpond.com>

Hi Frank

I am not sure what you need as there are various alternatives

for starters 
?latticeExtra::combineLimits

see 
http://finzi.psych.upenn.edu/R/Rhelp02/archive/43612.html
http://finzi.psych.upenn.edu/R/Rhelp02/archive/43626.html

I tried to check that these were the correct urls but I do not know if the
server is down.

This is Deepyan's code

xyplot(as.numeric(variety) ~ yield | year * site, data = barley,
       layout = c(6,2),
       scales = list(y = list(relation = "free",
                              rot = 0,
                              limits = rep(list( c(0, 6),   c( 5, 11 )),
c(6, 6)),
                              at     = rep(list( 1:5, NULL, 6:10, NULL ),
c(1, 5, 1, 5) ))),
       par.settings = list(layout.widths = list(axis.panel = rep(c(1, 0),
c(1, 5))))
)

Below is some code and templates for plots. I have stripped them down as
they are very long to get what I wanted particularly the large graph which
fitted on an A4 page

# varying ylimits
*********
# part of an a graph 5 rows x 7 cols
xyplot(GrowthMJ+I(SuppMJ+75)+GrowSuppMJ+Demand+Balance ~ Date, data =
balance,
       as.table = T,
       layout   = c(1, 5),
       outer    = TRUE,
       groups   = gFarm,
       strip    = FALSE,
       par.settings = list(layout.heights = list(panel =
c(55,15,55,20,60)/sum(c(55,15,20,55,60))) ), # see below
       scales   = list(x = list(alternating = FALSE),
                       y = list(alternating = FALSE,
                                relation    = "free",
                                axs         = "i",
                                limits      = list(c(0,55000),
                                                   c(0, 5000),
                                                   c(0,55000),
                                                   c(0,20000),
                                                   c(-10000,50000) ),
                                at          = list(seq(0,50000,10000),
                                                   seq(0, 4000, 2000),
                                                   seq(0,50000,10000),
                                                   seq(0,15000, 5000),
                                                   seq(-10000,40000,10000)
),
                                labels      = list(as.character(seq(0,50,10)
),
                                                   as.character(seq(0, 4, 2)
),
                                                   as.character(seq(0,50,10)
),
                                                   as.character(seq(0,15, 5)
),
 
as.character(seq(-10,40,10)) ),
                                rot         = 0)
                   ), 

# vary the panel heights: if limits c(0, max) then take max values for all
row limits and divide by sum 

# If missing panels
# 3x3
coln <- number of columns
rown <- number of rows

par.settings = list(layout.heights = list(panel = 1), # vary the panel
heights: 
...                                                                     
scales = limits(y = list(
   limits = rep(list(c(0,1), c(0,2), c(0,3)), ea = ncol),
   at     = rep(list(seq(0,1,0.5), NULL, seq(0,2,0.5), NULL, seq(0,3,1),
NULL), rep(c(1,ncol-1), nrow)),
   labels = rep(list(seq(0,1,0.5), NULL, seq(0,2,0.5), NULL, seq(0,3,1),
NULL), rep(c(1,ncol-1), nrow))),

# varying xlimits
*********
# part of an example  3 x 3 panels
library(latticeExtra)

useOuterStrips
xyplot(GLoss+DLoss+LLoss ~ SRday|Farm,  meb,
outer    = TRUE,
par.settings = list(layout.widths = list(panel = c(0.25, 0.25, 0.5)), # sum
to 1 to vary the widths
scales   = list(x = list(alternating = FALSE,
                         relation    = "free",
                         limits = rep(list(c(-30, 250),
                                           c(-30, 250),
                                           c(-30, 550)), 3),
                         at    = rep(list(NULL,
                                           seq(0, 200, by = 50),
                                           seq(0, 200, by = 50),
                                           seq(0, 500, by = 100)),
                                           c((3-1)*3, rep(1, 3)) ),
                         labels = rep(list(NULL,
                                           paste(seq(0, 200, by = 50)),
                                           paste(seq(0, 200, by = 50)),
                                           paste(seq(0, 500, by = 100))),
                                           c((3-1)*3, rep(1, 3)) ),
                         axs = "i",
                         rot         = 0),
                y = list(alternating = FALSE,
                         relation    = "same",
                         rot         = 0)
            ),

If you want further information you can contact me offline

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Frank Harrell
Sent: Sunday, 22 December 2013 09:19
To: RHELP
Subject: [R] Possible to vary widths and/or heights of lattice panels?

Is it possible to vary the size of the panels in lattice within one page?
The examine I have in mind is a 3 row by 2 column display where I vary the
y-axis scales in a dot plot and there are only a few levels on the y-axis
for one of the rows.  I'd like to remove wasted space in that row.

On a related issue
http://stackoverflow.com/questions/9654244/multipage-lattice-panel-arrangeme
nt
has some good information.

Thanks for any pointers.
Frank

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Sun Dec 22 05:00:50 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 22 Dec 2013 14:00:50 +1000
Subject: [R] plot different groups as factors
In-Reply-To: <CAMk+s2QdXD9qHdicnOA0DVhhJi3--mcKPg15E4B052236oRWgw@mail.gmail.com>
References: <CAMk+s2TGB4aCvbHPGvj2GK4N30DEchqD7q01U933UGbhc1iLLw@mail.gmail.com>	<001e01cefcb6$67c00d10$37402730$@bigpond.com>
	<CAMk+s2QdXD9qHdicnOA0DVhhJi3--mcKPg15E4B052236oRWgw@mail.gmail.com>
Message-ID: <000001cefeca$6783e8b0$368bba10$@bigpond.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131222/c7d9ccc6/attachment.pl>

From rewarp at gmail.com  Sun Dec 22 02:36:28 2013
From: rewarp at gmail.com (Rewarp)
Date: Sat, 21 Dec 2013 19:36:28 -0600
Subject: [R] Unable to install RcppEigen package due to Rcpp dependency
	issues
Message-ID: <CAO7fSPt8bbcPo+_qUzi5t9GFM_91foAu0is0S_XVO8Qqs4NzBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131221/1bf3c862/attachment.pl>

From pdalgd at gmail.com  Sun Dec 22 10:00:05 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 22 Dec 2013 10:00:05 +0100
Subject: [R] The difference between SAS and R
In-Reply-To: <CAKFxdiSPY3wGOx52GwqUz=QHrrc6Zdxh2Lyn3MB817ipMeqJAg@mail.gmail.com>
References: <CAKFxdiSPY3wGOx52GwqUz=QHrrc6Zdxh2Lyn3MB817ipMeqJAg@mail.gmail.com>
Message-ID: <B9BEDA1F-95E6-4CF4-9827-CE0B1660BB36@gmail.com>


On 20 Dec 2013, at 18:53 , Kevin Wright <kw.stat at gmail.com> wrote:

> SAS uses words.  R uses symbols.
> 
> See this:
> http://xkcd.com/1306/
> 
> (Yes, I know IML uses plenty of symbols.  It's just supposed to be funny.
> And somewhat true.)
> 

Actually, R is on par with C++ when it comes to _prefixed_ symbols like #missedthepoint, which is what the XKCD strip is about. In terms of general operators, SAS would be approaching COBOL (famous for "ADD YEARS TO AGE" like construct) were it not for the DATA step and the %MACRO language.

(The preceding XKCD (1305) is quite nice, by the way.) 

> -- 
> Kevin Wright
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Ted.Harding at wlandres.net  Sun Dec 22 10:59:16 2013
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Sun, 22 Dec 2013 09:59:16 -0000 (GMT)
Subject: [R] Season's Greetings (and great news ... )!
Message-ID: <XFMail.20131222095916.Ted.Harding@wlandres.net>

Greetings All!
With the Festive Season fast approaching, I bring you joy
with the news (which you will surely wish to celebrate)
that R cannot do arithmetic!

Usually, this is manifest in a trivial way when users report
puzzlement that, for instance,

  sqrt(pi)^2 == pi
  # [1] FALSE

which is the result of a (generally trivial) rounding or
truncation error:

  sqrt(pi)^2 - pi
  [1] -4.440892e-16

But for some very simple calculations R goes off its head.

I had originally posted this example some years ago, but I
have since generalised it, and the generalisation is even
more entertaining than the original.

The Original:
Consider a sequence generated by the recurrence relation

  x[n+1] = 2*x[n] if 0 <= x[n] <= 1/2
  x[n+1] = 2*(1 - x[n]) if 1/2 < x[n] <= 1

(for 0 <= x[n] <= 1).

This has equilibrium points (x[n+1] = x[n]) at x[n] = 0
and at x[n] = 2/3:

  2/3 -> 2*(1 - 2/3) = 2/3

It also has periodic points, e.g.

  2/5 -> 4/5 -> 2/5 (period 2)
  2/9 -> 4/9 -> 8/9 -> 2/9 (period 3)

The recurrence relation can be implemented as the R function

  nextx <- function(x){
    if( (0<=x)&(x<=1/2) ) {x <- 2*x} else {x <- 2*(1 - x)}
  }

Now have a look at what happens when we start at the equilibrium
point x = 2/3:

  N <- 1 ; x <- 2/3
  while(x > 0){
    cat(sprintf("%i: %.9f\n",N,x))
    x <- nextx(x) ; N <- N+1
  }
  cat(sprintf("%i: %.9f\n",N,x))

Run that, and you will see that successive values of x collapse
towards zero. Things look fine to start with:

  1: 0.666666667
  2: 0.666666667
  3: 0.666666667
  4: 0.666666667
  5: 0.666666667
  ...

but, later on,

  24: 0.666666667
  25: 0.666666666
  26: 0.666666668
  27: 0.666666664
  28: 0.666666672
  ...

  46: 0.667968750
  47: 0.664062500
  48: 0.671875000
  49: 0.656250000
  50: 0.687500000
  51: 0.625000000
  52: 0.750000000
  53: 0.500000000
  54: 1.000000000
  55: 0.000000000

What is happening is that, each time R multiplies by 2, the binary
representation is shifted up by one and a zero bit is introduced
at the bottom end. To illustrate this, do the calculation in
7-bit arithmetic where 2/3 = 0.1010101, so:

0.1010101  x[1], >1/2 so subtract from 1 = 1.0000000 -> 0.0101011,
and then multiply by 2 to get x[2] = 0.1010110. Hence

0.1010101  x[1] -> 2*(1 - 0.1010101) = 2*0.0101011 ->
0.1010110  x[2] -> 2*(1 - 0.1010110) = 2*0.0101010 ->
0.1010100  x[3] -> 2*(1 - 0.1010100) = 2*0.0101100 ->
0.1011000  x[4] -> 2*(1 - 0.1011000) = 2*0.0101000 ->
0.1010000  x[5] -> 2*(1 - 0.1010000) = 2*0.0110000 ->
0.1100000  x[6] -> 2*(1 - 0.1100000) = 2*0.0100000 ->
0.1000000  x[7] -> 2*0.1000000 = 1.0000000 ->
1.0000000  x[8] -> 2*(1 - 1.0000000) = 2*0 ->
0.0000000  x[9] and the end of the line.

The final index of x[i] is i=9, 2 more than the number of binary
places (7) in this arithmetic, since 8 successive zeros have to
be introduced. It is the same with the real R calculation since
this is working to .Machine$double.digits = 53 binary places;
it just takes longer (we reach 0 at x[55])! The above collapse
to 0 occurs for any starting value in this simple example (except
for multiples of 1/(2^k), when it works properly).

Generalisation:
This is basically the same, except that everything is multiplied
by a scale factor S, so instead of being on the interval [0,1].
it is on [0,S], and

  x[n+1] = 2*x[n] if 0 <= x[n] <= S/2
  x[n+1] = 2*(S - x[n]) if S/2 < x[n] <= S
(for 0 <= x[n] <= S).

Again, x[n] = 2*S/3 is an equilibrium point. 2*S/3 > S/2, so

  x[n] -> 2*(S - 2*S/3) = 2*(S/3) = 2*S/3

Functions to implement this:

  nxtS <- function(x,S){
    if((x >= 0)&(x <= S/2)){ x<- 2*x } else {x <- 2*(S-x)}
  }

  S <- 6 ##  Or some other value of S
  Nits <- 100
  x <- 2*S/3
  N <- 1 ; print(c(N,x))
  while(x>0){
  if(N > Nits) break   ### to stop infinite looping
  N <- (N+1) ; x <- nxtS(x,S)
  print(c(N,x))
}

The behaviour of the sequence now depends on the value of S.

If S is a multiple of 3, then with x[1] = 2*S/3 the equilibrium
is immediately attained and x[n] = 2*S/3 forever after, since
R is now calculating with integers. E.g. try the above with S<-6
That is what arithmetic ought to be like! But for S not a multiple
of 3 one can get the impression that R is on some sort of drug!

For other values of S (but not all) we observe the same collapse
to x=0 as before, and again it takes 54 steps (ending with x[55]).
Try e.g. S <- 16

For some values of S, however, the iteration ends up in a periodic loop.

For example, with S<-7, at x[52] we get x[52]=4, x[53]=6, x[54]=2,
and then 4 6 2 4 6 2 4 6 2 ... forever (or until Nits cuts in),
so period = 3.

For S<-11, x[52]=8 then 6 then 10 then 2 then 4 then 8 6 10 2 4 ...
so period = 5.

For S<-13, x[51]=4 then 8 10 6 12 2 4 8 10 6 12 2 4 8 ...
so period = 6.

For S<-19, x[51]=12 then 14 10 18 2 4 8 16 6 12 ...
so period = 9.

And so on ...

So, one sniff of something like S<-19, and R is off its head!

All it has to do is multiply by 2 -- and it gets it cumulatively wrong!
R just doesn't add up ...

Season's Greetings to all -- and may your calculations always
be accurate -- to within machine precision ...

Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 22-Dec-2013  Time: 09:59:00
This message was sent by XFMail


From daniel.haugstvedt at gmail.com  Sun Dec 22 12:42:50 2013
From: daniel.haugstvedt at gmail.com (Daniel Haugstvedt)
Date: Sun, 22 Dec 2013 12:42:50 +0100
Subject: [R] Knitr, ggplot and consistent fonts
Message-ID: <CANKVVa3SqzK8nXA0kEmg=Npe2PuJ+MqnFQsU-7M1KvaSN7t2aw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131222/fff357ed/attachment.pl>

From f.harrell at Vanderbilt.Edu  Sun Dec 22 14:03:40 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Sun, 22 Dec 2013 07:03:40 -0600
Subject: [R] Possible to vary widths and/or heights of lattice panels?
Message-ID: <52B6E32C.8070805@vanderbilt.edu>

Thanks very much Rich and Duncan.  latticeExtra's resizePanels function 
was a perfect solution.

Frank


From dulcalma at bigpond.com  Sun Dec 22 14:39:43 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 22 Dec 2013 23:39:43 +1000
Subject: [R] Possible to vary widths and/or heights of lattice panels?
In-Reply-To: <52B6E32C.8070805@vanderbilt.edu>
References: <52B6E32C.8070805@vanderbilt.edu>
Message-ID: <000001ceff1b$46729f80$d357de80$@bigpond.com>

Frank

I forgot about resizePanels but I sometimes have used the "old way" -- pre
latticeExtra to get exactly what I want. 
I find it is easier to make small changes when trying to get a large number
of rows eg (5-7)  etc onto a page especially in conjunction with modifying
the yaxis labels sensu
http://tolstoy.newcastle.edu.au/R/e2/help/07/07/20452.html

Not all my lattice graphs are simple  

Duncan 

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Frank Harrell
Sent: Sunday, 22 December 2013 23:04
To: RHELP
Subject: Re: [R] Possible to vary widths and/or heights of lattice panels?

Thanks very much Rich and Duncan.  latticeExtra's resizePanels function was
a perfect solution.

Frank

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From elham_h763 at yahoo.com  Sun Dec 22 16:40:21 2013
From: elham_h763 at yahoo.com (Patty Haaem)
Date: Sun, 22 Dec 2013 07:40:21 -0800 (PST)
Subject: [R] How do I separate elements of a vector by comma?
Message-ID: <1387726821.18931.YahooMailNeo@web141104.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131222/b444e4ee/attachment.pl>

From smartpink111 at yahoo.com  Sun Dec 22 16:57:17 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 22 Dec 2013 07:57:17 -0800 (PST)
Subject: [R] How do I separate elements of a vector by comma?
In-Reply-To: <1387726821.18931.YahooMailNeo@web141104.mail.bf1.yahoo.com>
References: <1387726821.18931.YahooMailNeo@web141104.mail.bf1.yahoo.com>
Message-ID: <1387727837.45951.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
vec1#vector

paste(vec1,collapse=",")
A.K.




On Sunday, December 22, 2013 10:42 AM, Patty Haaem <elham_h763 at yahoo.com> wrote:
I have a vector like this (this vector is a colomn of a data set):
> 3 5 2 3 7 4 7 8? 8 9 0 1 4 
I want to separate elements of?the vector by comma like this:
> 3,5,2,3,7,4,7,8,8,9,0,1,4
How can do this?
Thanks.
Elham
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jrkrideau at inbox.com  Sun Dec 22 17:02:48 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 22 Dec 2013 08:02:48 -0800
Subject: [R] How do I separate elements of a vector by comma?
In-Reply-To: <1387726821.18931.YahooMailNeo@web141104.mail.bf1.yahoo.com>
Message-ID: <D0356DB56CA.000002F9jrkrideau@inbox.com>

paste(xx,",", sep = "") but this coerces the vector to a character vector.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: elham_h763 at yahoo.com
> Sent: Sun, 22 Dec 2013 07:40:21 -0800 (PST)
> To: r-help at r-project.org
> Subject: [R] How do I separate elements of a vector by comma?
> 
> I have a vector like this (this vector is a colomn of a data set):
>> 3 5 2 3 7 4 7 8  8 9 0 1 4
> I want to separate elements of the vector by comma like this:
>> 3,5,2,3,7,4,7,8,8,9,0,1,4
> How can do this?
> Thanks.
> Elham
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From msuzen at gmail.com  Sun Dec 22 17:54:50 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Sun, 22 Dec 2013 17:54:50 +0100
Subject: [R] Season's Greetings (and great news ... )!
In-Reply-To: <XFMail.20131222095916.Ted.Harding@wlandres.net>
References: <XFMail.20131222095916.Ted.Harding@wlandres.net>
Message-ID: <CAPtbhHy+j70JRo8qjj74AKRi2Y5AyV5OxFnFxseE3j=S0D2AWQ@mail.gmail.com>

I wouldn't blame R for floating-point arithmetic and our personal
feeling of what 'zero' should be.

> options(digits=20)
> pi
[1] 3.141592653589793116
> sqrt(pi)^2
[1] 3.1415926535897926719
> (pi - sqrt(pi)^2) < 1e-15
[1] TRUE

There was a similar post before, for example see:
http://r.789695.n4.nabble.com/Why-does-sin-pi-not-return-0-td4676963.html

There is an example by Martin Maechler (author of Rmpfr) on how to use
arbitrary precision
with your arithmetic.

On 22 December 2013 10:59, Ted Harding <Ted.Harding at wlandres.net> wrote:
> Greetings All!
> With the Festive Season fast approaching, I bring you joy
> with the news (which you will surely wish to celebrate)
> that R cannot do arithmetic!
>
> Usually, this is manifest in a trivial way when users report
> puzzlement that, for instance,
>
>   sqrt(pi)^2 == pi
>   # [1] FALSE
>
> which is the result of a (generally trivial) rounding or
> truncation error:
>
>   sqrt(pi)^2 - pi
>   [1] -4.440892e-16
>
> But for some very simple calculations R goes off its head.
>
> I had originally posted this example some years ago, but I
> have since generalised it, and the generalisation is even
> more entertaining than the original.
>
> The Original:
> Consider a sequence generated by the recurrence relation
>
>   x[n+1] = 2*x[n] if 0 <= x[n] <= 1/2
>   x[n+1] = 2*(1 - x[n]) if 1/2 < x[n] <= 1
>
> (for 0 <= x[n] <= 1).
>
> This has equilibrium points (x[n+1] = x[n]) at x[n] = 0
> and at x[n] = 2/3:
>
>   2/3 -> 2*(1 - 2/3) = 2/3
>
> It also has periodic points, e.g.
>
>   2/5 -> 4/5 -> 2/5 (period 2)
>   2/9 -> 4/9 -> 8/9 -> 2/9 (period 3)
>
> The recurrence relation can be implemented as the R function
>
>   nextx <- function(x){
>     if( (0<=x)&(x<=1/2) ) {x <- 2*x} else {x <- 2*(1 - x)}
>   }
>
> Now have a look at what happens when we start at the equilibrium
> point x = 2/3:
>
>   N <- 1 ; x <- 2/3
>   while(x > 0){
>     cat(sprintf("%i: %.9f\n",N,x))
>     x <- nextx(x) ; N <- N+1
>   }
>   cat(sprintf("%i: %.9f\n",N,x))
>
> Run that, and you will see that successive values of x collapse
> towards zero. Things look fine to start with:
>
>   1: 0.666666667
>   2: 0.666666667
>   3: 0.666666667
>   4: 0.666666667
>   5: 0.666666667
>   ...
>
> but, later on,
>
>   24: 0.666666667
>   25: 0.666666666
>   26: 0.666666668
>   27: 0.666666664
>   28: 0.666666672
>   ...
>
>   46: 0.667968750
>   47: 0.664062500
>   48: 0.671875000
>   49: 0.656250000
>   50: 0.687500000
>   51: 0.625000000
>   52: 0.750000000
>   53: 0.500000000
>   54: 1.000000000
>   55: 0.000000000
>
> What is happening is that, each time R multiplies by 2, the binary
> representation is shifted up by one and a zero bit is introduced
> at the bottom end. To illustrate this, do the calculation in
> 7-bit arithmetic where 2/3 = 0.1010101, so:
>
> 0.1010101  x[1], >1/2 so subtract from 1 = 1.0000000 -> 0.0101011,
> and then multiply by 2 to get x[2] = 0.1010110. Hence
>
> 0.1010101  x[1] -> 2*(1 - 0.1010101) = 2*0.0101011 ->
> 0.1010110  x[2] -> 2*(1 - 0.1010110) = 2*0.0101010 ->
> 0.1010100  x[3] -> 2*(1 - 0.1010100) = 2*0.0101100 ->
> 0.1011000  x[4] -> 2*(1 - 0.1011000) = 2*0.0101000 ->
> 0.1010000  x[5] -> 2*(1 - 0.1010000) = 2*0.0110000 ->
> 0.1100000  x[6] -> 2*(1 - 0.1100000) = 2*0.0100000 ->
> 0.1000000  x[7] -> 2*0.1000000 = 1.0000000 ->
> 1.0000000  x[8] -> 2*(1 - 1.0000000) = 2*0 ->
> 0.0000000  x[9] and the end of the line.
>
> The final index of x[i] is i=9, 2 more than the number of binary
> places (7) in this arithmetic, since 8 successive zeros have to
> be introduced. It is the same with the real R calculation since
> this is working to .Machine$double.digits = 53 binary places;
> it just takes longer (we reach 0 at x[55])! The above collapse
> to 0 occurs for any starting value in this simple example (except
> for multiples of 1/(2^k), when it works properly).
>
> Generalisation:
> This is basically the same, except that everything is multiplied
> by a scale factor S, so instead of being on the interval [0,1].
> it is on [0,S], and
>
>   x[n+1] = 2*x[n] if 0 <= x[n] <= S/2
>   x[n+1] = 2*(S - x[n]) if S/2 < x[n] <= S
> (for 0 <= x[n] <= S).
>
> Again, x[n] = 2*S/3 is an equilibrium point. 2*S/3 > S/2, so
>
>   x[n] -> 2*(S - 2*S/3) = 2*(S/3) = 2*S/3
>
> Functions to implement this:
>
>   nxtS <- function(x,S){
>     if((x >= 0)&(x <= S/2)){ x<- 2*x } else {x <- 2*(S-x)}
>   }
>
>   S <- 6 ##  Or some other value of S
>   Nits <- 100
>   x <- 2*S/3
>   N <- 1 ; print(c(N,x))
>   while(x>0){
>   if(N > Nits) break   ### to stop infinite looping
>   N <- (N+1) ; x <- nxtS(x,S)
>   print(c(N,x))
> }
>
> The behaviour of the sequence now depends on the value of S.
>
> If S is a multiple of 3, then with x[1] = 2*S/3 the equilibrium
> is immediately attained and x[n] = 2*S/3 forever after, since
> R is now calculating with integers. E.g. try the above with S<-6
> That is what arithmetic ought to be like! But for S not a multiple
> of 3 one can get the impression that R is on some sort of drug!
>
> For other values of S (but not all) we observe the same collapse
> to x=0 as before, and again it takes 54 steps (ending with x[55]).
> Try e.g. S <- 16
>
> For some values of S, however, the iteration ends up in a periodic loop.
>
> For example, with S<-7, at x[52] we get x[52]=4, x[53]=6, x[54]=2,
> and then 4 6 2 4 6 2 4 6 2 ... forever (or until Nits cuts in),
> so period = 3.
>
> For S<-11, x[52]=8 then 6 then 10 then 2 then 4 then 8 6 10 2 4 ...
> so period = 5.
>
> For S<-13, x[51]=4 then 8 10 6 12 2 4 8 10 6 12 2 4 8 ...
> so period = 6.
>
> For S<-19, x[51]=12 then 14 10 18 2 4 8 16 6 12 ...
> so period = 9.
>
> And so on ...
>
> So, one sniff of something like S<-19, and R is off its head!
>
> All it has to do is multiply by 2 -- and it gets it cumulatively wrong!
> R just doesn't add up ...
>
> Season's Greetings to all -- and may your calculations always
> be accurate -- to within machine precision ...
>
> Ted.
>
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 22-Dec-2013  Time: 09:59:00
> This message was sent by XFMail
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sun Dec 22 18:35:56 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 22 Dec 2013 09:35:56 -0800
Subject: [R] Season's Greetings (and great news ... )!
In-Reply-To: <CAPtbhHy+j70JRo8qjj74AKRi2Y5AyV5OxFnFxseE3j=S0D2AWQ@mail.gmail.com>
References: <XFMail.20131222095916.Ted.Harding@wlandres.net>
	<CAPtbhHy+j70JRo8qjj74AKRi2Y5AyV5OxFnFxseE3j=S0D2AWQ@mail.gmail.com>
Message-ID: <CACk-te2mS_++Y+2H1Oc7dS2nNqVTwqWAH9gs9vhD5aS5QFSQZw@mail.gmail.com>

Yes.

See also Feigenbaum's constant and chaos theory for the general context.

Cheers,
Bert

On Sun, Dec 22, 2013 at 8:54 AM, Suzen, Mehmet <msuzen at gmail.com> wrote:
> I wouldn't blame R for floating-point arithmetic and our personal
> feeling of what 'zero' should be.
>
>> options(digits=20)
>> pi
> [1] 3.141592653589793116
>> sqrt(pi)^2
> [1] 3.1415926535897926719
>> (pi - sqrt(pi)^2) < 1e-15
> [1] TRUE
>
> There was a similar post before, for example see:
> http://r.789695.n4.nabble.com/Why-does-sin-pi-not-return-0-td4676963.html
>
> There is an example by Martin Maechler (author of Rmpfr) on how to use
> arbitrary precision
> with your arithmetic.
>
> On 22 December 2013 10:59, Ted Harding <Ted.Harding at wlandres.net> wrote:
>> Greetings All!
>> With the Festive Season fast approaching, I bring you joy
>> with the news (which you will surely wish to celebrate)
>> that R cannot do arithmetic!
>>
>> Usually, this is manifest in a trivial way when users report
>> puzzlement that, for instance,
>>
>>   sqrt(pi)^2 == pi
>>   # [1] FALSE
>>
>> which is the result of a (generally trivial) rounding or
>> truncation error:
>>
>>   sqrt(pi)^2 - pi
>>   [1] -4.440892e-16
>>
>> But for some very simple calculations R goes off its head.
>>
>> I had originally posted this example some years ago, but I
>> have since generalised it, and the generalisation is even
>> more entertaining than the original.
>>
>> The Original:
>> Consider a sequence generated by the recurrence relation
>>
>>   x[n+1] = 2*x[n] if 0 <= x[n] <= 1/2
>>   x[n+1] = 2*(1 - x[n]) if 1/2 < x[n] <= 1
>>
>> (for 0 <= x[n] <= 1).
>>
>> This has equilibrium points (x[n+1] = x[n]) at x[n] = 0
>> and at x[n] = 2/3:
>>
>>   2/3 -> 2*(1 - 2/3) = 2/3
>>
>> It also has periodic points, e.g.
>>
>>   2/5 -> 4/5 -> 2/5 (period 2)
>>   2/9 -> 4/9 -> 8/9 -> 2/9 (period 3)
>>
>> The recurrence relation can be implemented as the R function
>>
>>   nextx <- function(x){
>>     if( (0<=x)&(x<=1/2) ) {x <- 2*x} else {x <- 2*(1 - x)}
>>   }
>>
>> Now have a look at what happens when we start at the equilibrium
>> point x = 2/3:
>>
>>   N <- 1 ; x <- 2/3
>>   while(x > 0){
>>     cat(sprintf("%i: %.9f\n",N,x))
>>     x <- nextx(x) ; N <- N+1
>>   }
>>   cat(sprintf("%i: %.9f\n",N,x))
>>
>> Run that, and you will see that successive values of x collapse
>> towards zero. Things look fine to start with:
>>
>>   1: 0.666666667
>>   2: 0.666666667
>>   3: 0.666666667
>>   4: 0.666666667
>>   5: 0.666666667
>>   ...
>>
>> but, later on,
>>
>>   24: 0.666666667
>>   25: 0.666666666
>>   26: 0.666666668
>>   27: 0.666666664
>>   28: 0.666666672
>>   ...
>>
>>   46: 0.667968750
>>   47: 0.664062500
>>   48: 0.671875000
>>   49: 0.656250000
>>   50: 0.687500000
>>   51: 0.625000000
>>   52: 0.750000000
>>   53: 0.500000000
>>   54: 1.000000000
>>   55: 0.000000000
>>
>> What is happening is that, each time R multiplies by 2, the binary
>> representation is shifted up by one and a zero bit is introduced
>> at the bottom end. To illustrate this, do the calculation in
>> 7-bit arithmetic where 2/3 = 0.1010101, so:
>>
>> 0.1010101  x[1], >1/2 so subtract from 1 = 1.0000000 -> 0.0101011,
>> and then multiply by 2 to get x[2] = 0.1010110. Hence
>>
>> 0.1010101  x[1] -> 2*(1 - 0.1010101) = 2*0.0101011 ->
>> 0.1010110  x[2] -> 2*(1 - 0.1010110) = 2*0.0101010 ->
>> 0.1010100  x[3] -> 2*(1 - 0.1010100) = 2*0.0101100 ->
>> 0.1011000  x[4] -> 2*(1 - 0.1011000) = 2*0.0101000 ->
>> 0.1010000  x[5] -> 2*(1 - 0.1010000) = 2*0.0110000 ->
>> 0.1100000  x[6] -> 2*(1 - 0.1100000) = 2*0.0100000 ->
>> 0.1000000  x[7] -> 2*0.1000000 = 1.0000000 ->
>> 1.0000000  x[8] -> 2*(1 - 1.0000000) = 2*0 ->
>> 0.0000000  x[9] and the end of the line.
>>
>> The final index of x[i] is i=9, 2 more than the number of binary
>> places (7) in this arithmetic, since 8 successive zeros have to
>> be introduced. It is the same with the real R calculation since
>> this is working to .Machine$double.digits = 53 binary places;
>> it just takes longer (we reach 0 at x[55])! The above collapse
>> to 0 occurs for any starting value in this simple example (except
>> for multiples of 1/(2^k), when it works properly).
>>
>> Generalisation:
>> This is basically the same, except that everything is multiplied
>> by a scale factor S, so instead of being on the interval [0,1].
>> it is on [0,S], and
>>
>>   x[n+1] = 2*x[n] if 0 <= x[n] <= S/2
>>   x[n+1] = 2*(S - x[n]) if S/2 < x[n] <= S
>> (for 0 <= x[n] <= S).
>>
>> Again, x[n] = 2*S/3 is an equilibrium point. 2*S/3 > S/2, so
>>
>>   x[n] -> 2*(S - 2*S/3) = 2*(S/3) = 2*S/3
>>
>> Functions to implement this:
>>
>>   nxtS <- function(x,S){
>>     if((x >= 0)&(x <= S/2)){ x<- 2*x } else {x <- 2*(S-x)}
>>   }
>>
>>   S <- 6 ##  Or some other value of S
>>   Nits <- 100
>>   x <- 2*S/3
>>   N <- 1 ; print(c(N,x))
>>   while(x>0){
>>   if(N > Nits) break   ### to stop infinite looping
>>   N <- (N+1) ; x <- nxtS(x,S)
>>   print(c(N,x))
>> }
>>
>> The behaviour of the sequence now depends on the value of S.
>>
>> If S is a multiple of 3, then with x[1] = 2*S/3 the equilibrium
>> is immediately attained and x[n] = 2*S/3 forever after, since
>> R is now calculating with integers. E.g. try the above with S<-6
>> That is what arithmetic ought to be like! But for S not a multiple
>> of 3 one can get the impression that R is on some sort of drug!
>>
>> For other values of S (but not all) we observe the same collapse
>> to x=0 as before, and again it takes 54 steps (ending with x[55]).
>> Try e.g. S <- 16
>>
>> For some values of S, however, the iteration ends up in a periodic loop.
>>
>> For example, with S<-7, at x[52] we get x[52]=4, x[53]=6, x[54]=2,
>> and then 4 6 2 4 6 2 4 6 2 ... forever (or until Nits cuts in),
>> so period = 3.
>>
>> For S<-11, x[52]=8 then 6 then 10 then 2 then 4 then 8 6 10 2 4 ...
>> so period = 5.
>>
>> For S<-13, x[51]=4 then 8 10 6 12 2 4 8 10 6 12 2 4 8 ...
>> so period = 6.
>>
>> For S<-19, x[51]=12 then 14 10 18 2 4 8 16 6 12 ...
>> so period = 9.
>>
>> And so on ...
>>
>> So, one sniff of something like S<-19, and R is off its head!
>>
>> All it has to do is multiply by 2 -- and it gets it cumulatively wrong!
>> R just doesn't add up ...
>>
>> Season's Greetings to all -- and may your calculations always
>> be accurate -- to within machine precision ...
>>
>> Ted.
>>
>> -------------------------------------------------
>> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
>> Date: 22-Dec-2013  Time: 09:59:00
>> This message was sent by XFMail
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From wdunlap at tibco.com  Sun Dec 22 18:57:52 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 22 Dec 2013 17:57:52 +0000
Subject: [R] seq_len and loops
In-Reply-To: <52B62990.6070404@gmail.com>
References: <52B61CE0.10805@umu.se> <52B62935.50909@gmail.com>
	<52B62990.6070404@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1EE96@PA-MBX01.na.tibco.com>

> > for (i in seq_len(x - 1) + 1)
> >
> > should be efficient and safe.
> 
> Oops, not safe when x is 0.

Also, the '+ 1' should be '+ 1L' to get the same answer as
seq_len(x)[-1].

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Duncan Murdoch
> Sent: Saturday, December 21, 2013 3:52 PM
> To: G?ran Brostr?m; R-help at r-project.org
> Subject: Re: [R] seq_len and loops
> 
> On 13-12-21 6:50 PM, Duncan Murdoch wrote:
> > On 13-12-21 5:57 PM, G?ran Brostr?m wrote:
> >> I was recently reminded on this list that
> >>
> >> "Using 1:ncol() is bad practice (seq_len is designed for that purpose)"
> >> (Ripley)
> >>
> >> This triggers the following question: What is "good practice" for
> >> 2:ncol(x)? (This is not a joke; in a recursive situation it often makes
> >> sense to perform the calculation for the start value i = 1, then
> >> continue with a loop over the rest, "the Fortran way";)
> >>
> >> I usually use
> >>
> >> if (ncol(x) > 1)
> >>        for (i in 2:ncol(x)){
> >>           ....
> >>
> >> but I can think of
> >>
> >> for (i in seq_len(x - 1)){
> >>        I <- i + 1
> >>       ....
> >>
> >> and
> >>
> >> i <- 1
> >> while (i < ncol(x)){
> >>        i <- i + 1
> >>        ....
> >>
> >> What is "good practice" (efficient and safe)?
> >
> > for (i in seq_len(x - 1) + 1)
> >
> > should be efficient and safe.
> 
> Oops, not safe when x is 0.
> 
>  >
> A little less efficient, but clearer would be
> >
> > for (i in seq_len(x)[-1])
> >
> > Duncan Murdoch
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sun Dec 22 19:19:18 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 22 Dec 2013 10:19:18 -0800
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <CANKVVa3SqzK8nXA0kEmg=Npe2PuJ+MqnFQsU-7M1KvaSN7t2aw@mail.gmail.com>
Message-ID: <D16683C5446.00000494jrkrideau@inbox.com>

Hi Daniel, 

For some reason I cannot get your example to work. The problem is in the code chunk but I have no idea what is happening. The code is running perfectly in R, itself but LaTeX seems to be choking when it hits the first ggplot statement, that is the one in <<plot-figHeight>>=

The message I am getting is: "Missing $ inserted <inserted text> $ ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not enough to figure out the problem. 

I tried stripping out most of the LaTeX specific verbiage in the code chunk and running the code in LyX which I use rather than plain vanilla LaTeX and I still cannot get it to work. It is almost as if there is some hidden character in the in that piece of code since I can duplicate the code myself and I even pasted in most of the geom_histogram code into my code chunk and it runs. 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: daniel.haugstvedt at gmail.com
> Sent: Sun, 22 Dec 2013 12:42:50 +0100
> To: r-help at r-project.org
> Subject: [R] Knitr, ggplot and consistent fonts
> 
> Dear R-help
> 
> I am using Knitr and ggplot to draft an article and have now started to
> improve on the layout and graphics. So far I have not been able to
> maintain
> the same font size for labels in all my figures.
> 
> My goal is to be able to change the width of the figures while
> maintaining
> the same font. This works for the height parameter (example not
> included).
> 
> In the true document I also use tikz, but the problem can be reproduced
> without it.
> 
> I know the question is very specific, but my understanding is that this
> combination of packages  is common. (They are really great. Keep up the
> good work.)  There has to be others facing the same problem and someone
> must have found a nice solution.
> 
> Additional attempts from my side which failed are not included in the
> example. I have tested the Google results i could find without any luck.
> 
> Cheers
> Daniel
> 
> PS. I know the example plots could have been smaller, but they just
> became
> too ugly for me
> 
> 
> \documentclass{article}
> \begin{document}
> 
> <<setup, include=FALSE, cache=FALSE>>=
> library(knitr)
> library(ggplot2)
> @
> 
> \title{Knitr and ggplot2}
> \author{Daniel Haugstvedt}
> 
> \maketitle
> 
> There are four plots in this article. Figure \ref{fig:plot-figHeight}
> uses
> the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
> used both fig.height=2.5 and fig.width=3. The later option makes the font
> too big.
> 
> An alternative approach is used in Figures  \ref{fig:plot-figOutWidthBig}
> and
>  \ref{fig:plot-figOutWidthSmall}. There the argument out.width is set to
>  12 and 8 cm respectively. This stops the problem of excessively large
> fonts
>  for figures with smaller width, but there is still no consistency
>  across plots in terms of font size.
> 
> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot with
> no
> fig.width argument", fig.pos='ht'>>=
> df = data.frame(x = rnorm(100), y = 1:100)
> ggplot(df, aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
> 
> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>=
> ggplot(df, aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
> 
> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
> ggplot(df, aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
> 
> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width = "8cm",
> fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
> ggplot(df, aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
> 
> \end{document}
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From Ted.Harding at wlandres.net  Sun Dec 22 19:37:18 2013
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Sun, 22 Dec 2013 18:37:18 -0000 (GMT)
Subject: [R] Season's Greetings (and great news ... )!
In-Reply-To: <CACk-te2mS_++Y+2H1Oc7dS2nNqVTwqWAH9gs9vhD5aS5QFSQZw@mail.gmail.com>
Message-ID: <XFMail.20131222183718.Ted.Harding@wlandres.net>

Thanks for the comments, Bert and Mehmet! It is of course a serious
and interesting area to explore (and I'm aware of the chaos context;
I initially got into this areas year ago when I was exploring the
possibilities for chaos in fish population dynamics -- and they're
certainly there)!

But, before anyone takes my posting *too* seriously, let me say that
it was written tongue-in-cheek (or whatever the keyboard analogue of
that may be). I'm certainly not "blaming R".

Have fun anyway!
Ted.

On 22-Dec-2013 17:35:56 Bert Gunter wrote:
> Yes.
> 
> See also Feigenbaum's constant and chaos theory for the general context.
> 
> Cheers,
> Bert
> 
> On Sun, Dec 22, 2013 at 8:54 AM, Suzen, Mehmet <msuzen at gmail.com> wrote:
>> I wouldn't blame R for floating-point arithmetic and our personal
>> feeling of what 'zero' should be.
>>
>>> options(digits=20)
>>> pi
>> [1] 3.141592653589793116
>>> sqrt(pi)^2
>> [1] 3.1415926535897926719
>>> (pi - sqrt(pi)^2) < 1e-15
>> [1] TRUE
>>
>> There was a similar post before, for example see:
>> http://r.789695.n4.nabble.com/Why-does-sin-pi-not-return-0-td4676963.html
>>
>> There is an example by Martin Maechler (author of Rmpfr) on how to use
>> arbitrary precision
>> with your arithmetic.
>>
>> On 22 December 2013 10:59, Ted Harding <Ted.Harding at wlandres.net> wrote:
>>> Greetings All!
>>> With the Festive Season fast approaching, I bring you joy
>>> with the news (which you will surely wish to celebrate)
>>> that R cannot do arithmetic!
>>>
>>> Usually, this is manifest in a trivial way when users report
>>> puzzlement that, for instance,
>>>
>>>   sqrt(pi)^2 == pi
>>>   # [1] FALSE
>>>
>>> which is the result of a (generally trivial) rounding or
>>> truncation error:
>>>
>>>   sqrt(pi)^2 - pi
>>>   [1] -4.440892e-16
>>>
>>> But for some very simple calculations R goes off its head.
>>>
>>> I had originally posted this example some years ago, but I
>>> have since generalised it, and the generalisation is even
>>> more entertaining than the original.
>>>
>>> The Original:
>>> Consider a sequence generated by the recurrence relation
>>>
>>>   x[n+1] = 2*x[n] if 0 <= x[n] <= 1/2
>>>   x[n+1] = 2*(1 - x[n]) if 1/2 < x[n] <= 1
>>>
>>> (for 0 <= x[n] <= 1).
>>>
>>> This has equilibrium points (x[n+1] = x[n]) at x[n] = 0
>>> and at x[n] = 2/3:
>>>
>>>   2/3 -> 2*(1 - 2/3) = 2/3
>>>
>>> It also has periodic points, e.g.
>>>
>>>   2/5 -> 4/5 -> 2/5 (period 2)
>>>   2/9 -> 4/9 -> 8/9 -> 2/9 (period 3)
>>>
>>> The recurrence relation can be implemented as the R function
>>>
>>>   nextx <- function(x){
>>>     if( (0<=x)&(x<=1/2) ) {x <- 2*x} else {x <- 2*(1 - x)}
>>>   }
>>>
>>> Now have a look at what happens when we start at the equilibrium
>>> point x = 2/3:
>>>
>>>   N <- 1 ; x <- 2/3
>>>   while(x > 0){
>>>     cat(sprintf("%i: %.9f\n",N,x))
>>>     x <- nextx(x) ; N <- N+1
>>>   }
>>>   cat(sprintf("%i: %.9f\n",N,x))
>>>
>>> Run that, and you will see that successive values of x collapse
>>> towards zero. Things look fine to start with:
>>>
>>>   1: 0.666666667
>>>   2: 0.666666667
>>>   3: 0.666666667
>>>   4: 0.666666667
>>>   5: 0.666666667
>>>   ...
>>>
>>> but, later on,
>>>
>>>   24: 0.666666667
>>>   25: 0.666666666
>>>   26: 0.666666668
>>>   27: 0.666666664
>>>   28: 0.666666672
>>>   ...
>>>
>>>   46: 0.667968750
>>>   47: 0.664062500
>>>   48: 0.671875000
>>>   49: 0.656250000
>>>   50: 0.687500000
>>>   51: 0.625000000
>>>   52: 0.750000000
>>>   53: 0.500000000
>>>   54: 1.000000000
>>>   55: 0.000000000
>>>
>>> What is happening is that, each time R multiplies by 2, the binary
>>> representation is shifted up by one and a zero bit is introduced
>>> at the bottom end. To illustrate this, do the calculation in
>>> 7-bit arithmetic where 2/3 = 0.1010101, so:
>>>
>>> 0.1010101  x[1], >1/2 so subtract from 1 = 1.0000000 -> 0.0101011,
>>> and then multiply by 2 to get x[2] = 0.1010110. Hence
>>>
>>> 0.1010101  x[1] -> 2*(1 - 0.1010101) = 2*0.0101011 ->
>>> 0.1010110  x[2] -> 2*(1 - 0.1010110) = 2*0.0101010 ->
>>> 0.1010100  x[3] -> 2*(1 - 0.1010100) = 2*0.0101100 ->
>>> 0.1011000  x[4] -> 2*(1 - 0.1011000) = 2*0.0101000 ->
>>> 0.1010000  x[5] -> 2*(1 - 0.1010000) = 2*0.0110000 ->
>>> 0.1100000  x[6] -> 2*(1 - 0.1100000) = 2*0.0100000 ->
>>> 0.1000000  x[7] -> 2*0.1000000 = 1.0000000 ->
>>> 1.0000000  x[8] -> 2*(1 - 1.0000000) = 2*0 ->
>>> 0.0000000  x[9] and the end of the line.
>>>
>>> The final index of x[i] is i=9, 2 more than the number of binary
>>> places (7) in this arithmetic, since 8 successive zeros have to
>>> be introduced. It is the same with the real R calculation since
>>> this is working to .Machine$double.digits = 53 binary places;
>>> it just takes longer (we reach 0 at x[55])! The above collapse
>>> to 0 occurs for any starting value in this simple example (except
>>> for multiples of 1/(2^k), when it works properly).
>>>
>>> Generalisation:
>>> This is basically the same, except that everything is multiplied
>>> by a scale factor S, so instead of being on the interval [0,1].
>>> it is on [0,S], and
>>>
>>>   x[n+1] = 2*x[n] if 0 <= x[n] <= S/2
>>>   x[n+1] = 2*(S - x[n]) if S/2 < x[n] <= S
>>> (for 0 <= x[n] <= S).
>>>
>>> Again, x[n] = 2*S/3 is an equilibrium point. 2*S/3 > S/2, so
>>>
>>>   x[n] -> 2*(S - 2*S/3) = 2*(S/3) = 2*S/3
>>>
>>> Functions to implement this:
>>>
>>>   nxtS <- function(x,S){
>>>     if((x >= 0)&(x <= S/2)){ x<- 2*x } else {x <- 2*(S-x)}
>>>   }
>>>
>>>   S <- 6 ##  Or some other value of S
>>>   Nits <- 100
>>>   x <- 2*S/3
>>>   N <- 1 ; print(c(N,x))
>>>   while(x>0){
>>>   if(N > Nits) break   ### to stop infinite looping
>>>   N <- (N+1) ; x <- nxtS(x,S)
>>>   print(c(N,x))
>>> }
>>>
>>> The behaviour of the sequence now depends on the value of S.
>>>
>>> If S is a multiple of 3, then with x[1] = 2*S/3 the equilibrium
>>> is immediately attained and x[n] = 2*S/3 forever after, since
>>> R is now calculating with integers. E.g. try the above with S<-6
>>> That is what arithmetic ought to be like! But for S not a multiple
>>> of 3 one can get the impression that R is on some sort of drug!
>>>
>>> For other values of S (but not all) we observe the same collapse
>>> to x=0 as before, and again it takes 54 steps (ending with x[55]).
>>> Try e.g. S <- 16
>>>
>>> For some values of S, however, the iteration ends up in a periodic loop.
>>>
>>> For example, with S<-7, at x[52] we get x[52]=4, x[53]=6, x[54]=2,
>>> and then 4 6 2 4 6 2 4 6 2 ... forever (or until Nits cuts in),
>>> so period = 3.
>>>
>>> For S<-11, x[52]=8 then 6 then 10 then 2 then 4 then 8 6 10 2 4 ...
>>> so period = 5.
>>>
>>> For S<-13, x[51]=4 then 8 10 6 12 2 4 8 10 6 12 2 4 8 ...
>>> so period = 6.
>>>
>>> For S<-19, x[51]=12 then 14 10 18 2 4 8 16 6 12 ...
>>> so period = 9.
>>>
>>> And so on ...
>>>
>>> So, one sniff of something like S<-19, and R is off its head!
>>>
>>> All it has to do is multiply by 2 -- and it gets it cumulatively wrong!
>>> R just doesn't add up ...
>>>
>>> Season's Greetings to all -- and may your calculations always
>>> be accurate -- to within machine precision ...
>>>
>>> Ted.
>>>
>>> -------------------------------------------------
>>> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
>>> Date: 22-Dec-2013  Time: 09:59:00
>>> This message was sent by XFMail
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> (650) 467-7374
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 22-Dec-2013  Time: 18:37:15
This message was sent by XFMail


From jrkrideau at inbox.com  Sun Dec 22 19:41:11 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 22 Dec 2013 10:41:11 -0800
Subject: [R] Season's Greetings (and great news ... )!
In-Reply-To: <XFMail.20131222183718.Ted.Harding@wlandres.net>
References: <cack-te2ms_++y+2h1oc7ds2nnqvtwqwah9gs9vhd5as5qfsqzw@mail.gmail.com>
Message-ID: <D1976F4F9FC.000004C6jrkrideau@inbox.com>

"(or whatever the keyboard analogue of that may be) "

Hands clasped?  Fingers interlaced?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: ted.harding at wlandres.net
> Sent: Sun, 22 Dec 2013 18:37:18 -0000 (GMT)
> To: r-help at r-project.org
> Subject: Re: [R] Season's Greetings (and great news ... )!
> 
> Thanks for the comments, Bert and Mehmet! It is of course a serious
> and interesting area to explore (and I'm aware of the chaos context;
> I initially got into this areas year ago when I was exploring the
> possibilities for chaos in fish population dynamics -- and they're
> certainly there)!
> 
> But, before anyone takes my posting *too* seriously, let me say that
> it was written tongue-in-cheek (or whatever the keyboard analogue of
> that may be). I'm certainly not "blaming R".
> 
> Have fun anyway!
> Ted.
> 
> On 22-Dec-2013 17:35:56 Bert Gunter wrote:
>> Yes.
>> 
>> See also Feigenbaum's constant and chaos theory for the general context.
>> 
>> Cheers,
>> Bert
>> 
>> On Sun, Dec 22, 2013 at 8:54 AM, Suzen, Mehmet <msuzen at gmail.com> wrote:
>>> I wouldn't blame R for floating-point arithmetic and our personal
>>> feeling of what 'zero' should be.
>>> 
>>>> options(digits=20)
>>>> pi
>>> [1] 3.141592653589793116
>>>> sqrt(pi)^2
>>> [1] 3.1415926535897926719
>>>> (pi - sqrt(pi)^2) < 1e-15
>>> [1] TRUE
>>> 
>>> There was a similar post before, for example see:
>>> http://r.789695.n4.nabble.com/Why-does-sin-pi-not-return-0-td4676963.html
>>> 
>>> There is an example by Martin Maechler (author of Rmpfr) on how to use
>>> arbitrary precision
>>> with your arithmetic.
>>> 
>>> On 22 December 2013 10:59, Ted Harding <Ted.Harding at wlandres.net>
>>> wrote:
>>>> Greetings All!
>>>> With the Festive Season fast approaching, I bring you joy
>>>> with the news (which you will surely wish to celebrate)
>>>> that R cannot do arithmetic!
>>>> 
>>>> Usually, this is manifest in a trivial way when users report
>>>> puzzlement that, for instance,
>>>> 
>>>>   sqrt(pi)^2 == pi
>>>>   # [1] FALSE
>>>> 
>>>> which is the result of a (generally trivial) rounding or
>>>> truncation error:
>>>> 
>>>>   sqrt(pi)^2 - pi
>>>>   [1] -4.440892e-16
>>>> 
>>>> But for some very simple calculations R goes off its head.
>>>> 
>>>> I had originally posted this example some years ago, but I
>>>> have since generalised it, and the generalisation is even
>>>> more entertaining than the original.
>>>> 
>>>> The Original:
>>>> Consider a sequence generated by the recurrence relation
>>>> 
>>>>   x[n+1] = 2*x[n] if 0 <= x[n] <= 1/2
>>>>   x[n+1] = 2*(1 - x[n]) if 1/2 < x[n] <= 1
>>>> 
>>>> (for 0 <= x[n] <= 1).
>>>> 
>>>> This has equilibrium points (x[n+1] = x[n]) at x[n] = 0
>>>> and at x[n] = 2/3:
>>>> 
>>>>   2/3 -> 2*(1 - 2/3) = 2/3
>>>> 
>>>> It also has periodic points, e.g.
>>>> 
>>>>   2/5 -> 4/5 -> 2/5 (period 2)
>>>>   2/9 -> 4/9 -> 8/9 -> 2/9 (period 3)
>>>> 
>>>> The recurrence relation can be implemented as the R function
>>>> 
>>>>   nextx <- function(x){
>>>>     if( (0<=x)&(x<=1/2) ) {x <- 2*x} else {x <- 2*(1 - x)}
>>>>   }
>>>> 
>>>> Now have a look at what happens when we start at the equilibrium
>>>> point x = 2/3:
>>>> 
>>>>   N <- 1 ; x <- 2/3
>>>>   while(x > 0){
>>>>     cat(sprintf("%i: %.9f\n",N,x))
>>>>     x <- nextx(x) ; N <- N+1
>>>>   }
>>>>   cat(sprintf("%i: %.9f\n",N,x))
>>>> 
>>>> Run that, and you will see that successive values of x collapse
>>>> towards zero. Things look fine to start with:
>>>> 
>>>>   1: 0.666666667
>>>>   2: 0.666666667
>>>>   3: 0.666666667
>>>>   4: 0.666666667
>>>>   5: 0.666666667
>>>>   ...
>>>> 
>>>> but, later on,
>>>> 
>>>>   24: 0.666666667
>>>>   25: 0.666666666
>>>>   26: 0.666666668
>>>>   27: 0.666666664
>>>>   28: 0.666666672
>>>>   ...
>>>> 
>>>>   46: 0.667968750
>>>>   47: 0.664062500
>>>>   48: 0.671875000
>>>>   49: 0.656250000
>>>>   50: 0.687500000
>>>>   51: 0.625000000
>>>>   52: 0.750000000
>>>>   53: 0.500000000
>>>>   54: 1.000000000
>>>>   55: 0.000000000
>>>> 
>>>> What is happening is that, each time R multiplies by 2, the binary
>>>> representation is shifted up by one and a zero bit is introduced
>>>> at the bottom end. To illustrate this, do the calculation in
>>>> 7-bit arithmetic where 2/3 = 0.1010101, so:
>>>> 
>>>> 0.1010101  x[1], >1/2 so subtract from 1 = 1.0000000 -> 0.0101011,
>>>> and then multiply by 2 to get x[2] = 0.1010110. Hence
>>>> 
>>>> 0.1010101  x[1] -> 2*(1 - 0.1010101) = 2*0.0101011 ->
>>>> 0.1010110  x[2] -> 2*(1 - 0.1010110) = 2*0.0101010 ->
>>>> 0.1010100  x[3] -> 2*(1 - 0.1010100) = 2*0.0101100 ->
>>>> 0.1011000  x[4] -> 2*(1 - 0.1011000) = 2*0.0101000 ->
>>>> 0.1010000  x[5] -> 2*(1 - 0.1010000) = 2*0.0110000 ->
>>>> 0.1100000  x[6] -> 2*(1 - 0.1100000) = 2*0.0100000 ->
>>>> 0.1000000  x[7] -> 2*0.1000000 = 1.0000000 ->
>>>> 1.0000000  x[8] -> 2*(1 - 1.0000000) = 2*0 ->
>>>> 0.0000000  x[9] and the end of the line.
>>>> 
>>>> The final index of x[i] is i=9, 2 more than the number of binary
>>>> places (7) in this arithmetic, since 8 successive zeros have to
>>>> be introduced. It is the same with the real R calculation since
>>>> this is working to .Machine$double.digits = 53 binary places;
>>>> it just takes longer (we reach 0 at x[55])! The above collapse
>>>> to 0 occurs for any starting value in this simple example (except
>>>> for multiples of 1/(2^k), when it works properly).
>>>> 
>>>> Generalisation:
>>>> This is basically the same, except that everything is multiplied
>>>> by a scale factor S, so instead of being on the interval [0,1].
>>>> it is on [0,S], and
>>>> 
>>>>   x[n+1] = 2*x[n] if 0 <= x[n] <= S/2
>>>>   x[n+1] = 2*(S - x[n]) if S/2 < x[n] <= S
>>>> (for 0 <= x[n] <= S).
>>>> 
>>>> Again, x[n] = 2*S/3 is an equilibrium point. 2*S/3 > S/2, so
>>>> 
>>>>   x[n] -> 2*(S - 2*S/3) = 2*(S/3) = 2*S/3
>>>> 
>>>> Functions to implement this:
>>>> 
>>>>   nxtS <- function(x,S){
>>>>     if((x >= 0)&(x <= S/2)){ x<- 2*x } else {x <- 2*(S-x)}
>>>>   }
>>>> 
>>>>   S <- 6 ##  Or some other value of S
>>>>   Nits <- 100
>>>>   x <- 2*S/3
>>>>   N <- 1 ; print(c(N,x))
>>>>   while(x>0){
>>>>   if(N > Nits) break   ### to stop infinite looping
>>>>   N <- (N+1) ; x <- nxtS(x,S)
>>>>   print(c(N,x))
>>>> }
>>>> 
>>>> The behaviour of the sequence now depends on the value of S.
>>>> 
>>>> If S is a multiple of 3, then with x[1] = 2*S/3 the equilibrium
>>>> is immediately attained and x[n] = 2*S/3 forever after, since
>>>> R is now calculating with integers. E.g. try the above with S<-6
>>>> That is what arithmetic ought to be like! But for S not a multiple
>>>> of 3 one can get the impression that R is on some sort of drug!
>>>> 
>>>> For other values of S (but not all) we observe the same collapse
>>>> to x=0 as before, and again it takes 54 steps (ending with x[55]).
>>>> Try e.g. S <- 16
>>>> 
>>>> For some values of S, however, the iteration ends up in a periodic
>>>> loop.
>>>> 
>>>> For example, with S<-7, at x[52] we get x[52]=4, x[53]=6, x[54]=2,
>>>> and then 4 6 2 4 6 2 4 6 2 ... forever (or until Nits cuts in),
>>>> so period = 3.
>>>> 
>>>> For S<-11, x[52]=8 then 6 then 10 then 2 then 4 then 8 6 10 2 4 ...
>>>> so period = 5.
>>>> 
>>>> For S<-13, x[51]=4 then 8 10 6 12 2 4 8 10 6 12 2 4 8 ...
>>>> so period = 6.
>>>> 
>>>> For S<-19, x[51]=12 then 14 10 18 2 4 8 16 6 12 ...
>>>> so period = 9.
>>>> 
>>>> And so on ...
>>>> 
>>>> So, one sniff of something like S<-19, and R is off its head!
>>>> 
>>>> All it has to do is multiply by 2 -- and it gets it cumulatively
>>>> wrong!
>>>> R just doesn't add up ...
>>>> 
>>>> Season's Greetings to all -- and may your calculations always
>>>> be accurate -- to within machine precision ...
>>>> 
>>>> Ted.
>>>> 
>>>> -------------------------------------------------
>>>> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
>>>> Date: 22-Dec-2013  Time: 09:59:00
>>>> This message was sent by XFMail
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> --
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> 
>> (650) 467-7374
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 22-Dec-2013  Time: 18:37:15
> This message was sent by XFMail
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From daniel.haugstvedt at gmail.com  Sun Dec 22 23:56:59 2013
From: daniel.haugstvedt at gmail.com (Daniel Haugstvedt)
Date: Sun, 22 Dec 2013 23:56:59 +0100
Subject: [R] Fwd:  Knitr, ggplot and consistent fonts
In-Reply-To: <CANKVVa2Kgad=81VL_bQ0hGgU+rrr5aCe1P=rLWmLCC4QhJOabA@mail.gmail.com>
References: <CANKVVa3SqzK8nXA0kEmg=Npe2PuJ+MqnFQsU-7M1KvaSN7t2aw@mail.gmail.com>
	<D16683C5446.00000494jrkrideau@inbox.com>
	<CANKVVa2Kgad=81VL_bQ0hGgU+rrr5aCe1P=rLWmLCC4QhJOabA@mail.gmail.com>
Message-ID: <CANKVVa3urmnVRbrOT0JQ0ZbtXPSsLZkfcayW4JJa1AeUr7kf9g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131222/fef66d88/attachment.pl>

From dulcalma at bigpond.com  Sun Dec 22 23:59:05 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 23 Dec 2013 08:59:05 +1000
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <D16683C5446.00000494jrkrideau@inbox.com>
References: <CANKVVa3SqzK8nXA0kEmg=Npe2PuJ+MqnFQsU-7M1KvaSN7t2aw@mail.gmail.com>
	<D16683C5446.00000494jrkrideau@inbox.com>
Message-ID: <001201ceff69$6a46d900$3ed48b00$@bigpond.com>

Hi Daniel
I tried it in Sweave after modifying it for Sweave and a similar thing for Latex but R crashed.

I think there is an embedded character/s before the first chunk and in the first chunk.

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of John Kane
Sent: Monday, 23 December 2013 04:19
To: Daniel Haugstvedt; r-help at r-project.org
Subject: Re: [R] Knitr, ggplot and consistent fonts

Hi Daniel, 

For some reason I cannot get your example to work. The problem is in the code chunk but I have no idea what is happening. The code is running perfectly in R, itself but LaTeX seems to be choking when it hits the first ggplot statement, that is the one in <<plot-figHeight>>=

The message I am getting is: "Missing $ inserted <inserted text> $ ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not enough to figure out the problem. 

I tried stripping out most of the LaTeX specific verbiage in the code chunk and running the code in LyX which I use rather than plain vanilla LaTeX and I still cannot get it to work. It is almost as if there is some hidden character in the in that piece of code since I can duplicate the code myself and I even pasted in most of the geom_histogram code into my code chunk and it runs. 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: daniel.haugstvedt at gmail.com
> Sent: Sun, 22 Dec 2013 12:42:50 +0100
> To: r-help at r-project.org
> Subject: [R] Knitr, ggplot and consistent fonts
> 
> Dear R-help
> 
> I am using Knitr and ggplot to draft an article and have now started 
> to improve on the layout and graphics. So far I have not been able to 
> maintain the same font size for labels in all my figures.
> 
> My goal is to be able to change the width of the figures while 
> maintaining the same font. This works for the height parameter 
> (example not included).
> 
> In the true document I also use tikz, but the problem can be 
> reproduced without it.
> 
> I know the question is very specific, but my understanding is that 
> this combination of packages  is common. (They are really great. Keep 
> up the good work.)  There has to be others facing the same problem and 
> someone must have found a nice solution.
> 
> Additional attempts from my side which failed are not included in the 
> example. I have tested the Google results i could find without any luck.
> 
> Cheers
> Daniel
> 
> PS. I know the example plots could have been smaller, but they just 
> became too ugly for me
> 
> 
> \documentclass{article}
> \begin{document}
> 
> <<setup, include=FALSE, cache=FALSE>>=
> library(knitr)
> library(ggplot2)
> @
> 
> \title{Knitr and ggplot2}
> \author{Daniel Haugstvedt}
> 
> \maketitle
> 
> There are four plots in this article. Figure \ref{fig:plot-figHeight} 
> uses the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth} 
> used both fig.height=2.5 and fig.width=3. The later option makes the 
> font too big.
> 
> An alternative approach is used in Figures  
> \ref{fig:plot-figOutWidthBig} and  \ref{fig:plot-figOutWidthSmall}. 
> There the argument out.width is set to
>  12 and 8 cm respectively. This stops the problem of excessively large 
> fonts  for figures with smaller width, but there is still no 
> consistency  across plots in terms of font size.
> 
> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot 
> with no fig.width argument", fig.pos='ht'>>= df = data.frame(x = 
> rnorm(100), y = 1:100) ggplot(df, aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
> 
> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3, 
> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>= ggplot(df, 
> aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
> 
> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm", 
> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>= ggplot(df, 
> aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
> 
> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width = 
> "8cm", fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>= 
> ggplot(df, aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
> 
> \end{document}
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From onuruncu at gmail.com  Mon Dec 23 00:54:51 2013
From: onuruncu at gmail.com (Onur Uncu)
Date: Sun, 22 Dec 2013 23:54:51 +0000
Subject: [R] 2 factor split and lapply
Message-ID: <CAE4Ynx8dLtzcq-uuKOCvL+z0JaoZWOTrgt3j-8Y0CeKsPTPr5A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131222/78e5c699/attachment.pl>

From gunter.berton at gene.com  Mon Dec 23 01:44:06 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 22 Dec 2013 16:44:06 -0800
Subject: [R] 2 factor split and lapply
In-Reply-To: <CAE4Ynx8dLtzcq-uuKOCvL+z0JaoZWOTrgt3j-8Y0CeKsPTPr5A@mail.gmail.com>
References: <CAE4Ynx8dLtzcq-uuKOCvL+z0JaoZWOTrgt3j-8Y0CeKsPTPr5A@mail.gmail.com>
Message-ID: <CACk-te3Vdk3R0CuSvJY+hQYaB_yP82tXY32QSY1f-5iSP+8j4w@mail.gmail.com>

I believe you missed
 ?tapply
 which does what you want I think (in the absence of a reproducible
example one cannot be sure).

Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Sun, Dec 22, 2013 at 3:54 PM, Onur Uncu <onuruncu at gmail.com> wrote:
> R Users,
>
> I have a data frame which I split using 2 factors using the split function:
>
> split(datframe, list(f=factor1, f2=factor2));
>
> I then used lapply to get some summary statistics grouped by factor1 and
> factor2.
>
> I now want to change the appearance of this output. I want to get  a 2
> dimensional table where columns represent values of factor1, rows represent
> values of factor2 and the entries on the table represent the summary
> results that were calculated by lapply.
>
> I tried as.table() function but did not help. It seems the problem is that
> R combined factor1 and factor 2 into one factor when I used list(f=factor1,
> f2=factor2) in the split function. So R is now unable to treat them as 2
> different factors in order to put them on row and columns of a table... Any
> ideas how I can achieve the desired table?
>
> Thanks for your help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Dec 23 08:36:24 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 23 Dec 2013 07:36:24 +0000
Subject: [R] Fitting particle size analysis data
In-Reply-To: <CAM=4muQJ1r1mzVP++vgxX50=Ljfb3JnK0iP9gVwh0piEgugUZw@mail.gmail.com>
References: <CAM=4muR3PeYvvNsM4pGks0o0QwNWo=sXcTuPiHnTXDK89wmeCA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA7E2F@SRVEXCHMBX.precheza.cz>
	<CAM=4muQJ1r1mzVP++vgxX50=Ljfb3JnK0iP9gVwh0piEgugUZw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA818A@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131223/4b49a058/attachment.pl>

From petr.pikal at precheza.cz  Mon Dec 23 08:48:17 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 23 Dec 2013 07:48:17 +0000
Subject: [R] Using cbind to merge different variables
In-Reply-To: <1387555136.35753.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1387555136.35753.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA81DD@SRVEXCHMBX.precheza.cz>

Hi

Another option is

dat1$Newvar <- 1*(rowSums(dat1)>0)

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of arun
> Sent: Friday, December 20, 2013 4:59 PM
> To: R help
> Subject: Re: [R] Using cbind to merge different variables
> 
> HI,
> 
> May be this helps:
> set.seed(45)
> ?dat1 <- as.data.frame(matrix(sample(0:1,100*5,replace=TRUE),ncol=5))
> 
> dat1$Newvar <- 1*(!!rowSums(dat1))
> 
> A.K.
> 
> 
> Hello.
> 
> I have a problem combining a number of variables. I have five columns
> with binary variables with the values 0 and 1. I would like to combine
> them into just one binary variable with 1 whenever just one of the
> other has value one, and 0 if none of them have value one.
> 
> How can I do that?
> 
> I tried to use cbind function, but for some reason I get results
>  1 even though all of the varuables included = 0 and for some rows I
> get  2. I tried changing the deparse.level but that doesn't seem to be
> the problem.
> 
> I hope someone can help.
> 
> Kind regards
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Dec 23 08:59:44 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 23 Dec 2013 07:59:44 +0000
Subject: [R] ANOVA repeated mesures
In-Reply-To: <DUB125-W37561264631AC919F39B98B9DA0@phx.gbl>
References: <DUB125-W37561264631AC919F39B98B9DA0@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA820B@SRVEXCHMBX.precheza.cz>

Hi

You have only single value for each participant in each gruppo and AFAIK you can not do statistic on single value.

You can check differences among participants

fit<-lm(valor~participantes, data=df2)
> fit<-lm(valor~participantes, data=df2)
> anova(fit)
Analysis of Variance Table

Response: valor
              Df Sum Sq Mean Sq F value Pr(>F)
participantes  7  5.167  0.7381  0.3163 0.9358
Residuals     16 37.333  2.3333               

and in groups

> fit<-lm(valor~grupo, data=df2)
> anova(fit)
Analysis of Variance Table

Response: valor
          Df Sum Sq Mean Sq F value    Pr(>F)    
grupo      2  22.75 11.3750  12.095 0.0003202 ***
Residuals 21  19.75  0.9405                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Ma Teresa Martinez Soriano
> Sent: Wednesday, December 18, 2013 4:17 PM
> To: r-help at r-project.org
> Subject: [R] ANOVA repeated mesures
> 
> Hi to everyone, I am tring to make a Anova with repeated measures,my
> data set looks like:
> participantes <- c("1", "2", "3", "4", "5", "6", "7", "8", "1", "2",
> "3", "4",   "5", "6", "7", "8", "1", "2", "3", "4", "5", "6", "7", "8")
> grupo <- factor(c(rep("A", 8), rep("B", 8), rep("C", 8)))valor <- c(1,
> 2, 4, 1, 1, 2, 2, 3, 3, 4, 4, 2, 3, 4, 4, 3, 4, 5, 3, 5, 5, 3,  4,
> 6)df2 <- data.frame(participantes, grupo, valor)
> I want to find if there is differences in the "grupo"  in each
> participant. I don't know how to find this p-value for each
> participant, could you help me, please??Thanks a lot
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nuncio.m at gmail.com  Mon Dec 23 10:46:49 2013
From: nuncio.m at gmail.com (nuncio m)
Date: Mon, 23 Dec 2013 15:16:49 +0530
Subject: [R] Significance of spectral peaks
Message-ID: <CAKgEAEMkvdQdmrqgbqba9cs6KCyQpvrYToBn7QRqd6_bSDvyMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131223/a17074bb/attachment.pl>

From daniel.haugstvedt at gmail.com  Mon Dec 23 11:10:01 2013
From: daniel.haugstvedt at gmail.com (Daniel Haugstvedt)
Date: Mon, 23 Dec 2013 11:10:01 +0100
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <001201ceff69$6a46d900$3ed48b00$@bigpond.com>
References: <CANKVVa3SqzK8nXA0kEmg=Npe2PuJ+MqnFQsU-7M1KvaSN7t2aw@mail.gmail.com>
	<D16683C5446.00000494jrkrideau@inbox.com>
	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>
Message-ID: <CANKVVa3EY2Ruu-2CoJsvK2UQHXjUSDyg_d-NRCEdbxXWZp6z1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131223/7767dd09/attachment.pl>

From dulcalma at bigpond.com  Mon Dec 23 13:28:33 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 23 Dec 2013 22:28:33 +1000
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <CANKVVa3EY2Ruu-2CoJsvK2UQHXjUSDyg_d-NRCEdbxXWZp6z1A@mail.gmail.com>
References: <CANKVVa3SqzK8nXA0kEmg=Npe2PuJ+MqnFQsU-7M1KvaSN7t2aw@mail.gmail.com>	<D16683C5446.00000494jrkrideau@inbox.com>	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>
	<CANKVVa3EY2Ruu-2CoJsvK2UQHXjUSDyg_d-NRCEdbxXWZp6z1A@mail.gmail.com>
Message-ID: <001c01ceffda$7fa36090$7eea21b0$@bigpond.com>

Hi Dan

 

I think you still have problems with embedded characters or some problems in
char code page conversion or the like.

 

Not knowing knitr but Sweave I cobbled the figures manually and ran the
sweave file to produce the latex file.

Latex was consistently stopping at the \caption and \ref functions 

I tried to see what was happening I added hyperref & when I copied the text
to hyperref  latex bailed up

 

I tried a minimal latex file without problems

 

I put the \title etc in the preamble. Some compilers need this

 

Duncan

 

From: Daniel Haugstvedt [mailto:daniel.haugstvedt at gmail.com] 
Sent: Monday, 23 December 2013 20:10
To: Duncan Mackay
Cc: John Kane; R
Subject: Re: [R] Knitr, ggplot and consistent fonts

 

I am really sorry for posting a non-working example. It is running when I
cut the code from my previous mail into a clean session in RStudio (OSX).
However, I suspect that you are right. I did cut and paste some code from a
forum yesterday which had characters that had to be replaced. I gave emacs a
try, but could not find the problem there either. 

 

The code below was pasted though textEdit and converted to plain text. I
hope this takes care of any embedded characters.

 

\documentclass{article}

\begin{document}

 

<<setup, include=FALSE, cache=FALSE>>=

library(knitr)

library(ggplot2)

@

 

\title{Knitr and ggplot2}

\author{Daniel Haugstvedt}

 

\maketitle

  

There are four plots in this article. Figure \ref{fig:plot-figHeight} uses 

the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth} 

used both fig.height=2.5 and fig.width=3. The later option makes the font

too big. 

 

An alternative approach is used in Figures  \ref{fig:plot-figOutWidthBig}
and

 \ref{fig:plot-figOutWidthSmall}. There the argument out.width is set to 

 12 and 8 cm respectively. This stops the problem of excessively large fonts

 for figures with smaller width, but there is still no consistency

 across plots in terms o font size.

 

<<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot with no
fig.width argument", results='hide', fig.pos='ht'>>=

df = data.frame(x = rnorm(100), y = 1:100)

ggplot(df, aes(x = x)) + 

  geom_histogram(aes(y = ..density..), 

                 binwidth = 1, colour = "black", fill = "white") + 

  xlab("Improvement, %") +

  ylab("Density") +

  theme_classic() 

@

 

<<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3, fig.cap="Density
plot with fig.width=3", fig.pos='ht'>>=

ggplot(df, aes(x = x)) + 

  geom_histogram(aes(y = ..density..), 

                 binwidth = 1, colour = "black", fill = "white") + 

  xlab("Improvement, %") +

  ylab("Density") +

  theme_classic() 

@

 

<<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=

ggplot(df, aes(x = x)) + 

  geom_histogram(aes(y = ..density..), 

                 binwidth = 1, colour = "black", fill = "white") + 

  xlab("Improvement, %") +

  ylab("Density") +

  theme_classic() 

@

 

<<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width = "8cm",
fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=

ggplot(df, aes(x = x)) + 

  geom_histogram(aes(y = ..density..), 

                 binwidth = 1, colour = "black", fill = "white") + 

  xlab("Improvement, %") +

  ylab("Density") +

  theme_classic() 

@

 

\end{document}

 

 

 

 

 

On Sun, Dec 22, 2013 at 11:59 PM, Duncan Mackay <dulcalma at bigpond.com>
wrote:

Hi Daniel
I tried it in Sweave after modifying it for Sweave and a similar thing for
Latex but R crashed.

I think there is an embedded character/s before the first chunk and in the
first chunk.

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of John Kane
Sent: Monday, 23 December 2013 04:19
To: Daniel Haugstvedt; r-help at r-project.org
Subject: Re: [R] Knitr, ggplot and consistent fonts

Hi Daniel,

For some reason I cannot get your example to work. The problem is in the
code chunk but I have no idea what is happening. The code is running
perfectly in R, itself but LaTeX seems to be choking when it hits the first
ggplot statement, that is the one in <<plot-figHeight>>=

The message I am getting is: "Missing $ inserted <inserted text> $
ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not enough to
figure out the problem.

I tried stripping out most of the LaTeX specific verbiage in the code chunk
and running the code in LyX which I use rather than plain vanilla LaTeX and
I still cannot get it to work. It is almost as if there is some hidden
character in the in that piece of code since I can duplicate the code myself
and I even pasted in most of the geom_histogram code into my code chunk and
it runs.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: daniel.haugstvedt at gmail.com
> Sent: Sun, 22 Dec 2013 12:42:50 +0100
> To: r-help at r-project.org
> Subject: [R] Knitr, ggplot and consistent fonts
>
> Dear R-help
>
> I am using Knitr and ggplot to draft an article and have now started
> to improve on the layout and graphics. So far I have not been able to
> maintain the same font size for labels in all my figures.
>
> My goal is to be able to change the width of the figures while
> maintaining the same font. This works for the height parameter
> (example not included).
>
> In the true document I also use tikz, but the problem can be
> reproduced without it.
>
> I know the question is very specific, but my understanding is that
> this combination of packages  is common. (They are really great. Keep
> up the good work.)  There has to be others facing the same problem and
> someone must have found a nice solution.
>
> Additional attempts from my side which failed are not included in the
> example. I have tested the Google results i could find without any luck.
>
> Cheers
> Daniel
>
> PS. I know the example plots could have been smaller, but they just
> became too ugly for me
>
>
> \documentclass{article}
> \begin{document}
>
> <<setup, include=FALSE, cache=FALSE>>=
> library(knitr)
> library(ggplot2)
> @
>
> \title{Knitr and ggplot2}
> \author{Daniel Haugstvedt}
>
> \maketitle
>
> There are four plots in this article. Figure \ref{fig:plot-figHeight}
> uses the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
> used both fig.height=2.5 and fig.width=3. The later option makes the
> font too big.
>
> An alternative approach is used in Figures
> \ref{fig:plot-figOutWidthBig} and  \ref{fig:plot-figOutWidthSmall}.
> There the argument out.width is set to
>  12 and 8 cm respectively. This stops the problem of excessively large
> fonts  for figures with smaller width, but there is still no
> consistency  across plots in terms of font size.
>
> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
> with no fig.width argument", fig.pos='ht'>>= df = data.frame(x =
> rnorm(100), y = 1:100) ggplot(df, aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
>
> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>= ggplot(df,
> aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
>
> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>= ggplot(df,
> aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
>
> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
> "8cm", fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
> ggplot(df, aes(x = x)) +
>   geom_histogram(aes(y = ..density..),
>                  binwidth = 1, colour = "black", fill = "white") +
>   xlab("Improvement, %") +
>   ylab("Density") +
>   theme_classic()
> @
>
> \end{document}
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
http://www.inbox.com/smileys Works with AIMR, MSNR Messenger, Yahoo!R
Messenger, ICQR, Google TalkT and most webmails

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

 


From kridox at ymail.com  Mon Dec 23 13:35:32 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 23 Dec 2013 21:35:32 +0900
Subject: [R] Significance of spectral peaks
In-Reply-To: <CAKgEAEMkvdQdmrqgbqba9cs6KCyQpvrYToBn7QRqd6_bSDvyMw@mail.gmail.com>
References: <CAKgEAEMkvdQdmrqgbqba9cs6KCyQpvrYToBn7QRqd6_bSDvyMw@mail.gmail.com>
Message-ID: <CAAcyNCxRg6sar8Ke__5CwxO-uZop47J=cKwoUU50wAZFSJTfPg@mail.gmail.com>

Hello,

See ?redfit from "dplR", for example.

HTH,
Pascal

On 23 December 2013 18:46, nuncio m <nuncio.m at gmail.com> wrote:
> Dear useRs,
>
> I have a time series of length approcimately 55. Is it possible to find the
> significance of fft spectral peaks with R?
>
> thank you
>
> --
> Nuncio.M
> Scientist
> National Center for Antarctic and Ocean research
> Head land Sada
> Vasco da Gamma
> Goa-403804
> ph off 91 832 2525636
> ph: cell 91 9890357423
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From yanchangzhao at gmail.com  Mon Dec 23 14:25:19 2013
From: yanchangzhao at gmail.com (Yanchang Zhao)
Date: Tue, 24 Dec 2013 00:25:19 +1100
Subject: [R] New book release: Data Mining Applications with R
Message-ID: <CA+7aJfpQhF0Ydzh1hKf17otOoaW54uzpEMav3zxHtxyz1yPrKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131224/751f74e8/attachment.pl>

From onuruncu at gmail.com  Mon Dec 23 15:22:36 2013
From: onuruncu at gmail.com (Onur Uncu)
Date: Mon, 23 Dec 2013 14:22:36 +0000
Subject: [R] 2 factor split and lapply
In-Reply-To: <CACk-te3Vdk3R0CuSvJY+hQYaB_yP82tXY32QSY1f-5iSP+8j4w@mail.gmail.com>
References: <CAE4Ynx8dLtzcq-uuKOCvL+z0JaoZWOTrgt3j-8Y0CeKsPTPr5A@mail.gmail.com>
	<CACk-te3Vdk3R0CuSvJY+hQYaB_yP82tXY32QSY1f-5iSP+8j4w@mail.gmail.com>
Message-ID: <EBD14876-81F9-4514-8130-7EB1D8487E68@gmail.com>

Sure, here is a reproducible example:

testframe<-data.frame(factor1=c("a","b","a"),factor2=c(1,2,2),data=c(3.34,4.2,2.1))

splitframe<-split(testframe,list(factor1=testframe$factor1,factor2=testframe$factor2))

lapply(splitframe,function(x)mean(x[,"data"]))

The above lapply returns

$a.1
[1] 3.34

$b.1
[1] NaN

$a.2
[1] 2.1

$b.2
[1] 4.2

The results are correct but not presented in a format I prefer... Factor1 and factor2 are combined into a single factor, which is not desired. I want to keep them seperate. Ideally, a table output as below.

     a          b
1   3.34     NaN
2   2.1       4.2

How can I achieve this please?

> On 23 Dec 2013, at 00:44, Bert Gunter <gunter.berton at gene.com> wrote:
> 
> I believe you missed
> ?tapply
> which does what you want I think (in the absence of a reproducible
> example one cannot be sure).
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> H. Gilbert Welch
> 
> 
> 
> 
>> On Sun, Dec 22, 2013 at 3:54 PM, Onur Uncu <onuruncu at gmail.com> wrote:
>> R Users,
>> 
>> I have a data frame which I split using 2 factors using the split function:
>> 
>> split(datframe, list(f=factor1, f2=factor2));
>> 
>> I then used lapply to get some summary statistics grouped by factor1 and
>> factor2.
>> 
>> I now want to change the appearance of this output. I want to get  a 2
>> dimensional table where columns represent values of factor1, rows represent
>> values of factor2 and the entries on the table represent the summary
>> results that were calculated by lapply.
>> 
>> I tried as.table() function but did not help. It seems the problem is that
>> R combined factor1 and factor 2 into one factor when I used list(f=factor1,
>> f2=factor2) in the split function. So R is now unable to treat them as 2
>> different factors in order to put them on row and columns of a table... Any
>> ideas how I can achieve the desired table?
>> 
>> Thanks for your help.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Dec 23 15:35:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 23 Dec 2013 06:35:19 -0800 (PST)
Subject: [R] 2 factor split and lapply
In-Reply-To: <EBD14876-81F9-4514-8130-7EB1D8487E68@gmail.com>
References: <CAE4Ynx8dLtzcq-uuKOCvL+z0JaoZWOTrgt3j-8Y0CeKsPTPr5A@mail.gmail.com>	<CACk-te3Vdk3R0CuSvJY+hQYaB_yP82tXY32QSY1f-5iSP+8j4w@mail.gmail.com>
	<EBD14876-81F9-4514-8130-7EB1D8487E68@gmail.com>
Message-ID: <1387809319.86434.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
You could try:
library(reshape2)
dcast(as.data.frame(as.table(by(testframe[,3],testframe[,-3],mean))),factor2~factor1,value.var="Freq")
#? factor2??? a?? b
#1?????? 1 3.34? NA
#2?????? 2 2.10 4.2

A.K.




On Monday, December 23, 2013 9:24 AM, Onur Uncu <onuruncu at gmail.com> wrote:
Sure, here is a reproducible example:

testframe<-data.frame(factor1=c("a","b","a"),factor2=c(1,2,2),data=c(3.34,4.2,2.1))

splitframe<-split(testframe,list(factor1=testframe$factor1,factor2=testframe$factor2))

lapply(splitframe,function(x)mean(x[,"data"]))

The above lapply returns

$a.1
[1] 3.34

$b.1
[1] NaN

$a.2
[1] 2.1

$b.2
[1] 4.2

The results are correct but not presented in a format I prefer... Factor1 and factor2 are combined into a single factor, which is not desired. I want to keep them seperate. Ideally, a table output as below.

? ?  a? ? ? ? ? b
1?  3.34? ?  NaN
2?  2.1? ? ?  4.2

How can I achieve this please?


> On 23 Dec 2013, at 00:44, Bert Gunter <gunter.berton at gene.com> wrote:
> 
> I believe you missed
> ?tapply
> which does what you want I think (in the absence of a reproducible
> example one cannot be sure).
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> H. Gilbert Welch
> 
> 
> 
> 
>> On Sun, Dec 22, 2013 at 3:54 PM, Onur Uncu <onuruncu at gmail.com> wrote:
>> R Users,
>> 
>> I have a data frame which I split using 2 factors using the split function:
>> 
>> split(datframe, list(f=factor1, f2=factor2));
>> 
>> I then used lapply to get some summary statistics grouped by factor1 and
>> factor2.
>> 
>> I now want to change the appearance of this output. I want to get? a 2
>> dimensional table where columns represent values of factor1, rows represent
>> values of factor2 and the entries on the table represent the summary
>> results that were calculated by lapply.
>> 
>> I tried as.table() function but did not help. It seems the problem is that
>> R combined factor1 and factor 2 into one factor when I used list(f=factor1,
>> f2=factor2) in the split function. So R is now unable to treat them as 2
>> different factors in order to put them on row and columns of a table... Any
>> ideas how I can achieve the desired table?
>> 
>> Thanks for your help.
>> 
>>? ? ? ? [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Mon Dec 23 15:45:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 23 Dec 2013 06:45:28 -0800 (PST)
Subject: [R] 2 factor split and lapply
In-Reply-To: <1387809319.86434.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAE4Ynx8dLtzcq-uuKOCvL+z0JaoZWOTrgt3j-8Y0CeKsPTPr5A@mail.gmail.com>	<CACk-te3Vdk3R0CuSvJY+hQYaB_yP82tXY32QSY1f-5iSP+8j4w@mail.gmail.com>	<EBD14876-81F9-4514-8130-7EB1D8487E68@gmail.com>
	<1387809319.86434.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1387809928.84960.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
I think this will be more appropriate.

dcast(testframe,factor2~factor1,value.var="data",mean)
? factor2??? a?? b
1?????? 1 3.34 NaN
2?????? 2 2.10 4.2
A.K.


On Monday, December 23, 2013 9:37 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,
You could try:
library(reshape2)
dcast(as.data.frame(as.table(by(testframe[,3],testframe[,-3],mean))),factor2~factor1,value.var="Freq")
#? factor2??? a?? b
#1?????? 1 3.34? NA
#2?????? 2 2.10 4.2

A.K.




On Monday, December 23, 2013 9:24 AM, Onur Uncu <onuruncu at gmail.com> wrote:
Sure, here is a reproducible example:

testframe<-data.frame(factor1=c("a","b","a"),factor2=c(1,2,2),data=c(3.34,4.2,2.1))

splitframe<-split(testframe,list(factor1=testframe$factor1,factor2=testframe$factor2))

lapply(splitframe,function(x)mean(x[,"data"]))

The above lapply returns

$a.1
[1] 3.34

$b.1
[1] NaN

$a.2
[1] 2.1

$b.2
[1] 4.2

The results are correct but not presented in a format I prefer... Factor1 and factor2 are combined into a single factor, which is not desired. I want to keep them seperate. Ideally, a table output as below.

? ?? a? ? ? ? ? b
1?? 3.34? ?? NaN
2?? 2.1? ? ?? 4.2

How can I achieve this please?


> On 23 Dec 2013, at 00:44, Bert Gunter <gunter.berton at gene.com> wrote:
> 
> I believe you missed
> ?tapply
> which does what you want I think (in the absence of a reproducible
> example one cannot be sure).
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> H. Gilbert Welch
> 
> 
> 
> 
>> On Sun, Dec 22, 2013 at 3:54 PM, Onur Uncu <onuruncu at gmail.com> wrote:
>> R Users,
>> 
>> I have a data frame which I split using 2 factors using the split function:
>> 
>> split(datframe, list(f=factor1, f2=factor2));
>> 
>> I then used lapply to get some summary statistics grouped by factor1 and
>> factor2.
>> 
>> I now want to change the appearance of this output. I want to get? a 2
>> dimensional table where columns represent values of factor1, rows represent
>> values of factor2 and the entries on the table represent the summary
>> results that were calculated by lapply.
>> 
>> I tried as.table() function but did not help. It seems the problem is that
>> R combined factor1 and factor 2 into one factor when I used list(f=factor1,
>> f2=factor2) in the split function. So R is now unable to treat them as 2
>> different factors in order to put them on row and columns of a table... Any
>> ideas how I can achieve the desired table?
>> 
>> Thanks for your help.
>> 
>>? ? ? ? [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Mon Dec 23 16:24:50 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 23 Dec 2013 07:24:50 -0800
Subject: [R] 2 factor split and lapply
In-Reply-To: <EBD14876-81F9-4514-8130-7EB1D8487E68@gmail.com>
References: <CAE4Ynx8dLtzcq-uuKOCvL+z0JaoZWOTrgt3j-8Y0CeKsPTPr5A@mail.gmail.com>
	<CACk-te3Vdk3R0CuSvJY+hQYaB_yP82tXY32QSY1f-5iSP+8j4w@mail.gmail.com>
	<EBD14876-81F9-4514-8130-7EB1D8487E68@gmail.com>
Message-ID: <CACk-te1+VQFJq44uKN6COgtHnHaEbe3G3vG-6F1ztoubQ9qKsw@mail.gmail.com>

As I said, ?tapply gives you an answer (without using other packages) . Read it.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Mon, Dec 23, 2013 at 6:22 AM, Onur Uncu <onuruncu at gmail.com> wrote:
> Sure, here is a reproducible example:
>
> testframe<-data.frame(factor1=c("a","b","a"),factor2=c(1,2,2),data=c(3.34,4.2,2.1))
>
> splitframe<-split(testframe,list(factor1=testframe$factor1,factor2=testframe$factor2))
>
> lapply(splitframe,function(x)mean(x[,"data"]))
>
> The above lapply returns
>
> $a.1
> [1] 3.34
>
> $b.1
> [1] NaN
>
> $a.2
> [1] 2.1
>
> $b.2
> [1] 4.2
>
> The results are correct but not presented in a format I prefer... Factor1 and factor2 are combined into a single factor, which is not desired. I want to keep them seperate. Ideally, a table output as below.
>
>      a          b
> 1   3.34     NaN
> 2   2.1       4.2
>
> How can I achieve this please?
>
>> On 23 Dec 2013, at 00:44, Bert Gunter <gunter.berton at gene.com> wrote:
>>
>> I believe you missed
>> ?tapply
>> which does what you want I think (in the absence of a reproducible
>> example one cannot be sure).
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> H. Gilbert Welch
>>
>>
>>
>>
>>> On Sun, Dec 22, 2013 at 3:54 PM, Onur Uncu <onuruncu at gmail.com> wrote:
>>> R Users,
>>>
>>> I have a data frame which I split using 2 factors using the split function:
>>>
>>> split(datframe, list(f=factor1, f2=factor2));
>>>
>>> I then used lapply to get some summary statistics grouped by factor1 and
>>> factor2.
>>>
>>> I now want to change the appearance of this output. I want to get  a 2
>>> dimensional table where columns represent values of factor1, rows represent
>>> values of factor2 and the entries on the table represent the summary
>>> results that were calculated by lapply.
>>>
>>> I tried as.table() function but did not help. It seems the problem is that
>>> R combined factor1 and factor 2 into one factor when I used list(f=factor1,
>>> f2=factor2) in the split function. So R is now unable to treat them as 2
>>> different factors in order to put them on row and columns of a table... Any
>>> ideas how I can achieve the desired table?
>>>
>>> Thanks for your help.
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From costas.vorlow at gmail.com  Mon Dec 23 16:57:16 2013
From: costas.vorlow at gmail.com (Costas Vorlow)
Date: Mon, 23 Dec 2013 17:57:16 +0200
Subject: [R] R command execution at specific time from within R
Message-ID: <CABfqsR_8SRqB2Nuw3wMkvjO7CxReW9KE2gLVww1NaD+7ruevNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131223/6d76a403/attachment.pl>

From edd at debian.org  Mon Dec 23 17:16:54 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 23 Dec 2013 16:16:54 +0000
Subject: [R]
	=?utf-8?q?Unable_to_install_RcppEigen_package_due_to_Rcpp_dep?=
	=?utf-8?q?endency=09issues?=
References: <CAO7fSPt8bbcPo+_qUzi5t9GFM_91foAu0is0S_XVO8Qqs4NzBw@mail.gmail.com>
Message-ID: <loom.20131223T171538-202@post.gmane.org>

Rewarp <rewarp <at> gmail.com> writes:
> I am trying to install RcppEigen, which depends on Rcpp. Here's what the
> terminal says:
> 
> > install.packages("RcppEigen")
[...]
> g++ -shared -o RcppEigen.so RcppEigen.o fastLm.o
> -L/home/rewarp/R/x86_64-pc-linux-gnu-library/3.0/Rcpp/lib -lRcpp
> -Wl,-rpath,/home/rewarp/R/x86_64-pc-linux-gnu-library/3.0/Rcpp/lib -llapack
> -lblas -lgfortran -lm -lquadmath -L/usr/lib/R/lib -lR
> /usr/bin/ld: cannot find -llapack
> /usr/bin/ld: cannot find -lblas
> collect2: ld returned 1 exit status

You need to install the required libraries.  It looks like you may be
on Debian or Ubuntu so try

   $ sudo apt-get install r-base-dev

which should pull these in.

Support for Rcpp and friends is provided on the rcpp-devel list.

Dirk


From jrkrideau at inbox.com  Mon Dec 23 17:37:05 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 23 Dec 2013 08:37:05 -0800
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <001c01ceffda$7fa36090$7eea21b0$@bigpond.com>
References: <cankvva3sqzk8nxa0kemg=npe2puj+mqnfqsu-7m1kvasn7t2aw@mail.gmail.com>
	<d16683c5446.00000494jrkrideau@inbox.com>
	<cankvva3ey2ruu-2cojsvk2uqhxjusdyg_d-nrcedbxxwzp6z1a@mail.gmail.com>
	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>
Message-ID: <DD14B2ACA2B.00000424jrkrideau@inbox.com>

Same result here with the same error message mentioned in my first post.  I tried it in Texmaker which is my usual Latex editor, not that I do much in Latex, and then tried it in RStudio and it is still choking.  

Interestingly EMACS will process it and produce a pdf but it simply produces.  It also provides this warning: : Latex Warning; Reference 'fig:plot-figheight' undefined on page 2 on input line 14. 

It seems to repeat the same message for each of the other figures.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: dulcalma at bigpond.com
> Sent: Mon, 23 Dec 2013 22:28:33 +1000
> To: daniel.haugstvedt at gmail.com, r-help at r-project.org
> Subject: Re: [R] Knitr, ggplot and consistent fonts
> 
> Hi Dan
> 
> 
> 
> I think you still have problems with embedded characters or some problems
> in
> char code page conversion or the like.
> 
> 
> 
> Not knowing knitr but Sweave I cobbled the figures manually and ran the
> sweave file to produce the latex file.
> 
> Latex was consistently stopping at the \caption and \ref functions
> 
> I tried to see what was happening I added hyperref & when I copied the
> text
> to hyperref  latex bailed up
> 
> 
> 
> I tried a minimal latex file without problems
> 
> 
> 
> I put the \title etc in the preamble. Some compilers need this
> 
> 
> 
> Duncan
> 
> 
> 
> From: Daniel Haugstvedt [mailto:daniel.haugstvedt at gmail.com]
> Sent: Monday, 23 December 2013 20:10
> To: Duncan Mackay
> Cc: John Kane; R
> Subject: Re: [R] Knitr, ggplot and consistent fonts
> 
> 
> 
> I am really sorry for posting a non-working example. It is running when I
> cut the code from my previous mail into a clean session in RStudio (OSX).
> However, I suspect that you are right. I did cut and paste some code from
> a
> forum yesterday which had characters that had to be replaced. I gave
> emacs a
> try, but could not find the problem there either.
> 
> 
> 
> The code below was pasted though textEdit and converted to plain text. I
> hope this takes care of any embedded characters.
> 
> 
> 
> \documentclass{article}
> 
> \begin{document}
> 
> 
> 
> <<setup, include=FALSE, cache=FALSE>>=
> 
> library(knitr)
> 
> library(ggplot2)
> 
> @
> 
> 
> 
> \title{Knitr and ggplot2}
> 
> \author{Daniel Haugstvedt}
> 
> 
> 
> \maketitle
> 
> 
> 
> There are four plots in this article. Figure \ref{fig:plot-figHeight}
> uses
> 
> the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
> 
> used both fig.height=2.5 and fig.width=3. The later option makes the font
> 
> too big.
> 
> 
> 
> An alternative approach is used in Figures  \ref{fig:plot-figOutWidthBig}
> and
> 
>  \ref{fig:plot-figOutWidthSmall}. There the argument out.width is set to
> 
>  12 and 8 cm respectively. This stops the problem of excessively large
> fonts
> 
>  for figures with smaller width, but there is still no consistency
> 
>  across plots in terms o font size.
> 
> 
> 
> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot with
> no
> fig.width argument", results='hide', fig.pos='ht'>>=
> 
> df = data.frame(x = rnorm(100), y = 1:100)
> 
> ggplot(df, aes(x = x)) +
> 
>   geom_histogram(aes(y = ..density..),
> 
>                  binwidth = 1, colour = "black", fill = "white") +
> 
>   xlab("Improvement, %") +
> 
>   ylab("Density") +
> 
>   theme_classic()
> 
> @
> 
> 
> 
> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
> fig.cap="Density
> plot with fig.width=3", fig.pos='ht'>>=
> 
> ggplot(df, aes(x = x)) +
> 
>   geom_histogram(aes(y = ..density..),
> 
>                  binwidth = 1, colour = "black", fill = "white") +
> 
>   xlab("Improvement, %") +
> 
>   ylab("Density") +
> 
>   theme_classic()
> 
> @
> 
> 
> 
> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
> 
> ggplot(df, aes(x = x)) +
> 
>   geom_histogram(aes(y = ..density..),
> 
>                  binwidth = 1, colour = "black", fill = "white") +
> 
>   xlab("Improvement, %") +
> 
>   ylab("Density") +
> 
>   theme_classic()
> 
> @
> 
> 
> 
> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width = "8cm",
> fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
> 
> ggplot(df, aes(x = x)) +
> 
>   geom_histogram(aes(y = ..density..),
> 
>                  binwidth = 1, colour = "black", fill = "white") +
> 
>   xlab("Improvement, %") +
> 
>   ylab("Density") +
> 
>   theme_classic()
> 
> @
> 
> 
> 
> \end{document}
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> On Sun, Dec 22, 2013 at 11:59 PM, Duncan Mackay <dulcalma at bigpond.com>
> wrote:
> 
> Hi Daniel
> I tried it in Sweave after modifying it for Sweave and a similar thing
> for
> Latex but R crashed.
> 
> I think there is an embedded character/s before the first chunk and in
> the
> first chunk.
> 
> Duncan
> 
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On
> Behalf Of John Kane
> Sent: Monday, 23 December 2013 04:19
> To: Daniel Haugstvedt; r-help at r-project.org
> Subject: Re: [R] Knitr, ggplot and consistent fonts
> 
> Hi Daniel,
> 
> For some reason I cannot get your example to work. The problem is in the
> code chunk but I have no idea what is happening. The code is running
> perfectly in R, itself but LaTeX seems to be choking when it hits the
> first
> ggplot statement, that is the one in <<plot-figHeight>>=
> 
> The message I am getting is: "Missing $ inserted <inserted text> $
> ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not enough to
> figure out the problem.
> 
> I tried stripping out most of the LaTeX specific verbiage in the code
> chunk
> and running the code in LyX which I use rather than plain vanilla LaTeX
> and
> I still cannot get it to work. It is almost as if there is some hidden
> character in the in that piece of code since I can duplicate the code
> myself
> and I even pasted in most of the geom_histogram code into my code chunk
> and
> it runs.
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: daniel.haugstvedt at gmail.com
>> Sent: Sun, 22 Dec 2013 12:42:50 +0100
>> To: r-help at r-project.org
>> Subject: [R] Knitr, ggplot and consistent fonts
>> 
>> Dear R-help
>> 
>> I am using Knitr and ggplot to draft an article and have now started
>> to improve on the layout and graphics. So far I have not been able to
>> maintain the same font size for labels in all my figures.
>> 
>> My goal is to be able to change the width of the figures while
>> maintaining the same font. This works for the height parameter
>> (example not included).
>> 
>> In the true document I also use tikz, but the problem can be
>> reproduced without it.
>> 
>> I know the question is very specific, but my understanding is that
>> this combination of packages  is common. (They are really great. Keep
>> up the good work.)  There has to be others facing the same problem and
>> someone must have found a nice solution.
>> 
>> Additional attempts from my side which failed are not included in the
>> example. I have tested the Google results i could find without any luck.
>> 
>> Cheers
>> Daniel
>> 
>> PS. I know the example plots could have been smaller, but they just
>> became too ugly for me
>> 
>> 
>> \documentclass{article}
>> \begin{document}
>> 
>> <<setup, include=FALSE, cache=FALSE>>=
>> library(knitr)
>> library(ggplot2)
>> @
>> 
>> \title{Knitr and ggplot2}
>> \author{Daniel Haugstvedt}
>> 
>> \maketitle
>> 
>> There are four plots in this article. Figure \ref{fig:plot-figHeight}
>> uses the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>> used both fig.height=2.5 and fig.width=3. The later option makes the
>> font too big.
>> 
>> An alternative approach is used in Figures
>> \ref{fig:plot-figOutWidthBig} and  \ref{fig:plot-figOutWidthSmall}.
>> There the argument out.width is set to
>>  12 and 8 cm respectively. This stops the problem of excessively large
>> fonts  for figures with smaller width, but there is still no
>> consistency  across plots in terms of font size.
>> 
>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>> with no fig.width argument", fig.pos='ht'>>= df = data.frame(x =
>> rnorm(100), y = 1:100) ggplot(df, aes(x = x)) +
>>   geom_histogram(aes(y = ..density..),
>>                  binwidth = 1, colour = "black", fill = "white") +
>>   xlab("Improvement, %") +
>>   ylab("Density") +
>>   theme_classic()
>> @
>> 
>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>= ggplot(df,
>> aes(x = x)) +
>>   geom_histogram(aes(y = ..density..),
>>                  binwidth = 1, colour = "black", fill = "white") +
>>   xlab("Improvement, %") +
>>   ylab("Density") +
>>   theme_classic()
>> @
>> 
>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>= ggplot(df,
>> aes(x = x)) +
>>   geom_histogram(aes(y = ..density..),
>>                  binwidth = 1, colour = "black", fill = "white") +
>>   xlab("Improvement, %") +
>>   ylab("Density") +
>>   theme_classic()
>> @
>> 
>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
>> "8cm", fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>> ggplot(df, aes(x = x)) +
>>   geom_histogram(aes(y = ..density..),
>>                  binwidth = 1, colour = "black", fill = "white") +
>>   xlab("Improvement, %") +
>>   ylab("Density") +
>>   theme_classic()
>> @
>> 
>> \end{document}
>> 
>>       [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
> http://www.inbox.com/smileys Works with AIMR, MSNR Messenger, Yahoo!R
> Messenger, ICQR, Google TalkT and most webmails
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From rmh at temple.edu  Mon Dec 23 17:44:42 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 23 Dec 2013 11:44:42 -0500
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <DD14B2ACA2B.00000424jrkrideau@inbox.com>
References: <cankvva3sqzk8nxa0kemg=npe2puj+mqnfqsu-7m1kvasn7t2aw@mail.gmail.com>
	<d16683c5446.00000494jrkrideau@inbox.com>
	<cankvva3ey2ruu-2cojsvk2uqhxjusdyg_d-nrcedbxxwzp6z1a@mail.gmail.com>
	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>
	<001c01ceffda$7fa36090$7eea21b0$@bigpond.com>
	<DD14B2ACA2B.00000424jrkrideau@inbox.com>
Message-ID: <CAGx1TMCYKo2VBx036wTc8YyPYi_43yhY42GVJGN57yy8vtcXHQ@mail.gmail.com>

If the problem seems to be non-ASCII characters, then the first investigation
step is to use the R functions

?tools::showNonASCII
?tools::showNonASCIIfile

On Mon, Dec 23, 2013 at 11:37 AM, John Kane <jrkrideau at inbox.com> wrote:
> Same result here with the same error message mentioned in my first post.  I tried it in Texmaker which is my usual Latex editor, not that I do much in Latex, and then tried it in RStudio and it is still choking.
>
> Interestingly EMACS will process it and produce a pdf but it simply produces.  It also provides this warning: : Latex Warning; Reference 'fig:plot-figheight' undefined on page 2 on input line 14.
>
> It seems to repeat the same message for each of the other figures.
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: dulcalma at bigpond.com
>> Sent: Mon, 23 Dec 2013 22:28:33 +1000
>> To: daniel.haugstvedt at gmail.com, r-help at r-project.org
>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>
>> Hi Dan
>>
>>
>>
>> I think you still have problems with embedded characters or some problems
>> in
>> char code page conversion or the like.
>>
>>
>>
>> Not knowing knitr but Sweave I cobbled the figures manually and ran the
>> sweave file to produce the latex file.
>>
>> Latex was consistently stopping at the \caption and \ref functions
>>
>> I tried to see what was happening I added hyperref & when I copied the
>> text
>> to hyperref  latex bailed up
>>
>>
>>
>> I tried a minimal latex file without problems
>>
>>
>>
>> I put the \title etc in the preamble. Some compilers need this
>>
>>
>>
>> Duncan
>>
>>
>>
>> From: Daniel Haugstvedt [mailto:daniel.haugstvedt at gmail.com]
>> Sent: Monday, 23 December 2013 20:10
>> To: Duncan Mackay
>> Cc: John Kane; R
>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>
>>
>>
>> I am really sorry for posting a non-working example. It is running when I
>> cut the code from my previous mail into a clean session in RStudio (OSX).
>> However, I suspect that you are right. I did cut and paste some code from
>> a
>> forum yesterday which had characters that had to be replaced. I gave
>> emacs a
>> try, but could not find the problem there either.
>>
>>
>>
>> The code below was pasted though textEdit and converted to plain text. I
>> hope this takes care of any embedded characters.
>>
>>
>>
>> \documentclass{article}
>>
>> \begin{document}
>>
>>
>>
>> <<setup, include=FALSE, cache=FALSE>>=
>>
>> library(knitr)
>>
>> library(ggplot2)
>>
>> @
>>
>>
>>
>> \title{Knitr and ggplot2}
>>
>> \author{Daniel Haugstvedt}
>>
>>
>>
>> \maketitle
>>
>>
>>
>> There are four plots in this article. Figure \ref{fig:plot-figHeight}
>> uses
>>
>> the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>>
>> used both fig.height=2.5 and fig.width=3. The later option makes the font
>>
>> too big.
>>
>>
>>
>> An alternative approach is used in Figures  \ref{fig:plot-figOutWidthBig}
>> and
>>
>>  \ref{fig:plot-figOutWidthSmall}. There the argument out.width is set to
>>
>>  12 and 8 cm respectively. This stops the problem of excessively large
>> fonts
>>
>>  for figures with smaller width, but there is still no consistency
>>
>>  across plots in terms o font size.
>>
>>
>>
>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot with
>> no
>> fig.width argument", results='hide', fig.pos='ht'>>=
>>
>> df = data.frame(x = rnorm(100), y = 1:100)
>>
>> ggplot(df, aes(x = x)) +
>>
>>   geom_histogram(aes(y = ..density..),
>>
>>                  binwidth = 1, colour = "black", fill = "white") +
>>
>>   xlab("Improvement, %") +
>>
>>   ylab("Density") +
>>
>>   theme_classic()
>>
>> @
>>
>>
>>
>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>> fig.cap="Density
>> plot with fig.width=3", fig.pos='ht'>>=
>>
>> ggplot(df, aes(x = x)) +
>>
>>   geom_histogram(aes(y = ..density..),
>>
>>                  binwidth = 1, colour = "black", fill = "white") +
>>
>>   xlab("Improvement, %") +
>>
>>   ylab("Density") +
>>
>>   theme_classic()
>>
>> @
>>
>>
>>
>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
>>
>> ggplot(df, aes(x = x)) +
>>
>>   geom_histogram(aes(y = ..density..),
>>
>>                  binwidth = 1, colour = "black", fill = "white") +
>>
>>   xlab("Improvement, %") +
>>
>>   ylab("Density") +
>>
>>   theme_classic()
>>
>> @
>>
>>
>>
>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width = "8cm",
>> fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>
>> ggplot(df, aes(x = x)) +
>>
>>   geom_histogram(aes(y = ..density..),
>>
>>                  binwidth = 1, colour = "black", fill = "white") +
>>
>>   xlab("Improvement, %") +
>>
>>   ylab("Density") +
>>
>>   theme_classic()
>>
>> @
>>
>>
>>
>> \end{document}
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> On Sun, Dec 22, 2013 at 11:59 PM, Duncan Mackay <dulcalma at bigpond.com>
>> wrote:
>>
>> Hi Daniel
>> I tried it in Sweave after modifying it for Sweave and a similar thing
>> for
>> Latex but R crashed.
>>
>> I think there is an embedded character/s before the first chunk and in
>> the
>> first chunk.
>>
>> Duncan
>>
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On
>> Behalf Of John Kane
>> Sent: Monday, 23 December 2013 04:19
>> To: Daniel Haugstvedt; r-help at r-project.org
>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>
>> Hi Daniel,
>>
>> For some reason I cannot get your example to work. The problem is in the
>> code chunk but I have no idea what is happening. The code is running
>> perfectly in R, itself but LaTeX seems to be choking when it hits the
>> first
>> ggplot statement, that is the one in <<plot-figHeight>>=
>>
>> The message I am getting is: "Missing $ inserted <inserted text> $
>> ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not enough to
>> figure out the problem.
>>
>> I tried stripping out most of the LaTeX specific verbiage in the code
>> chunk
>> and running the code in LyX which I use rather than plain vanilla LaTeX
>> and
>> I still cannot get it to work. It is almost as if there is some hidden
>> character in the in that piece of code since I can duplicate the code
>> myself
>> and I even pasted in most of the geom_histogram code into my code chunk
>> and
>> it runs.
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>>> -----Original Message-----
>>> From: daniel.haugstvedt at gmail.com
>>> Sent: Sun, 22 Dec 2013 12:42:50 +0100
>>> To: r-help at r-project.org
>>> Subject: [R] Knitr, ggplot and consistent fonts
>>>
>>> Dear R-help
>>>
>>> I am using Knitr and ggplot to draft an article and have now started
>>> to improve on the layout and graphics. So far I have not been able to
>>> maintain the same font size for labels in all my figures.
>>>
>>> My goal is to be able to change the width of the figures while
>>> maintaining the same font. This works for the height parameter
>>> (example not included).
>>>
>>> In the true document I also use tikz, but the problem can be
>>> reproduced without it.
>>>
>>> I know the question is very specific, but my understanding is that
>>> this combination of packages  is common. (They are really great. Keep
>>> up the good work.)  There has to be others facing the same problem and
>>> someone must have found a nice solution.
>>>
>>> Additional attempts from my side which failed are not included in the
>>> example. I have tested the Google results i could find without any luck.
>>>
>>> Cheers
>>> Daniel
>>>
>>> PS. I know the example plots could have been smaller, but they just
>>> became too ugly for me
>>>
>>>
>>> \documentclass{article}
>>> \begin{document}
>>>
>>> <<setup, include=FALSE, cache=FALSE>>=
>>> library(knitr)
>>> library(ggplot2)
>>> @
>>>
>>> \title{Knitr and ggplot2}
>>> \author{Daniel Haugstvedt}
>>>
>>> \maketitle
>>>
>>> There are four plots in this article. Figure \ref{fig:plot-figHeight}
>>> uses the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>>> used both fig.height=2.5 and fig.width=3. The later option makes the
>>> font too big.
>>>
>>> An alternative approach is used in Figures
>>> \ref{fig:plot-figOutWidthBig} and  \ref{fig:plot-figOutWidthSmall}.
>>> There the argument out.width is set to
>>>  12 and 8 cm respectively. This stops the problem of excessively large
>>> fonts  for figures with smaller width, but there is still no
>>> consistency  across plots in terms of font size.
>>>
>>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>>> with no fig.width argument", fig.pos='ht'>>= df = data.frame(x =
>>> rnorm(100), y = 1:100) ggplot(df, aes(x = x)) +
>>>   geom_histogram(aes(y = ..density..),
>>>                  binwidth = 1, colour = "black", fill = "white") +
>>>   xlab("Improvement, %") +
>>>   ylab("Density") +
>>>   theme_classic()
>>> @
>>>
>>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>>> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>= ggplot(df,
>>> aes(x = x)) +
>>>   geom_histogram(aes(y = ..density..),
>>>                  binwidth = 1, colour = "black", fill = "white") +
>>>   xlab("Improvement, %") +
>>>   ylab("Density") +
>>>   theme_classic()
>>> @
>>>
>>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
>>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>= ggplot(df,
>>> aes(x = x)) +
>>>   geom_histogram(aes(y = ..density..),
>>>                  binwidth = 1, colour = "black", fill = "white") +
>>>   xlab("Improvement, %") +
>>>   ylab("Density") +
>>>   theme_classic()
>>> @
>>>
>>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
>>> "8cm", fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>> ggplot(df, aes(x = x)) +
>>>   geom_histogram(aes(y = ..density..),
>>>                  binwidth = 1, colour = "black", fill = "white") +
>>>   xlab("Improvement, %") +
>>>   ylab("Density") +
>>>   theme_classic()
>>> @
>>>
>>> \end{document}
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ____________________________________________________________
>> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
>> http://www.inbox.com/smileys Works with AIMR, MSNR Messenger, Yahoo!R
>> Messenger, ICQR, Google TalkT and most webmails
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mamushbukana at gmail.com  Mon Dec 23 18:07:35 2013
From: mamushbukana at gmail.com (mamush bukana)
Date: Mon, 23 Dec 2013 15:07:35 -0200
Subject: [R] error in "ca.jo"
Message-ID: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131223/34326994/attachment.pl>

From jrkrideau at inbox.com  Mon Dec 23 18:21:06 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 23 Dec 2013 09:21:06 -0800
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <CAE8W1T1CagaJnenBpPLkdDwmf_e7A0R4tJVT8X5=-uU1pBLOYg@mail.gmail.com>
References: <001c01ceffda$7fa36090$7eea21b0$@bigpond.com>
	<cankvva3sqzk8nxa0kemg=npe2puj+mqnfqsu-7m1kvasn7t2aw@mail.gmail.com>
	<d16683c5446.00000494jrkrideau@inbox.com>
	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>
	<cankvva3ey2ruu-2cojsvk2uqhxjusdyg_d-nrcedbxxwzp6z1a@mail.gmail.com>
	<dd14b2aca2b.00000424jrkrideau@inbox.com>
Message-ID: <DD771B6C739.000004DFjrkrideau@inbox.com>

Does not seem to be.? I 'think' I removed all the line breaks? and it still is not compiling.  Thanks for the suggestion. I had not bothered to paste the <<>>= text into RStudio and since TexMaker has an automatic wrap, I would never have noticed it. 

John Kane
Kingston ON Canada

-----Original Message-----
From: felasa at gmail.com
Sent: Mon, 23 Dec 2013 10:53:59 -0600
To: jrkrideau at inbox.com
Subject: Re: [R] Knitr, ggplot and consistent fonts

Hi, chiming in.?
Pasted the code in R studio and the format parser wouldn't mark the R code chunks. It was because there were line breaks in the middle of chunk options tags. ?Couldn't test if removing line breaks works, but maybe that's the source of the problem?

On Mon, Dec 23, 2013 at 10:37 AM, John Kane <jrkrideau at inbox.com> wrote:

	Same result here with the same error message mentioned in my first post. ?I tried it in Texmaker which is my usual Latex editor, not that I do much in Latex, and then tried it in RStudio and it is still choking.

 Interestingly EMACS will process it and produce a pdf but it simply produces. ?It also provides this warning: : Latex Warning; Reference 'fig:plot-figheight' undefined on page 2 on input line 14.

 It seems to repeat the same message for each of the other figures.

 John Kane
 Kingston ON Canada

 > -----Original Message-----

> From: dulcalma at bigpond.com
 > Sent: Mon, 23 Dec 2013 22:28:33 +1000
 > To: daniel.haugstvedt at gmail.com, r-help at r-project.org
 > Subject: Re: [R] Knitr, ggplot and consistent fonts
 >
 > Hi Dan
 >
 >
 >
 > I think you still have problems with embedded characters or some problems
 > in
 > char code page conversion or the like.
 >
 >
 >
 > Not knowing knitr but Sweave I cobbled the figures manually and ran the
 > sweave file to produce the latex file.
 >
 > Latex was consistently stopping at the \caption and \ref functions
 >
 > I tried to see what was happening I added hyperref & when I copied the
 > text
 > to hyperref ?latex bailed up
 >
 >
 >
 > I tried a minimal latex file without problems
 >
 >
 >
 > I put the \title etc in the preamble. Some compilers need this
 >
 >
 >
 > Duncan
 >
 >
 >
 > From: Daniel Haugstvedt [mailto:daniel.haugstvedt at gmail.com]
 > Sent: Monday, 23 December 2013 20:10
 > To: Duncan Mackay
 > Cc: John Kane; R
 > Subject: Re: [R] Knitr, ggplot and consistent fonts
 >
 >
 >
 > I am really sorry for posting a non-working example. It is running when I
 > cut the code from my previous mail into a clean session in RStudio (OSX).
 > However, I suspect that you are right. I did cut and paste some code from
 > a
 > forum yesterday which had characters that had to be replaced. I gave
 > emacs a
 > try, but could not find the problem there either.
 >
 >
 >
 > The code below was pasted though textEdit and converted to plain text. I
 > hope this takes care of any embedded characters.
 >
 >
 >
 > \documentclass{article}
 >
 > \begin{document}
 >
 >
 >
 > <<setup, include=FALSE, cache=FALSE>>=
 >
 > library(knitr)
 >
 > library(ggplot2)
 >
 > @
 >
 >
 >
 > \title{Knitr and ggplot2}
 >
 > \author{Daniel Haugstvedt}
 >
 >
 >
 > \maketitle
 >
 >
 >
 > There are four plots in this article. Figure \ref{fig:plot-figHeight}
 > uses
 >
 > the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
 >
 > used both fig.height=2.5 and fig.width=3. The later option makes the font
 >
 > too big.
 >
 >
 >
 > An alternative approach is used in Figures ?\ref{fig:plot-figOutWidthBig}
 > and
 >
 > ?\ref{fig:plot-figOutWidthSmall}. There the argument out.width is set to
 >
 > ?12 and 8 cm respectively. This stops the problem of excessively large
 > fonts
 >
 > ?for figures with smaller width, but there is still no consistency
 >
 > ?across plots in terms o font size.
 >
 >
 >
 > <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot with
 > no
 > fig.width argument", results='hide', fig.pos='ht'>>=
 >
 > df = data.frame(x = rnorm(100), y = 1:100)
 >
 > ggplot(df, aes(x = x)) +
 >
 > ? geom_histogram(aes(y = ..density..),
 >
 > ? ? ? ? ? ? ? ? ?binwidth = 1, colour = "black", fill = "white") +
 >
 > ? xlab("Improvement, %") +
 >
 > ? ylab("Density") +
 >
 > ? theme_classic()
 >
 > @
 >
 >
 >
 > <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
 > fig.cap="Density
 > plot with fig.width=3", fig.pos='ht'>>=
 >
 > ggplot(df, aes(x = x)) +
 >
 > ? geom_histogram(aes(y = ..density..),
 >
 > ? ? ? ? ? ? ? ? ?binwidth = 1, colour = "black", fill = "white") +
 >
 > ? xlab("Improvement, %") +
 >
 > ? ylab("Density") +
 >
 > ? theme_classic()
 >
 > @
 >
 >
 >
 > <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
 > fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
 >
 > ggplot(df, aes(x = x)) +
 >
 > ? geom_histogram(aes(y = ..density..),
 >
 > ? ? ? ? ? ? ? ? ?binwidth = 1, colour = "black", fill = "white") +
 >
 > ? xlab("Improvement, %") +
 >
 > ? ylab("Density") +
 >
 > ? theme_classic()
 >
 > @
 >
 >
 >
 > <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width = "8cm",
 > fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
 >
 > ggplot(df, aes(x = x)) +
 >
 > ? geom_histogram(aes(y = ..density..),
 >
 > ? ? ? ? ? ? ? ? ?binwidth = 1, colour = "black", fill = "white") +
 >
 > ? xlab("Improvement, %") +
 >
 > ? ylab("Density") +
 >
 > ? theme_classic()
 >
 > @
 >
 >
 >
 > \end{document}
 >
 >
 >
 >
 >
 >
 >
 >
 >
 >
 >
 > On Sun, Dec 22, 2013 at 11:59 PM, Duncan Mackay <dulcalma at bigpond.com>
 > wrote:
 >
 > Hi Daniel
 > I tried it in Sweave after modifying it for Sweave and a similar thing
 > for
 > Latex but R crashed.
 >
 > I think there is an embedded character/s before the first chunk and in
 > the
 > first chunk.
 >
 > Duncan
 >
 > Duncan Mackay
 > Department of Agronomy and Soil Science
 > University of New England
 > Armidale NSW 2351
 > Email: home: mackay at northnet.com.au
 >
 >
 > -----Original Message-----
 > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
 > On
 > Behalf Of John Kane
 > Sent: Monday, 23 December 2013 04:19
 > To: Daniel Haugstvedt; r-help at r-project.org
 > Subject: Re: [R] Knitr, ggplot and consistent fonts
 >
 > Hi Daniel,
 >
 > For some reason I cannot get your example to work. The problem is in the
 > code chunk but I have no idea what is happening. The code is running
 > perfectly in R, itself but LaTeX seems to be choking when it hits the
 > first
 > ggplot statement, that is the one in <<plot-figHeight>>=
 >
 > The message I am getting is: "Missing $ inserted <inserted text> $
 > ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not enough to
 > figure out the problem.
 >
 > I tried stripping out most of the LaTeX specific verbiage in the code
 > chunk
 > and running the code in LyX which I use rather than plain vanilla LaTeX
 > and
 > I still cannot get it to work. It is almost as if there is some hidden
 > character in the in that piece of code since I can duplicate the code
 > myself
 > and I even pasted in most of the geom_histogram code into my code chunk
 > and
 > it runs.
 >
 > John Kane
 > Kingston ON Canada
 >
 >
 >> -----Original Message-----
 >> From: daniel.haugstvedt at gmail.com
 >> Sent: Sun, 22 Dec 2013 12:42:50 +0100
 >> To: r-help at r-project.org
 >> Subject: [R] Knitr, ggplot and consistent fonts
 >>
 >> Dear R-help
 >>
 >> I am using Knitr and ggplot to draft an article and have now started
 >> to improve on the layout and graphics. So far I have not been able to
 >> maintain the same font size for labels in all my figures.
 >>
 >> My goal is to be able to change the width of the figures while
 >> maintaining the same font. This works for the height parameter
 >> (example not included).
 >>
 >> In the true document I also use tikz, but the problem can be
 >> reproduced without it.
 >>
 >> I know the question is very specific, but my understanding is that
 >> this combination of packages ?is common. (They are really great. Keep
 >> up the good work.) ?There has to be others facing the same problem and
 >> someone must have found a nice solution.
 >>
 >> Additional attempts from my side which failed are not included in the
 >> example. I have tested the Google results i could find without any luck.
 >>
 >> Cheers
 >> Daniel
 >>
 >> PS. I know the example plots could have been smaller, but they just
 >> became too ugly for me
 >>
 >>
 >> \documentclass{article}
 >> \begin{document}
 >>
 >> <<setup, include=FALSE, cache=FALSE>>=
 >> library(knitr)
 >> library(ggplot2)
 >> @
 >>
 >> \title{Knitr and ggplot2}
 >> \author{Daniel Haugstvedt}
 >>
 >> \maketitle
 >>
 >> There are four plots in this article. Figure \ref{fig:plot-figHeight}
 >> uses the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
 >> used both fig.height=2.5 and fig.width=3. The later option makes the
 >> font too big.
 >>
 >> An alternative approach is used in Figures
 >> \ref{fig:plot-figOutWidthBig} and ?\ref{fig:plot-figOutWidthSmall}.
 >> There the argument out.width is set to
 >> ?12 and 8 cm respectively. This stops the problem of excessively large
 >> fonts ?for figures with smaller width, but there is still no
 >> consistency ?across plots in terms of font size.
 >>
 >> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
 >> with no fig.width argument", fig.pos='ht'>>= df = data.frame(x =
 >> rnorm(100), y = 1:100) ggplot(df, aes(x = x)) +
 >> ? geom_histogram(aes(y = ..density..),
 >> ? ? ? ? ? ? ? ? ?binwidth = 1, colour = "black", fill = "white") +
 >> ? xlab("Improvement, %") +
 >> ? ylab("Density") +
 >> ? theme_classic()
 >> @
 >>
 >> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
 >> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>= ggplot(df,
 >> aes(x = x)) +
 >> ? geom_histogram(aes(y = ..density..),
 >> ? ? ? ? ? ? ? ? ?binwidth = 1, colour = "black", fill = "white") +
 >> ? xlab("Improvement, %") +
 >> ? ylab("Density") +
 >> ? theme_classic()
 >> @
 >>
 >> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
 >> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>= ggplot(df,
 >> aes(x = x)) +
 >> ? geom_histogram(aes(y = ..density..),
 >> ? ? ? ? ? ? ? ? ?binwidth = 1, colour = "black", fill = "white") +
 >> ? xlab("Improvement, %") +
 >> ? ylab("Density") +
 >> ? theme_classic()
 >> @
 >>
 >> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
 >> "8cm", fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
 >> ggplot(df, aes(x = x)) +
 >> ? geom_histogram(aes(y = ..density..),
 >> ? ? ? ? ? ? ? ? ?binwidth = 1, colour = "black", fill = "white") +
 >> ? xlab("Improvement, %") +
 >> ? ylab("Density") +
 >> ? theme_classic()
 >> @
 >>
 >> \end{document}
 >>
 >> ? ? ? [[alternative HTML version deleted]]
 >>
 >> ______________________________________________
 >> R-help at r-project.org mailing list
 >> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 >> PLEASE do read the posting guide
 >> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 >> and provide commented, minimal, self-contained, reproducible code.
 >
 > ____________________________________________________________
 > GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
 > http://www.inbox.com/smileys [http://www.inbox.com/smileys] Works with AIMR, MSNR Messenger, Yahoo!R
 > Messenger, ICQR, Google TalkT and most webmails
 >
 > ______________________________________________
 > R-help at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > and provide commented, minimal, self-contained, reproducible code.
 >
 > ______________________________________________
 > R-help at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > and provide commented, minimal, self-contained, reproducible code.
 >
 >
 >
 > ______________________________________________
 > R-help at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > and provide commented, minimal, self-contained, reproducible code.

 ____________________________________________________________

FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!

 ______________________________________________
 R-help at r-project.org mailing list
 https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From jrkrideau at inbox.com  Mon Dec 23 18:40:48 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 23 Dec 2013 09:40:48 -0800
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <CAGx1TMCYKo2VBx036wTc8YyPYi_43yhY42GVJGN57yy8vtcXHQ@mail.gmail.com>
References: <001c01ceffda$7fa36090$7eea21b0$@bigpond.com>
	<cankvva3sqzk8nxa0kemg=npe2puj+mqnfqsu-7m1kvasn7t2aw@mail.gmail.com>
	<d16683c5446.00000494jrkrideau@inbox.com>
	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>
	<cankvva3ey2ruu-2cojsvk2uqhxjusdyg_d-nrcedbxxwzp6z1a@mail.gmail.com>
	<dd14b2aca2b.00000424jrkrideau@inbox.com>
Message-ID: <DDA31CF559B.00000528jrkrideau@inbox.com>

Thanks Richard.  I did not realise such a function existed.

Assuming I am using it  correctly I do get an error though not where I was expecting it.  Anyway the code below returns an error

library(tools)
showNonASCII("ggplot(df, aes(x = x)) + geom_histogram(aes(y = ..density..)), binwidth = 1, colour = "black", fill = "white")")

Results
Error: unexpected symbol in:
"showNonASCII("ggplot(df, aes(x = x)) + geom_histogram(aes(y = ..density..)), binwidth = 1, colour = "black"



John Kane
Kingston ON Canada


> -----Original Message-----
> From: rmh at temple.edu
> Sent: Mon, 23 Dec 2013 11:44:42 -0500
> To: jrkrideau at inbox.com
> Subject: Re: [R] Knitr, ggplot and consistent fonts
> 
> If the problem seems to be non-ASCII characters, then the first
> investigation
> step is to use the R functions
> 
> ?tools::showNonASCII
> ?tools::showNonASCIIfile
> 
> On Mon, Dec 23, 2013 at 11:37 AM, John Kane <jrkrideau at inbox.com> wrote:
>> Same result here with the same error message mentioned in my first post.
>> I tried it in Texmaker which is my usual Latex editor, not that I do
>> much in Latex, and then tried it in RStudio and it is still choking.
>> 
>> Interestingly EMACS will process it and produce a pdf but it simply
>> produces.  It also provides this warning: : Latex Warning; Reference
>> 'fig:plot-figheight' undefined on page 2 on input line 14.
>> 
>> It seems to repeat the same message for each of the other figures.
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: dulcalma at bigpond.com
>>> Sent: Mon, 23 Dec 2013 22:28:33 +1000
>>> To: daniel.haugstvedt at gmail.com, r-help at r-project.org
>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>> 
>>> Hi Dan
>>> 
>>> 
>>> 
>>> I think you still have problems with embedded characters or some
>>> problems
>>> in
>>> char code page conversion or the like.
>>> 
>>> 
>>> 
>>> Not knowing knitr but Sweave I cobbled the figures manually and ran the
>>> sweave file to produce the latex file.
>>> 
>>> Latex was consistently stopping at the \caption and \ref functions
>>> 
>>> I tried to see what was happening I added hyperref & when I copied the
>>> text
>>> to hyperref  latex bailed up
>>> 
>>> 
>>> 
>>> I tried a minimal latex file without problems
>>> 
>>> 
>>> 
>>> I put the \title etc in the preamble. Some compilers need this
>>> 
>>> 
>>> 
>>> Duncan
>>> 
>>> 
>>> 
>>> From: Daniel Haugstvedt [mailto:daniel.haugstvedt at gmail.com]
>>> Sent: Monday, 23 December 2013 20:10
>>> To: Duncan Mackay
>>> Cc: John Kane; R
>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>> 
>>> 
>>> 
>>> I am really sorry for posting a non-working example. It is running when
>>> I
>>> cut the code from my previous mail into a clean session in RStudio
>>> (OSX).
>>> However, I suspect that you are right. I did cut and paste some code
>>> from
>>> a
>>> forum yesterday which had characters that had to be replaced. I gave
>>> emacs a
>>> try, but could not find the problem there either.
>>> 
>>> 
>>> 
>>> The code below was pasted though textEdit and converted to plain text.
>>> I
>>> hope this takes care of any embedded characters.
>>> 
>>> 
>>> 
>>> \documentclass{article}
>>> 
>>> \begin{document}
>>> 
>>> 
>>> 
>>> <<setup, include=FALSE, cache=FALSE>>=
>>> 
>>> library(knitr)
>>> 
>>> library(ggplot2)
>>> 
>>> @
>>> 
>>> 
>>> 
>>> \title{Knitr and ggplot2}
>>> 
>>> \author{Daniel Haugstvedt}
>>> 
>>> 
>>> 
>>> \maketitle
>>> 
>>> 
>>> 
>>> There are four plots in this article. Figure \ref{fig:plot-figHeight}
>>> uses
>>> 
>>> the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>>> 
>>> used both fig.height=2.5 and fig.width=3. The later option makes the
>>> font
>>> 
>>> too big.
>>> 
>>> 
>>> 
>>> An alternative approach is used in Figures
>>> \ref{fig:plot-figOutWidthBig}
>>> and
>>> 
>>>  \ref{fig:plot-figOutWidthSmall}. There the argument out.width is set
>>> to
>>> 
>>>  12 and 8 cm respectively. This stops the problem of excessively large
>>> fonts
>>> 
>>>  for figures with smaller width, but there is still no consistency
>>> 
>>>  across plots in terms o font size.
>>> 
>>> 
>>> 
>>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>>> with
>>> no
>>> fig.width argument", results='hide', fig.pos='ht'>>=
>>> 
>>> df = data.frame(x = rnorm(100), y = 1:100)
>>> 
>>> ggplot(df, aes(x = x)) +
>>> 
>>>   geom_histogram(aes(y = ..density..),
>>> 
>>>                  binwidth = 1, colour = "black", fill = "white") +
>>> 
>>>   xlab("Improvement, %") +
>>> 
>>>   ylab("Density") +
>>> 
>>>   theme_classic()
>>> 
>>> @
>>> 
>>> 
>>> 
>>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>>> fig.cap="Density
>>> plot with fig.width=3", fig.pos='ht'>>=
>>> 
>>> ggplot(df, aes(x = x)) +
>>> 
>>>   geom_histogram(aes(y = ..density..),
>>> 
>>>                  binwidth = 1, colour = "black", fill = "white") +
>>> 
>>>   xlab("Improvement, %") +
>>> 
>>>   ylab("Density") +
>>> 
>>>   theme_classic()
>>> 
>>> @
>>> 
>>> 
>>> 
>>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
>>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
>>> 
>>> ggplot(df, aes(x = x)) +
>>> 
>>>   geom_histogram(aes(y = ..density..),
>>> 
>>>                  binwidth = 1, colour = "black", fill = "white") +
>>> 
>>>   xlab("Improvement, %") +
>>> 
>>>   ylab("Density") +
>>> 
>>>   theme_classic()
>>> 
>>> @
>>> 
>>> 
>>> 
>>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width = "8cm",
>>> fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>> 
>>> ggplot(df, aes(x = x)) +
>>> 
>>>   geom_histogram(aes(y = ..density..),
>>> 
>>>                  binwidth = 1, colour = "black", fill = "white") +
>>> 
>>>   xlab("Improvement, %") +
>>> 
>>>   ylab("Density") +
>>> 
>>>   theme_classic()
>>> 
>>> @
>>> 
>>> 
>>> 
>>> \end{document}
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> On Sun, Dec 22, 2013 at 11:59 PM, Duncan Mackay <dulcalma at bigpond.com>
>>> wrote:
>>> 
>>> Hi Daniel
>>> I tried it in Sweave after modifying it for Sweave and a similar thing
>>> for
>>> Latex but R crashed.
>>> 
>>> I think there is an embedded character/s before the first chunk and in
>>> the
>>> first chunk.
>>> 
>>> Duncan
>>> 
>>> Duncan Mackay
>>> Department of Agronomy and Soil Science
>>> University of New England
>>> Armidale NSW 2351
>>> Email: home: mackay at northnet.com.au
>>> 
>>> 
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org
>>> [mailto:r-help-bounces at r-project.org]
>>> On
>>> Behalf Of John Kane
>>> Sent: Monday, 23 December 2013 04:19
>>> To: Daniel Haugstvedt; r-help at r-project.org
>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>> 
>>> Hi Daniel,
>>> 
>>> For some reason I cannot get your example to work. The problem is in
>>> the
>>> code chunk but I have no idea what is happening. The code is running
>>> perfectly in R, itself but LaTeX seems to be choking when it hits the
>>> first
>>> ggplot statement, that is the one in <<plot-figHeight>>=
>>> 
>>> The message I am getting is: "Missing $ inserted <inserted text> $
>>> ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not enough
>>> to
>>> figure out the problem.
>>> 
>>> I tried stripping out most of the LaTeX specific verbiage in the code
>>> chunk
>>> and running the code in LyX which I use rather than plain vanilla LaTeX
>>> and
>>> I still cannot get it to work. It is almost as if there is some hidden
>>> character in the in that piece of code since I can duplicate the code
>>> myself
>>> and I even pasted in most of the geom_histogram code into my code chunk
>>> and
>>> it runs.
>>> 
>>> John Kane
>>> Kingston ON Canada
>>> 
>>> 
>>>> -----Original Message-----
>>>> From: daniel.haugstvedt at gmail.com
>>>> Sent: Sun, 22 Dec 2013 12:42:50 +0100
>>>> To: r-help at r-project.org
>>>> Subject: [R] Knitr, ggplot and consistent fonts
>>>> 
>>>> Dear R-help
>>>> 
>>>> I am using Knitr and ggplot to draft an article and have now started
>>>> to improve on the layout and graphics. So far I have not been able to
>>>> maintain the same font size for labels in all my figures.
>>>> 
>>>> My goal is to be able to change the width of the figures while
>>>> maintaining the same font. This works for the height parameter
>>>> (example not included).
>>>> 
>>>> In the true document I also use tikz, but the problem can be
>>>> reproduced without it.
>>>> 
>>>> I know the question is very specific, but my understanding is that
>>>> this combination of packages  is common. (They are really great. Keep
>>>> up the good work.)  There has to be others facing the same problem and
>>>> someone must have found a nice solution.
>>>> 
>>>> Additional attempts from my side which failed are not included in the
>>>> example. I have tested the Google results i could find without any
>>>> luck.
>>>> 
>>>> Cheers
>>>> Daniel
>>>> 
>>>> PS. I know the example plots could have been smaller, but they just
>>>> became too ugly for me
>>>> 
>>>> 
>>>> \documentclass{article}
>>>> \begin{document}
>>>> 
>>>> <<setup, include=FALSE, cache=FALSE>>=
>>>> library(knitr)
>>>> library(ggplot2)
>>>> @
>>>> 
>>>> \title{Knitr and ggplot2}
>>>> \author{Daniel Haugstvedt}
>>>> 
>>>> \maketitle
>>>> 
>>>> There are four plots in this article. Figure \ref{fig:plot-figHeight}
>>>> uses the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>>>> used both fig.height=2.5 and fig.width=3. The later option makes the
>>>> font too big.
>>>> 
>>>> An alternative approach is used in Figures
>>>> \ref{fig:plot-figOutWidthBig} and  \ref{fig:plot-figOutWidthSmall}.
>>>> There the argument out.width is set to
>>>>  12 and 8 cm respectively. This stops the problem of excessively large
>>>> fonts  for figures with smaller width, but there is still no
>>>> consistency  across plots in terms of font size.
>>>> 
>>>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>>>> with no fig.width argument", fig.pos='ht'>>= df = data.frame(x =
>>>> rnorm(100), y = 1:100) ggplot(df, aes(x = x)) +
>>>>   geom_histogram(aes(y = ..density..),
>>>>                  binwidth = 1, colour = "black", fill = "white") +
>>>>   xlab("Improvement, %") +
>>>>   ylab("Density") +
>>>>   theme_classic()
>>>> @
>>>> 
>>>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>>>> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>= ggplot(df,
>>>> aes(x = x)) +
>>>>   geom_histogram(aes(y = ..density..),
>>>>                  binwidth = 1, colour = "black", fill = "white") +
>>>>   xlab("Improvement, %") +
>>>>   ylab("Density") +
>>>>   theme_classic()
>>>> @
>>>> 
>>>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
>>>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>= ggplot(df,
>>>> aes(x = x)) +
>>>>   geom_histogram(aes(y = ..density..),
>>>>                  binwidth = 1, colour = "black", fill = "white") +
>>>>   xlab("Improvement, %") +
>>>>   ylab("Density") +
>>>>   theme_classic()
>>>> @
>>>> 
>>>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
>>>> "8cm", fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>>> ggplot(df, aes(x = x)) +
>>>>   geom_histogram(aes(y = ..density..),
>>>>                  binwidth = 1, colour = "black", fill = "white") +
>>>>   xlab("Improvement, %") +
>>>>   ylab("Density") +
>>>>   theme_classic()
>>>> @
>>>> 
>>>> \end{document}
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ____________________________________________________________
>>> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
>>> http://www.inbox.com/smileys Works with AIMR, MSNR Messenger, Yahoo!R
>>> Messenger, ICQR, Google TalkT and most webmails
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
>> your desktop!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From murdoch.duncan at gmail.com  Mon Dec 23 18:51:43 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 23 Dec 2013 12:51:43 -0500
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <DDA31CF559B.00000528jrkrideau@inbox.com>
References: <001c01ceffda$7fa36090$7eea21b0$@bigpond.com>	<cankvva3sqzk8nxa0kemg=npe2puj+mqnfqsu-7m1kvasn7t2aw@mail.gmail.com>	<d16683c5446.00000494jrkrideau@inbox.com>	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>	<cankvva3ey2ruu-2cojsvk2uqhxjusdyg_d-nrcedbxxwzp6z1a@mail.gmail.com>	<dd14b2aca2b.00000424jrkrideau@inbox.com>
	<DDA31CF559B.00000528jrkrideau@inbox.com>
Message-ID: <52B8782F.50806@gmail.com>

On 13-12-23 12:40 PM, John Kane wrote:
> Thanks Richard.  I did not realise such a function existed.
>
> Assuming I am using it  correctly I do get an error though not where I was expecting it.  Anyway the code below returns an error
>
> library(tools)
> showNonASCII("ggplot(df, aes(x = x)) + geom_histogram(aes(y = ..density..)), binwidth = 1, colour = "black", fill = "white")")
>
> Results
> Error: unexpected symbol in:
> "showNonASCII("ggplot(df, aes(x = x)) + geom_histogram(aes(y = ..density..)), binwidth = 1, colour = "black"

You get that error because you're using double quotes around a string 
containing double quotes, and not escaping them.  With that string, 
using single quotes on the outside should be fine:

  showNonASCII('ggplot(df, aes(x = x)) + geom_histogram(aes(y = 
..density..)), binwidth = 1, colour = "black", fill = "white")')

Duncan Murdoch
>
>
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: rmh at temple.edu
>> Sent: Mon, 23 Dec 2013 11:44:42 -0500
>> To: jrkrideau at inbox.com
>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>
>> If the problem seems to be non-ASCII characters, then the first
>> investigation
>> step is to use the R functions
>>
>> ?tools::showNonASCII
>> ?tools::showNonASCIIfile
>>
>> On Mon, Dec 23, 2013 at 11:37 AM, John Kane <jrkrideau at inbox.com> wrote:
>>> Same result here with the same error message mentioned in my first post.
>>> I tried it in Texmaker which is my usual Latex editor, not that I do
>>> much in Latex, and then tried it in RStudio and it is still choking.
>>>
>>> Interestingly EMACS will process it and produce a pdf but it simply
>>> produces.  It also provides this warning: : Latex Warning; Reference
>>> 'fig:plot-figheight' undefined on page 2 on input line 14.
>>>
>>> It seems to repeat the same message for each of the other figures.
>>>
>>> John Kane
>>> Kingston ON Canada
>>>
>>>
>>>> -----Original Message-----
>>>> From: dulcalma at bigpond.com
>>>> Sent: Mon, 23 Dec 2013 22:28:33 +1000
>>>> To: daniel.haugstvedt at gmail.com, r-help at r-project.org
>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>
>>>> Hi Dan
>>>>
>>>>
>>>>
>>>> I think you still have problems with embedded characters or some
>>>> problems
>>>> in
>>>> char code page conversion or the like.
>>>>
>>>>
>>>>
>>>> Not knowing knitr but Sweave I cobbled the figures manually and ran the
>>>> sweave file to produce the latex file.
>>>>
>>>> Latex was consistently stopping at the \caption and \ref functions
>>>>
>>>> I tried to see what was happening I added hyperref & when I copied the
>>>> text
>>>> to hyperref  latex bailed up
>>>>
>>>>
>>>>
>>>> I tried a minimal latex file without problems
>>>>
>>>>
>>>>
>>>> I put the \title etc in the preamble. Some compilers need this
>>>>
>>>>
>>>>
>>>> Duncan
>>>>
>>>>
>>>>
>>>> From: Daniel Haugstvedt [mailto:daniel.haugstvedt at gmail.com]
>>>> Sent: Monday, 23 December 2013 20:10
>>>> To: Duncan Mackay
>>>> Cc: John Kane; R
>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>
>>>>
>>>>
>>>> I am really sorry for posting a non-working example. It is running when
>>>> I
>>>> cut the code from my previous mail into a clean session in RStudio
>>>> (OSX).
>>>> However, I suspect that you are right. I did cut and paste some code
>>>> from
>>>> a
>>>> forum yesterday which had characters that had to be replaced. I gave
>>>> emacs a
>>>> try, but could not find the problem there either.
>>>>
>>>>
>>>>
>>>> The code below was pasted though textEdit and converted to plain text.
>>>> I
>>>> hope this takes care of any embedded characters.
>>>>
>>>>
>>>>
>>>> \documentclass{article}
>>>>
>>>> \begin{document}
>>>>
>>>>
>>>>
>>>> <<setup, include=FALSE, cache=FALSE>>=
>>>>
>>>> library(knitr)
>>>>
>>>> library(ggplot2)
>>>>
>>>> @
>>>>
>>>>
>>>>
>>>> \title{Knitr and ggplot2}
>>>>
>>>> \author{Daniel Haugstvedt}
>>>>
>>>>
>>>>
>>>> \maketitle
>>>>
>>>>
>>>>
>>>> There are four plots in this article. Figure \ref{fig:plot-figHeight}
>>>> uses
>>>>
>>>> the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>>>>
>>>> used both fig.height=2.5 and fig.width=3. The later option makes the
>>>> font
>>>>
>>>> too big.
>>>>
>>>>
>>>>
>>>> An alternative approach is used in Figures
>>>> \ref{fig:plot-figOutWidthBig}
>>>> and
>>>>
>>>>   \ref{fig:plot-figOutWidthSmall}. There the argument out.width is set
>>>> to
>>>>
>>>>   12 and 8 cm respectively. This stops the problem of excessively large
>>>> fonts
>>>>
>>>>   for figures with smaller width, but there is still no consistency
>>>>
>>>>   across plots in terms o font size.
>>>>
>>>>
>>>>
>>>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>>>> with
>>>> no
>>>> fig.width argument", results='hide', fig.pos='ht'>>=
>>>>
>>>> df = data.frame(x = rnorm(100), y = 1:100)
>>>>
>>>> ggplot(df, aes(x = x)) +
>>>>
>>>>    geom_histogram(aes(y = ..density..),
>>>>
>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>
>>>>    xlab("Improvement, %") +
>>>>
>>>>    ylab("Density") +
>>>>
>>>>    theme_classic()
>>>>
>>>> @
>>>>
>>>>
>>>>
>>>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>>>> fig.cap="Density
>>>> plot with fig.width=3", fig.pos='ht'>>=
>>>>
>>>> ggplot(df, aes(x = x)) +
>>>>
>>>>    geom_histogram(aes(y = ..density..),
>>>>
>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>
>>>>    xlab("Improvement, %") +
>>>>
>>>>    ylab("Density") +
>>>>
>>>>    theme_classic()
>>>>
>>>> @
>>>>
>>>>
>>>>
>>>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
>>>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
>>>>
>>>> ggplot(df, aes(x = x)) +
>>>>
>>>>    geom_histogram(aes(y = ..density..),
>>>>
>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>
>>>>    xlab("Improvement, %") +
>>>>
>>>>    ylab("Density") +
>>>>
>>>>    theme_classic()
>>>>
>>>> @
>>>>
>>>>
>>>>
>>>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width = "8cm",
>>>> fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>>>
>>>> ggplot(df, aes(x = x)) +
>>>>
>>>>    geom_histogram(aes(y = ..density..),
>>>>
>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>
>>>>    xlab("Improvement, %") +
>>>>
>>>>    ylab("Density") +
>>>>
>>>>    theme_classic()
>>>>
>>>> @
>>>>
>>>>
>>>>
>>>> \end{document}
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On Sun, Dec 22, 2013 at 11:59 PM, Duncan Mackay <dulcalma at bigpond.com>
>>>> wrote:
>>>>
>>>> Hi Daniel
>>>> I tried it in Sweave after modifying it for Sweave and a similar thing
>>>> for
>>>> Latex but R crashed.
>>>>
>>>> I think there is an embedded character/s before the first chunk and in
>>>> the
>>>> first chunk.
>>>>
>>>> Duncan
>>>>
>>>> Duncan Mackay
>>>> Department of Agronomy and Soil Science
>>>> University of New England
>>>> Armidale NSW 2351
>>>> Email: home: mackay at northnet.com.au
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: r-help-bounces at r-project.org
>>>> [mailto:r-help-bounces at r-project.org]
>>>> On
>>>> Behalf Of John Kane
>>>> Sent: Monday, 23 December 2013 04:19
>>>> To: Daniel Haugstvedt; r-help at r-project.org
>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>
>>>> Hi Daniel,
>>>>
>>>> For some reason I cannot get your example to work. The problem is in
>>>> the
>>>> code chunk but I have no idea what is happening. The code is running
>>>> perfectly in R, itself but LaTeX seems to be choking when it hits the
>>>> first
>>>> ggplot statement, that is the one in <<plot-figHeight>>=
>>>>
>>>> The message I am getting is: "Missing $ inserted <inserted text> $
>>>> ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not enough
>>>> to
>>>> figure out the problem.
>>>>
>>>> I tried stripping out most of the LaTeX specific verbiage in the code
>>>> chunk
>>>> and running the code in LyX which I use rather than plain vanilla LaTeX
>>>> and
>>>> I still cannot get it to work. It is almost as if there is some hidden
>>>> character in the in that piece of code since I can duplicate the code
>>>> myself
>>>> and I even pasted in most of the geom_histogram code into my code chunk
>>>> and
>>>> it runs.
>>>>
>>>> John Kane
>>>> Kingston ON Canada
>>>>
>>>>
>>>>> -----Original Message-----
>>>>> From: daniel.haugstvedt at gmail.com
>>>>> Sent: Sun, 22 Dec 2013 12:42:50 +0100
>>>>> To: r-help at r-project.org
>>>>> Subject: [R] Knitr, ggplot and consistent fonts
>>>>>
>>>>> Dear R-help
>>>>>
>>>>> I am using Knitr and ggplot to draft an article and have now started
>>>>> to improve on the layout and graphics. So far I have not been able to
>>>>> maintain the same font size for labels in all my figures.
>>>>>
>>>>> My goal is to be able to change the width of the figures while
>>>>> maintaining the same font. This works for the height parameter
>>>>> (example not included).
>>>>>
>>>>> In the true document I also use tikz, but the problem can be
>>>>> reproduced without it.
>>>>>
>>>>> I know the question is very specific, but my understanding is that
>>>>> this combination of packages  is common. (They are really great. Keep
>>>>> up the good work.)  There has to be others facing the same problem and
>>>>> someone must have found a nice solution.
>>>>>
>>>>> Additional attempts from my side which failed are not included in the
>>>>> example. I have tested the Google results i could find without any
>>>>> luck.
>>>>>
>>>>> Cheers
>>>>> Daniel
>>>>>
>>>>> PS. I know the example plots could have been smaller, but they just
>>>>> became too ugly for me
>>>>>
>>>>>
>>>>> \documentclass{article}
>>>>> \begin{document}
>>>>>
>>>>> <<setup, include=FALSE, cache=FALSE>>=
>>>>> library(knitr)
>>>>> library(ggplot2)
>>>>> @
>>>>>
>>>>> \title{Knitr and ggplot2}
>>>>> \author{Daniel Haugstvedt}
>>>>>
>>>>> \maketitle
>>>>>
>>>>> There are four plots in this article. Figure \ref{fig:plot-figHeight}
>>>>> uses the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>>>>> used both fig.height=2.5 and fig.width=3. The later option makes the
>>>>> font too big.
>>>>>
>>>>> An alternative approach is used in Figures
>>>>> \ref{fig:plot-figOutWidthBig} and  \ref{fig:plot-figOutWidthSmall}.
>>>>> There the argument out.width is set to
>>>>>   12 and 8 cm respectively. This stops the problem of excessively large
>>>>> fonts  for figures with smaller width, but there is still no
>>>>> consistency  across plots in terms of font size.
>>>>>
>>>>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>>>>> with no fig.width argument", fig.pos='ht'>>= df = data.frame(x =
>>>>> rnorm(100), y = 1:100) ggplot(df, aes(x = x)) +
>>>>>    geom_histogram(aes(y = ..density..),
>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>>    xlab("Improvement, %") +
>>>>>    ylab("Density") +
>>>>>    theme_classic()
>>>>> @
>>>>>
>>>>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>>>>> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>= ggplot(df,
>>>>> aes(x = x)) +
>>>>>    geom_histogram(aes(y = ..density..),
>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>>    xlab("Improvement, %") +
>>>>>    ylab("Density") +
>>>>>    theme_classic()
>>>>> @
>>>>>
>>>>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
>>>>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>= ggplot(df,
>>>>> aes(x = x)) +
>>>>>    geom_histogram(aes(y = ..density..),
>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>>    xlab("Improvement, %") +
>>>>>    ylab("Density") +
>>>>>    theme_classic()
>>>>> @
>>>>>
>>>>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
>>>>> "8cm", fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>>>> ggplot(df, aes(x = x)) +
>>>>>    geom_histogram(aes(y = ..density..),
>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>>    xlab("Improvement, %") +
>>>>>    ylab("Density") +
>>>>>    theme_classic()
>>>>> @
>>>>>
>>>>> \end{document}
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ____________________________________________________________
>>>> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
>>>> http://www.inbox.com/smileys Works with AIMR, MSNR Messenger, Yahoo!R
>>>> Messenger, ICQR, Google TalkT and most webmails
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ____________________________________________________________
>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
>>> your desktop!
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at inbox.com  Mon Dec 23 19:07:51 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 23 Dec 2013 10:07:51 -0800
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <52B8782F.50806@gmail.com>
References: <dda31cf559b.00000528jrkrideau@inbox.com>
	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>
	<cankvva3sqzk8nxa0kemg=npe2puj+mqnfqsu-7m1kvasn7t2aw@mail.gmail.com>
	<d16683c5446.00000494jrkrideau@inbox.com>
	<cankvva3ey2ruu-2cojsvk2uqhxjusdyg_d-nrcedbxxwzp6z1a@mail.gmail.com>
	<001c01ceffda$7fa36090$7eea21b0$@bigpond.com>
	<dd14b2aca2b.00000424jrkrideau@inbox.com>
Message-ID: <DDDF93FC937.00000595jrkrideau@inbox.com>

Thanks  Duncan.  
I had the feeling I was doing something wrong but did not realise it was that stupid.

showNonASCII('ggplot(df, aes(x = x)) + geom_histogram(aes(y = ..density..)),
                 binwidth = 1, colour = "black", fill = "white")')

now runs and does what the help page seems to imply: Nothing.

From the showNonASCII help page:
"The elements of x containing non-ASCII characters will be returned invisibly. "

One gets a result one does not see?  Does one have to explicitly capture the result somehow?  I really have not the faintest idea of what the example from the help page is doing.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: murdoch.duncan at gmail.com
> Sent: Mon, 23 Dec 2013 12:51:43 -0500
> To: jrkrideau at inbox.com, rmh at temple.edu
> Subject: Re: [R] Knitr, ggplot and consistent fonts
> 
> On 13-12-23 12:40 PM, John Kane wrote:
>> Thanks Richard.  I did not realise such a function existed.
>> 
>> Assuming I am using it  correctly I do get an error though not where I
>> was expecting it.  Anyway the code below returns an error
>> 
>> library(tools)
>> showNonASCII("ggplot(df, aes(x = x)) + geom_histogram(aes(y =
>> ..density..)), binwidth = 1, colour = "black", fill = "white")")
>> 
>> Results
>> Error: unexpected symbol in:
>> "showNonASCII("ggplot(df, aes(x = x)) + geom_histogram(aes(y =
>> ..density..)), binwidth = 1, colour = "black"
> 
> You get that error because you're using double quotes around a string
> containing double quotes, and not escaping them.  With that string,
> using single quotes on the outside should be fine:
> 
>   showNonASCII('ggplot(df, aes(x = x)) + geom_histogram(aes(y =
> ..density..)), binwidth = 1, colour = "black", fill = "white")')
> 
> Duncan Murdoch
>> 
>> 
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: rmh at temple.edu
>>> Sent: Mon, 23 Dec 2013 11:44:42 -0500
>>> To: jrkrideau at inbox.com
>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>> 
>>> If the problem seems to be non-ASCII characters, then the first
>>> investigation
>>> step is to use the R functions
>>> 
>>> ?tools::showNonASCII
>>> ?tools::showNonASCIIfile
>>> 
>>> On Mon, Dec 23, 2013 at 11:37 AM, John Kane <jrkrideau at inbox.com>
>>> wrote:
>>>> Same result here with the same error message mentioned in my first
>>>> post.
>>>> I tried it in Texmaker which is my usual Latex editor, not that I do
>>>> much in Latex, and then tried it in RStudio and it is still choking.
>>>> 
>>>> Interestingly EMACS will process it and produce a pdf but it simply
>>>> produces.  It also provides this warning: : Latex Warning; Reference
>>>> 'fig:plot-figheight' undefined on page 2 on input line 14.
>>>> 
>>>> It seems to repeat the same message for each of the other figures.
>>>> 
>>>> John Kane
>>>> Kingston ON Canada
>>>> 
>>>> 
>>>>> -----Original Message-----
>>>>> From: dulcalma at bigpond.com
>>>>> Sent: Mon, 23 Dec 2013 22:28:33 +1000
>>>>> To: daniel.haugstvedt at gmail.com, r-help at r-project.org
>>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>> 
>>>>> Hi Dan
>>>>> 
>>>>> 
>>>>> 
>>>>> I think you still have problems with embedded characters or some
>>>>> problems
>>>>> in
>>>>> char code page conversion or the like.
>>>>> 
>>>>> 
>>>>> 
>>>>> Not knowing knitr but Sweave I cobbled the figures manually and ran
>>>>> the
>>>>> sweave file to produce the latex file.
>>>>> 
>>>>> Latex was consistently stopping at the \caption and \ref functions
>>>>> 
>>>>> I tried to see what was happening I added hyperref & when I copied
>>>>> the
>>>>> text
>>>>> to hyperref  latex bailed up
>>>>> 
>>>>> 
>>>>> 
>>>>> I tried a minimal latex file without problems
>>>>> 
>>>>> 
>>>>> 
>>>>> I put the \title etc in the preamble. Some compilers need this
>>>>> 
>>>>> 
>>>>> 
>>>>> Duncan
>>>>> 
>>>>> 
>>>>> 
>>>>> From: Daniel Haugstvedt [mailto:daniel.haugstvedt at gmail.com]
>>>>> Sent: Monday, 23 December 2013 20:10
>>>>> To: Duncan Mackay
>>>>> Cc: John Kane; R
>>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>> 
>>>>> 
>>>>> 
>>>>> I am really sorry for posting a non-working example. It is running
>>>>> when
>>>>> I
>>>>> cut the code from my previous mail into a clean session in RStudio
>>>>> (OSX).
>>>>> However, I suspect that you are right. I did cut and paste some code
>>>>> from
>>>>> a
>>>>> forum yesterday which had characters that had to be replaced. I gave
>>>>> emacs a
>>>>> try, but could not find the problem there either.
>>>>> 
>>>>> 
>>>>> 
>>>>> The code below was pasted though textEdit and converted to plain
>>>>> text.
>>>>> I
>>>>> hope this takes care of any embedded characters.
>>>>> 
>>>>> 
>>>>> 
>>>>> \documentclass{article}
>>>>> 
>>>>> \begin{document}
>>>>> 
>>>>> 
>>>>> 
>>>>> <<setup, include=FALSE, cache=FALSE>>=
>>>>> 
>>>>> library(knitr)
>>>>> 
>>>>> library(ggplot2)
>>>>> 
>>>>> @
>>>>> 
>>>>> 
>>>>> 
>>>>> \title{Knitr and ggplot2}
>>>>> 
>>>>> \author{Daniel Haugstvedt}
>>>>> 
>>>>> 
>>>>> 
>>>>> \maketitle
>>>>> 
>>>>> 
>>>>> 
>>>>> There are four plots in this article. Figure \ref{fig:plot-figHeight}
>>>>> uses
>>>>> 
>>>>> the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>>>>> 
>>>>> used both fig.height=2.5 and fig.width=3. The later option makes the
>>>>> font
>>>>> 
>>>>> too big.
>>>>> 
>>>>> 
>>>>> 
>>>>> An alternative approach is used in Figures
>>>>> \ref{fig:plot-figOutWidthBig}
>>>>> and
>>>>> 
>>>>>   \ref{fig:plot-figOutWidthSmall}. There the argument out.width is
>>>>> set
>>>>> to
>>>>> 
>>>>>   12 and 8 cm respectively. This stops the problem of excessively
>>>>> large
>>>>> fonts
>>>>> 
>>>>>   for figures with smaller width, but there is still no consistency
>>>>> 
>>>>>   across plots in terms o font size.
>>>>> 
>>>>> 
>>>>> 
>>>>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>>>>> with
>>>>> no
>>>>> fig.width argument", results='hide', fig.pos='ht'>>=
>>>>> 
>>>>> df = data.frame(x = rnorm(100), y = 1:100)
>>>>> 
>>>>> ggplot(df, aes(x = x)) +
>>>>> 
>>>>>    geom_histogram(aes(y = ..density..),
>>>>> 
>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>> 
>>>>>    xlab("Improvement, %") +
>>>>> 
>>>>>    ylab("Density") +
>>>>> 
>>>>>    theme_classic()
>>>>> 
>>>>> @
>>>>> 
>>>>> 
>>>>> 
>>>>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>>>>> fig.cap="Density
>>>>> plot with fig.width=3", fig.pos='ht'>>=
>>>>> 
>>>>> ggplot(df, aes(x = x)) +
>>>>> 
>>>>>    geom_histogram(aes(y = ..density..),
>>>>> 
>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>> 
>>>>>    xlab("Improvement, %") +
>>>>> 
>>>>>    ylab("Density") +
>>>>> 
>>>>>    theme_classic()
>>>>> 
>>>>> @
>>>>> 
>>>>> 
>>>>> 
>>>>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width =
>>>>> "12cm",
>>>>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
>>>>> 
>>>>> ggplot(df, aes(x = x)) +
>>>>> 
>>>>>    geom_histogram(aes(y = ..density..),
>>>>> 
>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>> 
>>>>>    xlab("Improvement, %") +
>>>>> 
>>>>>    ylab("Density") +
>>>>> 
>>>>>    theme_classic()
>>>>> 
>>>>> @
>>>>> 
>>>>> 
>>>>> 
>>>>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
>>>>> "8cm",
>>>>> fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>>>> 
>>>>> ggplot(df, aes(x = x)) +
>>>>> 
>>>>>    geom_histogram(aes(y = ..density..),
>>>>> 
>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>> 
>>>>>    xlab("Improvement, %") +
>>>>> 
>>>>>    ylab("Density") +
>>>>> 
>>>>>    theme_classic()
>>>>> 
>>>>> @
>>>>> 
>>>>> 
>>>>> 
>>>>> \end{document}
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> On Sun, Dec 22, 2013 at 11:59 PM, Duncan Mackay
>>>>> <dulcalma at bigpond.com>
>>>>> wrote:
>>>>> 
>>>>> Hi Daniel
>>>>> I tried it in Sweave after modifying it for Sweave and a similar
>>>>> thing
>>>>> for
>>>>> Latex but R crashed.
>>>>> 
>>>>> I think there is an embedded character/s before the first chunk and
>>>>> in
>>>>> the
>>>>> first chunk.
>>>>> 
>>>>> Duncan
>>>>> 
>>>>> Duncan Mackay
>>>>> Department of Agronomy and Soil Science
>>>>> University of New England
>>>>> Armidale NSW 2351
>>>>> Email: home: mackay at northnet.com.au
>>>>> 
>>>>> 
>>>>> -----Original Message-----
>>>>> From: r-help-bounces at r-project.org
>>>>> [mailto:r-help-bounces at r-project.org]
>>>>> On
>>>>> Behalf Of John Kane
>>>>> Sent: Monday, 23 December 2013 04:19
>>>>> To: Daniel Haugstvedt; r-help at r-project.org
>>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>> 
>>>>> Hi Daniel,
>>>>> 
>>>>> For some reason I cannot get your example to work. The problem is in
>>>>> the
>>>>> code chunk but I have no idea what is happening. The code is running
>>>>> perfectly in R, itself but LaTeX seems to be choking when it hits the
>>>>> first
>>>>> ggplot statement, that is the one in <<plot-figHeight>>=
>>>>> 
>>>>> The message I am getting is: "Missing $ inserted <inserted text> $
>>>>> ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not enough
>>>>> to
>>>>> figure out the problem.
>>>>> 
>>>>> I tried stripping out most of the LaTeX specific verbiage in the code
>>>>> chunk
>>>>> and running the code in LyX which I use rather than plain vanilla
>>>>> LaTeX
>>>>> and
>>>>> I still cannot get it to work. It is almost as if there is some
>>>>> hidden
>>>>> character in the in that piece of code since I can duplicate the code
>>>>> myself
>>>>> and I even pasted in most of the geom_histogram code into my code
>>>>> chunk
>>>>> and
>>>>> it runs.
>>>>> 
>>>>> John Kane
>>>>> Kingston ON Canada
>>>>> 
>>>>> 
>>>>>> -----Original Message-----
>>>>>> From: daniel.haugstvedt at gmail.com
>>>>>> Sent: Sun, 22 Dec 2013 12:42:50 +0100
>>>>>> To: r-help at r-project.org
>>>>>> Subject: [R] Knitr, ggplot and consistent fonts
>>>>>> 
>>>>>> Dear R-help
>>>>>> 
>>>>>> I am using Knitr and ggplot to draft an article and have now started
>>>>>> to improve on the layout and graphics. So far I have not been able
>>>>>> to
>>>>>> maintain the same font size for labels in all my figures.
>>>>>> 
>>>>>> My goal is to be able to change the width of the figures while
>>>>>> maintaining the same font. This works for the height parameter
>>>>>> (example not included).
>>>>>> 
>>>>>> In the true document I also use tikz, but the problem can be
>>>>>> reproduced without it.
>>>>>> 
>>>>>> I know the question is very specific, but my understanding is that
>>>>>> this combination of packages  is common. (They are really great.
>>>>>> Keep
>>>>>> up the good work.)  There has to be others facing the same problem
>>>>>> and
>>>>>> someone must have found a nice solution.
>>>>>> 
>>>>>> Additional attempts from my side which failed are not included in
>>>>>> the
>>>>>> example. I have tested the Google results i could find without any
>>>>>> luck.
>>>>>> 
>>>>>> Cheers
>>>>>> Daniel
>>>>>> 
>>>>>> PS. I know the example plots could have been smaller, but they just
>>>>>> became too ugly for me
>>>>>> 
>>>>>> 
>>>>>> \documentclass{article}
>>>>>> \begin{document}
>>>>>> 
>>>>>> <<setup, include=FALSE, cache=FALSE>>=
>>>>>> library(knitr)
>>>>>> library(ggplot2)
>>>>>> @
>>>>>> 
>>>>>> \title{Knitr and ggplot2}
>>>>>> \author{Daniel Haugstvedt}
>>>>>> 
>>>>>> \maketitle
>>>>>> 
>>>>>> There are four plots in this article. Figure
>>>>>> \ref{fig:plot-figHeight}
>>>>>> uses the argument fig.height=2.5 while Figures
>>>>>> \ref{fig:plot-figWidth}
>>>>>> used both fig.height=2.5 and fig.width=3. The later option makes the
>>>>>> font too big.
>>>>>> 
>>>>>> An alternative approach is used in Figures
>>>>>> \ref{fig:plot-figOutWidthBig} and  \ref{fig:plot-figOutWidthSmall}.
>>>>>> There the argument out.width is set to
>>>>>>   12 and 8 cm respectively. This stops the problem of excessively
>>>>>> large
>>>>>> fonts  for figures with smaller width, but there is still no
>>>>>> consistency  across plots in terms of font size.
>>>>>> 
>>>>>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>>>>>> with no fig.width argument", fig.pos='ht'>>= df = data.frame(x =
>>>>>> rnorm(100), y = 1:100) ggplot(df, aes(x = x)) +
>>>>>>    geom_histogram(aes(y = ..density..),
>>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>>>    xlab("Improvement, %") +
>>>>>>    ylab("Density") +
>>>>>>    theme_classic()
>>>>>> @
>>>>>> 
>>>>>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>>>>>> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>= ggplot(df,
>>>>>> aes(x = x)) +
>>>>>>    geom_histogram(aes(y = ..density..),
>>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>>>    xlab("Improvement, %") +
>>>>>>    ylab("Density") +
>>>>>>    theme_classic()
>>>>>> @
>>>>>> 
>>>>>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width =
>>>>>> "12cm",
>>>>>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
>>>>>> ggplot(df,
>>>>>> aes(x = x)) +
>>>>>>    geom_histogram(aes(y = ..density..),
>>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>>>    xlab("Improvement, %") +
>>>>>>    ylab("Density") +
>>>>>>    theme_classic()
>>>>>> @
>>>>>> 
>>>>>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
>>>>>> "8cm", fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>>>>> ggplot(df, aes(x = x)) +
>>>>>>    geom_histogram(aes(y = ..density..),
>>>>>>                   binwidth = 1, colour = "black", fill = "white") +
>>>>>>    xlab("Improvement, %") +
>>>>>>    ylab("Density") +
>>>>>>    theme_classic()
>>>>>> @
>>>>>> 
>>>>>> \end{document}
>>>>>> 
>>>>>>        [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> ____________________________________________________________
>>>>> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
>>>>> http://www.inbox.com/smileys Works with AIMR, MSNR Messenger, Yahoo!R
>>>>> Messenger, ICQR, Google TalkT and most webmails
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ____________________________________________________________
>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas
>>>> on
>>>> your desktop!
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>> and family!
>> Visit http://www.inbox.com/photosharing to find out more!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From emorway at usgs.gov  Mon Dec 23 19:11:01 2013
From: emorway at usgs.gov (Morway, Eric)
Date: Mon, 23 Dec 2013 10:11:01 -0800
Subject: [R] Inserting color into an irregular grid comprised of polygons
Message-ID: <CAPoqHzqiri47Q3OUfdqSnCm3qqKqk4SDj10xL54SMnMVq3BOhQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131223/1577d769/attachment.pl>

From smartpink111 at yahoo.com  Mon Dec 23 19:13:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 23 Dec 2013 10:13:32 -0800 (PST)
Subject: [R] 2 factor split and lapply
In-Reply-To: <CAE4Ynx8TbmC7dn4fQhzzmWHHQNK8dQmvG8uF9wViHpbp3Q1kZA@mail.gmail.com>
References: <CAE4Ynx8dLtzcq-uuKOCvL+z0JaoZWOTrgt3j-8Y0CeKsPTPr5A@mail.gmail.com>	<CACk-te3Vdk3R0CuSvJY+hQYaB_yP82tXY32QSY1f-5iSP+8j4w@mail.gmail.com>	<EBD14876-81F9-4514-8130-7EB1D8487E68@gmail.com>	<1387809319.86434.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<1387809928.84960.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAE4Ynx8TbmC7dn4fQhzzmWHHQNK8dQmvG8uF9wViHpbp3Q1kZA@mail.gmail.com>
Message-ID: <1387822412.27500.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
No problem.
If you have two columns and need the ratio, you could use ?transform
?testframe$data1 <- c(2.24,6.5,4.34)


dcast(transform(testframe,ratio=data/data1),factor2~factor1,value.var="ratio",mean)
#? factor2??????? a???????? b
#1?????? 1 1.491071?????? NaN
#2?????? 2 0.483871 0.6461538
A.K.




On Monday, December 23, 2013 10:49 AM, Onur Uncu <onuruncu at gmail.com> wrote:

Thank you Arun. May I ask a follow up question? What if the function needed to take multiple arguments? So, instead of "mean", suppose the function was ?function(x,y){x/y} and suppose x and y inputs were 2 columns of a data frame. In other words, is there an mapply type function under reshape package?

thnks






On Mon, Dec 23, 2013 at 2:45 PM, arun <smartpink111 at yahoo.com> wrote:

HI,
>I think this will be more appropriate.
>
>dcast(testframe,factor2~factor1,value.var="data",mean)
>? factor2??? a?? b
>1?????? 1 3.34 NaN
>2?????? 2 2.10 4.2
>A.K.
>
>
>On Monday, December 23, 2013 9:37 AM, arun <smartpink111 at yahoo.com> wrote:
>Hi,
>You could try:
>library(reshape2)
>dcast(as.data.frame(as.table(by(testframe[,3],testframe[,-3],mean))),factor2~factor1,value.var="Freq")
>#? factor2??? a?? b
>#1?????? 1 3.34? NA
>#2?????? 2 2.10 4.2
>
>A.K.
>
>
>
>
>On Monday, December 23, 2013 9:24 AM, Onur Uncu <onuruncu at gmail.com> wrote:
>Sure, here is a reproducible example:
>
>testframe<-data.frame(factor1=c("a","b","a"),factor2=c(1,2,2),data=c(3.34,4.2,2.1))
>
>splitframe<-split(testframe,list(factor1=testframe$factor1,factor2=testframe$factor2))
>
>lapply(splitframe,function(x)mean(x[,"data"]))
>
>The above lapply returns
>
>$a.1
>[1] 3.34
>
>$b.1
>[1] NaN
>
>$a.2
>[1] 2.1
>
>$b.2
>[1] 4.2
>
>The results are correct but not presented in a format I prefer... Factor1 and factor2 are combined into a single factor, which is not desired. I want to keep them seperate. Ideally, a table output as below.
>
>? ?? a? ? ? ? ? b
>1?? 3.34? ?? NaN
>2?? 2.1? ? ?? 4.2
>
>How can I achieve this please?
>
>
>> On 23 Dec 2013, at 00:44, Bert Gunter <gunter.berton at gene.com> wrote:
>>
>> I believe you missed
>> ?tapply
>> which does what you want I think (in the absence of a reproducible
>> example one cannot be sure).
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> H. Gilbert Welch
>>
>>
>>
>>
>>> On Sun, Dec 22, 2013 at 3:54 PM, Onur Uncu <onuruncu at gmail.com> wrote:
>>> R Users,
>>>
>>> I have a data frame which I split using 2 factors using the split function:
>>>
>>> split(datframe, list(f=factor1, f2=factor2));
>>>
>>> I then used lapply to get some summary statistics grouped by factor1 and
>>> factor2.
>>>
>>> I now want to change the appearance of this output. I want to get? a 2
>>> dimensional table where columns represent values of factor1, rows represent
>>> values of factor2 and the entries on the table represent the summary
>>> results that were calculated by lapply.
>>>
>>> I tried as.table() function but did not help. It seems the problem is that
>>> R combined factor1 and factor 2 into one factor when I used list(f=factor1,
>>> f2=factor2) in the split function. So R is now unable to treat them as 2
>>> different factors in order to put them on row and columns of a table... Any
>>> ideas how I can achieve the desired table?
>>>
>>> Thanks for your help.
>>>
>>>? ? ? ? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Mon Dec 23 20:05:49 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 23 Dec 2013 13:05:49 -0600
Subject: [R] Inserting color into an irregular grid comprised of polygons
In-Reply-To: <CAPoqHzqiri47Q3OUfdqSnCm3qqKqk4SDj10xL54SMnMVq3BOhQ@mail.gmail.com>
References: <CAPoqHzqiri47Q3OUfdqSnCm3qqKqk4SDj10xL54SMnMVq3BOhQ@mail.gmail.com>
Message-ID: <02af01cf0011$fde65b10$f9b31130$@tamu.edu>

Recode val into a set of integers equal to the number of color
levels you want and then use heat.colors(), terrain.colors(), or
a similar function to define a vector of continuous colors.

# cut makes it easy to split up the data but it creates a factor
# and loses the matrix dimensions so we have to convert back.

cv <- matrix(as.integer(cut(vals, breaks=10)), dim(vals))
pal <- heat.colors(10)

Then use

polygon(x=x, y=y, border=NA, col=pal[cv[k, j]])

Note: border=NA, not NULL

David Carlson

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Morway, Eric
Sent: Monday, December 23, 2013 12:11 PM
To: R mailing list
Subject: [R] Inserting color into an irregular grid comprised of
polygons

useRs,

The example code below is an attempt to plot some spatial data
that is
associated with an irregularly spaced grid.  The last thing I
hope to do
with this example is assign the color of each polygon generated
in the
nested for loop based on the value contained in "vals".  The R
code I'm
seeking help with appears at the end of the example code below.
How would
one assign a color to the polygon at position [j,k] that is
appropriately
scaled to the total range of "vals"?  The comment appearing
before the last
line of commented-out code in the example below provides a
little more
information.  Thanks, Eric

## Example R Code
library(gsubfn)  #uses paste0 func

x.space <-
c(0.13833334,0.27666667,0.27666667,0.27666667,0.13833334,0.13833
334,0.13833334,0.13833334,0.13833334,0.13833334,0.13833334,0.138
33334,0.13833334,0.13833334,0.13833334,0.13833334,0.13833334,0.1
3833334,0.13833334,0.13833334,0.13833334,0.13833334,0.13833334,0
.13833334,0.13833334,0.13833334,0.13833334,0.13833334,0.13833334
,0.13833334,0.13833334,0.13833334,0.13833334,0.13833334,0.138333
34,0.13833334,0.27666667,0.27666667,0.27666667,0.27666667,0.2766
6667,0.27666667,0.27666667,0.415,0.415,0.415,0.415,0.415,0.415,0
.415,
0.27666667, 0.27666667)
z.space <-
c(0.23503518,0.0993,0.0993,0.0993,0.0993,0.0993,0.0993,0.0993,0.
0993,0.0993,0.0993,0.0993,0.0993,0.0993,0.050285053,0.04901495,0
.0993,0.042104937,0.057195064,0.059790898,0.0395091,0.03392482,0
.022215653,0.043159526,0.048876755,0.050423246,0.049547195,0.049
752805,0.050217632,0.049082365,0.0993,0.046798017,0.052501984,0.
052228954,0.047071047,0.052899394,0.046400607,0.06309083,0.03620
9174,0.0993,0.050150216,0.04914978,0.055581152,0.043718845,0.099
3,0.0993,0.0993,0.0993,0.0993,0.1986,0.1986,0.1986,0.1986,0.1986
,0.3972,0.3972,0.3972,0.4965,0.3972,0.3972,0.3972,0.3972,0.3972,
0.3972,0.3972,0.3972,0.4965,0.4333665,0.44272622,0.5141073,0.595
8,0.4965,0.3972,0.3972,0.3972,0.3972,0.3972,0.3972,0.3972,0.3972
,0.3972,0.3972,0.3972,0.3972,0.3972,0.3972,0.3972,0.3972,0.3972,
0.3972,0.1986,0.1986)

x.range <- c(0,sum(x.space))
z.range <- c(0,sum(z.space))
z.sum <- sum(z.space)

vals <-
matrix(c(0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000
E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00
,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.0
00E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+
00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0
.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000
E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00
,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.0
00E+00,0.684E+01,

 
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.660E+01,0.679E+01,0.683E+01,0.
684E+01,

 
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.656E+01,0.679E+01,0.683E+01,0.
684E+01,

 
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.603E+01,0.655E+01,0.679E+01,0.683E+01,0.
684E+01,

 
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.632E+01,0.656E+01,0.680E+01,0.684E+01,0.
684E+01,

 
0.669E+01,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.583E+01,0.658E+01,0.681E+01,0.684E+01,0.
684E+01,

 
0.657E+01,0.637E+01,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.615E+01,0.586E+01,0.665E+01,0.682E+01,0.684E+01,0.
684E+01,

 
0.662E+01,0.639E+01,0.688E+01,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.665E+01,0.643E+01,0.696E+01,0.710E+01,0.712E+01,0.
712E+01,

 
0.674E+01,0.679E+01,0.675E+01,0.682E+01,0.650E+01,0.643E+01,0.33
8E+01,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.133E+00,0.758E+01,0.682E+01,0.721E+01,0.724E+01,0.724E+01,0.
724E+01,

 
0.683E+01,0.702E+01,0.665E+01,0.629E+01,0.634E+01,0.606E+01,0.34
7E+01,0.575E+00,0.776E-01,0.669E-02,0.844E-02,0.000E+00,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+0
0,0.352E+00,0.789E+01,0.834E+01,0.723E+01,0.705E+01,0.703E+01,0.
703E+01,

 
0.664E+01,0.674E+01,0.656E+01,0.632E+01,0.639E+01,0.619E+01,0.38
6E+01,0.619E+00,0.102E+00,0.960E-02,0.133E-01,0.111E-01,0.000E+0
0,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.166E+0
0,0.157E+01,0.678E+01,0.878E+01,0.791E+01,0.780E+01,0.779E+01,0.
779E+01,

 
0.670E+01,0.680E+01,0.647E+01,0.622E+01,0.665E+01,0.691E+01,0.69
3E+01,0.141E+01,0.290E+00,0.618E-01,0.543E-01,0.177E-01,0.587E-0
2,0.327E-02,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.553E+0
0,0.357E+01,0.571E+01,0.839E+01,0.734E+01,0.699E+01,0.695E+01,0.
694E+01,

 
0.663E+01,0.730E+01,0.648E+01,0.607E+01,0.658E+01,0.736E+01,0.74
8E+01,0.285E+01,0.124E+01,0.195E+01,0.371E+00,0.416E-01,0.935E-0
2,0.255E-02,0.364E-02,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.257E+00,0.155E+0
1,0.502E+01,0.579E+01,0.839E+01,0.784E+01,0.774E+01,0.772E+01,0.
772E+01,

 
0.629E+01,0.665E+01,0.604E+01,0.585E+01,0.649E+01,0.656E+01,0.65
9E+01,0.530E+01,0.301E+01,0.427E+01,0.936E+00,0.183E+00,0.138E-0
1,0.261E-02,0.540E-02,0.330E-02,0.000E+00,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.506E+00,0.320E+0
1,0.595E+01,0.641E+01,0.788E+01,0.825E+01,0.846E+01,0.849E+01,0.
849E+01,

 
0.602E+01,0.538E+01,0.561E+01,0.557E+01,0.601E+01,0.600E+01,0.59
9E+01,0.585E+01,0.380E+01,0.450E+01,0.156E+01,0.347E+00,0.413E-0
1,0.969E-02,0.119E-01,0.591E-02,0.149E-02,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.000E+00,0.293E-01,0.690E+00,0.478E+0
1,0.579E+01,0.593E+01,0.785E+01,0.818E+01,0.845E+01,0.849E+01,0.
849E+01,

 
0.553E+01,0.535E+01,0.513E+01,0.503E+01,0.581E+01,0.568E+01,0.57
4E+01,0.566E+01,0.538E+01,0.517E+01,0.400E+01,0.660E+00,0.872E-0
1,0.727E-01,0.292E-01,0.110E-01,0.175E-02,0.000E+00,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.000E+00,0.000E+00,0.291E-01,0.243E-01,0.648E+00,0.469E+0
1,0.567E+01,0.522E+01,0.698E+01,0.740E+01,0.742E+01,0.742E+01,0.
742E+01,

 
0.538E+01,0.555E+01,0.481E+01,0.461E+01,0.494E+01,0.534E+01,0.53
3E+01,0.542E+01,0.604E+01,0.623E+01,0.489E+01,0.175E+01,0.849E+0
0,0.125E+01,0.129E+00,0.317E-01,0.411E-02,0.482E-02,0.000E+00,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.00
0E+00,0.186E-01,0.185E-01,0.309E-01,0.247E-01,0.718E+00,0.528E+0
1,0.545E+01,0.479E+01,0.618E+01,0.736E+01,0.741E+01,0.741E+01,0.
741E+01,

 
0.523E+01,0.540E+01,0.405E+01,0.374E+01,0.393E+01,0.432E+01,0.45
5E+01,0.489E+01,0.643E+01,0.676E+01,0.609E+01,0.281E+01,0.272E+0
1,0.367E+01,0.307E+00,0.145E+00,0.180E-01,0.172E-01,0.303E-01,0.
000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.134E-01,0.25
4E-01,0.234E-01,0.240E-01,0.432E-01,0.541E-01,0.118E+01,0.531E+0
1,0.588E+01,0.561E+01,0.677E+01,0.734E+01,0.740E+01,0.741E+01,0.
741E+01,

 
0.508E+01,0.541E+01,0.370E+01,0.330E+01,0.357E+01,0.373E+01,0.40
1E+01,0.452E+01,0.647E+01,0.737E+01,0.738E+01,0.585E+01,0.412E+0
1,0.505E+01,0.897E+00,0.301E+00,0.105E+00,0.691E-01,0.513E-01,0.
209E-01,0.120E-01,0.643E-02,0.345E-02,0.137E-02,0.000E+00,0.000E
+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.000E+00,
0.000E+00,0.000E+00,0.000E+00,0.000E+00,0.219E-01,0.156E-01,0.37
3E-01,0.370E-01,0.375E-01,0.772E-01,0.175E+00,0.144E+01,0.560E+0
1,0.626E+01,0.583E+01,0.765E+01,0.733E+01,0.740E+01,0.741E+01,0.
741E+01,

 
0.484E+01,0.520E+01,0.306E+01,0.271E+01,0.266E+01,0.301E+01,0.32
3E+01,0.429E+01,0.579E+01,0.835E+01,0.786E+01,0.643E+01,0.574E+0
1,0.655E+01,0.195E+01,0.762E+00,0.968E+00,0.371E+00,0.966E-01,0.
294E-01,0.142E-01,0.689E-02,0.278E-02,0.713E-03,0.643E-03,0.362E
-02,0.223E-01,0.198E+00,0.122E+00,0.661E-01,0.453E-01,0.176E-01,
0.458E-01,0.429E-01,0.176E-01,0.176E-01,0.347E-01,0.266E-01,0.72
8E-01,0.908E-01,0.888E-01,0.158E+00,0.933E+00,0.211E+01,0.602E+0
1,0.637E+01,0.582E+01,0.831E+01,0.732E+01,0.740E+01,0.741E+01,0.
741E+01,

 
0.462E+01,0.409E+01,0.273E+01,0.195E+01,0.231E+01,0.217E+01,0.24
9E+01,0.396E+01,0.576E+01,0.869E+01,0.819E+01,0.677E+01,0.603E+0
1,0.694E+01,0.238E+01,0.145E+01,0.272E+01,0.946E+00,0.152E+00,0.
384E-01,0.223E-01,0.749E-02,0.311E-02,0.469E-03,0.313E-03,0.285E
-02,0.186E-01,0.104E+00,0.104E+00,0.758E-01,0.863E-01,0.108E+00,
0.818E-01,0.599E-01,0.394E-01,0.358E-01,0.476E-01,0.646E-01,0.13
7E+00,0.236E+00,0.228E+00,0.310E+00,0.214E+01,0.260E+01,0.625E+0
1,0.645E+01,0.554E+01,0.755E+01,0.730E+01,0.739E+01,0.741E+01,0.
741E+01,

 
0.378E+01,0.341E+01,0.252E+01,0.160E+01,0.210E+01,0.179E+01,0.20
7E+01,0.377E+01,0.567E+01,0.897E+01,0.833E+01,0.691E+01,0.589E+0
1,0.644E+01,0.255E+01,0.191E+01,0.397E+01,0.135E+01,0.197E+00,0.
412E-01,0.319E-01,0.793E-02,0.302E-02,0.374E-03,0.212E-03,0.254E
-02,0.158E-01,0.581E-01,0.840E-01,0.805E-01,0.134E+00,0.476E+00,
0.117E+00,0.694E-01,0.743E-01,0.714E-01,0.604E-01,0.127E+00,0.24
7E+00,0.448E+00,0.433E+00,0.485E+00,0.300E+01,0.292E+01,0.638E+0
1,0.645E+01,0.534E+01,0.683E+01,0.729E+01,0.739E+01,0.741E+01,0.
741E+01,

 
0.365E+01,0.315E+01,0.240E+01,0.146E+01,0.199E+01,0.164E+01,0.19
5E+01,0.367E+01,0.557E+01,0.872E+01,0.836E+01,0.696E+01,0.564E+0
1,0.539E+01,0.258E+01,0.220E+01,0.436E+01,0.149E+01,0.229E+00,0.
438E-01,0.345E-01,0.817E-02,0.309E-02,0.381E-03,0.207E-03,0.243E
-02,0.141E-01,0.421E-01,0.709E-01,0.820E-01,0.168E+00,0.799E+00,
0.147E+00,0.831E-01,0.105E+00,0.101E+00,0.714E-01,0.181E+00,0.33
1E+00,0.641E+00,0.620E+00,0.637E+00,0.323E+01,0.309E+01,0.644E+0
1,0.644E+01,0.526E+01,0.648E+01,0.728E+01,0.739E+01,0.741E+01,0.
741E+01,

 
0.353E+01,0.301E+01,0.231E+01,0.140E+01,0.189E+01,0.156E+01,0.19
8E+01,0.361E+01,0.541E+01,0.807E+01,0.832E+01,0.697E+01,0.526E+0
1,0.430E+01,0.277E+01,0.242E+01,0.405E+01,0.144E+01,0.259E+00,0.
446E-01,0.299E-01,0.832E-02,0.333E-02,0.478E-03,0.275E-03,0.244E
-02,0.125E-01,0.340E-01,0.594E-01,0.812E-01,0.187E+00,0.715E+00,
0.180E+00,0.989E-01,0.129E+00,0.132E+00,0.842E-01,0.221E+00,0.42
6E+00,0.817E+00,0.789E+00,0.798E+00,0.294E+01,0.322E+01,0.648E+0
1,0.640E+01,0.530E+01,0.629E+01,0.727E+01,0.739E+01,0.741E+01,0.
741E+01,

 
0.349E+01,0.294E+01,0.226E+01,0.142E+01,0.181E+01,0.158E+01,0.22
0E+01,0.359E+01,0.518E+01,0.721E+01,0.818E+01,0.691E+01,0.466E+0
1,0.493E+01,0.263E+01,0.250E+01,0.320E+01,0.116E+01,0.284E+00,0.
422E-01,0.251E-01,0.834E-02,0.398E-02,0.818E-03,0.607E-03,0.267E
-02,0.112E-01,0.313E-01,0.484E-01,0.758E-01,0.173E+00,0.720E+00,
0.209E+00,0.116E+00,0.137E+00,0.159E+00,0.998E-01,0.237E+00,0.52
3E+00,0.891E+00,0.857E+00,0.932E+00,0.224E+01,0.325E+01,0.648E+0
1,0.632E+01,0.554E+01,0.622E+01,0.675E+01,0.739E+01,0.741E+01,0.
741E+01,

 
0.341E+01,0.290E+01,0.227E+01,0.152E+01,0.180E+01,0.165E+01,0.25
1E+01,0.366E+01,0.517E+01,0.653E+01,0.799E+01,0.677E+01,0.407E+0
1,0.432E+01,0.237E+01,0.236E+01,0.241E+01,0.869E+00,0.289E+00,0.
370E-01,0.214E-01,0.826E-02,0.515E-02,0.159E-02,0.123E-02,0.318E
-02,0.105E-01,0.284E-01,0.530E-01,0.668E-01,0.237E+00,0.603E+00,
0.215E+00,0.127E+00,0.223E+00,0.201E+00,0.110E+00,0.202E+00,0.56
0E+00,0.809E+00,0.779E+00,0.938E+00,0.164E+01,0.313E+01,0.644E+0
1,0.623E+01,0.570E+01,0.621E+01,0.672E+01,0.739E+01,0.741E+01,0.
741E+01,

 
0.336E+01,0.288E+01,0.233E+01,0.163E+01,0.183E+01,0.174E+01,0.28
3E+01,0.376E+01,0.501E+01,0.602E+01,0.779E+01,0.661E+01,0.357E+0
1,0.384E+01,0.209E+01,0.212E+01,0.122E+01,0.651E+00,0.279E+00,0.
311E-01,0.187E-01,0.821E-02,0.685E-02,0.290E-02,0.229E-02,0.394E
-02,0.129E-01,0.265E-01,0.483E-01,0.569E-01,0.201E+00,0.661E+00,
0.383E+00,0.128E+00,0.240E+00,0.219E+00,0.176E+00,0.184E+00,0.54
5E+00,0.676E+00,0.654E+00,0.854E+00,0.202E+01,0.292E+01,0.636E+0
1,0.615E+01,0.584E+01,0.622E+01,0.669E+01,0.657E+01,0.657E+01,0.
657E+01,

 
0.334E+01,0.287E+01,0.242E+01,0.175E+01,0.189E+01,0.226E+01,0.24
4E+01,0.389E+01,0.489E+01,0.591E+01,0.762E+01,0.644E+01,0.317E+0
1,0.583E+01,0.182E+01,0.185E+01,0.123E+01,0.503E+00,0.261E+00,0.
304E-01,0.167E-01,0.183E-01,0.950E-02,0.417E-02,0.311E-02,0.729E
-02,0.137E-01,0.257E-01,0.678E-01,0.479E-01,0.327E+00,0.623E+00,
0.388E+00,0.273E+00,0.253E+00,0.234E+00,0.188E+00,0.167E+00,0.50
6E+00,0.674E+00,0.107E+01,0.741E+00,0.170E+01,0.268E+01,0.628E+0
1,0.609E+01,0.586E+01,0.623E+01,0.604E+01,0.657E+01,0.657E+01,0.
657E+01,

 
0.254E+01,0.287E+01,0.252E+01,0.186E+01,0.196E+01,0.243E+01,0.25
7E+01,0.402E+01,0.482E+01,0.566E+01,0.562E+01,0.628E+01,0.640E+0
1,0.571E+01,0.159E+01,0.162E+01,0.993E+00,0.402E+00,0.242E+00,0.
258E-01,0.380E-01,0.207E-01,0.104E-01,0.638E-02,0.466E-02,0.735E
-02,0.148E-01,0.254E-01,0.676E-01,0.117E+00,0.307E+00,0.602E+00,
0.546E+00,0.447E+00,0.264E+00,0.247E+00,0.539E+00,0.151E+00,0.46
0E+00,0.564E+00,0.959E+00,0.632E+00,0.146E+01,0.245E+01,0.620E+0
1,0.622E+01,0.594E+01,0.625E+01,0.601E+01,0.656E+01,0.657E+01,0.
657E+01,

 
0.248E+01,0.235E+01,0.261E+01,0.196E+01,0.205E+01,0.259E+01,0.26
9E+01,0.415E+01,0.441E+01,0.549E+01,0.539E+01,0.613E+01,0.631E+0
1,0.559E+01,0.140E+01,0.142E+01,0.828E+00,0.839E+00,0.417E+00,0.
533E-01,0.394E-01,0.329E-01,0.133E-01,0.911E-02,0.650E-02,0.910E
-02,0.162E-01,0.256E-01,0.681E-01,0.114E+00,0.294E+00,0.596E+00,
0.567E+00,0.483E+00,0.276E+00,0.260E+00,0.617E+00,0.459E+00,0.60
0E+00,0.478E+00,0.857E+00,0.540E+00,0.127E+01,0.225E+01,0.612E+0
1,0.619E+01,0.601E+01,0.566E+01,0.598E+01,0.655E+01,0.657E+01,0.
657E+01,

 
0.242E+01,0.230E+01,0.141E+01,0.127E+01,0.898E+00,0.161E+01,0.16
5E+01,0.237E+01,0.270E+01,0.491E+01,0.648E+01,0.660E+01,0.614E+0
1,0.578E+01,0.369E+01,0.372E+01,0.116E+01,0.768E+00,0.419E+00,0.
124E+00,0.423E-01,0.409E-01,0.289E-01,0.140E-01,0.968E-02,0.120E
-01,0.187E-01,0.264E-01,0.701E-01,0.111E+00,0.286E+00,0.608E+00,
0.606E+00,0.538E+00,0.496E+00,0.626E+00,0.736E+00,0.485E+00,0.10
6E+01,0.990E+00,0.892E+00,0.204E+01,0.220E+01,0.431E+01,0.641E+0
1,0.574E+01,0.553E+01,0.561E+01,0.594E+01,0.654E+01,0.656E+01,0.
657E+01,

 
0.165E+01,0.158E+01,0.136E+01,0.953E+00,0.853E+00,0.115E+01,0.17
7E+01,0.227E+01,0.255E+01,0.312E+01,0.514E+01,0.646E+01,0.662E+0
1,0.641E+01,0.361E+01,0.362E+01,0.187E+01,0.977E+00,0.432E+00,0.
134E+00,0.117E+00,0.810E-01,0.232E-01,0.190E-01,0.218E-01,0.243E
-01,0.512E-01,0.704E-01,0.779E-01,0.114E+00,0.541E+00,0.459E+00,
0.481E+00,0.102E+01,0.990E+00,0.103E+01,0.866E+00,0.960E+00,0.11
1E+01,0.163E+01,0.257E+01,0.202E+01,0.310E+01,0.425E+01,0.635E+0
1,0.551E+01,0.555E+01,0.530E+01,0.560E+01,0.653E+01,0.656E+01,0.
657E+01,

 
0.162E+01,0.153E+01,0.132E+01,0.845E+00,0.821E+00,0.102E+01,0.14
9E+01,0.219E+01,0.247E+01,0.324E+01,0.421E+01,0.637E+01,0.634E+0
1,0.643E+01,0.359E+01,0.359E+01,0.167E+01,0.958E+00,0.449E+00,0.
371E+00,0.131E+00,0.934E-01,0.275E-01,0.231E-01,0.264E-01,0.282E
-01,0.568E-01,0.753E-01,0.816E-01,0.412E+00,0.565E+00,0.485E+00,
0.517E+00,0.112E+01,0.110E+01,0.116E+01,0.984E+00,0.165E+01,0.11
7E+01,0.257E+01,0.245E+01,0.204E+01,0.465E+01,0.424E+01,0.632E+0
1,0.564E+01,0.531E+01,0.527E+01,0.558E+01,0.576E+01,0.656E+01,0.
657E+01,

 
0.159E+01,0.150E+01,0.103E+01,0.811E+00,0.785E+00,0.980E+00,0.14
2E+01,0.163E+01,0.267E+01,0.317E+01,0.412E+01,0.627E+01,0.628E+0
1,0.639E+01,0.561E+01,0.300E+01,0.170E+01,0.999E+00,0.841E+00,0.
204E+00,0.147E+00,0.107E+00,0.490E-01,0.278E-01,0.313E-01,0.324E
-01,0.624E-01,0.804E-01,0.863E-01,0.428E+00,0.599E+00,0.526E+00,
0.570E+00,0.125E+01,0.124E+01,0.131E+01,0.112E+01,0.198E+01,0.18
7E+01,0.267E+01,0.254E+01,0.349E+01,0.468E+01,0.426E+01,0.640E+0
1,0.560E+01,0.527E+01,0.524E+01,0.556E+01,0.575E+01,0.656E+01,0.
657E+01,

 
0.157E+01,0.146E+01,0.998E+00,0.775E+00,0.896E+00,0.932E+00,0.12
2E+01,0.157E+01,0.259E+01,0.311E+01,0.406E+01,0.445E+01,0.623E+0
1,0.637E+01,0.561E+01,0.304E+01,0.177E+01,0.105E+01,0.891E+00,0.
227E+00,0.167E+00,0.123E+00,0.571E-01,0.325E-01,0.360E-01,0.579E
-01,0.673E-01,0.851E-01,0.918E-01,0.444E+00,0.641E+00,0.583E+00,
0.640E+00,0.113E+01,0.140E+01,0.149E+01,0.127E+01,0.220E+01,0.20
4E+01,0.281E+01,0.266E+01,0.359E+01,0.474E+01,0.602E+01,0.637E+0
1,0.556E+01,0.522E+01,0.520E+01,0.554E+01,0.575E+01,0.656E+01,0.
657E+01,

 
0.155E+01,0.143E+01,0.958E+00,0.734E+00,0.840E+00,0.877E+00,0.11
5E+01,0.167E+01,0.252E+01,0.308E+01,0.402E+01,0.445E+01,0.619E+0
1,0.635E+01,0.472E+01,0.460E+01,0.187E+01,0.114E+01,0.102E+01,0.
826E+00,0.190E+00,0.873E-01,0.659E-01,0.377E-01,0.408E-01,0.631E
-01,0.707E-01,0.894E-01,0.982E-01,0.462E+00,0.698E+00,0.664E+00,
0.121E+01,0.128E+01,0.160E+01,0.171E+01,0.196E+01,0.247E+01,0.22
4E+01,0.300E+01,0.283E+01,0.373E+01,0.484E+01,0.631E+01,0.621E+0
1,0.552E+01,0.515E+01,0.517E+01,0.552E+01,0.574E+01,0.576E+01,0.
657E+01,

 
0.153E+01,0.116E+01,0.916E+00,0.750E+00,0.783E+00,0.969E+00,0.10
6E+01,0.158E+01,0.202E+01,0.306E+01,0.412E+01,0.447E+01,0.616E+0
1,0.633E+01,0.480E+01,0.466E+01,0.201E+01,0.205E+01,0.109E+01,0.
872E+00,0.220E+00,0.103E+00,0.755E-01,0.433E-01,0.455E-01,0.674E
-01,0.745E-01,0.932E-01,0.327E+00,0.480E+00,0.717E+00,0.780E+00,
0.138E+01,0.147E+01,0.184E+01,0.198E+01,0.224E+01,0.280E+01,0.33
8E+01,0.420E+01,0.401E+01,0.486E+01,0.496E+01,0.634E+01,0.620E+0
1,0.542E+01,0.508E+01,0.521E+01,0.550E+01,0.574E+01,0.576E+01,0.
576E+01,

 
0.151E+01,0.116E+01,0.869E+00,0.729E+00,0.718E+00,0.827E+00,0.10
4E+01,0.148E+01,0.200E+01,0.307E+01,0.412E+01,0.451E+01,0.483E+0
1,0.633E+01,0.491E+01,0.476E+01,0.302E+01,0.154E+01,0.119E+01,0.
927E+00,0.264E+00,0.125E+00,0.870E-01,0.735E-01,0.661E-01,0.713E
-01,0.779E-01,0.117E+00,0.313E+00,0.502E+00,0.826E+00,0.141E+01,
0.163E+01,0.173E+01,0.221E+01,0.317E+01,0.261E+01,0.392E+01,0.37
6E+01,0.454E+01,0.429E+01,0.506E+01,0.652E+01,0.639E+01,0.619E+0
1,0.538E+01,0.499E+01,0.517E+01,0.526E+01,0.558E+01,0.576E+01,0.
576E+01,

 
0.150E+01,0.116E+01,0.825E+00,0.657E+00,0.660E+00,0.734E+00,0.92
9E+00,0.139E+01,0.199E+01,0.274E+01,0.413E+01,0.457E+01,0.496E+0
1,0.566E+01,0.504E+01,0.486E+01,0.327E+01,0.218E+01,0.130E+01,0.
981E+00,0.318E+00,0.150E+00,0.981E-01,0.791E-01,0.696E-01,0.739E
-01,0.801E-01,0.116E+00,0.296E+00,0.523E+00,0.961E+00,0.171E+01,
0.192E+01,0.203E+01,0.265E+01,0.364E+01,0.300E+01,0.447E+01,0.41
8E+01,0.493E+01,0.460E+01,0.525E+01,0.659E+01,0.643E+01,0.618E+0
1,0.533E+01,0.489E+01,0.512E+01,0.525E+01,0.557E+01,0.576E+01,0.
576E+01,

 
0.125E+01,0.118E+01,0.769E+00,0.558E+00,0.589E+00,0.606E+00,0.76
1E+00,0.127E+01,0.201E+01,0.290E+01,0.418E+01,0.466E+01,0.519E+0
1,0.500E+01,0.524E+01,0.503E+01,0.397E+01,0.256E+01,0.145E+01,0.
105E+01,0.402E+00,0.194E+00,0.113E+00,0.853E-01,0.876E-01,0.764E
-01,0.819E-01,0.118E+00,0.265E+00,0.550E+00,0.122E+01,0.245E+01,
0.241E+01,0.250E+01,0.401E+01,0.447E+01,0.360E+01,0.634E+01,0.48
2E+01,0.556E+01,0.509E+01,0.553E+01,0.656E+01,0.649E+01,0.618E+0
1,0.528E+01,0.477E+01,0.506E+01,0.523E+01,0.557E+01,0.575E+01,0.
576E+01,

 
0.126E+01,0.123E+01,0.774E+00,0.464E+00,0.535E+00,0.475E+00,0.60
3E+00,0.118E+01,0.204E+01,0.327E+01,0.385E+01,0.474E+01,0.512E+0
1,0.568E+01,0.542E+01,0.517E+01,0.459E+01,0.303E+01,0.159E+01,0.
104E+01,0.610E+00,0.299E+00,0.127E+00,0.103E+00,0.832E-01,0.783E
-01,0.831E-01,0.105E+00,0.268E+00,0.572E+00,0.171E+01,0.383E+01,
0.296E+01,0.298E+01,0.525E+01,0.498E+01,0.418E+01,0.756E+01,0.54
7E+01,0.730E+01,0.650E+01,0.579E+01,0.674E+01,0.655E+01,0.619E+0
1,0.526E+01,0.453E+01,0.500E+01,0.520E+01,0.557E+01,0.575E+01,0.
576E+01,

 
0.127E+01,0.127E+01,0.756E+00,0.430E+00,0.520E+00,0.433E+00,0.53
3E+00,0.115E+01,0.208E+01,0.358E+01,0.391E+01,0.475E+01,0.525E+0
1,0.614E+01,0.502E+01,0.521E+01,0.494E+01,0.329E+01,0.163E+01,0.
107E+01,0.851E+00,0.322E+00,0.132E+00,0.102E+00,0.810E-01,0.796E
-01,0.102E+00,0.966E-01,0.250E+00,0.579E+00,0.187E+01,0.523E+01,
0.320E+01,0.314E+01,0.593E+01,0.559E+01,0.438E+01,0.822E+01,0.66
0E+01,0.749E+01,0.663E+01,0.625E+01,0.683E+01,0.656E+01,0.619E+0
1,0.524E+01,0.439E+01,0.497E+01,0.520E+01,0.557E+01,0.575E+01,0.
576E+01,

 
0.126E+01,0.125E+01,0.762E+00,0.442E+00,0.550E+00,0.450E+00,0.55
9E+00,0.113E+01,0.207E+01,0.341E+01,0.386E+01,0.473E+01,0.517E+0
1,0.590E+01,0.496E+01,0.423E+01,0.476E+01,0.319E+01,0.162E+01,0.
106E+01,0.727E+00,0.321E+00,0.133E+00,0.106E+00,0.848E-01,0.927E
-01,0.104E+00,0.102E+00,0.259E+00,0.578E+00,0.181E+01,0.450E+01,
0.313E+01,0.397E+01,0.569E+01,0.539E+01,0.531E+01,0.801E+01,0.65
6E+01,0.742E+01,0.657E+01,0.622E+01,0.679E+01,0.667E+01,0.623E+0
1,0.525E+01,0.445E+01,0.498E+01,0.520E+01,0.557E+01,0.575E+01,0.
576E+01,

 
0.125E+01,0.120E+01,0.788E+00,0.492E+00,0.579E+00,0.512E+00,0.65
6E+00,0.117E+01,0.204E+01,0.309E+01,0.373E+01,0.379E+01,0.494E+0
1,0.536E+01,0.481E+01,0.407E+01,0.429E+01,0.285E+01,0.180E+01,0.
103E+01,0.549E+00,0.300E+00,0.175E+00,0.112E+00,0.923E-01,0.963E
-01,0.110E+00,0.116E+00,0.291E+00,0.767E+00,0.160E+01,0.324E+01,
0.283E+01,0.375E+01,0.488E+01,0.465E+01,0.510E+01,0.728E+01,0.63
0E+01,0.712E+01,0.638E+01,0.611E+01,0.668E+01,0.665E+01,0.623E+0
1,0.527E+01,0.461E+01,0.501E+01,0.520E+01,0.557E+01,0.559E+01,0.
576E+01,

 
0.123E+01,0.116E+01,0.852E+00,0.590E+00,0.651E+00,0.631E+00,0.83
6E+00,0.129E+01,0.201E+01,0.276E+01,0.351E+01,0.355E+01,0.454E+0
1,0.472E+01,0.449E+01,0.342E+01,0.369E+01,0.234E+01,0.150E+01,0.
952E+00,0.505E+00,0.258E+00,0.217E+00,0.121E+00,0.103E+00,0.130E
+00,0.120E+00,0.135E+00,0.355E+00,0.779E+00,0.127E+01,0.218E+01,
0.228E+01,0.328E+01,0.383E+01,0.360E+01,0.434E+01,0.625E+01,0.57
4E+01,0.658E+01,0.601E+01,0.588E+01,0.651E+01,0.677E+01,0.616E+0
1,0.533E+01,0.483E+01,0.508E+01,0.520E+01,0.526E+01,0.559E+01,0.
576E+01,

 
0.120E+01,0.126E+01,0.961E+00,0.736E+00,0.785E+00,0.806E+00,0.10
9E+01,0.145E+01,0.192E+01,0.261E+01,0.293E+01,0.319E+01,0.408E+0
1,0.412E+01,0.303E+01,0.293E+01,0.313E+01,0.185E+01,0.130E+01,0.
104E+01,0.393E+00,0.298E+00,0.220E+00,0.129E+00,0.115E+00,0.152E
+00,0.158E+00,0.153E+00,0.445E+00,0.795E+00,0.125E+01,0.146E+01,
0.243E+01,0.263E+01,0.285E+01,0.262E+01,0.359E+01,0.522E+01,0.64
5E+01,0.763E+01,0.553E+01,0.701E+01,0.632E+01,0.673E+01,0.615E+0
1,0.542E+01,0.507E+01,0.533E+01,0.521E+01,0.526E+01,0.587E+01,0.
587E+01,

 
0.132E+01,0.128E+01,0.106E+01,0.933E+00,0.929E+00,0.964E+00,0.13
5E+01,0.160E+01,0.192E+01,0.249E+01,0.271E+01,0.291E+01,0.307E+0
1,0.400E+01,0.262E+01,0.255E+01,0.244E+01,0.132E+01,0.114E+01,0.
977E+00,0.327E+00,0.268E+00,0.219E+00,0.185E+00,0.176E+00,0.172E
+00,0.178E+00,0.178E+00,0.602E+00,0.808E+00,0.109E+01,0.113E+01,
0.199E+01,0.215E+01,0.227E+01,0.294E+01,0.300E+01,0.602E+01,0.59
6E+01,0.737E+01,0.710E+01,0.695E+01,0.686E+01,0.670E+01,0.614E+0
1,0.550E+01,0.525E+01,0.544E+01,0.543E+01,0.550E+01,0.587E+01,0.
587E+01,

 
0.138E+01,0.140E+01,0.125E+01,0.108E+01,0.108E+01,0.112E+01,0.13
9E+01,0.172E+01,0.194E+01,0.258E+01,0.259E+01,0.271E+01,0.282E+0
1,0.245E+01,0.234E+01,0.229E+01,0.231E+01,0.201E+01,0.103E+01,0.
888E+00,0.869E+00,0.761E+00,0.217E+00,0.272E+00,0.260E+00,0.188E
+00,0.193E+00,0.603E+00,0.716E+00,0.818E+00,0.164E+01,0.226E+01,
0.172E+01,0.183E+01,0.227E+01,0.344E+01,0.259E+01,0.580E+01,0.56
0E+01,0.765E+01,0.730E+01,0.691E+01,0.725E+01,0.667E+01,0.614E+0
1,0.560E+01,0.538E+01,0.539E+01,0.545E+01,0.550E+01,0.551E+01,0.
587E+01,

 
0.139E+01,0.145E+01,0.131E+01,0.151E+01,0.155E+01,0.159E+01,0.17
7E+01,0.190E+01,0.205E+01,0.253E+01,0.235E+01,0.245E+01,0.252E+0
1,0.342E+01,0.219E+01,0.216E+01,0.279E+01,0.177E+01,0.165E+01,0.
152E+01,0.132E+01,0.126E+01,0.115E+01,0.107E+01,0.939E+00,0.974E
+00,0.997E+00,0.106E+01,0.134E+01,0.152E+01,0.173E+01,0.225E+01,
0.278E+01,0.292E+01,0.302E+01,0.486E+01,0.495E+01,0.809E+01,0.80
7E+01,0.802E+01,0.789E+01,0.737E+01,0.705E+01,0.662E+01,0.603E+0
1,0.573E+01,0.540E+01,0.545E+01,0.560E+01,0.565E+01,0.567E+01,0.
559E+01,

 
0.175E+01,0.170E+01,0.171E+01,0.169E+01,0.175E+01,0.178E+01,0.18
3E+01,0.190E+01,0.244E+01,0.254E+01,0.262E+01,0.233E+01,0.326E+0
1,0.328E+01,0.328E+01,0.274E+01,0.269E+01,0.261E+01,0.162E+01,0.
146E+01,0.139E+01,0.131E+01,0.131E+01,0.115E+01,0.112E+01,0.111E
+01,0.119E+01,0.123E+01,0.130E+01,0.162E+01,0.206E+01,0.219E+01,
0.229E+01,0.444E+01,0.454E+01,0.460E+01,0.471E+01,0.799E+01,0.81
1E+01,0.806E+01,0.774E+01,0.768E+01,0.704E+01,0.661E+01,0.622E+0
1,0.579E+01,0.567E+01,0.564E+01,0.581E+01,0.566E+01,0.567E+01,0.
559E+01,

 
0.179E+01,0.187E+01,0.183E+01,0.181E+01,0.181E+01,0.192E+01,0.19
5E+01,0.232E+01,0.237E+01,0.257E+01,0.364E+01,0.368E+01,0.372E+0
1,0.322E+01,0.445E+01,0.443E+01,0.266E+01,0.262E+01,0.242E+01,0.
237E+01,0.145E+01,0.128E+01,0.125E+01,0.129E+01,0.128E+01,0.128E
+01,0.129E+01,0.138E+01,0.170E+01,0.175E+01,0.180E+01,0.218E+01,
0.371E+01,0.377E+01,0.445E+01,0.448E+01,0.779E+01,0.790E+01,0.80
5E+01,0.786E+01,0.783E+01,0.738E+01,0.704E+01,0.667E+01,0.608E+0
1,0.577E+01,0.574E+01,0.575E+01,0.571E+01,0.585E+01,0.586E+01,0.
567E+01,

 
0.193E+01,0.193E+01,0.192E+01,0.191E+01,0.191E+01,0.224E+01,0.22
6E+01,0.241E+01,0.244E+01,0.344E+01,0.369E+01,0.372E+01,0.375E+0
1,0.520E+01,0.448E+01,0.447E+01,0.419E+01,0.416E+01,0.249E+01,0.
245E+01,0.218E+01,0.135E+01,0.133E+01,0.132E+01,0.131E+01,0.138E
+01,0.139E+01,0.168E+01,0.180E+01,0.183E+01,0.187E+01,0.315E+01,
0.375E+01,0.379E+01,0.661E+01,0.663E+01,0.775E+01,0.792E+01,0.80
1E+01,0.782E+01,0.780E+01,0.736E+01,0.699E+01,0.667E+01,0.610E+0
1,0.580E+01,0.578E+01,0.578E+01,0.579E+01,0.586E+01,0.586E+01,0.
586E+01,

 
0.199E+01,0.201E+01,0.201E+01,0.204E+01,0.232E+01,0.234E+01,0.23
6E+01,0.327E+01,0.348E+01,0.353E+01,0.357E+01,0.491E+01,0.524E+0
1,0.526E+01,0.527E+01,0.431E+01,0.429E+01,0.426E+01,0.383E+01,0.
234E+01,0.230E+01,0.226E+01,0.223E+01,0.141E+01,0.140E+01,0.140E
+01,0.176E+01,0.178E+01,0.180E+01,0.298E+01,0.320E+01,0.326E+01,
0.331E+01,0.564E+01,0.662E+01,0.665E+01,0.680E+01,0.788E+01,0.78
3E+01,0.781E+01,0.746E+01,0.744E+01,0.698E+01,0.681E+01,0.642E+0
1,0.602E+01,0.582E+01,0.581E+01,0.581E+01,0.572E+01,0.586E+01,0.
586E+01,

 
0.215E+01,0.220E+01,0.219E+01,0.216E+01,0.243E+01,0.245E+01,0.32
9E+01,0.336E+01,0.344E+01,0.353E+01,0.495E+01,0.503E+01,0.509E+0
1,0.514E+01,0.516E+01,0.515E+01,0.512E+01,0.409E+01,0.401E+01,0.
392E+01,0.250E+01,0.243E+01,0.235E+01,0.229E+01,0.178E+01,0.177E
+01,0.178E+01,0.182E+01,0.300E+01,0.311E+01,0.323E+01,0.555E+01,
0.567E+01,0.575E+01,0.581E+01,0.681E+01,0.686E+01,0.772E+01,0.77
2E+01,0.749E+01,0.745E+01,0.709E+01,0.706E+01,0.681E+01,0.644E+0
1,0.605E+01,0.583E+01,0.584E+01,0.583E+01,0.576E+01,0.575E+01,0.
570E+01,

 
0.255E+01,0.282E+01,0.261E+01,0.251E+01,0.268E+01,0.274E+01,0.33
1E+01,0.348E+01,0.456E+01,0.488E+01,0.508E+01,0.507E+01,0.547E+0
1,0.561E+01,0.557E+01,0.545E+01,0.549E+01,0.532E+01,0.507E+01,0.
437E+01,0.414E+01,0.381E+01,0.399E+01,0.266E+01,0.256E+01,0.256E
+01,0.267E+01,0.277E+01,0.299E+01,0.466E+01,0.524E+01,0.568E+01,
0.586E+01,0.623E+01,0.638E+01,0.645E+01,0.637E+01,0.713E+01,0.75
1E+01,0.745E+01,0.718E+01,0.709E+01,0.690E+01,0.682E+01,0.666E+0
1,0.612E+01,0.592E+01,0.599E+01,0.584E+01,0.577E+01,0.586E+01,0.
585E+01,

 
0.463E+01,0.445E+01,0.412E+01,0.385E+01,0.392E+01,0.390E+01,0.40
5E+01,0.431E+01,0.472E+01,0.504E+01,0.526E+01,0.509E+01,0.547E+0
1,0.562E+01,0.557E+01,0.553E+01,0.558E+01,0.541E+01,0.508E+01,0.
501E+01,0.470E+01,0.436E+01,0.398E+01,0.358E+01,0.342E+01,0.351E
+01,0.361E+01,0.366E+01,0.400E+01,0.466E+01,0.526E+01,0.571E+01,
0.590E+01,0.603E+01,0.629E+01,0.636E+01,0.638E+01,0.695E+01,0.73
2E+01,0.727E+01,0.712E+01,0.703E+01,0.687E+01,0.682E+01,0.664E+0
1,0.636E+01,0.622E+01,0.632E+01,0.617E+01,0.616E+01,0.586E+01,0.
585E+01,

 
0.474E+01,0.469E+01,0.466E+01,0.461E+01,0.463E+01,0.465E+01,0.47
0E+01,0.486E+01,0.494E+01,0.520E+01,0.515E+01,0.521E+01,0.526E+0
1,0.570E+01,0.513E+01,0.513E+01,0.549E+01,0.544E+01,0.494E+01,0.
486E+01,0.477E+01,0.472E+01,0.463E+01,0.446E+01,0.442E+01,0.448E
+01,0.450E+01,0.452E+01,0.478E+01,0.490E+01,0.502E+01,0.525E+01,
0.551E+01,0.557E+01,0.623E+01,0.626E+01,0.635E+01,0.707E+01,0.70
9E+01,0.711E+01,0.708E+01,0.694E+01,0.681E+01,0.672E+01,0.655E+0
1,0.643E+01,0.639E+01,0.638E+01,0.640E+01,0.641E+01,0.615E+01,0.
615E+01,

 
0.483E+01,0.482E+01,0.482E+01,0.481E+01,0.481E+01,0.482E+01,0.51
1E+01,0.512E+01,0.514E+01,0.560E+01,0.573E+01,0.574E+01,0.576E+0
1,0.625E+01,0.609E+01,0.609E+01,0.608E+01,0.539E+01,0.537E+01,0.
536E+01,0.522E+01,0.473E+01,0.471E+01,0.470E+01,0.470E+01,0.470E
+01,0.471E+01,0.484E+01,0.495E+01,0.497E+01,0.499E+01,0.563E+01,
0.590E+01,0.591E+01,0.593E+01,0.692E+01,0.692E+01,0.701E+01,0.70
1E+01,0.697E+01,0.696E+01,0.685E+01,0.685E+01,0.666E+01,0.649E+0
1,0.641E+01,0.641E+01,0.641E+01,0.641E+01,0.641E+01,0.641E+01,0.
641E+01,

 
0.500E+01,0.503E+01,0.504E+01,0.503E+01,0.517E+01,0.517E+01,0.55
6E+01,0.558E+01,0.560E+01,0.562E+01,0.613E+01,0.615E+01,0.616E+0
1,0.627E+01,0.628E+01,0.628E+01,0.628E+01,0.601E+01,0.599E+01,0.
596E+01,0.536E+01,0.528E+01,0.525E+01,0.523E+01,0.492E+01,0.492E
+01,0.493E+01,0.495E+01,0.556E+01,0.560E+01,0.563E+01,0.636E+01,
0.638E+01,0.640E+01,0.641E+01,0.667E+01,0.668E+01,0.684E+01,0.68
4E+01,0.679E+01,0.678E+01,0.669E+01,0.668E+01,0.662E+01,0.652E+0
1,0.645E+01,0.638E+01,0.638E+01,0.641E+01,0.637E+01,0.637E+01,0.
637E+01,

 
0.562E+01,0.578E+01,0.542E+01,0.551E+01,0.546E+01,0.552E+01,0.57
0E+01,0.575E+01,0.607E+01,0.616E+01,0.618E+01,0.619E+01,0.629E+0
1,0.632E+01,0.624E+01,0.627E+01,0.639E+01,0.635E+01,0.621E+01,0.
611E+01,0.597E+01,0.596E+01,0.583E+01,0.538E+01,0.534E+01,0.571E
+01,0.575E+01,0.553E+01,0.562E+01,0.610E+01,0.628E+01,0.640E+01,
0.642E+01,0.644E+01,0.654E+01,0.655E+01,0.651E+01,0.667E+01,0.66
0E+01,0.671E+01,0.665E+01,0.659E+01,0.657E+01,0.656E+01,0.655E+0
1,0.644E+01,0.640E+01,0.642E+01,0.640E+01,0.639E+01,0.639E+01,0.
639E+01,

 
0.613E+01,0.610E+01,0.604E+01,0.599E+01,0.600E+01,0.601E+01,0.60
4E+01,0.610E+01,0.613E+01,0.618E+01,0.621E+01,0.625E+01,0.618E+0
1,0.620E+01,0.621E+01,0.621E+01,0.622E+01,0.619E+01,0.619E+01,0.
614E+01,0.608E+01,0.601E+01,0.593E+01,0.587E+01,0.584E+01,0.585E
+01,0.591E+01,0.595E+01,0.602E+01,0.611E+01,0.624E+01,0.631E+01,
0.634E+01,0.640E+01,0.642E+01,0.643E+01,0.654E+01,0.655E+01,0.66
4E+01,0.663E+01,0.661E+01,0.659E+01,0.656E+01,0.655E+01,0.653E+0
1,0.649E+01,0.646E+01,0.647E+01,0.645E+01,0.645E+01,0.645E+01,0.
645E+01,

 
0.616E+01,0.615E+01,0.614E+01,0.613E+01,0.613E+01,0.614E+01,0.61
4E+01,0.618E+01,0.622E+01,0.624E+01,0.624E+01,0.621E+01,0.630E+0
1,0.630E+01,0.631E+01,0.617E+01,0.624E+01,0.624E+01,0.614E+01,0.
612E+01,0.611E+01,0.609E+01,0.609E+01,0.607E+01,0.606E+01,0.609E
+01,0.608E+01,0.609E+01,0.611E+01,0.617E+01,0.622E+01,0.624E+01,
0.625E+01,0.630E+01,0.645E+01,0.645E+01,0.647E+01,0.660E+01,0.66
0E+01,0.660E+01,0.659E+01,0.659E+01,0.656E+01,0.654E+01,0.651E+0
1,0.649E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.645E+01,0.
645E+01,

 
0.618E+01,0.618E+01,0.618E+01,0.617E+01,0.618E+01,0.622E+01,0.62
2E+01,0.622E+01,0.622E+01,0.631E+01,0.634E+01,0.634E+01,0.634E+0
1,0.643E+01,0.639E+01,0.639E+01,0.639E+01,0.623E+01,0.623E+01,0.
623E+01,0.622E+01,0.612E+01,0.612E+01,0.611E+01,0.610E+01,0.611E
+01,0.612E+01,0.616E+01,0.618E+01,0.619E+01,0.619E+01,0.634E+01,
0.639E+01,0.640E+01,0.653E+01,0.657E+01,0.657E+01,0.657E+01,0.65
9E+01,0.658E+01,0.658E+01,0.656E+01,0.654E+01,0.653E+01,0.650E+0
1,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.
648E+01,

 
0.620E+01,0.622E+01,0.622E+01,0.622E+01,0.625E+01,0.625E+01,0.63
3E+01,0.633E+01,0.633E+01,0.634E+01,0.641E+01,0.641E+01,0.642E+0
1,0.644E+01,0.644E+01,0.644E+01,0.644E+01,0.639E+01,0.639E+01,0.
639E+01,0.625E+01,0.623E+01,0.623E+01,0.622E+01,0.617E+01,0.617E
+01,0.618E+01,0.618E+01,0.632E+01,0.633E+01,0.634E+01,0.636E+01,
0.648E+01,0.648E+01,0.648E+01,0.653E+01,0.653E+01,0.655E+01,0.65
5E+01,0.655E+01,0.655E+01,0.653E+01,0.652E+01,0.652E+01,0.650E+0
1,0.649E+01,0.648E+01,0.648E+01,0.648E+01,0.647E+01,0.647E+01,0.
647E+01,

 
0.634E+01,0.633E+01,0.630E+01,0.632E+01,0.631E+01,0.632E+01,0.63
6E+01,0.637E+01,0.642E+01,0.644E+01,0.644E+01,0.644E+01,0.644E+0
1,0.645E+01,0.644E+01,0.645E+01,0.647E+01,0.646E+01,0.644E+01,0.
642E+01,0.639E+01,0.640E+01,0.637E+01,0.628E+01,0.627E+01,0.636E
+01,0.637E+01,0.633E+01,0.634E+01,0.643E+01,0.646E+01,0.647E+01,
0.648E+01,0.648E+01,0.650E+01,0.650E+01,0.649E+01,0.652E+01,0.65
1E+01,0.653E+01,0.652E+01,0.651E+01,0.650E+01,0.650E+01,0.651E+0
1,0.649E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.647E+01,0.
647E+01,

 
0.643E+01,0.643E+01,0.642E+01,0.641E+01,0.641E+01,0.641E+01,0.64
2E+01,0.643E+01,0.643E+01,0.644E+01,0.644E+01,0.645E+01,0.644E+0
1,0.644E+01,0.644E+01,0.644E+01,0.645E+01,0.644E+01,0.643E+01,0.
643E+01,0.642E+01,0.640E+01,0.639E+01,0.638E+01,0.637E+01,0.638E
+01,0.639E+01,0.640E+01,0.641E+01,0.643E+01,0.645E+01,0.646E+01,
0.647E+01,0.648E+01,0.648E+01,0.648E+01,0.650E+01,0.650E+01,0.65
1E+01,0.651E+01,0.651E+01,0.651E+01,0.650E+01,0.650E+01,0.650E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
647E+01,

 
0.644E+01,0.644E+01,0.644E+01,0.644E+01,0.644E+01,0.644E+01,0.64
4E+01,0.644E+01,0.645E+01,0.645E+01,0.645E+01,0.644E+01,0.646E+0
1,0.646E+01,0.646E+01,0.645E+01,0.645E+01,0.645E+01,0.643E+01,0.
643E+01,0.642E+01,0.642E+01,0.642E+01,0.642E+01,0.642E+01,0.642E
+01,0.642E+01,0.643E+01,0.643E+01,0.644E+01,0.645E+01,0.645E+01,
0.645E+01,0.648E+01,0.648E+01,0.649E+01,0.649E+01,0.651E+01,0.65
1E+01,0.651E+01,0.651E+01,0.651E+01,0.650E+01,0.650E+01,0.650E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.644E+01,0.644E+01,0.644E+01,0.644E+01,0.644E+01,0.645E+01,0.64
5E+01,0.645E+01,0.646E+01,0.646E+01,0.646E+01,0.647E+01,0.648E+0
1,0.648E+01,0.648E+01,0.647E+01,0.647E+01,0.647E+01,0.645E+01,0.
645E+01,0.645E+01,0.645E+01,0.643E+01,0.643E+01,0.643E+01,0.643E
+01,0.644E+01,0.644E+01,0.644E+01,0.644E+01,0.647E+01,0.647E+01,
0.647E+01,0.648E+01,0.650E+01,0.650E+01,0.650E+01,0.650E+01,0.65
0E+01,0.650E+01,0.650E+01,0.650E+01,0.650E+01,0.650E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.645E+01,0.645E+01,0.645E+01,0.645E+01,0.646E+01,0.646E+01,0.64
7E+01,0.647E+01,0.647E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+0
1,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.
648E+01,0.647E+01,0.645E+01,0.645E+01,0.645E+01,0.645E+01,0.644E
+01,0.644E+01,0.646E+01,0.647E+01,0.647E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.650E+01,0.650E+01,0.65
0E+01,0.650E+01,0.650E+01,0.650E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.64
8E+01,0.648E+01,0.648E+01,0.649E+01,0.648E+01,0.648E+01,0.648E+0
1,0.648E+01,0.648E+01,0.649E+01,0.649E+01,0.649E+01,0.648E+01,0.
648E+01,0.648E+01,0.648E+01,0.647E+01,0.647E+01,0.647E+01,0.647E
+01,0.647E+01,0.647E+01,0.648E+01,0.648E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.64
8E+01,0.648E+01,0.648E+01,0.649E+01,0.649E+01,0.648E+01,0.649E+0
1,0.649E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.
648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E
+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.648E+01,0.
648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.648E
+01,0.648E+01,0.648E+01,0.648E+01,0.648E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.648E
+01,0.648E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,

 
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E
+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,
0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.64
9E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+0
1,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.649E+01,0.
649E+01),
                 nrow = length(z.space), ncol = length(x.space),
byrow =
TRUE,
                 dimnames =
list(paste0("R",seq(1,length(z.space),by=1)),
 
paste0("C",seq(1,length(x.space),by=1))))


plot(1,1, col="white" ,xlim=x.range, ylim=z.range, xaxs="i",
yaxs="i",
las=1, xlab="X", ylab="Z")
for (k in (1:length(z.space))){
  for (j in (1:length(x.space))){

    if (j==1){
      x = c(0, 0, x.space[j], x.space[j])
    } else {
      x = c(sum(x.space[1:(j-1)]), sum(x.space[1:(j-1)]),
sum(x.space[1:j]), sum(x.space[1:j]))
    }

    if (k==1){
      y = c(z.sum, z.sum - sum(z.space[1]), z.sum -
sum(z.space[1]), z.sum)
    } else {
      y = c(z.sum - sum(z.space[1:(k-1)]),  z.sum -
sum(z.space[1:k]),
z.sum - sum(z.space[1:k]), z.sum - sum(z.space[1:(k-1)]))
    }

    #This shows the grid cells
    polygon(x=x, y=y, border="black")

    #Instead of plotting the grid cell boundaries, I'd like to
plot a
colored polygon that is borderless
    #Need help assigning a color that is within the total range
of "vals"
and is based on vals[j,k]
    #polygon(x=x, y=y, border=NULL, col= vals[j,k])

  }
}

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From pburns at pburns.seanet.com  Mon Dec 23 20:09:03 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 23 Dec 2013 19:09:03 +0000
Subject: [R] error in "ca.jo"
In-Reply-To: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>
References: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>
Message-ID: <52B88A4F.9040603@pburns.seanet.com>

There is a fundamental problem with your
code, and there is the problem that you
have (sort of) identified.

The fundamental problem is that you are
only going to get the results of the last
call to 'ca.jo' that is done -- assuming
it were to run.  You presumably want to
save some information from each of the
computations.

You can get the loops to run even when you
run into an error with some combinations
by using 'try' or 'tryCatch'.  There is an
example in Circle 8.3.13 of 'The R Inferno'.

http://www.burns-stat.com/documents/books/the-r-inferno/

If you have a question related to the actual
function as opposed to general problems with
R, then the r-sig-finance mailing list would
be appropriate (you need to subscribe before
posting).

I'm not sure if this is enough of a hint for
you or not.  If not, then trying to formulate
a more explicit question might help.  (There
are some suggestions in Circle 9 of 'The R
Inferno'.)

Pat


On 23/12/2013 17:07, mamush bukana wrote:
> Dear all,
> I fit co-integration function between two integrated variables(y1 and y2)
> over different grid points:
>
> for(i in 1:N1){
> for(j in 1:N2){
> co<-ca.jo(data.frame(cbind(y2[i,j,],y1[i,j,])),type="trace", K=2,
> spec="transitory",ecdet="const",season=NULL,dumvar=NULL)
> }}
>
> I have already extracted grid points with integrated time series. However,
> when I run the above function, there happens an error
>
> Error in solve.default(t(V) %*% SKK %*% V) :
>    system is computationally singular: reciprocal condition number =
> 1.10221e-35
>
> May you suggest me how to fix this problem please?
>
> Thanks in advance
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From edd at debian.org  Mon Dec 23 17:13:47 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 23 Dec 2013 16:13:47 +0000
Subject: [R] R command execution at specific time from within R
References: <CABfqsR_8SRqB2Nuw3wMkvjO7CxReW9KE2gLVww1NaD+7ruevNw@mail.gmail.com>
Message-ID: <loom.20131223T171215-23@post.gmane.org>

Costas Vorlow <costas.vorlow <at> gmail.com> writes:
> I am trying to write a code that executes an R command at specific time
> intervals.
> 
> ? want R to do that instead of the operating system.
> 
> Any help/pointer extremely welcome.

Don't do it.   Just rely on cron [if you're lucky enough to be on Linux 
or OS X]; else rely on Windows Scheduler.  

Write a simple script using RScript, schedule.  Thousands of people do the 
sample.  

Dirk


From lbt1 at aber.ac.uk  Mon Dec 23 13:31:10 2013
From: lbt1 at aber.ac.uk (Laura Bethan Thomas [lbt1])
Date: Mon, 23 Dec 2013 12:31:10 +0000
Subject: [R] Fwd: Calculating group means
References: <B456B369-7201-43EB-BA83-9633CFD1A5BF@hotmail.com>
Message-ID: <94BBEA78-3B6F-43B0-8669-3C7D3D64D74C@aber.ac.uk>

> Hi All, 
> 
> Sorry for what I imagine is quite a basic question. I have been trying to do is create latency averages for each state (1-8) for each participant (n=13) in each condition (1-10). I'm not sure what function I would need, or what the most efficient ay of calculating this would be. If you have any help with that I would be very grateful.
> 
> structure(list(subject = c(1L, 1L, 1L, 1L, 1L, 1L), conditionNo = c(1L, 
> 1L, 1L, 1L, 1L, 1L), state = c(5L, 8L, 7L, 8L, 1L, 7L), latency = c(869L, 
> 864L, 1004L, 801L, 611L, 679L)), .Names = c("subject", "conditionNo", 
> "state", "latency"), row.names = 3:8, class = "data.frame")
> 
> Thanks again,
> 
> Laura


From felasa at gmail.com  Mon Dec 23 17:53:59 2013
From: felasa at gmail.com (Federico Lasa)
Date: Mon, 23 Dec 2013 10:53:59 -0600
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <DD14B2ACA2B.00000424jrkrideau@inbox.com>
References: <cankvva3sqzk8nxa0kemg=npe2puj+mqnfqsu-7m1kvasn7t2aw@mail.gmail.com>
	<d16683c5446.00000494jrkrideau@inbox.com>
	<cankvva3ey2ruu-2cojsvk2uqhxjusdyg_d-nrcedbxxwzp6z1a@mail.gmail.com>
	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>
	<001c01ceffda$7fa36090$7eea21b0$@bigpond.com>
	<DD14B2ACA2B.00000424jrkrideau@inbox.com>
Message-ID: <CAE8W1T1CagaJnenBpPLkdDwmf_e7A0R4tJVT8X5=-uU1pBLOYg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131223/4b6634fa/attachment.pl>

From sigtool at kcl.ac.uk  Mon Dec 23 19:30:00 2013
From: sigtool at kcl.ac.uk (sigtool at kcl.ac.uk)
Date: Mon, 23 Dec 2013 10:30:00 -0800 (PST)
Subject: [R] Exporting R graphics into Word without losing graph quality
In-Reply-To: <52B5EBFE.2080203@wisc.edu>
References: <CAEEpX7qKOprckgP8Do-9J+=yqJfn_XOOYM25uVCp1ASOrw0r=g@mail.gmail.com>
	<52B5EBFE.2080203@wisc.edu>
Message-ID: <8f297bcd-a33c-4514-b5f9-b15311c09f7c@googlegroups.com>

Waterloo Graphics is open-source and can be used from R.
Graphics can be copied and pasted in vector format to Word on Windows or 
Mac.
There is also an SVG file save option that produces output with easy-to-use 
object groupings for editing an Adobe Illustrator/Inkscape.
(as well as HTML5/Processing support)

http://waterloo.sourceforge.net

From tiaborrelli at yahoo.it  Mon Dec 23 20:06:23 2013
From: tiaborrelli at yahoo.it (Tia Borrelli)
Date: Mon, 23 Dec 2013 19:06:23 +0000 (GMT)
Subject: [R] Fitdistr and mle
Message-ID: <1387825583.42562.YahooMailNeo@web173205.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131223/dffe6861/attachment.pl>

From deter088 at umn.edu  Mon Dec 23 20:41:51 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 23 Dec 2013 13:41:51 -0600
Subject: [R] Fwd: Calculating group means
In-Reply-To: <94BBEA78-3B6F-43B0-8669-3C7D3D64D74C@aber.ac.uk>
References: <B456B369-7201-43EB-BA83-9633CFD1A5BF@hotmail.com>
	<94BBEA78-3B6F-43B0-8669-3C7D3D64D74C@aber.ac.uk>
Message-ID: <CAOLJph=-WZC1EvEf-OyrMHSNfRFeNKeDQocPgfRLMMaVSuUVBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131223/3a95932c/attachment.pl>

From smartpink111 at yahoo.com  Mon Dec 23 20:43:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 23 Dec 2013 11:43:09 -0800 (PST)
Subject: [R] Fwd: Calculating group means
In-Reply-To: <94BBEA78-3B6F-43B0-8669-3C7D3D64D74C@aber.ac.uk>
References: <B456B369-7201-43EB-BA83-9633CFD1A5BF@hotmail.com>
	<94BBEA78-3B6F-43B0-8669-3C7D3D64D74C@aber.ac.uk>
Message-ID: <1387827789.21730.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
You could either try:
#dat1 ##dataset
aggregate(latency~.,data=dat1,mean)

#or
?library(data.table)
?dt1 <- data.table(dat1,key=c('subject','conditionNo','state'))
?dt1[,mean(latency),by=c('subject','conditionNo','state')]

A.K.




On Monday, December 23, 2013 2:20 PM, Laura Bethan Thomas [lbt1] <lbt1 at aber.ac.uk> wrote:
> Hi All, 
> 
> Sorry for what I imagine is quite a basic question. I have been trying to do is create latency averages for each state (1-8) for each participant (n=13) in each condition (1-10). I'm not sure what function I would need, or what the most efficient ay of calculating this would be. If you have any help with that I would be very grateful.
> 
> structure(list(subject = c(1L, 1L, 1L, 1L, 1L, 1L), conditionNo = c(1L, 
> 1L, 1L, 1L, 1L, 1L), state = c(5L, 8L, 7L, 8L, 1L, 7L), latency = c(869L, 
> 864L, 1004L, 801L, 611L, 679L)), .Names = c("subject", "conditionNo", 
> "state", "latency"), row.names = 3:8, class = "data.frame")
> 
> Thanks again,
> 
> Laura

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From murdoch.duncan at gmail.com  Mon Dec 23 21:52:32 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 23 Dec 2013 15:52:32 -0500
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <DDDF93FC937.00000595jrkrideau@inbox.com>
References: <dda31cf559b.00000528jrkrideau@inbox.com>
	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>
	<cankvva3sqzk8nxa0kemg=npe2puj+mqnfqsu-7m1kvasn7t2aw@mail.gmail.com>
	<d16683c5446.00000494jrkrideau@inbox.com>
	<cankvva3ey2ruu-2cojsvk2uqhxjusdyg_d-nrcedbxxwzp6z1a@mail.gmail.com>
	<001c01ceffda$7fa36090$7eea21b0$@bigpond.com>
	<dd14b2aca2b.00000424jrkrideau@inbox.com>
	<DDDF93FC937.00000595jrkrideau@inbox.com>
Message-ID: <52B8A290.5050106@gmail.com>

On 13-12-23 1:07 PM, John Kane wrote:
> Thanks  Duncan.
> I had the feeling I was doing something wrong but did not realise it was that stupid.
>
> showNonASCII('ggplot(df, aes(x = x)) + geom_histogram(aes(y = ..density..)),
>                   binwidth = 1, colour = "black", fill = "white")')
>
> now runs and does what the help page seems to imply: Nothing.
>
>  From the showNonASCII help page:
> "The elements of x containing non-ASCII characters will be returned invisibly."
>
> One gets a result one does not see?  Does one have to explicitly capture the result somehow?  I really have not the faintest idea of what the example from the help page is doing.

"returned invisibly" means that the result is returned with a flag set 
so it won't automatically print.  If you want to print it, you need to 
ask.  So any of these will work to see the result:

x <- showNonASCII( .... )
x

or

print(showNonASCII( .... ))

or even (though this is one some of us don't like, it still works...)

(showNonASCII( .... ))

Duncan Murdoch

> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: murdoch.duncan at gmail.com
>> Sent: Mon, 23 Dec 2013 12:51:43 -0500
>> To: jrkrideau at inbox.com, rmh at temple.edu
>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>
>> On 13-12-23 12:40 PM, John Kane wrote:
>>> Thanks Richard.  I did not realise such a function existed.
>>>
>>> Assuming I am using it  correctly I do get an error though not where I
>>> was expecting it.  Anyway the code below returns an error
>>>
>>> library(tools)
>>> showNonASCII("ggplot(df, aes(x = x)) + geom_histogram(aes(y =
>>> ..density..)), binwidth = 1, colour = "black", fill = "white")")
>>>
>>> Results
>>> Error: unexpected symbol in:
>>> "showNonASCII("ggplot(df, aes(x = x)) + geom_histogram(aes(y =
>>> ..density..)), binwidth = 1, colour = "black"
>>
>> You get that error because you're using double quotes around a string
>> containing double quotes, and not escaping them.  With that string,
>> using single quotes on the outside should be fine:
>>
>>    showNonASCII('ggplot(df, aes(x = x)) + geom_histogram(aes(y =
>> ..density..)), binwidth = 1, colour = "black", fill = "white")')
>>
>> Duncan Murdoch
>>>
>>>
>>>
>>> John Kane
>>> Kingston ON Canada
>>>
>>>
>>>> -----Original Message-----
>>>> From: rmh at temple.edu
>>>> Sent: Mon, 23 Dec 2013 11:44:42 -0500
>>>> To: jrkrideau at inbox.com
>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>
>>>> If the problem seems to be non-ASCII characters, then the first
>>>> investigation
>>>> step is to use the R functions
>>>>
>>>> ?tools::showNonASCII
>>>> ?tools::showNonASCIIfile
>>>>
>>>> On Mon, Dec 23, 2013 at 11:37 AM, John Kane <jrkrideau at inbox.com>
>>>> wrote:
>>>>> Same result here with the same error message mentioned in my first
>>>>> post.
>>>>> I tried it in Texmaker which is my usual Latex editor, not that I do
>>>>> much in Latex, and then tried it in RStudio and it is still choking.
>>>>>
>>>>> Interestingly EMACS will process it and produce a pdf but it simply
>>>>> produces.  It also provides this warning: : Latex Warning; Reference
>>>>> 'fig:plot-figheight' undefined on page 2 on input line 14.
>>>>>
>>>>> It seems to repeat the same message for each of the other figures.
>>>>>
>>>>> John Kane
>>>>> Kingston ON Canada
>>>>>
>>>>>
>>>>>> -----Original Message-----
>>>>>> From: dulcalma at bigpond.com
>>>>>> Sent: Mon, 23 Dec 2013 22:28:33 +1000
>>>>>> To: daniel.haugstvedt at gmail.com, r-help at r-project.org
>>>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>>>
>>>>>> Hi Dan
>>>>>>
>>>>>>
>>>>>>
>>>>>> I think you still have problems with embedded characters or some
>>>>>> problems
>>>>>> in
>>>>>> char code page conversion or the like.
>>>>>>
>>>>>>
>>>>>>
>>>>>> Not knowing knitr but Sweave I cobbled the figures manually and ran
>>>>>> the
>>>>>> sweave file to produce the latex file.
>>>>>>
>>>>>> Latex was consistently stopping at the \caption and \ref functions
>>>>>>
>>>>>> I tried to see what was happening I added hyperref & when I copied
>>>>>> the
>>>>>> text
>>>>>> to hyperref  latex bailed up
>>>>>>
>>>>>>
>>>>>>
>>>>>> I tried a minimal latex file without problems
>>>>>>
>>>>>>
>>>>>>
>>>>>> I put the \title etc in the preamble. Some compilers need this
>>>>>>
>>>>>>
>>>>>>
>>>>>> Duncan
>>>>>>
>>>>>>
>>>>>>
>>>>>> From: Daniel Haugstvedt [mailto:daniel.haugstvedt at gmail.com]
>>>>>> Sent: Monday, 23 December 2013 20:10
>>>>>> To: Duncan Mackay
>>>>>> Cc: John Kane; R
>>>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>>>
>>>>>>
>>>>>>
>>>>>> I am really sorry for posting a non-working example. It is running
>>>>>> when
>>>>>> I
>>>>>> cut the code from my previous mail into a clean session in RStudio
>>>>>> (OSX).
>>>>>> However, I suspect that you are right. I did cut and paste some code
>>>>>> from
>>>>>> a
>>>>>> forum yesterday which had characters that had to be replaced. I gave
>>>>>> emacs a
>>>>>> try, but could not find the problem there either.
>>>>>>
>>>>>>
>>>>>>
>>>>>> The code below was pasted though textEdit and converted to plain
>>>>>> text.
>>>>>> I
>>>>>> hope this takes care of any embedded characters.
>>>>>>
>>>>>>
>>>>>>
>>>>>> \documentclass{article}
>>>>>>
>>>>>> \begin{document}
>>>>>>
>>>>>>
>>>>>>
>>>>>> <<setup, include=FALSE, cache=FALSE>>=
>>>>>>
>>>>>> library(knitr)
>>>>>>
>>>>>> library(ggplot2)
>>>>>>
>>>>>> @
>>>>>>
>>>>>>
>>>>>>
>>>>>> \title{Knitr and ggplot2}
>>>>>>
>>>>>> \author{Daniel Haugstvedt}
>>>>>>
>>>>>>
>>>>>>
>>>>>> \maketitle
>>>>>>
>>>>>>
>>>>>>
>>>>>> There are four plots in this article. Figure \ref{fig:plot-figHeight}
>>>>>> uses
>>>>>>
>>>>>> the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>>>>>>
>>>>>> used both fig.height=2.5 and fig.width=3. The later option makes the
>>>>>> font
>>>>>>
>>>>>> too big.
>>>>>>
>>>>>>
>>>>>>
>>>>>> An alternative approach is used in Figures
>>>>>> \ref{fig:plot-figOutWidthBig}
>>>>>> and
>>>>>>
>>>>>>    \ref{fig:plot-figOutWidthSmall}. There the argument out.width is
>>>>>> set
>>>>>> to
>>>>>>
>>>>>>    12 and 8 cm respectively. This stops the problem of excessively
>>>>>> large
>>>>>> fonts
>>>>>>
>>>>>>    for figures with smaller width, but there is still no consistency
>>>>>>
>>>>>>    across plots in terms o font size.
>>>>>>
>>>>>>
>>>>>>
>>>>>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>>>>>> with
>>>>>> no
>>>>>> fig.width argument", results='hide', fig.pos='ht'>>=
>>>>>>
>>>>>> df = data.frame(x = rnorm(100), y = 1:100)
>>>>>>
>>>>>> ggplot(df, aes(x = x)) +
>>>>>>
>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>
>>>>>>                    binwidth = 1, colour = "black", fill = "white") +
>>>>>>
>>>>>>     xlab("Improvement, %") +
>>>>>>
>>>>>>     ylab("Density") +
>>>>>>
>>>>>>     theme_classic()
>>>>>>
>>>>>> @
>>>>>>
>>>>>>
>>>>>>
>>>>>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>>>>>> fig.cap="Density
>>>>>> plot with fig.width=3", fig.pos='ht'>>=
>>>>>>
>>>>>> ggplot(df, aes(x = x)) +
>>>>>>
>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>
>>>>>>                    binwidth = 1, colour = "black", fill = "white") +
>>>>>>
>>>>>>     xlab("Improvement, %") +
>>>>>>
>>>>>>     ylab("Density") +
>>>>>>
>>>>>>     theme_classic()
>>>>>>
>>>>>> @
>>>>>>
>>>>>>
>>>>>>
>>>>>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width =
>>>>>> "12cm",
>>>>>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
>>>>>>
>>>>>> ggplot(df, aes(x = x)) +
>>>>>>
>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>
>>>>>>                    binwidth = 1, colour = "black", fill = "white") +
>>>>>>
>>>>>>     xlab("Improvement, %") +
>>>>>>
>>>>>>     ylab("Density") +
>>>>>>
>>>>>>     theme_classic()
>>>>>>
>>>>>> @
>>>>>>
>>>>>>
>>>>>>
>>>>>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
>>>>>> "8cm",
>>>>>> fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>>>>>
>>>>>> ggplot(df, aes(x = x)) +
>>>>>>
>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>
>>>>>>                    binwidth = 1, colour = "black", fill = "white") +
>>>>>>
>>>>>>     xlab("Improvement, %") +
>>>>>>
>>>>>>     ylab("Density") +
>>>>>>
>>>>>>     theme_classic()
>>>>>>
>>>>>> @
>>>>>>
>>>>>>
>>>>>>
>>>>>> \end{document}
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Sun, Dec 22, 2013 at 11:59 PM, Duncan Mackay
>>>>>> <dulcalma at bigpond.com>
>>>>>> wrote:
>>>>>>
>>>>>> Hi Daniel
>>>>>> I tried it in Sweave after modifying it for Sweave and a similar
>>>>>> thing
>>>>>> for
>>>>>> Latex but R crashed.
>>>>>>
>>>>>> I think there is an embedded character/s before the first chunk and
>>>>>> in
>>>>>> the
>>>>>> first chunk.
>>>>>>
>>>>>> Duncan
>>>>>>
>>>>>> Duncan Mackay
>>>>>> Department of Agronomy and Soil Science
>>>>>> University of New England
>>>>>> Armidale NSW 2351
>>>>>> Email: home: mackay at northnet.com.au
>>>>>>
>>>>>>
>>>>>> -----Original Message-----
>>>>>> From: r-help-bounces at r-project.org
>>>>>> [mailto:r-help-bounces at r-project.org]
>>>>>> On
>>>>>> Behalf Of John Kane
>>>>>> Sent: Monday, 23 December 2013 04:19
>>>>>> To: Daniel Haugstvedt; r-help at r-project.org
>>>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>>>
>>>>>> Hi Daniel,
>>>>>>
>>>>>> For some reason I cannot get your example to work. The problem is in
>>>>>> the
>>>>>> code chunk but I have no idea what is happening. The code is running
>>>>>> perfectly in R, itself but LaTeX seems to be choking when it hits the
>>>>>> first
>>>>>> ggplot statement, that is the one in <<plot-figHeight>>=
>>>>>>
>>>>>> The message I am getting is: "Missing $ inserted <inserted text> $
>>>>>> ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not enough
>>>>>> to
>>>>>> figure out the problem.
>>>>>>
>>>>>> I tried stripping out most of the LaTeX specific verbiage in the code
>>>>>> chunk
>>>>>> and running the code in LyX which I use rather than plain vanilla
>>>>>> LaTeX
>>>>>> and
>>>>>> I still cannot get it to work. It is almost as if there is some
>>>>>> hidden
>>>>>> character in the in that piece of code since I can duplicate the code
>>>>>> myself
>>>>>> and I even pasted in most of the geom_histogram code into my code
>>>>>> chunk
>>>>>> and
>>>>>> it runs.
>>>>>>
>>>>>> John Kane
>>>>>> Kingston ON Canada
>>>>>>
>>>>>>
>>>>>>> -----Original Message-----
>>>>>>> From: daniel.haugstvedt at gmail.com
>>>>>>> Sent: Sun, 22 Dec 2013 12:42:50 +0100
>>>>>>> To: r-help at r-project.org
>>>>>>> Subject: [R] Knitr, ggplot and consistent fonts
>>>>>>>
>>>>>>> Dear R-help
>>>>>>>
>>>>>>> I am using Knitr and ggplot to draft an article and have now started
>>>>>>> to improve on the layout and graphics. So far I have not been able
>>>>>>> to
>>>>>>> maintain the same font size for labels in all my figures.
>>>>>>>
>>>>>>> My goal is to be able to change the width of the figures while
>>>>>>> maintaining the same font. This works for the height parameter
>>>>>>> (example not included).
>>>>>>>
>>>>>>> In the true document I also use tikz, but the problem can be
>>>>>>> reproduced without it.
>>>>>>>
>>>>>>> I know the question is very specific, but my understanding is that
>>>>>>> this combination of packages  is common. (They are really great.
>>>>>>> Keep
>>>>>>> up the good work.)  There has to be others facing the same problem
>>>>>>> and
>>>>>>> someone must have found a nice solution.
>>>>>>>
>>>>>>> Additional attempts from my side which failed are not included in
>>>>>>> the
>>>>>>> example. I have tested the Google results i could find without any
>>>>>>> luck.
>>>>>>>
>>>>>>> Cheers
>>>>>>> Daniel
>>>>>>>
>>>>>>> PS. I know the example plots could have been smaller, but they just
>>>>>>> became too ugly for me
>>>>>>>
>>>>>>>
>>>>>>> \documentclass{article}
>>>>>>> \begin{document}
>>>>>>>
>>>>>>> <<setup, include=FALSE, cache=FALSE>>=
>>>>>>> library(knitr)
>>>>>>> library(ggplot2)
>>>>>>> @
>>>>>>>
>>>>>>> \title{Knitr and ggplot2}
>>>>>>> \author{Daniel Haugstvedt}
>>>>>>>
>>>>>>> \maketitle
>>>>>>>
>>>>>>> There are four plots in this article. Figure
>>>>>>> \ref{fig:plot-figHeight}
>>>>>>> uses the argument fig.height=2.5 while Figures
>>>>>>> \ref{fig:plot-figWidth}
>>>>>>> used both fig.height=2.5 and fig.width=3. The later option makes the
>>>>>>> font too big.
>>>>>>>
>>>>>>> An alternative approach is used in Figures
>>>>>>> \ref{fig:plot-figOutWidthBig} and  \ref{fig:plot-figOutWidthSmall}.
>>>>>>> There the argument out.width is set to
>>>>>>>    12 and 8 cm respectively. This stops the problem of excessively
>>>>>>> large
>>>>>>> fonts  for figures with smaller width, but there is still no
>>>>>>> consistency  across plots in terms of font size.
>>>>>>>
>>>>>>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>>>>>>> with no fig.width argument", fig.pos='ht'>>= df = data.frame(x =
>>>>>>> rnorm(100), y = 1:100) ggplot(df, aes(x = x)) +
>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>>                    binwidth = 1, colour = "black", fill = "white") +
>>>>>>>     xlab("Improvement, %") +
>>>>>>>     ylab("Density") +
>>>>>>>     theme_classic()
>>>>>>> @
>>>>>>>
>>>>>>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>>>>>>> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>= ggplot(df,
>>>>>>> aes(x = x)) +
>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>>                    binwidth = 1, colour = "black", fill = "white") +
>>>>>>>     xlab("Improvement, %") +
>>>>>>>     ylab("Density") +
>>>>>>>     theme_classic()
>>>>>>> @
>>>>>>>
>>>>>>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width =
>>>>>>> "12cm",
>>>>>>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
>>>>>>> ggplot(df,
>>>>>>> aes(x = x)) +
>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>>                    binwidth = 1, colour = "black", fill = "white") +
>>>>>>>     xlab("Improvement, %") +
>>>>>>>     ylab("Density") +
>>>>>>>     theme_classic()
>>>>>>> @
>>>>>>>
>>>>>>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
>>>>>>> "8cm", fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>>>>>> ggplot(df, aes(x = x)) +
>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>>                    binwidth = 1, colour = "black", fill = "white") +
>>>>>>>     xlab("Improvement, %") +
>>>>>>>     ylab("Density") +
>>>>>>>     theme_classic()
>>>>>>> @
>>>>>>>
>>>>>>> \end{document}
>>>>>>>
>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>> ____________________________________________________________
>>>>>> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
>>>>>> http://www.inbox.com/smileys Works with AIMR, MSNR Messenger, Yahoo!R
>>>>>> Messenger, ICQR, Google TalkT and most webmails
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>> ____________________________________________________________
>>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas
>>>>> on
>>>>> your desktop!
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ____________________________________________________________
>>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>>> and family!
>>> Visit http://www.inbox.com/photosharing to find out more!
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
> Check it out at http://www.inbox.com/marineaquarium
>
>


From jrkrideau at inbox.com  Mon Dec 23 22:09:45 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 23 Dec 2013 13:09:45 -0800
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <52B8A290.5050106@gmail.com>
References: <dda31cf559b.00000528jrkrideau@inbox.com>
	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>
	<cankvva3sqzk8nxa0kemg=npe2puj+mqnfqsu-7m1kvasn7t2aw@mail.gmail.com>
	<d16683c5446.00000494jrkrideau@inbox.com>
	<cankvva3ey2ruu-2cojsvk2uqhxjusdyg_d-nrcedbxxwzp6z1a@mail.gmail.com>
	<001c01ceffda$7fa36090$7eea21b0$@bigpond.com>
	<dddf93fc937.00000595jrkrideau@inbox.com>
	<dd14b2aca2b.00000424jrkrideau@inbox.com>
Message-ID: <DF762F2B0E9.0000083Fjrkrideau@inbox.com>

Thanks, I was not getting anything when I printed the x and so thought I was doing  something wrong. Instead I just didn't seem to have a non-ASCII character.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: murdoch.duncan at gmail.com
> Sent: Mon, 23 Dec 2013 15:52:32 -0500
> To: jrkrideau at inbox.com, rmh at temple.edu
> Subject: Re: [R] Knitr, ggplot and consistent fonts
> 
> On 13-12-23 1:07 PM, John Kane wrote:
>> Thanks  Duncan.
>> I had the feeling I was doing something wrong but did not realise it was
>> that stupid.
>> 
>> showNonASCII('ggplot(df, aes(x = x)) + geom_histogram(aes(y =
>> ..density..)),
>>                   binwidth = 1, colour = "black", fill = "white")')
>> 
>> now runs and does what the help page seems to imply: Nothing.
>> 
>>  From the showNonASCII help page:
>> "The elements of x containing non-ASCII characters will be returned
>> invisibly."
>> 
>> One gets a result one does not see?  Does one have to explicitly capture
>> the result somehow?  I really have not the faintest idea of what the
>> example from the help page is doing.
> 
> "returned invisibly" means that the result is returned with a flag set
> so it won't automatically print.  If you want to print it, you need to
> ask.  So any of these will work to see the result:
> 
> x <- showNonASCII( .... )
> x
> 
> or
> 
> print(showNonASCII( .... ))
> 
> or even (though this is one some of us don't like, it still works...)
> 
> (showNonASCII( .... ))
> 
> Duncan Murdoch
> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: murdoch.duncan at gmail.com
>>> Sent: Mon, 23 Dec 2013 12:51:43 -0500
>>> To: jrkrideau at inbox.com, rmh at temple.edu
>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>> 
>>> On 13-12-23 12:40 PM, John Kane wrote:
>>>> Thanks Richard.  I did not realise such a function existed.
>>>> 
>>>> Assuming I am using it  correctly I do get an error though not where I
>>>> was expecting it.  Anyway the code below returns an error
>>>> 
>>>> library(tools)
>>>> showNonASCII("ggplot(df, aes(x = x)) + geom_histogram(aes(y =
>>>> ..density..)), binwidth = 1, colour = "black", fill = "white")")
>>>> 
>>>> Results
>>>> Error: unexpected symbol in:
>>>> "showNonASCII("ggplot(df, aes(x = x)) + geom_histogram(aes(y =
>>>> ..density..)), binwidth = 1, colour = "black"
>>> 
>>> You get that error because you're using double quotes around a string
>>> containing double quotes, and not escaping them.  With that string,
>>> using single quotes on the outside should be fine:
>>> 
>>>    showNonASCII('ggplot(df, aes(x = x)) + geom_histogram(aes(y =
>>> ..density..)), binwidth = 1, colour = "black", fill = "white")')
>>> 
>>> Duncan Murdoch
>>>> 
>>>> 
>>>> 
>>>> John Kane
>>>> Kingston ON Canada
>>>> 
>>>> 
>>>>> -----Original Message-----
>>>>> From: rmh at temple.edu
>>>>> Sent: Mon, 23 Dec 2013 11:44:42 -0500
>>>>> To: jrkrideau at inbox.com
>>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>> 
>>>>> If the problem seems to be non-ASCII characters, then the first
>>>>> investigation
>>>>> step is to use the R functions
>>>>> 
>>>>> ?tools::showNonASCII
>>>>> ?tools::showNonASCIIfile
>>>>> 
>>>>> On Mon, Dec 23, 2013 at 11:37 AM, John Kane <jrkrideau at inbox.com>
>>>>> wrote:
>>>>>> Same result here with the same error message mentioned in my first
>>>>>> post.
>>>>>> I tried it in Texmaker which is my usual Latex editor, not that I do
>>>>>> much in Latex, and then tried it in RStudio and it is still choking.
>>>>>> 
>>>>>> Interestingly EMACS will process it and produce a pdf but it simply
>>>>>> produces.  It also provides this warning: : Latex Warning; Reference
>>>>>> 'fig:plot-figheight' undefined on page 2 on input line 14.
>>>>>> 
>>>>>> It seems to repeat the same message for each of the other figures.
>>>>>> 
>>>>>> John Kane
>>>>>> Kingston ON Canada
>>>>>> 
>>>>>> 
>>>>>>> -----Original Message-----
>>>>>>> From: dulcalma at bigpond.com
>>>>>>> Sent: Mon, 23 Dec 2013 22:28:33 +1000
>>>>>>> To: daniel.haugstvedt at gmail.com, r-help at r-project.org
>>>>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>>>> 
>>>>>>> Hi Dan
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> I think you still have problems with embedded characters or some
>>>>>>> problems
>>>>>>> in
>>>>>>> char code page conversion or the like.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Not knowing knitr but Sweave I cobbled the figures manually and ran
>>>>>>> the
>>>>>>> sweave file to produce the latex file.
>>>>>>> 
>>>>>>> Latex was consistently stopping at the \caption and \ref functions
>>>>>>> 
>>>>>>> I tried to see what was happening I added hyperref & when I copied
>>>>>>> the
>>>>>>> text
>>>>>>> to hyperref  latex bailed up
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> I tried a minimal latex file without problems
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> I put the \title etc in the preamble. Some compilers need this
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Duncan
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> From: Daniel Haugstvedt [mailto:daniel.haugstvedt at gmail.com]
>>>>>>> Sent: Monday, 23 December 2013 20:10
>>>>>>> To: Duncan Mackay
>>>>>>> Cc: John Kane; R
>>>>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> I am really sorry for posting a non-working example. It is running
>>>>>>> when
>>>>>>> I
>>>>>>> cut the code from my previous mail into a clean session in RStudio
>>>>>>> (OSX).
>>>>>>> However, I suspect that you are right. I did cut and paste some
>>>>>>> code
>>>>>>> from
>>>>>>> a
>>>>>>> forum yesterday which had characters that had to be replaced. I
>>>>>>> gave
>>>>>>> emacs a
>>>>>>> try, but could not find the problem there either.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> The code below was pasted though textEdit and converted to plain
>>>>>>> text.
>>>>>>> I
>>>>>>> hope this takes care of any embedded characters.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> \documentclass{article}
>>>>>>> 
>>>>>>> \begin{document}
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> <<setup, include=FALSE, cache=FALSE>>=
>>>>>>> 
>>>>>>> library(knitr)
>>>>>>> 
>>>>>>> library(ggplot2)
>>>>>>> 
>>>>>>> @
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> \title{Knitr and ggplot2}
>>>>>>> 
>>>>>>> \author{Daniel Haugstvedt}
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> \maketitle
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> There are four plots in this article. Figure
>>>>>>> \ref{fig:plot-figHeight}
>>>>>>> uses
>>>>>>> 
>>>>>>> the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>>>>>>> 
>>>>>>> used both fig.height=2.5 and fig.width=3. The later option makes
>>>>>>> the
>>>>>>> font
>>>>>>> 
>>>>>>> too big.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> An alternative approach is used in Figures
>>>>>>> \ref{fig:plot-figOutWidthBig}
>>>>>>> and
>>>>>>> 
>>>>>>>    \ref{fig:plot-figOutWidthSmall}. There the argument out.width is
>>>>>>> set
>>>>>>> to
>>>>>>> 
>>>>>>>    12 and 8 cm respectively. This stops the problem of excessively
>>>>>>> large
>>>>>>> fonts
>>>>>>> 
>>>>>>>    for figures with smaller width, but there is still no
>>>>>>> consistency
>>>>>>> 
>>>>>>>    across plots in terms o font size.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>>>>>>> with
>>>>>>> no
>>>>>>> fig.width argument", results='hide', fig.pos='ht'>>=
>>>>>>> 
>>>>>>> df = data.frame(x = rnorm(100), y = 1:100)
>>>>>>> 
>>>>>>> ggplot(df, aes(x = x)) +
>>>>>>> 
>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>> 
>>>>>>>                    binwidth = 1, colour = "black", fill = "white")
>>>>>>> +
>>>>>>> 
>>>>>>>     xlab("Improvement, %") +
>>>>>>> 
>>>>>>>     ylab("Density") +
>>>>>>> 
>>>>>>>     theme_classic()
>>>>>>> 
>>>>>>> @
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>>>>>>> fig.cap="Density
>>>>>>> plot with fig.width=3", fig.pos='ht'>>=
>>>>>>> 
>>>>>>> ggplot(df, aes(x = x)) +
>>>>>>> 
>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>> 
>>>>>>>                    binwidth = 1, colour = "black", fill = "white")
>>>>>>> +
>>>>>>> 
>>>>>>>     xlab("Improvement, %") +
>>>>>>> 
>>>>>>>     ylab("Density") +
>>>>>>> 
>>>>>>>     theme_classic()
>>>>>>> 
>>>>>>> @
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width =
>>>>>>> "12cm",
>>>>>>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
>>>>>>> 
>>>>>>> ggplot(df, aes(x = x)) +
>>>>>>> 
>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>> 
>>>>>>>                    binwidth = 1, colour = "black", fill = "white")
>>>>>>> +
>>>>>>> 
>>>>>>>     xlab("Improvement, %") +
>>>>>>> 
>>>>>>>     ylab("Density") +
>>>>>>> 
>>>>>>>     theme_classic()
>>>>>>> 
>>>>>>> @
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
>>>>>>> "8cm",
>>>>>>> fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>>>>>> 
>>>>>>> ggplot(df, aes(x = x)) +
>>>>>>> 
>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>> 
>>>>>>>                    binwidth = 1, colour = "black", fill = "white")
>>>>>>> +
>>>>>>> 
>>>>>>>     xlab("Improvement, %") +
>>>>>>> 
>>>>>>>     ylab("Density") +
>>>>>>> 
>>>>>>>     theme_classic()
>>>>>>> 
>>>>>>> @
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> \end{document}
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> On Sun, Dec 22, 2013 at 11:59 PM, Duncan Mackay
>>>>>>> <dulcalma at bigpond.com>
>>>>>>> wrote:
>>>>>>> 
>>>>>>> Hi Daniel
>>>>>>> I tried it in Sweave after modifying it for Sweave and a similar
>>>>>>> thing
>>>>>>> for
>>>>>>> Latex but R crashed.
>>>>>>> 
>>>>>>> I think there is an embedded character/s before the first chunk and
>>>>>>> in
>>>>>>> the
>>>>>>> first chunk.
>>>>>>> 
>>>>>>> Duncan
>>>>>>> 
>>>>>>> Duncan Mackay
>>>>>>> Department of Agronomy and Soil Science
>>>>>>> University of New England
>>>>>>> Armidale NSW 2351
>>>>>>> Email: home: mackay at northnet.com.au
>>>>>>> 
>>>>>>> 
>>>>>>> -----Original Message-----
>>>>>>> From: r-help-bounces at r-project.org
>>>>>>> [mailto:r-help-bounces at r-project.org]
>>>>>>> On
>>>>>>> Behalf Of John Kane
>>>>>>> Sent: Monday, 23 December 2013 04:19
>>>>>>> To: Daniel Haugstvedt; r-help at r-project.org
>>>>>>> Subject: Re: [R] Knitr, ggplot and consistent fonts
>>>>>>> 
>>>>>>> Hi Daniel,
>>>>>>> 
>>>>>>> For some reason I cannot get your example to work. The problem is
>>>>>>> in
>>>>>>> the
>>>>>>> code chunk but I have no idea what is happening. The code is
>>>>>>> running
>>>>>>> perfectly in R, itself but LaTeX seems to be choking when it hits
>>>>>>> the
>>>>>>> first
>>>>>>> ggplot statement, that is the one in <<plot-figHeight>>=
>>>>>>> 
>>>>>>> The message I am getting is: "Missing $ inserted <inserted text> $
>>>>>>> ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not
>>>>>>> enough
>>>>>>> to
>>>>>>> figure out the problem.
>>>>>>> 
>>>>>>> I tried stripping out most of the LaTeX specific verbiage in the
>>>>>>> code
>>>>>>> chunk
>>>>>>> and running the code in LyX which I use rather than plain vanilla
>>>>>>> LaTeX
>>>>>>> and
>>>>>>> I still cannot get it to work. It is almost as if there is some
>>>>>>> hidden
>>>>>>> character in the in that piece of code since I can duplicate the
>>>>>>> code
>>>>>>> myself
>>>>>>> and I even pasted in most of the geom_histogram code into my code
>>>>>>> chunk
>>>>>>> and
>>>>>>> it runs.
>>>>>>> 
>>>>>>> John Kane
>>>>>>> Kingston ON Canada
>>>>>>> 
>>>>>>> 
>>>>>>>> -----Original Message-----
>>>>>>>> From: daniel.haugstvedt at gmail.com
>>>>>>>> Sent: Sun, 22 Dec 2013 12:42:50 +0100
>>>>>>>> To: r-help at r-project.org
>>>>>>>> Subject: [R] Knitr, ggplot and consistent fonts
>>>>>>>> 
>>>>>>>> Dear R-help
>>>>>>>> 
>>>>>>>> I am using Knitr and ggplot to draft an article and have now
>>>>>>>> started
>>>>>>>> to improve on the layout and graphics. So far I have not been able
>>>>>>>> to
>>>>>>>> maintain the same font size for labels in all my figures.
>>>>>>>> 
>>>>>>>> My goal is to be able to change the width of the figures while
>>>>>>>> maintaining the same font. This works for the height parameter
>>>>>>>> (example not included).
>>>>>>>> 
>>>>>>>> In the true document I also use tikz, but the problem can be
>>>>>>>> reproduced without it.
>>>>>>>> 
>>>>>>>> I know the question is very specific, but my understanding is that
>>>>>>>> this combination of packages  is common. (They are really great.
>>>>>>>> Keep
>>>>>>>> up the good work.)  There has to be others facing the same problem
>>>>>>>> and
>>>>>>>> someone must have found a nice solution.
>>>>>>>> 
>>>>>>>> Additional attempts from my side which failed are not included in
>>>>>>>> the
>>>>>>>> example. I have tested the Google results i could find without any
>>>>>>>> luck.
>>>>>>>> 
>>>>>>>> Cheers
>>>>>>>> Daniel
>>>>>>>> 
>>>>>>>> PS. I know the example plots could have been smaller, but they
>>>>>>>> just
>>>>>>>> became too ugly for me
>>>>>>>> 
>>>>>>>> 
>>>>>>>> \documentclass{article}
>>>>>>>> \begin{document}
>>>>>>>> 
>>>>>>>> <<setup, include=FALSE, cache=FALSE>>=
>>>>>>>> library(knitr)
>>>>>>>> library(ggplot2)
>>>>>>>> @
>>>>>>>> 
>>>>>>>> \title{Knitr and ggplot2}
>>>>>>>> \author{Daniel Haugstvedt}
>>>>>>>> 
>>>>>>>> \maketitle
>>>>>>>> 
>>>>>>>> There are four plots in this article. Figure
>>>>>>>> \ref{fig:plot-figHeight}
>>>>>>>> uses the argument fig.height=2.5 while Figures
>>>>>>>> \ref{fig:plot-figWidth}
>>>>>>>> used both fig.height=2.5 and fig.width=3. The later option makes
>>>>>>>> the
>>>>>>>> font too big.
>>>>>>>> 
>>>>>>>> An alternative approach is used in Figures
>>>>>>>> \ref{fig:plot-figOutWidthBig} and
>>>>>>>> \ref{fig:plot-figOutWidthSmall}.
>>>>>>>> There the argument out.width is set to
>>>>>>>>    12 and 8 cm respectively. This stops the problem of excessively
>>>>>>>> large
>>>>>>>> fonts  for figures with smaller width, but there is still no
>>>>>>>> consistency  across plots in terms of font size.
>>>>>>>> 
>>>>>>>> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density
>>>>>>>> plot
>>>>>>>> with no fig.width argument", fig.pos='ht'>>= df = data.frame(x =
>>>>>>>> rnorm(100), y = 1:100) ggplot(df, aes(x = x)) +
>>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>>>                    binwidth = 1, colour = "black", fill = "white")
>>>>>>>> +
>>>>>>>>     xlab("Improvement, %") +
>>>>>>>>     ylab("Density") +
>>>>>>>>     theme_classic()
>>>>>>>> @
>>>>>>>> 
>>>>>>>> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>>>>>>>> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>=
>>>>>>>> ggplot(df,
>>>>>>>> aes(x = x)) +
>>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>>>                    binwidth = 1, colour = "black", fill = "white")
>>>>>>>> +
>>>>>>>>     xlab("Improvement, %") +
>>>>>>>>     ylab("Density") +
>>>>>>>>     theme_classic()
>>>>>>>> @
>>>>>>>> 
>>>>>>>> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width =
>>>>>>>> "12cm",
>>>>>>>> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
>>>>>>>> ggplot(df,
>>>>>>>> aes(x = x)) +
>>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>>>                    binwidth = 1, colour = "black", fill = "white")
>>>>>>>> +
>>>>>>>>     xlab("Improvement, %") +
>>>>>>>>     ylab("Density") +
>>>>>>>>     theme_classic()
>>>>>>>> @
>>>>>>>> 
>>>>>>>> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
>>>>>>>> "8cm", fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>>>>>>>> ggplot(df, aes(x = x)) +
>>>>>>>>     geom_histogram(aes(y = ..density..),
>>>>>>>>                    binwidth = 1, colour = "black", fill = "white")
>>>>>>>> +
>>>>>>>>     xlab("Improvement, %") +
>>>>>>>>     ylab("Density") +
>>>>>>>>     theme_classic()
>>>>>>>> @
>>>>>>>> 
>>>>>>>> \end{document}
>>>>>>>> 
>>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>>> ____________________________________________________________
>>>>>>> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
>>>>>>> http://www.inbox.com/smileys Works with AIMR, MSNR Messenger,
>>>>>>> Yahoo!R
>>>>>>> Messenger, ICQR, Google TalkT and most webmails
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> ____________________________________________________________
>>>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas
>>>>>> on
>>>>>> your desktop!
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ____________________________________________________________
>>>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>>>> and family!
>>>> Visit http://www.inbox.com/photosharing to find out more!
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>> 
>> ____________________________________________________________
>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
>> your desktop!
>> Check it out at http://www.inbox.com/marineaquarium
>> 
>> 
>

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From emorway at usgs.gov  Mon Dec 23 22:46:19 2013
From: emorway at usgs.gov (Morway, Eric)
Date: Mon, 23 Dec 2013 13:46:19 -0800
Subject: [R] Inserting color into an irregular grid comprised of polygons
In-Reply-To: <02af01cf0011$fde65b10$f9b31130$@tamu.edu>
References: <CAPoqHzqiri47Q3OUfdqSnCm3qqKqk4SDj10xL54SMnMVq3BOhQ@mail.gmail.com>
	<02af01cf0011$fde65b10$f9b31130$@tamu.edu>
Message-ID: <CAPoqHzruA1RZSpqHmFh63ssqVyuUeXemajMFyCDRsCkVh=jSTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131223/b95b57f2/attachment.pl>

From xie at yihui.name  Mon Dec 23 23:20:31 2013
From: xie at yihui.name (Yihui Xie)
Date: Mon, 23 Dec 2013 16:20:31 -0600
Subject: [R] Knitr, ggplot and consistent fonts
In-Reply-To: <CAE8W1T1CagaJnenBpPLkdDwmf_e7A0R4tJVT8X5=-uU1pBLOYg@mail.gmail.com>
References: <cankvva3sqzk8nxa0kemg=npe2puj+mqnfqsu-7m1kvasn7t2aw@mail.gmail.com>
	<d16683c5446.00000494jrkrideau@inbox.com>
	<cankvva3ey2ruu-2cojsvk2uqhxjusdyg_d-nrcedbxxwzp6z1a@mail.gmail.com>
	<001201ceff69$6a46d900$3ed48b00$@bigpond.com>
	<001c01ceffda$7fa36090$7eea21b0$@bigpond.com>
	<DD14B2ACA2B.00000424jrkrideau@inbox.com>
	<CAE8W1T1CagaJnenBpPLkdDwmf_e7A0R4tJVT8X5=-uU1pBLOYg@mail.gmail.com>
Message-ID: <CANROs4f08yfjfdxEAbunnVdE=G3jLdSj48nvweZF_eg08wehEQ@mail.gmail.com>

I believe you are right. We thank either Gmail or [[alternative HTML
version deleted]] for this. I think showNonASCII() is just irrelevant
here and pulling us to the wrong direction.

It is not reliable to paste code into Email due to the potentially
wrong text wrapping. Please consider an email attachment (not sure if
an Rnw document can get through), or a Github gist, or pastebin
instead, e.g. https://gist.github.com/yihui/8105762 Or ask on SO:
http://stackoverflow.com/questions/tagged/r

Now let's move back to the original question, to which I have no solution.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Mon, Dec 23, 2013 at 10:53 AM, Federico Lasa <felasa at gmail.com> wrote:
> Hi, chiming in.
> Pasted the code in R studio and the format parser wouldn't mark the R code
> chunks. It was because there were line breaks in the middle of chunk
> options tags.  Couldn't test if removing line breaks works, but maybe
> that's the source of the problem?
>
>
> On Mon, Dec 23, 2013 at 10:37 AM, John Kane <jrkrideau at inbox.com> wrote:
>
>> Same result here with the same error message mentioned in my first post.
>>  I tried it in Texmaker which is my usual Latex editor, not that I do much
>> in Latex, and then tried it in RStudio and it is still choking.
>>
>> Interestingly EMACS will process it and produce a pdf but it simply
>> produces.  It also provides this warning: : Latex Warning; Reference
>> 'fig:plot-figheight' undefined on page 2 on input line 14.
>>
>> It seems to repeat the same message for each of the other figures.
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>> > -----Original Message-----
>> > From: dulcalma at bigpond.com
>> > Sent: Mon, 23 Dec 2013 22:28:33 +1000
>> > To: daniel.haugstvedt at gmail.com, r-help at r-project.org
>> > Subject: Re: [R] Knitr, ggplot and consistent fonts
>> >
>> > Hi Dan
>> >
>> >
>> >
>> > I think you still have problems with embedded characters or some problems
>> > in
>> > char code page conversion or the like.
>> >
>> >
>> >
>> > Not knowing knitr but Sweave I cobbled the figures manually and ran the
>> > sweave file to produce the latex file.
>> >
>> > Latex was consistently stopping at the \caption and \ref functions
>> >
>> > I tried to see what was happening I added hyperref & when I copied the
>> > text
>> > to hyperref  latex bailed up
>> >
>> >
>> >
>> > I tried a minimal latex file without problems
>> >
>> >
>> >
>> > I put the \title etc in the preamble. Some compilers need this
>> >
>> >
>> >
>> > Duncan
>> >
>> >
>> >
>> > From: Daniel Haugstvedt [mailto:daniel.haugstvedt at gmail.com]
>> > Sent: Monday, 23 December 2013 20:10
>> > To: Duncan Mackay
>> > Cc: John Kane; R
>> > Subject: Re: [R] Knitr, ggplot and consistent fonts
>> >
>> >
>> >
>> > I am really sorry for posting a non-working example. It is running when I
>> > cut the code from my previous mail into a clean session in RStudio (OSX).
>> > However, I suspect that you are right. I did cut and paste some code from
>> > a
>> > forum yesterday which had characters that had to be replaced. I gave
>> > emacs a
>> > try, but could not find the problem there either.
>> >
>> >
>> >
>> > The code below was pasted though textEdit and converted to plain text. I
>> > hope this takes care of any embedded characters.
>> >
>> >
>> >
>> > \documentclass{article}
>> >
>> > \begin{document}
>> >
>> >
>> >
>> > <<setup, include=FALSE, cache=FALSE>>=
>> >
>> > library(knitr)
>> >
>> > library(ggplot2)
>> >
>> > @
>> >
>> >
>> >
>> > \title{Knitr and ggplot2}
>> >
>> > \author{Daniel Haugstvedt}
>> >
>> >
>> >
>> > \maketitle
>> >
>> >
>> >
>> > There are four plots in this article. Figure \ref{fig:plot-figHeight}
>> > uses
>> >
>> > the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>> >
>> > used both fig.height=2.5 and fig.width=3. The later option makes the font
>> >
>> > too big.
>> >
>> >
>> >
>> > An alternative approach is used in Figures  \ref{fig:plot-figOutWidthBig}
>> > and
>> >
>> >  \ref{fig:plot-figOutWidthSmall}. There the argument out.width is set to
>> >
>> >  12 and 8 cm respectively. This stops the problem of excessively large
>> > fonts
>> >
>> >  for figures with smaller width, but there is still no consistency
>> >
>> >  across plots in terms o font size.
>> >
>> >
>> >
>> > <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot with
>> > no
>> > fig.width argument", results='hide', fig.pos='ht'>>=
>> >
>> > df = data.frame(x = rnorm(100), y = 1:100)
>> >
>> > ggplot(df, aes(x = x)) +
>> >
>> >   geom_histogram(aes(y = ..density..),
>> >
>> >                  binwidth = 1, colour = "black", fill = "white") +
>> >
>> >   xlab("Improvement, %") +
>> >
>> >   ylab("Density") +
>> >
>> >   theme_classic()
>> >
>> > @
>> >
>> >
>> >
>> > <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>> > fig.cap="Density
>> > plot with fig.width=3", fig.pos='ht'>>=
>> >
>> > ggplot(df, aes(x = x)) +
>> >
>> >   geom_histogram(aes(y = ..density..),
>> >
>> >                  binwidth = 1, colour = "black", fill = "white") +
>> >
>> >   xlab("Improvement, %") +
>> >
>> >   ylab("Density") +
>> >
>> >   theme_classic()
>> >
>> > @
>> >
>> >
>> >
>> > <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
>> > fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>=
>> >
>> > ggplot(df, aes(x = x)) +
>> >
>> >   geom_histogram(aes(y = ..density..),
>> >
>> >                  binwidth = 1, colour = "black", fill = "white") +
>> >
>> >   xlab("Improvement, %") +
>> >
>> >   ylab("Density") +
>> >
>> >   theme_classic()
>> >
>> > @
>> >
>> >
>> >
>> > <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width = "8cm",
>> > fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>> >
>> > ggplot(df, aes(x = x)) +
>> >
>> >   geom_histogram(aes(y = ..density..),
>> >
>> >                  binwidth = 1, colour = "black", fill = "white") +
>> >
>> >   xlab("Improvement, %") +
>> >
>> >   ylab("Density") +
>> >
>> >   theme_classic()
>> >
>> > @
>> >
>> >
>> >
>> > \end{document}
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > On Sun, Dec 22, 2013 at 11:59 PM, Duncan Mackay <dulcalma at bigpond.com>
>> > wrote:
>> >
>> > Hi Daniel
>> > I tried it in Sweave after modifying it for Sweave and a similar thing
>> > for
>> > Latex but R crashed.
>> >
>> > I think there is an embedded character/s before the first chunk and in
>> > the
>> > first chunk.
>> >
>> > Duncan
>> >
>> > Duncan Mackay
>> > Department of Agronomy and Soil Science
>> > University of New England
>> > Armidale NSW 2351
>> > Email: home: mackay at northnet.com.au
>> >
>> >
>> > -----Original Message-----
>> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> > On
>> > Behalf Of John Kane
>> > Sent: Monday, 23 December 2013 04:19
>> > To: Daniel Haugstvedt; r-help at r-project.org
>> > Subject: Re: [R] Knitr, ggplot and consistent fonts
>> >
>> > Hi Daniel,
>> >
>> > For some reason I cannot get your example to work. The problem is in the
>> > code chunk but I have no idea what is happening. The code is running
>> > perfectly in R, itself but LaTeX seems to be choking when it hits the
>> > first
>> > ggplot statement, that is the one in <<plot-figHeight>>=
>> >
>> > The message I am getting is: "Missing $ inserted <inserted text> $
>> > ggplot(df, aes(x=x)) = geom_" and my knowledge of LateX is not enough to
>> > figure out the problem.
>> >
>> > I tried stripping out most of the LaTeX specific verbiage in the code
>> > chunk
>> > and running the code in LyX which I use rather than plain vanilla LaTeX
>> > and
>> > I still cannot get it to work. It is almost as if there is some hidden
>> > character in the in that piece of code since I can duplicate the code
>> > myself
>> > and I even pasted in most of the geom_histogram code into my code chunk
>> > and
>> > it runs.
>> >
>> > John Kane
>> > Kingston ON Canada
>> >
>> >
>> >> -----Original Message-----
>> >> From: daniel.haugstvedt at gmail.com
>> >> Sent: Sun, 22 Dec 2013 12:42:50 +0100
>> >> To: r-help at r-project.org
>> >> Subject: [R] Knitr, ggplot and consistent fonts
>> >>
>> >> Dear R-help
>> >>
>> >> I am using Knitr and ggplot to draft an article and have now started
>> >> to improve on the layout and graphics. So far I have not been able to
>> >> maintain the same font size for labels in all my figures.
>> >>
>> >> My goal is to be able to change the width of the figures while
>> >> maintaining the same font. This works for the height parameter
>> >> (example not included).
>> >>
>> >> In the true document I also use tikz, but the problem can be
>> >> reproduced without it.
>> >>
>> >> I know the question is very specific, but my understanding is that
>> >> this combination of packages  is common. (They are really great. Keep
>> >> up the good work.)  There has to be others facing the same problem and
>> >> someone must have found a nice solution.
>> >>
>> >> Additional attempts from my side which failed are not included in the
>> >> example. I have tested the Google results i could find without any luck.
>> >>
>> >> Cheers
>> >> Daniel
>> >>
>> >> PS. I know the example plots could have been smaller, but they just
>> >> became too ugly for me
>> >>
>> >>
>> >> \documentclass{article}
>> >> \begin{document}
>> >>
>> >> <<setup, include=FALSE, cache=FALSE>>=
>> >> library(knitr)
>> >> library(ggplot2)
>> >> @
>> >>
>> >> \title{Knitr and ggplot2}
>> >> \author{Daniel Haugstvedt}
>> >>
>> >> \maketitle
>> >>
>> >> There are four plots in this article. Figure \ref{fig:plot-figHeight}
>> >> uses the argument fig.height=2.5 while Figures \ref{fig:plot-figWidth}
>> >> used both fig.height=2.5 and fig.width=3. The later option makes the
>> >> font too big.
>> >>
>> >> An alternative approach is used in Figures
>> >> \ref{fig:plot-figOutWidthBig} and  \ref{fig:plot-figOutWidthSmall}.
>> >> There the argument out.width is set to
>> >>  12 and 8 cm respectively. This stops the problem of excessively large
>> >> fonts  for figures with smaller width, but there is still no
>> >> consistency  across plots in terms of font size.
>> >>
>> >> <<plot-figHeight, echo=FALSE, fig.height=2.5, fig.cap="Density plot
>> >> with no fig.width argument", fig.pos='ht'>>= df = data.frame(x =
>> >> rnorm(100), y = 1:100) ggplot(df, aes(x = x)) +
>> >>   geom_histogram(aes(y = ..density..),
>> >>                  binwidth = 1, colour = "black", fill = "white") +
>> >>   xlab("Improvement, %") +
>> >>   ylab("Density") +
>> >>   theme_classic()
>> >> @
>> >>
>> >> <<plot-figWidth, echo=FALSE, fig.height=2.5, fig.width = 3,
>> >> fig.cap="Density plot with fig.width=3", fig.pos='ht'>>= ggplot(df,
>> >> aes(x = x)) +
>> >>   geom_histogram(aes(y = ..density..),
>> >>                  binwidth = 1, colour = "black", fill = "white") +
>> >>   xlab("Improvement, %") +
>> >>   ylab("Density") +
>> >>   theme_classic()
>> >> @
>> >>
>> >> <<plot-figOutWidthBig, echo=FALSE, fig.height=2.5, out.width = "12cm",
>> >> fig.cap="Density plot with out.width=12cm", fig.pos='ht'>>= ggplot(df,
>> >> aes(x = x)) +
>> >>   geom_histogram(aes(y = ..density..),
>> >>                  binwidth = 1, colour = "black", fill = "white") +
>> >>   xlab("Improvement, %") +
>> >>   ylab("Density") +
>> >>   theme_classic()
>> >> @
>> >>
>> >> <<plot-figOutWidthSmall, echo=FALSE, fig.height=2.5, out.width =
>> >> "8cm", fig.cap="Density plot with out.width=8cm", fig.pos='ht'>>=
>> >> ggplot(df, aes(x = x)) +
>> >>   geom_histogram(aes(y = ..density..),
>> >>                  binwidth = 1, colour = "black", fill = "white") +
>> >>   xlab("Improvement, %") +
>> >>   ylab("Density") +
>> >>   theme_classic()
>> >> @
>> >>
>> >> \end{document}
>> >>
>> >>       [[alternative HTML version deleted]]

From dcarlson at tamu.edu  Mon Dec 23 23:30:27 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 23 Dec 2013 16:30:27 -0600
Subject: [R] Inserting color into an irregular grid comprised of polygons
In-Reply-To: <CAPoqHzruA1RZSpqHmFh63ssqVyuUeXemajMFyCDRsCkVh=jSTA@mail.gmail.com>
References: <CAPoqHzqiri47Q3OUfdqSnCm3qqKqk4SDj10xL54SMnMVq3BOhQ@mail.gmail.com>	<02af01cf0011$fde65b10$f9b31130$@tamu.edu>
	<CAPoqHzruA1RZSpqHmFh63ssqVyuUeXemajMFyCDRsCkVh=jSTA@mail.gmail.com>
Message-ID: <001401cf002e$949b1200$bdd13600$@tamu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131223/140705e1/attachment.pl>

From n.l.pace at utah.edu  Tue Dec 24 01:31:33 2013
From: n.l.pace at utah.edu (Nathan Pace)
Date: Tue, 24 Dec 2013 00:31:33 +0000
Subject: [R] svycoxph
In-Reply-To: <CEDE06EF.211B1%n.l.pace@utah.edu>
References: <CEDE06EF.211B1%n.l.pace@utah.edu>
Message-ID: <CEDE24C3.211CB%n.l.pace@utah.edu>


>The svycoxph function in the survey package loads the survival package and
>produces objects of class svycoxph and coxph.
>
>The print.coxph function - print(coxph.object, conf.int = 0.95) - in the
>survival package lists the values of the coxph object including the hazard
>ratios with 95% CIs.
>
>When applied to svycoxph/coxph objects, print(svycoxph.object, conf.int =
>0.95) does not list the 95% CIs.
>
>Using the call print.coxph(svycoxph.object, conf.int = 0.95) returns the
>error that print.coxph can?t be found.
>
>I have tried various arguments in print(predict(svycoxph.object, se = T,
>type = ?)), but without returning the CIs.
>
>Any suggestions on the correct syntax will be appreciated.
>
>Nathan
>
>-- 
>Nathan Pace, MD, MStat
>Department of Anesthesiology
>University of Utah
>801.581.6393
>n.l.pace at utah.edu
>
>


From jim at bitwrit.com.au  Tue Dec 24 03:37:42 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 24 Dec 2013 13:37:42 +1100
Subject: [R] Fwd: Calculating group means
In-Reply-To: <94BBEA78-3B6F-43B0-8669-3C7D3D64D74C@aber.ac.uk>
References: <B456B369-7201-43EB-BA83-9633CFD1A5BF@hotmail.com>
	<94BBEA78-3B6F-43B0-8669-3C7D3D64D74C@aber.ac.uk>
Message-ID: <52B8F376.50109@bitwrit.com.au>

On 12/23/2013 11:31 PM, Laura Bethan Thomas [lbt1] wrote:
>> Hi All,
>>
>> Sorry for what I imagine is quite a basic question. I have been trying to do is create latency averages for each state (1-8) for each participant (n=13) in each condition (1-10). I'm not sure what function I would need, or what the most efficient ay of calculating this would be. If you have any help with that I would be very grateful.
>>
>> structure(list(subject = c(1L, 1L, 1L, 1L, 1L, 1L), conditionNo = c(1L,
>> 1L, 1L, 1L, 1L, 1L), state = c(5L, 8L, 7L, 8L, 1L, 7L), latency = c(869L,
>> 864L, 1004L, 801L, 611L, 679L)), .Names = c("subject", "conditionNo",
>> "state", "latency"), row.names = 3:8, class = "data.frame")
>>
Hi Laura,
You can do it like this:

# make up enough data to do the calculation
lbtdat<-data.frame(subject=rep(1:13,each=160),
  condition=rep(rep(rep(1:10,each=8),2),13),
  state=rep(rep(1:8,20),13),
  latency=sample(600:1100,2080,TRUE))
by(lbtdat$latency,list(lbtdat$subject,
  lbtdat$condition,lbtdat$state),mean)

but you are going to get a rather long list of means.

Jim


From n.l.pace at utah.edu  Tue Dec 24 04:41:35 2013
From: n.l.pace at utah.edu (Nathan Pace)
Date: Tue, 24 Dec 2013 03:41:35 +0000
Subject: [R] svycoxph
Message-ID: <CEDE505F.515A%u0034942@umail.utah.edu>

Answered my own question.

In survey, summary does it.

On 2312//2013, 5:31 PM, "Nathan Pace" <n.l.pace at utah.edu> wrote:

>
>>The svycoxph function in the survey package loads the survival package
>>and
>>produces objects of class svycoxph and coxph.
>>
>>The print.coxph function - print(coxph.object, conf.int = 0.95) - in the
>>survival package lists the values of the coxph object including the
>>hazard
>>ratios with 95% CIs.
>>
>>When applied to svycoxph/coxph objects, print(svycoxph.object, conf.int =
>>0.95) does not list the 95% CIs.
>>
>>Using the call print.coxph(svycoxph.object, conf.int = 0.95) returns the
>>error that print.coxph can?t be found.
>>
>>I have tried various arguments in print(predict(svycoxph.object, se = T,
>>type = ?)), but without returning the CIs.
>>
>>Any suggestions on the correct syntax will be appreciated.
>>
>>Nathan
>>
>>-- 
>>Nathan Pace, MD, MStat
>>Department of Anesthesiology
>>University of Utah
>>801.581.6393
>>n.l.pace at utah.edu
>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Dec 24 08:28:08 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 23 Dec 2013 23:28:08 -0800
Subject: [R] Fwd: Calculating group means
In-Reply-To: <52B8F376.50109@bitwrit.com.au>
References: <B456B369-7201-43EB-BA83-9633CFD1A5BF@hotmail.com>
	<94BBEA78-3B6F-43B0-8669-3C7D3D64D74C@aber.ac.uk>
	<52B8F376.50109@bitwrit.com.au>
Message-ID: <CACk-te2DsLZyEnNPOOiZ7ebFXiBfb50w+b8EpS=Xs9C_Gxn3Jg@mail.gmail.com>

Jim:

Did you forget about with() ?

Instead of:

 by(lbtdat$latency,list(lbtdat$subject,
  lbtdat$condition,lbtdat$state),mean)

##do

with(ibtdat,by(latency,list(subject,condition,state),mean))


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Mon, Dec 23, 2013 at 6:37 PM, Jim Lemon <jim at bitwrit.com.au> wrote:
> On 12/23/2013 11:31 PM, Laura Bethan Thomas [lbt1] wrote:
>>>
>>> Hi All,
>>>
>>> Sorry for what I imagine is quite a basic question. I have been trying to
>>> do is create latency averages for each state (1-8) for each participant
>>> (n=13) in each condition (1-10). I'm not sure what function I would need, or
>>> what the most efficient ay of calculating this would be. If you have any
>>> help with that I would be very grateful.
>>>
>>> structure(list(subject = c(1L, 1L, 1L, 1L, 1L, 1L), conditionNo = c(1L,
>>> 1L, 1L, 1L, 1L, 1L), state = c(5L, 8L, 7L, 8L, 1L, 7L), latency = c(869L,
>>> 864L, 1004L, 801L, 611L, 679L)), .Names = c("subject", "conditionNo",
>>> "state", "latency"), row.names = 3:8, class = "data.frame")
>>>
> Hi Laura,
> You can do it like this:
>
> # make up enough data to do the calculation
> lbtdat<-data.frame(subject=rep(1:13,each=160),
>  condition=rep(rep(rep(1:10,each=8),2),13),
>  state=rep(rep(1:8,20),13),
>  latency=sample(600:1100,2080,TRUE))
> by(lbtdat$latency,list(lbtdat$subject,
>  lbtdat$condition,lbtdat$state),mean)
>
> but you are going to get a rather long list of means.
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wesleybell11 at yahoo.com  Tue Dec 24 16:38:05 2013
From: wesleybell11 at yahoo.com (wesley bell)
Date: Tue, 24 Dec 2013 07:38:05 -0800 (PST)
Subject: [R] Test to determine if there is a difference between two means
Message-ID: <1387899485.92025.YahooMailNeo@web141003.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131224/1261bb98/attachment.pl>

From saha.koushik2007 at gmail.com  Tue Dec 24 10:08:15 2013
From: saha.koushik2007 at gmail.com (Koushik Saha)
Date: Tue, 24 Dec 2013 14:38:15 +0530
Subject: [R] unique mismatch in R and Excel
Message-ID: <CAFGkLihZuT4ugAbfFMkwtnxtUN28N=RAgjcxNinW-wg4W17DHg@mail.gmail.com>

i have a wired problem. i want to count the unique entry in a certain
column.Here i have attached my csv file.

i am doing this to get the unique entries in the column.

dat<-read.csv("C:/Project/Gawk-scripts/Book1.csv")
names(dat)<-c("user_name")
unique(dat$user_name)

results says i have 170 unique values.


But i am doing "remove duplicate entries"  in excel i am having 147 unique
entries in the column.

Can anyone explain why there is a mismatch of the results or i am doing
something wrong.

Regards
Koushik

From nandini_dec6 at hotmail.com  Tue Dec 24 11:35:52 2013
From: nandini_dec6 at hotmail.com (Nandini Jayakumar)
Date: Tue, 24 Dec 2013 16:05:52 +0530
Subject: [R] Mean: category wise within a data frame
Message-ID: <COL126-W15FC31B41C87B376EE2E87AFC00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131224/f27bd674/attachment.pl>

From mamushbukana at gmail.com  Tue Dec 24 16:46:50 2013
From: mamushbukana at gmail.com (mamush bukana)
Date: Tue, 24 Dec 2013 13:46:50 -0200
Subject: [R] error in "ca.jo"
In-Reply-To: <52B88A4F.9040603@pburns.seanet.com>
References: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>
	<52B88A4F.9040603@pburns.seanet.com>
Message-ID: <CAFxDEqKyvR4y0Xg-LW8PDnn6O0NjAT2Mu+2-mrmy0rYkygMzJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131224/5d013e9b/attachment.pl>

From bbolker at gmail.com  Tue Dec 24 17:00:41 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Dec 2013 16:00:41 +0000
Subject: [R] Fitdistr and mle
References: <1387825583.42562.YahooMailNeo@web173205.mail.ir2.yahoo.com>
Message-ID: <loom.20131224T165535-1@post.gmane.org>

Tia Borrelli <tiaborrelli <at> yahoo.it> writes:

> 
> Hello, i'm using R for the exploration of a time series and i'm stuck in a
problem with the fitting of the distribution.
> What's the difference between "fitdistr" and "mle"?

  Hard to say without a reproducible example.  In the example below
the answers are not identical (different starting values etc.) but
they're closer than in your example.

  (I assume that what you're really doing is more complicated than
the trivial example shown here, since the MLEs of the Normal distribution
parameters are very easy ...)

set.seed(101)
ret <- rnorm(10000,mean=-1.5e-5,sd=1.69e-2)
MASS::fitdistr(ret,densfun="normal")
##        mean            sd     
##   7.419639e-05   1.678380e-02 
##  (1.678380e-04) (1.186794e-04)

library(stats4)
loglink <- function(media=0, devstd=1){
  -sum(dnorm(ret, mean=media, sd=devstd, log=TRUE))
}
mle(loglink)
##        media       devstd 
## 7.402637e-05 1.680457e-02 


> library(MASS)
> fitting <- fitdistr(ret,densfun="normal")
> print(c(mean(ret),sd(ret)))
> -------------------------------------------------------------
> The output of fitdistr is:?
> ? mean ? ? ? ? ? ? sd ? ? ?
> ? -1.526547e-05 ? ?1.692554e-02?
> ?( 5.105564e-04) ( 3.610179e-04)
> -------------------------------------------------------------
> 
> library(stats4)
> loglink <- function(media=0, devstd=1){
> ? -sum(dnorm(ret, mean=media, sd=devstd, log=TRUE))
> }
> mle(loglink)
> -------------------------------------------------------------
> 
> The output of mle is:
> Call:
> mle(minuslogl = loglink)
> 
> Coefficients:
> ? ? ? ? media ? ? ? ?devstd?
> -1.593559e-05 ?1.695075e-02?
> 
> Thank you for the help.


From dcarlson at tamu.edu  Tue Dec 24 17:14:07 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 24 Dec 2013 10:14:07 -0600
Subject: [R] Mean: category wise within a data frame
In-Reply-To: <COL126-W15FC31B41C87B376EE2E87AFC00@phx.gbl>
References: <COL126-W15FC31B41C87B376EE2E87AFC00@phx.gbl>
Message-ID: <007301cf00c3$2c4732c0$84d59840$@tamu.edu>

Please do not use html formatting in your messages to the list.
The format codes are stripped and you table becomes a single
long column (see below). Only use plain text emails and use the
results of dput(mydata) to insert your data into the message.

As to your question. Look at the aggregate() function:

?aggregate

David Carlson

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Nandini
Jayakumar
Sent: Tuesday, December 24, 2013 4:36 AM
To: r-help at r-project.org
Subject: [R] Mean: category wise within a data frame

Hello all

I have a table a sample of which is as follows:




	
	
	
	



	
	
	
	
		
			Categories

		
		
			Variable (x)

		
		
			Frequencies

		
	
	
		
			1

			1

			1

			1

			1

		
		
			0.009

			0.867

			0.567

			0.765

			0.445

		
		
			1003

			1200

			987

			134

			890

		
	
	
		
			2

			2

			2

			2

			2

		
		
			0.007

			0.768

			0.789

			0.544

			0.987

		
		
			899

			707

			865

			678

			889

		
	
	
		
			3

			3

			3

			3

			3

		
		
			0.898

			0.887

			0.560

			0.098

			0.987

		
		
			544

			677

			934

			467

			876

		
	
	
		
			40

			40

			40

			40

			40

		
		
			0.786

			0.342

			0.456

			0.987

			0.123

		
		
			843

			987

			675

			467

			223

		
	



Basically I have 40 categories and each category has several
hundred variables. I want to calculate the average per category,
that is variable * frequency/Summation of frequencies. I want to
do it for each category separately. Since i have many categories
i do not want to use the subset() function 40 times. Is it
possible to do it within a single data frame?

Really appreciate any help. Thank you.
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From gunter.berton at gene.com  Tue Dec 24 17:28:26 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 24 Dec 2013 08:28:26 -0800
Subject: [R] Test to determine if there is a difference between two means
In-Reply-To: <1387899485.92025.YahooMailNeo@web141003.mail.bf1.yahoo.com>
References: <1387899485.92025.YahooMailNeo@web141003.mail.bf1.yahoo.com>
Message-ID: <CACk-te2pxxVAs2adRc0afE9gZAwRHQwt=J3+z_ifpmufD0bf1g@mail.gmail.com>

Inline below.

 Cheers,

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Tue, Dec 24, 2013 at 7:38 AM, wesley bell <wesleybell11 at yahoo.com> wrote:
> Hi,
> I have a data set where there are 20 experiments which each ran for 10 minutes. In each experiment an insect had a choice to spend time in one of two chambers. Each experiment therefore has number of seconds spent in each chamber. I want to know whether there is a difference in the mean time spent in each chamber.

Yes, there is. Always.

>
> I was going to do a t-test but was advised that there was a better way, something about introducing random numbers? I was hoping someone could help?

This list is about R, not statistics, although they certainly overlap.
 I suggest you post on stats.stackexchange.com instead for statistics
help. Better yet, you might do well to talk with a local expert about
statistical issues, as you are obviously weak here.


> Thanks
> Wes
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kathryn.lord2000 at gmail.com  Tue Dec 24 18:04:39 2013
From: kathryn.lord2000 at gmail.com (Kathryn Lord)
Date: Wed, 25 Dec 2013 02:04:39 +0900
Subject: [R] replace NA with another vector
Message-ID: <CAMFx86zemt5pRQ0S13GjjFkwDeY8HExu164SOjxkq_8qqq0eAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131225/eec07f72/attachment.pl>

From murdoch.duncan at gmail.com  Tue Dec 24 18:11:46 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 24 Dec 2013 12:11:46 -0500
Subject: [R] unique mismatch in R and Excel
In-Reply-To: <CAFGkLihZuT4ugAbfFMkwtnxtUN28N=RAgjcxNinW-wg4W17DHg@mail.gmail.com>
References: <CAFGkLihZuT4ugAbfFMkwtnxtUN28N=RAgjcxNinW-wg4W17DHg@mail.gmail.com>
Message-ID: <52B9C052.2050602@gmail.com>

On 13-12-24 4:08 AM, Koushik Saha wrote:
> i have a wired problem. i want to count the unique entry in a certain
> column.Here i have attached my csv file.
>
> i am doing this to get the unique entries in the column.
>
> dat<-read.csv("C:/Project/Gawk-scripts/Book1.csv")
> names(dat)<-c("user_name")
> unique(dat$user_name)
>
> results says i have 170 unique values.
>
>
> But i am doing "remove duplicate entries"  in excel i am having 147 unique
> entries in the column.
>
> Can anyone explain why there is a mismatch of the results or i am doing
> something wrong.
>

Surely you can just compare the lists.  147 is not that many entries, 
and if they are sorted, it will be easy.

Duncan Murdoch

> Regards
> Koushik
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Tue Dec 24 18:08:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 24 Dec 2013 09:08:40 -0800 (PST)
Subject: [R] replace NA with another vector
In-Reply-To: <CAMFx86zemt5pRQ0S13GjjFkwDeY8HExu164SOjxkq_8qqq0eAA@mail.gmail.com>
References: <CAMFx86zemt5pRQ0S13GjjFkwDeY8HExu164SOjxkq_8qqq0eAA@mail.gmail.com>
Message-ID: <1387904920.55378.YahooMailNeo@web142604.mail.bf1.yahoo.com>

?z <- x
?z[is.na(z)] <- y
?z
#[1] 20 40? 3 50? 1


A.K.



On Tuesday, December 24, 2013 12:06 PM, Kathryn Lord <kathryn.lord2000 at gmail.com> wrote:
Dear R users,

I have two different vectors like below

x <- c( NA, NA, 3, NA, 1)
y <- c( 20, 40 ,50)

Combining x and y, I'd like to create new vector z

z <- c(20, 40, 3, 50, 1)


Any suggestion will be greatly appreciated.

Best,

Kathryn Lord

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Dec 24 18:21:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 24 Dec 2013 09:21:47 -0800 (PST)
Subject: [R] Mean: category wise within a data frame
In-Reply-To: <COL126-W15FC31B41C87B376EE2E87AFC00@phx.gbl>
References: <COL126-W15FC31B41C87B376EE2E87AFC00@phx.gbl>
Message-ID: <1387905707.8835.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,
May be this helps:


Please use ?dput() to show the example dataset
dat1 <- read.table(text="Categories? Variable Frequencies
1 0.009 1003
1 0.867 1200
1 0.567 987
1 0.765 134
1 0.445 890 
2 0.007 899?????????????? 
2 0.768 707??? 
2 0.789 865???? 
2 0.544? 678??????????? 
2? 0.987 889",sep="",header=TRUE)
library(plyr)
res <-? ddply(transform(dat1,NewCol=Variable*Frequencies),.(Categories),summarize, Avg=mean(NewCol/sum(Frequencies)))


A.K.




On Tuesday, December 24, 2013 10:43 AM, Nandini Jayakumar <nandini_dec6 at hotmail.com> wrote:
Hello all

I have a table a sample of which is as follows:




??? 
??? 
??? 
??? 



??? 
??? 
??? 
??? 
??? ??? 
??? ??? ??? Categories

??? ??? 
??? ??? 
??? ??? ??? Variable (x)

??? ??? 
??? ??? 
??? ??? ??? Frequencies

??? ??? 
??? 
??? 
??? ??? 
??? ??? ??? 1

??? ??? ??? 1

??? ??? ??? 1

??? ??? ??? 1

??? ??? ??? 1

??? ??? 
??? ??? 
??? ??? ??? 0.009

??? ??? ??? 0.867

??? ??? ??? 0.567

??? ??? ??? 0.765

??? ??? ??? 0.445

??? ??? 
??? ??? 
??? ??? ??? 1003

??? ??? ??? 1200

??? ??? ??? 987

??? ??? ??? 134

??? ??? ??? 890

??? ??? 
??? 
??? 
??? ??? 
??? ??? ??? 2

??? ??? ??? 2

??? ??? ??? 2

??? ??? ??? 2

??? ??? ??? 2

??? ??? 
??? ??? 
??? ??? ??? 0.007

??? ??? ??? 0.768

??? ??? ??? 0.789

??? ??? ??? 0.544

??? ??? ??? 0.987

??? ??? 
??? ??? 
??? ??? ??? 899

??? ??? ??? 707

??? ??? ??? 865

??? ??? ??? 678

??? ??? ??? 889

??? ??? 
??? 
??? 
??? ??? 
??? ??? ??? 3

??? ??? ??? 3

??? ??? ??? 3

??? ??? ??? 3

??? ??? ??? 3

??? ??? 
??? ??? 
??? ??? ??? 0.898

??? ??? ??? 0.887

??? ??? ??? 0.560

??? ??? ??? 0.098

??? ??? ??? 0.987

??? ??? 
??? ??? 
??? ??? ??? 544

??? ??? ??? 677

??? ??? ??? 934

??? ??? ??? 467

??? ??? ??? 876

??? ??? 
??? 
??? 
??? ??? 
??? ??? ??? 40

??? ??? ??? 40

??? ??? ??? 40

??? ??? ??? 40

??? ??? ??? 40

??? ??? 
??? ??? 
??? ??? ??? 0.786

??? ??? ??? 0.342

??? ??? ??? 0.456

??? ??? ??? 0.987

??? ??? ??? 0.123

??? ??? 
??? ??? 
??? ??? ??? 843

??? ??? ??? 987

??? ??? ??? 675

??? ??? ??? 467

??? ??? ??? 223

??? ??? 
??? 



Basically I have 40 categories and each category has several hundred variables. I want to calculate the average per category, that is variable * frequency/Summation of frequencies. I want to do it for each category separately. Since i have many categories i do not want to use the subset() function 40 times. Is it possible to do it within a single data frame?

Really appreciate any help. Thank you.
??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jdnewmil at dcn.davis.CA.us  Tue Dec 24 18:23:51 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 24 Dec 2013 09:23:51 -0800
Subject: [R] error in "ca.jo"
In-Reply-To: <CAFxDEqKyvR4y0Xg-LW8PDnn6O0NjAT2Mu+2-mrmy0rYkygMzJA@mail.gmail.com>
References: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>
	<52B88A4F.9040603@pburns.seanet.com>
	<CAFxDEqKyvR4y0Xg-LW8PDnn6O0NjAT2Mu+2-mrmy0rYkygMzJA@mail.gmail.com>
Message-ID: <2954bba2-ff43-4137-9d79-45f56e8f68e3@email.android.com>

Once you start describing your code in language that indicates you have read some of the recommended materials, we can make some progress. For example, you are still posting in HTML format so your code is getting mangled (see Posting Guide). You don't seem to understand what tryCatch does (see ?tryCatch; hint... it does not alter the result returned by ca.jo, nor does it guarantee that any result will be returned). For that matter, you don't seem to understand how to give valid inputs to ca.jo, but then you don't seem to understand how to provide a reproducible example either (see for example http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example).

In short, if you ask us why one divided by zero doesn't give 3, we have to wonder if you don't belong in some other educational forum, because this is not a mathematics theory support group... it is about R. Please read or otherwise absorb the recommended background materials mentioned here and then ask clear questions here about R, or find some one-on-one help offline.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

mamush bukana <mamushbukana at gmail.com> wrote:
>Dear Pat,
>I tried your suggestion:
>for(i in 1:N1){
>for(j in 1:N2){
>co<-tryCatch(ca.jo <http://ca.jo>(data.frame(cbind(y2[
>i,j,],y1[i,j,])),type="trace", K=2,
>spec="transitory",ecdet="const",season=NULL,dumvar=NULL),error=function(e)
>NaN)
>}}
>
>and the earlier error does not show up. However, when I try to extract
>some
>results from the "co.jo" function, it does not work the way it does
>without
>the "tryCatch" thing and there appears another error. For example:
>
>for(i in 1:N1){
>for(j in 1:N2){
>co<-tryCatch(ca.jo <http://ca.jo>(data.frame(cbind(y2[
>i,j,],y1[i,j,])),type="trace", K=2,
>spec="transitory",ecdet="const",season=NULL,dumvar=NULL),error=function(e)
>NaN)
>
>cor1<-cajorls(co,r=1)
>}}
>
>Error in cajorls(vecm, r = 1) :
>Please, provide object of class 'ca.jo' or 'cajo.test' as 'z'.
>
>So it seems "tryCatch" is disabling "ca.jo" from running properly. My
>intention is to run this function ("ca.jo") and extract some estimates
>for
>further computation.
>
>regards
>
>Bukana
>
>
>
>
>
>
>
>On Mon, Dec 23, 2013 at 5:09 PM, Patrick Burns
><pburns at pburns.seanet.com>wrote:
>
>> There is a fundamental problem with your
>> code, and there is the problem that you
>> have (sort of) identified.
>>
>> The fundamental problem is that you are
>> only going to get the results of the last
>> call to 'ca.jo' that is done -- assuming
>> it were to run.  You presumably want to
>> save some information from each of the
>> computations.
>>
>> You can get the loops to run even when you
>> run into an error with some combinations
>> by using 'try' or 'tryCatch'.  There is an
>> example in Circle 8.3.13 of 'The R Inferno'.
>>
>> http://www.burns-stat.com/documents/books/the-r-inferno/
>>
>> If you have a question related to the actual
>> function as opposed to general problems with
>> R, then the r-sig-finance mailing list would
>> be appropriate (you need to subscribe before
>> posting).
>>
>> I'm not sure if this is enough of a hint for
>> you or not.  If not, then trying to formulate
>> a more explicit question might help.  (There
>> are some suggestions in Circle 9 of 'The R
>> Inferno'.)
>>
>> Pat
>>
>>
>>
>> On 23/12/2013 17:07, mamush bukana wrote:
>>
>>> Dear all,
>>> I fit co-integration function between two integrated variables(y1
>and y2)
>>> over different grid points:
>>>
>>> for(i in 1:N1){
>>> for(j in 1:N2){
>>> co<-ca.jo(data.frame(cbind(y2[i,j,],y1[i,j,])),type="trace", K=2,
>>> spec="transitory",ecdet="const",season=NULL,dumvar=NULL)
>>> }}
>>>
>>> I have already extracted grid points with integrated time series.
>However,
>>> when I run the above function, there happens an error
>>>
>>> Error in solve.default(t(V) %*% SKK %*% V) :
>>>    system is computationally singular: reciprocal condition number =
>>> 1.10221e-35
>>>
>>> May you suggest me how to fix this problem please?
>>>
>>> Thanks in advance
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> --
>> Patrick Burns
>> pburns at pburns.seanet.com
>> twitter: @burnsstat @portfolioprobe
>> http://www.portfolioprobe.com/blog
>> http://www.burns-stat.com
>> (home of:
>>  'Impatient R'
>>  'The R Inferno'
>>  'Tao Te Programming')
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From aurelien.philippot at gmail.com  Tue Dec 24 18:39:14 2013
From: aurelien.philippot at gmail.com (=?ISO-8859-1?Q?Aur=E9lien_Philippot?=)
Date: Tue, 24 Dec 2013 09:39:14 -0800
Subject: [R] Simplifying an expression with an integral
Message-ID: <CAOwh97t16s=RhFYDy2AESG=V4_7zHr+18BAoie7fLfRDtY8jzg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131224/55e4c784/attachment.pl>

From dwinsemius at comcast.net  Tue Dec 24 18:43:08 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 24 Dec 2013 09:43:08 -0800
Subject: [R] unique mismatch in R and Excel
In-Reply-To: <CAFGkLihZuT4ugAbfFMkwtnxtUN28N=RAgjcxNinW-wg4W17DHg@mail.gmail.com>
References: <CAFGkLihZuT4ugAbfFMkwtnxtUN28N=RAgjcxNinW-wg4W17DHg@mail.gmail.com>
Message-ID: <23D1DB92-5B25-4DBF-8F5B-92595166B3AD@comcast.net>


On Dec 24, 2013, at 1:08 AM, Koushik Saha wrote:

> i have a wired problem. i want to count the unique entry in a certain
> column.Here i have attached my csv file.

Files named with extension .csv do not typically make it through the R-help mail server.

> 
> i am doing this to get the unique entries in the column.
> 
> dat<-read.csv("C:/Project/Gawk-scripts/Book1.csv")
> names(dat)<-c("user_name")
> unique(dat$user_name)
> 
> results says i have 170 unique values.
> 
> 
> But i am doing "remove duplicate entries"  in excel i am having 147 unique
> entries in the column.
> 
> Can anyone explain why there is a mismatch of the results or i am doing
> something wrong.
> 

Rename the file to have an extension of .txt. Then you mail-client will probably label it correctly as a MIME-TEXT file.

-- 
David Winsemius
Alameda, CA, USA


From mamushbukana at gmail.com  Tue Dec 24 22:36:40 2013
From: mamushbukana at gmail.com (mamush bukana)
Date: Tue, 24 Dec 2013 21:36:40 +0000
Subject: [R] error in "ca.jo"
In-Reply-To: <2954bba2-ff43-4137-9d79-45f56e8f68e3@email.android.com>
References: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>
	<52B88A4F.9040603@pburns.seanet.com>
	<CAFxDEqKyvR4y0Xg-LW8PDnn6O0NjAT2Mu+2-mrmy0rYkygMzJA@mail.gmail.com>
	<2954bba2-ff43-4137-9d79-45f56e8f68e3@email.android.com>
Message-ID: <CAFxDEqL9x199ah1qqQeUuyRrkYRGhmGyVMjnKwYEPf4ZWr8LYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131224/6c844ed6/attachment.pl>

From anton.sylchenko at gmail.com  Tue Dec 24 20:44:46 2013
From: anton.sylchenko at gmail.com (Anton Sylchenko)
Date: Tue, 24 Dec 2013 14:44:46 -0500
Subject: [R] Transferring data from R to MATLAB via Rmatlab package
Message-ID: <CANStP00aivWBpmJgBD0jgxwmR3REVkGuqfMgK4OzCjBJmdTM4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131224/feefc654/attachment.pl>

From tiaborrelli at yahoo.it  Tue Dec 24 22:27:12 2013
From: tiaborrelli at yahoo.it (Tia Borrelli)
Date: Tue, 24 Dec 2013 21:27:12 +0000
Subject: [R] Fitdistr and mle
In-Reply-To: <loom.20131224T165535-1@post.gmane.org>
References: <1387825583.42562.YahooMailNeo@web173205.mail.ir2.yahoo.com>
	<loom.20131224T165535-1@post.gmane.org>
Message-ID: <1387920432.23500.YahooMailNeo@web173205.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131224/836ef727/attachment.pl>

From josh.m.ulrich at gmail.com  Tue Dec 24 23:49:00 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 24 Dec 2013 16:49:00 -0600
Subject: [R] [R-SIG-Finance]  error in "ca.jo"
In-Reply-To: <CAFxDEqL9x199ah1qqQeUuyRrkYRGhmGyVMjnKwYEPf4ZWr8LYA@mail.gmail.com>
References: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>
	<52B88A4F.9040603@pburns.seanet.com>
	<CAFxDEqKyvR4y0Xg-LW8PDnn6O0NjAT2Mu+2-mrmy0rYkygMzJA@mail.gmail.com>
	<2954bba2-ff43-4137-9d79-45f56e8f68e3@email.android.com>
	<CAFxDEqL9x199ah1qqQeUuyRrkYRGhmGyVMjnKwYEPf4ZWr8LYA@mail.gmail.com>
Message-ID: <CAPPM_gSg4JH1ZPH6MmZtkQBfGJyXHrhXiMv5QfGe3Q-En7Xsxw@mail.gmail.com>

On Tue, Dec 24, 2013 at 3:36 PM, mamush bukana <mamushbukana at gmail.com> wrote:
> Hi Jeff,
> >From your words (if our words really describe us), I hope you don't expect
> me to teach you that this is "r-help" room. I don't expect you to tell me
> that I am a layman. I already know it and that is why I am here seeking a
> help. If I am an expert of things I asked here, there is no need for me to
> come here with such "stupid (in your understanding)" question. I know there
> are people on this planet who consider themselves advanced only when they
> meet stupid people like me - you may be one of them. It is always helpful
> for others if you could write a single line with a helping mind than
> writing tones of useless junk words. R is applied statistical language, to
> be used in different professions. So, don't expect all R users to be
> "experts" like you are. If you can't help people, at least keep yourself
> away from helping environment.
>
This isn't just R-help.  You've also cross-posted (which many feel is
rude) to R-SIG-Finance, even though this is off-topic for
R-SIG-Finance.  Your problem is with R's control-flow and
error-handling, not anything finance-related.  Also, these being
"help" forums and you being a laymen does not mean you can ignore the
guidelines.

Rather than (again) not following the suggestions in the posting guide
("If you feel insulted by some response to a post of yours, don't make
any hasty response in return - you're more likely than not to regret
it."), you would be wise to follow Jeff's advice:
1) Stop posting in HTML, so people can copy/paste your code.
2) Provide a small, self-contained reproducible example.
3) Carefully read ?try and ?tryCatch; use rseek.org to search for examples.
4) Skip 1-3 and find some one-on-one help in person.

It would also be wise to follow *both* of Pat's recommendations (you
ignored his suggestion to save some information from the ca.jo
calculations).

In short, please follow the posing guide, rather than expect people to
voluntarily help you on your terms.

> Cheers
>
> Bukana
>
>
> On Tue, Dec 24, 2013 at 5:23 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>wrote:
>
>> Once you start describing your code in language that indicates you have
>> read some of the recommended materials, we can make some progress. For
>> example, you are still posting in HTML format so your code is getting
>> mangled (see Posting Guide). You don't seem to understand what tryCatch
>> does (see ?tryCatch; hint... it does not alter the result returned by
>> ca.jo, nor does it guarantee that any result will be returned). For that
>> matter, you don't seem to understand how to give valid inputs to ca.jo,
>> but then you don't seem to understand how to provide a reproducible example
>> either (see for example
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> ).
>>
>> In short, if you ask us why one divided by zero doesn't give 3, we have to
>> wonder if you don't belong in some other educational forum, because this is
>> not a mathematics theory support group... it is about R. Please read or
>> otherwise absorb the recommended background materials mentioned here and
>> then ask clear questions here about R, or find some one-on-one help offline.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> mamush bukana <mamushbukana at gmail.com> wrote:
>> >Dear Pat,
>> >I tried your suggestion:
>> >for(i in 1:N1){
>> >for(j in 1:N2){
>> >co<-tryCatch(ca.jo <http://ca.jo>(data.frame(cbind(y2[
>> >i,j,],y1[i,j,])),type="trace", K=2,
>> >spec="transitory",ecdet="const",season=NULL,dumvar=NULL),error=function(e)
>> >NaN)
>> >}}
>> >
>> >and the earlier error does not show up. However, when I try to extract
>> >some
>> >results from the "co.jo" function, it does not work the way it does
>> >without
>> >the "tryCatch" thing and there appears another error. For example:
>> >
>> >for(i in 1:N1){
>> >for(j in 1:N2){
>> >co<-tryCatch(ca.jo <http://ca.jo>(data.frame(cbind(y2[
>> >i,j,],y1[i,j,])),type="trace", K=2,
>> >spec="transitory",ecdet="const",season=NULL,dumvar=NULL),error=function(e)
>> >NaN)
>> >
>> >cor1<-cajorls(co,r=1)
>> >}}
>> >
>> >Error in cajorls(vecm, r = 1) :
>> >Please, provide object of class 'ca.jo' or 'cajo.test' as 'z'.
>> >
>> >So it seems "tryCatch" is disabling "ca.jo" from running properly. My
>> >intention is to run this function ("ca.jo") and extract some estimates
>> >for
>> >further computation.
>> >
>> >regards
>> >
>> >Bukana
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >On Mon, Dec 23, 2013 at 5:09 PM, Patrick Burns
>> ><pburns at pburns.seanet.com>wrote:
>> >
>> >> There is a fundamental problem with your
>> >> code, and there is the problem that you
>> >> have (sort of) identified.
>> >>
>> >> The fundamental problem is that you are
>> >> only going to get the results of the last
>> >> call to 'ca.jo' that is done -- assuming
>> >> it were to run.  You presumably want to
>> >> save some information from each of the
>> >> computations.
>> >>
>> >> You can get the loops to run even when you
>> >> run into an error with some combinations
>> >> by using 'try' or 'tryCatch'.  There is an
>> >> example in Circle 8.3.13 of 'The R Inferno'.
>> >>
>> >> http://www.burns-stat.com/documents/books/the-r-inferno/
>> >>
>> >> If you have a question related to the actual
>> >> function as opposed to general problems with
>> >> R, then the r-sig-finance mailing list would
>> >> be appropriate (you need to subscribe before
>> >> posting).
>> >>
>> >> I'm not sure if this is enough of a hint for
>> >> you or not.  If not, then trying to formulate
>> >> a more explicit question might help.  (There
>> >> are some suggestions in Circle 9 of 'The R
>> >> Inferno'.)
>> >>
>> >> Pat
>> >>
>> >>
>> >>
>> >> On 23/12/2013 17:07, mamush bukana wrote:
>> >>
>> >>> Dear all,
>> >>> I fit co-integration function between two integrated variables(y1
>> >and y2)
>> >>> over different grid points:
>> >>>
>> >>> for(i in 1:N1){
>> >>> for(j in 1:N2){
>> >>> co<-ca.jo(data.frame(cbind(y2[i,j,],y1[i,j,])),type="trace", K=2,
>> >>> spec="transitory",ecdet="const",season=NULL,dumvar=NULL)
>> >>> }}
>> >>>
>> >>> I have already extracted grid points with integrated time series.
>> >However,
>> >>> when I run the above function, there happens an error
>> >>>
>> >>> Error in solve.default(t(V) %*% SKK %*% V) :
>> >>>    system is computationally singular: reciprocal condition number =
>> >>> 1.10221e-35
>> >>>
>> >>> May you suggest me how to fix this problem please?
>> >>>
>> >>> Thanks in advance
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/
>> >>> posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>>
>> >> --
>> >> Patrick Burns
>> >> pburns at pburns.seanet.com
>> >> twitter: @burnsstat @portfolioprobe
>> >> http://www.portfolioprobe.com/blog
>> >> http://www.burns-stat.com
>> >> (home of:
>> >>  'Impatient R'
>> >>  'The R Inferno'
>> >>  'Tao Te Programming')
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.


From jdnewmil at dcn.davis.CA.us  Tue Dec 24 23:51:37 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 24 Dec 2013 14:51:37 -0800
Subject: [R] error in "ca.jo"
In-Reply-To: <CAFxDEqL9x199ah1qqQeUuyRrkYRGhmGyVMjnKwYEPf4ZWr8LYA@mail.gmail.com>
References: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>
	<52B88A4F.9040603@pburns.seanet.com>
	<CAFxDEqKyvR4y0Xg-LW8PDnn6O0NjAT2Mu+2-mrmy0rYkygMzJA@mail.gmail.com>
	<2954bba2-ff43-4137-9d79-45f56e8f68e3@email.android.com>
	<CAFxDEqL9x199ah1qqQeUuyRrkYRGhmGyVMjnKwYEPf4ZWr8LYA@mail.gmail.com>
Message-ID: <beac4c9f-bea7-4664-8cf2-a0667cd2a1bc@email.android.com>

I am sorry you have chosen to interpret my response as unfriendly. I do not expect you or anyone posting here to be an expert before posting. However, the context here is that you have to read our responses anyway, so both Pat and I have recommended higher-quality reading material than we can write off the cuff. If you do read the recommended materials, you will be able to communicate in this forum effectively. If you do not, we will be guessing at problems we cannot know clearly about unless you tell us about them. You also need to read the Posting Guide to know what is on topic here, and what is not. When you start generating a lot of inputs to a function and getting errors then you may need to learn more about the theory behind that function... and this is not really the right place for that. So, please read the recommended materials and think about them before posting.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

mamush bukana <mamushbukana at gmail.com> wrote:
>Hi Jeff,
>>From your words (if our words really describe us), I hope you don't
>expect
>me to teach you that this is "r-help" room. I don't expect you to tell
>me
>that I am a layman. I already know it and that is why I am here seeking
>a
>help. If I am an expert of things I asked here, there is no need for me
>to
>come here with such "stupid (in your understanding)" question. I know
>there
>are people on this planet who consider themselves advanced only when
>they
>meet stupid people like me - you may be one of them. It is always
>helpful
>for others if you could write a single line with a helping mind than
>writing tones of useless junk words. R is applied statistical language,
>to
>be used in different professions. So, don't expect all R users to be
>"experts" like you are. If you can't help people, at least keep
>yourself
>away from helping environment.
>
>Cheers
>
>Bukana
>
>
>On Tue, Dec 24, 2013 at 5:23 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>wrote:
>
>> Once you start describing your code in language that indicates you
>have
>> read some of the recommended materials, we can make some progress.
>For
>> example, you are still posting in HTML format so your code is getting
>> mangled (see Posting Guide). You don't seem to understand what
>tryCatch
>> does (see ?tryCatch; hint... it does not alter the result returned by
>> ca.jo, nor does it guarantee that any result will be returned). For
>that
>> matter, you don't seem to understand how to give valid inputs to
>ca.jo,
>> but then you don't seem to understand how to provide a reproducible
>example
>> either (see for example
>>
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> ).
>>
>> In short, if you ask us why one divided by zero doesn't give 3, we
>have to
>> wonder if you don't belong in some other educational forum, because
>this is
>> not a mathematics theory support group... it is about R. Please read
>or
>> otherwise absorb the recommended background materials mentioned here
>and
>> then ask clear questions here about R, or find some one-on-one help
>offline.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> mamush bukana <mamushbukana at gmail.com> wrote:
>> >Dear Pat,
>> >I tried your suggestion:
>> >for(i in 1:N1){
>> >for(j in 1:N2){
>> >co<-tryCatch(ca.jo <http://ca.jo>(data.frame(cbind(y2[
>> >i,j,],y1[i,j,])),type="trace", K=2,
>>
>>spec="transitory",ecdet="const",season=NULL,dumvar=NULL),error=function(e)
>> >NaN)
>> >}}
>> >
>> >and the earlier error does not show up. However, when I try to
>extract
>> >some
>> >results from the "co.jo" function, it does not work the way it does
>> >without
>> >the "tryCatch" thing and there appears another error. For example:
>> >
>> >for(i in 1:N1){
>> >for(j in 1:N2){
>> >co<-tryCatch(ca.jo <http://ca.jo>(data.frame(cbind(y2[
>> >i,j,],y1[i,j,])),type="trace", K=2,
>>
>>spec="transitory",ecdet="const",season=NULL,dumvar=NULL),error=function(e)
>> >NaN)
>> >
>> >cor1<-cajorls(co,r=1)
>> >}}
>> >
>> >Error in cajorls(vecm, r = 1) :
>> >Please, provide object of class 'ca.jo' or 'cajo.test' as 'z'.
>> >
>> >So it seems "tryCatch" is disabling "ca.jo" from running properly.
>My
>> >intention is to run this function ("ca.jo") and extract some
>estimates
>> >for
>> >further computation.
>> >
>> >regards
>> >
>> >Bukana
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >On Mon, Dec 23, 2013 at 5:09 PM, Patrick Burns
>> ><pburns at pburns.seanet.com>wrote:
>> >
>> >> There is a fundamental problem with your
>> >> code, and there is the problem that you
>> >> have (sort of) identified.
>> >>
>> >> The fundamental problem is that you are
>> >> only going to get the results of the last
>> >> call to 'ca.jo' that is done -- assuming
>> >> it were to run.  You presumably want to
>> >> save some information from each of the
>> >> computations.
>> >>
>> >> You can get the loops to run even when you
>> >> run into an error with some combinations
>> >> by using 'try' or 'tryCatch'.  There is an
>> >> example in Circle 8.3.13 of 'The R Inferno'.
>> >>
>> >> http://www.burns-stat.com/documents/books/the-r-inferno/
>> >>
>> >> If you have a question related to the actual
>> >> function as opposed to general problems with
>> >> R, then the r-sig-finance mailing list would
>> >> be appropriate (you need to subscribe before
>> >> posting).
>> >>
>> >> I'm not sure if this is enough of a hint for
>> >> you or not.  If not, then trying to formulate
>> >> a more explicit question might help.  (There
>> >> are some suggestions in Circle 9 of 'The R
>> >> Inferno'.)
>> >>
>> >> Pat
>> >>
>> >>
>> >>
>> >> On 23/12/2013 17:07, mamush bukana wrote:
>> >>
>> >>> Dear all,
>> >>> I fit co-integration function between two integrated variables(y1
>> >and y2)
>> >>> over different grid points:
>> >>>
>> >>> for(i in 1:N1){
>> >>> for(j in 1:N2){
>> >>> co<-ca.jo(data.frame(cbind(y2[i,j,],y1[i,j,])),type="trace", K=2,
>> >>> spec="transitory",ecdet="const",season=NULL,dumvar=NULL)
>> >>> }}
>> >>>
>> >>> I have already extracted grid points with integrated time series.
>> >However,
>> >>> when I run the above function, there happens an error
>> >>>
>> >>> Error in solve.default(t(V) %*% SKK %*% V) :
>> >>>    system is computationally singular: reciprocal condition
>number =
>> >>> 1.10221e-35
>> >>>
>> >>> May you suggest me how to fix this problem please?
>> >>>
>> >>> Thanks in advance
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/
>> >>> posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible
>code.
>> >>>
>> >>>
>> >> --
>> >> Patrick Burns
>> >> pburns at pburns.seanet.com
>> >> twitter: @burnsstat @portfolioprobe
>> >> http://www.portfolioprobe.com/blog
>> >> http://www.burns-stat.com
>> >> (home of:
>> >>  'Impatient R'
>> >>  'The R Inferno'
>> >>  'Tao Te Programming')
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From eliza_botto at hotmail.com  Wed Dec 25 00:26:18 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Tue, 24 Dec 2013 23:26:18 +0000
Subject: [R] label in scatter3d plot
Message-ID: <BLU170-W23400C170DA3A4BE828E1A89C00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131224/194e9126/attachment.pl>

From ligges at statistik.tu-dortmund.de  Wed Dec 25 01:09:52 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 25 Dec 2013 01:09:52 +0100
Subject: [R] label in scatter3d plot
In-Reply-To: <BLU170-W23400C170DA3A4BE828E1A89C00@phx.gbl>
References: <BLU170-W23400C170DA3A4BE828E1A89C00@phx.gbl>
Message-ID: <52BA2250.8070106@statistik.tu-dortmund.de>

See what scatterplot3d() return. This is rather helpful, i.e. try

s3d <- scatterplot3d(x,y,z, main="3D Scatterplot")
text(s3d$xyz.convert(x,y,z)$x, s3d$xyz.convert(x,y,z)$y, V4, pos=4, cex=0.7)

Well, you still don't see too much, but at least it does what you were 
asking for.

Best,
Uwe Ligges



On 25.12.2013 00:26, eliza botto wrote:
> Dear Users of R,
> I plotted the following data by
>> scatterplot3d(x,y,z, main="3D Scatterplot")
> Then i wanted to label the points on that plot w.r.t column 4. i unsuccessfully tried
> textxy() & text3d()
> Kindly guide me through
>> dput(test)
> structure(list(x = c(458750L, 460350L, 415750L, 356250L, 387450L, 412350L, 411950L, 436750L, 428350L, 508450L, 437450L, 432550L, 433650L, 430050L, 457150L, 445350L, 444350L, 389150L, 421050L, 413450L, 420050L, 433850L, 421750L, 380850L, 337050L, 348550L, 399350L, 405750L, 406050L, 407550L, 507950L, 358150L, 374950L, 380350L, 319450L, 444150L, 329950L, 335150L, 330750L, 343350L, 401650L, 398550L, 423150L, 456550L, 457350L, 402150L, 367150L, 360050L, 408750L, 350650L, 360850L, 394850L, 388950L, 437950L, 418450L, 398850L, 476650L, 476450L, 469250L, 376650L, 382450L, 351150L, 351850L, 394750L, 393250L, 366550L, 377250L, 350450L, 401850L, 372950L, 371650L, 373250L, 390450L, 421450L, 341750L, 373750L, 364750L, 359650L, 499150L, 502950L, 366950L, 340750L, 429150L, 416950L, 436650L, 466850L, 365150L, 371650L, 385450L, 430850L, 450150L, 431350L, 392750L, 398550L, 407850L, 406650L, 402350L, 424850L, 411850L, 419450L, 401450L, 467750L, 439950L, 436550L, 362150L, 352950L, 385850L, 38395!
>   0L, 503650L), y = c(5062550L, 5053950L, 5090250L, 5076750L, 5052050L, 4981450L, 4978150L, 4947050L, 4931550L, 4946050L, 5109250L, 4904950L, 4917350L, 4898150L, 4934550L, 4926550L, 4918450L, 4909550L, 4959850L, 4900350L, 5058650L, 5044050L, 5055550L, 4976850L, 4982050L, 4980550L, 5039050L, 4895750L, 4897450L, 4900950L, 4959150L, 5064350L, 5065150L, 5060150L, 4995650L, 5129050L, 4977450L, 4993350L, 4992050L, 4994150L, 4904450L, 4896150L, 5041450L, 4927550L, 4922150L, 5080550L, 4953650L, 4917850L, 5078650L, 4927150L, 4926250L, 5015450L, 5020650L, 5081750L, 4907150L, 4888650L, 4938950L, 4940850L, 4924850L, 5036150L, 5033350L, 4962950L, 4973850L, 4909750L, 4897050L, 4948750L, 5003150L, 4950750L, 4983450L, 4954850L, 4978750L, 4956750L, 5010350L, 4931050L, 5059450L, 4988350L, 4988550L, 5042650L, 4949950L, 4941650L, 4906150L, 4913250L, 5075850L, 5076450L, 5052550L, 5094350L, 5016450L, 5012750L, 5041250L, 5060850L, 5079250L, 5054150L, 4911050L, 4921450L, 4905250L, 4888050L, 4926650L!
>   , 4932650L, 4892350L, 4893850L, 4886350L, 5051150L, 5110850L, 4928850L
> , 4940150L, 4939350L, 4892550L, 4895250L, 4939050L), z = c(1167L, 1167L, 4572L, 3179L, 3141L, 585L, 585L, 876L, 876L, 1678L, 2667L, 1369L, 1369L, 1369L, 1381L, 1381L, 1381L, 2284L, 410L, 2109L, 2507L, 2579L, 2507L, 1436L, 3234L, 3234L, 2792L, 2569L, 2569L, 2569L, 1669L, 4743L, 4743L, 4743L, 3403L, 3197L, 3267L, 3583L, 3583L, 3583L, 2584L, 2584L, 2579L, 1241L, 1241L, 4174L, 2366L, 2618L, 4487L, 3196L, 3196L, 2107L, 2107L, 2427L, 1814L, 2622L, 1268L, 1268L, 1268L, 3885L, 3885L, 3092L, 3234L, 2625L, 2625L, 3760L, 4743L, 3707L, 4743L, 3760L, 3885L, 3760L, 4743L, 782L, 3343L, 2697L, 2697L, 3915L, 1678L, 1678L, 3197L, 2957L, 4530L, 4530L, 4530L, 2131L, 3618L, 3618L, 3335L, 2512L, 2390L, 1616L, 3197L, 3197L, 2625L, 2622L, 3197L, 3197L, 2622L, 2622L, 2622L, 368L, 4572L, 863L, 3716L, 3716L, 2697L, 2697L, 1358L), V4 = 1:109), .Names = c("x", "y", "z", "V4"), row.names = c(NA, -109L), class = "data.frame")
>
>
> Thanks in advance,
> Eliza 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From eliza_botto at hotmail.com  Wed Dec 25 01:13:23 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Wed, 25 Dec 2013 00:13:23 +0000
Subject: [R] label in scatter3d plot
In-Reply-To: <52BA2250.8070106@statistik.tu-dortmund.de>
References: <BLU170-W23400C170DA3A4BE828E1A89C00@phx.gbl>,
	<52BA2250.8070106@statistik.tu-dortmund.de>
Message-ID: <BLU170-W20D4B50EA9A1ECC2601BCA89C30@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131225/cfa80236/attachment.pl>

From dwinsemius at comcast.net  Wed Dec 25 03:26:51 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 24 Dec 2013 18:26:51 -0800
Subject: [R] Simplifying an expression with an integral
In-Reply-To: <CAOwh97t16s=RhFYDy2AESG=V4_7zHr+18BAoie7fLfRDtY8jzg@mail.gmail.com>
References: <CAOwh97t16s=RhFYDy2AESG=V4_7zHr+18BAoie7fLfRDtY8jzg@mail.gmail.com>
Message-ID: <562CA2A3-5A86-443B-B7C8-E208AAB0146A@comcast.net>


On Dec 24, 2013, at 9:39 AM, Aur?lien Philippot wrote:

> Dear R experts,
> I am computing the following integral.
> 
> [image: \int_{1,100} \frac{1}{x+Max(x-50,0)} g(x)dx], where g is the
> density of the standard normal, and [1,100] is the domain.
> 
> 1) I use the following code which works fine:
> integrand1<- function(x){1/x*dnorm(x)}
> integrand2<- function(x){1/(2*x-50)*dnorm(x)}
> 
> res1<- integrate(integrand1, lower=1, upper=50)$value+
> integrate(integrand2, lower=50, upper=100)$value
> res1
> 0.1116
> 
> In other words, I split the max function depending on the value of x in the
> domain.
> 
> 2) Alternatively, I can also compute it by vectorizing the max function
> integrand<- function (x) ifelse(x<50, 1/x*dnorm(x) , 1/(2*x-50)*dnorm(x))
> res4<- integrate(integrand, lower=1, upper=100)$value
> res4
> 0.1116
> 
> 3) However, in both cases, the syntax is a little bit heavy and not very
> convenient if I want to add more integrals, all of them with a max in the
> integrand. Is there a way to have a more concise syntax?
> Using max or pmax directly in the definition of the integrand does not work.
> For example:
> integrand<- function(x) {1/(x+max(x-50,0)*dnorm(x))}

Is boolean math more to your liking?

integr_both<- function(x){ 
                   (x < 50)*(1/x*dnorm(x))+
                   (x>= 50 & x<100)*(  1/(2*x-50)*dnorm(x) ) }
res_b<- integrate(integr_both, lower=1, upper=100)$value

> res_b
[1] 0.1116587

-- 
David

> 
> res<- integrate(integrand, lower=1, upper=100)$value
> res
> 4.60517
> 
> Thank you for any suggestion, and merry Christmas!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From b.rowlingson at lancaster.ac.uk  Wed Dec 25 11:13:40 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 25 Dec 2013 10:13:40 +0000
Subject: [R] unique mismatch in R and Excel
In-Reply-To: <dcb7fb9bab4e4dd781dea290f797fc8c@EX-1-HT0.lancs.local>
References: <CAFGkLihZuT4ugAbfFMkwtnxtUN28N=RAgjcxNinW-wg4W17DHg@mail.gmail.com>
	<dcb7fb9bab4e4dd781dea290f797fc8c@EX-1-HT0.lancs.local>
Message-ID: <CANVKczN_czaGxzU97i+U9otod-Zb9Wx_jyaP7qz0_bSxYLdB5g@mail.gmail.com>

We answered this on StackOverflow already. Excel was doing
case-insensitive duplicate matching.

http://stackoverflow.com/questions/20759346/counting-unique-values-in-r-and-excel/20759523#20759523

Barry

On Tue, Dec 24, 2013 at 5:43 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Dec 24, 2013, at 1:08 AM, Koushik Saha wrote:
>
>> i have a wired problem. i want to count the unique entry in a certain
>> column.Here i have attached my csv file.
>
> Files named with extension .csv do not typically make it through the R-help mail server.
>
>>
>> i am doing this to get the unique entries in the column.
>>
>> dat<-read.csv("C:/Project/Gawk-scripts/Book1.csv")
>> names(dat)<-c("user_name")
>> unique(dat$user_name)
>>
>> results says i have 170 unique values.
>>
>>
>> But i am doing "remove duplicate entries"  in excel i am having 147 unique
>> entries in the column.
>>
>> Can anyone explain why there is a mismatch of the results or i am doing
>> something wrong.
>>
>
> Rename the file to have an extension of .txt. Then you mail-client will probably label it correctly as a MIME-TEXT file.
>
> --
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From musammilu at hotmail.com  Wed Dec 25 06:02:24 2013
From: musammilu at hotmail.com (Kochikkaran Musammilu)
Date: Wed, 25 Dec 2013 05:02:24 +0000
Subject: [R] x-axis value in boxplot
Message-ID: <BLU173-W3026115F4669848DDFCC11B5C30@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131225/36d9f828/attachment.pl>

From rottemguy at gmail.com  Wed Dec 25 09:58:27 2013
From: rottemguy at gmail.com (Guy Rotem)
Date: Wed, 25 Dec 2013 10:58:27 +0200
Subject: [R] Categorial data analysis
Message-ID: <CA+9PSGJVwSXuDoZyTjbOXtqVa66hRT0XOf51MPe5UBTNTGU2xg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131225/804ffd06/attachment.pl>

From dwinsemius at comcast.net  Wed Dec 25 16:32:56 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 25 Dec 2013 07:32:56 -0800
Subject: [R] x-axis value in boxplot
In-Reply-To: <BLU173-W3026115F4669848DDFCC11B5C30@phx.gbl>
References: <BLU173-W3026115F4669848DDFCC11B5C30@phx.gbl>
Message-ID: <BAEDAD26-F44A-4109-89A8-2C393A5DF2A1@comcast.net>


On Dec 24, 2013, at 9:02 PM, Kochikkaran Musammilu wrote:

> Hai,
> 
> I
> am new to ?R? software. 
> 
> I have a doubt, while doing analysis,
> keeping the x axis value as year, in graphical representation (ie, in
> boxplot) the values comes as "X2005", and "X2006"
> and so on in x axis. How to keep "2005", "2006"
> as x axis value instead of "X2005" and "X2006".
> In gist, there comes a prefix "X" before the numeric value
> of X axis variables. How to solve this problem?
> 
> If any suggestions/guidance, please feel free to write <musammilu at hotmail.com>.  Kindly give me the "R" command to get rid of above problem!
> 

`boxplot` has a names argument. If you are passing a dataframe with a 'grp' variable to boxplot.formula, then try:
     boxplot( ... , names = sub("^X", "" dfrm$grp), ...)

See ?regex and ?sub

If this does not address your specific problem, then you would need to be .... more specific.

-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Dec 25 16:36:03 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 25 Dec 2013 07:36:03 -0800
Subject: [R] Categorial data analysis
In-Reply-To: <CA+9PSGJVwSXuDoZyTjbOXtqVa66hRT0XOf51MPe5UBTNTGU2xg@mail.gmail.com>
References: <CA+9PSGJVwSXuDoZyTjbOXtqVa66hRT0XOf51MPe5UBTNTGU2xg@mail.gmail.com>
Message-ID: <B3C8D0DA-5A64-4315-89EA-B3C3B51A7677@comcast.net>

This is not a statistics tutorial service. This is information that should be in any introductory text on the use of R. You are expected to do more self-study. Please read the Posting Guide.

-- 
David.
On Dec 25, 2013, at 12:58 AM, Guy Rotem wrote:

> Hi,
> I want to analysis the effect of two continuous independent variables (rain
> and slope) on a categorical dependent variable (soil type).
> Do you know how doing it?
> 
> Many Thanks
> 
> -- 
> Guy Rotem
> Department of Life Sciences ,The Spatial Ecology Lab
> Postdoctoral fellow at Conservation Evidence
> Ben Gurion University of the Negev
> P.O.B. 653   Beer-Sheva 84105
> ISRAEL
> 

David Winsemius
Alameda, CA, USA


From bbolker at gmail.com  Wed Dec 25 17:46:16 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Dec 2013 16:46:16 +0000
Subject: [R] Fitdistr and mle
References: <1387825583.42562.YahooMailNeo@web173205.mail.ir2.yahoo.com>
	<loom.20131224T165535-1@post.gmane.org>
	<1387920432.23500.YahooMailNeo@web173205.mail.ir2.yahoo.com>
Message-ID: <loom.20131225T174143-996@post.gmane.org>

Tia Borrelli <tiaborrelli <at> yahoo.it> writes:

>  Thanks for answering, in ret i've the returns of FTSE MIB (the
> benchmark stock market index in Italy) and i'm estimating the
> parametres of the distribution of the returns of the index using
> different methods.?

  OK, but this still isn't a *reproducible* example (see e.g.
http://tinyurl.com/reproducible-000 )
 
> I need the mle and i found this two function and i could not
> understand why the result were different: it's possibile that i
> obtain different result because in the mle() i don't need to know
> the original distribution and in the fitdistr() i don't need to know
> the function i had to maximize?

  In your example fitdistr() and mle() are doing the same thing under
the hood, i.e.  using the built-in optim() function to minimize a
negative log-likelihood function based on the built-in dnorm().
fitdistr() picks the distribution for you based on your specification
of which distribution to use; mle() requires you to specify the
negative log-likelihood function (the mle2() function in the bbmle
package is an extension of stats4::mle that offers a middle ground,
e.g. you can say y ~ dnorm(mu,sigma) to specify the fit of a Normal
distribution).  The differences between the results you get will be
based on small numerical differences, e.g. the starting values of the
parameters, or differences in the control parameters for optimization.
In general you should get very similar, but not necessarily identical,
answers from these two functions; big differences would probably
indicate some kind of wonky data or numerical problem.  Again, we
would need a reproducible example to see precisely what is going on.


From lterlemez at anadolu.edu.tr  Wed Dec 25 18:09:43 2013
From: lterlemez at anadolu.edu.tr (Levent TERLEMEZ)
Date: Wed, 25 Dec 2013 17:09:43 +0000
Subject: [R] Erroneous Column Removing Result From User-Defined Function.....
Message-ID: <CEE0DDB6.DB3C%lterlemez@anadolu.edu.tr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131225/6d86f750/attachment.pl>

From jdnewmil at dcn.davis.ca.us  Wed Dec 25 20:15:10 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 25 Dec 2013 11:15:10 -0800
Subject: [R] Erroneous Column Removing Result From User-Defined
 Function.....
In-Reply-To: <CEE0DDB6.DB3C%lterlemez@anadolu.edu.tr>
References: <CEE0DDB6.DB3C%lterlemez@anadolu.edu.tr>
Message-ID: <alpine.BSF.2.00.1312251034100.91090@pedal.dcn.davis.ca.us>

You have pasted together a string, and are now trying to treat it as a 
data frame? I am not surprised at this error message.

Please take heed of this warning: you are in Circle 6 of the R Inferno 
[1], and would benefit greatly from learning to put your 
multiple-but-similarly-structured data into a list and returning the list 
from the function instead of mucking around in the global environment. [2]

[1] http://www.burns-stat.com/pages/Tutor/R_inferno.pdf

[2] Example:

MyFunction <- function ( dyolu, dadi, dsayi ) {
    # integer sequence up to dsayi
    dsayiseq <- seq.int( dsayi )
    # vector of names
    ad <- paste( dadi, dsayiseq, sep="" )
    # vector of filenames based on ad
    yol <- paste( dyolu, ad, ".csv", sep="" )
    # generate list of data frames, one filename at a time
    result <- lapply( yol
                    , function( yoli ) {
                        # avoid using "T" and "F"... they are variables
                        # that can be re-defined... instead use TRUE and
                        # FALSE
                        dta <- read.csv( yoli, sep=";", dec=","
                                       , header=TRUE )
                        # note that accessing columns by position is a
                        # brittle approach...
                        #  if a new column is inserted, this code will
                        #  break. Would be better to use column names
                        dta <- dta[,-12]
                        # dta is a local variable... as the result of this
                        # inner function, its value is stored in the result
                        # list
                        dta
                      }
                    )
    # name the elements of the list for easier access
    names( result ) <- ad
    result
}

# make example reproducible
set.seed( 42 )
# create fake files to test code with
for ( i in 1:5 ) {
    m <- matrix( runif( 150 ), nrow=10 )
    colnames( m ) <- paste0( "Col", 1:15 )
    samp <- data.frame( key=1:10, m )
    write.csv2( samp, paste0( "Fnameprefix", "Dtaprefix", i, ".csv" )
              , row.names=FALSE )
}

dtaList <- MyFunction( "Fnameprefix", "Dtaprefix", 5 )

> str( dtaList, 1 )
List of 5
  $ Dtaprefix1:'data.frame':	10 obs. of  15 variables:
  $ Dtaprefix2:'data.frame':	10 obs. of  15 variables:
  $ Dtaprefix3:'data.frame':	10 obs. of  15 variables:
  $ Dtaprefix4:'data.frame':	10 obs. of  15 variables:
  $ Dtaprefix5:'data.frame':	10 obs. of  15 variables:
> str( dtaList[[ 2 ]] )
'data.frame':	10 obs. of  15 variables:
  $ key  : int  1 2 3 4 5 6 7 8 9 10
  $ Col1 : num  0.719 0.324 0.779 0.394 0.679 ...
  $ Col2 : num  0.935 0.55 0.602 0.197 0.535 ...
  $ Col3 : num  0.73 0.412 0.414 0.48 0.427 ...
  $ Col4 : num  0.918 0.863 0.317 0.259 0.742 ...
  $ Col5 : num  0.1947 0.7841 0.1289 0.1291 0.0723 ...
  $ Col6 : num  0.885 0.517 0.852 0.443 0.158 ...
  $ Col7 : num  0.542 0.6499 0.3364 0.0609 0.4513 ...
  $ Col8 : num  0.49 0.172 0.543 0.961 0.314 ...
  $ Col9 : num  0.3511 0.159 0.3041 0.0175 0.9966 ...
  $ Col10: num  0.0676 0.5614 0.0707 0.2114 0.5496 ...
  $ Col12: num  0.715 0.123 0.311 0.946 0.5 ...
  $ Col13: num  0.136 0.785 0.453 0.136 0.885 ...
  $ Col14: num  0.4657 0.0499 0.1874 0.9827 0.3283 ...
  $ Col15: num  0.867 0.732 0.315 0.386 0.332 ...
> mean( dtaList[[ "Dtaprefix2" ]]$Col2 )
[1] 0.4070087

On Wed, 25 Dec 2013, Levent TERLEMEZ wrote:

> Dear Users,
> I have a little problem with user-defined function. I would like to remove columns from a data frame using a user-defined function but i am getting a "Error in ad[, -12] : incorrect number of dimensions? error.  The "ad<-ad[,-12]? and similar commands work from R console but i couldn?t make them run from my function. The function and the type imformation of one of my obtained data objects is below.
>
> Thanks in advance for your tips and helpful answers,
> Levent TERLEMEZ.
>
>
> Error:
> Error in ad[, -12] : incorrect number of dimensions
>
> My Function:
> function (dyolu,dadi,dsayi)
> {
>    for(i in 1:dsayi)
>    {
>        ad<-paste(dadi,i,sep="")
>        yol<-paste(dyolu,dadi,i,".csv",sep="")
>        print(ad)
>        print(yol)
>        assign(eval(substitute(ad)), read.csv(yol,sep=";",dec=",",header=T), envir = globalenv())
>        ad<-ad[,-12]????????????????????????> Here I would like to remove some columns but i even can?t remove one. I tried all the suggestion on internet forums.
>        #dat[ , -which(names(dat) %in% c("z","u"))]
>    }
> }
>
> dyolu: The string type variable containing the path of the csv  files that will be read.
> dadi: The string type variable containing the name of csv files that will be read.
> dsayi: The numeri type variabe containing the number of files that will be read.
>
> My Data Object?s Attributes:
>> str(be1)
> 'data.frame': 74 obs. of  16 variables:
> $ Avi.TimeStamp: Factor w/ 74 levels " 0:00:40.00",..: 2 1 3 4 5 6 7 8 9 10 ...
> $ Frame        : int  32949 32950 32952 32953 32954 32955 32957 32961 32962 32963 ...
> $ Spot.x       : num  274 275 275 275 275 ...
> $ Spot.y       : num  277 277 277 277 277 ...
> $ Pupil.x      : num  240 242 242 241 241 ...
> $ Pupil.y      : num  320 320 320 320 320 ...
> $ Pupil.r      : num  47.7 47.5 47.6 47.8 47.7 ...
> $ Scene.x      : num  46.2 30.3 34.6 30.4 43.1 ...
> $ Scene.y      : num  102.5 71 71.9 73.7 92.2 ...
> $ Mouse.x      : int  287 287 287 287 287 287 287 287 287 287 ...
> $ Mouse.y      : int  570 570 570 570 570 570 570 570 570 570 ...
> $ X            : logi  NA NA NA NA NA NA ...
> $ H            : int  0 0 0 0 0 0 0 0 0 0 ...
> $ M            : int  0 0 0 0 0 0 0 0 0 0 ...
> $ S            : int  40 40 41 41 41 41 41 41 41 41 ...
> $ Split        : int  96 0 8 12 16 20 28 44 48 52 ?
>
> This data frame is obtained with the assign command from my function.
>
>
> 	[[alternative HTML version deleted]]
>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From r.turner at auckland.ac.nz  Wed Dec 25 22:38:48 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 26 Dec 2013 10:38:48 +1300
Subject: [R] error in "ca.jo"
In-Reply-To: <2954bba2-ff43-4137-9d79-45f56e8f68e3@email.android.com>
References: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>
	<52B88A4F.9040603@pburns.seanet.com>
	<CAFxDEqKyvR4y0Xg-LW8PDnn6O0NjAT2Mu+2-mrmy0rYkygMzJA@mail.gmail.com>
	<2954bba2-ff43-4137-9d79-45f56e8f68e3@email.android.com>
Message-ID: <52BB5068.3060705@auckland.ac.nz>

On 25/12/13 06:23, Jeff Newmiller wrote:

     <SNIP>
> In short, if you ask us why one divided by zero doesn't give 3, we have to wonder if you don't belong in some other educational forum.
     <SNIP>

Fortune!

     cheers,

     Rolf Turner


From A.Robinson at ms.unimelb.edu.au  Thu Dec 26 00:26:51 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 26 Dec 2013 10:26:51 +1100
Subject: [R] error in "ca.jo"
In-Reply-To: <52BB5068.3060705@auckland.ac.nz>
References: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>
	<52B88A4F.9040603@pburns.seanet.com>
	<CAFxDEqKyvR4y0Xg-LW8PDnn6O0NjAT2Mu+2-mrmy0rYkygMzJA@mail.gmail.com>
	<2954bba2-ff43-4137-9d79-45f56e8f68e3@email.android.com>
	<52BB5068.3060705@auckland.ac.nz>
Message-ID: <CAHyGmd4vB2RsNkpSouTPRyikCQDcWyBad6=bd0fYcvbdarrL2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131226/c3fbc045/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Thu Dec 26 01:11:13 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 25 Dec 2013 16:11:13 -0800
Subject: [R] error in "ca.jo"
In-Reply-To: <CAHyGmd4vB2RsNkpSouTPRyikCQDcWyBad6=bd0fYcvbdarrL2Q@mail.gmail.com>
References: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>
	<52B88A4F.9040603@pburns.seanet.com>
	<CAFxDEqKyvR4y0Xg-LW8PDnn6O0NjAT2Mu+2-mrmy0rYkygMzJA@mail.gmail.com>
	<2954bba2-ff43-4137-9d79-45f56e8f68e3@email.android.com>
	<52BB5068.3060705@auckland.ac.nz>
	<CAHyGmd4vB2RsNkpSouTPRyikCQDcWyBad6=bd0fYcvbdarrL2Q@mail.gmail.com>
Message-ID: <db28a884-a75b-4b37-a4f6-b502f57ac4c7@email.android.com>

Out of context, I would agree with you. However, I stand behind it as regards the original question... the OP should have had no trouble recognizing what the error message meant and what to do about it if they were even somewhat familiar with the applicable theory (differential equations), and this is not the appropriate forum for that conversation.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
>I respectfully disagree.  Taken out of context, this would be simply
>snark.
>Indeed, even in context, ...
>
>Cheers,
>
>Andrew
>
>
>On Thu, Dec 26, 2013 at 8:38 AM, Rolf Turner
><r.turner at auckland.ac.nz>wrote:
>
>> On 25/12/13 06:23, Jeff Newmiller wrote:
>>
>>     <SNIP>
>>
>>> In short, if you ask us why one divided by zero doesn't give 3, we
>have
>>> to wonder if you don't belong in some other educational forum.
>>>
>>     <SNIP>
>>
>> Fortune!
>>
>>     cheers,
>>
>>     Rolf Turner
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From jsorkin at grecc.umaryland.edu  Thu Dec 26 01:14:36 2013
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Wed, 25 Dec 2013 19:14:36 -0500
Subject: [R] error in "ca.jo"
In-Reply-To: <db28a884-a75b-4b37-a4f6-b502f57ac4c7@email.android.com>
References: <CAFxDEqLOGbzTYVUjsJHRwen=tW5ad6-_sVJJ01BvVZ_WRdNKCg@mail.gmail.com>
	<52B88A4F.9040603@pburns.seanet.com>
	<CAFxDEqKyvR4y0Xg-LW8PDnn6O0NjAT2Mu+2-mrmy0rYkygMzJA@mail.gmail.com>
	<2954bba2-ff43-4137-9d79-45f56e8f68e3@email.android.com>
	<52BB5068.3060705@auckland.ac.nz>
	<CAHyGmd4vB2RsNkpSouTPRyikCQDcWyBad6=bd0fYcvbdarrL2Q@mail.gmail.com>
	<db28a884-a75b-4b37-a4f6-b502f57ac4c7@email.android.com>
Message-ID: <52BB2EA4020000CB000FBFE0@smtp.medicine.umaryland.edu>

Please, everyone civility is a positive virtue
J

Sent from my iPhone

> On Dec 25, 2013, at 7:11 PM, "Jeff Newmiller <jdnewmil at dcn.davis.ca.us>" <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Out of context, I would agree with you. However, I stand behind it as regards the original question... the OP should have had no trouble recognizing what the error message meant and what to do about it if they were even somewhat familiar with the applicable theory (differential equations), and this is not the appropriate forum for that conversation.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
>> I respectfully disagree.  Taken out of context, this would be simply
>> snark.
>> Indeed, even in context, ...
>> 
>> Cheers,
>> 
>> Andrew
>> 
>> 
>> On Thu, Dec 26, 2013 at 8:38 AM, Rolf Turner
>> <r.turner at auckland.ac.nz>wrote:
>> 
>>> On 25/12/13 06:23, Jeff Newmiller wrote:
>>> 
>>>    <SNIP>
>>> 
>>>> In short, if you ask us why one divided by zero doesn't give 3, we
>> have
>>>> to wonder if you don't belong in some other educational forum.
>>>    <SNIP>
>>> 
>>> Fortune!
>>> 
>>>    cheers,
>>> 
>>>    Rolf Turner
>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Confidentiality Statement:
This email message, including any attachments, is for th...{{dropped:6}}


From aurelien.philippot at gmail.com  Thu Dec 26 12:26:46 2013
From: aurelien.philippot at gmail.com (=?ISO-8859-1?Q?Aur=E9lien_Philippot?=)
Date: Thu, 26 Dec 2013 03:26:46 -0800
Subject: [R] Problem with uniroot.all
Message-ID: <CAOwh97uDmsuDEdC_9MGHmz3Oh85m5-4YtrDgtDf6G7auGFhZig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131226/7b6daf87/attachment.pl>

From murdoch.duncan at gmail.com  Thu Dec 26 12:59:13 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Dec 2013 06:59:13 -0500
Subject: [R] Problem with uniroot.all
In-Reply-To: <CAOwh97uDmsuDEdC_9MGHmz3Oh85m5-4YtrDgtDf6G7auGFhZig@mail.gmail.com>
References: <CAOwh97uDmsuDEdC_9MGHmz3Oh85m5-4YtrDgtDf6G7auGFhZig@mail.gmail.com>
Message-ID: <52BC1A11.40103@gmail.com>

On 13-12-26 6:26 AM, Aur?lien Philippot wrote:
> Dear R experts,
> I am trying to find all the solutions of an equation. Here is an example:
>
>
> integrand1<- function(x){1/x*dnorm(x)}
> integrand2<- function(x){1/(2*x-50)*dnorm(x)}
>
> integrand3<- function(x,C){
>    cd<- 1/(x+C)
>    return(cd)
> }
>
> res<- function(C){
>    ce<-integrate(integrand1, lower=1, upper=50)$value+ integrate(integrand2,
> lower=50, upper=100)$value-integrate(integrand3, C=C,lower=1,
> upper=100)$value
>    return(ce)
> }
>
> I want to find all the roots of res.
>
> First, I used uniroot to ensure that a solution existed, and it works.
> uniroot(res, c(1,1000))
>
> But,  there might be other roots, and I wanted to use the function uniroot.
> library(rootSolve)
> uniroot.all(res, c(1,1000))
>
> I obtain an error message:
> "Error in integrate(integrand3, C = C, lower = 1, upper = 100) :
>    evaluation of function gave a result of wrong length
> In addition: Warning message:
> In x + C : longer object length is not a multiple of shorter object length"
>
> I don't understand what is wrong? Thank you very much for any suggestion!

You can often use traceback() to find where the error came from:

3: integrate(integrand3, C = C, lower = 1, upper = 100) at #2
2: f(xseq, ...)
1: uniroot.all(res, c(1, 1000))

Not very informative, but notice that on line 2 the argument to f is 
called xseq.  If you call debug(res) and try again, it will break on the 
first call to res, and you can print C:

Browse[2]> C
   [1]    1.00   10.99   20.98   30.97   40.96   50.95   60.94   70.93 
  80.92   90.91  100.90  110.89  120.88  130.87  140.86  150.85
  [17]  160.84  170.83  180.82  190.81  200.80  210.79  220.78  230.77 
240.76  250.75  260.74  270.73  280.72  290.71  300.70  310.69
  [33]  320.68  330.67  340.66  350.65  360.64  370.63  380.62  390.61 
400.60  410.59  420.58  430.57  440.56  450.55  460.54  470.53
  [49]  480.52  490.51  500.50  510.49  520.48  530.47  540.46  550.45 
560.44  570.43  580.42  590.41  600.40  610.39  620.38  630.37
  [65]  640.36  650.35  660.34  670.33  680.32  690.31  700.30  710.29 
720.28  730.27  740.26  750.25  760.24  770.23  780.22  790.21
  [81]  800.20  810.19  820.18  830.17  840.16  850.15  860.14  870.13 
880.12  890.11  900.10  910.09  920.08  930.07  940.06  950.05
  [97]  960.04  970.03  980.02  990.01 1000.00

Aha!  uniroot.all() passes a vector of values to the function, whereas 
uniroot passes values one at a time.  You need to make sure res can 
handle a vector of C values.  The easiest method is to use Vectorize to 
vectorize it:

res <- Vectorize(res)

This isn't very fast, but in your function, it's fine.

Duncan Murdoch

P.S.  You might want to write to the maintainer of uniroot.all to point 
out that the documentation doesn't mention this difference from uniroot.


From jvadams at usgs.gov  Thu Dec 26 14:22:10 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 26 Dec 2013 07:22:10 -0600
Subject: [R] Erroneous Column Removing Result From User-Defined
	Function.....
In-Reply-To: <CEE0DDB6.DB3C%lterlemez@anadolu.edu.tr>
References: <CEE0DDB6.DB3C%lterlemez@anadolu.edu.tr>
Message-ID: <CAN5YmCEcDBTrnSeY7YW0FJG0N4PFh4OQUrBXT5zizc9ZH5MFnw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131226/e346785d/attachment.pl>

From bbolker at gmail.com  Thu Dec 26 15:39:01 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 26 Dec 2013 09:39:01 -0500
Subject: [R] Fitdistr and mle
In-Reply-To: <1388049189.58064.YahooMailNeo@web173201.mail.ir2.yahoo.com>
References: <1387825583.42562.YahooMailNeo@web173205.mail.ir2.yahoo.com>	<loom.20131224T165535-1@post.gmane.org>	<1387920432.23500.YahooMailNeo@web173205.mail.ir2.yahoo.com>
	<loom.20131225T174143-996@post.gmane.org>
	<1388049189.58064.YahooMailNeo@web173201.mail.ir2.yahoo.com>
Message-ID: <52BC3F85.5010207@gmail.com>

On 13-12-26 04:13 AM, Tia Borrelli wrote:
> 
> Thank you, this is code i'm running, very simple but my problem was on
> the interpretation of the difference between the functions.
> 
> library(fImport)
> data.oggi = Sys.timeDate()
> ftse_mib = yahooSeries("FTSEMIB.MI", from="2009-09-01", to=data.oggi)
> portaf <- ftse_mib[,6]
> mrk_ftse <- portaf$FTSEMIB.MI.Adj.Close
> returns(mrk_ftse)
> library(quantmod)
> ret <- dailyReturn(portaf[,1])
> library(MASS)
> fitting <- fitdistr(ret,densfun="normal")
> print(c(mean(ret),sd(ret)))
> library(stats4)
> loglik <- function(media=0, devstd=1){
>   -sum(dnorm(ret, mean=media, sd=devstd, log=TRUE))
> }
> mle(loglik)
> 

  Thank you.

  I was wrong: a closer look inside the guts of MASS::fitdistr (which
you can do yourself) reveals that for densfun="normal" it is in fact
just calculating the mean and standard deviation of the data (and
scaling the standard deviation to convert from the usual unbiased
estimate of the standard deviation to the MLE).  In contrast, mle() is
using numerical optimization.

  If you look at the coefficients:

          fitdistr           mle
mean -3.270946e-06 -2.332673e-06
sd    1.692252e-02  1.697018e-02

and the standard errors shown by fitdistr
       mean             sd
 ( 5.102331e-04) ( 3.607893e-04)

  you'll see that although the mle and fitdistr estimate of the mean
vary *relatively* (the magnitude of the fitdistr estimate is 50% larger
than that from mle), relative to the standard errors they are tiny (the
differences in the mean estimate are two orders of magnitude smaller
than the standard error of the mean).  It is a fact of life when you're
doing numerical optimization that you're never going to get exactly the
right answer, due to various forms of numerical "fuzz" -- you just have
to know enough about the methods, and about your problem, to know
whether the answers are correct within sensible error bounds.


> 
> Il Mercoled? 25 Dicembre 2013 17:49, Ben Bolker <bbolker at gmail.com> ha
> scritto:
> Tia Borrelli <tiaborrelli <at> yahoo.it> writes:
> 
>>  Thanks for answering, in ret i've the returns of FTSE MIB (the
>> benchmark stock market index in Italy) and i'm estimating the
>> parametres of the distribution of the returns of the index using
>> different methods. 
> 
>   OK, but this still isn't a *reproducible* example (see e.g.
> http://tinyurl.com/reproducible-000 <http://tinyurl.com/reproducible-000>)
> 
>> I need the mle and i found this two function and i could not
>> understand why the result were different: it's possibile that i
>> obtain different result because in the mle() i don't need to know
>> the original distribution and in the fitdistr() i don't need to know
>> the function i had to maximize?
> 
>   In your example fitdistr() and mle() are doing the same thing under
> the hood, i.e.  using the built-in optim() function to minimize a
> negative log-likelihood function based on the built-in dnorm().
> fitdistr() picks the distribution for you based on your specification
> of which distribution to use; mle() requires you to specify the
> negative log-likelihood function (the mle2() function in the bbmle
> package is an extension of stats4::mle that offers a middle ground,
> e.g. you can say y ~ dnorm(mu,sigma) to specify the fit of a Normal
> distribution).  The differences between the results you get will be
> based on small numerical differences, e.g. the starting values of the
> parameters, or differences in the control parameters for optimization.
> In general you should get very similar, but not necessarily identical,
> answers from these two functions; big differences would probably
> indicate some kind of wonky data or numerical problem.  Again, we
> would need a reproducible example to see precisely what is going on.
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From tiaborrelli at yahoo.it  Thu Dec 26 15:41:33 2013
From: tiaborrelli at yahoo.it (Tia Borrelli)
Date: Thu, 26 Dec 2013 14:41:33 +0000
Subject: [R] Fitdistr and mle
In-Reply-To: <52BC3F85.5010207@gmail.com>
References: <1387825583.42562.YahooMailNeo@web173205.mail.ir2.yahoo.com>	<loom.20131224T165535-1@post.gmane.org>	<1387920432.23500.YahooMailNeo@web173205.mail.ir2.yahoo.com>
	<loom.20131225T174143-996@post.gmane.org>
	<1388049189.58064.YahooMailNeo@web173201.mail.ir2.yahoo.com>
	<52BC3F85.5010207@gmail.com>
Message-ID: <1388068893.75850.YahooMailNeo@web173206.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131226/ff942e72/attachment.pl>

From bartek.taciak at gmail.com  Wed Dec 25 17:47:01 2013
From: bartek.taciak at gmail.com (=?ISO-8859-2?Q?Bart=B3omiej_Taciak?=)
Date: Wed, 25 Dec 2013 17:47:01 +0100
Subject: [R] Counts of duplicate rows as a new column without grouping of
 duplicates raws.
Message-ID: <CA+K+Tuq1zYR1Pm9-MUTbbu3V=DXh-8JO5556=uRm1McuAoQWcw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131225/3e6dde10/attachment.pl>

From lili at piazza.com.pa  Wed Dec 25 22:54:27 2013
From: lili at piazza.com.pa (Alisa Esperova)
Date: Wed, 25 Dec 2013 22:54:27 +0100
Subject: [R] =?koi8-u?b?+sTP0s/Xzywg0M/R18nM09Eg18HSycHO1Cwg2sHT1MHXydTY?=
	=?koi8-u?b?INfF0s7V1NjT0SDaxM/Sz9fPxSDa0sXOycU=?=
Message-ID: <9D65FFEBDE724D179EEB4E6E38A741FB@qumh>

  ??????????? ?????? ???????, ????? ????, ????? ??? ????? ? ? ?????????? ????????? ???????????? ???? ????????????????? ????? ? ????? ??????? ?? ??? ??? ????? ? ????. ??? ?????? ????????, ??????????????, ???????????? ?????????? ? ?? ??? ???? ???? ????????. 
  ? ???? ?? ?? ?????? ???????????? ???? ????????????????? ?????, ???????? ?? ??????. ? ???? ?? ??? ?? ??????? ???????? ???? ??????? ??????? ?? ?????????? ? ?????????????? ????????????? ??????? - ???????? ????. 
      ?????? ???? ?????????????: ?????????? ??? ????????, ??? ?? ??? ?????? ???? ???? ?? - ???? ?? + ????, ??????? ?????????? ?? ????. ????????? ?????? ????? ??????? ????????? ????????? ??? ? ?????? ???????? ?????????? ?????. http://goo.gl/5o78ou


From vwmoriarty at gmail.com  Thu Dec 26 05:04:20 2013
From: vwmoriarty at gmail.com (Vinny Moriarty)
Date: Wed, 25 Dec 2013 23:04:20 -0500
Subject: [R] Results from Vegan metaMDS varry depending on set.seed
Message-ID: <CAJzJDtG=G18re3w2Gi-cB9C-jAFO0S3V0c7kmfFcE6Nmnpp9=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131225/a015a97a/attachment.pl>

From smartpink111 at yahoo.com  Thu Dec 26 17:39:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 26 Dec 2013 08:39:30 -0800 (PST)
Subject: [R] Counts of duplicate rows as a new column without grouping
	of duplicates raws.
In-Reply-To: <CA+K+Tuq1zYR1Pm9-MUTbbu3V=DXh-8JO5556=uRm1McuAoQWcw@mail.gmail.com>
References: <CA+K+Tuq1zYR1Pm9-MUTbbu3V=DXh-8JO5556=uRm1McuAoQWcw@mail.gmail.com>
Message-ID: <1388075970.49730.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
dat1 <- read.table(text="A??? B??? C
1 a??? 1??? ff
2 b??? 1??? re
3 c??? 1??? sd
5 a??? 2??? as
6 c??? 4??? fe
7 d??? 5????? tt
8 d??? 5????? tt
9 d??? 9????? oi",sep="",header=TRUE,stringsAsFactors=FALSE)

?within(dat1,D<-ave(seq_along(A),A,FUN=length))
A.K.




On Thursday, December 26, 2013 11:28 AM, Bart?omiej Taciak <bartek.taciak at gmail.com> wrote:
Hi everyone,

My data looks like this one:
?  A? ? B? ?  C
1 a? ?  1? ?  ff
2 b? ?  1? ?  re
3 c? ?  1? ?  sd
5 a? ?  2? ?  as
6 c? ?  4? ?  fe
7 d? ?  5? ? ? tt
8 d? ?  5? ? ? tt
9 d? ?  9? ? ? oi

I want to add a new column D, which will contain how many an element from
the column A is repeated, like this:
?  A? ? B? ?  C?  D
1 a? ?  1? ?  ff? ? 2
2 b? ?  1? ?  re? 1
3 c? ?  1? ?  sd? 2
5 a? ?  2? ?  as? 2
6 c? ?  4? ?  fe?  2
7 d? ?  5? ?  tt?  3
8 d? ?  5? ?  tt?  3
9 d? ?  9? ?  oi?  3

I don't want to simplify my data and grouping raws like in this thread:
https://stat.ethz.ch/pipermail/r-help/2011-March/270481.html

Thanks in advance for any help,
best regards,
Bartek

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Dec 26 17:48:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 26 Dec 2013 08:48:40 -0800 (PST)
Subject: [R] Counts of duplicate rows as a new column without grouping
	of duplicates raws.
In-Reply-To: <1388075970.49730.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CA+K+Tuq1zYR1Pm9-MUTbbu3V=DXh-8JO5556=uRm1McuAoQWcw@mail.gmail.com>
	<1388075970.49730.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1388076520.85332.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Also, you could try:
library(plyr)
ddply(dat1,.(A),mutate, D=length(A))

#or
library(data.table)
?dt1 <- data.table(dat1,key='A')
?dt1[,D:=.N,by='A']
A.K.




On , arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
dat1 <- read.table(text="A??? B??? C
1 a??? 1??? ff
2 b??? 1??? re
3 c??? 1??? sd
5 a??? 2??? as
6 c??? 4??? fe
7 d??? 5????? tt
8 d??? 5????? tt
9 d??? 9????? oi",sep="",header=TRUE,stringsAsFactors=FALSE)

?within(dat1,D<-ave(seq_along(A),A,FUN=length))
A.K.





On Thursday, December 26, 2013 11:28 AM, Bart?omiej Taciak <bartek.taciak at gmail.com> wrote:
Hi everyone,

My data looks like this one:
?? A? ? B? ?? C
1 a? ?? 1? ?? ff
2 b? ?? 1? ?? re
3 c? ?? 1? ?? sd
5 a? ?? 2? ?? as
6 c? ?? 4? ?? fe
7 d? ?? 5? ? ? tt
8 d? ?? 5? ? ? tt
9 d? ?? 9? ? ? oi

I want to add a new column D, which will contain how many an element from
the column A is repeated, like this:
?? A? ? B? ?? C?? D
1 a? ?? 1? ?? ff? ? 2
2 b? ?? 1? ?? re? 1
3 c? ?? 1? ?? sd? 2
5 a? ?? 2? ?? as? 2
6 c? ?? 4? ?? fe?? 2
7 d? ?? 5? ?? tt?? 3
8 d? ?? 5? ?? tt?? 3
9 d? ?? 9? ?? oi?? 3

I don't want to simplify my data and grouping raws like in this thread:
https://stat.ethz.ch/pipermail/r-help/2011-March/270481.html

Thanks in advance for any help,
best regards,
Bartek

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ross at biostat.ucsf.edu  Thu Dec 26 21:45:07 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 26 Dec 2013 12:45:07 -0800
Subject: [R] spending most of my time in assignments?
In-Reply-To: <52B39F67.8050905@gmail.com>
References: <1387496222.10351.77.camel@localhost> <52B39F67.8050905@gmail.com>
Message-ID: <1388090707.22575.14.camel@localhost>

On Thu, 2013-12-19 at 20:37 -0500, Duncan Murdoch wrote:
> On 13-12-19 6:37 PM, Ross Boylan wrote:
> > My code seems to be spending most of its time in assignment statements,
> > in some cases simple assignment of a model frame or model matrix.
> >
> > Can anyone provide any insights into what's going on, or how to speed
> > things up?
> 
> You are seeing a lot of time being spent on complex assignments.  For 
> example, line 158 is
> 
> data(sims.c1[[k]]) <- sp
> 
> That makes a function call to `data<-` to do the assignment, and that 
> could be slow.  Since it's an S4 method there's a bunch of machinery 
> involved in dispatching it; most of that would not have line number 
> information, so it'll be charged to that line.
> 
> I can't really suggest how to speed it up.
> 
> Duncan Murdoch
Simply reexpressing the same computations without assigning to S4 slots
or dispatching using S4 cut the execution time to under 50% of what it
had been.

I attempted to recreate this with a small bit of code, but got nothing
like the effect in the original. 

Here's the example; v1 is like my original code and v2 is like the
restructured code:
slow <- setClass("slow",
                 representation(form="formula",  data="data.frame", mm="matrix"))
slowb <- setClass("slowb", representation(form="formula", data="data.frame", mm="matrix"))
slowc <- setClass("slowc", representation(form="formula", data="data.frame", mm="matrix"))
# original had only 3 classes
# fake data.  Using my real data didn't seem to affect relative times much.
# real data had ~ 100 columns in model matrix                                                                                                                                                                                                                                                             
mydata <- data.frame(a=rnorm(1500), b=rnorm(1500), c=rnorm(1500),d=as.factor(rep(c("x", "y", "z"), 500)))
myformula <- ~a*d + b*d + c*d
mymm <- model.matrix(myformula, mydata)

if (!isGeneric("putData<-"))
  setGeneric("putData<-", function(obj, value) standardGeneric("putData<-"))

setMethod("putData<-", c("slow", "data.frame"),
          function(obj, value){
            myf <- model.frame(obj at form, value)
            obj at data <- myf
            obj at mm <- model.matrix(obj at form, myf)
            obj
          }
)
setMethod("putData<-", c("slowb", "data.frame"),
          function(obj, value){
            myf <- model.frame(obj at form, value)
            obj at data <- myf
            obj at mm <- model.matrix(obj at form, myf)
            obj
          }    
)
setMethod("putData<-", c("slowc", "data.frame"),
          function(obj, value){
            myf <- model.frame(obj at form, value)
            obj at data <- myf
            obj at mm <- model.matrix(obj at form, myf)
            obj
          }    
)

v1 <- function(n) {
  s <- list(slow(form=myformula, mm=mymm), 1:5)
  for (i in 1:n) {
    mydata$b <- rnorm(nrow(mydata))
    putData(s[[1]]) <- mydata
  }
  mm <- s[[1]]@mm
}

# v2 eliminates the dispatch on putData and the assignment
# to the S4 slot
v2 <- function(n) {
  s <- slow(form=myformula, mm=mymm)
  for (i in 1:n) {
    mydata$b <- rnorm(nrow(mydata))
    myf <- model.frame(s at form, mydata)
    mm <- model.matrix(s at form, myf)
  }
  mm
}

> system.time(r <- v1(100))                                                                                                                                                                                                                                                   
    user  system elapsed
   0.304   0.000   0.307                                                                                                                                                                                                                                                       
> system.time(r <- v2(100))                                                                                                                                                                                                                                                   
    user  system elapsed
    0.26    0.00    0.26

Ross Boylan

> 
> >
> > For starters, is it possible that the reports are not accurate, or that
> > I am misreading them.  In R 3.0.1 (running under ESS):
> >   > Rprof(line.profiling=TRUE)
> >   > system.time(r <- totalEffect(dodata[[1]], dodata[[2]], 1:3, 4))
> >      user  system elapsed
> >    21.629   0.756  22.469
> > !> Rprof(NULL)
> >   > summaryRprof(lines="both")
> >   $by.self
> >                              self.time self.pct total.time total.pct
> >   box.R#158                       6.74    29.56      13.06     57.28
> >   simulator.multinomial.R#64      2.92    12.81       2.96     12.98
> >   simulator.multinomial.R#63      2.76    12.11       2.76     12.11
> >   box.R#171                       2.54    11.14       5.08     22.28
> >   simulator.d1.R#70               0.98     4.30       0.98      4.30
> >   simulator.d1.R#71               0.98     4.30       0.98      4.30
> >   densMap.R#42                    0.72     3.16       0.86      3.77
> >   "standardGeneric"               0.52     2.28      11.30     49.56
> > ......
> >
> > Here's some of the code, with comments at the line numbers
> > box.R:
> >                  sp <- merge(sexpartner, data, by="studyidx")
> >                  sp$y <- numFactor(sp$pEthnic)  #I think y is not used but must be present
> >                  data(sims.c1[[k]]) <- sp    ###<<<<< line 158
> >                  sp0 <- sp
> >                  sp <- sim(sims.c1[[k]], i)
> >                  ctable[[k]] <- update.c1(ctable[[k]], sp)
> >                  if (is.null(i.c1.in)) {
> >                      i.c1.in <- match("pEthnic", colnames(sp0))
> >                      i.c1.out <- match(c("studyidx", "n", "pEthnic"), colnames(sp))
> >                  }
> >                  sp0 <- merge(sp0[,-i.c1.in], sp[,i.c1.out], by=c("studyidx", "n"))
> >                  # d1
> >                  sp0 <- sp0[sp0$pIsMale == 1,]
> >                  # avoid lots of conversion warnings
> >                  sp0$pEthnic <- factor(sp0$pEthnic, levels=partRaceLevels)
> >                  data(sims.d1[[k]]) <- sp0    ###<<<<< line 171
> >                  sp <- sim(sims.d1[[k]], i)
> >                  dtable[[k]] <- update.d1(dtable[[k]], sp)
> >                  rngstate[[k]] <- .Random.seed
> > The timing seems odd since it doesn't appear there's anything to do at
> > the 2 lines except invoke data<-, but if that's slow I would expect the
> > time to go to the data<- function (in a different file) and not to the
> > call.
> >
> > In fact the other big time items are inside the data<- functions.
> > simulator.multinomial.R:
> >
> >     setMethod("data<-", c("simulator.multinomial", "data.frame"),
> >            function(obj, value) {
> >      mf <- model.frame(obj at dataFormula, data=value)
> >      mf$iCluster <- fromOrig(obj at idmap, as.character(mf$studyidx))
> >      if (any(is.na(mf$iCluster)))
> >          stop("New studyidx--need to draw from meta distn")
> >      mm <- model.matrix(obj at modelFormula, data=mf)
> >      obj at data <- mf  ##<<< line 63
> >      obj at mm <- mm    ##<<< line 64
> >      return(obj)
> > })
> >
> > The mm and data slots have type restrictions, but no other validation
> > tests.
> > setClass("simulator.multinomial",
> >           representation(fit="stanfit", idmap="sIDMap",
> >                          modelFormula="formula",
> >                          categories="ANY",  # could be factor or character
> >                                          # categories should be in the order of their numeric codes in y
> >                          # cached results
> >                          coef="list",
> >                          data="data.frame",
> >                          dataFormula="formula",
> >                          mm="matrix"))
> > Does it matter that, e.g., a model frame is more than a vanilla data frame?
> >
> > I thought assignment, given R's lazy copying behavior, was essentially
> > resetting a pointer, and so should be fast.
> >
> > Or maybe the time is going to garbage collecting the previous contents
> > of the slots?
> >
> > Ross Boylan
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From 538280 at gmail.com  Thu Dec 26 22:12:09 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 26 Dec 2013 14:12:09 -0700
Subject: [R] The difference between SAS and R
In-Reply-To: <B9BEDA1F-95E6-4CF4-9827-CE0B1660BB36@gmail.com>
References: <CAKFxdiSPY3wGOx52GwqUz=QHrrc6Zdxh2Lyn3MB817ipMeqJAg@mail.gmail.com>
	<B9BEDA1F-95E6-4CF4-9827-CE0B1660BB36@gmail.com>
Message-ID: <CAFEqCdyjQh8n6Pwm9VuTbRhht-3mOZqnfBu1VU44xQSxhJPsGw@mail.gmail.com>

When I first saw that comic, my thought was "where would APL fit in
that graph?" (http://en.wikipedia.org/wiki/APL_(programming_language))

On Sun, Dec 22, 2013 at 2:00 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On 20 Dec 2013, at 18:53 , Kevin Wright <kw.stat at gmail.com> wrote:
>
>> SAS uses words.  R uses symbols.
>>
>> See this:
>> http://xkcd.com/1306/
>>
>> (Yes, I know IML uses plenty of symbols.  It's just supposed to be funny.
>> And somewhat true.)
>>
>
> Actually, R is on par with C++ when it comes to _prefixed_ symbols like #missedthepoint, which is what the XKCD strip is about. In terms of general operators, SAS would be approaching COBOL (famous for "ADD YEARS TO AGE" like construct) were it not for the DATA step and the %MACRO language.
>
> (The preceding XKCD (1305) is quite nice, by the way.)
>
>> --
>> Kevin Wright
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From 538280 at gmail.com  Thu Dec 26 23:26:44 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 26 Dec 2013 15:26:44 -0700
Subject: [R] R command execution at specific time from within R
In-Reply-To: <CABfqsR_8SRqB2Nuw3wMkvjO7CxReW9KE2gLVww1NaD+7ruevNw@mail.gmail.com>
References: <CABfqsR_8SRqB2Nuw3wMkvjO7CxReW9KE2gLVww1NaD+7ruevNw@mail.gmail.com>
Message-ID: <CAFEqCdx4AYygTax1_qV-3M=Azgj_JH-gQNUCh_TYzpCLMoUUcA@mail.gmail.com>

If you really have to do this within R (see Dirk's reply for other
options) then the tclTaskSchedule function in the tcltk2 package is
one option.  However this can be dangerous if you are using the same
instance of R while waiting.  You might accidentally change something
that affects or is affected by the scheduled code and create a hard to
find bug.


Another is just to use a repeat loop with Sys.sleep for the delays.
This will not allow you to use that instance of R for anything else.



On Mon, Dec 23, 2013 at 8:57 AM, Costas Vorlow <costas.vorlow at gmail.com> wrote:
> Hello,
>
> I am trying to write a code that executes an R command at specific time
> intervals.
>
> ? want R to do that instead of the operating system.
>
> Any help/pointer extremely welcome.
>
> Thanks in advance,
> Costas
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From friendly at yorku.ca  Thu Dec 26 23:39:07 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 26 Dec 2013 17:39:07 -0500
Subject: [R] Categorial data analysis
In-Reply-To: <CA+9PSGJVwSXuDoZyTjbOXtqVa66hRT0XOf51MPe5UBTNTGU2xg@mail.gmail.com>
References: <CA+9PSGJVwSXuDoZyTjbOXtqVa66hRT0XOf51MPe5UBTNTGU2xg@mail.gmail.com>
Message-ID: <52BCB00B.5020702@yorku.ca>

On 12/25/2013 3:58 AM, Guy Rotem wrote:
> Hi,
> I want to analysis the effect of two continuous independent variables (rain
> and slope) on a categorical dependent variable (soil type).
> Do you know how doing it?

You could look a my short course notes for Visualizing Categorical Data 
with SAS and R, http://www.datavis.ca/courses/VCD/,
Section 5, Polytomous response models.  Various possibilities exist,
depending on whether soil type is ordinal or nominal.

Some of the R functions (among others) for fitting these models are:
polr in the MASS package
multinom in the nnet package


HTH
-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From ville.hallikainen at metla.fi  Thu Dec 26 23:39:03 2013
From: ville.hallikainen at metla.fi (Hallikainen Ville (METLA))
Date: Thu, 26 Dec 2013 22:39:03 +0000
Subject: [R] Problems installing some packages using Ubuntu 12.04
Message-ID: <5C63B3A12783404593B1FD860CF9D31B4698B0@FIHGA-EXMBX01.msvyvi.vaha.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131226/f4e01fab/attachment.pl>

From ligges at statistik.tu-dortmund.de  Fri Dec 27 01:32:28 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 27 Dec 2013 01:32:28 +0100
Subject: [R] Problems installing some packages using Ubuntu 12.04
In-Reply-To: <5C63B3A12783404593B1FD860CF9D31B4698B0@FIHGA-EXMBX01.msvyvi.vaha.local>
References: <5C63B3A12783404593B1FD860CF9D31B4698B0@FIHGA-EXMBX01.msvyvi.vaha.local>
Message-ID: <52BCCA9C.5020906@statistik.tu-dortmund.de>



On 26.12.2013 23:39, Hallikainen Ville (METLA) wrote:
> Dear R people using Ubuntu
>
> I'd like to run R in my Ubuntu 12.04. I have R v. 3.02. Many packages are available, but package mi is not. Loading indicates a zero status. I have tried to install it from carn using the terminal commands and via R-studio. I have install it into my Mac recently and it works. What's wrong with it?


And what is the error message?

Best,
Uwe Ligges

> Ville Hallikainen, The Finnish Forest Research Institute
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jari.oksanen at oulu.fi  Fri Dec 27 13:22:30 2013
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Fri, 27 Dec 2013 12:22:30 +0000
Subject: [R] Results from Vegan metaMDS varry depending on set.seed
References: <CAJzJDtG=G18re3w2Gi-cB9C-jAFO0S3V0c7kmfFcE6Nmnpp9=w@mail.gmail.com>
Message-ID: <loom.20131227T130827-701@post.gmane.org>

Dear Vinny Moriarty,

Vinny Moriarty <vwmoriarty <at> gmail.com> writes:

> 
> I've got an ecological data set that I've worked up to the point of having
> a relative abundance matrix I created with the decostand() command in Vegan.
> 
> Here is the distance matrix data:
<-- clip: 8 x 4 data matrix giving distance object of 28 elements -->
> 
> At first I was having issues with metaMDS producing two distinctly
> different NMDS plots at seemingly random intervals as I re-ran my analysis
> over multiple runs. I figured out it was because I was not using
> set.seedfor my metaMDS call. But now I am concerned that the seemingly
> small change
> of setting set.seed() has such a large impact on my analysis.
> 
There are several issues here:

1) small changes in random seed should give completely different sequences. 
In fact, they should give as different sequences as with large changes in 
random seed. 

> As can be seen in the below oridplots, it looks to me like there is a
> change in relative distances between some of the latter  'sites'.
> 
> set.seed(1)
> mds10<- metaMDS(DF, dist='bray')
> 
> ordiplot(mds10,display='sites',type='text')
> 
> vs.
> 
> set.seed(999)
> mds10<- metaMDS(DF, dist='bray')
> 
2) set.seed(1) indeed seems to get trapped in the local minimum (which is 
equal to the initial solution based on PCoA).

> ordiplot(mds10,display='sites',type='text')
> 
> The difference between the two plots is large enough that it would change
> my interpretation of my analysis, so as this is my first foray into NMDS I
> am a bit concerned. Can someone tell me if this is just part of how NMDS or
> Vegan works (different local minimums)? Or does this imply a certain
> ambiguity about my data set? Or am I completely misreading the plots.
> 
3) You should not make too firm conclusions based on data of 8 points. You
need more data. I would not perform NMDS with 8 data points although it is
technically possible.

> If I add vector arrows for the 'species' influence like so:
> 
> envfit10<-envfit(mds10, DF,perm=999)
> plot(mds10, display='sites',type='t')
> plot(envfit10)
> 
> I can see that the two plots have different 'species' vectors, but it looks
> like the relative distance between S5 and some of the other sites changes
> between the two plots.
> 
> Is one ordiplot more 'correct' than the other? If not, what am I to make of
> the difference between plots?

4) NMDS and metaMDS() return you a goodness of fit statistic called stress.
Low stress is good (also in Christmas time). One of the solutions has lower 
stress, and in that sense it is more correct. It also seems that you do not
get any random configurations, but all analyses end up in two alternative
state. With set.seed(1) you get one state with higher stress, and with 
set.seed(999) you get another state with lower stress. This would indicate
that set.seed(1) gives you a local minimum, and set.seed(999) possibly a
global minimum. The best way of comparing solutions is to use 
procrustes() function of vegan which shows you that solutions go to
either of these groups. However, with 8 points you should not push your
analysis too far away to firm conclusions.

Cheers, Jari Oksanen


From emorway at usgs.gov  Fri Dec 27 14:28:19 2013
From: emorway at usgs.gov (Morway, Eric)
Date: Fri, 27 Dec 2013 05:28:19 -0800
Subject: [R] Averaging specified array indices
Message-ID: <CAPoqHzr=z=P6gUXrZdtm3Pvf7yD9nVMcoyWoDoMM4oHYF2Hosg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131227/ab1558c9/attachment.pl>

From pomchip at free.fr  Fri Dec 27 15:33:21 2013
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien_Bihorel?=)
Date: Fri, 27 Dec 2013 09:33:21 -0500
Subject: [R] Problem of scope
Message-ID: <CABR8ZvpGm+fho4H-b6qjfriYi6WHTJytsLUzqYvarMdhSwYhmg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131227/757c0e6a/attachment.pl>

From smartpink111 at yahoo.com  Fri Dec 27 15:42:12 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 27 Dec 2013 06:42:12 -0800 (PST)
Subject: [R] Averaging specified array indices
In-Reply-To: <CAPoqHzr=z=P6gUXrZdtm3Pvf7yD9nVMcoyWoDoMM4oHYF2Hosg@mail.gmail.com>
References: <CAPoqHzr=z=P6gUXrZdtm3Pvf7yD9nVMcoyWoDoMM4oHYF2Hosg@mail.gmail.com>
Message-ID: <1388155332.81059.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,

You could try:

res1 <- sapply(seq(dim(edm)[4]),function(i) mean(edm[do.call(rbind,lapply(xyz_indices,function(x) c(x,i)))],na.rm=TRUE)) 

#or
indx <- cbind(matrix(rep(unlist(xyz_indices),50),ncol=3,byrow=TRUE),rep(1:50,each=4))
res2 <-tapply(edm[indx],((seq(200)-1)%/%4)+1,mean)
?dimnames(res2)[[1]] <- NULL
?identical(res1,as.vector(res2))
#[1] TRUE



A.K.





On Friday, December 27, 2013 8:31 AM, "Morway, Eric" <emorway at usgs.gov> wrote:
In the larger problem I'm attempting to solve, I read a 2Gb file
into a 4D array, where the first 3 dimensions are related to space
(x, y, z), and the 4th dimension is time.? My goal is to find the
average of specific x, y, z-indices for each time step.

A small, reproducible example starts like this:

edm <- array(rnorm(20*20*4*50), dim=c(20,20,4,50))
xyz_indices <- list(c(2,10,1), c(4,5,1), c(6,7,1), c(19,13,1))

What's the best way to calculate the average of the x, y, z
indices specified in the "xyz_indices" list for each of the 50 time
steps represented by the 4th dimension of "edm"?? In other words,
I want to end up with a time series of length 50 where each value of
the series is the average of the 4 xyz_indices.


Eric

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ligges at statistik.tu-dortmund.de  Fri Dec 27 15:52:29 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 27 Dec 2013 15:52:29 +0100
Subject: [R] Problem of scope
In-Reply-To: <CABR8ZvpGm+fho4H-b6qjfriYi6WHTJytsLUzqYvarMdhSwYhmg@mail.gmail.com>
References: <CABR8ZvpGm+fho4H-b6qjfriYi6WHTJytsLUzqYvarMdhSwYhmg@mail.gmail.com>
Message-ID: <52BD942D.6020400@statistik.tu-dortmund.de>



On 27.12.2013 15:33, S?bastien Bihorel wrote:
> Hi,
>
> I have a problem of variable scope illustrated by the following example
> (this examples greatly simplifies the actual code I am working on but I
> unfortunately cannot share it). I have two functions, funa and funb: funb
> is called within funa. The goal of funb is to modify variables created
> within funa and also perform some some action using these variables.
> Obviously, there is something wrong with this code because the variables
> aa, bb, and cc have different values when they are printed in funa or funb.
>
> I have read the section about scope in the Introduction to R manual and do
> not really understand why my code is not working. Any suggestion will be
> greatly appreciated.


If you want that funb modifies objects in the environment of funa, you 
either have to access that environment explicitly or to allow that from 
the scoping rules easily, define funb within funa, so that funa is 
funb's parent:


funa <- function(x){
   # here is some code that defines the variables aa, bb, cc
   aa <- 11
   bb <- 21
   cc <- 31
   # fun b uses some input variable of funa to modify aa, bb, and cc

   funb <- function(x){
     aa <<- pi*x
     bb <<- 5*x
     cc <<- sin(x)
     cat(sprintf('funb: aa=%s, bb=%s, cc=%s\n',aa,bb,cc))
}

   funb(x)
   cat(sprintf('funa: aa=%s, bb=%s, cc=%s\n',aa,bb,cc))
}
funa(5)


Best,
Uwe Ligges




> Thanks
>
> ##### CODE STARTS HERE ####
>
> funa <- function(x){
>    # here is some code that defines the variables aa, bb, cc
>    aa <- 11
>    bb <- 21
>    cc <- 31
>    # fun b uses some input variable of funa to modify aa, bb, and cc
>    funb(x)
>    cat(sprintf('funa: aa=%s, bb=%s, cc=%s\n',aa,bb,cc))
> }
>
> funb <- function(x){
>
>    aa <<- pi*x
>    bb <<- 5*x
>    cc <<- sin(x)
>    cat(sprintf('funb: aa=%s, bb=%s, cc=%s\n',aa,bb,cc))
>
>    # Not executed
>    # here is some code that would do something with aa, bb, and cc
>    # plot(aa,bb)
> }
>
> funa(5)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jvadams at usgs.gov  Fri Dec 27 15:55:04 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 27 Dec 2013 08:55:04 -0600
Subject: [R] Averaging specified array indices
In-Reply-To: <CAPoqHzr=z=P6gUXrZdtm3Pvf7yD9nVMcoyWoDoMM4oHYF2Hosg@mail.gmail.com>
References: <CAPoqHzr=z=P6gUXrZdtm3Pvf7yD9nVMcoyWoDoMM4oHYF2Hosg@mail.gmail.com>
Message-ID: <CAN5YmCF-mT914oHD2P6+AwaXJbgsFOi_VU_NTVv0-N=L0KCFRg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131227/69e3e348/attachment.pl>

From jvadams at usgs.gov  Fri Dec 27 16:06:51 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 27 Dec 2013 09:06:51 -0600
Subject: [R] Problem of scope
In-Reply-To: <CABR8ZvpGm+fho4H-b6qjfriYi6WHTJytsLUzqYvarMdhSwYhmg@mail.gmail.com>
References: <CABR8ZvpGm+fho4H-b6qjfriYi6WHTJytsLUzqYvarMdhSwYhmg@mail.gmail.com>
Message-ID: <CAN5YmCFUGCkKfZxe_GBMt+e0B_QL4AA9kT9c22Q1YdUrMCn3ew@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131227/fb1281c5/attachment.pl>

From smartpink111 at yahoo.com  Fri Dec 27 16:46:14 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 27 Dec 2013 07:46:14 -0800 (PST)
Subject: [R] Changing names into number
Message-ID: <1388159174.6614.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Not able to reproduce the problem when "A" is a matrix

A <- as.matrix( read.table(text="nazwa1 nazwa3? 0,2531
nazwa7 nazwa5? 0,562
nazwa2 nazwa6? 0,65959",header=FALSE,sep=""))
?cbind(A[,1],A[,3])
#???? [,1]???? [,2]???? 
#[1,] "nazwa1" "0,2531" 
#[2,] "nazwa7" "0,562"? 
#[3,] "nazwa2" "0,65959"

#data.frame
A2 <- read.table(text="nazwa1 nazwa3? 0,2531
nazwa7 nazwa5? 0,562
nazwa2 nazwa6? 0,65959",header=FALSE,sep="",dec=",")

cbind(A2[,1],A2[,3])
#???? [,1]??? [,2]
#[1,]??? 1 0.25310
#[2,]??? 3 0.56200
#[3,]??? 2 0.65959
cbind(as.character(A2[,1]),A2[,3])
#???? [,1]???? [,2]???? 
#[1,] "nazwa1" "0.2531" 
#[2,] "nazwa7" "0.562"? 
#[3,] "nazwa2" "0.

?A2[,c(1,3)]
????? V1????? V3
1 nazwa1 0.25310
2 nazwa7 0.56200
3 nazwa2 0.65959


#If you have a character and numeric column, it is better to store in data.frame.
A.K.


Hi, i have one problem in. I have a matrix A: 
nazwa1 nazwa3 ?0,2531 
nazwa7 nazwa5 ?0,562 
nazwa2 nazwa6 ?0,65959 

When i use function cbind(A[,1], A[,3]) R gaves me matrix like this: 

1 ? 0,2531 
3 ? 0,562 
2 ? 0,65959 

But i want matrix: 
nazwa1 ?0,2531 
nazwa7 ? 0,562 
nazwa2 ? 0,6595 

I dont want to R changing names into number. How I can do this?


From pomchip at free.fr  Fri Dec 27 16:50:40 2013
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien_Bihorel?=)
Date: Fri, 27 Dec 2013 10:50:40 -0500
Subject: [R] Problem of scope
In-Reply-To: <CABR8ZvpGm+fho4H-b6qjfriYi6WHTJytsLUzqYvarMdhSwYhmg@mail.gmail.com>
References: <CABR8ZvpGm+fho4H-b6qjfriYi6WHTJytsLUzqYvarMdhSwYhmg@mail.gmail.com>
Message-ID: <CABR8ZvpLjRoNu=RMHApwsu+acoLom3uAM-DwbNrmN0+vjDpfUw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131227/20089c0a/attachment.pl>

From gunter.berton at gene.com  Fri Dec 27 18:11:05 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 27 Dec 2013 09:11:05 -0800
Subject: [R] Averaging specified array indices
In-Reply-To: <1388155332.81059.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CAPoqHzr=z=P6gUXrZdtm3Pvf7yD9nVMcoyWoDoMM4oHYF2Hosg@mail.gmail.com>
	<1388155332.81059.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CACk-te1BW2opDEANbENoT5tazwUm20TC4DswBzQnPE=LzfXGKA@mail.gmail.com>

I just wanted to note that Arun's first approach, which uses matrix
indexing -- often a very useful way to do these things, btw -- can be
simplified a bit.

m <- do.call(rbind,xyz_indices) ## 4x3 matrix
## avoids repeated evaluation. lapply is not needed as it's a list already

sapply(seq(dim(edm)[4]), function(i)mean(edm[cbind(m,i)]))

does it.

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Fri, Dec 27, 2013 at 6:42 AM, arun <smartpink111 at yahoo.com> wrote:
> HI,
>
> You could try:
>
> res1 <- sapply(seq(dim(edm)[4]),function(i) mean(edm[do.call(rbind,lapply(xyz_indices,function(x) c(x,i)))],na.rm=TRUE))
>
> #or
> indx <- cbind(matrix(rep(unlist(xyz_indices),50),ncol=3,byrow=TRUE),rep(1:50,each=4))
> res2 <-tapply(edm[indx],((seq(200)-1)%/%4)+1,mean)
>  dimnames(res2)[[1]] <- NULL
>  identical(res1,as.vector(res2))
> #[1] TRUE
>
>
>
> A.K.
>
>
>
>
>
> On Friday, December 27, 2013 8:31 AM, "Morway, Eric" <emorway at usgs.gov> wrote:
> In the larger problem I'm attempting to solve, I read a 2Gb file
> into a 4D array, where the first 3 dimensions are related to space
> (x, y, z), and the 4th dimension is time.  My goal is to find the
> average of specific x, y, z-indices for each time step.
>
> A small, reproducible example starts like this:
>
> edm <- array(rnorm(20*20*4*50), dim=c(20,20,4,50))
> xyz_indices <- list(c(2,10,1), c(4,5,1), c(6,7,1), c(19,13,1))
>
> What's the best way to calculate the average of the x, y, z
> indices specified in the "xyz_indices" list for each of the 50 time
> steps represented by the 4th dimension of "edm"?  In other words,
> I want to end up with a time series of length 50 where each value of
> the series is the average of the 4 xyz_indices.
>
>
> Eric
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alejandro.th.na at gmail.com  Fri Dec 27 17:34:47 2013
From: alejandro.th.na at gmail.com (alejandro.th.na at gmail.com)
Date: Fri, 27 Dec 2013 16:34:47 +0000
Subject: [R] =?utf-8?q?Trying_to_optimize_a_graph?=
Message-ID: <52bdad56.62d2b40a.1395.ffffe3e8@mx.google.com>

Hi, I don?t really have a problem, but I?m trying to improve my R abilities and I think I might use some help.


I?ve done this graph:


a<-.05; b<- 1; kr1<-70;kr2<-60;kr3<-50
K1<- kr1/a; K2<- kr2/a; K3<- kr3/a
curve(kr1*x*(b-a*x/kr1),col="blue",from=-50,to=1500,xlab="Nombre d'individus",ylab="Creixement"); 
curve(kr2*x*(b-a*x/kr2),col="green",add=T);
curve(kr3*x*(b-a*x/kr3),col="red",add=T);
title("Relaci? del creixement en funci? del nombre d'individus")
abline(h=0,v=0,lty=3)
legend("topright",legend =c("Kr1=70", "Kr2=60", "Kr3=50"),pch = 22, col=NA, pt.bg=c("blue","green","red"))
points(K1,0, col="blue",pch=20); text(K1,-1000,"K1=1400",col="blue")
points(K2,0, col="green",pch=20); text(K2,-1000,"K2=1200",col="green")
points(K3,0, col="red",pch=20); text(K3,-1000,"K3=1000",col="red")


And it has everything I need it to, but I?m sure I could have obtained the same image using a color vector, a kr vector and a K vector that gathers all my values for those variables. I know nothing about loops and I think they?re what?s needed here. 


Could you help me optimize this?


Thank you very much.

From ross at biostat.ucsf.edu  Fri Dec 27 20:49:50 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 27 Dec 2013 11:49:50 -0800
Subject: [R] gc() vs memory.profile()
Message-ID: <1388173790.22575.109.camel@localhost>

I am trying to understand why a function causes my memory use to
explode.  While doing that I noticed that my memory use as reported by
gc() is growing, but the results of memory.profile() are almost
unchanged (the count for raw grew by 3).  How can the two functions
produce different results, and what does it mean?

 >   system.time(r <- Reduce(addResults, bigr[1:10]))                                                                                                                                                                                                                          
    user  system elapsed
   3.437   0.000   3.444
 >   gc()                                                                                                                                                                                                                                                                      
             used   (Mb) gc trigger    (Mb)   max used    (Mb)
 Ncells   2994756  160.0    4418719   236.0    3587436   191.6
 Vcells 797226672 6082.4 2470056017 18845.1 7340162895 56001.0
 > memory.profile()
        NULL      symbol    pairlist     closure environment     promise
           1       13324     1193588       34602        3000        9754
    language     special     builtin        char     logical     integer
      305689          44         637       52237       53954      141713
      double     complex   character         ...         any        list
      548076          38      426187          39           0      116692
  expression    bytecode externalptr     weakref         raw          S4
           1       65604        4195         708         735       23935
 >   system.time(r <- Reduce(addResults, bigr[1:20]))                                                                                                                                                                                                                          
    user  system elapsed
   8.432   0.164  10.315   # suspiciously higher than 2* time for 10
 >   gc()                                                                                                                                                                                                                                                                      
             used   (Mb) gc trigger    (Mb)   max used    (Mb)
 Ncells   2994759  160.0    4418719   236.0    3587436   191.6
!Vcells 828653314 6322.2 2470056017 18845.1 7340162895 56001.0                                                                                                                                                                                                                 
 > memory.profile()
        NULL      symbol    pairlist     closure environment     promise
           1       13324     1193588       34602        3000        9754
    language     special     builtin        char     logical     integer
      305689          44         637       52237       53954      141713
      double     complex   character         ...         any        list
      548076          38      426187          39           0      116692
  expression    bytecode externalptr     weakref         raw          S4
           1       65604        4195         708         738       23935
# by eye, the only change is raw, from 735 to 738.

R 3.0.1 running on Debian GNU/Linux squeeze.

Ross Boylan


From thjagger at gmail.com  Fri Dec 27 20:04:45 2013
From: thjagger at gmail.com (Thomas Jagger)
Date: Fri, 27 Dec 2013 12:04:45 -0700
Subject: [R] Subject: Counts of duplicate rows as a new column without
 grouping of duplicates raws.
Message-ID: <CABoW5_UywUiMg4v-yJBL16Kn4oNwor5PSDWwkE2ZOcMMKRDq9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131227/348742e6/attachment.pl>

From thyagomoraes at hotmail.com  Fri Dec 27 21:17:42 2013
From: thyagomoraes at hotmail.com (Thyago Moraes)
Date: Fri, 27 Dec 2013 20:17:42 +0000
Subject: [R] Matchit
Message-ID: <COL127-W36CD0DA8D2E94BF4E2ABF8C4CD0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131227/ac57ba3d/attachment.pl>

From h.wickham at gmail.com  Fri Dec 27 23:47:59 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 27 Dec 2013 16:47:59 -0600
Subject: [R] gc() vs memory.profile()
In-Reply-To: <1388173790.22575.109.camel@localhost>
References: <1388173790.22575.109.camel@localhost>
Message-ID: <CABdHhvF=mcHJjHqv0OJmPM1Ld+vL5k0RgRG6qK7CmvwsVuHsAw@mail.gmail.com>

Hi Ross,

It's not obvious how useful memory.profile() is here. I created the
following little experiment to help me understand what
memory.profile() is showing (and to make it easier to see the
changes), but it's left me more confused than enlightened:

m_delta <- function(expr) {
  # Evaluate in clean environment to limit effects
  e <- new.env(parent = parent.frame())
  # Force gc to flush any values no longer attached to names
  gc()
  old <- memory.profile()

  eval(substitute(expr), env = e)

  gc()
  new <- memory.profile()

  report <- cbind(old, new, delta = new - old)
  # Only show rows where something changed
  report[report[, 3] != 0, ]
}

# Why does this create 3 pairlists, 1 integer and 1 character,
# but no doubles?
m_delta(x <- 1.5)

# No different
m_delta({x <- 1.5})
# Only creates an extra pairlist compared to the previous case
m_delta({x <- 1.5; y <- 2.5})

# Creates 2 pairlists, 1 integer and 1 character even the code
# should have no lasting impact
m_delta(1)

For your original case, you may find it more useful to do memory +
line profiling (e.g. as visualised by
https://github.com/hadley/lineprof) to figure out what's going on.

Hadley

On Fri, Dec 27, 2013 at 1:49 PM, Ross Boylan <ross at biostat.ucsf.edu> wrote:
> I am trying to understand why a function causes my memory use to
> explode.  While doing that I noticed that my memory use as reported by
> gc() is growing, but the results of memory.profile() are almost
> unchanged (the count for raw grew by 3).  How can the two functions
> produce different results, and what does it mean?
>
>  >   system.time(r <- Reduce(addResults, bigr[1:10]))
>     user  system elapsed
>    3.437   0.000   3.444
>  >   gc()
>              used   (Mb) gc trigger    (Mb)   max used    (Mb)
>  Ncells   2994756  160.0    4418719   236.0    3587436   191.6
>  Vcells 797226672 6082.4 2470056017 18845.1 7340162895 56001.0
>  > memory.profile()
>         NULL      symbol    pairlist     closure environment     promise
>            1       13324     1193588       34602        3000        9754
>     language     special     builtin        char     logical     integer
>       305689          44         637       52237       53954      141713
>       double     complex   character         ...         any        list
>       548076          38      426187          39           0      116692
>   expression    bytecode externalptr     weakref         raw          S4
>            1       65604        4195         708         735       23935
>  >   system.time(r <- Reduce(addResults, bigr[1:20]))
>     user  system elapsed
>    8.432   0.164  10.315   # suspiciously higher than 2* time for 10
>  >   gc()
>              used   (Mb) gc trigger    (Mb)   max used    (Mb)
>  Ncells   2994759  160.0    4418719   236.0    3587436   191.6
> !Vcells 828653314 6322.2 2470056017 18845.1 7340162895 56001.0
>  > memory.profile()
>         NULL      symbol    pairlist     closure environment     promise
>            1       13324     1193588       34602        3000        9754
>     language     special     builtin        char     logical     integer
>       305689          44         637       52237       53954      141713
>       double     complex   character         ...         any        list
>       548076          38      426187          39           0      116692
>   expression    bytecode externalptr     weakref         raw          S4
>            1       65604        4195         708         738       23935
> # by eye, the only change is raw, from 735 to 738.
>
> R 3.0.1 running on Debian GNU/Linux squeeze.
>
> Ross Boylan
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From ross at biostat.ucsf.edu  Sat Dec 28 00:05:46 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 27 Dec 2013 15:05:46 -0800
Subject: [R] gc() vs memory.profile()
In-Reply-To: <CABdHhvF=mcHJjHqv0OJmPM1Ld+vL5k0RgRG6qK7CmvwsVuHsAw@mail.gmail.com>
References: <1388173790.22575.109.camel@localhost>
	<CABdHhvF=mcHJjHqv0OJmPM1Ld+vL5k0RgRG6qK7CmvwsVuHsAw@mail.gmail.com>
Message-ID: <1388185546.22575.130.camel@localhost>

On Fri, 2013-12-27 at 16:47 -0600, Hadley Wickham wrote:
> For your original case, you may find it more useful to do memory +
> line profiling (e.g. as visualised by
> https://github.com/hadley/lineprof) to figure out what's going on.
> 
> Hadley 
I've been trying memory and line profiling, but memory="stats" or
"tseries" doesn't seem to work in summaryRProf.  I'm not sure if I've
misunderstood something or there are bugs:
 >   Rprof(memory.profiling=TRUE, gc.profiling=TRUE,
line.profiling=TRUE)  
 >   system.time(r <- Reduce(addResults,
bigr[1:10]))                                                                                                                                                                                                                          
    user  system elapsed
   3.408   0.000   3.415
 >   Rprof(NULL)    
 > summaryRprof(memory="both")
 $by.self
        self.time self.pct total.time total.pct mem.total
 "<GC>"      4.06      100       4.06       100       3.2

 $by.total
               total.time total.pct mem.total self.time self.pct
 "<GC>"              4.06    100.00       3.2      4.06      100
 "gc"                4.06    100.00       3.2      0.00        0
 "system.time"       4.06    100.00       3.2      0.00        0
 "f"                 3.42     84.24       3.2      0.00        0
 "Reduce"            3.42     84.24       3.2      0.00        0

 $sample.interval
 [1] 0.02

 $sampling.time
 [1] 4.06

 > summaryRprof(memory="tseries")
 Error in r[i1] - r[-length(r):-(length(r) - lag + 1L)] :
   non-numeric argument to binary operator
 In addition: Warning message:
 In data.frame(..., check.names = FALSE) :
   row names were found from a short variable and have been discarded
 > summaryRprof(memory="tseries", index=2)
 Error in r[i1] - r[-length(r):-(length(r) - lag + 1L)] :
   non-numeric argument to binary operator
 In addition: Warning message:
 In data.frame(..., check.names = FALSE) :
   row names were found from a short variable and have been discarded
 > summaryRprof(memory="both", diff=TRUE)  # diff=TRUE doesn't seem to
matter
 $by.self
        self.time self.pct total.time total.pct mem.total
 "<GC>"      4.06      100       4.06       100       3.2

 $by.total
               total.time total.pct mem.total self.time self.pct
 "<GC>"              4.06    100.00       3.2      4.06      100
 "gc"                4.06    100.00       3.2      0.00        0
 "system.time"       4.06    100.00       3.2      0.00        0
 "f"                 3.42     84.24       3.2      0.00        0
 "Reduce"            3.42     84.24       3.2      0.00        0

 $sample.interval
 [1] 0.02

 $sampling.time
 [1] 4.06

 > summaryRprof(memory="stats", diff=TRUE)
 Error in tapply(seq_len(1L), list(index = c("\"system.time\":\"gc
\"",  :
   arguments must have same length
 > summaryRprof(memory="stats")
 Error in tapply(seq_len(1L), list(index = c("\"system.time\":\"gc
\"",  :
!  arguments must have same length   

Even the memory="both", which at least runs, is not illuminating to me.
I guess it's saying that all the time is going to garbage collection. I
may try your tool to see if that helps.

Thanks.
Ross


From juliosergio at gmail.com  Sat Dec 28 00:33:02 2013
From: juliosergio at gmail.com (Julio Sergio Santana)
Date: Fri, 27 Dec 2013 23:33:02 +0000
Subject: [R] R strange behaviour when working with fifos
Message-ID: <loom.20131228T000958-769@post.gmane.org>

I'm trying to establish a connection to a pair of fifos in R, one represents 
the input stream of a process and the other one the output of the same 
process. The problem is that R behaves very different when running the 
commands directly in the interpreter than when running via a script file.

Here is the script

   #! /usr/bin/Rscript --vanilla
   #  The fifos (fifo1 and fifo2) were previously created 
   #  in Linux with mkfifo

   #  First we open fifo2 for reading:
   cc2 <- fifo("fifo2", "r+")

   # We launch a process just to count lines, words and chars,
   # with fifo1 as its input and fifo2 as its output, the 
   # process won't wait: 
   system("wc < fifo1 > fifo2", wait=F)

   # we write three lines on the process' input stream
   writeLines(c("uno dos tres", "cuatro cinco", "seis"), "fifo1")

   # Finally we read the output stream of the process
   (xx <- readLines(cc2)) ## <NOTE 1
   ## character(0)        ## <OUTPUT 1

   (yy <- readLines(cc2))           ## <NOTE 2
   ## [1] "      3       6      31" ## <OUTPUT 2
   close(cc2)

The very strage thing is that when executing in the interpreter line by 
line, the line labeled with "NOTE 1" yields, as expected, the output in the 
line labeled as "OUTPUT 2", whereas when executing via the script file, the 
line in "NOTE 1" reads nothing and it's necesary to execute an additional 
reading, as in line labeled with "NOTE 2", to have the desired output.

Do you have any comments in this matter?

Thanks,

 -Sergio.


From capricyg at yahoo.com  Sat Dec 28 04:25:59 2013
From: capricyg at yahoo.com (capricy gao)
Date: Fri, 27 Dec 2013 19:25:59 -0800 (PST)
Subject: [R] need help with distribution graphics
Message-ID: <1388201159.77842.YahooMailNeo@web125004.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131227/d0771f77/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sat Dec 28 13:28:06 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 28 Dec 2013 13:28:06 +0100
Subject: [R] need help with distribution graphics
In-Reply-To: <1388201159.77842.YahooMailNeo@web125004.mail.ne1.yahoo.com>
References: <1388201159.77842.YahooMailNeo@web125004.mail.ne1.yahoo.com>
Message-ID: <52BEC3D6.9090703@statistik.tu-dortmund.de>



On 28.12.2013 04:25, capricy gao wrote:
> I need to graph categorical data like a or b in the the following figure. Could anybody let me know what command line I should go with?


Figures are removed when this goes to the mailing list, so nobody knows 
what you are talking about. Better provide a link to some web resource.

Best,
Uwe Ligges



> Thanks a lot!
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sat Dec 28 13:29:48 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 28 Dec 2013 13:29:48 +0100
Subject: [R] Matchit
In-Reply-To: <COL127-W36CD0DA8D2E94BF4E2ABF8C4CD0@phx.gbl>
References: <COL127-W36CD0DA8D2E94BF4E2ABF8C4CD0@phx.gbl>
Message-ID: <52BEC43C.9050701@statistik.tu-dortmund.de>



On 27.12.2013 21:17, Thyago Moraes wrote:
> Dear Friends,
> I'm using Matchit package for a Cohor Study.
> After match the number provided by the summary output apparently don't correspond to the true value:
> Here the values provided by summary:>summary (test) Summary of Balance for Matched Data Age: Means treated 44.89; Means control 45.47
> However, after applying a test (for instance) I get:
>> mean in group control: 47.47 and for treated group: 44.89
> Why the means differ between this 2 functions (summary and t-test)? Am I missing anything about the means generated by the summary command after match?There is no missing data.
> Thank you in advance for your help and patience.

Please provide the code and a toy example so that we know what you 
actually did. Otherwise it is hard to help.

Best,
Uwe Ligges


> Thyago
>
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From agrimasrivastava1 at gmail.com  Sat Dec 28 16:15:42 2013
From: agrimasrivastava1 at gmail.com (agrima srivastava)
Date: Sat, 28 Dec 2013 20:45:42 +0530
Subject: [R] Error in loading package
Message-ID: <CACV9Ukq93ukMzGYOhTw3XjBinOCWjFiBGjMc8cFf8jjQ4W_62Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131228/2e68a138/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sat Dec 28 16:57:39 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 28 Dec 2013 16:57:39 +0100
Subject: [R] Error in loading package
In-Reply-To: <CACV9Ukq93ukMzGYOhTw3XjBinOCWjFiBGjMc8cFf8jjQ4W_62Q@mail.gmail.com>
References: <CACV9Ukq93ukMzGYOhTw3XjBinOCWjFiBGjMc8cFf8jjQ4W_62Q@mail.gmail.com>
Message-ID: <52BEF4F3.9080904@statistik.tu-dortmund.de>



On 28.12.2013 16:15, agrima srivastava wrote:
> Hi
> I am trying to install a packaage "qgraph"
> I am using
> install.packages("qgraph", dependencies=TRUE) for the same.
> After that when I type library('qgraph') I am getting this error
>
> Error in loadNamespace(i[[1L]], c(lib.loc, .libPaths())) :
> there is no package called 'ReadImages'
> Error: package/namespace load failed for 'qgraph'
>
> Please suggest a way to resolve this issue.




Try to install ReadImages?

Best,
Uwe Ligges


> Thanks in advance.
>


From kridox at ymail.com  Sat Dec 28 17:06:30 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Sun, 29 Dec 2013 01:06:30 +0900
Subject: [R] Error in loading package
In-Reply-To: <CACV9Ukq93ukMzGYOhTw3XjBinOCWjFiBGjMc8cFf8jjQ4W_62Q@mail.gmail.com>
References: <CACV9Ukq93ukMzGYOhTw3XjBinOCWjFiBGjMc8cFf8jjQ4W_62Q@mail.gmail.com>
Message-ID: <CAAcyNCwJHhCbpaMpTTcbdnvqriOnBeisMcQkZyUvuEXM5uYhwg@mail.gmail.com>

Hello,

My suggestion: read the error message.

Regards,
Pascal

On 29 December 2013 00:15, agrima srivastava
<agrimasrivastava1 at gmail.com> wrote:
> Hi
> I am trying to install a packaage "qgraph"
> I am using
> install.packages("qgraph", dependencies=TRUE) for the same.
> After that when I type library('qgraph') I am getting this error
>
> Error in loadNamespace(i[[1L]], c(lib.loc, .libPaths())) :
> there is no package called 'ReadImages'
> Error: package/namespace load failed for 'qgraph'
>
> Please suggest a way to resolve this issue.
>
> Thanks in advance.
>
> --
> Thanks and Regards
> Agrima Srivastava
> -------------------------------------------------------------------------------
> Research Scholar
> Computer Science & Information Systems Department
> BITS Pilani Hyderabad Campus
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From ripley at stats.ox.ac.uk  Sat Dec 28 17:33:04 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 28 Dec 2013 16:33:04 +0000
Subject: [R] Error in loading package
In-Reply-To: <CACV9Ukq93ukMzGYOhTw3XjBinOCWjFiBGjMc8cFf8jjQ4W_62Q@mail.gmail.com>
References: <CACV9Ukq93ukMzGYOhTw3XjBinOCWjFiBGjMc8cFf8jjQ4W_62Q@mail.gmail.com>
Message-ID: <52BEFD40.4090201@stats.ox.ac.uk>

On 28/12/2013 15:15, agrima srivastava wrote:
> Hi
> I am trying to install a packaage "qgraph"
> I am using
> install.packages("qgraph", dependencies=TRUE) for the same.
> After that when I type library('qgraph') I am getting this error
>
> Error in loadNamespace(i[[1L]], c(lib.loc, .libPaths())) :
> there is no package called 'ReadImages'
> Error: package/namespace load failed for 'qgraph'
>
> Please suggest a way to resolve this issue.
>
> Thanks in advance.
>

Look at http://cran.r-project.org/web/packages/ReadImages/index.html and
http://cran.r-project.org/web/packages/qgraph/index.html

It seems you have an ancient version of qgraph and that depends on a 
package which has not been available for about a year.

You failed to give the 'at a minimum' information required in the 
posting guide, so we can only guess how you managed this.  Perhaps

'f you are using an old version of R and think it does not work 
properly, upgrade to the latest version and try that, before posting.'

applies?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From capricyg at yahoo.com  Sat Dec 28 17:41:47 2013
From: capricyg at yahoo.com (capricy gao)
Date: Sat, 28 Dec 2013 08:41:47 -0800 (PST)
Subject: [R] need help with distribution graphics
In-Reply-To: <52BEC3D6.9090703@statistik.tu-dortmund.de>
References: <1388201159.77842.YahooMailNeo@web125004.mail.ne1.yahoo.com>
	<52BEC3D6.9090703@statistik.tu-dortmund.de>
Message-ID: <1388248907.96530.YahooMailNeo@web125002.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131228/888eb2cb/attachment.pl>

From bogaso.christofer at gmail.com  Sat Dec 28 18:26:16 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sat, 28 Dec 2013 23:11:16 +0545
Subject: [R] How to subset an 'ff' object?
Message-ID: <CA+dpOJk91CnC2=2mk437ih5htHRq3fzj7jvOeOnPrEVreu-G0w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131228/0aab11d5/attachment.pl>

From smartpink111 at yahoo.com  Sat Dec 28 19:18:29 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 28 Dec 2013 10:18:29 -0800 (PST)
Subject: [R] How to subset an 'ff' object?
In-Reply-To: <CA+dpOJk91CnC2=2mk437ih5htHRq3fzj7jvOeOnPrEVreu-G0w@mail.gmail.com>
References: <CA+dpOJk91CnC2=2mk437ih5htHRq3fzj7jvOeOnPrEVreu-G0w@mail.gmail.com>
Message-ID: <1388254709.67444.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI,

The dput() is showing error message.
Is it not possible to convert it to data.frame and subset?

Using the example from ?ffdf
?m <- matrix(1:12, 3, 4, dimnames=list(c("r1","r2","r3"), c("m1","m2","m3","m4")))
?????? v <- 1:3
?????? ffm <- as.ff(m)
?????? ffv <- as.ff(v)
? ffd <- ffdf(ffm, v=ffv, row.names=row.names(ffm))
d1 <- data.frame(ffd)


subset(d1,m1>1)
?? m1 m2 m3 m4 v
r2? 2? 5? 8 11 2
r3? 3? 6? 9 12 3


A.K.


On Saturday, December 28, 2013 12:29 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
Hi again,

I have loaded a huge csv file in R using 'ff' package, however could not
understand how can I subset the loaded object. Below is my try:

> suppressMessages(library(ff))
>
> Dat <- read.csv.ffdf(file = "f:/Book1.csv", header = F, colClasses =
c('Date', 'factor'))
> Dat
ffdf (all open) dim=c(4,2), dimorder=c(1,2) row.names=NULL
ffdf virtual mapping
?  PhysicalName VirtualVmode PhysicalVmode? AsIs VirtualIsMatrix
PhysicalIsMatrix PhysicalElementNo PhysicalFirstCol PhysicalLastCol
PhysicalIsOpen
V1? ? ? ? ?  V1? ? ?  double? ? ? ? double FALSE? ? ? ? ?  FALSE
FALSE? ? ? ? ? ? ? ?  1? ? ? ? ? ? ? ? 1? ? ? ? ? ? ?  1? ? ? ? ?  TRUE
V2? ? ? ? ?  V2? ? ? integer? ? ?  integer FALSE? ? ? ? ?  FALSE
FALSE? ? ? ? ? ? ? ?  2? ? ? ? ? ? ? ? 1? ? ? ? ? ? ?  1? ? ? ? ?  TRUE
ffdf data
? ? ? ? ? V1? ? ? ?  V2
1 2013-12-28 a
2 2013-12-28 b
3 2013-12-27 c
4 2013-12-27 c
>
> subset(Dat, Dat$V1 == as.Date('2013-12-27'))
ffdf (all open) dim=c(4,0), dimorder=c(1,2) row.names=NULL
ffdf virtual mapping
[1] PhysicalName? ? ? VirtualVmode? ? ? PhysicalVmode? ?  AsIs
VirtualIsMatrix?  PhysicalIsMatrix? PhysicalElementNo PhysicalFirstCol
PhysicalLastCol
[10] PhysicalIsOpen
<0 rows> (or 0-length row.names)
ffdf data
[1] "[empty matrix]"



My resulting object is showing '0' rows!


The 'Dat' object looks like below:

> dput(Dat)
structure(list(virtual = structure(list(VirtualVmode = c("double",
"integer"), AsIs = c(FALSE, FALSE), VirtualIsMatrix = c(FALSE,
FALSE), PhysicalIsMatrix = c(FALSE, FALSE), PhysicalElementNo = 1:2,
? ? PhysicalFirstCol = c(1L, 1L), PhysicalLastCol = c(1L, 1L)), .Names =
c("VirtualVmode",
"AsIs", "VirtualIsMatrix", "PhysicalIsMatrix", "PhysicalElementNo",
"PhysicalFirstCol", "PhysicalLastCol"), row.names = c("V1", "V2"
), class = "data.frame", Dim = c(4L, 2L), Dimorder = 1:2), physical =
structure(list(
? ? V1 = structure(list(), physical = <pointer: 0x0298f498>, virtual =
structure(list(), Length = 4L, Symmetric = FALSE, ramclass = "Date"), class
= c("ff_vector",
? ? "ff")), V2 = structure(list(), physical = <pointer: 0x0298f4c8>,
virtual = structure(list(), Length = 4L, Symmetric = FALSE, Levels = c("a",
? ? "b", "c"), ramclass = "factor"), class = c("ff_vector", "ff"
? ? ))), .Names = c("V1", "V2")), row.names = NULL), .Names = c("virtual",
"physical", "row.names"), class = "ffdf")


Can experts here guide me how to subset that?

Thanks for your time.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From bogaso.christofer at gmail.com  Sat Dec 28 19:29:29 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 29 Dec 2013 00:14:29 +0545
Subject: [R] How to subset an 'ff' object?
In-Reply-To: <1388254709.67444.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CA+dpOJk91CnC2=2mk437ih5htHRq3fzj7jvOeOnPrEVreu-G0w@mail.gmail.com>
	<1388254709.67444.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CA+dpOJkL5UAey0_kNPbr2YmUuzxYx+xuxrayk8QUmt0q==hKBg@mail.gmail.com>

Hi Arun,

I will look into why dput is giving error......... In the mean time I am
attaching the csv file with this mail, however not sure if R-hep will
accept it.

I tried to converting it data.frame. However as 'Dat' is of huge size (that
is why I loaded it via ff route), converting the entire data to data.frame
giving memory allocation problem.

Thanks and regards,


On Sun, Dec 29, 2013 at 12:03 AM, arun <smartpink111 at yahoo.com> wrote:

> HI,
>
> The dput() is showing error message.
> Is it not possible to convert it to data.frame and subset?
>
> Using the example from ?ffdf
>  m <- matrix(1:12, 3, 4, dimnames=list(c("r1","r2","r3"),
> c("m1","m2","m3","m4")))
>        v <- 1:3
>        ffm <- as.ff(m)
>        ffv <- as.ff(v)
>   ffd <- ffdf(ffm, v=ffv, row.names=row.names(ffm))
> d1 <- data.frame(ffd)
>
>
> subset(d1,m1>1)
>    m1 m2 m3 m4 v
> r2  2  5  8 11 2
> r3  3  6  9 12 3
>
>
> A.K.
>
>
> On Saturday, December 28, 2013 12:29 PM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> I have loaded a huge csv file in R using 'ff' package, however could not
> understand how can I subset the loaded object. Below is my try:
>
> > suppressMessages(library(ff))
> >
> > Dat <- read.csv.ffdf(file = "f:/Book1.csv", header = F, colClasses =
> c('Date', 'factor'))
> > Dat
> ffdf (all open) dim=c(4,2), dimorder=c(1,2) row.names=NULL
> ffdf virtual mapping
>    PhysicalName VirtualVmode PhysicalVmode  AsIs VirtualIsMatrix
> PhysicalIsMatrix PhysicalElementNo PhysicalFirstCol PhysicalLastCol
> PhysicalIsOpen
> V1           V1       double        double FALSE           FALSE
> FALSE                 1                1               1           TRUE
> V2           V2      integer       integer FALSE           FALSE
> FALSE                 2                1               1           TRUE
> ffdf data
>           V1         V2
> 1 2013-12-28 a
> 2 2013-12-28 b
> 3 2013-12-27 c
> 4 2013-12-27 c
> >
> > subset(Dat, Dat$V1 == as.Date('2013-12-27'))
> ffdf (all open) dim=c(4,0), dimorder=c(1,2) row.names=NULL
> ffdf virtual mapping
> [1] PhysicalName      VirtualVmode      PhysicalVmode     AsIs
> VirtualIsMatrix   PhysicalIsMatrix  PhysicalElementNo PhysicalFirstCol
> PhysicalLastCol
> [10] PhysicalIsOpen
> <0 rows> (or 0-length row.names)
> ffdf data
> [1] "[empty matrix]"
>
>
>
> My resulting object is showing '0' rows!
>
>
> The 'Dat' object looks like below:
>
> > dput(Dat)
> structure(list(virtual = structure(list(VirtualVmode = c("double",
> "integer"), AsIs = c(FALSE, FALSE), VirtualIsMatrix = c(FALSE,
> FALSE), PhysicalIsMatrix = c(FALSE, FALSE), PhysicalElementNo = 1:2,
>     PhysicalFirstCol = c(1L, 1L), PhysicalLastCol = c(1L, 1L)), .Names =
> c("VirtualVmode",
> "AsIs", "VirtualIsMatrix", "PhysicalIsMatrix", "PhysicalElementNo",
> "PhysicalFirstCol", "PhysicalLastCol"), row.names = c("V1", "V2"
> ), class = "data.frame", Dim = c(4L, 2L), Dimorder = 1:2), physical =
> structure(list(
>     V1 = structure(list(), physical = <pointer: 0x0298f498>, virtual =
> structure(list(), Length = 4L, Symmetric = FALSE, ramclass = "Date"), class
> = c("ff_vector",
>     "ff")), V2 = structure(list(), physical = <pointer: 0x0298f4c8>,
> virtual = structure(list(), Length = 4L, Symmetric = FALSE, Levels = c("a",
>     "b", "c"), ramclass = "factor"), class = c("ff_vector", "ff"
>     ))), .Names = c("V1", "V2")), row.names = NULL), .Names = c("virtual",
> "physical", "row.names"), class = "ffdf")
>
>
> Can experts here guide me how to subset that?
>
> Thanks for your time.
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

From smartpink111 at yahoo.com  Sat Dec 28 19:33:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 28 Dec 2013 10:33:58 -0800 (PST)
Subject: [R] How to subset an 'ff' object?
In-Reply-To: <CA+dpOJkL5UAey0_kNPbr2YmUuzxYx+xuxrayk8QUmt0q==hKBg@mail.gmail.com>
References: <CA+dpOJk91CnC2=2mk437ih5htHRq3fzj7jvOeOnPrEVreu-G0w@mail.gmail.com>	<1388254709.67444.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CA+dpOJkL5UAey0_kNPbr2YmUuzxYx+xuxrayk8QUmt0q==hKBg@mail.gmail.com>
Message-ID: <1388255638.25614.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi Christofer,
You can check ?subset.ff from library(ffbase)

subset(ffd,m1>1)
ffdf (all open) dim=c(2,5), dimorder=c(1,2) row.names=NULL
ffdf virtual mapping
?? PhysicalName VirtualVmode PhysicalVmode? AsIs VirtualIsMatrix
m1????????? ffm????? integer?????? integer FALSE?????????? FALSE
m2????????? ffm????? integer?????? integer FALSE?????????? FALSE
m3????????? ffm????? integer?????? integer FALSE?????????? FALSE
m4????????? ffm????? integer?????? integer FALSE?????????? FALSE
v???????????? v????? integer?????? integer FALSE?????????? FALSE
?? PhysicalIsMatrix PhysicalElementNo PhysicalFirstCol PhysicalLastCol
m1???????????? TRUE???????????????? 1??????????????? 1?????????????? 1
m2???????????? TRUE???????????????? 1??????????????? 2?????????????? 2
m3???????????? TRUE???????????????? 1??????????????? 3?????????????? 3
m4???????????? TRUE???????????????? 1??????????????? 4?????????????? 4
v???????????? FALSE???????????????? 2??????????????? 1?????????????? 1
?? PhysicalIsOpen
m1?????????? TRUE
m2?????????? TRUE
m3?????????? TRUE
m4?????????? TRUE
v??????????? TRUE
ffdf data
? m1 m2 m3 m4? v
1? 2? 5? 8 11? 2
2? 3? 6? 9 12? 3
A.K.







On Saturday, December 28, 2013 1:29 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:

Hi Arun,

I will look into why dput is giving error......... In the mean time I am attaching the csv file with this mail, however not sure if R-hep will accept it.

I tried to converting it data.frame. However as 'Dat' is of huge size (that is why I loaded it via ff route), converting the entire data to data.frame giving memory allocation problem.

Thanks and regards,



On Sun, Dec 29, 2013 at 12:03 AM, arun <smartpink111 at yahoo.com> wrote:

HI,
>
>The dput() is showing error message.
>Is it not possible to convert it to data.frame and subset?
>
>Using the example from ?ffdf
>?m <- matrix(1:12, 3, 4, dimnames=list(c("r1","r2","r3"), c("m1","m2","m3","m4")))
>?????? v <- 1:3
>?????? ffm <- as.ff(m)
>?????? ffv <- as.ff(v)
>? ffd <- ffdf(ffm, v=ffv, row.names=row.names(ffm))
>d1 <- data.frame(ffd)
>
>
>subset(d1,m1>1)
>?? m1 m2 m3 m4 v
>r2? 2? 5? 8 11 2
>r3? 3? 6? 9 12 3
>
>
>A.K.
>
>
>
>On Saturday, December 28, 2013 12:29 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi again,
>
>I have loaded a huge csv file in R using 'ff' package, however could not
>understand how can I subset the loaded object. Below is my try:
>
>> suppressMessages(library(ff))
>>
>> Dat <- read.csv.ffdf(file = "f:/Book1.csv", header = F, colClasses =
>c('Date', 'factor'))
>> Dat
>ffdf (all open) dim=c(4,2), dimorder=c(1,2) row.names=NULL
>ffdf virtual mapping
>? ?PhysicalName VirtualVmode PhysicalVmode? AsIs VirtualIsMatrix
>PhysicalIsMatrix PhysicalElementNo PhysicalFirstCol PhysicalLastCol
>PhysicalIsOpen
>V1? ? ? ? ? ?V1? ? ? ?double? ? ? ? double FALSE? ? ? ? ? ?FALSE
>FALSE? ? ? ? ? ? ? ? ?1? ? ? ? ? ? ? ? 1? ? ? ? ? ? ? ?1? ? ? ? ? ?TRUE
>V2? ? ? ? ? ?V2? ? ? integer? ? ? ?integer FALSE? ? ? ? ? ?FALSE
>FALSE? ? ? ? ? ? ? ? ?2? ? ? ? ? ? ? ? 1? ? ? ? ? ? ? ?1? ? ? ? ? ?TRUE
>ffdf data
>? ? ? ? ? V1? ? ? ? ?V2
>1 2013-12-28 a
>2 2013-12-28 b
>3 2013-12-27 c
>4 2013-12-27 c
>>
>> subset(Dat, Dat$V1 == as.Date('2013-12-27'))
>ffdf (all open) dim=c(4,0), dimorder=c(1,2) row.names=NULL
>ffdf virtual mapping
>[1] PhysicalName? ? ? VirtualVmode? ? ? PhysicalVmode? ? ?AsIs
>VirtualIsMatrix? ?PhysicalIsMatrix? PhysicalElementNo PhysicalFirstCol
>PhysicalLastCol
>[10] PhysicalIsOpen
><0 rows> (or 0-length row.names)
>ffdf data
>[1] "[empty matrix]"
>
>
>
>My resulting object is showing '0' rows!
>
>
>The 'Dat' object looks like below:
>
>> dput(Dat)
>structure(list(virtual = structure(list(VirtualVmode = c("double",
>"integer"), AsIs = c(FALSE, FALSE), VirtualIsMatrix = c(FALSE,
>FALSE), PhysicalIsMatrix = c(FALSE, FALSE), PhysicalElementNo = 1:2,
>? ? PhysicalFirstCol = c(1L, 1L), PhysicalLastCol = c(1L, 1L)), .Names =
>c("VirtualVmode",
>"AsIs", "VirtualIsMatrix", "PhysicalIsMatrix", "PhysicalElementNo",
>"PhysicalFirstCol", "PhysicalLastCol"), row.names = c("V1", "V2"
>), class = "data.frame", Dim = c(4L, 2L), Dimorder = 1:2), physical =
>structure(list(
>? ? V1 = structure(list(), physical = <pointer: 0x0298f498>, virtual =
>structure(list(), Length = 4L, Symmetric = FALSE, ramclass = "Date"), class
>= c("ff_vector",
>? ? "ff")), V2 = structure(list(), physical = <pointer: 0x0298f4c8>,
>virtual = structure(list(), Length = 4L, Symmetric = FALSE, Levels = c("a",
>? ? "b", "c"), ramclass = "factor"), class = c("ff_vector", "ff"
>? ? ))), .Names = c("V1", "V2")), row.names = NULL), .Names = c("virtual",
>"physical", "row.names"), class = "ffdf")
>
>
>Can experts here guide me how to subset that?
>
>Thanks for your time.
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From bbolker at gmail.com  Sat Dec 28 19:38:36 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 28 Dec 2013 18:38:36 +0000
Subject: [R] need help with distribution graphics
References: <1388201159.77842.YahooMailNeo@web125004.mail.ne1.yahoo.com>
	<52BEC3D6.9090703@statistik.tu-dortmund.de>
	<1388248907.96530.YahooMailNeo@web125002.mail.ne1.yahoo.com>
Message-ID: <loom.20131228T193600-388@post.gmane.org>

capricy gao <capricyg <at> yahoo.com> writes:

> 
> Really? 
> 
> OK, here the linked is an example:
> 
> http://iai.asm.org/content/77/10/4631/F1.expansion.html
> 
> Please, any input would be appreciated!

(helpful advice from Uwe Ligges deleted) 

> On 28.12.2013 04:25, capricy gao wrote: > I need to graph
> categorical data like a or b in the the following figure. Could
> anybody let me know what command line I should go with?

 These are called "beeswarm plots".  Try googling "beeswarm plot R" for
a variety of options ...

  Ben Bolker


From smartpink111 at yahoo.com  Sat Dec 28 19:40:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 28 Dec 2013 10:40:43 -0800 (PST)
Subject: [R] How to subset an 'ff' object?
In-Reply-To: <1388255638.25614.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CA+dpOJk91CnC2=2mk437ih5htHRq3fzj7jvOeOnPrEVreu-G0w@mail.gmail.com>	<1388254709.67444.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CA+dpOJkL5UAey0_kNPbr2YmUuzxYx+xuxrayk8QUmt0q==hKBg@mail.gmail.com>
	<1388255638.25614.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1388256043.28350.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
I tried your example dataset:
?Dat <- read.csv.ffdf(file="Book1.csv",header=FALSE,colClasses=c('Date','factor'),sep="")
subset(Dat,V1=='2013-12-27')
ffdf (all open) dim=c(2,2), dimorder=c(1,2) row.names=NULL
ffdf virtual mapping
?? PhysicalName VirtualVmode PhysicalVmode? AsIs VirtualIsMatrix
V1?????????? V1?????? double??????? double FALSE?????????? FALSE
V2?????????? V2????? integer?????? integer FALSE?????????? FALSE
?? PhysicalIsMatrix PhysicalElementNo PhysicalFirstCol PhysicalLastCol
V1??????????? FALSE???????????????? 1??????????????? 1?????????????? 1
V2??????????? FALSE???????????????? 2??????????????? 1?????????????? 1
?? PhysicalIsOpen
V1?????????? TRUE
V2?????????? TRUE
ffdf data
????????? V1???????? V2
1 2013-12-27 c???????? 
2 2013-12-27 c?????? 


A.K.




On , arun <smartpink111 at yahoo.com> wrote:
Hi Christofer,
You can check ?subset.ff from library(ffbase)

subset(ffd,m1>1)
ffdf (all open) dim=c(2,5), dimorder=c(1,2) row.names=NULL
ffdf virtual mapping
?? PhysicalName VirtualVmode PhysicalVmode? AsIs VirtualIsMatrix
m1????????? ffm????? integer?????? integer FALSE?????????? FALSE
m2????????? ffm????? integer?????? integer FALSE?????????? FALSE
m3????????? ffm????? integer?????? integer FALSE?????????? FALSE
m4????????? ffm????? integer?????? integer FALSE?????????? FALSE
v???????????? v????? integer?????? integer FALSE?????????? FALSE
?? PhysicalIsMatrix PhysicalElementNo PhysicalFirstCol PhysicalLastCol
m1???????????? TRUE???????????????? 1??????????????? 1?????????????? 1
m2???????????? TRUE???????????????? 1??????????????? 2?????????????? 2
m3???????????? TRUE???????????????? 1??????????????? 3?????????????? 3
m4???????????? TRUE???????????????? 1??????????????? 4?????????????? 4
v???????????? FALSE???????????????? 2??????????????? 1?????????????? 1
?? PhysicalIsOpen
m1?????????? TRUE
m2?????????? TRUE
m3?????????? TRUE
m4?????????? TRUE
v??????????? TRUE
ffdf data
? m1 m2 m3 m4? v
1? 2? 5? 8 11? 2
2? 3? 6? 9 12? 3
A.K.








On Saturday, December 28, 2013 1:29 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:

Hi Arun,

I will look into why dput is giving error......... In the mean time I am attaching the csv file with this mail, however not sure if R-hep will accept it.

I tried to converting it data.frame. However as 'Dat' is of huge size (that is why I loaded it via ff route), converting the entire data to data.frame giving memory allocation problem.

Thanks and regards,



On Sun, Dec 29, 2013 at 12:03 AM, arun <smartpink111 at yahoo.com> wrote:

HI,
>
>The dput() is showing error message.
>Is it not possible to convert it to data.frame and subset?
>
>Using the example from ?ffdf
>?m <- matrix(1:12, 3, 4, dimnames=list(c("r1","r2","r3"), c("m1","m2","m3","m4")))
>?????? v <- 1:3
>?????? ffm <- as.ff(m)
>?????? ffv <- as.ff(v)
>? ffd <- ffdf(ffm, v=ffv, row.names=row.names(ffm))
>d1 <- data.frame(ffd)
>
>
>subset(d1,m1>1)
>?? m1 m2 m3 m4 v
>r2? 2? 5? 8 11 2
>r3? 3? 6? 9 12 3
>
>
>A.K.
>
>
>
>On Saturday, December 28, 2013 12:29 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi again,
>
>I have loaded a huge csv file in R using 'ff' package, however could not
>understand how can I subset the loaded object. Below is my try:
>
>> suppressMessages(library(ff))
>>
>> Dat <- read.csv.ffdf(file = "f:/Book1.csv", header = F, colClasses =
>c('Date', 'factor'))
>> Dat
>ffdf (all open) dim=c(4,2), dimorder=c(1,2) row.names=NULL
>ffdf virtual mapping
>? ?PhysicalName VirtualVmode PhysicalVmode? AsIs VirtualIsMatrix
>PhysicalIsMatrix PhysicalElementNo PhysicalFirstCol PhysicalLastCol
>PhysicalIsOpen
>V1? ? ? ? ? ?V1? ? ? ?double? ? ? ? double FALSE? ? ? ? ? ?FALSE
>FALSE? ? ? ? ? ? ? ? ?1? ? ? ? ? ? ? ? 1? ? ? ? ? ? ? ?1? ? ? ? ? ?TRUE
>V2? ? ? ? ? ?V2? ? ? integer? ? ? ?integer FALSE? ? ? ? ? ?FALSE
>FALSE? ? ? ? ? ? ? ? ?2? ? ? ? ? ? ? ? 1? ? ? ? ? ? ? ?1? ? ? ? ? ?TRUE
>ffdf data
>? ? ? ? ? V1? ? ? ? ?V2
>1 2013-12-28 a
>2 2013-12-28 b
>3 2013-12-27 c
>4 2013-12-27 c
>>
>> subset(Dat, Dat$V1 == as.Date('2013-12-27'))
>ffdf (all open) dim=c(4,0), dimorder=c(1,2) row.names=NULL
>ffdf virtual mapping
>[1] PhysicalName? ? ? VirtualVmode? ? ? PhysicalVmode? ? ?AsIs
>VirtualIsMatrix? ?PhysicalIsMatrix? PhysicalElementNo PhysicalFirstCol
>PhysicalLastCol
>[10] PhysicalIsOpen
><0 rows> (or 0-length row.names)
>ffdf data
>[1] "[empty matrix]"
>
>
>
>My resulting object is showing '0' rows!
>
>
>The 'Dat' object looks like below:
>
>> dput(Dat)
>structure(list(virtual = structure(list(VirtualVmode = c("double",
>"integer"), AsIs = c(FALSE, FALSE), VirtualIsMatrix = c(FALSE,
>FALSE), PhysicalIsMatrix = c(FALSE, FALSE), PhysicalElementNo = 1:2,
>? ? PhysicalFirstCol = c(1L, 1L), PhysicalLastCol = c(1L, 1L)), .Names =
>c("VirtualVmode",
>"AsIs", "VirtualIsMatrix", "PhysicalIsMatrix", "PhysicalElementNo",
>"PhysicalFirstCol", "PhysicalLastCol"), row.names = c("V1", "V2"
>), class = "data.frame", Dim = c(4L, 2L), Dimorder = 1:2), physical =
>structure(list(
>? ? V1 = structure(list(), physical = <pointer: 0x0298f498>, virtual =
>structure(list(), Length = 4L, Symmetric = FALSE, ramclass = "Date"), class
>= c("ff_vector",
>? ? "ff")), V2 = structure(list(), physical = <pointer: 0x0298f4c8>,
>virtual = structure(list(), Length = 4L, Symmetric = FALSE, Levels = c("a",
>? ? "b", "c"), ramclass = "factor"), class = c("ff_vector", "ff"
>? ? ))), .Names = c("V1", "V2")), row.names = NULL), .Names = c("virtual",
>"physical", "row.names"), class = "ffdf")
>
>
>Can experts here guide me how to subset that?
>
>Thanks for your time.
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From thyagomoraes at hotmail.com  Sat Dec 28 13:40:18 2013
From: thyagomoraes at hotmail.com (Thyago Moraes)
Date: Sat, 28 Dec 2013 12:40:18 +0000
Subject: [R] Matchit
In-Reply-To: <52BEC43C.9050701@statistik.tu-dortmund.de>
References: <COL127-W36CD0DA8D2E94BF4E2ABF8C4CD0@phx.gbl>,
	<52BEC43C.9050701@statistik.tu-dortmund.de>
Message-ID: <COL127-W41B6AD8F7BFCCE197A8B47C4CC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131228/9105f97b/attachment.pl>

From aljehani-k at hotmail.com  Sat Dec 28 16:02:32 2013
From: aljehani-k at hotmail.com (Ms khulood aljehani)
Date: Sat, 28 Dec 2013 18:02:32 +0300
Subject: [R] MISE
In-Reply-To: <DUB122-W3383B661ABBD3F7516E68785FC0@phx.gbl>
References: <DUB122-W3383B661ABBD3F7516E68785FC0@phx.gbl>
Message-ID: <DUB128-W26D055453490780D7A15285CC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131228/4b243ee9/attachment.pl>

From phaedrusv at gmail.com  Sat Dec 28 16:46:40 2013
From: phaedrusv at gmail.com (sun shine)
Date: Sat, 28 Dec 2013 15:46:40 +0000
Subject: [R] Translating a basic Python script into R
Message-ID: <52BEF260.1090103@gmail.com>

Hi

I am attempting to translate some of the models that Donella Meadows 
wrote about in her book "Thinking in systems" into code. Originally, I 
had wanted to do this in Python, but thought that it would be fun to see 
if it is feasible to do so in R, especially given the plotting capacity 
of R.

Meadows describes a very simple example of a stock and flow: 50 gallons 
of water in a bath tub - drain out at a rate of 5 gal/ minute and then 
turn on the faucet after five minutes which flows at 5 gal/ min. The 
outcome is obviously that after 5 minutes, the bath tub will maintain a 
steady stock of 25 gal thereafter.

My basic code in Python looks like this:

====Python code=====

stock = 50
time = 1
inflow_a = 0
inflow_b = 5
outflow = 5

x = [stock]
y = [time]

print "Model of inflow and outflow rates of water"
print "version 3"
print

print stock
while time <= 5:
     stock = (stock - outflow) + inflow_a
     time += 1
     y += [time]
     x += [stock]
     print stock
     if stock == 30:
         print "Faucet turned on"

while time >= 6 and time <= 9:
     stock = (stock - outflow) + inflow_b
     time += 1
     y += [time]
     x += [stock]
     print stock

print "Volume in tub stabilises at %d gallons over %d minutes" % (stock, 
time)
print x
print y
==== end code====

I want to translate this into an equivalent script in R.

After some searching around, I found how to set up a while loop, and 
constructed the first section, like this:

======R code======

while(time <= 10) {
   if time <= 5
   stock <
   time <- time + 1
   print(time)
}

===== end code =====

However, what I would like to learn how to do is to nest the if 
conditions in a way similar to that given in the Python code.

I'm sure that there must be some very elegant way to do this, but I 
cannot find out how to do so in any of the books I have, nor do my web 
searches throw back anything useful (I suspect that I'm not phrasing the 
question properly).

Can someone please offer a few suggestions about ways that I could 
translate the Python script into R so that I can then run a plot as well?

Many thanks in anticipation.

Sun


From jim at bitwrit.com.au  Sat Dec 28 21:50:05 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 29 Dec 2013 07:50:05 +1100
Subject: [R] need help with distribution graphics
In-Reply-To: <1388248907.96530.YahooMailNeo@web125002.mail.ne1.yahoo.com>
References: <1388201159.77842.YahooMailNeo@web125004.mail.ne1.yahoo.com>	<52BEC3D6.9090703@statistik.tu-dortmund.de>
	<1388248907.96530.YahooMailNeo@web125002.mail.ne1.yahoo.com>
Message-ID: <52BF397D.6060307@bitwrit.com.au>

On 12/29/2013 03:41 AM, capricy gao wrote:
> Really?
>
> OK, here the linked is an example:
>
> http://iai.asm.org/content/77/10/4631/F1.expansion.html
>
>
> Please, any input would be appreciated!
>
>
Hi Capricy,
Really. Try the beeswarm package or the ehplot or dendroPlot functions 
in the plotrix package.

Jim


From istazahn at gmail.com  Sun Dec 29 00:06:09 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 28 Dec 2013 18:06:09 -0500
Subject: [R] Translating a basic Python script into R
In-Reply-To: <52BEF260.1090103@gmail.com>
References: <52BEF260.1090103@gmail.com>
Message-ID: <CA+vqiLGeo_EibEo8oF+ywMkdTgirRKE0y--VoNPWStfKT=dptA@mail.gmail.com>

Hi,

On Sat, Dec 28, 2013 at 10:46 AM, sun shine <phaedrusv at gmail.com> wrote:
> Hi
>
> I am attempting to translate some of the models that Donella Meadows wrote
> about in her book "Thinking in systems" into code. Originally, I had wanted
> to do this in Python, but thought that it would be fun to see if it is
> feasible to do so in R, especially given the plotting capacity of R.
>
> Meadows describes a very simple example of a stock and flow: 50 gallons of
> water in a bath tub - drain out at a rate of 5 gal/ minute and then turn on
> the faucet after five minutes which flows at 5 gal/ min. The outcome is
> obviously that after 5 minutes, the bath tub will maintain a steady stock of
> 25 gal thereafter.
>
> My basic code in Python looks like this:
>
> ====Python code=====
>
> stock = 50
> time = 1
> inflow_a = 0
> inflow_b = 5
> outflow = 5
>
> x = [stock]
> y = [time]
>
> print "Model of inflow and outflow rates of water"
> print "version 3"
> print
>
> print stock
> while time <= 5:
>     stock = (stock - outflow) + inflow_a
>     time += 1
>     y += [time]
>     x += [stock]
>     print stock
>     if stock == 30:
>         print "Faucet turned on"
>
> while time >= 6 and time <= 9:
>     stock = (stock - outflow) + inflow_b
>     time += 1
>     y += [time]
>     x += [stock]
>     print stock
>
> print "Volume in tub stabilises at %d gallons over %d minutes" % (stock,
> time)
> print x
> print y
> ==== end code====
>
> I want to translate this into an equivalent script in R.
>
> After some searching around, I found how to set up a while loop, and
> constructed the first section, like this:
>
> ======R code======
>
> while(time <= 10) {
>   if time <= 5
>   stock <
>   time <- time + 1
>   print(time)
> }
>
> ===== end code =====
>
> However, what I would like to learn how to do is to nest the if conditions
> in a way similar to that given in the Python code.

I don't see any nested conditions in the python code... A direct
translation in R looks almost the same, except that you need to group
using parentheses and brackets instead of whitespace, and there is no
+= in R (at least not that I'm aware of). Making those changes gives

  stock = 50
  time = 1
  inflow_a = 0
  inflow_b = 5
  outflow = 5
  x = stock
  y = time

  print ("Model of inflow and outflow rates of water")
  print ("version 3")

  print (stock)
  while (time <= 9) {

      stock = (stock - outflow) + inflow_a
      time = time + 1
      y = c(y, time)
      x = c(x, stock)
      print (stock)
      if (stock == 30) {
          print ("Faucet turned on")
      }
  }

  while (time >= 6 & time <= 9) {
      stock = (stock - outflow) + inflow_b
      time = time + 1
      y = c(y, time)
      x = c(x, stock)
      print (stock)
  }
      sprintf("Volume in tub stabilises at %d gallons over %d
minutes", stock, time)
      print (x)
      print (y)


>
> I'm sure that there must be some very elegant way to do this, but I cannot
> find out how to do so in any of the books I have, nor do my web searches
> throw back anything useful (I suspect that I'm not phrasing the question
> properly).

In both python and R you can of course use if/else instead of the two
separate while loops. An R version is

  stock = 50
  time = 1
  inflow_a = 0
  inflow_b = 5
  outflow = 5
  x = stock
  y = time

  print ("Model of inflow and outflow rates of water")
  print ("version 3\n")


  print (stock)
  while (time <= 9) {
      if(time <= 5) {
          stock = (stock - outflow) + inflow_a
      } else {
          stock = (stock - outflow) + inflow_b
      }
      time = time + 1
      y = c(y, time)
      x = c(x, stock)
      print (stock)
      if (stock == 30) {
          print ("Faucet turned on")
      }
  }

  sprintf("Volume in tub stabilises at %d gallons over %d minutes", stock, time)
  print (x)
  print (y)
  plot(y, x)


>
> Can someone please offer a few suggestions about ways that I could translate
> the Python script into R so that I can then run a plot as well?

You can plot in python, e.g.,

  from matplotlib.pyplot import *
  plot(y, x)
  show()

Best,
Ista
>
> Many thanks in anticipation.
>
> Sun
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thyagomoraes at hotmail.com  Sat Dec 28 22:50:39 2013
From: thyagomoraes at hotmail.com (Thyago Moraes)
Date: Sat, 28 Dec 2013 21:50:39 +0000
Subject: [R] plot.cuminc
In-Reply-To: <COL127-W41B6AD8F7BFCCE197A8B47C4CC0@phx.gbl>
References: <COL127-W36CD0DA8D2E94BF4E2ABF8C4CD0@phx.gbl>, ,
	<52BEC43C.9050701@statistik.tu-dortmund.de>,
	<COL127-W41B6AD8F7BFCCE197A8B47C4CC0@phx.gbl>
Message-ID: <COL127-W4043ADF84E39C6A200CDD3C4CC0@phx.gbl>

Dear Friends, 
I'm using the following code for generate a Figure where the x-axis is divided in intervals of 12 months (package cmprsk).However, the same numbers also appears vertically in the top of the figure.Not sure what I'm missing to avoid this.
Thanks in advance
Thyago

plot.cuminc (fit.les, xaxt='n',axis(1,c(0,12,24,36,48,60)),xlab=('Months'), ylab='CIF',curvlab=c('Death','Competing Risk'))  		 	   		  

From ahoerner at rprogress.org  Sun Dec 29 04:27:15 2013
From: ahoerner at rprogress.org (Andrew Hoerner)
Date: Sat, 28 Dec 2013 19:27:15 -0800
Subject: [R] What purpose is served by reflexive function assignments?
Message-ID: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131228/0a5259cb/attachment.pl>

From dwinsemius at comcast.net  Sun Dec 29 05:40:33 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 28 Dec 2013 20:40:33 -0800
Subject: [R] How to subset an 'ff' object?
In-Reply-To: <CA+dpOJk91CnC2=2mk437ih5htHRq3fzj7jvOeOnPrEVreu-G0w@mail.gmail.com>
References: <CA+dpOJk91CnC2=2mk437ih5htHRq3fzj7jvOeOnPrEVreu-G0w@mail.gmail.com>
Message-ID: <7B58C26A-E866-4514-A1DC-8681A2CE278A@comcast.net>


On Dec 28, 2013, at 9:26 AM, Christofer Bogaso wrote:

> Hi again,
> 
> I have loaded a huge csv file in R using 'ff' package, however could not
> understand how can I subset the loaded object. Below is my try:
> 
>> suppressMessages(library(ff))
>> 
>> Dat <- read.csv.ffdf(file = "f:/Book1.csv", header = F, colClasses =
> c('Date', 'factor'))
>> Dat
> ffdf (all open) dim=c(4,2), dimorder=c(1,2) row.names=NULL
> ffdf virtual mapping
>   PhysicalName VirtualVmode PhysicalVmode  AsIs VirtualIsMatrix
> PhysicalIsMatrix PhysicalElementNo PhysicalFirstCol PhysicalLastCol
> PhysicalIsOpen
> V1           V1       double        double FALSE           FALSE
> FALSE                 1                1               1           TRUE
> V2           V2      integer       integer FALSE           FALSE
> FALSE                 2                1               1           TRUE
> ffdf data
>          V1         V2
> 1 2013-12-28 a
> 2 2013-12-28 b
> 3 2013-12-27 c
> 4 2013-12-27 c
>> 
>> subset(Dat, Dat$V1 == as.Date('2013-12-27'))
> ffdf (all open) dim=c(4,0), dimorder=c(1,2) row.names=NULL
> ffdf virtual mapping
> [1] PhysicalName      VirtualVmode      PhysicalVmode     AsIs
> VirtualIsMatrix   PhysicalIsMatrix  PhysicalElementNo PhysicalFirstCol
> PhysicalLastCol
> [10] PhysicalIsOpen
> <0 rows> (or 0-length row.names)
> ffdf data
> [1] "[empty matrix]"

> ?ff::subset
No documentation for ?subset? in specified packages and libraries:
you could try ???subset?

If there was there something in the documentation that suggested `subset` should succeed with an 'ffdf' object, then you should write to the package authors.

Perhaps you should read ?ff::Extract.ff

-- 
David.
> 
> 
> 
> My resulting object is showing '0' rows!
> 
> 
> The 'Dat' object looks like below:
> 
>> dput(Dat)
> structure(list(virtual = structure(list(VirtualVmode = c("double",
> "integer"), AsIs = c(FALSE, FALSE), VirtualIsMatrix = c(FALSE,
> FALSE), PhysicalIsMatrix = c(FALSE, FALSE), PhysicalElementNo = 1:2,
>    PhysicalFirstCol = c(1L, 1L), PhysicalLastCol = c(1L, 1L)), .Names =
> c("VirtualVmode",
> "AsIs", "VirtualIsMatrix", "PhysicalIsMatrix", "PhysicalElementNo",
> "PhysicalFirstCol", "PhysicalLastCol"), row.names = c("V1", "V2"
> ), class = "data.frame", Dim = c(4L, 2L), Dimorder = 1:2), physical =
> structure(list(
>    V1 = structure(list(), physical = <pointer: 0x0298f498>, virtual =
> structure(list(), Length = 4L, Symmetric = FALSE, ramclass = "Date"), class
> = c("ff_vector",
>    "ff")), V2 = structure(list(), physical = <pointer: 0x0298f4c8>,
> virtual = structure(list(), Length = 4L, Symmetric = FALSE, Levels = c("a",
>    "b", "c"), ramclass = "factor"), class = c("ff_vector", "ff"
>    ))), .Names = c("V1", "V2")), row.names = NULL), .Names = c("virtual",
> "physical", "row.names"), class = "ffdf")
> 
> 
> Can experts here guide me how to subset that?
> 
> Thanks for your time.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From michcurran at yahoo.com  Sun Dec 29 06:07:31 2013
From: michcurran at yahoo.com (michael curran)
Date: Sat, 28 Dec 2013 21:07:31 -0800 (PST)
Subject: [R] How to subset an 'ff' object?
In-Reply-To: <CA+dpOJk91CnC2=2mk437ih5htHRq3fzj7jvOeOnPrEVreu-G0w@mail.gmail.com>
References: <CA+dpOJk91CnC2=2mk437ih5htHRq3fzj7jvOeOnPrEVreu-G0w@mail.gmail.com>
Message-ID: <1388293651.24316.YahooMailNeo@web141401.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131228/2fa0c57a/attachment.pl>

From istazahn at gmail.com  Sun Dec 29 06:35:09 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 29 Dec 2013 00:35:09 -0500
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
Message-ID: <CA+vqiLHaL2fKGg1VAUUFDVgxomu75ig_bNBRCDugYE5Ov6G8wQ@mail.gmail.com>

On Sat, Dec 28, 2013 at 10:27 PM, Andrew Hoerner <ahoerner at rprogress.org> wrote:
> Let us suppose that we have a function foo(X) which is called inside
> another function, bar(). Suppose, moreover, that the name "X" has been
> assigned a value when foo is called:
>
> X <- 2
> bar(X=X){
> foo(X)
> }
>
> I have noticed that many functions contain arguments with defaults of the
> form X=X.

An example would be really helpful here.

Call this reflexive assignment of arguments.

Why call this anything special? All this does is set the default value
of the X argument. I'm not sure what makes this "reflexive", or why it
needs a special descriptive term.

How is foo(X=X)
> different from foo(X)? Isn't the environment from which X is located the

foo(X) is hardcoded, foo(X = X) just sets a default.

> parent environment of foo() in either case? Or if it looks first in the
> environment inside of foo, will it not immediately pop up to the parent
> environment if it is not found in foo? Are reflexive assignments just to
> keep X from being positionally assigned accidentally, or are they doing
> something deeper? Moreover, this is the only place I have seen people
> consistently using an equals sign in place of the usual "<-", and I am
> confident that there is some subtle difference in how the two assignment
> operators work, perhaps beyond the ken of lesser mortals like myself, that
> explains why the "=" is preferred in this particular application.

Again, some examples would really help here.

>
> Actually, although I would like to hear the deep answer, which I am sure
> has something to do with scoping, as everything really confusing in R does,
> my real question is, is there some rule of thumb by which one could decide
> whether or not to do a reflexive assignment in a function definition and be
> right most of the time?

I'm still not even sure what reflexive assignment means. Can you
clarify, preferably with some examples.

>
> Lately I have gotten several "Error: Promise is already under evaluation"
> messages, and my current rule of thumb for dealing with this is to add
> reflexive assignment to the variable if it is missing and take it out if it
> is present. This seems to work, but it makes me feel unintelligent. Is
> there a better rule? I would be most grateful for anyone who could shed
> light on the subject.

Perhaps someone can, but you will certainly make their job easier if
you provide a concrete example that produces this error.

Best,
Ista

>
> Sincerely, andrewH
>
> --
> J. Andrew Hoerner
> Director, Sustainable Economics Program
> Redefining Progress
> (510) 507-4820
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter.langfelder at gmail.com  Sun Dec 29 06:56:36 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Sat, 28 Dec 2013 21:56:36 -0800
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
Message-ID: <CA+hbrhWytW_g1+s3ZWKLu_M+Ns6W3XA8nWSLWu6e0Fe3zvOjmw@mail.gmail.com>

On Sat, Dec 28, 2013 at 7:27 PM, Andrew Hoerner <ahoerner at rprogress.org> wrote:
> Let us suppose that we have a function foo(X) which is called inside
> another function, bar(). Suppose, moreover, that the name "X" has been
> assigned a value when foo is called:
>
> X <- 2
> bar(X=X){
> foo(X)
> }
>
> I have noticed that many functions contain arguments with defaults of the
> form X=X. Call this reflexive assignment of arguments.

Your example code makes little sense, it throws an error even before
reaching foo():

> X <- 2
> bar(X=X){
Error: unexpected '{' in "bar(X=X){"
> foo(X)
Error: could not find function "foo"
> }
Error: unexpected '}' in "}"


What you may have in mind is something like

bar = function(X)
{
  foo(X)
}

X<-2
bar(X=X)

Note that bar(X=4) is different from bar(X<-4), as seen here:

# Define a trivial function
> bar = function(X) {X+2}
>
> X = 0
> bar(X=2)
[1] 4
# Here only the formal argument X of function bar was set to 2; the
global variable X was left untouched:
> X
[1] 0
# This assigns the value 4 to the global variable X and uses that
value as the value for the first formal argument of bar():
> bar(X<-4)
[1] 6
# Note that X changed in the global environment
> X
[1] 4

What you call "reflexive assignment" X=X is not really: the left hand
side is the formal argument of bar(), the right hand side is the
variable X in the calling environment of bar() (in this case global
environment).

Oh yes, and it has absolutely nothing to do with defaults. If you use
my example above, the default for the argument X is 2, but doing
X=0
bar(X=X)

will call the function with argument X=0, not X=2.

When there is only one argument, saying X=X does not make much sense,
but when there are many arguments, say

bar = function(X=0, Y=0, Z=0)

and you only want to set the argument Z to a value you call Z in the
calling function, saying

bar(Z=Z)

makes perfect sense and is very different from saying

bar(Z)

which would set the argument X to value Z, and leave argument Z at the default.

Hope this helps.

Peter


From dwinsemius at comcast.net  Sun Dec 29 07:09:33 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 28 Dec 2013 22:09:33 -0800
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
Message-ID: <26A72EB0-6412-4E79-BEF9-70FF05BACEAC@comcast.net>


On Dec 28, 2013, at 7:27 PM, Andrew Hoerner wrote:

> Let us suppose that we have a function foo(X) which is called inside
> another function, bar(). Suppose, moreover, that the name "X" has been
> assigned a value when foo is called:
> 
> X <- 2
> bar(X=X){
> foo(X)
> }
> 
> I have noticed that many functions contain arguments with defaults of the
> form X=X. Call this reflexive assignment of arguments. How is foo(X=X)
> different from foo(X)?

The LHS X becomes a name, the RHS X will be looked up in the calling environment and fails if no value is positionally matched and then no X is found (at the time of the function definition.

> Isn't the environment from which X is located the
> parent environment of foo() in either case?

Not really. The X in foo(X) will be whatever value is given as the argument when foo is called and it will be assigned to X inside the function body.

> Or if it looks first in the
> environment inside of foo, will it not immediately pop up to the parent
> environment if it is not found in foo?

With foo(X=X) the interpreter will first determine if an argument was offered:

rm(X)
foo <- function(Z=X) print(Z^3)
foo(5)    # No error.
#[1] 125   

> Are reflexive assignments just to
> keep X from being positionally assigned accidentally, or are they doing
> something deeper? Moreover, this is the only place I have seen people
> consistently using an equals sign in place of the usual "<-", and I am
> confident that there is some subtle difference in how the two assignment
> operators work, perhaps beyond the ken of lesser mortals like myself, that
> explains why the "=" is preferred in this particular application.

If you use`X <- value` in the argument list, then what is returned is only the value and the name `X` may be lost. Or in the case of data.frame morphed inot a strange name:

d <- data.frame(X <- letters[1:3])
d
  X....letters.1.3.
1                 a
2                 b
3                 c

Since it does a deparse(substitute(.)) on the nameless expressions in the argument list.

> 
> Actually, although I would like to hear the deep answer, which I am sure
> has something to do with scoping, as everything really confusing in R does,
> my real question is, is there some rule of thumb by which one could decide
> whether or not to do a reflexive assignment in a function definition and be
> right most of the time?
> 
> Lately I have gotten several "Error: Promise is already under evaluation"
> messages, and my current rule of thumb for dealing with this is to add
> reflexive assignment to the variable if it is missing and take it out if it
> is present. This seems to work, but it makes me feel unintelligent. Is
> there a better rule? I would be most grateful for anyone who could shed
> light on the subject.
> 
> Sincerely, andrewH
> 
> -- 
> J. Andrew Hoerner
> Director, Sustainable Economics Program
> Redefining Progress
> (510) 507-4820
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From tsdavis1 at gmail.com  Sun Dec 29 01:58:40 2013
From: tsdavis1 at gmail.com (Thomas Davis)
Date: Sat, 28 Dec 2013 16:58:40 -0800
Subject: [R] error using pvclust
Message-ID: <CA+PXmD=jGgxcnDMiLRYVfKPk1xj8ru-UswqRtaaA23Y-S_st2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131228/21726645/attachment.pl>

From phaedrusv at gmail.com  Sun Dec 29 10:32:37 2013
From: phaedrusv at gmail.com (sun shine)
Date: Sun, 29 Dec 2013 09:32:37 +0000
Subject: [R] Translating a basic Python script into R
In-Reply-To: <CA+vqiLGeo_EibEo8oF+ywMkdTgirRKE0y--VoNPWStfKT=dptA@mail.gmail.com>
References: <52BEF260.1090103@gmail.com>
	<CA+vqiLGeo_EibEo8oF+ywMkdTgirRKE0y--VoNPWStfKT=dptA@mail.gmail.com>
Message-ID: <52BFEC35.2000708@gmail.com>

Hi Ista

On 28/12/13 23:06, Ista Zahn wrote:
> Hi,
>
> <snip>
> I don't see any nested conditions in the python code... A direct
> translation in R looks almost the same, except that you need to group
> using parentheses and brackets instead of whitespace, and there is no
> += in R (at least not that I'm aware of). Making those changes gives
>
>    stock = 50
>    time = 1
>    inflow_a = 0
>    inflow_b = 5
>    outflow = 5
>    x = stock
>    y = time
>
>    print ("Model of inflow and outflow rates of water")
>    print ("version 3")
>
>    print (stock)
>    while (time <= 9) {
>
>        stock = (stock - outflow) + inflow_a
>        time = time + 1
>        y = c(y, time)
>        x = c(x, stock)
>        print (stock)
>        if (stock == 30) {
>            print ("Faucet turned on")
>        }
>    }
>
>    while (time >= 6 & time <= 9) {
>        stock = (stock - outflow) + inflow_b
>        time = time + 1
>        y = c(y, time)
>        x = c(x, stock)
>        print (stock)
>    }
>        sprintf("Volume in tub stabilises at %d gallons over %d
> minutes", stock, time)
>        print (x)
>        print (y)
>
>
>> I'm sure that there must be some very elegant way to do this, but I cannot
>> find out how to do so in any of the books I have, nor do my web searches
>> throw back anything useful (I suspect that I'm not phrasing the question
>> properly).
> In both python and R you can of course use if/else instead of the two
> separate while loops. An R version is
>
>    stock = 50
>    time = 1
>    inflow_a = 0
>    inflow_b = 5
>    outflow = 5
>    x = stock
>    y = time
>
>    print ("Model of inflow and outflow rates of water")
>    print ("version 3\n")
>
>
>    print (stock)
>    while (time <= 9) {
>        if(time <= 5) {
>            stock = (stock - outflow) + inflow_a
>        } else {
>            stock = (stock - outflow) + inflow_b
>        }
>        time = time + 1
>        y = c(y, time)
>        x = c(x, stock)
>        print (stock)
>        if (stock == 30) {
>            print ("Faucet turned on")
>        }
>    }
>
>    sprintf("Volume in tub stabilises at %d gallons over %d minutes", stock, time)
>    print (x)
>    print (y)
>    plot(y, x)
>
>
>> Can someone please offer a few suggestions about ways that I could translate
>> the Python script into R so that I can then run a plot as well?
> You can plot in python, e.g.,
>
>    from matplotlib.pyplot import *
>    plot(y, x)
>    show()
>
> Best,
> Ista
>
This was *very* helpful: I leaned about both R and Python and am pleased 
to see that the structure between the two - for this script at least - 
are so similar.

Thank you for taking the time to explain and demonstrate rather than to 
just tell me to RTFM. Your reply has given me a lot of ideas to play 
around with in experimenting, so I can envisage an enjoyable afternoon 
testing some of this on the other models Meadows described.

Many thanks for your clear explanations.

Best wishes

Sun


From hyu0401 at hotmail.com  Sun Dec 29 11:45:02 2013
From: hyu0401 at hotmail.com (YuHong)
Date: Sun, 29 Dec 2013 18:45:02 +0800
Subject: [R] Translating a basic Python script into R
In-Reply-To: <52BFEC35.2000708@gmail.com>
References: <52BEF260.1090103@gmail.com><CA+vqiLGeo_EibEo8oF+ywMkdTgirRKE0y--VoNPWStfKT=dptA@mail.gmail.com>
	<52BFEC35.2000708@gmail.com>
Message-ID: <SNT147-DS180114E7B1B47FDCC607C9AECF0@phx.gbl>


In my opinion, the best usages of Python and R should be for different type 
of tasks respectively.  For example, Python is good for automating 
miscellaneous tasks, while R is good for list data processing and 
statistical modelling.  Therefore when you become more familiar with Python 
and R, you shall not use the two for exactly the same thing.



-----Original Message----- 
From: sun shine
Sent: Sunday, December 29, 2013 5:32 PM
To: r-help at r-project.org
Subject: Re: [R] Translating a basic Python script into R

Hi Ista

On 28/12/13 23:06, Ista Zahn wrote:
> Hi,
>
> <snip>
> I don't see any nested conditions in the python code... A direct
> translation in R looks almost the same, except that you need to group
> using parentheses and brackets instead of whitespace, and there is no
> += in R (at least not that I'm aware of). Making those changes gives
>
>    stock = 50
>    time = 1
>    inflow_a = 0
>    inflow_b = 5
>    outflow = 5
>    x = stock
>    y = time
>
>    print ("Model of inflow and outflow rates of water")
>    print ("version 3")
>
>    print (stock)
>    while (time <= 9) {
>
>        stock = (stock - outflow) + inflow_a
>        time = time + 1
>        y = c(y, time)
>        x = c(x, stock)
>        print (stock)
>        if (stock == 30) {
>            print ("Faucet turned on")
>        }
>    }
>
>    while (time >= 6 & time <= 9) {
>        stock = (stock - outflow) + inflow_b
>        time = time + 1
>        y = c(y, time)
>        x = c(x, stock)
>        print (stock)
>    }
>        sprintf("Volume in tub stabilises at %d gallons over %d
> minutes", stock, time)
>        print (x)
>        print (y)
>
>
>> I'm sure that there must be some very elegant way to do this, but I 
>> cannot
>> find out how to do so in any of the books I have, nor do my web searches
>> throw back anything useful (I suspect that I'm not phrasing the question
>> properly).
> In both python and R you can of course use if/else instead of the two
> separate while loops. An R version is
>
>    stock = 50
>    time = 1
>    inflow_a = 0
>    inflow_b = 5
>    outflow = 5
>    x = stock
>    y = time
>
>    print ("Model of inflow and outflow rates of water")
>    print ("version 3\n")
>
>
>    print (stock)
>    while (time <= 9) {
>        if(time <= 5) {
>            stock = (stock - outflow) + inflow_a
>        } else {
>            stock = (stock - outflow) + inflow_b
>        }
>        time = time + 1
>        y = c(y, time)
>        x = c(x, stock)
>        print (stock)
>        if (stock == 30) {
>            print ("Faucet turned on")
>        }
>    }
>
>    sprintf("Volume in tub stabilises at %d gallons over %d minutes", 
> stock, time)
>    print (x)
>    print (y)
>    plot(y, x)
>
>
>> Can someone please offer a few suggestions about ways that I could 
>> translate
>> the Python script into R so that I can then run a plot as well?
> You can plot in python, e.g.,
>
>    from matplotlib.pyplot import *
>    plot(y, x)
>    show()
>
> Best,
> Ista
>
This was *very* helpful: I leaned about both R and Python and am pleased
to see that the structure between the two - for this script at least -
are so similar.

Thank you for taking the time to explain and demonstrate rather than to
just tell me to RTFM. Your reply has given me a lot of ideas to play
around with in experimenting, so I can envisage an enjoyable afternoon
testing some of this on the other models Meadows described.

Many thanks for your clear explanations.

Best wishes

Sun

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From taquito2007 at gmail.com  Sun Dec 29 11:57:56 2013
From: taquito2007 at gmail.com (Takatsugu Kobayashi)
Date: Sun, 29 Dec 2013 19:57:56 +0900
Subject: [R] Any way to pre-set the number of observations for each cluster
	with kmeans?
Message-ID: <CADL0PciqeNVxuncobRus4mPU-9O0Tfabqr8kTbUCz=iN-GZpRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131229/6a41b6e5/attachment.pl>

From murdoch.duncan at gmail.com  Sun Dec 29 13:18:30 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 29 Dec 2013 07:18:30 -0500
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
Message-ID: <52C01316.2060509@gmail.com>

You posted this same question two weeks ago, received a reasonable 
question in response, and ignored it.

If you want help on the list please respond to questions.  If the 
discussion goes offline, please post a summary when it is done.

Duncan Murdoch

On 13-12-28 10:27 PM, Andrew Hoerner wrote:
> Let us suppose that we have a function foo(X) which is called inside
> another function, bar(). Suppose, moreover, that the name "X" has been
> assigned a value when foo is called:
>
> X <- 2
> bar(X=X){
> foo(X)
> }
>
> I have noticed that many functions contain arguments with defaults of the
> form X=X. Call this reflexive assignment of arguments. How is foo(X=X)
> different from foo(X)? Isn't the environment from which X is located the
> parent environment of foo() in either case? Or if it looks first in the
> environment inside of foo, will it not immediately pop up to the parent
> environment if it is not found in foo? Are reflexive assignments just to
> keep X from being positionally assigned accidentally, or are they doing
> something deeper? Moreover, this is the only place I have seen people
> consistently using an equals sign in place of the usual "<-", and I am
> confident that there is some subtle difference in how the two assignment
> operators work, perhaps beyond the ken of lesser mortals like myself, that
> explains why the "=" is preferred in this particular application.
>
> Actually, although I would like to hear the deep answer, which I am sure
> has something to do with scoping, as everything really confusing in R does,
> my real question is, is there some rule of thumb by which one could decide
> whether or not to do a reflexive assignment in a function definition and be
> right most of the time?
>
> Lately I have gotten several "Error: Promise is already under evaluation"
> messages, and my current rule of thumb for dealing with this is to add
> reflexive assignment to the variable if it is missing and take it out if it
> is present. This seems to work, but it makes me feel unintelligent. Is
> there a better rule? I would be most grateful for anyone who could shed
> light on the subject.
>
> Sincerely, andrewH
>


From maitra.mbox.ignored at inbox.com  Sun Dec 29 16:57:49 2013
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sun, 29 Dec 2013 09:57:49 -0600
Subject: [R] Any way to pre-set the number of observations for each
 cluster with kmeans?
In-Reply-To: <CADL0PciqeNVxuncobRus4mPU-9O0Tfabqr8kTbUCz=iN-GZpRA@mail.gmail.com>
References: <CADL0PciqeNVxuncobRus4mPU-9O0Tfabqr8kTbUCz=iN-GZpRA@mail.gmail.com>
Message-ID: <20131229095749.6d95a884e602ce9682bf55aa@inbox.com>

Hello Taak,

I don't believe that this can be done. What you are asking for is
essentially a constrained k-means algorithm with the constraint that
regardless of the consequences (higher within sum or squares), you
restrict each of the K groups to have at least N observations: within
this constraint, you would like to minimize the WSS. You have to
redevelop the k-means algorithm and rewrite the appropriate code as
needed.

It appears that you may have a specific application for which you need
this particular set-up. Do you really need to use k-means for this
clustering? 

Many thanks,
Ranjan

On Sun, 29 Dec 2013 19:57:56 +0900 Takatsugu Kobayashi
<taquito2007 at gmail.com> wrote:

> Hi Rusers,
> 
> This is a simple question, but I cannot find an answer to it yet.
> I am currently running kmeans with a constraint that each cluster has at
> least an N observations. I look at Kmeans and thought "nstart" is the one,
> but it didn't work.
> 
> Could you please let me know if there are other packages that will do this?
> 
> Thank you so much.
> 
> Best,
> 
> Taak
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. Please respond to the mailing list if appropriate.
For those needing to send personal or professional e-mail, please use
appropriate addresses.

____________________________________________________________
TRY FREE IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if5
Capture screenshots, upload images, edit and send them to your friends
through IMs, post on Twitter?, Facebook?, MySpace?, LinkedIn? ? FAST!


From anna.berg1986 at hotmail.com  Sun Dec 29 13:16:02 2013
From: anna.berg1986 at hotmail.com (anna berg)
Date: Sun, 29 Dec 2013 13:16:02 +0100
Subject: [R] Smooth limits for a surface plot
Message-ID: <DUB110-W12608A0000B679A23C9613CF5CF0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131229/bacc2f8f/attachment.pl>

From elearn2014 at gmail.com  Sun Dec 29 12:42:10 2013
From: elearn2014 at gmail.com (luofeiyu)
Date: Sun, 29 Dec 2013 19:42:10 +0800
Subject: [R] why the "[^\\d]" is not equal to "[^0-9]" in R regular
	expression?
Message-ID: <52C00A92.1070103@gmail.com>

gregexpr(pattern="[^0-9]","+12345ty")
[[1]]
[1] 1 7 8
attr(,"match.length")
[1] 1 1 1
attr(,"useBytes")
[1] TRUE
gregexpr(pattern="[^\\d]","+12345ty")
[[1]]
[1] 1 2 3 4 5 6 7 8
attr(,"match.length")
[1] 1 1 1 1 1 1 1 1
attr(,"useBytes")
[1] TRUE

why the pattern `[^\\d]` has no same effect as of `[^0-9]` ?


From jingxia08 at gmail.com  Sun Dec 29 14:40:29 2013
From: jingxia08 at gmail.com (Jingxia Lin)
Date: Sun, 29 Dec 2013 21:40:29 +0800
Subject: [R] counts and percentage of multiple categorical columns in R
Message-ID: <CADA6nUDy2uGUVmVd=-+0iOkc497i8gOHozUYtfY3wWgCNV4pvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131229/2f9a91ff/attachment.pl>

From phaedrusv at gmail.com  Sun Dec 29 12:08:20 2013
From: phaedrusv at gmail.com (sun shine)
Date: Sun, 29 Dec 2013 11:08:20 +0000
Subject: [R] Translating a basic Python script into R
In-Reply-To: <SNT147-DS180114E7B1B47FDCC607C9AECF0@phx.gbl>
References: <52BEF260.1090103@gmail.com><CA+vqiLGeo_EibEo8oF+ywMkdTgirRKE0y--VoNPWStfKT=dptA@mail.gmail.com>
	<52BFEC35.2000708@gmail.com>
	<SNT147-DS180114E7B1B47FDCC607C9AECF0@phx.gbl>
Message-ID: <52C002A4.80102@gmail.com>

On 29/12/13 10:45, YuHong wrote:
>
> In my opinion, the best usages of Python and R should be for different 
> type of tasks respectively.  For example, Python is good for 
> automating miscellaneous tasks, while R is good for list data 
> processing and statistical modelling.  Therefore when you become more 
> familiar with Python and R, you shall not use the two for exactly the 
> same thing.
>
<snip>

That makes sense. The point I was trying to make really concerned the 
structure of conditional statements, as well as statements such as 
"print" and the declaration of the variables. I wasn't actually 
referring to any programming similarities. In any event, this opinion 
was made by someone with little experience in programming, so from the 
"outside" the similarities are more apparent probably than to someone 
with the more sophisticated awareness of the "inside" dissimilarities.

My original intent had been to use Meadows' models to try to get my hand 
in for modelling and since I know a (very) little about Python I started 
off with that, which gave me a rough idea of how I could approach such 
tasks, and it worked; R is something else I'd like to learn, so thought 
that I would try to do the same thing in R which is where I ran aground 
and hence was very appreciative of Ishta taking the time to demonstrate 
how to do such things in R.


From wdunlap at tibco.com  Sun Dec 29 19:09:34 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 29 Dec 2013 18:09:34 +0000
Subject: [R] why the "[^\\d]" is not equal to "[^0-9]" in R
	regular	expression?
In-Reply-To: <52C00A92.1070103@gmail.com>
References: <52C00A92.1070103@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1FB49@PA-MBX01.na.tibco.com>

Use perl=TRUE if you want \\d to mean something special (a digit) in a regular expression.

> identical(gregexpr(pattern="[^0-9]","+12345ty"), gregexpr(pattern="[^\\d]","+12345ty",perl=TRUE))
[1] TRUE

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of luofeiyu
> Sent: Sunday, December 29, 2013 3:42 AM
> To: R-help at r-project.org
> Subject: [R] why the "[^\\d]" is not equal to "[^0-9]" in R regular expression?
> 
> gregexpr(pattern="[^0-9]","+12345ty")
> [[1]]
> [1] 1 7 8
> attr(,"match.length")
> [1] 1 1 1
> attr(,"useBytes")
> [1] TRUE
> gregexpr(pattern="[^\\d]","+12345ty")
> [[1]]
> [1] 1 2 3 4 5 6 7 8
> attr(,"match.length")
> [1] 1 1 1 1 1 1 1 1
> attr(,"useBytes")
> [1] TRUE
> 
> why the pattern `[^\\d]` has no same effect as of `[^0-9]` ?
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sun Dec 29 19:28:19 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 29 Dec 2013 10:28:19 -0800
Subject: [R] counts and percentage of multiple categorical columns in R
In-Reply-To: <CADA6nUDy2uGUVmVd=-+0iOkc497i8gOHozUYtfY3wWgCNV4pvw@mail.gmail.com>
References: <CADA6nUDy2uGUVmVd=-+0iOkc497i8gOHozUYtfY3wWgCNV4pvw@mail.gmail.com>
Message-ID: <CACk-te3PApPeYeS2EMTu3XkydqasyCZorHD0j2-5hJELGwqrrw@mail.gmail.com>

Is this homework? (We generally don't do homework here).

However, hint: ?table and links therein.

Also, as you can see below, post in plain text, not HTML, which is
stripped and can lead to hard-to-read gobbledygook.

Cheers,

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Sun, Dec 29, 2013 at 5:40 AM, Jingxia Lin <jingxia08 at gmail.com> wrote:
> Dear R helpers,
>
> I have a data sheet (?milk?) with four types of milk from five brands (A,
> B, C, D, E), the column shows the brands that each customer chose for each
> type of the milk they bought. The data sheet goes like below. You can see
> for some type of milk, no brand is chosen.
>
> fatfreemilk fatmilk halfmilk 2fatmilk
> A A A A
> A B B A
> B A A A
> C C C C
> D A A A
> A E A E
> C A B A
> A A A A
> A B B A
> A A B E
>
> I want to summarize each column so that for each type of milk, i know the
> counts and percentages of the brands chosen for each milk type. I tried
> "summary" in R, but the result is not shown nicely. How I can display the
> result in a way like below:
> A B C D E
> fatfreemilk 6(60) 1(10) 2(20) 1(10) 0(0)
> fatmilk 6(60) 2(20) 1(10) 0(10) 1(10)
> halfmilk 5(50) 4(40) 1(10) 0(0) 0(0)
> 2fatmilk 7(70) 0(0) 1(10) 0(0) 2(20)
>
> Thank you!
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Sun Dec 29 20:48:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 29 Dec 2013 11:48:24 -0800 (PST)
Subject: [R] counts and percentage of multiple categorical columns in R
In-Reply-To: <CADA6nUDy2uGUVmVd=-+0iOkc497i8gOHozUYtfY3wWgCNV4pvw@mail.gmail.com>
References: <CADA6nUDy2uGUVmVd=-+0iOkc497i8gOHozUYtfY3wWgCNV4pvw@mail.gmail.com>
Message-ID: <1388346504.56853.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try:
dat1 <- read.table(text="fatfreemilk fatmilk halfmilk 2fatmilk
A A A A
A B B A
B A A A
C C C C
D A A A
A E A E
C A B A
A A A A
A B B A
A A B E",sep="",header=TRUE,stringsAsFactors=FALSE,check.names=FALSE)
?dat2 <- dat1
?dat2$id <- 1:nrow(dat2)
library(reshape2)
?res <- dcast(melt(dat2,id.var="id")[,-1],variable~value,length)
row.names(res) <- res[,1]
res1 <- res[,-1]
res2 <- as.matrix(res1)
?res2[]<- paste0(res2,paste0("(",(res2/rowSums(res2))*100),")")
?as.data.frame(res2)
#??????????????? A???? B???? C???? D???? E
#fatfreemilk 6(60) 1(10) 2(20) 1(10)? 0(0)
#fatmilk???? 6(60) 2(20) 1(10)? 0(0) 1(10)
#halfmilk??? 5(50) 4(40) 1(10)? 0(0)? 0(0)
#2fatmilk??? 7(70)? 0(0) 1(10)? 0(0) 2(20)
A.K.




On Sunday, December 29, 2013 1:07 PM, Jingxia Lin <jingxia08 at gmail.com> wrote:
Dear R helpers,

I have a data sheet (?milk?) with four types of milk from five brands (A,
B, C, D, E), the column shows the brands that each customer chose for each
type of the milk they bought. The data sheet goes like below. You can see
for some type of milk, no brand is chosen.

fatfreemilk fatmilk halfmilk 2fatmilk
A A A A
A B B A
B A A A
C C C C
D A A A
A E A E
C A B A
A A A A
A B B A
A A B E

I want to summarize each column so that for each type of milk, i know the
counts and percentages of the brands chosen for each milk type. I tried
"summary" in R, but the result is not shown nicely. How I can display the
result in a way like below:
A B C D E
fatfreemilk 6(60) 1(10) 2(20) 1(10) 0(0)
fatmilk 6(60) 2(20) 1(10) 0(10) 1(10)
halfmilk 5(50) 4(40) 1(10) 0(0) 0(0)
2fatmilk 7(70) 0(0) 1(10) 0(0) 2(20)

Thank you!

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sun Dec 29 20:56:54 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 29 Dec 2013 11:56:54 -0800 (PST)
Subject: [R] counts and percentage of multiple categorical columns in R
In-Reply-To: <1388346504.56853.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CADA6nUDy2uGUVmVd=-+0iOkc497i8gOHozUYtfY3wWgCNV4pvw@mail.gmail.com>
	<1388346504.56853.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1388347014.2028.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Another way is:
vec1 <- unique(unlist(dat1))
?res3 <- as.data.frame(t(sapply(dat1,function(x) {counts<- table(factor(x,levels=vec1)); percentage<-(counts/sum(counts))*100; paste0(counts,paste0("(",percentage,")"))})))
? colnames(res3) <- vec1
?
?identical(res3,as.data.frame(res2))
#[1] TRUE
A.K.




On Sunday, December 29, 2013 2:53 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
dat1 <- read.table(text="fatfreemilk fatmilk halfmilk 2fatmilk
A A A A
A B B A
B A A A
C C C C
D A A A
A E A E
C A B A
A A A A
A B B A
A A B E",sep="",header=TRUE,stringsAsFactors=FALSE,check.names=FALSE)
?dat2 <- dat1
?dat2$id <- 1:nrow(dat2)
library(reshape2)
?res <- dcast(melt(dat2,id.var="id")[,-1],variable~value,length)
row.names(res) <- res[,1]
res1 <- res[,-1]
res2 <- as.matrix(res1)
?res2[]<- paste0(res2,paste0("(",(res2/rowSums(res2))*100),")")
?as.data.frame(res2)
#??????????????? A???? B???? C???? D???? E
#fatfreemilk 6(60) 1(10) 2(20) 1(10)? 0(0)
#fatmilk???? 6(60) 2(20) 1(10)? 0(0) 1(10)
#halfmilk??? 5(50) 4(40) 1(10)? 0(0)? 0(0)
#2fatmilk??? 7(70)? 0(0) 1(10)? 0(0) 2(20)
A.K.




On Sunday, December 29, 2013 1:07 PM, Jingxia Lin <jingxia08 at gmail.com> wrote:
Dear R helpers,

I have a data sheet (?milk?) with four types of milk from five brands (A,
B, C, D, E), the column shows the brands that each customer chose for each
type of the milk they bought. The data sheet goes like below. You can see
for some type of milk, no brand is chosen.

fatfreemilk fatmilk halfmilk 2fatmilk
A A A A
A B B A
B A A A
C C C C
D A A A
A E A E
C A B A
A A A A
A B B A
A A B E

I want to summarize each column so that for each type of milk, i know the
counts and percentages of the brands chosen for each milk type. I tried
"summary" in R, but the result is not shown nicely. How I can display the
result in a way like below:
A B C D E
fatfreemilk 6(60) 1(10) 2(20) 1(10) 0(0)
fatmilk 6(60) 2(20) 1(10) 0(10) 1(10)
halfmilk 5(50) 4(40) 1(10) 0(0) 0(0)
2fatmilk 7(70) 0(0) 1(10) 0(0) 2(20)

Thank you!

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ahoerner at rprogress.org  Mon Dec 30 00:19:09 2013
From: ahoerner at rprogress.org (andrewH)
Date: Sun, 29 Dec 2013 15:19:09 -0800 (PST)
Subject: [R] Assigning default function arguments to themselves: Why?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1DA29@PA-MBX01.na.tibco.com>
References: <CA+t4QRpSs_1NYVNrMwqsHhPB==tjuA6F6dSzU76L0AhU_kHyFw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1DA29@PA-MBX01.na.tibco.com>
Message-ID: <1388359149161-4682817.post@n4.nabble.com>

Dear Bill--

I have seen it most often in functions that are defined or used inside of
other functions, and need an argument from the calling function.  So I have,
purely as a matter of imitation, taken to doing it when I am writing a
function that wants an argument of the calling function passed to it
unchanged, because that is how I saw it used. So for instance, in
read.table(), scan() is called several times with reflexive argument
assignments that include:
file = file
what = what
sep = sep
quote = quote
comment.char = comment.char
allowEscapes = allowEscapes
encoding = encoding

Is this what you mean by an example that 'works'? I am sort of foggy on the
shade of meaning conveyed by the single quotes. If not, let me know what
kind of example you want, and I'll try and find it.



--
View this message in context: http://r.789695.n4.nabble.com/Assigning-default-function-arguments-to-themselves-Why-tp4682294p4682817.html
Sent from the R help mailing list archive at Nabble.com.


From ahoerner at rprogress.org  Mon Dec 30 00:28:36 2013
From: ahoerner at rprogress.org (andrewH)
Date: Sun, 29 Dec 2013 15:28:36 -0800 (PST)
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <52C01316.2060509@gmail.com>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
	<52C01316.2060509@gmail.com>
Message-ID: <1388359716381-4682818.post@n4.nabble.com>

Dear Duncan --
I am terribly sorry. I had a browser crash, and when I reopened it I found a
tab with a Nabble composition box containing an unposted version of my
question. So I thought I had never hit the "send" button, so I edited it a
bit and sent it off. I should have checked first. My apologies.

andrewH





--
View this message in context: http://r.789695.n4.nabble.com/What-purpose-is-served-by-reflexive-function-assignments-tp4682794p4682818.html
Sent from the R help mailing list archive at Nabble.com.


From ahoerner at rprogress.org  Mon Dec 30 00:57:29 2013
From: ahoerner at rprogress.org (andrewH)
Date: Sun, 29 Dec 2013 15:57:29 -0800 (PST)
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <26A72EB0-6412-4E79-BEF9-70FF05BACEAC@comcast.net>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
	<26A72EB0-6412-4E79-BEF9-70FF05BACEAC@comcast.net>
Message-ID: <1388361449016-4682819.post@n4.nabble.com>

Dear David--

Thanks so much for your helpful reply!

 David Winsemius wrote:
>>The LHS X becomes a name, the RHS X will be looked up in the calling
environment and fails if no value is positionally matched and then no X is
found (at the time of the function definition. 

Does X really have to exist when the function is defined? I thought it was
enough if it existed in the environment of the calling function, or
somewhere up the environment chain of the calling function. If this is not
true, then that means it matters a lot whether you write a function inside
another function or just call it in that function.  Suppose a function with
a reflexive assignment X=X is defined in the global environment but called
inside another function, and X has a different value in those two places.
Will it look first in the global environment and only then in the calling
environment? And is this different from the behavior without the reflexive
assignment?

I should not bother you with those questions. I should just run it both ways
and see what happens.calling function and will it look first in the 

>>If you use`X <- value` in the argument list, then what is returned is only
the value and the name `X` may be lost. Or in the case of data.frame morphed
into a strange name: 

[example omitted]
I am not sure that I am understanding you correctly here. Are you saying
that assignment using the "=" retains the name (and other attributes? which
ones?) of the RHS, while "<-" does not? 




--
View this message in context: http://r.789695.n4.nabble.com/What-purpose-is-served-by-reflexive-function-assignments-tp4682794p4682819.html
Sent from the R help mailing list archive at Nabble.com.


From istazahn at gmail.com  Mon Dec 30 02:23:47 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 29 Dec 2013 20:23:47 -0500
Subject: [R] Assigning default function arguments to themselves: Why?
In-Reply-To: <1388359149161-4682817.post@n4.nabble.com>
References: <CA+t4QRpSs_1NYVNrMwqsHhPB==tjuA6F6dSzU76L0AhU_kHyFw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1DA29@PA-MBX01.na.tibco.com>
	<1388359149161-4682817.post@n4.nabble.com>
Message-ID: <CA+vqiLGBo00=Nu08Pv9ODA1k1rEMeHykXKJFyE=JiKqH0gQzzA@mail.gmail.com>

On Sun, Dec 29, 2013 at 6:19 PM, andrewH <ahoerner at rprogress.org> wrote:
> Dear Bill--
>
> I have seen it most often in functions that are defined or used inside of
> other functions, and need an argument from the calling function.  So I have,
> purely as a matter of imitation, taken to doing it when I am writing a
> function that wants an argument of the calling function passed to it
> unchanged, because that is how I saw it used. So for instance, in
> read.table(), scan() is called several times with reflexive argument
> assignments that include:
> file = file
> what = what
> sep = sep
> quote = quote
> comment.char = comment.char
> allowEscapes = allowEscapes
> encoding = encoding

I don't think there is anything special about the fact that the name
of the arguments
and the name of the objects they are set to have the same names. There
is no such thing as "reflexive assignment", or if there is I don't
know what it means. This example is also very different from your
original description: There you were talking about "functions [that]
contain arguments with defaults of
the form X=X". Your read.table/scan example doesn't have anything to
to with default arguments.

>
> Is this what you mean by an example that 'works'? I am sort of foggy on the
> shade of meaning conveyed by the single quotes. If not, let me know what
> kind of example you want, and I'll try and find it.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Assigning-default-function-arguments-to-themselves-Why-tp4682294p4682817.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Dec 30 02:43:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 29 Dec 2013 17:43:32 -0800 (PST)
Subject: [R] Expand a data frame
Message-ID: <1388367812.58418.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,
May be this helps:
dat1<- read.table(text="date event
01-jan-04 4
02-jan-04 3
03-jan-04 2
04-jan-04 3
05-jan-04 2
06-jan-04 2
07-jan-04 4",sep="",header=TRUE,stringsAsFactors=FALSE) 
?vec1 <- rep(1:nrow(dat1),dat1$event)
res <- transform(dat1[vec1,],event=1,id=seq(length(vec1)))
row.names(res) <- 1:nrow(res)


A.K.


I have an event per day which I wish to expand . ?As an output I wish to have a long data format ?with a unique sequential id for all events. ? 
Sample data and what I desire to have is shown below 


Current stand 

date	event 
01-jan-04	4 
02-jan-04	3 
03-jan-04	2 
04-jan-04	3 
05-jan-04	2 
06-jan-04	2 
07-jan-04	4 
? ? ? ? ? ? ? ? 

My desired output for the first two rows 
? ? ? ? ? ? ? ? 
date	event	id 
01-jan-04	1	1 
01-jan-04	1	2 
01-jan-04	1	3 
01-jan-04	1	4 
02-jan-04	1	5 
02-jan-04	1	6 
02-jan-04	1	7


From wdunlap at tibco.com  Mon Dec 30 02:47:24 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 30 Dec 2013 01:47:24 +0000
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <1388361449016-4682819.post@n4.nabble.com>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
	<26A72EB0-6412-4E79-BEF9-70FF05BACEAC@comcast.net>
	<1388361449016-4682819.post@n4.nabble.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1FB8A@PA-MBX01.na.tibco.com>

On Dec 28, 2013, at 7:27 PM, Andrew Hoerner wrote: 

> Let us suppose that we have a function foo(X) which is called inside 
> another function, bar(). Suppose, moreover, that the name "X" has been 
> assigned a value when foo is called: 
> 
> X <- 2 
> bar(X=X){ 
> foo(X) 
> }

The above is not valid R syntax.  Can you correct it to make a self-contained
runnable example and re-ask the question?
  
> I have noticed that many functions contain arguments with defaults of the 
> form X=X. Call this reflexive assignment of arguments. How is foo(X=X) 
> different from foo(X)?

I will venture that no useful function contains a default value of X=X. 

Are you confounding definitions of functions (where default values are specified) like
    foo <- function(X, Y=log(X)) { Y }
and calls to functions (where actual values are specified) like
    foo(X=10, Y=15)
or
   Y <- 7
   foo(Y=Y)
?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of andrewH
> Sent: Sunday, December 29, 2013 3:57 PM
> To: r-help at r-project.org
> Subject: Re: [R] What purpose is served by reflexive function assignments?
> 
> Dear David--
> 
> Thanks so much for your helpful reply!
> 
>  David Winsemius wrote:
> >>The LHS X becomes a name, the RHS X will be looked up in the calling
> environment and fails if no value is positionally matched and then no X is
> found (at the time of the function definition.
> 
> Does X really have to exist when the function is defined? I thought it was
> enough if it existed in the environment of the calling function, or
> somewhere up the environment chain of the calling function. If this is not
> true, then that means it matters a lot whether you write a function inside
> another function or just call it in that function.  Suppose a function with
> a reflexive assignment X=X is defined in the global environment but called
> inside another function, and X has a different value in those two places.
> Will it look first in the global environment and only then in the calling
> environment? And is this different from the behavior without the reflexive
> assignment?
> 
> I should not bother you with those questions. I should just run it both ways
> and see what happens.calling function and will it look first in the
> 
> >>If you use`X <- value` in the argument list, then what is returned is only
> the value and the name `X` may be lost. Or in the case of data.frame morphed
> into a strange name:
> 
> [example omitted]
> I am not sure that I am understanding you correctly here. Are you saying
> that assignment using the "=" retains the name (and other attributes? which
> ones?) of the RHS, while "<-" does not?
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/What-purpose-is-served-
> by-reflexive-function-assignments-tp4682794p4682819.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Dec 30 05:05:52 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 29 Dec 2013 20:05:52 -0800
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <1388361449016-4682819.post@n4.nabble.com>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
	<26A72EB0-6412-4E79-BEF9-70FF05BACEAC@comcast.net>
	<1388361449016-4682819.post@n4.nabble.com>
Message-ID: <E994EE1E-10D6-4AF2-B6CA-00DCC24B983B@comcast.net>


On Dec 29, 2013, at 3:57 PM, andrewH wrote:

> Dear David--
>
> Thanks so much for your helpful reply!
>
> David Winsemius wrote:
>>> The LHS X becomes a name, the RHS X will be looked up in the calling
> environment and fails if no value is positionally matched and then  
> no X is
> found (at the time of the function definition.
>
> Does X really have to exist when the function is defined?

No


> I thought it was
> enough if it existed in the environment of the calling function, or
> somewhere up the environment chain of the calling function. If this  
> is not
> true, then that means it matters a lot whether you write a function  
> inside
> another function or just call it in that function.  Suppose a  
> function with
> a reflexive assignment X=X

Arrrgh. The is no "reflexive assignment". You are making up a concept.

> is defined in the global environment but called
> inside another function, and X has a different value in those two  
> places.
> Will it look first in the global environment and only then in the  
> calling
> environment? And is this different from the behavior without the  
> reflexive
> assignment?
>
> I should not bother you with those questions. I should just run it  
> both ways
> and see what happens.calling function and will it look first in the
>
>>> If you use`X <- value` in the argument list, then what is returned  
>>> is only
> the value and the name `X` may be lost. Or in the case of data.frame  
> morphed
> into a strange name:
>
> [example omitted]
> I am not sure that I am understanding you correctly here. Are you  
> saying
> that assignment using the "=" retains the name (and other  
> attributes? which
> ones?) of the RHS, while "<-" does not?

Using "=" assigns a name. Using "<-" retruns a value and whether the  
value gets a name depends on the particular function.

 > foo <- function(X <- V) { print(X)}
Error: unexpected assignment in "foo <- function(X <-"
 > foo <- function(X = V) { print(X)}
 > foo(4)
[1] 4
 > foo <- function(X = V) { print(V)}
 > foo(4)
Error in print(V) : object 'V' not found


-- 

David Winsemius, MD
Alameda, CA, USA


From ahoerner at rprogress.org  Mon Dec 30 05:18:02 2013
From: ahoerner at rprogress.org (andrewH)
Date: Sun, 29 Dec 2013 20:18:02 -0800 (PST)
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <CA+hbrhWytW_g1+s3ZWKLu_M+Ns6W3XA8nWSLWu6e0Fe3zvOjmw@mail.gmail.com>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
	<CA+hbrhWytW_g1+s3ZWKLu_M+Ns6W3XA8nWSLWu6e0Fe3zvOjmw@mail.gmail.com>
Message-ID: <1388377082308-4682825.post@n4.nabble.com>


Dear Peter--

This is a truly wonderful explanation. It makes many things clear that were
completely mysterious to me. For one thing, I realize that, for functions
called inside the definitions of other functions, I have been confusing
function definitions with function calls -- as if the called function were
also being defined. So I have seen a lot of what I was calling reflexive
assignments _inside_ of function definitions, but not as a _part of_
function definitions -- rather they are a part of the calls to other,
already-defined functions that just happen to take place inside of function
definitions.  

Let me sum up a few things I think I have learned, to make sure I am not
merely hallucinating an improved understanding.

1. Outside of function definitions and calls, = and <- are pretty similar in
their effect.
2. Inside of the parentheses of a function call, <- assigns the RHS to the
variable on the LHS in the enclosing environment, so the value is picked up
when the call is executed -- but is also a permanent change in the variable
of that name in the enclosing environment. (This seems like an exception to
the general no-side-effects rule, yes?)
3. Inside parentheses of a function call, = assigns the RHS to the LHS, but
only in the environment of that function -- more like it was in the function
body.
4. Inside the parentheses of a function definition, you can not do a <-
assignment at all, and = has a a pretty different secondary meaning, a sort
of conditional assignment, along the lines of "if you can not match the
argument before this positionally, use the value of the RHS.
5. The names of formals in the function definition do not matter outside the
function. Only their position (or an = assignment) matters. You can not get
a function to recognize a variable in its surrounding environment because it
has the same name as the name of a formal in the function definition. 
Conversely, inside the function, only the formal name matters. if
f<-function(Y){X}, f(X) still gets you an "argument X is missing" error.
6. In a call, f(x=x) is different from f(x) if and only if x has a default
value different from the value of x in the calling environment.
7. I have learned by experiment that a reflexive assignment with = in a
function definition does not assign the value of x in the calling
environment as the default, though I do not know why. In fact, I have not
been able to make X=X do anything useful (and different from plain X) inside
the parentheses of a function definition, unless I am trying to generate
strange "recursive default error" warnings.

So the simple rule i wanted with respect to function definitions is "just
say no". 

Is that more or less right?

Many thanks!   --andrewH




plangfelder wrote
> On Sat, Dec 28, 2013 at 7:27 PM, Andrew Hoerner &lt;

> ahoerner@

> &gt; wrote:
>> Let us suppose that we have a function foo(X) which is called inside
>> another function, bar(). Suppose, moreover, that the name "X" has been
>> assigned a value when foo is called:
>>
>> X <- 2
>> bar(X=X){
>> foo(X)
>> }
>>
>> I have noticed that many functions contain arguments with defaults of the
>> form X=X. Call this reflexive assignment of arguments.
> 
> Your example code makes little sense, it throws an error even before
> reaching foo():
> 
>> X <- 2
>> bar(X=X){
> Error: unexpected '{' in "bar(X=X){"
>> foo(X)
> Error: could not find function "foo"
>> }
> Error: unexpected '}' in "}"
> 
> 
> What you may have in mind is something like
> 
> bar = function(X)
> {
>   foo(X)
> }
> 
> X<-2
> bar(X=X)
> 
> Note that bar(X=4) is different from bar(X<-4), as seen here:
> 
> # Define a trivial function
>> bar = function(X) {X+2}
>>
>> X = 0
>> bar(X=2)
> [1] 4
> # Here only the formal argument X of function bar was set to 2; the
> global variable X was left untouched:
>> X
> [1] 0
> # This assigns the value 4 to the global variable X and uses that
> value as the value for the first formal argument of bar():
>> bar(X<-4)
> [1] 6
> # Note that X changed in the global environment
>> X
> [1] 4
> 
> What you call "reflexive assignment" X=X is not really: the left hand
> side is the formal argument of bar(), the right hand side is the
> variable X in the calling environment of bar() (in this case global
> environment).
> 
> Oh yes, and it has absolutely nothing to do with defaults. If you use
> my example above, the default for the argument X is 2, but doing
> X=0
> bar(X=X)
> 
> will call the function with argument X=0, not X=2.
> 
> When there is only one argument, saying X=X does not make much sense,
> but when there are many arguments, say
> 
> bar = function(X=0, Y=0, Z=0)
> 
> and you only want to set the argument Z to a value you call Z in the
> calling function, saying
> 
> bar(Z=Z)
> 
> makes perfect sense and is very different from saying
> 
> bar(Z)
> 
> which would set the argument X to value Z, and leave argument Z at the
> default.
> 
> Hope this helps.
> 
> Peter
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/What-purpose-is-served-by-reflexive-function-assignments-tp4682794p4682825.html
Sent from the R help mailing list archive at Nabble.com.


From ahoerner at rprogress.org  Mon Dec 30 05:37:17 2013
From: ahoerner at rprogress.org (andrewH)
Date: Sun, 29 Dec 2013 20:37:17 -0800 (PST)
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <CA+vqiLHaL2fKGg1VAUUFDVgxomu75ig_bNBRCDugYE5Ov6G8wQ@mail.gmail.com>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
	<CA+vqiLHaL2fKGg1VAUUFDVgxomu75ig_bNBRCDugYE5Ov6G8wQ@mail.gmail.com>
Message-ID: <1388378237232-4682827.post@n4.nabble.com>

Dear Ista--
Peter's post has already persuaded me that my original question was based on
several misunderstandings and so difficult if not impossible to follow --
though he did a remarkable job of figuring out where I was going astray and
what examples might set me right. 

But I will post the results of two of my experiments that I still find
puzzling.

This generates a recursive default error in the cat function. I do not see
why it does not print 5:
X <- 2
gg <-  function(X=X){cat("gg: ", X)}
ss<- function(X){
X <- 5
gg()
}
ss()

And this generates an " 'x' is missing " error in x-y. I expected it to
return the number -1:
x<-1
y<-2
foo<- function(x=x,y=y){x-y}
foo() 

Thanks so much for your time and attention!
andrewH


Ista Zahn wrote
> On Sat, Dec 28, 2013 at 10:27 PM, Andrew Hoerner &lt;

> ahoerner@

> &gt; wrote:
>> Let us suppose that we have a function foo(X) which is called inside
>> another function, bar(). Suppose, moreover, that the name "X" has been
>> assigned a value when foo is called:
>>
>> X <- 2
>> bar(X=X){
>> foo(X)
>> }
>>
>> I have noticed that many functions contain arguments with defaults of the
>> form X=X.
> 
> An example would be really helpful here.
> 
> Call this reflexive assignment of arguments.
> 
> Why call this anything special? All this does is set the default value
> of the X argument. I'm not sure what makes this "reflexive", or why it
> needs a special descriptive term.
> 
> How is foo(X=X)
>> different from foo(X)? Isn't the environment from which X is located the
> 
> foo(X) is hardcoded, foo(X = X) just sets a default.
> 
>> parent environment of foo() in either case? Or if it looks first in the
>> environment inside of foo, will it not immediately pop up to the parent
>> environment if it is not found in foo? Are reflexive assignments just to
>> keep X from being positionally assigned accidentally, or are they doing
>> something deeper? Moreover, this is the only place I have seen people
>> consistently using an equals sign in place of the usual "<-", and I am
>> confident that there is some subtle difference in how the two assignment
>> operators work, perhaps beyond the ken of lesser mortals like myself,
>> that
>> explains why the "=" is preferred in this particular application.
> 
> Again, some examples would really help here.
> 
>>
>> Actually, although I would like to hear the deep answer, which I am sure
>> has something to do with scoping, as everything really confusing in R
>> does,
>> my real question is, is there some rule of thumb by which one could
>> decide
>> whether or not to do a reflexive assignment in a function definition and
>> be
>> right most of the time?
> 
> I'm still not even sure what reflexive assignment means. Can you
> clarify, preferably with some examples.
> 
>>
>> Lately I have gotten several "Error: Promise is already under evaluation"
>> messages, and my current rule of thumb for dealing with this is to add
>> reflexive assignment to the variable if it is missing and take it out if
>> it
>> is present. This seems to work, but it makes me feel unintelligent. Is
>> there a better rule? I would be most grateful for anyone who could shed
>> light on the subject.
> 
> Perhaps someone can, but you will certainly make their job easier if
> you provide a concrete example that produces this error.
> 
> Best,
> Ista
> 
>>
>> Sincerely, andrewH
>>
>> --
>> J. Andrew Hoerner
>> Director, Sustainable Economics Program
>> Redefining Progress
>> (510) 507-4820
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> 

> R-help@

>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/What-purpose-is-served-by-reflexive-function-assignments-tp4682794p4682827.html
Sent from the R help mailing list archive at Nabble.com.


From ahoerner at rprogress.org  Mon Dec 30 05:47:09 2013
From: ahoerner at rprogress.org (andrewH)
Date: Sun, 29 Dec 2013 20:47:09 -0800 (PST)
Subject: [R] Assigning default function arguments to themselves: Why?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1DA29@PA-MBX01.na.tibco.com>
References: <CA+t4QRpSs_1NYVNrMwqsHhPB==tjuA6F6dSzU76L0AhU_kHyFw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA1DA29@PA-MBX01.na.tibco.com>
Message-ID: <1388378829752-4682828.post@n4.nabble.com>

Dear Bill--

I have figured out  that my original question and my most recent response to
you were largely nonsensical bits of idiocy.  Please do not trouble yourself
with them further. But I do thank you most sincerely for your time and
attention.

andrewH




--
View this message in context: http://r.789695.n4.nabble.com/Assigning-default-function-arguments-to-themselves-Why-tp4682294p4682828.html
Sent from the R help mailing list archive at Nabble.com.


From juliosergio at gmail.com  Mon Dec 30 05:48:02 2013
From: juliosergio at gmail.com (Julio Sergio Santana)
Date: Mon, 30 Dec 2013 04:48:02 +0000
Subject: [R] R strange behaviour when working with fifos
References: <loom.20131228T000958-769@post.gmane.org>
Message-ID: <loom.20131230T054524-255@post.gmane.org>

Julio Sergio Santana <juliosergio <at> gmail.com> writes:

> 
> I'm trying to establish a connection to a pair of fifos in R, one 
represents 
> the input stream of a process and the other one the output of the same 
> process. The problem is that R behaves very different when running the 
> commands directly in the interpreter than when running via a script file.


Maybe this is not the right forum for my question. Could anyone direct me to 
the proper site?

Thanks,

  -Sergio.


From jdnewmil at dcn.davis.CA.us  Mon Dec 30 06:13:23 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 29 Dec 2013 21:13:23 -0800
Subject: [R] R strange behaviour when working with fifos
In-Reply-To: <loom.20131230T054524-255@post.gmane.org>
References: <loom.20131228T000958-769@post.gmane.org>
	<loom.20131230T054524-255@post.gmane.org>
Message-ID: <abd38136-1407-4e8d-b9d1-a2a812a32ac3@email.android.com>

Not sure what your question is. Fifos are very operating system specific, so not really on topic here. However, the fact that R responds differently to interactive terminals is pretty universal. Either you can ask a more clear question about interactivity or perhaps someone on R-sig-debian might be willing to help.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Julio Sergio Santana <juliosergio at gmail.com> wrote:
>Julio Sergio Santana <juliosergio <at> gmail.com> writes:
>
>> 
>> I'm trying to establish a connection to a pair of fifos in R, one 
>represents 
>> the input stream of a process and the other one the output of the
>same 
>> process. The problem is that R behaves very different when running
>the 
>> commands directly in the interpreter than when running via a script
>file.
>
>
>Maybe this is not the right forum for my question. Could anyone direct
>me to 
>the proper site?
>
>Thanks,
>
>  -Sergio.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tcmuigai at gmail.com  Mon Dec 30 06:49:07 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Mon, 30 Dec 2013 08:49:07 +0300
Subject: [R] Which R version is the package "ts" available for.
Message-ID: <CAAJc=rPvYF35GMr4+itHnRG54DJejzFFMf=4p+-MxWLY6xNwoA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/b3f0a5ab/attachment.pl>

From elearn2014 at gmail.com  Mon Dec 30 04:15:24 2013
From: elearn2014 at gmail.com (luofeiyu)
Date: Mon, 30 Dec 2013 11:15:24 +0800
Subject: [R] how to display prolerly chinese character of sheet name in
 excel file in xlsx library?
Message-ID: <52C0E54C.9060105@gmail.com>

> library("xlsx")
Loading required package: rJava
Loading required package: xlsxjars
> test_template <- loadWorkbook("c:/workspace/test.xls")
> design_tab <- getSheets(test_template)
> design_tab
$`??????`
[1] "Java-Object{org.apache.poi.hssf.usermodel.HSSFSheet at 1560ca4}"

the sheetname which design_tab denote can not be displayed properly ,the
sheet name of c:/workspace/test.xls is a chinese character ,
how can i make the chinese character of sheet name in excel file to be
displayed in xlsx library?


From gregory.carey at colorado.edu  Mon Dec 30 04:21:12 2013
From: gregory.carey at colorado.edu (Gregory Carey)
Date: Sun, 29 Dec 2013 20:21:12 -0700
Subject: [R] matrix propagation problem
Message-ID: <DA7E0ABF-1544-4E77-B1E2-6603E0603B12@colorado.edu>

Please see the code and R output below. I cannot understand why a matrix object is being propagated in row major order by default and then in column major order when byrow=TRUE is specified when I use one set of dimensions. But when I use different dimensions, the propagation is correct.
Greg

> pvec <- colMeans(rbind(hapn, hapn2))
> class(pvec)
[1] "numeric"
> length(pvec)
[1] 100
> pvec[1:5]
[1] 0.08263811 0.59034639 0.21173734 0.77819000 0.11360578
> nLoci
[1] 100
> nObs
[1] 500
> pvecMat <- matrix(pvec, nLoci, nObs)
> pvecMat[1:5, 1:7]
           [,1]       [,2]       [,3]       [,4]       [,5]       [,6]       [,7]
[1,] 0.08263811 0.08263811 0.08263811 0.08263811 0.08263811 0.08263811 0.08263811
[2,] 0.59034639 0.59034639 0.59034639 0.59034639 0.59034639 0.59034639 0.59034639
[3,] 0.21173734 0.21173734 0.21173734 0.21173734 0.21173734 0.21173734 0.21173734
[4,] 0.77819000 0.77819000 0.77819000 0.77819000 0.77819000 0.77819000 0.77819000
[5,] 0.11360578 0.11360578 0.11360578 0.11360578 0.11360578 0.11360578 0.11360578
> pvecMat2 <- matrix(pvec, nLoci, nObs, byrow=TRUE)
> pvecMat2[1:5, 1:7]
           [,1]      [,2]      [,3]    [,4]      [,5]     [,6]     [,7]
[1,] 0.08263811 0.5903464 0.2117373 0.77819 0.1136058 0.149802 0.829995
[2,] 0.08263811 0.5903464 0.2117373 0.77819 0.1136058 0.149802 0.829995
[3,] 0.08263811 0.5903464 0.2117373 0.77819 0.1136058 0.149802 0.829995
[4,] 0.08263811 0.5903464 0.2117373 0.77819 0.1136058 0.149802 0.829995
[5,] 0.08263811 0.5903464 0.2117373 0.77819 0.1136058 0.149802 0.829995
> matrix(pvec, 2, 5)
           [,1]      [,2]      [,3]      [,4]      [,5]
[1,] 0.08263811 0.2117373 0.1136058 0.8299950 0.7709431
[2,] 0.59034639 0.7781900 0.1498020 0.6973011 0.3875476

From jdnewmil at dcn.davis.CA.us  Mon Dec 30 07:24:27 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 29 Dec 2013 22:24:27 -0800
Subject: [R] Which R version is the package "ts" available for.
In-Reply-To: <CAAJc=rPvYF35GMr4+itHnRG54DJejzFFMf=4p+-MxWLY6xNwoA@mail.gmail.com>
References: <CAAJc=rPvYF35GMr4+itHnRG54DJejzFFMf=4p+-MxWLY6xNwoA@mail.gmail.com>
Message-ID: <da736499-8a95-486e-9d3a-14bb8cd72026@email.android.com>

You know, Google could have helped you with this question. E.g. http://r.789695.n4.nabble.com/library-ts-not-available-td3688535.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Charles Thuo <tcmuigai at gmail.com> wrote:
>I was attempting to install the ts package for time series analysis but
>got the following message.
>
>
>Warning message:
>package ?<ts>? is not available (for R version 3.0.2)
>
>Charles.
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Mon Dec 30 14:31:07 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 30 Dec 2013 08:31:07 -0500
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <1388378237232-4682827.post@n4.nabble.com>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
	<CA+vqiLHaL2fKGg1VAUUFDVgxomu75ig_bNBRCDugYE5Ov6G8wQ@mail.gmail.com>
	<1388378237232-4682827.post@n4.nabble.com>
Message-ID: <CA+vqiLE8TEFAtx5jU8k03tzbqpfgtHAQ3c=T+AqXfXZJ6f=dfQ@mail.gmail.com>

On Sun, Dec 29, 2013 at 11:37 PM, andrewH <ahoerner at rprogress.org> wrote:
> Dear Ista--
> Peter's post has already persuaded me that my original question was based on
> several misunderstandings and so difficult if not impossible to follow --
> though he did a remarkable job of figuring out where I was going astray and
> what examples might set me right.
>
> But I will post the results of two of my experiments that I still find
> puzzling.
>
> This generates a recursive default error in the cat function. I do not see
> why it does not print 5:
> X <- 2
> gg <-  function(X=X){cat("gg: ", X)}
> ss<- function(X){
> X <- 5
> gg()
> }
> ss()
>
> And this generates an " 'x' is missing " error in x-y. I expected it to
> return the number -1:
> x<-1
> y<-2
> foo<- function(x=x,y=y){x-y}
> foo()

OK, so don't do that. And google your errors before asking about theme
here; there are plenty of discussions already on the web.

Best,
Ista

>
> Thanks so much for your time and attention!
> andrewH
>
>
> Ista Zahn wrote
>> On Sat, Dec 28, 2013 at 10:27 PM, Andrew Hoerner &lt;
>
>> ahoerner@
>
>> &gt; wrote:
>>> Let us suppose that we have a function foo(X) which is called inside
>>> another function, bar(). Suppose, moreover, that the name "X" has been
>>> assigned a value when foo is called:
>>>
>>> X <- 2
>>> bar(X=X){
>>> foo(X)
>>> }
>>>
>>> I have noticed that many functions contain arguments with defaults of the
>>> form X=X.
>>
>> An example would be really helpful here.
>>
>> Call this reflexive assignment of arguments.
>>
>> Why call this anything special? All this does is set the default value
>> of the X argument. I'm not sure what makes this "reflexive", or why it
>> needs a special descriptive term.
>>
>> How is foo(X=X)
>>> different from foo(X)? Isn't the environment from which X is located the
>>
>> foo(X) is hardcoded, foo(X = X) just sets a default.
>>
>>> parent environment of foo() in either case? Or if it looks first in the
>>> environment inside of foo, will it not immediately pop up to the parent
>>> environment if it is not found in foo? Are reflexive assignments just to
>>> keep X from being positionally assigned accidentally, or are they doing
>>> something deeper? Moreover, this is the only place I have seen people
>>> consistently using an equals sign in place of the usual "<-", and I am
>>> confident that there is some subtle difference in how the two assignment
>>> operators work, perhaps beyond the ken of lesser mortals like myself,
>>> that
>>> explains why the "=" is preferred in this particular application.
>>
>> Again, some examples would really help here.
>>
>>>
>>> Actually, although I would like to hear the deep answer, which I am sure
>>> has something to do with scoping, as everything really confusing in R
>>> does,
>>> my real question is, is there some rule of thumb by which one could
>>> decide
>>> whether or not to do a reflexive assignment in a function definition and
>>> be
>>> right most of the time?
>>
>> I'm still not even sure what reflexive assignment means. Can you
>> clarify, preferably with some examples.
>>
>>>
>>> Lately I have gotten several "Error: Promise is already under evaluation"
>>> messages, and my current rule of thumb for dealing with this is to add
>>> reflexive assignment to the variable if it is missing and take it out if
>>> it
>>> is present. This seems to work, but it makes me feel unintelligent. Is
>>> there a better rule? I would be most grateful for anyone who could shed
>>> light on the subject.
>>
>> Perhaps someone can, but you will certainly make their job easier if
>> you provide a concrete example that produces this error.
>>
>> Best,
>> Ista
>>
>>>
>>> Sincerely, andrewH
>>>
>>> --
>>> J. Andrew Hoerner
>>> Director, Sustainable Economics Program
>>> Redefining Progress
>>> (510) 507-4820
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>>
>
>> R-help@
>
>>  mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>
>> R-help@
>
>>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/What-purpose-is-served-by-reflexive-function-assignments-tp4682794p4682827.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Mon Dec 30 14:56:31 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 30 Dec 2013 07:56:31 -0600
Subject: [R] Trying to optimize a graph
In-Reply-To: <52bdad56.62d2b40a.1395.ffffe3e8@mx.google.com>
References: <52bdad56.62d2b40a.1395.ffffe3e8@mx.google.com>
Message-ID: <CAN5YmCF=PJpGqarCdPSUp_wHVkpX2r5AOyGvkC5e4M8iSCpw-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/bb412d04/attachment.pl>

From smartpink111 at yahoo.com  Mon Dec 30 15:17:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 30 Dec 2013 06:17:03 -0800 (PST)
Subject: [R] I have a problem in doing the scatterplot
In-Reply-To: <CAFkF=gFK9GFZsnA8nMcroGNDrxF43dUDLesbgGYv7PBZY1skbg@mail.gmail.com>
References: <CAFkF=gFK9GFZsnA8nMcroGNDrxF43dUDLesbgGYv7PBZY1skbg@mail.gmail.com>
Message-ID: <1388413023.80359.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:

tab1 <- read.table("132p1vs132p2",sep="\t",header=TRUE)
?str(tab1)
#'data.frame':??? 1765 obs. of? 2 variables:
# $ Sample_132p1: num? 2.395 0 0.216 0 0.246 ...
# $ Sample_132p2: num? 2.428 0 0.247 0 0.136 ...

plot(tab1$Sample_132p1,tab1$Sample_132p2,pch=20)
fm <- lm(tab1$Sample_132p2~tab1$Sample_132p1)
abline(fm,col="red")
#or
abline(coef=coef(fm),col="blue")
#or
abline(a=fm$coefficients[1],b=fm$coefficients[2],col="green")

A.K.


On Monday, December 30, 2013 6:19 AM, Vivek Das <vd4mmind at gmail.com> wrote:

Dear Arun,

I am trying to draw a scatter plot with the best fit line. My data is in the attachment. and am providing the code am using but the best fit line is not coming. Can you please let me know where am getting wrong.

tab=read.table("~/Desktop/Bonn_New_Pas_algo_data/results_30092013/edgeR_24122013/corr_test_PGRTvsPDGRT/132p1vs132p2",sep="\t",header=T)
> plot(tab$Sample_132p1,tab$Sample_132p2,pch=20)

Am getting the plot but now if I want the best fit line am not getting it. Can you guide?


----------------------------------------------------------

Vivek Das


From dwinsemius at comcast.net  Mon Dec 30 16:48:48 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 30 Dec 2013 07:48:48 -0800
Subject: [R] matrix propagation problem
In-Reply-To: <DA7E0ABF-1544-4E77-B1E2-6603E0603B12@colorado.edu>
References: <DA7E0ABF-1544-4E77-B1E2-6603E0603B12@colorado.edu>
Message-ID: <9DF20669-735E-4BCD-AB0D-ADDC47B770A2@comcast.net>


On Dec 29, 2013, at 7:21 PM, Gregory Carey wrote:

> Please see the code and R output below. I cannot understand why a  
> matrix object is being propagated in row major order by default and  
> then in column major order when byrow=TRUE is specified when I use  
> one set of dimensions. But when I use different dimensions, the  
> propagation is correct.

You appear to be reversing the terms column-major and row-major order  
from the fashion in which they are being used by the majority of  
commenters in R help. The first example without byrow=TRUE is what I  
would have called column-major while the second is row-major.

The third example appears to be loading values in column-major order.  
So I do not see any inconsistency.

-- 
David.
> Greg
>
>> pvec <- colMeans(rbind(hapn, hapn2))
>> class(pvec)
> [1] "numeric"
>> length(pvec)
> [1] 100
>> pvec[1:5]
> [1] 0.08263811 0.59034639 0.21173734 0.77819000 0.11360578
>> nLoci
> [1] 100
>> nObs
> [1] 500
>> pvecMat <- matrix(pvec, nLoci, nObs)
>> pvecMat[1:5, 1:7]
>           [,1]       [,2]       [,3]       [,4]       [,5]       [, 
> 6]       [,7]
> [1,] 0.08263811 0.08263811 0.08263811 0.08263811 0.08263811  
> 0.08263811 0.08263811
> [2,] 0.59034639 0.59034639 0.59034639 0.59034639 0.59034639  
> 0.59034639 0.59034639
> [3,] 0.21173734 0.21173734 0.21173734 0.21173734 0.21173734  
> 0.21173734 0.21173734
> [4,] 0.77819000 0.77819000 0.77819000 0.77819000 0.77819000  
> 0.77819000 0.77819000
> [5,] 0.11360578 0.11360578 0.11360578 0.11360578 0.11360578  
> 0.11360578 0.11360578
>> pvecMat2 <- matrix(pvec, nLoci, nObs, byrow=TRUE)
>> pvecMat2[1:5, 1:7]
>           [,1]      [,2]      [,3]    [,4]      [,5]     [,6]     [,7]
> [1,] 0.08263811 0.5903464 0.2117373 0.77819 0.1136058 0.149802  
> 0.829995
> [2,] 0.08263811 0.5903464 0.2117373 0.77819 0.1136058 0.149802  
> 0.829995
> [3,] 0.08263811 0.5903464 0.2117373 0.77819 0.1136058 0.149802  
> 0.829995
> [4,] 0.08263811 0.5903464 0.2117373 0.77819 0.1136058 0.149802  
> 0.829995
> [5,] 0.08263811 0.5903464 0.2117373 0.77819 0.1136058 0.149802  
> 0.829995
>> matrix(pvec, 2, 5)
>           [,1]      [,2]      [,3]      [,4]      [,5]
> [1,] 0.08263811 0.2117373 0.1136058 0.8299950 0.7709431
> [2,] 0.59034639 0.7781900 0.1498020 0.6973011 0.3875476
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Dec 30 17:05:46 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 30 Dec 2013 08:05:46 -0800
Subject: [R] Which R version is the package "ts" available for.
In-Reply-To: <da736499-8a95-486e-9d3a-14bb8cd72026@email.android.com>
References: <CAAJc=rPvYF35GMr4+itHnRG54DJejzFFMf=4p+-MxWLY6xNwoA@mail.gmail.com>
	<da736499-8a95-486e-9d3a-14bb8cd72026@email.android.com>
Message-ID: <9D7A4374-A919-4FFE-B1B3-78867D972E98@comcast.net>


On Dec 29, 2013, at 10:24 PM, Jeff Newmiller wrote:

> You know, Google could have helped you with this question. E.g. http://r.789695.n4.nabble.com/library-ts-not-available-td3688535.html

fortunes::fortune("'Liaw-Baron principle'")


> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go  
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.   
> Live Go...
>                                      Live:   OO#.. Dead: OO#..   
> Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.   
> rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> Charles Thuo <tcmuigai at gmail.com> wrote:
>> I was attempting to install the ts package for time series analysis  
>> but
>> got the following message.
>>
>>
>> Warning message:
>> package ?<ts>? is not available (for R version 3.0.2)
>>
>> Charles.
>>
>> 	[[alternative HTML version deleted]]


David Winsemius, MD
Alameda, CA, USA


From axel.urbiz at gmail.com  Mon Dec 30 19:24:08 2013
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Mon, 30 Dec 2013 19:24:08 +0100
Subject: [R] Package dependencies in building R packages
Message-ID: <CAAyVsXJ_wPdugKUXOEbUFT_dXSv9kWboR-dz4V67tSMP+FxCfQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/7deb3704/attachment.pl>

From capricyg at yahoo.com  Mon Dec 30 19:42:33 2013
From: capricyg at yahoo.com (capricy gao)
Date: Mon, 30 Dec 2013 10:42:33 -0800 (PST)
Subject: [R] need help with distribution graphics
In-Reply-To: <52BF397D.6060307@bitwrit.com.au>
References: <1388201159.77842.YahooMailNeo@web125004.mail.ne1.yahoo.com>	<52BEC3D6.9090703@statistik.tu-dortmund.de>
	<1388248907.96530.YahooMailNeo@web125002.mail.ne1.yahoo.com>
	<52BF397D.6060307@bitwrit.com.au>
Message-ID: <1388428953.91574.YahooMailNeo@web125006.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/117012f1/attachment.pl>

From murdoch.duncan at gmail.com  Mon Dec 30 19:51:20 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 30 Dec 2013 13:51:20 -0500
Subject: [R] Package dependencies in building R packages
In-Reply-To: <CAAyVsXJ_wPdugKUXOEbUFT_dXSv9kWboR-dz4V67tSMP+FxCfQ@mail.gmail.com>
References: <CAAyVsXJ_wPdugKUXOEbUFT_dXSv9kWboR-dz4V67tSMP+FxCfQ@mail.gmail.com>
Message-ID: <52C1C0A8.4080301@gmail.com>

On 13-12-30 1:24 PM, Axel Urbiz wrote:
> Dear users,
>
> My package {foo} depends on a function "miscFUN" which is on package
> {foo_depend}. This last package also depends on other packages, say {A, B,
> C}, but miscFUN is not dependent on A, B, C (only on foo_depend).
>
> In my package {foo}, is there a way to only have it depend on the function
> miscFUN from {foo_depend} without having the user to have installed A, B,
> C? (as none of those packages are needed for my package to work properly).
> Also, is this a best practice?

There's no way for your package to tell R to ignore the dependencies 
declared by foo_depend.

If you really only need one function from that package, simply copy the 
source of miscFUN into your package (assuming foo_depend's license 
permits that).  But this is not best practice, unless that function is 
very simple.  Best practice is to declare your dependence by importing 
that function from foo_depend.

Duncan Murdoch


From axel.urbiz at gmail.com  Mon Dec 30 20:01:46 2013
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Mon, 30 Dec 2013 20:01:46 +0100
Subject: [R] Package dependencies in building R packages
In-Reply-To: <52C1C0A8.4080301@gmail.com>
References: <CAAyVsXJ_wPdugKUXOEbUFT_dXSv9kWboR-dz4V67tSMP+FxCfQ@mail.gmail.com>
	<52C1C0A8.4080301@gmail.com>
Message-ID: <CAAyVsXKCN1Zn4gbG=QkD759kaDadPbgp+9e3W6nPvOLVwAsU=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/9e7c2b64/attachment.pl>

From murdoch.duncan at gmail.com  Mon Dec 30 21:13:29 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 30 Dec 2013 15:13:29 -0500
Subject: [R] Package dependencies in building R packages
In-Reply-To: <CAAyVsXKCN1Zn4gbG=QkD759kaDadPbgp+9e3W6nPvOLVwAsU=w@mail.gmail.com>
References: <CAAyVsXJ_wPdugKUXOEbUFT_dXSv9kWboR-dz4V67tSMP+FxCfQ@mail.gmail.com>	<52C1C0A8.4080301@gmail.com>
	<CAAyVsXKCN1Zn4gbG=QkD759kaDadPbgp+9e3W6nPvOLVwAsU=w@mail.gmail.com>
Message-ID: <52C1D3E9.7080107@gmail.com>

On 13-12-30 2:01 PM, Axel Urbiz wrote:
> Thanks for your kind response Duncan. To be more specific, I'm using the
> function mvrnorm from MASS. The issue is that MASS depends on survival
> and I have a function in my package named tt() which conflicts with a
> function in survival of the same name. I can think of 2 alternatives
> solutions to my problem, but I'm to an expert:
>
> 1) Copy mvrnorm into my package, which I thought was not a good idea
> 2) Rename my tt() function to something else in my package, but this is
> painful as I have it all over the place in other functions.
>
> Any suggestions would be much appreciated.

I would simply import MASS::mvrnorm in your NAMESPACE file.  Then the tt 
function in survival won't be visible in your package and won't become 
visible to users because of you, so most users won't be affected by the 
conflict.  (In fact, I think MASS only "Suggests" survival, so even if 
you attach MASS, you won't automatically attach survival.)

Of course, some users may attach both your package and the survival 
package, and then the name clash will inconvenience them.  If your 
package is new, I'd choose a different name for tt() to avoid this.  If 
you have already published it using the name tt(), then renaming it will 
possibly inconvenience more people than dealing with the name clash 
does, so I'd just document it in the ?tt help page.

Duncan Murdoch


From chuse22 at gmail.com  Mon Dec 30 21:19:47 2013
From: chuse22 at gmail.com (Xuse Chuse)
Date: Mon, 30 Dec 2013 22:19:47 +0200
Subject: [R] Estimation of AR(1) model by QML.
Message-ID: <CANZw-E6HiXphMgoyaaxC5RUrLc2SmgTYXiTWuZNm0N8WOYeUcg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/95256163/attachment.pl>

From ahoerner at rprogress.org  Mon Dec 30 22:19:49 2013
From: ahoerner at rprogress.org (Andrew Hoerner)
Date: Mon, 30 Dec 2013 13:19:49 -0800
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1FB8A@PA-MBX01.na.tibco.com>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
	<26A72EB0-6412-4E79-BEF9-70FF05BACEAC@comcast.net>
	<1388361449016-4682819.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B933FA1FB8A@PA-MBX01.na.tibco.com>
Message-ID: <CA+t4QRqfpzKKAjDfKCHmG40hcJZmXBbtzLQvh369UeTnCz1z2g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/eb0ae8a5/attachment.pl>

From ahoerner at rprogress.org  Mon Dec 30 22:54:48 2013
From: ahoerner at rprogress.org (Andrew Hoerner)
Date: Mon, 30 Dec 2013 13:54:48 -0800
Subject: [R] What purpose is served by reflexive function assignments?
In-Reply-To: <E994EE1E-10D6-4AF2-B6CA-00DCC24B983B@comcast.net>
References: <CA+t4QRrxA9JZdK5L-henjuOn36=ye5BiV0NG5nUwt=vke_HqHg@mail.gmail.com>
	<26A72EB0-6412-4E79-BEF9-70FF05BACEAC@comcast.net>
	<1388361449016-4682819.post@n4.nabble.com>
	<E994EE1E-10D6-4AF2-B6CA-00DCC24B983B@comcast.net>
Message-ID: <CA+t4QRryOtdZat_E03Xy3Laa7yDbxicpcYAritwyzr3BoP1+AQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/5d25cb05/attachment.pl>

From tring at gvdnet.dk  Mon Dec 30 23:37:45 2013
From: tring at gvdnet.dk (Troels Ring)
Date: Mon, 30 Dec 2013 23:37:45 +0100
Subject: [R] Milliken and Johnson Unbalanced Machines
Message-ID: <52C1F5B9.3040006@gvdnet.dk>

Dear friends - reading Milliken and Johnson on messy data I failed to 
find R code to master the unbalanced Machines data in ch 23.
I wonder if anyone can lend me a hand - again
Happy new year
Troels Ring
Aalborg, Denmark


From szehnder at uni-bonn.de  Mon Dec 30 23:57:26 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Mon, 30 Dec 2013 23:57:26 +0100
Subject: [R] Estimation of AR(1) model by QML.
In-Reply-To: <CANZw-E6HiXphMgoyaaxC5RUrLc2SmgTYXiTWuZNm0N8WOYeUcg@mail.gmail.com>
References: <CANZw-E6HiXphMgoyaaxC5RUrLc2SmgTYXiTWuZNm0N8WOYeUcg@mail.gmail.com>
Message-ID: <17F8E444-889D-4C35-B5E8-2B831F058421@uni-bonn.de>

Why not using optim on the likelihood in a) with normally distributed standard errors and for b) optim with a likelihood with t(3)-distributed standard errors?

Best

Simon

On 30 Dec 2013, at 21:19, Xuse Chuse <chuse22 at gmail.com> wrote:

> Dear Users,
> 
> I am trying to estimate a model Y(t)=alpha+rho*Y(t-1)+e(t) where i know
> e(t)~t(3).
> 
> a) I want to estimate (alpha, rho) by QML estimation assuming (wrongly)
> that e(t)~N(0,sigma2) and calculate the standard errors.
> b) Estimate (alpha, rho) by ML estimation assuming (correctly) e(t)~t(3)
> and compute standard errors.
> 
> Can anyone help me out to figure out how I could answer this question in R?
> Thank you beforehand.
> 
> Cheers,
> Chuse
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From szehnder at uni-bonn.de  Tue Dec 31 00:04:28 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 31 Dec 2013 00:04:28 +0100
Subject: [R] Milliken and Johnson Unbalanced Machines
In-Reply-To: <52C1F5B9.3040006@gvdnet.dk>
References: <52C1F5B9.3040006@gvdnet.dk>
Message-ID: <C0786BB7-8F50-4D4F-BEBA-8B4986681233@uni-bonn.de>

I don?t know anything about this topic, but looking into this book: http://books.google.de/books?id=3TVDAAAAQBAJ&pg=PA25&lpg=PA25&dq=milliken+and+johnson+unbalanced+machines&source=bl&ots=lxqStiQju5&sig=d5dG_cHsTzilCIklBrW9SAMKYRM&hl=de&sa=X&ei=ifrBUuvoM8qPtAbPqoCQDQ&ved=0CGUQ6AEwBQ#v=onepage&q=milliken%20and%20johnson%20unbalanced%20machines&f=false

should give you a little hint I guess.

Best

Simon

On 30 Dec 2013, at 23:37, Troels Ring <tring at gvdnet.dk> wrote:

> Dear friends - reading Milliken and Johnson on messy data I failed to find R code to master the unbalanced Machines data in ch 23.
> I wonder if anyone can lend me a hand - again
> Happy new year
> Troels Ring
> Aalborg, Denmark
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From catalinroibu at gmail.com  Tue Dec 31 00:23:37 2013
From: catalinroibu at gmail.com (catalin roibu)
Date: Tue, 31 Dec 2013 01:23:37 +0200
Subject: [R] MTM power spectrum
Message-ID: <CAEW+BDL4t9Fzp3609PcpJS66gaM82yZQRhCdApEW9SBgTFUuaA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131231/e10b854f/attachment.pl>

From tohamyy at yahoo.com  Mon Dec 30 16:21:31 2013
From: tohamyy at yahoo.com (Tohamy Yousef)
Date: Mon, 30 Dec 2013 07:21:31 -0800 (PST)
Subject: [R] adding a fram around R plot
Message-ID: <1388416891.59178.YahooMailNeo@web122602.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/ed311995/attachment.pl>

From galak at gmx.net  Mon Dec 30 17:18:01 2013
From: galak at gmx.net (Alexander Schuster)
Date: Mon, 30 Dec 2013 17:18:01 +0100
Subject: [R] howto join matrices produced by rcorr()
Message-ID: <52C19CB9.2000402@gmx.net>

Hi,

i have used rcorr() for calculating pearsons r and according p-values
for my data, giving me 2 matrices.

Now I would like to print scatterplots for all results with "good"
correlation values.

So i need a way to extract the row-name and column-name for each item in
the matrix with "good" r-values, so i can use them in the
plot()-function on my original dataframe programmatically.

below is what i have got - and now i'm stuck:

--------------------------------------
incomingData <- read.csv(inputfile, header=TRUE, na="NA")
datamatrix <- data.matrix(incomingData)
library(Hmisc)
output <- rcorr(datamatrix, type="pearson")

# get short variables to ease reading
r <- output$r
n <- output$n
P <- output$P

r[n<5]<-NA # ignore less than five observations
r[r>-0.5 & r<0.5]<-NA # take only "good" korrelations
P[is.na(r)]<-NA # delete P values for deleted korrelations

r <- format(round(cbind(rep(-1.11, ncol(r)), r), 2))[,-1] ## trunctuate
matrix with correlations to 2 decimals

P <- format(round(cbind(rep(-1.11, ncol(P)), P), 4))[,-1] ## trunctuate
matrix with P-Values to 4 decimals

make_plot <- function(a,b,Rval,Pval,aname,bname) {
	png(paste(aname,'_vs_',bname,'.png', sep=""))
	plot(a,b, main="Rval(p=Pval)")
	fitline <- lm(a~b)
	abline(fitline)
	dev.off()
}

-------------------------------------

Big Thanks for any ideas on this, Alex


From jieyueli82 at gmail.com  Mon Dec 30 23:04:17 2013
From: jieyueli82 at gmail.com (Jieyue Li)
Date: Mon, 30 Dec 2013 14:04:17 -0800
Subject: [R] cumulative incidence for mstate in Survival package in R
Message-ID: <CALYjA0T3T7JbBOL8k_GMY4xm66k5aDXMXQ1mQTn6PT4sbUVBBQ@mail.gmail.com>

Dear All,

I want to have the cumulative incidence curves for 'mstate' data using
Survival package in R. But I got some problems:
I. Problem 1:
1. If I only use intercept without any covariates, I can have 'right'
cumulative incidence curves (2 for 2 competing risks):
library(Survival)
fitCI <- survfit(Surv(stop, status*as.numeric(event), type="mstate") ~
1,data=mgus1, subset=(start==0))
plot(fitCI)
2. If I include one variate ('sex'), I get 4 curves (attached; I guess
because there are two levels in 'sex' and 2 competing risks):
fitCI <- survfit(Surv(stop, status*as.numeric(event), type="mstate")
~sex,data=mgus1, subset=(start==0))
plot(fitCI)
However, I want to just have 2 cumulative incidence curves estimated from
several covariates (such as 'sex', 'age', 'alb', etc. in mgus1). Could you
please help me to do that? Thank you very much!
II. Problem 2:
I try using an example from sourcecode.pdf:
fit <- survfit(Surv(time, status, type=?mstate?) ~ sex, data=mine)
but where can I have the 'mine' data? Thank you!

Best,

Jieyue
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.png
Type: image/png
Size: 9373 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/4a7a0a41/attachment.png>

From kerriobrown at gmail.com  Mon Dec 30 23:09:00 2013
From: kerriobrown at gmail.com (Kerrio Brown)
Date: Mon, 30 Dec 2013 17:09:00 -0500
Subject: [R] dist() or cmdscale() function help
In-Reply-To: <CAND4j_G9L1XLeDC=Qo7pc0_yVbbbrrOn2OKexzWptKgDUP=z2Q@mail.gmail.com>
References: <CAND4j_G9L1XLeDC=Qo7pc0_yVbbbrrOn2OKexzWptKgDUP=z2Q@mail.gmail.com>
Message-ID: <CAND4j_Gh2K2HDKmRjqWNhL0j+LY4_=o=SPf=B5wSh3c51y-a6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/a5bd3bf2/attachment.pl>

From lordgeoffrey at optusnet.com.au  Tue Dec 31 01:46:53 2013
From: lordgeoffrey at optusnet.com.au (Geoffrey)
Date: Tue, 31 Dec 2013 10:46:53 +1000
Subject: [R] aes and parameter evaluation problems
Message-ID: <52C213FD.5090506@optusnet.com.au>

I am trying add geom_line's using a loop but the nature of unevaluated 
parameters is causing me problems.

This code works:
ex <- function() {
   d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
   g <- ggplot(d, aes(x))
   g <- g +
     geom_line(aes(y=a,colour=a)) +
     geom_line(aes(y=b,colour=b)) +
     geom_line(aes(y=c,colour=c))
   return(g)
}

This code (not surprisingly) fails:
ex2 <- function() {
   d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
   g <- ggplot(d, aes(x))
   for (n in c("a","b","c")) {
     g <- g + geom_line(aes(y=n,colour=n))
   }
   return(g)
}

I believe i want something like the failing code, but done right.

I have two problems (at least in this code):
#1 how do handle the parameter evaluation
#2 is this the right thing to be even doing with geom_line() & aes() ?

Geoff.


From smartpink111 at yahoo.com  Tue Dec 31 04:29:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 30 Dec 2013 19:29:00 -0800 (PST)
Subject: [R] aes and parameter evaluation problems
In-Reply-To: <52C213FD.5090506@optusnet.com.au>
References: <52C213FD.5090506@optusnet.com.au>
Message-ID: <1388460540.79355.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi,
Try:

ex2 <- function() {
? d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
? g <- ggplot(d, aes(x))
??? for (n in c("a","b","c")) {
??? g <- g + geom_line(aes_string(y=n,colour=n))
? }
?return(g)
}

A.K.


On Monday, December 30, 2013 7:49 PM, Geoffrey <lordgeoffrey at optusnet.com.au> wrote:
I am trying add geom_line's using a loop but the nature of unevaluated 
parameters is causing me problems.

This code works:
ex <- function() {
?  d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
?  g <- ggplot(d, aes(x))
?  g <- g +
? ?  geom_line(aes(y=a,colour=a)) +
? ?  geom_line(aes(y=b,colour=b)) +
? ?  geom_line(aes(y=c,colour=c))
?  return(g)
}

This code (not surprisingly) fails:
ex2 <- function() {
?  d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
?  g <- ggplot(d, aes(x))
?  for (n in c("a","b","c")) {
? ?  g <- g + geom_line(aes(y=n,colour=n))
?  }
?  return(g)
}

I believe i want something like the failing code, but done right.

I have two problems (at least in this code):
#1 how do handle the parameter evaluation
#2 is this the right thing to be even doing with geom_line() & aes() ?

Geoff.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jim at bitwrit.com.au  Tue Dec 31 05:07:04 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 31 Dec 2013 15:07:04 +1100
Subject: [R] adding a fram around R plot
In-Reply-To: <1388416891.59178.YahooMailNeo@web122602.mail.ne1.yahoo.com>
References: <1388416891.59178.YahooMailNeo@web122602.mail.ne1.yahoo.com>
Message-ID: <52C242E8.4010809@bitwrit.com.au>

On 12/31/2013 02:21 AM, Tohamy Yousef wrote:
> Hi all,
>
>   I need to know how to put a closed frame around my plot.  I am
> plotting
> using the field package, and I have been able to use box() with
> limited
>   success. Box() puts a border around only a part of  the
> plot area not all.
> I saw that there was a similar problem in this group but I used the suggested solution, par(c('bty','xpd')),
> but without success.
>
> How can I add a frame around my plot

Hi Tohamy,
Usually a box around the entire figure is wanted when embedding the plot 
in a document, and this is handled by the page formatting application. 
However, if you really need to add this:

outerBox<-function(lty=1,lwd=1,border=NULL) {
  plotlim<-par("usr")
  marg<-par("mar")
  ppin<-par("pin")
  pfin<-par("fin")
  xin<-(plotlim[2]-plotlim[1])*0.003
  yin<-(plotlim[4]-plotlim[3])*0.003
  xleft<-plotlim[1]-(plotlim[2]-plotlim[1])*
   ((pfin[1]-ppin[1])/ppin[1])*(marg[2]/(marg[2]+marg[4]))
  xright<-plotlim[2]+(plotlim[2]-plotlim[1])*
   ((pfin[1]-ppin[1])/ppin[1])*(marg[4]/(marg[2]+marg[4]))
  ybottom<-plotlim[3]-(plotlim[4]-plotlim[3])*
   ((pfin[2]-ppin[2])/ppin[2])*(marg[1]/(marg[1]+marg[3]))
  ytop<-plotlim[4]+(plotlim[4]-plotlim[3])*
   ((pfin[2]-ppin[2])/ppin[2])*(marg[3]/(marg[1]+marg[3]))
  cat(plotlim,"\n",xleft,ybottom,xright,ytop,"\n")
  par(xpd=TRUE)
 
rect(xleft+xin,ybottom+yin,xright-xin,ytop-yin,lty=lty,lwd=lwd,border=border)
  par(xpd=FALSE)
}

Jim


From jdnewmil at dcn.davis.CA.us  Tue Dec 31 07:04:00 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 30 Dec 2013 22:04:00 -0800
Subject: [R] aes and parameter evaluation problems
In-Reply-To: <1388460540.79355.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <52C213FD.5090506@optusnet.com.au>
	<1388460540.79355.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <9597a812-21c8-40d5-b546-18f7c1f815e8@email.android.com>

A.K. answered your question 1, but since you did say as question 2 that you wanted it done right...

library(reshape2)
ex3 <- function() {
  d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
  dl <- melt( d, id.vars="x" )
  ggplot(dl,aes(x=x,y=value,color=variable))+
    geom_line()
}

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

arun <smartpink111 at yahoo.com> wrote:
>
>
>Hi,
>Try:
>
>ex2 <- function() {
>? d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
>? g <- ggplot(d, aes(x))
>??? for (n in c("a","b","c")) {
>??? g <- g + geom_line(aes_string(y=n,colour=n))
>? }
>?return(g)
>}
>
>A.K.
>
>
>On Monday, December 30, 2013 7:49 PM, Geoffrey
><lordgeoffrey at optusnet.com.au> wrote:
>I am trying add geom_line's using a loop but the nature of unevaluated 
>parameters is causing me problems.
>
>This code works:
>ex <- function() {
>?  d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
>?  g <- ggplot(d, aes(x))
>?  g <- g +
>? ?  geom_line(aes(y=a,colour=a)) +
>? ?  geom_line(aes(y=b,colour=b)) +
>? ?  geom_line(aes(y=c,colour=c))
>?  return(g)
>}
>
>This code (not surprisingly) fails:
>ex2 <- function() {
>?  d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
>?  g <- ggplot(d, aes(x))
>?  for (n in c("a","b","c")) {
>? ?  g <- g + geom_line(aes(y=n,colour=n))
>?  }
>?  return(g)
>}
>
>I believe i want something like the failing code, but done right.
>
>I have two problems (at least in this code):
>#1 how do handle the parameter evaluation
>#2 is this the right thing to be even doing with geom_line() & aes() ?
>
>Geoff.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Tue Dec 31 08:22:47 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 31 Dec 2013 07:22:47 +0000
Subject: [R] Estimation of AR(1) model by QML.
In-Reply-To: <17F8E444-889D-4C35-B5E8-2B831F058421@uni-bonn.de>
References: <CANZw-E6HiXphMgoyaaxC5RUrLc2SmgTYXiTWuZNm0N8WOYeUcg@mail.gmail.com>
	<17F8E444-889D-4C35-B5E8-2B831F058421@uni-bonn.de>
Message-ID: <52C270C7.3080708@stats.ox.ac.uk>

On 30/12/2013 22:57, Simon Zehnder wrote:
> Why not using optim on the likelihood in a) with normally distributed standard errors and for b) optim with a likelihood with t(3)-distributed standard errors?

Because evaluating the likelihood is a tricky business here.

I don't know what is meant by 'QML' here (even if the Q means 'quasi', 
the term is used in several distinct senses, none common for time-series).

Suppose you observe (Y(1) ... Y(T)).  Note that Y(1) depends on the 
unobserved Y(0).  In the Gaussian case you can write down the joint 
multilvariate normal distribution and compute it with some matrix 
algebra (assuming stationarity, which means a constrained optimization). 
  But in case b) the joint distribution is not multivariate T.

An approach from 50+ years ago is to condition on Y(1), when this is 
just a regression.  For the Gaussian case, see ar.ols(): for the t(3) 
case you can use a robust regression function (but beware that the 
optimization can be tricky).

> Best
>
> Simon
>
> On 30 Dec 2013, at 21:19, Xuse Chuse <chuse22 at gmail.com> wrote:
>
>> Dear Users,
>>
>> I am trying to estimate a model Y(t)=alpha+rho*Y(t-1)+e(t) where i know
>> e(t)~t(3).
>>
>> a) I want to estimate (alpha, rho) by QML estimation assuming (wrongly)
>> that e(t)~N(0,sigma2) and calculate the standard errors.
>> b) Estimate (alpha, rho) by ML estimation assuming (correctly) e(t)~t(3)
>> and compute standard errors.
>>
>> Can anyone help me out to figure out how I could answer this question in R?
>> Thank you beforehand.
>>
>> Cheers,
>> Chuse

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From parkhurs at indiana.edu  Tue Dec 31 02:42:53 2013
From: parkhurs at indiana.edu (David Parkhurst)
Date: Mon, 30 Dec 2013 20:42:53 -0500
Subject: [R] Where did lost variables go
Message-ID: <52C2211D.5050606@indiana.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131230/7b5b91bb/attachment.pl>

From phgrosjean at sciviews.org  Tue Dec 31 10:32:27 2013
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 31 Dec 2013 10:32:27 +0100
Subject: [R] Package dependencies in building R packages
In-Reply-To: <CAAyVsXKCN1Zn4gbG=QkD759kaDadPbgp+9e3W6nPvOLVwAsU=w@mail.gmail.com>
References: <CAAyVsXJ_wPdugKUXOEbUFT_dXSv9kWboR-dz4V67tSMP+FxCfQ@mail.gmail.com>
	<52C1C0A8.4080301@gmail.com>
	<CAAyVsXKCN1Zn4gbG=QkD759kaDadPbgp+9e3W6nPvOLVwAsU=w@mail.gmail.com>
Message-ID: <28AE9D4B-8823-4625-899A-C3F3DF8252F0@sciviews.org>


On 30 Dec 2013, at 20:01, Axel Urbiz <axel.urbiz at gmail.com> wrote:

> Thanks for your kind response Duncan. To be more specific, I'm using the
> function mvrnorm from MASS. The issue is that MASS depends on survival and
> I have a function in my package named tt() which conflicts with a function
> in survival of the same name. I can think of 2 alternatives solutions to my
> problem, but I'm to an expert:

As of version 7.3-29 of MASS, it only depends on R (>= 3.0.0), grDevices, graphics, stats and utils. survival appears in the 'Suggests' field, which is very different. When you do 'library(MASS)' or 'require(MASS)', it does not import survival's NAMESPACE, at least at startup (and if it did, this would not cause interferences with your package? precisely the purpose of namespaces). It also does not attach survival to the search path, logically? and if it did, your package 'foo' would be attached higher on that search path, causing survival's tt() function being masked by your foo::tt() function, e.g., from the Global Environment with a warning. So, the only inconvenience in this case would be for users that need to use tt() from 'survival', and it would be better to always indicate explicitly foo::tt() or survival::tt() in order to eliminate the ambiguity.

> 1) Copy mvrnorm into my package, which I thought was not a good idea

Absolutely, think about future bug fixes. Moreover, it will not solve the problem in case someone attaches the 'survival' package higher in the search path than 'foo', e.g., using this in .GlobalEnv:

require(foo)
require(survival)
tt() # This would be survival::tt() that is called!

> 2) Rename my tt() function to something else in my package, but this is
> painful as I have it all over the place in other functions.

Definitely the best solution, providing your package is not on CRAN yet and has no other CRAN packages depending on it, and especially on your tt() function. Otherwise, you should declare tt() deprecated (see ?.Deprecated), make sure you inform maintainers of dependent packages of your changes, and wait long enough before removing tt() totally for user to adapt.

Otherwise, choose a good code editor, with regexpr search on all files in a directory makes it easy to change calls to tt() all over the places. RStudio, Emacs+ESS, Eclipse+StatEt, Komodo+SciViews-K come to me mind first, but there are many others.

Best,

Philippe

> Any suggestions would be much appreciated.
> 
> Best,
> Axel.
> 
> 
> On Mon, Dec 30, 2013 at 7:51 PM, Duncan Murdoch <murdoch.duncan at gmail.com>wrote:
> 
>> On 13-12-30 1:24 PM, Axel Urbiz wrote:
>> 
>>> Dear users,
>>> 
>>> My package {foo} depends on a function "miscFUN" which is on package
>>> {foo_depend}. This last package also depends on other packages, say {A, B,
>>> C}, but miscFUN is not dependent on A, B, C (only on foo_depend).
>>> 
>>> In my package {foo}, is there a way to only have it depend on the function
>>> miscFUN from {foo_depend} without having the user to have installed A, B,
>>> C? (as none of those packages are needed for my package to work properly).
>>> Also, is this a best practice?
>>> 
>> 
>> There's no way for your package to tell R to ignore the dependencies
>> declared by foo_depend.
>> 
>> If you really only need one function from that package, simply copy the
>> source of miscFUN into your package (assuming foo_depend's license permits
>> that).  But this is not best practice, unless that function is very simple.
>> Best practice is to declare your dependence by importing that function
>> from foo_depend.
>> 
>> Duncan Murdoch
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From szehnder at uni-bonn.de  Tue Dec 31 10:42:40 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 31 Dec 2013 10:42:40 +0100
Subject: [R] Where did lost variables go
In-Reply-To: <52C2211D.5050606@indiana.edu>
References: <52C2211D.5050606@indiana.edu>
Message-ID: <10F2147E-3BFA-467E-9A1F-05C132BE1EB9@uni-bonn.de>

A reproducible example would do well here David

Best

Simon
On 31 Dec 2013, at 02:42, David Parkhurst <parkhurs at indiana.edu> wrote:

> I have several variables in a data frame that aren't listed by ls() 
> after I attach that data frame.  Where did they go, and how can I stop 
> the hidden ones from masking the local ones?
> Thanks for any help.
> David
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From goran.brostrom at umu.se  Tue Dec 31 10:59:24 2013
From: goran.brostrom at umu.se (=?windows-1252?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 31 Dec 2013 10:59:24 +0100
Subject: [R] cumulative incidence for mstate in Survival package in R
In-Reply-To: <CALYjA0T3T7JbBOL8k_GMY4xm66k5aDXMXQ1mQTn6PT4sbUVBBQ@mail.gmail.com>
References: <CALYjA0T3T7JbBOL8k_GMY4xm66k5aDXMXQ1mQTn6PT4sbUVBBQ@mail.gmail.com>
Message-ID: <52C2957C.7010806@umu.se>

On 12/30/2013 11:04 PM, Jieyue Li wrote:
> Dear All,
>
> I want to have the cumulative incidence curves for 'mstate' data using
> Survival package in R. But I got some problems:
> I. Problem 1:
> 1. If I only use intercept without any covariates, I can have 'right'
> cumulative incidence curves (2 for 2 competing risks):
> library(Survival)

That shouldn't work;)

> fitCI <- survfit(Surv(stop, status*as.numeric(event), type="mstate") ~
> 1,data=mgus1, subset=(start==0))
> plot(fitCI)
> 2. If I include one variate ('sex'), I get 4 curves (attached; I guess
> because there are two levels in 'sex' and 2 competing risks):
> fitCI <- survfit(Surv(stop, status*as.numeric(event), type="mstate")
> ~sex,data=mgus1, subset=(start==0))
> plot(fitCI)
> However, I want to just have 2 cumulative incidence curves estimated from
> several covariates (such as 'sex', 'age', 'alb', etc. in mgus1). Could you
> please help me to do that? Thank you very much!

I suggest that you check the Task Views, under 'Survival' and 
'Multistate Models', for instance the 'cmprsk' and 'timereg' packages.

> II. Problem 2:
> I try using an example from sourcecode.pdf:
> fit <- survfit(Surv(time, status, type=?mstate?) ~ sex, data=mine)
> but where can I have the 'mine' data? Thank you!

Where do you find 'sourcecode.pdf'?

G?ran Brostr?m

>
> Best,
>
> Jieyue
>


From Berwin.Turlach at gmail.com  Tue Dec 31 11:14:40 2013
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Tue, 31 Dec 2013 18:14:40 +0800
Subject: [R] Where did lost variables go
In-Reply-To: <52C2211D.5050606@indiana.edu>
References: <52C2211D.5050606@indiana.edu>
Message-ID: <20131231181440.7c27d2eb@bossiaea>

G'day David,

On Mon, 30 Dec 2013 20:42:53 -0500
David Parkhurst <parkhurs at indiana.edu> wrote:

Some wild guesses in the absence of a reproducible example.

> I have several variables in a data frame that aren't listed by ls() 
> after I attach that data frame. 

ls() list the objects in the global environment.  If you attach a data
frame it is attached to the search path, typically after the global
environment.  

Type 'search()' to see your search path.

ls() list the global environment, the first entry in the list and
called ".GlobalEnv".  Your data frame should be listed as an object in
that environment.  

Assuming the name of your data frame is 'foo', then there should be the
name 'foo' somewhere in the list of names returned by 'search()'.
Assuming 'foo' is listed in the second position, then 'ls(2)' should
list all the objects found at that location of the search path, i.e.
all the variables in your data frame.

> Where did they go, 

See above.

> and how can I stop the hidden ones from masking the local ones?

Do you mean with "local ones" those in the global environment and by
"hidden ones" those that you couldn't find?  I.e. is there an object
"bar" listed by 'ls()' but also an object "bar" listed by 'ls(2)' (i.e.
your data frame 'foo' contained a variable with name 'bar')?  Then it is
the other way round, the local ones are hiding the hidden ones.  

For that reason attaching data frames has its dangers.  It allows to
easily access the variables in the data frame, but any changes to a
variable creates a local copy.  Thus, any change *will* not propagate
back to the data frame!  

Hopefully the commands below will clarify further.

Cheers,

	Berwin


R> foo <- data.frame(bar=rnorm(2), fubar=runif(2))
R> ls()
[1] "foo"
R> attach(foo)
R> search()
 [1] ".GlobalEnv"        "foo"               "package:stats"    
 [4] "package:graphics"  "package:grDevices" "package:utils"    
 [7] "package:datasets"  "package:methods"   "Autoloads"        
[10] "package:base"     
R> ls(2)
[1] "bar"   "fubar"
R> bar
[1] -0.07741633  1.05804653
R> fubar
[1] 0.08516929 0.82718383
R> bar <- "what now"
R> ls()
[1] "bar" "foo"
R> bar
[1] "what now"
R> ls(2)
[1] "bar"   "fubar"
R> get("bar", pos=2)
[1] -0.07741633  1.05804653
R> foo
          bar      fubar
1 -0.07741633 0.08516929
2  1.05804653 0.82718383
R> detach(2)
R> bar
[1] "what now"
R> fubar
Error: object 'fubar' not found
R> foo
          bar      fubar
1 -0.07741633 0.08516929
2  1.05804653 0.82718383
R> attach(foo)
The following object is masked _by_ .GlobalEnv:

    bar
R> bar
[1] "what now"
R> fubar
[1] 0.08516929 0.82718383
R> detach(2)
R> bar
[1] "what now"
R> fubar
Error: object 'fubar' not found
R> foo
          bar      fubar
1 -0.07741633 0.08516929
2  1.05804653 0.82718383


From jvadams at usgs.gov  Tue Dec 31 12:50:50 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 31 Dec 2013 05:50:50 -0600
Subject: [R] howto join matrices produced by rcorr()
In-Reply-To: <52C19CB9.2000402@gmx.net>
References: <52C19CB9.2000402@gmx.net>
Message-ID: <CAN5YmCEEpy43G-G9bgJZs1TZTOchAf-XjdGrhkAK=SFmcCqk9A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131231/3cb1ec50/attachment.pl>

From lordgeoffrey at optusnet.com.au  Tue Dec 31 14:07:30 2013
From: lordgeoffrey at optusnet.com.au (Geoffrey)
Date: Tue, 31 Dec 2013 23:07:30 +1000
Subject: [R] aes and parameter evaluation problems
In-Reply-To: <9597a812-21c8-40d5-b546-18f7c1f815e8@email.android.com>
References: <52C213FD.5090506@optusnet.com.au>	<1388460540.79355.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<9597a812-21c8-40d5-b546-18f7c1f815e8@email.android.com>
Message-ID: <52C2C192.8010008@optusnet.com.au>

Thanks A.K. and Jeff, both answers helped me.
(and of course gave me more homework!)

On 31/12/13 16:04, Jeff Newmiller wrote:
> A.K. answered your question 1, but since you did say as question 2 that you wanted it done right...
>
> library(reshape2)
> ex3 <- function() {
>    d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
>    dl <- melt( d, id.vars="x" )
>    ggplot(dl,aes(x=x,y=value,color=variable))+
>      geom_line()
> }
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> arun <smartpink111 at yahoo.com> wrote:
>>
>> Hi,
>> Try:
>>
>> ex2 <- function() {
>>    d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
>>    g <- ggplot(d, aes(x))
>>      for (n in c("a","b","c")) {
>>      g <- g + geom_line(aes_string(y=n,colour=n))
>>    }
>>   return(g)
>> }
>>
>> A.K.
>>
>>
>> On Monday, December 30, 2013 7:49 PM, Geoffrey
>> <lordgeoffrey at optusnet.com.au> wrote:
>> I am trying add geom_line's using a loop but the nature of unevaluated
>> parameters is causing me problems.
>>
>> This code works:
>> ex <- function() {
>>     d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
>>     g <- ggplot(d, aes(x))
>>     g <- g +
>>       geom_line(aes(y=a,colour=a)) +
>>       geom_line(aes(y=b,colour=b)) +
>>       geom_line(aes(y=c,colour=c))
>>     return(g)
>> }
>>
>> This code (not surprisingly) fails:
>> ex2 <- function() {
>>     d <- data.frame(x=1:5,a=1:5,b=2:6,c=3:7)
>>     g <- ggplot(d, aes(x))
>>     for (n in c("a","b","c")) {
>>       g <- g + geom_line(aes(y=n,colour=n))
>>     }
>>     return(g)
>> }
>>
>> I believe i want something like the failing code, but done right.
>>
>> I have two problems (at least in this code):
>> #1 how do handle the parameter evaluation
>> #2 is this the right thing to be even doing with geom_line() & aes() ?
>>
>> Geoff.
>


From h.wickham at gmail.com  Tue Dec 31 16:20:42 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 31 Dec 2013 09:20:42 -0600
Subject: [R] Package dependencies in building R packages
In-Reply-To: <CAAyVsXKCN1Zn4gbG=QkD759kaDadPbgp+9e3W6nPvOLVwAsU=w@mail.gmail.com>
References: <CAAyVsXJ_wPdugKUXOEbUFT_dXSv9kWboR-dz4V67tSMP+FxCfQ@mail.gmail.com>
	<52C1C0A8.4080301@gmail.com>
	<CAAyVsXKCN1Zn4gbG=QkD759kaDadPbgp+9e3W6nPvOLVwAsU=w@mail.gmail.com>
Message-ID: <CABdHhvEXz7emKwh5CevO_U10+V5EN_+N4Y=YWSzam96oL0Eg3A@mail.gmail.com>

> Thanks for your kind response Duncan. To be more specific, I'm using the
> function mvrnorm from MASS. The issue is that MASS depends on survival and
> I have a function in my package named tt() which conflicts with a function
> in survival of the same name. I can think of 2 alternatives solutions to my
> problem, but I'm to an expert:
>
> 1) Copy mvrnorm into my package, which I thought was not a good idea
> 2) Rename my tt() function to something else in my package, but this is
> painful as I have it all over the place in other functions.

3) Use namespaces: in your DESCRIPTION add `Import: MASS`, and in your
NAMESPACE add `importFrom(MASS,mvrnorm)`

Then you can access mvrnorm from your package, but it won't be made
available to the user who loads your package, and it won't pull in any
other functions from MASS or survival either.

Hadley


-- 
http://had.co.nz/


From friendly at yorku.ca  Tue Dec 31 16:25:08 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 31 Dec 2013 10:25:08 -0500
Subject: [R] format a matrix as fractions?
Message-ID: <52C2E1D4.1070604@yorku.ca>

Is there some way to format a matrix of fractions as fractions?  I think 
I've seen this somewhere,
but search on Rseek came up empty.

Example:

 > outer(1/seq(1:3), 1/seq(1:3))
           [,1]      [,2]      [,3]
[1,] 1.0000000 0.5000000 0.3333333
[2,] 0.5000000 0.2500000 0.1666667
[3,] 0.3333333 0.1666667 0.1111111
 >

should print as

       1     1/2     1/3
     1/2    1/4     1/6
     1/3    1/6     1/9

TIA
-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From smartpink111 at yahoo.com  Tue Dec 31 16:32:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 31 Dec 2013 07:32:18 -0800 (PST)
Subject: [R] format a matrix as fractions?
In-Reply-To: <52C2E1D4.1070604@yorku.ca>
References: <52C2E1D4.1070604@yorku.ca>
Message-ID: <1388503938.83818.YahooMailNeo@web142601.mail.bf1.yahoo.com>



library(MASS)
?fractions(outer(1/seq(1:3), 1/seq(1:3)))
#???? [,1] [,2] [,3]
#[1,]?? 1? 1/2? 1/3 
#[2,] 1/2? 1/4? 1/6 
#[3,] 1/3? 1/6? 1/9 
A.K.


On Tuesday, December 31, 2013 10:27 AM, Michael Friendly <friendly at yorku.ca> wrote:
Is there some way to format a matrix of fractions as fractions?? I think 
I've seen this somewhere,
but search on Rseek came up empty.

Example:

> outer(1/seq(1:3), 1/seq(1:3))
? ? ? ? ?  [,1]? ? ? [,2]? ? ? [,3]
[1,] 1.0000000 0.5000000 0.3333333
[2,] 0.5000000 0.2500000 0.1666667
[3,] 0.3333333 0.1666667 0.1111111
>

should print as

? ? ?  1? ?  1/2? ?  1/3
? ?  1/2? ? 1/4? ?  1/6
? ?  1/3? ? 1/6? ?  1/9

TIA
-Michael

-- 
Michael Friendly? ?  Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University? ? ? Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street? ? Web:? http://www.datavis.ca
Toronto, ONT? M3J 1P3 CANADA

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From gunter.berton at gene.com  Tue Dec 31 16:35:32 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 31 Dec 2013 07:35:32 -0800
Subject: [R] format a matrix as fractions?
In-Reply-To: <52C2E1D4.1070604@yorku.ca>
References: <52C2E1D4.1070604@yorku.ca>
Message-ID: <CACk-te2E8CUa983fTudFvAg3iPdAKFmEQn3wa7+sg7uyrpsnyw@mail.gmail.com>

I find that google is usually a better search engine for R topics

Google on "R fractions".

(I got, e.g.
http://stackoverflow.com/questions/5046026/print-number-as-reduced-fraction-in-r
)

-- Cheers,

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Tue, Dec 31, 2013 at 7:25 AM, Michael Friendly <friendly at yorku.ca> wrote:
> Is there some way to format a matrix of fractions as fractions?  I think
> I've seen this somewhere,
> but search on Rseek came up empty.
>
> Example:
>
>> outer(1/seq(1:3), 1/seq(1:3))
>           [,1]      [,2]      [,3]
> [1,] 1.0000000 0.5000000 0.3333333
> [2,] 0.5000000 0.2500000 0.1666667
> [3,] 0.3333333 0.1666667 0.1111111
>>
>
> should print as
>
>       1     1/2     1/3
>     1/2    1/4     1/6
>     1/3    1/6     1/9
>
> TIA
> -Michael
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Dec 31 16:50:01 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 31 Dec 2013 07:50:01 -0800
Subject: [R] Where did lost variables go
In-Reply-To: <20131231181440.7c27d2eb@bossiaea>
References: <52C2211D.5050606@indiana.edu> <20131231181440.7c27d2eb@bossiaea>
Message-ID: <CACk-te3qXFCcV2Bdq0kJqxOkSy5HVWUrm1Toosek4tzK1Bb8Nw@mail.gmail.com>

Gents:

I would add that:

1) attach() should probably no longer be used in R, for all the
reasons (and more) cited,

2)  The preferred alternative these days is to use lists, including
data frames, as containers and make liberal use of the  ?with and
?within  functions. Environments can also be useful, but are more
complicated as their semantics differ. S4 classes and objects are
probably also relevant.

Comments, criticisms, links, additions, and subtractions welcome, as
this issue comes up regularly here and it would be nice to have
consensus wisdom to refer to.

Cheers,


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
H. Gilbert Welch




On Tue, Dec 31, 2013 at 2:14 AM, Berwin A Turlach
<Berwin.Turlach at gmail.com> wrote:
> G'day David,
>
> On Mon, 30 Dec 2013 20:42:53 -0500
> David Parkhurst <parkhurs at indiana.edu> wrote:
>
> Some wild guesses in the absence of a reproducible example.
>
>> I have several variables in a data frame that aren't listed by ls()
>> after I attach that data frame.
>
> ls() list the objects in the global environment.  If you attach a data
> frame it is attached to the search path, typically after the global
> environment.
>
> Type 'search()' to see your search path.
>
> ls() list the global environment, the first entry in the list and
> called ".GlobalEnv".  Your data frame should be listed as an object in
> that environment.
>
> Assuming the name of your data frame is 'foo', then there should be the
> name 'foo' somewhere in the list of names returned by 'search()'.
> Assuming 'foo' is listed in the second position, then 'ls(2)' should
> list all the objects found at that location of the search path, i.e.
> all the variables in your data frame.
>
>> Where did they go,
>
> See above.
>
>> and how can I stop the hidden ones from masking the local ones?
>
> Do you mean with "local ones" those in the global environment and by
> "hidden ones" those that you couldn't find?  I.e. is there an object
> "bar" listed by 'ls()' but also an object "bar" listed by 'ls(2)' (i.e.
> your data frame 'foo' contained a variable with name 'bar')?  Then it is
> the other way round, the local ones are hiding the hidden ones.
>
> For that reason attaching data frames has its dangers.  It allows to
> easily access the variables in the data frame, but any changes to a
> variable creates a local copy.  Thus, any change *will* not propagate
> back to the data frame!
>
> Hopefully the commands below will clarify further.
>
> Cheers,
>
>         Berwin
>
>
> R> foo <- data.frame(bar=rnorm(2), fubar=runif(2))
> R> ls()
> [1] "foo"
> R> attach(foo)
> R> search()
>  [1] ".GlobalEnv"        "foo"               "package:stats"
>  [4] "package:graphics"  "package:grDevices" "package:utils"
>  [7] "package:datasets"  "package:methods"   "Autoloads"
> [10] "package:base"
> R> ls(2)
> [1] "bar"   "fubar"
> R> bar
> [1] -0.07741633  1.05804653
> R> fubar
> [1] 0.08516929 0.82718383
> R> bar <- "what now"
> R> ls()
> [1] "bar" "foo"
> R> bar
> [1] "what now"
> R> ls(2)
> [1] "bar"   "fubar"
> R> get("bar", pos=2)
> [1] -0.07741633  1.05804653
> R> foo
>           bar      fubar
> 1 -0.07741633 0.08516929
> 2  1.05804653 0.82718383
> R> detach(2)
> R> bar
> [1] "what now"
> R> fubar
> Error: object 'fubar' not found
> R> foo
>           bar      fubar
> 1 -0.07741633 0.08516929
> 2  1.05804653 0.82718383
> R> attach(foo)
> The following object is masked _by_ .GlobalEnv:
>
>     bar
> R> bar
> [1] "what now"
> R> fubar
> [1] 0.08516929 0.82718383
> R> detach(2)
> R> bar
> [1] "what now"
> R> fubar
> Error: object 'fubar' not found
> R> foo
>           bar      fubar
> 1 -0.07741633 0.08516929
> 2  1.05804653 0.82718383
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From vd4mmind at gmail.com  Tue Dec 31 11:58:37 2013
From: vd4mmind at gmail.com (Vivek Das)
Date: Tue, 31 Dec 2013 11:58:37 +0100
Subject: [R] Fwd: Problem with heatmap
In-Reply-To: <CAFkF=gF_=1rnprUo12E3ZSb2r5OWXhQ+97m8HCDnU=pexc4odQ@mail.gmail.com>
References: <CAFkF=gF_=1rnprUo12E3ZSb2r5OWXhQ+97m8HCDnU=pexc4odQ@mail.gmail.com>
Message-ID: <CAFkF=gGvcuTco2nL82bURUeVJH6vTcKry0GPeSVGYWbHzXfdhQ@mail.gmail.com>

Dear R users,



 I have a  problem and need some help with my analysis. I am trying to
generate heatmap with a list of genes and its expression values on few
samples. I am unable to get a proper heatmap. Be it the clustering or the
genes or the position of the color panel. Can you guide me how to change
it. I have a text file of which I want to generate a heatmap. It is made of
first column genes and the next columns are the samples with expression
values. Below is the code chunk am using to generate it. But am not being
able to figure out how to modify it for a better visualization.

library(RColorBrewer)
library(gplots)

#for my data sets

data<-read.table("/Desktop/my_
file.txt",sep="\t")

#let say you want to take from the 2 to 13 column

data2<-as.matrix(data[,2:13])

data3<-data2[-1,]

samples<-data2[1,]

genes<-data[2:length(data2[,1]),1]

vett<-as.numeric(data3)

data4<-matrix(vett,length(genes),length(samples),
dimnames=list(paste(genes),paste(samples)))


#cluster of columns (samples)

dc<-dist(t(data4), method = "euclidean", diag = FALSE, upper = FALSE, p = 2)

hc<-hclust(dc, method = "complete", members=NULL)

plot(hc)

## function for clustering genes using Spearman Rank Cor
mydist<-function(d)
{
cormia<-cor(d,method="spearman")
cormia[which(is.na(cormia))]<-1
dismia<-as.dist(1 - cormia)
dismia
}

#cluster of rows (genes) mydist is user defined function on Spearmanr Rank
Co

dr<-mydist(data4)#, method = "euclidean", diag = FALSE, upper = FALSE, p =
2)

hr<-hclust(dr, method = "complete", members=NULL)

plot(hr)



color <- colorpanel(100,low="blue",mid="white",high="red")

## This below heatmap.2 code does not work
heatmap.2(data4,Rowv=as.dendrogram(hr),Colv=as.dendrogram(hc),
col=color,trace='none',density.info="none",scale="row",labRow=NULL,lmat=rbind(
c(0, 3), c(2,1), c(0,4) ), lhei=c(1.5, 4, 2 ))

### Error in image.default(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5
+  :
  dimensions of z are not length(x)(-1) times length(y)(-1)

### for normal heatmap it is working
heatmap.2(data4,
col=color,trace='none',density.info="none",scale="row",labRow=NULL,lmat=rbind(
c(0, 3), c(2,1), c(0,4) ), lhei=c(1.5, 4, 2 ))

I am attaching the heatmap I have generated. But it is not properly visible
with the color key overlapping the labels of the sample. How can I work it
out with the code to change it. Since I have a lot of genes so the genes
are not visible but am not bothered about that much as the genes are order
according to fold change. But to understand how they are arranged am not
being able to create a proper heatmap. Can you suggest how to modify the
code to create one or if you have better script to generate a heatmap. I am
attaching the matrix and the sample heatmap I generated.
This list is a differentially expressed gene list of 2 conditions where I
have 12 samples. I want to understand the genes that are more expressed in
one condition and less in other.

As you can see in the matrix the samples they fall under 2 conditions:
peripheries that give rise to tumor(PGRT) : Samples
132p1,183p2,141p1,183p3,118p,91p
peripheries donot give rise to tumor(PDGRT): Samples
132p2,132p3,183p1,141p2,141p3,141p4

So now how will I workout with this problem? 1700 genes is not much to see
on a heatmap though to trace a pattern, but still am unable to do it. The
problem with heatmap for me still remains. It would be helpful if you can
guide me with my code or if you have any separate code to generate a
heatmap then I will use it for mine as well. Am attaching the matrix and
the heatmap I have generated.

I would be grateful if someone has better way to deal with it or can give
me insight within this code.
----------------------------------------------------------

Vivek Das
-------------- next part --------------
gene	Sample_118p.0	Sample_132p1.0	Sample_132p2.0	Sample_132p3.0	Sample_141p1.0	Sample_141p2.0	Sample_141p3.0	Sample_141p4.0	Sample_183p1.0	Sample_183p2.0	Sample_183p3.0	Sample_91p.0
NELL1	0	0	0	0	0	0	0	0	0	0	0	34.2088
LHFPL3	0	0.0189922	0	0	0	0	0	0	0	0	0	30.613
SOX21	1.43788	2.88E-05	2.86E-05	2.88E-05	2.87E-05	2.88E-05	0	0	2.88E-05	0	0	1.68978
PI15	2.53668	0.00287597	0	0	0	0	0	0	0	0	0	0.00876938
RPH3A	0.019839	0	0	0	0.00855576	0	0	0	0	0	0.013924	5.10083
SNTG1	0.0447399	0	0	0	0	0	0	0	0	0	0	7.60465
RGS6	0.0306737	0	0	0	0	0	0	0	0	0	0	8.63965
CHI3L1	386.573	0.0916236	0.0178187	0.0130868	0	0	0	0	0.292996	0.354946	0.0401748	11.1622
RNF43	2.89545	0	0	0	0	0	0	0	0	0	0	0.0263277
KCNJ16	2.01754	0	0	0	0	0	0	0	0	0	0	1.36823
OLIG2	0	0	0	0	0	0	0	0	0	0	0.0255351	6.60984
SEZ6	1.21939	0	0	0	0	0	0	0	0	0	0	2.00598
KCNJ2	0.916406	6.84E-06	0	6.66E-06	6.86E-06	6.67E-06	6.70E-06	6.68E-06	6.79E-06	0	6.68E-06	0.723963
AQP4	1.37214	0	0	0	0	0	0	0	0	0	0	0.0116472
IRX1	3.32589	0	0	0	0	0	0	0	0	0	0	1.6135
GRIK3	2.29406	0.00416554	0	0.00418765	0	0	0	0	0	0	0	5.30744
RASEF	1.15306	0	0	0	0	0	0	0	0	0	0	0
SHISA6	0	0	0	0	0	0	0	0	0	0	0	1.24329
TTYH1	30.2738	0.0114026	0	0.034391	0	0	0	0	0	0.118316	0	22.1782
MAPK4	4.09548	0	0	0	0	0.00808843	0	0	0	0	0	3.44171
MCHR1	7.50156	0.00848787	0	0.00853292	0	0	0	0	0	0.0220167	0	7.89108
ENHO	4.72034	0.0216876	0	0	0	0	0	0	0	0	0	3.17315
KCNJ10	0.36303	0	0	0	0	0	0	0	0	0	0	1.20123
PDGFD	0.531824	0.00997022	0	0	0	0	0	0	0	0	0	1.38234
GAL3ST3	0.691746	0.00604414	0	0	0	0	0	0	0	0.0156895	0	1.61943
PPP1R1B	3.18598	0.0444525	0	0	0	0	0	0	0	0.153573	0	0
KLHDC8A	6.64322	0.00687967	0.00470843	0.00345806	0	0	0	0	0	0	0.0106158	0.566011
GFAP	1361.66	0.74086	0.375353	0.616988	0.0534502	0.0467365	0.0953553	0.0621709	0.883276	1.09974	0	0.517441
FREM2	1.9024	0.00388151	0.00531302	0.0097501	0	0.00694611	0	0	0	0	0	21.2366
KLHDC7A	1.07268	0	0	0	0	0	0	0	0	0	0	0.0118035
"HOXA6,HOXA7"	0.0686577	0	0	0	0	0	0	0	0	0	0	4.473
SLC47A2	11.6421	0	0	0.00927048	0	0	0	0	0	0	0	0
BBOX1	2.15766	0	0	0	0	0	0	0	0	0	0	1.23199
LOC153469	2.06082	0	0	0	0	0	0	0	0	0	0	0.144781
NOS2	0.0546356	0	0	0	0	0	0	0	0	0	0	1.49553
SLC35F1	6.44992	0.00916344	0	0.00812986	0.0174165	0.0129298	0.0111771	0	0	0.0236181	0	14.9084
QKI	5.07477	0	0	0	0.0143486	0.0162503	0	0	0	0	0	4.09285
RBFOX3	27.0739	0	0	0	0	0.0136107	0	0	0	0	0	0.386879
IRX2	1.39232	0	0	0	0	0	0	0	0	0.0465617	0	0.0547159
CA14	2.14835	0	0	0	0	0	0	0	0	0	0	0.4311
SELL	1.55413	0.00941196	0	0	0	0	0	0	0	0	0.0290469	0.0256518
EDNRB	9.36928	0	0.00630855	0	0.0155128	0.0164978	0.0199112	0.0123899	0	0	0	12.9144
ATF6	0.200876	0	0	0	0	0	0	0	0	0	0	0.905626
B4GALNT3	0.140587	0.00581639	0	0	0	0	0	0	0	0	0	0.771874
WNT7A	2.27177	0	0	0	0	0	0	0	0	0	0	0
SYT6	0	0	0	0	0	0	0	0	0	0	0	0.994612
PPP1R14C	9.92818	0.0281656	0	0.00943837	0	0	0	0.0252362	0	0.0243529	0	2.77592
HR	2.50457	0	0	0	0	0	0	0	0.0102832	0	0	0.0667301
C5orf38	2.98542	0	0	0	0	0	0	0	0	0	0	0.563691
NPY2R	0.652479	0	0	0	0	0	0	0	0	0.142555	0	0
OLIG1	0	0	0	0	0	0	0	0	0	0	0	2.33991
BMP8B	0.0985808	0	0	0.007513	0.0141729	0	0	0	0	0.0193851	0	6.20753
TP73	3.10166	0	0	0	0	0	0.0143642	0	0	0	0	0.0487383
OLIG1	0	0	0	0	0	0	0	0	0	0	0	1.8776
KLHL14	0.0101875	0	0	0	0	0	0	0	0	0	0	0.776855
CRB1	0.258118	0	0	0	0	0	0	0	0	0	0	0.307883
ASTN1	2.27514	0	0	0.0102701	0	0.0141813	0	0	0	0	0	8.02209
HOXD-AS2	0.265521	0	0	0	0	0	0	0	0	0	0	1.24044
MYBPC1	0.570017	0	0	0	0	0	0	0	0	0	0	0.0169311
NWD1	0.269303	0	0	0	0	0	0	0	0	0	0	0.00794099
PAX9	0.738803	0	0	0	0.016924	0	0	0	0	0	0.0275406	0
PLEKHA7	5.2167	0	0	0.00588189	0.011096	0.0146058	0	0	0	0	0	0.854198
MYO3A	0.37234	0	0	0	0	0	0	0	0	0	0	0
GRM7	0	0	0	0	0	0	0	0	0	0	0	1.0473
LHX2	4.93411	0.0120094	0	0.0120731	0	0	0	0	0	0	0	0.292921
COL2A1	0.0265085	0.0192426	0.00550134	0.00808092	0.00729857	0	0	0	0.0226554	0	0	10.8862
BLMH	1.65243	0.305242	0	0	0	0	0	0	0	0	0	0
MCF2L	0.0315436	0	0	0	0	0	0	0	0	0	0	1.53687
DOK7	1.91175	0	0	0	0	0.0174746	0	0	0	0	0	2.55697
CPNE4	8.62485	0	0	0.0127062	0	0.0420518	0	0	0	0	0	6.09208
MMP7	1.95746	0	0	0	0	0	0	0	0	0	0	0.0631153
HOXD3	0.0569491	0	0	0	0	0	0	0	0	0	0	0.348666
MDGA1	1.15911	0	0	0	0.00148012	0	0.00645373	0	0	0.0525304	0.033455	0.841269
THSD7A	0.0795182	0	0	0	0	0	0	0	0	0.00938194	0	0.115762
TRPM8	0.38889	0	0.0096963	0.00712137	0	0.0126767	0	0	0.0171629	0	0	7.50594
TRIL	1.5242	0	0.00530156	0	0	0	0	0	0.0109161	0	0	2.01882
SLC4A10	0.317637	0	0	0	0	0	0	0	0	0	0	0
SEMA6B	1.92243	0.017577	0	0.0261274	0.0311525	0.00554039	0	0	0	0.0426089	0	12.3409
SDC3	0.142677	0.0577701	0	0	0	0	0	0	0	0.173423	0	0
LPL	10.479	0.0212312	0.00726534	0.00533598	0.0201322	0.0189971	0	0.0570692	0	0.0137679	0.0327613	3.81826
GPR123	0.0102937	0	0	0	0	0	0	0	0	0	0	0.505738
ATP12A	0.412036	0	0	0	0	0	0	0	0	0	0	0.0326425
HOXD11	0.133022	0	0	0	0	0	0	0	0	0	0	0.345372
GPR37L1	0.495596	0	0	0	0	0	0	0	0	0	0	0.10175
MAL	1.2942	0	0	0	0	0	0	0	0	0	0.0857736	0.779094
CAMK2B	0.12751	0.00483297	0	0	0	0	0	0	0	0	0.0149158	0.291355
DNAH9	1.72732	0	0	0.0071617	0	0.00127473	0	0	0	0.00307969	0	1.74857
EFNA2	0.342065	0.0194488	0	0	0	0	0	0	0	0	0	0.474264
DSG2	5.66227	0.00344714	0.00471881	0.0103982	0	0.00616956	0.00839216	0	0	0	0.0106404	0.483474
SEMA6B	7.12494	0.015041	0.0140535	0.0232163	0	0.0821952	0.0164242	0	0	0	0.0316854	21.5831
DHH	0.354643	0	0	0	0	0	0	0	0	0	0	0.0633112
PROX1-AS1	0.301146	0	0	0	0	0	0	0	0	0	0	3.42437
C21orf62	0.241782	0	0	0	0	0.00894616	0	0	0	0	0	1.50522
UG0898H09	0.0422772	0	0.00376029	0.00276174	0	0	0	0	0	0	0	2.19392
PTPRZ1	23.1748	0.0909567	0.0869444	0.154408	0.0132838	0.226127	0.12356	0.0340785	0.0357329	0.0329811	0	92.4986
S100B	129.439	0.235294	0.82245	1.05723	0	0.256114	0.348705	0.164074	0	0.0527772	0.47311	534.624
ATPIF1	0.779537	0	0	0	0	0	0	0	0	0	0	0
CA2	9.84904	0	0	0.0129789	0	0.0462071	0	0	0	0	0	0.590292
TRIM9	5.91802	0.034394	0.0186144	0.0248838	0.0419191	0.0701892	0.0214989	0.0716096	0.0242341	0.0572851	0.0946416	29.6755
EPHA3	11.2586	0.0355852	0.0172797	0.0536604	0.0239412	0.0254781	0.0259915	0.0250472	0.0100316	0.120868	0.0329536	17.2667
"HOXA10,HOXA10-HOXA9,HOXA9"	0.0830617	0	0	0	0	1.40E-06	0	0	0	0	0	0.652721
LOC100133991	0.427245	0.0102281	0	0	0	0	0	0	0	0.0265307	0.0315662	0.21824
PRPH	0.73826	0	0	0	0	0	0	0	0	0	0	0
RTBDN	1.2906	0	0	0	0	0	0	0	0	0	0	0
RTDR1	0.710683	0	0	0	0	0	0	0	0	0	0	1.1047
HOXA5	0.114241	0	0	0	0	0	0	0	0	0	0	0.950354
ATP1B2	25.8753	0.102239	0.0493924	0.0967359	0.022811	0.0645745	0.0731952	0.0969943	0.220352	0.499196	0.222723	60.1468
CNR1	7.28713	0	0.0094949	0.0383668	0	0	0.00844174	0.00932271	0	0.0269973	0	5.76641
FABP7	203.037	0.114919	0.275279	0.617944	0	0.565547	0	0.174195	0.242919	0.223567	0	104.699
PDK4	0.023653	0	0	0	0.0102018	0	0	0	0	0.0697675	0.0166014	0.295148
GPR158	1.58396	0	0	0	0	0	0.00707989	0	0.00819763	0	0	0.350906
TRIM29	0.382119	0	0	0	0	0	0	0	0	0	0	0
ADCY8	0.0106067	0	0	0	0	0	0	0	0	0	0	0.367648
DPP6	0	0.00442672	0	0	0	0.0079221	0	0	0	0	0	1.61935
OR7E14P	2.30534	0	0	0.00996793	0	0	0	0	0	0	0	0.265422
PDGFD	0.681737	0	0	0	0	0	0	0	0	0	0	3.43976
CHST8	0	0.0194989	0	0.00980103	0	0	0	0	0	0	0	3.46001
TMEM179	1.11288	0	0	0	0	0	0	0	0	0	0	0.867923
ADCY2	2.07764	0.00617037	0	0.0408003	0.0117019	0.0551352	0	0	0	0.0320106	0	23.8535
TSPAN11	0	0	0	0.0034682	0	0.00582161	0	0	0	0	0	2.06116
FAM78B	0.687382	0	0	0.0047192	0	0.0168473	0	0	0	0	0	2.44474
MCF2L	0.0925683	0	0	0.0169432	0	0	0	0.0226512	0.0237504	0.0655752	0	4.91923
TACR1	16.0148	0	0.00562443	0.00413083	0	0.0735325	0	0	0	0.0106584	0	0
"FABP9,PMP2"	4.51271	0.0117502	0.0241284	0.0590735	0	0.0525785	0	0.0157931	0.0165596	0	0.0362687	24.2421
KANK4	0	0	0	0	0	0	0	0	0	0	0	0.340794
SLC26A9	0.205819	0	0	0	0	0	0	0	0	0	0	0.0129709
CYP26A1	0.497653	0	0	0	0	0	0	0	0	0	0	0
SLC9A4	0.210135	0	0	0	0	0	0	0	0	0	0	0.0437019
HOXD13	0	0	0	0	0	0	0	0	0	0	0	0.622089
C2CD4A	0.0360578	0	0	0	0	0	0	0	0	0	0	0.349451
NSUN7	0.219372	0	0	0	0	0	0	0	0	0	0	0.0667388
HOXD-AS1	0	0.00389627	0	0	0	0	0	0	0	0	0	0.250187
GJB3	0.505399	0	0	0	0	0	0	0	0	0	0	0
GRM3	0	0	0	0	0	0	0	0	0	0	0	0.310819
ATP10B	0.135432	0	0	0	0	0	0.013654	0	0	0	0	0.669596
CPNE5	0.828253	0.0238856	0.0125248	0	0	0	0.022273	0.0475705	0	0	0	4.10256
CLU	1.60434	0	0	0	0	0	0	0	0	0	0	0
ELN	45.7361	0.0236308	0.035459	0.103942	0	0.0536211	0.11603	0	0.0731764	0.0154533	0	0.47432
C11orf93	1.03055	0	0	0	0	0	0	0	0	0	0	0
CACNG4	29.2731	0	0.0259613	0.0190671	0.0119897	0.187822	0	0.0467327	0	0	0	6.64016
GSX2	0.866962	0	0	0	0	0	0	0	0	0	0	0
IGSF3	0.271771	0.0456839	0.00919544	0.0324184	0.0101923	0.0144266	0	0	0.0302954	0.0418232	0.0331732	13.278
CHRM3	2.40087	0.0022503	0	0.0280568	0.00426775	0.00402711	0	0	0	0	0	3.17646
LEFTY2	0.428279	0	0	0	0	0	0	0	0	0	0	0
PPPDE1	0.271064	0	0	0	0	0	0	0	0	0	0	0
SLC35F3	0.292588	0	0	0	0	0	0	0	0	0	0	0.0249032
TTLL6	0.24176	0.00805413	0	0	0	0	0	0	0	0	0	0
HOXA4	0	0	0	0	0	0	0	0	0	0	0	0.754844
MSI1	9.16627	0.0282539	0.0103529	0.0280805	0.0530049	0.14783	0	0	0.0213174	0.146575	0	9.52568
PDE6B	0.862872	0	0	0	0	0.0130745	0	0	0	0	0	0.891298
CRB2	0.767481	0	0	0.00438763	0	0	0	0	0	0	0	0.0265881
ALDH3A1	47.5815	0.0578087	0	0.101702	0.0274079	0.344293	0	0	0.0407321	0	0	0
ARHGEF4	22.8848	0.0432127	0.0709283	0.0061848	0.126348	0.23805	0.0180187	0.0397958	0.0417269	0.057561	0.0228452	0.0935945
SEMA6A	2.69541	0.00442572	0.00605806	0.0177979	0.0335753	0.0316822	0	0	0.0124742	0	0	6.08831
ITGB4	36.371	0.0924055	0.102252	0.0689036	0.0400264	0.0800888	0.025687	0.0283309	0.16559	0.119862	0.0488516	0.671436
INSRR	0.0103615	0	0	0	0	0	0	0	0	0	0	0.25859
PREX2	0.0588691	0.0038133	0	0	0	0	0	0	0	0	0	0.127861
LIPG	14.8452	0.00506131	0.0261462	0.0203531	0.0191976	0.108692	0	0	0	0	0	0.41656
FAM5B	1.01303	0	0	0.00662587	0	0.0117947	0	0	0	0	0	1.50148
EN1	5.06022	0.0814734	0.0278791	0.0204752	0.072161	0	0	0	0.057406	0.0528328	0.12572	6.65432
IGSF11	9.24965	0	0	0.0210822	0	0.0187641	0	0	0	0	0	12.4493
MLC1	17.4839	0.0554814	0.00690348	0.116175	0.0287167	0.331547	0.0183225	0	0	0.0195251	0	40.3871
AQP7P3	0	0	0	0	0	0	0	0	0	0	0	3.31838
MT3	170.269	0.458589	0.139209	0.464677	0.192867	1.96034	0.123773	0.273368	0	0	0.62771	163.894
FXYD3	0	0	0	0	0	0	0	0	0	0.0313114	0	0.865367
FOXA3	0.371536	0	0	0	0	0	0	0	0	0	0	0.0643905
BMP7	3.38077	0.00491298	0	0.00987811	0	0.0791277	0	0.026412	0	0	0	8.28148
IL18	6.35866	0	0	0	0	0.0364082	0	0.0539887	0	0.158329	0	0.0620169
CTNND2	14.5826	0.0094165	0.0386681	0.0426086	0	0.0985381	0.0114605	0.0253115	0.0207076	0	0	6.76009
LIMCH1	2.69635	0.00660224	0	0.00664204	0	0.0236535	0.00804119	0.0177616	0	0	0	2.18155
MGAT4A	0.318712	0.00919046	0.00338494	0	0.00156324	0	0	0	0	0.0119195	0	0.31037
C1orf130	0.185613	0	0	0	0	0	0	0	0	0	0	0
LOC150568	0.127683	0	0	0	0	0	0	0	0	0	0	0.575342
ITGA9	0.0275288	0	0	0	0.00791548	0	0	0	0	0.0974405	0	0.0508909
GATM	18.4592	0	0.025245	0.0649947	0	0.105057	0	0.0370579	0	0	0	4.61713
RBM47	0.920951	0.00837757	0	0.00420853	0	0.00749543	0	0	0	0.0217373	0	0.357564
SLN	21.1422	0.108868	0.0496728	0.109446	0	0	0	0	0	0.0941306	0	0.110616
NTRK1	0.052466	0.00795347	0	0.00799533	0.0150846	0.0284702	0.0387256	0.0213812	0.0448397	0.0619022	0	12.0771
SH3GL2	4.23055	0	0.0216582	0	0.0150036	0.0266945	0	0	0	0.0205213	0	0.181877
HUNK	0.160997	0	0	0.00262926	0	0.00468032	0	0.00703009	0	0.0474881	0.0322857	1.31539
GAS7	1.90889	0.110893	0.0228539	0.0260915	0	0.00426806	0.00580556	0.0256454	0.0336125	0.0734414	0.0147219	10.033
SYT12	1.36297	0	0	0.00571746	0	0	0	0	0.0160298	0	0	0.537442
CRISPLD1	4.64889	0.00911786	0	0.0274988	0	0.0244752	0	0	0	0.0118254	0	1.44572
HNF4G	1.01292	0	0	0.0296546	0	0	0	0	0	0	0	0.117592
CA9	2.06418	0.032793	0	0	0.0283925	0.0842903	0	0	0	0.0388339	0	6.42535
FOXD3	0.0290065	0	0	0	0	0	0	0	0	0	0	0.245403
MDFI	0.130645	0.0653056	0.062526	0.049239	0	0.0292165	0.0397404	0	0.171658	0.7712	0.302315	32.2678
NDRG2	10.0654	0.0526321	0	0.0317475	0.0401748	0.0927831	0	0	0.0895581	0.136525	0	7.26687
ANKFN1	0.298164	0	0	0	0	0	0	0	0	0	0	0
PITX2	0.273197	0	0	0	0	0	0	0	0	0	0	0
LOC441204	0.0286993	0	0	0	0	0	0	0	0	0	0	1.5995
HEPN1	0.332771	0	0	0	0	0	0	0	0	0	0	0
ZDHHC8P1	1.38065	0	0	0	0	0.0177893	0	0	0	0	0	0.223134
RGMA	9.84521	0.0329564	0.0484002	0.0533208	0.0167646	0.034011	0	0	0.0185759	0	0	3.30925
RNF165	0.0244353	0.00404339	0	0	0.00766823	0.00976602	0	0	0	0	0	0.974323
B3GAT1	0.823427	0	0	0.0187371	0	0	0	0	0	0	0	2.21604
CFI	17.0957	0.0526019	0.0266491	0.146793	0.0228778	0.0522607	0	0	0.0679994	0.109157	0	14.6267
MYO16	0.0267304	0	0	0	0.00576449	0	0	0	0	0	0	0.0858372
PRIMA1	0.013386	0	0	0	0	0	0	0	0	0	0	0.241258
CLC	1.4732	0	0	0	0	0	0	0	0	0	0	0
FOXI1	0.298284	0	0	0	0	0	0	0	0	0	0	0
HEPACAM	0.791523	0	0	0	0	0.010082	0	0	0	0	0	0.120226
UNC5D	0.378761	0	0	0.00266455	0	0	0	0	0	0	0	0.0484746
PROM1	0.131604	0	0	0	0	0.00921045	0	0	0	0	0	0.881972
GAP43	179.184	0.250952	0.274803	1.23619	0.237961	0.561361	0.0916276	0.371005	0.778017	0.0976417	0.232342	117.723
CHL1	0.0232328	0.00264184	0	0.00265586	0	0	0.00643067	0	0	0	0	0.899218
CGNL1	2.50434	3.86E-07	4.10E-07	0.0361363	0	3.83E-07	3.64E-07	0	0	0	3.97E-07	2.65485
DACH1	1.41948	0	0	0.00523958	0	0.0151888	0	0	0	0	0	0.0317737
RIMKLA	0.0676949	0	0	0.00189299	0.00686998	0	0.00458358	0	0	0	0	0.564531
SPARCL1	15.565	0.0609196	0.0311603	0.179601	0	0.110825	0	0	0	0.0393661	0	0.910626
HCRTR1	0.322912	0	0	0	0	0	0	0	0	0	0	0
RGR	0.23095	0	0	0	0	0	0	0	0	0	0	0.320207
PAX3	0.181053	0	0	0	0	0	0	0	0	0	0	0.0642607
TMSB4Y	0.226911	0	0	0	0.0266681	0	0	0	0	0	0	0.196629
FLRT3	2.23679	0.0103718	0.0141971	0.0573487	0.01967	0	0	0.0139397	0.0146162	0	0.0160046	9.2091
RNF175	0	0	0	0	0	0.0686517	0	0	0	0	0	6.26998
CDH4	11.1846	0.026805	0.0210004	0.0269472	0.00581904	0.219645	0	0.0320228	0.0251825	0	0	12.5958
GPRC5B	4.64439	0.0369828	0.0350705	0.052127	0.00998505	0.0225257	0	0	0.0174113	0.0173231	0	8.34624
LSAMP	30.681	0.200654	0	0.0194915	0.0404891	0.717467	0.0684002	0.0571925	0.00607169	0	0.0199453	43.6716
LRP1B	1.31814	0.0171515	0	0.00577793	0.0162572	0.0153405	0.002798	0.0123592	0.0120894	0.0119277	0.0132308	2.84056
B4GALT6	0.387037	0.0513772	0	0.00469771	0.00886255	0.0334626	0	0.0188462	0.00658852	0.0424416	0.0852444	4.17995
SLAIN1	16.7197	0.0213769	0	0.0449628	0.0202703	0.299017	0	0.0287305	0	0	0.0276054	7.89487
WSCD1	5.1107	0.04349	0.0228958	0.0269051	0.0126888	0.0478936	0.0244293	0.00899233	0.0188574	0.0867758	0.0412973	6.38235
NCAM1	2.18215	0.0322701	0	0.0408919	0.0119777	0.296265	0.0170687	0.0169768	0	0	0.0216408	21.6956
CHI3L2	0.360905	0	0	0	0	0	0	0	0	0	0	0.0932025
DDX25	0.153788	0	0	0	0	0	0	0	0	0	0	0.248759
RLBP1	0.214378	0	0	0	0	0	0	0	0	0	0	0.193173
CDH7	0	0	0	0	0	0	0	0	0	0	0	0.187244
CYP4F11	0.194244	0	0	0	0	0	0	0	0	0	0	0
AGXT2L1	0.276935	0	0	0	0	0	0	0	0	0	0	0.0319955
STMN2	0	0	0	0	0	0	0	0	0	0	0	0.36981
STMN4	0.0397704	0	0	0	0	0	0	0	0	0	0	0.62323
LOC100507194	0.268457	0	0	0	0	0	0	0	0	0	0	0.237815
LONRF2	2.00547	0.013205	0.00749696	0.0165863	0.00312891	0.00295249	0.00401598	0.0133045	0.00465	0	0.0152752	1.7047
VSNL1	80.5297	0.0848949	0.538111	0.315967	0.0951441	0.61176	0	0.133816	0.0295028	0	0	1.05455
NR2E1	2.3831	0	0	0	0	0.0458264	0	0.0172082	0	0	0	1.48293
TRPM3	0.814085	0	0	0.00369492	0	0	0	0	0	0	0	1.27553
TTBK1	0.183717	0.00280677	0.00384218	0	0	0	0	0	0.00791195	0.00728305	0.00866134	0.844457
NOVA2	0.626518	0	0	0.00511558	0	0.0136597	0	0	0	0	0	1.70138
SOX2-OT	53.1158	0.0878094	0.102577	0.222904	0.0130499	0.753877	0.0167496	0.365798	0.0387879	0.0698309	0	40.1337
FAM84A	2.65456	0	0	0	0	0.0617836	0	0	0	0	0	1.33194
KCNIP1	18.9785	0.0908509	0.0198894	0.157034	0.116083	1.07566	0	0.0781156	0	0	0	87.89
LINGO3	0	0	0	0	0	0.0175111	0	0	0	0	0	1.08022
SLC9A2	0.441645	0	0	0.00360626	0	0	0	0	0	0	0	0.0218689
C4orf19	0.118274	0.00548081	0	0	0	0	0	0	0	0	0	0.0200282
MIR3659	0	0	0	0	0	0	0	0	0	0.0872127	0	1.12735
MPZL2	0.140165	0	0	0	0	0	0	0	0	0	0	0.0987786
HOXC8	0.198747	0	0	0	0	0	0	0	0	0	0	0.0551115
OVOL2	0.368775	0	0	0	0	0	0	0	0	0	0	0
UPK3A	0.646458	0	0	0	0	0	0	0	0	0	0	0
LINC00488	0.196295	0	0	0	0	0	0	0	0	0	0	0.0247416
SLC44A5	0.676227	0.0155967	0.00850448	0.0156795	0	0.106216	0	0	0	0	0.073327	6.40007
HAP1	6.21707	0.0151341	0.0292017	0.0375323	0	0	0.0129822	0	0.0150318	0.0415032	0.0329195	0.162573
GABBR2	4.88086	0.0313495	0.0188418	0.0567791	0.00822061	0.0310302	0.0335606	0.0185303	0	0	0.0425503	3.19299
LGALS7B	1.71899	0	0	0	0	0	0	0	0	0	0	0
ST8SIA5	1.0454	0.0190593	0.0201446	0.0443855	0.0313839	0.433528	0	0.0643486	0	0	0	32.093
CNTFR	0.577801	0	0	0.0117493	0	0	0	0	0	0	0	1.01519
"HOXD10,HOXD11,HOXD9"	2.5302	0	0.055109	0.0484246	0	0	0	0	0	0	0	4.19548
TF	0.0182234	0.0248671	0.0226921	0.00833296	0	0	0	0	0	0	0.134733	2.99618
SOX10	0	0	0	0.00428112	0	0	0.010356	0	0	0	0	1.23198
FOLR1	1.96117	0	0	0	0	0.0458619	0	0	0	0	0	0.846926
NOTUM	0.226368	0	0	0	0	0	0	0	0	0	0	0
EYA2	0.104537	0.0158398	0	0	0	0	0	0	0	0	0	0.0724613
PAQR9	0	0	0	0	0	0	0	0	0	0	0	0.332433
CHN2	0.0511656	0.0071595	0	0	0	0	0	0	0	0	0	0.106409
GPR126	0.397725	0	0	0	0	0.00808074	0	0	0	0	0	0.109998
ADORA1	10.0371	0.0948303	0.100651	0.0476412	0.0539826	0.0789532	0	0	0.0267419	0.0246116	0.0292821	7.64966
POU3F2	6.49202	0.0193512	0.0132554	0.0291884	0.0104736	0.0952885	0	0.0148449	0.0272933	0.00716252	0	5.47422
OGDHL	5.63906	0.049348	0.0242757	0.071317	0.0224226	0.0634753	0.0431695	0.0158904	0.0166615	0	0.0182442	9.98114
CHDH	1.46221	0.00559244	0	0.00562213	0	0.0100081	0	0.0150328	0	0	0	0.102284
PROX1	0.408339	0.00244354	0.00668963	0.00491313	0	0.0043729	0.00594805	0	0	0.00633847	0	1.20995
PLEKHB1	11.6882	0.0416158	0.0569638	0.0941328	0.0394614	0.11171	0.0506491	0	0.0586453	0.296856	0.128433	12.1636
SLC15A2	0.372788	0	0	0	0	0	0.00875149	0.0193288	0	0	0	0.850645
NGFR	4.48783	0.152075	0.0320247	0.0529208	0.0332776	0.125605	0.227797	0.141499	0.0824251	0.0455154	0.0541529	31.0756
"HOXC4,HOXC5,HOXC6"	1.66801	0.0127781	0.0176716	0	0	0.0231036	0	0	0	0	0.0394357	0.958327
LRRTM2	0.217296	0.00692801	0	0.00348239	0	0	0	0	0.00976301	0	0.0106904	0.557733
MAP3K9	0.19891	0	0	0	0	0	0	0	0	0	0	0.135813
SLITRK1	0.0580476	0	0	0	0	0	0	0	0	0	0	0.034492
LINC00052	0.262179	0	0	0	0	0	0	0	0	0	0	0
C2orf80	0	0	0	0	0	0	0	0	0	0	0	0.610628
ODZ2	5.3307	0.0103688	0.0198682	0.0250192	0.00393209	0.022268	0.0252374	0.0111485	0.0526086	0.129117	0.0768089	2.11832
FAM134B	1.53086	0.0366485	0	0.0127975	0.0115838	0.0455621	0	0.017109	0.0172151	0.142594	0.0392869	3.29546
ELMO1	1.39746	0.00755206	0.0304123	0.00577194	0.021068	0.0202053	0.013977	0.0149296	0	0	0	2.00793
REC8	8.42496	0.0258898	0.0239835	0.0173201	0.0496761	0.0777737	0.0422865	0	0.0757394	0.0677829	0.0270566	2.04583
GPC6	6.03505	0.0352309	0.0160747	0.0678843	0.026189	0.0840628	0.0252103	0.00927891	0.0496496	0.0456927	0.0213086	8.97597
RNF157	3.1527	0.028086	0	0.0327094	0.00771277	0.0906038	0	0	0.0114625	0.0187624	0	5.29446
VAV3	0.162927	0	0.00886905	0.00827743	0.012288	0.0115952	0	0	0	0	0	1.71582
PADI2	1.9628	0.300777	0.119495	0.0339085	0.0827775	0.234418	0.265527	0	0.183731	0.364244	0.0505141	43.095
BAI1	0	0.00979037	0.0407072	0.0203753	0.00960927	0.034992	0.023831	0.0263163	0.00963801	0	0	6.86895
LGALS7	1.39476	0	0	0	0	0	0	0	0	0	0	0
BAALC	9.59945	0	0.0103992	0.328506	0.0144081	0.0271916	0	0.0204216	0	0.0394138	0	31.6028
CPA6	1.87054	0	0	0	0	0.043148	0	0	0	0	0	0
ZMAT4	0	0	0	0	0	0.731181	0	0.732181	0	0	0	16.3642
CDH23	1.00809	0	0	0	0	0	0	0.0204053	0	0	0	0.0142475
GPR84	0	0	0.0379873	0	0	0	0	0	0	0	0	2.54127
HPD	1.4997	0	0	0.0155856	0	0	0	0	0	0.0402141	0	0
ALDH1A1	6.31224	0	0	0	0	0.093419	0	0.0233867	0.0490431	0	0	0
NRCAM	34.7145	0.0473025	0.0941057	0.150952	0.050271	0.590967	0.216053	0.127387	0.0186769	0.0818718	0.0948038	11.6655
NKAIN3	0.091444	0	0	0.0210939	0	0	0	0	0	0	0	2.61551
GRIA1	4.77641	0.0107267	0.0146827	0.0395402	0.0128955	0.146024	0.0174068	0.00961102	0.0100774	0.0834725	0.0110347	8.68471
LOC100507218	0.977063	0	0	0	0	0.00920651	0	0.0501462	0	0.0295545	0	1.41035
RASL11B	0.591177	0.010756	0	0.0108131	0	0.0192483	0	0	0	0	0	1.73766
PIPOX	22.5714	0.0206651	0.0848748	0.0519503	0.0783974	0.45624	0	0	0.0582526	0.053615	0.0318905	9.08632
NPAS3	3.33712	0.0134672	0.0229126	0.0342403	0	0.0299553	0	0.00904967	0	0	0	3.54658
EGLN3	3.12298	0.0149526	0.0137897	0.0303834	0.0191056	0.0360568	0	0.0541592	0.0421427	0.0261318	0.0461459	3.58614
PCDH20	0.704634	0.0123297	0	0.0123951	0.00779428	0.0147097	0	0	0	0	0	1.1524
BCMO1	0.175075	0	0	0	0	0	0	0	0	0	0	0
WDR49	0.121271	0	0	0	0	0	0	0	0	0	0	0.0240241
CXCL10	0.0411193	0.0187033	0	0	0.0709405	0	0	0	0	0	0	0.285054
LHX6	0.0535044	0	0	0	0	0	0	0	0	0	0	0.0927286
ST8SIA4	1.44136	0	0.0157237	0.00973175	0	0.00577442	0	0	0.0323756	0	0	0.0196717
CNNM1	0.093302	0	0	0	0	0.0120359	0	0	0	0	0	0.532802
"C1orf226,NOS1AP"	2.01617	0.00483696	0.00940235	0	0.0130305	0.0432427	0.00836005	0.0130017	0	0.0125466	0.0149275	0.795405
FAM184A	1.96351	0.0103295	0.0141391	0.0103843	0.010344	0.0184851	0	0	0.0307456	0.0282979	0.0336679	0.188528
STK32A	3.76103	0.0100282	0	0.0382502	0	0.0448645	0.012205	0	0	0.026012	0.0154741	0.616675
PLA2G5	2.19773	0	0	0.023856	0	0.0225902	0	0	0	0	0	0.776934
LIX1	0.461384	0	0	0	0	0.00894187	0	0	0	0	0	0
ST6GALNAC2	4.621	0.0495741	0	0.0598053	0	0	0	0.0266547	0	0.128589	0	0.574204
MYO5B	2.85919	0	0	0	0.324275	0	0	0	0	0	0	0.228104
GLT25D2	4.06787	0.137777	0.139843	0.162715	0.0345167	0.0907794	0.0460172	0	0.065987	0.0101215	0.0120423	28.9606
COL14A1	6.9243	0.0170358	0.00778525	0.0848354	0.0241497	0	0.00774876	0	0.0884343	0.313749	0.0491241	0.392501
DPYSL5	0.387954	0.00391901	0.00536444	0	0.00743251	0.0140271	0	0	0	0	0	0.663885
PRSS35	19.4663	0.0245952	0.145887	0.0576941	0.031096	0.0293427	0.0997807	0.154262	0	0	0	0.724719
JPH1	0.968856	0	0	0	0	0.058428	0	0	0	0	0	0.402422
INSM1	0	0.0147001	0.0100606	0.0147781	0	0.0263069	0	0	0	0	0	3.71876
EYA4	2.77323	0.00352683	0.0091114	0.0487895	0	0.0238241	0	0	0	0.00899142	0.0217704	2.92958
TGFA	4.36106	0.0203997	0.00698062	0.0446134	0.00967172	0.705944	0	0.0548345	0	0	0.015739	38.8843
AQP7P1	0	0	0	0.229277	0	0	0	0.0732933	0	0	0	26.9441
FBN2	0	0	0.0128639	0	0	0.033569	0.0254456	0.0756504	0.0264873	0	0	6.94241
COL20A1	0	0	0	0	0	0	0	0	0.0347598	0	0	0.71865
NEBL	1.24111	0.00278879	0	0.014018	0	0.0249534	0	0	0	0	0	1.02843
PLCH1	0.360236	0.00317106	0	0.00318789	0	0.00567483	0	0	0	0	0	0.161918
FAM78B	3.49357	0	0	0.0339626	0	0	0	0	0	0	0	3.94926
GRIK5	2.97934	0.0455936	0.00821355	0.0603251	0.0365861	0.11471	0.0370348	0.0161294	0	0.0311298	0	9.39987
ANO5	0.481869	0	0.00401981	0.00295161	0.00557031	0.00525612	0	0	0.00827926	0.00761956	0.0090659	0.474673
B4GALNT4	5.4635	0.0644555	0.0702203	0.0163989	0.0309357	0.261981	0	0	0	0.0844099	0	11.9224
C2orf55	0.543124	0	0	0.00920282	0	0.0190726	0	0	0.0150191	0	0	1.65228
C6orf141	4.54516	0	0	0	0	0.0576228	0	0	0	0	0	2.42153
KCNJ11	0.0486507	0	0	0	0	0	0	0	0	0.0191334	0	0.0715159
NTS	0.321579	0	0	0	0	0	0	0	0	0	0	0
ASCL1	0	0	0	0	0	0	0	0	0	0	0	0.201419
CA10	0.0544233	0	0	0	0	0	0	0	0	0	0	0.0840225
LINC00511	0.140683	0	0	0	0	0	0	0	0	0	0	0.0278646
MYCN	0.0689628	0	0	0	0	0	0	0	0	0	0	0.0956149
HOXB3	15.6829	0	0	0.0220986	0.0596254	0.678087	0.0552205	0.0644881	0	0	0	24.871
HOXB8	3.39272	0	0.025807	0	0	0.0674789	0	0	0	0	0	0.18923
NKAIN4	0.0728657	0	0	0	0	0	0	0	0	0	0.0138689	0.161071
IGF1	0.720578	0.0254895	0	0	0.00508769	0.0456144	0	0	0	0	0	0.0245348
ILDR2	1.40493	0.0048775	0.0100148	0.0269699	0	0.0654669	0	0.00655541	0	0	0.00752647	4.64199
PAQR6	0.780837	0.0245039	0	0	0.0265092	0.0438525	0	0	0	0.0362581	0	1.83991
CHODL	0.0781119	0.0103065	0	0.01692	0	0	0	0	0	0	0	1.62706
PGBD5	1.08732	0.00634131	0	0.00637497	0.0120262	0.0113481	0	0.0170455	0	0	0	0.231992
RIMBP2	0.361074	0	0.00568294	0.0139839	0.0080134	0.00756156	0	0	0	0	0	1.63531
KCNC1	0	0.00285155	0.00390321	0	0	0	0	0	0	0	0	0.312912
CLU	1592.39	6.88942	9.80323	13.1025	3.89333	19.8178	1.34228	4.616	3.86465	3.1861	5.82699	820.881
GATM	6.10859	0.0372951	0.0766534	0	0	0.0883375	0	0.0128285	0	0.0967396	0	1.52009
ALK	0.838309	0	0.0125336	0.0184122	0	0	0	0	0	0	0	0.181632
"LINC00461,MIR9-2"	2.125	0.00630711	0.00816095	0.0359641	0	0.0338613	0.0153526	0	0	0	0	3.58064
TMPRSS2	0.493777	0	0	0	0	0.0112264	0	0	0	0	0	0
ATP13A4	0.0406194	0	0	0	0	0	0	0	0.0130182	0	0	0.450542
C7orf57	0.687448	0.00987282	0	0	0	0.0231347	0	0	0	0	0	0.196739
EPHA4	0.7483	0	0.0096162	0.00353124	0	0.0251441	0	0.0094419	0.0179451	0	0.0108405	1.71275
CCDC64	2.75785	0	0.0193853	0.0155215	0	0.0276296	0	0	0	0	0.0476485	0
SPP1	857.989	0.332134	0.145479	1.52751	1.77875	24.2245	0.141696	3.9175	0.336993	0.426205	0.0898249	248.691
FAM181B	1.62642	0.0113826	0.0155805	0.0457721	0	0.0203696	0.0277067	0.0611925	0.128324	0	0	10.2693
KIAA0226L	0.122894	0.0219051	0	0.00734042	0.0553897	0.0130667	0.0177733	0.0196268	0.0205792	0	0	2.19636
FOXG1	11.4813	0.0188018	0.00857864	0.0503906	0.035657	0.391852	0.00700065	0.0505389	0.0176638	0.0162566	0	10.5601
COL9A3	3.77374	0.0206239	0.0143792	0.0100312	0.0177571	0.0339662	0.0436415	0.0495328	0.0781386	0.0926736	0	3.33533
MFAP5	75.8407	0.0227286	0	0.00594284	0.0534621	2.09895	0	0.24248	0.0320298	0.0294782	0.0364886	0.162179
RNASE1	0	0	0.0423757	0.0311224	0.0587115	0	0	0	0	0	0	5.60354
METTL7B	47.1283	0.294267	0.168319	0.31755	0.247708	0.246947	0.255903	0.295284	0.464732	0.215615	0.148043	10.9792
SERPINA1	0.788115	0	0.0171959	0	0	0	0	0	0	0	0	0
HLA-DMB	1.04499	0	0	0.0269044	0	0	0	0	0	0	0	0.162315
MTTP	0.854752	0.0100978	0	0.0152274	0.00957501	0	0	0	0	0	0	0.0615624
PLEKHG1	7.17818	0.0180231	0.0156835	0.0452621	0	0.112867	0.0219353	0.0363345	0.0888947	0.128506	0.0833991	1.97516
FLJ22184	3.90363	0.0173046	0.0118433	0.0347912	0	0.0774165	0	0	0.0243841	0.0224432	0	2.04647
NKX2-2	0.0709232	0.0161297	0	0.0162154	0	0.0577301	0	0	0	0	0	2.96434
SORCS3	0.0148768	0	0	0.00340136	0	0	0	0	0	0	0	0.309394
PHACTR3	0	0	0	0.0101383	0	0	0	0	0	0	0	0.971459
UBD	1.16779	0	0	0	0.0457888	0	0.0587702	0	0	0	0	0.66236
C3	1.88139	0.0191874	0.021011	0.00771571	0.00727767	0	0	0.0103151	0.0216313	0.0497702	0	0
ENTPD2	0.13113	0.0107617	0	0.0108188	0	0	0.0261961	0	0	0.0837476	0.0332131	1.39386
SNX10	0.634814	0	0	0.0239202	0	0.0945207	0	0.0238285	0.0249848	0	0	6.54846
SPOCK2	0.838314	0.0109991	0.010037	0.0479167	0	0	0	0	0	0.00951013	0	3.06221
MGAT5B	4.15943	0.09752	0.125287	0.0983798	0.172315	0.0632329	0.036861	0.0135683	0.0678826	0.07497	0.10067	13.6246
EPHB3	3.62307	0.0450786	0.0479917	0.0704946	0.0799004	0.0627434	0.0121918	0.0134633	0.0923559	0.168898	0.0154576	7.97442
GRIA2	1.00131	0.00371364	0	0.0224001	0	0	0	0	0	0	0	0.384872
IQGAP2	2.30093	0.00675219	0.0046212	0.00761516	0	0.0542227	0	0.0203614	0	0.00875724	0	0.524836
RRAGD	2.17	0.0198999	0	0.0040011	0.00754791	0.128202	0	0	0.0112172	0	0.0368483	2.87519
"FXYD2,FXYD6,FXYD6-FXYD2"	0.996348	0.0353712	0.0161386	0.0829711	0.0894406	0.43122	0.0573988	0.158462	0.664353	1.19228	0.463947	41.7017
CPVL	1.03242	0	0.0173724	0	0.0240695	0.0227123	0	0	0	0	0	0.65768
SFN	4.71553	0	0	0.0342265	0.0322834	0.0609263	0	0	0.0479776	0	0	0.0518885
VANGL2	1.00756	0	0	0.0115192	0	0.0820219	0	0	0	0	0	2.87562
GRIA4	0.0255084	0.0116026	0.0052938	0.00388798	0	0	0	0	0.0109003	0.0471191	0.0107042	0.734616
CYP2J2	1.80221	0	0.0175387	0	0	0.0229298	0	0.0344418	0	0	0	0.243465
CELSR1	1.05433	0.0285413	0.0243112	0.0236223	0.0190978	0.0127135	0.0043232	0.00954819	0.0283819	0.023035	0.0274064	2.96148
LOC645206	0.926156	0.0128218	0	0.0236117	0.0243164	0	0	0	0	0	0	0.229172
HAS3	7.29652	0.0237741	0.0520671	0.0478005	0.0270521	0.0850892	0.0347215	0	0.013401	0.024667	0.029348	0.652204
"DUSP5P,RHOU"	1.39747	0.00518595	0.00709855	0.00834782	0.0393403	0.0185611	0.0126234	0.0139398	0	0.0618951	0	0.0962336
LRRC4B	0.0601163	0.0557853	0.0190893	0.0560506	0.0396729	0.0748727	0	0.0187433	0.0786133	0	0.0430401	9.81822
NUP210	12.5828	0.0421823	0.0183973	0.0189165	0.0606483	0.190636	0.0524379	0.201221	0.0530331	0.221097	0.164568	2.2385
TMEM178	1.7982	0	0	0.0271343	0.0356122	0.331112	0	0.100951	0.0424318	0.0781037	0.0416491	14.6428
VGF	0.190309	0.0779065	0.0438909	0.0483531	0.045608	0.0717274	0.0421409	0.107738	0.0243969	0	0	12.1197
TMPRSS5	0.339775	0	0	0	0	0.0199802	0	0	0	0	0	0.374147
IL17RD	0.193895	0.0268472	0.0336862	0.0742221	0.0250896	0.0680629	0.0163373	0.0240549	0.00630534	0.063836	0.0483318	9.77163
C1orf187	3.32936	0.0147552	0.0154132	0.0424513	0.00533848	0.059686	0	0.0302681	0.0158683	0.00730186	0	1.96212
MMP9	0	0	0	0	0	0.034447	0	0	0	0	0	1.3197
HPSE	0.948645	0.119341	0.0370407	0.0227154	0.0514274	0.0323503	0.0330022	0.048594	0.168174	0.25435	0.153437	8.01708
MEGF11	0.0142099	0	0	0.0065765	0	0	0	0	0	0.0167657	0	1.0107
SOX8	0.218121	0.0264569	0.0452678	0.0465454	0	0.0236729	0.0160999	0.0177789	0.055925	0.10294	0.0816498	7.74192
CHST6	2.48688	0.0253032	0.00769643	0.0423945	0.00533169	0.00503107	0	0.00755693	0.0472423	0.0575586	0.0694658	1.00472
MYO5C	1.18922	0.00554791	0	0.00557736	0.0105214	0.0248205	0.00675217	0.0149127	0	0.00719536	0	0.152198
CADM1	35.1379	0.277252	0.136869	0.301569	0.146534	0.57749	0.044253	0.122171	0.947942	0.353687	0.757451	21.0259
TSHZ2	0.713966	0	0.00226905	0.00166641	0	0.03364	0	0	0	0	0	0.435953
GPR98	0.356949	0.0029698	0.00135574	0.00298715	0	0.00531458	0.0024109	0.00266234	0.0055801	0.00256915	0	0.199154
LYPD6	1.97186	0	0	0	0	0.0173126	0	0	0.0272685	0	0	0.339192
IGSF9B	0.131092	0.0137615	0	0	0	0	0	0	0.0389038	0	0	0.115905
ANGPTL7	0	0	0	0	0	0	0	0.0249006	0	0	0	0.73414
AGT	11.3897	0.063372	0.0867437	0.0477813	0.0300458	0	0.0771279	0.0212929	0.379544	0.924641	0.0733406	0.748526
MED12L	0.440159	0.00554919	0	0.00534853	0	0.0149081	0	9.41E-07	0	0	0	0.297501
TNFSF10	0.97176	0.0117827	0	0	0	0.0210859	0.0286811	0	0	0	0	0.143666
IGFBP5	23.2275	0.664349	2.99594	6.39608	1.49881	9.46886	1.51808	3.15573	0.474551	0.151996	0.166024	804.659
SPTBN2	0.143492	0.0036618	0.0162374	0.0128851	0.0112484	0.0636558	0	0	0.0103211	0.0192313	0.0091523	3.25479
APCDD1	1.08849	0.0159712	0.0437227	0.0481678	0.121155	0	0.0194379	0.0858604	0.13504	0.124283	0.0246446	8.4221
HKDC1	0.557606	0.0055493	0.00759602	0	0	0.0198623	0	0	0	0.0143949	0	0.263185
PTCHD2	0	0.00375077	0	0	0	0	0.00912987	0	0	0	0	0.274391
WNT11	0	0	0	0.0110024	0	0	0	0	0	0	0	0.833998
CHRNA1	1.04504	0.02122	0.0635055	0.0616608	0	0.138376	0.112631	0	0.089712	0	0	13.7434
LAMP5	1.19505	0	0.0151304	0.0222249	0	0	0	0	0	0	0	0.343885
STON2	0.975624	0.00175923	0	0.00176856	0	0.0314828	0.0111499	0	0.0128931	0.0091267	0	0.515742
CD70	38.3168	0.0458743	0	0.0355867	0.260999	1.87935	0	0.24662	0	0	0	0.408462
DBC1	0.0138248	0.0377297	0.0086074	0.0252866	0	0	0	0.0169028	0	0.0326223	0	2.14678
CHGB	1.40455	0.0153944	0	0.0386903	0	0.0688723	0.018736	0.0413799	0.0433879	0	0.0237547	4.83324
C1orf173	0.124677	0.0122466	0	0.00410386	0	0	0	0	0	0	0	0
IGDCC3	0.0200138	0.00910348	0	0	0	0.00814527	0	0	0	0	0	0.268246
ENKUR	0.0696846	0	0	0.0127459	0	0	0	0	0	0.0156702	0	0.692745
LPPR5	0.12267	0	0.0132279	0.0102373	0.00965606	0.09793	0.0123937	0.0136862	0.157864	0	0	7.70272
CDK5R2	0.291062	0.00827444	0.0113261	0	0.0156922	0.0592298	0	0.0222416	0.0233208	0	0	3.0014
HOXB6	28.3421	0	0	0.0128901	0.07295	1.29929	0.0312106	0.241259	0	0	0	9.18469
GAS2	0.592074	0	0.0138747	0.031282	0	0.0177264	0	0	0	0	0	6.30244
SYT17	0.855943	0.00677397	0	0.0256793	0.024283	0.0229139	0	0.034418	0.0360882	0.0662581	0.0395163	1.4635
CYP27A1	4.95674	0.0901845	0.043275	0.0423774	0.0199857	0.161388	0	0	0.127088	0.109343	0.0975694	4.30174
CSMD2	3.98074	0.0817697	0	0.0443699	0.0837936	0.129088	0.107637	0.113464	0	0.00655516	0.116698	2.25827
ABCC3	3.80581	0.190397	0.0375777	0.0655481	0.0390478	0.110048	0.033412	0.0553458	0.16094	0.0534086	0.0317716	7.11512
NOL4	0.345515	0	0.00966717	0.00709999	0.0133938	0	0	0	0	0	0	0.268188
RHPN1	1.83604	0.0223968	0	0.0225157	0.0106184	0.0400808	0.0408884	0	0	0.0871443	0.0172798	0.612921
DTX1	0.0402334	0.00610007	0	0.00613245	0.0115686	0.0218328	0	0	0	0	0	0.985297
JAM2	4.73819	0.0379319	0.0172858	0.156689	0.0240373	0.328216	0.185113	0.170348	0.178222	0.0655138	0.860556	20.932
OTP	0	0.00807496	0	0.00811785	0	0	0	0	0	0	0	0.625307
HOXB7	0.107308	0	0	0.0163562	0	0.0291155	0	0	0	0	0	1.88454
ITGB8	2.41222	0.0110701	0.049413	0.0489682	0.00456373	0.23256	0.023432	0.0194067	0.0271314	0.02497	0.0445632	9.63932
DHRS3	1.20699	0.0219925	0.0599344	0.114299	0.0359361	0.474527	0.160599	0.0591159	0.053406	0	0.0678725	24.4786
TMEM163	0.195059	0	0.050158	0.0254841	0	0	0	0.0340696	0	0	0.0391162	4.50018
SYT4	0.106362	0	0	0.00486014	0	0	0	0	0	0	0	0.176966
NRP2	22.7208	0.139187	0.0889109	0.0377898	0.146165	0.862754	0.0632778	0.174624	0.066778	0.159483	0.198594	4.71526
RAB39A	0.57754	0	0	0.0120192	0	0.0146332	0	0	0	0	0	0.327025
LGI3	0.0947347	0.00615016	0	0	0	0.0110059	0.0149771	0	0	0	0	0.581711
PRRG4	0.371729	0.0180986	0.00495449	0.00727771	0.00686452	0	0	0	0.0102018	0.0281676	0	0.176538
CNIH3	30.8799	0.273707	0.23878	0.737532	0.49178	1.3079	0.0889493	0.420685	0.642698	0.116199	0.245505	53.1271
NLGN1	1.90198	0.00398675	0.0109141	0.0240474	0	0.0713444	0	0	0	0	0	1.11801
KCNK1	5.77956	0	0	0.0580838	0	0.172324	0	0	0	0	0	0.0880571
CACNG7	1.06665	0.0260768	0.0237959	0.0791342	0.0164844	0.21132	0.021158	0	0	0.0225468	0.0268255	10.0403
IRF5	0.509893	0.00821962	0	0.00742385	0.0155886	0.0147097	0	0	0	0	0	0.0751677
CXCR4	7.42396	0	0.0175748	0.11617	0	0.206793	0	0.0345126	0	0.0666093	0	2.9353
CHRM4	0.591513	0	0	0	0	0.0267489	0	0	0	0.077544	0	0.045562
SIAH3	0.218138	0	0	0	0	0	0.0120759	0	0	0	0	0.0151221
LGI2	0.127903	0	0	0	0	0.00547949	0	0	0	0	0	0.0186667
IGFBP5	16.163	0.699372	1.59033	4.83362	1.3573	11.7802	1.28577	1.35948	0.211237	0.238188	0.489118	679.006
GPM6A	7.70656	0.0711563	0.0486833	0.307389	0.0674508	1.44875	0.034629	0.173007	0.0200477	0	0.0219521	52.0254
MYH14	0.578494	0.00598029	0.0163719	0.0150302	0	0.0204167	0	0.0080375	0	0	0	1.27595
TPD52	2.65312	0.0350514	0.0137078	0.0151015	0.0094959	0.152336	0	0.0134593	0.0282254	0.0779318	0.0463602	2.44214
RAMP1	29.4521	1.4286	0.295164	0.243879	1.02237	0.627073	0.196833	0.362268	0.227908	0.0699176	0.249557	8.70918
KCNIP2	0.141396	0.0268142	0	0.0107758	0	0.0383646	0	0.0288128	0	0.0441933	0.0330817	1.85453
SFRP2	0	0.1689	0.0577976	0.191021	0.0400392	0.0377816	0	0.255375	0.0297519	0.0273818	0	17.4722
WBSCR28	1.98702	0	0	0	0	0.087427	0	0	0	0	0	0
SCUBE2	1.35114	0.017352	0.0118757	0.00976543	0.0276333	0.044549	0.023645	0	0.0136889	0.0377956	0.0299787	0.771466
MMP28	0.375666	0.128339	0.0114066	0.00837749	0	0	0	0	0.0234866	0.119469	0	0.711231
HOXB2	9.24151	0.0135053	0.073944	0.190077	0	0.124794	0	0	0	0	0	2.59929
SCN4B	0.122791	0.00473184	0.00647701	0	0	0.118531	0	0	0.0266734	0.0117268	0	3.64064
RPE65	0.683004	0	0	0.00751486	0	0	0.0181984	0	0.0193661	0.0193915	0	0.205102
BCO2	0.120765	0	0	0.0138056	0	0	0	0	0	0.0356211	0	0.535158
CGN	1.21067	0	0.00524954	0.00385549	0.00727322	0.0617997	0	0	0	0	0	0.397707
EFNA1	2.1337	0.0145752	0.0199507	0.0146525	0	0.0521671	0	0	0.0410799	0	0	0.507139
LMTK3	0.550596	0.0218875	0.00499328	0.0146691	0.0553453	0.0195843	0.017759	0.0196111	0	0.0132613	0.022516	1.61989
CSDC2	2.17145	0.00832533	0.0113959	0.00836952	0	0.0869273	0	0	0	0	0.0256942	0.101514
CSPG5	0.396151	0.0200727	0.0137376	0.0279652	0.0548704	0.0898039	0.0704266	0.0269777	0.0565741	0	0.0309739	6.15862
SORL1	2.51849	0.0229111	0.0289484	0.0956752	0.0233962	0.0157693	0.00428965	0.00473704	0.0248358	0.0365719	0.0108778	2.83111
GRIK4	1.59414	0	0.0705321	0.0518841	0	0	0	0	0	0	0.0795919	3.9315
NPNT	0.460305	0	0	0.0129182	0	0	0	0	0	0.0120583	0.0143466	0.01417
DCHS1	0.450211	0.0360222	0.0215998	0.0492222	0.0249387	0.0235326	0.0192055	0.00706934	0.0211485	0.03411	0.0405831	3.60987
THSD1P1	2.331	0	0.0277451	0.00653056	0.0734515	0.0582449	0	0	0.0890111	0	0.141591	0.899585
LOC100499467	25.6471	0.388913	0.434533	0.477232	0.474915	0.653766	0.262133	0.518342	0.397908	0.405413	0.353123	51.9225
NBEAP1	1.35456	0	0.076669	0	0	0	0	0	0	0	0	1.36586
DAPL1	2.12514	0	0	0	0	0.101755	0	0	0	0	0	0.346641
PCDH17	3.26177	0.00217676	0.00508425	0.0284485	0.00412818	0.124635	0	0.0292559	0	0	0.00671785	0.770793
GSC	1.22545	0	0	0.0193228	0	0.0343964	0	0	0	0	0	0.29294
PRODH	0.486212	0.0526922	0	0	0	0.0152932	0	0	0.0297017	0.082007	0.032523	0.0321228
"CACNG8,MIR935"	0.0302962	0.00459338	0.0090215	0.00230884	0	0.0164403	0.00559046	0	0	0	0	0.889149
CLEC18C	0.383378	0	0	0.00357769	0.00674916	0.00955293	0.00866259	0	0	0	0.010983	0.141021
LEF1	3.23429	0.152718	0.0991273	0.384472	0.172168	0.143821	0.221081	0.197338	0.136377	0.223724	0.271558	27.9837
KIF5C	1.74247	0.0139078	0.00380741	0.016778	0.0263758	0.0348441	0	0	0.203862	0.404118	0.291801	1.80555
SYNDIG1	1.37546	0.0328163	0.0449531	0.0511729	0	0.460216	0	0.0273588	0.0942358	0.0852785	0.202161	16.3755
MYO5B	0.516234	0	0	0.00612812	0.0117094	0.029093	0	0	0	0.00527047	0	0.283487
FHOD3	1.85334	0.0655072	0	0	0	0.000148241	0	0.0808358	0.0972067	0	0	0.582281
IMPA2	2.70998	0.0794874	0.0217603	0	0	0.101419	0	0.0427321	0.0448056	0.0412363	0.0437531	0.581499
PPP2R2B	5.00907	0.0196625	0	0.197672	0.0186446	0.199739	0.155003	0.0264263	0.0554177	0.0825885	0.197251	11.6331
HOXB9	7.39561	0	0	0	0.014304	0.593891	0	0.020274	0	0	0	4.91999
SLC38A3	2.30133	0.0586193	0.0802395	0.00841863	0.0317628	0.0149873	0.0815367	0	0.070808	0.412714	0	2.11865
P2RY1	0.296572	0.00586085	0.00886905	0.0130276	0.0170657	0.00524407	0.00713298	0.0241882	0.0165182	0.105014	0.0416587	0.678858
FGF12	3.3796	0.0181173	0	0.11799	0	0.016353	0	0.0163754	0	0	0	1.48769
FAM20A	0.0118994	0	0	0	0	0	0	0	0.0152443	0.102122	0	0.115468
VIT	0.282051	0.0150406	0	0	0.0590472	0	0.0378937	0	0	0.0403809	0.048044	0.0703764
HAND2	0.114821	0	0	0.00875071	0	0	0	0	0	0	0	0.318393
HOPX	3.09765	0	0.122863	0	0.170227	0.281101	0.391965	0.120637	0	0	0.124238	14.4804
GPR56	5.83143	0.114012	0.0747298	0.246756	0.178618	0.283918	0.120661	0.103743	0.0219878	0	0.045948	15.4946
PHF21B	0.175699	0.00533499	0.00827968	0.00608091	0	0	0	0	0	0	0	0.291207
PTHLH	37.544	0.0445739	0.0128126	0.221662	0.0840967	1.84795	0.0227845	0.201734	0	0	0	10.8265
ICA1	0.125996	0	0	0.0192047	0	0	0	0	0.0537955	0	0.0327623	1.70409
CKB	184.692	2.56147	1.4437	0.939141	3.54329	7.36112	0.892886	2.38956	1.61372	1.05525	0.492289	70.4267
LOC283547	0.662982	0	0.0259636	0.0189998	0	0.00860143	0	0	0	0	0	0.181913
SRCIN1	0.0491819	0.0447413	0.0152947	0.0112446	0.0106062	0.0100082	0.0136132	0	0.0157624	0	0	1.18886
APOD	0.13479	0.0935248	0.293724	0.282098	0	0.538467	0.0746183	0	0.131833	0.238503	0	36.8731
SRGAP3	0.755379	0.00688084	0.0156976	0.0138352	0.0260989	0.0246273	0.00783499	0	0.00646436	0.0248241	0.00679627	0.774182
C1orf106	0.394107	0.017428	0.0170396	0.00500572	0.0330519	0	0	0.0334618	0.00701695	0.0710395	0.0691532	0.62231
PPARGC1A	0.628229	0	0	0.0168939	0	0.0300728	0	0	0	0.0174359	0	0.495457
EFR3B	1.08448	0.00609107	0.0125062	0.0183702	0	0.0381519	0.00741323	0.0245591	0.0171672	0.00789981	0.00939896	1.21592
ZNF853	0.937784	0.00535392	0.0146612	0.042882	0.0101558	0.0862658	0	0	0.0301904	0.0138915	0.0329103	3.38427
CDH19	0	0	0	0	0	0	0.0272276	0.0300671	0	0	0.0146703	0.508407
CCNO	0.879643	0.0307777	0	0.0154705	0	0.027539	0	0	0	0	0	0.140723
C1QL1	17.7207	0.247787	0.279317	0.205143	0.110569	0.0521676	0.212875	0.0391792	0.328643	0.415887	0.0899653	1.55502
NOVA1	3.19046	0.0565702	0.0591684	0.139888	0.262661	0.166097	0.130956	0.166897	0.105573	0.610369	0.188838	12.0235
ADD2	1.86093	0	0	0.0105362	0	0.140503	0	0.0140855	0	0	0	1.95055
LOC283174	0.218622	0.00368302	0.00504132	0.00740513	0.00698473	0.0065909	0	0.00989989	0	0.00955337	0	0.47151
ANKRD65	3.88606	0.0925361	0.0180933	0.0398678	0.0250689	0.163412	0	0	0	0.13716	0.0815939	0.0402939
MAEL	0.146141	0	0	0	0	0.023791	0	0	0	0	0	0.486291
LRRTM4	0	0	0	0.00552995	0	0	0	0	0	0	0	0.291626
PIWIL2	0.0361035	0	0	0	0.0934723	0.00686312	0	0	0	0	0.0169118	0.0116901
LPPR1	0.0551827	0	0	0.00894133	0	0	0	0	0	0	0	0.357049
PCDH7	0.00971188	0.00662572	0	0.0297556	0	0	0	0	0	0.00572858	0	0.884318
CABP4	0.0960784	0	0	0	0	0.0111593	0	0	0	0.0323514	0.01519	0.120024
NPR1	0.439625	0	0	0.00980592	0.00924921	0	0	0	0.0274917	0.0126507	0	0.201529
ESRRG	0.401474	0.0037266	0	0.00374638	0.00706768	0	0.0181433	0.0100176	0	0	0	0.0454407
TOX3	0.284247	0	0	0	0.0124688	0.107456	0	0	0	0	0	2.02273
MREG	15.7888	0.13598	0.266121	0.182292	0.225517	0.213877	0.312278	0.244183	0.256032	0.388382	0.372806	6.09003
SNN	3.78296	0.201522	0.0849613	0.0902554	0.0428828	0.160206	0.0950514	0.0393429	0.114953	0.0810791	0.0463324	7.38941
PDE6B	0.62089	0	0	0	0	0.0381494	0	0	0	0	0	0.194941
MKRN3	0.347512	0.180181	0	0	0.0454856	0.0192974	0	0.0636471	0	0	0	0.49323
GNG4	0.19897	0.0764527	0	0.00405065	0	0.00721077	0	0.0108311	0	0	0	0.688212
ESPN	0	0	0	0	0	0.018244	0	0	0	0	0	0.309757
TEX26	0.559411	0	0	0	0	0.029708	0	0	0	0	0	0
SALL4	0.138683	0	0	0	0.021751	0.0102623	0	0	0	0	0	0.0524399
HOXA1	0.0193522	0	0	0	0	0.0157523	0	0	0	0	0	0.367467
THSD1	1.83604	0.0659164	0.030783	0.0476212	0.0213249	0.0474494	0	0	0.031692	0.0389674	0.0347022	1.4229
CALY	0.0644458	0	0.0401243	0.023604	0	0	0.0713529	0	6.85E-07	0	0	2.28113
SNAP25	1.29251	0	0	0	0.0412941	0.0974131	0	0.0292628	0	0	0.167996	0.597341
LOC286297	0	0	0.0035961	0	0	0	0	0.00706183	0	0	0.0060809	0.270273
RBP1	2.79185	0.473468	0.562959	0.827285	0.174855	2.04579	0.100594	0.123916	0.347039	0.473535	0.614527	86.3836
"F11R,TSTD1"	11.226	0.0208833	0.0400195	0.0326744	0.0237628	0.284355	0.0406665	0.0336806	0.0470867	0.195012	0.0644495	1.03088
TMEM132A	78.5325	3.35892	3.36751	1.52225	1.8005	3.07051	0.539145	1.07388	2.44402	2.40119	2.56288	144.985
CIITA	0.17904	0.0123242	0	0.00412965	0	0	0	0	0.0115781	0	0	0.0500885
KLRK1	12.4036	0.245826	0.34236	0.757206	0.0912392	0.67524	0	0.683859	0.358521	0.659922	0.758656	19.5804
GPR4	0.0145517	0.344183	0	0	0.0502101	0.0473791	0.0644451	0	0.0373096	1.16747	0.0204268	0.0201755
KIAA1211	0.605922	0.00514513	0.00361504	0.0212412	0	0.0425379	0	0.0141986	0.0148876	0	0.00815079	1.30658
CELSR2	10.6309	0.177976	0.232486	0.169944	0.230426	0.34631	0.237605	0.182943	0.424529	0.653089	0.300925	11.1664
LCTL	1.87646	0.028055	0.0513287	0.00945049	0.070759	0.100476	0	0.0775936	0	0.0229174	0.0574869	1.57563
LRRC4C	0.0805959	0	0.00837665	0.00792637	0	0.0109129	0	0	0	0	0	0.510534
C14orf23	10.0037	0	0	0.0990933	0	0.646781	0	0.322829	0	0	0	8.31618
CADM2	0.0141416	0	0	0.0258692	0	0.0153481	0	0	0.00604132	0.00556057	0.00624161	1.266
MAPT	0.119251	0.0399089	0.0663566	0.0585874	0.0467186	0.0676436	0.0590009	0.00945929	0.0975936	0.148236	0.119469	7.22138
SLC1A3	60.7568	2.94963	1.20137	2.42734	0.568973	0.0487762	0.658155	0.637268	3.15416	6.92653	1.50128	83.6602
IL7	0.551016	0.0147064	0	0.00738894	0	0	0	0	0.0207244	0	0.0601189	0.210896
CA8	0.720554	0.00911933	0	0.00916775	0	0.0653047	0	0	0	0	0	0.720722
FGFR2	0.0505091	0.0068585	0.00938792	0	0	0	0	0	0	0.0355805	0.014177	0.0840418
SKAP1	0.363093	0	0	0	0	0.0246665	0	0	0	0	0	0.12612
ARHGEF26-AS1	0.151131	0	0	0	0	0.0153773	0	0	0	0	0	0.183347
TOMM40	0.330913	0.224354	0	0.0667683	0	0	0	0	0	0.18808	0.852694	0.502313
DNM1	3.22234	0.0218366	0.0281599	0.0694293	0.0653252	0.0644286	0.0125186	0.0138243	0.0434873	0.0599234	0.0158721	1.33945
CLEC18B	0.862157	0.010843	0.00742099	0.0145341	0.0068545	0	0.0219945	0	0.0458403	0.0281258	0.0446175	0.424159
ENPP5	1.65364	0.0063136	0.00864208	0.0223429	0	0.0225971	0	0	0.0626391	0	0.0514419	0.0169363
C10orf81	0.21473	0.019534	0.00668435	0.00490921	0	0	0	0	0	0.0196254	0	0.0144236
AP3B2	1.04141	0.01657	0.00756005	0.0055523	0	0.0593068	0.0134444	0	0	0	0	0.286221
SEMA4D	1.05643	0.0439651	0.0186913	0.0219351	0.0431611	0.00814552	0.0443181	0.02447	0	0.0580293	0.0421419	0.561551
SBK1	0.353795	0.011775	0	0.0118375	0.00744366	0.0140479	0.028662	0.0105504	0.0221246	0.0305432	0	0.993018
COL4A4	0.228015	0.148163	0.0177454	0.013033	0.010537	0.0066286	0	0.00497823	0.0104396	0.14412	0.0171469	0.28791
PTPRD	0.300337	0.00216661	0.00593548	0.0130802	0.0239823	0.0116415	0.0527882	0.00582787	0	0	0	1.09157
FAM43B	0.208897	0.00791816	0.0108384	0	0	0	0.0192738	0	0.0223167	0	0	0.57926
CXCR7	0.163282	0.0106097	0	0.0319986	0	0	0	0	0	0.0275209	0	0.905546
EN2	0.414725	0	0	0	0	0.031648	0	0	0	0	0	0.0898445
TAGLN3	2.38276	0	0	0.0191071	0.036045	0.325904	0	0	0	0	0	3.95173
ADAMTS9	1.44728	0.0982152	0.101177	0.0845218	0.0699166	0.151242	0.0342726	0.151489	0.079488	0.221962	0.151802	6.47092
CHRNA9	2.70209	0.0189096	0.0139772	0.143609	0	0	0	0	0	0	0	0.746695
AZGP1	1.53845	0.0356641	0	0.026743	0	0.190482	0	0	0	0	0	1.14145
TMEM200C	1.91514	0.0129056	0.0451076	0.0454085	0.0244749	0.0808313	0	0.0173447	0	0.117163	0.0339141	1.5735
LOC283174	0.202567	0.0184277	0	0	0	0	0.0448554	0	0	0	0.0568704	0.393194
GOLGA2P5	0.244949	0	0	0	0	0	0	0	0.0237504	0	0	0.0269963
CA3	0.34859	0	0	0.0122615	0	0	0	0	0	0	0	0.0371777
LHFPL4	0.415303	0.00803842	0	0.0242432	0.0076223	0	0	0	0	0.0104254	0	0.232773
EPHX4	0.15689	0.00319597	0.0100357	0.00642594	0.0242447	0.0686332	0	0.00859083	0.00826556	0.0248705	0.0181014	1.62135
GRID1	0.0431608	0.0517598	0.107719	0.0517393	0.0186156	0.0919684	0	0.069651	0.0729711	0.0223197	0	4.50588
PPP4R4	0.530125	0	0	0.00515933	0	0.00918407	0.0124922	0	0	0	0.0158383	0.0156434
SMTNL2	0	0.0652847	0	0.021877	0.020635	0	0	0	0.0306665	0.705051	0	0
PRRX2	1.14775	0.0287299	0	0	0.0324601	0.0514133	0	0.0772255	0.0809729	0.149045	0	0.0875734
HOXB5	4.97556	0	0	0.0117277	0	0.501033	0	0.0313574	0	0	0	3.27144
TMEM169	1.44864	0.029705	0.0406645	0.0290293	0.0676161	0.0744388	0.0433888	0.0159654	0.0334899	0.07707	0.0366722	2.24335
ELMOD1	0.688822	0.0136209	0.0186448	0.0203645	0.0129157	0.0121874	0	0	0.038392	0.017666	0.0210188	0.788939
ZDHHC23	0.523255	0.0116111	0	0.0175091	0	0.0311679	0	0.0156052	0.0163625	0.0136559	0.0162473	0.674111
LINC00475	2.60748	0.123979	0	0	0.118228	0.111562	0	0.068702	0.175703	0.161707	0	0.380052
NELL2	0.72929	0.00625837	0	0.00629159	0.0118693	0.109769	0	0	0	0	0	1.21526
ZNF536	0.122119	0	0	0.00402637	0.00759588	0.00716758	0	0	0	0	0	0.0732298
LRRC26	1.00797	0	0.0261487	0	0	0	0	0	0.0538411	0	0	0
CCDC88C	0.455703	0.00255935	0.014013	0.0077188	0	0	0	0.00687949	0.0144266	0	0	0.210607
PRKCQ	0.228883	0	0	0	0	0.0350396	0	0	0.018395	0	0.0188996	0.504014
DAB1	0.256394	0.0038853	0	0.00390592	0	0.00695304	0.00945761	0	0	0.0100784	0	1.05382
MPPED2	0	0	0	0.0086147	0.0162513	0.015335	0	0.023034	0	0.414739	0.026446	0.235085
EPHX2	0.544202	0	0.0135563	0	0	0.0177234	0	0.0266216	0	0.0770702	0	0.120757
DIRAS3	9.51049	0.0669648	0.109817	0.161494	0.126982	0.331446	0.0977354	0.143964	0.0754747	0.173515	0.0825275	2.94364
ACHE	1.20063	0.0869034	0.144378	0.0795635	0.154762	0.394563	0.132196	0.115971	0.153067	0.0196196	0.125741	14.9317
PDPN	9.39044	0.0723351	0.0395168	0.0945517	0.0588672	1.10914	0.0566671	0.271604	0	0.0402558	0.0446448	12.3779
GPR137C	0.895803	0	0.00785664	0.0403922	0.0544272	0.0102716	0	0.0462858	0	0.0297771	0.0354279	0.559804
ATP6V0E2	39.9383	1.9083	1.04521	1.30242	1.76791	2.95185	2.7383	2.30016	3.52407	5.13292	5.09532	127.741
GPC2	0.355682	0.075192	0.0775709	0.0566869	0.0356457	0.117745	0.0686274	0.0505229	0.0529745	0.0419635	0.0580066	6.00341
CPXM1	4.34548	0.102926	0.0274025	0.120755	0.163134	0.0341665	0.0929468	0.10264	0.67687	5.49531	0.132351	0.261445
NLGN4Y	5.76401	0.0668579	0.153946	0.762877	0.831555	0.224256	0.0136904	0.0596649	0.251599	1.44324	0.905166	10.9651
PALM3	0.249688	0.00946381	0.0129543	0	0.0179483	0	0	0.0254394	0	0.024549	0.0292077	0.173092
SFRP1	0.135718	0.030866	0.0120713	0.17288	0.14216	0.410324	0.0214662	0.118525	0.944497	10.4654	1.5105	9.35468
PADI3	0.651512	0.113493	0.00863054	0.00633865	0	0	0	0.0338965	0.0710825	0.212615	0	0.0384384
PCDHB3	0.0261286	0.571927	0.0216857	0.136795	0.0721091	0.143775	0	0	0.0482239	0.0186208	0.0410703	5.48811
LRAT	0.352845	0	0	0	0.00760926	0.0287209	0	0	0	0	0	0
DBNDD1	19.5759	0.138321	0.364104	0.384593	0.423755	1.96095	0.233098	0.457605	0.389846	0.634783	1.14929	33.2098
SEMA5B	0.345932	0	0.0165714	0.00431237	0	0	0.0313295	0	0.0120914	0	0	0.506978
SEMA3E	0	0.00568835	0.00444206	0.0142964	0	0.011615	0	0	0	0	0.0100153	0.600948
ACSS1	1.40303	0.0420846	0.0467397	0.0381113	0.106561	0.0167928	0.0205213	0.0226614	0.0481406	0.169988	0.144445	0.612353
TSPAN33	0.996048	0.0878438	0.0601158	0.0514677	0.0138727	0.0261692	0	0	0.0206167	0.0569594	0.0903664	1.60373
PSD2	0.268719	0.0174612	0.0119505	0	0	0.00781187	0.0106257	0	0	0	0.0134719	0.0931429
PLEKHH1	0.246303	0.0110613	0.00976858	0.00372002	0	0.0127104	0	0.00999822	0	0.0181196	0.0108752	0.229893
PCSK1	0.141854	0.00460867	0	0.00926637	0	0	0	0	0	0.0119546	0	0.0596705
CLDN23	0.830028	0.0107869	0	0.0325325	0.0409141	0	0	0.0579901	0	0.0559604	0	0.295923
FHDC1	0.184247	0.00598594	0	0.0120356	0.00567606	0.0107122	0	0.00804511	0.00843551	0	0.00923682	0.41055
CNTNAP3B	1.50628	0.0147791	0.0255721	0.139763	0	0	0	0.0117282	0.0456142	0.00298043	0.136959	4.39798
HLF	0.696753	0.00696531	0.00953413	0.0140046	0.00660475	0.0124647	0	0.0187226	0.0294467	0.027101	0	0.276008
C9orf171	0.476289	0.0411534	0.0187746	0	0	0.0490784	0	0	0	0	0	0.388448
HRCT1	4.36508	0.152729	0.104528	0.15354	0.531018	1.82E-06	1.69E-06	0.205267	0	0.0660273	0.314229	1.00868
KCNMB2	1.09737	0	0.0224631	0	0	0.0864418	0	0	0	0.041765	0	0.294478
SHISA9	0	0.0028974	0	0.00475354	0	0.109982	0	0	0.0133267	0	0	1.87883
ABCD2	0.212609	0.00365783	0	0.00735454	0	0	0	0.0196646	0	0.00948812	0.0112887	0.0668988
HS3ST3B1	6.28476	0.379253	0.204355	0.265024	0.136901	0.251271	0.0627548	0.0830017	0.111201	0.213681	0.270092	4.62603
CCDC85C	1.17348	0.0169146	0.0124415	0.0174315	0.0389131	0.0602732	0.0106722	0	0.0247082	0.0448414	0	0.269793
GJB2	0.48655	0.0088524	0.0484687	0.00889938	0	0.0158417	0	0	0	0	0	0.836489
"C4A,LOC100293534"	0.771914	0.0261774	0.0479351	0.0361706	0.0373808	0.0297608	0.0175166	0.0241778	0.0253511	0.118346	0.00380112	1.77828
EGR2	1.79366	0.122017	0.10021	0.0735989	0.0716353	0.148712	0.0594011	0.0437306	0.0229262	0.293948	0.100417	4.03869
ITPR3	3.01932	0.0217729	0.0327831	0.059099	0.0123875	0.116891	0	0.0351152	0.0306826	0.0564768	0.0470361	0.238923
HOXB13	0.525901	0	0.00909526	0.0133599	0	0.0118909	0	0	0	0	0	0.0405082
FRAS1	0.0561935	0.0012171	0	0.0110123	0.00507895	0.00871243	0.00296264	0.00327161	0	0	0	0.419233
RND2	2.92798	0.0571447	0.0847383	0.0735894	0.0188517	0.0937409	0.0811402	0.0667997	0.228165	0.141816	0.0613555	4.38388
GRAMD2	0.267874	0	0	0	0	0.0109022	0.0148292	0	0	0	0	0
ITPRIPL1	1.47804	0.0350849	0.050924	0.0374007	0.0282219	0.0209674	0.0855603	0.0200002	0.0419418	0.121398	0.072319	1.44178
NAT8L	0.0362475	0.0167683	0.011283	0.0165741	0.0127201	0.0120028	0.00816295	0	0.0232336	0.0213827	0.0206998	1.00562
PRR18	0.115888	0	0	0	0	0.0134758	0	0	0	0	0	0.0918147
ANXA8L2	0.40877	0.0137727	0.00471302	0.0103843	0.00652987	0	0	0.0185104	0	0	0	0
HCP5	0.692829	0.0137995	0.0185383	0	0	0	0	0.065032	0	0.04931	0	0
TNFRSF21	3.67668	1.56818	0.818081	0.700055	1.11265	3.01238	0.146813	1.10539	0.865411	1.35116	1.26913	84.4533
PCDH15	0	0	0	0.00886149	0	0.00788713	0	0	0	0	0	0.281974
KIAA0319	0.148133	0.00378265	0	0.00760611	0	0	0	0	0.0106623	0.0388386	0	0.0576599
HLA-DRA	10.8695	0.140256	0	0.0881255	0	0.65886	0.341402	0.329881	0.148238	0.0454763	0.0541063	4.7562
KCNAB3	1.00516	0.0403415	0	0.0405556	0	0	0.0327316	0	0.0378992	0.100051	0.0829996	0.122967
CACNA1G	0.282634	0.0163987	0.0102089	0.00942421	0	0	0	0	0.0105104	0	0.0156136	0.011367
DCHS1	0.399834	0.0163771	0.0592072	0.049611	0.0123278	0.0233822	0.01269	0.0458505	0	0.119045	0.0403235	2.56136
MFSD2A	21.4168	0.395821	0.594662	0.280595	0.529329	0.518297	0.46855	0.439802	0.217673	0.150248	0.744858	4.60596
MAP3K9	0.17212	0.0085082	0.00465752	0.00684233	0	0.00913559	0.012398	0.00457306	0.00479508	0.00882782	0	0.35191
MACROD2	0.129922	0	0.0243983	0.0179192	0	0	0.0108467	0	0.0125593	0.0346632	0.0275046	0.878363
HOXC10	0.641561	0	0	0.0196225	0	0.0402996	0	0.0524697	0	0	0	0.514817
CXCL14	8.90419	0.41567	0.14589	0.150007	0.101065	0.438686	0.0259435	0.257842	0.781021	1.93524	0.263142	6.62754
KIF1A	0.198775	0.00429417	0.00538383	0.0258999	0.00407152	0.0422149	0	0.00577082	0	0.0102024	0.0242771	1.18585
S1PR1	0.0145363	0.0132238	0	0	0.0125393	0.0236645	0	0	0	0	0	0.302312
FGFR3	4.49878	0.0863992	0.0622439	0.0718463	0.0813209	0.0976516	0.0579866	0.102454	0.161139	0.0617926	0.147038	0.421164
CX3CL1	10.8489	0.0980806	0.41954	0.511493	0.0697525	0.0548497	0.164134	0.0329548	0.138216	0.858637	0.0945907	8.38971
KIRREL2	0.979066	0	0.02175	0	0	0.0510541	0	0.0213558	0.0201017	0	0	0.0683124
"C4A,LOC100293534"	0.67699	0.037264	0.0430102	0.0452576	0.0443895	0.0330675	0.0175166	0.0338489	0.0253511	0.151791	0.00380112	1.83923
RNF144A	1.46229	0.00690776	0	0.0208355	0.0131014	0.0247263	0.088838	0	0.019471	0.0652543	0.0213206	0.249439
INPP5D	0.142897	0.0162509	0	0.00408298	0	0.0508765	0	0	0	0.0105349	0.0250682	0.557261
ELMO1	7.11179	0.187607	0	0.182222	0	0.660477	0.897868	0	0	0	0	13.7303
ANXA8	0.473756	0.0197529	0.00491567	0.0108313	0.0068108	0	0	0.0193074	0.0151832	0	0	0
P2RY2	0	0.00811638	0	0.00815946	0	0	0	0	0	0.0210539	0	0.197932
HRK	0.0318691	0	0	0.00364319	0	0	0	0	0	0	0	0.0662784
SALL3	0.0593642	0	0	0.00353325	0	0	0	0	0	0	0	0.0107131
SHC3	0	0.0120823	0	4.54E-06	0	0	0.00588168	0.0109146	0.0272431	0.0250728	0	0.344332
F2RL3	0	0.00744959	0.010197	0	0	0.0133313	0	0	0	0	0	0.386028
NRXN1	0.0297396	0	0	0.00453298	0	0.00806915	0	0	0	0	0	0.192386
CYP39A1	0.300441	0.00961441	0	0.0193312	0	0	0	0	0	0.0498789	0	0
NDRG4	2.80424	0.112588	4.00E-05	0.121059	0.266522	0	0.0684021	0.176281	0.211244	0.0971973	0	2.32774
GRIK2	6.70869	0.00431496	0.21854	0.135339	0	0.0386099	0.231071	0.0347965	0	0	0	0.749604
TMEM100	19.1119	0.193389	0.229416	0.673973	0.342306	0.162956	0.411645	0.485171	0.290694	0.944818	0.200733	4.67654
HEY1	5.23187	0.0721442	0.14813	0.108792	0.153928	0.0968326	0.197565	0.169686	0.0508322	0.280713	0.278317	2.22665
ADAM22	0.292826	0.00832827	0.00284966	0.0441802	0.00789712	0.0393326	0.0356851	0.0055964	0.0206273	0.037998	0.0192678	0.623908
PDLIM4	21.6104	8.45554	0.695434	0.326072	2.54591	3.63811	0.197378	0.460142	0.915182	1.84625	1.08441	19.8284
SOX1	0.195872	0	0	0	0	0.0473999	0	0	0	0	0.0148624	0.381667
DENND2D	1.40394	0.0602165	0.0468272	0.0229278	0.0648784	0	0.0366761	0	0.127399	0.0390834	0.0465003	0.243315
SALL1	1.80015	0.142617	0.105108	0.000198259	1.35E-05	0.183838	0.0552178	1.35E-05	0.176601	0.265062	0.099708	3.07288
EML6	0.495633	0.0100886	0	0.0152132	0.00478307	0.0180542	0.0122785	0.00677941	0	0.0191153	0.00778363	0.0384399
TIAM1	1.91628	0.0472701	0.0647468	0.0844852	0.0697716	0.0564323	0.0130322	0.0282548	0.0444387	0.0544767	0.0972873	0.640107
KCNIP4	4.07098	0.0344503	0.0235778	0.0346332	0.032667	0.184951	0.125785	0.0926019	0.0728215	0.0670205	0.106319	0.393788
SCN3B	0.00756108	0.00343915	0	0.0103724	0.032612	0.0123092	0.0251145	0	0	0	0.0106139	0.587067
SLCO2A1	2.74719	0.0748429	0.0537146	0.0376196	0.0266126	0.133935	0.0119399	0	0.118653	0.254475	0.0302765	0.269137
S100A1	0.974427	0.196989	0.134819	0.0990168	0.186795	0	0.119874	0	0.138801	0	0.151987	4.80361
DSCAM	0.0538204	0	0.00372321	0	0	0.0194706	0	0	0	0	0	0.257026
ZNF467	0	0	0	0	0.229915	0.0542379	0	0	0.0854214	0.0786166	0	1.38891
DMRT2	0	0.0176711	0	0.0162085	0	0	0	0	0	0	0	0.410738
TNC	55.9181	0.922806	1.82229	2.58782	2.87455	0.732792	3.26696	3.46785	2.88329	6.24827	3.2818	76.9423
NAT16	0.36361	0	0.00943276	0.0207835	0.013069	0	0	0	0	0	0	0.14704
CADPS	0.519061	0.00380847	0.0052131	0.0146146	0.0144458	0.0340785	0	0	0	0	0.0117539	0.0812655
LRRTM3	0	0	0.00475823	0.010484	0	0	0.00846153	0	0.00979738	0	0	0.487417
PCDHB5	1.83365	0.0603917	0.0381179	0.254991	0.0549275	0.150374	0.0847362	0.0374293	0.335385	0.279176	0.281576	9.16043
KLHDC9	0.764311	0	0	0.0215516	0.0813195	0.1151	0	0	0	0	0	0.70723
PLEKHA6	0.331794	0.0299161	0.0118925	0.0203374	0.0325562	0.00543811	0	0	0	0.026957	0.0233227	0.125453
RNF208	5.47649	0.260553	0.178322	0.19628	0.205301	0.504018	0.105289	0.17509	0.733867	0.901129	0.401574	11.3665
SERPINF1	3.20361	0.0852678	0.167279	0.0921424	0.0869113	0.136686	0.111551	0	0.129163	0.43587	0.0471437	2.7312
ID4	1.03576	0.0102418	0.0560757	0.118405	0	0.0458201	0.0124649	0.0137648	0.0721639	0	0	3.40282
ERBB3	0.037192	0.0033834	0.0305419	0.0674699	0.127407	0.00605473	0.00823564	0.189834	0.0631698	0	0.0208833	1.07775
RHOV	0.414621	0.0125728	0.0172097	0	0	0.0224996	0	0	0	0	0	0
LOC644554	0.634516	0	0	0.0223188	0.0421035	0	0	0	0.0625717	0.0575871	0	0.0676722
C19orf35	0.0174967	0.0397924	0.0217871	0	0	0	0	0	0	0.0206435	0	0.218328
ARHGAP25	0	0	0.00988244	0	0	0	0	0	0.0203489	0	0	0.336945
EPHB2	1.28959	0.0205676	0.0394134	0.0496235	0.0468062	0.169309	0.0100121	0.0110563	0.0579673	0	0.025389	2.4499
SCN3A	0.15816	0.003319	0.00151429	0.0100101	0.00209808	0.00791947	0.00538599	0	0.00623632	0	0.0034143	0.202344
ANXA9	1.39059	0	0	0.00368786	0	0	0	0.0762057	0.181228	0	0	0.255091
ZNF436	18.5327	0.402264	0.350461	0.640045	0.573976	0.460299	0.580128	0.282708	0.322169	0.563136	0.465537	4.86225
TMC7	1.5241	0.0134432	0.0122667	0.0180188	0.0339921	0.0681346	0.054537	0.0594298	0.0252586	0.0697401	0.0553161	0.300497
GPT	0.493014	0.0112125	0.0153477	0.022544	0.0212642	0	0	0	0	0	0.0346034	0
OTX1	0.280859	0.0141945	0	0.00713492	0	0.0127008	0.0172756	0.0190773	0	0	0.0219031	0.194702
RAMP2	1.35813	0.0327421	0.0448173	0	0.124188	0.0585931	0.0796983	0	0	0.0849293	0	0
PTPRE	1.30943	0.0890723	0.0548301	0.0695593	0.0317056	0.188984	0.008864	0.0449383	0.141267	0.156794	0.171836	3.55724
PCDHB9	1.09558	0.129543	0.0895043	0.0978698	0.0555978	0.14842	0.107576	0.212058	0.0577878	0.0738009	0.261459	3.93393
LAPTM5	1.44452	0.00925421	0	0.0372133	0.0351006	0.0828039	0	0	0.0521644	0.0240045	0.0571196	0.0564166
FHOD3	3.73203	0.328629	0.105673	0.103927	0.0245856	0.144086	0	0.0273213	0.123719	0.344925	0.199572	2.53565
PPP1R9A	0.649651	0.00926797	0.0127048	0.0372824	0	0.0627169	0.0228603	0.0211154	0.0261597	0.0480803	0.0424265	1.08509
EBF4	2.17553	0.0581459	0.0497212	0.0465428	0.0551526	0.138084	0.0375643	0.103705	0.143419	0.470574	0.0238131	1.70564
FAM196A	0.0330282	0	0.00622438	0.0452265	0	0.0162752	0.0110688	0	0	0.0194855	0.0140337	1.32704
KIAA1161	4.45417	0.117493	0.10936	0.0802817	0.0729245	0.201129	0.100791	0.0636012	0.0916953	0.15848	0.100405	0.92859
CD34	5.17729	0.0702549	0.0213699	0.0863229	0.0888242	0.293357	0.0190009	0.0582232	0.183145	0.0404964	0.0722722	0.0713829
SFXN5	21.9766	0.465904	0.605227	0.585566	0.534393	0.166274	0.599289	0.287375	1.09318	1.16288	0.700889	4.29152
IGLON5	0	0.00649738	0.00889363	0.00653187	0	0.0116273	0	0.0174649	0	0	0.0200518	0.534737
FAM198B	12.2896	0.405371	0.211193	0.475801	0.276171	0.220909	0.200308	0.152076	0.579938	0.200188	0.31744	2.42252
NRN1	7.18738	0.106154	0.269851	0.457362	0.947832	0.47954	0.479553	0.774497	2.25977	1.20627	1.06013	29.4027
MAN1C1	7.94808	0.882935	0.680575	0.642227	1.08146	0.386727	0.0880649	0.0622212	2.48107	3.92882	0.778631	29.5697
CDH3	0.612641	0.0270483	0	0.0135959	0.012824	0.0625117	0	0	0	0.0877006	0.0417374	0.0412237
ADRA2B	0	0.0064281	0	0	0	0	0.0469421	0	0	0.0166742	0	0.379547
C3orf80	0.156938	0	0.0217134	0	0	0	0	0	0.0223544	0.0411473	0	0.265943
HLA-DOA	0.201721	0	0	0	0	0.0321222	0	0	0	0.01552	0	0.0911912
BVES	35.1501	1.02724	0.626951	0.660808	0.803836	1.35621	1.01422	0.868949	0.546687	0.682886	0.809242	3.32109
OLFM1	7.70242	1.18029	0.309274	0.315354	0.569122	0.714529	0.418968	0.739252	0.82637	0.178849	0.706514	3.76001
CXADR	1.72035	0.00435309	0.0119171	0.0437624	0.0330223	0.267244	0	0.0818787	0.0363117	0.0297585	0.0940408	2.52378
BRSK2	0.185243	0	0.00661648	0.00485918	0	0.00865052	0.0117668	0	0.0272501	0.0250795	0.0298387	0.281567
GJA3	0.0660876	0.00375754	0.00514332	0.00377748	0.00712605	0.00672426	0.00914633	0	0.0211806	0	0.0115963	0.355061
TMEM59L	11.1764	0.455679	0.768987	0.268851	0.306131	1.63012	0.523649	0.506436	0.302774	0.420108	0.496459	23.8636
ID1	31.9369	0.38926	0.197529	1.45659	0.501739	0.129123	0.292721	0.323248	1.24975	0.561481	0.0742259	1.5687
CAPN8	0.0436867	0	0.0135998	0.00998831	0.0188425	0	0	0	0	0	0	0.363423
TBX6	0.181677	0.0236106	0	0.0118679	0	0	0	0	0.0332722	0.0612434	0.0364327	0.107953
CCR1	0.0167437	0	0	0	0.0144434	0.013629	0	0	0.0214649	0.019755	0	0.278576
PLEKHA6	0.246825	0.0236435	0.00645285	0.00662674	0.0435421	0.0423274	0	0.00938666	0.00744789	0.0769652	0.018021	0.159966
KIF21A	4.89004	0.11527	0.275404	0.188794	0.0692952	0.114311	0.170195	0.196502	0.0515196	0.144497	0.281881	1.27509
LOC439949	0.271317	0.0183905	0.0287525	0	0	0.018795	0	0	0.0267549	0.0272432	0	0.336343
HOXA3	0.121929	0	0	0	0	0.0441102	0	0	0	0	0	0.356887
AQP7P1	0.107355	0.0233978	0.0131948	0	0	0.0302808	0.023747	0.0500529	0	0.0508446	0.0286639	1.61435
AUTS2	2.98207	0.0811197	0.10895	0.174114	0.0427272	0.17739	0.0179402	0.0605869	0.0889376	0.221705	0.230631	2.96343
SDK1	1.90335	0.0129049	0.0131401	0.150137	0.0499982	0.096304	0.0077809	0.0515421	0.123846	0.0911552	0.324998	3.51314
RGS16	2.24877	0.177522	0.0347132	0.0254949	0.19238	1.01356	0.617303	0.159059	0.381205	0.175419	0.130442	17.0838
NRG1	5.72721	0.0474349	0.0860125	0.144809	0.0708819	0.223655	0.0352323	0.110322	0.0932473	0.0263797	0.0701968	0.0806778
TMTC2	2.1468	0.0171931	0.0221866	0.0788466	0.0244545	0.0692274	0.020925	0.069322	0.109029	0.21022	0.125057	0.568181
PDGFB	1.27396	0.121134	0.0592156	0.0435008	0.0164164	0.278503	0.294762	0.162876	0	0.0449071	0.0534291	6.983
RNF112	1.32677	0.0186642	0.0340638	0.0437815	0.0471954	0.022267	0.0151436	0.0501697	0	0.0322757	0	0.113785
CECR6	0.154012	0.0150142	0.0205515	0.00503127	0.0189827	0.0268685	0	0	0	0.0404464	0.0154453	0.249522
CLEC18A	0.529379	0.0115577	0.00736987	0.00387281	0.0292254	0.0310248	0.0234444	0	0.0488624	0	0.047559	0.258357
SNCA	0.261184	0	0	0.0134262	0	0	0	0.0179495	0	0.0173212	0.0206085	0
"FXYD1,FXYD7"	0.687571	1.34296	1.71235	0.563985	3.15063	1.79095	2.23147	1.84944	1.23403	4.05615	0.965176	51.8077
FAM84B	0.735844	0.0373796	0.0102498	0.0300634	0.0283798	0.114695	0	0.00957101	0.0210834	0.04618	0.0329661	0.803158
LOC113230	2.53292	0.0172571	0.0708676	0.0928735	0.0224448	0.123534	0	0	0.243199	0.134295	0.05326	0.921153
SOX6	0.00483543	0.00880033	0.0240935	0.0399646	0.0166902	0.0039368	0.00535505	0.0059135	0.00620049	0.0114134	0	1.21946
"FCGR2A,FCGR2C"	2.31547	0.192869	0.0639118	0.0334362	0.0911682	0.0297597	0.0295726	0.125507	0.0684834	0.123335	0.0749825	0.882246
SALL1	2.13719	0.171288	0.361256	0.203236	0.369003	0	0	0.219659	0.0767517	0.585151	0.230295	6.21632
MTRNR2L8	6.26101	0.132101	0.0794729	0.148841	0.104621	0.218192	0.19079	0.117049	0.0900011	0.112952	0.0537556	0
ANKRD45	0.52257	0.0152376	0.0208586	0.0221639	0	0.00789064	0	0	0.0745654	0	0.0408241	0.440931
KCNB1	0.00352281	0.00160237	0.00219333	0.0106362	0	0.00573501	0	0	0.00451615	0	0	0.257738
FMNL2	3.31415	0.357869	0.107099	0.376987	0.189676	0.32454	0.0426951	0.222036	0.318562	0.35295	0.49636	8.68978
ASRGL1	4.01338	0.0792969	0.171795	0.113917	0.118467	0.0788361	0.171573	0.0488812	0.102507	0.138886	0.0826208	1.53084
GLIPR1L1	0.396097	0.0675626	0	0.0226404	0.0427101	0.040302	0	0	0	0.0584168	0.0695026	0
CDH5	0.126403	0	0.00655827	0	0	0.00857413	0	0	0	0	0	0.029209
HAPLN4	0.102299	0	0	0	0	0.0104087	0	0	0.016393	0.0150871	0.0359004	0.0531879
STXBP5L	0.0317911	0	0	0.00415303	0	0	0	0	0	0	0	0.0440776
KCNN4	14.1573	0.972988	0.358758	0.363771	0.603709	1.67512	0.329456	0.771583	0.316585	0.194003	0.784879	14.4536
LINGO1	0	0.048292	0.0377727	0.0485483	0.0523339	0.0246916	0.0335854	0.018544	0.0388877	0.0536848	0	2.08185
SFRP4	7.57551	0.0747601	0.0279086	0.109319	0.0386673	1.19191	0.0827163	0.0548056	0.03831	0.229178	0	5.26197
SYBU	3.24615	0.00775379	0	0.0233862	0	0.384896	0	0.0416871	0	0.0201136	0	0.354425
COL9A2	1.3066	0.0222866	0.0103903	0.0839467	0.098621	0.0135842	0.0184775	0.0204046	0.085581	0.0787634	0.0917068	0.475536
GPD1	0.0154861	0.00704394	0.0192835	0.00708133	0	0	0	0	0	0	0.0217386	0.365008
ISL2	0.549543	0	0	0.017978	0	0.0423587	0	0	0	0.030699	0.0551896	0.109021
GNG7	0.173831	0.271066	2.44662	0.39305	0.247052	1.20577	1.00825	0.732149	0.144195	1.79032	0.423816	30.5499
AGAP2	0.324046	0.0176914	0.0118113	0.00800876	0.0409342	0.0308048	0.0420405	0.0591693	0.0850439	0.0884122	0.0526733	0.911644
HLA-DQA1	1.52228	0.0200851	0	0	0	0.0718865	0.29334	0.107977	0	0	0	1.50085
PCDHB10	0.0369962	0.0589339	0	0.0657996	0	0.0761235	0.00257719	0	0	0.070563	0	1.75789
"RWDD3,TMEM56-RWDD3"	0.581087	0.0170523	0.0155608	0.0371427	0.00538985	0.0406876	0.0207537	0.00763937	0.00801007	0.0442319	0.0263129	0.658389
TOX	0.917592	0.0364939	0.0214082	0.162472	0.0494351	0.0186591	0.0761145	0.0280269	0	0	0.064357	2.67175
SHOX2	0.717317	0	0.0162483	0.0178913	0	0.0424642	0.0625547	0	0	0.0923264	0.0183079	0
RHBDL3	0.405083	0.0228528	0.00625607	0.0262268	0.0433398	0.00817908	0.0211674	0.0122855	0.0257635	0.0474224	0.0282108	0.253672
CLGN	1.48626	0	0	0.0522782	0	0.0797658	0	0.0199684	0.0209374	0	0	0.0226442
ADAMTS3	0.0239991	0.0267537	0.0640855	0.0672389	0.0570794	0.0260465	0.079714	0.0293424	0.0615325	0.0693961	0.0516032	3.11925
DCLK2	4.94482	0.392877	0.178734	0.260006	0.237273	0.312554	0.209884	0.27417	0.287193	0.300873	0.403948	4.91289
COBL	0.516283	0	0	0.0115074	0	0.226245	0	0.0205124	0	0	0	1.8746
PTPRU	7.07332	0.217797	0.222039	0.209028	0.325841	0.266701	0.0902222	0.112156	0.20899	0.300572	0.131514	1.12352
SLC27A3	15.1594	0.827483	0.514585	0.377157	0.436594	0.442494	0.477353	0.297946	0.696903	1.03949	0.690818	2.23514
DNM3	1.85367	0.0854154	0.0407173	0.056495	0.0151638	0.0142756	0.17226	0.0919776	0.145674	0.0622208	0.0986382	1.54544
FGFRL1	34.8289	1.83176	2.14818	1.34375	1.74268	3.39754	1.20224	1.19221	1.05975	0.745498	1.74326	51.76
DDR1	67.1908	2.82278	3.08622	2.04321	2.3959	5.50314	1.52403	1.51079	2.64929	2.75616	3.07355	60.4768
LOC100128098	0	3.61564	0.223987	0.300432	2.79176	0.781536	0.267097	0.147457	0.772038	4.43161	2.59633	0
ANXA8	0.331629	0.0197529	0.00491567	0.0108313	0.0068108	0	0	0.0193074	0.0151832	0	0	0
CERS1	6.42985	0.211838	0.250138	0.170484	0.298431	0.668358	0.188304	0.198063	0.139865	0.173102	0.114949	6.59515
EPB41	0.684078	0.0270196	0.0183683	0.0279245	0.0173103	0.0713551	0.0148199	0.0386167	0.031529	0.0143091	0.0566163	0.827838
SCG2	65.5171	3.35323	5.82875	4.89621	4.23408	8.85456	2.60183	4.05488	11.856	20.7274	9.73262	232.984
SORBS1	3.60961	0.166421	0.0671376	0.0204894	0.141726	0.577449	0.0310018	0.075338	0.0287214	0.045438	0.0393061	1.85942
SIPA1L2	3.85857	0.203812	0.109671	0.246709	0.14631	0.0451843	0.283777	0.135602	0.167273	0.280694	0.155854	3.16882
GAD1	0.138215	0.0539047	0.012256	0.0270908	0.0169806	0.0514699	0	0	0	0	0	0.900829
HRASLS	0.624069	0.0217618	0	0.030225	0.120058	0.16141	0.158921	0	0.0613362	0.0779865	0.092786	1.65048
PDE11A	0.149319	0	0.00342701	0	0	0.00448054	0	0	0	0	0.00772723	0.103524
LOC100507127	4.14937	0	0	0.0272135	0.024903	0.743271	0	0.0176483	0	0	0.0839092	0.527972
SEMA3B	3.25398	0.173083	0.151592	0.111323	0.157557	0.0867193	0.201958	0.20471	0.214581	0.520832	0.341878	2.74281
HOXB4	0.217317	0	0	0	0	0.14779	0	0	0	0	0	1.1324
MX1	2.71204	0.152735	0.0668005	0.0614661	0.0895218	0.0740593	0.130211	0.0655878	0.129315	0.178429	0.16509	0.372728
NTNG1	2.39623	0	0	0.0084526	0.0318909	0.237866	0	0.248202	0.0236972	0.0653305	0.0923568	0.690728
FAM19A3	0.0484073	0.0440366	0	0	0.0835146	0.029708	0	0.0892463	0.062057	0.0430611	0	0.910847
COL24A1	0.0403286	0.00917697	0.0125614	0.0138385	0.00562154	0.00821127	0	0.0246675	0.0258645	0.0238041	0.02829	0.406336
UGT8	0.52259	0.00553162	0	0	0	0.109978	0	0.0148689	0	0	0.0215558	0.339359
EEPD1	0.32261	0.041926	0.0229553	0.00421485	0.0318045	0.0300113	0.0102053	0.0112696	0.023633	0.0217503	0	0.306713
NTN1	1.22832	0.274453	0.147585	0.154378	0.0619629	0.111092	0.0477178	0.0439119	0.478847	3.77987	0.231916	1.82254
TUBB4A	0.121421	0	0	0.0486705	0	1.30E-05	0	0.10736	0.0750462	0	0.205437	1.65489
MESP1	2.5641	0.0395354	0.0270581	0.0397453	0.149955	0.318376	0.0481172	0.0531353	0.278568	0.307652	0.183018	2.04867
HS6ST1	29.3267	1.06991	1.18287	1.00409	1.06701	0.844842	0.811064	0.710157	0.845207	1.19593	1.21213	6.27141
EYA1	0.393906	0	0.0144974	0.0159713	0.158265	0.0379078	0	0.134634	0.149258	0.298777	0.256076	1.08473
CYP46A1	0.861796	0.0416809	0.0273009	0.0701784	0.0378253	0.0559438	0.048549	0	0	0.0538246	0.0321572	0.999368
CD74	9.32695	0.0638989	0.532523	0.112027	0.0325794	0.644346	0.393635	0.355653	0	0.114401	0	6.25658
LYPD6B	0.0440624	0.0200417	0	0.0805941	0	0.0358659	0	0	0.0820655	0.103975	0	1.94804
ST8SIA1	0.107407	0.097709	0.118703	0.0736707	0	0.131141	0	0	0	0.126731	0	3.2017
TMEFF2	11.9182	0.729973	0.607402	1.7272	1.63874	3.86229	3.86912	1.57576	3.82994	6.61468	2.34944	101.024
KIF5A	0.503363	0.0339504	0	0.0170655	0.0193124	0.0486044	0.0578477	0.0365088	0.0861176	0.0265242	0.0628653	1.03941
AGPAT9	0.345722	0	0	0.060224	0.0295434	0.236006	0	0.041875	0	0	0	2.97948
SOX21	1.0864	0.00759992	0.0111233	0.0491924	0.00479376	0.058374	0	0.0219415	0.0286402	0	0	1.00099
CCDC103	6.1886	0.357785	0.145437	0.369769	0.34095	0.223062	0.49863	0.531393	0.540781	0.539003	0.33232	1.25715
FCER1G	0.109129	0.099276	0	0.0499015	0.282411	0.177658	0	0.133426	0	0.128756	0.30638	2.11826
FAM169A	0.540148	0.03275	0.0179313	0.042801	0.0248437	0.0234491	0.0318954	0.0352126	0	0.0339801	0.0404284	0.619089
CDH2	57.4419	2.42666	1.74948	2.93206	1.60915	5.95282	1.91636	1.85704	0.661792	0.314906	1.46894	67.0066
BOC	6.91171	0.524113	0.334205	0.343843	0.605426	0.641757	0.117458	0.181843	0.307659	0.47192	0.501505	7.47487
THY1	35.3863	3.49569	2.33955	1.91686	0.961028	2.93571	0.188159	1.17743	1.83974	1.40356	0.768692	42.2552
LRRN2	0.0968355	0	0.00860999	0.00632257	0	0	0	0	0	0	0	0.0958997
TCAP	0.439939	0.0250136	0.0684772	0	0.0474375	0	0	0	0	0	0	0.152491
LOC284276	0	0	0.0126485	0	0.0175244	0.0165363	0	0	0	0.071907	0.0285176	0.197166
WNK4	10.6701	0.0217716	0.0896731	0.043893	0.0447191	1.60076	0	0.128689	0	0.0124179	0.0147746	0.364607
ADRA1B	1.15851	0.100799	0.0571449	0.018479	0.122009	0.0328943	0.0673413	0.0748122	0.0392212	0.143045	0.0429469	0
MOXD1	45.4125	1.41726	1.89964	2.31773	2.3029	4.59947	0.732849	2.49184	1.39715	0.901351	1.86661	50.7107
DCLK1	1.67751	0.0652386	0.0297514	0.261734	0.0647746	0.138374	0.0536002	0.0986501	0.0837729	0	0.0835586	4.34823
SPRY1	5.40061	0.798427	0.612589	1.28831	0.33267	0.502862	0.662792	0.235962	0.794264	1.29726	0.541474	26.2682
PODNL1	0.917982	0.182069	0.086529	0.0682847	0.0970629	0.217363	0.0717917	0.171889	0.202367	0.248367	0.172328	4.1925
PMEPA1	15.5881	0.525447	0.851646	0.770972	0.366608	1.68662	0.264808	0.536168	0.476979	0.156854	0.372907	17.4839
LRRC4	0.0590146	0	0.00734929	0.0161915	0	0.00960761	0.0130681	0.028862	0.0151313	0	0	0.720029
EGF	2.08343	0.0267873	0.0366928	0.053901	0.0530245	0.263964	0.0163244	0.0360018	0.021587	0.0368178	0.0429031	0.326696
GLDC	4.60274	0.227662	0.387508	0.391	0.469876	0.316134	0.0457892	0.325555	0.991648	1.46558	0.217514	7.42929
ZDHHC22	0.0903519	0.017613	0.00803624	0.00590217	0	0	0	0.0157812	0	0	0	0.12527
CMYA5	0.0937828	0	0.00202685	0.00148861	0	0.0153281	0	0	0	0	0	0.0260213
DMRTA1	0.315864	0	0	0.0180544	0.0170294	0.0160692	0	0	0	0	0	0
MFAP3L	2.36687	0.148871	0.0774261	0.0884736	0.0357639	0.163139	0.0918083	0.0929343	0.044292	0.0163048	0.0581996	1.28722
LAMC3	0.021452	1.59818	0.0578772	0.385792	0.0370101	0.0969661	0.158343	0.0437139	0.332384	3.32423	1.52584	0.456689
SLC4A11	2.61789	0.131394	0.0647465	0.0739709	0.0996735	0.12227	0.063966	0.113019	0.118503	0.136329	0.11354	0.320408
SRSF12	0.365379	0.0242898	0.0530804	0.0244187	0	0.0108668	0	0	0.0171147	0	0.0374809	0.557247
MAST1	0.577867	0.0159301	0.00545127	0.00400365	0.0302109	0.0855224	0.0193879	0.0214099	0	0.0206605	0	0.230648
CTNNA2	0.917635	0.00515299	0	0	0.0097727	0.160058	0	0	0	0	0	0.141371
C21orf49	0.479887	0.0208668	0	0	0.0728286	0.0373429	0	0	0.16235	0.21651	0.0643993	0.175586
TNFAIP8L3	0.725987	0.0275182	0.0125557	0.0276643	0	0.082075	0	0	0	0	0.0283084	0.22368
LOC100192378	1.07064	0.0258029	0	0.0223968	0.0422505	0.119605	0.0628077	0.0346789	0	0	0	0.366221
MGC12916	0.322011	0.177855	0.0286409	0.0315527	0	0.0187222	0	0	0	0	0.0322873	0
GRTP1	3.68263	0.0157243	0.0215234	0.0158077	0	0.296825	0	0	0	0	0.0970546	0.0479301
GATA3	0.909374	0	0.0179835	0	0	0.141141	0	0	0	0	0	0.180617
L3MBTL4	1.38325	0.0242987	0.0166301	0.0181606	0	0.173491	0.0295732	0.0161858	0.034242	0.0156192	0	0.587029
MMP15	4.08093	0.457397	0.498437	0.272323	0.294761	0.182778	0.194568	0.226796	0.400508	0.49531	0.178162	7.70204
SLC12A7	0.728751	1.53318	0.0154354	0.404734	0.226806	0.104046	0.0661204	0	0.198774	1.84826	0.298692	0.249175
SESN3	4.52181	0.140351	0.215851	0.156915	0.180317	0.237444	0.190414	0.197317	0.403407	0.740053	0.104468	3.3409
RUNDC3A	0.0245434	0.0334929	0.0152791	0.0112203	0.0423466	0.0599404	0.0543535	0	0.0314653	0	0.0342956	1.06876
SCNN1A	0.469353	0	0.0085956	0.0126261	0	0.0224758	0	0.03376	0	0.016289	0	0
C1orf88	0.116006	0	0.0253085	0	0	0.0165436	0	0.0236389	0.0260557	0.045623	0.0285308	0.455716
ARHGEF26	0.873464	0.0113077	0.0472938	0.0849071	0.0364029	0.033726	0.0186891	0.0309576	0.0101433	0.0684392	0.0555339	0.949694
VMO1	0.693872	0.0427385	0.0462701	0.0339825	0.374674	0.0764825	0	0	0.120455	0	0	0.534463
ZNF323	1.89236	0.0573838	0.0523641	0.0384585	0.0604589	0.0684597	0.077599	0.10283	0.0718799	0.132308	0.019677	0.136044
RNF180	0.540435	0.180862	0.173666	0.235194	0.228408	0.219952	0.10616	0.127895	0.134094	0.203805	0.155873	7.22121
SEZ6L	0.218062	0.0122357	0	0	0.0116005	0.0766266	0	0.00822103	0	0	0	0.335671
SCARA3	20.5657	0.397478	0.588787	1.62025	0.196194	0.185132	0.145787	0.219535	0.153458	0.183604	0.201643	4.69696
KIAA1598	1.9642	0.0387216	0.0151434	0.214939	0.0090105	0.0692938	0.053859	0.0297379	0.0779525	0.0246483	0.136572	1.69445
USP2	0.761599	0.0277378	0.0444981	0	0.0263019	0.111638	0.0168792	0.0186396	0.0195441	0.0539627	0	0.443632
SLC1A2	0.133479	0.00492222	0.00224554	0.00164907	0.00622337	0.0117454	0.0119821	0	0	0.00851222	0	0.00500125
LOC100506474	1.73012	0.27521	0.191962	0.139888	0.407885	0.272121	0.46344	0.159929	0.562083	0.783349	0.51499	11.3653
CHST1	0.177039	0.0705269	0.0275712	0.0405088	0.0286344	0.0360522	0	0.0541614	0.0567902	0.0914731	0.046636	1.15059
TMEM221	1.26264	0.0327755	0.0195115	0.0143301	0.0414398	0.131528	0.0531873	0.0966245	0.0307919	0.0850164	0.0879826	0.333016
PURG	0.282723	0.00857322	0.0117351	0.00861883	0	0.0460264	0	0	0.0483324	0.0222394	0	0.470386
TMEM132B	0.216075	0.0647016	0.159307	0.26372	0.474652	0.952853	0.094164	0.146458	0.177967	0.13411	0.130673	9.83663
MAP3K14	5.49209	0.583265	0.237588	0.182437	0.49379	0.282253	0.499278	0.169629	0.378275	0.634136	0.706052	0.577229
ZNF704	0.0231009	0.00525378	0.00374102	0.0288499	0.00259157	0.00489094	0	0.014693	0.0231091	0.0170347	0.0210868	0.586518
CACNA1G	0.227612	0	0.0163547	0.0145319	0	0	0	0	0	0	0	0.10926
SLC22A23	5.884	1.50604	0.9452	0.867928	0.564046	0.433177	0.17582	0.482544	0.583116	1.32112	1.74243	21.4066
PMP22	104.358	5.74843	2.57475	3.54556	5.1516	2.41865	5.81616	4.73884	4.64637	8.66298	3.02112	41.9124
CDC42BPG	0.296681	0.0119071	0.0162984	0.0159604	0.0225814	0	0	0.0106687	0.0223728	0.0205905	0.0612449	0.0241965
DLX2	0.355007	0.0269128	0.0245589	0.00901856	0.0170131	0.0160539	0.0218364	0	0	0	0	0.0820346
HIVEP3	10.4973	1.07589	0.823363	0.691818	0.521517	1.02186	0.388369	0.655461	0.670474	0.539949	0.564831	17.6709
LOC149773	0.0236065	0.544977	0.0187215	0.161417	0.0203634	0	0.0906118	0.0340402	0	0.0294792	0.281079	0.0654594
PCDHA11	1.48314	0.185266	0.170281	0.141687	0.128878	0.0652313	0.0425523	0.083427	0.121253	0.0571899	0.0624323	2.92236
FAM65B	0.932123	0.0838773	0.0349468	0.0875779	0.0484207	0.113013	0	0.0374799	0.0982468	0.329822	0.157791	1.4237
RAPGEF4	0.428844	0.0770734	0.032968	0.135594	0.0365417	0.025861	0.0586271	0.0388446	0.0407296	0.0124949	0.0297323	2.18474
PRSS33	0.237359	0	0	0	0	0.0966028	0	0	0	0	0	0.493639
LRRN4CL	0.452038	0.0158163	0.0108247	0.0556508	0.0449926	0.0990636	0.0384989	0.021257	0.0222884	0.123078	0.0488113	1.25348
CNTNAP3	0.219157	0.012228	0.0143917	0.0563699	0	0.0564839	0.0164479	0.00314178	0.0296851	0.00303181	0.0216431	0.473374
CD200	2.92679	0.234237	0.128418	0.587417	0	0.356361	0.0452973	0.0315141	0.165094	0	0.361569	7.98703
TXLNB	0.355109	0.00419492	0.0229702	0.0506116	0.00795597	0	0	0	0	0.0326469	0.0258947	0.396437
HMSD	3.0101	0.0631809	0	0.165985	0	0.194562	0	0.16983	0.124133	0	0.281086	0.277627
CDK6	2.17546	0.32984	0.0846535	0.227969	0.0390957	0.295131	0	0.110826	0.174305	0.0534826	0.0636208	3.83311
JAG2	0.629855	0.0124854	0.0378372	0.00836767	0.0473571	0.0565345	0	0	0.0333893	0.0307294	0.0128439	0.114175
UTP3	1.81419	1.89417	0.991445	0	0	0	0	0	0.11021	0.985667	0	1.4836
NNAT	3.91589	1.22215	0	0.0187257	0.247075	1.0649	0	0	0.788477	2.30968	0.804124	0.0525133
DLX1	0.760215	0.0345931	0.0260805	0.0156821	0.0180672	0.0681943	0.0231894	0.0256078	0.0537009	0.0224327	0	0.210893
KIAA1456	0.0628972	0.00613029	0.00559408	0.00821719	0.0113894	0	0	0	0.0172782	0.0318037	0.00630632	0.0996631
LOC100507557	0.597745	0.0899755	0.0307896	0.0484534	0.127977	0.0468523	0	0.0604663	0.126795	0.233396	0	0.822782
CMPK2	0.176678	0.00847632	0	0.0170426	0.0346075	0	0	0.0227843	0	0	0	0.0258373
LRGUK	0	0.00782194	0.0214146	0.00786346	0.0148345	0	0	0	0	0	0	0.309971
PHKG1	0.406323	0	0.0210816	0.0154832	0	0.0275616	0	0	0	0.0798998	0	0.0469462
GPR37	0.885948	0.163966	0.00935369	0.130485	0.116564	0.0367136	0	0.0734734	0.192597	0.319058	0.168713	1.08269
ANO3	0	0.00359818	0	0.00723461	0.0244825	0.00643913	0	0.00967193	0.0912719	0.301374	0.20001	0
FAM57B	0.0966954	0.0879648	0.0301016	0.0663238	0.0208528	0.0787082	0	0.029556	0.0619804	0.0285215	0	1.87692
DIRAS2	0.328302	0.00481709	0	0.00968531	0	0.0431019	0	0.0129483	0.0271531	0.0374851	0.0297324	0.146833
KAT6A	0.519866	0.19891	0.0345674	0	0.147917	0.2495	0.00150444	0	0	0	0.0590805	0.714086
HLA-DQB1	0.495548	0.0397713	0	0	0	0.0948293	0.0967401	0.0356708	0	0	0	0.706956
RORB	0.340258	0	0	0.0259499	0	0.00991692	0	0	0	0	0	0.0337227
"CADM3,DARC"	0.0369745	0.0168179	0	0.0660979	0	0	0.0136456	0	0	0	0	0.797599
ANKS1B	2.29102	0	0	0.00712662	0	0.428509	0	3.24E-05	0.110129	0	0.106845	1.09194
SOX5	0.532977	0.0205225	0.00737219	0.0591824	0	0.0240966	0.029973	0	0.0303607	0.0768416	0.0415561	0.394033
DPY19L2P2	0.428784	0	0.0157038	0.00659059	0.0233116	0.0293296	0.0119682	0.0308382	0.0450376	0.0425126	0.0151741	0.241462
ITGA6	5.56999	0.12781	0.11498	0.260419	0.270116	1.40959	0.142244	0.464014	0.232661	0.0875893	0.76518	10.1717
SHC4	12.4693	0.545473	0.231667	0.277195	0.54277	0.988754	0.975539	0.58672	0.551046	0.130975	0.38592	3.65159
ACOT11	0.576062	0.0425942	0	0.0337732	0	0.0190733	0.0327073	0	0.0378709	0.0276463	0	0
SERPINA3	8.17878	0.61344	1.58547	0.383746	0.0775347	0.243917	0.0331721	0.0366316	0.115227	0.141398	0.0841153	10.302
HOXB-AS3	2.38698	0	0	0	0	0.499416	0	0	0	0	0	1.7262
FIBIN	0.828582	0	0.0296517	0.108161	0.0173196	0.0490292	0.0524316	0	0	0	0.112737	0.8908
LOC100506710	0	0.1415	0	0.150888	0.357337	0.118349	0.295886	0	0	0.908229	1.72423	0.835555
PIK3AP1	0.125564	0.00407953	0	0	0.00773669	0.0657042	0	0	0	0	0	0.310876
MCTP1	0.184223	0.0228438	0.00692809	0.00508828	0	0.026372	0.0123202	0.0228127	0.0214824	0.0593131	0.070569	0.34828
PODXL	16.8041	0.874501	1.27772	0.484023	0.69569	1.04712	0.129366	0.272921	0.720027	0.523121	2.60786	2.37663
FMNL1	0.153336	0.492842	0.0272668	0.0250333	0.0755695	0.0891387	0.024245	0.0669414	0.22443	0.542197	0.153734	0.2126
HS3ST1	2.96593	0.0535344	0.0146556	0.322911	0.0203053	0.0383208	0.0781858	0.0575598	0.150882	1.08313	0.132172	0.522181
HSPA7	0.316534	0.0123409	0.0112615	0.0165419	0.0156027	0.014723	0	0.0110574	0.0115939	0.0106703	0	0.062695
CHD5	0.087855	0	0.00275011	0.00201972	0	0.0106596	0	0	0	0	0.00620087	0.0122494
GNG2	3.4385	0.367331	0.248503	0.58371	0.32278	0.402899	0.201903	0.286662	0.333969	0.353468	0.108441	10.4385
MMP11	8.29634	0.357213	0.56418	0.31307	0.573221	0.442556	0.183835	0.203007	0.496072	0.546441	0.582694	2.56855
BMPR1B	0.53216	0	0.0148576	0.0363748	0.00686123	0	0	0.00972521	0.0203952	0.00938478	0	0
MIR600HG	0.200083	0.00975094	0.00889806	0.00653513	0.0246565	0	0.0158234	0.0174736	0.0274822	0	0	0.138705
TMEM63C	0.120721	0	0.0100211	0.0073598	0	0.0065505	0.00891017	0	0	0	0	0.133902
SCG3	0.067738	0.0061616	0.00843425	0.00619431	0.0116859	0	0.0299988	0.0331274	0	0	0	0.37567
HOMER2	2.49367	0.175216	0.223762	0.288456	0.116257	0.458659	0.199144	0.31416	0.348588	0.42404	0.32453	8.97819
GALNT12	1.0099	0.079148	0.043335	0.0556976	0.0450304	0.0566553	0.0192655	0.0425496	0.0669215	0.102651	0.0488523	0.29473
CLCN2	1.46961	0.0834227	0.0875615	0.106677	0.123978	0.0491735	0.0559506	0.0872993	0.159468	0.0931605	0.203192	1.143
GREB1	0.0258287	0.0140979	0.016081	0.002362	0.0267364	0.00420469	0.0114387	0.0240976	0.0463564	0.0426636	0.0217541	0.423494
SEMA3A	15.548	0.115139	0.164695	1.21842	1.02022	1.53386	0.390736	0.459396	0.480544	1.0129	0.711164	12.4167
FBXO32	3.66633	0.678463	0.339476	0.493871	0.259504	0.703995	0.527359	0.199227	0.369583	0.288381	0.360702	12.101
DRD2	0.680139	0	0	0	0	0.153919	0	0	0	0.0202817	0	0.143003
BCAM	21.1269	1.54956	1.53869	0.662779	1.80944	2.06575	1.35222	0.7797	2.1761	4.55016	1.31595	15.7845
PKP2	0.181314	0	0	0.00467167	0	0.0166335	0	0.0124921	0	0	0	0
IRF6	0.0510002	0.0185581	0.0127011	0.00466405	0.0879876	0.0166052	0.0225864	0.024942	0.0392285	0.312898	0.0944133	0
SULF2	0.267034	0.248566	0.221273	0.306325	0.145842	0.606787	0.061377	0.168782	0.298636	0.928508	0.3303	14.1882
HLA-DPA1	3.09564	0.236336	0.194674	0.150041	0.0261299	0.0818372	0.0576955	0.129282	0.567793	0.539966	0.211922	1.93541
RAB26	2.2485	0.0276459	0.189219	0.0557409	0.052432	0.0659542	0	0.107209	0.155844	0.06897	0	0.716329
RANBP3L	0.230093	0.124794	0.0220392	0.0323733	0.0152675	0	0.019596	0.06492	0.113451	0.465326	0	0.269938
ID2B	1.26738	0	0.026748	0.0393096	0	0.0699554	0	0.0525289	0.11018	0	0	0.297855
PARK2	0.448715	0.0485952	0.0407978	0.0349575	0.0829433	0.108146	0	0.0295463	0.126007	0.352943	0.168638	0.770255
KAZALD1	0.840847	0.0280717	0.0770507	0.0423409	0	0.0251836	0.0358255	0.0203061	0.0851675	0.148664	0	0.341336
SLC6A12	0	0.645542	0.0956728	0.06388	0.715598	0.0454822	0.0154642	0.357233	0.465637	2.0805	0.156879	0.038735
C2CD4C	0.580836	0.0257753	0.0176406	0.012956	0.0122205	0.0807202	0	0.0173209	0	0	0	0.0982089
C12orf53	4.63049	0.172575	0.182969	0.237846	0.280579	1.00629	0.115523	0.327587	0.294531	0.429193	0.337087	6.7822
MAPK8IP2	0.181609	0.0535942	0.0173951	0.025552	0.0361521	0.0556128	0	0.0170798	0.0179086	0.0659291	0.0392201	0.454689
NAT8L	0.0508497	0	0.0507162	0.00617188	0	0	0	0.0304473	0.0246133	0.0226527	0	0.71897
"LOC100507472,PCSK6"	0.0193797	0.00601704	0.0155281	0.00570225	0	0.015612	0	0	0.0759961	0.0466278	0.135932	0.319123
MTSS1	0.0555674	0	0	0	0.554356	0.238336	0	0	0	0.208662	0.0546103	0.434567
HRH2	0	0.0570401	0.0549375	0.0650073	0.0641582	0.014281	0.00971252	0.064713	0.227988	0.21735	0.135455	1.87611
PACRG	0.52635	0.0581664	0.0199046	0	0.193046	0.130115	0	0.19544	0	0.150879	0.044878	0.576235
PAX6	0.504856	0.00252328	0.00347034	0.0307109	0.00480049	0.0272185	0.0244715	0	0.0142548	0.0262662	0.0155516	0.0308399
"GLB1L2,GLB1L3"	0	0.0356934	0.0325835	0.016011	0.0112861	0.0106497	0.0289715	0.0159965	0.0167727	0.0308731	0.146928	0.603696
C7orf46	0.822585	0.0325679	0.0891581	0.0117423	0.0617641	0.0627071	0.0396373	0.043771	0.0987613	0	0.150477	0.772823
MEGF10	0.177823	0.018011	0.0211316	0.396519	0.043917	0.0460453	0.0187891	0.0345812	0.058015	0.16391	0.0555851	5.33081
FRMD5	6.12782	0.216998	0.362278	0.586566	0.241304	0.476101	0.173314	0.348216	0.283881	0.342458	0.34595	7.52918
RASSF2	1.43864	0.133137	0.101243	0.081793	0.203394	0.589	0.341585	0.0894672	0.22311	0.182265	0.23968	6.00717
COL11A1	32.7804	4.49504	1.7445	1.74902	2.51579	3.92994	2.29687	1.92407	1.08053	1.81535	3.06762	4.84671
CORO2A	0.382706	0.081709	0.0437647	0.0357141	0.0269492	0.0572172	0.0172946	0.0477461	0.0700882	0.0552901	0.0657822	0.90962
LOC100216479	0.323275	0.00775422	0.0106141	0.0467736	0	0.0138767	0.00943745	0.0208436	0.0437105	0.0603428	0.0478626	0.489489
LOC400043	0.314024	0.841143	0.0434475	0.303142	0	0.0568022	0	0	0.0894601	0.164667	0.440811	1.30616
DAPK2	1.85178	0.093208	0.0318958	0.0624685	0.0441915	0.231349	0.399285	0.0208784	0.109458	0.6656	0.119855	0.331465
ARAP2	0.431022	0.0211944	0.0145053	0.0372874	0.00502393	0.0189641	0	0	0.0597355	0.0272234	0.0572336	0.226119
ELOVL2	0.373928	0.317757	0.282379	0.0616723	0.423933	0.199562	0.339285	0.300562	0.246531	0.419483	0.524901	5.6522
SNCAIP	0.300528	0	0	0	0	0.0310326	0.0140619	0	0	0	0	0
RARRES2	1.35909	0	0	0	0	0.254398	0	0	0	0	0.144401	0.216621
PTK2B	3.49602	0.202809	0.209589	0.219744	0.191083	0.157771	0.126042	0.131396	0.215392	0.495662	0.385508	1.14464
TPRG1	2.23958	0.216239	0.00583535	0.130541	0.0821762	0	0	0.116473	0	0	0	0
C10orf11	4.10149	0.0775477	0	0	0	0.138775	0.185007	0.222812	0.218562	0	0	0
ATP1A2	0.193643	1.84631	0.337132	1.13099	0.216942	0	0.342559	0.0945698	2.10872	16.7002	0.596904	0.174451
ZMYND10	1.24251	0.0360743	0.0493785	0.0241772	0.0684137	0.0430375	0.0878094	0	0.135563	0.031191	0.0742201	0.0366534
ACSBG1	0.119486	0.0465847	0.0425101	0.0156106	0.0588976	0.0555768	0.0377977	0.0417396	0.0437648	0.0201393	0.0479223	1.01651
BST2	26.4396	24.976	3.19856	0.766958	3.01438	2.65938	0	2.55347	19.8424	18.3099	14.1705	0.566223
LOC645431	0.274185	0	0	0.0213769	0.0230397	0.0203916	0	0	0.0291776	0.0561552	0	0.0674473
SLC7A8	1.76931	0.109459	0.0881727	0.150763	0.0976651	0	0.0313594	0	0.586034	1.40266	0.298195	0.372819
KLRC3	0.106574	0.585754	0.331985	0.340075	0.192272	0.108436	0	0	1.36767	3.78432	0.461969	6.53352
IL27RA	2.41085	0.269613	0.252025	0.118425	0.153637	0.347683	0.0955621	0.138575	0.248974	0.206548	0.178488	3.17065
CSF1	38.4699	5.0999	2.61039	2.9035	3.77804	1.87733	3.68361	1.55407	3.17961	8.33168	3.45414	20.409
DTX4	0.431896	0.0456731	0.0281297	0.0282897	0.0905951	0	0.0132652	1.17E-05	0.122876	0.0956457	0.0168185	0.172478
FMO3	0	5.98398	0.414804	0.352564	3.5353	1.97387	0.110225	0.18258	0.761719	0.927877	0.249394	0
C8orf51	0.435316	0.0416854	0.0142648	0.0209533	0	0.0745976	0.0253669	0	0.0293717	0	0	0.412957
SLC25A18	2.5235	0.137793	0.188612	0.0923498	0.139371	0.147854	0.156523	0.123462	0.129453	0.166797	0.3402	0.364014
SNX22	0.118946	0.0240073	0.0328503	0.0300661	0.0340774	0.0107119	0	0.0483801	0.0677459	0.062442	0	0.856805
TLE2	2.08747	1.13447	0.42084	0.217919	0.250744	0.535337	0.0804534	0.0487402	0.668985	0.664354	0.279642	5.00782
C10orf114	0.718879	0.115957	0.0288752	0.0636127	0.0400064	0.0435945	0.0118594	0.113564	0.0137317	0.136767	0.13009	0.450357
"HLA-DRB1,HLA-DRB5"	462.538	0.291939	0.0694967	0.14	0.0240717	185.535	100.543	0.884102	0.285172	0	0.470068	9.03806
LOC100506779	0.331656	0	0.0137443	0.0298809	0	0	0	0	0	0	0	0.0324311
SNED1	0.190014	0.126464	0.12209	0.222339	0.169804	0.0622285	0.0585136	0.0440068	0.401617	1.11267	0.139697	3.6998
SOX11	0.64965	0.0374884	0.0784805	0.0554226	0.046003	0.169691	0.0053677	0.0533478	0.0186455	0.0114401	0.0272222	1.62662
PKIA	3.62154	0.0297896	0.129124	0.417199	0.0737463	0.252515	0.0801427	0.164359	0.0419799	0.025757	0.120008	3.54244
C1orf21	26.4174	10.4238	1.80166	5.32438	3.91051	3.07072	6.91461	4.49603	4.10429	6.90602	2.44998	67.7463
BAI3	0.0117759	0	0	0.0071467	0.0186934	0.028756	0	0	0	0	0	0.231933
FREM1	0.00417686	0	0	0.00763981	0	0	0.00462452	0	0	0.0147842	0.0135507	0.0989856
C9orf50	0.351737	0.0133325	0	0.0134032	0.0252846	0.0477179	0.0324529	0.0358374	0	0.0691661	0.0411458	0.121918
DDO	3.06493	0.0142219	0	0.0571899	0	0.112197	0.449833	0.420303	0.143851	0.104327	0.154791	1.09126
TXLNG2P	1.39549	0.0329721	0.0449937	0.27754	0.697461	0.00764986	0.0104053	0.0886286	0	0.427353	1.12076	0.701798
SUSD4	0.23754	0	0	0.0212665	0	0.227916	0	0	0	0	0	1.28063
ACE	0.112721	0.184244	0.0588841	0.0679024	0.291355	0.0440062	0.0689852	0.0326483	0.19834	1.08297	0.416921	0
SDC3	36.7218	2.68924	2.91423	2.07502	3.06775	4.66221	1.36499	2.06801	4.25235	6.81293	4.90085	28.8215
KNDC1	0.125727	0.0114375	0.00391392	0.00287455	0.00542272	0.0102339	0.0139202	0	0.0161178	0	0.00882443	0.0435792
RGL3	0.734637	0.0758414	0.0115344	0.0169428	0.111869	0.0576263	0.0820479	0.0226509	0.20421	0.313239	0.173919	0.0256861
ADAMTS17	0.125729	0.0191688	0.02628	0.00912587	0.0172155	0.0340932	0.0220963	0.00813356	0.108102	0.0499079	0.0373533	0.524712
REEP1	0.419188	0.0105169	0.0150809	0.0387668	0	0.00985813	0	0	0.0155261	0.0142893	0	0.0335838
CLDN4	1.01492	0	0	0.0146502	0.02818	0.215833	0	0	0.0901925	0.0200327	0.0207432	0.418843
LPHN1	2.52298	0.363804	0.324692	0.217083	0.224896	0.371305	0.110594	0.10011	0.317718	0.262178	0.263541	4.1676
C9orf106	3.72712	0.457702	0.183924	0.235704	0.226963	0.450769	0.292481	0.0870963	0.476694	1.0167	0.315085	2.33253
BCAN	0.930516	0.117642	0.0567951	0.0938001	0.0456501	0.0642791	0.018085	4.39E-06	0.013342	0.071226	0.101268	0.157473
CRLF1	0.554845	0.0279564	0.0191333	0.126449	0.0265094	0	0	0	0	0	0	0.679696
PLXDC2	1.33347	0.0630039	0.150853	0.0237404	0.0149409	0.309898	0.0767067	0.0211766	0.266423	0.0204159	0.315959	2.51996
PCYOX1L	3.02468	1.61415	0.598144	0.301531	0.245198	0.443555	0.247779	0	0	0	0.377096	2.41229
DMRTA2	0.732825	0	0	0	0	0.152051	0	0.0351366	0	0	0	0.0996119
SDK2	0.00789287	0.0345418	0.0147408	0.0162373	0.0327537	0.00963463	0	0.0192956	0.0292074	0.0232753	0.0443076	0.452637
SOX9	15.037	0.370025	0.970594	2.1299	0.421235	0.94797	0.366171	1.3089	0.141358	0.315849	0.243235	18.496
SLC47A1	1.88395	0.0625681	0.0653508	0.0830689	0.0602325	0.0227341	0.087473	0.256664	0.202404	0.129841	0.115855	0.0572144
C2	1.12816	0.151687	0.0667932	0.0572309	0.092891	0.0472124	0.0642183	0.0472771	0.23519	0.711571	0.310304	0.151481
GPR126	0.367098	0	0	0	0	0.0699805	0.0177043	0	0	0	0	0.0227354
LOC100861402	0.938327	0.0312555	0	0	0	0	0	0.161104	0.204203	0.0709785	0	0
FAIM2	1.01026	0.0620978	0.0793328	0.0957219	0.14132	0.0963095	0.0302308	0.0333835	0.0816748	0.246982	0.114985	0.668803
MAP7	0.664597	0.0930069	0.0572929	0.112232	0.152779	0.102713	0.158525	0.134347	0.123405	0.170362	0.287071	1.89794
TTC9	1.40099	0.269894	0.0974887	0.105516	0.0781985	0.167703	0.0273732	0.0806077	0.0950841	0.165296	0.185096	0.525601
BCHE	2.60066	0.0335867	0.0114934	0.151942	0.257477	0.812462	0.231029	0.361182	0.0532244	0.283142	0.181393	4.18069
CD24	7.62115	0.00953651	0	0.0958713	0.126602	1.89432	0.0232131	0.205072	0	0.0247367	0	2.76154
PARD6A	4.13236	0.268746	0.416915	0.161648	0.237844	0.421657	0.22059	0.146156	0.3065	0.466877	0.167806	2.78534
AMIGO1	1.0011	0.107714	0.120469	0.142144	0.188649	0.137631	0.141317	0.0222804	0.396913	0.466508	0.552408	2.51857
THBS4	2.02532	0.0839285	0.299181	0.102453	0.0341071	0.184843	0.0145923	0.229302	0.050688	0.0772014	0	0.272472
PLA2G16	25.4312	1.68991	1.23143	0.677311	3.06511	3.62723	1.42257	2.19632	3.30878	3.39369	2.63671	7.6449
VAT1L	8.75255	0.0527943	0.257722	0.229424	0.100124	1.73521	0.027773	0.199482	0.353736	0.109555	0.14085	4.39658
SDC1	61.263	3.58315	2.72588	5.02295	2.68023	2.36306	0.764466	2.39366	4.69618	6.16537	5.94759	8.24591
KCNMB4	2.32738	0.0741608	0.0336882	0.174093	0.187382	0.352773	0.0598846	0.0335241	0.0691695	0.0107836	0.01283	1.58073
PIGY	7.44446	0.00922949	0	0.000262706	3.21661	0.000190619	5.59315	0	0.000131945	3.69964	4.84753	0.335525
SLC8A3	0	0	0	0.0143094	0	0.0367076	0	0	0	0	0	0.412146
RNF125	0.0145334	0.0264424	0	0.00332284	0.00626839	0.0236598	0.00804552	0	0.0186314	0.042868	0.0102006	0.120901
EPB41L4A	0.275292	0.338088	0.0800466	0.0511675	0.0738614	0.0651677	0.0812792	0.0203417	0.103204	0.36811	0.167979	0.276331
PCDHB11	0.0362139	0.0378694	0.0290372	0.0281266	0.0033184	0.00200376	0.0746553	0.0240453	0.0394749	0.026627	0.0107799	0.914652
SEPP1	1.68952	0.295576	0.0959612	0.4829	0.474207	0.154314	0.47103	0.0696565	1.34042	4.8445	1.28101	3.31016
CLSTN3	4.1794	0.594088	0.59632	0.383219	0.198402	0.548578	0.05093	0.159685	0.837168	0.847527	0.76391	6.35296
KIAA1244	0.0253079	0.00396778	0	0	0	0.0222626	0.00643876	0.00355509	0.00745529	0	0	0.154298
ABCA13	0.109135	0.00774703	0.0120882	0.0178024	0.00629645	0.0138642	0.00808173	0.00892464	0.0342269	0.0658115	0.0783005	0.228929
CXCL16	21.3144	1.69209	1.11548	1.39646	1.48828	0.747073	1.06552	0.649605	1.83222	2.03628	1.59054	6.39489
MRPS30	0.379247	0.204022	0.0383665	0.072954	0.0612394	0.0751761	0.0980762	0	0.0780219	0.0926816	0.119656	0.774168
HYAL1	0.120026	0.296698	0.0978728	0.0721182	0.101773	0	0.130964	0.0478661	0.807781	1.66722	0.883161	0
APOD	0	0.0881746	0	0.079034	0	0.861912	0	0	0.124143	0.000136719	0.573414	5.77357
SPECC1	5.82917	0.496404	0.586818	0.499443	0.221777	0.622285	0.183994	0.186968	0.119492	0.234827	0.140599	2.80342
GFRA1	0.303864	0.0176436	0.0544635	0.0336827	0.0627387	0.0868286	0.0161051	0.0592823	0.0310794	0.00572067	0.0710912	1.02193
CHN1	16.2148	0.815385	0.838061	1.48201	0.447496	0.758276	0.957788	0.540851	0.633762	0.918572	0.338711	8.23197
SPTBN4	0.454834	0.0165533	0.0453731	0.00854839	0.0235609	0.0815025	0.0296757	0.0537808	0.0233563	0.0173348	0.0127874	0.284016
NACAD	0.527982	0.155012	0.0150339	0.10432	0.127956	0.231023	0.0723398	0.00784758	0.197889	0.184165	0.545172	1.51718
RTN4RL1	0	0.0381388	0.0174015	0.063902	0.0482193	0.0113751	0.0154725	0.0512582	0.0537455	0.428689	0.0196169	0.639392
SALL2	2.39621	0.36548	0.393447	0.45621	0.314999	0.376264	0.215558	0.0895605	0.249764	0.976624	0.375189	5.3679
KCNH2	1.03486	0.00840797	0.0115088	0.00632374	0.0479537	0.375054	0	0.015466	0	0.0438869	0.0518963	1.14692
ARHGEF3	3.39454	0.370767	0.330696	0.446153	0.149145	0.271592	0.0957669	0.0906481	0.205947	0.49544	0.225511	3.22204
STOX2	0.0666361	0.0129899	0	0.0326475	0.0287537	0.0232459	0.0105397	0.0174583	0.00610181	0	0.00668143	0.405824
TNIK	0.588197	0.0219045	0.0222778	0.0512637	0.00771707	0.114525	0.00999707	0.0225361	0.0472594	0.0844156	0.0664419	0.638866
SMAD9	0.422719	0	0.00974738	0.0322161	0.0472685	0.0436832	0.0260011	0.0287127	0.0100351	0.0369437	0.0109884	0.217069
ZNF334	1.1524	0.133803	0.163649	0.117721	0.0104228	0.0597716	0.0203657	0.0224896	0.0471182	0.0747615	0.103177	0.812304
CNIH2	4.00224	0.87177	0.51163	0.825412	0.430339	0.739578	0.289022	0.722049	0.442044	0.476398	0.48446	9.5634
TRIM47	0.90021	0.0587202	0.0277547	0.131205	0	0	0	0	0	0	0.187061	0
PDE4B	1.39086	0.154367	0.176102	0.271331	0.21425	0.230232	0.336552	0.0691621	0.333593	2.26517	0.269339	2.56773
PID1	0.206371	0.265962	0.0214145	0.165142	0.0890094	0.153983	0	0.126159	0.242515	0.993301	0.289692	1.38687
CCDC151	0.380874	0.0769967	0.0526966	0.0387027	0.0365055	0	0	0	0.0271261	0.0249652	0	0.0586746
LGI4	0.339166	0.0701234	0.0671895	0.0422974	0.146285	0.0376466	0.256034	0.0753962	0.0790548	0.145514	0.0649232	1.66723
GPR19	0.242594	0.110345	0.0503468	0.098605	0	0.0219407	0	0	0	0	0	0.859559
ADAMTS16	0.0433089	0.00393985	0.00539287	0.0277253	0	0.00705052	0.00959011	0.0211805	0	0	0	0.420326
FRZB	0.93653	0.0220337	0.0402131	0.132904	0.0835726	0.0131434	0.125144	0.0789684	0.0621002	0.53343	0.0453328	0.626849
KCNH1	0.270885	0.0712241	0.0330696	0.0801498	0.114545	0.0129703	0.058382	0.0714344	0.0544733	0.175823	0.193855	0.683522
MEIS1	1.08597	0.0485331	0.0717955	0.0686103	0.113459	0.150041	0.0358816	0.138222	0.0227976	0	0	0.904987
MFRP	0.48988	0.0607703	0.0623869	0.0305464	0.00960408	0.0362503	0.0123269	0	0.057092	0.091952	0.0156288	0.246984
LOC100131067	0.385685	0.0354312	0.182535	0.184606	0.123558	0	0	0	0	0.0941184	0.361123	1.97956
RDM1	1.59496	0.093493	0.0429339	0.15661	0.214369	0	0	0.168652	0.159291	0.195839	0.193633	0
SORCS1	0	0.00269367	0.00368718	0.0135407	0	0	0	0.014847	0	0	0	0.181816
FGFRL1	4.76471	0.197157	0.187306	0.333326	0.513876	0.681258	0.174861	0.287962	0.382717	0	0.406338	4.1642
SLC35F2	11.2556	0.934871	0.563353	0.5389	0.486924	0.908898	0.386011	0.534221	1.10767	0.457395	0.919398	1.70336
DDIT4L	0.0681366	0.0309923	0.0212112	0.124627	0.102858	0.15252	0.0565795	0	0.0655119	0.502443	0.0239117	1.79492
SLCO3A1	4.31452	1.58296	0.816856	0.775774	0.758825	0.083854	1.40289	0.483474	1.16181	2.82455	0.995278	12.271
IL33	0.711315	0.0150482	0	0.044581	0	0.0538597	0.0215885	0.0715202	0.0249968	0	0.0547427	0
ARNT2	3.82231	0.434705	0.457675	0.607312	0.239588	0.212852	0.101689	0.169798	0.199024	0.192689	0.298106	4.11632
CTSH	8.43628	0.412933	0.706529	0.207562	0.385406	0.587476	0.323079	0.237848	1.12226	0.80333	0.86475	1.39354
PCDHB14	0.666858	0.158756	0.0821209	0.135059	0.0870008	0.0445764	0	0.058741	0.0287208	0.103616	0.169002	0.702027
ZNF793	0.662004	0	0.106588	0.125466	0.168625	0.139351	0	0.111824	0.2345	0	0	1.40525
GNAO1	0.104905	0.488313	0.141961	0.115465	0.0593082	0.0974855	0.0320326	0.0732364	0.212873	0.483116	0.188785	1.41062
INO80D	0.228	0.0516884	0.038015	0.0466947	0	0	0	0	0.107948	0.181137	0.0143264	0.456208
KIAA1324	0.260045	0.0467631	0.030122	0.0110615	0.0365172	0.0147678	0.0133915	0.0295761	0.0232584	0.0499465	0.0169785	0.0251544
ZNF605	1.60877	0.120092	0.178372	0	0.247134	0.230789	0	0.147666	0.367276	0.169009	0.398011	1.1766
SPRY2	31.0834	2.78026	3.70788	3.47996	4.83502	5.39591	3.18313	3.5151	2.69389	2.4229	4.40883	60.0297
C21orf63	6.12341	0.420986	0.208887	0.692748	0.0646813	0.173181	0.0264535	0.286905	0.854513	1.24444	0.485838	1.57925
ID2	16.2675	0.570434	0.423869	1.83508	0.247271	0.262495	0.357046	0.613327	0.413414	0.0422756	0.150895	2.8814
MIAT	0.0464342	0.021134	0.015639	0.0274038	0.0433355	0.0408921	0.00695267	0.00767776	0.0422484	0.0222164	0.00592523	0.381363
TMEM108	2.54011	1.08619	0.0217643	1.00814	0.195139	0.371908	0.742401	0.837524	0.28407	1.61398	0.0981441	12.4516
ODZ3	0.378765	0.39453	0.114108	0.153602	0.20545	0.33315	0.0344846	0.0373431	0.0355759	0.00720922	0.0600063	2.49822
LRRK1	0.155658	0.00505728	0.00692242	0.0101683	0.00479549	0	0.0123101	0.00679695	0.0356338	0.00655904	0.00780374	0.1002
CDKN2A	187.682	4.49233	5.6917	3.61523	8.66472	29.1183	6.44436	6.99634	9.23544	3.33692	6.10266	3.01656
GRAMD4	3.2758	0.224013	0.262685	0.247597	0.277443	0.359975	0.244819	0.098309	0.2577	0.355693	0.239851	2.22944
ELOVL7	0.47886	0.0933475	0.0141966	0.0208535	0	0.0649633	0.0252462	0.041819	0.029232	0.0403552	0.0320088	0
SCRG1	14.0963	0.750468	1.69495	1.24484	0.853943	1.54444	1.46139	0.201725	1.05757	0.973319	1.27383	16.5823
NTRK3	2.56946	0.0939628	0.0976265	0.280101	0.0507959	0.265462	0.0248559	0.103746	0.153969	0.23786	0.0943124	2.06987
BAI2	8.42684	1.18867	1.0959	0.636169	0.840556	2.09727	0.499884	0.485346	0.980708	1.53871	0.712265	11.1151
PLEKHH2	0.0375487	0.00853841	0.0292222	0.0128764	0.00809633	0.034856	0.0203186	0	0	0.0216523	0.0601114	0.432875
NKX2-5	0.22711	0.0206604	0	0.0415402	0	0.0739453	0.0502901	0.0555348	0.0582297	0	0	0.6406
TLCD1	19.5472	2.76292	1.74793	1.18407	2.11753	1.41267	0.847726	1.80973	1.50506	1.48239	1.14645	5.41258
C12orf34	0.470207	0.0897202	0.157045	0.0579834	0.0717106	0.0344053	0	0.0689047	0.0541862	0.0166232	0.0593334	0.839979
VASH2	0.08	0.0152747	0.0278777	0.0255932	0.0193121	0	0.0247873	0	0.0287006	0	0	0.40707
SUCNR1	0	0.0238891	0	0.150291	0.0543674	0	0.347869	0.0385295	0.350113	2.57778	0.811054	0
C6orf15	0.0446837	0	0	0	0	0.836549	0	0.109264	0	0	0	4.89426
BTG2	3.02116	0.578211	0.616719	0.626575	0.726292	0.456894	0.274177	0.141293	0.338626	0.331129	0.486666	7.62215
TUBA8	0.0702162	0.127944	0.109144	0.0428102	0.2019	0.0571547	0.0259137	0.0572329	0.0900153	0.276149	0.131421	0.808155
HILS1	0.120974	0.163894	0.119516	0.0973842	0.183714	0.173224	0.157127	0.173521	0.273025	0	0.199306	3.40262
TTC39A	0.149236	0.0150826	0.0103217	0.0151626	0.0429097	0.0674876	0.0367163	0.0608196	0.0425132	0	0	0.78168
FAIM3	0.60016	0.077996	0.0854089	0.0313638	0.044375	0	0	0.020965	0.043965	0	0	0
RND1	0.426044	0.0645962	0.0353677	0.0389634	0.0980037	0.0231195	0	0.0347267	0.0728236	0.100533	0	0.0787598
LOC647946	6.0428	0	0.0997469	0.293888	0.13902	0.130396	0.43778	1.43042	0.206603	0.155505	0	1.18365
ZNF385D	2.7181	0.152383	0	0.355201	0	0.180697	0	0	0	0	0	0.19108
ABTB2	2.98079	0.355955	0.205294	0.241244	0.113774	0.307762	0.0389412	0.118256	0.112723	0.11781	0.216621	0.609556
LOC100506421	0.279958	0.0142543	0.00933671	0.0358515	0	0.125094	0.0346725	0.0383151	0.0401574	0	0.0219948	1.04809
FZD3	0.388866	0.0525106	0.0332679	0.0515741	0.05522	0.0397	0.0236246	0.0445729	0.0617954	0.0359651	0.0684649	0.494493
SLC6A6	6.65749	0.976943	0.646205	0.665132	0.648518	0.552913	0.593543	0.390466	0.861351	1.89257	0.549816	4.44693
CBX2	0.836173	0.129619	0.0823748	0.0698073	0.0351169	0.0165685	0.0450728	0.0871034	0.0782829	0.0480312	0.0714326	0.40921
VASH1	0.408596	0.210632	0.118717	0.21175	0.117487	0.155208	0.150796	0.0333045	0.139682	0.0964162	0.229426	3.13467
PCDHB4	0.417474	0.0380192	0.0218196	0.0626879	0.0230494	0.0208554	0.0182595	0.00504061	0.00132095	0.0378109	0.0694528	0.102062
FAM49A	0.644068	0.276193	0.0802002	0.247061	0.216176	0.119822	0.122246	0.0230216	0.557554	1.96464	0.736203	0.849054
MIR31HG	0.475997	0.0615305	0.0211685	0.0454982	0.0366519	0.094236	0	0	0.13076	0.160458	0.278127	0.179784
DMKN	1.91404	0	0.0873047	0.0254518	0.163739	0.328499	0	0.0421247	0.0883382	0.206061	0.0483645	0
ZFP2	0.297628	0.0676899	0.0347441	0.018943	0	0.0437659	0.0823809	0	0	0.0488769	0.0581523	0.258672
DTX4	0.41817	0.00880123	0.02405	0.0264727	0.0333572	0.0300675	0	0.0451558	0	0.0456206	0	0.0268053
APOE	24.8651	3.20095	1.56671	4.13457	2.46499	1.56224	0.897206	1.77297	15.036	51.2769	3.29286	6.68207
CHST2	10.4989	1.12814	1.4984	1.9607	1.09694	1.46281	0.663239	0.732408	1.88619	2.70309	1.26872	23.8673
C19orf57	0.737575	0.147592	0.0303373	0.0918356	0.0210129	0.0583799	0.0809121	0.0297886	0.0934961	0.172443	0.056979	0.348039
SPIRE2	2.36103	0.443144	0.189257	0.142866	0.137345	0.203277	0.18428	0.111883	0.181492	0.294482	0.303519	0.476837
DBP	3.63879	0.451474	0.64572	0.318856	0.339703	0.298664	0.214324	0.322051	0.334212	0.69716	0.40603	3.2963
KCNQ5	0.273101	0.00621203	0.0526287	0.130828	0	0.00555833	0	0.00834895	0.00875408	0.0241704	0.0287572	1.2261
KCND3	1.05282	0.339525	0.343354	0.0585854	0.115324	0.0138276	0.0616746	0.0340531	0.0642704	0.0854398	0.0714031	0.673563
HERC5	0.362405	0.028421	0.00778054	0.0285718	0.0431196	0.0406884	0	0	0.112143	0	0.0175422	0.242569
CFB	3.26296	0.606103	0.489271	0.335907	0.162103	0.0973399	0.189145	0.187984	0.32851	1.77373	0.743411	0.0473717
SESN3	2.06516	0.191153	0.257535	0.471832	0.17327	0.380383	0.172236	0.0950984	0.0498559	0.321196	0.461452	4.37752
NTRK2	3.83022	0.0835475	0.280595	0.168376	0.304244	0.23531	0.139684	0.132417	0.327318	0.319184	0.26296	0.163487
PTGFRN	4.33025	0.558959	0.421271	1.08347	0.559094	1.12729	0.173486	0.261243	0.470995	0.403359	0.329934	12.5317
ANO8	3.75328	0.236023	0.125744	0.166672	0.110038	0.345779	0.154441	0.0939475	0.179552	0.302764	0.202118	1.11044
ABCA7	3.85608	0.274096	0.225976	0.186015	0.208481	0.202536	0.100362	0.0465517	0.621742	0.226736	0.297524	0.677713
CRIP1	6.06744	1.81119	0.863455	1.06074	0.897235	0.846646	4.03064	1.05976	1.11118	22.4987	1.46008	0
MAP2K6	0.561362	0	0.0187823	0.0551806	0	0	0	0.036885	0.0773509	0.0355939	0	0.204799
LAYN	5.8573	0.039407	0.280604	0.117765	0.316575	1.01147	0.0926709	0.259774	0.185083	0.159525	0.225953	0.928383
FHIT	20.0002	6.94695	3.1082	2.23778	0.472631	2.58294	0	2.94728	6.23625	4.42458	2.72667	23.8416
C1orf94	0.362537	0	0	0	0	0.150702	0.0256228	0	0	0	0	0.352955
ALDH1L1	1.17193	0.0708577	0.13706	0.00671053	0.0379789	0.0716754	0.162488	0	0.037628	0.0692612	0.059639	0.0203475
GSTO2	0.453403	0.152044	0.0871211	0.0614343	0.413838	0.130441	0.113104	0	0	0.0412712	0.0491033	0.64975
PROS1	5.62364	0.642773	0.731496	1.0316	0.684268	0.655479	0.383448	0.454651	0.848344	1.52372	1.19548	8.87605
RASGRP3	0.74861	0.0158627	0.031589	0.046401	0.00899866	0.0849159	0	0.0109155	0.0114452	0	0.0125324	0.0495137
SH3PXD2B	8.52573	0.608695	0.653874	0.972203	0.315827	0.337089	0.335407	0.271525	1.33098	1.53657	0.84241	4.42306
ISLR2	0.0305621	0.00463356	0.0126853	0.0465839	0	0	0.0112791	0.0124554	0.0130598	0.108177	0.028601	0.437864
FZD1	11.9908	0.797964	0.688756	1.12581	0.825447	0.567981	0.57377	0.658079	0.460047	0.835037	0.559601	1.96249
RHBDF2	1.67603	2.17745	0.411159	0.923392	0.40528	0.837287	0.0378598	0.326096	0.350721	0.515019	0.926935	6.11904
ZNF204P	0.678079	0.0140176	0.0671626	0.0493285	0	0.0125423	0	0.0565242	0.138294	0.181825	0.0216311	0.405966
KIAA0040	0.17381	0.736367	0.179346	0.197468	0.49778	0.031247	0.0824297	0.136332	0.0984254	0.462938	0.148191	0.26635
CPEB1	0.548664	0.0484919	0.0398249	0.068014	0.054987	0.0520671	0.0393446	0	0.0273327	0.0419272	0.0698394	0.27498
TRIM45	3.1243	0.148308	0.176753	0.146506	0.141145	0.272213	0.157182	0.246786	0.163144	0.208009	0.245895	0.3308
VPS37D	0.811569	0.0881901	0.0663505	0.252742	1.00152	0.287701	0.181985	0	0	3.85E-05	0.466844	1.48434
FAM211A	0.503636	0.106928	0.0499172	0.145888	0.0579404	0.0273668	0	0	0.150683	0.378363	0.0942861	0.605306
KCNAB2	1.78139	0.215789	0.247268	0.0880689	0.178022	0.580466	0.112427	0.0465884	0.195397	0.570286	0.267447	2.244
STX1B	0.0553246	0.0303558	0	0.0305167	0.0668137	0.0620044	0.0122508	0.0349252	0.0141849	0.0261098	0.0155323	0.506256
"NCRNA00185,TTTY14"	2.5796	0	0	0.246233	0.487369	0.60245	0.151244	0.0690779	0.393954	0.161171	1.7775	1.03321
SOX15	0.768265	0.0635363	0.0434843	0.127747	0.0301285	0.142126	0	0.0853971	0	0.0824089	0.0980445	0.968347
IRS2	19.7676	0.497621	0.820343	2.3452	0.617031	2.30576	0.411874	0.563122	0.45419	0.125368	0.556498	13.0122
NEURL1B	2.8762	0.408826	0.248712	0.365329	0.0643096	0.0808382	0.147427	0.0814012	0.290202	0.942624	0.411229	0.184655
WWTR1	44.9127	16.7062	17.4089	6.74765	9.49142	9.09514	4.21305	3.40542	5.59335	11.6733	21.3737	101.976
C3orf15	0.205217	0.00892821	0.0183335	0.0089756	0	0.00798847	0.0217352	0.0120001	0	0	0.0137779	0.0408288
FAM184B	0.565541	0.128995	0.138483	0.136056	0.147702	0.12568	0.136295	0.0916136	0.091128	0.136315	0.139494	2.12734
OSBPL6	2.23918	0.0590199	0.143212	0.273647	0.109712	0.293226	0.0871721	0.0785968	0.124239	0.114331	0.119024	2.09362
"GBGT1,RALGDS"	6.98306	1.36536	0.966102	0.904798	1.59453	1.73536	1.07375	0.73874	1.0865	1.65626	0.722059	13.0784
UNC79	0.00866848	0.0237425	0.0240668	0.0157029	0.0298389	0.014075	0.00978376	0.0110033	0.039056	0.015129	0.0183371	0.491867
LIMK1	7.9336	2.52651	3.25822	3.23325	3.36208	4.44187	1.92703	2.036	2.58313	2.78853	3.18173	62.2625
"LFNG,MIR4648"	3.6642	0.335516	0.389671	0.306633	0.366225	0.198431	0.169098	0.245798	0.660753	0.632769	0.407904	1.79708
SLC4A8	0.585656	0.102336	0.0498013	0.175278	0.0413462	0.0910925	0.0241071	0.0885763	0.0820353	0.150889	0.0917024	0.962948
NT5M	6.14678	0.34969	0.460055	0.319287	0.526146	0.971587	0.402363	0.461062	0.392885	0.601903	0.354176	2.68556
HS3ST3A1	2.96128	0.929945	0.657767	1.0002	0.466461	0.6294	0.157565	0.27252	0.341513	0.408233	0.6839	12.5407
MSI2	16.25	2.0415	1.68325	1.44043	1.84562	2.34049	2.11812	1.23368	1.99551	1.73594	2.4838	19.9777
NFATC1	1.05712	0.0599795	0.0650126	0.0418312	0.258373	0.107245	0.202695	0.111848	0.424347	0.995253	0.392953	0.0228619
PART1	0	0.0661141	0.0136289	0.0831175	0.137839	0	0.0242384	0	0.0561242	0.307123	0.143303	0
INPP5J	0.249211	0.0843635	0.0602488	0.0294996	0.106436	0.052512	0	0.0518741	0.135979	0.0750878	0.113199	0.484533
RAB42	0.373349	0.00725035	0.0198495	0.0364463	0.0137505	0.0379967	0.0524863	0.0579602	0	0.0188075	0	0.195388
FAM13C	0.832578	0.0635689	0.0811727	0.178856	0.121116	0.106123	0.0999342	0.0735892	0.10288	0.647598	0.0704244	1.15241
NDRG4	3.45737	0.32735	1.02104	0.312298	1.93E-05	0.0976779	1.91E-05	1.93E-05	1.94E-05	1.91E-05	0.084225	3.84048
WBSCR27	1.17006	0.130063	0.0808593	0.106871	0.132204	0.113653	0.102722	0.0776907	0.260269	0.432576	0.341578	0.330351
TMEM26	0.108479	0.00379555	0.0207814	0.0076314	0.0215944	0.00679229	0	0.0204048	0.0213949	0.0787622	0.0234272	0.0578473
MRPS6	412.153	46.4648	55.9241	40.9348	54.1329	58.3501	59.4042	69.8405	55.31	45.4085	36.9938	102.954
BEND5	0.554722	0.0721508	0.170949	0.018133	0.204979	0.771193	0	0.36639	0.0508379	0.140365	0.111335	4.70824
CA13	0.506593	0.0360529	0.0422994	0.0339059	0.0213206	0.0553012	0.0273652	0.0151095	0.0316855	0.0534385	0.0346953	0.154208
STAP2	2.9406	0.89068	0.329294	0.37347	0.658035	0.572972	0.210688	0.41872	0.399193	1.04173	0.329373	1.21711
ANO1	0.29773	0	0.0226946	0.0272427	0.0640523	0.0528856	0.155039	0.0291365	0	0.0140583	0	0.664417
NAV2	2.47266	0.242028	0.161668	0.424575	0.200506	0.362911	0.219332	0.409087	0.25422	0.2336	0.159362	1.23471
STK33	0.958369	0.0616377	0.0843143	0.134068	0	0.0367676	0.0250056	0.0923898	0.0968727	0.0668667	0.0504465	0.811937
SLC12A7	1.07275	1.71974	0.145568	0.458571	1.02894	0.434711	0.275915	0.185997	1.47104	2.13575	1.24957	0.913294
TFAP2A	3.72861	0.679224	0.430294	0.429726	1.25686	0.661193	1.51191	1.1976	1.16741	0.884853	1.06514	13.7337
CASZ1	0.336023	0.0705159	0.0448135	0.0253173	0.0191038	0.0225335	0.00612932	0.0406165	0.0354894	0.0261295	0.0464022	0.0767666
GNAZ	0.812394	0.106487	0.0857291	0.0818522	0.0395655	0.224083	0.228532	0.112299	0.235497	0.378837	0.257693	1.20565
MGP	19.1418	0.870675	0.758406	1.76651	0.600439	2.63462	1.734	0.340416	0.892336	1.68356	1.22137	8.92694
COL22A1	0.792802	0.404226	0.23808	0.184342	0.0546372	0.239572	0.0427311	0.15611	0.0563347	0.141355	0	1.56365
TMTC4	0.901048	0.132017	0.165166	0.150028	0.226469	0.28464	0.132016	0.231539	0.200958	0.238217	0.220047	2.86492
FUT8	173.859	9.2004	5.35846	19.2657	20.7829	21.108	12.1249	10.7286	14.7648	23.1528	17.5814	68.6025
IFITM10	1.43912	0.187794	0.271756	0.124064	0.335809	0.528115	0.143681	0.201916	0.378076	0.320121	0.264956	3.74528
LINC00340	0.763743	0.0395354	0.0811742	0.0805474	0	0.0353751	0	0.0531353	0	0.0512754	0.0610059	0.229108
ZNF214	0.733743	0.106969	0.0209154	0.0844926	0.0434695	0.0683654	0.148787	0.0205363	0	0.0594562	0.09432	0.16303
ARHGAP27	0.570585	0.0222574	0.0685494	0.0279695	0.0527637	0.0398308	0.0541781	0.0299139	0.0470485	0.115469	0.034345	0.152652
EPB49	1.83976	0.0768064	0.046726	0.0772141	0.0485531	0.503892	0.0207719	0.183517	0.192422	0.0442723	0.172073	1.34569
PAPLN	0.311049	0.074114	0.018445	0.0541907	0	0.0180859	0.00820034	0.00905575	0.0569739	0.0578653	0.0393397	0.0971389
OASL	0.795559	0.0849723	0.0387864	0.0854612	0.0537395	0	0.167258	0.0761685	0.0986985	0.183756	0.0424119	0.142326
FLG	1.30665	0.0115532	0.0324844	0.0170372	0.0244689	0.640005	0	0.0765267	0.0109931	0	0.0231205	0.887296
PER3	2.70797	0.24555	0.136117	0.272963	0.314962	0.440778	0.609811	0.102709	0.173446	0.32928	0.248286	1.2844
STRBP	1.77749	0.274361	0.111038	0.225585	0.14195	0.223494	0.136611	0.0740375	0.140625	0.341594	0.211646	0.868686
MDGA1	1.28115	0.357059	0.270802	0.250041	0.378312	0.375166	0.161351	0.0821118	0.143646	0.162509	0.362022	1.59002
EMID2	0.0147699	0.154524	0	0.332811	0.0127407	0	0	0.0180584	0.416461	1.36168	0.966007	1.18074
ENC1	30.3909	2.02529	2.25446	1.78155	2.32264	9.47766	0.966171	2.3808	0.832006	0.375894	1.10174	26.0706
SEPN1	21.6853	8.17472	8.67305	8.2094	12.745	9.43011	6.22628	2.91502	6.35067	11.8027	11.0794	112.156
OSBPL10	6.90262	1.19658	1.09858	1.13371	0.689061	0.959199	0.548695	0.369069	0.729713	1.1475	0.766734	9.6571
WBSCR17	0	1.00053	0.0676346	0.416592	0.0819942	0.0442119	0.0150341	0.0996133	0.191486	0.242825	0.13343	1.3693
RASSF5	0.29983	0.0235575	0.015556	0.0401097	0.0111688	0.0316179	0.028671	0	0.0803209	0.0305529	0	0.358461
APLP1	33.9993	3.26372	3.06025	1.57378	4.23487	7.83657	3.63375	1.78497	2.75241	3.85468	4.46203	19.9466
SCD5	259.226	14.1945	11.7762	6.27979	21.0903	21.2833	19.5514	12.9926	10.6194	9.25216	23.5639	35.7593
SYNE2	6.04402	0.394155	0.438727	0.654988	0.192044	0.121722	0.198081	0.209467	0.411268	0.693168	0.431081	0.678622
HOXB3	0.717858	0.0140621	0.0384965	0	0.0466863	0.371122	0.0130217	0.244946	0	0	0	1.65802
S100A16	72.2778	6.5221	8.73444	15.2726	16.8464	12.0595	1.67524	14.0319	12.2547	10.1676	16.4934	139.393
PNMAL1	2.42758	0.463441	0.383745	0.660522	0.0759656	0.346953	0.131091	0.123052	0.0645117	0.0742158	0.21192	5.07043
NPTXR	0.508191	0.371669	0.261373	0.138071	0.56544	0.395673	0.277248	0.342185	0.151061	0.130335	0.113714	3.88863
ARC	0.649559	0.0618395	0.0470256	0.103613	0.0651537	0.0614802	0.0669002	0.0738772	0.116193	0.392102	0.233256	0.314161
LOC100130275	0.7073	0.048314	0.0411509	0.0755551	0	0.0806986	0.036588	0	0.127093	0.11697	0.0463885	0.426855
FLG	4.79647	0	7.54E-06	0.0130906	0.03524	2.5345	0.00734174	0.0965878	0	0.0185853	0.0259715	2.12012
FZD5	0.279208	0.0206743	0.0121282	0.0445373	0.0112023	0.0264268	0.0215674	0.0238167	0.0249724	0.030644	0.0364593	0.234069
RASD1	1.82934	0.110129	0.184244	0.0904779	0.121916	0.161059	0.148927	0.098675	0.0724737	0.0952211	0.0396788	0.313527
JAKMIP2	1.73212	0.472192	0.0851729	0.421119	0.165075	0.243386	0.291326	0.228079	0.337321	0.822624	0.497185	1.75894
FAT3	0.913266	0.0379804	0.0742638	0.0600508	0.212525	0.165188	0.157152	0.173418	0.0492472	0.084506	0.11984	0.859761
C1orf213	1.32308	0.107242	0.13101	0.147743	0.0268078	0.157021	0	0.104725	0.220789	0.129193	0.120881	2.15245
KIAA1958	0.599607	0.037915	0.0622604	0.0340423	0.0719424	0.0813662	0.073856	0.0204016	0.0400341	0.0983361	0.0234065	0.392828
PAQR4	7.6381	1.20071	0.887669	0.953463	0.484375	0.576133	0.646978	0.881909	0.939147	1.2227	1.16138	2.68983
MGC45800	0.0360792	0.0779516	0.0168472	0.0358048	0.00778049	0.0220258	0	0	0.011563	0	0.025323	0.205063
NEK6	53.044	7.42159	9.15798	3.94129	5.36471	7.76324	2.71439	4.75116	7.22612	5.34623	4.69617	55.6053
C18orf1	0.12195	0	0.0217502	0.00795837	0.0301348	0.056777	0	0	0	0.0186673	0	0.0803659
PLXNA4	0.308399	0.0617219	0.107526	0.253839	0.117054	0.0100412	0.163897	0.030165	0.126515	0.116437	0.0173166	2.77076
C1S	7.78228	2.65189	2.06401	1.43804	1.46183	0.639923	0.633407	0.341499	1.93064	5.27632	1.57334	4.71161
CDO1	2.8085	0.131569	0.243391	0.153266	0.21657	0.355802	0.0618295	0.256486	0.509009	0.7297	0.502832	0.555366
ABCA3	6.2963	0.878647	0.901663	0.484951	0.833377	1.40729	0.627903	0.951807	1.90431	2.43516	1.70171	5.66479
PITX1	6.67844	0.0524719	0.807005	0.189574	0.294025	0.703905	0.734173	0.176305	0.139862	0.0340266	0.364046	1.2834
GAA	10.6078	3.42687	3.95876	1.73009	2.36299	4.73159	1.06635	0.902037	1.98834	2.56305	1.73807	36.2918
KIAA1522	1.50526	0.0870728	0.128947	0.106677	0.0358692	0.21929	0.0183609	0.0304664	0.0641718	0.140333	0.0935324	0.272196
SEL1L3	11.003	4.57611	1.89486	1.8265	0.702401	2.20946	0.632065	0.463776	1.34819	1.54756	2.3525	7.21205
BMP8A	0.0190464	0.00693057	0.0142299	0.0104511	0.00657181	0.0186038	0.0253049	0.0186293	0.00488331	0	0	0.34857
CCNJL	0.765144	0.571618	0.33266	0.218601	0.133988	0.259463	0.101353	0.132937	0.117354	0.165894	0.130824	2.52913
ITPKA	1.28562	0.103195	0.0627793	0.11527	0	0.102595	0.11164	0.0308207	0.0646325	0.0594838	0.070772	0.139802
EFNB3	0.987768	0.218406	0.170831	0.175652	0.106508	0.0670021	0.167083	0.0838672	0.492446	0.809317	0.250354	1.4456
CDH24	2.76427	0.345421	0.472756	0.329764	0.556487	0.551488	0.396905	0.375108	0.508183	0.684684	0.520394	4.43548
SLC6A10P	2.67621	0.451377	0.875047	0.386014	0.515162	1.01609	0.338063	0.312929	0.425974	0.439721	0.497953	8.80929
POU3F3	3.89358	0.0875141	0.134402	0.132093	0.091369	1.09818	1.30071	0.283585	0.271574	0.0464621	0.442766	7.58754
SPSB4	0.411383	0.101338	0.0350768	0.180334	0.0323997	0	0.0722496	0.0688821	0.0899777	0.421619	0.0458012	0.893284
PCDH9	0.680482	0.0372611	0.0863041	0.262184	0.140538	0.0440298	0.223234	0.181849	0.0646191	0.0817733	0.173812	2.64451
GAS1	0.110393	0.0358662	0.0294562	0.0937471	0.0136038	0.0128368	0.139685	0.0192816	0.303258	0.316313	0.177101	1.48683
LTBP4	16.6487	3.30823	3.06691	1.28688	0.979027	1.73174	0.889207	0.494958	1.09626	2.18452	0.93253	3.1176
MDK	57.5606	4.97174	10.2215	6.92695	8.98926	9.92457	6.52372	6.56474	4.39775	5.49745	2.90854	88.9601
TMEM150C	0.41754	0.0335973	0.0173961	0.0652889	0.048203	0.100051	0.0309349	0.060105	0.0630216	0.145022	0.0690081	0.374558
LAT2	0.4251	0.0253143	0.060638	0.0421136	0.0240041	0.0374356	0.0308092	0.0281844	0.10702	0.112974	0.0390618	0.629731
OSGIN1	6.42368	1.72704	1.10021	0.982758	1.11236	0.544258	0.634542	0.437948	0.795946	0.676191	0.871554	4.1717
TRIM47	8.02327	0.429885	0.537054	0.189893	1.12209	0.697862	1.24382	1.37354	0.682194	2.15848	0.712895	0.0819777
PLA2G6	2.03038	0.18677	0.28472	0.167604	0.311034	0.241302	0.144835	0.324966	0.276417	0.280129	0.212113	1.58989
KANK1	4.42337	0.627103	0.700523	0.78485	0.530175	0.51799	0.411617	0.597719	0.29916	0.272539	0.476363	4.56891
HS3ST5	0.234914	0.00741124	0.0101445	0.00745058	0	0.0764861	0	0	0	0.0138581	0	0.0903636
NCALD	0.19661	0.0762731	0.0306022	0.0337135	0.1166	0.0700159	0.079568	0.087866	0.0472587	0.101487	0.0336268	0.510933
PDE9A	2.93836	0.564137	0.376297	0.569347	0.445309	0.718848	0.195252	0.137674	0.902911	0.933459	0.772219	4.5984
SMOX	9.29388	1.29802	1.3409	0.813253	1.14596	1.14111	0.764478	0.540727	1.20018	1.26781	1.05392	5.25621
EFEMP1	48.4541	1.6968	2.97426	5.32991	2.33418	7.00199	1.39922	2.09072	3.54232	1.79928	4.89762	33.7508
ZNF883	2.15184	0.101227	0.354596	0.188757	0.191973	0.112552	0.0571651	0.0637978	0.263353	0.0820854	0.0976628	1.24721
COL8A2	0.535949	0.0310264	0.024268	0.0222794	0.00840581	0.103114	0.0215778	0.0238282	0.0874454	0.103474	0.150467	0.0135105
CERS4	5.16731	1.96337	1.78319	0.335903	1.31456	1.65271	0.965837	0.689156	1.06134	1.2822	0.458293	14.4055
ADAMTS4	0.187546	1.36733	1.31338	0.897158	1.44027	1.02868	1.03971	1.45562	0.856854	0.837375	1.0989	19.6612
VLDLR	3.98359	0.401102	0.540447	0.409398	0.24683	1.31419	0.388406	0.41381	0.201322	0.0882953	0.259408	7.44513
ALDH5A1	1.56804	0.0800947	0.167063	0.199384	0.195298	0.23889	0.111407	0.112773	0.161244	0.0791457	0.188331	1.59275
C6orf192	3.32928	0.255463	0.346665	0.342516	0.153822	0.338995	0.108199	0.269769	0.375043	0.368964	0.0912144	1.73856
ASAP3	5.30014	0.646363	0.608375	0.506531	0.726208	0.664609	0.14287	0.295124	0.972599	0.990638	0.74813	1.14881
SHC3	0.148924	4.99E-07	0.00798179	0.0422954	0	0.0210627	5.32E-07	0.0280503	5.14E-07	5.16E-07	0.0205059	0.288273
CCDC125	0.876975	0.0641459	0.0481368	0.122368	0.154514	0.128132	0.0808601	0.0446465	0.235497	0.273665	0.187835	0.550807
CDON	0.554025	0.0466024	0.0520661	0.0562198	0.0450859	0.0893421	0.092589	0.0255611	0.0603036	0.049333	0.0660318	0.521812
FBXL19	0.841008	0.253219	1.05743	0	1.81607	0.459741	0	0.57068	0	0	1.91979	2.81933
ARHGEF37	0.111156	0.012136	0.0166126	0.0296496	0.0159807	0.0376993	0	0.0453011	0.0237496	0.0327865	0.0390084	0.372406
SMO	2.78124	0.245759	0.946616	0.60873	0.547216	0.848224	0.332188	0.172624	0.606681	0.710451	0.892444	9.45576
ROBO2	0.849055	0	0.00990934	0.125817	0.0228819	0.0518212	0.140974	0.0366429	0.013603	0.0543196	0.0297893	0.391291
CARNS1	0.450159	0.0301802	0.0137695	0.0101126	0.0476972	0.0900169	0.0734643	0	0.056708	0.0260946	0.0465708	0.0459977
TRPV4	0.13526	0.0796252	0.0998322	0.0412329	0.0518563	0.0128952	0.0175403	0	0.101551	0.25727	0.166409	0.241625
LRP8	2.19933	0.261133	0.151477	0.305701	0.208119	0.225268	0.216174	0.226132	0.178493	0.348173	0.272862	1.0235
FLJ46906	1.95977	0.495013	0.554156	0.332463	0.139339	0.608178	0	0.0658314	0.138052	0.28403	0.226748	3.45919
FAXC	0.466616	0.0195651	0.0533176	0.0648955	0.0698874	0.0457078	0.0382595	0.0472329	0.0166124	0.0101927	0.0303172	0.401216
NRARP	1.02757	0.0545294	0.0533142	0.101806	0.0295466	0.0836421	0.0758466	0.0418783	0.0219552	0.0404125	0.0240408	0.118724
FUT8	29.125	2.41833	2.58553	4.28997	3.16769	2.28555	2.56673	1.83521	2.37913	3.86642	2.06691	15.0692
C10orf58	2.67026	2.06295	2.28041	2.69617	1.78011	0.804183	0.913978	2.23959	3.98718	14.0156	3.50869	14.2707
AQP11	0.59522	0.135369	0.105882	0.106926	0.275061	0.121124	0.0706086	0.129954	0	0.025081	0.0596813	0.707362
TRIM14	2.94449	0.688051	0.393518	0.560248	0.184535	0.324516	0.215076	0.118888	0.523559	0.544951	0.702966	2.57928
TLE6	0.501488	0.0124973	0.0513194	0.0545977	0	0.0971889	0.0304203	0.0671857	0.0352229	0.0648341	0	0.595958
EZR	116.09	10.2494	7.65987	11.9202	7.04412	8.60327	6.00078	8.07034	10.3947	8.853	9.26004	19.5916
LINC00473	0.744419	0.020615	0.0282178	0.191795	0	0	0	0.0628329	0	0.128533	0.0360695	0.187951
NHSL1	1.48056	0.621441	0.157898	0.32873	0.571389	0.676945	0.374727	0.224226	0.271219	0.245518	0.181673	0.94371
PPL	0.497666	0.155517	0.0438217	0.0868967	0.0391736	0.0271273	0	0.0765957	0.314933	0.42812	0.0940485	0.21063
ABHD8	3.39695	0.87106	0.628055	0.147806	0.850378	2.56455	0	0	0	1.14964	1.1888	3.89172
IL1RAP	5.09978	1.37759	1.51935	1.83148	1.18995	0.915212	1.33473	0.96413	0.630997	1.28267	1.42225	14.9303
BEGAIN	0.401848	0.0690463	0.0420039	0.0617	0	0.0274568	0.0186727	0	0.108113	0.118529	0.0710288	0.163697
SSX2IP	4.99499	0.383358	0.402348	0.497614	0.247685	0.597555	0.326947	0.220054	0.182663	0.30968	0.411259	1.13336
MPV17L	0.107354	0.0184813	0.0267351	0.0637869	0.0175672	0.0816427	0.11252	0.0994158	0.00917423	0.0253316	0.0285875	1.21966
GCNT2	1.55539	0.0226475	0.0155	0.0604703	0.182479	0.686543	0.0337879	0.121753	0.0638303	0.161468	0.209636	1.01794
BDKRB2	0.237778	0.0423662	0.0193098	0.0899244	0	0	0	0	0.0132616	0.232035	0.0290514	0.0430465
MANEAL	2.23337	0.446735	0.244359	0.263087	0.321336	0.492894	0.386097	0.39496	0.178609	0.281298	0.410178	1.96006
NACAD	1.10574	0.26332	0.196956	0.165386	0.345487	0.393552	0.249966	0.220807	0.354763	0.540792	0.408983	2.18913
SLC19A1	1.35265	0.355526	0.661455	0.180115	0.52177	0.212298	0.0568848	0.272196	0.445275	0.970628	0.82326	2.16482
FOS	11.3861	1.14768	1.34653	1.64825	0.67674	0.241626	0.586892	0.414783	1.46782	3.42727	1.13103	1.41109
LOC100130987	1.18115	0.356519	0.19462	0.207262	0.0905428	0.210822	0	0	0.53824	0.979769	0.365366	0.721218
LSR	0.14902	0.22047	0.347929	0.0687896	0.36367	0.123493	0.293211	0.458041	0.38208	0.351643	0.321797	3.05073
FBLN7	1.81952	0.037479	0.208527	0.201205	0.106614	0.204958	0.0698189	0.07152	0.363502	0.173701	0.324708	0.880282
PLS1	1.99582	0.134291	0.0909946	0.297009	0.0630363	0.246994	0.0539383	0.0893453	0.109294	0.100588	0.099466	0.835057
NBEAL2	0.499307	0.142868	0.106011	0.0530311	0.130458	0.125867	0.0984734	0.0972686	0.150976	0.19554	0.201953	0.476682
ANKRD6	0.590266	0.101202	0.229312	0.113212	0.0715441	0.107972	0.0606333	0	0.128613	0.238218	0.206373	1.30433
AHNAK2	0.381708	0.128032	0.0429485	0.0539933	0.355596	0.157045	0.0605693	0.177231	0.285716	0.197355	0.2153	0.079942
DNER	0.294313	0.248765	0.0697988	0.0605268	0	0.444134	0.0177317	0.089909	0	0	0.144518	1.52565
ROM1	3.47693	0.248078	0.254677	0.436441	0.6469	0.277466	0.754823	0.250061	0.262195	0.643489	0.478512	1.41784
CSRP2	34.5534	4.55276	6.48115	4.10211	5.47027	9.02336	4.36244	3.8847	2.49847	3.60203	3.8011	51.9823
CECR7	2.21689	0.0493141	0.306159	0.0178662	0.209399	0.333834	0.0727788	0.0238853	0.218977	0.0977478	0.0822698	0.112562
P2RX7	0.255323	0.0404606	0.0537927	0.0700573	0.0230196	0.014481	0.0492432	0.0108756	0.0342104	0.153073	0.0624337	0.324014
FBXO41	0.26552	0.0172526	0.041355	0.0303729	0.0818336	0.169855	0.0420236	0.0116015	0.0729354	0.0512851	0.106475	0.565388
THRB	0.136287	0.00262202	0.00358913	0.0316349	0	0.0187707	0.0127658	0.0281947	0.0221721	0.165855	0.0242783	0.071939
SHROOM3	1.07274	0.18083	0.2133	0.175997	0.23717	0.278871	0.699086	0.206865	0.0759114	0.0948038	0.178129	3.3362
TNFAIP2	2.50312	0.569255	0.380686	0.304665	0.852513	0.296773	0.526002	0.431438	0.335775	0.665893	0.429125	1.02708
ZNF835	0.450882	0.0369822	0.070871	0.00743456	0	0.0661821	0.0540123	0.0198808	0.0833866	0.0383712	0.0684805	0.270555
ACBD4	2.29634	0.378274	0.291261	0.295859	0.218097	0.261637	0.231287	0.170433	0.503038	0.646543	0.400429	1.66083
RASSF4	3.13209	0.882233	1.20398	0.646982	0.873542	1.08444	0.907157	0.76689	1.51397	1.97357	1.52273	10.9049
GPC1	99.8872	42.1505	29.8378	19.7969	22.1099	34.0187	11.1925	9.97245	18.3132	15.4261	30.3358	191.629
EPHX1	33.4372	7.16113	4.90053	3.56056	3.61796	2.9949	3.25025	4.03983	7.52851	11.6539	4.95115	10.0926
PLXNA4	0.832993	0.496133	0.427484	1.26217	0.511617	0.0968114	0.704357	0.40211	0.369803	0.530398	0.285803	11.3236
KIAA1549	0.138985	0.0445397	0.0756819	0.0586721	0.0175444	0.0248331	0.00375246	0.02477	0.0476153	0.0677253	0.0571019	0.617961
GFPT2	5.59123	0.744061	0.247343	0.943551	0.546707	1.10374	0.130549	0.693144	0.264528	0.295624	0.268966	3.70503
IFI44L	1.21782	0.26398	0.317415	0.333346	0.315681	0.0593575	0.0798713	0.110813	0.278135	1.3381	0.546241	0.604733
DHRS11	5.02239	0.918088	0.953579	0.570898	0.604665	0.815062	0.489743	0.233803	0.850417	0.786681	0.83961	3.30609
HES6	3.9153	0.68854	0.658813	0.156278	0.21976	0.650341	0.300977	0.56861	0.305167	0.318803	0.402141	1.67735
CEND1	7.22367	2.0814	0.555469	0.763281	1.34059	1.52269	1.2427	0.914866	1.18063	1.59591	1.05038	1.8754
PTPRN2	1.11131	0.239345	0.280784	0.467461	0.181563	0.330419	0.128845	0.183815	0.520388	0.337026	0.379879	4.30371
MAPK8IP3	1.90271	0.350508	0.450339	0.260682	0.410515	0.773484	0.258124	0.247	0.425943	0.585537	0.40533	4.10974
ACSS3	7.96441	1.19333	0.873403	0.911593	0.624036	0.925474	0.433754	0.621344	1.14254	2.61611	1.58044	0.986976
MEX3A	0.181423	0.101449	0.0999041	0.105276	0.114344	0.198758	0.0772428	0.102358	0.0178874	0.155946	0.102047	1.50896
B4GALNT1	4.65318	0.658282	0.375374	1.07592	0.547717	0.484113	0.390758	0.256741	0.410177	0.552495	0.818777	3.52947
PION	1.75646	0.217106	0.431288	0.247102	0.33829	0.264961	0.122315	0.374265	0.336758	0.323154	0.431086	2.2053
TPPP3	1.69358	1.12468	1.55064	1.41218	0.644521	0.121636	0.386048	0.703237	1.08556	11.5124	1.39845	2.14092
TRIM2	1.37457	0.28146	0.207129	0.348814	0.200346	0.261095	0.110984	0.0980432	0.231336	0.379687	0.350941	1.7592
RCOR2	0.496068	0.20822	0.237595	0.0872641	0.164526	0.139804	0.126774	0.0933304	0.0733943	0.135095	0.133944	1.1903
OSBP2	2.75169	0.80937	0.419883	0.333239	0.528149	1.24131	0.813306	0.575646	0.336832	0.167881	0.392059	5.05066
CDH8	0.649126	0.226287	1.26365	0.152464	0.418517	0.739599	0.449272	0.279297	0.18665	0.143107	0.97579	9.15372
FAM131B	1.09654	0.460714	0.477344	0.481982	0.576794	1.51482	0.36552	0.40357	0.723358	2.02665	1.1508	7.90994
PIK3C2B	0.0948264	0.0634298	0.041675	0.0357092	0.0336819	0.0317828	0.00617586	0.0136399	0.0643578	0.0460685	0.0156603	0.34802
TUBB4A	0.200042	0.13854	0.140118	0.0609429	0	0.495836	0.0299754	0	0	0.119786	0	2.31474
ALDH3A2	33.9582	3.15234	2.35798	4.76955	2.17646	1.42913	2.42389	2.7162	2.66276	4.76936	2.09231	2.50843
ASTN2	2.49338	1.04433	1.13754	0.683094	0.975272	0.759401	0.383845	0.489009	0.657688	0.723706	1.0475	4.54697
SOX13	5.48872	0.916054	0.943831	0.745476	0.833208	0.510751	0.736944	0.399652	0.551308	0.59978	0.74707	3.20162
FLRT2	0.156959	0.0192412	0.0225749	0.215541	0.192848	0.04919	0.00669076	0.0664974	0.147196	0.94109	0.415669	0.20942
NDOR1	0.600004	0.381982	0.280106	0.129761	0.0723272	0.191791	0.0125799	0	0.0140439	0.143128	0.31667	0.53326
DPYSL3	45.7034	4.97256	5.29862	6.03099	1.64271	5.86056	1.61448	2.29922	3.11291	3.30004	3.96799	20.4462
RPS4Y2	4.15506	0.138967	0.342392	2.84997	4.69112	0.348161	0.608874	0.522957	0.939999	3.02791	4.80336	6.01502
EFNB2	10.7565	1.24288	1.81489	1.88577	0.562515	0.603158	0.711041	1.16725	0.976477	0.898687	1.2546	9.59028
GUCY1A2	0.0984752	0.0106083	0.0112939	0.00355462	0.0223541	0.0442971	0.00860725	0.0253471	0.0232549	0.0703229	0.0218262	0.0898244
CCDC152	1.62626	0.00869245	0	0.105996	0.184847	0.0654346	0.650177	0.0379055	0.0249193	0.0230026	0.133406	0.219238
SPON1	0	0.0761886	0.0625727	0.0344668	0.0866935	0.054537	0.0370907	0.102432	0.0322099	0.0592877	0.0705395	0.696705
PVRL1	4.71614	0.676549	0.69822	0.615802	0.607253	0.376017	0.450892	0.392486	0.311158	0.314084	0.474688	2.42044
"H19,MIR675"	0	0.37606	0.330912	0.594088	0.135845	0.0160232	0.130769	0.120339	0.883245	2.62446	0.0552655	4.0939
PHLPP1	5.32907	0.657424	0.62559	1.03874	0.632158	0.667649	0.328878	0.55619	0.749639	0.600419	0.777663	4.50983
KIF13B	1.85446	0.406141	0.545381	0.357334	0.283247	0.504175	0.246864	0.263987	0.445315	0.531644	0.494057	4.30665
B4GALT5	8.97613	2.21763	2.17407	1.77197	1.77618	2.60681	2.40781	1.75317	1.04163	1.74918	1.44264	21.0534
LOC202781	0.91628	0.218673	0.195546	0.179189	0.180307	0.216447	0.138602	2.19E-05	0.247673	0.313528	0.320676	1.05426
FBLN1	101.585	27.7905	12.9566	8.57902	17.7895	17.7126	15.9613	9.01655	14.5066	34.6275	15.5894	0.569957
PTN	78.9613	13.9355	26.5556	21.279	20.7622	7.57043	28.3975	19.7868	18.0148	39.5159	20.6431	313.33
DUSP15	1.44035	0.24023	0.179256	0.0877692	0.165622	0.703405	0.212594	0.234771	0.123038	0.283202	0.202152	2.13014
PHF15	1.96768	0.427241	0.250768	0.241729	0.320425	0.319939	0.20095	0.257553	0.270179	0.354653	0.390265	0.650927
NR3C2	0.465194	0.0142344	0.0329291	0.148563	0.00674867	0.0689448	0	0.0286965	0.0100295	0.0276921	0.0329472	0.754247
OPRL1	0.28761	0.0498216	0.0974109	0.0438252	0.0901691	0.100303	0.0606364	0.0167398	0.0175521	0.306927	0.0733655	0.271749
C2orf72	0.159272	0.0445819	0.0381399	0.0168069	0.0422741	0.249316	0.0542591	0.0299588	0.0314126	0.0578204	0.0515947	1.00221
PLCD3	16.0732	3.28169	2.84661	2.36982	2.5324	2.16754	1.399	1.52871	3.21591	3.66484	3.01373	9.65272
COL15A1	0.0100337	3.27566	2.12976	3.4165	1.65277	0.399785	0.265662	0.11041	3.75521	21.4008	1.8725	4.0588
SOX4	1.92713	0.438282	0.643951	1.79073	0.358402	0.503693	0.450224	0.389095	0.657294	0.92826	0.657685	14.3768
FOXO1	1.03003	0.213887	0.102237	0.153587	0.103017	0.139738	0.140487	0.127761	0.076549	0.211353	0.0523878	0.382899
PTGDS	13.611	5.19739	6.31244	2.64837	0.831591	2.22289	0	0.589322	8.32434	27.0766	3.71061	7.22036
TTYH3	22.2934	6.59762	6.17834	5.07715	4.56356	4.67064	2.12738	2.65901	6.58745	7.80115	5.60307	31.646
PLXNB1	3.36733	0.476919	0.644377	0.349301	0.396798	0.922461	0.368626	0.451081	0.472904	0.740472	0.804189	2.79417
ECHDC2	2.00336	0.257133	0.128241	0.265298	0.196561	0.352517	0.0372139	0.122692	0.128645	0.0591987	0.0704328	0.372378
METTL7A	6.50604	0.414514	0.340402	1.4811	0.338575	0.136966	0.74517	0.737065	1.06045	1.87329	0.531299	4.80146
SLC16A1	24.9289	3.00432	3.33475	4.30315	3.88409	4.22525	1.84598	2.47745	1.84847	3.07951	4.07996	17.6104
DAPK1	0.417454	0.0135628	0.00464107	0.109079	0.00643025	0.0303391	0.00825332	0	0.124235	0.00879505	0.167429	0.361743
KIAA0895	0.469014	0.114232	0.0947446	0.133301	0.0765731	0.103222	0.112322	0.0775228	0.146312	0.314054	0.142409	0.738211
BCL2L11	0.22918	0.0769801	0.0379255	0.133589	0.0325241	0.0343227	0.0313087	0.0115246	0.0725032	0.290121	0.0396951	0.468063
FBF1	1.7395	0.191943	0.255442	0.215955	0.180408	0.201194	0.182351	0.0960615	0.163675	0.224322	0.234368	0.7117
ST3GAL4	27.3532	7.57121	5.90911	3.00521	5.21975	5.21608	5.63927	5.14481	5.93083	6.57535	5.97842	27.826
TRAF4	30.2237	8.20688	7.56902	3.62669	7.92455	6.11668	4.51754	4.72299	6.06755	5.40112	7.22408	32.1161
KLF5	2.9973	0.107632	0.0900331	0.216407	0.1134	0.781148	0.0291101	0.112511	0.101117	0.108573	0.129176	0.38276
PDE8B	0.706804	0.124441	0.0797033	0.121943	0.0439871	0.133194	0.149624	0.0657073	0.231016	0.794185	0.177232	0.195416
CREG2	0.188487	0.030419	0.0416376	0.0815479	0.0192296	0.104628	0	0	0	0	0	0.722608
E2F2	0.707092	0.0765769	0.0524092	0.107777	0.0435675	0.0205553	0.0465994	0.0617512	0.075539	0.049658	0.0708981	0.0700256
OLFML2A	1.90451	0.376963	0.342631	0.356735	0.240906	0.147081	0.136394	0.0903564	0.315898	0.969009	0.265183	0.227714
SLC4A3	1.24735	0.225182	0.251439	0.270609	0.389538	1.06801	0.214948	0.263443	0.303314	0.434633	0.776492	5.27358
DUSP6	16.3895	5.39577	3.90015	4.23157	4.42748	6.03893	3.41564	4.12004	4.60922	3.11837	5.52096	42.323
SEMA4B	4.5893	0.686145	0.511802	1.09196	0.39998	0.702422	0.784356	0.615146	1.14296	1.99424	0.640342	4.79646
MICAL3	1.81585	0.508132	0.59284	0.401126	0.668748	0.623861	0.397404	0.294819	0.441052	0.521616	0.814056	4.12644
MMD	4.31357	0.545553	0.41941	0.657517	0.524399	0.695439	0.472967	0.401763	0.505511	0.620322	0.545516	2.40618
SLC48A1	2.26552	0.555478	0.335884	0.313053	0.45075	0.538335	0.523741	0.396861	0.403178	1.7982	0.327121	0.856507
FP588	0.188491	0.022366	0.0408195	0.0374745	0.0141388	0.0733788	0.0181472	0.0200398	0.0315183	0.0580151	0.0345123	0.420413
MAP3K4	1.94716	0.505938	0.35731	0.614049	0.484269	0.482892	0.399131	0.400953	0.365729	0.447319	0.540019	4.08354
LRFN1	0.480348	0.109244	0.175922	0.0689603	0.236528	0.357185	0.0629547	0.167623	0.12303	0.0503147	0.0997734	1.93911
CA11	4.06735	0.371336	0.641208	0.422386	0.920461	1.2487	0.352921	0.995198	1.44428	2.45842	0.86317	4.28074
SUV420H2	1.61447	0.454558	0.471047	0.250571	0.402663	0.327164	0.157293	0.198511	0.435853	0.52287	0.370363	1.65856
"TUBB2A,TUBB2B"	113.18	42.7937	31.0196	18.4013	34.5142	36.3052	24.7665	34.0054	30.0491	22.2432	35.1506	184.52
RPS4Y1	65.2306	2.33582	4.5111	46.1492	67.339	9.66871	7.74143	8.63853	13.3773	56.7601	80.7981	82.036
ST6GAL1	0.0691403	0.161289	0.241135	0.543246	0.668028	0.995086	0.26608	0.188363	0.354541	1.2409	0.479201	5.57254
LOC154860	0.738774	0	0	0	0.0208772	0.21603	0	0.0221536	0	0	0	0
NFASC	12.6797	5.29949	2.98169	0.743555	4.16586	5.24284	3.01893	1.65304	2.70029	1.59746	3.45831	8.72727
KIAA1324L	0.0313143	0.0323201	0.0292771	0.0500509	0.0405633	0.0382473	0.398576	0.114812	0.196896	0.0553966	0.175924	2.25244
CHST10	7.15892	0.949813	1.01723	1.06197	0.803418	0.725854	0.568245	0.748025	1.08749	1.14847	0.940171	3.29072
"ADHFE1,C8orf46"	1.87499	0.430047	0.548203	0.397871	0.211302	0.507532	0.139438	0.428733	0.722172	0.295328	0.293055	0.871488
TMEM229B	0.437218	0.300683	0.172612	0.214523	0.119573	0.14751	0.011801	0.130369	0.368936	0.528436	0.344291	1.16769
B3GNT5	0.667836	0.0151867	0.0692982	0.198496	0.0192011	0.10872	0.0123218	0.0544333	0.214035	0.22325	0.453111	0.925933
ALDH1A3	0.245002	0.0401972	0.0106275	0.0471438	0.05082	1.69558	0	0.0417395	0.0218824	0.0201392	0	5.94539
FAM189A1	0.0839105	0.302476	0.513016	0.374821	0.216644	0.204889	0.0107352	0.101264	0.62651	0.590149	1.53935	3.2426
"KGFLP2,LOC643648"	0.863954	0.115861	0.428883	0.363587	0.402134	0.822758	0.166313	0.141816	0.474115	1.03628	1.30396	5.64955
PLD5	1.22704	0	0	0.0071347	0.0253645	0.911938	0	0	0	0	0	1.55332
SIM2	0.00929805	0	0.0282688	0.00445392	0	0.0244188	0.011738	0	0.0141384	0	0	0.295138
LRRK2	0.333268	0.0128467	0.0117199	0.0854975	0.0487268	0.0230041	0.00518942	0.0115167	0.0482636	0.0665927	0.0197389	0.169677
ITPK1	48.5518	9.68113	7.17777	5.2402	6.24828	8.21552	4.16414	4.01697	6.98258	5.03534	7.42413	23.1411
CYFIP2	1.82039	1.7301	1.06871	0.73923	0.819734	1.48736	0.488947	0.87862	1.59777	1.8194	2.23118	7.21727
TYRO3P	3.35791	0.605182	0.512803	0.376625	0.655841	1.13457	0.911914	0.232392	0.4874	0.448519	0.978312	3.77723
ITPKB	3.30515	0.562023	0.570845	0.71121	0.428713	0.618746	0.426267	0.445845	0.807129	1.18591	0.772717	3.20051
TLN2	1.18594	0.140685	0.136133	0.132863	0.156235	0.260828	0.0856552	0.120301	0.154164	0.167513	0.212261	0.47962
LRRN3	6.21067	0.754262	0.405049	1.5134	1.63888	1.29245	2.50773	1.51503	0.69545	0.940064	0.732831	12.2191
C10orf32-AS3MT	1.83755	0.155677	0.247226	0.239405	0.260495	0.400175	0.335124	0.272937	0.309776	1.02623	0.621781	0.976803
ARHGAP33	2.79488	0.419833	0.487783	0.478263	0.393909	0.384771	0.211844	0.171644	0.33375	0.259278	0.324268	1.93779
SLC39A8	4.60493	0.140963	0.300202	0.571704	0.371493	0.50409	0.267016	0.589624	0.318622	0.447137	0.338422	0.548979
ADAMTS13	0.408527	0.0507905	0.10106	0.0576539	0.0768653	0.133323	0.0302591	0.0244463	0.0373003	0.192545	0.114725	0.193945
"C1R,C1RL"	31.3667	9.45705	10.2082	7.03854	6.08134	1.36946	3.74833	2.79306	11.2765	28.7222	5.61701	15.9169
ZNF462	2.40451	0.364884	0.393169	0.621271	0.439198	0.364409	0.444821	0.396129	0.554632	0.654408	0.433258	1.24057
RFX2	1.1419	0.409227	0.378913	0.163656	0.200494	0.241489	0.183812	0.198054	0.314006	0.643664	0.503594	0.613733
P4HTM	11.8861	4.23398	3.5218	1.72339	3.12949	2.75876	2.43117	2.42416	4.54369	4.95616	3.1494	15.1561
KIAA1467	1.21021	0.241873	0.342492	0.255734	0.316348	0.492543	0.456789	0.246609	0.235069	0.216343	0.360357	3.59736
KATNAL2	0.715231	0.0697466	0.191686	0.0987945	0.0742411	0.148729	0.0639531	0.0468635	0.195939	0.215323	0.216443	1.02917
FAM125B	0.75344	0.331344	0.6714	0.770555	0.302696	0.208108	0.201326	0.223697	0.719728	0.361162	0.51959	4.84839
"BACE2,MIR3197"	4.88049	4.0357	2.29852	1.95358	1.99623	2.39082	0.492725	1.63234	3.23292	3.74548	3.06108	12.7061
NIM1	0.433071	0.35129	0.236639	0.300956	0.499054	0.265222	0.180246	0.297484	0.130252	0.0878447	0.318642	2.40946
CELSR3	0.513891	0.0364269	0.0914006	0.033568	0.0921078	0.119508	0.103449	0.0326347	0.0598903	0.0629855	0.0655906	0.419949
RALGAPA2	1.12981	0.257887	0.228155	0.217554	0.211571	0.275925	0.175124	0.193507	0.246298	0.386019	0.266016	1.2061
CHST11	12.2982	3.14362	2.78133	2.79745	1.481	1.92944	1.55665	1.95353	2.0192	2.52542	2.46315	14.7514
TIMP3	14.3471	9.65058	5.20694	7.27635	8.44025	5.08043	3.19292	4.04446	5.64274	10.7665	6.44817	33.2191
CCDC136	0.388513	0.0657768	0.0711422	0.092259	0.111431	0.137492	0.106896	0.0542299	0.0710914	0.066054	0.0928013	0.66336
DTNB	2.30241	0.444128	0.46402	0.562158	0.225561	0.620411	0.306451	0.194583	0.469318	0.799531	0.358828	3.7444
KIAA0195	6.97502	1.57761	1.65879	1.30484	1.46766	1.9306	1.38906	1.0593	1.62031	2.24694	1.94443	7.78927
TYRO3	7.33013	0.95997	1.82704	0.948298	1.70308	1.6905	0.698765	1.09787	0.952964	0.961552	0.983553	7.6284
ZFPM2	0.281083	0.0432583	0.0442495	0.0858814	0.0370911	0.0742856	0	0.049095	0.0451841	0.0236882	0.112734	0.469678
VWA5A	2.21734	0.388101	0.376772	0.814654	0.474925	0.13136	0.111029	0.254972	1.05458	1.21268	0.405643	2.03183
SCAMP5	1.15479	0.205461	0.360363	0.201683	0.438618	0.684134	0.381147	0.196571	0.119076	0.155175	0.123537	3.38143
ANKRD13B	2.70613	0.592008	0.533878	0.529413	0.498489	0.619349	0.380164	0.168422	0.353006	0.355745	0.476064	2.75604
PCDHGA8	73.0026	38.6476	34.9067	31.4171	27.5783	29.5632	18.7985	20.9371	30.3022	32.8662	33.1222	269.894
TMEM2	3.48074	1.1618	1.26571	1.6418	1.71295	1.07757	1.95201	1.39113	0.97839	0.854451	1.50841	14.9237
DCLK1	0.139475	0	0.0308319	0.0537491	0.0427183	0.0568345	0.0137073	0.0454106	0	0.029214	0.00171962	0.496958
PKD1P1	3.12492	0.657741	0.664524	0.453319	0.637329	0.528601	0.378984	0.186012	0.537639	0.904612	0.800156	0.774708
SAMD10	1.35006	0.140738	0.183869	0.125395	0.109177	0.291899	0.146817	0.135107	0.31166	0.208606	0.0930719	1.05013
REEP2	6.78989	4.19479	2.47622	1.4026	2.78169	4.7522	1.84059	1.93462	3.10695	3.54518	3.18943	17.0254
A2M	7.50984	4.85568	1.84875	2.36593	5.53786	5.70236	0.868735	2.05827	1.34531	3.77728	1.3531	8.2631
AKR1B1	28.9563	8.26349	6.3249	5.92416	5.94434	4.53309	4.08454	6.08493	7.7187	9.07482	7.05341	25.0437
ACACB	0.401723	0.0577425	0.0516786	0.0692122	0.042118	0.0317946	0.0486528	0.0238785	0.0438152	0.0752848	0.068539	0.0473868
KLLN	0.050763	0.147542	0.15757	0.256841	0.131626	0.229624	0.168401	0.107952	0.146457	0.195541	0.106271	2.89952
KIAA1244	0.0809961	0	0.0094568	0.00694549	0.0087349	0.0725086	0	0	0	0.0119472	0.0213216	0.166612
TOX	0.426514	0.0553368	0.0252487	0.204474	0	0	0.137401	0.049582	0	0	0.0569264	1.02584
PODXL2	6.8454	3.16406	2.54033	1.94439	2.01138	2.51173	2.87826	1.59996	3.10278	2.95136	3.18364	20.4804
HRH1	3.1363	0.277964	0.41992	0.365	0.192493	0.411189	0.0336958	0.148842	0.208086	0.394989	0.213612	0.0703272
PLCE1	0.817108	0.138464	0.143853	0.192445	0.128396	0.1007	0.126478	0.104683	0.146446	0.430695	0.146922	0.327655
FRMD4B	0.400296	0.163481	0.157674	0.39393	0.28188	0.0864456	0.063314	0.279645	0.2513	0.183088	0.252288	2.38449
C5orf65	2.15868	0.374915	0.291935	0.246305	0.117063	0.176683	0.251102	0.0577685	0.254401	0.323358	0.171385	0.131658
NFE2L3	2.15806	0.187739	0.212924	0.113242	0.142417	1.67023	0.0652834	0.158601	0.332594	0.139137	0.562835	3.85866
PILRB	1.14724	0.141556	0.283191	0.149606	0.0963693	0.116917	0.0795154	0.117077	0.0716091	0.291863	0.156823	0.420426
ATP11A	1.00096	0.208536	0.238903	0.245683	0.342729	0.294612	0.498152	0.160876	0.182738	0.522273	0.458278	1.75631
COX10	1.334	0.207834	0.195848	0.205485	0.282101	0.252342	0.161533	0.119144	0.103927	0.264648	0.230502	0.555228
CMIP	3.13471	0.927927	0.929376	0.518757	0.429216	0.886709	0.319576	0.538177	0.511766	0.48139	0.572743	3.36657
RAB3IP	0.584862	0.117054	0.0426306	0.122837	0.0701019	0.191098	0.0758099	0.10488	0.121545	0.0852285	0.190129	0.618281
B3GNT1	14.2798	3.91936	3.913	3.7066	3.48659	4.24808	2.85223	3.47552	3.78652	4.45436	3.86563	28.3276
SIPA1L1	2.35453	0.683747	0.607794	0.79333	0.48761	0.541557	0.385411	0.368315	0.562258	0.412811	0.865049	4.38669
CAPRIN2	4.36564	0.664005	0.619126	0.538681	0.596029	0.646586	0.448435	0.375368	0.384729	0.348803	0.515436	0.759033
RBM38	7.55061	0.969178	1.38369	1.06862	0.719686	0.988419	0.927708	1.00842	0.910525	0.946116	0.771887	5.22317
IRF2BPL	6.50328	1.83949	1.80432	1.3415	1.11507	1.83747	1.06785	0.250804	1.15038	2.17912	1.34434	6.639
FZD7	18.273	1.19105	2.35019	1.95934	2.71837	6.14518	3.21294	2.09277	1.71477	0.722213	1.44802	21.4845
ZNF680	2.01319	0.170092	0.317956	0.438778	0.318005	0.435676	0.421174	0.258003	0.258028	0.36325	0.466609	2.86607
"ANGEL1,VASH1"	0.87158	0.551956	0.390644	0.396713	0.396145	0.654352	0.386862	0.259514	0.433131	0.890114	0.626628	6.11045
GPR153	0.759389	0.369666	0.543225	0.301482	0.361435	0.423651	0.35162	0.310608	0.537173	0.973602	0.552622	3.49241
DFNB31	0.876717	0.328549	0.307413	0.224506	0.286474	0.448954	0.240073	0.200181	0.206887	0.436323	0.430917	1.58342
TPST1	1.35691	0.204514	0.338061	0.19971	0.322493	0.695013	0.0643325	0.151148	0.148175	0.241933	0.766207	1.58085
DOCK3	0.0627377	0.0242292	0.0248737	0.0475284	0.0272873	0.0220701	0.0150093	0.0110494	0.0115856	0.031424	0	0.292127
ETV4	8.47575	1.28145	1.39372	2.21363	1.20094	0.881302	1.00287	0.602073	1.26953	1.53755	0.753492	7.83028
FAM63A	2.38324	0.683233	0.652117	0.606227	0.716546	0.7385	0.671333	0.562153	0.653638	0.936874	0.735067	4.42347
SLC37A4	5.53666	0.845127	0.883134	0.89056	0.717141	1.30865	0.66805	0.834985	1.19857	1.19258	1.19781	3.51925
PLXNA2	0.554493	0.0868578	0.109744	0.102429	0.0886943	0.0971198	0.13623	0.0273521	0.109938	0.136374	0.0994455	0.529497
MFSD3	5.79015	1.45925	1.69027	0.812944	1.33089	2.49164	0.788399	1.17115	1.51316	2.32548	1.55048	8.04628
MRAP2	1.51954	0.057773	0.0952704	0.378798	0.0879975	0.0415152	0.112482	0.0311777	0.0653869	0.0601777	0	0.620833
PDE4D	0.323739	0.191198	0.0629214	0.137709	0.19055	0.32091	0.167499	0.063782	0.0735647	0.220878	0.117167	1.02036
SEC14L2	6.64685	1.71306	1.18193	1.90471	1.45856	1.92773	1.05281	1.2143	1.62475	1.90116	1.8901	6.98266
SPATA6	3.82877	0.765592	0.695527	0.827863	0.922367	0.706467	1.12696	0.495982	0.736394	1.95399	0.871123	5.04556
KIAA1024	0.104858	0.0810888	0.137114	0.0862885	0.126563	0.187705	0.0925271	0.140982	0.0403323	0.0741658	0.147194	1.30761
IVNS1ABP	13.4109	1.38962	1.88535	1.76269	1.35722	2.3002	2.76528	1.43002	1.19601	1.80925	1.8163	8.1117
DCC	0.111317	0.0112578	0.0462291	0.113176	0.0569336	0.00671543	0.0822089	0.030263	0.052882	0.340685	0.0405337	0.554769
BAIAP2	7.90375	1.05592	1.96609	0.837424	1.64309	1.17494	0.79293	1.12716	1.3736	0.589926	1.30618	4.61184
ATAT1	2.59018	0.658113	0.696438	0.653705	0.678709	0.656716	0.745581	0.804671	0.805155	0.807381	0.775146	4.43022
TSKU	4.68252	2.3858	2.30695	1.94362	1.75679	2.16738	0.852452	1.17669	1.72731	1.60863	1.64359	14.9894
CYTH1	1.95296	0.647082	0.699044	0.365519	0.413941	0.46165	0.57393	0.143282	0.429936	0.773957	0.545418	2.06133
FAM59A	0.33855	0.148483	0.0978464	0.309494	0.114717	0.177148	0.0736153	0.0443414	0.123992	0.22826	0.110309	1.71838
ZNF365	0.412905	0.0845154	0.186846	0.136886	0.0623314	0.168049	0.16001	0.126209	0.0529333	0.0243583	0.130413	1.71799
SLC29A4	0.451651	0.547975	1.44859	0.333852	0.511856	1.41594	0.949398	0.415444	1.01569	0.455572	0.787102	12.9035
HSPA4L	3.46513	0.380021	0.520439	0.68987	0.313979	0.987808	0.328532	0.23076	0.362939	0.493232	0.699889	3.47278
LMLN	0.795422	0.204083	0.225648	0.233067	0.372675	0.215691	0.403258	0.093581	0.125176	0.256651	0.545521	1.00599
B3GALT1	0.0073339	0.0191749	0.0262408	0.0536571	0.0726306	0.0716359	0.105559	0.0269002	0.0188037	0	0.0296117	0.782955
C6orf174	0.739941	0.183981	0.0917839	0.159024	0.168796	0.404268	0.200535	0.189597	0.160007	0.205162	0.207196	1.22284
ADAM19	7.66599	3.23366	2.53203	1.85207	2.82143	5.39332	2.30304	1.84048	1.41792	1.87948	2.60681	18.8408
FEN1	2.26199	0.10692	0.300346	0.256016	0.0645781	0.188157	0.305026	0.319242	0.126168	0.263936	0.120159	0.842407
NT5DC3	1.51994	0.249413	0.313565	0.316146	0.26422	0.287681	0.316749	0.313347	0.191019	0.288315	0.314206	1.71056
EXTL3	6.02276	1.54685	1.83837	1.64551	1.83363	2.25314	1.56494	1.12433	1.30329	1.39584	2.1122	12.2201
GPR125	4.33316	0.995513	0.841631	0.885103	0.538037	1.43514	0.517076	0.617977	0.489096	0.665034	0.886433	4.44079
ENPP4	2.02195	0.298329	0.276068	0.396817	0.0637087	0.202893	0.143181	0.0677465	0.177525	0.152491	0.23341	0.537589
MLLT11	8.22657	3.00401	2.95563	5.84654	2.73262	5.57459	2.93234	3.36788	2.2059	2.59752	4.53827	44.729
TMEM170B	0.809813	0.1066	0.175318	0.132499	0.215833	0.166832	0.240891	0.167055	0.0843369	0.17912	0.191822	0.815905
BAMBI	1.11905	4.18377	2.76991	2.43372	2.73112	2.84373	1.39008	2.30257	1.92444	1.09489	1.30266	23.6892
LMO4	3.06042	1.56404	1.36302	1.36433	1.21935	1.4654	1.10271	0.912682	0.844972	0.974418	0.847204	10.8589
CD276	18.7153	8.86931	8.89327	7.10332	9.10002	8.00667	8.02635	5.85997	8.8993	10.9693	11.7602	47.3069
SLC22A17	12.9341	1.96902	3.99791	1.42676	2.45426	3.71233	1.70442	1.88362	2.07635	3.82644	2.10027	11.9419
FAM168A	9.18984	2.0778	2.42006	2.01978	2.25249	1.89175	1.98479	0.890203	1.55429	2.44672	2.17266	7.81443
MFSD6	5.50675	1.43629	0.70574	1.62109	0.442338	0.578501	0.637441	0.582957	1.39548	2.16529	1.43964	2.10787
"ERV3-1,ZNF117"	0.802291	0.0834731	0.239412	0.27647	0.251865	0.102304	0.138548	0.156175	0.82635	0.148	0.358648	1.64002
SV2A	12.1803	3.49753	2.39174	2.63412	2.0318	2.94913	2.65646	2.93894	1.76323	1.98438	1.19592	13.8224
VWA1	0.0556529	2.39466	2.42774	1.29362	1.9843	3.54853	1.92041	1.36087	3.54349	4.73195	2.00514	23.3503
HHAT	3.23177	1.42849	1.95844	1.11137	1.06253	1.32337	0.597384	0.736126	0.974366	1.88583	1.50378	10.1681
MARCKSL1	38.4878	10.0057	15.3331	12.3224	9.68788	4.88562	7.87858	7.33845	15.0718	17.8135	10.1192	72.837
TANC1	4.50599	0.951357	1.36167	1.11223	0.857334	0.993751	0.884377	0.402493	0.844353	1.17601	1.44486	3.78397
ODZ4	0.800264	0.0604199	0.153	0.198924	0.0716152	0.0432494	0.0147069	0.0609028	0.165895	0.505394	0.125857	0.0506466
LOC442421	0.477315	0.111801	0.163656	0.158097	0.0453688	0.162988	0.0809582	0.0403118	0	0.231503	0.0625578	0.724724
AHCYL2	1.55749	0.383847	0.344163	0.452824	0.438258	0.609982	0.329563	0.407046	0.294358	0.583604	0.447249	2.579
BICD1	8.1157	2.33965	2.41224	2.32429	2.85163	2.99344	1.72628	1.62379	0.98911	2.10233	2.80654	9.81959
FAM131A	3.75616	0.543628	0.770076	0.475545	0.743266	1.13534	0.557699	0.212841	0.476931	0.704625	0.63439	1.84893
PLXNA1	6.32842	2.13969	2.25156	1.7013	1.94752	1.89495	1.71448	0.947605	1.60579	1.99372	2.37122	9.07054
LRRC8D	7.94169	0.841645	1.10375	1.74688	1.44703	1.67486	0.555825	0.750855	1.07752	1.53454	1.62626	3.84816
EIF1AY	5.85165	0.0956283	0.174528	3.74129	3.33997	0.770088	0.581929	0.642618	0.2246	2.64587	4.67277	4.27519
TSHZ1	1.29592	0.593494	0.519489	0.672709	0.394724	0.419179	0.461855	0.132535	0.348759	0.709859	0.759175	2.92896
RTTN	1.39361	0.174743	0.231415	0.284005	0.207849	0.151182	0.181372	0.133651	0.15424	0.141969	0.153478	0.408778
ABAT	2.27938	0.505531	0.591524	0.331979	0.65719	1.05788	0.134301	0.394508	0.211618	0.200924	0.417096	2.22442
B4GALT5	1.87105	0.633932	0.390568	1.18193	0.821454	0.592844	0.37197	0.427659	0.401694	0.825263	0.843282	4.24235
PRKAR2B	0.810143	0.138333	0.108631	0.333762	0.172009	0.168335	0.0942811	0.17848	0.127814	0.352898	0.0874721	1.16378
SLC16A9	0.231308	0.0300603	0.0579961	0.0996242	0.0760118	0.187231	0.0172105	0.0380107	0.0847229	0.0259911	0.0339924	0.981222
LRRCC1	2.84882	0.407618	0.290092	0.692644	0.225633	0.140457	0.347585	0.288058	0.267919	0.385869	0.201704	0.749382
SH3BP5	2.81262	0.865508	0.764906	0.916278	0.432917	1.20976	0.477335	0.703462	0.52694	1.02809	0.670202	5.52883
C7	0.607732	0.0888526	0.155405	0.327522	0.0280843	0.00883362	0.0480619	0.0265371	0.222599	1.242	0.182808	0.105325
HIP1	1.66659	0.415823	0.363787	0.54592	0.396977	0.584183	0.519665	0.277628	0.443937	0.906187	0.553809	2.51162
ADAM17	6.67783	1.0902	1.09764	1.45156	1.10817	1.50136	1.37545	0.595602	0.894386	1.00911	1.11587	5.88342
TTC39C	0.844369	0.0315383	0.125381	0.19219	0.0753234	0.141079	0.0383845	0.0624138	0.183176	0.0920338	0.145999	0.790274
TSPAN13	4.07767	0.158786	0.241622	0.435426	0.46338	1.86826	0.405512	0.759227	0.313021	0.0915724	0.719786	3.85932
MRC2	25.7541	9.77885	10.8831	6.80677	6.70492	13.0852	6.06129	5.07766	8.51171	6.67919	6.2055	41.9119
GLI3	0.995498	0.225464	0.2367	0.360338	0.17389	0.110964	0.215622	0.181083	0.218482	0.332015	0.147763	1.42374
GLUL	8.12264	3.35563	4.02368	4.61785	4.27425	2.90251	3.56385	3.14015	3.45986	5.34094	2.55385	29.4826
ARHGAP32	0.639381	0.121776	0.166687	0.192367	0.197953	0.186791	0.150562	0.119502	0.0762699	0.190528	0.208788	0.826012
ZNRF3	1.12701	0.200937	0.301876	0.283293	0.244473	0.214687	0.148333	0.153105	0.135187	0.181717	0.27762	0.964137
LYPD1	23.3992	5.64725	12.1717	9.57551	5.55688	1.94165	3.16857	6.07993	5.00754	3.57087	5.04916	55.9107
MAGI2	1.01293	0.168687	0.326773	0.321423	0.339844	0.634007	0.329689	0.333589	0.198048	0.274436	0.358088	3.30335
EPHB4	4.02106	2.43859	3.14813	2.50347	2.21647	2.25279	1.81073	1.18627	2.07087	2.75113	2.14306	17.4606
SPATA13	1.07752	0.155515	0.350273	0.350717	0.477751	0.357619	0.263552	0.114903	0.202357	0.341939	0.258492	1.38889
PLEKHG5	1.36197	0.0960104	0.243369	0.179045	0.183857	0.502701	0.069245	0.0955831	0.14031	0.101461	0.208509	0.856235
TIPARP	1.28828	0.654765	1.0666	0.821791	0.662417	1.27613	0.10996	0	0	0.859874	3.22294	2.49185
SHC2	1.48254	0.0904604	0.517801	0.0330696	0.190072	1.25091	0.0488085	0.134747	0.0463554	0.18196	0.177655	2.7323
PGM5	3.06934	0.0900376	0.362019	0.855217	0.0341508	0.214842	0.07306	0.0528811	0.110894	0.0934196	0.0926405	1.66709
CYP1B1	0.0831326	0.646217	0.321779	1.62491	0.388859	0.219302	0	0.0795071	0.236225	1.5333	0.358792	4.34962
INHBA	0.0315451	0.983981	0	0	0.000375386	0	0	2.71565	0.0546425	0	0.000195292	0
CLDN22	0	0.367681	0.131676	0.310386	0.277273	0.279014	0.411403	0.568536	0.23559	0	0.000148826	0
SSR3	0	10.0001	9.06839	6.8728	6.42566	8.06723	7.43402	20.4874	6.58162	2.67898	2.24427	0
IFT80	0	0.300103	0	0.119584	0	0.181152	0	1.07661	0.176458	0.0379246	0	0
SERPINB2	0.0243306	1.08456	0.4999	0.890056	0.461739	2.23794	0.107754	0.594956	0.904548	0.057413	0.136617	0
RCN1	1.92203	5.70336	1.02956	2.07935	7.69074	9.09903	6.41218	34.0071	22.4316	4.69961	4.26099	0.655023
ADIPOR2	0.0977026	0.645971	0.841753	0	0.31748	0.308639	0	3.1303	1.75588	0.671696	0	0.0549392
SHOC2	0.00233041	2.25789	2.38145	1.23212	2.02384	1.02091	0.750376	6.61508	3.70442	0.0563288	0	5.10E-05
FKBP10	3.04586	5.84291	8.61681	1.8929	9.62703	15.5394	7.53595	39.1803	26.3712	11.1323	5.86107	0
ACTR2	1.73998	15.8535	17.852	18.8823	14.5316	21.6585	25.0549	47.1461	22.2346	9.70816	8.52657	2.22046
ERBB2IP	0.311224	1.22245	1.07186	0.484347	0.877192	2.18913	0.837667	3.76439	1.87686	0	0	0.240794
SGMS2	0.144305	0.465338	0.674388	0.560553	0.52968	1.11523	0.436039	0.839469	0.383287	0.131508	8.82E-05	0.0642337
ARCN1	0.93776	2.74412	2.39567	2.21487	0	0.991917	2.46176	5.11462	3.86796	0	0	0.103917
SKIL	0.265923	0.425387	0.412345	0.490705	0.0132699	0.46408	0.822063	0.82693	0.408907	0.0751749	0.178902	0.0635645
CRIM1	0.939505	19.3617	23.0081	23.8712	16.714	35.9055	24.4579	49.6397	19.5928	2.25398	13.621	0
LRBA	0	0.66383	0.409666	0.382414	0.472864	0.998257	0	4.56157	1.75243	0.279587	0.337609	0.292692
ARHGAP31	0	0.0581005	0.0139148	0.0329426	0.112191	0.098785	0	0.370897	0.34308	0.0142631	0	0
OXTR	0.714734	5.21111	11.042	3.03297	5.88119	23.2874	0.775356	10.4212	6.69216	0	5.07538	0.00396038
MYOM1	0.00771379	0.324556	0.533103	0.232804	0.212933	0.288833	1.7124	0.754509	0.089001	0.245734	0.205739	0
CPNE3	0.483415	0.864759	1.04966	1.20382	0.864373	1.84918	1.42814	1.45589	1.82062	0.00808909	0.0124922	0.140818
DSP	0.0106835	5.34333	13.8211	6.91692	9.4533	30.2808	11.0609	6.44382	4.19224	1.08182	8.8141	1.3904
PCGF5	0.0548471	0.331216	0.561087	0.678664	0.270599	0.06255	0.387178	0.697643	0.813038	0.0747781	0.229356	0
LOX	0.814139	7.9903	15.4268	12.5181	25.7367	88.8534	22.8243	14.8128	8.7001	3.73443	16.2037	3.07786
ZBTB11	0	0.310529	0.587698	0.374138	0.402234	0.917467	0.605953	0.881963	0.411889	0.324497	0.015505	0
"C4orf22,FGF5"	0.0406529	2.26064	7.24617	7.02145	9.67852	6.46663	18.4721	11.6392	4.71725	1.02962	7.75255	0.0359618
ZNF627	0.122199	0.373266	0.138801	0.132669	0	0.117339	0.61081	1.43734	0.760095	0.00113208	0	0
KRTAP4-9	0	0.151462	0.072386	0.148835	0.274515	0.832618	0.283145	0.742845	0.412081	0.219436	0	0
HCLS1	0	0.68025	0.846479	0.165784	0.56685	1.62311	0.577027	2.27177	7.29128	0.962454	1.01786	0
SEC16A	0	0.889028	0.520678	1.59062	0.834883	2.79136	1.62268	4.59891	2.45837	1.39331	0.747075	0.00108861
ACAN	0	2.12125	2.52654	0.722125	4.14218	1.86476	18.7942	4.39101	1.5376	0.542938	1.08146	0
TACC1	1.1885	0.695437	1.06319	2.08477	0.374399	1.85262	1.25959	2.00481	1.1966	0.597459	0.168459	0
NUP43	8.08E-05	0.349442	0.0500998	0.723576	0	0.132686	0.956432	0.16413	0.159908	0.155178	3.72E-05	0.00967574
ADAMTS5	0	0.0932903	0.0679231	0.34728	0.248445	0.202468	1.10167	0.256099	0.11748	0.132965	0.153142	0.0302511
ESM1	0.0955746	0.141348	0.0743816	0.227579	0.164889	0.213939	0.949228	0.467416	0.122524	0.0778102	0	0
TBCC	0	9.00E-05	0	0.0011852	0.694148	0.880952	0.000126911	2.57957	0.000151124	0	0.190634	0
C12orf69	0	0.218236	0.190095	0.299174	0.376252	1.97046	0.55536	0.293307	0.167749	0.180117	0.244911	0
CTNNB1	2.33965	3.1989	6.91367	13.3617	5.8845	6.16236	12.8888	16.4737	5.33904	2.31968	5.39322	0
KHDRBS1	0	3.17631	4.64791	10.9858	3.76362	2.63622	9.01826	11.6282	2.71312	2.85138	2.74802	0
FRMD6	0	4.30616	7.00521	6.9851	3.72036	8.17708	5.72115	11.202	6.67015	1.38035	1.52919	0
AKAP10	0	0.322077	0.155957	0.440822	0	0.49132	0.0865874	1.28982	1.2237	0	0.187139	0.359159
HNRNPU	2.01228	2.11593	6.45726	6.01042	3.20074	2.91528	6.28469	12.84	6.54538	1.40315	2.90045	0
GJA5	0	0.0189858	0.00872269	0.0381731	0.337306	0.513273	0.662398	0.578379	0	0.0492471	0.0196703	0.0194265
CDK15	0.0386497	0.0820401	0.11645	0.324011	0.155586	0.251681	0.42792	0.157516	0.0495478	0.110756	0.0437797	0.043384
STARD7	0	0	0.879309	0.966015	1.57611	0.262861	0	1.84321	1.6074	0.000712305	0.000210633	0
SLC39A7	2.74616	0	0	0	0	4.1822	0	8.38079	4.65704	1.84098	0	0
ANKRD30B	0	0.172184	0.556756	0.155866	0.208804	0.345852	0.510448	0.536406	0.0638028	0.0126938	0.120822	0
PTPRF	0.623464	1.63086	2.93264	3.1008	1.09114	5.44497	1.23349	4.73129	4.26222	0.59172	1.08817	0.647481
JMJD1C	0	0.877049	0.979152	1.25223	0.545779	1.61827	1.38218	2.42789	1.98086	0.103337	0.322795	0.173822
MYLK-AS1	1.04381	2.44112	11.5493	5.85138	10.8764	14.7963	21.2471	26.6809	17.8715	0.370482	11.7248	0.384637
TSLP	0.168862	0.751011	1.73594	2.44553	0.404621	0.748343	1.74496	0.963472	1.29886	0.299563	0.895484	0.0260135
MGRN1	0	0.479891	0.446477	0.124685	0	0.0374651	0	2.31108	2.8968	0	0	0.379925
ZC3H11A	0.340779	1.82836	3.02718	1.0579	0.470183	2.33162	1.2297	8.55477	5.852	0.186665	0.640667	0.337254
SERPINH1	0	0	0	11.5946	8.1132	12.399	17.4237	20.3734	14.1921	7.56665	7.40666	0
ABI3BP	0.0215061	5.13168	3.44202	6.27989	0	17.4051	5.12747	15.361	14.6725	6.76683	0.0310645	0.186479
PUM1	0	0.607632	1.3624	1.72044	1.33738	0.620583	1.81067	4.2399	2.13797	0	0.330777	0.246706
SEC61A1	0.00280919	2.60034	0.744427	0	0	0.0074538	0	16.2185	12.9714	0.352488	0	0
HSD17B2	0.0957059	1.10651	2.85599	4.91098	0.224224	1.3886	0.104592	3.08231	1.70845	1.56078	1.06508	0
SLC16A1	0.797257	0.973201	1.0259	1.26733	0.0183547	1.7429	2.45627	3.40289	1.74508	0.12149	0.00661421	0
TSHZ1	0	0	0.105763	0.326719	0.205818	0.226082	6.47E-05	0.524749	0.402957	0.24086	0.00153017	0
ALPL	0.0196191	1.04181	1.49769	1.65391	2.3335	4.18254	10.7289	2.42079	0.572066	0.329014	0.291516	0.023994
LASP1	0	5.56813	6.00667	5.72565	2.5461	8.22533	11.1804	19.3999	15.373	0.00215558	1.14024	0
MSTN	0.090637	0	0.088674	0	0.232064	1.47851	1.06878	0.0443266	0.0697163	0.0855503	0.356248	0.0502662
MAP4	0.202944	0.619462	1.7018	0.305157	0	1.77359	0	2.07075	4.55373	0.789397	0	0.236827
MTPN	0	2.87044	4.50239	6.68848	1.90134	9.57968	8.41401	13.3849	6.32149	3.53905	1.05829	0.405694
COL5A1	0	7.11236	6.23143	8.08764	0	12.9374	4.11288	15.0933	14.9007	0	0	0
PXDN	0	1.35739	5.84151	5.77185	2.62795	6.99231	3.95573	13.3397	7.40335	3.34901	2.34928	0
GJD3	0	0.123771	0.531509	0.331906	0.184236	0.129845	0.330107	0.558215	0.473149	0	0.13511	0.00014776
LINC00547	0	0.00604898	0.0165597	0.0304054	0.0803019	0.346397	0.0883441	0.0812978	0	0	0.037336	0
NOX4	0.0240191	0.0438539	0.0625638	0.245706	0.103889	0.83271	0.186805	0.162043	0	0	0.0338348	0.267234
HHIP	0.0706408	1.60068	11.5448	4.54113	4.42762	4.35141	12.4328	7.43649	1.33449	0.298815	3.44225	0.0326923
TNPO3	0.211049	0.350288	0.332139	1.51623	0.233355	0.900943	1.06582	4.92821	0.325285	0.692239	0.248757	0.000453421
PAPPA	0	0.657596	1.58695	1.91023	2.31193	15.368	4.91313	3.36605	1.42146	0.469598	2.704	0.108509
NECAP1	0	0.105327	0	0	0	0	0.199482	0.870993	0.47494	0	0	0
ST6GALNAC5	0.249016	0.0309375	0.0141157	0.0207344	0.117344	2.3049	0	0.19392	0	0	0.0318258	0.0941697
SUN1	0	0.886719	1.20802	2.48142	1.01298	1.46154	3.0008	3.57509	2.84251	0	0	0
CLDN1	0.0636604	0.0579125	0.0554895	0.0407539	0.0658975	2.41474	0.0704833	0.0934007	0.0326443	0.0300438	0.0178726	0.406011
HGSNAT	0.443795	0	0	0	0	0.333902	0	1.50611	1.12198	0	0	0
TTC38	0	0	0.0157291	0	0	0.165162	0	0.935857	0.549874	0.283675	0	0
PHLDA3	0	0	0.141521	0	0	0.236434	0.000294167	1.17253	0	0	0	0.350718
HAPLN1	0.0554158	0	0	0	0.0478026	0.496184	0	0.0564617	0	0	0	0
RPL23AP53	0.000167597	0.00204661	0.125515	7.02E-05	0.185453	0.754472	0.101963	0.203717	0.00933201	0	0.013145	0
SUSD5	0.0430357	0.162277	0.777578	0.667549	0.344608	0.417179	0.626321	1.16455	0.443299	0	0.0274576	0.0157896
LRRC8D	0	0.0505885	0	0	0	0.038744	0	0.775683	0.0395773	0	0	0
GSTA1	0	0.0253174	0.207927	0	0.0480137	1.13845	0.0876352	0.19356	0	0.186084	0.0555512	0
CSRP1	0.428604	0	0.442366	0	0.663671	0	0	8.32707	0	0	0	0
ZNF804A	0.0184431	0.00419447	0.0114828	0.202403	0.0556828	0.090074	0.0306297	0.0112747	0	0	0	0
SEMA3F	0	0.0454323	0.338399	0.158614	0.0443282	0.0313715	0.292603	0.0628293	0.0164693	0	0.0360678	0.0173106
H2AFZ	0	1.65692	1.05837	23.0112	9.14646	4.11527	21.0447	38.6067	4.84157	0	2.46095	1.23823
PYGB	0	0	0.547694	0	3.21725	6.24675	0.955709	12.2139	7.3417	0	0.000564877	0
LRMP	0	0.0218536	0.0204994	0.10985	0.0142007	0	0.0182269	0.0805127	0.266906	0	0.0231093	0
ANXA10	0	0.184737	0.137928	1.46886	0.0955491	0.120216	0	0.0902851	0.0473329	0	0	0
NFE2L1	0	0.342107	1.72797	0.85163	0	2.35331	1.24693	3.55795	7.16827	1.47171	0.601096	0
MDGA2	0	0	0	0.410271	0.0283099	0.0133627	0.44801	0.190538	0.0420725	0	0.0230447	0.2247
OR51E1	0	0.00648839	0.00888132	0.00652283	0.012305	0	0.205317	0.0174407	0	0	0	0
CYTIP	0	0.114037	1.73504	3.18617	0.486781	0.567122	1.93625	0.703581	0.32742	0.301103	0.371608	0
TIMP3	0	0	0	0	0	0	0	1.58085	0.102961	0	0	0.246919
EIF4E3	0.0690187	0	0.0561984	0.105277	0	0	0	0.268241	0	0	0	0
ZNF362	0.0194196	0	0.743954	1.06059	0.708274	0.537518	0.615002	1.01368	1.58015	0.0471164	0	0
ZFP57	0	0.0226416	0.0154959	0	0	0.263367	0	0.0912902	0	0	0	0
TRPC6	0	0.0175221	0.396894	0.961132	0.590045	0.412061	5.46266	0.849671	0.499256	0.249998	0.325045	0
"PTPN20A,PTPN20B"	0	0.0139775	0.0275507	0.0581321	0.0319151	0	0.406301	0.0541026	0	0	0	0
CCND1	0	0	13.0224	44.3811	19.047	44.852	50.5987	64.4874	10.4665	11.4287	2.40935	0
SGCA	0	0.479948	1.6281	2.45443	3.12636	17.6445	14.3239	10.6573	0.999816	0.21651	1.35239	0.127214
TES	0.0302491	0.0824282	1.74181	2.01961	0.270425	0	1.0432	4.33665	2.50459	0.0544412	1.3025	0
ZNF569	0	2.64E-05	0.116074	0	0.0274529	0	1.23E-05	0.204355	0	0	0	0
RASSF1	0	0	0	0	0	0.303112	0.504324	1.71842	0.640667	0.233304	0.0435588	0
"C15orf48,MIR147B"	0	0	0	0.0639342	0	1.2519	0.077401	0	0	0	0	0.193853
SATB2	0	0.0712528	0.230772	0.265601	0.0129933	0.244779	0.33284	0.292631	0.304022	0	0	0
NETO1	0	0.00957528	0	0.00928311	0.00601793	0.205464	0.0465601	0.102893	0	0	0	0
SPOP	0.000224925	0.00117547	0.340642	1.63022	0.118745	0.840026	1.11412	4.35027	1.43499	0.24719	0.711858	0
WDR1	0.310365	0.0877065	0.161922	0.883571	0.94328	0.45855	1.84353	20.5616	0	0	0	0
FERMT2	0	0.265713	0.511182	0.440526	0.192627	0.62119	0.703547	10.7191	1.923	0	0.238337	0
NID1	0	0.853396	1.17539	6.44524	0.780143	2.1478	4.41505	13.1201	6.2209	0	0	0
PSG2	0	0	0	0.0134799	0.0508584	0.647876	0.0326385	0.0360424	0.0188957	0	0	0
ADAM12	0.556393	0.0008514	1.03681	0.449671	0	0.350229	0.388957	4.54857	1.72834	0	0	0
KPNB1	0	0.122355	0.113043	0.0823903	0.238666	0	0	10.666	1.17769	0	0	0.112842
ENG	0.252819	0	0	0	0	2.11158	0.327897	12.2896	6.03291	0.676003	0	0
SH3RF3	0.0323768	0	0	8.54E-05	0	0.178243	0.0163756	0.469784	0.28101	0	0	0
QSOX2	5.03E-05	0	0.248642	0.103494	0	0.077985	0	0.129818	0.100758	0	0.0437475	0
SLC13A5	0	0	0.00875986	0.00643356	0.0121368	0.218755	0.093468	0.0688104	0	0	0	0
CAPN2	0	0.0636253	0.949432	5.74176	0	3.9118	3.97159	39.2361	17.2486	2.76383	0	0
OR51E2	0	0.0510522	0.878496	1.56902	0.0553251	0	1.65099	0.235247	0	0	0.0450155	0.0222308
EPS15	0	0	0.193836	0.000554548	0.000164455	0	1.59465	1.66085	1.02751	0.0299835	0.125228	0
CALB1	0	0	0	0	0.0170776	0.535816	0.02192	0.0726186	0	0	0	0
PSG1	0	0	0.0433965	0.021284	0.0200757	0.593362	0.0257674	0.0542758	0.0149175	0	0	0
PSG5	0	0	0.0377877	0.0138762	0	1.01225	0	0.148413	0	0	0.0425987	0
DYRK1B	0	0	0	0	0	0	0	0.534245	0.460607	0	0	0
LOC202781	0	0	4.90E-06	0.242167	0	0	0.000301828	0.182778	0	0	5.47E-05	0.0147459
PEX11B	0	0	0	0	0	0	0	0	0.422356	0	0	0
HRCT1	0	0	0	0	0	0.106919	0.0727148	0	0.673576	0	0	0
LOC284344	0	0	0	0	0.0229221	1.29778	0	0	0	0	0	0
PPP2R4	0	0	0	0	0.00402339	0	0	0.28003	0.503631	0	0	0
MIR4461	0	0	0	0.465254	0	0.961098	0	1.13621	0.444643	0	0	0
TIPARP	0.000106329	0	0	0.415145	0.000137863	1.42582	0.000335635	2.53797	1.25175	0.103825	0	0
APLP1	0	0	0	0	0	0	0	3.02699	0.900535	0	0	0
ZNF503-AS1	0	0	0	0.223339	0	0	0	0	0	0	0	0
SLC27A2	0	0	0	0	0	0.246601	0	0	0	0	0	0
ACTR3	0	0	1.22342	1.20658	0.121146	1.24259	1.79293	2.05869	1.21255	0	0	0
C1orf124	2.59E-05	0	0	2.28E-05	0	0.0749502	0	0.222998	0.0821161	0	0	0
FUT8	0	0	0	0	0	0	0	0.698503	0.198311	0	0	0
MAN1A1	0	0	0.168923	0.148316	0	0	0	0.000303803	0	0	0	0
ATXN7L3B	0	0.000128583	0.0382246	0.0958552	0	0	0.0018805	1.86682	0.132215	0.0179	0	0.000161434
MYO1E	0	0	0	0	0	0	0	1.01285	0	0	0	0
RTN4R	0.000610391	2.06E-05	1.65E-05	0	0.00264351	0.294343	0.23853	0.301036	0.355099	0	0	0
PSG9	0	0	0	0	0	0.483417	0	0.101319	0	0	0	0
DDX43	0	0	0.0310222	0.106326	0	0.0811155	0	0.0406133	0.042584	0	0	0
ZNF43	0	0	0	0.0010677	0	0.196126	0	0	1.47E-05	0	0	0
HDHD2	0	0	0	0	0	0	0	1.17168	0.287976	0	0	0
DES	0	0.0184357	1.79167	0.0834008	0.0349626	7.67048	2.19886	0.520325	0	0	0.0284475	0
DPYSL3	0	0	0	0	0	0	0	0.587934	0	0	0	0
RABGAP1	0	0	0	0	0	0	0	1.09346	0	0	0	0
CD82	0	0	0	0	0	0	0	1.82749	0	0	0	0
HIST2H2BE	9.48E-05	0.000114799	9.48E-05	0.000104663	0.00010346	9.45E-05	9.47E-05	1.17876	9.45E-05	9.48E-05	0.00011049	9.41E-05
C5orf43	0	0	0	0.138323	0	0	0	8.14E-05	0	0	0	0
STRN3	0	0	0	0	0	0.205403	0	0.727246	0.0297369	0	0	0
RFK	0.00025611	0	0	0.381564	0	0.131039	0.0283571	0.0163299	1.00741	0	0	0
FAM54B	0	0	0	0	0	0	1.32563	3.19772	0	0	0	0
SPTSSA	0	0	0	0.000809338	0	0	1.1492	0.99684	0	0	0	0
SDC1	0	0	0	0	0	0	0	1.46215	1.45587	0	0	0
ESYT2	0	0	0	0	0	0	0	1.87491	0	0	0	0
FUBP3	0	0	0	1.52779	0	0	0.944668	1.93724	0.000114612	0	0	0
LOC100652999	0	0	0.330717	0	0	0.155265	0	0.43428	0.507776	0	4.80E-05	0
NCEH1	0	0	0	0	0	0	0.640013	2.28665	0	0	0	0
PRRC2B	0	0	0.00134906	0	0	0.655671	0	0.796072	0.58839	0	0	0
SKI	0	0	0	0	0	8.49E-05	0	2.37607	0.771863	0	0	0
FAM168A	0	0	0	0	0	0.749089	0.13713	1.05063	0.588408	0	0	0
ITGA5	0	0	0	0.20078	0	1.01091	0	14.8976	8.53434	0	0	0
LOX	0	0	0.13241	1.37365	0	0	1.87488	5.26048	0.260044	0	0	0
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sample_heatmap.pdf
Type: application/pdf
Size: 12637447 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131231/a4e69feb/attachment-0001.pdf>

From parkhurs at imap.iu.edu  Tue Dec 31 15:48:25 2013
From: parkhurs at imap.iu.edu (David Parkhurst)
Date: Tue, 31 Dec 2013 09:48:25 -0500
Subject: [R] Where did lost variables go, with example
In-Reply-To: <52C2D51B.5090705@indiana.edu>
References: <52C2D51B.5090705@indiana.edu>
Message-ID: <52C2D939.8090300@imap.iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131231/705bdeb1/attachment.pl>

From parkhurs at imap.iu.edu  Tue Dec 31 16:11:25 2013
From: parkhurs at imap.iu.edu (David Parkhurst)
Date: Tue, 31 Dec 2013 10:11:25 -0500
Subject: [R] Problem with http://www.r-project.org/mail.html#instructions
Message-ID: <52C2DE9D.6040806@imap.iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131231/ea137a17/attachment.pl>

From murdoch.duncan at gmail.com  Tue Dec 31 17:32:04 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 31 Dec 2013 11:32:04 -0500
Subject: [R] Where did lost variables go, with example
In-Reply-To: <52C2D939.8090300@imap.iu.edu>
References: <52C2D51B.5090705@indiana.edu> <52C2D939.8090300@imap.iu.edu>
Message-ID: <52C2F184.5030409@gmail.com>

On 13-12-31 9:48 AM, David Parkhurst wrote:
> Two or three respondents asked for an example of my problem.  Here's
> what's happening to me now.  I can't reproduce how I got to this point,
> though:
>
>   > ls()
> [1] "All8"   "All8Sites"  "A"   "B"  "C"  "i"  "n"  "D"  "F"
>   > X
> Error: object 'X' not found
>   > attach(All8Sites)
>   > ls()
> [1] "All8"  "All8Sites"  "A"  "B"  "C"  "i"  "n"  "D"  "F"
>
>
> "X" is one of the variables in the data frame I attached in the third
> command above, but it's not listed by >ls().  If I enter > X now, its
> values ARE listed, but it's hiding somewhere.  What is happening here?
> How can I get the variables in that data frame listed when I attach it?

Use search() to see the search list.  Your dataframe will likely be in 
position 2.  Use ls(2) to see the variables there.

Duncan Murdoch


From pgilbert902 at gmail.com  Tue Dec 31 17:57:32 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 31 Dec 2013 11:57:32 -0500
Subject: [R] Package dependencies in building R packages
In-Reply-To: <mailman.11.1388487606.13223.r-help@r-project.org>
References: <mailman.11.1388487606.13223.r-help@r-project.org>
Message-ID: <52C2F77C.6080004@gmail.com>

The responses to this seem to be assuming that you want users to have 
access to your tt() function, that is, you export it. Just in case the 
really simple case has been overlooked: if you are only using this 
function internally in your package there should be no problem. Your 
package's namespace ensures that your package's functions find your 
tt(), and if you do not export it then user references to tt() will not 
find your version.

As others have pointed out, if you want users to have access to your 
tt() and they also need access to survival's tt(), then there is a 
problem. You either need to change the name or users will need to be 
explicit about which one they want.

(BTW - this is a question that could be asked on the R-devel list.)

Paul

On 13-12-31 06:00 AM, r-help-request at r-project.org wrote:
> Date: Mon, 30 Dec 2013 20:01:46 +0100
> From: Axel Urbiz<axel.urbiz at gmail.com>
> To: Duncan Murdoch<murdoch.duncan at gmail.com>
> Cc:"R-help at r-project.org"  <R-help at r-project.org>
> Subject: Re: [R] Package dependencies in building R packages
> Message-ID:
> 	<CAAyVsXKCN1Zn4gbG=QkD759kaDadPbgp+9e3W6nPvOLVwAsU=w at mail.gmail.com>
> Content-Type: text/plain
>
> Thanks for your kind response Duncan. To be more specific, I'm using the
> function mvrnorm from MASS. The issue is that MASS depends on survival and
> I have a function in my package named tt() which conflicts with a function
> in survival of the same name. I can think of 2 alternatives solutions to my
> problem, but I'm to an expert:
>
> 1) Copy mvrnorm into my package, which I thought was not a good idea
> 2) Rename my tt() function to something else in my package, but this is
> painful as I have it all over the place in other functions.
>
> Any suggestions would be much appreciated.
>
> Best,
> Axel.
>
>
> On Mon, Dec 30, 2013 at 7:51 PM, Duncan Murdoch<murdoch.duncan at gmail.com>wrote:
>
>> >On 13-12-30 1:24 PM, Axel Urbiz wrote:
>> >
>>> >>Dear users,
>>> >>
>>> >>My package {foo} depends on a function "miscFUN" which is on package
>>> >>{foo_depend}. This last package also depends on other packages, say {A, B,
>>> >>C}, but miscFUN is not dependent on A, B, C (only on foo_depend).
>>> >>
>>> >>In my package {foo}, is there a way to only have it depend on the function
>>> >>miscFUN from {foo_depend} without having the user to have installed A, B,
>>> >>C? (as none of those packages are needed for my package to work properly).
>>> >>Also, is this a best practice?
>>> >>
>> >
>> >There's no way for your package to tell R to ignore the dependencies
>> >declared by foo_depend.
>> >
>> >If you really only need one function from that package, simply copy the
>> >source of miscFUN into your package (assuming foo_depend's license permits
>> >that).  But this is not best practice, unless that function is very simple.
>> >  Best practice is to declare your dependence by importing that function
>> >from foo_depend.
>> >
>> >Duncan Murdoch
>> >
>> >
>> >
> 	[[alternative HTML version deleted]]
>


From taquito2007 at gmail.com  Tue Dec 31 18:02:27 2013
From: taquito2007 at gmail.com (Takatsugu Kobayashi)
Date: Wed, 1 Jan 2014 02:02:27 +0900
Subject: [R] Request for help regarding RWeka
Message-ID: <CADL0Pci3EJcMC+5bws12UFmBg+xdSuUH6-6H7iJwtMd6YZ+k-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140101/07317429/attachment.pl>

From ligges at statistik.tu-dortmund.de  Tue Dec 31 18:38:42 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 31 Dec 2013 18:38:42 +0100
Subject: [R] Problem with http://www.r-project.org/mail.html#instructions
In-Reply-To: <52C2DE9D.6040806@imap.iu.edu>
References: <52C2DE9D.6040806@imap.iu.edu>
Message-ID: <52C30122.8010109@statistik.tu-dortmund.de>

Thanks for the report, if this is not a temporary problem, we will 
provide an alternative link.

Some search engine suggests that it is mirrored here:
http://linuxgazette.net/no-mime

Best,
Uwe Ligges


On 31.12.2013 16:11, David Parkhurst wrote:
> This web page includes this information about turning off HTML in messages:
>
> http://www.r-project.org/mail.html#instructions
>
>
>      General Instructions
>
> Note that you should configure your e-mail software in such a way as to
> send /only plain text/, i.e., *no HTML*. 'html-ified' messages are
> usually considerably longer (in bytes!) and harder to filter for spam or
> viruses. Many of these (e.g. 'html-only' ones) are currently
> spam-filtered or otherwise intercepted completely and without notice to
> the sender. For more details and instructions on turning off HTML for
> your e-mail software, see here <http://expita.com/nomime.html>.
> Furthermore, most binary e-mail /attachments are not accepted/, i.e.,
> they are removed from the posting completely. As an /exception/, we
> allow application/pdf, application/postscript, and image/png (and x-tar
> and gzip on R-devel). You can use text/plain as well, or simply paste
> text into your message instead.
>
> However, when I click on the _here_ link, I get a message that the
> server is not available. Perhaps someone can repair that?
>
> Thanks.
>
> David
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Tue Dec 31 18:42:04 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 31 Dec 2013 12:42:04 -0500
Subject: [R] Where did lost variables go, with example
In-Reply-To: <52C2F31E.2070009@imap.iu.edu>
References: <52C2D51B.5090705@indiana.edu> <52C2D939.8090300@imap.iu.edu>
	<52C2F184.5030409@gmail.com> <52C2F31E.2070009@imap.iu.edu>
Message-ID: <52C301EC.1000604@gmail.com>

On 13-12-31 11:38 AM, David Parkhurst wrote:
> Thank you.  I've tried what you're suggesting, at an earlier suggestion
> from another respondent, and I don't find my variable in any of lists
> ls() through ls(7).

Are you sure that "X" is really the name of a column in the dataframe? 
names(All8Sites) will tell you all the names that are there.

>
> I'm just going back to using R after being away from statistics for
> several years.  I'm thinking I might uninstall R, then reinstall it, and
> redo my work so far (I've kept the commands elsewhere), and avoid using
> "attach," as someone else has suggested.

It's not likely to be necessary to reinstall R, but it shouldn't hurt.

Duncan Murdoch

>
> David
> On 12/31/2013 11:32 AM, Duncan Murdoch wrote:
>> On 13-12-31 9:48 AM, David Parkhurst wrote:
>>> Two or three respondents asked for an example of my problem.  Here's
>>> what's happening to me now.  I can't reproduce how I got to this point,
>>> though:
>>>
>>>   > ls()
>>> [1] "All8"   "All8Sites"  "A"   "B"  "C"  "i"  "n"  "D"  "F"
>>>   > X
>>> Error: object 'X' not found
>>>   > attach(All8Sites)
>>>   > ls()
>>> [1] "All8"  "All8Sites"  "A"  "B"  "C"  "i"  "n"  "D"  "F"
>>>
>>>
>>> "X" is one of the variables in the data frame I attached in the third
>>> command above, but it's not listed by >ls().  If I enter > X now, its
>>> values ARE listed, but it's hiding somewhere.  What is happening here?
>>> How can I get the variables in that data frame listed when I attach it?
>>
>> Use search() to see the search list.  Your dataframe will likely be in
>> position 2.  Use ls(2) to see the variables there.
>>
>> Duncan Murdoch
>>
>


From jun.shen.ut at gmail.com  Tue Dec 31 20:02:49 2013
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Tue, 31 Dec 2013 14:02:49 -0500
Subject: [R] How to ask a function to continuously print intermediate results
Message-ID: <CAMCXXmo1MAt5FLL8_iTPnM0cQc2U1fQqMPHTtE-tTdjxavVUSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131231/d3bb9c6e/attachment.pl>

From murdoch.duncan at gmail.com  Tue Dec 31 20:10:17 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 31 Dec 2013 14:10:17 -0500
Subject: [R] How to ask a function to continuously print intermediate
 results
In-Reply-To: <CAMCXXmo1MAt5FLL8_iTPnM0cQc2U1fQqMPHTtE-tTdjxavVUSw@mail.gmail.com>
References: <CAMCXXmo1MAt5FLL8_iTPnM0cQc2U1fQqMPHTtE-tTdjxavVUSw@mail.gmail.com>
Message-ID: <52C31699.10103@gmail.com>

On 13-12-31 2:02 PM, Jun Shen wrote:
> Dear all,
>
> I have a print command to export some intermediate results from a
> user-defined function. It takes a while to run the function and I found I
> have to press a key to see the printed results on the screen. How can I ask
> the function to continuously print results on the screen without pressing
> any keys? Thanks.

This depends to some extent on which platform you're on.  On Windows in 
Rgui, you can disable "buffered output" using Ctrl-W or the entry in the 
"Misc" menu.  If you're using a different platform, search for "buffered 
output" in its help system.

Duncan Murdoch


From bogaso.christofer at gmail.com  Tue Dec 31 22:53:12 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Wed, 1 Jan 2014 03:23:12 +0530
Subject: [R] Working with Date
Message-ID: <CA+dpOJk=Kkv3P5p64WsKm-M9w0mR59usEFpAYzyLPXrcq1bHnA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140101/3867a499/attachment.pl>

From ligges at statistik.tu-dortmund.de  Tue Dec 31 22:54:49 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 31 Dec 2013 22:54:49 +0100
Subject: [R] How to ask a function to continuously print intermediate
 results
In-Reply-To: <52C31699.10103@gmail.com>
References: <CAMCXXmo1MAt5FLL8_iTPnM0cQc2U1fQqMPHTtE-tTdjxavVUSw@mail.gmail.com>
	<52C31699.10103@gmail.com>
Message-ID: <52C33D29.6050301@statistik.tu-dortmund.de>



On 31.12.2013 20:10, Duncan Murdoch wrote:
> On 13-12-31 2:02 PM, Jun Shen wrote:
>> Dear all,
>>
>> I have a print command to export some intermediate results from a
>> user-defined function. It takes a while to run the function and I found I
>> have to press a key to see the printed results on the screen. How can
>> I ask
>> the function to continuously print results on the screen without pressing
>> any keys? Thanks.
>
> This depends to some extent on which platform you're on.  On Windows in
> Rgui, you can disable "buffered output" using Ctrl-W or the entry in the
> "Misc" menu.  If you're using a different platform, search for "buffered
> output" in its help system.

And see ?flush.console

Best,
Uwe Ligges



> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Tue Dec 31 23:02:41 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 31 Dec 2013 16:02:41 -0600
Subject: [R] cumulative incidence for mstate in Survival package in R
In-Reply-To: <CALYjA0T3T7JbBOL8k_GMY4xm66k5aDXMXQ1mQTn6PT4sbUVBBQ@mail.gmail.com>
References: <CALYjA0T3T7JbBOL8k_GMY4xm66k5aDXMXQ1mQTn6PT4sbUVBBQ@mail.gmail.com>
Message-ID: <52C33F01.3020009@mayo.edu>

Question 1: How to get just 2 cumulative incidence curves when there are multiple covariates.
   I don't understand what you want.  Assume that we have "liver transplant" and "death 
while waiting for a transplant" as my two events.  There are overall curves (2), or one 
can create curves separately for each sex, or for different institutions.  What do you 
mean by "a curve for age"?
   If you want competing risks after Cox model adjustment, see the mstate package.

Question 2: "mine" data.  There is no such data.  This was a hypthetical example in the 
document, and I chose a poor name for the data set; "your_data_set" would have been 
better.  I was using "mine" in the sense of "this data set is mine, it belongs to me", and 
now see that it could confuse someone.  The file sourcecode.pdf is intended to document 
the computational algorithms, but not how a user would approach the function.  A vignette 
is planned, someday...

Terry Therneau


On 12/30/2013 04:04 PM, Jieyue Li wrote:
> Dear All,
>
> I want to have the cumulative incidence curves for 'mstate' data using Survival package in
> R. But I got some problems:
> I. Problem 1:
> 1. If I only use intercept without any covariates, I can have 'right' cumulative incidence
> curves (2 for 2 competing risks):
> library(Survival)
> fitCI <- survfit(Surv(stop, status*as.numeric(event), type="mstate") ~ 1,data=mgus1,
> subset=(start==0))
> plot(fitCI)
> 2. If I include one variate ('sex'), I get 4 curves (attached; I guess because there are
> two levels in 'sex' and 2 competing risks):
> fitCI <- survfit(Surv(stop, status*as.numeric(event), type="mstate") ~sex,data=mgus1,
> subset=(start==0))
> plot(fitCI)
> However, I want to just have 2 cumulative incidence curves estimated from several
> covariates (such as 'sex', 'age', 'alb', etc. in mgus1). Could you please help me to do
> that? Thank you very much!
> II. Problem 2:
> I try using an example from sourcecode.pdf:
> fit <- survfit(Surv(time, status, type=?mstate?) ~ sex, data=mine)
> but where can I have the 'mine' data? Thank you!
>
> Best,
>
> Jieyue
>


From istazahn at gmail.com  Tue Dec 31 23:37:06 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 31 Dec 2013 17:37:06 -0500
Subject: [R] Working with Date
In-Reply-To: <CA+dpOJk=Kkv3P5p64WsKm-M9w0mR59usEFpAYzyLPXrcq1bHnA@mail.gmail.com>
References: <CA+dpOJk=Kkv3P5p64WsKm-M9w0mR59usEFpAYzyLPXrcq1bHnA@mail.gmail.com>
Message-ID: <CA+vqiLFkWY1Lb_ZHprggmyAL_x74VZb6LH12QAqPPd0WCTvusQ@mail.gmail.com>

Use, format() to extract a character string representation of the
year, then paste() it together with Months. Like this:

paste(Months, format(Given_Date, format = "%Y"), sep = "-")

See ?strftime for details.

Best,
Ista

On Tue, Dec 31, 2013 at 4:53 PM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> Happy new year 2014 to every R gurus and users.
>
> I am struggling with some calculation with dates... Let say I have
> following vector of months:
>
> Months <- c("Jan", "Dec", "Mar")
>
> Now I need to assign year with them. This assignment will be based on some
> given date. Let say my given date is :
>
> Given_Date <- as.Date("2013-12-23")
>
> So in this case, the modified month will be:
>
>  Months_Mod <- c("Jan-2014", "Dec-2013", "Mar-2014")
>
> However if given date is:
>
> Given_Date <- as.Date("2014-01-04")
>
> then the modified months will be:
>
>  Months_Mod <- c("Jan-2014", "Dec-2014", "Mar-2014")
>
> My problem is that, I can not extablish some logic around it, so that I can
> do it programmatically for any Month-vector and for any Given-date.
>
> Can someone help me to accomplice this?
>
> Thank for your help
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Tue Dec 31 23:57:08 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 01 Jan 2014 09:57:08 +1100
Subject: [R] Working with Date
In-Reply-To: <CA+dpOJk=Kkv3P5p64WsKm-M9w0mR59usEFpAYzyLPXrcq1bHnA@mail.gmail.com>
References: <CA+dpOJk=Kkv3P5p64WsKm-M9w0mR59usEFpAYzyLPXrcq1bHnA@mail.gmail.com>
Message-ID: <52C34BC4.7000008@bitwrit.com.au>

On 01/01/2014 08:53 AM, Christofer Bogaso wrote:
> Hi again,
>
> Happy new year 2014 to every R gurus and users.
>
> I am struggling with some calculation with dates... Let say I have
> following vector of months:
>
> Months<- c("Jan", "Dec", "Mar")
>
> Now I need to assign year with them. This assignment will be based on some
> given date. Let say my given date is :
>
> Given_Date<- as.Date("2013-12-23")
>
> So in this case, the modified month will be:
>
>   Months_Mod<- c("Jan-2014", "Dec-2013", "Mar-2014")
>
> However if given date is:
>
> Given_Date<- as.Date("2014-01-04")
>
> then the modified months will be:
>
>   Months_Mod<- c("Jan-2014", "Dec-2014", "Mar-2014")
>
> My problem is that, I can not extablish some logic around it, so that I can
> do it programmatically for any Month-vector and for any Given-date.
>
> Can someone help me to accomplice this?
>
Hi Christofer,
I would like to be an accomplice in this, but I can't quite work out 
your logic. I thought that you might want:

IF Given_Date is in the same month as an element of Months

THEN use the year in Given_Date

ELSE use the year in Given_Date plus 1

However, when I programmed it:

assignYear<-function(index_date,months) {
  index_year<-as.numeric(format(index_date,"%Y"))
  index_month<-which(months==format(index_date,"%b"))
  dates<-as.Date(paste(index_year+1,months,"1",sep="-"),"%Y-%b-%d")
  dates[index_month]<-
   as.Date(paste(index_year,months[index_month],"1",sep="-"),"%Y-%b-%d")
  return(format(dates,"%Y-%b"))
}

it didn't work for the second example. Could you give some idea of what 
you want to do?

Jim


From parkhurs at imap.iu.edu  Tue Dec 31 17:38:54 2013
From: parkhurs at imap.iu.edu (David Parkhurst)
Date: Tue, 31 Dec 2013 11:38:54 -0500
Subject: [R] Where did lost variables go, with example
In-Reply-To: <52C2F184.5030409@gmail.com>
References: <52C2D51B.5090705@indiana.edu> <52C2D939.8090300@imap.iu.edu>
	<52C2F184.5030409@gmail.com>
Message-ID: <52C2F31E.2070009@imap.iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131231/c86de6c4/attachment.pl>

From jieyueli82 at gmail.com  Tue Dec 31 21:05:40 2013
From: jieyueli82 at gmail.com (Jieyue Li)
Date: Tue, 31 Dec 2013 12:05:40 -0800
Subject: [R] cumulative incidence for mstate in Survival package in R
In-Reply-To: <52C2957C.7010806@umu.se>
References: <CALYjA0T3T7JbBOL8k_GMY4xm66k5aDXMXQ1mQTn6PT4sbUVBBQ@mail.gmail.com>
	<52C2957C.7010806@umu.se>
Message-ID: <CALYjA0S_uP29KNvUxeD5x2Uo+hL=t0LVfJrPmz1QwwTTRzHidA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131231/7b61dd5c/attachment.pl>

From taquito2007 at gmail.com  Tue Dec 31 18:02:27 2013
From: taquito2007 at gmail.com (Takatsugu Kobayashi)
Date: Wed, 1 Jan 2014 02:02:27 +0900
Subject: [R] Request for help regarding RWeka
Message-ID: <CADL0Pci3EJcMC+5bws12UFmBg+xdSuUH6-6H7iJwtMd6YZ+k-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140101/07317429/attachment.ksh>

From ligges at statistik.tu-dortmund.de  Tue Dec 31 18:38:42 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 31 Dec 2013 18:38:42 +0100
Subject: [R] Problem with http://www.r-project.org/mail.html#instructions
In-Reply-To: <52C2DE9D.6040806@imap.iu.edu>
References: <52C2DE9D.6040806@imap.iu.edu>
Message-ID: <52C30122.8010109@statistik.tu-dortmund.de>

Thanks for the report, if this is not a temporary problem, we will 
provide an alternative link.

Some search engine suggests that it is mirrored here:
http://linuxgazette.net/no-mime

Best,
Uwe Ligges


On 31.12.2013 16:11, David Parkhurst wrote:
> This web page includes this information about turning off HTML in messages:
>
> http://www.r-project.org/mail.html#instructions
>
>
>      General Instructions
>
> Note that you should configure your e-mail software in such a way as to
> send /only plain text/, i.e., *no HTML*. 'html-ified' messages are
> usually considerably longer (in bytes!) and harder to filter for spam or
> viruses. Many of these (e.g. 'html-only' ones) are currently
> spam-filtered or otherwise intercepted completely and without notice to
> the sender. For more details and instructions on turning off HTML for
> your e-mail software, see here <http://expita.com/nomime.html>.
> Furthermore, most binary e-mail /attachments are not accepted/, i.e.,
> they are removed from the posting completely. As an /exception/, we
> allow application/pdf, application/postscript, and image/png (and x-tar
> and gzip on R-devel). You can use text/plain as well, or simply paste
> text into your message instead.
>
> However, when I click on the _here_ link, I get a message that the
> server is not available. Perhaps someone can repair that?
>
> Thanks.
>
> David
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From murdoch.duncan at gmail.com  Tue Dec 31 18:42:04 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 31 Dec 2013 12:42:04 -0500
Subject: [R] Where did lost variables go, with example
In-Reply-To: <52C2F31E.2070009@imap.iu.edu>
References: <52C2D51B.5090705@indiana.edu> <52C2D939.8090300@imap.iu.edu>
	<52C2F184.5030409@gmail.com> <52C2F31E.2070009@imap.iu.edu>
Message-ID: <52C301EC.1000604@gmail.com>

On 13-12-31 11:38 AM, David Parkhurst wrote:
> Thank you.  I've tried what you're suggesting, at an earlier suggestion
> from another respondent, and I don't find my variable in any of lists
> ls() through ls(7).

Are you sure that "X" is really the name of a column in the dataframe? 
names(All8Sites) will tell you all the names that are there.

>
> I'm just going back to using R after being away from statistics for
> several years.  I'm thinking I might uninstall R, then reinstall it, and
> redo my work so far (I've kept the commands elsewhere), and avoid using
> "attach," as someone else has suggested.

It's not likely to be necessary to reinstall R, but it shouldn't hurt.

Duncan Murdoch

>
> David
> On 12/31/2013 11:32 AM, Duncan Murdoch wrote:
>> On 13-12-31 9:48 AM, David Parkhurst wrote:
>>> Two or three respondents asked for an example of my problem.  Here's
>>> what's happening to me now.  I can't reproduce how I got to this point,
>>> though:
>>>
>>>   > ls()
>>> [1] "All8"   "All8Sites"  "A"   "B"  "C"  "i"  "n"  "D"  "F"
>>>   > X
>>> Error: object 'X' not found
>>>   > attach(All8Sites)
>>>   > ls()
>>> [1] "All8"  "All8Sites"  "A"  "B"  "C"  "i"  "n"  "D"  "F"
>>>
>>>
>>> "X" is one of the variables in the data frame I attached in the third
>>> command above, but it's not listed by >ls().  If I enter > X now, its
>>> values ARE listed, but it's hiding somewhere.  What is happening here?
>>> How can I get the variables in that data frame listed when I attach it?
>>
>> Use search() to see the search list.  Your dataframe will likely be in
>> position 2.  Use ls(2) to see the variables there.
>>
>> Duncan Murdoch
>>
>



From jun.shen.ut at gmail.com  Tue Dec 31 20:02:49 2013
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Tue, 31 Dec 2013 14:02:49 -0500
Subject: [R] How to ask a function to continuously print intermediate results
Message-ID: <CAMCXXmo1MAt5FLL8_iTPnM0cQc2U1fQqMPHTtE-tTdjxavVUSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131231/d3bb9c6e/attachment.asc>

From murdoch.duncan at gmail.com  Tue Dec 31 20:10:17 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 31 Dec 2013 14:10:17 -0500
Subject: [R] How to ask a function to continuously print intermediate
 results
In-Reply-To: <CAMCXXmo1MAt5FLL8_iTPnM0cQc2U1fQqMPHTtE-tTdjxavVUSw@mail.gmail.com>
References: <CAMCXXmo1MAt5FLL8_iTPnM0cQc2U1fQqMPHTtE-tTdjxavVUSw@mail.gmail.com>
Message-ID: <52C31699.10103@gmail.com>

On 13-12-31 2:02 PM, Jun Shen wrote:
> Dear all,
>
> I have a print command to export some intermediate results from a
> user-defined function. It takes a while to run the function and I found I
> have to press a key to see the printed results on the screen. How can I ask
> the function to continuously print results on the screen without pressing
> any keys? Thanks.

This depends to some extent on which platform you're on.  On Windows in 
Rgui, you can disable "buffered output" using Ctrl-W or the entry in the 
"Misc" menu.  If you're using a different platform, search for "buffered 
output" in its help system.

Duncan Murdoch



From bogaso.christofer at gmail.com  Tue Dec 31 22:53:12 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Wed, 1 Jan 2014 03:23:12 +0530
Subject: [R] Working with Date
Message-ID: <CA+dpOJk=Kkv3P5p64WsKm-M9w0mR59usEFpAYzyLPXrcq1bHnA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140101/3867a499/attachment.ksh>

From ligges at statistik.tu-dortmund.de  Tue Dec 31 22:54:49 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 31 Dec 2013 22:54:49 +0100
Subject: [R] How to ask a function to continuously print intermediate
 results
In-Reply-To: <52C31699.10103@gmail.com>
References: <CAMCXXmo1MAt5FLL8_iTPnM0cQc2U1fQqMPHTtE-tTdjxavVUSw@mail.gmail.com>
	<52C31699.10103@gmail.com>
Message-ID: <52C33D29.6050301@statistik.tu-dortmund.de>



On 31.12.2013 20:10, Duncan Murdoch wrote:
> On 13-12-31 2:02 PM, Jun Shen wrote:
>> Dear all,
>>
>> I have a print command to export some intermediate results from a
>> user-defined function. It takes a while to run the function and I found I
>> have to press a key to see the printed results on the screen. How can
>> I ask
>> the function to continuously print results on the screen without pressing
>> any keys? Thanks.
>
> This depends to some extent on which platform you're on.  On Windows in
> Rgui, you can disable "buffered output" using Ctrl-W or the entry in the
> "Misc" menu.  If you're using a different platform, search for "buffered
> output" in its help system.

And see ?flush.console

Best,
Uwe Ligges



> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From therneau at mayo.edu  Tue Dec 31 23:02:41 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 31 Dec 2013 16:02:41 -0600
Subject: [R] cumulative incidence for mstate in Survival package in R
In-Reply-To: <CALYjA0T3T7JbBOL8k_GMY4xm66k5aDXMXQ1mQTn6PT4sbUVBBQ@mail.gmail.com>
References: <CALYjA0T3T7JbBOL8k_GMY4xm66k5aDXMXQ1mQTn6PT4sbUVBBQ@mail.gmail.com>
Message-ID: <52C33F01.3020009@mayo.edu>

Question 1: How to get just 2 cumulative incidence curves when there are multiple covariates.
   I don't understand what you want.  Assume that we have "liver transplant" and "death 
while waiting for a transplant" as my two events.  There are overall curves (2), or one 
can create curves separately for each sex, or for different institutions.  What do you 
mean by "a curve for age"?
   If you want competing risks after Cox model adjustment, see the mstate package.

Question 2: "mine" data.  There is no such data.  This was a hypthetical example in the 
document, and I chose a poor name for the data set; "your_data_set" would have been 
better.  I was using "mine" in the sense of "this data set is mine, it belongs to me", and 
now see that it could confuse someone.  The file sourcecode.pdf is intended to document 
the computational algorithms, but not how a user would approach the function.  A vignette 
is planned, someday...

Terry Therneau


On 12/30/2013 04:04 PM, Jieyue Li wrote:
> Dear All,
>
> I want to have the cumulative incidence curves for 'mstate' data using Survival package in
> R. But I got some problems:
> I. Problem 1:
> 1. If I only use intercept without any covariates, I can have 'right' cumulative incidence
> curves (2 for 2 competing risks):
> library(Survival)
> fitCI <- survfit(Surv(stop, status*as.numeric(event), type="mstate") ~ 1,data=mgus1,
> subset=(start==0))
> plot(fitCI)
> 2. If I include one variate ('sex'), I get 4 curves (attached; I guess because there are
> two levels in 'sex' and 2 competing risks):
> fitCI <- survfit(Surv(stop, status*as.numeric(event), type="mstate") ~sex,data=mgus1,
> subset=(start==0))
> plot(fitCI)
> However, I want to just have 2 cumulative incidence curves estimated from several
> covariates (such as 'sex', 'age', 'alb', etc. in mgus1). Could you please help me to do
> that? Thank you very much!
> II. Problem 2:
> I try using an example from sourcecode.pdf:
> fit <- survfit(Surv(time, status, type=?mstate?) ~ sex, data=mine)
> but where can I have the 'mine' data? Thank you!
>
> Best,
>
> Jieyue
>



From istazahn at gmail.com  Tue Dec 31 23:37:06 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 31 Dec 2013 17:37:06 -0500
Subject: [R] Working with Date
In-Reply-To: <CA+dpOJk=Kkv3P5p64WsKm-M9w0mR59usEFpAYzyLPXrcq1bHnA@mail.gmail.com>
References: <CA+dpOJk=Kkv3P5p64WsKm-M9w0mR59usEFpAYzyLPXrcq1bHnA@mail.gmail.com>
Message-ID: <CA+vqiLFkWY1Lb_ZHprggmyAL_x74VZb6LH12QAqPPd0WCTvusQ@mail.gmail.com>

Use, format() to extract a character string representation of the
year, then paste() it together with Months. Like this:

paste(Months, format(Given_Date, format = "%Y"), sep = "-")

See ?strftime for details.

Best,
Ista

On Tue, Dec 31, 2013 at 4:53 PM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> Happy new year 2014 to every R gurus and users.
>
> I am struggling with some calculation with dates... Let say I have
> following vector of months:
>
> Months <- c("Jan", "Dec", "Mar")
>
> Now I need to assign year with them. This assignment will be based on some
> given date. Let say my given date is :
>
> Given_Date <- as.Date("2013-12-23")
>
> So in this case, the modified month will be:
>
>  Months_Mod <- c("Jan-2014", "Dec-2013", "Mar-2014")
>
> However if given date is:
>
> Given_Date <- as.Date("2014-01-04")
>
> then the modified months will be:
>
>  Months_Mod <- c("Jan-2014", "Dec-2014", "Mar-2014")
>
> My problem is that, I can not extablish some logic around it, so that I can
> do it programmatically for any Month-vector and for any Given-date.
>
> Can someone help me to accomplice this?
>
> Thank for your help
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jim at bitwrit.com.au  Tue Dec 31 23:57:08 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 01 Jan 2014 09:57:08 +1100
Subject: [R] Working with Date
In-Reply-To: <CA+dpOJk=Kkv3P5p64WsKm-M9w0mR59usEFpAYzyLPXrcq1bHnA@mail.gmail.com>
References: <CA+dpOJk=Kkv3P5p64WsKm-M9w0mR59usEFpAYzyLPXrcq1bHnA@mail.gmail.com>
Message-ID: <52C34BC4.7000008@bitwrit.com.au>

On 01/01/2014 08:53 AM, Christofer Bogaso wrote:
> Hi again,
>
> Happy new year 2014 to every R gurus and users.
>
> I am struggling with some calculation with dates... Let say I have
> following vector of months:
>
> Months<- c("Jan", "Dec", "Mar")
>
> Now I need to assign year with them. This assignment will be based on some
> given date. Let say my given date is :
>
> Given_Date<- as.Date("2013-12-23")
>
> So in this case, the modified month will be:
>
>   Months_Mod<- c("Jan-2014", "Dec-2013", "Mar-2014")
>
> However if given date is:
>
> Given_Date<- as.Date("2014-01-04")
>
> then the modified months will be:
>
>   Months_Mod<- c("Jan-2014", "Dec-2014", "Mar-2014")
>
> My problem is that, I can not extablish some logic around it, so that I can
> do it programmatically for any Month-vector and for any Given-date.
>
> Can someone help me to accomplice this?
>
Hi Christofer,
I would like to be an accomplice in this, but I can't quite work out 
your logic. I thought that you might want:

IF Given_Date is in the same month as an element of Months

THEN use the year in Given_Date

ELSE use the year in Given_Date plus 1

However, when I programmed it:

assignYear<-function(index_date,months) {
  index_year<-as.numeric(format(index_date,"%Y"))
  index_month<-which(months==format(index_date,"%b"))
  dates<-as.Date(paste(index_year+1,months,"1",sep="-"),"%Y-%b-%d")
  dates[index_month]<-
   as.Date(paste(index_year,months[index_month],"1",sep="-"),"%Y-%b-%d")
  return(format(dates,"%Y-%b"))
}

it didn't work for the second example. Could you give some idea of what 
you want to do?

Jim



From parkhurs at imap.iu.edu  Tue Dec 31 17:38:54 2013
From: parkhurs at imap.iu.edu (David Parkhurst)
Date: Tue, 31 Dec 2013 11:38:54 -0500
Subject: [R] Where did lost variables go, with example
In-Reply-To: <52C2F184.5030409@gmail.com>
References: <52C2D51B.5090705@indiana.edu> <52C2D939.8090300@imap.iu.edu>
	<52C2F184.5030409@gmail.com>
Message-ID: <52C2F31E.2070009@imap.iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131231/c86de6c4/attachment-0001.pl>

From jieyueli82 at gmail.com  Tue Dec 31 21:05:40 2013
From: jieyueli82 at gmail.com (Jieyue Li)
Date: Tue, 31 Dec 2013 12:05:40 -0800
Subject: [R] cumulative incidence for mstate in Survival package in R
In-Reply-To: <52C2957C.7010806@umu.se>
References: <CALYjA0T3T7JbBOL8k_GMY4xm66k5aDXMXQ1mQTn6PT4sbUVBBQ@mail.gmail.com>
	<52C2957C.7010806@umu.se>
Message-ID: <CALYjA0S_uP29KNvUxeD5x2Uo+hL=t0LVfJrPmz1QwwTTRzHidA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131231/7b61dd5c/attachment-0001.pl>

