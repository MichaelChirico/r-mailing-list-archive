From thoffman at zappa.sax.de  Sat Feb  1 01:45:03 2003
From: thoffman at zappa.sax.de (Thomas Hoffmann)
Date: Sat Feb  1 01:45:03 2003
Subject: [R] Do not understand: log10(-0.04)
Message-ID: <3E3B18EA.2010509@zappa.sax.de>

I ran into some mysterious crashes of R and when stepping through the 
code it appeared to me that a call to

	GScale(0.0,1.0,1,dd)

(as e.g. in do_plot_new(), plot.c:458 )

possibly with min=-0.04 runs into (graphics.c:1911)

    Rf_gpptr(dd)->logusr[0] = Rf_dpptr(dd)->logusr[0] = log10(min);

which should end up with a domain error.

As I cannot reproduce this fully, I asked myself if there is some 
mysterious handling of this situation.

Can anybody explain this to me?

Thomas.



From djw1005 at cam.ac.uk  Sat Feb  1 02:56:02 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Sat Feb  1 02:56:02 2003
Subject: [R] Trouble with optim
Message-ID: <Pine.SOL.3.96.1030201013245.10933A-100000@draco.cus.cam.ac.uk>

I am having trouble with optim. It claims to have converged to a minimum,
yet it has in the course of the optimization visited many points which are
closer to optimal. I would be grateful for any explanation of this
behaviour.

I'm trying to estimate the parameters in the model
  X ~ Binomial(1,p) * NegBin(mu,theta).
So I define a log likelihood function, and invoke optim thus:
  o <- optim (c(.7,10.3,8.5), fn=loglikfun, method="L-BFGS-B",
              lower=c(.001,.001,.001), upper=c(1,Inf,Inf))
The initial parameters are an educated guess. I made the loglikfun print
out some information every time it's called. An (edited) output is like
this:

Eval fn at 0.7 10.3 8.5 --- Val = 42.70597
Eval fn at 0.701 10.3 8.5 --- Val = 42.70595
Eval fn at 0.699 10.3 8.5 --- Val = 42.70603
...
Eval fn at 0.7425713 21.12820 0.001 --- Val = 64.99
Eval fn at 0.7425713 21.12920 0.002 --- Val = 60.20449
Eval fn at 0.7425713 21.12920 0.001 --- Val = 64.99

> o$val
[1] 64.99
> o$convergence
[1] 0
> o$message
[1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"

So optim thinks it has found an optimum (i.e. minimum). But my initial
guess is better than optim's answer; and optim has visited many points
which are better than its final answer.

If I choose a different initial guess, like c(.7,10.3,1), optim reaches
the answer I expect.

What is going on?

Damon Wischik.


I'm running R 1.6.2 on Windows 2000.

Sys.info() tells me:

sysname: Windows
version: (build 2195) Service Pack 2
machine: x86
release: NT 5.0

R.Version() tells me:

platform: i386-pc-mingw32
arch: i386
os: mingw32
system: i386, mingw32
status: 
R.version.string: R version 1.6.2, 2003-01-10


My full code is here:

dnegbinp <- function(x,prob,mu,size,log=FALSE) {
  ll <- ifelse(x==0,
          log(1-prob+prob*dnbinom(0*x,mu=mu,size=size)),
          log(prob)+dnbinom(x,mu=mu,size=size,log=TRUE));
  if (log) ll else exp(ll);
  }

x <- c(1,3,0,19,32,0,0,2,23,23)

loglikfun <- function(p) {
    cat("Eval fn at ")
    cat(p)
    s <- -sum(dnegbinp(x, prob=p[[1]],mu=p[[2]],size=p[[3]], log=TRUE))
    cat(" --- Val = ")
    cat(s)
    cat("\n")
    s }

o <- optim (c(.7,10.3,8.5), fn=loglikfun, method="L-BFGS-B",
       lower=c(.001,.001,.001), upper=c(1,Inf,Inf))
o$val
o$convergence
o$message



From ptremb17 at po-box.mcgill.ca  Sat Feb  1 03:25:03 2003
From: ptremb17 at po-box.mcgill.ca (ptremb17)
Date: Sat Feb  1 03:25:03 2003
Subject: [R] Read.table problem
Message-ID: <3E7E0A86@webmail.mcgill.ca>

Hi !

I am new to R, and using the MAC version onto Mac OS 9.1. My question concerns 
the problem I encounter when I try to read some data I have using the 
read.table function. I always get an error of type : Error in scan(file = 
file, what = what, sep = sep, quote = quote, dec = dec,  :
	line 1 did not have 9 elements

Here is my code:

varnames <- c("names", "symbol", "price", "displ", "gas", "weight", "reliab", 
"origin", "type")

cardat <- read.table("PowerMac 7300:Logiciels de 
Statistiques:rm162:car02.txt", col.names=varnames, 
as.is=c(F,T,F,F,F,F,F,F,F,F))

Can you advice me ?

Thanks in advance,

Pascale Tremblay



From RexBryan1 at attbi.com  Sat Feb  1 03:35:03 2003
From: RexBryan1 at attbi.com (Rex_Bryan@urscorp.com)
Date: Sat Feb  1 03:35:03 2003
Subject: [R] Re-assigning vector elements based on their initial values.
Message-ID: <00ec01c2c99b$07f5d360$3182fd0c@dell1700>

Is there an eloquent solution to re-assign vector element values?
I have a vector which contains chemical data, some of them are "flagged" as
non-detected values by their negative values.
I can find the statistics on the positive values in vector "v"  simply by
typing:
>v<- c(5,5,-3,-3,7,8,10)

> v[(v>0)]
[1] 5  5  7  8  10

I can also convert to positive values by
>asb(v)
[1]  5  5  3  3  7  9  10

I then can do mean() and var() etc.

But when I want to come up with a way to change a negative value to a
postive 1/2 value I couldn't come up with a
nice way using "vectoral syntax" to do it.  In the method I came up with , I
discovered that I have to pre-define a new vector "v.new" or I get an error.

>v.new <-v

then I have to loop through all of the elements!

>for(i in 1:length(v)){ if (v[i] < 0) v.new[i] <-  -1*v[i]/2 else v[i] <-
v[i]}
> v.new
[1]  5.0  5.0  -1.5  -1.5  7.0  9.0  10.0

This works but seems labored given the previous crisp vector operations.


REX



From ggrothendieck at yifan.net  Sat Feb  1 06:28:14 2003
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Sat Feb  1 06:28:14 2003
Subject: [R] [Summary] Problems for 13 year old
Message-ID: <3E3B1412.19887.6CD4D7@localhost>

This e-mail
- summarizes some of the responses/suggestions to using R for 13 year olds
  from my query on this list
- discusses some additional investigation I did
- the approach I am currently using (which will likely incorporate your suggestions 
for R)

SUGGESTIONS

- find relationship between monthly heating bills and temperature.  For data
  see http://lwf.ncdc.noaa.gov/cgi-bin/res40.pl?page=climvisgsod.html

- generate fractal images, get chaotic behavior from a simple iterated 
  function, or simply plot 3-d surfaces of sines and cosines

- rep('Dad is a task master', 5000) and 
  paste(c('Joe','Sally','Roger'),'is not playing with a full deck.')

- analyze Bush vs. Gore vote.  See http://www.sas.upenn.edu/~baron/policy.html .

- rate autos (or other product) via several criteria and use stat methods to
  combine these into a single desirability score

- spam filtering See http://www.paulgraham.com/spam.html and
  http://www.mozilla.org/mailnews/spam.html .

LANGUAGES

Suggestions. I don't really want to get too sidetracked into the relative
merits of various languages here as the intention was to focus on science, math
and stats rather than programming, per se, however, for completeness some
people mentioned the following two languages:
- python (www.python.org).  www.pygame.org allows you to quickly develop
  games in python and I noticed www.pythoncard.org which in the spirit of Apple's 
  HyperCard (which is a commercial product at hypercard.apple.com that could 
  also be considered)
- the kid-friendly lisp variant, logo (el.media.mit.edu/logo-foundation,
  education.mit.edu/starlogo)

First Languages. Also my googling revealed that first year university courses 
in programming often use:
- the squeak version of smalltalk (www.squeak.org),
- scheme (www.drscheme.org is one possibility of many) and 
- java (java.sun.com , www.bluej.org).   

RAD. On the theory that rapid application development (RAD) provides better 
motivation, the commercial www.realbasic.com could be considered.

Other. Finally, I am not sure where this one fits but I also came across 
www.toontalk.com which is a concurrent constraint language aimed at kids.

CURRENT APPROACH

My current approach is to start with HTML and then transition to Javascript 
followed by R:     HTML -->  Javascript --> R

I think motivation is key since the exercise is pointless if the student lacks  interest.
HTML is pretty motivating since it does not take long to teach a basic tag
set and after that you can develop your own web pages which is empowering.  
Moving to Javascriptis quite motivating since it allows one to put nifty dynamic 
features into your web pages.  By that time you are using programming and its a 
natural transition from Javascript to R since the syntaxes of both are inspired by C.

For teaching HTML, which is where I am now, I printed out the tag reference at 
werbach.com and both source and web page image of the pages at 
www.epcomm.com/webwiz .  I am still deciding on how to proceed with Javascript
and the answers here will undoubtedly help me formulate my approach to R.

Variety. This approach means that we will have covered topics in:
- web design via HTML
- programming via Javascript, and
- scientific/math/stats via R
This should give him a broad introduction to three different areas from
which I can assess his relative interest and return to refocus on that area of 
greatest appeal to him.


Thanks to those who responded.



From ripley at stats.ox.ac.uk  Sat Feb  1 08:09:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Feb  1 08:09:04 2003
Subject: [R] Trouble with optim
In-Reply-To: <Pine.SOL.3.96.1030201013245.10933A-100000@draco.cus.cam.ac.uk>
Message-ID: <Pine.LNX.4.44.0302010704240.3297-100000@gannet.stats>

I thinks it has found a *local* minimum.  It is not a global optimizer.

You appear to have made no attempt to scale the problem as the help page 
suggests you need to.  Please look into this, as from what little 
information you give I think the initial step has overshot.

On Sat, 1 Feb 2003, Damon Wischik wrote:

> 
> I am having trouble with optim. It claims to have converged to a minimum,
> yet it has in the course of the optimization visited many points which are
> closer to optimal. I would be grateful for any explanation of this
> behaviour.
> 
> I'm trying to estimate the parameters in the model
>   X ~ Binomial(1,p) * NegBin(mu,theta).
> So I define a log likelihood function, and invoke optim thus:
>   o <- optim (c(.7,10.3,8.5), fn=loglikfun, method="L-BFGS-B",
>               lower=c(.001,.001,.001), upper=c(1,Inf,Inf))
> The initial parameters are an educated guess. I made the loglikfun print
> out some information every time it's called. An (edited) output is like
> this:
> 
> Eval fn at 0.7 10.3 8.5 --- Val = 42.70597
> Eval fn at 0.701 10.3 8.5 --- Val = 42.70595
> Eval fn at 0.699 10.3 8.5 --- Val = 42.70603
> ...
> Eval fn at 0.7425713 21.12820 0.001 --- Val = 64.99
> Eval fn at 0.7425713 21.12920 0.002 --- Val = 60.20449
> Eval fn at 0.7425713 21.12920 0.001 --- Val = 64.99
> 
> > o$val
> [1] 64.99
> > o$convergence
> [1] 0
> > o$message
> [1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"
> 
> So optim thinks it has found an optimum (i.e. minimum). But my initial
> guess is better than optim's answer; and optim has visited many points
> which are better than its final answer.
> 
> If I choose a different initial guess, like c(.7,10.3,1), optim reaches
> the answer I expect.
> 
> What is going on?
> 
> Damon Wischik.
> 
> 
> I'm running R 1.6.2 on Windows 2000.
> 
> Sys.info() tells me:
> 
> sysname: Windows
> version: (build 2195) Service Pack 2
> machine: x86
> release: NT 5.0
> 
> R.Version() tells me:
> 
> platform: i386-pc-mingw32
> arch: i386
> os: mingw32
> system: i386, mingw32
> status: 
> R.version.string: R version 1.6.2, 2003-01-10
> 
> 
> My full code is here:
> 
> dnegbinp <- function(x,prob,mu,size,log=FALSE) {
>   ll <- ifelse(x==0,
>           log(1-prob+prob*dnbinom(0*x,mu=mu,size=size)),
>           log(prob)+dnbinom(x,mu=mu,size=size,log=TRUE));
>   if (log) ll else exp(ll);
>   }
> 
> x <- c(1,3,0,19,32,0,0,2,23,23)
> 
> loglikfun <- function(p) {
>     cat("Eval fn at ")
>     cat(p)
>     s <- -sum(dnegbinp(x, prob=p[[1]],mu=p[[2]],size=p[[3]], log=TRUE))
>     cat(" --- Val = ")
>     cat(s)
>     cat("\n")
>     s }
> 
> o <- optim (c(.7,10.3,8.5), fn=loglikfun, method="L-BFGS-B",
>        lower=c(.001,.001,.001), upper=c(1,Inf,Inf))
> o$val
> o$convergence
> o$message
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From djw1005 at cam.ac.uk  Sat Feb  1 12:55:03 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Sat Feb  1 12:55:03 2003
Subject: [R] Trouble with optim
In-Reply-To: <Pine.LNX.4.44.0302010704240.3297-100000@gannet.stats>
Message-ID: <Pine.SOL.3.96.1030201113209.20662A-100000@draco.cus.cam.ac.uk>

> I thinks it has found a *local* minimum.  It is not a global optimizer.

It has not found a local minimum. The derivatives at its last guess are
these:

d/dprob: -9.4, at prob=.7, 
  function is pretty much linear for prob in [.2,1]
d/dmu: 0.0002, at mu=21, 
  function is pretty much linear for mu in [5,30]
  (Yes, a clear sign of a badly scaled problem!)
d/dtheta: -6900, at theta=.001, 
  function has a vertical asymptote tending to +Inf as theta->0
  (though to make the function finite, I bounded it to theta>=.001)  

It might believe it's found a local minimum in mu, but it oughtn't to
think it's found one in at least one of the other parameters. If it does
think it has found a local minimum, why does it think so?

I'm still puzzled by its behaviour at the last points it visits:

Eval fn at 0.7425713 21.12820 0.001 --- Val = 64.99
Eval fn at 0.7425713 21.12920 0.002 --- Val = 60.20449
Eval fn at 0.7425713 21.12920 0.001 --- Val = 64.99

it visits a good point, and then straight away after settles on a worse!

> You appear to have made no attempt to scale the problem as the help page 
> suggests you need to.  Please look into this, as from what little 
> information you give I think the initial step has overshot.

I did note that suggestion, both in the help page and in MASS (4th ed). In
this particular case, I can see how to scale things (I can even
provide derivatives). (Although the loglik function, as a function of
theta, has a vertical asymptote at theta=0, so I guess I would have to
reexpress the loglik function as a function of some transform of theta).

But this is part of a general model-fitting routine, with vectors for
prob, mu and theta according to factors, in which it is not at all clear
to me how to scale parameters. Does anyone have any general
recommendations?

Damon.


In the unlikely event that the following is of interest, here is a trace
of the values it visits

Eval fn at 0.7 10.3 8.5 --- Val = 42.70597
Eval fn at 0.701 10.3 8.5 --- Val = 42.70595
Eval fn at 0.699 10.3 8.5 --- Val = 42.70603
Eval fn at 0.7 10.301 8.5 --- Val = 42.70462
Eval fn at 0.7 10.299 8.5 --- Val = 42.70732
Eval fn at 0.7 10.3 8.501 --- Val = 42.70698
Eval fn at 0.7 10.3 8.499 --- Val = 42.70496
Eval fn at 0.723089 11.10079 7.901503 --- Val = 41.20297
Eval fn at 0.724089 11.10079 7.901503 --- Val = 41.20411
Eval fn at 0.722089 11.10079 7.901503 --- Val = 41.20188
Eval fn at 0.723089 11.10179 7.901503 --- Val = 41.20203
Eval fn at 0.723089 11.09979 7.901503 --- Val = 41.20392
Eval fn at 0.723089 11.10079 7.902503 --- Val = 41.20397
Eval fn at 0.723089 11.10079 7.900503 --- Val = 41.20197
Eval fn at 0.001 13.98670 5.534439 --- Val = 79.65909
Eval fn at 0.002 13.98670 5.534439 --- Val = 74.81006
Eval fn at 0.001 13.98670 5.534439 --- Val = 79.65909
Eval fn at 0.001 13.98770 5.534439 --- Val = 79.65899
Eval fn at 0.001 13.98570 5.534439 --- Val = 79.6592
Eval fn at 0.001 13.98670 5.535439 --- Val = 79.6602
Eval fn at 0.001 13.98670 5.533439 --- Val = 79.65797
Eval fn at 0.4611668 12.14759 7.042902 --- Val = 40.72491
Eval fn at 0.4621668 12.14759 7.042902 --- Val = 40.71531
Eval fn at 0.4601668 12.14759 7.042902 --- Val = 40.73455
Eval fn at 0.4611668 12.14859 7.042902 --- Val = 40.72437
Eval fn at 0.4611668 12.14659 7.042902 --- Val = 40.72545
Eval fn at 0.4611668 12.14759 7.043902 --- Val = 40.72593
Eval fn at 0.4611668 12.14759 7.041902 --- Val = 40.72389
Eval fn at 0.6522179 14.65926 5.138706 --- Val = 36.97182
Eval fn at 0.6532179 14.65926 5.138706 --- Val = 36.96971
Eval fn at 0.6512179 14.65926 5.138706 --- Val = 36.97397
Eval fn at 0.6522179 14.66026 5.138706 --- Val = 36.97182
Eval fn at 0.6522179 14.65826 5.138706 --- Val = 36.97183
Eval fn at 0.6522179 14.65926 5.139706 --- Val = 36.97298
Eval fn at 0.6522179 14.65926 5.137706 --- Val = 36.97066
Eval fn at 0.7531634 19.00619 1.708864 --- Val = 32.87589
Eval fn at 0.7541634 19.00619 1.708864 --- Val = 32.87811
Eval fn at 0.7521634 19.00619 1.708864 --- Val = 32.87372
Eval fn at 0.7531634 19.00719 1.708864 --- Val = 32.87603
Eval fn at 0.7531634 19.00519 1.708864 --- Val = 32.87575
Eval fn at 0.7531634 19.00619 1.709864 --- Val = 32.87732
Eval fn at 0.7531634 19.00619 1.707864 --- Val = 32.87446
Eval fn at 0.8034285 21.17072 0.001 --- Val = 64.44045
Eval fn at 0.8044285 21.17072 0.001 --- Val = 64.43177
Eval fn at 0.8024285 21.17072 0.001 --- Val = 64.44914
Eval fn at 0.8034285 21.17172 0.001 --- Val = 64.44045
Eval fn at 0.8034285 21.16972 0.001 --- Val = 64.44045
Eval fn at 0.8034285 21.17072 0.002 --- Val = 59.65652
Eval fn at 0.8034285 21.17072 0.001 --- Val = 64.44045
Eval fn at 0.7706081 19.75740 1.116143 --- Val = 32.23114
Eval fn at 0.7716081 19.75740 1.116143 --- Val = 32.23324
Eval fn at 0.7696081 19.75740 1.116143 --- Val = 32.2291
Eval fn at 0.7706081 19.75840 1.116143 --- Val = 32.23126
Eval fn at 0.7706081 19.75640 1.116143 --- Val = 32.23103
Eval fn at 0.7706081 19.75740 1.117143 --- Val = 32.23228
Eval fn at 0.7706081 19.75740 1.115143 --- Val = 32.23000
Eval fn at 0.7425713 21.12920 0.001 --- Val = 64.99
Eval fn at 0.7435713 21.12920 0.001 --- Val = 64.98061
Eval fn at 0.7415713 21.12920 0.001 --- Val = 64.99941
Eval fn at 0.7425713 21.13020 0.001 --- Val = 64.99
Eval fn at 0.7425713 21.12820 0.001 --- Val = 64.99
Eval fn at 0.7425713 21.12920 0.002 --- Val = 60.20449
Eval fn at 0.7425713 21.12920 0.001 --- Val = 64.99

And a trace of what optim is doing. I'm sure this can tell me what's going
wrong, but I don't understand the optimization method, so I can't
interpret this output.

N = 3, M = 5 machine precision = 2.22045e-016
L = 0.001 0.001 0.001 
X0 = 0.7 10.3 8.5 
U = 1 1.#INF 1.#INF 
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       42.706  |proj g|=       1.3527
Iteration     0

---------------- CAUCHY entered-------------------

There are 2  breakpoints

Piece      1 f1, f2 at start point -2.8533e+000 2.8533e+000
Distance to the next break point =  7.6921e+000
Distance to the stationary point =  1.0000e+000

GCP found in this segment
Piece      1 f1, f2 at start point -2.8533e+000 2.8533e+000
Distance to the stationary point =  1.0000e+000
Cauchy X =  0.739001 11.6527 7.48904 

---------------- exit CAUCHY----------------------

3  variables are free at GCP on iteration 1
LINE SEARCH 0 times; norm of step = 1
X = 0.723089 11.1008 7.9015 
G = 1.11513 -0.944325 1.00394 
Iteration     1

---------------- CAUCHY entered-------------------

There are 2  breakpoints

Piece      1 f1, f2 at start point -3.1431e+000 7.9760e+000
Distance to the next break point =  6.4754e-001
Distance to the stationary point =  3.9407e-001

GCP found in this segment
Piece      1 f1, f2 at start point -3.1431e+000 7.9760e+000
Distance to the stationary point =  3.9407e-001
Cauchy X =  0.283647 11.4729 7.50588 

---------------- exit CAUCHY----------------------

3  variables are free at GCP on iteration 2
LINE SEARCH 1 times; norm of step = 1.37898
X = 0.461167 12.1476 7.0429 
G = -9.62019 -0.542 1.022 
Iteration     2

---------------- CAUCHY entered-------------------

There are 2  breakpoints

Piece      1 f1, f2 at start point -9.3886e+001 4.1691e+003
Distance to the next break point =  5.6011e-002
Distance to the stationary point =  2.2519e-002

GCP found in this segment
Piece      1 f1, f2 at start point -9.3886e+001 4.1691e+003
Distance to the stationary point =  2.2519e-002
Cauchy X =  0.677808 12.1598 7.01989 

---------------- exit CAUCHY----------------------

3  variables are free at GCP on iteration 3
LINE SEARCH 0 times; norm of step = 3.15767
X = 0.652218 14.6593 5.13871 
G = -2.13069 -0.00539645 1.15734 
Iteration     3

---------------- CAUCHY entered-------------------

There are 2  breakpoints

Piece      1 f1, f2 at start point -5.8793e+000 2.4656e+002
Distance to the next break point =  1.6322e-001
Distance to the stationary point =  2.3846e-002

GCP found in this segment
Piece      1 f1, f2 at start point -5.8793e+000 2.4656e+002
Distance to the stationary point =  2.3846e-002
Cauchy X =  0.703026 14.6594 5.11111 

---------------- exit CAUCHY----------------------

3  variables are free at GCP on iteration 4
LINE SEARCH 2 times; norm of step = 6.49509
X = 0.770608 19.7574 1.11614 
G = 2.07073 0.113724 1.1404 
Iteration     4

---------------- CAUCHY entered-------------------

There are 3  breakpoints

Piece      1 f1, f2 at start point -5.6014e+000 2.7530e+002
Distance to the next break point =  3.7166e-001
Distance to the stationary point =  2.0346e-002

GCP found in this segment
Piece      1 f1, f2 at start point -5.6014e+000 2.7530e+002
Distance to the stationary point =  2.0346e-002
Cauchy X =  0.728477 19.7551 1.09294 

---------------- exit CAUCHY----------------------

3  variables are free at GCP on iteration 5
LINE SEARCH 0 times; norm of step = 1.7681
X = 0.742571 21.1292 0.001 
G = -9.39676 0.000205735 -4785.51 

iterations 5
function evaluations 9
segments explored during Cauchy searches 5
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4785.51
final function value 64.99

X = 0.742571 21.1292 0.001 
F = 64.99
final  value 64.990005 
converged



From ozric at web.de  Sat Feb  1 13:12:04 2003
From: ozric at web.de (Christian Schulz)
Date: Sat Feb  1 13:12:04 2003
Subject: [R] Read.table problem
References: <3E7E0A86@webmail.mcgill.ca>
Message-ID: <001401c2c9e9$fb5f87a0$e0ba07d5@c5c9i0>

Perhaps your data entrys delimited with comma, semicolon so you have
to use sep="," or sep=";" .

For tab-delimited data i take read.delim.

hope this helps.christian




----- Original Message -----
From: "ptremb17" <ptremb17 at po-box.mcgill.ca>
To: "R-HELP" <r-help at stat.math.ethz.ch>
Sent: Saturday, February 01, 2003 3:24 AM
Subject: [R] Read.table problem


> Hi !
>
> I am new to R, and using the MAC version onto Mac OS 9.1. My question
concerns
> the problem I encounter when I try to read some data I have using the
> read.table function. I always get an error of type : Error in scan(file =
> file, what = what, sep = sep, quote = quote, dec = dec,  :
> line 1 did not have 9 elements
>
> Here is my code:
>
> varnames <- c("names", "symbol", "price", "displ", "gas", "weight",
"reliab",
> "origin", "type")
>
> cardat <- read.table("PowerMac 7300:Logiciels de
> Statistiques:rm162:car02.txt", col.names=varnames,
> as.is=c(F,T,F,F,F,F,F,F,F,F))
>
> Can you advice me ?
>
> Thanks in advance,
>
> Pascale Tremblay
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jfox at mcmaster.ca  Sat Feb  1 13:21:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat Feb  1 13:21:03 2003
Subject: [R] Re-assigning vector elements based on their initial
  values.
In-Reply-To: <00ec01c2c99b$07f5d360$3182fd0c@dell1700>
Message-ID: <5.1.0.14.2.20030201070839.01df59a0@mcmail.cis.mcmaster.ca>

Dear Rex,

You can use if.else, which is vectorized:

         > v.new <- ifelse(v < 0, -v/2, v)
         > v.new
         [1]  5.0  5.0  1.5  1.5  7.0  8.0 10.0

(By the way, the solution that you suggested using a loop works, but for 
some reason the sign is wrong in the result that you printed; notice that 
your "else" clause does nothing -- you probably meant to assign to v.new 
not v -- and is unnecessary in any event.)

I hope that this helps,
  John



At 07:38 PM 1/31/2003 -0700, Rex_Bryan at urscorp.com wrote:
>Is there an eloquent solution to re-assign vector element values?
>I have a vector which contains chemical data, some of them are "flagged" as
>non-detected values by their negative values.
>I can find the statistics on the positive values in vector "v"  simply by
>typing:
> >v<- c(5,5,-3,-3,7,8,10)
>
> > v[(v>0)]
>[1] 5  5  7  8  10
>
>I can also convert to positive values by
> >asb(v)
>[1]  5  5  3  3  7  9  10
>
>I then can do mean() and var() etc.
>
>But when I want to come up with a way to change a negative value to a
>postive 1/2 value I couldn't come up with a
>nice way using "vectoral syntax" to do it.  In the method I came up with , I
>discovered that I have to pre-define a new vector "v.new" or I get an error.
>
> >v.new <-v
>
>then I have to loop through all of the elements!
>
> >for(i in 1:length(v)){ if (v[i] < 0) v.new[i] <-  -1*v[i]/2 else v[i] <-
>v[i]}
> > v.new
>[1]  5.0  5.0  -1.5  -1.5  7.0  9.0  10.0
>
>This works but seems labored given the previous crisp vector operations.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From jfox at mcmaster.ca  Sat Feb  1 13:30:11 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat Feb  1 13:30:11 2003
Subject: [R] Read.table problem
In-Reply-To: <3E7E0A86@webmail.mcgill.ca>
Message-ID: <5.1.0.14.2.20030201072324.01e4d4e0@mcmail.cis.mcmaster.ca>

Dear Pascale,

It seems an obvious question, so perhaps not worth asking, but did you 
check that line 1 of the data file actually has 9 elements (separated by 
white space)? (I notice that your as.is argument specifies 10 elements; I 
don't believe that this should cause a problem if there are really 9.) If 
inspection of the file doesn't reveal the problem, you could try to run 
count.fields() on the file to see how many elements R thinks are in each line.

John

At 09:24 PM 1/31/2003 -0500, ptremb17 wrote:
>Hi !
>
>I am new to R, and using the MAC version onto Mac OS 9.1. My question 
>concerns
>the problem I encounter when I try to read some data I have using the
>read.table function. I always get an error of type : Error in scan(file =
>file, what = what, sep = sep, quote = quote, dec = dec,  :
>         line 1 did not have 9 elements
>
>Here is my code:
>
>varnames <- c("names", "symbol", "price", "displ", "gas", "weight", "reliab",
>"origin", "type")
>
>cardat <- read.table("PowerMac 7300:Logiciels de
>Statistiques:rm162:car02.txt", col.names=varnames,
>as.is=c(F,T,F,F,F,F,F,F,F,F))

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From ripley at stats.ox.ac.uk  Sat Feb  1 13:40:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Feb  1 13:40:03 2003
Subject: [R] Read.table problem
In-Reply-To: <001401c2c9e9$fb5f87a0$e0ba07d5@c5c9i0>
Message-ID: <Pine.LNX.4.44.0302011233260.4189-100000@gannet.stats>

Let's try to scotch this one.

That is what happens with an unpatched build of R 1.6.2 on classic MacOS,
which has CR line endings in text files and the OS is not treating as
text-mode files (as say Windows does and many Mac applications do).  It
happens only with such files and only with R 1.6.2.  There is a patch on 
CRAN for those who downloaded rm162 before Jan 22.

On Sat, 1 Feb 2003, Christian Schulz wrote:

> Perhaps your data entrys delimited with comma, semicolon so you have
> to use sep="," or sep=";" .
> 
> For tab-delimited data i take read.delim.
> 
> hope this helps.christian
> 
> 
> 
> 
> ----- Original Message -----
> From: "ptremb17" <ptremb17 at po-box.mcgill.ca>
> To: "R-HELP" <r-help at stat.math.ethz.ch>
> Sent: Saturday, February 01, 2003 3:24 AM
> Subject: [R] Read.table problem
> 
> 
> > Hi !
> >
> > I am new to R, and using the MAC version onto Mac OS 9.1. My question
> concerns
> > the problem I encounter when I try to read some data I have using the
> > read.table function. I always get an error of type : Error in scan(file =
> > file, what = what, sep = sep, quote = quote, dec = dec,  :
> > line 1 did not have 9 elements
> >
> > Here is my code:
> >
> > varnames <- c("names", "symbol", "price", "displ", "gas", "weight",
> "reliab",
> > "origin", "type")
> >
> > cardat <- read.table("PowerMac 7300:Logiciels de
> > Statistiques:rm162:car02.txt", col.names=varnames,
> > as.is=c(F,T,F,F,F,F,F,F,F,F))
> >
> > Can you advice me ?
> >
> > Thanks in advance,
> >
> > Pascale Tremblay
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fharrell at virginia.edu  Sat Feb  1 14:47:04 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sat Feb  1 14:47:04 2003
Subject: [R] [Summary] Problems for 13 year old
In-Reply-To: <3E3B1412.19887.6CD4D7@localhost>
References: <3E3B1412.19887.6CD4D7@localhost>
Message-ID: <20030201084605.471c63f9.fharrell@virginia.edu>

That sounds like a great plan and thanks for the well done summary.

One other thought.  All students need to write reports.  Learning LaTeX at this stage would give them a real efficiency tool.  In working with my 10 year old daughter the other night on OpenOffice, it was really easy to insert pictures from the Internet.  But basic stuff takes so much longer.  OpenOffice, like MS Office, kept changing fonts on her, for example, and we had to keep changing them back.  Sectioning was also more time-consuming than just typing \section{name}.

LaTeX can also teach programming:

\def\smallreport{1}
\def\textonly{0}

\ifnum\smallreport=0
  Stuff to include for large report only.
  ...
\fi

\ifnum\textonly=0
 \includegraphics{ } ...
\fi

I haven't tried this on kids yet but hope to soon.  I may also investigate lyx or possibly texmacs (Linux/Unix only) for introducing LaTeX.

Frank Harrell


On Sat, 01 Feb 2003 00:25:54 -0500
ggrothendieck at yifan.net wrote:
....
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From simon at stats.gla.ac.uk  Sat Feb  1 16:51:05 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Sat Feb  1 16:51:05 2003
Subject: [R] floating point question
In-Reply-To: <Pine.A41.4.44.0301311159200.247918-100000@homer07.u.washington.edu>
Message-ID: <Pine.SOL.3.96.1030201154207.22200A-100000@moon.stats.gla.ac.uk>

> Incidentally, this may well be a reason for the irritating habit of DLLs
> in setting the floating point precision to 53 bits (well, the irritating
> bit is not changing it back). This makes the results of computations
> more nearly independent of where the numbers end up being stored.
- I suspect that's right, I still find it a bit alarming that
a=b; if (a==b) printf("hooray") else printf("rats"); 
can occasionally print `rats' since `a' got stored in memory, `b' was left
in an fpu register and hence, when it comes to comparison, they are not
equal. Simon





> 
> 	-thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From hennig at stat.math.ethz.ch  Sat Feb  1 17:36:03 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Sat Feb  1 17:36:03 2003
Subject: [R] Overlaying histograms
Message-ID: <Pine.LNX.4.44.0302011732130.2071-100000@florence>

Hi,

is there a command for plotting two (or more) histograms in the same graph,
or is there a low-level plotting command for adding a second histogram (in
different color) to the graph of the first one?

Best,
Christian

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de



From chong at stat.purdue.edu  Sat Feb  1 17:58:02 2003
From: chong at stat.purdue.edu (Chong Gu)
Date: Sat Feb  1 17:58:02 2003
Subject: [R] c/cbind/rbind of factor variables
Message-ID: <200302011657.h11GvcP1052886@odds.stat.purdue.edu>

I guess this is a feature

> c(as.factor(2),as.factor(3))
[1] 1 1

But is there a way to turn off the feature and return the following?

[1] 2 3

Thanks for any pointer.

Chong Gu



From Paul.Bliese at NA.AMEDD.ARMY.MIL  Sat Feb  1 18:29:02 2003
From: Paul.Bliese at NA.AMEDD.ARMY.MIL (Bliese, Paul D MAJ WRAIR-Wash DC)
Date: Sat Feb  1 18:29:02 2003
Subject: [R] matrix subscripts in replacement
Message-ID: <58CAB2332C0DD511BC7900A0C9EA316D013D18D8@dasmtyjqf009.amedd.army.mil>

I'm reluctant to draw the S-PLUS and R comparison (these are different
programs after all), but could someone tell me why the following matrix
substitution works in S-PLUS, but not R.  I'm curious because matrix
substitution is a really slick way to "cleaning up" columns of data in data
frames.  For example, in the following I change values of 1 to values of 10,
but only for columns 1 and 3.

# S-PLUS example below

> TEMP<-data.frame(VAR1=c(1,2,3,4,5),VAR2=c(5,4,3,2,1),VAR3=c(1,1,1,1,NA))
> TEMP
  VAR1 VAR2 VAR3 
1    1    5    1
2    2    4    1
3    3    3    1
4    4    2    1
5    5    1   NA
> TEMP[,c(1,3)][TEMP[,c(1,3)]==1&!is.na(TEMP[,c(1,3)])]<-10
> TEMP
  VAR1 VAR2 VAR3 
1   10    5   10
2    2    4   10
3    3    3   10
4    4    2   10
5    5    1   NA

# R Example Below (version 1.6.1 Windows)

> TEMP<-data.frame(VAR1=c(1,2,3,4,5),VAR2=c(5,4,3,2,1),VAR3=c(1,1,1,1,NA))
> TEMP
  VAR1 VAR2 VAR3
1    1    5    1
2    2    4    1
3    3    3    1
4    4    2    1
5    5    1   NA
> TEMP[,c(1,3)][TEMP[,c(1,3)]==1&!is.na(TEMP[,c(1,3)])]<-10
Error in "[<-.data.frame"(*tmp*, TEMP[, c(1, 3)] == 1 & !is.na(TEMP[,  : 
        matrix subscripts not allowed in replacement


Thanks!

Paul Bliese
Walter Reed Army Institute of Research



From ripley at stats.ox.ac.uk  Sat Feb  1 18:57:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Feb  1 18:57:05 2003
Subject: [R] matrix subscripts in replacement (in a data frame)
In-Reply-To: <58CAB2332C0DD511BC7900A0C9EA316D013D18D8@dasmtyjqf009.amedd.army.mil>
Message-ID: <Pine.LNX.4.44.0302011752560.32719-100000@gannet.stats>

Simple: it's not been implemented in R.  Would you like to contribute an 
implementation?

Remember, R is a volunteer project and what gets implemented depends on 
the volunteer's needs.

On Sat, 1 Feb 2003, Bliese, Paul D MAJ WRAIR-Wash DC wrote:

> I'm reluctant to draw the S-PLUS and R comparison (these are different
> programs after all), but could someone tell me why the following matrix
> substitution works in S-PLUS, but not R.  I'm curious because matrix
> substitution is a really slick way to "cleaning up" columns of data in data
> frames.  For example, in the following I change values of 1 to values of 10,
> but only for columns 1 and 3.
> 
> # S-PLUS example below
> 
> > TEMP<-data.frame(VAR1=c(1,2,3,4,5),VAR2=c(5,4,3,2,1),VAR3=c(1,1,1,1,NA))
> > TEMP
>   VAR1 VAR2 VAR3 
> 1    1    5    1
> 2    2    4    1
> 3    3    3    1
> 4    4    2    1
> 5    5    1   NA
> > TEMP[,c(1,3)][TEMP[,c(1,3)]==1&!is.na(TEMP[,c(1,3)])]<-10
> > TEMP
>   VAR1 VAR2 VAR3 
> 1   10    5   10
> 2    2    4   10
> 3    3    3   10
> 4    4    2   10
> 5    5    1   NA
> 
> # R Example Below (version 1.6.1 Windows)
> 
> > TEMP<-data.frame(VAR1=c(1,2,3,4,5),VAR2=c(5,4,3,2,1),VAR3=c(1,1,1,1,NA))
> > TEMP
>   VAR1 VAR2 VAR3
> 1    1    5    1
> 2    2    4    1
> 3    3    3    1
> 4    4    2    1
> 5    5    1   NA
> > TEMP[,c(1,3)][TEMP[,c(1,3)]==1&!is.na(TEMP[,c(1,3)])]<-10
> Error in "[<-.data.frame"(*tmp*, TEMP[, c(1, 3)] == 1 & !is.na(TEMP[,  : 
>         matrix subscripts not allowed in replacement

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fharrell at virginia.edu  Sat Feb  1 19:28:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sat Feb  1 19:28:03 2003
Subject: [R] Overlaying histograms
In-Reply-To: <Pine.LNX.4.44.0302011732130.2071-100000@florence>
References: <Pine.LNX.4.44.0302011732130.2071-100000@florence>
Message-ID: <20030201132736.57e56cac.fharrell@virginia.edu>

Take a look at the histbackback function in http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html

F Harrell

On Sat, 1 Feb 2003 17:35:05 +0100 (CET)
Christian Hennig <hennig at stat.math.ethz.ch> wrote:

> Hi,
> 
> is there a command for plotting two (or more) histograms in the same graph,
> or is there a low-level plotting command for adding a second histogram (in
> different color) to the graph of the first one?
> 
> Best,
> Christian
> 
> -- 
> ***********************************************************************
> Christian Hennig
> Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
> and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
> hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
> hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
> #######################################################################
> ich empfehle www.boag.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From TyagiAnupam at aol.com  Sat Feb  1 20:33:03 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Sat Feb  1 20:33:03 2003
Subject: [R] Reading fixed format file
Message-ID: <144.94f14bf.2b6d7ab0@aol.com>

I am looking for suggestions to read a large fixed-column format file and 
create a data-frame with about 50,000 observations and 400 variables, each 
variable in 2--5 colums. This is on a machine with 128 Mb of RAM with R on 
Linux or MS-win. I will also be thankful for any other suggestions about 
working with data of this size.



From ripley at stats.ox.ac.uk  Sat Feb  1 20:48:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Feb  1 20:48:03 2003
Subject: [R] Reading fixed format file
In-Reply-To: <144.94f14bf.2b6d7ab0@aol.com>
Message-ID: <Pine.LNX.4.44.0302011940270.4809-100000@gannet.stats>

What do you want to do with it once you have read it in?  There is no 
point in reading in a matrix that is likely to take up all of the
available memory (160Mb if numeric) ....

Possible suggestions are to load it into a database and access in blocks
of rows or columns, or spend a small amount of money on another 1Gb of
memory and write C code in a package to read the file.

On Sat, 1 Feb 2003 TyagiAnupam at aol.com wrote:

> I am looking for suggestions to read a large fixed-column format file and 
> create a data-frame with about 50,000 observations and 400 variables, each 
> variable in 2--5 colums. This is on a machine with 128 Mb of RAM with R on 
> Linux or MS-win. I will also be thankful for any other suggestions about 
> working with data of this size.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Sat Feb  1 21:03:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sat Feb  1 21:03:03 2003
Subject: [R] c/cbind/rbind of factor variables
In-Reply-To: <200302011657.h11GvcP1052886@odds.stat.purdue.edu>
References: <200302011657.h11GvcP1052886@odds.stat.purdue.edu>
Message-ID: <x2adhfrcqi.fsf@biostat.ku.dk>

Chong Gu <chong at stat.purdue.edu> writes:

> I guess this is a feature
> 
> > c(as.factor(2),as.factor(3))
> [1] 1 1
> 
> But is there a way to turn off the feature and return the following?
> 
> [1] 2 3
> 
> Thanks for any pointer.

How about 

cc <- function(...) do.call("c", lapply(list(...),as.character))
cc(as.factor(2),as.factor(3))

?

(or as.integer(do.call.....) if you really want integers back)
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From fnj at cin.ufpe.br  Sat Feb  1 21:37:03 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Sat Feb  1 21:37:03 2003
Subject: [R] Try for to use in read.pnm()
Message-ID: <Pine.LNX.4.44.0302011707000.5998-100000@buique.cin.ufpe.br>

Hi,
I don't obtain to use try to capture an error of read.pnm().
I was using:
res <- try(read.pnm(file_name))

But I don't understand that the variable res represents, or eiher, as I
can access its attrbites.
Tks,
Francisco.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco J?nior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From chong at stat.purdue.edu  Sat Feb  1 22:01:05 2003
From: chong at stat.purdue.edu (Chong Gu)
Date: Sat Feb  1 22:01:05 2003
Subject: [R] c/cbind/rbind of factor variables 
In-Reply-To: Your message of "01 Feb 2003 21:02:13 +0100."
             <x2adhfrcqi.fsf@biostat.ku.dk> 
Message-ID: <200302012059.h11KxtP1094684@odds.stat.purdue.edu>

Thanks for all the replies.

Actually, I ran into this only because I was using the wrong approach
to solve the real problem I had.  Through private email exchanges
Professor Ripley tipped me into the right direction, so case is solved
but not through this.

Thanks to all for your attentions.

Chong Gu


> Chong Gu <chong at stat.purdue.edu> writes:
> 
> > I guess this is a feature
> > 
> > > c(as.factor(2),as.factor(3))
> > [1] 1 1
> > 
> > But is there a way to turn off the feature and return the following?
> > 
> > [1] 2 3
> > 
> > Thanks for any pointer.
> 
> How about 
> 
> cc <- function(...) do.call("c", lapply(list(...),as.character))
> cc(as.factor(2),as.factor(3))
> 
> ?
> 
> (or as.integer(do.call.....) if you really want integers back)
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From R.Goecke at t-online.de  Sat Feb  1 22:12:02 2003
From: R.Goecke at t-online.de (Roland Goecke)
Date: Sat Feb  1 22:12:02 2003
Subject: [R] LDA newbie question
Message-ID: <3E3C37E0.2070907@t-online.de>

Hi,

I have tried the (MASS) LDA example (Iris) that's given on the help 
pages but I don't fully understand the results. Perhaps someone could be 
so kind to explain it to me.

On the help pages it says as return values:

prior
means
scaling
svd
N
call

What I get as results are

prior
means
coefficients of linear discriminants
proportion of trace

OK, so the first 3 appear to be the same in both cases (perhaps just a 
different wording) and I know I can show the other return values by 
something like z$call. No problem.

But what is the proportion of trace?

Is there a simple way to get the discriminant score or do I have to 
manually multiply the coefficients with the data?

Cheers
Roland



From feldesmanm at pdx.edu  Sat Feb  1 22:21:02 2003
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Sat Feb  1 22:21:02 2003
Subject: [R] LDA newbie question
In-Reply-To: <3E3C37E0.2070907@t-online.de>
Message-ID: <5.2.0.9.2.20030201131801.0156d2f0@pop4.attglobal.net>

At 01:10 PM 2/1/2003, Roland Goecke wrote:
 >Hi,

 >Is there a simple way to get the discriminant score or do I have to
 >manually multiply the coefficients with the data?


predict.lda will generate an object with a scores component, among other 
things.

Try ?predict.lda



From feldesmanm at pdx.edu  Sat Feb  1 22:25:03 2003
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Sat Feb  1 22:25:03 2003
Subject: [R] LDA newbie question
In-Reply-To: <3E3C37E0.2070907@t-online.de>
Message-ID: <5.2.0.9.2.20030201132040.0158c690@pop4.attglobal.net>

At 01:10 PM 2/1/2003, Roland Goecke wrote:

 >But what is the proportion of trace?
 >

Is the proportion of variance explained by each successive discriminant.



From ripley at stats.ox.ac.uk  Sat Feb  1 22:30:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Feb  1 22:30:03 2003
Subject: [R] LDA newbie question
In-Reply-To: <3E3C37E0.2070907@t-online.de>
Message-ID: <Pine.LNX.4.44.0302012118320.7843-100000@gannet.stats>

On Sat, 1 Feb 2003, Roland Goecke wrote:

> I have tried the (MASS) LDA example (Iris) that's given on the help 
> pages but I don't fully understand the results. Perhaps someone could be 
> so kind to explain it to me.

`It' is explained in MASS the book, as referenced on the help page.
That also includes many examples of getting the scores (or you could 
explore the `See Also' links).

[...]

Note that the help page is correct, but you are failing to appreciate that
a return object and its printed representation are often different.  The
help page describes the first (as do all R help pages).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From zhuw at post.cis.smu.edu  Sun Feb  2 00:21:03 2003
From: zhuw at post.cis.smu.edu (zhu wang)
Date: Sun Feb  2 00:21:03 2003
Subject: [R] unable to open connection
Message-ID: <000501c2ca48$6dbb1b30$caaa7781@omnibook>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030202/8caceca8/attachment.pl

From wviechtb at s.psych.uiuc.edu  Sun Feb  2 06:10:04 2003
From: wviechtb at s.psych.uiuc.edu (Wolfgang Viechtbauer)
Date: Sun Feb  2 06:10:04 2003
Subject: [R] Finding Missing Data Patterns
Message-ID: <Pine.SOL.4.30.0302012254430.15460-100000@s.psych.uiuc.edu>

Dear R-Helpers,

I have a large data matrix, which contains missing data. The matrix
looks something like this:

1) X  X  X  X  X  X NA NA NA
2) NA NA NA NA X  X  X  X  X
3) NA NA X  X  X  X NA NA NA
4) X  X  X  X  X  X  X  X  X
5) X  X  NA NA X NA NA NA NA

and so on. Notice that the first row starts with complete data but ends
with missing. The second row starts with missing, but the rest is
complete. The third starts and ends with missing, but the middle part is
complete. The fourth is complete. What I want to do is filter out
patterns like in row 5, where the data are interrupted by missing data.
Basically, I need to test each row for a "data, at least one NA, data"
pattern.

Is there some kind of way of doing this? I am at a loss for an easy way
to accomplishing this. Any suggestions would be most appreciated!

--
Wolfgang Viechtbauer



From ligges at statistik.uni-dortmund.de  Sun Feb  2 11:34:02 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Feb  2 11:34:02 2003
Subject: [R] unable to open connection
References: <000501c2ca48$6dbb1b30$caaa7781@omnibook>
Message-ID: <3E3CF3F5.15D9D40@statistik.uni-dortmund.de>

zhu wang wrote:
> 
> Dear list members,
> 
> I have problem to load data of the library waveslim.
> After I load the library waveslim and tried to load data ibm
> 
> data(ibm)
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `ibm.txt'
> 
> I also tried other data sets without success. It works for other
> libraries though.
> 
> Any suggestions? Thanks.
> 
> Zhu Wang

That's a bug in the package which occurs on Windows (only?). Thus CC to
the package maintainer, Brandon Whitcher.
A solution would be to present the files *either* as ASCII tables *or*
as R code files.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Sun Feb  2 11:59:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Feb  2 11:59:03 2003
Subject: [R] Try for to use in read.pnm()
References: <Pine.LNX.4.44.0302011707000.5998-100000@buique.cin.ufpe.br>
Message-ID: <3E3CF9E0.6E783A7B@statistik.uni-dortmund.de>

Francisco do Nascimento Junior wrote:
> 
> Hi,
> I don't obtain to use try to capture an error of read.pnm().
> I was using:
> res <- try(read.pnm(file_name))
> 
> But I don't understand that the variable res represents, 

?try tells us:
"The value of the expression if expr is evaluated without error, but an
invisible object of class "try-error" containing the error message if it
if fails."

[R-Core: One "if" too much at the end of that sentence]


> or eiher, as I can access its attrbites.

See ?attributes and ?attr
There is only one attribute, class = "try-error", if expr fails...


> Tks,
> Francisco.
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Francisco J?nior,
> Computer Science - UFPE-Brazil
> "One life has more value that the
> world whole"
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Sun Feb  2 12:36:02 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Feb  2 12:36:02 2003
Subject: [R] Finding Missing Data Patterns
References: <Pine.SOL.4.30.0302012254430.15460-100000@s.psych.uiuc.edu>
Message-ID: <3E3D026B.96408A0E@statistik.uni-dortmund.de>


Wolfgang Viechtbauer wrote:
> 
> Dear R-Helpers,
> 
> I have a large data matrix, which contains missing data. The matrix
> looks something like this:
> 
> 1) X  X  X  X  X  X NA NA NA
> 2) NA NA NA NA X  X  X  X  X
> 3) NA NA X  X  X  X NA NA NA
> 4) X  X  X  X  X  X  X  X  X
> 5) X  X  NA NA X NA NA NA NA
> 
> and so on. Notice that the first row starts with complete data but ends
> with missing. The second row starts with missing, but the rest is
> complete. The third starts and ends with missing, but the middle part is
> complete. The fourth is complete. What I want to do is filter out
> patterns like in row 5, where the data are interrupted by missing data.
> Basically, I need to test each row for a "data, at least one NA, data"
> pattern.
> 
> Is there some kind of way of doing this? I am at a loss for an easy way
> to accomplishing this. Any suggestions would be most appreciated!
> 
> --
> Wolfgang Viechtbauer

Presumably not most efficient, but it came into my mind at first:

  apply(X, 1, function(x) grep("0.1.0", paste(as.numeric(is.na(x)),
collapse="")))

Uwe Ligges



From miranda at di.fct.unl.pt  Sun Feb  2 13:39:03 2003
From: miranda at di.fct.unl.pt (Don Eduardo Miranda)
Date: Sun Feb  2 13:39:03 2003
Subject: [R] Re: Validation of Clustering
References: <20030201110007.17111.69298.Mailman@hypatia.math.ethz.ch>
Message-ID: <001501c2cab7$eb95bc80$f801000a@pong>

For Clustering validation it maybe good to refer to "On Clustering
Validation Techniques" by Maria Hakidi.  It presents a good survey on these
kind of techniques.  You can even find this an orticles on the subject here
http://www.db-net.aueb.gr/mhalk/Publ_maria.htm
______________
Eduardo Miranda
Departamento de Inform?tica da FCT/ UNL
Quinta da Torre, 2829-516 Caparica, Portugal
Tel: +351-21 294 85 36  - Ext. 10731
Fax: +351-21 294 85 41
E-mail: miranda at di.fct.unl.pt
http://ctp.di.fct.unl.pt/QUASAR

> Date: Fri, 31 Jan 2003 12:34:47 +0100 (CET)
> From: Christian Hennig <hennig at stat.math.ethz.ch>
> To: Francisco do Nascimento Junior <fnj at cin.ufpe.br>
> cc: R-help <R-help at stat.math.ethz.ch>
> Subject: Re: [R] Validation of clustering
>
> Hi,
>
> I am not really sure what you want to know.
> If you simply want to know how to find the resulting clustering, consider
> help(clara.object). For validation and assessment of the clustering, you
> might use a silhouette plot, see help(plot.partition),
> help(partition.object).
>
> For more descriptions consider the book of Kaufman and Rousseeuw; some
free
> material is on
> http://win-www.uia.ac.be/u/statis/index.html
> (Programs->Clustering)
>
> Best,
> Christian
>
> On Thu, 30 Jan 2003, Francisco do Nascimento Junior wrote:
>
> > Hi,
> > I'm using the library cluster to cluster a set of figures (method
CLARA).
> > Somebody that it work with clustering would know informs what I make to
> > evaluate the clustering?
> >
> > Tks VM,
> > Francisco.
> > ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> > Francisco J?nior,
> > Computer Science - UFPE-Brazil
> > "One life has more value that the
> > world whole"
> > ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From james.holtman at convergys.com  Sun Feb  2 15:44:06 2003
From: james.holtman at convergys.com (james.holtman@convergys.com)
Date: Sun Feb  2 15:44:06 2003
Subject: [R] Finding Missing Data Patterns
Message-ID: <OFB85D05AF.B371F0AD-ON85256CC1.00505D1D@cbis.com>

use 'rle' to test for the sequence of data--NAs.

Depending on what you want to test for, a length > 2 of 'data/NA' would say
that you have an mix.  If you want 'data' first, then check the first
value.  Here is an example:

> x.1
     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
[1,]    1    1   NA   NA    1   NA   NA
[2,]    1    1    1    1    1   NA   NA
[3,]   NA   NA   NA    1    1    1    1
[4,]    1   NA    1   NA    1   NA    1
> x.2 <- apply(x.1,1,function(x)rle(is.na(x)))
> x.2
[[1]]
Run Length Encoding
  lengths: int [1:4] 2 2 1 2
  values : logi [1:4] FALSE  TRUE FALSE  TRUE

[[2]]
Run Length Encoding
  lengths: int [1:2] 5 2
  values : logi [1:2] FALSE  TRUE

[[3]]
Run Length Encoding
  lengths: int [1:2] 3 4
  values : logi [1:2]  TRUE FALSE

[[4]]
Run Length Encoding
  lengths: int [1:7] 1 1 1 1 1 1 1
  values : logi [1:7] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE

> sapply(x.2,function(x)length(x$lengths)>2)
[1]  TRUE FALSE FALSE  TRUE
> # first and fourth cases have the sequence you want and both
> # start with 'data' because 'values' is FALSE


                                                                                                                 
                      Wolfgang                                                                                   
                      Viechtbauer                To:       <r-help at stat.math.ethz.ch>                            
                      <wviechtb at s.psych.u        cc:                                                             
                      iuc.edu>                   Subject:  [R] Finding Missing Data Patterns                     
                      Sent by:                                                                                   
                      r-help-admin at stat.m                                                                        
                      ath.ethz.ch                                                                                
                                                                                                                 
                                                                                                                 
                      02/02/2003 00:09                                                                           
                                                                                                                 
                                                                                                                 




Dear R-Helpers,

I have a large data matrix, which contains missing data. The matrix
looks something like this:

1) X  X  X  X  X  X NA NA NA
2) NA NA NA NA X  X  X  X  X
3) NA NA X  X  X  X NA NA NA
4) X  X  X  X  X  X  X  X  X
5) X  X  NA NA X NA NA NA NA

and so on. Notice that the first row starts with complete data but ends
with missing. The second row starts with missing, but the rest is
complete. The third starts and ends with missing, but the middle part is
complete. The fourth is complete. What I want to do is filter out
patterns like in row 5, where the data are interrupted by missing data.
Basically, I need to test each row for a "data, at least one NA, data"
pattern.

Is there some kind of way of doing this? I am at a loss for an easy way
to accomplishing this. Any suggestions would be most appreciated!

--
Wolfgang Viechtbauer

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help




--
"NOTICE:  The information contained in this electronic mail transmission is
intended by Convergys Corporation for the use of the named individual or
entity to which it is directed and may contain information that is
privileged or otherwise confidential.  If you have received this electronic
mail transmission in error, please delete it from your system without
copying or forwarding it, and notify the sender of the error by reply email
or by telephone (collect), so that the sender's address records can be
corrected."



From otoomet at econ.dk  Sun Feb  2 16:03:03 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Sun Feb  2 16:03:03 2003
Subject: [R] printing reals from C with digits -- once more
Message-ID: <200302021450.h12Eow617368@punik.econ.au.dk>

Thank for Brian D. Ripley for the answer to my previous question.  

My aim is to print single values from different real vectors with
different digits option.  This is quite a possible with Rprintf() but
that one supprots printing format as C does, not in R native way
(setting digits=7 or printing with "%12.7f" are two quite different
things).  So I would like to find something more R-ish.

PrintValue() seems promising (it understands when I change
options(digits) but I did not get it to print a single value.  I tried

  SEXP variable;
  PrintValue(VECTOR_ELT(variable, i));

which lead to crash, while

  PrintValue(variable);

prints the whole vector.  

StringFromReal() (and printing as CHAR) is otherwise nice but I dont
know how can I make it to understand options(digits).


Can anybody suggest me a way for this?

Best wishes,

Ott


BTW, can I be sure that everything defined in /usr/lib/R/include and
R_ext are (more or less) safe to use?


 | From: Prof Brian D Ripley <ripley at stats.ox.ac.uk>
 | Date: Wed, 29 Jan 2003 09:01:44 +0000 (GMT Standard Time)
 | 
 | On Wed, 29 Jan 2003, Ott Toomet wrote:
 | 
 | > I want to print real numbers in C code with different values for
 | > digits.  How to do that?
 | 
 | Use Rprintf or PrintValue.  You'll need to work hard to convince me that
 | Rprintf is not adequate.
 | 
 | > As I have understood, what I should do is to call
 | >
 | > StringFromReal()
 | 
 | That's a coercion, not a printing routine.
 | 
 | > which calls FormatReal(), that one suggests the parameters (width,
 | > decimal places and exponential form).  FormatReal() includes
 | >
 | >     eps = pow(10.0, -(double)R_print.digits);
 | >
 | > So I guess I have to change the value of R_print.digits.
 | > R_print.digits is defined in include/Print.h in the package source,
 | > but unfortunately the installed version (in /usr/lib/R/include/R_ext) is
 | > quite a different.
 | 
 | R_ext/Print.h and Print.h are not the same thing: one is not a version of
 | the other.  The routines you mention are not documented in R-exts, and are
 | not part of the API.
 | 
 | > I guess that is because the structure is not meant
 | > to be accessible by user, although some system routines alter
 | > R_print.digits directly.
 | 
 | (Only the coercion and print routines!)
 | 
 | > So are there any good way to achieve it?
 | 
 | Temporarily change the options(digits) and call PrintValue().  You are not
 | meant to (and it is not safe to) mess with R's printing internals, and
 | these structures change even at patch releases.



From ripley at stats.ox.ac.uk  Sun Feb  2 16:19:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Feb  2 16:19:02 2003
Subject: [R] Re: printing reals from C with digits -- once more
In-Reply-To: <200302021450.h12Eow617368@punik.econ.au.dk>
Message-ID: <Pine.LNX.4.44.0302021505450.29084-100000@gannet.stats>

On Sun, 2 Feb 2003, Ott Toomet wrote:

> Thank for Brian D. Ripley for the answer to my previous question.  
> 
> My aim is to print single values from different real vectors with
> different digits option.  This is quite a possible with Rprintf() but
> that one supprots printing format as C does, not in R native way
> (setting digits=7 or printing with "%12.7f" are two quite different
> things).  So I would like to find something more R-ish.

R *does* use C printing formats, and all you need to so is to track those
down in the sources.

> PrintValue() seems promising (it understands when I change
> options(digits) but I did not get it to print a single value.  I tried
> 
>   SEXP variable;
>   PrintValue(VECTOR_ELT(variable, i));
> 
> which lead to crash, while
> 
>   PrintValue(variable);
> 
> prints the whole vector.  

You need to create a vector of length 1 to print one value.

> StringFromReal() (and printing as CHAR) is otherwise nice but I dont
> know how can I make it to understand options(digits).

It's not a public entry point, and support for options(digits) is in the 
callers.

> Can anybody suggest me a way for this?
> 
> Best wishes,
> 
> Ott
> 
> 
> BTW, can I be sure that everything defined in /usr/lib/R/include and
> R_ext are (more or less) safe to use?

No, read R_exts for what is in the API and what is not.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kjetil at entelnet.bo  Sun Feb  2 16:44:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sun Feb  2 16:44:03 2003
Subject: [R] mgcv, gam
In-Reply-To: <Pine.SOL.3.96.1030131103153.23643C-100000@moon.stats.gla.ac.uk>
References: <3E38F8AF.13862.4A482C@localhost>
Message-ID: <3E3CE3D8.17360.103644@localhost>

On 31 Jan 2003 at 10:40, Simon Wood wrote:

Thanks for the help. I will try out your suggestions. Some specific 
comments:

> > I have some problems with gam in mgcv. Firts a detail: it would
> > be nice igf gam would accept an na.action argument, but that not the 
> > main point.
> - I find it hard to think of a sensible action except dropping the
> associated data, but if you've a concrete suggestion I'm happy to add it
> to the "to do" list.

One other usefull action would be to add the possibility of using 
na.exclude, which makes it necessary to rewrite (slightly)
the residuals and predict methods using
naresid and napredict. 

And one other thing, of interest only for Simon Wood:
I tried to reply privately, but had the following problem: My
mail bounced, with the following explication:

The original message was received at Thu, 30 Jan 2003 10:07:13 +0400 
(GMT)
from s250r.entelnet.bo [166.114.10.19]

   ----- The following addresses had permanent fatal errors -----
<spam_manager at mcs.st-and.ac.uk>
    (reason: 550 5.7.1 Mail from 166.114.10.32 refused by blackhole 
site blackholes.five-ten-sg.com as suspected spam.  If this e-mail is 
not spam please e-mail spam_manager at mcs.st-and.ac.uk quoting this 
message.)

   ----- Transcript of session follows -----
... while talking to twopi.mcs.st-and.ac.uk.:
>>> MAIL From:<kjetil at entelnet.bo>
<<< 550 5.7.1 Mail from 166.114.10.32 refused by blackhole site 
blackholes.five-ten-sg.com as suspected spam.  If this e-mail is not 
spam please e-mail spam_manager at mcs.st-and.ac.uk quoting this 
message.
554 5.0.0 Service unavailable


Trying to write to spam_manager at etc then 
produced the same type of response!

I cannot understand why this should be filtered as spam!

Thanks, Kjetil Halvorsen



From TyagiAnupam at aol.com  Sun Feb  2 20:28:02 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Sun Feb  2 20:28:02 2003
Subject: [R] A good DBMS for R?
Message-ID: <7a.376ac223.2b6ecb0c@aol.com>

<PRE>I am looking for suggestions for a good Database Management System to use 
with R.  The main use of this will be to format, query and make subsets of 
large datafiles for use in R.  I recall reading a comparative write-up either 
in the newsletter, in the mails or someone's webpage last summer, but cant 
seem to find it now.  I will be thankful if someone can help in locating such 
a document.  For the DBMS it will be nice if it is a good database system to 
learn independent of its integration with R. My preference will be something 
that also works under Linux and has a user-friendly interface.



From ripley at stats.ox.ac.uk  Sun Feb  2 20:53:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Feb  2 20:53:02 2003
Subject: [R] A good DBMS for R?
In-Reply-To: <7a.376ac223.2b6ecb0c@aol.com>
Message-ID: <Pine.LNX.4.44.0302021949510.8817-100000@gannet.stats>

See the `R Data Import/Export' manual, or my R-News article.

On Linux (what do you mean by `also works', when you haven't mentioned any 
other OS?) I would suggest MySQL.

On Sun, 2 Feb 2003 TyagiAnupam at aol.com wrote:

> <PRE>I am looking for suggestions for a good Database Management System to use 
> with R.  The main use of this will be to format, query and make subsets of 
> large datafiles for use in R.  I recall reading a comparative write-up either 
> in the newsletter, in the mails or someone's webpage last summer, but cant 
> seem to find it now.  I will be thankful if someone can help in locating such 
> a document.  For the DBMS it will be nice if it is a good database system to 
> learn independent of its integration with R. My preference will be something 
> that also works under Linux and has a user-friendly interface.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From cpp at normandnet.fr  Sun Feb  2 21:28:03 2003
From: cpp at normandnet.fr (cpp@normandnet.fr)
Date: Sun Feb  2 21:28:03 2003
Subject: [R] nomogramme
Message-ID: <000401c2cafa$112ea6e0$c91924d5@ppp>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030202/a7a08472/attachment.pl

From r.darnell at shrs.uq.edu.au  Mon Feb  3 01:19:03 2003
From: r.darnell at shrs.uq.edu.au (Ross Darnell)
Date: Mon Feb  3 01:19:03 2003
Subject: [R] Re: Finding missing data patterns
Message-ID: <r8aqmd3c.fsf@shrs.uq.edu.au>

The norm package of Joe Schafer can be used. It has a function called
'prelim' (or very similar) that does this.

Regards
Ross Darnell

Email: <r.darnell at shrs.uq.edu.au>



From rabaieremon at hotmail.com  Mon Feb  3 02:33:03 2003
From: rabaieremon at hotmail.com (Rabaie Remon)
Date: Mon Feb  3 02:33:03 2003
Subject: [R] Option pricing
Message-ID: <F6Rj9tvHpFKAFRr1fPg00007d69@hotmail.com>

Dear sir:

I want just ask if there is in R any package to use like in S+, for the 
Basic option pricing (Binomail model, Black-Scholes pricing formula)

Thank you,



From Rob.Dunne at cmis.CSIRO.AU  Mon Feb  3 03:52:03 2003
From: Rob.Dunne at cmis.CSIRO.AU (Rob Dunne)
Date: Mon Feb  3 03:52:03 2003
Subject: [R] itanium
Message-ID: <15933.55607.533578.685313@pride.nsw.cmis.CSIRO.AU>

I am trying to compile R-1.6.1 on an itanium.

using either gcc 2.96 or gcc 3.0.4 nad either
the supplied Redhat blas libs or the supplied code (ie
wiht the --no-blas option) I get this error.

Has anyone who has compiled R for the itanium advise
me on the compilers versions and flags that they used?

				       thanks 
					bye
					rob




gcc -shared -L/usr/local/lib -o lapack.so  Lapack.lo double.lo  cmplx.lo cmplxblas.lo   -L/usr/local/lib -L/usr/lib/gcc-lib/ia64-redhat-linux/2.96 -L/usr/lib/gcc-lib/ia64-redhat-linux/2.96/../../.. -lreadline -ldl -lncurses -lg2c -lm -lpcre -lbz2 -lz -lreadline -ldl -lncurses -lm
/usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
/usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
/usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
/usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
/usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
/usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
collect2: ld returned 1 exit status
make[4]: *** [lapack.so] Error 1
make[4]: Leaving directory `/home/robd/junk/R-1.6.1/src/modules/lapack'

-- 
Rob Dunne         Fax: +61 2 9325 3200     Tel: +61 2 9325 3263
CSIRO Mathematical and Information Sciences     +61 2 9325 3100
Locked Bag 17, North Ryde, New South Wales, Australia, 1670         
http://matilda.vu.edu.au/~dunne  Email: Rob.Dunne at csiro.au

        Java has certainly revolutionized marketing and litigation.



From vsensae at hotmail.com  Mon Feb  3 04:33:02 2003
From: vsensae at hotmail.com (Vincent Stoliaroff)
Date: Mon Feb  3 04:33:02 2003
Subject: [R] Downloading Package
Message-ID: <F161UgrMbzjqruzTvzt0000101e@hotmail.com>



Thank you very much to you 3
I didn't know it was possible to download, update and load the package 
directly within R. It is pretty convenient...
Eventhough my system was not correctly set up because I cannot open any url 
from R I finally succeed in installing the package after downloading it 
directly from 
http://www.stat.math.ethz.ch/CRAN/bin/windows/contrib/multiv.zip
and then installing it "from a local zip file"
Thanks again.



>From: "Warnes, Gregory R" <gregory_r_warnes at groton.pfizer.com>
>To: "'Peter von Rohr'" <vonrohr at inf.ethz.ch>,   Vincent Stoliaroff 
><vsensae at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: RE: [R] Downloading Package
>Date: Thu, 30 Jan 2003 10:03:35 -0500
>
>If your system is set up appropriately, you should be able to use the menu
>"Packages -> Install Packages from Cran" to get a list of packages, then
>select the desired package and press OK.
>
>-Greg
>
> > -----Original Message-----
> > From: Peter von Rohr [mailto:vonrohr at inf.ethz.ch]
> > Sent: Thursday, January 30, 2003 6:57 AM
> > To: Vincent Stoliaroff
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] Downloading Package
> >
> >
> > Hello Vincent,
> > >
> > > I am a beginner in using R so my question could seem very
> > simple. I would
> > > like to download the package multiv to do multivariate data
> > analysis. The
> > > package I download seems to be a file meant for UNIX and I
> > am using a Window
> > > OS. How could I download and install correctly this file?
> >
> > although i am not using R for windows, but there are binaries for
> > windows available for multiv at:
> > http://www.stat.math.ethz.ch/CRAN/bin/windows/contrib/multiv.zip
> >
> > you may want to read the documentation about how to install
> > pakages from
> > http://stat.ethz.ch/CRAN/doc/manuals/R-admin.pdf (chapter 5).
> >
> > depending on where you are physically, you may want to select another
> > cran mirror for a list of mirrors see:
> > http://cran.r-project.org/mirrors.html
> >
> > hth, peter
> >
> > --
> > Peter von Rohr                       http://www.inf.ethz.ch/~vonrohr
> > Institute of Scientific Computing                vonrohr at inf.ethz.ch
> > ETH-Zentrum, HRS H23                           phone: +41 1 632 7473
> > CH - 8092 Zurich                                 fax: +41 1 632 1374
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>
>LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... 
>[[dropped]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help


_________________________________________________________________
MSN Search, le moteur de recherche qui pense comme vous !



From edd at debian.org  Mon Feb  3 04:40:03 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon Feb  3 04:40:03 2003
Subject: [R] itanium
In-Reply-To: <15933.55607.533578.685313@pride.nsw.cmis.CSIRO.AU>; from Rob.Dunne@cmis.CSIRO.AU on Mon, Feb 03, 2003 at 01:51:35PM +1100
References: <15933.55607.533578.685313@pride.nsw.cmis.CSIRO.AU>
Message-ID: <20030202213406.A2740@debian.org>

On Mon, Feb 03, 2003 at 01:51:35PM +1100, Rob Dunne wrote:
> 
> I am trying to compile R-1.6.1 on an itanium.
> 
> using either gcc 2.96 or gcc 3.0.4 nad either
> the supplied Redhat blas libs or the supplied code (ie
> wiht the --no-blas option) I get this error.
> 
> Has anyone who has compiled R for the itanium advise
> me on the compilers versions and flags that they used?

Debian's automated building system, covering 11 architecture beyond i386, 
has logs going back until at least Oct 2001.  The page at

	http://buildd.debian.org/build.php?arch=ia64&pkg=r-base

shows logs for all builds since R 1.3.1. All of those would have used our
scheme of atlas (at runtime, if available) or else default blas.

IIRC we always imposed at least a gcc 3.0 version on ia64.  We recently
switched to using gcc 3.2.* on every platform, so the point is a little
moot.

Hope this helps,  Dirk

-- 
Three out of two people have difficulties with fractions.



From fharrell at virginia.edu  Mon Feb  3 04:44:12 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon Feb  3 04:44:12 2003
Subject: [R] nomogramme
In-Reply-To: <000401c2cafa$112ea6e0$c91924d5@ppp>
References: <000401c2cafa$112ea6e0$c91924d5@ppp>
Message-ID: <20030202223946.7a61e125.fharrell@virginia.edu>

On Sun, 2 Feb 2003 21:31:17 +0100
cpp at normandnet.fr wrote:

> somebody can help me to draw a nomogram
> of the Cumulative Binomiale Distribution
> or simple example of nomogram
> Pascal (France)
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

It depends on what you mean by nomogram.  nomograms for regression models may be produced with the nomogram function in the Design library (http://hesweb1.med.virginia.edu/biostat/s/Design.html).  By the way nomograms were created in the French schools of civil engineering.

To draw something fairly simple such as a distribution you could program this in R easily, and my nomogram function would not apply.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From Toby.Patterson at csiro.au  Mon Feb  3 07:14:03 2003
From: Toby.Patterson at csiro.au (Toby.Patterson@csiro.au)
Date: Mon Feb  3 07:14:03 2003
Subject: [R] plot.gam for glm objects.
Message-ID: <A8877251964B294BAB5BA1FC58B43FED4F7846@molly.tas.csiro.au>

All, 

I was wondering if someone had come across the problem of producing partial
regression plots for glm objects in R? 

When using Splus in the past I have passed glm objects to the plot.gam
function. 
To my knowledge this functionality isn't included in R ( I would be happily
corrected here) and if someone had some code floating around to do this it
would save me re-inventing wheels etc. 

Thanks 

Toby 


Toby Patterson
Sustainable Pelagic Fisheries and Ecosystems
CSIRO Marine Research



From wettenhall at wehi.edu.au  Mon Feb  3 07:58:04 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Mon Feb  3 07:58:04 2003
Subject: [R] R tcltk modal dialog box with radio buttons
Message-ID: <Pine.LNX.4.44.0302031740480.26515-100000@unix24.alpha.wehi.edu.au>

Dear R-help,

I am having a lot of trouble creating a modal dialog box in R 
tcltk.  Can anyone give me an example subroutine, so that when a 
button is pressed on my main dialog box, this subroutine will 
produce a modal dialog box with some radio buttons, an OK button 
and a Cancel button?

I am using R 1.6.1 in Windows 2000.

Thanks in advance,
James

--------------------------------------------------------------------------
James Wettenhall                                  Tel: (+61 3) 9345 2629
Division of Genetics and Bioinformatics           Fax: (+61 3) 9347 0852
The Walter & Eliza Hall Institute         E-mail: wettenhall at wehi.edu.au
 of Medical Research,                     Mobile: (+61 / 0 ) 438 527 921    
1G Royal Parade,
Parkville, Vic 3050, Australia
http://www.wehi.edu.au
--------------------------------------------------------------------------



From ripley at stats.ox.ac.uk  Mon Feb  3 08:25:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb  3 08:25:04 2003
Subject: [R] itanium
In-Reply-To: <15933.55607.533578.685313@pride.nsw.cmis.CSIRO.AU>
Message-ID: <Pine.LNX.4.44.0302030715340.26606-100000@gannet.stats>

I think you need to use a later compiler, one with a shared libg2c:  
open.o is in libg2c.  With the system you are using, Fortran code cannot
be used in shared (.so) objects.  As Dirk E. says gcc 3.2 works on Debian,
you could try that (although Debian had a relocatable libg2c when gcc did
not).  Alternatively, try rebuilding the g77 libraries with PIC flags.

While you are at it, why not use the current R-1.6.2?

On Mon, 3 Feb 2003, Rob Dunne wrote:

> 
> I am trying to compile R-1.6.1 on an itanium.
> 
> using either gcc 2.96 or gcc 3.0.4 nad either
> the supplied Redhat blas libs or the supplied code (ie
> wiht the --no-blas option) I get this error.
> 
> Has anyone who has compiled R for the itanium advise
> me on the compilers versions and flags that they used?
> 
> 				       thanks 
> 					bye
> 					rob
> 
> 
> 
> 
> gcc -shared -L/usr/local/lib -o lapack.so  Lapack.lo double.lo  cmplx.lo cmplxblas.lo   -L/usr/local/lib -L/usr/lib/gcc-lib/ia64-redhat-linux/2.96 -L/usr/lib/gcc-lib/ia64-redhat-linux/2.96/../../.. -lreadline -ldl -lncurses -lg2c -lm -lpcre -lbz2 -lz -lreadline -ldl -lncurses -lm
> /usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
> /usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
> /usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
> /usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
> /usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
> /usr/bin/ld: open.o: @gprel relocation against dynamic symbol f__buflen
> collect2: ld returned 1 exit status
> make[4]: *** [lapack.so] Error 1
> make[4]: Leaving directory `/home/robd/junk/R-1.6.1/src/modules/lapack'
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gjermund.Boethun at imr.no  Mon Feb  3 09:20:04 2003
From: gjermund.Boethun at imr.no (=?iso-8859-1?Q?=22B=F8thun=2C_Gjermund=22?=)
Date: Mon Feb  3 09:20:04 2003
Subject: [R] Read.table problem
Message-ID: <3418BE5B6E6DD511991400B0D0D034E40146C101@hipost.imr.no>

----- Original Message -----
From: "ptremb17" <ptremb17 at po-box.mcgill.ca>
length(varnames) = 9
length(c(F,T,F,F,F,F,F,F,F,F))) = 10

To: "R-HELP" <r-help at stat.math.ethz.ch>
Sent: Saturday, February 01, 2003 3:24 AM
Subject: [R] Read.table problem


> Hi !
>
> I am new to R, and using the MAC version onto Mac OS 9.1. My question
concerns
> the problem I encounter when I try to read some data I have using the
> read.table function. I always get an error of type : Error in scan(file =
> file, what = what, sep = sep, quote = quote, dec = dec,  :
> line 1 did not have 9 elements
>
> Here is my code:
>
> varnames <- c("names", "symbol", "price", "displ", "gas", "weight",
"reliab",
> "origin", "type")
>
> cardat <- read.table("PowerMac 7300:Logiciels de
> Statistiques:rm162:car02.txt", col.names=varnames,
> as.is=c(F,T,F,F,F,F,F,F,F,F))
>
> Can you advice me ?
>
> Thanks in advance,
>
> Pascale Tremblay
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From vsensae at hotmail.com  Mon Feb  3 10:52:03 2003
From: vsensae at hotmail.com (Vincent Stoliaroff)
Date: Mon Feb  3 10:52:03 2003
Subject: [R] correspondance analysis & clustering
Message-ID: <F110QTs7wIBypO9QtWj0000d20e@hotmail.com>


Hi

1) I am using the function ca() of the package multiv to make a 
correspondance analysis of a matrix of categorical datas which are 
numericaly coded. I would like to be sure that it is considered as a matrix 
of categorical datas and not numerical. I cannot find any explicit mention 
of that in the help file for this function

2) I would like to take the resulting matrix rproj to do a clustering.
I use hierclust() and partition() of the package multiv

regarding hierclust()
when I use the method number 1 i get this error:
Error in hclust(a, method) : invalid clustering method

when I change the number of the method I get
Error in pmatch(x, table, duplicates.ok) :
        argument is not of mode character


As for the partition() function, I also have some troubles. It seems I 
should mention a vector of clustered centers for initiating the iterative 
optimization process. But I do not know where to enter it.
I get the following message
Error in matrix(0, ng, m) : non-numeric matrix extent

Has anybody ever encountered those problems?
Thanks a lot


_________________________________________________________________
MSN Search, le moteur de recherche qui pense comme vous !



From jon.davies at imperial.ac.uk  Mon Feb  3 11:03:03 2003
From: jon.davies at imperial.ac.uk (Davies, Jonathan)
Date: Mon Feb  3 11:03:03 2003
Subject: [R] interpolation and 3D plots
Message-ID: <F8514F0F5918D411BC6F00A0C9D884C70B14FAAF@icex7.cc.ic.ac.uk>

I've been told that you may be able to help.

I have a complex linear model with multiple two-way interaction terms. Is
there a way to view the interaction terms in a 3d plot equivalent to the S
functions:
 
> plan<-interp(x,y,z)
> image(plan)

where x and y are my explanatory variables and z my response variable.

Thanks,

Jonatha Davies



From ripley at stats.ox.ac.uk  Mon Feb  3 11:22:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb  3 11:22:02 2003
Subject: [R] interpolation and 3D plots
In-Reply-To: <F8514F0F5918D411BC6F00A0C9D884C70B14FAAF@icex7.cc.ic.ac.uk>
Message-ID: <Pine.LNX.4.44.0302031020100.5419-100000@gannet.stats>

library(akima)
plan <- interp.old(x,y.z)
image(plan)

is very close.

This is in MASS (the book) with examples.

On Mon, 3 Feb 2003, Davies, Jonathan wrote:

> I've been told that you may be able to help.
> 
> I have a complex linear model with multiple two-way interaction terms. Is
> there a way to view the interaction terms in a 3d plot equivalent to the S
> functions:
>  
> > plan<-interp(x,y,z)
> > image(plan)
> 
> where x and y are my explanatory variables and z my response variable.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Jose.Alegria at oni.pt  Mon Feb  3 12:31:03 2003
From: Jose.Alegria at oni.pt (=?iso-8859-1?Q?Jos=E9_Santos_Alegria?=)
Date: Mon Feb  3 12:31:03 2003
Subject: [R] Overlaying a moving average curve on top of a barplot
Message-ID: <3E41285CB4BABD4D81B3A3A0324542E92D1FBD@dnslgp01>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030203/5bef5228/attachment.pl

From Morten.Sickel at nrpa.no  Mon Feb  3 12:45:03 2003
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Mon Feb  3 12:45:03 2003
Subject: [R] Overlaying a moving average curve on top of a barplot
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5DBB@postix.nrpa.no>

Jose Santos Alegria wrote:

>I'm using standard barplot (Windows version 1.6.2 of R) to represent a
certain weekly 
>metric "v" and I would like to properly overlay on top of it its moving
average "mean.8" 
>(window of 8 weeks). I must be doing something wrong since the moving
average (using >"lines") doesn't overlay properly, i.e., both x-scales do
not match!

Have you considered using "filter"? I made a somehov similiar plot this way:
(prec being a data frame with 'columns' date with dates of measurements and
prec, precipitation at the actual date)

<code>
  plot(prec)
  lines(prec$date,filter(prec$value,c(0.25,0.25,0.25,0.25))) 
</code>

Points showing actual measurements and a four periods moving average  as a
line.


Hope this helps.

Morten

-- 
Morten Sickel
Norwegian Radiation Protection Authority
http://www.nrpa.no



From petr.pikal at precheza.cz  Mon Feb  3 13:05:04 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon Feb  3 13:05:04 2003
Subject: [R] Re-assigning vector elements based on their initial values.
In-Reply-To: <5.1.0.14.2.20030201070839.01df59a0@mcmail.cis.mcmaster.ca>
References: <00ec01c2c99b$07f5d360$3182fd0c@dell1700>
Message-ID: <3E3E68E9.4961.12C367E@localhost>

Hi

On 1 Feb 2003 at 7:17, John Fox wrote:

> Dear Rex,
> 
> You can use if.else, which is vectorized:
> 
>          > v.new <- ifelse(v < 0, -v/2, v)
>          > v.new
>          [1]  5.0  5.0  1.5  1.5  7.0  8.0 10.0

or simply

abs(v/((v<0)+1))

it should be a little bit quicker


> 
> (By the way, the solution that you suggested using a loop works, but
> for some reason the sign is wrong in the result that you printed;
> notice that your "else" clause does nothing -- you probably meant to
> assign to v.new not v -- and is unnecessary in any event.)
> 
> I hope that this helps,
>   John
> 
> 
> 
> At 07:38 PM 1/31/2003 -0700, Rex_Bryan at urscorp.com wrote:
> >Is there an eloquent solution to re-assign vector element values? I
> >have a vector which contains chemical data, some of them are
> >"flagged" as non-detected values by their negative values. I can find
> >the statistics on the positive values in vector "v"  simply by
> >typing:
> > >v<- c(5,5,-3,-3,7,8,10)
> >
> > > v[(v>0)]
> >[1] 5  5  7  8  10
> >
> >I can also convert to positive values by
> > >asb(v)
> >[1]  5  5  3  3  7  9  10
> >
> >I then can do mean() and var() etc.
> >
> >But when I want to come up with a way to change a negative value to a
> >postive 1/2 value I couldn't come up with a nice way using "vectoral
> >syntax" to do it.  In the method I came up with , I discovered that I
> >have to pre-define a new vector "v.new" or I get an error.
> >
> > >v.new <-v
> >
> >then I have to loop through all of the elements!
> >
> > >for(i in 1:length(v)){ if (v[i] < 0) v.new[i] <-  -1*v[i]/2 else
> > >v[i] <-
> >v[i]}
> > > v.new
> >[1]  5.0  5.0  -1.5  -1.5  7.0  9.0  10.0
> >
> >This works but seems labored given the previous crisp vector
> >operations.
> 
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

Cheers
Petr
petr.pikal at precheza.cz
p.pik at volny.cz



From Jose.Alegria at oni.pt  Mon Feb  3 13:43:03 2003
From: Jose.Alegria at oni.pt (=?iso-8859-1?Q?Jos=E9_Santos_Alegria?=)
Date: Mon Feb  3 13:43:03 2003
Subject: [R] Overlaying a moving average curve on top of a barplot
Message-ID: <3E41285CB4BABD4D81B3A3A0324542E92D1FBF@dnslgp01>

My problem is not with "plot()" but with "barplot()"! I guess it may have to do with the fact that the barplot's bars have a non-negligible width and the moving average line not! Is it?

Jos? A. S. Alegria
 
 


-----Original Message-----
From: Morten Sickel [mailto:Morten.Sickel at nrpa.no] 
Sent: segunda-feira, 3 de Fevereiro de 2003 11:43 AM
To: Jos? Santos Alegria; R help (E-post)
Subject: RE: [R] Overlaying a moving average curve on top of a barplot


Jose Santos Alegria wrote:

>I'm using standard barplot (Windows version 1.6.2 of R) to represent a
certain weekly 
>metric "v" and I would like to properly overlay on top of it its moving
average "mean.8" 
>(window of 8 weeks). I must be doing something wrong since the moving
average (using >"lines") doesn't overlay properly, i.e., both x-scales do not match!

Have you considered using "filter"? I made a somehov similiar plot this way: (prec being a data frame with 'columns' date with dates of measurements and prec, precipitation at the actual date)

<code>
  plot(prec)
  lines(prec$date,filter(prec$value,c(0.25,0.25,0.25,0.25))) 
</code>

Points showing actual measurements and a four periods moving average  as a line.


Hope this helps.

Morten

-- 
Morten Sickel
Norwegian Radiation Protection Authority
http://www.nrpa.no



From Ted.Harding at nessie.mcc.ac.uk  Mon Feb  3 13:48:24 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon Feb  3 13:48:24 2003
Subject: [R] Lattice not plotting within loop
Message-ID: <XFMail.030203123502.Ted.Harding@nessie.mcc.ac.uk>

Something I don't understand ... (!)

With the lattice library loaded, I have a loop

  for( Z in ... ) {
  ...
  xyplot(y~x | t, xlab=..., ylab=... )
  }

and no plot appears on the R graphics device.
However, when I run the commands within {...}
separately for each instance of Z, I get the
plot displayed each time.

So it looks as though "xyplot" is not outputting
to the graphics display when invoked within a loop.

What am I mising?

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 03-Feb-03                                       Time: 12:35:02
------------------------------ XFMail ------------------------------



From ripley at stats.ox.ac.uk  Mon Feb  3 13:56:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb  3 13:56:03 2003
Subject: [R] Lattice not plotting within loop
In-Reply-To: <XFMail.030203123502.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0302031252110.11475-100000@gannet.stats>

This discussed almost daily.

You *print* a trellis/lattice plot, and no printing is done in your 
example.

On Mon, 3 Feb 2003 Ted.Harding at nessie.mcc.ac.uk wrote:

> Something I don't understand ... (!)

It's in all good books on S/R ....

> With the lattice library loaded, I have a loop
> 
>   for( Z in ... ) {
>   ...
>   xyplot(y~x | t, xlab=..., ylab=... )
>   }
> 
> and no plot appears on the R graphics device.
> However, when I run the commands within {...}
> separately for each instance of Z, I get the
> plot displayed each time.
> 
> So it looks as though "xyplot" is not outputting
> to the graphics display when invoked within a loop.

It never does.  print.trellis does the outputting.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Mon Feb  3 14:33:05 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon Feb  3 14:33:05 2003
Subject: [R] plot.gam for glm objects.
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED4F7846@molly.tas.csiro.au>
Message-ID: <5.1.0.14.2.20030203082942.01df61e8@mcmail.cis.mcmaster.ca>

Dear Toby,

I think that you mean "partial-residual" (i.e., component+residual) plots 
rather than "partial-regression" (i.e., added-variable) plots. In either 
event, see the cr.plots and av.plots functions in the car package; both 
have methods for GLMs.

I hope that this does what you need,
  John

At 05:11 PM 2/3/2003 +1100, Toby.Patterson at csiro.au wrote:
>All,
>
>I was wondering if someone had come across the problem of producing partial
>regression plots for glm objects in R?
>
>When using Splus in the past I have passed glm objects to the plot.gam
>function.
>To my knowledge this functionality isn't included in R ( I would be happily
>corrected here) and if someone had some code floating around to do this it
>would save me re-inventing wheels etc.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From Bernhard.Pfaff at drkw.com  Mon Feb  3 14:41:03 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Mon Feb  3 14:41:03 2003
Subject: [R] Option pricing
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB90047301B9@ibfftce505.is.de.dresdnerkb.com>

Hello Rabaie,

how about the contributed package: "RQuantLib"?

HTH,
Bernhard


-----Original Message-----
From: Rabaie Remon [mailto:rabaieremon at hotmail.com]
Sent: 02 February 2003 19:24
To: r-help at stat.math.ethz.ch
Subject: [R] Option pricing



Dear sir:

I want just ask if there is in R any package to use like in S+, for the 
Basic option pricing (Binomail model, Black-Scholes pricing formula)

Thank you,

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------



From jfox at mcmaster.ca  Mon Feb  3 14:44:15 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon Feb  3 14:44:15 2003
Subject: [R] interpolation and 3D plots
In-Reply-To: <F8514F0F5918D411BC6F00A0C9D884C70B14FAAF@icex7.cc.ic.ac.uk
 >
Message-ID: <5.1.0.14.2.20030203083239.01e4afa0@mcmail.cis.mcmaster.ca>

Dear Jonathan,

The all.effects function in the car package will identify the high-order 
terms in a linear or generalized-linear model and absorb terms marginal to 
them (e.g., for a two-way interaction, the main effects marginal to the 
interaction and the constant). The plot method for the object produced uses 
trellis graphics to plot terms, but for a two-way interaction, the 
information in the object could easily be plotted as an image (or other 3D) 
plot.

I hope that this helps,
  John

At 10:02 AM 2/3/2003 +0000, Davies, Jonathan wrote:
>I've been told that you may be able to help.
>
>I have a complex linear model with multiple two-way interaction terms. Is
>there a way to view the interaction terms in a 3d plot equivalent to the S
>functions:
>
> > plan<-interp(x,y,z)
> > image(plan)
>
>where x and y are my explanatory variables and z my response variable.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From GPetris at uark.edu  Mon Feb  3 15:37:05 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Mon Feb  3 15:37:05 2003
Subject: [R] Bus error with xyplot
Message-ID: <200302031436.IAA24221@definetti.uark.edu>

Has anybody else experienced something like the example below? 
Any clues about where I could start looking?

Thank you in advance,
Giovanni 


> version
         _                   
platform sparc-sun-solaris2.7
arch     sparc               
os       solaris2.7          
system   sparc, solaris2.7   
status                       
major    1                   
minor    6.2                 
year     2003                
month    01                  
day      10                  
language R                   
> library(lattice)
> example(xyplot)

xyplot> data(quakes)

xyplot> Depth <- equal.count(quakes$depth, number = 8, overlap = 0.1)

xyplot> xyplot(lat ~ long | Depth, data = quakes)
Bus error

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From maechler at stat.math.ethz.ch  Mon Feb  3 15:49:05 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Feb  3 15:49:05 2003
Subject: [R] Bus error with xyplot
In-Reply-To: <200302031436.IAA24221@definetti.uark.edu>
References: <200302031436.IAA24221@definetti.uark.edu>
Message-ID: <15934.33094.898841.948643@gargle.gargle.HOWL>

>>>>> "Giovanni" == Giovanni Petris <GPetris at uark.edu>
>>>>>     on Mon, 3 Feb 2003 08:36:06 -0600 (CST) writes:

    Giovanni> Has anybody else experienced something like the example below? 
not recently.
Could it be that your version of the `grid' package (which is
loaded by `lattice') or `lattice' are incompatible (i.e. older
than) to your R version?
After   library(lattice), use 
 .path.package()
to see where it was loaded from.

    Giovanni> Any clues about where I could start looking?

If it's not the above, and since you are on a unix system, start
R inside the debugger.  You then will hopefully see in which
call the problem occurs:

  R -d gdb
  run
  library(lattice)
  ## .... 

The "Bus error" should leave you inside gdb,
where you can enter `bt' to get the [b]ack[t]race of function
calls.

More details on using the debugger are in the R-FAQ and "Writing
Extensions.."
  
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From andy_liaw at merck.com  Mon Feb  3 16:02:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon Feb  3 16:02:03 2003
Subject: [R] Bus error with xyplot
Message-ID: <3A822319EB35174CA3714066D590DCD534BC24@usrymx25.merck.com>

> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> 
> >>>>> "Giovanni" == Giovanni Petris <GPetris at uark.edu>
> >>>>>     on Mon, 3 Feb 2003 08:36:06 -0600 (CST) writes:
> 
>     Giovanni> Has anybody else experienced something like the 
> example below? 
> not recently.
> Could it be that your version of the `grid' package (which is
> loaded by `lattice') or `lattice' are incompatible (i.e. older
> than) to your R version?
> After   library(lattice), use 
>  .path.package()
> to see where it was loaded from.

This brings up (IIRC) a topic that was discussed on R-devel a while ago:
Version checks for required packages.  Is this feasible?  Seems quite
worthwhile to me...

[...]

Cheers,
Andy


------------------------------------------------------------------------------



From phgrosjean at sciviews.org  Mon Feb  3 16:23:02 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Mon Feb  3 16:23:02 2003
Subject: [R] [Out off-topic] SJava under Windows
Message-ID: <MABBLJDICACNFOLGIHJOKEEIDDAA.phgrosjean@sciviews.org>

Sorry for this off-topic subject.

I am fighting for running SJava under Windows.
SJava_0.64 (compiled by Simon Urbanek, thanks), R 1.6.2, Java JDK 1.4.0_02,
Windows XP pro:

> library(SJava)
> .JavaInit()
Error in .JavaInit() : Couldn't start Java Virtual Machine: Cannot find the
Omegahat interface manager class. Check you classpath!
> # And the second time...
> .JavaInit()
It gives the error: The instruction at "0x10bc9f0d" referenced memory at
"0x10d60008". The memory could not be "read", and ejects me.

I have:
> .javaConfig
$classPath
[1] "C:/PROGRA~1/R/rw1062/library/SJava/org/omegahat/Jars/Environment.jar"
[2] "C:/PROGRA~1/R/rw1062/library/SJava/org/.."
[3] "C:/PROGRA~1/R/rw1062/library/SJava/org/omegahat/Jars/antlr.jar"
[4] "C:/PROGRA~1/R/rw1062/library/SJava/org/omegahat/Jars/jas.jar"
[5] "C:/PROGRA~1/R/rw1062/library/SJava/org/omegahat/Jars/jhall.jar"

$properties
                                                                 EmbeddedInR
                                                                      "true"
                                                       InterfaceManagerClass
             "org/omegahat/Interfaces/NativeInterface/OmegaInterfaceManager"
                                                   ForeignReferenceBaseClass
                                     "org/omegahat/R/Java/RForeignReference"
                                                               java.compiler
                                                                      "NONE"
                                                                  OMEGA_HOME
                           "C:/PROGRA~1/R/rw1062/library/SJava/org/omegahat"
                                                          OmegahatSearchPath
".,${OMEGA_HOME}/Environment/Scripts/Run,${OMEGA_HOME}/Jars/Environment.jar"
                                                           java.library.path
                                   "C:/PROGRA~1/R/rw1062/library/SJava/libs"

$libraryPath
[1] "C:/PROGRA~1/R/rw1062/library/SJava/libs"

Any idea?
Best regards,

Philippe Grosjean


...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



From tlumley at u.washington.edu  Mon Feb  3 16:27:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Feb  3 16:27:03 2003
Subject: [R] plot.gam for glm objects.
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED4F7846@molly.tas.csiro.au>
Message-ID: <Pine.A41.4.44.0302030721500.147594-100000@homer40.u.washington.edu>

On Mon, 3 Feb 2003 Toby.Patterson at csiro.au wrote:

> All,
>
> I was wondering if someone had come across the problem of producing partial
> regression plots for glm objects in R?
>
> When using Splus in the past I have passed glm objects to the plot.gam
> function.
> To my knowledge this functionality isn't included in R ( I would be happily
> corrected here) and if someone had some code floating around to do this it
> would save me re-inventing wheels etc.

It is included, in the termplot() function.  In fact help(plot.gam) takes
you to termplot (though it shouldn't as we now have a real plot.gam in the
mgcv package).

	-thomas



From J.B.Bremnes at met.no  Mon Feb  3 16:36:08 2003
From: J.B.Bremnes at met.no (John Bjornar Bremnes)
Date: Mon Feb  3 16:36:08 2003
Subject: [R] convert from seconds to date-time objects
Message-ID: <3E3E8C55.EAD645AB@met.no>

A colleague of mine would like to know how seconds since 1970
(represented as integers) can be converted to date-time objects? 

thanks

-- 
John Bjornar Bremnes
Norwegian Meteorological Institute (met.no)
Research and Development Department
P.O.Box 43 Blindern, N-0313 Oslo, Norway
Phone: (+47) 2296 3326. Fax: (+47) 2269 6355



From rgentlem at jimmy.harvard.edu  Mon Feb  3 16:49:02 2003
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Mon Feb  3 16:49:02 2003
Subject: [R] Bus error with xyplot
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BC24@usrymx25.merck.com>; from andy_liaw@merck.com on Mon, Feb 03, 2003 at 10:00:46AM -0500
References: <3A822319EB35174CA3714066D590DCD534BC24@usrymx25.merck.com>
Message-ID: <20030203104759.J8829@jimmy.harvard.edu>

On Mon, Feb 03, 2003 at 10:00:46AM -0500, Liaw, Andy wrote:
> > From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> > 
> > >>>>> "Giovanni" == Giovanni Petris <GPetris at uark.edu>
> > >>>>>     on Mon, 3 Feb 2003 08:36:06 -0600 (CST) writes:
> > 
> >     Giovanni> Has anybody else experienced something like the 
> > example below? 
> > not recently.
> > Could it be that your version of the `grid' package (which is
> > loaded by `lattice') or `lattice' are incompatible (i.e. older
> > than) to your R version?
> > After   library(lattice), use 
> >  .path.package()
> > to see where it was loaded from.
> 
> This brings up (IIRC) a topic that was discussed on R-devel a while ago:
> Version checks for required packages.  Is this feasible?  Seems quite
> worthwhile to me...

 And there has been some work on it (reposTools, under
 www.bioconductor.org), however, getting this right is not a small
 thing and has some fairly large implications that we are looking
 at. We too would like to be able to do this reliably.


  Robert

> 
> [...]
> 
> Cheers,
> Andy
> 
> 
> ------------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20
| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
+---------------------------------------------------------------------------+



From MSchwartz at medanalytics.com  Mon Feb  3 17:19:03 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon Feb  3 17:19:03 2003
Subject: [R] Overlaying a moving average curve on top of a barplot
In-Reply-To: <3E41285CB4BABD4D81B3A3A0324542E92D1FBD@dnslgp01>
Message-ID: <000a01c2cb9f$d8da02c0$27da56d1@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jos? 
>Santos Alegria
>Sent: Monday, February 03, 2003 5:30 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Overlaying a moving average curve on top of a barplot
>
>
>I'm using standard barplot (Windows version 1.6.2 of R) to 
>represent a certain weekly metric "v" and I would like to 
>properly overlay on top of it its moving average "mean.8" 
>(window of 8 weeks). I must be doing something wrong since the 
>moving average (using "lines") doesn't overlay properly, i.e., 
>both x-scales do not match!
> 
>...
>barplot(v[8:length(v)], col=7)
>lines(mean.8[1:length(mean.8)],   lty=1, lwd=2, col=2)
>...
> 
>How do I make sure that both graphics are in synch as far as 
>the x-scale and y-scales are concerned?
> 
>Thanks,
>
>Jos? A. S. Alegria

The problem that you are having is that you need to get the bar
midpoints from barplot() in order to use those values as the x
coordinate values for lines().  barplot() returns the bar midpoints as
an invisible vector (or matrix where appropriate).

Modify your code to:

mp <- barplot(v[8:length(v)], col=7)
lines(mp, mean.8[1:length(mean.8)],   lty=1, lwd=2, col=2)

This puts the bar midpoints (x axis values) in mp, which you can then
use for lines().

HTH,

Marc



From pms at cin.ufpe.br  Mon Feb  3 17:26:02 2003
From: pms at cin.ufpe.br (Patricia Maforte dos Santos)
Date: Mon Feb  3 17:26:02 2003
Subject: [R] Problems with table
Message-ID: <Pine.GSO.4.32.0302031313490.4078-100000@goiana>

Hi,

I'm having difficulties in the manipulation of the function table.
Necessary to have access its elements and I am not obtaining. For example,
if I have a data.frame with name "df" and make:
t < - data.frame(table(df))
and later trying to make a comparison of the type t[1,1 ] < 0.1, generates
an error of the type:

[1] NA
Warning message:
"<" not meaningful for factors in: Ops.factor(t[1, 1], 0.1)

How can I resolve this?

Thanks,


----------------------------------
Patrcia Maforte dos Santos
Centro de Informatica
Universidade Federal de Pernambuco
Recife/PE - Brasil
----------------------------------



From Jose.Alegria at oni.pt  Mon Feb  3 17:33:02 2003
From: Jose.Alegria at oni.pt (=?iso-8859-1?Q?Jos=E9_Santos_Alegria?=)
Date: Mon Feb  3 17:33:02 2003
Subject: [R] Overlaying a moving average curve on top of a barplot
Message-ID: <3E41285CB4BABD4D81B3A3A0324542E9015CF6BD@dnslgp01>

It makes sense and it works!

Thanks and best regards,

Jos? A. S. Alegria
 
 


-----Original Message-----
From: Marc Schwartz [mailto:MSchwartz at MedAnalytics.com] 
Sent: segunda-feira, 3 de Fevereiro de 2003 4:18 PM
To: Jos? Santos Alegria; r-help at stat.math.ethz.ch
Subject: RE: [R] Overlaying a moving average curve on top of a barplot


>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jos? 
>Santos Alegria
>Sent: Monday, February 03, 2003 5:30 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Overlaying a moving average curve on top of a barplot
>
>
>I'm using standard barplot (Windows version 1.6.2 of R) to
>represent a certain weekly metric "v" and I would like to 
>properly overlay on top of it its moving average "mean.8" 
>(window of 8 weeks). I must be doing something wrong since the 
>moving average (using "lines") doesn't overlay properly, i.e., 
>both x-scales do not match!
> 
>...
>barplot(v[8:length(v)], col=7)
>lines(mean.8[1:length(mean.8)],   lty=1, lwd=2, col=2)
>...
> 
>How do I make sure that both graphics are in synch as far as
>the x-scale and y-scales are concerned?
> 
>Thanks,
>
>Jos? A. S. Alegria

The problem that you are having is that you need to get the bar midpoints from barplot() in order to use those values as the x coordinate values for lines().  barplot() returns the bar midpoints as an invisible vector (or matrix where appropriate).

Modify your code to:

mp <- barplot(v[8:length(v)], col=7)
lines(mp, mean.8[1:length(mean.8)],   lty=1, lwd=2, col=2)

This puts the bar midpoints (x axis values) in mp, which you can then use for lines().

HTH,

Marc



From p.dalgaard at biostat.ku.dk  Mon Feb  3 17:54:17 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Feb  3 17:54:17 2003
Subject: [R] r-bugs web site temporarily UP
In-Reply-To: <x2wuklwe9z.fsf@biostat.ku.dk>
References: <x2wuklwe9z.fsf@biostat.ku.dk>
Message-ID: <x2isw1johl.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> The machine that serves r-bugs.biostat.ku.dk has been taken off the
> net. A new machine is planned to replace it, but we need to
> reconfigure the DNS, which is not going to happen until Monday. The
> mail interface should still work.

We got swamped by ORDB pointing out that sendmail wasn't up to snuff
(if you don't know what that means, just consider yourself lucky...).
So we just put the old machine back up for now, but it will obviously
have to be taken down eventually.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From showie at uoguelph.ca  Mon Feb  3 18:00:05 2003
From: showie at uoguelph.ca (Steve Howie)
Date: Mon Feb  3 18:00:05 2003
Subject: [R] Installation problem - No X interface
Message-ID: <3E3E9F50.3000706@uoguelph.ca>

Hi

I've installed the "R" system under Solaris 8 on a SunFire V880. I 
configured it using the "--with-x" option. Installation seemed to go 
fine, but when I start R with the X-Windows GUI option,

				R  --gui=X11

I just get put into the command-line mode.

Any ideas what I'm missing?

Thanks

Scotty



From J.B.Bremnes at met.no  Mon Feb  3 18:04:02 2003
From: J.B.Bremnes at met.no (John Bjornar Bremnes)
Date: Mon Feb  3 18:04:02 2003
Subject: [R] convert from seconds to date-time objects
References: <3E3E8C55.EAD645AB@met.no>
Message-ID: <3E3EA035.9DC93100@met.no>

The solution turned out to be simple:

> x <- 0:100
> class(x) <- "POSIXct"
> x


John Bjornar

John Bjornar Bremnes wrote:
> 
> A colleague of mine would like to know how seconds since 1970
> (represented as integers) can be converted to date-time objects?
> 
> thanks
> 
> --
> John Bjornar Bremnes
> Norwegian Meteorological Institute (met.no)
> Research and Development Department
> P.O.Box 43 Blindern, N-0313 Oslo, Norway
> Phone: (+47) 2296 3326. Fax: (+47) 2269 6355
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Mon Feb  3 18:08:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Feb  3 18:08:03 2003
Subject: [R] convert from seconds to date-time objects
In-Reply-To: <3E3E8C55.EAD645AB@met.no>
Message-ID: <Pine.A41.4.44.0302030904490.141248-100000@homer06.u.washington.edu>

On Mon, 3 Feb 2003, John Bjornar Bremnes wrote:

> A colleague of mine would like to know how seconds since 1970
> (represented as integers) can be converted to date-time objects?

ISOdate(1970,1,1)+seconds

	-thomas



From tlumley at u.washington.edu  Mon Feb  3 18:12:04 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Feb  3 18:12:04 2003
Subject: [R] convert from seconds to date-time objects
In-Reply-To: <3E3EA035.9DC93100@met.no>
Message-ID: <Pine.A41.4.44.0302030907240.141248-100000@homer06.u.washington.edu>

On Mon, 3 Feb 2003, John Bjornar Bremnes wrote:

> The solution turned out to be simple:
>
> > x <- 0:100
> > class(x) <- "POSIXct"
> > x
>

Yes, but that relies on the internal representation of POSIXct objects,
which is probably unwise.

	-thomas



From p.dalgaard at biostat.ku.dk  Mon Feb  3 18:15:19 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Feb  3 18:15:19 2003
Subject: [R] Installation problem - No X interface
In-Reply-To: <3E3E9F50.3000706@uoguelph.ca>
References: <3E3E9F50.3000706@uoguelph.ca>
Message-ID: <x2bs1tjno9.fsf@biostat.ku.dk>

Steve Howie <showie at uoguelph.ca> writes:

> Hi
> 
> I've installed the "R" system under Solaris 8 on a SunFire V880. I
> configured it using the "--with-x" option. Installation seemed to go
> fine, but when I start R with the X-Windows GUI option,
> 
> 				R  --gui=X11
> 
> I just get put into the command-line mode.
> 
> Any ideas what I'm missing?

Possibly nothing. X11 *is* a GUI, --gui=X11 just means that X11
windows are used for graphics and the data editor. If plot(1) pops
up a window, things are as they should be.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From heberto.ghezzo at mcgill.ca  Mon Feb  3 18:19:02 2003
From: heberto.ghezzo at mcgill.ca (Heberto Ghezzo)
Date: Mon Feb  3 18:19:02 2003
Subject: [R] problems with sd()
Message-ID: <3E3EA373.8090806@mcgill.ca>

Hello, The other day I wrote about my SD() function did not work with NA 
in the input and it did not recognise the na.rm=T parameter.
BDR ask me if I had another SD function loaded. I did not wrote any sd 
function but with ls() there it was sd <- function(x) 
sqrt(var(as.vector(x)), I found out that it came from 
 BugsR\regression.r  an interface to WinBugs from R written by Andrew 
Gelman of Columbia U.
So if you use BugsR be sure to delete the redefinition of sd in 
regression R.
If somebody has the email address of Andrew Gelman please forward this 
one to him so he can fix it for the next version.
Thanks to all
Heberto Ghezzo Ph.D.
Meakins-Christie Labs
McGill University
Montreal - Canada



From p.dalgaard at biostat.ku.dk  Mon Feb  3 18:26:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Feb  3 18:26:03 2003
Subject: [R] convert from seconds to date-time objects
In-Reply-To: <Pine.A41.4.44.0302030904490.141248-100000@homer06.u.washington.edu>
References: <Pine.A41.4.44.0302030904490.141248-100000@homer06.u.washington.edu>
Message-ID: <x265s1jmy2.fsf@biostat.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

> On Mon, 3 Feb 2003, John Bjornar Bremnes wrote:
> 
> > A colleague of mine would like to know how seconds since 1970
> > (represented as integers) can be converted to date-time objects?
> 
> ISOdate(1970,1,1)+seconds

I think you might want 

ISOdate(1970,1,1,hour=0)+1:100

to get it to count from midnight, GMT.

Notice that there are devils lurking in using class(x)<-

> class(ISOdate(1970,1,1,hour=0)+1:100)
[1] "POSIXt"  "POSIXct"

so that's what you need to set class(x) to. Without the "POSIXt" bit
you may run into method dispatch problems later on. Currently, that
is! Relying on the internal representation of a class is generally to
be avoided.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Mon Feb  3 19:38:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb  3 19:38:03 2003
Subject: [R] convert from seconds to date-time objects
In-Reply-To: <3E3E8C55.EAD645AB@met.no>
Message-ID: <Pine.LNX.4.44.0302031835550.11708-100000@gannet.stats>

On Mon, 3 Feb 2003, John Bjornar Bremnes wrote:

> A colleague of mine would like to know how seconds since 1970
> (represented as integers) can be converted to date-time objects? 

structure(as.double(x), class=c("POSIXt", "POSIXlt"))

will do it in the current version.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Feb  3 19:43:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb  3 19:43:03 2003
Subject: [R] convert from seconds to date-time objects
In-Reply-To: <3E3EA035.9DC93100@met.no>
Message-ID: <Pine.LNX.4.44.0302031839551.11708-100000@gannet.stats>

On Mon, 3 Feb 2003, John Bjornar Bremnes wrote:

> The solution turned out to be simple:

But wrong.  That's not the right class.  Thomas Lumley's suggestion is 
better, and mine is correct but less elegant.

> > x <- 0:100
> > class(x) <- "POSIXct"
> > x

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From stranda at cofc.edu  Mon Feb  3 20:29:05 2003
From: stranda at cofc.edu (Allan Strand)
Date: Mon Feb  3 20:29:05 2003
Subject: [R] vectorized "leave one out" analyses
In-Reply-To: <3E3CE3D8.17360.103644@localhost>
Message-ID: <87isw1nozf.fsf_-_@linum.cofc.edu>

Hi all,

I'm implementing a population genetic statistic that requires repeated
re-estimation of population parameters after a single observation has
been left out.  It seems to me that one could:

a) use looping in R,
b) use a vectorized approach in R,
c) loop in a dynamically loaded c-function,
d) or use an existing jackknife routine.

an untested skeleton of the code for  'a':

foo <- function(datfrm)
{
  retvec <- rep(0,nrow(datfrm))
  selvec <- rep(T,nrow(datfrm))
  for (i in 1:nrow(datfrm))
    {
       selvec[i] <- F
       retvec[i] <- popstat(datfrm[selvec]) 
       selvec[i] <- T
    }
  retvec
}

I suppose that 'd' is the easiest option if such a routine exists, but
I have not come across one by means of an archive search.  I'd like to
avoid 'a' because of efficiency, and 'c' because of additional coding
and linking steps.  I like the idea of 'b' because it would be nifty
and likely fast, though there may be memory issues.  I'm sure that
this is a general problem that somebody has solved in an elegant
fashion.  I'm just looking for the solution. 

-- 
Allan Strand,   Biology    http://linum.cofc.edu
College of Charleston      Ph. (843) 953-9189
Charleston, SC 29424       Fax (843) 953-9199



From ripley at stats.ox.ac.uk  Mon Feb  3 20:42:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb  3 20:42:02 2003
Subject: [R] vectorized "leave one out" analyses
In-Reply-To: <87isw1nozf.fsf_-_@linum.cofc.edu>
Message-ID: <Pine.LNX.4.44.0302031937590.11819-100000@gannet.stats>

There are jackknife functions about, but this is not jackknifing. Unless
popstat is itself vectorized (meaning I think that it can take list of
datasets, or perhaps a matrix)  I doubt if anything is better than (a).

Remember Jackson's rules of programming (which are quoted in `S 
Programming').  Don't optimize until you need to.

On 3 Feb 2003, Allan Strand wrote:

> Hi all,
> 
> I'm implementing a population genetic statistic that requires repeated
> re-estimation of population parameters after a single observation has
> been left out.  It seems to me that one could:
> 
> a) use looping in R,
> b) use a vectorized approach in R,
> c) loop in a dynamically loaded c-function,
> d) or use an existing jackknife routine.
> 
> an untested skeleton of the code for  'a':
> 
> foo <- function(datfrm)
> {
>   retvec <- rep(0,nrow(datfrm))
>   selvec <- rep(T,nrow(datfrm))
>   for (i in 1:nrow(datfrm))
>     {
>        selvec[i] <- F
>        retvec[i] <- popstat(datfrm[selvec]) 
>        selvec[i] <- T
>     }
>   retvec
> }
> 
> I suppose that 'd' is the easiest option if such a routine exists, but
> I have not come across one by means of an archive search.  I'd like to
> avoid 'a' because of efficiency, and 'c' because of additional coding
> and linking steps.  I like the idea of 'b' because it would be nifty
> and likely fast, though there may be memory issues.  I'm sure that
> this is a general problem that somebody has solved in an elegant
> fashion.  I'm just looking for the solution. 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rolf at math.unb.ca  Mon Feb  3 20:46:03 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon Feb  3 20:46:03 2003
Subject: [R] (Off topic.) Game theory.
Message-ID: <200302031945.PAA08133@gelfand.math.unb.ca>

This has nothing to do with R as such; I'm simply trying to exploit
the vast resource of knowledge and expertise that resides in the R
community.

For my sins, I am teaching a course on Game Theory this term.  Game
Theory I know from ***nothing***.  I am trying to learn the subject
as I go along, staying perhaps half a step in front of the students.

I am having considerable difficulty with several elementary points,
(vis-a-vis two person non-zero-sum games) and have not yet succeeded
in clarifying these points from any of the books that I have managed
to get my hands on.

Is there any kind soul out there (or do any of you have a kind-soul
colleague) who might be willing to discuss some of my game theory
difficulties with me by email?  Such a person would earn my undying
gratitude.  (Sorry that I can't offer a more substantial reward. :-) )

Since this is off-topic, please reply to me (only) at

		rolf at math.unb.ca

and not to the list.

Thanks, and thanks to everyone for their patience with my usurption
of bandwidth.

				cheers,

					Rolf Turner



From thomasio at cs.tu-berlin.de  Mon Feb  3 20:50:22 2003
From: thomasio at cs.tu-berlin.de (Thomas Koenig)
Date: Mon Feb  3 20:50:22 2003
Subject: [R] extension of generic functions in methods package
Message-ID: <200302050624.37819.thomasio@cs.tu-berlin.de>

How can I extend the signature of a generic function, because the following 
example is unclear for me.

setClass("A",representation(data="numeric"));

setGeneric("func",function(obj,...){
  res <- standardGeneric("func");
  res at cal <- match.arg();
  return(res);
});

func1.A <- function(obj){
  print("A");
  return();
}

setMethod("func","A",func1.A);
showMethods("func")

##Function "func":
##obj = "A"

func2.A <- function(obj,x){
  print("A");
  return();
}

## gives error
## setMethod("func",c("A","numeric"),func2.A);
##Error in matchSignature(signature, fdef) :
##       Invalid names in signature:

## extending the signature
setGeneric("func",function(obj,x,...){
  res <- standardGeneric("func");
  res at cal <- match.arg();
  return(res);
});

setMethod("func",c("A","numeric"),func2.A);

## but:
showMethods("func")

##Function "func":
##obj = "A", x = "numeric"

## and
a <- new("A");
func(A)
## gives
##Error in func(a) : No direct or inherited method for function "func" for 
##this call

## but this works
func(a,1)

##[1] "A"
##NULL


My questions:
1) Is it correct, that func1.A disappears in the showMethods output?
2) How can I extend the signature of a generic function, without removing the  
other functions?

Thanks

Thomas



From zhuw at post.cis.smu.edu  Mon Feb  3 20:54:40 2003
From: zhuw at post.cis.smu.edu (zhu wang)
Date: Mon Feb  3 20:54:40 2003
Subject: FW: [R] unable to open connection
Message-ID: <000101c2cbbd$27d1e600$45e37781@omnibook>

Thanks to Brian D. Ripley and Uwe Ligges. It works now.
 
 Zhu Wang
 
 Statistical Science Department
 Southern Methodist University
 3225 Daniel Avenue, Heroy 123
 Dallas, TX 75275
 Tel:  (214)768-2453
 Fax: (214)768-4035
> 
> 
> > -----Original Message-----
> > From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> > Sent: Sunday, February 02, 2003 5:22 AM
> > To: ripley at stats.ox.ac.uk
> > Cc: zhuw at post.cis.smu.edu; whitcher at ucar.edu
> > Subject: Re: [R] unable to open connection
> >
> > ripley at stats.ox.ac.uk wrote:
> > >
> > > It works here on Windows with R 1.6.2.  I rebuilt the precompiled
> > version,
> > > as that seems no longer to so so (although it did when it was
built
> > > under I think 1.5.0).
> > >
> > > The original posting did not give an OS.  If this is Windows, the
> > comments
> > > in the ReadMe and rw-FAQ apply: compile it from source yourself,
and
> > don't
> > > report problems on R-help.  The service provided does not extend
to
> > > checking that packages keep working with each new R version.
> > >
> > > My recompiled version will get to CRAN tonight: right now see
> > > http://toucan.stats.ox.ac.uk/R/RWin/waveslim.zip
> >
> > Great, Brian, it works now. But where is the relevant difference?
> > I haven't tried to recompile, because I thought it does not matter.
> >
> > Uwe



From fugate at trinidad.c3.lanl.gov  Mon Feb  3 21:11:02 2003
From: fugate at trinidad.c3.lanl.gov (Michael Lynn Fugate)
Date: Mon Feb  3 21:11:02 2003
Subject: [R] binary scatterplot
Message-ID: <Pine.LNX.4.33.0302031301430.10857-100000@trinidad.c3.lanl.gov>

Hi,

When I use the function plot() to plot a categorical variable with two
levels versus a continuous variable, the two levels of the categorical
variable are plotted at the values of 1.0 and 2.0.  I would like them to
be plotted at the values of 0.0 and 1.0.  How can I do this?

Example:

x <- 1:10
y <- as.factor(rep(c("A","B"),c(5,5)))
plot(x,y)

Thanks in advance.

version:
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.1
year     2002
month    11
day      01
language R

-- 

******************************************************************
| Michael Fugate                         Phone:  (505) 667-0398  |
| Los Alamos National Laboratory         Fax:    (505) 665-5220  |
| Group: CCS-3,  Mail Stop: B265         e-mail: fugate at lanl.gov |
| Los Alamos, NM 87545                                           |
******************************************************************



From mmiller3 at iupui.edu  Mon Feb  3 21:26:03 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Mon Feb  3 21:26:03 2003
Subject: [R] binary scatterplot
In-Reply-To: <Pine.LNX.4.33.0302031301430.10857-100000@trinidad.c3.lanl.gov>
References: <Pine.LNX.4.33.0302031301430.10857-100000@trinidad.c3.lanl.gov>
Message-ID: <871y2p158y.fsf@lumen.indyrad.iupui.edu>

>>>>> "Michael" == Michael Lynn Fugate <fugate at trinidad.c3.lanl.gov> writes:

    > Hi, When I use the function plot() to plot a categorical
    > variable with two levels versus a continuous variable, the
    > two levels of the categorical variable are plotted at the
    > values of 1.0 and 2.0.  I would like them to be plotted at
    > the values of 0.0 and 1.0.  How can I do this?

This is not quite what you are asking for, but it might serve
just as well:

> x <- 1:10
> y <- as.factor(rep(c("A","B"),c(5,5)))
> dotchart(x,groups=y)

or

> require(lattice)
> df<-data.frame(x,y)
> stripplot(y~x, data=df) 

or

> require(lattice)
> df<-data.frame(x,y)
> dotplot(y~x, data=df)

Mike



From ligges at statistik.uni-dortmund.de  Mon Feb  3 21:49:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Feb  3 21:49:03 2003
Subject: [R] binary scatterplot
References: <Pine.LNX.4.33.0302031301430.10857-100000@trinidad.c3.lanl.gov>
Message-ID: <3E3ED5B2.F1D636B5@statistik.uni-dortmund.de>


Michael Lynn Fugate wrote:
> 
> Hi,
> 
> When I use the function plot() to plot a categorical variable with two
> levels versus a continuous variable, the two levels of the categorical
> variable are plotted at the values of 1.0 and 2.0.  I would like them to
> be plotted at the values of 0.0 and 1.0.  How can I do this?
> 
> Example:
> 
> x <- 1:10
> y <- as.factor(rep(c("A","B"),c(5,5)))
> plot(x,y)


 plot(x, as.integer(y) - 1)

Uwe Ligges


> Thanks in advance.
> 
> version:
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    6.1
> year     2002
> month    11
> day      01
> language R
> 
> --
> 
> ******************************************************************
> | Michael Fugate                         Phone:  (505) 667-0398  |
> | Los Alamos National Laboratory         Fax:    (505) 665-5220  |
> | Group: CCS-3,  Mail Stop: B265         e-mail: fugate at lanl.gov |
> | Los Alamos, NM 87545                                           |
> ******************************************************************
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jfox at mcmaster.ca  Mon Feb  3 21:56:08 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon Feb  3 21:56:08 2003
Subject: [R] binary scatterplot
In-Reply-To: <Pine.LNX.4.33.0302031301430.10857-100000@trinidad.c3.lanl.
 gov>
Message-ID: <5.0.2.1.0.20030203151920.00b0eda8@mcmail.cis.mcmaster.ca>

Dear Michael,

You could use plot(x, as.numeric(y) - 1).

John

At 01:10 PM 2/3/2003 -0700, Michael Lynn Fugate wrote:
>Hi,
>
>When I use the function plot() to plot a categorical variable with two
>levels versus a continuous variable, the two levels of the categorical
>variable are plotted at the values of 1.0 and 2.0.  I would like them to
>be plotted at the values of 0.0 and 1.0.  How can I do this?
>
>Example:
>
>x <- 1:10
>y <- as.factor(rep(c("A","B"),c(5,5)))
>plot(x,y)

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From ligges at statistik.uni-dortmund.de  Mon Feb  3 22:05:07 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Feb  3 22:05:07 2003
Subject: [R] Problems with table
References: <Pine.GSO.4.32.0302031313490.4078-100000@goiana>
Message-ID: <3E3ED941.67EF78DB@statistik.uni-dortmund.de>

Patricia Maforte dos Santos wrote:
> 
> Hi,
> 
> I'm having difficulties in the manipulation of the function table.
> Necessary to have access its elements and I am not obtaining. For example,
> if I have a data.frame with name "df" and make:
> t < - data.frame(table(df))

Dou you really want to generate a data.frame from that table?
BTW: Assigning is done by "<-", not "< -" ...


> and later trying to make a comparison of the type t[1,1 ] < 0.1, generates
> an error of the type:
> 
> [1] NA
> Warning message:
> "<" not meaningful for factors in: Ops.factor(t[1, 1], 0.1)

Because t[1,1] is an element of a vector of class "factor" (due to the
use of data.frame()).
BTW: t() is a very basic function in R. Thus it's generally a bad idea
to call another object "t", although it works at least in this case.

> How can I resolve this?


I guess you want something like 
 table(df)[1,1] < 0.1
don't you?


Uwe Ligges

> Thanks,
> 
> ----------------------------------
> Patr?cia Maforte dos Santos
> Centro de Informatica
> Universidade Federal de Pernambuco
> Recife/PE - Brasil
> ----------------------------------
>



From dyang at nrcan.gc.ca  Mon Feb  3 22:49:05 2003
From: dyang at nrcan.gc.ca (Yang, Richard)
Date: Mon Feb  3 22:49:05 2003
Subject: [R] Mtext and xyplot
Message-ID: <F0E0B899CB43D5118D220002A55113CF21BBD0@s2-edm-r1.nofc.cfs.nrcan.gc.ca>

Dear all;

I wish to create a graphic object combing an xyplot() and an mtext(). My
code looks like following,

gmv <-  {
         trellis.device("windows", bg="white", width = 7, height = 7)
         
  xyplot(Mvol  ~ Age | Nl * Th , data = Hft1, 
  
  prepanel = function(x, y) prepanel.loess(x, y, span = 1),
        xlab =list(label = "Age (Years)", font = 2),
        ylab = " ", 
#        ylab = list(expression(paste("Volume ( ", paste(m^3/ha, ")"), sep=
" ")), font=2),
         main = list(" Volume"),
         par.strip.text = list(cex=1.0, font = 2),
       panel = function(x, y)  {
         panel.grid ()
         panel.xyplot(x,y, col= "black")
         panel.lmline(x, y, lty = 2, lwd = 2) 
         panel.loess(x, y, span = 1, degree = 1, lty=1, lwd=2) } )
         mtext(expression(paste("Volume ( ", paste(m^3/ha, ")"), sep = "
")), outer=T,
font = 2, side = 2, line = -1 )
         }

The mtext() is to replace the ylab because the font = 2 in the above
commented line does not result in a bold font as in the xlab. The code
within the outmost { } works fine on a windows device  but generates error
when it runs as a function:

Error in mtext(expression(paste("Volume ( ", paste(m^3/ha, ")"),  : 
        plot.new has not been called yet

Any suggestions to rectify the error?

TIA,

Richard



From deepayan at stat.wisc.edu  Mon Feb  3 23:35:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon Feb  3 23:35:03 2003
Subject: [R] Mtext and xyplot
In-Reply-To: <F0E0B899CB43D5118D220002A55113CF21BBD0@s2-edm-r1.nofc.cfs.nrcan.gc.ca>
References: <F0E0B899CB43D5118D220002A55113CF21BBD0@s2-edm-r1.nofc.cfs.nrcan.gc.ca>
Message-ID: <200302031634.32139.deepayan@stat.wisc.edu>

On Monday 03 February 2003 03:47 pm, Yang, Richard wrote:
> Dear all;
>
> I wish to create a graphic object combing an xyplot() and an mtext(). 

You cannot. xyplot() uses grid for all its graphics, and grid graphics cannot 
be used in conjunction with base R graphics functions.

> My
> code looks like following,
>
> gmv <-  {
>          trellis.device("windows", bg="white", width = 7, height = 7)
>
>   xyplot(Mvol  ~ Age | Nl * Th , data = Hft1,
>
>   prepanel = function(x, y) prepanel.loess(x, y, span = 1),
>         xlab =list(label = "Age (Years)", font = 2),
>         ylab = " ",
> #        ylab = list(expression(paste("Volume ( ", paste(m^3/ha, ")"), sep=
> " ")), font=2),
>          main = list(" Volume"),
>          par.strip.text = list(cex=1.0, font = 2),
>        panel = function(x, y)  {
>          panel.grid ()
>          panel.xyplot(x,y, col= "black")
>          panel.lmline(x, y, lty = 2, lwd = 2)
>          panel.loess(x, y, span = 1, degree = 1, lty=1, lwd=2) } )
>          mtext(expression(paste("Volume ( ", paste(m^3/ha, ")"), sep = "
> ")), outer=T,
> font = 2, side = 2, line = -1 )
>          }
>
> The mtext() is to replace the ylab because the font = 2 in the above
> commented line does not result in a bold font as in the xlab. 

And it does inside mtext ? (I don't see that on Linux, maybe it does on 
Windows.)

> The code
> within the outmost { } works fine on a windows device  but generates error
> when it runs as a function:
>
> Error in mtext(expression(paste("Volume ( ", paste(m^3/ha, ")"),  :
>         plot.new has not been called yet
>
> Any suggestions to rectify the error?

maybe something like 

  ylab = list(expression(bold("Volume...

(read ?plotmath)



> TIA,
>
> Richard
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dyang at nrcan.gc.ca  Tue Feb  4 00:11:03 2003
From: dyang at nrcan.gc.ca (Yang, Richard)
Date: Tue Feb  4 00:11:03 2003
Subject: [R] Mtext and xyplot
Message-ID: <F0E0B899CB43D5118D220002A55113CF21BBD2@s2-edm-r1.nofc.cfs.nrcan.gc.ca>

Many thanks to  Patrick Connolly and  Deepayan Sarkar for their quick
responses to my query. In essence,
grid graphics cannot be used in conjunction with base R graphic functions
such as mtext(). Deepayan suggests using bold() in the ylab in place of font
= 2;  the bold() does produce the desired font in ylab.

Richard



From dstates at bioinformatics.med.umich.edu  Tue Feb  4 00:38:02 2003
From: dstates at bioinformatics.med.umich.edu (David States)
Date: Tue Feb  4 00:38:02 2003
Subject: [R] Plotting Venn diagrams in R
Message-ID: <8D9D9C12B61BD242AD67248A007140270A2901@mail.bicc.med.umich.edu>

Last year there was a request seeking functions to plot Venn diagrams in
R.   Seeing no reply and for other reasons needing this, I wrote a quick
routine.  The general problem of creating a Venn diagram with overlap
areas proportional to the number of counts in each overlap is over
determined.  An approximate solution is to make the area of the circles
and pair wise overlap areas proportional to the number of counts in
each.  Using just the pair wise overlaps ignores (or hopes for the best
on :) ) the area of the three-way overlap.  R code that implements this
is shown below.  

Usage: A, B and C are Boolean vectors of equal length, e.g.

A = runif(100) < 0.5
B = runif(100) < 0.4
C = runif(100) < 0.6

d = list()
d$table = table(A,B,C)
d$labels = c("A","B","C")

plot.venn.diagram(d)

This is pre-alpha code, caveat emptor.  In particular, the code to
position the labels needs work.  If someone wants to convert this to a
package or add it to an existing package, feel free to do so.  

To optimize the solution over all of the overlaps or if you have more
than three sets, you can use a random sampling approach, but
implementing this in R is too slow to be useful.

David

David J. States, M.D., Ph.D.
Professor of Human Genetics
Director of Bioinformatics
University of Michigan School of Medicine
Medical Science Building I, Room 5443
Ann Arbor, MI 48109
USA

venn.overlap <- 
function(r, a, b, target = 0)
{
#
# calculate the overlap area for circles of radius a and b 
# with centers separated by r
# target is included for the root finding code
#
	pi = acos(-1)
	if(r >= a + b) {
		return( - target)
	}
	if(r < a - b) {
		return(pi * b * b - target)
	}
	if(r < b - a) {
		return(pi * a * a - target)
	}
	s = (a + b + r)/2
	triangle.area = sqrt(s * (s - a) * (s - b) * (s - r))
	h = (2 * triangle.area)/r
	aa = 2 * atan(sqrt(((s - r) * (s - a))/(s * (s - b))))
	ab = 2 * atan(sqrt(((s - r) * (s - b))/(s * (s - a))))
	sector.area = aa * (a * a) + ab * (b * b)
	overlap = sector.area - 2 * triangle.area
	return(overlap - target)
}

plot.venn.diagram <- 
function(d)
{
#
# Draw Venn diagrams with proportional overlaps
# d$table = 3 way table of overlaps
# d$labels = array of character string to use as labels
#
pi = acos(-1)
csz = 0.1
# Normalize the data
n = length(dim(d$table))
c1 = vector(length = n)
c1[1] = sum(d$table[2,  ,  ])
c1[2] = sum(d$table[, 2,  ])
c1[3] = sum(d$table[,  , 2])
n1 = c1
#
c2 = matrix(nrow = n, ncol = n, 0)
c2[1, 2] = sum(d$table[2, 2,  ])
c2[2, 1] = c2[1, 2]
c2[1, 3] = sum(d$table[2,  , 2])
c2[3, 1] = c2[1, 3]
c2[2, 3] = sum(d$table[, 2, 2])
c2[3, 2] = c2[2, 3]
n2 = c2
#
c3 = d$table[2, 2, 2]
n3 = c3
c2 = c2/sum(c1)
c3 = c3/sum(c1)
c1 = c1/sum(c1)
n = length(c1)
# Radii are set so the area is proporitional to number of counts
pi = acos(-1)
r = sqrt(c1/pi)
r12 = uniroot(venn.overlap, interval = c(max(r[1] - r[2], r[2] - r[1],
0) + 0.01, r[1] + r[2] - 0.01), a = r[1], b = r[
2], target = c2[1, 2])$root
r13 = uniroot(venn.overlap, interval = c(max(r[1] - r[3], r[3] - r[1],
0) + 0.01, r[1] + r[3] - 0.01), a = r[1], b = r[
3], target = c2[1, 3])$root
r23 = uniroot(venn.overlap, interval = c(max(r[2] - r[3], r[3] - r[2],
0) + 0.01, r[2] + r[3] - 0.01), a = r[2], b = r[
3], target = c2[2, 3])$root
s = (r12 + r13 + r23)/2
x = vector()
y = vector()
x[1] = 0
y[1] = 0
x[2] = r12
y[2] = 0
angle = 2 * atan(sqrt(((s - r12) * (s - r13))/(s * (s - r13))))
x[3] = r13 * cos(angle)
y[3] = r13 * sin(angle)
xc = cos(seq(from = 0, to = 2 * pi, by = 0.01))
yc = sin(seq(from = 0, to = 2 * pi, by = 0.01))
cmx = sum(x * c1)
cmy = sum(y * c1)
x = x - cmx
y = y - cmy
rp=sqrt(x*x + y*y)
frame()
par(usr = c(-1, 1, -1, 1), pty = "s")
box()
for(i in 1:3) {
lines(xc * r[i] + x[i], yc * r[i] + y[i])
}
xl = (rp[1] + (0.7 * r[1])) * x[1]/rp[1]
yl = (rp[1] + (0.7 * r[1])) * y[1]/rp[1]
text(xl, yl, d$labels[1])
text(xl, yl - csz, d$table[2, 1, 1])
xl = (rp[2] + (0.7 * r[2])) * x[2]/rp[2]
yl = (rp[2] + (0.7 * r[2])) * y[2]/rp[2]
text(xl, yl, d$labels[2])
text(xl, yl - csz, d$table[1, 2, 1])
xl = (rp[3] + (0.7 * r[3])) * x[3]/rp[3]
yl = (rp[3] + (0.7 * r[3])) * y[3]/rp[3]
text(xl, yl, d$labels[3])
text(xl, yl - csz, d$table[1, 1, 2])
#
text((x[1] + x[2])/2, (y[1] + y[2])/2, d$table[2, 2, 1])
text((x[1] + x[3])/2, (y[1] + y[3])/2, d$table[2, 1, 2])
text((x[2] + x[3])/2, (y[2] + y[3])/2, d$table[1, 2, 2])
#
text(0, 0, n3)
list(r = r, x = x, y = y, dist = c(r12, r13, r23), count1 = c1, count2 =
c2, labels = d$labels)
}



From Frederic.Archaux at nogent.cemagref.fr  Tue Feb  4 09:49:03 2003
From: Frederic.Archaux at nogent.cemagref.fr (Archaux Frederic)
Date: Tue Feb  4 09:49:03 2003
Subject: [R] basic question
Message-ID: <31CFB6E0A456D511917700C04F10997CC3647F@orme.nogent.cemagref.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030204/d21b9757/attachment.pl

From Ko-Kang at xtra.co.nz  Tue Feb  4 10:19:03 2003
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Tue Feb  4 10:19:03 2003
Subject: [R] basic question
References: <31CFB6E0A456D511917700C04F10997CC3647F@orme.nogent.cemagref.fr>
Message-ID: <001601c2cc2e$472e8c30$733158db@kwan022>

Hi,


From ligges at statistik.uni-dortmund.de  Tue Feb  4 10:24:41 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue Feb  4 10:24:41 2003
Subject: [R] basic question
In-Reply-To: <31CFB6E0A456D511917700C04F10997CC3647F@orme.nogent.cemagref.fr>
References: <31CFB6E0A456D511917700C04F10997CC3647F@orme.nogent.cemagref.fr>
Message-ID: <3E3F859A.2050300@statistik.uni-dortmund.de>

Archaux Frederic wrote:
> Dear R users,
> 
> Up to now, I only used precompiled packages. As I am working on vegetation
> ecology, I would be interested in using a package not stored by CRAN called
> labdsv_0.9-1.tar.gz and developped by Dave Roberts at the National Center
> for Ecological Analysis and Synthesis (unfortunately I did not find any
> corresponding .zip file).
> 
> Although I tried to follow the proposed guidelines  to install such a file
> in R, I did not succeed. I installed the library tools, the Perl and the
> MinGW softwares, but I feel all this stuff is useless in my case (my
> knowledge in informatic in so poor that I am reduced to "intuitions"!)
> 
> I know this is probably one of the most FAQ, but I did not find the answer
> to my problem on the R-CRAN web site. Thank you in advance!
> 
> Have a good day. 

Thanks.


Well, you tell us about the existance of an R package with a specific 
name, which you cannot compile using the given instructions.
So, what answer do you expect?

Possible causes:
  - the package depends on anything not available on your system (or not 
found by the package)
  - the package is incompatible with your version of R
  - you have misinterpreted the instructions
  - you have not followed the isntrructions exactly
  - ...

Please tell us *relevant* facts, we cannot help without information!

In an attack of kindness I (and Google) found 
http://labdsv.nr.usu.edu/splus_R/labdsv_0.9-1.tar.gz
That package is not a complete R package! It's missing its DESCRIPTION 
file (and others)!
You might want to contact the author / maintainer or fix that package 
yourself.

Uwe Ligges


> Fr?d?ric Archaux (PhD, Engineer)
> ============================
> Biodiversity and Forest Management Team
> CEMAGREF
> Domaine des Barres
> F-45290 Nogent-sur-Vernisson
> FRANCE
>



From jarioksa at sun3.oulu.fi  Tue Feb  4 10:31:13 2003
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Tue Feb  4 10:31:13 2003
Subject: [R] basic question
In-Reply-To: 
	<31CFB6E0A456D511917700C04F10997CC3647F@orme.nogent.cemagref.fr>
References: <31CFB6E0A456D511917700C04F10997CC3647F@orme.nogent.cemagref.fr>
Message-ID: <1044350737.1729.21.camel@pc112145.oulu.fi>

On Tue, 2003-02-04 at 10:46, Archaux Frederic wrote:

> Up to now, I only used precompiled packages. As I am working on vegetation
> ecology, I would be interested in using a package not stored by CRAN called
> labdsv_0.9-1.tar.gz and developped by Dave Roberts at the National Center
> for Ecological Analysis and Synthesis (unfortunately I did not find any
> corresponding .zip file).
> 
> Although I tried to follow the proposed guidelines  to install such a file
> in R, I did not succeed. I installed the library tools, the Perl and the
> MinGW softwares, but I feel all this stuff is useless in my case (my
> knowledge in informatic in so poor that I am reduced to "intuitions"!)
> 
> I know this is probably one of the most FAQ, but I did not find the answer
> to my problem on the R-CRAN web site. Thank you in advance!

Fr?d?ric, 

Dave Roberts is not yet quite finished up with his package -- it is
labelled as a zero version for a reason. He wrote to me that it won't
compile in Windows yet, for an unknown reason. He said that he got to
edit the FORTRAN files to compile them in Windows (they work in Linux).
However, he had still some other problems and so you got to dyn.load the
resulting dll into R, which, but in Dave's words "That concept is
completely foreign to windows people of course, so it's pretty much
useless." 

It may be that you have to wait until Dave Roberts lectures on these
methods again, since then he may have to finish up the package.

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From ripley at stats.ox.ac.uk  Tue Feb  4 10:37:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb  4 10:37:03 2003
Subject: [R] basic question
In-Reply-To: <001601c2cc2e$472e8c30$733158db@kwan022>
Message-ID: <Pine.LNX.4.44.0302040929400.20364-100000@gannet.stats>

On Tue, 4 Feb 2003, Ko-Kang Kevin Wang wrote:

> >From your description I am guessing you're using Windows.
> 
> What you may need is to compile this package from source.  It is explained
> in one of the R manuals (I can't remember which one though).

The file README.packages in the Windows distribution, if on Windows.

> You can also look at my "R Guide for Windows Users" at
> http://www.stat.auckland.ac.nz/~kwan022/rinfo.php (Section 5).
> 
> I'm not sure the exact contents in the labdsv_0.9-1.tar.gz , but in general
> you can first unpack it with, e.g.:
>    tar zxvf labdsv_0.9-1.tar.gz
>  then you may need:
>    Rcmd labdsv_0.9-1

Rcmd INSTALL labdsv_0.9-1.tar.gz

is all that is needed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From grimm.heinz at rcc.ch  Tue Feb  4 14:00:04 2003
From: grimm.heinz at rcc.ch (Heinz Grimm)
Date: Tue Feb  4 14:00:04 2003
Subject: [R] [Out off-topic] SJava under Windows
Message-ID: <3E3FBA86.16AE4BFC@rcc.ch>

Philippe,

I didn't use JDK 1.4 (and R1.6.2) yet, but may be I can help
you anyway:

- Did you add the directory that holds the jvm.dll to
  your PATH?

- If you take a look to the source of .JavaInit() ($R_HOME/
  library/SJava/R/SJava), there is a line:
    pathSeparator <- ifelse(version$os == "Win32", ";", ":") 
  this should be:
    pathSeparator <- ifelse(version$os == "mingw32", ";", ":")
  All versions of R that I know of, return "mingw32" for version$os.

Best regards,
Heinz Grimm
-------------- next part --------------
A non-text attachment was scrubbed...
Name: grimm.heinz.vcf
Type: text/x-vcard
Size: 292 bytes
Desc: Card for Heinz Grimm
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030204/c094ecb6/grimm.heinz.vcf
-------------- next part --------------
This e-mail transmission contains confidential or legally privileged
information that is intended for the addressee(s) only. You are hereby
notified that any disclosure, copying, distribution or use of the
contents of this e-mail is strictly prohibited if you are not the
intended recipient. Please inform the sender and delete the message from
your system if you have received this e-mail transmission in error.
Thank you.

From rbonk at host.sk  Tue Feb  4 15:24:03 2003
From: rbonk at host.sk (Rado Bonk)
Date: Tue Feb  4 15:24:03 2003
Subject: [R] test for two samples
Message-ID: <3E40222C.9050802@host.sk>

Hi R-users,

My question is more methodological one, rather than technical.

I have to samples representing residuals based on two measurements 
techniques (resid1,resid2; n=69). I need to compare two samples, to 
reject one technique (the worse one), and to keep the one which gave 
lower residuals (better one). What to look for? What should I analyse? 
Means, variance, std. deviations?

Based on preliminary EDA:

mean_resid1 < mean_resid2	#I would reject resid2 technique
stdev_resid1 > stdev_resid2	#I would reject resid1 technique
var_resid1 > var_resid2		#I would reject resid1 technique

Based on means I would reject resid2 technique, but based on analyses of 
stdev. and variance I would reject resid1 technique.

How to deal with that problem? What is proper statist. atrribute to look 
for? Should I use t.test()?

Best regards,

Rado Bonk

-- 
Radoslav Bonk M.S.
Dept. of Physical Geography and Geoecology
Faculty of Sciences, Comenius University
Mlynska Dolina 842 15, Bratislava, SLOVAKIA
tel: +421 905 968 127 e-mail: rbonk at host.sk



From azzalini at stat.unipd.it  Tue Feb  4 16:31:03 2003
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Tue Feb  4 16:31:03 2003
Subject: [R] downloaf.file
In-Reply-To: <20030204110013.12993.2104.Mailman@hypatia.math.ethz.ch>
References: <20030204110013.12993.2104.Mailman@hypatia.math.ethz.ch>
Message-ID: <20030204152839.97A727CA822@tango.stat.unipd.it>

Dear List-members,

to download a file from the net, the function download.file(..)
does the job.  However, before embarking on the download, I would
like to find out how large the file is.  Is there a way to know it?

Most easily, this question has been asked before, but I am new to 
the list.

Regards, with thanks in advance,

Adelchi Azzalini

----
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit? di Padova, Italia
http://azzalini.stat.unipd.it/



From ripley at stats.ox.ac.uk  Tue Feb  4 16:40:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb  4 16:40:03 2003
Subject: [R] downloaf.file
In-Reply-To: <20030204152839.97A727CA822@tango.stat.unipd.it>
Message-ID: <Pine.LNX.4.44.0302041537120.30203-100000@gannet.stats>

Essentially no.  Most servers will give you the length if you start the 
download, and then R prints it out, but it may be "unknown".  As in
> update.packages()
trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 95407 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ...
downloaded 93Kb

and you can (probably) interrupt during those dots.

On Tue, 4 Feb 2003, Adelchi Azzalini wrote:

> to download a file from the net, the function download.file(..)
> does the job.  However, before embarking on the download, I would
> like to find out how large the file is.  Is there a way to know it?
> 
> Most easily, this question has been asked before, but I am new to 
> the list.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From phgrosjean at sciviews.org  Tue Feb  4 16:55:03 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue Feb  4 16:55:03 2003
Subject: [R] [Out off-topic] SJava under Windows
In-Reply-To: <3E3FBA86.16AE4BFC@rcc.ch>
Message-ID: <MABBLJDICACNFOLGIHJOAEFJDDAA.phgrosjean@sciviews.org>

For those who are interested, I posted a Windows compiled version of SJava
0.64 that works with R 1.6.2 and JDK 1.4 on ftp.sciviews.org, under
/Download/Rwindows/.


Thanks Simon, Heinz and Brian for helping me getting this running version.
When compiling SJava 0.64 under Windows (R 1.6.2, JDK 1.4.0-02, Win XP),
line 286 of $R_HOME/library/SJava/R/SJava has to be changed from:

   pathSeparator <- ifelse(version$os == "Win32", ";", ":")

to

   pathSeparator <- ifelse(.Platform$OS.type == "windows", ";", ":")

in order to work in R 1.6.2. Of course, the path to jvm.dll must also be
added to the "path" environment variable. With my installation, it is:

c:\progra~1\Java\j2re1.4.0_02\bin\Client


Best regards,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oceanologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



From pms at cin.ufpe.br  Tue Feb  4 17:20:04 2003
From: pms at cin.ufpe.br (Patricia Maforte dos Santos)
Date: Tue Feb  4 17:20:04 2003
Subject: [R] Background color of plot
Message-ID: <Pine.GSO.4.32.0302041308350.15551-100000@goiana>

I'm using the parameters "mfrow" and "mfg" to display some graphics(plots)
at the same time. Although, because of the parameter "mfg", the parameter
"bg" dont change the background color.

What can I do to solve this?


Here is the code I'm using...

...
     i <- 1
     for(j in 1:4){
         for(k in 1:2){
                     limiares <- tabLimiar(arrayMetricas[,i])
                     op <- par(mfrow=c(4,2),pty="s")
                     par(mfg=c(j,k))
                     plot(limiares,main=a[i],ylab="frequencia",xlab="limiares",bg="white",col="green",col.main="seagreen",type="b")
                     box(which="figure",lty="solid",col="white")
                     par(op)
                     i <- i+1
                     if(i == ncol(arrayMetricas))
                        break
         }
     }
...


Patricia.

----------------------------------
Patrcia Maforte dos Santos
Centro de Informatica
Universidade Federal de Pernambuco
Recife/PE - Brasil
----------------------------------



From B.Rowlingson at lancaster.ac.uk  Tue Feb  4 17:26:09 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue Feb  4 17:26:09 2003
Subject: [R] downloaf.file
In-Reply-To: <Pine.LNX.4.44.0302041537120.30203-100000@gannet.stats>
References: <Pine.LNX.4.44.0302041537120.30203-100000@gannet.stats>
Message-ID: <3E3FE8E4.9030205@lancaster.ac.uk>

>>to download a file from the net, the function download.file(..)
>>does the job.  However, before embarking on the download, I would
>>like to find out how large the file is.  Is there a way to know it?
>>

  You can send web servers a 'HEAD' request, which can give you some 
basic information about the download. I cant see a way to get this from 
the current R functions, so here's a little routine to leverage the 
'lynx' web browser:


"head.download" <-
   function (url)
{
   if (system("lynx -help > /dev/null") == 0) {
     method <- "lynx"
   }
   else {
     stop("No lynx found")
   }
   if (method == "lynx") {
     heads <- system(paste("lynx -head -dump '", url,"'", sep = 
""),intern=T)
   }

# turn name: value lines into named list. prob vectorisable

   ret <- list(status=heads[1])
   for(l in 2:length(heads)){
     col <- regexpr(":",heads[l])
     if(col>-1){
       name <- substr(heads[l],1,(col-1))
       value <- substr(heads[l],(col+1),nchar(heads[l]))
       ret[[name]] <- value
     }else{
       ret <- c(ret,heads[l])
     }
   }
   ret
}

  this borrows bits from download.file(), but it does depend on you 
having lynx installed. The return value is a list with names 
corresponding to the header titles and values being the values. It looks 
for a : as the title: value separator, and anything that doesnt have a : 
is just added verbatim unnamed.

  For example, how big is the R logo on the home page?

 > head.download("http://www.r-project.org/Rlogo.jpg")$"Content-Length"
[1] " 8793"

  That's bytes. Yes I know its character! I dont think web servers are 
under any obligation to provide accurate Content-length values. Many 
dynamic web servers have pages that change length every time. This will 
also not for for ftp:// URLs or local file:// URLs (or gopher:// URLs?).

  Perhaps HEAD-getting functionality can be put in the next release of 
R? It would probably have a better "name: value -> named list" routine 
than the one I just hacked up in two minutes above. Oops. Shame.

Baz



From ligges at statistik.uni-dortmund.de  Tue Feb  4 17:32:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue Feb  4 17:32:03 2003
Subject: [R] Background color of plot
In-Reply-To: <Pine.GSO.4.32.0302041308350.15551-100000@goiana>
References: <Pine.GSO.4.32.0302041308350.15551-100000@goiana>
Message-ID: <3E3FEB0C.4090603@statistik.uni-dortmund.de>

Patricia Maforte dos Santos wrote:
> I'm using the parameters "mfrow" and "mfg" to display some graphics(plots)
> at the same time. Although, because of the parameter "mfg", the parameter
> "bg" don?t change the background color.
> 
> What can I do to solve this?
> 
> 
> Here is the code I'm using...
> 
> ...
>      i <- 1
>      for(j in 1:4){
>          for(k in 1:2){
>                      limiares <- tabLimiar(arrayMetricas[,i])
>                      op <- par(mfrow=c(4,2),pty="s")
>                      par(mfg=c(j,k))

Set it in par() as in the following example:

  par(bg="green", mfrow=c(2, 1))
  plot(1:10)
  plot(1:10)

Uwe Ligges


>                      plot(limiares,main=a[i],ylab="frequencia",xlab="limiares",bg="white",col="green",col.main="seagreen",type="b")
>                      box(which="figure",lty="solid",col="white")
>                      par(op)
>                      i <- i+1
>                      if(i == ncol(arrayMetricas))
>                         break
>          }
>      }
> ...
> 
> 
> Patricia.
> 
> ----------------------------------
> Patr?cia Maforte dos Santos
> Centro de Informatica
> Universidade Federal de Pernambuco
> Recife/PE - Brasil
> ----------------------------------



From kent at darwin.eeb.uconn.edu  Tue Feb  4 17:44:06 2003
From: kent at darwin.eeb.uconn.edu (Kent Holsinger)
Date: Tue Feb  4 17:44:06 2003
Subject: [R] Help with NLME
Message-ID: <HFEOICEAHLOEAPPHMCOMMEOOCIAA.kent@darwin.eeb.uconn.edu>

I am relatively new to NLME, so the solution to the problem I describe here
may be obvious. But I've spent several days trying to get the right syntax
to formulate random effects for this model appropriately. The full model is:

  nlme(a ~ a.mitscherlich(a.qe, a.max, lcp, light),
       data=light,
       fixed = a.max + a.qe + lcp ~ trt,
       random = a.max + a.qe + lcp ~ 1 | bench/line,
       start = list(fixed=c(17.4305, 0.182444, 0.00928341, -0.00057221,
                            44.8384, 8.67678)),
       method="ML", verbose=T,
       control = nlmeControl(maxIter=250, msMaxIter=200, pnlsMaxIter=20,
                             gradHess=TRUE, returnObject=TRUE, niterEM=100))

What I'd like to do is to compare reduced models with something like

       random = list(a.max ~ 1 | bench, a.qe + lcp ~ 1 | bench/line)

i.e., to drop the nested term on each of the coefficients one by one so that
I can do and anova() to compare the models.

       random = a.max + a.qe +lcp ~ 1 | bench

works fine, but I can't figure out how to drop nested terms from only some
of the coefficients.

Any help (including pointers to appropriate pages in Pinheiro and Bates)
will be much appreciated.

Thanks.

Kent

--
Kent E. Holsinger                kent at darwin.eeb.uconn.edu
                                 http://darwin.eeb.uconn.edu
-- Department of Ecology & Evolutionary Biology
-- University of Connecticut, U-3043
-- Storrs, CT   06269-3043



From tlumley at u.washington.edu  Tue Feb  4 17:47:35 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Feb  4 17:47:35 2003
Subject: [R] downloaf.file
In-Reply-To: <3E3FE8E4.9030205@lancaster.ac.uk>
Message-ID: <Pine.A41.4.44.0302040842170.52616-100000@homer38.u.washington.edu>

On Tue, 4 Feb 2003, Barry Rowlingson wrote:
>
>   That's bytes. Yes I know its character! I dont think web servers are
> under any obligation to provide accurate Content-length values. Many
> dynamic web servers have pages that change length every time. This will
> also not for for ftp:// URLs or local file:// URLs (or gopher:// URLs?).
>

The HTTP protocol says that a content length SHOULD be provided and MUST
be accurate if it is provided.

	-thomas



From morrct at andrew.cmu.edu  Tue Feb  4 17:51:06 2003
From: morrct at andrew.cmu.edu (Mark G Orr)
Date: Tue Feb  4 17:51:06 2003
Subject: [R] SORTING Arrays by index value
Message-ID: <Pine.LNX.4.44L-027.0302041139180.7674-100000@unix47.andrew.cmu.edu>

Hello, I'm somewhat new to R.  I've searched the archive for the last year
and tried to consult the manual pages for the following problem, but did
not find an answer.

I want to sort an array by the index values.  Here is the array

>acc.gp.bl.wtmn
        Gp17       Gp4
1  0.5703125 0.6406250
10 0.7812500 0.7109375
11 0.8046875 0.7343750
12 0.8359375 0.7890625
13 0.8515625 0.7109375
14 0.8281250 0.7343750
15 0.8671875 0.7812500
16 0.8125000 0.7578125
17 0.7734375 0.7500000
18 0.8000000 0.7800000
19 0.8700000 0.7300000
2  0.8046875 0.7265625
20 0.8300000 0.7400000
21 0.7500000 0.8000000
22 0.7700000 0.7600000
23 0.8200000 0.7800000
24 0.7600000 0.7400000
25 0.8100000 0.8000000
3  0.7578125 0.7812500
4  0.8203125 0.7890625
5  0.7890625 0.7421875
6  0.7265625 0.7812500
7  0.8125000 0.7421875
8  0.8515625 0.7265625
9  0.8203125 0.6953125

My question is:  How do I sort by the first index (the values are 1:25)
without losing the associated values per index value for the two
columns(Gp17 and Gp4).  I want ascending order (1:25) of the index values.

Thank you in advance.

-Mark Orr



Postdoctoral Fellow
Psychology Dept.
Carnegie Mellon Univ.
Pittsburgh, PA 15213



From ripley at stats.ox.ac.uk  Tue Feb  4 17:58:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb  4 17:58:02 2003
Subject: [R] downloaf.file
In-Reply-To: <Pine.A41.4.44.0302040842170.52616-100000@homer38.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0302041651550.826-100000@gannet.stats>

On Tue, 4 Feb 2003, Thomas Lumley wrote:

> On Tue, 4 Feb 2003, Barry Rowlingson wrote:
> >
> >   That's bytes. Yes I know its character! I dont think web servers are
> > under any obligation to provide accurate Content-length values. Many
> > dynamic web servers have pages that change length every time. This will
> > also not for for ftp:// URLs or local file:// URLs (or gopher:// URLs?).
> >
> 
> The HTTP protocol says that a content length SHOULD be provided and MUST
> be accurate if it is provided.

Most proxies of my acquaintance will report unknown unless they are asked
to actually get the file or have it already cached.  Further, the IE 
internals used under Windows with --internet2 usually seems to get the 
wrong length (far too short) when talking to a proxy.

Why is this of interest: there are lots of internet download tools 
available apart from R?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb  4 18:15:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb  4 18:15:03 2003
Subject: [R] SORTING Arrays by index value
In-Reply-To: <Pine.LNX.4.44L-027.0302041139180.7674-100000@unix47.andrew.cmu.edu>
Message-ID: <Pine.LNX.4.44.0302041710120.1332-100000@gannet.stats>

acc.gp.bl.wtmn[sort.list(row.names(acc.gp.bl.wtmn)), ]

I am not clear how you missed order/sort.list, which have examples like 
this.  It's referenced off ?sort.  Indeed, sort() can be used too.

On Tue, 4 Feb 2003, Mark G Orr wrote:

> Hello, I'm somewhat new to R.  I've searched the archive for the last year
> and tried to consult the manual pages for the following problem, but did
> not find an answer.
> 
> I want to sort an array by the index values.  Here is the array
> 
> >acc.gp.bl.wtmn
>         Gp17       Gp4
> 1  0.5703125 0.6406250
> 10 0.7812500 0.7109375
> 11 0.8046875 0.7343750
> 12 0.8359375 0.7890625
> 13 0.8515625 0.7109375
> 14 0.8281250 0.7343750
> 15 0.8671875 0.7812500
> 16 0.8125000 0.7578125
> 17 0.7734375 0.7500000
> 18 0.8000000 0.7800000
> 19 0.8700000 0.7300000
> 2  0.8046875 0.7265625
> 20 0.8300000 0.7400000
> 21 0.7500000 0.8000000
> 22 0.7700000 0.7600000
> 23 0.8200000 0.7800000
> 24 0.7600000 0.7400000
> 25 0.8100000 0.8000000
> 3  0.7578125 0.7812500
> 4  0.8203125 0.7890625
> 5  0.7890625 0.7421875
> 6  0.7265625 0.7812500
> 7  0.8125000 0.7421875
> 8  0.8515625 0.7265625
> 9  0.8203125 0.6953125
> 
> My question is:  How do I sort by the first index (the values are 1:25)
> without losing the associated values per index value for the two
> columns(Gp17 and Gp4).  I want ascending order (1:25) of the index values.

I think the `first column' is the row names.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kjetil at entelnet.bo  Tue Feb  4 18:19:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Tue Feb  4 18:19:03 2003
Subject: [R] test for two samples
In-Reply-To: <3E40222C.9050802@host.sk>
Message-ID: <3E3FBCDD.1362.7F306C@localhost>

On 4 Feb 2003 at 15:27, Rado Bonk wrote:

You should really give more details, i.e. which model
did you fit? If it is a linear model with intercept, the residuals
theoretically have sum zero, and for a non-linear model the
sum should be close to zero. Comparing means of residuals
doesn't seem to make much sense.

Kjetil Halvorsen

> Hi R-users,
> 
> My question is more methodological one, rather than technical.
> 
> I have to samples representing residuals based on two measurements 
> techniques (resid1,resid2; n=69). I need to compare two samples, to 
> reject one technique (the worse one), and to keep the one which gave 
> lower residuals (better one). What to look for? What should I analyse? 
> Means, variance, std. deviations?
> 
> Based on preliminary EDA:
> 
> mean_resid1 < mean_resid2	#I would reject resid2 technique
> stdev_resid1 > stdev_resid2	#I would reject resid1 technique
> var_resid1 > var_resid2		#I would reject resid1 technique
> 
> Based on means I would reject resid2 technique, but based on analyses of 
> stdev. and variance I would reject resid1 technique.
> 
> How to deal with that problem? What is proper statist. atrribute to look 
> for? Should I use t.test()?
> 
> Best regards,
> 
> Rado Bonk
> 
> -- 
> Radoslav Bonk M.S.
> Dept. of Physical Geography and Geoecology
> Faculty of Sciences, Comenius University
> Mlynska Dolina 842 15, Bratislava, SLOVAKIA
> tel: +421 905 968 127 e-mail: rbonk at host.sk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Tue Feb  4 18:22:08 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Feb  4 18:22:08 2003
Subject: [R] SORTING Arrays by index value
In-Reply-To: <Pine.LNX.4.44L-027.0302041139180.7674-100000@unix47.andrew.cmu.edu>
Message-ID: <Pine.A41.4.44.0302040915410.52616-100000@homer38.u.washington.edu>

On Tue, 4 Feb 2003, Mark G Orr wrote:

> My question is:  How do I sort by the first index (the values are 1:25)
> without losing the associated values per index value for the two
> columns(Gp17 and Gp4).  I want ascending order (1:25) of the index values.
>

order()

	-thomas



From baron at cattell.psych.upenn.edu  Tue Feb  4 18:26:04 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue Feb  4 18:26:04 2003
Subject: [R] SORTING Arrays by index value
In-Reply-To: <Pine.LNX.4.44L-027.0302041139180.7674-100000@unix47.andrew.cmu.edu>; from morrct@andrew.cmu.edu on Tue, Feb 04, 2003 at 11:46:38AM -0500
References: <Pine.LNX.4.44L-027.0302041139180.7674-100000@unix47.andrew.cmu.edu>
Message-ID: <20030204121912.A2060@cattell.psych.upenn.edu>

On 02/04/03 11:46, Mark G Orr wrote:
>Hello, I'm somewhat new to R.  I've searched the archive for the last year
>and tried to consult the manual pages for the following problem, but did
>not find an answer.
>
>I want to sort an array by the index values.  Here is the array

Looks like a matrix (which is, I guess, a type of array).

To sort by the first column, try

acc.gp.bl.wtmn[order(acc.gp.bl.wtmn[,1],]

>>acc.gp.bl.wtmn
>        Gp17       Gp4
>1  0.5703125 0.6406250
>10 0.7812500 0.7109375
>11 0.8046875 0.7343750
>12 0.8359375 0.7890625
>13 0.8515625 0.7109375
>14 0.8281250 0.7343750
>15 0.8671875 0.7812500
>16 0.8125000 0.7578125
>17 0.7734375 0.7500000
>18 0.8000000 0.7800000
>19 0.8700000 0.7300000
>2  0.8046875 0.7265625
>20 0.8300000 0.7400000
>21 0.7500000 0.8000000
>22 0.7700000 0.7600000
>23 0.8200000 0.7800000
>24 0.7600000 0.7400000
>25 0.8100000 0.8000000
>3  0.7578125 0.7812500
>4  0.8203125 0.7890625
>5  0.7890625 0.7421875
>6  0.7265625 0.7812500
>7  0.8125000 0.7421875
>8  0.8515625 0.7265625
>9  0.8203125 0.6953125
>
>My question is:  How do I sort by the first index (the values are 1:25)
>without losing the associated values per index value for the two
>columns(Gp17 and Gp4).  I want ascending order (1:25) of the index values.
>
>Thank you in advance.
>
>-Mark Orr
>
>
>
>Postdoctoral Fellow
>Psychology Dept.
>Carnegie Mellon Univ.
>Pittsburgh, PA 15213
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
R page:               http://finzi.psych.upenn.edu/



From tplate at blackmesacapital.com  Tue Feb  4 18:29:12 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue Feb  4 18:29:12 2003
Subject: [R] SORTING Arrays by index value
In-Reply-To: <Pine.LNX.4.44L-027.0302041139180.7674-100000@unix47.andrew
 .cmu.edu>
Message-ID: <5.1.0.14.2.20030204101440.04647008@mailhost.blackmesacapital.com>

This should do it:

 > acc.gp.bl.wtmn[order(as.numeric(row.names(acc.gp.bl.wtmn))),]

(This is not completely straightforward because in a dataframe, row names 
are almost always stored as character vectors, which means that you need to 
convert the row names to numeric values before calling order())

-- Tony Plate

At Tuesday 11:46 AM 2/4/2003 -0500, Mark G Orr wrote:
>Hello, I'm somewhat new to R.  I've searched the archive for the last year
>and tried to consult the manual pages for the following problem, but did
>not find an answer.
>
>I want to sort an array by the index values.  Here is the array
>
> >acc.gp.bl.wtmn
>         Gp17       Gp4
>1  0.5703125 0.6406250
>10 0.7812500 0.7109375
>11 0.8046875 0.7343750
>12 0.8359375 0.7890625
>13 0.8515625 0.7109375
>14 0.8281250 0.7343750
>15 0.8671875 0.7812500
>16 0.8125000 0.7578125
>17 0.7734375 0.7500000
>18 0.8000000 0.7800000
>19 0.8700000 0.7300000
>2  0.8046875 0.7265625
>20 0.8300000 0.7400000
>21 0.7500000 0.8000000
>22 0.7700000 0.7600000
>23 0.8200000 0.7800000
>24 0.7600000 0.7400000
>25 0.8100000 0.8000000
>3  0.7578125 0.7812500
>4  0.8203125 0.7890625
>5  0.7890625 0.7421875
>6  0.7265625 0.7812500
>7  0.8125000 0.7421875
>8  0.8515625 0.7265625
>9  0.8203125 0.6953125
>
>My question is:  How do I sort by the first index (the values are 1:25)
>without losing the associated values per index value for the two
>columns(Gp17 and Gp4).  I want ascending order (1:25) of the index values.
>
>Thank you in advance.
>
>-Mark Orr
>
>
>
>Postdoctoral Fellow
>Psychology Dept.
>Carnegie Mellon Univ.
>Pittsburgh, PA 15213
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jfox at mcmail.cis.mcmaster.ca  Tue Feb  4 18:33:04 2003
From: jfox at mcmail.cis.mcmaster.ca (John Fox)
Date: Tue Feb  4 18:33:04 2003
Subject: [R] SORTING Arrays by index values
In-Reply-To: <Pine.LNX.4.44L-027.0302041139180.7674-100000@unix47.andrew.cmu.edu>
Message-ID: <Pine.SOL.4.33.0302041226500.15568-100000@mcmail.cis.mcmaster.ca>

Dear Mark,

If I understand properly what you want, then one way to do it is
acc.gp.bl.wtmn[order(as.numeric(row.names(acc.gp.bl.wtmn))),]

(Note that the rows are currently ordered by character value.)

I hope that this helps,
 John

On Tue, 4 Feb 2003, Mark G Orr wrote:

> Hello, I'm somewhat new to R.  I've searched the archive for the last year
> and tried to consult the manual pages for the following problem, but did
> not find an answer.
>
> I want to sort an array by the index values.  Here is the array
>
> >acc.gp.bl.wtmn
>         Gp17       Gp4
> 1  0.5703125 0.6406250
> 10 0.7812500 0.7109375
> 11 0.8046875 0.7343750
> 12 0.8359375 0.7890625
> 13 0.8515625 0.7109375
> 14 0.8281250 0.7343750
> 15 0.8671875 0.7812500
> 16 0.8125000 0.7578125
> 17 0.7734375 0.7500000
> 18 0.8000000 0.7800000
> 19 0.8700000 0.7300000
> 2  0.8046875 0.7265625
> 20 0.8300000 0.7400000
> 21 0.7500000 0.8000000
> 22 0.7700000 0.7600000
> 23 0.8200000 0.7800000
> 24 0.7600000 0.7400000
> 25 0.8100000 0.8000000
> 3  0.7578125 0.7812500
> 4  0.8203125 0.7890625
> 5  0.7890625 0.7421875
> 6  0.7265625 0.7812500
> 7  0.8125000 0.7421875
> 8  0.8515625 0.7265625
> 9  0.8203125 0.6953125
>
> My question is:  How do I sort by the first index (the values are 1:25)
> without losing the associated values per index value for the two
> columns(Gp17 and Gp4).  I want ascending order (1:25) of the index values.
>
> Thank you in advance.
>
> -Mark Orr
>
>
>
> Postdoctoral Fellow
> Psychology Dept.
> Carnegie Mellon Univ.
> Pittsburgh, PA 15213
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From lm.silva at sapo.pt  Tue Feb  4 19:49:05 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Tue Feb  4 19:49:05 2003
Subject: [R] forecast
Message-ID: <1044384504.3e400af8a2236@webmail.sapo.pt>

Dear helpers

I have a 55 observations of a time series that I want to make 
predictions 17 steps ahead. I read that it is possible to use 
neural networks to do that. How can I do that with R?

Luis
--
Kit SAPO.ADSL.PT Apenas 50 ?.
Adira j? em http://www.sapo.pt/kitadsl



From hennig at stat.math.ethz.ch  Tue Feb  4 20:25:03 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Tue Feb  4 20:25:03 2003
Subject: [R] correspondance analysis & clustering
In-Reply-To: <F110QTs7wIBypO9QtWj0000d20e@hotmail.com>
Message-ID: <Pine.LNX.4.44.0302042021580.2345-100000@florence>

Hi,

as far as I remember, no answer until now...?
Please tell us exactly what you have done, including data, if possible.
Without this information no help is possible.

Christian

On Mon, 3 Feb 2003, Vincent Stoliaroff wrote:

> 
> 
> Hi
> 
> 1) I am using the function ca() of the package multiv to make a 
> correspondance analysis of a matrix of categorical datas which are 
> numericaly coded. I would like to be sure that it is considered as a matrix 
> of categorical datas and not numerical. I cannot find any explicit mention 
> of that in the help file for this function
> 
> 2) I would like to take the resulting matrix rproj to do a clustering.
> I use hierclust() and partition() of the package multiv
> 
> regarding hierclust()
> when I use the method number 1 i get this error:
> Error in hclust(a, method) : invalid clustering method
> 
> when I change the number of the method I get
> Error in pmatch(x, table, duplicates.ok) :
>         argument is not of mode character
> 
> 
> As for the partition() function, I also have some troubles. It seems I 
> should mention a vector of clustered centers for initiating the iterative 
> optimization process. But I do not know where to enter it.
> I get the following message
> Error in matrix(0, ng, m) : non-numeric matrix extent
> 
> Has anybody ever encountered those problems?
> Thanks a lot
> 
> 
> _________________________________________________________________
> MSN Search, le moteur de recherche qui pense comme vous !
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de



From stormplot at hotmail.com  Tue Feb  4 21:03:02 2003
From: stormplot at hotmail.com (Jason Fisher)
Date: Tue Feb  4 21:03:02 2003
Subject: [R] UltraEdit syntax highlighting
Message-ID: <F5Vf2grCr8tU3HWJl0g00010669@hotmail.com>

Hello everyone...

I was curious if anyone had an UltraEdit (syntax highlighting) wordfile for 
R.  The UltraEdit webpage previously made available an R wordfile on their 
webpage, however, it is no longer posted.

Thanks in advance...

Jason

***************************************
Jason C. Fisher
UCLA Graduate Student
Civil & Environmental Engineering Dept.
5731 Boelter Hall
Box 951593
Los Angeles, CA 90095-1593
Phone Number: (310) 825-2292
Email: stormplot at hotmail.com
***************************************



From f0z6305 at labs.tamu.edu  Tue Feb  4 21:18:02 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue Feb  4 21:18:02 2003
Subject: [R] About Cumulant Generating Functions
Message-ID: <002601c2cc8a$6ed87d70$8bd75ba5@IE.TAMU.EDU>

Hey, all

Can anybody tell me the definition or form of 
cumulant generating function for a series
of random variables x1, x2, ....?

I know the moment generationg function
is E[exp(tx)], and want to know the relationships
bw cumulants and moments.

Thanks.

Fred



From chrysopa at insecta.ufv.br  Tue Feb  4 22:43:03 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Tue Feb  4 22:43:03 2003
Subject: [R] testing slope
Message-ID: <200302041750.46124.chrysopa@insecta.ufv.br>

Hi all,

I try to test a linear slope using offset.

I have:

> m2 <- glm(Y~X*V)
> summary(m2)

Call:
glm(formula = Y ~ X * V)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.01688  -0.56028   0.05224   0.53213   3.60216  

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   1.3673     0.8476   1.613 0.119788    
X             4.0235     0.1366  29.453  < 2e-16 ***
Vn2           0.9683     1.1987   0.808 0.427131    
Vn3           4.6043     1.1987   3.841 0.000787 ***
X:Vn2         4.1108     0.1932  21.279  < 2e-16 ***
X:Vn3        -4.0069     0.1932 -20.740  < 2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

(Dispersion parameter for gaussian family taken to be 1.53955)

    Null deviance: 15303.977  on 29  degrees of freedom
Residual deviance:    36.949  on 24  degrees of freedom
AIC: 105.39

Number of Fisher Scoring iterations: 2

It is clear that X slope is diferent of Zero.
X             4.0235     0.1366  29.453  < 2e-16 ***

It is too clear that X:Vn2's slope is diferent of X's slope and diferent of 
Zero, because is greater than X'slope.
X:Vn2         4.1108     0.1932  21.279  < 2e-16 ***

But, the X:Vn3' slope is different of X'slope, but not necessarily different 
of Zero.

How I make to introduce this parameter in a new model for test? An offset only 
with Vn3 slope???

I try:

m2 <- glm(Y~V*offset(0*X))
m2 <- glm(Y~X*V+V*offset(0*X))
m2 <- glm(Y~V:X+V*offset(0*X))

but neither work :((

Thanks for all.
Ronaldo
-- 
If you live in a country run by committee, be on the committee.
		-- Graham Summer
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Gnu/Debian Woody D+:) | Lxuser#: 205366



From debene at unimc.it  Wed Feb  5 01:21:03 2003
From: debene at unimc.it (Luca De Benedictis)
Date: Wed Feb  5 01:21:03 2003
Subject: [R] rearranging rows
Message-ID: <3E40594F.28A2DFFC@unimc.it>

Dear all,
I am working with a matrix structured as follows

                    Factor 1    Factor2  ...
Country 1
Country 1
Country 2
Country 2
...

Country N
Country N

and I need to rearrange it according to the following scheme


                    Factor 1    Factor2  ...
Country 2
Country 2
Country N
Country N
...

Country 1
Country 1

where countries are ordered accordingly to the average value of factor 1

correspondent to each country.
What is the easy way of doing it?

Many thanks in advance,

Luca



From kjetil at entelnet.bo  Wed Feb  5 03:45:04 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed Feb  5 03:45:04 2003
Subject: [R] rearranging rows
In-Reply-To: <3E40594F.28A2DFFC@unimc.it>
Message-ID: <3E40424F.4382.1E5CE3@localhost>

On 5 Feb 2003 at 1:22, Luca De Benedictis wrote:

Well, you want to rearrange according to the mean of factor 1. 
Factors are catecorical variables, and doesn't have means, so
I assume you really want to say a numerical variable.

Assuming your data is in a data frame with "Country 1" etc levels of
a factor  Country  :

attach(your.data.frame)

Something like
means <- tapply(Factor1, Country, mean)
s <- sort(means)
na <- names(s)
ns <- vector(length=length(s))
for (i in 1:n) {
    ns[i] <- sum(Country==na[i])
}
names <- rep(na, ns)
your.data.frame <- your.data.frame[names,]

This is assuming that the different countries are contiguous
in the data frame, and is not tested. Surely somebody 
have a nicer solution.

Kjetil Halvorsen



> 
> Dear all,
> I am working with a matrix structured as follows
> 
>                     Factor 1    Factor2  ...
> Country 1
> Country 1
> Country 2
> Country 2
> ...
> 
> Country N
> Country N
> 
> and I need to rearrange it according to the following scheme
> 
> 
>                     Factor 1    Factor2  ...
> Country 2
> Country 2
> Country N
> Country N
> ...
> 
> Country 1
> Country 1
> 
> where countries are ordered accordingly to the average value of factor 1
> 
> correspondent to each country.
> What is the easy way of doing it?
> 
> Many thanks in advance,
> 
> Luca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From vito.muggeo at giustizia.it  Wed Feb  5 10:01:02 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Wed Feb  5 10:01:02 2003
Subject: [R] testing slope
References: <200302041750.46124.chrysopa@insecta.ufv.br>
Message-ID: <004401c2ccf4$691eade0$5c13070a@it.giustizia.it>

Hi,
in order to avoid the parameter of x:v3 to be estimated, you can
re-formulate the model.

You fitted
y~1+x+v2+v3+x:v2+x:v3
with 6 df

Now you would fit
y~0+v1+v2+v3+x:v1+x:v2)
with 5 df as x:v3 is not included in the model, i.e. the parameter x:v3 is
constrained to be zero.
best,
vito

A toy example is following:


x<-1:100 #explanatory continuous variable
 f<-factor(rep(1:3,length=100)) #categorical variable
f<-model.matrix(~f-1)
xx<-f*x
X<-cbind(f,xx) #design matrix
colnames(X)[4:6]<-c("xf1","xf2","xf3")
b<-c(2,5,-3,-2,3,0) #parameters
y<-X%*%b+rnorm(100,0,1) #response
m0<-lm(y~0+X) #full model
m1<-lm(y~0+X[,-6]) #reduced model
anova(m0,m1) #test for nonnull slope


----- Original Message -----
From: "Ronaldo Reis Jr." <chrysopa at insecta.ufv.br>
To: "R-Help" <r-help at stat.math.ethz.ch>
Sent: Tuesday, February 04, 2003 8:50 PM
Subject: [R] testing slope


Hi all,

I try to test a linear slope using offset.

I have:

> m2 <- glm(Y~X*V)
> summary(m2)

Call:
glm(formula = Y ~ X * V)

Deviance Residuals:
     Min        1Q    Median        3Q       Max
-2.01688  -0.56028   0.05224   0.53213   3.60216

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   1.3673     0.8476   1.613 0.119788
X             4.0235     0.1366  29.453  < 2e-16 ***
Vn2           0.9683     1.1987   0.808 0.427131
Vn3           4.6043     1.1987   3.841 0.000787 ***
X:Vn2         4.1108     0.1932  21.279  < 2e-16 ***
X:Vn3        -4.0069     0.1932 -20.740  < 2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

(Dispersion parameter for gaussian family taken to be 1.53955)

    Null deviance: 15303.977  on 29  degrees of freedom
Residual deviance:    36.949  on 24  degrees of freedom
AIC: 105.39

Number of Fisher Scoring iterations: 2

It is clear that X slope is diferent of Zero.
X             4.0235     0.1366  29.453  < 2e-16 ***

It is too clear that X:Vn2's slope is diferent of X's slope and diferent of
Zero, because is greater than X'slope.
X:Vn2         4.1108     0.1932  21.279  < 2e-16 ***

But, the X:Vn3' slope is different of X'slope, but not necessarily different
of Zero.

How I make to introduce this parameter in a new model for test? An offset
only
with Vn3 slope???

I try:

m2 <- glm(Y~V*offset(0*X))
m2 <- glm(Y~X*V+V*offset(0*X))
m2 <- glm(Y~V:X+V*offset(0*X))

but neither work :((

Thanks for all.
Ronaldo
--
If you live in a country run by committee, be on the committee.
-- Graham Summer
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Gnu/Debian Woody D+:) | Lxuser#: 205366

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From helgito at hi.is  Wed Feb  5 10:27:03 2003
From: helgito at hi.is (Helgi Tomasson)
Date: Wed Feb  5 10:27:03 2003
Subject: [R] big ps-files
Message-ID: <3E40D914.3BB7CC84@hi.is>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030205/ad675199/attachment.pl

From ripley at stats.ox.ac.uk  Wed Feb  5 10:55:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb  5 10:55:03 2003
Subject: [R] big ps-files
In-Reply-To: <3E40D914.3BB7CC84@hi.is>
Message-ID: <Pine.LNX.4.44.0302050945040.23524-100000@gannet.stats>

Why does it matter?  Surely the time taken to read the file or send it to
the printer is not important, and the actual files compress well for
storage (about a factor of 6 with bzip2 on the example I tried).

Which version of S-PLUS, which has had two completely separate postscript
drivers?  The AT&T S version was written in the 1980s when this did matter
and is somewhat optimized for compact code.

I've just done a quick comparison on the MASS4 ch05 script using Linux.  
S-PLUS 6.1 produces 212Kb, R 1.6.2 produces 596Kb.  These compressed to 48
and 108Kb respectively.

On Wed, 5 Feb 2003, Helgi Tomasson wrote:

> I have been using R for many years and I am very happy with it.  One
> thing puzzles me.
> Graphic postscript files tend to become quite big, much bigger than
> corresponding splus
> postscript files. Does anybody have a hint  to avoid this?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From SAULEAUEA at ch-mulhouse.fr  Wed Feb  5 12:19:03 2003
From: SAULEAUEA at ch-mulhouse.fr (=?iso-8859-1?Q?SAULEAU_Erik-Andr=E9?=)
Date: Wed Feb  5 12:19:03 2003
Subject: [R] tcltk installation problem
Message-ID: <1B849FE29A3ED21198A40008C72853B301C4FDA4@MESSAGERIE>

Dear all,

I want to use GraspeR (on R 1.6.0) and have to install tcltk library.  When
I try to do this, I get back this error message:

Error in firstlib(which.lib.loc, package) : 
        TCL_LIBRARY is not set
Error in library(pkg, character.only = TRUE) : 
        .First.lib failed

But I have a tcl/tk package (Active TCL 8.4.1.0) correctly install on my PC
(Win95) and in the autoexec.bat the path for "bin" and "lib" . So where am I
wrong??

Thanks for advance. With very best regards,

Erik.

============================================
Erik-Andr? SAULEAU

SEAIM
H?pital du Hasenrain
BP 1070
87, Avenue de Altkirch
68051 MULHOUSE C?dex

Tel: 03-89-64-79-95
Fax: 03-89-64-79-71
M?l: sauleauea at ch-mulhouse.fr
Web: http://www.ch-mulhouse.fr
============================================




************************************************************************************
Afin d'?viter toute propagation de virus informatique, et en compl?ment des dispositifs en place, ce message (et ses pi?ces jointes s'il y en a) a ?t? automatiquement analys? par un antivirus de messagerie. 
***********************************************************************************



From AlessandroSemeria at cramont.it  Wed Feb  5 12:33:05 2003
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Wed Feb  5 12:33:05 2003
Subject: [R] tcltk installation problem
Message-ID: <OFBA589DC0.013FF679-ONC1256CC4.003F762D@tomware.it>

You have to install the previous version of Active Tcl/Tk :  8.3.5.0.

A.S.


----------------------------

|------------------------------------+------------------------------------|
|Alessandro Semeria                  |Tel. +39 544 536811                 |
|------------------------------------+------------------------------------|
|Models and Simulation Laboratory    |Fax. +39 544 538663                 |
|------------------------------------+------------------------------------|
|The Environment Research Center -   |                                    |
|Montecatini (Edison Group),    Via  |                                    |
|Ciro Menotti 48,                    |E-mail: asemeria at cramont.it         |
|48023 Marina di Ravenna (RA), Italy |                                    |
|------------------------------------+------------------------------------|



From ligges at statistik.uni-dortmund.de  Wed Feb  5 13:03:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Feb  5 13:03:03 2003
Subject: [R] tcltk installation problem
In-Reply-To: <1B849FE29A3ED21198A40008C72853B301C4FDA4@MESSAGERIE>
References: <1B849FE29A3ED21198A40008C72853B301C4FDA4@MESSAGERIE>
Message-ID: <3E40FD5E.5090405@statistik.uni-dortmund.de>

SAULEAU Erik-Andr? wrote:
> Dear all,
> 
> I want to use GraspeR (on R 1.6.0) and have to install tcltk library.  When
> I try to do this, I get back this error message:
> 
> Error in firstlib(which.lib.loc, package) : 
>         TCL_LIBRARY is not set
> Error in library(pkg, character.only = TRUE) : 
>         .First.lib failed
> 
> But I have a tcl/tk package (Active TCL 8.4.1.0) correctly install on my PC
> (Win95) and in the autoexec.bat the path for "bin" and "lib" . So where am I
> wrong??
> 
> Thanks for advance. With very best regards,
> 
> Erik

See the R for Windows FAQ 3.6 "Package TclTk does not work."
(I guess you are on Windows)

Uwe Ligges



From ripley at stats.ox.ac.uk  Wed Feb  5 13:09:43 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb  5 13:09:43 2003
Subject: [R] tcltk installation problem
In-Reply-To: <1B849FE29A3ED21198A40008C72853B301C4FDA4@MESSAGERIE>
Message-ID: <Pine.LNX.4.44.0302051202240.23692-100000@gannet.stats>

Wrong version of tcl/tk: see the rw-FAQ.  You can build R-1.6.2 (but not 
earlier) and the packages to use 8.4.x, but you will have to do it 
yourself.

On Wed, 5 Feb 2003, SAULEAU Erik-Andr? wrote:

> Dear all,
> 
> I want to use GraspeR (on R 1.6.0) and have to install tcltk library.  When
> I try to do this, I get back this error message:
> 
> Error in firstlib(which.lib.loc, package) : 
>         TCL_LIBRARY is not set
> Error in library(pkg, character.only = TRUE) : 
>         .First.lib failed
> 
> But I have a tcl/tk package (Active TCL 8.4.1.0) correctly install on my PC
> (Win95) and in the autoexec.bat the path for "bin" and "lib" . So where am I
> wrong??

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From phgrosjean at sciviews.org  Wed Feb  5 13:20:03 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed Feb  5 13:20:03 2003
Subject: [R] UltraEdit syntax highlighting
In-Reply-To: <F5Vf2grCr8tU3HWJl0g00010669@hotmail.com>
Message-ID: <MABBLJDICACNFOLGIHJOAEGDDDAA.phgrosjean@sciviews.org>

Jason Fisher wrote:
>Hello everyone...

>I was curious if anyone had an UltraEdit (syntax highlighting) wordfile for
>R.  The UltraEdit webpage previously made available an R wordfile on their
>webpage, however, it is no longer posted.

I have just asked the UltraEdit webmaster, and he does not know why that
file disappeared. Anyway, he asked me to resubmit it... Does someone have
it?
Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



From andy_liaw at merck.com  Wed Feb  5 14:01:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Feb  5 14:01:03 2003
Subject: [R] barplot default colors
Message-ID: <3A822319EB35174CA3714066D590DCD534BC41@usrymx25.merck.com>

Dear R-help,

Can some one explain why barplot() uses changing colors in the bars by
default?  I should think that most of the time when people draw barplots,
they want the bars to be in the same color.  (At least that's what I'd
expect.  The first time I used barplot() in R, I was shocked to see the
colors.)  As an example, one example in ?layout draws a scatterplot with
histograms drawn on the margins.  The histograms were drawn by barplot(),
and, IMHO, look rather hideous in the colors.

Regards,
Andy

Andy I. Liaw, PhD
Biometrics Research          Phone: (732) 594-0820
Merck & Co., Inc.              Fax: (732) 594-1565
P.O. Box 2000, RY84-16            Rahway, NJ 07065
mailto:andy_liaw at merck.com



------------------------------------------------------------------------------



From humbertc at univ-mlv.fr  Wed Feb  5 14:06:04 2003
From: humbertc at univ-mlv.fr (Cyril Humbert)
Date: Wed Feb  5 14:06:04 2003
Subject: [R] big ps-files
In-Reply-To: <3E40D914.3BB7CC84@hi.is>; from helgito@hi.is on Wed, Feb 05, 2003 at 09:27:48AM +0000
References: <3E40D914.3BB7CC84@hi.is>
Message-ID: <20030205140405.A9564@borneo.univ-mlv.fr>

Helgi Tomasson wrote:
> To R-users
> 
> I have been using R for many years and I am very happy with it.  One
> thing puzzles me.
> Graphic postscript files tend to become quite big, much bigger than
> corresponding splus
> postscript files. Does anybody have a hint  to avoid this?
>
> best  regards
> 
> Helgi

If you are using Unix/Linux, the command `eps2eps' (ghostscript) 
can help to reduce the size of the eps files.

> 
> --
> Helgi Tomasson                                       FAX:  354-552-6806
> University of Iceland                                PHONE:354-525-4571
> Faculty of Economics and Business Administration     email:helgito at rhi.hi.is
> Oddi v/ Sturlugotu
> IS-101 Reykjavik
> ICELAND

-- 
Cyril



From ripley at stats.ox.ac.uk  Wed Feb  5 14:21:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb  5 14:21:04 2003
Subject: [R] big ps-files
In-Reply-To: <20030205140405.A9564@borneo.univ-mlv.fr>
Message-ID: <Pine.LNX.4.44.0302051312010.23732-100000@gannet.stats>

On Wed, 5 Feb 2003, Cyril Humbert wrote:

> Helgi Tomasson wrote:
> > 
> > I have been using R for many years and I am very happy with it.  One
> > thing puzzles me.
> > Graphic postscript files tend to become quite big, much bigger than
> > corresponding splus
> > postscript files. Does anybody have a hint  to avoid this?
> >
> If you are using Unix/Linux, the command `eps2eps' (ghostscript) 
> can help to reduce the size of the eps files.

It makes my example 50% bigger!  
Its man page says

       ps2ps uses gs(1) to convert PostScript(tm) file "input.ps"
       to simpler and (usually) faster PostScript in "output.ps".

so the intention is speed not size.

Two reasons that that postscript from S-PLUS 6 is smaller are

- it is less accurate, working to the nearest point (actually bp) whereas
R works to 1/100 point.
- it makes much more use of relative move operators.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Havard.Rue at math.ntnu.no  Wed Feb  5 14:32:03 2003
From: Havard.Rue at math.ntnu.no (Havard Rue)
Date: Wed Feb  5 14:32:03 2003
Subject: [R] R as a `script'
Message-ID: <1044451834.10726.32.camel@wotan.math.ntnu.no>

is there any way i can use R as a tool for scripts in unix, as 

wotan[hrue]$ cat example.R 
#!/usr/bin/R
x=1

havard

-- 
 Havard Rue
 Department of Mathematical Sciences
 Norwegian University of Science and Technology
 N-7491 Trondheim, Norway
 Voice: +47-7359-3533    URL  : http://www.math.ntnu.no/~hrue  
 Fax  : +47-7359-3524    Email: havard.rue at math.ntnu.no



From sway at tanox.com  Wed Feb  5 14:36:02 2003
From: sway at tanox.com (Shawn Way)
Date: Wed Feb  5 14:36:02 2003
Subject: [R] attr function
Message-ID: <2F3262756375D411B0CC00B0D049775DAFB2A4@exchange.tanox.com>

I've been trying unsuccessfully to extract the term labels from a model
frame using the attr function.

The code is as follows

a <- data.frame(col1=c(1,2,3,2,1,3),col2=c(2,4,7,6,4,3))
b <- model.frame(col2~col1,data=a)

Now the term.labels attribute is col1, but how do I get this from the b data
frame attributes?

Thanks in advance...


Shawn Way



From baron at cattell.psych.upenn.edu  Wed Feb  5 14:40:04 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Wed Feb  5 14:40:04 2003
Subject: [R] R as a `script'
In-Reply-To: <1044451834.10726.32.camel@wotan.math.ntnu.no>; from Havard.Rue@math.ntnu.no on Wed, Feb 05, 2003 at 02:30:34PM +0100
References: <1044451834.10726.32.camel@wotan.math.ntnu.no>
Message-ID: <20030205083858.A29900@cattell.psych.upenn.edu>

On 02/05/03 14:30, Havard Rue wrote:
>
>is there any way i can use R as a tool for scripts in unix, as 
>
>wotan[hrue]$ cat example.R 
>#!/usr/bin/R
>x=1
>
>havard

What I do - explained in the R man page - is

R < example.R > example.out

and I have found it useful (for some reason I can't recall) to
use the --vanilla option in these cases:

R --vanilla < example.R > example.out

And the last part (> example.out) is not needed if the script
itself contains commands for writing output.

I'm sure there is at least one other way to do it.

--
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From ripley at stats.ox.ac.uk  Wed Feb  5 14:46:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb  5 14:46:03 2003
Subject: [R] attr function
In-Reply-To: <2F3262756375D411B0CC00B0D049775DAFB2A4@exchange.tanox.com>
Message-ID: <Pine.LNX.4.44.0302051342580.24520-100000@gannet.stats>

attr(attr(b, "terms"), "term.labels")

works, as I would have expected.  This is part of the "terms" attribute, 
not of the model frame per se.

On Wed, 5 Feb 2003, Shawn Way wrote:

> 
> I've been trying unsuccessfully to extract the term labels from a model
> frame using the attr function.
> 
> The code is as follows
> 
> a <- data.frame(col1=c(1,2,3,2,1,3),col2=c(2,4,7,6,4,3))
> b <- model.frame(col2~col1,data=a)
> 
> Now the term.labels attribute is col1, but how do I get this from the b data
> frame attributes?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tord.snall at ebc.uu.se  Wed Feb  5 15:16:02 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Wed Feb  5 15:16:02 2003
Subject: [R] simplify a data frame
Message-ID: <3.0.6.32.20030205150804.00b1f370@mail.anst.uu.se>

Dear all,
For the past three hours I have tried simplify a data frame. I would be
really happy if someone could help solving this, I'm sure simple, problem.

I want to "aggregate" the data frame:

ObjektID	BalteNummer	Baltessegment
S.13	S.13.1		S.13.1.2
S.13	S.13.1		S.13.1.3
S.13	S.13.2		S.13.2.1
S.13	S.13.2		S.13.2.2
S.13	S.13.2		S.13.2.3
S.13	S.13.3		S.13.3.6
S.13	S.13.3		S.13.3.7
S.13	S.13.3		S.13.3.8
S.13	S.13.3		S.13.3.9


so that the results look likte this:


ObjektID	BalteNummer	
S.13	S.13.1
S.13	S.13.2
S.13	S.13.3

There are in fact many ObjektID.


Thanks in advance!


Sincerely
Tord

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From tord.snall at ebc.uu.se  Wed Feb  5 15:39:03 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Wed Feb  5 15:39:03 2003
Subject: [R] simplify a data frame
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BC43@usrymx25.merck.com>
Message-ID: <3.0.6.32.20030205153059.00a7c670@mail.anst.uu.se>

Prof Ripley and Andy Liaw,

Thanks for you quick replies! As always, I really appreciate it! 

They are exactly what I looked for, but unique() was new to me.


Tord




At 09:25 2003-02-05 -0500, you wrote:
>Is the following what you're looking for?
>
>> try.dat
>  ObjektID BalteNummer Baltessegment
>1     S.13      S.13.1      S.13.1.2
>2     S.13      S.13.1      S.13.1.3
>3     S.13      S.13.2      S.13.2.1
>4     S.13      S.13.2      S.13.2.2
>5     S.13      S.13.2      S.13.2.3
>6     S.13      S.13.3      S.13.3.6
>7     S.13      S.13.3      S.13.3.7
>8     S.13      S.13.3      S.13.3.8
>9     S.13      S.13.3      S.13.3.9
>> unique(try.dat[,-3])
>  ObjektID BalteNummer
>1     S.13      S.13.1
>3     S.13      S.13.2
>6     S.13      S.13.3
>
>
>Andy
>
>> -----Original Message-----
>> From: Tord Snall [mailto:tord.snall at ebc.uu.se]
>> Sent: Wednesday, February 05, 2003 9:08 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] simplify a data frame
>> 
>> 
>> Dear all,
>> For the past three hours I have tried simplify a data frame. 
>> I would be
>> really happy if someone could help solving this, I'm sure 
>> simple, problem.
>> 
>> I want to "aggregate" the data frame:
>> 
>> ObjektID	BalteNummer	Baltessegment
>> S.13	S.13.1		S.13.1.2
>> S.13	S.13.1		S.13.1.3
>> S.13	S.13.2		S.13.2.1
>> S.13	S.13.2		S.13.2.2
>> S.13	S.13.2		S.13.2.3
>> S.13	S.13.3		S.13.3.6
>> S.13	S.13.3		S.13.3.7
>> S.13	S.13.3		S.13.3.8
>> S.13	S.13.3		S.13.3.9
>> 
>> 
>> so that the results look likte this:
>> 
>> 
>> ObjektID	BalteNummer	
>> S.13	S.13.1
>> S.13	S.13.2
>> S.13	S.13.3
>> 
>> There are in fact many ObjektID.
>> 
>> 
>> Thanks in advance!
>> 
>> 
>> Sincerely
>> Tord
>> 
>> --------------------------------------------------------------
>> ---------
>> Tord Sn?ll
>> Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
>> Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala 
>> University
>> Villav?gen 14			
>> SE-752 36 Uppsala, Sweden
>> Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
>> Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
>> Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
>> E-mail: Tord.Snall at ebc.uu.se
>> Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
>> --------------------------------------------------------------
>> ----------
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> 
>
>---------------------------------------------------------------------------
---
>Notice: This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
may be confidential, proprietary copyrighted and/or legally privileged, and
is intended solely for the use of the individual or entity named on this
message. If you are not the intended recipient, and have received this
message in error, please immediately return this by e-mail and then delete it.
>
>===========================================================================
===
>
>

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From Bernhard.Pfaff at drkw.com  Wed Feb  5 15:56:06 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Wed Feb  5 15:56:06 2003
Subject: [R] Package: cluster -- plot.partition() change title: main=""
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB90047301C9@ibfftce505.is.de.dresdnerkb.com>

Dear R-list members,

I am using the cluster package and by the generation of plot.partition I ran
into the problem that an alternative title overlaps the default title.

> plot.partition(clara.14,which.plot=2,stand=TRUE, main="Silhouette plot of
14 clusters")

The manual states that all optional arguments for clusplot.default may also
be supplied to plot.partition(). Altering the title in clusplot() works.
Question: What am I doing wrong and what would be the correct way to insert
the graphic title "Silhouette plot of 14 clusters" alone?

I am using R 1.61 on Windows NT and the latest available cluster package
from CRAN.

Many thks in advance.

Rgds,
Bernhard






----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------



From Morten.Sickel at nrpa.no  Wed Feb  5 16:03:02 2003
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Wed Feb  5 16:03:02 2003
Subject: [R] Bug in recording (Windows graphical device)
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5DD5@postix.nrpa.no>

I was making a lot of similiar plots, so I made a script for making each of
them and a driver program that repeatly called the script with the right
parameters. The plot is made by:

<code>
barplot(Releases[[i]],col='gray',names.arg=as.character(Releases$Year),
ylim=c(0,max),ylab=unit)
box()
grid(col='black',nx=NA,ny=NULL)
rect(-0.5,max*0.98,-0.2+strwidth(Nuc)*1.2,max*0.92,col='white',border='white
')
text(strwidth(Nuc)/2-0.2,max*0.95,Nuc,cex=1.2)
</code>

My first attempt was to use the recording function in the device and just
call it using 

<code>
for (i in c(1,2,5,7,8,9,10,12,14,15,16,18,19,20,23,24,25)){
source('Barplot-prog.R')}
}
</code>

Which messed up the grid drawed on the plot, the lines were extended all the
way through the margins. Saving each plot to a file, otoh, works, it also
makes the recorded plots correct. After this has occured the first time, I
have to close and reopen the graphics device to make it work correctly
again. 

I can send data and complete scripts if someone needs them to investigate
the problem.

Morten



From mschwartz at medanalytics.com  Wed Feb  5 17:14:02 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed Feb  5 17:14:02 2003
Subject: [R] barplot default colors
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BC41@usrymx25.merck.com>
Message-ID: <006701c2cd24$2f5f80e0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Liaw, Andy
>Sent: Wednesday, February 05, 2003 7:00 AM
>To: 'r-help at stat.math.ethz.ch'
>Subject: [R] barplot default colors
>
>
>Dear R-help,
>
>Can some one explain why barplot() uses changing colors in the 
>bars by default?  I should think that most of the time when 
>people draw barplots, they want the bars to be in the same 
>color.  (At least that's what I'd expect.  The first time I 
>used barplot() in R, I was shocked to see the
>colors.)  As an example, one example in ?layout draws a 
>scatterplot with histograms drawn on the margins.  The 
>histograms were drawn by barplot(), and, IMHO, look rather 
>hideous in the colors.
>
>Regards,
>Andy
>
>Andy I. Liaw, PhD
>Biometrics Research          Phone: (732) 594-0820
>Merck & Co., Inc.              Fax: (732) 594-1565
>P.O. Box 2000, RY84-16            Rahway, NJ 07065
>mailto:andy_liaw at merck.com

Andy,

This is an extrapolation beyond known data by me, but I would suspect
that one plausible reason is that since barplot can do grouped bars
and stacked bars, the original author decided to set a single default
multiple color vector for all cases. 

This would be one approach rather than checking to see what type of
barplot was being drawn and using a single color for the scenario you
are using or a multiple color vector for grouped/stacked bars.

It is obviously easy enough to add 'col = "color"' to the barplot()
arguments to use a single color of your choosing or an alternate
multiple color vector.

To change the default behavior now would likely break other code in
use.

My two cents....

Regards,

Marc Schwartz



From otoomet at econ.dk  Wed Feb  5 17:46:06 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Wed Feb  5 17:46:06 2003
Subject: [R] About Cumulant Generating Functions
In-Reply-To: <002601c2cc8a$6ed87d70$8bd75ba5@IE.TAMU.EDU>
	(f0z6305@labs.tamu.edu)
References: <002601c2cc8a$6ed87d70$8bd75ba5@IE.TAMU.EDU>
Message-ID: <200302051646.h15Gkx120302@punik.econ.au.dk>

Hi,

 | From: "Feng Zhang" <f0z6305 at labs.tamu.edu>
 | Hey, all
 | 
 | Can anybody tell me the definition or form of 
 | cumulant generating function for a series
 | of random variables x1, x2, ....?
 | 
 | I know the moment generationg function
 | is E[exp(tx)], and want to know the relationships
 | bw cumulants and moments.

This is the log of moment-generating function:

K(s) = log M(s) = E[exp(sx)]

It is closely related with central moments:

K'(0) = E[x]
K''(0) = Var x
K'''(0) = E[(x - Ex)^3]

this was true for K''''(0) too AFAIR, but not for further
derivatives (but check rather yourself).


Best,

Ott



From tlumley at u.washington.edu  Wed Feb  5 17:51:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Feb  5 17:51:03 2003
Subject: [R] barplot default colors
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BC41@usrymx25.merck.com>
Message-ID: <Pine.A41.4.44.0302050842450.41512-100000@homer17.u.washington.edu>

On Wed, 5 Feb 2003, Liaw, Andy wrote:

> Can some one explain why barplot() uses changing colors in the bars by
> default?  I should think that most of the time when people draw barplots,
> they want the bars to be in the same color.  (At least that's what I'd
> expect.  The first time I used barplot() in R, I was shocked to see the
> colors.)  As an example, one example in ?layout draws a scatterplot with
> histograms drawn on the margins.  The histograms were drawn by barplot(),
> and, IMHO, look rather hideous in the colors.

The changing colours are useful when the data are a matrix (so that you
have bars either stacked or in groups).  You can easily get a single
color,
eg
data(VADeaths)
barplot(VADeaths, beside=TRUE, col="thistle")


The colours themselves are definitely not ideal. As Paul Murrell said at
the beginning of his talk on colour at last year' JSM "The only word for
this is `embarassing'".  Better colour palettes are in the works, eg see
the RColorBrewer package.

	-thomas



From duncan at research.bell-labs.com  Wed Feb  5 17:55:03 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Wed Feb  5 17:55:03 2003
Subject: [R] R as a `script'
In-Reply-To: <1044451834.10726.32.camel@wotan.math.ntnu.no>; from Havard.Rue@math.ntnu.no on Wed, Feb 05, 2003 at 02:30:34PM +0100
References: <1044451834.10726.32.camel@wotan.math.ntnu.no>
Message-ID: <20030205115131.M12650@jessie.research.bell-labs.com>

The feature will hopefully be available in 1.7.0.  I have done some
work on this thanks to some code provided by Neil McKay.  It is become
slightly more complex as we try to also explore different startup
techniques, and get it tested on all of the different platforms.  But,
hopefully by 1.7.0.

Havard Rue wrote:
> 
> is there any way i can use R as a tool for scripts in unix, as 
> 
> wotan[hrue]$ cat example.R 
> #!/usr/bin/R
> x=1
> 
> havard
> 
> -- 
>  Havard Rue
>  Department of Mathematical Sciences
>  Norwegian University of Science and Technology
>  N-7491 Trondheim, Norway
>  Voice: +47-7359-3533    URL  : http://www.math.ntnu.no/~hrue  
>  Fax  : +47-7359-3524    Email: havard.rue at math.ntnu.no
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From tlumley at u.washington.edu  Wed Feb  5 17:58:14 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Feb  5 17:58:14 2003
Subject: [R] R as a `script'
In-Reply-To: <20030205083858.A29900@cattell.psych.upenn.edu>
Message-ID: <Pine.A41.4.44.0302050848380.41512-100000@homer17.u.washington.edu>

On Wed, 5 Feb 2003, Jonathan Baron wrote:

> On 02/05/03 14:30, Havard Rue wrote:
> >
> >is there any way i can use R as a tool for scripts in unix, as
> >
> >wotan[hrue]$ cat example.R
> >#!/usr/bin/R
> >x=1
> >
> >havard
>
> What I do - explained in the R man page - is
>
> R < example.R > example.out
>
> and I have found it useful (for some reason I can't recall) to
> use the --vanilla option in these cases:
>
> R --vanilla < example.R > example.out
>

It's useful because it won't work otherwise -- you need --save, --no-save
or --vanilla.


You can also send small amounts of R code into stdin directly.  For
example, a shell script Sweave.sh to run Sweave can be written as

#!/bin/sh
R --vanilla < SweaveSh.R >/dev/null  $1

with SweaveSh.R being
library(tools)
Sweave(commandArgs()[3])

or more elegantly in a single file as
#!/bin/sh
echo "library(tools);Sweave('"$1"')" | /usr/local/bin/R --vanilla --silent


(the first is mine, the second is from Fritz Leisch).


	-thomas



From andy_liaw at merck.com  Wed Feb  5 18:02:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Feb  5 18:02:03 2003
Subject: [R] barplot default colors
Message-ID: <3A822319EB35174CA3714066D590DCD534BC45@usrymx25.merck.com>

> From: Thomas Lumley [mailto:tlumley at u.washington.edu]
> 
> On Wed, 5 Feb 2003, Liaw, Andy wrote:
> 
> > Can some one explain why barplot() uses changing colors in 
> the bars by
> > default?  I should think that most of the time when people 
> draw barplots,
> > they want the bars to be in the same color.  (At least 
> that's what I'd
> > expect.  The first time I used barplot() in R, I was 
> shocked to see the
> > colors.)  As an example, one example in ?layout draws a 
> scatterplot with
> > histograms drawn on the margins.  The histograms were drawn 
> by barplot(),
> > and, IMHO, look rather hideous in the colors.
> 
> The changing colours are useful when the data are a matrix 
> (so that you
> have bars either stacked or in groups).  You can easily get a single
> color,
> eg
> data(VADeaths)
> barplot(VADeaths, beside=TRUE, col="thistle")

In that case, couldn't the code check whether the input is a matrix, and
only use the changing colors if it is, and use only one color if the input
is a vector (w/o dimensions)?  Getting all bars to have the same color is
easy.  My gripe is that it's not the default, which surprised me.  

In the danger of taking this a bit off-topic, are there any "guidelines" on
what aspect of R should and should not be compatible with Splus?  barplot()
in Splus does not use varying colors for the bars by default.  Meanwhile,
lattice uses the gray background / light blue foreground theme from Trellis
as default, for the supposed compatibility with Splus.  Personally I hated
that color-scheme (because of my poor eye-sight and colorblind), but thought
that compatibility with S is a rather weak reason there...

OK, I guess enough venting for the day...

Cheers,
Andy

[...]

------------------------------------------------------------------------------



From B.Rowlingson at lancaster.ac.uk  Wed Feb  5 18:28:03 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed Feb  5 18:28:03 2003
Subject: [R] R as a `script'
In-Reply-To: <Pine.A41.4.44.0302050848380.41512-100000@homer17.u.washington.edu>
References: <Pine.A41.4.44.0302050848380.41512-100000@homer17.u.washington.edu>
Message-ID: <3E41499A.8040402@lancaster.ac.uk>

Thomas Lumley wrote:

> or more elegantly in a single file as
> #!/bin/sh
> echo "library(tools);Sweave('"$1"')" | /usr/local/bin/R --vanilla --silent
> 

What's more elegant than a 'here' document?

#!/bin/sh
R --slave --vanilla "$@" <<EOF

print(commandArgs())
x <- runif(1000)
print(mean(x))

EOF

  - save to a file, make executable, run. It even handles command line 
arguments (the "$@" bit) which can be picked up by commandArgs().


Baz



From Huiqin.Yang at noaa.gov  Wed Feb  5 20:38:02 2003
From: Huiqin.Yang at noaa.gov (Huiqin Yang)
Date: Wed Feb  5 20:38:02 2003
Subject: [R] (no subject)
Message-ID: <3E416715.97847709@noaa.gov>

Hello everyone,

 I am a new beginner and I want to know how to use Splus object in R and how to convert each other?

 Thanks a lot.

Helen Yang



From forporphyry at hotmail.com  Wed Feb  5 21:22:03 2003
From: forporphyry at hotmail.com (graham lawrence)
Date: Wed Feb  5 21:22:03 2003
Subject: [R] R 1.6 crashes if  in object displayed on console
Message-ID: <F1687QiL40jguVZ70wm00016088@hotmail.com>

Dear R-help,

Under Win98se, the mere presence of this character,  (Alt+0178), causes R 
1.6 to crash, but only when it is in an object displayed to the console.

>x<-""   #no problem
>x

R crashes with Illegal operation message

graham lawrence



From edd at debian.org  Wed Feb  5 21:30:03 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed Feb  5 21:30:03 2003
Subject: [R] R 1.6 crashes if  in object displayed on console
Message-ID: <E18gWAW-0003uq-00@sonny.eddelbuettel.com>


> Under Win98se, the mere presence of this character, ? (Alt+0178), causes R 
> 1.6 to crash, but only when it is in an object displayed to the console.
> 
> >x<-"?"   #no problem
> >x
> 
> R crashes with Illegal operation message

Well, there never was "R 1.6". Do you use 1.6.0, 1.6.1 or 1.6.2? 

For what's it worth, R 1.6.2 on NT4 is happy to show ALT+0178.

Dirk

-- 
According to the latest figures, 43% of all signatures are totally worthless.



From mschwartz at medanalytics.com  Wed Feb  5 21:51:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed Feb  5 21:51:03 2003
Subject: [R] =?iso-8859-1?Q?RE:_=5BR=5D_R_1.6_crashes_if_=B2_in_object_displayed_on_co?=
 =?iso-8859-1?Q?nsole?=
In-Reply-To: <E18gWAW-0003uq-00@sonny.eddelbuettel.com>
Message-ID: <000e01c2cd58$283edde0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Dirk
Eddelbuettel
>Sent: Wednesday, February 05, 2003 2:29 PM
>To: graham lawrence; r-help at stat.math.ethz.ch
>Subject: Re: [R] R 1.6 crashes if ? in object displayed on console
>
>> graham lawrence wrote:
>>
>> Under Win98se, the mere presence of this character, ? (Alt+0178),
>> causes R
>> 1.6 to crash, but only when it is in an object displayed to 
>the console.
>> 
>> >x<-"?"   #no problem
>> >x
>> 
>> R crashes with Illegal operation message
>
>Well, there never was "R 1.6". Do you use 1.6.0, 1.6.1 or 1.6.2?
>
>For what's it worth, R 1.6.2 on NT4 is happy to show ALT+0178.
>
>Dirk


The same using 1.6.2 under WinXP:

> x <- "?"
> x
[1] "?"


No crash.

HTH,

Marc Schwartz



From vograno at arbitrade.com  Wed Feb  5 21:56:13 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Wed Feb  5 21:56:13 2003
Subject: [R] commandArgs() prints warnings to STDOUT
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DCDE@jupiter.arbitrade.com>

Dear R-Users,

I was glad to hear that there is an ongoing work to make R more easily
runnable as a batch. I'd like to raise two issues in this regards:

1. commandArgs() prints warnings to STDOUT rather than to STDERR, see
example below

$ cat foo.R
argv <- commandArgs()

$ R --no-save --no-restore --silent A < foo.R 2> /dev/null
ARGUMENT 'A' __ignored__
> argv <- commandArgs()
> 


2. It should be possible to turn off echoing of R commands, the '>' lines
above. Please let me know if it is already there.

Thanks, Vadim

-------------------------------------------------- 
DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]



From gregory_r_warnes at groton.pfizer.com  Wed Feb  5 22:42:13 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Wed Feb  5 22:42:13 2003
Subject: [R] testing slope
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C568@groexmb02.pfizer.com>

For testing the hypothesis

	Beta[X] + Beta[Vn3] + Beta[X:Vn3] = 0

you can use the estimable function from the gregmisc package:

	estimable(m2, c("Intercept"=0,
			   "X"=1,
			   "Vn2"=0,
			   "Vn3"=1,
                     "X:Vn2"=0,
			   "X:Vn3"=1)
		    )

See the estimable help page for details.

-Greg




> -----Original Message-----
> From: Ronaldo Reis Jr. [mailto:chrysopa at insecta.ufv.br]
> Sent: Tuesday, February 04, 2003 2:51 PM
> To: R-Help
> Subject: [R] testing slope
> 
> 
> Hi all,
> 
> I try to test a linear slope using offset.
> 
> I have:
> 
> > m2 <- glm(Y~X*V)
> > summary(m2)
> 
> Call:
> glm(formula = Y ~ X * V)
> 
> Deviance Residuals: 
>      Min        1Q    Median        3Q       Max  
> -2.01688  -0.56028   0.05224   0.53213   3.60216  
> 
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)    
> (Intercept)   1.3673     0.8476   1.613 0.119788    
> X             4.0235     0.1366  29.453  < 2e-16 ***
> Vn2           0.9683     1.1987   0.808 0.427131    
> Vn3           4.6043     1.1987   3.841 0.000787 ***
> X:Vn2         4.1108     0.1932  21.279  < 2e-16 ***
> X:Vn3        -4.0069     0.1932 -20.740  < 2e-16 ***
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> 
> (Dispersion parameter for gaussian family taken to be 1.53955)
> 
>     Null deviance: 15303.977  on 29  degrees of freedom
> Residual deviance:    36.949  on 24  degrees of freedom
> AIC: 105.39
> 
> Number of Fisher Scoring iterations: 2
> 
> It is clear that X slope is diferent of Zero.
> X             4.0235     0.1366  29.453  < 2e-16 ***
> 
> It is too clear that X:Vn2's slope is diferent of X's slope 
> and diferent of 
> Zero, because is greater than X'slope.
> X:Vn2         4.1108     0.1932  21.279  < 2e-16 ***
> 
> But, the X:Vn3' slope is different of X'slope, but not 
> necessarily different 
> of Zero.
> 
> How I make to introduce this parameter in a new model for 
> test? An offset only 
> with Vn3 slope???
> 
> I try:
> 
> m2 <- glm(Y~V*offset(0*X))
> m2 <- glm(Y~X*V+V*offset(0*X))
> m2 <- glm(Y~V:X+V*offset(0*X))
> 
> but neither work :((
> 
> Thanks for all.
> Ronaldo
> -- 
> If you live in a country run by committee, be on the committee.
> 		-- Graham Summer
> --
> |   //|\\   [*****************************][*******************]
> || ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
> |     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
> ||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
> |  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
> ||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
> |/ (linux) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
> ||  ( x )   [*****************************][*******************]
> ||| _/ \_Powered by Gnu/Debian Woody D+:) | Lxuser#: 205366
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From vograno at arbitrade.com  Wed Feb  5 22:47:03 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Wed Feb  5 22:47:03 2003
Subject: [R] commandArgs() prints warnings to STDOUT - correction
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DCDF@jupiter.arbitrade.com>

I realized that it is not commandArgs() rather R itslef that prints the
warning to the stdout (which is still not desirable of course):

$ R --no-save --no-restore --silent A < /dev/null 2> /dev/null
ARGUMENT 'A' __ignored__


=======original message below========


Dear R-Users,

I was glad to hear that there is an ongoing work to make R more easily
runnable as a batch. I'd like to raise two issues in this regards:

1. commandArgs() prints warnings to STDOUT rather than to STDERR, see
example below

$ cat foo.R
argv <- commandArgs()

$ R --no-save --no-restore --silent A < foo.R 2> /dev/null
ARGUMENT 'A' __ignored__
> argv <- commandArgs()
> 


2. It should be possible to turn off echoing of R commands, the '>' lines
above. Please let me know if it is already there.

Thanks, Vadim


-------------------------------------------------- 
DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]



From jbond at arg.org  Wed Feb  5 22:56:02 2003
From: jbond at arg.org (Jason Bond)
Date: Wed Feb  5 22:56:02 2003
Subject: [R] clustering and stratification
Message-ID: <5.1.0.14.2.20030205134629.01da1840@arg.org>

Hello,

   Does R have any capabilities (or are there any add on packages) which 
can do estimation of standard statistical models (means, regression, 
logistic regression, etc) which take into account not only weights (e.g. 
post-stratification weights) but also the sample design, such as 
stratification and clustering information (to compute a robust taylor 
linearized variance estimator, for example)?  Thanks much for any input,

   Jason

_______________________________

Jason C. Bond, Ph.D.
Biostatistician, Associate Scientist
Public Health Institute
Alcohol Research Group
2000 Hearst Avenue
Berkeley, CA  94709

Telephone: 	(510) 642-7965
Fax:		(510) 642-7175



From dfs at research.att.com  Wed Feb  5 23:37:03 2003
From: dfs at research.att.com (Deborah Swayne)
Date: Wed Feb  5 23:37:03 2003
Subject: [R] postscript: can't center plot
Message-ID: <20030205223547.GA2085624@fry.research.att.com>

One of our color postscript printers needs a slightly larger margin
than the default, so I'm trying to send slightly smaller graphics to
it, but all the extra margin I provide ends up at the right and
bottom of the page.

These are the relevant (I imagine) ps.options:

$paper      [1] "special"
$width      [1] 10
$height     [1] 8
$pagecentre [1] TRUE

I tried this on two systems, in two versions of R, and the output
is identical.
  linux: R 1.6.1 (2002-11-01)
  mips-sgi-irix6.5: R 1.6.1 Beta (2002-10-28)

I'll attach a postscript file, which is very simple but I think
shows the asymmetry I'm talking about.

I'll file a bug report if I should, but I thought I'd give y'all a
chance to confirm the behavior or tell me I'm going about this all
wrong.

Debby
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lestat.ps
Type: application/postscript
Size: 3906 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030205/f7fc1d48/lestat.ps

From pkleiber at honlab.nmfs.hawaii.edu  Wed Feb  5 23:50:06 2003
From: pkleiber at honlab.nmfs.hawaii.edu (Pierre Kleiber)
Date: Wed Feb  5 23:50:06 2003
Subject: [R] R as a `script'
References: <Pine.A41.4.44.0302050848380.41512-100000@homer17.u.washington.edu> <3E41499A.8040402@lancaster.ac.uk>
Message-ID: <3E41957D.8030502@honlab.nmfs.hawaii.edu>

While on the subject of scripts... Can someone suggest a strategy for
plotting something in an X11 window with R in a Unix script, such that
the plot window will persist after the script exits?  i.e.:

      #!/bin/sh
      R --slave --vanilla  <<EOF

      X11()

      plot something

      do something to preserve the image

      q()

      EOF


-- 
-----------------------------------------------------------------
Pierre Kleiber             Email: pkleiber at honlab.nmfs.hawaii.edu
Fishery Biologist                     Tel: 808 983-5399/737-7544
NOAA FISHERIES - Honolulu Laboratory         Fax: 808 983-2902
2570 Dole St., Honolulu, HI 96822-2396
-----------------------------------------------------------------



From david.orlovich at botany.otago.ac.nz  Wed Feb  5 23:55:11 2003
From: david.orlovich at botany.otago.ac.nz (David Orlovich)
Date: Wed Feb  5 23:55:11 2003
Subject: [R] =?ISO-8859-1?Q?Re:_[R]_RE:_[R]_R_1.6_crashes_if_=B2_in_object_di?=
 =?ISO-8859-1?Q?splayed_on_console?=
In-Reply-To: <000e01c2cd58$283edde0$0201a8c0@MARC>
Message-ID: <70ACE601-395C-11D7-BAF4-003065CC6B30@botany.otago.ac.nz>

No problem on a Mac running X11 (the best platform ;)

[David-Orlovichs-Computer:~] orlovich% /usr/local/bin/R

R : Copyright 2003, The R Development Core Team
Version 1.6.2 Patched (2003-01-23)

<snip>

 > x<-"?"
 > x
[1] "?"
 >

On Thursday, February 6, 2003, at 09:50 AM, Marc Schwartz wrote:

>>>> x<-"?"   #no problem



From fharrell at virginia.edu  Wed Feb  5 23:59:47 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed Feb  5 23:59:47 2003
Subject: [R] clustering and stratification
In-Reply-To: <5.1.0.14.2.20030205134629.01da1840@arg.org>
References: <5.1.0.14.2.20030205134629.01da1840@arg.org>
Message-ID: <20030205175914.0bff5282.fharrell@virginia.edu>

On Wed, 05 Feb 2003 13:50:06 -0800
Jason Bond <jbond at arg.org> wrote:

> Hello,
> 
>    Does R have any capabilities (or are there any add on packages) which 
> can do estimation of standard statistical models (means, regression, 
> logistic regression, etc) which take into account not only weights (e.g. 
> post-stratification weights) but also the sample design, such as 
> stratification and clustering information (to compute a robust taylor 
> linearized variance estimator, for example)?  Thanks much for any input,
> 
>    Jason
> 
> _______________________________
> 
> Jason C. Bond, Ph.D.
> Biostatistician, Associate Scientist
> Public Health Institute
> Alcohol Research Group
> 2000 Hearst Avenue
> Berkeley, CA  94709
> 
> Telephone: 	(510) 642-7965
> Fax:		(510) 642-7175
> 
>

For ols, logistic, accelerated failure time, and Cox models you can do cluster adjustments using either the robcov (Huber-White-Efron methods) or bootcov (cluster bootstrap) functions in the Design library.  See http://hesweb1.med.virginia.edu/biostat/s/Design.html

Doing this as the same time as using weights may not be supported by the functions.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From ripley at stats.ox.ac.uk  Thu Feb  6 00:04:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb  6 00:04:03 2003
Subject: [R] postscript: can't center plot
In-Reply-To: <20030205223547.GA2085624@fry.research.att.com>
Message-ID: <Pine.LNX.4.44.0302052244431.6423-100000@gannet.stats>

You can't centre with paper = "special". You seemto be trying to set a
special *paper* size, and there is no way to do that: paper="special" says
make the paper size the same as the device region so there will never be a
margin.

This is really an issue for the PS device manager, which should be able to 
decide how to print a document of size A on paper of size B: yours seems 
to print at one corner of the page.  Normally with paper="special"
the R output contains no paper information at all.

If I understand you aright, you do want to reduce width and height but do
want a paper size (I nearly wrote `standard' there, but I presume it is a
non-Standard one like `letter').  Using width=6, height=8, paper="a4" will
centre on A4 with large margins.

Brian

On Wed, 5 Feb 2003, Deborah Swayne wrote:

> One of our color postscript printers needs a slightly larger margin
> than the default, so I'm trying to send slightly smaller graphics to
> it, but all the extra margin I provide ends up at the right and
> bottom of the page.
> 
> These are the relevant (I imagine) ps.options:
> 
> $paper      [1] "special"
> $width      [1] 10
> $height     [1] 8
> $pagecentre [1] TRUE
> 
> I tried this on two systems, in two versions of R, and the output
> is identical.
>   linux: R 1.6.1 (2002-11-01)
>   mips-sgi-irix6.5: R 1.6.1 Beta (2002-10-28)
> 
> I'll attach a postscript file, which is very simple but I think
> shows the asymmetry I'm talking about.
> 
> I'll file a bug report if I should, but I thought I'd give y'all a
> chance to confirm the behavior or tell me I'm going about this all
> wrong.
> 
> Debby
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Feb  6 00:08:15 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb  6 00:08:15 2003
Subject: [R] =?ISO-8859-1?Q?Re:_[R]_RE:_[R]_R_1.6_crashes_if_=B2_in_object_di?=
 =?ISO-8859-1?Q?splayed_on_console?=
In-Reply-To: <70ACE601-395C-11D7-BAF4-003065CC6B30@botany.otago.ac.nz>
Message-ID: <Pine.LNX.4.44.0302052302170.6423-100000@gannet.stats>

This is covered in the rw-FAQ, and is a bug in some (obselete and
unsupported by Microsoft) versions of Windows.

On Thu, 6 Feb 2003, David Orlovich wrote:

> No problem on a Mac running X11 (the best platform ;)

The comparison should be with MacOS ca 1995, which I think runs neither
R nor X11.

> [David-Orlovichs-Computer:~] orlovich% /usr/local/bin/R
> 
> R : Copyright 2003, The R Development Core Team
> Version 1.6.2 Patched (2003-01-23)
> 
> <snip>
> 
>  > x<-"?"
>  > x
> [1] "?"
>  >
> 
> On Thursday, February 6, 2003, at 09:50 AM, Marc Schwartz wrote:
> 
> >>>> x<-"?"   #no problem
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bojaniss at poczta.onet.pl  Thu Feb  6 00:41:02 2003
From: bojaniss at poczta.onet.pl (Michal Bojanowski)
Date: Thu Feb  6 00:41:02 2003
Subject: [R] UltraEdit syntax highlighting
In-Reply-To: <F5Vf2grCr8tU3HWJl0g00010669@hotmail.com>
References: <F5Vf2grCr8tU3HWJl0g00010669@hotmail.com>
Message-ID: <1297176272.20030206003451@poczta.onet.pl>

Hello,

I use UltraEdit for writing R code and I have a part of WORDFILE.TXT
for highlighting R syntax.

Unfortunately currently I do not have the possibility to put it on the
web. Please contact me off-list at bojaniss at poczta.onet.pl, I will
gladly email it to you.


all the best


mb



~,~`~,~`~,~`~,~`~,~`~,~
Micha? Bojanowski
bojaniss at poczta.onet.pl



--------------r-e-k-l-a-m-a-----------------

OnetPoczta: du?a, szybka, bezpieczna!
http://poczta.onet.pl/oferta/



From macq at llnl.gov  Thu Feb  6 00:46:02 2003
From: macq at llnl.gov (Don MacQueen)
Date: Thu Feb  6 00:46:02 2003
Subject: [R] R as a `script'
In-Reply-To: <1044451834.10726.32.camel@wotan.math.ntnu.no>
References: <1044451834.10726.32.camel@wotan.math.ntnu.no>
Message-ID: <p05200f02ba67519eb704@[128.115.153.6]>

In R 1.6.2 you can do this if you start the script with

    #! /path/to/r_home/lib/R/bin/R.bin

provided that you first define the environment variables R_HOME and 
LD_LIBRARY_PATH as they are defined in the R shell script (/usr/bin/R 
in your case).

I've only tested this running on Sun Solaris. I can't claim to have 
done extensive testing for pitfalls (i.e., pitfalls that aren't 
obvious to me!).

-Don

At 2:30 PM +0100 2/5/03, Havard Rue wrote:
>is there any way i can use R as a tool for scripts in unix, as
>
>wotan[hrue]$ cat example.R
>#!/usr/bin/R
>x=1
>
>havard
>
>--
>  Havard Rue
>  Department of Mathematical Sciences
>  Norwegian University of Science and Technology
>  N-7491 Trondheim, Norway
>  Voice: +47-7359-3533    URL  : http://www.math.ntnu.no/~hrue 
>  Fax  : +47-7359-3524    Email: havard.rue at math.ntnu.no
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------



From ririzarr at jhsph.edu  Thu Feb  6 01:19:02 2003
From: ririzarr at jhsph.edu (Rafael A. Irizarry)
Date: Thu Feb  6 01:19:02 2003
Subject: [R] rdbi segmentation fault
Message-ID: <Pine.GSO.4.10.10302051907240.4655-100000@athena.biostat.jhsph.edu>

hi! i am experiencing the same behaviour explained here:

http://finzi.psych.upenn.edu/R/Rhelp02/archive/2482.html 
(i copied the message below)

has anybody found a solution?

here is the code that gives me a segmentation fault
 library(Rdbi)
 library(Rdbi.PgSQL)
 
 conn <- dbConnect(PgSQL(), dbname = "PGA")
 tmp <- "create table test ( expid int, name varchar(128));" 
 result <- dbSendQuery(conn,tmp)
 dbClearResult(result) 

the last line can be substituted by
 dbDisconnect(conn)
and you get a segmentation fault too.
 
The database PGA does exist and the dbSendQuery does create a table (i
checked via psql)

i followed the instructions given by tim (see url or msg below) and im
sending (what think is) the backtrace:
Program received signal SIGSEGV, Segmentation fault.
Rf_getAttrib (vec=0x8b50cd0, name=0x81d19b8) at attrib.c:93
93		if (TAG(s) == name) {
(gdb) backtrace
#0  Rf_getAttrib (vec=0x8b50cd0, name=0x81d19b8) at attrib.c:93
#1  0x080c0a8f in Rf_usemethod (generic=0xbffff0c0 "print", obj=0x8b50cd0, 
    call=0x880c5a0, args=0x81d1b08, rho=0x89dd900, callrho=0x81e6f68, 
    defrho=0x81e6f14, ans=0xbffff0bc) at objects.c:271
#2  0x080c1058 in do_usemethod (call=0x880c5a0, op=0x81e4f80, 
args=0x880c5bc, 
    env=0x89dd900) at objects.c:409
#3  0x0809cd29 in Rf_eval (e=0x880c5a0, rho=0x89dd900) at eval.c:404
#4  0x0809d26d in Rf_applyClosure (call=0x89de354, op=0x880c4c0, 
    arglist=0x89dd874, rho=0x81e6f68, suppliedenv=0x81d1b08) at eval.c:595
#5  0x0809cf1d in Rf_eval (e=0x89de354, rho=0x81e6f68) at eval.c:439
#6  0x080f013c in Rf_PrintValueEnv (s=0x8b50cd0, env=0x81e6f68) at 
print.c:662
#7  0x080b5597 in Rf_ReplIteration (rho=0x81e6f68, savestack=0, 
browselevel=0, 
    state=0xbffff550) at main.c:236
#8  0x080b56ad in R_ReplConsole (rho=0x81e6f68, savestack=0, 
browselevel=0)
    at main.c:280
#9  0x080b5d4b in run_Rmainloop () at main.c:579
#10 0x0811570e in main (ac=1, av=0xbffffa34) at system.c:99
#11 0x42017499 in __libc_start_main () from /lib/i686/libc.so.6


thanks,
rafael

MESSGAGE from archive:

I've not seen this behavior. Try "R -d gdb" and then type "run" at the
gdb prompt. Run your R session until the seg fault and send me the
backtrace. Thanks.

Tim

On Thu, 2002-04-25 at 18:05, Andrew Schuh wrote:
> I can use the Rdbi package to connect to a PostGreSQL server fine but
> when I use the dbDisconnect(), I get a segmentation error and it throws
> me out of R. I'm using RH7.2, R1.4.1, Rdbi 0.1-2, and Rdbi.PgSQL 0.1-2.
>
> Anyone else seen anything like this and have an possible answer?
>
> Andrew Schuh
>
>
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !) To: r-help-request at stat.math.ethz.ch
> 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._



From tlumley at u.washington.edu  Thu Feb  6 01:50:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Feb  6 01:50:03 2003
Subject: [R] clustering and stratification
In-Reply-To: <5.1.0.14.2.20030205134629.01da1840@arg.org>
Message-ID: <Pine.A41.4.44.0302051646450.117192-100000@homer03.u.washington.edu>

On Wed, 5 Feb 2003, Jason Bond wrote:

> Hello,
>
>    Does R have any capabilities (or are there any add on packages) which
> can do estimation of standard statistical models (means, regression,
> logistic regression, etc) which take into account not only weights (e.g.
> post-stratification weights) but also the sample design, such as
> stratification and clustering information (to compute a robust taylor
> linearized variance estimator, for example)?  Thanks much for any input,

The new `survey' package does this for means, tables, glm and cox models.
It would be pretty easy to add support for the parametric survival models
if there were any demand.

It incorporates weights, stratification, clustering, and the finite
population correction to variance if desired.

	-thomas



From daver969 at yahoo.com  Thu Feb  6 03:57:02 2003
From: daver969 at yahoo.com (David Richmond)
Date: Thu Feb  6 03:57:02 2003
Subject: [R] .Rprofile, .Rfirst, and .Rdata
Message-ID: <99ACECB0-397E-11D7-872F-000393DBCEC2@yahoo.com>

Hi all,
	After a short hiatus away from R I have found that it's changed a bit. 
I used to keep a definition of .First in .Rprofile that did a couple of 
things on startup (load a couple of libraries). Now, I've discovered 
that when I change the definition of .First in .Rprofile it doesn't 
change anything when I start up, because .First is held over in .Rdata 
from the last session. The manual states that now .Rdata is loaded 
last, as intended. My question is, how do I change what's in .First (or 
any other variable, for that matter), if .Rdata will always override my 
changes? (I'd prefer not to have to do it manually, and I'd prefer to 
have all the other data preserved, rather than just leaving out .Rdata)

Dave R.



From pingzhao at waffle.cs.dal.ca  Thu Feb  6 04:53:03 2003
From: pingzhao at waffle.cs.dal.ca (pingzhao)
Date: Thu Feb  6 04:53:03 2003
Subject: [R] Call C routine problem
Message-ID: <3E4B9BC7@webmail.ucis.dal.ca>

When I call C function from Splus, I often meet this problem:
"Problem: Couldn't find a function definition for "Stest" "

My c function is saved as 'test.c' (the function is also named as 'test'
My splus function is saved as 'Stest', such as

Stest <-
function(d,f)
{
.C("test",
as.integer(d),
as.single(f))
}


Assume my files (test.c and Stest) have been stored in the directory ''work''
I have done the following steps in this directory:
(1) Splus CHAPTER test.c
(2) Splus make
(3) Splus
(4) d<-10
f<-rep(0,d)
result<-Stest(d,f)

then the error message is :
Problem: Couldn't find a function definition for "Stest"

What am I wrong???

Thank you for your help in advance!!!



From hb at maths.lth.se  Thu Feb  6 06:31:04 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu Feb  6 06:31:04 2003
Subject: [R] .Rprofile, .Rfirst, and .Rdata
In-Reply-To: <99ACECB0-397E-11D7-872F-000393DBCEC2@yahoo.com>
Message-ID: <001201c2cda0$d5fa7e60$7341a8c0@alpha.wehi.edu.au>

What do you have in .First() that you can not have directly in the
.Rprofile script? For example:

# ~/.Rprofile
cat("Running my .Rprofile...");
library(modreg)
cat("Running my .Rprofile...done");

Henrik Bengtsson

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of David Richmond
> Sent: den 6 februari 2003 13:57
> To: r-help at stat.math.ethz.ch
> Subject: [R] .Rprofile, .Rfirst, and .Rdata
> 
> 
> Hi all,
> 	After a short hiatus away from R I have found that it's 
> changed a bit. 
> I used to keep a definition of .First in .Rprofile that did a 
> couple of 
> things on startup (load a couple of libraries). Now, I've discovered 
> that when I change the definition of .First in .Rprofile it doesn't 
> change anything when I start up, because .First is held over 
> in .Rdata 
> from the last session. The manual states that now .Rdata is loaded 
> last, as intended. My question is, how do I change what's in 
> .First (or 
> any other variable, for that matter), if .Rdata will always 
> override my 
> changes? (I'd prefer not to have to do it manually, and I'd prefer to 
> have all the other data preserved, rather than just leaving 
> out .Rdata)
> 
> Dave R.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From rpeng at stat.ucla.edu  Thu Feb  6 06:55:04 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu Feb  6 06:55:04 2003
Subject: [R] Call C routine problem
In-Reply-To: <3E4B9BC7@webmail.ucis.dal.ca>
Message-ID: <Pine.GSO.4.10.10302052153310.6941-100000@quetelet.stat.ucla.edu>

Is there a question about R here?

I haven't used S-PLUS in a long long time but it seems like you need to
load your C function *before* you call it in S-PLUS.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 5 Feb 2003, pingzhao wrote:

> When I call C function from Splus, I often meet this problem:
> "Problem: Couldn't find a function definition for "Stest" "
> 
> My c function is saved as 'test.c' (the function is also named as 'test'
> My splus function is saved as 'Stest', such as
> 
> Stest <-
> function(d,f)
> {
> .C("test",
> as.integer(d),
> as.single(f))
> }
> 
> 
> Assume my files (test.c and Stest) have been stored in the directory ''work''
> I have done the following steps in this directory:
> (1) Splus CHAPTER test.c
> (2) Splus make
> (3) Splus
> (4) d<-10
> f<-rep(0,d)
> result<-Stest(d,f)
> 
> then the error message is :
> Problem: Couldn't find a function definition for "Stest"
> 
> What am I wrong???
> 
> Thank you for your help in advance!!!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From f0z6305 at labs.tamu.edu  Thu Feb  6 07:06:03 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu Feb  6 07:06:03 2003
Subject: [R] About STEM Plot in R
Message-ID: <000b01c2cda5$b0de6ce0$8bd75ba5@IE.TAMU.EDU>

Hey

Does anybody know if R can plot the 3-dimensinal 
stem graphs?

In Matlab, there is such similare function to plot
3D plots, stem3(X,Y, Z), where X, Y , Z (column vectors) are
coordinate values of data points.

Thanks.

Fred



From daver969 at yahoo.com  Thu Feb  6 07:45:07 2003
From: daver969 at yahoo.com (David Richmond)
Date: Thu Feb  6 07:45:07 2003
Subject: [R] .Rprofile, .Rfirst, and .Rdata
In-Reply-To: <001201c2cda0$d5fa7e60$7341a8c0@alpha.wehi.edu.au>
Message-ID: <86008410-399E-11D7-872F-000393DBCEC2@yahoo.com>

On Wednesday, February 5, 2003, at 09:30  PM, Henrik Bengtsson wrote:

> What do you have in .First() that you can not have directly in the
> .Rprofile script? For example:
>

Nothing that I can think of, but it's the principle of the thing. If i 
did have a reason to change .First, how would I do it ? More generally, 
suppose I want to ensure a variable is set to a certain value in 
.Rprofile, how can I be sure that R.data won't overwrite it? It just 
seems like loading .Rdata after .Rprofile makes it difficult to change 
things easily.


> # ~/.Rprofile
> cat("Running my .Rprofile...");
> library(modreg)
> cat("Running my .Rprofile...done");
>
> Henrik Bengtsson
>
>> -----Original Message-----
>> From: r-help-admin at stat.math.ethz.ch
>> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of David Richmond
>> Sent: den 6 februari 2003 13:57
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] .Rprofile, .Rfirst, and .Rdata
>>
>>
>> Hi all,
>> 	After a short hiatus away from R I have found that it's
>> changed a bit.
>> I used to keep a definition of .First in .Rprofile that did a
>> couple of
>> things on startup (load a couple of libraries). Now, I've discovered
>> that when I change the definition of .First in .Rprofile it doesn't
>> change anything when I start up, because .First is held over
>> in .Rdata
>> from the last session. The manual states that now .Rdata is loaded
>> last, as intended. My question is, how do I change what's in
>> .First (or
>> any other variable, for that matter), if .Rdata will always
>> override my
>> changes? (I'd prefer not to have to do it manually, and I'd prefer to
>> have all the other data preserved, rather than just leaving
>> out .Rdata)
>>
>> Dave R.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
>>
>>
>



From gregory.benmenzer at gazdefrance.com  Thu Feb  6 09:22:03 2003
From: gregory.benmenzer at gazdefrance.com (Gregory BENMENZER)
Date: Thu Feb  6 09:22:03 2003
Subject: [R] =?iso-8859-1?Q?R=E9f=2E_=3A_[R]_About_STEM_Plot_in_R?=
Message-ID: <OF7389B4A1.117BA043-ON41256CC5.002CFD7E@notes.edfgdf.fr>

hello,

you can use the persp() function. The shade=0.7 option is very nice. With
matlab, it is possible to change of colors automaticalli with the value to
be plotted.

Does someone know to do that ?

Gr?gory





f0z6305 at labs.tamu.edu@stat.math.ethz.ch on 06/02/2003 07:05:04

Envoy? par :      r-help-admin at stat.math.ethz.ch


Pour : r-help at stat.math.ethz.ch
cc :
Objet :     [R] About STEM Plot in R


Hey

Does anybody know if R can plot the 3-dimensinal
stem graphs?

In Matlab, there is such similare function to plot
3D plots, stem3(X,Y, Z), where X, Y , Z (column vectors) are
coordinate values of data points.

Thanks.

Fred

______________________________________________
R-help at stat.math.ethz.ch mailing list
 http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From maechler at stat.math.ethz.ch  Thu Feb  6 09:34:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Feb  6 09:34:02 2003
Subject: [R] .Rprofile, .First, and .RData
In-Reply-To: <86008410-399E-11D7-872F-000393DBCEC2@yahoo.com>
References: <001201c2cda0$d5fa7e60$7341a8c0@alpha.wehi.edu.au>
	<86008410-399E-11D7-872F-000393DBCEC2@yahoo.com>
Message-ID: <15938.7626.479963.601843@gargle.gargle.HOWL>

>>>>> "David" == David Richmond <daver969 at yahoo.com>
>>>>>     on Wed, 5 Feb 2003 22:45:04 -0800 writes:

    David> On Wednesday, February 5, 2003, at 09:30  PM, Henrik Bengtsson wrote:
    >> What do you have in .First() that you can not have directly in the
    >> .Rprofile script? For example:
    >> 

    David> Nothing that I can think of, but it's the principle
    David> of the thing. If i did have a reason to change
    David> .First, how would I do it ? More generally, suppose I
    David> want to ensure a variable is set to a certain value
    David> in .Rprofile, how can I be sure that .RData won't
    David> overwrite it? It just seems like loading .RData after
    David> .Rprofile makes it difficult to change things easily.

Setting global variables and relying on their values is always `un-clean'.
In your case, I would set options(): They can't ever be overridden by
any .RData -- e.g.,
     options(myABC = 1:3, myFile = "/abc/def")
and then use  getOption("myABC")
instead of a global variable named `ABC'.

BTW: I advocate not working with .RData at all. 
     I work with *.R scripts (using ESS) and when needed, explicit  
     save(.) and load(.) for a given list of objects and with
     filenames such as "foobar.rda" instead of ".RData".

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From laurent at cbs.dtu.dk  Thu Feb  6 09:40:03 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Thu Feb  6 09:40:03 2003
Subject: [R] function 'silhouette' in package 'cluster'
Message-ID: <20030206083727.GC12630578@genome.cbs.dtu.dk>

Dear all,

I am trying (without much success) to use the fuction 'silhouette'.
Would anyone encountered that before (or would know where I am wrong ?)

Please find below the R ouput. Thanks in advance,


L.


> s <- silhouette(ct, as.dist(metric))
Error in "[<-"(*tmp*, iC, "sil_width", value = s.i) : 
	number of items to replace is not a multiple of replacement length
In addition: Warning messages: 
1: longer object length
	is not a multiple of shorter object length in: b.i - a.i 
2: number of rows of result
	is not a multiple of vector length (arg 2) in: cbind(mmm, as.vector(each)) 
> 
> traceback()
2: silhouette.default(ct, as.dist(metric))
1: silhouette(ct, as.dist(metric))

> str(ct)
 Named int [1:2381] 1 1 1 1 1 2 2 2 1 1 ...
 - attr(*, "names")= chr [1:2381] "5153" "22" "5185" "356" ...
> str(metric)
 num [1:2381, 1:2381] 0.000 1.438 1.172 0.751 0.432 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:2381] "5153" "22" "5185" "356" ...
  ..$ : chr [1:2381] "5153" "22" "5185" "356" ...
>



From maechler at stat.math.ethz.ch  Thu Feb  6 09:47:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Feb  6 09:47:02 2003
Subject: [R] Re: persp() varying colors with "z" values.
In-Reply-To: <OF7389B4A1.117BA043-ON41256CC5.002CFD7E@notes.edfgdf.fr>
References: <OF7389B4A1.117BA043-ON41256CC5.002CFD7E@notes.edfgdf.fr>
Message-ID: <15938.8399.932346.834636@gargle.gargle.HOWL>

>>>>> "Gregory" == Gregory BENMENZER <gregory.benmenzer at gazdefrance.com>
>>>>>     on Thu, 6 Feb 2003 09:17:41 +0100 writes:

    Gregory> hello,

    Gregory> you can use the persp() function. The shade=0.7
    Gregory> option is very nice. With matlab, it is possible to
    Gregory> change of colors automaticalli with the value to be
    Gregory> plotted.

    Gregory> Does someone know to do that ?

Yes.  Look at the last plot of the persp() demo,
> demo(persp)

As you can see there you need two steps:
 1) define a color vector, say `zCol' varying with your z variate
 2) persp(x,y,z, col = zCol, ....)

I hope this helps.

    >> f0z6305 at labs.tamu.edu@stat.math.ethz.ch on 06/02/2003 07:05:04
    >> Pour : r-help at stat.math.ethz.ch
    >> Objet :     [R] About STEM Plot in R

    Fred> Hey

    Fred> Does anybody know if R can plot the 3-dimensinal
    Fred> stem graphs?

    Fred> In Matlab, there is such similare function to plot
    Fred> 3D plots, stem3(X,Y, Z), where X, Y , Z (column vectors) are
    Fred> coordinate values of data points.

    Fred> Thanks.
    Fred> Fred

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From AlessandroSemeria at cramont.it  Thu Feb  6 09:52:03 2003
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Thu Feb  6 09:52:03 2003
Subject: [R] .Rprofile, .Rfirst, and .Rdata
Message-ID: <OF39BDB87C.826BF696-ONC1256CC5.002F8859@tomware.it>

.Rdata is the file containing default ( the last one) workspace (at the end
of a session if your answer at the qestion "Save workspace?[y/n/c]" is
yes a backup of the present  WorkSpace is performed overwriting .RData)
then you can simply delete it!
If you have to perform a backup of your WS use save.image
("path_to_file.Rdata") (something like ../pluto.Rdata).

A.S.

----------------------------

|------------------------------------+------------------------------------|
|Alessandro Semeria                  |Tel. +39 544 536811                 |
|------------------------------------+------------------------------------|
|Models and Simulation Laboratory    |Fax. +39 544 538663                 |
|------------------------------------+------------------------------------|
|The Environment Research Center -   |                                    |
|Montecatini (Edison Group),    Via  |                                    |
|Ciro Menotti 48,                    |E-mail: asemeria at cramont.it         |
|48023 Marina di Ravenna (RA), Italy |                                    |
|------------------------------------+------------------------------------|



From maechler at stat.math.ethz.ch  Thu Feb  6 10:36:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Feb  6 10:36:02 2003
Subject: [R] Package: cluster -- plot.partition() change title: main=""
In-Reply-To: <18D602BD42B7E24EB810D6454A58DB90047301C9@ibfftce505.is.de.dresdnerkb.com>
References: <18D602BD42B7E24EB810D6454A58DB90047301C9@ibfftce505.is.de.dresdnerkb.com>
Message-ID: <15938.11364.132075.90146@gargle.gargle.HOWL>

>>>>> "BernPf" == Pfaff, Bernhard <Bernhard.Pfaff at drkw.com>
>>>>>     on Wed, 5 Feb 2003 15:55:42 +0100 writes:


    BernPf> I am using the cluster package and by the generation
    BernPf> of plot.partition I ran into the problem that an
    BernPf> alternative title overlaps the default title.

    >> plot.partition(clara.14,which.plot=2,stand=TRUE, 
    >> 		     main="Silhouette plot of 14 clusters")

{ using an explicit method call which is ``discouraged''.
  Simply using  plot(.......) gives the same result. }


    BernPf> The manual states that all optional arguments for
    BernPf> clusplot.default may also be supplied to
    BernPf> plot.partition(). Altering the title in clusplot()
    BernPf> works.  Question: What am I doing wrong and what
    BernPf> would be the correct way to insert the graphic title
    BernPf> "Silhouette plot of 14 clusters" alone?

For the moment, you must change the code, for an *installed*
package, this is the file  <RHOME>/library/cluster/R/cluster
Change the two lines {1433 and 1448 in the above file} with text
    plot(silhouette(x), nmax.lab, max.strlen)
into
    plot(silhouette(x), nmax.lab, max.strlen, ...)

This will work perfectly in your case,
but can give extraneous warnings in other situations.
The next version of cluster will have a better solution,
an explicit `main' argument.

    BernPf> I am using R 1.61 on Windows NT and the latest
    BernPf> available cluster package from CRAN.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From helgito at hi.is  Thu Feb  6 10:43:03 2003
From: helgito at hi.is (Helgi Tomasson)
Date: Thu Feb  6 10:43:03 2003
Subject: [R] big ps-files
References: <Pine.LNX.4.44.0302051312010.23732-100000@gannet.stats>
Message-ID: <3E422D4A.EAE59472@hi.is>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030206/dbd0f505/attachment.pl

From maechler at stat.math.ethz.ch  Thu Feb  6 10:47:03 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Feb  6 10:47:03 2003
Subject: [R] Package: cluster -- plot.partition() change title: main=""
In-Reply-To: <15938.11364.132075.90146@gargle.gargle.HOWL>
References: <18D602BD42B7E24EB810D6454A58DB90047301C9@ibfftce505.is.de.dresdnerkb.com>
	<15938.11364.132075.90146@gargle.gargle.HOWL>
Message-ID: <15938.11839.289136.460068@gargle.gargle.HOWL>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 6 Feb 2003 10:35:32 +0100 writes:

>>>>> "BernPf" == Pfaff, Bernhard <Bernhard.Pfaff at drkw.com>
>>>>>     on Wed, 5 Feb 2003 15:55:42 +0100 writes:


    BernPf> I am using the cluster package and by the generation
    BernPf> of plot.partition I ran into the problem that an
    BernPf> alternative title overlaps the default title.

    >>> plot.partition(clara.14,which.plot=2,stand=TRUE, 
    >>> main="Silhouette plot of 14 clusters")

    MM> { using an explicit method call which is ``discouraged''.
    MM> Simply using  plot(.......) gives the same result. }

    BernPf> The manual states that all optional arguments for
    BernPf> clusplot.default may also be supplied to
    BernPf> plot.partition(). Altering the title in clusplot()
    BernPf> works.  Question: What am I doing wrong and what
    BernPf> would be the correct way to insert the graphic title
    BernPf> "Silhouette plot of 14 clusters" alone?

Instead of patching, there's a much easier solution, I had
forgotten:
	plot(silhouette(clara.14), main = "Silhouette plot of 14 clusters")

calling the plot.silhouette() method indirectly which has its own
help page.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From maechler at stat.math.ethz.ch  Thu Feb  6 10:51:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Feb  6 10:51:02 2003
Subject: [R] function 'silhouette' in package 'cluster'
In-Reply-To: <20030206083727.GC12630578@genome.cbs.dtu.dk>
References: <20030206083727.GC12630578@genome.cbs.dtu.dk>
Message-ID: <15938.12284.424038.744430@gargle.gargle.HOWL>

Hi Laurent,
I'm the maintainer of the cluster package and had introduced the
silhoutte() function a while ago to make the original Rousseeuw
code more transparent and flexible. 
Does
   example(silhouette)
work ok?

If not, type traceback() after the error {and send the results
to me}.  If it does work,
can you please give a reproducible example of its failure?

Thank you,
Martin

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From s.lewis at public-health.ucl.ac.uk  Thu Feb  6 12:23:02 2003
From: s.lewis at public-health.ucl.ac.uk (Sarah Lewis)
Date: Thu Feb  6 12:23:02 2003
Subject: [R] Graphical display problem
Message-ID: <3E424580.13440.4749D5@localhost>

I have downloaded a copy of Rgui for windows, but I am having 
trouble visualising graphic imagines in this package. When I run 
the demo : demo (graphics) the system crashes and no graphs 
appear. I wonder if you could offer me some advice please?

Thank you
Sarah Lewis

Department of Epidemiology and Public Health
UCL
1-19 Torrington Place 
London
WE1C 6BT
Tel: (+44) 0207 6791682



From baron at cattell.psych.upenn.edu  Thu Feb  6 12:29:03 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Thu Feb  6 12:29:03 2003
Subject: [R] big ps-files
In-Reply-To: <3E422D4A.EAE59472@hi.is>; from helgito@hi.is on Thu, Feb 06, 2003 at 09:39:23AM +0000
References: <Pine.LNX.4.44.0302051312010.23732-100000@gannet.stats> <3E422D4A.EAE59472@hi.is>
Message-ID: <20030206062830.A1803@cattell.psych.upenn.edu>

On 02/06/03 09:39, Helgi Tomasson wrote:

>The reason for my question is that a pdf-publication site is asking for a
>total size of document
>less than 2MB.   My R-graphs are simple plots of many points. I migth try to
>tell the same story by
>using fewer points.  An old (10 years +) Splus gave a particular graph 68k
>wheras the corresponding
>R was something like 1MB+.  My latex documents therefore become huge.  The
>explanation I got was
>that Splus used some kind of compression optimization which was absent in R.
>
>Perhaps it is better to try to generate other form of the graph than ps or
>to generate the
>graph using a subsample of the points.

You say a "pdf-publication."  Pdf itself is compressed.  So when
you convert to pdf, the figure should get smaller.  Apparently
this is not happening.

You might try producing pdf directly from R instead of ps.

Or use ps2pdf on the output of R, then use pdflatex.

Or use R's xfig output and then use xfig to produce the eps (and
then convert to ps), but I'm not sure that xfig will be any
smaller.

Or make the graphs smaller using par().  Then, when you include
them in your LaTeX document, blow them up again using (e.g.) 
includegraphicx[width=4in]{...}.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From dmurdoch at pair.com  Thu Feb  6 12:34:02 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu Feb  6 12:34:02 2003
Subject: [R] Bug in recording (Windows graphical device)
In-Reply-To: <54DE9A561AD20C4D9FF88B116965420E4E5DD5@postix.nrpa.no>
References: <54DE9A561AD20C4D9FF88B116965420E4E5DD5@postix.nrpa.no>
Message-ID: <nuh44vo9a04bb9u6t4tdphjpbusv5e2m03@4ax.com>

On Wed, 5 Feb 2003 16:01:10 +0100 , you wrote:

>I can send data and complete scripts if someone needs them to investigate
>the problem.

Could you please do that?  I'll take a look.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Thu Feb  6 12:38:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb  6 12:38:03 2003
Subject: [R] big ps-files
In-Reply-To: <20030206062830.A1803@cattell.psych.upenn.edu>
Message-ID: <Pine.LNX.4.44.0302061129420.11633-100000@gannet.stats>

On Thu, 6 Feb 2003, Jonathan Baron wrote:

> On 02/06/03 09:39, Helgi Tomasson wrote:
> 
> >The reason for my question is that a pdf-publication site is asking for a
> >total size of document
> >less than 2MB.   My R-graphs are simple plots of many points. I migth try to
> >tell the same story by
> >using fewer points.  An old (10 years +) Splus gave a particular graph 68k
> >wheras the corresponding
> >R was something like 1MB+.  My latex documents therefore become huge.  The
> >explanation I got was
> >that Splus used some kind of compression optimization which was absent in R.
> >
> >Perhaps it is better to try to generate other form of the graph than ps or
> >to generate the
> >graph using a subsample of the points.
> 
> You say a "pdf-publication."  Pdf itself is compressed.  So when
> you convert to pdf, the figure should get smaller.  Apparently
> this is not happening.

PDF *may* be compressed.  Distilling R ps output makes much smaller 
figures.

> You might try producing pdf directly from R instead of ps.

R's pdf is not compressed, BTW.

> Or use ps2pdf on the output of R, then use pdflatex.

Much better to use Distiller if you have it.

> Or use R's xfig output and then use xfig to produce the eps (and
> then convert to ps), but I'm not sure that xfig will be any
> smaller.
> 
> Or make the graphs smaller using par().  Then, when you include
> them in your LaTeX document, blow them up again using (e.g.) 
> includegraphicx[width=4in]{...}.

That should make almost no difference.

More than 2-3x difference is unusual, but then a 1Mb+ plot from R is 
unusual.  I do suggest you try to make a better graph  as the first step.

We know R's .ps and .pdf output could be optimized and compressed.  But 
that's not something the R developers are interested in, so any 
volunteers?

As a final point, if S-PLUS does what you want, why not use it?  I 
normally do for my publication-quality graphs ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Feb  6 12:42:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb  6 12:42:04 2003
Subject: [R] Graphical display problem
In-Reply-To: <3E424580.13440.4749D5@localhost>
Message-ID: <Pine.LNX.4.44.0302061137520.11633-100000@gannet.stats>

On Thu, 6 Feb 2003, Sarah Lewis wrote:

> I have downloaded a copy of Rgui for windows, but I am having 
> trouble visualising graphic imagines in this package. When I run 
> the demo : demo (graphics) the system crashes and no graphs 
> appear. I wonder if you could offer me some advice please?

Re-install Windows, or at least make sure your Windows installation has 
nothing interfering with programs, like a screen manager.

Less drastically, try using a different Windows machine.

Assuming you downloaded rw1062.exe (Rgui for windows is not available 
separately) and you checked the md5 sums (see the download area), this has 
worked for very many other people and is most likely a problem in your OS 
installation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From murdoch at stats.uwo.ca  Thu Feb  6 15:31:05 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu Feb  6 15:31:05 2003
Subject: [R] (no subject)
In-Reply-To: <3E416715.97847709@noaa.gov>
References: <3E416715.97847709@noaa.gov>
Message-ID: <75s44vch4g23g6tue0qderofse2jl06o37@4ax.com>

On Wed, 05 Feb 2003 14:33:41 -0500, you wrote in message
<3E416715.97847709 at noaa.gov>:

>Hello everyone,
>
> I am a new beginner and I want to know how to use Splus object in R and how to convert each other?

You can often use "dump" to convert an object to a text representation
and have it usable in the other package.  This works for simple
objects like vectors, and should work for data frames (there might be
exceptions, I'm not sure).

For more complicated objects (e.g. the result of a linear model fit)
you'll probably find that the objects can't easily be transferred.  

Functions can often be transferred, but there might be subtle changes
in behaviour (due to different libraries and scoping rules);  test
them very carefully.

Duncan Murdoch



From mike.prager at noaa.gov  Thu Feb  6 15:46:03 2003
From: mike.prager at noaa.gov (Mike Prager)
Date: Thu Feb  6 15:46:03 2003
Subject: [R] Graphical display problem
References: <3E424580.13440.4749D5@localhost>
Message-ID: <3E4274CB.8050301@noaa.gov>

A similar problem was solved for me by re-installing the latest Windows 
service pack.

Mike Prager

Sarah Lewis wrote:

>I have downloaded a copy of Rgui for windows, but I am having 
>trouble visualising graphic imagines in this package. When I run 
>the demo : demo (graphics) the system crashes and no graphs 
>appear. I wonder if you could offer me some advice please?
>
>Thank you
>Sarah Lewis
>
>Department of Epidemiology and Public Health
>UCL
>1-19 Torrington Place 
>London
>WE1C 6BT
>Tel: (+44) 0207 6791682
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From ririzarr at jhsph.edu  Thu Feb  6 17:02:03 2003
From: ririzarr at jhsph.edu (Rafael A. Irizarry)
Date: Thu Feb  6 17:02:03 2003
Subject: [R] rdbi segmentation fault (fwd)
Message-ID: <Pine.LNX.4.33.0302061056430.16795-100000@localhost.localdomain>

one more bit of information about this problem. If I start R as the 
user "postgres" i dont have the segmentation fault.

---------- Forwarded message ----------
Date: Wed, 5 Feb 2003 19:19:39 -0500 (EST)
From: Rafael A. Irizarry <ririzarr at jhsph.edu>
Reply-To: rafa at jhu.edu
To: "R-Help (E-mail)" <r-help at r-project.org>
Subject: rdbi segmentation fault

hi! i am experiencing the same behaviour explained here:

http://finzi.psych.upenn.edu/R/Rhelp02/archive/2482.html 
(i copied the message below)

has anybody found a solution?

here is the code that gives me a segmentation fault
 library(Rdbi)
 library(Rdbi.PgSQL)
 
 conn <- dbConnect(PgSQL(), dbname = "PGA")
 tmp <- "create table test ( expid int, name varchar(128));" 
 result <- dbSendQuery(conn,tmp)
 dbClearResult(result) 

the last line can be substituted by
 dbDisconnect(conn)
and you get a segmentation fault too.
 
The database PGA does exist and the dbSendQuery does create a table (i
checked via psql)

i followed the instructions given by tim (see url or msg below) and im
sending (what think is) the backtrace:
Program received signal SIGSEGV, Segmentation fault.
Rf_getAttrib (vec=0x8b50cd0, name=0x81d19b8) at attrib.c:93
93		if (TAG(s) == name) {
(gdb) backtrace
#0  Rf_getAttrib (vec=0x8b50cd0, name=0x81d19b8) at attrib.c:93
#1  0x080c0a8f in Rf_usemethod (generic=0xbffff0c0 "print", obj=0x8b50cd0, 
    call=0x880c5a0, args=0x81d1b08, rho=0x89dd900, callrho=0x81e6f68, 
    defrho=0x81e6f14, ans=0xbffff0bc) at objects.c:271
#2  0x080c1058 in do_usemethod (call=0x880c5a0, op=0x81e4f80, 
args=0x880c5bc, 
    env=0x89dd900) at objects.c:409
#3  0x0809cd29 in Rf_eval (e=0x880c5a0, rho=0x89dd900) at eval.c:404
#4  0x0809d26d in Rf_applyClosure (call=0x89de354, op=0x880c4c0, 
    arglist=0x89dd874, rho=0x81e6f68, suppliedenv=0x81d1b08) at eval.c:595
#5  0x0809cf1d in Rf_eval (e=0x89de354, rho=0x81e6f68) at eval.c:439
#6  0x080f013c in Rf_PrintValueEnv (s=0x8b50cd0, env=0x81e6f68) at 
print.c:662
#7  0x080b5597 in Rf_ReplIteration (rho=0x81e6f68, savestack=0, 
browselevel=0, 
    state=0xbffff550) at main.c:236
#8  0x080b56ad in R_ReplConsole (rho=0x81e6f68, savestack=0, 
browselevel=0)
    at main.c:280
#9  0x080b5d4b in run_Rmainloop () at main.c:579
#10 0x0811570e in main (ac=1, av=0xbffffa34) at system.c:99
#11 0x42017499 in __libc_start_main () from /lib/i686/libc.so.6


thanks,
rafael

MESSGAGE from archive:

I've not seen this behavior. Try "R -d gdb" and then type "run" at the
gdb prompt. Run your R session until the seg fault and send me the
backtrace. Thanks.

Tim

On Thu, 2002-04-25 at 18:05, Andrew Schuh wrote:
> I can use the Rdbi package to connect to a PostGreSQL server fine but
> when I use the dbDisconnect(), I get a segmentation error and it throws
> me out of R. I'm using RH7.2, R1.4.1, Rdbi 0.1-2, and Rdbi.PgSQL 0.1-2.
>
> Anyone else seen anything like this and have an possible answer?
>
> Andrew Schuh
>
>
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !) To: r-help-request at stat.math.ethz.ch
> 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._



From feldesmanm at pdx.edu  Thu Feb  6 17:34:05 2003
From: feldesmanm at pdx.edu (Marc Feldesman)
Date: Thu Feb  6 17:34:05 2003
Subject: [R] OT:  Xemacs config help
In-Reply-To: <3E4274CB.8050301@noaa.gov>
References: <3E424580.13440.4749D5@localhost>
	<3E4274CB.8050301@noaa.gov>
Message-ID: <20030206083416.4e5dc45b.feldesmanm@pdx.edu>

Sorry for the off topic post, but I haven't gotten help from
the usual places, and r-help is usually a treasure trove of
information.

I'm using xemacs 21.4 & ess & r 1.6.2 on RedHat Linux 8.0 (I
also have the same under Windows XP, but that isn't my
problem right now).

I'd like to "ps pretty print" R code to study after I've
written it.  I can do this with no problem from xemacs under
Windows, but in Linux, I keep getting the same error:

ps-postscript-code-directory isn't set properly

I've scoured the net, have posted to the xemacs group and
all I can find are others with the same problem, but no
solution.  I'm still pretty new at Linux & xemacs and so I'm
somewhat stuck.  I'd really prefer to be able to print the
code directly from xemacs in a somewhat prettier format than
I get.  For now, I simply exit from xemacs and go into
another editor (gedit) that gives me better control of the
output format.


Has anyone here seen this message (or know what it means
beyond the obvious fact that xemacs can't find something it
expects to find) and know how to fix it?  Please feel free
to reply b/c if you don't wish to reply here.  

Many thanks for any help you can offer.



From ripley at stats.ox.ac.uk  Thu Feb  6 18:15:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb  6 18:15:05 2003
Subject: [R] rdbi segmentation fault (fwd)
In-Reply-To: <Pine.LNX.4.33.0302061056430.16795-100000@localhost.localdomain>
Message-ID: <Pine.LNX.4.44.0302061709290.2467-100000@gannet.stats>

I got very similar behaviour with RODBC and the ODBC postgresql driver in
unixODBC, with postgresql 7.3.1. The segfault was in the driver.  
Getting the latest driver fixed it, so my guess is that something has
changed recently in the postgresql interface: I tried to find out what but 
the code had been changed in many minor ways.

On Thu, 6 Feb 2003, Rafael A. Irizarry wrote:

> one more bit of information about this problem. If I start R as the 
> user "postgres" i dont have the segmentation fault.
> 
> ---------- Forwarded message ----------
> Date: Wed, 5 Feb 2003 19:19:39 -0500 (EST)
> From: Rafael A. Irizarry <ririzarr at jhsph.edu>
> Reply-To: rafa at jhu.edu
> To: "R-Help (E-mail)" <r-help at r-project.org>
> Subject: rdbi segmentation fault
> 
> hi! i am experiencing the same behaviour explained here:
> 
> http://finzi.psych.upenn.edu/R/Rhelp02/archive/2482.html 
> (i copied the message below)
> 
> has anybody found a solution?
> 
> here is the code that gives me a segmentation fault
>  library(Rdbi)
>  library(Rdbi.PgSQL)
>  
>  conn <- dbConnect(PgSQL(), dbname = "PGA")
>  tmp <- "create table test ( expid int, name varchar(128));" 
>  result <- dbSendQuery(conn,tmp)
>  dbClearResult(result) 
> 
> the last line can be substituted by
>  dbDisconnect(conn)
> and you get a segmentation fault too.
>  
> The database PGA does exist and the dbSendQuery does create a table (i
> checked via psql)
> 
> i followed the instructions given by tim (see url or msg below) and im
> sending (what think is) the backtrace:
> Program received signal SIGSEGV, Segmentation fault.
> Rf_getAttrib (vec=0x8b50cd0, name=0x81d19b8) at attrib.c:93
> 93		if (TAG(s) == name) {
> (gdb) backtrace
> #0  Rf_getAttrib (vec=0x8b50cd0, name=0x81d19b8) at attrib.c:93
> #1  0x080c0a8f in Rf_usemethod (generic=0xbffff0c0 "print", obj=0x8b50cd0, 
>     call=0x880c5a0, args=0x81d1b08, rho=0x89dd900, callrho=0x81e6f68, 
>     defrho=0x81e6f14, ans=0xbffff0bc) at objects.c:271
> #2  0x080c1058 in do_usemethod (call=0x880c5a0, op=0x81e4f80, 
> args=0x880c5bc, 
>     env=0x89dd900) at objects.c:409
> #3  0x0809cd29 in Rf_eval (e=0x880c5a0, rho=0x89dd900) at eval.c:404
> #4  0x0809d26d in Rf_applyClosure (call=0x89de354, op=0x880c4c0, 
>     arglist=0x89dd874, rho=0x81e6f68, suppliedenv=0x81d1b08) at eval.c:595
> #5  0x0809cf1d in Rf_eval (e=0x89de354, rho=0x81e6f68) at eval.c:439
> #6  0x080f013c in Rf_PrintValueEnv (s=0x8b50cd0, env=0x81e6f68) at 
> print.c:662
> #7  0x080b5597 in Rf_ReplIteration (rho=0x81e6f68, savestack=0, 
> browselevel=0, 
>     state=0xbffff550) at main.c:236
> #8  0x080b56ad in R_ReplConsole (rho=0x81e6f68, savestack=0, 
> browselevel=0)
>     at main.c:280
> #9  0x080b5d4b in run_Rmainloop () at main.c:579
> #10 0x0811570e in main (ac=1, av=0xbffffa34) at system.c:99
> #11 0x42017499 in __libc_start_main () from /lib/i686/libc.so.6
> 
> 
> thanks,
> rafael
> 
> MESSGAGE from archive:
> 
> I've not seen this behavior. Try "R -d gdb" and then type "run" at the
> gdb prompt. Run your R session until the seg fault and send me the
> backtrace. Thanks.
> 
> Tim
> 
> On Thu, 2002-04-25 at 18:05, Andrew Schuh wrote:
> > I can use the Rdbi package to connect to a PostGreSQL server fine but
> > when I use the dbDisconnect(), I get a segmentation error and it throws
> > me out of R. I'm using RH7.2, R1.4.1, Rdbi 0.1-2, and Rdbi.PgSQL 0.1-2.
> >
> > Anyone else seen anything like this and have an possible answer?
> >
> > Andrew Schuh
> >
> >
> > 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !) To: r-help-request at stat.math.ethz.ch
> > 
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From RexBryan1 at attbi.com  Thu Feb  6 18:24:02 2003
From: RexBryan1 at attbi.com (Rex_Bryan@urscorp.com)
Date: Thu Feb  6 18:24:02 2003
Subject: [R] Fw: Plotting in subareas using par(fig=)  parameter
Message-ID: <006501c2ce05$1c7911d0$3182fd0c@dell1700>

Any idea why I can no longer plot two graphs on the same graphics device
using the par(fig=) parameter?
A simpler par(mfrow=c(1,2)) does work, showing the two plots side-by-side,
but I would like the first
to be larger.   This simple example fails:


x<-c(1,1,NA,2,2,NA,3,3)
y<-c(2,4,NA,3,5,NA,1,4)

par(fig=c(0,2/3,0,1))
plot(x,y)

par(fig=c(2/3,1,0,1))
qqnorm(x)

When plotted, the last figure qqnorm(x) is alone on the graphics display.
The first figure plot(x,y) disapears.
I'm even more puzzled in that I'm sure that I had this type of command
working before.

REX



From sundar.dorai-raj at pdf.com  Thu Feb  6 18:31:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu Feb  6 18:31:03 2003
Subject: [R] Fw: Plotting in subareas using par(fig=)  parameter
References: <006501c2ce05$1c7911d0$3182fd0c@dell1700>
Message-ID: <3E429B80.9080607@pdf.com>

Try:

R> par(fig=c(0,2/3,0,1))
R> plot(x,y)
R> par(fig=c(2/3,1,0,1), new = TRUE)
R> qqnorm(x)
R>

 From ?par:

      `new' logical, defaulting to `FALSE'.  If set to `TRUE', the next
           high-level plotting command (actually `plot.new') should not
           clean the frame before drawing ``as if it was on a new
           device''.

Regards,
Sundar

Rex_Bryan at urscorp.com wrote:
> Any idea why I can no longer plot two graphs on the same graphics device
> using the par(fig=) parameter?
> A simpler par(mfrow=c(1,2)) does work, showing the two plots side-by-side,
> but I would like the first
> to be larger.   This simple example fails:
> 
> 
> x<-c(1,1,NA,2,2,NA,3,3)
> y<-c(2,4,NA,3,5,NA,1,4)
> 
> par(fig=c(0,2/3,0,1))
> plot(x,y)
> 
> par(fig=c(2/3,1,0,1))
> qqnorm(x)
> 
> When plotted, the last figure qqnorm(x) is alone on the graphics display.
> The first figure plot(x,y) disapears.
> I'm even more puzzled in that I'm sure that I had this type of command
> working before.
> 
> REX
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Thu Feb  6 18:35:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb  6 18:35:03 2003
Subject: [R] Fw: Plotting in subareas using par(fig=)  parameter
In-Reply-To: <006501c2ce05$1c7911d0$3182fd0c@dell1700>
Message-ID: <Pine.LNX.4.44.0302061731080.2619-100000@gannet.stats>

On Thu, 6 Feb 2003, Rex_Bryan at urscorp.com wrote:

> Any idea why I can no longer plot two graphs on the same graphics device
> using the par(fig=) parameter?
> A simpler par(mfrow=c(1,2)) does work, showing the two plots side-by-side,
> but I would like the first
> to be larger.   This simple example fails:
> 
> 
> x<-c(1,1,NA,2,2,NA,3,3)
> y<-c(2,4,NA,3,5,NA,1,4)
> 
> par(fig=c(0,2/3,0,1))
> plot(x,y)
> 
> par(fig=c(2/3,1,0,1))

add par(new=TRUE) here, as you want to plot again in the same device 
region.

> qqnorm(x)
> 
> When plotted, the last figure qqnorm(x) is alone on the graphics display.
> The first figure plot(x,y) disapears.
> I'm even more puzzled in that I'm sure that I had this type of command
> working before.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From f0z6305 at labs.tamu.edu  Thu Feb  6 19:04:03 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu Feb  6 19:04:03 2003
Subject: [R] Confused by SVD and Eigenvector Decomposition in PCA
Message-ID: <000501c2ce0a$068e7770$8bd75ba5@IE.TAMU.EDU>

Hey, All

In principal component analysis (PCA), we want to know how many percentage
the first principal component explain the total variances among the data.

Assume the data matrix X is zero-meaned, and
I used the following procedures:
C = covriance(X) %% calculate the covariance matrix;
[EVector,EValues]=eig(C) %%
L = diag(EValues) %%L is a column vector with eigenvalues as the elements
percent = L(1)/sum(L);


Others argue using Sigular Value Decomposition(SVD) to
calculate the same quantity, as:
[U,S,V]=svd(X);
L = diag(S);
L = L.^2;
percent = L(1)/sum(L);


So which way is the correct method to calculate the percentage explained by
the first principal component?

Thanks for your advices on this.

Fred



From hennig at stat.math.ethz.ch  Thu Feb  6 19:08:05 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Thu Feb  6 19:08:05 2003
Subject: [R] svm
Message-ID: <Pine.LNX.4.44.0302061900240.6299-100000@florence>

Hello list,

I want to apply svm from library e1071, and I want to supply class weights.
I do not really understand the help entry (and there is no example)

class.weights: a named vector of weights for the different classes,
          used for asymetric class sizes. Not all factor levels have to
          be supplied (default weight: 1). All components have to be
          named.

I have two classes, factor levels are 1 (2000 cases, say) and 2 (1000
cases). How has the entry for class.weights to look like? (I'm more
interested in the syntax than what the weight should be, but if you know,
please tell me...)

Best,
Christian


-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de



From pkleiber at honlab.nmfs.hawaii.edu  Thu Feb  6 19:21:02 2003
From: pkleiber at honlab.nmfs.hawaii.edu (Pierre Kleiber)
Date: Thu Feb  6 19:21:02 2003
Subject: [R] .Rprofile, .Rfirst, and .Rdata
References: <86008410-399E-11D7-872F-000393DBCEC2@yahoo.com>
Message-ID: <3E42A756.2090102@honlab.nmfs.hawaii.edu>

For me, it's useful to have local versions of .First in the working
directories of each project.  I put global startup stuff in .Rprofile 
and startup stuff particular to each project in the .First-s.  I've 
always thought that .First was designed for that purpose.

Pierre Kleiber             Email: pkleiber at honlab.nmfs.hawaii.edu
Fishery Biologist                     Tel: 808 983-5399/737-7544
NOAA FISHERIES - Honolulu Laboratory         Fax: 808 983-2902


David Richmond wrote:
> On Wednesday, February 5, 2003, at 09:30  PM, Henrik Bengtsson wrote:
> 
>> What do you have in .First() that you can not have directly in the
>> .Rprofile script? For example:
>>
> 
> Nothing that I can think of, but it's the principle of the thing. If i 
> did have a reason to change .First, how would I do it ? More generally, 
> suppose I want to ensure a variable is set to a certain value in 
> .Rprofile, how can I be sure that R.data won't overwrite it? It just 
> seems like loading .Rdata after .Rprofile makes it difficult to change 
> things easily.
> 
> 
>> # ~/.Rprofile
>> cat("Running my .Rprofile...");
>> library(modreg)
>> cat("Running my .Rprofile...done");
>>
>> Henrik Bengtsson
>>
>>> -----Original Message-----
>>> From: r-help-admin at stat.math.ethz.ch
>>> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of David Richmond
>>> Sent: den 6 februari 2003 13:57
>>> To: r-help at stat.math.ethz.ch
>>> Subject: [R] .Rprofile, .Rfirst, and .Rdata
>>>
>>>
>>> Hi all,
>>>     After a short hiatus away from R I have found that it's
>>> changed a bit.
>>> I used to keep a definition of .First in .Rprofile that did a
>>> couple of
>>> things on startup (load a couple of libraries). Now, I've discovered
>>> that when I change the definition of .First in .Rprofile it doesn't
>>> change anything when I start up, because .First is held over
>>> in .Rdata
>>> from the last session. The manual states that now .Rdata is loaded
>>> last, as intended. My question is, how do I change what's in
>>> .First (or
>>> any other variable, for that matter), if .Rdata will always
>>> override my
>>> changes? (I'd prefer not to have to do it manually, and I'd prefer to
>>> have all the other data preserved, rather than just leaving
>>> out .Rdata)
>>>
>>> Dave R.
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
>>>
>>>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From david.meyer at ci.tuwien.ac.at  Thu Feb  6 19:25:13 2003
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Thu Feb  6 19:25:13 2003
Subject: [R] svm
References: <Pine.LNX.4.44.0302061900240.6299-100000@florence>
Message-ID: <3E42A796.8FA4EC31@ci.tuwien.ac.at>

Christian Hennig wrote:
> 
> Hello list,
> 
> I want to apply svm from library e1071, and I want to supply class weights.
> I do not really understand the help entry (and there is no example)
> 
> class.weights: a named vector of weights for the different classes,
>           used for asymetric class sizes. Not all factor levels have to
>           be supplied (default weight: 1). All components have to be
>           named.
> 
> I have two classes, factor levels are 1 (2000 cases, say) and 2 (1000
> cases). How has the entry for class.weights to look like? (I'm more
> interested in the syntax than what the weight should be, but if you know,
> please tell me...)

for example, consider the two classes `male' and `female':

svm(..., class.weights = c(male=0.4, female=0.6))

g.,
-d

> 
> Best,
> Christian
> 
> --
> ***********************************************************************
> Christian Hennig
> Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
> and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
> hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
> hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
> #######################################################################
> ich empfehle www.boag.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
        Mag. David Meyer            Wiedner Hauptstrasse 8-10
Vienna University of Technology     A-1040 Vienna/AUSTRIA
         Department of              Tel.: (+431) 58801/10772
Statistics and Probability Theory   Fax.: (+431) 58801/10798



From sundar.dorai-raj at pdf.com  Thu Feb  6 20:01:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu Feb  6 20:01:03 2003
Subject: [R] options(chmhelp = TRUE)
Message-ID: <3E42B0B4.2000800@pdf.com>

Hi all,
   Here's a curosity I ran into since upgrading to 1.6.2 (precompiled 
for Windows). When using the chm help I get the following warning. I saw 
a recent post regarding this as a new warning (``dyn.load warning 
message in R1.6.2 on Windows XP'' dated 1/28/03), but not in the context 
of the help system. The warning only appears once and does not prevent 
the chm file from opening, so it's more of a minor annoyance. Should I 
fill out a bug report?


R> ?ls # use Rd help
R> options(chmhelp = TRUE)
R> ?ls # use chm help
Warning message:
DLL attempted to change FPU control word from 8001f to 9001f
R> ?ls # open again, but this time no warning
R> version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.2
year     2003
month    01
day      10
language R


Regards,
Sundar



From andy_liaw at merck.com  Thu Feb  6 20:10:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Feb  6 20:10:03 2003
Subject: [R] options(chmhelp = TRUE)
Message-ID: <3A822319EB35174CA3714066D590DCD534BC5A@usrymx25.merck.com>

This is caused by a bug in a dll that MS Explorer loads when you ask for
compiled help (which, as I understand, uses MS Explorer).  The warning from
R is to warn you that there's a buggy dll, but R is correcting it.

Seem to recall that someone mentioned that upgrading Explorer eliminated the
problem.

Andy

> -----Original Message-----
> From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at pdf.com]
> Sent: Thursday, February 06, 2003 2:00 PM
> To: R-help
> Subject: [R] options(chmhelp = TRUE)
> 
> 
> Hi all,
>    Here's a curosity I ran into since upgrading to 1.6.2 (precompiled 
> for Windows). When using the chm help I get the following 
> warning. I saw 
> a recent post regarding this as a new warning (``dyn.load warning 
> message in R1.6.2 on Windows XP'' dated 1/28/03), but not in 
> the context 
> of the help system. The warning only appears once and does 
> not prevent 
> the chm file from opening, so it's more of a minor annoyance. 
> Should I 
> fill out a bug report?
> 
> 
> R> ?ls # use Rd help
> R> options(chmhelp = TRUE)
> R> ?ls # use chm help
> Warning message:
> DLL attempted to change FPU control word from 8001f to 9001f
> R> ?ls # open again, but this time no warning
> R> version
>           _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R
> 
> 
> Regards,
> Sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From andy_liaw at merck.com  Thu Feb  6 20:14:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Feb  6 20:14:03 2003
Subject: [R] Confused by SVD and Eigenvector Decomposition in PCA
Message-ID: <3A822319EB35174CA3714066D590DCD534BC5B@usrymx25.merck.com>

If I'm not mistaken, for positive semi-definite matrices, the eigenvalues
are equal to squared singular values, so you should get the same answer
either way.

The code you shown is definitely not R (looks like Matlab), so why are you
posting to R-help?

Andy

> -----Original Message-----
> From: Feng Zhang [mailto:f0z6305 at labs.tamu.edu]
> Sent: Thursday, February 06, 2003 1:03 PM
> To: R-Help
> Subject: [R] Confused by SVD and Eigenvector Decomposition in PCA
> 
> 
> Hey, All
> 
> In principal component analysis (PCA), we want to know how 
> many percentage
> the first principal component explain the total variances 
> among the data.
> 
> Assume the data matrix X is zero-meaned, and
> I used the following procedures:
> C = covriance(X) %% calculate the covariance matrix;
> [EVector,EValues]=eig(C) %%
> L = diag(EValues) %%L is a column vector with eigenvalues as 
> the elements
> percent = L(1)/sum(L);
> 
> 
> Others argue using Sigular Value Decomposition(SVD) to
> calculate the same quantity, as:
> [U,S,V]=svd(X);
> L = diag(S);
> L = L.^2;
> percent = L(1)/sum(L);
> 
> 
> So which way is the correct method to calculate the 
> percentage explained by
> the first principal component?
> 
> Thanks for your advices on this.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From mschwartz at medanalytics.com  Thu Feb  6 20:18:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu Feb  6 20:18:03 2003
Subject: [R] options(chmhelp = TRUE)
In-Reply-To: <3E42B0B4.2000800@pdf.com>
Message-ID: <006301c2ce14$60126040$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Sundar Dorai-Raj
>Sent: Thursday, February 06, 2003 1:00 PM
>To: R-help
>Subject: [R] options(chmhelp = TRUE)
>
>
>Hi all,
>   Here's a curosity I ran into since upgrading to 1.6.2 (precompiled

>for Windows). When using the chm help I get the following 
>warning. I saw 
>a recent post regarding this as a new warning (``dyn.load warning 
>message in R1.6.2 on Windows XP'' dated 1/28/03), but not in 
>the context 
>of the help system. The warning only appears once and does not
prevent 
>the chm file from opening, so it's more of a minor annoyance. Should
I 
>fill out a bug report?
>
>
>R> ?ls # use Rd help
>R> options(chmhelp = TRUE)
>R> ?ls # use chm help
>Warning message:
>DLL attempted to change FPU control word from 8001f to 9001f
>R> ?ls # open again, but this time no warning
>R> version
>          _
>platform i386-pc-mingw32
>arch     i386
>os       mingw32
>system   i386, mingw32
>status
>major    1
>minor    6.2
>year     2003
>month    01
>day      10
>language R
>
>
>Regards,
>Sundar


I just tried the same sequence using 1.6.2 on my WinXP Pro system and
it works fine. I can bring up the CHM help file without problem or
warning messages.

You might want to be sure that you have all WinXP/IE service packs and
updates installed, which includes some brand new security updates just
released today.  These latest updates are not yet on the MS Windows
Update site, so be sure to use the WinXP AutoUpdate feature.

HTH,

Marc Schwartz



From v_bill_pikounis at merck.com  Thu Feb  6 20:22:03 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Thu Feb  6 20:22:03 2003
Subject: [R] options(chmhelp = TRUE)
Message-ID: <E827328028C66044B4998F2EC353CD30031851B0@usrymx12.merck.com>

I have received this too each time I launch an R console and a new CHTML
instance, using R1.6.2 on Windows NT.  If I close the CHTML window, R
crashes.

Perhaps related, the Search tab in the CHTML window always returns "No
topics found" for me regardless of what keyword/phrase is entered for the
"base" and "recommended" packages (e.g. boot, lattice, nlme, etc) that were
included in the binary installer from CRAN. (I seem to recall this might
have previously been an issue discussed in R-help).  The Windows CHTML
search widget for MASS and other packages such as Hmisc seems to work as
expected though.

Best Regards,
Bill

> -----Original Message-----
> From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at pdf.com]
> Sent: Thursday, February 06, 2003 2:00 PM
> To: R-help
> Subject: [R] options(chmhelp = TRUE)
> 
> 
> Hi all,
>    Here's a curosity I ran into since upgrading to 1.6.2 (precompiled 
> for Windows). When using the chm help I get the following 
> warning. I saw 
> a recent post regarding this as a new warning (``dyn.load warning 
> message in R1.6.2 on Windows XP'' dated 1/28/03), but not in 
> the context 
> of the help system. The warning only appears once and does 
> not prevent 
> the chm file from opening, so it's more of a minor annoyance. 
> Should I 
> fill out a bug report?
> 
> 
> R> ?ls # use Rd help
> R> options(chmhelp = TRUE)
> R> ?ls # use chm help
> Warning message:
> DLL attempted to change FPU control word from 8001f to 9001f
> R> ?ls # open again, but this time no warning
> R> version
>           _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R
> 
> 
> Regards,
> Sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From sundar.dorai-raj at pdf.com  Thu Feb  6 20:26:06 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu Feb  6 20:26:06 2003
Subject: [R] options(chmhelp = TRUE)
References: <3A822319EB35174CA3714066D590DCD534BC5A@usrymx25.merck.com>
Message-ID: <3E42B5B7.6050801@pdf.com>

<sarcasm>
A bug in MSIE?? Say it isn't so...
</sarcasm>

Anyway, I have IE6.0 SP1 on Win2000, apparently the most recent version 
and the warning still appears. Perhaps this should go into rw-faq.

Sundar

Liaw, Andy wrote:
> This is caused by a bug in a dll that MS Explorer loads when you ask for
> compiled help (which, as I understand, uses MS Explorer).  The warning from
> R is to warn you that there's a buggy dll, but R is correcting it.
> 
> Seem to recall that someone mentioned that upgrading Explorer eliminated the
> problem.
> 
> Andy
> 
> 
>>-----Original Message-----
>>From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at pdf.com]
>>Sent: Thursday, February 06, 2003 2:00 PM
>>To: R-help
>>Subject: [R] options(chmhelp = TRUE)
>>
>>
>>Hi all,
>>   Here's a curosity I ran into since upgrading to 1.6.2 (precompiled 
>>for Windows). When using the chm help I get the following 
>>warning. I saw 
>>a recent post regarding this as a new warning (``dyn.load warning 
>>message in R1.6.2 on Windows XP'' dated 1/28/03), but not in 
>>the context 
>>of the help system. The warning only appears once and does 
>>not prevent 
>>the chm file from opening, so it's more of a minor annoyance. 
>>Should I 
>>fill out a bug report?
>>
>>
>>R> ?ls # use Rd help
>>R> options(chmhelp = TRUE)
>>R> ?ls # use chm help
>>Warning message:
>>DLL attempted to change FPU control word from 8001f to 9001f
>>R> ?ls # open again, but this time no warning
>>R> version
>>          _
>>platform i386-pc-mingw32
>>arch     i386
>>os       mingw32
>>system   i386, mingw32
>>status
>>major    1
>>minor    6.2
>>year     2003
>>month    01
>>day      10
>>language R
>>
>>
>>Regards,
>>Sundar
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
> 
> ------------------------------------------------------------------------------
> Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.
> 
> ==============================================================================
> 
>



From renaud.lancelot at cirad.fr  Thu Feb  6 20:34:02 2003
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Thu Feb  6 20:34:02 2003
Subject: [R] options(chmhelp = TRUE)
In-Reply-To: <3E42B0B4.2000800@pdf.com>
References: <3E42B0B4.2000800@pdf.com>
Message-ID: <3E42B832.5090406@cirad.fr>

Sundar Dorai-Raj wrote:
> Hi all,
>   Here's a curosity I ran into since upgrading to 1.6.2 (precompiled for 
> Windows). When using the chm help I get the following warning. I saw a 
> recent post regarding this as a new warning (``dyn.load warning message 
> in R1.6.2 on Windows XP'' dated 1/28/03), but not in the context of the 
> help system. The warning only appears once and does not prevent the chm 
> file from opening, so it's more of a minor annoyance. Should I fill out 
> a bug report?
> 
> 
> R> ?ls # use Rd help
> R> options(chmhelp = TRUE)
> R> ?ls # use chm help
> Warning message:
> DLL attempted to change FPU control word from 8001f to 9001f
> R> ?ls # open again, but this time no warning
> R> version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R
> 
> 
> Regards,
> Sundar

Got the same with Win98

R>options(chmhelp = TRUE)
R>?lm
Warning message:
DLL attempted to change FPU control word from 8001f to 9001f

platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.2
year     2003
month    01
day      10
language R


Best,

Renaud


-- 
Dr Renaud Lancelot, v?t?rinaire
CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
Programme Productions Animales
http://www.cirad.fr/presentation/programmes/prod-ani.shtml (Fran?ais)
http://www.cirad.fr/presentation/en/program-eng/prod-ani.shtml (English)

ISRA-LNERV                      tel    +221 832 49 02
BP 2057 Dakar-Hann              fax    +221 821 18 79 (CIRAD)
Senegal                         e-mail renaud.lancelot at cirad.fr



From mschwartz at medanalytics.com  Thu Feb  6 20:50:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu Feb  6 20:50:03 2003
Subject: [R] options(chmhelp = TRUE)
In-Reply-To: <3E42B5B7.6050801@pdf.com>
Message-ID: <006a01c2ce18$decb0820$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Sundar Dorai-Raj
>Sent: Thursday, February 06, 2003 1:21 PM
>To: Liaw, Andy
>Cc: R-help
>Subject: Re: [R] options(chmhelp = TRUE)
>
>
><sarcasm>
>A bug in MSIE?? Say it isn't so...
></sarcasm>
>
>Anyway, I have IE6.0 SP1 on Win2000, apparently the most 
>recent version 
>and the warning still appears. Perhaps this should go into rw-faq.
>
>Sundar

Sundar,

An error in my first reply as I thought that you were using WinXP. 

There are still some security updates for IE6 post SP1, which could
always be modifying something else besides just security
vulnerabilities. It is MS after all....  ;-)

This is available at

asp. It is a cumulative patch and is today's release.

There may also be some updates for Win2k that you might require, so I
would be sure that you have all of those installed as well, just to
cover all bases.

Regards,

Marc



From vijayasr at its.caltech.edu  Thu Feb  6 21:53:02 2003
From: vijayasr at its.caltech.edu (Vijaya Rao)
Date: Thu Feb  6 21:53:02 2003
Subject: [R] Looking for R-1.3.0 binary
Message-ID: <000801c2ce21$4a01a6a0$7436d783@oryza>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030206/1ab9762b/attachment.pl

From Benjamin.STABLER at odot.state.or.us  Thu Feb  6 22:06:03 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Thu Feb  6 22:06:03 2003
Subject: [R] UltraEdit R Syntax Highlighting File
Message-ID: <76A000A82289D411952F001083F9DD06039ACA32@exsalem4-bu.odot.state.or.us>

Attached as a text file is the UltraEdit R syntax highlighting file that I
wrote a few months ago and submitted to UltraEdit.  I resubmitted it
yesterday and it should be available soon.  Regards.

 <<r.txt>> 

Benjamin Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
555 13th Street NE, Suite 2
Salem, OR 97301  Ph: 503-986-4104


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: r.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030206/45f366fd/r.txt

From GPetris at uark.edu  Fri Feb  7 00:31:02 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Fri Feb  7 00:31:02 2003
Subject: [R] confint.lm in MASS
Message-ID: <200302062329.RAA01839@definetti.uark.edu>

I don't know if this has already come up in the list or elsewhere - a
quick search did't show anything relevant - but I think it's worth of
mention. The confint.lm function in package MASS doesn't work
correctly when called on a subset of parameters. The bug, easy to fix,
is that confidence intervals are computed for all parameters anyway,
and then assigned to a matrix which is too small for all of them (see
function body below). 
As I said, I think it's worth knowing it.

Best,
Giovanni


> confint.lm
function (object, parm, level = 0.95, ...) 
{
    cf <- coef(object)
    pnames <- names(cf)
    if (missing(parm)) 
        parm <- seq(along = pnames)
    else if (is.character(parm)) 
        parm <- match(parm, pnames, nomatch = 0)
    a <- (1 - level)/2
    a <- c(a, 1 - a)
    pct <- paste(round(100 * a, 1), "%")
    ci <- array(NA, dim = c(length(parm), 2), dimnames = list(pnames[parm], 
        pct))
    ses <- sqrt(diag(vcov(object)))
    fac <- qt(a, object$df.residual)
    ci[] <- cf + ses %o% fac
    ci
}

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From fharrell at virginia.edu  Fri Feb  7 01:20:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri Feb  7 01:20:03 2003
Subject: [R] OT:  Xemacs config help
In-Reply-To: <20030206083416.4e5dc45b.feldesmanm@pdx.edu>
References: <3E424580.13440.4749D5@localhost>
	<3E4274CB.8050301@noaa.gov>
	<20030206083416.4e5dc45b.feldesmanm@pdx.edu>
Message-ID: <20030206191921.72a923eb.fharrell@virginia.edu>

On Thu, 6 Feb 2003 08:34:16 -0800
Marc Feldesman <feldesmanm at pdx.edu> wrote:

> Sorry for the off topic post, but I haven't gotten help from
> the usual places, and r-help is usually a treasure trove of
> information.
> 
> I'm using xemacs 21.4 & ess & r 1.6.2 on RedHat Linux 8.0 (I
> also have the same under Windows XP, but that isn't my
> problem right now).
> 
> I'd like to "ps pretty print" R code to study after I've
> written it.  I can do this with no problem from xemacs under
> Windows, but in Linux, I keep getting the same error:
> 
> ps-postscript-code-directory isn't set properly
> 
> I've scoured the net, have posted to the xemacs group and
> all I can find are others with the same problem, but no
> solution.  I'm still pretty new at Linux & xemacs and so I'm
> somewhat stuck.  I'd really prefer to be able to print the
> code directly from xemacs in a somewhat prettier format than
> I get.  For now, I simply exit from xemacs and go into
> another editor (gedit) that gives me better control of the
> output format.
> 
> 
> Has anyone here seen this message (or know what it means
> beyond the obvious fact that xemacs can't find something it
> expects to find) and know how to fix it?  Please feel free
> to reply b/c if you don't wish to reply here.  
> 
> Many thanks for any help you can offer.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

This was tricky.  On RedHat 8.0 I had to put            
(setq ps-postscript-code-directory "/usr/share/emacs/21.2/etc")
in .xemacs/init.el

Frank
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From drf5n at mug.sys.virginia.edu  Fri Feb  7 03:02:03 2003
From: drf5n at mug.sys.virginia.edu (David Forrest)
Date: Fri Feb  7 03:02:03 2003
Subject: [R] Command line completion?
Message-ID: <Pine.LNX.4.33.0302062038190.7813-100000@mug.sys.virginia.edu>

Using R 1.6.0 on a redhat linux system, if I start typing at the prompt,
and hit <TAB>, it seems to do a completion based on the filenames in the
current directory, but upon hitting return after picking one of these
completions, it returns an 'Error: Object "xxx.yyy" not found'.

It /is/ helpful in completing a filename inside a function, (it even
supplies the closing '"'), but that doesn't seem especially useful.  It
seems that it would be nice for it to either attempt to source in the
object not found if it is a file name, or for the readline completion to
work on the list of objects and functions instead of the filenames.  As it
is, it seems to assume the right thing to do is something that it cannot.

Is there some bit of the documentation that explains the readline /
completion functions?

Thanks for your time,
Dave,
-- 
 Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
 drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/



From matt at wrdavis.net  Fri Feb  7 04:17:03 2003
From: matt at wrdavis.net (Matt Davis)
Date: Fri Feb  7 04:17:03 2003
Subject: [R] Importing Packages Using OS-X
Message-ID: <98A265C3-3A4A-11D7-A72B-000393582B82@wrdavis.net>

I am trying to import/load some new packages into my R (1.6.2 or 1.5.1) 
program.  Unfortunately there are a lot of problems that seem to occur.  
I cannot seem to sucessfuly  run any of the commands that should import 
the packages.
Some help with this matter would be greatly appreciated.  (A step by 
step process would be the best, especially how to load a predownloaded 
package (*.tar) into R.)
Matt Davis



From deleeuw at stat.ucla.edu  Fri Feb  7 04:53:02 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Fri Feb  7 04:53:02 2003
Subject: [R] Importing Packages Using OS-X
References: <98A265C3-3A4A-11D7-A72B-000393582B82@wrdavis.net>
Message-ID: <3E432D71.6090902@stat.ucla.edu>

Are you using Carbon R or Darwin R ? Do you want to load or
build packages ?

Matt Davis wrote:
> I am trying to import/load some new packages into my R (1.6.2 or 1.5.1) 
> program.  Unfortunately there are a lot of problems that seem to occur.  
> I cannot seem to sucessfuly  run any of the commands that should import 
> the packages.
> Some help with this matter would be greatly appreciated.  (A step by 
> step process would be the best, especially how to load a predownloaded 
> package (*.tar) into R.)
> Matt Davis
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From nklepeis at uclink4.berkeley.edu  Fri Feb  7 05:21:03 2003
From: nklepeis at uclink4.berkeley.edu (Neil Klepeis)
Date: Fri Feb  7 05:21:03 2003
Subject: [R] Postscript linewidth errors
Message-ID: <3E4334FA.1050405@uclink4.berkeley.edu>

Nothing in Rbugs or Rhelp on this that I could see:

[Redhat 7.3 (Intel); R 1.6.2]

R Postscript output contains a bunch of the following commands:

nan setlinewidth

And GNU Ghostscript 6.52 chokes with:

Error: /undefined in nan
Operand stack:
...

The figure is a fairly complex directed graph with varying linewidths. 
I am able to write the figure to the x11 and xfig devices just fine from 
within R, and even export to EPS from xfig with no problems. So it seems 
like a bug in the R postscript driver.

Anyone else see this?

-- 
______________________________________________________
Neil E. Klepeis, UC Berkeley, School of Public Health,
Berkeley, CA USA.
---
The most beautiful thing we can experience is the mysterious.
It is the source of all true art and science.  --Einstein



From matt at wrdavis.net  Fri Feb  7 05:33:02 2003
From: matt at wrdavis.net (Matt Davis)
Date: Fri Feb  7 05:33:02 2003
Subject: [R] Importing Packages Using OS-X
In-Reply-To: <3E432D71.6090902@stat.ucla.edu>
Message-ID: <17F1285A-3A55-11D7-98FE-000393582B82@wrdavis.net>

I forgot to mention that I am using carbon, and that I am just trying to 
load packages.
On Thursday, February 6, 2003, at 08:52  PM, Jan de Leeuw wrote:

> Are you using Carbon R or Darwin R ? Do you want to load or
> build packages ?
>
> Matt Davis wrote:
>> I am trying to import/load some new packages into my R (1.6.2 or 
>> 1.5.1) program.  Unfortunately there are a lot of problems that seem 
>> to occur.  I cannot seem to sucessfuly  run any of the commands that 
>> should import the packages.
>> Some help with this matter would be greatly appreciated.  (A step by 
>> step process would be the best, especially how to load a predownloaded 
>> package (*.tar) into R.)
>> Matt Davis
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>



From arv at ono.com  Fri Feb  7 09:32:03 2003
From: arv at ono.com (antonio rodriguez)
Date: Fri Feb  7 09:32:03 2003
Subject: [R] Confused by SVD and Eigenvector Decomposition in PCA
References: <000501c2ce0a$068e7770$8bd75ba5@IE.TAMU.EDU>
Message-ID: <006201c2ce83$f7e346e0$0300a8c0@ono>

Hi Feng,

AFIK SVD analysis provides a one-step method for computing all the
components of the eigen value problem, without the need to compute and
store big covariance matrices. And also the resulting decomposition is
computationally more stable and robust.

Cheers,

Antonio Rodriguez


----- Original Message -----
From: "Feng Zhang" <f0z6305 at labs.tamu.edu>
To: "R-Help" <r-help at stat.math.ethz.ch>
Sent: Thursday, February 06, 2003 7:03 PM
Subject: [R] Confused by SVD and Eigenvector Decomposition in PCA


> Hey, All
>
> In principal component analysis (PCA), we want to know how many
percentage
> the first principal component explain the total variances among the
data.
>
> Assume the data matrix X is zero-meaned, and
> I used the following procedures:
> C = covriance(X) %% calculate the covariance matrix;
> [EVector,EValues]=eig(C) %%
> L = diag(EValues) %%L is a column vector with eigenvalues as the
elements
> percent = L(1)/sum(L);
>
>
> Others argue using Sigular Value Decomposition(SVD) to
> calculate the same quantity, as:
> [U,S,V]=svd(X);
> L = diag(S);
> L = L.^2;
> percent = L(1)/sum(L);
>
>
> So which way is the correct method to calculate the percentage
explained by
> the first principal component?
>
> Thanks for your advices on this.
>
> Fred
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help


---



From andrejk at zrc-sazu.si  Fri Feb  7 11:05:06 2003
From: andrejk at zrc-sazu.si (Andrej Kveder)
Date: Fri Feb  7 11:05:06 2003
Subject: [R] a question regarding s-plus libraries and R
Message-ID: <FHEEJBDDCNPPNJEACDJAIEDBCJAA.andrejk@zrc-sazu.si>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030207/a590c50d/attachment.pl

From s195404 at student.uq.edu.au  Fri Feb  7 11:21:03 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri Feb  7 11:21:03 2003
Subject: [R] a question regarding s-plus libraries and R
In-Reply-To: <FHEEJBDDCNPPNJEACDJAIEDBCJAA.andrejk@zrc-sazu.si>
References: <FHEEJBDDCNPPNJEACDJAIEDBCJAA.andrejk@zrc-sazu.si>
Message-ID: <1044613230.3e43886e1cb30@my.uq.edu.au>

Andrej, you may need to be more explicit about the
precise capabilities that are lacking in R. For
instance, there is a package on CRAN called norm
that is based on work by Joseph Schafer. If you're
aware of this package and it doesn't do what you
want, perhaps there are others that do (survey,
hmisc, mice, etc).



Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting Andrej Kveder <andrejk at zrc-sazu.si>:

> Hi!
> 
> I am a relatively new user of R and I use it to prepare my dissertation. I
> have come to some very usefull and specific libraries written for S-PLUS 4
> and would like to use them in R. Is that possible? I just found out that one
> of these libraries has already been transfered to R, while 3 others have
> not. For the matter of beeing more exact I'm interested in the dealing with
> missing survey data and Joe Shafer has the routines in S posted on his web
> site. Could you advise how I could get them to work in R?
> 
> Thank you very much for the raply.
> 
> Best regards
> 
> Andrej
> 
> _________
> Andrej Kveder, M.A.
> researcher
> Institute of Medical Sciences SRS SASA; Novi trg 2, SI-1000 Ljubljana,
> Slovenia
> phone: +386 1 47 06 440   fax: +386 1 42 61 493
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From boiko at demogr.mpg.de  Fri Feb  7 11:49:03 2003
From: boiko at demogr.mpg.de (Serge Boiko)
Date: Fri Feb  7 11:49:03 2003
Subject: [R] postscript: can't center plot
In-Reply-To: <20030205223547.GA2085624@fry.research.att.com> (Deborah
 Swayne's message of "Wed, 5 Feb 2003 17:36:14 -0500")
References: <20030205223547.GA2085624@fry.research.att.com>
Message-ID: <m2znp848s1.fsf@boiko_linux.demogr.mpg.de>

Deborah, 
Perhaps, a good idea is to use eps output to include it into a LaTeX
document, in this manner you can format and layout your graphics 
exactly the way you want.
If you need more information, I'm ready for your disposal.
-Serge



From dmurdoch at pair.com  Fri Feb  7 12:53:02 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri Feb  7 12:53:02 2003
Subject: [R] options(chmhelp = TRUE)
In-Reply-To: <3E42B0B4.2000800@pdf.com>
References: <3E42B0B4.2000800@pdf.com>
Message-ID: <g7774vki6bnais97ilhnvsuv6fbmf4dmv8@4ax.com>

On Thu, 06 Feb 2003 13:00:04 -0600, you wrote:


>R> options(chmhelp = TRUE)
>R> ?ls # use chm help
>Warning message:
>DLL attempted to change FPU control word from 8001f to 9001f

As Andy said, that's a bug in one of the help system DLLs.  There are
a number of Windows DLLs that contain this bug. 

I'm thinking of changing the behaviour in 1.7.0, as follows:

 1.  By default, the bug will be silently corrected.
 2.  Optionally, it will print the warning you saw.
 3.  The option will be enabled for people testing packages.

Any comments?

Duncan Murdoch



From maechler at stat.math.ethz.ch  Fri Feb  7 14:19:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Feb  7 14:19:02 2003
Subject: [R] function 'silhouette' in package 'cluster'
In-Reply-To: <20030206083727.GC12630578@genome.cbs.dtu.dk>
References: <20030206083727.GC12630578@genome.cbs.dtu.dk>
Message-ID: <15939.45624.522732.206460@gargle.gargle.HOWL>

>>>>> "Laurent" == Laurent Gautier <laurent at cbs.dtu.dk>
>>>>>     on Thu, 6 Feb 2003 09:37:27 +0100 writes:

    Laurent> Dear all,
    Laurent> I am trying (without much success) to use the fuction 'silhouette'.
    Laurent> Would anyone encountered that before (or would know where I am wrong ?)

Lauren has sent me his data in the mean time.
He hit a bug: I see that the silhouette.default()
method does not work when you have only two clusters.
{Note that this is quite new function/method anyway, so that bug
 only bites those who do want the new functionality!}

For the interested ones: The reason is a subtle version of the
famous ``forgotten drop=FALSE'' :

Current silhouette.default has a line
   diC <- apply(dmatrix[!iC, iC], 2, function(r) tapply(r, x[!iC], mean))
which usually returns a (k-1)x Nj matrix (k = #{clusters}),
but for the case k=2 returns a vector instead of a 1-row matrix.
The solution is to wrap the RHS into an  rbind(.).

Since, from Laurent's example, I found that I could improve the
function further (by allowing a direct `dmatrix' argument
alternatively to `dist'), I post here the new version of the
silhouette.default method. This will be in the next version of
the cluster package, but that will appear only by the end of
February or so.

Regards,
Martin


silhouette.default <- function(x, dist, dmatrix, ...) {
    cll <- match.call()
    if(!is.null(cl <- x$clustering)) x <- cl
    n <- length(x)
    if(!all(x == round(x))) stop("`x' must only have integer codes")
    k <- length(clid <- sort(unique(x)))
    if(k <= 1 || k >= n)
        return(NA)
    ## check dist/dmatrix
    if(missing(dist)) {
        if(missing(dmatrix))
            stop("Need either a dissimilarity `dist' or diss.matrix `dmatrix'")
        if(is.null(dm <- dim(dmatrix)) || length(dm) != 2 || !all(n == dm))
            stop("`dmatrix' is not a dissimilarity matrix compatible to `x'")
    } else { # `dist'
        dist <- as.dist(dist) # hopefully
        if(n != attr(dist, "Size"))
            stop("clustering `x' and dissimilarity `dist' are incompatible")
        dmatrix <- as.matrix(dist)# so we can apply(.) below
    }
    wds <- matrix(NA, n,3, dimnames =
                  list(names(x), c("cluster","neighbor","sil_width")))
    for(j in 1:k) { # j-th cluster:
        Nj <- sum(iC <- x == clid[j])
        wds[iC, 1] <- j
        a.i <- if(Nj > 1) colSums(dmatrix[iC, iC])/(Nj - 1) else 0 # length(a.i)= Nj
        ## minimal distances to points in all other clusters:
        diC <- rbind(apply(dmatrix[!iC, iC], 2,
                           function(r) tapply(r, x[!iC], mean)))# (k-1) x Nj
        wds[iC,"neighbor"]  <- clid[-j][minC <- max.col(-t(diC))]
        b.i <- diC[cbind(minC, seq(minC))]
        s.i <- (b.i - a.i) / pmax(b.i, a.i)
        wds[iC,"sil_width"] <- s.i
    }
    attr(wds, "Ordered") <- FALSE
    attr(wds, "call") <- cll
    class(wds) <- "silhouette"
    wds
}


    Laurent> Please find below the R ouput. Thanks in advance,
    Laurent> L.


    >> s <- silhouette(ct, as.dist(metric))
    Laurent> Error in "[<-"(*tmp*, iC, "sil_width", value = s.i) : 
    Laurent> number of items to replace is not a multiple of replacement length
    Laurent> In addition: Warning messages: 
    Laurent> 1: longer object length
    Laurent> is not a multiple of shorter object length in: b.i - a.i 
    Laurent> 2: number of rows of result
    Laurent> is not a multiple of vector length (arg 2) in: cbind(mmm, as.vector(each)) 
    >> 
    >> traceback()
    Laurent> 2: silhouette.default(ct, as.dist(metric))
    Laurent> 1: silhouette(ct, as.dist(metric))

    >> str(ct)
    Laurent> Named int [1:2381] 1 1 1 1 1 2 2 2 1 1 ...
    Laurent> - attr(*, "names")= chr [1:2381] "5153" "22" "5185" "356" ...
    >> str(metric)
    Laurent> num [1:2381, 1:2381] 0.000 1.438 1.172 0.751 0.432 ...
    Laurent> - attr(*, "dimnames")=List of 2
    Laurent> ..$ : chr [1:2381] "5153" "22" "5185" "356" ...
    Laurent> ..$ : chr [1:2381] "5153" "22" "5185" "356" ...



From lecoutre at stat.ucl.ac.be  Fri Feb  7 14:27:03 2003
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Fri Feb  7 14:27:03 2003
Subject: [R] My remark on libraries
Message-ID: <5.1.1.5.2.20030207135447.00cbc8f0@stat4ux.stat.ucl.ac.be>

Hi R community,

These days, I am writing some functions to work with 2-ways frequency 
tables ; you know all this tuff about measures of association: Chisq and 
derived (phi, cramer's v), tau b, tau c, somer's d and so on.

So I consider all those functions could be gathered in a single R file, as 
they are coherent and dealing with the same problem / objective (analysis 
of crosstables). Nervertheless, I wouldn't say there is here enough stuff 
to juystify the creation of a library. First, there is here few material, 
second it is not enough to cover the practical problem; which should be the 
goal of a library.

In fact, I have also lot of others splitted files with R code suitable for 
different purposes. And I could easily imagine I am not the only one among 
R programmers... And at the end, this is pity that I can't share this code 
(and BTW that I can't benefit of other's one!)

I though the solution was to deliver my own (eric)misc library, you know... 
But then we would rapidly be overcome by all miscmisc from world, and it 
would be difficult to find specific functions with all that libraries.

To me, a possible solution would be to have a page on CRAN listing such R 
files. Then, everyone would be able to upload R files with a short comment 
(what does the functions do). I am thinking about something less "strict" 
than libraries: for that, no reason to test the code (programmer's 
responsability). Then, maybe sometimes there would be enough pieces of code 
on a statistical subject to justify the creation of a library (still with 
the mind: a library is a collection of tools designed to help on a precise 
situation).

While I'm at it, it would also be nice to have a shared page on 
screenshots/graphics. For sure, I really enjoy to use R to produce 
wonderfull graphics. Not only would it be nice sometimes to show them, but 
it would also be the occasion to demonstrate R possibilities for newcomers 
(think on color graphics including mathematics). R would never have enough 
publicity!

Eric


__________________________________________________

Eric Lecoutre           Informaticien/Statisticien
Institut de Statistique                        UCL

                               (+32) (0)10 47 30 50
                            lecoutre at stat.ucl.ac.be
     http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
__________________________________________________
Le vrai danger, ce n'est pas quand les ordinateurs
penseront comme des hommes, c'est quand les hommes
penseront comme des ordinateurs.     Sydney Harris



From phgrosjean at sciviews.org  Fri Feb  7 14:53:02 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri Feb  7 14:53:02 2003
Subject: [R] My remark on libraries
In-Reply-To: <5.1.1.5.2.20030207135447.00cbc8f0@stat4ux.stat.ucl.ac.be>
Message-ID: <MABBLJDICACNFOLGIHJOAEHLDDAA.phgrosjean@sciviews.org>

Eric,

What you propose is similar (but not exactly the same) as electronic
reference cards we discussed earlier here and in R-SIG-GUI. A code
repository and a graph gallery,...humm, why not! It seems appealing to me.
Somebody has to take the initiative to start it. So,... go ahead!

Bonne journee,

Philippe

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oceanologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



-----Original Message-----
From: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of Eric Lecoutre
Sent: vendredi 7 fevrier 2003 2:25
To: r-help at stat.math.ethz.ch
Subject: [R] My remark on libraries



Hi R community,

These days, I am writing some functions to work with 2-ways frequency
tables ; you know all this tuff about measures of association: Chisq and
derived (phi, cramer's v), tau b, tau c, somer's d and so on.

So I consider all those functions could be gathered in a single R file, as
they are coherent and dealing with the same problem / objective (analysis
of crosstables). Nervertheless, I wouldn't say there is here enough stuff
to juystify the creation of a library. First, there is here few material,
second it is not enough to cover the practical problem; which should be the
goal of a library.

In fact, I have also lot of others splitted files with R code suitable for
different purposes. And I could easily imagine I am not the only one among
R programmers... And at the end, this is pity that I can't share this code
(and BTW that I can't benefit of other's one!)

I though the solution was to deliver my own (eric)misc library, you know...
But then we would rapidly be overcome by all miscmisc from world, and it
would be difficult to find specific functions with all that libraries.

To me, a possible solution would be to have a page on CRAN listing such R
files. Then, everyone would be able to upload R files with a short comment
(what does the functions do). I am thinking about something less "strict"
than libraries: for that, no reason to test the code (programmer's
responsability). Then, maybe sometimes there would be enough pieces of code
on a statistical subject to justify the creation of a library (still with
the mind: a library is a collection of tools designed to help on a precise
situation).

While I'm at it, it would also be nice to have a shared page on
screenshots/graphics. For sure, I really enjoy to use R to produce
wonderfull graphics. Not only would it be nice sometimes to show them, but
it would also be the occasion to demonstrate R possibilities for newcomers
(think on color graphics including mathematics). R would never have enough
publicity!

Eric


__________________________________________________

Eric Lecoutre           Informaticien/Statisticien
Institut de Statistique                        UCL

                               (+32) (0)10 47 30 50
                            lecoutre at stat.ucl.ac.be
     http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
__________________________________________________
Le vrai danger, ce n'est pas quand les ordinateurs
penseront comme des hommes, c'est quand les hommes
penseront comme des ordinateurs.     Sydney Harris

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ben at zoo.ufl.edu  Fri Feb  7 14:57:03 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Fri Feb  7 14:57:03 2003
Subject: [R] My remark on libraries
In-Reply-To: <5.1.1.5.2.20030207135447.00cbc8f0@stat4ux.stat.ucl.ac.be>
Message-ID: <Pine.LNX.4.44.0302070843440.22079-100000@bolker.zoo.ufl.edu>

  This comes up from time to time; at the moment I can't find the thread
in the mailing list archives.  The advantage, obviously, would be to make
all this accumulated code available to the R community.  The disadvantage
would be that such a heap of code would be highly heterogeneous -- some
stuff would work, some wouldn't, some would work originally but obsolesce
-- and the good stuff would get lost anyway.  On the other hand, you're
right that it would be hard to find the functions one wanted in a set of
"miscmisc" packages (but would it be any harder than finding it in a
random heap of contributed code?)  
  I guess I don't have a good answer; I would encourage you to bundle your
stuff up into a little library, even if you don't think it's enough. (I am
equally guilty of laziness: I've written a variety of packages for
landscape generation, genetic stock analysis, 3D graphics, maximum
likelihood ... but while I have put them up on my own web page at
http://www.zoo.ufl.edu/bolker/R, I've never submitted them to CRAN for
most of the reasons you cite.)

http://lark.cc.ukans.edu/~pauljohn/R/statsRus.html
is a good collection of (tiny) bits and pieces, but it depends on a single 
person for updating (and for keeping it coherent ...)
  
  Ben Bolker



On Fri, 7 Feb 2003, Eric Lecoutre wrote:

> 
> Hi R community,
> 
> These days, I am writing some functions to work with 2-ways frequency 
> tables ; you know all this tuff about measures of association: Chisq and 
> derived (phi, cramer's v), tau b, tau c, somer's d and so on.
> 
> So I consider all those functions could be gathered in a single R file, as 
> they are coherent and dealing with the same problem / objective (analysis 
> of crosstables). Nervertheless, I wouldn't say there is here enough stuff 
> to juystify the creation of a library. First, there is here few material, 
> second it is not enough to cover the practical problem; which should be the 
> goal of a library.
> 
> In fact, I have also lot of others splitted files with R code suitable for 
> different purposes. And I could easily imagine I am not the only one among 
> R programmers... And at the end, this is pity that I can't share this code 
> (and BTW that I can't benefit of other's one!)
> 
> I though the solution was to deliver my own (eric)misc library, you know... 
> But then we would rapidly be overcome by all miscmisc from world, and it 
> would be difficult to find specific functions with all that libraries.
> 
> To me, a possible solution would be to have a page on CRAN listing such R 
> files. Then, everyone would be able to upload R files with a short comment 
> (what does the functions do). I am thinking about something less "strict" 
> than libraries: for that, no reason to test the code (programmer's 
> responsability). Then, maybe sometimes there would be enough pieces of code 
> on a statistical subject to justify the creation of a library (still with 
> the mind: a library is a collection of tools designed to help on a precise 
> situation).
> 
> While I'm at it, it would also be nice to have a shared page on 
> screenshots/graphics. For sure, I really enjoy to use R to produce 
> wonderfull graphics. Not only would it be nice sometimes to show them, but 
> it would also be the occasion to demonstrate R possibilities for newcomers 
> (think on color graphics including mathematics). R would never have enough 
> publicity!
> 
> Eric
> 
> 
> __________________________________________________
> 
> Eric Lecoutre           Informaticien/Statisticien
> Institut de Statistique                        UCL
> 
>                                (+32) (0)10 47 30 50
>                             lecoutre at stat.ucl.ac.be
>      http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
> __________________________________________________
> Le vrai danger, ce n'est pas quand les ordinateurs
> penseront comme des hommes, c'est quand les hommes
> penseront comme des ordinateurs.     Sydney Harris
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From baresel at wzw.tum.de  Fri Feb  7 15:05:09 2003
From: baresel at wzw.tum.de (=?iso-8859-1?Q?J=F6rg_Peter_Baresel?=)
Date: Fri Feb  7 15:05:09 2003
Subject: [R] RMySQL
Message-ID: <000d01c2ceb2$240fa1e0$1a7f288d@AGRARINF>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030207/6fd4981a/attachment.pl

From ripley at stats.ox.ac.uk  Fri Feb  7 15:20:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb  7 15:20:03 2003
Subject: [R] RMySQL
In-Reply-To: <000d01c2ceb2$240fa1e0$1a7f288d@AGRARINF>
Message-ID: <Pine.LNX.4.44.0302071413170.14476-100000@gannet.stats>

It needs package DBI: do you have that installed too?
See the dependency list for RMySQL in its DESCRIPTION file.

On Fri, 7 Feb 2003, J?rg Peter Baresel wrote:

> Being relatively new to R, I want to use R in connection with a MySQL database. 
> After installing (apparently sucessfully) the package RMySQL (R Version 1.6.2)
> the result is as follows:
> 
> > library(RMySQL)
> > con <- dbConnect(MySQL(), dbname= "test")
> Error: couldn't find function "dbConnect"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rgentlem at jimmy.harvard.edu  Fri Feb  7 15:31:06 2003
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Fri Feb  7 15:31:06 2003
Subject: [R] My remark on libraries
In-Reply-To: <Pine.LNX.4.44.0302070843440.22079-100000@bolker.zoo.ufl.edu>; from ben@zoo.ufl.edu on Fri, Feb 07, 2003 at 09:01:04AM -0500
References: <5.1.1.5.2.20030207135447.00cbc8f0@stat4ux.stat.ucl.ac.be> <Pine.LNX.4.44.0302070843440.22079-100000@bolker.zoo.ufl.edu>
Message-ID: <20030207092955.M8829@jimmy.harvard.edu>

Hi,
 This message is really informational -- some of us are trying to
 address these concerns -- the software is a few months away.

 First, I would like to second Ben's comments about the importance of
 both versioning and testing software, for this if for no other reason you
 should put your software into a package.

 Some of the distribution issues (and some of the dependency issues
 just mentioned on the MySQL thread) are being addressed. There is a
 (very alpha) version of reposTools at the Bioconductor site
 (www.bioconductor.org) that will make setting up your own website as an R
 repository (like CRAN) easier.

 In general, we will need to address some mechanism for attaching
 meta-data that is meaningful and searchable. This isn't easy nor is
 it a small project.

 Tools like install.packages and update.packages (-- our versions have
 a 2 as a suffix to avoid collisions), will try to resolve
 dependencies. There are a few other bells and whistles that need to
 be added -- but it seems to work most days.

 The Bioconductor mirror of CRAN has a suitable structure for trying
 this out (and there are some help files, that we try to keep in sync
 with the code base, but it is alpha)

 Robert


On Fri, Feb 07, 2003 at 09:01:04AM -0500, Ben Bolker wrote:
> 
>   This comes up from time to time; at the moment I can't find the thread
> in the mailing list archives.  The advantage, obviously, would be to make
> all this accumulated code available to the R community.  The disadvantage
> would be that such a heap of code would be highly heterogeneous -- some
> stuff would work, some wouldn't, some would work originally but obsolesce
> -- and the good stuff would get lost anyway.  On the other hand, you're
> right that it would be hard to find the functions one wanted in a set of
> "miscmisc" packages (but would it be any harder than finding it in a
> random heap of contributed code?)  
>   I guess I don't have a good answer; I would encourage you to bundle your
> stuff up into a little library, even if you don't think it's enough. (I am
> equally guilty of laziness: I've written a variety of packages for
> landscape generation, genetic stock analysis, 3D graphics, maximum
> likelihood ... but while I have put them up on my own web page at
> http://www.zoo.ufl.edu/bolker/R, I've never submitted them to CRAN for
> most of the reasons you cite.)
> 
> http://lark.cc.ukans.edu/~pauljohn/R/statsRus.html
> is a good collection of (tiny) bits and pieces, but it depends on a single 
> person for updating (and for keeping it coherent ...)
>   
>   Ben Bolker
> 
> 
> 
> On Fri, 7 Feb 2003, Eric Lecoutre wrote:
> 
> > 
> > Hi R community,
> > 
> > These days, I am writing some functions to work with 2-ways frequency 
> > tables ; you know all this tuff about measures of association: Chisq and 
> > derived (phi, cramer's v), tau b, tau c, somer's d and so on.
> > 
> > So I consider all those functions could be gathered in a single R file, as 
> > they are coherent and dealing with the same problem / objective (analysis 
> > of crosstables). Nervertheless, I wouldn't say there is here enough stuff 
> > to juystify the creation of a library. First, there is here few material, 
> > second it is not enough to cover the practical problem; which should be the 
> > goal of a library.
> > 
> > In fact, I have also lot of others splitted files with R code suitable for 
> > different purposes. And I could easily imagine I am not the only one among 
> > R programmers... And at the end, this is pity that I can't share this code 
> > (and BTW that I can't benefit of other's one!)
> > 
> > I though the solution was to deliver my own (eric)misc library, you know... 
> > But then we would rapidly be overcome by all miscmisc from world, and it 
> > would be difficult to find specific functions with all that libraries.
> > 
> > To me, a possible solution would be to have a page on CRAN listing such R 
> > files. Then, everyone would be able to upload R files with a short comment 
> > (what does the functions do). I am thinking about something less "strict" 
> > than libraries: for that, no reason to test the code (programmer's 
> > responsability). Then, maybe sometimes there would be enough pieces of code 
> > on a statistical subject to justify the creation of a library (still with 
> > the mind: a library is a collection of tools designed to help on a precise 
> > situation).
> > 
> > While I'm at it, it would also be nice to have a shared page on 
> > screenshots/graphics. For sure, I really enjoy to use R to produce 
> > wonderfull graphics. Not only would it be nice sometimes to show them, but 
> > it would also be the occasion to demonstrate R possibilities for newcomers 
> > (think on color graphics including mathematics). R would never have enough 
> > publicity!
> > 
> > Eric
> > 
> > 
> > __________________________________________________
> > 
> > Eric Lecoutre           Informaticien/Statisticien
> > Institut de Statistique                        UCL
> > 
> >                                (+32) (0)10 47 30 50
> >                             lecoutre at stat.ucl.ac.be
> >      http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
> > __________________________________________________
> > Le vrai danger, ce n'est pas quand les ordinateurs
> > penseront comme des hommes, c'est quand les hommes
> > penseront comme des ordinateurs.     Sydney Harris
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> -- 
> 318 Carr Hall                                bolker at zoo.ufl.edu
> Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
> Box 118525                                   (ph)  352-392-5697
> Gainesville, FL 32611-8525                   (fax) 352-392-3704
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20
| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
+---------------------------------------------------------------------------+



From dnogues at ipe.csic.es  Fri Feb  7 16:14:03 2003
From: dnogues at ipe.csic.es (dnogues@ipe.csic.es)
Date: Fri Feb  7 16:14:03 2003
Subject: [R] hierarchical partitioning in multiple regression
Message-ID: <20030207151151.6883C1F07F@posta.ipe.csic.es>

Hello to everybody:

Im starting to use R and this is my first message to the list. My first 
question is: Can R-Program calculate hierarchical partitioning analysis to 
measure the "independent effect" of each independent variable in a multiple 
regression (lm, glm)

Thanks in
advance

-----------------------------------------------------
Delegaci?n del CSIC en Arag?n. Servicio de Correo Web
http://www.dicar.csic.es



From RexBryan1 at attbi.com  Fri Feb  7 16:44:02 2003
From: RexBryan1 at attbi.com (Rex_Bryan@urscorp.com)
Date: Fri Feb  7 16:44:02 2003
Subject: [R] Fw: Plotting in subareas using par(fig=)  parameter
References: <006501c2ce05$1c7911d0$3182fd0c@dell1700> <3E429B80.9080607@pdf.com>
Message-ID: <007301c2cec0$36fae450$3182fd0c@dell1700>

Sundar and Brian,
Thank you both.
Despite the oddly inverted command structure of par(new=TRUE) when one wants
plot a new plot without erasing an old one, it works like a charm.  It works
so well that I have to remember to put par(new=FALSE) to create a clean
slate for  new plots!
REX
----- Original Message -----
From: "Sundar Dorai-Raj" <sundar.dorai-raj at pdf.com>
To: <Rex_Bryan at urscorp.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Thursday, February 06, 2003 10:29 AM
Subject: Re: [R] Fw: Plotting in subareas using par(fig=) parameter


>
> Try:
>
> R> par(fig=c(0,2/3,0,1))
> R> plot(x,y)
> R> par(fig=c(2/3,1,0,1), new = TRUE)
> R> qqnorm(x)
> R>
>
>  From ?par:
>
>       `new' logical, defaulting to `FALSE'.  If set to `TRUE', the next
>            high-level plotting command (actually `plot.new') should not
>            clean the frame before drawing ``as if it was on a new
>            device''.
>
> Regards,
> Sundar
>
> Rex_Bryan at urscorp.com wrote:
> > Any idea why I can no longer plot two graphs on the same graphics device
> > using the par(fig=) parameter?
> > A simpler par(mfrow=c(1,2)) does work, showing the two plots
side-by-side,
> > but I would like the first
> > to be larger.   This simple example fails:
> >
> >
> > x<-c(1,1,NA,2,2,NA,3,3)
> > y<-c(2,4,NA,3,5,NA,1,4)
> >
> > par(fig=c(0,2/3,0,1))
> > plot(x,y)
> >
> > par(fig=c(2/3,1,0,1))
> > qqnorm(x)
> >
> > When plotted, the last figure qqnorm(x) is alone on the graphics
display.
> > The first figure plot(x,y) disapears.
> > I'm even more puzzled in that I'm sure that I had this type of command
> > working before.
> >
> > REX
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>
>
>



From f.calboli at ucl.ac.uk  Fri Feb  7 16:57:16 2003
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: Fri Feb  7 16:57:16 2003
Subject: [R] nested anova
Message-ID: <3.0.6.32.20030207160208.025024b0@pop-server.ucl.ac.uk>

Hi All,

I would like to ask a clarification about a nested anova.

I did an experiment where I check for size differencies in flies. I have:

4 selection lines 
3 cage nested in each selection line (12 cages overall)
5 vials nested within each cage (15 vials per line, 60 overall)

I started out with the code:

aov(area ~ selection + cage:selection + vial:cage:selection, scf)

which does not exactly do what I would want (but gives me a fast reading of
the SS I should expect)

The code:

aov(area ~ selection/cage/vial+ Error(selection/cage/vial),scf)

does the trick (althought does not calculate the F value for me)

(BTW, the slighty shorted code

aov(area ~ selection/cage+ Error(selection/cage/vial),scf)

gives the same results).

Now, the question:

assuming that "selection" is a fixed effect and "cage" and "vial" are
random,  how do I do the same analysis using lme?  I tried to no avail.

Regards,
Federico Calboli













=========================

Federico C.F. Calboli

Department of Biology
University College London
Room 327
Darwin Building
Gower Street
London
WClE 6BT

Tel: (+44) 020 7679 4395 
Fax (+44) 020 7679 7096
f.calboli at ucl.ac.uk



From mschwartz at medanalytics.com  Fri Feb  7 17:02:14 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri Feb  7 17:02:14 2003
Subject: [R] Fw: Plotting in subareas using par(fig=)  parameter
In-Reply-To: <007301c2cec0$36fae450$3182fd0c@dell1700>
Message-ID: <004a01c2cec2$2531e780$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of 
>Rex_Bryan at urscorp.com
>Sent: Friday, February 07, 2003 9:47 AM
>To: Sundar Dorai-Raj; ripley at stats.ox.ac.uk
>Cc: r-help at stat.math.ethz.ch
>Subject: Re: [R] Fw: Plotting in subareas using par(fig=) parameter
>
>
>Sundar and Brian,
>Thank you both.
>Despite the oddly inverted command structure of par(new=TRUE) 
>when one wants plot a new plot without erasing an old one, it 
>works like a charm.  It works so well that I have to remember 
>to put par(new=FALSE) to create a clean slate for  new plots! REX
>
> SNIP
>

Rex,

To your point regarding the modifications to par() and as you might
get more complex in those modifications, you might want to consider
"wrapping" your code within the following two lines:

op <- par(no.readonly = TRUE) 

...your code...

par(op)


This sets 'op' to contain those parameters that you might modify in
your code and then restores par() to the values that were present
prior to your manipulation. This is contained in the examples and
elsewhere in ?par.  There is a caveat in the "Note" section of the
?par help page to be aware of in this situation.

HTH,

Marc Schwartz



From rdiaz at cnio.es  Fri Feb  7 17:49:03 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Fri Feb  7 17:49:03 2003
Subject: [R] arrays when calling C++ from R
Message-ID: <200302071747.52549.rdiaz@cnio.es>

Dear All,

I am writing some code in C++ that I call from R (using ".C"). I would like to 
have support for 2D and 3D arrays, including reading, assignment and 
operations over whole columns, rows, and slices, etc (with linear algebra a 
plus).  In the past I have used Blitz++ (http://www.oonumerics.org/blitz/).  
However, I would eventually want to make that code a contributed package, and 
thus Blitz++ does not seem a good option (and, for the same reasons, probably 
neither is MTL). I am considering instead TNT (its "ancestor", Lapack++, is 
used in the Matrix package), or GSL. Does anybody have any suggestions as to 
the best way to go?

Thanks,


-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
http://bioinfo.cnio.es/~rdiaz



From deleeuw at stat.ucla.edu  Fri Feb  7 17:55:03 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Fri Feb  7 17:55:03 2003
Subject: [R] Importing Packages Using OS-X
In-Reply-To: <17F1285A-3A55-11D7-98FE-000393582B82@wrdavis.net>
Message-ID: <3E527A1A-3ABC-11D7-9F9D-000393860F3C@stat.ucla.edu>

In that case you have to download the ready-made packages from CRAN.

If you want to build additional ones, it can be done using CodeWarrior
or MPW, but you are basically one your own in the desolate reaches of
MacOS 9.x.

-- Jan

On Thursday, February 6, 2003, at 08:31 PM, Matt Davis wrote:

> I forgot to mention that I am using carbon, and that I am just trying 
> to load packages.
> On Thursday, February 6, 2003, at 08:52  PM, Jan de Leeuw wrote:
>
>> Are you using Carbon R or Darwin R ? Do you want to load or
>> build packages ?
>>
>> Matt Davis wrote:
>>> I am trying to import/load some new packages into my R (1.6.2 or 
>>> 1.5.1) program.  Unfortunately there are a lot of problems that seem 
>>> to occur.  I cannot seem to sucessfuly  run any of the commands that 
>>> should import the packages.
>>> Some help with this matter would be greatly appreciated.  (A step by 
>>> step process would be the best, especially how to load a 
>>> predownloaded package (*.tar) into R.)
>>> Matt Davis
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
>>
>



From f0z6305 at labs.tamu.edu  Fri Feb  7 18:08:03 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Fri Feb  7 18:08:03 2003
Subject: [R] Confused by SVD and Eigenvector Decomposition in PCA
References: <000501c2ce0a$068e7770$8bd75ba5@IE.TAMU.EDU> <006201c2ce83$f7e346e0$0300a8c0@ono>
Message-ID: <001701c2cecb$51a75940$8bd75ba5@IE.TAMU.EDU>

Thanks for those replies.

But I tested several cases, and found the two
percentage from SVD and EVD are not
the same.
So how to explain the difference and which
one should be the right one for use
in PCA?


----- Original Message -----
From: "antonio rodriguez" <arv at ono.com>
To: "Feng Zhang" <f0z6305 at labs.tamu.edu>; "R-Help"
<r-help at stat.math.ethz.ch>
Sent: Friday, February 07, 2003 2:36 AM
Subject: Re: [R] Confused by SVD and Eigenvector Decomposition in PCA


> Hi Feng,
>
> AFIK SVD analysis provides a one-step method for computing all the
> components of the eigen value problem, without the need to compute and
> store big covariance matrices. And also the resulting decomposition is
> computationally more stable and robust.
>
> Cheers,
>
> Antonio Rodriguez
>
>
> ----- Original Message -----
> From: "Feng Zhang" <f0z6305 at labs.tamu.edu>
> To: "R-Help" <r-help at stat.math.ethz.ch>
> Sent: Thursday, February 06, 2003 7:03 PM
> Subject: [R] Confused by SVD and Eigenvector Decomposition in PCA
>
>
> > Hey, All
> >
> > In principal component analysis (PCA), we want to know how many
> percentage
> > the first principal component explain the total variances among the
> data.
> >
> > Assume the data matrix X is zero-meaned, and
> > I used the following procedures:
> > C = covriance(X) %% calculate the covariance matrix;
> > [EVector,EValues]=eig(C) %%
> > L = diag(EValues) %%L is a column vector with eigenvalues as the
> elements
> > percent = L(1)/sum(L);
> >
> >
> > Others argue using Sigular Value Decomposition(SVD) to
> > calculate the same quantity, as:
> > [U,S,V]=svd(X);
> > L = diag(S);
> > L = L.^2;
> > percent = L(1)/sum(L);
> >
> >
> > So which way is the correct method to calculate the percentage
> explained by
> > the first principal component?
> >
> > Thanks for your advices on this.
> >
> > Fred
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
> ---
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From lstringer at montana.edu  Fri Feb  7 23:39:03 2003
From: lstringer at montana.edu (Lew)
Date: Fri Feb  7 23:39:03 2003
Subject: [R] Data manipulation
Message-ID: <3.0.6.32.20030207153639.007b1950@trex2.msu.montana.edu>

I am interested in building a model with a subset of data from a column.

The first 6 lines of my data look like this:
    QUAD YEAR SITE TREAT HERB TILL PLANT SEED Kweed 
1     A4 2002    s     1    N    N     N    N 55.00   
2    A10 2002    s     1    N    N     N    N 60.00   
3     B2 2002    s     1    N    N     N    N 35.00  
4     C2 2002    s     1    N    N     N    N 23.00   
5     C9 2002    s     1    N    N     N    N 70.00   
6     11 2002    m     1    N    N     N    N 22.00   

I tried this command to get the subset I want:

> knap.fit1<-(lm(Kweed~TREAT[41:60,81:100,101:120,121:140], data=knap))
No luck.
 
Can anyone tell me how to code for this subset.

Thanks

Lew Stringer
M.S. Student- Land Rehabilitation
Dept. of Land Resources and Environmental Sciences 
Montana State University
822 Leon Johnson Hall
Bozeman, MT 59717
Lab:(406)994-6811
Fax:(406)994-3933



From rpeng at stat.ucla.edu  Fri Feb  7 23:48:03 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri Feb  7 23:48:03 2003
Subject: [R] Data manipulation
In-Reply-To: <3.0.6.32.20030207153639.007b1950@trex2.msu.montana.edu>
Message-ID: <Pine.GSO.4.10.10302071445180.8819-100000@quetelet.stat.ucla.edu>

You might want to try subsetting the data frame first, and then fit the
model.  Something like

knap.sub <- knap[c(41:60,81:100,101:120,121:140), ]
knap.fit1 <- lm(Kweed ~ TREAT, data = knap.sub)

might work for you.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Fri, 7 Feb 2003, Lew wrote:

> I am interested in building a model with a subset of data from a column.
> 
> The first 6 lines of my data look like this:
>     QUAD YEAR SITE TREAT HERB TILL PLANT SEED Kweed 
> 1     A4 2002    s     1    N    N     N    N 55.00   
> 2    A10 2002    s     1    N    N     N    N 60.00   
> 3     B2 2002    s     1    N    N     N    N 35.00  
> 4     C2 2002    s     1    N    N     N    N 23.00   
> 5     C9 2002    s     1    N    N     N    N 70.00   
> 6     11 2002    m     1    N    N     N    N 22.00   
> 
> I tried this command to get the subset I want:
> 
> > knap.fit1<-(lm(Kweed~TREAT[41:60,81:100,101:120,121:140], data=knap))
> No luck.
>  
> Can anyone tell me how to code for this subset.
> 
> Thanks
> 
> Lew Stringer
> M.S. Student- Land Rehabilitation
> Dept. of Land Resources and Environmental Sciences 
> Montana State University
> 822 Leon Johnson Hall
> Bozeman, MT 59717
> Lab:(406)994-6811
> Fax:(406)994-3933
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jfox at mcmaster.ca  Sat Feb  8 00:35:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat Feb  8 00:35:03 2003
Subject: [R] Data manipulation
In-Reply-To: <3.0.6.32.20030207153639.007b1950@trex2.msu.montana.edu>
Message-ID: <5.1.0.14.2.20030207182848.01df8cd8@mcmail.cis.mcmaster.ca>

Dear Lew,

You could use the subset argument to lm:

         knap.fit1 <- lm(Kweed ~ TREAT, data=knap, 
subset=c(41:60,81:100,101:120,121:140))

(You could alternatively subscript both Kweed and TREAT, rather than just 
TREAT, but this is unnecessarily complicated; as well, you'd need to use 
c() within the subscript, as in Kweed[c(41:60,81:100,101:120,121:140)].)

John

At 03:36 PM 2/7/2003 -0700, Lew wrote:
>I am interested in building a model with a subset of data from a column.
>
>The first 6 lines of my data look like this:
>     QUAD YEAR SITE TREAT HERB TILL PLANT SEED Kweed
>1     A4 2002    s     1    N    N     N    N 55.00
>2    A10 2002    s     1    N    N     N    N 60.00
>3     B2 2002    s     1    N    N     N    N 35.00
>4     C2 2002    s     1    N    N     N    N 23.00
>5     C9 2002    s     1    N    N     N    N 70.00
>6     11 2002    m     1    N    N     N    N 22.00
>
>I tried this command to get the subset I want:
>
> > knap.fit1<-(lm(Kweed~TREAT[41:60,81:100,101:120,121:140], data=knap))
>No luck.
>
>Can anyone tell me how to code for this subset.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From arnab at myrealbox.com  Sat Feb  8 03:14:02 2003
From: arnab at myrealbox.com (Arnab mukherji)
Date: Sat Feb  8 03:14:02 2003
Subject: [R] converting to a language object
Message-ID: <1044670383.b4de3ce0arnab@myrealbox.com>

Hi,

I have a query about the following:

CONTEXT:
if we define:

eq <- y ~ x1 + x2

then is.language(eq) returns true.
this works perfectly with commands such as
lm(eq,data=my.data)

THE PROBLEM:
Now I have a big data set with about 2000 independent variables. So I tried to automate this. I can pick off the names of the variables and insert a plus in between them and get a string. Thus I have 

eq<- y ~ " x1 + x2 + ... +x2000"
or
eq<-"y ~ " x1 + x2 + ... +x2000"

from either case how can I typecast eq into a langugae object and get the lm command to work ?

Does anyone have any suggestions?

thanks

Arnab.



From MSchwartz at medanalytics.com  Sat Feb  8 04:01:03 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sat Feb  8 04:01:03 2003
Subject: [R] converting to a language object
In-Reply-To: <1044670383.b4de3ce0arnab@myrealbox.com>
References: <1044670383.b4de3ce0arnab@myrealbox.com>
Message-ID: <3E4472D3.4010400@MedAnalytics.com>

Arnab mukherji wrote:
> Hi,
> 
> I have a query about the following:
> 
> CONTEXT: if we define:
> 
> eq <- y ~ x1 + x2
> 
> then is.language(eq) returns true. this works perfectly with commands
> such as lm(eq,data=my.data)
> 
> THE PROBLEM: Now I have a big data set with about 2000 independent
> variables. So I tried to automate this. I can pick off the names of
> the variables and insert a plus in between them and get a string.
> Thus I have
> 
> eq<- y ~ " x1 + x2 + ... +x2000" or eq<-"y ~ " x1 + x2 + ... +x2000"
> 
> from either case how can I typecast eq into a langugae object and get
> the lm command to work ?
> 
> Does anyone have any suggestions?
> 
> thanks
> 
> Arnab.


Arnab,

Once you have your full formula string constructed you can use:

eq <- eval(parse(text = string))

This will put the model formula into eq.


For example try:

eq <- eval(parse(text = "y ~ x1 + x2"))


See ?eval and ?parse for more information.

Hope that helps.


Regards,

Marc Schwartz



From f0z6305 at labs.tamu.edu  Sat Feb  8 04:17:03 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Sat Feb  8 04:17:03 2003
Subject: [R] Confused by SVD and Eigenvector Decomposition in PCA
References: <3A822319EB35174CA3714066D590DCD534BC67@usrymx25.merck.com>
Message-ID: <00ab01c2cf20$707bf470$8bd75ba5@IE.TAMU.EDU>

I used Matlab to do this case study.
>x = randn(200,3); %%generating a 200x3 Gaussian matrix
>[a,b,c]=svd(x); %%SVD composition
>S=diag(b)
  S =[15.6765   14.8674   13.4016]'

>S(1)^2/sum(S.^2);
 0.3802

>ZeroedX = X - repmat(mean(X),200,1); %%ZeroedX is now zero centered data
>C = cov(ZeroedX); %%Covariance matrix of ZeroedX
>[U,L] = eig(C); %% Eigen decompostion of C
> SE = diag(L);
  [0.8918    1.1098    1.2337]'
>SE(1)/sum(SE)
  0.3813

This is the case that I was confused by.

Fred
----- Original Message -----
From: "Liaw, Andy" <andy_liaw at merck.com>
To: "'Feng Zhang'" <f0z6305 at labs.tamu.edu>
Sent: Friday, February 07, 2003 6:25 PM
Subject: RE: [R] Confused by SVD and Eigenvector Decomposition in PCA


> I've already shown you one example.  If that's not enough, here's another
> one:
>
> > set.seed(1)
> > x <- matrix(runif(1e3), 50, 20)
> > La.eigen(crossprod(x))$value
>  [1] 258.5242317   9.3638224   8.7213839   7.7425270   6.5057190
6.2719056
>  [7]   5.6582657   4.5002047   4.2289555   3.9098726   3.7172642
3.2826449
> [13]   2.8758329   2.6907474   2.3300505   1.9700120   1.3191512
1.0228788
> [19]   0.8883083   0.5883287
> > La.svd(x)$d^2
>  [1] 258.5242317   9.3638224   8.7213839   7.7425270   6.5057190
6.2719056
>  [7]   5.6582657   4.5002047   4.2289555   3.9098726   3.7172642
3.2826449
> [13]   2.8758329   2.6907474   2.3300505   1.9700120   1.3191512
1.0228788
> [19]   0.8883083   0.5883287
>
> Where's your example of this not working?
>
> Andy
>
>
> > -----Original Message-----
> > From: Feng Zhang [mailto:f0z6305 at labs.tamu.edu]
> > Sent: Friday, February 07, 2003 12:07 PM
> > To: antonio rodriguez; R-Help
> > Subject: Re: [R] Confused by SVD and Eigenvector Decomposition in PCA
> >
> >
> > Thanks for those replies.
> >
> > But I tested several cases, and found the two
> > percentage from SVD and EVD are not
> > the same.
> > So how to explain the difference and which
> > one should be the right one for use
> > in PCA?
> >
> >
> > ----- Original Message -----
> > From: "antonio rodriguez" <arv at ono.com>
> > To: "Feng Zhang" <f0z6305 at labs.tamu.edu>; "R-Help"
> > <r-help at stat.math.ethz.ch>
> > Sent: Friday, February 07, 2003 2:36 AM
> > Subject: Re: [R] Confused by SVD and Eigenvector Decomposition in PCA
> >
> >
> > > Hi Feng,
> > >
> > > AFIK SVD analysis provides a one-step method for computing all the
> > > components of the eigen value problem, without the need to
> > compute and
> > > store big covariance matrices. And also the resulting
> > decomposition is
> > > computationally more stable and robust.
> > >
> > > Cheers,
> > >
> > > Antonio Rodriguez
> > >
> > >
> > > ----- Original Message -----
> > > From: "Feng Zhang" <f0z6305 at labs.tamu.edu>
> > > To: "R-Help" <r-help at stat.math.ethz.ch>
> > > Sent: Thursday, February 06, 2003 7:03 PM
> > > Subject: [R] Confused by SVD and Eigenvector Decomposition in PCA
> > >
> > >
> > > > Hey, All
> > > >
> > > > In principal component analysis (PCA), we want to know how many
> > > percentage
> > > > the first principal component explain the total variances
> > among the
> > > data.
> > > >
> > > > Assume the data matrix X is zero-meaned, and
> > > > I used the following procedures:
> > > > C = covriance(X) %% calculate the covariance matrix;
> > > > [EVector,EValues]=eig(C) %%
> > > > L = diag(EValues) %%L is a column vector with eigenvalues as the
> > > elements
> > > > percent = L(1)/sum(L);
> > > >
> > > >
> > > > Others argue using Sigular Value Decomposition(SVD) to
> > > > calculate the same quantity, as:
> > > > [U,S,V]=svd(X);
> > > > L = diag(S);
> > > > L = L.^2;
> > > > percent = L(1)/sum(L);
> > > >
> > > >
> > > > So which way is the correct method to calculate the percentage
> > > explained by
> > > > the first principal component?
> > > >
> > > > Thanks for your advices on this.
> > > >
> > > > Fred
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> > >
> > > ---
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> --------------------------------------------------------------------------
----
> Notice: This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
may be confidential, proprietary copyrighted and/or legally privileged, and
is intended solely for the use of the individual or entity named on this
message.  If you are not the intended recipient, and have received this
message in error, please immediately return this by e-mail and then delete
it.
>
>
============================================================================
==
>



From mitsu5 at ruby.famille.ne.jp  Sat Feb  8 07:43:03 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Sat Feb  8 07:43:03 2003
Subject: [R] to modify a vector
Message-ID: <200302080642.h186gBG28417@mp1.vectant.ne.jp>

Hi All.

I am quite a newbie to R.
This is a basic question.

I like to modify elements of a vector.
For Example:
a1 <- c(1,2,3,4,3,5)

TThe following program sentence does not work but the intention is;
  
  if (a1==3) a1*3 .

3 in the vector should be changed to 9, and
the resulted vector is (1,2,9,4,9,5).

How can I get the result?

Thanks in advance for help.
-------========--------
mitsu5
mitsu5 at ruby.famille.ne.jp



From deepayan at stat.wisc.edu  Sat Feb  8 07:56:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat Feb  8 07:56:03 2003
Subject: [R] to modify a vector
In-Reply-To: <200302080642.h186gBG28417@mp1.vectant.ne.jp>
References: <200302080642.h186gBG28417@mp1.vectant.ne.jp>
Message-ID: <200302080055.08542.deepayan@stat.wisc.edu>

On Saturday 08 February 2003 12:41 am, Mitsuo Igarashi wrote:
> Hi All.
>
> I am quite a newbie to R.
> This is a basic question.
>
> I like to modify elements of a vector.
> For Example:
> a1 <- c(1,2,3,4,3,5)
>
> TThe following program sentence does not work but the intention is;
>
>   if (a1==3) a1*3 .
>
> 3 in the vector should be changed to 9, and
> the resulted vector is (1,2,9,4,9,5).
>
> How can I get the result?

if you want to store the result in a1 itself,

a1[a1==3] <- a1[a1==3] * 3

Alternately, 

ifelse(a1 == 3, a1 * 3, a1)



From ripley at stats.ox.ac.uk  Sat Feb  8 08:17:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Feb  8 08:17:04 2003
Subject: [R] converting to a language object
In-Reply-To: <3E4472D3.4010400@MedAnalytics.com>
Message-ID: <Pine.LNX.4.44.0302080708330.26583-100000@gannet.stats>

In this case a simler answer is that you want a formula, so use 
as.formula:

> eq <- "y ~ x1 + x2 +x2000"
> as.formula(eq)
y ~ x1 + x2 + x2000

once the quotation marks are in the right place.

It is much simpler to use lm(y ~ ., data=foo) !

A caveat: you may hit some limits on expression size if you try to put
2000 variables in a formula, and almost certainly you will hit
computational limits if you try to do a regression on it, as you need
n >> p = 2000, and the key computation is (I think) O(np^2).

On Fri, 7 Feb 2003, Marc Schwartz wrote:

> Arnab mukherji wrote:
> > Hi,
> > 
> > I have a query about the following:
> > 
> > CONTEXT: if we define:
> > 
> > eq <- y ~ x1 + x2
> > 
> > then is.language(eq) returns true. this works perfectly with commands
> > such as lm(eq,data=my.data)
> > 
> > THE PROBLEM: Now I have a big data set with about 2000 independent
> > variables. So I tried to automate this. I can pick off the names of
> > the variables and insert a plus in between them and get a string.
> > Thus I have
> > 
> > eq<- y ~ " x1 + x2 + ... +x2000" or eq<-"y ~ " x1 + x2 + ... +x2000"
> > 
> > from either case how can I typecast eq into a langugae object and get
> > the lm command to work ?
> > 
> > Does anyone have any suggestions?
> > 
> > thanks
> > 
> > Arnab.
> 
> 
> Arnab,
> 
> Once you have your full formula string constructed you can use:
> 
> eq <- eval(parse(text = string))
> 
> This will put the model formula into eq.
> 
> 
> For example try:
> 
> eq <- eval(parse(text = "y ~ x1 + x2"))
> 
> 
> See ?eval and ?parse for more information.
> 
> Hope that helps.
> 
> 
> Regards,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dray at biomserv.univ-lyon1.fr  Sat Feb  8 10:28:08 2003
From: dray at biomserv.univ-lyon1.fr (Stephane Dray)
Date: Sat Feb  8 10:28:08 2003
Subject: [R] Confused by SVD and Eigenvector Decomposition in PCA
In-Reply-To: <00ab01c2cf20$707bf470$8bd75ba5@IE.TAMU.EDU>
References: <3A822319EB35174CA3714066D590DCD534BC67@usrymx25.merck.com>
Message-ID: <5.1.0.14.0.20030208102533.00b9db20@biomserv.univ-lyon1.fr>

At 21:16 07/02/2003 -0600, Feng Zhang wrote:
>I used Matlab to do this case study.
> >x = randn(200,3); %%generating a 200x3 Gaussian matrix
> >[a,b,c]=svd(x); %%SVD composition
> >S=diag(b)
>   S =[15.6765   14.8674   13.4016]'
>
> >S(1)^2/sum(S.^2);
>  0.3802

> >ZeroedX = X - repmat(mean(X),200,1); %%ZeroedX is now zero centered data
> >C = cov(ZeroedX); %%Covariance matrix of ZeroedX
> >[U,L] = eig(C); %% Eigen decompostion of C
> > SE = diag(L);
>   [0.8918    1.1098    1.2337]'
> >SE(1)/sum(SE)
>   0.3813
>
>This is the case that I was confused by.
>
>Fred

You must also apply svd on your centred table X (i.e. ZeroeX)



From kjetil at entelnet.bo  Sat Feb  8 14:06:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat Feb  8 14:06:03 2003
Subject: [R] converting to a language object
In-Reply-To: <1044670383.b4de3ce0arnab@myrealbox.com>
Message-ID: <3E44C857.16189.3745B8@localhost>

On 8 Feb 2003 at 2:13, Arnab mukherji wrote:

> Hi,
> 
> I have a query about the following:
> 
> CONTEXT:
> if we define:
> 
> eq <- y ~ x1 + x2
> 
> then is.language(eq) returns true.
> this works perfectly with commands such as
> lm(eq,data=my.data)
> 
> THE PROBLEM:
> Now I have a big data set with about 2000 independent variables. So I tried to automate this. I can pick off the names of the variables and insert a plus in between them and get a string. Thus I have 
> 
> eq<- y ~ " x1 + x2 + ... +x2000"
> or
> eq<-"y ~ " x1 + x2 + ... +x2000"
> 
> from either case how can I typecast eq into a langugae object and get the lm command to work ?
> 
> Does anyone have any suggestions?
> 
What about the following:

> sum <- paste("+ x", 1:5, sep="", collapse="")
> sum
[1] "+ x1+ x2+ x3+ x4+ x5"
> sum <- substr(sum,2,20)
> sum
[1] " x1+ x2+ x3+ x4+ x5"
> formula <- as.formula(paste("y ~ ", sum, sep="", collapse=""))
> formula
y ~ x1 + x2 + x3 + x4 + x5
> class(formula)
[1] "formula"
> # simulating some random data
> lm(formula)

Call:
lm(formula = formula)

Coefficients:
(Intercept)           x1           x2           x3           x4       
    x5  
    0.05959      0.07876      0.20845     -0.11539     -0.14293     -
0.11421 

Kjetil Halvorsen


> thanks
> 
> Arnab.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Sat Feb  8 14:14:38 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat Feb  8 14:14:38 2003
Subject: [R] to modify a vector
In-Reply-To: <200302080642.h186gBG28417@mp1.vectant.ne.jp>
Message-ID: <3E44C857.14448.374644@localhost>

On 8 Feb 2003 at 15:41, Mitsuo Igarashi wrote:

You should realy read "An Introduction to R", which comes
with your R installation.

> Hi All.
> 
> I am quite a newbie to R.
> This is a basic question.
> 
> I like to modify elements of a vector.
> For Example:
> a1 <- c(1,2,3,4,3,5)
> 
> TThe following program sentence does not work but the intention is;
>   
>   if (a1==3) a1*3 .
> 
> 3 in the vector should be changed to 9, and
> the resulted vector is (1,2,9,4,9,5).
> 

a1[a1==3] <- 9

Kjetil Halvorsen

> How can I get the result?
> 
> Thanks in advance for help.
> -------========--------
> mitsu5
> mitsu5 at ruby.famille.ne.jp
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mitsu5 at ruby.famille.ne.jp  Sat Feb  8 16:05:06 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Sat Feb  8 16:05:06 2003
Subject: [R] to modify a matrix
Message-ID: <200302081504.h18F4YG02875@mp1.vectant.ne.jp>

Hi All.

I am quite a newbie to R.
This is a next basic question.

I have a matrix;
> x <- matrix(1:10.,5)
> x
     [,1] [,2]
[1,]    1    6
[2,]    2    7
[3,]    3    8
[4,]    4    9
[5,]    5   10

I like to get a modified matrix as follows;
     [,1] [,2]
[1,]    1    6
[2,]    2    7
[3,]    3    8 * 5 -> 40
[4,]    4    9
[5,]    5   10

The following expression does not work.
 if (x[x[,1]==3])  x[x[,1]==3],2]*5

How can I obtain a right expresion to get a modified matrix?

Thanks in advance for help.

-------========--------
mitsu5
mitsu5 at ruby.famille.ne.jp



From baron at cattell.psych.upenn.edu  Sat Feb  8 16:21:02 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sat Feb  8 16:21:02 2003
Subject: [R] to modify a matrix
In-Reply-To: <200302081504.h18F4YG02875@mp1.vectant.ne.jp>; from mitsu5@ruby.famille.ne.jp on Sun, Feb 09, 2003 at 12:04:21AM +0900
References: <200302081504.h18F4YG02875@mp1.vectant.ne.jp>
Message-ID: <20030208101951.A6714@cattell.psych.upenn.edu>

On 02/09/03 00:04, Mitsuo Igarashi wrote:
>Hi All.
>
>I am quite a newbie to R.
>This is a next basic question.
>
>I have a matrix;
>> x <- matrix(1:10.,5)
>> x
>     [,1] [,2]
>[1,]    1    6
>[2,]    2    7
>[3,]    3    8
>[4,]    4    9
>[5,]    5   10
>
>I like to get a modified matrix as follows;
>     [,1] [,2]
>[1,]    1    6
>[2,]    2    7
>[3,]    3    8 * 5 -> 40
>[4,]    4    9
>[5,]    5   10
>
>The following expression does not work.
> if (x[x[,1]==3])  x[x[,1]==3],2]*5
>
>How can I obtain a right expresion to get a modified matrix?

This will do it:
x[,2] <- x[,2]*(1+4*(x[,1]==3))

But probably you want to do it with something like "if".  So:
x[,2] <- ifelse(x[,1]==3, x[,2]*5, x[,2])

Or a loop:
for(i in 1:5) {if (x[,1]==3) {x[,2] <- 5*x[,2]}}

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
R page:               http://finzi.psych.upenn.edu/



From jfox at mcmaster.ca  Sat Feb  8 16:30:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat Feb  8 16:30:03 2003
Subject: [R] to modify a matrix
In-Reply-To: <200302081504.h18F4YG02875@mp1.vectant.ne.jp>
Message-ID: <5.1.0.14.2.20030208102535.01df8f40@mcmail.cis.mcmaster.ca>

Dear Mitsuo,

It isn't completely clear to me what the criterion is for selecting 
elements, but if you want to change 8 to 40, but aren't sure where 8 is (or 
8s are), then the following will work:

         x[x==8] <- 40

The trick here is to index the matrix as a vector (since matrices in R are 
vectors with a dim attribute).

More generally, there's a great deal of free information available about 
how to use R that can help you to answer questions like this, including 
manuals supplied with the R distribution and other material available from 
the R web site.

John

At 12:04 AM 2/9/2003 +0900, Mitsuo Igarashi wrote:
>Hi All.
>
>I am quite a newbie to R.
>This is a next basic question.
>
>I have a matrix;
> > x <- matrix(1:10.,5)
> > x
>      [,1] [,2]
>[1,]    1    6
>[2,]    2    7
>[3,]    3    8
>[4,]    4    9
>[5,]    5   10
>
>I like to get a modified matrix as follows;
>      [,1] [,2]
>[1,]    1    6
>[2,]    2    7
>[3,]    3    8 * 5 -> 40
>[4,]    4    9
>[5,]    5   10
>
>The following expression does not work.
>  if (x[x[,1]==3])  x[x[,1]==3],2]*5
>
>How can I obtain a right expresion to get a modified matrix?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From MSchwartz at medanalytics.com  Sat Feb  8 16:41:02 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sat Feb  8 16:41:02 2003
Subject: [R] converting to a language object
In-Reply-To: <Pine.LNX.4.44.0302080708330.26583-100000@gannet.stats>
References: <Pine.LNX.4.44.0302080708330.26583-100000@gannet.stats>
Message-ID: <3E4524BF.5060004@MedAnalytics.com>

ripley at stats.ox.ac.uk wrote:
> In this case a simler answer is that you want a formula, so use 
> as.formula:
> 
> 
>>eq <- "y ~ x1 + x2 +x2000"
>>as.formula(eq)
> 
> y ~ x1 + x2 + x2000
> 
> once the quotation marks are in the right place.
> 
> It is much simpler to use lm(y ~ ., data=foo) !
> 
> A caveat: you may hit some limits on expression size if you try to put
> 2000 variables in a formula, and almost certainly you will hit
> computational limits if you try to do a regression on it, as you need
> n >> p = 2000, and the key computation is (I think) O(np^2).
 >
 > SNIP


Valid points of course on all accounts.

Indeed there is a good example at the end of ?as.formula that addresses 
the construction of a formula from a large number of variables with just 
the type of sequencing that Arnab is using.  To wit:

## Create a formula for a model with a large number of variables:
xnam <- paste("x", 1:25, sep="")
(fmla <- as.formula(paste("y ~ ", paste(xnam, collapse= "+"))))

which obviously results in:

y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 +
     x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19 + x20 + x21 +
     x22 + x23 + x24 + x25


I had been in the habit of using the more "generic" approach of 
eval(parse(text = charvector)) when constructing R code for evaluation 
in other situations.

Regards and thanks,

Marc Schwartz



From lsophir at wisemail.weizmann.ac.il  Sat Feb  8 19:20:04 2003
From: lsophir at wisemail.weizmann.ac.il (Ron Ophir)
Date: Sat Feb  8 19:20:04 2003
Subject: [R] mirroring R
Message-ID: <se456637.086@wisemail.weizmann.ac.il>

Dear supporter,
Can you tell me please how can I mirroring R at our site? One of the reasons I would like to do this is the fact that it is impossible to update R behind our firewalls.
Thank in advance

Ron Ophir, Ph.D.
Bioinformatician,
Biological Services
Weizmann Institute of Science
POB 26
Rehovot 76100
Israel
e-mail: Ron.Ophir at weizmann.ac.il
Phone: 972-8-9342614
Fax:972-8-9344113



From andy_liaw at merck.com  Sat Feb  8 19:47:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat Feb  8 19:47:03 2003
Subject: [R] Confused by SVD and Eigenvector Decomposition in PCA
Message-ID: <3A822319EB35174CA3714066D590DCD534BC68@usrymx25.merck.com>

There *is* a Matlab newsgroup for you to ask Matlab questions.  From the
latest Matlab digest:

MATLAB Usenet Group Celebrates Its 10th Anniversary
The MATLAB Usenet group, comp.soft-sys.matlab (CSSM), celebrated its 10th
anniversary this month. CSSM is a collaboration space where thousands of
MATLAB users discuss MATLAB-related topics or post questions to the
community. In 2002, CSSM featured more than 33,800 posts. Use our online
newsreader to communicate with the MATLAB community at:
www.mathworks.com/matlabcentral

Andy

------------------------------------------------------------------------------



From edd at debian.org  Sat Feb  8 19:52:30 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat Feb  8 19:52:30 2003
Subject: [R] mirroring R
In-Reply-To: <se456637.086@wisemail.weizmann.ac.il>
References: <se456637.086@wisemail.weizmann.ac.il>
Message-ID: <20030208184615.GA6406@sonny.eddelbuettel.com>

On Sat, Feb 08, 2003 at 08:18:55PM +0200, Ron Ophir wrote:
> Dear supporter,
> Can you tell me please how can I mirroring R at our site?

There is a (old-ish) Perl package / program called mirror which is
frequently employed to do what its name suggests. There is also a more
modern tool called rsync. Lastly, GNU wget (see below) could be used as well
but may be less efficient. You may want to read up on either one. 

> One of the reasons I would like to do this is the fact that 
> it is impossible to update R behind our firewalls.

As a general rule, you should be able to connect past firewalls, both of the
"mery proxy" kind and the "authentication based" type. R on Windows supports
either by using the --internet2 flag which then "borrows" the firewall-
poking capabilities of Internet Explorer.  Also, I believe that Brian Ripley
just added some code to make this possible from within R, but IIRC this
won't be officially available until R 1.7.0 is released.

Alternatively for Windows, or generally speaking on non-Windows, you could
use GNU wget, an extremely versatile download tool ported to many OSs (incl.
all Unix flavours, Windows, and I suspect most Mac flavours).  In its config
file ($HOME/.wgetrc under Unix, or Cygwin), specify the proxy as well as
user + password settings. Then tell R via $HOME/.Rprofile to use wget as the
argument to the download.file.method, as in
	options(download.file.method="wget") 
and you should be all set.  

Hope this helps, mail me off-line is you have more questions,

Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr



From fnj at cin.ufpe.br  Sat Feb  8 19:58:03 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Sat Feb  8 19:58:03 2003
Subject: [R] Repetitions in array
Message-ID: <Pine.GSO.4.32.0302081545510.15033-100000@goiana>

Hello,

How I make to remove repeated elements of an array???

I used table(array), but I don't obtain to come back from table to array!

Tks,
Francisco.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco Jnior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From kjetil at entelnet.bo  Sat Feb  8 20:08:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat Feb  8 20:08:03 2003
Subject: [R] Repetitions in array
In-Reply-To: <Pine.GSO.4.32.0302081545510.15033-100000@goiana>
Message-ID: <3E451D07.15163.182144D@localhost>

On 8 Feb 2003 at 15:49, Francisco do Nascimento Junior wrote:

> Hello,
> 
> How I make to remove repeated elements of an array???

?unique

Kjetil Halvorsen

> 
> I used table(array), but I don't obtain to come back from table to array!
> 
> Tks,
> Francisco.
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Francisco J?nior,
> Computer Science - UFPE-Brazil
> "One life has more value that the
> world whole"
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From fnj at cin.ufpe.br  Sat Feb  8 20:50:03 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Sat Feb  8 20:50:03 2003
Subject: [R] Find strings in a array
Message-ID: <Pine.GSO.4.32.0302081643350.15033-100000@goiana>

I need to know which strings of an array that are in another array.
What a best solution?

Tks,
Francisco.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco Jnior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From bates at stat.wisc.edu  Sat Feb  8 21:06:02 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat Feb  8 21:06:02 2003
Subject: [R] Find strings in a array
In-Reply-To: <Pine.GSO.4.32.0302081643350.15033-100000@goiana>
References: <Pine.GSO.4.32.0302081643350.15033-100000@goiana>
Message-ID: <6radh64jy6.fsf@bates4.stat.wisc.edu>

Francisco do Nascimento Junior <fnj at cin.ufpe.br> writes:

> I need to know which strings of an array that are in another array.
> What a best solution?

%in%

> c("foo", "bar", "baz") %in% c("foo", "bar", "boz", "bonz")
[1]  TRUE  TRUE FALSE



From sundar.dorai-raj at pdf.com  Sat Feb  8 21:12:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sat Feb  8 21:12:03 2003
Subject: [R] Find strings in a array
References: <Pine.GSO.4.32.0302081643350.15033-100000@goiana>
Message-ID: <3E45634C.9040907@pdf.com>

Francisco,

Francisco do Nascimento Junior wrote:
> I need to know which strings of an array that are in another array.
> What a best solution?
> 


Look at match, pmatch, %in%. Or for regular expressions, regexpr, grep.


For example,

R> x <- c("a", "b", "c")
R> y <- c("a", "b", "d")
R> z <- c("apple", "cantaloupe", "pear")
R> x %in% y
[1]  TRUE  TRUE FALSE
R> x[x %in% y]
[1] "a" "b"
R>
R> pmatch(x, z, nomatch = 0)
[1] 1 0 2
R> x[pmatch(x, z, nomatch = 0) > 0]
[1] "a" "c"
R>

Sundar



From upton at mitre.org  Sat Feb  8 21:20:04 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Sat Feb  8 21:20:04 2003
Subject: [R] Find strings in a array
References: <Pine.GSO.4.32.0302081643350.15033-100000@goiana>
Message-ID: <3E456629.9B99D927@mitre.org>

Francisco,

Is this what you're looking for?

> aa
[1] "ab" "cd" "de" "aa"
> bb
[1] "ab" "cd" "de" "df" "gg" "FF"
> bb %in% aa
[1]  TRUE  TRUE  TRUE FALSE FALSE FALSE
> aa %in% bb
[1]  TRUE  TRUE  TRUE FALSE

OR
> match(aa,bb)
[1]  1  2  3 NA
> match(bb,aa)
[1]  1  2  3 NA NA

If you have a string pattern, then you might also want to take a look at
grep .

HTH
steve

Francisco do Nascimento Junior wrote:

> I need to know which strings of an array that are in another array.
> What a best solution?
>
> Tks,
> Francisco.
>
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Francisco J?nior,
> Computer Science - UFPE-Brazil
> "One life has more value that the
> world whole"
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From swisdom at operamail.com  Sun Feb  9 02:30:04 2003
From: swisdom at operamail.com (stephen wisdom)
Date: Sun Feb  9 02:30:04 2003
Subject: [R] is.finite() of a list
Message-ID: <20030209012922.15985.qmail@operamail.com>

> ?is.finite

     `is.finite' and `is.infinite' return a vector of the same length
     as `x', indicating which elements are finite or not.

is.finite() of a list seems to return a vector of the length of the list, but with value FALSE if any list element isn't finite.  Is this intended?

> l4 <- list(NA,1,2,3); l4; length(l4); is.finite(l4)
[[1]]
[1] NA

[[2]]
[1] 1

[[3]]
[1] 2

[[4]]
[1] 3

[1] 4
[1] FALSE FALSE FALSE FALSE

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.2            
year     2003           
month    01             
day      10             
language R              

> system('winver') 
[Windows XP Professional]

Thanks,
Steve Wisdom
Westport CT USA 







-- 
_______________________________________________
http://www.operamail.com
Now with OperaMail Premium for only US$29.99/yr



From pzhang at hsph.harvard.edu  Sun Feb  9 05:34:05 2003
From: pzhang at hsph.harvard.edu (Peng Zhang)
Date: Sun Feb  9 05:34:05 2003
Subject: [R] installation on FreeBSD
Message-ID: <Pine.GSO.4.53.0302082329350.18164@hsph.harvard.edu>

Hello there,

I just changed to FreeBSD platform, and want to install R on it. I use
FreeBSD 5.0 and install nearly all packages on the machine. When I use
ports to install R, (cd /usr/ports/math/R-letter, and then type make) I
got the following error information.
../../../../library/methods/libs/methods.so is unchanged
dumping R code in package 'methods'
Fatal error: The X11 shared library could not be loaded.
  The error was /usr/ports/math/R-letter/work/R-1.6.0/modules/R_X11.so:
Undefined symbol "R_GlobalEnv"
Can somebody tell me why and how to fix this problem?

Thank you for your help!

Best wishes,
Peng

*******************************
Peng Zhang
Department of Biostatistics
Harvard School of Public Health
655 Huntington Avenue
Boston, Massachusetts 02115
*******************************

I believe I can fly
I believe I can touch the sky



From yuhong at cs.ualberta.ca  Sun Feb  9 06:51:04 2003
From: yuhong at cs.ualberta.ca (Yuhong Guo)
Date: Sun Feb  9 06:51:04 2003
Subject: [R] install error
Message-ID: <Pine.LNX.4.44.0302082246080.17377-100000@lousana.cs.ualberta.ca>

I just download R-1.6.2 source code for unix 
to install. I am intalling it under redhat linux.

But after ./configure, when I try to make, 
there always error showed: 

/usr/bin/install: cannot change ownership of `../../bin/BATCH': Operation 
not permitted
/usr/bin/install: cannot change ownership of `../../bin/LINK': Operation 
not permitted
/usr/bin/install: cannot change ownership of `../../bin/Rcmd': Operation 
not permitted
/usr/bin/install: cannot change ownership of `../../bin/Rdiff': Operation 
not permitted
/usr/bin/install: cannot change ownership of `../../bin/Rd2dvi': Operation 
not permitted
/usr/bin/install: cannot change ownership of `../../bin/Rd2txt': Operation 
not permitted
/usr/bin/install: cannot change ownership of `../../bin/config': Operation 
not permitted
/usr/bin/install: cannot change ownership of `../../bin/pager': Operation 
not permitted
/usr/bin/install: cannot change ownership of `../../bin/texi2dvi': 
Operation not permitted

Does anyone know what is the problem? (Oh, I install it as a common user
to linux, not as root)?



From rpeng at stat.ucla.edu  Sun Feb  9 08:26:03 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Sun Feb  9 08:26:03 2003
Subject: [R] install error
In-Reply-To: <Pine.LNX.4.44.0302082246080.17377-100000@lousana.cs.ualberta.ca>
Message-ID: <Pine.GSO.4.10.10302082322530.6662-100000@quetelet.stat.ucla.edu>

If you just run the `configure' script without other arguments, it will
try to install in /usr/local, which you probably don't have permission to
write to.  

Just pick a directory that you have permission to write to and use the
--prefix argument to configure.  For example,

./configure --prefix=/home/rpeng/R

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Sat, 8 Feb 2003, Yuhong Guo wrote:

> 
> I just download R-1.6.2 source code for unix 
> to install. I am intalling it under redhat linux.
> 
> But after ./configure, when I try to make, 
> there always error showed: 
> 
> /usr/bin/install: cannot change ownership of `../../bin/BATCH': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/LINK': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/Rcmd': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/Rdiff': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/Rd2dvi': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/Rd2txt': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/config': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/pager': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/texi2dvi': 
> Operation not permitted
> 
> Does anyone know what is the problem? (Oh, I install it as a common user
> to linux, not as root)?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From yuhong at cs.ualberta.ca  Sun Feb  9 08:44:04 2003
From: yuhong at cs.ualberta.ca (Yuhong Guo)
Date: Sun Feb  9 08:44:04 2003
Subject: [R] install error
In-Reply-To: <Pine.GSO.4.10.10302082322530.6662-100000@quetelet.stat.ucla.edu>
Message-ID: <Pine.LNX.4.44.0302090040440.18511-100000@lousana.cs.ualberta.ca>

Thanks.
But in fact, I used --prefix parameter, the make error 
are still there.

On Sat, 8 Feb 2003, Roger Peng wrote:

> If you just run the `configure' script without other arguments, it will
> try to install in /usr/local, which you probably don't have permission to
> write to.  
> 
> Just pick a directory that you have permission to write to and use the
> --prefix argument to configure.  For example,
> 
> ./configure --prefix=/home/rpeng/R
> 
> -roger
> _______________________________
> UCLA Department of Statistics
> rpeng at stat.ucla.edu
> http://www.stat.ucla.edu/~rpeng
> 
> On Sat, 8 Feb 2003, Yuhong Guo wrote:
> 
> > 
> > I just download R-1.6.2 source code for unix 
> > to install. I am intalling it under redhat linux.
> > 
> > But after ./configure, when I try to make, 
> > there always error showed: 
> > 
> > /usr/bin/install: cannot change ownership of `../../bin/BATCH': Operation 
> > not permitted
> > /usr/bin/install: cannot change ownership of `../../bin/LINK': Operation 
> > not permitted
> > /usr/bin/install: cannot change ownership of `../../bin/Rcmd': Operation 
> > not permitted
> > /usr/bin/install: cannot change ownership of `../../bin/Rdiff': Operation 
> > not permitted
> > /usr/bin/install: cannot change ownership of `../../bin/Rd2dvi': Operation 
> > not permitted
> > /usr/bin/install: cannot change ownership of `../../bin/Rd2txt': Operation 
> > not permitted
> > /usr/bin/install: cannot change ownership of `../../bin/config': Operation 
> > not permitted
> > /usr/bin/install: cannot change ownership of `../../bin/pager': Operation 
> > not permitted
> > /usr/bin/install: cannot change ownership of `../../bin/texi2dvi': 
> > Operation not permitted
> > 
> > Does anyone know what is the problem? (Oh, I install it as a common user
> > to linux, not as root)?
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
>



From mitsu5 at ruby.famille.ne.jp  Sun Feb  9 09:08:02 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Sun Feb  9 09:08:02 2003
Subject: [R] to modify a matrix : Summary
In-Reply-To: <Pine.SOL.3.96.1030208175720.9572C-100000@libra.cus.cam.ac.uk>
References: <Pine.SOL.3.96.1030208175720.9572C-100000@libra.cus.cam.ac.uk>
Message-ID: <200302090807.h1987WG28987@mp1.vectant.ne.jp>

I truly thank for evrybody to give me many very
good answers and suggestions.

I like to summarize the replies with their results
when excuted on R and with my comments.

My question is
> x <- matrix(1:10.,5)
> x
     [,1] [,2]
[1,]    1    6
[2,]    2    7
[3,]    3    8
[4,]    4    9
[5,]    5   10
there is a matrix. On condition x[? ,1]=3, how to modify the
appropriate location to be x[? ,2] * 5.

SUMMARY
(1) x[,2] <- x[,2]*(1+4*(x[,1]==3))
  good result, a little bit tricky.

(2) x[,2] <- ifelse(x[,1]==3, x[,2]*5, x[,2])
  good result, easy to be understood.

(3) for(i in 1:5) {if (x[,1]==3) {x[,2] <- 5*x[,2]}}
  unable to get any modification, theoretically easily undrstandable
from a programmer.

(4) rowstochange <- x[,1]==3
    x[rowstochange,2] <- x[rowstochange,2]*5
  good result, to give many suggetions.

When I excute "rowstochange <- x[,1]==3", I have
> rowstochange
[1] FALSE FALSE  TRUE FALSE FALSE  .

This is my first time to realize the meaning of the
expression of "x[,1]==3". This short sentence has inclusively
the way of "for", "repeat", and/or  "if" clauses.
This is the wonderful part of R and the difficult part.

(5) x[x[,1]==3,2] <- x[x[,1]==3,2]*5
  good result, simple, direct and straight.

My Best Gegards to everyone concerned.

-------========--------
mitsu5
mitsu5 at ruby.famille.ne.jp



From ripley at stats.ox.ac.uk  Sun Feb  9 09:19:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Feb  9 09:19:03 2003
Subject: [R] is.finite() of a list
In-Reply-To: <20030209012922.15985.qmail@operamail.com>
Message-ID: <Pine.LNX.4.44.0302090812280.28445-100000@gannet.stats>

On Sun, 9 Feb 2003, stephen wisdom wrote:

> 
> > ?is.finite
> 
>      `is.finite' and `is.infinite' return a vector of the same length
>      as `x', indicating which elements are finite or not.
> 
> is.finite() of a list seems to return a vector of the length of the list, 
but with value FALSE if any list element isn't finite.  Is this intended?

That is not the pattern, and the real pattern *is* intentional.  All
non-numeric vectors are not finite:

> is.finite(list(1,2,3))
[1] FALSE FALSE FALSE

Although a list is a generic vector, it is not a numeric vector.

I'll add that comment to the help page.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From seanpor at acm.org  Sun Feb  9 09:24:03 2003
From: seanpor at acm.org (Sean O'Riordain)
Date: Sun Feb  9 09:24:03 2003
Subject: [R] install error
In-Reply-To: <Pine.LNX.4.44.0302082246080.17377-100000@lousana.cs.ualberta.ca>
References: <Pine.LNX.4.44.0302082246080.17377-100000@lousana.cs.ualberta.ca>
Message-ID: <3E460FCB.2050000@acm.org>

Good morning Yuhong!

I've just done a rebuild of R-1.6.2 on my machine here using the 
following commands (from my history)...


    48  mkdir tmpR
    49  cd tmpR
    50  tar xzvf ../R-1.6.2.tgz
    51  pwd
    52  cd R-1.6.2/
    53  ./configure --prefix=/home/sean/software/R/tmpR
    54  make
    55  nice make check
    56  nice make install

it installed with no problem... creating the following directories...

[sean at sean4 R-1.6.2]$ pwd
/home/sean/software/R/tmpR/R-1.6.2
[sean at sean4 R-1.6.2]$ cd ..
[sean at sean4 tmpR]$ ll
total 16
drwxrwxr-x    2 sean     sean         4096 Feb  9 08:13 bin
drwxrwxr-x    3 sean     sean         4096 Feb  9 08:13 lib
drwxrwxr-x    3 sean     sean         4096 Feb  9 08:13 man
drwxr-xr-x   15 sean     sean         4096 Feb  9 07:56 R-1.6.2

where the last line is the build directory...

note that I have full permissions from my home directory /home/sean 
downwards.

could you be low on quota or disk space?

cheers,
Sean


Yuhong Guo wrote:
> I just download R-1.6.2 source code for unix 
> to install. I am intalling it under redhat linux.
> 
> But after ./configure, when I try to make, 
> there always error showed: 
> 
> /usr/bin/install: cannot change ownership of `../../bin/BATCH': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/LINK': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/Rcmd': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/Rdiff': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/Rd2dvi': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/Rd2txt': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/config': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/pager': Operation 
> not permitted
> /usr/bin/install: cannot change ownership of `../../bin/texi2dvi': 
> Operation not permitted
> 
> Does anyone know what is the problem? (Oh, I install it as a common user
> to linux, not as root)?



From gisar at nus.edu.sg  Sun Feb  9 10:24:03 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Sun Feb  9 10:24:03 2003
Subject: [R] to modify a matrix
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053EF0@MBXSRV03.stf.nus.edu.sg>

May I suggest you learn the handy function called which().

yes.rows <- which(x[,1]==3)        # Row that meets this condition
x[ yes, 2] <- x[ yes.rows, 2] * 5  # Perform the desired change for the
row that meets this condition.




At 12:04 AM 2/9/2003 +0900, Mitsuo Igarashi wrote:
>Hi All.
>
>I am quite a newbie to R.
>This is a next basic question.
>
>I have a matrix;
> > x <- matrix(1:10.,5)
> > x
>      [,1] [,2]
>[1,]    1    6
>[2,]    2    7
>[3,]    3    8
>[4,]    4    9
>[5,]    5   10
>
>I like to get a modified matrix as follows;
>      [,1] [,2]
>[1,]    1    6
>[2,]    2    7
>[3,]    3    8 * 5 -> 40
>[4,]    4    9
>[5,]    5   10
>
>The following expression does not work.
>  if (x[x[,1]==3])  x[x[,1]==3],2]*5
>
>How can I obtain a right expresion to get a modified matrix?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From vsensae at hotmail.com  Sun Feb  9 12:34:03 2003
From: vsensae at hotmail.com (Vincent Stoliaroff)
Date: Sun Feb  9 12:34:03 2003
Subject: [R] Clustering partition and memory
Message-ID: <F31DLkTVw7oNy99n22J0001e4a4@hotmail.com>


Dear R-help list members

i would like to use R to produce clustering or partitioning of a dataset.
I am trying to use the functions:
- hierclust() of the package multiv
-pam(), agnes() and fanny() of the package cluster

But I cannot get any result because of lack of memory. Would you know any 
clustering function not to greedy in memory?
I have tried to expand my memory limit with memory.limit() but no 
significant results.

Thank you for any answer that could help.
Vincent



From gisar at nus.edu.sg  Sun Feb  9 12:51:03 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Sun Feb  9 12:51:03 2003
Subject: [R] Clustering partition and memory
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053EF2@MBXSRV03.stf.nus.edu.sg>

What distance metric are you using? See if clara() in cluster library
etc is more appropriate. 

-----Original Message-----
From: Vincent Stoliaroff [mailto:vsensae at hotmail.com] 
Sent: Sunday, February 09, 2003 7:33 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Clustering partition and memory




Dear R-help list members

i would like to use R to produce clustering or partitioning of a
dataset. I am trying to use the functions:
- hierclust() of the package multiv
-pam(), agnes() and fanny() of the package cluster

But I cannot get any result because of lack of memory. Would you know
any 
clustering function not to greedy in memory?
I have tried to expand my memory limit with memory.limit() but no 
significant results.

Thank you for any answer that could help.
Vincent

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Sun Feb  9 14:45:04 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sun Feb  9 14:45:04 2003
Subject: [R] Clustering partition and memory
In-Reply-To: <F31DLkTVw7oNy99n22J0001e4a4@hotmail.com>
Message-ID: <3E4622F4.10403.2F439C@localhost>

On 9 Feb 2003 at 11:33, Vincent Stoliaroff wrote:

cluster have the function clara() "clustering large applications", 
written just to cluster large amounts of data. Did you try that?

Kjetil Halvorsen

> 
> 
> Dear R-help list members
> 
> i would like to use R to produce clustering or partitioning of a dataset.
> I am trying to use the functions:
> - hierclust() of the package multiv
> -pam(), agnes() and fanny() of the package cluster
> 
> But I cannot get any result because of lack of memory. Would you know any 
> clustering function not to greedy in memory?
> I have tried to expand my memory limit with memory.limit() but no 
> significant results.
> 
> Thank you for any answer that could help.
> Vincent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From fnj at cin.ufpe.br  Sun Feb  9 17:28:11 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Sun Feb  9 17:28:11 2003
Subject: [R] Help for to use tkbutton
Message-ID: <Pine.GSO.4.32.0302091323520.19798-100000@goiana>

Where I can to find a good help with examples?

Tks,
Francisco.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco Jnior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From brendan at peblnz.com  Sun Feb  9 21:22:03 2003
From: brendan at peblnz.com (Brendan Murray)
Date: Sun Feb  9 21:22:03 2003
Subject: [R] postgres/R access problems
Message-ID: <1044820936.871.15.camel@wolfhound.homeip.net>

Hello

I have a problem that has exhausted my ingenuity and would like pointers
to a solution, or at least where to debug.

- I am using R and postgresql.
- I have databases on two different servers.
- I have a few users, who use different client machines - whose R
installations are identical (rsync'd)

>From one client machine I can access databases on both servers, using
both psql and by connecting using db.connect()

>From another client I can access the databases on both servers using
psql, BUT I cannot connect to the database on one of the servers using
db.connect()

It looks like an authentication/authorisation problem. There are no log
entries anywhere that suggest auth/auth are failing - not in the
postgres logs,not  in the usual /var/log/* suspects. I'm using the same
user/password for psql and db.connect(). 

Any suggestions? 

Thanks

Brendan Murray



From lorenmc at socrates.berkeley.edu  Sun Feb  9 21:33:15 2003
From: lorenmc at socrates.berkeley.edu (loren mccarter)
Date: Sun Feb  9 21:33:15 2003
Subject: [R] installation on FreeBSD
In-Reply-To: <Pine.GSO.4.53.0302082329350.18164@hsph.harvard.edu>
Message-ID: <Pine.GSO.4.44.0302091215260.12254-100000@socrates.Berkeley.EDU>

I've been using R on FreeBSD for several years now so I can tell you it
works fine. However I have not yet upgraded to FreeBSD 5.0 so perhaps it
has something to do with the new version. Here's something you may want
to try: Rather than using the old version of R from the FreeBSD ports
collection, download the latest R source directly from CRAN then try to
./configure && make && make install it. I've found that R obeys the
FreeBSD 'hier' and the sources on CRAN are always more up to date than the
compliled FreeBSD packages or ports.

Loren




On Sat, 8 Feb 2003, Peng Zhang wrote:

> Hello there,
>
> I just changed to FreeBSD platform, and want to install R on it. I use
> FreeBSD 5.0 and install nearly all packages on the machine. When I use
> ports to install R, (cd /usr/ports/math/R-letter, and then type make) I
> got the following error information.
> ../../../../library/methods/libs/methods.so is unchanged
> dumping R code in package 'methods'
> Fatal error: The X11 shared library could not be loaded.
>   The error was /usr/ports/math/R-letter/work/R-1.6.0/modules/R_X11.so:
> Undefined symbol "R_GlobalEnv"
> Can somebody tell me why and how to fix this problem?
>
> Thank you for your help!
>
> Best wishes,
> Peng
>
> *******************************
> Peng Zhang
> Department of Biostatistics
> Harvard School of Public Health
> 655 Huntington Avenue
> Boston, Massachusetts 02115
> *******************************
>
> I believe I can fly
> I believe I can touch the sky
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Sun Feb  9 22:10:04 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sun Feb  9 22:10:04 2003
Subject: [R] postgres/R access problems
In-Reply-To: <1044820936.871.15.camel@wolfhound.homeip.net>
Message-ID: <Pine.GSO.4.44.0302092100240.624-100000@auk.stats>

On 10 Feb 2003, Brendan Murray wrote:

> I have a problem that has exhausted my ingenuity and would like pointers
> to a solution, or at least where to debug.
>
> - I am using R and postgresql.

And which R package are you using, which version, from which repository?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From TyagiAnupam at aol.com  Sun Feb  9 22:31:04 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Sun Feb  9 22:31:04 2003
Subject: [R] label storage and conversions: DBMS and R
Message-ID: <a8.1816510f.2b78224f@aol.com>

Hi R users, 

I am new to using DBMS with R for large datasets. Thanks to all who responded 
with useful suggestion to my earlier postings about using large datasets and 
DBMS with R. I am writing to get some help about how to design good tables in 
DBMS to take full advantage of the wonderful built-in facilities in R, like 
labels.

I am using RMySQL client. Because R makes good use of variable and value 
labels and data (column) types, I would like to create tables with 
appropriate design in terms of,
 (1) datatype (char, varchar, int, etc.) in DBMS such that it corresponds 
with the appropriate datatype in R (factor, numeric, etc.) when converted,
(2) How best to store variable and values lables and formats in DBMS, so they 
are correctly included in the data.frame that DBMS clients like RMySQL create 
for use in R. 
If I had only a few variables and values this will not be a problem; I can 
use meaningful variable names or create labels directly in R. But with 1600 
variables, many with about 10 catagorical values, this approach does not look 
promising. Is there a document somewhere that addresses this issue? What 
would be a good way to solve this problem?
Anupam.
*********************************************************
Prediction is very difficult, especially about the future. 
                  -- Niels Bohr



From brendan at peblnz.com  Sun Feb  9 22:58:03 2003
From: brendan at peblnz.com (Brendan Murray)
Date: Sun Feb  9 22:58:03 2003
Subject: [R] postgres/R access problems
In-Reply-To: <Pine.GSO.4.44.0302092100240.624-100000@auk.stats>
References: <Pine.GSO.4.44.0302092100240.624-100000@auk.stats>
Message-ID: <1044826687.880.6.camel@wolfhound.homeip.net>

On Mon, 2003-02-10 at 10:01, Prof Brian D Ripley wrote:
> On 10 Feb 2003, Brendan Murray wrote:
> 
> > I have a problem that has exhausted my ingenuity and would like pointers
> > to a solution, or at least where to debug.
> >
> > - I am using R and postgresql.
> 
> And which R package are you using, which version, from which repository?

$ R --version
R 1.5.1 (2002-06-17).
$ /usr/local/pgsql/bin/psql --version
psql (PostgreSQL) 7.2.1

repository? I didn't install this originally so I don't know where it 
came from. The chap that did has left

Perhaps  the R version is a little past its use-by, but if nobody has
ever seen the error before then upgrading isn't necessarily going to fix
it. It will be my next step if nobody can give me some idea of what
isn't working.



From pzhang at hsph.harvard.edu  Sun Feb  9 23:08:09 2003
From: pzhang at hsph.harvard.edu (Peng Zhang)
Date: Sun Feb  9 23:08:09 2003
Subject: [R] installation on FreeBSD
In-Reply-To: <Pine.GSO.4.44.0302091215260.12254-100000@socrates.Berkeley.EDU>
References: <Pine.GSO.4.44.0302091215260.12254-100000@socrates.Berkeley.EDU>
Message-ID: <Pine.GSO.4.53.0302091701270.608@hsph.harvard.edu>

Dear loren,

Thank you for your reply! I did try to install directly from source code.
However I got the following error information:

../../../../library/methods/libs/methods.so is unchanged
dumping R code in package 'methods'
Segmentation fault (core dumped)
*** Error code 139

Stop in /usr/home/pzhang/R-1.6.2/src/library/methods.
*** Error code 1

Whether is there something wrong with my X settings? Thank you for your
help.

Best wishes,
Peng

*******************************
Peng Zhang
Department of Biostatistics
Harvard School of Public Health
655 Huntington Avenue
Boston, Massachusetts 02115
*******************************

I believe I can fly
I believe I can touch the sky

On Sun, 9 Feb 2003, loren mccarter wrote:

> I've been using R on FreeBSD for several years now so I can tell you it
> works fine. However I have not yet upgraded to FreeBSD 5.0 so perhaps it
> has something to do with the new version. Here's something you may want
> to try: Rather than using the old version of R from the FreeBSD ports
> collection, download the latest R source directly from CRAN then try to
> ./configure && make && make install it. I've found that R obeys the
> FreeBSD 'hier' and the sources on CRAN are always more up to date than the
> compliled FreeBSD packages or ports.
>
> Loren
>
>
>
>
> On Sat, 8 Feb 2003, Peng Zhang wrote:
>
> > Hello there,
> >
> > I just changed to FreeBSD platform, and want to install R on it. I use
> > FreeBSD 5.0 and install nearly all packages on the machine. When I use
> > ports to install R, (cd /usr/ports/math/R-letter, and then type make) I
> > got the following error information.
> > ../../../../library/methods/libs/methods.so is unchanged
> > dumping R code in package 'methods'
> > Fatal error: The X11 shared library could not be loaded.
> >   The error was /usr/ports/math/R-letter/work/R-1.6.0/modules/R_X11.so:
> > Undefined symbol "R_GlobalEnv"
> > Can somebody tell me why and how to fix this problem?
> >
> > Thank you for your help!
> >
> > Best wishes,
> > Peng
> >
> > *******************************
> > Peng Zhang
> > Department of Biostatistics
> > Harvard School of Public Health
> > 655 Huntington Avenue
> > Boston, Massachusetts 02115
> > *******************************
> >
> > I believe I can fly
> > I believe I can touch the sky
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>



From fharrell at virginia.edu  Sun Feb  9 23:16:07 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sun Feb  9 23:16:07 2003
Subject: [R] label storage and conversions: DBMS and R
In-Reply-To: <a8.1816510f.2b78224f@aol.com>
References: <a8.1816510f.2b78224f@aol.com>
Message-ID: <20030209170604.6b97b3d1.fharrell@virginia.edu>

On Sun, 9 Feb 2003 16:29:51 EST
TyagiAnupam at aol.com wrote:

> Hi R users, 
> 
> I am new to using DBMS with R for large datasets. Thanks to all who responded 
> with useful suggestion to my earlier postings about using large datasets and 
> DBMS with R. I am writing to get some help about how to design good tables in 
> DBMS to take full advantage of the wonderful built-in facilities in R, like 
> labels.
> 
> I am using RMySQL client. Because R makes good use of variable and value 
> labels and data (column) types, I would like to create tables with 
> appropriate design in terms of,
>  (1) datatype (char, varchar, int, etc.) in DBMS such that it corresponds 
> with the appropriate datatype in R (factor, numeric, etc.) when converted,
> (2) How best to store variable and values lables and formats in DBMS, so they 
> are correctly included in the data.frame that DBMS clients like RMySQL create 
> for use in R. 
> If I had only a few variables and values this will not be a problem; I can 
> use meaningful variable names or create labels directly in R. But with 1600 
> variables, many with about 10 catagorical values, this approach does not look 
> promising. Is there a document somewhere that addresses this issue? What 
> would be a good way to solve this problem?
> Anupam.
> *********************************************************
> Prediction is very difficult, especially about the future. 
>                   -- Niels Bohr
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

We are working on a PostgrSQL-based system in which all metadata are defined in XML.  Ultimately I will interpret the XML metadata in R to fetch the variable labels.  In the Hmisc library I have a label function to make it easy to assign a 'label' attribute to an individual variable, and a function upData which makes it easy to assign lots of labels.  I will use the same 'label' attribute these use when fetching labels from XML.

Another possibility is to make a table defining variable-specific metadata.  Then you could just read in the table and write a short function to pull out labels after matching on variable names, assigning the labels to an attribute of your choosing.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From ripley at stats.ox.ac.uk  Sun Feb  9 23:25:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Feb  9 23:25:03 2003
Subject: [R] postgres/R access problems
In-Reply-To: <1044826687.880.6.camel@wolfhound.homeip.net>
Message-ID: <Pine.LNX.4.44.0302092158300.23604-100000@gannet.stats>

I was asking about which R *package* and version: R itself does not
interface to any DBMS, but there are several ways to interface to PgSQL
and they are *packages* like RPgSQL, which has different versions in
different repositories (although AFAIK none are current on CRAN).
(There is also a dbi.something package.)

That's the vital piece of information: db.connect is not a part of R per 
se, and that seems to be where the problem is.

On 10 Feb 2003, Brendan Murray wrote:

> On Mon, 2003-02-10 at 10:01, Prof Brian D Ripley wrote:
> > On 10 Feb 2003, Brendan Murray wrote:
> > 
> > > I have a problem that has exhausted my ingenuity and would like pointers
> > > to a solution, or at least where to debug.
> > >
> > > - I am using R and postgresql.
> > 
> > And which R package are you using, which version, from which repository?
> 
> $ R --version
> R 1.5.1 (2002-06-17).
> $ /usr/local/pgsql/bin/psql --version
> psql (PostgreSQL) 7.2.1
> 
> repository? I didn't install this originally so I don't know where it 
> came from. The chap that did has left
> 
> Perhaps  the R version is a little past its use-by, but if nobody has
> ever seen the error before then upgrading isn't necessarily going to fix
> it. It will be my next step if nobody can give me some idea of what
> isn't working.
> 
> 
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From brendan at peblnz.com  Sun Feb  9 23:37:03 2003
From: brendan at peblnz.com (Brendan Murray)
Date: Sun Feb  9 23:37:03 2003
Subject: [R] postgres/R access problems
In-Reply-To: <Pine.LNX.4.44.0302092158300.23604-100000@gannet.stats>
References: <Pine.LNX.4.44.0302092158300.23604-100000@gannet.stats>
Message-ID: <1044829089.880.46.camel@wolfhound.homeip.net>

On Mon, 2003-02-10 at 11:06, ripley at stats.ox.ac.uk wrote:
> I was asking about which R *package* and version: R itself does not
> interface to any DBMS, but there are several ways to interface to PgSQL
> and they are *packages* like RPgSQL, which has different versions in
> different repositories (although AFAIK none are current on CRAN).
> (There is also a dbi.something package.)

Ah. Now that my brain is in gear.....  the db.connect in question looks
to be from RPgSQL. I suspect it came from sourceforge. Interesting that
the maintainer has declared it obsolete - I didn't realise that. More
complications

Package: RPgSQL
Version: 1.0-0
Date: Wed Jun 20 15:18:04 EDT 2001
Title: PostgreSQL access
Author: Timothy H. Keitt <thk at users.sourceforge.net>
Maintainer: Timothy H. Keitt <thk at users.sourceforge.net>
Description: Provides methods for accessing data stored in PostgreSQL
             tables.
Depends: R (>= 1.2)
License: GPL (version 2 or higher; see LICENSE)
URL: http://rpgsql.sourceforge.net/
Built: R 1.5.1; i686-pc-linux-gnu; Fri Jul 5 16:50:14 NZST 2002

These are the loaded libraries from the script I was using to test.

library(DBI)
library(Rdbi)
library(RPgSQL)

I have since tried it without DBI and Rdbi and got exactly the same
error 

Error in db.connect(host = "praetorius", .... 

This is the whole script (passwords elided)

# mine.R
thingy <- function(){

#CLEANING UP AND LOADING THE NECESSARY R FUNCTIONS
rm(list=ls())

#library(DBI)
#library(Rdbi)
library(RPgSQL)

#SELECT THE HYBS TO BE NORMALISED
query <- paste("select usename from pg_user");

print(query);

db.connect(host="praetorius",dbname="testdb",
pass="XXXXXXX",user="brendan"); 
db.execute(query, clear=F);

things<- db.fetch.result();
print(things);

}
# end script

The 'select' works just fine if I use it in psql

> 
> That's the vital piece of information: db.connect is not a part of R per 
> se, and that seems to be where the problem is.

Oh yeah. That part I got to, and thats where my only-recent exposure to
R started me lost. I know unix backwards, but I'm an OS person, not an
app person. I know that when I use tcpdump to trace the transactions the
machines are talking together, and I can't see anything particularly
different between the transactions when it works and when it doesn't,
except that the one that works returns data. 

R is happy  enough when I get the data. I've just got this odd ball
problem where it seems to work fine on some boxes and not on others,
despite the fact that they should be damn near identical. The box that
works is the 'definitive' workstation in the lab and we rsync changes to
it out to the others, though that doesn't stop them getting slowly
different from each other as various people need specific
enhancements/software. 

\
> >



From cadolph at fas.harvard.edu  Mon Feb 10 00:20:03 2003
From: cadolph at fas.harvard.edu (Christopher Adolph)
Date: Mon Feb 10 00:20:03 2003
Subject: [R] Wireframe (lattice) questions
Message-ID: <Pine.OSF.4.44.0302091814420.11333-100000@is05.fas.harvard.edu>

I have a few questions on formatting wireframe plots:

1.  How can I remove (or at least "white-out") the border on the plot?
(I.e., the 2-d box around the whole plotting area, not the 3-d cube).  I'm
willing to hack the code if necessary.

2.  Is it possible to suppress plotting of all sides of the cube except
for the axes?

3.  Is there a reliable way to print expressions in wireframe plots?  I'm
using the same code I use for other plots, but can't seem to get Greek
letters in the plots.  E.g.,

xlabstr <- expression(rho);

....

print(wireframe(z ~ p1 * p2,
                    data=data,
                    zoom=zoom,
                    drape = drape,
                    perspective = perspective,
                    colorkey = colorkey,
                    xlab=xlabstr,
                    ylab=ylabstr,
                    zlab=zlabstr,
                    scales = scales,
                    distance= distance,
                    screen = screen,
                    aspect = aspect,
                    scpos = scpos,
                    shade = shade,
                    shade.colors = function(cosangle, height)
                    palette.shade(cosangle, height = .5, saturation =
.05),
                    light.source = c(0, 0, 1),
                    panel.3d.wire=panel.custom
                    ));

Thanks in advance,

Chris



From cpp at normandnet.fr  Mon Feb 10 00:51:13 2003
From: cpp at normandnet.fr (cpp@normandnet.fr)
Date: Mon Feb 10 00:51:13 2003
Subject: [R] nomogram
Message-ID: <003201c2d096$7f098f80$5e1824d5@ppp>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030210/7ea41301/attachment.pl

From deepayan at stat.wisc.edu  Mon Feb 10 01:04:05 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon Feb 10 01:04:05 2003
Subject: [R] Wireframe (lattice) questions
In-Reply-To: <Pine.OSF.4.44.0302091814420.11333-100000@is05.fas.harvard.edu>
References: <Pine.OSF.4.44.0302091814420.11333-100000@is05.fas.harvard.edu>
Message-ID: <200302091800.45214.deepayan@stat.wisc.edu>

On Sunday 09 February 2003 05:19 pm, Christopher Adolph wrote:
> I have a few questions on formatting wireframe plots:
>
> 1.  How can I remove (or at least "white-out") the border on the plot?
> (I.e., the 2-d box around the whole plotting area, not the 3-d cube).  I'm
> willing to hack the code if necessary.

You would have to change print.trellis. Find the part that looks like


                            pargs <- c(x$panel.args[[panel.number]],
                                       x$panel.args.common)
                            if (!("..." %in% names(formals(panel))))
                                pargs <- pargs[names(formals(panel))]
                            do.call("panel", pargs)

                            grid.rect()

and comment out the grid.rect() part. 


> 2.  Is it possible to suppress plotting of all sides of the cube except
> for the axes?

No, not currently.

> 3.  Is there a reliable way to print expressions in wireframe plots?  I'm
> using the same code I use for other plots, but can't seem to get Greek
> letters in the plots.  E.g.,

This is definitely a bug in lattice. For now, you could work around it with

xlabstr <- list(expression(rho))


> xlabstr <- expression(rho);
>
> ....
>
> print(wireframe(z ~ p1 * p2,
>                     data=data,
>                     zoom=zoom,
>                     drape = drape,
>                     perspective = perspective,
>                     colorkey = colorkey,
>                     xlab=xlabstr,
>                     ylab=ylabstr,
>                     zlab=zlabstr,
>                     scales = scales,
>                     distance= distance,
>                     screen = screen,
>                     aspect = aspect,
>                     scpos = scpos,
>                     shade = shade,
>                     shade.colors = function(cosangle, height)
>                     palette.shade(cosangle, height = .5, saturation =
> .05),
>                     light.source = c(0, 0, 1),
>                     panel.3d.wire=panel.custom
>                     ));
>
> Thanks in advance,
>
> Chris
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From fharrell at virginia.edu  Mon Feb 10 02:07:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon Feb 10 02:07:03 2003
Subject: [R] nomogram
In-Reply-To: <003201c2d096$7f098f80$5e1824d5@ppp>
References: <003201c2d096$7f098f80$5e1824d5@ppp>
Message-ID: <20030209200624.4f50a360.fharrell@virginia.edu>

On Mon, 10 Feb 2003 00:53:50 +0100
cpp at normandnet.fr wrote:

> somebody can help me to draw a nomogram
> of the Cumulative Binomiale Distribution
> or simple example of nomogram
> cpp at normandnet.fr
> 
> Pascal (France)
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

I guess this means that my reply to you a few weeks ago (which you did not acknowledge) when you first asked the question was not helpful.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From hb at maths.lth.se  Mon Feb 10 02:57:03 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Mon Feb 10 02:57:03 2003
Subject: [R] to modify a vector
In-Reply-To: <200302080642.h186gBG28417@mp1.vectant.ne.jp>
Message-ID: <000d01c2d0a7$85ff6ba0$7341a8c0@alpha.wehi.edu.au>

Hi, if I understand you correctly, you would like to change the value of
all elements with current value of 3 to 9. This is how you do it:

   a1 <- c(1,2,3,4,3,5)

   idx <- (a1 == 3)
   a1[idx] <- 9

or in one line

   a1[a1 == 3] <- 9

Look at 'idx' above. It is a logical vector of the same length as 'a1',
i.e.

   idx:   FALSE FALSE  TRUE FALSE  TRUE FALSE

When you then do 'a1[idx]' you select only those elements for which idx
is TRUE, here it is the third and the fifth. 'a1[idx] <- 9' selects
those elements and then assign the value 9 to them. Details: You could
also have done

   idx <- which(a1 == 3)

where 'idx' then becomes equal to c(3,5), giving 'a1[c(3,5)] <- 9',
which gives identical results (of course).

Hope this helps

Henrik Bengtsson


> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Mitsuo Igarashi
> Sent: den 8 februari 2003 17:42
> To: r-help at stat.math.ethz.ch
> Subject: [R] to modify a vector
> 
> 
> Hi All.
> 
> I am quite a newbie to R.
> This is a basic question.
> 
> I like to modify elements of a vector.
> For Example:
> a1 <- c(1,2,3,4,3,5)
> 
> TThe following program sentence does not work but the intention is;
>   
>   if (a1==3) a1*3 .
> 
> 3 in the vector should be changed to 9, and
> the resulted vector is (1,2,9,4,9,5).
> 
> How can I get the result?
> 
> Thanks in advance for help.
> -------========--------
> mitsu5
> mitsu5 at ruby.famille.ne.jp
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From s.mcclatchie at niwa.co.nz  Mon Feb 10 03:12:03 2003
From: s.mcclatchie at niwa.co.nz (Sam McClatchie)
Date: Mon Feb 10 03:12:03 2003
Subject: [R] calling sweave function from LaTex re directories, formatting
Message-ID: <3E470A29.9070501@niwa.cri.nz>

System info:
Mandrake 9.0
R Version 1.6.1
ESS 5.1.21
Emacs 21.2.1
-------------------

Colleagues

I have followed suggestions by David Whiting, Friedrich Leisch and Frank 
Harrell, but have a few more queries.

1. On formatting:

I added the suggested sweave customization to my .emacs file

; Sweave customisation
(defun Rnw-mode ()
   (require 'ess-noweb)
   (noweb-mode)
   (if (fboundp 'R-mode)
       (setq noweb-default-code-mode 'R-mode)))
(add-to-list 'auto-mode-alist '("\\.Rnw\\'" . Rnw-mode))
(add-to-list 'auto-mode-alist '("\\.Snw\\'" . Rnw-mode))

(setq reftex-file-extensions
       '(("Snw" "Rnw" "nw" "tex" ".tex" ".ltx") ("bib" ".bib")))
(setq TeX-file-extensions
       '("Snw"  "Rnw" "nw" "tex" "sty" "cls" "ltx" "texi" "texinfo"))

but I am a bit puzzled that the LaTex color coding is lost in the 
foo.Rnw file. It does work if I rename the file foo.tex.


2. On directories

I like to keep my directories structred under /projects/ with 
subdirectories for ../R/, ../report/, ../figures/ and so forth.
So my foo.Rnw is in /projects/reports.

I set up an executable file to process foo.Rnw by calling Sweave from 
the R tools library, and run this shell from my /projects reports 
directory, as follows:

process foo.Rnw

where *process is

#!/bin/sh
echo "library(tools); Sweave(\"$1\")" | R --no-save --no-restore

In my LaTex document, I set the eval option to FALSE if I don't want the 
Sweave chunks to run

<<echo=false,results=hide,eval=FALSE>>=
'../R/R-src/vary.mean.roughy.density()'
@

However, I haven't been able to get the code to find the R script when 
called from a directory tree like this when eval=TRUE.

If I put foo.Rnw in /projects/R and Sweave("foo.Rnw") the process runs, 
producing a foo.tex file and foo.eps and foo.pdf files, but the foo.pdf 
gives and empty page error on loading into Acrobat 5.0.

OK, so I'm screwing something up here, but am not sure exactly what. The 
R script runs fine and generates a pdf graph okay on its own. Any help, 
gratefully received.

Best fishes

Sam

-- 
Sam McClatchie, Research scientist (fisheries acoustics))))))))))
NIWA (National Institute of Water & Atmospheric Research Ltd)
PO Box 14 901, Kilbirnie, Wellington, New Zealand
s.mcclatchie at niwa.cri.nz
Research home page <http://www.smcc.150m.com/>
                       /\
            >><xX(&>
                    /// \\\
                   //// \\\\
                  ///  <%)Xx><<
                 /////  \\\\\\
           ><(((@>
     ><(((%>     ..>><xX(?>O<?)Xx><<



From lorenmc at socrates.berkeley.edu  Mon Feb 10 03:50:03 2003
From: lorenmc at socrates.berkeley.edu (loren mccarter)
Date: Mon Feb 10 03:50:03 2003
Subject: [R] installation on FreeBSD
In-Reply-To: <Pine.GSO.4.53.0302091701270.608@hsph.harvard.edu>
Message-ID: <Pine.GSO.4.44.0302091811200.10687-100000@socrates.Berkeley.EDU>

I'm not sure what is causing it to dump core. I'm using FreeBSD 4.7 and
I'm waiting for 5.1 before upgrading so I can't troubleshoot it on my
end. Here are some things you may want to try: (1)~use /stand/sysinstall
to add R as a binary package (R-1.5.1_1 is available this way), (2)~if
you think it's X, try configuring R to install without X (I think there
is a configure option for this, something like: configure --without-x).
(3)~when you installed the FreeBSD packages, make sure that none of them
had XFree86 3.3.6 as a dependency, which would cause it to overwrite the 4.2
libraries (but, you'd really notice if this happened this b/c X would not
work at all, not just R). (4)~if this is a brand new machine setup, you
may want to use the more stable FreeBSD 4.7 until 5.1 comes out in a few
months. Of course, none of those suggestions are ideal, but may help you
to trouble shoot the issue.

Loren


On Sun, 9 Feb 2003, Peng Zhang wrote:

> Dear loren,
>
> Thank you for your reply! I did try to install directly from source code.
> However I got the following error information:
>
> ../../../../library/methods/libs/methods.so is unchanged
> dumping R code in package 'methods'
> Segmentation fault (core dumped)
> *** Error code 139
>
> Stop in /usr/home/pzhang/R-1.6.2/src/library/methods.
> *** Error code 1
>
> Whether is there something wrong with my X settings? Thank you for your
> help.
>
> Best wishes,
> Peng
>
> *******************************
> Peng Zhang
> Department of Biostatistics
> Harvard School of Public Health
> 655 Huntington Avenue
> Boston, Massachusetts 02115
> *******************************
>
> I believe I can fly
> I believe I can touch the sky
>
> On Sun, 9 Feb 2003, loren mccarter wrote:
>
> > I've been using R on FreeBSD for several years now so I can tell you it
> > works fine. However I have not yet upgraded to FreeBSD 5.0 so perhaps it
> > has something to do with the new version. Here's something you may want
> > to try: Rather than using the old version of R from the FreeBSD ports
> > collection, download the latest R source directly from CRAN then try to
> > ./configure && make && make install it. I've found that R obeys the
> > FreeBSD 'hier' and the sources on CRAN are always more up to date than the
> > compliled FreeBSD packages or ports.
> >
> > Loren
> >
> >
> >
> >
> > On Sat, 8 Feb 2003, Peng Zhang wrote:
> >
> > > Hello there,
> > >
> > > I just changed to FreeBSD platform, and want to install R on it. I use
> > > FreeBSD 5.0 and install nearly all packages on the machine. When I use
> > > ports to install R, (cd /usr/ports/math/R-letter, and then type make) I
> > > got the following error information.
> > > ../../../../library/methods/libs/methods.so is unchanged
> > > dumping R code in package 'methods'
> > > Fatal error: The X11 shared library could not be loaded.
> > >   The error was /usr/ports/math/R-letter/work/R-1.6.0/modules/R_X11.so:
> > > Undefined symbol "R_GlobalEnv"
> > > Can somebody tell me why and how to fix this problem?
> > >
> > > Thank you for your help!
> > >
> > > Best wishes,
> > > Peng
> > >
> > > *******************************
> > > Peng Zhang
> > > Department of Biostatistics
> > > Harvard School of Public Health
> > > 655 Huntington Avenue
> > > Boston, Massachusetts 02115
> > > *******************************
> > >
> > > I believe I can fly
> > > I believe I can touch the sky
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From vsensae at hotmail.com  Mon Feb 10 04:53:02 2003
From: vsensae at hotmail.com (Vincent Stoliaroff)
Date: Mon Feb 10 04:53:02 2003
Subject: [R] Clustering partition and memory
Message-ID: <F172gzBscdTfMqiXYd400020771@hotmail.com>


Thanks.
Clara() is performing well.
I had a dataset of 7500 rows and the clustering was produced very quickly




>From: "Adaikalavan Ramasamy" <gisar at nus.edu.sg>
>To: "Vincent Stoliaroff" <vsensae at hotmail.com>,<r-help at stat.math.ethz.ch>
>Subject: RE: [R] Clustering partition and memory
>Date: Sun, 9 Feb 2003 19:50:24 +0800
>
>What distance metric are you using? See if clara() in cluster library
>etc is more appropriate.
>
>-----Original Message-----
>From: Vincent Stoliaroff [mailto:vsensae at hotmail.com]
>Sent: Sunday, February 09, 2003 7:33 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Clustering partition and memory
>
>
>
>
>Dear R-help list members
>
>i would like to use R to produce clustering or partitioning of a
>dataset. I am trying to use the functions:
>- hierclust() of the package multiv
>-pam(), agnes() and fanny() of the package cluster
>
>But I cannot get any result because of lack of memory. Would you know
>any
>clustering function not to greedy in memory?
>I have tried to expand my memory limit with memory.limit() but no
>significant results.
>
>Thank you for any answer that could help.
>Vincent
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gregory.benmenzer at gazdefrance.com  Mon Feb 10 10:18:05 2003
From: gregory.benmenzer at gazdefrance.com (Gregory BENMENZER)
Date: Mon Feb 10 10:18:05 2003
Subject: [R] nls
Message-ID: <OF088557A9.74A16735-ON41256CC9.003265DE@notes.edfgdf.fr>

Hello,

I want to estimate parameters of the model y=a/x with x=1:10 and y=3/x.
I tested the NLS function.

Could you tell me why it doesn't converge ?

Regards,

Gr?gory Benmenzer

> x=1:10
> y=3/x
> nls(y~a/x, start=list(a=2), control=nls.control(maxiter=100))
Error in nls(y ~ a/x, start = list(a = 2), control = nls.control(maxiter = 100)) :
        number of iterations exceeded maximum of 100
>



From ripley at stats.ox.ac.uk  Mon Feb 10 10:33:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon Feb 10 10:33:03 2003
Subject: [R] nls
In-Reply-To: <OF088557A9.74A16735-ON41256CC9.003265DE@notes.edfgdf.fr>
Message-ID: <Pine.WNT.4.44.0302100931080.3656-100000@petrel>

Don't use nls for exact fits, as that's not what it is intended for, and
you are trying to achieve a fit to machine accuracy with rounding errors.

You will find several discussions of this in the archives.

On Mon, 10 Feb 2003, Gregory BENMENZER wrote:

> I want to estimate parameters of the model y=a/x with x=1:10 and y=3/x.
> I tested the NLS function.
>
> Could you tell me why it doesn't converge ?
>
> Regards,
>
> Grgory Benmenzer
>
> > x=1:10
> > y=3/x
> > nls(y~a/x, start=list(a=2), control=nls.control(maxiter=100))
> Error in nls(y ~ a/x, start = list(a = 2), control = nls.control(maxiter = 100)) :
>         number of iterations exceeded maximum of 100

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From laurent at cbs.dtu.dk  Mon Feb 10 10:50:03 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Mon Feb 10 10:50:03 2003
Subject: [R] Memory allocation, IBM-AIX and R-1.6.2
Message-ID: <20030210094945.GC20148647@genome.cbs.dtu.dk>

Dear all,
         
I compiled R-1.6.2 for IBM-AIX (using the native compilers)
and I am facing problems to instanciate (rather) large     
matrices.
I have:  
>  m <- matrix(0, 640*640, 102)
Error: cannot allocate vector of size 326400 Kb

I am not truly familiar with AIX, but this does not
seem to be caused by kernel/user limitations:      

ulimit -Ha gives:
                 
core file size        (blocks, -c) unlimited
data seg size         (kbytes, -d) unlimited
file size             (blocks, -f) unlimited
max memory size       (kbytes, -m) unlimited
open files                    (-n) unlimited
pipe size          (512 bytes, -p) 64       
stack size            (kbytes, -s) unlimited
cpu time             (seconds, -t) unlimited
max user processes            (-u) 512      
virtual memory        (kbytes, -v) unlimited


Can anyone (with similar settings) create large objects ?


L.




-- 
--------------------------------------------------------------
currently at the National Yang-Ming University in Taipei, Taiwan
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent



From steffen.durinck at esat.kuleuven.ac.be  Mon Feb 10 12:06:05 2003
From: steffen.durinck at esat.kuleuven.ac.be (Steffen Durinck)
Date: Mon Feb 10 12:06:05 2003
Subject: [R] hashmaps/hashtables and R
Message-ID: <1044874789.1039.8.camel@sista-08.esat.kuleuven.ac.be>

Dear,

Do hashmaps or hashtables exist in R?
If so how can I implement them?

Kind Regards,
Steffen



From emb7 at st-andrews.ac.uk  Mon Feb 10 14:09:05 2003
From: emb7 at st-andrews.ac.uk (Martin Biuw)
Date: Mon Feb 10 14:09:05 2003
Subject: [R] Factor level comparisons in lme
Message-ID: <5.1.0.14.0.20030210124611.02308be0@gatty.st-and.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030210/eead8a70/attachment.pl

From jfox at mcmaster.ca  Mon Feb 10 14:16:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon Feb 10 14:16:03 2003
Subject: [R] nls
In-Reply-To: <OF088557A9.74A16735-ON41256CC9.003265DE@notes.edfgdf.fr>
Message-ID: <5.1.0.14.2.20030210081052.01df9468@mcmail.cis.mcmaster.ca>

Dear Gregory,

As Brian Ripley pointed out (and as the help page for nls mentions), you 
shouldn't test nls on zero-residual data. But, in any event, you can fit 
this model with linear least squares, as lm(y ~ I(1/x) - 1).

I hope that this helps,
  John

At 10:11 AM 2/10/2003 +0100, Gregory BENMENZER wrote:
>Hello,
>
>I want to estimate parameters of the model y=a/x with x=1:10 and y=3/x.
>I tested the NLS function.
>
>Could you tell me why it doesn't converge ?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From zeileis at ci.tuwien.ac.at  Mon Feb 10 14:37:03 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Mon Feb 10 14:37:03 2003
Subject: [R] DSC 2003: Workshop on Distributed Statistical Computing
Message-ID: <200302101336.h1ADaVPX025209@thorin.ci.tuwien.ac.at>

Dear R users,

the preliminary program for the 3rd international workshop on 
'Distributed Statistical Computing' (DSC 2003) is now available at
  http://www.ci.tuwien.ac.at/Conferences/DSC-2003/

The workshop will take place at the Technische Universit?t Wien in 
Vienna, Austria from March 20-22. The deadline for registrations is 
March 14, but the deadline for early registration ends on February 14. 
Further details can be found on the webpage.

This workshop will deal with future directions in (open source) 
statistical computing and graphics. Topics of particular interest 
include:
    * Bioinformatics
    * Database Connectivity
    * Graphical Modeling
    * User Interfaces and Office Integration
    * Resample and Combine Methods
    * Spatial Statistics
    * Visualization

Emphasis will be given to the R, Omegahat and BioConductor projects. 

In addition to the conference program there will be several half-day 
tutorials on March 19 about:
  * An Introduction to BioConductor
  * Exploring Genomic Data Using R and BioConductor
  * Writing R Extensions
  * R Graphics

For the organization committee
Achim Zeileis


------------------------------------
Achim Zeileis
Institut f?r Statistik
Technische Universit?t Wien
http://www.ci.tuwien.ac.at/~zeileis/



From ernesto at ipimar.pt  Mon Feb 10 15:34:03 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon Feb 10 15:34:03 2003
Subject: [R] shapiro.test
Message-ID: <1044887778.31477.24.camel@gandalf>

Hi

The shapiro.test function outputs a value of the W statistic, which
should be 1 if the distribution is normal, and a p-value for the test
(as the documentation states).

I'm a bit confused with some results. I'm getting a W=0.9977 and a
p-value=0.1889.

I was expecting that a W of 0.9977 would tell me that the distribution
is normal so p-value should be small ...

What am I missing ?

Thanks

EJ



From rab at nauticom.net  Mon Feb 10 15:41:02 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Mon Feb 10 15:41:02 2003
Subject: [R] shapiro.test
In-Reply-To: <1044887778.31477.24.camel@gandalf>
References: <1044887778.31477.24.camel@gandalf>
Message-ID: <3E47BB75.7080701@nauticom.net>

Ernesto Jardim wrote:

>Hi
>
>The shapiro.test function outputs a value of the W statistic, which
>should be 1 if the distribution is normal, and a p-value for the test
>(as the documentation states).
>
>I'm a bit confused with some results. I'm getting a W=0.9977 and a
>p-value=0.1889.
>
>I was expecting that a W of 0.9977 would tell me that the distribution
>is normal so p-value should be small ...
>
>What am I missing ?
>
>Thanks
>
>EJ
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>  
>
You have it backwards. The null hypothesis is that the distribution is 
Normal. You reject this null when the p-value is small. If the 
distribution is Normal, the p-value will tend to be large.

 > shapiro.test(rnorm(100))

        Shapiro-Wilk normality test

data:  rnorm(100)
W = 0.9877, p-value = 0.4894


Rick B.



From luca at stat.unipg.it  Mon Feb 10 15:44:24 2003
From: luca at stat.unipg.it (Luca Scrucca)
Date: Mon Feb 10 15:44:24 2003
Subject: [R] problems using lqs()
Message-ID: <Pine.SOL.4.50.0302101538420.24463-100000@pearson.stat.unipg.it>

Dear List-members,

I found a strange behaviour in the lqs function.
Suppose I have the following data:

y <-  c(7.6, 7.7, 4.3, 5.9, 5.0, 6.5, 8.3, 8.2, 13.2, 12.6, 10.4, 10.8,
13.1, 12.3, 10.4, 10.5, 7.7, 9.5, 12.0, 12.6, 13.6, 14.1, 13.5, 11.5,
12.0, 13.0, 14.1, 15.1)
x1 <- c(8.2, 7.6,, 4.6, 4.3, 5.9, 5.0, 6.5, 8.3, 10.1, 13.2, 12.6, 10.4,
10.8, 13.1, 13.3, 10.4, 10.5, 7.7, 10.0, 12.0, 12.1, 13.6, 15.0, 13.5,
11.5, 12.0, 13.0, 14.1)
x2 <- c(23.005, 23.873, 26.417, 24.868, 29.895, 24.200, 23.215, 21.862,
22.274, 23.830, 25.144, 22.430, 21.785, 22.380, 23.927, 33.443, 24.859,
22.686, 21.789, 22.041, 21.033, 21.005, 25.865, 26.290, 22.932, 21.313,
20.769, 21.393)

and I would like to fit the following model:

mod1 <- lqs(y ~ x1 + x2, method="lms", nsamp="exact")
mod1$coefficients
(Intercept)          x1          x2
 35.5293489   0.4422742  -1.2944534
mod1$bestone
[1] 12 17 27

Now, instead of using the formula, I want to provide the design matrix and
the response, then:

X <- cbind(1, x1, x2)
mod2 <- lqs.default(X, y, intercept=F, method="lms", nsamp="exact")
mod2$coefficients
                   x1         x2
35.4217275  0.4276641 -1.2834731
mod2$bestone
[1]  6 14 15

The results are not the same (?!). Furthermore, if I create the design
matrix without the column of 1's for the intercept:

X <- cbind(x1, x2)
mod3 <- lqs.default(X, y, intercept=T, method="lms", nsamp="exact")
> mod3$coefficients
(Intercept)          x1          x2
 35.5293489   0.4422742  -1.2944534
> mod3$bestone
[1] 12 17 27

I get the same result I had using the formula (see mod1).
This is confusing me!

Another small problem appears if I re-fit the first model using the
formula and asking to return the x-matrix and the response:

lqs(y ~ x1 + x2, method="lms", nsamp="exact", x.ret=T, y.ret=T)

Error in model.frame(formula, rownames, variables, varnames, extras,
extranames,  :
	variable lengths differ

Does anyone know what's going on?

Regards, with thanks in advance,

Luca Scrucca


+-----------------------------------------------------------------------+
| Dr. Luca Scrucca                                                      |
| Dipartimento di Scienze Statistiche      tel. +39 - 075 - 5855278     |
| Universita' degli Studi di Perugia       fax. +39 - 075 - 43242       |
| Via Pascoli - C.P. 1315 Succ. 1                                       |
| 06100 PERUGIA  (ITALY)                                                |
|                                                                       |
| E-mail:   luca at stat.unipg.it                                          |
| Web page: http://www.stat.unipg.it/luca                               |
+-----------------------------------------------------------------------+



From hedderik at cmu.edu  Mon Feb 10 15:50:15 2003
From: hedderik at cmu.edu (Hedderik van Rijn)
Date: Mon Feb 10 15:50:15 2003
Subject: [R] Importing e-prime data
Message-ID: <E1D4F54D-3D06-11D7-85A6-000393678426@cmu.edu>

Before I'm reinventing the wheel: did anyone already work on an E-Prime 
(experiment presentation and data collection tool used in Psychology, 
http://www.pstnet.com/e-prime/default.htm) data import function?

   - Hedderik.

(Googling with "e-prime site:r-project.org" didn't result in any hits.)

--
http://www.van-rijn.org



From laurent at cbs.dtu.dk  Mon Feb 10 16:03:02 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Mon Feb 10 16:03:02 2003
Subject: [R] Memory allocation, IBM-AIX and R-1.6.2 - addendum
In-Reply-To: <Pine.SOL.4.44.0302100928090.10496-100000@rygar.gpcc.itd.umich.edu>
References: <20030210140210.GA20140183@genome.cbs.dtu.dk> <Pine.SOL.4.44.0302100928090.10496-100000@rygar.gpcc.itd.umich.edu>
Message-ID: <20030210150317.GB20831840@genome.cbs.dtu.dk>

...sorry for the spam, but answers I get to my previous
question suggest that I should specify that the
machine has a *lot* of memory and should be able
to the instanciation...

Anybody with an IBM mainframe, R-1.6.2 and large
matrices ?

L.



From ernesto at ipimar.pt  Mon Feb 10 16:18:02 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon Feb 10 16:18:02 2003
Subject: [R] shapiro.test
In-Reply-To: <3E47BB75.7080701@nauticom.net>
References: <1044887778.31477.24.camel@gandalf> 
	<3E47BB75.7080701@nauticom.net>
Message-ID: <1044890421.31479.31.camel@gandalf>

Ok, let me put it the other way around.

On another test I have W = 0.9907, p-value = 6.024e-06. The same
question stands, with such huge W should it be expected to be normal ?

EJ

On Mon, 2003-02-10 at 14:47, Richard A. Bilonick wrote:
> Ernesto Jardim wrote:
> 
> >Hi
> >
> >The shapiro.test function outputs a value of the W statistic, which
> >should be 1 if the distribution is normal, and a p-value for the test
> >(as the documentation states).
> >
> >I'm a bit confused with some results. I'm getting a W=0.9977 and a
> >p-value=0.1889.
> >
> >I was expecting that a W of 0.9977 would tell me that the distribution
> >is normal so p-value should be small ...
> >
> >What am I missing ?
> >
> >Thanks
> >
> >EJ
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
> >  
> >
> You have it backwards. The null hypothesis is that the distribution is 
> Normal. You reject this null when the p-value is small. If the 
> distribution is Normal, the p-value will tend to be large.
> 
>  > shapiro.test(rnorm(100))
> 
>         Shapiro-Wilk normality test
> 
> data:  rnorm(100)
> W = 0.9877, p-value = 0.4894
> 
> 
> Rick B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rab at nauticom.net  Mon Feb 10 16:27:03 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Mon Feb 10 16:27:03 2003
Subject: [R] shapiro.test
In-Reply-To: <1044890421.31479.31.camel@gandalf>
References: <1044887778.31477.24.camel@gandalf> 	<3E47BB75.7080701@nauticom.net> <1044890421.31479.31.camel@gandalf>
Message-ID: <3E47C648.9030303@nauticom.net>

Ernesto Jardim wrote:

>Ok, let me put it the other way around.
>
>On another test I have W = 0.9907, p-value = 6.024e-06. The same
>question stands, with such huge W should it be expected to be normal ?
>
>EJ
>
>  
>
>>You have it backwards. The null hypothesis is that the distribution is 
>>Normal. You reject this null when the p-value is small. If the 
>>distribution is Normal, the p-value will tend to be large.
>>
>> > shapiro.test(rnorm(100))
>>
>>        Shapiro-Wilk normality test
>>
>>data:  rnorm(100)
>>W = 0.9877, p-value = 0.4894
>>
>>
>>Rick B.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>  
>
It depends on how non-Normal the distribution and the size of the 
sample. A t-distribution with df = 30 isn't Normal but it is close to 
being Normal. A small sample size probably won't detect it:

 > shapiro.test(rt(100,30))

        Shapiro-Wilk normality test

data:  rt(100, 30)
W = 0.9927, p-value = 0.8708

But a large enough sample size will:

 > shapiro.test(rt(2000,30))

        Shapiro-Wilk normality test

data:  rt(2000, 30)
W = 0.9968, p-value = 0.0003097

You haven't told us your sample size.

Rick B.



From rab at nauticom.net  Mon Feb 10 16:48:02 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Mon Feb 10 16:48:02 2003
Subject: [R] shapiro.test
In-Reply-To: <1044891744.31479.33.camel@gandalf>
References: <1044887778.31477.24.camel@gandalf>	<3E47BB75.7080701@nauticom.net> <1044890421.31479.31.camel@gandalf> 	<3E47C648.9030303@nauticom.net> <1044891744.31479.33.camel@gandalf>
Message-ID: <3E47CB25.1000002@nauticom.net>

Ernesto Jardim wrote:

>Hi
>
>It's a bootstrap empirical distribution and has 1000 replicates.
>
>EJ
>
>On Mon, 2003-02-10 at 15:33, Richard A. Bilonick wrote:
>  
>
>>It depends on how non-Normal the distribution and the size of the 
>>sample. A t-distribution with df = 30 isn't Normal but it is close to 
>>being Normal. A small sample size probably won't detect it:
>>
>> > shapiro.test(rt(100,30))
>>
>>        Shapiro-Wilk normality test
>>
>>data:  rt(100, 30)
>>W = 0.9927, p-value = 0.8708
>>
>>But a large enough sample size will:
>>
>> > shapiro.test(rt(2000,30))
>>
>>        Shapiro-Wilk normality test
>>
>>data:  rt(2000, 30)
>>W = 0.9968, p-value = 0.0003097
>>
>>You haven't told us your sample size.
>>
>>Rick B.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>    
>>
First, the convention is to place replies at the bottom of the last 
message. (I would prefer it otherwise, but that is the convention.)

Apparently even with your "large" sample size, it is not large enough to 
differentiate a difference between your distribution and the Normal. The 
difference can't be distinguished from a chance departure from the 
Normal for the given sample size. There is nothing unusual in this that 
I can see. It just tends to take huge sample sizes to pick up small 
differences (assuming your distribution actually differs from the Normal!).

Rick B.



From ripley at stats.ox.ac.uk  Mon Feb 10 16:54:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb 10 16:54:03 2003
Subject: [R] problems using lqs()
In-Reply-To: <Pine.SOL.4.50.0302101538420.24463-100000@pearson.stat.unipg.it>
Message-ID: <Pine.LNX.4.44.0302101549400.25462-100000@gannet.stats>

On Mon, 10 Feb 2003, Luca Scrucca wrote:

> I found a strange behaviour in the lqs function.

Why is this strange?  It *is* covered in the Note on the help page: please
read it and the reference there.

> Suppose I have the following data:

[...]

> Now, instead of using the formula, I want to provide the design matrix and
> the response, then:
> 
> X <- cbind(1, x1, x2)
> mod2 <- lqs.default(X, y, intercept=F, method="lms", nsamp="exact")
> mod2$coefficients
>                    x1         x2
> 35.4217275  0.4276641 -1.2834731
> mod2$bestone
> [1]  6 14 15
> 
> The results are not the same (?!). Furthermore, if I create the design
> matrix without the column of 1's for the intercept:

Right, it's not the same algorithm.

> X <- cbind(x1, x2)
> mod3 <- lqs.default(X, y, intercept=T, method="lms", nsamp="exact")

> I get the same result I had using the formula (see mod1).
> This is confusing me!

That *is* the same algorithm.

> Another small problem appears if I re-fit the first model using the
> formula and asking to return the x-matrix and the response:
> 
> lqs(y ~ x1 + x2, method="lms", nsamp="exact", x.ret=T, y.ret=T)
> 
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  :
> 	variable lengths differ
> 
> Does anyone know what's going on?

No, but R has debugging tools for you to find out ....


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Timur.Elzhov at jinr.ru  Mon Feb 10 17:04:03 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Mon Feb 10 17:04:03 2003
Subject: [R] Zero rows/cols in the hessian matrix
Message-ID: <20030210160617.GA24917@pcf004.jinr.ru>

Dear R experts!

I try to minimize a function with external C fitting function.
I get the hessian matrix. Here it is:

            [,1] [,2]      [,3] [,4]
  [1,] 1.8816631    0 0.8859803    0
  [2,] 0.0000000    0 0.0000000    0
  [3,] 0.8859803    0 0.4859983    0
  [4,] 0.0000000    0 0.0000000    0

Second and fourth rows/columns have zero values only. That's OK,
because that ones related to parameters were not included in fitting
expression (but *were* passed to minimization function as arguments),
so dF/dp == 0 for them.  It of course doesn't make sense to calculate
the standard errors for the mentioned "fitting-independent"
parameters, but I want to do that for others! I read in R-intro, that
I have to calculate the inverse of hessian at first.
solve(hessian) logs:

  Error in solve.default(hessian) : singular matrix `a' in solve

So, the question is:
  How can I calculate the errors of remaining parameters (without
  removing "fitting-independent" parameters from arguments)?

Thanks!


--
WBR,
Timur



From lm.silva at sapo.pt  Mon Feb 10 17:08:02 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Mon Feb 10 17:08:02 2003
Subject: [R] lda
Message-ID: <1044893245.3e47ce3de4212@webmail.sapo.pt>

Dear helpers

There are some versions of lda. I would like to know which one 
is behind R's lda function.

Luis
--
Ofere?a a si uma prenda no Dia dos Namorados: SAPO.ADSL.PT, e receba ainda uma oferta especial para a sua cara-metade. Tudo s? por 50?

http://adsl.sapo.pt/destaque_namorados.html



From bates at stat.wisc.edu  Mon Feb 10 17:11:06 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon Feb 10 17:11:06 2003
Subject: [R] Factor level comparisons in lme
In-Reply-To: <5.1.0.14.0.20030210124611.02308be0@gatty.st-and.ac.uk>
References: <5.1.0.14.0.20030210124611.02308be0@gatty.st-and.ac.uk>
Message-ID: <6rfzqwazlb.fsf@bates4.stat.wisc.edu>

Martin Biuw <emb7 at st-andrews.ac.uk> writes:

> Hello,
> I'm trying to fit a linear mixed effects model of the form:
> 
> lme(y ~ x * Sex * Year, random=x|subject)

Did you mean 

lme(y ~ x * Sex * Year, random= ~ x|subject)

The random argument should be a formula or a list.

> where Sex and Year are factors with two and three levels respectively. I 
> want to compare the fixed effects for each level to the overall mean, but 
> the default in R is to compare to the first level. This can be changed by 
> adding the term -1 to the righthand side of the model formula. But what I 
> can't figure out is how to do this for both factors simultaneously. If I 
> specify the model as:
> 
> lme(y ~ x * Sex * Year-1, random=x|subject)
> 
> the output gives me the fixed effects for each level of "Sex" compared to 
> the overall mean, but still only gives me the effects of the second two 
> levels in the "Year" factor compared to the first level. How do I specify 
> the fixed effects structure to allow comparisons to the overall mean for 
> each level of both factors?

This isn't really an lme question - it is a question about the
parameterization used in the model matrix for a linear model formula.

I'm not sure what you mean by "allow comparisons to the overall
mean".  You may find that setting

 options(contrasts=c('contr.sum', 'contr.poly'))

does what you want or what you want to do may be impossible.  With two
levels of Sex and, say, 4 levels of year, the number of degrees of
freedom in the crossed factors plus intercept is
  1(constant) + 1(Sex) + 3(Year) + 3(Sex * Year) = 8
If you want to get separate means for each level of Sex and Year and
Sex*Year you would need 
  2(Sex) + 4(Year) + 8(Sex*Year) = 14 
degrees of freedom.



From kjetil at entelnet.bo  Mon Feb 10 17:17:16 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon Feb 10 17:17:16 2003
Subject: [R] problems using lqs()
In-Reply-To: <Pine.SOL.4.50.0302101538420.24463-100000@pearson.stat.unipg.it>
Message-ID: <3E4796ED.11724.3C7DB7@localhost>

On 10 Feb 2003 at 15:40, Luca Scrucca wrote:

I am not sure about this, but lqs have an extra argument `adjust'.
from the help page:

adjust:
should the intercept be optimized for each sample? Defaults to TRUE

When you use formula, the estimation algorithm knows 
the columns of 1's is the intercept, and can traet it accordingly. 

When yo make the matrix X with on regressor column being all1's, 
the estimation algorithm does'nt know it represents the 
intercept (you did'nt give it a name). Could this be the reason why 
the different results?

Testing this conjecture:

 mod4 <- lqs(y ~ x1 + x2, method="lms", nsamp="exact", adjust=FALSE)
> coef(mod4)
(Intercept)          x1          x2 
 35.4217275   0.4276641  -1.2834731 
> coef(mod1)
(Intercept)          x1          x2 
 35.5293489   0.4422742  -1.2944534 
> coef(mod2)
                   x1         x2 
35.4217275  0.4276641 -1.2834731 

so this might be the explanation.

By the way, for the last question, using debug()
and looking at the output gives:

Browse[1]> n
debug: subset <- eval(substitute(subset), data, env)
Browse[1]> n
debug: data <- .Internal(model.frame(formula, rownames, variables, 
varnames, 
    extras, extranames, subset, na.action))
Browse[1]> n
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  : 
        variable lengths differ

so the error occurs in model.frame. You could continue 
the debugging yourself. (don't have time now).

Kjetil Halvorsen

> Dear List-members,
> 
> I found a strange behaviour in the lqs function.
> Suppose I have the following data:
> 
> y <-  c(7.6, 7.7, 4.3, 5.9, 5.0, 6.5, 8.3, 8.2, 13.2, 12.6, 10.4, 10.8,
> 13.1, 12.3, 10.4, 10.5, 7.7, 9.5, 12.0, 12.6, 13.6, 14.1, 13.5, 11.5,
> 12.0, 13.0, 14.1, 15.1)
> x1 <- c(8.2, 7.6,, 4.6, 4.3, 5.9, 5.0, 6.5, 8.3, 10.1, 13.2, 12.6, 10.4,
> 10.8, 13.1, 13.3, 10.4, 10.5, 7.7, 10.0, 12.0, 12.1, 13.6, 15.0, 13.5,
> 11.5, 12.0, 13.0, 14.1)
> x2 <- c(23.005, 23.873, 26.417, 24.868, 29.895, 24.200, 23.215, 21.862,
> 22.274, 23.830, 25.144, 22.430, 21.785, 22.380, 23.927, 33.443, 24.859,
> 22.686, 21.789, 22.041, 21.033, 21.005, 25.865, 26.290, 22.932, 21.313,
> 20.769, 21.393)
> 
> and I would like to fit the following model:
> 
> mod1 <- lqs(y ~ x1 + x2, method="lms", nsamp="exact")
> mod1$coefficients
> (Intercept)          x1          x2
>  35.5293489   0.4422742  -1.2944534
> mod1$bestone
> [1] 12 17 27
> 
> Now, instead of using the formula, I want to provide the design matrix and
> the response, then:
> 
> X <- cbind(1, x1, x2)
> mod2 <- lqs.default(X, y, intercept=F, method="lms", nsamp="exact")
> mod2$coefficients
>                    x1         x2
> 35.4217275  0.4276641 -1.2834731
> mod2$bestone
> [1]  6 14 15
> 
> The results are not the same (?!). Furthermore, if I create the design
> matrix without the column of 1's for the intercept:
> 
> X <- cbind(x1, x2)
> mod3 <- lqs.default(X, y, intercept=T, method="lms", nsamp="exact")
> > mod3$coefficients
> (Intercept)          x1          x2
>  35.5293489   0.4422742  -1.2944534
> > mod3$bestone
> [1] 12 17 27
> 
> I get the same result I had using the formula (see mod1).
> This is confusing me!
> 
> Another small problem appears if I re-fit the first model using the
> formula and asking to return the x-matrix and the response:
> 
> lqs(y ~ x1 + x2, method="lms", nsamp="exact", x.ret=T, y.ret=T)
> 
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  :
> 	variable lengths differ
> 
> Does anyone know what's going on?
> 
> Regards, with thanks in advance,
> 
> Luca Scrucca
> 
> 
> +-----------------------------------------------------------------------+
> | Dr. Luca Scrucca                                                      |
> | Dipartimento di Scienze Statistiche      tel. +39 - 075 - 5855278     |
> | Universita' degli Studi di Perugia       fax. +39 - 075 - 43242       |
> | Via Pascoli - C.P. 1315 Succ. 1                                       |
> | 06100 PERUGIA  (ITALY)                                                |
> |                                                                       |
> | E-mail:   luca at stat.unipg.it                                          |
> | Web page: http://www.stat.unipg.it/luca                               |
> +-----------------------------------------------------------------------+
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tomer_maymon at hotmail.com  Mon Feb 10 17:22:01 2003
From: tomer_maymon at hotmail.com (Tomer Maymon)
Date: Mon Feb 10 17:22:01 2003
Subject: [R] (no subject)
Message-ID: <F62aS36Il06sIQrttDR00005646@hotmail.com>

my name is Tomer Maimon,
and i'm a student in the israeli Institue for
science ( "Technion") .i have some problem with the R program. i want
to write formula with two factors to predict(in rpart algorithm). i'll
be more then thankfull if you could send me an answer & internet link,
where can i find answers to this kind of problems.



From otoomet at econ.dk  Mon Feb 10 17:26:04 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Mon Feb 10 17:26:04 2003
Subject: [R] Zero rows/cols in the hessian matrix
Message-ID: <200302101625.h1AGPXn08104@punik.econ.au.dk>

Hi,

 | From: Timur Elzhov <Timur.Elzhov at jinr.ru>
 | Date: Mon, 10 Feb 2003 19:06:18 +0300
 | 
 | Dear R experts!
 | 
 | I try to minimize a function with external C fitting function.
 | I get the hessian matrix. Here it is:
 | 
 |             [,1] [,2]      [,3] [,4]
 |   [1,] 1.8816631    0 0.8859803    0
 |   [2,] 0.0000000    0 0.0000000    0
 |   [3,] 0.8859803    0 0.4859983    0
 |   [4,] 0.0000000    0 0.0000000    0

First, are you sure that your fitting (minimisation?) routine handles
the problem correctly?  Not all of the optimising routines are able to
deal with constant parameters.

 | Second and fourth rows/columns have zero values only. That's OK,
 | because that ones related to parameters were not included in fitting
 | expression (but *were* passed to minimization function as arguments),
 | so dF/dp == 0 for them.  It of course doesn't make sense to calculate
 | the standard errors for the mentioned "fitting-independent"
 | parameters, but I want to do that for others! I read in R-intro, that
 | I have to calculate the inverse of hessian at first.
 | solve(hessian) logs:
 | 
 |   Error in solve.default(hessian) : singular matrix `a' in solve

The matrix is definitely singular.  In the example above, you have in
fact fitted a 2-parameter model and made a hessian which includes 2
extra rows and columns (of course, it depends on your fitting
algorithm, but I guess it handles the problem in this way).  Then you
have to exclude those rows and columns when you invert the hessian.  I
use to do so:

ind <- c(1, 3) # indices you need
varcov <- matrix(0, 4, 4)
varcovar[ind,ind] <- solve(hessian[ind,ind])

I.e. invert only parameter-depending part of the hessian and put it
into the corresponding elements in the full varcovar matrix (if you
need that).

Be sure how your fitting algorithm handles constant parameters!

Best wishes,

Ott

 | So, the question is:
 |   How can I calculate the errors of remaining parameters (without
 |   removing "fitting-independent" parameters from arguments)?
 | 
 | Thanks!
 | 
 | 
 | --
 | WBR,
 | Timur



From ripley at stats.ox.ac.uk  Mon Feb 10 17:56:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb 10 17:56:02 2003
Subject: [R] lda
In-Reply-To: <1044893245.3e47ce3de4212@webmail.sapo.pt>
Message-ID: <Pine.LNX.4.44.0302101653100.25510-100000@gannet.stats>

R per se does not have lda() function.  Package MASS does, and MASS (the
book) describes it in detail.

If you use a package supporting a book (there are several) do expect to 
read the book for the fine details ....

On Mon, 10 Feb 2003, Luis Silva wrote:

> There are some versions of lda. I would like to know which one 
> is behind R's lda function.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Timur.Elzhov at jinr.ru  Mon Feb 10 18:18:02 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Mon Feb 10 18:18:02 2003
Subject: [R] Zero rows/cols in the hessian matrix
In-Reply-To: <200302101625.h1AGPXn08104@punik.econ.au.dk>
References: <200302101625.h1AGPXn08104@punik.econ.au.dk>
Message-ID: <20030210172016.GA25257@pcf004.jinr.ru>

On Mon, Feb 10, 2003 at 05:25:33PM +0100, Ott Toomet wrote:

> ind <- c(1, 3) # indices you need
> varcov <- matrix(0, 4, 4)
> varcovar[ind,ind] <- solve(hessian[ind,ind])
> 
> I.e. invert only parameter-depending part of the hessian and put it
> into the corresponding elements in the full varcovar matrix (if you
> need that).
> 
> Be sure how your fitting algorithm handles constant parameters!
Yes, that's low-level `minpack' library, and I wrote the interface
between them and R in C by myself (with help of r-help people ;),
so that's zero columns are not surprise.

Thank you very much! ;-)


--
WBR,
Timur



From p.dalgaard at biostat.ku.dk  Mon Feb 10 18:36:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Feb 10 18:36:03 2003
Subject: [R] Memory allocation, IBM-AIX and R-1.6.2 - addendum
In-Reply-To: <20030210150317.GB20831840@genome.cbs.dtu.dk>
References: <20030210140210.GA20140183@genome.cbs.dtu.dk>
	<Pine.SOL.4.44.0302100928090.10496-100000@rygar.gpcc.itd.umich.edu>
	<20030210150317.GB20831840@genome.cbs.dtu.dk>
Message-ID: <x2u1fc2g1w.fsf@biostat.ku.dk>

Laurent Gautier <laurent at cbs.dtu.dk> writes:

> ...sorry for the spam, but answers I get to my previous
> question suggest that I should specify that the
> machine has a *lot* of memory and should be able
> to the instanciation...
> 
> Anybody with an IBM mainframe, R-1.6.2 and large
> matrices ?

For whatever it's worth, that size does not appear to be a problem in
Linux. Takes a while, and a lot of memory, to get a summary of the
matrix though (I'm slightly puzzled by that: The memory footprint
appears to shoot up to 1.7G for something that is just working
on the columns of a 319M matrix?).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From luca at stat.unipg.it  Mon Feb 10 18:44:45 2003
From: luca at stat.unipg.it (Luca Scrucca)
Date: Mon Feb 10 18:44:45 2003
Subject: [R] problems using lqs()
In-Reply-To: <3E4796ED.11724.3C7DB7@localhost>
References: <3E4796ED.11724.3C7DB7@localhost>
Message-ID: <Pine.SOL.4.50.0302101842010.24463-100000@pearson.stat.unipg.it>

Many thanks to Kjetil Halvorsen for explaining me the reason I got
different results.
Regarding the second point, Both Kjetil and Brian Ripley suggest to go
through debugging and see what the reason for the message.
I'm not so expert to fully understand why, but I have found a patch that
makes the function works. It is based on the behaviour of the lm function.

The original function is:

lqs.formula <- function (formula, data, ..., method = c("lts", "lqs",
"lms", "S", "model.frame"), subset, na.action = na.fail, model = TRUE,
x.ret = FALSE, y.ret = FALSE, contrasts = NULL)
{
    method <- match.arg(method)
...
    if (x.ret)
        fit$x <- x
    if (y.ret)
        fit$y <- y
    fit
}

I only changed the name of the arguments (x.ret to x, y.ret to y) as in
lm():

lqs.formula <- function (formula, data, ..., method = c("lts", "lqs",
"lms", "S", "model.frame"), subset, na.action = na.fail, model = TRUE, x =
FALSE, y = FALSE, contrasts = NULL)
{
    ret.x <- x
    ret.y <- y
    method <- match.arg(method)
...
    if (ret.x)
        fit$x <- x
    if (ret.y)
        fit$y <- y
    fit
}

Note that we need also to replace the 'x' with something else in:

lqs <- function(what, ...) UseMethod("lqs")

Now

mod <- lqs(y ~ x1 + x2, x=T, y=T)

and mod$x and mod$y returns what expected. The x-matrix is without the
enventual column of 1's. Maybe we may want to add it if required.

I hope this may help to fix the problem.

Best,

Luca

+-----------------------------------------------------------------------+
| Dr. Luca Scrucca                                                      |
| Dipartimento di Scienze Statistiche      tel. +39 - 075 - 5855278     |
| Universita' degli Studi di Perugia       fax. +39 - 075 - 43242       |
| Via Pascoli - C.P. 1315 Succ. 1                                       |
| 06100 PERUGIA  (ITALY)                                                |
|                                                                       |
| E-mail:   luca at stat.unipg.it                                          |
| Web page: http://www.stat.unipg.it/luca                               |
+-----------------------------------------------------------------------+



From dnogues at ipe.csic.es  Mon Feb 10 19:54:02 2003
From: dnogues at ipe.csic.es (David =?iso-8859-1?Q?Nogu=E9s?=)
Date: Mon Feb 10 19:54:02 2003
Subject: [R] hierarchical partitioning in multiple regression
Message-ID: <3E47F5E0.8A26D2CC@ipe.csic.es>

Hello to everybody:

Im starting to use R and this is my first message to the list. My first
question is: Can R-Program calculate hierarchical partitioning analysis
to
measure the "independent effect" of each independent variable in a
multiple
regression (lm, glm)

Thanks in
advance

--
David Nogu?s Bravo.
-----------------------------------------------------------
Instituto Pirenaico de Ecolog?a.
Consejo Superior de Investigaciones Cient?ficas.
Campus de Alua Dei.
Avenida Monta?ana, 1005.
50080 Zaragoza, Espa?a.
Tel?fono: 976-716034
dnogues at ipe.csic.es
-----------------------------------------------------------



From pvirketis at hbk.com  Mon Feb 10 21:04:10 2003
From: pvirketis at hbk.com (Pijus Virketis)
Date: Mon Feb 10 21:04:10 2003
Subject: [R] non-SQL sqlQuery error
Message-ID: <BFC55A5E0CBD26488EF3EE2E162FFA7F063E92@nycdc1.hbk.com>

Dear all, 

I've encountered a curious problem. I am trying to run an SQL query
using sqlQuery() function in RODBC. 
The query works fine when run in a stand-alone SQL browser (Microsoft
Query Analyzer, in particular). 
However, when I use the exact same thing from sqlQuery() function, I get
the following error:

Error in "[.data.frame"(data, , ) : not all specified columns exist

Traceback() gives this:

5: stop("not all specified columns exist")
4: "[.data.frame"(data, , )
3: data[, ]
2: sqlGetResults(channel, errors = errors, ...)
1: sqlQuery(con.object, " ... long query here ... ")

The puzzling thing is that the error does not seem to be like the usual
mispecified-SQL type that I normally 
get when using sqlQuery(). I am not sure how to debug this problem,
since I can't really see what's going on 
in the sqlQuery() internally. 

My query includes a "SUM(ColumnName1) GROUP BY ColumnName2" construct,
and from trial and error, it seems 
that this is the cause of the failure (at least removing it makes the
error go away).

I am using R1.6.2 and the RODBC package from
http://cran.r-project.org/bin/windows/contrib/PACKAGES.

Can anyone offer any clues?

Thanks, 

Pijus



From ripley at stats.ox.ac.uk  Mon Feb 10 21:17:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb 10 21:17:03 2003
Subject: [R] non-SQL sqlQuery error
In-Reply-To: <BFC55A5E0CBD26488EF3EE2E162FFA7F063E92@nycdc1.hbk.com>
Message-ID: <Pine.LNX.4.44.0302102013410.25831-100000@gannet.stats>

On Mon, 10 Feb 2003, Pijus Virketis wrote:

> I've encountered a curious problem. I am trying to run an SQL query
> using sqlQuery() function in RODBC. 
> The query works fine when run in a stand-alone SQL browser (Microsoft
> Query Analyzer, in particular). 
> However, when I use the exact same thing from sqlQuery() function, I get
> the following error:
> 
> Error in "[.data.frame"(data, , ) : not all specified columns exist
> 
> Traceback() gives this:
> 
> 5: stop("not all specified columns exist")
> 4: "[.data.frame"(data, , )
> 3: data[, ]
> 2: sqlGetResults(channel, errors = errors, ...)
> 1: sqlQuery(con.object, " ... long query here ... ")

There is no statement 3 in the released version of sqlGetResults ...

> The puzzling thing is that the error does not seem to be like the usual
> mispecified-SQL type that I normally 
> get when using sqlQuery(). I am not sure how to debug this problem,
> since I can't really see what's going on 
> in the sqlQuery() internally. 

You can.  R are RODBC and Open Source, so why not open it and read it?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pvirketis at hbk.com  Mon Feb 10 21:24:02 2003
From: pvirketis at hbk.com (Pijus Virketis)
Date: Mon Feb 10 21:24:02 2003
Subject: [R] non-SQL sqlQuery error
Message-ID: <BFC55A5E0CBD26488EF3EE2E162FFA7F362A75@nycdc1.hbk.com>

Professor Ripley,

> There is no statement 3 in the released version of sqlGetResults ...

In other words, I have an outdated/wrong version of RODBC?

> You can.  R are RODBC and Open Source, so why not open it and read it?

Because I don't know C/C++. I realise I should learn it, but I hope that
there is a more immediate
solution to my problem that I can apply before looking for "C++ for
Beginners" on Amazon.

Thank you, 

Pijus



From xiao.gang.fan1 at libertysurf.fr  Mon Feb 10 21:40:03 2003
From: xiao.gang.fan1 at libertysurf.fr (Fan)
Date: Mon Feb 10 21:40:03 2003
Subject: [R] Type of multi-valued variable
Message-ID: <3E4810E6.2E520ADF@libertysurf.fr>

Hi,

I've read in the past a thead in the R discussion list
about the multi-valued type variable (what was called checklist).
At the moment Gregory had intention to add some general code
in his gregmisc package.

I'm wondering if there's some general code / packages available ?

A general class for taking account this type of variable 
would be very useful in the domain of survey processings,
as multi-responses questions are often used. 
The simple operations applied to these variables are holecount, 
cross tabulations with others variables, transformation to single 
coded variables like number of responses, etc.

Thanks in advance for any help
--
Fan



From pvirketis at hbk.com  Mon Feb 10 22:12:03 2003
From: pvirketis at hbk.com (Pijus Virketis)
Date: Mon Feb 10 22:12:03 2003
Subject: [R] non-SQL sqlQuery error
Message-ID: <BFC55A5E0CBD26488EF3EE2E162FFA7F362A77@nycdc1.hbk.com>

Dear All, 

Reverting to RODBC 0.9.1 that I had archived resolved the problem.
Thanks to Professor Ripley for noting
that I had a non-release version of RODBC (how I might have obtained it
is still beyond me ;)).

Pijus



From fharrell at virginia.edu  Mon Feb 10 22:23:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon Feb 10 22:23:03 2003
Subject: [R] Type of multi-valued variable
In-Reply-To: <3E4810E6.2E520ADF@libertysurf.fr>
References: <3E4810E6.2E520ADF@libertysurf.fr>
Message-ID: <20030210162449.05ceb2c1.fharrell@virginia.edu>

On Mon, 10 Feb 2003 21:51:50 +0100
Fan <xiao.gang.fan1 at libertysurf.fr> wrote:

> Hi,
> 
> I've read in the past a thead in the R discussion list
> about the multi-valued type variable (what was called checklist).
> At the moment Gregory had intention to add some general code
> in his gregmisc package.
> 
> I'm wondering if there's some general code / packages available ?
> 
> A general class for taking account this type of variable 
> would be very useful in the domain of survey processings,
> as multi-responses questions are often used. 
> The simple operations applied to these variables are holecount, 
> cross tabulations with others variables, transformation to single 
> coded variables like number of responses, etc.
> 
> Thanks in advance for any help
> --
> Fan
> 

Fan, Take a look at p. 38-44 of http://hesweb1.med.virginia.edu/biostat/s/doc/summary.pdf where examples of the mChoice (multiple choice) function in Hmisc are given.

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From ozric at web.de  Mon Feb 10 22:27:02 2003
From: ozric at web.de (Christian Schulz)
Date: Mon Feb 10 22:27:02 2003
Subject: [R] multilm for simseg/acm
Message-ID: <001101c2d14a$4a67fff0$02d706d5@c5c9i0>

hi,
for working with the simseg/acm approach i need multilm and it seems
that the last version  is 0.1-4.tar ? 
What's wrong in the description file, if i attempt  install the package ?

c:\DataMining\rw1062\bin>Rcmd Install multilm
Malformed DCF file (file multilm/DESCRIPTION, line 6)

[R1.6.2 /W2K]
P.S. 
 ..hmm a solution might be import the functions from multilm
in my .Rprofile, but i would like understand the package problem !

many thanks, regards christian



From ripley at stats.ox.ac.uk  Mon Feb 10 22:41:06 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon Feb 10 22:41:06 2003
Subject: [R] multilm for simseg/acm
In-Reply-To: <001101c2d14a$4a67fff0$02d706d5@c5c9i0>
Message-ID: <Pine.GSO.4.44.0302102133060.1466-100000@auk.stats>

On Mon, 10 Feb 2003, Christian Schulz wrote:

> hi,
> for working with the simseg/acm approach i need multilm and it seems
> that the last version  is 0.1-4.tar ?
> What's wrong in the description file, if i attempt  install the package ?
>
> c:\DataMining\rw1062\bin>Rcmd Install multilm
> Malformed DCF file (file multilm/DESCRIPTION, line 6)
>
> [R1.6.2 /W2K]
> P.S.
>  ..hmm a solution might be import the functions from multilm
> in my .Rprofile, but i would like understand the package problem !

It appears to have an empty Depends: line, so delete it.
Also, the wrapping on the Description: line is wrong, and there is no
Maintainer field.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From slambert at jhsph.edu  Tue Feb 11 02:08:03 2003
From: slambert at jhsph.edu (Sharon Lambert)
Date: Tue Feb 11 02:08:03 2003
Subject: [R] geoR question from new R user
Message-ID: <fde73afdd610.fdd610fde73a@jhsph.edu>

Hi,

I'm a new R user. My goal is to do a variogram using geoR.
I started by trying to do the example in the geoR Illustrative Session 
using my own data.

I am able to read in my Ascii data using: D <- matrix(scan("file.dat", 
n=530*3), 530,3, byrow=TRUE).

Then I use: as.geodata(D, coords.col=1:2, data.col=3) to make the 
object D geodata.

I check the descriptive statistics, and my data file appears to be in 
order.

But when I try the following command:  cloud1<- variog(D, 
option="cloud", max.dist=1), I get this error:
    Error in array(x, c(length(x), 1), if (!is.null(names(x))) list
(names(x),  : 
        attempt to set an attribute on NULL

I get that same error message when I try different arguments with the 
variog command. 

Can someone help?

Thanks,

Sharon



From rpeng at stat.ucla.edu  Tue Feb 11 02:33:03 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue Feb 11 02:33:03 2003
Subject: [R] geoR question from new R user
In-Reply-To: <fde73afdd610.fdd610fde73a@jhsph.edu>
Message-ID: <Pine.GSO.4.10.10302101729350.7473-100000@quetelet.stat.ucla.edu>

Is `D' the original matrix or a `geodata' object?  You need to assign the
output of `as.geodata to another variable and pass that to `variog'.  For
example,

B <- as.geodata(D, coords.col=1:2, data.col=3)
variog(B, option = "cloud", max.dist = 1)

It seems like the problem is that you're passing the matrix `D' into
`variog'.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Mon, 10 Feb 2003, Sharon Lambert wrote:

> Hi,
> 
> I'm a new R user. My goal is to do a variogram using geoR.
> I started by trying to do the example in the geoR Illustrative Session 
> using my own data.
> 
> I am able to read in my Ascii data using: D <- matrix(scan("file.dat", 
> n=530*3), 530,3, byrow=TRUE).
> 
> Then I use: as.geodata(D, coords.col=1:2, data.col=3) to make the 
> object D geodata.
> 
> I check the descriptive statistics, and my data file appears to be in 
> order.
> 
> But when I try the following command:  cloud1<- variog(D, 
> option="cloud", max.dist=1), I get this error:
>     Error in array(x, c(length(x), 1), if (!is.null(names(x))) list
> (names(x),  : 
>         attempt to set an attribute on NULL
> 
> I get that same error message when I try different arguments with the 
> variog command. 
> 
> Can someone help?
> 
> Thanks,
> 
> Sharon
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From john.maindonald at anu.edu.au  Tue Feb 11 04:12:03 2003
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue Feb 11 04:12:03 2003
Subject: [R] Parallel Processing Interface for lapply()
Message-ID: <04028CD7-3D6F-11D7-A2A8-000393073F7A@anu.edu.au>

In co-operation with Markus Hegland and myself, Zhongwen Ding
has written a package, based partly on Markus Hegland's code,
that provides a parallel processing interface to a remote
multi-processsor system.  Pyro (Python Remote Objects) and R
must both be installed, both on the client machine and on the remote
server.  The system uses rsync, with an ssh protocol, to handle
file transfer.

Once setup is complete on the client and server side, the R
qlapply package provides the following functions:
(1) autoStart() to initiate communication with the server
(2) qlapply(), which is a version of lapply() that is adapted
for parallel processing
(3) autoKill(), to terminate the server processes.

An experimental version can be downloaded from
    http://datamining.anu.edu.au/software/qlapply

Please forward comments to one of the following:
Zhongwen Din:  zhongwen at faceng.anu.edu.au
Markus Hegland: markus.hegland at anu.edu.au
or to myself.

Ideas on simpler ways of handling the establishing of
communication with the server will be particularly
welcome.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From pzhang at hsph.harvard.edu  Tue Feb 11 05:37:03 2003
From: pzhang at hsph.harvard.edu (Peng Zhang)
Date: Tue Feb 11 05:37:03 2003
Subject: [R] installation on FreeBSD
In-Reply-To: <Pine.GSO.4.44.0302091811200.10687-100000@socrates.Berkeley.EDU>
References: <Pine.GSO.4.44.0302091811200.10687-100000@socrates.Berkeley.EDU>
Message-ID: <Pine.GSO.4.53.0302102331110.757@hsph.harvard.edu>

Dr Mccarter and Dr Gentleman,

Thank you for your reply. I reinstalled the system and found out that you
can not install R on FreeBSD 5.0 (I mean in the default setting when
installing R and also I tried to open the --enable-R-shlib. I chose
installing full binary, kernel src, & X during the installation of
FreeBSD) but can install R on FreeBSD 4.7. I don't have ability to figure
out why. Just bring it out.

Best wishes,
Peng

*******************************
Peng Zhang
Department of Biostatistics
Harvard School of Public Health
655 Huntington Avenue
Boston, Massachusetts 02115
*******************************

I believe I can fly
I believe I can touch the sky

On Sun, 9 Feb 2003, loren mccarter wrote:

> I'm not sure what is causing it to dump core. I'm using FreeBSD 4.7 and
> I'm waiting for 5.1 before upgrading so I can't troubleshoot it on my
> end. Here are some things you may want to try: (1)~use /stand/sysinstall
> to add R as a binary package (R-1.5.1_1 is available this way), (2)~if
> you think it's X, try configuring R to install without X (I think there
> is a configure option for this, something like: configure --without-x).
> (3)~when you installed the FreeBSD packages, make sure that none of them
> had XFree86 3.3.6 as a dependency, which would cause it to overwrite the 4.2
> libraries (but, you'd really notice if this happened this b/c X would not
> work at all, not just R). (4)~if this is a brand new machine setup, you
> may want to use the more stable FreeBSD 4.7 until 5.1 comes out in a few
> months. Of course, none of those suggestions are ideal, but may help you
> to trouble shoot the issue.
>
> Loren
>
>
> On Sun, 9 Feb 2003, Peng Zhang wrote:
>
> > Dear loren,
> >
> > Thank you for your reply! I did try to install directly from source code.
> > However I got the following error information:
> >
> > ../../../../library/methods/libs/methods.so is unchanged
> > dumping R code in package 'methods'
> > Segmentation fault (core dumped)
> > *** Error code 139
> >
> > Stop in /usr/home/pzhang/R-1.6.2/src/library/methods.
> > *** Error code 1
> >
> > Whether is there something wrong with my X settings? Thank you for your
> > help.
> >
> > Best wishes,
> > Peng
> >
> > *******************************
> > Peng Zhang
> > Department of Biostatistics
> > Harvard School of Public Health
> > 655 Huntington Avenue
> > Boston, Massachusetts 02115
> > *******************************
> >
> > I believe I can fly
> > I believe I can touch the sky
> >
> > On Sun, 9 Feb 2003, loren mccarter wrote:
> >
> > > I've been using R on FreeBSD for several years now so I can tell you it
> > > works fine. However I have not yet upgraded to FreeBSD 5.0 so perhaps it
> > > has something to do with the new version. Here's something you may want
> > > to try: Rather than using the old version of R from the FreeBSD ports
> > > collection, download the latest R source directly from CRAN then try to
> > > ./configure && make && make install it. I've found that R obeys the
> > > FreeBSD 'hier' and the sources on CRAN are always more up to date than the
> > > compliled FreeBSD packages or ports.
> > >
> > > Loren
> > >
> > >
> > >
> > >
> > > On Sat, 8 Feb 2003, Peng Zhang wrote:
> > >
> > > > Hello there,
> > > >
> > > > I just changed to FreeBSD platform, and want to install R on it. I use
> > > > FreeBSD 5.0 and install nearly all packages on the machine. When I use
> > > > ports to install R, (cd /usr/ports/math/R-letter, and then type make) I
> > > > got the following error information.
> > > > ../../../../library/methods/libs/methods.so is unchanged
> > > > dumping R code in package 'methods'
> > > > Fatal error: The X11 shared library could not be loaded.
> > > >   The error was /usr/ports/math/R-letter/work/R-1.6.0/modules/R_X11.so:
> > > > Undefined symbol "R_GlobalEnv"
> > > > Can somebody tell me why and how to fix this problem?
> > > >
> > > > Thank you for your help!
> > > >
> > > > Best wishes,
> > > > Peng
> > > >
> > > > *******************************
> > > > Peng Zhang
> > > > Department of Biostatistics
> > > > Harvard School of Public Health
> > > > 655 Huntington Avenue
> > > > Boston, Massachusetts 02115
> > > > *******************************
> > > >
> > > > I believe I can fly
> > > > I believe I can touch the sky
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > >
> > >
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>



From f0z6305 at labs.tamu.edu  Tue Feb 11 07:12:06 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue Feb 11 07:12:06 2003
Subject: [R] Covariance matrix for GMM
Message-ID: <021f01c2d194$6e59f770$8bd75ba5@IE.TAMU.EDU>

Hey, All

Now I generate a data vector X (d-dimension column vector) from a Gaussian
Mixture Model (GMM).
That is, the pdf of vector X is
f(X) = a1*N(u1, Cov1) + a2*(u2, Cov2)
where a1+a2 = 1, N is multidimensional normal distribution, ui is the mean
vecotr, Covi is the covariance matrix, i=1, 2.

So can I get the close forms of the mean and covariance matrix for the
random vector X?

Thanks very much.

Fred



From ozric at web.de  Tue Feb 11 08:47:03 2003
From: ozric at web.de (Christian Schulz)
Date: Tue Feb 11 08:47:03 2003
Subject: [R] RPgSQL W2K
Message-ID: <000a01c2d1a1$0b30c2c0$224007d5@c5c9i0>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030211/8f8790d9/attachment.pl

From slambert at jhsph.edu  Tue Feb 11 09:25:03 2003
From: slambert at jhsph.edu (Sharon Lambert)
Date: Tue Feb 11 09:25:03 2003
Subject: [R] geoR question from new R user
Message-ID: <100269b10006b5.10006b5100269b@jhsph.edu>

THANKS!
This was exactly the problem.

Sharon

----- Original Message -----
From: Roger Peng <rpeng at stat.ucla.edu>
Date: Monday, February 10, 2003 8:31 pm
Subject: Re: [R] geoR question from new R user

> Is `D' the original matrix or a `geodata' object?  You need to 
> assign the
> output of `as.geodata to another variable and pass that to 
> `variog'.  For
> example,
> 
> B <- as.geodata(D, coords.col=1:2, data.col=3)
> variog(B, option = "cloud", max.dist = 1)
> 
> It seems like the problem is that you're passing the matrix `D' into
> `variog'.
> 
> -roger
> _______________________________
> UCLA Department of Statistics
> rpeng at stat.ucla.edu
> http://www.stat.ucla.edu/~rpeng
> 
> On Mon, 10 Feb 2003, Sharon Lambert wrote:
> 
> > Hi,
> > 
> > I'm a new R user. My goal is to do a variogram using geoR.
> > I started by trying to do the example in the geoR Illustrative 
> Session 
> > using my own data.
> > 
> > I am able to read in my Ascii data using: D <- 
> matrix(scan("file.dat", 
> > n=530*3), 530,3, byrow=TRUE).
> > 
> > Then I use: as.geodata(D, coords.col=1:2, data.col=3) to make 
> the 
> > object D geodata.
> > 
> > I check the descriptive statistics, and my data file appears to 
> be in 
> > order.
> > 
> > But when I try the following command:  cloud1<- variog(D, 
> > option="cloud", max.dist=1), I get this error:
> >     Error in array(x, c(length(x), 1), if (!is.null(names(x))) list
> > (names(x),  : 
> >         attempt to set an attribute on NULL
> > 
> > I get that same error message when I try different arguments 
> with the 
> > variog command. 
> > 
> > Can someone help?
> > 
> > Thanks,
> > 
> > Sharon
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
>



From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Feb 11 10:45:03 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue Feb 11 10:45:03 2003
Subject: [R] multilm for simseg/acm
In-Reply-To: <001101c2d14a$4a67fff0$02d706d5@c5c9i0>
References: <001101c2d14a$4a67fff0$02d706d5@c5c9i0>
Message-ID: <Pine.LNX.4.51.0302111041080.14740@artemis.imbe.med.uni-erlangen.de>

> hi,
> for working with the simseg/acm approach i need multilm and it seems
> that the last version  is 0.1-4.tar ?

hm.

once upon a time this package was part of the CRAN devel section but was
removed more than a year ago, if I recall it correctly, since multivariate
analysis of variance models are now part of the R-base.

Torsten

> What's wrong in the description file, if i attempt  install the package ?
>
> c:\DataMining\rw1062\bin>Rcmd Install multilm
> Malformed DCF file (file multilm/DESCRIPTION, line 6)
>
> [R1.6.2 /W2K]
> P.S.
>  ..hmm a solution might be import the functions from multilm
> in my .Rprofile, but i would like understand the package problem !
>
> many thanks, regards christian
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From ozric at web.de  Tue Feb 11 11:39:02 2003
From: ozric at web.de (Christian Schulz)
Date: Tue Feb 11 11:39:02 2003
Subject: [R] multilm for simseg/acm
References: <001101c2d14a$4a67fff0$02d706d5@c5c9i0> <Pine.LNX.4.51.0302111041080.14740@artemis.imbe.med.uni-erlangen.de>
Message-ID: <000b01c2d1b9$205ce8f0$12ba07d5@c5c9i0>

thanks, with recommendation from
Prof. Ripley  the installation works :-)

P.S.
...and it seems that some further
modifications necessary to run "sfb_2.0-3.tar.gz"  on windows ,like recoding
RPgSQL -> RODBC .

christian


----- Original Message -----
From: "Torsten Hothorn" <Torsten.Hothorn at rzmail.uni-erlangen.de>
To: "Christian Schulz" <ozric at web.de>
Cc: <r-help at stat.math.ethz.ch>
Sent: Tuesday, February 11, 2003 10:44 AM
Subject: Re: [R] multilm for simseg/acm


> > hi,
> > for working with the simseg/acm approach i need multilm and it seems
> > that the last version  is 0.1-4.tar ?
>
> hm.
>
> once upon a time this package was part of the CRAN devel section but was
> removed more than a year ago, if I recall it correctly, since multivariate
> analysis of variance models are now part of the R-base.
>
> Torsten
>
> > What's wrong in the description file, if i attempt  install the package
?
> >
> > c:\DataMining\rw1062\bin>Rcmd Install multilm
> > Malformed DCF file (file multilm/DESCRIPTION, line 6)
> >
> > [R1.6.2 /W2K]
> > P.S.
> >  ..hmm a solution might be import the functions from multilm
> > in my .Rprofile, but i would like understand the package problem !
> >
> > many thanks, regards christian
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From vito.muggeo at giustizia.it  Tue Feb 11 15:26:03 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Tue Feb 11 15:26:03 2003
Subject: [R] is.null() and lm obj
References: <001101c2d14a$4a67fff0$02d706d5@c5c9i0> <Pine.LNX.4.51.0302111041080.14740@artemis.imbe.med.uni-erlangen.de> <000b01c2d1b9$205ce8f0$12ba07d5@c5c9i0>
Message-ID: <004b01c2d1d8$d32d55e0$5c13070a@it.giustizia.it>

Dear all,
I found the following strange behavior of is.null() in the x component of a
lm object.
*However note that I'm running R-1.5.1, so probably the error (if someone)
has been fixed in the the versions 1.6.x. If it is so, please apologizes for
this my e-mail

x<-1:10
y<-rnorm(10)
obj<-lm(y~x)
>is.null(obj$y)
[1] TRUE
>is.null(obj$x)
[1] FALSE
>dim(obj$x)
NULL

That is, according to "is.null(obj$x)" the design matrix seems to be present
in the lm object, but it is not so, of course. "is.null(obj$y)" seems to
work correctly.

best,
vito



From jfox at mcmaster.ca  Tue Feb 11 15:38:10 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue Feb 11 15:38:10 2003
Subject: [R] RPgSQL W2K
In-Reply-To: <000a01c2d1a1$0b30c2c0$224007d5@c5c9i0>
Message-ID: <5.1.0.14.2.20030211091936.01eab288@mcmail.cis.mcmaster.ca>

Dear Christian,

At 08:41 AM 2/11/2003 +0100, Christian Schulz wrote:

>i found tis message in the archive  and have
>got the same problems ?
>John, perhaps you have found now a way
>install RPgSQL  for windows2000, or anybody other  ?
>
>many thanks for advance
>christian
>
>
>[SNIP]
>I wonder whether anyone has succeeded in building either the RPgSQL or the
>Rdbi.PGSQL and Rdbi packages for Windows. If so, would you be willing to
>share either the binary package(s) or instructions about how to set up the
>configure scripts? My preliminary efforts to get things going under Windows
>2000 haven't met with much success.

I haven't been able to install RPgSQL for Windows, but I found (following 
Brian Ripley's suggestion) that RODBC works well, both with Postgresql and 
MySQL.

I ended up implementing something similar to the proxy data frames in 
RPgSQL, which I've attached to this message. This is another example of 
some code that seems too small to bundle in a package, so it's not 
documented, but the general idea is to create an odbcDataset object via the 
function of that name, which can then be indexed, summarized, etc. Row 
indices can be SQL queries. For example, assuming that the table usarrests 
is in the MySQL database test:

         channel <- odbcConnect("test", case="mysql")
         USarrests <- odbcDataset(channel, "usarrests")
         USarrests["rape > 20 AND assault < 200 ORDER BY rape", c("rape", 
"assault")]
         lm(murder ~ ., data=USarrests[])

I hope that this is of some use to you.
  John

----------------------- snip -------------------------

.DBMS <- matrix(c("MySQL",      "Column_name", "Type_name",
                   "PostgreSQL", "COLUMN_NAME", "TYPE_NAME"),
             byrow=TRUE, ncol=3)
colnames(.DBMS) <- c("dbname", "column.selector", "type.selector")

odbcDataset <- function(channel, table, rownames){
     if (length(channel) != 1 || !is.integer(channel) || channel < 0) 
stop("channel must be a non-negative integer")
     if (length(table) != 1 || !is.character(table)) stop("table must be a 
data-base table name")
     odbcTableExists(channel, table)
     info <- odbcGetInfo(channel)
     db <- sapply(.DBMS[,"dbname"], function(x) 1 == length(grep(x, info)))
     if (!any(db)) stop(paste("database not located in the .DBMS 
table\ndatabase info:", info))
     if (missing(rownames)){
         col.info <- sqlColumns(channel, table)
         rownames <- 1 == length(grep("char", col.info[1, .DBMS[db, 
"type.selector"]]))
         }
     result <- list(channel=channel, table=table, column.selector=.DBMS[db, 
"column.selector"], rownames=rownames)
     class(result) <- c("odbcDataset", "data.frame")
     result
     }

print.odbcDataset <- function(x, ..., verbose=FALSE){
     if (verbose) print(x[,])
     else {
         x <- unclass(x)  # necessary because of $.odbcDataset
         cat(  "channel:           ", x$channel)
         cat("\ntable:             ", x$table)
         cat("\nrow names:         ", x$rownames)
         class(x) <- c("odbcDataset", "data.frame")
         cat("\nnumber of rows:    ", nrow(x))
         cat("\nnumber of columns: ", ncol(x), "\n")
         invisible(x)
         }
     }

summary.odbcDataset <- function(object, ...) summary(object[,])

"[.odbcDataset" <- function(x, i, j, ...){
     same.sign <- function(x) {
         any(x > 0) == all(x >= 0)
         }
     x <- unclass(x)
     names <- sqlColumns(x$channel, x$table)[[x$column.selector]]
     selection <- if (missing(j)) "*"
                     else if (is.numeric(j)) {
                         j <- j[j != 0]
                         if (length(j) == 0) return(NULL)
                         if (!same.sign(j)) stop("cannot mix positive and 
negative subscripts")
                         if (j[1] > 0) names[j + x$rownames]
                             else names[-1 * c(rep(1, x$rownames), (abs(j) 
+ x$rownames))]
                         }
                         else j
     selection <- if (selection == "*" || !x$rownames) selection
                     else c(names[1], selection)
     if (selection != "*" && (any(is.na(selection)) || 
any(!is.element(selection, names)))) stop("bad column index")
     result <- if (missing(i)) sqlQuery(x$channel, paste("select", 
paste(selection, collapse=","), "from", x$table))
                 else {
                     if (!is.character(i) && length(i) != 1) stop("row 
'subscript' must be an SQL row selector")
                     sqlQuery(x$channel, paste("select", paste(selection, 
collapse=","), "from", x$table, "where", i))
                     }
     if (x$rownames) {
         rownames(result) <- as.character(result[,1])
         result <- result[, -1]
         }
     if (length(dim(result)) == 2 && dim(result)[2] == 1) 
result[,,drop=TRUE] else result
     }

"$.odbcDataset" <- function(x, i){
     x <- unclass(x)
     sqlQuery(x$channel, paste("select", i, "from", x$table))[[1]]
     }

"[[.odbcDataset" <- function(x, i){
     x <- unclass(x)
     if (is.numeric(i)) i <- sqlColumns(x$channel, 
x$table)[[x$column.selector]][i + x$rownames]
     sqlQuery(x$channel, paste("select", i, "from", x$table))[[1]]
     }

as.data.frame.odbcDataset <- function(x, rownames, optional) x[,]

as.matrix.odbcDataset <- function(x) as.matrix(x[,])

as.list.odbcDataset <- function(x, ...) as.list(x[,])

row.names.odbcDataset <- function(x) {
     x <- unclass(x)
     if (x$rownames) {
         name <- sqlColumns(x$channel, x$table)[[x$column.selector]][1]
         as.character(sqlQuery(x$channel, paste("select", name, "from", 
x$table))[[1]])
         }
     else NULL
     }

names.odbcDataset <- function(x){
     x <- unclass(x)
     names <- sqlColumns(x$channel, x$table)[[x$column.selector]]
     if (x$rownames) names[-1] else names
     }

dimnames.odbcDataset <- function(x) list(row.names(x), names(x))

dim.odbcDataset <- function (x) c(length(x[[1]]), length(names(x)))



From spok_1 at yahoo.com  Tue Feb 11 15:42:32 2003
From: spok_1 at yahoo.com (Hyung Kim)
Date: Tue Feb 11 15:42:32 2003
Subject: [R] rpart- error rate for survival regression?
Message-ID: <20030211143628.23954.qmail@web20421.mail.yahoo.com>

Hello

I am using rpart with survival data.  When I 'printcp'
I get the results below.  Can someone please explain
two things for me in lay man's terms.  1) What exactly
is the complexity parameter?  2) How do I calculate
the absolute cross validated error rate when the root
node error in my example is 1.39?

Thanks you.

spok leen


Survival regression tree:
rpart(formula = Surv(fu, death) ~ p + k + c + 
    g + a + e, data = dat2, xval = 700)

Variables actually used in tree construction:
[1] c e  k  p a 

Root node error: 972.86/700 = 1.3898

n= 700 

        CP nsplit rel error  xerror     xstd
1 0.068408      0   1.00000 1.00390 0.048144
2 0.036091      1   0.93159 0.93917 0.048700
3 0.025606      2   0.89550 0.94267 0.052853
4 0.022596      3   0.86990 0.90079 0.052251
5 0.011670      4   0.84730 0.87244 0.050768
6 0.010000      5   0.83563 0.90675 0.053937



From forbeckd at mail.nih.gov  Tue Feb 11 15:47:04 2003
From: forbeckd at mail.nih.gov (Forbeck, Doug (NIH/NCI))
Date: Tue Feb 11 15:47:04 2003
Subject: [R] Tcl/Tk support is not available on this system.
Message-ID: <9D7EF737FA4C6F4FBBFC52FC30B83690C43E9B@nihexchange7.nih.gov>

I am trying to get R to run on a Red Hat 8 system, I am running R version
1.6.2 with Tcl/Tk version 8.3.5 installed. When I try to test R from the
data_sets directory I get the error message;
Error in firstlib(which.lib.loc, package) :
	Tcl/Tk support is not available on this system
Error in fileBrowser(textToShow = "Choose one CDF file" , nSelect = 1, :
	tcl/tk library not available
Execution halted.

Any help would be appreciated.

Doug Forbeck



From ripley at stats.ox.ac.uk  Tue Feb 11 15:52:08 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb 11 15:52:08 2003
Subject: [R] is.null() and lm obj
In-Reply-To: <004b01c2d1d8$d32d55e0$5c13070a@it.giustizia.it>
Message-ID: <Pine.LNX.4.44.0302111448300.896-100000@gannet.stats>

Partial matching!

obj$x matches obj$xlevels.  You need to use obj[["x"]] to be sure to
get exactly that component.

Why didn't you try

> names(obj)
 [1] "coefficients"  "residuals"     "effects"       "rank"         
 [5] "fitted.values" "assign"        "qr"            "df.residual"  
 [9] "xlevels"       "call"          "terms"         "model"        
> obj$x
list()

?

On Tue, 11 Feb 2003, vito muggeo wrote:

> I found the following strange behavior of is.null() in the x component of a
> lm object.
> *However note that I'm running R-1.5.1, so probably the error (if someone)
> has been fixed in the the versions 1.6.x. If it is so, please apologizes for
> this my e-mail
> 
> x<-1:10
> y<-rnorm(10)
> obj<-lm(y~x)
> >is.null(obj$y)
> [1] TRUE
> >is.null(obj$x)
> [1] FALSE
> >dim(obj$x)
> NULL
> 
> That is, according to "is.null(obj$x)" the design matrix seems to be present
> in the lm object, but it is not so, of course. "is.null(obj$y)" seems to
> work correctly.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb 11 16:02:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb 11 16:02:04 2003
Subject: [R] is.null() and lm obj
In-Reply-To: <Pine.LNX.4.44.0302111448300.896-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0302111458190.896-100000@gannet.stats>

On Tue, 11 Feb 2003 ripley at stats.ox.ac.uk wrote:

> Partial matching!
> 
> obj$x matches obj$xlevels.  You need to use obj[["x"]] to be sure to
> get exactly that component.

Apparently you need obj[[match("x", names(obj), 0)]] in current R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Tue Feb 11 16:06:32 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Feb 11 16:06:32 2003
Subject: [R] Tcl/Tk support is not available on this system.
In-Reply-To: <9D7EF737FA4C6F4FBBFC52FC30B83690C43E9B@nihexchange7.nih.gov>
References: <9D7EF737FA4C6F4FBBFC52FC30B83690C43E9B@nihexchange7.nih.gov>
Message-ID: <x23cmu7td1.fsf@biostat.ku.dk>

"Forbeck, Doug (NIH/NCI)" <forbeckd at mail.nih.gov> writes:

> I am trying to get R to run on a Red Hat 8 system, I am running R version
> 1.6.2 with Tcl/Tk version 8.3.5 installed. When I try to test R from the
> data_sets directory I get the error message;
> Error in firstlib(which.lib.loc, package) :
> 	Tcl/Tk support is not available on this system
> Error in fileBrowser(textToShow = "Choose one CDF file" , nSelect = 1, :
> 	tcl/tk library not available
> Execution halted.
> 
> Any help would be appreciated.

8.3.5 is not stock RH8 is it? I have 8.3.3. 

My best guess is that something went wrong during the build of R. Make
sure that the configure process figures out where to find the Tcl/Tck
header files and libraries.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jzhang at jimmy.harvard.edu  Tue Feb 11 16:34:03 2003
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Tue Feb 11 16:34:03 2003
Subject: [R] Tcl/Tk support is not available on this system.
Message-ID: <200302111533.KAA27289@blaise.dfci.harvard.edu>

You probably do not have the tcl/tk libraries on which R tcltk package relies.
tcl/tk can be downloaded from the web.


>From: "Forbeck, Doug (NIH/NCI)" <forbeckd at mail.nih.gov>
>To: "'R-help at lists.R-project.org'" <R-help at stat.math.ethz.ch>
>MIME-Version: 1.0
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Spam-Status: No, hits=0.7 required=5.0 
tests=EXCHANGE_SERVER,SPAM_PHRASE_00_01 version=2.43
>X-Spam-Level: 
>Subject: [R] Tcl/Tk support is not available on this system.
>X-BeenThere: r-help at stat.math.ethz.ch
>X-Mailman-Version: 2.0.13
>List-Help: <mailto:r-help-request at stat.math.ethz.ch?subject=help>
>List-Post: <mailto:r-help at stat.math.ethz.ch>
>List-Subscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>
>List-Id: Main R Mailing List: Primary help <r-help.stat.math.ethz.ch>
>List-Unsubscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
>List-Archive: <http://www.stat.math.ethz.ch/pipermail/r-help/>
>X-Original-Date: Tue, 11 Feb 2003 09:39:30 -0500
>Date: Tue, 11 Feb 2003 09:39:30 -0500
>
>
>I am trying to get R to run on a Red Hat 8 system, I am running R version
>1.6.2 with Tcl/Tk version 8.3.5 installed. When I try to test R from the
>data_sets directory I get the error message;
>Error in firstlib(which.lib.loc, package) :
>	Tcl/Tk support is not available on this system
>Error in fileBrowser(textToShow = "Choose one CDF file" , nSelect = 1, :
>	tcl/tk library not available
>Execution halted.
>
>Any help would be appreciated.
>
>Doug Forbeck
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help

Jianhua Zhang
Department of Biostatistics
Dana-Farber Cancer Institute
44 Binney Street
Boston, MA 02115-6084



From mschwartz at medanalytics.com  Tue Feb 11 17:07:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue Feb 11 17:07:03 2003
Subject: [R] Tcl/Tk support is not available on this system.
In-Reply-To: <x23cmu7td1.fsf@biostat.ku.dk>
Message-ID: <000301c2d1e7$7294f350$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Peter Dalgaard
BSA
>Sent: Tuesday, February 11, 2003 9:03 AM
>To: Forbeck, Doug (NIH/NCI)
>Cc: R-help at stat.math.ethz.ch
>Subject: Re: [R] Tcl/Tk support is not available on this system.
>
>
>"Forbeck, Doug (NIH/NCI)" <forbeckd at mail.nih.gov> writes:
>
>> I am trying to get R to run on a Red Hat 8 system, I am running R 
>> version 1.6.2 with Tcl/Tk version 8.3.5 installed. When I 
>try to test 
>> R from the data_sets directory I get the error message; Error in 
>> firstlib(which.lib.loc, package) :
>> 	Tcl/Tk support is not available on this system
>> Error in fileBrowser(textToShow = "Choose one CDF file" , 
>nSelect = 1, :
>> 	tcl/tk library not available
>> Execution halted.
>> 
>> Any help would be appreciated.
>
>8.3.5 is not stock RH8 is it? I have 8.3.3. 
>
>My best guess is that something went wrong during the build of 
>R. Make sure that the configure process figures out where to 
>find the Tcl/Tck header files and libraries.


Tcl/tk version 8.3.3-74 is indeed the current "official" version from
RH for 8.0 and is what I have as well.  No updates to that version are
yet available via RHN, though updates are of course available from
ActiveState to 8.3.5 and 8.4.1.

Tcl/tk works fine on my system using R 1.6.2 installed from the RPM
provided by Martyn Plummer on CRAN
(http://cran.r-project.org/bin/linux/redhat/8.x/i386/R-1.6.2-1.i386.rp
m) and tcl/tk installed from the RH DVD.

I agree with Peter, sounds like a library location problem/conflict.
Which came first?  The build/install of R or the install/upgrade of
tcl/tk?  If you installed/upgraded the tcl package second, the path
for the tcl libraries may not be the same as what was present when you
first built/installed R, presuming that tcl was installed at that
point.

Regards,

Marc Schwartz



From boiko at demogr.mpg.de  Tue Feb 11 17:20:03 2003
From: boiko at demogr.mpg.de (Serge Boiko)
Date: Tue Feb 11 17:20:03 2003
Subject: [R] problems with ess and xemacs on win32
Message-ID: <m2heba3fn7.fsf@boiko_linux.demogr.mpg.de>

Hi there;

I have the following problem --- Xemacs cannot 
correctly parse a path to file when I load it.

I have the following error, reported by Xemacs:

from  ess-parse-errors:
Error in file(file, "r") : cannot open file
`u:US-mortalityjuttalexible.r
While the correct file path should be:
u:\US-mortality\jutta\flexible.r

Any ideas? Many thanks for your help.

-Serge



From mros at autan.toulouse.inra.fr  Tue Feb 11 17:30:04 2003
From: mros at autan.toulouse.inra.fr (Mathieu Ros)
Date: Tue Feb 11 17:30:04 2003
Subject: [R] problems with ess and xemacs on win32
In-Reply-To: <m2heba3fn7.fsf@boiko_linux.demogr.mpg.de>
References: <m2heba3fn7.fsf@boiko_linux.demogr.mpg.de>
Message-ID: <15945.9391.209715.993010@autan.toulouse.inra.fr>

>>>>> "SB" == Serge Boiko <boiko at demogr.mpg.de> disait:

    SB> Hi there; I have the following problem --- Xemacs cannot
    SB> correctly parse a path to file when I load it.

    SB> I have the following error, reported by Xemacs:

    SB> from ess-parse-errors: Error in file(file, "r") : cannot open
    SB> file `u:US-mortalityjuttalexible.r While the correct file path
    SB> should be: u:\US-mortality\jutta\flexible.r

    SB> Any ideas? Many thanks for your help.

on windows? try replacing the "\" by "/"...

-mathieu-



From sundar.dorai-raj at pdf.com  Tue Feb 11 17:35:14 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue Feb 11 17:35:14 2003
Subject: [R] problems with ess and xemacs on win32
References: <m2heba3fn7.fsf@boiko_linux.demogr.mpg.de>
Message-ID: <3E492562.3060206@pdf.com>

Serge,

Serge Boiko wrote:
> Hi there;
> 
> I have the following problem --- Xemacs cannot 
> correctly parse a path to file when I load it.
> 
> I have the following error, reported by Xemacs:
> 
> from  ess-parse-errors:
> Error in file(file, "r") : cannot open file
> `u:US-mortalityjuttalexible.r
> While the correct file path should be:
> u:\US-mortality\jutta\flexible.r
> 
> Any ideas? Many thanks for your help.
> 

Try reversing the slashes:


u:/US-mortality/jutta/flexible.r

Also, there is a xemacs newsgroup (comp.emacs.xemacs) as well as an ess 
mailing list (ess-help at stat.math.ethz.ch) for these types of questions.

Regards,
Sundar



From tarnold at smpllc.com  Tue Feb 11 17:39:53 2003
From: tarnold at smpllc.com (Tom Arnold)
Date: Tue Feb 11 17:39:53 2003
Subject: [R] Periods instead of spaces in dataframe names?
Message-ID: <JFEDJKCABKCOMJDIIFPJOEOOCJAA.tarnold@smpllc.com>

Basic question:
when I use names() to extract the name of a dataframe element, why does it
have "." instead of " " between words?

Context:
I'm importing a CSV file of survey results for analysis. I read them like
this:

df <- read.csv("surveydata.csv",nrows=40,header=TRUE,
               na.string=c("N/A",""),comment.char="",strip.white=TRUE)

To do a summary of the responses to a question, I can now do something like
this:

table(df[13])

 1  2  3  4
13 13  4  2

and can then do a barplot with:
barplot(table(df[13])))

Which is fine. But since the first row of my data file includes the questions
themselves, I want to use those questions as chart titles, like this:

barplot(table(df[13]),main=names(df[13]))

This gives an unexpected result: the title has a "." where every space should
be between words, like this: "How.many.cats.do.you.own"

I can't figure out why, or how to get spaces instead of "." to show up. I've
tried using gsub but without success, to substitute " " for "."

I'm think I'm confused about something fundamental here, and hope someone has
the patience to enlighten me. I confess to a being a bit vague in my
understanding of R's handling of arrays, dataframes, and vectors. My
background is in C programming and I keep looking for a "string"...

Thank you very much. Please reply or copy me directly if you respond.

Tom Arnold
Managing Partner, Summit Media Partners LLC
Visit our web site at http://www.summitmediapartners.com



From f0z6305 at labs.tamu.edu  Tue Feb 11 17:57:03 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue Feb 11 17:57:03 2003
Subject: [R] Covariance matrix for GMM
References: <021f01c2d194$6e59f770$8bd75ba5@IE.TAMU.EDU>
Message-ID: <024501c2d1ee$9122bdf0$8bd75ba5@IE.TAMU.EDU>

There is no way to answer this question?

even for writing the sample covariance matrix
formulation for the data set [X, Y] where
X(n observations) and Y (m observations) are from
the class 1 and class 2 which both are
multidimensional normal distribution?


----- Original Message -----
From: "Feng Zhang" <f0z6305 at labs.tamu.edu>
To: "R-Help" <r-help at stat.math.ethz.ch>
Sent: Tuesday, February 11, 2003 12:11 AM
Subject: [R] Covariance matrix for GMM


> Hey, All
>
> Now I generate a data vector X (d-dimension column vector) from a Gaussian
> Mixture Model (GMM).
> That is, the pdf of vector X is
> f(X) = a1*N(u1, Cov1) + a2*(u2, Cov2)
> where a1+a2 = 1, N is multidimensional normal distribution, ui is the mean
> vecotr, Covi is the covariance matrix, i=1, 2.
>
> So can I get the close forms of the mean and covariance matrix for the
> random vector X?
>
> Thanks very much.
>
> Fred
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From sundar.dorai-raj at pdf.com  Tue Feb 11 18:06:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue Feb 11 18:06:03 2003
Subject: [R] Periods instead of spaces in dataframe names?
References: <JFEDJKCABKCOMJDIIFPJOEOOCJAA.tarnold@smpllc.com>
Message-ID: <3E492D0F.7070501@pdf.com>

Tom,

Tom Arnold wrote:
> Basic question:
> when I use names() to extract the name of a dataframe element, why does it
> have "." instead of " " between words?
> 
> Context:
> I'm importing a CSV file of survey results for analysis. I read them like
> this:
> 
> df <- read.csv("surveydata.csv",nrows=40,header=TRUE,
>                na.string=c("N/A",""),comment.char="",strip.white=TRUE)
> 
> To do a summary of the responses to a question, I can now do something like
> this:
> 
> table(df[13])
> 
>  1  2  3  4
> 13 13  4  2
> 
> and can then do a barplot with:
> barplot(table(df[13])))
> 
> Which is fine. But since the first row of my data file includes the questions
> themselves, I want to use those questions as chart titles, like this:
> 
> barplot(table(df[13]),main=names(df[13]))
> 
> This gives an unexpected result: the title has a "." where every space should
> be between words, like this: "How.many.cats.do.you.own"
> 
> I can't figure out why, or how to get spaces instead of "." to show up. I've
> tried using gsub but without success, to substitute " " for "."
> 
> I'm think I'm confused about something fundamental here, and hope someone has
> the patience to enlighten me. I confess to a being a bit vague in my
> understanding of R's handling of arrays, dataframes, and vectors. My
> background is in C programming and I keep looking for a "string"...
> 
> Thank you very much. Please reply or copy me directly if you respond.

You can use check.names = FALSE in your read.csv(...) call. Or you can 
use gsub as in:

names(df2) = gsub("\\.", " ", names(df2))

The "."  must be escaped in gsub if used in the pattern argument.

Regards,
Sundar



From ben at zoo.ufl.edu  Tue Feb 11 18:11:20 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue Feb 11 18:11:20 2003
Subject: [R] Covariance matrix for GMM
In-Reply-To: <024501c2d1ee$9122bdf0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <Pine.LNX.4.44.0302111211350.6908-100000@bolker.zoo.ufl.edu>

  I think the problem (for me at least) is that you haven't stated the
problem quite clearly enough.  I may (quite probably) be missing
something; the means clearly combine additively (mean=a1*u1+a2*u2), I 
think the covariances combine additively as well.

  In addition, you may not be getting much in the way of answers because 
this is a general stats/probability question, not an R question.  People 
on this list sometimes answer general questions if they're feeling 
particularly generous and/or interested, but it's not the general purpose 
of the list; you could try the newsgroup sci.stat.consult ... 

  Ben Bolker


On Tue, 11 Feb 2003, Feng Zhang wrote:

> There is no way to answer this question?
> 
> even for writing the sample covariance matrix
> formulation for the data set [X, Y] where
> X(n observations) and Y (m observations) are from
> the class 1 and class 2 which both are
> multidimensional normal distribution?
> 
> 
> ----- Original Message -----
> From: "Feng Zhang" <f0z6305 at labs.tamu.edu>
> To: "R-Help" <r-help at stat.math.ethz.ch>
> Sent: Tuesday, February 11, 2003 12:11 AM
> Subject: [R] Covariance matrix for GMM
> 
> 
> > Hey, All
> >
> > Now I generate a data vector X (d-dimension column vector) from a Gaussian
> > Mixture Model (GMM).
> > That is, the pdf of vector X is
> > f(X) = a1*N(u1, Cov1) + a2*(u2, Cov2)
> > where a1+a2 = 1, N is multidimensional normal distribution, ui is the mean
> > vecotr, Covi is the covariance matrix, i=1, 2.
> >
> > So can I get the close forms of the mean and covariance matrix for the
> > random vector X?
> >
> > Thanks very much.
> >
> > Fred
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From jfox at mcmaster.ca  Tue Feb 11 18:21:02 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue Feb 11 18:21:02 2003
Subject: [R] Periods instead of spaces in dataframe names?
In-Reply-To: <JFEDJKCABKCOMJDIIFPJOEOOCJAA.tarnold@smpllc.com>
Message-ID: <5.1.0.14.2.20030211121143.01e50f38@mcmail.cis.mcmaster.ca>

Dear Tom,

When you read the data into a data frame via read.csv, the character 
strings in the first row of the data file, which you've indicated is to be 
interpreted as a header, are used for column names; in the process, blanks 
are converted to periods, since nonstandard names including blanks are more 
difficult to deal with; names(df[13]) just returns the name of column 13 in 
the data frame. You could use the gsub function to recover the blanks -- 
something like gsub("\\."," ", names(df[2])). Alternatively, you could 
specify the argument check.names=FALSE to read.csv to avoid substituting 
periods for blanks in the first place, but this probably isn't a good idea. 
See ?read.csv for details.

I hope that this helps,
  John


At 09:33 AM 2/11/2003 -0700, Tom Arnold wrote:
>Basic question:
>when I use names() to extract the name of a dataframe element, why does it
>have "." instead of " " between words?
>
>Context:
>I'm importing a CSV file of survey results for analysis. I read them like
>this:
>
>df <- read.csv("surveydata.csv",nrows=40,header=TRUE,
>                na.string=c("N/A",""),comment.char="",strip.white=TRUE)
>
>To do a summary of the responses to a question, I can now do something like
>this:
>
>table(df[13])
>
>  1  2  3  4
>13 13  4  2
>
>and can then do a barplot with:
>barplot(table(df[13])))
>
>Which is fine. But since the first row of my data file includes the questions
>themselves, I want to use those questions as chart titles, like this:
>
>barplot(table(df[13]),main=names(df[13]))
>
>This gives an unexpected result: the title has a "." where every space should
>be between words, like this: "How.many.cats.do.you.own"
>
>I can't figure out why, or how to get spaces instead of "." to show up. I've
>tried using gsub but without success, to substitute " " for "."
>
>I'm think I'm confused about something fundamental here, and hope someone has
>the patience to enlighten me. I confess to a being a bit vague in my
>understanding of R's handling of arrays, dataframes, and vectors. My
>background is in C programming and I keep looking for a "string"...
>
>Thank you very much. Please reply or copy me directly if you respond.
>
>Tom Arnold
>Managing Partner, Summit Media Partners LLC
>Visit our web site at http://www.summitmediapartners.com
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From p.dalgaard at biostat.ku.dk  Tue Feb 11 18:33:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Feb 11 18:33:03 2003
Subject: [R] Covariance matrix for GMM
In-Reply-To: <024501c2d1ee$9122bdf0$8bd75ba5@IE.TAMU.EDU>
References: <021f01c2d194$6e59f770$8bd75ba5@IE.TAMU.EDU>
	<024501c2d1ee$9122bdf0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <x2ptpy67tx.fsf@biostat.ku.dk>

"Feng Zhang" <f0z6305 at labs.tamu.edu> writes:

> There is no way to answer this question?
> 
> even for writing the sample covariance matrix
> formulation for the data set [X, Y] where
> X(n observations) and Y (m observations) are from
> the class 1 and class 2 which both are
> multidimensional normal distribution?

It's hardly an R question, is it? However, the calculation is easy
enough in principle, at least in your original formulation: You need
the conditioning event C (the latent class) and then work out

E(X) = E(E(X|C)) = a1 * mu1 + a2 * mu2 = mu
V(X) = E(V(X|C)) + V(E(X|C))  = a1*V1 + a2*V2 + foo

with 

foo = a1 * (mu1 - mu)^2 + a2 * (mu2 - mu)^2 = a1 * a2 * (mu1 - mu2)^2
 
where "x^2" really means x x' (==outer(x,x)) so that you get a matrix
of the proper dimensions. (And do check the math rather than believe
that I get it right 1st time...)

        -p

> 
> ----- Original Message -----
> From: "Feng Zhang" <f0z6305 at labs.tamu.edu>
> To: "R-Help" <r-help at stat.math.ethz.ch>
> Sent: Tuesday, February 11, 2003 12:11 AM
> Subject: [R] Covariance matrix for GMM
> 
> 
> > Hey, All
> >
> > Now I generate a data vector X (d-dimension column vector) from a Gaussian
> > Mixture Model (GMM).
> > That is, the pdf of vector X is
> > f(X) = a1*N(u1, Cov1) + a2*(u2, Cov2)
> > where a1+a2 = 1, N is multidimensional normal distribution, ui is the mean
> > vecotr, Covi is the covariance matrix, i=1, 2.
> >
> > So can I get the close forms of the mean and covariance matrix for the
> > random vector X?
> >
> > Thanks very much.
> >
> > Fred
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tarnold at smpllc.com  Tue Feb 11 18:44:02 2003
From: tarnold at smpllc.com (Tom Arnold)
Date: Tue Feb 11 18:44:02 2003
Subject: [R] Periods instead of spaces in dataframe names?
In-Reply-To: <5.1.0.14.2.20030211121143.01e50f38@mcmail.cis.mcmaster.ca>
Message-ID: <JFEDJKCABKCOMJDIIFPJIEPCCJAA.tarnold@smpllc.com>

Thanks to John, Sundar, and Peter Dalgaard for their quick and helpful (and
correct!) answers to my questions.

By explaining the check.names argument and the need to escape the "." to be
"\\." in gsub(), I now have several ways to solve the problem.

I also found the "strwrap" function, so now I can easily put neat titles on my
charts without manual formatting or retyping data.

The more I use R, the easier it gets. But without the help of the community of
users, I really would be stuck.

-Tom
> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch
> [mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of John Fox
> Sent: Tuesday, February 11, 2003 10:21 AM
> To: Tom Arnold
> Cc: R-Help
> Subject: Re: [R] Periods instead of spaces in dataframe names?
>
>
> Dear Tom,
>
> When you read the data into a data frame via read.csv, the character
> strings in the first row of the data file, which you've indicated is to be
> interpreted as a header, are used for column names; in the process, blanks
> are converted to periods, since nonstandard names including blanks are more
> difficult to deal with; names(df[13]) just returns the name of column 13 in
> the data frame. You could use the gsub function to recover the blanks --
> something like gsub("\\."," ", names(df[2])). Alternatively, you could
> specify the argument check.names=FALSE to read.csv to avoid substituting
> periods for blanks in the first place, but this probably isn't a good idea.
> See ?read.csv for details.
>
> I hope that this helps,
>   John



From gavin.simpson at ucl.ac.uk  Tue Feb 11 18:50:08 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue Feb 11 18:50:08 2003
Subject: [R] Dynamic Linear Models for Times Series - Implemented?
Message-ID: <000501c2d1f5$e68fc650$4c202880@gsimpson>

Hi,

I was wondering whether a package that can perform dynamic linear models on
times series data was available for R?

Many Thanks,

Gavin Simpson

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       
26 Bedford Way                    
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From Setzer.Woodrow at epamail.epa.gov  Tue Feb 11 19:31:06 2003
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Tue Feb 11 19:31:06 2003
Subject: [R] Problems with Rcmd check on Win 2000 & rw1062
Message-ID: <OF8E6A9DAE.037C6A08-ON85256CCA.00639D9A@rtp.epa.gov>

When I run Rcmd check on a package on my Windows 2000 machine, I get a
series of error messages like the following:

* checking generic/method consistency ...c:\DOCUME~1\R5018~1.WOO\LOCALS~1\Temp/R
utils138414013: cannot open c:DOCUME~1R5018~1.WOOLOCALS~1Temp/Rin138408157: no s
uch file

It looks as if a Windows style path to the temp directory is not being interpreted correctly, with backslashes not being properly escaped.
However,
I define three different environment variables to point to a temp directory (TMP, TEMP, TMPDIR), and all definitions use forward slashes,
Unix-style,
so Rcmd check has found some other way to construct the path to a temp directory.
Does anyone know how I can fix this so that Rcmd check will work?

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status =
 major = 1
 minor = 6.2
 year = 2003
 month = 01
 day = 10
 language = R

Windows 2000 Professional (build 2195) Service Pack 2.0

Search Path:
 .GlobalEnv, package:OPmodels, package:odesolve, package:ctest, Autoloads, package:base

R. Woodrow Setzer, Jr.                        Phone: (919) 541-0128
Experimental Toxicology Division             Fax:  (919) 541-4284
Pharmacokinetics Branch
NHEERL B143-05; US EPA; RTP, NC 27711



From ripley at stats.ox.ac.uk  Tue Feb 11 20:02:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb 11 20:02:03 2003
Subject: [R] Problems with Rcmd check on Win 2000 & rw1062
In-Reply-To: <OF8E6A9DAE.037C6A08-ON85256CCA.00639D9A@rtp.epa.gov>
Message-ID: <Pine.LNX.4.44.0302111850590.1244-100000@gannet.stats>

Rcmd check uses TMPDIR, so what exactly do you have that set to?
It does look to me as if you do not have it set correctly, but you can 
debug the Perl to find out what it is doing.

It certainly works for me iff TMPDIR is set correctly.

On Tue, 11 Feb 2003 Setzer.Woodrow at epamail.epa.gov wrote:

> When I run Rcmd check on a package on my Windows 2000 machine, I get a
> series of error messages like the following:
> 
> * checking generic/method consistency ...c:\DOCUME~1\R5018~1.WOO\LOCALS~1\Temp/R
> utils138414013: cannot open c:DOCUME~1R5018~1.WOOLOCALS~1Temp/Rin138408157: no s
> uch file
> 
> It looks as if a Windows style path to the temp directory is not being interpreted correctly, with backslashes not being properly escaped.
> However,
> I define three different environment variables to point to a temp directory (TMP, TEMP, TMPDIR), and all definitions use forward slashes,
> Unix-style,
> so Rcmd check has found some other way to construct the path to a temp directory.
> Does anyone know how I can fix this so that Rcmd check will work?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Setzer.Woodrow at epamail.epa.gov  Tue Feb 11 20:32:03 2003
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Tue Feb 11 20:32:03 2003
Subject: [R] Problems with Rcmd check on Win 2000 & rw1062
Message-ID: <OFA55CBBA0.919C1E05-ON85256CCA.00692177@rtp.epa.gov>

TMPDIR seems to be OK:

> echo %TMPDIR%
C:/DOCUME~1/R5018~1.WOO/LOCALS~1/Temp

>

I'll poke around in the Perl code to see what I can find.

R. Woodrow Setzer, Jr.                        Phone: (919) 541-0128
Experimental Toxicology Division             Fax:  (919) 541-4284
Pharmacokinetics Branch
NHEERL B143-05; US EPA; RTP, NC 27711


                                                                                                                                       
                      ripley at stats.ox.a                                                                                                
                      c.uk                     To:       Woodrow Setzer/RTP/USEPA/US at EPA                                               
                                               cc:       r-help at stat.math.ethz.ch                                                      
                      02/11/03 02:01 PM        Subject:  Re: [R] Problems with Rcmd check on Win 2000 & rw1062                         
                                                                                                                                       
                                                                                                                                       




Rcmd check uses TMPDIR, so what exactly do you have that set to?
It does look to me as if you do not have it set correctly, but you can
debug the Perl to find out what it is doing.

It certainly works for me iff TMPDIR is set correctly.

On Tue, 11 Feb 2003 Setzer.Woodrow at epamail.epa.gov wrote:

> When I run Rcmd check on a package on my Windows 2000 machine, I get a
> series of error messages like the following:
>
> * checking generic/method consistency ...c:
\DOCUME~1\R5018~1.WOO\LOCALS~1\Temp/R
> utils138414013: cannot open
c:DOCUME~1R5018~1.WOOLOCALS~1Temp/Rin138408157: no s
> uch file
>
> It looks as if a Windows style path to the temp directory is not being
interpreted correctly, with backslashes not being properly escaped.
> However,
> I define three different environment variables to point to a temp
directory (TMP, TEMP, TMPDIR), and all definitions use forward slashes,
> Unix-style,
> so Rcmd check has found some other way to construct the path to a temp
directory.
> Does anyone know how I can fix this so that Rcmd check will work?

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jgramlich at piocon.com  Tue Feb 11 21:55:04 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Tue Feb 11 21:55:04 2003
Subject: [R] postgres
Message-ID: <1044996862.4198.60.camel@localhost.localdomain>

Is anyone using R with postgres?  I'd like to do so, but cannot seem to
find any reasonable explanation of how to do so.


Joshua Gramlich
Chicago, IL



From drf5n at mug.sys.virginia.edu  Tue Feb 11 22:09:03 2003
From: drf5n at mug.sys.virginia.edu (David Forrest)
Date: Tue Feb 11 22:09:03 2003
Subject: [R] postgres
In-Reply-To: <1044996862.4198.60.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.33.0302111601350.7813-100000@mug.sys.virginia.edu>

On 11 Feb 2003, Joshua Gramlich wrote:

> Is anyone using R with postgres?  I'd like to do so, but cannot seem to
> find any reasonable explanation of how to do so.
>
>
> Joshua Gramlich
> Chicago, IL

library(RPgSQL)  # It isn't in an obvious place:
                 # http://lib.stat.cmu.edu/R/CRAN/src/contrib/Devel
db.connect()
db.ls()

Dave,
-- 
 Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
 drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/



From luke at stat.uiowa.edu  Tue Feb 11 22:16:03 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue Feb 11 22:16:03 2003
Subject: [R] Memory allocation, IBM-AIX and R-1.6.2 - addendum
In-Reply-To: <x2u1fc2g1w.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0302111459470.4949-100000@itasca.stat.uiowa.edu>

On 10 Feb 2003, Peter Dalgaard BSA wrote:

> Laurent Gautier <laurent at cbs.dtu.dk> writes:
> 
> > ...sorry for the spam, but answers I get to my previous
> > question suggest that I should specify that the
> > machine has a *lot* of memory and should be able
> > to the instanciation...
> > 
> > Anybody with an IBM mainframe, R-1.6.2 and large
> > matrices ?
> 
> For whatever it's worth, that size does not appear to be a problem in
> Linux. Takes a while, and a lot of memory, to get a summary of the
> matrix though (I'm slightly puzzled by that: The memory footprint
> appears to shoot up to 1.7G for something that is just working
> on the columns of a 319M matrix?).

If the AIX you are using is 32 bit (I forget if they support 64) then
you have to remember that, no matter how much memory you have, you are
starting to run up against address space limits.  It is only fairly
recent Linux malloc's that are able to give a process more than 1GB of
address space, and the way things are done when the 1G threshold is
crossed is not necessarily very efficient.  (1G is usually the point
in the address space where the traditional heap has to stop because
the shared library loader is mapped there).  AIX will be different in
detail but the basic issue is the same: 2^32 = 4G only leave you so
much room to do the things the OS needs to do.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From jfox at mcmaster.ca  Tue Feb 11 22:31:02 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue Feb 11 22:31:02 2003
Subject: [R] postgres
In-Reply-To: <Pine.LNX.4.33.0302111601350.7813-100000@mug.sys.virginia.e
 du>
References: <1044996862.4198.60.camel@localhost.localdomain>
Message-ID: <5.1.0.14.2.20030211162642.01dfac90@mcmail.cis.mcmaster.ca>

Dear David and Joshua,

One can also access PostgreSQL via the RODBC package. There's more 
information in section 4 of the R Data Import/Export manual, which is part 
of the R distribution and is also available on CRAN.

John

At 04:08 PM 2/11/2003 -0500, David Forrest wrote:
>On 11 Feb 2003, Joshua Gramlich wrote:
>
> > Is anyone using R with postgres?  I'd like to do so, but cannot seem to
> > find any reasonable explanation of how to do so.
> >
> >
> > Joshua Gramlich
> > Chicago, IL
>
>library(RPgSQL)  # It isn't in an obvious place:
>                  # http://lib.stat.cmu.edu/R/CRAN/src/contrib/Devel
>db.connect()
>db.ls()
>
>Dave,
>--
>  Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
>  drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From clists at perrin.socsci.unc.edu  Tue Feb 11 22:36:03 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Tue Feb 11 22:36:03 2003
Subject: [R] postgres
In-Reply-To: <1044996862.4198.60.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.21.0302111632560.21972-100000@perrin.socsci.unc.edu>

Yes, I do. Here's a code snippet that worked for me:

library(RPgSQL)
db.connect(dbname='fgdata')
fgdata.df<-db.read.table('mlm_data')


This assumes you have the RPgSQL library installed, and that you have
postgres running on the local machine.  There's more documentation in the
RPgSQL package.

Best,
Andy Perrin

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu


On 11 Feb 2003, Joshua Gramlich wrote:

> Is anyone using R with postgres?  I'd like to do so, but cannot seem to
> find any reasonable explanation of how to do so.
> 
> 
> Joshua Gramlich
> Chicago, IL
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From andy_liaw at merck.com  Tue Feb 11 22:40:22 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Feb 11 22:40:22 2003
Subject: [R] configure can't get readline to work
Message-ID: <3A822319EB35174CA3714066D590DCD534BC7E@usrymx25.merck.com>

Dear R-help,

I'm running into some strange problem compiling R 1.6.2 on Mandrake Linux
9.0.  When I do 

  ./configure --enable-R-shlib

I get the following in config.log:
===========================
configure:11366: checking for rl_callback_read_char in -lreadline
configure:11397: gcc -o conftest -g -O2  -L/usr/local/lib conftest.c
-lreadline  -ldl -lm  >&5
/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
undefined reference to `tgetnum'
/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
undefined reference to `tgoto'
/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
undefined reference to `tgetflag'
/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
undefined reference to `BC'
/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
undefined reference to `tputs'
/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
undefined reference to `PC'
/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
undefined reference to `tgetent'
/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
undefined reference to `UP'
/usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
undefined reference to `tgetstr'
collect2: ld returned 1 exit status
configure:11400: $? = 1
configure: failed program was:
| #line 11373 "configure"
| /* confdefs.h.  */
| 
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "r"
| #define PACKAGE_VERSION "1.6.2"
| #define PACKAGE_STRING "R 1.6.2"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "1.6.2"
| #define R_PLATFORM "i686-pc-linux-gnu"
| #define R_CPU "i686"
| #define R_VENDOR "pc"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #ifdef __cplusplus
| #include <stdlib.h>
| #endif
| #define HAVE_LIBM 1
| #define HAVE_LIBDL 1
| /* end confdefs.h.  */
| 
| /* Override any gcc2 internal prototype to avoid an error.  */
| #ifdef __cplusplus
| extern "C"
| #endif
| /* We use char because int might match the return type of a gcc2
|    builtin and then its argument prototype would still apply.  */
| char rl_callback_read_char ();
| int
| main ()
| {
| rl_callback_read_char ();
|   ;
|   return 0;
| }
configure:11418: result: no
=================================

Does this mean my readline installation is somehow defective?  I've tried
re-installing readline (and readline-devel) version 4.3-4, to no avail.  Can
someone give me some hints?

Regards,
Andy



Andy I. Liaw, PhD
Biometrics Research          Phone: (732) 594-0820
Merck & Co., Inc.              Fax: (732) 594-1565
P.O. Box 2000, RY84-16            Rahway, NJ 07065
mailto:andy_liaw at merck.com



------------------------------------------------------------------------------



From edd at debian.org  Tue Feb 11 22:45:04 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue Feb 11 22:45:04 2003
Subject: [R] postgres
Message-ID: <E18ihlC-0003A0-00@sonny.eddelbuettel.com>

> Is anyone using R with postgres?  I'd like to do so, but cannot seem to
> find any reasonable explanation of how to do so.

Lots of us do.  There is a confusingly wide selection of connection mechanisms
available, I mostly stick with RODBC as I can then use the same code snippets
under Windoze and Linux.  But I also use the RPgSQL (sp?) module directly. Where
exactly are you faltering?

Dirk, also in Chicago

-- 
According to the latest figures, 43% of all signatures are totally worthless.



From jgramlich at piocon.com  Tue Feb 11 22:50:07 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Tue Feb 11 22:50:07 2003
Subject: [R] postgres
In-Reply-To: <5.1.0.14.2.20030211162642.01dfac90@mcmail.cis.mcmaster.ca>
References: <1044996862.4198.60.camel@localhost.localdomain> 
	<5.1.0.14.2.20030211162642.01dfac90@mcmail.cis.mcmaster.ca>
Message-ID: <1045000130.4197.80.camel@localhost.localdomain>

I'm actually looking at that exact page in the import/export manual
right now.  I'm trying to install RODBC via CRAN, but I get this:

....blahblahblah...
checking for library containing SQLTables... no
configure: error: "no ODBC driver manager found"
ERROR: configuration failed for package 'RODBC'

Delete downloaded files (y/N)? y

Warning message: 
Installation of package RODBC had non-zero exit status in:
install.packages("RODBC") 
>


I tried installing unixODBC, but that didn't seem to solve the problem.

Thoughts?



Josh
Chicago






On Tue, 2003-02-11 at 15:31, John Fox wrote:
> Dear David and Joshua,
> 
> One can also access PostgreSQL via the RODBC package. There's more 
> information in section 4 of the R Data Import/Export manual, which is part 
> of the R distribution and is also available on CRAN.
> 
> John
> 
> At 04:08 PM 2/11/2003 -0500, David Forrest wrote:
> >On 11 Feb 2003, Joshua Gramlich wrote:
> >
> > > Is anyone using R with postgres?  I'd like to do so, but cannot seem to
> > > find any reasonable explanation of how to do so.
> > >
> > >
> > > Joshua Gramlich
> > > Chicago, IL
> >
> >library(RPgSQL)  # It isn't in an obvious place:
> >                  # http://lib.stat.cmu.edu/R/CRAN/src/contrib/Devel
> >db.connect()
> >db.ls()
> >
> >Dave,
> >--
> >  Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
> >  drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/
> 
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jmartinez at uia.net  Tue Feb 11 23:05:13 2003
From: jmartinez at uia.net (Jason W. Martinez)
Date: Tue Feb 11 23:05:13 2003
Subject: [R] postgres
In-Reply-To: <1045000130.4197.80.camel@localhost.localdomain>
References: <1044996862.4198.60.camel@localhost.localdomain> <5.1.0.14.2.20030211162642.01dfac90@mcmail.cis.mcmaster.ca> <1045000130.4197.80.camel@localhost.localdomain>
Message-ID: <200302111411.28022.jmartinez@uia.net>

Josh,

It sounds like part of your problem is that you're not reading all of the 
documentation. The first step is to _understand_ what an ODBC Manager is AND 
what it is supposed to be doing.

You have to configure your manager (among other things) before you can even 
begin to make a connection from R with (RODBC).

Don't get discouraged. ODBC is beautiful thing! Further, I make connections 
with RODBC to postgresql databases all the time. It is possible, just be 
patient and read the docs.

Jason

On Tuesday 11 February 2003 01:48 pm, Joshua Gramlich wrote:
> I'm actually looking at that exact page in the import/export manual
> right now.  I'm trying to install RODBC via CRAN, but I get this:
>
> ....blahblahblah...
> checking for library containing SQLTables... no
> configure: error: "no ODBC driver manager found"
> ERROR: configuration failed for package 'RODBC'
>
> Delete downloaded files (y/N)? y
>
> Warning message:
> Installation of package RODBC had non-zero exit status in:
> install.packages("RODBC")
>
>
>
> I tried installing unixODBC, but that didn't seem to solve the problem.
>
> Thoughts?
>
>
>
> Josh
> Chicago
>
> On Tue, 2003-02-11 at 15:31, John Fox wrote:
> > Dear David and Joshua,
> >
> > One can also access PostgreSQL via the RODBC package. There's more
> > information in section 4 of the R Data Import/Export manual, which is
> > part of the R distribution and is also available on CRAN.
> >
> > John
> >
> > At 04:08 PM 2/11/2003 -0500, David Forrest wrote:
> > >On 11 Feb 2003, Joshua Gramlich wrote:
> > > > Is anyone using R with postgres?  I'd like to do so, but cannot seem
> > > > to find any reasonable explanation of how to do so.
> > > >
> > > >
> > > > Joshua Gramlich
> > > > Chicago, IL
> > >
> > >library(RPgSQL)  # It isn't in an obvious place:
> > >                  # http://lib.stat.cmu.edu/R/CRAN/src/contrib/Devel
> > >db.connect()
> > >db.ls()
> > >
> > >Dave,
> > >--
> > >  Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
> > >  drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/
> >
> > -----------------------------------------------------
> > John Fox
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario, Canada L8S 4M4
> > email: jfox at mcmaster.ca
> > phone: 905-525-9140x23604
> > web: www.socsci.mcmaster.ca/jfox
> > -----------------------------------------------------
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Jason W. Martinez, Graduate student
Department of Sociology
University of California, Riverside



From Brian.J.GREGOR at odot.state.or.us  Tue Feb 11 23:44:12 2003
From: Brian.J.GREGOR at odot.state.or.us (Brian.J.GREGOR@odot.state.or.us)
Date: Tue Feb 11 23:44:12 2003
Subject: [R] How "else" works
Message-ID: <372EFF9FE4E42E419C978E7A305DC5FE014E52E6@exsalem5.odot.state.or.us>

I have what is likely to be a simple question about the else keyword.

The usage in the help pages is as follows:

	if(cond) cons.expr  else  alt.expr

I would expect to be able to use it in the following way as well:

	if(cond){
		cons.expr
	}
	else alt.expr

This results a syntax error.

Am I doing something wrong, or doesn't R support the spanning of the
combination of if and else statements over several lines?

Brian Gregor, P.E.
Transportation Planning Analysis Unit
Oregon Department of Transportation
Brian.J.GREGOR at odot.state.or.us
(503) 986-4120



From p.dalgaard at biostat.ku.dk  Tue Feb 11 23:50:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Feb 11 23:50:04 2003
Subject: [R] configure can't get readline to work
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BC7E@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD534BC7E@usrymx25.merck.com>
Message-ID: <x23cmu4ew6.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> Dear R-help,
> 
> I'm running into some strange problem compiling R 1.6.2 on Mandrake Linux
> 9.0.  When I do 
> 
>   ./configure --enable-R-shlib
> 
> I get the following in config.log:
> ===========================
> configure:11366: checking for rl_callback_read_char in -lreadline
> configure:11397: gcc -o conftest -g -O2  -L/usr/local/lib conftest.c
> -lreadline  -ldl -lm  >&5
> /usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
> undefined reference to `tgetnum'
> /usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
> undefined reference to `tgoto'
> /usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
> undefined reference to `tgetflag'
...
> configure:11418: result: no
> =================================
> 
> Does this mean my readline installation is somehow defective?  I've tried
> re-installing readline (and readline-devel) version 4.3-4, to no avail.  Can
> someone give me some hints?

Those are ncurses routines, so if it were RedHat I'd point you towards
the ncurses and ncurses-devel RPMs. Mandrake is usually similar.

(Curiously, on RH, the readline RPM does not require ncurses, even
though the library clearly has symbol references to it...)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jgramlich at piocon.com  Tue Feb 11 23:54:27 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Tue Feb 11 23:54:27 2003
Subject: [R] postgres
In-Reply-To: <200302111411.28022.jmartinez@uia.net>
References: <1044996862.4198.60.camel@localhost.localdomain>
	<5.1.0.14.2.20030211162642.01dfac90@mcmail.cis.mcmaster.ca>
	<1045000130.4197.80.camel@localhost.localdomain> 
	<200302111411.28022.jmartinez@uia.net>
Message-ID: <1045003564.4197.106.camel@localhost.localdomain>

Right, but you see, I'm not trying to make a connection in R yet, I'm
trying to get the right tools installed.  I have found zero coherent
documentation for any of this stuff.  Yes, there's the import/export
guide, and that's helpful and all but it doesn't tell me what I need to
do with these files:

DBI.RPgSQL_0.1-2.tar.gz
Rdbi_0.1-2.tar.gz
Rdbi.PgSQL_0.1-2.tar.gz

None of these files contains any documentation either.

...now, when I go to 

http://rpgsql.sourceforge.net/

There's no documentation there either.  In fact, there's only a message
saying that this project has been deprecated in favor of Rdbi.  If you
click on the download link, you get an error from sourceforge, so you
cannot even get the code through the sourceforge website.  If you go to
the Rdbi page, there isn't anything there either...and on the
sourceforge page the download is for version 0.1.2.

...and that just covers the postgres specific stuff.


As to how RODBC works, I don't know, because I haven't found any
documentation specifically about that either.  Again, there's the
import/export guide, but that's only about how to use it, not how to get
one's system set up to use it.   All I've figured out to do is run
"install.packages("RODBC")"...which begins the installation process, but
because the driver manager apparently isn't set up correctly, it tells
me I must install a driver manager....or "no ODBC driver manager found".

I have unixODBC installed...

Ugh.  I'm giving up on this for today.  I just found out that there is
no odbc rpm for postgres 7.3.1, so i'm gonna have to go back to 7.2.4 to
get that functionality in rpm format...which means blowing out my
database...which means tomorrow.


Thanks for all the help so far folks.


Josh
Chicago







On Tue, 2003-02-11 at 16:11, Jason W. Martinez wrote:
> Josh,
> 
> It sounds like part of your problem is that you're not reading all of the 
> documentation. The first step is to _understand_ what an ODBC Manager is AND 
> what it is supposed to be doing.
> 
> You have to configure your manager (among other things) before you can even 
> begin to make a connection from R with (RODBC).
> 
> Don't get discouraged. ODBC is beautiful thing! Further, I make connections 
> with RODBC to postgresql databases all the time. It is possible, just be 
> patient and read the docs.
> 
> Jason
> 
> On Tuesday 11 February 2003 01:48 pm, Joshua Gramlich wrote:
> > I'm actually looking at that exact page in the import/export manual
> > right now.  I'm trying to install RODBC via CRAN, but I get this:
> >
> > ....blahblahblah...
> > checking for library containing SQLTables... no
> > configure: error: "no ODBC driver manager found"
> > ERROR: configuration failed for package 'RODBC'
> >
> > Delete downloaded files (y/N)? y
> >
> > Warning message:
> > Installation of package RODBC had non-zero exit status in:
> > install.packages("RODBC")
> >
> >
> >
> > I tried installing unixODBC, but that didn't seem to solve the problem.
> >
> > Thoughts?
> >
> >
> >
> > Josh
> > Chicago
> >
> > On Tue, 2003-02-11 at 15:31, John Fox wrote:
> > > Dear David and Joshua,
> > >
> > > One can also access PostgreSQL via the RODBC package. There's more
> > > information in section 4 of the R Data Import/Export manual, which is
> > > part of the R distribution and is also available on CRAN.
> > >
> > > John
> > >
> > > At 04:08 PM 2/11/2003 -0500, David Forrest wrote:
> > > >On 11 Feb 2003, Joshua Gramlich wrote:
> > > > > Is anyone using R with postgres?  I'd like to do so, but cannot seem
> > > > > to find any reasonable explanation of how to do so.
> > > > >
> > > > >
> > > > > Joshua Gramlich
> > > > > Chicago, IL
> > > >
> > > >library(RPgSQL)  # It isn't in an obvious place:
> > > >                  # http://lib.stat.cmu.edu/R/CRAN/src/contrib/Devel
> > > >db.connect()
> > > >db.ls()
> > > >
> > > >Dave,
> > > >--
> > > >  Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
> > > >  drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/
> > >
> > > -----------------------------------------------------
> > > John Fox
> > > Department of Sociology
> > > McMaster University
> > > Hamilton, Ontario, Canada L8S 4M4
> > > email: jfox at mcmaster.ca
> > > phone: 905-525-9140x23604
> > > web: www.socsci.mcmaster.ca/jfox
> > > -----------------------------------------------------
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> -- 
> Jason W. Martinez, Graduate student
> Department of Sociology
> University of California, Riverside
>



From sundar.dorai-raj at pdf.com  Tue Feb 11 23:59:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue Feb 11 23:59:03 2003
Subject: [R] How "else" works
References: <372EFF9FE4E42E419C978E7A305DC5FE014E52E6@exsalem5.odot.state.or.us>
Message-ID: <3E497ECF.3000303@pdf.com>


Brian.J.GREGOR at odot.state.or.us wrote:
> I have what is likely to be a simple question about the else keyword.
> 
> The usage in the help pages is as follows:
> 
> 	if(cond) cons.expr  else  alt.expr
> 
> I would expect to be able to use it in the following way as well:
> 
> 	if(cond){
> 		cons.expr
> 	}
> 	else alt.expr
> 
> This results a syntax error.
> 
> Am I doing something wrong, or doesn't R support the spanning of the
> combination of if and else statements over several lines?
> 


I believe this is the ``Introduction to R'' though where I am not sure. 
You need to have the following instead:

if(cond1) {
   do action 1
} else if(cond2) {
   do action 2
} else {
   do action 3
}

Regards,
Sundar



From jfox at mcmaster.ca  Wed Feb 12 00:08:02 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed Feb 12 00:08:02 2003
Subject: [R] How "else" works
In-Reply-To: <372EFF9FE4E42E419C978E7A305DC5FE014E52E6@exsalem5.odot.sta
 te.or.us>
Message-ID: <5.1.0.14.2.20030211180446.01e0b160@mcmail.cis.mcmaster.ca>

Dear Brian,

At 02:40 PM 2/11/2003 -0800, Brian.J.GREGOR at odot.state.or.us wrote:
>I have what is likely to be a simple question about the else keyword.
>
>The usage in the help pages is as follows:
>
>         if(cond) cons.expr  else  alt.expr
>
>I would expect to be able to use it in the following way as well:
>
>         if(cond){
>                 cons.expr
>         }
>         else alt.expr
>
>This results a syntax error.
>
>Am I doing something wrong, or doesn't R support the spanning of the
>combination of if and else statements over several lines?

This construction will work in a function, but not directly at the command 
prompt, since the lines of the command preceding "else" are syntactically 
complete and hence not subject to continuation. The following (and 
variations) will work at the prompt, however:

         if (cond) {
                 cons.expr
         } else
         alt.expr

John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From p.dalgaard at biostat.ku.dk  Wed Feb 12 00:13:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Feb 12 00:13:03 2003
Subject: [R] How "else" works
In-Reply-To: <372EFF9FE4E42E419C978E7A305DC5FE014E52E6@exsalem5.odot.state.or.us>
References: <372EFF9FE4E42E419C978E7A305DC5FE014E52E6@exsalem5.odot.state.or.us>
Message-ID: <x2y94m2z1e.fsf@biostat.ku.dk>

Brian.J.GREGOR at odot.state.or.us writes:

> 	if(cond){
> 		cons.expr
> 	}
> 	else alt.expr
> 
> This results a syntax error.
> 
> Am I doing something wrong, or doesn't R support the spanning of the
> combination of if and else statements over several lines?

The rule is that in it read-eval-print loop, R will evaluate as soon
as an expression is syntactically complete. Consider these two
examples:

(1)
if (x == y) print("equal")
b <- log(x)

and

(2)
if (x == y) print("equal")
else print("not equal")

The problem is that in (1), you want output after reading the first
line, and in the other, you don't. However, after reading the first
line you cannot know which type of example you have. So R assumes it
is of type (1), and that a new expression starts on the next line.
However, an expression cannot begin with "else", hence you get a
syntax error in case (2).

The way out is to ensure that the first line remains incomplete, so

if (x == y) print("equal") else 
print("not equal")

if (x == y) 
print("equal") else print("not equal")

{if (x == y) print("equal")
else print("not equal")}

all work.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From deepayan at stat.wisc.edu  Wed Feb 12 00:18:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed Feb 12 00:18:03 2003
Subject: [R] How "else" works
In-Reply-To: <372EFF9FE4E42E419C978E7A305DC5FE014E52E6@exsalem5.odot.state.or.us>
References: <372EFF9FE4E42E419C978E7A305DC5FE014E52E6@exsalem5.odot.state.or.us>
Message-ID: <200302111713.35078.deepayan@stat.wisc.edu>

On Tuesday 11 February 2003 04:40 pm, Brian.J.GREGOR at odot.state.or.us wrote:
> I have what is likely to be a simple question about the else keyword.
>
> The usage in the help pages is as follows:
>
> 	if(cond) cons.expr  else  alt.expr
>
> I would expect to be able to use it in the following way as well:
>
> 	if(cond){
> 		cons.expr
> 	}
> 	else alt.expr
>
> This results a syntax error.


What makes you say it does not work ? For example,


> foo = function(x) {
+    if (x == 1) {
+        print("one")
+    }
+    else {
+        print(x)
+    }
+  }
> 
> foo(1)
[1] "one"
> foo(2)
[1] 2
>



From rolf at math.unb.ca  Wed Feb 12 00:30:03 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed Feb 12 00:30:03 2003
Subject: [R] rpart v. lda classification.
Message-ID: <200302112328.TAA23634@gelfand.math.unb.ca>

I've been groping my way through a classification/discrimination
problem, from a consulting client.  There are 26 observations, with 4
possible categories and 24 (!!!) potential predictor variables.

I tried using lda() on the first 7 predictor variables and got 24 of
the 26 observations correctly classified.  (Training and testing both
on the complete data set --- just to get started.)

I then tried rpart() for comparison and was somewhat surprised when
rpart() only managed to classify 14 of the 26 observations correctly.
(I got the same classification using just the first 7 predictors as I
did using all of the predictors.)

I would have thought that rpart(), being unconstrained by a parametric
model, would have a tendency to over-fit and therefore to appear to
do better than lda() when the test data and training data are the
same.

Am I being silly, or is there something weird going on?  I can
give more detail on what I actually did, if anyone is interested.

The data are pretty obviously nothing like Gaussian, so my
gut feeling is that rpart() should be much more appropriate than
lda().  And it does not seem surprizing that with so few
observations to train with, the success rate should be low, even
when testing and training on the same data set.  What does
surprise me is that lda() gets such a high success rate.

Should I just put this down as a random occurrence of a low
prob. event?

				cheers,

					Rolf Turner
					rolf at math.unb.ca

P.S.  Using CV=TRUE in lda() I got only 16 of the 26 observations
correctly classified.



From Nick.Bond at sci.monash.edu.au  Wed Feb 12 00:57:06 2003
From: Nick.Bond at sci.monash.edu.au (Nick Bond)
Date: Wed Feb 12 00:57:06 2003
Subject: [R] Na/NaN error in subsampling script
Message-ID: <000801c2d229$173a8b40$8171fea9@monty>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030212/5a8e4d2b/attachment.pl

From andy_liaw at merck.com  Wed Feb 12 01:57:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Feb 12 01:57:03 2003
Subject: [R] configure can't get readline to work
Message-ID: <3A822319EB35174CA3714066D590DCD534BC83@usrymx25.merck.com>

Thanks very much to Prof. Dalgaard.  The problem was missing ncurses and
ncurses-devel.  After installing those, configure now finds readline
properly.

Cheers,
Andy

> -----Original Message-----
> From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> Sent: Tuesday, February 11, 2003 5:44 PM
> To: Liaw, Andy
> Cc: 'r-help at stat.math.ethz.ch'
> Subject: Re: [R] configure can't get readline to work
> 
> 
> "Liaw, Andy" <andy_liaw at merck.com> writes:
> 
> > Dear R-help,
> > 
> > I'm running into some strange problem compiling R 1.6.2 on 
> Mandrake Linux
> > 9.0.  When I do 
> > 
> >   ./configure --enable-R-shlib
> > 
> > I get the following in config.log:
> > ===========================
> > configure:11366: checking for rl_callback_read_char in -lreadline
> > configure:11397: gcc -o conftest -g -O2  -L/usr/local/lib conftest.c
> > -lreadline  -ldl -lm  >&5
> > 
> /usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
> > undefined reference to `tgetnum'
> > 
> /usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
> > undefined reference to `tgoto'
> > 
> /usr/lib/gcc-lib/i586-mandrake-linux-gnu/3.2/../../../libreadline.so:
> > undefined reference to `tgetflag'
> ...
> > configure:11418: result: no
> > =================================
> > 
> > Does this mean my readline installation is somehow 
> defective?  I've tried
> > re-installing readline (and readline-devel) version 4.3-4, 
> to no avail.  Can
> > someone give me some hints?
> 
> Those are ncurses routines, so if it were RedHat I'd point you towards
> the ncurses and ncurses-devel RPMs. Mandrake is usually similar.
> 
> (Curiously, on RH, the readline RPM does not require ncurses, even
> though the library clearly has symbol references to it...)
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: 
> (+45) 35327907
> 

------------------------------------------------------------------------------



From sundar.dorai-raj at pdf.com  Wed Feb 12 02:38:02 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed Feb 12 02:38:02 2003
Subject: [R] Na/NaN error in subsampling script
References: <000801c2d229$173a8b40$8171fea9@monty>
Message-ID: <3E49A535.9040907@pdf.com>


Nick Bond wrote:
 > R-help readers,
 >
 > I'm having a problem with an R script (see below), which regularly 
generates the error message,
 >
 > Error in start:(start + (sample.length - 1)) :
 >         NA/NaN argument
 >
 > , for which I am unsure of the cause.
 >
 > In essence, the script (below) generates the start and end points for 
random subsamples from along a vector (in reality a transect (of a given 
length, sample.length), that may be used to subsample from another 
vector of data.  The important point is that once a section of the 
transect has
 > been sampled, it cannot be resampled by an overlapping sub-transect. 
  WHile there are obvious limits on the number of non-overlapping 
subvectors that can be
 > taken from the original vector, I don't think this is the source of 
the error message, although the error is increasingly common as more of 
hte original vector is sampled.
 > Any help would be greatly appreciated.
 > regards
 > Nick
 >
 > r1<-function(transect.length,sample.length,reps) {   #Input: transect 
length, subsample length No.subsamples (reps).
 > x<-c(1:transect.length)     #create transect, x, of required length.
 > subsamples<-mat.or.vec(reps,2)    #create matrix for output of 
subsampled start and end points.
 > for(i in 1:reps) {     #start loop for reps.
 > start<-ceiling(runif(1,0,(transect.length-sample.length))) 
#generate initial random start point.
 > while (any(x[start:(start+(sample.length-1))])=="NA")

If x is numeric then you should use is.na to test for missing values:

while(any(is.na(x[start:(start+(sample.length-1))])))

 > subsamples[i,1]<-start     #store start point in ouput matrix
 > subsamples[i,2]<-(start+(sample.length-1))  #store end point in 
output matrix
 > x[start:(start+(sample.length-1))]<-NA   #convert sampled points to 
NA, for detection within the while loop above.
 > }
 > return(x,subsamples)     #return output.
 > }
 >
 > I would typically run the script with an input such as r1(1000,50,10)
 >

I didn't run this so I'm not sure if my suggestion is the only problem 
with the script.

Regards,
Sundar



From Setzer.Woodrow at epamail.epa.gov  Wed Feb 12 02:57:03 2003
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Wed Feb 12 02:57:03 2003
Subject: [R] Problems with Rcmd check on Win 2000 & rw1062
Message-ID: 
 <OF61CF5198.7F1C34C0-ON85256CCB.000A7A47-85256CCB.000A2D10@rtp.epa.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030212/3d7d8ddf/attachment.pl

From mschwartz at medanalytics.com  Wed Feb 12 06:42:04 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed Feb 12 06:42:04 2003
Subject: [R] Problems with Rcmd check on Win 2000 & rw1062
In-Reply-To: <OF61CF5198.7F1C34C0-ON85256CCB.000A7A47-85256CCB.000A2D10@rtp.epa.gov>
Message-ID: <003901c2d259$57f5bd00$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of 
>Setzer.Woodrow at epamail.epa.gov
>Sent: Tuesday, February 11, 2003 7:56 PM
>To: Setzer.Woodrow at epamail.epa.gov
>Cc: r-help at stat.math.ethz.ch; ripley at stats.ox.ac.uk
>Subject: Re: [R] Problems with Rcmd check on Win 2000 & rw1062
>
>
>I do not understand why, but changing the definition of TMPDIR 
>to C:/tmp 
>solved the problem. 
>
>R. Woodrow Setzer, Jr.
>
> SNIP
>


I was able to re-create your directory tree on my system (half of
which is WinXP Pro). I used the DOS 8.3 short format names, since I
don't have your expanded user name.

If I run Rcmd check with TMPDIR set to
C:\DOCUME~1\R5018~1.WOO\LOCALS~1\Temp with single backslashes, I run
into the problems that you identified in your first post.

If I run Rcmd check with TMPDIR set to
C:/DOCUME~1/R5018~1.WOO/LOCALS~1/Temp with single forward slashes, I
do not get the problems and Rcmd check runs fine on a package that I
have here.

Also, if I run Rcmd check with TMPDIR set to
C:\\DOCUME~1\\R5018~1.WOO\\LOCALS~1\\Temp with double backslashes, I
do not get the problems and Rcmd check runs fine.

I might add that I get the same phenomenon if I use my own directory
and make the above changes.  My normal TMPDIR is set using single
forward slashes. 

I was initially wondering if there was something in your full pathname
that might be an issue or perhaps you did not have proper access
rights to the directory tree. 

The above supports Prof. Ripley's observation that proper setting of
the TMPDIR variable using unix-style paths is required for the script
to work properly (as is the case with R file pathnames in general).

Hope that helps,

Marc Schwartz



From ripley at stats.ox.ac.uk  Wed Feb 12 09:03:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb 12 09:03:03 2003
Subject: [R] postgres
In-Reply-To: <1045003564.4197.106.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.44.0302120752400.2558-100000@gannet.stats>

RPgSQL etc seem now to be unsupported.

As for ODBC, there is some information in the README *but* setting up ODBC 
is not an R question.  Once you have a working connection (tested by say 
isql -v foo), then odbcConnect("foo") will work too.  There is lots of 
documentation on the unixODBC site.  Where I would be critical is of the 
Postrgres ODBC documentation: there are several drivers, no documentation 
and most of them are broken.  The one place you will find how to do it is 
in the RODBC README.  So I do resent your comments.


From ripley at stats.ox.ac.uk  Wed Feb 12 09:10:08 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb 12 09:10:08 2003
Subject: [R] rpart v. lda classification.
In-Reply-To: <200302112328.TAA23634@gelfand.math.unb.ca>
Message-ID: <Pine.LNX.4.44.0302120804090.2558-100000@gannet.stats>

On Tue, 11 Feb 2003, Rolf Turner wrote:

> 
> I've been groping my way through a classification/discrimination
> problem, from a consulting client.  There are 26 observations, with 4
> possible categories and 24 (!!!) potential predictor variables.
> 
> I tried using lda() on the first 7 predictor variables and got 24 of
> the 26 observations correctly classified.  (Training and testing both
> on the complete data set --- just to get started.)
> 
> I then tried rpart() for comparison and was somewhat surprised when
> rpart() only managed to classify 14 of the 26 observations correctly.
> (I got the same classification using just the first 7 predictors as I
> did using all of the predictors.)
> 
> I would have thought that rpart(), being unconstrained by a parametric
> model, would have a tendency to over-fit and therefore to appear to
> do better than lda() when the test data and training data are the
> same.
> 
> Am I being silly, or is there something weird going on?  I can
> give more detail on what I actually did, if anyone is interested.

The first.  rpart is seriously constrained by having so few observations,
and its model is much more restricted than lda: axis-parallel splits only.
There is a similar example, with pictures, in MASS (on Cushings).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From remigijus.lapinskas at maf.vu.lt  Wed Feb 12 11:54:02 2003
From: remigijus.lapinskas at maf.vu.lt (Remigijus Lapinskas)
Date: Wed Feb 12 11:54:02 2003
Subject: [R] Interpolation
Message-ID: <16536.030212@maf.vu.lt>

Dear all,

I have two vectors and connect the points by line segments:

x <- c(1990,1994,1995,1997)
y <- c(30,40,80,20)
plot(x,y,type="l")

I want to get the values of y's on these lines at missing x's,
i.e., at 1991,1992,1993,and 1996. Is there a simple way to do this?

Best regards,
Remigijus                          mailto:remigijus.lapinskas at maf.vu.lt



From ray at mcs.vuw.ac.nz  Wed Feb 12 12:13:05 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Wed Feb 12 12:13:05 2003
Subject: [R] Interpolation
Message-ID: <200302121112.h1CBC6P8018346@tahi.mcs.vuw.ac.nz>

> I have two vectors and connect the points by line segments:
> 
> x <- c(1990,1994,1995,1997)
> y <- c(30,40,80,20)
> plot(x,y,type="l")
> 
> I want to get the values of y's on these lines at missing x's,
> i.e., at 1991,1992,1993,and 1996. Is there a simple way to do this?
> 
Easy:
approx(x, y, c(1991:1993, 1996))$y
while
approx(x, y, 1990:1997)$y
will give you all the y values.

Hope this helps,
Ray Brownrigg <ray at mcs.vuw.ac.nz>	http://www.mcs.vuw.ac.nz/~ray



From john_hendrickx at yahoo.com  Wed Feb 12 14:00:03 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Wed Feb 12 14:00:03 2003
Subject: [R] multinomial conditional logit models
Message-ID: <20030212125928.87391.qmail@web14203.mail.yahoo.com>

A little while ago, I asked for some help in estimating "multinomial
conditional logit models". If you restructure your data, you can
estimate a multinomial logit as a conditional logit model. This gives
flexibility in imposing constraints on your dependent variable. One
application is to estimate a loglinear model for square tables such
as quasi-independence or quasi-symmetry with covariates.

Anyhow, I think I've sorted out most of the problems and I've posted
a sample program at
http://www.xs4all.nl/~jhckx/mcl/R/

There's also a sample program there on how to estimate models for
square tables, aka mobility models. Comments and suggestions on how
to do things more efficiently or elegantly in R are most welcome.

One problem that remains is that clogit in R doesn't produce the same
estimates as other programs like Stata. I've estimated this sample
model in several packages and they all have the same estimates to 3
decimal places accuracy. I've tried different convergence settings in
clogit but to no effect. I'd appreciate it if anyone could clarify
this.

Best regards,
John Hendrickx



From chrysopa at insecta.ufv.br  Wed Feb 12 14:05:36 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Wed Feb 12 14:05:36 2003
Subject: [R] Receiving Rnews by mail
Message-ID: <200302121008.41573.chrysopa@insecta.ufv.br>

Hi all,

I possible to receive Rnews automatically in my E-mail?

Thanks
Ronaldo
-- 
	O cerebro e um orgao maravilhoso. Comeca a funcionar assim 
	que voce se levanta da cama e nao p ra ate voce chegar ao 
	escritorio.
		-- Robert Frost 
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Gnu/Debian Woody D+:) | Lxuser#: 205366



From remigijus.lapinskas at maf.vu.lt  Wed Feb 12 14:09:03 2003
From: remigijus.lapinskas at maf.vu.lt (Remigijus Lapinskas)
Date: Wed Feb 12 14:09:03 2003
Subject: [R] Interpolation
References: <x2k7g5oivm.fsf@biostat.ku.dk>
Message-ID: <8625.030212@maf.vu.lt>

Many thanks to all who replied to my e-mail. My problem was that I
had not known about the approx function.

By the way, if I have  x <- c(1990,1994,1995,1997), is there an
automated way to fill in the gaps, i.e., to get
c(1991,1992,1993,1996)?

Cheers,
Remigijus


Wednesday, February 12, 2003, 12:09:33 PM, you wrote:

PDB> Remigijus Lapinskas <remigijus.lapinskas at maf.vu.lt> writes:

>> Dear all,
>>
>> I have two vectors and connect the points by line segments:
>>
>> x <- c(1990,1994,1995,1997)
>> y <- c(30,40,80,20)
>> plot(x,y,type="l")
>>
>> I want to get the values of y's on these lines at missing x's,
>> i.e., at 1991,1992,1993,and 1996. Is there a simple way to do this?


PDB> approx(x,y,c(1991,1992,1993,1996))
PDB> plot(x,y,type="l")
PDB> points(approx(x,y,c(1991,1992,1993,1996)),pch="*",col="red",cex=5)

PDB> --
PDB>    O__  ---- Peter Dalgaard             Blegdamsvej 3
PDB>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
PDB>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
PDB> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From john_hendrickx at yahoo.com  Wed Feb 12 14:12:30 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Wed Feb 12 14:12:30 2003
Subject: [R] models for square tables
Message-ID: <20030212130146.13275.qmail@web14206.mail.yahoo.com>

I've posted a sample file for estimating loglinear models for square
tables (mobility models) at http://www.xs4all.nl/~jhckx/mcl/R/
Comments and suggestions are welcome.

John Hendrickx



From gavin.simpson at ucl.ac.uk  Wed Feb 12 14:16:03 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed Feb 12 14:16:03 2003
Subject: [R] Dynamic Linear Models for Times Series - Implemented?
In-Reply-To: <000501c2d1f5$e68fc650$4c202880@gsimpson>
Message-ID: <000a01c2d297$e2fc37b0$4c202880@gsimpson>

Hi,

Following an off-list reply to my original post, I realised that I hadn't
really provided very much information for you to work with.  So here's a
second attempt:

Following West & Harrison (1989) and Pole et al. (1994) a DLM is defined as:

Y[t] = F'[t]theta[t] + v[t],	v[t] ~ N[0,V] #Observation equation
theta[t] = G[t]theta[t-1] + w[t],  w[t] ~ N[0,W] #system equation

The system equation is a first order Markov process, where G[t] is a matrix
of known coefficients that defines the systematic evolution of the state
vector (theta[t]) across time, and w[t] is an unobservable stochastic error
term having a normal distribution with zero mean and covariance matrix.

Y[t] denotes the observation series at time t
F[t] is a vector of known constants (the regression vector)
theta[t] denotes the vector of model state parameters
v[t] is a stochastic error term having zero mean and variance V[t]

If I have understood Brockwell and Davis (1991) correctly, the DLM can be
considered from the point of view of State-space models (although I am
venturing some way out of my statistical depth here, all the papers I have
collected are applied examples and they all refer to dynamic Linear Models,
not State-space models).

It seems that some of this has been done in S (for S-Plus), as I found the
bts package by Harrison and Reed on StatLib
(http://lib.stat.cmu.edu/DOS/S/), 

"SPLUS for Windows functions and datasets for Bayesian forecasting based on
the algorithms in Bayesian Forecasting and Dynamic Linear Models by West and
Harrison"

So I was wondering whether anyone knew of existing R code that could fit
such models?

Many thanks

Gavin Simpson

Refs:
Brockwell and Davis (1991).  Time Series: Theory and Methods.  Springer
Pole, West and Harrison (1994).  Applied Bayesian Forecasting and Time
Series Analysis.  Chapman & Hall/CRC
West and Harrison (1989).  Bayesian Forecasting and Dynamic Models.
Springer

-----Original Message-----
From: r-help-admin at stat.math.ethz.ch [mailto:r-help-admin at stat.math.ethz.ch]
On Behalf Of Gavin Simpson
Sent: 11 February 2003 17:49
To: r-help
Subject: [R] Dynamic Linear Models for Times Series - Implemented?


Hi,

I was wondering whether a package that can perform dynamic linear models on
times series data was available for R?

Many Thanks,

Gavin Simpson

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       
26 Bedford Way                    
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From sundar.dorai-raj at pdf.com  Wed Feb 12 14:42:02 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed Feb 12 14:42:02 2003
Subject: [R] Interpolation
References: <x2k7g5oivm.fsf@biostat.ku.dk> <8625.030212@maf.vu.lt>
Message-ID: <3E4A4E73.9020003@pdf.com>


Remigijus Lapinskas wrote:
> Many thanks to all who replied to my e-mail. My problem was that I
> had not known about the approx function.
> 
> By the way, if I have  x <- c(1990,1994,1995,1997), is there an
> automated way to fill in the gaps, i.e., to get
> c(1991,1992,1993,1996)?
> 

Try this:

R> x <- c(1990, 1994, 1995, 1997)
R> all.x <- seq(min(x), max(x))
R> missing.x <- all.x[!all.x %in% x]
R> missing.x
[1] 1991 1992 1993 1996
R>

Regards,
Sundar



From stecalza at tiscali.it  Wed Feb 12 15:23:06 2003
From: stecalza at tiscali.it (Stefano Calza)
Date: Wed Feb 12 15:23:06 2003
Subject: [R] GLMMGibbs crashes R
Message-ID: <3E4A6721.22050.108CDDD@localhost>

Hi everybody.

I'm trying to use the GLMMGibbs package (R 1.6.2, Linux/Debian 3.0) with the data 
scottish.lip.cancer, as described in the paper by J.Miles and D. Clayton. The problem is 
that the code at pag 18 crasches R:

***sparse_rd***too few elements (column 32) /n
Process R exited abnormally with code 1 ...

Has anyone experienced the same problem?

TIA,
Stefano



From markus.jantti at iki.fi  Wed Feb 12 16:02:06 2003
From: markus.jantti at iki.fi (Markus =?ISO-8859-1?Q?J=E4ntti?=)
Date: Wed Feb 12 16:02:06 2003
Subject: [R] rbind.data.frame: character comverted to factor
Message-ID: <1045061927.1163.56.camel@hugh.pp.htv.fi>

Dear All,

on rbind:ing together a number of data.frames, I found that
character variables are converted into factors. Since this
occurred for a data identifier, it was a little inconvenient
and, to me, unexpected. (The help page explains the
general procedure used. I also found that on forming 
a data frame, character variables are converted to factors.

The help page on read.table has the 'as.is' argument, which
I suppose kind of suggests that character variables  tend to
get converted into factors. Is there such a "preference" for 
factors and should this behaviour be expected?

Example code

 d1 <- data.frame(id =letters[1:20], x = runif(20))
d2 <- data.frame(id =paste(letters[1:20],letters[1:20], sep = ""),  x =
rexp(20))
d3 <- rbind(d1, d2)
str(d1) # <- id is factor
str(d2) # <- id is factor
str(d3) # <- id is factor
d1[["id"]] <- as.character(d1[["id"]])
d2[["id"]] <- as.character(d2[["id"]])
d3 <- rbind(d1, d2)
str(d1) # <- id is character
str(d2) # <- id is character
str(d3) # <- id is factor

Regards,

Markus
-- 
Markus J?ntti <markus.jantti at iki.fi>
Statistics Finland



From ripley at stats.ox.ac.uk  Wed Feb 12 16:14:02 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed Feb 12 16:14:02 2003
Subject: [R] rbind.data.frame: character comverted to factor
In-Reply-To: <1045061927.1163.56.camel@hugh.pp.htv.fi>
Message-ID: <Pine.GSO.4.44.0302121505080.2056-100000@auk.stats>

Read ?data.frame: that tells you to use

d1 <- data.frame(id =I(letters[1:20]), x = runif(20))
d2 <- data.frame(id =I(paste(letters[1:20],letters[1:20], sep = "")),  x
=rexp(20))
d3 <- rbind(d1, d2)

which of course works!

On 12 Feb 2003, Markus [ISO-8859-1] Jntti wrote:

> Dear All,
>
> on rbind:ing together a number of data.frames, I found that
> character variables are converted into factors. Since this
> occurred for a data identifier, it was a little inconvenient
> and, to me, unexpected. (The help page explains the
> general procedure used. I also found that on forming
> a data frame, character variables are converted to factors.

as documented in many places, including ?data.frame.

>
> The help page on read.table has the 'as.is' argument, which
> I suppose kind of suggests that character variables  tend to
> get converted into factors. Is there such a "preference" for
> factors and should this behaviour be expected?

It's as documented.

> Example code
>
>  d1 <- data.frame(id =letters[1:20], x = runif(20))
> d2 <- data.frame(id =paste(letters[1:20],letters[1:20], sep = ""),  x =
> rexp(20))
> d3 <- rbind(d1, d2)
> str(d1) # <- id is factor
> str(d2) # <- id is factor
> str(d3) # <- id is factor
> d1[["id"]] <- as.character(d1[["id"]])
> d2[["id"]] <- as.character(d2[["id"]])
> d3 <- rbind(d1, d2)
> str(d1) # <- id is character
> str(d2) # <- id is character
> str(d3) # <- id is factor

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Wed Feb 12 17:04:44 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Feb 12 17:04:44 2003
Subject: [R] Dynamic Linear Models for Times Series - Implemented?
In-Reply-To: <000a01c2d297$e2fc37b0$4c202880@gsimpson>
Message-ID: <Pine.A41.4.44.0302120759140.14012-100000@homer17.u.washington.edu>

On Wed, 12 Feb 2003, Gavin Simpson wrote:

> Hi,
>
> Following an off-list reply to my original post, I realised that I hadn't
> really provided very much information for you to work with.  So here's a
> second attempt:
>
> Following West & Harrison (1989) and Pole et al. (1994) a DLM is defined as:
>
> Y[t] = F'[t]theta[t] + v[t],	v[t] ~ N[0,V] #Observation equation
> theta[t] = G[t]theta[t-1] + w[t],  w[t] ~ N[0,W] #system equation
>
> The system equation is a first order Markov process, where G[t] is a matrix
> of known coefficients that defines the systematic evolution of the state
> vector (theta[t]) across time, and w[t] is an unobservable stochastic error
> term having a normal distribution with zero mean and covariance matrix.
>
> Y[t] denotes the observation series at time t
> F[t] is a vector of known constants (the regression vector)
> theta[t] denotes the vector of model state parameters
> v[t] is a stochastic error term having zero mean and variance V[t]
>
> If I have understood Brockwell and Davis (1991) correctly, the DLM can be
> considered from the point of view of State-space models (although I am
> venturing some way out of my statistical depth here, all the papers I have
> collected are applied examples and they all refer to dynamic Linear Models,
> not State-space models).
>

There are some models of this form in the ts package, see eg StructTS. It
may be possible to use some of the underlying Kalman filter machinery to
fit more models.

I'm trying to fit a model of this sort where F[t] contains a linear
regression term, and having some difficulty with optimisation. (Brian
Ripley has noted that parameter estimation is more difficult in this
models than is generally realised).

	-thomas



From Timur.Elzhov at jinr.ru  Wed Feb 12 17:18:03 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Wed Feb 12 17:18:03 2003
Subject: [R] `UNPROTECT' and `return'
Message-ID: <20030212162051.GA29001@pcf004.jinr.ru>

Dear R experts,

In all R functions written in C one must unprotect
result before returning them:

  {
      ...
      UNPROTECT(1)  /* unprotecting `ans' */

      return ans;
  }

Why does one shure that memory occupied by `ans'
won't be used by R immediately after unprotecting?

Ok, is the next construction also absolutely safe?
  {
      ...
      UNPROTECT(1)  /* unprotecting `ans' */

      PROTECT( val = ans )
      ...
  }

Thanks a lot!


--
WBR,
Timur.



From pgilbert at bank-banque-canada.ca  Wed Feb 12 17:22:04 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed Feb 12 17:22:04 2003
Subject: [R] Dynamic Linear Models for Times Series - Implemented?
References: <000a01c2d297$e2fc37b0$4c202880@gsimpson>
Message-ID: <3E4A741A.DA7FBD9@bank-banque-canada.ca>

Gavin

I am not familiar with the two texts you mention that define DLM, but I think
since at least twenty years prior to those texts, the term has been used to mean
the state-space model you describe, and also ARMA models, transfer function
models, and possibly some other representations of linear models in time series
(and continuous time too, which is not always consider time series). 

There are several packages on CRAN that implement ARMA and/or state-space
models, including my dse (Dynamic Systems Estimation) which handles both
multivariate ARMA and the state-space model you describe. For estimation
purposes I would suggest you consider the innovations form state-space model
rather than the non-innovations form you have indicated. If you use the
non-innovations form you will need to worry much more about identification
problems.

Paul Gilbert

Gavin Simpson wrote:
> 
> Hi,
> 
> Following an off-list reply to my original post, I realised that I hadn't
> really provided very much information for you to work with.  So here's a
> second attempt:
> 
> Following West & Harrison (1989) and Pole et al. (1994) a DLM is defined as:
> 
> Y[t] = F'[t]theta[t] + v[t],    v[t] ~ N[0,V] #Observation equation
> theta[t] = G[t]theta[t-1] + w[t],  w[t] ~ N[0,W] #system equation
> 
> The system equation is a first order Markov process, where G[t] is a matrix
> of known coefficients that defines the systematic evolution of the state
> vector (theta[t]) across time, and w[t] is an unobservable stochastic error
> term having a normal distribution with zero mean and covariance matrix.
> 
> Y[t] denotes the observation series at time t
> F[t] is a vector of known constants (the regression vector)
> theta[t] denotes the vector of model state parameters
> v[t] is a stochastic error term having zero mean and variance V[t]
> 
> If I have understood Brockwell and Davis (1991) correctly, the DLM can be
> considered from the point of view of State-space models (although I am
> venturing some way out of my statistical depth here, all the papers I have
> collected are applied examples and they all refer to dynamic Linear Models,
> not State-space models).
> 
> It seems that some of this has been done in S (for S-Plus), as I found the
> bts package by Harrison and Reed on StatLib
> (http://lib.stat.cmu.edu/DOS/S/),
> 
> "SPLUS for Windows functions and datasets for Bayesian forecasting based on
> the algorithms in Bayesian Forecasting and Dynamic Linear Models by West and
> Harrison"
> 
> So I was wondering whether anyone knew of existing R code that could fit
> such models?
> 
> Many thanks
> 
> Gavin Simpson
> 
> Refs:
> Brockwell and Davis (1991).  Time Series: Theory and Methods.  Springer
> Pole, West and Harrison (1994).  Applied Bayesian Forecasting and Time
> Series Analysis.  Chapman & Hall/CRC
> West and Harrison (1989).  Bayesian Forecasting and Dynamic Models.
> Springer
> 
> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch [mailto:r-help-admin at stat.math.ethz.ch]
> On Behalf Of Gavin Simpson
> Sent: 11 February 2003 17:49
> To: r-help
> Subject: [R] Dynamic Linear Models for Times Series - Implemented?
> 
> Hi,
> 
> I was wondering whether a package that can perform dynamic linear models on
> times series data was available for R?
> 
> Many Thanks,
> 
> Gavin Simpson
> 
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Gavin Simpson                     [T] +44 (0)20 7679 5522
> ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
> UCL Department of Geography
> 26 Bedford Way
> London.  WC1H 0AP.
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Wed Feb 12 17:26:10 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb 12 17:26:10 2003
Subject: [R] `UNPROTECT' and `return'
In-Reply-To: <20030212162051.GA29001@pcf004.jinr.ru>
Message-ID: <Pine.LNX.4.44.0302121622520.14589-100000@gannet.stats>

This _is_ covered in `Writing R Extensions'.  What is unsafe is to allow a 
gc to occur.

On Wed, 12 Feb 2003, Timur Elzhov wrote:

> In all R functions written in C one must unprotect
> result before returning them:
> 
>   {
>       ...
>       UNPROTECT(1)  /* unprotecting `ans' */
> 
>       return ans;
>   }
> 
> Why does one shure that memory occupied by `ans'
> won't be used by R immediately after unprotecting?
> 
> Ok, is the next construction also absolutely safe?
>   {
>       ...
>       UNPROTECT(1)  /* unprotecting `ans' */
> 
>       PROTECT( val = ans )
>       ...
>   }

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rolf at math.unb.ca  Wed Feb 12 17:32:03 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed Feb 12 17:32:03 2003
Subject: [R] rbind.data.frame: character comverted to factor
Message-ID: <200302121631.MAA13189@gelfand.math.unb.ca>

Brian Ripley wrote:

> d1 <- data.frame(id=I(letters[1:20]), x = runif(20))
> d2 <- data.frame(id=I(paste(letters[1:20],letters[1:20],sep="")),
>                   x=rexp(20))
> d3 <- rbind(d1, d2)
> 
> which of course works!

Why ``of course''?  It seems to me that there is no ``of course''
about it.  It is completely counter-intuitive.  What appears
to be going on is that the I() operator NOT ONLY puts its argument
into the data frame ``as is'', but it ALSO tacks a class ``AsIs''
onto that argument which prevents it from being mucked around with
thereafter.

This is a neat trick, but is fairly mysterious --- and could have
intricate ramifications.  How can one discern all the impacts of
an object's having ``AsIs'' as a class?  (It would appear that
objects of any structure and class can ``inherit from'' AsIs.)

It would be highly preferable not to have to use the I() operator, or
the ``AsIs'' class at all.  I.e. to have character vectors stay
character vectors unless the user explicitly asks them to be
converted to factors.  However Splus introduced the contrary policy
years ago, and R is stuck with it for compatibility reasons.


					cheers,

						Rolf Turner
						rolf at math.unb.ca



From kjetil at entelnet.bo  Wed Feb 12 17:50:06 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed Feb 12 17:50:06 2003
Subject: [R] Poesia
Message-ID: <3E4A428D.17534.2F3A45@localhost>

Hola!

Sorry for going off-topic, but here are
something I found on the web 
yesterday - an explanation of 
statistics in poetic form:



             First, you see your data for what they seem to be
     Then, you ask them for the truth  - are you what you seem to me?

You see with broad expanse
       you ask with narrowed power
       you see and ask and see
   and ask and see...    and ask

With brush you paint the possibilities
     with pen you scribe the probabilities

For in pictures we find insight
    while in numbers we find strengt


(author is probably Forrest Young)

Kjetil Halvorsen



From tvargas at cisco.com  Wed Feb 12 19:24:02 2003
From: tvargas at cisco.com (Tony Vargas)
Date: Wed Feb 12 19:24:02 2003
Subject: [R] Three questions - loading(sourcing a file??), summaries to bitmaps,
 and error messages
Message-ID: <Pine.GSO.4.44.0302121003370.10987-100000@tvargas-u10.cisco.com>

R helpers,

I have three questions about R and was wondering if I could get some help.

First, I am trying to send the output of a a summary command -
summary("info") to a bitmap file instead of the default device.  Anybody
know how to send a summary to a bitmap device?

Second - this question is more difficult.  What I am trying to do is have
Perl (because I already have the data structures loaded into
hashes) generate a gigantic R file that I can then have R source, and then
parse.  The output of the file(s) that I generate is below:




my.badger.Sep.2002.cpu.utilization <-
read.table(file="/auto/solperf/tgu/ActiveParsedFiles/badger/Sep.2002/cpu.utilization",
sep="=", header=TRUE) names(my.badger.Sep.2002.cpu.utilization)
attach(my.badger.Sep.2002.cpu.utilization) Tony Vargas Cisco Systems
Engineering Computing Services (408) 525-4113 tvargas at cisco.com
my.balvenie.Sep.2002.cpu.utilization <-
read.table(file="/auto/solperf/tgu/ActiveParsedFiles/balvenie/Sep.2002/cpu.utilization",
sep="=", header=TRUE) names(my.balvenie.Sep.2002.cpu.utilization)
attach(my.balvenie.Sep.2002.cpu.utilization)
my.bobcat.Sep.2002.cpu.utilization <-
read.table(file="/auto/solperf/tgu/ActiveParsedFiles/bobcat/Sep.2002/cpu.utilization",
sep="=", header=TRUE) names(my.bobcat.Sep.2002.cpu.utilization)
attach(my.bobcat.Sep.2002.cpu.utilization)
my.bowmore.Sep.2002.cpu.utilization <-
read.table(file="/auto/solperf/tgu/ActiveParsedFiles/bowmore/Sep.2002/cpu.utilization",
sep="=", header=TRUE) names(my.bowmore.Sep.2002.cpu.utilization)
attach(my.bowmore.Sep.2002.cpu.utilization)

etc. . . .

My "plotting" file looks like this:

bitmap(file =
"/auto/solperf/tgu/Images/badger.Sep.2002.usr.cpu.summary.thumbnail", type
= "png256", height = 6, width = 6, res = 72")
summary(my.badger.Sep.2002.cpu.utilization) bitmap(file =
"/auto/solperf/tgu/Images/badger.Sep.2002.usr.cpu.lines.thumbnail", type =
"png256", height = 6, width = 6, res = 72")
 lines(usr.cpu ~ Time, xlab = "Time", ylab = "%Usr CPU Utilization", main
= "badger's %Usr CPU Utilization Sep.2002")
 legend(0,0, usr.cpu) bitmap(file =
"/auto/solperf/tgu/Images/badger.Sep.2002.usr.cpu.scatter.thumbnail", type
= "png256", height = 6, width = 6, res = 72")
 plot(usr.cpu, main = "Scatter plot of badger's %Usr CPU Utilization
Sep.2002")
 legend(0,0, usr.cpu) bitmap(file =
"/auto/solperf/tgu/Images/badger.Sep.2002.usr.cpu.summary.large", type =
"png256",


I tried having R do a "load" on my files, but I get the error messages
below:

> load("rgraphfileload")
Error: bad restore file magic number (file may be corrupted)-- no data
loaded

Any idea why I would get the message above?  I am using R version 1.6.1 on
a Solaris host.

Thanks,

Tony



From tkt2 at cdc.gov  Wed Feb 12 19:38:03 2003
From: tkt2 at cdc.gov (Thompson, Trevor)
Date: Wed Feb 12 19:38:03 2003
Subject: [R] Various Errors using Survey Package
Message-ID: <2414774BEDB1D611B89900034772AF2B38B21C@mcdc-atl-66.nccd.cdc.gov>

Hi,

I have been experimenting with the new Survey package.  Specifically, I was
trying to use some of the functions on the public-use survey data from NHIS
(2000 Sample Adult file).  

Error 1):  The first error I get is when I try to specify the complex survey
design.

nhis.design<-svydesign(ids=~psu, probs=~probs, strata=~strata, data=nhis.df,
check.strata=TRUE)
Error in svydesign(ids = ~psu, probs = ~probs, strata = ~strata, data =
nhis.df,  : 
        Clusters not nested in strata

My data are sorted by strata, psu.  Can someone tell me what the structure
has to be for a stratified sample with clustering?  Looking at the code, it
appears to me that it does not allow more than 1 observation per psu [i.e.
any(sc > 1)].

Error 2).  If I go ahead and specify check.strata=FALSE, then svydesign runs
ok.  I then tried using the svymean function.  In the following example, if
I specify na.rm=TRUE, I get the error below:

> svymean(nhis.df$crc10yr, design=nhis.design, na.rm=TRUE)
Error in rowsum.default(x, strata) : Incorrect length for 'group'

I traced this to the svyCprod call within svymean.   SvyCprod calls rowsum
and the group argument ("strata") appears to be the full length of that
column rather than the subset with non-missing data.  

Error 3).  I then tried svymean on another variable with na.rm=FALSE.  I got
the following error:

> svymean(nhis.df$age, design=nhis.design)
Error in drop(rval) : names attribute must be the same length as the vector 

I also traced this error to a call to rowsum within the function svyCprod.
I'm not sure what names attribute this is referring to because the arguments
to rowsum and the rval object do not appear to have a names attribute.  Does
anyone know what the problem here might be?

Has anyone else used the survey package on public-use survey datasets like
BRFSS or NHIS?  Was there anything special you had to do to those datasets
before specifying the survey design?  I know that's a pretty vague question.
If any of you are SUDAAN users, I basically mean does it have to be
structured differently that what you pass into a SUDAAN procedure.

Thanks in advance for any suggestions!  I am using R 1.6.2 on Windows 2000.

-Trevor



From sugnet at soe.ucsc.edu  Wed Feb 12 20:12:03 2003
From: sugnet at soe.ucsc.edu (Charles Sugnet)
Date: Wed Feb 12 20:12:03 2003
Subject: [R] Debugging in R
Message-ID: <Pine.LNX.4.44.0302121105450.5327-100000@quack.cse.ucsc.edu>

Hello *,

Is it possible in R to set breakpoints and conditional breakpoints in the
browser mode? I've discovered "debug()" to debug functions, but I find
stepping throw loops or having to go back and put in "browse()" calls a
little tedious. I would really like to be able to set a breakpoint while
in the browser mode. Can anyone tell me how to do this? Any other pointers
to useful debugging tutorials/howtos in R would be greatly appreciated.

Thanks,
-Chuck Sugnet
http://www.cse.ucsc.edu/~sugnet/



From yuelin at mail.med.upenn.edu  Wed Feb 12 21:42:03 2003
From: yuelin at mail.med.upenn.edu (Yuelin Li)
Date: Wed Feb 12 21:42:03 2003
Subject: [R] rl_callback_read_char error on Solaris 7
Message-ID: <200302122041.h1CKfks28909@pandora.outcomes.chop.edu>

This question is about compiling R-1.6.2 from source on a 
Sparcstation-20 machine running Solaris 7, gcc-2.95.3 and 
readline-4.2 (both gcc and readline from sunfreeware.com).  

I searched the r-help archive and the FAQ.  The errors seem to be 
related to the binary readline libraries, and I have 
/usr/local/lib/libreadline.a,libreadline.so@, and 
libreadline.so.4.

The attached errors are from config.log.  ./configure finds 
readline header files in /usr/local/include/readline.  I can make 
and install R, but command line editing and savehistory() do not 
work.   

Suggestions are appreciated.

Yuelin Li.

--------
configure:11366: checking for rl_callback_read_char in -lreadline
configure:11397: gcc -o conftest -g -O2 -I/usr/local/include 
-L/usr/local/lib conftest.c -lreadline  -ldl -lncurses -lm  >&5
ld: fatal: symbol `_init' is multiply-defined:
        (file 
/usr/local/lib/gcc-lib/sparc-sun-solaris2.7/2.95.3/crti.o and 
file /usr/local/lib/libreadline.so);
ld: fatal: symbol `_start' is multiply-defined:
        (file 
/usr/local/lib/gcc-lib/sparc-sun-solaris2.7/2.95.3/crt1.o and 
file /usr/local/lib/libreadline.so);
ld: fatal: symbol `_fini' is multiply-defined:
        (file 
/usr/local/lib/gcc-lib/sparc-sun-solaris2.7/2.95.3/crti.o and 
file /usr/local/lib/libreadline.so);
ld: fatal: symbol `_lib_version' is multiply-defined:
        (file /usr/ccs/lib/values-Xa.o and file 
/usr/local/lib/libreadline.so);
ld: fatal: File processing errors. No output written to conftest
collect2: ld returned 1 exit status
configure:11400: $? = 1
configure: failed program was:
| #line 11373 "configure"
| /* confdefs.h.  */
| 
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "r"| #define PACKAGE_VERSION "1.6.2"
| #define PACKAGE_STRING "R 1.6.2"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "1.6.2"
| #define R_PLATFORM "sparc-sun-solaris2.7"
| #define R_CPU "sparc"
| #define R_VENDOR "sun"
| #define R_OS "solaris2.7"
| #define Unix 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define HAVE_LIBM 1
| #define HAVE_LIBNCURSES 1
| #define HAVE_LIBDL 1
| /* end confdefs.h.  */
| 
| /* Override any gcc2 internal prototype to avoid an error.  */
| #ifdef __cplusplus
| extern "C"
| #endif
| /* We use char because int might match the return type of a 
gcc2
|    builtin and then its argument prototype would still apply.  
*/
| char rl_callback_read_char ();
| int
| main ()
| {
| rl_callback_read_char ();
|   ;
|   return 0;
| }



From timothysharac at mybluelight.com  Wed Feb 12 21:50:13 2003
From: timothysharac at mybluelight.com (Tim Sharac)
Date: Wed Feb 12 21:50:13 2003
Subject: [R] Matrix formatting
Message-ID: <20030212204208.16932.qmail@confucius.synacor.com>

Hi R-users:

I have a data formatting question. I have a data set that looks something like this:

foo.dat <- cbind(c(NA, 1, 2, 3, 4, 5), c(NA, NA, 0, 10 ,20, 30))

What I have:

     [,1] [,2]
[1,]   NA   NA
[2,]    1   NA
[3,]    2    0
[4,]    3   10
[5,]    4   20
[6,]    5   30


I want to line up the columns by the first value that is not NA. Like so:

     [,1] [,2]
[1,]    1   0
[2,]    2   10
[3,]    3   20
[4,]    4   30
[5,]    5   NA
[6,]    NA  NA

Question is: Is there an elegant way to do this without a for loop?

I tried doing this with na.omit and na.exclude without success.

The real data is many hundreds of columns and many thousands of rows.

Thanks in advance, Tim

Sign up for Internet Service under $10 dollars a month, at http://isp.BlueLight.com



From p.dalgaard at biostat.ku.dk  Wed Feb 12 21:54:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Feb 12 21:54:04 2003
Subject: [R] Three questions - loading(sourcing a file??), summaries to bitmaps, and error messages
In-Reply-To: <Pine.GSO.4.44.0302121003370.10987-100000@tvargas-u10.cisco.com>
References: <Pine.GSO.4.44.0302121003370.10987-100000@tvargas-u10.cisco.com>
Message-ID: <x2isvpxlx3.fsf@biostat.ku.dk>

Tony Vargas <tvargas at cisco.com> writes:

> R helpers,
> 
> I have three questions about R and was wondering if I could get some help.
> 
> First, I am trying to send the output of a a summary command -
> summary("info") to a bitmap file instead of the default device.  Anybody
> know how to send a summary to a bitmap device?

Eh? Bitmap as in GIF/JPEG/... or what? Print to file is sink() if
that's what you mean. You can also sink() to a text connection and use
text() to put that on the graphics display (ruins tabular output, though).
 
> Second - this question is more difficult.  What I am trying to do is have
> Perl (because I already have the data structures loaded into
> hashes) generate a gigantic R file that I can then have R source, and then
> parse.  The output of the file(s) that I generate is below:

> 
> my.badger.Sep.2002.cpu.utilization <-
> read.table(file="/auto/solperf/tgu/ActiveParsedFiles/badger/Sep.2002/cpu.utilization",
> sep="=", header=TRUE) names(my.badger.Sep.2002.cpu.utilization)
> attach(my.badger.Sep.2002.cpu.utilization) Tony Vargas Cisco Systems
> Engineering Computing Services (408) 525-4113 tvargas at cisco.com
> my.balvenie.Sep.2002.cpu.utilization <-
> read.table(file="/auto/solperf/tgu/ActiveParsedFiles/balvenie/Sep.2002/cpu.utilization",
> sep="=", header=TRUE) names(my.balvenie.Sep.2002.cpu.utilization)
> attach(my.balvenie.Sep.2002.cpu.utilization)

You seem to need semicolons or \n mefore names(...) I assume that your
address got in there with the aid of your emailer, not the Perl script?


> I tried having R do a "load" on my files, but I get the error messages
> below:
> 
> > load("rgraphfileload")
> Error: bad restore file magic number (file may be corrupted)-- no data
> loaded
> 
> Any idea why I would get the message above?  I am using R version 1.6.1 on
> a Solaris host.

load() is for binary files made by save() or save.image(). Were you
looking for source()?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Wed Feb 12 22:04:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb 12 22:04:03 2003
Subject: [R] rl_callback_read_char error on Solaris 7
In-Reply-To: <200302122041.h1CKfks28909@pandora.outcomes.chop.edu>
Message-ID: <Pine.LNX.4.44.0302122059310.28000-100000@gannet.stats>

On Wed, 12 Feb 2003, Yuelin Li wrote:

> This question is about compiling R-1.6.2 from source on a 
> Sparcstation-20 machine running Solaris 7, gcc-2.95.3 and 
> readline-4.2 (both gcc and readline from sunfreeware.com).  

This is not an R question, but one for the maintainers of sunfreeware.com.
There is no problem with those tools if compiled from the sources 
(although they are rather old versions).

> I searched the r-help archive and the FAQ.  The errors seem to be 
> related to the binary readline libraries, and I have 
> /usr/local/lib/libreadline.a,libreadline.so@, and 
> libreadline.so.4.
> 
> The attached errors are from config.log.  ./configure finds 
> readline header files in /usr/local/include/readline.  I can make 
> and install R, but command line editing and savehistory() do not 
> work.   
> 
> Suggestions are appreciated.

Compile libreadline yourself?

> 
> Yuelin Li.
> 
> --------
> configure:11366: checking for rl_callback_read_char in -lreadline
> configure:11397: gcc -o conftest -g -O2 -I/usr/local/include 
> -L/usr/local/lib conftest.c -lreadline  -ldl -lncurses -lm  >&5
> ld: fatal: symbol `_init' is multiply-defined:
>         (file 
> /usr/local/lib/gcc-lib/sparc-sun-solaris2.7/2.95.3/crti.o and 
> file /usr/local/lib/libreadline.so);
> ld: fatal: symbol `_start' is multiply-defined:
>         (file 
> /usr/local/lib/gcc-lib/sparc-sun-solaris2.7/2.95.3/crt1.o and 
> file /usr/local/lib/libreadline.so);
> ld: fatal: symbol `_fini' is multiply-defined:
>         (file 
> /usr/local/lib/gcc-lib/sparc-sun-solaris2.7/2.95.3/crti.o and 
> file /usr/local/lib/libreadline.so);
> ld: fatal: symbol `_lib_version' is multiply-defined:
>         (file /usr/ccs/lib/values-Xa.o and file 
> /usr/local/lib/libreadline.so);

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jerome at hivnet.ubc.ca  Wed Feb 12 22:07:23 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed Feb 12 22:07:23 2003
Subject: [R] Matrix formatting
In-Reply-To: <20030212204208.16932.qmail@confucius.synacor.com>
References: <20030212204208.16932.qmail@confucius.synacor.com>
Message-ID: <200302122108.NAA20435@hivnet.ubc.ca>

Would this do what you want?

Cheers,
Jerome

> foo.dat <- cbind(c(NA, 1, 2, 3, 4, 5), c(NA, NA, 0, 10 ,20, 30))
> apply(foo.dat,2,function(x) x[order(as.logical(x))])
     [,1] [,2]
[1,]    1    0
[2,]    2   10
[3,]    3   20
[4,]    4   30
[5,]    5   NA
[6,]   NA   NA


On Wednesday 12 February 2003 12:42, Tim Sharac wrote:
> Content-Length: 918
> Status: R
> X-Status: N
>
> Hi R-users:
>
> I have a data formatting question. I have a data set that looks something
> like this:
>
> foo.dat <- cbind(c(NA, 1, 2, 3, 4, 5), c(NA, NA, 0, 10 ,20, 30))
>
> What I have:
>
>      [,1] [,2]
> [1,]   NA   NA
> [2,]    1   NA
> [3,]    2    0
> [4,]    3   10
> [5,]    4   20
> [6,]    5   30
>
>
> I want to line up the columns by the first value that is not NA. Like so:
>
>      [,1] [,2]
> [1,]    1   0
> [2,]    2   10
> [3,]    3   20
> [4,]    4   30
> [5,]    5   NA
> [6,]    NA  NA
>
> Question is: Is there an elegant way to do this without a for loop?
>
> I tried doing this with na.omit and na.exclude without success.
>
> The real data is many hundreds of columns and many thousands of rows.
>
> Thanks in advance, Tim
>
> Sign up for Internet Service under $10 dollars a month, at
> http://isp.BlueLight.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From r.hankin at auckland.ac.nz  Wed Feb 12 22:11:09 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Wed Feb 12 22:11:09 2003
Subject: [R] R CMD check .
In-Reply-To: <3E4A428D.17534.2F3A45@localhost> (kjetil@entelnet.bo)
References: <3E4A428D.17534.2F3A45@localhost>
Message-ID: <200302122109.h1CL9QZ5030805@r.hankin.sges.auckland.ac.nz>

Hello everybody

I'm writing a package and am trying to get it past "R CMD check ."  It
has no C or Fortan code, just R code.

"R CMD check ."  reports that the examples don't work:


r:Davies% R CMD check .
* checking for working latex ... OK
* using log directory '/home/rksh/information/Davies/Davies.Rcheck'


[deleted]

* checking for code/documentation mismatches ... OK
* checking for undocumented arguments in \usage ... OK
* checking for CRLF line endings in C sources/headers ... OK
* creating Davies-Ex.R ... OK
* checking examples ... ERROR
Running examples failed.
r:Davies%

Everything works fine with "R CMD check --no-example ."  

How do I tell which .Rd file is the problem?  (I suspect that the
examples aren't actually being executed because most of them take a
long time and the error is pretty much instantaneous).



Any clues?  


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042



From rpeng at stat.ucla.edu  Wed Feb 12 22:14:26 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed Feb 12 22:14:26 2003
Subject: [R] Matrix formatting
In-Reply-To: <20030212204208.16932.qmail@confucius.synacor.com>
Message-ID: <Pine.GSO.4.10.10302121308580.19088-100000@quetelet.stat.ucla.edu>

Is

apply(foo.dat, 2, sort, na.last = TRUE)

what you want?

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On 12 Feb 2003, Tim Sharac wrote:

> Hi R-users:
> 
> I have a data formatting question. I have a data set that looks something like this:
> 
> foo.dat <- cbind(c(NA, 1, 2, 3, 4, 5), c(NA, NA, 0, 10 ,20, 30))
> 
> What I have:
> 
>      [,1] [,2]
> [1,]   NA   NA
> [2,]    1   NA
> [3,]    2    0
> [4,]    3   10
> [5,]    4   20
> [6,]    5   30
> 
> 
> I want to line up the columns by the first value that is not NA. Like so:
> 
>      [,1] [,2]
> [1,]    1   0
> [2,]    2   10
> [3,]    3   20
> [4,]    4   30
> [5,]    5   NA
> [6,]    NA  NA
> 
> Question is: Is there an elegant way to do this without a for loop?
> 
> I tried doing this with na.omit and na.exclude without success.
> 
> The real data is many hundreds of columns and many thousands of rows.
> 
> Thanks in advance, Tim
> 
> Sign up for Internet Service under $10 dollars a month, at http://isp.BlueLight.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jerome at hivnet.ubc.ca  Wed Feb 12 22:18:04 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed Feb 12 22:18:04 2003
Subject: [R] Matrix formatting
In-Reply-To: <200302122108.NAA20435@hivnet.ubc.ca>
References: <20030212204208.16932.qmail@confucius.synacor.com> <200302122108.NAA20435@hivnet.ubc.ca>
Message-ID: <200302122116.NAA20790@hivnet.ubc.ca>

Sorry, this is probably better if you want to preserve the order of the 
numbers in each column.

apply(foo.dat,2,function(x) x[order(is.na(x))])

Jerome

On Wednesday 12 February 2003 13:05, Jerome Asselin wrote:
> Would this do what you want?
>
> Cheers,
> Jerome
>
> > foo.dat <- cbind(c(NA, 1, 2, 3, 4, 5), c(NA, NA, 0, 10 ,20, 30))
> > apply(foo.dat,2,function(x) x[order(as.logical(x))])
>
>      [,1] [,2]
> [1,]    1    0
> [2,]    2   10
> [3,]    3   20
> [4,]    4   30
> [5,]    5   NA
> [6,]   NA   NA
>
> On Wednesday 12 February 2003 12:42, Tim Sharac wrote:
> > Content-Length: 918
> > Status: R
> > X-Status: N
> >
> > Hi R-users:
> >
> > I have a data formatting question. I have a data set that looks something
> > like this:
> >
> > foo.dat <- cbind(c(NA, 1, 2, 3, 4, 5), c(NA, NA, 0, 10 ,20, 30))
> >
> > What I have:
> >
> >      [,1] [,2]
> > [1,]   NA   NA
> > [2,]    1   NA
> > [3,]    2    0
> > [4,]    3   10
> > [5,]    4   20
> > [6,]    5   30
> >
> >
> > I want to line up the columns by the first value that is not NA. Like so:
> >
> >      [,1] [,2]
> > [1,]    1   0
> > [2,]    2   10
> > [3,]    3   20
> > [4,]    4   30
> > [5,]    5   NA
> > [6,]    NA  NA
> >
> > Question is: Is there an elegant way to do this without a for loop?
> >
> > I tried doing this with na.omit and na.exclude without success.
> >
> > The real data is many hundreds of columns and many thousands of rows.
> >
> > Thanks in advance, Tim
> >
> > Sign up for Internet Service under $10 dollars a month, at
> > http://isp.BlueLight.com
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 

Jerome Asselin (J?r?me)
Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital
608 - 1081 Burrard Street
Vancouver, British Columbia
CANADA V6Z 1Y6

Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044



From d.scott at auckland.ac.nz  Wed Feb 12 22:22:04 2003
From: d.scott at auckland.ac.nz (David Scott)
Date: Wed Feb 12 22:22:04 2003
Subject: [R] R CMD check .
In-Reply-To: <200302122109.h1CL9QZ5030805@r.hankin.sges.auckland.ac.nz>
Message-ID: <Pine.SOL.4.21.0302131016470.6402-100000@stat1.stat.auckland.ac.nz>

On Thu, 13 Feb 2003, Robin Hankin wrote:

> Hello everybody
> 
> I'm writing a package and am trying to get it past "R CMD check ."  It
> has no C or Fortan code, just R code.
> 
> "R CMD check ."  reports that the examples don't work:
> 
> 
> r:Davies% R CMD check .
> * checking for working latex ... OK
> * using log directory '/home/rksh/information/Davies/Davies.Rcheck'
> 
> 
> [deleted]
> 
> * checking for code/documentation mismatches ... OK
> * checking for undocumented arguments in \usage ... OK
> * checking for CRLF line endings in C sources/headers ... OK
> * creating Davies-Ex.R ... OK
> * checking examples ... ERROR
> Running examples failed.
> r:Davies%
> 
> Everything works fine with "R CMD check --no-example ."  
> 
> How do I tell which .Rd file is the problem?  (I suspect that the
> examples aren't actually being executed because most of them take a
> long time and the error is pretty much instantaneous).
> 
Rcmd check makes a directory called libname.Rcheck. Inside that you will
find a .Rout file which gives a log of the examples. If I understand the
pattern it is called libname-Ed.Rout.

Look at that file to see where the running of your examples failed.

David Scott 
_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
		The University of Auckland, PB 92019
		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz 

Webmaster, New Zealand Statistical Association:
        http://www.stat.auckland.ac.nz/nzsa/



From macq at llnl.gov  Wed Feb 12 22:25:19 2003
From: macq at llnl.gov (Don MacQueen)
Date: Wed Feb 12 22:25:19 2003
Subject: [R] rl_callback_read_char error on Solaris 7
In-Reply-To: <Pine.LNX.4.44.0302122059310.28000-100000@gannet.stats>
References: <Pine.LNX.4.44.0302122059310.28000-100000@gannet.stats>
Message-ID: <p05200f15ba7069da651a@[128.115.153.6]>

At 9:03 PM +0000 2/12/03, ripley at stats.ox.ac.uk wrote:
>On Wed, 12 Feb 2003, Yuelin Li wrote:
>
>>  This question is about compiling R-1.6.2 from source on a
>>  Sparcstation-20 machine running Solaris 7, gcc-2.95.3 and
>>  readline-4.2 (both gcc and readline from sunfreeware.com). 
>
>This is not an R question, but one for the maintainers of sunfreeware.com.
>There is no problem with those tools if compiled from the sources
>(although they are rather old versions).
>
>>  I searched the r-help archive and the FAQ.  The errors seem to be
>>  related to the binary readline libraries, and I have
>>  /usr/local/lib/libreadline.a,libreadline.so@, and
>>  libreadline.so.4.
>>
>>  The attached errors are from config.log.  ./configure finds
>>  readline header files in /usr/local/include/readline.  I can make
>>  and install R, but command line editing and savehistory() do not
>>  work.  
>>
>>  Suggestions are appreciated.
>
>Compile libreadline yourself?

That is what I had to do.
I first tried a version from sunfreeware.com, without success.
(Also for png and jpeg support, though the pre-compiled versions may 
not have come from sunfreeware; I do not remember.)

>
>>
>>  Yuelin Li.
>>
>>  --------
>>  configure:11366: checking for rl_callback_read_char in -lreadline
>>  configure:11397: gcc -o conftest -g -O2 -I/usr/local/include
>>  -L/usr/local/lib conftest.c -lreadline  -ldl -lncurses -lm  >&5
>>  ld: fatal: symbol `_init' is multiply-defined:
>>          (file
>>  /usr/local/lib/gcc-lib/sparc-sun-solaris2.7/2.95.3/crti.o and
>>  file /usr/local/lib/libreadline.so);
>>  ld: fatal: symbol `_start' is multiply-defined:
>>          (file
>>  /usr/local/lib/gcc-lib/sparc-sun-solaris2.7/2.95.3/crt1.o and
>>  file /usr/local/lib/libreadline.so);
>>  ld: fatal: symbol `_fini' is multiply-defined:
>>          (file
>>  /usr/local/lib/gcc-lib/sparc-sun-solaris2.7/2.95.3/crti.o and
>>  file /usr/local/lib/libreadline.so);
>>  ld: fatal: symbol `_lib_version' is multiply-defined:
>>          (file /usr/ccs/lib/values-Xa.o and file
>  > /usr/local/lib/libreadline.so);
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------



From jgentry at jimmy.harvard.edu  Wed Feb 12 22:30:04 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Wed Feb 12 22:30:04 2003
Subject: [R] R CMD check .
In-Reply-To: <200302122109.h1CL9QZ5030805@r.hankin.sges.auckland.ac.nz>
Message-ID: <Pine.SOL.4.20.0302121618540.1066-100000@santiam.dfci.harvard.edu>

> * checking for CRLF line endings in C sources/headers ... OK
> * creating Davies-Ex.R ... OK
> * checking examples ... ERROR
> Running examples failed.
> r:Davies%
> How do I tell which .Rd file is the problem?  (I suspect that the
> examples aren't actually being executed because most of them take a
> long time and the error is pretty much instantaneous).

You should have a directory named <pkgName>.Rcheck, inside of that there
should be a file <pkgname>-Ex.Rout .... that should give you a clue as to
what is happening (it is the R output from the examples running).

-Jeff



From d.scott at auckland.ac.nz  Wed Feb 12 22:34:57 2003
From: d.scott at auckland.ac.nz (David Scott)
Date: Wed Feb 12 22:34:57 2003
Subject: [R] R CMD check .
In-Reply-To: <Pine.SOL.4.21.0302131016470.6402-100000@stat1.stat.auckland.ac.nz>
Message-ID: <Pine.SOL.4.21.0302131026080.6402-100000@stat1.stat.auckland.ac.nz>

Sorry, there was a typo in my answer:

On Thu, 13 Feb 2003, David Scott wrote:
.
.
.
lots of stuff cut
.
.

> > examples aren't actually being executed because most of them take a
> > long time and the error is pretty much instantaneous).
> > 
> Rcmd check makes a directory called libname.Rcheck. Inside that you will
> find a .Rout file which gives a log of the examples. If I understand the
> pattern it is called libname-Ed.Rout.
> 
                                ^
Make that libname-Ex.Rout

David Scott

_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
		The University of Auckland, PB 92019
		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz 

Webmaster, New Zealand Statistical Association:
        http://www.stat.auckland.ac.nz/nzsa/



From p.dalgaard at biostat.ku.dk  Wed Feb 12 23:06:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Feb 12 23:06:03 2003
Subject: [R] rl_callback_read_char error on Solaris 7
In-Reply-To: <200302122041.h1CKfks28909@pandora.outcomes.chop.edu>
References: <200302122041.h1CKfks28909@pandora.outcomes.chop.edu>
Message-ID: <x2el6dxif4.fsf@biostat.ku.dk>

Yuelin Li <yuelin at mail.med.upenn.edu> writes:

> This question is about compiling R-1.6.2 from source on a 
> Sparcstation-20 machine running Solaris 7, gcc-2.95.3 and 
> readline-4.2 (both gcc and readline from sunfreeware.com).  

I had some problems with the sunfreeware readline too when I tried 1.5
years ago. Ended up removing the .so version.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Mark.Wilkinson at stjude.org  Thu Feb 13 00:27:03 2003
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Thu Feb 13 00:27:03 2003
Subject: [R] legend
Message-ID: <A1DAD6685C12D511B20F00034725151380CE75@sjmemexc3.stjude.org>

I think I'm missing something tonight in the usage of 'legend':

plot(0, type="n")
legend(locator(1), month.abb[1:5], pch=15, col=1:5)

gives me something similar to what I want. But

legend(locator(1), month.abb[1:5], fill=T, col=1:5)

gives me 5 black boxes.

What am I doing wrong?

Thank you, 


> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.1
year     2002
month    11
day      01
language R


Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences

The opinions expressed here are my own and do not necessarily represent
those of St. Jude Children's Research Hospital.



From r.hankin at auckland.ac.nz  Thu Feb 13 00:34:03 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Thu Feb 13 00:34:03 2003
Subject: [R] R CMD check .
In-Reply-To: 
	<Pine.SOL.4.21.0302131026080.6402-100000@stat1.stat.auckland.ac.nz>
	(message from David Scott on Thu, 13 Feb 2003 10:27:50 +1300 (NZDT))
References: <Pine.SOL.4.21.0302131026080.6402-100000@stat1.stat.auckland.ac.nz>
Message-ID: <200302122333.h1CNXfuq000347@r.hankin.sges.auckland.ac.nz>

Hello everybody 

thanks for your help with my R CMD check problem.  The file
Davies-Ex.Rout does indeed contain a transcript of the examples.

I've found the .Rd file that contains the problem.  The relevant
command executes perfectly when I cut-and-paste it onto the R command
line, but not when executed by R CMD check.  How can this be?

[tail of Davies-Ex.Rout included below]

The first four lines work fine (including a function listing) but the
final line "least.squares(rdavies(100,params))" fails, apparently
because the is.sorted argument doesn't take its default value of
FALSE.  Anyone got any ideas as to why not?


robin


r:Davies.Rcheck% tail -27 Davies-Ex.Rout
> ##___ Examples ___:
>
> params <- c(10,0.1,-0.1)
> rdavies(n=5,params)
[1] 10.367054  9.068977  9.409128  8.326713  9.885775
> ddavies(10,params)
[1] 0.25
> least.squares
function (data, print = FALSE, is.sorted = FALSE, start.v = NULL)
{
    if (is.sorted == FALSE) {
        data <- sort(data)
    }
    if (is.null(start.v)) {
        start.v <- start.davies(data)
    }
    jj <- optim(start.v, objective, dataset = data, is.sorted = TRUE)
    if (print != TRUE) {
        return(jj$par)
    }
    else {
        return(list(parameters = jj$par, error = jj$value))
    }
}
> least.squares(rdavies(100,params))
Error in if (is.sorted == FALSE) { : missing value where logical needed
Execution halted
r:Davies.Rcheck%


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042



From hedderik at cmu.edu  Thu Feb 13 00:51:03 2003
From: hedderik at cmu.edu (Hedderik van Rijn)
Date: Thu Feb 13 00:51:03 2003
Subject: [R] legend
In-Reply-To: <A1DAD6685C12D511B20F00034725151380CE75@sjmemexc3.stjude.org>
Message-ID: <C4F8748B-3EE4-11D7-85A6-000393678426@cmu.edu>

> legend(locator(1), month.abb[1:5], fill=T, col=1:5)
>
> gives me 5 black boxes.

Try:

legend(locator(1), month.abb[1:5], fill=1:5)

> What am I doing wrong?

The "T" is interpreted as (equal to?) a "1", so you're requesting the 
boxes to be filled with color 1, which is black.

  - Hedderik.



From naumov at buffalo.edu  Thu Feb 13 00:55:06 2003
From: naumov at buffalo.edu (Aleksey Y Naumov)
Date: Thu Feb 13 00:55:06 2003
Subject: [R] legend
In-Reply-To: <A1DAD6685C12D511B20F00034725151380CE75@sjmemexc3.stjude.org>
Message-ID: <Pine.GSO.4.05.10302121850090.6459-100000@hercules.acsu.buffalo.edu>

Try:

legend(locator(1), month.abb[1:5], fill=1:5)

'col' takes care of the color of points and lines.

Aleksey

On Wed, 12 Feb 2003, Wilkinson, Mark wrote:

> 
> I think I'm missing something tonight in the usage of 'legend':
> 
> plot(0, type="n")
> legend(locator(1), month.abb[1:5], pch=15, col=1:5)
> 
> gives me something similar to what I want. But
> 
> legend(locator(1), month.abb[1:5], fill=T, col=1:5)
> 
> gives me 5 black boxes.
> 
> What am I doing wrong?
> 
> Thank you, 
> 
> 
> > version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    6.1
> year     2002
> month    11
> day      01
> language R
> 
> 
> Mark Wilkinson
> Informatics Analyst
> St. Jude Children's Research Hospital
> Department of Pharmaceutical Sciences
> 
> The opinions expressed here are my own and do not necessarily represent
> those of St. Jude Children's Research Hospital.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From emb7 at st-andrews.ac.uk  Thu Feb 13 00:58:18 2003
From: emb7 at st-andrews.ac.uk (emb7@st-andrews.ac.uk)
Date: Thu Feb 13 00:58:18 2003
Subject: [R] sorting in lmList object
Message-ID: <1045093967.3e4ade4fa829a@webmail.st-andrews.ac.uk>

Hi all,
Forgive me if this is an obvious one....
I want to make a plot of confidence intervals from an lmList object with a 
collection of simple linear models (lm(y~x)) using:

plot(intervals(mylmList))

and sort the plot by increasing mean values for the intercept. Is there an easy 
way of doing this? I've tried the "order()" and "sort.list()" functions, but I 
suspect they only work for data frames? Can I sort directly when plotting, or 
do I have to sort the whole lmList object?

Thanks!

Martin




------------------------------------------------------
Sent through WebMail: http://webmail.st-andrews.ac.uk/



From Ngayee.Law at celeradiagnostics.com  Thu Feb 13 02:13:02 2003
From: Ngayee.Law at celeradiagnostics.com (Ngayee J Law)
Date: Thu Feb 13 02:13:02 2003
Subject: [R] k- means cluster analysis
Message-ID: <OF9A33E239.102F634C-ON88256CCC.00063D87@pe-c.com>

Hi all,

I am trying to run the k-means cluster analysis using the function kmeans
in the package cluster.
The data are:
x = c(-0.26, -0.23, -0.05, -0.20,  0.30, -0.84, -0.10, -0.12,  0.10, -0.31,
-0.19,  0.18, -0.26,
      -0.23, -0.37, -0.23)
I've got two different solutions when I ran this function over a few times:
kmeans(x, centers=2)

The first solution gives the following:
$cluster
 [1] 2 2 1 2 1 2 2 2 1 2 2 1 2 2 2 2
$centers
        [,1]
1  0.1325000
2 -0.2783333
$withinss
[1] 0.0646750 0.4033667
$size
[1]  4 12

The second solution gives the following:
$cluster
 [1] 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
$centers
        [,1]
1 -0.1313333
2 -0.8400000
$withinss
[1] 0.5035733 0.0000000
$size
[1] 15  1

I don't understand why this is happening, and how do I choose between the
two solutions. Also, how can I ensure
consistent solution over times? Thanks a lot!

- Jacqueline



From tlumley at u.washington.edu  Thu Feb 13 02:50:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Feb 13 02:50:03 2003
Subject: [R] Various Errors using Survey Package
In-Reply-To: <2414774BEDB1D611B89900034772AF2B38B21C@mcdc-atl-66.nccd.cdc.gov>
Message-ID: <Pine.A41.4.44.0302121728070.206860-100000@homer01.u.washington.edu>

On Wed, 12 Feb 2003, Thompson, Trevor wrote:

> Hi,
>
> I have been experimenting with the new Survey package.  Specifically, I was
> trying to use some of the functions on the public-use survey data from NHIS
> (2000 Sample Adult file).
>
> Error 1):  The first error I get is when I try to specify the complex survey
> design.
>
> nhis.design<-svydesign(ids=~psu, probs=~probs, strata=~strata, data=nhis.df,
> check.strata=TRUE)
> Error in svydesign(ids = ~psu, probs = ~probs, strata = ~strata, data =
> nhis.df,  :
>         Clusters not nested in strata
>
> My data are sorted by strata, psu.  Can someone tell me what the structure
> has to be for a stratified sample with clustering?  Looking at the code, it
> appears to me that it does not allow more than 1 observation per psu [i.e.
> any(sc > 1)].

  The problem is probably that your id numbers for PSU start up again in
each stratum (eg you have a PSU numbered 1 in each stratum).  If so, you
need the nest=TRUE option to tell svydesign() that all the PSUs numbered 1
in different strata are really different PSUs


> Error 2).  If I go ahead and specify check.strata=FALSE, then svydesign runs
> ok.  I then tried using the svymean function.  In the following example, if
> I specify na.rm=TRUE, I get the error below:

No, it doesn't run ok, it just doesn't report an error.

> > svymean(nhis.df$crc10yr, design=nhis.design, na.rm=TRUE)
> Error in rowsum.default(x, strata) : Incorrect length for 'group'
>
> I traced this to the svyCprod call within svymean.   SvyCprod calls rowsum
> and the group argument ("strata") appears to be the full length of that
> column rather than the subset with non-missing data.

With missing data you do need to use the data stored in the design object,
not a separate data frame, otherwise it will get confused. That is, you
want
  svymean(~crc10yr, design=nhis.design, na.rm=TRUE)


> Error 3).  I then tried svymean on another variable with na.rm=FALSE.  I got
> the following error:
>
> > svymean(nhis.df$age, design=nhis.design)
> Error in drop(rval) : names attribute must be the same length as the vector
>
> I also traced this error to a call to rowsum within the function svyCprod.
> I'm not sure what names attribute this is referring to because the arguments
> to rowsum and the rval object do not appear to have a names attribute.  Does
> anyone know what the problem here might be?

This might be the same problem, in which case
    svymean(~age, design=nhis.design)
should work.  You should also make sure you have version 1.0 of `survey'
rather than any of them 0.9-x versions that went up briefly on CRAN.

If you tell me where to find the NHIS data I will look at them. There
shouldn't be any special requirements on the format (other than using
nest=TRUE if PSUs don't have globally unique ids).  I've looked at data
from some NCHS studies that are used as examples by Stata, and I don't
have any of these problems.

Incidentally, you should try writing to the package maintainer first,
rather than the list. In this case it doesn't matter, since I read the
list frequently, but it might in other cases.

	-thomas



From sundar.dorai-raj at pdf.com  Thu Feb 13 03:46:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu Feb 13 03:46:03 2003
Subject: [R] k- means cluster analysis
References: <OF9A33E239.102F634C-ON88256CCC.00063D87@pe-c.com>
Message-ID: <3E4B067E.40605@pdf.com>


Ngayee J Law wrote:
> Hi all,
> 
> I am trying to run the k-means cluster analysis using the function kmeans
> in the package cluster.
> The data are:
> x = c(-0.26, -0.23, -0.05, -0.20,  0.30, -0.84, -0.10, -0.12,  0.10, -0.31,
> -0.19,  0.18, -0.26,
>       -0.23, -0.37, -0.23)
> I've got two different solutions when I ran this function over a few times:
> kmeans(x, centers=2)
> 
> The first solution gives the following:
> $cluster
>  [1] 2 2 1 2 1 2 2 2 1 2 2 1 2 2 2 2
> $centers
>         [,1]
> 1  0.1325000
> 2 -0.2783333
> $withinss
> [1] 0.0646750 0.4033667
> $size
> [1]  4 12
> 
> The second solution gives the following:
> $cluster
>  [1] 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
> $centers
>         [,1]
> 1 -0.1313333
> 2 -0.8400000
> $withinss
> [1] 0.5035733 0.0000000
> $size
> [1] 15  1
> 
> I don't understand why this is happening, and how do I choose between the
> two solutions. Also, how can I ensure
> consistent solution over times? Thanks a lot!
> 
> - Jacqueline
> 

 From the help page for `kmeans':

  centers: Either the number of clusters or a set of initial cluster
           centers. If the first, a random set of rows in `x' are chosen
           as the initial centers.

If you want the same results try supplying an initial center, as in:

kmeans(x, centers = c(0.1, -0.2))

However, choosing bad starting values could cause kmeans to crash, as in:

kmeans(x, centers = c(0, 0))

Regards,
Sundar



From saurav at sas.upenn.edu  Thu Feb 13 03:53:02 2003
From: saurav at sas.upenn.edu (Saurav Pathak)
Date: Thu Feb 13 03:53:02 2003
Subject: [R] multi-color plot
Message-ID: <20030213024607.GA23781@mail1.sas.upenn.edu>

hi all,

i am trying to make multi-color plots.  that is, i generally use,

	plot(x, y, type="n")
	text(x, y, labels=class)

here, the vector class denotes the class of each point.  there are
usually 3-4 classes of points.  how may i display the different
classes in different colors?

thanks for any help.

-- 
saurav



From sundar.dorai-raj at pdf.com  Thu Feb 13 04:09:02 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu Feb 13 04:09:02 2003
Subject: [R] multi-color plot
References: <20030213024607.GA23781@mail1.sas.upenn.edu>
Message-ID: <3E4B0C0A.7040704@pdf.com>


Saurav Pathak wrote:
> hi all,
> 
> i am trying to make multi-color plots.  that is, i generally use,
> 
> 	plot(x, y, type="n")
> 	text(x, y, labels=class)
> 
> here, the vector class denotes the class of each point.  there are
> usually 3-4 classes of points.  how may i display the different
> classes in different colors?
> 

Use the col argument in text, as in:

R> plot(x=1:26,y=rep(0:1,13),type="n")
R> text(x=1:26,y=0.5,labels=letters,col=terrain.colors(26))
R>

where terrain.colors(26) is:

R> terrain.colors(26)
  [1] "#00A600" "#0EAB00" "#1DB000"
  [4] "#2DB600" "#3EBB00" "#50C000"
  [7] "#63C600" "#76CB00" "#8BD000"
[10] "#A0D600" "#B6DB00" "#CEE000"
[13] "#E6E600" "#E6D612" "#E7C924"
[16] "#E8BF36" "#E9B848" "#EAB35A"
[19] "#EBB16D" "#ECB27F" "#EDB592"
[22] "#EEBCA5" "#EFC5B8" "#F0D1CB"
[25] "#F1E0DF" "#F2F2F2"

Also, I would avoid using `class' as a variable name since it has a 
special definition in R.


Hope this helps,
Sundar



From saurav at sas.upenn.edu  Thu Feb 13 04:43:09 2003
From: saurav at sas.upenn.edu (Saurav Pathak)
Date: Thu Feb 13 04:43:09 2003
Subject: [R] multi-color plot
In-Reply-To: <3E4B0C0A.7040704@pdf.com>
References: <20030213024607.GA23781@mail1.sas.upenn.edu> <3E4B0C0A.7040704@pdf.com>
Message-ID: <20030213034244.GA25584@mail1.sas.upenn.edu>



Thus spake Sundar Dorai-Raj:

+  R> plot(x=1:26,y=rep(0:1,13),type="n")
+  R> text(x=1:26,y=0.5,labels=letters,col=terrain.colors(26))

now i get it.  what i am doing now is:

R> mycol <- cls
R> mycol[mycol==0] <- "red"
R> mycol[mycol==1] <- "blue"
R> mycol[mycol==2] <- "green"
R> plot(x, y, type="n")
R> text(x, y, labels=cls, col=mycol)

which is exactly what i wanted.

thanks!!
saurav



From f0z6305 at labs.tamu.edu  Thu Feb 13 05:00:06 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu Feb 13 05:00:06 2003
Subject: [R] Urgent Help on Cumulant computation on two R.V's
Message-ID: <030401c2d314$3e8d4ed0$8bd75ba5@IE.TAMU.EDU>

Hey

Now I am going to check the independence of random variables using cumulant
function.

So if R has such package or functions to calculate
the sample cumulant of a random vector?

Thanks a lot.

Fred



From ripley at stats.ox.ac.uk  Thu Feb 13 07:47:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb 13 07:47:03 2003
Subject: [R] k- means cluster analysis
In-Reply-To: <3E4B067E.40605@pdf.com>
Message-ID: <Pine.LNX.4.44.0302130640570.30949-100000@gannet.stats>

On Wed, 12 Feb 2003, Sundar Dorai-Raj wrote:

> Ngayee J Law wrote:
> > Hi all,
> > 
> > I am trying to run the k-means cluster analysis using the function kmeans
> > in the package cluster.

I think it's the one in package mva.

[...]

> However, choosing bad starting values could cause kmeans to crash, as in:
> 
> kmeans(x, centers = c(0, 0))

Really?  That does not crash here, but correctly reports an error message:

> kmeans(x, c(0,0))
Error in switch(Z$ifault, stop("empty cluster: try a better set of initial 
centers"),  : 
        empty cluster: try a better set of initial centers

If you actually have a crash, please report to R-bugs.

There is an increasing trend for people to describe informative error 
messages describing their errors as `crashes', but that is confusing at 
best.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gisar at nus.edu.sg  Thu Feb 13 08:21:04 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Thu Feb 13 08:21:04 2003
Subject: [R] Interpolation
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053F02@MBXSRV03.stf.nus.edu.sg>

Here is another way of doing it:

x <- c(1990, 1994, 1995, 1997)
all.x <- seq(min(x), max(x))
complementary.x <- setdiff(all.x, x)



-----Original Message-----
From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at pdf.com] 
Sent: Wednesday, February 12, 2003 9:39 PM
To: Remigijus Lapinskas
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Interpolation




Remigijus Lapinskas wrote:
> Many thanks to all who replied to my e-mail. My problem was that I had

> not known about the approx function.
> 
> By the way, if I have  x <- c(1990,1994,1995,1997), is there an 
> automated way to fill in the gaps, i.e., to get 
> c(1991,1992,1993,1996)?
> 

Try this:

R> x <- c(1990, 1994, 1995, 1997)
R> all.x <- seq(min(x), max(x))
R> missing.x <- all.x[!all.x %in% x]
R> missing.x
[1] 1991 1992 1993 1996
R>

Regards,
Sundar

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gisar at nus.edu.sg  Thu Feb 13 08:43:04 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Thu Feb 13 08:43:04 2003
Subject: [R] Matrix formatting
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F206@MBXSRV03.stf.nus.edu.sg>

I do something like this as part of a missing value plot where I 'flush'
the rows with most missing spots to the bottom and the columns with the
most missing values to the right. In this manner I can visually see how
much data I will retain (by looking at the area) if I decide to truncate
rows/columns by missing value criterion. You might find this code useful
in rearranging your matrix:

na.mat <- 1*is.na(data)                           
spots.na.per.row <- rowSums(na.mat)/ncol(data)    # calculates the
percentage missing by row
spots.na.per.column <- colSums(na.mat)/nrow(data)

data.re <- data[ order(spots.na.per.row), order(spots.na.per.column) ]



-----Original Message-----
From: Jerome Asselin [mailto:jerome at hivnet.ubc.ca] 
Sent: Thursday, February 13, 2003 5:06 AM
To: Tim Sharac; r-help at stat.math.ethz.ch
Subject: Re: [R] Matrix formatting



Would this do what you want?

Cheers,
Jerome

> foo.dat <- cbind(c(NA, 1, 2, 3, 4, 5), c(NA, NA, 0, 10 ,20, 30))
> apply(foo.dat,2,function(x) x[order(as.logical(x))])
     [,1] [,2]
[1,]    1    0
[2,]    2   10
[3,]    3   20
[4,]    4   30
[5,]    5   NA
[6,]   NA   NA


On Wednesday 12 February 2003 12:42, Tim Sharac wrote:
> Content-Length: 918
> Status: R
> X-Status: N
>
> Hi R-users:
>
> I have a data formatting question. I have a data set that looks 
> something like this:
>
> foo.dat <- cbind(c(NA, 1, 2, 3, 4, 5), c(NA, NA, 0, 10 ,20, 30))
>
> What I have:
>
>      [,1] [,2]
> [1,]   NA   NA
> [2,]    1   NA
> [3,]    2    0
> [4,]    3   10
> [5,]    4   20
> [6,]    5   30
>
>
> I want to line up the columns by the first value that is not NA. Like 
> so:
>
>      [,1] [,2]
> [1,]    1   0
> [2,]    2   10
> [3,]    3   20
> [4,]    4   30
> [5,]    5   NA
> [6,]    NA  NA
>
> Question is: Is there an elegant way to do this without a for loop?
>
> I tried doing this with na.omit and na.exclude without success.
>
> The real data is many hundreds of columns and many thousands of rows.
>
> Thanks in advance, Tim
>
> Sign up for Internet Service under $10 dollars a month, at 
> http://isp.BlueLight.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From thomas_chapuis at yahoo.fr  Thu Feb 13 09:36:03 2003
From: thomas_chapuis at yahoo.fr (=?iso-8859-1?q?thomas=20chapuis?=)
Date: Thu Feb 13 09:36:03 2003
Subject: [R] Distribution function of Kolmogorov Smirnov and Anderson Darling
Message-ID: <20030213083531.22768.qmail@web20421.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030213/03e1221c/attachment.pl

From lun_li at hotmail.com  Thu Feb 13 10:51:05 2003
From: lun_li at hotmail.com (lun li)
Date: Thu Feb 13 10:51:05 2003
Subject: [R] Function update problem
Message-ID: <BAY2-F7fRUqFTMZxDoW0001e73b@hotmail.com>

Dear all,

I am trying an automatic model selection for a multiple linear regression 
using function lm and update. But, I meet a problem when using update. The 
problem is the function update can not update when variables as a vector(for 
example,x is a matrix with 100 regression variables). The code is as below:

  > model<-lm(y~x1,singular.ok=T,na.action=na.omit)
  > for(i in 1:100){
  > model<-update(model,.~.+x[,i],singular.ok=T,na.action=na.omit)}

If the above code is represented as below, I can get the correct result. 
However, I must use the loops.

>model<-lm(y~x1,singular.ok=T,na.action=na.omit)
>model<-update(model,.~.+x[,1],singular.ok=T,na.action=na.omit)
>model<-update(model,.~.+x[,2],singular.ok=T,na.action=na.omit)
        ......
>model<-update(model,.~.+x[,100],singular.ok=T,na.action=na.omit)

Can anyone help?

Cheers,

Lun



From ripley at stats.ox.ac.uk  Thu Feb 13 11:03:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb 13 11:03:02 2003
Subject: [R] Function update problem
In-Reply-To: <BAY2-F7fRUqFTMZxDoW0001e73b@hotmail.com>
Message-ID: <Pine.LNX.4.44.0302130958230.2267-100000@gannet.stats>

You can use substitute: something like (untested)

for(i in 1:100){
    form <- substitute(.~.+x[,i], list(i=i))
    model <- update(model, form)
    ## do something useful in here
}
and you do not need to update unchanged arguments!

However, why are you rewriting add1.default, when there is add1.lm?

On Thu, 13 Feb 2003, lun li wrote:

> Dear all,
> 
> I am trying an automatic model selection for a multiple linear regression 
> using function lm and update. But, I meet a problem when using update. The 
> problem is the function update can not update when variables as a vector(for 
> example,x is a matrix with 100 regression variables). The code is as below:
> 
>   > model<-lm(y~x1,singular.ok=T,na.action=na.omit)
>   > for(i in 1:100){
>   > model<-update(model,.~.+x[,i],singular.ok=T,na.action=na.omit)}
> 
> If the above code is represented as below, I can get the correct result. 
> However, I must use the loops.
> 
> >model<-lm(y~x1,singular.ok=T,na.action=na.omit)
> >model<-update(model,.~.+x[,1],singular.ok=T,na.action=na.omit)
> >model<-update(model,.~.+x[,2],singular.ok=T,na.action=na.omit)
>         ......
> >model<-update(model,.~.+x[,100],singular.ok=T,na.action=na.omit)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Soren.Hojsgaard at agrsci.dk  Thu Feb 13 11:48:12 2003
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Thu Feb 13 11:48:12 2003
Subject: [R] Fax numbers
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0CC5E3@DJFPOST01.djf.agrsci.dk>

Hi !

I am trying to register. How to interpret the fax numer? Is it
+43 1 58801
or
+43 1 10798

I get a voice saying that these numbers do not exist?

Best
S?ren H?jsgaard

-----Oprindelig meddelelse-----
Fra: Friedrich.Leisch at ci.tuwien.ac.at
[mailto:Friedrich.Leisch at ci.tuwien.ac.at]
Sendt: 25. november 2002 19:29
Til: r-announce at stat.math.ethz.ch
Emne: Final CFP: DSC 2003




This is a short reminder that the submission deadline for the workshop
Distributed Statistical Computing DSC 2003 is approaching rapidly. If
you want to give a talk to the conference please submit a paper or
extended abstract (1-2 pages) by the end of this week. Details on the
workshop can be found at

	http://www.ci.tuwien.ac.at/Conferences/DSC-2003/

Best,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-announce mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._



From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Feb 13 11:59:02 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu Feb 13 11:59:02 2003
Subject: [R] Fax numbers
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0CC5E3@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0CC5E3@DJFPOST01.djf.agrsci.dk>
Message-ID: <Pine.LNX.4.51.0302131156500.22442@artemis.imbe.med.uni-erlangen.de>

> Hi !
>
> I am trying to register. How to interpret the fax numer? Is it
> +43 1 58801
> or
> +43 1 10798

hm, do you expect Vienna being a small village with only 5-digit telephone
numbers? ;-)

it is +43 1 58801 10798 ...

Torsten

>
> I get a voice saying that these numbers do not exist?
>
> Best
> S?ren H?jsgaard
>
> -----Oprindelig meddelelse-----
> Fra: Friedrich.Leisch at ci.tuwien.ac.at
> [mailto:Friedrich.Leisch at ci.tuwien.ac.at]
> Sendt: 25. november 2002 19:29
> Til: r-announce at stat.math.ethz.ch
> Emne: Final CFP: DSC 2003
>
>
>
>
> This is a short reminder that the submission deadline for the workshop
> Distributed Statistical Computing DSC 2003 is approaching rapidly. If
> you want to give a talk to the conference please submit a paper or
> extended abstract (1-2 pages) by the end of this week. Details on the
> workshop can be found at
>
> 	http://www.ci.tuwien.ac.at/Conferences/DSC-2003/
>
> Best,
>
> --
> -------------------------------------------------------------------
>                         Friedrich Leisch
> Institut f?r Statistik                     Tel: (+43 1) 58801 10715
> Technische Universit?t Wien                Fax: (+43 1) 58801 10798
> Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
> A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
> -------------------------------------------------------------------
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-
> r-announce mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From Ekkehardt.Altpeter at bag.admin.ch  Thu Feb 13 13:02:03 2003
From: Ekkehardt.Altpeter at bag.admin.ch (Ekkehardt.Altpeter@bag.admin.ch)
Date: Thu Feb 13 13:02:03 2003
Subject: [R] ESRI shape file import and time-space models
Message-ID: <D5542210BB281E4E94DCFF34A85D9BF9878CF8@bag015ex.bag.admin.ch>

Dear R user,

I am running R under Windows 2000.

 

I am looking for a routine for importing

 

-        shape files (ESRI) into R

-        dbase files (FOXPRO) into R

 

and I am looking for time-space models for description and prediction of
Bernoulli-, Binomial- and Poissonvaraibles.

 

Thank's a lot for a reply. 

 

Sincerely yours,

Ekkehardt Altpeter

Swiss Federal Office of Public Health.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20030213/a6ea5247/attachment.html

From dechwang at yahoo.co.uk  Thu Feb 13 13:39:03 2003
From: dechwang at yahoo.co.uk (=?iso-8859-1?q?dechao=20wang?=)
Date: Thu Feb 13 13:39:03 2003
Subject: [R] ROC
Message-ID: <20030213123812.14473.qmail@web40701.mail.yahoo.com>

Hi, can you advise me is there any ROC(Receiver
Operating Characteristic)analysis program in R?

Thanks,

Dechao

=====
Dechao Wang

Tel: (44) 01223 719718
Mob: (44) 07729 411134

__________________________________________________

Everything you'll ever need on one web page
from News and Sport to Email and Music Charts



From andy_liaw at merck.com  Thu Feb 13 13:52:02 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Feb 13 13:52:02 2003
Subject: [R] ROC
Message-ID: <3A822319EB35174CA3714066D590DCD534BC8F@usrymx25.merck.com>

Look for the ROC package on www.bioconductor.org.

Andy

> -----Original Message-----
> From: dechao wang [mailto:dechwang at yahoo.co.uk]
> Sent: Thursday, February 13, 2003 7:38 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] ROC
> 
> 
> Hi, can you advise me is there any ROC(Receiver
> Operating Characteristic)analysis program in R?
> 
> Thanks,
> 
> Dechao
> 
> =====
> Dechao Wang
> 
> Tel: (44) 01223 719718
> Mob: (44) 07729 411134
> 
> __________________________________________________
> 
> Everything you'll ever need on one web page
> from News and Sport to Email and Music Charts
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From tkt2 at cdc.gov  Thu Feb 13 14:13:03 2003
From: tkt2 at cdc.gov (Thompson, Trevor)
Date: Thu Feb 13 14:13:03 2003
Subject: [R] Various Errors using Survey Package
Message-ID: <2414774BEDB1D611B89900034772AF2B38B22A@mcdc-atl-66.nccd.cdc.gov>

Dr. Lumley,

Thanks for your response.  I want to point out that I did try using the
nest=TRUE option earlier and got the same error with svydesign.  I checked
and I was using version 0.9-1.  I have updated this to version 1.0 and I am
no longer getting an error.  

Your other suggestions work too of course.  Still, if you are interstested
in looking at the NHIS data, it is available at:

http://www.cdc.gov/nchs/nhis.htm 

Thanks again for your help.  I will first e-mail the package maintainer
directly in the future.

-Trevor
 
-----Original Message-----
From: Thomas Lumley [mailto:tlumley at u.washington.edu]
Sent: Wednesday, February 12, 2003 8:49 PM
To: Thompson, Trevor
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Various Errors using Survey Package


On Wed, 12 Feb 2003, Thompson, Trevor wrote:

> Hi,
>
> I have been experimenting with the new Survey package.  Specifically, I
was
> trying to use some of the functions on the public-use survey data from
NHIS
> (2000 Sample Adult file).
>
> Error 1):  The first error I get is when I try to specify the complex
survey
> design.
>
> nhis.design<-svydesign(ids=~psu, probs=~probs, strata=~strata,
data=nhis.df,
> check.strata=TRUE)
> Error in svydesign(ids = ~psu, probs = ~probs, strata = ~strata, data =
> nhis.df,  :
>         Clusters not nested in strata
>
> My data are sorted by strata, psu.  Can someone tell me what the structure
> has to be for a stratified sample with clustering?  Looking at the code,
it
> appears to me that it does not allow more than 1 observation per psu [i.e.
> any(sc > 1)].

  The problem is probably that your id numbers for PSU start up again in
each stratum (eg you have a PSU numbered 1 in each stratum).  If so, you
need the nest=TRUE option to tell svydesign() that all the PSUs numbered 1
in different strata are really different PSUs


> Error 2).  If I go ahead and specify check.strata=FALSE, then svydesign
runs
> ok.  I then tried using the svymean function.  In the following example,
if
> I specify na.rm=TRUE, I get the error below:

No, it doesn't run ok, it just doesn't report an error.

> > svymean(nhis.df$crc10yr, design=nhis.design, na.rm=TRUE)
> Error in rowsum.default(x, strata) : Incorrect length for 'group'
>
> I traced this to the svyCprod call within svymean.   SvyCprod calls rowsum
> and the group argument ("strata") appears to be the full length of that
> column rather than the subset with non-missing data.

With missing data you do need to use the data stored in the design object,
not a separate data frame, otherwise it will get confused. That is, you
want
  svymean(~crc10yr, design=nhis.design, na.rm=TRUE)


> Error 3).  I then tried svymean on another variable with na.rm=FALSE.  I
got
> the following error:
>
> > svymean(nhis.df$age, design=nhis.design)
> Error in drop(rval) : names attribute must be the same length as the
vector
>
> I also traced this error to a call to rowsum within the function svyCprod.
> I'm not sure what names attribute this is referring to because the
arguments
> to rowsum and the rval object do not appear to have a names attribute.
Does
> anyone know what the problem here might be?

This might be the same problem, in which case
    svymean(~age, design=nhis.design)
should work.  You should also make sure you have version 1.0 of `survey'
rather than any of them 0.9-x versions that went up briefly on CRAN.

If you tell me where to find the NHIS data I will look at them. There
shouldn't be any special requirements on the format (other than using
nest=TRUE if PSUs don't have globally unique ids).  I've looked at data
from some NCHS studies that are used as examples by Stata, and I don't
have any of these problems.

Incidentally, you should try writing to the package maintainer first,
rather than the list. In this case it doesn't matter, since I read the
list frequently, but it might in other cases.

	-thomas



From dray at biomserv.univ-lyon1.fr  Thu Feb 13 14:19:06 2003
From: dray at biomserv.univ-lyon1.fr (Stephane Dray)
Date: Thu Feb 13 14:19:06 2003
Subject: [R] ESRI shape file import and time-space models
In-Reply-To: <D5542210BB281E4E94DCFF34A85D9BF9878CF8@bag015ex.bag.admin.ch>
References: <D5542210BB281E4E94DCFF34A85D9BF9878CF8@bag015ex.bag.admin.ch>
Message-ID: <a05010400ba714a7af9cc@[134.214.32.69]>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030213/7b275c41/attachment.pl

From Robert.Espesser at lpl.univ-aix.fr  Thu Feb 13 14:36:03 2003
From: Robert.Espesser at lpl.univ-aix.fr (Robert Espesser)
Date: Thu Feb 13 14:36:03 2003
Subject: [R] search contrasts tutorial
Message-ID: <3E4BD61A.404860C@lpl.univ-aix.fr>

I'm looking for a tutorial or notes on the use of contrasts factor in 
linear model in R, 
I've  found  some mails and infos about in various documents about R,
but I've probably missed
a good review on this subject. 



-- 
Robert Espesser     
Laboratoire Parole et Langage  UMR 6057, CNRS
29 Av. Robert Schuman  13621 AIX    (FRANCE)
Tel: +33 (0)4 42 95 36 26   Fax: +33 (0)4 42 59 50 96
http://www.lpl.univ-aix.fr/~espesser
mailto:Robert.Espesser at lpl.univ-aix.fr



From ripley at stats.ox.ac.uk  Thu Feb 13 14:42:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb 13 14:42:02 2003
Subject: [R] search contrasts tutorial
In-Reply-To: <3E4BD61A.404860C@lpl.univ-aix.fr>
Message-ID: <Pine.LNX.4.44.0302131340130.12310-100000@gannet.stats>

Chapter 6 of MASS contains Bill Venables' tutorial dating back to 1993 or
so but still I believe unrivalled.

On Thu, 13 Feb 2003, Robert Espesser wrote:

> I'm looking for a tutorial or notes on the use of contrasts factor in 
> linear model in R, 
> I've  found  some mails and infos about in various documents about R,
> but I've probably missed
> a good review on this subject. 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Luis.Tito-de-Morais at ird.sn  Thu Feb 13 14:55:03 2003
From: Luis.Tito-de-Morais at ird.sn (Tito de Morais Luis)
Date: Thu Feb 13 14:55:03 2003
Subject: [R] search contrasts tutorial
In-Reply-To: <3E4BD61A.404860C@lpl.univ-aix.fr>
References: <3E4BD61A.404860C@lpl.univ-aix.fr>
Message-ID: <1045144312.7868.152.camel@rap6.ird.sn>

Hi,

Did you look at :

http://pbil.univ-lyon1.fr/R/enseignement.html

There is a huge list of statistical courses based on R. You may find
what you look for.

It's in French but this should not be a problem for you ;-)

HTH

L. Tito

Le jeu 13/02/2003 ? 17:30, Robert Espesser a ?crit :
> I'm looking for a tutorial or notes on the use of contrasts factor in 
> linear model in R, 
> I've  found  some mails and infos about in various documents about R,
> but I've probably missed
> a good review on this subject. 
-- 
L. Tito de Morais
      UR RAP
   IRD de Dakar
      BP1386
       Dakar
      S?n?gal

T?l: +221 849 33 31
Fax: +221 832 16 75
Courriel: tito at ird.sn



From JonesW at kssg.com  Thu Feb 13 15:05:03 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Thu Feb 13 15:05:03 2003
Subject: [R] RODBC
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE1FE5@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030213/3800c1fc/attachment.pl

From john_hendrickx at yahoo.com  Thu Feb 13 15:21:03 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Thu Feb 13 15:21:03 2003
Subject: [R] models for square tables
In-Reply-To: <D5EF2418-3E9C-11D7-A0F2-000393CD9F1A@nuffield.oxford.ac.uk>
Message-ID: <20030213142020.23210.qmail@web14201.mail.yahoo.com>

Labels can be helpful but can also cause messy output. In some of the
other functions, I added an option to suppress printing labels,
especially for symmetrical interactions.

A problem (in my view) with your approach is that it sorts the
categories according to the level names. I'd prefer the following,
which would make labels optional but otherwise maintain the original
order.

mob.qi <- function
(rowvar,colvar,constrained=FALSE,print.labels=FALSE) {
	check.square(rowvar,colvar)
	if (constrained) {
		qi <- ifelse(rowvar==colvar, 1, 0)
		nms<-c("diagonal")
	}
	else {
		qi <- ifelse(rowvar==colvar, rowvar, 0)
		nms<-levels(rowvar)
	}

	qi<-factor(qi)
	qi<-C(qi,contr.treatment,base=1)
	if (print.labels) {
		levels(qi)<-c("offdiag",nms)
	}
	qi
}

Thanks for your suggestions and for pointing out "relevel" to me!

John Hendrickx

--- David Firth <david.firth at nuffield.oxford.ac.uk> wrote:
> Nice.
> 
> I guess I normally do things a little bit differently, to get 
> coefficient names that look a bit more meaningful (eg avoiding
> numeric 
> codes for factor levels).
> 
> For example one possible adjustment to your code for the qi models 
> would be
> 
> mob.qi <- function(rowvar, colvar, constrained=FALSE) {
> 	check.square(rowvar, colvar)
> 	if (!constrained) {
> 		qi <- ifelse(rowvar==colvar, as.character(rowvar), "offdiag")
> 		relevel(factor(qi), "offdiag")
> 	} else qi <- ifelse(rowvar==colvar, 1, 0)
> }
> 
> immobile <- mob.qi(OccFather, OccSon)
> glm.qi2<-glm(Freq ~ OccFather + OccSon + immobile,
> family=poisson())
> 
> immobile <- mob.qi(OccFather, OccSon, constrained=T)
> glm.q02 <-glm(Freq ~ OccFather + OccSon + immobile,
> family=poisson())
> 
> Cheers,
> David
> 
> On Wednesday, Feb 12, 2003, at 13:01 Europe/London, John Hendrickx 
> wrote:
> 
> > I've posted a sample file for estimating loglinear models for
> square
> > tables (mobility models) at http://www.xs4all.nl/~jhckx/mcl/R/
> > Comments and suggestions are welcome.
> >
> > John Hendrickx
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>



From ernesto at ipimar.pt  Thu Feb 13 16:02:03 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu Feb 13 16:02:03 2003
Subject: [R] Cook's distance in lm (1.6.1 vs 1.6.2)
Message-ID: <1045148657.1286.46.camel@gandalf>

Hi

I found differences between the Cook's distance plot produced by R-1.6.1
and R-1.6.2, when analysing a linear model (lm).

This was allready identified ?

Regards

EJ



From jonathan.williams at pharmacology.oxford.ac.uk  Thu Feb 13 16:40:03 2003
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Thu Feb 13 16:40:03 2003
Subject: [R] (no subject)
Message-ID: <NGBBKJEMOMLJFCOIEGCEKELAJIAA.jonathan.williams@pharm.ox.ac.uk>

Dear R helpers,

I have a curious problem, which is that a program I have written in R
crashes R, unpredictably. When I say that the program crashes R, I mean
that it causes R to terminate, completely. But, the operating system
(Windows) continues OK.

The program loops around a randomForest regression. I am trying to use
randomForest to predict the diagnosis for a set of patients with dementia.
I have 140 patients, of whom 125 have one kind of dementia and 15 have
a different kind. We have measured about 50 variables for each patient.
The program repeatedly and randomly splits the 150 patients into 75:25 
groupings. Then it 'trains' the randomForest using the 75% grouping, then 
it 'predicts' the remaining 25% of cases. I save the predictions and at
the end compute a Receiver Operating Characteristic curve.

The program will work away happily for hours and will sometimes perform
as many as 100 cycles around the above loop. It gives quite nice results.
But, quite frequently, and unpredictably, it fails and R just stops. As I 
say, the operating system continues and any other programs that are multi-
tasking are unaffected.

If anyone could give me an idea on how to avoid this problem, I'd be
grateful.

Thanks,

Jonathan Williams


Jonathan Williams
OPTIMA
Radcliffe Infirmary
Woodstock Road
OXFORD OX2 6HE
Tel +1865 (2)24356



From tlumley at u.washington.edu  Thu Feb 13 16:55:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Feb 13 16:55:03 2003
Subject: [R] (no subject)
In-Reply-To: <NGBBKJEMOMLJFCOIEGCEKELAJIAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <Pine.A41.4.44.0302130747320.132968-100000@homer06.u.washington.edu>

On Thu, 13 Feb 2003, Jonathan Williams wrote:

> The program will work away happily for hours and will sometimes perform
> as many as 100 cycles around the above loop. It gives quite nice results.
> But, quite frequently, and unpredictably, it fails and R just stops. As I
> say, the operating system continues and any other programs that are multi-
> tasking are unaffected.
>
> If anyone could give me an idea on how to avoid this problem, I'd be
> grateful.

It sounds as though randomForest has a small bug in its C memory
management.  Unfortunately these can be quite hard to find and fix and
there isn't any straightforward way to work around them.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From kris.nackaerts at agr.kuleuven.ac.be  Thu Feb 13 17:02:03 2003
From: kris.nackaerts at agr.kuleuven.ac.be (Kris Nackaerts)
Date: Thu Feb 13 17:02:03 2003
Subject: [R] OO programming in R
Message-ID: <3E4BC14E.7030707@agr.kuleuven.ac.be>

Dear,

I'm looking for some examples on OO programming in R. I have the 
programming manual with explanation on UseMethod and NextMethod but I 
miss some practical examples to get me going (I hope). I searched the 
web but could not find  a good independent tutorial on this.

Any suggestions are welcome,

Kris


-- 
------------------------------------------------------------------------
 
 http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=krisn
 
------------------------------------------------------------------------
 Minds are like parachutes, they only work when open



From andy_liaw at merck.com  Thu Feb 13 17:06:04 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Feb 13 17:06:04 2003
Subject: [R] (no subject)
Message-ID: <3A822319EB35174CA3714066D590DCD534BC96@usrymx25.merck.com>

Jonathan,

Is there any possibility for you to send me the data, and/or the code?  I
and others have seen similar problems before, but not reproducible on the
current version, at least on the NT and Linux boxes that I have access to.
As Thomas said, it's difficult to nail these kinds of problems.  Having
reproducible data and code, at least, can help.  (It's no help that I'm no
expert in C...)

BTW, what version of the package are you using?  I've uploaded a version to
CRAN a week or two ago.

Cheers,
Andy

> -----Original Message-----
> From: Jonathan Williams
> [mailto:jonathan.williams at pharmacology.oxford.ac.uk]
> Sent: Thursday, February 13, 2003 10:52 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] (no subject)
> 
> 
> Dear R helpers,
> 
> I have a curious problem, which is that a program I have written in R
> crashes R, unpredictably. When I say that the program crashes 
> R, I mean
> that it causes R to terminate, completely. But, the operating system
> (Windows) continues OK.
> 
> The program loops around a randomForest regression. I am trying to use
> randomForest to predict the diagnosis for a set of patients 
> with dementia.
> I have 140 patients, of whom 125 have one kind of dementia and 15 have
> a different kind. We have measured about 50 variables for 
> each patient.
> The program repeatedly and randomly splits the 150 patients 
> into 75:25 
> groupings. Then it 'trains' the randomForest using the 75% 
> grouping, then 
> it 'predicts' the remaining 25% of cases. I save the 
> predictions and at
> the end compute a Receiver Operating Characteristic curve.
> 
> The program will work away happily for hours and will 
> sometimes perform
> as many as 100 cycles around the above loop. It gives quite 
> nice results.
> But, quite frequently, and unpredictably, it fails and R just 
> stops. As I 
> say, the operating system continues and any other programs 
> that are multi-
> tasking are unaffected.
> 
> If anyone could give me an idea on how to avoid this problem, I'd be
> grateful.
> 
> Thanks,
> 
> Jonathan Williams
> 
> 
> Jonathan Williams
> OPTIMA
> Radcliffe Infirmary
> Woodstock Road
> OXFORD OX2 6HE
> Tel +1865 (2)24356
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From bates at stat.wisc.edu  Thu Feb 13 17:09:53 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu Feb 13 17:09:53 2003
Subject: [R] sorting in lmList object
In-Reply-To: <1045093967.3e4ade4fa829a@webmail.st-andrews.ac.uk>
References: <1045093967.3e4ade4fa829a@webmail.st-andrews.ac.uk>
Message-ID: <6r1y2cb23y.fsf@bates4.stat.wisc.edu>

emb7 at st-andrews.ac.uk writes:

> Hi all,
> Forgive me if this is an obvious one....
> I want to make a plot of confidence intervals from an lmList object with a 
> collection of simple linear models (lm(y~x)) using:
> 
> plot(intervals(mylmList))
> 
> and sort the plot by increasing mean values for the intercept. Is there an easy 
> way of doing this? I've tried the "order()" and "sort.list()" functions, but I 
> suspect they only work for data frames? Can I sort directly when plotting, or 
> do I have to sort the whole lmList object?

I think the easiest way to do this would be to ensure that the
grouping factor that you pass to lmList is an ordered factor with the
desired ordering.  This may involve two passes through lmList - the
first to get the ordering and the second to create an lmList object
with the desired ordering.



From dgoliche at sclc.ecosur.mx  Thu Feb 13 17:14:03 2003
From: dgoliche at sclc.ecosur.mx (Duncan Goliche)
Date: Thu Feb 13 17:14:03 2003
Subject: [R] (no subject)
Message-ID: <000001c2d37b$23bc5b20$480ca8c0@sclc.ecosur.mx>

I have two routine tasks that I am wasting time over trying to solve. Can
anyone help?  I want to display the results of some geostatistical analysis
quickly in R before exporting back to GIS . Does anyone have a trick for
overlaying a polygon on an image of a krigging surface (prmat in spatial) in
such a way that the space outside the polygon is whited out (so I trim
within state boundaries)?  Also, has anyone got a function for converting
decimal degrees to UTM within R itself?

Thanks,

Duncan Golicher
Departamento de Ecolog?a y Sistem?tica Terrestre
El Colegio de la Frontera Sur
Carretera Panamericana y Perif?rico Sur s/n
C.P. 29290, San Crist?bal de Las Casas, Chiapas
Tel. (967) 81883 y 81884, ext. 5115, Fax (967) 82322
Email: dgoliche at sclc.ecosur.mx
Internet: http://www.ecosur.mx/bosques



From wolski at molgen.mpg.de  Thu Feb 13 17:26:03 2003
From: wolski at molgen.mpg.de (Wolski)
Date: Thu Feb 13 17:26:03 2003
Subject: [R] OO programming in R
In-Reply-To: <3E4BC14E.7030707@agr.kuleuven.ac.be>
References: <3E4BC14E.7030707@agr.kuleuven.ac.be>
Message-ID: <200302131725310179.01D6BB39@harry.molgen.mpg.de>

Hi Kris!
I am also looking for practical examples. I know that the bio conductor is written using the oo method package.
But I am still looking for some simple (without database interfaces and special file formats or sophisticated statistics) implementations using oo in R.
/Eryk

*********** REPLY SEPARATOR  ***********

On 2/13/2003 at 5:01 PM Kris Nackaerts wrote:

>Dear,
>
>I'm looking for some examples on OO programming in R. I have the 
>programming manual with explanation on UseMethod and NextMethod but I 
>miss some practical examples to get me going (I hope). I searched the 
>web but could not find  a good independent tutorial on this.
>
>Any suggestions are welcome,
>
>Kris
>
>
>-- 
>------------------------------------------------------------------------
> 
> http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=krisn
> 
>------------------------------------------------------------------------
> Minds are like parachutes, they only work when open
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help


Dipl. bio-chem. Eryk Witold Wolski     
MPI-MG Dep. Vertebrate Genomics      _ _
Ihnestrasse 73 14195 Berlin          'v'    
tel: 0049-30-84131285               /   \    
mail: wolski at molgen.mpg.de        ---W-W----



From sfalcon at fhcrc.org  Thu Feb 13 17:30:03 2003
From: sfalcon at fhcrc.org (Falcon, Seth)
Date: Thu Feb 13 17:30:03 2003
Subject: [R] OO programming in R
Message-ID: <9667A0D2033CD51195F90002B330A3BF0525F6FC@moe.fhcrc.org>

>  I'm looking for some examples on OO programming in R.

Me too!  Please share anything you find with the list.

+ seth



From rpeng at stat.ucla.edu  Thu Feb 13 17:35:04 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu Feb 13 17:35:04 2003
Subject: [R] OO programming in R
In-Reply-To: <3E4BC14E.7030707@agr.kuleuven.ac.be>
Message-ID: <Pine.GSO.4.10.10302130830270.29625-100000@quetelet.stat.ucla.edu>

You may want to look at the book "Programming with Data" by John Chambers,
which describes the new-style classes.  It has yet to fail me.  Also the
Bioconductor packages (http://www.bioconductor.org) use the new-style
class system and provide a good source of code examples (even if you're
not interested in bioinformatics).

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Thu, 13 Feb 2003, Kris Nackaerts wrote:

> Dear,
> 
> I'm looking for some examples on OO programming in R. I have the 
> programming manual with explanation on UseMethod and NextMethod but I 
> miss some practical examples to get me going (I hope). I searched the 
> web but could not find  a good independent tutorial on this.
> 
> Any suggestions are welcome,
> 
> Kris
> 
> 
> -- 
> ------------------------------------------------------------------------
>  
>  http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=krisn
>  
> ------------------------------------------------------------------------
>  Minds are like parachutes, they only work when open
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From rpeng at stat.ucla.edu  Thu Feb 13 17:39:04 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu Feb 13 17:39:04 2003
Subject: [R] OO programming in R
In-Reply-To: <200302131725310179.01D6BB39@harry.molgen.mpg.de>
Message-ID: <Pine.GSO.4.10.10302130836160.29625-100000@quetelet.stat.ucla.edu>

Smaller (and simpler?) examples include the `pixmap' package and my
`gpclib' package.  They both use the `methods' package.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Thu, 13 Feb 2003, Wolski wrote:

> Hi Kris! I am also looking for practical examples. I know that the bio
> conductor is written using the oo method package. But I am still
> looking for some simple (without database interfaces and special file
> formats or sophisticated statistics) implementations using oo in R.
> /Eryk
> 
> *********** REPLY SEPARATOR  ***********
> 
> On 2/13/2003 at 5:01 PM Kris Nackaerts wrote:
> 
> >Dear,
> >
> >I'm looking for some examples on OO programming in R. I have the 
> >programming manual with explanation on UseMethod and NextMethod but I 
> >miss some practical examples to get me going (I hope). I searched the 
> >web but could not find  a good independent tutorial on this.
> >
> >Any suggestions are welcome,
> >
> >Kris
> >
> >
> >-- 
> >------------------------------------------------------------------------
> > 
> > http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=krisn
> > 
> >------------------------------------------------------------------------
> > Minds are like parachutes, they only work when open
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> Dipl. bio-chem. Eryk Witold Wolski     
> MPI-MG Dep. Vertebrate Genomics      _ _
> Ihnestrasse 73 14195 Berlin          'v'    
> tel: 0049-30-84131285               /   \    
> mail: wolski at molgen.mpg.de        ---W-W----
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From rgentlem at jimmy.harvard.edu  Thu Feb 13 19:18:03 2003
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Thu Feb 13 19:18:03 2003
Subject: [R] OO programming in R
In-Reply-To: <Pine.GSO.4.10.10302130830270.29625-100000@quetelet.stat.ucla.edu>; from rpeng@stat.ucla.edu on Thu, Feb 13, 2003 at 08:34:35AM -0800
References: <3E4BC14E.7030707@agr.kuleuven.ac.be> <Pine.GSO.4.10.10302130830270.29625-100000@quetelet.stat.ucla.edu>
Message-ID: <20030213131722.C9665@jimmy.harvard.edu>

I have some notes and examples using S4 (for want of a better name)
at
http://biosun1.harvard.edu/courses/individual/bio271/
lectures 12 and 13 --
  Robert

On Thu, Feb 13, 2003 at 08:34:35AM -0800, Roger Peng wrote:
> You may want to look at the book "Programming with Data" by John Chambers,
> which describes the new-style classes.  It has yet to fail me.  Also the
> Bioconductor packages (http://www.bioconductor.org) use the new-style
> class system and provide a good source of code examples (even if you're
> not interested in bioinformatics).
> 
> -roger
> _______________________________
> UCLA Department of Statistics
> rpeng at stat.ucla.edu
> http://www.stat.ucla.edu/~rpeng
> 
> On Thu, 13 Feb 2003, Kris Nackaerts wrote:
> 
> > Dear,
> > 
> > I'm looking for some examples on OO programming in R. I have the 
> > programming manual with explanation on UseMethod and NextMethod but I 
> > miss some practical examples to get me going (I hope). I searched the 
> > web but could not find  a good independent tutorial on this.
> > 
> > Any suggestions are welcome,
> > 
> > Kris
> > 
> > 
> > -- 
> > ------------------------------------------------------------------------
> >  
> >  http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=krisn
> >  
> > ------------------------------------------------------------------------
> >  Minds are like parachutes, they only work when open
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20                            |
| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
+---------------------------------------------------------------------------+



From rengelho at ix.urz.uni-heidelberg.de  Thu Feb 13 19:47:06 2003
From: rengelho at ix.urz.uni-heidelberg.de (Ralf Engelhorn)
Date: Thu Feb 13 19:47:06 2003
Subject: [R] How to solve A'A=S for A ?
Message-ID: <Pine.A41.4.42.0302131926200.50926-100000@aixterm4.urz.uni-heidelberg.de>

Dear R helpers,

is there a function or way within R to solve A'A=S for A, where all
matrices have p x p order and S is a variance-covariance matrix?

Thank you,
Ralf Engelhorn



From sundar.dorai-raj at pdf.com  Thu Feb 13 19:56:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu Feb 13 19:56:03 2003
Subject: [R] How to solve A'A=S for A ?
References: <Pine.A41.4.42.0302131926200.50926-100000@aixterm4.urz.uni-heidelberg.de>
Message-ID: <3E4BEA06.5050308@pdf.com>


Ralf Engelhorn wrote:
> Dear R helpers,
> 
> is there a function or way within R to solve A'A=S for A, where all
> matrices have p x p order and S is a variance-covariance matrix?
> 
> Thank you,
> Ralf Engelhorn
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

See ?chol. Here's an example:

R> S = diag(4)
R> S[row(S) < col(S)] =
+  S[row(S) > col(S)] = 0.5
R> S
      [,1] [,2] [,3] [,4]
[1,]  1.0  0.5  0.5  0.5
[2,]  0.5  1.0  0.5  0.5
[3,]  0.5  0.5  1.0  0.5
[4,]  0.5  0.5  0.5  1.0
R> A = chol(S)
R> t(A) %*% A
      [,1] [,2] [,3] [,4]
[1,]  1.0  0.5  0.5  0.5
[2,]  0.5  1.0  0.5  0.5
[3,]  0.5  0.5  1.0  0.5
[4,]  0.5  0.5  0.5  1.0
R>

Sundar



From deleeuw at stat.ucla.edu  Thu Feb 13 20:00:03 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Thu Feb 13 20:00:03 2003
Subject: [R] How to solve A'A=S for A ?
In-Reply-To: <Pine.A41.4.42.0302131926200.50926-100000@aixterm4.urz.uni-heidelberg.de>
Message-ID: <C7BCC788-3F84-11D7-AEAE-000393BB6D36@stat.ucla.edu>

Use eigen() or any of the principal component analysis functions.

If K has eigenvectors and D has eigenvalues, then A'=KD^{1/2} is
a orthogonal solution, and A=A'=KD^{1/2}K' is a symmetric solution.

On Thursday, Feb 13, 2003, at 10:46 US/Pacific, Ralf Engelhorn wrote:

> Dear R helpers,
>
> is there a function or way within R to solve A'A=S for A, where all
> matrices have p x p order and S is a variance-covariance matrix?
>
> Thank you,
> Ralf Engelhorn
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------



From gregory_r_warnes at groton.pfizer.com  Thu Feb 13 20:04:04 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Thu Feb 13 20:04:04 2003
Subject: [R] search contrasts tutorial
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C5C7@groexmb02.pfizer.com>

You might also find the help pages for 'fit.contrasts', 'estimable', and
'glh.test' functions in the gregmisc library useful.

-Greg

> -----Original Message-----
> From: Tito de Morais Luis [mailto:Luis.Tito-de-Morais at ird.sn]
> Sent: Thursday, February 13, 2003 8:52 AM
> To: r-help at stat.math.ethz.ch
> Cc: Robert.Espesser at lpl.univ-aix.fr
> Subject: Re: [R] search contrasts tutorial
> 
> 
> Hi,
> 
> Did you look at :
> 
> http://pbil.univ-lyon1.fr/R/enseignement.html
> 
> There is a huge list of statistical courses based on R. You may find
> what you look for.
> 
> It's in French but this should not be a problem for you ;-)
> 
> HTH
> 
> L. Tito
> 
> Le jeu 13/02/2003 ? 17:30, Robert Espesser a ?crit :
> > I'm looking for a tutorial or notes on the use of contrasts 
> factor in 
> > linear model in R, 
> > I've  found  some mails and infos about in various 
> documents about R,
> > but I've probably missed
> > a good review on this subject. 
> -- 
> L. Tito de Morais
>       UR RAP
>    IRD de Dakar
>       BP1386
>        Dakar
>       S?n?gal
> 
> T?l: +221 849 33 31
> Fax: +221 832 16 75
> Courriel: tito at ird.sn
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From abunn at montana.edu  Thu Feb 13 20:08:13 2003
From: abunn at montana.edu (Andy Bunn)
Date: Thu Feb 13 20:08:13 2003
Subject: [R] Matrix formatting - reprise
In-Reply-To: <20030212204208.16932.qmail@confucius.synacor.com>
Message-ID: <000001c2d392$b8ab5f80$15a00ecf@simATE>

Given all these NA formatting replies - I have a question of my own.

I too have an object like foo.dat from the pervious posts:

foo.dat <- cbind(c(NA, 1, 2, 3, 4, 5), c(NA, NA, 0, 10 ,20, 30))

> foo.dat
     [,1] [,2]
[1,]   NA   NA
[2,]    1   NA
[3,]    2    0
[4,]    3   10
[5,]    4   20
[6,]    5   30


and I have vector I want to subtract from each column of foo.dat say:

foo.subtract <- c(0.1, 0.2, 0.3, 0.4, 0.5)

I want to perform the subtraction from foo.dat but preserve the
structure of the data. I.e.,

     [,1] [,2]
[1,]   NA   NA
[2,]  0.9   NA
[3,]  1.8 -0.1
[4,]  2.7  9.8
[5,]  3.6 19.7
[6,]  4.5 29.6

The final formatting of foo.dat has to be intact - I can't just shove
the NAs to the bottom. I tried to order the data in an apply function
but couldn't make it work.

Thanks, Andy


-----Original Message-----
From: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Tim Sharac
Sent: Wednesday, February 12, 2003 1:42 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Matrix formatting

Hi R-users:

I have a data formatting question. I have a data set that looks
something like this:

foo.dat <- cbind(c(NA, 1, 2, 3, 4, 5), c(NA, NA, 0, 10 ,20, 30))

What I have:

     [,1] [,2]
[1,]   NA   NA
[2,]    1   NA
[3,]    2    0
[4,]    3   10
[5,]    4   20
[6,]    5   30


I want to line up the columns by the first value that is not NA. Like
so:

     [,1] [,2]
[1,]    1   0
[2,]    2   10
[3,]    3   20
[4,]    4   30
[5,]    5   NA
[6,]    NA  NA

Question is: Is there an elegant way to do this without a for loop?

I tried doing this with na.omit and na.exclude without success.

The real data is many hundreds of columns and many thousands of rows.

Thanks in advance, Tim

Sign up for Internet Service under $10 dollars a month, at
http://isp.BlueLight.com

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Thu Feb 13 20:11:34 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb 13 20:11:34 2003
Subject: [R] How to solve A'A=S for A ?
In-Reply-To: <3E4BEA06.5050308@pdf.com>
Message-ID: <Pine.LNX.4.44.0302131903070.14714-100000@gannet.stats>

That will work if S is unambiguously positive definite, but covariance
matrices need not be, and then chol (without pivoting) will fail.
Pivoting can be used: see ?chol.

A more expensive but safer solution is to use eigen: see the code for 
mvrnorm.

On Thu, 13 Feb 2003, Sundar Dorai-Raj wrote:

> 
> 
> Ralf Engelhorn wrote:
> > Dear R helpers,
> > 
> > is there a function or way within R to solve A'A=S for A, where all
> > matrices have p x p order and S is a variance-covariance matrix?
> > 
> > Thank you,
> > Ralf Engelhorn
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> See ?chol. Here's an example:
> 
> R> S = diag(4)
> R> S[row(S) < col(S)] =
> +  S[row(S) > col(S)] = 0.5
> R> S
>       [,1] [,2] [,3] [,4]
> [1,]  1.0  0.5  0.5  0.5
> [2,]  0.5  1.0  0.5  0.5
> [3,]  0.5  0.5  1.0  0.5
> [4,]  0.5  0.5  0.5  1.0
> R> A = chol(S)
> R> t(A) %*% A
>       [,1] [,2] [,3] [,4]
> [1,]  1.0  0.5  0.5  0.5
> [2,]  0.5  1.0  0.5  0.5
> [3,]  0.5  0.5  1.0  0.5
> [4,]  0.5  0.5  0.5  1.0
> R>
> 
> Sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From f.calboli at ucl.ac.uk  Thu Feb 13 20:57:03 2003
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: Thu Feb 13 20:57:03 2003
Subject: [R] fixed and random effects in lme
Message-ID: <3.0.6.32.20030213200140.00a21318@pop-server.ucl.ac.uk>

Hi All,

I would like to ask a question on fixed and random effecti in lme. I am
fiddlying around Mick Crawley dataset "rats" :

http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/
 
The advantage is that most work is already done in Crawley's book (page 361
onwards) so I can check what I am doing.

I am tryg to reproduce the nested analysis on page 368:

model<-aov(Glycogen~Treatment/Rat/Liver + Error(Treatment/Rat/Liver), rats)

using lme.
The code: 

model1<- lme(Glycogen~Treatment, random = ~1|Rat/Liver, data=rats)
VarCorr(model1)

            Variance     StdDev  
Rat =       pdLogChol(1)         
(Intercept) 20.6019981   4.538942
Liver =     pdLogChol(1)         
(Intercept)  0.0540623   0.232513
Residual    42.4362241   6.514309

Does NOT give me the same variance componets I find in Crawley's book (page
371 onwards).
The code:

model2<- lme(Glycogen~Treatment, random = ~1|Treatment/Rat/Liver, data=rats)
VarCorr(model2)

 	Variance     StdDev  
Treatment = pdLogChol(1)         
(Intercept) 12.54061     3.541272
Rat =       pdLogChol(1)         
(Intercept) 36.07900     6.006580
Liver =     pdLogChol(1)         
(Intercept) 14.17434     3.764883
Residual    21.16227     4.600247


gets me very similar results (I would guess the differences are due to
rounding and the fact I am using R 1.6.2 and Crawley used S+).

My problem is: as *Treatment* is a fixed factor, why should I put it in
both the fixed term side and random terms side of my code to get the right
numbers? I fail to get this at all. Any elucidation would be appreciated.

Regards,

Federico Calboli



=========================

Federico C.F. Calboli

Department of Biology
University College London
Room 327
Darwin Building
Gower Street
London
WClE 6BT

Tel: (+44) 020 7679 4395 
Fax (+44) 020 7679 7096
f.calboli at ucl.ac.uk



From vograno at arbitrade.com  Thu Feb 13 22:05:02 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Thu Feb 13 22:05:02 2003
Subject: [R] modeling interaction of continuous vars
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DCF7@jupiter.arbitrade.com>

Dear R-Users,

I wonder what methods are available for modeling interaction of continuous
variables. Specifically I am interested in fitting a regression

y ~ f(w) * x

where y, x are vectors and f(w) is a smooth function of a continuous
parameter w (so it is f() that needs to be estimated). I can further assume
that f(w) is positive but I can not take the logarithms as both y and x can
be negative.


Thanks, Vadim

-------------------------------------------------- 
DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]



From bates at stat.wisc.edu  Thu Feb 13 22:20:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu Feb 13 22:20:03 2003
Subject: [R] fixed and random effects in lme
In-Reply-To: <3.0.6.32.20030213200140.00a21318@pop-server.ucl.ac.uk>
References: <3.0.6.32.20030213200140.00a21318@pop-server.ucl.ac.uk>
Message-ID: <6ru1f798vo.fsf@bates4.stat.wisc.edu>

Federico Calboli <f.calboli at ucl.ac.uk> writes:

> Hi All,
> 
> I would like to ask a question on fixed and random effecti in lme. I am
> fiddlying around Mick Crawley dataset "rats" :
> 
> http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/
>  
> The advantage is that most work is already done in Crawley's book (page 361
> onwards) so I can check what I am doing.
> 
> I am tryg to reproduce the nested analysis on page 368:
> 
> model<-aov(Glycogen~Treatment/Rat/Liver + Error(Treatment/Rat/Liver), rats)
> 
> using lme.
> The code: 
> 
> model1<- lme(Glycogen~Treatment, random = ~1|Rat/Liver, data=rats)
> VarCorr(model1)
> 
>             Variance     StdDev  
> Rat =       pdLogChol(1)         
> (Intercept) 20.6019981   4.538942
> Liver =     pdLogChol(1)         
> (Intercept)  0.0540623   0.232513
> Residual    42.4362241   6.514309
> 
> Does NOT give me the same variance componets I find in Crawley's book (page
> 371 onwards).
> The code:
> 
> model2<- lme(Glycogen~Treatment, random = ~1|Treatment/Rat/Liver, data=rats)
> VarCorr(model2)
> 
>  	Variance     StdDev  
> Treatment = pdLogChol(1)         
> (Intercept) 12.54061     3.541272
> Rat =       pdLogChol(1)         
> (Intercept) 36.07900     6.006580
> Liver =     pdLogChol(1)         
> (Intercept) 14.17434     3.764883
> Residual    21.16227     4.600247
> 
> 
> gets me very similar results (I would guess the differences are due to
> rounding and the fact I am using R 1.6.2 and Crawley used S+).
> 
> My problem is: as *Treatment* is a fixed factor, why should I put it in
> both the fixed term side and random terms side of my code to get the right
> numbers? I fail to get this at all. Any elucidation would be appreciated.

Rat is nested within Treatment and Liver is nested within Rat within
Treatment.  Although level 1 of Rat in Treatment 1 is unrelated to
level 1 of Rat in Treatment 2, lme won't recognize that when you
specify the random effects as ~ 1 | Rat/Liver.  There are two ways out
of this: you can specify the nesting as you did
   ~ 1|Treatment/Rat/Liver 
but, as you point out, that doesn't always make sense, or you can
define a new set of groups as shown below

> library(nlme)
Loading required package: nls 
Loading required package: lattice 
> Rats = read.table('/tmp/rats.txt', header = TRUE)
> Rats$Trat = getGroups(Rats, form = ~ 1|Treatment/Rat, level = 2)
> str(Rats)
`data.frame':	36 obs. of  5 variables:
 $ Glycogen : int  131 130 131 125 136 142 150 148 140 143 ...
 $ Treatment: int  1 1 1 1 1 1 1 1 1 1 ...
 $ Rat      : int  1 1 1 1 1 1 2 2 2 2 ...
 $ Liver    : int  1 1 2 2 3 3 1 1 2 2 ...
 $ Trat     : Factor w/ 6 levels "1/1","1/2","2/1",..: 1 1 1 1 1 1 2 2 2 2 ...
> fm = lme(Glycogen ~ Treatment, data = Rats, random=~1|Trat/Liver)
> VarCorr(fm)
            Variance     StdDev  
Trat =      pdLogChol(1)         
(Intercept) 82.71680     9.094878
Liver =     pdLogChol(1)         
(Intercept) 14.17466     3.764925
Residual    21.16529     4.600575

Is this result comparable to Crawley's? 

Note that it can be meaningful to have a factor appear as both a fixed
effect and a random effect if, as a random effect, it is nested within
a random effect.



From jbond at arg.org  Thu Feb 13 22:46:03 2003
From: jbond at arg.org (Jason Bond)
Date: Thu Feb 13 22:46:03 2003
Subject: [R] position of an element in a vector
Message-ID: <5.1.0.14.2.20030213133908.01dcdd50@arg.org>

Hello.  Sorry for the elementary post.  I've looked through the 
documentation, but can't seem to find a function which allows one to 
extract the position of an element within a list...for example the position 
of the element 4 in the vector c(1,2,4,3,6) is 3.  Thanks much for any help.

   Jason



From spencer.graves at pdf.com  Thu Feb 13 22:53:02 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu Feb 13 22:53:02 2003
Subject: [R] position of an element in a vector
References: <5.1.0.14.2.20030213133908.01dcdd50@arg.org>
Message-ID: <3E4C1388.6000505@pdf.com>

How about:

 > x <- c(1, 2, 4, 3, 6)
 > (1:length(x))[x==4]
[1] 3

Spencer Graves

Jason Bond wrote:
> Hello.  Sorry for the elementary post.  I've looked through the 
> documentation, but can't seem to find a function which allows one to 
> extract the position of an element within a list...for example the 
> position of the element 4 in the vector c(1,2,4,3,6) is 3.  Thanks much 
> for any help.
> 
>   Jason
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rpeng at stat.ucla.edu  Thu Feb 13 22:57:07 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu Feb 13 22:57:07 2003
Subject: [R] position of an element in a vector
In-Reply-To: <5.1.0.14.2.20030213133908.01dcdd50@arg.org>
Message-ID: <Pine.GSO.4.10.10302131351280.19094-100000@quetelet.stat.ucla.edu>

For extracting list elements, you can use the [[ operator, as in

a <- list(6, 5, 4, 3)
a[[1]] ## get '6'

For vectors, you can use [, as in

a <- c(1,2,4,3,6)
a[3]

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Thu, 13 Feb 2003, Jason Bond wrote:

> Hello.  Sorry for the elementary post.  I've looked through the 
> documentation, but can't seem to find a function which allows one to 
> extract the position of an element within a list...for example the position 
> of the element 4 in the vector c(1,2,4,3,6) is 3.  Thanks much for any help.
> 
>    Jason
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From mschwartz at medanalytics.com  Thu Feb 13 23:00:37 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu Feb 13 23:00:37 2003
Subject: [R] position of an element in a vector
In-Reply-To: <5.1.0.14.2.20030213133908.01dcdd50@arg.org>
Message-ID: <011701c2d3aa$539ffc50$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jason Bond
>Sent: Thursday, February 13, 2003 3:41 PM
>To: R-help at stat.math.ethz.ch
>Subject: [R] position of an element in a vector
>
>
>Hello.  Sorry for the elementary post.  I've looked through the 
>documentation, but can't seem to find a function which allows one to 
>extract the position of an element within a list...for example 
>the position 
>of the element 4 in the vector c(1,2,4,3,6) is 3.  Thanks much 
>for any help.
>
>   Jason

Take a look at ?which.

For example:

> which(c(1,2,4,3,6) == 4)
[1] 3


Regards,

Marc



From deepayan at stat.wisc.edu  Thu Feb 13 23:04:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu Feb 13 23:04:03 2003
Subject: [R] position of an element in a vector
In-Reply-To: <5.1.0.14.2.20030213133908.01dcdd50@arg.org>
References: <5.1.0.14.2.20030213133908.01dcdd50@arg.org>
Message-ID: <200302131557.57570.deepayan@stat.wisc.edu>

?which

On Thursday 13 February 2003 03:40 pm, Jason Bond wrote:
> Hello.  Sorry for the elementary post.  I've looked through the
> documentation, but can't seem to find a function which allows one to
> extract the position of an element within a list...for example the position
> of the element 4 in the vector c(1,2,4,3,6) is 3.  Thanks much for any
> help.
>
>    Jason
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jgramlich at piocon.com  Thu Feb 13 23:17:05 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Thu Feb 13 23:17:05 2003
Subject: [R] pie charts?
Message-ID: <1045174590.4534.13.camel@localhost.localdomain>

I don't suppose it's possible to create a pie chart in R?  I've got 1500
some odd elements in a frame that are valued at either -1, 0 or 1 and
I'd like to find a reasonable way to represent the distribution
graphically...any ideas?


Joshua Gramlich
Piocon Technologies
Chicago, IL



From mschwartz at medanalytics.com  Thu Feb 13 23:34:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu Feb 13 23:34:03 2003
Subject: [R] pie charts?
In-Reply-To: <1045174590.4534.13.camel@localhost.localdomain>
Message-ID: <011a01c2d3af$f57a84a0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Joshua Gramlich
>Sent: Thursday, February 13, 2003 4:17 PM
>To: R-help at stat.math.ethz.ch
>Subject: [R] pie charts?
>
>
>I don't suppose it's possible to create a pie chart in R?  
>I've got 1500 some odd elements in a frame that are valued at 
>either -1, 0 or 1 and I'd like to find a reasonable way to 
>represent the distribution graphically...any ideas?
>
>
>Joshua Gramlich
>Piocon Technologies
>Chicago, IL


You can. See ?pie.

However, I believe the general disposition would be to not do so.

You would probably be better off with either a bar chart (see ?barplot
in base R or ?barplot2 in the gregmisc package) or perhaps a Cleveland
dot plot (see ?dotchart in base R) depending upon what you might wish
to show.  barplot2() has some additional features like plotting
confidence intervals if you wish to include these in your graphic.

The reasoning behind this is covered in W.S. Cleveland's "Elements of
Graphing Data" on pages 262 - 264 in the section dealing with what he
calls "Pop Charts".

Hope that helps,

Marc Schwartz



From r.hankin at auckland.ac.nz  Thu Feb 13 23:38:03 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Thu Feb 13 23:38:03 2003
Subject: [R] generic handling of NA and NaN and NULL
Message-ID: <200302132235.h1DMZe2O013863@r.hankin.sges.auckland.ac.nz>

Hello everybody


I have a generic problem which the following toy function illustrates:

f <- function(n) {
  if(abs(n) < pi) {
    return(TRUE)
  } else {
    return(FALSE)
  }
}
                   
I want it to return TRUE if abs(n)<pi and FALSE otherwise.  f() is
fine as far as it goes, but does not deal well with NA or NaN or NULL
(I want these to signal some problem with the argument (ie return
FALSE), but not to stop execution of f().  In particular, I want f()
to pass R CMD check )-:

R> f(NA)
Error in if (abs(n) < pi) { : missing value where logical needed

R> f(NULL)
Error in abs(n) : non-numeric argument to function


So, how best to patch f() up?  The best I could come up with was:

f2 <- function(n) {
  if(is.null(n)){return(FALSE)}
  if(is.na(n)){return(FALSE)}
  if(abs(n) < pi) {
    return(TRUE)
  } else {
    return(FALSE)
  }
}

This can't be the best way!  Anyway, f2() isn't right: f2(numeric(0))
fails; note that

R> if(is.na(numeric(0))){print("asdf")}

falls over.  help.search("trap") was not very helpful.  try() doesn't
help either:

R> try(if(1==NA){print("asdf")})
Error in if (1 == NA) { : missing value where logical needed



QUESTION: how to make f() not give an error under any circumstances?






-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042



From jgramlich at piocon.com  Thu Feb 13 23:42:03 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Thu Feb 13 23:42:03 2003
Subject: [R] pie charts?
In-Reply-To: <011a01c2d3af$f57a84a0$0201a8c0@MARC>
References: <011a01c2d3af$f57a84a0$0201a8c0@MARC>
Message-ID: <1045176015.4532.18.camel@localhost.localdomain>

I did find ?pie and saw the explanation as to why not to use pie
charts.  I may end up using it anyway, because the comparison is
something like 94%,5%,1%, so the difficulty of the human eye to read
area as opposed to length(as in a bar chart) doesn't make much
difference in this case.

Thanks for the reply.


Joshua Gramlich



On Thu, 2003-02-13 at 16:33, Marc Schwartz wrote:
> >-----Original Message-----
> >From: r-help-admin at stat.math.ethz.ch 
> >[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Joshua Gramlich
> >Sent: Thursday, February 13, 2003 4:17 PM
> >To: R-help at stat.math.ethz.ch
> >Subject: [R] pie charts?
> >
> >
> >I don't suppose it's possible to create a pie chart in R?  
> >I've got 1500 some odd elements in a frame that are valued at 
> >either -1, 0 or 1 and I'd like to find a reasonable way to 
> >represent the distribution graphically...any ideas?
> >
> >
> >Joshua Gramlich
> >Piocon Technologies
> >Chicago, IL
> 
> 
> You can. See ?pie.
> 
> However, I believe the general disposition would be to not do so.
> 
> You would probably be better off with either a bar chart (see ?barplot
> in base R or ?barplot2 in the gregmisc package) or perhaps a Cleveland
> dot plot (see ?dotchart in base R) depending upon what you might wish
> to show.  barplot2() has some additional features like plotting
> confidence intervals if you wish to include these in your graphic.
> 
> The reasoning behind this is covered in W.S. Cleveland's "Elements of
> Graphing Data" on pages 262 - 264 in the section dealing with what he
> calls "Pop Charts".
> 
> Hope that helps,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From White.Denis at epamail.epa.gov  Fri Feb 14 00:16:03 2003
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Fri Feb 14 00:16:03 2003
Subject: [R] example methods for "whatis"
Message-ID: <OF995FBB70.DCA93832-ON88256CCC.007F6296@rtp.epa.gov>

Having difficulty following the examples in John Chambers paper "Classes
and Methods in the S Language", dated 9 August 2001.  See error below in
whatis (matrix (0,2,3)).  Thanks for help.

> library (methods)
> whatis <- function (object) paste ("an object of class",
+     data.class (object))
> setMethod ("whatis", "vector", function (object)
+     paste (data.class (object), "vector of length",
+       length (object)))
Creating a new generic function for "whatis" in package
.GlobalEnv
[1] "whatis"
> whatIsMatrix <- function (object)
+     paste (data.class (as (object, "vector")), "matrix with",
+         nrow (object), "rows and", ncol (object), "columns")
> setMethod ("whatis", "matrix", whatIsMatrix)
[1] "whatis"
> whatis (matrix (0,2,3))
Error in paste(".", prefix, name, sep = "__") :
        evaluation is nested too deeply: infinite recursion?
> R.version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.2
year     2003
month    01
day      10
language R



From spencer.graves at pdf.com  Fri Feb 14 00:21:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 14 00:21:06 2003
Subject: [R] generic handling of NA and NaN and NULL
References: <200302132235.h1DMZe2O013863@r.hankin.sges.auckland.ac.nz>
Message-ID: <3E4C278B.5090401@pdf.com>

How about:

 > f3 <- function(n){
+   n.pi <- (abs(n)<pi)
+   n.pi[is.na(n.pi)] <- F
+   n.pi
+ }
 >
 > f3(c(1, 5, NA))
[1]  TRUE FALSE FALSE
 >

Spencer Graves

Robin Hankin wrote:
> Hello everybody
> 
> 
> I have a generic problem which the following toy function illustrates:
> 
> f <- function(n) {
>   if(abs(n) < pi) {
>     return(TRUE)
>   } else {
>     return(FALSE)
>   }
> }
>                    
> I want it to return TRUE if abs(n)<pi and FALSE otherwise.  f() is
> fine as far as it goes, but does not deal well with NA or NaN or NULL
> (I want these to signal some problem with the argument (ie return
> FALSE), but not to stop execution of f().  In particular, I want f()
> to pass R CMD check )-:
> 
> R> f(NA)
> Error in if (abs(n) < pi) { : missing value where logical needed
> 
> R> f(NULL)
> Error in abs(n) : non-numeric argument to function
> 
> 
> So, how best to patch f() up?  The best I could come up with was:
> 
> f2 <- function(n) {
>   if(is.null(n)){return(FALSE)}
>   if(is.na(n)){return(FALSE)}
>   if(abs(n) < pi) {
>     return(TRUE)
>   } else {
>     return(FALSE)
>   }
> }
> 
> This can't be the best way!  Anyway, f2() isn't right: f2(numeric(0))
> fails; note that
> 
> R> if(is.na(numeric(0))){print("asdf")}
> 
> falls over.  help.search("trap") was not very helpful.  try() doesn't
> help either:
> 
> R> try(if(1==NA){print("asdf")})
> Error in if (1 == NA) { : missing value where logical needed
> 
> 
> 
> QUESTION: how to make f() not give an error under any circumstances?
> 
> 
> 
> 
> 
>



From andy_liaw at merck.com  Fri Feb 14 00:26:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Feb 14 00:26:03 2003
Subject: [R] generic handling of NA and NaN and NULL
Message-ID: <3A822319EB35174CA3714066D590DCD534BCA7@usrymx25.merck.com>

Try:

f <- function(n) {
  if(is.null(n) || is.na(n) || abs(n) < pi) {
    return(FALSE)
  } else {
    return(TRUE)
  }
}

Note that the order of the conditions inside if() matters: is.na(n) only
gets evaluated if is.null(n) is FALSE, and so on.

Andy

> -----Original Message-----
> From: Robin Hankin [mailto:r.hankin at auckland.ac.nz]
> Sent: Thursday, February 13, 2003 5:36 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] generic handling of NA and NaN and NULL
> 
> 
> Hello everybody
> 
> 
> I have a generic problem which the following toy function illustrates:
> 
> f <- function(n) {
>   if(abs(n) < pi) {
>     return(TRUE)
>   } else {
>     return(FALSE)
>   }
> }
>                    
> I want it to return TRUE if abs(n)<pi and FALSE otherwise.  f() is
> fine as far as it goes, but does not deal well with NA or NaN or NULL
> (I want these to signal some problem with the argument (ie return
> FALSE), but not to stop execution of f().  In particular, I want f()
> to pass R CMD check )-:
> 
> R> f(NA)
> Error in if (abs(n) < pi) { : missing value where logical needed
> 
> R> f(NULL)
> Error in abs(n) : non-numeric argument to function
> 
> 
> So, how best to patch f() up?  The best I could come up with was:
> 
> f2 <- function(n) {
>   if(is.null(n)){return(FALSE)}
>   if(is.na(n)){return(FALSE)}
>   if(abs(n) < pi) {
>     return(TRUE)
>   } else {
>     return(FALSE)
>   }
> }
> 
> This can't be the best way!  Anyway, f2() isn't right: f2(numeric(0))
> fails; note that
> 
> R> if(is.na(numeric(0))){print("asdf")}
> 
> falls over.  help.search("trap") was not very helpful.  try() doesn't
> help either:
> 
> R> try(if(1==NA){print("asdf")})
> Error in if (1 == NA) { : missing value where logical needed
> 
> 
> 
> QUESTION: how to make f() not give an error under any circumstances?
> 
> 
> 
> 
> 
> 
> -- 
> 
> Robin Hankin, Lecturer,
> School of Geography and Environmental Science
> Tamaki Campus
> Private Bag 92019 Auckland
> New Zealand
> 
> r.hankin at auckland.ac.nz
> tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From r.hankin at auckland.ac.nz  Fri Feb 14 00:30:04 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Fri Feb 14 00:30:04 2003
Subject: [R] generic handling of NA and NaN and NULL
In-Reply-To: <3E4C278B.5090401@pdf.com> (message from Spencer Graves on Thu,
	13 Feb 2003 15:17:31 -0800)
References: <200302132235.h1DMZe2O013863@r.hankin.sges.auckland.ac.nz> <3E4C278B.5090401@pdf.com>
Message-ID: <200302132327.h1DNRetG014190@r.hankin.sges.auckland.ac.nz>

Hi Spencer


thanks for this


> How about:
> 
>  > f3 <- function(n){
> +   n.pi <- (abs(n)<pi)
> +   n.pi[is.na(n.pi)] <- F
> +   n.pi
> + }
>  >


nope!

Sometimes I need things like

R> x <- 1:10
R> if(f3(x[x>11])==TRUE){print("asfd")}
Error in if (f3(x[x > 11]) == TRUE) { : missing value where logical needed



best


rksh





-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042



From r.hankin at auckland.ac.nz  Fri Feb 14 00:33:25 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Fri Feb 14 00:33:25 2003
Subject: [R] generic handling of NA and NaN and NULL
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BCA7@usrymx25.merck.com>
	(andy_liaw@merck.com)
References: <3A822319EB35174CA3714066D590DCD534BCA7@usrymx25.merck.com>
Message-ID: <200302132329.h1DNTe8s014210@r.hankin.sges.auckland.ac.nz>


Hello Andy

thanks for this; but


R> x <- 1:10
R> f
function(n) {
  if(is.null(n) || is.na(n) || abs(n) < pi) {
    return(FALSE)
  } else {
    return(TRUE)
  }
}
R> x <- 1:10
R> f(x[x>11])
Error in if (is.null(n) || is.na(n) || abs(n) < pi) { : 
	missing value where logical needed
> 






> 
> Try:
> 
> f <- function(n) {
>   if(is.null(n) || is.na(n) || abs(n) < pi) {
>     return(FALSE)
>   } else {
>     return(TRUE)
>   }
> }
> 
> Note that the order of the conditions inside if() matters: is.na(n) only
> gets evaluated if is.null(n) is FALSE, and so on.
> 
> Andy
> 


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042



From andy_liaw at merck.com  Fri Feb 14 00:36:41 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Feb 14 00:36:41 2003
Subject: [R] generic handling of NA and NaN and NULL
Message-ID: <3A822319EB35174CA3714066D590DCD534BCA8@usrymx25.merck.com>

> From: Spencer Graves [mailto:spencer.graves at pdf.com]
> 
> How about:
> 
>  > f3 <- function(n){
> +   n.pi <- (abs(n)<pi)
> +   n.pi[is.na(n.pi)] <- F
> +   n.pi
> + }
>  >
>  > f3(c(1, 5, NA))
> [1]  TRUE FALSE FALSE
>  >

A couple of problems: 

a) It chokes if argument is NULL.
b) Use of F instead of FALSE will not pass R CMD check, which is what Robin
wants.

Andy

 
> Spencer Graves
> 
> Robin Hankin wrote:
> > Hello everybody
> > 
> > 
> > I have a generic problem which the following toy function 
> illustrates:
> > 
> > f <- function(n) {
> >   if(abs(n) < pi) {
> >     return(TRUE)
> >   } else {
> >     return(FALSE)
> >   }
> > }
> >                    
> > I want it to return TRUE if abs(n)<pi and FALSE otherwise.  f() is
> > fine as far as it goes, but does not deal well with NA or 
> NaN or NULL
> > (I want these to signal some problem with the argument (ie return
> > FALSE), but not to stop execution of f().  In particular, I want f()
> > to pass R CMD check )-:
> > 
> > R> f(NA)
> > Error in if (abs(n) < pi) { : missing value where logical needed
> > 
> > R> f(NULL)
> > Error in abs(n) : non-numeric argument to function
> > 
> > 
> > So, how best to patch f() up?  The best I could come up with was:
> > 
> > f2 <- function(n) {
> >   if(is.null(n)){return(FALSE)}
> >   if(is.na(n)){return(FALSE)}
> >   if(abs(n) < pi) {
> >     return(TRUE)
> >   } else {
> >     return(FALSE)
> >   }
> > }
> > 
> > This can't be the best way!  Anyway, f2() isn't right: 
> f2(numeric(0))
> > fails; note that
> > 
> > R> if(is.na(numeric(0))){print("asdf")}
> > 
> > falls over.  help.search("trap") was not very helpful.  
> try() doesn't
> > help either:
> > 
> > R> try(if(1==NA){print("asdf")})
> > Error in if (1 == NA) { : missing value where logical needed
> > 
> > 
> > 
> > QUESTION: how to make f() not give an error under any circumstances?
> > 
> > 
> > 
> > 
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From andy_liaw at merck.com  Fri Feb 14 00:40:05 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Feb 14 00:40:05 2003
Subject: [R] generic handling of NA and NaN and NULL
Message-ID: <3A822319EB35174CA3714066D590DCD534BCA9@usrymx25.merck.com>

The version I gave is obviously not vectorized (since your original version
seem to indicate that the argument won't have length > 1, otherwise the if()
won't really make sense).

Replacing is.null(n) with length(n)!=1 (or length(n)==0) should do the trick
(I hope!).

Andy

> -----Original Message-----
> From: Robin Hankin [mailto:r.hankin at auckland.ac.nz]
> Sent: Thursday, February 13, 2003 6:30 PM
> To: andy_liaw at merck.com
> Cc: r.hankin at auckland.ac.nz; r-help at stat.math.ethz.ch
> Subject: Re: [R] generic handling of NA and NaN and NULL
> 
> 
> 
> 
> Hello Andy
> 
> thanks for this; but
> 
> 
> R> x <- 1:10
> R> f
> function(n) {
>   if(is.null(n) || is.na(n) || abs(n) < pi) {
>     return(FALSE)
>   } else {
>     return(TRUE)
>   }
> }
> R> x <- 1:10
> R> f(x[x>11])
> Error in if (is.null(n) || is.na(n) || abs(n) < pi) { : 
> 	missing value where logical needed
> > 
> 
> 
> 
> 
> 
> 
> > 
> > Try:
> > 
> > f <- function(n) {
> >   if(is.null(n) || is.na(n) || abs(n) < pi) {
> >     return(FALSE)
> >   } else {
> >     return(TRUE)
> >   }
> > }
> > 
> > Note that the order of the conditions inside if() matters: 
> is.na(n) only
> > gets evaluated if is.null(n) is FALSE, and so on.
> > 
> > Andy
> > 
> 
> 
> -- 
> 
> Robin Hankin, Lecturer,
> School of Geography and Environmental Science
> Tamaki Campus
> Private Bag 92019 Auckland
> New Zealand
> 
> r.hankin at auckland.ac.nz
> tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
> 


------------------------------------------------------------------------------



From spencer.graves at pdf.com  Fri Feb 14 00:52:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 14 00:52:03 2003
Subject: [R] generic handling of NA and NaN and NULL
References: <3A822319EB35174CA3714066D590DCD534BCA9@usrymx25.merck.com>
Message-ID: <3E4C2F76.7090100@pdf.com>

How about the following modification:

 > f3 <- function(n){
+   if(length(n)<1)return(FALSE)
+   n.pi <- (abs(n)<pi)
+   n.pi[is.na(n.pi)] <- FALSE
+   n.pi
+ }
 >
 >  x <- 1:10
 > f3(x[x>11])
[1] FALSE

Spencer

Liaw, Andy wrote:
> The version I gave is obviously not vectorized (since your original version
> seem to indicate that the argument won't have length > 1, otherwise the if()
> won't really make sense).
> 
> Replacing is.null(n) with length(n)!=1 (or length(n)==0) should do the trick
> (I hope!).
> 
> Andy
> 
> 
>>-----Original Message-----
>>From: Robin Hankin [mailto:r.hankin at auckland.ac.nz]
>>Sent: Thursday, February 13, 2003 6:30 PM
>>To: andy_liaw at merck.com
>>Cc: r.hankin at auckland.ac.nz; r-help at stat.math.ethz.ch
>>Subject: Re: [R] generic handling of NA and NaN and NULL
>>
>>
>>
>>
>>Hello Andy
>>
>>thanks for this; but
>>
>>
>>R> x <- 1:10
>>R> f
>>function(n) {
>>  if(is.null(n) || is.na(n) || abs(n) < pi) {
>>    return(FALSE)
>>  } else {
>>    return(TRUE)
>>  }
>>}
>>R> x <- 1:10
>>R> f(x[x>11])
>>Error in if (is.null(n) || is.na(n) || abs(n) < pi) { : 
>>	missing value where logical needed
>>
>>
>>
>>
>>
>>
>>>Try:
>>>
>>>f <- function(n) {
>>>  if(is.null(n) || is.na(n) || abs(n) < pi) {
>>>    return(FALSE)
>>>  } else {
>>>    return(TRUE)
>>>  }
>>>}
>>>
>>>Note that the order of the conditions inside if() matters: 
>>
>>is.na(n) only
>>
>>>gets evaluated if is.null(n) is FALSE, and so on.
>>>
>>>Andy
>>>
>>
>>
>>-- 
>>
>>Robin Hankin, Lecturer,
>>School of Geography and Environmental Science
>>Tamaki Campus
>>Private Bag 92019 Auckland
>>New Zealand
>>
>>r.hankin at auckland.ac.nz
>>tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
>>
> 
> 
> 
> ------------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From cadolph at fas.harvard.edu  Fri Feb 14 01:09:05 2003
From: cadolph at fas.harvard.edu (Christopher Adolph)
Date: Fri Feb 14 01:09:05 2003
Subject: [R] Levelplot problem
In-Reply-To: <Pine.OSF.4.44.0302091814420.11333-100000@is05.fas.harvard.edu>
Message-ID: <Pine.OSF.4.44.0302131902190.21578-100000@is07.fas.harvard.edu>

I'm working with a levelplot in which the x's are unequally spaced:

x = {.8,.85,.9,.91,.92,.93,.94,.95,.96,.97,.98,.99,1}

It seems this results in a "gap" in the plot in the vicinity of x = 8.75
to 8.85 or so.  I assume this is because the rectangles are centered on
the points in the dataset, whereas the unequal space means that some need
to be "lopsided" for the levelplot to be gapless.

Is there any easy way to fix this problem?

Thanks,
Chris



From deepayan at stat.wisc.edu  Fri Feb 14 01:44:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Feb 14 01:44:03 2003
Subject: [R] Levelplot problem (lattice)
In-Reply-To: <Pine.OSF.4.44.0302131902190.21578-100000@is07.fas.harvard.edu>
References: <Pine.OSF.4.44.0302131902190.21578-100000@is07.fas.harvard.edu>
Message-ID: <200302131843.43407.deepayan@stat.wisc.edu>

On Thursday 13 February 2003 06:08 pm, Christopher Adolph wrote:
> I'm working with a levelplot in which the x's are unequally spaced:
>
> x = {.8,.85,.9,.91,.92,.93,.94,.95,.96,.97,.98,.99,1}
>
> It seems this results in a "gap" in the plot in the vicinity of x = 8.75
> to 8.85 or so.  I assume this is because the rectangles are centered on
> the points in the dataset, whereas the unequal space means that some need
> to be "lopsided" for the levelplot to be gapless.
>
> Is there any easy way to fix this problem?

Probably not. There's something wrong with the code, but I won't have time to 
look at this for a few days.



From jbond at arg.org  Fri Feb 14 02:15:06 2003
From: jbond at arg.org (Jason Bond)
Date: Fri Feb 14 02:15:06 2003
Subject: [R] data manipulation function descriptions
In-Reply-To: <200302131557.57570.deepayan@stat.wisc.edu>
References: <5.1.0.14.2.20030213133908.01dcdd50@arg.org>
 <5.1.0.14.2.20030213133908.01dcdd50@arg.org>
Message-ID: <5.1.0.14.2.20030213164137.01dc9c50@arg.org>

Hello,

   I'm a recovering xlispstat user, and am trying to become a good R 
user.  I've looked around on the CRAN doc website and have found quite a 
few sets of documentation with various level of data manipulation function 
descriptions (of what I've seen, most relatively low levels), and many with 
examples of Rs use in statistical analyses.  Although I don't expect to get 
my wish, ideally, it would be nice to have some sort of data manipulation 
function guide for programmers.  I guess I'm somewhat of a different case, 
as I know which functions that I want to use...I just don't know their 
names...for example, all those great xlispstat functions like:

remove-duplicates
sort-data
combine
remove
reverse
butlast
first
case
which
mapcar
map-elements
all the string functions
and many many more,

descriptions of a few of which are spread out in various documents.  Part 
of my problem is clinging to that which I know.  Anyway, any general advice 
would be greatly appreciated.

   Jason

At 03:57 PM 2/13/03 -0600, you wrote:

>?which
>
>On Thursday 13 February 2003 03:40 pm, Jason Bond wrote:
> > Hello.  Sorry for the elementary post.  I've looked through the
> > documentation, but can't seem to find a function which allows one to
> > extract the position of an element within a list...for example the position
> > of the element 4 in the vector c(1,2,4,3,6) is 3.  Thanks much for any
> > help.
> >
> >    Jason
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From White.Denis at epamail.epa.gov  Fri Feb 14 02:29:03 2003
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Fri Feb 14 02:29:03 2003
Subject: [R] masking polygons (formerly no subject)
Message-ID: <OF3C3D42EC.D9DBA578-ON88256CCD.00071FB4@rtp.epa.gov>

> I have two routine tasks that I am wasting time over
> trying to solve. Can anyone help?  I want to display
> the results of some geostatistical analysis quickly in
> R before exporting back to GIS . Does anyone have a trick
> for overlaying a polygon on an image of a krigging surface
> (prmat in spatial) in such a way that the space outside
> the polygon is whited out (so I trim within state
> boundaries)?  Also, has anyone got a function for converting
> decimal degrees to UTM within R itself?
>
> Thanks,
>
> Duncan Golicher

Below is some simple code to illustrate a way to do it.  The idea is to
concatenate the coordinates of the polygon of interest (e.g., state
boundary) to the coordinates describing the plot region (in data space).
This trick assumes that the polygon of interest lies entirely within the
plot region.  Then the polygon shading algorithm treats the polygon of
interest like a hole in the outer polygon and leaves it transparent.  If
the polygon of interest itself has interior holes it may not work.

n <- 50 * 3
x <- runif (n)
y <- runif (n)
x[(seq(n) %% 3) == 0] <- NA
y[(seq(n) %% 3) == 0] <- NA

plot.new ()
range.x <- range (x, na.rm=TRUE)
range.y <- range (y, na.rm=TRUE)
plot.window (range.x, range.y, asp=1)
lines (x, y)

wind.x <- c(range.x, rev (range.x), range.x[1])
wind.y <- c(range.y[1], range.y, rev (range.y))

# example polygon
poly.x <- wind.x / 2 + 0.25
poly.y <- wind.y / 2 + 0.25

mask.x <- c(wind.x, poly.x)
mask.y <- c(wind.y, poly.y)
polygon (mask.x, mask.y, col="white", border="white")



From kjetil at entelnet.bo  Fri Feb 14 03:35:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri Feb 14 03:35:03 2003
Subject: [R] modeling interaction of continuous vars
In-Reply-To: <AFD78192EC49D311BFAE00902798AB8F23DCF7@jupiter.arbitrade.com>
Message-ID: <3E4C1D54.5724.32B41D2@localhost>

On 13 Feb 2003 at 15:03, Vadim Ogranovich wrote:

I beleave this can be done with the mgcv package.

library(mgcv)
?gam

Kjetil Halvorsen

> Dear R-Users,
> 
> I wonder what methods are available for modeling interaction of continuous
> variables. Specifically I am interested in fitting a regression
> 
> y ~ f(w) * x
> 
> where y, x are vectors and f(w) is a smooth function of a continuous
> parameter w (so it is f() that needs to be estimated). I can further assume
> that f(w) is positive but I can not take the logarithms as both y and x can
> be negative.
> 
> 
> Thanks, Vadim
> 
> -------------------------------------------------- 
> DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Fri Feb 14 04:00:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri Feb 14 04:00:03 2003
Subject: [R] data manipulation function descriptions
In-Reply-To: <5.1.0.14.2.20030213164137.01dc9c50@arg.org>
References: <200302131557.57570.deepayan@stat.wisc.edu>
Message-ID: <3E4C2303.8324.3417367@localhost>

On 13 Feb 2003 at 17:09, Jason Bond wrote:

As lisp-stat user, I tried to compile a short dictionary within your 
answer below:

> Hello,
> 
>    I'm a recovering xlispstat user, and am trying to become a good R 
> user.  I've looked around on the CRAN doc website and have found quite a 
> few sets of documentation with various level of data manipulation function 
> descriptions (of what I've seen, most relatively low levels), and many with 
> examples of Rs use in statistical analyses.  Although I don't expect to get 
> my wish, ideally, it would be nice to have some sort of data manipulation 
> function guide for programmers.  I guess I'm somewhat of a different case, 
> as I know which functions that I want to use...I just don't know their 
> names...for example, all those great xlispstat functions like:
> 
> remove-duplicates                more or less    unique()
> sort-data                                  "                 sort()
> combine                                                     c()
> remove
                               x <- c(1,2,3,5,7,9,12,15, 18, 22)
                                x[-which(x==15)]
> reverse                                                      rev
> butlast
                                    n <- length(x)
                                    x[-n]
> first                           x[1] or for a list x[[1]]
> case                          switch
                                    [R-core : switch should be better 
                                               announced. It is for   
                                                instance not     
                                                 mentioned in "An 
                                                  introduction to R"]
> which                           which
> mapcar                         apply, lapply, sapply
> map-elements                     nothing better than the ones above
> all the string functions             paste, strwidth, strwrap, substr, toString
> and many many more,\

Kjetil Halvorsen

> 
> descriptions of a few of which are spread out in various documents.  Part 
> of my problem is clinging to that which I know.  Anyway, any general advice 
> would be greatly appreciated.
> 
>    Jason
> 
> At 03:57 PM 2/13/03 -0600, you wrote:
> 
> >?which
> >
> >On Thursday 13 February 2003 03:40 pm, Jason Bond wrote:
> > > Hello.  Sorry for the elementary post.  I've looked through the
> > > documentation, but can't seem to find a function which allows one to
> > > extract the position of an element within a list...for example the position
> > > of the element 4 in the vector c(1,2,4,3,6) is 3.  Thanks much for any
> > > help.
> > >
> > >    Jason
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From david.whiting at ncl.ac.uk  Fri Feb 14 05:20:06 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Fri Feb 14 05:20:06 2003
Subject: [R] ESRI shape file import and time-space models
In-Reply-To: <D5542210BB281E4E94DCFF34A85D9BF9878CF8@bag015ex.bag.admin.ch>
References: <D5542210BB281E4E94DCFF34A85D9BF9878CF8@bag015ex.bag.admin.ch>
Message-ID: <20030213164843.GH10750@192.168.57.2>

On Thu, Feb 13, 2003 at 12:36:51PM +0100, Ekkehardt.Altpeter at bag.admin.ch wrote:
> Dear R user,
> 
> I am running R under Windows 2000.
> 
> I am looking for a routine for importing
> 
> -        shape files (ESRI) into R
> 
> -        dbase files (FOXPRO) into R

I assume that as you say dbase (Foxpro) you mean Foxpro version < 3.0,
e.g. 2.x.  I don't know of a way of opening dbase/foxpro files from
within R (I think I saw once that RODBC can connect with dbase files,
and if it does I'm sure you'll hear from someone else who knows more
about it than me). 

If you have Foxpro and don't need an elegant solution, but just need to
get the job done then you can export files from foxpro as tab-delimited
files (COPY TO foxdata.txt DELIM WITH TAB) which you can then read into
R with:

dta <- read.delim("foxdata.txt", header=FALSE, sep="\t", strip.white =
TRUE)

This gets the data in, but does not give you the field names.  I have
written a little foxpro program that creates a tab-delimited file with
the headers (field names) that seems to work.  Again, I read the data
into R with read.delim(). Let me know if you want me to send you the
Foxpro program.

HTH,

Dave
 
-- 
Dave Whiting
Dar es Salaam, Tanzania



From j+rhelp at howard.fm  Fri Feb 14 06:38:03 2003
From: j+rhelp at howard.fm (j+rhelp@howard.fm)
Date: Fri Feb 14 06:38:03 2003
Subject: [R] Translating lm.object to SQL, C, etc function
Message-ID: <20030214053742.87AAA46CA7@server2.fastmail.fm>

This is my first post to this list so I suppose a quick intro is in
order. I've been using SPLUS 2000 and R1.6.2 for just a couple of days,
and love S already. I'm reading MASS and also John Fox's book - both have
been very useful. My background in stat software was mainly SPSS (which
I've never much liked - thanks heavens I've found S!), and Perl is my
tool of choice for general-purpose programming (I chaired the
perl6-language-data working group, responsible for improving the data
analysis capabilities in Perl).

I have just completed my first S project, and I now have 8 lm.objects.
The models are all reasonably complex with multiple numeric and factor
variables and some 2-way and 3-way interactions. I now need to use these
models in other environments, such as C code, SQL functions (using CASE)
and in Perl - I can not work out how to do this.

The difficulty I am having is that the output of coef() is not really
parsable, since there is no marker in the name of an coefficient of
separate out the components. For instance, in SPSS the name of a
coefficient might be:

  var1=[a]*var2=[b]*var3

...which is easy to write a little script to pull that apart and turn it
into a line of SQL, C, or whatever. In S however the name looks like:

  var1avar2bvar3

...which provides no way to pull the bits apart.

So my question is, how do I export an lm.object in some form that I can
then apply to prediction in C, SQL, or some other language? All I'm
looking for is some well-structured textual or data frame output that I
can then manipulate with appropriate tools, whether it be S itself, or
something like Perl.

Thanks in advance for any suggestions (and apologies in advance if this
is well documented somewhere!),

  Jeremy



From petr.pikal at precheza.cz  Fri Feb 14 07:49:03 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri Feb 14 07:49:03 2003
Subject: [R] removing dropouts (setting the values to NA)
Message-ID: <3E4C9F42.13602.243EA7@localhost>

Dear all 

I hope there is somebody who encountered similar problem and 
can give me a  hint how to do it or where to look. 

I have several data sets in DBF format. I can transfer them to R 
data frames and  then I want to perform aggregation or some 
other computations, but there are  values in my data which I can 
call drop-outs and I want them to be discarded (see  example).  

Usually I can find row of zeros (the measuring device is out of 
order or does not  obtain any data) or a gradual decrease of some 
measured values due to real  interruption of the process. I would 
like to do some evaluation (automatic) to set  an logical vector 
where, for instance, TRUE will stay for "correct" values and  
FALSE will be for "drop-outs" (or vice versa).  

Preferably I would like to ***discard few values before and after 
actual drop-out  occurred***. Then I will set all "wrong" values in 
my variables to NA and  continue further computations. 

Here is some foo code for making artificial drop-outs similar like 
in my actual  data 

x<-seq(0,100,.1) 
y<-sin(x)+rnorm(length(x),mean=0,sd=1) 
y1<-y-c(rep(0,200),exp(x[20:50]),rep(0,770)) 
y<-y1+50 
y<-y*(y>0) 
y[600:700]<-0 

My actual data looks like: 

Date, 		Time, 		Var1, 	Var2, 	Var3, ...... 
01.01.01, 	03:05:00, 	12, 	27, 	0.53, ..... 
01.01.01, 	03:05:15, 	12.2, 	29, 	1.2, ..... 
01.01.01, 	03:05:30, 	12.2, 	29, 	0, ..... 
......... 
   
in several data sets.  

I can simply put  

idx1<-y==0  

I can set an arbitrary limit under or over which the value is 
considered a drop-out  

idx2<-y<45 

and I can combine both indexes 

idx<-as.logical(idx1+idx2) 

But I do not know how easily enlarge the TRUE parts of index 
vector forwards  and backwards the actual drop-out occurred.  

The only way how I am able to accomplish it is  

changes<-seq(along=x)[as.logical(diff(idx))]+1 

than select odd an even values from changes subtract a certain 
value from odd  and add a value to even and construct something 
like that 

c(rep(F,odd[1]),rep(T,even[1]-odd[1]),rep(F,odd[2]-
even[1]),rep(T,even[2]- odd[2]),rep(F,length(x)-even[2])) 

what is a little bit complicated and not very general solution. 

Please can somebody help me find the better procedure or 
function for such drop- out filtering? 

Thank you. 

Petr Pikal
Precheza a.s., Nab?.Dr.E.Bene?e 24, 750 62 P?erov
tel: +420581 252 257 ; 724 008 364
petr.pikal at precheza.cz; p.pik at volny.cz
fax +420581 252 561



From ligges at statistik.uni-dortmund.de  Fri Feb 14 08:33:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Feb 14 08:33:03 2003
Subject: [R] Translating lm.object to SQL, C, etc function
In-Reply-To: <20030214053742.87AAA46CA7@server2.fastmail.fm>
References: <20030214053742.87AAA46CA7@server2.fastmail.fm>
Message-ID: <3E4C9B6E.8060805@statistik.uni-dortmund.de>

j+rhelp at howard.fm wrote:
> This is my first post to this list so I suppose a quick intro is in
> order. I've been using SPLUS 2000 and R1.6.2 for just a couple of days,
> and love S already. I'm reading MASS and also John Fox's book - both have
> been very useful. My background in stat software was mainly SPSS (which
> I've never much liked - thanks heavens I've found S!), and Perl is my
> tool of choice for general-purpose programming (I chaired the
> perl6-language-data working group, responsible for improving the data
> analysis capabilities in Perl).
> 
> I have just completed my first S project, and I now have 8 lm.objects.
> The models are all reasonably complex with multiple numeric and factor
> variables and some 2-way and 3-way interactions. I now need to use these
> models in other environments, such as C code, SQL functions (using CASE)
> and in Perl - I can not work out how to do this.
> 
> The difficulty I am having is that the output of coef() is not really
> parsable, since there is no marker in the name of an coefficient of
> separate out the components. For instance, in SPSS the name of a
> coefficient might be:
> 
>   var1=[a]*var2=[b]*var3
> 
> ...which is easy to write a little script to pull that apart and turn it
> into a line of SQL, C, or whatever. In S however the name looks like:
> 
>   var1avar2bvar3
 >
> ...which provides no way to pull the bits apart.
> 
> So my question is, how do I export an lm.object in some form that I can
> then apply to prediction in C, SQL, or some other language? All I'm
> looking for is some well-structured textual or data frame output that I
> can then manipulate with appropriate tools, whether it be S itself, or
> something like Perl.
> 
> Thanks in advance for any suggestions (and apologies in advance if this
> is well documented somewhere!),
> 
>   Jeremy
> 


See ?dump

Uwe Ligges



From ripley at stats.ox.ac.uk  Fri Feb 14 08:45:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 14 08:45:05 2003
Subject: [R] data manipulation function descriptions
In-Reply-To: <3E4C2303.8324.3417367@localhost>
Message-ID: <Pine.LNX.4.44.0302140735510.16111-100000@gannet.stats>

On Thu, 13 Feb 2003, kjetil brinchmann halvorsen wrote:

> On 13 Feb 2003 at 17:09, Jason Bond wrote:

> > case                          switch
>                                     [R-core : switch should be better 
>                                                announced. It is for   
>                                                 instance not     
>                                                  mentioned in "An 
>                                                   introduction to R"]

Well, that is an *introduction*, not a programmer's guide.  You will find
switch() is rarely used in R: it is a bit peculiar in its semantics, and 
something definitely not to be considered introductory.

On the original question, I think it would be a mistake to translate what
you know.  R is a vector language, not a pairlist language, and I see
quite a bit of evidence of convoluted solutions in its internals dating
from when R was the second.  Chapter 2 of Venables & Ripley (2002) (as in
the R FAQ) is devoted to using S/R for data manipulation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Feb 14 08:51:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 14 08:51:03 2003
Subject: [R] ESRI shape file import and time-space models
In-Reply-To: <20030213164843.GH10750@192.168.57.2>
Message-ID: <Pine.LNX.4.44.0302140746580.16111-100000@gannet.stats>

On Thu, 13 Feb 2003 david.whiting at ncl.ac.uk wrote:

> On Thu, Feb 13, 2003 at 12:36:51PM +0100, Ekkehardt.Altpeter at bag.admin.ch wrote:

> > I am running R under Windows 2000.
> > 
> > I am looking for a routine for importing
> > 
> > -        shape files (ESRI) into R
> > 
> > -        dbase files (FOXPRO) into R
> 
> I assume that as you say dbase (Foxpro) you mean Foxpro version < 3.0,
> e.g. 2.x.  I don't know of a way of opening dbase/foxpro files from
> within R (I think I saw once that RODBC can connect with dbase files,
> and if it does I'm sure you'll hear from someone else who knows more
> about it than me). 

It does read dBase files, easily, including the column (aka field) names.
Also for FoxPro files.  You don't need either program installed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From j+rhelp at howard.fm  Fri Feb 14 09:02:03 2003
From: j+rhelp at howard.fm (j+rhelp@howard.fm)
Date: Fri Feb 14 09:02:03 2003
Subject: [R] Translating lm.object to SQL, C, etc function
In-Reply-To: <3E4C9B6E.8060805@statistik.uni-dortmund.de>
References: <20030214053742.87AAA46CA7@server2.fastmail.fm> <3E4C9B6E.8060805@statistik.uni-dortmund.de>
Message-ID: <20030214080110.0B8F14711F@server2.fastmail.fm>

On Fri, 14 Feb 2003 08:31:58 +0100, "Uwe Ligges"
<ligges at statistik.uni-dortmund.de> said:
> j+rhelp at howard.fm wrote:
<...>
> > So my question is, how do I export an lm.object in some form that I can
> > then apply to prediction in C, SQL, or some other language? All I'm
> > looking for is some well-structured textual or data frame output that I
> > can then manipulate with appropriate tools, whether it be S itself, or
> > something like Perl.
<...>

> See ?dump

Thanks for the suggestion. After my last post I tried switching from
SPLUS to R and discovered the useful xlevels attribute, which when output
with expression(), combined with the coefficients attribute, gives me the
information I need. dump() also provides those things, although it has a
lot of other stuff not needed to build the prediction function.

I'll start coding something using this, but it won't be ideal. The two
problems are:
 - The variable name / level name are still concatenated with
   no delimiter in the coefficients, so it's possible there will
   be ambiguous names
 - It feels rather clunky to be relying on these attributes when
   I feel like I should be adding methods directly to the class
   somehow...

In SPLUS I came across a useful attribute 'assign', which has a mapping
of term names to variables - the same attribute in R doesn't appear to
provide this information. Is this available somewhere?

What approaches are others using to apply their models to data sets where
S is not available? Has anyone written any convertors of models to other
languages? Is it possible to compile an expression or model into a DLL or
COM object and access it that way? I'm aware of the SOAP interface, but
that doesn't really suit our needs in this case.

TIA,
  Jeremy



From ripley at stats.ox.ac.uk  Fri Feb 14 09:07:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 14 09:07:03 2003
Subject: [R] Translating lm.object to SQL, C, etc function
In-Reply-To: <20030214053742.87AAA46CA7@server2.fastmail.fm>
Message-ID: <Pine.LNX.4.44.0302140750530.16111-100000@gannet.stats>

The issue here is that coef() tells you the coefficients in R's internal
parametrization of the model, and that is of no use to you unless you have
a means of creating a model matrix in C, SQL or (heaven forbid) Perl. The
information needed to re-create a model matrix is stored in the lm fit,
but in ways that are going to be hard to use anywhere else (since they
include R functions).  This is not perverse: what R does is very general,
*far* more so than SPSS.  Formulae in lm can include poly() and ns() 
terms, for example.

The only practical solution it seems to us is to ask R to create the model 
matrix for new data.  Then the things you are talking about are just the 
colnames of that matrix, and don't need to be interpreted.

You may want to read the sources to find out how R does it: that area is 
one of the most complex parts of the internals, and one in which bugs 
continue to emerge.

On Fri, 14 Feb 2003 j+rhelp at howard.fm wrote:

> This is my first post to this list so I suppose a quick intro is in
> order. I've been using SPLUS 2000 and R1.6.2 for just a couple of days,
> and love S already. I'm reading MASS and also John Fox's book - both have
> been very useful. My background in stat software was mainly SPSS (which
> I've never much liked - thanks heavens I've found S!), and Perl is my
> tool of choice for general-purpose programming (I chaired the
> perl6-language-data working group, responsible for improving the data
> analysis capabilities in Perl).
> 
> I have just completed my first S project, and I now have 8 lm.objects.
> The models are all reasonably complex with multiple numeric and factor
> variables and some 2-way and 3-way interactions. I now need to use these
> models in other environments, such as C code, SQL functions (using CASE)
> and in Perl - I can not work out how to do this.
> 
> The difficulty I am having is that the output of coef() is not really
> parsable, since there is no marker in the name of an coefficient of
> separate out the components. For instance, in SPSS the name of a
> coefficient might be:
> 
>   var1=[a]*var2=[b]*var3
> 
> ...which is easy to write a little script to pull that apart and turn it
> into a line of SQL, C, or whatever. In S however the name looks like:
> 
>   var1avar2bvar3
> 
> ...which provides no way to pull the bits apart.

I find that impossible to understand anyway, but doubt that it corresponds
to SPSS.  For a variable V, label Va does not mean V=[a] except in unusual
special cases.

> So my question is, how do I export an lm.object in some form that I can
> then apply to prediction in C, SQL, or some other language? All I'm
> looking for is some well-structured textual or data frame output that I
> can then manipulate with appropriate tools, whether it be S itself, or
> something like Perl.
> 
> Thanks in advance for any suggestions (and apologies in advance if this
> is well documented somewhere!),
> 
>   Jeremy
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From yyjia at pmail.ntu.edu.sg  Fri Feb 14 09:20:03 2003
From: yyjia at pmail.ntu.edu.sg (#JIA YIYU#)
Date: Fri Feb 14 09:20:03 2003
Subject: [R] How to keep two Vectors to be
Message-ID: <295CB338B611594582D82D9F26AEF7060DC6AC@mail02.student.main.ntu.edu.sg>

Hi all,

I am beginner of R. I want to ask for help from you. 

I have two "data.frame" type object : s40 and s100. s40 and s100 have same structure: they are actually two dimention array like : 

V1    V2
34     6768
234   36
65     60
.....

Now s40 and s100 have almost same value in V1, but they lack some value in V1 from each other. What I want to do is to expand them to be same long by inserting those lacking values into V1 of s40 and s50 and the responed value in V2 is 0 or mean of V2. 

Is there any easy way to set this problem down? Any help will be appreciated very much!

	Jia Yiyu



From ripley at stats.ox.ac.uk  Fri Feb 14 09:29:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 14 09:29:03 2003
Subject: [R] Translating lm.object to SQL, C, etc function
In-Reply-To: <20030214080110.0B8F14711F@server2.fastmail.fm>
Message-ID: <Pine.LNX.4.44.0302140807560.16111-100000@gannet.stats>

On Fri, 14 Feb 2003 j+rhelp at howard.fm wrote:

[...]

> Thanks for the suggestion. After my last post I tried switching from
> SPLUS to R and discovered the useful xlevels attribute, which when output

Eh?  S-PLUS has an "xlevels" attribute, but R has an "xlevels" component
(speaks the author of both).

> with expression(), combined with the coefficients attribute, gives me the
> information I need. dump() also provides those things, although it has a
> lot of other stuff not needed to build the prediction function.
> 
> I'll start coding something using this, but it won't be ideal. The two
> problems are:
>  - The variable name / level name are still concatenated with
>    no delimiter in the coefficients, so it's possible there will
>    be ambiguous names
>  - It feels rather clunky to be relying on these attributes when
>    I feel like I should be adding methods directly to the class
>    somehow...

You add methods to functions, not classes, in R.  You could indeed add
generic accessor functions with lm methods, but their absence (and the
lack of documentation of the internal structure) should alert you to the
idea that this is internal structure and not part of a public API.

> In SPLUS I came across a useful attribute 'assign', which has a mapping
> of term names to variables - the same attribute in R doesn't appear to
> provide this information. Is this available somewhere?

Both have an assign *component*, not attribute.  R has a mapping from
model.matrix columns to terms in its assign component: that's not an
accurate description of S-PLUS's component ....

> What approaches are others using to apply their models to data sets where
> S is not available? Has anyone written any convertors of models to other
> languages? Is it possible to compile an expression or model into a DLL or
> COM object and access it that way? I'm aware of the SOAP interface, but
> that doesn't really suit our needs in this case.

As I have just posted, in general this is impossible.  We just send new 
data to R and get back the model matrix (using CORBA at present).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From poizot at cnam.fr  Fri Feb 14 09:56:05 2003
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Fri Feb 14 09:56:05 2003
Subject: [R] Change array size
Message-ID: <200302140951.38672.poizot@cnam.fr>

Hi,
I would like to know if there is a way to change a vector of arbitrary size
to make it fits the nearest upper size multiple of a power of 2.

-- 
Cordialy
----------------------------------------
Emmanuel POIZOT
Cnam/Intechmer
Digue de Collignon
50110 Tourlaville
T?l : (33)(0)2 33 88 73 42
Fax : (33)(0)2 33 88 73 39
-----------------------------------------



From boiko at demogr.mpg.de  Fri Feb 14 10:43:05 2003
From: boiko at demogr.mpg.de (Serge Boiko)
Date: Fri Feb 14 10:43:05 2003
Subject: [R] factorial function
Message-ID: <m2ptpvxi73.fsf@boiko_linux.demogr.mpg.de>

Sorry for the stupid question, but is there the factorial function in
R? I tried to find it using help.search('factorial') but got nothing
appropriate. 
Many thanks, 
-Serge



From rdiaz at cnio.es  Fri Feb 14 10:48:53 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Fri Feb 14 10:48:53 2003
Subject: [R] off topic: sharing of software in the life sciences
Message-ID: <200302141047.15410.rdiaz@cnio.es>

This might be of interest to some people in these lists.
The latest issue of Science (vol 299, 14 Febr. 2003), on p. 990, mentions a 
recent report from the National Academy of Sciences that deals with some 
guidelines for the sharing of data and research materials in the life 
sciences. The NAS report can be accessed from

http://bob.nap.edu/books/0309088593/html/

and the most relevant pages, regarding making code available, are pp. 20-23 
and p. 27.




-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
http://bioinfo.cnio.es/~rdiaz



From Ko-Kang at xtra.co.nz  Fri Feb 14 10:58:03 2003
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Fri Feb 14 10:58:03 2003
Subject: [R] factorial function
References: <m2ptpvxi73.fsf@boiko_linux.demogr.mpg.de>
Message-ID: <006401c2d40f$62e814d0$a43158db@kwan022>

Hi,

----- Original Message -----
From: "Serge Boiko" <boiko at demogr.mpg.de>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, February 14, 2003 11:36 PM
Subject: [R] factorial function


>
> Sorry for the stupid question, but is there the factorial function in
> R? I tried to find it using help.search('factorial') but got nothing
> appropriate.


There isn't.

But there are at least four different ways to do this -- from the S
Programming Workshop (by Dr. Ross Ihaka):

  # Iteration
  fac1 <- function(n) {
    ans <- 1
    for(i in seq(n)) ans <- ans * i
    ans
  }

  # Recursion
  fac2 <- function(n)
    if (n <= 0) 1 else n * fac(n - 1)

  # Vectorised
  fac3 <- function(n)
     prod(seq(n))

  # Special Mathematical Function -- Gamma
  fac4 <- function(n)
     gamma(n+1)

Of these Gamma is probably the most efficient.  Note that the above hasn't
got any debugging codes, you probably want to add them.

Cheers,

Kevin

------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022



From rdiaz at cnio.es  Fri Feb 14 11:10:06 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Fri Feb 14 11:10:06 2003
Subject: [R] factorial function
In-Reply-To: <m2ptpvxi73.fsf@boiko_linux.demogr.mpg.de>
References: <m2ptpvxi73.fsf@boiko_linux.demogr.mpg.de>
Message-ID: <200302141109.22593.rdiaz@cnio.es>

Dear Serge,

For factorial of x, you can use "gamma(x + 1)". Alternatively, you can install 
the gregmisc package which has a "factorial" function that does that (if I 
recall correctly).

Best,




On Friday 14 February 2003 11:36, Serge Boiko wrote:
> Sorry for the stupid question, but is there the factorial function in
> R? I tried to find it using help.search('factorial') but got nothing
> appropriate.
> Many thanks,
> -Serge
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
http://bioinfo.cnio.es/~rdiaz



From Christian.Stratowa at vie.boehringer-ingelheim.com  Fri Feb 14 11:29:02 2003
From: Christian.Stratowa at vie.boehringer-ingelheim.com (Christian.Stratowa@vie.boehringer-ingelheim.com)
Date: Fri Feb 14 11:29:02 2003
Subject: [R] FW: [Fwd: Re: [S] Exact p-values]
Message-ID: <AF7DB4C757D2D2119C080001FA7E56B204944E96@VIEEXCH2.vie.at.bic>

Dear all

Just for fun, I have just downloaded the paper mentioned below and checked
it with R-1.6.1.
Everything is ok with exception of Table 2b, where I get always 1 instead of
0.5:
> pbinom(1e15,2e15,0.5)
[1] 1

Which value should be correct?

Best regards
Christian Stratowa

==============================================
Christian Stratowa, PhD
Boehringer Ingelheim Austria
Dept NCE Lead Discovery - Bioinformatics
Dr. Boehringergasse 5-11
A-1121 Vienna, Austria
Tel.: ++43-1-80105-2470
Fax: ++43-1-80105-2683
email: christian.stratowa at vie.boehringer-ingelheim.com


> -------- Original Message --------
> Subject: Re: [S] Exact p-values
> Date: Thu, 13 Feb 2003 18:31:38 +0100
> From: "Rau, Roland" <Rau at demogr.mpg.de>
> To: 'Spencer Graves' <spencer.graves at PDF.COM>,	Jose Mar?a Fedriani
> Laffitte <fedriani at ebd.csic.es>
> CC: s-news at lists.biostat.wustl.edu
> 
> Dear all,
> 
> in relation to your question, the following working paper of Leo Knuesel,
> University of Munich, might be of interest:
> "On the Accuracy of Statistical Distributions in S-Plus for Windows
> (1999)"
> You can download the paper from (pdf-Format, 45k):
> http://www.stat.uni-muenchen.de/~knuesel/elv/accuracy.html
> 
> Best,
> Roland
> 
>  > -----Original Message-----
>  > From:	Spencer Graves [SMTP:spencer.graves at PDF.COM]
>  > Sent:	Thursday, February 13, 2003 6:12 PM
>  > To:	Jose Mar?a Fedriani Laffitte
>  > Cc:	s-news at lists.biostat.wustl.edu
>  > Subject:	Re: [S] Exact p-values
>  >
>  >
>  > Try ( 1-pchisq(29.8, df=1)):  With S-Plus 6.1, I got  4.78992e-008.
>  >
>  >          By the way, the distribtion functions in R have more
> arguments.
>  >  For example,  pchisq(29.8, df=1, lower.tail=F) produces the same
>  > answer, and pchisq(29.8, df=1, lower.tail=F, log=T) produces its
> natural
>  > logarithm.  Also, pchisq, dchisq, qchisq, and rchisq in R all have an
>  > "ncp" noncentrality parameter argument;  only pchisq has such in S-Plus
>  > 6.1.  Similarly, none of the Student's t functions in S-Plus have a
>  > non-centralitity parameter;  in R, pt has an argument ncp, and from
> this
>  > one can easily program ncp for dt, qt and rt.  Also, the distribution
>  > functions in the current release of S-Plus are known to have problems.
>  >  For example, pt(-1, Inf) = 0.5 in S-Plus 6.1, but 0.159 in R;
> clearly,
>  > S-Plus gives a wrong answer without warning.
>  >
>  > Best Wishes,
>  > Spencer Graves
>  >
>  > Jose Mar?a Fedriani Laffitte wrote:
>  >
>  > >Dear all,
>  > >
>  > >    I want to get the exact p-values, on 1 degree of freedom, for an
>  > array
>  > >of chi-square values.  When my chi-square values are equal or lower
> than
>  > >29.7, I get the exact associated p-values.  Thus, for instance:
>  > >
>  > >
>  > >
>  > >>pchisq(29.7, df=1)
>  > >>
>  > >>
>  > >[1] 0.9999999
>  > >
>  > >However, when my chi-square values are greater or equal to 29.8 what I
>  > get
>  > >is:
>  > >
>  > >
>  > >
>  > >>pchisq(29.8, df=1)
>  > >>
>  > >>
>  > >[1] 1
>  > >
>  > >
>  > >    Could anyone tell me how to fix this trivial issue?  Very
> grateful,
>  > Jose
>  > >M. Fedriani
>  > >
>  > >****************************************
>  > >Jose M? Fedriani Laffitte
>  > >Estacion Biologica de Donana (CSIC)
>  > >Avda. M? Luisa s/n
>  > >41013-Sevilla
>  > >Spain
>  > >Tel. +34-954232340
>  > >Fax +34-954621125
>  > >http://ebd.csic.es
>  > >
>  > >--------------------------------------------------------------------
>  > >This message was distributed by s-news at lists.biostat.wustl.edu.  To
>  > >...(s-news-request clipped)...

>  > >
>  > >
>  >
>  >
>  > --------------------------------------------------------------------
>  > This message was distributed by s-news at lists.biostat.wustl.edu.  To
>  > ...(s-news-request clipped)...

> --------------------------------------------------------------------
> This message was distributed by s-news at lists.biostat.wustl.edu.  To
> ...(s-news-request clipped)...

> 
>



From SchnitzlerJ at rki.de  Fri Feb 14 11:54:02 2003
From: SchnitzlerJ at rki.de (Schnitzler, Johannes)
Date: Fri Feb 14 11:54:02 2003
Subject: [R] time series  missing 0 counts
Message-ID: <3DDCC4D685EE744B9FB47706995CFCD102236174@SEMAIL01.RKI.IVBB.BUND.DE>

> Dear All.
> 
> The problem.
> 
> I have several large data sets with counts per week. 
> (Maximum week per year is 52. Counts from Week 53
> are added to week 52.) 
> 
> A data set contains for example:
> 
> Year	Week	Count
> 2000 	52	2
> 2001	1	5
> 2001	2	7
> 2001	5	4
> 2001	7	2
> ...	...	...
> ...	...	...
> 
> Weeks with 0 counts are not listed in the data set.
> I want to perform time series analysis (frequency 52).
> 
> 
> Is there an easy way to expand the data set to:
> 
> Year	Week	Count
> 2000	52	2
> 2001	1	5
> 2001	2	7
> 2001	3	0
> 2001	4	0
> 2001	5	4
> 2001	6	0
> 2001	7	2
> ...	...	...
> ...	...	...
> 
> or is there already a function in "ts", which i have not found so far,
> to deal with this problem?
> 
> 
> Thank you very much.
> 
> Johannes Schnitzler
> Germany Berlin
> 
>  
>



From andrejk at zrc-sazu.si  Fri Feb 14 12:15:09 2003
From: andrejk at zrc-sazu.si (Andrej Kveder)
Date: Fri Feb 14 12:15:09 2003
Subject: [R] two lme questions
Message-ID: <FDEAIKIBHNNFHKGBBPJHIEFNCAAA.andrejk@zrc-sazu.si>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030214/63ccb999/attachment.pl

From andy_liaw at merck.com  Fri Feb 14 12:20:13 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Feb 14 12:20:13 2003
Subject: [R] Change array size
Message-ID: <3A822319EB35174CA3714066D590DCD534BCAC@usrymx25.merck.com>

Is the following what you want?

> x<- rnorm(800)
> xt <- x[1:2^trunc(log(length(x),base=2))]
> length(xt)
[1] 512

HTH,
Andy

> -----Original Message-----
> From: Poizot Emmanuel [mailto:poizot at cnam.fr]
> Sent: Friday, February 14, 2003 4:52 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Change array size
> 
> 
> Hi,
> I would like to know if there is a way to change a vector of 
> arbitrary size
> to make it fits the nearest upper size multiple of a power of 2.
> 
> -- 
> Cordialy
> ----------------------------------------
> Emmanuel POIZOT
> Cnam/Intechmer
> Digue de Collignon
> 50110 Tourlaville
> T?l : (33)(0)2 33 88 73 42
> Fax : (33)(0)2 33 88 73 39
> -----------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From ripley at stats.ox.ac.uk  Fri Feb 14 12:24:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 14 12:24:02 2003
Subject: [R] time series  missing 0 counts
In-Reply-To: <3DDCC4D685EE744B9FB47706995CFCD102236174@SEMAIL01.RKI.IVBB.BUND.DE>
Message-ID: <Pine.LNX.4.44.0302141114130.16334-100000@gannet.stats>

Yes, there is an easy way.  Create the regular time series you want by 
something like

x <- ts(0, start=c(2000,52), end=c(2003,9), frequency=52)

and fill in the time points you have data for by

xYear <- trunc(times(x)); xWeek <- cycle(x)
attach(mydata)
x[(xYear==year) & (xWeek==Week)] <- Count
detach()

Easy!

On Fri, 14 Feb 2003, Schnitzler, Johannes wrote:

> > I have several large data sets with counts per week. 
> > (Maximum week per year is 52. Counts from Week 53
> > are added to week 52.) 
> > 
> > A data set contains for example:
> > 
> > Year	Week	Count
> > 2000 	52	2
> > 2001	1	5
> > 2001	2	7
> > 2001	5	4
> > 2001	7	2
> > ...	...	...
> > ...	...	...
> > 
> > Weeks with 0 counts are not listed in the data set.
> > I want to perform time series analysis (frequency 52).
> > 
> > 
> > Is there an easy way to expand the data set to:
> > 
> > Year	Week	Count
> > 2000	52	2
> > 2001	1	5
> > 2001	2	7
> > 2001	3	0
> > 2001	4	0
> > 2001	5	4
> > 2001	6	0
> > 2001	7	2
> > ...	...	...
> > ...	...	...
> > 
> > or is there already a function in "ts", which i have not found so far,
> > to deal with this problem?
> > 
> > 
> > Thank you very much.
> > 
> > Johannes Schnitzler
> > Germany Berlin
> > 
> >  
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fharrell at virginia.edu  Fri Feb 14 12:53:02 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri Feb 14 12:53:02 2003
Subject: [R] Translating lm.object to SQL, C, etc function
In-Reply-To: <20030214053742.87AAA46CA7@server2.fastmail.fm>
References: <20030214053742.87AAA46CA7@server2.fastmail.fm>
Message-ID: <20030214065157.230a5a01.fharrell@virginia.edu>

On Fri, 14 Feb 2003 16:37:42 +1100
j+rhelp at howard.fm wrote:

> This is my first post to this list so I suppose a quick intro is in
> order. I've been using SPLUS 2000 and R1.6.2 for just a couple of days,
> and love S already. I'm reading MASS and also John Fox's book - both have
> been very useful. My background in stat software was mainly SPSS (which
> I've never much liked - thanks heavens I've found S!), and Perl is my
> tool of choice for general-purpose programming (I chaired the
> perl6-language-data working group, responsible for improving the data
> analysis capabilities in Perl).
> 
> I have just completed my first S project, and I now have 8 lm.objects.
> The models are all reasonably complex with multiple numeric and factor
> variables and some 2-way and 3-way interactions. I now need to use these
> models in other environments, such as C code, SQL functions (using CASE)
> and in Perl - I can not work out how to do this.
> 
> The difficulty I am having is that the output of coef() is not really
> parsable, since there is no marker in the name of an coefficient of
> separate out the components. For instance, in SPSS the name of a
> coefficient might be:
> 
>   var1=[a]*var2=[b]*var3
> 
> ...which is easy to write a little script to pull that apart and turn it
> into a line of SQL, C, or whatever. In S however the name looks like:
> 
>   var1avar2bvar3
> 
> ...which provides no way to pull the bits apart.
> 
> So my question is, how do I export an lm.object in some form that I can
> then apply to prediction in C, SQL, or some other language? All I'm
> looking for is some well-structured textual or data frame output that I
> can then manipulate with appropriate tools, whether it be S itself, or
> something like Perl.
> 
> Thanks in advance for any suggestions (and apologies in advance if this
> is well documented somewhere!),
> 
>   Jeremy
> 


Some functions that may give you some ideas, from the Design library (http://hesweb1.med.virginia.edu/biostat/s/Design.html).:

Function(fit): generate S function to obtain predicted values from a regression fit that was done with Design in effect (i.e., fit with ols, cph, lrm, psm, glmD)

latex(fit): generate LaTeX code for typesetting the model fit

sascode(Function(fit)): translate formula to SAS notation

What I think would be very useful would be a function like Function that instead symbolically creates the design matrix, and translating that function to SQL etc.  This would allow computation of confidence limits.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From spencer.graves at pdf.com  Fri Feb 14 13:10:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 14 13:10:03 2003
Subject: [R] How to keep two Vectors to be
References: <295CB338B611594582D82D9F26AEF7060DC6AC@mail02.student.main.ntu.edu.sg>
Message-ID: <3E4CDC1F.9090001@pdf.com>

Have you considered "merge"?

#JIA YIYU# wrote:
> Hi all,
> 
> I am beginner of R. I want to ask for help from you. 
> 
> I have two "data.frame" type object : s40 and s100. s40 and s100 have same structure: they are actually two dimention array like : 
> 
> V1    V2
> 34     6768
> 234   36
> 65     60
> .....
> 
> Now s40 and s100 have almost same value in V1, but they lack some value in V1 from each other. What I want to do is to expand them to be same long by inserting those lacking values into V1 of s40 and s50 and the responed value in V2 is 0 or mean of V2. 
> 
> Is there any easy way to set this problem down? Any help will be appreciated very much!
> 
> 	Jia Yiyu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From spencer.graves at pdf.com  Fri Feb 14 13:30:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 14 13:30:03 2003
Subject: [R] FW: [Fwd: Re: [S] Exact p-values]
References: <AF7DB4C757D2D2119C080001FA7E56B204944E96@VIEEXCH2.vie.at.bic>
Message-ID: <3E4CE10C.7060800@pdf.com>

To understand the correct answer, you need to understand the following:

 > pbinom(1, 2, .5)
[1] 0.75

This is the binomial cumulative distribution function.
*** pbinom(0, 2, .5) = 0.25
*** pbinom(1, 2, .5) = 0.75 = 0.25 + 0.5
*** pbinom(2, 2, .5) = 1

However, pbinom(1e15, 2e15, .5) is a computational challenge.  Standard 
numerical algorithms often fail in situations like this.  The code 
should test for such cases and use more numerically stable 
"approximations" in place of the "exact" algorithms.

The standard deviation for a binomial is sqrt(p*(1-p)/n) = 
0.5/sqrt(2e15), which is roughly 1e-8 in your case.


I get the following from both S-Plus and R:

 > pbinom(1e5+c(-1, 0, 1), 2e5, .5)
[1] 0.4991079 0.5008921 0.5026762

For the problem you cite, the correct answer should be 0.5 to about 8 
significant digits.  Instead, I get 1 from R (as you did) and the 
following from S-Plus:

 > pbinom(1e15,2e15,0.5)
[1] 0.7411209

Both give wrong answers without warning, though in this case, S-Plus is 
closer.

Answer the question?
Spencer Graves
#####################

Christian.Stratowa at vie.boehringer-ingelheim.com wrote:
> Dear all
> 
> Just for fun, I have just downloaded the paper mentioned below and checked
> it with R-1.6.1.
> Everything is ok with exception of Table 2b, where I get always 1 instead of
> 0.5:
> 
>>pbinom(1e15,2e15,0.5)
> 
> [1] 1
> 
> Which value should be correct?
> 
> Best regards
> Christian Stratowa
> 
> ==============================================
> Christian Stratowa, PhD
> Boehringer Ingelheim Austria
> Dept NCE Lead Discovery - Bioinformatics
> Dr. Boehringergasse 5-11
> A-1121 Vienna, Austria
> Tel.: ++43-1-80105-2470
> Fax: ++43-1-80105-2683
> email: christian.stratowa at vie.boehringer-ingelheim.com
> 
> 
> 
>>-------- Original Message --------
>>Subject: Re: [S] Exact p-values
>>Date: Thu, 13 Feb 2003 18:31:38 +0100
>>From: "Rau, Roland" <Rau at demogr.mpg.de>
>>To: 'Spencer Graves' <spencer.graves at PDF.COM>,	Jose Mar?a Fedriani
>>Laffitte <fedriani at ebd.csic.es>
>>CC: s-news at lists.biostat.wustl.edu
>>
>>Dear all,
>>
>>in relation to your question, the following working paper of Leo Knuesel,
>>University of Munich, might be of interest:
>>"On the Accuracy of Statistical Distributions in S-Plus for Windows
>>(1999)"
>>You can download the paper from (pdf-Format, 45k):
>>http://www.stat.uni-muenchen.de/~knuesel/elv/accuracy.html
>>
>>Best,
>>Roland
>>
>> > -----Original Message-----
>> > From:	Spencer Graves [SMTP:spencer.graves at PDF.COM]
>> > Sent:	Thursday, February 13, 2003 6:12 PM
>> > To:	Jose Mar?a Fedriani Laffitte
>> > Cc:	s-news at lists.biostat.wustl.edu
>> > Subject:	Re: [S] Exact p-values
>> >
>> >
>> > Try ( 1-pchisq(29.8, df=1)):  With S-Plus 6.1, I got  4.78992e-008.
>> >
>> >          By the way, the distribtion functions in R have more
>>arguments.
>> >  For example,  pchisq(29.8, df=1, lower.tail=F) produces the same
>> > answer, and pchisq(29.8, df=1, lower.tail=F, log=T) produces its
>>natural
>> > logarithm.  Also, pchisq, dchisq, qchisq, and rchisq in R all have an
>> > "ncp" noncentrality parameter argument;  only pchisq has such in S-Plus
>> > 6.1.  Similarly, none of the Student's t functions in S-Plus have a
>> > non-centralitity parameter;  in R, pt has an argument ncp, and from
>>this
>> > one can easily program ncp for dt, qt and rt.  Also, the distribution
>> > functions in the current release of S-Plus are known to have problems.
>> >  For example, pt(-1, Inf) = 0.5 in S-Plus 6.1, but 0.159 in R;
>>clearly,
>> > S-Plus gives a wrong answer without warning.
>> >
>> > Best Wishes,
>> > Spencer Graves
>> >
>> > Jose Mar?a Fedriani Laffitte wrote:
>> >
>> > >Dear all,
>> > >
>> > >    I want to get the exact p-values, on 1 degree of freedom, for an
>> > array
>> > >of chi-square values.  When my chi-square values are equal or lower
>>than
>> > >29.7, I get the exact associated p-values.  Thus, for instance:
>> > >
>> > >
>> > >
>> > >>pchisq(29.7, df=1)
>> > >>
>> > >>
>> > >[1] 0.9999999
>> > >
>> > >However, when my chi-square values are greater or equal to 29.8 what I
>> > get
>> > >is:
>> > >
>> > >
>> > >
>> > >>pchisq(29.8, df=1)
>> > >>
>> > >>
>> > >[1] 1
>> > >
>> > >
>> > >    Could anyone tell me how to fix this trivial issue?  Very
>>grateful,
>> > Jose
>> > >M. Fedriani
>> > >
>> > >****************************************
>> > >Jose M? Fedriani Laffitte
>> > >Estacion Biologica de Donana (CSIC)
>> > >Avda. M? Luisa s/n
>> > >41013-Sevilla
>> > >Spain
>> > >Tel. +34-954232340
>> > >Fax +34-954621125
>> > >http://ebd.csic.es
>> > >
>> > >--------------------------------------------------------------------
>> > >This message was distributed by s-news at lists.biostat.wustl.edu.  To
>> > >...(s-news-request clipped)...
> 
> 
>> > >
>> > >
>> >
>> >
>> > --------------------------------------------------------------------
>> > This message was distributed by s-news at lists.biostat.wustl.edu.  To
>> > ...(s-news-request clipped)...
> 
> 
>>--------------------------------------------------------------------
>>This message was distributed by s-news at lists.biostat.wustl.edu.  To
>>...(s-news-request clipped)...
> 
> 
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Christian.Stratowa at vie.boehringer-ingelheim.com  Fri Feb 14 13:35:04 2003
From: Christian.Stratowa at vie.boehringer-ingelheim.com (Christian.Stratowa@vie.boehringer-ingelheim.com)
Date: Fri Feb 14 13:35:04 2003
Subject: [R] FW: [Fwd: Re: [S] Exact p-values]
Message-ID: <AF7DB4C757D2D2119C080001FA7E56B204944E97@VIEEXCH2.vie.at.bic>

Dear Spencer

Thank you for this extensive explanation of the problem.
I was just curious.

Best regards
Christian

==============================================
Christian Stratowa, PhD
Boehringer Ingelheim Austria
Dept NCE Lead Discovery - Bioinformatics
Dr. Boehringergasse 5-11
A-1121 Vienna, Austria
Tel.: ++43-1-80105-2470
Fax: ++43-1-80105-2683
email: christian.stratowa at vie.boehringer-ingelheim.com

> -----Original Message-----
> From:	Spencer Graves [SMTP:spencer.graves at PDF.COM]
> Sent:	Friday, February 14, 2003 1:29 PM
> To:	Stratowa,Dr,Christian   FEX BIG-AT-V
> Cc:	r-help at stat.math.ethz.ch; David Smith
> Subject:	Re: [R] FW: [Fwd: Re: [S] Exact p-values]
> 
> To understand the correct answer, you need to understand the following:
> 
>  > pbinom(1, 2, .5)
> [1] 0.75
> 
> This is the binomial cumulative distribution function.
> *** pbinom(0, 2, .5) = 0.25
> *** pbinom(1, 2, .5) = 0.75 = 0.25 + 0.5
> *** pbinom(2, 2, .5) = 1
> 
> However, pbinom(1e15, 2e15, .5) is a computational challenge.  Standard 
> numerical algorithms often fail in situations like this.  The code 
> should test for such cases and use more numerically stable 
> "approximations" in place of the "exact" algorithms.
> 
> The standard deviation for a binomial is sqrt(p*(1-p)/n) = 
> 0.5/sqrt(2e15), which is roughly 1e-8 in your case.
> 
> 
> I get the following from both S-Plus and R:
> 
>  > pbinom(1e5+c(-1, 0, 1), 2e5, .5)
> [1] 0.4991079 0.5008921 0.5026762
> 
> For the problem you cite, the correct answer should be 0.5 to about 8 
> significant digits.  Instead, I get 1 from R (as you did) and the 
> following from S-Plus:
> 
>  > pbinom(1e15,2e15,0.5)
> [1] 0.7411209
> 
> Both give wrong answers without warning, though in this case, S-Plus is 
> closer.
> 
> Answer the question?
> Spencer Graves
> #####################
> 
> Christian.Stratowa at vie.boehringer-ingelheim.com wrote:
> > Dear all
> > 
> > Just for fun, I have just downloaded the paper mentioned below and
> checked
> > it with R-1.6.1.
> > Everything is ok with exception of Table 2b, where I get always 1
> instead of
> > 0.5:
> > 
> >>pbinom(1e15,2e15,0.5)
> > 
> > [1] 1
> > 
> > Which value should be correct?
> > 
> > Best regards
> > Christian Stratowa
> > 
> > ==============================================
> > Christian Stratowa, PhD
> > Boehringer Ingelheim Austria
> > Dept NCE Lead Discovery - Bioinformatics
> > Dr. Boehringergasse 5-11
> > A-1121 Vienna, Austria
> > Tel.: ++43-1-80105-2470
> > Fax: ++43-1-80105-2683
> > email: christian.stratowa at vie.boehringer-ingelheim.com
> > 
> > 
> > 
> >>-------- Original Message --------
> >>Subject: Re: [S] Exact p-values
> >>Date: Thu, 13 Feb 2003 18:31:38 +0100
> >>From: "Rau, Roland" <Rau at demogr.mpg.de>
> >>To: 'Spencer Graves' <spencer.graves at PDF.COM>,	Jose Mar?a Fedriani
> >>Laffitte <fedriani at ebd.csic.es>
> >>CC: s-news at lists.biostat.wustl.edu
> >>
> >>Dear all,
> >>
> >>in relation to your question, the following working paper of Leo
> Knuesel,
> >>University of Munich, might be of interest:
> >>"On the Accuracy of Statistical Distributions in S-Plus for Windows
> >>(1999)"
> >>You can download the paper from (pdf-Format, 45k):
> >>http://www.stat.uni-muenchen.de/~knuesel/elv/accuracy.html
> >>
> >>Best,
> >>Roland
> >>
> >> > -----Original Message-----
> >> > From:	Spencer Graves [SMTP:spencer.graves at PDF.COM]
> >> > Sent:	Thursday, February 13, 2003 6:12 PM
> >> > To:	Jose Mar?a Fedriani Laffitte
> >> > Cc:	s-news at lists.biostat.wustl.edu
> >> > Subject:	Re: [S] Exact p-values
> >> >
> >> >
> >> > Try ( 1-pchisq(29.8, df=1)):  With S-Plus 6.1, I got  4.78992e-008.
> >> >
> >> >          By the way, the distribtion functions in R have more
> >>arguments.
> >> >  For example,  pchisq(29.8, df=1, lower.tail=F) produces the same
> >> > answer, and pchisq(29.8, df=1, lower.tail=F, log=T) produces its
> >>natural
> >> > logarithm.  Also, pchisq, dchisq, qchisq, and rchisq in R all have an
> >> > "ncp" noncentrality parameter argument;  only pchisq has such in
> S-Plus
> >> > 6.1.  Similarly, none of the Student's t functions in S-Plus have a
> >> > non-centralitity parameter;  in R, pt has an argument ncp, and from
> >>this
> >> > one can easily program ncp for dt, qt and rt.  Also, the distribution
> >> > functions in the current release of S-Plus are known to have
> problems.
> >> >  For example, pt(-1, Inf) = 0.5 in S-Plus 6.1, but 0.159 in R;
> >>clearly,
> >> > S-Plus gives a wrong answer without warning.
> >> >
> >> > Best Wishes,
> >> > Spencer Graves
> >> >
> >> > Jose Mar?a Fedriani Laffitte wrote:
> >> >
> >> > >Dear all,
> >> > >
> >> > >    I want to get the exact p-values, on 1 degree of freedom, for an
> >> > array
> >> > >of chi-square values.  When my chi-square values are equal or lower
> >>than
> >> > >29.7, I get the exact associated p-values.  Thus, for instance:
> >> > >
> >> > >
> >> > >
> >> > >>pchisq(29.7, df=1)
> >> > >>
> >> > >>
> >> > >[1] 0.9999999
> >> > >
> >> > >However, when my chi-square values are greater or equal to 29.8 what
> I
> >> > get
> >> > >is:
> >> > >
> >> > >
> >> > >
> >> > >>pchisq(29.8, df=1)
> >> > >>
> >> > >>
> >> > >[1] 1
> >> > >
> >> > >
> >> > >    Could anyone tell me how to fix this trivial issue?  Very
> >>grateful,
> >> > Jose
> >> > >M. Fedriani
> >> > >
> >> > >****************************************
> >> > >Jose M? Fedriani Laffitte
> >> > >Estacion Biologica de Donana (CSIC)
> >> > >Avda. M? Luisa s/n
> >> > >41013-Sevilla
> >> > >Spain
> >> > >Tel. +34-954232340
> >> > >Fax +34-954621125
> >> > >http://ebd.csic.es
> >> > >
> >> > >--------------------------------------------------------------------
> >> > >This message was distributed by s-news at lists.biostat.wustl.edu.  To
> >> > >...(s-news-request clipped)...
> > 
> > 
> >> > >
> >> > >
> >> >
> >> >
> >> > --------------------------------------------------------------------
> >> > This message was distributed by s-news at lists.biostat.wustl.edu.  To
> >> > ...(s-news-request clipped)...
> > 
> > 
> >>--------------------------------------------------------------------
> >>This message was distributed by s-news at lists.biostat.wustl.edu.  To
> >>...(s-news-request clipped)...
> > 
> > 
> >>
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Fri Feb 14 13:48:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 14 13:48:02 2003
Subject: [R] FW: [Fwd: Re: [S] Exact p-values]
In-Reply-To: <3E4CE10C.7060800@pdf.com>
Message-ID: <Pine.LNX.4.44.0302141239200.16470-100000@gannet.stats>

On Fri, 14 Feb 2003, Spencer Graves wrote:

> To understand the correct answer, you need to understand the following:
> 
>  > pbinom(1, 2, .5)
> [1] 0.75
> 
> This is the binomial cumulative distribution function.
> *** pbinom(0, 2, .5) = 0.25
> *** pbinom(1, 2, .5) = 0.75 = 0.25 + 0.5
> *** pbinom(2, 2, .5) = 1
> 
> However, pbinom(1e15, 2e15, .5) is a computational challenge.  Standard 
> numerical algorithms often fail in situations like this.  The code 
> should test for such cases and use more numerically stable 
> "approximations" in place of the "exact" algorithms.

Another point of view is that people should do the 2e15 trials first, and 
then worry about what their software will give when they have finished 
... that is an awfully large number of trials.

Of course software `should' be perfect, even free software, but the
developers are told several times a day on R-help what they `should' do,
which seems mean-spirited.  The constructive thing to do would be to 
submit a fully-tested patch.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Fri Feb 14 13:54:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Fri Feb 14 13:54:03 2003
Subject: [R] Translating lm.object to SQL, C, etc function
In-Reply-To: <20030214053742.87AAA46CA7@server2.fastmail.fm>
Message-ID: <5.1.0.14.2.20030214074620.01e4db18@mcmail.cis.mcmaster.ca>

Dear Jeremy,

I've written replacements for the standard R contrast functions that 
produce the kind of more easily parsed (and more readable) contrast names 
that I think you have in mind. I intend to include these in the next 
release of the car package for R but haven't done so yet. Since the code 
isn't very long, I've appended it (and the .Rd documentation file to this 
note). Note that R does separate terms in an interaction with a colon.

I hope that this does what you need.
  John

---------------------------- Contrasts.R -----------------------------

# last modified 2 Dec 2002 by J. Fox
# all of these functions are adapted from functions in the R base package

contr.Treatment <- function (n, base = 1, contrasts = TRUE) {
     if (is.numeric(n) && length(n) == 1)
         levs <- 1:n
     else {
         levs <- n
         n <- length(n)
     }
     lev.opt <- getOption("decorate.contrasts")
     pre <- if (is.null(lev.opt)) "[" else lev.opt[1]
     suf <- if (is.null(lev.opt)) "]" else lev.opt[2]
     dec <- getOption("decorate.contr.Treatment")
     dec <- if (!contrasts) ""
            else if (is.null(dec)) "T."
            else dec
     contr.names <- paste(pre, dec, levs, suf, sep="")
     contr <- array(0, c(n, n), list(levs, contr.names))
     diag(contr) <- 1
     if (contrasts) {
         if (n < 2)
             stop(paste("Contrasts not defined for", n - 1, "degrees of 
freedom"))
         if (base < 1 | base > n)
             stop("Baseline group number out of range")
         contr <- contr[, -base, drop = FALSE]
     }
     contr
}

contr.Sum <- function (n, contrasts = TRUE)
{
     if (length(n) <= 1) {
         if (is.numeric(n) && length(n) == 1 && n > 1)
             levels <- 1:n
         else stop("Not enough degrees of freedom to define contrasts")
     }
     else levels <- n
     lenglev <- length(levels)
     lev.opt <- getOption("decorate.contrasts")
     pre <- if (is.null(lev.opt)) "[" else lev.opt[1]
     suf <- if (is.null(lev.opt)) "]" else lev.opt[2]
     dec <- getOption("decorate.contr.Sum")
     dec <- if (!contrasts) ""
            else if (is.null(dec)) "S."
            else dec
     show.lev <- getOption("contr.Sum.show.levels")
     contr.names <- if ((is.null(show.lev)) || show.lev) paste(pre, dec, 
levels, suf, sep="")
     if (contrasts) {
         cont <- array(0, c(lenglev, lenglev - 1), list(levels,
             contr.names[-lenglev]))
         cont[col(cont) == row(cont)] <- 1
         cont[lenglev, ] <- -1
     }
     else {
         cont <- array(0, c(lenglev, lenglev), list(levels,
             contr.names))
         cont[col(cont) == row(cont)] <- 1
     }
     cont
}


contr.Helmert <- function (n, contrasts = TRUE)
{
     if (length(n) <= 1) {
         if (is.numeric(n) && length(n) == 1 && n > 1)
             levels <- 1:n
         else stop("contrasts are not defined for 0 degrees of freedom")
     }
     else levels <- n
     lenglev <- length(levels)
     lev.opt <- getOption("decorate.contrasts")
     pre <- if (is.null(lev.opt)) "[" else lev.opt[1]
     suf <- if (is.null(lev.opt)) "]" else lev.opt[2]
     dec <- getOption("decorate.contr.Helmert")
     dec <- if (!contrasts) ""
            else if (is.null(dec)) "H."
            else dec
     nms <- if (contrasts) 1:lenglev else levels
     contr.names <- paste(pre, dec, nms, suf, sep="")
     if (contrasts) {
         cont <- array(-1, c(lenglev, lenglev - 1), list(levels,
             contr.names[-lenglev]))
         cont[col(cont) <= row(cont) - 2] <- 0
         cont[col(cont) == row(cont) - 1] <- 1:(lenglev - 1)
     }
     else {
         cont <- array(0, c(lenglev, lenglev), list(levels, contr.names))
         cont[col(cont) == row(cont)] <- 1
     }
     cont
}

------------------------------- Contrasts.Rd 
------------------------------------------

\name{Contrasts}
\alias{Contrasts}
\alias{contr.Treatment}
\alias{contr.Sum}
\alias{contr.Helmert}

\title{Functions to Construct Contrasts}
\description{
     These are substitutes for similarly named functions in the base package
     (note the uppercase letter starting the second word in each function 
name).
     The only difference is that the contrast functions from the car package
     produce easier-to-read names for the contrasts when they are used in 
statistical models.

     The functions and this documentation are adapted from the base package.
     }

\usage{
contr.Treatment(n, base = 1, contrasts = TRUE)

contr.Sum(n, contrasts = TRUE)

contr.Helmert(n, contrasts = TRUE)
}

\arguments{
   \item{n}{a vector of levels for a factor, or the number of levels.}
   \item{base}{an integer specifying which level is considered the baseline 
level.
     Ignored if \code{contrasts} is \code{FALSE}.}
   \item{contrasts}{a logical indicating whether contrasts should be computed.}
}

\details{
     These functions are used for creating contrast matrices for use in 
fitting analysis of variance and regression models.
     The columns of the resulting matrices contain contrasts which can be 
used for coding a factor with \code{n} levels.
     The returned value contains the computed contrasts. If the argument 
\code{contrasts} is \code{FALSE} then a square matrix is returned.

     Several aspects of these contrast functions are controlled by options 
set via the \code{options} command:
     \describe{
         \item{\code{decorate.contrasts}}{This option should be set to a 
2-element character vector containing the prefix and suffix
             characters to surround contrast names. If the option is not 
set, then \code{c("[", "]")} is used. For example, setting
             \code{options(decorate.contrasts=c(".", ""))} produces 
contrast names that are separated from factor names by a period.
             Setting \code{options(decorate.contrasts=c("", ""))} 
reproduces the behaviour of the R base contrast functions.}
         \item{\code{decorate.contr.Treatment}}{A character string to be 
appended to contrast names to signify treatment contrasts;
             if the option is unset, then \code{"T."} is used.}
         \item{\code{decorate.contr.Sum}}{Similar to the above, with 
default \code{"S."}.}
         \item{\code{decorate.contr.Helmert}}{Similar to the above, with 
default \code{"H."}.}
         \item{\code{contr.Sum.show.levels}}{Logical value: if \code{TRUE} 
(the default if unset),
             then level names are used for contrasts; if \code{FALSE}, then 
numbers are used, as in \code{contr.sum}
             in the \code{base} package.}
         }

     Note that there is no replacement for \code{contr.poly} in the 
\code{base} package (which produces
     orthogonal-polynomial contrasts) since this function already 
constructs easy-to-read contrast names.
}

\value{
     A matrix with \code{n} rows and \code{k} columns, with \code{k = n - 
1} if \code{contrasts} is \code{TRUE}
     and \code{k = n} if \code{contrasts} is \code{FALSE}.
}

\author{John Fox \email{jfox at mcmaster.ca}}

\seealso{\code{\link[base]{contr.treatment}}, \code{\link[base]{contr.sum}},
   \code{\link[base]{contr.helmert}}, \code{\link[base]{contr.poly}} }

\examples{
# contr.Treatment vs. contr.treatment in the base package:

data(Prestige)
lm(prestige ~ (income + education)*type, data=Prestige,
     contrasts=list(type="contr.Treatment"))

##  Call:
##  lm(formula = prestige ~ (income + education) * type, data = Prestige,
##      contrasts = list(type = "contr.Treatment"))
##
##  Coefficients:
##          (Intercept)                  income               education
##              2.275753                0.003522                1.713275
##          type[T.prof]              type[T.wc]     income:type[T.prof]
##              15.351896              -33.536652               -0.002903
##      income:type[T.wc]  education:type[T.prof]    education:type[T.wc]
##              -0.002072                1.387809                4.290875

lm(prestige ~ (income + education)*type, data=Prestige,
     contrasts=list(type="contr.treatment"))

##  Call:
##  lm(formula = prestige ~ (income + education) * type, data = Prestige,
##      contrasts = list(type = "contr.treatment"))
##
##  Coefficients:
##      (Intercept)              income           education
##          2.275753            0.003522            1.713275
##          typeprof              typewc     income:typeprof
##          15.351896          -33.536652           -0.002903
##      income:typewc  education:typeprof    education:typewc
##          -0.002072            1.387809            4.290875
}

\keyword{models}
\keyword{regression}

-------------------------------------------------------------------------------------------------------------------------------------------------

At 04:37 PM 2/14/2003 +1100, j+rhelp at howard.fm wrote:
>This is my first post to this list so I suppose a quick intro is in
>order. I've been using SPLUS 2000 and R1.6.2 for just a couple of days,
>and love S already. I'm reading MASS and also John Fox's book - both have
>been very useful. My background in stat software was mainly SPSS (which
>I've never much liked - thanks heavens I've found S!), and Perl is my
>tool of choice for general-purpose programming (I chaired the
>perl6-language-data working group, responsible for improving the data
>analysis capabilities in Perl).
>
>I have just completed my first S project, and I now have 8 lm.objects.
>The models are all reasonably complex with multiple numeric and factor
>variables and some 2-way and 3-way interactions. I now need to use these
>models in other environments, such as C code, SQL functions (using CASE)
>and in Perl - I can not work out how to do this.
>
>The difficulty I am having is that the output of coef() is not really
>parsable, since there is no marker in the name of an coefficient of
>separate out the components. For instance, in SPSS the name of a
>coefficient might be:
>
>   var1=[a]*var2=[b]*var3
>
>...which is easy to write a little script to pull that apart and turn it
>into a line of SQL, C, or whatever. In S however the name looks like:
>
>   var1avar2bvar3
>
>...which provides no way to pull the bits apart.
>
>So my question is, how do I export an lm.object in some form that I can
>then apply to prediction in C, SQL, or some other language? All I'm
>looking for is some well-structured textual or data frame output that I
>can then manipulate with appropriate tools, whether it be S itself, or
>something like Perl.
>
>Thanks in advance for any suggestions (and apologies in advance if this
>is well documented somewhere!),



From spencer.graves at pdf.com  Fri Feb 14 13:57:27 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 14 13:57:27 2003
Subject: [R] FW: [Fwd: Re: [S] Exact p-values]
References: <Pine.LNX.4.44.0302141239200.16470-100000@gannet.stats>
Message-ID: <3E4CE6A4.5060803@pdf.com>

Dear Prof. Ripley:

Thanks for your reply.  You are absolutely correct.  I have only started 
working with R recently, and I have been absolutely awed by what you all 
have done with it.

Thanks again for your very impressive contributions to the profession, 
both in your publications and in R.

Sincerely,
Spencer Graves

ripley at stats.ox.ac.uk wrote:
> On Fri, 14 Feb 2003, Spencer Graves wrote:
> 
> 
>>To understand the correct answer, you need to understand the following:
>>
>> > pbinom(1, 2, .5)
>>[1] 0.75
>>
>>This is the binomial cumulative distribution function.
>>*** pbinom(0, 2, .5) = 0.25
>>*** pbinom(1, 2, .5) = 0.75 = 0.25 + 0.5
>>*** pbinom(2, 2, .5) = 1
>>
>>However, pbinom(1e15, 2e15, .5) is a computational challenge.  Standard 
>>numerical algorithms often fail in situations like this.  The code 
>>should test for such cases and use more numerically stable 
>>"approximations" in place of the "exact" algorithms.
> 
> 
> Another point of view is that people should do the 2e15 trials first, and 
> then worry about what their software will give when they have finished 
> ... that is an awfully large number of trials.
> 
> Of course software `should' be perfect, even free software, but the
> developers are told several times a day on R-help what they `should' do,
> which seems mean-spirited.  The constructive thing to do would be to 
> submit a fully-tested patch.
>



From p.dalgaard at biostat.ku.dk  Fri Feb 14 14:48:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Feb 14 14:48:03 2003
Subject: [R] Change array size
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BCAC@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD534BCAC@usrymx25.merck.com>
Message-ID: <x2isvnj7lo.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> Is the following what you want?
> 
> > x<- rnorm(800)
> > xt <- x[1:2^trunc(log(length(x),base=2))]
> > length(xt)
> [1] 512

I don't think so (notice "upper"). More likely

x <- rnorm(800)
l <- length(x)
xt <- c(x,numeric(2^ceiling(log(l,base=2))-l))
length(xt) # 1024

but "fits" might also imply interpolation?

> > Hi,
> > I would like to know if there is a way to change a vector of 
> > arbitrary size
> > to make it fits the nearest upper size multiple of a power of 2.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From luke at stat.uiowa.edu  Fri Feb 14 15:39:02 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri Feb 14 15:39:02 2003
Subject: [R] data manipulation function descriptions
In-Reply-To: <Pine.LNX.4.44.0302140735510.16111-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0302140704570.6964-100000@nokomis2.stat.umn.edu>

On Fri, 14 Feb 2003 ripley at stats.ox.ac.uk wrote:

> On Thu, 13 Feb 2003, kjetil brinchmann halvorsen wrote:
> 
> > On 13 Feb 2003 at 17:09, Jason Bond wrote:
> 
> > > case                          switch
> >                                     [R-core : switch should be better 
> >                                                announced. It is for   
> >                                                 instance not     
> >                                                  mentioned in "An 
> >                                                   introduction to R"]
> 
> Well, that is an *introduction*, not a programmer's guide.  You will find
> switch() is rarely used in R: it is a bit peculiar in its semantics, and 
> something definitely not to be considered introductory.
> 
> On the original question, I think it would be a mistake to translate what
> you know.  R is a vector language, not a pairlist language, and I see
> quite a bit of evidence of convoluted solutions in its internals dating
> from when R was the second.  Chapter 2 of Venables & Ripley (2002) (as in
> the R FAQ) is devoted to using S/R for data manipulation.

As someone reasonably familiar with both languages I have to disagree
with several points here.  First and foremost, despite differences in
surface syntax, as languages xlispstat and R are much more alike than
they are different.  xlispstat is much closer to R than S-plus because
both xlispstat and R use lexical scope, a feature of R that is still
not used as much as it could be.  The main language differences are
the limited form of lazy evaluation used in R, which you can usully
ignore, and the fact that R does not provide mutable data structures,
which is also rarely an issue.  There are other differences, but these
are the main ones that affect coding practices I think.

The basic xlispstat data handling functions mentioned in the original
post are quite similar to corresponding basic functions in R.  This is
not by accident: the choice of functions included in xlispstat was
heavily influenced by what was then called the "New S" language.  As a
result, if you want to create an R version of an xlispstat function
you can often do far worse than start with a fairly direct
transliteration.  In my view at least, good coding practices in
xlispstat are good coding practices for any high level mostly
functional language and carry over quite well to R.

I am sorry if the following seems a bit harsh, but I, and many others
who have worked with lisp, find it extremely frustrating to read
statements about lisp like the one above that suggest that lisp is a
pairlist language only, especially when these statements come from
people I thought knew better.  Lisp dates back to the 1950's.  The
only other language of any consequence still in use from that era is
FORTRAN.  No one would now claim that a major flaw in FORTAN is the
lack of an if-then-else construct.  That was true in the early days
but has not been for several decades.  But for some reason many people
seem very happy to very authoritatively make statements about lisp
that, if they were ever true at all, have not been so for a very long
time indeed.  Pairlists are a very useful data structure for
expressing many algorithms in a functional style.  That is why they
were one of the first data structures in Lisp, and that is why they
are available in virtually all other high level functional languages
(ML, Haskell, Miranda, Clean, ...).  Pailrists are NOT the only data
structure in Lisp.  For many years Lisp has also supported vectors and
arrays, both generic and typed (and other data structures).  Vectors
and pairlists are collectively referred to as sequences, and, if I
remember correctly, all the functions listed in the original post
except mapcar are designed to work on all kinds of sequences (the
sequence version of mapcar is map).  Code written in xlispstat in
terms of sequence functions can often be translated quite easily to R,
and the resulting code will be quite consistent with good R coding
practices.

R does not provide a pairlist data structure. This creates a dilemma
when translating some list-based xlispstat code, or, more importantly,
when implementing an algorithm for which parilists are the natural
data structure to use.  There are two choices: use a vector based
algorithm that may be a bit less natural but fits better with the
basic R data structures, or build your own pairlist abstraction for
this particular problem and write the algorithm the more natural way.
I have used both approaches on different occasions.  I usually prefer
to write an algorithm in the most natural way for the algorithm, since
that usually maximizes the probability that my code is actually
correct.  If this approach requires some additional abstract data
types, be they pairlists or anything else, then I develop and test
them separately and write the main code in terms of these
abstractions.  Occasianally, but not all that often, this results in
code that is slower than I like; then I may profile and optimize the
critical bits by using more efficient data structures if that turns
out to be the issue.

I really don't think it is reasonable to say R was ever
pairlist-based.  At one point in time generic vectors (the things
returned by list(...))  were pairlists as opposed to vectors which
they are now, but numeric data have always been true vectors.
Pairlists were and still are used internally for many things.  In some
cases other data structures would have advantages, and I suspect we
will slowly move in that direction.  But for some things the pairlist
really is a good fit.  I also have seen some convoluted code in the R
internals--I'm sure I have written some of it.  I can't speak for
others, but in my case I am reluctant to blame pairlists or any other
aspect of the R internals for convolutions in my code. {One of the
things anyone releasing open source code has to come to terms with is
that you have to release all your code, but the bits of which you may
feel justifialy proud as well as ...]

luke


-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From JonesW at kssg.com  Fri Feb 14 15:53:03 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Fri Feb 14 15:53:03 2003
Subject: [R] Numeric Coerceing
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE1FF1@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030214/8ca0b671/attachment.pl

From mschwartz at medanalytics.com  Fri Feb 14 16:07:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri Feb 14 16:07:03 2003
Subject: [R] Numeric Coerceing
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB01EE1FF1@gimli.middleearth.kssg.com>
Message-ID: <003f01c2d43a$8fe079c0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Wayne Jones
>Sent: Friday, February 14, 2003 8:20 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Numeric Coerceing
>
>
>Does anyone know how to coerce a numeric to a string??
>
>THanks
>
>Wayne


See ?as.character

For example:

> y <- 123
> y
[1] 123
> as.character(y)
[1] "123"


Regards,

Marc Schwartz



From spencer.graves at pdf.com  Fri Feb 14 16:22:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 14 16:22:06 2003
Subject: [R] Change array size
References: <3A822319EB35174CA3714066D590DCD534BCAC@usrymx25.merck.com> <x2isvnj7lo.fsf@biostat.ku.dk>
Message-ID: <3E4D0922.9080901@pdf.com>

then change "trunc" to "ceiling"???

Peter Dalgaard BSA wrote:
> "Liaw, Andy" <andy_liaw at merck.com> writes:
> 
> 
>>Is the following what you want?
>>
>>
>>>x<- rnorm(800)
>>>xt <- x[1:2^trunc(log(length(x),base=2))]
>>>length(xt)
>>
>>[1] 512
> 
> 
> I don't think so (notice "upper"). More likely
> 
> x <- rnorm(800)
> l <- length(x)
> xt <- c(x,numeric(2^ceiling(log(l,base=2))-l))
> length(xt) # 1024
> 
> but "fits" might also imply interpolation?
> 
> 
>>>Hi,
>>>I would like to know if there is a way to change a vector of 
>>>arbitrary size
>>>to make it fits the nearest upper size multiple of a power of 2.
>>
> 
>



From gregory_r_warnes at groton.pfizer.com  Fri Feb 14 16:58:03 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri Feb 14 16:58:03 2003
Subject: [R] pairlists (was: data manipulation function descriptions)
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C5D7@groexmb02.pfizer.com>


> -----Original Message-----
> From: Luke Tierney [mailto:luke at stat.uiowa.edu]

> R does not provide a pairlist data structure. This creates a dilemma
> when translating some list-based xlispstat code, or, more
> importantly, when implementing an algorithm for which parilists are
> the natural data structure to use.
> ...
> Pairlists were and still are used internally for many things. 
> ...

Wouldn't it, therefore, make sense to provide a 'pairlist' package which
exposes the internal pairlist structure and provides appropriate functions
(car, cdr, ...), instead of expecting people to keep re-implementing these
features?

-Greg


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From shona at public-health.ucl.ac.uk  Fri Feb 14 17:16:04 2003
From: shona at public-health.ucl.ac.uk (Shona Livingstone)
Date: Fri Feb 14 17:16:04 2003
Subject: [R] programs for genetics - haplo.score for R
Message-ID: <3E4D15F8.13895.149DAA2@localhost>

A non-text attachment was scrubbed...
Name: not available
Type: text/enriched
Size: 1819 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030214/7f3adccd/attachment.bin

From charles.raux at let.ish-lyon.cnrs.fr  Fri Feb 14 17:21:20 2003
From: charles.raux at let.ish-lyon.cnrs.fr (Charles Raux)
Date: Fri Feb 14 17:21:20 2003
Subject: [R] RODBC  connection failed
Message-ID: <200302141614.RAA14644@docsrvr.ish-lyon.cnrs.fr>

I am trying to restart on R after 2 months stop. Start with previously 
functioning procedure:
"ch<-odbcConnect("dBase Files")"
get
"Warning message: 
ODBC connection failed in: odbcConnect("dBase Files") "
I have tried unsuccessfully different working directories.
The only change I see is that I am working with a new login account on 
the same machine. Microsoft ODBC is still here in c:\WINNT\system32.
What is wrong?
Thanks
Charles Raux


---------------
Charles RAUX,
Laboratoire d'Economie des Transports
CNRS-Universit? Lumi?re Lyon 2-ENTPE
email : charles.raux at let.ish-lyon.cnrs.fr
http://www.ish-lyon.cnrs.fr/let



From Benjamin.STABLER at odot.state.or.us  Fri Feb 14 17:30:03 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Fri Feb 14 17:30:03 2003
Subject: [R] ESRI shape file import and time-space models
Message-ID: <76A000A82289D411952F001083F9DD06039ACA54@exsalem4-bu.odot.state.or.us>

Attached are some functions that I wrote to read and write shapefiles and
dbfs easily from within R.  You do not need any additional libraries or C
code.  I am still working out a few bugs but I have tested it with quite a
few different files and it seems to be working pretty well.  There is little
documentation at this point though.  I'd appreciate any comments about the
code.  Thanks.

Benjamin Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
555 13th Street NE, Suite 2
Salem, OR 97301  Ph: 503-986-4104



>Dear R user,
>I am running R under Windows 2000.

>I am looking for a routine for importing

 

>        shape files (ESRI) into R

>        dbase files (FOXPRO) into R


>and I am looking for time-space models for description and prediction of
>Bernoulli-, Binomial- and Poissonvaraibles.

>Thank's a lot for a reply. 

>Sincerely yours,

>Ekkehardt Altpeter

>Swiss Federal Office of Public Health.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: shapefiles.R
Type: application/octet-stream
Size: 26290 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030214/fad15efe/shapefiles.obj

From rpeng at stat.ucla.edu  Fri Feb 14 17:35:04 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri Feb 14 17:35:04 2003
Subject: [R] programs for genetics - haplo.score for R
In-Reply-To: <3E4D15F8.13895.149DAA2@localhost>
Message-ID: <Pine.GSO.4.10.10302140830210.25507-100000@quetelet.stat.ucla.edu>

It would appear that Gregory Warnes has ported it to R and the package
`haplo.score' can be downloaded from CRAN (http://cran.r-project.org).

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Fri, 14 Feb 2003, Shona Livingstone wrote:

> <color><param>0100,0100,0100</param>Dear All,
> 
> I wish to use a suite of programs called "haplo.score" first written in S plus by 
> Rowland et al of the Mayo clinic (details given below). Unfortunately, I do not 
> have S plus available to me at the moment
> 
> 
> Has anyone written the equivalent for R? 
> 
> 
> Any pointers will be appreciated, bearing in mind that I am new to R.
> 
> 
> Thank you for your help
> 
> Shona Livingstone
> 
> Epidemiology and Public Health, UCL
> 
> 
> *****************************
> 
> <bold><FontFamily><param>Arial</param><smaller>haplo.score
> 
> <italic>Score Tests for Association of Traits with Haplotypes when
> 
> Linkage Phase is Ambiguous
> 
> </italic></bold><FontFamily><param>Times New Roman</param>Charles M. Rowland, David E. Tines, and Daniel J. Schaid
> 
> Mayo Clinic
> 
> Rochester, MN
> 
> E-mail contact: rowland at mayo.edu
> 
> <bold><FontFamily><param>Arial</param>I
> 
> [</bold><FontFamily><param>Times New Roman</param>A suite of S-PLUS routines, referred to as "haplo.score", can be used to compute score 
> statistics to
> 
> test associations between haplotypes and a wide variety of traits, including binary, 
> ordinal,
> 
> quantitative, and Poisson. These methods assume that all subjects are unrelated and that 
> haplotypes
> 
> are ambiguous (due to unknown linkage phase of the genetic markers). The methods 
> provide
> 
> several different global and haplotype-specific tests for association, as well as provide 
> adjustment
> 
> for non-genetic covariates and computation of simulation p-values (which may be 
> needed for
> 
> sparse data). Details on the background and theory of the score statistics can be found 
> in the
> 
> following reference:
> 
> Schaid DJ, Rowland CM, Tines DE, Jacobson RM, Poland GA. Score tests for
> 
> association of traits with haplotypes when linkage phase is ambiguous. American J
> 
> Human Genetics, February, 2002.]
> 
> 
> <nofill>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ozric at web.de  Fri Feb 14 17:40:18 2003
From: ozric at web.de (Christian Schulz)
Date: Fri Feb 14 17:40:18 2003
Subject: [R] RODBC  connection failed
References: <200302141614.RAA14644@docsrvr.ish-lyon.cnrs.fr>
Message-ID: <001301c2d446$76d22d00$5eb907d5@c5c9i0>

try:
ch <- odbcConnect("dBase Files","","")

Perhaps you should avoid the space
in your dsn name !?

regards,christian


I am trying to restart on R after 2 months stop. Start with previously
functioning procedure:
"ch<-odbcConnect("dBase Files")"
get
"Warning message:
ODBC connection failed in: odbcConnect("dBase Files") "
I have tried unsuccessfully different working directories.
The only change I see is that I am working with a new login account on
the same machine. Microsoft ODBC is still here in c:\WINNT\system32.
What is wrong?
Thanks
Charles Raux


---------------
Charles RAUX,
Laboratoire d'Economie des Transports
CNRS-Universit? Lumi?re Lyon 2-ENTPE
email : charles.raux at let.ish-lyon.cnrs.fr
http://www.ish-lyon.cnrs.fr/let

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From cliff at ms.washington.edu  Fri Feb 14 17:52:02 2003
From: cliff at ms.washington.edu (Cliff Lunneborg)
Date: Fri Feb 14 17:52:02 2003
Subject: [R] How to solve A'A=S for A
Message-ID: <002101c2d449$4b75d5f0$95abd00c@C56909A>

It is not clear to me that one can. If the singular value decomposition
of A is the triple product P d Q', then the singular value decomposition
of A'A=S is Q d^2 Q'. The information about the orthonormal matrix P is
lost, is it not?
**********************************************************
Cliff Lunneborg, Professor Emeritus, Statistics &
Psychology, University of Washington, Seattle
Visiting: Melbourne, Feb-May 1999, Brisbane, Jun-Aug 1999,
Sydney, Sep-Nov 1999, Perth, Dec 1999-Feb 2000
cliff at stat.washington.edu



From deleeuw at stat.ucla.edu  Fri Feb 14 18:06:03 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Fri Feb 14 18:06:03 2003
Subject: [R] How to solve A'A=S for A
In-Reply-To: <002101c2d449$4b75d5f0$95abd00c@C56909A>
Message-ID: <70058036-403E-11D7-B605-000393BB6D36@stat.ucla.edu>

Well, you cannot solve uniquely for A, there is an orthogonal solution,
a triangular solution, a symmetric solution and so on. It is true that
the solution is unique up to an orthonormal tranformation.

On Friday, Feb 14, 2003, at 08:51 US/Pacific, Cliff Lunneborg wrote:

> It is not clear to me that one can. If the singular value decomposition
> of A is the triple product P d Q', then the singular value  
> decomposition
> of A'A=S is Q d^2 Q'. The information about the orthonormal matrix P is
> lost, is it not?
> **********************************************************
> Cliff Lunneborg, Professor Emeritus, Statistics &
> Psychology, University of Washington, Seattle
> Visiting: Melbourne, Feb-May 1999, Brisbane, Jun-Aug 1999,
> Sydney, Sep-Nov 1999, Perth, Dec 1999-Feb 2000
> cliff at stat.washington.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------



From mihastaut at hotmail.com  Fri Feb 14 18:21:02 2003
From: mihastaut at hotmail.com (Miha STAUT)
Date: Fri Feb 14 18:21:02 2003
Subject: [R] matrix from sequences
Message-ID: <BAY2-F1336ACYnEWVq50002a6b6@hotmail.com>

Hi all,

I have a data frame with sequences of x and y from a map. I would like to 
know it both ways:
1. How to make a matrix from that;
2. how to make a data frame of all points in a map.

Probably it is a silly question, but please tell me where to read about it 
or tell me how to do it.

Miha Staut



From p.dalgaard at biostat.ku.dk  Fri Feb 14 18:28:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Feb 14 18:28:03 2003
Subject: [R] pairlists (was: data manipulation function descriptions)
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C202F2C5D7@groexmb02.pfizer.com>
References: <D7A3CFD7825BD6119B880002A58F06C202F2C5D7@groexmb02.pfizer.com>
Message-ID: <x265rmkc03.fsf@biostat.ku.dk>

"Warnes, Gregory R" <gregory_r_warnes at groton.pfizer.com> writes:

> > -----Original Message-----
> > From: Luke Tierney [mailto:luke at stat.uiowa.edu]
> 
> > R does not provide a pairlist data structure. This creates a dilemma
> > when translating some list-based xlispstat code, or, more
> > importantly, when implementing an algorithm for which parilists are
> > the natural data structure to use.
> > ...
> > Pairlists were and still are used internally for many things. 
> > ...
> 
> Wouldn't it, therefore, make sense to provide a 'pairlist' package which
> exposes the internal pairlist structure and provides appropriate functions
> (car, cdr, ...), instead of expecting people to keep re-implementing these
> features?

Some ancient consideration pops up here. We do actually expose
pairlists in a few places (try mode(.Options)). Some people consider
that this is a remnant and should be stamped out, but we might also
consider doing what you suggest. 

The big problem with old R was not so much the pairlists but that they
were used for representing objects of mode "list" so to get to X[[n]]
you had to count through the list from the beginning which killed
performance in some important cases. Then again, adding elements to a
generic vector requires copying the whole thing. Of course all the
legacy S code tended to do the former and not the latter, so generic
vectors ended up winning.

One or two reservations: With full lisp style access, could we end up
with (circular) data structures that confuse the garbage collector?
And might we -- supposing we allowed destructive list modifications --
end up with strange semantics a la the .Alias mess we had for a while?
Of course Luke would be the first to know about this.

Then of course there is the question of reverse compatibility. I don't
consider it much of a loss if R code doesn't run in Splus, but others
might.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tplate at blackmesacapital.com  Fri Feb 14 18:32:04 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Fri Feb 14 18:32:04 2003
Subject: [R] Change array size
In-Reply-To: <200302140951.38672.poizot@cnam.fr>
Message-ID: <5.1.0.14.2.20030214102449.046f2d38@mailhost.blackmesacapital.com>

If you just want to extend the vector, and fill new elements with NA, then 
a simple way is:

 > x <- 1:5
 > length(x) <- 2 ^ ceiling(log(length(x))/log(2))
 > x
[1]  1  2  3  4  5 NA NA NA
 >

However, one needs to be careful with kind of arithmetic -- floating point 
inaccuracies can cause unexpected results.  E.g., one would expect the 
following points to form a straight line, but they don't -- on my computer 
there are 4 anomalies between 29 and 50:

 > plot(ceiling(log(2**(1:50))/log(2)))

In the question asked, this is unlikely to cause problems as it is unlikely 
that a vector will have 2^29 elements.

At Friday 09:51 AM 2/14/2003 +0000, Poizot Emmanuel wrote:
>Hi,
>I would like to know if there is a way to change a vector of arbitrary size
>to make it fits the nearest upper size multiple of a power of 2.
>
>--
>Cordialy
>----------------------------------------
>Emmanuel POIZOT
>Cnam/Intechmer
>Digue de Collignon
>50110 Tourlaville
>T?l : (33)(0)2 33 88 73 42
>Fax : (33)(0)2 33 88 73 39
>-----------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Fri Feb 14 18:36:04 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri Feb 14 18:36:04 2003
Subject: [R] How to solve A'A=S for A
In-Reply-To: <002101c2d449$4b75d5f0$95abd00c@C56909A>
Message-ID: <Pine.GSO.4.44.0302141728110.18406-100000@auk.stats>

On Fri, 14 Feb 2003, Cliff Lunneborg wrote:

> It is not clear to me that one can. If the singular value decomposition
> of A is the triple product P d Q', then the singular value decomposition
> of A'A=S is Q d^2 Q'. The information about the orthonormal matrix P is
> lost, is it not?

S was a covariance matrix, so symmetric and non-negative definite.
Hence P = Q.

> **********************************************************
> Cliff Lunneborg, Professor Emeritus, Statistics &
> Psychology, University of Washington, Seattle

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Feb 14 18:40:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri Feb 14 18:40:03 2003
Subject: [R] RODBC  connection failed
In-Reply-To: <200302141614.RAA14644@docsrvr.ish-lyon.cnrs.fr>
Message-ID: <Pine.GSO.4.44.0302141730030.18406-100000@auk.stats>

On Fri, 14 Feb 2003, Charles Raux wrote:

> I am trying to restart on R after 2 months stop. Start with previously
> functioning procedure:
> "ch<-odbcConnect("dBase Files")"
> get
> "Warning message:
> ODBC connection failed in: odbcConnect("dBase Files") "
> I have tried unsuccessfully different working directories.
> The only change I see is that I am working with a new login account on
> the same machine. Microsoft ODBC is still here in c:\WINNT\system32.
> What is wrong?

DSNs are often per-user.
Try

ch<-odbcDriverConnect("")

and explore (assuming your RODBC is current).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lun_li at hotmail.com  Fri Feb 14 19:40:13 2003
From: lun_li at hotmail.com (lun li)
Date: Fri Feb 14 19:40:13 2003
Subject: [R] Function update problem
Message-ID: <BAY2-F88XGA7zyWR4At0002aac7@hotmail.com>

Dear Professor Ripley,

Thank you very much for your help.

I tested the idea by" form <- substitute(.~.+x[,i], list(i=i))", however the 
problem still is there.  In order to automate model selection, I prefer to 
use "update". My regression problem is to test significant predictors from  
several hundred candidates using forward regression by BIC criteria. For 
each loop, first to find one with maximum BIC and then to update "lm" to get 
a new model.  So, it is convenient to use"update" function. I would be 
grateful if you could still help.

In addition, I tried the way "update+add1" to my question.  But, new problem 
is " update.default(model, . ~ . + x) need an object with call component", 
help? The code is:

>model<-add1(model,.~.+form)
>model.new<-update(model,.~.+x)

With best regards,


Lun




>You can use substitute: something like (untested)
>
>for(i in 1:100){
>     form <- substitute(.~.+x[,i], list(i=i))
>     model <- update(model, form)
>     ## do something useful in here
>}
>and you do not need to update unchanged arguments!
>
>However, why are you rewriting add1.default, when there is add1.lm?
>
>On Thu, 13 Feb 2003, lun li wrote:
>
> > Dear all,
> >
> > I am trying an automatic model selection for a multiple linear 
>regression
> > using function lm and update. But, I meet a problem when using update. 
>The
> > problem is the function update can not update when variables as a 
>vector(for
> > example,x is a matrix with 100 regression variables). The code is as 
>below:
> >
> >   > model<-lm(y~x1,singular.ok=T,na.action=na.omit)
> >   > for(i in 1:100){
> >   > model<-update(model,.~.+x[,i],singular.ok=T,na.action=na.omit)}
> >
> > If the above code is represented as below, I can get the correct result.
> > However, I must use the loops.
> >
> > >model<-lm(y~x1,singular.ok=T,na.action=na.omit)
> > >model<-update(model,.~.+x[,1],singular.ok=T,na.action=na.omit)
> > >model<-update(model,.~.+x[,2],singular.ok=T,na.action=na.omit)
> >         ......
> > >model<-update(model,.~.+x[,100],singular.ok=T,na.action=na.omit)
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>----- End forwarded message -----
>
>
>
>Lun Li
>Department of Geology and Geophysics
>The University of Edinburgh
>Grant Institute                        Tel. +44(0)131 650 7339
>King's Buildings                       Fax. +44(0)131 668 3184
>West Mains Road			       E-mail:lun.li at glg.ed.ac.uk
>Edinburgh EH9 3JW
>UK



From csillery at selway.umt.edu  Fri Feb 14 21:01:03 2003
From: csillery at selway.umt.edu (Katalin Csillery)
Date: Fri Feb 14 21:01:03 2003
Subject: [R] error in unique(pkgs) (fwd)
Message-ID: <Pine.OSF.4.21.0302141259130.14678-100000@selway.umt.edu>

> 
> I read your reply as an R mail archive in respect to the installation of
> new R contributed packages on a Mac OS X. 
> I found the same problem, I use OroborOSX and emacs-ESS, I wanted to
> install xtable, ape packages, with the install.packages() command, and I
> got the same error message (naturally: sudo emacs - which avoids the
> argument "lib" missing error message), 
> 
> Error in unique(pkgs) : Object "ape" not found
> 
> Ape is not a base package so it should be available separately.
> 
> Any idea?
> 
> Thanks for your help in advance!

You really need to use the r-help list for this, I'm not a Mac expert.
(I think you might need to fetch the Stuffit archive from CRAN and
unstuff it manually.)

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From mihastaut at hotmail.com  Fri Feb 14 21:53:03 2003
From: mihastaut at hotmail.com (Miha STAUT)
Date: Fri Feb 14 21:53:03 2003
Subject: [R] matrix from sequences
Message-ID: <BAY2-F156GShOvkGOFg00023938@hotmail.com>

>Miha STAUT wrote:
>>Hi all,
>>
>>I have a data frame with sequences of x and y from a map. I would like to 
>>know it both ways:
>>1. How to make a matrix from that;
>>2. how to make a data frame of all points in a map.
>>
>>Probably it is a silly question, but please tell me where to read about it 
>>or tell me how to do it.
>>
>>Miha Staut
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>Hi Miha,
>
>1) What is the structure of your data.frame ? Assuming all co-ordinates are 
>in the same column (one column for x and one column for y), the simplest 
>way to extract them and turn them into a matrix would be:
>
>as.matrix(mydata[ , c("x", "y")])
>
>e.g.:
>
>R>mydata <- data.frame(x = rnorm(10), y = rnorm(10), z = rnorm(10))
>R>mydata
>              x           y          z
>1  -0.73735224 -0.51218243 -0.9602624
>2  -1.46079091 -0.63634091  1.4967066
>3  -0.28574919 -1.30719383 -0.2887403
>4   0.04137159  0.61711350 -0.7057102
>5   0.03179303  0.05734869 -0.4637660
>6  -0.06638058 -0.74565157  0.9239402
>7  -0.67611541 -1.01760810 -0.2854017
>8   0.34215052  0.30564550  0.6931193
>9   0.83597837  0.75443762 -2.3394679
>10 -0.14967073 -0.02027512 -0.1143414
>R>as.matrix(mydata[ , c("x", "y")])
>              x           y
>1  -0.73735224 -0.51218243
>2  -1.46079091 -0.63634091
>3  -0.28574919 -1.30719383
>4   0.04137159  0.61711350
>5   0.03179303  0.05734869
>6  -0.06638058 -0.74565157
>7  -0.67611541 -1.01760810
>8   0.34215052  0.30564550
>9   0.83597837  0.75443762
>10 -0.14967073 -0.02027512
>
>
>2) How are the points stored ? If in a matrix, say mat, with 2 columns for 
>x and y, simply:
>
>as.data.frame(mat)
>
>Best,
>
>Renaud


Thanks to both of you (Dr Renaud Lancelot and James Holtman)

I see I formulated the question in a wrong way. I got from GRASS the 
coordinates of a map. There is a package in R named GRASS to connect R with 
GRASS.

library(GRASS)
G<-gmeta() # copy the environment from GRASS

Now G is a data frame containig also $xseq and $yseq which would be the 
coordinates of all the points in x and y direction. The final matrix should 
have length(G$xseq) * length(G$yseq) points.

Miha Staut



From spencer.graves at pdf.com  Fri Feb 14 22:19:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 14 22:19:06 2003
Subject: [R] matrix from sequences
References: <BAY2-F156GShOvkGOFg00023938@hotmail.com>
Message-ID: <3E4D5D08.9030406@pdf.com>

Hi, Miha:

1.  How do I get the GRASS library?  "library(GRASS)" produced "Error in 
library(GRASS) : There is no package called `GRASS'" for me from R 1.6.2 
for Windows.

2.  I assume there is a typographical error in the last line of your 
email:  If G$xseq and $yseq are coordinates of points, then 
length(G$xseq) == length(G$yseq)???  In that case, 
'as.matrix(G[,c("xseq", "yseq")])' should give you what you want.

Or am I missing something?
Best Wishes,
Spencer Graves

Miha STAUT wrote:
>> Miha STAUT wrote:
>>
>>> Hi all,
>>>
>>> I have a data frame with sequences of x and y from a map. I would 
>>> like to know it both ways:
>>> 1. How to make a matrix from that;
>>> 2. how to make a data frame of all points in a map.
>>>
>>> Probably it is a silly question, but please tell me where to read 
>>> about it or tell me how to do it.
>>>
>>> Miha Staut
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>
>> Hi Miha,
>>
>> 1) What is the structure of your data.frame ? Assuming all 
>> co-ordinates are in the same column (one column for x and one column 
>> for y), the simplest way to extract them and turn them into a matrix 
>> would be:
>>
>> as.matrix(mydata[ , c("x", "y")])
>>
>> e.g.:
>>
>> R>mydata <- data.frame(x = rnorm(10), y = rnorm(10), z = rnorm(10))
>> R>mydata
>>              x           y          z
>> 1  -0.73735224 -0.51218243 -0.9602624
>> 2  -1.46079091 -0.63634091  1.4967066
>> 3  -0.28574919 -1.30719383 -0.2887403
>> 4   0.04137159  0.61711350 -0.7057102
>> 5   0.03179303  0.05734869 -0.4637660
>> 6  -0.06638058 -0.74565157  0.9239402
>> 7  -0.67611541 -1.01760810 -0.2854017
>> 8   0.34215052  0.30564550  0.6931193
>> 9   0.83597837  0.75443762 -2.3394679
>> 10 -0.14967073 -0.02027512 -0.1143414
>> R>as.matrix(mydata[ , c("x", "y")])
>>              x           y
>> 1  -0.73735224 -0.51218243
>> 2  -1.46079091 -0.63634091
>> 3  -0.28574919 -1.30719383
>> 4   0.04137159  0.61711350
>> 5   0.03179303  0.05734869
>> 6  -0.06638058 -0.74565157
>> 7  -0.67611541 -1.01760810
>> 8   0.34215052  0.30564550
>> 9   0.83597837  0.75443762
>> 10 -0.14967073 -0.02027512
>>
>>
>> 2) How are the points stored ? If in a matrix, say mat, with 2 columns 
>> for x and y, simply:
>>
>> as.data.frame(mat)
>>
>> Best,
>>
>> Renaud
> 
> 
> 
> Thanks to both of you (Dr Renaud Lancelot and James Holtman)
> 
> I see I formulated the question in a wrong way. I got from GRASS the 
> coordinates of a map. There is a package in R named GRASS to connect R 
> with GRASS.
> 
> library(GRASS)
> G<-gmeta() # copy the environment from GRASS
> 
> Now G is a data frame containig also $xseq and $yseq which would be the 
> coordinates of all the points in x and y direction. The final matrix 
> should have length(G$xseq) * length(G$yseq) points.
> 
> Miha Staut
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mihastaut at hotmail.com  Fri Feb 14 22:50:03 2003
From: mihastaut at hotmail.com (Miha STAUT)
Date: Fri Feb 14 22:50:03 2003
Subject: [R] matrix from sequences
Message-ID: <BAY2-F22zgwKzBBrYK90002b297@hotmail.com>

>Hi, Miha:
>
>1.  How do I get the GRASS library?  "library(GRASS)" produced "Error in 
>library(GRASS) : There is no package called `GRASS'" for me from R 1.6.2 
>for Windows.

I do not know whether it exists for Windows or not, but look under:
http://cran.r-project.org/src/contrib/Devel/
Or visit:
http://grass.itc.it/index.html

>
>2.  I assume there is a typographical error in the last line of your email: 
>  If G$xseq and $yseq are coordinates of points, then length(G$xseq) == 
>length(G$yseq)???  In that case, 'as.matrix(G[,c("xseq", "yseq")])' should 
>give you what you want.
>
>Or am I missing something?

OK I really am lousy at explaining things. The length(G$xseq) * 
length(G$yseq) stands because you have to get all the permutations of the 
elements of those two sequences. Get it? If you have:
xseq<-1:10
yseq<-1:10
I would like to get:
      x
y     [,1] [,2] [,3] [,4] [,5] ...
[1,]
[2,]
[3,]
[4,]
...

or

str(xy)
$x 1,1,1,1,1,1,1,1,1,1,2,2,2,...
$y 1,2,3,4,5,6,7,8,9,10,1,2,3,...


>Spencer Graves
>
>Miha STAUT wrote:
>>>Miha STAUT wrote:
>>>
>>>>Hi all,
>>>>
>>>>I have a data frame with sequences of x and y from a map. I would like 
>>>>to know it both ways:
>>>>1. How to make a matrix from that;
>>>>2. how to make a data frame of all points in a map.
>>>>
>>>>Probably it is a silly question, but please tell me where to read about 
>>>>it or tell me how to do it.
>>>>
>>>>Miha Staut
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>>
>>>Hi Miha,
>>>
>>>1) What is the structure of your data.frame ? Assuming all co-ordinates 
>>>are in the same column (one column for x and one column for y), the 
>>>simplest way to extract them and turn them into a matrix would be:
>>>
>>>as.matrix(mydata[ , c("x", "y")])
>>>
>>>e.g.:
>>>
>>>R>mydata <- data.frame(x = rnorm(10), y = rnorm(10), z = rnorm(10))
>>>R>mydata
>>>              x           y          z
>>>1  -0.73735224 -0.51218243 -0.9602624
>>>2  -1.46079091 -0.63634091  1.4967066
>>>3  -0.28574919 -1.30719383 -0.2887403
>>>4   0.04137159  0.61711350 -0.7057102
>>>5   0.03179303  0.05734869 -0.4637660
>>>6  -0.06638058 -0.74565157  0.9239402
>>>7  -0.67611541 -1.01760810 -0.2854017
>>>8   0.34215052  0.30564550  0.6931193
>>>9   0.83597837  0.75443762 -2.3394679
>>>10 -0.14967073 -0.02027512 -0.1143414
>>>R>as.matrix(mydata[ , c("x", "y")])
>>>              x           y
>>>1  -0.73735224 -0.51218243
>>>2  -1.46079091 -0.63634091
>>>3  -0.28574919 -1.30719383
>>>4   0.04137159  0.61711350
>>>5   0.03179303  0.05734869
>>>6  -0.06638058 -0.74565157
>>>7  -0.67611541 -1.01760810
>>>8   0.34215052  0.30564550
>>>9   0.83597837  0.75443762
>>>10 -0.14967073 -0.02027512
>>>
>>>
>>>2) How are the points stored ? If in a matrix, say mat, with 2 columns 
>>>for x and y, simply:
>>>
>>>as.data.frame(mat)
>>>
>>>Best,
>>>
>>>Renaud
>>
>>
>>
>>Thanks to both of you (Dr Renaud Lancelot and James Holtman)
>>
>>I see I formulated the question in a wrong way. I got from GRASS the 
>>coordinates of a map. There is a package in R named GRASS to connect R 
>>with GRASS.
>>
>>library(GRASS)
>>G<-gmeta() # copy the environment from GRASS
>>
>>Now G is a data frame containig also $xseq and $yseq which would be the 
>>coordinates of all the points in x and y direction. The final matrix 
>>should have length(G$xseq) * length(G$yseq) points.
>>
>>Miha Staut
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From +rhelp at howard.fm  Fri Feb 14 22:57:03 2003
From: +rhelp at howard.fm (+rhelp@howard.fm)
Date: Fri Feb 14 22:57:03 2003
Subject: [R] Translating lm.object to SQL, C, etc function
In-Reply-To: <Pine.LNX.4.44.0302140807560.16111-100000@gannet.stats>
References: <Pine.LNX.4.44.0302140807560.16111-100000@gannet.stats>
Message-ID: <20030214215643.9D9931BEF@server2.fastmail.fm>

On Fri, 14 Feb 2003 08:25:05 +0000 (GMT), ripley at stats.ox.ac.uk said:
> On Fri, 14 Feb 2003 j+rhelp at howard.fm wrote:
> > Thanks for the suggestion. After my last post I tried switching from
> > SPLUS to R and discovered the useful xlevels attribute, which when output
> 
> Eh?  S-PLUS has an "xlevels" attribute, but R has an "xlevels" component
> (speaks the author of both).
> 
Thanks for the clarification.

> You add methods to functions, not classes, in R.  You could indeed add
> generic accessor functions with lm methods, but their absence (and the
> lack of documentation of the internal structure) should alert you to the
> idea that this is internal structure and not part of a public API.
> 
OK, I'll stay away from that then...

> > In SPLUS I came across a useful attribute 'assign', which has a mapping
> > of term names to variables - the same attribute in R doesn't appear to
> > provide this information. Is this available somewhere?
> 
> Both have an assign *component*, not attribute.  R has a mapping from
> model.matrix columns to terms in its assign component: that's not an
> accurate description of S-PLUS's component ....
> 
Now that I look again more closely I see what you mean. Sorry for the
missing that.
-- 
  Jeremy Howard
  jhoward at fastmail.fm



From j+rhelp at howard.fm  Fri Feb 14 23:00:33 2003
From: j+rhelp at howard.fm (j+rhelp@howard.fm)
Date: Fri Feb 14 23:00:33 2003
Subject: [R] Translating lm.object to SQL, C, etc function
Message-ID: <20030214215652.322D9433C1@server2.fastmail.fm>

On Fri, 14 Feb 2003 08:25:05 +0000 (GMT), ripley at stats.ox.ac.uk said:
> On Fri, 14 Feb 2003 j+rhelp at howard.fm wrote:
> > Thanks for the suggestion. After my last post I tried switching from
> > SPLUS to R and discovered the useful xlevels attribute, which when output
> 
> Eh?  S-PLUS has an "xlevels" attribute, but R has an "xlevels" component
> (speaks the author of both).
> 
Thanks for the clarification.

> You add methods to functions, not classes, in R.  You could indeed add
> generic accessor functions with lm methods, but their absence (and the
> lack of documentation of the internal structure) should alert you to the
> idea that this is internal structure and not part of a public API.
> 
OK, I'll stay away from that then...

> > In SPLUS I came across a useful attribute 'assign', which has a mapping
> > of term names to variables - the same attribute in R doesn't appear to
> > provide this information. Is this available somewhere?
> 
> Both have an assign *component*, not attribute.  R has a mapping from
> model.matrix columns to terms in its assign component: that's not an
> accurate description of S-PLUS's component ....
> 
Now that I look again more closely I see what you mean. Sorry for the
missing that.
-- 
  Jeremy Howard
  jhoward at fastmail.fm



From jgramlich at piocon.com  Fri Feb 14 23:08:03 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Fri Feb 14 23:08:03 2003
Subject: [R] function editing?
Message-ID: <1045260435.3089.11.camel@localhost.localdomain>

Is there a way to edit user defined functions once they've been
created?  For instance, I've a simple function that plots a table, but
I'd like to go back and add more parameters to the barplot call.  Is
there a way to change this function without completely starting from
scratch?  Other than storing the code in a file and re-running it?


Joshua Gramlich
Piocon Technologies
Chicago, Illinois USA



From sundar.dorai-raj at pdf.com  Fri Feb 14 23:16:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri Feb 14 23:16:03 2003
Subject: [R] function editing?
References: <1045260435.3089.11.camel@localhost.localdomain>
Message-ID: <3E4D6A56.7000609@pdf.com>

See ?fix.

Joshua Gramlich wrote:
> Is there a way to edit user defined functions once they've been
> created?  For instance, I've a simple function that plots a table, but
> I'd like to go back and add more parameters to the barplot call.  Is
> there a way to change this function without completely starting from
> scratch?  Other than storing the code in a file and re-running it?
> 
> 
> Joshua Gramlich
> Piocon Technologies
> Chicago, Illinois USA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From deepayan at stat.wisc.edu  Fri Feb 14 23:20:04 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Feb 14 23:20:04 2003
Subject: [R] function editing?
In-Reply-To: <1045260435.3089.11.camel@localhost.localdomain>
References: <1045260435.3089.11.camel@localhost.localdomain>
Message-ID: <200302141617.08927.deepayan@stat.wisc.edu>

See ?edit

If you use ESS, C-c C-d.

On Friday 14 February 2003 04:07 pm, Joshua Gramlich wrote:
> Is there a way to edit user defined functions once they've been
> created?  For instance, I've a simple function that plots a table, but
> I'd like to go back and add more parameters to the barplot call.  Is
> there a way to change this function without completely starting from
> scratch?  Other than storing the code in a file and re-running it?
>
>
> Joshua Gramlich
> Piocon Technologies
> Chicago, Illinois USA
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From luke at stat.uiowa.edu  Fri Feb 14 23:25:04 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri Feb 14 23:25:04 2003
Subject: [R] pairlists (was: data manipulation function descriptions)
In-Reply-To: <x265rmkc03.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0302141617530.7779-100000@nokomis2.stat.umn.edu>

On 14 Feb 2003, Peter Dalgaard BSA wrote:

> "Warnes, Gregory R" <gregory_r_warnes at groton.pfizer.com> writes:
> 
> > > -----Original Message-----
> > > From: Luke Tierney [mailto:luke at stat.uiowa.edu]
> > 
> > > R does not provide a pairlist data structure. This creates a dilemma
> > > when translating some list-based xlispstat code, or, more
> > > importantly, when implementing an algorithm for which parilists are
> > > the natural data structure to use.
> > > ...
> > > Pairlists were and still are used internally for many things. 
> > > ...
> > 
> > Wouldn't it, therefore, make sense to provide a 'pairlist' package which
> > exposes the internal pairlist structure and provides appropriate functions
> > (car, cdr, ...), instead of expecting people to keep re-implementing these
> > features?
> 
> Some ancient consideration pops up here. We do actually expose
> pairlists in a few places (try mode(.Options)). Some people consider
> that this is a remnant and should be stamped out, but we might also
> consider doing what you suggest. 
> 
> The big problem with old R was not so much the pairlists but that they
> were used for representing objects of mode "list" so to get to X[[n]]
> you had to count through the list from the beginning which killed
> performance in some important cases. Then again, adding elements to a
> generic vector requires copying the whole thing. Of course all the
> legacy S code tended to do the former and not the latter, so generic
> vectors ended up winning.
> 
> One or two reservations: With full lisp style access, could we end up
> with (circular) data structures that confuse the garbage collector?
> And might we -- supposing we allowed destructive list modifications --
> end up with strange semantics a la the .Alias mess we had for a while?
> Of course Luke would be the first to know about this.
> 
> Then of course there is the question of reverse compatibility. I don't
> consider it much of a loss if R code doesn't run in Splus, but others
> might.
> 
> 

The garbage collector isn't a problem--it can handle circularities
fine.  It's all the rest of the internals that would get confused (in
most cases blowing out the C stack).  But you can only get
circularities if you allow destructive modification, which you don't
need for purely functional uses and which we did not allow in the old
days of parlists for generic vectors.

But I really don't think there is much benefit in making the internal
pairlist objects available (and potentially significant cost because
I'm not sure what would break).  Writing a list package might be quite
a useful contribution, but it can be done with a pure R representation
using, say, S4 classes.  Looking at the list functions provided in CL
and in the Standard ML library might be a good way to start for anyone
who wants to give it a go.  There are also some interesting choices of
semantics.  Here are two different implementations

	Cons <- function(x, y) list(x,y)
	First <- function(x) x[[1]]
	Rest <- function(x) x[[2]]

	Cons <- function(x, y) list(function() x, function() y)
	First <- function(x) x[[1]]()
	Rest <- function(x) x[[2]]()

Performance is different (not necessarily the direction you might
expect) and semantics are different (think about what

	intsFrom <- function(n) Cons(n, intsFrom(n + 1))

does)

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
On 14 Feb 2003, Peter Dalgaard BSA wrote:

> "Warnes, Gregory R" <gregory_r_warnes at groton.pfizer.com> writes:
> 
> > > -----Original Message-----
> > > From: Luke Tierney [mailto:luke at stat.uiowa.edu]
> > 
> > > R does not provide a pairlist data structure. This creates a dilemma
> > > when translating some list-based xlispstat code, or, more
> > > importantly, when implementing an algorithm for which parilists are
> > > the natural data structure to use.
> > > ...
> > > Pairlists were and still are used internally for many things. 
> > > ...
> > 
> > Wouldn't it, therefore, make sense to provide a 'pairlist' package which
> > exposes the internal pairlist structure and provides appropriate functions
> > (car, cdr, ...), instead of expecting people to keep re-implementing these
> > features?
> 
> Some ancient consideration pops up here. We do actually expose
> pairlists in a few places (try mode(.Options)). Some people consider
> that this is a remnant and should be stamped out, but we might also
> consider doing what you suggest. 
> 
> The big problem with old R was not so much the pairlists but that they
> were used for representing objects of mode "list" so to get to X[[n]]
> you had to count through the list from the beginning which killed
> performance in some important cases. Then again, adding elements to a
> generic vector requires copying the whole thing. Of course all the
> legacy S code tended to do the former and not the latter, so generic
> vectors ended up winning.
> 
> One or two reservations: With full lisp style access, could we end up
> with (circular) data structures that confuse the garbage collector?
> And might we -- supposing we allowed destructive list modifications --
> end up with strange semantics a la the .Alias mess we had for a while?
> Of course Luke would be the first to know about this.
> 
> Then of course there is the question of reverse compatibility. I don't
> consider it much of a loss if R code doesn't run in Splus, but others
> might.
> 
> 

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From vograno at arbitrade.com  Fri Feb 14 23:39:06 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Fri Feb 14 23:39:06 2003
Subject: [R] using locator with xyplot() result
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DCFB@jupiter.arbitrade.com>

Dear R-Users,

Is there a way to interactively get location of a point on a graph produced
by xyplot() of lattice package (similar to what locator() does with a
regular plot)?

Thanks, Vadim

-------------------------------------------------- 
DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]



From deepayan at stat.wisc.edu  Fri Feb 14 23:50:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Feb 14 23:50:03 2003
Subject: [R] using locator with xyplot() result
In-Reply-To: <AFD78192EC49D311BFAE00902798AB8F23DCFB@jupiter.arbitrade.com>
References: <AFD78192EC49D311BFAE00902798AB8F23DCFB@jupiter.arbitrade.com>
Message-ID: <200302141648.57469.deepayan@stat.wisc.edu>

No.

On Friday 14 February 2003 04:37 pm, Vadim Ogranovich wrote:
> Dear R-Users,
>
> Is there a way to interactively get location of a point on a graph produced
> by xyplot() of lattice package (similar to what locator() does with a
> regular plot)?
>
> Thanks, Vadim



From j+rhelp at howard.fm  Sat Feb 15 00:07:02 2003
From: j+rhelp at howard.fm (j+rhelp@howard.fm)
Date: Sat Feb 15 00:07:02 2003
Subject: [R] Translating lm.object to SQL, C, etc function
In-Reply-To: <Pine.LNX.4.44.0302140750530.16111-100000@gannet.stats>
References: <Pine.LNX.4.44.0302140750530.16111-100000@gannet.stats>
Message-ID: <20030214230558.2B8DF482EB@server2.fastmail.fm>

On Fri, 14 Feb 2003 08:06:45 +0000 (GMT), ripley at stats.ox.ac.uk said:
> The issue here is that coef() tells you the coefficients in R's
> internal parametrization of the model, and that is of no use to you
> unless you have a means of creating a model matrix in C, SQL or (heaven
> forbid) Perl. The information needed to re-create a model matrix is
> stored in the lm fit, but in ways that are going to be hard to use
> anywhere else (since they include R functions).  This is not perverse:
> what R does is very general, *far* more so than SPSS.  Formulae in lm
> can include poly() and ns() terms, for example.
>
I understand that. And indeed a perfectly general function export is a
very big job. However, once we can export the model into a reasonably
generic textual form, simply including the text name of any R functions
in the export, then users can create special-case translators for the
parts that they need. We try to make this as easy for ourselves as
possible, for instance by doing all required transformations in SQL
(where possible) before importing to R, which means that all the terms in
the linear model are often untransformed variables. The only thing we
don't do in SQL normally is creating the contrasts, since this is
something that SQL is not well suited for.

> The only practical solution it seems to us is to ask R to create the
> model matrix for new data.  Then the things you are talking about are
> just the colnames of that matrix, and don't need to be interpreted.
>
Yes, that makes things pretty easy then, but's it's not an option in all
cases. We need to embed our models into C code. Previously we had a
routine to take the SPSS output, convert it into C code, and then
recompile the C code into our simulation. The linear model is utilised in
the inner loop of the simulation so needs to be very fast; CORBA or SOAP
calls to uncompiled code in the inner loop slow things down a great deal.
In addition, the simulation is accessed by many people - requiring all of
them install R would make the roll-out procedure much more complex.

> You may want to read the sources to find out how R does it: that area
> is one of the most complex parts of the internals, and one in which
> bugs continue to emerge.
>
I'm glad to hear it is considered complex! ;-) I've actually been reading
that bit of the code quite a bit over the last two days and haven't been
getting that far. My lack of familiarity with the language, combined with
the lack of comments in that section of code, and the very
concise/non-descriptive variable names often used in the code, make this
even harder. Still, it's a useful exercise for learning more about the
language. 

> > The difficulty I am having is that the output of coef() is not really
> > parsable, since there is no marker in the name of an coefficient of
> > separate out the components. For instance, in SPSS the name of a
> > coefficient might be:
> >
> >   var1=[a]*var2=[b]*var3
> >
> > ...which is easy to write a little script to pull that apart and
> > turn it into a line of SQL, C, or whatever. In S however the name
> > looks like:
> >
> >   var1avar2bvar3
> >
> > ...which provides no way to pull the bits apart.
>
> I find that impossible to understand anyway, but doubt that it
> corresponds to SPSS.  For a variable V, label Va does not mean V=[a]
> except in unusual special cases.
>
I should firstly mention that I got this slightly wrong - I showed above
the SPLUS output, not the R output. R actually looks like this:
  var1a:var2b:var3

The ':'s certainly help a lot, but still there's the problem of handling
factor levels, which are concatenated with the variable name without a
delimiter (at least, in all the linear models I've run so far, this is
the case).

I think with all the great feedback and ideas I've got so far on the list
and in private mail (thanks everyone!) I have enough information to make
a start. If I create anything that might be more generally useful I'll
post back of course.

Many thanks,
  Jeremy
-- 
  Jeremy Howard
  jhoward at fastmail.fm



From j+rhelp at howard.fm  Sat Feb 15 04:40:03 2003
From: j+rhelp at howard.fm (j+rhelp@howard.fm)
Date: Sat Feb 15 04:40:03 2003
Subject: [R] Translating lm.object to SQL, C, etc function
In-Reply-To: <5.1.0.14.2.20030214074620.01e4db18@mcmail.cis.mcmaster.ca>
References: <5.1.0.14.2.20030214074620.01e4db18@mcmail.cis.mcmaster.ca>
Message-ID: <20030215033935.60A99492E1@server2.fastmail.fm>

On Fri, 14 Feb 2003 07:53:46 -0500, "John Fox" <jfox at mcmaster.ca> said:
> I've written replacements for the standard R contrast functions that 
> produce the kind of more easily parsed (and more readable) contrast names 
> that I think you have in mind. I intend to include these in the next 
> release of the car package for R but haven't done so yet. Since the code 
> isn't very long, I've appended it (and the .Rd documentation file to this 
> note). Note that R does separate terms in an interaction with a colon.
> 
> I hope that this does what you need.
<...>
> ##  Coefficients:
> ##          (Intercept)                  income               education
> ##              2.275753                0.003522                1.713275
> ##          type[T.prof]              type[T.wc]     income:type[T.prof]
> ##              15.351896              -33.536652               -0.002903
> ##      income:type[T.wc]  education:type[T.prof]    education:type[T.wc]
> ##              -0.002072                1.387809                4.290875

Yes, it's perfect. Thanks so much (and also thanks for your really
readable and useful book, including web appendices)!

Regards,
  Jeremy
-- 
  Jeremy Howard
  jhoward at fastmail.fm



From h_m_ at po.harenet.ne.jp  Sat Feb 15 06:10:03 2003
From: h_m_ at po.harenet.ne.jp (Hiroto Miyoshi)
Date: Sat Feb 15 06:10:03 2003
Subject: [R] how to do regression analysis for multiple dependent variables at once
Message-ID: <002f01c2d4b0$4db2eee0$0101a8c0@hirotomi>

Dear R-users

I have, say, 5 dependent variables, d1 to d5.
And I also have 2 independent variable x1, x2.
Suppose I need to do regression analyses for all
the dependent variables, using the same set 
of independent variables, x1 and x2.

How can I do the analyses without writing five lines of
lm(d1~x1*x2)
lm(d2~x1*x2)
lm(d3~x1*x2)
lm(d4~x1*x2)
lm(d5~x1*x2)

I like to write the R codes something like
l <- c("d1","d2","d3","d4","d5")
for( i in l ) lm(i~x1*x2).

However, this does not work.

I hope you get the idea about what I want to do.
So, Could you help me.
Sincerely

---------------------------
Hiroto Miyoshi???????
h_m_ at po.harenet.ne.jp



From edd at debian.org  Sat Feb 15 06:17:00 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat Feb 15 06:17:00 2003
Subject: [R] time series  missing 0 counts
In-Reply-To: <Pine.LNX.4.44.0302141114130.16334-100000@gannet.stats>
References: <3DDCC4D685EE744B9FB47706995CFCD102236174@SEMAIL01.RKI.IVBB.BUND.DE> <Pine.LNX.4.44.0302141114130.16334-100000@gannet.stats>
Message-ID: <20030215050907.GA4887@sonny.eddelbuettel.com>

On Fri, Feb 14, 2003 at 11:21:33AM +0000, ripley at stats.ox.ac.uk wrote:
> Yes, there is an easy way.  Create the regular time series you want by 
> something like
> 
> x <- ts(0, start=c(2000,52), end=c(2003,9), frequency=52)
> 
> and fill in the time points you have data for by
> 
> xYear <- trunc(times(x)); xWeek <- cycle(x)
> attach(mydata)
> x[(xYear==year) & (xWeek==Week)] <- Count
> detach()

But won't this will fail for weeks with a count number of 0 or 53 (as both
of those are outside the ts() range specified above)?  

As 52*7=364 is different from the number of days in a year, each year is
bound to have one of those unless the data is pre-scrubbed.

Dirk


> Easy!
> 
> On Fri, 14 Feb 2003, Schnitzler, Johannes wrote:
> 
> > > I have several large data sets with counts per week. 
> > > (Maximum week per year is 52. Counts from Week 53
> > > are added to week 52.) 
> > > 
> > > A data set contains for example:
> > > 
> > > Year	Week	Count
> > > 2000 	52	2
> > > 2001	1	5
> > > 2001	2	7
> > > 2001	5	4
> > > 2001	7	2
> > > ...	...	...
> > > ...	...	...
> > > 
> > > Weeks with 0 counts are not listed in the data set.
> > > I want to perform time series analysis (frequency 52).
> > > 
> > > 
> > > Is there an easy way to expand the data set to:
> > > 
> > > Year	Week	Count
> > > 2000	52	2
> > > 2001	1	5
> > > 2001	2	7
> > > 2001	3	0
> > > 2001	4	0
> > > 2001	5	4
> > > 2001	6	0
> > > 2001	7	2
> > > ...	...	...
> > > ...	...	...
> > > 
> > > or is there already a function in "ts", which i have not found so far,
> > > to deal with this problem?
> > > 
> > > 
> > > Thank you very much.
> > > 
> > > Johannes Schnitzler
> > > Germany Berlin
> > > 
> > >  
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr



From Roger.Bivand at nhh.no  Sat Feb 15 10:54:03 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat Feb 15 10:54:03 2003
Subject: [R] matrix from sequences
In-Reply-To: <BAY2-F22zgwKzBBrYK90002b297@hotmail.com>
Message-ID: <Pine.LNX.4.44.0302151036040.1871-100000@reclus.nhh.no>

On Fri, 14 Feb 2003, Miha STAUT wrote:

> >Hi, Miha:
> >
> >1.  How do I get the GRASS library?  "library(GRASS)" produced "Error in 
> >library(GRASS) : There is no package called `GRASS'" for me from R 1.6.2 
> >for Windows.
> 
> I do not know whether it exists for Windows or not, but look under:
> http://cran.r-project.org/src/contrib/Devel/
> Or visit:
> http://grass.itc.it/index.html

There is as yet no pre-compiled GRASS package for GRASS/Cygwin and 
R/MinGW, although there are hints on the GRASS site about how one might 
build one from the GRASS source package (look for the geostatistics link). 

(Incidentally, library(GRASS) loads an installed package - you would need 
to install it first for library() to find it)

This has been the subject of discussion on the GRASS developers' list 
recently, and a revised source package will be released soon that will 
also build using the standard R MinGW toolset under Windows. 

> 
> >
> >2.  I assume there is a typographical error in the last line of your email: 
> >  If G$xseq and $yseq are coordinates of points, then length(G$xseq) == 
> >length(G$yseq)???  In that case, 'as.matrix(G[,c("xseq", "yseq")])' should 
> >give you what you want.


length(G$xseq) == length(G$yseq) only by coincidence for square grids. The 
values of xseq are the midpoint eastings of raster columns, of yseq the 
midpoint northings (north to south) of the raster rows, and are mostly 
used to get image() to display data correctly. There are two helper 
functions: east(G) and north(G), that unroll the sequences to give a 
complete list of raster cell midpoints in the order GRASS rasters store 
data (starting at the NW (aka top left) corner). So:

cbind(east(G), north(G))

should give you what you need. You will see this used inside krige.G() in 
the same package (there optionally checking for a mask too).

Please contact me off-list, or via the dedicated R/GRASS list described 
on: http://grass.itc.it/statsgrass/index.html

Roger

> OK I really am lousy at explaining things. The length(G$xseq) * 
> length(G$yseq) stands because you have to get all the permutations of the 
> elements of those two sequences. Get it? If you have:
> xseq<-1:10
> yseq<-1:10
> I would like to get:
>       x
> y     [,1] [,2] [,3] [,4] [,5] ...
> [1,]
> [2,]
> [3,]
> [4,]
> ...
> 
> or
> 
> str(xy)
> $x 1,1,1,1,1,1,1,1,1,1,2,2,2,...
> $y 1,2,3,4,5,6,7,8,9,10,1,2,3,...
> 




> 
> >Spencer Graves
> >
> >Miha STAUT wrote:
> >>>Miha STAUT wrote:
> >>>
> >>>>Hi all,
> >>>>
> >>>>I have a data frame with sequences of x and y from a map. I would like 
> >>>>to know it both ways:
> >>>>1. How to make a matrix from that;
> >>>>2. how to make a data frame of all points in a map.
> >>>>
> >>>>Probably it is a silly question, but please tell me where to read about 
> >>>>it or tell me how to do it.
> >>>>
> >>>>Miha Staut
> >>>>
> >>>>______________________________________________
> >>>>R-help at stat.math.ethz.ch mailing list
> >>>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>>>
> >>>Hi Miha,
> >>>
> >>>1) What is the structure of your data.frame ? Assuming all co-ordinates 
> >>>are in the same column (one column for x and one column for y), the 
> >>>simplest way to extract them and turn them into a matrix would be:
> >>>
> >>>as.matrix(mydata[ , c("x", "y")])
> >>>
> >>>e.g.:
> >>>
> >>>R>mydata <- data.frame(x = rnorm(10), y = rnorm(10), z = rnorm(10))
> >>>R>mydata
> >>>              x           y          z
> >>>1  -0.73735224 -0.51218243 -0.9602624
> >>>2  -1.46079091 -0.63634091  1.4967066
> >>>3  -0.28574919 -1.30719383 -0.2887403
> >>>4   0.04137159  0.61711350 -0.7057102
> >>>5   0.03179303  0.05734869 -0.4637660
> >>>6  -0.06638058 -0.74565157  0.9239402
> >>>7  -0.67611541 -1.01760810 -0.2854017
> >>>8   0.34215052  0.30564550  0.6931193
> >>>9   0.83597837  0.75443762 -2.3394679
> >>>10 -0.14967073 -0.02027512 -0.1143414
> >>>R>as.matrix(mydata[ , c("x", "y")])
> >>>              x           y
> >>>1  -0.73735224 -0.51218243
> >>>2  -1.46079091 -0.63634091
> >>>3  -0.28574919 -1.30719383
> >>>4   0.04137159  0.61711350
> >>>5   0.03179303  0.05734869
> >>>6  -0.06638058 -0.74565157
> >>>7  -0.67611541 -1.01760810
> >>>8   0.34215052  0.30564550
> >>>9   0.83597837  0.75443762
> >>>10 -0.14967073 -0.02027512
> >>>
> >>>
> >>>2) How are the points stored ? If in a matrix, say mat, with 2 columns 
> >>>for x and y, simply:
> >>>
> >>>as.data.frame(mat)
> >>>
> >>>Best,
> >>>
> >>>Renaud
> >>
> >>
> >>
> >>Thanks to both of you (Dr Renaud Lancelot and James Holtman)
> >>
> >>I see I formulated the question in a wrong way. I got from GRASS the 
> >>coordinates of a map. There is a package in R named GRASS to connect R 
> >>with GRASS.
> >>
> >>library(GRASS)
> >>G<-gmeta() # copy the environment from GRASS
> >>
> >>Now G is a data frame containig also $xseq and $yseq which would be the 
> >>coordinates of all the points in x and y direction. The final matrix 
> >>should have length(G$xseq) * length(G$yseq) points.
> >>
> >>Miha Staut
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From Stefan.Strecker at iw.uni-karlsruhe.de  Sat Feb 15 12:50:03 2003
From: Stefan.Strecker at iw.uni-karlsruhe.de (Strecker, Stefan)
Date: Sat Feb 15 12:50:03 2003
Subject: [R] How to code a bootstrap version of the Wilcoxon-Mann-Whitney test (and variants)?
Message-ID: <D5F4FCB34ECBC041992A289145E3FD662208AB@ibwsrvp2.iw.uni-karlsruhe.de>

Hello,

can someone please help me with coding a function for a bootstrap WMW test (package boot, R under Windows, version 1.6.2)?


From baron at cattell.psych.upenn.edu  Sat Feb 15 13:26:03 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sat Feb 15 13:26:03 2003
Subject: [R] how to do regression analysis for multiple dependent variables at once
In-Reply-To: <002f01c2d4b0$4db2eee0$0101a8c0@hirotomi>; from h_m_@po.harenet.ne.jp on Sat, Feb 15, 2003 at 02:08:39PM +0900
References: <002f01c2d4b0$4db2eee0$0101a8c0@hirotomi>
Message-ID: <20030215072505.A7951@cattell.psych.upenn.edu>

On 02/15/03 14:08, Hiroto Miyoshi wrote:
>Dear R-users
>
>I have, say, 5 dependent variables, d1 to d5.
>And I also have 2 independent variable x1, x2.
>Suppose I need to do regression analyses for all
>the dependent variables, using the same set 
>of independent variables, x1 and x2.
>
>How can I do the analyses without writing five lines of
>lm(d1~x1*x2)
>lm(d2~x1*x2)
>lm(d3~x1*x2)
>lm(d4~x1*x2)
>lm(d5~x1*x2)

lm(cbind(d1,d2,d3,d4,d5)~x1*x2)

This is because the dependent variable in lm() can be a matrix
instead of a vector.

It says this in "In introduction to R" under "Formula for
statistical models."  But I could not find this in the help page
for lm() or formula().

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
R page:               http://finzi.psych.upenn.edu/



From xiao.gang.fan1 at libertysurf.fr  Sat Feb 15 14:30:06 2003
From: xiao.gang.fan1 at libertysurf.fr (Fan)
Date: Sat Feb 15 14:30:06 2003
Subject: [R] Type of multi-valued variable
References: <3E4810E6.2E520ADF@libertysurf.fr> <20030210162449.05ceb2c1.fharrell@virginia.edu>
Message-ID: <3E4E4375.A7637446@libertysurf.fr>

Thanks to Frank for pointing out that. There're so many "misc" in the 
package hmisc, I haven't yet explored all the functionalities !

The implementation of mChoice / summary() is very interesting, and it could
be a good starting point for adding more functionalities on the class mChoice.

I'm having a little question on the usage of the function summary.formula() in hmisc:
how to get the cross tabluations result like an array, as what xtabs does ?

For example, suppose "titanic" is a dataset as the following:
> str(titanic)
`data.frame':   1313 obs. of  11 variables:
 $ pclass   : Factor w/ 3 levels "1st","2nd","3rd": 1 1 1 1 1 1 1 1 1 1 ...
 $ survived : int  1 0 0 0 1 1 1 0 1 0 ...
 $ sex      : Factor w/ 2 levels "female","male": 1 1 2 1 2 2 1 2 1 2 ...
 $ age      : num  29.000  2.000 30.000 25.000  0.917 ...
 ...

> ftable(xtabs( ~ sex + pclass + survived, data=titanic))
              survived   0   1
sex    pclass                 
female 1st               9 134
       2nd              13  94
       3rd             134  79
male   1st             120  59
       2nd             148  25
       3rd             440  58

My question is how to get that with hmisc::summary() ?
(survived could be a mChoice variable)

Thanks in advance
--
Fan

Frank E Harrell Jr a ?crit :
> 
> On Mon, 10 Feb 2003 21:51:50 +0100
> Fan <xiao.gang.fan1 at libertysurf.fr> wrote:
> 
> > Hi,
> >
> > I've read in the past a thead in the R discussion list
> > about the multi-valued type variable (what was called checklist).
> > At the moment Gregory had intention to add some general code
> > in his gregmisc package.
> >
> > I'm wondering if there's some general code / packages available ?
> >
> > A general class for taking account this type of variable
> > would be very useful in the domain of survey processings,
> > as multi-responses questions are often used.
> > The simple operations applied to these variables are holecount,
> > cross tabulations with others variables, transformation to single
> > coded variables like number of responses, etc.
> >
> > Thanks in advance for any help
> > --
> > Fan
> >
> 
> Fan, Take a look at p. 38-44 of http://hesweb1.med.virginia.edu/biostat/s/doc/summary.pdf where examples of the mChoice (multiple choice) function in Hmisc are given.
> 
> --
> Frank E Harrell Jr              Prof. of Biostatistics & Statistics
> Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
> U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From xiao.gang.fan1 at libertysurf.fr  Sat Feb 15 16:35:03 2003
From: xiao.gang.fan1 at libertysurf.fr (Fan)
Date: Sat Feb 15 16:35:03 2003
Subject: [R] ESRI shape file import and time-space models
References: <76A000A82289D411952F001083F9DD06039ACA54@exsalem4-bu.odot.state.or.us>
Message-ID: <3E4E6099.540C795A@libertysurf.fr>

For reading dBase file on Windows, one can use ODBC with the following 
wrapper function if fast loading is an important issue:

odbc.dbase <- function(dbf.file, rownames=FALSE)
{
  connstr <- paste("Driver={Microsoft dBASE Driver (*.dbf)};DriverID=277;Dbq=", getwd(),
sep="")
  o <- odbcDriverConnect(connstr)
  ans <- sqlQuery(o, paste("select * from", basename(dbf.file)), rownames)
  odbcClose(o)
  ans
}

It's much faster than the R function read.dbf() of Benjamin, here's a little bench:

> system.time(read.dbf("xxx.dbf"))
[1]   NA   NA 25.2   NA   NA

> system.time(odbc.dbase("xxx.dbf"))
[1]   NA   NA 4.54   NA   NA

I have also a C implementation which is even more fast:
> system.time(read.dbase("xxx.dbf"))
[1]   NA   NA 1.83   NA   NA
But I think the odbc wrapper is suffisant enough and conceptually more
general (the same method can be used for Excel file, MS Access file).

Cheers
--
Fan

Benjamin.STABLER at odot.state.or.us:
> 
> Attached are some functions that I wrote to read and write shapefiles and
> dbfs easily from within R.  You do not need any additional libraries or C
> code.  I am still working out a few bugs but I have tested it with quite a
> few different files and it seems to be working pretty well.  There is little
> documentation at this point though.  I'd appreciate any comments about the
> code.  Thanks.
> 
> Benjamin Stabler
> Transportation Planning Analysis Unit
> Oregon Department of Transportation
> 555 13th Street NE, Suite 2
> Salem, OR 97301  Ph: 503-986-4104
> 
> >Dear R user,
> >I am running R under Windows 2000.
> 
> >I am looking for a routine for importing
> 
> 
> 
> >        shape files (ESRI) into R
> 
> >        dbase files (FOXPRO) into R
> 
> >and I am looking for time-space models for description and prediction of
> >Bernoulli-, Binomial- and Poissonvaraibles.
> 
> >Thank's a lot for a reply.
> 
> >Sincerely yours,
> 
> >Ekkehardt Altpeter
> 
> >Swiss Federal Office of Public Health.
> 
>   ------------------------------------------------------------------------------------------
>                    Name: shapefiles.R
>    shapefiles.R    Type: fichier R (application/x-unknown-content-type-R_auto_file)
>                Encoding: quoted-printable



From kawa at aris.ss.uci.edu  Sat Feb 15 17:45:03 2003
From: kawa at aris.ss.uci.edu (Hiroyuki Kawakatsu)
Date: Sat Feb 15 17:45:03 2003
Subject: [R] print with no array index
Message-ID: <Pine.GSO.4.30.0302150838010.21123-100000@aris.ss.uci.edu>

hi,

can someone tell me an easy way to print arrays interactively without
printing the array index? for example, instead of

> print("foo",quote=FALSE)
[1] foo

i want

foo

thanks,
h.
--------------------------------------------------------------------
Time series regression studies give no sign of converging toward the
truth. (Phillip Cagan)



From rmeeksweb at hotmail.com  Sat Feb 15 17:52:04 2003
From: rmeeksweb at hotmail.com (r meeks)
Date: Sat Feb 15 17:52:04 2003
Subject: [R] RMySQL
Message-ID: <F154wJRyAjPlj586ONn000204ac@hotmail.com>

I don't know if this is the proper forum but here goes:

I'm trying to install the RMySQL library under Windows XP.  The instructions 
say to use reimp to create an R-compatible MySQL library file "libmysql.dll" 
but when I try to run reimp I get the error "reimp: dlltool: No such file or 
directory"

Obviously something is missing or can't be found but I can't tell what from 
the message!  I'm using fresh downloads of mingw utils and the RMySQL 
library.

And of course the library doesn't work in R - I get the message "Error in 
testRversion(descfile) : This package has not been installed properly
See the Note in ?library" when I try to load it.

Other libraries work fine.  I realize this failure is due to the reimport 
failure.

Any suggestions?

Bob Meeks



From mschwartz at medanalytics.com  Sat Feb 15 17:55:27 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sat Feb 15 17:55:27 2003
Subject: [R] print with no array index
In-Reply-To: <Pine.GSO.4.30.0302150838010.21123-100000@aris.ss.uci.edu>
Message-ID: <002001c2d512$8a889650$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Hiroyuki
Kawakatsu
>Sent: Saturday, February 15, 2003 10:45 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] print with no array index
>
>
>hi,
>
>can someone tell me an easy way to print arrays interactively 
>without printing the array index? for example, instead of
>
>> print("foo",quote=FALSE)
>[1] foo
>
>i want
>
>foo
>
>thanks,
>h.

Look at ?cat

You will need to add a newline character "\n" to the vector.

For example:

> cat("foo\n")
foo
>

Regards,

Marc Schwartz



From ligges at statistik.uni-dortmund.de  Sat Feb 15 18:07:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Feb 15 18:07:03 2003
Subject: [R] RMySQL
In-Reply-To: <F154wJRyAjPlj586ONn000204ac@hotmail.com>
References: <F154wJRyAjPlj586ONn000204ac@hotmail.com>
Message-ID: <3E4E73AF.20705@statistik.uni-dortmund.de>

r meeks wrote:
> I don't know if this is the proper forum but here goes:
> 
> I'm trying to install the RMySQL library under Windows XP.  The 
> instructions say to use reimp to create an R-compatible MySQL library 
> file "libmysql.dll" but when I try to run reimp I get the error "reimp: 
> dlltool: No such file or directory"
> 
> Obviously something is missing or can't be found but I can't tell what 
> from the message!  I'm using fresh downloads of mingw utils and the 
> RMySQL library.
> 
> And of course the library doesn't work in R - I get the message "Error 
> in testRversion(descfile) : This package has not been installed properly
> See the Note in ?library" when I try to load it.
> 
> Other libraries work fine.  I realize this failure is due to the 
> reimport failure.
> 
> Any suggestions?

Most easiest: Download and install the binary file from

  http://cran.r-project.org/bin/windows/contrib/RMySQL.zip

or any appropriate CRAN mirror.

And read the file README.windows which path has to be set in your 
environment variable PATH.


Uwe Ligges


> Bob Meeks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tblackw at umich.edu  Sat Feb 15 18:13:03 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Sat Feb 15 18:13:03 2003
Subject: [R] print with no array index
In-Reply-To: <Pine.GSO.4.30.0302150838010.21123-100000@aris.ss.uci.edu>
Message-ID: <Pine.SOL.4.44.0302151206000.7948-100000@robotron.gpcc.itd.umich.edu>

Hiroyuki  -

Function  write()  with "" as its second argument might do
what you want.  This function does not check the "dims"
attribute of its first argument, so you have to set that
explicitly.  See  help(write), help(format), help(cat).

Seems unfortunate that  help(print)  does not point backwards
to these alternatives.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



On Sat, 15 Feb 2003, Hiroyuki Kawakatsu wrote:

> hi,
>
> can someone tell me an easy way to print arrays interactively without
> printing the array index? for example, instead of
>
> > print("foo",quote=FALSE)
> [1] foo
>
> i want
>
> foo
>
> thanks,
> h.
> --------------------------------------------------------------------
> Time series regression studies give no sign of converging toward the
> truth. (Phillip Cagan)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Sat Feb 15 18:17:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Feb 15 18:17:03 2003
Subject: [R] RMySQL
In-Reply-To: <F154wJRyAjPlj586ONn000204ac@hotmail.com>
Message-ID: <Pine.LNX.4.44.0302151711290.25815-100000@gannet.stats>

dlltool is part of the compiler set, so that's where your troubles begin.

However, the instructions are not those for the binary install.  All you
need to do is to get RMySQL.zip from CRAN and put RMySQL/libs/libmysql.dll
somewhere in your path.

On Sat, 15 Feb 2003, r meeks wrote:

> I don't know if this is the proper forum but here goes:
> 
> I'm trying to install the RMySQL library under Windows XP.  The instructions 
> say to use reimp to create an R-compatible MySQL library file "libmysql.dll" 
> but when I try to run reimp I get the error "reimp: dlltool: No such file or 
> directory"
> 
> Obviously something is missing or can't be found but I can't tell what from 
> the message!  I'm using fresh downloads of mingw utils and the RMySQL 
> library.
> 
> And of course the library doesn't work in R - I get the message "Error in 
> testRversion(descfile) : This package has not been installed properly
> See the Note in ?library" when I try to load it.
> 
> Other libraries work fine.  I realize this failure is due to the reimport 
> failure.
> 
> Any suggestions?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From cmoffet at nwrc.ars.usda.gov  Sat Feb 15 18:51:02 2003
From: cmoffet at nwrc.ars.usda.gov (Corey Moffet)
Date: Sat Feb 15 18:51:02 2003
Subject: [R] tests for spericity
Message-ID: <3.0.6.32.20030215105026.01015410@nwrc.ars.usda.gov>

Dear R-help,

Does any one know of a function/package in R that will test the assumption of
spericity in a split-plot analysis of variance?  How are people dealing with 
this issue in R?
With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Support Scientist

University of Idaho
Northwest Watershed Research Center
800 Park Blvd, Plaza IV, Suite 105
Boise, ID 83712-7716
(208) 422-0718



From rmeeksweb at hotmail.com  Sat Feb 15 19:22:03 2003
From: rmeeksweb at hotmail.com (r meeks)
Date: Sat Feb 15 19:22:03 2003
Subject: [R] RMySQL
Message-ID: <F110SgNpaMo0oETQGYb0000d074@hotmail.com>

Thank you - it works great now.


>From: ripley at stats.ox.ac.uk
>To: r meeks <rmeeksweb at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] RMySQL
>Date: Sat, 15 Feb 2003 17:14:50 +0000 (GMT)
>
>dlltool is part of the compiler set, so that's where your troubles begin.
>
>However, the instructions are not those for the binary install.  All you
>need to do is to get RMySQL.zip from CRAN and put RMySQL/libs/libmysql.dll
>somewhere in your path.
>
>On Sat, 15 Feb 2003, r meeks wrote:
>
> > I don't know if this is the proper forum but here goes:
> >
> > I'm trying to install the RMySQL library under Windows XP.  The 
>instructions
> > say to use reimp to create an R-compatible MySQL library file 
>"libmysql.dll"
> > but when I try to run reimp I get the error "reimp: dlltool: No such 
>file or
> > directory"
> >
> > Obviously something is missing or can't be found but I can't tell what 
>from
> > the message!  I'm using fresh downloads of mingw utils and the RMySQL
> > library.
> >
> > And of course the library doesn't work in R - I get the message "Error 
>in
> > testRversion(descfile) : This package has not been installed properly
> > See the Note in ?library" when I try to load it.
> >
> > Other libraries work fine.  I realize this failure is due to the 
>reimport
> > failure.
> >
> > Any suggestions?
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sat Feb 15 19:46:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Feb 15 19:46:05 2003
Subject: [R] tests for spericity
In-Reply-To: <3.0.6.32.20030215105026.01015410@nwrc.ars.usda.gov>
Message-ID: <Pine.LNX.4.44.0302151839350.28130-100000@gannet.stats>

I can guess you meant `sphericity', but you didn't tell us of what. Note
that the `analysis of variance' is an algorithm to partition sums of
squares, and that makes no such assumption.

I suspect that you could do what you want in lme (package nlme), if you
were able to specify it unambiguously.

On Sat, 15 Feb 2003, Corey Moffet wrote:

> Does any one know of a function/package in R that will test the assumption of
> spericity in a split-plot analysis of variance?  How are people dealing with 
> this issue in R?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pzhang at hsph.harvard.edu  Sat Feb 15 19:50:03 2003
From: pzhang at hsph.harvard.edu (Peng Zhang)
Date: Sat Feb 15 19:50:03 2003
Subject: [R] (no subject)
Message-ID: <Pine.GSO.4.53.0302151346350.25271@hsph.harvard.edu>

Hi,

Are there some packages which can generate multi-normal, multi-t, etc
multivariate sampling? thanks!

Best wishes,
Peng

*******************************
Peng Zhang
Department of Biostatistics
Harvard School of Public Health
655 Huntington Avenue
Boston, Massachusetts 02115
*******************************

I believe I can fly
I believe I can touch the sky



From bates at stat.wisc.edu  Sat Feb 15 19:54:04 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat Feb 15 19:54:04 2003
Subject: [R] Perl on Windows XP for Rcmd build
Message-ID: <6rvfzlz89f.fsf@bates4.stat.wisc.edu>

Is there a recommended binary version of perl to use under Windows XP
for `Rcmd build'?  The R FAQ for Windows just mentions "perl".  I
think that Kevin Wang's document on R for Windows suggests ActiveState
perl but I have not been able to install it.  

I am running Windows XP Professional on a laptop.  The operating
system was originally Windows 98 then upgraded to Windows ME then to
XP Pro.  I have downloaded the MSI installer version of ActiveState
perl 5.8.0 and tried to install it.  All that happens when I execute
the installer is that I get a command prompt window that exits a few
moments later, apparently with no effect.  I tried this a few times,
rebooted the computer and tried again and still no luck.  I then
removed the 5.8.0 installer and downloaded the ActivePerl-5.6.1.635
MSI installer instead but the same thing happened.

Should I try Apache Perl or some other binary distribution instead?

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From fharrell at virginia.edu  Sat Feb 15 20:05:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sat Feb 15 20:05:03 2003
Subject: [R] Type of multi-valued variable
In-Reply-To: <3E4E4375.A7637446@libertysurf.fr>
References: <3E4810E6.2E520ADF@libertysurf.fr>
	<20030210162449.05ceb2c1.fharrell@virginia.edu>
	<3E4E4375.A7637446@libertysurf.fr>
Message-ID: <20030215140422.23c55f88.fharrell@virginia.edu>

On Sat, 15 Feb 2003 14:41:09 +0100
Fan <xiao.gang.fan1 at libertysurf.fr> wrote:

> Thanks to Frank for pointing out that. There're so many "misc" in the 
> package hmisc, I haven't yet explored all the functionalities !
> 
> The implementation of mChoice / summary() is very interesting, and it could
> be a good starting point for adding more functionalities on the class mChoice.
> 
> I'm having a little question on the usage of the function summary.formula() in hmisc:
> how to get the cross tabluations result like an array, as what xtabs does ?
> 
> For example, suppose "titanic" is a dataset as the following:
> > str(titanic)
> `data.frame':   1313 obs. of  11 variables:
>  $ pclass   : Factor w/ 3 levels "1st","2nd","3rd": 1 1 1 1 1 1 1 1 1 1 ...
>  $ survived : int  1 0 0 0 1 1 1 0 1 0 ...
>  $ sex      : Factor w/ 2 levels "female","male": 1 1 2 1 2 2 1 2 1 2 ...
>  $ age      : num  29.000  2.000 30.000 25.000  0.917 ...
>  ...
> 
> > ftable(xtabs( ~ sex + pclass + survived, data=titanic))
>               survived   0   1
> sex    pclass                 
> female 1st               9 134
>        2nd              13  94
>        3rd             134  79
> male   1st             120  59
>        2nd             148  25
>        3rd             440  58
> 
> My question is how to get that with hmisc::summary() ?
> (survived could be a mChoice variable)
> 
> Thanks in advance
> --
> Fan
> 
> > 
> > On Mon, 10 Feb 2003 21:51:50 +0100
> > Fan <xiao.gang.fan1 at libertysurf.fr> wrote:
> > 
> > > Hi,
> > >
> > > I've read in the past a thead in the R discussion list
> > > about the multi-valued type variable (what was called checklist).
> > > At the moment Gregory had intention to add some general code
> > > in his gregmisc package.
> > >
> > > I'm wondering if there's some general code / packages available ?
> > >
> > > A general class for taking account this type of variable
> > > would be very useful in the domain of survey processings,
> > > as multi-responses questions are often used.
> > > The simple operations applied to these variables are holecount,
> > > cross tabulations with others variables, transformation to single
> > > coded variables like number of responses, etc.
> > >
> > > Thanks in advance for any help
> > > --
> > > Fan
> > >
> > 
> > Fan, Take a look at p. 38-44 of http://hesweb1.med.virginia.edu/biostat/s/doc/summary.pdf where examples of the mChoice (multiple choice) function in Hmisc are given.

Hello Fan,

[This reminds me that I forgot to mail you a paper I promised - will do that on Monday - Sorry]  For cross-classification, summarize in Hmisc is favored over summary(..., method='cross')  and summary(..., method='cross') does not handle mChoice variables until I make a small change to use the new function about to be described.  If you define

as.character.mChoice <- function(x) {
  lev <- dimnames(x)[[2]]
  d <- dim(x)
  w <- rep('',d[1])
  for(j in 1:d[2]) {
    w <- paste(w,ifelse(w!='' & x[,j],',',''),
               ifelse(x[,j],lev[j],''),sep='')
  }
w
}

you can add the line 
        if(inherits(xi,'mChoice')) xi <- as.character(xi) else
before
        if(is.matrix(xi) && ncol(xi) > 1) 
in summary.formula and obtain an (ugly) output with method='cross'.  Defining as.character.mChoice will fix summarize (here I'm using the titanic3 data frame):

n <- nrow(titanic3)
set.seed(1)
w <- c('good','bad','ugly')
a <- factor(sample(w,n,TRUE))
b <- factor(sample(w,n,TRUE))
m <- mChoice(a,b)
table(as.character(m))

      bad  bad,good  bad,ugly      good good,ugly      ugly 
      146       275       284       150       319       135 

attach(titanic3)
summarize(survived,llist(sex,pclass,m),
          function(y)c(died=sum(y==0),lived=sum(y==1)))

      sex pclass         m survived lived
1  female    1st       bad        0    14
2  female    1st  bad,good        1    28
3  female    1st  bad,ugly        0    34
4  female    1st      good        3    21
5  female    1st good,ugly        1    33
6  female    1st      ugly        0     9
7  female    2nd       bad        2    13
8  female    2nd  bad,good        1    28
9  female    2nd  bad,ugly        4    13
10 female    2nd      good        1     9
11 female    2nd good,ugly        4    19
. . . .

Here m is the multiple choice variable, not survived, but you get the idea.
These changes will be in the next version of Hmisc.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From tlumley at u.washington.edu  Sat Feb 15 20:10:06 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat Feb 15 20:10:06 2003
Subject: [R] how to do regression analysis for multiple dependent variables
 at once
In-Reply-To: <20030215072505.A7951@cattell.psych.upenn.edu>
Message-ID: <Pine.A41.4.44.0302151104020.42694-100000@homer29.u.washington.edu>

On Sat, 15 Feb 2003, Jonathan Baron wrote:
>
> lm(cbind(d1,d2,d3,d4,d5)~x1*x2)
>
> This is because the dependent variable in lm() can be a matrix
> instead of a vector.
>
> It says this in "In introduction to R" under "Formula for
> statistical models."  But I could not find this in the help page
> for lm() or formula().

There's an allusion to it in describing the value returned by lm(), but
I'll add an actual description.

	-thomas



From jerome at hivnet.ubc.ca  Sat Feb 15 20:17:03 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Sat Feb 15 20:17:03 2003
Subject: [R] (no subject)
In-Reply-To: <Pine.GSO.4.53.0302151346350.25271@hsph.harvard.edu>
References: <Pine.GSO.4.53.0302151346350.25271@hsph.harvard.edu>
Message-ID: <200302151921.LAA16902@hivnet.ubc.ca>

For multivariate normal and t distribution, install and try package "mvtnorm".
Then look for ?rmvnorm and ?rmvt.

Jerome

On Saturday 15 February 2003 10:48, Peng Zhang wrote:
> Content-Length: 501
> Status: R
> X-Status: N
>
> Hi,
>
> Are there some packages which can generate multi-normal, multi-t, etc
> multivariate sampling? thanks!
>
> Best wishes,
> Peng
>
> *******************************
> Peng Zhang
> Department of Biostatistics
> Harvard School of Public Health
> 655 Huntington Avenue
> Boston, Massachusetts 02115
> *******************************
>
> I believe I can fly
> I believe I can touch the sky
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 

Jerome Asselin (J?r?me)
Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital
608 - 1081 Burrard Street
Vancouver, British Columbia
CANADA V6Z 1Y6

Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044



From p.dalgaard at biostat.ku.dk  Sat Feb 15 20:22:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sat Feb 15 20:22:03 2003
Subject: [R] (no subject)
In-Reply-To: <Pine.GSO.4.53.0302151346350.25271@hsph.harvard.edu>
References: <Pine.GSO.4.53.0302151346350.25271@hsph.harvard.edu>
Message-ID: <x2of5d1h6z.fsf@biostat.ku.dk>

Peng Zhang <pzhang at hsph.harvard.edu> writes:

> Hi,
> 
> Are there some packages which can generate multi-normal, multi-t, etc
> multivariate sampling? thanks!
> 
> Best wishes,
> Peng

This was discussed here in October. For the multivariate T you can use

   rmvt <- function(corr,df)
            rmvnorm(n,sigma=corr)/sqrt(rchisq(n,df)/df)

(R.Koenker, correcting my suggestion). I believe rmvnorm came from the
mvtnorm package but there's also mvrnorm in library(MASS).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Sat Feb 15 20:28:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sat Feb 15 20:28:03 2003
Subject: [R] (no subject)
In-Reply-To: <x2of5d1h6z.fsf@biostat.ku.dk>
References: <Pine.GSO.4.53.0302151346350.25271@hsph.harvard.edu>
	<x2of5d1h6z.fsf@biostat.ku.dk>
Message-ID: <x2k7g11gxs.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> This was discussed here in October. For the multivariate T you can use
> 
>    rmvt <- function(corr,df)
>             rmvnorm(n,sigma=corr)/sqrt(rchisq(n,df)/df)
> 
> (R.Koenker, correcting my suggestion). I believe rmvnorm came from the
> mvtnorm package but there's also mvrnorm in library(MASS).

... and of course Torsten in the meantime added that one to the
mvtnorm package as Jerome points out. Doh!

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From mschwartz at medanalytics.com  Sat Feb 15 20:34:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sat Feb 15 20:34:03 2003
Subject: [R] Perl on Windows XP for Rcmd build
In-Reply-To: <6rvfzlz89f.fsf@bates4.stat.wisc.edu>
Message-ID: <002901c2d529$15c20f10$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Douglas Bates
>Sent: Saturday, February 15, 2003 12:52 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Perl on Windows XP for Rcmd build
>
>
>Is there a recommended binary version of perl to use under 
>Windows XP for `Rcmd build'?  The R FAQ for Windows just 
>mentions "perl".  I think that Kevin Wang's document on R for 
>Windows suggests ActiveState perl but I have not been able to 
>install it.  
>
>I am running Windows XP Professional on a laptop.  The 
>operating system was originally Windows 98 then upgraded to 
>Windows ME then to XP Pro.  I have downloaded the MSI 
>installer version of ActiveState perl 5.8.0 and tried to 
>install it.  All that happens when I execute the installer is 
>that I get a command prompt window that exits a few moments 
>later, apparently with no effect.  I tried this a few times, 
>rebooted the computer and tried again and still no luck.  I 
>then removed the 5.8.0 installer and downloaded the 
>ActivePerl-5.6.1.635 MSI installer instead but the same thing
happened.
>
>Should I try Apache Perl or some other binary distribution instead?
>
>-- 
>Douglas Bates                            bates at stat.wisc.edu
>Statistics Department                    608/262-2598
>University of Wisconsin - Madison        
>http://www.stat.wisc.edu/~bates/


Doug,

I have ActiveState 5.6 installed on my XP Pro system, having used the
.msi version of the install program.

You might want to be sure that you have all XP updates installed,
which would include the SP1a update.  This is available at
http://www.microsoft.com/WindowsXP/pro/downloads/servicepacks/sp1/defa
ult.asp or you can use IE to go to Windows Update and get any required
updates there.  Mozilla (not surprisingly) will not work there.  

There are no updates to my knowledge for XP for the installer program,
though there are for Win9x/NT to upgrade to version 2. It is possible
of course that something has been compromised on your system, given
the OS updates.

Prompted by your e-mail, I just upgraded to 5.8 and had no problem
just double-clicking on the .msi install file.

If you continue to have a problem, you can download the .zip version
of the 5.8 (or 5.6) install file from the ActiveState download page at
http://www.activestate.com/Products/Download/Download.plex?id=ActivePe
rl.  This has a batch install file in the archive.

Hope that might provide some guidance.

Regards,

Marc Schwartz



From rossini at blindglobe.net  Sat Feb 15 20:43:03 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Sat Feb 15 20:43:03 2003
Subject: [R] Perl on Windows XP for Rcmd build
In-Reply-To: <6rvfzlz89f.fsf@bates4.stat.wisc.edu> (Douglas Bates's message
 of "15 Feb 2003 12:52:28 -0600")
References: <6rvfzlz89f.fsf@bates4.stat.wisc.edu>
Message-ID: <87r8a9nxeu.fsf@jeeves.blindglobe.net>

Douglas Bates <bates at stat.wisc.edu> writes:


> Is there a recommended binary version of perl to use under Windows XP
> for `Rcmd build'?  The R FAQ for Windows just mentions "perl".  I
> think that Kevin Wang's document on R for Windows suggests ActiveState
> perl but I have not been able to install it.  
>
> I am running Windows XP Professional on a laptop.  The operating
> system was originally Windows 98 then upgraded to Windows ME then to
> XP Pro.  I have downloaded the MSI installer version of ActiveState
> perl 5.8.0 and tried to install it.  All that happens when I execute
> the installer is that I get a command prompt window that exits a few
> moments later, apparently with no effect.  I tried this a few times,
> rebooted the computer and tried again and still no luck.  I then
> removed the 5.8.0 installer and downloaded the ActivePerl-5.6.1.635
> MSI installer instead but the same thing happened.

Hmm....  I'm actually in the IDENTICAL situation (just inherited a
laptop from a prof in another dept who insisted that I edit files in
MS Word rather than OpenOffice :-); It's an ancient IBM thinkpad,
originally Win98, now Win XP Pro (no "ME" in the middle, though).

No problems with installing ActivePerl 5.8.0 Build 805.  Did you try
the AS installer instead of the MSI?

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From ripley at stats.ox.ac.uk  Sat Feb 15 20:47:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Feb 15 20:47:03 2003
Subject: [R] Perl on Windows XP for Rcmd build
In-Reply-To: <6rvfzlz89f.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0302151944430.28234-100000@gannet.stats>

You do need Windows Perl, but I have only tested ActiveState perl.
Cygwin Perl wil not work: it does not understand the Windows paths.

We've never seen a problem with ActiveState perl on XP.

On 15 Feb 2003, Douglas Bates wrote:

> Is there a recommended binary version of perl to use under Windows XP
> for `Rcmd build'?  The R FAQ for Windows just mentions "perl".  I
> think that Kevin Wang's document on R for Windows suggests ActiveState
> perl but I have not been able to install it.  
> 
> I am running Windows XP Professional on a laptop.  The operating
> system was originally Windows 98 then upgraded to Windows ME then to
> XP Pro.  I have downloaded the MSI installer version of ActiveState
> perl 5.8.0 and tried to install it.  All that happens when I execute
> the installer is that I get a command prompt window that exits a few
> moments later, apparently with no effect.  I tried this a few times,
> rebooted the computer and tried again and still no luck.  I then
> removed the 5.8.0 installer and downloaded the ActivePerl-5.6.1.635
> MSI installer instead but the same thing happened.
> 
> Should I try Apache Perl or some other binary distribution instead?
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From stanislav_markus at yahoo.com  Sat Feb 15 21:55:03 2003
From: stanislav_markus at yahoo.com (Stan Markus)
Date: Sat Feb 15 21:55:03 2003
Subject: [R] logit regression / propensity scores  in R
Message-ID: <20030215205422.67128.qmail@web41403.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030215/5a011b06/attachment.pl

From fharrell at virginia.edu  Sat Feb 15 22:35:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sat Feb 15 22:35:03 2003
Subject: [R] logit regression / propensity scores  in R
In-Reply-To: <20030215205422.67128.qmail@web41403.mail.yahoo.com>
References: <20030215205422.67128.qmail@web41403.mail.yahoo.com>
Message-ID: <20030215163410.16d26993.fharrell@virginia.edu>

On Sat, 15 Feb 2003 12:54:22 -0800 (PST)
Stan Markus <stanislav_markus at yahoo.com> wrote:

> 
> Dear All:
> 
> what R function should be used for logit regression? glm()? And, more
> 
> importantly, is there a function that would calculate the *probability of
> 
> Y given X in the logit framework* (say for propensity score calculation)?
> 
>  
> 
> Thanks!
> 
> Stan

The "An Introduction to R" manual that comes with the system covers the glm function.

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From schnitzlerj at gmx.de  Sun Feb 16 00:20:06 2003
From: schnitzlerj at gmx.de (Johannes Schnitzler)
Date: Sun Feb 16 00:20:06 2003
Subject: [R] rownames as parameter in functions
Message-ID: <11025.1045351178@www67.gmx.net>

Dear all,

i want to give the names of columns of a data set (dat) as parameter to a
function,
in order to select single rows by the row names.

I tried several ways.
Like:
the data set :
dat
A  B C D  E
1  2  3  1  6
1  4  5  2  4
..  .. ..  ..  ..

the.col.names<-c("A","C")

f<-function(par){sapply,function(par)(dat$par*2)}

f(the.col.names)

Should give the result

A  C
2   6
2  10
..  ..


Thank you in advance


Johannes Schnitzler
schnitzlerj at gmx.de



From spencer.graves at pdf.com  Sun Feb 16 00:39:02 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun Feb 16 00:39:02 2003
Subject: [R] rownames as parameter in functions
References: <11025.1045351178@www67.gmx.net>
Message-ID: <3E4ECF33.4050901@pdf.com>

How about the following:

 > anArray <- array(1:4, dim=c(2,2))
 > dimnames(anArray) <- list(c("a", "b"), c("c", "d"))
 > anArray["a",]
c d
1 3
 >
You can then pass a vector of character strings to the function, and 
subset the rows  by "anArray[select.charvec,]".  Alternatively, 
"anArray[select.charvec,, drop=FALSE]" will ensure that the result is 
still a 2-dimensional array, not a vector [oops!!].

Does this help?
Spencer Graves

Johannes Schnitzler wrote:
> Dear all,
> 
> i want to give the names of columns of a data set (dat) as parameter to a
> function,
> in order to select single rows by the row names.
> 
> I tried several ways.
> Like:
> the data set :
> dat
> A  B C D  E
> 1  2  3  1  6
> 1  4  5  2  4
> ..  .. ..  ..  ..
> 
> the.col.names<-c("A","C")
> 
> f<-function(par){sapply,function(par)(dat$par*2)}
> 
> f(the.col.names)
> 
> Should give the result
> 
> A  C
> 2   6
> 2  10
> ..  ..
> 
> 
> Thank you in advance
> 
> 
> Johannes Schnitzler
> schnitzlerj at gmx.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From alansmith at wisc.edu  Sun Feb 16 02:06:03 2003
From: alansmith at wisc.edu (Alan Smith)
Date: Sun Feb 16 02:06:03 2003
Subject: [R] Help with tabs, and importing data
Message-ID: <5.2.0.9.2.20030215183218.00abe348@wiscmail.wisc.edu>

Hello,
I am new at using R and I am trying to import data from microarray 
experiments and analyze the data using the MAANOVA package and also 
bioconductor.  I have searched this lists email archive and could not find 
the solution to my problem so hopefully members of this group can help me.
OS=windowsXP
R 1.6.2
My Problem:
It seems that MS excel is adding little boxes at the end of each cell when 
I save the file as tab delimited.  Is there any way to let R know by sep 
command that these little boxes really mean a tab is present?  I have had 
success using comma delimited format, but it seems that one of the programs 
I am using is designed to recognize tabs.
Another question:  Is there a way to stop MS excel (XP version) from 
placing these hidden boxes after each of the cells in a row and really 
place a tab?
Could you please reply back to my email address because I am not a member 
of this list.

Thank You,

Alan Smith
Graduate Student
University of Wisconsin-Madison
Plant Breeding and Plant Genetics
alansmith at wisc.edu



From jasont at indigoindustrial.co.nz  Sun Feb 16 03:17:03 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sun Feb 16 03:17:03 2003
Subject: [R] Change array size
In-Reply-To: <200302140951.38672.poizot@cnam.fr>; from poizot@cnam.fr on Fri, Feb 14, 2003 at 09:51:38AM +0000
References: <200302140951.38672.poizot@cnam.fr>
Message-ID: <20030216151649.A1256@camille.indigoindustrial.co.nz>

On Fri, Feb 14, 2003 at 09:51:38AM +0000, Poizot Emmanuel wrote:
> Hi,
> I would like to know if there is a way to change a vector of arbitrary size
> to make it fits the nearest upper size multiple of a power of 2.

Do you want to interpolate to a new shape, or zero-pad?  If
zero-padding is what you're after, I think nextn() is what you want...

> zz <- rnorm(10)
> zz.pad <- vector(length=nextn(length(zz),factors=2))
> zz.pad[1:length(zz)] <- zz
> zz.pad
 [1]  0.2759134 -1.3738876  0.9816857 -0.4639678 -1.0549718  2.8562435
 [7] -0.6275852  0.1169049  0.2463690  0.9059579  0.0000000  0.0000000
[13]  0.0000000  0.0000000  0.0000000  0.0000000

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From fnj at cin.ufpe.br  Sun Feb 16 03:24:02 2003
From: fnj at cin.ufpe.br (Francisco do Nascimento Junior)
Date: Sun Feb 16 03:24:02 2003
Subject: [R] create buttons dynamically
Message-ID: <Pine.LNX.4.44.0302152314300.5168-100000@buique.cin.ufpe.br>

Hi,is it right?
    for (i in 1:length(imagens)) {
      buts[i] <- tkbutton(tt,
         text=paste("Figure",i),command=function()show(i))
      chk.g[i] <- tkcheckbutton(tt,text="Grafics",
         variable=grafs[i],command=function()(values[i] <- calcule(i) ))
      chk.f[i] <- tkcheckbutton(tt,text="Fotogr?fica",
         variable=fotos[i],command=function()(values[i] <- calcule(i)))
      tkgrid(chk.g[i],chk.f[i],buts[i])
    }

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Francisco J?nior,
Computer Science - UFPE-Brazil
"One life has more value that the
world whole"
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



From day at upci.pitt.edu  Sun Feb 16 04:06:03 2003
From: day at upci.pitt.edu (Day, Roger)
Date: Sun Feb 16 04:06:03 2003
Subject: [R] Rgui crash and Macro Magic
Message-ID: <73D624FECBBAF6459BB60437FF7C02FB6B9E78@nsabpmail>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030216/fe8d393b/attachment.pl

From stanislav_markus at yahoo.com  Sun Feb 16 04:34:03 2003
From: stanislav_markus at yahoo.com (Stan Markus)
Date: Sun Feb 16 04:34:03 2003
Subject: [R] ! arithmetic
In-Reply-To: <20030215163410.16d26993.fharrell@virginia.edu>
Message-ID: <20030216033337.32245.qmail@web41414.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030216/aac4811f/attachment.pl

From MSchwartz at medanalytics.com  Sun Feb 16 05:07:03 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun Feb 16 05:07:03 2003
Subject: [R] ! arithmetic
In-Reply-To: <20030216033337.32245.qmail@web41414.mail.yahoo.com>
References: <20030216033337.32245.qmail@web41414.mail.yahoo.com>
Message-ID: <3E4F0E1D.3080705@MedAnalytics.com>

Stan Markus wrote:
> Since "!" is a logical operator in R, how does one use it in its arithmetic sense, say to calculate x!/y!(N-y)! ?
> 
> Thanks!
> 
> Stan

You can use gamma(x + 1) for x! or you can use the factorial() function 
in the gregmisc package on CRAN.

See ?gamma for the former option.

HTH,

Marc Schwartz



From jeff_hamann at hamanndonald.com  Sun Feb 16 05:33:03 2003
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Sun Feb 16 05:33:03 2003
Subject: [R] __stdcall funcitons called using .C() on win32 chokes
Message-ID: <45641.128.193.4.98.1045369947.squirrel@www.hamanndonald.com>

I've developed a dll (win32) of a bunch of functions prototypes as:

/* for building on *nix */
#ifndef WIN32
#define __stdcall /*nothing*/
#endif


void __stdcall dbh_2_height(
  const unsigned long    *func_idx,
  const unsigned long    *metric,
  const unsigned long    *species,
  const double             *dbh,
  double                        *pred_height );

and have created a R interface function as,

## wrapper function for dbh_2_height /
dbh2height <- function( func, metric, sp, dbh )
{
    d <- double(length(func))

    .C("dbh_2_height",
      as.integer(func),
      as.integer(metric),
      as.integer(sp),
      as.double(dbh),
      d )[[5]]
}

I would like to keep the __stdcall in the source code and still use the
.C() in R to call the function as the library is already used for many
other projects. When I attempt to call the function (win32) I get an
application error. I've commented out the __stdcall and the library works
fine. Does anyone see a good solution around this? I would like to make
use of the library and the tcltk library to use R as a simulation
environment.

Jeff.


Jeff D. Hamann
PO Box 1421
Corvallis, Oregon USA 97339-1421
541-753-7333
www.hamanndonald.com
jeff_hamann at hamanndonald.com



From TyagiAnupam at aol.com  Sun Feb 16 06:12:04 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Sun Feb 16 06:12:04 2003
Subject: [R] RMySQL installation and loading errors
Message-ID: <175.1681b1f9.2b807767@aol.com>

Hi R users,

I have been trying to install and use RMySQL on Windows98 for 
MySQL3.23.55-max using the pulldown menu. I am getting the following errors. 
I read the doc and some archived mails about a similar problem on unix like 
systems. Still can't get it to work. Some info below that may indicated where 
the problem is:
* The directory RMySQL\libs is empty---I was not expecting this.
* There is a file "README.windows" in RMySQL directory which suggests some 
changes using  the re-import utility "reimp", available at
      
http://mefriss1.swan.ac.uk/~jfonseca/gnu-win32/software/reimp/index.html
This file is missing at this location. Instead there is a note stating that 
it is included in MinGW distribution. I installed this, but did not find this 
file. 
* Below is the info from the installation and loading the library:

> {a <- CRAN.packages()
+ install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a)}
trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 8948 bytes
opened URL
downloaded 8948 bytes

trying URL `http://cran.r-project.org/bin/windows/contrib/RMySQL.zip'
Content type `application/zip' length 322573 bytes
opened URL
downloaded 315Kb


Delete downloaded files (y/N)? y

updating HTML package descriptions
Warning message: 
DLL attempted to change FPU control word from 8001f to 9001f 
> library(RMySQL)
Loading required package: methods 
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library 
"H:/PROGRAMLOCAL/RW1062/library/RMySQL/libs/RMySQL.dll":
  LoadLibrary failure:  One of the library files needed to run this 
application cannot be found.
Error in library(RMySQL) : .First.lib failed
> 
-at

*********************************************************
Prediction is very difficult, especially about the future. 
                  -- Niels Bohr



From pzhang at hsph.harvard.edu  Sun Feb 16 06:18:04 2003
From: pzhang at hsph.harvard.edu (Peng Zhang)
Date: Sun Feb 16 06:18:04 2003
Subject: [R] multivariate sampling question again
Message-ID: <Pine.GSO.4.53.0302160010110.363@hsph.harvard.edu>

Hi

Thanks for replying my question! What really interested me is that the
package providing some complex form sampling, such as wishart,
multinomial, dirichlet. And others for example conditional beta
distribution confining the random variable in the interval (a, b). Since
these concept are widely used in the baysian, I wonder whether somebody
has already written this package. Thanks!

Best wishes,
Peng

*******************************
Peng Zhang
Department of Biostatistics
Harvard School of Public Health
655 Huntington Avenue
Boston, Massachusetts 02115
*******************************

I believe I can fly
I believe I can touch the sky



From mschwartz at medanalytics.com  Sun Feb 16 06:39:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sun Feb 16 06:39:03 2003
Subject: [R] Help with tabs, and importing data
In-Reply-To: <5.2.0.9.2.20030215183218.00abe348@wiscmail.wisc.edu>
Message-ID: <001201c2d57d$9f9b2b50$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Alan Smith
>Sent: Saturday, February 15, 2003 7:05 PM
>To: R-help at stat.math.ethz.ch
>Subject: [R] Help with tabs, and importing data
>
>
>Hello,
>I am new at using R and I am trying to import data from microarray 
>experiments and analyze the data using the MAANOVA package and also 
>bioconductor.  I have searched this lists email archive and 
>could not find 
>the solution to my problem so hopefully members of this group 
>can help me. OS=windowsXP R 1.6.2 My Problem: It seems that MS 
>excel is adding little boxes at the end of each cell when 
>I save the file as tab delimited.  Is there any way to let R 
>know by sep 
>command that these little boxes really mean a tab is present?  
>I have had 
>success using comma delimited format, but it seems that one of 
>the programs 
>I am using is designed to recognize tabs.
>Another question:  Is there a way to stop MS excel (XP version) from 
>placing these hidden boxes after each of the cells in a row and
really 
>place a tab?
>Could you please reply back to my email address because I am 
>not a member 
>of this list.
>
>Thank You,
>
>Alan Smith
>Graduate Student
>University of Wisconsin-Madison
>Plant Breeding and Plant Genetics
>alansmith at wisc.edu

Alan,

When you say little boxes, what application are you using to see them?

My guess is that you are seeing the tab characters being represented
by the boxes in some text editor.

If you display the tab delimited file in Word and use the "Show/Hide"
formatting tool bar button (the paragraph symbol "?"), you will see
little right pointing arrows where the tab characters are.  This is
normal.

To import the tab delimited file into R, use read.delim(), which uses
the tab character ("\t") as the default field separator.  See
?read.delim for more information.

Hope that helps,

Marc Schwartz



From j+rhelp at howard.fm  Sun Feb 16 07:34:03 2003
From: j+rhelp at howard.fm (j+rhelp@howard.fm)
Date: Sun Feb 16 07:34:03 2003
Subject: [R] [SUMMARY] Converting coef(lm) to SQL/VBA/etc
Message-ID: <20030216063321.A1153487DF@server2.fastmail.fm>

Many thanks to all who helped with my question last week about how to
take the output of lm() and turn it into code that can be run on systems
without R (using SQL, C, etc). This is a summary of the answers, caveats,
and a solution including a little Perl script I wrote to do this.

Brian Ripley pointed out an important caveat to this whole process - the
model.matrix could contain R functions that simply don't exist in other
environments. Therefore, any solution will need to be somewhat special
purpose - avoiding functions that are not implemented in the target
language (or porting them to that language).

My simplistic solution is to ensure that all required transformations
from the raw data to the model.matrix is done in the original data source
- which, in most cases, will probably be an SQL data base. So in my case
I added a bunch of extra fields to the query I used as my data source,
containing any required transformations (with the exception of recoding
factors into dummy variables, which I'll get too shortly).

Frank Harrel pointed out that his Design library has a function called,
err..., "Function", which does pretty much what I was after. To use this,
grab the library from:
  http://hesweb1.med.virginia.edu/biostat/s/library/r/
...and instead of running lm(), run the library's ols() . Then
'Function(ols(y~x))' gives you an expression representing your model. It
should be reasonably simply to convert that expression into your target
language.

Unfortunately, it turns out that ols() can't handle nested designs
('%in%', '/', ':'), so this solution didn't work for me.

John Fox provided an (unreleased) addition to his 'car' library which
enhances the contr functions to delimit the levels from the factor names
and encode the contrast type in the contrast names. A coefficient then
will have a name like:
  a:b[T.c]:d
(an interaction between continuous variables a and d, and level c of
factor b, which is of contrast type 'T' (Treatment)). For now you will
need to look up these updated functions in the list archive - I'm sure
they'll appear in a new 'car' release shortly.

I used these functions as the basis for my converter. Here's the
details...

First, specify to use John Fox's new contr.Treatment function (note the
case!):
  options(contrasts=c("contr.Treatment", "contr.poly"))

Now run your lm() as usual
  mod <- lm( . ~ . )
...and save the coefficients
  write.table(mod$coeff, file="mod.csv", sep=",")

Now, I needed two target languages for my model, which were SQL (using a
CASE statement) and VBA. These two targets meant I could utilise my model
in any ANSI-92 compliant DB (since CASE is ANSI-92), and also in the MS
Access DB (since the Jet database engine can utilise any VBA function
from within SQL). The attached script can convert from the csv file saved
above into either of these two formats. To use it:
 - Download Perl if you don't already have it
 - Install Text::CSV_XS
   . Windows: ppm; install Text-CSV_XS; q
   . Unix: perl -MCPAN -e shell; install Text::CSV_XS; q
 - Run `perl lm2code.pl mod vba`
   or `perl lm2code.pl mod sql`
   (where 'mod' is the filename without extension
   from write.table)

To convert to some target language other than VBA or SQL, simply open
lm2code.pl (attached) and add your own entry to the %output hash at the
top of the script. Use the VBA and SQL examples already there to guide
you.

Of course, it's a bit silly using Perl for this last stage, when doing it
in R would make it much simpler. Maybe that's a useful update for a
future version, unless something better comes along first...

Note that the script only handles Treatment contrasts, and lm models.

Hope this helps someone,
  Jeremy
-- 
  Jeremy Howard
  jhoward at fastmail.fm
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lm2code.pl
Type: application/x-perl
Size: 3663 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030216/92ec2393/lm2code.bin

From daver969 at yahoo.com  Sun Feb 16 07:58:03 2003
From: daver969 at yahoo.com (David Richmond)
Date: Sun Feb 16 07:58:03 2003
Subject: [R] ! arithmetic
In-Reply-To: <20030216033337.32245.qmail@web41414.mail.yahoo.com>
Message-ID: <EF228A69-417B-11D7-9F4E-000393DBCEC2@yahoo.com>

you can create your own function:

 > fact <- function(n) prod(1:n)
 > fact(3)
[1] 6
 > fact(10)
[1] 3628800
 > fact(c(3,4))
[1] 6
Warning message:
Numerical expression has 2 elements: only the first used in: 1:n

fact() will work for scalars but doesn't do well with vectors.


Dave Richmond


On Saturday, February 15, 2003, at 07:33  PM, Stan Markus wrote:

>
> Since "!" is a logical operator in R, how does one use it in its 
> arithmetic sense, say to calculate x!/y!(N-y)! ?
>
> Thanks!
>
> Stan



From ripley at stats.ox.ac.uk  Sun Feb 16 09:18:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Feb 16 09:18:03 2003
Subject: [R] __stdcall funcitons called using .C() on win32 chokes
In-Reply-To: <45641.128.193.4.98.1045369947.squirrel@www.hamanndonald.com>
Message-ID: <Pine.LNX.4.44.0302160813380.6129-100000@gannet.stats>

Just add a glue routine to provide a _cdecl interface.

Note, it is a .C interface and not a .Pascal interface.  You could write a 
.Pascal, of course.

On Sat, 15 Feb 2003, Jeff D. Hamann wrote:

> I've developed a dll (win32) of a bunch of functions prototypes as:
> 
> /* for building on *nix */
> #ifndef WIN32
> #define __stdcall /*nothing*/
> #endif
> 
> 
> void __stdcall dbh_2_height(
>   const unsigned long    *func_idx,
>   const unsigned long    *metric,
>   const unsigned long    *species,
>   const double             *dbh,
>   double                        *pred_height );
> 
> and have created a R interface function as,
> 
> ## wrapper function for dbh_2_height /
> dbh2height <- function( func, metric, sp, dbh )
> {
>     d <- double(length(func))
> 
>     .C("dbh_2_height",
>       as.integer(func),
>       as.integer(metric),
>       as.integer(sp),
>       as.double(dbh),
>       d )[[5]]
> }
> 
> I would like to keep the __stdcall in the source code and still use the
> .C() in R to call the function as the library is already used for many
> other projects. When I attempt to call the function (win32) I get an
> application error. I've commented out the __stdcall and the library works
> fine. Does anyone see a good solution around this? I would like to make
> use of the library and the tcltk library to use R as a simulation
> environment.
> 
> Jeff.
> 
> 
> Jeff D. Hamann
> PO Box 1421
> Corvallis, Oregon USA 97339-1421
> 541-753-7333
> www.hamanndonald.com
> jeff_hamann at hamanndonald.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Feb 16 09:30:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Feb 16 09:30:03 2003
Subject: [R] RMySQL installation and loading errors
In-Reply-To: <175.1681b1f9.2b807767@aol.com>
Message-ID: <Pine.LNX.4.44.0302160824230.6176-100000@gannet.stats>

The message does not say that RMySQL is empty, indeed finds a DLL there,
so please check your facts and the R-help archives for *yesterday*.
I suspect all you need to do is to put .../library/RMySQL/lib in your 
path.

On Sun, 16 Feb 2003 TyagiAnupam at aol.com wrote:

> Hi R users,
> 
> I have been trying to install and use RMySQL on Windows98 for 
> MySQL3.23.55-max using the pulldown menu. I am getting the following errors. 
> I read the doc and some archived mails about a similar problem on unix like 
> systems. Still can't get it to work. Some info below that may indicated where 
> the problem is:
> * The directory RMySQL\libs is empty---I was not expecting this.
> * There is a file "README.windows" in RMySQL directory which suggests some 
> changes using  the re-import utility "reimp", available at
>       
> http://mefriss1.swan.ac.uk/~jfonseca/gnu-win32/software/reimp/index.html
> This file is missing at this location. Instead there is a note stating that 
> it is included in MinGW distribution. I installed this, but did not find this 
> file. 
> * Below is the info from the installation and loading the library:
> 
> > {a <- CRAN.packages()
> + install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a)}
> trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 8948 bytes
> opened URL
> downloaded 8948 bytes
> 
> trying URL `http://cran.r-project.org/bin/windows/contrib/RMySQL.zip'
> Content type `application/zip' length 322573 bytes
> opened URL
> downloaded 315Kb
> 
> 
> Delete downloaded files (y/N)? y
> 
> updating HTML package descriptions
> Warning message: 
> DLL attempted to change FPU control word from 8001f to 9001f 
> > library(RMySQL)
> Loading required package: methods 
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
>         unable to load shared library 
> "H:/PROGRAMLOCAL/RW1062/library/RMySQL/libs/RMySQL.dll":
>   LoadLibrary failure:  One of the library files needed to run this 
> application cannot be found.
> Error in library(RMySQL) : .First.lib failed
> > 
> -at
> 
> *********************************************************
> Prediction is very difficult, especially about the future. 
>                   -- Niels Bohr
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From TyagiAnupam at aol.com  Sun Feb 16 11:06:03 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Sun Feb 16 11:06:03 2003
Subject: [R] RMySQL installation and loading errors
Message-ID: <23.2bf5bd2c.2b80bc50@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030216/7562fb85/attachment.pl

From TyagiAnupam at aol.com  Sun Feb 16 12:56:03 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Sun Feb 16 12:56:03 2003
Subject: [R] RMySQL installation and loading errors
Message-ID: <a6.34170a73.2b80d60f@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030216/2d6fd189/attachment.pl

From jazevedo at provide.com.br  Sun Feb 16 13:40:03 2003
From: jazevedo at provide.com.br (Joao Pedro W. de Azevedo)
Date: Sun Feb 16 13:40:03 2003
Subject: [R] download CRAN packages and proxy config.
Message-ID: <KLEBLDAPNFNMNOIHCMBLEENJDBAA.jazevedo@provide.com.br>

Dear R users,

I'm starting to get acquainted with R. I've been reading the manual, and I
understood that if I wanted to install a user written package on R, I could
do it directly from the Internet, by typing the line
install.packages("quantreg") in an R session.

To my surprise this command did not work, nor did the command "update
packages from CRAN..." from the menu option. In the latter I got the
following error message:

<- CRAN.packages()
+ install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a)}
trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
unable to connect to 'cran.r-project.org'.
Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  :
        cannot open URL
`http://cran.r-project.org/bin/windows/contrib/PACKAGES'
>

The strange thing was that I was able to visit the internet address the R
was trying to connect, from my web browser. Thus I imagine that the problem
was a proxy issue on R.

I would sincerely appreciate if one of the more experience R user could help
me to sort this issue out. I found a way to configure my proxy setting by
typing on the main window '"http://wwwcache.ncl.ac.uk:8080/"', however it
didn't seem to have worked, as I kept getting the same error message when I
tried to connect the CRAN.

Any help would be extremely appreciated,

Joao Pedro/



From ligges at statistik.uni-dortmund.de  Sun Feb 16 13:48:02 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Feb 16 13:48:02 2003
Subject: [R] RMySQL installation and loading errors
References: <a6.34170a73.2b80d60f@aol.com>
Message-ID: <3E4F8892.10EF0AF0@statistik.uni-dortmund.de>


TyagiAnupam at aol.com wrote:
> 
> In a message dated 2/16/03 6:24:53 AM Eastern Standard Time,
> ligges at statistik.uni-dortmund.de writes:
> 
> > TyagiAnupam at aol.com wrote:
> > >
> > > Thanks. The file is indeed there. By default Windows Explorer makes the
> > *.dll
> > > files invisible. The file seem to be in a branch of the default library.
> > I am
> > > missing something here.
> > > > .libPaths()
> > > [1] "H:/PROGRAMLOCAL/RW1062/library"
> > > > library(RMySQL)
> > >  Loading required package: methods
> > >  Error in dyn.load(x, as.logical(local), as.logical(now)) :
> > >          unable to load shared library
> > >  "H:/PROGRAMLOCAL/RW1062/library/RMySQL/libs/RMySQL.dll":
> > >    LoadLibrary failure:  One of the library files needed to run this
> > >  application cannot be found.
> > >  Error in library(RMySQL) : .First.lib failed
> >
> >
> > You missed to read README.windows in the packages' directory and Brian
> > Ripley's mail carefully (citing the latter):
> > "I suspect all you need to do is to put .../library/RMySQL/lib in your
> > path",
> > where path means the *environment variable* of your OS called PATH.
> >
> > If you don't know how to set environment variables, please contact the
> > IT stuff of your department or the OS manuals / support.
> >
> > Uwe Ligges
> >
> 
> Thanks. Just did it in Autoexec.bat file. It seems to be working well. While
> loading the library there is still a warning. Is this something to worry
> about?
> 
> > {pkg <- select.list(sort(.packages(all.available = TRUE)))
> + if(nchar(pkg)) library(pkg, character.only=TRUE)}
> Loading required package: methods
> Warning message:
> DLL attempted to change FPU control word from 8001f to 9001f


From ligges at statistik.uni-dortmund.de  Sun Feb 16 13:54:02 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Feb 16 13:54:02 2003
Subject: [R] download CRAN packages and proxy config.
References: <KLEBLDAPNFNMNOIHCMBLEENJDBAA.jazevedo@provide.com.br>
Message-ID: <3E4F89C5.964525FA@statistik.uni-dortmund.de>

"Joao Pedro W. de Azevedo" wrote:
> 
> Dear R users,
> 
> I'm starting to get acquainted with R. I've been reading the manual, and I
> understood that if I wanted to install a user written package on R, I could
> do it directly from the Internet, by typing the line
> install.packages("quantreg") in an R session.
> 
> To my surprise this command did not work, nor did the command "update
> packages from CRAN..." from the menu option. In the latter I got the
> following error message:
> 
> <- CRAN.packages()
> + install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a)}
> trying URL `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
> unable to connect to 'cran.r-project.org'.
> Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  :
>         cannot open URL
> `http://cran.r-project.org/bin/windows/contrib/PACKAGES'
> >
> 
> The strange thing was that I was able to visit the internet address the R
> was trying to connect, from my web browser. Thus I imagine that the problem
> was a proxy issue on R.
> 
> I would sincerely appreciate if one of the more experience R user could help
> me to sort this issue out. I found a way to configure my proxy setting by
> typing on the main window '"http://wwwcache.ncl.ac.uk:8080/"', however it
> didn't seem to have worked, as I kept getting the same error message when I
> tried to connect the CRAN.
> 
> Any help would be extremely appreciated,
> 
> Joao Pedro/

Please read Section 2.16 "The internet download functions fail." of the
R for Windows FAQ.

Uwe Ligges



From ralf.herold at charite.de  Sun Feb 16 17:51:03 2003
From: ralf.herold at charite.de (R. Herold)
Date: Sun Feb 16 17:51:03 2003
Subject: [R] ESRI shape file import and time-space models
Message-ID: <000001c2d5db$5b7bf680$22011aac@knmnote>

Thanks for providing your functions, especially those for 
reading and writing dBase files (read.dbf and write.dbf), 
which presumably are of general interest because there is 
no other implementation for reading and writing these 
formats (apart from ODBC), as far as I know. 

However, I suggest changing one byte character readBin to 
readChar as the latter does not expect zero-terminated
strings which were not present in my dBase-III-files' headers.
One such header entry for example was (hex): 

4B 4C 49 4e 00 00 00 00 00 00 00 43 2B 00 00 00
02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 

(field "KLIN", type "C" [note "43" followed by "2B", 
 not "00"], width/length 2, padded to size 32)

## ---------------------------------------------------
## From read.dbf: 
## Field Descriptions (32 bytes each)
for (i in 1:num.fields) {
  field.name.test <- readBin (infile, character(), 1, size=10,
endian="little")
  field.name      <- c (field.name, field.name.test)
  if (nchar (field.name.test)!=10) {
    file.temp <- readBin (infile,integer(), 10 - (nchar
(field.name.test)), 1, endian="little")
  }
  ## RH 2003-02-16: replaced readBin by readChar in next line 
  field.type   <- c (field.type, readChar (infile, 1))  
  ## RH 2003-02-16: incremented by 1 to 4 items in next line 
  ## to compensate for above change 
  file.temp    <- readBin (infile, integer(),  4, 1, endian="little")  
  field.length <- c (field.length, readBin (infile, integer(), 1, 1,
endian="little")) 
  file.temp    <- readBin (infile, integer(), 15, 1, endian="little")
}
## ---------------------------------------------------

An enhancement might be to also set the appropriate type for 
date fields, maybe like this (although I don't know internals
of dBase date and time storage variants): 

## ---------------------------------------------------
## From read.dbf: 
## Set the numeric fields to numeric
for (i in 1:ncol(dbf)) {
  ## RH 2003-02-16: added next line for date type setting 
  if(fields$TYPE[i]=="D") {dbf[,i] <- strptime (as.character (dbf[,i]),
format="%Y%m%d")}
  if(fields$TYPE[i]=="C") {dbf[,i] <- as.character (dbf[,i])}
  if(fields$TYPE[i]=="N") {dbf[,i] <- as.numeric (as.character
(dbf[,i]))}
  if(fields$TYPE[i]=="F") {dbf[,i] <- as.numeric (as.character
(dbf[,i]))
                           warning("Possible trouble converting numeric
field in the DBF\n") 
                          } 
} 
## ---------------------------------------------------

Thanks and greetings - Ralf Herold 

-- Dr. med. Ralf Herold  
| Koordinationszentrale Kompetenznetz
| P?diatrische Onkologie und H?matologie  
| http://www.kinderkrebsinfo.de/   
| Charit? Campus Virchow-Klinikum  
| Medizinische Fakult?t Humboldt-Universit?t  
| D-13353 Berlin, Augustenburger Platz 1  
| Raum 4.3425 4. Etage Mittelallee 8  
| Tel. +49 (30) 450-566834 Fax -566906  
| mailto:ralf.herold at charite.de  

> ----- Original Message ----- 
> From: Benjamin.STABLER at odot.state.or.us
> To: Ekkehardt.Altpeter at bag.admin.ch
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] ESRI shape file import and time-space models
> Date: Fri, 14 Feb 2003 08:29:12 -0800
[...]
> Attached are some functions that I wrote to read and write 
> shapefiles and
> dbfs easily from within R.  You do not need any additional 
> libraries or C
> code.  I am still working out a few bugs but I have tested it 
[...]
> Benjamin Stabler
> Transportation Planning Analysis Unit
> Oregon Department of Transportation
> 555 13th Street NE, Suite 2
> Salem, OR 97301  Ph: 503-986-4104
[...]



From rob.hyndman at buseco.monash.edu.au  Sun Feb 16 22:53:03 2003
From: rob.hyndman at buseco.monash.edu.au (Rob Hyndman)
Date: Sun Feb 16 22:53:03 2003
Subject: [R] Re: ROC
Message-ID: <3E5007C4.6CE2D60F@buseco.monash.edu.au>

In addition to the Bioconductor package, I have a few routines for
estimation of ROC curves (including kernel estimates) on my web page at

http://www-personal.buseco.monash.edu.au/~hyndman/Rlibrary/ROC.htm

Best wishes,
Rob
___________________________________________________
Rob J Hyndman
Associate Professor & Director of Consulting
Department of Econometrics & Business Statistics
Monash University, VIC 3800, Australia.
http://www-personal.buseco.monash.edu.au/~hyndman/



From maj at stats.waikato.ac.nz  Mon Feb 17 04:29:02 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Mon Feb 17 04:29:02 2003
Subject: [R] lda on curves
Message-ID: <3E5056E2.3030006@stats.waikato.ac.nz>

I'm working on a rather interesting consulting problem with a client. A 
number of physical variables are measured on a number of cricket bowlers 
in the performance of a delivery. An example variable might be a 
directional component of angular momentum for a particular joint 
measured at a large number (101) of equally spaced timepoints.

Each bowler generates a (fairly smooth) curve for each variable 
measured. I decided to represent each curve by a few orthogonal 
polynomial constrasts.

There are 4 groups of bowlers corresponding to various speeds of 
delivery. I want to use canonical variant analysis to find linear 
combinations of my transformed variables discriminating well between the 
groups of bowlers.

I used lda() from the MASS library to do this, but examining the output 
I notice that the higher-order orthogonal polynomials are getting larger 
coefficients than the more important lower-order ones. This is clearly 
because some scaling of the variables is being done by lda(), and 
because the higher-order polynomial vaiable values are smaller, they are 
scaled up.

I would like to turn off this scaling as it is not what is needed in 
this problem and will cause the tail to "wag the dog". There is no 
obvious parameter to do this in

lda(x,   grouping, prior = proportions, tol = 1.0e-4,
                    subset, na.action = na.fail,
                    method, CV = FALSE, nu)

so I thought that I might try a hack. However:

 > lda
function (x, ...)
{
     if (is.null(class(x)))
         class(x) <- data.class(x)
     UseMethod("lda", x, ...)
}

which isn't very helpful.

Any ideas about how to perform an unscaled canonical variates analysis?

Cheers,

Murray
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From emami at knmi.nl  Mon Feb 17 09:58:02 2003
From: emami at knmi.nl (Nader Emami)
Date: Mon Feb 17 09:58:02 2003
Subject: [R] installation of RODBC
Message-ID: <3E50A400.7070408@knmi.nl>

I have tried to install the RODBC package with the next command:

 > install.packages(("ORDBC"), (lib="usr/lib/R/library"))

But it is failed. Can I get some information about the installation of 
this package anywhere?

Best regards,

Nader
--------------------------------------------------------------
Zie ook/see also: http://www.knmi.nl/maildisclaimer.html



From jasont at indigoindustrial.co.nz  Mon Feb 17 10:16:04 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon Feb 17 10:16:04 2003
Subject: [R] installation of RODBC
In-Reply-To: <3E50A400.7070408@knmi.nl>; from emami@knmi.nl on Mon, Feb 17, 2003 at 09:57:36AM +0100
References: <3E50A400.7070408@knmi.nl>
Message-ID: <20030217221548.A3028@camille.indigoindustrial.co.nz>

On Mon, Feb 17, 2003 at 09:57:36AM +0100, Nader Emami wrote:
> I have tried to install the RODBC package with the next command:
> 
>  > install.packages(("ORDBC"), (lib="usr/lib/R/library"))

"RODBC", I presume?  If that's a cut-and-paste, there's one error...


> But it is failed. Can I get some information about the installation of 
> this package anywhere?

What was the error message?

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From TyagiAnupam at aol.com  Mon Feb 17 10:23:03 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Mon Feb 17 10:23:03 2003
Subject: [R] installation of RODBC
Message-ID: <1df.229fbba.2b8203bc@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030217/515b268a/attachment.pl

From ligges at statistik.uni-dortmund.de  Mon Feb 17 10:28:09 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Feb 17 10:28:09 2003
Subject: [R] installation of RODBC
In-Reply-To: <3E50A400.7070408@knmi.nl>
References: <3E50A400.7070408@knmi.nl>
Message-ID: <3E50AA74.7010203@statistik.uni-dortmund.de>

Nader Emami wrote:
> I have tried to install the RODBC package with the next command:
> 
>  > install.packages(("ORDBC"), (lib="usr/lib/R/library"))

The correct spelling, RODBC, might help.

BTW: install.packages("RODBC") should be sufficient and all your inner 
parantheses are superfluously at all.

Uwe Ligges


> But it is failed. Can I get some information about the installation of 
> this package anywhere?
 >
 > Best regards,
 >
 > Nader



From ligges at statistik.uni-dortmund.de  Mon Feb 17 10:34:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Feb 17 10:34:03 2003
Subject: [R] installation of RODBC
In-Reply-To: <3E50AA74.7010203@statistik.uni-dortmund.de>
References: <3E50A400.7070408@knmi.nl> <3E50AA74.7010203@statistik.uni-dortmund.de>
Message-ID: <3E50AB76.2040507@statistik.uni-dortmund.de>

Uwe Ligges wrote:
> Nader Emami wrote:
> 
>> I have tried to install the RODBC package with the next command:
>>
>>  > install.packages(("ORDBC"), (lib="usr/lib/R/library"))
> 
> 
> The correct spelling, RODBC, might help.

Arrgh, I overlooked another point:

Of course, lib="usr/lib/R/library" should be lib="/usr/lib/R/library", 
since you surely want it to be treated as an absolute pathname...

Uwe Ligges



> BTW: install.packages("RODBC") should be sufficient and all your inner 
> parantheses are superfluously at all.
> 
> Uwe Ligges
> 
> 
>> But it is failed. Can I get some information about the installation of 
>> this package anywhere?
> 
>  >
>  > Best regards,
>  >
>  > Nader
>



From mhv at dmu.dk  Mon Feb 17 11:16:03 2003
From: mhv at dmu.dk (mhv@dmu.dk)
Date: Mon Feb 17 11:16:03 2003
Subject: [R] Q: libreadline.so.4.1 problems on Alpha/Linux
Message-ID: <0D86E7094B70754C900E4160015800360100DF5E@dmurexch.dmu.dk>

Dear List

I'm trying to run R on a DIGITAL Alpha / Linux RedHat 7.2

The .rpm requires libreadlin.so.4.1
RedHat 7.2 comes with libreadline.so.4.2

I installed the R-1.6.0-1.aplha.rpm with option --nodeps, since it otherwise
complained that the required libreadline.so.4.1 was missing.
This seemed to be the only unsatisfied dependency, at least that was the
only one mentioned when installing without the --nodeps option.

I then made a link /usr/lib/libreadline.so.4.1 to point to
/usr/lib/libreadline.so.4.2 

So far so good --- I thought...

I can start R and gets the prompt, but when I writes licence(), help(),
demo() or any other of the sugested commands I get an error: "Segmentation
fault" and the progam exits to the shell prompt.

Any sugestions are welcomed...

----------------------------------------------------------------------------
-----------------------------
Martin Hvidberg
Geographer, M.Sc.


National Environmental Research Institute	Phone(direct):	+45 46 30 11
55
Dept. of Atmospheric Environment		Phone:		+45 46 30 12
00
Frederiksborgvej 399			Fax:		+45 46 30 12 14
Box 358					E-mail:		mhv at dmu.dk
DK-4000 Roskilde				Location:
55?41'43.1"N 12?06'06.6"E
Denmark



From vito.muggeo at giustizia.it  Mon Feb 17 11:59:02 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Mon Feb 17 11:59:02 2003
Subject: [R] LRT in arima models
Message-ID: <007a01c2d672$c3c6d9c0$5c13070a@it.giustizia.it>

Dear all,

For some reason I'm evaluating the size of the LRT testing for the effect of
some explanatory variable in arima models.
I performed three different simulations
y<-2+arima.sim(n, model=list(ar=ar.p,ma=0),sd=1)
with different ar parameter, namely 0.7, 0.5, and 0.2. n=100.

Out of 1000 replications performed for each ar, the H_0 (no effect of
x<-1:n) was rejected 77, 67 and 53 times with ar=0.7, 0.5 and 0.2
respectively. (sigma was assumed known in calculating the statistic test and
the nominal significance level is 0.05)

That is, the LRT seems to become somewhat anti-conservative when the ar
parameter increases.
I am aware the 1000 replictions are few to assess the size, but the "trend"
in the sizes seems noticeable.  Am I wrong?
Am I missing some theoretical issues or could it depend on any computational
apect related to the the arima() function?

Any comment is coming?
Many thanks
best,
vito



From alobo at ija.csic.es  Mon Feb 17 13:51:02 2003
From: alobo at ija.csic.es (Agustin Lobo)
Date: Mon Feb 17 13:51:02 2003
Subject: [R] inserting elements in a list
Message-ID: <Pine.OSF.3.91.1030217133410.1061D-100000@paleo>

I've searched the doc for insert
and could not find the way to do the following,
hope someone can help:

Let's say we have a vector:
> a
[1] "1" "2" "3" "5" "6" "3"

and we want to insert a "7" after
any given "3", i.e., we want vector a 
to become:

[1] "1" "2" "3" "7" "5" "6" "3" "7"

That is, how can we replce one
element by more than one elements?
(...causing the vector to go beyond its
length)

Thanks

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es



From hennig at stat.math.ethz.ch  Mon Feb 17 13:59:54 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Mon Feb 17 13:59:54 2003
Subject: [R] lda on curves
In-Reply-To: <31325.1045485121@www42.gmx.net>
Message-ID: <Pine.LNX.4.44.0302171345310.8249-100000@florence>

Hi,

I recently work about linear dimension reduction for classification.
There is a research report on
ftp://ftp.stat.math.ethz.ch/Research-Reports/108.html
In this report I discuss nine methods for linear dimension reduction, five
of which are new. Four of the methods do not perform "internal scaling" which
you want to avoid. Two of these have been published before by other
authors. The coordinates are
Young, Marco and Odell, Journal of Statistical Planning and Inference, 17
(1987), 307-319
and
Hastie and Tibshirani, IEEE Transactions on Pattern Analysis and Machine
Intelligence, 18 (1996), 607-616.
I have R functions for all the methods, but I don't want to make them open
before the corresponding paper is published. If you are interested, please
contact me off list.
There is more literature about "unscaled canonical variates" especially by
W. Krzanowski, two references are
Krzanowski, Journal of Chemometrics, 9 (1995), 509-520
Kiers and Krzanowski in Gaul, Opitz and Schader (Eds.) Data Analysis,
Springer, Berlin 2000, 207-218.

Best,
Christian

On Mon, 17 Feb 2003, Murray Jorgensen wrote:

> I'm working on a rather interesting consulting problem with a client. A 
> number of physical variables are measured on a number of cricket bowlers 
> in the performance of a delivery. An example variable might be a 
> directional component of angular momentum for a particular joint 
> measured at a large number (101) of equally spaced timepoints.
> 
> Each bowler generates a (fairly smooth) curve for each variable 
> measured. I decided to represent each curve by a few orthogonal 
> polynomial constrasts.
> 
> There are 4 groups of bowlers corresponding to various speeds of 
> delivery. I want to use canonical variant analysis to find linear 
> combinations of my transformed variables discriminating well between the 
> groups of bowlers.
> 
> I used lda() from the MASS library to do this, but examining the output 
> I notice that the higher-order orthogonal polynomials are getting larger 
> coefficients than the more important lower-order ones. This is clearly 
> because some scaling of the variables is being done by lda(), and 
> because the higher-order polynomial vaiable values are smaller, they are 
> scaled up.
> 
> I would like to turn off this scaling as it is not what is needed in 
> this problem and will cause the tail to "wag the dog". There is no 
> obvious parameter to do this in
> 
> lda(x,   grouping, prior = proportions, tol = 1.0e-4,
>                     subset, na.action = na.fail,
>                     method, CV = FALSE, nu)
> 
> so I thought that I might try a hack. However:
> 
>  > lda
> function (x, ...)
> {
>      if (is.null(class(x)))
>          class(x) <- data.class(x)
>      UseMethod("lda", x, ...)
> }
> 
> which isn't very helpful.
> 
> Any ideas about how to perform an unscaled canonical variates analysis?
> 
> Cheers,
> 
> Murray
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de



From Isabelle.ZABALZA-MEZGHANI at ifp.fr  Mon Feb 17 14:05:06 2003
From: Isabelle.ZABALZA-MEZGHANI at ifp.fr (ZABALZA-MEZGHANI Isabelle)
Date: Mon Feb 17 14:05:06 2003
Subject: [R] Call to glm inside a function
Message-ID: <488C02265C6AD611BF200002A542182F022B32F7@irnts22.ifp.fr>

Hello,

I want to call glm inside a function. In the first lines of code I build the
weights, the formula, ... and then I call glm with the following command:
    glm(formularesp, data=data, family=familyresp,
weights=eval(data$weights)

My problem is that the fitting proccess is performed just like if
weights=NULL, even if my weights are not equals to 1. I've performed some
return() command before this glm call to check the value of each argument,
and everything seems OK.

Please, help me to understand why the code bypass my weighting instruction.

Regards

Isabelle



From adrian.trapletti at lmttrading.com  Mon Feb 17 14:17:03 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Mon Feb 17 14:17:03 2003
Subject: [R] Re: R-help digest, Vol 1 #80 - 14 msgs
References: <20030217110012.3189.9331.Mailman@hypatia.math.ethz.ch>
Message-ID: <3E50E094.E7D3AB8@lmttrading.com>

> Subject: [R] LRT in arima models
> Date: Mon, 17 Feb 2003 11:53:04 +0100
> From: "vito muggeo" <vito.muggeo at giustizia.it>
> To: <r-help at stat.math.ethz.ch>
>
> Dear all,
>
> For some reason I'm evaluating the size of the LRT testing for the effect of
> some explanatory variable in arima models.
> I performed three different simulations
> y<-2+arima.sim(n, model=list(ar=ar.p,ma=0),sd=1)
> with different ar parameter, namely 0.7, 0.5, and 0.2. n=100.
>
> Out of 1000 replications performed for each ar, the H_0 (no effect of
> x<-1:n) was rejected 77, 67 and 53 times with ar=0.7, 0.5 and 0.2
> respectively. (sigma was assumed known in calculating the statistic test and
> the nominal significance level is 0.05)
>
> That is, the LRT seems to become somewhat anti-conservative when the ar
> parameter increases.
> I am aware the 1000 replictions are few to assess the size, but the "trend"
> in the sizes seems noticeable.  Am I wrong?
> Am I missing some theoretical issues or could it depend on any computational
> apect related to the the arima() function?
>
> Any comment is coming?
> Many thanks
> best,
> vito

Just a general comment:

I am more surprised that the test is still doing that well: An AR coefficient of 0.7
introduces quite a bit of dependence in your DGP. Hence the number of "independent
observations" is considerably smaller than 100. Therefore asymptotic theory might be a
bad approximation and small sample effects might lead to severe size distortions.

Maybe someone can explain more formally whats going on here?

best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com



From mkondrin at hppi.troitsk.ru  Mon Feb 17 14:21:25 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Mon Feb 17 14:21:25 2003
Subject: [R] grid: clipping points to viewport?
Message-ID: <3E510895.1030207@hppi.troitsk.ru>

Why command 
grid.points(c(0,1,1.1),c(0,1,1.1),vp=viewport(w=0.5,h=0.5,x=0.5,y=0.5,clip=TRUE)) 
does not clip points (point (1.1,1.1) is still visible), although there 
is no problem with grid.lines(...)?
And one more question - how can I swap direction of tick marks on 
grid.x(y)axis to turn it inside plot?



From mkondrin at hppi.troitsk.ru  Mon Feb 17 14:35:03 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Mon Feb 17 14:35:03 2003
Subject: [R] grid: clipping points to viewport?
Message-ID: <3E511000.60806@hppi.troitsk.ru>

Why command
grid.points(c(0,1,1.1),c(0,1,1.1),vp=viewport(w=0.5,h=0.5,x=0.5,y=0.5,clip=TRUE)) 

does not clip points (point (1.1,1.1) is still visible), although there
is no problem with grid.lines(...)?
And one more question - how can I swap direction of tick marks on
grid.x(y)axis to turn it inside plot?



From upton9265 at yahoo.com  Mon Feb 17 14:49:02 2003
From: upton9265 at yahoo.com (Stephen Upton)
Date: Mon Feb 17 14:49:02 2003
Subject: [R] inserting elements in a list
Message-ID: <20030217134816.29608.qmail@web13705.mail.yahoo.com>

Agustin,

Not sure this is the most effective means, but works:
> a
[1] 1 2 3 5 6 3
> lapply(as.list(a), function(x) if(x==3) x<-c(3,7)
else x) -> aa
> aa
[[1]]
[1] 1

[[2]]
[1] 2

[[3]]
[1] 3 7

[[4]]
[1] 5

[[5]]
[1] 6

[[6]]
[1] 3 7

> unlist(aa)
[1] 1 2 3 7 5 6 3 7
>
Basically, convert vector to a list, modify that
element of the
list
matching your condition, then unlist the resulting
list.

HTH
steve


Agustin Lobo wrote:

> I've searched the doc for insert
> and could not find the way to do the following,
> hope someone can help:
>
> Let's say we have a vector:
> > a
> [1] "1" "2" "3" "5" "6" "3"
>
> and we want to insert a "7" after
> any given "3", i.e., we want vector a
> to become:
>
> [1] "1" "2" "3" "7" "5" "6" "3" "7"
>
> That is, how can we replce one
> element by more than one elements?
> (...causing the vector to go beyond its
> length)
>
> Thanks
>
> Agus
>
> Dr. Agustin Lobo
> Instituto de Ciencias de la Tierra (CSIC)
> Lluis Sole Sabaris s/n
> 08028 Barcelona SPAIN
> tel 34 93409 5410
> fax 34 93411 0012
> alobo at ija.csic.es
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ben at zoo.ufl.edu  Mon Feb 17 15:53:03 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Mon Feb 17 15:53:03 2003
Subject: [R] multivariate sampling question again
In-Reply-To: <Pine.GSO.4.53.0302160010110.363@hsph.harvard.edu>
Message-ID: <Pine.LNX.4.44.0302170958460.11873-100000@bolker.zoo.ufl.edu>

  I have a few of these implemented (Wishart, multinomial, dirichlet),
mostly from hints provided on the R list; I may try to clean them up for
presentation, but you can write directly to me for fairly raw code if
you're interested.

  Ben Bolker

On Sun, 16 Feb 2003, Peng Zhang wrote:

> Hi
> 
> Thanks for replying my question! What really interested me is that the
> package providing some complex form sampling, such as wishart,
> multinomial, dirichlet. And others for example conditional beta
> distribution confining the random variable in the interval (a, b). Since
> these concept are widely used in the baysian, I wonder whether somebody
> has already written this package. Thanks!
> 
> Best wishes,
> Peng
> 
> *******************************
> Peng Zhang
> Department of Biostatistics
> Harvard School of Public Health
> 655 Huntington Avenue
> Boston, Massachusetts 02115
> *******************************
> 
> I believe I can fly
> I believe I can touch the sky
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From pzhang at hsph.harvard.edu  Mon Feb 17 17:42:03 2003
From: pzhang at hsph.harvard.edu (Peng Zhang)
Date: Mon Feb 17 17:42:03 2003
Subject: [R] multivariate sampling question again
In-Reply-To: <Pine.LNX.4.44.0302170958460.11873-100000@bolker.zoo.ufl.edu>
References: <Pine.LNX.4.44.0302170958460.11873-100000@bolker.zoo.ufl.edu>
Message-ID: <Pine.GSO.4.53.0302171136240.11733@hsph.harvard.edu>

Dr. Bolker

I just wrote it yesterday. Thank you anyway. However do you have some
ideas about sampling from restricted beta distribution. say from beta(a,
b) but value between m and n. Now I generate lots of samples from beta(a,
b) and then choose value between m and n, but it is very time-consuming.
Do you have some good ideas? Thanks again!

Best wishes,
Peng

*******************************
Peng Zhang
Department of Biostatistics
Harvard School of Public Health
655 Huntington Avenue
Boston, Massachusetts 02115
*******************************

I believe I can fly
I believe I can touch the sky

On Mon, 17 Feb 2003, Ben Bolker wrote:

>
>   I have a few of these implemented (Wishart, multinomial, dirichlet),
> mostly from hints provided on the R list; I may try to clean them up for
> presentation, but you can write directly to me for fairly raw code if
> you're interested.
>
>   Ben Bolker
>
> On Sun, 16 Feb 2003, Peng Zhang wrote:
>
> > Hi
> >
> > Thanks for replying my question! What really interested me is that the
> > package providing some complex form sampling, such as wishart,
> > multinomial, dirichlet. And others for example conditional beta
> > distribution confining the random variable in the interval (a, b). Since
> > these concept are widely used in the baysian, I wonder whether somebody
> > has already written this package. Thanks!
> >
> > Best wishes,
> > Peng
> >
> > *******************************
> > Peng Zhang
> > Department of Biostatistics
> > Harvard School of Public Health
> > 655 Huntington Avenue
> > Boston, Massachusetts 02115
> > *******************************
> >
> > I believe I can fly
> > I believe I can touch the sky
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> --
> 318 Carr Hall                                bolker at zoo.ufl.edu
> Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
> Box 118525                                   (ph)  352-392-5697
> Gainesville, FL 32611-8525                   (fax) 352-392-3704
>
>



From ripley at stats.ox.ac.uk  Mon Feb 17 18:02:02 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon Feb 17 18:02:02 2003
Subject: [R] multivariate sampling question again
In-Reply-To: <Pine.GSO.4.53.0302171136240.11733@hsph.harvard.edu>
Message-ID: <Pine.WNT.4.44.0302171654230.2644-100000@gannet.stats.ox.ac.uk>

R-devel already contains rmultinom.

I don't see why rejection sampling on (m, n) should be slow unless m-n is
very small or far out in the tails, in which case why do you want this?
In any case, inversion will be a perfectly adequate method as you have
pbeta and qbeta.

On Mon, 17 Feb 2003, Peng Zhang wrote:

> Dr. Bolker
>
> I just wrote it yesterday. Thank you anyway. However do you have some
> ideas about sampling from restricted beta distribution. say from beta(a,
> b) but value between m and n. Now I generate lots of samples from beta(a,
> b) and then choose value between m and n, but it is very time-consuming.
> Do you have some good ideas? Thanks again!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jasont at indigoindustrial.co.nz  Mon Feb 17 18:17:03 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon Feb 17 18:17:03 2003
Subject: [R] inserting elements in a list
In-Reply-To: <Pine.OSF.3.91.1030217133410.1061D-100000@paleo>; from alobo@ija.csic.es on Mon, Feb 17, 2003 at 02:01:47PM +0100
References: <Pine.OSF.3.91.1030217133410.1061D-100000@paleo>
Message-ID: <20030218061652.A3660@camille.indigoindustrial.co.nz>

On Mon, Feb 17, 2003 at 02:01:47PM +0100, Agustin Lobo wrote:
...
> Let's say we have a vector:
> > a
> [1] "1" "2" "3" "5" "6" "3"
> 
> and we want to insert a "7" after
> any given "3", i.e., we want vector a 
> to become:
> 
> [1] "1" "2" "3" "7" "5" "6" "3" "7"
...

No one-step way I can think of.  I'd use a "for" loop.

a <- c(1,2,3,5,6,3)

N <- length(a)
for(ii in which(a==3)) {
    if(ii == N) {
        a <- c(a,7)
    } else {
        a <- c(a[1:ii],7,a[(ii+1):N])
    }
}

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From p.dalgaard at biostat.ku.dk  Mon Feb 17 18:32:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Feb 17 18:32:02 2003
Subject: [R] inserting elements in a list
In-Reply-To: <20030218061652.A3660@camille.indigoindustrial.co.nz>
References: <Pine.OSF.3.91.1030217133410.1061D-100000@paleo>
	<20030218061652.A3660@camille.indigoindustrial.co.nz>
Message-ID: <x2r8a6zubm.fsf@biostat.ku.dk>

Jason Turner <jasont at indigoindustrial.co.nz> writes:

> On Mon, Feb 17, 2003 at 02:01:47PM +0100, Agustin Lobo wrote:
> ...
> > Let's say we have a vector:
> > > a
> > [1] "1" "2" "3" "5" "6" "3"
> > 
> > and we want to insert a "7" after
> > any given "3", i.e., we want vector a 
> > to become:
> > 
> > [1] "1" "2" "3" "7" "5" "6" "3" "7"
> ...
> 
> No one-step way I can think of.  I'd use a "for" loop.
> 
> a <- c(1,2,3,5,6,3)
> 
> N <- length(a)
> for(ii in which(a==3)) {
>     if(ii == N) {
>         a <- c(a,7)
>     } else {
>         a <- c(a[1:ii],7,a[(ii+1):N])
>     }
> }

This should work:

unlist(lapply(a,function(x)if(x==3)c(3,7)else x))

Whether it is cleaner is debatable.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Torsten.Hothorn at rzmail.uni-erlangen.de  Mon Feb 17 18:46:03 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon Feb 17 18:46:03 2003
Subject: [R] How to code a bootstrap version of the Wilcoxon-Mann-Whitneytest (and variants)?
In-Reply-To: <D5F4FCB34ECBC041992A289145E3FD662208AB@ibwsrvp2.iw.uni-karlsruhe.de>
References: <D5F4FCB34ECBC041992A289145E3FD662208AB@ibwsrvp2.iw.uni-karlsruhe.de>
Message-ID: <Pine.LNX.4.51.0302171837250.18227@artemis.imbe.med.uni-erlangen.de>

> Hello,
>
> can someone please help me with coding a function for a bootstrap WMW test (package boot, R under Windows, version 1.6.2)?
>
> >From reading the RNews article on the boot package I understand that I have to supply the boot command with a function to calculate the test statistic but I have difficulties coding the function. Since some of the pooled samples contain many ties, I would like to code the function so that I can easily exchange the Wilcoxon W (or Mann-Whitney U) statistic with a variant (such as for example the Fligner-Policello robust rank-order test statistic or the Uleman U statistic). Is there a way to achieve this?
>

what are you interested in? The permutation distribution of (almost) any
statistic can be computed either using special functions like {dpq}wilcox (as you
already noticed) or pperm (package exactRankTests). If I recall it
correctly, there is a chapter in "MASS" on how to simulate the permutation
distribution in a fast way.

Torsten

> My samples are independent and consist of 8 observations. The values are discrete and measured on ordinal scale. I found the following example for an WMW test online but I do not know how to write a function to be supplied to the boot command:
>
> # Run Wilcoxon Exact Test
> #
> # Create X and Y variables
> x <- c(76.375, 75.125, 77, 77, 77, 76.375, 77, 76.375)
> y <- c(76.375, 75.75, 76.375, 76.375, 76.375, 75.75, 77, 76.375)
> print(nx <- length(x))
> print(ny <- length(y))
>
> data <- c(x, y)
> names(data) <- c(rep("x", nx), rep("y", ny))
> data <- sort(data)
> r <- rank(data)
>
> # Printout data and ranks in X and Y
> rbind(data, r)
>
> # Wilcoxon W statistic
> print(w <- sum(r[names(data) == "y"]))
>
> # Umrechnen in Mann-Whitney U statistic
> print(u <- w - ny * (ny + 1) / 2)
>
> # Get probability from Wilcoxon distribution m=8, n=8
> pwilcox(u, nx, ny)
>
> # Perform two-sided exact test
> wilcox.exact(y, x, alternative="two.sided")
>
>
> Thanks in advance
> Stefan
> ---
> Stefan Strecker
> Universitaet Karlsruhe (TH)
> Department of Economics and Business Engineering
> Chair for Information Management and Systems
> Englerstrasse 14
> D-76131 Karlsruhe, Germany
> T: +49 721 608 8374
> F: +49 721 608 8399
> M: +49 179 69 29 746
> http://www.iw.uni-karlsruhe.de
> DH PGP Key available upon request
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From korponai at georgikon.hu  Mon Feb 17 18:59:03 2003
From: korponai at georgikon.hu (Korponai =?iso-8859-2?q?J=E1nos?=)
Date: Mon Feb 17 18:59:03 2003
Subject: [R] shipro.test
Message-ID: <E18kpW5-000080-00@daphnia>

Hi,

I am newby to R. I run this test (shapiro.test(rt(2000,30))) (R : Copyright 
2001, The R Development Core Team Version 1.3.1  (2001-08-31)) for several 
times and results were different.
Why do the shapiro.test produce different outputs?
Thanks,
-- 
Dr. Janos Korponai
West-Transdanubian District Water Authority
Dept. Kis-Balaton
Csik F. str. 1
H-8360 Keszthely
Hungary
e-mail: korponai at georgikon.hu



From zeileis at ci.tuwien.ac.at  Mon Feb 17 19:09:02 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Mon Feb 17 19:09:02 2003
Subject: [R] shipro.test
In-Reply-To: <E18kpW5-000080-00@daphnia>
References: <E18kpW5-000080-00@daphnia>
Message-ID: <200302171808.h1HI8Bt9016825@thorin.ci.tuwien.ac.at>

On Monday 17 February 2003 18:57, Korponai J?nos wrote:

> Hi,
>
> I am newby to R. I run this test (shapiro.test(rt(2000,30))) (R :
> Copyright 2001, The R Development Core Team Version 1.3.1 
> (2001-08-31))

That version is ancient...by now there is R 1.6.2

> for several times and results were different.
> Why do the shapiro.test produce different outputs?

If you generate random numbers by rt() you would
expect the output to be different in each run, wouldn't you?

If you generate the random numbers first:
R> x <- rt(2000,30)
and then run the test
R> shapiro.test(x)
it will indeed produce stable results.
Z

> Thanks,



From p.dalgaard at biostat.ku.dk  Mon Feb 17 19:13:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Feb 17 19:13:03 2003
Subject: [R] shipro.test
In-Reply-To: <E18kpW5-000080-00@daphnia>
References: <E18kpW5-000080-00@daphnia>
Message-ID: <x2heb2zsfe.fsf@biostat.ku.dk>

Korponai J?nos <korponai at georgikon.hu> writes:

> Hi,
> 
> I am newby to R. I run this test (shapiro.test(rt(2000,30))) (R : Copyright 
> 2001, The R Development Core Team Version 1.3.1  (2001-08-31)) for several 
> times and results were different.
> Why do the shapiro.test produce different outputs?

Because you are calling it with different random samples from the t
distribution! Look at help(rt), or just do rt(10,30) a couple of
times. 

BTW, you should get a newer version. 1.6.2 is current.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tlumley at u.washington.edu  Mon Feb 17 19:17:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Feb 17 19:17:03 2003
Subject: [R] ! arithmetic
In-Reply-To: <20030216033337.32245.qmail@web41414.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0302171012380.88408-100000@homer39.u.washington.edu>

On Sat, 15 Feb 2003, Stan Markus wrote:

>
> Since "!" is a logical operator in R, how does one use it in its
> arithmetic sense, say to calculate x!/y!(N-y)! ?
>

- You can use gamma(x+1) for factorial, or the factorial() function in the
"gregmisc" package
- More usefully, you can use lgamma(x+1) to compute log factorials and
reduce overflow problems if any of the numbers is large
- It's also worth looking at choose() and lchoose() , which compute the
binomial coefficients and their logarithms.

	-thomas



From jasont at indigoindustrial.co.nz  Mon Feb 17 19:35:03 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon Feb 17 19:35:03 2003
Subject: [R] inserting elements in a list
In-Reply-To: <x2r8a6zubm.fsf@biostat.ku.dk>; from p.dalgaard@biostat.ku.dk on Mon, Feb 17, 2003 at 06:32:45PM +0100
References: <Pine.OSF.3.91.1030217133410.1061D-100000@paleo> <20030218061652.A3660@camille.indigoindustrial.co.nz> <x2r8a6zubm.fsf@biostat.ku.dk>
Message-ID: <20030218073443.A4347@camille.indigoindustrial.co.nz>

On Mon, Feb 17, 2003 at 06:32:45PM +0100, Peter Dalgaard BSA wrote:
> Jason Turner <jasont at indigoindustrial.co.nz> writes:
> 
> > On Mon, Feb 17, 2003 at 02:01:47PM +0100, Agustin Lobo wrote:
> > ...
> > > Let's say we have a vector:
> > > > a
> > > [1] "1" "2" "3" "5" "6" "3"
> > > 
> > > and we want to insert a "7" after
> > > any given "3", i.e., we want vector a 
> > > to become:
> > > 
> > > [1] "1" "2" "3" "7" "5" "6" "3" "7"
> > ...
> > 
> > No one-step way I can think of.  I'd use a "for" loop.
...
> This should work:
> 
> unlist(lapply(a,function(x)if(x==3)c(3,7)else x))
> 
> Whether it is cleaner is debatable.

Looks much cleaner to me.

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From tlumley at u.washington.edu  Mon Feb 17 19:39:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Feb 17 19:39:03 2003
Subject: [R] inserting elements in a list
In-Reply-To: <x2r8a6zubm.fsf@biostat.ku.dk>
Message-ID: <Pine.A41.4.44.0302171021240.88408-100000@homer39.u.washington.edu>

On 17 Feb 2003, Peter Dalgaard BSA wrote:

>
> > On Mon, Feb 17, 2003 at 02:01:47PM +0100, Agustin Lobo wrote:
> > ...
> > > Let's say we have a vector:
> > > > a
> > > [1] "1" "2" "3" "5" "6" "3"
> > >
> > > and we want to insert a "7" after
> > > any given "3", i.e., we want vector a
> > > to become:
> > >
> > > [1] "1" "2" "3" "7" "5" "6" "3" "7"
> > ...
> >
> >
> This should work:
>
> unlist(lapply(a,function(x)if(x==3)c(3,7)else x))
>
> Whether it is cleaner is debatable.
>

Or
  N<-length(a)
  threes<- a==3
  offset<- c(0,cumsum(threes)[-N])
  a[offset+(1:N)]<-a
  a[which(threes)+offset[threes]+1]<-7

for a more vectorised version.  Equally ugly, but understanding
these two solutions is probably educational.

Adding elements in the middle is something vectors are not good at, in
contrast to (pair-based or linked) lists.

	-thomas



From spencer.graves at pdf.com  Mon Feb 17 19:45:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon Feb 17 19:45:03 2003
Subject: [R] Call to glm inside a function
References: <488C02265C6AD611BF200002A542182F022B32F7@irnts22.ifp.fr>
Message-ID: <3E512D20.4040300@pdf.com>

	  Others know this subject much better than I do, and you should ignore 
these remarks if you get a more authoritative reply sooner, but in the 
interest of getting you an answer now, I'll expose my ignorance on this 
subject:  First, if you have access to a copy of Venables and Ripley, S 
Programming, I would read about "assign" there (and all other 
documentation you can find).

	  I'm guessing that "gml" probably uses "get" to find the weights and 
can't find them because it does not look in the frame of the calling 
function.

	  To get around this, try an "assign" something like the following 
before your call to "glm":

	  assign("data", data)

   	  I'm not certain this will work, but I've had similar problems in 
S-Plus and worked around them using assign.

	  I don't have time to work an example now,  but if this does not fix 
your problem, you might experiment with the "assign" arguments until you 
find something that works.  I don't like being too bold with "assign", 
because I don't understand what it does, and it could be just a little 
dangerous -- like overwriting a library or something.

Best Wishes,
Spencer Graves

ZABALZA-MEZGHANI Isabelle wrote:
> Hello,
> 
> I want to call glm inside a function. In the first lines of code I build the
> weights, the formula, ... and then I call glm with the following command:
>     glm(formularesp, data=data, family=familyresp,
> weights=eval(data$weights)
> 
> My problem is that the fitting proccess is performed just like if
> weights=NULL, even if my weights are not equals to 1. I've performed some
> return() command before this glm call to check the value of each argument,
> and everything seems OK.
> 
> Please, help me to understand why the code bypass my weighting instruction.
> 
> Regards
> 
> Isabelle
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Mon Feb 17 19:49:05 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Feb 17 19:49:05 2003
Subject: [R] How to code a bootstrap version of the Wilcoxon-Mann-Whitneytest
 (and variants)?
In-Reply-To: <Pine.LNX.4.51.0302171837250.18227@artemis.imbe.med.uni-erlangen.de>
Message-ID: <Pine.A41.4.44.0302171039020.88408-100000@homer39.u.washington.edu>

On Mon, 17 Feb 2003, Torsten Hothorn wrote:
> what are you interested in? The permutation distribution of (almost) any
> statistic can be computed either using special functions like {dpq}wilcox (as you
> already noticed) or pperm (package exactRankTests). If I recall it
> correctly, there is a chapter in "MASS" on how to simulate the permutation
> distribution in a fast way.
>

One could be interested in a bootstrap estimate of the sampling
distribution of the test statistic.  This is only the same as the
permutation distribution if the two distributions are the same. You can
certainly have the level of the test equal to the power without the
distributions being the same;  whether this counts as part of the null
hypothesis is really a philosophical question.

	-thomas



From ligges at statistik.uni-dortmund.de  Mon Feb 17 19:59:06 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Feb 17 19:59:06 2003
Subject: [R] Call to glm inside a function
References: <488C02265C6AD611BF200002A542182F022B32F7@irnts22.ifp.fr>
Message-ID: <3E513116.9649554F@statistik.uni-dortmund.de>


ZABALZA-MEZGHANI Isabelle wrote:
> 
> Hello,
> 
> I want to call glm inside a function. In the first lines of code I build the
> weights, the formula, ... and then I call glm with the following command:
>     glm(formularesp, data=data, family=familyresp,
> weights=eval(data$weights)
> 
> My problem is that the fitting proccess is performed just like if
> weights=NULL, even if my weights are not equals to 1. I've performed some
> return() command before this glm call to check the value of each argument,
> and everything seems OK.
> 
> Please, help me to understand why the code bypass my weighting instruction.

That's extremly hard, because you haven't told us what you *really* did.
Please provide a *short*, *reproducible* example. I guess you have got a
problem with scoping and specified the data in strange places, but
nothing I can see without more details. I presume you are on the recent
version of R, R-1.6.2 (please, tell it as well).

BTW: data() is an R function, thus it's not a good idea to use it as a
variable name.

Uwe Ligges
 
> Regards
> 
> Isabelle



From jgramlich at piocon.com  Mon Feb 17 20:09:02 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Mon Feb 17 20:09:02 2003
Subject: [R] R environment advice?
Message-ID: <1045508911.1952.6.camel@localhost.localdomain>

Hello,

My questions are meant to be not necessarily specific...I am looking for
advice and best practices for setting up an R environment.  Here's my
situation:

I am one of perhaps three or four individuals who will be analyzing the
same data through the use of R.  I would like to set up a "base"
environment for our project, basically some scripts that connect to a
database, load several database tables into matrices in R, strip the
columns out of those matrices and do some minor tabluation...for
instance:


channel <- odbcConnect(yada, yada, yada)

surveyresults <- (channel, select * from sometable)

multiresults <- (channel, select * from othertable)

multiresults.columnname <- multiresults[,1]  # or column 2 or 3 or 4 or
so on...

multiresults.columname.table <- table(multiresults.columnname)

etcetera, etcetera.


I would like to create a single file that I could share that would load
this environment up for a new R user for this dataset.  If any of you
wouldn't mind taking the time explaining how you would go about doing
something like this, I would appreciate it.

Also, does anyone know if one can set VI keybindings in an R shell?


Thank you,

Joshua Gramlich
Piocon Technologies
Chicago, Illinois USA



From p.dalgaard at biostat.ku.dk  Mon Feb 17 20:14:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Feb 17 20:14:03 2003
Subject: [R] inserting elements in a list
In-Reply-To: <Pine.A41.4.44.0302171021240.88408-100000@homer39.u.washington.edu>
References: <Pine.A41.4.44.0302171021240.88408-100000@homer39.u.washington.edu>
Message-ID: <x28ywezprk.fsf@biostat.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

>   N<-length(a)
>   threes<- a==3
>   offset<- c(0,cumsum(threes)[-N])
>   a[offset+(1:N)]<-a
>   a[which(threes)+offset[threes]+1]<-7
> 
> for a more vectorised version.  Equally ugly, but understanding
> these two solutions is probably educational.
> 
> Adding elements in the middle is something vectors are not good at, in
> contrast to (pair-based or linked) lists.

Extra exercises for the over-achievers:

1) Show that 

offset <- cumsum(threes) - threes

also works.

2) Show that the index in the last line is the same as

which(threes)+seq(length=sum(threes))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tlumley at u.washington.edu  Mon Feb 17 20:18:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Feb 17 20:18:03 2003
Subject: [R] Call to glm inside a function
In-Reply-To: <3E512D20.4040300@pdf.com>
Message-ID: <Pine.A41.4.44.0302171054160.88408-100000@homer39.u.washington.edu>

On Mon, 17 Feb 2003, Spencer Graves wrote:

>
> 	  Others know this subject much better than I do, and you should ignore
> these remarks if you get a more authoritative reply sooner, but in the
> interest of getting you an answer now, I'll expose my ignorance on this
> subject:  First, if you have access to a copy of Venables and Ripley, S
> Programming, I would read about "assign" there (and all other
> documentation you can find).

I would actually say that reading about 'assign' is the last resort --
most of the time you would be happier if you didn't know it existed.

> 	  I'm guessing that "gml" probably uses "get" to find the weights and
> can't find them because it does not look in the frame of the calling
> function.

Partially.  What is actually happening is complicated and since we weren't
given an example it's hard to be sure, but here is an attempt at
diagnosis.

Consider the following two functions
> test1
function(df){
ff<-y~x
glm(ff,data=df,weights=w)
}
> test2
function(df,ff){
glm(ff,data=df,weights=eval(df$w))
}

The first one `works', the second doesn't.  Now, the data and weights are
the same in both cases. What has changed is *where the formula was
defined*.  Formulas in R carry around a environment (usually where they
were created).

Now, glm() has to go through some complicated contortions in looking for
variables.  These are necessary to pick up variables that *aren't* in the
data= argument.  If everything is in the data argument then glm() has no
problems.  However, eval(df$w) isn't a reference to the data argument, so
it gets evaluated in the environment of the formula, where it doesn't
exist.  This would normally give an error, but if the data frame is called
`df' or `data' or `install.packages' or some other name that does exist in
the global environment you will get the $w component of that object,
almost certainly NULL, and end up not using any weights.

This suggests a solution to the problem:

> test3
function(df,ff){
glm(ff,data=df,weights=w)
}

which works because `w' is now found in the data= argument.

Now, some general lessons can be drawn from this (which is why it's worth
such a long response)

 --  Life is a lot simpler if everything that can be in the data argument
     is there.
 --  It's a real pity that glm() didn't come with syntax to distinguish
explictly between references to data= and actual variables (eg weights=~w
vs weights=w). If you are writing functions of your own, please use some
such syntax.
 --  A useful aid to debugging is to change variable names: data$w or
     df$returns NULL, but myDataFrame$w is an error.


> 	  To get around this, try an "assign" something like the following
> before your call to "glm":
>
> 	  assign("data", data)
>
>    	  I'm not certain this will work, but I've had similar problems in
> S-Plus and worked around them using assign.

While the symptoms are similar the underlying problem is different in R.
This is like antibiotics for a cold: it might appear to work by accident,
but prolonged use will create highly resistant bugs.


> 	  I don't have time to work an example now,  but if this does not fix
> your problem, you might experiment with the "assign" arguments until you
> find something that works.  I don't like being too bold with "assign",
> because I don't understand what it does, and it could be just a little
> dangerous -- like overwriting a library or something.

The main danger is ending up with subtle bugs in your code.  It's not too
hard to understand what a particular call to assign() does, but it can be
very hard to work out what goes wrong when a use of assign() somewhere
else in your code changes a variable.

	-thomas



From p.dalgaard at biostat.ku.dk  Mon Feb 17 20:22:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Feb 17 20:22:03 2003
Subject: [R] R environment advice?
In-Reply-To: <1045508911.1952.6.camel@localhost.localdomain>
References: <1045508911.1952.6.camel@localhost.localdomain>
Message-ID: <x24r72zp99.fsf@biostat.ku.dk>

Joshua Gramlich <jgramlich at piocon.com> writes:

> Also, does anyone know if one can set VI keybindings in an R shell?

Ctrl-Meta-j, as always in readline (gosh, someone really wants that?)
-- assuming you're not using Windows of course...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jgramlich at piocon.com  Mon Feb 17 20:48:03 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Mon Feb 17 20:48:03 2003
Subject: [R] Graphing
Message-ID: <1045511253.2210.0.camel@localhost.localdomain>

I think this may be a histogram, but I'm not sure.  Can anyone tell me
how to replicate this graph in R?




http://www.ginworks.com/images/multitot.gif





Thanks,


Joshua Gramlich



From mail at joeconway.com  Mon Feb 17 21:17:03 2003
From: mail at joeconway.com (Joe Conway)
Date: Mon Feb 17 21:17:03 2003
Subject: [R] PL/R - R procedural language handler for PostgreSQL
Message-ID: <3E5142AD.1020605@joeconway.com>

Hello,

I've been working on a procedural language handler for PostgreSQL, that 
allows R to be used to write PostgreSQL functions. At this point, I 
think PL/R is ready for wider testing and use. If anyone is interested 
in giving PL/R a try, the documentation and source tarball can be found 
here:

   http://www.joeconway.com/plr/

PL/R has been developed against PostgreSQL 7.3.2 and 7.4devel, and R 
1.6.2, on Red Hat 7.3 and 8.0 machines. You'll need a PostgreSQL source 
tree to compile and install PL/R. I'm sure that PL/R will *not* work 
with versions of PostgreSQL less than 7.3, but I'm not so sure WRT the 
minimum R version.

I'd appreciate any and all feedback.

Thanks,

Joe



From ligges at statistik.uni-dortmund.de  Mon Feb 17 21:24:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Feb 17 21:24:03 2003
Subject: [R] Graphing
References: <1045511253.2210.0.camel@localhost.localdomain>
Message-ID: <3E51438A.BF9170AF@statistik.uni-dortmund.de>

Joshua Gramlich wrote:
> 
> I think this may be a histogram, but I'm not sure.  Can anyone tell me
> how to replicate this graph in R?
> 
> http://www.ginworks.com/images/multitot.gif
> 
> Thanks,
> 
> Joshua Gramlich

Exactly? I think the visualization given at that URL could be improved.

A barplot() in R might be a appropriate solution, because a histogram
implies a continuous distribution (looks like a discrete one). You have
to play with margin sizes in order to print all that text into the
figure.

barplot(), par(), and text() are your friends.

Uwe Ligges



From p.murrell at auckland.ac.nz  Mon Feb 17 21:28:18 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon Feb 17 21:28:18 2003
Subject: [R] grid: clipping points to viewport?
References: <3E510895.1030207@hppi.troitsk.ru>
Message-ID: <3E51438C.5090403@stat.auckland.ac.nz>

Hi


M.Kondrin wrote:

> Why command 
> grid.points(c(0,1,1.1),c(0,1,1.1),vp=viewport(w=0.5,h=0.5,x=0.5,y=0.5,clip=TRUE)) 
> does not clip points (point (1.1,1.1) is still visible), although there 
> is no problem with grid.lines(...)?



What version/device is this happening on?
This works for me (R 1.6.2, X11/postscript)


> And one more question - how can I swap direction of tick marks on 
> grid.x(y)axis to turn it inside plot?



If I understand what you mean, there is no argument to grid.x(y)axis 
that will do what you want.  This is something that should probably be 
added at some piont.  For now, it is pretty straightforward to do 
something by hand.  The following may help ...

push.viewport(viewport(w=0.5,h=0.5,x=0.5,y=0.5))
x <- rnorm(10)
y <- rnorm(10)
push.viewport(dataViewport(x, y))
grid.rect(gp=gpar(col="grey"))
grid.points(x, y)
tick.loc <- grid.pretty(range(x))
grid.segments(unit(tick.loc, "native"),
               0,
               unit(tick.loc, "native"),
               unit(0.5, "lines"))
grid.lines(unit(range(tick.loc), "native"), 0)
grid.text(tick.loc, unit(tick.loc, "native"),
           unit(-0.5, "lines"))
pop.viewport(2)


Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz



From jfox at mcmaster.ca  Mon Feb 17 23:05:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon Feb 17 23:05:03 2003
Subject: [R] inserting elements in a list
In-Reply-To: <x28ywezprk.fsf@biostat.ku.dk>
References: <Pine.A41.4.44.0302171021240.88408-100000@homer39.u.washington.edu>
 <Pine.A41.4.44.0302171021240.88408-100000@homer39.u.washington.edu>
Message-ID: <5.1.0.14.2.20030217165522.01f39ee8@mcmail.cis.mcmaster.ca>

Dear Peter, Thomas, et al.,

In the spirit of programming exercises, here's a recursive solution:

insert.values <- function(vector, after, values){
     where <- which(vector == after)[1]
     if (is.na(where)) vector
     else c(vector[1:where], values,
         Recall(vector[-(1:where)], after, values))
     }
insert.values(a, "3", "7")

Regards,
  John

At 08:11 PM 2/17/2003 +0100, Peter Dalgaard BSA wrote:
>Thomas Lumley <tlumley at u.washington.edu> writes:
>
> >   N<-length(a)
> >   threes<- a==3
> >   offset<- c(0,cumsum(threes)[-N])
> >   a[offset+(1:N)]<-a
> >   a[which(threes)+offset[threes]+1]<-7
> >
> > for a more vectorised version.  Equally ugly, but understanding
> > these two solutions is probably educational.
> >
> > Adding elements in the middle is something vectors are not good at, in
> > contrast to (pair-based or linked) lists.
>
>Extra exercises for the over-achievers:
>
>1) Show that
>
>offset <- cumsum(threes) - threes
>
>also works.
>
>2) Show that the index in the last line is the same as
>
>which(threes)+seq(length=sum(threes))

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From Michael.Scroggie at nre.vic.gov.au  Mon Feb 17 23:31:03 2003
From: Michael.Scroggie at nre.vic.gov.au (Michael.Scroggie@nre.vic.gov.au)
Date: Mon Feb 17 23:31:03 2003
Subject: [R] returning argument names
Message-ID: <OF24EC5583.4C63C010-ONCA256CD0.007AC82B@nre.vic.gov.au>

Dear r-list folks,

I have a problem which has been bugging me for a while now and I was hoping
someone out there might be able to help.

If I have a user-defined function with an indeterminate number of
arguments, using the well-known "..." construct, how can I get the
function to return the names of the items which were the arguments of the
function as part of the function's output? This is easily done where there
is a fixed number of arguments: e.g:

aa<-c(1,2,3,4,5)
bb<-c(6,7,8,9,10)

argument.out<-function(object1,object2){
name1<-deparse(substitute(object1))
name2<-deparse(substitute(object2))
output<-c(name1,name2)
return(output)
}
argument.out(aa,bb)


How can I produce a similar results from a function where there is an indeterminate number of arguments i.e:

argument.list<-function(object,...){

Any suggestions or solutions would be much appreciated.

Kind regards,


Michael Scroggie



From p.connolly at hortresearch.co.nz  Mon Feb 17 23:35:04 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Mon Feb 17 23:35:04 2003
Subject: [R] Plotting POSIXct data:  Is this error message for real?
Message-ID: <20030217223356.GB8569@hortresearch.co.nz>

platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.2              
year     2003             
month    01               
day      10               
language R                
> 


> x <- paste(1:28, "/02/03", sep = "")
> xct <- as.POSIXct(strptime(x, "%d/%m/%y"))
> count <- rpois(28, 5)
> plot(xct, count, ylab = "something")
Warning message: 
parameter "ylab" couldn't be set in high-level plot() function 


Even though "ylab" can't be set, the resulting plot does succeed.


Compare with:
> plot(as.numeric(xct), count, ylab = "something")


No error (but of course, the x axis isn't much use).
Should the warning really be given?

best


-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From day at upci.pitt.edu  Mon Feb 17 23:39:03 2003
From: day at upci.pitt.edu (Day, Roger)
Date: Mon Feb 17 23:39:03 2003
Subject: [R] Rgui crash and Macro Magic
Message-ID: <73D624FECBBAF6459BB60437FF7C02FB6B9E82@nsabpmail>

You're welcome!

Here's some more:

this morning, even though the Macro Magic icon was not
displayed on the process section of the taskbar,
R was crashing again.
However, I found  Macro.exe in the Task Manager Processes tab.
Killed it, and then R worked fine.
Somehow, Macro Magic had reloaded, but invisibly this time.


-----Original Message-----
From: Duncan Murdoch [mailto:dmurdoch at pair.com] 
Sent: Sunday, February 16, 2003 10:43 AM
To: Day, Roger
Subject: Re: [R] Rgui crash and Macro Magic


On Sat, 15 Feb 2003 22:03:50 -0500, you wrote:

>A consistent Rgui crash (1062 on XP) I was experiencing
>seemed initially to be solved by following  R Win FAQ 2.12: placing a 
>generic microsoft msvcrt.exe in rw1062\bin.
>
>But the crash problem quickly reappeared.
>Exiting Macro Magic, a keyboard macro utility,
>did solve the problem, apparently permanently
>according to my little "crossover design" study.
>I discovered this solution thanks to previous r-help messages about the

>dangers of keyboard macro programs.
>

Thanks for posting that.

Duncan Murdoch



From p.dalgaard at biostat.ku.dk  Tue Feb 18 00:00:19 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Feb 18 00:00:19 2003
Subject: [R] returning argument names
In-Reply-To: <OF24EC5583.4C63C010-ONCA256CD0.007AC82B@nre.vic.gov.au>
References: <OF24EC5583.4C63C010-ONCA256CD0.007AC82B@nre.vic.gov.au>
Message-ID: <x2lm0etsu0.fsf@biostat.ku.dk>

Michael.Scroggie at nre.vic.gov.au writes:

> Dear r-list folks,
> 
> I have a problem which has been bugging me for a while now and I was hoping
> someone out there might be able to help.
> 
> If I have a user-defined function with an indeterminate number of
> arguments, using the well-known "..." construct, how can I get the
> function to return the names of the items which were the arguments of the
> function as part of the function's output? This is easily done where there
> is a fixed number of arguments: e.g:
> 
> aa<-c(1,2,3,4,5)
> bb<-c(6,7,8,9,10)
> 
> argument.out<-function(object1,object2){
> name1<-deparse(substitute(object1))
> name2<-deparse(substitute(object2))
> output<-c(name1,name2)
> return(output)
> }
> argument.out(aa,bb)
> 
> 
> How can I produce a similar results from a function where there is an indeterminate number of arguments i.e:
> 
> argument.list<-function(object,...){
> 
> Any suggestions or solutions would be much appreciated.

match.call() is your friend. E.g.

 f <- function(...) sapply(as.list(match.call())[-1], deparse)
 f(fee=foo,fie=bar,foe=baz)

actually, as.list is superfluous:

 f <- function(...) sapply(match.call()[-1], deparse)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From mschwartz at medanalytics.com  Tue Feb 18 00:06:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue Feb 18 00:06:03 2003
Subject: [R] returning argument names
In-Reply-To: <OF24EC5583.4C63C010-ONCA256CD0.007AC82B@nre.vic.gov.au>
Message-ID: <004e01c2d6d8$ad02ff50$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of 
>Michael.Scroggie at nre.vic.gov.au
>Sent: Monday, February 17, 2003 4:32 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] returning argument names
>
>
>Dear r-list folks,
>
>I have a problem which has been bugging me for a while now and 
>I was hoping someone out there might be able to help.
>
>If I have a user-defined function with an indeterminate number 
>of arguments, using the well-known "..." construct, how can I 
>get the function to return the names of the items which were 
>the arguments of the function as part of the function's 
>output? This is easily done where there is a fixed number of 
>arguments: e.g:
>
>aa<-c(1,2,3,4,5)
>bb<-c(6,7,8,9,10)
>
>argument.out<-function(object1,object2){
>name1<-deparse(substitute(object1))
>name2<-deparse(substitute(object2))
>output<-c(name1,name2)
>return(output)
>}
>argument.out(aa,bb)
>
>
>How can I produce a similar results from a function where 
>there is an indeterminate number of arguments i.e:
>
>argument.list<-function(object,...){
>
>Any suggestions or solutions would be much appreciated.
>
>Kind regards,
>
>
>Michael Scroggie


Somebody jump in and correct me if wrong but I believe that you can
use the following in the body of your function:

{
  ...

  dotargs <- list(...)

  ...
}


You can then access 'dotargs', which will be a list containing the
arguments and their names, if you specified names.  Of course the
length of dotargs will be the number of additional arguments
specified.

A quick sample that just returns some arbitrary arguments:

dottest <- function(Arg1, ...)
{
  dotargs <- list(...)
  return(dotargs)
}


>dottest(1, b = 2, MyArg = 3, d = "something")
$b
[1] 2

$MyArg
[1] 3

$d
[1] "something"


Note that 'Arg1' is explicitly defined in the function, so it is not
part of 'dotargs'. You would need to add that into your function
return or print values.


Hope that helps,

Regards,

Marc Schwartz



From Wendy.Zhao at fimat.com  Tue Feb 18 00:28:02 2003
From: Wendy.Zhao at fimat.com (Wendy Zhao)
Date: Tue Feb 18 00:28:02 2003
Subject: [R] compile R on i386-sun-solaris
Message-ID: <OFAEDF730A.CC9F67D9-ON86256CD0.007A600C@fimat.com>

Hi

We purchased new Sun LX50 intel based server, and download 2.95.3 gcc intel
for solaris8 as compiler to compile R
Here is what I did

#./configure --build=i386-sun-solaris
#make

And it fails with the following error

gcc -G -L/usr/local/lib -o eda.so init.o line.o smooth.o
ld: fatal: file line.o: wrong ELF machine type: EM_SPARC
ld: fatal: File processing errors. No output written to eda.so
collect2: ld returned 1 exit status
*** Error code 1
make: Fatal error: Command failed for target `eda.so'
Current working directory
/fimatrix/froutines/r-project/R-1.6.1/src/library/eda/src
*** Error code 1
make: Fatal error: Command failed for target `all'
Current working directory
/fimatrix/froutines/r-project/R-1.6.1/src/library/eda/src
*** Error code 1
make: Fatal error: Command failed for target `all'
Current working directory
/fimatrix/froutines/r-project/R-1.6.1/src/library/eda
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /fimatrix/froutines/r-project/R-1.6.1/src/library
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /fimatrix/froutines/r-project/R-1.6.1/src
*** Error code 1
make: Fatal error: Command failed for target `R'


does anyone knows how to compile it under solaris for intel machine.
thanks
-Wendy



From NAVMSE-SRVMAIL at benefitmura.co.il  Tue Feb 18 02:26:03 2003
From: NAVMSE-SRVMAIL at benefitmura.co.il (NAV for Microsoft Exchange-SRVMAIL)
Date: Tue Feb 18 02:26:03 2003
Subject: [R] Norton AntiVirus detected and quarantined a virus in a message yo
 u sent.
Message-ID: <C6B7B95DDDDCD611B66100508BB0873A74D604@SRVMAIL>

Recipient of the infected attachment:  Tsila Livni\Inbox
Subject of the message:  Worm Klez.E immunity
One or more attachments were quarantined.
  Attachment not.exe was Quarantined for the following reasons:
    Virus W32.Klez.H at mm was found.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/ms-tnef
Size: 1705 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030218/39afc9e4/attachment.bin

From j+rhelp at howard.fm  Tue Feb 18 07:27:03 2003
From: j+rhelp at howard.fm (j+rhelp@howard.fm)
Date: Tue Feb 18 07:27:03 2003
Subject: [R] inserting elements in a list
In-Reply-To: <x28ywezprk.fsf@biostat.ku.dk>
References: <Pine.A41.4.44.0302171021240.88408-100000@homer39.u.washington.edu> <x28ywezprk.fsf@biostat.ku.dk>
Message-ID: <20030218062603.5031F46C22@server2.fastmail.fm>

On 17 Feb 2003 20:11:11 +0100, "Peter Dalgaard BSA"
<p.dalgaard at biostat.ku.dk> said:
> Thomas Lumley <tlumley at u.washington.edu> writes:
> 
> >   N<-length(a)
> >   threes<- a==3
> >   offset<- c(0,cumsum(threes)[-N])
> >   a[offset+(1:N)]<-a
> >   a[which(threes)+offset[threes]+1]<-7
> > 
> > for a more vectorised version.  Equally ugly, but understanding
> > these two solutions is probably educational.
> > 
> > Adding elements in the middle is something vectors are not good at, in
> > contrast to (pair-based or linked) lists.

Indeed they're not - and the code above fails to do this insertion:

> a[which(threes)+offset[threes]+1]<-7
> a
[1]  1  2  3  7  6  3 NA  7

The problem is that it is placing the '7's in the correct place, but is
not shifting the right-hand side of the list across to make room.

> 2) Show that the index in the last line is the same as
> 
> which(threes)+seq(length=sum(threes))

That's a neat way to find the right spots to place the '7's - wherever
the '3's were before, plus one spot for each '3' that we've seen so
far... I'm not sure how to insert into the vector rather than replace
though - a quick browse through the list archives didn't turn up any
quick solutions (other than the types of loops suggested in earlier
answers in this thread).
-- 
  Jeremy Howard
  jhoward at fastmail.fm



From mkondrin at hppi.troitsk.ru  Tue Feb 18 09:06:03 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Tue Feb 18 09:06:03 2003
Subject: [R] grid: clipping points to viewport?
References: <3E510895.1030207@hppi.troitsk.ru> <3E51438C.5090403@stat.auckland.ac.nz>
Message-ID: <3E52142E.8060302@hppi.troitsk.ru>

Paul Murrell wrote:

> Hi
>
>
> M.Kondrin wrote:
>
>> Why command 
>> grid.points(c(0,1,1.1),c(0,1,1.1),vp=viewport(w=0.5,h=0.5,x=0.5,y=0.5,clip=TRUE)) 
>> does not clip points (point (1.1,1.1) is still visible), although 
>> there is no problem with grid.lines(...)?
>
>
>
>
> What version/device is this happening on?
> This works for me (R 1.6.2, X11/postscript) 

Paul -thank you very much!
Problem with clipping happens when I use gtk() device from Omegahat 
RGtkDevice (R ver. 1.6.1). I think I should address this question to them.



From pwolf at wiwi.uni-bielefeld.de  Tue Feb 18 09:49:06 2003
From: pwolf at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Tue Feb 18 09:49:06 2003
Subject: [R] inserting elements in a list
Message-ID: <3E51F346.8AE27FD6@wiwi.uni-bielefeld.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030218/2cfe9740/attachment.pl

From Robert.Espesser at lpl.univ-aix.fr  Tue Feb 18 11:12:03 2003
From: Robert.Espesser at lpl.univ-aix.fr (Robert Espesser)
Date: Tue Feb 18 11:12:03 2003
Subject: [R] Redundancy contrasts
References: <3.0.6.32.20030213200140.00a21318@pop-server.ucl.ac.uk> <6ru1f798vo.fsf@bates4.stat.wisc.edu>
Message-ID: <3E523D93.77F4C3B7@lpl.univ-aix.fr>

Is it meaningful to run 2 different sets of contrasts on a model , or is
there some redundancy somewhere ?
For example,I have a model :
tcons ~ group

where group is a factor with 3 levels ( A, B, C)
I first run the model with the default contrasts (treatment), 
so I  tested   (A vs B)   and (A vs C); 
but is it meaningful to also carry on a 2nd analysis with an other set
of
contrasts, to  test B vs C  ?  ie   c(0,-1,1)  ,  in fit.contrasts
gregmisc notation.

I'v heard  that the  first  set of contrast ( ie treatment default in
the example)
 extracts all the "information"
in the model, and that  a second analysis with an other set of contrasts
was not meaningful.

Thanks for help. 
-- 
Robert Espesser     
Laboratoire Parole et Langage  UMR 6057, CNRS
29 Av. Robert Schuman  13621 AIX    (FRANCE)
Tel: +33 (0)4 42 95 36 26   Fax: +33 (0)4 42 59 50 96
http://www.lpl.univ-aix.fr/~espesser
mailto:Robert.Espesser at lpl.univ-aix.fr



From hardouin at cebc.cnrs.fr  Tue Feb 18 12:09:02 2003
From: hardouin at cebc.cnrs.fr (Hardouin =?iso-8859-1?Q?Lo=EFc?=)
Date: Tue Feb 18 12:09:02 2003
Subject: [R] glm and overdispersion
Message-ID: <3E521341.1F7747B2@cebc.cnrs.fr>


Hi,

I am performing glm with binomial family and my data show slight
overdispersion (HF<1.5). Nevertheless, in order to take into account for
this heterogeneity though weak, I use F-test rather than Chi-square
(Krackow & Tkadlec, 2001). But surprisingly, outputs of this two tests
are exactly similar. What is the reason and how can I scale the output
by overdispersion ??

Thank you,

Alexandre MILLON
-------------- next part --------------
A non-text attachment was scrubbed...
Name: hardouin.vcf
Type: text/x-vcard
Size: 360 bytes
Desc: Carte pour Hardouin Loc
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030218/31e9825f/hardouin.vcf

From ripley at stats.ox.ac.uk  Tue Feb 18 12:19:09 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb 18 12:19:09 2003
Subject: [R] glm and overdispersion
In-Reply-To: <3E521341.1F7747B2@cebc.cnrs.fr>
Message-ID: <Pine.LNX.4.44.0302181115490.13642-100000@gannet.stats>

Use the quasibinomial family -- see the help pages.

Warning: how are you estimating the over-dispersion?  The estimate given 
by the residual deviance can be badly biased.

I don't know your reference, but this is all in McCullagh & Nelder (1989) 
and earlier.

On Tue, 18 Feb 2003, Hardouin Lo?c wrote:

> I am performing glm with binomial family and my data show slight
> overdispersion (HF<1.5). Nevertheless, in order to take into account for
> this heterogeneity though weak, I use F-test rather than Chi-square
> (Krackow & Tkadlec, 2001). But surprisingly, outputs of this two tests
> are exactly similar. What is the reason and how can I scale the output
> by overdispersion ??

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Tue Feb 18 13:55:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue Feb 18 13:55:03 2003
Subject: [R] glm and overdispersion
In-Reply-To: <3E521341.1F7747B2@cebc.cnrs.fr>
Message-ID: <5.1.0.14.2.20030218075214.01e4cda8@mcmail.cis.mcmaster.ca>

Dear Alexandre,

The Anova function in the car package by default will calculate F-tests 
(specified by test="F") using a dispersion estimate based on the Pearson 
residuals. See ?Anova for details.

I hope that this helps,
  John

At 12:04 PM 2/18/2003 +0100, Hardouin Lo?c wrote:

>Hi,
>
>I am performing glm with binomial family and my data show slight
>overdispersion (HF<1.5). Nevertheless, in order to take into account for
>this heterogeneity though weak, I use F-test rather than Chi-square
>(Krackow & Tkadlec, 2001). But surprisingly, outputs of this two tests
>are exactly similar. What is the reason and how can I scale the output
>by overdispersion ??
>
>Thank you,
>
>Alexandre MILLON

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From jfox at mcmaster.ca  Tue Feb 18 14:35:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue Feb 18 14:35:03 2003
Subject: [R] Redundancy contrasts
In-Reply-To: <3E523D93.77F4C3B7@lpl.univ-aix.fr>
References: <3.0.6.32.20030213200140.00a21318@pop-server.ucl.ac.uk>
 <6ru1f798vo.fsf@bates4.stat.wisc.edu>
Message-ID: <5.1.0.14.2.20030218083112.01f18a58@mcmail.cis.mcmaster.ca>

Dear Robert,

What you suggest is certainly meaningful (that is the hypothesis tested 
makes sense), but raises an issue of simultaneous inference. There are 
simultaneous comparison procedures for dealing with this kind of problem. 
See, for example, the multcomp package.

John

At 12:05 PM 2/18/2003 -0200, you wrote:
>Is it meaningful to run 2 different sets of contrasts on a model , or is
>there some redundancy somewhere ?
>For example,I have a model :
>tcons ~ group
>
>where group is a factor with 3 levels ( A, B, C)
>I first run the model with the default contrasts (treatment),
>so I  tested   (A vs B)   and (A vs C);
>but is it meaningful to also carry on a 2nd analysis with an other set
>of
>contrasts, to  test B vs C  ?  ie   c(0,-1,1)  ,  in fit.contrasts
>gregmisc notation.
>
>I'v heard  that the  first  set of contrast ( ie treatment default in
>the example)
>  extracts all the "information"
>in the model, and that  a second analysis with an other set of contrasts
>was not meaningful.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From ccleland at optonline.net  Tue Feb 18 15:01:02 2003
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue Feb 18 15:01:02 2003
Subject: [R] coplot with boxplot panel function
Message-ID: <3E523C6A.7050307@optonline.net>

   I am attempting to construct a conditioning plot with a pair 
of boxplots within each panel.  The resulting plot has panels 
misplaced.  One misplaced panel is on top of the subcomponent 
describing ranges of the conditioning variable.  This is what I did:

X <- cut(rnorm(200), 2)
Y <- runif(200)
Z <- rnorm(200)
given.Z <- co.intervals(Z, number = 4, overlap = .25)

coplot(Y ~ X | Z, given.v = given.Z,
panel = function(x, y, ...){boxplot(y ~ x)})

   Any suggestions as to why this does not work and what the 
correct specification is would be greatly appreciated.

thanks,

Chuck Cleland

WinXP Pro

 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.2
year     2003
month    01
day      10
language R



From friendly at yorku.ca  Tue Feb 18 15:16:05 2003
From: friendly at yorku.ca (Michael Friendly)
Date: Tue Feb 18 15:16:05 2003
Subject: [R] Graphing
In-Reply-To: <20030218110008.56.17311.Mailman@hypatia.math.ethz.ch>
References: <20030218110008.56.17311.Mailman@hypatia.math.ethz.ch>
Message-ID: <3E524006.7030805@yorku.ca>

>Message: 26
>From: Joshua Gramlich <jgramlich at piocon.com>
>To: "help R (E-mail)" <r-help at stat.math.ethz.ch>
>Date: 17 Feb 2003 13:47:32 -0600
>Subject: [R] Graphing
>
>I think this may be a histogram, but I'm not sure.  Can anyone tell me
>how to replicate this graph in R?
>
>
>
>
>http://www.ginworks.com/images/multitot.gif
>
How about  :-)

system("sas multitot")

where multitot.sas is

goptions device=gif;
proc gchart;
  hbar devices;
  by year;

-Michael

-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From sundar.dorai-raj at pdf.com  Tue Feb 18 15:22:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue Feb 18 15:22:03 2003
Subject: [R] coplot with boxplot panel function
References: <3E523C6A.7050307@optonline.net>
Message-ID: <3E524141.6040506@pdf.com>

Chuck Cleland wrote:
>   I am attempting to construct a conditioning plot with a pair of 
> boxplots within each panel.  The resulting plot has panels misplaced.  
> One misplaced panel is on top of the subcomponent describing ranges of 
> the conditioning variable.  This is what I did:
> 
> X <- cut(rnorm(200), 2)
> Y <- runif(200)
> Z <- rnorm(200)
> given.Z <- co.intervals(Z, number = 4, overlap = .25)
> 
> coplot(Y ~ X | Z, given.v = given.Z,
> panel = function(x, y, ...){boxplot(y ~ x)})
> 
>   Any suggestions as to why this does not work and what the correct 
> specification is would be greatly appreciated.
> 


Not sure, but you might want to try boxplot(y ~ x, add = TRUE).

When I did this I had to add xlim = c(0, 3) so the boxplots were drawn 
completely within the panel.

Sundar



From hgoehlmann at gmx.de  Tue Feb 18 15:49:03 2003
From: hgoehlmann at gmx.de (hgoehlmann@gmx.de)
Date: Tue Feb 18 15:49:03 2003
Subject: [R] Help on eqscplot scatterplot
References: <Pine.LNX.4.44.0302140807560.16111-100000@gannet.stats>
Message-ID: <30008.1045579679@www47.gmx.net>

Hi,

I am using the equal scales scatterplot plot (eqscplot {MASS}), into which I
plot a few thousand data points. The data points which accumulate towards
the centrum of the plot are not informative while the data points furthest away
from the centrum are most informative. I therefore would like to create a
combined plot which instead of drawing all data points, would only draw the
less informative data points via a density surface and starting from a defined
distance from the centrum the actual data points would be plotted.

Has anyone worked with this kind of problem? I have tried combinations of
filled.contour with plotting individual points, but I really would need to have
an geometrically equal scales plot. Should I study the lattice graphs?

I would appreciate any comment you can give.

Cheers,
hinrich   d8-)



From hi_ono2001 at ybb.ne.jp  Tue Feb 18 16:31:03 2003
From: hi_ono2001 at ybb.ne.jp (Hisaji Ono)
Date: Tue Feb 18 16:31:03 2003
Subject: [R] PL/R - R procedural language handler for PostgreSQL
References: <3E5142AD.1020605@joeconway.com>
Message-ID: <00b101c2d762$b01358e0$7a8001db@webgis>

Hi.

 Thank you for your interesting PL/R.

  This can be built on Win32?


> I've been working on a procedural language handler for PostgreSQL, that 
> allows R to be used to write PostgreSQL functions.



From ben at zoo.ufl.edu  Tue Feb 18 16:36:03 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue Feb 18 16:36:03 2003
Subject: [R] glm and overdispersion
In-Reply-To: <3E521341.1F7747B2@cebc.cnrs.fr>
Message-ID: <Pine.LNX.4.44.0302181035590.17335-100000@bolker.zoo.ufl.edu>

  Use family=quasibinomial in your glm() statement.
  R "does what you say rather than doing what you mean": it specifically
says something like "(Dispersion for binomial family taken to be 1)",
which is an indication that R is not using a dispersion factor > 1 in this
case.  (There is a hint of this in the ?anova.glm man page: "For models
with known dispersion (e.g. binomial and Poisson fits) the chi-squared
test is most appropriate, and for those with dispersion estimated by
moments (e.g.  `gaussian', `quasibinomial' and `quasipoisson' fits) the F
test is most appropriate.")

  I brought this up with R-devel -- I think that many people are likely to 
run into this confusion -- but I wasn't sufficiently convincing to get a 
note put into the help page ...

  Ben  


On Tue, 18 Feb 2003, Hardouin Lo?c wrote:

> 
> Hi,
> 
> I am performing glm with binomial family and my data show slight
> overdispersion (HF<1.5). Nevertheless, in order to take into account for
> this heterogeneity though weak, I use F-test rather than Chi-square
> (Krackow & Tkadlec, 2001). But surprisingly, outputs of this two tests
> are exactly similar. What is the reason and how can I scale the output
> by overdispersion ??
> 
> Thank you,
> 
> Alexandre MILLON
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From plummer at iarc.fr  Tue Feb 18 16:40:03 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: Tue Feb 18 16:40:03 2003
Subject: [R] Q: libreadline.so.4.1 problems on Alpha/Linux
In-Reply-To: <0D86E7094B70754C900E4160015800360100DF5E@dmurexch.dmu.dk>
References: <0D86E7094B70754C900E4160015800360100DF5E@dmurexch.dmu.dk>
Message-ID: <1045583320.1049.4.camel@xena>

On Mon, 2003-02-17 at 11:15, mhv at dmu.dk wrote:
> Dear List
> 
> I'm trying to run R on a DIGITAL Alpha / Linux RedHat 7.2
> 
> The .rpm requires libreadlin.so.4.1
> RedHat 7.2 comes with libreadline.so.4.2
> 
> I installed the R-1.6.0-1.aplha.rpm with option --nodeps, since it otherwise
> complained that the required libreadline.so.4.1 was missing.
> This seemed to be the only unsatisfied dependency, at least that was the
> only one mentioned when installing without the --nodeps option.
> 
> I then made a link /usr/lib/libreadline.so.4.1 to point to
> /usr/lib/libreadline.so.4.2 
> 
> So far so good --- I thought...
> 
> I can start R and gets the prompt, but when I writes licence(), help(),
> demo() or any other of the sugested commands I get an error: "Segmentation
> fault" and the progam exits to the shell prompt.
> 
> Any sugestions are welcomed...

You need to install the readline41 package (readline41-4.1-10.ia64.rpm)
which is part of the Red Hat 7.2 distribution and provides the required
library.

Martyn



From tblackw at umich.edu  Tue Feb 18 16:43:45 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue Feb 18 16:43:45 2003
Subject: [R] Help on eqscplot scatterplot
In-Reply-To: <30008.1045579679@www47.gmx.net>
Message-ID: <Pine.SOL.4.44.0302181030460.10612-100000@robotron.gpcc.itd.umich.edu>

H  -

To make a slightly sophisticated plot such as you describe,
most R users would build up the plot from successive calls to
the plotting primitive functions  plot(), points(), lines(), etc.
For a single plot, where you know what the data is, it's routine
to guarantee equal scales by explicitly setting the range covered
by each axis.  Use the arguments xlim= and ylim= in the call to
plot().  You will have to experiment a bit with a ruler to allow
for changes in the aspect ratio by hardcopy printing devices.

Yes, if you want to do something complicated, you do it by trial
and error, adjusting a little bit each time.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



On Tue, 18 Feb 2003 hgoehlmann at gmx.de wrote:

> Hi,
>
> I am using the equal scales scatterplot plot (eqscplot {MASS}), into which I
> plot a few thousand data points. The data points which accumulate towards
> the centrum of the plot are not informative while the data points furthest away
> from the centrum are most informative. I therefore would like to create a
> combined plot which instead of drawing all data points, would only draw the
> less informative data points via a density surface and starting from a defined
> distance from the centrum the actual data points would be plotted.
>
> Has anyone worked with this kind of problem? I have tried combinations of
> filled.contour with plotting individual points, but I really would need to have
> an geometrically equal scales plot. Should I study the lattice graphs?
>
> I would appreciate any comment you can give.
>
> Cheers,
> hinrich   d8-)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tlumley at u.washington.edu  Tue Feb 18 16:49:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Feb 18 16:49:03 2003
Subject: [R] inserting elements in a list
In-Reply-To: <20030218062603.5031F46C22@server2.fastmail.fm>
Message-ID: <Pine.A41.4.44.0302180742000.126612-100000@homer11.u.washington.edu>

On Tue, 18 Feb 2003 j+rhelp at howard.fm wrote:

> On 17 Feb 2003 20:11:11 +0100, "Peter Dalgaard BSA"
> <p.dalgaard at biostat.ku.dk> said:
> > Thomas Lumley <tlumley at u.washington.edu> writes:
> >
> > >   N<-length(a)
> > >   threes<- a==3
> > >   offset<- c(0,cumsum(threes)[-N])
> > >   a[offset+(1:N)]<-a
> > >   a[which(threes)+offset[threes]+1]<-7
> > >
> > > for a more vectorised version.  Equally ugly, but understanding
> > > these two solutions is probably educational.
> > >
> > > Adding elements in the middle is something vectors are not good at, in
> > > contrast to (pair-based or linked) lists.
>
> Indeed they're not - and the code above fails to do this insertion:
>
> > a[which(threes)+offset[threes]+1]<-7
> > a
> [1]  1  2  3  7  6  3 NA  7
>
> The problem is that it is placing the '7's in the correct place, but is
> not shifting the right-hand side of the list across to make room.
>

The code does work, but you have to use all of it, not just that line.
The *previous* line does the shifting.

	-thomas



From mail at joeconway.com  Tue Feb 18 17:29:03 2003
From: mail at joeconway.com (Joe Conway)
Date: Tue Feb 18 17:29:03 2003
Subject: [R] PL/R - R procedural language handler for PostgreSQL
In-Reply-To: <00b101c2d762$b01358e0$7a8001db@webgis>
References: <3E5142AD.1020605@joeconway.com> <00b101c2d762$b01358e0$7a8001db@webgis>
Message-ID: <3E525EA7.7060602@joeconway.com>

Hisaji Ono wrote:
>   This can be built on Win32?
> 

Not presently (well, maybe under cygwin, but I haven't yet tried).

There is a good chance that PostgreSQL will be have a native win32 port 
when version 7.4 comes out. If so, I'll make sure that PL/R will support it.

Joe



From deleeuw at stat.ucla.edu  Tue Feb 18 17:39:03 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Tue Feb 18 17:39:03 2003
Subject: [R] PL/R - R procedural language handler for PostgreSQL
In-Reply-To: <3E525EA7.7060602@joeconway.com>
Message-ID: <5418B84E-435F-11D7-9364-000393BB6D36@stat.ucla.edu>

It builds on OS X, with some tweaks. There seems to be a problem with
7.3.2, though.

On Tuesday, Feb 18, 2003, at 08:26 US/Pacific, Joe Conway wrote:

> Hisaji Ono wrote:
>>   This can be built on Win32?
>
> Not presently (well, maybe under cygwin, but I haven't yet tried).
>
> There is a good chance that PostgreSQL will be have a native win32  
> port when version 7.4 comes out. If so, I'll make sure that PL/R will  
> support it.
>
> Joe
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------



From poizot at cnam.fr  Tue Feb 18 17:52:04 2003
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Tue Feb 18 17:52:04 2003
Subject: [R] Wavelets analysis
Message-ID: <200302181716.50086.poizot@cnam.fr>

Hello,

I would like to compare 2 vectors representing 2 signals.
To do so, I use a wavelet decomposition (wavethresh package).
I then try to find if the such transformed vectors are equivalent or not.
I can do for example a simple a correlation test on wavelets coefficents, but 
it seems to me that in this case, it's no more better than a FFT analysis.
What I wanted to do (and that's my question), is to compare coefficients 
values,
but also compare the relative positions of coefficients on each levels.
Does anybody did such a stuff under R ?

-- 
Cordialy
----------------------------------------
Emmanuel POIZOT
Cnam/Intechmer
Digue de Collignon
50110 Tourlaville
T?l : (33)(0)2 33 88 73 42
Fax : (33)(0)2 33 88 73 39
-----------------------------------------



From ripley at stats.ox.ac.uk  Tue Feb 18 18:00:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb 18 18:00:05 2003
Subject: [R] PL/R - R procedural language handler for PostgreSQL
In-Reply-To: <3E525EA7.7060602@joeconway.com>
Message-ID: <Pine.LNX.4.44.0302181653450.1549-100000@gannet.stats>

On Tue, 18 Feb 2003, Joe Conway wrote:

> Hisaji Ono wrote:
> >   This can be built on Win32?
> > 
> 
> Not presently (well, maybe under cygwin, but I haven't yet tried).
> 
> There is a good chance that PostgreSQL will be have a native win32 port 
> when version 7.4 comes out. If so, I'll make sure that PL/R will support it.

But R does not build under Cygwin (last time I looked and I would be
surprised if it would without a lot of tinkering), and the Windows port of
R does not have libR.so but a different (and much older) mechanism using
R.dll.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From brahm at alum.mit.edu  Tue Feb 18 18:11:06 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Tue Feb 18 18:11:06 2003
Subject: [R] download CRAN packages and proxy config.
Message-ID: <15954.26846.880908.727326@gargle.gargle.HOWL>

Joao Pedro W. de Azevedo <jazevedo at provide.com.br> wrote:
> install.packages("quantreg")
> To my surprise this command did not work...
> Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/")...

It took me years to figure out how to get through our firewall, from my
Solaris 2.6 machine (now) running R-1.6.2.  There were 3 crucial steps:

1) In my .Rprofile:  options(download.file.method="wget")
   (The default method "internal" does not seem to work for me.)

2) In my .cshrc:     setenv http_proxy <some.proxy.server>:8000

3) <some.proxy.server> is NOT the name I find in my web browser!  The web
   browser knows the machine that serves "Proxy Auto-Configuration" files, but
   I needed to get the name of an actual proxy server from our local guru.

Hope that helps!
-- 
                              -- David Brahm (brahm at alum.mit.edu)



From rossini at blindglobe.net  Tue Feb 18 18:39:03 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue Feb 18 18:39:03 2003
Subject: [R] PL/R - R procedural language handler for PostgreSQL
In-Reply-To: <Pine.LNX.4.44.0302181653450.1549-100000@gannet.stats> (ripley@stats.ox.ac.uk's
 message of "Tue, 18 Feb 2003 16:57:59 +0000 (GMT)")
References: <Pine.LNX.4.44.0302181653450.1549-100000@gannet.stats>
Message-ID: <87bs19jytm.fsf@jeeves.blindglobe.net>

ripley at stats.ox.ac.uk writes:

> But R does not build under Cygwin (last time I looked and I would be
> surprised if it would without a lot of tinkering), and the Windows port of
> R does not have libR.so but a different (and much older) mechanism using
> R.dll.

I spent a bit of time on this yesterday -- Brian is correct as always;
I've done a "little" tinkering, and seem to be about 1/3 of the way
there to successfully compiling; currently I'm fixing a failure in
R.bin, but there is a nasty hack that I did, that I'm not showing
anyone, to get it that far.  Don't assume that I'll finish -- vacation
is over for me.

It seems to be (Cygwin / R) a truly weird setup, at least as far as R
is concerned.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From rossini at blindglobe.net  Tue Feb 18 18:43:04 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue Feb 18 18:43:04 2003
Subject: Cygwin and R (was: Re: [R] PL/R - R procedural language handler for
 PostgreSQL)
In-Reply-To: <Pine.LNX.4.44.0302181653450.1549-100000@gannet.stats> (ripley@stats.ox.ac.uk's
 message of "Tue, 18 Feb 2003 16:57:59 +0000 (GMT)")
References: <Pine.LNX.4.44.0302181653450.1549-100000@gannet.stats>
Message-ID: <87adgtjyt8.fsf@jeeves.blindglobe.net>

ripley at stats.ox.ac.uk writes:

> But R does not build under Cygwin (last time I looked and I would be
> surprised if it would without a lot of tinkering), and the Windows port of
> R does not have libR.so but a different (and much older) mechanism using
> R.dll.

I spent a bit of time on this yesterday -- Brian is correct as always;
I've done a "little" tinkering, and seem to be about 1/3 of the way
there to successfully compiling; currently I'm fixing a failure in
R.bin, but there is a nasty hack that I did, that I'm not showing
anyone, to get it that far.  Don't assume that I'll finish -- vacation
is over for me.

It seems to be (Cygwin / R) a truly weird setup, at least as far as R
is concerned.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From rociobarroso at prodigy.net.mx  Tue Feb 18 18:54:03 2003
From: rociobarroso at prodigy.net.mx (rociobarroso@prodigy.net.mx)
Date: Tue Feb 18 18:54:03 2003
Subject: [R] R interface to Qt-Embedded?
Message-ID: <0HAI00JATMZ3QY@SMTP.Prodigy.Net.mx>

Is there an R interface to Qt-Embedded? That is, Qt running on Linux under
a virtual console using not X, but framebuffers?
Thanks.
Hugo



From rengelho at ix.urz.uni-heidelberg.de  Tue Feb 18 20:00:04 2003
From: rengelho at ix.urz.uni-heidelberg.de (Ralf Engelhorn)
Date: Tue Feb 18 20:00:04 2003
Subject: [R] How to solve A'A=S for A
In-Reply-To: <Pine.GSO.4.44.0302141728110.18406-100000@auk.stats>
Message-ID: <Pine.A41.4.42.0302181949210.31954-100000@aixterm4.urz.uni-heidelberg.de>

Dear R-helpers,
thank you very much for your immediate and numerous reactions
(also via E-mail).
I see that the problem I encountered lies in the field of
matrix algebra and not R. Beeing a biologist, I think I should
direct further questions to a local statistician.

To give you some feedback on your engagement, I'd like to report,
what I was struggling with: Following a numerical example
from Burnaby 1966 (Growth-invariant discriminant functions and
generalized distances. Biometrics 22:96-110) one of the first
steps is to solve R'R=W^{-1} for R (where all matrices have p x p
order and W^{-1} is the inverse of the within-group covariance
matrix).

When I tried

W <- matrix(c(1,0,2,0,4,2,2,2,6),3,3)
W.inv <- solve(W)
A.chol <- chol(W.inv);A.chol
         [,1]      [,2]       [,3]
[1,] 2.236068 0.4472136 -0.8944272
[2,] 0.000000 0.5477226 -0.1825742
[3,] 0.000000 0.0000000  0.4082483

I received a matrix A.chol which was different from R given
in Burnaby's example

R <- matrix(c(1,0,-2,0,0.5,-0.5,0,0,1),3,3);R
     [,1] [,2] [,3]
[1,]    1  0.0    0
[2,]    0  0.5    0
[3,]   -2 -0.5    1

The guidance the author provides for finding R is:
"The matrix R may be computed during the process of inverting W (it is not
really necessary to complete the inversion)."
The only way that I know to compute the inverse of a matrix is via the
matrix of cofactors (Searle 1982). But this matrix
did not resemble the R that I was looking for.

The symmetric solution (A=A'=KD^{1/2}K', where K has eigenvectors and D
has eigenvalues) suggested by Jan de Leeuw yields results (discriminant
function coefficients, D^2) as expected, though a matrix calculated in an
intermediate step differs from its counterpart in the example.

To me it looks like having to get deeper into matrix algebra to solve
this.



From ripley at stats.ox.ac.uk  Tue Feb 18 20:21:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb 18 20:21:02 2003
Subject: [R] How to solve A'A=S for A
In-Reply-To: <Pine.A41.4.42.0302181949210.31954-100000@aixterm4.urz.uni-heidelberg.de>
Message-ID: <Pine.LNX.4.44.0302181910540.2854-100000@gannet.stats>

It's usual to use R for an upper-triangular matrix, not a lower-triangular 
one. (As in the QR decomposition.)

If U'U = W then Winv = Uinv Uinv' and so you can take R = t(Uinv), that is
> t(solve(chol(W)))
     [,1] [,2] [,3]
[1,]    1  0.0    0
[2,]    0  0.5    0
[3,]   -2 -0.5    1

Now, you can do that a bit more efficiently by

t(backsolve(chol(W), diag(ncol(W))))

since triangular matrices are relatively simple to invert.  But R is not 
going to notice unless W is enormous.


On Tue, 18 Feb 2003, Ralf Engelhorn wrote:

> Dear R-helpers,
> thank you very much for your immediate and numerous reactions
> (also via E-mail).
> I see that the problem I encountered lies in the field of
> matrix algebra and not R. Beeing a biologist, I think I should
> direct further questions to a local statistician.
> 
> To give you some feedback on your engagement, I'd like to report,
> what I was struggling with: Following a numerical example
> from Burnaby 1966 (Growth-invariant discriminant functions and
> generalized distances. Biometrics 22:96-110) one of the first
> steps is to solve R'R=W^{-1} for R (where all matrices have p x p
> order and W^{-1} is the inverse of the within-group covariance
> matrix).
> 
> When I tried
> 
> W <- matrix(c(1,0,2,0,4,2,2,2,6),3,3)
> W.inv <- solve(W)
> A.chol <- chol(W.inv);A.chol
>          [,1]      [,2]       [,3]
> [1,] 2.236068 0.4472136 -0.8944272
> [2,] 0.000000 0.5477226 -0.1825742
> [3,] 0.000000 0.0000000  0.4082483
> 
> I received a matrix A.chol which was different from R given
> in Burnaby's example
> 
> R <- matrix(c(1,0,-2,0,0.5,-0.5,0,0,1),3,3);R
>      [,1] [,2] [,3]
> [1,]    1  0.0    0
> [2,]    0  0.5    0
> [3,]   -2 -0.5    1
> 
> The guidance the author provides for finding R is:
> "The matrix R may be computed during the process of inverting W (it is not
> really necessary to complete the inversion)."
> The only way that I know to compute the inverse of a matrix is via the
> matrix of cofactors (Searle 1982). But this matrix
> did not resemble the R that I was looking for.
> 
> The symmetric solution (A=A'=KD^{1/2}K', where K has eigenvectors and D
> has eigenvalues) suggested by Jan de Leeuw yields results (discriminant
> function coefficients, D^2) as expected, though a matrix calculated in an
> intermediate step differs from its counterpart in the example.
> 
> To me it looks like having to get deeper into matrix algebra to solve
> this.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Tue Feb 18 20:25:04 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue Feb 18 20:25:04 2003
Subject: [R] How to solve A'A=S for A
In-Reply-To: <Pine.A41.4.42.0302181949210.31954-100000@aixterm4.urz.uni-heidelberg.de>
References: <Pine.A41.4.42.0302181949210.31954-100000@aixterm4.urz.uni-heidelberg.de>
Message-ID: <6r1y25o0k2.fsf@bates4.stat.wisc.edu>

Ralf Engelhorn <rengelho at ix.urz.uni-heidelberg.de> writes:

> Dear R-helpers,
> thank you very much for your immediate and numerous reactions
> (also via E-mail).
> I see that the problem I encountered lies in the field of
> matrix algebra and not R. Beeing a biologist, I think I should
> direct further questions to a local statistician.
> 
> To give you some feedback on your engagement, I'd like to report,
> what I was struggling with: Following a numerical example
> from Burnaby 1966 (Growth-invariant discriminant functions and
> generalized distances. Biometrics 22:96-110) one of the first
> steps is to solve R'R=W^{-1} for R (where all matrices have p x p
> order and W^{-1} is the inverse of the within-group covariance
> matrix).
> 
> When I tried
> 
> W <- matrix(c(1,0,2,0,4,2,2,2,6),3,3)
> W.inv <- solve(W)
> A.chol <- chol(W.inv);A.chol
>          [,1]      [,2]       [,3]
> [1,] 2.236068 0.4472136 -0.8944272
> [2,] 0.000000 0.5477226 -0.1825742
> [3,] 0.000000 0.0000000  0.4082483
> 
> I received a matrix A.chol which was different from R given
> in Burnaby's example
> 
> R <- matrix(c(1,0,-2,0,0.5,-0.5,0,0,1),3,3);R
>      [,1] [,2] [,3]
> [1,]    1  0.0    0
> [2,]    0  0.5    0
> [3,]   -2 -0.5    1
> 
> The guidance the author provides for finding R is:
> "The matrix R may be computed during the process of inverting W (it is not
> really necessary to complete the inversion)."
> The only way that I know to compute the inverse of a matrix is via the
> matrix of cofactors (Searle 1982). But this matrix
> did not resemble the R that I was looking for.

The author is referring to the fact that you can determine the inverse
of a positive-definite, symmetric matrix by computing its Cholesky
decomposition W = R'R and inverting only the triangular matrix R.
This is because W^{-1} = R^{-1} R^{-1}' so a lower triangular factor
for W^{-1}, in the sense of L where W^{-1}=L'L, is R^{-1}'.  You can
reproduce this in R as

> W <- matrix(c(1,0,2,0,4,2,2,2,6),3,3)
> R = La.chol(W)
> R
     [,1] [,2] [,3]
[1,]    1    0    2
[2,]    0    2    1
[3,]    0    0    1
> L = t(solve(R))
> t(L) %*% L
     [,1] [,2] [,3]
[1,]    5  1.0 -2.0
[2,]    1  0.5 -0.5
[3,]   -2 -0.5  1.0
> crossprod(L)    # same as above
     [,1] [,2] [,3]
[1,]    5  1.0 -2.0
[2,]    1  0.5 -0.5
[3,]   -2 -0.5  1.0
> round(W %*% crossprod(L), 6) # shows t(L) %*% L is W^{-1}
     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    0    1    0
[3,]    0    0    1

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From spencer.graves at pdf.com  Tue Feb 18 20:29:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue Feb 18 20:29:03 2003
Subject: [R] How to solve A'A=S for A
References: <Pine.A41.4.42.0302181949210.31954-100000@aixterm4.urz.uni-heidelberg.de>
Message-ID: <3E528944.6040808@pdf.com>

There are two square roots for any real number.  With matrices, there 
are infinite.  There are several standard "square root" matrices, one of 
which is the Cholesky decomposition.  I just did "R <- solve(chol(W))", 
and got the transpose of the matrix you reported from Burnaby (1966). 
Since the Cholesky decomposition is not symmetric, it is essentially as 
correct to specify either R or its transpose.

I think it's interesting that solve(chol(W)) is not the same as 
chol(solve(W)), but I'll let someone else comment on that.

Spencer Graves


Ralf Engelhorn wrote:
> Dear R-helpers,
> thank you very much for your immediate and numerous reactions
> (also via E-mail).
> I see that the problem I encountered lies in the field of
> matrix algebra and not R. Beeing a biologist, I think I should
> direct further questions to a local statistician.
> 
> To give you some feedback on your engagement, I'd like to report,
> what I was struggling with: Following a numerical example
> from Burnaby 1966 (Growth-invariant discriminant functions and
> generalized distances. Biometrics 22:96-110) one of the first
> steps is to solve R'R=W^{-1} for R (where all matrices have p x p
> order and W^{-1} is the inverse of the within-group covariance
> matrix).
> 
> When I tried
> 
> W <- matrix(c(1,0,2,0,4,2,2,2,6),3,3)
> W.inv <- solve(W)
> A.chol <- chol(W.inv);A.chol
>          [,1]      [,2]       [,3]
> [1,] 2.236068 0.4472136 -0.8944272
> [2,] 0.000000 0.5477226 -0.1825742
> [3,] 0.000000 0.0000000  0.4082483
> 
> I received a matrix A.chol which was different from R given
> in Burnaby's example
> 
> R <- matrix(c(1,0,-2,0,0.5,-0.5,0,0,1),3,3);R
>      [,1] [,2] [,3]
> [1,]    1  0.0    0
> [2,]    0  0.5    0
> [3,]   -2 -0.5    1
> 
> The guidance the author provides for finding R is:
> "The matrix R may be computed during the process of inverting W (it is not
> really necessary to complete the inversion)."
> The only way that I know to compute the inverse of a matrix is via the
> matrix of cofactors (Searle 1982). But this matrix
> did not resemble the R that I was looking for.
> 
> The symmetric solution (A=A'=KD^{1/2}K', where K has eigenvectors and D
> has eigenvalues) suggested by Jan de Leeuw yields results (discriminant
> function coefficients, D^2) as expected, though a matrix calculated in an
> intermediate step differs from its counterpart in the example.
> 
> To me it looks like having to get deeper into matrix algebra to solve
> this.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Huiqin.Yang at noaa.gov  Tue Feb 18 20:59:03 2003
From: Huiqin.Yang at noaa.gov (Huiqin Yang)
Date: Tue Feb 18 20:59:03 2003
Subject: [R] functions different in R and S
Message-ID: <3E528F7A.BDF18373@noaa.gov>

Hello everyone,

  We have encountered the problem of functions that appear different in
R and S.  For example, ! in S becomes system() in R.  We also have
found that new() in S does not exist in R, unless it has a different
name.  I wonder whether there is any resource that can point to useful substitutes for S functions that are not recognized by R.  At the same time whether there is a list
of functions, which appear in both R and S but which don't do exactly the same thing.

  Many thanks.

Helen Yang



From ypeng at math.mun.ca  Tue Feb 18 21:20:03 2003
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Tue Feb 18 21:20:03 2003
Subject: [R] Combining shared libraries (*.so files) directly?
Message-ID: <3E5295A5.13561CC8@math.mun.ca>

This is an off topic.

Is it possible to combine a few shared library files (.so files)
without changing source files of the libraries?

I am not sure whether it makes sense or not. I have a few shared
libraries and mainly use them separately. But sometimes, for the
purpose of easy transportation and loading, I would like to combine
them together to form a single big .so file. I could do this
by combining all relevant source files together and rebuild it.
But I wonder whether it is possible to directly combine the .so
files. Comments or hints are welcome. The shared libraries are built
in a Linux system and used with S+6 and R.

Thanks.
Paul.



From j+rhelp at howard.fm  Tue Feb 18 21:36:03 2003
From: j+rhelp at howard.fm (j+rhelp@howard.fm)
Date: Tue Feb 18 21:36:03 2003
Subject: [R] inserting elements in a list
In-Reply-To: <Pine.A41.4.44.0302180742000.126612-100000@homer11.u.washington.edu>
References: <Pine.A41.4.44.0302180742000.126612-100000@homer11.u.washington.edu>
Message-ID: <20030218203536.69C5142D4A@server2.fastmail.fm>

On Tue, 18 Feb 2003 07:47:56 -0800 (PST), "Thomas Lumley"
<tlumley at u.washington.edu> said:
> history()
> a<-c(1,2,3,5,6,3)
> N<-length(a)
> threes<- a==3
> offset<- c(0,cumsum(threes)[-N])
> a[offset+(1:N)]<-a
> a[which(threes)+offset[threes]+1]<-7

> On Tue, 18 Feb 2003 j+rhelp at howard.fm wrote:
<...>
> > The problem is that it is placing the '7's in the correct place, but is
> > not shifting the right-hand side of the list across to make room.
> 
> The code does work, but you have to use all of it, not just that line.
> The *previous* line does the shifting.

D'oh! Of course!

Now that *is* a clever solution. :-)
-- 
  Jeremy Howard
  jhoward at fastmail.fm



From ripley at stats.ox.ac.uk  Tue Feb 18 21:48:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb 18 21:48:02 2003
Subject: [R] functions different in R and S
In-Reply-To: <3E528F7A.BDF18373@noaa.gov>
Message-ID: <Pine.LNX.4.44.0302182039520.3042-100000@gannet.stats>

new() *is* in R, in package methods. Which is where you would expect, as 
it creates a new instance of a formal class.  It is not in many other
implementations of S, however.

Most of the time in S, ! means `not', the same as in R, and system() 
exists in S (but not in all version of S-PLUS).

There is a partial list in the R FAQ, but I suspect no one knows all the
differences, and those who know most have probably forgotten a few. You
also have to be very careful what you mean by `S': very few of us have
seen vanilla S, and S-PLUS 6.x is not S, nor is S-PLUS 3.4, nor is S-PLUS
2000 ... and the differences between them are about as large as between
their medoid and R.

There are major differences not in the functions, e.g. scoping rules, 
interpretation of formulae: see the R FAQ.

On Tue, 18 Feb 2003, Huiqin Yang wrote:

>   We have encountered the problem of functions that appear different in
> R and S.  For example, ! in S becomes system() in R.  We also have
> found that new() in S does not exist in R, unless it has a different
> name.  I wonder whether there is any resource that can point to useful substitutes for S functions that are not recognized by R.  At the same time whether there is a list
> of functions, which appear in both R and S but which don't do exactly the same thing.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From websterwest at yahoo.com  Tue Feb 18 23:05:03 2003
From: websterwest at yahoo.com (Webster West)
Date: Tue Feb 18 23:05:03 2003
Subject: [R] Solaris 8
Message-ID: <20030218220354.47509.qmail@web13405.mail.yahoo.com>

Has anyone been able to install R 1.6.2 under Solaris
8?

WW



From Benjamin.STABLER at odot.state.or.us  Tue Feb 18 23:13:03 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Tue Feb 18 23:13:03 2003
Subject: [R] ESRI shape file import and time-space models
Message-ID: <76A000A82289D411952F001083F9DD06039ACA6B@exsalem4-bu.odot.state.or.us>

Thanks to R. Herold for the suggested change from readBin to readChar for
the field type in the field header descriptions.  The code below is the
revised read.dbf function.  Fan's odbc.dbase function is much faster than my
read.dbf() function, and it is defintely better for large files.  Thanks
also to Fan for the comments.  Finally, I am working on putting together a
package to read and write shapefiles.  

Regards,
Benjamin Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
555 13th Street NE, Suite 2
Salem, OR 97301  Ph: 503-986-4104

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~
#Read DBF format
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~

read.dbf <- function(dbf.name) {
	
	infile<-file(dbf.name,"rb")
	
	#Header
	file.version <- readBin(infile,integer(), 1, size=1,
endian="little")
	file.year <- readBin(infile,integer(), 1, size=1, endian="little")
	file.month <- readBin(infile,integer(), 1, size=1, endian="little")
	file.day <- readBin(infile,integer(), 1, size=1, endian="little")
	num.records <- readBin(infile,integer(), 1, size=4, endian="little")
	header.length <- readBin(infile,integer(), 1, size=2,
endian="little")
	record.length <- readBin(infile,integer(), 1, size=2,
endian="little")
	file.temp <- readBin(infile,integer(), 20, size=1, endian="little")
	header <- list(file.version,file.year, file.month, file.day,
num.records, header.length, record.length)
	names(header) <-
c("file.version","file.year","file.month","file.day","num.records","header.l
ength","record.length")
	rm(file.version,file.year, file.month, file.day, num.records,
header.length, record.length)
		
	#Calculate the number of fields
	num.fields <- (header$header.length-32-1)/32
	field.name <- NULL
	field.type <- NULL
	field.length <- NULL
	
	#Field Descriptions (32 bytes each)
	for (i in 1:num.fields) {
		field.name.test <- readBin(infile,character(), 1, size=10,
endian="little")
		field.name <- c(field.name,field.name.test)
		if (nchar(field.name.test)!=10) {
			file.temp <- readBin(infile,integer(),
10-(nchar(field.name.test)), 1, endian="little")
		}	
		field.type <- c(field.type,readChar(infile, 1))
		file.temp <- readBin(infile,integer(), 4, 1,
endian="little")
		field.length <- c(field.length,readBin(infile,integer(), 1,
1, endian="little"))
		file.temp <- readBin(infile,integer(), 15, 1,
endian="little")
	}
	
	#Create a table of the field info
	fields <-
data.frame(NAME=field.name,TYPE=field.type,LENGTH=field.length)
	#Set all fields with length<0 equal to correct number of characters
	fields$LENGTH[fields$LENGTH<0]<-(256+fields$LENGTH[fields$LENGTH<0])
	#Read in end of attribute descriptions terminator - should be
integer value 13
	file.temp <- readBin(infile,integer(), 1, 1, endian="little")
	#Increase the length of field 1 by one to account for the space at
the beginning of each record	
	fields$LENGTH[1]<-fields$LENGTH[1]+1
	#Add fields to the header list
	header <- c(header,fields=NULL)
	header$fields <- fields
	
	#Read in all the records data and the end of file value - should be
value 26
	all.records <- readBin(infile, integer(),
header$num.records*header$record.length, size=1, endian="little")
	file.temp <- readBin(infile,integer(), 1, 1, endian="little")
	close(infile)
	
	#Compress the binary values using run length encoding
	all.records <- rle(all.records)
	#Swap ASCII decimal codes for ASCII character codes
	ascii <-
c(32,46,48,49,50,51,52,53,54,55,56,57,65,66,67,68,69,70,71,72,73,74,75,76,77
,78,79,80,81,82,83,84,85,86,87,88,89,90,97,98,99,100,101,102,103,104,105,106
,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,33,35,36,37
,38,39,40,41,42,43,44,45,47,58,59,60,61,62,63,64,91,92,93,94,95,123,124,125,
126)
	ascii.values <- c("
",".","0","1","2","3","4","5","6","7","8","9","A","B","C","D","E","F","G","H
","I","J","K","L","M","N","O","P","Q","R","S","T","U","V","W","X","Y","Z","a
","b","c","d","e","f","g","h","i","j","k","l","m","n","o","p","q","r","s","t
","u","v","w","x","y","z","!","#","$","%","&","'","(",")","*","+","\,","-","
/",":",";","<","=",">","?","@","["," ","]","^","_","{","|","}","~")
	all.records$values <-
ascii.values[match(as.character(all.records$values),as.character(ascii),
nomatch=1)]
	all.records <- inverse.rle(all.records)
	
	#Create a matrix of the ASCII data by record
	base.data <-
t(matrix(all.records,header$record.length,header$num.records))
	rm(all.records)
	
	#Function to collapse the ASCII codes, string split them and replace
" " with ""
	format.record <- function(record) {
		record <- paste(record,collapse="")
		record <- substring(record,
c(1,cumsum(fields$LENGTH)[1:length(cumsum(fields$LENGTH))-1]+1),cumsum(field
s$LENGTH))
		record <- gsub(" + ","", record)
		record
	}
	#Format the base.data ASCII record stream
	dbf <- as.data.frame(t(apply(base.data,1,format.record)))
	#Set the numeric fields to numeric
	for (i in 1:ncol(dbf)) {
		if(fields$TYPE[i]=="C") { dbf[[i]] <- as.character(dbf[[i]])
}
		if(fields$TYPE[i]=="N") { dbf[[i]] <-
as.numeric(as.character(dbf[[i]])) }
		if(fields$TYPE[i]=="F") { dbf[[i]] <-
as.numeric(as.character(dbf[[i]])) 
			warning("Possible trouble converting numeric field
in the DBF\n")
		}
	}
	colnames(dbf) <- as.character(fields$NAME)
	list(dbf=dbf, header=header)
}

>-----Original Message-----
>From: R. Herold [mailto:ralf.herold at charite.de]
>Sent: Sunday, February 16, 2003 8:49 AM
>To: r-help at stat.math.ethz.ch
>Cc: STABLER Benjamin
>Subject: Re: Re: [R] ESRI shape file import and time-space models
>
>
>Thanks for providing your functions, especially those for 
>reading and writing dBase files (read.dbf and write.dbf), 
>which presumably are of general interest because there is 
>no other implementation for reading and writing these 
>formats (apart from ODBC), as far as I know. 
>
>However, I suggest changing one byte character readBin to 
>readChar as the latter does not expect zero-terminated
>strings which were not present in my dBase-III-files' headers.
>One such header entry for example was (hex): 
>
>4B 4C 49 4e 00 00 00 00 00 00 00 43 2B 00 00 00
>02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 
>
>(field "KLIN", type "C" [note "43" followed by "2B", 
> not "00"], width/length 2, padded to size 32)
>
>## ---------------------------------------------------
>## From read.dbf: 
>## Field Descriptions (32 bytes each)
>for (i in 1:num.fields) {
>  field.name.test <- readBin (infile, character(), 1, size=10,
>endian="little")
>  field.name      <- c (field.name, field.name.test)
>  if (nchar (field.name.test)!=10) {
>    file.temp <- readBin (infile,integer(), 10 - (nchar
>(field.name.test)), 1, endian="little")
>  }
>  ## RH 2003-02-16: replaced readBin by readChar in next line 
>  field.type   <- c (field.type, readChar (infile, 1))  
>  ## RH 2003-02-16: incremented by 1 to 4 items in next line 
>  ## to compensate for above change 
>  file.temp    <- readBin (infile, integer(),  4, 1, endian="little")  
>  field.length <- c (field.length, readBin (infile, integer(), 1, 1,
>endian="little")) 
>  file.temp    <- readBin (infile, integer(), 15, 1, endian="little")
>}
>## ---------------------------------------------------
>
>An enhancement might be to also set the appropriate type for 
>date fields, maybe like this (although I don't know internals
>of dBase date and time storage variants): 
>
>## ---------------------------------------------------
>## From read.dbf: 
>## Set the numeric fields to numeric
>for (i in 1:ncol(dbf)) {
>  ## RH 2003-02-16: added next line for date type setting 
>  if(fields$TYPE[i]=="D") {dbf[,i] <- strptime (as.character (dbf[,i]),
>format="%Y%m%d")}
>  if(fields$TYPE[i]=="C") {dbf[,i] <- as.character (dbf[,i])}
>  if(fields$TYPE[i]=="N") {dbf[,i] <- as.numeric (as.character
>(dbf[,i]))}
>  if(fields$TYPE[i]=="F") {dbf[,i] <- as.numeric (as.character
>(dbf[,i]))
>                           warning("Possible trouble converting numeric
>field in the DBF\n") 
>                          } 
>} 
>## ---------------------------------------------------
>
>Thanks and greetings - Ralf Herold 
>
>-- Dr. med. Ralf Herold  
>| Koordinationszentrale Kompetenznetz
>| P?diatrische Onkologie und H?matologie  
>| http://www.kinderkrebsinfo.de/   
>| Charit? Campus Virchow-Klinikum  
>| Medizinische Fakult?t Humboldt-Universit?t  
>| D-13353 Berlin, Augustenburger Platz 1  
>| Raum 4.3425 4. Etage Mittelallee 8  
>| Tel. +49 (30) 450-566834 Fax -566906  
>| mailto:ralf.herold at charite.de  
>
>> ----- Original Message ----- 
>> From: Benjamin.STABLER at odot.state.or.us
>> To: Ekkehardt.Altpeter at bag.admin.ch
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] ESRI shape file import and time-space models
>> Date: Fri, 14 Feb 2003 08:29:12 -0800
>[...]
>> Attached are some functions that I wrote to read and write 
>> shapefiles and
>> dbfs easily from within R.  You do not need any additional 
>> libraries or C
>> code.  I am still working out a few bugs but I have tested it 
>[...]
>> Benjamin Stabler
>> Transportation Planning Analysis Unit
>> Oregon Department of Transportation
>> 555 13th Street NE, Suite 2
>> Salem, OR 97301  Ph: 503-986-4104
>[...]
>



From jgramlich at piocon.com  Tue Feb 18 23:27:02 2003
From: jgramlich at piocon.com (Joshua Gramlich)
Date: Tue Feb 18 23:27:02 2003
Subject: [R] Graphing Tools?
Message-ID: <1045607229.1670.96.camel@localhost.localdomain>

I am looking for graphing alternatives to those of R.  I need to
generate graphs based upon survey data, and R is good at that, but it
cannot generate the 3D graphs I'm looking for.

The 3D graphs I'm looking for aren't anything terribly complicated or
fancy, just the same type of pie-chart/bar-chart stuff you'll find in
OpenOffice (what I'm using now) and MS Excel.

Does anyone have any suggestions or know of a tool that does attractive,
3D, data generated graphs?


Joshua Gramlich
Piocon Technologies
Chicago, Illinois USA



From p.dalgaard at biostat.ku.dk  Tue Feb 18 23:52:10 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Feb 18 23:52:10 2003
Subject: [R] How to solve A'A=S for A
In-Reply-To: <3E528944.6040808@pdf.com>
References: <Pine.A41.4.42.0302181949210.31954-100000@aixterm4.urz.uni-heidelberg.de>
	<3E528944.6040808@pdf.com>
Message-ID: <x2bs199p55.fsf@biostat.ku.dk>

Spencer Graves <spencer.graves at pdf.com> writes:

> I think it's interesting that solve(chol(W)) is not the same as
> chol(solve(W)), but I'll let someone else comment on that.

That's basically because inv(R'R) = inv(R)inv(R') = inv(R)inv(R)'
Notice that the last form is upper tri by lower tri, whereas the
Choleski factorization is the other way around. Actually, this UU'
factorization works just like the Choleski factorization taking the
rows and columns of W in the reverse order so we have

> solve(chol(W))
     [,1] [,2] [,3]
[1,]    1  0.0 -2.0
[2,]    0  0.5 -0.5
[3,]    0  0.0  1.0

> zapsmall(chol(solve(W)[3:1,3:1]))[3:1,3:1]
     [,1] [,2] [,3]
[1,]    1  0.0    0
[2,]    0  0.5    0
[3,]   -2 -0.5    1

which are each others transposes.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Andrew.Swan at csiro.au  Tue Feb 18 23:57:03 2003
From: Andrew.Swan at csiro.au (Andrew.Swan@csiro.au)
Date: Tue Feb 18 23:57:03 2003
Subject: [R] power.t.test function
Message-ID: <183F031D4C18264AA6C1B637B3CD3F31BCD0A5@exchange-ar.li.csiro.au>

Hi - Is it possible to use the power.t.test function in a scenario where the
number of observations in each group is different?

Thanks
--
Andrew Swan
CSIRO Livestock Industries
Armidale 2350 Australia
ph. 02 6776 1377
fax. 02 6776 1408
email: andrew.swan at csiro.au



From Guangchun.Song at stjude.org  Wed Feb 19 00:05:04 2003
From: Guangchun.Song at stjude.org (Song, Guangchun)
Date: Wed Feb 19 00:05:04 2003
Subject: [R] How to use Cox PH model to select genes from DNA gene expression
 profiles?
Message-ID: <A1DAD6685C12D511B20F0003472515138E68F4@sjmemexc3.stjude.org>

I'm doing prediction of the survival cases using gene expression
profiles(Affymetrix chips).  Can somebody tell me how to use the Cox PH
model to select genes and make a prediction of survival?


Thanks.

Guangchun



From spencer.graves at pdf.com  Wed Feb 19 00:10:07 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed Feb 19 00:10:07 2003
Subject: [R] How to solve A'A=S for A
References: <Pine.A41.4.42.0302181949210.31954-100000@aixterm4.urz.uni-heidelberg.de>	<3E528944.6040808@pdf.com> <x2bs199p55.fsf@biostat.ku.dk>
Message-ID: <3E52BC01.9090703@pdf.com>

Of course.  Thanks helping me understand something that should have been 
obvious to me but wasn't.

Spencer Graves

Peter Dalgaard BSA wrote:
> Spencer Graves <spencer.graves at pdf.com> writes:
> 
> 
>>I think it's interesting that solve(chol(W)) is not the same as
>>chol(solve(W)), but I'll let someone else comment on that.
> 
> 
> That's basically because inv(R'R) = inv(R)inv(R') = inv(R)inv(R)'
> Notice that the last form is upper tri by lower tri, whereas the
> Choleski factorization is the other way around. Actually, this UU'
> factorization works just like the Choleski factorization taking the
> rows and columns of W in the reverse order so we have
> 
> 
>>solve(chol(W))
> 
>      [,1] [,2] [,3]
> [1,]    1  0.0 -2.0
> [2,]    0  0.5 -0.5
> [3,]    0  0.0  1.0
> 
> 
>>zapsmall(chol(solve(W)[3:1,3:1]))[3:1,3:1]
> 
>      [,1] [,2] [,3]
> [1,]    1  0.0    0
> [2,]    0  0.5    0
> [3,]   -2 -0.5    1
> 
> which are each others transposes.
>



From p.dalgaard at biostat.ku.dk  Wed Feb 19 00:21:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Feb 19 00:21:02 2003
Subject: [R] power.t.test function
In-Reply-To: <183F031D4C18264AA6C1B637B3CD3F31BCD0A5@exchange-ar.li.csiro.au>
References: <183F031D4C18264AA6C1B637B3CD3F31BCD0A5@exchange-ar.li.csiro.au>
Message-ID: <x23cml9nta.fsf@biostat.ku.dk>

Andrew.Swan at csiro.au writes:

> Hi - Is it possible to use the power.t.test function in a scenario where the
> number of observations in each group is different?

No. It's not rocket science to modify the p.body expression, though.
The tricky bit is what to do instead of "solve for n".

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From vograno at arbitrade.com  Wed Feb 19 00:35:44 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Wed Feb 19 00:35:44 2003
Subject: [R] fitting a curve according to a custom loss function
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DCFC@jupiter.arbitrade.com>

Dear R-Users,

I need to find a smooth function f() and coefficients a_i that give the best
fit to

y ~ a_0 + a_1*f(x_1) + a_2*f(x_2)

Note that it is the same non-linear transformation f() that is applied to
both x_1 and x_2.

So my first question is how can I do it in R?

A more general question is this: suppose I have a utility function U(a_i,
f()), where f() is say a spline. Is there a general optimizer that could
find an extremum of such U()? If not, how easy it would be to hack up
something like this? Would it become easier if U() depended on f() only,
i.e. no a_i terms?

Thanks, Vadim

-------------------------------------------------- 
DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]



From jerome at hivnet.ubc.ca  Wed Feb 19 00:40:05 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed Feb 19 00:40:05 2003
Subject: [R] How to use Cox PH model to select genes from DNA gene expression profiles?
In-Reply-To: <A1DAD6685C12D511B20F0003472515138E68F4@sjmemexc3.stjude.org>
References: <A1DAD6685C12D511B20F0003472515138E68F4@sjmemexc3.stjude.org>
Message-ID: <200302182340.PAA12700@hivnet.ubc.ca>

See the "newdata" argument in ?survfit.

You can use it like this:
cox.surv <- survfit(cox.fit,newdata=selected.genes)
Indeed, you're going to have to build the data frame of your selected genes.

Then see ?plot.survfit for additional plotting options. That'll help you to 
build a "plot(cox.surv,--other arguments--)" command to draw nice survival 
curves.

Hope this helps.

Jerome

On Tuesday 18 February 2003 15:04, Song, Guangchun wrote:
> Content-Length: 355
> Status: R
> X-Status: N
>
>
> I'm doing prediction of the survival cases using gene expression
> profiles(Affymetrix chips).  Can somebody tell me how to use the Cox PH
> model to select genes and make a prediction of survival?
>
>
> Thanks.
>
> Guangchun
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 

Jerome Asselin (J?r?me)
Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital
608 - 1081 Burrard Street
Vancouver, British Columbia
CANADA V6Z 1Y6

Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044



From pburns at pburns.seanet.com  Wed Feb 19 00:43:55 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Wed Feb 19 00:43:55 2003
Subject: [R] S for the Unwilling
Message-ID: <3E52C51B.4070001@pburns.seanet.com>

There is a draft of a new document at 
http://www.burns-stat.com/pages/Tutor/unwilling_S.pdf
entitled "Using S for the Unwilling". (Or click on Tutorials from the 
main web page.)

The aim is to get an inexperienced person who has a task to do in S-PLUS 
or R
oriented and comfortable enough not to give up.  The audience I have in 
mind has
no experience with either statistics or programming (and probably is not 
keen on
changing that state).  Attention span is assumed to be minimal, so the 
document
is by design as brief as possible.

I would appreciate comments.  I'd be especially interested in the 
thoughts of the
recently unwilling.

The document will be available for copying and redistribution as long as 
no more
than a nominal fee is charged.


Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0) 208 525 0696
http://www.burns-stat.com/    (new home of S Poetry)



From ekstrom at dina.kvl.dk  Wed Feb 19 00:48:21 2003
From: ekstrom at dina.kvl.dk (=?iso-8859-1?Q?Claus_Ekstr=F8m?=)
Date: Wed Feb 19 00:48:21 2003
Subject: [R] power.t.test function
In-Reply-To: <x23cml9nta.fsf@biostat.ku.dk>; from p.dalgaard@biostat.ku.dk on Wed, Feb 19, 2003 at 12:22:25AM +0100
References: <183F031D4C18264AA6C1B637B3CD3F31BCD0A5@exchange-ar.li.csiro.au> <x23cml9nta.fsf@biostat.ku.dk>
Message-ID: <20030219004250.A1343@biostat.ku.dk>

> Andrew.Swan at csiro.au writes:
> 
> > Hi - Is it possible to use the power.t.test function in a scenario where the
> > number of observations in each group is different?
> 
> No. It's not rocket science to modify the p.body expression, though.
> The tricky bit is what to do instead of "solve for n".

One possibility would be to have a fixed number >= 1 as the (constant) ratio between the two
group sizes. That shouldn't be too hard to implement. Next step is different variances ....

Claus

*****************************************
Claus Thorn Ekstr?m <ekstrom at dina.kvl.dk>
Dept of Mathematics and Physics, KVL
Thorvaldsensvej 40
DK-1871 Frederiksberg C
Denmark
Phone:[+45] 3528 2341
Fax:  [+45] 3528 2350



From j+rhelp at howard.fm  Wed Feb 19 00:55:03 2003
From: j+rhelp at howard.fm (j+rhelp@howard.fm)
Date: Wed Feb 19 00:55:03 2003
Subject: [R] Non-parametric predictive modelling consultant required
Message-ID: <20030218235421.AFB60483F7@server2.fastmail.fm>

I have an urgent need for assistance with a complex predictive modelling
project - preliminary discussion with numerous statisticians suggests
that off-the-shelf packages (including existing R libraries) are unlikely
to provide a complete solution to the particular problem that we're
tackling. 

I'm looking for a statistics consultant to help with a short (less than 4
weeks) project. The project would probably suit those in academia doing
active research in the area of non-parametric predictive modelling, and
who are interested in some commercial applications. Some understanding of
basic economics would also be helpful.

Could anyone with expertise in GAMs, locally weighted multivariate
logistic regression, and/or logistic regression trees please send me an
email at jhowardATfastmailDOTfm ? I will send more information to those
interested - I don't want to waste other list members' time with these
details.

TIA,
  Jeremy



From stormplot at hotmail.com  Wed Feb 19 01:01:03 2003
From: stormplot at hotmail.com (Jason Fisher)
Date: Wed Feb 19 01:01:03 2003
Subject: [R] tkrplot file ps save
Message-ID: <F163vlUQ9cAgjHXwKHv0000f0df@hotmail.com>

Hello...

In an attempt to avoid nasty R crashes that are believed to be the result of 
poor communication between Tcl/Tk GUI's and Windows (XP) devices, I thought 
I'd use tkrplot for my latest GUI extravaganza.  While tkrplot does a 
beautiful job at reproducing my plots within Tcl/Tk, it leaves me wondering 
how I'm going to generate postscript files that were once easily created 
within the Windows device.  Does anyone have any ideas?  If this topic was 
previously covered, I apologize for asking the same old question.

Regards,
Jason


***************************************
Jason C. Fisher
UCLA Graduate Student
Civil & Environmental Engineering Dept.
5731 Boelter Hall
Box 951593
Los Angeles, CA 90095-1593
Phone Number: (310) 825-2292
Email: stormplot at hotmail.com



From csillery at selway.umt.edu  Wed Feb 19 01:11:03 2003
From: csillery at selway.umt.edu (Katalin Csillery)
Date: Wed Feb 19 01:11:03 2003
Subject: [R] groups of boxplots
Message-ID: <Pine.OSF.4.21.0302181705190.28796-100000@selway.umt.edu>

Hi,

does anyone know how to make pairs of boxplots? E.g. 5 pairs of boxes. I
figured a not very elegant way, by inserting a dummy NA field to the list
where the data is given. So, where I have the dummy I got more distance
between boxes, as a result it looks like groups. But I am having problems
with putting the names under the groups, and the thick marks.

Any better idea?
Thanks, Kati
___
Katalin Csillery
Division of Biological Sciences
University of Montana, Missoula MT 59801
Phone: 406 243 6106, E-mail: csillery at selway.umt.edu
----------------------------------------------------



From MSchwartz at medanalytics.com  Wed Feb 19 01:25:03 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed Feb 19 01:25:03 2003
Subject: [R] groups of boxplots
In-Reply-To: <Pine.OSF.4.21.0302181705190.28796-100000@selway.umt.edu>
References: <Pine.OSF.4.21.0302181705190.28796-100000@selway.umt.edu>
Message-ID: <3E52CE94.3010904@MedAnalytics.com>

Katalin Csillery wrote:
> Hi,
> 
> does anyone know how to make pairs of boxplots? E.g. 5 pairs of boxes. I
> figured a not very elegant way, by inserting a dummy NA field to the list
> where the data is given. So, where I have the dummy I got more distance
> between boxes, as a result it looks like groups. But I am having problems
> with putting the names under the groups, and the thick marks.
> 
> Any better idea?
> Thanks, Kati
> ___
> Katalin Csillery
> Division of Biological Sciences
> University of Montana, Missoula MT 59801
> Phone: 406 243 6106, E-mail: csillery at selway.umt.edu
> ----------------------------------------------------

Use the 'add' and 'at' arguments to boxplot().

Better yet, look at the last example in ?boxplot

For the labels, use the midpoints of the pairs of 'at' values for 
mtext().  See ?mtext for more details.

Regards,

Marc Schwartz



From sfalcon at fhcrc.org  Wed Feb 19 02:40:04 2003
From: sfalcon at fhcrc.org (Falcon, Seth)
Date: Wed Feb 19 02:40:04 2003
Subject: [R] Pretty onscreen plots?
Message-ID: <9667A0D2033CD51195F90002B330A3BF0525F728@moe.fhcrc.org>

I'm looking for ideas for creating high-quality plots for use in projected
presentations (powerpoint, etc) --- ideally high-quality png, jpg, bmp.

The graphics produced using the postscript device look very good.  Those
generated with win.graph(), png are plagued by the jaggy lines.

So far, the only way I can use the postscript plots in my presentations is
using separate screen capture software.  Can someone suggest a better way?

Thanks,

+ seth



From MSchwartz at medanalytics.com  Wed Feb 19 03:42:03 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed Feb 19 03:42:03 2003
Subject: [R] Pretty onscreen plots?
In-Reply-To: <9667A0D2033CD51195F90002B330A3BF0525F728@moe.fhcrc.org>
References: <9667A0D2033CD51195F90002B330A3BF0525F728@moe.fhcrc.org>
Message-ID: <3E52EEBC.5070200@MedAnalytics.com>

Falcon, Seth wrote:
> I'm looking for ideas for creating high-quality plots for use in projected
> presentations (powerpoint, etc) --- ideally high-quality png, jpg, bmp.
> 
> The graphics produced using the postscript device look very good.  Those
> generated with win.graph(), png are plagued by the jaggy lines.
> 
> So far, the only way I can use the postscript plots in my presentations is
> using separate screen capture software.  Can someone suggest a better way?
> 
> Thanks,
> 
> + seth

If you are using R under Windows, the best way to get an R graphic into 
PowerPoint (at least one of them) is to simply right click over the plot 
window and copy the graphic to the clipboard as a metafile.

Then in PowerPoint, use the "large object" slide type. Click on the 
object frame in the slide and simply paste the graphic (CTRL-V) from the 
clipboard into the slide.

Using the metafile format will enable you to maintain a high quality 
image that is also re-sizable (ie. dragging the object frame on the slide).

The bitmapped graphic formats do not re-size will and will distort.

Hope that helps,

Marc Schwartz



From skayis at lic.co.nz  Wed Feb 19 03:58:03 2003
From: skayis at lic.co.nz (skayis@lic.co.nz)
Date: Wed Feb 19 03:58:03 2003
Subject: [R] function
Message-ID: <OF855C6F3B.3B46F9F2-ONCC256CD2.000EA103-CC256CD2.001008DE@livestock.org.nz>

Dear R users,

I have some R code and trying to understand it. I have a vector

 myvec
 [1] 24 24 10 10 10 10 10 44 44 44 45 45 45 54 54 54 54 42 42

and a scaler

 myscaler
[1] 10

The following function:
match(myvec,myscaler)!="NA"

 returns :

 [1]   NA   NA TRUE TRUE TRUE TRUE TRUE   NA   NA   NA   NA   NA   NA   NA
NA   NA   NA   NA    NA

I need a return

FALSE  FALSE TRUE TRUE TRUE TRUE TRUE   FALSE FALSE ...FALSE

Is there any function to perform this?

Any help deeply appreciated.

Kind Regards

Seyit Ali



From jgentry at jimmy.harvard.edu  Wed Feb 19 04:09:04 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Wed Feb 19 04:09:04 2003
Subject: [R] function
In-Reply-To: <OF855C6F3B.3B46F9F2-ONCC256CD2.000EA103-CC256CD2.001008DE@livestock.org.nz>
Message-ID: <Pine.SOL.4.20.0302182207520.22537-100000@santiam.dfci.harvard.edu>


On Wed, 19 Feb 2003 skayis at lic.co.nz wrote:
> The following function:
> match(myvec,myscaler)!="NA"
> I need a return
> FALSE  FALSE TRUE TRUE TRUE TRUE TRUE   FALSE FALSE ...FALSE
> Is there any function to perform this?

Try: 

myvec == myscaler

> z <- c(24, 24, 10, 10, 10, 10, 44, 44, 44, 45, 45, 45, 54, 54, 54, 54,
42, 42)> a <- 10
> match(z,a)
 [1] NA NA  1  1  1  1 NA NA NA NA NA NA NA NA NA NA NA NA
> which(z == a)
[1] 3 4 5 6
> z == a
 [1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE
FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE

-J



From baron at cattell.psych.upenn.edu  Wed Feb 19 04:13:03 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Wed Feb 19 04:13:03 2003
Subject: [R] function
In-Reply-To: <OF855C6F3B.3B46F9F2-ONCC256CD2.000EA103-CC256CD2.001008DE@livestock.org.nz>; from skayis@lic.co.nz on Wed, Feb 19, 2003 at 03:50:47PM +1300
References: <OF855C6F3B.3B46F9F2-ONCC256CD2.000EA103-CC256CD2.001008DE@livestock.org.nz>
Message-ID: <20030218220849.C17825@cattell.psych.upenn.edu>

On 02/19/03 15:50, skayis at lic.co.nz wrote:
>Dear R users,
>
>I have some R code and trying to understand it. I have a vector
>
> myvec
> [1] 24 24 10 10 10 10 10 44 44 44 45 45 45 54 54 54 54 42 42
>
>and a scaler
>
> myscaler
>[1] 10
>
>The following function:
>match(myvec,myscaler)!="NA"
>
> returns :
>
> [1]   NA   NA TRUE TRUE TRUE TRUE TRUE   NA   NA   NA   NA   NA   NA   NA
>NA   NA   NA   NA    NA
>
>I need a return
>
>FALSE  FALSE TRUE TRUE TRUE TRUE TRUE   FALSE FALSE ...FALSE
>
>Is there any function to perform this?

myvec==myscaler

or the reverse.  The scalar is "recycled."

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
R page:               http://finzi.psych.upenn.edu/



From upton at mitre.org  Wed Feb 19 04:16:56 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Wed Feb 19 04:16:56 2003
Subject: [R] function
References: <OF855C6F3B.3B46F9F2-ONCC256CD2.000EA103-CC256CD2.001008DE@livestock.org.nz>
Message-ID: <3E52F544.E02B889E@mitre.org>

Why not just use "=="?

> bb
[1] 1 2 3 5 6 3
> bb==3
[1] FALSE FALSE  TRUE FALSE FALSE  TRUE

HTH
steve


skayis at lic.co.nz wrote:

> Dear R users,
>
> I have some R code and trying to understand it. I have a vector
>
>  myvec
>  [1] 24 24 10 10 10 10 10 44 44 44 45 45 45 54 54 54 54 42 42
>
> and a scaler
>
>  myscaler
> [1] 10
>
> The following function:
> match(myvec,myscaler)!="NA"
>
>  returns :
>
>  [1]   NA   NA TRUE TRUE TRUE TRUE TRUE   NA   NA   NA   NA   NA   NA   NA
> NA   NA   NA   NA    NA
>
> I need a return
>
> FALSE  FALSE TRUE TRUE TRUE TRUE TRUE   FALSE FALSE ...FALSE
>
> Is there any function to perform this?
>
> Any help deeply appreciated.
>
> Kind Regards
>
> Seyit Ali
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From daver969 at yahoo.com  Wed Feb 19 04:21:05 2003
From: daver969 at yahoo.com (David Richmond)
Date: Wed Feb 19 04:21:05 2003
Subject: [R] function
In-Reply-To: <OF855C6F3B.3B46F9F2-ONCC256CD2.000EA103-CC256CD2.001008DE@livestock.org.nz>
Message-ID: <466147AE-43B8-11D7-ACDE-000393DBCEC2@yahoo.com>

If you want to test for "NA" (Not a number?) you want

is.na()

or !is.na() (is not "NA") in your case.


On Tuesday, February 18, 2003, at 06:50  PM, skayis at lic.co.nz wrote:

> Dear R users,
>
> I have some R code and trying to understand it. I have a vector
>
>  myvec
>  [1] 24 24 10 10 10 10 10 44 44 44 45 45 45 54 54 54 54 42 42
>
> and a scaler
>
>  myscaler
> [1] 10
>
> The following function:
> match(myvec,myscaler)!="NA"
>
>  returns :
>
>  [1]   NA   NA TRUE TRUE TRUE TRUE TRUE   NA   NA   NA   NA   NA   NA  
>  NA
> NA   NA   NA   NA    NA
>
> I need a return
>
> FALSE  FALSE TRUE TRUE TRUE TRUE TRUE   FALSE FALSE ...FALSE
>
> Is there any function to perform this?
>
> Any help deeply appreciated.
>
> Kind Regards
>
> Seyit Ali
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From mail at joeconway.com  Wed Feb 19 04:47:03 2003
From: mail at joeconway.com (Joe Conway)
Date: Wed Feb 19 04:47:03 2003
Subject: [R] PL/R - R procedural language handler for PostgreSQL
In-Reply-To: <Pine.LNX.4.44.0302181653450.1549-100000@gannet.stats>
References: <Pine.LNX.4.44.0302181653450.1549-100000@gannet.stats>
Message-ID: <3E52FD83.2040008@joeconway.com>

ripley at stats.ox.ac.uk wrote:
> But R does not build under Cygwin (last time I looked and I would be
> surprised if it would without a lot of tinkering), and the Windows port of
> R does not have libR.so but a different (and much older) mechanism using
> R.dll.
> 

Hmmm. I neglected to think about that angle :-(

Is there a desire to get R to build under Cygwin, or is it preferable to 
put any effort into the Windows port?

Joe



From s195404 at student.uq.edu.au  Wed Feb 19 05:19:03 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Wed Feb 19 05:19:03 2003
Subject: [R] Pretty onscreen plots?
In-Reply-To: <9667A0D2033CD51195F90002B330A3BF0525F728@moe.fhcrc.org>
References: <9667A0D2033CD51195F90002B330A3BF0525F728@moe.fhcrc.org>
Message-ID: <1045628293.3e53058584203@my.uq.edu.au>

Seth,

The R functions png(), jpg() and bmp() will generate files that can be used in 
PowerPoint. Previews can be added to postscript files, using Ghostview and 
ImageMagik among others. I have done the latter in the past since the 
postscript files are of an excellent standard, and because I've wanted both to 
display and print a report. Having separate viewing and printing versions of 
graphs is not very convenient.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting "Falcon, Seth" <sfalcon at fhcrc.org>:

> I'm looking for ideas for creating high-quality plots for use in projected
> presentations (powerpoint, etc) --- ideally high-quality png, jpg, bmp.
> 
> The graphics produced using the postscript device look very good.  Those
> generated with win.graph(), png are plagued by the jaggy lines.
> 
> So far, the only way I can use the postscript plots in my presentations is
> using separate screen capture software.  Can someone suggest a better way?
> 
> Thanks,
> 
> + seth
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From s195404 at student.uq.edu.au  Wed Feb 19 05:24:03 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Wed Feb 19 05:24:03 2003
Subject: [R] function
In-Reply-To: <OF855C6F3B.3B46F9F2-ONCC256CD2.000EA103-CC256CD2.001008DE@livestock.org.nz>
References: <OF855C6F3B.3B46F9F2-ONCC256CD2.000EA103-CC256CD2.001008DE@livestock.org.nz>
Message-ID: <1045628503.3e53065778785@my.uq.edu.au>

!is.na(match(myvec, myscaler)) is probably what you want.

Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting skayis at lic.co.nz:

> Dear R users,
> 
> I have some R code and trying to understand it. I have a vector
> 
>  myvec
>  [1] 24 24 10 10 10 10 10 44 44 44 45 45 45 54 54 54 54 42 42
> 
> and a scaler
> 
>  myscaler
> [1] 10
> 
> The following function:
> match(myvec,myscaler)!="NA"
> 
>  returns :
> 
>  [1]   NA   NA TRUE TRUE TRUE TRUE TRUE   NA   NA   NA   NA   NA   NA   NA
> NA   NA   NA   NA    NA
> 
> I need a return
> 
> FALSE  FALSE TRUE TRUE TRUE TRUE TRUE   FALSE FALSE ...FALSE
> 
> Is there any function to perform this?
> 
> Any help deeply appreciated.
> 
> Kind Regards
> 
> Seyit Ali
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From sck2348 at cacs.louisiana.edu  Wed Feb 19 05:33:02 2003
From: sck2348 at cacs.louisiana.edu (Komanduru Sai C)
Date: Wed Feb 19 05:33:02 2003
Subject: [R] nls
Message-ID: <200302190432.h1J4WAq03928@mailer.cacs.louisiana.edu>

Hi,

I am using nls library

df <- read.table("data.txt", header=T);						
library(nls);
fm <- nls(y ~ a*(x+d)^(-b), df, start=list(a=max(df->y,na.rm=T)/2,b=1,d=0));
coef(fm); 
q();

When i am using the above routine i am getting the following error

Error in nlsModel(formula, mf, start) : singular gradient matrix at initial 
parameter estimates

Can some one help me in this.

The data.txt file looks like this


x                y                z
1.0                NA                478
2.0                NA                473
3.0                NA                449
4.0                NA                446
5.0                NA                438
6.5                NA                437
6.5                NA                437
8.0                NA                427
9.0                NA                426
10.0                NA                425
11.0                NA                424
14.0                NA                423
14.0                NA                423
14.0                NA                423
14.0                NA                423
14.0                NA                423
.........

The y field has some values at the bottom.

Thanks,
SAi



From smyth at wehi.edu.au  Wed Feb 19 05:45:03 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Wed Feb 19 05:45:03 2003
Subject: [R] Rcmd check does not recognize formal generic function as code
 object
Message-ID: <5.2.0.9.1.20030219140303.00aeb770@imaphost.wehi.edu.au>

Dear all,

I am trying to write a package using formal methods and classes from the 
methods package. I have not been able to get the package to pass rcmd check 
without warnings, because rcmd check does not recognize my generic 
functions as code objects and therefore queries why they have documentation 
entries.

I have isolated the problem in a very small trivial example which I give 
below. I have one file test.R in the R directory and one file test.Rd in 
the man directory. Here is the message from rcmd check:

    * checking for code/documentation mismatches ... WARNING
    Objects with usage in documentation object 'myGenericFun' but missing 
from code:
    [1] "myGenericFun"

Can I get rcmd check to recognize that myGenericFun is something that need 
a documentation entry?

The document "Writing R Extensions" doesn't cover formal methods and 
classes, and I haven't found any other documentation that covers writing 
packages using formal methods. I am working from looking at code in 
Bioconductor, pixmap and gpclib. I downloaded source for pixmap and 
confirmed that it has the same problem with rcmd check that I mention here.

Any advice gratefully received, including any tips about how to write 
organise .Rd files for generic methods.

Thanks
Gordon

-------------------------------- test.R -----------------------------
.initClassesandMethods <- function(where) {
setGeneric("myGenericFun",where=where,
         def=function(object) standardGeneric("myGenericFun"))
setMethod("myGenericFun","ANY",where=where,
         def=function(object) paste("myGenericFun on object of 
class",class(object)))
setMethod("myGenericFun","matrix",where=where,
         def=function(object) "myGenericFun for matrices")
}
#  Use of .First.lib ensures that the new generic function is assigned in 
the package itself
.First.lib <- function(libname, pkgname) {
         require(methods, quietly=TRUE)
#  Find what position in the search path this package is
         where <- match(paste("package:", pkgname, sep=""), search())
         .initClassesandMethods(where)
         cacheMetaData(as.environment(where))
}
------------------------- end test.R ----------------------------------

------------------------- myGenericFun.Rd ------------------------
\name{myGenericFun}
\docType{methods}
\alias{myGenericFun}
\title{My Generic Function}
\description{A simple example generic function.}

\usage{myGenericFun(object)}

\arguments{
   \item{object}{Any R object. A special method exists for objects of class 
"matrix".}
}

\value{A character string explaining the class of object and the method 
dispatched.}

\examples{
x <- rnorm(10)
myGenericFun(x)
dim(x) <- c(5,2)
myGenericFun(x)
}

\keyword{models}
-------------------------------- end myGenericFun.Rd -------------------
---------------------------------------------------------------------------------------
Dr Gordon K Smyth, Senior Research Scientist, Bioinformatics,
Walter and Eliza Hall Institute of Medical Research,
1G Royal Parade, Parkville, Vic 3050, Australia
Tel: (03) 9345 2326, Fax (03) 9347 0852,
Email: smyth at wehi.edu.au, www: http://www.statsci.org



From rgentlem at jimmy.harvard.edu  Wed Feb 19 06:18:04 2003
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Wed Feb 19 06:18:04 2003
Subject: [R] Rcmd check does not recognize formal generic function as code object
In-Reply-To: <5.2.0.9.1.20030219140303.00aeb770@imaphost.wehi.edu.au>; from smyth@wehi.edu.au on Wed, Feb 19, 2003 at 03:44:31PM +1100
References: <5.2.0.9.1.20030219140303.00aeb770@imaphost.wehi.edu.au>
Message-ID: <20030219001655.G2907@jimmy.harvard.edu>

On Wed, Feb 19, 2003 at 03:44:31PM +1100, Gordon Smyth wrote:
> Dear all,
> 
> I am trying to write a package using formal methods and classes from the 
> methods package. I have not been able to get the package to pass rcmd check 
> without warnings, because rcmd check does not recognize my generic 
> functions as code objects and therefore queries why they have documentation 
> entries.
> 
> I have isolated the problem in a very small trivial example which I give 
> below. I have one file test.R in the R directory and one file test.Rd in 
> the man directory. Here is the message from rcmd check:
> 
>     * checking for code/documentation mismatches ... WARNING
>     Objects with usage in documentation object 'myGenericFun' but missing 
> from code:
>     [1] "myGenericFun"
> 
> Can I get rcmd check to recognize that myGenericFun is something that need 
> a documentation entry?
> 

  Mostly this is not documented (yet) because the exact API is still
  being worked on.

  Documenting generic functions (and the methods that they dispatch)
  is hard in a language that allows users to attach and detach
  packages (and hence both generic functions and methods). We don't
  really have the notion of dynamic documentation (yet) that will
  handle the applications that are likely to arise.

  The current problem arises, I think, from an effort to solve a
  different problem. Since many functions in "base" are not generic
  (yet?) when a package author wants to make one generic we don't
  really want to override the documentation for that function in base
  ( we might want to document the method that we are adding, but the
  creation of the generic is artificial in some sense, if users could
  assign into base, or if all base functions were generic the generic
  would live in base and be documented there).

  It was decided that should not be an error to omit documentation for
  a generic function defined in a package (whose sole purpose is to
  extend a current function to be generic). It appears that the
  implementation of that decision was to treat all generic functions
  in packages as non-entities. That is probably not the best and one
  can argue that there should be no warning if a generic is documented
  (nor one if it isn't and there is already documentation for it
  somewhere). 

  What we have been doing is using promptClass and documenting methods
  (and generics with the classes) in Bioconductor. 

  This will continue to change as we gain experience with the methods
  class and with feedback from users. As I noted, with generic
  functions it would be nice to explain the purpose and list all
  available methods when the user wants help.

 I think that you can safely ignore this warning.

 Robert

> The document "Writing R Extensions" doesn't cover formal methods and 
> classes, and I haven't found any other documentation that covers writing 
> packages using formal methods. I am working from looking at code in 
> Bioconductor, pixmap and gpclib. I downloaded source for pixmap and 
> confirmed that it has the same problem with rcmd check that I mention here.
> 
> Any advice gratefully received, including any tips about how to write 
> organise .Rd files for generic methods.
> 
> Thanks
> Gordon
> 
> -------------------------------- test.R -----------------------------
> .initClassesandMethods <- function(where) {
> setGeneric("myGenericFun",where=where,
>          def=function(object) standardGeneric("myGenericFun"))
> setMethod("myGenericFun","ANY",where=where,
>          def=function(object) paste("myGenericFun on object of 
> class",class(object)))
> setMethod("myGenericFun","matrix",where=where,
>          def=function(object) "myGenericFun for matrices")
> }
> #  Use of .First.lib ensures that the new generic function is assigned in 
> the package itself
> .First.lib <- function(libname, pkgname) {
>          require(methods, quietly=TRUE)
> #  Find what position in the search path this package is
>          where <- match(paste("package:", pkgname, sep=""), search())
>          .initClassesandMethods(where)
>          cacheMetaData(as.environment(where))
> }
> ------------------------- end test.R ----------------------------------
> 
> ------------------------- myGenericFun.Rd ------------------------
> \name{myGenericFun}
> \docType{methods}
> \alias{myGenericFun}
> \title{My Generic Function}
> \description{A simple example generic function.}
> 
> \usage{myGenericFun(object)}
> 
> \arguments{
>    \item{object}{Any R object. A special method exists for objects of class 
> "matrix".}
> }
> 
> \value{A character string explaining the class of object and the method 
> dispatched.}
> 
> \examples{
> x <- rnorm(10)
> myGenericFun(x)
> dim(x) <- c(5,2)
> myGenericFun(x)
> }
> 
> \keyword{models}
> -------------------------------- end myGenericFun.Rd -------------------
> ---------------------------------------------------------------------------------------
> Dr Gordon K Smyth, Senior Research Scientist, Bioinformatics,
> Walter and Eliza Hall Institute of Medical Research,
> 1G Royal Parade, Parkville, Vic 3050, Australia
> Tel: (03) 9345 2326, Fax (03) 9347 0852,
> Email: smyth at wehi.edu.au, www: http://www.statsci.org
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20                            |
| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
+---------------------------------------------------------------------------+



From j+rhelp at howard.fm  Wed Feb 19 06:45:05 2003
From: j+rhelp at howard.fm (j+rhelp@howard.fm)
Date: Wed Feb 19 06:45:05 2003
Subject: [R] PL/R - R procedural language handler for PostgreSQL
In-Reply-To: <3E52FD83.2040008@joeconway.com>
References: <Pine.LNX.4.44.0302181653450.1549-100000@gannet.stats> <3E52FD83.2040008@joeconway.com>
Message-ID: <20030219054356.42F953E71C@server2.fastmail.fm>

On Tue, 18 Feb 2003 19:44:03 -0800, "Joe Conway" <mail at joeconway.com>
said:
> Is there a desire to get R to build under Cygwin, or is it preferable to 
> put any effort into the Windows port?

Given that:
 - R runs already directly under Windows
 - PostgresQL will run shortly directly under Windows
 - PostgresQL is too slow for heavy use under Cygwin
...I'd suggest putting any effort into the Windows port of your library.



From laurent at cbs.dtu.dk  Wed Feb 19 07:23:02 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Wed Feb 19 07:23:02 2003
Subject: [R] assign value to slot of S4 object
Message-ID: <20030219062316.GB37809598@genome.cbs.dtu.dk>

Dear list,

I noticed something while assigning a new value to the slot
of an object of class S4.
Apparently(*) this object is copied while the operation
is performed. Is it really wished ?  (or did I miss something ?)

I use R-1.6.2:
> R.version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.2              
year     2003             
month    01               
day      10               
language R      



L.


(*): I did 'top' as I heard my machine playing with the swap



From ihaka at stat.auckland.ac.nz  Wed Feb 19 08:05:04 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Wed Feb 19 08:05:04 2003
Subject: [R] assign value to slot of S4 object
References: <20030219062316.GB37809598@genome.cbs.dtu.dk>
Message-ID: <3E532C65.7000206@stat.auckland.ac.nz>

Laurent Gautier wrote:
> Dear list,
> 
> I noticed something while assigning a new value to the slot
> of an object of class S4.
> Apparently(*) this object is copied while the operation
> is performed. Is it really wished ?  (or did I miss something ?)
> 
> I use R-1.6.2:

This is a product of the S call-by-value semantics.  There is actually 
an enormous amount of copying which takes place in R (and Splus). 
However, it is only with large objects that this becomes noticable.

Coincidentally John Chambers, Robert Gentleman, Paul Murrell and I were 
discussing exactly this type of issue today.  We are certainly aware 
that there are problems and are looking at potential solutions.

-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand



From ripley at stats.ox.ac.uk  Wed Feb 19 08:09:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb 19 08:09:58 2003
Subject: [R] Solaris 8
In-Reply-To: <20030218220354.47509.qmail@web13405.mail.yahoo.com>
Message-ID: <Pine.GSO.4.31.0302190703360.366-100000@toucan.stats>

Yes, several ways.

On Tue, 18 Feb 2003, Webster West wrote:

> Has anyone been able to install R 1.6.2 under Solaris
> 8?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mhv at dmu.dk  Wed Feb 19 08:19:04 2003
From: mhv at dmu.dk (mhv@dmu.dk)
Date: Wed Feb 19 08:19:04 2003
Subject: [R] Q: libreadline.so.4.1 problems on Alpha/Linux
Message-ID: <0D86E7094B70754C900E4160015800360100DF69@dmurexch.dmu.dk>

	...snip...

? 
? You need to install the readline41 package 
? (readline41-4.1-10.ia64.rpm)
? which is part of the Red Hat 7.2 distribution and provides 
? the required
? library.
? 
? Martyn
? 
? 

Thanks - Are you shure the ia64 will work on an Alpha ?

:-? Martin



From eac at ma.adfa.edu.au  Wed Feb 19 08:24:05 2003
From: eac at ma.adfa.edu.au (eac@ma.adfa.edu.au)
Date: Wed Feb 19 08:24:05 2003
Subject: [R] plotmath
Message-ID: <Pine.LNX.4.33.0302192021430.26158-100000@stat.ma.adfa.ed.au>

There's something (probably a lot) missing in my understanding of
plotmath. The LaTeX code for what I'm trying to produce is

\log(-\log(\hat R))

My (probably hopeless) attempt at it uses nested group()s:

expression(plain(log) * group("(", -plain(log)*group("(", \hat(R), ")"),
")"))

Can anyone do it right for me, please?

Thanks,
	Ted.

Dr E.A. Catchpole
 ----------------------------------
| Associate Professor              |      ------------------------------
| School of Maths & Stats          |     |  Hon Senior Research Fellow  |
| University of New South Wales at |     |  Institute of Maths & Stats  |
| Australian Defence Force Academy | and |  University of Kent          |
| Canberra, ACT 2600, Australia    |     |  Canterbury CT2 7NF, England |
| e-catchpole at adfa.edu.au          |     |  E.A.Catchpole at ukc.ac.uk     |
| www.ma.adfa.edu.au/~eac          |      ------------------------------
| fax: +61 2 6268 8886		   |
| ph:  +61 2 6268 8895             |
 ----------------------------------



From ripley at stats.ox.ac.uk  Wed Feb 19 08:39:04 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb 19 08:39:04 2003
Subject: [R] PL/R - R procedural language handler for PostgreSQL
In-Reply-To: <3E52FD83.2040008@joeconway.com>
Message-ID: <Pine.GSO.4.31.0302190730220.366-100000@toucan.stats>

On Tue, 18 Feb 2003, Joe Conway wrote:

> ripley at stats.ox.ac.uk wrote:
> > But R does not build under Cygwin (last time I looked and I would be
> > surprised if it would without a lot of tinkering), and the Windows port of
> > R does not have libR.so but a different (and much older) mechanism using
> > R.dll.
> >
>
> Hmmm. I neglected to think about that angle :-(
>
> Is there a desire to get R to build under Cygwin, or is it preferable to
> put any effort into the Windows port?

Clearly there is some interest (or Tony Rossini would not be trying),
but I don't see any desire to maintain R under Cygwin: it's an ongoing
commitment to keep it working that would be needed.

In my experience Windows users want a Windows interface (and especially
Windows filenames), not a somewhat-like-Unix one.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From hb at maths.lth.se  Wed Feb 19 08:45:09 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed Feb 19 08:45:09 2003
Subject: [R] plotmath
In-Reply-To: <Pine.LNX.4.33.0302192021430.26158-100000@stat.ma.adfa.ed.au>
Message-ID: <000801c2d7ea$5f5cedc0$7341a8c0@alpha.wehi.edu.au>

Is this an example of what you want?

xlab <- expression(log(-log(hat(R))))
plot(1, xlab=xlab)

Henrik Bengtsson
Mathematical Statistics, Lund University, Sweden

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of 
> eac at ma.adfa.edu.au
> Sent: den 19 februari 2003 20:26
> To: R Help list
> Cc: eac at ma.adfa.edu.au
> Subject: [R] plotmath
> 
> 
> There's something (probably a lot) missing in my 
> understanding of plotmath. The LaTeX code for what I'm trying 
> to produce is
> 
> \log(-\log(\hat R))
> 
> My (probably hopeless) attempt at it uses nested group()s:
> 
> expression(plain(log) * group("(", -plain(log)*group("(", 
> \hat(R), ")"),
> ")"))
> 
> Can anyone do it right for me, please?
> 
> Thanks,
> 	Ted.
> 
> Dr E.A. Catchpole
>  ----------------------------------
> | Associate Professor              |      
> ------------------------------
> | School of Maths & Stats          |     |  Hon Senior 
> Research Fellow  |
> | University of New South Wales at |     |  Institute of 
> Maths & Stats  |
> | Australian Defence Force Academy | and |  University of 
> Kent          |
> | Canberra, ACT 2600, Australia    |     |  Canterbury CT2 
> 7NF, England |
> | e-catchpole at adfa.edu.au          |     |  
> E.A.Catchpole at ukc.ac.uk     |
> | www.ma.adfa.edu.au/~eac          |      
> ------------------------------
> | fax: +61 2 6268 8886		   |
> | ph:  +61 2 6268 8895             |
>  ----------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From ripley at stats.ox.ac.uk  Wed Feb 19 08:49:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed Feb 19 08:49:22 2003
Subject: [R] Pretty onscreen plots?
In-Reply-To: <1045628293.3e53058584203@my.uq.edu.au>
Message-ID: <Pine.GSO.4.31.0302190738470.366-100000@toucan.stats>

I use PDF and make my presentations in PDF using pdflatex, or even in
postscript and Distiller.  That way the final document has vector
graphics, and bitmapping only occurs at the very last minute, when the
projector resolution is known.

In theory win.metafile should do the same for powerpoint, but in practice
it is not as good.  Probably the metafile graphics driver could be
improved ....

On Wed, 19 Feb 2003, Andrew C. Ward wrote:

> Seth,
>
> The R functions png(), jpg() and bmp() will generate files that can be used in
> PowerPoint. Previews can be added to postscript files, using Ghostview and
> ImageMagik among others. I have done the latter in the past since the
> postscript files are of an excellent standard, and because I've wanted both to
> display and print a report. Having separate viewing and printing versions of
> graphs is not very convenient.
>
>
> Regards,
>
> Andrew C. Ward
>
> CAPE Centre
> Department of Chemical Engineering
> The University of Queensland
> Brisbane Qld 4072 Australia
> andreww at cheque.uq.edu.au
>
>
>
> Quoting "Falcon, Seth" <sfalcon at fhcrc.org>:
>
> > I'm looking for ideas for creating high-quality plots for use in projected
> > presentations (powerpoint, etc) --- ideally high-quality png, jpg, bmp.
> >
> > The graphics produced using the postscript device look very good.  Those
> > generated with win.graph(), png are plagued by the jaggy lines.
> >
> > So far, the only way I can use the postscript plots in my presentations is
> > using separate screen capture software.  Can someone suggest a better way?
> >
> > Thanks,
> >
> > + seth
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ihaka at stat.auckland.ac.nz  Wed Feb 19 08:54:06 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Wed Feb 19 08:54:06 2003
Subject: [R] plotmath
References: <Pine.LNX.4.33.0302192021430.26158-100000@stat.ma.adfa.ed.au>
Message-ID: <3E53364E.1040806@stat.auckland.ac.nz>

eac at ma.adfa.edu.au wrote:
> There's something (probably a lot) missing in my understanding of
> plotmath. The LaTeX code for what I'm trying to produce is
> 
> \log(-\log(\hat R))
> 
> My (probably hopeless) attempt at it uses nested group()s:
> 
> expression(plain(log) * group("(", -plain(log)*group("(", \hat(R), ")"),
> ")"))
> 
> Can anyone do it right for me, please?

Here's my attempt

     expression(log(-log(hat(italic(R)))))

Unlike TeX, if you want italics you have to ask for it.

(If you are attempting anthing serious, the TeX package psfrag  is worth 
a look.)


-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand



From roger at ysidro.econ.uiuc.edu  Wed Feb 19 09:36:27 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Wed Feb 19 09:36:27 2003
Subject: [R] Pretty onscreen plots?
In-Reply-To: <Pine.GSO.4.31.0302190738470.366-100000@toucan.stats>
Message-ID: <Pine.SOL.4.30.0302190231300.12804-100000@ysidro.econ.uiuc.edu>

I have also been using pdf() and pdflatex ... the nice post processing of ppower4
gives pdf files that have considerable flexibility.  See

	www.phys.uni-paderborn.de/~stern/ppower

for an example....

url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
email	rkoenker at uiuc.edu	Department of Economics Drayton House,
vox: 	217-333-4558		University of Illinois	30 Gorden St,
fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK
							vox:	020-7679-5838

On Wed, 19 Feb 2003, Prof Brian Ripley wrote:

> I use PDF and make my presentations in PDF using pdflatex, or even in
> postscript and Distiller.  That way the final document has vector
> graphics, and bitmapping only occurs at the very last minute, when the
> projector resolution is known.
>



From mkondrin at hppi.troitsk.ru  Wed Feb 19 09:42:05 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Wed Feb 19 09:42:05 2003
Subject: [R] fitting a curve according to a custom loss function
In-Reply-To: <AFD78192EC49D311BFAE00902798AB8F23DCFC@jupiter.arbitrade.com>
References: <AFD78192EC49D311BFAE00902798AB8F23DCFC@jupiter.arbitrade.com>
Message-ID: <3E53DB93.5040202@hppi.troitsk.ru>

Vadim Ogranovich wrote:

>Dear R-Users,
>
>I need to find a smooth function f() and coefficients a_i that give the best
>fit to
>
>y ~ a_0 + a_1*f(x_1) + a_2*f(x_2)
>
>Note that it is the same non-linear transformation f() that is applied to
>both x_1 and x_2.
>
>So my first question is how can I do it in R?
>
>A more general question is this: suppose I have a utility function U(a_i,
>f()), where f() is say a spline. Is there a general optimizer that could
>find an extremum of such U()? If not, how easy it would be to hack up
>something like this? Would it become easier if U() depended on f() only,
>i.e. no a_i terms?
>
>Thanks, Vadim
>
>-------------------------------------------------- 
>DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>  
>
Vadim
It seems to me that ls (linear least squares) will be enourgh. You have
to find linear coefficients of three vectors - first consisting of all
ones , second and third filled with values f(x_1) and f(x_2).
Answer to more general question will be ?optim (in general). You have to
write a function that have as a result a sum of residuals between y
values to be fit and modelled values and find minimum of this function.
This is what optim exactly do.



From plummer at iarc.fr  Wed Feb 19 09:45:42 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: Wed Feb 19 09:45:42 2003
Subject: [R] Q: libreadline.so.4.1 problems on Alpha/Linux
In-Reply-To: <0D86E7094B70754C900E4160015800360100DF69@dmurexch.dmu.dk>
References: <0D86E7094B70754C900E4160015800360100DF69@dmurexch.dmu.dk>
Message-ID: <1045644703.966.5.camel@xena>

On Wed, 2003-02-19 at 08:18, mhv at DMU.dk wrote:
> 
> 	...snip...
> 
> ? 
> ? You need to install the readline41 package 
> ? (readline41-4.1-10.ia64.rpm)
> ? which is part of the Red Hat 7.2 distribution and provides 
> ? the required
> ? library.
> ? 
> ? Martyn
> ? 
> ? 
> 
> Thanks - Are you shure the ia64 will work on an Alpha ?

I'm sure it won't! You want the alpha version, from Compaq, but the
package name is the same.

Martyn



From luca at stat.unipg.it  Wed Feb 19 12:41:03 2003
From: luca at stat.unipg.it (Luca Scrucca)
Date: Wed Feb 19 12:41:03 2003
Subject: [R] glm and overdispersion
Message-ID: <Pine.SOL.4.50.0302191238370.1555-100000@pearson.stat.unipg.it>

I recently uploaded a package to CRAN called `dispmod' which provides
functions for modelling dispersion in GLM.
In particular, the function `glm.binomial.disp' fits overdispersed
binomial logit models following the approach discussed by Williams, D. A.
(1982), Extra-binomial variation in logistic linear models, Applied
Statistics, 31, 144-148.

I hope this can help you.

Luca

+-----------------------------------------------------------------------+
| Dr. Luca Scrucca                                                      |
| Dipartimento di Scienze Statistiche      tel. +39 - 075 - 5855278     |
| Universita' degli Studi di Perugia       fax. +39 - 075 - 43242       |
| Via Pascoli - C.P. 1315 Succ. 1                                       |
| 06100 PERUGIA  (ITALY)                                                |
|                                                                       |
| E-mail:   luca at stat.unipg.it                                          |
| Web page: http://www.stat.unipg.it/luca                               |
+-----------------------------------------------------------------------+



From sharon at math.chalmers.se  Wed Feb 19 13:26:03 2003
From: sharon at math.chalmers.se (Sharon Kuhlmann-Berenzon)
Date: Wed Feb 19 13:26:03 2003
Subject: [R] GLM for Beta distribution
Message-ID: <Pine.SOL.4.30.0302191316150.15333-100000@krilov.math.chalmers.se>

Hi R-help,

Is there such a thing as a function in R for fitting a GLM where the
response is distributed as a Beta distribution?

In my case, the response variable is a percentage ([0,1] and continuous).

The current glm() function in R doesn't include the Beta distribution.

Thank you for any help on this topic.

Sincerely,

Sharon K?hlmann



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
SHARON K?HLMANN-BERENZON

Tel. +46-31-772 53 60			Dept. Mathematical Statistics
Fax. +46-31-772 35 08			Chalmers University of Tech.
e-mail: sharon at math.chalmers.se		Eklandagatan 86
					412 96 G?teborg, Sweden



From andy_liaw at merck.com  Wed Feb 19 14:34:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Feb 19 14:34:03 2003
Subject: [R] fitting a curve according to a custom loss function
Message-ID: <3A822319EB35174CA3714066D590DCD534BCC2@usrymx25.merck.com>

> From: M.Kondrin [mailto:mkondrin at hppi.troitsk.ru]
> Sent: Wednesday, February 19, 2003 2:32 PM
> 
> Vadim Ogranovich wrote:
> 
> >Dear R-Users,
> >
> >I need to find a smooth function f() and coefficients a_i 
> that give the best
> >fit to
> >
> >y ~ a_0 + a_1*f(x_1) + a_2*f(x_2)
> >
> >Note that it is the same non-linear transformation f() that 
> is applied to
> >both x_1 and x_2.
> >
> >So my first question is how can I do it in R?
> >
> >A more general question is this: suppose I have a utility 
> function U(a_i,
> >f()), where f() is say a spline. Is there a general 
> optimizer that could
> >find an extremum of such U()? If not, how easy it would be to hack up
> >something like this? Would it become easier if U() depended 
> on f() only,
> >i.e. no a_i terms?
> >
> >Thanks, Vadim
> >
> >-------------------------------------------------- 
> >DISCLAIMER \ This e-mail, and any attachments thereto, is 
> intend ... [[dropped]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >  
> >
> Vadim
> It seems to me that ls (linear least squares) will be 
> enourgh. You have
> to find linear coefficients of three vectors - first consisting of all
> ones , second and third filled with values f(x_1) and f(x_2).
> Answer to more general question will be ?optim (in general). 
> You have to
> write a function that have as a result a sum of residuals between y
> values to be fit and modelled values and find minimum of this 
> function.
> This is what optim exactly do.

Note that Vadim said he wanted to find f().  You're assuming f() is known.

The model is very strange (to me, at least).  It's not obvious to me that
it's even identifiable.  (Sorry that I don't have anything constructive to
add.)

Andy
 


------------------------------------------------------------------------------



From tlumley at u.washington.edu  Wed Feb 19 14:42:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Feb 19 14:42:03 2003
Subject: [R] GLM for Beta distribution
In-Reply-To: <Pine.SOL.4.30.0302191316150.15333-100000@krilov.math.chalmers.se>
Message-ID: <Pine.A41.4.44.0302190536340.37318-100000@homer17.u.washington.edu>

On Wed, 19 Feb 2003, Sharon Kuhlmann-Berenzon wrote:

>
> Hi R-help,
>
> Is there such a thing as a function in R for fitting a GLM where the
> response is distributed as a Beta distribution?
>
> In my case, the response variable is a percentage ([0,1] and continuous).
>
> The current glm() function in R doesn't include the Beta distribution.
>

That's because they aren't generalised linear models.

Two simple possibilities

 - use the quasibinomial variance and an appropriate link such as logit in
glm -- there's an example in McCullagh & Nelder that tries this (though
they decide in the end that it doesn't fit their data very well)

 - Take logits and model with linear regression: a lot of beta
distributions are fairly similar to logit-normal distributions.

Or you could write down the loglikelihood and use nlm() or optim() to
maximise it.

	-thomas



From gavin.simpson at ucl.ac.uk  Wed Feb 19 15:12:06 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed Feb 19 15:12:06 2003
Subject: [R] getting/storing the name of an object passed to a function
Message-ID: <000a01c2d821$323cf010$4c202880@gsimpson>

Hi

I have a couple of functions that work on the object created by another R
command and then print out or summarise the results of this work.

The main function is defined as:

hotelling.t <- function(obj)
{
	#internal commands
}

I then have print.hotelling.t() that takes the list returned by hotelling.t
and prints it with some extra significance calculations, formatting, etc.

I want to then use the named object in another calculation in
print.hotelling.t() , that only gets done/printed if you ask for it in the
call to print.hotelling.t()

How do I store the name of the object obj passed to hotelling.t in the
object returned by hotelling.t?

And how do I "paste" the name of that object into a call to another R
function within my print.hotelling.t()?

Perhaps this is not the best way to do things in R?  So any comments would
be most appreciated.

By the way, the object obj is of class lda (Package MASS), if that matters.
Functions appended below.  R 1.6.2 on windows XP.

Many Thanks

Gavin Simpson

Functions:  the commented line in print.hotelling.t (last line) is where I
want to use the name of obj, to replace picea.lda.  The code works if you
known the lda object, I now just want to grab it from the original call to
hotelling.t

hotelling.t <- function(obj)
{
    if (is.null(class(obj))) {
        stop("You must supply an object of class lda from lda()")
    } else {
        if (class(obj) != "lda") {
            stop("You must supply an object of class lda from lda()")
        }
    }
    group <- as.factor(eval(obj$call[[3]]))
    fac.levels <- levels(group)
    x <- eval(obj$call[[2]])
    x1 <- subset(x, group==fac.levels[1])
    x2 <- subset(x, group==fac.levels[2])
    s1 <- cov(x1)
    s2 <- cov(x2)    
    cor1 <- cor(x1)
    cor2 <- cor(x2)
    n1 <- nrow(x1)
    n2 <- nrow(x2)
    n.vars <- ncol(x)
    V <- (1/(n1+n2-2))*(((n1-1)*s1)+((n2-1)*s2))
    Vcor <- (1/(n1+n2-2))*(((n1-1)*cor1)+((n2-1)*cor2))
    mu1 <- obj$means[1,]
    mu2 <- obj$means[2,]
    d2 <- mahalanobis(mu1, mu2, V)
    d <- sqrt(d2)
    t2 <- ((n1*n2)/(n1+n2)) * d2
    F.stat <- ((n1 + n2 - ((n.vars)+1)) / ((n1 + n2 - 2) * (n.vars-1))) * t2
    tmp <- list(s1 = s1, s2 = s2, V = V, Vcor = Vcor, d2 = d2, d = d, t2 =
t2, 	F.stat = F.stat, obj.call = obj$call, n.obs = obj$N, n1 = n1, n2 =
n2,
	mu1 = mu1, mu2 = mu2)
    return(tmp)
}

print.hotelling.t <- function(x, digits = max(3, getOption("digits") - 3),
na.print = "", 
    ...)
{
    ## Do the required calculations
    df1 <- ncol(x$V)
    df2 <- x$n.obs - (df1 + 1)
    p.F.stat <- 1 - pf(x$F.stat, df1 = df1, df2 = df2)
    inv.mat <- solve(x$V)
    means.diff <- x$mu1 - x$mu2
    lambda <- inv.mat %*% means.diff
    colnames(lambda) <- "lambda"
    rownames(lambda) <- colnames(x$V)
    
    ## Print the results
    cat("\nCall: ", deparse(x$call), "\n\n")
    cat("Pooled Variance-Covariance Matrix:", "\n\n")
    print.default(x$V, digits = digits)
    cat("\n")
    cat("Covariance Matrices:", "\n\n")
    cat("Group 1:", "\n")
    print.default(x$s1, digits = digits)
    cat("\n")
    cat("Group 2:", "\n")
    print.default(x$s2, digits = digits)
    cat("\n")
    cat("Pooled correlation matrix:", "\n\n")
    print.default(x$Vcor, digits = digits)
    cat("\n")
    cat("Mahanalobis Generalised distance \(d^2\):", x$d2, "\n")
    cat("Square root of Mahalanobis Distance:", x$d, "\n")
    cat("Hotelling's T^2:", x$t2, "\n")
    cat("F-value:", x$F.stat, "on", df1, "and", df2, "degrees of freedom\n")
    cat("p-value:", p.F.stat, "\n\n")
    cat("Variable means for Group 1:\n")
    print.default(x$mu1, digits = digits)
    cat("\nVariable means for Group 2:\n")
    print.default(x$mu2, digits = digits)
    cat("\n")
    cat("Coefficients of discriminant function:\n")
    print.default(lambda, digits=digits)
    cat("\nClassification success:\n")
    #print(table(predict(picea.lda)$class, picea[,1],
	dnn=c("Actual", "Predicted")))
}



From bates at stat.wisc.edu  Wed Feb 19 15:35:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed Feb 19 15:35:03 2003
Subject: [R] nls
In-Reply-To: <200302190432.h1J4WAq03928@mailer.cacs.louisiana.edu>
References: <200302190432.h1J4WAq03928@mailer.cacs.louisiana.edu>
Message-ID: <6rel64s5kf.fsf@bates4.stat.wisc.edu>

Komanduru Sai C <sck2348 at cacs.louisiana.edu> writes:

> Hi,
> 
> I am using nls library
> 
> df <- read.table("data.txt", header=T);						
> library(nls);
> fm <- nls(y ~ a*(x+d)^(-b), df, start=list(a=max(df->y,na.rm=T)/2,b=1,d=0));
> coef(fm); 
> q();

1) Are you sure you meant max(df->y, na.rm=TRUE) and not 
   max(df$y, na.rm=TRUE)? 

2) To begin you may want to use a data frame without the missing data
   df1 = na.omit(df[, 1:2])

3) Use the plinear algorithm and change from b to exp(lb)

   fm = nls(y ~ (x+d)^(-exp(lb)), data = df1, start=c(lb = 0, d = 0),
            alg = 'plinear', trace = TRUE)

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From kawa at aris.ss.uci.edu  Wed Feb 19 15:47:06 2003
From: kawa at aris.ss.uci.edu (Hiroyuki Kawakatsu)
Date: Wed Feb 19 15:47:06 2003
Subject: [R] working with list
Message-ID: <Pine.GSO.4.30.0302190610570.20765-100000@aris.ss.uci.edu>

hi,

i have two questions:
(1) lookup: given a list of 'strings' in a list, i want to know the index
of a given string in the list. if the string is not in the list, the index
can be 0 or length()+1. for example, suppose i have
names <- c("dog", "cat", "pig", "fish");
then i want
lookup(names, "cat") to return 2 and
lookup(names, "ant") to return 0 (or 5)

i am currently doing this in a for loop with a break using identical().
however, since i call this function repeatedly, i am wondering whether
there is a more efficient way of doing this.

(2) combining lists: when lists are combined, the higher level list
structure appears to be lost. what i mean is, suppose i have two lists
with the same structure
a <- list(name="foo", year=1989, grade="A");
b <- list(name="bar", year=2000, grade="B+");
then when i combine the two lists into one
ab <- c(a, b);
length(ab) returns length(a)+length(b), not 2.

given a list of lists, is there any way i can loop through each
list and work with the named components in each list? it seems that i need
to know the length of each list and the order each component appears in
the list to work with the combined list. the solution i am currently using
is not to combine the list but use ... in a function argument and to
extract each list by:

foo <- function(...) {
   args <- list(...);
   for (i in 1:length(args)) {
      #extract i-th list
      tmp <- args[[i]];
   }
}

h.
--------------------------------------------------------------------
Time series regression studies give no sign of converging toward the
truth. (Phillip Cagan)



From Charles.Annis at statisticalengineering.com  Wed Feb 19 15:58:02 2003
From: Charles.Annis at statisticalengineering.com (Charles Annis, P.E.)
Date: Wed Feb 19 15:58:02 2003
Subject: [R] Pretty onscreen plots?
In-Reply-To: <Pine.GSO.4.31.0302190738470.366-100000@toucan.stats>
Message-ID: <008501c2d827$2144db00$0202a8c0@DHT0TL11>

I find the Windows metafile works quite well if you size the graphic in
R before right-clicking and copying as a metafile.  Resizing in
PowerPoint sometimes produces undesirable font characteristics.  Getting
the size and aspect ratio the way you want it in R, by dragging the
grapic's edges, avoids that.

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFAX: 503-217-5849
http://www.StatisticalEngineering.com


-----Original Message-----
From: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Prof Brian Ripley
Sent: Wednesday, February 19, 2003 2:43 AM
To: Andrew C. Ward
Cc: Falcon, Seth; r-help at stat.math.ethz.ch
Subject: Re: [R] Pretty onscreen plots?

I use PDF and make my presentations in PDF using pdflatex, or even in
postscript and Distiller.  That way the final document has vector
graphics, and bitmapping only occurs at the very last minute, when the
projector resolution is known.

In theory win.metafile should do the same for powerpoint, but in
practice
it is not as good.  Probably the metafile graphics driver could be
improved ....

On Wed, 19 Feb 2003, Andrew C. Ward wrote:

> Seth,
>
> The R functions png(), jpg() and bmp() will generate files that can be
used in
> PowerPoint. Previews can be added to postscript files, using Ghostview
and
> ImageMagik among others. I have done the latter in the past since the
> postscript files are of an excellent standard, and because I've wanted
both to
> display and print a report. Having separate viewing and printing
versions of
> graphs is not very convenient.
>
>
> Regards,
>
> Andrew C. Ward
>
> CAPE Centre
> Department of Chemical Engineering
> The University of Queensland
> Brisbane Qld 4072 Australia
> andreww at cheque.uq.edu.au
>
>
>
> Quoting "Falcon, Seth" <sfalcon at fhcrc.org>:
>
> > I'm looking for ideas for creating high-quality plots for use in
projected
> > presentations (powerpoint, etc) --- ideally high-quality png, jpg,
bmp.
> >
> > The graphics produced using the postscript device look very good.
Those
> > generated with win.graph(), png are plagued by the jaggy lines.
> >
> > So far, the only way I can use the postscript plots in my
presentations is
> > using separate screen capture software.  Can someone suggest a
better way?
> >
> > Thanks,
> >
> > + seth
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gavin.simpson at ucl.ac.uk  Wed Feb 19 16:07:03 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed Feb 19 16:07:03 2003
Subject: [R] getting/storing the name of an object passed to a function
In-Reply-To: <000a01c2d821$323cf010$4c202880@gsimpson>
Message-ID: <000d01c2d828$d0240c30$4c202880@gsimpson>

Dear List,

Thanks to Patrick Burns I have now have the answer to my problem.

getting the name and storing it in a variable is done by:

obj.nam <- deparse(substitute(obj))

getting the object back out using its name is done by:

get(obj.nam)

To actually use the entity that is described by obj.nam I then wrapped get()
in eval().  The final line of code now looks like this:

print(table(predict(get(x$obj.nam))$class, eval(get(x$obj.nam)$call[[3]]),
dnn=c("Actual", "Predicted")))

Which does exactly what I wanted it to.

Many thanks

Gavin Simpson

-----Original Message-----
From: r-help-admin at stat.math.ethz.ch [mailto:r-help-admin at stat.math.ethz.ch]
On Behalf Of Gavin Simpson
Sent: 19 February 2003 14:14
To: 'r-help'
Subject: [R] getting/storing the name of an object passed to a function


Hi

I have a couple of functions that work on the object created by another R
command and then print out or summarise the results of this work.

The main function is defined as:

hotelling.t <- function(obj)
{
	#internal commands
}

I then have print.hotelling.t() that takes the list returned by hotelling.t
and prints it with some extra significance calculations, formatting, etc.

I want to then use the named object in another calculation in
print.hotelling.t() , that only gets done/printed if you ask for it in the
call to print.hotelling.t()

How do I store the name of the object obj passed to hotelling.t in the
object returned by hotelling.t?

And how do I "paste" the name of that object into a call to another R
function within my print.hotelling.t()?

Perhaps this is not the best way to do things in R?  So any comments would
be most appreciated.

By the way, the object obj is of class lda (Package MASS), if that matters.
Functions appended below.  R 1.6.2 on windows XP.

Many Thanks

Gavin Simpson

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rossini at blindglobe.net  Wed Feb 19 16:11:03 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed Feb 19 16:11:03 2003
Subject: [R] PL/R - R procedural language handler for PostgreSQL
In-Reply-To: <Pine.GSO.4.31.0302190730220.366-100000@toucan.stats> (Prof
 Brian Ripley's message of "Wed, 19 Feb 2003 07:37:55 +0000 (GMT)")
References: <Pine.GSO.4.31.0302190730220.366-100000@toucan.stats>
Message-ID: <87wujwtk1j.fsf@jeeves.blindglobe.net>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:


> On Tue, 18 Feb 2003, Joe Conway wrote:

>> Is there a desire to get R to build under Cygwin, or is it preferable to
>> put any effort into the Windows port?
>
> Clearly there is some interest (or Tony Rossini would not be trying),
> but I don't see any desire to maintain R under Cygwin: it's an ongoing
> commitment to keep it working that would be needed.

It's amusing, and there are reasons for ME to be interested in it, but
I think the reasons for constructing a Cygwin port are not pragmatic,
given that Rterm exists and works.

> In my experience Windows users want a Windows interface (and especially
> Windows filenames), not a somewhat-like-Unix one.

This is exactly the point.  All but a negligible few unix-"primary"
users who want a unix interface under Windows should be satisfied by
the current Rterm.

(it would be "nice" to have a cygwin port, it would solve some of the
config and potential licensing (redistribution of ActivePerl) issues
with Perl, etc, but this is a case of causing more pain to save a
minimal amount of time and some documentation reading).

I shouldn't be so negative; it WOULD be a nice thing to have someone
do it.  It just probably won't be me to finish it.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From marcosrr at usc.es  Wed Feb 19 16:23:02 2003
From: marcosrr at usc.es (Marcos R. Rey)
Date: Wed Feb 19 16:23:02 2003
Subject: [R] Multiple Logit/Probit
Message-ID: <NHBBIDADOLEPBBCEEHPOCEAGCAAA.marcosrr@usc.es>

Does anybody know how to do multiple logit/probit analysis with R?

Thanks in advance!



From tblackw at umich.edu  Wed Feb 19 16:27:04 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed Feb 19 16:27:04 2003
Subject: [R] working with list
In-Reply-To: <Pine.GSO.4.30.0302190610570.20765-100000@aris.ss.uci.edu>
Message-ID: <Pine.SOL.4.44.0302191017410.13255-100000@robotron.gpcc.itd.umich.edu>

Three quick answers:

(1) function  match("cat", names, 0)  would return 2.
(2) syntax  list(a,b)  would return a list of lists with length 2.
(3) syntax  unlist(lapply(ab, function(x) x[["year"]]))
    would return a vector equal to  c(1989,2000).

See the interactive help for each of these functions.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



On Wed, 19 Feb 2003, Hiroyuki Kawakatsu wrote:

> hi,
>
> i have two questions:
> (1) lookup: given a list of 'strings' in a list, i want to know the index
> of a given string in the list. if the string is not in the list, the index
> can be 0 or length()+1. for example, suppose i have
> names <- c("dog", "cat", "pig", "fish");
> then i want
> lookup(names, "cat") to return 2 and
> lookup(names, "ant") to return 0 (or 5)
>
> i am currently doing this in a for loop with a break using identical().
> however, since i call this function repeatedly, i am wondering whether
> there is a more efficient way of doing this.
>
> (2) combining lists: when lists are combined, the higher level list
> structure appears to be lost. what i mean is, suppose i have two lists
> with the same structure
> a <- list(name="foo", year=1989, grade="A");
> b <- list(name="bar", year=2000, grade="B+");
> then when i combine the two lists into one
> ab <- c(a, b);
> length(ab) returns length(a)+length(b), not 2.
>
> given a list of lists, is there any way i can loop through each
> list and work with the named components in each list? it seems that i need
> to know the length of each list and the order each component appears in
> the list to work with the combined list. the solution i am currently using
> is not to combine the list but use ... in a function argument and to
> extract each list by:
>
> foo <- function(...) {
>    args <- list(...);
>    for (i in 1:length(args)) {
>       #extract i-th list
>       tmp <- args[[i]];
>    }
> }
>
> h.
> --------------------------------------------------------------------
> Time series regression studies give no sign of converging toward the
> truth. (Phillip Cagan)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Wed Feb 19 16:33:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb 19 16:33:03 2003
Subject: [R] getting/storing the name of an object passed to a function
In-Reply-To: <000d01c2d828$d0240c30$4c202880@gsimpson>
Message-ID: <Pine.LNX.4.44.0302191526050.26895-100000@gannet.stats>

Here's a comment I wrote that has not come through yet (and there is an 
engineer working on my mail server so it may be delayed/lost):

Use  objname <- deparse(substitute(obj))

at the top of hotelling.t, and make objname part of the returned list.

Another way is to capture the call by

        Call <- match.call()

pass that on and look at it in the print function.

However, if you really want the object and not its name, it is better to
pass the object.  Otherwise I could do

fit.lda <- lda(...)
hT <- hotelling.t(fit.lda)
fit.lda <- update(fit.lda, ....)
hT

and that would I suspect not be what you want.


More generally, get() is dangerous, and I am pretty sure you don't want to
start the get() search inside your function nor do you want to eval()
there.  There is a real danger of getting the wrong objects.



On Wed, 19 Feb 2003, Gavin Simpson wrote:

> Dear List,
> 
> Thanks to Patrick Burns I have now have the answer to my problem.
> 
> getting the name and storing it in a variable is done by:
> 
> obj.nam <- deparse(substitute(obj))
> 
> getting the object back out using its name is done by:
> 
> get(obj.nam)
> 
> To actually use the entity that is described by obj.nam I then wrapped get()
> in eval().  The final line of code now looks like this:
> 
> print(table(predict(get(x$obj.nam))$class, eval(get(x$obj.nam)$call[[3]]),
> dnn=c("Actual", "Predicted")))
> 
> Which does exactly what I wanted it to.
> 
> Many thanks
> 
> Gavin Simpson
> 
> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch [mailto:r-help-admin at stat.math.ethz.ch]
> On Behalf Of Gavin Simpson
> Sent: 19 February 2003 14:14
> To: 'r-help'
> Subject: [R] getting/storing the name of an object passed to a function
> 
> 
> Hi
> 
> I have a couple of functions that work on the object created by another R
> command and then print out or summarise the results of this work.
> 
> The main function is defined as:
> 
> hotelling.t <- function(obj)
> {
> 	#internal commands
> }
> 
> I then have print.hotelling.t() that takes the list returned by hotelling.t
> and prints it with some extra significance calculations, formatting, etc.
> 
> I want to then use the named object in another calculation in
> print.hotelling.t() , that only gets done/printed if you ask for it in the
> call to print.hotelling.t()
> 
> How do I store the name of the object obj passed to hotelling.t in the
> object returned by hotelling.t?
> 
> And how do I "paste" the name of that object into a call to another R
> function within my print.hotelling.t()?
> 
> Perhaps this is not the best way to do things in R?  So any comments would
> be most appreciated.
> 
> By the way, the object obj is of class lda (Package MASS), if that matters.
> Functions appended below.  R 1.6.2 on windows XP.
> 
> Many Thanks
> 
> Gavin Simpson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gavin.simpson at ucl.ac.uk  Wed Feb 19 16:49:03 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed Feb 19 16:49:03 2003
Subject: [R] getting/storing the name of an object passed to a function
In-Reply-To: <Pine.LNX.4.44.0302191526050.26895-100000@gannet.stats>
Message-ID: <000f01c2d82e$bac7d9b0$4c202880@gsimpson>

Hi,

As usual Prof. Ripley has delved a little deeper into the question and
pointed out that whilst my functions might be doing/printing what I wanted
them to do, they might not do if the object was updated AFTER using
hotelling.t!  See Prof. Ripley's reply below.

This was something I wasn't even close to considering, so thank you for
pointing this out.  I'll opt for the safe option and pass the bits I
actually require between functions rather than just the name.

All the best,

Gavin

-----Original Message-----
From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk] 
Sent: 19 February 2003 15:33
To: Gavin Simpson
Cc: 'r-help'
Subject: RE: [R] getting/storing the name of an object passed to a function


Here's a comment I wrote that has not come through yet (and there is an 
engineer working on my mail server so it may be delayed/lost):

Use  objname <- deparse(substitute(obj))

at the top of hotelling.t, and make objname part of the returned list.

Another way is to capture the call by

        Call <- match.call()

pass that on and look at it in the print function.

However, if you really want the object and not its name, it is better to
pass the object.  Otherwise I could do

fit.lda <- lda(...)
hT <- hotelling.t(fit.lda)
fit.lda <- update(fit.lda, ....)
hT

and that would I suspect not be what you want.


More generally, get() is dangerous, and I am pretty sure you don't want to
start the get() search inside your function nor do you want to eval()
there.  There is a real danger of getting the wrong objects.



On Wed, 19 Feb 2003, Gavin Simpson wrote:

> Dear List,
> 
> Thanks to Patrick Burns I have now have the answer to my problem.
> 
> getting the name and storing it in a variable is done by:
> 
> obj.nam <- deparse(substitute(obj))
> 
> getting the object back out using its name is done by:
> 
> get(obj.nam)
> 
> To actually use the entity that is described by obj.nam I then wrapped
get()
> in eval().  The final line of code now looks like this:
> 
> print(table(predict(get(x$obj.nam))$class, eval(get(x$obj.nam)$call[[3]]),
> dnn=c("Actual", "Predicted")))
> 
> Which does exactly what I wanted it to.
> 
> Many thanks
> 
> Gavin Simpson
> 
> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]
> On Behalf Of Gavin Simpson
> Sent: 19 February 2003 14:14
> To: 'r-help'
> Subject: [R] getting/storing the name of an object passed to a function
> 
> 
> Hi
> 
> I have a couple of functions that work on the object created by another R
> command and then print out or summarise the results of this work.
> 
> The main function is defined as:
> 
> hotelling.t <- function(obj)
> {
> 	#internal commands
> }
> 
> I then have print.hotelling.t() that takes the list returned by
hotelling.t
> and prints it with some extra significance calculations, formatting, etc.
> 
> I want to then use the named object in another calculation in
> print.hotelling.t() , that only gets done/printed if you ask for it in the
> call to print.hotelling.t()
> 
> How do I store the name of the object obj passed to hotelling.t in the
> object returned by hotelling.t?
> 
> And how do I "paste" the name of that object into a call to another R
> function within my print.hotelling.t()?
> 
> Perhaps this is not the best way to do things in R?  So any comments would
> be most appreciated.
> 
> By the way, the object obj is of class lda (Package MASS), if that
matters.
> Functions appended below.  R 1.6.2 on windows XP.
> 
> Many Thanks
> 
> Gavin Simpson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kuehn at halle.ufz.de  Wed Feb 19 16:55:07 2003
From: kuehn at halle.ufz.de (Ingolf Kuehn)
Date: Wed Feb 19 16:55:07 2003
Subject: [R] RODBC  problems
Message-ID: <3E53B4C5.8979.8B1F0D@localhost>

Hello,

I successfully used RODBC very frequently, but after having updatetd to R 6.0.2, the 
current RODBC-Version gives me some problems.

After connecting to my Oracle-Database via odbcConnect("") (or the necessary 
information) I receive a much longer output than usual:

RODB Connection 0
Details:
  case=nochange
  DRIVER={Oracle in OraHome90}
...

with all the details.

Previously, I just received my connection number (channel).

When I try to get data, now, I get an error, e.g.

> odbcTables(0)
Error in odbcTables(0) : first argument is not an open RODBC channel

However, I use the same DSN as ever and it works perfectly from MS-Query, MS-
Access and Quest-Toad to connect to Oracle

My machine is a Pentium 3 with Windows XP.

Any help or suggestions are appreciated!

Thanks a lot

Ingolf Kuehn


================================================
Dr. Ingolf Kuehn
UFZ - Umweltforschungszentrum Leipzig-Halle GmbH
- Sektion Biozoenoseforschung -
UFZ - Centre for Environmental Research
- Department of Community Ecology -
Theodor-Lieser-Strasse 4
06120 Halle
Germany
Tel (+49)345 / 558 5311
Fax (+49)345 / 558 5329
email: kuehn at halle.ufz.de
http://www.ufz.de/spb/bioz/



From brahm at alum.mit.edu  Wed Feb 19 17:00:09 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Wed Feb 19 17:00:09 2003
Subject: [R] functions different in R and S
Message-ID: <15955.43359.684172.546604@gargle.gargle.HOWL>

Helen Yang <Huiqin.Yang at noaa.gov> wrote:
> I wonder whether there is any resource that can point to useful substitutes
> for S functions that are not recognized by R.  At the same time whether there
> is a list of functions, which appear in both R and S but which don't do
> exactly the same thing.

As Prof. Brian D. Ripley <ripley at stats.ox.ac.uk> said, see the FAQ at:
  <http://www.r-project.org/> (Click "FAQs", "R FAQ", "R and S".)

Here are my own crib notes on some differences that I care about.  Note "S"
here really means S-Plus version 6.1.2.  I have not checked whether any of
these have changed since October.  This list is certainly not complete.

                     ***   R vs. S (DB 10/28/02)  ***

Language differences:
- Scoping rules differ.  In R, functions see the functions they're in.  Try:
    f1 <- function() {x <- 1; f2 <- function() print(x); f2()};  f1()
- Data must be loaded explicitly in R, can be attach()'ed in S.
    Addressed by my contributed package "g.data".
- R has a character-type NA, so LETTERS[c(NA,2)] = c(NA,"B") not c("","B")
- paste("a","b", sep="|", sep=".") is an error in R; ok in S.
- for() loops more efficient in R.

Graphics differences:
- Log scale indicated in S with par(xaxt)=="l", in R with par("xlog")==T.
- R has cex.main, col.lab, font.axis, etc.  Thus title("Hi", cex=4) fails.
- R has plotmath and Hershey vector fonts.
- R has palette(rainbow(10)) to define colors (both screen and printer).

Functions missing from R:
- unpaste, slice.index, colVars

Functions missing from S:
- strsplit, sub, gsub, chartr, formatC

Functions that work differently:
- system() has no "input" argument in R.
- substring(s,"x") <- "X" only works in S, but R has s <- gsub("x","X",s).
- scan expects numbers by default in R.
- which(<numeric>) converts to logical in S, is an error in R.
- The NULL returned by if(F){...} is invisible in R, visible in S.
- The NULL returned by return() is visible in R, invisible in S.
- Args to "var" differ, and R has "cov".  S na.method="a" ~ R use="p".
- var (or cov) drops dimensions in S, not R.
- cut allows labels=F in R, not in S (also left.include=T becomes right=F).
- Last argument of a replacement function must be named "value" in R.
- tapply(1:3, c("a","b","a"), sum) is a 1D-array in R, a vector in S.

-- 
                              -- David Brahm (brahm at alum.mit.edu)



From brahm at alum.mit.edu  Wed Feb 19 17:07:03 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Wed Feb 19 17:07:03 2003
Subject: [R] Pretty onscreen plots?
Message-ID: <15955.43898.702289.618149@gargle.gargle.HOWL>

Seth Falcon <sfalcon at fhcrc.org> wrote:
> I'm looking for ideas for creating high-quality plots for use in projected
> presentations (powerpoint, etc) --- ideally high-quality png, jpg, bmp.

I recently struggled with the problem of generating plots from R on Unix that
could be used in PowerPoint on Windows.  I learned that "png" format works
reasonably well, but the default resolution from png() was inadequate.  I ended
up using:

  bitmap("myfile.png", type="png16m", height=8.5, width=11, res=300)

and you might try even higher resolutions (res=600).
-- 
                              -- David Brahm (brahm at alum.mit.edu)



From gregory_s_steeno at groton.pfizer.com  Wed Feb 19 17:29:03 2003
From: gregory_s_steeno at groton.pfizer.com (Steeno, Gregory S)
Date: Wed Feb 19 17:29:03 2003
Subject: [R] Nested Design Coding Question
Message-ID: <C735670CCC69D61193DA0002A58EE99002C8DA95@groexmb07.pfizer.com>

I'm a SAS user who is slowly but surely migrating over to R.  I'm trying to
find the proper code to analyze a nested design.  I  have four
classification variables, L (fixed), A (random within L), D (random within
L), and I (random within L).  The model I'm interested in is

L A(L) D(L) I(L) A:D:I(L),

where the interaction is interpreted as the lack-of-fit term.  I've tried
variants of the lme function similar to these,

lme(response~L, data, random=~Lab/(A+L+I+A:D:I),
lme(response~1, data, random=~Lab/(A+L+I+A:D:I),
lme(response~L, data, random=~1/(A+L+I+A:D:I).

All give results different from SAS, and all give warning messages regarding
either false- or non-convergence.

For reference, the abbreviated SAS code is,

model response = L;
random A(L) D(L) I(L) A:D:I(L);

Can anyone shed some light?  I'd be very appreciative.

Thanks.

Greg Steeno









LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From ligges at statistik.uni-dortmund.de  Wed Feb 19 17:34:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Feb 19 17:34:03 2003
Subject: [R] RODBC  problems
In-Reply-To: <3E53B4C5.8979.8B1F0D@localhost>
References: <3E53B4C5.8979.8B1F0D@localhost>
Message-ID: <3E53B134.40304@statistik.uni-dortmund.de>

Ingolf Kuehn wrote:
> Hello,
> 
> I successfully used RODBC very frequently, but after having updatetd to R 6.0.2, the 
> current RODBC-Version gives me some problems.
> 
> After connecting to my Oracle-Database via odbcConnect("") (or the necessary 
> information) I receive a much longer output than usual:
> 
> RODB Connection 0
> Details:
>   case=nochange
>   DRIVER={Oracle in OraHome90}
> ...
> 
> with all the details.
> 
> Previously, I just received my connection number (channel).
> 
> When I try to get data, now, I get an error, e.g.
> 
> 
>>odbcTables(0)
> 
> Error in odbcTables(0) : first argument is not an open RODBC channel


Reading, e.g., ?odbcTables helps:

You have to specify the 'channel', which is a 'connection handle as 
returned by odbcConnect() of class "RODBC"', but not any integer.

Uwe Ligges


> However, I use the same DSN as ever and it works perfectly from MS-Query, MS-
> Access and Quest-Toad to connect to Oracle
> 
> My machine is a Pentium 3 with Windows XP.
> 
> Any help or suggestions are appreciated!
> 
> Thanks a lot
> 
> Ingolf Kuehn
> 
> 
> ================================================
> Dr. Ingolf Kuehn
> UFZ - Umweltforschungszentrum Leipzig-Halle GmbH
> - Sektion Biozoenoseforschung -
> UFZ - Centre for Environmental Research
> - Department of Community Ecology -
> Theodor-Lieser-Strasse 4
> 06120 Halle
> Germany
> Tel (+49)345 / 558 5311
> Fax (+49)345 / 558 5329
> email: kuehn at halle.ufz.de
> http://www.ufz.de/spb/bioz/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Wed Feb 19 17:40:03 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed Feb 19 17:40:03 2003
Subject: [R] working with list
In-Reply-To: <Pine.GSO.4.30.0302190610570.20765-100000@aris.ss.uci.edu>
Message-ID: <3E537ADF.17647.2F1FA8@localhost>

On 19 Feb 2003 at 6:46, Hiroyuki Kawakatsu wrote:

Is this what you want:

> names <- c("dog",
+ "cat", "pig", "fish");
> names
[1] "dog"  "cat"  "pig"  "fish"
> which(names=="cat")
[1] 2
> which(names=="ant")
numeric(0)
> lookup <- function(db, item) {
+    res <- which(db==item)
+    if (length(res)==0) res <- 0
+    res}
> lookup(names, "cat")
[1] 2
> lookup(names, "ant")
[1] 0


> hi,
> 
> i have two questions:
> (1) lookup: given a list of 'strings' in a list, i want to know the index
> of a given string in the list. if the string is not in the list, the index
> can be 0 or length()+1. for example, suppose i have
> names <- c("dog", "cat", "pig", "fish");
> then i want
> lookup(names, "cat") to return 2 and
> lookup(names, "ant") to return 0 (or 5)
> 
> i am currently doing this in a for loop with a break using identical().
> however, since i call this function repeatedly, i am wondering whether
> there is a more efficient way of doing this.
> 
> (2) combining lists: when lists are combined, the higher level list
> structure appears to be lost. what i mean is, suppose i have two lists
> with the same structure
> a <- list(name="foo", year=1989, grade="A");
> b <- list(name="bar", year=2000, grade="B+");
> then when i combine the two lists into one
> ab <- c(a, b);
> length(ab) returns length(a)+length(b), not 2.

so you want ab <- list(a,b)

> 
> given a list of lists, is there any way i can loop through each
> list and work with the named components in each list? it seems that i need
> to know the length of each list and the order each component appears in
> the list to work with the combined list. the solution i am currently using
> is not to combine the list but use ... in a function argument and to
> extract each list by:
> 
> foo <- function(...) {
>    args <- list(...);
>    for (i in 1:length(args)) {
>       #extract i-th list
>       tmp <- args[[i]];
>    }
> }
> 
> h.
> --------------------------------------------------------------------
> Time series regression studies give no sign of converging toward the
> truth. (Phillip Cagan)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jfox at mcmaster.ca  Wed Feb 19 17:52:03 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed Feb 19 17:52:03 2003
Subject: [R] Multiple Logit/Probit
In-Reply-To: <NHBBIDADOLEPBBCEEHPOCEAGCAAA.marcosrr@usc.es>
Message-ID: <5.0.2.1.0.20030219112259.00af2740@mcmail.cis.mcmaster.ca>

Dear Marcos,

At 04:21 PM 2/19/2003 -0600, Marcos R. Rey wrote:
>Does anybody know how to do multiple logit/probit analysis with R?

Assuming that I'm interpreting the question correctly, the multnom function 
in the nnet package fits the multinomial logistic regression model, and the 
polr function in the MASS package fits the proportional-odds (ordered) 
logistic regression model.

I don't believe that there's an implementation on CRAN of multinomial or 
ordered probit models, though I do recall previous discussion of these on 
the list, so searching the list archive might prove helpful.

John

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From andrejk at zrc-sazu.si  Wed Feb 19 18:48:02 2003
From: andrejk at zrc-sazu.si (Andrej Kveder)
Date: Wed Feb 19 18:48:02 2003
Subject: [R] simulating correlated vars
Message-ID: <FHEEJBDDCNPPNJEACDJACEIECJAA.andrejk@zrc-sazu.si>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030219/fdab639d/attachment.pl

From spencer.graves at pdf.com  Wed Feb 19 18:59:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed Feb 19 18:59:06 2003
Subject: [R] functions different in R and S
References: <15955.43359.684172.546604@gargle.gargle.HOWL>
Message-ID: <3E53C3E0.3040508@pdf.com>

Also, many of the probability distribution functions are better in R
1.6.2 than in S-Plus 6.1.  For example, in R, most of the functions will
work with the logarithm of the probability (or density) using argument
"log.x";  S does not have this argument.Simularly, probability functions 
that could have a noncentrality parameter are more likely to have it in 
R than in S-Plus.

I had trouble over a year ago with numerical precision with some 
probability functions in S-Plus 2000, but I can't recall the details 
now.  If you are estimating degrees of freedom in Student's t 
distribution, e.g., to model kurtosis, you don't want the functions to 
malfunction for unusual values of the argument df.  I just sent S-Plus 
6.1 into an incredibly long computation with pt(-1.96, df=1e99);  R 
returned a sensible answer immediately.  If you are trying to estimate 
df numerically, it is better not to have this.

Spencer Graves

David Brahm wrote:
 > Helen Yang <Huiqin.Yang at noaa.gov> wrote:
 >
 >>I wonder whether there is any resource that can point to useful 
substitutes
 >>for S functions that are not recognized by R.  At the same time 
whether there
 >>is a list of functions, which appear in both R and S but which don't do
 >>exactly the same thing.
 >
 >
 > As Prof. Brian D. Ripley <ripley at stats.ox.ac.uk> said, see the FAQ at:
 >   <http://www.r-project.org/> (Click "FAQs", "R FAQ", "R and S".)
 >
 > Here are my own crib notes on some differences that I care about. 
Note "S"
 > here really means S-Plus version 6.1.2.  I have not checked whether 
any of
 > these have changed since October.  This list is certainly not complete.
 >
 >                      ***   R vs. S (DB 10/28/02)  ***
 >
 > Language differences:
 > - Scoping rules differ.  In R, functions see the functions they're 
in.  Try:
 >     f1 <- function() {x <- 1; f2 <- function() print(x); f2()};  f1()
 > - Data must be loaded explicitly in R, can be attach()'ed in S.
 >     Addressed by my contributed package "g.data".
 > - R has a character-type NA, so LETTERS[c(NA,2)] = c(NA,"B") not 
c("","B")
 > - paste("a","b", sep="|", sep=".") is an error in R; ok in S.
 > - for() loops more efficient in R.
 >
 > Graphics differences:
 > - Log scale indicated in S with par(xaxt)=="l", in R with par("xlog")==T.
 > - R has cex.main, col.lab, font.axis, etc.  Thus title("Hi", cex=4) 
fails.
 > - R has plotmath and Hershey vector fonts.
 > - R has palette(rainbow(10)) to define colors (both screen and printer).
 >
 > Functions missing from R:
 > - unpaste, slice.index, colVars
 >
 > Functions missing from S:
 > - strsplit, sub, gsub, chartr, formatC
 >
 > Functions that work differently:
 > - system() has no "input" argument in R.
 > - substring(s,"x") <- "X" only works in S, but R has s <- 
gsub("x","X",s).
 > - scan expects numbers by default in R.
 > - which(<numeric>) converts to logical in S, is an error in R.
 > - The NULL returned by if(F){...} is invisible in R, visible in S.
 > - The NULL returned by return() is visible in R, invisible in S.
 > - Args to "var" differ, and R has "cov".  S na.method="a" ~ R use="p".
 > - var (or cov) drops dimensions in S, not R.
 > - cut allows labels=F in R, not in S (also left.include=T becomes 
right=F).
 > - Last argument of a replacement function must be named "value" in R.
 > - tapply(1:3, c("a","b","a"), sum) is a 1D-array in R, a vector in S.
 >



From a.shipunov at rbgkew.org.uk  Wed Feb 19 19:33:02 2003
From: a.shipunov at rbgkew.org.uk (Alexey Shipunov)
Date: Wed Feb 19 19:33:02 2003
Subject: [R] Help in separate window under X11
Message-ID: <3E53CDB4.20009.64559B@localhost>

Dear R users,

Is there the possibitily in R under X11 to get (after typing help(...) 
command) separate help window, as it is in Windows version?

Best wishes,


=================================
Dr. Alexey B. Shipunov
Section of Molecular Systematics
Jodrell Laboratory
Royal Botanic Gardens, Kew,
Richmond, Surrey, TW9 3DS, U.K.
e-mail: a.shipunov at rbgkew.org.uk



From mkondrin at hppi.troitsk.ru  Wed Feb 19 19:39:53 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Wed Feb 19 19:39:53 2003
Subject: [R] fitting a curve according to a custom loss function
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BCC2@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD534BCC2@usrymx25.merck.com>
Message-ID: <3E5467A6.2060001@hppi.troitsk.ru>

>
>
>Note that Vadim said he wanted to find f().  You're assuming f() is known.
>
>The model is very strange (to me, at least).  It's not obvious to me that
>it's even identifiable.  (Sorry that I don't have anything constructive to
>add.)
>
>Andy
> 
>  
>
Yes, I have missed the point.

But if you have a grid in (x_1,x_2) plane and y[i,j] values in the 
nodes  (or you can interpolate an irregularly spaced data) then you may 
solve your problem with Fourier transform, get fourier coefficients and 
find your function (i.e tabulated values) with inverse fourier transform.
Precisely it would look like that
Suppose there is a square grid in plane. Your model is 
y[i,j]=a0+a*(z<-cbind(c(f1,f2,f3...fn), c(f1,f2,f3,...fn)....))+t(z), 
i,j<N (because function f(x) is a table then may painlessly suppose that 
a2 is included in it). Then you convolve row-wise and column-wise y[i,j] 
with sin(2*pi*w*i/N), cos(...) (w<N). "Best-fit" Fourier coefficient 
(with multiplier "a" for columnwise convolution) is an average of vector 
you got after convolution.   a0 may be found then convolving with 1 
(i.e. just calculate average). After you got all coefficients "a" may be 
found with linear fit and (fi) with inverse fourier transform.
Fourier transform is little tricky when dealing with partial sums (with 
truncated series) because a result is not always smooth although in 
theory it should be, but why not give it a try.



From bates at stat.wisc.edu  Wed Feb 19 19:43:29 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed Feb 19 19:43:29 2003
Subject: [R] Nested Design Coding Question
In-Reply-To: <C735670CCC69D61193DA0002A58EE99002C8DA95@groexmb07.pfizer.com>
References: <C735670CCC69D61193DA0002A58EE99002C8DA95@groexmb07.pfizer.com>
Message-ID: <6risvgqfot.fsf@bates4.stat.wisc.edu>

"Steeno, Gregory S" <gregory_s_steeno at groton.pfizer.com> writes:

> I'm a SAS user who is slowly but surely migrating over to R.  I'm trying to
> find the proper code to analyze a nested design.  I  have four
> classification variables, L (fixed), A (random within L), D (random within
> L), and I (random within L).  The model I'm interested in is
> 
> L A(L) D(L) I(L) A:D:I(L),
> 
> where the interaction is interpreted as the lack-of-fit term.  I've tried
> variants of the lme function similar to these,
> 
> lme(response~L, data, random=~Lab/(A+L+I+A:D:I),
> lme(response~1, data, random=~Lab/(A+L+I+A:D:I),
> lme(response~L, data, random=~1/(A+L+I+A:D:I).
> 
> All give results different from SAS, and all give warning messages regarding
> either false- or non-convergence.
> 
> For reference, the abbreviated SAS code is,
> 
> model response = L;
> random A(L) D(L) I(L) A:D:I(L);
> 
> Can anyone shed some light?  I'd be very appreciative.

You can use lme to fit models with crossed random effects like this
but not easily.  The algorithms for lme are tuned for nested random
effects.  If you have A random within L, you must first establish a
unique set of levels for the factor

data$aL = getGroups(data, ~ 1 | L/A, level = 2)
data$dL = getGroups(data, ~ 1 | L/D, level = 2)
data$iL = getGroups(data, ~ 1 | L/I, level = 2)

Then you must establish an artificial grouping factor with only one level

data$grp = as.factor(rep(1, nrow(data)))

Once you have the artifical grouping factor you create a blocked
variance-covariance matrix whose blocks are multiples of the identity
applied to indicator variables.  In R the indicators for a factor are
generated from a formula like ~ aL - 1.  (By the way, D and I are poor
choices for variable names - see Venables and Ripley (Springer, 2002,
p. 13).)

Putting it all together provides the highly unintuitive function call

fm = lme(response ~ L, data, random = list(
 grp = pdBlocked(list(pdIdent(~ aL - 1),
                    pdIdent(~ dL - 1),
                    pdIdent(~ iL - 1),
                    pdIdent(~ aL:dL:iL - 1))))


-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From ben at zoo.ufl.edu  Wed Feb 19 19:47:04 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Wed Feb 19 19:47:04 2003
Subject: [R] Help in separate window under X11
In-Reply-To: <3E53CDB4.20009.64559B@localhost>
Message-ID: <Pine.LNX.4.44.0302191354210.19622-100000@bolker.zoo.ufl.edu>

  Your best bet is help.start().

On Wed, 19 Feb 2003, Alexey Shipunov wrote:

> Dear R users,
> 
> Is there the possibitily in R under X11 to get (after typing help(...) 
> command) separate help window, as it is in Windows version?
> 
> Best wishes,
> 
> 
> =================================
> Dr. Alexey B. Shipunov
> Section of Molecular Systematics
> Jodrell Laboratory
> Royal Botanic Gardens, Kew,
> Richmond, Surrey, TW9 3DS, U.K.
> e-mail: a.shipunov at rbgkew.org.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From edd at debian.org  Wed Feb 19 19:50:40 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed Feb 19 19:50:40 2003
Subject: [R] Help in separate window under X11
Message-ID: <E18lZ9N-0005jx-00@sonny.eddelbuettel.com>

> Is there the possibitily in R under X11 to get (after typing help(...) 
> command) separate help window, as it is in Windows version?

IIRC help.start() starts a webbrowser pointing to the html version of the
help pages.  It requires cooperation from your browser and the jurrassic 
netscape provides it, but not all modern browsers do it.  Two remedies:  

a) manually point a browser to the URL  file:/usr/lib/R/doc/html

b) use ESS with Emacs or XEmacs, it really is worth your while (I even use
XEmacs/ESS under NT).  How to get started in explained in other places.

Dirk

-- 
According to the latest figures, 43% of all signatures are totally worthless.



From vograno at arbitrade.com  Wed Feb 19 19:55:03 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Wed Feb 19 19:55:03 2003
Subject: [R] fitting a curve according to a custom loss function
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DD02@jupiter.arbitrade.com>

Andy,

Here is a toy example where such model might make sense. Suppose y is the
total income of an individual over the last two years and x_1 and x_2 are
the taxes he paid on each of the two years. If taxes were linear in income
then y ~ a*(x_1 + x_2). With a progressive tax system it is
y ~ f(x_1) + f(x_2)

Hope it makes more sense now,
Vadim

> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com]
> Sent: Wednesday, February 19, 2003 5:33 AM
> > Vadim Ogranovich wrote:
> > 
> > >Dear R-Users,
> > >
> > >I need to find a smooth function f() and coefficients a_i 
> > that give the best
> > >fit to
> > >
> > >y ~ a_0 + a_1*f(x_1) + a_2*f(x_2)
> > >
> 
> The model is very strange (to me, at least).  It's not 
> obvious to me that
> it's even identifiable.  (Sorry that I don't have anything 
> constructive to
> add.)
> 
> Andy

-------------------------------------------------- 
DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]



From james.lindsey at luc.ac.be  Wed Feb 19 19:58:52 2003
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Wed Feb 19 19:58:52 2003
Subject: [R] GLM for Beta distribution
Message-ID: <200302191850.TAA04229@luc.ac.be>

> On Wed, 19 Feb 2003, Sharon Kuhlmann-Berenzon wrote:
> 
> >
> > Hi R-help,
> >
> > Is there such a thing as a function in R for fitting a GLM where the
> > response is distributed as a Beta distribution?
> >
> > In my case, the response variable is a percentage ([0,1] and continuous).
> >
> > The current glm() function in R doesn't include the Beta distribution.
> >
> 
> That's because they aren't generalised linear models.
> 
> Two simple possibilities
> 
>  - use the quasibinomial variance and an appropriate link such as logit in
> glm -- there's an example in McCullagh & Nelder that tries this (though
> they decide in the end that it doesn't fit their data very well)
> 
>  - Take logits and model with linear regression: a lot of beta
> distributions are fairly similar to logit-normal distributions.

A third simple possibility: my gnlr function in my gnlm library, which
fits linear and nonlinear regression models with a beta distribution.
www.luc.ac.be/~jlindsey/rcode.html
  Jim

> 
> Or you could write down the loglikelihood and use nlm() or optim() to
> maximise it.
> 
> 	-thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From mkondrin at hppi.troitsk.ru  Wed Feb 19 20:02:31 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Wed Feb 19 20:02:31 2003
Subject: [R] Help in separate window under X11
In-Reply-To: <3E53CDB4.20009.64559B@localhost>
References: <3E53CDB4.20009.64559B@localhost>
Message-ID: <3E546AEE.8030706@hppi.troitsk.ru>

Alexey Shipunov wrote:

>Dear R users,
>
>Is there the possibitily in R under X11 to get (after typing help(...) 
>command) separate help window, as it is in Windows version?
>
>Best wishes,
>
>
>=================================
>Dr. Alexey B. Shipunov
>Section of Molecular Systematics
>Jodrell Laboratory
>Royal Botanic Gardens, Kew,
>Richmond, Surrey, TW9 3DS, U.K.
>e-mail: a.shipunov at rbgkew.org.uk
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>  
>
Yes - just use R under emacs with ess-mode (see link in r-project.org)



From cri_rocha at hotmail.com  Wed Feb 19 20:07:03 2003
From: cri_rocha at hotmail.com (Cristiane Rocha)
Date: Wed Feb 19 20:07:03 2003
Subject: [R] trouble using CGIwithR
Message-ID: <F6LI9mK6PYzDabigPas000000b9@hotmail.com>

Hi,

I am having trouble to make the CGIwithR work in my server (Linux RedHat 7 - 
Apache), I installed the package, edited the R.cgi archive, but when I try 
to run any script  from the browser I receive the following:

Error message: Premature end of script headers: trivial.R

Need I change some configuration of my system so that scripts work?



Cris



From polasek at ihs.ac.at  Wed Feb 19 20:12:03 2003
From: polasek at ihs.ac.at (Wolfgang Polasek)
Date: Wed Feb 19 20:12:03 2003
Subject: [R] Markov switching models
Message-ID: <5.1.1.6.0.20030219200832.03a607e0@pop.ihs.ac.at>

I'm looking for Markov switching models, written in R or S-plus:
Does anyone know about programs?
Thanks,
Yours
  W.Polasek



From rossini at blindglobe.net  Wed Feb 19 20:16:03 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed Feb 19 20:16:03 2003
Subject: [R] trouble using CGIwithR
In-Reply-To: <F6LI9mK6PYzDabigPas000000b9@hotmail.com> ("Cristiane Rocha"'s
 message of "Wed, 19 Feb 2003 15:59:35 -0300")
References: <F6LI9mK6PYzDabigPas000000b9@hotmail.com>
Message-ID: <87u1f02icm.fsf@jeeves.blindglobe.net>

"Cristiane Rocha" <cri_rocha at hotmail.com> writes:


> I am having trouble to make the CGIwithR work in my server (Linux
> RedHat 7 -
> Apache), I installed the package, edited the R.cgi archive, but when I
> try to run any script  from the browser I receive the following:
>
> Error message: Premature end of script headers: trivial.R
>
> Need I change some configuration of my system so that scripts work?

One catch would be to make sure that the mod_magicmime setting is
OFF (i.e. the module isn't loaded).  My name for it might not be
right, but the exact name shouldn't be hard to find in the config
file. 


-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From james.lindsey at luc.ac.be  Wed Feb 19 20:47:03 2003
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Wed Feb 19 20:47:03 2003
Subject: [R] Markov switching models
In-Reply-To: <5.1.1.6.0.20030219200832.03a607e0@pop.ihs.ac.at> from "Wolfgang Polasek" at Feb 19, 2003 08:09:59 PM
Message-ID: <200302191946.UAA08942@luc.ac.be>

> 
> I'm looking for Markov switching models, written in R or S-plus:
> Does anyone know about programs?


If I am correct in believing that these are hidden Markov models,
there are hidden (discrete time) and chidden (continuous time) in my
repeated library. www.luc.ac.be/~jlindsey/rcode.html
  Jim

> Thanks,
> Yours
>   W.Polasek
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From skayis at lic.co.nz  Wed Feb 19 21:10:04 2003
From: skayis at lic.co.nz (skayis@lic.co.nz)
Date: Wed Feb 19 21:10:04 2003
Subject: [R] function
Message-ID: <OFAA378BF4.BFDF1D2F-ONCC256CD2.006DCBAB-CC256CD2.006E7DBF@livestock.org.nz>

Dear R users,

I have received many suggestions regarding my following function question.

I would like to express my sincere thanks to all R users who replied me. If
anybody needs, I can share the answers.

Kind Regards

Seyit Ali


----- Forwarded by Seyit Kayis/randd/Livestock on 20/02/03 09:03 -----
                                                                                                           
                      Seyit Kayis                                                                          
                                               To:       r-help at stat.math.ethz.ch                          
                      19/02/03 15:50           cc:                                                         
                                               Subject:  function                                          
                                                                                                           



Dear R users,

I have some R code and trying to understand it. I have a vector

 myvec
 [1] 24 24 10 10 10 10 10 44 44 44 45 45 45 54 54 54 54 42 42

and a scaler

 myscaler
[1] 10

The following function:
match(myvec,myscaler)!="NA"

 returns :

 [1]   NA   NA TRUE TRUE TRUE TRUE TRUE   NA   NA   NA   NA   NA   NA   NA
NA   NA   NA   NA    NA

I need a return

FALSE  FALSE TRUE TRUE TRUE TRUE TRUE   FALSE FALSE ...FALSE

Is there any function to perform this?

Any help deeply appreciated.

Kind Regards

Seyit Ali



From dgrove at fhcrc.org  Wed Feb 19 22:03:03 2003
From: dgrove at fhcrc.org (Douglas Grove)
Date: Wed Feb 19 22:03:03 2003
Subject: [R] removing leading/trailing blanks
Message-ID: <Pine.LNX.4.44.0302191243290.18325-100000@echidna.fhcrc.org>

Hi,

What's the best way of dropping leading or trailing
blanks from a character string?  

The only thing I can think of is using sub() to replace
blanks with null strings, but I don't know if there is
a better way (I also don't know how to represent the
trailing blank in a regular expression).

Thanks,
Doug Grove



From sundar.dorai-raj at pdf.com  Wed Feb 19 22:14:04 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed Feb 19 22:14:04 2003
Subject: [R] removing leading/trailing blanks
References: <Pine.LNX.4.44.0302191243290.18325-100000@echidna.fhcrc.org>
Message-ID: <3E53F376.7020107@pdf.com>


Douglas Grove wrote:
> Hi,
> 
> What's the best way of dropping leading or trailing
> blanks from a character string?  
> 
> The only thing I can think of is using sub() to replace
> blanks with null strings, but I don't know if there is
> a better way (I also don't know how to represent the
> trailing blank in a regular expression).
> 


I would use gsub instead:

R> ch = "    lkj df klj lkjsdf  "
R> ch
[1] "    lkj df klj lkjsdf  "
R> gsub("^ .", "", ch) # remove leading white space
[1] "lkj df klj lkjsdf  "
R> gsub(". $", "", ch) # remove trailing white space
[1] "    lkj df klj lkjsdf"
R>

Regards,
Sundar



From white.denis at epamail.epa.gov  Wed Feb 19 22:21:03 2003
From: white.denis at epamail.epa.gov (white.denis@epamail.epa.gov)
Date: Wed Feb 19 22:21:03 2003
Subject: [R] removing leading/trailing blanks
Message-ID: <OF6577DD84.33271D60-ON88256CD2.007507A4@rtp.epa.gov>

> Hi,
>
> What's the best way of dropping leading or trailing
> blanks from a character string?
>
> The only thing I can think of is using sub() to replace
> blanks with null strings, but I don't know if there is
> a better way (I also don't know how to represent the
> trailing blank in a regular expression).
>
> Thanks,
> Doug Grove

sub ("^[ \t]*", "", sub ("[ \t]*$", "", "  hello  "))



From TyagiAnupam at aol.com  Wed Feb 19 22:40:07 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Wed Feb 19 22:40:07 2003
Subject: [R] Subpopulations in Complex Surveys
Message-ID: <10e.1ec5a6e1.2b85538b@aol.com>

Hi, 
is there a way to analyze subpopulations (e.g. women over 50, those who 
answered "yes" to a particular question) in a survey using Survey package? 
Other packages (e.g. Stata, SUDAAN) do this with a subpopulation option to 
identify the subpopulation for which the analysis shoud be done. I did not 
see this option in the Survey package. Is there another way to do this?

*********************************************************
Prediction is very difficult, especially about the future. 
                  -- Niels Bohr



From csoh at hsph.harvard.edu  Thu Feb 20 01:03:03 2003
From: csoh at hsph.harvard.edu (Chang-Heok Soh)
Date: Thu Feb 20 01:03:03 2003
Subject: [R] Variable selection in Cox proportional hazards model?
Message-ID: <Pine.GSO.4.53.0302191849380.16239@hsph.harvard.edu>

Hello,
I need to implement variable selection procedures (such as stepwise and
backward selection) in Cox proportional hazards model, but can't seem to
find an R or S-plus command for these procedures.  I am aware that these
can be done in SAS.

I would appreciate help from anyone who knows how to implement these
procedures in Cox models using S-plus or (preferably) R.

Thanks!

Regards,
Chang-Heok



From smyth at wehi.edu.au  Thu Feb 20 01:32:03 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Thu Feb 20 01:32:03 2003
Subject: [R] Rcmd check does not recognize formal generic function
  as code object
Message-ID: <5.2.0.9.1.20030220113104.00a04730@imaphost.wehi.edu.au>

Thanks ... there are issues here that I don't understand but your mention 
of promptClass prompted me to try promptMethods, and that seems to be the 
solution. The following files do the job and pass rcmd path without warnings:

test.R as before

myGenericFun.Rd replaced with

------------------------------------------------------
\name{myGenericFun-methods}
\alias{myGenericFun-methods}
\alias{myGenericFun,ANY-method}
\alias{myGenericFun,matrix-method}
\docType{methods}

\title{Methods for Function myGenericFun in package test}

\section{Methods}{\describe{
         \item{object = ANY}{default method}
         \item{object = matrix}{special method for matrices}
}}

\description{A trivial example}

\examples{
x <- rnorm(10)
myGenericFun(x)
dim(x) <- c(5,2)  # x is now a matrix
myGenericFun(x)
}

\keyword{methods}
\keyword{models}
-------------------------------------------------------

Regards
Gordon

At 04:16 PM 19/02/2003, you wrote:
>On Wed, Feb 19, 2003 at 03:44:31PM +1100, Gordon Smyth wrote:
> > Dear all,
> >
> > I am trying to write a package using formal methods and classes from the
> > methods package. I have not been able to get the package to pass rcmd 
> check
> > without warnings, because rcmd check does not recognize my generic
> > functions as code objects and therefore queries why they have 
> documentation
> > entries.
> >
> > I have isolated the problem in a very small trivial example which I give
> > below. I have one file test.R in the R directory and one file test.Rd in
> > the man directory. Here is the message from rcmd check:
> >
> >     * checking for code/documentation mismatches ... WARNING
> >     Objects with usage in documentation object 'myGenericFun' but missing
> > from code:
> >     [1] "myGenericFun"
> >
> > Can I get rcmd check to recognize that myGenericFun is something that need
> > a documentation entry?
> >
>
>   Mostly this is not documented (yet) because the exact API is still
>   being worked on.
>
>   Documenting generic functions (and the methods that they dispatch)
>   is hard in a language that allows users to attach and detach
>   packages (and hence both generic functions and methods). We don't
>   really have the notion of dynamic documentation (yet) that will
>   handle the applications that are likely to arise.
>
>   The current problem arises, I think, from an effort to solve a
>   different problem. Since many functions in "base" are not generic
>   (yet?) when a package author wants to make one generic we don't
>   really want to override the documentation for that function in base
>   ( we might want to document the method that we are adding, but the
>   creation of the generic is artificial in some sense, if users could
>   assign into base, or if all base functions were generic the generic
>   would live in base and be documented there).
>
>   It was decided that should not be an error to omit documentation for
>   a generic function defined in a package (whose sole purpose is to
>   extend a current function to be generic). It appears that the
>   implementation of that decision was to treat all generic functions
>   in packages as non-entities. That is probably not the best and one
>   can argue that there should be no warning if a generic is documented
>   (nor one if it isn't and there is already documentation for it
>   somewhere).
>
>   What we have been doing is using promptClass and documenting methods
>   (and generics with the classes) in Bioconductor.
>
>   This will continue to change as we gain experience with the methods
>   class and with feedback from users. As I noted, with generic
>   functions it would be nice to explain the purpose and list all
>   available methods when the user wants help.
>
>  I think that you can safely ignore this warning.
>
>  Robert
>
> > The document "Writing R Extensions" doesn't cover formal methods and
> > classes, and I haven't found any other documentation that covers writing
> > packages using formal methods. I am working from looking at code in
> > Bioconductor, pixmap and gpclib. I downloaded source for pixmap and
> > confirmed that it has the same problem with rcmd check that I mention here.
> >
> > Any advice gratefully received, including any tips about how to write
> > organise .Rd files for generic methods.
> >
> > Thanks
> > Gordon
> >
> > -------------------------------- test.R -----------------------------
> > .initClassesandMethods <- function(where) {
> > setGeneric("myGenericFun",where=where,
> >          def=function(object) standardGeneric("myGenericFun"))
> > setMethod("myGenericFun","ANY",where=where,
> >          def=function(object) paste("myGenericFun on object of
> > class",class(object)))
> > setMethod("myGenericFun","matrix",where=where,
> >          def=function(object) "myGenericFun for matrices")
> > }
> > #  Use of .First.lib ensures that the new generic function is assigned in
> > the package itself
> > .First.lib <- function(libname, pkgname) {
> >          require(methods, quietly=TRUE)
> > #  Find what position in the search path this package is
> >          where <- match(paste("package:", pkgname, sep=""), search())
> >          .initClassesandMethods(where)
> >          cacheMetaData(as.environment(where))
> > }
> > ------------------------- end test.R ----------------------------------
> >
> > ------------------------- myGenericFun.Rd ------------------------
> > \name{myGenericFun}
> > \docType{methods}
> > \alias{myGenericFun}
> > \title{My Generic Function}
> > \description{A simple example generic function.}
> >
> > \usage{myGenericFun(object)}
> >
> > \arguments{
> >    \item{object}{Any R object. A special method exists for objects of 
> class
> > "matrix".}
> > }
> >
> > \value{A character string explaining the class of object and the method
> > dispatched.}
> >
> > \examples{
> > x <- rnorm(10)
> > myGenericFun(x)
> > dim(x) <- c(5,2)
> > myGenericFun(x)
> > }
> >
> > \keyword{models}
> > -------------------------------- end myGenericFun.Rd -------------------
> > 
> ---------------------------------------------------------------------------------------
> > Dr Gordon K Smyth, Senior Research Scientist, Bioinformatics,
> > Walter and Eliza Hall Institute of Medical Research,
> > 1G Royal Parade, Parkville, Vic 3050, Australia
> > Tel: (03) 9345 2326, Fax (03) 9347 0852,
> > Email: smyth at wehi.edu.au, www: http://www.statsci.org
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>--
>+---------------------------------------------------------------------------+
>| Robert Gentleman                 phone : (617) 632-5250                   |
>| Associate Professor              fax:   (617)  632-2444                   |
>| Department of Biostatistics      office: M1B20                            |
>| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
>+---------------------------------------------------------------------------+



From ken_lee at tynesys.com  Thu Feb 20 02:03:02 2003
From: ken_lee at tynesys.com (Ken Lee)
Date: Thu Feb 20 02:03:02 2003
Subject: [R] strwidth issue
In-Reply-To: <10e.1ec5a6e1.2b85538b@aol.com>
Message-ID: <FFEKIEFDONDECJDODGDJAELMCEAA.ken_lee@tynesys.com>

Dear all,
       Could I have any method or set the graphical parameter (par(...)) to let each character have the same width when I print out some string , 
like "w" is too wide , "i" is too thin.

Thank's very much

Best Regards

   Ken



From Robert.Schick at noaa.gov  Thu Feb 20 02:12:04 2003
From: Robert.Schick at noaa.gov (Robert Schick)
Date: Thu Feb 20 02:12:04 2003
Subject: [R] subset with NA
Message-ID: <3E542B67.3DB680D6@noaa.gov>

Easy question that I can't find an answer for. I'm trying to subset a
data frame and want to exclude the positive values, i.e. I want the NA
values. 

My data:
> summary(temp$tuna)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
      1       2       3       3       4       5    1211 

Querying for 
subset(temp, tuna %in% "NA", select....
subset(temp, tuna == NA, select....
subset(temp, tuna == as.character(NA), select....

All yield an empty data frame.

An R-help post
(http://www.r-project.org/nocvs/mail/r-help/2002/3645.html) suggested
looking at http://developer.r-project.org/150update.txt, which I did
but I'm confused as to how to accurately query for an NA string.


-- 
Rob Schick
Ecologist
NOAA Fisheries
Santa Cruz Lab
110 Shaffer Road
Santa Cruz, CA 95060
Phone: 831.420.3960



From white.denis at epamail.epa.gov  Thu Feb 20 02:22:02 2003
From: white.denis at epamail.epa.gov (white.denis@epamail.epa.gov)
Date: Thu Feb 20 02:22:02 2003
Subject: [R] subset with NA
Message-ID: <OFF2336B38.95E2A15A-ON88256CD3.00074717@rtp.epa.gov>

> Easy question that I can't find an answer for. I'm trying to subset a
> data frame and want to exclude the positive values, i.e. I want the NA
> values.
>
> My data:
> > summary(temp$tuna)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
>       1       2       3       3       4       5    1211
>
> Querying for
> subset(temp, tuna %in% "NA", select....
> subset(temp, tuna == NA, select....
> subset(temp, tuna == as.character(NA), select....
>
> All yield an empty data frame.
>
> An R-help post
> (http://www.r-project.org/nocvs/mail/r-help/2002/3645.html) suggested
> looking at http://developer.r-project.org/150update.txt, which I did
> but I'm confused as to how to accurately query for an NA string.

subset (temp, is.na (temp$tuna), ...)



From rpeng at stat.ucla.edu  Thu Feb 20 02:41:05 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu Feb 20 02:41:05 2003
Subject: [R] subset with NA
In-Reply-To: <3E542B67.3DB680D6@noaa.gov>
Message-ID: <Pine.GSO.4.10.10302191737190.5248-100000@quetelet.stat.ucla.edu>

If `temp' is your data frame and `tuna' is a variable in `temp', then try

subset(temp, is.na(tuna))

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 19 Feb 2003, Robert Schick wrote:

> Easy question that I can't find an answer for. I'm trying to subset a
> data frame and want to exclude the positive values, i.e. I want the NA
> values. 
> 
> My data:
> > summary(temp$tuna)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
>       1       2       3       3       4       5    1211 
> 
> Querying for 
> subset(temp, tuna %in% "NA", select....
> subset(temp, tuna == NA, select....
> subset(temp, tuna == as.character(NA), select....
> 
> All yield an empty data frame.
> 
> An R-help post
> (http://www.r-project.org/nocvs/mail/r-help/2002/3645.html) suggested
> looking at http://developer.r-project.org/150update.txt, which I did
> but I'm confused as to how to accurately query for an NA string.
> 
> 
> -- 
> Rob Schick
> Ecologist
> NOAA Fisheries
> Santa Cruz Lab
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: 831.420.3960
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jonathan_li at labs.agilent.com  Thu Feb 20 02:47:02 2003
From: jonathan_li at labs.agilent.com (Jonathan Q. Li)
Date: Thu Feb 20 02:47:02 2003
Subject: [R] proxy setting RedHat Linux
Message-ID: <3E543406.5080600@labs.agilent.com>

Hi,

I was trying to update packages with my R 1.6 under RedHat 8.0 system.
When entering this command,
 > update.packages()

It simply says,
    trying URL `http://cran.r-project.org/src/contrib/PACKAGES'

But nothing happens.

Is this a problem with my proxy setting since I am working behind a 
firewall? It seems so:

 > Sys.getenv("http_proxy")
http_proxy
        ""

Then the documentation in "download.file" says that Sys.putenv won't 
work in setting the proxy. It says " These environment variables must be 
set before the download code
     is first used: they cannot be altered later by calling
     `Sys.putenv'.".

I don't understand what this means: "set it before the download code is 
first used". I have installed the R 1.6 simply from  RPM in CRAN.

Thanks in advance for your help.
Jonathan



From andy_liaw at merck.com  Thu Feb 20 03:04:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Feb 20 03:04:03 2003
Subject: [R] fitting a curve according to a custom loss function
Message-ID: <3A822319EB35174CA3714066D590DCD534BCCE@usrymx25.merck.com>

Vadim,

> Here is a toy example where such model might make sense. 
> Suppose y is the
> total income of an individual over the last two years and x_1 
> and x_2 are
> the taxes he paid on each of the two years. If taxes were 
> linear in income
> then y ~ a*(x_1 + x_2). With a progressive tax system it is
> y ~ f(x_1) + f(x_2)
> 
> Hope it makes more sense now,

Yes, that does make sense.  However, one would then expect x1 and x2 to be
quite highly correlated (and thus make what Kondrin proposed inappropriate).
Also, in this case, you don't need the coefficients a0, a1 and a2.  It was
the original form with both coefficients and f() that made me wonder whether
the model is identifiable.  It's still not clear to me whether the contraint
that both variable go through the same transformation f() was enough to make
it identifiable.

I suppose you might consider something like a nonparametric ANCOVA (analysis
of covariance).  I believe the book by Azzalini and Bowman on smoothing has
some coverage on this, as well as a paper by Bowman and Young.  (There may
be some function for fitting this kind of model in the `sm' package.)
Hopefully others with more expertise in this have something more to say.

Cheers,
Andy

> Vadim
> 
> > -----Original Message-----
> > From: Liaw, Andy [mailto:andy_liaw at merck.com]
> > Sent: Wednesday, February 19, 2003 5:33 AM
> > > Vadim Ogranovich wrote:
> > > 
> > > >Dear R-Users,
> > > >
> > > >I need to find a smooth function f() and coefficients a_i 
> > > that give the best
> > > >fit to
> > > >
> > > >y ~ a_0 + a_1*f(x_1) + a_2*f(x_2)
> > > >
> > 
> > The model is very strange (to me, at least).  It's not 
> > obvious to me that
> > it's even identifiable.  (Sorry that I don't have anything 
> > constructive to
> > add.)
> > 
> > Andy
> 
> -------------------------------------------------- 
> DISCLAIMER \ This e-mail, and any attachments thereto, is 
> intend ... [[dropped]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From hb at maths.lth.se  Thu Feb 20 03:09:03 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu Feb 20 03:09:03 2003
Subject: [R] Who to decide what a generic function should look like?
Message-ID: <000d01c2d884$98690fa0$7341a8c0@alpha.wehi.edu.au>

I am not sure if what I am asking below should be discussed under r-help
or r-devel, so please feel free to move over to r-devel. 

This is a spin off from Gordon Smyth's question about generic functions
and Robert Gentleman's reply. I have tried to raise the question before
and I am sure this has been discussed by others, but never on the r-help
list what I can see. My concern is that generic functions as defined
today are only semi-generic. From ?Methods the definition of a generic
function is:

     "A generic function is a function that has associated with it a
     collection of other functions (the methods), all of which agree in
     formal arguments with the generic."

For me a generic function should be fully generic in the sense that
there are no requirements of arguments agreement (and therefore it
should not be documented as a reply to Smyth's thread). Under the
S3/UseMethod scheme as well S4/methods scheme this requirement is
enforced (even though one can get around it by using only arguments
"...") and under S4/methods it is followed even more strictly. I
understand that by enforcing matching arguments (and argument types) the
method dispatching mechanism can work much faster. Are there any another
purposes than efficiency behind the argument matching requirement? Why
not make a generic function truly generic? Having truly generic
functions, the method dispatching mechanism could equally well be done
by the language interpreter itself and thus making generic functions
obsolete.


My concern is that enforcing methods to match the argument signature of
the generic function will make packages incompatible with each other. I
can not create a generic function called "normalize" for my microarray
package and expect it to work together with other package defining a
generic function with the same name. Some short-term and long-term
outcomes from this are:

  * Each developer who cares has to come up with a less general name
than "normalize", e.g. 
    "normalizeLowess". However, this will still not guarantee you that
there will not be any 
    naming conflict with other, to you unknown or future upcoming,
packages. People will have 
    to create extremely awkward method names to make there generic
functions unique. This is
    already happening today (and unfortunately everyone invents his/her
own naming rules).

  * This in turn will result in an object-oriented programming style
that looks like a 
    procedural programming style and the gain/idea of having
polymorphism and the possibility 
    of overloading methods will disappear. This can also be seen in some
packages.

  * If you do not follow the approach of having unique method names, but
still want to keep your 
    package compatible with other, you will have to change your API
constantly, which hurt the 
    end user who has to update there scripts accordingly. This will also
result in unnecessary 
    troubleshooting and bug fixes.

  * Trying to learn object-oriented programming by using R will be
confusing, resulting in 
    procedural/object-oriented hybrids. This can also be seen today.

Does anyone agree with this and what are the thoughts about this?

So,

  * who is the person to decide what a generic function should look
like, and 
  * who owns the right to the method name "normalize"?

Best wishes

Henrik Bengtsson

Home: 201/445 Royal Parade, 3052 Parkville
Office: Bioinformatics, WEHI, Parkville
+61 (0)412 269 734 (cell), +61 (0)3 9345 2324 (lab),
+1 (508) 464 6644 (global fax)
hb at wehi.edu.au, http://www.maths.lth.se/~hb/
Time zone: +11h UTC (Sweden +1h UTC, Calif. -8h UTC)



From ray at mcs.vuw.ac.nz  Thu Feb 20 03:13:02 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Thu Feb 20 03:13:02 2003
Subject: [R] inserting elements in a list
Message-ID: <200302200210.h1K2A8ou007844@tahi.mcs.vuw.ac.nz>

> From: Peter Wolf <pwolf at wiwi.uni-bielefeld.de>
> 
> "insert.values" <- function(x,pos.insert,x.insert){
> :

Which when reduced to its bare minimum to solve the stated problem,
becomes:
  threes <- which(a==3)
  a <- c(a, rep(7, length(threes)))[order(c(seq(a), threes))]

This is by far the overall fastest solution so far proposed, and
certainly is reasonably easy to understand.  However an even faster
solution is based on rep():

 N <- which(threes <- a == 3)		# which ones
 a <- rep(a, times = 1 + threes)	# duplicate them
 a[N + 1:length(N)] <- 7		# replace the duplicates

Relative timing for vector lengths n=1000 and n=10000 with 1000 repeats
(on a 1.7GHz P4 running R-1.6.1 under NetBSD) is as follows:

a <- sample(1:9, n, TRUE)			n=1000	n=10000
lapply (Stephen Upton and Peter Dalgaard)	  9.2s	 117.8s
recursion (John Fox) [options(expressions=n)]	 59.9s	 stack overflow
offset <- (Thomas Lumley)			  1.4s	 12.7s
offset <- (Peter Dalgaard)			  1.3s	 10.9s
order() (Peter Wolf)				  1.1s	  8.7s
rep() (me)					  0.9s	  7.6s

Hope this helps,
Ray Brownrigg <ray at mcs.vuw.ac.nz>	http://www.mcs.vuw.ac.nz/~ray



From ripley at stats.ox.ac.uk  Thu Feb 20 08:07:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb 20 08:07:03 2003
Subject: [R] Variable selection in Cox proportional hazards model?
In-Reply-To: <Pine.GSO.4.53.0302191849380.16239@hsph.harvard.edu>
Message-ID: <Pine.LNX.4.44.0302200705250.20651-100000@gannet.stats>

stepAIC (package MASS) works with coxph (package survival).

On Wed, 19 Feb 2003, Chang-Heok Soh wrote:

> I need to implement variable selection procedures (such as stepwise and
> backward selection) in Cox proportional hazards model, but can't seem to
> find an R or S-plus command for these procedures.  I am aware that these
> can be done in SAS.
> 
> I would appreciate help from anyone who knows how to implement these
> procedures in Cox models using S-plus or (preferably) R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jasont at indigoindustrial.co.nz  Thu Feb 20 09:44:03 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu Feb 20 09:44:03 2003
Subject: [R] working with list
In-Reply-To: <Pine.GSO.4.30.0302190610570.20765-100000@aris.ss.uci.edu>; from kawa@aris.ss.uci.edu on Wed, Feb 19, 2003 at 06:46:28AM -0800
References: <Pine.GSO.4.30.0302190610570.20765-100000@aris.ss.uci.edu>
Message-ID: <20030220214350.A9667@camille.indigoindustrial.co.nz>

On Wed, Feb 19, 2003 at 06:46:28AM -0800, Hiroyuki Kawakatsu wrote:
> hi,
> 
> i have two questions:

I counted three ;-)

> (1) lookup: given a list of 'strings' in a list, i want to know the index
> of a given string in the list. if the string is not in the list, the index
> can be 0 or length()+1. for example, suppose i have
> names <- c("dog", "cat", "pig", "fish");
> then i want
> lookup(names, "cat") to return 2 and
> lookup(names, "ant") to return 0 (or 5)

That's not a list of strings; it's a character-type vector.  See below
for more.

For this, grep() is your friend.  To match a word exactly, you need to
put the pattern between a ^ and a $, all in quotes.  If you don't,
you'll get all partial matches too (which is also pretty useful
sometimes).

eg:

> names <- c("dog", "cat", "pig", "fish","catskills","cat stevens")
> grep("^cat$",names)
[1] 2
> grep("cat",names)
[1] 2 5 6

(I'm told that now works on all platforms - thanks for the regexes,
R-core!)

> (2) combining lists: when lists are combined, the higher level list
> structure appears to be lost. what i mean is, suppose i have two lists
> with the same structure
> a <- list(name="foo", year=1989, grade="A");
> b <- list(name="bar", year=2000, grade="B+");
> then when i combine the two lists into one
> ab <- c(a, b);
> length(ab) returns length(a)+length(b), not 2.

c() makes vectors.  list() makes lists.  Vectors:  each element is of
the *same* data type (numeric, character, Date/Time, factor,
logical,...).  This is why you lose the list-like character above;
you've "pushed" everything into a character vector.  This is a handy
way of throwing away exotic data classes, btw.

I think what you wanted to do was:

ab <- list(a, b)
length(ab)
ab


> given a list of lists, is there any way i can loop through each
> list and work with the named components in each list? 

lapply() is your friend, and can help with recursion too.

lapply(your.big.list,function(bar,...) {

  listfunc <- function(foo,...) {
     #magic thing you do to non-list elements;
     #you didn't specify, so I'm not sure what you want.
  }

  if(is.list(bar)) 
    lapply(bar,listfunc)
  else
    listfunc(bar,...)                 
}


This can make life easy, but think really hard about what you want the
functions to do, and what values you want them to return, and how
you're going to structure this.  Generalised list travels aren't
trivial, particularly the return trip.

Hope that helps

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From plummer at iarc.fr  Thu Feb 20 10:36:03 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: Thu Feb 20 10:36:03 2003
Subject: [R] proxy setting RedHat Linux
In-Reply-To: <3E543406.5080600@labs.agilent.com>
References: <3E543406.5080600@labs.agilent.com>
Message-ID: <1045734409.992.10.camel@xena>

On Thu, 2003-02-20 at 02:48, Jonathan Q. Li wrote:
> Hi,
> 
> I was trying to update packages with my R 1.6 under RedHat 8.0 system.
> When entering this command,
>  > update.packages()
> 
> It simply says,
>     trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
> 
> But nothing happens.
> 
> Is this a problem with my proxy setting since I am working behind a 
> firewall? It seems so:
> 
>  > Sys.getenv("http_proxy")
> http_proxy
>         ""
> 
> Then the documentation in "download.file" says that Sys.putenv won't 
> work in setting the proxy. It says " These environment variables must be 
> set before the download code
>      is first used: they cannot be altered later by calling
>      `Sys.putenv'.".
> 
> I don't understand what this means: "set it before the download code is 
> first used". I have installed the R 1.6 simply from  RPM in CRAN.

Try setting the environment variables on the command line before you
launch R, e.g.

export http_proxy="http://proxy.domain.com/"

If this works, then you should put this line in your profile
( ~/.bash_profile ) or create a new file - say "R.sh" in the directory
/etc/profile.d containing the same line. This will ensure that the
environment variables are set every time you log on.

Martyn



From gisar at nus.edu.sg  Thu Feb 20 10:41:05 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Thu Feb 20 10:41:05 2003
Subject: [R] Using evaluate-deparse-substitute
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F20F@MBXSRV03.stf.nus.edu.sg>

Being the lazy soul I am, I wish to write a function to replace saying
ls(pattern=...) everytime. Here is what I have:

lsp <- function(x){
  y <- eval(deparse(substitute(x))) 
  print(y)                                   # CHECK

  print( ls(pattern = eval(y))   )                    # TRY 1
  print( ls(pattern = eval(deparse(substitute(x)))) ) # TRY 2
}

Suppose I have 
rubbish.in = rubbish.out = grub <- 1

I get the following when I try

> lsp(rub)
[1] "rub"
character(0)
character(0)

Can someone explain/help with this? Thank you very much.



From ahenningsen at email.uni-kiel.de  Thu Feb 20 10:59:03 2003
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Thu Feb 20 10:59:03 2003
Subject: [R] is.numeric
In-Reply-To: <20030219110012.10581.77582.Mailman@hypatia.math.ethz.ch>
References: <20030219110012.10581.77582.Mailman@hypatia.math.ethz.ch>
Message-ID: <200302201058.46878.ahenningsen@email.uni-kiel.de>

Hi,
I have a vector, which contains both strings and numbers, e.g.

> foo <- c("str1",1234,"str2",0.9876)

I want to know if a distinct element of the vector is a string or a number and 
took "is.numeric", but

> is.numeric(foo[2])
[1] FALSE

because R treats the numbers in a mixed vectors as strings:

> foo
[1] "str1"   "1234"   "str2"   "0.9876"

As a workaround I use:

> !is.na(as.numeric(foo[2]))
[1] TRUE
> !is.na(as.numeric(foo[1]))
[1] FALSE
Warning message:
NAs introduced by coercion

This works, but I always get the spurious warning messages. Do you know a 
better way or a way to suppress these warning messages?

Thanks,
Arne

-- 
Arne Henningsen
Department of Agricultural Economics
Christian-Albrechts-University Kiel
24098 Kiel, Germany
Tel: +49-431-880-4445
Fax: +49-431-880-1397 
ahenningsen at email.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen.html



From stuart.leask at nottingham.ac.uk  Thu Feb 20 11:04:03 2003
From: stuart.leask at nottingham.ac.uk (Stuart Leask)
Date: Thu Feb 20 11:04:03 2003
Subject: [R] Help in separate window under X11
References: <3E53CDB4.20009.64559B@localhost>
Message-ID: <005301c2d8c0$4bc94fc0$f2e1f380@mczsjl>

Or, from the R prompt:
> library(tcltk); options(pager=tkpager)

works for me, without changing my editor or anything!



StuartDr Stuart Leask MA MRCPsych, Clinical Lecturer in Psychiatry
University of Nottingham Dept of Psychiatry, Duncan Macmillan House
Porchester Road, Nottingham. NG3 6AA. UK
http://www.nottingham.ac.uk/psychiatry/staff/sjl.html

----- Original Message ----- 
From: "Alexey Shipunov" <a.shipunov at rbgkew.org.uk>
To: <R-help at stat.math.ethz.ch>
Sent: Wednesday, February 19, 2003 6:32 PM
Subject: [R] Help in separate window under X11


> Dear R users,
> 
> Is there the possibitily in R under X11 to get (after typing help(...) 
> command) separate help window, as it is in Windows version?
> 
> Best wishes,
> 
> 
> =================================
> Dr. Alexey B. Shipunov
> Section of Molecular Systematics
> Jodrell Laboratory
> Royal Botanic Gardens, Kew,
> Richmond, Surrey, TW9 3DS, U.K.
> e-mail: a.shipunov at rbgkew.org.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Thu Feb 20 11:08:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Feb 20 11:08:03 2003
Subject: [R] Using evaluate-deparse-substitute
In-Reply-To: <024D6AEFCB92CB47BA1085751D184BB80105F20F@MBXSRV03.stf.nus.edu.sg>
References: <024D6AEFCB92CB47BA1085751D184BB80105F20F@MBXSRV03.stf.nus.edu.sg>
Message-ID: <3E54A868.4080004@statistik.uni-dortmund.de>

Adaikalavan Ramasamy wrote:
> Being the lazy soul I am, I wish to write a function to replace saying
> ls(pattern=...) everytime. Here is what I have:
> 
> lsp <- function(x){
>   y <- eval(deparse(substitute(x))) 
>   print(y)                                   # CHECK
> 
>   print( ls(pattern = eval(y))   )                    # TRY 1
>   print( ls(pattern = eval(deparse(substitute(x)))) ) # TRY 2
> }
> 
> Suppose I have 
> rubbish.in = rubbish.out = grub <- 1
> 
> I get the following when I try
> 
> 
>>lsp(rub)
> 
> [1] "rub"
> character(0)
> character(0)
> 
> Can someone explain/help with this? Thank you very much.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help


You have to think about environments and scoping rules.
You define another function and ls() is invoked in that functions, thus 
it is called in another environment than you obviously expected.
See ?ls, particularly its argument "name", why the following prints the 
things you expect from ls().

lsp <- function(x){
    y <- deparse(substitute(x))
    print(y)
    print(ls(sys.frame(sys.parent()), pattern = y))
  }

Consider to read
  Venables and Ripley (2000): S Programming, Springer.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Thu Feb 20 11:12:27 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Feb 20 11:12:27 2003
Subject: [R] strwidth issue
In-Reply-To: <FFEKIEFDONDECJDODGDJAELMCEAA.ken_lee@tynesys.com>
References: <FFEKIEFDONDECJDODGDJAELMCEAA.ken_lee@tynesys.com>
Message-ID: <3E54A8DF.9010907@statistik.uni-dortmund.de>

Ken Lee wrote:
> Dear all,
>        Could I have any method or set the graphical parameter (par(...)) to let each character have the same width when I print out some string , 
> like "w" is too wide , "i" is too thin.
> 
> Thank's very much
> 
> Best Regards
> 

See the "family" argument in ?postscript, ?ps.options and ?pdf.
E.g.  family = "Courier"  will do the trick.

Uwe Ligges



From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Feb 20 11:17:06 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu Feb 20 11:17:06 2003
Subject: [R] is.numeric
Message-ID: <Pine.LNX.4.51.0302201108570.6347@artemis.imbe.med.uni-erlangen.de>

> Hi,
> I have a vector, which contains both strings and numbers, e.g.
>
> > foo <- c("str1",1234,"str2",0.9876)
>

R> foo <- list("str1",1234,"str2",0.9876)
R> lapply(foo, is.numeric)
[[1]]
[1] FALSE

[[2]]
[1] TRUE

[[3]]
[1] FALSE

[[4]]
[1] TRUE


using lists is maybe the better solution.

Torsten

> I want to know if a distinct element of the vector is a string or a number and
> took "is.numeric", but
>
> > is.numeric(foo[2])
> [1] FALSE
>
> because R treats the numbers in a mixed vectors as strings:
>
> > foo
> [1] "str1"   "1234"   "str2"   "0.9876"
>
> As a workaround I use:
>
> > !is.na(as.numeric(foo[2]))
> [1] TRUE
> > !is.na(as.numeric(foo[1]))
> [1] FALSE
> Warning message:
> NAs introduced by coercion
>
> This works, but I always get the spurious warning messages. Do you know a
> better way or a way to suppress these warning messages?
>
> Thanks,
> Arne
>
> --
> Arne Henningsen
> Department of Agricultural Economics
> Christian-Albrechts-University Kiel
> 24098 Kiel, Germany
> Tel: +49-431-880-4445
> Fax: +49-431-880-1397
> ahenningsen at email.uni-kiel.de
> http://www.uni-kiel.de/agrarpol/ahenningsen.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From mmarques at power.inescn.pt  Thu Feb 20 11:57:02 2003
From: mmarques at power.inescn.pt (Mark Marques)
Date: Thu Feb 20 11:57:02 2003
Subject: [R] ClustPlot question
Message-ID: <895043261.20030220110441@power.inescn.pt>

  Hi...  Being new to this mailing list I have small question to make.
  I am using R in Windows.
  I  have  several  clust plots to make but each time I call "plot" it
  stops  asking  for  a  "graph  type". How can I disable that kind of
  interaction  ?
  For   each   plot  I  am using the "savePlot" function, is there any
  other way of exporting the above plots ? in a Non-interactive manner ?

  Greetings in advance

  Mark Marques



From JonesW at kssg.com  Thu Feb 20 12:02:02 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Thu Feb 20 12:02:02 2003
Subject: [R] inserting an extra row into an array
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE2015@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030220/c7ad5812/attachment.pl

From petr.pikal at precheza.cz  Thu Feb 20 12:28:06 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu Feb 20 12:28:06 2003
Subject: [R] inserting an extra row into an array
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB01EE2015@gimli.middleearth.kssg.com>
Message-ID: <3E54C98B.6019.108BC19@localhost>

Hi

On 20 Feb 2003 at 10:53, Wayne Jones wrote:

> Does anyone know a simple way to insert an extra row into a matrix or
> data frame, thus increasing the dimensions. 

something like

rbind(mat[1:5,],0,mat[6:8,])

if mat is matrix it should be OK but if it is data.frame you has 
either to add a correct sequence (factors, numbers, character 
values...) or to change a generated NA's to appropriate values.

> 
> 
> Wayne
> 
> 
> 
> KSS Ltd
> A division of Knowledge Support Systems Group plc
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1
> 6SS  England Company Registration Number 2800886 (Limited) 3449594
> (plc) Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com		http://www.kssg.com
> 
> 
> The information in this Internet email is confidential and may be
> legally privileged. It is intended solely for the addressee(s). Access
> to this Internet email by anyone else is unauthorised.
> 
> If you are not the intended recipient, any disclosure, copying,
> distribution or any action taken or omitted to be taken in reliance on
> it, is prohibited and may be unlawful. When addressed to our clients
> any opinions or advice contained in this Internet email are subject to
> the terms and conditions expressed in the governing engagement letter
> or contract.
> 
> This email message and any attached files have been scanned for the
> presence of computer viruses.  However you are advised that you open
> any attachments at your own risk.
> 
> 
>  [[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

Best regardsPetr Pikal
Precheza a.s., Nab?.Dr.E.Bene?e 24, 750 62 P?erov
tel: +420581 252 257 ; 724 008 364
petr.pikal at precheza.cz; p.pik at volny.cz
fax +420581 252 561



From fharrell at virginia.edu  Thu Feb 20 12:42:03 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu Feb 20 12:42:03 2003
Subject: [R] Who to decide what a generic function should look like?
In-Reply-To: <000d01c2d884$98690fa0$7341a8c0@alpha.wehi.edu.au>
References: <000d01c2d884$98690fa0$7341a8c0@alpha.wehi.edu.au>
Message-ID: <20030220064154.54e6c1e7.fharrell@virginia.edu>

On Thu, 20 Feb 2003 13:05:44 +1100
Henrik Bengtsson <hb at maths.lth.se> wrote:

> I am not sure if what I am asking below should be discussed under r-help
> or r-devel, so please feel free to move over to r-devel. 
> 
> This is a spin off from Gordon Smyth's question about generic functions
> and Robert Gentleman's reply. I have tried to raise the question before
> and I am sure this has been discussed by others, but never on the r-help
> list what I can see. My concern is that generic functions as defined
> today are only semi-generic. From ?Methods the definition of a generic
> function is:
> 
>      "A generic function is a function that has associated with it a
>      collection of other functions (the methods), all of which agree in
>      formal arguments with the generic."
> 
> For me a generic function should be fully generic in the sense that
> there are no requirements of arguments agreement (and therefore it
> should not be documented as a reply to Smyth's thread). Under the
> S3/UseMethod scheme as well S4/methods scheme this requirement is
> enforced (even though one can get around it by using only arguments
> "...") and under S4/methods it is followed even more strictly. I
> understand that by enforcing matching arguments (and argument types) the
> method dispatching mechanism can work much faster. Are there any another
> purposes than efficiency behind the argument matching requirement? Why
> not make a generic function truly generic? Having truly generic
> functions, the method dispatching mechanism could equally well be done
> by the language interpreter itself and thus making generic functions
> obsolete.
> 
. . .
> Henrik Bengtsson
> 

I agree completely with Henrik about the problems caused by argument agreement.  This has caused me a great deal of trouble.  As an example, I have many functions for converting S objects to LaTeX, with parallel functions for printing or plotting.  If I latex( ) a regression model fit, the types of LaTeX options that apply are drastically different than if I latex( ) a data frame for making a table with minor and major groupings.  A very small number of arguments are in common.  I tried converting latex( ) to use the new methods some time ago, and had to abondon the effort to large extent because of this problem.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From fharrell at virginia.edu  Thu Feb 20 12:49:02 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu Feb 20 12:49:02 2003
Subject: [R] is.numeric
In-Reply-To: <200302201058.46878.ahenningsen@email.uni-kiel.de>
References: <20030219110012.10581.77582.Mailman@hypatia.math.ethz.ch>
	<200302201058.46878.ahenningsen@email.uni-kiel.de>
Message-ID: <20030220064833.4dee99f8.fharrell@virginia.edu>

On Thu, 20 Feb 2003 10:58:46 +0100
Arne Henningsen <ahenningsen at email.uni-kiel.de> wrote:

> Hi,
> I have a vector, which contains both strings and numbers, e.g.
> 
> > foo <- c("str1",1234,"str2",0.9876)
> 
> I want to know if a distinct element of the vector is a string or a number and 
> took "is.numeric", but
> 
> > is.numeric(foo[2])
> [1] FALSE
> 
> because R treats the numbers in a mixed vectors as strings:
> 
> > foo
> [1] "str1"   "1234"   "str2"   "0.9876"
> 
> As a workaround I use:
> 
> > !is.na(as.numeric(foo[2]))
> [1] TRUE
> > !is.na(as.numeric(foo[1]))
> [1] FALSE
> Warning message:
> NAs introduced by coercion
> 
> This works, but I always get the spurious warning messages. Do you know a 
> better way or a way to suppress these warning messages?
> 
> Thanks,
> Arne
> 
> -- 
> Arne Henningsen
> Department of Agricultural Economics
> Christian-Albrechts-University Kiel
> 24098 Kiel, Germany
> Tel: +49-431-880-4445
> Fax: +49-431-880-1397 
> ahenningsen at email.uni-kiel.de
> http://www.uni-kiel.de/agrarpol/ahenningsen.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

This function in the Hmisc library may help:

all.is.numeric <- function(x, what=c('test','vector')) {
  what <- match.arg(what)
  old <- options(warn=-1)
  on.exit(options(old))
  xs <- x[x!='' & x!=' ']
  isnum <- !any(is.na(as.numeric(xs)))
  if(what=='test') isnum else if(isnum) as.numeric(x) else x
}


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From s.su at qut.edu.au  Thu Feb 20 13:00:07 2003
From: s.su at qut.edu.au (Steve Su)
Date: Thu Feb 20 13:00:07 2003
Subject: [R] Sobol Sequence Generator
Message-ID: <005001c2d8d7$82b7ff60$2032b583@busaccb337f>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030220/18660c97/attachment.pl

From mmarques at power.inescn.pt  Thu Feb 20 14:17:03 2003
From: mmarques at power.inescn.pt (Mark Marques)
Date: Thu Feb 20 14:17:03 2003
Subject: [R] ClustPlots part 2
Message-ID: <13813408380.20030220132405@power.inescn.pt>

Being more specific regarding the plots...
according to the docs the plot command is
smart enough to know which kind of plot is required based on the object passed
as parameter.
So I want to make several plots,from different objects, save each one in a JPEG or PNG but
each I try that the 1st plot stops the command line window asking what type of plot do I want to see.
How can I disable that interactiveness ?
I am using a R file as source I was hoping to end up with several PNG or JPG in directory...

Thanks in advance
Mark Marques



From kevin.wright at pioneer.com  Thu Feb 20 15:53:02 2003
From: kevin.wright at pioneer.com (Wright, Kevin)
Date: Thu Feb 20 15:53:02 2003
Subject: [R] Why does 'exists' need a quoted argument?
Message-ID: <BCB409391040E040A3B7F77238076C6F0C8E5A@leo.phibred.com>

Some functions in R need quoted arguments.  Consider this list:

help(rm)
rm(a)
is.na(a)
get("rm")
exists("rm")

Can someone explain why 'get' and 'exists' require quoted object names?

Would it make sense (more consistency) to have these functions check to see if the first argument is a string, and if not, then 'substitute' it?    Intuitively, 'exists' is checking to see if an object exists, not to see if a character string exists.  Evidently my intuition is wrong.

I can see that 'get' might need to have the option of using quotes, for example, get("?") or get("*").  However, look at this: 

> is.function(?)
Error: syntax error
> is.function("?")
[1] FALSE

I grow used to not quoting things and then stumble over 'exists' from time to time.

Looking forward to clarity or maybe a request for change.

Kevin Wright



This communication is for use by the intended recipient and cont ... [[dropped]]



From liuwensui at hotmail.com  Thu Feb 20 16:31:03 2003
From: liuwensui at hotmail.com (wensui liu)
Date: Thu Feb 20 16:31:03 2003
Subject: [R] loess
Message-ID: <DAV67EwgpeGwTzx4KkV0001a530@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030220/515c2086/attachment.pl

From loughlin at unc.edu  Thu Feb 20 16:37:03 2003
From: loughlin at unc.edu (Dan Loughlin)
Date: Thu Feb 20 16:37:03 2003
Subject: [R] Latin Hypercube Sampling in R?
Message-ID: <1045755874.21484.81.camel@condor2.emc.mcnc.org>

Hi,
I am interested in using R to perform Monte Carlo simulation using MC
sampling, Latin Hypercube Sampling (LHS), and importance sampling. While
I'm sure I can code R to do LHS, I would be surprised if others had not
done so. Is there R code publically available for this purpose? (I have
searched CRAN and the WWW extensively with no luck). Thanks in
advance.    
 
Dan Loughlin



From andy_liaw at merck.com  Thu Feb 20 16:41:02 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Feb 20 16:41:02 2003
Subject: [R] loess
Message-ID: <3A822319EB35174CA3714066D590DCD534BCD4@usrymx25.merck.com>

If your data are generated from a polynomial of degree p, then a local
polynomial smoother of degree p will reproduce that polynomial *exactly*.

You can find out how to change the span to loess by reading its help page.

Andy


> -----Original Message-----
> From: wensui liu [mailto:liuwensui at hotmail.com]
> Sent: Thursday, February 20, 2003 10:30 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] loess
> 
> 
> Dear Users,
> 
> I tried to use loess to fit a simple local quadratic: 
> loess(y~x).  But it returned the exact y value to me. (residuals==0)
> 
> Is it too good to be true? How do I specify the SPAN in loess 
> function?
> 
> Thanks a lot.
> 
> 
> 
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From spencer.graves at pdf.com  Thu Feb 20 16:59:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu Feb 20 16:59:06 2003
Subject: [R] inserting an extra row into an array
References: <3E54C98B.6019.108BC19@localhost>
Message-ID: <3E54FAE9.5050004@pdf.com>

How about

	  mat[c(1:5, 5:8),]?

Then change mat[6,] to whatever you want.

Spencer Graves

Petr Pikal wrote:
> Hi
> 
> On 20 Feb 2003 at 10:53, Wayne Jones wrote:
> 
> 
>>Does anyone know a simple way to insert an extra row into a matrix or
>>data frame, thus increasing the dimensions. 
> 
> 
> something like
> 
> rbind(mat[1:5,],0,mat[6:8,])
> 
> if mat is matrix it should be OK but if it is data.frame you has 
> either to add a correct sequence (factors, numbers, character 
> values...) or to change a generated NA's to appropriate values.
> 
> 
>>
>>Wayne
>>
>>
>>
>>KSS Ltd
>>A division of Knowledge Support Systems Group plc
>>Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1
>>6SS  England Company Registration Number 2800886 (Limited) 3449594
>>(plc) Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
>>mailto:kssg at kssg.com		http://www.kssg.com
>>
>>
>>The information in this Internet email is confidential and may be
>>legally privileged. It is intended solely for the addressee(s). Access
>>to this Internet email by anyone else is unauthorised.
>>
>>If you are not the intended recipient, any disclosure, copying,
>>distribution or any action taken or omitted to be taken in reliance on
>>it, is prohibited and may be unlawful. When addressed to our clients
>>any opinions or advice contained in this Internet email are subject to
>>the terms and conditions expressed in the governing engagement letter
>>or contract.
>>
>>This email message and any attached files have been scanned for the
>>presence of computer viruses.  However you are advised that you open
>>any attachments at your own risk.
>>
>>
>> [[alternate HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> Best regardsPetr Pikal
> Precheza a.s., Nab?.Dr.E.Bene?e 24, 750 62 P?erov
> tel: +420581 252 257 ; 724 008 364
> petr.pikal at precheza.cz; p.pik at volny.cz
> fax +420581 252 561
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Zhongming.Yang at cchmc.org  Thu Feb 20 17:03:27 2003
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Thu Feb 20 17:03:27 2003
Subject: [R] how to get std from loess
Message-ID: <se54b4c6.080@mailx.chmcc.org>

R Uers:

How can I get standard deviation from loess model in my R scripts?

Thanks



From jasont at indigoindustrial.co.nz  Thu Feb 20 17:15:03 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu Feb 20 17:15:03 2003
Subject: [R] Why does 'exists' need a quoted argument?
In-Reply-To: <BCB409391040E040A3B7F77238076C6F0C8E5A@leo.phibred.com>; from kevin.wright@pioneer.com on Thu, Feb 20, 2003 at 08:52:22AM -0600
References: <BCB409391040E040A3B7F77238076C6F0C8E5A@leo.phibred.com>
Message-ID: <20030221051526.B10195@camille.indigoindustrial.co.nz>

On Thu, Feb 20, 2003 at 08:52:22AM -0600, Wright, Kevin wrote:
> 
> Some functions in R need quoted arguments.  Consider this list:
> 
> help(rm)
> rm(a)
> is.na(a)
> get("rm")
> exists("rm")
> 
> Can someone explain why 'get' and 'exists' require quoted object names?
...

I just tried it:

 my.exists <- function (x, where = -1, 
        envir = if (missing(frame)) as.environment(where) 
                else sys.frame(frame), 
                frame, mode = "any", inherits = TRUE) {
                   if(!is.character(x)) x <- deparse(substitute(x))
                   .Internal(exists(x, envir, mode, inherits))
}

The problem is the the "if" statement if the object doesn't exist.  R
quite correctly stops when it tries to do a conditional based on a
non-existant object.

If, on the other hand, we don't do that, and deparse(substitute(x))
without the check, it does unexpected things if a string is given to
it.

my.exists <- function (x, where = -1, 
        envir = if (missing(frame)) as.environment(where) 
                else sys.frame(frame), 
                frame, mode = "any", inherits = TRUE) {
                   x <- deparse(substitute(x))
                   .Internal(exists(x, envir, mode, inherits))
}

> my.exists(ls)
[1] TRUE
> my.exists("ls")
[1] FALSE
> deparse(substitute("ls"))
[1] "\"ls\""

So deparse(substitute(x)) correctly passes the quotes, which wasn't
our intention (but it *was* what we asked for... ;).

If we start pulling quotes out using gsub or similar, we're getting
into very kludgy territory.

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From ripley at stats.ox.ac.uk  Thu Feb 20 17:19:06 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu Feb 20 17:19:06 2003
Subject: [R] Why does 'exists' need a quoted argument?
In-Reply-To: <BCB409391040E040A3B7F77238076C6F0C8E5A@leo.phibred.com>
Message-ID: <Pine.WNT.4.44.0302201612530.1188-100000@gannet.stats.ox.ac.uk>

foo <- "bar"
exists(foo)

asks if the object whose name is "bar" exists, not that whose name is "foo"
exists.  There is a distinction between operating on objects (rm and is.na)
and names of objects (get, exists, help).

The one exception in your list is help.  That should really be help("rm")
(which works), but help has special semantics (as do library, require and a
few others).


On Thu, 20 Feb 2003, Wright, Kevin wrote:

> Some functions in R need quoted arguments.  Consider this list:
>
> help(rm)
> rm(a)
> is.na(a)
> get("rm")
> exists("rm")
>
> Can someone explain why 'get' and 'exists' require quoted object names?
>
> Would it make sense (more consistency) to have these functions check to see if the first argument is a string, and if not, then 'substitute' it?    Intuitively, 'exists' is checking to see if an object exists, not to see if a character string exists.  Evidently my intuition is wrong.
>
> I can see that 'get' might need to have the option of using quotes, for example, get("?") or get("*").  However, look at this:
>
> > is.function(?)
> Error: syntax error
> > is.function("?")
> [1] FALSE
>
> I grow used to not quoting things and then stumble over 'exists' from time to time.
>
> Looking forward to clarity or maybe a request for change.

Get used to quoting things ....


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mmarques at power.inescn.pt  Thu Feb 20 17:29:03 2003
From: mmarques at power.inescn.pt (Mark Marques)
Date: Thu Feb 20 17:29:03 2003
Subject: [R] ClustPlots part3
In-Reply-To: <20030221045349.A10195@camille.indigoindustrial.co.nz>
References: <13813408380.20030220132405@power.inescn.pt>
 <20030221045349.A10195@camille.indigoindustrial.co.nz>
Message-ID: <807369023.20030220163612@power.inescn.pt>

I am using the library(cluster), and (mva)
Clustering function clara()

sometihng like this:

cdata <- clara(vdata,6)
plot(cdata)
savePlot(filename="c:\\clara1",type=c("png"),2)

But for my surprise the after the plot I get :

   "Hit <Return> to see next plot:"
if i do something like :
   plot(cdata,3)

I get:
  Make a plot selection (or 0 to exit):
 
  1:plot  All
  2:plot  Clusplot
  3:plot  Silhouette Plot
  Selection:

As   far   I   know  calling  plot  is using clusPlot() by reading the
"clara" object.
How can I avoid that interaction ?

Thanks in advance



From Morten.Sickel at nrpa.no  Thu Feb 20 17:33:03 2003
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Thu Feb 20 17:33:03 2003
Subject: [R] Why does 'exists' need a quoted argument?
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5E52@postix.nrpa.no>

Kevin Wright wrote:
/snip/
>Can someone explain why 'get' and 'exists' require quoted object names?

>Would it make sense (more consistency) to have these functions check to see
if the 
>first argument is a string, and if not, then 'substitute' it?
Intuitively, >'exists' is checking to see if an object exists, not to see if
a character string 
>exists.  Evidently my intuition is wrong.

Well, if you read the ?exists you'll see that it "Search for an R object of
the given name on the search path". Even though I am absolutely no R
developer, I would guess that it would be not impossible to write a function
that does as you thinks, but, its functionality would be worse than for the
current exists, consider for example:

<code>
sql<-Big_ugly_slow_query
sql2<-some_more_parameters
for (i in c("Foo","Bar","Baz"))
  if (!exists(i)){ 
	assign(i,sqlquery(handle,paste(sql1,i,sql2)
  }
}
</code>

i.e. if the object doesn't exist, I have to initialize it, if it does exist,
I just keep on using it, I know that the object i exists, so I don't care
about that. On the other hand, if it was automatically substituting what was
found to be a string, it would not be possible to

<code>
if (!exists("String")){String<-"Default value"}
</code>

So, no, I think some useful functionality would be thrown out if exist did
not require a string.

Morten Sickel



From carlos.ortega at minorplanet.com  Thu Feb 20 17:41:03 2003
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Thu Feb 20 17:41:03 2003
Subject: [R] ClustPlots part3
In-Reply-To: <807369023.20030220163612@power.inescn.pt>
Message-ID: <LMEKLMMLPDKOJNOOEELEAEAHEAAA.carlos.ortega@minorplanet.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030220/60cf98a1/attachment.pl

From gavin.simpson at ucl.ac.uk  Thu Feb 20 18:03:03 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu Feb 20 18:03:03 2003
Subject: [R] ClustPlots part3
In-Reply-To: <807369023.20030220163612@power.inescn.pt>
Message-ID: <001201c2d902$2d4d0720$4c202880@gsimpson>

Hi Mark

Does this help?

plot(clara.obj, which.plots = 1)

This was buried a bit in the documentation for cluster.  plot.partition() is
the function used to do the plotting.  See its help page

You need to tell it to do plot 1 or 2 or NULL.  1 gets you a clusplot, 2
gets a silhouette plot, NULL gets both.  In the above command, the
which.plots gets passed though to plot.partition and only produces the one
diagram.

All the best,

Gavin

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

-----Original Message-----
From: r-help-admin at stat.math.ethz.ch [mailto:r-help-admin at stat.math.ethz.ch]
On Behalf Of Mark Marques
Sent: 20 February 2003 16:36
To: R-help Mailing list.
Subject: [R] ClustPlots part3


I am using the library(cluster), and (mva)
Clustering function clara()

sometihng like this:

cdata <- clara(vdata,6)
plot(cdata)
savePlot(filename="c:\\clara1",type=c("png"),2)

But for my surprise the after the plot I get :

   "Hit <Return> to see next plot:"
if i do something like :
   plot(cdata,3)

I get:
  Make a plot selection (or 0 to exit):
 
  1:plot  All
  2:plot  Clusplot
  3:plot  Silhouette Plot
  Selection:

As   far   I   know  calling  plot  is using clusPlot() by reading the
"clara" object.
How can I avoid that interaction ?

Thanks in advance

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rbonk at host.sk  Thu Feb 20 18:34:03 2003
From: rbonk at host.sk (Rado Bonk)
Date: Thu Feb 20 18:34:03 2003
Subject: [R] outliers/interval data extraction
Message-ID: <1045784268.14823.140.camel@templar.fns.uniba.sk>

Dear R-users,

I have two outliers related questions.

I.
I have a vector consisting of 69 values.

mean = 0.00086
SD = 0.02152

The shape of EDA graphics (boxplots, density plots) is heavily distorted
due to outliers. How to define the interval for outliers exception? Is
<2SD - mean + 2SD> interval a correct approach?

Or should I define 95% (or 99%) limit of agreement for data interval,
and exclude lower, and higher values? 

II. 
How to extract only those values from vector which fulfill the condition
of interval (higher than A, and lower than B)?

Rado Bonk



From ben at zoo.ufl.edu  Thu Feb 20 18:44:02 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Thu Feb 20 18:44:02 2003
Subject: [R] outliers/interval data extraction
In-Reply-To: <1045784268.14823.140.camel@templar.fns.uniba.sk>
Message-ID: <Pine.LNX.4.44.0302201251350.26480-100000@bolker.zoo.ufl.edu>

> II. 
> How to extract only those values from vector which fulfill the condition
> of interval (higher than A, and lower than B)?

  x[x>A & x<B]

> 
> Rado Bonk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From hennig at stat.math.ethz.ch  Thu Feb 20 18:55:03 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Thu Feb 20 18:55:03 2003
Subject: [R] outliers/interval data extraction
In-Reply-To: <1045784268.14823.140.camel@templar.fns.uniba.sk>
Message-ID: <Pine.LNX.4.44.0302201841560.2077-100000@florence>

Hi,

the boxplot is based on the quartiles which are much less outlier sensitive
than mean and SD and should therefore not be "heavily distorted by
outliers". What you mean is presumably that you see the area of the main
bulk of the data only as a very small box on the screen because of your
outliers. 
However, a simple straight forward method for outlier identification is  
median +/- 5.2*mad as suggested by Hampel, Technometrics 27 (1985) 95-107.
Outlier identification by use of mean and SD is often bad because these
statistics are strongly influenced by the outliers.

x <- data vector
medx <- median(x)
madx <- mad(x)
outliers <- (x<medx-5.2*madx) | (x>medx+5.2*madx)
selected <- x[!outliers]

Best,
Christian

On 20 Feb 2003, Rado Bonk wrote:

> Dear R-users,
> 
> I have two outliers related questions.
> 
> I.
> I have a vector consisting of 69 values.
> 
> mean = 0.00086
> SD = 0.02152
> 
> The shape of EDA graphics (boxplots, density plots) is heavily distorted
> due to outliers. How to define the interval for outliers exception? Is
> <2SD - mean + 2SD> interval a correct approach?
> 
> Or should I define 95% (or 99%) limit of agreement for data interval,
> and exclude lower, and higher values? 
> 
> II. 
> How to extract only those values from vector which fulfill the condition
> of interval (higher than A, and lower than B)?
> 
> Rado Bonk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de



From jasont at indigoindustrial.co.nz  Thu Feb 20 19:10:03 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu Feb 20 19:10:03 2003
Subject: [R] outliers/interval data extraction
In-Reply-To: <1045784268.14823.140.camel@templar.fns.uniba.sk>; from rbonk@host.sk on Thu, Feb 20, 2003 at 06:37:48PM -0500
References: <1045784268.14823.140.camel@templar.fns.uniba.sk>
Message-ID: <20030221070803.A10839@camille.indigoindustrial.co.nz>

On Thu, Feb 20, 2003 at 06:37:48PM -0500, Rado Bonk wrote:
> Dear R-users,
> 
> I have two outliers related questions.
> 
> I.
> I have a vector consisting of 69 values.
> 
> mean = 0.00086
> SD = 0.02152
> 
> The shape of EDA graphics (boxplots, density plots) is heavily distorted
> due to outliers. How to define the interval for outliers exception? Is
> <2SD - mean + 2SD> interval a correct approach?

Yikes.  

There's been a lot of discussion of this over the years; these
discussions usually  generate more heat than light.

<personal bias>
Throwing away outliers without further investigation is often
considered a bad idea.  The argument is that you get into a situation
where you are rejecting data because it doesn't fit the model, which
is a strange approach.  The most famous case of this was satelite
data on ozone thickness over Antarctica - the ozone hole was missed
for years because of an automatic outlier-rejection routine in the
data analysis.  If those outliers hadn't been rejected, the steps
taken could've been done sooner, avoiding a lot of dammage.

My own work is in industrial process control - if I ignored outliers,
I'd make an awful lot of very bad mistakes, and wouldn't have a job
for long. 

Outliers aren't necessarily wrong - sometimes the data is trying to
tell you something.
</personal bias>

Robust summaries are another way.  Check out the help pages for mad(),
IQR(), fivenum().  

Having said that, if you want to compare outlier-free data with your
raw data to help enlighten you about where those outliers might be
comming from, something like this might help...

ss <- mad(myvec)
mm <- median(myvec)
ind <- (myvec > mm - 3*ss & myvec < mm + 3*ss)
# or
ind2 <- (myvec > quantile(myvec,0.025) & myvec <quantile(myvec,0.975))

boxplot(myvec[ind])
boxplot(myvec[ind2])

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From jasont at indigoindustrial.co.nz  Thu Feb 20 19:18:02 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu Feb 20 19:18:02 2003
Subject: [R] outliers/interval data extraction
In-Reply-To: <Pine.LNX.4.44.0302201841560.2077-100000@florence>; from hennig@stat.math.ethz.ch on Thu, Feb 20, 2003 at 06:54:21PM +0100
References: <1045784268.14823.140.camel@templar.fns.uniba.sk> <Pine.LNX.4.44.0302201841560.2077-100000@florence>
Message-ID: <20030221071811.A10997@camille.indigoindustrial.co.nz>

On Thu, Feb 20, 2003 at 06:54:21PM +0100, Christian Hennig wrote:
... 
> However, a simple straight forward method for outlier identification is  
> median +/- 5.2*mad as suggested by Hampel, Technometrics 27 (1985) 95-107.
...
> x <- data vector
> medx <- median(x)
> madx <- mad(x)
> outliers <- (x<medx-5.2*madx) | (x>medx+5.2*madx)
> selected <- x[!outliers]

I haven't read the paper cited above, but I suspect the authors were
talking about the true mad.  By default, R re-scales the mad to adjust
for the normal case (ie multiplies by about 1.48).  If that's correct
(and I'm quite happy to be wrong), this changes 5.2 to 3.5 in the
example above.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From arnaud_amsellem at ssga.com  Thu Feb 20 19:56:03 2003
From: arnaud_amsellem at ssga.com (arnaud_amsellem@ssga.com)
Date: Thu Feb 20 19:56:03 2003
Subject: [R] R and Factset
Message-ID: <OF91A6A7C0.B1AE59D2-ON80256CD3.0067CE52@ssga.statestreet.com>

Has anybody ever tried to download data straight from Factset into an R
dataframe?
Any help appreciated

Thanks
                           
 Arnaud Amsellem           
 Investment Manager        
 Active Equity             
 State Street Global       
 Advisors United Kingdom   
 Ltd.                      
 Regulated by the          
 Financial Services        
 Authority                 
 +44 20 7698 6170 (Direct  
 Line)                     
 +44 20 7698 6333 (Main    
 Fax)                      
                           
 Please visit our Web site 
 at www.ssga.com/uk



From spencer.graves at pdf.com  Thu Feb 20 20:31:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu Feb 20 20:31:03 2003
Subject: [R] transportable code?
References: <Pine.LNX.4.44.0302191243290.18325-100000@echidna.fhcrc.org> <3E53F376.7020107@pdf.com>
Message-ID: <3E552CBE.9060301@pdf.com>

As an extension of the recent discussion of "functions different in R 
and S", what suggestions do people have for writing transportable code 
for R/S beyond Venables and Ripley (2000, S Programming, pp. 202-203)?

For example, I recently found myself using the following construct:

	if(version$major < 5){
#		Function oldClass was introduced with the "new S"
#		and is not present in R or S-Plus 2000
		oldClass <- class
	}

Similarly, I plan to define a function "gsub" 
if(is.null(version$language)).

Do these seem reasonable?  Are there other suggestions / standard / 
compilations of thoughts?

Thanks,
Spencer Graves



From bates at stat.wisc.edu  Thu Feb 20 20:52:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu Feb 20 20:52:03 2003
Subject: [R] Conversion to S4 classes and methods
Message-ID: <6r7kbuwx1t.fsf@bates4.stat.wisc.edu>

Recently on R-help there has been some discussion of the use of S4
classes and methods from the methods package in R.  I will be
presenting a paper (joint work with Saikat DebRoy) at DSC-2003
entitled "Converting a large R package to S4 classes and methods".  A
preprint copy of the paper is now available on my web site

                   http://www.stat.wisc.edu/~bates

Comments are welcome.



From David_Hinds at perlegen.com  Thu Feb 20 21:06:03 2003
From: David_Hinds at perlegen.com (David Hinds)
Date: Thu Feb 20 21:06:03 2003
Subject: [R] Odd scheduling behavior of R on Windows
Message-ID: <945A2BF651FA6D4B92F4F5D46AEE863A03EC88@newman.perlegen.com>

I'm using R-1.6.1 on a dual Xeon system running Windows XP.  
When I have two compute intensive programs running in the 
background, and I start a calculation in an interactive R 
session, that calculation gets just a few percent of the 
available CPU time.  This is true even if I use the task 
manager to set the priority of the background jobs to "low" 
and the R session to "high".  Scheduling of the background 
jobs seems to behave as expected; if I start more than two, 
then jobs with higher priority get more CPU time than jobs 
with lower priority.  So it seems to be R that is behaving 
strangely.

R seems to get its full allotment of CPU time when I invoke
single internal functions that take a significant amount of 
time to run.  It is starved when I run more complex R code
that is accumulating results of several thousand small
linear regressions.

Is this a known issue?  I'm not sure what could cause this; 
perhaps R is yielding the processor when the GUI checks for 
interactive events, and is getting starved for CPU time 
because it is yielding too frequently?  If these GUI checks
happen between execution of R statements, then perhaps there
should be a way to throttle the frequency of the checks, or
an option to disable them?

-- Dave Hinds



From spencer.graves at pdf.com  Thu Feb 20 23:28:02 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu Feb 20 23:28:02 2003
Subject: [R] Managing size of plots with many points
References: <Pine.LNX.4.44.0302191243290.18325-100000@echidna.fhcrc.org> <3E53F376.7020107@pdf.com>
Message-ID: <3E55565B.2060306@pdf.com>

What is available to limit obvious overplotting, e.g. with a million 
points?  My primary motivation is to produce plots from R and S-Plus 
that occupy minimal hard drive space without sacrificing visual clarity. 
  (I've crashed MicroSoft PowerPoint by including plots that are too big.)

Right now, I can think of three different scenarios:

	  1.  Monotonic applications such as a normal probability plot.

	  2.  Lines (or connected dots).

	  3.  General scatterplots.

Several approaches have been suggested, and I've implemented an ugly 
algorithm.  However, I believe something better should be available, but 
I don't even know what words to use in a search.

Ideas?
Thanks,
Spencer Graves



From jerrytheshrub at hotmail.com  Thu Feb 20 23:45:04 2003
From: jerrytheshrub at hotmail.com (Jeremy Z Butler)
Date: Thu Feb 20 23:45:04 2003
Subject: [R] group means
Message-ID: <F13sATW7vgyYoP1towy0003d652@hotmail.com>

Hi,
Any hints on how I would generate the means of each 5 number group in a 
column of numbers in data.frame form. i.e. get mean of first five in column 
and then mean of second five in column etc. etc.

1   3.4
2   6.0
3   2.5
4   7.5
5   1.8
6   4.2
7   6.4
8   5.7
9   17.2
10  13.5

Grateful for any suggestions
Jeremy



From sundar.dorai-raj at pdf.com  Thu Feb 20 23:56:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu Feb 20 23:56:03 2003
Subject: [R] group means
References: <F13sATW7vgyYoP1towy0003d652@hotmail.com>
Message-ID: <3E555CAE.2050902@pdf.com>


Jeremy Z Butler wrote:
> Hi,
> Any hints on how I would generate the means of each 5 number group in a 
> column of numbers in data.frame form. i.e. get mean of first five in 
> column and then mean of second five in column etc. etc.
> 
> 1   3.4
> 2   6.0
> 3   2.5
> 4   7.5
> 5   1.8
> 6   4.2
> 7   6.4
> 8   5.7
> 9   17.2
> 10  13.5
> 

See ?running in package:gregmisc.

Sundar



From lockwood at rand.org  Fri Feb 21 00:00:07 2003
From: lockwood at rand.org (J.R. Lockwood)
Date: Fri Feb 21 00:00:07 2003
Subject: [R] group means
In-Reply-To: <F13sATW7vgyYoP1towy0003d652@hotmail.com>
Message-ID: <Pine.LNX.4.33.0302201747240.4433-100000@penguin.rand.org>

> Date: Fri, 21 Feb 2003 11:43:53 +1300
> From: Jeremy Z Butler <jerrytheshrub at hotmail.com>
> To: r-help at stat.math.ethz.ch
> Subject: [R] group means
> 
> Hi,
> Any hints on how I would generate the means of each 5 number group in a 
> column of numbers in data.frame form. i.e. get mean of first five in column 
> and then mean of second five in column etc. etc.
> 

One way to do what you want is to create a grouping variable and add
it to your data frame as a factor, and then use tapply. e.g., assuming
your dataframe "d" with column "x" has a number of rows divisible by
5, use

d$grp<-gl(dim(d)[1]/5,5)
tapply(d$x,d$grp,"mean")

J.R. Lockwood
412-683-2300 x4941
lockwood at rand.org
http://www.rand.org/methodology/stat/members/lockwood/



From rpeng at stat.ucla.edu  Fri Feb 21 00:04:04 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri Feb 21 00:04:04 2003
Subject: [R] group means
In-Reply-To: <3E555CAE.2050902@pdf.com>
Message-ID: <Pine.GSO.4.10.10302201459110.22849-100000@quetelet.stat.ucla.edu>

You could try using `aggregate', e.g.

df <- data.frame(a = rnorm(10, 1), b = rnorm(10, 2))
grps <- rep(1:2, each = 5)
aggregate(df, list(grps), mean)

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Thu, 20 Feb 2003, Sundar Dorai-Raj wrote:

> 
> 
> Jeremy Z Butler wrote:
> > Hi,
> > Any hints on how I would generate the means of each 5 number group in a 
> > column of numbers in data.frame form. i.e. get mean of first five in 
> > column and then mean of second five in column etc. etc.
> > 
> > 1   3.4
> > 2   6.0
> > 3   2.5
> > 4   7.5
> > 5   1.8
> > 6   4.2
> > 7   6.4
> > 8   5.7
> > 9   17.2
> > 10  13.5
> > 
> 
> See ?running in package:gregmisc.
> 
> Sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From hb at maths.lth.se  Fri Feb 21 00:33:03 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri Feb 21 00:33:03 2003
Subject: [R] group means
In-Reply-To: <F13sATW7vgyYoP1towy0003d652@hotmail.com>
Message-ID: <001e01c2d938$592bbdb0$7341a8c0@alpha.wehi.edu.au>

When all groups have the same number of elements and the groups are
consecutive I normally transform the vector into a matrix where each
column contains data from one group. Then I perform whatever on each
group using apply():

x <- c(3.4, 6.0, 2.5, 7.5, 1.8, 4.2, 6.4, 5.7, 17.2, 13.5)
xm <- matrix(x, nrow=5)   # matrix() "fills by column" by default
print(xm)
#      [,1] [,2]
# [1,]  3.4  4.2
# [2,]  6.0  6.4
# [3,]  2.5  5.7
# [4,]  7.5 17.2
# [5,]  1.8 13.5
m <- apply(xm, MARGIN=2, FUN=mean, na.rm=TRUE) # MARGIN=2 means "along
columns" or "columnwise"
print(m) 
# [1] 4.24 9.40

Hope this helps

Henrik Bengtsson

Home: 201/445 Royal Parade, 3052 Parkville
Office: Bioinformatics, WEHI, Parkville
+61 (0)412 269 734 (cell), +61 (0)3 9345 2324 (lab),
+1 (508) 464 6644 (global fax)
hb at wehi.edu.au, http://www.maths.lth.se/~hb/
Time zone: +11h UTC (Sweden +1h UTC, Calif. -8h UTC)

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jeremy Z Butler
> Sent: den 21 februari 2003 09:44
> To: r-help at stat.math.ethz.ch
> Subject: [R] group means
> 
> 
> Hi,
> Any hints on how I would generate the means of each 5 number 
> group in a 
> column of numbers in data.frame form. i.e. get mean of first 
> five in column 
> and then mean of second five in column etc. etc.
> 
> 1   3.4
> 2   6.0
> 3   2.5
> 4   7.5
> 5   1.8
> 6   4.2
> 7   6.4
> 8   5.7
> 9   17.2
> 10  13.5
> 
> Grateful for any suggestions
> Jeremy
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From spencer.graves at pdf.com  Fri Feb 21 01:12:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 21 01:12:03 2003
Subject: [R] group means
References: <001e01c2d938$592bbdb0$7341a8c0@alpha.wehi.edu.au>
Message-ID: <3E556E88.20607@pdf.com>

How about:

 > group.means <- function(x, k=5){
+  n.gps <- floor(length(x)/k)
+  rep(1, k) %*% array(x[1:(k*n.gps)], dim=c(k, n.gps))
+ }
 > group.means(c(3.4, 6.0, 2.5, 7.5, 1.8, 4.2, 6.4, 5.7, 17.2, 13.5))
      [,1] [,2]
[1,] 21.2   47

Best Wishes,
Spencer Graves

Henrik Bengtsson wrote:
> When all groups have the same number of elements and the groups are
> consecutive I normally transform the vector into a matrix where each
> column contains data from one group. Then I perform whatever on each
> group using apply():
> 
> x <- c(3.4, 6.0, 2.5, 7.5, 1.8, 4.2, 6.4, 5.7, 17.2, 13.5)
> xm <- matrix(x, nrow=5)   # matrix() "fills by column" by default
> print(xm)
> #      [,1] [,2]
> # [1,]  3.4  4.2
> # [2,]  6.0  6.4
> # [3,]  2.5  5.7
> # [4,]  7.5 17.2
> # [5,]  1.8 13.5
> m <- apply(xm, MARGIN=2, FUN=mean, na.rm=TRUE) # MARGIN=2 means "along
> columns" or "columnwise"
> print(m) 
> # [1] 4.24 9.40
> 
> Hope this helps
> 
> Henrik Bengtsson
> 
> Home: 201/445 Royal Parade, 3052 Parkville
> Office: Bioinformatics, WEHI, Parkville
> +61 (0)412 269 734 (cell), +61 (0)3 9345 2324 (lab),
> +1 (508) 464 6644 (global fax)
> hb at wehi.edu.au, http://www.maths.lth.se/~hb/
> Time zone: +11h UTC (Sweden +1h UTC, Calif. -8h UTC)
> 
> 
>>-----Original Message-----
>>From: r-help-admin at stat.math.ethz.ch 
>>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jeremy Z Butler
>>Sent: den 21 februari 2003 09:44
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] group means
>>
>>
>>Hi,
>>Any hints on how I would generate the means of each 5 number 
>>group in a 
>>column of numbers in data.frame form. i.e. get mean of first 
>>five in column 
>>and then mean of second five in column etc. etc.
>>
>>1   3.4
>>2   6.0
>>3   2.5
>>4   7.5
>>5   1.8
>>6   4.2
>>7   6.4
>>8   5.7
>>9   17.2
>>10  13.5
>>
>>Grateful for any suggestions
>>Jeremy
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list 
>>http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From elvis at xlsolutions-corp.com  Fri Feb 21 02:12:03 2003
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Fri Feb 21 02:12:03 2003
Subject: [R] XLS Course***R/S-plus Programming III-Intermediate with Advanced Topics***New York, San Francisco, Philadelphia.
Message-ID: <APEHLKCMHHAKBGLAPKPCEEGICCAA.elvis@xlsolutions-corp.com>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud
to announce a 2-day "R/S-plus Programming III" course;
Intermediate level with advanced topics.


****New York City ---------------> March 13-14

****San Francisco ----------> April 28-29

****Philadelphia -----------> February 20-21


Course Description:

This intermediate level course is recommended for R/Splus users who have
some previous experience using R/S-plus and wish to hone their skills.
Casual users can "fill in the gaps" of their knowledge to make better
use of R/S-PLus.

This course will focus on advanced topics and graphics, Vectorization,
resource management, connecting to C++, classes and methods (including S4
classes)
and macros.


Course Outline:

- Overview of R/S-Plus
- Using Advanced Lattice/Trellis Graphics
- Using High-level Plotting Functions
- Taking advantage of fast objects and fast functions
- Avoiding Loops
- Vectorization
- Resource Management
- Techniques for Effective use of R and S-Plus
- Connecting to C++
- Classes (S4/S-Plus) and Methods
- Macros
- Building and Distributing Packages (libraries)


Payments are due AFTER the course! Take advantage of the early-bird and
save even more.

Registration and Additional Information:

Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578 x221
Visit us: www.xlsolutions-corp.com/training.htm


Course Format:

This course consists of a series of short lectures thought by R developper
gurus with demonstrations and interactive sessions for the participants.
Each student is provided with bound copies of the notes and
a CD-ROM containing all examples, exercises and software used on the course.



Share Your Thoughts:

Are there any additional topics you would like for this course to address?
Would you like for this course to be offered in another city?

Please let us know by contributing to our recommendation list:
training at xlsolutions-corp.com.

========================================================================

R/S-Plus Programming III-Intermediate with Advanced Topics
Pre-registration Form (Please email or print and fax: 206-686-1578)
XLsolutions Corporation: For your Solutions needs, Consulting and Training.
www.xlsolutions-corp.com



Title...... First Name ................. Last Name....................

Organization..........................................................

Mailing Address.......................................................

.....................................................................

.....................................................................

Zip Code...................... Country.............................

Telephone........................... Fax ...............................

E-mail................................................................

Payment will be made by: (1) check (2) invoice (3) Credit Card



Elvis Miller, PhD
Manager Training and Technical Support
North American Division
XLSolutions Corporation
Email: elvis at xlsolutions-corp.com
Web: www.xlsolutions-corp.com



From white.denis at epamail.epa.gov  Fri Feb 21 02:43:03 2003
From: white.denis at epamail.epa.gov (white.denis@epamail.epa.gov)
Date: Fri Feb 21 02:43:03 2003
Subject: [R] Managing size of plots with many points
Message-ID: <OFEEF0C97E.D6019A23-ON88256CD4.0008FAE5@rtp.epa.gov>

One approach you might consider is Dan Carr's hexbin function available
in Splus and in the Bioconductor package at www.bioconductor.org.

> What is available to limit obvious overplotting, e.g. with a million
> points?  My primary motivation is to produce plots from R and S-Plus
> that occupy minimal hard drive space without sacrificing visual
clarity.
>   (I've crashed MicroSoft PowerPoint by including plots that are too
big.)
>
> Right now, I can think of three different scenarios:
>
>              1.  Monotonic applications such as a normal probability
plot.
>
>              2.  Lines (or connected dots).
>
>              3.  General scatterplots.
>
> Several approaches have been suggested, and I've implemented an ugly
> algorithm.  However, I believe something better should be available,
but
> I don't even know what words to use in a search.
>
> Ideas?
> Thanks,
> Spencer Graves



From hennig at stat.math.ethz.ch  Fri Feb 21 10:10:03 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Fri Feb 21 10:10:03 2003
Subject: [R] outliers/interval data extraction
In-Reply-To: <20030221071811.A10997@camille.indigoindustrial.co.nz>
Message-ID: <Pine.LNX.4.44.0302210953270.2075-100000@florence>

Hi,

sorry, I was wrong and that's true. The Hampel
suggestion is
outliers <- (x<medx-3.5*madx) | (x>medx+3.5*madx)
or to use the multiplier 5.2 with
madx <- mad(x, constant=1).

Christian

On Fri, 21 Feb 2003, Jason Turner wrote:

> On Thu, Feb 20, 2003 at 06:54:21PM +0100, Christian Hennig wrote:
> ... 
> > However, a simple straight forward method for outlier identification is  
> > median +/- 5.2*mad as suggested by Hampel, Technometrics 27 (1985) 95-107.
> ...
> > x <- data vector
> > medx <- median(x)
> > madx <- mad(x)
> > outliers <- (x<medx-5.2*madx) | (x>medx+5.2*madx)
> > selected <- x[!outliers]
> 
> I haven't read the paper cited above, but I suspect the authors were
> talking about the true mad.  By default, R re-scales the mad to adjust
> for the normal case (ie multiplies by about 1.48).  If that's correct
> (and I'm quite happy to be wrong), this changes 5.2 to 3.5 in the
> example above.
> 
> Cheers
> 
> Jason
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de



From otoomet at econ.dk  Fri Feb 21 10:17:09 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Fri Feb 21 10:17:09 2003
Subject: [R] Managing size of plots with many points
In-Reply-To: <3E55565B.2060306@pdf.com> (message from Spencer Graves on Thu,
	20 Feb 2003 14:27:39 -0800)
References: <Pine.LNX.4.44.0302191243290.18325-100000@echidna.fhcrc.org> <3E53F376.7020107@pdf.com> <3E55565B.2060306@pdf.com>
Message-ID: <200302210916.h1L9Gkh13490@punik.econ.au.dk>

Hi,

 | What is available to limit obvious overplotting, e.g. with a million 
 | points?  My primary motivation is to produce plots from R and S-Plus 
 | that occupy minimal hard drive space without sacrificing visual clarity. 
 |   (I've crashed MicroSoft PowerPoint by including plots that are too big.)
 | 
 | Right now, I can think of three different scenarios:
 | 
 | 	  1.  Monotonic applications such as a normal probability plot.
 | 
 | 	  2.  Lines (or connected dots).
 | 
 | 	  3.  General scatterplots.
 | 
 | Several approaches have been suggested, and I've implemented an ugly 
 | algorithm.  However, I believe something better should be available, but 
 | I don't even know what words to use in a search.

These issues have been discussed occasionally here in the list.  Some
options I remember where:

If you consider only about storage space, then PNG output may be a
choice.

Use contour plot or another way to smooth the density and plot it
e.g. as persp.

Use smoothed density in order to drop part of your points (drop more
points where the density is higher).


Perhaps it helps.

Ott



From otoomet at econ.dk  Fri Feb 21 10:22:04 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Fri Feb 21 10:22:04 2003
Subject: [R] question about XML (package)
Message-ID: <200302210923.h1L9NFj13501@punik.econ.au.dk>

Hi,

I have a problem with spacing in XML files when reading them with
xmlTreeParse.  I don't know the exact specification of xml but
according what I have red before it should work.

consider a tiny test.xml file:

<?xml version="1.0"?>
<fields>
<v1>1 </v1>
<v2> 2 </v2>
<v3> 3</v3>
</fields>

i.e. I have three fields v1, v2 and v3 which differ only by spacing.
Now when reading it as

> a <- xmlTreeParse("/home/otoomet/tyyq/Taani-piir/andmed/test.xml")
> a$doc$children$fields
 <fields>
  <v1>
  </v1>
  <v2>
  2
  </v2>
  <v3>
  3
  </v3>
 </fields>

you can see that field v1 is empty.  Is it my misinterpretation, or a
problem with the library?

Thanks in advance,

Ott

-----------------
> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    5.1              
year     2002             
month    06               
day      17               
language R                
------------
Package: XML
Version: 0.93-1
Date: 2002/11/06



From Kamile.Sanli at science.ankara.edu.tr  Fri Feb 21 10:38:03 2003
From: Kamile.Sanli at science.ankara.edu.tr (Kamile.Sanli@science.ankara.edu.tr)
Date: Fri Feb 21 10:38:03 2003
Subject: [R] Robust Regression
Message-ID: <BasiliX-1.1.0-10458201583e55f2fecbc90@ceres.cc.ankara.edu.tr>

I need Robust Regression algorithm; Huber, Tukey and Andrews.
Thank you a lot, for your time.



From mkondrin at hppi.troitsk.ru  Fri Feb 21 10:47:03 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Fri Feb 21 10:47:03 2003
Subject: [R] grid.grill?
Message-ID: <3E568E59.5030809@hppi.troitsk.ru>

Why this command does not return grob? What is special about grill and 
what makes it different from axis, lines, rectangles...
Thanks in advance



From ripley at stats.ox.ac.uk  Fri Feb 21 11:09:10 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 21 11:09:10 2003
Subject: [R] Robust Regression
In-Reply-To: <BasiliX-1.1.0-10458201583e55f2fecbc90@ceres.cc.ankara.edu.tr>
Message-ID: <Pine.LNX.4.44.0302211006310.28621-100000@gannet.stats>

Try help.search("robust")

On Fri, 21 Feb 2003 Kamile.Sanli at science.ankara.edu.tr wrote:

> I need Robust Regression algorithm; Huber, Tukey and Andrews.

Sounds like a homework exercise: why do you not want the best available 
robust regression methods?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Fri Feb 21 11:14:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Feb 21 11:14:03 2003
Subject: [R] Robust Regression
In-Reply-To: <BasiliX-1.1.0-10458201583e55f2fecbc90@ceres.cc.ankara.edu.tr>
References: <BasiliX-1.1.0-10458201583e55f2fecbc90@ceres.cc.ankara.edu.tr>
Message-ID: <3E55FBE6.5020208@statistik.uni-dortmund.de>

Kamile.Sanli at science.ankara.edu.tr wrote:
> I need Robust Regression algorithm; Huber, Tukey and Andrews.
> Thank you a lot, for your time.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

See ?rlm in package MASS for robust regression (using e.g. Huber's M 
estimator).

Uwe Ligges



From upton at mitre.org  Fri Feb 21 13:25:03 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Fri Feb 21 13:25:03 2003
Subject: [R] question about XML (package)
References: <200302210923.h1L9NFj13501@punik.econ.au.dk>
Message-ID: <3E561A7C.D14C7ACC@mitre.org>

Ott,

I get the same thing on windows version. If you set "trim=FALSE" in the
xmlTreeParse function call, it works. I suspect xmlTreeParse is trimming
a little too much! But xmlTreeParse(with trim=TRUE) also works when the
first character is a non-digit - see below. We'll probably need to look
at the source code, unless someone else has better insight.

> a <- xmlTreeParse("test.xml",trim=FALSE)
> a$doc
$file
[1] "test.xml"

$version
[1] "1.0"

$children
$children$fields
 <fields>


  <v1>
  1
  </v1>


  <v2>
   2
  </v2>


  <v3>
   3
  </v3>


 </fields>

However, it also works when the first character is a non-digit - so far.
Here's a revised test.xml file:
<?xml version="1.0"?>
<fields>
<v1>a1 </v1>
<v2>2 </v2>
<v3> 3</v3>
</fields>

> a <- xmlTreeParse("test.xml")
> a
$doc
$file
[1] "test.xml"

$version
[1] "1.0"

$children
$children$fields
 <fields>
  <v1>
  a1
  </v1>
  <v2>
  </v2>
  <v3>
  3
  </v3>
 </fields>

HTH
steve


-------------------------------
> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.2
year     2003
month    01
day      10
language R  -

Ott Toomet wrote:

> Hi,
>
> I have a problem with spacing in XML files when reading them with
> xmlTreeParse.  I don't know the exact specification of xml but
> according what I have red before it should work.
>
> consider a tiny test.xml file:
>
> <?xml version="1.0"?>
> <fields>
> <v1>1 </v1>
> <v2> 2 </v2>
> <v3> 3</v3>
> </fields>
>
> i.e. I have three fields v1, v2 and v3 which differ only by spacing.
> Now when reading it as
>
> > a <- xmlTreeParse("/home/otoomet/tyyq/Taani-piir/andmed/test.xml")
> > a$doc$children$fields
>  <fields>
>   <v1>
>   </v1>
>   <v2>
>   2
>   </v2>
>   <v3>
>   3
>   </v3>
>  </fields>
>
> you can see that field v1 is empty.  Is it my misinterpretation, or a
> problem with the library?
>
> Thanks in advance,
>
> Ott
>
> -----------------
> > version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    5.1
> year     2002
> month    06
> day      17
> language R
> ------------
> Package: XML
> Version: 0.93-1
> Date: 2002/11/06
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From bragadeesh02 at hotmail.com  Fri Feb 21 14:08:06 2003
From: bragadeesh02 at hotmail.com (Thanjavur Bragadeesh)
Date: Fri Feb 21 14:08:06 2003
Subject: [R] help
Message-ID: <F142VSzOjnbDAVWZtWU000218e2@hotmail.com>

Hi,

help.I would like to plot the mean and standard deviation against a factor 
in the xaxis- in other words I want an errorplot. I also want to put the 
standard deviation like a "T" on top of a barplot.  How can do this in R

Bragadeesh



From bragadeesh02 at hotmail.com  Fri Feb 21 14:12:36 2003
From: bragadeesh02 at hotmail.com (Thanjavur Bragadeesh)
Date: Fri Feb 21 14:12:36 2003
Subject: [R] help
Message-ID: <F138rWXYCYb6xn1peYv0002232f@hotmail.com>



hi,
I would like to plot error bar graph in R . Can I also change the the error 
bar graph to mean and Stdev instead of std error of mean. Also can we put a 
error bar on top of a bar plot like a "T" graph.

Bragadeesh



From gbrumen at student.ethz.ch  Fri Feb 21 14:16:32 2003
From: gbrumen at student.ethz.ch (Gorazd Brumen)
Date: Fri Feb 21 14:16:32 2003
Subject: [R] GARCH with t-innovations
Message-ID: <1045832865.1568.26.camel@misko>

Dear all,

Can garch function fit also t-innovations or only Gaussian innovations?

-- 
With kind regards -- Lepo pozdravljeni -- Gr??e (Gr?ezi) --

					       Gorazd Brumen
-------------------------------
Mail 1: gbrumen at student.ethz.ch
Mail 2: gorazd.brumen at fmf.uni-lj.si
Tel.: +41 (0)1 63 34906
Homepage: valjhun.fmf.uni-lj.si/~brumen



From petr.pikal at precheza.cz  Fri Feb 21 14:36:03 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri Feb 21 14:36:03 2003
Subject: [R] how to chage values in data frame to NA iside a function
Message-ID: <3E563924.3831.1B8BD09@localhost>

Dear all

I have a function in which I would like to change some values to NA according to 
some condition.

dropout<-function(y, nahr=FALSE,...) {

<some stuff for computing an index>

if (nahr) y[index]<<-NA
invisible(index)

}

in case y is a vector all works OK but if it is a part of data frame by calling

dropout(df$y) or dropout(df[,number]) no change is done.

Please can you help me what is wrong with my code?

By the way

idx<-dropout(df$y)
df$y[idx]<-NA

works OK

Thanks a lot beforehand

Best regards.

Petr Pikal
Precheza a.s., Nab?.Dr.E.Bene?e 24, 750 62 P?erov
tel: +420581 252 257 ; 724 008 364
petr.pikal at precheza.cz; p.pik at volny.cz
fax +420581 252 561



From mschwartz at medanalytics.com  Fri Feb 21 14:41:07 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri Feb 21 14:41:07 2003
Subject: [R] help
In-Reply-To: <F142VSzOjnbDAVWZtWU000218e2@hotmail.com>
Message-ID: <003401c2d9ae$7552c210$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Thanjavur 
>Bragadeesh
>Sent: Monday, February 10, 2003 4:08 PM
>To: r-announce at stat.math.ethz.ch
>Subject: [R] help
>
>
>
>Hi,
>
>help.I would like to plot the mean and standard deviation 
>against a factor 
>in the xaxis- in other words I want an errorplot. I also want 
>to put the 
>standard deviation like a "T" on top of a barplot.  How can do 
>this in R
>
>Bragadeesh

Look at the barplot2() function in the gregmisc package on CRAN.

A quick example using barplot2() and faked numbers:


library(gregmisc)
barplot2(c(5, 8, 4, 6, 9), plot.ci = TRUE, ci.l = c(5, 8, 4, 6, 9),
ci.u = c(5.5, 8.3, 4.25, 6.7, 10.5))


This will give you 5 vertical bars, with the upper bounds of the
confidence intervals plotted on top of the bars. Note that I have
specified that the lower bounds are the same as the bar values, which
results in no lower intervals being plotted.  If you want both upper
and lower bounds plotted, use appropriate values for the 'ci.l'
argument.

There are other options for axis configuration, grid lines and so
forth in barplot2() if you should need them.

Hope that helps,

Marc Schwartz



From tblackw at umich.edu  Fri Feb 21 15:04:06 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri Feb 21 15:04:06 2003
Subject: [R] how to chage values in data frame to NA iside a function
In-Reply-To: <3E563924.3831.1B8BD09@localhost>
Message-ID: <Pine.SOL.4.44.0302210856460.15028-100000@asteroids.gpcc.itd.umich.edu>

Petr  -

Does your function return "index" or return "y" after modifying y ?
In the email, it looks as though it returns "index".  If so, the
following should work:

> df$y[ dropout(df$y) ] <- NA

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



On Fri, 21 Feb 2003, Petr Pikal wrote:

> Dear all
>
> I have a function in which I would like to change some values to NA according to
> some condition.
>
> dropout<-function(y, nahr=FALSE,...) {
>
> <some stuff for computing an index>
>
> if (nahr) y[index]<<-NA
> invisible(index)
>
> }
>
> in case y is a vector all works OK but if it is a part of data frame by calling
>
> dropout(df$y) or dropout(df[,number]) no change is done.
>
> Please can you help me what is wrong with my code?
>
> By the way
>
> idx<-dropout(df$y)
> df$y[idx]<-NA
>
> works OK
>
> Thanks a lot beforehand
>
> Best regards.
>
> Petr Pikal
> Precheza a.s., Nab.Dr.E.Benee 24, 750 62 Perov
> tel: +420581 252 257 ; 724 008 364
> petr.pikal at precheza.cz; p.pik at volny.cz
> fax +420581 252 561
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From gerds at fdm.uni-freiburg.de  Fri Feb 21 15:07:55 2003
From: gerds at fdm.uni-freiburg.de (Thomas Gerds)
Date: Fri Feb 21 15:07:55 2003
Subject: [R] how to turn axis labels for trellis/dotplot
Message-ID: <7en0kpg29o.fsf@rembrandt.fdm.uni-freiburg.de>

hi,

it occurs quite naturally that groupnames have so many characters that
they overlap as horizontally printed labels for the xaxis in a
dotplot. is it possible to turn ('par(las=1)') the (x)axis-labels in a
dotplot? in general, is it possible to add new customization themes to
trellis.get()?

any solution is very welcome!

tomy


-- 
no signature



From mmarques at power.inescn.pt  Fri Feb 21 15:16:03 2003
From: mmarques at power.inescn.pt (Mark Marques)
Date: Fri Feb 21 15:16:03 2003
Subject: [R] Help Var passing in function
Message-ID: <141504546.20030221142314@power.inescn.pt>

  First thanks to the fast answer regarding the "Clustplot problem"...
  Regarding a new problem:

  for (i in 1:5)
  {
  z <- clara(adata, i)
  plot(z)
  }

  in the above code in the plot screen I get something like:
         clusplot(clara(x=adata,i)) in title
  in the 2nd type of plot I get
     silhouete plot of clara(x=adata,k=i,samples=50)

     How can I pass the real value to the i?
     What kind of command "transform" a var into their own value ?

     I tried using something like ~i , %i , but with no luck...
     Comments ?
     Any undocumented feature ?



From ripley at stats.ox.ac.uk  Fri Feb 21 15:28:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 21 15:28:02 2003
Subject: [R] Help Var passing in function
In-Reply-To: <141504546.20030221142314@power.inescn.pt>
Message-ID: <Pine.LNX.4.44.0302211426110.13427-100000@gannet.stats>

?substitute

On Fri, 21 Feb 2003, Mark Marques wrote:

> 
>   First thanks to the fast answer regarding the "Clustplot problem"...
>   Regarding a new problem:
> 
>   for (i in 1:5)
>   {
>   z <- clara(adata, i)
>   plot(z)
>   }
> 
>   in the above code in the plot screen I get something like:
>          clusplot(clara(x=adata,i)) in title
>   in the 2nd type of plot I get
>      silhouete plot of clara(x=adata,k=i,samples=50)
> 
>      How can I pass the real value to the i?
>      What kind of command "transform" a var into their own value ?
> 
>      I tried using something like ~i , %i , but with no luck...
>      Comments ?
>      Any undocumented feature ?

It's documented, both in R and in all good books on S programming.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lehmann at puk.unibe.ch  Fri Feb 21 15:32:07 2003
From: lehmann at puk.unibe.ch (Christoph Lehmann)
Date: Fri Feb 21 15:32:07 2003
Subject: [R] help.start() error:
Message-ID: <1045837623.1163.16.camel@christophl>

Hi 
I am new to R and just wanted to go through some tutorial. First I tried
to start help, but I got: 

----------------
> help.start()
Making links in per-session dir ...
If /usr/bin/netscape is already running, it is *not* restarted, and
    you must switch to its window.
Otherwise, be patient ...
> sh: line 1: /usr/bin/netscape: No such file or directory
sh: line 1: /usr/bin/netscape: No such file or directory
---------------
how to solve this problem? thanks a lot

christoph



From james at tifton.uga.edu  Fri Feb 21 15:37:30 2003
From: james at tifton.uga.edu (James Taylor)
Date: Fri Feb 21 15:37:30 2003
Subject: [R] expanding out date and time
Message-ID: <000001c2d9b5$f63c7360$7403120a@cpes.peachnet.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030221/e0e4bc0e/attachment.pl

From ripley at stats.ox.ac.uk  Fri Feb 21 15:46:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 21 15:46:02 2003
Subject: [R] help.start() error:
In-Reply-To: <1045837623.1163.16.camel@christophl>
Message-ID: <Pine.LNX.4.44.0302211441120.16979-100000@gannet.stats>

R version, operating system, who installed R and how?

It looks to be as if you probably installed a Unix/Linux binary version 
and do not have netscape installed (and the installation failed to check 
this).

The simplest answer is to install netscape in /usr/bin.

The next simplest answer is to alter R_BROWSER in R_HOME/etc/Renviron or 
to set R_BROWSER to point to a valid browser.

However, you really ought to take this up with whoever installed your 
version of R, for the installation is faulty.


On Fri, 21 Feb 2003, Christoph Lehmann wrote:

> Hi 
> I am new to R and just wanted to go through some tutorial. First I tried
> to start help, but I got: 
> 
> ----------------
> > help.start()
> Making links in per-session dir ...
> If /usr/bin/netscape is already running, it is *not* restarted, and
>     you must switch to its window.
> Otherwise, be patient ...
> > sh: line 1: /usr/bin/netscape: No such file or directory
> sh: line 1: /usr/bin/netscape: No such file or directory
> ---------------
> how to solve this problem? thanks a lot
> 
> christoph
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Feb 21 15:51:09 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 21 15:51:09 2003
Subject: [R] expanding out date and time
In-Reply-To: <000001c2d9b5$f63c7360$7403120a@cpes.peachnet.edu>
Message-ID: <Pine.LNX.4.44.0302211445320.16979-100000@gannet.stats>

Probably strptime() -- see its help page.

strsplit() is fairly easy but you would need to reorganize it's output.

On Fri, 21 Feb 2003, James Taylor wrote:

> What is the easiest way yo convert a column of time eg 09:25:45 into
> three columns of hour, minute,seconds

Is that a character string: I am assuming so, but they are printed with 	
quotes?

Your subject says `date and time', but your example is only a time.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gerds at fdm.uni-freiburg.de  Fri Feb 21 15:56:15 2003
From: gerds at fdm.uni-freiburg.de (Thomas Gerds)
Date: Fri Feb 21 15:56:15 2003
Subject: [R] expanding out date and time
In-Reply-To: <000001c2d9b5$f63c7360$7403120a@cpes.peachnet.edu> ("James
 Taylor"'s message of "Fri, 21 Feb 2003 09:31:42 -0500")
References: <000001c2d9b5$f63c7360$7403120a@cpes.peachnet.edu>
Message-ID: <7ek7ftg01n.fsf@rembrandt.fdm.uni-freiburg.de>

strsplit("09:25:45",":")
[[1]]
[1] "09" "25" "45"

tomy
"James Taylor" <james at tifton.uga.edu> writes:

> Hi,
>
>  
>
> What is the easiest way yo convert a column of time eg 09:25:45 into
> three columns of hour, minute,seconds
>
>  
>
> Thanks
>
>  
>
> James
>
>
> 	[[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
no signature



From mmarques at power.inescn.pt  Fri Feb 21 16:00:09 2003
From: mmarques at power.inescn.pt (Mark Marques)
Date: Fri Feb 21 16:00:09 2003
Subject: [R] Var problem
Message-ID: <933755961.20030221150045@power.inescn.pt>

> Regarding a  new  problem:
> for  (i in 1:5) { z <- clara(adata, i) plot(z) }
> in the above code  in  the  plot  screen
> I get something like: clusplot(clara(x=adata,i)) as title;
>  in    the    2nd    type   of   plot   I   get
>   silhouete   plot   of clara(x=adata,k=i,samples=50)
>
>     How can I pass the real value to the i?
>     What kind of command "transform" a var into their own value ?
>     I tried using something like ~i , %i , but with no luck...
>     Comments ?
>     Any undocumented feature ?

Using eval() or quote() or substitute I get this as title in the plot:
      silhouete   plot   of clara(x=adata,k=eval(i),samples=50) or
      silhouete   plot   of clara(x=adata,k=substitute(i),samples=50)

      how can I pass the numeric value of "i" ? not i itself... ?



From Nathan.Weisz at uni-konstanz.de  Fri Feb 21 16:13:02 2003
From: Nathan.Weisz at uni-konstanz.de (Nathan Weisz)
Date: Fri Feb 21 16:13:02 2003
Subject: [R] Linear mixed effects models
Message-ID: <BA7C01FE.2B55%Nathan.Weisz@uni-konstanz.de>

Hi everyone,

I'm a newbie to R and to linear mixed effects modeling, so please have mercy
:-)
Just wanted to check, whether what I'm doing is alright.

I've collected data concerning tonotopic organization of the auditory cortex
in humans, and I have approximately 1400-1800 data/time points per person
(13 in total). Observations were made how the focus of neuronal activity
changed spatially while processing of a frequency-modulated tone.

Regression analysis was performed for each individual using orthogonal
polynomials ...
regtemp <- lm(tempmat[,j] ~ poly(tempmat[,1],degree=i))
... up to degree = 5.

Based on the median (i.e. over all individuals) adjusted R-square, it could
be seen that a linear approach yielded about .5 adj-R2, adding a quadratic
term increased R2 to about .7 (adding further terms didn't increase adj-R2
in a significant manner).

SO: the next step is to apply a linear mixed effects model of the kind:
        y ~ x + x^2
My data.frame looks something like this:

   Latency medlat Subject
1    124.1     NA       1
2    125.6     NA       1
....
306   573.9  -3.83       1
307   575.3  -3.83       1
....
3000  1859.7  -6.04       2
3001  1861.2  -6.04       2
3002  1862.6  -6.03       2
..... etc. until subject 13

I.e. medlat is the dependent variable, latency my independent variable,
subject is the grouping variable (however I didn't group specifically before
calling lme --> was this wrong?).

There are 23686 observations in total, and depending on the subject some NA.
Following function call was used:
dummy.lme <- lme(medlat ~ poly(Latency, degree = 2), data = dummy,
+ random = ~ Latency | Subject, na.action = na.omit)

Questions:
- Is this approach o.k., or have you lost all your hair already?
- Can one of the lme-experts see if there's something overtly wrong with my
lme-call (especially the fixed and random term)
- I wanted to see how the fits look like for every individual. Using
plot(dummy.lme), I thought this should yield a trellis plot, with each
individual in a separate plot (and fitted line). However it didn't (it was
just a big mess). Any hints?

Thanks for your patience and all the best,

Nathan

---------------------------------------

Nathan Weisz
Institute for Clinical Psychology and
Behavioral Neuroscience
University of Konstanz
P.O. Box D25
D - 78467 Konstanz
GERMANY

Tel: +49 (0)7531 88- 4612
Fax: +49 (0)7531 88- 2891
E-mail: Nathan.Weisz at uni-konstanz.de
http://www.clinical-psychology.uni-konstanz.de

-----------------------------------------



From gregory_r_warnes at groton.pfizer.com  Fri Feb 21 16:25:06 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri Feb 21 16:25:06 2003
Subject: [R] help
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C5F8@groexmb02.pfizer.com>

Alternatively, use the 'plotCI' function (or for standard errors,
'plotmeans' function) in the gregmisc package.  

-Greg

> -----Original Message-----
> From: Marc Schwartz [mailto:mschwartz at medanalytics.com]
> Sent: Friday, February 21, 2003 8:38 AM
> To: 'Thanjavur Bragadeesh'; r-help at stat.math.ethz.ch
> Subject: RE: [R] help
> 
> 
> >-----Original Message-----
> >From: r-help-admin at stat.math.ethz.ch 
> >[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Thanjavur 
> >Bragadeesh
> >Sent: Monday, February 10, 2003 4:08 PM
> >To: r-announce at stat.math.ethz.ch
> >Subject: [R] help
> >
> >
> >
> >Hi,
> >
> >help.I would like to plot the mean and standard deviation 
> >against a factor 
> >in the xaxis- in other words I want an errorplot. I also want 
> >to put the 
> >standard deviation like a "T" on top of a barplot.  How can do 
> >this in R
> >
> >Bragadeesh
> 
> Look at the barplot2() function in the gregmisc package on CRAN.
> 
> A quick example using barplot2() and faked numbers:
> 
> 
> library(gregmisc)
> barplot2(c(5, 8, 4, 6, 9), plot.ci = TRUE, ci.l = c(5, 8, 4, 6, 9),
> ci.u = c(5.5, 8.3, 4.25, 6.7, 10.5))
> 
> 
> This will give you 5 vertical bars, with the upper bounds of the
> confidence intervals plotted on top of the bars. Note that I have
> specified that the lower bounds are the same as the bar values, which
> results in no lower intervals being plotted.  If you want both upper
> and lower bounds plotted, use appropriate values for the 'ci.l'
> argument.
> 
> There are other options for axis configuration, grid lines and so
> forth in barplot2() if you should need them.
> 
> Hope that helps,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From edd at debian.org  Fri Feb 21 16:47:03 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri Feb 21 16:47:03 2003
Subject: [R] GARCH with t-innovations
Message-ID: <E18mFNV-00073O-00@sonny.eddelbuettel.com>

> Can garch function fit also t-innovations or only Gaussian innovations?

The latter -- Adrian's code uses analytic gradients, and those are always
tied to the particular distribution of innovations for which they were 
derived.  You could of course do the legwork of coding this for the t-dist, 
IIRC an old Bollerslev paper has all/most of the math, release it as a 
(GPL'ed) patch and thereby secure your claim to fame as another co-author
of tseries.

Dirk 
(who has a more modest patch in tseries)

-- 
According to the latest figures, 43% of all signatures are totally worthless.



From agobbi at anadyspharma.com  Fri Feb 21 17:17:06 2003
From: agobbi at anadyspharma.com (Alberto Gobbi)
Date: Fri Feb 21 17:17:06 2003
Subject: [R] Problem Writeing a pipe using R (stdin is consumed)
Message-ID: <F71FE60EC95F164BB32C51B0E7A9C4C7163DF9@eggs.anadys.anadyspharma.com>

Hi everybody,
I a, trying to use R as a pipe like this:

cat inputData | R --silent RCommandFile >outputData

The RCommandFile would contain something like readLines(stdin()).
I have tryed various things and none did work cleanly.

One possible solution is to use the pipe() function inside R and to pass in the "cat inputData" however this is not very convenient
since I would like to use variable commands to generate the inputData which are much more complex than just "cat inputData" they might consist themselves of multiple pipes.

The problem is that R uses the stdin for itself to read commands and I could not find any solution.

Thanks a lot,
Alberto



From deepayan at stat.wisc.edu  Fri Feb 21 18:27:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Feb 21 18:27:03 2003
Subject: [R] how to turn axis labels for trellis/dotplot
In-Reply-To: <7en0kpg29o.fsf@rembrandt.fdm.uni-freiburg.de>
References: <7en0kpg29o.fsf@rembrandt.fdm.uni-freiburg.de>
Message-ID: <200302211125.58074.deepayan@stat.wisc.edu>

On Friday 21 February 2003 08:02 am, Thomas Gerds wrote:
> hi,
>
> it occurs quite naturally that groupnames have so many characters that
> they overlap as horizontally printed labels for the xaxis in a
> dotplot. is it possible to turn ('par(las=1)') the (x)axis-labels in a
> dotplot? 

See the 'scales' argument in ?xyplot. What you need is 'rot', for example,

xyplot(...,
       scales = list(x = list(rot = 90)))

('abbreviate' might help as well, depending on your situation)

> in general, is it possible to add new customization themes to
> trellis.get()?

See ?lset

Not everything can be controlled by the settings though. 

Deepayan



From reid_huntsinger at merck.com  Fri Feb 21 18:59:02 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri Feb 21 18:59:02 2003
Subject: [R] Problem Writeing a pipe using R (stdin is consumed)
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC354@uswpmx11.merck.com>

Perhaps a named pipe (aka fifo) would solve your problem? You could
write to it from an arbitrary process and read from it from
your R program.

Reid Huntsinger

-----Original Message-----
From: Alberto Gobbi [mailto:agobbi at anadyspharma.com]
Sent: Friday, February 21, 2003 11:16 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Problem Writeing a pipe using R (stdin is consumed)


Hi everybody,
I a, trying to use R as a pipe like this:

cat inputData | R --silent RCommandFile >outputData

The RCommandFile would contain something like readLines(stdin()).
I have tryed various things and none did work cleanly.

One possible solution is to use the pipe() function inside R and to pass in
the "cat inputData" however this is not very convenient
since I would like to use variable commands to generate the inputData which
are much more complex than just "cat inputData" they might consist
themselves of multiple pipes.

The problem is that R uses the stdin for itself to read commands and I could
not find any solution.

Thanks a lot,
Alberto

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------



From mkondrin at hppi.troitsk.ru  Fri Feb 21 19:22:07 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Fri Feb 21 19:22:07 2003
Subject: [R] Problem Writeing a pipe using R (stdin is consumed)
References: <2C23DE2983BE034CB1CB90DB6B813FD6028AC354@uswpmx11.merck.com>
Message-ID: <3E570775.4020104@hppi.troitsk.ru>

May be R -slave ... will help?
man R
...
        -q, --quiet
               Don't print startup message

        --silent
               Same as --quiet

        --slave
               Make R run as quietly as possible

...



From spencer.graves at pdf.com  Fri Feb 21 19:26:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 21 19:26:03 2003
Subject: [R] how to chage values in data frame to NA iside a function
References: <Pine.SOL.4.44.0302210856460.15028-100000@asteroids.gpcc.itd.umich.edu>
Message-ID: <3E566EB1.3000103@pdf.com>

Thomas Blackwell's solution will also work if dropout(df$y) returns a 
logical vector of length = length(df$y).  This also allows more general 
conditions, e.g.,
	
	  select1 <- df[,1] > 0
	  select2 <- (select1) & (dr[,2] > 0)

	  df[select2, "y"] <- NA	

Spencer Graves

Thomas W Blackwell wrote:
> Petr  -
> 
> Does your function return "index" or return "y" after modifying y ?
> In the email, it looks as though it returns "index".  If so, the
> following should work:
> 
> 
>>df$y[ dropout(df$y) ] <- NA
> 
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> 
> 
> On Fri, 21 Feb 2003, Petr Pikal wrote:
> 
> 
>>Dear all
>>
>>I have a function in which I would like to change some values to NA according to
>>some condition.
>>
>>dropout<-function(y, nahr=FALSE,...) {
>>
>><some stuff for computing an index>
>>
>>if (nahr) y[index]<<-NA
>>invisible(index)
>>
>>}
>>
>>in case y is a vector all works OK but if it is a part of data frame by calling
>>
>>dropout(df$y) or dropout(df[,number]) no change is done.
>>
>>Please can you help me what is wrong with my code?
>>
>>By the way
>>
>>idx<-dropout(df$y)
>>df$y[idx]<-NA
>>
>>works OK
>>
>>Thanks a lot beforehand
>>
>>Best regards.
>>
>>Petr Pikal
>>Precheza a.s., Nab?.Dr.E.Bene?e 24, 750 62 P?erov
>>tel: +420581 252 257 ; 724 008 364
>>petr.pikal at precheza.cz; p.pik at volny.cz
>>fax +420581 252 561
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From chrysopa at insecta.ufv.br  Fri Feb 21 19:30:09 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Fri Feb 21 19:30:09 2003
Subject: [R] Help on a simple function.
Message-ID: <200302201013.40368.chrysopa@insecta.ufv.br>

Hi,

I try to make a function that have two others functions inside.

It is simple, but the problem is that functions inside use the same variable, 
but with different values. I try something like this:

Teste <- function(Pdig(nlinhas),Ldig(nlinhas)) {

Pdig <- function(nlinhas) {
Tdig <- (15.50 + 7.45*nlinhas);
(3*(Tdig*(30/3600))+1*(30*(30/3600)));
}

Ldig <- function(nlinhas) {
Tdig <- (30.50 + 7.45*nlinhas);
(2*(Tdig*(30/3600))+1*(30*(30/3600)));
}

print(Pdig)
print(Ldig)
print(Pdig+Ldig)
}

It dont work.

How to make this?

Thanks
Ronaldo

-- 
If at first you don't succeed, quit; don't be a nut about success.
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366



From fruits at portland.econw.com  Fri Feb 21 19:36:14 2003
From: fruits at portland.econw.com (Eric Fruits)
Date: Fri Feb 21 19:36:14 2003
Subject: [R] Copy-paste graphics from R to Word on Mac OS X
Message-ID: <E30AD7F6-45CA-11D7-8779-0003938E023E@portland.econw.com>

Greetings:

	I'm (very) new  to R.

	One of the features of R that I really like is R's ability to quickly 
generate very good looking graphics.  However, I've noticed that when I 
attempt to copy and paste the graphs from the R graphics output window 
into Word (in Mac OS X), the resulting picture is very jaggy.

	I'm aware of the various options such as dev2bitmap, but I'd really 
like to be able to do a quick copy and paste without switching among 
various applications or creating extraneous files.

	Thanks.

-- 
Eric Fruits, Ph.D.
Senior Economist & Project Manager
ECONorthwest - Portland



From fharrell at virginia.edu  Fri Feb 21 19:42:04 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri Feb 21 19:42:04 2003
Subject: [R] Copy-paste graphics from R to Word on Mac OS X
In-Reply-To: <E30AD7F6-45CA-11D7-8779-0003938E023E@portland.econw.com>
References: <E30AD7F6-45CA-11D7-8779-0003938E023E@portland.econw.com>
Message-ID: <20030221134619.61af8dd5.fharrell@virginia.edu>

On Fri, 21 Feb 2003 10:32:52 -0800
Eric Fruits <fruits at portland.econw.com> wrote:

> Greetings:
> 
> 	I'm (very) new  to R.
> 
> 	One of the features of R that I really like is R's ability to quickly 
> generate very good looking graphics.  However, I've noticed that when I 
> attempt to copy and paste the graphs from the R graphics output window 
> into Word (in Mac OS X), the resulting picture is very jaggy.
> 
> 	I'm aware of the various options such as dev2bitmap, but I'd really 
> like to be able to do a quick copy and paste without switching among 
> various applications or creating extraneous files.
> 
> 	Thanks.
> 
> -- 
> Eric Fruits, Ph.D.
> Senior Economist & Project Manager
> ECONorthwest - Portland
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

This was discussed in the group just a few days ago.  Please check the r-help archive.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From mkondrin at hppi.troitsk.ru  Fri Feb 21 19:49:10 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Fri Feb 21 19:49:10 2003
Subject: [R] Help on a simple function.
References: <200302201013.40368.chrysopa@insecta.ufv.br>
Message-ID: <3E570D4A.5070707@hppi.troitsk.ru>

Ronaldo Reis Jr. wrote:
> Hi,
> 
> I try to make a function that have two others functions inside.
> 
> It is simple, but the problem is that functions inside use the same variable, 
> but with different values. I try something like this:
> 
> Teste <- function(Pdig(nlinhas),Ldig(nlinhas)) {
> 
> Pdig <- function(nlinhas) {
> Tdig <- (15.50 + 7.45*nlinhas);
> (3*(Tdig*(30/3600))+1*(30*(30/3600)));
> }
> 
> Ldig <- function(nlinhas) {
> Tdig <- (30.50 + 7.45*nlinhas);
> (2*(Tdig*(30/3600))+1*(30*(30/3600)));
> }
> 
> print(Pdig)
> print(Ldig)
> print(Pdig+Ldig)
> }
> 
> It dont work.
> 
> How to make this?
> 
> Thanks
> Ronaldo
> 

Teste <- function(nlinhas) {

Pdig <- function(z) {
Tdig <- (15.50 + 7.45*z);
(3*(Tdig*(30/3600))+1*(30*(30/3600)));
}

Ldig <- function(z) {
Tdig <- (30.50 + 7.45*z);
(2*(Tdig*(30/3600))+1*(30*(30/3600)));
}

print(Pdig(nlinhas))
print(Ldig(nlinhas))
print(Pdig(nlinhas)+Ldig(nlinhas))
}

 > Teste(10)
[1] 2.5
[1] 2
[1] 4.5
 >



From mkondrin at hppi.troitsk.ru  Fri Feb 21 19:55:03 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Fri Feb 21 19:55:03 2003
Subject: [R] Problem Writeing a pipe using R (stdin is consumed)
References: <2C23DE2983BE034CB1CB90DB6B813FD6028AC354@uswpmx11.merck.com> <3E570775.4020104@hppi.troitsk.ru>
Message-ID: <3E570DEE.3070505@hppi.troitsk.ru>

M.Kondrin wrote:
> May be R -slave ... will help?
> man R
> ...
>        -q, --quiet
>               Don't print startup message
> 
>        --silent
>               Same as --quiet
> 
>        --slave
>               Make R run as quietly as possible
> 
> ...
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

$ echo "h<-1; print(h)" | R --slave
[1] 1

$



From cbecker at psy.uni-muenchen.de  Fri Feb 21 20:41:06 2003
From: cbecker at psy.uni-muenchen.de (Cordula Becker)
Date: Fri Feb 21 20:41:06 2003
Subject: [R] calculating mean direction (CircStats)
Message-ID: <002501c2d9e0$e232d8c0$f1e2548d@tulpe>

Hi,

I've currently to work with some circular data. Unfortunately I'm not very
familiar with circular statistics and would really appreciate if I could get
some help concerning the CircStats package this way.

My data lies in the range 0 to 2*pi, and is transformed to radians (as
expected by the CircStats methods). Calculating the mean direction
(circ.mean) results for some datasets in a negative mean direction
like -0.8309982. I think that this might be wrong. If it is correct, what is
the meaning of a negative mean direction?

I also read that some transformation of the data might be necessary to get
the correct mean direction (multiplying all angles by two and taking the
modulus of these angles and 360?). I manage to do so, but I'm not sure about
how to back-transfer the mean direction I'm getting as a result to the
angles of my original data.

I would be very happy if anybody has some hints concerning this problem.

Thanks a lot, Cordula Becker
--------------------------------------------------------
Cordula Becker

Ludwig-Maximilians-Universit?t M?nchen
Allgemeine und Experimentelle Psychologie

Leopoldstr.13
D-80802 M?nchen
Germany

Tel. +49 (89) 2180 6231
Fax. +49 (89) 2180 5211



From Mark.Wilkinson at stjude.org  Fri Feb 21 20:47:03 2003
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Fri Feb 21 20:47:03 2003
Subject: [R] more mulitpage postscript problems
Message-ID: <A1DAD6685C12D511B20F00034725151380CE9E@sjmemexc3.stjude.org>

Hi,

I posted a while ago about 'overlap' problems using png/jpeg.  If what
Patrick Connolly suggests is truly happening, I think the following may be
related.

My new problem is with the following code (the overlap is still there if I
use png() instead of postscript(), compounded by the difficulty described
below):

tmp <- matrix(runif(16000), nrow=16)
##postscript(paper='letter')
for (i in seq(1, 16, 4)) {
  X11()
  par(mfrow=c(2, 2))
  for (j in 1:min(i+3, 16)) {
    plot(density(tmp[j, ], from=0, to=1), lwd=3, main=paste(i, j))
  }
}
##dev.off()

When I run as is, I get what I want: four 'pages', 4 plots each.  But when I
comment X11(), and uncomment the first and last lines, the postscript file I
get has 10 pages!

Could someone kindly point out what I'm doing wrong?  Thank you,

> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.1
year     2002
month    11
day      01
language R


Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences

The opinions expressed here are my own and do not necessarily represent
those of St. Jude Children's Research Hospital.


 -----Original Message-----
From: 	Patrick Connolly [mailto:p.connolly at hortresearch.co.nz] 
Sent:	Sunday, February 02, 2003 4:49 PM
To:	Wilkinson, Mark
Subject:	Re: [R] png()/jpeg()

On Fri, 31-Jan-2003 at 02:12PM -0600, Wilkinson, Mark wrote:

|> When I execute the following code, it works just like I want it to: three
|> pages of nine (or fewer) plots.  However, when I execute the code with
the
|> first and last lines uncommented, I get three pages (files), but the 2nd
&
|> 3rd pages have overlapping plots.  It's like a new page wasn't created.  

It works if you use a postscript device to create a multipage
postscript file.  I think the bitmap procedure, in fact, creates one
and uses ImageMagick to make the bitmap file/s.  Looks like a job for
Brian to work out where the problem is.

Until then, you can quite simply make a postscript file and conver it
to a png using the Gimp.  I'm used to doing that with lattice plots.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From agobbi at anadyspharma.com  Fri Feb 21 20:53:03 2003
From: agobbi at anadyspharma.com (Alberto Gobbi)
Date: Fri Feb 21 20:53:03 2003
Subject: [R] Problem Writeing a pipe using R (stdin is consumed)
Message-ID: <F71FE60EC95F164BB32C51B0E7A9C4C7163DFB@eggs.anadys.anadyspharma.com>

Thanks for the answer!
However what I would like to ba able to do is something like:
perl -e 'print "1 2\n\2 2\n";'  |  R --silent commandFile

and commandFile would contain something like:
t<-read.table(file("t"), sep=" ")
print(t*2)

This would need read.table to get the original stdin() and the commands to be read from a file.

The idea with the named pipe does not work either for the same reasons.

Thanks again,
Alberto



-----Original Message-----
From: M.Kondrin [mailto:mkondrin at hppi.troitsk.ru]
Sent: Friday, February 21, 2003 21:43 PM
To: R-Help
Subject: Re: [R] Problem Writeing a pipe using R (stdin is consumed)


M.Kondrin wrote:
> May be R -slave ... will help?
> man R
> ...
>        -q, --quiet
>               Don't print startup message
> 
>        --silent
>               Same as --quiet
> 
>        --slave
>               Make R run as quietly as possible
> 
> ...
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

$ echo "h<-1; print(h)" | R --slave
[1] 1

$

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tblackw at umich.edu  Fri Feb 21 21:33:06 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri Feb 21 21:33:06 2003
Subject: [R] Help on a simple function.
In-Reply-To: <200302201013.40368.chrysopa@insecta.ufv.br>
Message-ID: <Pine.SOL.4.44.0302211526030.2611-100000@timepilot.gpcc.itd.umich.edu>

Make it three separate functions.  This gives an example
of how argument passing works.

> Pdig <- function(nlinhas) {
> Tdig <- (15.50 + 7.45*nlinhas);
> (3*(Tdig*(30/3600))+1*(30*(30/3600)));
> }

> Ldig <- function(nlinhas) {
> Tdig <- (30.50 + 7.45*nlinhas);
> (2*(Tdig*(30/3600))+1*(30*(30/3600)));
> }

> Teste <- function(nlinhas) {
> print(Pdig(nlinhas))
> print(Ldig(nlinhas))
> print(Pdig(nlinhas) + Ldig(nlinhas))
> }

> Teste(17)

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



From Mark.Wilkinson at stjude.org  Fri Feb 21 22:03:03 2003
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Fri Feb 21 22:03:03 2003
Subject: [R] more mulitpage postscript problems
Message-ID: <A1DAD6685C12D511B20F00034725151380CE9F@sjmemexc3.stjude.org>

Doh!  

The second loop should be
for (j in i:min(i+3, 16)) {

Thanks for the help!

Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences

The opinions expressed here are my own and do not necessarily represent
those of St. Jude Children's Research Hospital.


 -----Original Message-----
From: 	Michael Na Li [mailto:lina at u.washington.edu] 
Sent:	Friday, February 21, 2003 2:53 PM
To:	Wilkinson, Mark
Subject:	Re: [R] more mulitpage postscript problems

On Fri, 21 Feb 2003, Mark Wilkinson stated:

>  
>  tmp <- matrix(runif(16000), nrow=16)
>  ##postscript(paper='letter')
>  for (i in seq(1, 16, 4)) {
>    X11()
>    par(mfrow=c(2, 2))
>    for (j in 1:min(i+3, 16)) {
>      plot(density(tmp[j, ], from=0, to=1), lwd=3, main=paste(i, j))
>    }
>  }
>  ##dev.off()
>  
>  When I run as is, I get what I want: four 'pages', 4 plots each.  But
when
>  I comment X11(), and uncomment the first and last lines, the postscript
>  file I get has 10 pages!

You do have 40 plots so you should get 10 pages with 4 plots on each page.
However, X11() is only called 4 times that is why you only have four
plot windows popping up.  Pages plotted on the same plot window will
override
previous pages, for obvious reasons.

Michael



From rossini at blindglobe.net  Fri Feb 21 22:52:04 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri Feb 21 22:52:04 2003
Subject: [R] Problem Writeing a pipe using R (stdin is consumed)
In-Reply-To: <F71FE60EC95F164BB32C51B0E7A9C4C7163DFB@eggs.anadys.anadyspharma.com> ("Alberto
 Gobbi"'s message of "Fri, 21 Feb 2003 11:52:21 -0800")
References: <F71FE60EC95F164BB32C51B0E7A9C4C7163DFB@eggs.anadys.anadyspharma.com>
Message-ID: <87vfzdgv9q.fsf@jeeves.blindglobe.net>

Instead of piping the data through, have R read it in from a file?
Then you just specify the data file name within read.table in the
string,  and the only downside might be an additional "temporary" file
to clean up.  

It seems to solve the problem as you've described it, though not in
the way you want.



"Alberto Gobbi" <agobbi at anadyspharma.com> writes:


> Thanks for the answer!
> However what I would like to ba able to do is something like:
> perl -e 'print "1 2\n\2 2\n";'  |  R --silent commandFile
>
> and commandFile would contain something like:
> t<-read.table(file("t"), sep=" ")
> print(t*2)
>
> This would need read.table to get the original stdin() and the commands to be read from a file.
>
> The idea with the named pipe does not work either for the same reasons.
>
> Thanks again,
> Alberto
>
>
>
> -----Original Message-----
> From: M.Kondrin [mailto:mkondrin at hppi.troitsk.ru]
> Sent: Friday, February 21, 2003 21:43 PM
> To: R-Help
> Subject: Re: [R] Problem Writeing a pipe using R (stdin is consumed)
>
>
> M.Kondrin wrote:
>> May be R -slave ... will help?
>> man R
>> ...
>>        -q, --quiet
>>               Don't print startup message
>> 
>>        --silent
>>               Same as --quiet
>> 
>>        --slave
>>               Make R run as quietly as possible
>> 
>> ...
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> 
>
> $ echo "h<-1; print(h)" | R --slave
> [1] 1
>
> $
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From shaliniyv at yahoo.co.in  Fri Feb 21 23:25:03 2003
From: shaliniyv at yahoo.co.in (=?iso-8859-1?q?Shalini=20Venkatachar?=)
Date: Fri Feb 21 23:25:03 2003
Subject: [R] Help needed regarding acf
Message-ID: <20030221222439.75893.qmail@web8006.mail.in.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030221/2c559a42/attachment.pl

From crmora at unity.ncsu.edu  Sat Feb 22 03:37:03 2003
From: crmora at unity.ncsu.edu (Christian Mora)
Date: Sat Feb 22 03:37:03 2003
Subject: [R] 4-parameter logistic model
Message-ID: <000701c2da1b$6ac283e0$6101a8c0@launchmodem.com>

Dear R users

I'm a new user of R and I have a basic question about the 4-parameter
logistic model. According to the information from Pinheiro & Bates the model
is:

y(x)=theta1+(theta2-theta1)/(1+exp((theta3-x)/theta4)) ==
y(x)=A+(B-A)/(1+exp((xmid-input)/scal))

from the graph in page 518 of the book of the same authors (mixed models in
S) theta 1 corresponds to the horizontal asymptote as x goes to infinity and
theta2 the horizontal asymptote as x goes to -infinity. When I use the
function SSfpl(input,A,B,xmid,scal), I'm not sure why the value of A is the
lower of the two asymptotes if according to the original function A should
be equal to theta1 (upper asymptote).. or maybe I'm wrong.

I'll appreciate any comment on this.

Best Regards

CM



From mkocherg at students.uiuc.edu  Sat Feb 22 03:50:04 2003
From: mkocherg at students.uiuc.edu (Maria N Kocherginsky)
Date: Sat Feb 22 03:50:04 2003
Subject: [R] printf() in C
Message-ID: <3E71498F@webmail.uiuc.edu>

Hi,

1. I'm making an R package in Windows 2000, and I'm including the .c files. 
Everything works fine, except that when I call the printf() function in the C 
code, it doesn't actually print anything. I'm including the following header 
files:
#include <stdio.h>
#include <math.h>
#include <sys/types.h>
#include <stdlib.h>
and I have the recommended MinGW compiler.
Any suggestions?

2.  I get a warning about having CRLF line endings in the C code, but I saved 
the .c files as ASCII in Notepad. Is this really a problem? How can I get rid 
of these?

Thank you,

Masha



From r_abades at yahoo.es  Sat Feb 22 06:07:04 2003
From: r_abades at yahoo.es (=?iso-8859-1?Q?Rom=E1n_Abades?=)
Date: Sat Feb 22 06:07:04 2003
Subject: [R] R in other languages
Message-ID: <001801c2da30$111724d0$179b523e@sfux.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030222/039e7e94/attachment.pl

From rpeng at stat.ucla.edu  Sat Feb 22 08:20:04 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Sat Feb 22 08:20:04 2003
Subject: [R] printf() in C
In-Reply-To: <3E71498F@webmail.uiuc.edu>
Message-ID: <Pine.GSO.4.10.10302212317530.19838-100000@quetelet.stat.ucla.edu>

Try including the line

<R.h>

and using the function Rprintf().  This prints output to the R console.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Fri, 21 Feb 2003, Maria N Kocherginsky wrote:

> Hi,
> 
> 1. I'm making an R package in Windows 2000, and I'm including the .c files. 
> Everything works fine, except that when I call the printf() function in the C 
> code, it doesn't actually print anything. I'm including the following header 
> files:
> #include <stdio.h>
> #include <math.h>
> #include <sys/types.h>
> #include <stdlib.h>
> and I have the recommended MinGW compiler.
> Any suggestions?
> 
> 2.  I get a warning about having CRLF line endings in the C code, but I saved 
> the .c files as ASCII in Notepad. Is this really a problem? How can I get rid 
> of these?
> 
> Thank you,
> 
> Masha
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ligges at statistik.uni-dortmund.de  Sat Feb 22 12:18:02 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Feb 22 12:18:02 2003
Subject: [R] Help needed regarding acf
References: <20030221222439.75893.qmail@web8006.mail.in.yahoo.com>
Message-ID: <3E575C73.78D921E4@statistik.uni-dortmund.de>

Shalini Venkatachar wrote:
> 
> Hi,
> 
>  When I plot the auto co-relation function (acf), 2 blue lines appear near the base. Can anyone tell me what they mean?

The lines are representing the confidence interval. See ?plot.acf for
details.


> Also can anyone tell me how to print the graphs that are generated. There is a print option but when I click on it, it doesn't seem to do anything. Is copying the graph as a bitmap file in paint the only way out?

No, there are several ways! Please read the manuals and ?Devices !
 
Uwe Ligges


>  Thanks for any help.
> 
> Regards,
> 
>  Shalini



From mkondrin at hppi.troitsk.ru  Sat Feb 22 12:27:03 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Sat Feb 22 12:27:03 2003
Subject: [R] Problem Writeing a pipe using R (stdin is consumed)
References: <F71FE60EC95F164BB32C51B0E7A9C4C7163DFB@eggs.anadys.anadyspharma.com>
Message-ID: <3E578928.90805@hppi.troitsk.ru>

But may be you will like to feed through pipe both data  and commands? 
It will require to do some formatting of input but I think it will not 
be hard to do in perl. I mean something like that:

echo 
"source(\"RCommands.R\");t<-matrix(c(1,2,3,4,5,6),ncol=2);print(process(t))" 
| R --slave

You only need to substitute your data inside c() with all separators 
replaced with commas and specify number of columns in your data as ncol=...

Good luck...



From rrsilva at ib.usp.br  Sat Feb 22 13:18:03 2003
From: rrsilva at ib.usp.br (Rogerio R. Silva)
Date: Sat Feb 22 13:18:03 2003
Subject: [R] moving-window analysis
Message-ID: <002c01c2da6c$57b380a0$10266b8f@mz.usp.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030222/aa0eee5f/attachment.pl

From smyth at wehi.edu.au  Sat Feb 22 14:28:08 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Sat Feb 22 14:28:08 2003
Subject: [R] Rcmd check does not recognize formal generic function
  as code object
In-Reply-To: <20030219001655.G2907@jimmy.harvard.edu>
References: <5.2.0.9.1.20030219140303.00aeb770@imaphost.wehi.edu.au>
 <5.2.0.9.1.20030219140303.00aeb770@imaphost.wehi.edu.au>
Message-ID: <5.2.0.9.1.20030222233918.00ac19b0@imaphost.wehi.edu.au>

At 04:16 PM 19/02/2003, Robert Gentleman wrote:
>   It was decided that should not be an error to omit documentation for
>   a generic function defined in a package (whose sole purpose is to
>   extend a current function to be generic). It appears that the
>   implementation of that decision was to treat all generic functions
>   in packages as non-entities. That is probably not the best and one
>   can argue that there should be no warning if a generic is documented
>   (nor one if it isn't and there is already documentation for it
>   somewhere).

Actually methods are also treated as non-entities, unless they are actually 
assigned into a function name, which the setMethod function does not do in 
itself nor require. This seems wrong - it should definitely be considered a 
mistake to define a new method using setMethod and not document it. Such 
documentation cannot occur in the .Rd file belonging to the class that it 
operates on if that class is defined in a different package.

Classes defined using setClass are similarly treated an non-entities. It 
seems that rcmd check is largely "unaware" of formal methods and classes.

Regards
Gordon



From stop4optimal at hotmail.com  Sat Feb 22 14:44:04 2003
From: stop4optimal at hotmail.com (chenwj)
Date: Sat Feb 22 14:44:04 2003
Subject: [R] program always halt
Message-ID: <OE15mH4PrC1AuAP7MQO000018b1@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030222/2713de51/attachment.pl

From bates at stat.wisc.edu  Sat Feb 22 14:53:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat Feb 22 14:53:03 2003
Subject: [R] 4-parameter logistic model
In-Reply-To: <000701c2da1b$6ac283e0$6101a8c0@launchmodem.com>
References: <000701c2da1b$6ac283e0$6101a8c0@launchmodem.com>
Message-ID: <6rwujstobq.fsf@bates4.stat.wisc.edu>

"Christian Mora" <crmora at unity.ncsu.edu> writes:

> I'm a new user of R and I have a basic question about the 4-parameter
> logistic model. According to the information from Pinheiro & Bates the model
> is:
> 
> y(x)=theta1+(theta2-theta1)/(1+exp((theta3-x)/theta4)) ==
> y(x)=A+(B-A)/(1+exp((xmid-input)/scal))
> 
> from the graph in page 518 of the book of the same authors (mixed models in
> S) theta 1 corresponds to the horizontal asymptote as x goes to infinity and
> theta2 the horizontal asymptote as x goes to -infinity. When I use the
> function SSfpl(input,A,B,xmid,scal), I'm not sure why the value of A is the
> lower of the two asymptotes if according to the original function A should
> be equal to theta1 (upper asymptote).. or maybe I'm wrong.
> 
> I'll appreciate any comment on this.

Is scal negative in your call to SSfpl?



From nikthe at aegean.gr  Sat Feb 22 16:42:03 2003
From: nikthe at aegean.gr (Nicoleris Theodoros)
Date: Sat Feb 22 16:42:03 2003
Subject: [R] question
Message-ID: <D2F647887C1BD711905C00508B6144AA6A7B67@eupalinos.samos.aegean.gr>

Iam a novice R-user and I have a few questions:
1) How can R import an Excell data file?

2) I have a file.s file which it seems I can open but I can 
not load it i.e. when I write the file name in the command line, for e.g.
>file.s it gives me an error message
thank you for your consideration,
Theo Nicoleris



From ripley at stats.ox.ac.uk  Sat Feb 22 17:02:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Feb 22 17:02:02 2003
Subject: [R] question
In-Reply-To: <D2F647887C1BD711905C00508B6144AA6A7B67@eupalinos.samos.aegean.gr>
Message-ID: <Pine.LNX.4.44.0302221559510.30216-100000@gannet.stats>

On Sat, 22 Feb 2003, Nicoleris Theodoros wrote:

> Iam a novice R-user and I have a few questions:
> 1) How can R import an Excell data file?

That's covered in the R Data Import/Export Manual (if you mean MicroSoft's 
Excel).


> 2) I have a file.s file which it seems I can open but I can 
> not load it i.e. when I write the file name in the command line, for e.g.
> >file.s it gives me an error message

Try ?source, if it is a file of R commands.  Try also looking at `An 
Introduction to R'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Sat Feb 22 17:10:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Feb 22 17:10:03 2003
Subject: [R] program always halt
In-Reply-To: <OE15mH4PrC1AuAP7MQO000018b1@hotmail.com>
References: <OE15mH4PrC1AuAP7MQO000018b1@hotmail.com>
Message-ID: <3E57A0AE.9050502@statistik.uni-dortmund.de>

chenwj wrote:
> i wrote a program recently.  it is a 1000-time cycle containing a series of R code.  but it always halted after just finished several cycles.  
>  
> does anyone know the reason why? or any suggestions to solve it?
> 
> thanks a lot.

Please folks, don't ask questions this way.

Please provide a *minimal* example that reproduces your problem, and 
tell us about your OS and your version of R.
Please tell us the error message.
Nobody is able to debug code one knows nothing about (except there's a 
loop in it).

Uwe Ligges



From Ahmad_Abu_Hammour/STUDENTS/FIRE%FIRE at fordham.edu  Sat Feb 22 17:27:06 2003
From: Ahmad_Abu_Hammour/STUDENTS/FIRE%FIRE at fordham.edu (Ahmad_Abu_Hammour/STUDENTS/FIRE%FIRE@fordham.edu)
Date: Sat Feb 22 17:27:06 2003
Subject: [R] "deriv" and chain rule and matrix derivatives
Message-ID: <OF968F2309.8F73A3F0-ON85256CD5.005A500F-85256CD5.005A5031@fire.fordham.edu>

Hi,
Anybody knows if I can use "deriv" to implement CHAIN RULE AND MATRIX
derivation.
Simple examples:

y=expression(log(x))
z=expression (x*y)
deriv(z,"x") # chain rule

f=expression(det(x)) # where x is an (nxn) matrix
deriv(f, "x")

Is there any way to work around this?

Thank you very much.

Ahmad Abu Hammour

PS. by the way I tried to send the same email using my http-based account
hammour at msn.com, but I could not, although I set send email to plain text.



From lehmann at puk.unibe.ch  Sat Feb 22 17:50:03 2003
From: lehmann at puk.unibe.ch (Christoph Lehmann)
Date: Sat Feb 22 17:50:03 2003
Subject: [R] faraway tutorial: cryptic command to newbie
Message-ID: <1045932555.3686.6.camel@christophl>

I am just about working through Faraways excellent tutorial "practical
regression and ANOVA using R"

on page 24 he makes the x matrix:
x <- cbind(1,gala[,-c(1,2)])

how can I understand this gala[,-c(1,2)])... I couldn't find an
explanation of such "c-like" abbreviations anywhere.

thanks for a hint.

another problem: I couldn't load the faraway library, using the
library() command, even though I specified the path, .. do I need to put
library files into a certain directory? I always got an error: Error in
library(faraway) : There is no package called `faraway'


Thanks a lot

christoph

-- 
Christoph Lehmann 
Department of Psychiatric Neurophysiology 
University Hospital of Clinical Psychiatry 
Waldau 
CH-3000 Bern 60 
Switzerland 

Phone:  ++41 31 930 93 83 
Mobile: ++41 31 570 28 00
Fax:    ++41 31 930 99 61 
Email:  lehmann at puk.unibe.ch 
Web:    http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html



From ripley at stats.ox.ac.uk  Sat Feb 22 18:28:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Feb 22 18:28:02 2003
Subject: [R] faraway tutorial: cryptic command to newbie
In-Reply-To: <1045932555.3686.6.camel@christophl>
Message-ID: <Pine.LNX.4.44.0302221705150.30278-100000@gannet.stats>

On 22 Feb 2003, Christoph Lehmann wrote:

> I am just about working through Faraways excellent tutorial "practical
> regression and ANOVA using R"

I assume this is a reference to the PDF version available via CRAN. I am
afraid that is *not* a good discussion of how to do regression, especially
not using R.  That page is seriously misleading: good ways to compute
regressions are QR decompositions with pivoting (which R uses) or an SVD.
Solving the normal equations is well known to square the condition number,
and is close to the worse possible way.  (If you must use normal
equations, do at least centre the columns, and preferably do some 
scaling.)

> on page 24 he makes the x matrix:
> x <- cbind(1,gala[,-c(1,2)])
> 
> how can I understand this gala[,-c(1,2)])... I couldn't find an
> explanation of such "c-like" abbreviations anywhere.

Well, it is in all good books (as they say) including `An Introduction to 
R'. (It's even on page 210 of that book!)

-c(1,2) is (try it)

> -c(1,2)
[1] -1 -2

so this drops columns 1 and 2.  It then adds in front a column made up of 
ones, which is usually a sign of someone not really understanding how
R's linear models work.

> another problem: I couldn't load the faraway library, using the
> library() command, even though I specified the path, .. do I need to put
> library files into a certain directory? I always got an error: Error in
> library(faraway) : There is no package called `faraway'

Did you *install* the *package*?  Is it a valid R package which has passed 
R CMD check?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rab at nauticom.net  Sat Feb 22 22:00:04 2003
From: rab at nauticom.net (rab)
Date: Sat Feb 22 22:00:04 2003
Subject: [R] Problem Replicating Venables & Riply Split-Plot Example
In-Reply-To: <3E96F037.60105@arcriswell.com>
References: <3E96F037.60105@arcriswell.com>
Message-ID: <3E57EC5B.7090609@nauticom.net>

I'm using R 1.6.1 under Redhat Linux 8.0. I'm following the example from 
V&R (1994) pp. 177-181. I get the split-plot ANOVA table:

 > summary(oats.aov)

Error: B
          Df  Sum Sq Mean Sq F value Pr(>F)
Residuals  5 15875.3  3175.1

Error: B:V
          Df Sum Sq Mean Sq F value Pr(>F)
V          2 1786.4   893.2  1.4853 0.2724
Residuals 10 6013.3   601.3

Error: Within
          Df  Sum Sq Mean Sq F value    Pr(>F)
Nf         3 20020.5  6673.5 37.6856 2.458e-12 ***
Nf:V       6   321.7    53.6  0.3028    0.9322
Residuals 45  7968.7   177.1
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1


I need to get hold of the residuals and fitted values. The usual way of 
using "resid" and "fitted" doesn't work I guess because this is a 
multistratum model. The "studres" function shows up if I load the MASS 
library. But I cannot get the "proj" and "update" functions to work as 
they do in S-Plus:

 > oats.fm <- update(oats.aov,qr=TRUE)
Error in update.default(oats.aov, qr = TRUE) :
        need an object with call component

How can I get the residuals and fitted values? Wouldn't there be three 
sets of residuals? One for the blocks (6 residuals), one for the 
varieties (18 resduals), and another for the subplots (72 residuals)? If 
we only looked at the varieties and blocks, this would be a randomized 
block design using the average for each plot as the observations. There 
would be 18 residuals. The F-statistic and p-value match the split-plot 
ANOVA results for variety.

Thanks.

Rick B.



From agobbi at anadyspharma.com  Sat Feb 22 23:24:03 2003
From: agobbi at anadyspharma.com (Alberto Gobbi)
Date: Sat Feb 22 23:24:03 2003
Subject: [R] Problem Writeing a pipe using R (stdin is consumed)
Message-ID: <F71FE60EC95F164BB32C51B0E7A9C4C76B9FE1@eggs.anadys.anadyspharma.com>

Actually I must correct myself, the named pipe will work (thanks Reid!).

Also the suggestion to mix R commands and data should work, but I think I prefer the named pipe. The datafile will be huge in my case like GB, so that is the reason I do not want to use temporary files.

Thanks to everybody!
Alberto

-----Original Message-----
From: Alberto Gobbi 
Sent: Friday, February 21, 2003 11:52 AM
To: R-Help
Subject: RE: [R] Problem Writeing a pipe using R (stdin is consumed)


Thanks for the answer!
However what I would like to ba able to do is something like:
perl -e 'print "1 2\n\2 2\n";'  |  R --silent commandFile

and commandFile would contain something like:
t<-read.table(file("t"), sep=" ")
print(t*2)

This would need read.table to get the original stdin() and the commands to be read from a file.

The idea with the named pipe does not work either for the same reasons.

Thanks again,
Alberto



-----Original Message-----
From: M.Kondrin [mailto:mkondrin at hppi.troitsk.ru]
Sent: Friday, February 21, 2003 21:43 PM
To: R-Help
Subject: Re: [R] Problem Writeing a pipe using R (stdin is consumed)


M.Kondrin wrote:
> May be R -slave ... will help?
> man R
> ...
>        -q, --quiet
>               Don't print startup message
> 
>        --silent
>               Same as --quiet
> 
>        --slave
>               Make R run as quietly as possible
> 
> ...
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

$ echo "h<-1; print(h)" | R --slave
[1] 1

$

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From s195404 at student.uq.edu.au  Sun Feb 23 00:33:02 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Sun Feb 23 00:33:02 2003
Subject: [R] question
In-Reply-To: <D2F647887C1BD711905C00508B6144AA6A7B67@eupalinos.samos.aegean.gr>
References: <D2F647887C1BD711905C00508B6144AA6A7B67@eupalinos.samos.aegean.gr>
Message-ID: <1045956708.3e58086477aa1@my.uq.edu.au>

1. The easiest way may be to save the file as a delimited
file (CSV works well) and then read it into R (using
read.csv, read.delim, etc). A DCOM server does exist for
R (see CRAN), but I don't have any experience with it. I
know that others use it successfully.

2. You will need to give the exact error message if you
want a more specific advice. Perhaps R cannot find the
file. 


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting Nicoleris Theodoros <nikthe at aegean.gr>:

> Iam a novice R-user and I have a few questions:
> 1) How can R import an Excell data file?
> 
> 2) I have a file.s file which it seems I can open but I can 
> not load it i.e. when I write the file name in the command line, for e.g.
> >file.s it gives me an error message
> thank you for your consideration,
> Theo Nicoleris
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From spencer.graves at pdf.com  Sun Feb 23 00:50:04 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun Feb 23 00:50:04 2003
Subject: [R] spherical coordinates and quadratic regression
Message-ID: <3E580C6B.4000607@pdf.com>

	  What functions are available to support working in spherical 
coordinates, e.g., transforming (x, y, z) on a unit sphere to 
(longitude, latitude) and vice versa?

	  More generally, is anything available on quadratic regression, i.e., 
obtaining a least squares solution to a system of n equations quadratic 
in 3 unknowns?  The sum of squares of residuals (SSE) can have either 
one or two local minima.  With polar coordinates, I can tell if a 
solution is unique and find the other solution if it is not.

	  I can write my own, but I'd rather use more standard utilities if 
they exist.

	  Thanks,
	  Spencer Graves



From rab at nauticom.net  Sun Feb 23 01:32:03 2003
From: rab at nauticom.net (rab)
Date: Sun Feb 23 01:32:03 2003
Subject: [R] Variance Components
In-Reply-To: <3E96F037.60105@arcriswell.com>
References: <3E96F037.60105@arcriswell.com>
Message-ID: <3E581E18.10404@nauticom.net>

Does anyone know of a function or package that provides methods for 
variance components similar to S-Plus's "varcomp" and "is.random" functions?

Thanks.

Rick B.



From MSchwartz at medanalytics.com  Sun Feb 23 02:14:03 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun Feb 23 02:14:03 2003
Subject: [R] question
In-Reply-To: <1045956708.3e58086477aa1@my.uq.edu.au>
References: <D2F647887C1BD711905C00508B6144AA6A7B67@eupalinos.samos.aegean.gr> <1045956708.3e58086477aa1@my.uq.edu.au>
Message-ID: <3E582010.7050206@MedAnalytics.com>

Andrew C. Ward wrote:
> 1. The easiest way may be to save the file as a delimited file (CSV
> works well) and then read it into R (using read.csv, read.delim,
> etc). A DCOM server does exist for R (see CRAN), but I don't have any
> experience with it. I know that others use it successfully.
> 
> 2. You will need to give the exact error message if you want a more
> specific advice. Perhaps R cannot find the file.
> 
> 
> Regards,
> 
> Andrew C. Ward
> 
> CAPE Centre Department of Chemical Engineering The University of
> Queensland Brisbane Qld 4072 Australia andreww at cheque.uq.edu.au
> 
> 
> 
> Quoting Nicoleris Theodoros <nikthe at aegean.gr>:
> 
> 
>> Iam a novice R-user and I have a few questions: 1) How can R import
>> an Excell data file?
>> 
>> 2) I have a file.s file which it seems I can open but I can not
>> load it i.e. when I write the file name in the command line, for
>> e.g.
>> 
>>> file.s it gives me an error message
>> 
>> thank you for your consideration, Theo Nicoleris


In follow up to Andrew and Prof Ripley on your second question, one
thought comes to mind on the file load issue. That is to be sure that
you have properly specified the file's pathname when loading it.

I am presuming that you are under Windows.

Be sure to use either Linux/Unix-like pathnames using the "/" separator
or use a Windows-like double "\\" in the path. Also be sure to use
double quotes around the full file/pathname.


Thus, within Rgui if you use source(), use something like:

source("C:/My Documents/file.s")

or

source("C:\\My Documents\\file.s")


If you are using Rterm from a Windows command line use something like:

Rterm.exe --no-restore --no-save < "C:/My Documents/file.s" > R.out

or

Rterm.exe --no-restore --no-save < "C:\\My Documents\\file.s" > R.out


In both cases, of course adjust the file/pathname accordingly. On the
command line, spaces in the pathname as with "My Documents" will cause
problems since the text on either side of the blanks will be treated as
separate command line arguments, not as a single filename. Thus
surrounding the full path/filename with double quotes will help.


BTW, this is covered in the R Windows FAQ at

http://cran.r-project.org/bin/windows/contrib/rw-FAQ.html

under:

2.13 R can't find my file, but I know it is there!


Hope that might help,

Marc Schwartz



From spencer.graves at pdf.com  Sun Feb 23 02:52:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun Feb 23 02:52:03 2003
Subject: [R] Variance Components
References: <3E96F037.60105@arcriswell.com> <3E581E18.10404@nauticom.net>
Message-ID: <3E58290F.20602@pdf.com>

"lme" in library(nlme) is vastly superior in many ways to varcomp, but 
has the disadvantage of being difficult to use, at least in my 
experience.  When I need it, I also refer to Jos? C. Pinheiro and 
Douglas M. Bates (2000) Mixed-effects models in S and S-PLUS (NY:  New 
York : Springer).  I highly recommend this book.

I hope this helps.
Spencer Graves

rab wrote:
> Does anyone know of a function or package that provides methods for 
> variance components similar to S-Plus's "varcomp" and "is.random" 
> functions?
> 
> Thanks.
> 
> Rick B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sun Feb 23 08:46:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Feb 23 08:46:03 2003
Subject: [R] Problem Replicating Venables & Riply Split-Plot Example
In-Reply-To: <3E57EC5B.7090609@nauticom.net>
Message-ID: <Pine.LNX.4.44.0302230734150.5332-100000@gannet.stats>

I don't know how you got oats.aov (or where you got a name similar to mine
from).

Package MASS comes with scripts for the 1999 and 2002 editions which do
what you ask.  I really don't know why you expect code written for 1993
S-PLUS to work unchanged in 2003 R (or 2003 S-PLUS), and suggest you
invest in the current edition.

On Sat, 22 Feb 2003, rab wrote:

> I'm using R 1.6.1 under Redhat Linux 8.0. I'm following the example from 
> V&R (1994) pp. 177-181. I get the split-plot ANOVA table:
> 
>  > summary(oats.aov)
> 
> Error: B
>           Df  Sum Sq Mean Sq F value Pr(>F)
> Residuals  5 15875.3  3175.1
> 
> Error: B:V
>           Df Sum Sq Mean Sq F value Pr(>F)
> V          2 1786.4   893.2  1.4853 0.2724
> Residuals 10 6013.3   601.3
> 
> Error: Within
>           Df  Sum Sq Mean Sq F value    Pr(>F)
> Nf         3 20020.5  6673.5 37.6856 2.458e-12 ***
> Nf:V       6   321.7    53.6  0.3028    0.9322
> Residuals 45  7968.7   177.1
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> 
> 
> I need to get hold of the residuals and fitted values. The usual way of 
> using "resid" and "fitted" doesn't work I guess because this is a 
> multistratum model. The "studres" function shows up if I load the MASS 
> library. But I cannot get the "proj" and "update" functions to work as 
> they do in S-Plus:
> 
>  > oats.fm <- update(oats.aov,qr=TRUE)
> Error in update.default(oats.aov, qr = TRUE) :
>         need an object with call component
> 
> How can I get the residuals and fitted values? Wouldn't there be three 
> sets of residuals? One for the blocks (6 residuals), one for the 
> varieties (18 resduals), and another for the subplots (72 residuals)? If 
> we only looked at the varieties and blocks, this would be a randomized 
> block design using the average for each plot as the observations. There 
> would be 18 residuals. The F-statistic and p-value match the split-plot 
> ANOVA results for variety.
> 
> Thanks.
> 
> Rick B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From efc at sfsu.edu  Sun Feb 23 10:15:04 2003
From: efc at sfsu.edu (Edward F. Connor)
Date: Sun Feb 23 10:15:04 2003
Subject: [R] Extracting the dispersion parameter
Message-ID: <5.1.0.14.0.20030223011004.037ae500@sfsu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030223/cd5ab741/attachment.pl

From ligges at statistik.uni-dortmund.de  Sun Feb 23 10:29:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Feb 23 10:29:03 2003
Subject: [R] Extracting the dispersion parameter
References: <5.1.0.14.0.20030223011004.037ae500@sfsu.edu>
Message-ID: <3E589484.C2B04269@statistik.uni-dortmund.de>


"Edward F. Connor" wrote:
> 
> I have been unsuccessful in extracting the dispersion parameter in SPLUS
> 6.1 using
> 
> summary or summary.glm(modelobj$dispersion)
> 
> from a glm object in which the family was set to quasi. This is the syntax
> given in the manual. I want to write a script to bootstrap the estimate of
> the dispersion parameter, but cannot seem to access that value.
> 
> Any suggestions?


summary() calculates it, hence it's part of the summary object:
 
  summary(modelobj)$dispersion


Uwe Ligges

> Thanks,
> 
> Ed
> 
> ----------
> 
> Edward F. Connor                                Office Phone    415-338-6997
> Department of Biology                           Lab Phone       415-338-3873
> San Francisco State University                  Fax             415-405-0306
> 1600 Holloway Avenue                            email:          efc at sfsu.edu
> San Francisco, CA 94132                 web: http://userwww.sfsu.edu/~efc
> 
> ----------
> 
>         [[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sun Feb 23 10:33:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Feb 23 10:33:03 2003
Subject: [R] Extracting the dispersion parameter
In-Reply-To: <5.1.0.14.0.20030223011004.037ae500@sfsu.edu>
Message-ID: <Pine.LNX.4.44.0302230924480.5516-100000@gannet.stats>

On Sun, 23 Feb 2003, Edward F. Connor wrote:

> I have been unsuccessful in extracting the dispersion parameter in SPLUS 
> 6.1 using
> 
> summary or summary.glm(modelobj$dispersion)
> 
> from a glm object in which the family was set to quasi. This is the syntax 
> given in the manual. 

What is `the manual'?  If this is an accurate transcription then `the
manual' is incorrect.

> I want to write a script to bootstrap the estimate of 
> the dispersion parameter, but cannot seem to access that value.
> 
> Any suggestions?

Ask on S-news about S-PLUS questions!  You may have meant

summary(glmobject)$dispersion

but as glm is one area where S-PLUS and R differ considerably it does help 
to ask in the correct forum.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dvumani at hotmail.com  Sun Feb 23 15:18:03 2003
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Sun Feb 23 15:18:03 2003
Subject: [R] expression for simple EM
Message-ID: <F143UQtXvXOCcUB5Ayj0000062b@hotmail.com>

Dear R users,

I know this is the wrong forum for such a question but I need help.

I would like to write down the likelihood expression for a simple EM 
problem. I have one categorical covariate with 5 levels and a missing count 
which can fall in any of the categories. I know the solution to the problem 
but can't seem to get the likelihood expression correct (if it is possible).

Thanks.


Vumani Dlamini, Student
Faculty of Health Sciences
University of Natal



From pburns at pburns.seanet.com  Sun Feb 23 18:40:03 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sun Feb 23 18:40:03 2003
Subject: [R] A Guide for the Unwilling S User
Message-ID: <3E590867.5060108@pburns.seanet.com>

"A Guide for the Unwilling S User" is available at
 http://www.burns-stat.com/pages/Tutor/unwilling_S.pdf
(Or click on Tutorials from the main web page.)

This is an improved version of the document that was put in
the same location a few days ago.  It has dropped the "draft"
status, but I am always interested in suggestions for improvements.

The 8 page document has the aim of allowing a novice user
to get some useful work done fast enough that they don't give up.
This could be a student with an assignment, a worker with a
graph to produce before they go home, or a prospective user of
some specific S functionality.  It applies equally to S-PLUS and R.

It may be redistributed as long as there is no more than a nominal
charge for the media.

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0) 208 525 0696
http://www.burns-stat.com/    (new home of S Poetry)



From tlumley at u.washington.edu  Sun Feb 23 19:18:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun Feb 23 19:18:03 2003
Subject: [R] Subpopulations in Complex Surveys
In-Reply-To: <10e.1ec5a6e1.2b85538b@aol.com>
Message-ID: <Pine.A41.4.44.0302231010380.61242-100000@homer36.u.washington.edu>

On Wed, 19 Feb 2003 TyagiAnupam at aol.com wrote:

> Hi,
> is there a way to analyze subpopulations (e.g. women over 50, those who
> answered "yes" to a particular question) in a survey using Survey package?
> Other packages (e.g. Stata, SUDAAN) do this with a subpopulation option to
> identify the subpopulation for which the analysis shoud be done. I did not
> see this option in the Survey package. Is there another way to do this?
>

Not directly.

This only really matters for svymean. For the regression models it's just
a convenience as you can specify a model that has an interaction with the
subpopulation indicator to get estimates and standard errors in the
subpopulation.

For svymean you can use a regression model too:
Instead of a hypothetical   svymean(~x, design=d, subpop=race==2)  do
   svyglm(x~I(race==2)+0, design=d)

I need to work out if there's a general way to handle subpopulations or
whether it needs to be coded on a case by case basis.


	-thomas



From p.murrell at auckland.ac.nz  Sun Feb 23 21:00:03 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Sun Feb 23 21:00:03 2003
Subject: [R] grid.grill?
References: <3E568E59.5030809@hppi.troitsk.ru>
Message-ID: <3E59281F.9050305@stat.auckland.ac.nz>

Hi


M.Kondrin wrote:
> Why this command does not return grob? What is special about grill and 
> what makes it different from axis, lines, rectangles...


Most of the predefined grid drawing functions do two things:  draw 
something and create and (invisibly) return a grob (graphical object). 
This means that they can be used in several different ways: 
"procedurally" just for their side effect (drawing something); or 
"functionally" for the object they produce (e.g., to use in the 
placement or sizing of another object); or both (e.g., to have a record 
of what has been drawn that can be uniquely identified and edited).  The 
default behaviour is "both" so that grid functions appear to work like 
their standard graphics counterparts (i.e., they just draw something).

Functions that call the grid drawing functions can choose to just draw 
something, or they can choose to use the graphical objects from the grid 
functions to produce a graphical object of their own.  Ideally, a new 
function will do the latter so that functions that want to call it also 
have a choice.  But it is easier to write a function that just does drawing.

grid.grill is an example of a function that just does drawing.  It's a 
convenience function that was easy to write.  It should be rewritten to 
produce a graphical object at some stage -- perhaps a good exercise for 
someone learning grid? :)

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz



From tblackw at umich.edu  Sun Feb 23 21:13:08 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Sun Feb 23 21:13:08 2003
Subject: [R] 4-parameter logistic model
In-Reply-To: <000701c2da1b$6ac283e0$6101a8c0@launchmodem.com>
Message-ID: <Pine.SOL.4.44.0302231503200.18025-100000@robotron.gpcc.itd.umich.edu>

Christian  -

I acknowledge Prof. Bates' answer and his superior knowledge.
But for the first equation you have typed below, theta1 is
clearly the asymptote as x goes to minus infinity, and theta2
is the asymptote as x goes to plus infinity.

The equation you have typed and the excerpt you have quoted
from the book clearly disagree.  I don't know anything about
the function  SSfpl(), inparticular whether it agrees with
the book or not.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -


On Fri, 21 Feb 2003, Christian Mora wrote:

> Dear R users
>
> I'm a new user of R and I have a basic question about the 4-parameter
> logistic model. According to the information from Pinheiro & Bates the model
> is:
>
> y(x)=theta1+(theta2-theta1)/(1+exp((theta3-x)/theta4)) ==
> y(x)=A+(B-A)/(1+exp((xmid-input)/scal))
>
> from the graph in page 518 of the book of the same authors (mixed models in
> S) theta 1 corresponds to the horizontal asymptote as x goes to infinity and
> theta2 the horizontal asymptote as x goes to -infinity. When I use the
> function SSfpl(input,A,B,xmid,scal), I'm not sure why the value of A is the
> lower of the two asymptotes if according to the original function A should
> be equal to theta1 (upper asymptote).. or maybe I'm wrong.
>
> I'll appreciate any comment on this.
>
> Best Regards
>
> CM
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From TyagiAnupam at aol.com  Sun Feb 23 23:14:03 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Sun Feb 23 23:14:03 2003
Subject: [R] Subpopulations in Complex Surveys
Message-ID: <f3.28cf8d75.2b8aa173@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030223/8b9cc801/attachment.pl

From schnitzlerj at gmx.de  Sun Feb 23 23:46:02 2003
From: schnitzlerj at gmx.de (Johannes Schnitzler)
Date: Sun Feb 23 23:46:02 2003
Subject: [R] time series outbreak detection
Message-ID: <22222.1046040309@www34.gmx.net>

Dear all,

i have multivariate timeseries (weekly data).

1)"Moving standard deviation"
With the "filter function" together with "lag" from package ts
it is possible to calculate a moving average for the time series for each
week at once (6 weeks back from the actual week and 12 weeks from the last two
years).
But i also need the associated standard deviations. Is there a function for
this?


2)"Robust Regression"
The time series derives from reported cases due to different pathogens.
Some of them with saisonal pattern. There are huge differences in counts
(depending on the pathogen) from zero up to several hundred counts per week. I
have only data since 2001. I want to realize outbreak detection algorithms (so
far, depending on the pathogen with Standard Deviation / Poisson and CUSUM).
Beforehand i have to "clean" the data from past outbreaks.
Has anybody experience with a rather robust regression model which cuts
former "outliers"?

Thank you very much for advice.


Johannes Schnitzler
Germany Berlin
schnitzlerj at gmx.de



From parkhurs at indiana.edu  Mon Feb 24 01:17:03 2003
From: parkhurs at indiana.edu (David Parkhurst)
Date: Mon Feb 24 01:17:03 2003
Subject: [R] trellis.datasets help
Message-ID: <001e01c2db9a$113de230$2cf31644@spea.indiana.edu>

I've looked every way I can think of for help on trellis.datasets, but nothing comes
up for me.  Please help me find information on what is included, and how to get at
those data.  Thanks.

Dave Parkhurst



From TyagiAnupam at aol.com  Mon Feb 24 01:28:03 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Mon Feb 24 01:28:03 2003
Subject: [R] trellis.datasets help
Message-ID: <6a.2dfae59f.2b8ac0c4@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030224/7ff0ae7c/attachment.pl

From deepayan at stat.wisc.edu  Mon Feb 24 01:37:03 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon Feb 24 01:37:03 2003
Subject: [R] trellis.datasets help (lattice ?)
In-Reply-To: <001e01c2db9a$113de230$2cf31644@spea.indiana.edu>
References: <001e01c2db9a$113de230$2cf31644@spea.indiana.edu>
Message-ID: <200302231836.03165.deepayan@stat.wisc.edu>

Are you talking about lattice ? 

If so, help(singer) brings up the following:

--------------------------------------------------------------------

trellis.datasets           package:lattice           R Documentation

Data Sets in the Lattice library

Description:

     These data sets are included to facilitate the same examples as
     S-Plus trellis. (Detailed descriptions of the datasets are omitted
     for now.)

Usage:

     data(singer)
     data(melanoma)
     data(ethanol)
     data(sunspot)
     data(environmental)

Source:

     These datasets are part of the collection of datasets used in the
     book Visualizing Data by Bill Cleveland, and are available at Bill
     Cleveland's Homepage <URL:
     http://cm.bell-labs.com/cm/ms/departments/sia/wsc/index.html> as
     well as in Statlib.

----------------------------------------------------------------------

which should point you to Bill Cleveland's website and book.


On Sunday 23 February 2003 06:15 pm, David Parkhurst wrote:
> I've looked every way I can think of for help on trellis.datasets, but
> nothing comes up for me.  Please help me find information on what is
> included, and how to get at those data.  Thanks.
>
> Dave Parkhurst
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jerrytheshrub at hotmail.com  Mon Feb 24 02:31:02 2003
From: jerrytheshrub at hotmail.com (Jeremy Z Butler)
Date: Mon Feb 24 02:31:02 2003
Subject: [R] fill prob. in legend
Message-ID: <F17mRpVgRdc6GoVaE7W000023e1@hotmail.com>





Hi,
I'm trying to construct a legend which has four lines of text and associated 
symbols. The first two symbols need to be normal lines which vary only in 
colour. The second two symbols should have filled boxes. How do I suppress 
the fill boxes in the first two lines?
J.



From till.baumgaertel at epost.de  Mon Feb 24 02:42:02 2003
From: till.baumgaertel at epost.de (Till Baumgaertel)
Date: Mon Feb 24 02:42:02 2003
Subject: [R] Mass: lda and collinear variables
Message-ID: <3E596C8D0000000D@PPD27104.x.de>

hello list,

when I use method lda of the MASS package I experience a warning:
variables are collinear in: lda.default(data[train, ], classes[train])

Is there an easy way to recover from this issue within the MASS package?
Or how can I tell how severe this issue is at all?

I understand that I shouldn't use lda at all with collinear data and should
use "quadratische" (squared?) discr. analysis (by Welch) instead. Or is
this wrong? Could I do this in R? 

Thanks four your help,
Till Baumg?rtel





________________________________________
Abos online bestellen. Oder Leser werben und Pr?mie aussuchen. http://www.epost.de/aboservice



From spencer.graves at pdf.com  Mon Feb 24 03:42:02 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon Feb 24 03:42:02 2003
Subject: [R] Subpopulations in Complex Surveys
References: <f3.28cf8d75.2b8aa173@aol.com>
Message-ID: <3E598626.1050301@pdf.com>

I'm not familiar with the survey systems, any array or data.frame can be 
subsetted using a logical vector.

For example, let Data = data.frame(sex = ..., age =, ..., ...).  Then,

	Sel.fem50 <- (Data$sex=="Female") & (Data$age> 50)
	fem50Answers <- FUN(... data=Data[Sel.fem50,])

If you want to do this to many subgoups, consider "split", "by", 
"lapply", "sapply", "tapply", "aggregate", etc.  See Venables and 
Ripley, Modern Applied Statistics with S, 4th ed.

Hope this helps.
Spencer Graves

TyagiAnupam at aol.com wrote:
> In a message dated 2/23/03 1:19:39 PM Eastern Standard Time, 
> tlumley at u.washington.edu writes:
> 
> 
>>On Wed, 19 Feb 2003 TyagiAnupam at aol.com wrote:
>>
>>
>>>Hi,
>>>is there a way to analyze subpopulations (e.g. women over 50, those who
>>>answered "yes" to a particular question) in a survey using Survey 
>>
>>package?
>>
>>>Other packages (e.g. Stata, SUDAAN) do this with a subpopulation option 
>>
>>to
>>
>>>identify the subpopulation for which the analysis shoud be done. I did 
>>
>>not
>>
>>>see this option in the Survey package. Is there another way to do this?
>>>
>>
>>Not directly.
>>
>>This only really matters for svymean. For the regression models it's just
>>a convenience as you can specify a model that has an interaction with the
>>subpopulation indicator to get estimates and standard errors in the
>>subpopulation.
>>
>>For svymean you can use a regression model too:
>>Instead of a hypothetical   svymean(~x, design=d, subpop=race==2)  do
>>   svyglm(x~I(race==2)+0, design=d)
>>
>>I need to work out if there's a general way to handle subpopulations or
>>whether it needs to be coded on a case by case basis.
>>
>>
>>    -thomas
>>
> 
> 
> Thanks a lot for the answer.  Is there a way to get quantiles and 
> cross-tabulations in subpopulations? If I think of proportion as mean of 
> binary indicator (y: "got milk?"=1), can I use the solution above for 
> proportions in subpopulations?
> svyglm(y~I(race==2)+0, design=d)
> If I create a binary indicator for a subpopulation (men over 50), can I use 
> it with svytable?
> svytable( ~y+z,design=d)
> --anupam.
> 
> *********************************************************
> Prediction is very difficult, especially about the future. 
>                   -- Niels Bohr
> *********************************************************
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gisar at nus.edu.sg  Mon Feb 24 06:31:03 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Mon Feb 24 06:31:03 2003
Subject: [R] faraway tutorial: cryptic command to newbie
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F217@MBXSRV03.stf.nus.edu.sg>

c = concatenate / combine 
Try help(c) or under the 'Vector and Assignments' section of An
Introduction to R.

You have to put the folder 'faraway' into c:/.../R/rw1061/library/
where ... is your path to R and rw1061 could be rw1062 ect depending on
your version.


-----Original Message-----
From: Christoph Lehmann [mailto:lehmann at puk.unibe.ch] 
Sent: Sunday, February 23, 2003 12:49 AM
To: r-help at stat.math.ethz.ch
Subject: [R] faraway tutorial: cryptic command to newbie


I am just about working through Faraways excellent tutorial "practical
regression and ANOVA using R"

on page 24 he makes the x matrix:
x <- cbind(1,gala[,-c(1,2)])

how can I understand this gala[,-c(1,2)])... I couldn't find an
explanation of such "c-like" abbreviations anywhere.

thanks for a hint.

another problem: I couldn't load the faraway library, using the
library() command, even though I specified the path, .. do I need to put
library files into a certain directory? I always got an error: Error in
library(faraway) : There is no package called `faraway'


Thanks a lot

christoph

-- 
Christoph Lehmann 
Department of Psychiatric Neurophysiology 
University Hospital of Clinical Psychiatry 
Waldau 
CH-3000 Bern 60 
Switzerland 

Phone:  ++41 31 930 93 83 
Mobile: ++41 31 570 28 00
Fax:    ++41 31 930 99 61 
Email:  lehmann at puk.unibe.ch 
Web:    http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gisar at nus.edu.sg  Mon Feb 24 06:40:10 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Mon Feb 24 06:40:10 2003
Subject: [R] Mass: lda and collinear variables
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053F28@MBXSRV03.stf.nus.edu.sg>

What is the dimension of your data. i.e. how many observations and how many variables do you have?

-----Original Message-----
From: Till Baumgaertel [mailto:till.baumgaertel at epost.de] 
Sent: Monday, February 24, 2003 9:41 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Mass: lda and collinear variables


hello list,

when I use method lda of the MASS package I experience a warning: variables are collinear in: lda.default(data[train, ], classes[train])

Is there an easy way to recover from this issue within the MASS package? Or how can I tell how severe this issue is at all?

I understand that I shouldn't use lda at all with collinear data and should use "quadratische" (squared?) discr. analysis (by Welch) instead. Or is this wrong? Could I do this in R? 

Thanks four your help,
Till Baumg?rtel





________________________________________
Abos online bestellen. Oder Leser werben und Pr?mie aussuchen. http://www.epost.de/aboservice

______________________________________________
R-help at stat.math.ethz.ch mailing list http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From till.baumgaertel at epost.de  Mon Feb 24 09:54:03 2003
From: till.baumgaertel at epost.de (Till Baumgaertel)
Date: Mon Feb 24 09:54:03 2003
Subject: AW: RE: [R] Mass: lda and collinear variables
In-Reply-To: <024D6AEFCB92CB47BA1085751D184BB801053F28@MBXSRV03.stf.nus.edu.sg>
Message-ID: <3E548CB900003FE7@PPD27101.x.de>

On one dataset I have 220 cases of physical data (the variables represent
points on a curve). The Original data set holds about 1800 variables but
I reduce this to a power of 2 (32, 64, ...) with an approximation method
so that the representation of one curve (one observation) with say 32 points
(variables) does not differ too much from the original representation with
1800 variables.

What I was also wondering about: Why does lda tell me about warnings and
not *errors*?

thanks,
till

>-- Original Nachricht --
>What is the dimension of your data. i.e. how many observations and how
many
>variables do you have?
>
>-----Original Message-----
>From: Till Baumgaertel [mailto:till.baumgaertel at epost.de] 
>Sent: Monday, February 24, 2003 9:41 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Mass: lda and collinear variables
>
>
>hello list,
>
>when I use method lda of the MASS package I experience a warning: variables
>are collinear in: lda.default(data[train, ], classes[train])
>
>Is there an easy way to recover from this issue within the MASS package?
>Or how can I tell how severe this issue is at all?
>
>I understand that I shouldn't use lda at all with collinear data and should
>use "quadratische" (squared?) discr. analysis (by Welch) instead. Or is
this
>wrong? Could I do this in R? 
>
>Thanks four your help,
>Till Baumg?rtel
>
>
>
>
>
>________________________________________
>Abos online bestellen. Oder Leser werben und Pr?mie aussuchen. http://www.epost.de/aboservice
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list http://www.stat.math.ethz.ch/mailman/listinfo/r-help






________________________________________
Abos online bestellen. Oder Leser werben und Pr?mie aussuchen. http://www.epost.de/aboservice



From ripley at stats.ox.ac.uk  Mon Feb 24 10:26:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb 24 10:26:02 2003
Subject: AW: RE: [R] Mass: lda and collinear variables
In-Reply-To: <3E548CB900003FE7@PPD27101.x.de>
Message-ID: <Pine.LNX.4.44.0302240921310.8592-100000@gannet.stats>

On Mon, 24 Feb 2003, Till Baumgaertel wrote:

> On one dataset I have 220 cases of physical data (the variables represent
> points on a curve). The Original data set holds about 1800 variables but
> I reduce this to a power of 2 (32, 64, ...) with an approximation method
> so that the representation of one curve (one observation) with say 32 points
> (variables) does not differ too much from the original representation with
> 1800 variables.
> 
> What I was also wondering about: Why does lda tell me about warnings and
> not *errors*?

Because they are not errors, but they probably indicate problems with 
your dataset.  Just occasionally it is right to use highly collinear 
inputs.  It may even be in your case, but it sounds as if you need to take 
a more orthogonal representation.


BTW, it is MASS not Mass!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ximing at are.berkeley.edu  Mon Feb 24 10:54:02 2003
From: ximing at are.berkeley.edu (ximing wu)
Date: Mon Feb 24 10:54:02 2003
Subject: [R] error-handling question
Message-ID: <5.1.0.14.2.20030224014310.00a8ad80@are.berkeley.edu>

hi,
I have a question about error-handling.  Say I want to do a simulation 100 
times, each experiment involves inverting a matrix. Occasionally the matrix 
is close to singularity,  R gives an error message and the program stops 
right there. Is there any way I can prevent the error message, assign 
something (say a NULL) to the outcome, and move on?

thanks a lot.


-----------------------------------------
Ximing Wu
Department of Agricultural & Resource Economics
University of California, Berkeley
http://are.berkeley.edu/~ximing/
------------------------------------------



From theis at statistik.uni-dortmund.de  Mon Feb 24 11:00:04 2003
From: theis at statistik.uni-dortmund.de (Winfried Theis)
Date: Mon Feb 24 11:00:04 2003
Subject: [R] error-handling question
In-Reply-To: <5.1.0.14.2.20030224014310.00a8ad80@are.berkeley.edu>
Message-ID: <XFMail.030224121512.theis@statistik.uni-dortmund.de>

Hi,

have a look at ?try.

Cheers,

Winfried
On 24-Feb-03 ximing wu wrote:
> hi,
> I have a question about error-handling.  Say I want to do a simulation 100 
> times, each experiment involves inverting a matrix. Occasionally the matrix 
> is close to singularity,  R gives an error message and the program stops 
> right there. Is there any way I can prevent the error message, assign 
> something (say a NULL) to the outcome, and move on?
> 
> thanks a lot.
> 
> 
> -----------------------------------------
> Ximing Wu
> Department of Agricultural & Resource Economics
> University of California, Berkeley
> http://are.berkeley.edu/~ximing/
> ------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

---------------------------------------------------------------------
E-Mail: Winfried Theis <theis at statistik.uni-dortmund.de>
Date: 24-Feb-03

Dipl.-Math. Winfried Theis
SFB 475, Fachbereich Statistik, Universit"at Dortmund, 44221 Dortmund
Tel.: +49-231-755-5903 FAX: +49-231-755-4387
----------------------------------------------------------------------



From roger at ysidro.econ.uiuc.edu  Mon Feb 24 11:04:58 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Mon Feb 24 11:04:58 2003
Subject: [R] error-handling question
In-Reply-To: <5.1.0.14.2.20030224014310.00a8ad80@are.berkeley.edu>
Message-ID: <Pine.SOL.4.30.0302240404270.19901-100000@ysidro.econ.uiuc.edu>

look at

?try


url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
email	rkoenker at uiuc.edu	Department of Economics Drayton House,
vox: 	217-333-4558		University of Illinois	30 Gorden St,
fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK
							vox:	020-7679-5838

On Mon, 24 Feb 2003, ximing wu wrote:

> hi,
> I have a question about error-handling.  Say I want to do a simulation 100
> times, each experiment involves inverting a matrix. Occasionally the matrix
> is close to singularity,  R gives an error message and the program stops
> right there. Is there any way I can prevent the error message, assign
> something (say a NULL) to the outcome, and move on?
>
> thanks a lot.
>
>
> -----------------------------------------
> Ximing Wu
> Department of Agricultural & Resource Economics
> University of California, Berkeley
> http://are.berkeley.edu/~ximing/
> ------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jasont at indigoindustrial.co.nz  Mon Feb 24 11:09:08 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon Feb 24 11:09:08 2003
Subject: [R] error-handling question
In-Reply-To: <5.1.0.14.2.20030224014310.00a8ad80@are.berkeley.edu>; from ximing@are.berkeley.edu on Mon, Feb 24, 2003 at 01:50:55AM -0800
References: <5.1.0.14.2.20030224014310.00a8ad80@are.berkeley.edu>
Message-ID: <20030224230531.A15827@camille.indigoindustrial.co.nz>

On Mon, Feb 24, 2003 at 01:50:55AM -0800, ximing wu wrote:
> hi,
> I have a question about error-handling.  Say I want to do a simulation 100 
> times, each experiment involves inverting a matrix. Occasionally the matrix 
> is close to singularity,  R gives an error message and the program stops 
> right there. Is there any way I can prevent the error message, assign 
> something (say a NULL) to the outcome, and move on?

Almost a FAQ.

help(try)


Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From andreww at cheque.uq.edu.au  Mon Feb 24 11:12:41 2003
From: andreww at cheque.uq.edu.au (Andrew C. Ward)
Date: Mon Feb 24 11:12:41 2003
Subject: [R] error-handling question
Message-ID: <01C2DC3F.FA5574B0.andreww@cheque.uq.edu.au>

You can achieve this with try(). Look at the second example (?try),
which is probably most like what you want to do.
	

Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



On Monday, February 24, 2003 7:51 PM, ximing wu [SMTP:ximing at are.berkeley.edu] wrote:
> hi,
> I have a question about error-handling.  Say I want to do a simulation 100 
> times, each experiment involves inverting a matrix. Occasionally the matrix 
> is close to singularity,  R gives an error message and the program stops 
> right there. Is there any way I can prevent the error message, assign 
> something (say a NULL) to the outcome, and move on?
> 
> thanks a lot.
> 
> 
> -----------------------------------------
> Ximing Wu
> Department of Agricultural & Resource Economics
> University of California, Berkeley
> http://are.berkeley.edu/~ximing/
> ------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From adrian.trapletti at lmttrading.com  Mon Feb 24 11:40:03 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Mon Feb 24 11:40:03 2003
Subject: [R] Re: GARCH with t-innovations
References: <20030222110007.10009.11973.Mailman@hypatia.math.ethz.ch>
Message-ID: <3E59F66C.F0F37CFD@lmttrading.com>

> Subject: [R] GARCH with t-innovations
> Date: 21 Feb 2003 14:07:44 +0100
> From: Gorazd Brumen <gbrumen at student.ethz.ch>
> To: r-help at stat.math.ethz.ch
>
> Dear all,
>
> Can garch function fit also t-innovations or only Gaussian innovations?
>
> --
> With kind regards -- Lepo pozdravljeni -- Gr??e (Gr?ezi) --
>
>                                                Gorazd Brumen
> -------------------------------
> Mail 1: gbrumen at student.ethz.ch
> Mail 2: gorazd.brumen at fmf.uni-lj.si
> Tel.: +41 (0)1 63 34906
> Homepage: valjhun.fmf.uni-lj.si/~brumen

The estimator provided by the garch function is the maximum likelihood estimator under conditional normality. Under conditional-nonnormality (e.g., t-distribution) the estimator is a quasi-maximum likelihood
estimator which is still consistent under certain (more restrictive than Gaussian case) assumptions. However, the standard errors as computed by the garch function are in the latter case not any more consistent.

For an overview see section 8 of the first citation in the help page of the garch function.

For practical purposes, that means you can fit a garch model with the garch function, take the residuals and fit, e.g., a t-distribution. This might be a consistent estimation procedure, however unless the residuals
are Gaussian not the ideal one.

best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com



From KINLEY_ROBERT at lilly.com  Mon Feb 24 12:09:03 2003
From: KINLEY_ROBERT at lilly.com (KINLEY_ROBERT@lilly.com)
Date: Mon Feb 24 12:09:03 2003
Subject: [R] Rcgi ?
Message-ID: <OFA06CF3AE.FB022BC9-ON80256CD7.003CC1DD@d49.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030224/ff5c9fc4/attachment.pl

From tkt2 at cdc.gov  Mon Feb 24 14:02:03 2003
From: tkt2 at cdc.gov (Thompson, Trevor)
Date: Mon Feb 24 14:02:03 2003
Subject: [R] Subpopulations in Complex Surveys
Message-ID: <2414774BEDB1D611B89900034772AF2B38B268@mcdc-atl-66.nccd.cdc.gov>

For svymean, can't you just pass the subpopulation into the design argument?

> svymean(~crc10yr, design=nhis.design[nhis.design$variables$age>=50,],
na.rm=TRUE)
  crc10yr 
0.3461349 
attr(,"var")
             [,1]
[1,] 2.903020e-05
> svyglm(crc10yr~I(age>=50)+0, design=nhis.design)
Stratified 1 - level Cluster Sampling design
With ( 678 ) clusters.

Call:  svyglm(formula = crc10yr ~ I(age >= 50) + 0, design = nhis.design) 

Coefficients:
I(age >= 50)FALSE   I(age >= 50)TRUE  
           0.1109             0.3461  

Degrees of Freedom: 17802 Total (i.e. Null);  17800 Residual
Null Deviance:      0.1394 
Residual Deviance: 0.09631      AIC: 6.601 

-trevor

-----Original Message-----
From: Thomas Lumley [mailto:tlumley at u.washington.edu]
Sent: Sunday, February 23, 2003 1:17 PM
To: TyagiAnupam at aol.com
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Subpopulations in Complex Surveys


On Wed, 19 Feb 2003 TyagiAnupam at aol.com wrote:

> Hi,
> is there a way to analyze subpopulations (e.g. women over 50, those who
> answered "yes" to a particular question) in a survey using Survey package?
> Other packages (e.g. Stata, SUDAAN) do this with a subpopulation option to
> identify the subpopulation for which the analysis shoud be done. I did not
> see this option in the Survey package. Is there another way to do this?
>

Not directly.

This only really matters for svymean. For the regression models it's just
a convenience as you can specify a model that has an interaction with the
subpopulation indicator to get estimates and standard errors in the
subpopulation.

For svymean you can use a regression model too:
Instead of a hypothetical   svymean(~x, design=d, subpop=race==2)  do
   svyglm(x~I(race==2)+0, design=d)

I need to work out if there's a general way to handle subpopulations or
whether it needs to be coded on a case by case basis.


	-thomas

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gbrumen at student.ethz.ch  Mon Feb 24 14:42:03 2003
From: gbrumen at student.ethz.ch (Gorazd Brumen)
Date: Mon Feb 24 14:42:03 2003
Subject: [R] nlm constrained minimization
Message-ID: <1046094066.1572.3.camel@misko>

Only one question: Can you constrain the minimization in the nlm
procedure?


-- 
With kind regards -- Lepo pozdravljeni -- Gr??e (Gr?ezi) --

					       Gorazd Brumen
-------------------------------
Mail 1: gbrumen at student.ethz.ch
Mail 2: gorazd.brumen at fmf.uni-lj.si
Tel.: +41 (0)1 63 34906
Homepage: valjhun.fmf.uni-lj.si/~brumen



From ripley at stats.ox.ac.uk  Mon Feb 24 15:10:04 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb 24 15:10:04 2003
Subject: [R] nlm constrained minimization
In-Reply-To: <1046094066.1572.3.camel@misko>
Message-ID: <Pine.LNX.4.44.0302241408001.1492-100000@gannet.stats>

On 24 Feb 2003, Gorazd Brumen wrote:

> Only one question: Can you constrain the minimization in the nlm
> procedure?

No, but you can in optim() and in constrOptim() (the latter in the 
development sources only).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From socher at stat.uni-muenchen.de  Mon Feb 24 15:15:13 2003
From: socher at stat.uni-muenchen.de (Anne-Laure Boulesteix)
Date: Mon Feb 24 15:15:13 2003
Subject: [R] gap statistic
Message-ID: <3E5A285D.7010902@stat.uni-muenchen.de>

Hi,

Just one question : Has the gap statistic of R.Tibshirani been 
implemented in R ?
I found nothing on the R website...

Thanks in advance
Anne-Laure Boulesteix



From KINLEY_ROBERT at lilly.com  Mon Feb 24 15:20:03 2003
From: KINLEY_ROBERT at lilly.com (KINLEY_ROBERT@lilly.com)
Date: Mon Feb 24 15:20:03 2003
Subject: [R] Rcgi  or better
Message-ID: <OF15A344C1.97C3E1CB-ON80256CD7.004E5216@d49.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030224/04da551a/attachment.pl

From tlumley at u.washington.edu  Mon Feb 24 16:20:06 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Feb 24 16:20:06 2003
Subject: [R] Subpopulations in Complex Surveys
In-Reply-To: <2414774BEDB1D611B89900034772AF2B38B268@mcdc-atl-66.nccd.cdc.gov>
Message-ID: <Pine.A41.4.44.0302240713420.133640-100000@homer38.u.washington.edu>

On Mon, 24 Feb 2003, Thompson, Trevor wrote:

> For svymean, can't you just pass the subpopulation into the design
> argument?
>

Yes, but you get the wrong standard errors (very slightly) in stratified
designs.

  If you compare the subsetting approach to the regression approach you
will find slightly different standard errors for the same point estimates.
Roughly speaking, you don't deserve as much benefit from the difference
between strata if some of the PSUs you originally sampled don't have any
of the subpopulation.

I've nearly finished an upgrade that I think handles this.

	-thomas



From reid_huntsinger at merck.com  Mon Feb 24 16:26:04 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Mon Feb 24 16:26:04 2003
Subject: [R] Problem Writeing a pipe using R (stdin is consumed)
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC357@uswpmx11.merck.com>

The named pipe idea works for me:

basically,

$ mknod to_R p

$ echo "test this out" > to_R &
$ R CMD BATCH rtest.R out

where rtest.R is

con <- fifo("to_R", open="r")
print(readlines(con))

Reid Huntsinger



-----Original Message-----
From: Alberto Gobbi [mailto:agobbi at anadyspharma.com]
Sent: Friday, February 21, 2003 2:52 PM
To: R-Help
Subject: RE: [R] Problem Writeing a pipe using R (stdin is consumed)


Thanks for the answer!
However what I would like to ba able to do is something like:
perl -e 'print "1 2\n\2 2\n";'  |  R --silent commandFile

and commandFile would contain something like:
t<-read.table(file("t"), sep=" ")
print(t*2)

This would need read.table to get the original stdin() and the commands to
be read from a file.

The idea with the named pipe does not work either for the same reasons.

Thanks again,
Alberto



-----Original Message-----
From: M.Kondrin [mailto:mkondrin at hppi.troitsk.ru]
Sent: Friday, February 21, 2003 21:43 PM
To: R-Help
Subject: Re: [R] Problem Writeing a pipe using R (stdin is consumed)


M.Kondrin wrote:
> May be R -slave ... will help?
> man R
> ...
>        -q, --quiet
>               Don't print startup message
> 
>        --silent
>               Same as --quiet
> 
>        --slave
>               Make R run as quietly as possible
> 
> ...
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

$ echo "h<-1; print(h)" | R --slave
[1] 1

$

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------



From huan.huang at bnpparibas.com  Mon Feb 24 16:34:02 2003
From: huan.huang at bnpparibas.com (huan.huang@bnpparibas.com)
Date: Mon Feb 24 16:34:02 2003
Subject: [R] nlm constrained minimization
Message-ID: <OFCEC5AF31.8799BE12-ON80256CD7.005517EC@bnpparibas.com>

Dear all,

By the old emails I was told that function constrOptim() is in package
r-devel. But where I can find this package?

Thanks  a lot.

Huan



> Only one question: Can you constrain the minimization in the nlm
> procedure?

No, but you can in optim() and in constrOptim() (the latter in the
development sources only).




--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help






This message and any attachments (the "message") is\ intended so ... [[dropped]]



From Huiqin.Yang at noaa.gov  Mon Feb 24 16:38:02 2003
From: Huiqin.Yang at noaa.gov (Huiqin Yang)
Date: Mon Feb 24 16:38:02 2003
Subject: [R] convert Splus mapproject() in R
Message-ID: <3E5A3AB8.DA7BA9C8@noaa.gov>

Hello everyone,

  I was wondering if anyone knows how to convert the Splus mapproject( ) function for use in R, I would greatly appreciate your help. I am using the following system, R
Version 1.6.1  (2002-11-01) for SunOS 5.5 and  Splus  Version 5.1 Release 1 for Sun SPARC, SunOS 5.5.

Thanks, 

Helen



From andy_liaw at merck.com  Mon Feb 24 16:47:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon Feb 24 16:47:03 2003
Subject: [R] convert Splus mapproject() in R
Message-ID: <3A822319EB35174CA3714066D590DCD534BCFC@usrymx25.merck.com>

That function does not seem to exist in Splus 6.1.2 release 2 for Linux.
Could it be that it's written by someone locally, or it was in some add-on
module?

Andy

> -----Original Message-----
> From: Huiqin Yang [mailto:Huiqin.Yang at noaa.gov]
> Sent: Monday, February 24, 2003 10:31 AM
> To: r-help
> Subject: [R] convert Splus mapproject() in R
> 
> 
> Hello everyone,
> 
>   I was wondering if anyone knows how to convert the Splus 
> mapproject( ) function for use in R, I would greatly 
> appreciate your help. I am using the following system, R
> Version 1.6.1  (2002-11-01) for SunOS 5.5 and  Splus  Version 
> 5.1 Release 1 for Sun SPARC, SunOS 5.5.
> 
> Thanks, 
> 
> Helen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From ripley at stats.ox.ac.uk  Mon Feb 24 16:57:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb 24 16:57:03 2003
Subject: [R] nlm constrained minimization
In-Reply-To: <OFCEC5AF31.8799BE12-ON80256CD7.005517EC@bnpparibas.com>
Message-ID: <Pine.LNX.4.44.0302241553180.1743-100000@gannet.stats>

On Mon, 24 Feb 2003 huan.huang at bnpparibas.com wrote:

> By the old emails I was told that function constrOptim() is in package
> r-devel. But where I can find this package?

Look in the R FAQ.  It is not a package but a version of R.


BTW, it is impolite (and a breach of copyright law) to quote people
without attribution, as you have just done here.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From B.Rowlingson at lancaster.ac.uk  Mon Feb 24 17:02:10 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon Feb 24 17:02:10 2003
Subject: [R] convert Splus mapproject() in R
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BCFC@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD534BCFC@usrymx25.merck.com>
Message-ID: <3E5A41EE.3060107@lancaster.ac.uk>

Liaw, Andy wrote:
> That function does not seem to exist in Splus 6.1.2 release 2 for Linux.
> Could it be that it's written by someone locally, or it was in some add-on
> module?

Its part of the 'maps' library. Ray Brownrigg has ported it to R, but 
looking at the DESCRIPTION file tells me this:

Description: Display of maps.  The projection code found in the original
         S code is not included because of unclear licensing issues (and
         that code didn't work straight off anyway :-)).


  If the original poster is feeling brave, my Rmap library will do map 
projections using the PROJ4 library (so you'll have to install that 
first). Its in a very early state, and the current version wont read 
that format of map file (thing.G, thing.L, thing.N files) if thats what 
is being used.

  But it might be that all is needed is a project(xy) function, which my 
code does as a simple (~5 line) wrapper to the PROJ4 library.

Here:
  http://www.maths.lancs.ac.uk/Software/Rmap/

  But be warned, its very very fragile and I cant help you if it fails.

Baz



From m.kienzle at marlab.ac.uk  Mon Feb 24 17:17:03 2003
From: m.kienzle at marlab.ac.uk (Marco Kienzle)
Date: Mon Feb 24 17:17:03 2003
Subject: [R] Legend in plot: symbol for mean and standard deviation
Message-ID: <1046102774.9916.103.camel@PC535>

Dear list,

I am facing the following problem with the legend of a plot that display
the mean and variance of a measurement y as a function of x, the mean
being represented by a dot and the variance by a vertical line.

My problem is that I am unable to display the symbol (dot + vertical
line) in the legend. 


any help is welcome,
thanks
marco
-- 
____________________________________________________________________________

Marco Kienzle
Fisheries Research Services
Marine Laboratory
PO Box 101 Victoria Road
Aberdeen AB119DB
United Kingdom
 
direct: +44 (0) 1224 295421
tel:    +44 (0) 1224 876544 
fax:    +44 (0) 1224 295511
http://www.marlab.ac.uk



From kurt.sys at rug.ac.be  Mon Feb 24 17:26:03 2003
From: kurt.sys at rug.ac.be (Kurt Sys)
Date: Mon Feb 24 17:26:03 2003
Subject: [R] segmented regression
Message-ID: <15962.18380.725334.108427@ksys.rug.ac.be>

Hello all,

I'm trying to find out how to perform a 'segmented regression'. I have some data and the 'classical' model used is:

y(t) = a + bx(t) + cx(t)^2 + u(t) for x(t) < x(0)
y(t) = a + bx(0) + cx(0)^2 + d(x(t) - x(0)) + u(t) for x(t) > x(0)
and u(t) = rho.u(t-1) + eps

(It's a model using an ARIMA-model, in this case AR(1)-process)
The parameters to estimate here are: a, b, c, d and x(0) (with the last one, the most important one). u(t) is estimated using the rho of the AR(1).
How can I use such a 'segmented formula' or 'segmented model' in R or how do I perform such a regression (nonlinear or restricted maximum likelihood)?

thanks in advance,
Kurt



From maechler at stat.math.ethz.ch  Mon Feb 24 17:32:52 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Feb 24 17:32:52 2003
Subject: [R] calculating mean direction (CircStats)
In-Reply-To: <002501c2d9e0$e232d8c0$f1e2548d@tulpe>
References: <002501c2d9e0$e232d8c0$f1e2548d@tulpe>
Message-ID: <15962.18683.198238.98841@gargle.gargle.HOWL>

>>>>> "Cordula" == Cordula Becker <cbecker at psy.uni-muenchen.de>
>>>>>     on Fri, 21 Feb 2003 20:39:00 +0100 writes:

    Cordula> Hi, I've currently to work with some circular
    Cordula> data. Unfortunately I'm not very familiar with
    Cordula> circular statistics and would really appreciate if
    Cordula> I could get some help concerning the CircStats
    Cordula> package this way.

    Cordula> My data lies in the range 0 to 2*pi, and is
    Cordula> transformed to radians (as expected by the
    Cordula> CircStats methods). Calculating the mean direction
    Cordula> (circ.mean) results for some datasets in a negative
    Cordula> mean direction like -0.8309982. I think that this
    Cordula> might be wrong. If it is correct, what is the
    Cordula> meaning of a negative mean direction?

It's in  (-pi, pi]  which is as valid as (0, 2*pi].

As a matter of fact, any angle is valid; it's just they are
periodic, i.e.,  phi + 2*k*pi is equivalent to phi for any
k in Z = { .... -1,0,1,.... }p.

    Cordula> I also read that some transformation of the data
    Cordula> might be necessary to get the correct mean
    Cordula> direction (multiplying all angles by two and taking
    Cordula> the modulus of these angles and 360?). I manage to
    Cordula> do so, but I'm not sure about how to back-transfer
    Cordula> the mean direction I'm getting as a result to the
    Cordula> angles of my original data.

I don't think that the CircStats package has any of those
restrictions for input.
It *is* important to use "radians", not "degrees" though
(I say this, since you mention 360? above).

I hope this helps,
Martin

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From knussear at biodiversity.unr.edu  Mon Feb 24 17:45:04 2003
From: knussear at biodiversity.unr.edu (Ken Nussear)
Date: Mon Feb 24 17:45:04 2003
Subject: [R] bwplot stats question
In-Reply-To: <9E71B848-44E9-11D7-8102-0003939B3BBE@biodiversity.unr.edu>
Message-ID: <2A384989-4817-11D7-B026-0003939B3BBE@biodiversity.unr.edu>

Hi List,

Just wondering where the documentation exists for the statistics which 
makeup the bwplot.

I'm guessing that if R is like similar products that the graph is 
constructed as

The median is the filled circle. The box surrounding the filled circle 
depicts the 25th and 75th quartile. The range of values is given by the 
dotted lines (?whiskers?) outside of each box, and possible outliers 
are given by the open circles outside the box.

Is this close?


Thanks


Kenneth E. Nussear                    Phone  775 784-1703
Ecology, Evolution and                  FAX 775 784-1369
Conservation Biology/314             knussear at biodiversity.unr.edu
Reno, Nevada   89557-0013         http://www.brrc.unr.edu/~knussear/



From gerds at fdm.uni-freiburg.de  Mon Feb 24 18:02:03 2003
From: gerds at fdm.uni-freiburg.de (Thomas Gerds)
Date: Mon Feb 24 18:02:03 2003
Subject: [R] printing decimal numbers
Message-ID: <7e8yw5wr4a.fsf@rembrandt.fdm.uni-freiburg.de>

hi,

this is a very basic question -- sorry for posing it:
     
how can i force R to print 0.0001 instead of 1e-04???

.--------------------.
| > 0.0001           |
| [1] 1e-04          |
`--------------------'

i tried the functions format, formatC, ... and changed
options()$digits with no success!

thanks for advice,
tomy

-- 
no signature



From mschwartz at medanalytics.com  Mon Feb 24 18:19:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon Feb 24 18:19:03 2003
Subject: [R] printing decimal numbers
In-Reply-To: <7e8yw5wr4a.fsf@rembrandt.fdm.uni-freiburg.de>
Message-ID: <002701c2dc28$b8ab1ea0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Thomas Gerds
>Sent: Monday, February 24, 2003 11:01 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] printing decimal numbers
>
>
>hi,
>
>this is a very basic question -- sorry for posing it:
>     
>how can i force R to print 0.0001 instead of 1e-04???
>
>.--------------------.
>| > 0.0001           |
>| [1] 1e-04          |
>`--------------------'
>
>i tried the functions format, formatC, ... and changed 
>options()$digits with no success!
>
>thanks for advice,
>tomy


Try:

> formatC(0.0001, format = "f", digits = 4)
[1] "0.0001"

Be sure to use the 'format = "f"' argument.

See ?formatC

HTH,

Marc Schwartz



From andy_liaw at merck.com  Mon Feb 24 18:23:21 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon Feb 24 18:23:21 2003
Subject: [R] bwplot stats question
Message-ID: <3A822319EB35174CA3714066D590DCD534BD02@usrymx25.merck.com>

bwplot() calls boxplot.stats() for the statistics, so look up
?boxplot.stats.

Andy

> -----Original Message-----
> From: Ken Nussear [mailto:knussear at biodiversity.unr.edu]
> Sent: Monday, February 24, 2003 11:44 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] bwplot stats question
> 
> 
> 
> Hi List,
> 
> Just wondering where the documentation exists for the 
> statistics which 
> makeup the bwplot.
> 
> I'm guessing that if R is like similar products that the graph is 
> constructed as
> 
> The median is the filled circle. The box surrounding the 
> filled circle 
> depicts the 25th and 75th quartile. The range of values is 
> given by the 
> dotted lines (?whiskers?) outside of each box, and possible outliers 
> are given by the open circles outside the box.
> 
> Is this close?
> 
> 
> Thanks
> 
> 
> Kenneth E. Nussear                    Phone  775 784-1703
> Ecology, Evolution and                  FAX 775 784-1369
> Conservation Biology/314             knussear at biodiversity.unr.edu
> Reno, Nevada   89557-0013         http://www.brrc.unr.edu/~knussear/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From ripley at stats.ox.ac.uk  Mon Feb 24 18:31:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb 24 18:31:02 2003
Subject: [R] bwplot stats question
In-Reply-To: <2A384989-4817-11D7-B026-0003939B3BBE@biodiversity.unr.edu>
Message-ID: <Pine.LNX.4.44.0302241718230.2155-100000@gannet.stats>

The documentation is

1) the code
2) ?boxplot
3) the standard references on EDA.  I'd have to look up which exactly, but 
my guess would be to look at

Velleman & Hoaglin (1981) ABC of EDA.
Hoaglin, Mosteller, Tukey (1983) Understanding Robust and Exploratory Data 
Analysis.

Some better references should be given on the help page.

On Mon, 24 Feb 2003, Ken Nussear wrote:

> Just wondering where the documentation exists for the statistics which 
> makeup the bwplot.
> 
> I'm guessing that if R is like similar products that the graph is 
> constructed as
> 
> The median is the filled circle. The box surrounding the filled circle 
> depicts the 25th and 75th quartile. The range of values is given by the 
> dotted lines (?whiskers?) outside of each box, and possible outliers 
> are given by the open circles outside the box.
> 
> Is this close?

Yes.  They are I think hinges not quartiles (that's just a small 
difference in definition), and the whiskers extend to the most extreme 
data point less than 1.5*IQR outside the box.  Points beyond the whiskers 
eare plotted separately: they would be unusual for a Normal sample.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jasont at indigoindustrial.co.nz  Mon Feb 24 18:36:23 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon Feb 24 18:36:23 2003
Subject: [R] bwplot stats question
In-Reply-To: <2A384989-4817-11D7-B026-0003939B3BBE@biodiversity.unr.edu>; from knussear@biodiversity.unr.edu on Mon, Feb 24, 2003 at 08:43:56AM -0800
References: <9E71B848-44E9-11D7-8102-0003939B3BBE@biodiversity.unr.edu> <2A384989-4817-11D7-B026-0003939B3BBE@biodiversity.unr.edu>
Message-ID: <20030225063436.A16268@camille.indigoindustrial.co.nz>

On Mon, Feb 24, 2003 at 08:43:56AM -0800, Ken Nussear wrote:
...
> Just wondering where the documentation exists for the statistics which 
> makeup the bwplot.

It goes:  bwplot calls panel.bwplot, which calls boxplot.stats

help(boxplot.stats) 

gives you all you need to know, and more.

> The median is the filled circle. The box surrounding the filled circle 
> depicts the 25th and 75th quartile. The range of values is given by the 
> dotted lines (?whiskers?) outside of each box, and possible outliers 
> are given by the open circles outside the box.

For the whiskers, check out the "coef" argument to boxplot.stats.  For
now, because of the way it's nested, you can only use the default of
1.5 with bwplot.  Sifting through the code, I don't see an easy, clean
fix for this, but I'm not a very good R programmer.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From faraway at umich.edu  Mon Feb 24 18:41:23 2003
From: faraway at umich.edu (Julian Faraway)
Date: Mon Feb 24 18:41:23 2003
Subject: [R] faraway tutorial: cryptic command to newbie
In-Reply-To: <20030223110007.2993.86978.Mailman@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0302241154070.2323-100000@snow.stat.lsa.umich.edu>

That's an unfair criticism. That discussion was never intended as 
a recommendation for how to compute a regression. Of course, SVD or
QR decompositions are the preferred method but many newbies don't want to 
digest all that right from the start. These are just obscure details to 
the beginner.

One of the strengths of R in teaching is that students can directly 
implement the formulae from the theory. This reinforces the connection 
between theory and practice. Implementing the normal equations directly
is a quick early illustration of this connection. Explaining the precise 
details of how to fit a regression model is something that can be 
deferred.

Julian Faraway

>> I am just about working through Faraways excellent tutorial "practical
>> regression and ANOVA using R"
>
>I assume this is a reference to the PDF version available via CRAN. I am
>afraid that is *not* a good discussion of how to do regression, 
especially
>not using R.  That page is seriously misleading: good ways to compute
>regressions are QR decompositions with pivoting (which R uses) or an SVD.
>Solving the normal equations is well known to square the condition 
number,
>and is close to the worse possible way.  (If you must use normal
>equations, do at least centre the columns, and preferably do some 
>scaling.)
>
>> on page 24 he makes the x matrix:
>> x <- cbind(1,gala[,-c(1,2)])
>> 
>> how can I understand this gala[,-c(1,2)])... I couldn't find an
>> explanation of such "c-like" abbreviations anywhere.
>
>Well, it is in all good books (as they say) including `An Introduction to 
>R'. (It's even on page 210 of that book!)
>
>-c(1,2) is (try it)
>
>> -c(1,2)
>[1] -1 -2
>
>so this drops columns 1 and 2.  It then adds in front a column made up of 
>ones, which is usually a sign of someone not really understanding how
>R's linear models work.
>



From ligges at statistik.uni-dortmund.de  Mon Feb 24 18:52:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Feb 24 18:52:03 2003
Subject: [R] Legend in plot: symbol for mean and standard deviation
References: <1046102774.9916.103.camel@PC535>
Message-ID: <3E5A5BA7.1772871B@statistik.uni-dortmund.de>


Marco Kienzle wrote:
> 
> Dear list,
> 
> I am facing the following problem with the legend of a plot that display
> the mean and variance of a measurement y as a function of x, the mean
> being represented by a dot and the variance by a vertical line.

At least for me the latter does not appear to be "that common" ...

> My problem is that I am unable to display the symbol (dot + vertical
> line) in the legend.
> 
> any help is welcome,
> thanks
> marco


Does the following do what you are looking for?

  legend(..., c("y.", "y|"))
or
  legend(..., expression(y[.], y["|"]))


Uwe Ligges



From tlumley at u.washington.edu  Mon Feb 24 18:59:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Feb 24 18:59:03 2003
Subject: [R] Re: Subpopulations in Complex Surveys
In-Reply-To: <10e.1ec5a6e1.2b85538b@aol.com>
Message-ID: <Pine.A41.4.44.0302240952330.20380-100000@homer40.u.washington.edu>

On Wed, 19 Feb 2003 TyagiAnupam at aol.com wrote:

> Hi,
> is there a way to analyze subpopulations (e.g. women over 50, those who
> answered "yes" to a particular question) in a survey using Survey package?
> Other packages (e.g. Stata, SUDAAN) do this with a subpopulation option to
> identify the subpopulation for which the analysis shoud be done. I did not
> see this option in the Survey package. Is there another way to do this?
>

Ok, there is a new version of survey (1.1) that will appear on CRAN over
the next few days that handles subsets as subpopulations in the sense used
by Stata.   There is a function subset.survey.design that makes it easy to
select subsets, eg
    black<-subset(dnhanes, race==1)
but subsets resulting from dropping NAs or from the subset argument to
svyglm or svycoxph are handled the same way.


	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From gerds at fdm.uni-freiburg.de  Mon Feb 24 19:04:04 2003
From: gerds at fdm.uni-freiburg.de (Thomas Gerds)
Date: Mon Feb 24 19:04:04 2003
Subject: [R] printing decimal numbers
In-Reply-To: <002701c2dc28$b8ab1ea0$0201a8c0@MARC> ("Marc Schwartz"'s
 message of "Mon, 24 Feb 2003 11:18:15 -0600")
References: <002701c2dc28$b8ab1ea0$0201a8c0@MARC>
Message-ID: <7e65r9woff.fsf@rembrandt.fdm.uni-freiburg.de>

> formatC(0.0001, format = "f", digits = 4)

works fine for this case. however, i need a way to automatize this,
i.e. to change the default behaviour of print.default!? how could this
be done? the problem with applying the above solution to a number
which is the result of a function, say, is that one has to know
beforehand the number of digits, since

> formatC(1e-04,format="f",digits=5)
[1] "0.00010"

which is also unwanted. 

thanks a lot so far!

tomy


"Marc Schwartz" <mschwartz at medanalytics.com> writes:

>>-----Original Message-----
>>From: r-help-admin at stat.math.ethz.ch 
>>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Thomas Gerds
>>Sent: Monday, February 24, 2003 11:01 AM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] printing decimal numbers
>>
>>
>>hi,
>>
>>this is a very basic question -- sorry for posing it:
>>     
>>how can i force R to print 0.0001 instead of 1e-04???
>>
>>.--------------------.
>>| > 0.0001           |
>>| [1] 1e-04          |
>>`--------------------'
>>
>>i tried the functions format, formatC, ... and changed 
>>options()$digits with no success!
>>
>>thanks for advice,
>>tomy
>
>
> Try:
>
>> formatC(0.0001, format = "f", digits = 4)
> [1] "0.0001"
>
> Be sure to use the 'format = "f"' argument.
>
> See ?formatC
>
> HTH,
>
> Marc Schwartz

-- 
no signature



From jerome at hivnet.ubc.ca  Mon Feb 24 19:10:03 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Mon Feb 24 19:10:03 2003
Subject: [R] fill prob. in legend
In-Reply-To: <F17mRpVgRdc6GoVaE7W000023e1@hotmail.com>
References: <F17mRpVgRdc6GoVaE7W000023e1@hotmail.com>
Message-ID: <200302241813.KAA26657@hivnet.ubc.ca>

I think this does what you want...

Jerome

plot(0,0)
legend(0,0,c("blah","blahblah","blahblahblah","blah..."),
pch=c(21,21,22,22),
col=c("green","red","blue","blue"),
pt.bg=c("white","white","yellow","orange"),cex=2)


On Sunday 23 February 2003 17:29, Jeremy Z Butler wrote:
> Content-Length: 419
> Status: R
> X-Status: N
>
>
>
>
>
>
> Hi,
> I'm trying to construct a legend which has four lines of text and
> associated symbols. The first two symbols need to be normal lines which
> vary only in colour. The second two symbols should have filled boxes. How
> do I suppress the fill boxes in the first two lines?
> J.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 

Jerome Asselin (J?r?me)
Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital
608 - 1081 Burrard Street
Vancouver, British Columbia
CANADA V6Z 1Y6

Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044



From ligges at statistik.uni-dortmund.de  Mon Feb 24 19:34:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Feb 24 19:34:03 2003
Subject: [R] fill prob. in legend
References: <F17mRpVgRdc6GoVaE7W000023e1@hotmail.com> <200302241813.KAA26657@hivnet.ubc.ca>
Message-ID: <3E5A659D.291C4856@statistik.uni-dortmund.de>

Jerome Asselin wrote:
> 
> I think this does what you want...
> 
> Jerome
> 
> plot(0,0)
> legend(0,0,c("blah","blahblah","blahblahblah","blah..."),
> pch=c(21,21,22,22),
> col=c("green","red","blue","blue"),
> pt.bg=c("white","white","yellow","orange"),cex=2)

I don't think so, because Jeremy Butler asked for *lines*.
Unfortunately, the my answer won't be much more helpful (see below).


> On Sunday 23 February 2003 17:29, Jeremy Z Butler wrote:

> > Hi,
> > I'm trying to construct a legend which has four lines of text and
> > associated symbols. The first two symbols need to be normal lines which
> > vary only in colour. The second two symbols should have filled boxes. How
> > do I suppress the fill boxes in the first two lines?
> > J.

Well, you cannot, AFAIK.
You have to construct such a special legend using either two tricky
calls to legend, or add the elements with low level functions like
text() and friends to the plot.
I think a contribution of an improvement of legend() that solves your
problem is welcome.

Uwe Ligges



From ripley at stats.ox.ac.uk  Mon Feb 24 19:40:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb 24 19:40:05 2003
Subject: [R] printing decimal numbers
In-Reply-To: <7e65r9woff.fsf@rembrandt.fdm.uni-freiburg.de>
Message-ID: <Pine.LNX.4.44.0302241830470.2409-100000@gannet.stats>

The way to change the behavour of print.default() is to alter the source 
code, which you can do as R is Open Source but you may find daunting.

I find sprintf() more useful than formatC(), but your mileage may differ.
In either case you can do as the internals of print.default do, and
calculate the format from the characteristics of the set of numbers 
supplied.  Just write your own special-pupose format routine.

On Mon, 24 Feb 2003, Thomas Gerds wrote:

> 
> > formatC(0.0001, format = "f", digits = 4)
> 
> works fine for this case. however, i need a way to automatize this,
> i.e. to change the default behaviour of print.default!? how could this
> be done? the problem with applying the above solution to a number
> which is the result of a function, say, is that one has to know
> beforehand the number of digits, since
> 
> > formatC(1e-04,format="f",digits=5)
> [1] "0.00010"
> 
> which is also unwanted. 
> 
> thanks a lot so far!
> 
> tomy
> 
> 
> "Marc Schwartz" <mschwartz at medanalytics.com> writes:
> 
> >>-----Original Message-----
> >>From: r-help-admin at stat.math.ethz.ch 
> >>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Thomas Gerds
> >>Sent: Monday, February 24, 2003 11:01 AM
> >>To: r-help at stat.math.ethz.ch
> >>Subject: [R] printing decimal numbers
> >>
> >>
> >>hi,
> >>
> >>this is a very basic question -- sorry for posing it:
> >>     
> >>how can i force R to print 0.0001 instead of 1e-04???
> >>
> >>.--------------------.
> >>| > 0.0001           |
> >>| [1] 1e-04          |
> >>`--------------------'
> >>
> >>i tried the functions format, formatC, ... and changed 
> >>options()$digits with no success!
> >>
> >>thanks for advice,
> >>tomy
> >
> >
> > Try:
> >
> >> formatC(0.0001, format = "f", digits = 4)
> > [1] "0.0001"
> >
> > Be sure to use the 'format = "f"' argument.
> >
> > See ?formatC
> >
> > HTH,
> >
> > Marc Schwartz
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jerome at hivnet.ubc.ca  Mon Feb 24 19:49:03 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Mon Feb 24 19:49:03 2003
Subject: [R] fill prob. in legend
In-Reply-To: <3E5A659D.291C4856@statistik.uni-dortmund.de>
References: <F17mRpVgRdc6GoVaE7W000023e1@hotmail.com> <200302241813.KAA26657@hivnet.ubc.ca> <3E5A659D.291C4856@statistik.uni-dortmund.de>
Message-ID: <200302241849.KAA28405@hivnet.ubc.ca>

Ok... All we need is an "blank" symbol (such as pch=30(?)).

Now try again...

Jerome

plot(0,0)
legend(0,0,c("blah","blahblah","blahblahblah","blah..."),
pch=c(30,30,22,22),
col=c("green","red","blue","blue"),
lty=c(1,1,2,2),
pt.bg=c("white","white","yellow","orange"),cex=2)

On Monday 24 February 2003 10:34, Uwe Ligges wrote:
> Content-Length: 1182
> Status: R
> X-Status: N
>
> Jerome Asselin wrote:
> > I think this does what you want...
> >
> > Jerome
> >
> > plot(0,0)
> > legend(0,0,c("blah","blahblah","blahblahblah","blah..."),
> > pch=c(21,21,22,22),
> > col=c("green","red","blue","blue"),
> > pt.bg=c("white","white","yellow","orange"),cex=2)
>
> I don't think so, because Jeremy Butler asked for *lines*.
> Unfortunately, the my answer won't be much more helpful (see below).
>
> > On Sunday 23 February 2003 17:29, Jeremy Z Butler wrote:
> > > Hi,
> > > I'm trying to construct a legend which has four lines of text and
> > > associated symbols. The first two symbols need to be normal lines which
> > > vary only in colour. The second two symbols should have filled boxes.
> > > How do I suppress the fill boxes in the first two lines?
> > > J.
>
> Well, you cannot, AFAIK.
> You have to construct such a special legend using either two tricky
> calls to legend, or add the elements with low level functions like
> text() and friends to the plot.
> I think a contribution of an improvement of legend() that solves your
> problem is welcome.
>
> Uwe Ligges
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 

Jerome Asselin (J?r?me)
Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital
608 - 1081 Burrard Street
Vancouver, British Columbia
CANADA V6Z 1Y6

Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044



From chong at stat.purdue.edu  Mon Feb 24 19:53:03 2003
From: chong at stat.purdue.edu (Chong Gu)
Date: Mon Feb 24 19:53:03 2003
Subject: [R] faraway tutorial: cryptic command to newbie 
In-Reply-To: Your message of "Mon, 24 Feb 2003 12:40:24 EST."
             <Pine.LNX.4.44.0302241154070.2323-100000@snow.stat.lsa.umich.edu> 
Message-ID: <200302241850.h1OIoWP1039598@odds.stat.purdue.edu>

Not only it's unfair criticism, it's probably also imprecise
information.

For a detailed discussion of the precisions of regression estimates
through QR-decomposition and normal equations, one may consult Golub
and Van Loan's book on Matrix Computation (1989, Section 5.3.9 on page
230).  QR takes twice as much computation, requires more memory, but
does NOT necessarily provide better precision.

The above said, I am not questioning the adequacy of the QR approach
to regression calculation as implemented in R.

> 
> That's an unfair criticism. That discussion was never intended as 
> a recommendation for how to compute a regression. Of course, SVD or
> QR decompositions are the preferred method but many newbies don't want to 
> digest all that right from the start. These are just obscure details to 
> the beginner.
> 
> One of the strengths of R in teaching is that students can directly 
> implement the formulae from the theory. This reinforces the connection 
> between theory and practice. Implementing the normal equations directly
> is a quick early illustration of this connection. Explaining the precise 
> details of how to fit a regression model is something that can be 
> deferred.
> 
> Julian Faraway
> 
> >> I am just about working through Faraways excellent tutorial "practical
> >> regression and ANOVA using R"
> >
> >I assume this is a reference to the PDF version available via CRAN. I am
> >afraid that is *not* a good discussion of how to do regression, 
> especially
> >not using R.  That page is seriously misleading: good ways to compute
> >regressions are QR decompositions with pivoting (which R uses) or an SVD.
> >Solving the normal equations is well known to square the condition 
> number,
> >and is close to the worse possible way.  (If you must use normal
> >equations, do at least centre the columns, and preferably do some 
> >scaling.)
> >
> >> on page 24 he makes the x matrix:
> >> x <- cbind(1,gala[,-c(1,2)])
> >> 
> >> how can I understand this gala[,-c(1,2)])... I couldn't find an
> >> explanation of such "c-like" abbreviations anywhere.
> >
> >Well, it is in all good books (as they say) including `An Introduction to 
> >R'. (It's even on page 210 of that book!)
> >
> >-c(1,2) is (try it)
> >
> >> -c(1,2)
> >[1] -1 -2
> >
> >so this drops columns 1 and 2.  It then adds in front a column made up of 
> >ones, which is usually a sign of someone not really understanding how
> >R's linear models work.
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jbond at arg.org  Mon Feb 24 20:11:21 2003
From: jbond at arg.org (Jason Bond)
Date: Mon Feb 24 20:11:21 2003
Subject: [R] exact range of axes in plots
Message-ID: <5.1.0.14.2.20030224110455.01df12f0@arg.org>

Hello.  I was wondering how one can find the exact values of the range of 
an axis within a plot.  In xlispstat it was (send plot :range 0).  Thanks much,

   Jason



From jerome at hivnet.ubc.ca  Mon Feb 24 20:18:03 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Mon Feb 24 20:18:03 2003
Subject: [R] exact range of axes in plots
In-Reply-To: <5.1.0.14.2.20030224110455.01df12f0@arg.org>
References: <5.1.0.14.2.20030224110455.01df12f0@arg.org>
Message-ID: <200302241921.LAA29978@hivnet.ubc.ca>

Hope this helps.

Jerome

> plot(0:1,0:1)
> par()$usr
[1] -0.04  1.04 -0.04  1.04

On Monday 24 February 2003 11:06, Jason Bond wrote:
> Hello.  I was wondering how one can find the exact values of the range of
> an axis within a plot.  In xlispstat it was (send plot :range 0).  Thanks
> much,
>
>    Jason
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From andy_liaw at merck.com  Mon Feb 24 20:23:23 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon Feb 24 20:23:23 2003
Subject: [R] faraway tutorial: cryptic command to newbie
Message-ID: <3A822319EB35174CA3714066D590DCD534BD06@usrymx25.merck.com>

I'm no expert in these matters, but I'll toss in my $0.02 anyway.

My recollection from reading Golub & Van Loan a few years ago is that
there's quite a bit of controversy as to the "best" approach to least
squares.  Just recently I've read Monahan's "Numerical Methods in
Statistics", which has three relevant chapters (including one titled
"Regression Computations").  In it, several approaches were presented:
QR-Householder, QR-Givens, SVD, MCD, sweep, etc.  The conclusion drawn was
that no single method is the best for all problems, and the task of writing
a regression routine is best avoided unless the workhorse routines in stat
packages are not satisfactory (in terms of speed/storage requirement/etc.).

My impression is that, with the glaring exception of SAS (which uses sweep,
if I'm not mistaken), most stat packages use QR, as a good compromise
between stability and speed.

Andy

> -----Original Message-----
> From: Chong Gu [mailto:chong at stat.purdue.edu]
> Sent: Monday, February 24, 2003 1:51 PM
> To: Julian Faraway
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] faraway tutorial: cryptic command to newbie
> 
> 
> 
> Not only it's unfair criticism, it's probably also imprecise
> information.
> 
> For a detailed discussion of the precisions of regression estimates
> through QR-decomposition and normal equations, one may consult Golub
> and Van Loan's book on Matrix Computation (1989, Section 5.3.9 on page
> 230).  QR takes twice as much computation, requires more memory, but
> does NOT necessarily provide better precision.
> 
> The above said, I am not questioning the adequacy of the QR approach
> to regression calculation as implemented in R.
> 
> > 
> > That's an unfair criticism. That discussion was never intended as 
> > a recommendation for how to compute a regression. Of course, SVD or
> > QR decompositions are the preferred method but many newbies 
> don't want to 
> > digest all that right from the start. These are just 
> obscure details to 
> > the beginner.
> > 
> > One of the strengths of R in teaching is that students can directly 
> > implement the formulae from the theory. This reinforces the 
> connection 
> > between theory and practice. Implementing the normal 
> equations directly
> > is a quick early illustration of this connection. 
> Explaining the precise 
> > details of how to fit a regression model is something that can be 
> > deferred.
> > 
> > Julian Faraway
> > 
> > >> I am just about working through Faraways excellent 
> tutorial "practical
> > >> regression and ANOVA using R"
> > >
> > >I assume this is a reference to the PDF version available 
> via CRAN. I am
> > >afraid that is *not* a good discussion of how to do regression, 
> > especially
> > >not using R.  That page is seriously misleading: good ways 
> to compute
> > >regressions are QR decompositions with pivoting (which R 
> uses) or an SVD.
> > >Solving the normal equations is well known to square the condition 
> > number,
> > >and is close to the worse possible way.  (If you must use normal
> > >equations, do at least centre the columns, and preferably do some 
> > >scaling.)
> > >
> > >> on page 24 he makes the x matrix:
> > >> x <- cbind(1,gala[,-c(1,2)])
> > >> 
> > >> how can I understand this gala[,-c(1,2)])... I couldn't find an
> > >> explanation of such "c-like" abbreviations anywhere.
> > >
> > >Well, it is in all good books (as they say) including `An 
> Introduction to 
> > >R'. (It's even on page 210 of that book!)
> > >
> > >-c(1,2) is (try it)
> > >
> > >> -c(1,2)
> > >[1] -1 -2
> > >
> > >so this drops columns 1 and 2.  It then adds in front a 
> column made up of 
> > >ones, which is usually a sign of someone not really 
> understanding how
> > >R's linear models work.
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From ihaka at stat.auckland.ac.nz  Mon Feb 24 20:28:03 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Mon Feb 24 20:28:03 2003
Subject: [R] exact range of axes in plots
References: <5.1.0.14.2.20030224110455.01df12f0@arg.org>
Message-ID: <3E5A70AC.5020801@stat.auckland.ac.nz>

Jason Bond wrote:
> Hello.  I was wondering how one can find the exact values of the range 
> of an axis within a plot.  In xlispstat it was (send plot :range 0).  
> Thanks much,

After you have created the plot try par("usr").  This gives 4 values:
xmin, xmax, ymin, ymax.

 > plot(1:10, 1:10)
 > par("usr")
[1]  0.64 10.36  0.64 10.36


-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand



From Ko-Kang at xtra.co.nz  Mon Feb 24 20:32:09 2003
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Mon Feb 24 20:32:09 2003
Subject: [R] exact range of axes in plots
References: <5.1.0.14.2.20030224110455.01df12f0@arg.org>
Message-ID: <007b01c2dc39$ecc84670$352558db@kwan022>

Hi,

----- Original Message -----
From: "Jason Bond" <jbond at arg.org>
To: <R-help at stat.math.ethz.ch>
Sent: Tuesday, February 25, 2003 8:06 AM
Subject: [R] exact range of axes in plots


> Hello.  I was wondering how one can find the exact values of the range of
> an axis within a plot.  In xlispstat it was (send plot :range 0).  Thanks
much,

Is xlim and ylim in the plot() what you want?  For example:
    > x <- rnorm(100)
    > plot(x)
    > plot(x, xlim = c(20, 80), ylim = c(-2, 2))
the second plot() will restrict the range of x-axis to be between 20 and 80,
y-axis between -2, 2.

Cheers,

Kevin



From mschwartz at medanalytics.com  Mon Feb 24 20:36:15 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon Feb 24 20:36:15 2003
Subject: [R] exact range of axes in plots
In-Reply-To: <5.1.0.14.2.20030224110455.01df12f0@arg.org>
Message-ID: <000801c2dc3a$30209210$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jason Bond
>Sent: Monday, February 24, 2003 1:06 PM
>To: R-help at stat.math.ethz.ch
>Subject: [R] exact range of axes in plots
>
>
>Hello.  I was wondering how one can find the exact values of 
>the range of 
>an axis within a plot.  In xlispstat it was (send plot :range 
>0).  Thanks much,
>
>   Jason


See ?par

Specifically par("usr"), which will give you the actual range of the x
and y axes.

par("xaxp") or par("yaxp") will also give you information on the axis
tick marks.

Be aware that the above pars are altered when log scales are used, so
be sure to read the help file carefully in that situation.

If you want to SET the axis ranges explicitly, most of the plotting
functions take the arguments 'xlim' and 'ylim', which can be used for
that purpose.

HTH,

Marc Schwartz



From jfox at mcmaster.ca  Mon Feb 24 20:41:15 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon Feb 24 20:41:15 2003
Subject: [R] exact range of axes in plots
In-Reply-To: <5.1.0.14.2.20030224110455.01df12f0@arg.org>
Message-ID: <5.0.2.1.0.20030224142721.00af6000@mcmail.cis.mcmaster.ca>

Dear Jason,

par("usr") will give you what you want.

John

At 11:06 AM 2/24/2003 -0800, Jason Bond wrote:
>Hello.  I was wondering how one can find the exact values of the range of 
>an axis within a plot.  In xlispstat it was (send plot :range 0).  Thanks much,
>
>   Jason
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From jbond at arg.org  Mon Feb 24 20:55:04 2003
From: jbond at arg.org (Jason Bond)
Date: Mon Feb 24 20:55:04 2003
Subject: [R] creating a plot legend
Message-ID: <5.1.0.14.2.20030224114548.01df7ec0@arg.org>

Thanks so much to all for their help.  I was wondering if there was an easy 
way to create legends in R plots.  For example, if I am plotting lines for 
subjects in a longitudinal design of the outcome by time for two different 
treatments, where the individual for treatment 1 are plotted in one color, 
and the others are plotted in another.  What I would like to do is, for 
example, have a little legend in the bottom right corner which puts the 
line color next to the treatment name.  I guess I could start messing with 
magins and try to draw text at given coordinates within the margin, but 
thought I might ask if anyone else has had success with a simpler 
solution.  Thanks so much again,

   Jason



From tlumley at u.washington.edu  Mon Feb 24 21:27:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Feb 24 21:27:03 2003
Subject: [R] creating a plot legend
In-Reply-To: <5.1.0.14.2.20030224114548.01df7ec0@arg.org>
Message-ID: <Pine.A41.4.44.0302241224110.85506-100000@homer09.u.washington.edu>

On Mon, 24 Feb 2003, Jason Bond wrote:

> Thanks so much to all for their help.  I was wondering if there was an easy
> way to create legends in R plots.  For example, if I am plotting lines for
> subjects in a longitudinal design of the outcome by time for two different
> treatments, where the individual for treatment 1 are plotted in one color,
> and the others are plotted in another.  What I would like to do is, for
> example, have a little legend in the bottom right corner which puts the
> line color next to the treatment name.  I guess I could start messing with
> magins and try to draw text at given coordinates within the margin, but
> thought I might ask if anyone else has had success with a simpler
> solution.  Thanks so much again,
>

The legend() function.

As  a meta-answer I would also note that help.search("legend") would have
told you this.

	-thomas



From giles.heywood at btinternet.com  Mon Feb 24 21:49:02 2003
From: giles.heywood at btinternet.com (Giles Heywood)
Date: Mon Feb 24 21:49:02 2003
Subject: [R] Test suites
Message-ID: <03bc01c2dc46$089c5600$807420d9@pr8x0>

I have a collection of functions, class definitions and methods which I
would like to test systematically for their correctness after changes to
their code, and also after major R revisions.  I believe that the correct
term for these systematic tests (as opposed to more informal tests) is a
'test suite'.  Does anyone [apart from Pat Burns :-) ] have code, or
templates, or specific suggestions for the best approach to constructing
test suites?

Thanks in advance

Giles Heywood



From spencer.graves at pdf.com  Mon Feb 24 22:00:04 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon Feb 24 22:00:04 2003
Subject: [R] Test suites
References: <03bc01c2dc46$089c5600$807420d9@pr8x0>
Message-ID: <3E5A878A.3010709@pdf.com>

"all.equal" described in Venables and Ripley (MASS, 4th ed., p. 49, and 
S Programming, p. 21) is useful.  (The index entry in "S Programming is 
off by 1 page.)

Hope this helps.
Spencer Graves

Giles Heywood wrote:
> I have a collection of functions, class definitions and methods which I
> would like to test systematically for their correctness after changes to
> their code, and also after major R revisions.  I believe that the correct
> term for these systematic tests (as opposed to more informal tests) is a
> 'test suite'.  Does anyone [apart from Pat Burns :-) ] have code, or
> templates, or specific suggestions for the best approach to constructing
> test suites?
> 
> Thanks in advance
> 
> Giles Heywood
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From andy_liaw at merck.com  Mon Feb 24 22:06:26 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon Feb 24 22:06:26 2003
Subject: [R] Test suites
Message-ID: <3A822319EB35174CA3714066D590DCD534BD0A@usrymx25.merck.com>

Perhaps the best way to do this is to make up an R package.  The "Writing R
Extensions" manual has discussions on how to set up test codes.  There are
also examples in some packages that shipped with R itself.  Look in the
`check' subdirectory of packages under .../R-1.6.2/src/library.

Andy

> -----Original Message-----
> From: Giles Heywood [mailto:giles.heywood at btinternet.com]
> Sent: Monday, February 24, 2003 3:48 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Test suites
> 
> 
> I have a collection of functions, class definitions and 
> methods which I
> would like to test systematically for their correctness after 
> changes to
> their code, and also after major R revisions.  I believe that 
> the correct
> term for these systematic tests (as opposed to more informal 
> tests) is a
> 'test suite'.  Does anyone [apart from Pat Burns :-) ] have code, or
> templates, or specific suggestions for the best approach to 
> constructing
> test suites?
> 
> Thanks in advance
> 
> Giles Heywood
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From ripley at stats.ox.ac.uk  Mon Feb 24 22:18:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Feb 24 22:18:03 2003
Subject: [R] Test suites
In-Reply-To: <03bc01c2dc46$089c5600$807420d9@pr8x0>
Message-ID: <Pine.LNX.4.44.0302242114090.6099-100000@gannet.stats>

Well, R itself has lots of tests in its test suite (see directory tests 
in the sources) as well as a mechanism for running test suites in 
packages: recommended packages nlme and rpart have them, for example.

So I suggest just adding a test suite to your package (this *is* a 
package, I hope) and running R CMD check on it.  It's documented in
`Writing R Extensions'.


On Mon, 24 Feb 2003, Giles Heywood wrote:

> I have a collection of functions, class definitions and methods which I
> would like to test systematically for their correctness after changes to
> their code, and also after major R revisions.  I believe that the correct
> term for these systematic tests (as opposed to more informal tests) is a
> 'test suite'.  Does anyone [apart from Pat Burns :-) ] have code, or
> templates, or specific suggestions for the best approach to constructing
> test suites?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jbond at arg.org  Tue Feb 25 00:17:02 2003
From: jbond at arg.org (Jason Bond)
Date: Tue Feb 25 00:17:02 2003
Subject: [R] Forcing plots to "adjust-to-data"
Message-ID: <5.1.0.14.2.20030224150940.02a88d30@arg.org>

Hello.  In messing around with some of the graphical parameters using the 
par() function (setting margins for example), I've noticed that the plot 
doesn't always immediately respond to changes...for example when lines are 
added, if they are out of the range you need to physically find out what 
the new max range has to be.  Is there a companion function in R to the 
xlispstat function :adjust-to-data which dynamically forces the plot to do 
just that?  Thanks much again,

   Jason



From jim.lemon at uts.edu.au  Tue Feb 25 00:26:04 2003
From: jim.lemon at uts.edu.au (Jim Lemon)
Date: Tue Feb 25 00:26:04 2003
Subject: [R] fill prob. in legend
Message-ID: <0HAU00DMD6C39F@mail.uts.edu.au>

Jeremy Z. Butler wrote:
>
> Hi,
> I'm trying to construct a legend which has four lines of text and
>  associated symbols. The first two symbols need to be normal lines which
>  vary only in colour. The second two symbols should have filled boxes. How
>  do I suppress the fill boxes in the first two lines?
> J.

As far as I can see, it would be really hard to suppress the fill boxes. 
However, it isn't too hard to overwrite the point/line indicators. First, do 
the legend like this:

legendinfo<-legend(...,lty=1,col=c(...))

This will produce a legend with all different colored lines. Then call the 
function below like this:

add.legend.bars(legendinfo,which=c(3,4),border="black",col=c(2,3))

The function below seems to work for a linear or log axis plot. Hope it helps.

Jim

add.legend.bars<-function(legend.info,which,border,col) {
 if(!missing(legend.info) &&
    !missing(which) &&
    !missing(border) &&
    !missing(col)) {
  nelem<-length(legend.info$text$x)
  if(par("ylog")) 
   barheight<-(10^legend.info$text$y[1]-10^legend.info$text$y[2])/2
  else
   barheight<-(legend.info$text$y[1]-legend.info$text$y[2])/2
  if(par("xlog"))
   barwidth<-(10^legend.info$text$x[1]-10^legend.info$rect$left)/2
  else
   barwidth<-(legend.info$text$x[1]-legend.info$rect$left)/2
  if(par("xlog"))
   xleft<-10^legend.info$rect$left+barwidth/2
  else
   xleft<-legend.info$rect$left+barwidth/2
  xright<-xleft+barwidth
  if(par("ylog"))
   ytop<-(10^legend.info$text$y+barheight/2)[which]
  else
   ytop<-(legend.info$text$y+barheight/2)[which]
  ybottom<-ytop-barheight
  rect(xleft,ybottom,xright,ytop,border=border,col=col)
 }
 else cat("Usage: add.legend.bars(legend.info,which,border,col)\n")
}



UTS CRICOS Provider Code:  00099F

DISCLAIMER\ ==================================================== ... [[dropped]]



From mschwartz at medanalytics.com  Tue Feb 25 00:34:02 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue Feb 25 00:34:02 2003
Subject: [R] Forcing plots to "adjust-to-data"
In-Reply-To: <5.1.0.14.2.20030224150940.02a88d30@arg.org>
Message-ID: <004701c2dc5d$22cbdc50$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jason Bond
>Sent: Monday, February 24, 2003 5:12 PM
>To: R-help at stat.math.ethz.ch
>Subject: [R] Forcing plots to "adjust-to-data"
>
>
>Hello.  In messing around with some of the graphical 
>parameters using the 
>par() function (setting margins for example), I've noticed 
>that the plot 
>doesn't always immediately respond to changes...for example 
>when lines are 
>added, if they are out of the range you need to physically 
>find out what 
>the new max range has to be.  Is there a companion function in 
>R to the 
>xlispstat function :adjust-to-data which dynamically forces 
>the plot to do 
>just that?  Thanks much again,
>
>   Jason

In general, once you actually plot the graphic in a device window, you
would need to re-plot the graphic if you need to alter the dimensional
attributes of the plot.  You can add new objects to an existing plot
quite easily, but within the pre-existing coordinate system or margin
areas. 

Thus, if you need to adjust the x or y axis ranges for example, you
would need to re-draw the graphic.

HTH,

Marc Schwartz



From baiyan at ece.ogi.edu  Tue Feb 25 05:35:03 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Tue Feb 25 05:35:03 2003
Subject: [R] question on - build R as a shared library
In-Reply-To: <20030225042703.27231.78978.Mailman@hypatia.math.ethz.ch>
Message-ID: <Pine.GSO.4.44.0302242028221.15334-100000@ece.ogi.edu>

Please help me.

I used '--enable-R-shlib' as the argument for 'configure'. After the
installation, I want to check whether R is built as a shared library since
I need to assure this for installing other packages like SJava. Could
anybody tell me how to get this information? where is libR.so?

Thanks in advance.

Yan



From edd at debian.org  Tue Feb 25 05:44:15 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue Feb 25 05:44:15 2003
Subject: [R] question on - build R as a shared library
In-Reply-To: <Pine.GSO.4.44.0302242028221.15334-100000@ece.ogi.edu>; from baiyan@ece.ogi.edu on Mon, Feb 24, 2003 at 08:34:24PM -0800
References: <20030225042703.27231.78978.Mailman@hypatia.math.ethz.ch> <Pine.GSO.4.44.0302242028221.15334-100000@ece.ogi.edu>
Message-ID: <20030224224207.A21681@debian.org>

On Mon, Feb 24, 2003 at 08:34:24PM -0800, Bai Yan wrote:
> I used '--enable-R-shlib' as the argument for 'configure'. After the
> installation, I want to check whether R is built as a shared library since
> I need to assure this for installing other packages like SJava. Could
> anybody tell me how to get this information? where is libR.so?

In $prefix/lib/R/bin/  e.g. /usr/local/lib/R/bin unless --prefix was changed.

Dirk

-- 
Three out of two people have difficulties with fractions.



From baiyan at ece.ogi.edu  Tue Feb 25 05:53:02 2003
From: baiyan at ece.ogi.edu (Bai Yan)
Date: Tue Feb 25 05:53:02 2003
Subject: [R] question on - build R as a shared library
In-Reply-To: <20030224224207.A21681@debian.org>
Message-ID: <Pine.GSO.4.44.0302242050340.15334-100000@ece.ogi.edu>

Hi Dirk, thank you for the prompt reply.
I found libR.so. But how can I know whether it is build as shared or not.


On Mon, 24 Feb 2003, Dirk Eddelbuettel wrote:

> On Mon, Feb 24, 2003 at 08:34:24PM -0800, Bai Yan wrote:
> > I used '--enable-R-shlib' as the argument for 'configure'. After the
> > installation, I want to check whether R is built as a shared library since
> > I need to assure this for installing other packages like SJava. Could
> > anybody tell me how to get this information? where is libR.so?
>
> In $prefix/lib/R/bin/  e.g. /usr/local/lib/R/bin unless --prefix was changed.
>
> Dirk
>
> --
> Three out of two people have difficulties with fractions.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From petr.pikal at precheza.cz  Tue Feb 25 08:13:03 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue Feb 25 08:13:03 2003
Subject: [R] how to chage values in data frame to NA iside a function
Message-ID: <3E5B2574.20993.1EFB8F@localhost>

Thank you for your answers. It works OK but my real question is 
why my  function behaves differently used on vector and data 
frame (or matrix or list).  

I attached a full version below with some foo data, but basically 
the function  returns the correct index if applied correctly on any 
type (list, data frame, matrix,  vector) but it changes values of 
operand only if operand is a vector. 

Why please? 

On 21 Feb 2003 at 10:23, Spencer Graves wrote: 

> Thomas Blackwell's solution will also work if dropout(df$y) returns a 
> logical vector of length = length(df$y).  This also allows more 
> general conditions, e.g., 
>  
>    select1 <- df[,1] > 0 
>    select2 <- (select1) & (dr[,2] > 0) 
>  
>    df[select2, "y"] <- NA	 
>  
> Spencer Graves 
>  
> Thomas W Blackwell wrote: 
> > Petr  - 
> >  
> > Does your function return "index" or return "y" after modifying y ? 
> > In the email, it looks as though it returns "index".  If so, the 
> > following should work: 
> >  
> >  
> >>df$y[ dropout(df$y) ] <- NA 
> >  
> >  
> > -  tom blackwell  -  u michigan medical school  -  ann arbor  - 
> >  
> >  
> >  
> > On Fri, 21 Feb 2003, Petr Pikal wrote: 
> >  
> >  
> >>Dear all 
> >> 
> >>I have a function in which I would like to change some values to NA 
> >>according to some condition. 
> >> 
> >>dropout<-function(y, nahr=FALSE,...) { 
> >> 
> >><some stuff for computing an index> 
> >> 
> >>if (nahr) y[index]<<-NA 
> >>invisible(index) 
> >> 
> >>} 
> >> 
> >>in case y is a vector all works OK but if it is a part of data frame 
> >>by calling 
> >> 
> >>dropout(df$y) or dropout(df[,number]) no change is done. 
> >> 
> >>Please can you help me what is wrong with my code? 
> >> 
> >>By the way 
> >> 
> >>idx<-dropout(df$y) 
> >>df$y[idx]<-NA 
> >> 
> >>works OK 
> >> 
> >>Thanks a lot beforehand 
> >> 
> >>Best regards. 
> >> 
> >>Petr Pikal 


#foo data 

x<-seq(0,100,.1) 
y<-sin(x)+rnorm(length(x),mean=0,sd=1) 
y1<-y-c(rep(0,200),exp(x[20:50]),rep(0,770)) 
y<-y1+50 
y<-y*(y>0) 
y[600:700]<-0 
df<-data.frame(y) 
mat<-as.matrix(df) 
mylist<-as.list(df) 

#vector 

plot(x,y) 
ddd<-dropout(y) 
points(x[ddd],y[ddd],col=2) 
ddd<-dropout(y,nahr=T) 
plot(x,y) 
rm(ddd) 

#data frame 

plot(x,df$y) 
ddd<-dropout(df$y) 
points(x[ddd],df$y[ddd],col=2) 
ddd<-dropout(df$y,nahr=T) 
plot(x,df$y) 
rm(ddd) 

#matrix 

plot(x,mat[,1]) 
ddd<-dropout(mat[,1]) 
points(x[ddd],mat[ddd,1],col=2) 
ddd<-dropout(mat[,1],nahr=T) 
plot(x,mat[,1]) 
rm(ddd) 

#list 

plot(x,mylist$y) 
ddd<-dropout(df$y) 
points(x[ddd],mylist$y[ddd],col=2) 
ddd<-dropout(mylist$y,nahr=T) 
plot(x,mylist$y) 

#this is full function 

dropout<-function(y,span=21, mez=NULL, p=0.99995, 
nahradit=FALSE, ...) { 

### this part is just computing the logical index vector with length 
= length(y)  ### and TRUE values where dropout occurs 

#kontrola licheho spanu 
if(span/2-span%/%2<.4|span<2) span<-
ceiling(span+floor(1/span)+.1) 

n<-length(y) 
s<-span%/%2 


idx1<-y==0 
prumer<-median(y[!idx1],na.rm=T) 

if (is.null(mez))   
{ 
mez<-mad(y[!idx1],na.rm=T) 
dm<-prumer-mez*qnorm(p) 
hm<-prumer+mez*qnorm(p) 
} else { 

dm<-prumer-mez 
hm<-prumer+mez 
} 


idx2<-y<dm 
idx3<-y>hm 

idx<-as.logical(idx1+idx2+idx3) 
z <- embed(idx,span) 
rowSums(z) 
length(rowSums(z)) 
sumy<-rowSums(z)>0 
index<-c(rep(sumy[1],s),sumy,rep(sumy[n-span+1],s)) 

### index is a returned logical vector and it is OK 

if (nahradit) y[index]<<-NA 
### this is the ghastly line which does not work as I expected :-( 

invisible(index) 

} 


Thank you 

Best regardsPetr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From ripley at stats.ox.ac.uk  Tue Feb 25 08:58:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb 25 08:58:03 2003
Subject: [R] how to chage values in data frame to NA iside a function
In-Reply-To: <3E5B2574.20993.1EFB8F@localhost>
Message-ID: <Pine.LNX.4.44.0302250742020.9982-100000@gannet.stats>

You are mis-using <<-.  I don't know what you think it does, so please
look it up.  Using <<- in R/S programming is normally a sign of incorrect
thinking (but not quite always).  (Also, it behaves differently in R and
in S which can be a cause of confusion to those who know only one of the
definitions.)

On Tue, 25 Feb 2003, Petr Pikal wrote:

> Thank you for your answers. It works OK but my real question is 
> why my  function behaves differently used on vector and data 
> frame (or matrix or list).  

> I attached a full version below with some foo data, but basically 
> the function  returns the correct index if applied correctly on any 
> type (list, data frame, matrix,  vector) but it changes values of 
> operand only if operand is a vector. 

Not so.  It always alters an object called `y'.  It just so happens that
your vector argument was called `y' and the other cases you tried were
not.
 
> Why please? 

(Because that is what you asked it to do ....)

I can see a way to do what I think is your intention (to change the
object which was passed as the y argument from the parent environment), 
but it is convoluted and against the spirit of a functional language, so I 
won't describe it.

> On 21 Feb 2003 at 10:23, Spencer Graves wrote: 
> 
> > Thomas Blackwell's solution will also work if dropout(df$y) returns a 
> > logical vector of length = length(df$y).  This also allows more 
> > general conditions, e.g., 
> >  
> >    select1 <- df[,1] > 0 
> >    select2 <- (select1) & (dr[,2] > 0) 
> >  
> >    df[select2, "y"] <- NA	 
> >  
> > Spencer Graves 
> >  
> > Thomas W Blackwell wrote: 
> > > Petr  - 
> > >  
> > > Does your function return "index" or return "y" after modifying y ? 
> > > In the email, it looks as though it returns "index".  If so, the 
> > > following should work: 
> > >  
> > >  
> > >>df$y[ dropout(df$y) ] <- NA 
> > >  
> > >  
> > > -  tom blackwell  -  u michigan medical school  -  ann arbor  - 
> > >  
> > >  
> > >  
> > > On Fri, 21 Feb 2003, Petr Pikal wrote: 
> > >  
> > >  
> > >>Dear all 
> > >> 
> > >>I have a function in which I would like to change some values to NA 
> > >>according to some condition. 
> > >> 
> > >>dropout<-function(y, nahr=FALSE,...) { 
> > >> 
> > >><some stuff for computing an index> 
> > >> 
> > >>if (nahr) y[index]<<-NA 
> > >>invisible(index) 
> > >> 
> > >>} 
> > >> 
> > >>in case y is a vector all works OK but if it is a part of data frame 
> > >>by calling 
> > >> 
> > >>dropout(df$y) or dropout(df[,number]) no change is done. 
> > >> 
> > >>Please can you help me what is wrong with my code? 
> > >> 
> > >>By the way 
> > >> 
> > >>idx<-dropout(df$y) 
> > >>df$y[idx]<-NA 
> > >> 
> > >>works OK 
> > >> 
> > >>Thanks a lot beforehand 
> > >> 
> > >>Best regards. 
> > >> 
> > >>Petr Pikal 
> 
> 
> #foo data 
> 
> x<-seq(0,100,.1) 
> y<-sin(x)+rnorm(length(x),mean=0,sd=1) 
> y1<-y-c(rep(0,200),exp(x[20:50]),rep(0,770)) 
> y<-y1+50 
> y<-y*(y>0) 
> y[600:700]<-0 
> df<-data.frame(y) 
> mat<-as.matrix(df) 
> mylist<-as.list(df) 
> 
> #vector 
> 
> plot(x,y) 
> ddd<-dropout(y) 
> points(x[ddd],y[ddd],col=2) 
> ddd<-dropout(y,nahr=T) 
> plot(x,y) 
> rm(ddd) 
> 
> #data frame 
> 
> plot(x,df$y) 
> ddd<-dropout(df$y) 
> points(x[ddd],df$y[ddd],col=2) 
> ddd<-dropout(df$y,nahr=T) 
> plot(x,df$y) 
> rm(ddd) 
> 
> #matrix 
> 
> plot(x,mat[,1]) 
> ddd<-dropout(mat[,1]) 
> points(x[ddd],mat[ddd,1],col=2) 
> ddd<-dropout(mat[,1],nahr=T) 
> plot(x,mat[,1]) 
> rm(ddd) 
> 
> #list 
> 
> plot(x,mylist$y) 
> ddd<-dropout(df$y) 
> points(x[ddd],mylist$y[ddd],col=2) 
> ddd<-dropout(mylist$y,nahr=T) 
> plot(x,mylist$y) 
> 
> #this is full function 
> 
> dropout<-function(y,span=21, mez=NULL, p=0.99995, 
> nahradit=FALSE, ...) { 
> 
> ### this part is just computing the logical index vector with length 
> = length(y)  ### and TRUE values where dropout occurs 
> 
> #kontrola licheho spanu 
> if(span/2-span%/%2<.4|span<2) span<-
> ceiling(span+floor(1/span)+.1) 
> 
> n<-length(y) 
> s<-span%/%2 
> 
> 
> idx1<-y==0 
> prumer<-median(y[!idx1],na.rm=T) 
> 
> if (is.null(mez))   
> { 
> mez<-mad(y[!idx1],na.rm=T) 
> dm<-prumer-mez*qnorm(p) 
> hm<-prumer+mez*qnorm(p) 
> } else { 
> 
> dm<-prumer-mez 
> hm<-prumer+mez 
> } 
> 
> 
> idx2<-y<dm 
> idx3<-y>hm 
> 
> idx<-as.logical(idx1+idx2+idx3) 
> z <- embed(idx,span) 
> rowSums(z) 
> length(rowSums(z)) 
> sumy<-rowSums(z)>0 
> index<-c(rep(sumy[1],s),sumy,rep(sumy[n-span+1],s)) 
> 
> ### index is a returned logical vector and it is OK 
> 
> if (nahradit) y[index]<<-NA 
> ### this is the ghastly line which does not work as I expected :-( 
> 
> invisible(index) 
> 
> } 
> 
> 
> Thank you 
> 
> Best regardsPetr Pikal
> petr.pikal at precheza.cz
> p.pik at volny.cz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Tue Feb 25 10:13:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue Feb 25 10:13:02 2003
Subject: [R] fill prob. in legend
In-Reply-To: <200302241849.KAA28405@hivnet.ubc.ca>
References: <F17mRpVgRdc6GoVaE7W000023e1@hotmail.com>
	<200302241813.KAA26657@hivnet.ubc.ca>
	<3E5A659D.291C4856@statistik.uni-dortmund.de>
	<200302241849.KAA28405@hivnet.ubc.ca>
Message-ID: <15963.13199.158794.305600@gargle.gargle.HOWL>

>>>>> "Jerome" == Jerome Asselin <jerome at hivnet.ubc.ca>
>>>>>     on Mon, 24 Feb 2003 10:49:38 -0800 writes:

    Jerome> Ok... All we need is an "blank" symbol (such as pch=30(?)).

no, that's "currently undefined".  Rather use NA

    Jerome> Now try again...

    Jerome> Jerome

    Jerome> plot(0,0)
    Jerome> legend(0,0,c("blah","blahblah","blahblahblah","blah..."),
    Jerome> pch=c(30,30,22,22),
    Jerome> col=c("green","red","blue","blue"),
    Jerome> lty=c(1,1,2,2),
    Jerome> pt.bg=c("white","white","yellow","orange"),cex=2)

well done!  Using NA instead, twice, (and indenting) gives

plot(0,0)
legend(0,0,c("blah","blahblah","blahblahblah","blah..."),
       pch=c(NA,NA,22,22),
       col=c("green","red","blue","blue"),
       lty=c(1,1,2,2),
       pt.bg=c(NA,NA,"yellow","orange"), cex=2)


    Jerome> On Monday 24 February 2003 10:34, Uwe Ligges wrote:
    >> Content-Length: 1182
    >> Status: R
    >> X-Status: N
    >> 
    >> Jerome Asselin wrote:
    >> > I think this does what you want...
    >> >
    >> > Jerome
    >> >
    >> > plot(0,0)
    >> > legend(0,0,c("blah","blahblah","blahblahblah","blah..."),
    >> > pch=c(21,21,22,22),
    >> > col=c("green","red","blue","blue"),
    >> > pt.bg=c("white","white","yellow","orange"),cex=2)
    >> 
    >> I don't think so, because Jeremy Butler asked for *lines*.
    >> Unfortunately, the my answer won't be much more helpful (see below).
    >> 
    >> > On Sunday 23 February 2003 17:29, Jeremy Z Butler wrote:
    >> > > Hi,
    >> > > I'm trying to construct a legend which has four lines of text and
    >> > > associated symbols. The first two symbols need to be normal lines which
    >> > > vary only in colour. The second two symbols should have filled boxes.
    >> > > How do I suppress the fill boxes in the first two lines?
    >> > > J.
    >> 
    >> Well, you cannot, AFAIK.
    >> You have to construct such a special legend using either two tricky
    >> calls to legend, or add the elements with low level functions like
    >> text() and friends to the plot.
    >> I think a contribution of an improvement of legend() that solves your
    >> problem is welcome.
    >> 
    >> Uwe Ligges
    >> 
    >> ______________________________________________
    >> R-help at stat.math.ethz.ch mailing list
    >> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

    Jerome> -- 

    Jerome> Jerome Asselin (J?r?me)
    Jerome> Statistical Analyst
    Jerome> British Columbia Centre for Excellence in HIV/AIDS
    Jerome> St. Paul's Hospital
    Jerome> 608 - 1081 Burrard Street
    Jerome> Vancouver, British Columbia
    Jerome> CANADA V6Z 1Y6

    Jerome> Email: jerome at hivnet.ubc.ca
    Jerome> Phone: 604 806-9112   Fax: 604 806-9044

    Jerome> ______________________________________________
    Jerome> R-help at stat.math.ethz.ch mailing list
    Jerome> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gerds at fdm.uni-freiburg.de  Tue Feb 25 10:21:07 2003
From: gerds at fdm.uni-freiburg.de (Thomas Gerds)
Date: Tue Feb 25 10:21:07 2003
Subject: [R] printing decimal numbers
In-Reply-To: <Pine.LNX.4.44.0302241830470.2409-100000@gannet.stats> (ripley@stats.ox.ac.uk's
 message of "Mon, 24 Feb 2003 18:35:54 +0000 (GMT)")
References: <Pine.LNX.4.44.0302241830470.2409-100000@gannet.stats>
Message-ID: <7er89wd8go.fsf@rembrandt.fdm.uni-freiburg.de>

thanks a lot for your answer. i have not enough skills to write my own
print.default routine, though. i thought there should be a user-option
that allows to change the default behaviour.  anyway, whats the idea
of printing 1e-04 instead of 0.0001 and what is the appropriate topic
in the help-pages or faq?

cheers,
tomy

ripley at stats.ox.ac.uk writes:

> The way to change the behavour of print.default() is to alter the source 
> code, which you can do as R is Open Source but you may find daunting.
>
> I find sprintf() more useful than formatC(), but your mileage may differ.
> In either case you can do as the internals of print.default do, and
> calculate the format from the characteristics of the set of numbers 
> supplied.  Just write your own special-pupose format routine.
>
> On Mon, 24 Feb 2003, Thomas Gerds wrote:
>
>> 
>> > formatC(0.0001, format = "f", digits = 4)
>> 
>> works fine for this case. however, i need a way to automatize this,
>> i.e. to change the default behaviour of print.default!? how could this
>> be done? the problem with applying the above solution to a number
>> which is the result of a function, say, is that one has to know
>> beforehand the number of digits, since
>> 
>> > formatC(1e-04,format="f",digits=5)
>> [1] "0.00010"
>> 
>> which is also unwanted. 
>> 
>> thanks a lot so far!
>> 
>> tomy
>> 
>> 
>> "Marc Schwartz" <mschwartz at medanalytics.com> writes:
>> 
>> >>-----Original Message-----
>> >>From: r-help-admin at stat.math.ethz.ch 
>> >>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Thomas Gerds
>> >>Sent: Monday, February 24, 2003 11:01 AM
>> >>To: r-help at stat.math.ethz.ch
>> >>Subject: [R] printing decimal numbers
>> >>
>> >>
>> >>hi,
>> >>
>> >>this is a very basic question -- sorry for posing it:
>> >>     
>> >>how can i force R to print 0.0001 instead of 1e-04???
>> >>
>> >>.--------------------.
>> >>| > 0.0001           |
>> >>| [1] 1e-04          |
>> >>`--------------------'
>> >>
>> >>i tried the functions format, formatC, ... and changed 
>> >>options()$digits with no success!
>> >>
>> >>thanks for advice,
>> >>tomy
>> >
>> >
>> > Try:
>> >
>> >> formatC(0.0001, format = "f", digits = 4)
>> > [1] "0.0001"
>> >
>> > Be sure to use the 'format = "f"' argument.
>> >
>> > See ?formatC
>> >
>> > HTH,
>> >
>> > Marc Schwartz
>> 
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
no signature



From tord.snall at ebc.uu.se  Tue Feb 25 10:44:02 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Tue Feb 25 10:44:02 2003
Subject: [R] summary(polr.object)
Message-ID: <3.0.6.32.20030225104739.00c22130@mail.anst.uu.se>

Dear all, 

I have used polr in MASS but I am uncertain about the summary(polr.object)
interpretation and would be happy for help on that. This is my summary:

> summary(shade.polr)

Re-fitting to get Hessian

Call:
polr(formula = as.ordered(shade) ~ as.factor(objekt), data = sof, 
    weights = as.numeric(frek))

Coefficients:
     Value Std. Error    t value 
 2.1699520  0.3681840  5.8936612 

Intercepts:
    Value   Std. Error t value
2|3 -2.2975  0.2656    -8.6500
3|4  2.8737  0.3296     8.7175

Residual Deviance: 347.5964 
AIC: 353.5964 


The ordered variable thus has 3 levels. The independent as.factor(objekt)
has two levels.

Is t=5.8936612 for a test of difference in the ordered response between the
two groups, and is the p-value for the two-sided test thus 
2* (1-pt(5.8936612, df=shade.polr$df.residual))

Why is the p-value not reported? Is there a special reason that would be
good to know?

Furthermore is t = -8.6500 in 
2|3 -2.2975  0.2656    -8.6500
for a test of difference in the proportion of twos and threes between the
two levels of the independet factor?

Is the p-value: 2* (1-pt(8.6500, df=shade.polr$df.residual))?


Thanks in advance!


Sincerely,
Tord Sn?ll

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From gerds at fdm.uni-freiburg.de  Tue Feb 25 10:49:03 2003
From: gerds at fdm.uni-freiburg.de (Thomas Gerds)
Date: Tue Feb 25 10:49:03 2003
Subject: [R] printing decimal numbers
In-Reply-To: <Pine.LNX.4.44.0302250931190.13516-100000@gannet.stats> (ripley@stats.ox.ac.uk's
 message of "Tue, 25 Feb 2003 09:33:00 +0000 (GMT)")
References: <Pine.LNX.4.44.0302250931190.13516-100000@gannet.stats>
Message-ID: <7eof50d74j.fsf@rembrandt.fdm.uni-freiburg.de>

sorry, i didnot mean to displease you and i do appreciate R a
lot. (please note that i am not a native speaker and perhaps was
unable to find the appropriate degree of politeness when posting this
request) i was hoping someone could give me a hint about where to find
a discussion on my problem ...

tomy


ripley at stats.ox.ac.uk writes:

> If you know enough to tell people what `should' happen, you know enough 
> to answer your own questions.
>
> Telling people what they `should' do seems pretty arrogant to me.
> R is a free gift to you, and you don't seem to appreciate it.
>
> On Tue, 25 Feb 2003, Thomas Gerds wrote:
>
>> 
>> thanks a lot for your answer. i have not enough skills to write my own
>> print.default routine, though. i thought there should be a user-option
>> that allows to change the default behaviour.  anyway, whats the idea
>> of printing 1e-04 instead of 0.0001 and what is the appropriate topic
>> in the help-pages or faq?
>> 
>> cheers,
>> tomy
>> 
>> ripley at stats.ox.ac.uk writes:
>> 
>> > The way to change the behavour of print.default() is to alter the source 
>> > code, which you can do as R is Open Source but you may find daunting.
>> >
>> > I find sprintf() more useful than formatC(), but your mileage may differ.
>> > In either case you can do as the internals of print.default do, and
>> > calculate the format from the characteristics of the set of numbers 
>> > supplied.  Just write your own special-pupose format routine.
>> >
>> > On Mon, 24 Feb 2003, Thomas Gerds wrote:
>> >
>> >> 
>> >> > formatC(0.0001, format = "f", digits = 4)
>> >> 
>> >> works fine for this case. however, i need a way to automatize this,
>> >> i.e. to change the default behaviour of print.default!? how could this
>> >> be done? the problem with applying the above solution to a number
>> >> which is the result of a function, say, is that one has to know
>> >> beforehand the number of digits, since
>> >> 
>> >> > formatC(1e-04,format="f",digits=5)
>> >> [1] "0.00010"
>> >> 
>> >> which is also unwanted. 
>> >> 
>> >> thanks a lot so far!
>> >> 
>> >> tomy
>> >> 
>> >> 
>> >> "Marc Schwartz" <mschwartz at medanalytics.com> writes:
>> >> 
>> >> >>-----Original Message-----
>> >> >>From: r-help-admin at stat.math.ethz.ch 
>> >> >>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Thomas Gerds
>> >> >>Sent: Monday, February 24, 2003 11:01 AM
>> >> >>To: r-help at stat.math.ethz.ch
>> >> >>Subject: [R] printing decimal numbers
>> >> >>
>> >> >>
>> >> >>hi,
>> >> >>
>> >> >>this is a very basic question -- sorry for posing it:
>> >> >>     
>> >> >>how can i force R to print 0.0001 instead of 1e-04???
>> >> >>
>> >> >>.--------------------.
>> >> >>| > 0.0001           |
>> >> >>| [1] 1e-04          |
>> >> >>`--------------------'
>> >> >>
>> >> >>i tried the functions format, formatC, ... and changed 
>> >> >>options()$digits with no success!
>> >> >>
>> >> >>thanks for advice,
>> >> >>tomy
>> >> >
>> >> >
>> >> > Try:
>> >> >
>> >> >> formatC(0.0001, format = "f", digits = 4)
>> >> > [1] "0.0001"
>> >> >
>> >> > Be sure to use the 'format = "f"' argument.
>> >> >
>> >> > See ?formatC
>> >> >
>> >> > HTH,
>> >> >
>> >> > Marc Schwartz
>> >> 
>> >> 
>> >
>> > -- 
>> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> > University of Oxford,             Tel:  +44 1865 272861 (self)
>> > 1 South Parks Road,                     +44 1865 272866 (PA)
>> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> 
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
no signature



From ripley at stats.ox.ac.uk  Tue Feb 25 10:59:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Feb 25 10:59:02 2003
Subject: [R] summary(polr.object)
In-Reply-To: <3.0.6.32.20030225104739.00c22130@mail.anst.uu.se>
Message-ID: <Pine.LNX.4.44.0302250950180.16861-100000@gannet.stats>

On Tue, 25 Feb 2003, Tord Snall wrote:

> Dear all, 
> 
> I have used polr in MASS but I am uncertain about the summary(polr.object)
> interpretation and would be happy for help on that. This is my summary:
> 
> > summary(shade.polr)
> 
> Re-fitting to get Hessian
> 
> Call:
> polr(formula = as.ordered(shade) ~ as.factor(objekt), data = sof, 
>     weights = as.numeric(frek))
> 
> Coefficients:
>      Value Std. Error    t value 
>  2.1699520  0.3681840  5.8936612 
> 
> Intercepts:
>     Value   Std. Error t value
> 2|3 -2.2975  0.2656    -8.6500
> 3|4  2.8737  0.3296     8.7175
> 
> Residual Deviance: 347.5964 
> AIC: 353.5964 
> 
> 
> The ordered variable thus has 3 levels. The independent as.factor(objekt)
> has two levels.
> 
> Is t=5.8936612 for a test of difference in the ordered response between the
> two groups, and is the p-value for the two-sided test thus 
> 2* (1-pt(5.8936612, df=shade.polr$df.residual))
> 
> Why is the p-value not reported? Is there a special reason that would be
> good to know?

Like glms. there is no exact p-value.  R is unwise to report them for 
binomial and Poisson glms: S-PLUS is more sanguine here.

> Furthermore is t = -8.6500 in 
> 2|3 -2.2975  0.2656    -8.6500
> for a test of difference in the proportion of twos and threes between the
> two levels of the independet factor?
> 
> Is the p-value: 2* (1-pt(8.6500, df=shade.polr$df.residual))?

Not quite.  It's between categories to the left of the line and to the 
right of the line, at the base value of the regressor.  In your case that 
is between proportions of 2 vs 3,4 at the base value of object (assuming 
you are using treatment contrasts).

Also, use a normal reference distribution: there is no real evidence that 
I know of for the accuracy of a t distribution.

As ever, MASS the package supports MASS the book and the details are in 
the latter.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From steffen.durinck at esat.kuleuven.ac.be  Tue Feb 25 11:46:02 2003
From: steffen.durinck at esat.kuleuven.ac.be (Steffen Durinck)
Date: Tue Feb 25 11:46:02 2003
Subject: [R] How to modify XML documents and save changes
Message-ID: <1046169844.1042.24.camel@sista-08.esat.kuleuven.ac.be>

Dear,

I want to read XML documents, add child nodes to some elements and store
everything back as an XML document.

I've tryed the following:

doc <- xmlTreeParse("file.xml")       
QTListNode<-xmlElementsByTagName(xmlRoot(doc)[[1]],"tagname") 
append.xmlNode(QTListNode[[1]],newXMLNode(name ="Norm", attrs = NULL))
saveXML(doc, file = "out.xml", compression = 0, indent=T)

This doesn't seem to work.
Can anyone help?

Thanks,
Steffen



From rutis at giub.unibe.ch  Tue Feb 25 12:23:05 2003
From: rutis at giub.unibe.ch (This Rutishauser)
Date: Tue Feb 25 12:23:05 2003
Subject: [R] linear trend
Message-ID: <3E5B51DA.5ABF38F9@giub.unibe.ch>

hej!
can anyone help me with a hint how to find a function to fit a linear
trend line into a scatter plot. as well as testing it for significance.

thanx/thisse



From baron at cattell.psych.upenn.edu  Tue Feb 25 12:32:04 2003
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue Feb 25 12:32:04 2003
Subject: [R] linear trend
In-Reply-To: <3E5B51DA.5ABF38F9@giub.unibe.ch>; from rutis@giub.unibe.ch on Tue, Feb 25, 2003 at 12:22:02PM +0100
References: <3E5B51DA.5ABF38F9@giub.unibe.ch>
Message-ID: <20030225063036.A27568@cattell.psych.upenn.edu>

On 02/25/03 12:22, This Rutishauser wrote:
>can anyone help me with a hint how to find a function to fit a linear
>trend line into a scatter plot. as well as testing it for significance.

Look at the help page for abline().  That is what you use for
drawing lines in a plot.  It turns out that you can specify the
line with lm(), and summary(lm()) gives you the significance
test.  For example (all but the last line from ?abline):

data(cars)
z <- lm(dist ~ speed, data = cars)
plot(cars)
abline(z)
summary(z)

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
R page:               http://finzi.psych.upenn.edu/



From rossini at blindglobe.net  Tue Feb 25 13:15:05 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue Feb 25 13:15:05 2003
Subject: [R] question on - build R as a shared library
In-Reply-To: <Pine.GSO.4.44.0302242050340.15334-100000@ece.ogi.edu> (Bai
 Yan's message of "Mon, 24 Feb 2003 20:52:02 -0800 (PST)")
References: <Pine.GSO.4.44.0302242050340.15334-100000@ece.ogi.edu>
Message-ID: <87fzqc8srt.fsf@jeeves.blindglobe.net>

Bai Yan <baiyan at ece.ogi.edu> writes:


> Hi Dirk, thank you for the prompt reply.
> I found libR.so. But how can I know whether it is build as shared or not.

Traditionally, for linking purposes, libR.so would be a shared
library, where as libR.a would be a static library.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From petr.pikal at precheza.cz  Tue Feb 25 13:29:05 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue Feb 25 13:29:05 2003
Subject: [R] how to chage values in data frame to NA iside a function
In-Reply-To: <Pine.LNX.4.44.0302250742020.9982-100000@gannet.stats>
References: <3E5B2574.20993.1EFB8F@localhost>
Message-ID: <3E5B6F68.6206.13FDA95@localhost>

Thanks a lot. 

If I understand it correctly I shall have some object, preferably 
before I use a function, in which I can make changes and which 
shall have the same name "inside" and "outside" a function (eg. 
df$myvariable)

>dropout<-function(y, nahr=FALSE,...) { 
><some stuff for computing an index> 
>if (nahr) df$myvariable[index]<<-NA 
###############################
or
>if (nahr) df[index,]<<-NA 

>invisible(index) 
}

Changed function works on artificial example. 

On 25 Feb 2003 at 7:57, ripley at stats.ox.ac.uk wrote:

> You are mis-using <<-.  I don't know what you think it does, so please
> look it up.  Using <<- in R/S programming is normally a sign of
> incorrect thinking (but not quite always).  (Also, it behaves
> differently in R and in S which can be a cause of confusion to those
> who know only one of the definitions.)
> 
> On Tue, 25 Feb 2003, Petr Pikal wrote:
> 
> > Thank you for your answers. It works OK but my real question is why
> > my  function behaves differently used on vector and data frame (or
> > matrix or list).  
> 
> > I attached a full version below with some foo data, but basically
> > the function  returns the correct index if applied correctly on any
> > type (list, data frame, matrix,  vector) but it changes values of
> > operand only if operand is a vector. 
> 
> Not so.  It always alters an object called `y'.  It just so happens
> that your vector argument was called `y' and the other cases you tried
> were not.
> 
> > Why please? 
> 
> (Because that is what you asked it to do ....)
> 
> I can see a way to do what I think is your intention (to change the
> object which was passed as the y argument from the parent
> environment), but it is convoluted and against the spirit of a
> functional language, so I won't describe it.
> 

<snip>

> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self) 1 South
> Parks Road,                     +44 1865 272866 (PA) Oxford OX1 3TG,
> UK                Fax:  +44 1865 272595
> 

Petr Pikal
Precheza a.s., Nab?.Dr.E.Bene?e 24, 750 62 P?erov
tel: +420581 252 257 ; 724 008 364
petr.pikal at precheza.cz; p.pik at volny.cz
fax +420581 252 561



From lehmann at puk.unibe.ch  Tue Feb 25 14:00:03 2003
From: lehmann at puk.unibe.ch (Christoph Lehmann)
Date: Tue Feb 25 14:00:03 2003
Subject: [R] Variance Decomposition Proportion (Belsley, Kuh, Welsch)
Message-ID: <1046177972.1130.36.camel@christophl>

Hi, dear R

I am dealing with a dataset with collinearity. I want to use the
Variance Decomposition (Variance Proportion) method. I wonder if I can
find a function in R?

By the way: Does anybody know a nice tutorial about computing
regressions by means of  QR decompositions with pivoting (which R uses)
or an SVD? (thank you Brian for the hint!!)

Thanks a lot! 

Christoph

-- 
Christoph Lehmann                                              Phone: 
++41 31 930 93 83 
Department of Psychiatric Neurophysiology                      Mobile:
++41 31 570 28 00
University Hospital of Clinical Psychiatry                     Fax:   
++41 31 930 99 61 
Waldau                                                             
lehmann at puk.unibe.ch 
CH-3000 Bern 60                             
http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html



From poizot at cnam.fr  Tue Feb 25 14:17:02 2003
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Tue Feb 25 14:17:02 2003
Subject: [R] Wavelets correlation test
Message-ID: <200302251351.42310.poizot@cnam.fr>

Hello,
I use wavethresh packages to perform wavelet analysis.
In particular, I would like to compare 2 signals (vectors) after a wavelet 
decomposition. I would like to use cor.test function, but this function acts 
on the entire vector values.
I plan to perform a cor.test on each level of the wavelet decomposition, say 
N. So I will have at the end of a first step N results of cor.test.

How can I deal with this N results to have an answer globaly ?

-- 
Cordialy
----------------------------------------
Emmanuel POIZOT
Cnam/Intechmer
Digue de Collignon
50110 Tourlaville
T?l : (33)(0)2 33 88 73 42
Fax : (33)(0)2 33 88 73 39
-----------------------------------------



From Timur.Elzhov at jinr.ru  Tue Feb 25 15:08:03 2003
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Tue Feb 25 15:08:03 2003
Subject: [R] Error analysis
Message-ID: <20030225140909.GA3288@pcf004.jinr.ru>

Dear R experts,

I fitted data (length == m) with an external library (that's
a non-linear problem), and, I've got the final parameter vector
(length == n) and Jacobian matrix (dim == c(m, n)).  Now, I want
to analyse the standard errors of the parameters correctly.
How can I do it?
Where can I read about it else?

Thanks!


--
WBR,
Timur.



From Mariabeth.Silkey at insightful.com  Tue Feb 25 15:16:06 2003
From: Mariabeth.Silkey at insightful.com (Mariabeth Silkey)
Date: Tue Feb 25 15:16:06 2003
Subject: [R] COURSE: Bill Venables on Advanced Programming in S, London Mar 17/18
Message-ID: <DB851E21ABFADF47946A3511383B24DC0E6751@ch2kexc01.insightful.com>

Insightful presents

Advanced Programming in S by DR. BILL VENABLES
Click here for all details: http://www.insightful.com/services/course.asp?CID=16

*Mar 17-18, 2003 in London, Mar 24-25 in Boston, MA and Mar 27-28 in San Francisco*

This course is for data analysts and other research workers who will be using the system
fairly extensively for their daily work. Such users will typically need to use the system
as a programming language for non-standard calculations as well as a pre-written system 
for standard ones. This course is designed to make programming in S-PLUS effective, 
efficient and easy.


Mit freundlichen Gr??en / Best  Regards

Mariabeth Silkey

Insightful AG
------------------------------------------- ------------------
For the latest in upcoming training events, see http://www.insightful.com/services/intl_training.asp 
Highlights include: Brian Ripley on Statistical Data Mining, Zuerich April 3/4
                    Analysis of Financial Time Series With S-PLUS and S+FinMetrics, NYC, April 3/4



From Mariabeth.Silkey at insightful.com  Tue Feb 25 15:19:57 2003
From: Mariabeth.Silkey at insightful.com (Mariabeth Silkey)
Date: Tue Feb 25 15:19:57 2003
Subject: [R] COURSE: Prof. Brian D. Ripley on Statistical Data Mining, Zuerich, April 3/4
Message-ID: <DB851E21ABFADF47946A3511383B24DC0E6752@ch2kexc01.insightful.com>

Insightful AG and Seminar for Statistics of ETH Z?rich present:

Statistical Data Mining by PROF. BRIAN D. RIPLEY
click here for all details: http://www.insightful.com/services/training/datamining_by_Ripley.asp

*Zuerich April 3/4*

Data Mining has become popular in science, engineering and in traditionally data-rich
industries such as banking, insurance and market research. There are emerging applications
in official, environmental and medical statistics. Data Mining, also known as 'knowledge
discovery in databases', is one of many terms for finding structure in large-scale datasets on
the boundaries of statistics, engineering, machine learning and computer science.

Register before March 7th, 2003 for a 10% discount on the course fee for Statistical Data Mining. 


Mit freundlichen Gr??en / Best  Regards

Mariabeth Silkey

Insightful AG
------------------------------------------- ------------------
For the latest in upcoming training events, see http://www.insightful.com/services/intl_training.asp 
Highlights include: Bill Venables on Advanced Programming in S, London Mar 17/18
                    Analysis of Financial Time Series With S-PLUS and S+FinMetrics, NYC, April 3/4



From tblackw at umich.edu  Tue Feb 25 15:39:03 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue Feb 25 15:39:03 2003
Subject: [R] Error analysis
In-Reply-To: <20030225140909.GA3288@pcf004.jinr.ru>
Message-ID: <Pine.SOL.4.44.0302250923110.11863-100000@millipede.gpcc.itd.umich.edu>

Gosh - Approximate standard errors would be discussed in almost
any advanced textbook on linear regression models.  G.A.F. Seber,
Linear Models, circa 1980, is the one I learned from.

See also G.A.F. Seber and C.J. Wild, Nonlinear Regression, 1989,
D.M. Bates and D.G. Watts, Nonlinear Regression Analysis, 1988,
or another book by Gallant (? A.R.?) which came out about the
same time.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -



On Tue, 25 Feb 2003, Timur Elzhov wrote:

> Dear R experts,
>
> I fitted data (length == m) with an external library (that's
> a non-linear problem), and, I've got the final parameter vector
> (length == n) and Jacobian matrix (dim == c(m, n)).  Now, I want
> to analyse the standard errors of the parameters correctly.
> How can I do it?
> Where can I read about it else?
>
> Thanks!
>
>
> --
> WBR,
> Timur.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From kawa at aris.ss.uci.edu  Tue Feb 25 16:19:03 2003
From: kawa at aris.ss.uci.edu (Hiroyuki Kawakatsu)
Date: Tue Feb 25 16:19:03 2003
Subject: [R] syntax rules
Message-ID: <Pine.GSO.4.30.0302250651220.13453-100000@aris.ss.uci.edu>

hi,

i lost half a day trying to figure out how r is parsing statements
in multiple lines. can someone explain (or direct me to documentation) the
following. consider the following statements in a program file, say
foo.r:

a <- 1 +
 2;
b <- {1
 + 2};
{c <- 1
 + 2};
d <- c(1,
 2);

if i do source("foo.r"), i get a=3, b=2, c=1, d={1,2}.
according to the r language definition p.11, section 3.2, it says

"A semicolon always indicates the end of a statement while a new line
'may' indicate the end of a statement. If the current statement is not
syntactically complete new lines are simply ignored by the evaluator."

then, a and d are evaluated as expected since the first lines are not
syntactically complete. however, why does b evaluate to 2 and c to 1?
(it appears to evaluate differently if i do this interactively.)
i got the idea of using curly braces from p.12 of the language definition.

is there a way to keep adding terms with a line beginning with a plus sign
(notationally, i don't like plus symbols hanging at the end of a line...)?

h.
--------------------------------------------------------------------
Time series regression studies give no sign of converging toward the
truth. (Phillip Cagan)



From rob.foxall at BBSRC.AC.UK  Tue Feb 25 16:24:03 2003
From: rob.foxall at BBSRC.AC.UK (rob foxall (IFR))
Date: Tue Feb 25 16:24:03 2003
Subject: [R] cat in windows vs linux
Message-ID: <AF4854EAE0A4D411A7AC00508BDCD6E802969263@fr-exsrv1.ifrn.bbsrc.ac.uk>

Hi all,
	Easy question for you (which I failed to find the answer to in the FAQ etc). I've recently been forced to switch from linux to windows (currently windows NT), and my usual habit of putting lots of "cat" statements in slow functions to get an idea of the progress rate is no longer useful. Why -- because R waits until the function is completely finished before printing the cat statements all at once to the screen. Don't know if this is an R thing or a windows thing, but if there is a way to get cat statements printed to the screen as soon as the function calls it, I'd like to hear it! Using R version 1.6.2.

Cheers,
	Rob.



From andy_liaw at merck.com  Tue Feb 25 16:32:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Feb 25 16:32:03 2003
Subject: [R] syntax rules
Message-ID: <3A822319EB35174CA3714066D590DCD534BD1F@usrymx25.merck.com>

> From: Hiroyuki Kawakatsu [mailto:kawa at aris.ss.uci.edu]
> 
> hi,
> 
> i lost half a day trying to figure out how r is parsing statements
> in multiple lines. can someone explain (or direct me to 
> documentation) the
> following. consider the following statements in a program file, say
> foo.r:
> 
> a <- 1 +
>  2;
> b <- {1
>  + 2};

The first line is not a complete statement because there's no enclosing }.
Thus b gets assign the value of the statement enclosed in {}.

> {c <- 1
>  + 2};

The first line here *is* a complete statement.  The entire { } expression
gets the value of the the last line, namely "+2".  Try:

> junk <- { b <- 1
+ + 2};
> b
[1] 1
> junk
[1] 2

Andy


> d <- c(1,
>  2);
> 
> if i do source("foo.r"), i get a=3, b=2, c=1, d={1,2}.
> according to the r language definition p.11, section 3.2, it says
> 
> "A semicolon always indicates the end of a statement while a new line
> 'may' indicate the end of a statement. If the current statement is not
> syntactically complete new lines are simply ignored by the evaluator."
> 
> then, a and d are evaluated as expected since the first lines are not
> syntactically complete. however, why does b evaluate to 2 and c to 1?
> (it appears to evaluate differently if i do this interactively.)
> i got the idea of using curly braces from p.12 of the 
> language definition.
> 
> is there a way to keep adding terms with a line beginning 
> with a plus sign
> (notationally, i don't like plus symbols hanging at the end 
> of a line...)?
> 
> h.
> --------------------------------------------------------------------
> Time series regression studies give no sign of converging toward the
> truth. (Phillip Cagan)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From ligges at statistik.uni-dortmund.de  Tue Feb 25 16:36:02 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue Feb 25 16:36:02 2003
Subject: [R] cat in windows vs linux
In-Reply-To: <AF4854EAE0A4D411A7AC00508BDCD6E802969263@fr-exsrv1.ifrn.bbsrc.ac.uk>
References: <AF4854EAE0A4D411A7AC00508BDCD6E802969263@fr-exsrv1.ifrn.bbsrc.ac.uk>
Message-ID: <3E5B8D6B.70503@statistik.uni-dortmund.de>

rob foxall (IFR) wrote:
> Hi all,
> 	Easy question for you (which I failed to find the answer to in the FAQ etc). I've recently been forced to switch from linux to windows (currently windows NT), and my usual habit of putting lots of "cat" statements in slow functions to get an idea of the progress rate is no longer useful. Why -- because R waits until the function is completely finished before printing the cat statements all at once to the screen. Don't know if this is an R thing or a windows thing, but if there is a way to get cat statements printed to the screen as soon as the function calls it, I'd like to hear it! Using R version 1.6.2.


It *is* in the R for Windows FAQs, Section 6.3.

Uwe Ligges



> Cheers,
> 	Rob.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From andy_liaw at merck.com  Tue Feb 25 16:39:44 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Feb 25 16:39:44 2003
Subject: [R] cat in windows vs linux
Message-ID: <3A822319EB35174CA3714066D590DCD534BD20@usrymx25.merck.com>

It would be even easier if you read the R for Windows FAQ, Q6.3 in
particular.

Andy

> -----Original Message-----
> From: rob foxall (IFR) [mailto:rob.foxall at BBSRC.AC.UK]
> Sent: Tuesday, February 25, 2003 10:17 AM
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] cat in windows vs linux
> 
> 
> Hi all,
> 	Easy question for you (which I failed to find the 
> answer to in the FAQ etc). I've recently been forced to 
> switch from linux to windows (currently windows NT), and my 
> usual habit of putting lots of "cat" statements in slow 
> functions to get an idea of the progress rate is no longer 
> useful. Why -- because R waits until the function is 
> completely finished before printing the cat statements all at 
> once to the screen. Don't know if this is an R thing or a 
> windows thing, but if there is a way to get cat statements 
> printed to the screen as soon as the function calls it, I'd 
> like to hear it! Using R version 1.6.2.
> 
> Cheers,
> 	Rob.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From andy_liaw at merck.com  Tue Feb 25 16:44:02 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Feb 25 16:44:02 2003
Subject: [R] syntax rules
Message-ID: <3A822319EB35174CA3714066D590DCD534BD21@usrymx25.merck.com>

> From: Hiroyuki Kawakatsu [mailto:kawa at aris.ss.uci.edu]
[...]
> is there a way to keep adding terms with a line beginning 
> with a plus sign
> (notationally, i don't like plus symbols hanging at the end 
> of a line...)?

Use options(continue = "whatever you want")

Andy

> h.
> --------------------------------------------------------------------
> Time series regression studies give no sign of converging toward the
> truth. (Phillip Cagan)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From mschwartz at medanalytics.com  Tue Feb 25 16:47:57 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue Feb 25 16:47:57 2003
Subject: [R] cat in windows vs linux
In-Reply-To: <AF4854EAE0A4D411A7AC00508BDCD6E802969263@fr-exsrv1.ifrn.bbsrc.ac.uk>
Message-ID: <007401c2dce3$d7d6f130$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of rob foxall (IFR)
>Sent: Tuesday, February 25, 2003 9:17 AM
>To: 'r-help at stat.math.ethz.ch'
>Subject: [R] cat in windows vs linux
>
>
>Hi all,
>	Easy question for you (which I failed to find the 
>answer to in the FAQ etc). I've recently been forced to switch 
>from linux to windows (currently windows NT), and my usual 
>habit of putting lots of "cat" statements in slow functions to 
>get an idea of the progress rate is no longer useful. Why -- 
>because R waits until the function is completely finished 
>before printing the cat statements all at once to the screen. 
>Don't know if this is an R thing or a windows thing, but if 
>there is a way to get cat statements printed to the screen as 
>soon as the function calls it, I'd like to hear it! Using R 
>version 1.6.2.
>
>Cheers,
>	Rob.


You might wish to try to turn off "buffered output", which is on the
"Misc" menu in Rgui.

BTW, this is in the R Windows FAQ:

6.3 When using Rgui the output to the console seems to be delayed.

This is deliberate: the console output is buffered and re-written in
chunks to be faster and less distracting. You can turn buffering off
or on from the `Misc' menu or the right-click menu: <Ctrl-W> toggles
the setting.

If you are sourcing R code or writing from a function, there is
another option. A call to the R function flush.console() will write
out the buffer and so update the console.


HTH,

Marc Schwartz



From m.kienzle at marlab.ac.uk  Tue Feb 25 16:51:46 2003
From: m.kienzle at marlab.ac.uk (Marco Kienzle)
Date: Tue Feb 25 16:51:46 2003
Subject: [R] Legend in plot: symbol for mean and standard deviation
In-Reply-To: <3E5A5BA7.1772871B@statistik.uni-dortmund.de>
References: <1046102774.9916.103.camel@PC535>
	 <3E5A5BA7.1772871B@statistik.uni-dortmund.de>
Message-ID: <1046186943.25787.15.camel@PC535>

Dear list,


I attached to this mail an eps file containing an example that illustrate the problem: the
plot display dot+vertical lines while with the legend I am able only to
display dot+horizontal line.

Any help is appreciate,

cheers,
marco

On Mon, 2003-02-24 at 17:51, Uwe Ligges wrote:
> Marco Kienzle wrote:
> > 
> > Dear list,
> > 
> > I am facing the following problem with the legend of a plot that display
> > the mean and variance of a measurement y as a function of x, the mean
> > being represented by a dot and the variance by a vertical line.
> 
> At least for me the latter does not appear to be "that common" ...
> 
> > My problem is that I am unable to display the symbol (dot + vertical
> > line) in the legend.
> > 
> > any help is welcome,
> > thanks
> > marco
> 
> 
> Does the following do what you are looking for?
> 
>   legend(..., c("y.", "y|"))
> or
>   legend(..., expression(y[.], y["|"]))
> 
> 
> Uwe Ligges
-- 
____________________________________________________________________________

Marco Kienzle
Fisheries Research Services
Marine Laboratory
PO Box 101 Victoria Road
Aberdeen AB119DB
United Kingdom
 
direct: +44 (0) 1224 295421
tel:    +44 (0) 1224 876544 
fax:    +44 (0) 1224 295511
http://www.marlab.ac.uk
-------------- next part --------------
A non-text attachment was scrubbed...
Name: graph.eps
Type: application/postscript
Size: 4524 bytes
Desc: 
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030225/a9e83d0d/graph.eps

From york at noaa.gov  Tue Feb 25 17:11:03 2003
From: york at noaa.gov (Anne York)
Date: Tue Feb 25 17:11:03 2003
Subject: [R] Legend in plot: symbol for mean and standard deviation
Message-ID: <Pine.GSO.4.05.10302250807430.2471-100000@ofis450a.akctr.noaa.gov>

You can specify that no plot character is drawn using pch = -1. 

Maybe this is what you want:

plot(1:10,1:10)
legend(locator(1),c("blah","blahblah","blahblahblah","blah..."),
 pch = c(-1,-1,22,22),lty=c(1,1,0,0),col=c("green","red","blue","blue"),
 pt.bg=c("white","white","yellow","orange"))
 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Anne E. York
National Marine Mammal Laboratory
Seattle WA 98115-0070  USA
e-mail: anne.york at noaa.gov
Voice: +1 206-526-4039
Fax: +1 206-526-6615
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



Date: Mon, 24 Feb 2003 18:51:35 +0100
From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
To: Marco Kienzle <m.kienzle at marlab.ac.uk>
CC: r-help at stat.math.ethz.ch
Subject: Re: [R] Legend in plot: symbol for mean and standard deviation



Marco Kienzle wrote:
> 
> Dear list,
> 
> I am facing the following problem with the legend of a plot that display
> the mean and variance of a measurement y as a function of x, the mean
> being represented by a dot and the variance by a vertical line.

At least for me the latter does not appear to be "that common" ...

> My problem is that I am unable to display the symbol (dot + vertical
> line) in the legend.
> 
> any help is welcome,
> thanks
> marco


Does the following do what you are looking for?

  legend(..., c("y.", "y|"))
or
  legend(..., expression(y[.], y["|"]))


Uwe Ligges



From spencer.graves at pdf.com  Tue Feb 25 17:35:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue Feb 25 17:35:06 2003
Subject: [R] syntax rules
References: <3A822319EB35174CA3714066D590DCD534BD1F@usrymx25.merck.com>
Message-ID: <3E5B9A93.20403@pdf.com>

Permit me to elaborate on Andy Liaw's brief comments:

Liaw, Andy wrote:
>>From: Hiroyuki Kawakatsu [mailto:kawa at aris.ss.uci.edu]
>>
>>hi,
>>
>>i lost half a day trying to figure out how r is parsing statements
>>in multiple lines. can someone explain (or direct me to 
>>documentation) the
>>following. consider the following statements in a program file, say
>>foo.r:
>>
>>a <- 1 +
>> 2;

"a <- 1 +" is NOT systactically complete.  Therefore, it looks for more 
of this statement on the next line.

>>b <- {1
>> + 2};

"b <- {1" is syntactically complete:  The "{" opens a separate 
evaluation (frame?), the first statement of which is "1".  This 
evaluation also includes a second "statement", which is "+2".  The 
variable "b" gets the value of last statement in the frame, which is 2.

If you start a line with "(", then it will not be syntactically complete 
until it finds the matching ")".  Consider the following:
 > (b <- 1
+ +2)
[1] 3

> 
> The first line is not a complete statement because there's no enclosing }.
> Thus b gets assign the value of the statement enclosed in {}.
> 
> 
>>{c <- 1
>> + 2};
> 
> 
> The first line here *is* a complete statement.  The entire { } expression
> gets the value of the the last line, namely "+2".  Try:
> 
> 
>>junk <- { b <- 1
> 
> + + 2};
> 
>>b
> 
> [1] 1
> 
>>junk
> 
> [1] 2
> 
> Andy
> 
> 
> 
>>d <- c(1,
>> 2);
>>

"c" is a function that creates a vector or a list, in this case, the 
vector consisting of "1" and "2".

>>if i do source("foo.r"), i get a=3, b=2, c=1, d={1,2}.
>>according to the r language definition p.11, section 3.2, it says
>>
>>"A semicolon always indicates the end of a statement while a new line
>>'may' indicate the end of a statement. If the current statement is not
>>syntactically complete new lines are simply ignored by the evaluator."

Here, the documentation "new lines are simply ignored" might be clearer 
as "new line characters are simply ignored".

	a <- 1; b <- 2

is two statements, on one line, while

  a <- 1 +
  2

is one statement on 2 lines;  since the first line is not syntactically 
complete, the "new line [character]" that ends the first line is ignored.

>>
>>then, a and d are evaluated as expected since the first lines are not
>>syntactically complete. however, why does b evaluate to 2 and c to 1?
>>(it appears to evaluate differently if i do this interactively.)
>>i got the idea of using curly braces from p.12 of the 
>>language definition.
>>
>>is there a way to keep adding terms with a line beginning 
>>with a plus sign
>>(notationally, i don't like plus symbols hanging at the end 
>>of a line...)?
>>
>>h.
>>--------------------------------------------------------------------
>>Time series regression studies give no sign of converging toward the
>>truth. (Phillip Cagan)
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
> 
> 
> ------------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From upton at mitre.org  Tue Feb 25 17:42:30 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Tue Feb 25 17:42:30 2003
Subject: [R] How to modify XML documents and save changes
References: <1046169844.1042.24.camel@sista-08.esat.kuleuven.ac.be>
Message-ID: <3E5B9BC8.BC0DA745@mitre.org>

Steffen,

As with most R objects, you're basically putting a copy of the R object into
the new object. Any operation or function you apply to that object does not
affect the original. Same goes for append.xmlNode - you're appending to the
original and getting back another structure that is the original plus the
new node. Finally, saveXML works on an object of XMLInternalDocument and doc
(the object returned by xmlTreeParse) is a XMLDocument object.

Here's one suggestion:
1. Read in the doc object as you've done, but manipulate the structure as
you would any other R object, e.g.,
QTListNode [[1]] <-
append.xmlNode(QTListNode[[1]],xmlNode(name="Norm",attrs=NULL))
2. you then need to modify that node within the root with this new, modified
node, e.g. (assume I've assigned root <- xmlRoot(doc)),
root[[whateverindextagnameis]] <- QTListNode[[1]]
(I use the index here rather than the name, since it's unique - if you use a
name,e.g., root[["tagname"]], that just adds a list element to root with
name "tagname")
3. to write out, use write with toString.XMLNode,
write(toString.XMLNode(root, file="out.xml")

Since this is probably a little cumbersome, suggest writing a function to do
the finding, appending, and replacement.

A little cumbersome, but doable. One other option is to use xmlEventParse
and write a handler that would add the element after the one you're
interested in.  I hope there is a better way, but haven't seen it yet. :-(

HTH
steve


Steffen Durinck wrote:

> Dear,
>
> I want to read XML documents, add child nodes to some elements and store
> everything back as an XML document.
>
> I've tryed the following:
>
> doc <- xmlTreeParse("file.xml")
> QTListNode<-xmlElementsByTagName(xmlRoot(doc)[[1]],"tagname")
> append.xmlNode(QTListNode[[1]],newXMLNode(name ="Norm", attrs = NULL))
> saveXML(doc, file = "out.xml", compression = 0, indent=T)
>
> This doesn't seem to work.
> Can anyone help?
>
> Thanks,
> Steffen
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From bigler at fowi.ethz.ch  Tue Feb 25 17:52:15 2003
From: bigler at fowi.ethz.ch (Christof Bigler)
Date: Tue Feb 25 17:52:15 2003
Subject: [R] plotting question: filling area between two lines
Message-ID: <5301C220-48E1-11D7-AD49-000A27D7D440@fowi.ethz.ch>

Is there any way to fill the area within a plotted line and a 
horizontal line, e.g. in the following example:

x <- rnorm(100)
plot(x,type="l")
abline(h=0)

Thanks for any help.

Christof



From kurt.sys at rug.ac.be  Tue Feb 25 18:01:06 2003
From: kurt.sys at rug.ac.be (Kurt Sys)
Date: Tue Feb 25 18:01:06 2003
Subject: [R] segmented regression
In-Reply-To: <15962.18380.725334.108427@ksys.rug.ac.be>
References: <15962.18380.725334.108427@ksys.rug.ac.be>
Message-ID: <15963.41317.656707.136677@ksys.rug.ac.be>

Hello all,
 
I'm trying to find out how to perform a 'segmented regression'. I have some data and the 'classical' model used is:
 
y(t) = a + bx(t) + cx(t)^2 + u(t) for x(t) < x(0)
y(t) = a + bx(0) + cx(0)^2 + d(x(t) - x(0)) + u(t) for x(t) > x(0)
and u(t) = rho.u(t-1) + eps
 
(It's a model using an ARIMA-model, in this case AR(1)-process)
The parameters to estimate here are: a, b, c, d and x(0) (with the last one, the most important one). u(t) is estimated using the rho of the AR(1).
How can I use such a 'segmented formula' or 'segmented model' in R or how do I perform such a regression (nonlinear or restricted maximum likelihood)?
 
thanks in advance,
Kurt



From zeileis at ci.tuwien.ac.at  Tue Feb 25 18:05:04 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Tue Feb 25 18:05:04 2003
Subject: [R] plotting question: filling area between two lines
In-Reply-To: <5301C220-48E1-11D7-AD49-000A27D7D440@fowi.ethz.ch>
References: <5301C220-48E1-11D7-AD49-000A27D7D440@fowi.ethz.ch>
Message-ID: <200302251701.h1PH1RV3001102@thorin.ci.tuwien.ac.at>

On Tuesday 25 February 2003 17:51, Christof Bigler wrote:

> Is there any way to fill the area within a plotted line and a
> horizontal line, e.g. in the following example:
>
> x <- rnorm(100)
> plot(x,type="l")
> abline(h=0)

You could do
   polygon(c(1, 1:100, 100), c(0, x, 0), col = "grey")
in the above example.
Z

> Thanks for any help.
>
> Christof
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From reid_huntsinger at merck.com  Tue Feb 25 18:27:21 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Tue Feb 25 18:27:21 2003
Subject: [R] segmented regression
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC35C@uswpmx11.merck.com>

This can be done by hand, for example by using linear regression to
find the minimum residual sum-of-squares for fixed x(0), then using
an optimizer (for non-differentiable objective fns) to minimize over x(0).

You may want to have a look at polymars in the polspline package.  It will
fit linear splines in multiple variables, with multiple knots (your x(0)).

Reid Huntsinger

-----Original Message-----
From: Kurt Sys [mailto:kurt.sys at rug.ac.be]
Sent: Tuesday, February 25, 2003 12:01 PM
To: r-help at stat.math.ethz.ch
Subject: [R] segmented regression


Hello all,
 
I'm trying to find out how to perform a 'segmented regression'. I have some
data and the 'classical' model used is:
 
y(t) = a + bx(t) + cx(t)^2 + u(t) for x(t) < x(0)
y(t) = a + bx(0) + cx(0)^2 + d(x(t) - x(0)) + u(t) for x(t) > x(0)
and u(t) = rho.u(t-1) + eps
 
(It's a model using an ARIMA-model, in this case AR(1)-process)
The parameters to estimate here are: a, b, c, d and x(0) (with the last one,
the most important one). u(t) is estimated using the rho of the AR(1).
How can I use such a 'segmented formula' or 'segmented model' in R or how do
I perform such a regression (nonlinear or restricted maximum likelihood)?
 
thanks in advance,
Kurt

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------



From drf5n at mug.sys.virginia.edu  Tue Feb 25 18:35:10 2003
From: drf5n at mug.sys.virginia.edu (David Forrest)
Date: Tue Feb 25 18:35:10 2003
Subject: [R] push/pop on a stack
Message-ID: <Pine.LNX.4.33.0302251224030.466-100000@mug.sys.virginia.edu>

Is there a package for stacks with pushing and popping?

I'd really like to do something like

push(par(no.readonly=TRUE))

 some stuff....

par(pop())

It seems like it wouldn't be difficult, and that someone may have already
implemented a set of stack functions, and I wouldn't like to duplicate it.

Thanks for your time,
Dave
-- 
 Dave Forrest    (434)924-3954w(111B) (804)642-0662h (804)695-2026p
 drf5n at virginia.edu             http://mug.sys.virginia.edu/~drf5n/



From mschwartz at medanalytics.com  Tue Feb 25 18:43:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue Feb 25 18:43:03 2003
Subject: [R] push/pop on a stack
In-Reply-To: <Pine.LNX.4.33.0302251224030.466-100000@mug.sys.virginia.edu>
Message-ID: <008e01c2dcf5$2b4733a0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of David Forrest
>Sent: Tuesday, February 25, 2003 11:34 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] push/pop on a stack
>
>
>Is there a package for stacks with pushing and popping?
>
>I'd really like to do something like
>
>push(par(no.readonly=TRUE))
>
> some stuff....
>
>par(pop())
>
>It seems like it wouldn't be difficult, and that someone may 
>have already implemented a set of stack functions, and I 
>wouldn't like to duplicate it.
>
>Thanks for your time,
>Dave


In at least that particular example, the same save/restore operation
can be achieved by:

old.pars <- par(no.readonly=TRUE)

...other code

par(old.pars)

That is in the examples in ?par.


Not sure that you need a LIFO based stack mechanism for that unless I
am missing something.

HTH,

Marc Schwartz



From f0z6305 at labs.tamu.edu  Tue Feb 25 18:49:03 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue Feb 25 18:49:03 2003
Subject: [R] How to calculate the closest distance from a point to a curve?
Message-ID: <000f01c2dcf6$0119f8a0$8bd75ba5@IE.TAMU.EDU>

Hely, R-list

Now I have non-parametric curve function, that is,
I only use N 2-Dimensional data points to represent
this curve, without explicit function formulation.

And given a new measurement (x1,x)', how can I calculate the shortese
Euclidean distance from this new
data point to the above curve?

Thanks a lot.

Fred



From paulda at BATTELLE.ORG  Tue Feb 25 18:58:02 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Tue Feb 25 18:58:02 2003
Subject: [R] Exporting Splus Data to R
Message-ID: 
 <CFA6739DD532764AA51E7459970BF0E205D0AB0A@ns-bco-mse3.im.battelle.org>

Using 

> data.dump(c("foo.frame.1","foo.frame.2", ...), file="DumpData",
oldStyle=T)

in Splus generates the requisite file in my working Splus directory.
However, when I use

> library(foreign)
> data.restore(file = "C:/.../DumpData",verbose = TRUE, env = .GlobalEnv)

I get the error messages

Error in as.name(name) : attempt to use zero-length variable name
In addition: Warning messages: 
1: NAs introduced by coercion 
2: NAs introduced by coercion 
3: NAs introduced by coercion 

and not all of the Splus dataframes are imported into R (though some of them
are).
Any suggestions would be greatly appreciated.  I am using R version 1.6.1 on
Windows 2000, Splus version 6.1 on Windows 2000.


Respectfully,

 David Paul, Ph.D.
  Battelle Memorial Institute
  505 King Avenue
  Columbus, OH  43201
  614.424.3176

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20030225/dc70260c/attachment.html

From B.Rowlingson at lancaster.ac.uk  Tue Feb 25 19:11:04 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue Feb 25 19:11:04 2003
Subject: [R] push/pop on a stack
In-Reply-To: <Pine.LNX.4.33.0302251224030.466-100000@mug.sys.virginia.edu>
References: <Pine.LNX.4.33.0302251224030.466-100000@mug.sys.virginia.edu>
Message-ID: <3E5BB18C.60200@lancaster.ac.uk>

> It seems like it wouldn't be difficult, and that someone may have already
> implemented a set of stack functions, and I wouldn't like to duplicate it.

Here's a Tuesday evening lash-up. Usage is:

  > mystack <- stack()   # initialisation
  > push(mystack,value)  # stores something on the stack
  > pop(mystack)         # returns 'value'

There's a print method that lists the stack. Its simply a list. Stack 
underflow is reported as 'attempt to select less than one element'. You 
can push anything on the stack. Almost. I just tried pushing a stack 
object onto the stack, and got infinite recursion, cant think why. 
Anyway, this seems to work for most sensible situations!


stack <- function(){

   it <- list()
   res <- list(
               push=function(x){
                 it[[length(it)+1]] <<- x
               },
               pop=function(){
                 val <- it[[length(it)]]
                 it <<- it[-length(it)]
                 return(val)
               },
               value=function(){
                 return(it)
               }
               )
   class(res) <- "stack"
   res

}

print.stack <- function(x,...){
   print(x$value())
}

push <- function(stack,obj){
   stack$push(obj)
}

pop <- function(stack){
   stack$pop()
}


Baz



From mschwartz at medanalytics.com  Tue Feb 25 19:19:05 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue Feb 25 19:19:05 2003
Subject: [R] push/pop on a stack
In-Reply-To: <3E5BB18C.60200@lancaster.ac.uk>
Message-ID: <000601c2dcfa$544ccfd0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-admin at stat.math.ethz.ch 
>[mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Barry Rowlingson
>Sent: Tuesday, February 25, 2003 12:10 PM
>To: David Forrest
>Cc: r-help at stat.math.ethz.ch
>Subject: Re: [R] push/pop on a stack
>
>
>
>> It seems like it wouldn't be difficult, and that someone may have 
>> already implemented a set of stack functions, and I wouldn't like
to 
>> duplicate it.
>
>Here's a Tuesday evening lash-up. Usage is:
>
>  > mystack <- stack()   # initialisation
>  > push(mystack,value)  # stores something on the stack
>  > pop(mystack)         # returns 'value'
>
>There's a print method that lists the stack. Its simply a list. Stack

>underflow is reported as 'attempt to select less than one 
>element'. You 
>can push anything on the stack. Almost. I just tried pushing a stack 
>object onto the stack, and got infinite recursion, cant think why. 
>Anyway, this seems to work for most sensible situations!
>
>
>stack <- function(){
>
>   it <- list()
>   res <- list(
>               push=function(x){
>                 it[[length(it)+1]] <<- x
>               },
>               pop=function(){
>                 val <- it[[length(it)]]
>                 it <<- it[-length(it)]
>                 return(val)
>               },
>               value=function(){
>                 return(it)
>               }
>               )
>   class(res) <- "stack"
>   res
>
>}
>
>print.stack <- function(x,...){
>   print(x$value())
>}
>
>push <- function(stack,obj){
>   stack$push(obj)
>}
>
>pop <- function(stack){
>   stack$pop()
>}
>
>
>Baz


Just as an FYI, if you should elect to implement that function, there
is already a stack() function in base R, so you would want to use a
different name.

See ?stack, which is used to transform data.

Regards,

Marc



From jelozano at wanadoo.es  Tue Feb 25 20:10:03 2003
From: jelozano at wanadoo.es (Jose Lozano (MEGA))
Date: Tue Feb 25 20:10:03 2003
Subject: [R] How to calculate the closest distance from a point to a curve?
In-Reply-To: <000f01c2dcf6$0119f8a0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <E18nkSS-0002dk-00@smtp2.yaonline.es>

>Hely, R-list
>
>Now I have non-parametric curve function, that is,
>I only use N 2-Dimensional data points to represent
>this curve, without explicit function formulation.
>

(x,y) gives the points that define the curve (I've generated a circle 
centered at 0)
(a,b) is the point (I've set it to (2,2))

x<-seq(from=-1,to=+1,length=1000)
y<-sqrt(1-x^2)
x<-c(x,x)
y<-c(y,-y)
n<-length(x)
a<-2
b<-2

The code to find the closest point to (a,b) is:

minimo<-min((1:n)[sqrt((a-x)^2+(b-y)^2)==min(sqrt((a-x)^2+(b-y)^2))])
cat(x[minimo],y[minimo],"\n")

0.7077077 0.7065053 

Regards
Jose Lozano



From spencer.graves at pdf.com  Tue Feb 25 20:24:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue Feb 25 20:24:03 2003
Subject: [R] How to calculate the closest distance from a point to a curve?
References: <E18nkSS-0002dk-00@smtp2.yaonline.es>
Message-ID: <3E5BC2A1.6010205@pdf.com>

If you want the closest point to a fitted model, "predict" may work with 
the output of the fitting function to generate a column of y's;  see, 
e.g, Venables and Ripley, Modern Applied Statistics with S.  Then the 
nearest point can be found as Jose Lozano suggested.

Jose Lozano (MEGA) wrote:
>>Hely, R-list
>>
>>Now I have non-parametric curve function, that is,
>>I only use N 2-Dimensional data points to represent
>>this curve, without explicit function formulation.
>>
> 
> 
> (x,y) gives the points that define the curve (I've generated a circle 
> centered at 0)
> (a,b) is the point (I've set it to (2,2))
> 
> x<-seq(from=-1,to=+1,length=1000)
> y<-sqrt(1-x^2)
> x<-c(x,x)
> y<-c(y,-y)
> n<-length(x)
> a<-2
> b<-2
> 
> The code to find the closest point to (a,b) is:
> 
> minimo<-min((1:n)[sqrt((a-x)^2+(b-y)^2)==min(sqrt((a-x)^2+(b-y)^2))])
> cat(x[minimo],y[minimo],"\n")
> 
> 0.7077077 0.7065053 
> 
> Regards
> Jose Lozano
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jzhang at jimmy.harvard.edu  Tue Feb 25 22:22:05 2003
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Tue Feb 25 22:22:05 2003
Subject: [R] Re: A tcltk question
Message-ID: <200302252120.QAA01483@blaise.dfci.harvard.edu>

Hi, 

I am trying to create a light-weight window with no border and title bar. The 
following code does not work for me. 

base <- tktoplevel()
tkwm.overrideredirect(base, TRUE) (or FALSE)

Could someone help me out? Thanks.


Jianhua Zhang
Department of Biostatistics
Dana-Farber Cancer Institute
44 Binney Street
Boston, MA 02115-6084



From tvargas at cisco.com  Tue Feb 25 22:57:06 2003
From: tvargas at cisco.com (Tony Vargas)
Date: Tue Feb 25 22:57:06 2003
Subject: [R] R performance, labeling questions, etc.
Message-ID: <Pine.GSO.4.44.0302251343430.20403-101000@tvargas-u10.cisco.com>

R helpers,

I am trying to add labels to my graphs.  I have a Perl Program which
generates thousands of R files like the one attached.

My data files have 2 - 8 columns in them.  The first column of every data
file is a header (Time) - which I want to have plotted against everything
else.  My current formula just plots each column, which is fine, yet at
the bottom for my labels I wind up with numbers.  What I would like to do
is have R grab the Time label in increments of 144 data points and use
that to label my X-axis instead of just plain numbers.  (Each data file
has about 4400 columns).

I can kind of have R lable the bottom by chaning my plot to "plot(usr.cpu
~ Time), yet then the graphs take much, much longer to generate.

Worst case, I will use "plot(usr.cpu ~ Time)" - yet, anyone know why this
would take a very, very long time?

Any ideas?

Thanks,

Tony

Tony Vargas
Cisco Systems
Engineering Computing Services
(408) 525-4113
tvargas at cisco.com
-------------- next part --------------
A non-text attachment was scrubbed...
Name: wbu.vob5.Feb.2003.sys.cpu.lines.png
Type: application/octet-stream
Size: 7270 bytes
Desc: 
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030225/90cdba26/wbu.vob5.Feb.2003.sys.cpu.lines.obj

From lehmann at puk.unibe.ch  Tue Feb 25 23:14:02 2003
From: lehmann at puk.unibe.ch (Christoph Lehmann)
Date: Tue Feb 25 23:14:02 2003
Subject: [R] Potential-Residual Plot (Hadi, 1994)
Message-ID: <1046211214.1615.3.camel@christophl>

Hi
Does anybody know, whether the Potential-Residual Plot, suggested by
Hadi (1994) has already been implemented in R? 

Hadi, A. S. (1992), "A New Measure of Overall Potential Influence in
Linear Regression," Computational Statistics & Data Analysis, 14, 1-27.
(The proposed Potential-Residual Plot has been implemented in Data Desk)

Thanks a lot for a hint

Cheers
Christoph

-- 
Christoph Lehmann                            Phone:  ++41 31 930 93 83 
Department of Psychiatric Neurophysiology    Mobile: ++41 31 570 28 00
University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61 
Waldau                                            lehmann at puk.unibe.ch 
CH-3000 Bern 60            http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html



From john.maindonald at anu.edu.au  Wed Feb 26 00:26:03 2003
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed Feb 26 00:26:03 2003
Subject: [R] (no subject)
Message-ID: <048C9644-4919-11D7-B43A-000393073F7A@anu.edu.au>

Let's assume that the columns of the model matrix, apart perhaps
from an initial column that corresponds to the overall mean, have
been centred.  Then:

1) Normal equation methods give an accurate fit to the matrix
of centred sums of squares and products.
2) QR methods give an accurate fit to the predicted values.

QR will give better precision than normal equation methods
(e.g., Cholesky) if there are substantial correlations between
the columns of the model matrix.  This is because sequential
normal equations methods successively modify the centred
sums of squares and products (CSSP) matrix to be a
representation of the matrix of sums of squares and  products
of partial residuals as columns of the model matrix are partialed
out in turn.  QR directly modifies a representation of the partial
residuals themselves.

If columns of the model matrix are almost uncorrelated then
normal equation methods may however give the better precision,
essentially because the CSSP matrix does not change much and
normal equation methods require fewer arithmetic operations.

In the situations where QR gives substantially better precision,
the correlations between columns of the model matrix will mean
that some regression coefficients have a large standard error.
The variance inflation factor for some regression coefficients
will be large.  Will the additional precision be meaningful?
The question has especial point now that double precision
is standardly used.

I think it useful to expose students to both classes of method.
In contexts where QR gives results that are numerically
more precise, I'd encourage them to examine the variance
inflation factors (they should examine them anyway).  It is
often a good idea, if the VIFs are large, to consider whether
there is a simple re-parameterization [perhaps as simple
as replacing x1 and x2 by (x1+x2) and (x1-x2)] where
correlations create less havoc.  This may be an important
issue for interpretation, even if the increased numerical
accuracy serves no useful purpose.

------------------------------------------------------------------------ 
------------------------------
> Date: Mon, 24 Feb 2003 13:50:31 -0500
> From: Chong Gu <chong at stat.purdue.edu>
>
>
> Not only it's unfair criticism, it's probably also imprecise
> information.
>
> For a detailed discussion of the precisions of regression estimates
> through QR-decomposition and normal equations, one may consult Golub
> and Van Loan's book on Matrix Computation (1989, Section 5.3.9 on page
> 230).  QR takes twice as much computation, requires more memory, but
> does NOT necessarily provide better precision.
>
> The above said, I am not questioning the adequacy of the QR approach
> to regression calculation as implemented in R.
>
>>
>> That's an unfair criticism. That discussion was never intended as
>> a recommendation for how to compute a regression. Of course, SVD or
>> QR decompositions are the preferred method but many newbies don't  
>> want to
>> digest all that right from the start. These are just obscure details  
>> to
>> the beginner.
>>
>> One of the strengths of R in teaching is that students can directly
>> implement the formulae from the theory. This reinforces the connection
>> between theory and practice. Implementing the normal equations  
>> directly
>> is a quick early illustration of this connection. Explaining the  
>> precise
>> details of how to fit a regression model is something that can be
>> deferred.
>>
>> Julian Faraway
>>
>>>> I am just about working through Faraways excellent tutorial  
>>>> "practical
>>>> regression and ANOVA using R"
>>>
>>> I assume this is a reference to the PDF version available via CRAN.  
>>> I am
>>> afraid that is *not* a good discussion of how to do regression,
>> especially
>>> not using R.  That page is seriously misleading: good ways to compute
>>> regressions are QR decompositions with pivoting (which R uses) or an  
>>> SVD.
>>> Solving the normal equations is well known to square the condition
>> number,
>>> and is close to the worse possible way.  (If you must use normal
>>> equations, do at least centre the columns, and preferably do some
>>> scaling.)
>>>
>>>> on page 24 he makes the x matrix:
>>>> x <- cbind(1,gala[,-c(1,2)])
>>>>
>>>> how can I understand this gala[,-c(1,2)])... I couldn't find an
>>>> explanation of such "c-like" abbreviations anywhere.
>>>
>>> Well, it is in all good books (as they say) including `An  
>>> Introduction to
>>> R'. (It's even on page 210 of that book!)
>>>
>>> -c(1,2) is (try it)
>>>
>>>> -c(1,2)
>>> [1] -1 -2
>>>
>>> so this drops columns 1 and 2.  It then adds in front a column made  
>>> up of
>>> ones, which is usually a sign of someone not really understanding how
>>> R's linear models work.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From p.dalgaard at biostat.ku.dk  Wed Feb 26 00:37:08 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Feb 26 00:37:08 2003
Subject: [R] Re: A tcltk question
In-Reply-To: <200302252120.QAA01483@blaise.dfci.harvard.edu>
References: <200302252120.QAA01483@blaise.dfci.harvard.edu>
Message-ID: <x2u1esvsjv.fsf@biostat.ku.dk>

John Zhang <jzhang at jimmy.harvard.edu> writes:

> Hi, 
> 
> I am trying to create a light-weight window with no border and title bar. The 
> following code does not work for me. 
> 
> base <- tktoplevel()
> tkwm.overrideredirect(base, TRUE) (or FALSE)
> 
> Could someone help me out? Thanks.

The point would seem to be that once the wm grabs the window there's
nothing you can do. Try for instance

tkwm.overrideredirect(tt<-tktoplevel(),1)

You might not like the effect though.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From bcmarc at uclink4.berkeley.edu  Wed Feb 26 03:21:03 2003
From: bcmarc at uclink4.berkeley.edu (AH)
Date: Wed Feb 26 03:21:03 2003
Subject: [R] error message
Message-ID: <3E5C24C0.9080506@uclink4.berkeley.edu>

Can someone tell me what this error means?  I have been unable to find 
the problem.

Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file `d://clss2003/s151b/data/applemo.txt'

thanks



From edd at debian.org  Wed Feb 26 03:28:02 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed Feb 26 03:28:02 2003
Subject: [R] error message
In-Reply-To: <3E5C24C0.9080506@uclink4.berkeley.edu>; from bcmarc@uclink4.berkeley.edu on Tue, Feb 25, 2003 at 06:21:52PM -0800
References: <3E5C24C0.9080506@uclink4.berkeley.edu>
Message-ID: <20030225202504.A3881@debian.org>

On Tue, Feb 25, 2003 at 06:21:52PM -0800, AH wrote:
> Can someone tell me what this error means?  I have been unable to find 
> the problem.
> 
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `d://clss2003/s151b/data/applemo.txt'

You asked to read a file, and what you told R about the file location
and name did not result in a successful operation -- in other words,
the could not be opened for R by the OS because what you tought was the
correct location ... was in fact wrong.

May be as easy as removing the second / to yield
'd:/clss2003/s151b/data/applemo.txt'

Dirk

-- 
Three out of two people have difficulties with fractions.



From ripley at stats.ox.ac.uk  Wed Feb 26 04:50:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb 26 04:50:03 2003
Subject: [R] error message
In-Reply-To: <3E5C24C0.9080506@uclink4.berkeley.edu>
Message-ID: <Pine.LNX.4.44.0302260348190.10025-100000@gannet.stats>

On Tue, 25 Feb 2003, AH wrote:

> Can someone tell me what this error means?  I have been unable to find 
> the problem.
> 
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `d://clss2003/s151b/data/applemo.txt'
                      ^^
That's not a valid path to a file on Windows 9x, at least.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From arc at arcriswell.com  Wed Feb 26 05:13:02 2003
From: arc at arcriswell.com (Andrew Criswell)
Date: Wed Feb 26 05:13:02 2003
Subject: [R] Odds ratio in fisher.test()
Message-ID: <003401c2dd4d$092316b0$4dd994cb@andrewhdh0e5oe>

Hello:

Please help me through my confusion. I am having trouble reconciling the
difference between what I believe is the conventional definition of an
odds ratio for a 2-by-2 table and the output produced by fisher.test()
in R. Consider the following example:

> Discrim <- matrix(c(1,10,24,17), 
+            nr = 2,
+            dimnames = list(AGE    = c('young', 'old'),
+                            EMPLOY = c('fired', 'kept')))
> Discrim
       EMPLOY
AGE     fired kept
  young     1   24
  old      10   17

The conventional odds ratio is computed as

> (1 * 17) / (24 * 10)
[1] 0.07083333

Why is it, when I use fisher.test(), I get an estimated odds ratio like
that reported below? There, the difference seems slight, but with other
cases it can be quite large.

> fisher.test(Discrim, alternative = 'two.sided')

        Fisher's Exact Test for Count Data

data:  Discrim 
p-value = 0.005242
alternative hypothesis: true odds ratio is not equal to 1 
95 percent confidence interval:
 0.001573963 0.606416320 
sample estimates:
odds ratio 
0.07407528


Thanks,
ANDREW



From zynnel at yahoo.com  Wed Feb 26 07:42:03 2003
From: zynnel at yahoo.com (Hi from Zynnel)
Date: Wed Feb 26 07:42:03 2003
Subject: [R] multiple plot overlay - dataframe
Message-ID: <20030226064101.69754.qmail@web11806.mail.yahoo.com>

I hope you could help me with this. I have a dataframe
with 5 columns, the first column determining the X
values, and the rest four determining four separate Y
vectors. How can I plot them on the same graph,
overlaying each other?
Thanks.

Elena Zheleva



From zynnel at yahoo.com  Wed Feb 26 07:51:03 2003
From: zynnel at yahoo.com (Hi from Zynnel)
Date: Wed Feb 26 07:51:03 2003
Subject: [R] waveform plotting
Message-ID: <20030226065005.70777.qmail@web11806.mail.yahoo.com>

Another question I have is what is the best plotting
to use if I want to get something like a waveform
produced from points.
Thanks.

Elena Zheleva



From hb at maths.lth.se  Wed Feb 26 08:05:03 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed Feb 26 08:05:03 2003
Subject: [R] multiple plot overlay - dataframe
In-Reply-To: <20030226064101.69754.qmail@web11806.mail.yahoo.com>
Message-ID: <000301c2dd65$581ebcc0$7341a8c0@alpha.wehi.edu.au>

Here's one idea:

df <- ...

# Create an empty plot big enough to fit all data points
xlim <- range(df[,1], na.rm=TRUE)
ylim <- range(df[,-1], na.rm=TRUE)
plot(NA, xlim=xlim, ylim=ylim, xlab="x", ylab="y")

# For each Y column, plot the data against the X column
for (k in 2:ncol(df))
  points(df[,1], df[,k], col=k-1)  # Works with lines() too!

and here is another one that assumes a scatter plot:

xs <- rep(df[,1], times=ncol(df)-1)
ys <- as.vector(as.matrix(df[,-1]))
col <- rep(1:5, each=nrow(df))
plot(xs,ys, col=col, xlab="x", ylab="y")

Hope that helps

Henrik Bengtsson

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Hi from Zynnel
> Sent: den 26 februari 2003 17:41
> To: r-help at stat.math.ethz.ch
> Subject: [R] multiple plot overlay - dataframe
> 
> 
> I hope you could help me with this. I have a dataframe
> with 5 columns, the first column determining the X
> values, and the rest four determining four separate Y
> vectors. How can I plot them on the same graph,
> overlaying each other?
> Thanks.
> 
> Elena Zheleva
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From petr.pikal at precheza.cz  Wed Feb 26 08:10:25 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed Feb 26 08:10:25 2003
Subject: [R] multiple plot overlay - dataframe
In-Reply-To: <20030226064101.69754.qmail@web11806.mail.yahoo.com>
Message-ID: <3E5C764A.23389.221804@localhost>

Hi

On 25 Feb 2003 at 22:41, Hi from Zynnel wrote:

> I hope you could help me with this. I have a dataframe
> with 5 columns, the first column determining the X
> values, and the rest four determining four separate Y
> vectors. How can I plot them on the same graph,
> overlaying each other?
It depends little bit on range of your Y values. If it is similar magnitude, then 
simple

matplot(your.df[,1],your.df[,3:6],type="l")

see
?matplot

will do it. But if the range of your Y values is big you have to do some 
"flattening" or to use subsequent plot commands with par(new=T).

See
?plot and ?par

> Thanks.
> 
> Elena Zheleva
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

Cheers.Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From zeileis at ci.tuwien.ac.at  Wed Feb 26 08:43:03 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Wed Feb 26 08:43:03 2003
Subject: [R] Odds ratio in fisher.test()
In-Reply-To: <003401c2dd4d$092316b0$4dd994cb@andrewhdh0e5oe>
References: <003401c2dd4d$092316b0$4dd994cb@andrewhdh0e5oe>
Message-ID: <200302260742.h1Q7gPOe021167@thorin.ci.tuwien.ac.at>

On Wednesday 26 February 2003 05:10, Andrew Criswell wrote:

> Hello:
>
> Please help me through my confusion. I am having trouble reconciling
> the difference between what I believe is the conventional definition
> of an odds ratio for a 2-by-2 table and the output produced by
> fisher.test()
>
> in R. Consider the following example:
> > Discrim <- matrix(c(1,10,24,17),
>
> +            nr = 2,
> +            dimnames = list(AGE    = c('young', 'old'),
> +                            EMPLOY = c('fired', 'kept')))
>
> > Discrim
>
>        EMPLOY
> AGE     fired kept
>   young     1   24
>   old      10   17
>
> The conventional odds ratio is computed as
>
> > (1 * 17) / (24 * 10)
>
> [1] 0.07083333
>
> Why is it, when I use fisher.test(), I get an estimated odds ratio
> like that reported below? There, the difference seems slight, but
> with other cases it can be quite large.


From michel.arnaud at cirad.fr  Wed Feb 26 08:53:04 2003
From: michel.arnaud at cirad.fr (Michel ARNAUD)
Date: Wed Feb 26 08:53:04 2003
Subject: [R] IDW (inverse distances weighted)
Message-ID: <3E5C708D.4AD11478@cirad.fr>

Hello
I would like to find the function IDW (inverse distances weighted).
Thanks for your help

--
Michel ARNAUD
CIRAD TA60/15
73, av. Jean Fran?ois Breton
34938 MONTPELLIER CEDEX 5
tel : 04 67 59 38 34
Fax : 04 67 59 38 38

-------------- next part --------------
A non-text attachment was scrubbed...
Name: michel.arnaud.vcf
Type: text/x-vcard
Size: 204 bytes
Desc: Carte pour Michel ARNAUD
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030226/022c8128/michel.arnaud.vcf

From ligges at statistik.uni-dortmund.de  Wed Feb 26 09:00:00 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Feb 26 09:00:00 2003
Subject: [R] R performance, labeling questions, etc.
In-Reply-To: <Pine.GSO.4.44.0302251343430.20403-101000@tvargas-u10.cisco.com>
References: <Pine.GSO.4.44.0302251343430.20403-101000@tvargas-u10.cisco.com>
Message-ID: <3E5C6E3F.30600@statistik.uni-dortmund.de>

Tony Vargas wrote:
> R helpers,
> 
> I am trying to add labels to my graphs.  I have a Perl Program which
> generates thousands of R files like the one attached.
> 
> My data files have 2 - 8 columns in them.  The first column of every data
> file is a header (Time) - which I want to have plotted against everything
> else.  My current formula just plots each column, which is fine, yet at
> the bottom for my labels I wind up with numbers.  What I would like to do
> is have R grab the Time label in increments of 144 data points and use
> that to label my X-axis instead of just plain numbers.  (Each data file
> has about 4400 columns).

You have somehow confused columns and rows. Anyway, you might want to 
use something like

  plot(..., xaxt="n")
  temp <- seq(1, length(Time), by = 144)
  axis(1, at = temp, labels = Time[temp])

Uwe Ligges


> I can kind of have R lable the bottom by chaning my plot to "plot(usr.cpu
> ~ Time), yet then the graphs take much, much longer to generate.
> 
> Worst case, I will use "plot(usr.cpu ~ Time)" - yet, anyone know why this
> would take a very, very long time?
> 
> Any ideas?
> 
> Thanks,
> 
> Tony
> 
> Tony Vargas
> Cisco Systems
> Engineering Computing Services
> (408) 525-4113
> tvargas at cisco.com



From jelozano at wanadoo.es  Wed Feb 26 09:07:03 2003
From: jelozano at wanadoo.es (Jose Lozano (MEGA))
Date: Wed Feb 26 09:07:03 2003
Subject: [R] multiple plot overlay - dataframe
In-Reply-To: <20030226064101.69754.qmail@web11806.mail.yahoo.com>
Message-ID: <E18nwNV-0001pq-00@smtp2.yaonline.es>

>I hope you could help me with this. I have a dataframe
>with 5 columns, the first column determining the X
>values, and the rest four determining four separate Y
>vectors. How can I plot them on the same graph,
>overlaying each other?

Use matplot() to plot several plots in the same window.

help(matplot) for more info.

Regards
Jose Lozano



From ligges at statistik.uni-dortmund.de  Wed Feb 26 09:14:18 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Feb 26 09:14:18 2003
Subject: [R] waveform plotting
In-Reply-To: <20030226065005.70777.qmail@web11806.mail.yahoo.com>
References: <20030226065005.70777.qmail@web11806.mail.yahoo.com>
Message-ID: <3E5C7396.3050209@statistik.uni-dortmund.de>

Hi from Zynnel wrote:
> Another question I have is what is the best plotting
> to use if I want to get something like a waveform
> produced from points.
> Thanks.
> 
> Elena Zheleva

Reading "An Introduction to R" carefully leads to
   plot(..., type = "l")

Uwe Ligges



From lehmann at puk.unibe.ch  Wed Feb 26 11:04:02 2003
From: lehmann at puk.unibe.ch (Christoph Lehmann)
Date: Wed Feb 26 11:04:02 2003
Subject: [R] plot as .ps file: where are the axes and labels gone
Message-ID: <1046253812.1284.9.camel@christophl>

Sorry, I am sure, this must be documented somewhere (but there are that
many docs and tutorials to scan for topics..., actually a great thing...
but if you are in a hurry..):

I want to save a plot as .ps (or .eps):

> postscript("plot1.eps", horizontal=FALSE,
onefile=FALSE,height=8,width=8,pointsize=10)
> plot(hpfit$fit,rstudent(hpfit),xlab="Fitted
Response",ylab="Studentized Residuals")

unfortunately, I cannot find the axes and labels in the .ps anymore.
where are they gone? how to fix it?

thanks a lot
christoph

-- 
Christoph Lehmann                            Phone:  ++41 31 930 93 83 
Department of Psychiatric Neurophysiology    Mobile: ++41 31 570 28 00
University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61 
Waldau                                            lehmann at puk.unibe.ch 
CH-3000 Bern 60            http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html



From ligges at statistik.uni-dortmund.de  Wed Feb 26 11:44:06 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Feb 26 11:44:06 2003
Subject: [R] plot as .ps file: where are the axes and labels gone
In-Reply-To: <1046253812.1284.9.camel@christophl>
References: <1046253812.1284.9.camel@christophl>
Message-ID: <3E5C9A8F.5030605@statistik.uni-dortmund.de>

Christoph Lehmann wrote:
> Sorry, I am sure, this must be documented somewhere (but there are that
> many docs and tutorials to scan for topics..., actually a great thing...
> but if you are in a hurry..):
> 
> I want to save a plot as .ps (or .eps):
> 
> 
>>postscript("plot1.eps", horizontal=FALSE,
> 
> onefile=FALSE,height=8,width=8,pointsize=10)
> 
>>plot(hpfit$fit,rstudent(hpfit),xlab="Fitted
> 
> Response",ylab="Studentized Residuals")
> 
> unfortunately, I cannot find the axes and labels in the .ps anymore.
> where are they gone? how to fix it?
> 
> thanks a lot
> christoph
> 

Well, it works for me with R-1.6.2 on WinNT 4.0 (you haven't told such 
relevant information), given you had closed the device with device.off().

Uwe Ligges



From lehmann at puk.unibe.ch  Wed Feb 26 13:05:03 2003
From: lehmann at puk.unibe.ch (Christoph Lehmann)
Date: Wed Feb 26 13:05:03 2003
Subject: [R] plot mutiple graphs in one .eps
Message-ID: <1046261078.1150.28.camel@christophl>

how can I use the following approach correctly to print all plots into
one .eps file? thanks for a hint, even a documentation describing it
easily:

> opar <- par(mfrow = c(4,4), pty= "s", oma = c(0, 0, 0, 0))
> postscript("bivreg01.eps")
> plot(CMEDV ~ CRIM, HousePrice)
> plot(CMEDV ~ ZN, HousePrice)
> plot(CMEDV ~ INDUS, HousePrice)
> plot(CMEDV ~ CHAS, HousePrice)
> plot(CMEDV ~ NOX, HousePrice)
> plot(CMEDV ~ RM, HousePrice)
> plot(CMEDV ~ AGE, HousePrice)
> plot(CMEDV ~ DIS, HousePrice)
> plot(CMEDV ~ RAD, HousePrice)
> plot(CMEDV ~ TAX, HousePrice)
> plot(CMEDV ~ PTRATIO, HousePrice)
> plot(CMEDV ~ B, HousePrice)
> plot(CMEDV ~ LSTAT, HousePrice)
> dev.off()

thanks
christoph
-- 
Christoph Lehmann                            Phone:  ++41 31 930 93 83 
Department of Psychiatric Neurophysiology    Mobile: ++41 31 570 28 00
University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61 
Waldau                                            lehmann at puk.unibe.ch 
CH-3000 Bern 60            http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html



From sundar.dorai-raj at pdf.com  Wed Feb 26 13:47:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed Feb 26 13:47:03 2003
Subject: [R] plot mutiple graphs in one .eps
References: <1046261078.1150.28.camel@christophl>
Message-ID: <3E5CB711.6010809@pdf.com>


Christoph Lehmann wrote:
> how can I use the following approach correctly to print all plots into
> one .eps file? thanks for a hint, even a documentation describing it
> easily:
> 
> 
>>opar <- par(mfrow = c(4,4), pty= "s", oma = c(0, 0, 0, 0))
>>postscript("bivreg01.eps")
>>plot(CMEDV ~ CRIM, HousePrice)
>>plot(CMEDV ~ ZN, HousePrice)
>>plot(CMEDV ~ INDUS, HousePrice)
>>plot(CMEDV ~ CHAS, HousePrice)
>>plot(CMEDV ~ NOX, HousePrice)
>>plot(CMEDV ~ RM, HousePrice)
>>plot(CMEDV ~ AGE, HousePrice)
>>plot(CMEDV ~ DIS, HousePrice)
>>plot(CMEDV ~ RAD, HousePrice)
>>plot(CMEDV ~ TAX, HousePrice)
>>plot(CMEDV ~ PTRATIO, HousePrice)
>>plot(CMEDV ~ B, HousePrice)
>>plot(CMEDV ~ LSTAT, HousePrice)
>>dev.off()
> 
> 
> thanks
> christoph


Place the postscript() before the call to par():

postscript("bivreg01.eps")
opar <- par(mfrow = c(4,4), pty= "s", oma = c(0, 0, 0, 0))
...
par(opar)
dev.off()


Sundar



From cg.pettersson at evp.slu.se  Wed Feb 26 13:56:02 2003
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Wed Feb 26 13:56:02 2003
Subject: [R] na.action in model.tables and TukeyHSD
Message-ID: <200302261255.NAA18523@mail1.slu.se>

Hello everybody!

I use R 1.6.2 in Windows, and have a problem controlling the na.action.

In a dataset with twelve trials, one of the trials lack any readings of the variable "STS.SH" (standing power at harvest)

Fitting an aov() object with the call:
led1t7sts.aov <- aov(STS.SH ~ Trial/Block + Treatment + Treatment:Trial, data = led1t7, na.action=na.exclude)  
seems to work as it produces an object with 10 df for the factor "Trial".

But when I use model.tables or TukeyHSD on the object I get this:
> model.tables(led1t7sts.aov, "means")
Error in replications(paste("~", paste(names(tables), collapse = "+")),  : 
        na.action must be a function

I have tried to use "na.action=na.exclude" inside the model.tables call as well, without any bettering.

I can naturally cope with the problem by taking the whole trial away from the dataset, but it doesn?t feel very sophisticated...;-)
(Prof. Ripley answered a similar question from me two weeks ago. The answer was good but didn?t work as the reason of the error was the same as this time: a whole 
trial with only na:s in it).

Thanks
/CG
CG Pettersson
cg.pettersson at evp.slu.se



From ripley at stats.ox.ac.uk  Wed Feb 26 14:59:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Feb 26 14:59:02 2003
Subject: [R] Exporting Splus Data to R
In-Reply-To: <CFA6739DD532764AA51E7459970BF0E205D0AB0A@ns-bco-mse3.im.battelle.org>
Message-ID: <Pine.LNX.4.44.0302261354210.1278-100000@gannet.stats>

On Tue, 25 Feb 2003, Paul, David  A wrote:

> Using 
> 
> > data.dump(c("foo.frame.1","foo.frame.2", ...), file="DumpData",
> oldStyle=T)
> 
> in Splus generates the requisite file in my working Splus directory.
> However, when I use
> 
> > library(foreign)
> > data.restore(file = "C:/.../DumpData",verbose = TRUE, env = .GlobalEnv)
> 
> I get the error messages
> 
> Error in as.name(name) : attempt to use zero-length variable name
> In addition: Warning messages: 
> 1: NAs introduced by coercion 
> 2: NAs introduced by coercion 
> 3: NAs introduced by coercion 
> 
> and not all of the Splus dataframes are imported into R (though some of them
> are).
> Any suggestions would be greatly appreciated.  I am using R version 1.6.1 on
> Windows 2000, Splus version 6.1 on Windows 2000.

?data.restore does say

    ... S-PLUS on either Windows (versions 3.x, 4.x, 2000) ...

and we are not sure that data.dump(oldStyle=T) generates the same format: 
it looks from your example that it does not.  If you could make an example 
available we could try to crack the differences.

If you want to transfer data frames, why not use dump and source?  That 
has worked for me.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lehmann at puk.unibe.ch  Wed Feb 26 15:39:03 2003
From: lehmann at puk.unibe.ch (Christoph Lehmann)
Date: Wed Feb 26 15:39:03 2003
Subject: [R] calculationg condition numbers
Message-ID: <1046270279.1202.4.camel@christophl>

am I right in the assumption, that for calculation of the condition
numbers I have to use the correlation matrix of X, and not t(x) %*% x?

> e <- eigen(t(x) %*% x)

better (x must not have a first column of ones): 
> e <- eigen(cor(x))


> e$val
[1] 6.6653e+07 2.0907e+05 1.0536e+05 1.8040e+04 2.4557e+01 2.0151e+00
> sqrt(e$val[1]/e$val)
[1] 1.000 17.855 25.153 60.785 1647.478 5751.216

thanks

christoph
-- 
Christoph Lehmann                            Phone:  ++41 31 930 93 83 
Department of Psychiatric Neurophysiology    Mobile: ++41 76 570 28 00
University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61 
Waldau                                            lehmann at puk.unibe.ch 
CH-3000 Bern 60            http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html



From maechler at stat.math.ethz.ch  Wed Feb 26 16:35:03 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Feb 26 16:35:03 2003
Subject: [R] calculationg condition numbers
In-Reply-To: <1046270279.1202.4.camel@christophl>
References: <1046270279.1202.4.camel@christophl>
Message-ID: <15964.56949.492314.571784@gargle.gargle.HOWL>

>>>>> "ChrisL" == Christoph Lehmann <lehmann at puk.unibe.ch>
>>>>>     on Wed, 26 Feb 2003 15:37:58 +0100 writes:

    ChrisL> am I right in the assumption, that for calculation
    ChrisL> of the condition numbers I have to use the
    ChrisL> correlation matrix of X, and not t(x) %*% x?

not quite.
R has a kappa() with several variants/methods for computing
condition numbers, as  help.search() shows quickly.
If I do

  > help.search("condition number")
  Help files with alias or title matching 'condition number',
  type 'help(FOO, package = PKG)' to inspect entry 'FOO(PKG) TITLE':

  rcond(Matrix)           Estimate the Reciprocal Condition Number
  kappa(base)             Estimate the Condition Number

I see that the CRAN package Matrix has even more

    >> e <- eigen(t(x) %*% x)

using the SVD directly is better...

    ChrisL> better (x must not have a first column of ones): 
    >> e <- eigen(cor(x))


    >> e$val
    ChrisL> [1] 6.6653e+07 2.0907e+05 1.0536e+05 1.8040e+04 2.4557e+01 2.0151e+00
    >> sqrt(e$val[1]/e$val)
    ChrisL> [1] 1.000 17.855 25.153 60.785 1647.478 5751.216

    ChrisL> thanks

    ChrisL> christoph
    ChrisL> -- 
    ChrisL> Christoph Lehmann                            Phone:  ++41 31 930 93 83 
    ChrisL> Department of Psychiatric Neurophysiology    Mobile: ++41 76 570 28 00
    ChrisL> University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61 
    ChrisL> Waldau                                            lehmann at puk.unibe.ch 
    ChrisL> CH-3000 Bern 60            http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html

    ChrisL> ______________________________________________
    ChrisL> R-help at stat.math.ethz.ch mailing list
    ChrisL> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From elvis at xlsolutions-corp.com  Wed Feb 26 18:05:03 2003
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Wed Feb 26 18:05:03 2003
Subject: [R] COURSE***R/S-plus Fundamentals and Programming Techniques***March 2003/Boston
Message-ID: <1046279878.3e5cf6c671b84@email.featureprice.com>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud
to announce a 2-day course: "R/S-plus Fundamentals and Programming Techniques".

****Boston, MA-----------------> March 13-14


Course Description:

This two-day R/S-plus course focuses on a broad spectrum of topics, 
from reading raw data to a comparison of R and S. We will learn 
the essentials of data manipulation, graphical visualization 
and R/S-plus programming. We will explore statistical data analysis tools,
including graphics with data sets. How to enhance your plots.
We will perform basic statistics and fit linear regression models. 
Participants are encouraged to bring data for interactive sessions


Course Outline:

- An Overview of R: Installation and Demonstration
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling 
- Generalized Linear Models
- Linear Regression
- Parametric Models, etc
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)



Payments are due AFTER the course and early-bird ends February 28.

Registration:

Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578 x221
Visit us: www.xlsolutions-corp.com/training.htm


Course Format:

This course consists of a series of short lectures with
demonstrations and interactive sessions for the participants.
Each student is provided with bound copies of the notes and
a CD-ROM containing all examples, exercises and software used
on the course.



Share Your Thoughts:

Are there any additional topics you would like for this course to address?
Would you like for this course to be offered in another city?

Please let us know by contributing to our recommendation list:
training at xlsolutions-corp.com.

========================================================================

R/S-Plus Fundamentals and Programming Techniques / Boston March 2003
Pre-registration Form (Please email or print and fax: 206-686-1578)
XLsolutions Corporation: For your Solutions needs, Consulting and Training.
www.xlsolutions-corp.com



Title...... First Name ................. Last Name....................

Organization..........................................................

Mailing Address.......................................................

.....................................................................

.....................................................................

Zip Code...................... Country.............................

Telephone........................... Fax ...............................

E-mail................................................................



Elvis Miller, PhD
Manager Training and Technical Support
North American Division
XLSolutions Corporation
Email: elvis at xlsolutions-corp.com
Phone: 206-686-1578
Web: www.xlsolutions-corp.com



From MSRYJHN2 at stud.man.ac.uk  Wed Feb 26 18:17:03 2003
From: MSRYJHN2 at stud.man.ac.uk (Haitham Nobanee)
Date: Wed Feb 26 18:17:03 2003
Subject: [R] help in writong an EViews programme
Message-ID: <3E5CF64A.27028.38779165@localhost>

Dear all,

I have a daily date for 1283 companies listed in Tokyo Stock 
Exchange.  My data covers the periods 1990-2002. I need to 
write an EVIEWS programme in order to run the E-GARCH 
(1.1) IN MEAN. My variables are: X the independent variable, 
which is the closing price for the market index.  The dependent 
variables are:  (closing prices for the companies) Y1, Y2, 
Y3
Y1283. I need to run the E-GARCH (1.1) IN MEAN 
model 1283 times for each year; I have 13years and 1283 
company. The dependent variables are Y1, Y2, Y3
Y1283 
and the independent variable is X. 


I need to have the coefficient of E-GARCH (1.1) IN MEAN, 
and the BETA coefficient in separate columns for all the 
companies.


I can either run the model for all the companies once or 
separating them in different groups, and then to run the 
programme several times. 

Is there any mailing list for the EViews users?

Thank you for your kindly co-operation and I am looking 
forward to hearing from you.


Yours sincerely,


Haitham Nobanee



From Jim_Garrett at bd.com  Wed Feb 26 18:29:03 2003
From: Jim_Garrett at bd.com (Jim_Garrett@bd.com)
Date: Wed Feb 26 18:29:03 2003
Subject: [R] Re: R-help digest, Vol 1 #89 - 53 msgs
Message-ID: <OF1EBDCEE9.66B51D44-ON85256CD9.0056ADAC@bd.com>


I couldn't resist tossing in my two-cents' worth on this, because R has
some language features that allow you to use efficient optimization
routines in a straightforward, elegant way.  I'm particularly enthusiastic
about this because I have suffered through other languages, which made this
approach either painful or impossible, depending on the problem.  Thanks to
the R development team for their great work!

Jose has offered a "brute force" approach, evaluating distance on a fine
grid of points.  This certainly is very robust.  However, using an
optimization routine can lead to fewer evaluations than evaluating on a
fine grid of points, and can give resolution that is finer than the grid.
You may wish to combine the two, and start the optimization from a grid of
starting points.  This grid need not be very fine, though.  And in the
one-dimensional case, the "optimize" function appears to be very robust
(perhaps it already incorporates this strategy).

For any search to work, You need to have the curve be "parameterized" in
some sense, allowing you to identify an infinite number of points lying on
the curve as you vary some underlying parameter.  For instance, perhaps
you've fitted a nonparametric regression model allowing you to make
predictions for any point x.  Or you have some means to calculate a y
value, given any x (such that x is on the curve).

The overall strategy I'm enthusiastic about is to create a loss function
that's specific to the point in question, and then use an optimization
routine to, well, optimize.  And because you'll want to do this again and
again, for convenience you can write a function that makes point-specific
loss functions (this is the part that is so straightforward to R, relative
to many other languages).

Here's an example:

example.data <- data.frame(x = seq(-1, 1, length = 200))
set.seed(123)
example.data$y <- example.data$x^2 + rnorm(200, sd = 0.2)
library(modreg)
example.spline <- smooth.spline(example.data)
plot(example.data)
lines(example.spline)
X1 <- c(0.25, 0.75)
points(X1[1], X1[2], pch = "x")

# What's the point on the curve defined by example.spline
# that's closest to X1?

# Euclidean distance
MyDistance <- function(x1, x2)
  {
    sqrt(sum((x2 - x1)^2))
  }

# For convenient re-use, a function that makes point-specific loss
functions.
# (For some model objects, the predict method requires something
# like "predict(CurveObject, newdata = data.frame(x = s))".)
MakeLoss <- function(x, CurveObject)
  {
    function(s) MyDistance(x, c(s, predict(CurveObject, s)$y))
  }

# Now make the loss function for X1...
MyLoss <- MakeLoss(X1, example.spline)

# ...and optimize.  For a higher-dimensional problem, use "optim"
# rather than "optimize".
closest.x <- optimize(MyLoss, interval = c(-1, 1))$minimum
lines(c(X1[1], closest.x),
      c(X1[2], predict(example.spline, closest.x)$y))

Good luck!

-Jim Garrett
Becton Dickinson Diagnostic Systems
Baltimore, Maryland, USA


**********************************************************************
This message is intended only for the designated recipient(s).   ... [[dropped]]



From ripley at stats.ox.ac.uk  Wed Feb 26 19:30:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed Feb 26 19:30:03 2003
Subject: [R] R performance, labeling questions, etc.
In-Reply-To: <Pine.GSO.4.44.0302251343430.20403-101000@tvargas-u10.cisco.com>
Message-ID: <Pine.GSO.4.44.0302261820320.20799-100000@auk.stats>

On Tue, 25 Feb 2003, Tony Vargas wrote:

> R helpers,
>
> I am trying to add labels to my graphs.  I have a Perl Program which
> generates thousands of R files like the one attached.
>
> My data files have 2 - 8 columns in them.  The first column of every data
> file is a header (Time) - which I want to have plotted against everything
> else.  My current formula just plots each column, which is fine, yet at
> the bottom for my labels I wind up with numbers.  What I would like to do
> is have R grab the Time label in increments of 144 data points and use
> that to label my X-axis instead of just plain numbers.  (Each data file
> has about 4400 columns).

Call plot() with xaxt="n", then call axis() to add the labels you want.
You can use plot.POSIXct as a model.

> I can kind of have R lable the bottom by chaning my plot to "plot(usr.cpu
> ~ Time), yet then the graphs take much, much longer to generate.

I presume that Time is a character variable, so a lot of conversion is goin
on: but we are short on details here.

> Worst case, I will use "plot(usr.cpu ~ Time)" - yet, anyone know why this
> would take a very, very long time?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From stormplot at hotmail.com  Wed Feb 26 20:58:03 2003
From: stormplot at hotmail.com (Jason Fisher)
Date: Wed Feb 26 20:58:03 2003
Subject: [R] DLL Advice
Message-ID: <F188437bIRopN51b7Kt0000dfb4@hotmail.com>

Hi All...

A few questions concerning the use of DLLs in R.  Before you get scared off 
and dont read any further (Ive seen a lot of talk within the help pages 
concerning loading DLLs in R) realize that communication between R and my 
DLLs is solid.  The problem arises when comparing the computational 
performance between calling a *.dll file, compiled using g77 under MinGW 
version 2.0.0 with package upgrades, and calling an *.exe file, compiled 
with Compaq Visual FORTRAN Professional Edition 6.6.A.  Both calls (.Fortran 
and system) are made from the R - Tcl/Tk GUI environment.  After comparing 
identical code, compiled as a DLL and EXE, Ive come to the disappointing 
realization that the DLL calls take about five times the computational time 
of the EXE calls.  I tried the experiment using a number of different 
FORTRAN codes with the same results.

My first thought was that I was compiling the code incorrectly.  The 
following command is what I typically use to generate the DLL.

g77 shared o temp.dll temp.f

After a short search over the net, I discovered a number of g77 optimization 
options (e.g. O, O2) for compiling.  These options had little to no impact 
on the computational times.  Next, I went back to Writing R Extensions and 
started working with the Rcmd SHLIB.  This again had little to no impact on 
computational time.

Any ideas, Im a novice at working with DLLs and know there must be 
something Im missing.  One option is to just call the EXE, however, it just 
seems crummy to generate an input file in R, run the EXE which produces an 
output file, read the EXE output file in R, and finally delete the input  
and output files.

Thanks in advance for any insightful knowledge you bring my way.

Regards,
Jason

R 1.6.2

***************************************
Jason C. Fisher
UCLA Graduate Student
Civil & Environmental Engineering Dept.
5731 Boelter Hall
Box 951593
Los Angeles, CA 90095-1593
Phone Number: (310) 825-2292
Email: stormplot at hotmail.com



From tord.snall at ebc.uu.se  Wed Feb 26 21:07:07 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Wed Feb 26 21:07:07 2003
Subject: [R] colours change in barplot
Message-ID: <3.0.6.32.20030226210815.00c44268@mail.anst.uu.se>

Dear all,

I use the code below for my barplot and it looks fine on my screen. But
when I paste into my MSWord file, after having copied it by presing the
camera, the colours change. The same actually happens when I change the
size of the R Graphics Device window by dragging the corners.

Could someone please help with this.

I use R 1.6.2 on Win XP.

Thanks in advance!


Sincerely,
Tord Sn?ll

par(mar=c(5, 12, 1, 2), mai=c(1, 2.2, 0.01, 0.2), xpd=NA) # yttre kanterna
och plotting ?ven i Margin V&R, sid 66
(palette(gray(seq(0,.9,len=25)))) # gray scales; print old palette
barplot(as.matrix(t(nedbr[nedbr$fran.lan == "X", c("nedbr1volS.ha",
"nedbr2volS.ha", "nedbr3volS.ha", "nedbr4volS.ha", "nedbr5volS.ha")])), 
        names.arg = as.vector(nedbr[nedbr$fran.lan == "X", "Objektnamn"]),  
        horiz=T, las=1, cex.names=0.8, xlab="Volym m3/ha", xlim=c(0,100),
col=c(25,21,17,14,10))

legend(locator(1), c("Nedbrytning 1 (<10%)", "Nedbrytning 2 (10-25%)",
"Nedbrytning 3 (25-50%)", 
        "Nedbrytning 4 (50-75%)", "Nedbrytning 5 (75-100%)"),
fill=c(25,21,17,14,10), cex=0.75)
palette("default")      # reset back to the default


-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From hugovanwoerkom at care2.com  Wed Feb 26 21:32:03 2003
From: hugovanwoerkom at care2.com (hugo vanwoerkom)
Date: Wed Feb 26 21:32:03 2003
Subject: [R] COURSE***R/S-plus Fundamentals and Programming Techniques***March 2003/Boston
Message-ID: <E6BA80E9445B16642ABA8960F8A5B527@hugovanwoerkom.care2.com>

XLSolutions Corporation
(www.xlsolutions-corp.com) is proud
to announce a 2-day course: "R/S-plus
Fundamentals and Programming Techniques".

****Boston, MA-----------------> March 13-14
<...>
Did I miss the price of the course?
Hugo.


Find out who's green and who's not! Use Care2's Green Thumbs-up!
http://www.care2.com/go/z/4029



From andy_liaw at merck.com  Wed Feb 26 21:51:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Feb 26 21:51:03 2003
Subject: FW: [R] DLL Advice
Message-ID: <3A822319EB35174CA3714066D590DCD534BD32@usrymx25.merck.com>

For those who are interested.  Anyone care to comment?  I have no idea the
performance gap on simple i/o can be that big...

Andy

From: Jason Fisher [mailto:stormplot at hotmail.com]
Sent: Wednesday, February 26, 2003 3:44 PM
To: andy_liaw at merck.com
Subject: RE: [R] DLL Advice


Hi Andy...

Comparing apples to apples really clarified things.

g77 -> 58 seconds to run
Visual FORTRAN -> 3.5 seconds to run

Wow!

I bet g77 and Visual FORTRAN handle read statements differently.  My program

is pretty simplistic.  Open a massive text file (323,063 KB) and read a few 
key pieces of information spread evenly throughout the file.

Thanks Again,
J



***************************************
Jason C. Fisher
UCLA Graduate Student
Civil & Environmental Engineering Dept.
5731 Boelter Hall
Box 951593
Los Angeles, CA 90095-1593
Phone Number: (310) 825-2292
Email: stormplot at hotmail.com
***************************************





>From: "Liaw, Andy" <andy_liaw at merck.com>
>To: "'Jason Fisher'" <stormplot at hotmail.com>
>Subject: RE: [R] DLL Advice
>Date: Wed, 26 Feb 2003 15:10:24 -0500
>
>You may want to try comparing apple to apple first.  Try compiling your 
>code
>to .exe using the MinGW g77 and see how that fares with the .exe you get
>with Visual Fortran.  I strongly suspect that what you're seeing is due in
>large part to the difference in g77 and visual fortran.
>
>g77 is known to be at best OK when it comes to performance.  The problem is
>that on Windows you don't have much of a choice.
>
>Andy
>
> > -----Original Message-----
> > From: Jason Fisher [mailto:stormplot at hotmail.com]
> > Sent: Wednesday, February 26, 2003 2:57 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] DLL Advice
> >
> >
> > Hi All...
> >
> > A few questions concerning the use of DLLs in R.  Before you
> > get scared off
> > and don't read any further (I've seen a lot of talk within
> > the help pages
> > concerning loading DLLs in R) realize that communication
> > between R and my
> > DLLs is solid.  The problem arises when comparing the computational
> > performance between calling a *.dll file, compiled using g77
> > under MinGW
> > version 2.0.0 with package upgrades, and calling an *.exe
> > file, compiled
> > with Compaq Visual FORTRAN Professional Edition 6.6.A.  Both
> > calls (.Fortran
> > and system) are made from the R - Tcl/Tk GUI environment.
> > After comparing
> > identical code, compiled as a DLL and EXE, I've come to the
> > disappointing
> > realization that the DLL calls take about five times the
> > computational time
> > of the EXE calls.  I tried the experiment using a number of different
> > FORTRAN codes with the same results.
> >
> > My first thought was that I was compiling the code incorrectly.  The
> > following command is what I typically use to generate the DLL.
> >
> > g77 -shared -o temp.dll temp.f
> >
> > After a short search over the net, I discovered a number of
> > g77 optimization
> > options (e.g. -O, -O2) for compiling.  These options had
> > little to no impact
> > on the computational times.  Next, I went back to "Writing R
> > Extensions" and
> > started working with the Rcmd SHLIB.  This again had little
> > to no impact on
> > computational time.
> >
> > Any ideas, I'm a novice at working with DLLs and know there must be
> > something I'm missing.  One option is to just call the EXE,
> > however, it just
> > seems crummy to generate an input file in R, run the EXE
> > which produces an
> > output file, read the EXE output file in R, and finally
> > delete the input
> > and output files.
> >
> > Thanks in advance for any insightful knowledge you bring my way.
> >
> > Regards,
> > Jason
> >
> > R 1.6.2
> >
> > ***************************************
> > Jason C. Fisher
> > UCLA Graduate Student
> > Civil & Environmental Engineering Dept.
> > 5731 Boelter Hall
> > Box 951593
> > Los Angeles, CA 90095-1593
> > Phone Number: (310) 825-2292
> > Email: stormplot at hotmail.com
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>---------------------------------------------------------------------------
---
>Notice: This e-mail message, together with any attachments, contains 
>information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that

>may be confidential, proprietary copyrighted and/or legally privileged, and

>is intended solely for the use of the individual or entity named on this 
>message. If you are not the intended recipient, and have received this 
>message in error, please immediately return this by e-mail and then delete 
>it.
>
>===========================================================================
===
>


_________________________________________________________________




------------------------------------------------------------------------------



From den.duurs at lycos.com  Wed Feb 26 22:04:02 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Wed Feb 26 22:04:02 2003
Subject: [R] horizontal high-density lines?
Message-ID: <FJDKPKDGBCLJJDAA@mailcity.com>

Hi all,

the option type="h" in plot() makes nice vertical (histogram-like) lines. Is there a way to make similar, horizontal lines?

I can of course resort to using lines() multiple times, but i was hoping that there is a more elegant solution.

thanks,

Remko Duursma



Ph.D. student
Dept. Forest Resources
Forest Biometrics Lab
University of Idaho, Moscow, ID.



From tblackw at umich.edu  Wed Feb 26 22:46:02 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed Feb 26 22:46:02 2003
Subject: [R] horizontal high-density lines?
In-Reply-To: <FJDKPKDGBCLJJDAA@mailcity.com>
Message-ID: <Pine.SOL.4.44.0302261640240.3760-100000@timepilot.gpcc.itd.umich.edu>


On Wed, 26 Feb 2003, Remko Duursma wrote:

> Hi all,
>
> the option type="h" in plot() makes nice vertical (histogram-like)
> lines. Is there a way to make similar, horizontal lines?  I can
> of course resort to using lines() multiple times, but i was hoping
> that there is a more elegant solution.

Yes - turn your head sideways.  But, seriously, for hardcopy plots
I have been known to rotate all the text and all the labels, and use
axis() commands to reverse the left-to-right ordering of labels along
an axis, in order to get a plot that I could turn sideways after it
was printed.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

>
> thanks,
>
> Remko Duursma
>
>
>
> Ph.D. student
> Dept. Forest Resources
> Forest Biometrics Lab
> University of Idaho, Moscow, ID.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From spencer.graves at pdf.com  Wed Feb 26 23:23:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed Feb 26 23:23:03 2003
Subject: [R] horizontal high-density lines?
References: <Pine.SOL.4.44.0302261640240.3760-100000@timepilot.gpcc.itd.umich.edu>
Message-ID: <3E5D3DEC.1030604@pdf.com>

What about 'plot(1:4, type="s")'?

Is this what you want?
Spencer Graves

Thomas W Blackwell wrote:
> 
> On Wed, 26 Feb 2003, Remko Duursma wrote:
> 
> 
>>Hi all,
>>
>>the option type="h" in plot() makes nice vertical (histogram-like)
>>lines. Is there a way to make similar, horizontal lines?  I can
>>of course resort to using lines() multiple times, but i was hoping
>>that there is a more elegant solution.
> 
> 
> Yes - turn your head sideways.  But, seriously, for hardcopy plots
> I have been known to rotate all the text and all the labels, and use
> axis() commands to reverse the left-to-right ordering of labels along
> an axis, in order to get a plot that I could turn sideways after it
> was printed.
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> 
>>thanks,
>>
>>Remko Duursma
>>
>>
>>
>>Ph.D. student
>>Dept. Forest Resources
>>Forest Biometrics Lab
>>University of Idaho, Moscow, ID.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From sagarwal at cs.berkeley.edu  Thu Feb 27 04:18:03 2003
From: sagarwal at cs.berkeley.edu (Sharad Agarwal)
Date: Thu Feb 27 04:18:03 2003
Subject: [R] epoch time conversion in R
Message-ID: <3E5D835D.5090808@cs.berkeley.edu>

I have a data file where each entry is indexed by the time in seconds since 
epoch (e.g. 1046315697). Is there an easy way to convert this time value into 
a more friendly time (such as Month-Year) when plotting it?

I searched through the manual, mailing lists, and functions like as.POSIXct 
and strptime, but didn't find what I need.

Thanks,
Sharad.



From jlvw at rau.ac.za  Thu Feb 27 06:12:04 2003
From: jlvw at rau.ac.za (Jacob van Wyk)
Date: Thu Feb 27 06:12:04 2003
Subject: [R] PRESS
Message-ID: <se5dba2c.037@rauzen.rau.ac.za>

Hallo

Can anybody please help? How can I get the PRESS (predicted sum of
squares) criterion in R?

Thank you
Jacob


Jacob L van Wyk
Department of Mathematics and Statistics
Rand Afrikaans University
P O Box 524
Auckland Park 2006
South Africa
Tel: +27-11-489-3080
Fax: +27-11-489-2832


______________________________________

VRYWARING                                                                                         

Die inhoud en enige aanhegsels van hierdie elektroniese posboodskap is
vertroulik en net vir die genoemde geadresseerdes bedoel.

Verspreiding, aanstuur, publikasie of enige gebruik van die boodskap of
aanhegsels deur enige ongemagtigde persoon is streng verbode.

Die menings wat in hierdie boodskap uitgedruk word, tensy anders
vermeld, is die van die skrywer en nie van die Randse Afrikaanse
Universiteit of sy Bestuur nie.

Gebruikersbeleide van die Randse Afrikaanse Universiteit is beskikbaar
by:
http://www.rau.ac.za/disclaimer                                                                    

DISCLAIMER\ \ The contents and any attachments of this electroni ... [[dropped]]



From jerome at hivnet.ubc.ca  Thu Feb 27 08:14:07 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Thu Feb 27 08:14:07 2003
Subject: [R] epoch time conversion in R
In-Reply-To: <3E5D835D.5090808@cs.berkeley.edu>
References: <3E5D835D.5090808@cs.berkeley.edu>
Message-ID: <200302270718.XAA02722@hivnet.ubc.ca>

Install the "chron" package. Then convert the seconds into days...
Also have a look at the help file for chron().

Below is an example.

Cheers,
Jerome

library(chron)
epoch <- c(month=3,day=23,year=1935)
data.seconds <- 1046315697+(0:10)*60*60*24
data.days <- data.seconds/(60*60*24)
fulldate <- chron(data.days,origin.=epoch)
date.only <- chron(floor(data.days),out.format="mon-day-year",origin.=epoch)
plot(date.only,xlab="Date")


On Wednesday 26 February 2003 19:17, Sharad Agarwal wrote:
> Content-Length: 493
> Status: R
> X-Status: N
>
> I have a data file where each entry is indexed by the time in seconds since
> epoch (e.g. 1046315697). Is there an easy way to convert this time value
> into a more friendly time (such as Month-Year) when plotting it?
>
> I searched through the manual, mailing lists, and functions like as.POSIXct
> and strptime, but didn't find what I need.
>
> Thanks,
> Sharad.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 

Jerome Asselin (J?r?me)
Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital
608 - 1081 Burrard Street
Vancouver, British Columbia
CANADA V6Z 1Y6

Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044



From ligges at statistik.uni-dortmund.de  Thu Feb 27 08:30:04 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Feb 27 08:30:04 2003
Subject: [R] horizontal high-density lines?
In-Reply-To: <FJDKPKDGBCLJJDAA@mailcity.com>
References: <FJDKPKDGBCLJJDAA@mailcity.com>
Message-ID: <3E5DBE78.70500@statistik.uni-dortmund.de>

Remko Duursma wrote:
> Hi all,
> 
> the option type="h" in plot() makes nice vertical (histogram-like) lines. Is there a way to make similar, horizontal lines?
> 
> I can of course resort to using lines() multiple times, but i was hoping that there is a more elegant solution.
> 
> thanks,
> 
> Remko Duursma

I guess you are looking for ?segments.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Thu Feb 27 08:51:02 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Feb 27 08:51:02 2003
Subject: [R] colours change in barplot
In-Reply-To: <3.0.6.32.20030226210815.00c44268@mail.anst.uu.se>
References: <3.0.6.32.20030226210815.00c44268@mail.anst.uu.se>
Message-ID: <3E5DC36A.9010004@statistik.uni-dortmund.de>

Tord Snall wrote:
> Dear all,
> 
> I use the code below for my barplot and it looks fine on my screen. But
> when I paste into my MSWord file, after having copied it by presing the
> camera, the colours change. The same actually happens when I change the
> size of the R Graphics Device window by dragging the corners.
> 
> Could someone please help with this.
> 
> I use R 1.6.2 on Win XP.
> 
> Thanks in advance!

I cannot reproduce such an behaviour on WinNT 4.0.
Could you provide an example which we can reproduce, please?
(preferable using data like 1:10 ...)

Uwe Ligges



> Sincerely,
> Tord Sn?ll
> 
> par(mar=c(5, 12, 1, 2), mai=c(1, 2.2, 0.01, 0.2), xpd=NA) # yttre kanterna
> och plotting ?ven i Margin V&R, sid 66
> (palette(gray(seq(0,.9,len=25)))) # gray scales; print old palette
> barplot(as.matrix(t(nedbr[nedbr$fran.lan == "X", c("nedbr1volS.ha",
> "nedbr2volS.ha", "nedbr3volS.ha", "nedbr4volS.ha", "nedbr5volS.ha")])), 
>         names.arg = as.vector(nedbr[nedbr$fran.lan == "X", "Objektnamn"]),  
>         horiz=T, las=1, cex.names=0.8, xlab="Volym m3/ha", xlim=c(0,100),
> col=c(25,21,17,14,10))
> 
> legend(locator(1), c("Nedbrytning 1 (<10%)", "Nedbrytning 2 (10-25%)",
> "Nedbrytning 3 (25-50%)", 
>         "Nedbrytning 4 (50-75%)", "Nedbrytning 5 (75-100%)"),
> fill=c(25,21,17,14,10), cex=0.75)
> palette("default")      # reset back to the default
> 
> 
> -----------------------------------------------------------------------
> Tord Sn?ll
> Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
> Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
> Villav?gen 14			
> SE-752 36 Uppsala, Sweden
> Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
> Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
> Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
> E-mail: Tord.Snall at ebc.uu.se
> Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tord.snall at ebc.uu.se  Thu Feb 27 11:25:03 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Thu Feb 27 11:25:03 2003
Subject: [R] colours change in barplot
In-Reply-To: <3E5DC36A.9010004@statistik.uni-dortmund.de>
References: <3.0.6.32.20030226210815.00c44268@mail.anst.uu.se>
 <3.0.6.32.20030226210815.00c44268@mail.anst.uu.se>
Message-ID: <3.0.6.32.20030227112756.00c58af8@mail.anst.uu.se>

Dear Uwe,

When I prepred simple code I found the problem:
I had executed the row 
palette("default")      
and after that I copied and dragged the R Graphics Device window. 

If I copy and drag after having executed the line before 
( fill=c(25,21,17,14,10), cex=0.75) )
everything looks fine.

Thanks for, as always, quick responses on this list!


Sincerely,
Tord



At 08:51 2/27/2003 +0100, Uwe Ligges wrote:
>Tord Snall wrote:
>> Dear all,
>> 
>> I use the code below for my barplot and it looks fine on my screen. But
>> when I paste into my MSWord file, after having copied it by presing the
>> camera, the colours change. The same actually happens when I change the
>> size of the R Graphics Device window by dragging the corners.
>> 
>> Could someone please help with this.
>> 
>> I use R 1.6.2 on Win XP.
>> 
>> Thanks in advance!
>
>I cannot reproduce such an behaviour on WinNT 4.0.
>Could you provide an example which we can reproduce, please?
>(preferable using data like 1:10 ...)
>
>Uwe Ligges
>
>
>
>> Sincerely,
>> Tord Sn?ll
>> 
>> par(mar=c(5, 12, 1, 2), mai=c(1, 2.2, 0.01, 0.2), xpd=NA) # yttre kanterna
>> och plotting ?ven i Margin V&R, sid 66
>> (palette(gray(seq(0,.9,len=25)))) # gray scales; print old palette
>> barplot(as.matrix(t(nedbr[nedbr$fran.lan == "X", c("nedbr1volS.ha",
>> "nedbr2volS.ha", "nedbr3volS.ha", "nedbr4volS.ha", "nedbr5volS.ha")])), 
>>         names.arg = as.vector(nedbr[nedbr$fran.lan == "X",
"Objektnamn"]),  
>>         horiz=T, las=1, cex.names=0.8, xlab="Volym m3/ha", xlim=c(0,100),
>> col=c(25,21,17,14,10))
>> 
>> legend(locator(1), c("Nedbrytning 1 (<10%)", "Nedbrytning 2 (10-25%)",
>> "Nedbrytning 3 (25-50%)", 
>>         "Nedbrytning 4 (50-75%)", "Nedbrytning 5 (75-100%)"),
>> fill=c(25,21,17,14,10), cex=0.75)
>> palette("default")      # reset back to the default
>> 
>> 
>> -----------------------------------------------------------------------
>> Tord Sn?ll
>> Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
>> Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
>> Villav?gen 14			
>> SE-752 36 Uppsala, Sweden
>> Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
>> Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
>> Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
>> E-mail: Tord.Snall at ebc.uu.se
>> Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
>> ------------------------------------------------------------------------
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
------------------------------------------------------------------------



From rahul.maniar at feri.de  Thu Feb 27 11:34:02 2003
From: rahul.maniar at feri.de (rahul.maniar@feri.de)
Date: Thu Feb 27 11:34:02 2003
Subject: [R] Factor Analysis
Message-ID: <A05FF736A3208846B04D74334040A7B95971D3@feriex.FERI.DE>

Hello,

I am encountering a problem while doing factor analysis in R. I am using
correlation matrix of the performance data of funds.And it gives me error
message saying singular matrix in use. Now when I try to find the
determinant of this matrix it is indeed singular. The problem is when I use
same matrix for principal component analysis it works. I was wondering if
any of you could help me with this.

Rahul Maniar



From jlvw at rau.ac.za  Thu Feb 27 13:37:03 2003
From: jlvw at rau.ac.za (Jacob van Wyk)
Date: Thu Feb 27 13:37:03 2003
Subject: [R] PRESS again
Message-ID: <se5e2240.042@rauzen.rau.ac.za>

Sorry for the repeat.
The PRESS statistic is defined as
sum(y-yhat(i))^2, where yhat(i) denotes the ith predicted value using
all the data except the ith case (as used typically in linear models).
Thanks again
Jacob



Jacob L van Wyk
Department of Mathematics and Statistics
Rand Afrikaans University
P O Box 524
Auckland Park 2006
South Africa
Tel: +27-11-489-3080
Fax: +27-11-489-2832


______________________________________

VRYWARING                                                                                         

Die inhoud en enige aanhegsels van hierdie elektroniese posboodskap is
vertroulik en net vir die genoemde geadresseerdes bedoel.

Verspreiding, aanstuur, publikasie of enige gebruik van die boodskap of
aanhegsels deur enige ongemagtigde persoon is streng verbode.

Die menings wat in hierdie boodskap uitgedruk word, tensy anders
vermeld, is die van die skrywer en nie van die Randse Afrikaanse
Universiteit of sy Bestuur nie.

Gebruikersbeleide van die Randse Afrikaanse Universiteit is beskikbaar
by:
http://www.rau.ac.za/disclaimer                                                                    

DISCLAIMER

The contents and any attachments of this electronic mail message are
confidential and intended only for the named addressees.

Dissemination, forwarding, publication or other use of the message or
attachments by any unauthorised person is strictly prohibited.                                    

The views expressed in this message are, unless otherwise stated, those
of the author and not those of the Rand Afrikaans University or its
management.

User policies of the Rand Afrikaans University are available at:
http://www.rau.ac.za/disclaimer



From mounier at lmd.polytechnique.fr  Thu Feb 27 14:12:03 2003
From: mounier at lmd.polytechnique.fr (Flore MOUNIER)
Date: Thu Feb 27 14:12:03 2003
Subject: [R] spatial evolution and variance after rotation of Principal components
Message-ID: <200302271414.41054.mounier@lmd.polytechnique.fr>

Dear R users,
I have been doing rotation on Principal components analyse, with varimax 
function and promax. Following those changes, I cannot find now how to get 
the spatial evolution and the variance. Indeed, with the function princomp  
that has been used to get the principal components, arguments such as $scores 
and $sdev were available to get the spatial evolution and the variance, with 
varimax and promax, there no more present.
If you have any advices about this matter, thank you in advance.
Sincerely,
Flore MOUNIER

-- 
Flore MOUNIER
Laboratoire de M?t?orologie Dynamique
Ecole Polytechnique
F 91128 Palaiseau Cedex
T?l:  01-69-33-36-19
Fax:  01-69-33-30-49
e-mail : mounier at lmd.polytechnique.fr



From chrysopa at insecta.ufv.br  Thu Feb 27 15:18:03 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Thu Feb 27 15:18:03 2003
Subject: [R] Nested analysis with non-normal errors
Message-ID: <200302271058.06346.chrysopa@insecta.ufv.br>

I have some doubt to make some analysis in R, I remember that in GLIM all 
analysis use glm. I have using the new Crawley's Book to help-me.

How make a nested or splitplot analysis with poisson errors??

with normal errors use aov, and non-normal errors?

Thanks fo all
Ronaldo
-- 
Whenever someone tells you to take their advice, you can be pretty sure
that they're not using it.
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366



From tlumley at u.washington.edu  Thu Feb 27 16:02:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Feb 27 16:02:03 2003
Subject: [R] epoch time conversion in R
In-Reply-To: <3E5D835D.5090808@cs.berkeley.edu>
Message-ID: <Pine.A41.4.44.0302270658410.100298-100000@homer38.u.washington.edu>

On Wed, 26 Feb 2003, Sharad Agarwal wrote:

> I have a data file where each entry is indexed by the time in seconds since
> epoch (e.g. 1046315697). Is there an easy way to convert this time value into
> a more friendly time (such as Month-Year) when plotting it?
>

Yes. As POSIXct objects are also indexed in seconds you can do something
like
   ISOdate(1960,1,1)+time.in.sec
using your epoch date instead of 1960-1-1

	-thomas



From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Feb 27 16:27:03 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu Feb 27 16:27:03 2003
Subject: [R] PRESS again
In-Reply-To: <se5e2240.042@rauzen.rau.ac.za>
References: <se5e2240.042@rauzen.rau.ac.za>
Message-ID: <Pine.LNX.4.51.0302271623150.12436@artemis.imbe.med.uni-erlangen.de>


> Sorry for the repeat.
> The PRESS statistic is defined as
> sum(y-yhat(i))^2, where yhat(i) denotes the ith predicted value using
> all the data except the ith case (as used typically in linear models).
> Thanks again
> Jacob
>


library(ipred)
errorest(y ~., data=mydata, model=lm, estimator="cv",
               est.para=control.errorest(k=nrow(mydata)))

does the job, given that your data is organized in a data.frame "mydata"
with numeric response "y".

Torsten




>
>
> Jacob L van Wyk
> Department of Mathematics and Statistics
> Rand Afrikaans University
> P O Box 524
> Auckland Park 2006
> South Africa
> Tel: +27-11-489-3080
> Fax: +27-11-489-2832
>
>
> ______________________________________
>
> VRYWARING
>
> Die inhoud en enige aanhegsels van hierdie elektroniese posboodskap is
> vertroulik en net vir die genoemde geadresseerdes bedoel.
>
> Verspreiding, aanstuur, publikasie of enige gebruik van die boodskap of
> aanhegsels deur enige ongemagtigde persoon is streng verbode.
>
> Die menings wat in hierdie boodskap uitgedruk word, tensy anders
> vermeld, is die van die skrywer en nie van die Randse Afrikaanse
> Universiteit of sy Bestuur nie.
>
> Gebruikersbeleide van die Randse Afrikaanse Universiteit is beskikbaar
> by:
> http://www.rau.ac.za/disclaimer
>
> DISCLAIMER
>
> The contents and any attachments of this electronic mail message are
> confidential and intended only for the named addressees.
>
> Dissemination, forwarding, publication or other use of the message or
> attachments by any unauthorised person is strictly prohibited.
>
> The views expressed in this message are, unless otherwise stated, those
> of the author and not those of the Rand Afrikaans University or its
> management.
>
> User policies of the Rand Afrikaans University are available at:
> http://www.rau.ac.za/disclaimer
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From ernesto at ipimar.pt  Thu Feb 27 17:41:03 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu Feb 27 17:41:03 2003
Subject: [R] NA in dummy regression coefficients
Message-ID: <3E5E3F4E.7000306@ipimar.pt>

Hi

I'm doing a regression analysis with dummy variables and I'm getting NA 
for some coefficients. I've inspected residuals, leverage effects and 
Cook's distance and it seems ok.

Can someone explains what can cause this problem ?

Thanks

EJ



From andy_liaw at merck.com  Thu Feb 27 17:58:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Feb 27 17:58:03 2003
Subject: [R] PRESS again
Message-ID: <3A822319EB35174CA3714066D590DCD534BD3F@usrymx25.merck.com>

That seems like an overkill, don't you think?  PRESS can be expressed as:

sum { e_i / (1 - h_i) }^2

so all you need are residuals() and hat().

Andy

> -----Original Message-----
> From: Torsten Hothorn [mailto:Torsten.Hothorn at rzmail.uni-erlangen.de]
> Sent: Thursday, February 27, 2003 10:26 AM
> To: Jacob van Wyk
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] PRESS again
> 
> 
> 
> 
> > Sorry for the repeat.
> > The PRESS statistic is defined as
> > sum(y-yhat(i))^2, where yhat(i) denotes the ith predicted 
> value using
> > all the data except the ith case (as used typically in 
> linear models).
> > Thanks again
> > Jacob
> >
> 
> 
> library(ipred)
> errorest(y ~., data=mydata, model=lm, estimator="cv",
>                est.para=control.errorest(k=nrow(mydata)))
> 
> does the job, given that your data is organized in a 
> data.frame "mydata"
> with numeric response "y".
> 
> Torsten
> 
> 
> 
> 
> >
> >
> > Jacob L van Wyk
> > Department of Mathematics and Statistics
> > Rand Afrikaans University
> > P O Box 524
> > Auckland Park 2006
> > South Africa
> > Tel: +27-11-489-3080
> > Fax: +27-11-489-2832
> >
> >
> > ______________________________________
> >
> > VRYWARING
> >
> > Die inhoud en enige aanhegsels van hierdie elektroniese 
> posboodskap is
> > vertroulik en net vir die genoemde geadresseerdes bedoel.
> >
> > Verspreiding, aanstuur, publikasie of enige gebruik van die 
> boodskap of
> > aanhegsels deur enige ongemagtigde persoon is streng verbode.
> >
> > Die menings wat in hierdie boodskap uitgedruk word, tensy anders
> > vermeld, is die van die skrywer en nie van die Randse Afrikaanse
> > Universiteit of sy Bestuur nie.
> >
> > Gebruikersbeleide van die Randse Afrikaanse Universiteit is 
> beskikbaar
> > by:
> > http://www.rau.ac.za/disclaimer
> >
> > DISCLAIMER
> >
> > The contents and any attachments of this electronic mail message are
> > confidential and intended only for the named addressees.
> >
> > Dissemination, forwarding, publication or other use of the 
> message or
> > attachments by any unauthorised person is strictly prohibited.
> >
> > The views expressed in this message are, unless otherwise 
> stated, those
> > of the author and not those of the Rand Afrikaans University or its
> > management.
> >
> > User policies of the Rand Afrikaans University are available at:
> > http://www.rau.ac.za/disclaimer
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Feb 27 18:04:06 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu Feb 27 18:04:06 2003
Subject: [R] PRESS again
In-Reply-To: <3A822319EB35174CA3714066D590DCD534BD3F@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD534BD3F@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.51.0302271758260.12876@artemis.imbe.med.uni-erlangen.de>


> That seems like an overkill, don't you think?  PRESS can be expressed as:
>
> sum { e_i / (1 - h_i) }^2
>
> so all you need are residuals() and hat().
>

for "model=lm" yes, but what about "model=randomForest"? :-)

best,

Torsten

> Andy
>
> > -----Original Message-----
> > From: Torsten Hothorn [mailto:Torsten.Hothorn at rzmail.uni-erlangen.de]
> > Sent: Thursday, February 27, 2003 10:26 AM
> > To: Jacob van Wyk
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] PRESS again
> >
> >
> >
> >
> > > Sorry for the repeat.
> > > The PRESS statistic is defined as
> > > sum(y-yhat(i))^2, where yhat(i) denotes the ith predicted
> > value using
> > > all the data except the ith case (as used typically in
> > linear models).
> > > Thanks again
> > > Jacob
> > >
> >
> >
> > library(ipred)
> > errorest(y ~., data=mydata, model=lm, estimator="cv",
> >                est.para=control.errorest(k=nrow(mydata)))
> >
> > does the job, given that your data is organized in a
> > data.frame "mydata"
> > with numeric response "y".
> >
> > Torsten
> >
> >
> >
> >
> > >
> > >
> > > Jacob L van Wyk
> > > Department of Mathematics and Statistics
> > > Rand Afrikaans University
> > > P O Box 524
> > > Auckland Park 2006
> > > South Africa
> > > Tel: +27-11-489-3080
> > > Fax: +27-11-489-2832
> > >
> > >
> > > ______________________________________
> > >
> > > VRYWARING
> > >
> > > Die inhoud en enige aanhegsels van hierdie elektroniese
> > posboodskap is
> > > vertroulik en net vir die genoemde geadresseerdes bedoel.
> > >
> > > Verspreiding, aanstuur, publikasie of enige gebruik van die
> > boodskap of
> > > aanhegsels deur enige ongemagtigde persoon is streng verbode.
> > >
> > > Die menings wat in hierdie boodskap uitgedruk word, tensy anders
> > > vermeld, is die van die skrywer en nie van die Randse Afrikaanse
> > > Universiteit of sy Bestuur nie.
> > >
> > > Gebruikersbeleide van die Randse Afrikaanse Universiteit is
> > beskikbaar
> > > by:
> > > http://www.rau.ac.za/disclaimer
> > >
> > > DISCLAIMER
> > >
> > > The contents and any attachments of this electronic mail message are
> > > confidential and intended only for the named addressees.
> > >
> > > Dissemination, forwarding, publication or other use of the
> > message or
> > > attachments by any unauthorised person is strictly prohibited.
> > >
> > > The views expressed in this message are, unless otherwise
> > stated, those
> > > of the author and not those of the Rand Afrikaans University or its
> > > management.
> > >
> > > User policies of the Rand Afrikaans University are available at:
> > > http://www.rau.ac.za/disclaimer
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> ------------------------------------------------------------------------------
> Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.
>
> ==============================================================================
>
>



From spencer.graves at pdf.com  Thu Feb 27 18:35:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu Feb 27 18:35:03 2003
Subject: [R] NA in dummy regression coefficients
References: <3E5E3F4E.7000306@ipimar.pt>
Message-ID: <3E5E4C07.1070007@pdf.com>

Your model must be singular.  Consider the following example:

 > dat0 <- data.frame(x1=1:3, x2=1:3, y=rnorm(3))
 > coef(lm(y~x1+x2, dat0))
(Intercept)          x1          x2
   -3.714515    1.487876          NA

Since x1 = x2, ordinarly least squares cannot produce separate estimates 
for coefficients for x1 and x2.  In such situations, "lm" drops terms 
out of the model until it gets a model that is estimable.

In S-Plus, "lm" will give an error message and no answer to this 
problem, unless you add ""singular.ok=TRUE".  I prefer the R default.

Spencer Graves

Ernesto Jardim wrote:
> Hi
> 
> I'm doing a regression analysis with dummy variables and I'm getting NA 
> for some coefficients. I've inspected residuals, leverage effects and 
> Cook's distance and it seems ok.
> 
> Can someone explains what can cause this problem ?
> 
> Thanks
> 
> EJ
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From spencer.graves at pdf.com  Thu Feb 27 18:43:02 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu Feb 27 18:43:02 2003
Subject: [R] Factor Analysis
References: <A05FF736A3208846B04D74334040A7B95971D3@feriex.FERI.DE>
Message-ID: <3E5E4C66.60401@pdf.com>

To obtain an nonsingular estimate of an (n x n) covariance or 
correlation matrix, you need at least (n+1) observations.  However, you 
can obtain estimates of the largest k singular values or eigenvalues 
with only (k+1) observations.  The principal components routine must use 
something like "eigen" or "svd", which does not require a nonsingular 
covariance matrix.

Spencer Graves

rahul.maniar at feri.de wrote:
> Hello,
> 
> I am encountering a problem while doing factor analysis in R. I am using
> correlation matrix of the performance data of funds.And it gives me error
> message saying singular matrix in use. Now when I try to find the
> determinant of this matrix it is indeed singular. The problem is when I use
> same matrix for principal component analysis it works. I was wondering if
> any of you could help me with this.
> 
> Rahul Maniar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From den.duurs at lycos.com  Thu Feb 27 19:05:03 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Thu Feb 27 19:05:03 2003
Subject: [R] horizontal high-density lines?
Message-ID: <PHADPKJBPOPNJDAA@mailcity.com>

Hi all,

two solutions for horizontal high-density lines were suggested:

Use plot(..., type="h") and turn your head sideways. This turned out to be a pain in the neck ;-). But it sure works!

segments() sure does the trick,

for example

y <- runif(10)
x <- 1:10
plot(x,y,type='n')
segments(x0=0, y0=y, x1=x, y1=y, col="red")


thanks for the help!

Remko

--

On Thu, 27 Feb 2003 08:30:00  
 Uwe Ligges wrote:
>Remko Duursma wrote:
>> Hi all,
>> 
>> the option type="h" in plot() makes nice vertical (histogram-like) lines. Is there a way to make similar, horizontal lines?
>> 
>> I can of course resort to using lines() multiple times, but i was hoping that there is a more elegant solution.
>> 
>> thanks,
>> 
>> Remko Duursma
>
>I guess you are looking for ?segments.
>
>Uwe Ligges
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Thu Feb 27 19:34:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb 27 19:34:02 2003
Subject: [R] na.action in model.tables and TukeyHSD
In-Reply-To: <200302261255.NAA18523@mail1.slu.se>
Message-ID: <Pine.LNX.4.44.0302271832200.14805-100000@gannet.stats>

This ia already fixed in R-devel.  The answer is the same: don't use 
na.omit implicitly: use it explicitly.

On Wed, 26 Feb 2003, CG Pettersson wrote:

> Hello everybody!
> 
> I use R 1.6.2 in Windows, and have a problem controlling the na.action.
> 
> In a dataset with twelve trials, one of the trials lack any readings of the variable "STS.SH" (standing power at harvest)
> 
> Fitting an aov() object with the call:
> led1t7sts.aov <- aov(STS.SH ~ Trial/Block + Treatment + Treatment:Trial, data = led1t7, na.action=na.exclude)  
> seems to work as it produces an object with 10 df for the factor "Trial".
> 
> But when I use model.tables or TukeyHSD on the object I get this:
> > model.tables(led1t7sts.aov, "means")
> Error in replications(paste("~", paste(names(tables), collapse = "+")),  : 
>         na.action must be a function
> 
> I have tried to use "na.action=na.exclude" inside the model.tables call as well, without any bettering.
> 
> I can naturally cope with the problem by taking the whole trial away from the dataset, but it doesn?t feel very sophisticated...;-)
> (Prof. Ripley answered a similar question from me two weeks ago. The answer was good but didn?t work as the reason of the error was the same as this time: a whole 
> trial with only na:s in it).
> 
> Thanks
> /CG
> CG Pettersson
> cg.pettersson at evp.slu.se
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Feb 27 19:41:23 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Feb 27 19:41:23 2003
Subject: [R] Factor Analysis
In-Reply-To: <3E5E4C66.60401@pdf.com>
Message-ID: <Pine.LNX.4.44.0302271834190.14805-100000@gannet.stats>

On Thu, 27 Feb 2003, Spencer Graves wrote:

> To obtain an nonsingular estimate of an (n x n) covariance or 
> correlation matrix, you need at least (n+1) observations.  However, you 
> can obtain estimates of the largest k singular values or eigenvalues 
> with only (k+1) observations.  The principal components routine must use 
> something like "eigen" or "svd", which does not require a nonsingular 
> covariance matrix.

That's because principal components analysis is defined for simgular 
covariance matrices, but the factor analysis model can never generate 
them.  It's not to do with the computational technique.

Using PCA to find constant combinations is quite common, and such data 
matrices have singular covariance structures.

> rahul.maniar at feri.de wrote:
> > 
> > I am encountering a problem while doing factor analysis in R. I am using
> > correlation matrix of the performance data of funds.And it gives me error
> > message saying singular matrix in use. Now when I try to find the
> > determinant of this matrix it is indeed singular. The problem is when I use
> > same matrix for principal component analysis it works. I was wondering if
> > any of you could help me with this.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tvargas at cisco.com  Thu Feb 27 19:53:18 2003
From: tvargas at cisco.com (Tony Vargas)
Date: Thu Feb 27 19:53:18 2003
Subject: [R] R performance, labeling questions, etc.
In-Reply-To: <3E5C6E3F.30600@statistik.uni-dortmund.de>
Message-ID: <Pine.GSO.4.44.0302271032560.1200-100000@tvargas-u10.cisco.com>

Uwe,

Thanks for your help.  The solution solved most of my problem and was
consistent with the other responses I got back.

The solution below gives me tick marks at 144 point intervals, yet when I
try to get the information located at the point, I get the number
position back, not the date (02/01/03,00:50).  Any ideas?

In addition, thanks for your help so far,

Tony

Tony Vargas
Cisco Systems
Engineering Computing Services
(408) 525-4113
tvargas at cisco.com

On Wed, 26 Feb 2003, Uwe Ligges wrote:

> Tony Vargas wrote:
> > R helpers,
> >
> > I am trying to add labels to my graphs.  I have a Perl Program which
> > generates thousands of R files like the one attached.
> >
> > My data files have 2 - 8 columns in them.  The first column of every data
> > file is a header (Time) - which I want to have plotted against everything
> > else.  My current formula just plots each column, which is fine, yet at
> > the bottom for my labels I wind up with numbers.  What I would like to do
> > is have R grab the Time label in increments of 144 data points and use
> > that to label my X-axis instead of just plain numbers.  (Each data file
> > has about 4400 columns).
>
> You have somehow confused columns and rows. Anyway, you might want to
> use something like
>
>   plot(..., xaxt="n")
>   temp <- seq(1, length(Time), by = 144)
>   axis(1, at = temp, labels = Time[temp])
>
> Uwe Ligges
>
>
> > I can kind of have R lable the bottom by chaning my plot to "plot(usr.cpu
> > ~ Time), yet then the graphs take much, much longer to generate.
> >
> > Worst case, I will use "plot(usr.cpu ~ Time)" - yet, anyone know why this
> > would take a very, very long time?
> >
> > Any ideas?
> >
> > Thanks,
> >
> > Tony
> >
> > Tony Vargas
> > Cisco Systems
> > Engineering Computing Services
> > (408) 525-4113
> > tvargas at cisco.com
>
>
>



From matthew_wiener at merck.com  Thu Feb 27 19:59:04 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Thu Feb 27 19:59:04 2003
Subject: [R] multidimensional function fitting
Message-ID: <AEBD81486231A343B1813FE62D335225013176FA@usrymx15.merck.com>

Take a look at package mgcv.  Hope this helps.  --Matt

-----Original Message-----
From: RenE J.V. Bertin [mailto:rjvbertin at despammed.com]
Sent: Thursday, February 27, 2003 1:39 PM
To: r-help at stat.math.ethz.ch
Subject: [R] multidimensional function fitting


Hello,

I have been looking around for how to perform a multidimensional, arbitrary
function fit (in any case non-linear; more below), but haven't found
anything yet on how to accomplish this. I found some references to the
funfits package (that apparently is now called fields), but as far as I have
understood it, it does not do what I need.

Basically, I have a set of data that describe some measured, dependent
variable as a function of a number of controlled variables, in casu
z=f(x,y). What I need is to obtain some f that reliably describes my data on
the range of controlled variables. (This is for inverse-filtering in a
visual stimulus programme, so I don't really care about the form of f as
long as it is reasonably simple to implement -- i.e. a spline surface would
not be ideal in the context ;^). )

Clearly, something like

fit<-lm(z~x+y+x*y+x*x+y*y, data)

does not give the result I want.

Is there a package somewhere that allows to do this sort of operation? Like
a multidimensional version of polyreg()?

Thanks in advance,
RenE Bertin

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------



From spencer.graves at pdf.com  Thu Feb 27 20:12:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu Feb 27 20:12:03 2003
Subject: [R] Factor Analysis
References: <Pine.LNX.4.44.0302271834190.14805-100000@gannet.stats>
Message-ID: <3E5E62BE.4010108@pdf.com>

Of course.  Thanks for the correction.  Spencer Graves

ripley at stats.ox.ac.uk wrote:
> On Thu, 27 Feb 2003, Spencer Graves wrote:
> 
> 
>>To obtain an nonsingular estimate of an (n x n) covariance or 
>>correlation matrix, you need at least (n+1) observations.  However, you 
>>can obtain estimates of the largest k singular values or eigenvalues 
>>with only (k+1) observations.  The principal components routine must use 
>>something like "eigen" or "svd", which does not require a nonsingular 
>>covariance matrix.
> 
> 
> That's because principal components analysis is defined for simgular 
> covariance matrices, but the factor analysis model can never generate 
> them.  It's not to do with the computational technique.
> 
> Using PCA to find constant combinations is quite common, and such data 
> matrices have singular covariance structures.
> 
> 
>>rahul.maniar at feri.de wrote:
>>
>>>I am encountering a problem while doing factor analysis in R. I am using
>>>correlation matrix of the performance data of funds.And it gives me error
>>>message saying singular matrix in use. Now when I try to find the
>>>determinant of this matrix it is indeed singular. The problem is when I use
>>>same matrix for principal component analysis it works. I was wondering if
>>>any of you could help me with this.
>>
>



From jerosenb at hcs.harvard.edu  Thu Feb 27 20:53:03 2003
From: jerosenb at hcs.harvard.edu (janet rosenbaum)
Date: Thu Feb 27 20:53:03 2003
Subject: [R] R problems
Message-ID: <200302271952.OAA06362@hcs.harvard.edu>

Hi.  
I have an ibook G3/800 running 10.2.4, with Mac's X11.  
Up until a few days ago, R was working fine but recently it stopped working.  

The error I get is:

dyld: /usr/local/lib/R/bin/R.bin version mismatch for library:
/usr/lib/libncurses.5.dylib (compatibility version of user: 6.0.0
greater than library's version: 5.0.0)
Trace/BPT trap

which seems to imply that it wants a higher version of this library,
although I think it's been using version 5 all along.

I've been having a lot of unrelated problems with my computer, so a lot
of things have changed and it's hard to say what might have happened.  

Thus far, I have moved all my old X11R6 and X11 directories elsewhere, 
including the Library/Receipts for them, and reinstalled Mac's X11 and
SDK, but that didn't work.

Thanks for any help you can give.

Janet Rosenbaum
PhD Candidate, Health Policy
Center for Basic Research in the Social Sciences, Harvard University



From am.power at ucc.ie  Thu Feb 27 21:32:04 2003
From: am.power at ucc.ie (Power, Anne Marie)
Date: Thu Feb 27 21:32:04 2003
Subject: [R] qda plots
Message-ID: <49AB9D0C6521D84ABD017BF83CDF44C401BFC562@xch1.ucc.ie>

Hi,

I have been using some of the functions in r for classification purposes,
chiefly lda, qda, knn and nnet.
My problem is that the only one I can figure out how to represenent
graphically is lda (using plot.lda).  I have tried 'fooling' this function
into accepting qda input for plotting but to no avail.  I wonder if you have
any suggestions?

Thanks alot,

Anne Marie Power

Marine lab.
Dept. Zooogy & Animal Ecology,
University College Cork
Ireland



From jerome at hivnet.ubc.ca  Thu Feb 27 21:39:14 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Thu Feb 27 21:39:14 2003
Subject: [R] interval-censored data in survreg()
Message-ID: <200302272041.MAA01590@hivnet.ubc.ca>

I am trying to fit a lognormal distribution on interval-censored
data. Some of my intervals have a lower bound of zero.
Unfortunately, it seems like survreg() cannot deal with lower
bounds of zero, despite the fact that plnorm(0)==0 and
pnorm(-Inf)==0 are well defined. Below is a short example to
reproduce the problem.

Does anyone know why survreg() must behave that way?
Is there an alternate solution to this problem?

Sincerely,
Jerome Asselin

library(survival)
data(ovarian)
newovarian <- ovarian

newovarian$lower59 <- newovarian$futime-59
newovarian$time59 <- Surv(newovarian$lower59,newovarian$futime,
    event=rep(3,nrow(newovarian)),type="interval")
survreg(time59~ecog.ps+rx,data=newovarian,dist="lognormal")
#THIS DOES NOT WORK BECAUSE ONE OF THE LOWER BOUNDS IS ZERO
#Error in survreg(time59 ~ ecog.ps + rx, data = newovarian,
#  dist = "lognormal") :
#        Invalid survival times for this distribution

-- 

Jerome Asselin (J?r?me)
Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital
608 - 1081 Burrard Street
Vancouver, British Columbia
CANADA V6Z 1Y6

Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044



From andy_liaw at merck.com  Thu Feb 27 21:59:50 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Feb 27 21:59:50 2003
Subject: [R] qda plots
Message-ID: <3A822319EB35174CA3714066D590DCD534BD49@usrymx25.merck.com>

plot.lda uses the linear discriminants, which do not exist for the other
methods you mentioned.  However, the book that the software supports (MASS4)
does have examples for those methods.  I believe the scripts for generating
the plots are bundled with the package, under the "scripts" subdirectory.

Andy

> -----Original Message-----
> From: Power, Anne Marie [mailto:am.power at ucc.ie]
> Sent: Thursday, February 27, 2003 3:31 PM
> To: 'r-help at lists.r-project.org'
> Subject: [R] qda plots
> 
> 
> Hi,
> 
> I have been using some of the functions in r for 
> classification purposes,
> chiefly lda, qda, knn and nnet.
> My problem is that the only one I can figure out how to represenent
> graphically is lda (using plot.lda).  I have tried 'fooling' 
> this function
> into accepting qda input for plotting but to no avail.  I 
> wonder if you have
> any suggestions?
> 
> Thanks alot,
> 
> Anne Marie Power
> 
> Marine lab.
> Dept. Zooogy & Animal Ecology,
> University College Cork
> Ireland
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From andy_liaw at merck.com  Thu Feb 27 22:10:09 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Feb 27 22:10:09 2003
Subject: [despammed] RE: [R] multidimensional function fitting
Message-ID: <3A822319EB35174CA3714066D590DCD534BD4B@usrymx25.merck.com>

If something like the second-order function does not fit your data well, it
may well be that the data do not admit a simple structure that you can
easily code in C.

If you expect the structure of the function to be simple, tell gam() so by
specifying a small dimensional basis (via the k= argument in s()).  This
will probably ease the computational burden.

HTH,
Andy

> -----Original Message-----
> From: RenE J.V. Bertin [mailto:rjvbertin at despammed.com]
> Sent: Thursday, February 27, 2003 3:42 PM
> To: Wiener, Matthew
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [despammed] RE: [R] multidimensional function fitting
> 
> 
> On Thu, 27 Feb 2003 13:52:50 -0500, "Wiener, Matthew" 
> <matthew_wiener at merck.com> wrote regarding
> "[despammed] RE: [R] multidimensional function fitting"
> 
> 8-) Take a look at package mgcv.  Hope this helps.  --Matt
> 8-) 
> 
> Thank you, I just did. It may indeed be what I'm looking for 
> (I haven't quite understood everything about it...), but:
> 
> 1) The best fits I obtain with a formula like z~s(x,y) ; but 
> this I cannot possibly transport into the C programme where I 
> need it! Maybe I wasn't clear on this aspect?
> 
> 2) It is very memory hungry, esp. when using the s() 
> function: I have 192Mb with 256Mb swap (not a lot, but 
> reasonable I'd say), and I've never had to kill R as often as 
> when trying gam()...
> 
> R.B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From jerome at hivnet.ubc.ca  Thu Feb 27 22:21:03 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Thu Feb 27 22:21:03 2003
Subject: [R] interval-censored data in survreg()
In-Reply-To: <200302272041.MAA01590@hivnet.ubc.ca>
References: <200302272041.MAA01590@hivnet.ubc.ca>
Message-ID: <200302272125.NAA03376@hivnet.ubc.ca>

After receiving some feedback, I've realised that
this slight modification corrects the problem, although
I still can't think of a reason why it didn't work the first
way I've done it.

newovarian$time59[newovarian$lower59==0] <-
    Surv(59,NA,event=2,type="interval")

#NOW THIS WORKS...
newovarian$lower59 <- newovarian$futime-59
newovarian$time59 <- Surv(newovarian$lower59,newovarian$futime,
    event=rep(3,nrow(newovarian)),type="interval")
newovarian$time59[newovarian$lower59==0] <- 
Surv(59,NA,event=2,type="interval")
survreg(time59~ecog.ps+rx,data=newovarian,dist="lognormal")

Thanks,
Jerome

On Thursday 27 February 2003 12:36, Jerome Asselin wrote:
> I am trying to fit a lognormal distribution on interval-censored
> data. Some of my intervals have a lower bound of zero.
> Unfortunately, it seems like survreg() cannot deal with lower
> bounds of zero, despite the fact that plnorm(0)==0 and
> pnorm(-Inf)==0 are well defined. Below is a short example to
> reproduce the problem.
>
> Does anyone know why survreg() must behave that way?
> Is there an alternate solution to this problem?
>
> Sincerely,
> Jerome Asselin
>
> library(survival)
> data(ovarian)
> newovarian <- ovarian
>
> newovarian$lower59 <- newovarian$futime-59
> newovarian$time59 <- Surv(newovarian$lower59,newovarian$futime,
>     event=rep(3,nrow(newovarian)),type="interval")
> survreg(time59~ecog.ps+rx,data=newovarian,dist="lognormal")
> #THIS DOES NOT WORK BECAUSE ONE OF THE LOWER BOUNDS IS ZERO
> #Error in survreg(time59 ~ ecog.ps + rx, data = newovarian,
> #  dist = "lognormal") :
> #        Invalid survival times for this distribution



From tlumley at u.washington.edu  Thu Feb 27 22:31:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Feb 27 22:31:03 2003
Subject: [R] interval-censored data in survreg()
In-Reply-To: <200302272041.MAA01590@hivnet.ubc.ca>
Message-ID: <Pine.A41.4.44.0302271317380.206932-100000@homer06.u.washington.edu>

On Thu, 27 Feb 2003, Jerome Asselin wrote:

>
> I am trying to fit a lognormal distribution on interval-censored
> data. Some of my intervals have a lower bound of zero.
> Unfortunately, it seems like survreg() cannot deal with lower
> bounds of zero, despite the fact that plnorm(0)==0 and
> pnorm(-Inf)==0 are well defined. Below is a short example to
> reproduce the problem.
>
> Does anyone know why survreg() must behave that way?
> Is there an alternate solution to this problem?

The code takes the log transformation of all the numbers and then checks
that they are finite, which they aren't.  Removing the checks gives NA
answers, so I would guess that some part of the C code uses an computation
that needs to be written differently to be valid for infinite arguments.

You could maximise the loglikelihood directly with nlm or similar, or you
could add a small epsilon to your data. If there really isn't a
singularity at zero then this will work perfectly well.

	-thomas



From ntomioka at cc.ucsf.edu  Fri Feb 28 00:01:03 2003
From: ntomioka at cc.ucsf.edu (Nobumoto Tomioka)
Date: Fri Feb 28 00:01:03 2003
Subject: [R] Concerning the clustering tree
Message-ID: <000b01c2deb3$fbf9ce80$f8ceda80@ntomioka>

Dear Stuff,

I am trying to enjoy "PAM", but I could not recognize which sample is in
which branches in the clustering tree because of too many samples and size
limitation for my monitor.
I mean, I did unsupervised clustering with "PAM" (
data2$newy<-pamr.makeclasses(data2) ) with 275 primary samples,
but samples were piled up at the point of each branch, so I cannot recognize
them.
Can we get the output file with clustered information ?
Can we change the size of charactor ?
Please let me know how should I do for it.
Best regards

Nobumoto TOMIOKA

**************************************
Nobumoto TOMIOKA M.D.

Feuerstein Lab
Cancer Genetics and
Brain Tumor Research Center
Box 0808, Mt. Zion Brunn Research Institute,
Rm E-120, 1657 Scott Street,
SAN FRANCISCO, CA 94115

Phone: 415-476-0633
Fax:    415-476-8218
E-mail: ntomioka at cc.ucsf.edu (Lab)


US Mail:
2340 Sutter Street
Cancer Research Building
SAN FRANCISCO, CA 94143-0808

Delivery:
Mt. Zion Brunn Research Institute
1657 Scott Street Room E-120
SAN FRANCISCO, CA 94115



From umalvarez at fata.unam.mx  Fri Feb 28 00:19:03 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Fri Feb 28 00:19:03 2003
Subject: [R] R problems
In-Reply-To: <200302271952.OAA06362@hcs.harvard.edu>
Message-ID: <Pine.LNX.4.44.0302271712490.5713-100000@fata.unam.mx>

> Hi.  
> I have an ibook G3/800 running 10.2.4, with Mac's X11.  
> Up until a few days ago, R was working fine but recently it stopped working.  
> 
> The error I get is:
> 
> dyld: /usr/local/lib/R/bin/R.bin version mismatch for library:
> /usr/lib/libncurses.5.dylib (compatibility version of user: 6.0.0
> greater than library's version: 5.0.0)
> Trace/BPT trap
> 
> which seems to imply that it wants a higher version of this library,
> although I think it's been using version 5 all along.
> 
> I've been having a lot of unrelated problems with my computer, so a lot
> of things have changed and it's hard to say what might have happened.  
> 
> Thus far, I have moved all my old X11R6 and X11 directories elsewhere, 
> including the Library/Receipts for them, and reinstalled Mac's X11 and
> SDK, but that didn't work.
> 
> Thanks for any help you can give.
> 
> Janet Rosenbaum
> PhD Candidate, Health Policy
> Center for Basic Research in the Social Sciences, Harvard University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

Hi:

It would be more helpfull if you give more information. How do you install 
R, precompiled or from the source?

Any way, I have R running on the same hardware; I did install it from the 
source through fink. Among many others, the following files are on 
/sw/lib/

libncurses++.5.0.2.dylib
libncurses++.5.dylib
libncurses++.a
libncurses++.dylib
libncurses++.la
libncurses.5.0.2.dylib
libncurses.5.dylib
libncurses.a
libncurses.dylib
libncurses.dylib.5
libncurses.la

Regards.
-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From jonathan_li at labs.agilent.com  Fri Feb 28 01:04:02 2003
From: jonathan_li at labs.agilent.com (Jonathan Q. Li)
Date: Fri Feb 28 01:04:02 2003
Subject: [R] File opening error after 1020 files opened
Message-ID: <3E5EA53F.2020300@labs.agilent.com>

Hi,

I am trying to use "read.pnm" from the package "pixmap" to read more 
than 10 thousand image files in "mydir".

 > file.list <- dir( "mydir", full=T)
 > for( i in 1:length(file.list) ) {
    print(i)
    x <- read.pnm(file.list[i])
}

In the beginning it was fine. But after reading 1020 images or so, the 
read.pnm function
seems to crash on me:

[1] 1017
[1] 1018
[1] 1019
[1] 1020
Error in open.connection(con, open = "rb") :
        unable to open connection
In addition: Warning message:
cannot open file `/mydir/myfile1020.ppm'

Then the R environment seems to crash too because I can't read any other 
files anymore. Neither can I use function "dir".

dir("mydir")
character(0)
Warning message:
list.files: "mydir" is not a readable directory

I quit R and close all other applications and come back. The problem is 
easily repeated.
THe following is my system information. The linux version is Redhat 8.0.

 > R.version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.1
year     2002
month    11
day      01
language R


Your help is highly appreciated!
Best Regards,
Jonathan



From deleeuw at stat.ucla.edu  Fri Feb 28 01:19:02 2003
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Fri Feb 28 01:19:02 2003
Subject: [R] R problems
In-Reply-To: <Pine.LNX.4.44.0302271712490.5713-100000@fata.unam.mx>
Message-ID: <278E3448-4AB2-11D7-A9DA-000393BB6D36@stat.ucla.edu>

Janet installed the binaries from gifi, which use newer versions of
ncurses and readline (in the unstable tree from fink).

On Thursday, Feb 27, 2003, at 15:19 US/Pacific, Ulises Mora Alvarez  
wrote:

>> Hi.
>> I have an ibook G3/800 running 10.2.4, with Mac's X11.
>> Up until a few days ago, R was working fine but recently it stopped  
>> working.
>>
>> The error I get is:
>>
>> dyld: /usr/local/lib/R/bin/R.bin version mismatch for library:
>> /usr/lib/libncurses.5.dylib (compatibility version of user: 6.0.0
>> greater than library's version: 5.0.0)
>> Trace/BPT trap
>>
>> which seems to imply that it wants a higher version of this library,
>> although I think it's been using version 5 all along.
>>
>> I've been having a lot of unrelated problems with my computer, so a  
>> lot
>> of things have changed and it's hard to say what might have happened.
>>
>> Thus far, I have moved all my old X11R6 and X11 directories elsewhere,
>> including the Library/Receipts for them, and reinstalled Mac's X11 and
>> SDK, but that didn't work.
>>
>> Thanks for any help you can give.
>>
>> Janet Rosenbaum
>> PhD Candidate, Health Policy
>> Center for Basic Research in the Social Sciences, Harvard University
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>
> Hi:
>
> It would be more helpfull if you give more information. How do you  
> install
> R, precompiled or from the source?
>
> Any way, I have R running on the same hardware; I did install it from  
> the
> source through fink. Among many others, the following files are on
> /sw/lib/
>
> libncurses++.5.0.2.dylib
> libncurses++.5.dylib
> libncurses++.a
> libncurses++.dylib
> libncurses++.la
> libncurses.5.0.2.dylib
> libncurses.5.dylib
> libncurses.a
> libncurses.dylib
> libncurses.dylib.5
> libncurses.la
>
> Regards.
> --  
> Ulises M. Alvarez
> LAB. DE ONDAS DE CHOQUE
> FISICA APLICADA Y TECNOLOGIA AVANZADA
> UNAM
> umalvarez at fata.unam.mx
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------



From Mark.Wilkinson at stjude.org  Fri Feb 28 01:29:02 2003
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Fri Feb 28 01:29:02 2003
Subject: [R] axis annotation
Message-ID: <A1DAD6685C12D511B20F00034725151380CEAE@sjmemexc3.stjude.org>

Hi,

Is there a way to specify a vector of colors for the tick annotation in a
call to axis(), to achieve the x-axis here?


 <<Rplot003.png>> 

Thanks,

Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences

The opinions expressed here are my own and do not necessarily represent
those of St. Jude Children's Research Hospital.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot003.png
Type: application/octet-stream
Size: 2684 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030228/85148dcb/Rplot003.obj

From umalvarez at fata.unam.mx  Fri Feb 28 01:35:03 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Fri Feb 28 01:35:03 2003
Subject: [R] R problems
In-Reply-To: <278E3448-4AB2-11D7-A9DA-000393BB6D36@stat.ucla.edu>
Message-ID: <Pine.LNX.4.44.0302271827190.6201-100000@fata.unam.mx>

On Thu, 27 Feb 2003, Jan de Leeuw wrote:

> Janet installed the binaries from gifi, which use newer versions of
> ncurses and readline (in the unstable tree from fink).


> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical  
> Software
> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>    
> ------------------------------------------------------------------------ 
> -------------------------
>            No matter where you go, there you are. --- Buckaroo Banzai
>                     http://gifi.stat.ucla.edu/sounds/nomatter.au
>    
> ------------------------------------------------------------------------ 
> -------------------------
> 
Well, Janet

Maybe the way to go is install the newer fink versions of ncurses and 
readline. I have no idea if you can compile the sources along or if you 
need to install fink on your box. So far I have only compile one package 
outside fink (xfce). The result was OK.

Good look.

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From s195404 at student.uq.edu.au  Fri Feb 28 01:47:03 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri Feb 28 01:47:03 2003
Subject: [R] axis annotation
In-Reply-To: <A1DAD6685C12D511B20F00034725151380CEAE@sjmemexc3.stjude.org>
References: <A1DAD6685C12D511B20F00034725151380CEAE@sjmemexc3.stjude.org>
Message-ID: <1046393191.3e5eb167537cb@my.uq.edu.au>

The following works. No doubt there are other ways to do it.

plot(1:10, 1:10, xaxt="n")
axis(side=1, at=1:10, labels=NA)
text(x=1:10, y=rep(0, 10), col=1:10, 1:10, xpd=NA)


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



Quoting "Wilkinson, Mark" <Mark.Wilkinson at stjude.org>:

> Hi,
> 
> Is there a way to specify a vector of colors for the tick annotation in a
> call to axis(), to achieve the x-axis here?
> 
> 
>  <<Rplot003.png>> 
> 
> Thanks,
> 
> Mark Wilkinson
> Informatics Analyst
> St. Jude Children's Research Hospital
> Department of Pharmaceutical Sciences
> 
> The opinions expressed here are my own and do not necessarily represent
> those of St. Jude Children's Research Hospital.
> 
> 
>



From hb at maths.lth.se  Fri Feb 28 01:53:03 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri Feb 28 01:53:03 2003
Subject: [R] File opening error after 1020 files opened
In-Reply-To: <3E5EA53F.2020300@labs.agilent.com>
Message-ID: <000301c2dec3$baeda280$7341a8c0@alpha.wehi.edu.au>

Reconformed on R v1.6.2 (no patch) on WinXP Pro. Here is my
troubleshooting. Using the following files

-rwx------+   1 hb       None        29943 Jun 30  2002 hb.ppm
-rwx------+   1 hb       None         2049 Jul 20  2002 logosm-gray.pgm
-rwx------+   1 hb       None          379 Jul 20  2002 logosm-mono.pbm
-rwx------+   1 hb       None         3682 Feb  2  1998 logosm.jpg
-rwx------+   1 hb       None         5924 Jun 29  2002 logosm.ppm

# R --vanilla
library(pixmap)

# The following fails to read the file at try 509:
for( i in 1:2000 ) { print(i); x <- read.pnm("logosm.ppm"); }

# The following fails to read the file at try 509:
for( i in 1:2000 ) { print(i); x <- read.pnm("logosm-mono.pbm"); }

# The following fails to read the file at try 509:
for( i in 1:2000 ) { print(i); x <- read.pnm("logosm-gray.pgm"); }

# The following fails to read the file at try 509:
for( i in 1:2000 ) { print(i); x <- read.pnm("hb.ppm"); }

Note that I have to restart R between each file; the problem is not just
locking one file, but it messes up the I/O for all files. I get the same
result over and over again after restarting R and it does not seem like
the filesize matters. Most I/O seems to fails. My dir() and file.show()
still works though. Can not save workspace when quiting R etc. Trying to
delete "logosm.ppm" using WinXP Explorer won't work - the file is
locked.

> R.version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.2
year     2003
month    01
day      10
language R

Cheers

Henrik Bengtsson

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jonathan Q. Li
> Sent: den 28 februari 2003 10:55
> To: r-help at stat.math.ethz.ch
> Subject: [R] File opening error after 1020 files opened
> 
> 
> Hi,
> 
> I am trying to use "read.pnm" from the package "pixmap" to read more 
> than 10 thousand image files in "mydir".
> 
>  > file.list <- dir( "mydir", full=T)
>  > for( i in 1:length(file.list) ) {
>     print(i)
>     x <- read.pnm(file.list[i])
> }
> 
> In the beginning it was fine. But after reading 1020 images 
> or so, the 
> read.pnm function
> seems to crash on me:
> 
> [1] 1017
> [1] 1018
> [1] 1019
> [1] 1020
> Error in open.connection(con, open = "rb") :
>         unable to open connection
> In addition: Warning message:
> cannot open file `/mydir/myfile1020.ppm'
> 
> Then the R environment seems to crash too because I can't 
> read any other 
> files anymore. Neither can I use function "dir".
> 
> dir("mydir")
> character(0)
> Warning message:
> list.files: "mydir" is not a readable directory
> 
> I quit R and close all other applications and come back. The 
> problem is 
> easily repeated.
> THe following is my system information. The linux version is 
> Redhat 8.0.
> 
>  > R.version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    6.1
> year     2002
> month    11
> day      01
> language R
> 
> 
> Your help is highly appreciated!
> Best Regards,
> Jonathan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help



From makram.talih at yale.edu  Fri Feb 28 04:07:02 2003
From: makram.talih at yale.edu (Makram Talih)
Date: Fri Feb 28 04:07:02 2003
Subject: [R] NULL object, R programming
Message-ID: <Pine.LNX.4.44.0302272152030.19878-100000@argos.its.yale.edu>

Dear R users,

I get the following (I think puzzling) result when doing the following:

> a <- list(3,4,5)
> a[[2]] <- NULL
> a
[[1]]
[1] 3

[[2]]
[1] 5

I would have expected the result to be:

[[1]]
[1] 3

[[2]]
NULL

[[3]]
[1] 4

as in the outcome of:

> list(3, NULL, 4)

Is this a desired effect? If so, could it be built in a 'help(NULL)' file?

If you think it is relevant, I am using the following R version:

platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.2            
year     2003           
month    01             
day      10             
language R  


Many thanks for any clarifications regarding this!

Regards,

Makram Talih
Yale University
Statistics



From makram.talih at yale.edu  Fri Feb 28 04:17:02 2003
From: makram.talih at yale.edu (Makram Talih)
Date: Fri Feb 28 04:17:02 2003
Subject: [R] NULL object, R programming
Message-ID: <Pine.LNX.4.44.0302272206460.19878-100000@argos.its.yale.edu>

Dear R users,

I get the following (I think puzzling) result when doing the following:

> a <- list(3,4,5)
> a[[2]] <- NULL
> a
[[1]]
[1] 3

[[2]]
[1] 5

I would have expected the result to be:

[[1]]
[1] 3

[[2]]
NULL

[[3]]
[1] 4

as in the outcome of:

> list(3, NULL, 4)

Is this a desired effect? If so, could it be built in a 'help(NULL)' file?

If you think it is relevant, I am using the following R version:

platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.2            
year     2003           
month    01             
day      10             
language R  


Many thanks for any clarifications regarding this!

Regards,

Makram Talih
Yale University
Statistics



From MSchwartz at medanalytics.com  Fri Feb 28 04:47:03 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri Feb 28 04:47:03 2003
Subject: [R] NULL object, R programming
In-Reply-To: <Pine.LNX.4.44.0302272152030.19878-100000@argos.its.yale.edu>
References: <Pine.LNX.4.44.0302272152030.19878-100000@argos.its.yale.edu>
Message-ID: <3E5EDB81.6010509@MedAnalytics.com>

Makram Talih wrote:
> Dear R users,
> 
> I get the following (I think puzzling) result when doing the following:
> 
> 
>>a <- list(3,4,5)
>>a[[2]] <- NULL
>>a
> 
> [[1]]
> [1] 3
> 
> [[2]]
> [1] 5
> 
> I would have expected the result to be:
> 
> [[1]]
> [1] 3
> 
> [[2]]
> NULL
> 
> [[3]]
> [1] 4
> 
> as in the outcome of:
> 
> 
>>list(3, NULL, 4)
> 
> 
> Is this a desired effect? If so, could it be built in a 'help(NULL)' file?
> 
> If you think it is relevant, I am using the following R version:
> 
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    6.2            
> year     2003           
> month    01             
> day      10             
> language R  
> 
> 
> Many thanks for any clarifications regarding this!
> 
> Regards,
> 
> Makram Talih
> Yale University
> Statistics

That behavior is documented in R FAQ 7.3:

"7.3 How can I set components of a list to NULL?

You can use

x[i] <- list(NULL)

to set component i of the list x to NULL, similarly for named 
components. Do not set x[i] or x[[i]] to NULL, because this will remove 
the corresponding component from the list.

For dropping the row names of a matrix x, it may be easier to use 
rownames(x) <- NULL, similarly for column names."


Change your code sequence to:

 > a <- list(3,4,5)
 > a[2] <- list(NULL)
 > a
[[1]]
[1] 3

[[2]]
NULL

[[3]]
[1] 5


HTH,

Marc Schwartz



From jonathan_li at agilent.com  Fri Feb 28 05:10:03 2003
From: jonathan_li at agilent.com (jonathan_li@agilent.com)
Date: Fri Feb 28 05:10:03 2003
Subject: [R] File opening error after 1020 files opened
Message-ID: <FC0B9DA2600ED4118F76009027AA5DDD05ABD3DF@ALEX2>

I experimented with openning just one file repeatedly.

# R
library(pixmap)
filename <- dir("mydir", full=T)[1]
for(i in 2000){ print(i); tmp <- read.pnm(filename); }

The file open failed at when i=1021. So the difference in when file openning
fails is due to the difference in system, not to the fact that I am openning
different files each time.

Thanks,
Jonathan



-----Original Message-----
From: Henrik Bengtsson [mailto:hb at maths.lth.se]
Sent: Thursday, February 27, 2003 4:53 PM
To: 'Jonathan Q. Li'; r-help at stat.math.ethz.ch
Subject: RE: [R] File opening error after 1020 files opened


Reconformed on R v1.6.2 (no patch) on WinXP Pro. Here is my
troubleshooting. Using the following files

-rwx------+   1 hb       None        29943 Jun 30  2002 hb.ppm
-rwx------+   1 hb       None         2049 Jul 20  2002 logosm-gray.pgm
-rwx------+   1 hb       None          379 Jul 20  2002 logosm-mono.pbm
-rwx------+   1 hb       None         3682 Feb  2  1998 logosm.jpg
-rwx------+   1 hb       None         5924 Jun 29  2002 logosm.ppm

# R --vanilla
library(pixmap)

# The following fails to read the file at try 509:
for( i in 1:2000 ) { print(i); x <- read.pnm("logosm.ppm"); }

# The following fails to read the file at try 509:
for( i in 1:2000 ) { print(i); x <- read.pnm("logosm-mono.pbm"); }

# The following fails to read the file at try 509:
for( i in 1:2000 ) { print(i); x <- read.pnm("logosm-gray.pgm"); }

# The following fails to read the file at try 509:
for( i in 1:2000 ) { print(i); x <- read.pnm("hb.ppm"); }

Note that I have to restart R between each file; the problem is not just
locking one file, but it messes up the I/O for all files. I get the same
result over and over again after restarting R and it does not seem like
the filesize matters. Most I/O seems to fails. My dir() and file.show()
still works though. Can not save workspace when quiting R etc. Trying to
delete "logosm.ppm" using WinXP Explorer won't work - the file is
locked.

> R.version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.2
year     2003
month    01
day      10
language R

Cheers

Henrik Bengtsson

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jonathan Q. Li
> Sent: den 28 februari 2003 10:55
> To: r-help at stat.math.ethz.ch
> Subject: [R] File opening error after 1020 files opened
> 
> 
> Hi,
> 
> I am trying to use "read.pnm" from the package "pixmap" to read more 
> than 10 thousand image files in "mydir".
> 
>  > file.list <- dir( "mydir", full=T)
>  > for( i in 1:length(file.list) ) {
>     print(i)
>     x <- read.pnm(file.list[i])
> }
> 
> In the beginning it was fine. But after reading 1020 images 
> or so, the 
> read.pnm function
> seems to crash on me:
> 
> [1] 1017
> [1] 1018
> [1] 1019
> [1] 1020
> Error in open.connection(con, open = "rb") :
>         unable to open connection
> In addition: Warning message:
> cannot open file `/mydir/myfile1020.ppm'
> 
> Then the R environment seems to crash too because I can't 
> read any other 
> files anymore. Neither can I use function "dir".
> 
> dir("mydir")
> character(0)
> Warning message:
> list.files: "mydir" is not a readable directory
> 
> I quit R and close all other applications and come back. The 
> problem is 
> easily repeated.
> THe following is my system information. The linux version is 
> Redhat 8.0.
> 
>  > R.version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    6.1
> year     2002
> month    11
> day      01
> language R
> 
> 
> Your help is highly appreciated!
> Best Regards,
> Jonathan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help



From edd at debian.org  Fri Feb 28 05:28:02 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri Feb 28 05:28:02 2003
Subject: [R] File opening error after 1020 files opened
In-Reply-To: <FC0B9DA2600ED4118F76009027AA5DDD05ABD3DF@ALEX2>
References: <FC0B9DA2600ED4118F76009027AA5DDD05ABD3DF@ALEX2>
Message-ID: <20030228042739.GA15952@sonny.eddelbuettel.com>

On Thu, Feb 27, 2003 at 08:08:48PM -0800, jonathan_li at agilent.com wrote:
> The file open failed at when i=1021. So the difference in when file openning
> fails is due to the difference in system, not to the fact that I am openning
> different files each time.

It's a question for the operating system / kernel. See e.g. what I just
found via Google at

  http://www.jguru.com/faq/view.jsp?EID=239607 
	
and which answers the question "How can I increase the number of sockets and
files that I can simultaneously have open under Linux?" as follows:

  Linux 2.2.x kernels allow control of the maximum number of open files
  through the /proc/sys/fs/file-max pseudo-file. Read that file to see the
  current limits; write a new value to it to change the limit. For example:

  cat /proc/sys/fs/file-max
  echo 16384 >/proc/sys/fs/file-max
    
  You may also find it useful to manipulate the kernel inode limit. This
  is controlled, using the same techniques, through the 
  /proc/sys/fs/inode-max pseudo-file.

On my Debian systems this would appear to be set to 4096, both under 2.2 and
2.4 kernels. 

Still, what seems odd is that the pixmap library doesn't close the
filehandle after reading.  It seems to me that you should be able to 
loop endlessly over the ops open; do something; close; repeat as that
would only consume one file handle at a time.

Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr



From spencer.graves at pdf.com  Fri Feb 28 06:15:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 28 06:15:06 2003
Subject: [R] NULL object, R programming
References: <Pine.LNX.4.44.0302272206460.19878-100000@argos.its.yale.edu>
Message-ID: <3E5EF00A.1010904@pdf.com>

When you set the second attribute of the list to NULL, it actually 
eliminated that attribute, so the length(a) went from 3 to 2.  If you 
don't like that, try the following:

	a <- list(a=3, b=4, c=5)
	a[["b"]] <- NULL
	
You can still refer to the attributes of the list via a[["a"]], 
a[["c"]]], a$a, a$b, etc., and get what you expect even though though 
the length of the list has been reduced.

Spencer Graves
	

Makram Talih wrote:
> Dear R users,
> 
> I get the following (I think puzzling) result when doing the following:
> 
> 
>>a <- list(3,4,5)
>>a[[2]] <- NULL
>>a
> 
> [[1]]
> [1] 3
> 
> [[2]]
> [1] 5
> 
> I would have expected the result to be:
> 
> [[1]]
> [1] 3
> 
> [[2]]
> NULL
> 
> [[3]]
> [1] 4
> 
> as in the outcome of:
> 
> 
>>list(3, NULL, 4)
> 
> 
> Is this a desired effect? If so, could it be built in a 'help(NULL)' file?
> 
> If you think it is relevant, I am using the following R version:
> 
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    6.2            
> year     2003           
> month    01             
> day      10             
> language R  
> 
> 
> Many thanks for any clarifications regarding this!
> 
> Regards,
> 
> Makram Talih
> Yale University
> Statistics
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From f0z6305 at labs.tamu.edu  Fri Feb 28 06:23:04 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Fri Feb 28 06:23:04 2003
Subject: [R] How to generate multiple squre Orthogonal matrices?
Message-ID: <000b01c2dee9$47b7f6a0$8bd75ba5@IE.TAMU.EDU>

Hey, all

Will you please tell me how to generate multiple
square orthogonal matrices for data transformation usage?

Thanks.

Fred



From spencer.graves at pdf.com  Fri Feb 28 06:45:04 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 28 06:45:04 2003
Subject: [R] How to generate multiple squre Orthogonal matrices?
References: <000b01c2dee9$47b7f6a0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <3E5EF71C.7040700@pdf.com>

k <- 5
tstMat <- array(runif(k), dim=c(k,k))
tstOrth <- qr.Q(qr(tstMat))
t(tstOrth)%*%tstOrth

Is this what you want?
Spencer Graves

Feng Zhang wrote:
> Hey, all
> 
> Will you please tell me how to generate multiple
> square orthogonal matrices for data transformation usage?
> 
> Thanks.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From laurent at cbs.dtu.dk  Fri Feb 28 07:42:03 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Fri Feb 28 07:42:03 2003
Subject: [R] R (external ?) reference
Message-ID: <20030228064256.GA45986607@genome.cbs.dtu.dk>

Dear List,

I found a documentation on the web that mentions things like 'R references'
(http://www.stat.uiowa.edu/~luke/R/simpleref.html).

However, I could not find the R_MakeReference and friends in R...
Does anyone knows more about that ?


Thanks,


L.



From mona at sun3.oulu.fi  Fri Feb 28 08:20:04 2003
From: mona at sun3.oulu.fi (Mona Riihimaki)
Date: Fri Feb 28 08:20:04 2003
Subject: [R] Mean Squares
Message-ID: <Pine.GSO.4.44.0302280915020.16669-100000@sun3.oulu.fi>

Hi!

I've done lme-analysis with R; three fixed factors, one random, and the
dependent variable is continous. The results print out only the F-values
and p-values. I'd need also the mean squares.

I was not able to find the command for MSs from R Help - would somebody be
able to help me with this code?

Cheers,
Mona-Anitta Riihim?ki

*********************************************
Mona-Anitta Riihim?ki
University of Oulu, Department of Biology
P.O.Box 3000, FIN-90401 Oulu
Tel. +358 (0)8 553 1795
Fax +358 (0)8 553 1061
E-mail Mona.Riihimaki at Oulu.fi
http://cc.oulu.fi/~genetwww/plants/index.html



From ripley at stats.ox.ac.uk  Fri Feb 28 08:27:05 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 28 08:27:05 2003
Subject: [R] NULL object, R programming
In-Reply-To: <Pine.LNX.4.44.0302272152030.19878-100000@argos.its.yale.edu>
Message-ID: <Pine.LNX.4.44.0302280721020.19298-100000@gannet.stats>

On Thu, 27 Feb 2003, Makram Talih wrote:

[...]

> Is this a desired effect? If so, could it be built in a 'help(NULL)' file?

It's not to do with NULL, but to do with [[<-.  It is Q7.3 in the FAQ.
Did you check the FAQ?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Roger.Bivand at nhh.no  Fri Feb 28 08:49:03 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri Feb 28 08:49:03 2003
Subject: [R] File opening error after 1020 files opened
In-Reply-To: <20030228042739.GA15952@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.44.0302280841140.3081-100000@reclus.nhh.no>

On Thu, 27 Feb 2003, Dirk Eddelbuettel wrote:

> On Thu, Feb 27, 2003 at 08:08:48PM -0800, jonathan_li at agilent.com wrote:
> > The file open failed at when i=1021. So the difference in when file openning
> > fails is due to the difference in system, not to the fact that I am openning
> > different files each time.
> 
> It's a question for the operating system / kernel. See e.g. what I just
> found via Google at
> 
>   http://www.jguru.com/faq/view.jsp?EID=239607 
> 	
> and which answers the question "How can I increase the number of sockets and
> files that I can simultaneously have open under Linux?" as follows:
> 
>   Linux 2.2.x kernels allow control of the maximum number of open files
>   through the /proc/sys/fs/file-max pseudo-file. Read that file to see the
>   current limits; write a new value to it to change the limit. For example:
> 
>   cat /proc/sys/fs/file-max
>   echo 16384 >/proc/sys/fs/file-max
>     
>   You may also find it useful to manipulate the kernel inode limit. This
>   is controlled, using the same techniques, through the 
>   /proc/sys/fs/inode-max pseudo-file.
> 
> On my Debian systems this would appear to be set to 4096, both under 2.2 and
> 2.4 kernels. 
> 
> Still, what seems odd is that the pixmap library doesn't close the
> filehandle after reading.  It seems to me that you should be able to 
> loop endlessly over the ops open; do something; close; repeat as that
> would only consume one file handle at a time.

Since I wrote that bit of pixmap, could I ask that people report which
version they are using (help(package=pixmap))? If you are using 0.3-1, you
will see that function read.pnm() makes a connection to a file, opens it,
reads it, and closes the connection. I don't have a copy of 0.3-0 to hand,
but believe it did the same. Could you please confirm that we are all
looking at 0.3-1?

Roger

> 
> Dirk
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From hb at maths.lth.se  Fri Feb 28 09:03:03 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri Feb 28 09:03:03 2003
Subject: [R] File opening error after 1020 files opened
In-Reply-To: <Pine.LNX.4.44.0302280841140.3081-100000@reclus.nhh.no>
Message-ID: <000301c2deff$c0e2c8f0$7341a8c0@alpha.wehi.edu.au>

When running my WinXP Pro testing I used pixmap 0.3-1:

pixmap          Bitmap Images (``Pixel Maps'')

Description:

Package: pixmap
Version: 0.3-1
Title: Bitmap Images (``Pixel Maps'')
Depends: R (>= 1.6.0)
Author: Friedrich Leisch and Roger Bivand
Maintainer: Friedrich Leisch <Friedrich.Leisch at ci.tuwien.ac.at>
Description: Functions for import, export, plotting and other
        manipulations of bitmapped images.
License: GPL version 2.
Built: R 1.6.2; Win32; Wed Feb 19 08:24:37 GMTST 2003

/Henrik

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Roger Bivand
> Sent: den 28 februari 2003 18:50
> To: Dirk Eddelbuettel
> Cc: jonathan_li at agilent.com; hb at maths.lth.se; r-help at stat.math.ethz.ch
> Subject: Re: [R] File opening error after 1020 files opened
> 
> 
> On Thu, 27 Feb 2003, Dirk Eddelbuettel wrote:
> 
> > On Thu, Feb 27, 2003 at 08:08:48PM -0800, jonathan_li at agilent.com 
> > wrote:
> > > The file open failed at when i=1021. So the difference in 
> when file 
> > > openning fails is due to the difference in system, not to 
> the fact 
> > > that I am openning different files each time.
> > 
> > It's a question for the operating system / kernel. See e.g. what I 
> > just found via Google at
> > 
> >   http://www.jguru.com/faq/view.jsp?EID=239607
> > 	
> > and which answers the question "How can I increase the number of 
> > sockets and files that I can simultaneously have open under 
> Linux?" as 
> > follows:
> > 
> >   Linux 2.2.x kernels allow control of the maximum number 
> of open files
> >   through the /proc/sys/fs/file-max pseudo-file. Read that 
> file to see the
> >   current limits; write a new value to it to change the limit. For 
> > example:
> > 
> >   cat /proc/sys/fs/file-max
> >   echo 16384 >/proc/sys/fs/file-max
> >     
> >   You may also find it useful to manipulate the kernel 
> inode limit. This
> >   is controlled, using the same techniques, through the 
> >   /proc/sys/fs/inode-max pseudo-file.
> > 
> > On my Debian systems this would appear to be set to 4096, 
> both under 
> > 2.2 and 2.4 kernels.
> > 
> > Still, what seems odd is that the pixmap library doesn't close the 
> > filehandle after reading.  It seems to me that you should 
> be able to 
> > loop endlessly over the ops open; do something; close; 
> repeat as that 
> > would only consume one file handle at a time.
> 
> Since I wrote that bit of pixmap, could I ask that people 
> report which version they are using (help(package=pixmap))? 
> If you are using 0.3-1, you will see that function read.pnm() 
> makes a connection to a file, opens it, reads it, and closes 
> the connection. I don't have a copy of 0.3-0 to hand, but 
> believe it did the same. Could you please confirm that we are 
> all looking at 0.3-1?
> 
> Roger
> 
> > 
> > Dirk
> > 
> > 
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, 
> Norwegian School of Economics and Business Administration, 
> Breiviksveien 40, N-5045 Bergen, Norway. voice: +47 55 95 93 
> 55; fax +47 55 95 93 93
> e-mail: Roger.Bivand at nhh.no
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From remigijus.lapinskas at maf.vu.lt  Fri Feb 28 09:55:03 2003
From: remigijus.lapinskas at maf.vu.lt (Remigijus Lapinskas)
Date: Fri Feb 28 09:55:03 2003
Subject: [R] optim
Message-ID: <12453.030228@maf.vu.lt>

Dear all,

I have a function MYFUN which depends on 3 positive parameters TETA[1],
TETA[2], and TETA[3]; x belongs to [0,1].
I integrate the function over [0,0.1], [0.1,0.2] and
[0.2,0.3] and want to choose the three parameters so that
these three integrals are as close to, resp., 2300, 4600 and 5800 as
possible. As I have three equations with three unknowns, I expect the
exact fit, i.e., the SS (see below) to be zero. However, the optim
function never gives me what I expect, the minimal SS value(=res$value)
never comes close to zero, the estimates of the parameters, res$par,
wildly depends on init etc.
I would be grateful for any comments on this miserable situation.

aa <- c(2300,4600,5800)
init <- c(2.5,8000,0.84) # initial values of parameters
print(init)
###################
myfun <- function(x,TETA) TETA[2]*(((1-x)^(-1/TETA[3]))-
1)^(1/TETA[1])
###################
x <- seq(0,0.3,by=0.01)
plot(x,myfun(x,init),type="l")
###################
LSS <- function(teta,aa)
{
integr <- numeric(3)
   for(i in 1:3)
   {integr[i] <- 10*integrate(myfun,
   lower=(i-1)/10,upper=i/10,TETA=teta)$value
   }
SS <- sum((integr-aa)^2) # SS=Sum of Squares
SS
}
####################
res <- optim(init,LSS,aa=aa,
method = "L-BFGS-B",lower=c(0,0,0.5))
print(res$par)
print(res$value)


> source("C:/Program Files/R/integral.R")
[1]    2.50      7000.00         0.84        # initial
[1]    2.3487221 6999.9999823    0.5623628   # final
[1] 75613.05                                 # minSS
> source("C:/Program Files/R/integral.R")
[1]     2.5      15000            0.84       # initial
[1]     2.125804 14999.999747     2.241179   # final
[1] 50066.35                                 # minSS



Best regards,
Remigijus                          mailto:remigijus.lapinskas at maf.vu.lt



From bhx2 at mevik.net  Fri Feb 28 10:03:04 2003
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge?= Mevik)
Date: Fri Feb 28 10:03:04 2003
Subject: [R] Mean Squares
In-Reply-To: <Pine.GSO.4.44.0302280915020.16669-100000@sun3.oulu.fi>
References: <Pine.GSO.4.44.0302280915020.16669-100000@sun3.oulu.fi>
Message-ID: <7olm00pyuc.fsf@foo.nemo-project.org>

Mona Riihimaki <mona at sun3.oulu.fi> writes:

> I've done lme-analysis with R; [...] I'd need also the mean squares.

AFAIK, lme doesn't calculate sum of squares (or mean squares).  It
maximises the likelihood (or restricted likelihood) and uses tests
based on likelihood ratios.

-- 
Bj?rn-Helge Mevik



From maechler at stat.math.ethz.ch  Fri Feb 28 10:10:28 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Feb 28 10:10:28 2003
Subject: [R] Concerning the clustering tree
In-Reply-To: <000b01c2deb3$fbf9ce80$f8ceda80@ntomioka>
References: <000b01c2deb3$fbf9ce80$f8ceda80@ntomioka>
Message-ID: <15967.9803.632823.202970@gargle.gargle.HOWL>

>>>>> "Nobumoto" == Nobumoto Tomioka <ntomioka at cc.ucsf.edu>
>>>>>     on Thu, 27 Feb 2003 15:00:11 -0800 writes:

    Nobumoto> Dear Stuff,
[you probably meant "staff" but that's not much better:
 There's no paid staff for the R project.
 It's all volunteering ! ]

    Nobumoto> I am trying to enjoy "PAM", but I could not
    Nobumoto> recognize which sample is in which branches in the
    Nobumoto> clustering tree because of too many samples and
    Nobumoto> size limitation for my monitor.

I first thought you were talking about PAM as in
Kaufman & Rousseeuw (1990) and  pam() from the (recommended)
cluster package.
Now I found that you meant the "pamr" CRAN package ...
it would have been helpful if you had told us so.
Also, for packages like these, it is customary to ask the package
maintainers {library(help = pamr) gives you}  rather than on R-help.

Further note that when I do
> library(pamr)

I now get
>> 
>> Attaching package 'pamr':
>> 
>> 
>> 	The following object(s) are masked from package:MASS :
>> 
>> 	 enlist 

(this is a bit unfortunate, since MASS is a recommended package
 in all newer engines of S)

>> 
>> There were 48 warnings (use warnings() to see them)

>> > warnings()
>> Warning messages:
>> 1: The use of _ is soon to be removed: you will be warned repeatedly
>> 2: The use of _ is soon to be removed: you will be warned repeatedly
>> 3: The use of _ is soon to be removed: you will be warned repeatedly
>> 4: The use of _ is soon to be removed: you will be warned repeatedly
>> ......
>> ......

{I hope you all take note of this if you haven't before!}


    Nobumoto> size limitation for my monitor.  I mean, I did
    Nobumoto> unsupervised clustering with "PAM" (
    Nobumoto> data2$newy<-pamr.makeclasses(data2) ) 
    Nobumoto> with 275 primary samples, but samples were piled up at the
    Nobumoto> point of each branch, so I cannot recognize them.
    Nobumoto> Can we get the output file with clustered
    Nobumoto> information ?  Can we change the size of charactor
    Nobumoto> ?  Please let me know how should I do for it.
    Nobumoto> Best regards

I see that the function calls  dist() and hclust() 
from the "mva" package and also plot.hclust() indirectly.
Also help(pamr.makeclasses) says that the function is fragile.
Unfortunately, it does not allow to pass arguments to plot.hclust()
(it passes everything ("...") only to hclust().
plot(hclust(..), cex = 0.6)  would work (if the cex was passed),
but as I see, setting par(cex = 0.6) globally
does not work with plot.hclust().

To solve this, it seems you need to change the
pamr.makeclasses() function, e.g. allowing it to pass a `cex'
parameter.

[BTW: `Netiquette' recommends E-mail signatures of 3-6 lines or so,
      *not* the 24 lines you used for all the address information!]

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ripley at stats.ox.ac.uk  Fri Feb 28 10:32:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 28 10:32:03 2003
Subject: [R] optim
In-Reply-To: <12453.030228@maf.vu.lt>
Message-ID: <Pine.LNX.4.44.0302280926590.23603-100000@gannet.stats>

Do read the help page.  It says:

     `fnscale' An overall scaling to be applied to the value of `fn'
          and `gr' during optimization. If negative, turns the problem
          into a maximization problem. Optimization is performed on
          `fn(par)/fnscale'.

     `parscale' A vector of scaling values for the parameters.
          Optimization is performed on `par/parscale' and these should
          be comparable in the sense that a unit change in any element
          produces about a unit change in the scaled value.

You have not used either, AFAICS.

Also, I doubt if the function value returned by calls to integrate is a 
smooth function of the parameters, so scaling is particularly important 
here, and you may need to supply ndeps too.

Attempting to optimize blindly without supplying derivatives is asking far 
too much of a computer program.


On Fri, 28 Feb 2003, Remigijus Lapinskas wrote:

> Dear all,
> 
> I have a function MYFUN which depends on 3 positive parameters TETA[1],
> TETA[2], and TETA[3]; x belongs to [0,1].
> I integrate the function over [0,0.1], [0.1,0.2] and
> [0.2,0.3] and want to choose the three parameters so that
> these three integrals are as close to, resp., 2300, 4600 and 5800 as
> possible. As I have three equations with three unknowns, I expect the
> exact fit, i.e., the SS (see below) to be zero. However, the optim
> function never gives me what I expect, the minimal SS value(=res$value)
> never comes close to zero, the estimates of the parameters, res$par,
> wildly depends on init etc.
> I would be grateful for any comments on this miserable situation.
> 
> aa <- c(2300,4600,5800)
> init <- c(2.5,8000,0.84) # initial values of parameters
> print(init)
> ###################
> myfun <- function(x,TETA) TETA[2]*(((1-x)^(-1/TETA[3]))-
> 1)^(1/TETA[1])
> ###################
> x <- seq(0,0.3,by=0.01)
> plot(x,myfun(x,init),type="l")
> ###################
> LSS <- function(teta,aa)
> {
> integr <- numeric(3)
>    for(i in 1:3)
>    {integr[i] <- 10*integrate(myfun,
>    lower=(i-1)/10,upper=i/10,TETA=teta)$value
>    }
> SS <- sum((integr-aa)^2) # SS=Sum of Squares
> SS
> }
> ####################
> res <- optim(init,LSS,aa=aa,
> method = "L-BFGS-B",lower=c(0,0,0.5))
> print(res$par)
> print(res$value)
> 
> 
> > source("C:/Program Files/R/integral.R")
> [1]    2.50      7000.00         0.84        # initial
> [1]    2.3487221 6999.9999823    0.5623628   # final
> [1] 75613.05                                 # minSS
> > source("C:/Program Files/R/integral.R")
> [1]     2.5      15000            0.84       # initial
> [1]     2.125804 14999.999747     2.241179   # final
> [1] 50066.35                                 # minSS
> 
> 
> 
> Best regards,
> Remigijus                          mailto:remigijus.lapinskas at maf.vu.lt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mmarques at power.inescn.pt  Fri Feb 28 10:52:03 2003
From: mmarques at power.inescn.pt (Mark Marques)
Date: Fri Feb 28 10:52:03 2003
Subject: [R] Pam and Fanny vector length problems
Message-ID: <1521737468.20030228095102@power.inescn.pt>

  I have "small" problem ...
  with the cluster library  each time I try to use
  the "agnes","pam","fanny" functions with more than 20000 elements
  I get the following error:
  >Error in vector("double", length) : negative length vectors are not allowed
  >In addition: Warning message:
  >NAs introduced by coercion

  But with the clara function everything works fine...
  What could be wrong ?

  Thanks in advance

 From 
 Mark
 mailto:mmarques at power.inescn.pt



From vito.muggeo at giustizia.it  Fri Feb 28 11:11:02 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Fri Feb 28 11:11:02 2003
Subject: [R] updating glm
References: <000b01c2dee9$47b7f6a0$8bd75ba5@IE.TAMU.EDU> <3E5EF71C.7040700@pdf.com>
Message-ID: <009501c2df10$f5f5e980$5c13070a@it.giustizia.it>

Dear all,
my function fn() (see code below) just takes a glm object and updates it by
including a function of a specified variable in dataframe.

 x<-1:50
 y<-rnorm(50)
 d<-data.frame(yy=y,xx=x);rm(x,y)
 o<-glm(yy~xx,data=d)

> fn(obj=o,x=xx)

Call:  glm(formula = yy ~ xx + x1, data = obj$data)
....[SNIP]....

It works but I have two problems:
1)In the returning glm object the name of the dataframe is "obj$data", but I
would like to get the original one, i.e. "d";

2)fn() does not work if glm() is called without the data argument, namely
> attach(d)
>  o<-glm(yy~xx)
> fn(obj=o,x=xx)
Error in eval(expr, envir, enclos) : Object "x1" not found

Here there seems to be some problem with the scoping rule; could you suggest
me how solve this problem? Also I'm almost sure that there exist a much more
elegant solution instead of the mine used; I tried get(), environment() and
friends, but without any success....Could you suggest me anything?

thanks in advance,
vito


#########
function(obj,x){
 if(!is.null(obj$call$data)){
  attach(eval(obj$call$data))
  on.exit(detach(eval(obj$call$data)))
    }
 x1<-ifelse(x>mean(x),1,0)
 if(!is.null(obj$call$data)) obj$data$x1<-x1
 obj1<-update(obj,.~.+x1,data=obj$data)
 return(obj1)
 }



From john_hendrickx at yahoo.com  Fri Feb 28 11:22:03 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Fri Feb 28 11:22:03 2003
Subject: [R] (multiway) percentage tables
Message-ID: <20030228102151.64046.qmail@web14202.mail.yahoo.com>

R has amazing capabilities, but percentage tables are a weak spot
IMHO. There's prop.table but that's rather unwieldly, especially for
multiway tables. CrossTable by Marc Schwartz in the gregmisc library
makes percentage tables a breeze but is limited to two-way tables. So
I decided to try my own hand at writing an R-function that would make
it easy to produce nicely formatted percentage tables for one-way,
two-way, or multi-way tables.

The first argument for ctab can be either a table object or one or
more factors. The first variable is assumed to be the row variable,
the second the column variable, subsequent variables are grouping
variables. The "type" option can be used to specify percentage type
("n", "row", "column", or "total"), "digits" to specify the number of
decimal points, "percentage=FALSE" can be used to print proportions
rather than percentages. "row.vars" and "col.vars" are passed on to
ftables for formatting multiway tables.

I'd like to see something like ctab in R-base at some point in the
future. Perhaps it could be integrated in ftable? Perhaps I'll try
that myself as a next project. I'm still learning R so comments on
ctab are most welcome.

Best,
John Hendrickx

----------------examples of usage ------------------------
source("ctab.R")
data(Titanic)
ctab(Titanic)
ctab(Titanic,type="r")
ctab(Titanic,row.vars=1:3,type="r")
ctab(Titanic,col.vars=c(2,4),type="r")
ctab(Titanic,row.vars=c(1,3),type="c")
ctab(Titanic,col.vars=c("Sex","Survived"),type="r")
ctab(Titanic,col.vars=c("Sex","Survived"),type="t")
------------------ ctab ----------------------------------
# ctab: oneway, twoway, multiway percentage tables
# first argument must consist of one or more factors
# or a table object (class table, xtabs, or ftable)
# digits: number of digits after the decimal (default 2)
# type: "n" for counts, "row", "column" or "total"
# for percentages (default "n")
# row.vars:
# col.vars: same usage as ftable, ignored for one- and
# two-way tables
# percentages: FALSE==> proportions are presented rather
# than percentages (default TRUE)

# comments to John Hendrickx <John_Hendrickx at yahoo.com>

ctab<-function(...,digits=2,
		type=c("n", "row", "column", "total"),
		row.vars=NULL, col.vars=NULL,
		percentages=TRUE) {
	if (attributes(...)$class=="factor") {
		# create a table if the arguments are factors
		tbl<-table(...)
	}
	else if ("table" %in% class(...) || class(...)=="ftable") {
		# the argument is a table object (table, xtabs, ftable)
		tbl<-eval(...)
	}
	else {
		stop("first argument must be either factors or a table object")
	}

	type<-match.arg(type)

	# one dimensional table,restrict choices to "n" and "total"
	if (length(dim(tbl))==1) {
		type<-ifelse(type=="n","n","total")
	}

	# if the object is an ftable, use the row.vars and col.vars
	# use numeric indices to avoid finding the omitted
	# the object must be converted to a table to get the dimensions
right
	if (class(tbl)=="ftable") {
		nrowvar<-length(names(attr(tbl,"row.vars")))
		row.vars<-1:nrowvar
		col.vars<-(1:length(names(attr(tbl,"col.vars"))))+nrowvar
		tbl<-as.table(tbl)
	}

	# marginals to exclude assuming first factor is the row vaariable,
	# second factor is the column variable
	# is overridden by row.vars or col.vars
	mrg2drop<-0
	if (type=="column") {mrg2drop<-1}
	if (type=="row") {mrg2drop<-2}
	if (type=="total" && length(dim(tbl)) > 1) {mrg2drop<-c(1,2)}


	# use row.vars and col.vars to determine the
	# marginals to use when calculating percentages
	# start by translating names to variable positions
	nms<-names(dimnames(tbl))
	if (!is.null(row.vars) && !is.numeric(row.vars)) {
		row.vars<-order(match(nms,row.vars),na.last=NA)
	}
	if (!is.null(col.vars) && !is.numeric(col.vars)) {
		col.vars<-order(match(nms,col.vars),na.last=NA)
	}
	# calculate the other if only one is given
	if (!is.null(row.vars) && is.null(col.vars)) {
		col.vars<-(1:length(dim(tbl)))[-row.vars]
	}
	if (!is.null(col.vars) && is.null(row.vars)) {
		row.vars<-(1:length(dim(tbl)))[-col.vars]
	}
	# now determine the margin as the last element
	if (type=="row" && !is.null(col.vars)) {
		mrg2drop<-col.vars[length(col.vars)]
	}
	if (type=="column" && !is.null(row.vars)) {
		mrg2drop<-row.vars[length(row.vars)]
	}
	# if row.vars is given, col.vars has been determined
	if (type=="total" && !is.null(row.vars)) {
		mrg2drop<-c(col.vars[length(col.vars)],row.vars[length(row.vars)])
	}

	marg<-(1:length(dim(tbl)))[(-mrg2drop)]

	# create percentages
	if (type=="n") {
		digits<-0
	}
	else {
		tbl<-prop.table(tbl,marg)
		if (percentages) {tbl<-tbl*100}
	}


	# use ftable for more than 2 dimensions
	# (ftable doesn't work for 1 dimension,
	# and table is nicer for 2 dimensions IMHO
	if (length(dim(tbl))>2) {
		if (is.null(row.vars)) {
			# let the second variable be the column variable
			row.vars<-names(dimnames(tbl))[-2]
			# reverse the order, last variables are groups, first is row
variable
			row.vars<-rev(row.vars)
		}
		tbl<-ftable(tbl,row.vars=row.vars,col.vars=col.vars)
	}

	# get the names of the column variable
	if (class(tbl)=="ftable") {
		nms<-attr(tbl,"col.vars")[[1]]
	}
	else if (length(dim(tbl))==1) {
		nms<-dimnames(tbl)[[1]]
	}
	else{
		nms<-dimnames(tbl)[[2]]
	}

	# present the (percentage) table
	wd<-max(nchar(nms),nchar(as.integer(tbl))+digits+1)
	tbl<-formatC(tbl,format="f",width=wd,digits=digits)
	tbl
}
----------------------------------------------------------



From cg.pettersson at evp.slu.se  Fri Feb 28 11:51:03 2003
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Fri Feb 28 11:51:03 2003
Subject: [R] na.action in model.tables and TukeyHSD
Message-ID: <200302281050.LAA18422@mail1.slu.se>

In 27/2, I got the following answer from Prof. Ripley: (The question is at the bottom)

>This ia already fixed in R-devel.  The answer is the same: don't use
>na.omit implicitly: use it explicitly. 

I feel rather stupid for the moment, as I don?t understand an answer that looks very simple.
What?s the code to do the trick using na.omit explicitly? (Preferably starting with my code in the question)
I can?t get it to work, so my tries are not worth printing here...

Thanks
/CG

On Wed, 26 Feb 2003, CG Pettersson wrote: > Hello everybody!
>
> I use R 1.6.2 in Windows, and have a problem controlling the na.action.
>
> In a dataset with twelve trials, one of the trials lack any readings of the variable "STS.SH" (standing power at harvest)
>
> Fitting an aov() object with the call:
> led1t7sts.aov <- aov(STS.SH ~ Trial/Block + Treatment + Treatment:Trial, data = led1t7, na.action=na.exclude) 
> seems to work as it produces an object with 10 df for the factor "Trial".
>
> But when I use model.tables or TukeyHSD on the object I get this:
> > model.tables(led1t7sts.aov, "means")
> Error in replications(paste("~", paste(names(tables), collapse = "+")),  :
>         na.action must be a function
>
> I have tried to use "na.action=na.exclude" inside the model.tables call as well, without any bettering.
>
> I can naturally cope with the problem by taking the whole trial away from the dataset, but it doesn?t feel very sophisticated...;-)
> (Prof. Ripley answered a similar question from me two weeks ago. The answer was good but didn?t work as the reason of the error was the same as this time: a 
whole
> trial with only na:s in it).
>
> Thanks
> /CG
> CG Pettersson
> cg.pettersson at evp.slu.se
CG Pettersson
cg.pettersson at evp.slu.se



From Patrik.Waldmann at djingis.se  Fri Feb 28 12:10:29 2003
From: Patrik.Waldmann at djingis.se (Patrik Waldmann)
Date: Fri Feb 28 12:10:29 2003
Subject: [R] Tabulating
Message-ID: <000801c2df19$e2cc6e20$a110a8c0@djingisob7lo8t>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030228/83c390ff/attachment.pl

From maechler at stat.math.ethz.ch  Fri Feb 28 12:15:51 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Feb 28 12:15:51 2003
Subject: [R] Pam and Fanny vector length problems
In-Reply-To: <1521737468.20030228095102@power.inescn.pt>
References: <1521737468.20030228095102@power.inescn.pt>
Message-ID: <15967.16793.676772.511019@gargle.gargle.HOWL>

>>>>> "Mark" == Mark Marques <mmarques at power.inescn.pt>
>>>>>     on Fri, 28 Feb 2003 09:51:02 +0000 writes:

    Mark> I have "small" problem ...
    Mark> with the cluster library  each time I try to use
    Mark> the "agnes","pam","fanny" functions with more than 20000 elements
    Mark> I get the following error:
    >> Error in vector("double", length) : negative length vectors are not allowed
    >> In addition: Warning message:
    >> NAs introduced by coercion

"negative" is certainly misleading here; I presume it's an
integer overflow somewhere.
But (with agnes()) I could never get close, even
  a <- agnes(dist(cbind(1,rnorm(5000))))
pumps my R up to a memory footprint of 638 MBytes...

    Mark> But with the clara function everything works fine...

because clara() is for  large applications !!
In clustering, 20000 is definitely "large".
I would recommend to use quite a bit larger `samples' and `sampsize'
than the default in clara().

All routines but clara() work with a dissimilarity/distance object
of size n*(n-1)/2  (basically one the triangles of a symmetric n^2 matrix).
The implementation will need to duplicate these at least, and
one double is 8 bytes.

    Mark> What could be wrong ?

You have no chance of getting anything from agnes() or pam()
when you want to cluster 20'000 objects at least not on 32-bit computers.

It seems though one could carefully change agnes() (e.g.) to use
less duplication of the large objects and save memory..


Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From gavin.simpson at ucl.ac.uk  Fri Feb 28 14:06:19 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri Feb 28 14:06:19 2003
Subject: [R] summary.glm() print problem(?) with cor = TRUE
Message-ID: <001601c2df2a$69252e20$4c202880@gsimpson>

Hi,

I've had a look the bug list and searched though the R documentation, email
lists etc. but didn't see anything on this:

when I do:

summary(species.glm1, correlation = TRUE)

I get a correlation matrix like this:

Correlation of Coefficients:
        ( p I(H C
pH      * 1      
I(pH^2) * B 1    
Ca        . .   1
I(Ca^2)   . .   B
attr(,"legend")
[1] 0 ` ' 0.3 `.' 0.6 `,' 0.8 `+' 0.9 `*' 0.95 `B' 1

I'm not worried about the symbolic representation, but should the columns be
labelled this way?  I can work out which is which, but it isn't immediately
clear and doesn't look "nice".  Is this printing intended?

Because when I do:

print(summary(species.glm3, correlation = TRUE), symbolic.cor = FALSE)

I get a much more nicely formatted correlation matrix:

Correlation of Coefficients:
        (Intercept)      pH I(pH^2)      Ca
pH          -0.9321                        
I(pH^2)      0.9233 -0.9968                
Ca           0.1442 -0.4893  0.4950        
I(Ca^2)     -0.1619  0.5009 -0.5162 -0.9876

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.2            
year     2003           
month    01             
day      10             
language R 

Cheers

Gav

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Dr. Gavin Simpson                 [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From bates at stat.wisc.edu  Fri Feb 28 14:14:51 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Feb 28 14:14:51 2003
Subject: [R] Mean Squares
In-Reply-To: <7olm00pyuc.fsf@foo.nemo-project.org>
References: <Pine.GSO.4.44.0302280915020.16669-100000@sun3.oulu.fi>
	<7olm00pyuc.fsf@foo.nemo-project.org>
Message-ID: <6rwujk5ze2.fsf@bates4.stat.wisc.edu>

bhx2 at mevik.net (Bj?rn-Helge Mevik) writes:

> Mona Riihimaki <mona at sun3.oulu.fi> writes:
> 
> > I've done lme-analysis with R; [...] I'd need also the mean squares.
> 
> AFAIK, lme doesn't calculate sum of squares (or mean squares).  It
> maximises the likelihood (or restricted likelihood) and uses tests
> based on likelihood ratios.

Yes - you are correct.



From lehmann at puk.unibe.ch  Fri Feb 28 14:21:03 2003
From: lehmann at puk.unibe.ch (Christoph Lehmann)
Date: Fri Feb 28 14:21:03 2003
Subject: [R] show numbers not rounded
Message-ID: <1046438297.1404.42.camel@christophl>

how can I show an number not rounded, but in the format, eg. x.xxxx 

e.g. 
> signif(1-pf(((RSSred-RSSful)/2)/(RSSful/(34-3)),2,34-3),digits = 5)

shows
[1] 0

but I need something like

[1] 2.2e-16


thanks
christoph
-- 
Christoph Lehmann                            Phone:  ++41 31 930 93 83 
Department of Psychiatric Neurophysiology    Mobile: ++41 76 570 28 00
University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61 
Waldau                                            lehmann at puk.unibe.ch 
CH-3000 Bern 60            http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html



From gavin.simpson at ucl.ac.uk  Fri Feb 28 14:43:02 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri Feb 28 14:43:02 2003
Subject: [R] show numbers not rounded
In-Reply-To: <1046438297.1404.42.camel@christophl>
Message-ID: <001c01c2df2f$381fa490$4c202880@gsimpson>

format.pval() as in:

format.pval(1-pf(((RSSred-RSSful)/2)/(RSSful/(34-3)),2,34-3),digits = 5)

see ?format for more information

Gav

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Dr. Gavin Simpson                 [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

-----Original Message-----
From: r-help-admin at stat.math.ethz.ch [mailto:r-help-admin at stat.math.ethz.ch]
On Behalf Of Christoph Lehmann
Sent: 28 February 2003 13:18
To: r-help at stat.math.ethz.ch
Subject: [R] show numbers not rounded


how can I show an number not rounded, but in the format, eg. x.xxxx 

e.g. 
> signif(1-pf(((RSSred-RSSful)/2)/(RSSful/(34-3)),2,34-3),digits = 5)

shows
[1] 0

but I need something like

[1] 2.2e-16


thanks
christoph
-- 
Christoph Lehmann                            Phone:  ++41 31 930 93 83 
Department of Psychiatric Neurophysiology    Mobile: ++41 76 570 28 00
University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61 
Waldau                                            lehmann at puk.unibe.ch 
CH-3000 Bern 60            http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Fri Feb 28 15:13:02 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri Feb 28 15:13:02 2003
Subject: [R] na.action in model.tables and TukeyHSD
In-Reply-To: <200302281050.LAA18422@mail1.slu.se>
Message-ID: <Pine.WNT.4.44.0302281411120.2668-100000@gannet.stats.ox.ac.uk>

ndata <- na.omit(led1t7sts) and work with ndata.

Why is that difficult?

On Fri, 28 Feb 2003, CG Pettersson wrote:

> In 27/2, I got the following answer from Prof. Ripley: (The question is at the bottom)
>
> >This ia already fixed in R-devel.  The answer is the same: don't use
> >na.omit implicitly: use it explicitly.
>
> I feel rather stupid for the moment, as I dont understand an answer that looks very simple.
> Whats the code to do the trick using na.omit explicitly? (Preferably starting with my code in the question)
> I cant get it to work, so my tries are not worth printing here...
>
> Thanks
> /CG
>
> On Wed, 26 Feb 2003, CG Pettersson wrote: > Hello everybody!
> >
> > I use R 1.6.2 in Windows, and have a problem controlling the na.action.
> >
> > In a dataset with twelve trials, one of the trials lack any readings of the variable "STS.SH" (standing power at harvest)
> >
> > Fitting an aov() object with the call:
> > led1t7sts.aov <- aov(STS.SH ~ Trial/Block + Treatment + Treatment:Trial, data = led1t7, na.action=na.exclude)
> > seems to work as it produces an object with 10 df for the factor "Trial".
> >
> > But when I use model.tables or TukeyHSD on the object I get this:
> > > model.tables(led1t7sts.aov, "means")
> > Error in replications(paste("~", paste(names(tables), collapse = "+")),  :
> >         na.action must be a function
> >
> > I have tried to use "na.action=na.exclude" inside the model.tables call as well, without any bettering.
> >
> > I can naturally cope with the problem by taking the whole trial away from the dataset, but it doesnt feel very sophisticated...;-)
> > (Prof. Ripley answered a similar question from me two weeks ago. The answer was good but didnt work as the reason of the error was the same as this time: a
> whole
> > trial with only na:s in it).
> >
> > Thanks
> > /CG
> > CG Pettersson
> > cg.pettersson at evp.slu.se
> CG Pettersson
> cg.pettersson at evp.slu.se
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Fri Feb 28 15:20:15 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Feb 28 15:20:15 2003
Subject: [R] Tabulating
Message-ID: <3A822319EB35174CA3714066D590DCD534BD56@usrymx25.merck.com>

If I understand you correctly, here's a quick and dirty way:

## Simulate some data:
x1 <- sample(3, 20, replace=TRUE)
x2 <- sample(3, 20, replace=TRUE)

x.tab <- table(x1, x2)
x.count <- c(diag(x.tab), x.tab[upper.tri(x.tab)] + x.tab[lower.tri(x.tab)])

The first 3 elements of x.count will be (1,1), (2,2) and (3,3), followed by
(1,2)/(2,1), (1,3)/(3,1) and (2,3)/(3,2).

HTH,
Andy

> -----Original Message-----
> From: Patrik Waldmann [mailto:Patrik.Waldmann at djingis.se]
> Sent: Friday, February 28, 2003 6:10 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Tabulating
> 
> 
> Hello,
> 
> I wonder if someone could send me suggestions on how to solve 
> the following problem:
> 
> I have a vector of an arbitrary size (ex. 
> data<-c(10,10,11,10,12,11,10,12,11,11,10,11)) and use the 
> table function, which gives the following result
> 10  11  12
> 5    5     2
> 
> that's fine, but what I would like to do now is: 
> 
> construct new classes based on the number of classes from 
> table, 10 10, 11 11, 12 12, 10 11, 10 12, 11 12. After that I 
> would like to do tabulation on the pairs in data, and 
> positions in pairs should be unimportant: 10 11 should be 
> treated as the same class as 11 10.
> So the following result should be obtained:
> 10 10, 11 11, 12 12, 10 11, 10 12, 11 12
> 1 , 1 , 0 , 2 , 1 , 2
> 
> Remeber that it should be possible to do for an arbitrary 
> number of classes.
> 
> Best regards,
> 
> Patrik.Waldmann at djingis.se
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------



From luke at stat.uiowa.edu  Fri Feb 28 15:35:03 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri Feb 28 15:35:03 2003
Subject: [R] R (external ?) reference
In-Reply-To: <20030228064256.GA45986607@genome.cbs.dtu.dk>
Message-ID: <Pine.LNX.4.44.0302280829270.11161-100000@itasca.stat.uiowa.edu>

On Fri, 28 Feb 2003, Laurent Gautier wrote:

> Dear List,
> 
> I found a documentation on the web that mentions things like 'R references'
> (http://www.stat.uiowa.edu/~luke/R/simpleref.html).
> 
> However, I could not find the R_MakeReference and friends in R...
> Does anyone knows more about that ?
> 

It's not as clear as it could be in that document but that part was
just a proposal.  It has not been implemented.  Something at the pure
R level along these lines can easily be implemented with environments;
something a bit more sophisticated may eventually make it into the
methods package.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From maechler at stat.math.ethz.ch  Fri Feb 28 15:45:03 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Feb 28 15:45:03 2003
Subject: [R] summary.glm() print problem(?) with cor = TRUE
In-Reply-To: <001601c2df2a$69252e20$4c202880@gsimpson>
References: <001601c2df2a$69252e20$4c202880@gsimpson>
Message-ID: <15967.30133.943227.222065@gargle.gargle.HOWL>

>>>>> "GS" == Gavin Simpson <gavin.simpson at ucl.ac.uk>
>>>>>     on Fri, 28 Feb 2003 13:07:55 -0000 writes:

    GS> Hi,
    GS> I've had a look the bug list and searched though the R documentation, email
    GS> lists etc. but didn't see anything on this:

    GS> when I do:

    GS> summary(species.glm1, correlation = TRUE)

    GS> I get a correlation matrix like this:

    GS> Correlation of Coefficients:

    GS>         ( p I(H C
    GS> pH      * 1      
    GS> I(pH^2) * B 1    
    GS> Ca        . .   1
    GS> I(Ca^2)   . .   B

    GS> attr(,"legend")
    GS> [1] 0 ` ' 0.3 `.' 0.6 `,' 0.8 `+' 0.9 `*' 0.95 `B' 1

    GS> I'm not worried about the symbolic representation, but
    GS> should the columns be labelled this way?  I can work out
    GS> which is which, but it isn't immediately clear and
    GS> doesn't look "nice".  Is this printing intended?

[we are talking about the print method for class "summary.lm",
 i.e. print.summary.glm() , and *.*.lm() ]

Yes, these column labels have been critized before and rightly so.
Currently, for R-devel, the default has even been changed from
 `symbolic.cor = p > 4' to  `symbolic.cor = FALSE' -- mostly
because of this, AFAIR -- and against my own opinion. 
I would have voted to change it to `symbolic.cor = p > 6' or so
(*and* to improve the column labels, too, see below).

As the original implementor I can tell you:
I've liked the idea of graphical correlation matrices which
motivated the "symbolic.cor" option to print.summary.* and the
underlying symnum() function.  
Since this is ASCII graphic, and showing (the lower triangle of)
a square matrix, I've felt the matrix should remain close to
``square'', also in its graphical form. 
Hence, the row labels were kept and the column labels
abbreviated "as much as possible" using R's internal abbreviate().
And this has given the very ugly "(" for "(Intercept)".
One easy possibility was to use more customized version of abbreviate()
either inside symnum() or by postprocessing ..

Given the topic, I'm really interested about your opinions on
the symbolic printing of correlation matrices.


    GS> Because when I do:

    GS> print(summary(species.glm3, correlation = TRUE), symbolic.cor = FALSE)

    GS> I get a much more nicely formatted correlation matrix:

    GS> Correlation of Coefficients:
    GS>         (Intercept)      pH I(pH^2)      Ca
    GS> pH          -0.9321                        
    GS> I(pH^2)      0.9233 -0.9968                
    GS> Ca           0.1442 -0.4893  0.4950        
    GS> I(Ca^2)     -0.1619  0.5009 -0.5162 -0.9876

It nicer only as long as it stays small, IMHO.
no longer for a 10 x 10 case; look at the examples in
help(symnum) !

Note that you can always say
 sglm <- summary(species.glm3, correlation = TRUE)
 sglm$corr
to see the matrix in its usual form

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From maechler at stat.math.ethz.ch  Fri Feb 28 15:58:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Feb 28 15:58:02 2003
Subject: [R] show numbers not rounded
In-Reply-To: <001c01c2df2f$381fa490$4c202880@gsimpson>
References: <1046438297.1404.42.camel@christophl>
	<001c01c2df2f$381fa490$4c202880@gsimpson>
Message-ID: <15967.30909.103570.641140@gargle.gargle.HOWL>

>>>>> "GS" == Gavin Simpson <gavin.simpson at ucl.ac.uk>
>>>>>     on Fri, 28 Feb 2003 13:42:21 -0000 writes:

    GS> format.pval() as in:
    GS> format.pval(1-pf(((RSSred-RSSful)/2)/(RSSful/(34-3)),2,34-3),digits = 5)

    GS> see ?format for more information

and if you want to make sure not to suffer from unnecessary
precision cancellation, 
use
	pf(S, df1,df2,  lower.tail = FALSE)
instead of
	1 - pf(S, df1,df2,  lower.tail = FALSE)

E.g.

  > pf(180, 2,31, lower.tail = FALSE)
  [1] 8.656982e-18
  > 1 - pf(180, 2,31)
  [1] 0

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


    GS> -----Original Message-----
    GS> From: r-help-admin at stat.math.ethz.ch [mailto:r-help-admin at stat.math.ethz.ch]
    GS> On Behalf Of Christoph Lehmann
    GS> Sent: 28 February 2003 13:18
    GS> To: r-help at stat.math.ethz.ch
    GS> Subject: [R] show numbers not rounded


    GS> how can I show an number not rounded, but in the format, eg. x.xxxx 

    GS> e.g. 
    >> signif(1-pf(((RSSred-RSSful)/2)/(RSSful/(34-3)),2,34-3),digits = 5)

    GS> shows
    GS> [1] 0

    GS> but I need something like

    GS> [1] 2.2e-16


    GS> thanks
    GS> christoph
    GS> -- 
    GS> Christoph Lehmann                            Phone:  ++41 31 930 93 83 
    GS> Department of Psychiatric Neurophysiology    Mobile: ++41 76 570 28 00
    GS> University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61 
    GS> Waldau                                            lehmann at puk.unibe.ch 
    GS> CH-3000 Bern 60            http://www.puk.unibe.ch/cl/pn_ni_cv_cl.html



From f.calboli at ucl.ac.uk  Fri Feb 28 16:21:02 2003
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: Fri Feb 28 16:21:02 2003
Subject: [R] chi square
Message-ID: <3.0.6.32.20030228152603.02483ab0@pop-server.ucl.ac.uk>

Hi All,

I woul like to ask you a couple of questions on chisq.test.

First, I have 40 flies, 14 males and 26 females and I want to test for an a
priori hypothesis that the sex ratio is 1:1

sex<-c(14,26)
pr<-c(1,1)/2
chisq.test(se, p=pr, correct=TRUE)

Chi-squared test for given probabilities

data:  sex 
X-squared = 3.6, df = 1, p-value = 0.05778

If my calculations are correct, this is the Chi-square without the Yates
correction. The value after correction would be X-squared = 3.02. How do I
apply Yates correction? 

Second, I want to do an homogeneity test on seed colour segregation. I have
green and yellow seed in an a priori expected segregation ration of 3:1.

green<-c(85,130,110,107,70,45,30)
yellow<-c(26,41,51,35,36,16,11)
chisq.test(rbind(green,yellow))

 Pearson's Chi-squared test

data:  rbind(verdi, gialli) 
X-squared = 6.2672, df = 6, p-value = 0.3939

That's fine. Now I want to tell chisq.test that I have my a priori expected
frequncies:

prob.green<-rep(3/4,7)
prob.yellow<-rep(1/4,7)
chisq.test(rbind(green,yellow), p=rbind(prob.green,prob.yellow))

 Pearson's Chi-squared test

data:  rbind(verdi, gialli) 
X-squared = 6.2672, df = 6, p-value = 0.3939

Exactly the same thing as before! How do I tell chisq.test to take my a
priori assumption into account? on paper I would calculate my seven X^2 on
my expectations, sum them and then subtracted the X^2 done on the sum. the
resulting X^2 of homogeneity is 6.6 on 6 df. Is my calculation on paper
sensible anyway?

Cheers,
Federico Calboli

=========================

Federico C.F. Calboli

Department of Biology
University College London
Room 327
Darwin Building
Gower Street
London
WClE 6BT

Tel: (+44) 020 7679 4395 
Fax (+44) 020 7679 7096
f.calboli at ucl.ac.uk



From pedro.aphalo at cc.jyu.fi  Fri Feb 28 17:05:04 2003
From: pedro.aphalo at cc.jyu.fi (Pedro J. Aphalo)
Date: Fri Feb 28 17:05:04 2003
Subject: [R] Mean Squares
References: <Pine.GSO.4.44.0302280915020.16669-100000@sun3.oulu.fi>
		<7olm00pyuc.fsf@foo.nemo-project.org> <6rwujk5ze2.fsf@bates4.stat.wisc.edu>
Message-ID: <3E5F8880.B4D953FC@cc.jyu.fi>


Douglas Bates wrote:
> 
> bhx2 at mevik.net (Bj?rn-Helge Mevik) writes:
> 
> > Mona Riihimaki <mona at sun3.oulu.fi> writes:
> >
> > > I've done lme-analysis with R; [...] I'd need also the mean squares.
> >
> > AFAIK, lme doesn't calculate sum of squares (or mean squares).  It
> > maximises the likelihood (or restricted likelihood) and uses tests
> > based on likelihood ratios.
> 
> Yes - you are correct.
> 
although the function is called anova.lme, is it still correct to talk
about "anova results" when referring to the results of these tests? and
in the case of the Wald tests in the single lme object case?

(sorry if this is a dumb question...)

Pedro.

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
==================================================================
Pedro J. Aphalo
Department of Biological and Environmental Science
P.O. Box 35
FIN-40014 University of Jyv?skyl?
Finland
mailto:pedro.aphalo at cc.jyu.fi
http://www.jyu.fi/~aphalo/                       ,,,^..^,,,



From spencer.graves at pdf.com  Fri Feb 28 17:37:04 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri Feb 28 17:37:04 2003
Subject: [R] Mean Squares
References: <Pine.GSO.4.44.0302280915020.16669-100000@sun3.oulu.fi>		<7olm00pyuc.fsf@foo.nemo-project.org> <6rwujk5ze2.fsf@bates4.stat.wisc.edu> <3E5F8880.B4D953FC@cc.jyu.fi>
Message-ID: <3E5F8FF6.2000609@pdf.com>

The term "anova" has evolved to include roughly any table with something 
like a partition of sums of squares even in non-normal situations, e.g., 
when using "glm" for logistic regression, where the "deviance" = 
(-2)*log(likelihood) is partitioned.

Hope this helps.
Spencer Graves

Pedro J. Aphalo wrote:
> 
> Douglas Bates wrote:
> 
>>bhx2 at mevik.net (Bj?rn-Helge Mevik) writes:
>>
>>
>>>Mona Riihimaki <mona at sun3.oulu.fi> writes:
>>>
>>>
>>>>I've done lme-analysis with R; [...] I'd need also the mean squares.
>>>
>>>AFAIK, lme doesn't calculate sum of squares (or mean squares).  It
>>>maximises the likelihood (or restricted likelihood) and uses tests
>>>based on likelihood ratios.
>>
>>Yes - you are correct.
>>
> 
> although the function is called anova.lme, is it still correct to talk
> about "anova results" when referring to the results of these tests? and
> in the case of the Wald tests in the single lme object case?
> 
> (sorry if this is a dumb question...)
> 
> Pedro.
> 
> 
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From jrogers at cantatapharm.com  Fri Feb 28 17:47:26 2003
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Fri Feb 28 17:47:26 2003
Subject: [R] Lexical scoping question
Message-ID: <99A12772DCDEEB458B996332957B0D53011776@mercury.cantatapharm.com>

Hello, 

Could someone please tell me what I am thinking about incorrectly:

f <- function(y) { 
  g <- function(x) x + y
  g
}

In the following, I get what I expect based on my understanding of
lexical scoping:

(f(1))(3) # 4
(f(2))(3) # 5

But now,

fs <- lapply(c(1, 2), f)
fs[[1]](3) # 5  (Why not 4 ?)
fs[[2]](3) # 5


Checking the environments of these functions, I see that "y" is indeed
bound to the value 2 in both cases:

es <- lapply(fs, environment)
ys <- lapply(es, function(env) get("y", env)) # list(2, 2)

?

Thanks for help,
Jim Rogers

James A. Rogers, Ph.D. <rogers at cantatapharm.com>
Statistical Scientist
Cantata Pharmaceuticals
3-G Gill St
Woburn, MA  01801
617.225.9009
Fax 617.225.9010



From charles.rosa at gm.com  Fri Feb 28 17:53:02 2003
From: charles.rosa at gm.com (charles.rosa@gm.com)
Date: Fri Feb 28 17:53:02 2003
Subject: [R] Help on rpart
Message-ID: <OFF078BB83.416AB962-ON85256CDB.005B45F0@mail.gm.com>

To whom it may concern,
I am using the rpart() function to perform a recursive tree analysis on a
set
of data that includes both numerical and categorical attributes.
At the end of the analysis, I would like to see the linear model at each
node in the tree.  In particular, I would like to see each node specific
model coefficients
associated with each of the independent variables and intercepts.

I've tried using the summary() method, but don't see this kind of
information.
How can I see this information?

Thanks, Charlie

-------------------------
Charles H. Rosa, Ph.D.
Staff Research Engineer, Research & Development
GM R&D
Warren, MI
Tel/work: +1 586 986-6032
Tel/cell: +1 781 367-5154



From white.denis at epamail.epa.gov  Fri Feb 28 18:07:02 2003
From: white.denis at epamail.epa.gov (white.denis@epamail.epa.gov)
Date: Fri Feb 28 18:07:02 2003
Subject: [R] Help on rpart
Message-ID: <OFBDAF88C6.26943041-ON88256CDB.005D8F48@rtp.epa.gov>

rpart (and tree) do not fit a linear model at each node, merely a
threshold split.  See Alexander, W. P., and Grimshaw, S. D. (1996),
"Treed Regression," Journal of Computational and Graphical Statistics,
5, 156-175, for an alternative that may meet your needs.

> I am using the rpart() function to perform a recursive tree analysis
on a
> set of data that includes both numerical and categorical attributes.
> At the end of the analysis, I would like to see the linear model at
each
> node in the tree.  In particular, I would like to see each node
specific
> model coefficients associated with each of the independent variables
and
> intercepts.
>
> I've tried using the summary() method, but don't see this kind of
> information.  How can I see this information?



From ripley at stats.ox.ac.uk  Fri Feb 28 18:15:26 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 28 18:15:26 2003
Subject: [R] Help on rpart
In-Reply-To: <OFF078BB83.416AB962-ON85256CDB.005B45F0@mail.gm.com>
Message-ID: <Pine.LNX.4.44.0302281713400.1423-100000@gannet.stats>

Rpart does not fit a linear model at any node.  Please read up on 
tree-based models.

On Fri, 28 Feb 2003 charles.rosa at gm.com wrote:

> To whom it may concern,
> I am using the rpart() function to perform a recursive tree analysis on a
> set
> of data that includes both numerical and categorical attributes.
> At the end of the analysis, I would like to see the linear model at each
> node in the tree.  In particular, I would like to see each node specific
> model coefficients
> associated with each of the independent variables and intercepts.
> 
> I've tried using the summary() method, but don't see this kind of
> information.
> How can I see this information?
> 
> Thanks, Charlie
> 
> -------------------------
> Charles H. Rosa, Ph.D.
> Staff Research Engineer, Research & Development
> GM R&D
> Warren, MI
> Tel/work: +1 586 986-6032
> Tel/cell: +1 781 367-5154
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rgentlem at jimmy.harvard.edu  Fri Feb 28 18:22:02 2003
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Fri Feb 28 18:22:02 2003
Subject: [R] Lexical scoping question
In-Reply-To: <99A12772DCDEEB458B996332957B0D53011776@mercury.cantatapharm.com>; from jrogers@cantatapharm.com on Fri, Feb 28, 2003 at 11:40:11AM -0500
References: <99A12772DCDEEB458B996332957B0D53011776@mercury.cantatapharm.com>
Message-ID: <20030228121954.O14492@jimmy.harvard.edu>

Hi,
  it is sort of a bug (and sort of not a bug). You are getting bitten
  by lazy evaluation. The value of y is not getting evaluated until
  the second function is created and returned.

f <- function(y) {
  y
  g <- function(x) x + y
  g
}

 will give the behavior you want and I think there is a proposal to
 have a function force, force evaluation so that we have
f <- function(y) {
  force(y)
  g <- function(x) x + y
  g
}

 and no one is tempted to optimize it away....

 Best,
   Robert


On Fri, Feb 28, 2003 at 11:40:11AM -0500, Jim Rogers wrote:
> Hello, 
> 
> Could someone please tell me what I am thinking about incorrectly:
> 
> f <- function(y) { 
>   g <- function(x) x + y
>   g
> }
> 
> In the following, I get what I expect based on my understanding of
> lexical scoping:
> 
> (f(1))(3) # 4
> (f(2))(3) # 5
> 
> But now,
> 
> fs <- lapply(c(1, 2), f)
> fs[[1]](3) # 5  (Why not 4 ?)
> fs[[2]](3) # 5
> 
> 
> Checking the environments of these functions, I see that "y" is indeed
> bound to the value 2 in both cases:
> 
> es <- lapply(fs, environment)
> ys <- lapply(es, function(env) get("y", env)) # list(2, 2)
> 
> ?
> 
> Thanks for help,
> Jim Rogers
> 
> James A. Rogers, Ph.D. <rogers at cantatapharm.com>
> Statistical Scientist
> Cantata Pharmaceuticals
> 3-G Gill St
> Woburn, MA  01801
> 617.225.9009
> Fax 617.225.9010
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20                            |
| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
+---------------------------------------------------------------------------+



From tlumley at u.washington.edu  Fri Feb 28 18:28:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri Feb 28 18:28:03 2003
Subject: [R] Lexical scoping question
In-Reply-To: <99A12772DCDEEB458B996332957B0D53011776@mercury.cantatapharm.com>
Message-ID: <Pine.A41.4.44.0302280920530.291640-100000@homer01.u.washington.edu>

On Fri, 28 Feb 2003, Jim Rogers wrote:

> Hello,
>
> Could someone please tell me what I am thinking about incorrectly:
>
> f <- function(y) {
>   g <- function(x) x + y
>   g
> }
>
> In the following, I get what I expect based on my understanding of
> lexical scoping:
>
> (f(1))(3) # 4
> (f(2))(3) # 5
>
> But now,
>
> fs <- lapply(c(1, 2), f)
> fs[[1]](3) # 5  (Why not 4 ?)
> fs[[2]](3) # 5
>
>
> Checking the environments of these functions, I see that "y" is indeed
> bound to the value 2 in both cases:
>
> es <- lapply(fs, environment)
> ys <- lapply(es, function(env) get("y", env)) # list(2, 2)
>

Because that's the way it works.  It's a wart caused by the
interaction of lazy evaluation and lexical scoping.  The problem is that
`y' is not evaluated until you actually call an element of fs.

You can do


  force<-function(z) z

 f <- function(y) {
   force(y)
   g <- function(x) x + y
   g
 }

which will work as you expect.  IIRC Luke Tierney has added force() to
the forthcoming R1.7.0.

You could also do
 f <- function(y) {
   y
   g <- function(x) x + y
   g
 }

but that makes less visual sense.


	-thomas



From gavin.simpson at ucl.ac.uk  Fri Feb 28 18:47:04 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri Feb 28 18:47:04 2003
Subject: [R] summary.glm() print problem(?) with cor = TRUE
In-Reply-To: <15967.30133.943227.222065@gargle.gargle.HOWL>
Message-ID: <003401c2df51$d13c4c10$4c202880@gsimpson>

Dear Martin,

Thanks for explaining this.

One thing that might be considered IMHO could be to replace the named column
heads (or both column and row head if so desired) with a number
corresponding to the position of the term in the printed table.

        1 2 3 4
pH      * 1      
I(pH^2) * B 1    
Ca        . . 1
I(Ca^2)   . . B

or even

        1 2 3 4
1       * 1      
2       * B 1    
3         . . 1
4         . . B

That keeps the property of square formatting of the table, well almost.
Then a line under the correlation table explaining the 1, 2, 3, etc. as well
and the legend for the symbolic characters.

Also printing the legend attribute as it is presented for the regression
terms (i.e. without attr(,"legend") and [1]) would also improve the look of
the thing.

All the best,

Gavin

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Dr. Gavin Simpson                 [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

-----Original Message-----
From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
Sent: 28 February 2003 14:44
To: gavin.simpson
Cc: 'r-help'
Subject: Re: [R] summary.glm() print problem(?) with cor = TRUE


>>>>> "GS" == Gavin Simpson <gavin.simpson at ucl.ac.uk>
>>>>>     on Fri, 28 Feb 2003 13:07:55 -0000 writes:

    GS> Hi,
    GS> I've had a look the bug list and searched though the R
documentation, email
    GS> lists etc. but didn't see anything on this:

    GS> when I do:

    GS> summary(species.glm1, correlation = TRUE)

    GS> I get a correlation matrix like this:

    GS> Correlation of Coefficients:

    GS>         ( p I(H C
    GS> pH      * 1      
    GS> I(pH^2) * B 1    
    GS> Ca        . .   1
    GS> I(Ca^2)   . .   B

    GS> attr(,"legend")
    GS> [1] 0 ` ' 0.3 `.' 0.6 `,' 0.8 `+' 0.9 `*' 0.95 `B' 1

    GS> I'm not worried about the symbolic representation, but
    GS> should the columns be labelled this way?  I can work out
    GS> which is which, but it isn't immediately clear and
    GS> doesn't look "nice".  Is this printing intended?

[we are talking about the print method for class "summary.lm",
 i.e. print.summary.glm() , and *.*.lm() ]

Yes, these column labels have been critized before and rightly so.
Currently, for R-devel, the default has even been changed from
 `symbolic.cor = p > 4' to  `symbolic.cor = FALSE' -- mostly
because of this, AFAIR -- and against my own opinion. 
I would have voted to change it to `symbolic.cor = p > 6' or so
(*and* to improve the column labels, too, see below).

As the original implementor I can tell you:
I've liked the idea of graphical correlation matrices which
motivated the "symbolic.cor" option to print.summary.* and the
underlying symnum() function.  
Since this is ASCII graphic, and showing (the lower triangle of)
a square matrix, I've felt the matrix should remain close to
``square'', also in its graphical form. 
Hence, the row labels were kept and the column labels
abbreviated "as much as possible" using R's internal abbreviate().
And this has given the very ugly "(" for "(Intercept)".
One easy possibility was to use more customized version of abbreviate()
either inside symnum() or by postprocessing ..

Given the topic, I'm really interested about your opinions on
the symbolic printing of correlation matrices.


    GS> Because when I do:

    GS> print(summary(species.glm3, correlation = TRUE), symbolic.cor =
FALSE)

    GS> I get a much more nicely formatted correlation matrix:

    GS> Correlation of Coefficients:
    GS>         (Intercept)      pH I(pH^2)      Ca
    GS> pH          -0.9321                        
    GS> I(pH^2)      0.9233 -0.9968                
    GS> Ca           0.1442 -0.4893  0.4950        
    GS> I(Ca^2)     -0.1619  0.5009 -0.5162 -0.9876

It nicer only as long as it stays small, IMHO.
no longer for a 10 x 10 case; look at the examples in
help(symnum) !

Note that you can always say
 sglm <- summary(species.glm3, correlation = TRUE)
 sglm$corr
to see the matrix in its usual form

Martin Maechler <maechler at stat.math.ethz.ch>
http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From tamntm2 at yahoo.com  Fri Feb 28 18:55:07 2003
From: tamntm2 at yahoo.com (a a)
Date: Fri Feb 28 18:55:07 2003
Subject: [R] R Graphics Crash Problem
Message-ID: <20030228175305.46173.qmail@web21302.mail.yahoo.com>

I recently built R 1.6.2 on solaris 2.8 with gcc 3.2. 
Things seem to run OK, but using graphics causes R to
core dump.  (For instance, by using the plot() or
hist() functions.)  Sometimes I can see the graphics
drawn before it actually core dumps.  The core file
shows a crash in Rf_gpptr.  

I'm quite new to R, so I don't know what info would be
helpful for diagnosis.  I'm including the gdb dump of
the crash.

Thanks for any help!

B Jones



-------------------------------------------
GNU gdb 5.3
Copyright 2002 Free Software Foundation, Inc.
GDB is free software, covered by the GNU General
Public License, and you are
welcome to change it and/or distribute copies of it
under certain conditions.
Type "show copying" to see the conditions.
There is absolutely no warranty for GDB.  Type "show
warranty" for details.
This GDB was configured as "sparc-sun-solaris2.8"...
Core was generated by
`/export/deriv/tools/lib/R/bin/R.bin'.
Program terminated with signal 10, Bus error.
Reading symbols from
/export/deriv/tools/lib/libreadline.so.4...done.
Loaded symbols for
/export/deriv/tools/lib/libreadline.so.4
Reading symbols from /usr/lib/libdl.so.1...done.
Loaded symbols for /usr/lib/libdl.so.1
Reading symbols from /usr/lib/libcurses.so.1...done.
Loaded symbols for /usr/lib/libcurses.so.1
Reading symbols from /usr/lib/libm.so.1...done.
Loaded symbols for /usr/lib/libm.so.1
Reading symbols from
/export/deriv/tools/lib/libpcre.so.0...done.
Loaded symbols for
/export/deriv/tools/lib/libpcre.so.0
Reading symbols from
/export/deriv/tools/lib/libz.so...done.
Loaded symbols for /export/deriv/tools/lib/libz.so
Reading symbols from /usr/lib/libnsl.so.1...done.
Loaded symbols for /usr/lib/libnsl.so.1
Reading symbols from /usr/lib/libsocket.so.1...done.
Loaded symbols for /usr/lib/libsocket.so.1
Reading symbols from /usr/lib/libc.so.1...done.
Loaded symbols for /usr/lib/libc.so.1
Reading symbols from
/export/deriv/tools/lib/libgcc_s.so.1...done.
Loaded symbols for
/export/deriv/tools/lib/libgcc_s.so.1
Reading symbols from /usr/lib/libmp.so.2...done.
Loaded symbols for /usr/lib/libmp.so.2
Reading symbols from
/usr/platform/SUNW,Ultra-4/lib/libc_psr.so.1...done.
Loaded symbols for
/usr/platform/SUNW,Ultra-4/lib/libc_psr.so.1
Reading symbols from
/export/deriv/tools/lib/R/modules/R_X11.so...done.
Loaded symbols for
/export/deriv/tools/lib/R/modules/R_X11.so
Reading symbols from /usr/lib/libSM.so.6...done.
Loaded symbols for /usr/lib/libSM.so.6
Reading symbols from /usr/lib/libICE.so.6...done.
Loaded symbols for /usr/lib/libICE.so.6
Reading symbols from /usr/lib/libX11.so.4...done.
Loaded symbols for /usr/lib/libX11.so.4
Reading symbols from
/export/deriv/tools/lib/libjpeg.so.62...done.
Loaded symbols for
/export/deriv/tools/lib/libjpeg.so.62
Reading symbols from
/export/deriv/tools/lib/libpng.so.2...done.
Loaded symbols for /export/deriv/tools/lib/libpng.so.2
Reading symbols from /usr/lib/libXext.so.0...done.
Loaded symbols for /usr/lib/libXext.so.0
Reading symbols from
/usr/openwin/lib/libdga.so.1...done.
Loaded symbols for /usr/openwin/lib/libdga.so.1
Reading symbols from
/export/deriv/tools/lib/R/library/ctest/libs/ctest.so...
done.
Loaded symbols for
/export/deriv/tools/lib/R/library/ctest/libs/ctest.so
#0  Rf_gpptr (dd=0xd) at base.c:162
162         if (dd->newDevStruct)
(gdb) where
#0  Rf_gpptr (dd=0xd) at base.c:162
#1  0x00081bc8 in setClipRect (x1=0xffbec850,
y1=0xffbec848, x2=0xffbec840,
    y2=0xffbec838, coords=0, dd=0xd) at
graphics.c:2389
#2  0x00083e20 in clipRectCode (x0=1.393025351641106,
y0=0.44224368861108854,
    x1=1.4574378883093166, y1=5.294888903103388e-315,
coords=-2017264452,
    dd=0xd) at graphics.c:3354
#3  0x000849ac in clipText (x=1.393025351641106,
y=0.44224368861108854,
    str=0xa3d618 "2", rot=0, clipToDevice=1, hadj=0,
dd=0xa21758)
    at graphics.c:3606
#4  0x00084e14 in Rf_GText (x=1.4252316199752113,
y=0.44224368861108854,
    coords=1, str=0x0, xc=0.5, yc=0, rot=0,
dd=0xa21758) at graphics.c:3761
#5  0x000874a4 in Rf_GMtext (str=0x9ffcf0 "2", side=1,
    line=1.8999999999999997, outer=0, at=2, las=0,
dd=0xa21758)
    at graphics.c:4390
#6  0x000b01e8 in do_axis (call=0x2dd1c0, op=0x1d8eac,
args=0x1bab20, env=0x0)
    at plot.c:1129
#7  0x00099e50 in do_internal (call=0x1807b4,
op=0x94da80, args=0x850598,
    env=0x85011c) at names.c:1044
#8  0x00072444 in Rf_eval (e=0x2dd134, rho=0x85011c)
at eval.c:404
#9  0x0007350c in do_begin (call=0x2dcc34,
op=0x1cb37c, args=0x2dd118,
    rho=0x85011c) at eval.c:891
#10 0x00072444 in Rf_eval (e=0x2dcc34, rho=0x85011c)
at eval.c:404
#11 0x0007279c in Rf_applyClosure (call=0x7d45bc,
op=0x2ddfd4,
    arglist=0x850d1c, rho=0x86e670,
suppliedenv=0x1bab20) at eval.c:587
#12 0x00072274 in Rf_eval (e=0x7d45bc, rho=0x86e670)
at eval.c:439
#13 0x0007350c in do_begin (call=0x7d45a0,
op=0x1cb37c, args=0x7d4584,
    rho=0x86e670) at eval.c:891
#14 0x00072444 in Rf_eval (e=0x7d45a0, rho=0x86e670)
at eval.c:404
#15 0x00072444 in Rf_eval (e=0x7d4434, rho=0x86e670)
at eval.c:404
#16 0x0007350c in do_begin (call=0x7d2e18,
op=0x1cb37c, args=0x7d4418,
    rho=0x86e670) at eval.c:891
#17 0x00072444 in Rf_eval (e=0x7d2e18, rho=0x86e670)
at eval.c:404
#18 0x0007279c in Rf_applyClosure (call=0x86fc40,
op=0x7d3f48,
    arglist=0x87015c, rho=0x8702ac,
suppliedenv=0x86fbd0) at eval.c:587
#19 0x0009a1a4 in applyMethod (call=0x86fc40,
op=0x7d3f48, args=0x87015c,
    rho=0x8702ac, newrho=0x86fbd0) at objects.c:121
#20 0x0009a6f0 in Rf_usemethod (generic=0xffbed928
"plot", obj=0x9f61a8,
    call=0xffbed6a8, args=0x1bab20, rho=0x8702ac,
callrho=0x1db408,
    defrho=0x1db3b4, ans=0xffbed924) at objects.c:340
#21 0x0009ac00 in do_usemethod (call=0x7d12f4,
op=0x1d93c8, args=0x7d1310,
    env=0x8702ac) at objects.c:409
#22 0x00072444 in Rf_eval (e=0x7d12f4, rho=0x8702ac)
at eval.c:404
#23 0x00072444 in Rf_eval (e=0x7d1284, rho=0x8702ac)
at eval.c:404
#24 0x0007350c in do_begin (call=0x7d1268,
op=0x1cb37c, args=0x7d124c,
    rho=0x8702ac) at eval.c:891
#25 0x00072444 in Rf_eval (e=0x7d1268, rho=0x8702ac)
at eval.c:404
#26 0x0007279c in Rf_applyClosure (call=0x86ff64,
op=0x7d116c,
    arglist=0x87015c, rho=0x1db408,
suppliedenv=0x1bab20) at eval.c:587
#27 0x00072274 in Rf_eval (e=0x86ff64, rho=0x1db408)
at eval.c:439
#28 0x0008c86c in Rf_ReplIteration (rho=0x1db408,
savestack=0, browselevel=0,
    state=0xffbedfb8) at main.c:232
#29 0x0008ca10 in R_ReplConsole (rho=0x1db408,
savestack=0, browselevel=0)
    at main.c:280
#30 0x0008d1cc in run_Rmainloop () at main.c:579
#31 0x000f66c0 in main (ac=0, av=0xffbee524) at
system.c:99



From f0z6305 at labs.tamu.edu  Fri Feb 28 19:12:03 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Fri Feb 28 19:12:03 2003
Subject: [R] How to determine the #,means and variances of 1-D Gaussian Mixture Model
Message-ID: <001701c2df54$bb29f050$8bd75ba5@IE.TAMU.EDU>

Hey, R-listers

I am going to approximate arbitrary 1-D data density by
mixture of Gaussian models.
The problem is that given a set of data generated from an
unknown density function, and want to use a Gaussian mixture density model
to approximate it.
Now how to determine the number of components, the means and variances for
all the components?
And can I plot them with plot of original empirical data density?

Thanks for your advice.

Fred



From ripley at stats.ox.ac.uk  Fri Feb 28 19:18:02 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 28 19:18:02 2003
Subject: [R] R Graphics Crash Problem
In-Reply-To: <20030228175305.46173.qmail@web21302.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0302281809190.10289-100000@gannet.stats>

This is a known bug in gcc 3.2.1 and 3.2.2: are you using either of those?
It is described in the R-admin manual: please consult it for details.

The Sun Forte compilers work, and the actual 3.2 does work for me.

On Fri, 28 Feb 2003, a a wrote:

> I recently built R 1.6.2 on solaris 2.8 with gcc 3.2. 
> Things seem to run OK, but using graphics causes R to
> core dump.  (For instance, by using the plot() or
> hist() functions.)  Sometimes I can see the graphics
> drawn before it actually core dumps.  The core file
> shows a crash in Rf_gpptr.  

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Fri Feb 28 19:23:43 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Feb 28 19:23:43 2003
Subject: [R] Mean Squares
In-Reply-To: <3E5F8880.B4D953FC@cc.jyu.fi>
References: <Pine.GSO.4.44.0302280915020.16669-100000@sun3.oulu.fi>
	<7olm00pyuc.fsf@foo.nemo-project.org>
	<6rwujk5ze2.fsf@bates4.stat.wisc.edu> <3E5F8880.B4D953FC@cc.jyu.fi>
Message-ID: <6rheao5l1d.fsf@bates4.stat.wisc.edu>

"Pedro J. Aphalo" <pedro.aphalo at cc.jyu.fi> writes:

> Douglas Bates wrote:
> > 
> > bhx2 at mevik.net (Bj?rn-Helge Mevik) writes:
> > 
> > > Mona Riihimaki <mona at sun3.oulu.fi> writes:
> > >
> > > > I've done lme-analysis with R; [...] I'd need also the mean squares.
> > >
> > > AFAIK, lme doesn't calculate sum of squares (or mean squares).  It
> > > maximises the likelihood (or restricted likelihood) and uses tests
> > > based on likelihood ratios.
> > 
> > Yes - you are correct.
> > 
> although the function is called anova.lme, is it still correct to talk
> about "anova results" when referring to the results of these tests? and
> in the case of the Wald tests in the single lme object case?

Anova applied to lme objects generates different types of tests
according to whether it is used with one argument or more than one
argument.  (We took Oscar Wilde's admonition that "Consistency is the
last refuge of the unimaginative" to heart.)

With more than one argument, likelihood ratio statistics and their
p-values are returned.  These are appropriate for comparing models in
which the random-effects structure has changed.  Bear in mind that the
p-values can be conservative because the null hypothesis is usually on
the boundary of a constrained parameter space.

With a single argument, F-tests on terms in the fixed-effects part of
the model are returned.  These tests are conditional on the values of
the parameters determining the random-effects distribution.  This is
usually not a problem because these parameters are asymptotically
uncorrelated with the fixed-effects parameters.

I would refer to the results for more than one argument as
"conservative likelihood ratio tests" or just "likelihood ratio
tests".



From katrina.grech at ed.ac.uk  Fri Feb 28 19:54:03 2003
From: katrina.grech at ed.ac.uk (Katrina Grech)
Date: Fri Feb 28 19:54:03 2003
Subject: [R] Error bars for interaction plots
Message-ID: <083BBD0B-4B91-11D7-B8B6-000393D9A7C6@ed.ac.uk>

How do I add error bars to an interaction plot of means?

Thanks



From ben at zoo.ufl.edu  Fri Feb 28 20:07:02 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Fri Feb 28 20:07:02 2003
Subject: [R] Error bars for interaction plots
In-Reply-To: <083BBD0B-4B91-11D7-B8B6-000393D9A7C6@ed.ac.uk>
Message-ID: <Pine.LNX.4.44.0302281409290.3549-100000@bolker.zoo.ufl.edu>

  Put your own solution together with arrows(...,angle=90), or use plotCI
within gregmisc, or get plotCI from my website
(http://www.zoo.ufl.edu/bolker/R/windows -- you want the bbmisc bundle)

  Ben

On Fri, 28 Feb 2003, Katrina Grech wrote:

> 
> How do I add error bars to an interaction plot of means?
> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From rex.dwyer at syngenta.com  Fri Feb 28 20:12:04 2003
From: rex.dwyer at syngenta.com (rex.dwyer@syngenta.com)
Date: Fri Feb 28 20:12:04 2003
Subject: [R] gprof / prof of shared library
Message-ID: <BD22EF7C4DAAD4118B7400508BAF0E10018DA0ED@se-excur01-usre.nabri.usre>

I have inherited a legacy S-plus system with about 10,000 lines of S and
10,000 lines of
Fortran.  It's now running under R.  However, I would like to profile the
fortran code with gprof or prof for performance tuning.  I've successfully
linked the .so file into a simple C driver program and profiled, but I can't
seem to get profiling to work when using dyn.load() to use it from R.  Do I
have to use .C() to call some monitor initialization procedure explicitly?
The /var/tmp/foo.so.profile file is never created.

I'm using R 1.6.2 and I have the same problem under both SunOS 5.8 and under
Red Hat Linux 7.3 with 2.4.18-openmosix4smp kernel.

Has anyone had any success with this sort of profiling?

Rex Dwyer
Syngenta Biotechnology Inc.
Research Triangle Park, North Carolina



From myotis at cix.compulink.co.uk  Fri Feb 28 20:19:03 2003
From: myotis at cix.compulink.co.uk (Graham Smith)
Date: Fri Feb 28 20:19:03 2003
Subject: [R] Yahoo ecological monitoring group
Message-ID: <memo.284450@cix.compulink.co.uk>

Hello,

I hope this is an acceptable spam.I have just set up a Yahoo group 
called ecomon to discuss ecological monitoring. Currently the people 
who have shown an interest in the group are people interested in 
ecological monitoring associated with ecological impact assessment, 
but there is no reason why the group should be restricted in this 
way.

At present there are no messages, but hopefully this will change !

The links are

Group name: ecomon 
Group home page: http://groups.yahoo.com/group/ecomon 
Group email address: ecomon at yahoogroups.com 

Cheers,

Graham S



From ripley at stats.ox.ac.uk  Fri Feb 28 21:58:03 2003
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Feb 28 21:58:03 2003
Subject: [R] gprof / prof of shared library
In-Reply-To: <BD22EF7C4DAAD4118B7400508BAF0E10018DA0ED@se-excur01-usre.nabri.usre>
Message-ID: <Pine.LNX.4.44.0302282055210.16072-100000@gannet.stats>

Did you build R with profiling (not R profiling, which must be disabled)  
compiler/linker options, as mentioned in the R-admin manual?

I've certainly profiled dyn.load-ed code on Solaris in R, but not 
recently.

On Fri, 28 Feb 2003 rex.dwyer at syngenta.com wrote:

> I have inherited a legacy S-plus system with about 10,000 lines of S and
> 10,000 lines of
> Fortran.  It's now running under R.  However, I would like to profile the
> fortran code with gprof or prof for performance tuning.  I've successfully
> linked the .so file into a simple C driver program and profiled, but I can't
> seem to get profiling to work when using dyn.load() to use it from R.  Do I
> have to use .C() to call some monitor initialization procedure explicitly?
> The /var/tmp/foo.so.profile file is never created.
> 
> I'm using R 1.6.2 and I have the same problem under both SunOS 5.8 and under
> Red Hat Linux 7.3 with 2.4.18-openmosix4smp kernel.
> 
> Has anyone had any success with this sort of profiling?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Paul.Bliese at NA.AMEDD.ARMY.MIL  Fri Feb 28 22:10:03 2003
From: Paul.Bliese at NA.AMEDD.ARMY.MIL (Bliese, Paul D MAJ WRAIR-Wash DC)
Date: Fri Feb 28 22:10:03 2003
Subject: [R] lattice and fitted function error
Message-ID: <58CAB2332C0DD511BC7900A0C9EA316D013D1951@dasmtyjqf009.amedd.army.mil>

Platform:  WIN2000
Version of R:  1.6.2

I'm interested in plotting fitted values in a trellis xyplot.  I believe the
following should work; however, I only get the points (not the fitted
lines).

library(lattice)
trellis.device(bg="white")

 xyplot(MULTDV~TIME|SUBNUM,data=TEMP,
 panel=function(x,y){
 panel.xyplot(x,y)
 lines(x,fitted(lm(y~poly(x,1),na.action=na.omit)))
 lines(x,fitted(lm(y~poly(x,2),na.action=na.omit)),lty=3)},
 xlab="Time",
 ylab="Average Reaction Time")

Happy to send the very small TEMP file for the curious...

Any suggestions?

Paul

MAJ Paul Bliese, Ph.D.
Walter Reed Army Institute of Research
Phone: (301) 319-9873
Fax: (301) 319-9484
paul.bliese at na.amedd.army.mil



From dpowers at mail.la.utexas.edu  Fri Feb 28 22:19:02 2003
From: dpowers at mail.la.utexas.edu (Daniel A. Powers)
Date: Fri Feb 28 22:19:02 2003
Subject: [R] Splitting survivor episodes
Message-ID: <Pine.GSO.4.33.0302281457100.24482-100000@honoria.la.utexas.edu>

To R-list --

Does anyone know of an R function that will create split-episode data from
single spell event/duration data according to user-defined time intervals?

Example: original data
 t     d  x
------------
 6     0  x1
 5     1  x2

Split using intervals [0,3) [3,infty) (or cutpoint at 3)

 start end    event
 _t0    _t     _d   _x  episode
   0     3      0   x1   1
   3     6      0   x1   2
   0     3      0   x2   1
   3     5      1   x2   2

Thanks,
Dan
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Daniel A. Powers, Ph.D.
Associate Professor of Sociology
University of Texas at Austin
370 Burdine
Austin, TX  78712
phone: 512-232-6335
fax:   512-471-1748
dpowers at mail.la.utexas.edu



From upton at mitre.org  Fri Feb 28 22:39:02 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Fri Feb 28 22:39:02 2003
Subject: [R] lattice and fitted function error
References: <58CAB2332C0DD511BC7900A0C9EA316D013D1951@dasmtyjqf009.amedd.army.mil>
Message-ID: <3E5FD604.235FF484@mitre.org>

Paul,

I don't think you can use lines with trellis graphics. Check out ?panel.lmline
(and other associated panel. functions).

HTH
steve

"Bliese, Paul D MAJ WRAIR-Wash DC" wrote:

> Platform:  WIN2000
> Version of R:  1.6.2
>
> I'm interested in plotting fitted values in a trellis xyplot.  I believe the
> following should work; however, I only get the points (not the fitted
> lines).
>
> library(lattice)
> trellis.device(bg="white")
>
>  xyplot(MULTDV~TIME|SUBNUM,data=TEMP,
>  panel=function(x,y){
>  panel.xyplot(x,y)
>  lines(x,fitted(lm(y~poly(x,1),na.action=na.omit)))
>  lines(x,fitted(lm(y~poly(x,2),na.action=na.omit)),lty=3)},
>  xlab="Time",
>  ylab="Average Reaction Time")
>
> Happy to send the very small TEMP file for the curious...
>
> Any suggestions?
>
> Paul
>
> MAJ Paul Bliese, Ph.D.
> Walter Reed Army Institute of Research
> Phone: (301) 319-9873
> Fax: (301) 319-9484
> paul.bliese at na.amedd.army.mil
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tamntm2 at yahoo.com  Fri Feb 28 23:18:03 2003
From: tamntm2 at yahoo.com (a a)
Date: Fri Feb 28 23:18:03 2003
Subject: [R] R Graphics Crash Problem
In-Reply-To: <Pine.LNX.4.44.0302281809190.10289-100000@gannet.stats>
Message-ID: <20030228221701.34078.qmail@web21301.mail.yahoo.com>

Thanks for the help.  I had in fact used gcc 3.2.1 to
build.  Rebuilding using the SunPro compiler seems to
have fixed the problem.

B Jones


--- ripley at stats.ox.ac.uk wrote:
> This is a known bug in gcc 3.2.1 and 3.2.2: are you
> using either of those?
> It is described in the R-admin manual: please
> consult it for details.
> 
> The Sun Forte compilers work, and the actual 3.2
> does work for me.
> 
> On Fri, 28 Feb 2003, a a wrote:
> 
> > I recently built R 1.6.2 on solaris 2.8 with gcc
> 3.2. 
> > Things seem to run OK, but using graphics causes R
> to
> > core dump.  (For instance, by using the plot() or
> > hist() functions.)  Sometimes I can see the
> graphics
> > drawn before it actually core dumps.  The core
> file
> > shows a crash in Rf_gpptr.  
> 
> [...]



From deepayan at cs.wisc.edu  Fri Feb 28 23:34:02 2003
From: deepayan at cs.wisc.edu (Deepayan Sarkar)
Date: Fri Feb 28 23:34:02 2003
Subject: [R] lattice and fitted function error
In-Reply-To: <58CAB2332C0DD511BC7900A0C9EA316D013D1951@dasmtyjqf009.amedd.army.mil>
References: <58CAB2332C0DD511BC7900A0C9EA316D013D1951@dasmtyjqf009.amedd.army.mil>
Message-ID: <1046471596.3e5fe3ac5630b@www-auth.cs.wisc.edu>

You need to use llines instead of lines (lines doesn't produce any output with 
grid graphics).

Quoting "Bliese, Paul D MAJ WRAIR-Wash DC" <Paul.Bliese at NA.AMEDD.ARMY.MIL>:

> Platform:  WIN2000
> Version of R:  1.6.2
> 
> I'm interested in plotting fitted values in a trellis xyplot.  I believe
> the
> following should work; however, I only get the points (not the fitted
> lines).
> 
> library(lattice)
> trellis.device(bg="white")
> 
>  xyplot(MULTDV~TIME|SUBNUM,data=TEMP,
>  panel=function(x,y){
>  panel.xyplot(x,y)
>  lines(x,fitted(lm(y~poly(x,1),na.action=na.omit)))
>  lines(x,fitted(lm(y~poly(x,2),na.action=na.omit)),lty=3)},
>  xlab="Time",
>  ylab="Average Reaction Time")
> 
> Happy to send the very small TEMP file for the curious...
> 
> Any suggestions?
> 
> Paul
> 
> MAJ Paul Bliese, Ph.D.
> Walter Reed Army Institute of Research
> Phone: (301) 319-9873
> Fax: (301) 319-9484
> paul.bliese at na.amedd.army.mil
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From nuootinl at usc.edu  Fri Feb 28 23:40:11 2003
From: nuootinl at usc.edu (Jassy Molitor)
Date: Fri Feb 28 23:40:11 2003
Subject: [R] How do I find the first derivative from the cubic natural  spline
Message-ID: <4.3.2.7.0.20030228143235.00b391b8@email.usc.edu>

Hi, Everyboday,
   Does anybody know how to get the first derivative form the cubic natural 
spline matrix?


Thanks !!!


Jassy

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Nuoo-Ting (Jassy) Molitor, MS, Junior Statistician
Division of Biostatistics
Department of Preventive Medicine
University of Southern California          Tel: (323) 442-2584
1540 Alcazar St., CHP-210F               Fax: (323) 442-3272
Los Angeles, CA 90089-9011, USA     e-mail: nuootinl at usc.edu
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From reid_huntsinger at merck.com  Fri Feb 28 23:47:33 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri Feb 28 23:47:33 2003
Subject: [despammed] RE: [R] multidimensional function fitting
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC369@uswpmx11.merck.com>

You can use R objects, such as the return from gam, and the
predict.gam function, from C. See the R extensions manual.

Reid Huntsinger

-----Original Message-----
From: RenE J.V. Bertin [mailto:rjvbertin at despammed.com] 
Sent: Thursday, February 27, 2003 3:42 PM
To: Wiener, Matthew
Cc: r-help at stat.math.ethz.ch
Subject: Re: [despammed] RE: [R] multidimensional function fitting


On Thu, 27 Feb 2003 13:52:50 -0500, "Wiener, Matthew"
<matthew_wiener at merck.com> wrote regarding
"[despammed] RE: [R] multidimensional function fitting"

8-) Take a look at package mgcv.  Hope this helps.  --Matt
8-) 

Thank you, I just did. It may indeed be what I'm looking for (I haven't
quite understood everything about it...), but:

1) The best fits I obtain with a formula like z~s(x,y) ; but this I cannot
possibly transport into the C programme where I need it! Maybe I wasn't
clear on this aspect?

2) It is very memory hungry, esp. when using the s() function: I have 192Mb
with 256Mb swap (not a lot, but reasonable I'd say), and I've never had to
kill R as often as when trying gam()...

R.B.

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------



From luke at stat.uiowa.edu  Fri Feb 28 23:56:02 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri Feb 28 23:56:02 2003
Subject: [R] Lexical scoping question
In-Reply-To: <Pine.A41.4.44.0302280920530.291640-100000@homer01.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0302281648110.11161-100000@itasca.stat.uiowa.edu>

On Fri, 28 Feb 2003, Thomas Lumley wrote:

> On Fri, 28 Feb 2003, Jim Rogers wrote:
> 
> > Hello,
> >
> > Could someone please tell me what I am thinking about incorrectly:
> >
> > f <- function(y) {
> >   g <- function(x) x + y
> >   g
> > }
> >
> > In the following, I get what I expect based on my understanding of
> > lexical scoping:
> >
> > (f(1))(3) # 4
> > (f(2))(3) # 5
> >
> > But now,
> >
> > fs <- lapply(c(1, 2), f)
> > fs[[1]](3) # 5  (Why not 4 ?)
> > fs[[2]](3) # 5
> >
> >
> > Checking the environments of these functions, I see that "y" is indeed
> > bound to the value 2 in both cases:
> >
> > es <- lapply(fs, environment)
> > ys <- lapply(es, function(env) get("y", env)) # list(2, 2)
> >
> 
> Because that's the way it works.  It's a wart caused by the
> interaction of lazy evaluation and lexical scoping.  The problem is that
> `y' is not evaluated until you actually call an element of fs.

I'd call it a three-way interaction of lazy evaluation. lexical
scoping and changing variable bindings by explicit assignment by the
implicit assignment done in a loop.  The internal lapply actually does
something a bit different but with the same effect.  If the value of a
variable in a deferred evaluation is going to change and you want the
result of the evaluation befoe the change, then you have to force the
evaluation to occur before the change.

> You can do
> 
> 
>   force<-function(z) z
> 
>  f <- function(y) {
>    force(y)
>    g <- function(x) x + y
>    g
>  }
> 
> which will work as you expect.  IIRC Luke Tierney has added force() to
> the forthcoming R1.7.0.

It has been added now.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



