From phddas at yahoo.com  Sat May  1 00:58:44 2004
From: phddas at yahoo.com (Fred J.)
Date: Fri, 30 Apr 2004 15:58:44 -0700 (PDT)
Subject: [R] grid location on plot
Message-ID: <20040430225844.17228.qmail@web20507.mail.yahoo.com>

Hello
I have
x <- c(0.5, 0.7, 3.5, 1.5, 2.5, 2.8)
y <- c(0.5, 0.8, 1.5, 3.5, 1.5, 1.5)
plot.default(x,y,type="p",panel.first=grid(5,5))
I need to plot that on a grid of 0,1,2,3,4,5 showing
the grid lines on the these numbers. how can I do
this?
e.g
how can I contorl the x and y min,max values on the
plot and the location of the grid lines?


thanks



From patrick.giraudoux at univ-fcomte.fr  Sat May  1 05:22:11 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 1 May 2004 05:22:11 +0200
Subject: [R] glm.nb and anova
Message-ID: <000e01c42f2b$80814070$7b653351@PC728329681112>

Hi,

I am trying to fit a negative binomial model with a number of parasite tapeworms as response variable to geographical coordinates
(actually preparing a trend surface before kriging). When I try an anova, I get warnings:

> glm4.nb<-glm.nb(wb~X4+Y4+I(X4^2)+I(Y4^2))
> anova(glm4.nb)
Analysis of Deviance Table

Model: Negative Binomial(0.0463), link: log

Response: wb

Terms added sequentially (first to last)


         Df Deviance Resid. Df Resid. Dev P(>|Chi|)
NULL                       344      225.7
X4        1      0.0       343     9578.7       1.0
Y4        1   1695.7       342     7883.1       0.0
I(X4^2)   1   1992.2       341     5890.9       0.0
I(Y4^2)   1   5687.4       340      203.5       0.0
Warning messages:
1: tests made without re-estimating theta in: anova.negbin(glm4.nb)
2: Algorithm did not converge in: method(x = x[, varseq <= i, drop = FALSE], y = object$y, weights = object$prior.weights,
3: Algorithm did not converge in: method(x = x[, varseq <= i, drop = FALSE], y = object$y, weights = object$prior.weights,
4: Algorithm did not converge in: method(x = x[, varseq <= i, drop = FALSE], y = object$y, weights = object$prior.weights,
>

 Results look like non sense with an intercept deviance smaller than the next variables... One can see that X4  has a null deviance.
If X4 is removed from the model, Y4 get a null deviance in the model updated (due to an intercept deviance smaller), and so on...
Actually smaller intercept deviance and null deviance for the first variable is obtained for every first independant variable,
except when only one is left in the model.

Can somebody tell me what happens?

Thanks in advance,

Patrick Giraudoux



From ramasamy at cancer.org.uk  Sat May  1 09:33:39 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: 01 May 2004 08:33:39 +0100
Subject: [R] grid location on plot
In-Reply-To: <20040430225844.17228.qmail@web20507.mail.yahoo.com>
References: <20040430225844.17228.qmail@web20507.mail.yahoo.com>
Message-ID: <1083396818.3857.10.camel@localhost.localdomain>

plot(x, y, xlim=c(0,4), ylim=c(0,4))
grid() # OR ...
abline( h=0:4, v=0:4, col="lightgray", lty=3 )

help(par) gives you more options to use in plot.
grid() usually gives quite pretty results by default.


On Fri, 2004-04-30 at 23:58, Fred J. wrote:
> Hello
> I have
> x <- c(0.5, 0.7, 3.5, 1.5, 2.5, 2.8)
> y <- c(0.5, 0.8, 1.5, 3.5, 1.5, 1.5)
> plot.default(x,y,type="p",panel.first=grid(5,5))
> I need to plot that on a grid of 0,1,2,3,4,5 showing
> the grid lines on the these numbers. how can I do
> this?
> e.g
> how can I contorl the x and y min,max values on the
> plot and the location of the grid lines?
> 
> 
> thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From abuse at internet-support.co.nz  Sat May  1 09:50:58 2004
From: abuse at internet-support.co.nz (abuse@internet-support.co.nz)
Date: Sat, 1 May 2004 19:50:58 +1200
Subject: [R] NOTICE: a file you sent was removed
Message-ID: <E1BJpH1-0000nS-02@mailsrv2.tranzpeer.net>

This is an automated delivery status notification from mailsrv2
running server version 3.4.3.

Our Email Virus filter has detected a virus contained in an email sent
from your address.  We have removed the virus from the email before
forwarding to the recipient.

The original message was received on Sat, 01 May 2004 19:50:43 +1200

---------------------------------------------------------------------------

                           ATTACHMENT REMOVED

	   From: r-help at lists.r-project.org
	     To: barclayj at slingshot.co.nz
	Subject: Oh my God

The message attachment was removed for the following reason:
	Virus and Spam Protection Mode::Strip Viruses:W32/Sober-F;

The following attachments were removed: 
	        Size: 58.2k
	      Reason: Virus and Spam Protection Mode:Strip Viruses:virus-W32/Sober-F;

---------------------------------------------------------------------------

From ligges at statistik.uni-dortmund.de  Sat May  1 10:49:38 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 01 May 2004 10:49:38 +0200
Subject: [R] ./configure --prefix and R_LIBS
References: <200404302101320233.0262302B@mail.math.fu-berlin.de>
Message-ID: <409364A2.3F5987D6@statistik.uni-dortmund.de>



Wolski wrote:
> 
> Hi!
> I am installing R in non standard directory.
> ./configure --prefix=/non/standard/directory
> 
> The installation works fine.
> But after starting R i get
> .libPaths()
> /usr/lib/R/library

Are you sure you have started the R version in /non/standard/directory
rather than another one that is installed in a standard location?

Uwe Ligges


> but they cant be there of course!
> 
> Have I to set some additional switches during config?
> Eryk
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic
> Ihnestrasse 63-73 14195 Berlin       'v'
> tel: 0049-30-84131469               /   \
> mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat May  1 10:54:01 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 01 May 2004 10:54:01 +0200
Subject: [R] Problems in plot
References: <78B50CF247E5D04B8A5E02D001CC8E9A595C54@XMAIL.sooner.net.ou.edu>
Message-ID: <409365A9.5F2A8FE2@statistik.uni-dortmund.de>



"Yao, Minghua" wrote:
> 
> The problem is still there if windows() is used.

OK, so we need a reproducible example. Please specify some code that
results (at least sometimes) in the mentioned error message.

I tried

for(i in 1:20){
 windows()
 par(cex = 0.75)
 plot(1:10)
}

and all plots came out well...

Uwe Ligges



> Minghua
> 
> ________________________________
> 
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Thu 4/29/2004 9:31 AM
> To: Yao, Minghua
> Cc: R Help
> Subject: Re: [R] Problems in plot
> 
> The primary graphics device under Windows is called *windows* not *x11*.
> 
> Something in your Windows setup is sometimes failing to choose a
> reasonable window size.  I have never seen that, and suspect it is nothing
> to do with it, but please use windows() and see if the problem vanishes.
> 
> On Thu, 29 Apr 2004, Yao, Minghua wrote:
> 
> > Hello,
> >
> >
> >
> > I have R1.9.0 under Windows XP. My program plots several plots using
> >
> > x11()
> > par(cex = 0.75)
> > ......
> > x11()
> > par(cex = 0.75)
> > ......
> > x11()
> > par(cex = 0.75)
> > ......
> > x11()
> > par(cex = 0.75)
> > ......
> >
> > Sometimes, one of them generates  a small frame only with title area "R graphics: Device X (ACTIVE)". The message in the console window is
> >
> > Error in plot.new() : Figure margins too large
> >
> > This program ran well under R1.6.X under Windows NT.
> >
> > It seems to me that it is not a specific x11() that generates that small graphics frame.
> >
> > Thank you for you help in advance.
> >
> > Minghua
> >
> >
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From patrick.giraudoux at univ-fcomte.fr  Sat May  1 13:39:37 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 1 May 2004 13:39:37 +0200
Subject: [R] RWinEdt, R.profile and version 1.9.0
Message-ID: <000701c42f71$09ec7d80$f645fb51@PC728329681112>

Hi,

I have just upgraded from the 1.8.1 to  the 1.9.0 version of R, and have some trouble to run RWinEdt from the .Rprofile file (in the
user folder). The script is:

library(MASS)
library(lattice)
cat("Load editor?(y/n default = y): ")
nf <- as.character(readLines(n = 1))
if ((nf=="y")|(nf=="Y")|(nf=="")) {library(RWinEdt)}
rm(nf)

When run at start, this prompts:

Loading required package: stats
Load editor?(y/n default = y): y
Loading required package: SWinRegistry
Error in eval(expr, envir, enclos) : couldn't find function "winMenuAdd"

and the WinEdt is not started.

However, if I run

> library(RWinEdt)

from the gui.exe interface, everything goes well.

How can I manage with this "Error in eval(expr, envir, enclos) : couldn't find function "winMenuAdd" generated by a call to
library(RWinEdt) in the .Rprofile script?

Patrick Giraudoux



From patrick.giraudoux at univ-fcomte.fr  Sat May  1 14:44:51 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 1 May 2004 14:44:51 +0200
Subject: [R] Re: RWinEdt, R.profile and version 1.9.0
Message-ID: <001601c42f7a$1ca90110$e52ff951@PC728329681112>

Apologises to reply to myself...

I found where the trouble came from.

The function winMenuAdd() is included in the library utils, not loaded at this stage. Now, it works with

library(MASS)
library(lattice)
cat("Load editor?(y/n default = y): ")
nf <- as.character(readLines(n = 1))
if (any(nf=="y",nf=="Y",nf=="")) {library(utils);library(RWinEdt)}
rm(nf)

This loading was not necessary in the version 1.8.1.




----- Original Message ----- 
From: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
To: "r-help" <r-help at stat.math.ethz.ch>
Sent: Saturday, May 01, 2004 1:39 PM
Subject: RWinEdt, R.profile and version 1.9.0


> Hi,
>
> I have just upgraded from the 1.8.1 to  the 1.9.0 version of R, and have some trouble to run RWinEdt from the .Rprofile file (in
the
> user folder). The script is:
>
> library(MASS)
> library(lattice)
> cat("Load editor?(y/n default = y): ")
> nf <- as.character(readLines(n = 1))
> if ((nf=="y")|(nf=="Y")|(nf=="")) {library(RWinEdt)}
> rm(nf)
>
> When run at start, this prompts:
>
> Loading required package: stats
> Load editor?(y/n default = y): y
> Loading required package: SWinRegistry
> Error in eval(expr, envir, enclos) : couldn't find function "winMenuAdd"
>
> and the WinEdt is not started.
>
> However, if I run
>
> > library(RWinEdt)
>
> from the gui.exe interface, everything goes well.
>
> How can I manage with this "Error in eval(expr, envir, enclos) : couldn't find function "winMenuAdd" generated by a call to
> library(RWinEdt) in the .Rprofile script?
>
> Patrick Giraudoux
>



From ligges at statistik.uni-dortmund.de  Sat May  1 15:05:04 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 01 May 2004 15:05:04 +0200
Subject: [R] Re: RWinEdt, R.profile and version 1.9.0
In-Reply-To: <001601c42f7a$1ca90110$e52ff951@PC728329681112>
References: <001601c42f7a$1ca90110$e52ff951@PC728329681112>
Message-ID: <4093A080.4040908@statistik.uni-dortmund.de>

Patrick Giraudoux wrote:
> Apologises to reply to myself...
> 
> I found where the trouble came from.
> 
> The function winMenuAdd() is included in the library utils, not loaded at this stage. Now, it works with
> 
> library(MASS)
> library(lattice)
> cat("Load editor?(y/n default = y): ")
> nf <- as.character(readLines(n = 1))
> if (any(nf=="y",nf=="Y",nf=="")) {library(utils);library(RWinEdt)}
> rm(nf)
> 
> This loading was not necessary in the version 1.8.1.

I'll update RWinEdt so that it carefully loads "utils". Thanks for the 
report.

Uwe Ligges



> 
> 
> 
> ----- Original Message ----- 
> From: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
> To: "r-help" <r-help at stat.math.ethz.ch>
> Sent: Saturday, May 01, 2004 1:39 PM
> Subject: RWinEdt, R.profile and version 1.9.0
> 
> 
> 
>>Hi,
>>
>>I have just upgraded from the 1.8.1 to  the 1.9.0 version of R, and have some trouble to run RWinEdt from the .Rprofile file (in
> 
> the
> 
>>user folder). The script is:
>>
>>library(MASS)
>>library(lattice)
>>cat("Load editor?(y/n default = y): ")
>>nf <- as.character(readLines(n = 1))
>>if ((nf=="y")|(nf=="Y")|(nf=="")) {library(RWinEdt)}
>>rm(nf)
>>
>>When run at start, this prompts:
>>
>>Loading required package: stats
>>Load editor?(y/n default = y): y
>>Loading required package: SWinRegistry
>>Error in eval(expr, envir, enclos) : couldn't find function "winMenuAdd"
>>
>>and the WinEdt is not started.
>>
>>However, if I run
>>
>>
>>>library(RWinEdt)
>>
>>from the gui.exe interface, everything goes well.
>>
>>How can I manage with this "Error in eval(expr, envir, enclos) : couldn't find function "winMenuAdd" generated by a call to
>>library(RWinEdt) in the .Rprofile script?
>>
>>Patrick Giraudoux
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From patrick.giraudoux at univ-fcomte.fr  Sat May  1 15:30:59 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 1 May 2004 15:30:59 +0200
Subject: [R] log(0) error is not handled in xyplot, Windows
Message-ID: <006101c42f80$8c507920$e52ff951@PC728329681112>

Hi,

We had some exchanges off the list with Deepayan Sarkar about a bug (?) we cannot fix (it seems it does not occur under Unix).  It
likely needs the help of somebody on Windows.

The initial problem was that when running the following script (Windows XP, R 1.8.1 as well as R 1.9.0):

> lset(col.whitebg())
> xyplot(rdens ~ annee | habitat,
>        groups = sp, type = 'b',
>        scales = list(y = list(log = TRUE)))

I got a crash (just show the "hourglass" icon, stay on, GUI.exe no longer answer, and I must interrupt the process via
Windows...)

When the following is used:

> lset(col.whitebg())
> xyplot(rdens+1 ~ annee | habitat,
>        groups = sp, type = 'b',
>        scales = list(y = list(log = TRUE)))

It draws the plot OK.

The same (plot drawn OK) , when lset(col.whitebg()) is not used.

The conclusion was that in the  lset(col.whitebg()) environment, log(0) was not properly handled (leading to an error message or
something else).

I can provide a data.frame off the list to anybody who wants a reproducible example and to look at what happens.

Patrick Giraudoux



----- Original Message ----- 
From: "Deepayan Sarkar" <deepayan at stat.wisc.edu>
To: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
Sent: Saturday, May 01, 2004 2:56 PM
Subject: Re: Fw: log(0) error is not handled in xyplot


> On Saturday 01 May 2004 07:50, Patrick Giraudoux wrote:
> > > library(grid)
> > > x = 1:10 / 11
> > > y = rep(.5, 10)
> > > y[5] = NA
> > > grid.lines(x, y)
> >
> > Does not give a crash and makes this plot:
>
> In that case, you should probably report the original xyplot problem to
> r-help. Hopefully someone on Windows would be able to figure it out.
> Make sure to give a reproducible example.
>
> Deepayan


----- Original Message ----- 
From: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
To: "Deepayan Sarkar" <deepayan at stat.wisc.edu>
Sent: Thursday, April 29, 2004 4:15 PM
Subject: Re: Fw: log(0) error is not handled in xyplot


> > Hmm, that's very odd. So what exactly were your symptoms ? Did R crash
> > or just hang ?
>
> R crashes actually (just show the "hourglass" icon, stay on, GUI.exe no longer answer, and I must interrupt the process via
> Windows...).
>
> > BTW, if you are not looking for code compatible with S-PLUS, you can
> > omit the panel.superpose call (which is the default anyway when groups
> > are present); e.g.
> >
> > xyplot(rdens ~ annee | habitat,
> >        groups = sp, type = 'b',
> >        scales = list(y = list(log = TRUE)))
>
> I have just tried and get the same result under lset(col.whitebg()): a crash...
>
> Don't worry too much about this. Things go well when I pass rdens+1 rather than rdens, so the bug (if any bug) can be turned...
>
> Best regards, and warm thanks for all the work you have done (and still do).
>
> Patrick
>
>
>
>
> ----- Original Message ----- 
> From: "Deepayan Sarkar" <deepayan at stat.wisc.edu>
> To: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
> Sent: Thursday, April 29, 2004 3:35 PM
> Subject: Re: Fw: log(0) error is not handled in xyplot
>
>
> > On Thursday 29 April 2004 02:43, Patrick Giraudoux wrote:
> > > > Could you give me a reproducible example ?
> > >
> > > My pleasure.  Actually I have refined the analysis after your e-mail.
> > > The trouble comes from the use of lset(col.whitebg()), scales,
> > > panel.superpose, in combination. This does not simplify the things...
> >
> > Hmm, that's very odd. So what exactly were your symptoms ? Did R crash
> > or just hang ?
> >
> > > Just load the attached file, a data.frame saved with
> > > save(tblcinetique,file="tblcinetique"), and run the following script:
> >
> > Well, I don't see a major problem with either on 1.9.0, and I don't have
> > a 1.8.1 handy right now (I'll try if I get the opportunity).
> >
> > There is a small problem with the first plot, which stems from a grid
> > bug. Effectively what happens is that although NA's are normally
> > removed before the data gets passed to the panel function, in this case
> > the log(0) = -Inf is not being removed. But I'll probably wait for this
> > to be fixed in grid.
> >
> > BTW, if you are not looking for code compatible with S-PLUS, you can
> > omit the panel.superpose call (which is the default anyway when groups
> > are present); e.g.
> >
> > xyplot(rdens ~ annee | habitat,
> >        groups = sp, type = 'b',
> >        scales = list(y = list(log = TRUE)))
> >
> > Deepayan
>



From pgraz at polytechnic.edu.na  Sat May  1 15:40:54 2004
From: pgraz at polytechnic.edu.na (F. Patrick Graz)
Date: Sat, 01 May 2004 14:40:54 +0100
Subject: [R] results from t-test
Message-ID: <4093A8E6.3080209@polytechnic.edu.na>

Greetings,
I'm rather new to R, and only just subscribed to the mailing list.

I have run into a strange result in a t-test. The data represents the 
the hypothetical differences obtained for a t-test for dependent samples.

All the numeric output looks OK, but the statement that the alternative 
hypothesis is accepted seems rather strange.

 > data <- c(-6,6,-4,11,6,-3,-12,7,-1,4)
 > length(data)
 > t.test (data,mu=0)

         One Sample t-test

data:  data
t = 0.3548, df = 9, p-value = 0.7309
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
  -4.300873  5.900873
sample estimates:
mean of x
       0.8

Can someone explain this? Beware though, I'm a forester and may not 
understand too technical explanations.

Patrick



From jasont at indigoindustrial.co.nz  Sat May  1 16:15:02 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sun, 02 May 2004 02:15:02 +1200
Subject: [R] results from t-test
In-Reply-To: <4093A8E6.3080209@polytechnic.edu.na>
References: <4093A8E6.3080209@polytechnic.edu.na>
Message-ID: <4093B0E6.8020205@indigoindustrial.co.nz>

F. Patrick Graz wrote:
> Greetings,
> I'm rather new to R, and only just subscribed to the mailing list.
> 
> I have run into a strange result in a t-test. The data represents the 
> the hypothetical differences obtained for a t-test for dependent samples.
> 
> All the numeric output looks OK, but the statement that the alternative 
> hypothesis is accepted seems rather strange.
> 

It doesn't say which hypothesis is accepted - the printed output just 
helps remind you what the alternative hypothesis is.  In this case, a 
p-value of 0.73 means you would be really, really safe sticking with the 
null hypothesis.

Cheers

Jason
(who is deliberately not dragging the professed non-statistician into 
the discussion we've had recently on the merits of p-values).  :)



From dmurdoch at pair.com  Sat May  1 16:36:15 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 01 May 2004 10:36:15 -0400
Subject: [R] results from t-test
In-Reply-To: <4093A8E6.3080209@polytechnic.edu.na>
References: <4093A8E6.3080209@polytechnic.edu.na>
Message-ID: <dcd790hk7nltd2smt8lsci6i2koffhh765@4ax.com>

On Sat, 01 May 2004 14:40:54 +0100, "F. Patrick Graz"
<pgraz at polytechnic.edu.na> wrote:

>All the numeric output looks OK, but the statement that the alternative 
>hypothesis is accepted seems rather strange.

I think you misread it.  It says

>alternative hypothesis: true mean is not equal to 0

which should be read as 

alternative hypothesis: "true mean is not equal to 0"

not

alternative hypothesis: true,  mean is not equal to 0

Duncan Murdoch



From p.dalgaard at biostat.ku.dk  Sat May  1 16:58:17 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 May 2004 16:58:17 +0200
Subject: [R] results from t-test
In-Reply-To: <4093B0E6.8020205@indigoindustrial.co.nz>
References: <4093A8E6.3080209@polytechnic.edu.na>
	<4093B0E6.8020205@indigoindustrial.co.nz>
Message-ID: <x2d65ojit2.fsf@biostat.ku.dk>

Jason Turner <jasont at indigoindustrial.co.nz> writes:

> F. Patrick Graz wrote:
> > Greetings,
> > I'm rather new to R, and only just subscribed to the mailing list.
> > I have run into a strange result in a t-test. The data represents
> > the the hypothetical differences obtained for a t-test for dependent
> > samples.
> > All the numeric output looks OK, but the statement that the
> > alternative hypothesis is accepted seems rather strange.
> >
> 
> It doesn't say which hypothesis is accepted - the printed output just
> helps remind you what the alternative hypothesis is.  In this case, a
> p-value of 0.73 means you would be really, really safe sticking with
> the null hypothesis.
> 
> Cheers
> 
> Jason
> (who is deliberately not dragging the professed non-statistician into
> the discussion we've had recently on the merits of p-values).  :)

Oops. Be careful, you very nearly dragged at least one professed
statistician into a sermon about the proper interpretation of
non-significant p-values (absence of evidence, etc.)....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From wcvinyard at earthlink.net  Sat May  1 19:07:34 2004
From: wcvinyard at earthlink.net (Bill Vinyard)
Date: Sat, 1 May 2004 13:07:34 -0400
Subject: [R] grid location on plot
In-Reply-To: <20040430225844.17228.qmail@web20507.mail.yahoo.com>
Message-ID: <MJENLJEPCHEMCAGNPDMGCECHCCAA.wcvinyard@earthlink.net>

Here's one way, maybe not the best...

x <- c(0.5, 0.7, 3.5, 1.5, 2.5, 2.8)
y <- c(0.5, 0.8, 1.5, 3.5, 1.5, 1.5)
plot(x,y,type="p",xlim=c(0,5),ylim=c(0,5))
abline(h=seq(0,5),lty=2)
abline(v=seq(0,5),lty=2)

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Fred J.
Sent: Friday, April 30, 2004 18:59
To: r help
Subject: [R] grid location on plot


Hello
I have
x <- c(0.5, 0.7, 3.5, 1.5, 2.5, 2.8)
y <- c(0.5, 0.8, 1.5, 3.5, 1.5, 1.5)
plot.default(x,y,type="p",panel.first=grid(5,5))
I need to plot that on a grid of 0,1,2,3,4,5 showing
the grid lines on the these numbers. how can I do
this?
e.g
how can I contorl the x and y min,max values on the
plot and the location of the grid lines?


thanks

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From elkurdy at qp.com.qa  Sat May  1 20:21:45 2004
From: elkurdy at qp.com.qa (elkurdy@qp.com.qa)
Date: Sat, 1 May 2004 21:21:45 +0300
Subject: [R] PCA filtering
Message-ID: <OF79EEEBCB.74C9168D-ON43256E87.00649B65@qp.com.qa>





Hi,

Is there a function under R that does principal component analysis and then
use the selected eignevectors to filter the data and transform back to the
original coordinates?
If there isn't, can someone guide as to how to do this approach.

Much appreciated.






Sami Saad El Kurdy
SENIOR GEOPHYSICIST, NFD/1
Reservoir & Fields Development Department
North Field Development
Staff Number: 20504


Tel: 974 449 1247


Email: elkurdy at qp.com.qa










--------------------------------------------------------------------------------------------------

Confidentiality Notice : This e-mail  and  any attachments  ...{{dropped}}



From rbaer at atsu.edu  Sat May  1 20:54:26 2004
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Sat, 1 May 2004 13:54:26 -0500
Subject: [R] results from t-test
References: <4093A8E6.3080209@polytechnic.edu.na>
	<dcd790hk7nltd2smt8lsci6i2koffhh765@4ax.com>
Message-ID: <011201c42fad$ba380e20$6401a8c0@meadow>

 >All the numeric output looks OK, but the statement that the alternative
> >hypothesis is accepted seems rather strange.
>
> I think you misread it.  It says alternative hypothesis: true mean is not
equal to 0
> which should be read as  alternative hypothesis: "true mean is not equal
to 0"
> not
> alternative hypothesis: true,  mean is not equal to 0
>
> Duncan Murdoch
>
Interestingly, I had a student fooled by a similar re-statement of the
alternative hypothesis in R output (although I don't think it was the
t-test) just last week.  At the time, I wondered
1)  Why the null AND the alternative weren't stated (guessed the answer was
parsimony)
2)  Why if only one was stated, the convention was to re-state the
alternative rather than the null hypothesis.
ans
3)  Since technically the hypothesis is made a priori, why is it not
re-iterated until AFTER producing the test results on the output.

I think it is this last logic that my student and Patrick.  Shouldn't the
hypothesis re-statement preceed the output?

Rob Baer



From lindaportman at yahoo.com  Sat May  1 20:59:35 2004
From: lindaportman at yahoo.com (Linda portman)
Date: Sat, 1 May 2004 11:59:35 -0700 (PDT)
Subject: [R] Confidence intervals pointwise and family
Message-ID: <20040501185935.34346.qmail@web50706.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040501/4237a6c1/attachment.pl

From spencer.graves at pdf.com  Sat May  1 21:15:23 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 01 May 2004 12:15:23 -0700
Subject: [R] Confidence intervals pointwise and family
In-Reply-To: <20040501185935.34346.qmail@web50706.mail.yahoo.com>
References: <20040501185935.34346.qmail@web50706.mail.yahoo.com>
Message-ID: <4093F74B.1030708@pdf.com>

?predict.lm in R 1.9.0 provides examples. 

hope this helps.  spencer graves

Linda portman wrote:

>How can I add confidence intervals (pointwise and family) around the curves?
>The curve is made by plot(x,y). Thanks!
> 
> 
> 
>
>		
>---------------------------------
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From huang.hlc at msa.hinet.net  Sat May  1 21:27:44 2004
From: huang.hlc at msa.hinet.net (=?big5?B?tsC3R6Xg?=)
Date: Sun, 2 May 2004 03:27:44 +0800
Subject: [R] ONE QUESTION IN R-PROJECT
Message-ID: <000801c42fb2$6ccee8c0$6e01fea9@hlc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040502/625898cd/attachment.pl

From spencer.graves at pdf.com  Sat May  1 21:40:48 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 01 May 2004 12:40:48 -0700
Subject: [R] ONE QUESTION IN R-PROJECT
In-Reply-To: <000801c42fb2$6ccee8c0$6e01fea9@hlc>
References: <000801c42fb2$6ccee8c0$6e01fea9@hlc>
Message-ID: <4093FD40.1070205@pdf.com>

  It depends. If I had only this specific set of equations to solve, and 
I wanted an answer in the next few minutes, I might solve the second 
equation to give X in terms of Y , substitute the result in the first, 
then plot the result over a range that seemed plausible.

fun2 <- function(Y){
X <- (7-4*(Y^2))/3
2*exp(X)+X^2+3*Y
}
plot(fun2)
fun2.0 <- 2*exp(1)+4
abline(h=fun2.0)

 From here, one can read the solution from the plot: Y is approximately 1.

If you want more than this, see "?optim", work the examples, etc. If you 
want more than this, check the references given with "?optim".

hope this helps. spencer graves

??? wrote:

>Hello:
>
>I have a question in Math.
>If we want to get X's and Y's solution, X>0 and Y>0
>We have two equation :
>
>2*exp(X)+X^2+3*Y=2*exp(1)+4
>3*X+4*(Y^2)=7
>
>How I use R-project to  solve above question??
>
>THANKS  YOU !!!!
>                                   HLC
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From dmurdoch at pair.com  Sat May  1 22:03:58 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 01 May 2004 16:03:58 -0400
Subject: [R] results from t-test
In-Reply-To: <011201c42fad$ba380e20$6401a8c0@meadow>
References: <4093A8E6.3080209@polytechnic.edu.na>
	<dcd790hk7nltd2smt8lsci6i2koffhh765@4ax.com>
	<011201c42fad$ba380e20$6401a8c0@meadow>
Message-ID: <jtv790pm5k3001p6026a00gkdbti4l0cr1@4ax.com>

On Sat, 1 May 2004 13:54:26 -0500, "Robert W. Baer, Ph.D."
<rbaer at atsu.edu> wrote:

>1)  Why the null AND the alternative weren't stated (guessed the answer was
>parsimony)

In one-sided tests the p-value is the same whether the null is "the
mean is zero" or "the mean is less than or equal to zero", so which
statement should it give?

>2)  Why if only one was stated, the convention was to re-state the
>alternative rather than the null hypothesis.

The p-value depends on whether a one-sided or two-sided alternative is
used, so it's important to state that.

>3)  Since technically the hypothesis is made a priori, why is it not
>re-iterated until AFTER producing the test results on the output.

That might be preferable, but I doubt that anybody who misinterprets
it now would notice the difference.  It would probably be sufficient
to add "the":

alternative hypothesis: the true mean is not equal to 0

However, the code that prints this line also prints results of lots of
other tests, and it doesn't really seem worth the time required to
know if "the" is appropriate in all situations.  

Duncan Murdoch



From wdieteri at du.edu  Sun May  2 00:08:55 2004
From: wdieteri at du.edu (William Dieterich)
Date: Sat, 01 May 2004 16:08:55 -0600
Subject: [R] changes to y-axis labels in lmList intervals plot
Message-ID: <000001c42fc8$e5828f40$8cccfd82@D8S18W01>

Dear List,

I am plotting lmList objects using plot(intervals()) in nlme 
package.  I want to make changes to the y-axis labels. When I 
try to change cex of y-axis labels using the following: 

fm1 <- lmList(distance ~ age | Subject, Orthodont)
plot(intervals(fm1), scales=list(y=list(cex = .7)))

I receive: Error in bwplot(formula = group ~ intervals | what, 
data = structure(list( : formal argument "scales" matched by 
multiple actual arguments

I have searched the documentation on Trellis and Lattice but 
can't seem to figure this out.

Any help would be greatly appreciated.

Thank you,

Bill Dieterich



From vograno at evafunds.com  Sun May  2 00:25:25 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Sat, 1 May 2004 15:25:25 -0700
Subject: [R] skip lines on a connection
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B32D7@phost015.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040501/c72aac47/attachment.pl

From deepayan at stat.wisc.edu  Sun May  2 00:29:37 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 1 May 2004 17:29:37 -0500
Subject: [R] changes to y-axis labels in lmList intervals plot
In-Reply-To: <000001c42fc8$e5828f40$8cccfd82@D8S18W01>
References: <000001c42fc8$e5828f40$8cccfd82@D8S18W01>
Message-ID: <200405011729.37987.deepayan@stat.wisc.edu>

On Saturday 01 May 2004 17:08, William Dieterich wrote:
> Dear List,
>
> I am plotting lmList objects using plot(intervals()) in nlme
> package.  I want to make changes to the y-axis labels. When I
> try to change cex of y-axis labels using the following:
>
> fm1 <- lmList(distance ~ age | Subject, Orthodont)
> plot(intervals(fm1), scales=list(y=list(cex = .7)))
>
> I receive: Error in bwplot(formula = group ~ intervals | what,
> data = structure(list( : formal argument "scales" matched by
> multiple actual arguments

As the error message suggests, the plot method supplies its own scales 
argument, which conflicts with the one you give. The only way out that 
I can think of (short of making changes to the plot method) is changing 
the global settings:

> lset(list(axis.text = list(cex = .7)))
> plot(intervals(fm1))

Unfortunately, this would change the x-axis cex as well.

If you don't want to make the change globally, and you are using R 
1.9.0, you could also do 

> plot(intervals(fm1), 
+      par.settings = list(axis.text = list(cex = .7)))

which has the effect of attaching the settings to the trellis object, 
and using them for the duration of the plotting.

HTH,

Deepayan



From ggrothendieck at myway.com  Sun May  2 00:43:33 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 1 May 2004 22:43:33 +0000 (UTC)
Subject: [R] skip lines on a connection
References: <C698D707214E6F4AB39AB7096C3DE5A54B32D7@phost015.intermedia.net>
Message-ID: <loom.20040502T004307-606@post.gmane.org>



?seek

Vadim Ogranovich <vograno <at> evafunds.com> writes:

: 
: Hi,
: 
: I am looking for an efficient way of skipping big chunks of lines on a
: connection (not necessarily at the beginning of the file). One way is to
: use read lines, e.g. readLines(1e6), but a) this incurs the overhead of
: construction of the return char vector and b) has a (fairly remote)
: potential to blow up the memory.
: 
: Another way would be to use scan(), e.g. 
: 
: scan(con, skip=1e6, nmax=0)
: 
: but somehow this doesn't work:
: 
: > scan(con, skip=10, nmax=0)
: Error in scan(con, skip = 10, nmax = 0) : 
:  "scan" expected a real, got "A;12;0;"
: 
: I can stick to readLines, but am curious if there is a better way.
: 
: I use R-1.8.1 on RH-7.3.
: 
: Thanks,
: Vadim



From vograno at evafunds.com  Sun May  2 01:35:52 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Sat, 1 May 2004 16:35:52 -0700
Subject: [R] skip lines on a connection
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B32D8@phost015.intermedia.net>

Unfortunately, seek only works in terms of bytes not lines and I only
know how many lines I need to skip, but not bytes.


-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at myway.com] 
Sent: Saturday, May 01, 2004 3:44 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] skip lines on a connection




?seek

Vadim Ogranovich <vograno <at> evafunds.com> writes:

: 
: Hi,
: 
: I am looking for an efficient way of skipping big chunks of lines on a
: connection (not necessarily at the beginning of the file). One way is
to
: use read lines, e.g. readLines(1e6), but a) this incurs the overhead
of
: construction of the return char vector and b) has a (fairly remote)
: potential to blow up the memory.
: 
: Another way would be to use scan(), e.g. 
: 
: scan(con, skip=1e6, nmax=0)
: 
: but somehow this doesn't work:
: 
: > scan(con, skip=10, nmax=0)
: Error in scan(con, skip = 10, nmax = 0) : 
:  "scan" expected a real, got "A;12;0;"
: 
: I can stick to readLines, but am curious if there is a better way.
: 
: I use R-1.8.1 on RH-7.3.
: 
: Thanks,
: Vadim

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Sun May  2 02:28:10 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 1 May 2004 20:28:10 -0400
Subject: [R] skip lines on a connection
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7CCA@usrymx25.merck.com>

Your scan() call doesn't work because default argument what=0; i.e., it
expects numeric data.  You probably can just use what="".

The other alternative is to just loop readLines() n times, reading one line
at a time.  It probably won't be too bad in terms of time, and surely will
save on memory usage.

(Try using replicate().)

HTH,
Andy

> From: Vadim Ogranovich
> 
> Unfortunately, seek only works in terms of bytes not lines and I only
> know how many lines I need to skip, but not bytes.
> 
> 
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at myway.com] 
> Sent: Saturday, May 01, 2004 3:44 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] skip lines on a connection
> 
> 
> 
> 
> ?seek
> 
> Vadim Ogranovich <vograno <at> evafunds.com> writes:
> 
> : 
> : Hi,
> : 
> : I am looking for an efficient way of skipping big chunks of 
> lines on a
> : connection (not necessarily at the beginning of the file). 
> One way is
> to
> : use read lines, e.g. readLines(1e6), but a) this incurs the overhead
> of
> : construction of the return char vector and b) has a (fairly remote)
> : potential to blow up the memory.
> : 
> : Another way would be to use scan(), e.g. 
> : 
> : scan(con, skip=1e6, nmax=0)
> : 
> : but somehow this doesn't work:
> : 
> : > scan(con, skip=10, nmax=0)
> : Error in scan(con, skip = 10, nmax = 0) : 
> :  "scan" expected a real, got "A;12;0;"
> : 
> : I can stick to readLines, but am curious if there is a better way.
> : 
> : I use R-1.8.1 on RH-7.3.
> : 
> : Thanks,
> : Vadim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From kjetil at acelerate.com  Sun May  2 02:37:13 2004
From: kjetil at acelerate.com (kjetil@acelerate.com)
Date: Sun, 02 May 2004 00:37:13 -0000
Subject: [R] skip lines on a connection
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A54B32D8@phost015.intermedia.net>
Message-ID: <40BB9383.19485.294ACD0@localhost>

On 1 May 2004 at 16:35, Vadim Ogranovich wrote:

> Unfortunately, seek only works in terms of bytes not lines and I only
> know how many lines I need to skip, but not bytes.
> 

read.table() has a skip= agrument

(probably also has scan()   )

Kjetil Halvorsen

> 
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at myway.com] 
> Sent: Saturday, May 01, 2004 3:44 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] skip lines on a connection
> 
> 
> 
> 
> ?seek
> 
> Vadim Ogranovich <vograno <at> evafunds.com> writes:
> 
> : 
> : Hi,
> : 
> : I am looking for an efficient way of skipping big chunks of lines on
> a : connection (not necessarily at the beginning of the file). One way
> is to : use read lines, e.g. readLines(1e6), but a) this incurs the
> overhead of : construction of the return char vector and b) has a
> (fairly remote) : potential to blow up the memory. : : Another way
> would be to use scan(), e.g. : : scan(con, skip=1e6, nmax=0) : : but
> somehow this doesn't work: : : > scan(con, skip=10, nmax=0) : Error in
> scan(con, skip = 10, nmax = 0) : :  "scan" expected a real, got
> "A;12;0;" : : I can stick to readLines, but am curious if there is a
> better way. : : I use R-1.8.1 on RH-7.3. : : Thanks, : Vadim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From jasont at indigoindustrial.co.nz  Sun May  2 05:04:07 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sun, 02 May 2004 15:04:07 +1200
Subject: [R] PCA filtering
In-Reply-To: <OF79EEEBCB.74C9168D-ON43256E87.00649B65@qp.com.qa>
References: <OF79EEEBCB.74C9168D-ON43256E87.00649B65@qp.com.qa>
Message-ID: <40946527.40204@indigoindustrial.co.nz>

elkurdy at qp.com.qa wrote:
> 
> 
> 
> Hi,
> 
> Is there a function under R that does principal component analysis and then
> use the selected eignevectors to filter the data and transform back to the
> original coordinates?
> If there isn't, can someone guide as to how to do this approach.
> 
> Much appreciated.
> 

Does the "predict" function do what you want?

Cheers

Jason



From Charles.Annis at StatisticalEngineering.com  Sun May  2 05:15:54 2004
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Sat, 1 May 2004 23:15:54 -0400
Subject: [R] building a "simple" R package
Message-ID: <200405020315.i423FuBN023014@hypatia.math.ethz.ch>

Dear R-ers:

Recognizing that it is better to remain silent and have people think you
stupid than to speak and remove any doubt, I fear that I must speak
nonetheless.

I am having the Devil's own time trying to make a simple R package for my
own use.  Yes, I have perused the FAQs and searched the archives.  Yes, I
have read "Writing R Extensions" and eventually divined what Rcmd means and
that it isn?t accessed from an R session.  I downloaded and installed Perl,
and eventually some Unix tools from
http://www.murdoch-sutherland.com/Rtools/tools.zip, specifically tar.exe,
sh.exe, cygwin1.dll, gzip.exe.  I found "package.skeleton" and was able to
produce the requisite files, and even got "Rcmd build" to progress far
enough to begin packaging things.  Alas, I am stymied.  As can be seen in
the screen-dump below, after declaring that tar was building, it was unable
to proceed.

I am using R1.8.1 on a WinXP Professional DELL 3 GHz Pentium 4 with 2 Gig
RAM.  I put all the files mentioned above, including my source folder (I
only have R routines - no C or FORTRAN) in C:\Program Files\R\rw1081\bin to
avoid any potential PATH problems.

Can any kind reader help me?  I realize this shouldn't be this complicated,
but somehow I have made it thus, and would welcome a helping hand.

Thank you.

Charles Annis, P.E.

##########  Screen Dump    #########################################

C:\Program Files\R\rw1081\bin>Rcmd build myPOD
* checking for file 'myPOD/DESCRIPTION' ... OK
* preparing 'myPOD':
* checking whether 'INDEX' is up-to-date ... OK
* removing junk files
* building 'myPOD_1.0.tar.gz'
tar: Files/R/rw1081/bin/myPOD_1.0.tar: Cannot stat: No such file or
directory
tar: Error exit delayed from previous errors
tar: Files/R/rw1081/bin/myPOD_1.0.tar: Not found in archive
tar: Error exit delayed from previous errors
tar: Files/R/rw1081/bin/myPOD_1.0.tar: Cannot stat: No such file or
directory
tar: myPOD: Cannot stat: No such file or directory
tar: Error exit delayed from previous errors
myPOD_1.0.tar: No such file or directory

Charles Annis, P.E.
 
Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  503-217-5849
http://www.StatisticalEngineering.com



From jasont at indigoindustrial.co.nz  Sun May  2 05:58:20 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sun, 02 May 2004 15:58:20 +1200
Subject: [R] building a "simple" R package
In-Reply-To: <200405020315.i423FuBN023014@hypatia.math.ethz.ch>
References: <200405020315.i423FuBN023014@hypatia.math.ethz.ch>
Message-ID: <409471DC.4000007@indigoindustrial.co.nz>

Charles Annis, P.E. wrote:

> Dear R-ers:
> 
> Recognizing that it is better to remain silent and have people think you
> stupid than to speak and remove any doubt, I fear that I must speak
> nonetheless.
> 
> I am having the Devil's own time trying to make a simple R package for my
> own use.  Yes, I have perused the FAQs and searched the archives.  Yes, I
> have read "Writing R Extensions" and eventually divined what Rcmd means and
> that it isn?t accessed from an R session.  I downloaded and installed Perl,
> and eventually some Unix tools from
> http://www.murdoch-sutherland.com/Rtools/tools.zip, specifically tar.exe,
> sh.exe, cygwin1.dll, gzip.exe.  I found "package.skeleton" and was able to
> produce the requisite files, and even got "Rcmd build" to progress far
> enough to begin packaging things.  Alas, I am stymied.  As can be seen in
> the screen-dump below, after declaring that tar was building, it was unable
> to proceed.
> 
> I am using R1.8.1 on a WinXP Professional DELL 3 GHz Pentium 4 with 2 Gig
> RAM.  I put all the files mentioned above, including my source folder (I
> only have R routines - no C or FORTRAN) in C:\Program Files\R\rw1081\bin to
> avoid any potential PATH problems.
> 
> Can any kind reader help me?  I realize this shouldn't be this complicated,
> but somehow I have made it thus, and would welcome a helping hand.
> 
> Thank you.
> 
> Charles Annis, P.E.
> 
> ##########  Screen Dump    #########################################
> 
> C:\Program Files\R\rw1081\bin>Rcmd build myPOD
> * checking for file 'myPOD/DESCRIPTION' ... OK
> * preparing 'myPOD':
> * checking whether 'INDEX' is up-to-date ... OK
> * removing junk files
> * building 'myPOD_1.0.tar.gz'
> tar: Files/R/rw1081/bin/myPOD_1.0.tar: Cannot stat: No such file or
> directory
> tar: Error exit delayed from previous errors
> tar: Files/R/rw1081/bin/myPOD_1.0.tar: Not found in archive
> tar: Error exit delayed from previous errors
> tar: Files/R/rw1081/bin/myPOD_1.0.tar: Cannot stat: No such file or
> directory
> tar: myPOD: Cannot stat: No such file or directory
> tar: Error exit delayed from previous errors
> myPOD_1.0.tar: No such file or directory
> 

"Writing R Extensions" does say that you can't use a directory path with 
spaces in the name.  Is that the issue here (are you working in "Program 
Files" and not "Files" as the printout says)?

This is why my R work on my XP box is done in c:\devel\R

Hope that helps.

Cheers

Jason



From vograno at evafunds.com  Sun May  2 07:28:46 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Sat, 1 May 2004 22:28:46 -0700
Subject: [R] skip lines on a connection
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B32D9@phost015.intermedia.net>

Andy,

It is surprising that scan() attempts to read anything at all: note that
I set nmax=0, which AFAIK means read no lines.

Thank you for a reference to replicate(). I didn't know about it.

Thanks,
Vadim

-----Original Message-----
From: Liaw, Andy [mailto:andy_liaw at merck.com] 
Sent: Saturday, May 01, 2004 5:28 PM
To: Vadim Ogranovich; r-help at stat.math.ethz.ch
Subject: RE: [R] skip lines on a connection


Your scan() call doesn't work because default argument what=0; i.e., it
expects numeric data.  You probably can just use what="".

The other alternative is to just loop readLines() n times, reading one
line at a time.  It probably won't be too bad in terms of time, and
surely will save on memory usage.

(Try using replicate().)

HTH,
Andy

> From: Vadim Ogranovich
> 
> Unfortunately, seek only works in terms of bytes not lines and I only 
> know how many lines I need to skip, but not bytes.
> 
> 
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at myway.com]
> Sent: Saturday, May 01, 2004 3:44 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] skip lines on a connection
> 
> 
> 
> 
> ?seek
> 
> Vadim Ogranovich <vograno <at> evafunds.com> writes:
> 
> :
> : Hi,
> : 
> : I am looking for an efficient way of skipping big chunks of 
> lines on a
> : connection (not necessarily at the beginning of the file). 
> One way is
> to
> : use read lines, e.g. readLines(1e6), but a) this incurs the overhead
> of
> : construction of the return char vector and b) has a (fairly remote)
> : potential to blow up the memory.
> : 
> : Another way would be to use scan(), e.g. 
> : 
> : scan(con, skip=1e6, nmax=0)
> : 
> : but somehow this doesn't work:
> : 
> : > scan(con, skip=10, nmax=0)
> : Error in scan(con, skip = 10, nmax = 0) : 
> :  "scan" expected a real, got "A;12;0;"
> : 
> : I can stick to readLines, but am curious if there is a better way.
> : 
> : I use R-1.8.1 on RH-7.3.
> : 
> : Thanks,
> : Vadim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------
------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ripley at stats.ox.ac.uk  Sun May  2 08:44:13 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 May 2004 07:44:13 +0100 (BST)
Subject: [R] skip lines on a connection
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A54B32D9@phost015.intermedia.net>
Message-ID: <Pine.LNX.4.44.0405020735210.18781-100000@gannet.stats>

On Sat, 1 May 2004, Vadim Ogranovich wrote:

> Andy,
> 
> It is surprising that scan() attempts to read anything at all: note that
> I set nmax=0, which AFAIK means read no lines.

You will be telling us next you think the default nmax=-1 means to read a
negative number of lines!  So reading no lines would mean not calling scan
at all, and what would be the point of that?

nmax <= 0 and nlines <= 0 are ignored.

Note carefully what nmax actually means, and it is not what `nlines' 
means!

> Thank you for a reference to replicate(). I didn't know about it.

Do read the documentation for scan, too, please.


Note that to read *lines* you do need to read every byte on the file to 
find the EOL marker(s) so readLines() or scan() with NULL in "what" are as 
good as anything.  You can use them in blocks of lines, in a loop.

> 
> Thanks,
> Vadim
> 
> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com] 
> Sent: Saturday, May 01, 2004 5:28 PM
> To: Vadim Ogranovich; r-help at stat.math.ethz.ch
> Subject: RE: [R] skip lines on a connection
> 
> 
> Your scan() call doesn't work because default argument what=0; i.e., it
> expects numeric data.  You probably can just use what="".
> 
> The other alternative is to just loop readLines() n times, reading one
> line at a time.  It probably won't be too bad in terms of time, and
> surely will save on memory usage.
> 
> (Try using replicate().)
> 
> HTH,
> Andy
> 
> > From: Vadim Ogranovich
> > 
> > Unfortunately, seek only works in terms of bytes not lines and I only 
> > know how many lines I need to skip, but not bytes.
> > 
> > 
> > -----Original Message-----
> > From: Gabor Grothendieck [mailto:ggrothendieck at myway.com]
> > Sent: Saturday, May 01, 2004 3:44 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: Re: [R] skip lines on a connection
> > 
> > 
> > 
> > 
> > ?seek
> > 
> > Vadim Ogranovich <vograno <at> evafunds.com> writes:
> > 
> > :
> > : Hi,
> > : 
> > : I am looking for an efficient way of skipping big chunks of 
> > lines on a
> > : connection (not necessarily at the beginning of the file). 
> > One way is
> > to
> > : use read lines, e.g. readLines(1e6), but a) this incurs the overhead
> > of
> > : construction of the return char vector and b) has a (fairly remote)
> > : potential to blow up the memory.
> > : 
> > : Another way would be to use scan(), e.g. 
> > : 
> > : scan(con, skip=1e6, nmax=0)
> > : 
> > : but somehow this doesn't work:
> > : 
> > : > scan(con, skip=10, nmax=0)
> > : Error in scan(con, skip = 10, nmax = 0) : 
> > :  "scan" expected a real, got "A;12;0;"
> > : 
> > : I can stick to readLines, but am curious if there is a better way.
> > : 
> > : I use R-1.8.1 on RH-7.3.
> > : 
> > : Thanks,
> > : Vadim

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun May  2 08:51:00 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 May 2004 07:51:00 +0100 (BST)
Subject: [R] building a "simple" R package
In-Reply-To: <200405020315.i423FuBN023014@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0405020745290.18781-100000@gannet.stats>

Did you read the bits in README.packages which say

  Do not use filepaths with spaces in: you can always use the short forms
  ...

  BEWARE: Don't expect this to work if the path to R_HOME contains spaces.
  It may work, but we don't recommend it.

?  You also appear to be trying to build your package in a filepath with 
spaces in.  So try putting your source files somewhere without spaces in 
the file name.

Or try updating to R 1.9.0, as its CHANGES files says

  R CMD INSTALL/build/check map path names with spaces in to their short
  forms.

so it should work in the current version of R.


On Sat, 1 May 2004, Charles Annis, P.E. wrote:

> Dear R-ers:
> 
> Recognizing that it is better to remain silent and have people think you
> stupid than to speak and remove any doubt, I fear that I must speak
> nonetheless.

A third possibility is to read the READMEs and FAQs.

> I am having the Devil's own time trying to make a simple R package for my
> own use.  Yes, I have perused the FAQs and searched the archives.  Yes, I
> have read "Writing R Extensions" and eventually divined what Rcmd means and
> that it isn?t accessed from an R session.  I downloaded and installed Perl,
> and eventually some Unix tools from
> http://www.murdoch-sutherland.com/Rtools/tools.zip, specifically tar.exe,
> sh.exe, cygwin1.dll, gzip.exe.  I found "package.skeleton" and was able to
> produce the requisite files, and even got "Rcmd build" to progress far
> enough to begin packaging things.  Alas, I am stymied.  As can be seen in
> the screen-dump below, after declaring that tar was building, it was unable
> to proceed.
> 
> I am using R1.8.1 on a WinXP Professional DELL 3 GHz Pentium 4 with 2 Gig
> RAM.  I put all the files mentioned above, including my source folder (I
> only have R routines - no C or FORTRAN) in C:\Program Files\R\rw1081\bin to
> avoid any potential PATH problems.
> 
> Can any kind reader help me?  I realize this shouldn't be this complicated,
> but somehow I have made it thus, and would welcome a helping hand.
> 
> Thank you.
> 
> Charles Annis, P.E.
> 
> ##########  Screen Dump    #########################################
> 
> C:\Program Files\R\rw1081\bin>Rcmd build myPOD
> * checking for file 'myPOD/DESCRIPTION' ... OK
> * preparing 'myPOD':
> * checking whether 'INDEX' is up-to-date ... OK
> * removing junk files
> * building 'myPOD_1.0.tar.gz'
> tar: Files/R/rw1081/bin/myPOD_1.0.tar: Cannot stat: No such file or
> directory
> tar: Error exit delayed from previous errors
> tar: Files/R/rw1081/bin/myPOD_1.0.tar: Not found in archive
> tar: Error exit delayed from previous errors
> tar: Files/R/rw1081/bin/myPOD_1.0.tar: Cannot stat: No such file or
> directory
> tar: myPOD: Cannot stat: No such file or directory
> tar: Error exit delayed from previous errors
> myPOD_1.0.tar: No such file or directory
> 
> Charles Annis, P.E.
>  
> Charles.Annis at StatisticalEngineering.com
> phone: 561-352-9699
> eFax:  503-217-5849
> http://www.StatisticalEngineering.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From patrick.giraudoux at univ-fcomte.fr  Sun May  2 10:30:39 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 2 May 2004 10:30:39 +0200
Subject: [R] contourplot, xyplot, aspect ratio, mfrow
Message-ID: <001201c4301f$cdacf480$a249fb51@PC728329681112>

Hi,

I am gradually moving from the classical R plot functions to the library Lattice

I have some questions about contourplot () and its arguments:

1/ I am working on geographical coordinates which makes necessary that the X (longitude) and Y (latitude) units be represented with
the same distance on screen. This was obtained in the classical R plots with plot.default(x,y, asp=1,...)  and then contour(...,
add=T). When I try aspect=1 with contour plot, I get a square but not at all the aspect ratio I wish: 1 unit on X = one unit on Y =
the same distance on screen. What goes wrong?

2/ I would also be capable to project points and symbols on a contourplot (the equivalent of points() and symbols() after plot() and
contour()), but can hardly guess from the help how to manage with.

3/ I would also appreciate to manage the equivalent of par(mfrow=c(2,2)) -or any other numbers of screens- and have a "Trellis" plot
in each of the sub-screens. It seems that contourplot does not comply with and ignore the above parameters. Right or wrong? If so,
which approach can solve this problem?

Thanks in advance for any hint,

Patrick Giraudoux



From tura at centroin.com.br  Sun May  2 11:35:08 2004
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Sun, 02 May 2004 06:35:08 -0300
Subject: [R] Probability(Markov chain transition matrix)
In-Reply-To: <BAY2-F8LdElsBt8sBju000149cf@hotmail.com>
References: <BAY2-F8LdElsBt8sBju000149cf@hotmail.com>
Message-ID: <6.0.0.22.2.20040502061700.037c6070@pop.centroin.com.br>

At 17:25 30/04/2004, you wrote:
>So we come up with Transition matrix stating probabilities of each state
>
>FromTo NC   0       1     2     3
>NC      0.79  0.21  0      0    0
>0          0.09  0.73 0.18 0    0
>1          0.09  0.51  0   0.40  0
>2          0.09  0.38  0      0   0.55
>3          0.06  0.32  0      0   0.62
>
>
>Thus if one starts with all the accounts having no credit ?0 =(1,0,0,0,0), after one period the distribution of account is ?1=(0.79, 0.21, 0, 0, 0)  
>after subsequent periods, it becomes
>
>?2=(0.64, 0.32, 0.04, 0, 0),
>?3= (0.540, 0.387, 0.058, 0.015, 0)
>?4=(0.468,0.431, 0.070, 0.023, 0.008)
>?5=(0.417, 0.460, 0.077, 0.028, 0.018)
>and ++++
>?10=(0.315, 0.512, 0.091, 0.036, 0.046)

Hi 


I create a rotine for a problem like this, I hope this is useful for you
------------
#############################################
##            MARKOV CHAIN                 ## 
##                                         ##
## ini- initial state                      ## 
## trans- transition matrix                ##
## n - number of transitions               ##
## f - ini%*%trans                         ##  
## fase - f consolidate                    ##
##                                         ## 
#############################################



#          initial state

ini<-matrix(c(10,0,0,0,0,0,0,0,0),nrow=3,ncol=3)

#          transition matrix
#
#      [,1] [,2] [,3]
# [1,] 0.85  0.1  0.05
# [2,] 0.00  0.7  0.3
# [3,] 0.00  0.0  1.0
#
# In R the command is

trans<-matrix(c(.85,0,0,.1,.7,0,0.05,0.3,1),ncol=3)

markov<-function(ini,trans,n){
  l<-ncol(ini)
  fase<-matrix(0,nrow=l,ncol=l)
  fases<-array(0,dim=c(nrow(ini),ncol(ini),n))
  for (i in 1:n){
    f<-ini%*%trans
    for (w in 1:l){fase[w,w]<-sum(f[,w])}
  ini<-fase
  fases[,,i]<-fase
# print(fase)
# 
# Fase allow calcule de value for transition:
# If sate 1 value 0,95, state 2 value 0,3 and  state 3
# value 0 QALY. 
# I?m calculate de value of any transition if
#  print(sum(fase%*%c(.95,.3,0)))
#
# 

  }
  return(fases)
}

a<-markov(ini,trans,5)

For your case:

ini<-matrix(c(1,rep(0,24)),ncol=5)
trans<-matrix(c(0.79,0.21,0,0,0,0.09,0.73,0.18,0,0,0.09,0.51,0,0.40,0,0.09,0.38,0,0,0.55,0.06,0.32,0,0,0.62),ncol=5)
solv<-markov(ini,trans,10)
> solv[,,10]
          [,1]      [,2]      [,3]      [,4]      [,5]
[1,] 0.3173366 0.0000000 0.0000000 0.0000000 0.0000000
[2,] 0.0000000 0.2876792 0.0000000 0.0000000 0.0000000
[3,] 0.0000000 0.0000000 0.2875772 0.0000000 0.0000000
[4,] 0.0000000 0.0000000 0.0000000 0.2886571 0.0000000
[5,] 0.0000000 0.0000000 0.0000000 0.0000000 0.2810951








Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil 

From phddas at yahoo.com  Sun May  2 12:26:41 2004
From: phddas at yahoo.com (Fred J.)
Date: Sun, 2 May 2004 03:26:41 -0700 (PDT)
Subject: [R] Least Squares Fit
Message-ID: <20040502102641.87598.qmail@web20503.mail.yahoo.com>

Hello

I need to plot the least squares fit and get the slope
of the line that best fit the data. after reading lm
and lsfit, since not being able to understand the use
of the second argument "y" for the lsfit, I am giving
the lm a go, but know not why the code below does not
draw the line on the plot. e.g. well.. why -50
Intercept?
thanks

x <- 1:10; y <- x+50
plot(x,y)
z <- lm(as.data.frame(cbind(x,y))))
abline(z)

> z$coefficients
(Intercept)           y 
        -50           1



From highstat at highstat.com  Sun May  2 12:27:23 2004
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Sun, 02 May 2004 11:27:23 +0100
Subject: [R] stats courses in Aberdeen (UK) and Ancona (Italy)
Message-ID: <6.0.0.22.2.20040502112544.01c68c28@mail.highstat.com>



From m.dewey at iop.kcl.ac.uk  Sun May  2 12:24:07 2004
From: m.dewey at iop.kcl.ac.uk (Michael Dewey)
Date: Sun, 02 May 2004 11:24:07 +0100
Subject: [R] rbind with missing columns
In-Reply-To: <200405011003.i41A1DFf003694@hypatia.math.ethz.ch>
References: <200405011003.i41A1DFf003694@hypatia.math.ethz.ch>
Message-ID: <6.1.0.6.0.20040502112101.02647740@pop.freeserve.net>

At 11:03 01/05/04, you wrote:
>Message: 3
>Date: Fri, 30 Apr 2004 13:47:35 +0200
>From: <klaus.thul at infineon.com>
>Subject: [R] rbind with missing columns
>To: <r-help at stat.math.ethz.ch>
>Message-ID:
>         <7509DD89A305F34E9EF16F1EEDFB80AF08D6D3 at drsse401.eu.infineon.com>
>Content-Type: text/plain;       charset="us-ascii"
>
>Hello,
>
>I have several data sets, which I want to combine column-by-column using
>"rbind" (the data sets have ~100 columns). The problem is, that in some
>data sets some of the columns are missing.
>
>Simply using rbind gives me:
>"Error in match.names(clabs, names(xi)) : names don't match previous
>names"
>
>Is there a simple way to make R do the rbind despite the missing columns
>and to fill out the missing data with NA's? (I could program this
>somehow, but probably there is one very simple solution available)
>
>To make it clear here a simplified example. "unknown.command" is what I
>am looking for.
>
>A <- data.frame(a = c(1,2,3), b = c(4,5,6))
>B <- data.frame(a = c(1,2,3))
>unknown.command(A, B) - should give
>
>A B
>1 4
>2 5
>3 6
>4 NA
>5 NA
>6 NA

Does

A$id <- 1:nrow(A)
B$id <- 1:nrow(B) + nrow(A)
AandB <- merge(A, B, all = TRUE)


 > A
   a b id
1 1 4  1
2 2 5  2
3 3 6  3
 > B
   a id
1 1  4
2 2  5
3 3  6
 > AandB
   a id  b
1 1  1 4
2 1  4 NA
3 2  2 5
4 2  5 NA
5 3  3 6
6 3  6 NA
 >

Give you what you wanted? You can always strip out the "id" column if you 
wish (after sorting on it if you would like the original order back.

>Thank you for your help
>Klaus

Michael Dewey
m.dewey at iop.kcl.ac.uk



From baron at psych.upenn.edu  Sun May  2 13:10:10 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sun, 2 May 2004 07:10:10 -0400
Subject: [R] Least Squares Fit
In-Reply-To: <20040502102641.87598.qmail@web20503.mail.yahoo.com>
References: <20040502102641.87598.qmail@web20503.mail.yahoo.com>
Message-ID: <20040502111010.GA20854@psych>

On 05/02/04 03:26, Fred J. wrote:
>Hello
>
>I need to plot the least squares fit and get the slope
>of the line that best fit the data. after reading lm
>and lsfit, since not being able to understand the use
>of the second argument "y" for the lsfit, I am giving
>the lm a go, but know not why the code below does not
>draw the line on the plot. e.g. well.. why -50
>Intercept?
>thanks
>
>x <- 1:10; y <- x+50
>plot(x,y)
>z <- lm(as.data.frame(cbind(x,y))))
>abline(z)
>
>> z$coefficients
>(Intercept)           y
>        -50           1

The lm() is predicting x from y, and plot() is plotting y as a
function of x.

Try
plot(x,y)
abline(lm(y~x))

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From deepayan at stat.wisc.edu  Sun May  2 15:24:51 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 2 May 2004 08:24:51 -0500
Subject: [R] contourplot, xyplot, aspect ratio, mfrow
In-Reply-To: <001201c4301f$cdacf480$a249fb51@PC728329681112>
References: <001201c4301f$cdacf480$a249fb51@PC728329681112>
Message-ID: <200405020824.52064.deepayan@stat.wisc.edu>

On Sunday 02 May 2004 03:30, Patrick Giraudoux wrote:
> Hi,
>
> I am gradually moving from the classical R plot functions to the
> library Lattice
>
> I have some questions about contourplot () and its arguments:
>
> 1/ I am working on geographical coordinates which makes necessary
> that the X (longitude) and Y (latitude) units be represented with the
> same distance on screen. This was obtained in the classical R plots
> with plot.default(x,y, asp=1,...)  and then contour(..., add=T). When
> I try aspect=1 with contour plot, I get a square but not at all the
> aspect ratio I wish: 1 unit on X = one unit on Y = the same distance
> on screen. What goes wrong?

Well, aspect works as documented, so nothing goes wrong. The behaviour 
is just different from asp. You could try 

aspect = diff(range(y))/diff(range(x))

and if your x and y are factors, aspect = "xy" should help. Maybe there 
should be a new option (perhaps aspect = "data") that should do this.

> 2/ I would also be capable to project points and symbols on a
> contourplot (the equivalent of points() and symbols() after plot()
> and contour()), but can hardly guess from the help how to manage
> with.

You need to use a custom panel function (see the section on 'panel' 
in ?xyplot). There's no equivalent of symbols, unfortunately, but 
see ?panel.abline and ?lpoints.

> 3/ I would also appreciate to manage the equivalent of
> par(mfrow=c(2,2)) -or any other numbers of screens- and have a
> "Trellis" plot in each of the sub-screens. It seems that contourplot
> does not comply with and ignore the above parameters. Right or wrong?

Right.

> If so, which approach can solve this problem?

See ?print.trellis. (Note that this also allows you to place trellis 
plots inside grid viewports, which maybe overkill for your use, but 
gives you more flexibility.)

Deepayan



From patrick.giraudoux at univ-fcomte.fr  Sun May  2 15:50:24 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 2 May 2004 15:50:24 +0200
Subject: [R] contourplot, xyplot, aspect ratio, mfrow
References: <001201c4301f$cdacf480$a249fb51@PC728329681112>
	<200405020824.52064.deepayan@stat.wisc.edu>
Message-ID: <002701c4304c$849b8950$8d49fb51@PC728329681112>

Confirmed after checking:

aspect = diff(range(y))/diff(range(x)) in coutourplot looks like being the equivalent of asp = 1  (regarding practical result) in
contour().

Essential for maps!

Thanks a lot for the information and other most valuable hints.

Patrick





----- Original Message ----- 
From: "Deepayan Sarkar" <deepayan at stat.wisc.edu>
To: <r-help at stat.math.ethz.ch>; "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
Sent: Sunday, May 02, 2004 3:24 PM
Subject: Re: [R] contourplot, xyplot, aspect ratio, mfrow


> On Sunday 02 May 2004 03:30, Patrick Giraudoux wrote:
> > Hi,
> >
> > I am gradually moving from the classical R plot functions to the
> > library Lattice
> >
> > I have some questions about contourplot () and its arguments:
> >
> > 1/ I am working on geographical coordinates which makes necessary
> > that the X (longitude) and Y (latitude) units be represented with the
> > same distance on screen. This was obtained in the classical R plots
> > with plot.default(x,y, asp=1,...)  and then contour(..., add=T). When
> > I try aspect=1 with contour plot, I get a square but not at all the
> > aspect ratio I wish: 1 unit on X = one unit on Y = the same distance
> > on screen. What goes wrong?
>
> Well, aspect works as documented, so nothing goes wrong. The behaviour
> is just different from asp. You could try
>
> aspect = diff(range(y))/diff(range(x))
>
> and if your x and y are factors, aspect = "xy" should help. Maybe there
> should be a new option (perhaps aspect = "data") that should do this.
>
> > 2/ I would also be capable to project points and symbols on a
> > contourplot (the equivalent of points() and symbols() after plot()
> > and contour()), but can hardly guess from the help how to manage
> > with.
>
> You need to use a custom panel function (see the section on 'panel'
> in ?xyplot). There's no equivalent of symbols, unfortunately, but
> see ?panel.abline and ?lpoints.
>
> > 3/ I would also appreciate to manage the equivalent of
> > par(mfrow=c(2,2)) -or any other numbers of screens- and have a
> > "Trellis" plot in each of the sub-screens. It seems that contourplot
> > does not comply with and ignore the above parameters. Right or wrong?
>
> Right.
>
> > If so, which approach can solve this problem?
>
> See ?print.trellis. (Note that this also allows you to place trellis
> plots inside grid viewports, which maybe overkill for your use, but
> gives you more flexibility.)
>
> Deepayan



From binabina at bellsouth.net  Sun May  2 15:52:16 2004
From: binabina at bellsouth.net (zubin)
Date: Sun, 2 May 2004 09:52:16 -0400
Subject: [R] r dev site is down
Message-ID: <MBBBIIHJANJBMHLGMACKMECPCGAA.binabina@bellsouth.net>

the R developer site has been down for some time, what gives?

http://developer.r-project.org/

From bates at stat.wisc.edu  Sun May  2 17:06:54 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 02 May 2004 10:06:54 -0500
Subject: [R] r dev site is down
In-Reply-To: <MBBBIIHJANJBMHLGMACKMECPCGAA.binabina@bellsouth.net>
References: <MBBBIIHJANJBMHLGMACKMECPCGAA.binabina@bellsouth.net>
Message-ID: <6rad0qkgvl.fsf@bates4.stat.wisc.edu>

"zubin" <binabina at bellsouth.net> writes:

> the R developer site has been down for some time, what gives?

That web site was a casualty of the break-in on the machine that was
cvs.r-project.org.  We need to move it to another server.



From baron at psych.upenn.edu  Sun May  2 17:51:18 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sun, 2 May 2004 11:51:18 -0400
Subject: [R] report, installation of Fedora 1 RPM on Core 2 test 3
Message-ID: <20040502155118.GA5486@psych>

The installation of R was trivially easy with the RPM for Fedora
Core 1.  The only trick was to use the tck and tk RPMs from Core
1.  Then up2date will complain about them being out of date, but
you can exclude these from up2date's domain.  I also used blas
from Core 1, but then I updated it and yum did not complain.  (It
did when I tried to update tcl and tk.)  So I suspect that the
new version of blas is fine.

FWIW, I really like this new version of Fedora.  Of course, I
expected lots of problems installing it on a Dell Inspiron 9100
(very new model with the latest and greatest of everything), and
I'm having some, but slowly solving them (and filing bug
reports).

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From Charles.Annis at StatisticalEngineering.com  Sun May  2 18:36:57 2004
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Sun, 2 May 2004 12:36:57 -0400
Subject: [R] building a "simple" R package
In-Reply-To: <Pine.LNX.4.44.0405020745290.18781-100000@gannet.stats>
Message-ID: <200405021636.i42GapxO027871@hypatia.math.ethz.ch>

My thanks to Jason Turner and Professor Ripley for alerting me to the
difficulties of spaces-in-filepaths.   

To possible readers of the archives the "short form" the Professor suggested
is e.g.: C:\PROGRA~1\R\rw1081\bin, substituting the tilde for the offending
space-containing filepath and constructing an 8-character name.

This indeed has allowed me to build the tar file as is corroborated by the
screendump:
##########  Screen Dump    #########################################
C:\PROGRA~1\R\rw1081\bin>Rcmd build myPOD
* checking for file 'myPOD/DESCRIPTION' ... OK
* preparing 'myPOD':
* checking whether 'INDEX' is up-to-date ... OK
* removing junk files
* building 'myPOD_1.0.tar.gz'

C:\PROGRA~1\R\rw1081\bin>
##########  End Screen Dump    #####################################

I would like to report that I was subsequently able to install this
successfully, but, alas, I am not out of the woods yet - but at least now I
have a compass, and for this I am indebted to Jason Turner and Professor
Ripley.

Thank you.


Charles Annis, P.E.
 
Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  503-217-5849
http://www.StatisticalEngineering.com

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Sunday, May 02, 2004 2:51 AM
To: Charles Annis, P.E.
Cc: R-help at stat.math.ethz.ch
Subject: Re: [R] building a "simple" R package

Did you read the bits in README.packages which say

  Do not use filepaths with spaces in: you can always use the short forms
  ...

  BEWARE: Don't expect this to work if the path to R_HOME contains spaces.
  It may work, but we don't recommend it.

?  You also appear to be trying to build your package in a filepath with 
spaces in.  So try putting your source files somewhere without spaces in 
the file name.

Or try updating to R 1.9.0, as its CHANGES files says

  R CMD INSTALL/build/check map path names with spaces in to their short
  forms.

so it should work in the current version of R.


On Sat, 1 May 2004, Charles Annis, P.E. wrote:

> Dear R-ers:
> 
> Recognizing that it is better to remain silent and have people think you
> stupid than to speak and remove any doubt, I fear that I must speak
> nonetheless.

A third possibility is to read the READMEs and FAQs.

> I am having the Devil's own time trying to make a simple R package for my
> own use.  Yes, I have perused the FAQs and searched the archives.  Yes, I
> have read "Writing R Extensions" and eventually divined what Rcmd means
and
> that it isn?t accessed from an R session.  I downloaded and installed
Perl,
> and eventually some Unix tools from
> http://www.murdoch-sutherland.com/Rtools/tools.zip, specifically tar.exe,
> sh.exe, cygwin1.dll, gzip.exe.  I found "package.skeleton" and was able to
> produce the requisite files, and even got "Rcmd build" to progress far
> enough to begin packaging things.  Alas, I am stymied.  As can be seen in
> the screen-dump below, after declaring that tar was building, it was
unable
> to proceed.
> 
> I am using R1.8.1 on a WinXP Professional DELL 3 GHz Pentium 4 with 2 Gig
> RAM.  I put all the files mentioned above, including my source folder (I
> only have R routines - no C or FORTRAN) in C:\Program Files\R\rw1081\bin
to
> avoid any potential PATH problems.
> 
> Can any kind reader help me?  I realize this shouldn't be this
complicated,
> but somehow I have made it thus, and would welcome a helping hand.
> 
> Thank you.
> 
> Charles Annis, P.E.
> 
> ##########  Screen Dump    #########################################
> 
> C:\Program Files\R\rw1081\bin>Rcmd build myPOD
> * checking for file 'myPOD/DESCRIPTION' ... OK
> * preparing 'myPOD':
> * checking whether 'INDEX' is up-to-date ... OK
> * removing junk files
> * building 'myPOD_1.0.tar.gz'
> tar: Files/R/rw1081/bin/myPOD_1.0.tar: Cannot stat: No such file or
> directory
> tar: Error exit delayed from previous errors
> tar: Files/R/rw1081/bin/myPOD_1.0.tar: Not found in archive
> tar: Error exit delayed from previous errors
> tar: Files/R/rw1081/bin/myPOD_1.0.tar: Cannot stat: No such file or
> directory
> tar: myPOD: Cannot stat: No such file or directory
> tar: Error exit delayed from previous errors
> myPOD_1.0.tar: No such file or directory
> 
> Charles Annis, P.E.
>  
> Charles.Annis at StatisticalEngineering.com
> phone: 561-352-9699
> eFax:  503-217-5849
> http://www.StatisticalEngineering.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From vograno at evafunds.com  Sun May  2 23:26:45 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Sun, 2 May 2004 14:26:45 -0700
Subject: [R] skip lines on a connection
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B32DB@phost015.intermedia.net>

> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Saturday, May 01, 2004 11:44 PM
> You will be telling us next you think the default nmax=-1 
> means to read a negative number of lines!

No, I won't. Your extrapolation is inaccurate.


> ...  So reading no 
> lines would mean not calling scan at all, and what would be 
> the point of that?


It would mean skipping the number of lines specified in the skip
argument thus advancing the read point on the connection to where I want
it to be. I guess you wouldn't argue that seek(con, where) has no
meaning.


> 
> nmax <= 0 and nlines <= 0 are ignored.
> 
> Note carefully what nmax actually means, and it is not what `nlines' 
> means!


I had noted that. If one reads no "data value" one reads no line, so the
two should have the same effect in the case at hand.


> Do read the documentation for scan, too, please.


I had. For your convenience this is what it says about nmax.

    nmax: the maximum number of data values to be read, or if 'what' is
          a list, the maximum number of records to be read.  If omitted
          (and 'nlines' is not set to a positive value), 'scan' will
          read to the end of 'file'.

It is hard to see from the text that nmax=0 is ignored since "omitted"
means leaving it set to -1.

BTW, the paragraph regarding 'nlines' doesn't mention that nlines=0 is a
special case either.

  nlines: the maximum number of lines of data to be read.


> Note that to read *lines* you do need to read every byte on 
> the file to 
> find the EOL marker(s) so readLines() or scan() with NULL in 
> "what" are as 
> good as anything.  You can use them in blocks of lines, in a loop.


This is a very nice trick indeed! Just what I've been looking for.

Thank you very much,
Vadim



From andy_liaw at merck.com  Sun May  2 23:54:28 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 2 May 2004 17:54:28 -0400
Subject: [R] parallel REML computation
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7CCD@usrymx25.merck.com>

Sorry for the off-topic (non-R) post.  Has anyone seen/tried this (from this
week's NA-digest)?

Andy
-------------------------------------------------------

From: Joel Malard <JM.Malard at pnl.gov>
Date: Sat, 01 May 2004 15:31:15 -0700
Subject: ACRE, Parallel Covariance Component Estimation Code

A couple of people have asked recently for a copy of the parallel
(restricted/residual) maximum (REML/ML) gradient algorithms from the paper:

    J.M. Malard, "Parallel Restricted Maximum Likelihood Estimation
    for Linear models with a Dense Exogenous Matrix", Parallel
    Computing, 28, pp343-53, 2002. 

The code has been upgraded to PETSc 2.2.0 and TAO 1.6 and is available
by sending an email at acre-developers at eml.pnl.gov. This software solves
covariance component estimation problems for linear models were the
residual vector comes from a normal distribution. The Cholesky
factorization of the covariance matrix is a sparse matrix. The problem
must be framed in the following form, which underlines that REML and ML
estimation can be viewed as a next step in complexity after solving
linear least squares.

    Given a dense matrix A and a response vector b, find the
    Best Linear Unbiased Estimator x and an upper triangular
    matrix L such that Ax=b+e and the matrix LL' (L times
    the transpose of L) is equal to the expected value of xx'.
    Both L and A are assumed full rank. 
 
It is customary in statistical modeling to split the matrix A into fixed
and random effects. The two formulations are equivalent but no script is
provided to do the conversion. 

The purpose of this project was to demonstrate that linear estimation
algorithms such as REML can scale to a few hundred processors on a
distributed memory platform. The dll webpage
http://csm.pnl.gov/statistics/dll contains some additional information. 

If anyone needs an implementation of the REML Hessian matrix using the
forward differentiation mode, it has existed in the past, send an email
to the above address. My current priority is to allow for a singular
matrix L. Comments, bugs reports and suggestions are welcome at the same
email address.

With best regards,

Joel M. Malard, Ph.D.
Pacific Northwest National Laboratory
Battelle Boulevard, PO Box 999
Mail Stop K1-85
Richland, WA 99352



------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From feh3k at spamcop.net  Mon May  3 01:58:53 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Sun, 2 May 2004 19:58:53 -0400
Subject: [R] p-values
In-Reply-To: <975B1B9A-9998-11D8-BD27-000A95CDA0F2@anu.edu.au>
References: <200404281007.i3SA6eWm029623@hypatia.math.ethz.ch>
	<975B1B9A-9998-11D8-BD27-000A95CDA0F2@anu.edu.au>
Message-ID: <20040502195853.61718dc9.feh3k@spamcop.net>

On Thu, 29 Apr 2004 14:49:26 +1000
John Maindonald <john.maindonald at anu.edu.au> wrote:

> This is, of course, not strictly about R.  But if there should be
> a decision to pursue such matters on this list, then we'd need
> another list to which such discussion might be diverted.
> 
> I've pulled Frank's "Regression Modeling Stratregies" down
> from my shelf and looked to see what he says about
> inferential issues.  There is a suggestion, in the introduction,
> that modeling provides the groundwork that can be used a
> point of departure for a variety of inferential interpretations.
> As far as I can see Bayesian interpretations are never
> really explicitly discussed, though the word Bayesian does
> appear in a couple of places in the text.  Frank, do you now
> have ideas on how you would (perhaps, in a future edition,
> will) push the discussion in a more overtly Bayesian direction?
> What might be the style of a modeling book, aimed at practical
> data analysts who of necessity must (mostly, at least) use
> off-the-shelf software, that "seriously entertains" the Bayesian
> approach?

I'm sorry to have taken so long in responding to your excellent question
John.  And I'm responding to r-help since the question was posed there
before taking the discussion offline.  

In the words of Don Berry "It takes time to be a Bayesian" and that's the
main reason there are no explicit Bayesian calculations in the book.  I do
make a lot of use of prior information though.  In the future I could see
making some additions to the book along the lines of inclusion of examples
using the MCMCpack package, whose design is appealing to me.

> 
> R provides a lot of help for those who want a frequentist
> interpretation, even to including by default the *, **, ***
> labeling that some of us deplore.  There is no similar help
> for those who want at least the opportunity to place the
> output from a modeling exercise in a Bayesian context of
> some description.  There is surely a strong argument for
> the use of a more neutral form of default output, even to
> the excluding of p-values, on the argument that they also
> push too strongly in the direction of a frequentist
> interpretative framework.

Agreed.  I do try to approximate the Bayesian approach with the bootstrap.

> 
> There seems, unfortunately, to be a dearth of good ideas
> on how the assist the placing of output from modeling
> functions such as R provides in an explicitly Bayesian
> framework.  Or is it, at least in part, that I am unaware of
> what is out there? That, I guess, is the point of my
> question to Frank.  Is it just too technically demanding
> to go much beyond trying to get users to understand
> that a Bayesian credible interval can, if there is an
> informative prior, be very different from a frequentist CI,
> that they really do need to pause if there is an
> informative prior lurking somewhere in the undergrowth?

It's all worth pursuing.  I wish there were already a Bayesian package
that made use of Bayesian methods irresistable.

All the best,

Frank

> 
> John Maindonald.
> 
> Frank Harrell wrote:
> 
> > They [p-values] are objective only in the sense that
> > subjectivity is deferred in a difficult to document way
> > when P-values are translated into decisions.
> 
> 
> > The statement that frequentist methods are the norm, which I'm
> > afraid is usually true, is a sad comment on the state of much
> > of "scientific" inquiry.  IMHO P-values are so defective that
> > the imperfect Bayesian approach should be seriously entertained.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Bioinformation Science, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html


---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From pav at uga.edu  Mon May  3 02:04:20 2004
From: pav at uga.edu (Stephen Pavlik)
Date: Sun, 2 May 2004 20:04:20 -0400
Subject: [R] Help making a simple R code only package
Message-ID: <000001c430a2$31f595f0$0200a8c0@LAPTOP>

Hello,
I am new to R and I am trying to figure out how to build and install a
package with nothing but R code inside. I have run 'package.skeleton' to
get the basic structure. 

When I run 'Rcmd INSTALL testPackage' I get this error message:

make: *** No rule to make target `Files/R/rw1080'.  Stop.
*** Installation of testPackage failed ***


When I run 'Rcmd build testPackage' I get this error message:

C:\Program Files\R\rw1080>Rcmd build testPackage
* checking for file ' testPackage /DESCRIPTION' ... OK
* preparing ' testPackage ':
* cleaning src
* checking whether 'INDEX' is up-to-date ... OK
* removing junk files
* building ' testPackage_1.0.tar.gz'
tar: Files/R/rw1080/ testPackage_1.0.tar: Cannot stat: No such file or
directory
tar: Error exit delayed from previous errors
tar: Files/R/rw1080/ testPackage_1.0.tar: Not found in archive
tar: Error exit delayed from previous errors
tar: Files/R/rw1080/ testPackage_1.0.tar: Cannot stat: No such file or
directory
tar: testPackage: Cannot stat: No such file or directory
tar: Error exit delayed from previous errors
testPackage_1.0.tar: No such file or directory

This is on a Windows machine running XP Pro and R version 1080.

I sure would appreciate some help. I have read the manual but I don't
understand much of what is being discussed.

Stephen



From jasont at indigoindustrial.co.nz  Mon May  3 02:24:03 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 03 May 2004 12:24:03 +1200
Subject: [R] Help making a simple R code only package
In-Reply-To: <000001c430a2$31f595f0$0200a8c0@LAPTOP>
References: <000001c430a2$31f595f0$0200a8c0@LAPTOP>
Message-ID: <40959123.4070702@indigoindustrial.co.nz>

Stephen Pavlik wrote:
> Hello,
> I am new to R and I am trying to figure out how to build and install a
> package with nothing but R code inside. I have run 'package.skeleton' to
> get the basic structure. 
> 
> When I run 'Rcmd INSTALL testPackage' I get this error message:
> 
> make: *** No rule to make target `Files/R/rw1080'.  Stop.
> *** Installation of testPackage failed ***
> 

Spaces aren't allowed in the directory where you're building the 
package.  Create a separate directory with no spaces in the name, and 
build there (e.g. c:\MyPackages\...).  It says so in README.packages.

Interestingly, you missed this appearing on the list by about 12 hours.

Cheers

Jason



From christianlederer at t-online.de  Mon May  3 04:33:12 2004
From: christianlederer at t-online.de (Christian Lederer)
Date: Mon, 03 May 2004 04:33:12 +0200
Subject: [R] Build problems on Linux SuSE 9.1
Message-ID: <4095AF68.2030804@t-online.de>


Hi,

did anybody succeed in building R on SuSE Linux 9.1?
My compilation failed with the following error messages:

make[4]: Entering directory `/home/lederer/Source/R-1.9.0/src/modules/X11'
gcc -I. -I../../../src/include -I../../../src/include 
-I/usr/X11R6/include -I/us
r/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES -mieee-fp -fPIC  -g 
-O2 -c d
ataentry.c -o dataentry.lo
In file included from dataentry.c:31:
/usr/X11R6/include/X11/Xlib.h:1400: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1488: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:1516: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1520: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:1542: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1577: error: parse error before '*' token
/usr/X11R6/include/X11/Xlib.h:1586: error: parse error before "_Xconst"
...
lots more
...
dataentry.c: In function `GetKey':
dataentry.c:1272: warning: passing arg 4 of `XLookupString' from 
incompatible po
inter type
dataentry.c: In function `GetCharP':
dataentry.c:1281: warning: passing arg 4 of `XLookupString' from 
incompatible po
inter type
dataentry.c: In function `doControl':
dataentry.c:1302: warning: passing arg 4 of `XLookupString' from 
incompatible po
inter type
make[4]: *** [dataentry.lo] Fehler 1
make[4]: Leaving directory `/home/lederer/Source/R-1.9.0/src/modules/X11'
make[3]: *** [R] Fehler 2
make[3]: Leaving directory `/home/lederer/Source/R-1.9.0/src/modules/X11'
make[2]: *** [R] Fehler 1
make[2]: Leaving directory `/home/lederer/Source/R-1.9.0/src/modules'
make[1]: *** [R] Fehler 1
make[1]: Leaving directory `/home/lederer/Source/R-1.9.0/src'
make: *** [R] Fehler 1

The same happened for R-1.8.1.
However, i cannot believe that SuSE 9.1 contains faulty Xlib.h,
since i can compile other programs including this file.
Fortunetely i could install the rpm for SuSE 9.0.

Christian :-(



From ksm32 at student.canterbury.ac.nz  Mon May  3 03:39:52 2004
From: ksm32 at student.canterbury.ac.nz (Karla Meurk)
Date: Mon, 03 May 2004 13:39:52 +1200
Subject: [R] plotting in R
Message-ID: <4095A2E8.5040004@student.canterbury.ac.nz>

Hi there, I have 2 questions which I cannot find answers for in Dalgaard 
or the helpfiles currently available.

(1) I wish to plot 3 ecdf plots on one graph.  Is there any way of 
holding a figure to plot all on the same plot.  I can't get an ecdf for 
any plot command other than "plot" or "ecdf.plot" so using lower level 
command is no good, have also tried x11().

(2) If I have three curves on a plot how can I label each curve so the 
label sits directly above the curve?

Thanks

Carla



From john.maindonald at anu.edu.au  Mon May  3 03:52:00 2004
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 3 May 2004 11:52:00 +1000
Subject: [R] p-values
In-Reply-To: <20040502195853.61718dc9.feh3k@spamcop.net>
References: <200404281007.i3SA6eWm029623@hypatia.math.ethz.ch>
	<975B1B9A-9998-11D8-BD27-000A95CDA0F2@anu.edu.au>
	<20040502195853.61718dc9.feh3k@spamcop.net>
Message-ID: <7776435D-9CA4-11D8-BD27-000A95CDA0F2@anu.edu.au>

Frank -
Thanks for your reply, on which I really have no comment.

There are contexts where a Bayesian approach necessary,
natural and easy to handle, and can be used to broaden
the inferential vision of students.  Examples from HIV
testing and mammography screening in
Gigerenzer's book, sold in the USA under the title:
"Calculated Risks: How to Know When Numbers Deceive You"
(Simon & Schuster)
can be used to make highly important points.
I have, in the section on inference in my book with John Braun,
injected some of this into the discussion of inference.

[Incidentally, Frank's book does have a great deal of
practically oriented comment (e.g., wrt variable selection)
that I have found useful. There is useful critical comment
on inappropriate use of p-values in such contexts.]

John Maindonald.

On 3 May 2004, at 9:58 AM, Frank E Harrell Jr wrote:

....
> I'm sorry to have taken so long in responding to your excellent 
> question
> John.  And I'm responding to r-help since the question was posed there
> before taking the discussion offline.
>
> In the words of Don Berry "It takes time to be a Bayesian" and that's 
> the
> main reason there are no explicit Bayesian calculations in the book.  
> I do
> make a lot of use of prior information though.  In the future I could 
> see
> making some additions to the book along the lines of inclusion of 
> examples
> using the MCMCpack package, whose design is appealing to me.
>
>> R provides a lot of help for those who want a frequentist
>> interpretation, even to including by default the *, **, ***
>> labeling that some of us deplore.  There is no similar help
>> for those who want at least the opportunity to place the
>> output from a modeling exercise in a Bayesian context of
>> some description.  There is surely a strong argument for
>> the use of a more neutral form of default output, even to
>> the excluding of p-values, on the argument that they also
>> push too strongly in the direction of a frequentist
>> interpretative framework.
>
> Agreed.  I do try to approximate the Bayesian approach with the 
> bootstrap.
>
>>
>> There seems, unfortunately, to be a dearth of good ideas
>> on how the assist the placing of output from modeling
>> functions such as R provides in an explicitly Bayesian
>> framework.  . . . .
>
> It's all worth pursuing.  I wish there were already a Bayesian package
> that made use of Bayesian methods irresistable.
>
> All the best,
>
> Frank

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From jasont at indigoindustrial.co.nz  Mon May  3 03:55:22 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 03 May 2004 13:55:22 +1200
Subject: [R] plotting in R
In-Reply-To: <4095A2E8.5040004@student.canterbury.ac.nz>
References: <4095A2E8.5040004@student.canterbury.ac.nz>
Message-ID: <4095A68A.1080503@indigoindustrial.co.nz>

Karla Meurk wrote:

> Hi there, I have 2 questions which I cannot find answers for in Dalgaard 
> or the helpfiles currently available.
> 
> (1) I wish to plot 3 ecdf plots on one graph.  Is there any way of 
> holding a figure to plot all on the same plot.  I can't get an ecdf for 
> any plot command other than "plot" or "ecdf.plot" so using lower level 
> command is no good, have also tried x11().

Not familiar with plotting ecdf objects, but the following might be 
helpful...

a)  str() to find the structure of the ecdf object (if the help page for 
ecdf's "Value" section isn't clear enough), then use "lines" to put the 
lines on.

b) par(new=TRUE), before replotting, then plot(..., xaxt="n", yaxt="n") 
to prevent re-drawing the axes.

> (2) If I have three curves on a plot how can I label each curve so the 
> label sits directly above the curve?

?text.  To select where the text goes, you can work out the 
co-ordinates, or use mouse clicks, as in...

text(locator(1),"Curve 1")
text(locator(1),"Curve 2")
...

and click at the points you want the text.

Cheers

Jason



From hodgess at gator.uhd.edu  Mon May  3 07:20:23 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Mon, 3 May 2004 00:20:23 -0500
Subject: [R] EXTREMELY off topic
Message-ID: <200405030520.i435KNe25067@gator.dt.uh.edu>

Dear R People:

Someone in the group has a profound statement by Albert Einstein
in his or her signature set.

The statement is something like:  "make things as simple as possible,
but no simpler."

could you please send me the exact quote?
Thanks,
Erin
mailto: hodgess at gator.uhd.edu



From Detlef.Steuer at UniBw-Hamburg.DE  Mon May  3 07:57:03 2004
From: Detlef.Steuer at UniBw-Hamburg.DE (Detlef Steuer)
Date: Mon, 3 May 2004 07:57:03 +0200
Subject: [R] Build problems on Linux SuSE 9.1
In-Reply-To: <4095AF68.2030804@t-online.de>
References: <4095AF68.2030804@t-online.de>
Message-ID: <20040503075703.617e5704@gaia.unibw-hamburg.de>

Hi!

My copy of suse 9.1 is on its way, so I  expect rpms
by the end of the week. 
(If I can get past that error ... )

detlef


On Mon, 03 May 2004 04:33:12 +0200
christianlederer at t-online.de (Christian Lederer) wrote:

> 
> Hi,
> 
> did anybody succeed in building R on SuSE Linux 9.1?
> My compilation failed with the following error messages:
> 
> make[4]: Entering directory `/home/lederer/Source/R-1.9.0/src/modules/X11'
> gcc -I. -I../../../src/include -I../../../src/include 
> -I/usr/X11R6/include -I/us
> r/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES -mieee-fp -fPIC  -g 
> -O2 -c d
> ataentry.c -o dataentry.lo
> In file included from dataentry.c:31:
> /usr/X11R6/include/X11/Xlib.h:1400: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1488: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:1516: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1520: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:1542: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1577: error: parse error before '*' token
> /usr/X11R6/include/X11/Xlib.h:1586: error: parse error before "_Xconst"
> ...
> lots more
> ...
> dataentry.c: In function `GetKey':
> dataentry.c:1272: warning: passing arg 4 of `XLookupString' from 
> incompatible po
> inter type
> dataentry.c: In function `GetCharP':
> dataentry.c:1281: warning: passing arg 4 of `XLookupString' from 
> incompatible po
> inter type
> dataentry.c: In function `doControl':
> dataentry.c:1302: warning: passing arg 4 of `XLookupString' from 
> incompatible po
> inter type
> make[4]: *** [dataentry.lo] Fehler 1
> make[4]: Leaving directory `/home/lederer/Source/R-1.9.0/src/modules/X11'
> make[3]: *** [R] Fehler 2
> make[3]: Leaving directory `/home/lederer/Source/R-1.9.0/src/modules/X11'
> make[2]: *** [R] Fehler 1
> make[2]: Leaving directory `/home/lederer/Source/R-1.9.0/src/modules'
> make[1]: *** [R] Fehler 1
> make[1]: Leaving directory `/home/lederer/Source/R-1.9.0/src'
> make: *** [R] Fehler 1
> 
> The same happened for R-1.8.1.
> However, i cannot believe that SuSE 9.1 contains faulty Xlib.h,
> since i can compile other programs including this file.
> Fortunetely i could install the rpm for SuSE 9.0.
> 
> Christian :-(
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****



From ripley at stats.ox.ac.uk  Mon May  3 08:50:05 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 May 2004 07:50:05 +0100 (BST)
Subject: [R] Help making a simple R code only package
In-Reply-To: <40959123.4070702@indigoindustrial.co.nz>
Message-ID: <Pine.LNX.4.44.0405030748430.20295-100000@gannet.stats>

Also, less incidentally, it would have worked in the current version of R, 
but it seems 1.8.0 was used -- an update of R would be a good idea.

On Mon, 3 May 2004, Jason Turner wrote:

> Stephen Pavlik wrote:
> > Hello,
> > I am new to R and I am trying to figure out how to build and install a
> > package with nothing but R code inside. I have run 'package.skeleton' to
> > get the basic structure. 
> > 
> > When I run 'Rcmd INSTALL testPackage' I get this error message:
> > 
> > make: *** No rule to make target `Files/R/rw1080'.  Stop.
> > *** Installation of testPackage failed ***
> > 
> 
> Spaces aren't allowed in the directory where you're building the 
> package.  Create a separate directory with no spaces in the name, and 
> build there (e.g. c:\MyPackages\...).  It says so in README.packages.
> 
> Interestingly, you missed this appearing on the list by about 12 hours.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May  3 08:52:44 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 May 2004 07:52:44 +0100 (BST)
Subject: [R] Build problems on Linux SuSE 9.1
In-Reply-To: <4095AF68.2030804@t-online.de>
Message-ID: <Pine.LNX.4.44.0405030750280.20295-100000@gannet.stats>

It is the result of a bug in the XFree 4.4.0 headers.  Please try the
patched version r-patched (see the FAQ) where we have a workaround in
src/modules/X11/dataentry.c (and quite a few other bug fixes).

On Mon, 3 May 2004, Christian Lederer wrote:

> 
> Hi,
> 
> did anybody succeed in building R on SuSE Linux 9.1?
> My compilation failed with the following error messages:
> 
> make[4]: Entering directory `/home/lederer/Source/R-1.9.0/src/modules/X11'
> gcc -I. -I../../../src/include -I../../../src/include 
> -I/usr/X11R6/include -I/us
> r/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES -mieee-fp -fPIC  -g 
> -O2 -c d
> ataentry.c -o dataentry.lo
> In file included from dataentry.c:31:
> /usr/X11R6/include/X11/Xlib.h:1400: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1488: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:1516: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1520: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:1542: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1577: error: parse error before '*' token
> /usr/X11R6/include/X11/Xlib.h:1586: error: parse error before "_Xconst"
> ...
> lots more
> ...
> dataentry.c: In function `GetKey':
> dataentry.c:1272: warning: passing arg 4 of `XLookupString' from 
> incompatible po
> inter type
> dataentry.c: In function `GetCharP':
> dataentry.c:1281: warning: passing arg 4 of `XLookupString' from 
> incompatible po
> inter type
> dataentry.c: In function `doControl':
> dataentry.c:1302: warning: passing arg 4 of `XLookupString' from 
> incompatible po
> inter type
> make[4]: *** [dataentry.lo] Fehler 1
> make[4]: Leaving directory `/home/lederer/Source/R-1.9.0/src/modules/X11'
> make[3]: *** [R] Fehler 2
> make[3]: Leaving directory `/home/lederer/Source/R-1.9.0/src/modules/X11'
> make[2]: *** [R] Fehler 1
> make[2]: Leaving directory `/home/lederer/Source/R-1.9.0/src/modules'
> make[1]: *** [R] Fehler 1
> make[1]: Leaving directory `/home/lederer/Source/R-1.9.0/src'
> make: *** [R] Fehler 1
> 
> The same happened for R-1.8.1.
> However, i cannot believe that SuSE 9.1 contains faulty Xlib.h,
> since i can compile other programs including this file.
> Fortunetely i could install the rpm for SuSE 9.0.
> 
> Christian :-(
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Mon May  3 09:44:06 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 May 2004 09:44:06 +0200
Subject: [R] EXTREMELY off topic
In-Reply-To: <200405030520.i435KNe25067@gator.dt.uh.edu>
References: <200405030520.i435KNe25067@gator.dt.uh.edu>
Message-ID: <x2ad0qkla1.fsf@biostat.ku.dk>

Erin Hodgess <hodgess at gator.uhd.edu> writes:

> Dear R People:
> 
> Someone in the group has a profound statement by Albert Einstein
> in his or her signature set.
> 
> The statement is something like:  "make things as simple as possible,
> but no simpler."
> 
> could you please send me the exact quote?

QuoteDB and others have it as

"Make everything as simple as possible, but not simpler."
  --  Albert Einstein

(which you might easily have found via Google yourself...)

Not a word about context though...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From vaze0348 at uosis.mif.vu.lt  Mon May  3 10:03:10 2004
From: vaze0348 at uosis.mif.vu.lt (Mpiktas)
Date: Mon, 3 May 2004 11:03:10 +0300
Subject: [R] multinomial regresion, nls
Message-ID: <20040503080310.GA1442@debian.vu.lt>

Hi,

Does R have any functions implementing such multinomial regression:

(S_t^A,S_t^B)~MN(N_t-Y_{t-1},P_t^A,P_t^B)

where MN(n,p_1,p_2) is multinomial distribution with parameters n, p_1, p_2.
Here P_t^A and P_t^B are nonlinear functions from predictor variables and
parameters which need to be estimated.

Here A and B are used for notation, they are not parameters.

My second question is about nls capabilities. Can I use lagged response
variable in right side of formula specified in nls. Like this:

nls(y~a*f(B(y)),data=data,start=list(a=1))

where B is lag operator. Or should I just use lagged response variable as
predictor variable:

nls(y~a*f(x),data=data1,start=list(a=1))

data1<-data.frame(y=y,x=c(0,y[1:(length(y)-1)]))

here f is arbitrary function.

Thank you in advance for any answers.

Sincerely,

Vaidotas Zemlys

PS I'm resending this mail, since it seems that it didn't get through the  
first time. I am sorry, if you got 2 messages.



From david.netherway at adelaide.edu.au  Mon May  3 10:25:12 2004
From: david.netherway at adelaide.edu.au (David J. Netherway)
Date: Mon, 03 May 2004 17:55:12 +0930
Subject: [R] Setting up contrasts
Message-ID: <409601E8.4A7637B6@adelaide.edu.au>

I am using the following model:
lm <- lm(mydata[[variableName]] ~ Age + Gender + Group, data=mydata)

There are 5 groups in "Group": nonc (the control), c1,c2,c3 and c4.

How do I contrast nonc vs the others?

and

How do I contrast c1 vs other c's (ie c2,c3,c4 as a subgroup)?

I have looked at the contrasts option in lm and model.matrix and am
really none the wiser.
Though it looks like I need to read up on model matrices again.

Any help would be appreciated.

Thanks, David



From phgrosjean at sciviews.org  Mon May  3 10:22:25 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Mon, 3 May 2004 10:22:25 +0200
Subject: [R] PCA filtering
In-Reply-To: <40946527.40204@indigoindustrial.co.nz>
Message-ID: <MABBLJDICACNFOLGIHJOCEFIEGAA.phgrosjean@sciviews.org>

elkurdy at qp.com.qa wrote:
>
>
>
> Hi,
>
> Is there a function under R that does principal component analysis and
then
> use the selected eignevectors to filter the data and transform back to the
> original coordinates?
> If there isn't, can someone guide as to how to do this approach.
>
> Much appreciated.
>

You have such a function in the pastecs library. It is called decevf(), for
"decomposition with eigenvector filtering (EVF), which is a synonyme for PCA
filtering. Once you have installed pastecs package, issue:

> library(pastecs)
> ?decevf
> example(decevf)

as a starting point.
Best,

Philippe Grosjean

.......................................................<?}))><....
 ) ) ) ) )
( ( ( ( (   Prof. Philippe Grosjean
\  ___   )
 \/ECO\ (   Numerical Ecology of Aquatic Systems
 /\___/  )  Mons-Hainaut University, Pentagone
/ ___  /(   8, Av. du Champ de Mars, 7000 Mons, Belgium
 /NUM\/  )
 \___/\ (   phone: + 32.65.37.34.97, fax: + 32.65.37.33.12
       \ )  email: Philippe.Grosjean at umh.ac.be
 ) ) ) ) )  SciViews project coordinator (http://www.sciviews.org)
( ( ( ( (
...................................................................



From bxc at steno.dk  Mon May  3 10:42:42 2004
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Mon, 3 May 2004 10:42:42 +0200
Subject: [R] Setting up contrasts
Message-ID: <0ABD88905D18E347874E0FB71C0B29E90179E81C@exdkba022.novo.dk>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of David 
> J. Netherway
> Sent: Monday, May 03, 2004 10:25 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Setting up contrasts
> 
> 
> I am using the following model:
> lm <- lm(mydata[[variableName]] ~ Age + Gender + Group, data=mydata)
> 
> There are 5 groups in "Group": nonc (the control), c1,c2,c3 and c4.
> 
> How do I contrast nonc vs the others?

"nonc" will be the reference if you use treatment contrasts (the
default).

> 
> and
> 
> How do I contrast c1 vs other c's (ie c2,c3,c4 as a subgroup)?

In the second case you just replace:

Group

with

relevel( Group, "c1" )

--- see the help page for "relevel".

Try for example:

table( Group, relevel( Group, "c1" ) )
table( Group, relevel( Group, 2 ) )

to see the mechanics of it.

Bendix Carstensen
----------------------
Bendix Carstensen
Senior Statistician
Steno Diabetes Center
Niels Steensens Vej 2
DK-2820 Gentofte
Denmark
tel: +45 44 43 87 38
mob: +45 30 75 87 38
fax: +45 44 43 07 06
bxc at steno.dk
www.biostat.ku.dk/~bxc
----------------------
> 
> I have looked at the contrasts option in lm and model.matrix 
> and am really none the wiser. Though it looks like I need to 
> read up on model matrices again.
> 
> Any help would be appreciated.
> 
> Thanks, David
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From giampi at speech.kth.se  Mon May  3 11:50:38 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Mon, 3 May 2004 11:50:38 +0200 (CEST)
Subject: [R] adding a method to the dist function
Message-ID: <Pine.LNX.4.58.0405031138570.8862@bayes.speech.kth.se>

Hi all,
I'd like to add the Bhattacharyya method to the dist function.
What is the best way to do this? I'm using R 1.9.0 and I was looking
for the code that defines the already existing distances, but I didn't
manage. As far as I understand, dist is defined in mva that is part
of the stats package now, but where is the code?

Thank you very much,
Giampiero



From ripley at stats.ox.ac.uk  Mon May  3 12:16:25 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 May 2004 11:16:25 +0100 (BST)
Subject: [R] adding a method to the dist function
In-Reply-To: <Pine.LNX.4.58.0405031138570.8862@bayes.speech.kth.se>
Message-ID: <Pine.LNX.4.44.0405031106070.25642-100000@gannet.stats>

On Mon, 3 May 2004, Giampiero Salvi wrote:

> Hi all,
> I'd like to add the Bhattacharyya method to the dist function.
> What is the best way to do this? I'm using R 1.9.0 and I was looking
> for the code that defines the already existing distances, but I didn't
> manage. As far as I understand, dist is defined in mva that is part
> of the stats package now, but where is the code?

In src/library/stats/src/distance.c

Where else did you think the C source code for the stats package would be
but src/library/stats/src?

You will need to add your own function, and BTW, I don't think `the 
Bhattacharyya method' is appropriate for dist, as it is defined for 
distributions, not data items.  It's even defined that way in your own 
paper

http://www.speech.kth.se/ctt/publications/papers03/icphs03_giampi.pdf

although you make Gaussian assumptions about the distributions whihc you 
did not in your posting.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Mon May  3 12:21:47 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 May 2004 12:21:47 +0200
Subject: [R] Least Squares Fit
In-Reply-To: <20040502111010.GA20854@psych>
References: <20040502102641.87598.qmail@web20503.mail.yahoo.com>
	<20040502111010.GA20854@psych>
Message-ID: <16534.7483.243268.790775@gargle.gargle.HOWL>

>>>>> "Jon" == Jonathan Baron <baron at psych.upenn.edu>
>>>>>     on Sun, 2 May 2004 07:10:10 -0400 writes:

    Jon> On 05/02/04 03:26, Fred J. wrote:
    >> Hello
    >> 
    >> I need to plot the least squares fit and get the slope of
    >> the line that best fit the data. after reading lm and
    >> lsfit, since not being able to understand the use of the
    >> second argument "y" for the lsfit, I am giving the lm a
    >> go, but know not why the code below does not draw the
    >> line on the plot. e.g. well.. why -50 Intercept?  thanks
    >> 
    >> x <- 1:10; y <- x+50
    >> plot(x,y)
    >> z <- lm(as.data.frame(cbind(x,y))))
    >> abline(z)
    >> 
    >>> z$coefficients
    >> (Intercept)           y
    >> -50           1

Did you, "Fred J.",  really ever take time to read the
"Introduction to R", maybe with a pencil in your hand to mark a
few things?


    Jon> The lm() is predicting x from y, and plot() is plotting
    Jon> y as a function of x.

    Jon> Try 
    Jon> plot(x,y) 
    Jon> abline(lm(y~x))

or in this case, the more intuitive

     plot(y ~ x)
abline(lm(y ~ x))

y ~ x  : `` y is modeled by (predictor) x ''

--
Martin



From maechler at stat.math.ethz.ch  Mon May  3 12:34:51 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 May 2004 12:34:51 +0200
Subject: [R] adding a method to the dist function
In-Reply-To: <Pine.LNX.4.58.0405031138570.8862@bayes.speech.kth.se>
References: <Pine.LNX.4.58.0405031138570.8862@bayes.speech.kth.se>
Message-ID: <16534.8267.822097.658316@gargle.gargle.HOWL>

>>>>> "Giampiero" == Giampiero Salvi <giampi at speech.kth.se>
>>>>>     on Mon, 3 May 2004 11:50:38 +0200 (CEST) writes:

    Giampiero> I'd like to add the Bhattacharyya method to the
    Giampiero> dist function.  What is the best way to do this?
    Giampiero> I'm using R 1.9.0 and I was looking for the code
    Giampiero> that defines the already existing distances, but
    Giampiero> I didn't manage. As far as I understand, dist is
    Giampiero> defined in mva that is part of the stats package
    Giampiero> now, but where is the code?

All the standard R packages (such as "stats") are in
 <Rsource>/src/library/
and look very much like usual R packages,
[with the exception of the 'base' package that is very special]

I.e, in

    <Rsource>/src/library/stats/R/dist.R
    <Rsource>/src/library/stats/man/dist.Rd
    <Rsource>/src/library/stats/src/distance.c

are the R source, docu, and C code, respectively.
Where you can e.g. take and unpack 
      ftp://stat.ethz.ch/Software/R/R-devel.tar.gz
such that the above '<Rsource>' will be  'R-devel' for you.

If you do this, please consider contributing the three changed
files back to the R project!


    Giampiero> Thank you very much,
    Giampiero> Giampiero

you're welcome,
Martin



From giampi at speech.kth.se  Mon May  3 13:00:48 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Mon, 3 May 2004 13:00:48 +0200 (CEST)
Subject: [R] adding a method to the dist function
In-Reply-To: <Pine.LNX.4.44.0405031106070.25642-100000@gannet.stats>
References: <Pine.LNX.4.44.0405031106070.25642-100000@gannet.stats>
Message-ID: <Pine.LNX.4.58.0405031253410.8862@bayes.speech.kth.se>

On Mon, 3 May 2004, Prof Brian Ripley wrote:

> On Mon, 3 May 2004, Giampiero Salvi wrote:
>
> > Hi all,
> > I'd like to add the Bhattacharyya method to the dist function.
> > What is the best way to do this? I'm using R 1.9.0 and I was looking
> > for the code that defines the already existing distances, but I didn't
> > manage. As far as I understand, dist is defined in mva that is part
> > of the stats package now, but where is the code?
>
> In src/library/stats/src/distance.c
>
> Where else did you think the C source code for the stats package would be
> but src/library/stats/src?

Sorry,
I was looking in the installation directory that of course
didn't have a src dir...

> You will need to add your own function, and BTW, I don't think `the
> Bhattacharyya method' is appropriate for dist, as it is defined for
> distributions, not data items.  It's even defined that way in your own
> paper

I also had the same doubt. My intension was to interpret the data matrix
as composed by vectors of means and covariances, but I did suspect that
this would generate some confusion. Do you have any suggestions on where
this method better belongs?

Thank you again,
Giampiero



From ripley at stats.ox.ac.uk  Mon May  3 13:05:21 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 May 2004 12:05:21 +0100 (BST)
Subject: [R] adding a method to the dist function
In-Reply-To: <Pine.LNX.4.58.0405031253410.8862@bayes.speech.kth.se>
Message-ID: <Pine.LNX.4.44.0405031202490.25987-100000@gannet.stats>

On Mon, 3 May 2004, Giampiero Salvi wrote:

> On Mon, 3 May 2004, Prof Brian Ripley wrote:
> 
> > On Mon, 3 May 2004, Giampiero Salvi wrote:
> >
> > > Hi all,
> > > I'd like to add the Bhattacharyya method to the dist function.
> > > What is the best way to do this? I'm using R 1.9.0 and I was looking
> > > for the code that defines the already existing distances, but I didn't
> > > manage. As far as I understand, dist is defined in mva that is part
> > > of the stats package now, but where is the code?
> >
> > In src/library/stats/src/distance.c
> >
> > Where else did you think the C source code for the stats package would be
> > but src/library/stats/src?
> 
> Sorry,
> I was looking in the installation directory that of course
> didn't have a src dir...
> 
> > You will need to add your own function, and BTW, I don't think `the
> > Bhattacharyya method' is appropriate for dist, as it is defined for
> > distributions, not data items.  It's even defined that way in your own
> > paper
> 
> I also had the same doubt. My intension was to interpret the data matrix
> as composed by vectors of means and covariances, but I did suspect that
> this would generate some confusion. Do you have any suggestions on where
> this method better belongs?

dist() compares pairs of rows in the x matrix.  How can they have `means 
and covariances'? -- you have a sample of size one from each of two 
populations.

It seems that (Gaussian) Bhattacharyya is more like mahalanobis().

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From giampi at speech.kth.se  Mon May  3 14:01:23 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Mon, 3 May 2004 14:01:23 +0200 (CEST)
Subject: [R] adding a method to the dist function
In-Reply-To: <Pine.LNX.4.44.0405031202490.25987-100000@gannet.stats>
References: <Pine.LNX.4.44.0405031202490.25987-100000@gannet.stats>
Message-ID: <Pine.LNX.4.58.0405031317290.8862@bayes.speech.kth.se>

On Mon, 3 May 2004, Prof Brian Ripley wrote:

> dist() compares pairs of rows in the x matrix.  How can they have `means
> and covariances'? -- you have a sample of size one from each of two
> populations.
>
> It seems that (Gaussian) Bhattacharyya is more like mahalanobis().

I had planned to use mean vectors and covariance matrices I computed
over N groups of data samples as input to dist, like this

mu_1_1 mu_1_2 ... mu_1_M cov_1_1_1 cov_1_1_2 ... cov_1_M_M
mu_2_1 mu_2_2 ... mu_2_M cov_2_1_1 cov_2_1_2 ... cov_2_M_M
...
mu_N_1 mu_N_2 ... mu_N_M cov_N_1_1 cov_N_1_2 ... cov_N_M_M

where N is the number of groups and M the dimension.

I agree that it would be better to use a new function (similar to
mahalanobis), as the function dist in all the other cases uses raw
data samples, and my interpretation of the input data might be
confusing. The reason why I though of dist is that bhattacharyya is
a symmetrical distance, and the result fits well the dist class.

One way to solve this, if you agree, would be to write a new function
bhattacharyya() that returns a dist object.

Giampiero



From cristian at biometria.univr.it  Mon May  3 14:13:46 2004
From: cristian at biometria.univr.it (Cristian Pattaro)
Date: Mon, 03 May 2004 14:13:46 +0200
Subject: [R] Multinomial Logistic Models
Message-ID: <4096377A.70406@biometria.univr.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040503/3e5335aa/attachment.pl

From ripley at stats.ox.ac.uk  Mon May  3 14:09:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 May 2004 13:09:55 +0100 (BST)
Subject: [R] adding a method to the dist function
In-Reply-To: <Pine.LNX.4.58.0405031317290.8862@bayes.speech.kth.se>
Message-ID: <Pine.LNX.4.44.0405031308310.26250-100000@gannet.stats>

On Mon, 3 May 2004, Giampiero Salvi wrote:

> On Mon, 3 May 2004, Prof Brian Ripley wrote:
> 
> > dist() compares pairs of rows in the x matrix.  How can they have `means
> > and covariances'? -- you have a sample of size one from each of two
> > populations.
> >
> > It seems that (Gaussian) Bhattacharyya is more like mahalanobis().
> 
> I had planned to use mean vectors and covariance matrices I computed
> over N groups of data samples as input to dist, like this
> 
> mu_1_1 mu_1_2 ... mu_1_M cov_1_1_1 cov_1_1_2 ... cov_1_M_M
> mu_2_1 mu_2_2 ... mu_2_M cov_2_1_1 cov_2_1_2 ... cov_2_M_M
> ...
> mu_N_1 mu_N_2 ... mu_N_M cov_N_1_1 cov_N_1_2 ... cov_N_M_M
> 
> where N is the number of groups and M the dimension.
> 
> I agree that it would be better to use a new function (similar to
> mahalanobis), as the function dist in all the other cases uses raw
> data samples, and my interpretation of the input data might be
> confusing. The reason why I though of dist is that bhattacharyya is
> a symmetrical distance, and the result fits well the dist class.
> 
> One way to solve this, if you agree, would be to write a new function
> bhattacharyya() that returns a dist object.

So you would be computing distances for groups of rows.  That needs a 
different interface from dist().

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May  3 14:19:47 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 May 2004 13:19:47 +0100 (BST)
Subject: [R] Multinomial Logistic Models
In-Reply-To: <4096377A.70406@biometria.univr.it>
Message-ID: <Pine.LNX.4.44.0405031316200.26297-100000@gannet.stats>

On Mon, 3 May 2004, Cristian Pattaro wrote:

> Are there any *R* command for fitting multinomial logistic regression 
> models?

Yes.  help.search("multinomial") will lead you there (if I understand what
you mean by the term `multinomial logistic' which strictly a
contradiction).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Mon May  3 14:21:09 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 May 2004 14:21:09 +0200
Subject: [R] adding a method to the dist function
In-Reply-To: <Pine.LNX.4.58.0405031317290.8862@bayes.speech.kth.se>
References: <Pine.LNX.4.44.0405031202490.25987-100000@gannet.stats>
	<Pine.LNX.4.58.0405031317290.8862@bayes.speech.kth.se>
Message-ID: <16534.14645.552627.120943@gargle.gargle.HOWL>

>>>>> "Giampiero" == Giampiero Salvi <giampi at speech.kth.se>
>>>>>     on Mon, 3 May 2004 14:01:23 +0200 (CEST) writes:

      ...................

    Giampiero> I agree that it would be better to use a new
    Giampiero> function (similar to mahalanobis), as the
    Giampiero> function dist in all the other cases uses raw
    Giampiero> data samples, and my interpretation of the input
    Giampiero> data might be confusing. The reason why I though
    Giampiero> of dist is that bhattacharyya is a symmetrical
    Giampiero> distance, and the result fits well the dist
    Giampiero> class.

    Giampiero> One way to solve this, if you agree, would be to
    Giampiero> write a new function bhattacharyya() that returns
    Giampiero> a dist object.

That sounds like a good idea (returning a "dist" object).
Do consider also setting the '$ method' component (e.g. to
"bhattacharyaa" or even something more specific) in the result.
Note that the help page for 'dist' has had a typo, calling the
component 'methods' instead of 'method'.

Martin



From giampi at speech.kth.se  Mon May  3 14:20:55 2004
From: giampi at speech.kth.se (Giampiero Salvi)
Date: Mon, 3 May 2004 14:20:55 +0200 (CEST)
Subject: [R] adding a method to the dist function
In-Reply-To: <Pine.LNX.4.44.0405031308310.26250-100000@gannet.stats>
References: <Pine.LNX.4.44.0405031308310.26250-100000@gannet.stats>
Message-ID: <Pine.LNX.4.58.0405031410150.8862@bayes.speech.kth.se>

On Mon, 3 May 2004, Prof Brian Ripley wrote:

> On Mon, 3 May 2004, Giampiero Salvi wrote:
>
> > On Mon, 3 May 2004, Prof Brian Ripley wrote:
> >
> > > dist() compares pairs of rows in the x matrix.  How can they have `means
> > > and covariances'? -- you have a sample of size one from each of two
> > > populations.
> > >
> > > It seems that (Gaussian) Bhattacharyya is more like mahalanobis().
> >
> > I had planned to use mean vectors and covariance matrices I computed
> > over N groups of data samples as input to dist, like this
> >
> > mu_1_1 mu_1_2 ... mu_1_M cov_1_1_1 cov_1_1_2 ... cov_1_M_M
> > mu_2_1 mu_2_2 ... mu_2_M cov_2_1_1 cov_2_1_2 ... cov_2_M_M
> > ...
> > mu_N_1 mu_N_2 ... mu_N_M cov_N_1_1 cov_N_1_2 ... cov_N_M_M
> >
> > where N is the number of groups and M the dimension.
> >
> > I agree that it would be better to use a new function (similar to
> > mahalanobis), as the function dist in all the other cases uses raw
> > data samples, and my interpretation of the input data might be
> > confusing. The reason why I though of dist is that bhattacharyya is
> > a symmetrical distance, and the result fits well the dist class.
> >
> > One way to solve this, if you agree, would be to write a new function
> > bhattacharyya() that returns a dist object.
>
> So you would be computing distances for groups of rows.  That needs a
> different interface from dist().

What I meant is that I compute the means and covaraiances before I use
dist. Then I compute the distance between every row with the same interface
as in the current dist. The whole point is that each row in my case does not
represent a data point, but already a mean vector (and covariance matrix) over
a number of data points.

A difference with mahalanobis is that mahalanobis computes the distance
between a data point (or a number of data points) and a distribution, while
bhattacharyya computes the distance between pairs of distributions (in this
respect it is closer to dist in the sense that the two objects involved in
the computation are of the same kind).

Giampiero

>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From apierce at stny.rr.com  Mon May  3 14:27:47 2004
From: apierce at stny.rr.com (Andy Pierce)
Date: Mon, 03 May 2004 08:27:47 -0400
Subject: [R] R 1.9.0 on AIX, 64-bit
Message-ID: <40963AC3.1000702@stny.rr.com>

I'm trying to get R 1.9.0 running on AIX 5.1 with the standard AIX 
compilers (xlc, xlf) and it is failing 2 of the tests,
test-Reg in reg-tests-1.R like this:

bash-2.05b$ tail -30 reg-tests-1.Rout.fail
      [,1] [,2]
[1,] 1    3
[2,] 2    4
[3,] 1    3
[4,] 2    4
 > stopifnot(typeof(res) == "list")
 > ## were not implemented in 1.8.1
 >
 >
 > ## Date objects with NA's
 > (t1 <- strptime(c("6. Aug. 1930", "3. Nov. 1925", "28. Mar. 1959",
+                  NA, paste(1:29," Feb. 1960", sep=".")),
+                format = "%d. %b. %Y"))
  [1] "1930-08-06" "1925-11-03" "1959-03-28" NA           "1960-02-01"
  [6] "1960-02-02" "1960-02-03" "1960-02-04" "1960-02-05" "1960-02-06"
[11] "1960-02-07" "1960-02-08" "1960-02-09" "1960-02-10" "1960-02-11"
[16] "1960-02-12" "1960-02-13" "1960-02-14" "1960-02-15" "1960-02-16"
[21] "1960-02-17" "1960-02-18" "1960-02-19" "1960-02-20" "1960-02-21"
[26] "1960-02-22" "1960-02-23" "1960-02-24" "1960-02-25" "1960-02-26"
[31] "1960-02-27" "1960-02-28" "1960-02-29"
 > stopifnot(6 == length(print(s1 <- summary(t1))),
+           s1== summary(as.POSIXct(t1)),
+           6 == length(print(format(as.Date(s1)))) )
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
      NA      NA      NA      NA      NA      NA
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
      NA      NA      NA      NA      NA      NA
Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r))) 
stop(paste(deparse(mc[[i +  :
         missing value where TRUE/FALSE needed
Execution halted

and also in base-Ex.R like this:

bash-2.05b$ tail base-Ex.Rout.fail
 > ### Title: Generate Regular Sequences of Dates
 > ### Aliases: seq.Date
 > ### Keywords: manip chron
 >
 > ### ** Examples
 >
 > ## first days of years
 > seq(as.Date("1910/1/1"), as.Date("1999/1/1"), "years")
Error in fromchar(x) : character string is not in a standard unambiguous 
format
Execution halted

Does anyone have any ideas on how to fix this?

Andy Pierce



From ripley at stats.ox.ac.uk  Mon May  3 14:58:02 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 May 2004 13:58:02 +0100 (BST)
Subject: [R] R 1.9.0 on AIX, 64-bit
In-Reply-To: <40963AC3.1000702@stny.rr.com>
Message-ID: <Pine.LNX.4.44.0405031352410.26348-100000@gannet.stats>

The second (at least) looks like a broken strptime.  Try undefining
HAVE_WORKING_STRPTIME in src/include/config.h and recompiling.

Unfortunately, it could also be a broken mktime.

On Mon, 3 May 2004, Andy Pierce wrote:

> I'm trying to get R 1.9.0 running on AIX 5.1 with the standard AIX 
> compilers (xlc, xlf) and it is failing 2 of the tests,
> test-Reg in reg-tests-1.R like this:
> 
> bash-2.05b$ tail -30 reg-tests-1.Rout.fail
>       [,1] [,2]
> [1,] 1    3
> [2,] 2    4
> [3,] 1    3
> [4,] 2    4
>  > stopifnot(typeof(res) == "list")
>  > ## were not implemented in 1.8.1
>  >
>  >
>  > ## Date objects with NA's
>  > (t1 <- strptime(c("6. Aug. 1930", "3. Nov. 1925", "28. Mar. 1959",
> +                  NA, paste(1:29," Feb. 1960", sep=".")),
> +                format = "%d. %b. %Y"))
>   [1] "1930-08-06" "1925-11-03" "1959-03-28" NA           "1960-02-01"
>   [6] "1960-02-02" "1960-02-03" "1960-02-04" "1960-02-05" "1960-02-06"
> [11] "1960-02-07" "1960-02-08" "1960-02-09" "1960-02-10" "1960-02-11"
> [16] "1960-02-12" "1960-02-13" "1960-02-14" "1960-02-15" "1960-02-16"
> [21] "1960-02-17" "1960-02-18" "1960-02-19" "1960-02-20" "1960-02-21"
> [26] "1960-02-22" "1960-02-23" "1960-02-24" "1960-02-25" "1960-02-26"
> [31] "1960-02-27" "1960-02-28" "1960-02-29"
>  > stopifnot(6 == length(print(s1 <- summary(t1))),
> +           s1== summary(as.POSIXct(t1)),
> +           6 == length(print(format(as.Date(s1)))) )
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>       NA      NA      NA      NA      NA      NA
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>       NA      NA      NA      NA      NA      NA
> Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r))) 
> stop(paste(deparse(mc[[i +  :
>          missing value where TRUE/FALSE needed
> Execution halted
> 
> and also in base-Ex.R like this:
> 
> bash-2.05b$ tail base-Ex.Rout.fail
>  > ### Title: Generate Regular Sequences of Dates
>  > ### Aliases: seq.Date
>  > ### Keywords: manip chron
>  >
>  > ### ** Examples
>  >
>  > ## first days of years
>  > seq(as.Date("1910/1/1"), as.Date("1999/1/1"), "years")
> Error in fromchar(x) : character string is not in a standard unambiguous 
> format
> Execution halted
> 
> Does anyone have any ideas on how to fix this?
> 
> Andy Pierce
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From prechelt at pcpool.mi.fu-berlin.de  Mon May  3 16:36:14 2004
From: prechelt at pcpool.mi.fu-berlin.de (Lutz Prechelt)
Date: Mon, 3 May 2004 16:36:14 +0200
Subject: [R] Lattice: finding out xlim within panel function
Message-ID: <85D25331FFB7AE4C900EA467D4ADA392045913@circle.pcpool.mi.fu-berlin.de>

Dear Lattice bit-meddlers,

while within a panel function for xyplot, how can I 
find out the values of (effectively) xlim and
ylim -- no matter whether they have been set
explicitly or chosen by Lattice itself?

I have just tried for an hour to find out, 
with no success whatsoever.
I looked in Grid for something that would
return such data, but got lost.
I looked at tracebacks of panel calls, but
couldn't see the forest for the trees.

Lonely, sad, and crying...
;-)

  Lutz

Prof. Dr. Lutz Prechelt;  prechelt at inf.fu-berlin.de
Institut fuer Informatik; Freie Universitaet Berlin
Takustr. 9; 14195 Berlin; Germany
+49 30 838 75115; http://www.inf.fu-berlin.de/inst/ag-se/



From wolski at molgen.mpg.de  Mon May  3 17:27:45 2004
From: wolski at molgen.mpg.de (wolski)
Date: Mon, 03 May 2004 17:27:45 +0200
Subject: [R] ./configure on SunOS does not run to completion
Message-ID: <200405031727450487.621D40B2@harry.molgen.mpg.de>

OS:
SunOS human 5.9 Generic_112233-12 sun4u sparc SUNW,Sun-Fire-480R


I run
./configure --prefix=/non/standard/path
...

and it stops at the line
checking for xmkmf... /usr/openwin/bin/xmkmf


Sincerely Eryk



From deepayan at stat.wisc.edu  Mon May  3 17:44:20 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 3 May 2004 10:44:20 -0500
Subject: [R] Lattice: finding out xlim within panel function
In-Reply-To: <85D25331FFB7AE4C900EA467D4ADA392045913@circle.pcpool.mi.fu-berlin.de>
References: <85D25331FFB7AE4C900EA467D4ADA392045913@circle.pcpool.mi.fu-berlin.de>
Message-ID: <200405031044.20497.deepayan@stat.wisc.edu>

On Monday 03 May 2004 09:36, Lutz Prechelt wrote:
> Dear Lattice bit-meddlers,
>
> while within a panel function for xyplot, how can I
> find out the values of (effectively) xlim and
> ylim -- no matter whether they have been set
> explicitly or chosen by Lattice itself?
>
> I have just tried for an hour to find out,
> with no success whatsoever.
> I looked in Grid for something that would
> return such data, but got lost.
> I looked at tracebacks of panel calls, but
> couldn't see the forest for the trees.

Not surprising, since there's no documented way to do this. You could 
try something along these lines, but this exact construct is not 
guaranteed to work in future versions of grid:

panel = function(...) {
    cvp = grid::current.viewport() 
    print(cvp$xscale)
    print(cvp$yscale)
}

Deepayan



From rvaradha at jhsph.edu  Mon May  3 18:12:58 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Mon, 03 May 2004 12:12:58 -0400
Subject: [R] numericDeriv
Message-ID: <52f73552be9d.52be9d52f735@jhsph.edu>

Hi All:

Along the lines of this thread, I was wondering about the usefulness of 
putting together a package for numerical differentiation, to perform 
tasks such as gradient, jacobian, and hessian calculations for exact 
functions, as well as for noisy functions (via some type of smoothing). 
Based on finite difference calculus, I have written a number of 
(simple) R functions for gradient, jacobian, and hessian computations 
of different orders of accuracy.  If such functions aren't already 
available, I could supply these to whoever may be interested in 
undertaking this project. 

Best,
Ravi.


----- Original Message -----
From: Paul Gilbert <pgilbert at bank-banque-canada.ca>
Date: Friday, April 30, 2004 2:19 pm
Subject: Re: [R] numericDeriv

> Jean Eid wrote:
> 
> >Dear All,
> >I am trying to solve a Generalized Method of Moments problem which
> >necessitate the gradient of moments computation to get the
> >standard  errors of estimates.
> >I know optim does not output the gradient, but I can use 
> numericDeriv to
> >get that. My question is: is this the best function to do this?
> >  
> >
> 'Best' depends on what you want. If you want an accurate numerical 
> estimate of the gradient then you might look at the program 
> gradRichardson in the curve package of the dseplus bundle in the 
> devel 
> area of CRAN. It uses Richarson extrapolation to improve the 
> accuracy. 
> However, this is not the program to use if you want a quick 
> numerical 
> estimate of the gradient. Most anything else you might think of 
> using 
> will be quicker.
> 
> There are some other programs around too. A year or two ago there 
> was 
> some discussion of putting various gradient calculation techniques 
> together in one place. I don't  think anything has happen yet.
> 
> Paul Gilbert
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From xt_wang at cs.concordia.ca  Mon May  3 18:44:53 2004
From: xt_wang at cs.concordia.ca (xt_wang@cs.concordia.ca)
Date: Mon,  3 May 2004 12:44:53 -0400
Subject: [R] again question about nmath/standalone
Message-ID: <1083602693.4096770510c83@mailhost.cs.concordia.ca>

Thanks every expert! I have fixed the problem that I can use R library in c 
code right now. 

However, it still has problem that I can not compile the c code. I attach the 
operation process to this letter. Who is so kind to help me find where is the 
problem? Thnaks in advance!

[credsim at confsys ~/src]$ gcc test1.c -o test1 -lRmath -lm
/tmp/ccYbnKy1.o(.text+0xd0): In function `main':
: undefined reference to `dim'
/tmp/ccYbnKy1.o(.text+0xdf): In function `main':
: undefined reference to `c'
/tmp/ccYbnKy1.o(.text+0xee): In function `main':
: undefined reference to `solve'
collect2: ld returned 1 exit status


test1.c code is as follow:

[credsim at confsys ~/src]$ vi test1.c

#define MATHLIB_STANDALONE
#include <math.h>
#include <stdlib.h>
#include <stdio.h>
#include </usr/local/lib/R/include/Rmath.h>


 main()
{

  int i,j,I,J,n;

  I=3;
  J=3;
  n=I*J;

  double valin;
  double x2[9];


  FILE *in_file;


    /* input x value from file data_2Dx.txt */
    in_file=fopen("data_2Dx.txt","r");
        if (in_file==NULL)
        {/*Test for error*/
                fprintf(stderr,"Error:Unable to input file 
from 'data_2Dx.txt'\n");
                exit(8);
        }
        for( i=0;i<n;i++)
         /* for (j=0;j<J;j++)*/
          { fscanf(in_file, "%lf\n", &valin, stdin);/* read a single double 
value in */
               x2[i]=valin;
                   valin=0.0;
          }
        fclose(in_file);


   dim(x2)<-c(3,3);
   solve(x2);

   return (0);
   

}



From dsheuman at rogers.com  Mon May  3 18:51:15 2004
From: dsheuman at rogers.com (dsheuman@rogers.com)
Date: Mon, 3 May 2004 12:51:15 -0400
Subject: [R] Speed up graphics output?
Message-ID: <20040503165115.RNHT222321.web02-imail.rogers.com@localhost>

Hi all,

I've written some code to generate 4 maps per screen and write the output to a jpeg.  The output is fairly quick at the start (about 5 jpegs per minute) and then slows down greatly (1-2 jpegs per minute).

Is there some way to speed it up?  One of my thoughts is to keep the base map static on the screen and just update the points that are being plotted on the map (with the exception of the first map as it has the title I want).  I don't know how to do this though.  After it writes out the jpeg in updates the screen to blank.

Thanks,

Danny



platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    9.0            
year     2004           
month    04             
day      12             
language R 

-------------------------------------------
#Input file is comma-delimited and has GeogID, LON, LAT and CLUSTER
#LON should be in column 2 and LAT in column 3

library(maptools)

#Number of clusters in total
ClusCount <- 150

#Read in Cluster Assignments
datain <- as.data.frame( read.table("c:\\data\\Run1\\kmeansout_150.txt", header=TRUE ))
colnames(datain) <- c("geogid","long","lat","cluster")


#Set up screen device
#split 2x2 - permits 1 map per section
par(bg="white") 
split.screen(c(2,2))

#Load maps once only
w <- read.shape("c:\\data\\region1.shp", dbf.data = TRUE)
x <- read.shape("c:\\data\\region2.shp", dbf.data = TRUE)
y <- read.shape("c:\\data\\region3.shp", dbf.data = TRUE)
z <- read.shape("c:\\data\\region4.shp", dbf.data = TRUE)

#Loop through the clusters and produce maps of each region
#The base maps stay the same with the exception of map1
#which has the title of Cluster # and the points which
#reflect the current cluster.

#Subset data on cluster
for(i in 1:ClusCount){
	mapit <- subset(datain, cluster == i)

	screen(1)
	plot(w, xlab="", ylab="", fg="white", axes = F, main=paste("Cluster",i))
	points( as.matrix(mapit[,2]), as.matrix(mapit[,3]), col="red", pch=19)
	
	screen(2)
	plot(x, ylim=c(42.9, 44.2), xlim=c(-80.2, -78.5), xlab="", ylab="", fg="white", axes = F)
	points( as.matrix(mapit[,2]), as.matrix(mapit[,3]), col="red", pch=19)
	
	screen(3)
	plot(y, ylim=c(45.2, 45.8), xlim=c(-74.3, -73.0), xlab="", ylab="", fg="white", axes = F)
	points( as.matrix(mapit[,2]), as.matrix(mapit[,3]), col="red", pch=19)
	
	screen(4)
	plot(z, ylim=c(48.9, 49.7), xlim=c(-123.6, -121.8), xlab="", ylab="", fg="white", axes = F)
	points( as.matrix(mapit[,2]), as.matrix(mapit[,3]), col="red", pch=19)

	#send to jpeg
	dev.print(jpeg,file=paste("c:\\temp\\cluster",format(i),"_canada.jpeg",sep=""),width=1024,height=768, pointsize = 12,quality = 100, bg = "white") 
	
}



From dmurdoch at pair.com  Mon May  3 19:07:25 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 03 May 2004 13:07:25 -0400
Subject: [R] r dev site is down
In-Reply-To: <MBBBIIHJANJBMHLGMACKMECPCGAA.binabina@bellsouth.net>
References: <MBBBIIHJANJBMHLGMACKMECPCGAA.binabina@bellsouth.net>
Message-ID: <jluc9013sef74aa259uqbtiq6h2r1rreri@4ax.com>

On Sun, 2 May 2004 09:52:16 -0400, "zubin" <binabina at bellsouth.net>
wrote :

>the R developer site has been down for some time, what gives?
>
>http://developer.r-project.org/

It's back online now at a different site.  There are a few problems
that will be worked out over the next few days:

- DNS isn't working yet, so you need to go to http://66.39.64.254 for
a while.

- Some of the links on the page are broken.  (If anyone knows
corrections, please let me know about them.)

- It will only be updated manually for a while, so things may get a
little stale.

- If anyone used email addresses at developer.r-project.org, those
will no longer forward or be read by anyone.  

Duncan Murdoch



From wolski at molgen.mpg.de  Mon May  3 19:25:20 2004
From: wolski at molgen.mpg.de (witek)
Date: Mon, 03 May 2004 19:25:20 +0200
Subject: [R] RODBC/odbcConnect and Xemacs/ess Problem
Message-ID: <200405031925200368.025C6392@mail.math.fu-berlin.de>

Hi Folks

I am trying to use Xemacs/ess 5.2 on windows XP and have a problem with the RODBC package in R1.9.0

library(RODBC) 
channel<-odbcConnect("mysql")
Warning messages: 
1: [RODBC] ERROR: Could not SQLDriverConnect 
2: ODBC connection failed in: odbcDriverConnect(paste("DSN=", dsn, ";UID=", uid, ";PWD=", pwd,  

But the same code works in the Rterm, Rgui with the same R1.9.1 

On a Windows 2000 computer with R1.9.1 and Xemacs/ESS 5.1.24 the same code is working.

Any ideas sugestions?

Eryk



Sys.info()
                      sysname                       release 
                    "Windows"                      "NT 5.1" 
                      version                      nodename 
"(build 2600) Service Pack 1"                        "FUGU" 
                      machine                         login 
                        "x86"                     "ewolski" 
                         user 
                    "ewolski" 


R.Version()
$platform
[1] "i386-pc-mingw32"

$arch
[1] "i386"

$os
[1] "mingw32"

$system
[1] "i386, mingw32"

$status
[1] ""

$major
[1] "1"

$minor
[1] "9.0"

$year
[1] "2004"

$month
[1] "04"

$day
[1] "12"

$language
[1] "R"



From p.dalgaard at biostat.ku.dk  Mon May  3 19:23:19 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 May 2004 19:23:19 +0200
Subject: [R] r dev site is down
In-Reply-To: <jluc9013sef74aa259uqbtiq6h2r1rreri@4ax.com>
References: <MBBBIIHJANJBMHLGMACKMECPCGAA.binabina@bellsouth.net>
	<jluc9013sef74aa259uqbtiq6h2r1rreri@4ax.com>
Message-ID: <x2k6zt5ss8.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch at pair.com> writes:

> On Sun, 2 May 2004 09:52:16 -0400, "zubin" <binabina at bellsouth.net>
> wrote :
> 
> >the R developer site has been down for some time, what gives?
> >
> >http://developer.r-project.org/
> 
> It's back online now at a different site.  There are a few problems
> that will be worked out over the next few days:

Thanks!
 
> - DNS isn't working yet, so you need to go to http://66.39.64.254 for
> a while.

> - Some of the links on the page are broken.  (If anyone knows
> corrections, please let me know about them.)

The CVS log is one casualty; what are the others? The CVS log is
awkward to fix since its functionality depended on having the website
at the cvs repository (and likewise the automagic web update upon
commits). It is still being generated, and there's a web server and
everything at the CVS site, it is just that the rest of the world is
getting firewalled out. Hmm.. perhaps all we need is to commit the log
to R-dev-web when it is modified?
 
> - It will only be updated manually for a while, so things may get a
> little stale.
> 
> - If anyone used email addresses at developer.r-project.org, those
> will no longer forward or be read by anyone.  

I don't think they were ever official.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jtd152 at psu.edu  Mon May  3 20:02:11 2004
From: jtd152 at psu.edu (Joseph Dauer)
Date: Mon, 3 May 2004 14:02:11 -0400
Subject: [R] circular correlation
Message-ID: <B5C1B0561422B24A8C9C6655D10144F4041EE9D4@ag2admin3.cas.psu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040503/21fc2dd6/attachment.pl

From vograno at evafunds.com  Mon May  3 20:20:20 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Mon, 3 May 2004 11:20:20 -0700
Subject: [R] seek(..., origin='current') doesn't work on gzfile
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B32DC@phost015.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040503/138e3eab/attachment.pl

From macq at llnl.gov  Mon May  3 21:20:11 2004
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 3 May 2004 12:20:11 -0700
Subject: [R] ./configure on SunOS does not run to completion
In-Reply-To: <200405031727450487.621D40B2@harry.molgen.mpg.de>
References: <200405031727450487.621D40B2@harry.molgen.mpg.de>
Message-ID: <p06002005bcbc4b1cc3e2@[128.115.153.6]>

Well, that's interesting, but mine does run to completion.

configure:28052: checking for xmkmf
configure:28070: found /usr/openwin/bin/xmkmf
configure:28082: result: /usr/openwin/bin/xmkmf

(SunOS 5.8, but I have that file in that location also on a 5.9 system)

I think you need to look at *your* openwin installation.

-Don

At 5:27 PM +0200 5/3/04, wolski wrote:
>OS:
>SunOS human 5.9 Generic_112233-12 sun4u sparc SUNW,Sun-Fire-480R
>
>
>I run
>./configure --prefix=/non/standard/path
>...
>
>and it stops at the line
>checking for xmkmf... /usr/openwin/bin/xmkmf
>
>
>Sincerely Eryk
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From rbonneau at systemsbiology.org  Mon May  3 21:49:53 2004
From: rbonneau at systemsbiology.org (Richard Bonneau)
Date: Mon, 3 May 2004 12:49:53 -0700
Subject: [R] selecting a coordinate from a graph
Message-ID: <0BA8E26A-9D3B-11D8-93F8-000A95AFB68E@systemsbiology.org>

hello everyone,

What is the method for selecting a coordinate from a graph
with the mouse, if any such function exists? For example, we
would like to select outliers in a scatter-plot  with the mouse, or
add figure legends with the mouse.
There was a way to add figure legends with the mouse in Splus
but I haven't  found such functions in R.

Thanks,
Rich



From FWS4 at CDRH.FDA.GOV  Mon May  3 21:51:43 2004
From: FWS4 at CDRH.FDA.GOV (Samuelson, Frank*)
Date: Mon, 3 May 2004 15:51:43 -0400
Subject: [R] openMosix vs SNOW: redhat kernel causing slowdown?
Message-ID: <644D9337A02FC24689647BF9E48EC39E08ABB7E1@drm556>

You're using sockets for connection in snow?  or pvm or mpi?
There's nothing magical about snow.  It just uses the socket
connections provided in R, which in turn uses regular  BSD sockets.

-----Original Message-----
From: Jim Thomas [mailto:james at staarfunds.com] 
Sent: Thursday, April 29, 2004 6:13 PM
To: r-help at stat.math.ethz.ch
Subject: [R] openMosix vs SNOW: redhat kernel causing slowdown?


Hi there,

We're currently attempting to explain a slowdown of an LVQ-type parallel 
analysis we're working on.  We are benchmarking our analysis running 
over openMosix against the same running via SNOW for R.  Both perform 
similarly on small datasets, but on large datasets SNOW drastically 
outperforms openMosix.  However, these results are achieve running SNOW 
on the default RedHat kernel (Enterprise Edition, RHEL-3) and mosix on 
the same kernel patched with the rpm for RedHat 9 from sourceforge. 
 Even though the rpm seems to be compatible and everything runs fine, 
when the same SNOW analysis is run under the patched kernel there is an 
enormous slowdown in runtime, to the point that openMosix outperforms SNOW.

Is there some sort of incompatibility issue with the RedHat kernels 
(either general or specific to this version) that would cause a slowdown 
of this kind?  I know that Enterprise Edition was marketed as having 
tools to increase java clustering speeds, would this interfere with the 
type of socket communication SNOW uses?

Thanks,
Jim

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Mon May  3 22:13:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 May 2004 21:13:19 +0100 (BST)
Subject: [R] selecting a coordinate from a graph
In-Reply-To: <0BA8E26A-9D3B-11D8-93F8-000A95AFB68E@systemsbiology.org>
Message-ID: <Pine.LNX.4.44.0405032111390.27087-100000@gannet.stats>

On Mon, 3 May 2004, Richard Bonneau wrote:

> What is the method for selecting a coordinate from a graph
> with the mouse, if any such function exists? For example, we
> would like to select outliers in a scatter-plot  with the mouse, or
> add figure legends with the mouse.
> There was a way to add figure legends with the mouse in Splus
> but I haven't  found such functions in R.

There are exactly the same functions as in S-PLUS (sic), namely locator() 
and identify().  They *are* in `An Introduction to R', too.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mihastaut at hotmail.com  Mon May  3 23:14:41 2004
From: mihastaut at hotmail.com (Miha STAUT)
Date: Mon, 03 May 2004 21:14:41 +0000
Subject: [R] Legend outside the plotting region
Message-ID: <BAY2-F67ibxZxjbP3SI00004c83@hotmail.com>

Hello,

How would I add a legend to the plot outside the plotting region? I tried 
different graphical parameters (fig, plt, usr and fig in combination with 
plt) in par() without success.

Thanks in advance, Miha Staut



From ndesnoyers at att.net  Mon May  3 23:21:39 2004
From: ndesnoyers at att.net (ndesnoyers@att.net)
Date: Mon, 03 May 2004 21:21:39 +0000
Subject: [R] Factor loadings and principal component plots
Message-ID: <050320042121.3617.4096B7E30008493700000E212160376223FF8C8D9A8690918C9A9B@att.net>

Hi- Can anyone tell me the command(s) to produce the following plots:

-Factor loadings plot for principal components
-Plot of principal component scores

Also, apart from the prcomp (or princomp) command is there any other way to obtain principal components and if so, how does it/they stack up to prcomp?

Thanks in advance for any assistance you can provide.

Neil Desnoyers



From ksm32 at student.canterbury.ac.nz  Mon May  3 23:36:25 2004
From: ksm32 at student.canterbury.ac.nz (Karla Meurk)
Date: Tue, 04 May 2004 09:36:25 +1200
Subject: [R] plotting with R
Message-ID: <4096BB59.3030204@student.canterbury.ac.nz>

(2) If I have three curves on a plot how can I label each curve so the
 > label sits directly above the curve?


[A]As to your second question: I don't think there will be a simple
answer because
	on has to decide where "above" is. Could you please be more
specific?

	Dietrich

I have a picture of S+ output which has the label sitting on top of each 
curve and curving with it -does that make sense?

Thanks for your help
Carla



From macq at llnl.gov  Tue May  4 00:20:59 2004
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 3 May 2004 15:20:59 -0700
Subject: [R] circular correlation
In-Reply-To: <B5C1B0561422B24A8C9C6655D10144F4041EE9D4@ag2admin3.cas.psu.edu>
References: <B5C1B0561422B24A8C9C6655D10144F4041EE9D4@ag2admin3.cas.psu.edu>
Message-ID: <p06002009bcbc739f42d0@[128.115.153.6]>

I think you're going to have to decide which wind speed values are 
relevant to which seed collection data points. For example, if you 
collected a seed on Tuesday, is Monday's wind speed relevant or not? 
You've given no indication of what the relationships between your 
wind speed values and your seed collection values might be. Whatever 
the relationship is, you have to use your data in a way that makes 
sense for that relationship. And yes, your basic correlation 
calculation requires one-to-one correspondence. If you have 
many-to-one, you'll have to adapt your data in some way, to make it 
one-to-one. How you adapt it depends on information you haven't 
provided (and isn't an R question either). For example, if seeds 
float about for around 2 days, on average, before settling down to 
the ground, maybe 2 day averages of wind seed are relevant. That's 
the kind of thing you'll have to decide.

-Don

At 2:02 PM -0400 5/3/04, Joseph Dauer wrote:
>I have a problem that deals with correlating wind velocity to seed
>collection data.  The problem lies in that I have a wind data set that
>is contains 2000+ data points and weed collection data on the order of a
>couple hundred.  Both data sets were collected for the same time period,
>but there is not a one-to-one wind velocity->seed location match.  My
>understanding of correlation is that you need equal data sets.  Is there
>a way to compare means and standard deviations (or kappa in circular
>stats) that doesn't require equal data sets?  Thank you in advance. Joe
>
>
>
>Example (simplified):
>
>library(CircStats)
>
>wind<-c(2.1, 2.3, 2.6, 2.1, 2.6, 2.4, 1.2, 1.5) # in radians
>
>seed<-c(1.7, 1.3, 1.5, 1.9, 1.8, 2.3)
>
>circ.cor(wind, seed, test=T)
>
>
>
>
>
>
>
>Joseph Dauer
>
>Master's Student
>
>Weed Ecology
>
>412 ASI
>
>Pennsylvania State University
>
>University Park, PA 16802
>
>
>
>email: jtd152 at psu.edu
>
>office phone: (814) 865 - 6679
>
>http://www.agronomy.psu.edu/weedecology
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From user at domain.invalid  Tue May  4 01:04:49 2004
From: user at domain.invalid (user@domain.invalid)
Date: Mon, 03 May 2004 16:04:49 -0700
Subject: [R] Getting parameters from within function
Message-ID: <c76j6f$snn$1@sea.gmane.org>

Hi R-Helpers

Is there a way to access the parameters passed to a function all at 
once?  I want something like:

misc.params = list(...)

except such that it works with formal named parameters.

Context--I am running lots of simulations, want to record how they were 
specified.

Thanks!



From wwsprague at ucdavis.edu  Tue May  4 01:10:34 2004
From: wwsprague at ucdavis.edu (wwsprague@ucdavis.edu)
Date: Mon, 03 May 2004 16:10:34 -0700
Subject: [R] Getting parameters from within function (redux)
Message-ID: <c76jh8$te9$1@sea.gmane.org>

(Sorry about the wack name--don't want to go into your spam buckets...)

Hi R-Helpers

Is there a way to access the parameters passed to a function all at 
once?  I want something like:

misc.params = list(...)

except such that it works with formal named parameters.

Context--I am running lots of simulations, want to record how they were 
specified.

Thanks!



From andy_liaw at merck.com  Tue May  4 01:14:26 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 3 May 2004 19:14:26 -0400
Subject: [R] plotting with R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7CE1@usrymx25.merck.com>

> From: Karla Meurk
> 
> (2) If I have three curves on a plot how can I label each curve so the
>  > label sits directly above the curve?
> 
> 
> [A]As to your second question: I don't think there will be a simple
> answer because
> 	on has to decide where "above" is. Could you please be more
> specific?

I believe Prof. Harrell has something that places labels for curves in
`strategic' places in the plot, in his `Hmisc' package.  Maybe it's only for
Trellis graphics?

Andy

 
> 	Dietrich
> 
> I have a picture of S+ output which has the label sitting on 
> top of each 
> curve and curving with it -does that make sense?
> 
> Thanks for your help
> Carla
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From tlumley at u.washington.edu  Tue May  4 01:30:36 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 3 May 2004 16:30:36 -0700 (PDT)
Subject: [R] Getting parameters from within function (redux)
In-Reply-To: <c76jh8$te9$1@sea.gmane.org>
References: <c76jh8$te9$1@sea.gmane.org>
Message-ID: <Pine.A41.4.58.0405031630220.118976@homer06.u.washington.edu>

On Mon, 3 May 2004 wwsprague at ucdavis.edu wrote:

> Hi R-Helpers
>
> Is there a way to access the parameters passed to a function all at
> once?  I want something like:
>
> misc.params = list(...)
>
> except such that it works with formal named parameters.
>

match.call() or sys.call()

	-thomas



From feh3k at spamcop.net  Tue May  4 01:50:34 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Mon, 3 May 2004 19:50:34 -0400
Subject: [R] plotting with R
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7CE1@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7CE1@usrymx25.merck.com>
Message-ID: <20040503195034.26fe1c60.feh3k@spamcop.net>

On Mon, 3 May 2004 19:14:26 -0400
"Liaw, Andy" <andy_liaw at merck.com> wrote:

> > From: Karla Meurk
> > 
> > (2) If I have three curves on a plot how can I label each curve so the
> >  > label sits directly above the curve?
> > 
> > 
> > [A]As to your second question: I don't think there will be a simple
> > answer because
> > 	on has to decide where "above" is. Could you please be more
> > specific?
> 
> I believe Prof. Harrell has something that places labels for curves in
> `strategic' places in the plot, in his `Hmisc' package.  Maybe it's only
> for Trellis graphics?

The labcurve function in Hmisc works for both trellis and standard
graphics.  It has many label placement options.

Frank

> 
> Andy
> 
>  
> > 	Dietrich
> > 
> > I have a picture of S+ output which has the label sitting on 
> > top of each 
> > curve and curving with it -does that make sense?
> > 
> > Thanks for your help
> > Carla

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From jfox at mcmaster.ca  Tue May  4 01:59:09 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 3 May 2004 19:59:09 -0400
Subject: [R] plotting with R
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7CE1@usrymx25.merck.com>
Message-ID: <20040503235907.DIXH4905.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Carla,

I often position text on a graph interactively with the mouse via a call to
locator(): e.g., text(locator(3), c("one", "two", "three")).

I hope that this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
> Sent: Monday, May 03, 2004 6:14 PM
> To: 'Karla Meurk'; r-help at stat.math.ethz.ch
> Subject: RE: [R] plotting with R
> 
> > From: Karla Meurk
> > 
> > (2) If I have three curves on a plot how can I label each 
> curve so the  
> > > label sits directly above the curve?
> > 
> > 
> > [A]As to your second question: I don't think there will be a simple 
> > answer because
> > 	on has to decide where "above" is. Could you please be 
> more specific?
> 
> I believe Prof. Harrell has something that places labels for 
> curves in `strategic' places in the plot, in his `Hmisc' 
> package.  Maybe it's only for Trellis graphics?
> 
> Andy
> 
>  
> > 	Dietrich
> > 
> > I have a picture of S+ output which has the label sitting on top of 
> > each curve and curving with it -does that make sense?
> > 
> > Thanks for your help
> > Carla
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Tue May  4 02:02:12 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 3 May 2004 20:02:12 -0400
Subject: [R] Legend outside the plotting region
In-Reply-To: <BAY2-F67ibxZxjbP3SI00004c83@hotmail.com>
Message-ID: <20040504000211.MMFT5998.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Miha,

Try setting par(xpd=TRUE) or par(xpd=NA).

I hope this helps,
 John 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Miha STAUT
> Sent: Monday, May 03, 2004 4:15 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Legend outside the plotting region
> 
> Hello,
> 
> How would I add a legend to the plot outside the plotting 
> region? I tried different graphical parameters (fig, plt, usr 
> and fig in combination with
> plt) in par() without success.
> 
> Thanks in advance, Miha Staut



From p.murrell at auckland.ac.nz  Tue May  4 02:44:04 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 04 May 2004 12:44:04 +1200
Subject: [R] Speed up graphics output?
References: <20040503165115.RNHT222321.web02-imail.rogers.com@localhost>
Message-ID: <4096E754.3080401@stat.auckland.ac.nz>

Hi

Try using par(mfrow=c(2, 2)) instead of split.screen(c(2, 2))
and removing all of the screen(?) commands.

I think what is happening is that you are just overwriting previous 
output every time through the loop so your picture just gets bigger and 
bigger (more and more overlayed output).  With the above adjustments, 
every time through the loop should start a clean page so the dev.print() 
should only have the same amount of output to write out.

Paul


dsheuman at rogers.com wrote:
> Hi all,
> 
> I've written some code to generate 4 maps per screen and write the output to a jpeg.  The output is fairly quick at the start (about 5 jpegs per minute) and then slows down greatly (1-2 jpegs per minute).
> 
> Is there some way to speed it up?  One of my thoughts is to keep the base map static on the screen and just update the points that are being plotted on the map (with the exception of the first map as it has the title I want).  I don't know how to do this though.  After it writes out the jpeg in updates the screen to blank.
> 
> Thanks,
> 
> Danny
> 
> 
> 
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    9.0            
> year     2004           
> month    04             
> day      12             
> language R 
> 
> -------------------------------------------
> #Input file is comma-delimited and has GeogID, LON, LAT and CLUSTER
> #LON should be in column 2 and LAT in column 3
> 
> library(maptools)
> 
> #Number of clusters in total
> ClusCount <- 150
> 
> #Read in Cluster Assignments
> datain <- as.data.frame( read.table("c:\\data\\Run1\\kmeansout_150.txt", header=TRUE ))
> colnames(datain) <- c("geogid","long","lat","cluster")
> 
> 
> #Set up screen device
> #split 2x2 - permits 1 map per section
> par(bg="white") 
> split.screen(c(2,2))
> 
> #Load maps once only
> w <- read.shape("c:\\data\\region1.shp", dbf.data = TRUE)
> x <- read.shape("c:\\data\\region2.shp", dbf.data = TRUE)
> y <- read.shape("c:\\data\\region3.shp", dbf.data = TRUE)
> z <- read.shape("c:\\data\\region4.shp", dbf.data = TRUE)
> 
> #Loop through the clusters and produce maps of each region
> #The base maps stay the same with the exception of map1
> #which has the title of Cluster # and the points which
> #reflect the current cluster.
> 
> #Subset data on cluster
> for(i in 1:ClusCount){
> 	mapit <- subset(datain, cluster == i)
> 
> 	screen(1)
> 	plot(w, xlab="", ylab="", fg="white", axes = F, main=paste("Cluster",i))
> 	points( as.matrix(mapit[,2]), as.matrix(mapit[,3]), col="red", pch=19)
> 	
> 	screen(2)
> 	plot(x, ylim=c(42.9, 44.2), xlim=c(-80.2, -78.5), xlab="", ylab="", fg="white", axes = F)
> 	points( as.matrix(mapit[,2]), as.matrix(mapit[,3]), col="red", pch=19)
> 	
> 	screen(3)
> 	plot(y, ylim=c(45.2, 45.8), xlim=c(-74.3, -73.0), xlab="", ylab="", fg="white", axes = F)
> 	points( as.matrix(mapit[,2]), as.matrix(mapit[,3]), col="red", pch=19)
> 	
> 	screen(4)
> 	plot(z, ylim=c(48.9, 49.7), xlim=c(-123.6, -121.8), xlab="", ylab="", fg="white", axes = F)
> 	points( as.matrix(mapit[,2]), as.matrix(mapit[,3]), col="red", pch=19)
> 
> 	#send to jpeg
> 	dev.print(jpeg,file=paste("c:\\temp\\cluster",format(i),"_canada.jpeg",sep=""),width=1024,height=768, pointsize = 12,quality = 100, bg = "white") 
> 	
> }
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From p.murrell at auckland.ac.nz  Tue May  4 02:52:40 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 04 May 2004 12:52:40 +1200
Subject: [R] Lattice: finding out xlim within panel function
References: <85D25331FFB7AE4C900EA467D4ADA392045913@circle.pcpool.mi.fu-berlin.de>
	<200405031044.20497.deepayan@stat.wisc.edu>
Message-ID: <4096E958.6000405@stat.auckland.ac.nz>

Hi


Deepayan Sarkar wrote:
> On Monday 03 May 2004 09:36, Lutz Prechelt wrote:
> 
>>Dear Lattice bit-meddlers,
>>
>>while within a panel function for xyplot, how can I
>>find out the values of (effectively) xlim and
>>ylim -- no matter whether they have been set
>>explicitly or chosen by Lattice itself?
>>
>>I have just tried for an hour to find out,
>>with no success whatsoever.
>>I looked in Grid for something that would
>>return such data, but got lost.
>>I looked at tracebacks of panel calls, but
>>couldn't see the forest for the trees.
> 
> 
> Not surprising, since there's no documented way to do this. You could 
> try something along these lines, but this exact construct is not 
> guaranteed to work in future versions of grid:
> 
> panel = function(...) {
>     cvp = grid::current.viewport() 
>     print(cvp$xscale)
>     print(cvp$yscale)
> }


Yep, the API for interrogating grid objects needs more work.  On the 
other hand, it's possible that you don't need to know the x- and 
y-scales.  You may be able to do what you want with the unit() function 
and unit conversion functions (which are documented).  Can you tell me 
more about what you are trying to do?

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From fdimzon at boxfrog.com  Tue May  4 03:46:35 2004
From: fdimzon at boxfrog.com (Francis Dimzon)
Date: Mon, 03 May 2004 20:46:35 -0500
Subject: [R] Epidemiology Tools
Message-ID: <20040504014637.44259.qmail@www.boxfrog.com>

Hi all, 

Please help on this.  We will be teaching epidemiology using opensource 
software. What are R built-in functions or functions in available packages 
that are capable of doing these: 

a) Logistic regression   (glm?)
b) Conditional logistic regression
c) Logistic regression with random effects
d) Beta-binomial regression
e) Poisson regression
f) Weibull regression  (eha?)
g) Exponential regression
h) Cox proportional hazards regression  (survival?, eha?)
i) Cox regression with time repeated covariables
j) Kaplan-Meier Analysis and Plots (survival?)
k) Post-fit analysis with plots, delta-betas, hazard functions
l) meta analysis (rmeta?) 

Thanks in advance for your help. 


 ------------------
Francis D. Dimzon
Assistant Professor, Computer Science
University of the Philippines in the Visayas
Miag-ao, Iloilo, Philippines



From jasont at indigoindustrial.co.nz  Tue May  4 04:00:02 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 04 May 2004 14:00:02 +1200
Subject: [R] Getting parameters from within function
In-Reply-To: <c76j6f$snn$1@sea.gmane.org>
References: <c76j6f$snn$1@sea.gmane.org>
Message-ID: <4096F922.6010801@indigoindustrial.co.nz>

user at domain.invalid wrote:

> Hi R-Helpers
> 
> Is there a way to access the parameters passed to a function all at 
> once?  I want something like:
> 
> misc.params = list(...)
> 
> except such that it works with formal named parameters.
> 

Does match.call() do what you want?

foo <- function(x,y,long.winded.arguemnt.name,...) {
     args <- match.call()
     args
}

foo(rnorm(10),rnorm(10),"some text")
foo(x = rnorm(10), y = rnorm(10), long.winded.arguemnt.name = "some text")

Cheers

Jason



From mathinee at gaccl.com  Tue May  4 04:32:33 2004
From: mathinee at gaccl.com (mathinee@gaccl.com)
Date: Mon, 3 May 2004 19:32:33 -0700 (PDT)
Subject: [R] I have some problem about "save and open"
Message-ID: <22380.203.144.212.245.1083637953.squirrel@www.gaccl.com>

Hello R-help

I use R program on linux.
and when I would like to quick R, then I type q()
after than has question "Save workspace image? [y/n/c]:"
when I ans "y" , why not to ask about name of file.
and when I would like to open last file , how can I do?
thanks for your help.
and sorry if my English not so good. I'm Thai people and I know
English a little.
Mathinee



From hodgess at gator.uhd.edu  Tue May  4 05:59:08 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Mon, 3 May 2004 22:59:08 -0500
Subject: [R] cointegration
Message-ID: <200405040359.i443x8l31618@gator.dt.uh.edu>

Dear R People:

Is there a function for cointegration in any of the libraries, please?

for R Windows, please?

thanks,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu



From fdimzon at boxfrog.com  Tue May  4 06:28:46 2004
From: fdimzon at boxfrog.com (Francis Dimzon)
Date: Mon, 03 May 2004 23:28:46 -0500
Subject: [R] Re: Epidemiology Tools
In-Reply-To: <MBEPIIKLODKFDMIPFOGAOECJCFAA.ndrew@efn.org> 
References: <MBEPIIKLODKFDMIPFOGAOECJCFAA.ndrew@efn.org>
Message-ID: <20040504042847.93002.qmail@www.boxfrog.com>

Yes I found that: I already integrated menus using the functions at
http://www.medepi.org/epitools/rfunctions/index.html
in Rcmdr. 

The work of Tomas Aragon (http://www.medepi.org/rdocs/index.html) is still 
in progress. 

My objective actually is to provide in R those functions available in 
non-opensource epidemiology software (epiinfo for example, no linux version 
available) 

Pease help. 


Nick Drew writes:
> You might try:
> http://www.medepi.org/epitools/rfunctions/index.html#A

> and 
> 
> http://www.medepi.org/rdocs/index.html 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Francis Dimzon
> Sent: Monday, May 03, 2004 5:47 PM
> To: r-help
> Subject: [R] Epidemiology Tools 
> 
> 
> Hi all, 
> 
> Please help on this.  We will be teaching epidemiology using opensource
> software. What are R built-in functions or functions in available packages
> that are capable of doing these: 
> 
> a) Logistic regression   (glm?)
> b) Conditional logistic regression
> c) Logistic regression with random effects
> d) Beta-binomial regression
> e) Poisson regression
> f) Weibull regression  (eha?)
> g) Exponential regression
> h) Cox proportional hazards regression  (survival?, eha?)
> i) Cox regression with time repeated covariables
> j) Kaplan-Meier Analysis and Plots (survival?)
> k) Post-fit analysis with plots, delta-betas, hazard functions
> l) meta analysis (rmeta?) 
> 
> Thanks in advance for your help. 
> 
> 
>  ------------------
> Francis D. Dimzon
> Assistant Professor, Computer Science
> University of the Philippines in the Visayas
> Miag-ao, Iloilo, Philippines 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html 
> 
>  
> 
Francis D. Dimzon
Assistant Professor, Computer Science
University of the Philippines in the Visayas
Miag-ao, Iloilo, Philippines



From arv at ono.com  Tue May  4 08:17:59 2004
From: arv at ono.com (antonio rodriguez)
Date: Tue, 4 May 2004 08:17:59 +0200
Subject: [R] Factor loadings and principal component plots
In-Reply-To: <050320042121.3617.4096B7E30008493700000E212160376223FF8C8D9A8690918C9A9B@att.net>
Message-ID: <IPEFKICOHOECENGJBAGLCEFIDDAA.arv@ono.com>

Hi Neil,


> -----Mensaje original-----
> De: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]En nombre de ndesnoyers at att.net
> Enviado el: lunes, 03 de mayo de 2004 23:22
> Para: r-help at stat.math.ethz.ch
> Asunto: [R] Factor loadings and principal component plots
> 
> 
> Hi- Can anyone tell me the command(s) to produce the following plots:
> 
> -Factor loadings plot for principal components
> -Plot of principal component scores

Probably you can look directly to the screeplot() or loadings() functions. 

> 
> Also, apart from the prcomp (or princomp) command is there any 
> other way to obtain principal components and if so, how does 
> it/they stack up to prcomp?

 eigen()or svd() functions

> 
> Thanks in advance for any assistance you can provide.
> 
> Neil Desnoyers


Antonio
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> ---
> Incoming mail is certified Virus Free.
> Checked by AVG anti-virus system (http://www.grisoft.com).
> Version: 6.0.672 / Virus Database: 434 - Release Date: 28/04/2004
> 
---



From sgamibo at hotmail.com  Tue May  4 08:25:35 2004
From: sgamibo at hotmail.com (Chou Andy)
Date: Tue, 04 May 2004 06:25:35 +0000
Subject: [R] Linear Programming
Message-ID: <BAY16-F82ir3wSimD3J00008240@hotmail.com>

Hi,

Can someone tell me how to use R to solve a simple LP problem like this?  
Thanks!

Maximize 5X1 + 3X2 
Subject to:
2X1 + X2 <=40
X1 + 2X2 <=50
Where
X1 >= 0
X2 >=0 


Andy

_________________________________________________________________
{bNW MSN |GbuWsBA



From jasont at indigoindustrial.co.nz  Tue May  4 08:34:32 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 4 May 2004 18:34:32 +1200 (NZST)
Subject: [R] Linear Programming
In-Reply-To: <BAY16-F82ir3wSimD3J00008240@hotmail.com>
References: <BAY16-F82ir3wSimD3J00008240@hotmail.com>
Message-ID: <15186.203.9.176.60.1083652472.squirrel@webmail.maxnet.co.nz>

> Hi,
>
> Can someone tell me how to use R to solve a simple LP problem like this?
> Thanks!
>
> Maximize 5X1 + 3X2
> Subject to:
> 2X1 + X2 <=40
> X1 + 2X2 <=50
> Where
> X1 >= 0
> X2 >=0

help(I.will.do.my.own.homework) is the function you're looking for.

Cheers

Jason



From ripley at stats.ox.ac.uk  Tue May  4 08:34:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 May 2004 07:34:55 +0100 (BST)
Subject: [R] Factor loadings and principal component plots
In-Reply-To: <050320042121.3617.4096B7E30008493700000E212160376223FF8C8D9A8690918C9A9B@att.net>
Message-ID: <Pine.LNX.4.44.0405040729570.27771-100000@gannet.stats>

Well, factor loadings apply to factor analysis, not PCA, so have you 
confused the two?  (Lots of the literature does.)

On Mon, 3 May 2004 ndesnoyers at att.net wrote:

> Hi- Can anyone tell me the command(s) to produce the following plots:
> 
> -Factor loadings plot for principal components
> -Plot of principal component scores

Easy via the predict and biplot methods: see the examples in the 
MASS/scripts/ch11.R file.

> Also, apart from the prcomp (or princomp) command is there any other way
> to obtain principal components and if so, how does it/they stack up to
> prcomp?

Yes, but princomp is the recommended way, not prcomp.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jarioksa at sun3.oulu.fi  Tue May  4 08:43:03 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 04 May 2004 09:43:03 +0300
Subject: [R] Factor loadings and principal component plots
In-Reply-To: <Pine.LNX.4.44.0405040729570.27771-100000@gannet.stats>
References: <Pine.LNX.4.44.0405040729570.27771-100000@gannet.stats>
Message-ID: <1083652983.7580.2.camel@biol102145.oulu.fi>

On Tue, 2004-05-04 at 09:34, Prof Brian Ripley wrote:

> 
> Yes, but princomp is the recommended way, not prcomp.

But the documentation seems to recommend prcomp:

?prcomp:

 
     The calculation is done by a singular value decomposition of the
     (centered and scaled) data matrix, not by using 'eigen' on the
     covariance matrix.  This is generally the preferred method for
     numerical accuracy.

?princomp:

     The calculation is done using 'eigen' on the correlation or
     covariance matrix, as determined by 'cor'.  This is done for
     compatibility with the S-PLUS result.  A preferred method of
     calculation is to use 'svd' on 'x', as is done in 'prcomp'.

Just confused, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From ripley at stats.ox.ac.uk  Tue May  4 08:56:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 May 2004 07:56:55 +0100 (BST)
Subject: [R] Factor loadings and principal component plots
In-Reply-To: <1083652983.7580.2.camel@biol102145.oulu.fi>
Message-ID: <Pine.LNX.4.44.0405040756060.27927-100000@gannet.stats>

On 4 May 2004, Jari Oksanen wrote:

> On Tue, 2004-05-04 at 09:34, Prof Brian Ripley wrote:
> 
> > 
> > Yes, but princomp is the recommended way, not prcomp.
> 
> But the documentation seems to recommend prcomp:

For numerical accuracy, but not for flexibility.

> 
> ?prcomp:
> 
>  
>      The calculation is done by a singular value decomposition of the
>      (centered and scaled) data matrix, not by using 'eigen' on the
>      covariance matrix.  This is generally the preferred method for
>      numerical accuracy.
> 
> ?princomp:
> 
>      The calculation is done using 'eigen' on the correlation or
>      covariance matrix, as determined by 'cor'.  This is done for
>      compatibility with the S-PLUS result.  A preferred method of
>      calculation is to use 'svd' on 'x', as is done in 'prcomp'.
> 
> Just confused, jari oksanen
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jarioksa at sun3.oulu.fi  Tue May  4 10:02:42 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 04 May 2004 11:02:42 +0300
Subject: [R] Factor loadings and principal component plots
In-Reply-To: <Pine.LNX.4.44.0405040756060.27927-100000@gannet.stats>
References: <Pine.LNX.4.44.0405040756060.27927-100000@gannet.stats>
Message-ID: <1083657762.7580.20.camel@biol102145.oulu.fi>

On Tue, 2004-05-04 at 09:56, Prof Brian Ripley wrote:
> On 4 May 2004, Jari Oksanen wrote:
> 
> > On Tue, 2004-05-04 at 09:34, Prof Brian Ripley wrote:
> > 
> > > 
> > > Yes, but princomp is the recommended way, not prcomp.
> > 
> > But the documentation seems to recommend prcomp:
> 
> For numerical accuracy, but not for flexibility.
> 
Wouldn't the best alternative be to combine flexibility and accuracy
into one alternative? I mean, I'd still use prcomp after reading the
help pages, and I'd put more weight on accuracy than on flexibility. A
quick exploitation of the princomp would yield the attached "flexible
prcomp" code.

prcomp is more flexible at least in one point: it can handle data with
less units than variables.

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>
-------------- next part --------------
"prcomp.default" <-
    function (x, retx = TRUE, center = TRUE, scale. = FALSE, tol = NULL,
              subset = rep(TRUE, nrow(as.matrix(x))), ...) 
{
    x <- as.matrix(x)
    x <- x[subset, , drop = FALSE]
    x <- scale(x, center = center, scale = scale.)
    s <- svd(x, nu = 0)
    if (!is.null(tol)) {
        rank <- sum(s$d > (s$d[1] * tol))
        if (rank < ncol(x)) 
            s$v <- s$v[, 1:rank, drop = FALSE]
    }
    s$d <- s$d/sqrt(max(1, nrow(x) - 1))
    dimnames(s$v) <- list(colnames(x), paste("PC", seq(len = ncol(s$v)), 
                                             sep = ""))
    r <- list(sdev = s$d, rotation = s$v)
    if (retx) 
        r$x <- x %*% s$v
    class(r) <- "prcomp"
    r
}
"prcomp.formula" <-
    function (formula, data = NULL, subset, na.action, ...) 
{
    mt <- terms(formula, data = data)
    if (attr(mt, "response") > 0) 
        stop("response not allowed in formula")
    cl <- match.call()
    mf <- match.call(expand.dots = FALSE)
    mf$... <- NULL
    mf[[1]] <- as.name("model.frame")
    mf <- eval.parent(mf)
    if (any(sapply(mf, function(x) is.factor(x) || !is.numeric(x)))) 
        stop("PCA applies only to numerical variables")
    na.act <- attr(mf, "na.action")
    mt <- attr(mf, "terms")
    attr(mt, "intercept") <- 0
    x <- model.matrix(mt, mf)
    res <- prcomp.default(x, ...)
    cl[[1]] <- as.name("prcomp")
    res$call <- cl
    if (!is.null(na.act)) {
        res$na.action <- na.act
        if (!is.null(sc <- res$x)) 
            res$x <- napredict(na.act, sc)
    }
    res
}
"prcomp" <-
    function (x, ...) 
    UseMethod("prcomp")

From ligges at statistik.uni-dortmund.de  Tue May  4 10:09:16 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 04 May 2004 10:09:16 +0200
Subject: [R] I have some problem about "save and open"
In-Reply-To: <22380.203.144.212.245.1083637953.squirrel@www.gaccl.com>
References: <22380.203.144.212.245.1083637953.squirrel@www.gaccl.com>
Message-ID: <40974FAC.7070405@statistik.uni-dortmund.de>

mathinee at gaccl.com wrote:

> Hello R-help
> 
> I use R program on linux.
> and when I would like to quick R, then I type q()
> after than has question "Save workspace image? [y/n/c]:"
> when I ans "y" , why not to ask about name of file.


It saves the file ".RData" in the current working directory (getwd() 
tells you which it is). Use save.image() if you want to write to an 
explicitly given filename.


> and when I would like to open last file , how can I do?

Either start R in the working directory you have used the last time (it 
load ".RData" from the current), or use load() to explicitly load a 
workspace image.

Please read the manuals and the help ?Startup

Uwe Ligges


> thanks for your help.
> and sorry if my English not so good. I'm Thai people and I know
> English a little.
> Mathinee
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Wanzare at HCJP.com  Tue May  4 10:14:21 2004
From: Wanzare at HCJP.com (Manoj - Hachibushu Capital)
Date: Tue, 4 May 2004 17:14:21 +0900
Subject: [R] cointegration
Message-ID: <1CBA12F2D414914989C723D196B287DC055608@jp-svr-ex1.HCJP.COM>

See library(tseries) & library(urca).

 
Lib tseries has cointegration test for ADF and PO, whereas the newly
added urca package has functions for Johansen & VECM test.

Cheers

Manoj


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erin Hodgess
Sent: Tuesday, May 04, 2004 12:59 PM
To: r-help at stat.math.ethz.ch
Subject: [R] cointegration

Dear R People:

Is there a function for cointegration in any of the libraries, please?

for R Windows, please?

thanks,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From lutz.thieme at amd.com  Tue May  4 10:38:58 2004
From: lutz.thieme at amd.com (lutz.thieme@amd.com)
Date: Tue, 4 May 2004 10:38:58 +0200
Subject: [R] How to use multiple versions of a R library?
Message-ID: <E540DF203FFED21182EB0008C728756014A87A8B@deexmta4.amd.com>

Hello everybody,

is there a possibility to install and use multiple versions of a R library 
at the same time? 
A few words regarding the background of this question:
If I change functions of an already developed package, I have to 
verify complex functions in a lot of R applications. So it would be useful
to use different versions of a function/library and switch to the newer 
function/library application by application to avoid crashes. I know that 
the library function has an argument "version", but finally I don't know 
how to install and use different versions at the same time.
Any ideas and hints are appreciated - thank you in advance!

	Kind regards,

	Lutz


	Lutz Thieme
	Product Engineering
	AMD Saxony Limited Liability Company & Co. KG
	M/S E22-PE, Wilschdorfer Landstr. 101
	D-01109 Dresden, Gemany
	phone:	+ 49-351-277 -  4269
	fax:		+ 49-351-277-9-4269



From ligges at statistik.uni-dortmund.de  Tue May  4 10:46:11 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 04 May 2004 10:46:11 +0200
Subject: [R] How to use multiple versions of a R library?
In-Reply-To: <E540DF203FFED21182EB0008C728756014A87A8B@deexmta4.amd.com>
References: <E540DF203FFED21182EB0008C728756014A87A8B@deexmta4.amd.com>
Message-ID: <40975853.2010407@statistik.uni-dortmund.de>

lutz.thieme at amd.com wrote:

> Hello everybody,
> 
> is there a possibility to install and use multiple versions of a R library 
> at the same time? 
> A few words regarding the background of this question:
> If I change functions of an already developed package, I have to 
> verify complex functions in a lot of R applications. So it would be useful
> to use different versions of a function/library and switch to the newer 
> function/library application by application to avoid crashes. I know that 
> the library function has an argument "version", but finally I don't know 
> how to install and use different versions at the same time.
> Any ideas and hints are appreciated - thank you in advance!


R CMD INSTALL --help
tells us to use the option
   --with-package-versions
      allow for multiple versions of the same package
when installing the packages.

Uwe Ligges






> 	Kind regards,
> 
> 	Lutz
> 
> 
> 	Lutz Thieme
> 	Product Engineering
> 	AMD Saxony Limited Liability Company & Co. KG
> 	M/S E22-PE, Wilschdorfer Landstr. 101
> 	D-01109 Dresden, Gemany
> 	phone:	+ 49-351-277 -  4269
> 	fax:		+ 49-351-277-9-4269
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From janeteborges at gmx.net  Tue May  4 12:56:04 2004
From: janeteborges at gmx.net (Janete Borges)
Date: Tue, 4 May 2004 12:56:04 +0200 (MEST)
Subject: [R] Test the adjustment to Exponential distribution
Message-ID: <17928.1083668164@www18.gmx.net>

Hello!

I need to test the adjustment of a (Negative) Exponential Distribution to a
dataset. The parameter of the distribution is unknown. What is the
appropriate test to do? I've tried the ks.test, although I think this isn't
the appropriate one, as I don't know the parameter. 
Can anybody help me?

Thanks in advance,
Janete

-- 
Janete da Silva Borges

janeteborges at gmx.net


Ab sofort DSL-Tarif ohne Grundgebhr: http://www.gmx.net/dsl



From jerosenb at hcs.harvard.edu  Tue May  4 13:55:16 2004
From: jerosenb at hcs.harvard.edu (Janet Rosenbaum)
Date: Tue, 4 May 2004 07:55:16 -0400 (EDT)
Subject: [R] increasing memory
In-Reply-To: <200405041001.i44A1De4008300@hypatia.math.ethz.ch> from
	"r-help-request@stat.math.ethz.ch" at May 04, 2004 12:01:13 PM
Message-ID: <20040504115516.8DC032E88F@hcs.harvard.edu>


Hi.  I want to use R with very large files, a couple hundred megabytes,
but R crashes every time that I try.

Reading help files seems to indicate that R ought to manage its memory
itself.  I know I have enough memory since stata handles these files 
perfectly well.  I have a mac running OS 10.3 and am running RAqua 1.8.1.

Is there anything I can do to make it deal with these files successfully?

Janet
-- 
Janet Rosenbaum					 jerosenb at fas.harvard.edu
Harvard Injury Control Research Center,   Harvard School of Public Health



From k.wang at auckland.ac.nz  Tue May  4 14:01:44 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 5 May 2004 00:01:44 +1200
Subject: [R] ts() objects in R
Message-ID: <002901c431cf$91c89710$6633d882@stat.auckland.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040505/7ceb5451/attachment.pl

From ligges at statistik.uni-dortmund.de  Tue May  4 14:26:07 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 04 May 2004 14:26:07 +0200
Subject: [R] ts() objects in R
In-Reply-To: <002901c431cf$91c89710$6633d882@stat.auckland.ac.nz>
References: <002901c431cf$91c89710$6633d882@stat.auckland.ac.nz>
Message-ID: <40978BDF.9030502@statistik.uni-dortmund.de>

Ko-Kang Kevin Wang wrote:

> Does anyone know why this is happening?
> 
>>diff.prop[1:5]
> 
>          1          2          3          4          5 
> -0.6323988 -0.5226586 -0.5605096 -0.6656347 -0.6011561 
> 
>>ts(diff.prop, start = c(1997, 11), frequency = 1)

I think you mean

   ts(diff.prop, start = c(1997, 11), frequency = 12)

Uwe Ligges


> Time Series:
> Start = 2007 
> End = 2125 
> Frequency = 1 
> [snip]
> 
> diff.prop is a vector, I want to convert it to a time series starting from Nov 1997 on a monthly basis.  However when it's created it starts from 2007.  It's happening on both R 1.8.1 and R 1.9.0 on Windows XP Pro
> 
> Cheers,
> 
> Kevin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From k.wang at auckland.ac.nz  Tue May  4 14:26:37 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 5 May 2004 00:26:37 +1200
Subject: [R] ts() objects in R
References: <002901c431cf$91c89710$6633d882@stat.auckland.ac.nz>
	<40978BDF.9030502@statistik.uni-dortmund.de>
Message-ID: <005001c431d3$0bc16260$6633d882@stat.auckland.ac.nz>

Hi,

----- Original Message ----- 
From: "Uwe Ligges" <ligges at statistik.uni-dortmund.de>
> 
> I think you mean
> 
>    ts(diff.prop, start = c(1997, 11), frequency = 12)

Whoops, indeed......thanks!  That was a stupid question *_*

kevin Wang



From ligges at statistik.uni-dortmund.de  Tue May  4 14:28:40 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 04 May 2004 14:28:40 +0200
Subject: [R] increasing memory
In-Reply-To: <20040504115516.8DC032E88F@hcs.harvard.edu>
References: <20040504115516.8DC032E88F@hcs.harvard.edu>
Message-ID: <40978C78.7050905@statistik.uni-dortmund.de>

Janet Rosenbaum wrote:

> Hi.  I want to use R with very large files, a couple hundred megabytes,
> but R crashes every time that I try.
> 
> Reading help files seems to indicate that R ought to manage its memory
> itself.  I know I have enough memory since stata handles these files 
> perfectly well.  I have a mac running OS 10.3 and am running RAqua 1.8.1.
> 
> Is there anything I can do to make it deal with these files successfully?
> 
> Janet

I guess you mean R gives an error, but does *not* crash (if it crashes, 
it is a bug that needs to be fixed, and you should cross-check with a 
recent version of R).

If it gives an error, either read in the data in a more appropriate way 
(if there is any, but we do not know how you tried to read in the data), 
or "increase memory" as the subject already suggests.

Uwe Ligges



From unung at enciety.com  Tue May  4 14:35:45 2004
From: unung at enciety.com (Unung Istopo Hartanto)
Date: Tue, 04 May 2004 19:35:45 +0700
Subject: [R] ts() objects in R
In-Reply-To: <002901c431cf$91c89710$6633d882@stat.auckland.ac.nz>
References: <002901c431cf$91c89710$6633d882@stat.auckland.ac.nz>
Message-ID: <1083674144.4696.3.camel@IT05>

hello Kevin,

On Tue, 2004-05-04 at 19:01, Ko-Kang Kevin Wang wrote:
> Does anyone know why this is happening?
> > diff.prop[1:5]
>          1          2          3          4          5 
> -0.6323988 -0.5226586 -0.5605096 -0.6656347 -0.6011561 
> > ts(diff.prop, start = c(1997, 11), frequency = 1)

Please try :

ts(diff.prop,start=c(1997,11), frequency=12)

thanks,

Unung

> Time Series:
> Start = 2007 # is 1997 + 11 - 1
> End = 2125 
> Frequency = 1 
> [snip]
> 
> diff.prop is a vector, I want to convert it to a time series starting from Nov 1997 on a monthly basis.  However when it's created it starts from 2007.  It's happening on both R 1.8.1 and R 1.9.0 on Windows XP Pro
> 
> Cheers,
> 
> Kevin



From ripley at stats.ox.ac.uk  Tue May  4 14:38:44 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 May 2004 13:38:44 +0100 (BST)
Subject: [R] increasing memory
In-Reply-To: <20040504115516.8DC032E88F@hcs.harvard.edu>
Message-ID: <Pine.LNX.4.44.0405041336090.12609-100000@gannet.stats>

On Tue, 4 May 2004, Janet Rosenbaum wrote:

> Hi.  I want to use R with very large files, a couple hundred megabytes,
> but R crashes every time that I try.

If it actually crashes there is a bug, but I suspect that it stops with an
error message -- please do read the posting guide and tell us exactly what
happens.

> Reading help files seems to indicate that R ought to manage its memory
> itself.  I know I have enough memory since stata handles these files 
> perfectly well.  

That tells you very little: R and stata work in different ways.  How much 
memory do you have?

> I have a mac running OS 10.3 and am running RAqua 1.8.1.
> 
> Is there anything I can do to make it deal with these files successfully?

Start by giving us the information requested in the posting guide.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From unung at enciety.com  Tue May  4 15:07:10 2004
From: unung at enciety.com (Unung Istopo Hartanto)
Date: Tue, 04 May 2004 20:07:10 +0700
Subject: [R] Re: Importing SPSS Data Entry data files
In-Reply-To: <1083674144.4696.3.camel@IT05>
References: <002901c431cf$91c89710$6633d882@stat.auckland.ac.nz>
	<1083674144.4696.3.camel@IT05>
Message-ID: <1083676029.4696.10.camel@IT05>

Thank you very much, Mr Bibo,

btw... indeed..... i'm very happy after read your answer on 22 Apr.


Best Regards,

-- 
Unung Istopo Hartanto
------------------------------------------------
ENCIETY Business Consult
Research, Consulting and Training
Jl. Manyar Tirtoyoso Utara V/7 Surabaya Indonesia
Telp. +62-31-5992340, Fax. +62-31-5994230
www.enciety.com



From Soren.Hojsgaard at agrsci.dk  Tue May  4 15:26:32 2004
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Tue, 4 May 2004 15:26:32 +0200
Subject: [R] Seeing the definition of a function
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC01AACA96@DJFPOST01.djf.agrsci.dk>

Dear all,
I was trying to see how the function 'confint' is defined. Doing

> confint
function (object, parm, level = 0.95, ...) 
UseMethod("confint")
<environment: namespace:stats>

does not really enlighten me. How can I get to see the implementation (I guess it should be possible according to the general philosophy of the R project)?

Thanks in advance
S??ren

============================================================================================= 
S??ren H??jsgaard,  PhD, Head of Research Unit    Phone: +45 8999 1703 
Biometry Research Unit,                         Fax:     +45 8999 1300 
Danish Institute of Agricultural Sciences       E-mail: sorenh at agrsci.dk 
Research Centre Foulum, DK-8830 Tjele, Denmark  Homepage : http://www.jbs.agrsci.dk/~sorenh/



From rpeng at jhsph.edu  Tue May  4 15:31:34 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 04 May 2004 09:31:34 -0400
Subject: [R] Seeing the definition of a function
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC01AACA96@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC01AACA96@DJFPOST01.djf.agrsci.dk>
Message-ID: <40979B36.2090603@jhsph.edu>

confint is generic so it does nothing but dispatch appropriate 
methods.  If you do methods(confint), you'll see

 > methods(confint)
[1] confint.lm*

     Non-visible functions are asterisked

Typing confint.lm will give you an error because the function is not 
exported by the stats package namespace.  But doing 
getAnywhere(confint.lm) should do what you want.

-roger

S??ren H??jsgaard wrote:
> Dear all,
> I was trying to see how the function 'confint' is defined. Doing
> 
> 
>>confint
> 
> function (object, parm, level = 0.95, ...) 
> UseMethod("confint")
> <environment: namespace:stats>
> 
> does not really enlighten me. How can I get to see the implementation (I guess it should be possible according to the general philosophy of the R project)?
> 
> Thanks in advance
> S??ren
> 
> ============================================================================================= 
> S??ren H??jsgaard,  PhD, Head of Research Unit    Phone: +45 8999 1703 
> Biometry Research Unit,                         Fax:     +45 8999 1300 
> Danish Institute of Agricultural Sciences       E-mail: sorenh at agrsci.dk 
> Research Centre Foulum, DK-8830 Tjele, Denmark  Homepage : http://www.jbs.agrsci.dk/~sorenh/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Tue May  4 15:36:25 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 4 May 2004 09:36:25 -0400
Subject: [R] Seeing the definition of a function
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7CF4@usrymx25.merck.com>

You _are_ looking at the definition of confint(), which is a generic.  What
you're probably interested in are the methods, which you can find by:

> methods("confint")
[1] confint.lm*

    Non-visible functions are asterisked

> getAnywhere("confint.lm")
A single object matching 'confint.lm' was found
It was found in the following places
  registered S3 method for confint from namespace stats
  namespace:stats
with value

function (object, parm, level = 0.95, ...) 
{
    cf <- coef(object)
    pnames <- names(cf)
    if (missing(parm)) 
        parm <- seq(along = pnames)
    else if (is.character(parm)) 
        parm <- match(parm, pnames, nomatch = 0)
    a <- (1 - level)/2
    a <- c(a, 1 - a)
    pct <- paste(round(100 * a, 1), "%")
    ci <- array(NA, dim = c(length(parm), 2), dimnames = list(pnames[parm], 
        pct))
    ses <- sqrt(diag(vcov(object)))[parm]
    fac <- qt(a, object$df.residual)
    ci[] <- cf[parm] + ses %o% fac
    ci
}
<environment: namespace:stats>

You'll probably want to read a bit about how S3 methods work (e.g., in the
White Book).

HTH,
Andy


> From: S??ren H??jsgaard
> 
> Dear all,
> I was trying to see how the function 'confint' is defined. Doing
> 
> > confint
> function (object, parm, level = 0.95, ...) 
> UseMethod("confint")
> <environment: namespace:stats>
> 
> does not really enlighten me. How can I get to see the 
> implementation (I guess it should be possible according to 
> the general philosophy of the R project)?
> 
> Thanks in advance
> S??ren
> 
> ==============================================================
> =============================== 
> S??ren H??jsgaard,  PhD, Head of Research Unit    Phone: +45 8999 1703 
> Biometry Research Unit,                         Fax:     +45 
> 8999 1300 
> Danish Institute of Agricultural Sciences       E-mail: 
> sorenh at agrsci.dk 
> Research Centre Foulum, DK-8830 Tjele, Denmark  Homepage : 
http://www.jbs.agrsci.dk/~sorenh/

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Christoph.Scherber at uni-jena.de  Tue May  4 15:41:39 2004
From: Christoph.Scherber at uni-jena.de (Christoph Scherber)
Date: Tue, 04 May 2004 15:41:39 +0200
Subject: [R] lm(y~x) question: removing =?iso-8859-1?q?NA=B4s?=
Message-ID: <40979D93.2010005@uni-jena.de>

Dear all,

I have a data frame with different numbers of NA??s in each column, e.g.:

x       y  
1      2
NA  3
NA  4
4     NA
1     5
NA NA


I now want to do a linear regression on y~x with all the NA??s removed. 
The problem now is that is.na(x) (and is.na(y) obviously gives vectors 
with different lengths. How could I solve this problem?

Thank you very much for any help.

Best regards
Chris



From andy_liaw at merck.com  Tue May  4 15:45:47 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 4 May 2004 09:45:47 -0400
Subject: =?ISO-8859-1?Q?RE=3A_=5BR=5D_lm=28y=7Ex=29_question=3A_removin?=
	=?ISO-8859-1?Q?g_NA=B4s?=
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7CF6@usrymx25.merck.com>

By (`factory') default that's done for you automagically, because
options("na.action") is `na.omit'.

If you really want to do it `by hand', and have the data in a data frame,
you can use something like:

lm(y ~ x, df[complete.cases(df),])

HTH,
Andy

> From: Christoph Scherber
> 
> Dear all,
> 
> I have a data frame with different numbers of NA??s in each 
> column, e.g.:
> 
> x       y  
> 1      2
> NA  3
> NA  4
> 4     NA
> 1     5
> NA NA
> 
> 
> I now want to do a linear regression on y~x with all the NA??s 
> removed. 
> The problem now is that is.na(x) (and is.na(y) obviously 
> gives vectors 
> with different lengths. How could I solve this problem?
> 
> Thank you very much for any help.
> 
> Best regards
> Chris
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From Christoph.Scherber at uni-jena.de  Tue May  4 15:55:09 2004
From: Christoph.Scherber at uni-jena.de (Christoph Scherber)
Date: Tue, 04 May 2004 15:55:09 +0200
Subject: [R] more on lm(y~x) question: removing =?iso-8859-1?q?NA=B4s_?=
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7CF6@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7CF6@usrymx25.merck.com>
Message-ID: <4097A0BD.5060404@uni-jena.de>

actually, the situation is much more complicated. I am producing 
multiple graphs within a "for" loop. For some strange reason, the 
plotting routine always stops once lm(y~x) encounters more than one 
missing value (I have marked the important bit with "***********"):

par(mfrow=c(5,5))
p_seq(3,122,2)
i_0
k_0
number_0
for (i in p) {
   j_foranalysis[93:174,i+1]
   k_foranalysis[93:174,i]  
   df_data.frame(j,k)
   mainlab1_substring(names(foranalysis[i]),2,8)
   mainlab2_"; corr.:"
   mainlab3_round(cor(j,k,na.method="available"),4)
   mainlab4_"; excl.Mono:"
   mainlab5_round(cor(j[j<0.9],k[j<0.9],na.method="available"),4)
   mainlab_paste(mainlab1,mainlab2,mainlab3,mainlab4,mainlab5)
   plot(k,j,main=mainlab,xlab="% of total biomass",ylab="% of total 
cover",pch="n")
   for (k in 1:length(foranalysis[93:174,i])) 
number[k]_substring(plotcode[foranalysis[k,1]],1,5)
   text(foranalysis[93:174,i],foranalysis[93:174,i+1],number)
**********************************
   model_lm(j~k,na.action=na.exclude])
**********************************
   abline(model)
   abline(0,1,lty=2)
    }

Does anyone have any suggestions on this?

Best regards
Chris.,




Liaw, Andy wrote:

>By (`factory') default that's done for you automagically, because
>options("na.action") is `na.omit'.
>
>If you really want to do it `by hand', and have the data in a data frame,
>you can use something like:
>
>lm(y ~ x, df[complete.cases(df),])
>
>HTH,
>Andy
>
>  
>
>>From: Christoph Scherber
>>
>>Dear all,
>>
>>I have a data frame with different numbers of NA??s in each 
>>column, e.g.:
>>
>>x       y  
>>1      2
>>NA  3
>>NA  4
>>4     NA
>>1     5
>>NA NA
>>
>>
>>I now want to do a linear regression on y~x with all the NA??s 
>>removed. 
>>The problem now is that is.na(x) (and is.na(y) obviously 
>>gives vectors 
>>with different lengths. How could I solve this problem?
>>
>>Thank you very much for any help.
>>
>>Best regards
>>Chris
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
>>    
>>
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New Jersey, USA 08889), and/or its affiliates (which may be known outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan as Banyu) that may be confidential, proprietary copyrighted and/or legally privileged. It is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please notify us immediately by reply e-mail and then delete it from your system.
>------------------------------------------------------------------------------
>
>  
>



From andy_liaw at merck.com  Tue May  4 16:02:22 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 4 May 2004 10:02:22 -0400
Subject: [R] =?iso-8859-1?q?RE=3A_more_on_lm=28y=7Ex=29_question=3A_remov?=
 =?iso-8859-1?q?ing_NA=B4s_?=
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7CF8@usrymx25.merck.com>

1. If your code actually runs, you should upgrade R, and quit using `_' for
assignment... 8-)

2. You seem to have an extraneous `]' after the na.exclude.  Could that be
the problem?

Andy


> From: Christoph Scherber 
> 
> actually, the situation is much more complicated. I am producing 
> multiple graphs within a "for" loop. For some strange reason, the 
> plotting routine always stops once lm(y~x) encounters more than one 
> missing value (I have marked the important bit with "***********"):
> 
> par(mfrow=c(5,5))
> p_seq(3,122,2)
> i_0
> k_0
> number_0
> for (i in p) {
>    j_foranalysis[93:174,i+1]
>    k_foranalysis[93:174,i]  
>    df_data.frame(j,k)
>    mainlab1_substring(names(foranalysis[i]),2,8)
>    mainlab2_"; corr.:"
>    mainlab3_round(cor(j,k,na.method="available"),4)
>    mainlab4_"; excl.Mono:"
>    mainlab5_round(cor(j[j<0.9],k[j<0.9],na.method="available"),4)
>    mainlab_paste(mainlab1,mainlab2,mainlab3,mainlab4,mainlab5)
>    plot(k,j,main=mainlab,xlab="% of total biomass",ylab="% of total 
> cover",pch="n")
>    for (k in 1:length(foranalysis[93:174,i])) 
> number[k]_substring(plotcode[foranalysis[k,1]],1,5)
>    text(foranalysis[93:174,i],foranalysis[93:174,i+1],number)
> **********************************
>    model_lm(j~k,na.action=na.exclude])
> **********************************
>    abline(model)
>    abline(0,1,lty=2)
>     }
> 
> Does anyone have any suggestions on this?
> 
> Best regards
> Chris.,
> 
> 
> 
> 
> Liaw, Andy wrote:
> 
> >By (`factory') default that's done for you automagically, because
> >options("na.action") is `na.omit'.
> >
> >If you really want to do it `by hand', and have the data in 
> a data frame,
> >you can use something like:
> >
> >lm(y ~ x, df[complete.cases(df),])
> >
> >HTH,
> >Andy
> >
> >  
> >
> >>From: Christoph Scherber
> >>
> >>Dear all,
> >>
> >>I have a data frame with different numbers of NA??s in each 
> >>column, e.g.:
> >>
> >>x       y  
> >>1      2
> >>NA  3
> >>NA  4
> >>4     NA
> >>1     5
> >>NA NA
> >>
> >>
> >>I now want to do a linear regression on y~x with all the NA??s 
> >>removed. 
> >>The problem now is that is.na(x) (and is.na(y) obviously 
> >>gives vectors 
> >>with different lengths. How could I solve this problem?
> >>
> >>Thank you very much for any help.
> >>
> >>Best regards
> >>Chris
> >>
>



From tlumley at u.washington.edu  Tue May  4 16:12:36 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 4 May 2004 07:12:36 -0700 (PDT)
Subject: [R] Epidemiology Tools
In-Reply-To: <20040504014637.44259.qmail@www.boxfrog.com>
References: <20040504014637.44259.qmail@www.boxfrog.com>
Message-ID: <Pine.A41.4.58.0405040652360.64916@homer34.u.washington.edu>

On Mon, 3 May 2004, Francis Dimzon wrote:

> Hi all,
>
> Please help on this.  We will be teaching epidemiology using opensource
> software. What are R built-in functions or functions in available packages
> that are capable of doing these:
>
> a) Logistic regression   (glm?)

glm

> b) Conditional logistic regression

clogit (survival package)

> c) Logistic regression with random effects

It depends what you mean.  Random intercept models are in the glmmML
package, approximate maximum likelihood for more complicated models (PQL) is
available in MASS and nlme packages.  Doug Bates is making progress on
more accurate approximations, but I'm not sure where he's got to.

Personally, I teach marginal models (GEE estimates) before random
effects effects models to epidemiologists. GEE is in the gee and geepack
packages. (I realise this is a minority view, but it is based on
experience).

> d) Beta-binomial regression

Don't know. I'd use a logistic regression model with sandwich variances
(eg gee or glm with robcov from the Design package). I don't see any real
advantage of beta-binomial regression.

> e) Poisson regression
glm

> f) Weibull regression

survreg in the survival package

> g) Exponential regression

For censored data, survreg, for uncensored data, glm

> h) Cox proportional hazards regression
coxph in survival

> i) Cox regression with time repeated covariables
coxph in survival

> j) Kaplan-Meier Analysis and Plots

survfit and survdiff  (for left-truncated data you need to use coxph).

> k) Post-fit analysis with plots, delta-betas, hazard functions
Just about every  model has delta-betas. For the Cox model look at the
help page help(residuals.coxph).

Tests and graphical diagnostics for the proportional hazards assumption
are in cox.zph.  survfit() gives fitted survival curves

Hazard rate functions are estimated by the muhaz package.

> l) meta analysis

rmeta (which is also useful for Mantel-Haenszel-type analyses of
stratified 2x2 tables, and for drawing forest plots even outside
meta-analyses).

	-thomas



From tlumley at u.washington.edu  Tue May  4 16:14:08 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 4 May 2004 07:14:08 -0700 (PDT)
Subject: [R] =?iso-8859-1?q?RE=3A_more_on_lm=28y=7Ex=29_question=3A_remov?=
	=?iso-8859-1?q?ing_NA=B4s_?=
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7CF8@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7CF8@usrymx25.merck.com>
Message-ID: <Pine.A41.4.58.0405040713300.64916@homer34.u.washington.edu>

On Tue, 4 May 2004, Liaw, Andy wrote:

> 1. If your code actually runs, you should upgrade R, and quit using `_' for
> assignment... 8-)
>
> 2. You seem to have an extraneous `]' after the na.exclude.  Could that be
> the problem?

More seriously, the for() loop over k will mess up the value of k that you
want to use for lm.

	-thomas


>
> Andy
>
>
> > From: Christoph Scherber
> >
> > actually, the situation is much more complicated. I am producing
> > multiple graphs within a "for" loop. For some strange reason, the
> > plotting routine always stops once lm(y~x) encounters more than one
> > missing value (I have marked the important bit with "***********"):
> >
> > par(mfrow=c(5,5))
> > p_seq(3,122,2)
> > i_0
> > k_0
> > number_0
> > for (i in p) {
> >    j_foranalysis[93:174,i+1]
> >    k_foranalysis[93:174,i]
> >    df_data.frame(j,k)
> >    mainlab1_substring(names(foranalysis[i]),2,8)
> >    mainlab2_"; corr.:"
> >    mainlab3_round(cor(j,k,na.method="available"),4)
> >    mainlab4_"; excl.Mono:"
> >    mainlab5_round(cor(j[j<0.9],k[j<0.9],na.method="available"),4)
> >    mainlab_paste(mainlab1,mainlab2,mainlab3,mainlab4,mainlab5)
> >    plot(k,j,main=mainlab,xlab="% of total biomass",ylab="% of total
> > cover",pch="n")
> >    for (k in 1:length(foranalysis[93:174,i]))
> > number[k]_substring(plotcode[foranalysis[k,1]],1,5)
> >    text(foranalysis[93:174,i],foranalysis[93:174,i+1],number)
> > **********************************
> >    model_lm(j~k,na.action=na.exclude])
> > **********************************
> >    abline(model)
> >    abline(0,1,lty=2)
> >     }
> >
> > Does anyone have any suggestions on this?
> >
> > Best regards
> > Chris.,
> >
> >
> >
> >
> > Liaw, Andy wrote:
> >
> > >By (`factory') default that's done for you automagically, because
> > >options("na.action") is `na.omit'.
> > >
> > >If you really want to do it `by hand', and have the data in
> > a data frame,
> > >you can use something like:
> > >
> > >lm(y ~ x, df[complete.cases(df),])
> > >
> > >HTH,
> > >Andy
> > >
> > >
> > >
> > >>From: Christoph Scherber
> > >>
> > >>Dear all,
> > >>
> > >>I have a data frame with different numbers of NA??s in each
> > >>column, e.g.:
> > >>
> > >>x       y
> > >>1      2
> > >>NA  3
> > >>NA  4
> > >>4     NA
> > >>1     5
> > >>NA NA
> > >>
> > >>
> > >>I now want to do a linear regression on y~x with all the NA??s
> > >>removed.
> > >>The problem now is that is.na(x) (and is.na(y) obviously
> > >>gives vectors
> > >>with different lengths. How could I solve this problem?
> > >>
> > >>Thank you very much for any help.
> > >>
> > >>Best regards
> > >>Chris
> > >>
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From Christoph.Scherber at uni-jena.de  Tue May  4 16:20:06 2004
From: Christoph.Scherber at uni-jena.de (Christoph Scherber)
Date: Tue, 04 May 2004 16:20:06 +0200
Subject: =?ISO-8859-1?Q?Re=3A_=5BR=5D_RE=3A_more_on_lm=28y=7Ex=29?=
	=?ISO-8859-1?Q?_question=3A_removing_NA=B4s_?=
In-Reply-To: <Pine.A41.4.58.0405040713300.64916@homer34.u.washington.edu>
References: <3A822319EB35174CA3714066D590DCD504AF7CF8@usrymx25.merck.com>
	<Pine.A41.4.58.0405040713300.64916@homer34.u.washington.edu>
Message-ID: <4097A696.6070205@uni-jena.de>

it all works fine (the regression lines fit correctly to the data) as 
long as there are not both missing values in j and k.

What suggestions would you have for this? Or, more precisely, how would 
you create multiple graphs from subsequent columns of a data.frame?



Thomas Lumley wrote:

>On Tue, 4 May 2004, Liaw, Andy wrote:
>
>  
>
>>1. If your code actually runs, you should upgrade R, and quit using `_' for
>>assignment... 8-)
>>
>>2. You seem to have an extraneous `]' after the na.exclude.  Could that be
>>the problem?
>>    
>>
>
>More seriously, the for() loop over k will mess up the value of k that you
>want to use for lm.
>
>	-thomas
>
>
>  
>
>>Andy
>>
>>
>>    
>>
>>>From: Christoph Scherber
>>>
>>>actually, the situation is much more complicated. I am producing
>>>multiple graphs within a "for" loop. For some strange reason, the
>>>plotting routine always stops once lm(y~x) encounters more than one
>>>missing value (I have marked the important bit with "***********"):
>>>
>>>par(mfrow=c(5,5))
>>>p_seq(3,122,2)
>>>i_0
>>>k_0
>>>number_0
>>>for (i in p) {
>>>   j_foranalysis[93:174,i+1]
>>>   k_foranalysis[93:174,i]
>>>   df_data.frame(j,k)
>>>   mainlab1_substring(names(foranalysis[i]),2,8)
>>>   mainlab2_"; corr.:"
>>>   mainlab3_round(cor(j,k,na.method="available"),4)
>>>   mainlab4_"; excl.Mono:"
>>>   mainlab5_round(cor(j[j<0.9],k[j<0.9],na.method="available"),4)
>>>   mainlab_paste(mainlab1,mainlab2,mainlab3,mainlab4,mainlab5)
>>>   plot(k,j,main=mainlab,xlab="% of total biomass",ylab="% of total
>>>cover",pch="n")
>>>   for (k in 1:length(foranalysis[93:174,i]))
>>>number[k]_substring(plotcode[foranalysis[k,1]],1,5)
>>>   text(foranalysis[93:174,i],foranalysis[93:174,i+1],number)
>>>**********************************
>>>   model_lm(j~k,na.action=na.exclude])
>>>**********************************
>>>   abline(model)
>>>   abline(0,1,lty=2)
>>>    }
>>>
>>>Does anyone have any suggestions on this?
>>>
>>>Best regards
>>>Chris.,
>>>
>>>
>>>
>>>
>>>Liaw, Andy wrote:
>>>
>>>      
>>>
>>>>By (`factory') default that's done for you automagically, because
>>>>options("na.action") is `na.omit'.
>>>>
>>>>If you really want to do it `by hand', and have the data in
>>>>        
>>>>
>>>a data frame,
>>>      
>>>
>>>>you can use something like:
>>>>
>>>>lm(y ~ x, df[complete.cases(df),])
>>>>
>>>>HTH,
>>>>Andy
>>>>
>>>>
>>>>
>>>>        
>>>>
>>>>>From: Christoph Scherber
>>>>>
>>>>>Dear all,
>>>>>
>>>>>I have a data frame with different numbers of NA??s in each
>>>>>column, e.g.:
>>>>>
>>>>>x       y
>>>>>1      2
>>>>>NA  3
>>>>>NA  4
>>>>>4     NA
>>>>>1     5
>>>>>NA NA
>>>>>
>>>>>
>>>>>I now want to do a linear regression on y~x with all the NA??s
>>>>>removed.
>>>>>The problem now is that is.na(x) (and is.na(y) obviously
>>>>>gives vectors
>>>>>with different lengths. How could I solve this problem?
>>>>>
>>>>>Thank you very much for any help.
>>>>>
>>>>>Best regards
>>>>>Chris
>>>>>
>>>>>          
>>>>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>    
>>
>
>Thomas Lumley			Assoc. Professor, Biostatistics
>tlumley at u.washington.edu	University of Washington, Seattle
>
>  
>



From ramasamy at cancer.org.uk  Tue May  4 16:25:03 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: 04 May 2004 15:25:03 +0100
Subject: [R] more on lm(y~x) question: removing =?ISO-8859-1?Q?NA=B4s?=
In-Reply-To: <4097A0BD.5060404@uni-jena.de>
References: <3A822319EB35174CA3714066D590DCD504AF7CF6@usrymx25.merck.com>
	<4097A0BD.5060404@uni-jena.de>
Message-ID: <1083680703.4412.41.camel@vpn202001.lif.icnet.uk>

1. There should have been warning or error when using "_" as it is
depreceated. Use "<-" instead.
2. There is an extra "]"
3. Could it be that after removing all the cases with NA, you do not
have sufficient observations. Example :

> j <- c(NA, 2, NA,  4, NA)
> k <- c(1, NA,  3, NA,  5)
> lm(j~k,na.action=na.exclude)
Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
        0 (non-NA) cases

4. I would suggest you put a 'cat(i, "before", "\n") or something
similar before and after the problematic syntax to find out which values
of i is causing the problem.



On Tue, 2004-05-04 at 14:55, Christoph Scherber wrote:
> actually, the situation is much more complicated. I am producing 
> multiple graphs within a "for" loop. For some strange reason, the 
> plotting routine always stops once lm(y~x) encounters more than one 
> missing value (I have marked the important bit with "***********"):
> 
> par(mfrow=c(5,5))
> p_seq(3,122,2)
> i_0
> k_0
> number_0
> for (i in p) {
>    j_foranalysis[93:174,i+1]
>    k_foranalysis[93:174,i]  
>    df_data.frame(j,k)
>    mainlab1_substring(names(foranalysis[i]),2,8)
>    mainlab2_"; corr.:"
>    mainlab3_round(cor(j,k,na.method="available"),4)
>    mainlab4_"; excl.Mono:"
>    mainlab5_round(cor(j[j<0.9],k[j<0.9],na.method="available"),4)
>    mainlab_paste(mainlab1,mainlab2,mainlab3,mainlab4,mainlab5)
>    plot(k,j,main=mainlab,xlab="% of total biomass",ylab="% of total 
> cover",pch="n")
>    for (k in 1:length(foranalysis[93:174,i])) 
> number[k]_substring(plotcode[foranalysis[k,1]],1,5)
>    text(foranalysis[93:174,i],foranalysis[93:174,i+1],number)
> **********************************
>    model_lm(j~k,na.action=na.exclude])
> **********************************
>    abline(model)
>    abline(0,1,lty=2)
>     }
> 
> Does anyone have any suggestions on this?
> 
> Best regards
> Chris.,
> 
> 
> 
> 
> Liaw, Andy wrote:
> 
> >By (`factory') default that's done for you automagically, because
> >options("na.action") is `na.omit'.
> >
> >If you really want to do it `by hand', and have the data in a data frame,
> >you can use something like:
> >
> >lm(y ~ x, df[complete.cases(df),])
> >
> >HTH,
> >Andy
> >
> >  
> >
> >>From: Christoph Scherber
> >>
> >>Dear all,
> >>
> >>I have a data frame with different numbers of NAs in each 
> >>column, e.g.:
> >>
> >>x       y  
> >>1      2
> >>NA  3
> >>NA  4
> >>4     NA
> >>1     5
> >>NA NA
> >>
> >>
> >>I now want to do a linear regression on y~x with all the NAs 
> >>removed. 
> >>The problem now is that is.na(x) (and is.na(y) obviously 
> >>gives vectors 
> >>with different lengths. How could I solve this problem?
> >>
> >>Thank you very much for any help.
> >>
> >>Best regards
> >>Chris
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! 
> >>http://www.R-project.org/posting-guide.html
> >>
> >>
> >>    
> >>
> >
> >
> >------------------------------------------------------------------------------
> >Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New Jersey, USA 08889), and/or its affiliates (which may be known outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan as Banyu) that may be confidential, proprietary copyrighted and/or legally privileged. It is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please notify us immediately by reply e-mail and then delete it from your system.
> >------------------------------------------------------------------------------
> >
> >  
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
--



From fm3a004 at math.uni-hamburg.de  Tue May  4 16:36:49 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Tue, 4 May 2004 16:36:49 +0200 (MET DST)
Subject: [R] spdep question
Message-ID: <Pine.GSO.3.95q.1040504163459.29042E-100000@sun11.math.uni-hamburg.de>

Dear list,

(also sent to Roger Bivand, but perhaps somebody of you can help me also)

I am trying to use package spdep for fitting an SAR model with errorsarlm.
However, I am not sure how to make a valid nb object out of my
neighborhood. As far as I have seen, there is no documentation for
nb.object.

I have done the following:

class(pschmid$nb) <- "nb"
# pschmid is a prab object as generated from function prabinit, package
# prabclus, and the neighborhood looks as follows:
> unclass(pschmid$nb)
[[1]]
 [1]  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

[[2]]
 [1]  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

[[3]]
 [1]  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

(...and so on, a list of 65 integer vectors, up to...)

[[65]]
 [1] 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59
60 61
[26] 62 63 64

# This looks more or less like the example (cal.gol.nb), apart from some
# attribs which I do not understand, and it is exactly
# how an nb object is described in help(read.gal). But...

> summary(pschmid$nb)
Neighbour list object:
Number of regions: 65 
Number of nonzero links: 0 
Percentage nonzero weights: 0 
Average number of links: 0 
65 regions with no links:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
54 55 56 57 58 59 60 61 62 63 64 65
Link number distribution:

 0 
65 

# Why are there no links? Do I understand properly what a link is?
# 1 is a neighbor of 2 and vice versa, so I consider them linked?

Can somebody tell me how to turn my neighborhood into an object errorsarlm
and nb2listw (do I need that?) can handle!

Best,
Christian

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From HStevens at MUOhio.edu  Tue May  4 16:41:18 2004
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Tue, 4 May 2004 10:41:18 -0400
Subject: [R] degrees of freedom in lm() treatment contrasts
Message-ID: <1A5736AC-9DD9-11D8-A6A2-000A958F43CC@MUOhio.edu>

Does anyone have a good (and specific) reference for an explanation for 
the calculation of degrees of freedom in treatment contrasts? I checked 
the indexes of Venables and Ripley 2002, Crawley 2002, and Neter et al. 
(Applied Linear Statistical Models, 4th ed.), as well as the lm code. I 
would happily accept a "verbal" email explanation as well.
Many thanks,
Hank Stevens

338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/



From fm3a004 at math.uni-hamburg.de  Tue May  4 16:45:19 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Tue, 4 May 2004 16:45:19 +0200 (MET DST)
Subject: [R] More spatial modeling
Message-ID: <Pine.GSO.3.95q.1040504164128.29042F-100000@sun11.math.uni-hamburg.de>

Hi,

is there any function to fit a spatial CAR model or to compute the
iterated Papadakis method as in Sec. 5.2/5.3 of Ripley (1981) Spatial
Statistics? errorsarlm in spdep seems to be the SAR fit, or are there
alternatives for that? (Only methods based on neighborhood lists are of
interest here; distances between the regions are not available.)

Christian

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From Ted.Harding at nessie.mcc.ac.uk  Tue May  4 16:48:23 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 04 May 2004 15:48:23 +0100 (BST)
Subject: [R] Superposing data on boxplot
Message-ID: <XFMail.040504154823.Ted.Harding@nessie.mcc.ac.uk>

Hi folks,

I have a vaiable Y and an associated factor Z at several (13)
levels.

  boxplot(Y~Z)

produces a nice array of boxplots, one for each level of Z,
and each duly labaelled with its level of Z.

I would like to superpose on each boxplot the actual data
points which it represents, i.e. do something conceptually
(though not in real R) expressed as

  points(Y~Z)

or

  points(Z,Y)

It can be done "with bare hands" along the lines of

  B<-boxplot(Y~Z)
  x<-bxp(B)
  X<-rep(x,ngroups)
  points(X,Y)

where ngroups is the number of data at each level of Z,
*provided* the data are pre-sorted by level of Z and in the
same order as these levels occurr in the boxplot. But of course
they're not!

OK, I could do this by hand as well, but now it's getting a bit
tedious, and I'm wondering if there's a better way.

Thanks for any suggestions,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 04-May-04                                       Time: 15:48:23
------------------------------ XFMail ------------------------------



From andy_liaw at merck.com  Tue May  4 17:10:19 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 4 May 2004 11:10:19 -0400
Subject: [R] Superposing data on boxplot
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7CFC@usrymx25.merck.com>

Try:

y = rnorm(50)
z = factor(rep(1:5, each=10))
boxplot(y~z, horizontal=TRUE)
stripchart(y~z, add=TRUE)


HTH,
Andy

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Ted.Harding at nessie.mcc.ac.uk
> Sent: Tuesday, May 04, 2004 10:48 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Superposing data on boxplot
> 
> 
> Hi folks,
> 
> I have a vaiable Y and an associated factor Z at several (13)
> levels.
> 
>   boxplot(Y~Z)
> 
> produces a nice array of boxplots, one for each level of Z,
> and each duly labaelled with its level of Z.
> 
> I would like to superpose on each boxplot the actual data
> points which it represents, i.e. do something conceptually
> (though not in real R) expressed as
> 
>   points(Y~Z)
> 
> or
> 
>   points(Z,Y)
> 
> It can be done "with bare hands" along the lines of
> 
>   B<-boxplot(Y~Z)
>   x<-bxp(B)
>   X<-rep(x,ngroups)
>   points(X,Y)
> 
> where ngroups is the number of data at each level of Z,
> *provided* the data are pre-sorted by level of Z and in the
> same order as these levels occurr in the boxplot. But of course
> they're not!
> 
> OK, I could do this by hand as well, but now it's getting a bit
> tedious, and I'm wondering if there's a better way.
> 
> Thanks for any suggestions,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 04-May-04                                       Time: 15:48:23
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ltarca at rsvs.ulaval.ca  Tue May  4 17:12:30 2004
From: ltarca at rsvs.ulaval.ca (Tarca Adi Laurentiu)
Date: Tue, 04 May 2004 11:12:30 -0400
Subject: [R] nnet function
Message-ID: <6.0.0.22.2.20040504111037.01c39a38@biota.rsvs.ulaval.ca>



Hi I got two questions about the nnet function in R. I would be thankful to 
have an answer.

1) Does the function intrinsically normalize the X and Y matrices before 
the training, or normalization should be
done by the user.
  2) I need to understand the $wts matrix. I do imagine that it is a single 
column transformation of the two
matrices of weighs (input to hidden Ninputs+1 x Nodes) and hidden to output 
(Nodes+1 x Noutputs).

Thanks
----------------------------------------------
Dr. Laurentiu Adi Tarca
Post Doc. in Bioinformatics
Forest Biology Research Center
C-E-Marchand Bld, 3113
Laval University
Quebec, (Qc)
G1K-7P4
Tel: 656-2131 ext. 4509
e-mail: ltarca at rsvs.ulaval.ca



From s-plus at wiwi.uni-bielefeld.de  Tue May  4 17:14:28 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Tue, 04 May 2004 17:14:28 +0200
Subject: [R] Superposing data on boxplot
References: <XFMail.040504154823.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <4097B354.30208@wiwi.uni-bielefeld.de>

What about:

y<-rnorm(100);z<-sample(1:7,100,T);boxplot(y~z);points(y~z)

Peter Wolf

Ted Harding wrote:

>Hi folks,
>
>I have a vaiable Y and an associated factor Z at several (13)
>levels.
>
>  boxplot(Y~Z)
>
>produces a nice array of boxplots, one for each level of Z,
>and each duly labaelled with its level of Z.
>
>I would like to superpose on each boxplot the actual data
>points which it represents, i.e. do something conceptually
>(though not in real R) expressed as
>
>  points(Y~Z)
>
>or
>
>  points(Z,Y)
>
>It can be done "with bare hands" along the lines of
>
>  B<-boxplot(Y~Z)
>  x<-bxp(B)
>  X<-rep(x,ngroups)
>  points(X,Y)
>
>where ngroups is the number of data at each level of Z,
>*provided* the data are pre-sorted by level of Z and in the
>same order as these levels occurr in the boxplot. But of course
>they're not!
>
>OK, I could do this by hand as well, but now it's getting a bit
>tedious, and I'm wondering if there's a better way.
>
>Thanks for any suggestions,
>Ted.
>
>
>--------------------------------------------------------------------
>E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
>Fax-to-email: +44 (0)870 167 1972
>Date: 04-May-04                                       Time: 15:48:23
>------------------------------ XFMail ------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From Anne.Olga.Piotet at omsv.vd.ch  Tue May  4 17:19:06 2004
From: Anne.Olga.Piotet at omsv.vd.ch (Anne Piotet)
Date: Tue, 4 May 2004 17:19:06 +0200
Subject: [R] Installing Hmisc after upgrade
Message-ID: <001201c431eb$246f3540$83dad10a@prod.omsv.ch>

Hello
I just upgraded my version of R to 1.9.0 for Windows (2000 and XP)
When trying to run the library Hmisc I get the following error:

Error in testRversion(descfields) : This package has not been installed
properly
 See the Note in ?library

Till now, I had no problem with other libraries...

How do I correct the problem?

Thanks
Anne



From srkim at jhsph.edu  Tue May  4 17:21:37 2004
From: srkim at jhsph.edu (Sung Kim)
Date: Tue, 04 May 2004 11:21:37 -0400
Subject: [R] Sampling 1000 times from a bivariate normal distibution
Message-ID: <000001c431eb$7e06ffc0$6680110a@srkim1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040504/b4ec013f/attachment.pl

From ripley at stats.ox.ac.uk  Tue May  4 17:29:43 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 May 2004 16:29:43 +0100 (BST)
Subject: [R] nnet function
In-Reply-To: <6.0.0.22.2.20040504111037.01c39a38@biota.rsvs.ulaval.ca>
Message-ID: <Pine.LNX.4.44.0405041627090.16360-100000@gannet.stats>

On Tue, 4 May 2004, Tarca Adi Laurentiu wrote:

> Hi I got two questions about the nnet function in R. I would be thankful to 
> have an answer.

I don't think you have consulted the book this R code supports: please do 
so.

> 1) Does the function intrinsically normalize the X and Y matrices before 
> the training, or normalization should be
> done by the user.

The documentation (p.247) answers that.

>   2) I need to understand the $wts matrix. I do imagine that it is a single 
> column transformation of the two
> matrices of weighs (input to hidden Ninputs+1 x Nodes) and hidden to output 
> (Nodes+1 x Noutputs).

There are no `matrices' of weights, just weights along links in the 
network.  See the documentation for all the details.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Tue May  4 17:30:39 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 4 May 2004 08:30:39 -0700 (PDT)
Subject: =?ISO-8859-1?Q?Re=3A_=5BR=5D_RE=3A_more_on_lm=28y=7Ex=29?=
	=?ISO-8859-1?Q?_question=3A_removing_NA=B4s_?=
In-Reply-To: <4097A696.6070205@uni-jena.de>
References: <3A822319EB35174CA3714066D590DCD504AF7CF8@usrymx25.merck.com>
	<Pine.A41.4.58.0405040713300.64916@homer34.u.washington.edu>
	<4097A696.6070205@uni-jena.de>
Message-ID: <Pine.A41.4.58.0405040808200.152504@homer38.u.washington.edu>

On Tue, 4 May 2004, Christoph Scherber wrote:

> it all works fine (the regression lines fit correctly to the data) as
> long as there are not both missing values in j and k.

That's very strange.  The lines
 for (k in 1:length(foranalysis[93:174,i]))
     number[k]_substring(plotcode[foranalysis[k,1]],1,5)

should set result in k being the scalar value 81 after the loop is over.
In R (unlike S-PLUS), loop indices are just ordinary variables in the
environment where the loop is executed. I'd expect this code to work in
S-PLUS but not in R.

That loop is actually redundant, since substring() is vectorised:
	number <- substring(plotcode[foranalysis[93:174,1]],1,5)
should work just as well.

It's also strange that you create a data frame df from j and k but don't
use it in the lm() call (or AFAICS anywhere else).

>
> What suggestions would you have for this? Or, more precisely, how would
> you create multiple graphs from subsequent columns of a data.frame?

I'd probably use lsfit. The following is obviously not tested, since I
don't have the data (or even understand fully the data layout).

L <- length(93:174)
for(i in p) {
	X<-foranalysis[93:174, i]
	Y<-foranalysis[93:174, i+1]
	corr<-cor(X,Y)
	corrtrunc<-cor(X[X<0.9], Y[X<0.9])
	mainlab <- paste(substring(names(foranalysis[i]), 2, 8),
			"; corr.:", corr,
			";excl.Mono", corrtrunc))
        plot(X,Y,main=mainlab,
		xlab="% of total biomass",ylab="% of total cover",pch="n")
	number <- substring(plotcode[foranalysis[1:L,1]], 1, 5)
	text(X, Y, number)
	model <- lsfit(X,Y)
	abline(model)
	abline(0, 1, lty=2)
    }


	-thomas

> >>>
> >>>par(mfrow=c(5,5))
> >>>p_seq(3,122,2)
> >>>i_0
> >>>k_0
> >>>number_0
> >>>for (i in p) {
> >>>   j_foranalysis[93:174,i+1]
> >>>   k_foranalysis[93:174,i]
> >>>   df_data.frame(j,k)
> >>>   mainlab1_substring(names(foranalysis[i]),2,8)
> >>>   mainlab2_"; corr.:"
> >>>   mainlab3_round(cor(j,k,na.method="available"),4)
> >>>   mainlab4_"; excl.Mono:"
> >>>   mainlab5_round(cor(j[j<0.9],k[j<0.9],na.method="available"),4)
> >>>   mainlab_paste(mainlab1,mainlab2,mainlab3,mainlab4,mainlab5)
> >>>   plot(k,j,main=mainlab,xlab="% of total biomass",ylab="% of total
> >>>cover",pch="n")
> >>>   for (k in 1:length(foranalysis[93:174,i]))
> >>>number[k]_substring(plotcode[foranalysis[k,1]],1,5)
> >>>   text(foranalysis[93:174,i],foranalysis[93:174,i+1],number)
> >>>**********************************
> >>>   model_lm(j~k,na.action=na.exclude])
> >>>**********************************
> >>>   abline(model)
> >>>   abline(0,1,lty=2)
> >>>    }
> >>>
> >>>Does anyone have any suggestions on this?
> >>>
> >>>Best regards
> >>>Chris.,
> >>>
> >>>
> >>>
> >>>
> >>>Liaw, Andy wrote:
> >>>
> >>>
> >>>
> >>>>By (`factory') default that's done for you automagically, because
> >>>>options("na.action") is `na.omit'.
> >>>>
> >>>>If you really want to do it `by hand', and have the data in
> >>>>
> >>>>
> >>>a data frame,
> >>>
> >>>
> >>>>you can use something like:
> >>>>
> >>>>lm(y ~ x, df[complete.cases(df),])
> >>>>
> >>>>HTH,
> >>>>Andy
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>>From: Christoph Scherber
> >>>>>
> >>>>>Dear all,
> >>>>>
> >>>>>I have a data frame with different numbers of NA??s in each
> >>>>>column, e.g.:
> >>>>>
> >>>>>x       y
> >>>>>1      2
> >>>>>NA  3
> >>>>>NA  4
> >>>>>4     NA
> >>>>>1     5
> >>>>>NA NA
> >>>>>
> >>>>>
> >>>>>I now want to do a linear regression on y~x with all the NA??s
> >>>>>removed.
> >>>>>The problem now is that is.na(x) (and is.na(y) obviously
> >>>>>gives vectors
> >>>>>with different lengths. How could I solve this problem?
> >>>>>
> >>>>>Thank you very much for any help.
> >>>>>
> >>>>>Best regards
> >>>>>Chris
> >>>>>
> >>>>>
> >>>>>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>
> >>
> >>
> >
> >Thomas Lumley			Assoc. Professor, Biostatistics
> >tlumley at u.washington.edu	University of Washington, Seattle
> >
> >
> >
>
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From Achim.Zeileis at wu-wien.ac.at  Tue May  4 17:34:34 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 4 May 2004 17:34:34 +0200
Subject: [R] Sampling 1000 times from a bivariate normal distibution
In-Reply-To: <000001c431eb$7e06ffc0$6680110a@srkim1>
References: <000001c431eb$7e06ffc0$6680110a@srkim1>
Message-ID: <20040504173434.0d536e9a.Achim.Zeileis@wu-wien.ac.at>

On Tue, 04 May 2004 11:21:37 -0400 Sung Kim wrote:

> Dear expert,
> 
> I have two coefficients and covariance matrix. 
> 
> My objective is sampling 1000 times from the mean and covariance
> matrix.
> 
> In order to get that, what kind of commend should I use?
> 
> If you do not mind, could you tell me the comment in detail about
> parameter used in that commend also? 
> 

Look at rmvnorm in package mvtnorm:

library(mvtnorm)
help(rmvnorm)

m <- c(10, 40)
S <- matrix(c(10, 80, 80, 30), ncol = 2)
x <- rmvnorm(n = 1000, mean = m, sigma = S)
plot(x)

hth
Z
  
> 
> Thank you.
> 
>  
> 
> Sung.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From rpeng at jhsph.edu  Tue May  4 17:38:32 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 04 May 2004 11:38:32 -0400
Subject: [R] Sampling 1000 times from a bivariate normal distibution
In-Reply-To: <000001c431eb$7e06ffc0$6680110a@srkim1>
References: <000001c431eb$7e06ffc0$6680110a@srkim1>
Message-ID: <4097B8F8.9040902@jhsph.edu>

The MASS library has the function mvrnorm() which you should be able 
to use.

-roger

Sung Kim wrote:
> Dear expert,
> 
>  
> 
> I have two coefficients and covariance matrix. 
> 
>  
> 
> My objective is sampling 1000 times from the mean and covariance matrix.
> 
>  
> 
> In order to get that, what kind of commend should I use?
> 
>  
> 
> If you do not mind, could you tell me the comment in detail about
> parameter used in that commend also? 
> 
>  
> 
> Thank you.
> 
>  
> 
> Sung.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From myao at ou.edu  Tue May  4 17:40:03 2004
From: myao at ou.edu (Yao, Minghua)
Date: Tue, 4 May 2004 10:40:03 -0500
Subject: [R] Problems in plot
Message-ID: <78B50CF247E5D04B8A5E02D001CC8E9A595C56@XMAIL.sooner.net.ou.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040504/bd78c68d/attachment.pl

From ripley at stats.ox.ac.uk  Tue May  4 17:49:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 May 2004 16:49:55 +0100 (BST)
Subject: [R] Problems in plot
In-Reply-To: <78B50CF247E5D04B8A5E02D001CC8E9A595C56@XMAIL.sooner.net.ou.edu>
Message-ID: <Pine.LNX.4.44.0405041646110.16915-100000@gannet.stats>

You have been asked for a reproducible set of conditions -- this is the 
first time `minimized' has been mentioned.  If you can find a completely 
reproducible set of actions please file a bug report (after reading the 
FAQ section carefully).

We cannot help you otherwise, and don't want to spend time guessing what 
you might have forgotten to tell us.  (I see you have not told us if you 
use MDI or SDI mode, for example.)


On Tue, 4 May 2004, Yao, Minghua wrote:

> It seems to me that the problem happens to the graphic window that is
> generated immediately after the R window is minimized.
>  
> Minghua 
> 
> ________________________________
> 
> From: r-help-bounces at stat.math.ethz.ch on behalf of Yao, Minghua
> Sent: Fri 4/30/2004 4:12 PM
> To: Prof Brian Ripley
> Cc: R Help
> Subject: RE: [R] Problems in plot
> 
> 
> 
> The problem is still there if windows() is used.
> 
> Minghua
> 
> ________________________________
> 
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Thu 4/29/2004 9:31 AM
> To: Yao, Minghua
> Cc: R Help
> Subject: Re: [R] Problems in plot
> 
> 
> 
> The primary graphics device under Windows is called *windows* not *x11*.
> 
> Something in your Windows setup is sometimes failing to choose a
> reasonable window size.  I have never seen that, and suspect it is nothing
> to do with it, but please use windows() and see if the problem vanishes.
> 
> On Thu, 29 Apr 2004, Yao, Minghua wrote:
> 
> > Hello,
> >
> >
> >
> > I have R1.9.0 under Windows XP. My program plots several plots using
> >
> > x11()
> > par(cex = 0.75)
> > ......
> > x11()
> > par(cex = 0.75)
> > ......
> > x11()
> > par(cex = 0.75)
> > ......
> > x11()
> > par(cex = 0.75)
> > ......
> >
> > Sometimes, one of them generates  a small frame only with title area "R graphics: Device X (ACTIVE)". The message in the console window is
> >
> > Error in plot.new() : Figure margins too large
> >
> > This program ran well under R1.6.X under Windows NT.
> >
> > It seems to me that it is not a specific x11() that generates that small graphics frame.
> >
> > Thank you for you help in advance.
> >
> > Minghua


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Roger.Bivand at nhh.no  Tue May  4 17:52:48 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 4 May 2004 17:52:48 +0200 (CEST)
Subject: [R] spdep question
In-Reply-To: <Pine.GSO.3.95q.1040504163459.29042E-100000@sun11.math.uni-hamburg.de>
Message-ID: <Pine.LNX.4.44.0405041747500.19922-100000@reclus.nhh.no>

On Tue, 4 May 2004, Christian Hennig wrote:

> Dear list,
> 
> (also sent to Roger Bivand, but perhaps somebody of you can help me also)
> 
> I am trying to use package spdep for fitting an SAR model with errorsarlm.
> However, I am not sure how to make a valid nb object out of my
> neighborhood. As far as I have seen, there is no documentation for
> nb.object.
> 

Well, there is always the code ... if you look at tri2nb(), there may be 
some ideas you can use to construct an "nb" object that is recognised as 
such. If you attach me a saved copy of your object, I'll take a look. What 
does str(pschmid$nb) say? Does that look the same as the examples in 
spdep? 

> I have done the following:
> 
> class(pschmid$nb) <- "nb"
> # pschmid is a prab object as generated from function prabinit, package
> # prabclus, and the neighborhood looks as follows:
> > unclass(pschmid$nb)
> [[1]]
>  [1]  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
> 
> [[2]]
>  [1]  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
> 
> [[3]]
>  [1]  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
> 
> (...and so on, a list of 65 integer vectors, up to...)
> 
> [[65]]
>  [1] 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59
> 60 61
> [26] 62 63 64
> 
> # This looks more or less like the example (cal.gol.nb), apart from some
> # attribs which I do not understand, and it is exactly
> # how an nb object is described in help(read.gal). But...
> 
> > summary(pschmid$nb)
> Neighbour list object:
> Number of regions: 65 
> Number of nonzero links: 0 
> Percentage nonzero weights: 0 
> Average number of links: 0 
> 65 regions with no links:
> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
> 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
> 54 55 56 57 58 59 60 61 62 63 64 65
> Link number distribution:
> 
>  0 
> 65 
> 
> # Why are there no links? Do I understand properly what a link is?
> # 1 is a neighbor of 2 and vice versa, so I consider them linked?
> 
> Can somebody tell me how to turn my neighborhood into an object errorsarlm
> and nb2listw (do I need that?) can handle!
> 
> Best,
> Christian
> 
> ***********************************************************************
> Christian Hennig
> Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
> hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
> #######################################################################
> ich empfehle www.boag-online.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Tue May  4 17:56:02 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 4 May 2004 17:56:02 +0200 (CEST)
Subject: [R] More spatial modeling
In-Reply-To: <Pine.GSO.3.95q.1040504164128.29042F-100000@sun11.math.uni-hamburg.de>
Message-ID: <Pine.LNX.4.44.0405041753390.19922-100000@reclus.nhh.no>

On Tue, 4 May 2004, Christian Hennig wrote:

> Hi,
> 
> is there any function to fit a spatial CAR model or to compute the
> iterated Papadakis method as in Sec. 5.2/5.3 of Ripley (1981) Spatial
> Statistics? errorsarlm in spdep seems to be the SAR fit, or are there
> alternatives for that? (Only methods based on neighborhood lists are of
> interest here; distances between the regions are not available.)

Contribution of a CAR model fitting function would be welcome, yes, 
errorsarlm is a SAR (simultaneous autoregressive), but bits of it could be 
recycled.

> 
> Christian
> 
> ***********************************************************************
> Christian Hennig
> Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
> hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
> #######################################################################
> ich empfehle www.boag-online.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From Christoph.Scherber at uni-jena.de  Tue May  4 17:59:13 2004
From: Christoph.Scherber at uni-jena.de (Christoph Scherber)
Date: Tue, 04 May 2004 17:59:13 +0200
Subject: =?ISO-8859-1?Q?Re=3A_=5BR=5D_RE=3A_more_on_lm=28y=7Ex=29?=
	=?ISO-8859-1?Q?_question=3A_removing_NA=B4s_?=
In-Reply-To: <Pine.A41.4.58.0405040808200.152504@homer38.u.washington.edu>
References: <3A822319EB35174CA3714066D590DCD504AF7CF8@usrymx25.merck.com>
	<Pine.A41.4.58.0405040713300.64916@homer34.u.washington.edu>
	<4097A696.6070205@uni-jena.de>
	<Pine.A41.4.58.0405040808200.152504@homer38.u.washington.edu>
Message-ID: <4097BDD1.6040305@uni-jena.de>

Great!!! This works, many thanks!

**************
using lsfit(x,y) instead of lm(y~x)  produces a perfectly correct output.
***************




Thomas Lumley wrote:

>On Tue, 4 May 2004, Christoph Scherber wrote:
>
>  
>
>>it all works fine (the regression lines fit correctly to the data) as
>>long as there are not both missing values in j and k.
>>    
>>
>
>That's very strange.  The lines
> for (k in 1:length(foranalysis[93:174,i]))
>     number[k]_substring(plotcode[foranalysis[k,1]],1,5)
>
>should set result in k being the scalar value 81 after the loop is over.
>In R (unlike S-PLUS), loop indices are just ordinary variables in the
>environment where the loop is executed. I'd expect this code to work in
>S-PLUS but not in R.
>
>That loop is actually redundant, since substring() is vectorised:
>	number <- substring(plotcode[foranalysis[93:174,1]],1,5)
>should work just as well.
>
>It's also strange that you create a data frame df from j and k but don't
>use it in the lm() call (or AFAICS anywhere else).
>
>  
>
>>What suggestions would you have for this? Or, more precisely, how would
>>you create multiple graphs from subsequent columns of a data.frame?
>>    
>>
>
>I'd probably use lsfit. The following is obviously not tested, since I
>don't have the data (or even understand fully the data layout).
>
>L <- length(93:174)
>for(i in p) {
>	X<-foranalysis[93:174, i]
>	Y<-foranalysis[93:174, i+1]
>	corr<-cor(X,Y)
>	corrtrunc<-cor(X[X<0.9], Y[X<0.9])
>	mainlab <- paste(substring(names(foranalysis[i]), 2, 8),
>			"; corr.:", corr,
>			";excl.Mono", corrtrunc))
>        plot(X,Y,main=mainlab,
>		xlab="% of total biomass",ylab="% of total cover",pch="n")
>	number <- substring(plotcode[foranalysis[1:L,1]], 1, 5)
>	text(X, Y, number)
>	model <- lsfit(X,Y)
>	abline(model)
>	abline(0, 1, lty=2)
>    }
>
>
>	-thomas
>
>  
>
>>>>>par(mfrow=c(5,5))
>>>>>p_seq(3,122,2)
>>>>>i_0
>>>>>k_0
>>>>>number_0
>>>>>for (i in p) {
>>>>>  j_foranalysis[93:174,i+1]
>>>>>  k_foranalysis[93:174,i]
>>>>>  df_data.frame(j,k)
>>>>>  mainlab1_substring(names(foranalysis[i]),2,8)
>>>>>  mainlab2_"; corr.:"
>>>>>  mainlab3_round(cor(j,k,na.method="available"),4)
>>>>>  mainlab4_"; excl.Mono:"
>>>>>  mainlab5_round(cor(j[j<0.9],k[j<0.9],na.method="available"),4)
>>>>>  mainlab_paste(mainlab1,mainlab2,mainlab3,mainlab4,mainlab5)
>>>>>  plot(k,j,main=mainlab,xlab="% of total biomass",ylab="% of total
>>>>>cover",pch="n")
>>>>>  for (k in 1:length(foranalysis[93:174,i]))
>>>>>number[k]_substring(plotcode[foranalysis[k,1]],1,5)
>>>>>  text(foranalysis[93:174,i],foranalysis[93:174,i+1],number)
>>>>>**********************************
>>>>>  model_lm(j~k,na.action=na.exclude])
>>>>>**********************************
>>>>>  abline(model)
>>>>>  abline(0,1,lty=2)
>>>>>   }
>>>>>
>>>>>Does anyone have any suggestions on this?
>>>>>
>>>>>Best regards
>>>>>Chris.,
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>Liaw, Andy wrote:
>>>>>
>>>>>
>>>>>
>>>>>          
>>>>>
>>>>>>By (`factory') default that's done for you automagically, because
>>>>>>options("na.action") is `na.omit'.
>>>>>>
>>>>>>If you really want to do it `by hand', and have the data in
>>>>>>
>>>>>>
>>>>>>            
>>>>>>
>>>>>a data frame,
>>>>>
>>>>>
>>>>>          
>>>>>
>>>>>>you can use something like:
>>>>>>
>>>>>>lm(y ~ x, df[complete.cases(df),])
>>>>>>
>>>>>>HTH,
>>>>>>Andy
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>            
>>>>>>
>>>>>>>From: Christoph Scherber
>>>>>>>
>>>>>>>Dear all,
>>>>>>>
>>>>>>>I have a data frame with different numbers of NA??s in each
>>>>>>>column, e.g.:
>>>>>>>
>>>>>>>x       y
>>>>>>>1      2
>>>>>>>NA  3
>>>>>>>NA  4
>>>>>>>4     NA
>>>>>>>1     5
>>>>>>>NA NA
>>>>>>>
>>>>>>>
>>>>>>>I now want to do a linear regression on y~x with all the NA??s
>>>>>>>removed.
>>>>>>>The problem now is that is.na(x) (and is.na(y) obviously
>>>>>>>gives vectors
>>>>>>>with different lengths. How could I solve this problem?
>>>>>>>
>>>>>>>Thank you very much for any help.
>>>>>>>
>>>>>>>Best regards
>>>>>>>Chris
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>              
>>>>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>>
>>>>
>>>>
>>>>        
>>>>
>>>Thomas Lumley			Assoc. Professor, Biostatistics
>>>tlumley at u.washington.edu	University of Washington, Seattle
>>>
>>>
>>>
>>>      
>>>
>>    
>>
>
>Thomas Lumley			Assoc. Professor, Biostatistics
>tlumley at u.washington.edu	University of Washington, Seattle
>
>  
>



From Ted.Harding at nessie.mcc.ac.uk  Tue May  4 17:36:11 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 04 May 2004 16:36:11 +0100 (BST)
Subject: [R] Superposing data on boxplot
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7CFC@usrymx25.merck.com>
Message-ID: <XFMail.040504163611.Ted.Harding@nessie.mcc.ac.uk>

Thanks, Andy, and Peter Wolf, for very prompt replies!

On 04-May-04 Liaw, Andy wrote:
> Try:
> 
> y = rnorm(50)
> z = factor(rep(1:5, each=10))
> boxplot(y~z, horizontal=TRUE)
> stripchart(y~z, add=TRUE)

Actually the other way up works the way I want. Details:

  boxplot(Y~Z)
  stripchart(Y~Z,vertical=TRUE,add=TRUE,pch=1,col="red")

which produces exactly the effect I'd been trying to achieve
with my code.

Thanks for drawing my attention to 'stripchart'. Just the job.

Peter: your suggestion

y<-rnorm(100);z<-sample(1:7,100,T);boxplot(y~z);points(y~z)

is what I would have used had Z been numerical. Unfortunately
Z is of the form c("A","B","C",...), which is why I went through
all that footwork to extract the x-coordinates of "A", "B", etc.
from bxp().

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 04-May-04                                       Time: 16:36:11
------------------------------ XFMail ------------------------------



From ligges at statistik.uni-dortmund.de  Tue May  4 18:19:47 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 04 May 2004 18:19:47 +0200
Subject: [R] Installing Hmisc after upgrade
In-Reply-To: <001201c431eb$246f3540$83dad10a@prod.omsv.ch>
References: <001201c431eb$246f3540$83dad10a@prod.omsv.ch>
Message-ID: <4097C2A3.3000000@statistik.uni-dortmund.de>

Anne Piotet wrote:

> Hello
> I just upgraded my version of R to 1.9.0 for Windows (2000 and XP)
> When trying to run the library Hmisc I get the following error:
> 
> Error in testRversion(descfields) : This package has not been installed
> properly
>  See the Note in ?library
> 
> Till now, I had no problem with other libraries...
> 
> How do I correct the problem?
> 
> Thanks
> Anne
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Please try to reinstall Hmisc (which you should do for the other 
libraries as well after upgrading R):

  install.packages("Hmisc")

I guess you have either installed the source instead of the binary 
version, or you have a got a version of Hmisc that is outdated by year(s).

Uwe Ligges



From myao at ou.edu  Tue May  4 18:19:59 2004
From: myao at ou.edu (Yao, Minghua)
Date: Tue, 4 May 2004 11:19:59 -0500
Subject: [R] Problems in plot
Message-ID: <78B50CF247E5D04B8A5E02D001CC8E9A595C57@XMAIL.sooner.net.ou.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040504/ca78f37a/attachment.pl

From ripley at stats.ox.ac.uk  Tue May  4 18:25:00 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 May 2004 17:25:00 +0100 (BST)
Subject: [R] Problems in plot
In-Reply-To: <78B50CF247E5D04B8A5E02D001CC8E9A595C57@XMAIL.sooner.net.ou.edu>
Message-ID: <Pine.LNX.4.44.0405041721490.24652-100000@gannet.stats>

Why did you minize the RGui frame?  Since it is minmized, there is no room 
for any windows, as I believe they are now sized to fit within the frame:
see the CHANGES file which says

  Changed windows() so that new windows fit within the MDI client
  area.

So just don't minimize the MDI frame.  (Duncan M might want to revisit 
that code.)

On Tue, 4 May 2004, Yao, Minghua wrote:

> My code is over 700 lines. That is why I didn't send it. I am sorry I did not tell you this.
>  
> See this code,
>  
> for(i in 1:20){ 
>  windows() 
>  par(cex = 0.75) 
>  plot(1:10) 
> } 
> 
> 
> if the RGui window is minimized immediately (by clicking the "minimize" button on the upper right corner) after the code is pasted and run.
> 
> > for(i in 1:20){ 
> +  windows() 
> +  par(cex = 0.75) 
> +  plot(1:10) 
> + } 
> Error in plot.new() : Figure margins too large
> > 
> >
> 
> I am using MDI mode. My operating system is Windows XP.
>  
> Thanks.
>  
> Minghua
> 
> ________________________________
> 
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Tue 5/4/2004 10:49 AM
> To: Yao, Minghua
> Cc: R Help
> Subject: RE: [R] Problems in plot
> 
> 
> 
> You have been asked for a reproducible set of conditions -- this is the
> first time `minimized' has been mentioned.  If you can find a completely
> reproducible set of actions please file a bug report (after reading the
> FAQ section carefully).
> 
> We cannot help you otherwise, and don't want to spend time guessing what
> you might have forgotten to tell us.  (I see you have not told us if you
> use MDI or SDI mode, for example.)
> 
> 
> On Tue, 4 May 2004, Yao, Minghua wrote:
> 
> > It seems to me that the problem happens to the graphic window that is
> > generated immediately after the R window is minimized.
> > 
> > Minghua
> >
> > ________________________________
> >
> > From: r-help-bounces at stat.math.ethz.ch on behalf of Yao, Minghua
> > Sent: Fri 4/30/2004 4:12 PM
> > To: Prof Brian Ripley
> > Cc: R Help
> > Subject: RE: [R] Problems in plot
> >
> >
> >
> > The problem is still there if windows() is used.
> >
> > Minghua
> >
> > ________________________________
> >
> > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > Sent: Thu 4/29/2004 9:31 AM
> > To: Yao, Minghua
> > Cc: R Help
> > Subject: Re: [R] Problems in plot
> >
> >
> >
> > The primary graphics device under Windows is called *windows* not *x11*.
> >
> > Something in your Windows setup is sometimes failing to choose a
> > reasonable window size.  I have never seen that, and suspect it is nothing
> > to do with it, but please use windows() and see if the problem vanishes.
> >
> > On Thu, 29 Apr 2004, Yao, Minghua wrote:
> >
> > > Hello,
> > >
> > >
> > >
> > > I have R1.9.0 under Windows XP. My program plots several plots using
> > >
> > > x11()
> > > par(cex = 0.75)
> > > ......
> > > x11()
> > > par(cex = 0.75)
> > > ......
> > > x11()
> > > par(cex = 0.75)
> > > ......
> > > x11()
> > > par(cex = 0.75)
> > > ......
> > >
> > > Sometimes, one of them generates  a small frame only with title area "R graphics: Device X (ACTIVE)". The message in the console window is
> > >
> > > Error in plot.new() : Figure margins too large
> > >
> > > This program ran well under R1.6.X under Windows NT.
> > >
> > > It seems to me that it is not a specific x11() that generates that small graphics frame.
> > >
> > > Thank you for you help in advance.
> > >
> > > Minghua
> 
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From prechelt at pcpool.mi.fu-berlin.de  Tue May  4 18:26:15 2004
From: prechelt at pcpool.mi.fu-berlin.de (Lutz Prechelt)
Date: Tue, 4 May 2004 18:26:15 +0200
Subject: [R] Lattice: finding out xlim within panel function
Message-ID: <85D25331FFB7AE4C900EA467D4ADA392045919@circle.pcpool.mi.fu-berlin.de>

> >>while within a panel function for xyplot, how can I
> >>find out the values of (effectively) xlim and
> >>ylim -- no matter whether they have been set
> >>explicitly or chosen by Lattice itself?
...
> > Not surprising, since there's no documented way to do this. 
> > You could 
> > try something along these lines, but this exact construct is not 
> > guaranteed to work in future versions of grid:
> > 
> >     cvp = grid::current.viewport() 
> >     print(cvp$xscale)
...
> Can you tell me 
> more about what you are trying to do?

I am writing a panel function that will (among other
things) plot a regression line for a scatter plot
and add curves for confidence or prediction intervals.
I want the intervals to cover not only the
x-range of the data, but the whole length of the
axis.

And while for drawing the line I need not know
the size of the scale (by using abline),
there is nobody taking it off me to decide where
to start and stop drawing the curves for the
intervals.

  Lutz



From ligges at statistik.uni-dortmund.de  Tue May  4 18:28:50 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 04 May 2004 18:28:50 +0200
Subject: [R] Problems in plot
In-Reply-To: <78B50CF247E5D04B8A5E02D001CC8E9A595C57@XMAIL.sooner.net.ou.edu>
References: <78B50CF247E5D04B8A5E02D001CC8E9A595C57@XMAIL.sooner.net.ou.edu>
Message-ID: <4097C4C2.6040901@statistik.uni-dortmund.de>

Yao, Minghua wrote:

> My code is over 700 lines. That is why I didn't send it. I am sorry I did not tell you this.
>  
> See this code,
>  
> for(i in 1:20){ 
>  windows() 
>  par(cex = 0.75) 
>  plot(1:10) 
> } 
> 
> 
> if the RGui window is minimized immediately (by clicking the "minimize" button on the upper right corner) after the code is pasted and run.

After RGui in MDI mode is minimized??!!
Of course, then you cannot plot anything, since the remaining errea to 
plot anything in is 0x0 (and the error message indicates that the 
margins are too large, because no space is left to do any sensible 
plotting)!

That's expected!

Uwe Ligges



> 
>>for(i in 1:20){ 
> 
> +  windows() 
> +  par(cex = 0.75) 
> +  plot(1:10) 
> + } 
> Error in plot.new() : Figure margins too large
> 
>>
> 
> I am using MDI mode. My operating system is Windows XP.
>  
> Thanks.
>  
> Minghua
> 
> ________________________________
> 
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Tue 5/4/2004 10:49 AM
> To: Yao, Minghua
> Cc: R Help
> Subject: RE: [R] Problems in plot
> 
> 
> 
> You have been asked for a reproducible set of conditions -- this is the
> first time `minimized' has been mentioned.  If you can find a completely
> reproducible set of actions please file a bug report (after reading the
> FAQ section carefully).
> 
> We cannot help you otherwise, and don't want to spend time guessing what
> you might have forgotten to tell us.  (I see you have not told us if you
> use MDI or SDI mode, for example.)
> 
> 
> On Tue, 4 May 2004, Yao, Minghua wrote:
> 
> 
>>It seems to me that the problem happens to the graphic window that is
>>generated immediately after the R window is minimized.
>>
>>Minghua
>>
>>________________________________
>>
>>From: r-help-bounces at stat.math.ethz.ch on behalf of Yao, Minghua
>>Sent: Fri 4/30/2004 4:12 PM
>>To: Prof Brian Ripley
>>Cc: R Help
>>Subject: RE: [R] Problems in plot
>>
>>
>>
>>The problem is still there if windows() is used.
>>
>>Minghua
>>
>>________________________________
>>
>>From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>>Sent: Thu 4/29/2004 9:31 AM
>>To: Yao, Minghua
>>Cc: R Help
>>Subject: Re: [R] Problems in plot
>>
>>
>>
>>The primary graphics device under Windows is called *windows* not *x11*.
>>
>>Something in your Windows setup is sometimes failing to choose a
>>reasonable window size.  I have never seen that, and suspect it is nothing
>>to do with it, but please use windows() and see if the problem vanishes.
>>
>>On Thu, 29 Apr 2004, Yao, Minghua wrote:
>>
>>
>>>Hello,
>>>
>>>
>>>
>>>I have R1.9.0 under Windows XP. My program plots several plots using
>>>
>>>x11()
>>>par(cex = 0.75)
>>>......
>>>x11()
>>>par(cex = 0.75)
>>>......
>>>x11()
>>>par(cex = 0.75)
>>>......
>>>x11()
>>>par(cex = 0.75)
>>>......
>>>
>>>Sometimes, one of them generates  a small frame only with title area "R graphics: Device X (ACTIVE)". The message in the console window is
>>>
>>>Error in plot.new() : Figure margins too large
>>>
>>>This program ran well under R1.6.X under Windows NT.
>>>
>>>It seems to me that it is not a specific x11() that generates that small graphics frame.
>>>
>>>Thank you for you help in advance.
>>>
>>>Minghua
> 
> 
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Tue May  4 19:23:15 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 May 2004 18:23:15 +0100 (BST)
Subject: [R] degrees of freedom in lm() treatment contrasts
In-Reply-To: <1A5736AC-9DD9-11D8-A6A2-000A958F43CC@MUOhio.edu>
Message-ID: <Pine.LNX.4.44.0405041817210.24775-100000@gannet.stats>

The thing is, it is *terms* that have degrees of freedom, and that does
not depend on the contrasts used except in rather exceptional
circumstances (when you set them with C() being one).

And the number of df assigned to a term depends on what went before, as
well as the data (since you can extrinsic aliasing). The only source that
is close to comprehensive is section 2.4 of the White Book (not an easy
read, though).  Do read V&R section 6.2 first.

I teach my students via series of examples: the general principles seem 
too hard for beginners.


On Tue, 4 May 2004, Martin Henry H. Stevens wrote:

> Does anyone have a good (and specific) reference for an explanation for 
> the calculation of degrees of freedom in treatment contrasts? I checked 
> the indexes of Venables and Ripley 2002, Crawley 2002, and Neter et al. 
> (Applied Linear Statistical Models, 4th ed.), as well as the lm code. I 
> would happily accept a "verbal" email explanation as well.
> Many thanks,
> Hank Stevens

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dfs at research.att.com  Tue May  4 20:27:40 2004
From: dfs at research.att.com (Deborah Swayne)
Date: Tue, 4 May 2004 14:27:40 -0400
Subject: [R] setting INSTALL libraries
Message-ID: <16535.57500.528320.350849@fry.research.att.com>


Could someone remind me how to control the libraries and the search
order used by 'R CMD INSTALL'?  I need to override the usual order to
resolve a conflict on the old SGI I'm working with.  There must be
something I can do with configure-args, right?  And what is the syntax
for using multiple configure-args?

Thanks,
Debby



From bates at stat.wisc.edu  Tue May  4 22:03:22 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 04 May 2004 15:03:22 -0500
Subject: [R] setting INSTALL libraries
In-Reply-To: <16535.57500.528320.350849@fry.research.att.com>
References: <16535.57500.528320.350849@fry.research.att.com>
Message-ID: <6rn04o7yet.fsf@bates4.stat.wisc.edu>

Deborah Swayne <dfs at research.att.com> writes:

> Could someone remind me how to control the libraries and the search
> order used by 'R CMD INSTALL'?  I need to override the usual order to
> resolve a conflict on the old SGI I'm working with.  There must be
> something I can do with configure-args, right?  And what is the syntax
> for using multiple configure-args?

Set the environment variable R_LIBS.  In emacs I use

(setenv "R_LIBS" "/usr/local/lib/R/site-library:/usr/local/lib/R/library")



From p.dalgaard at biostat.ku.dk  Tue May  4 22:18:54 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 May 2004 22:18:54 +0200
Subject: [R] setting INSTALL libraries
In-Reply-To: <6rn04o7yet.fsf@bates4.stat.wisc.edu>
References: <16535.57500.528320.350849@fry.research.att.com>
	<6rn04o7yet.fsf@bates4.stat.wisc.edu>
Message-ID: <x2zn8o9c9d.fsf@biostat.ku.dk>

Douglas Bates <bates at stat.wisc.edu> writes:

> Deborah Swayne <dfs at research.att.com> writes:
> 
> > Could someone remind me how to control the libraries and the search
> > order used by 'R CMD INSTALL'?  I need to override the usual order to
> > resolve a conflict on the old SGI I'm working with.  There must be
> > something I can do with configure-args, right?  And what is the syntax
> > for using multiple configure-args?
> 
> Set the environment variable R_LIBS.  In emacs I use
> 
> (setenv "R_LIBS" "/usr/local/lib/R/site-library:/usr/local/lib/R/library")

My first thought too, but Debby would know that, I suspect. Perhaps
LD_LIBRARY_PATH is more to the point? Re. configure-args, can't you
just do --configure-args="FEE=foe FIE=fum" ?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.murrell at auckland.ac.nz  Tue May  4 22:58:19 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 05 May 2004 08:58:19 +1200
Subject: [R] Lattice: finding out xlim within panel function
References: <85D25331FFB7AE4C900EA467D4ADA392045919@circle.pcpool.mi.fu-berlin.de>
Message-ID: <409803EB.9060204@stat.auckland.ac.nz>

Hi


Lutz Prechelt wrote:
>>>>while within a panel function for xyplot, how can I
>>>>find out the values of (effectively) xlim and
>>>>ylim -- no matter whether they have been set
>>>>explicitly or chosen by Lattice itself?
>>>
> ...
> 
>>>Not surprising, since there's no documented way to do this. 
>>>You could 
>>>try something along these lines, but this exact construct is not 
>>>guaranteed to work in future versions of grid:
>>>
>>>    cvp = grid::current.viewport() 
>>>    print(cvp$xscale)
>>
> ...
> 
>>Can you tell me 
>>more about what you are trying to do?
> 
> 
> I am writing a panel function that will (among other
> things) plot a regression line for a scatter plot
> and add curves for confidence or prediction intervals.
> I want the intervals to cover not only the
> x-range of the data, but the whole length of the
> axis.
> 
> And while for drawing the line I need not know
> the size of the scale (by using abline),
> there is nobody taking it off me to decide where
> to start and stop drawing the curves for the
> intervals.


Yep, sounds like you need the x-scale alright :)
If you want something that is documented (and therefore much less likely 
to change in future grid versions), the following call will also give 
you the x-axis range:

convertX(unit(0:1, "npc"), "native", valueOnly=TRUE)

Thanks for the extra info.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From lj22 at u.washington.edu  Tue May  4 23:02:16 2004
From: lj22 at u.washington.edu (Lei Jiang)
Date: Tue, 4 May 2004 14:02:16 -0700 (PDT)
Subject: [R] error in file(file, "r"): all connections are in use
Message-ID: <Pine.A41.4.58.0405041358160.60578@homer40.u.washington.edu>

Hi, there.

I am trying to read multiple files into R, but I got following message

Error in file(file, "r"): All connections are in use.

I clean up memory everytime I read in one file. Do i have to somehow
release file connection everytime i read in one??

Thanks.

Lei

Department of Chemsitry
University of Washington
Box 351700
Seattle, WA 98195
Phone: 206-616-6882
Fax: 206-685-8665



From ripley at stats.ox.ac.uk  Tue May  4 23:06:54 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 May 2004 22:06:54 +0100 (BST)
Subject: [R] error in file(file, "r"): all connections are in use
In-Reply-To: <Pine.A41.4.58.0405041358160.60578@homer40.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0405042204000.9193-100000@gannet.stats>

On Tue, 4 May 2004, Lei Jiang wrote:

> I am trying to read multiple files into R, but I got following message
> 
> Error in file(file, "r"): All connections are in use.
> 
> I clean up memory everytime I read in one file. Do i have to somehow
> release file connection everytime i read in one??

No, but you do need to release them eventually -- call close().
Your OS will also have a limit on the number of files you can have open at 
any one time, and it may not be much greater than the number of 
connections that can be in use (around 50).

I cannot imagine needing more than 50 connections open at once, but if you 
do you can alter the limit and recompile R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ericw at qualsolutions.com  Tue May  4 23:17:49 2004
From: ericw at qualsolutions.com (ericw@qualsolutions.com)
Date: Tue, 4 May 2004 17:17:49 -0400
Subject: [R] help with DCOM R Server
Message-ID: <000001c4321d$4145a460$6501a8c0@ericlaptop>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040504/96ac2ad4/attachment.pl

From gabriel_bader at yahoo.ca  Tue May  4 23:21:04 2004
From: gabriel_bader at yahoo.ca (Gabriel Bader)
Date: Tue, 4 May 2004 17:21:04 -0400 (EDT)
Subject: [R] scaling of variables 
Message-ID: <20040504212104.23842.qmail@web50101.mail.yahoo.com>

Hi all, 
I am wondering if someone has a good reference for
scaling variables when running nonlinear optimization.
I would apreciate it if someone can direct me to a
book or lecture notes on the web. I need to know the
general intuition about doing this. 

Thank You
Gabriel.



From vograno at evafunds.com  Tue May  4 23:49:17 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Tue, 4 May 2004 14:49:17 -0700
Subject: [R] error in file(file, "r"): all connections are in use
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B32E1@phost015.intermedia.net>

If you open a connection within a function it is often a good idea to
set an "on.exit" expression that will close the connection. This will be
called even if your function terminates via stop(). Here is an example:

 con <- file("foo")
 open(con)
 on.exit(close(con), add=TRUE)

HTH,
Vadim

> -----Original Message-----
> From: Lei Jiang [mailto:lj22 at u.washington.edu] 
> Sent: Tuesday, May 04, 2004 2:02 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] error in file(file, "r"): all connections are in use
> 
> 
> Hi, there.
> 
> I am trying to read multiple files into R, but I got following message
> 
> Error in file(file, "r"): All connections are in use.
> 
> I clean up memory everytime I read in one file. Do i have to 
> somehow release file connection everytime i read in one??
> 
> Thanks.
> 
> Lei
> 
> Department of Chemsitry
> University of Washington
> Box 351700
> Seattle, WA 98195
> Phone: 206-616-6882
> Fax: 206-685-8665
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From wwsprague at ucdavis.edu  Tue May  4 23:57:18 2004
From: wwsprague at ucdavis.edu (wwsprague@ucdavis.edu)
Date: Tue, 04 May 2004 14:57:18 -0700
Subject: [R] "put()" like "get()"
Message-ID: <c793k8$crn$1@sea.gmane.org>

Is there a function that takes a string and creates and assigns a 
variable with that name?  Could someone point me in the right direction?

Thnx
W



From ripley at stats.ox.ac.uk  Wed May  5 00:01:32 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 May 2004 23:01:32 +0100 (BST)
Subject: [R] "put()" like "get()"
In-Reply-To: <c793k8$crn$1@sea.gmane.org>
Message-ID: <Pine.LNX.4.44.0405042300430.9351-100000@gannet.stats>

On Tue, 4 May 2004 wwsprague at ucdavis.edu wrote:

> Is there a function that takes a string and creates and assigns a 
                                                          ^^^^^^
> variable with that name?  Could someone point me in the right direction?

?assign

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rpeng at jhsph.edu  Wed May  5 00:02:13 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 04 May 2004 18:02:13 -0400
Subject: [R] "put()" like "get()"
In-Reply-To: <c793k8$crn$1@sea.gmane.org>
References: <c793k8$crn$1@sea.gmane.org>
Message-ID: <409812E5.1070603@jhsph.edu>

assign().

-roger

wwsprague at ucdavis.edu wrote:
> Is there a function that takes a string and creates and assigns a 
> variable with that name?  Could someone point me in the right direction?
> 
> Thnx
> W
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From sdavis2 at mail.nih.gov  Wed May  5 00:05:13 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 04 May 2004 18:05:13 -0400
Subject: [R] Simple lattice graphics question
Message-ID: <BCBD8BD9.7A41%sdavis2@mail.nih.gov>

Dear all,

I am using panel graphics to do a stripplot of a variable versus a shingle
and putting a loess curve on the stripplot.  I want the data jittered, but I
can't seem to get the panel function to work.  This jitter's the data, but
of course doesn't give me the loess:

> stripplot((g[,3]) ~ c,jitter=T,pch=".",scales=list(y=list(log=T)))

But this doesn't give me any jittering.  What am I missing?

> stripplot(jitter(g[,3]) ~ c,scales=list(y=list(log=T)),panel=function(x,y)
{panel.stripplot(x,y,pch='.'); panel.loess(x,y,span=1)},jitter=T)

Thanks for any help.

Sean



From spencer.graves at pdf.com  Wed May  5 00:12:08 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 04 May 2004 15:12:08 -0700
Subject: [R] "put()" like "get()"
In-Reply-To: <c793k8$crn$1@sea.gmane.org>
References: <c793k8$crn$1@sea.gmane.org>
Message-ID: <40981538.6070204@pdf.com>

      Have you tried "?assign"?  That works, as does its converse "get". 

      hope this helps.  spencer graves

wwsprague at ucdavis.edu wrote:

> Is there a function that takes a string and creates and assigns a 
> variable with that name?  Could someone point me in the right direction?
>
> Thnx
> W
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From deepayan at stat.wisc.edu  Wed May  5 00:39:07 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 4 May 2004 17:39:07 -0500
Subject: [R] Simple lattice graphics question
In-Reply-To: <BCBD8BD9.7A41%sdavis2@mail.nih.gov>
References: <BCBD8BD9.7A41%sdavis2@mail.nih.gov>
Message-ID: <200405041739.07287.deepayan@stat.wisc.edu>

On Tuesday 04 May 2004 05:05 pm, Sean Davis wrote:
> Dear all,
>
> I am using panel graphics to do a stripplot of a variable versus a shingle
> and putting a loess curve on the stripplot.  I want the data jittered, but
> I can't seem to get the panel function to work.  This jitter's the data,
> but
>
> of course doesn't give me the loess:
> > stripplot((g[,3]) ~ c,jitter=T,pch=".",scales=list(y=list(log=T)))
>
> But this doesn't give me any jittering.  What am I missing?
>
> > stripplot(jitter(g[,3]) ~
> > c,scales=list(y=list(log=T)),panel=function(x,y)
>
> {panel.stripplot(x,y,pch='.'); panel.loess(x,y,span=1)},jitter=T)

?panel.stripplot says:

Usage:

     panel.stripplot(x, y, jitter.data = FALSE, factor = 0.5,
                     horizontal = TRUE, groups = NULL,
                     ...)


You are never passing the jitter.data argument to it, so it's using the 
default. There's more than one way around this, but I would probably do 

panel=function(x,y,...) {
    panel.stripplot(x,y,pch='.',...)
    <etc etc>
}

Deepayan



From datkins at u.washington.edu  Wed May  5 00:40:34 2004
From: datkins at u.washington.edu (Dave Atkins)
Date: Tue, 04 May 2004 15:40:34 -0700
Subject: [R] xyplot and for loops
Message-ID: <40981BE2.1080607@u.washington.edu>


I'm attempting to use xyplot() within a for() loop to plot the relationship 
between a DV and a series of predictor variables, split by 2 conditioning 
variables.  However, xyplot() does not "seem" to be recognized within the for() 
loop; I don't receive any error message, but nothing is plotted and a plotting 
device is not opened.  When I use the generic function plot(), everything works 
as expected.  I'm using R v1.9.0 and lattice v0.9-11.

Here's a trivial example:

### create single outcome and two predictors
 > y.tmp <- rnorm(20) ; x1.tmp <- rnorm(20) ; x2.tmp <- rnorm(20)
### combine into data.frame
 > tmp.df <- data.frame(y.tmp, x1.tmp, x2.tmp)
 > tmp.df
         y.tmp       x1.tmp      x2.tmp
1   1.5022759 -0.150326662 -1.36627981
[snip]
20  1.2667825 -0.070356651 -0.38433160

### simple loop calling the columns of tmp.df to specify x variables
 > for (i in 2:3){
+ plot(tmp.df$y.tmp ~ tmp.df[,i])
+ }
### works fine for plot()

### try the same with xyplot()
 > for (i in 2:3){
+ xyplot(tmp.df$y.tmp ~ tmp.df[,i])
+ }
### nothing happens; no error msg; no plotting device opened

 > xyplot(tmp.df$y.tmp ~ tmp.df[,2])
### without loop works fine and plots relationship of x1.tmp and y.tmp

Can someone see what I'm missing?  Any directions/pointers appreciated.

cheers, Dave
datkins at u.washington.edu



From lsjensen at micron.com  Wed May  5 00:59:44 2004
From: lsjensen at micron.com (lsjensen@micron.com)
Date: Tue, 4 May 2004 16:59:44 -0600
Subject: [R] rpart question
Message-ID: <363801FFD7B74240A329CEC3F7FE4CC402B83F9B@ntxboimbx07.micron.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040504/5119d7e1/attachment.pl

From apjaworski at mmm.com  Wed May  5 01:00:38 2004
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Tue, 4 May 2004 18:00:38 -0500
Subject: [R] xyplot and for loops
In-Reply-To: <40981BE2.1080607@u.washington.edu>
Message-ID: <OF651DCA1E.73A370DF-ON86256E8A.007E2B23-86256E8A.007E66DC@mmm.com>






Dave,

I think inside the loop you have to explicitly "print" a trellis object,
i.e.  say

print(yplot(tmp.df$y.tmp ~ tmp.df[,i]))

If you read the help page for xyplot, look under "Value".

Hope this helps,

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


                                                                           
             Dave Atkins                                                   
             <datkins at u.washin                                             
             gton.edu>                                                  To 
             Sent by:                  r-help at stat.math.ethz.ch            
             r-help-bounces at st                                          cc 
             at.math.ethz.ch                                               
                                                                   Subject 
                                       [R] xyplot and for loops            
             05/04/2004 05:40                                              
             PM                                                            
                                                                           
                                                                           
                                                                           
                                                                           





I'm attempting to use xyplot() within a for() loop to plot the relationship

between a DV and a series of predictor variables, split by 2 conditioning
variables.  However, xyplot() does not "seem" to be recognized within the
for()
loop; I don't receive any error message, but nothing is plotted and a
plotting
device is not opened.  When I use the generic function plot(), everything
works
as expected.  I'm using R v1.9.0 and lattice v0.9-11.

Here's a trivial example:

### create single outcome and two predictors
 > y.tmp <- rnorm(20) ; x1.tmp <- rnorm(20) ; x2.tmp <- rnorm(20)
### combine into data.frame
 > tmp.df <- data.frame(y.tmp, x1.tmp, x2.tmp)
 > tmp.df
         y.tmp       x1.tmp      x2.tmp
1   1.5022759 -0.150326662 -1.36627981
[snip]
20  1.2667825 -0.070356651 -0.38433160

### simple loop calling the columns of tmp.df to specify x variables
 > for (i in 2:3){
+ plot(tmp.df$y.tmp ~ tmp.df[,i])
+ }
### works fine for plot()

### try the same with xyplot()
 > for (i in 2:3){
+ xyplot(tmp.df$y.tmp ~ tmp.df[,i])
+ }
### nothing happens; no error msg; no plotting device opened

 > xyplot(tmp.df$y.tmp ~ tmp.df[,2])
### without loop works fine and plots relationship of x1.tmp and y.tmp

Can someone see what I'm missing?  Any directions/pointers appreciated.

cheers, Dave
datkins at u.washington.edu

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From datkins at u.washington.edu  Wed May  5 01:21:37 2004
From: datkins at u.washington.edu (Dave Atkins)
Date: Tue, 04 May 2004 16:21:37 -0700
Subject: [R] xyplot and for loops
In-Reply-To: <OF651DCA1E.73A370DF-ON86256E8A.007E2B23-86256E8A.007E66DC@mmm.com>
References: <OF651DCA1E.73A370DF-ON86256E8A.007E2B23-86256E8A.007E66DC@mmm.com>
Message-ID: <40982581.60901@u.washington.edu>


Thanks to Andy and Bert for setting me straight!  Explicitly printing the xyplot 
command takes care of the issue.  Just didn't dig quite far enough into the 
documentation.

cheers, Dave

apjaworski at mmm.com wrote:

> 
> 
> 
> 
> Dave,
> 
> I think inside the loop you have to explicitly "print" a trellis object,
> i.e.  say
> 
> print(yplot(tmp.df$y.tmp ~ tmp.df[,i]))
> 
> If you read the help page for xyplot, look under "Value".
> 
> Hope this helps,
> 
> Andy
> 
> __________________________________
> Andy Jaworski
> 518-1-01
> Process Laboratory
> 3M Corporate Research Laboratory
> -----
> E-mail: apjaworski at mmm.com
> Tel:  (651) 733-6092
> Fax:  (651) 736-3122
> 
> 
>                                                                            
>              Dave Atkins                                                   
>              <datkins at u.washin                                             
>              gton.edu>                                                  To 
>              Sent by:                  r-help at stat.math.ethz.ch            
>              r-help-bounces at st                                          cc 
>              at.math.ethz.ch                                               
>                                                                    Subject 
>                                        [R] xyplot and for loops            
>              05/04/2004 05:40                                              
>              PM                                                            
>                                                                            
>                                                                            
>                                                                            
>                                                                            
> 
> 
> 
> 
> 
> I'm attempting to use xyplot() within a for() loop to plot the relationship
> 
> between a DV and a series of predictor variables, split by 2 conditioning
> variables.  However, xyplot() does not "seem" to be recognized within the
> for()
> loop; I don't receive any error message, but nothing is plotted and a
> plotting
> device is not opened.  When I use the generic function plot(), everything
> works
> as expected.  I'm using R v1.9.0 and lattice v0.9-11.
> 
> Here's a trivial example:
> 
> ### create single outcome and two predictors
>  > y.tmp <- rnorm(20) ; x1.tmp <- rnorm(20) ; x2.tmp <- rnorm(20)
> ### combine into data.frame
>  > tmp.df <- data.frame(y.tmp, x1.tmp, x2.tmp)
>  > tmp.df
>          y.tmp       x1.tmp      x2.tmp
> 1   1.5022759 -0.150326662 -1.36627981
> [snip]
> 20  1.2667825 -0.070356651 -0.38433160
> 
> ### simple loop calling the columns of tmp.df to specify x variables
>  > for (i in 2:3){
> + plot(tmp.df$y.tmp ~ tmp.df[,i])
> + }
> ### works fine for plot()
> 
> ### try the same with xyplot()
>  > for (i in 2:3){
> + xyplot(tmp.df$y.tmp ~ tmp.df[,i])
> + }
> ### nothing happens; no error msg; no plotting device opened
> 
>  > xyplot(tmp.df$y.tmp ~ tmp.df[,2])
> ### without loop works fine and plots relationship of x1.tmp and y.tmp
> 
> Can someone see what I'm missing?  Any directions/pointers appreciated.
> 
> cheers, Dave
> datkins at u.washington.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Wed May  5 01:48:16 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 4 May 2004 19:48:16 -0400
Subject: [R] rpart question
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D07@usrymx25.merck.com>

AFAIK rpart does not have built-in facility for adjusting bias in split
selection.  One possibility is to define your own splitting criterion that
does the adjustment is some fashion.  I believe the current version of rpart
allows you to define custom splitting criterion, but I have not tried it
myself.

Prof. Wei-yin Loh at UW-Madison (and his current and former students) had
worked on algorithms that compensate for bias in split selection.  There are
software on his web page that you might want to check out.

HTH,
Andy

> From: lsjensen at micron.com
> 
> Wondered about the best way to control for input variables that have a
> large number of levels in 'rpart' models.  I understand the algorithm
> searches through all possible splits (2^(k-1) for k levels) and so
> variables with more levels are more prone to be good 
> spliters... so I'm
> looking for ways to compensate and adjust for this complexity.
> 
> For example, if two variables produce comparable splits in 
> the data but
> one contains 2 levels and the other 13 levels then I would 
> like to have
> to have the algorithm choose the 'simpler' split.
> 
> Is this best done with the 'cost' argument in the rpart options?  This
> defaults to one for all variables... so would it make sense to scale
> this by nlevels in each variable or sqrt(nlevels) or 
> something similar?
> 
> Thanks,
> Landon
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From jcwatts999 at yahoo.com  Wed May  5 03:25:42 2004
From: jcwatts999 at yahoo.com (Jason Watts)
Date: Tue, 4 May 2004 18:25:42 -0700 (PDT)
Subject: [R] dataset.date, date of an object
Message-ID: <20040505012542.12741.qmail@web50007.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040504/b44aa126/attachment.pl

From dmurdoch at pair.com  Wed May  5 03:56:06 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 04 May 2004 21:56:06 -0400
Subject: [R] Problems in plot
In-Reply-To: <Pine.LNX.4.44.0405041721490.24652-100000@gannet.stats>
References: <78B50CF247E5D04B8A5E02D001CC8E9A595C57@XMAIL.sooner.net.ou.edu>
	<Pine.LNX.4.44.0405041721490.24652-100000@gannet.stats>
Message-ID: <rvhg9014b6t4ookboh8jkpeka2k78phsch@4ax.com>

On Tue, 4 May 2004 17:25:00 +0100 (BST), Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:

>Why did you minize the RGui frame?  Since it is minmized, there is no room 
>for any windows, as I believe they are now sized to fit within the frame:
>see the CHANGES file which says
>
>  Changed windows() so that new windows fit within the MDI client
>  area.
>
>So just don't minimize the MDI frame.  (Duncan M might want to revisit 
>that code.)

I've removed the test for the size of the frame in the case where the
frame is minimized.  Now for a minimized R it just uses the physical
size of the monitor, as before:  likely giving a window that's too
big, but at least not causing errors.

You can still get the error by making the frame really small (but not
minimized), but I'd say that's reasonable behaviour.

Duncan Murdoch



From jianqings at yahoo.com  Wed May  5 05:14:40 2004
From: jianqings at yahoo.com (Mike)
Date: Tue, 4 May 2004 20:14:40 -0700 (PDT)
Subject: [R] anyone know how to combine two vector with some # overlaped?
Message-ID: <20040505031440.20523.qmail@web41012.mail.yahoo.com>

Hi, there,

Suppose I have two vector say x=c(1 2 3 4 5) and y=(2
3 6 7). Then I want to combine these two vector
together and get z=c(1 2 3 4 5 6 7) with 2 and 3 only
appear once. I want to extend this one to a general
case(say more than 100 elements in x and y and each
time I don't know which elements are the same). Do you
happen to know how to do this and which command should
use?

Thank you very much. Please reply to this email. Any
kind help would be greatly appreciated.

Mike



From julian.taylor at adelaide.edu.au  Wed May  5 05:26:05 2004
From: julian.taylor at adelaide.edu.au (Julian Taylor)
Date: Wed, 05 May 2004 12:56:05 +0930
Subject: [R] anyone know how to combine two vector with some # overlaped?
References: <20040505031440.20523.qmail@web41012.mail.yahoo.com>
Message-ID: <40985ECD.34176BA3@adelaide.edu.au>


Try

x <- c(1,2,3,4,5)
y <- c(2,3,6,7)
z <- c(x,y)[!duplicated(c(x,y))] 

HTH,
Jules

Mike wrote:
> 
> Hi, there,
> 
> Suppose I have two vector say x=c(1 2 3 4 5) and y=(2
> 3 6 7). Then I want to combine these two vector
> together and get z=c(1 2 3 4 5 6 7) with 2 and 3 only
> appear once. I want to extend this one to a general
> case(say more than 100 elements in x and y and each
> time I don't know which elements are the same). Do you
> happen to know how to do this and which command should
> use?
> 
> Thank you very much. Please reply to this email. Any
> kind help would be greatly appreciated.
> 
> Mike
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
---
Julian Taylor			phone: +61 8 8303 6751
ARC Research Associate            fax: +61 8 8303 6760
BiometricsSA,                  mobile: +61 4 1638 8180  
University of Adelaide/SARDI    email: julian.taylor at adelaide.edu.au
Private Mail Bag 1                www:
http://www.BiometricsSA.adelaide.edu.au
Glen Osmond SA 5064

"There is no spoon."   -- Orphan boy  
---



From jerosenb at hcs.harvard.edu  Wed May  5 05:39:44 2004
From: jerosenb at hcs.harvard.edu (Janet Rosenbaum)
Date: Tue, 4 May 2004 23:39:44 -0400 (EDT)
Subject: [R] increasing memory
In-Reply-To: <Pine.LNX.4.44.0405041336090.12609-100000@gannet.stats> from
	"Prof Brian Ripley" at May 04, 2004 01:38:44 PM
Message-ID: <20040505033944.412002E17C@hcs.harvard.edu>


 
> If it actually crashes there is a bug, but I suspect that it stops with an
> error message -- please do read the posting guide and tell us exactly what
> happens.

Sorry, I hadn't realized that "crash" means to give an error message on
this mailing list.  

To me, "crash" means that the computer freezes entirely, or if I'm
lucky it just runs for several hours without doing anything, and the 
process can't even be killed with  -9, and the computer can't be
shutdown, but has to be powercycled. 

For instance, I left it doing a read.table on a text format file from this 
data (a few hundred megs) and eight hours later it was still "going".
I watched the process with "top" for awhile and the computer had plenty 
of free memory -- over 100 M this whole time, and R was using almost no
CPU.

I have tried all sorts of ways of reading in the data.  It's best if I
can read the xport file since that has all the original labels which
don't get to the text file, but read.xport actually freezes the
computer.  

As I said, I am running R 1.8.1 which claims to be the most recent
version (when I type is.RAqua.updated()) on an ibook G3/800 with 620 M
RAM (the maximum) running 10.3.3.  

The command really doesn't much matter.  These are totally normal files
and I can load in the normal sized files with the exact same
commands.  
> w<-read.table("pedagogue.csv",header=T, sep=",")
> library(foreign)
> w<-read.xport("demagogue.xpt")

The xpt files are up to 400 M, and the csv files are about 100 M.  

Janet
-- 
Janet Rosenbaum					 jerosenb at fas.harvard.edu
Harvard Injury Control Research Center,   Harvard School of Public Health



From knussear at biodiversity.unr.edu  Wed May  5 05:59:29 2004
From: knussear at biodiversity.unr.edu (knussear)
Date: Tue, 4 May 2004 20:59:29 -0700
Subject: [R] Repeated measures regression
Message-ID: <9BB7E36C-9E48-11D8-BED7-000A959A19D8@biodiversity.unr.edu>

Hi List,

Just wondering if there is such a thing as repeated measures 
regression, and if so, can R do it?

I have repeated measurements of 10 individuals over a 45 day period, 
and I would like to regress their daily activity time against a daily 
environmental temperature. If I do so using averages of activity time I 
find a significant negative correlation, but I worry that because I 
have used the same 10 individuals for each daily mean that the daily 
averages are not independent.

Can anyone help?

Thanks

Kenneth E. Nussear                     Phone  775 784-4565
Biological Resources                   FAX 775 784-1369
Research Center/315                  knussear at biodiversity.unr.edu
Reno, Nevada   89557                http://www.brrc.unr.edu/~knussear/



From ripley at stats.ox.ac.uk  Wed May  5 07:52:56 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 May 2004 06:52:56 +0100 (BST)
Subject: [R] dataset.date, date of an object
In-Reply-To: <20040505012542.12741.qmail@web50007.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0405050649580.9946-100000@gannet.stats>

What do you mean by `a permanently stored version of a dataset'?
If you mean a save()d version, use file.info() on the saved file.

R does not store objects `permanently' as S-PLUS (sic) does, so your exact 
phrasing is meaningless.

On Tue, 4 May 2004, Jason Watts wrote:

> I'm looking for a function that returns the time at which a permanently
> stored version of a dataset (object) was last modified, just like
> dataset.date in S-Plus.  Any suggestions?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Lorenz.Gygax at fat.admin.ch  Wed May  5 08:00:23 2004
From: Lorenz.Gygax at fat.admin.ch (Lorenz.Gygax@fat.admin.ch)
Date: Wed, 5 May 2004 08:00:23 +0200 
Subject: [R] Repeated measures regression
Message-ID: <BF74FADD4B44554CA7E53D0B5242CD6A018DAF03@evd-s7014.evd.admin.ch>


Why not start with:

@Book{Pin:00a,
  author = 	 {Pinheiro, Jose C and Bates, Douglas M},
  title = 	 {Mixed-Effects Models in {S} and {S}-{P}{L}{U}{S}},
  publisher = 	 {Springer},
  year = 	 {2000},
  address = 	 {New York}
}

Regards, Lorenz

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of knussear
> Sent: Wednesday, May 05, 2004 5:59 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Repeated measures regression
> 
> 
> Hi List,
> 
> Just wondering if there is such a thing as repeated measures 
> regression, and if so, can R do it?
> 
> I have repeated measurements of 10 individuals over a 45 day period, 
> and I would like to regress their daily activity time against a daily 
> environmental temperature. If I do so using averages of 
> activity time I 
> find a significant negative correlation, but I worry that because I 
> have used the same 10 individuals for each daily mean that the daily 
> averages are not independent.
> 
> Can anyone help?
> 
> Thanks
> 
> Kenneth E. Nussear                     Phone  775 784-4565
> Biological Resources                   FAX 775 784-1369
> Research Center/315                  knussear at biodiversity.unr.edu
> Reno, Nevada   89557                http://www.brrc.unr.edu/~knussear/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed May  5 08:05:53 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 May 2004 07:05:53 +0100 (BST)
Subject: [R] increasing memory
In-Reply-To: <20040505033944.412002E17C@hcs.harvard.edu>
Message-ID: <Pine.LNX.4.44.0405050700430.9946-100000@gannet.stats>

The commands do matter.  Both ?read.table and the Data Import/Export 
Manual tell you ways to speed up reading a table.

However, there seems to be a problem with either MacOS X or perhaps your
hardware that is probably impossible to diagnose remotely.  A Unix system
should be able to kill any process you own with kill -9 (unless it is out
of other resources, e.g. processes to run kill): that's not an R issue.

On Tue, 4 May 2004, Janet Rosenbaum wrote:

> 
>  
> > If it actually crashes there is a bug, but I suspect that it stops with an
> > error message -- please do read the posting guide and tell us exactly what
> > happens.
> 
> Sorry, I hadn't realized that "crash" means to give an error message on
> this mailing list.  
> 
> To me, "crash" means that the computer freezes entirely, or if I'm
> lucky it just runs for several hours without doing anything, and the 
> process can't even be killed with  -9, and the computer can't be
> shutdown, but has to be powercycled. 
> 
> For instance, I left it doing a read.table on a text format file from this 
> data (a few hundred megs) and eight hours later it was still "going".
> I watched the process with "top" for awhile and the computer had plenty 
> of free memory -- over 100 M this whole time, and R was using almost no
> CPU.

It may still have been swapping.

> I have tried all sorts of ways of reading in the data.  It's best if I
> can read the xport file since that has all the original labels which
> don't get to the text file, but read.xport actually freezes the
> computer.  
> 
> As I said, I am running R 1.8.1 which claims to be the most recent
> version (when I type is.RAqua.updated()) on an ibook G3/800 with 620 M
> RAM (the maximum) running 10.3.3.  
> 
> The command really doesn't much matter.  These are totally normal files
> and I can load in the normal sized files with the exact same
> commands.  
> > w<-read.table("pedagogue.csv",header=T, sep=",")
> > library(foreign)
> > w<-read.xport("demagogue.xpt")
> 
> The xpt files are up to 400 M, and the csv files are about 100 M.  
> 
> Janet
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Wed May  5 08:26:06 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 05 May 2004 08:26:06 +0200
Subject: [R] anyone know how to combine two vector with some # overlaped?
In-Reply-To: <20040505031440.20523.qmail@web41012.mail.yahoo.com>
References: <20040505031440.20523.qmail@web41012.mail.yahoo.com>
Message-ID: <409888FE.5090703@statistik.uni-dortmund.de>

Mike wrote:
> Hi, there,
> 
> Suppose I have two vector say x=c(1 2 3 4 5) and y=(2
> 3 6 7). Then I want to combine these two vector
> together and get z=c(1 2 3 4 5 6 7) with 2 and 3 only
> appear once. I want to extend this one to a general
> case(say more than 100 elements in x and y and each
> time I don't know which elements are the same). Do you
> happen to know how to do this and which command should
> use?
> 
> Thank you very much. Please reply to this email. Any
> kind help would be greatly appreciated.
> 
> Mike
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

See ?unique

Uwe Ligges



From p.dalgaard at biostat.ku.dk  Wed May  5 09:12:59 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 May 2004 09:12:59 +0200
Subject: [R] Problems in plot
In-Reply-To: <rvhg9014b6t4ookboh8jkpeka2k78phsch@4ax.com>
References: <78B50CF247E5D04B8A5E02D001CC8E9A595C57@XMAIL.sooner.net.ou.edu>
	<Pine.LNX.4.44.0405041721490.24652-100000@gannet.stats>
	<rvhg9014b6t4ookboh8jkpeka2k78phsch@4ax.com>
Message-ID: <x2n04ngxdw.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch at pair.com> writes:

> I've removed the test for the size of the frame in the case where the
> frame is minimized.  Now for a minimized R it just uses the physical
> size of the monitor, as before:  likely giving a window that's too
> big, but at least not causing errors.

It would be better if you could get a hold of the unminimized size (as
opposed to the maximized one). Isn't there a way to do that on
Windows?

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From pallier at lscp.ehess.fr  Wed May  5 09:29:44 2004
From: pallier at lscp.ehess.fr (pallier)
Date: Wed, 05 May 2004 09:29:44 +0200
Subject: [R] anyone know how to combine two vector with some # overlaped?
In-Reply-To: <20040505031440.20523.qmail@web41012.mail.yahoo.com>
References: <20040505031440.20523.qmail@web41012.mail.yahoo.com>
Message-ID: <409897E8.1030303@lscp.ehess.fr>

Mike wrote:

>Hi, there,
>
>Suppose I have two vector say x=c(1 2 3 4 5) and y=(2
>3 6 7). Then I want to combine these two vector
>together and get z=c(1 2 3 4 5 6 7) with 2 and 3 only
>appear once.
>
union(x,y)

R provides several set operators. See ?union.

Christophe Pallier



From ripley at stats.ox.ac.uk  Wed May  5 09:27:41 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 May 2004 08:27:41 +0100 (BST)
Subject: [R] Problems in plot
In-Reply-To: <x2n04ngxdw.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0405050826200.11496-100000@gannet.stats>

On 5 May 2004, Peter Dalgaard wrote:

> Duncan Murdoch <dmurdoch at pair.com> writes:
> 
> > I've removed the test for the size of the frame in the case where the
> > frame is minimized.  Now for a minimized R it just uses the physical
> > size of the monitor, as before:  likely giving a window that's too
> > big, but at least not causing errors.
> 
> It would be better if you could get a hold of the unminimized size (as
> opposed to the maximized one). Isn't there a way to do that on
> Windows?

  The GetWindowPlacement function retrieves the minimized, maximized, and
  restored positions for the window, and also determines the window's show
  state.

apparently.  `restored' seems to be the key word here.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ok at cs.otago.ac.nz  Wed May  5 10:08:01 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Wed, 5 May 2004 20:08:01 +1200 (NZST)
Subject: [R] anyone know how to combine two vector with some # overlaped?
Message-ID: <200405050808.i45881t1115500@atlas.otago.ac.nz>

If you want this:

	> Suppose I have two vector say x=c(1 2 3 4 5) and y=(2
	> 3 6 7). Then I want to combine these two vector
	> together and get z=c(1 2 3 4 5 6 7) with 2 and 3 only
	> appear once.

Julian Taylor <julian.taylor at adelaide.edu.au> suggests:
	x <- c(1,2,3,4,5)
	y <- c(2,3,6,7)
	z <- c(x,y)[!duplicated(c(x,y))] 
	
But you can do it in one step:
	z <- unique(c(x,y))

I don't know how unique() is implemented, but using a hash table it
_could_ be done in linear expected time, and in practice it seems to
be pretty quick, more than quick enough for a few hundred elements.



From Laetitia.Marisa at cgm.cnrs-gif.fr  Wed May  5 10:40:27 2004
From: Laetitia.Marisa at cgm.cnrs-gif.fr (Laetitia Marisa)
Date: Wed, 05 May 2004 10:40:27 +0200
Subject: [R] Graphic size with X11 device
Message-ID: <4098A87B.6060902@cgm.cnrs-gif.fr>

Hello,

I have done a script that make multiple graphics : one graphic per 
columns of my data matrix and one x11 window every 4 graphcis. For 
example, if my matrix has 6 columns, there will appears one x11 window 
with 4 graphics and a second one with the last 2 graphics.
I wanted that all graphics have the same size so when I open x11 I 
specify width and height proportional to the number of lines expected by 
window. But in the second windows it is always different in size of the 
graphics, in size of the points and in size of the text.
What do i miss?

Thanks.

Laetitia.



From ripley at stats.ox.ac.uk  Wed May  5 10:41:46 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 May 2004 09:41:46 +0100 (BST)
Subject: [R] anyone know how to combine two vector with some # overlaped?
In-Reply-To: <200405050808.i45881t1115500@atlas.otago.ac.nz>
Message-ID: <Pine.LNX.4.44.0405050939290.11717-100000@gannet.stats>

On Wed, 5 May 2004, Richard A. O'Keefe wrote:

> If you want this:
> 
> 	> Suppose I have two vector say x=c(1 2 3 4 5) and y=(2
> 	> 3 6 7). Then I want to combine these two vector
> 	> together and get z=c(1 2 3 4 5 6 7) with 2 and 3 only
> 	> appear once.
> 
> Julian Taylor <julian.taylor at adelaide.edu.au> suggests:
> 	x <- c(1,2,3,4,5)
> 	y <- c(2,3,6,7)
> 	z <- c(x,y)[!duplicated(c(x,y))] 
> 	
> But you can do it in one step:
> 	z <- unique(c(x,y))
> 
> I don't know how unique() is implemented, but using a hash table it
> _could_ be done in linear expected time, and in practice it seems to
> be pretty quick, more than quick enough for a few hundred elements.

It does use a hash table (as does duplicated).

An slightly shorter step is union(x, y), which is implemented as 
unique(c(x,y)).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed May  5 10:54:30 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 May 2004 09:54:30 +0100 (BST)
Subject: [R] Graphic size with X11 device
In-Reply-To: <4098A87B.6060902@cgm.cnrs-gif.fr>
Message-ID: <Pine.LNX.4.44.0405050951130.11717-100000@gannet.stats>

Are you using par(mfrow)?  If so, that changes the base cex for layouts
with 2 or more rows and columns.

Otherwise, the text size should be the same, but in calculating the window 
size you have to compute the device not plot region, that is included the 
margins (and outer margins) which are of fixed size.

I would use par(mfrow=c(2,2)) on all windows, and accept that there will 
be white space on the last one.

On Wed, 5 May 2004, Laetitia Marisa wrote:

> I have done a script that make multiple graphics : one graphic per 
> columns of my data matrix and one x11 window every 4 graphcis. For 
> example, if my matrix has 6 columns, there will appears one x11 window 
> with 4 graphics and a second one with the last 2 graphics.
> I wanted that all graphics have the same size so when I open x11 I 
> specify width and height proportional to the number of lines expected by 
> window. But in the second windows it is always different in size of the 
> graphics, in size of the points and in size of the text.
> What do i miss?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From cullens at tcd.ie  Wed May  5 11:20:07 2004
From: cullens at tcd.ie (Simon Cullen)
Date: Wed, 05 May 2004 10:20:07 +0100
Subject: [R] Discontinuities in a simple graph (machine precision?)
Message-ID: <opr7ir7te31pelvz@smtp.tcd.ie>

Hi,

I've got an ugly but fairly simple function:

mdevstdev <- function(a){
	l <- dnorm(a)/(1-pnorm(a))
	integrand  <- function(z)(abs(z-l)*dnorm(z))
	inted <- integrate(integrand, a, Inf)
	inted[[1]]/((1- pnorm(a))*sqrt((1 + a*l - l^2)))
}

I wanted to quickly produce a graph of this over the range [-3,3] so I  
used:

plotit <-function(x=seq(-3,3,0.01),...){
	y<-sapply(x,mdevstdev)
	plot(x,y,...)
}

> plotit()

This produces the graph, but some discontinuities appear on it. I've  
produced the same graph in Mathematica 5  
(http://econserv2.bess.tcd.ie/cullens/R/DOverDelta.eps), and it was smooth  
over this range (it takes ages to run, though). Is this a numerical  
precision problem? Any suggestions on how to improve the precision?

I'm running R 1.9 on WinXP, PIII. I haven't changed any R parameters that  
I know of.

-- 
SC

Simon Cullen
Room 3030
Dept. Of Economics
Trinity College Dublin

Ph. (608)3477
Email cullens at tcd.ie



From ripley at stats.ox.ac.uk  Wed May  5 11:35:25 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 May 2004 10:35:25 +0100 (BST)
Subject: [R] Using integrate (was Discontinuities in a simple graph
	(machine precision?))
In-Reply-To: <opr7ir7te31pelvz@smtp.tcd.ie>
Message-ID: <Pine.LNX.4.44.0405051023390.11754-100000@gannet.stats>

Note, this is about integrate, nothing else.  You are looking for an
answer with high absolute precision for larger a because of your divisor
(about 1e-3). If I add rel.tol=1e-12 it is fine.


On Wed, 5 May 2004, Simon Cullen wrote:

> Hi,
> 
> I've got an ugly but fairly simple function:
> 
> mdevstdev <- function(a){
> 	l <- dnorm(a)/(1-pnorm(a))
> 	integrand  <- function(z)(abs(z-l)*dnorm(z))
> 	inted <- integrate(integrand, a, Inf)
> 	inted[[1]]/((1- pnorm(a))*sqrt((1 + a*l - l^2)))
> }
> 
> I wanted to quickly produce a graph of this over the range [-3,3] so I  
> used:
> 
> plotit <-function(x=seq(-3,3,0.01),...){
> 	y<-sapply(x,mdevstdev)
> 	plot(x,y,...)
> }
> 
> > plotit()
> 
> This produces the graph, but some discontinuities appear on it. I've  
> produced the same graph in Mathematica 5  
> (http://econserv2.bess.tcd.ie/cullens/R/DOverDelta.eps), and it was smooth  
> over this range (it takes ages to run, though). Is this a numerical  
> precision problem? Any suggestions on how to improve the precision?
> 
> I'm running R 1.9 on WinXP, PIII. I haven't changed any R parameters that  
> I know of.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From WAVELA at iscw.agric.za  Wed May  5 11:37:21 2004
From: WAVELA at iscw.agric.za (WAVELA MTHOBELI)
Date: Wed, 05 May 2004 11:37:21 +0200
Subject: [R] Logit Deriv
Message-ID: <4098D1F1.17866.C4AB97@localhost>



From p.dalgaard at biostat.ku.dk  Wed May  5 11:42:35 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 May 2004 11:42:35 +0200
Subject: [R] Discontinuities in a simple graph (machine precision?)
In-Reply-To: <opr7ir7te31pelvz@smtp.tcd.ie>
References: <opr7ir7te31pelvz@smtp.tcd.ie>
Message-ID: <x2wu3r9pmc.fsf@biostat.ku.dk>

"Simon Cullen" <cullens at tcd.ie> writes:

> Hi,
> 
> I've got an ugly but fairly simple function:
> 
> mdevstdev <- function(a){
> 	l <- dnorm(a)/(1-pnorm(a))
> 	integrand  <- function(z)(abs(z-l)*dnorm(z))
> 	inted <- integrate(integrand, a, Inf)
> 	inted[[1]]/((1- pnorm(a))*sqrt((1 + a*l - l^2)))
> }
> 
> I wanted to quickly produce a graph of this over the range [-3,3] so I
> used:
> 
> plotit <-function(x=seq(-3,3,0.01),...){
> 	y<-sapply(x,mdevstdev)
> 	plot(x,y,...)
> }
> 
> > plotit()
> 
> This produces the graph, but some discontinuities appear on it. I've
> produced the same graph in Mathematica 5
> (http://econserv2.bess.tcd.ie/cullens/R/DOverDelta.eps), and it was
> smooth  over this range (it takes ages to run, though). Is this a
> numerical  precision problem? Any suggestions on how to improve the
> precision?
> 
> I'm running R 1.9 on WinXP, PIII. I haven't changed any R parameters
> that  I know of.

This is probably related to integrating a non-smooth function across
the singularity. It works better like this:

> mdevstdev
function(a){
  l <- dnorm(a)/(1-pnorm(a))
  integrand  <- function(z)(abs(z-l)*dnorm(z))
  inted <- if (l < a) integrate(integrand, a, Inf)[[1]] else
    integrate(integrand, a, l)[[1]] + integrate(integrand, l, Inf)[[1]]
  inted/((1- pnorm(a))*sqrt((1 + a*l - l^2)))
}

(as you see, I was too lazy to think about whether l >= a always...)


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Wed May  5 11:59:21 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 05 May 2004 11:59:21 +0200
Subject: [R] Discontinuities in a simple graph (machine precision?)
In-Reply-To: <opr7ir7te31pelvz@smtp.tcd.ie>
References: <opr7ir7te31pelvz@smtp.tcd.ie>
Message-ID: <4098BAF9.90506@statistik.uni-dortmund.de>

Simon Cullen wrote:

> Hi,
> 
> I've got an ugly but fairly simple function:
> 
> mdevstdev <- function(a){
>     l <- dnorm(a)/(1-pnorm(a))
>     integrand  <- function(z)(abs(z-l)*dnorm(z))
>     inted <- integrate(integrand, a, Inf)

It's a matter of numerical accuracy, you might want to use, e.g.:

     inted <- integrate(integrand, a, Inf,
         rel.tol = .Machine$double.eps^0.5)

Uwe Ligges

>     inted[[1]]/((1- pnorm(a))*sqrt((1 + a*l - l^2)))
> }
> 
> I wanted to quickly produce a graph of this over the range [-3,3] so I  
> used:
> 
> plotit <-function(x=seq(-3,3,0.01),...){
>     y<-sapply(x,mdevstdev)
>     plot(x,y,...)
> }
> 
>> plotit()
> 
> 
> This produces the graph, but some discontinuities appear on it. I've  
> produced the same graph in Mathematica 5  
> (http://econserv2.bess.tcd.ie/cullens/R/DOverDelta.eps), and it was 
> smooth  over this range (it takes ages to run, though). Is this a 
> numerical  precision problem? Any suggestions on how to improve the 
> precision?
> 
> I'm running R 1.9 on WinXP, PIII. I haven't changed any R parameters 
> that  I know of.
>



From migreja at med.up.pt  Wed May  5 12:37:19 2004
From: migreja at med.up.pt (Margarida =?iso-8859-1?Q?J=FAlia?= Rodrigues Igreja)
Date: Wed, 05 May 2004 11:37:19 +0100
Subject: [R] reading data
Message-ID: <6.0.3.0.1.20040505113104.01afc498@mail.med.up.pt>

Hello,
I??m trying to read data from a text file but i can??t

When i print:
 > a<-read.table(file="C:/dados10.txt")

The next error appears:
Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file `C:/dados10.txt'
  Can you help me?

Margarida

PS:The operating sistem i??m using is Unix



From ripley at stats.ox.ac.uk  Wed May  5 12:41:34 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 May 2004 11:41:34 +0100 (BST)
Subject: [R] reading data
In-Reply-To: <6.0.3.0.1.20040505113104.01afc498@mail.med.up.pt>
Message-ID: <Pine.LNX.4.44.0405051140340.4352-100000@gannet.stats>

Unix does not file paths like C:/dados10.txt.

It's an issue with your local environment, so please ask your local 
advisors.

On Wed, 5 May 2004, Margarida J??lia Rodrigues Igreja wrote:

> Hello,
> I??m trying to read data from a text file but i can??t
> 
> When i print:
>  > a<-read.table(file="C:/dados10.txt")
> 
> The next error appears:
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `C:/dados10.txt'
>   Can you help me?
> 
> Margarida
> 
> PS:The operating sistem i??m using is Unix

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From huang.hlc at msa.hinet.net  Wed May  5 12:50:17 2004
From: huang.hlc at msa.hinet.net (=?big5?B?tsC3R6Xg?=)
Date: Wed, 5 May 2004 18:50:17 +0800
Subject: [R] (no subject)
Message-ID: <001b01c4328e$c10399c0$6e01fea9@hlc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040505/17536458/attachment.pl

From u6001513 at tknet.tku.edu.tw  Wed May  5 12:51:41 2004
From: u6001513 at tknet.tku.edu.tw (=?big5?B?pP26zadn?=)
Date: Wed, 5 May 2004 18:51:41 +0800
Subject: [R] ONE QUESTION IN R-PROJECT
Message-ID: <002e01c4328e$f322b760$6e01fea9@hlc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040505/df22cb5a/attachment.pl

From christoph.lange at tuebingen.mpg.de  Wed May  5 12:53:36 2004
From: christoph.lange at tuebingen.mpg.de (Christoph Lange)
Date: Wed, 5 May 2004 12:53:36 +0200
Subject: [R] reading data
In-Reply-To: <6.0.3.0.1.20040505113104.01afc498@mail.med.up.pt>
References: <6.0.3.0.1.20040505113104.01afc498@mail.med.up.pt>
Message-ID: <20040505105336.GA24083@sesame.kyb.local>

(Reply to Margarida J??lia Rodrigues Igreja)

Hello!

> When i print:
> > a<-read.table(file="C:/dados10.txt")
> 
> The next error appears:
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `C:/dados10.txt'
>  Can you help me?

Contrary to what Professor Ripley wrote, this file name is of course
totally valid under unixoid systems.

But 'C:' looks like a windows hard drive mounted under a Unix
directory named 'C:'. Usually this is done directly under '/', so just
try:

  a<-read.table(file="/C:/dados10.txt")

-cl

-- 
Christoph Lange
MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|



From Christoph.Scherber at uni-jena.de  Wed May  5 13:02:54 2004
From: Christoph.Scherber at uni-jena.de (Christoph Scherber)
Date: Wed, 05 May 2004 13:02:54 +0200
Subject: [R] reading data
In-Reply-To: <20040505105336.GA24083@sesame.kyb.local>
References: <6.0.3.0.1.20040505113104.01afc498@mail.med.up.pt>
	<20040505105336.GA24083@sesame.kyb.local>
Message-ID: <4098C9DE.4060601@uni-jena.de>

Just one small remark:

why don??t you try ("C:\\dados10.txt") ? It seems to me that the double 
"\\" is important!

Cheers
Chris



Christoph Lange wrote:

>(Reply to Margarida J??lia Rodrigues Igreja)
>
>Hello!
>
>  
>
>>When i print:
>>    
>>
>>>a<-read.table(file="C:/dados10.txt")
>>>      
>>>
>>The next error appears:
>>Error in file(file, "r") : unable to open connection
>>In addition: Warning message:
>>cannot open file `C:/dados10.txt'
>> Can you help me?
>>    
>>
>
>Contrary to what Professor Ripley wrote, this file name is of course
>totally valid under unixoid systems.
>
>But 'C:' looks like a windows hard drive mounted under a Unix
>directory named 'C:'. Usually this is done directly under '/', so just
>try:
>
>  a<-read.table(file="/C:/dados10.txt")
>
>-cl
>
>  
>



From joehl at gmx.de  Wed May  5 13:23:43 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Wed, 5 May 2004 13:23:43 +0200 (MEST)
Subject: [R] Item Similarity in Scale Analysis?
Message-ID: <16511.1083756223@www24.gmx.net>



Does anyone know about R code for the methods presented in "Item Similarity
in Scale Analysis" in Political Analysis, 2000, 8:3, 261-283 by Marco R.
Steenbergen? (seems to be a variant of Item Similarity Index from Hunter
1973 ("Methods for Reordering the Correltation Matrix to Facilitate Visual
Inspection and Preliminary Cluster Analysis", Journal of Educational
Measurement 10:51-61) which replaces guessing single item reliabilities by
assumption of equal item reliabilites. Does anyone has experience with this
method? SEM experts?

Thanks for any help. 


Jens Oehlschl??gel

-- 
"Sie haben neue Mails!" - Die GMX Toolbar informiert Sie beim Surfen!
Jetzt aktivieren unter http://www.gmx.net/info



From jcwatts999 at yahoo.com  Wed May  5 13:36:04 2004
From: jcwatts999 at yahoo.com (Jason Watts)
Date: Wed, 5 May 2004 04:36:04 -0700 (PDT)
Subject: [R] dataset.date, date of an object
In-Reply-To: <Pine.LNX.4.44.0405050649580.9946-100000@gannet.stats>
Message-ID: <20040505113604.91139.qmail@web50005.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040505/f3c754be/attachment.pl

From maechler at stat.math.ethz.ch  Wed May  5 14:05:38 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 5 May 2004 14:05:38 +0200
Subject: [R] ONE QUESTION IN R-PROJECT
In-Reply-To: <002e01c4328e$f322b760$6e01fea9@hlc>
References: <002e01c4328e$f322b760$6e01fea9@hlc>
Message-ID: <16536.55442.712452.835472@gargle.gargle.HOWL>

You've been answered a few days ago when you asked (almost?) the
same question.
Now you've sent it *again* and even twice to the mailing list.

How can we know that you are not just a student who is too
lazy to do his/her homework?

>>>>> "??????" == ??????  <u6001513 at tknet.tku.edu.tw>
>>>>>     on Wed, 5 May 2004 18:51:41 +0800 writes:

    ??????> Hello:
    ??????> I have already found references "optim" ,
    ??????> but I do not understand its means !!
    ??????> So I want to ask next question
    ??????> I have a question in Math.
    ??????> If we want to get X's and Y's solution, X>0 and Y>0
    ??????> We have two equation :

    ??????> 2*exp(X)+X^2+3*Y=2*exp(1)+4
    ??????> 3*exp(X/Y)+3*X*Y+4*Y=3*exp(1)+7

    ??????> How I use R-project to  solve above question??

it looks like you really try to misuse the "R-project" (namely
its community of volunteers) instead of using R --
for which you need to spend some time learning the language,
functionality, graphics, etc.
do read the posting guide AND some of its links, mentioned at
the end of every R-help message.

Regards,
Martin



From ripley at stats.ox.ac.uk  Wed May  5 14:12:09 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 May 2004 13:12:09 +0100 (BST)
Subject: [R] dataset.date, date of an object
In-Reply-To: <20040505113604.91139.qmail@web50005.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0405051311240.8964-100000@gannet.stats>

Let me repeat

> R does not store objects `permanently' as S-PLUS (sic) does, so your exact
> phrasing is meaningless.

In S-PLUS my.dataframe is an object in a .Data directory.  There is no 
such concept in R.

On Wed, 5 May 2004, Jason Watts wrote:

> Ok, I'd like the date an object was saved.  Here's what I used to do in S-PLUS:
>  
> > dataset.date('my.dataframe')
> [1] "Tue May  4 10:16:00 2004"
> 
> 
> Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> What do you mean by `a permanently stored version of a dataset'?
> If you mean a save()d version, use file.info() on the saved file.
> 
> R does not store objects `permanently' as S-PLUS (sic) does, so your exact 
> phrasing is meaningless.
> 
> On Tue, 4 May 2004, Jason Watts wrote:
> 
> > I'm looking for a function that returns the time at which a permanently
> > stored version of a dataset (object) was last modified, just like
> > dataset.date in S-Plus. Any suggestions?
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lmassis at yahoo.com.br  Wed May  5 14:17:57 2004
From: lmassis at yahoo.com.br (Leonard assis)
Date: Wed, 5 May 2004 09:17:57 -0300
Subject: [R] Lme4 error
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAHlebCTgy30WZ5WwsVbJtq8KAAAAQAAAA+MkEJ5k2ukSX6X8dtYg/OgEAAAAA@yahoo.com.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040505/a72b45b9/attachment.pl

From rpeng at jhsph.edu  Wed May  5 14:20:21 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 05 May 2004 08:20:21 -0400
Subject: [R] increasing memory
In-Reply-To: <20040505033944.412002E17C@hcs.harvard.edu>
References: <20040505033944.412002E17C@hcs.harvard.edu>
Message-ID: <4098DC05.3070302@jhsph.edu>

Just a note, R 1.9.0 is the most recent version.

It sounds like your computer might just be running out of memory 
and thrashing.  620MB of RAM is unfortunately not an enormous 
amount of RAM with which to be using R.  These are the trade 
offs.  If you can't read in your table using scan() then we may 
be running out of R options.

-roger

Janet Rosenbaum wrote:

>  
> 
>>If it actually crashes there is a bug, but I suspect that it stops with an
>>error message -- please do read the posting guide and tell us exactly what
>>happens.
> 
> 
> Sorry, I hadn't realized that "crash" means to give an error message on
> this mailing list.  
> 
> To me, "crash" means that the computer freezes entirely, or if I'm
> lucky it just runs for several hours without doing anything, and the 
> process can't even be killed with  -9, and the computer can't be
> shutdown, but has to be powercycled. 
> 
> For instance, I left it doing a read.table on a text format file from this 
> data (a few hundred megs) and eight hours later it was still "going".
> I watched the process with "top" for awhile and the computer had plenty 
> of free memory -- over 100 M this whole time, and R was using almost no
> CPU.
> 
> I have tried all sorts of ways of reading in the data.  It's best if I
> can read the xport file since that has all the original labels which
> don't get to the text file, but read.xport actually freezes the
> computer.  
> 
> As I said, I am running R 1.8.1 which claims to be the most recent
> version (when I type is.RAqua.updated()) on an ibook G3/800 with 620 M
> RAM (the maximum) running 10.3.3.  
> 
> The command really doesn't much matter.  These are totally normal files
> and I can load in the normal sized files with the exact same
> commands.  
> 
>>w<-read.table("pedagogue.csv",header=T, sep=",")
>>library(foreign)
>>w<-read.xport("demagogue.xpt")
> 
> 
> The xpt files are up to 400 M, and the csv files are about 100 M.  
> 
> Janet



From rpeng at jhsph.edu  Wed May  5 14:22:48 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 05 May 2004 08:22:48 -0400
Subject: [R] dataset.date, date of an object
In-Reply-To: <20040505113604.91139.qmail@web50005.mail.yahoo.com>
References: <20040505113604.91139.qmail@web50005.mail.yahoo.com>
Message-ID: <4098DC98.1010100@jhsph.edu>

What exactly do you mean by "saved"?  Do you mean "modified"?  I 
don't think there is a way to tell when the last time an object 
was modified.  However, if you use the save() function and save 
an object to a file, then you can just look at the time stamps on 
the file.

-roger

Jason Watts wrote:

> Ok, I'd like the date an object was saved.  Here's what I used to do in S-PLUS:
>  
> 
>>dataset.date('my.dataframe')
> 
> [1] "Tue May  4 10:16:00 2004"
> 
> 
> Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> What do you mean by `a permanently stored version of a dataset'?
> If you mean a save()d version, use file.info() on the saved file.
> 
> R does not store objects `permanently' as S-PLUS (sic) does, so your exact 
> phrasing is meaningless.
> 
> On Tue, 4 May 2004, Jason Watts wrote:
> 
> 
>>I'm looking for a function that returns the time at which a permanently
>>stored version of a dataset (object) was last modified, just like
>>dataset.date in S-Plus. Any suggestions?
> 
>



From ggrothendieck at myway.com  Wed May  5 14:31:44 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 5 May 2004 12:31:44 +0000 (UTC)
Subject: [R] dataset.date, date of an object
References: <20040505012542.12741.qmail@web50007.mail.yahoo.com>
Message-ID: <loom.20040505T142110-520@post.gmane.org>

Jason Watts <jcwatts999 <at> yahoo.com> writes:

> 
> I'm looking for a function that returns the time at which a permanently 
stored version of a dataset (object)
> was last modified, just like dataset.date in S-Plus.  Any suggestions?

I think others have already answered this (i.e. R does not store objects in
files so you can't get the dates of those files); however, if its only
specific objects whose dates you need and you are willing to set them 
yourself you could do something like this:

# create object and set timestamp in an attribute
df <- data.frame(a=1:5,b=letters[1:5])
attr(df,"timestamp") <- Sys.time()

# ...

# update object and timestamp
df$a <- df$a+1
attr(df,"timestamp") <- Sys.time()

# ...

# show last modified time
attr(df,"timetamp")

You could get much fancier by creating a class which automatically 
appends and updates timestamps whenever an operation is performed
on its objects.   That would be even easier to use but it would
be more work to set up initially.



From heberto.ghezzo at mcgill.ca  Wed May  5 14:36:20 2004
From: heberto.ghezzo at mcgill.ca (r.ghezzo)
Date: Wed, 05 May 2004 08:36:20 -0400
Subject: [R] sampling with weights
Message-ID: <4098DFC4.4000409@mcgill.ca>

Hello, I am trying to produce an example of weighted sampling vs uniform 
sampling, the subject is estimation of the size distribution by sampling 
from a micrograph with a graticule of points. The sampling obtained is 
thus area weighted.
I created a distribution by
pop <- rexp(1000)+rexp(1000)+rexp(1000)
Now an uniform random sample is
index <- floor(1000*runif(100))+1
samp1 <- pop[index]
and the histograms of pop and samp1 are very similar as expected, Now to 
simulate a sample obtained by point counting method I did
cupop <- cumsum(pop)
popmax <- cupop[1000]
index <- popmax * runif(100)
samp2 <- rep(0,100)
now for each value in index I have to find the last point in cupop that 
is less than , then the next one is the chosen
for( i in 1:100) {
   xi <- which(cupop < index[i])
   samp2[i] <- pop[xi[length(xi)]+1]
}
Q: is there a more elegant and general way to do this sampling?
As it is it works but look clumsy
Thanks
Heberto Ghezzo Ph.D.
Meakins-Christie Labs
McGill University
Montreal - Canada



From thsudler at swissonline.ch  Wed May  5 14:45:04 2004
From: thsudler at swissonline.ch (thsudler@swissonline.ch)
Date: Wed, 5 May 2004 14:45:04 +0200
Subject: [R] Analysis of ordinal categorical data
Message-ID: <200405051245.i45Cj4mO019098@smtp.hispeed.ch>

Hi

I would like to analyse an ordinal categorical variable. I know how I can analyse a nominal categorical variable (with multinom or if there are only two levels with glm).

Does somebody know which command I need in R to analyse an ordinal categorical variable?

I want to describe the variable y with the variables x1,x2,x3 and x4. So my model looks like: y ~ x1+x2+x3+x4.

y: ordinal factor variable with levels (never, rare, bychance, often).

Thanks a lot in advance
Thomas



From andy_liaw at merck.com  Wed May  5 14:45:17 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 5 May 2004 08:45:17 -0400
Subject: [R] increasing memory
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D0C@usrymx25.merck.com>

> From: Roger D. Peng
> 
> Just a note, R 1.9.0 is the most recent version.
> 
> It sounds like your computer might just be running out of memory 
> and thrashing.  620MB of RAM is unfortunately not an enormous 
> amount of RAM with which to be using R.  These are the trade 
> offs.  If you can't read in your table using scan() then we may 
> be running out of R options.

`Easy' ones anyway.  One can always use `lower level' things like
connections and readLines() to read in chunks at a time...

BTW (for Janet) `crash' and `freeze' aren't exactly the same (at least to
me).  To me `crash' is something like segfaults, or if the program abruptly
exits, or BSOD, etc.  If you still can run top, then the computer hasn't
really frozen, either.  I suspect the reason you can't kill the program is
that the computer is running _really_ low on memory and thrashing, thus not
really responding to `kill' in a timely manner.  I have gotten into that
situation on a Linux box (w/ 2GB RAM), and can't even log in as root to try
the `kill'.  Similarly, the only option was to hit that big red (or maybe
not so `big' or `red') button...

We do need accurate descriptions of what happened to be able to be more
helpful, including some basic descriptions of the data file (e.g., how many
rows/columns, delimiters, column types, etc.)

Andy

 
> -roger
> 
> Janet Rosenbaum wrote:
> 
> >  
> > 
> >>If it actually crashes there is a bug, but I suspect that 
> it stops with an
> >>error message -- please do read the posting guide and tell 
> us exactly what
> >>happens.
> > 
> > 
> > Sorry, I hadn't realized that "crash" means to give an 
> error message on
> > this mailing list.  
> > 
> > To me, "crash" means that the computer freezes entirely, or if I'm
> > lucky it just runs for several hours without doing 
> anything, and the 
> > process can't even be killed with  -9, and the computer can't be
> > shutdown, but has to be powercycled. 
> > 
> > For instance, I left it doing a read.table on a text format 
> file from this 
> > data (a few hundred megs) and eight hours later it was 
> still "going".
> > I watched the process with "top" for awhile and the 
> computer had plenty 
> > of free memory -- over 100 M this whole time, and R was 
> using almost no
> > CPU.
> > 
> > I have tried all sorts of ways of reading in the data.  
> It's best if I
> > can read the xport file since that has all the original labels which
> > don't get to the text file, but read.xport actually freezes the
> > computer.  
> > 
> > As I said, I am running R 1.8.1 which claims to be the most recent
> > version (when I type is.RAqua.updated()) on an ibook G3/800 
> with 620 M
> > RAM (the maximum) running 10.3.3.  
> > 
> > The command really doesn't much matter.  These are totally 
> normal files
> > and I can load in the normal sized files with the exact same
> > commands.  
> > 
> >>w<-read.table("pedagogue.csv",header=T, sep=",")
> >>library(foreign)
> >>w<-read.xport("demagogue.xpt")
> > 
> > 
> > The xpt files are up to 400 M, and the csv files are about 100 M.  
> > 
> > Janet
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From gguigon at pasteur.fr  Thu May  6 00:08:10 2004
From: gguigon at pasteur.fr (Ghislaine Guigon)
Date: Wed, 5 May 2004 15:08:10 -0700
Subject: [R] externals controls normalization
Message-ID: <a06020401bcbf149aa2ee@[157.99.241.13]>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040505/e095a439/attachment.pl

From dmurdoch at pair.com  Wed May  5 15:18:11 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 05 May 2004 09:18:11 -0400
Subject: [R] Problems in plot
In-Reply-To: <x2n04ngxdw.fsf@biostat.ku.dk>
References: <78B50CF247E5D04B8A5E02D001CC8E9A595C57@XMAIL.sooner.net.ou.edu>
	<Pine.LNX.4.44.0405041721490.24652-100000@gannet.stats>
	<rvhg9014b6t4ookboh8jkpeka2k78phsch@4ax.com>
	<x2n04ngxdw.fsf@biostat.ku.dk>
Message-ID: <niph90t33a6chg8mspo3nvr5akhgiuu765@4ax.com>

On 05 May 2004 09:12:59 +0200, Peter Dalgaard
<p.dalgaard at biostat.ku.dk> wrote :

>Duncan Murdoch <dmurdoch at pair.com> writes:
>
>> I've removed the test for the size of the frame in the case where the
>> frame is minimized.  Now for a minimized R it just uses the physical
>> size of the monitor, as before:  likely giving a window that's too
>> big, but at least not causing errors.
>
>It would be better if you could get a hold of the unminimized size (as
>opposed to the maximized one). Isn't there a way to do that on
>Windows?

I don't know if there is.  I think the GetWindowPlacement function
Brian mentioned returns what GetWindowRect would give if the window
hadn't been minimized, but what we want is GetClientRect. 

GetWindowRect gives the outer dimensions of the window, GetClientRect
gives the "client area", i.e. the area where the MDI child windows are
allowed to show.  GetWindowRect is also too big, just not necessarily
as much too big as what we're currently using (which is what pre-1.9.0
versions were using).

It's possible that we could compute something like GetClientRect, but
it's hard, because I think it depends on all sorts of things like font
settings, etc.  It doesn't really seem worth it to me.  How often do
people create new graphics windows while the MDI frame is minimized,
anyway?

Duncan Murdoch



From jfox at mcmaster.ca  Wed May  5 15:51:15 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 5 May 2004 09:51:15 -0400
Subject: [R] Analysis of ordinal categorical data
In-Reply-To: <200405051245.i45Cj4mO019098@smtp.hispeed.ch>
Message-ID: <20040505135113.SEYV11251.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Thomas,

One approach to an ordinal response variable is the proportional-odds model,
implemented in the MASS package as polr(). The proportional-odds assumption
may not hold, however.

I hope this helps,
 John 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> thsudler at swissonline.ch
> Sent: Wednesday, May 05, 2004 7:45 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Analysis of ordinal categorical data
> 
> Hi
> 
> I would like to analyse an ordinal categorical variable. I 
> know how I can analyse a nominal categorical variable (with 
> multinom or if there are only two levels with glm).
> 
> Does somebody know which command I need in R to analyse an 
> ordinal categorical variable?
> 
> I want to describe the variable y with the variables x1,x2,x3 
> and x4. So my model looks like: y ~ x1+x2+x3+x4.
> 
> y: ordinal factor variable with levels (never, rare, bychance, often).
> 
> Thanks a lot in advance
> Thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From thsudler at swissonline.ch  Wed May  5 16:29:15 2004
From: thsudler at swissonline.ch (thsudler@swissonline.ch)
Date: Wed, 5 May 2004 16:29:15 +0200
Subject: [R] Analysis of ordinal categorical data
Message-ID: <200405051429.i45ETFmO003272@smtp.hispeed.ch>

Thanks a lot for your advice. What do you mean with "the proportional-odds assumption may not hold"? Does this solution with "polr" always works? Or what's important to take into account?

Regards
Thomas

>Dear Thomas,
>
>One approach to an ordinal response variable is the proportional-odds model,
>implemented in the MASS package as polr(). The proportional-odds >assumption
>may not hold, however.
>
>I hope this helps,
> John 
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> thsudler at swissonline.ch
> Sent: Wednesday, May 05, 2004 7:45 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Analysis of ordinal categorical data
> 
> Hi
> 
> I would like to analyse an ordinal categorical variable. I 
> know how I can analyse a nominal categorical variable (with 
> multinom or if there are only two levels with glm).
> 
> Does somebody know which command I need in R to analyse an 
> ordinal categorical variable?
> 
> I want to describe the variable y with the variables x1,x2,x3 
> and x4. So my model looks like: y ~ x1+x2+x3+x4.
> 
> y: ordinal factor variable with levels (never, rare, bychance, often).
> 
> Thanks a lot in advance
> Thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Wed May  5 16:41:36 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 May 2004 15:41:36 +0100 (BST)
Subject: [R] Analysis of ordinal categorical data
In-Reply-To: <20040505135113.SEYV11251.tomts36-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.44.0405051540330.29067-100000@gannet.stats>

On Wed, 5 May 2004, John Fox wrote:

> One approach to an ordinal response variable is the proportional-odds model,
> implemented in the MASS package as polr(). The proportional-odds assumption
> may not hold, however.

And you can find out by comparing the fit with a multinom fit -- see the 
MASS scripts for a worked example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From DAVID.BICKEL at PIONEER.COM  Wed May  5 16:46:18 2004
From: DAVID.BICKEL at PIONEER.COM (Bickel, David)
Date: Wed, 5 May 2004 09:46:18 -0500
Subject: [R] Installation on Windows XP
Message-ID: <5F883C17941B9F4E80E5FA8C9F1C5E0EBD5B48@jhms08.phibred.com>

R never gave me any serious problems until I tried to use it on Windows XP. I had 1.8.1 installed and working successfully for a few weeks. This morning when I launched it, I received this error message: "R for Windows GUI front-end has encountered a problem and needs to close.  We are sorry for the inconvenience."

I downloaded 1.9.0 and installed it, but when I launch it, I get this message: "Fatal error: Invalid HOMEDRIVE."

I would appreciate any assistance.

-Dave
______________________________
David Bickel
http://davidbickel.com



This communication is for use by the intended recipient and ...{{dropped}}



From jfox at mcmaster.ca  Wed May  5 16:48:06 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 5 May 2004 10:48:06 -0400
Subject: [R] Analysis of ordinal categorical data
In-Reply-To: <200405051429.i45ETFmO003272@smtp.hispeed.ch>
Message-ID: <20040505144805.TGHW11251.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Thomas,

Barring a numerical problem, polr() will fit the model as a mechanical
matter, but the proportional-odds model and other, relatively parsimonious,
models for ordinal data, make assumptions about the structure of the data. I
don't think that it's sensible to explain the model in detail here; you
could consult a text that discusses the model -- it's a standard topic in
categorical-data analysis. Two sources are Venables and Ripley's Modern
Applied Statistics with S (with which the MASS package is associated) and my
own R and S-PLUS Companion to Applied Regression. 

Regards,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> thsudler at swissonline.ch
> Sent: Wednesday, May 05, 2004 9:29 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Analysis of ordinal categorical data
> 
> Thanks a lot for your advice. What do you mean with "the 
> proportional-odds assumption may not hold"? Does this 
> solution with "polr" always works? Or what's important to 
> take into account?
> 
> Regards
> Thomas
> 
> >Dear Thomas,
> >
> >One approach to an ordinal response variable is the 
> proportional-odds 
> >model, implemented in the MASS package as polr(). The 
> proportional-odds 
> >>assumption may not hold, however.
> >
> >I hope this helps,
> > John
> >
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> > thsudler at swissonline.ch
> > Sent: Wednesday, May 05, 2004 7:45 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Analysis of ordinal categorical data
> > 
> > Hi
> > 
> > I would like to analyse an ordinal categorical variable. I 
> know how I 
> > can analyse a nominal categorical variable (with multinom 
> or if there 
> > are only two levels with glm).
> > 
> > Does somebody know which command I need in R to analyse an ordinal 
> > categorical variable?
> > 
> > I want to describe the variable y with the variables 
> x1,x2,x3 and x4. 
> > So my model looks like: y ~ x1+x2+x3+x4.
> > 
> > y: ordinal factor variable with levels (never, rare, 
> bychance, often).
> > 
> > Thanks a lot in advance
> > Thomas
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From haynesm at cfr.nichd.nih.gov  Wed May  5 16:55:02 2004
From: haynesm at cfr.nichd.nih.gov (Haynes, Maurice (NIH/NICHD))
Date: Wed, 5 May 2004 10:55:02 -0400 
Subject: [R] Installation on Windows XP
Message-ID: <6000BB14AFA9A741BC2315A598837ED5693D19@nihexchange4.nih.gov>

David,

See the message of Duncan Murdoch to another user which I have pasted next:

On Mon, 26 Apr 2004 09:56:29 -0700, "Brett Melbourne"
<bamelbourne at ucdavis.edu> wrote :

>Alain,
>I'm sure you'll find that the Windows critical update KB835732 has been
>installed on your machine. This is most likely the problem, not SPSS.

I put up a little web page

http://www.murdoch-sutherland.com/HOMEPATH.html

describing this bug in KB835732.  Can you let me know if your
experience with it matches my description?  

For newcomers reading this, the symptoms are that R fails to start.
In version 1.9.0 the error message is usually "Fatal Error: INVALID
HOMEDRIVE".  The patched version of 1.9.0 can deal with the bug; the
workaround in earlier ones is to put something like "R_USER=c:/" on
the command line that starts R.

Duncan Murdoch

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

-----Original Message-----
From: Bickel, David [mailto:DAVID.BICKEL at PIONEER.COM]
Sent: Wednesday, May 05, 2004 10:46 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Installation on Windows XP


R never gave me any serious problems until I tried to use it on Windows XP.
I had 1.8.1 installed and working successfully for a few weeks. This morning
when I launched it, I received this error message: "R for Windows GUI
front-end has encountered a problem and needs to close.  We are sorry for
the inconvenience."

I downloaded 1.9.0 and installed it, but when I launch it, I get this
message: "Fatal error: Invalid HOMEDRIVE."

I would appreciate any assistance.

-Dave
______________________________
David Bickel
http://davidbickel.com



This communication is for use by the intended recipient and ...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From uleopold at science.uva.nl  Wed May  5 17:06:23 2004
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: 05 May 2004 17:06:23 +0200
Subject: [R] syntax error in function 'for'
Message-ID: <1083769583.20658.9.camel@snowdon.science.uva.nl>

Dear list,

I get a syntax error for the following function:

for(na.omit(sqrt(D))>2) {na.omit(A)-(na.omit(B)+(na.omit(sqrt(C))))}

Any idea what is wrong?

I am using R 1.8.1 on Linux, Kernel 2.4.21-i686.

Regards, Ulrich

-- 
__________________________________________________

Ulrich Leopold MSc.

Computational Bio- and Physical Geography (CBPG)
Institute for Biodiversity and Ecosystem Dynamics (IBED)
Faculty of Science
University of Amsterdam
Nieuwe Achtergracht 166
NL-1018WV Amsterdam

Room:   B2.52
Phone:	+31 20 525 7456 (7451 Secretary)
Fax:	+31 20 525 7431
Mobile:	+31 64 220 3028
Email:	uleopold at science.uva.nl
URL:    www.science.uva.nl/ibed/cbpg



From sundar.dorai-raj at PDF.COM  Wed May  5 17:13:47 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 05 May 2004 10:13:47 -0500
Subject: [R] syntax error in function 'for'
In-Reply-To: <1083769583.20658.9.camel@snowdon.science.uva.nl>
References: <1083769583.20658.9.camel@snowdon.science.uva.nl>
Message-ID: <409904AB.2060802@pdf.com>



Ulrich Leopold wrote:

> Dear list,
> 
> I get a syntax error for the following function:
> 
> for(na.omit(sqrt(D))>2) {na.omit(A)-(na.omit(B)+(na.omit(sqrt(C))))}
> 
> Any idea what is wrong?
> 
> I am using R 1.8.1 on Linux, Kernel 2.4.21-i686.
> 
> Regards, Ulrich
> 

`na.omit(sqrt(D))>2' is not of the form `var in seq' as the help page 
for `for' would have told you.

Try help("for").

--sundar



From s-plus at wiwi.uni-bielefeld.de  Wed May  5 17:14:29 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Wed, 05 May 2004 17:14:29 +0200
Subject: [R] syntax error in function 'for'
References: <1083769583.20658.9.camel@snowdon.science.uva.nl>
Message-ID: <409904D5.8050509@wiwi.uni-bielefeld.de>

Ulrich Leopold wrote:

>Dear list,
>
>I get a syntax error for the following function:
>
>for(na.omit(sqrt(D))>2) {na.omit(A)-(na.omit(B)+(na.omit(sqrt(C))))}
>
>Any idea what is wrong?
>
>I am using R 1.8.1 on Linux, Kernel 2.4.21-i686.
>
>Regards, Ulrich
>
>  
>
have a look at help("for"):

Control                 package:base                 R Documentation

Control Flow

Description:
...
Usage:

     if(cond) expr
     if(cond) cons.expr  else  alt.expr
     for(var in seq) expr
    ...
Examples:

     for(i in 1:5) print(1:i)
     for(n in c(2,5,10,20,50)) {
        x <- rnorm(n)
        cat(n,":", sum(x^2),"\n")
     }

Peter Wolf



From p.dalgaard at biostat.ku.dk  Wed May  5 17:11:14 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 May 2004 17:11:14 +0200
Subject: [R] syntax error in function 'for'
In-Reply-To: <1083769583.20658.9.camel@snowdon.science.uva.nl>
References: <1083769583.20658.9.camel@snowdon.science.uva.nl>
Message-ID: <x2oep2aoz1.fsf@biostat.ku.dk>

Ulrich Leopold <uleopold at science.uva.nl> writes:

> Dear list,
> 
> I get a syntax error for the following function:
> 
> for(na.omit(sqrt(D))>2) {na.omit(A)-(na.omit(B)+(na.omit(sqrt(C))))}
> 
> Any idea what is wrong?

Yes, that's not the syntax for a for loop. I have no idea what your
intention might have been, though. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From uleopold at science.uva.nl  Wed May  5 17:32:57 2004
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: 05 May 2004 17:32:57 +0200
Subject: [R] syntax error in function 'for'
In-Reply-To: <x2oep2aoz1.fsf@biostat.ku.dk>
References: <1083769583.20658.9.camel@snowdon.science.uva.nl>
	<x2oep2aoz1.fsf@biostat.ku.dk>
Message-ID: <1083771177.20658.27.camel@snowdon.science.uva.nl>

On Wed, 2004-05-05 at 17:11, Peter Dalgaard wrote:
> Ulrich Leopold <uleopold at science.uva.nl> writes:
> 
> > Dear list,
> > 
> > I get a syntax error for the following function:
> > 
> > for(na.omit(sqrt(D))>2) {na.omit(A)-(na.omit(B)+(na.omit(sqrt(C))))}
> > 
> > Any idea what is wrong?
> 
> Yes, that's not the syntax for a for loop. I have no idea what your
> intention might have been, though.

Ok thanks. I think I misunderstood the example in the help. I think, I
rather need an if function.

I would like to calculate the right hand side if the condition on the
left hand side is met. I am afraid I do not quite understand the syntax.

if(na.omit(sqrt(D))>2) {na.omit(A)-(na.omit(B)+(na.omit(sqrt(C))))}

Now I get the following warning:
the condition has length > 1 and only the first element will be used in:
if(na.omit(sqrt(D))>2) {


-- 
__________________________________________________

Ulrich Leopold MSc.

Computational Bio- and Physical Geography (CBPG)
Institute for Biodiversity and Ecosystem Dynamics (IBED)
Faculty of Science
University of Amsterdam
Nieuwe Achtergracht 166
NL-1018WV Amsterdam

Room:   B2.52
Phone:	+31 20 525 7456 (7451 Secretary)
Fax:	+31 20 525 7431
Mobile:	+31 64 220 3028
Email:	uleopold at science.uva.nl
URL:    www.science.uva.nl/ibed/cbpg



From s-plus at wiwi.uni-bielefeld.de  Wed May  5 17:46:28 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Wed, 05 May 2004 17:46:28 +0200
Subject: [R] syntax error in function 'for'
References: <1083769583.20658.9.camel@snowdon.science.uva.nl>
	<x2oep2aoz1.fsf@biostat.ku.dk>
	<1083771177.20658.27.camel@snowdon.science.uva.nl>
Message-ID: <40990C54.5000800@wiwi.uni-bielefeld.de>

Ulrich Leopold wrote:

>On Wed, 2004-05-05 at 17:11, Peter Dalgaard wrote:
>  
>
>>Ulrich Leopold <uleopold at science.uva.nl> writes:
>>
>>    
>>
>>>Dear list,
>>>
>>>I get a syntax error for the following function:
>>>
>>>for(na.omit(sqrt(D))>2) {na.omit(A)-(na.omit(B)+(na.omit(sqrt(C))))}
>>>
>>>Any idea what is wrong?
>>>      
>>>
>>Yes, that's not the syntax for a for loop. I have no idea what your
>>intention might have been, though.
>>    
>>
>
>Ok thanks. I think I misunderstood the example in the help. I think, I
>rather need an if function.
>
>I would like to calculate the right hand side if the condition on the
>left hand side is met. I am afraid I do not quite understand the syntax.
>
>if(na.omit(sqrt(D))>2) {na.omit(A)-(na.omit(B)+(na.omit(sqrt(C))))}
>
>Now I get the following warning:
>the condition has length > 1 and only the first element will be used in:
>if(na.omit(sqrt(D))>2) {
>
What is the result of the "condition"   (1:10) >2 ? What should be done?
Read the text of the warning again.

Peter Wolf



From jfox at mcmaster.ca  Wed May  5 17:53:17 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 5 May 2004 11:53:17 -0400
Subject: [R] syntax error in function 'for'
In-Reply-To: <1083769583.20658.9.camel@snowdon.science.uva.nl>
Message-ID: <20040505155316.TSFR11783.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Ulrich,

I believe that you want ifelse(), not if(), but there are likely some other
problems lurking here: You're removing missing data independently from the
several vectors -- unless the NAs are all in the same places, things will
not work or not work correctly. As well, what do you want to happen if the
condition fails?

John 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ulrich Leopold
> Sent: Wednesday, May 05, 2004 10:06 AM
> To: R-help
> Subject: [R] syntax error in function 'for'
> 
> Dear list,
> 
> I get a syntax error for the following function:
> 
> for(na.omit(sqrt(D))>2) {na.omit(A)-(na.omit(B)+(na.omit(sqrt(C))))}
> 
> Any idea what is wrong?
> 
> I am using R 1.8.1 on Linux, Kernel 2.4.21-i686.
> 
> Regards, Ulrich
> 
> --



From Jesus.Frias at dit.ie  Wed May  5 18:36:56 2004
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Wed, 05 May 2004 17:36:56 +0100
Subject: [R] Reshape of repeated measures data
Message-ID: <LGECJJCANFBOOHCMGPJEOEJODCAA.Jesus.Frias@dit.ie>

Dear R-helpers,

	I am trying to reshape a data frame that is in a wide format into a long
format one. I have come across the reshape() function, but I have been very
successful using it.

As an example:

ll <-
data.frame(time.1=seq(0.1,1,length=10),L1=rnorm(10),time.2=c(seq(1,7),rep(NA
,3)),R2=c(rnorm(7),rep(NA,3)),time.3=c(seq(1,1.5,length=3)+5,rep(NA,7)),M3=c
(rnorm(3),rep(NA,7)))

which gives me
> ll
   time.1          L1 time.2         R2 time.3         M3
1     0.1 -0.41682731      1 -0.6734289   6.00 -1.7197765
2     0.2  0.45803536      2 -1.7629712   6.25 -0.1756395
3     0.3  0.70046943      3  1.0004967   6.50 -0.6492431
4     0.4 -0.44064572      4 -1.9410689     NA         NA
5     0.5 -0.16925252      5  1.3035123     NA         NA
6     0.6 -0.06501635      6  1.5709351     NA         NA
7     0.7  0.50151676      7  0.1625204     NA         NA
8     0.8 -0.78538134     NA         NA     NA         NA
9     0.9 -0.08774319     NA         NA     NA         NA
10    1.0  1.23420424     NA         NA     NA         NA
>

I have some NA data given that different subjects have different number of
measures and the rate of measurements is different between subjects.

I would like to have a data frame with three variables: 1) time 2) Measure
3) Subject of the form

time	Measure 	Subject
0.1	-0.41682731	L1
...	...		...
6.50 -0.6492431	M3


I have tried with reshape and the closest I've got to it was,

reshape(ll,idvar="Time",varying=list(names(ll)),v.names="Strain",timevar="ID
",direction="long")


Could anybody give me some help?

thanks in advance,

Jesus

--------------------------------------------------------------
Jes??s Mar??a Fr??as Celayeta
School of Food Sci. and Env. Health.
Faculty of Tourism and Food
Dublin Institute of Technology
Cathal Brugha St., Dublin 1. Ireland
t +353 1 4024459 f +353 1 4024495
w www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------


-- 
This message has been scanned for content and 
viruses by the DIT Information Services MailScanner 
Service, and is believed to be clean.
http://www.dit.ie



From germanick89 at hotmail.com  Wed May  5 18:54:17 2004
From: germanick89 at hotmail.com (Bong Jo An)
Date: Wed, 05 May 2004 16:54:17 +0000
Subject: [R] Do I get some help?
Message-ID: <BAY9-F40AWiZAtGYkNU000043f2@hotmail.com>

Dear helper.

I am a student in SFSU.
I had a class that introduce a new open-source "R" in this semester.
It's, however,  hard to understand how to make "R" command.
Especially, at this time we( including my friend) have to explain some 
concepts
(e.g. mahalanobis distance, kolmogorov-smirnow statistics, ROC curve, Gini 
coefficient, and the delta approach)
We have to explain these concepts based on credit scoring and we also have 
to  show examples of each concept by using "R". I did not find any dataset 
with which i can use.

This is why i send an e-mail to you helper.
I think you helpers are able to make "R" command.
Please send me any examples you make.
If you need more information, just let me know and I send all information 
you need.

Thank you!
Have a nice day!

Sincerely,
Bong-Jo An



From wwsprague at ucdavis.edu  Wed May  5 19:09:33 2004
From: wwsprague at ucdavis.edu (foobar)
Date: Wed, 05 May 2004 10:09:33 -0700
Subject: [R] cgi/servlets/httpd  in R
Message-ID: <c7b70h$6rs$1@sea.gmane.org>

Hi R-helpers

Has anyone had any experience doing CGI or Servlets or using an httpd 
server in R?

Context:  we are interested in running dynamic demographic calculations 
on the internet (life tables, and such) in response to form submissions. 
  I might do simple cgi to get started, but loading in data each time 
seems like it would be quite, quite slow.

I have looked at Rserv, but I am most interested in something non-Java 
(once Sun goes the way of the dinosaurs, so will that silly language -- 
come on, flame me, I can take it!)

If there is a project, I might be able to contribute to it.  If there 
isn't, I might start one....

Thanks!
webb



From d.firth at warwick.ac.uk  Wed May  5 19:22:05 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Wed, 5 May 2004 18:22:05 +0100
Subject: [R] cgi/servlets/httpd  in R
In-Reply-To: <c7b70h$6rs$1@sea.gmane.org>
Message-ID: <BB12D17A-9EB8-11D8-8BA1-0050E4C03977@warwick.ac.uk>

On Wednesday, May 5, 2004, at 18:09 Europe/London, foobar wrote:

> Hi R-helpers
>
> Has anyone had any experience doing CGI or Servlets or using an httpd 
> server in R?
>
>

yes.  See the R FAQ, section 4.  (Or maybe you already have, in which 
case I misunderstood the question...)

Best wishes,
David



From hj4cho at msn.com  Wed May  5 19:29:35 2004
From: hj4cho at msn.com (Hyung Cho)
Date: Wed, 05 May 2004 17:29:35 +0000
Subject: [R] heatmap for gene clustering?
Message-ID: <BAY5-F26my332GzkHpI0000231c@hotmail.com>


I am using "heatmap" to cluster genes in microarrays. It works fine with 
100~200 genes.
But when I draw a heatmap with 600 genes, I can't read a clustering tree 
well.
Maybe I will be able to read it by dividing it into several subtrees using a 
function such as "subtree".
I found "subtree" in Splus, but not in R. Is there a similar function in R?
Or, without it, how can I solve this problem?

HJ

_________________________________________________________________



From prechelt at pcpool.mi.fu-berlin.de  Wed May  5 19:39:16 2004
From: prechelt at pcpool.mi.fu-berlin.de (Lutz Prechelt)
Date: Wed, 5 May 2004 19:39:16 +0200
Subject: [R] Do I get some help?
Message-ID: <85D25331FFB7AE4C900EA467D4ADA39204592B@circle.pcpool.mi.fu-berlin.de>


Start R.
Enter
  help.start()
Read "Introduction to R" to understand the basics.
Then in R enter
  ?help.search
and understand how to use that function for finding what
you need.
For instance, try
  ?mahalanobis
and review the examples at the bottom.

  Lutz



From cullens at tcd.ie  Wed May  5 20:19:03 2004
From: cullens at tcd.ie (Simon Cullen)
Date: Wed, 05 May 2004 19:19:03 +0100
Subject: [R] Discontinuities in a simple graph (machine precision?)
In-Reply-To: <opr7ir7te31pelvz@smtp.tcd.ie>
References: <opr7ir7te31pelvz@smtp.tcd.ie>
Message-ID: <opr7jg51bd1pelvz@smtp.tcd.ie>

Thanks to Prof. Ripley, Peter Dalgaard and Uwe Ligges for pointing out  
that all I needed to do to improve the precision was replace
> inted <- integrate(integrand, a, Inf)
with
> inted <- integrate(integrand, a, Inf,rel.tol = .Machine$double.eps^0.5)

Thanks for the advice!

-- 
SC

Simon Cullen
Room 3030
Dept. Of Economics
Trinity College Dublin

Ph. (608)3477
Email cullens at tcd.ie



From rrsilva at ib.usp.br  Wed May  5 20:50:26 2004
From: rrsilva at ib.usp.br (=?iso-8859-1?q?Rog=E9rio_Rosa_da_Silva?=)
Date: Wed, 5 May 2004 15:50:26 -0300
Subject: [R] sample
Message-ID: <200405051550.26630.rrsilva@ib.usp.br>

Dear List:

	I have the following simple program:

x<- sample(site)
VarGuilda1<- var(tapply(x,site,func1))
VarGuilda2<- var(tapply(x,site,func2))
VarGuilda3<- var(tapply(x,site,func3))
VarGuilda4<- var(tapply(x,site,func4))
VarGuilda5<- var(tapply(x,site,func5))
VarGuilda6<- var(tapply(x,site,func6))
VarGuilda7<- var(tapply(x,site,func7))
VarGuilda8<- var(tapply(x,site,func8))
VarGuilda9<- var(tapply(x,site,func9))
Var<-cbind(VarGuilda1,VarGuilda2,VarGuilda3,VarGuilda4,VarGuilda5,VarGuilda6,VarGuilda7,VarGuilda8,VarGuilda9)
write(Var,file="LAU_Var_01.txt", ncol=9)

	Every time I want to repeat this I have to change the name of *.txt 
file manually. How can I automate this, so it could be done for all the  
*.txt files (1000) I have to generate.


	Thanks in advance, Rog??rio

-- 
Rog??rio R. Silva
MZUSP http://www.mz.usp.br
Linux User #354364
Linux counter http://counter.li.org



From wwsprague at ucdavis.edu  Wed May  5 20:53:12 2004
From: wwsprague at ucdavis.edu (Webb Sprague)
Date: Wed, 05 May 2004 11:53:12 -0700
Subject: [R] weirdness in sourc()ing a dump()  (bug?)
Message-ID: <c7bd2s$u0l$1@sea.gmane.org>

Hi all,

I dump the result of a long simulation, which I know has run to 
completion and returned a fairly complex list of lists of things. 
However, when I try to read it back in, I get the following error:

 > source ('../SIMULATIONS/run.1.R')
Error in structure(list(do.extinction.runs, alpha = 1.8, delta.change = 
0.005,  : Object "do.extinction.runs" not found

I think the offending part of my dump is:

<SNIP OF LOTS OF DATA>
call.list = structure(list(do.extinction.runs, alpha = 1.8,
         delta.change = 0.005, delta.bar = 0.01, extinction = seq(0.6,
             0.8, 0.005)), .Names = c("", "alpha", "delta.change",
     "delta.bar", "extinction"))),
</SNIP>

The return statement for the simulation is:

<SNIP>
return(list (DATA=my.data, MEANS=data.frame(EXT.CUT=means[,1], 
MEAN=means[,2]), run.date=date(), call.list=as.list(match.call())))
</SNIP>

As you can see, I am trying to return my call parameters as a list (so I 
can write appropriate titles on my graphs).  It works just fine when do

 > a = do.extinction.runs(blah, blah)

but not when I do:

 > a = do.ext...
 > dump('a', 'foo.R')
 > source ('foo.R')

Any thoughts?  Seems like a bug in dump, and I would be happy to help 
squash it if the right person gets hold of me.

Thanks much to a list that might be getting tired of me this week!

W



From sundar.dorai-raj at PDF.COM  Wed May  5 20:58:29 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 05 May 2004 13:58:29 -0500
Subject: [R] sample
In-Reply-To: <200405051550.26630.rrsilva@ib.usp.br>
References: <200405051550.26630.rrsilva@ib.usp.br>
Message-ID: <40993955.9000907@pdf.com>



Rog??rio Rosa da Silva wrote:
> Dear List:
> 
> 	I have the following simple program:
> 
> x<- sample(site)
> VarGuilda1<- var(tapply(x,site,func1))
> VarGuilda2<- var(tapply(x,site,func2))
> VarGuilda3<- var(tapply(x,site,func3))
> VarGuilda4<- var(tapply(x,site,func4))
> VarGuilda5<- var(tapply(x,site,func5))
> VarGuilda6<- var(tapply(x,site,func6))
> VarGuilda7<- var(tapply(x,site,func7))
> VarGuilda8<- var(tapply(x,site,func8))
> VarGuilda9<- var(tapply(x,site,func9))
> Var<-cbind(VarGuilda1,VarGuilda2,VarGuilda3,VarGuilda4,VarGuilda5,VarGuilda6,VarGuilda7,VarGuilda8,VarGuilda9)
> write(Var,file="LAU_Var_01.txt", ncol=9)
> 
> 	Every time I want to repeat this I have to change the name of *.txt 
> file manually. How can I automate this, so it could be done for all the  
> *.txt files (1000) I have to generate.
> 
> 
> 	Thanks in advance, Rog??rio
> 

Use ?paste.

for(i in 1:1000) {
   ...
   file <- paste("LAU_Var_", i, ".txt", sep = "")
   write(Var, file = file, ncol = 9)
}

or if you want something like "LAU_VAR_xxxx.txt", you can use ?sprintf:

file <- "LAU_Var_%04d.txt"
for(i in 1:1000) {
   ...
   write(Var, file = sprintf(file, i), ncol = 9)
}


--sundar



From wwsprague at ucdavis.edu  Wed May  5 20:56:56 2004
From: wwsprague at ucdavis.edu (foobar)
Date: Wed, 05 May 2004 11:56:56 -0700
Subject: [R] sample
In-Reply-To: <200405051550.26630.rrsilva@ib.usp.br>
References: <200405051550.26630.rrsilva@ib.usp.br>
Message-ID: <409938F8.1000507@ucdavis.edu>


> 
> 	Every time I want to repeat this I have to change the name of *.txt 
> file manually. How can I automate this, so it could be done for all the  
> *.txt files (1000) I have to generate.

Use something like:

for (i in 1:1000){
   name = paste('foo_', i, '.txt', sep='')

You can figure out how to apply that idea.

You can also refer to a variable by its name in string form, like

a = get(paste('varname', i, sep=''))

paste is your friend!

W



From p.dalgaard at biostat.ku.dk  Wed May  5 21:05:29 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 May 2004 21:05:29 +0200
Subject: [R] weirdness in sourc()ing a dump()  (bug?)
In-Reply-To: <c7bd2s$u0l$1@sea.gmane.org>
References: <c7bd2s$u0l$1@sea.gmane.org>
Message-ID: <x2ekpy66fa.fsf@biostat.ku.dk>

Webb Sprague <wwsprague at ucdavis.edu> writes:

> return(list (DATA=my.data, MEANS=data.frame(EXT.CUT=means[,1],
> MEAN=means[,2]), run.date=date(), call.list=as.list(match.call())))
> </SNIP>
> 
> As you can see, I am trying to return my call parameters as a list (so
> I can write appropriate titles on my graphs).  It works just fine when
> do

> Any thoughts?  Seems like a bug in dump, and I would be happy to help
> squash it if the right person gets hold of me.

Yep, it's a bug. A minimal version is

> f <- function()as.list(match.call())
> dput(f())
list(f)

> dput(f(),"xx")
> dget("xx")
[[1]]
function()as.list(match.call())

(or an error if you remove f first). What should happen is probably

> dput(f)
list(as.name("f"))

Similarly

> f <- function()match.call()
> dput(f())
f()
> dput(f(),"xx")
> rm(f)
> dget("xx")
Error in eval(expr, envir, enclos) : couldn't find function "f"

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From andy_liaw at merck.com  Wed May  5 21:11:35 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 5 May 2004 15:11:35 -0400
Subject: [R] sample
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D1D@usrymx25.merck.com>

Others have pointed out `paste' for constructing the file names.  What I'd
like to suggest is `cleaning up' the code a bit.  Assuming func1, ..., func9
all return a single number, so that each tapply() call returns a vector, you
can try something like:

> f1 = mean
> f2 = median
> f3 = function(x) (mean(x) + median(x)) / 2
> ## Put the functions into a list.
> flist = sapply(1:3, function(i) get(paste("f", i, sep="")))
> x = rnorm(20)           ## generate some data
> g = rep(1:4, each=5)    ## generate groups
> res = apply(sapply(flist, function(f) tapply(x, g, f)), 2, var)
> res
[1] 0.4264803 0.5438598 0.4639551

(You obviously need to work out the details to make sure this fits the data
structure you have.)

This is sort of taking the `whole object' approach.  You can take it one
step further by using replicate() instead of explicit for loop to repeat the
1000 times...

Andy

> From: Rog??rio Rosa da Silva
> 
> Dear List:
> 
> 	I have the following simple program:
> 
> x<- sample(site)
> VarGuilda1<- var(tapply(x,site,func1))
> VarGuilda2<- var(tapply(x,site,func2))
> VarGuilda3<- var(tapply(x,site,func3))
> VarGuilda4<- var(tapply(x,site,func4))
> VarGuilda5<- var(tapply(x,site,func5))
> VarGuilda6<- var(tapply(x,site,func6))
> VarGuilda7<- var(tapply(x,site,func7))
> VarGuilda8<- var(tapply(x,site,func8))
> VarGuilda9<- var(tapply(x,site,func9))
> Var<-cbind(VarGuilda1,VarGuilda2,VarGuilda3,VarGuilda4,VarGuil
> da5,VarGuilda6,VarGuilda7,VarGuilda8,VarGuilda9)
> write(Var,file="LAU_Var_01.txt", ncol=9)
> 
> 	Every time I want to repeat this I have to change the 
> name of *.txt 
> file manually. How can I automate this, so it could be done 
> for all the  
> *.txt files (1000) I have to generate.
> 
> 
> 	Thanks in advance, Rog??rio
> 
> -- 
> Rog??rio R. Silva
> MZUSP http://www.mz.usp.br
> Linux User #354364
> Linux counter http://counter.li.org
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From p.dalgaard at biostat.ku.dk  Wed May  5 21:10:00 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 May 2004 21:10:00 +0200
Subject: [R] weirdness in sourc()ing a dump()  (bug?)
In-Reply-To: <x2ekpy66fa.fsf@biostat.ku.dk>
References: <c7bd2s$u0l$1@sea.gmane.org> <x2ekpy66fa.fsf@biostat.ku.dk>
Message-ID: <x2ad0m667r.fsf@biostat.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> (or an error if you remove f first). What should happen is probably
> 
> > dput(f)
> list(as.name("f"))

Erm, more likely: quote(f)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Wed May  5 21:20:51 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 May 2004 20:20:51 +0100 (BST)
Subject: [R] weirdness in sourc()ing a dump()  (bug?)
In-Reply-To: <x2ekpy66fa.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0405052013000.31430-100000@gannet.stats>

I don't think it is a bug.  Note that dump does not even claim to dump
lists let alone symbols, but ?dump says

     At present the implementation of 'dump' is very incomplete and it
     really only works for functions and simple vectors.

Given that, this is not unexpected. (Looks like more than one person did 
not check the help page ....)

I think save/load is a much safer way to handle saving R objects, and it 
does work in PD's example.


On 5 May 2004, Peter Dalgaard wrote:

> Webb Sprague <wwsprague at ucdavis.edu> writes:
> 
> > return(list (DATA=my.data, MEANS=data.frame(EXT.CUT=means[,1],
> > MEAN=means[,2]), run.date=date(), call.list=as.list(match.call())))
> > </SNIP>
> > 
> > As you can see, I am trying to return my call parameters as a list (so
> > I can write appropriate titles on my graphs).  It works just fine when
> > do
> 
> > Any thoughts?  Seems like a bug in dump, and I would be happy to help
> > squash it if the right person gets hold of me.
> 
> Yep, it's a bug. A minimal version is
> 
> > f <- function()as.list(match.call())
> > dput(f())
> list(f)
> 
> > dput(f(),"xx")
> > dget("xx")
> [[1]]
> function()as.list(match.call())
> 
> (or an error if you remove f first). What should happen is probably
> 
> > dput(f)
> list(as.name("f"))
> 
> Similarly
> 
> > f <- function()match.call()
> > dput(f())
> f()
> > dput(f(),"xx")
> > rm(f)
> > dget("xx")
> Error in eval(expr, envir, enclos) : couldn't find function "f"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sdavis2 at mail.nih.gov  Wed May  5 21:23:36 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 05 May 2004 15:23:36 -0400
Subject: [R] heatmap for gene clustering?
In-Reply-To: <BAY5-F26my332GzkHpI0000231c@hotmail.com>
Message-ID: <BCBEB778.7ADA%sdavis2@mail.nih.gov>

Look into ?cutree.

Sean

On 5/5/04 1:29 PM, "Hyung Cho" <hj4cho at msn.com> wrote:

> 
> I am using "heatmap" to cluster genes in microarrays. It works fine with
> 100~200 genes.
> But when I draw a heatmap with 600 genes, I can't read a clustering tree
> well.
> Maybe I will be able to read it by dividing it into several subtrees using a
> function such as "subtree".
> I found "subtree" in Splus, but not in R. Is there a similar function in R?
> Or, without it, how can I solve this problem?
> 
> HJ
> 
> _________________________________________________________________
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dmurdoch at pair.com  Wed May  5 21:40:48 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 05 May 2004 15:40:48 -0400
Subject: [R] weirdness in sourc()ing a dump()  (bug?)
In-Reply-To: <Pine.LNX.4.44.0405052013000.31430-100000@gannet.stats>
References: <x2ekpy66fa.fsf@biostat.ku.dk>
	<Pine.LNX.4.44.0405052013000.31430-100000@gannet.stats>
Message-ID: <gfgi90djg77sivu1ve4ahsc3qpvgds1ptu@4ax.com>

On Wed, 5 May 2004 20:20:51 +0100 (BST), Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote :

>I don't think it is a bug.  Note that dump does not even claim to dump
>lists let alone symbols, but ?dump says
>
>     At present the implementation of 'dump' is very incomplete and it
>     really only works for functions and simple vectors.
>
>Given that, this is not unexpected. (Looks like more than one person did 
>not check the help page ....)
>
>I think save/load is a much safer way to handle saving R objects, and it 
>does work in PD's example.

I'd still call it a bug, since 'dump("x"); source("dumpdata.R")' could
change the meaning of x without any warning, and that can't be
desirable behaviour.  

For example,

> f<-function (...) 
+ {
+     return(list(call.list = as.list(match.call())))
+ }
> x <- f(y=4)
> x
$call.list
$call.list[[1]]
f

$call.list$y
[1] 4


> f <- quote(g)
> dump("x")
> source("dumpdata.R")
> x
$call.list
$call.list[[1]]
g

$call.list$y
[1] 4

If dump() can't handle certain kinds of objects, then it should signal
an error, it shouldn't dump something that can't be sourced properly.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Wed May  5 21:50:29 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 May 2004 20:50:29 +0100 (BST)
Subject: [R] weirdness in sourc()ing a dump()  (bug?)
In-Reply-To: <gfgi90djg77sivu1ve4ahsc3qpvgds1ptu@4ax.com>
Message-ID: <Pine.LNX.4.44.0405052042330.31559-100000@gannet.stats>

On Wed, 5 May 2004, Duncan Murdoch wrote:

> On Wed, 5 May 2004 20:20:51 +0100 (BST), Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote :
> 
> >I don't think it is a bug.  Note that dump does not even claim to dump
> >lists let alone symbols, but ?dump says
> >
> >     At present the implementation of 'dump' is very incomplete and it
> >     really only works for functions and simple vectors.
> >
> >Given that, this is not unexpected. (Looks like more than one person did 
> >not check the help page ....)
> >
> >I think save/load is a much safer way to handle saving R objects, and it 
> >does work in PD's example.
> 
> I'd still call it a bug, since 'dump("x"); source("dumpdata.R")' could
> change the meaning of x without any warning, and that can't be
> desirable behaviour.  

That's not what it says it does, and not what the S version achieves 
either.  (Do see the documentation on `what is a bug' in the FAQ, which 
does not agree with you.)

I was trying to be constructive: save/load *is* supposed to reproduce
objects, and it just not realistic to get dump/source to do that.  And we
do warn about it in the documentation and I can see nowhere that
recommends dump/save as a way of saving objects ....  (If there is such a 
place, then that is a bug and needs fixing.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Wed May  5 22:42:48 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 05 May 2004 16:42:48 -0400
Subject: [R] weirdness in sourc()ing a dump()  (bug?)
In-Reply-To: <Pine.LNX.4.44.0405052042330.31559-100000@gannet.stats>
References: <gfgi90djg77sivu1ve4ahsc3qpvgds1ptu@4ax.com>
	<Pine.LNX.4.44.0405052042330.31559-100000@gannet.stats>
Message-ID: <psji909q1d1nj6n97k620vmmn344r59fit@4ax.com>

On Wed, 5 May 2004 20:50:29 +0100 (BST), Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote :

>That's not what it says it does, and not what the S version achieves 
>either.  (Do see the documentation on `what is a bug' in the FAQ, which 
>does not agree with you.)

"If a command does the wrong thing, that is a bug. But be sure you
know for certain what it ought to have done."

This is a case where we disagree about what it ought to have done. The
documentation says

"This function takes a vector of names of R objects and produces
 text representations of the objects on a file or connection. A
 'dump' file can be 'source'd into another R (or S) session."

The error generated in the original example contradicts this, and the
incorrect value being loaded in my example contradicts the implication
that when 'source'd, the value will match the original one.

Later it says

"At present the implementation of 'dump' is very incomplete and it
really only works for functions and simple vectors."

Here's where we disagree about the interpretation.  If I understand
you correctly, you're saying that this implies that any behaviour at
all for other objects would be acceptable.  I'd say it's okay to have
limitations on the function, but it's too much of a contradiction with
the purpose of the function given in the initial description if it
silently corrupts data.

>I was trying to be constructive: save/load *is* supposed to reproduce
>objects, and it just not realistic to get dump/source to do that.  And we
>do warn about it in the documentation and I can see nowhere that
>recommends dump/save as a way of saving objects ....  (If there is such a 
>place, then that is a bug and needs fixing.)

I think we're both trying to be constructive.  I'm suggesting that the
internal dump code should check the type of inputs, and generate an
error when it gets something that it can't handle properly.

Duncan Murdoch



From p.dalgaard at biostat.ku.dk  Wed May  5 22:50:50 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 May 2004 22:50:50 +0200
Subject: [R] weirdness in sourc()ing a dump()  (bug?)
In-Reply-To: <Pine.LNX.4.44.0405052042330.31559-100000@gannet.stats>
References: <Pine.LNX.4.44.0405052042330.31559-100000@gannet.stats>
Message-ID: <x265ba61jp.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Wed, 5 May 2004, Duncan Murdoch wrote:
> 
> > On Wed, 5 May 2004 20:20:51 +0100 (BST), Prof Brian Ripley
> > <ripley at stats.ox.ac.uk> wrote :
> > 
> > >I don't think it is a bug.  Note that dump does not even claim to dump
> > >lists let alone symbols, but ?dump says
> > >
> > >     At present the implementation of 'dump' is very incomplete and it
> > >     really only works for functions and simple vectors.
> > >
> > >Given that, this is not unexpected. (Looks like more than one person did 
> > >not check the help page ....)
> > >
> > >I think save/load is a much safer way to handle saving R objects, and it 
> > >does work in PD's example.
> > 
> > I'd still call it a bug, since 'dump("x"); source("dumpdata.R")' could
> > change the meaning of x without any warning, and that can't be
> > desirable behaviour.  
> 
> That's not what it says it does, and not what the S version achieves 
> either.  (Do see the documentation on `what is a bug' in the FAQ, which 
> does not agree with you.)

Weelll.. The goal of dump/dput is to create a construct that can be
evaluated so as to yield the original object. This is one place where
we fail to meet that goal, so I'll call it a bug, documented or not.
Especially, since it is something we might actually be able to fix
fairly simply (note "might" -- we've had our share of "fixes" that
didn't in the deparsing area).

> I was trying to be constructive: save/load *is* supposed to reproduce
> objects, and it just not realistic to get dump/source to do that.  And we
> do warn about it in the documentation and I can see nowhere that
> recommends dump/save as a way of saving objects ....  (If there is such a 
> place, then that is a bug and needs fixing.)

I don't disagree that save/load is a better strategy for data storage,
but dump and friends do have the potential to create an *editable*
text representation, so there is some point in trying to make them
work predictably as far as possible.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From lforzani at stat.umn.edu  Wed May  5 23:20:58 2004
From: lforzani at stat.umn.edu (Liliana Forzani)
Date: Wed, 5 May 2004 16:20:58 -0500 (CDT)
Subject: [R] GLMM with random slope
In-Reply-To: <Pine.LNX.4.44.0405041817210.24775-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0405051619300.2436-100000@muskrat.stat.umn.edu>


I was using GLMM to fit a model (binomial)
with random slope.

When I put random~1|ID  I got the results (random intercept)

when I put random~time|ID  I got an error

Thanks. Liliana



From wwsprague at ucdavis.edu  Wed May  5 23:36:27 2004
From: wwsprague at ucdavis.edu (foobar)
Date: Wed, 05 May 2004 14:36:27 -0700
Subject: [R] weirdness in sourc()ing a dump()  (bug?)
In-Reply-To: <x265ba61jp.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0405052042330.31559-100000@gannet.stats>
	<x265ba61jp.fsf@biostat.ku.dk>
Message-ID: <c7bmkv$n21$1@sea.gmane.org>

Well, that has been interesting.  I don't actually understand why there 
are separate commands for "dump" and "save", rather than options to one 
single "save x object to a file for later".

I would agree with Peter that being able to edit (possible compex) data 
object would be very nice.

I am forced to agree with Brian that I was remiss in reading the 
documentation.

W



From kj_phoenix at hotmail.com  Wed May  5 23:48:28 2004
From: kj_phoenix at hotmail.com (liao kaijun)
Date: Wed, 05 May 2004 21:48:28 +0000
Subject: [R] need help!
Message-ID: <BAY14-F29zJUePldjMq00007e31@hotmail.com>

Dear:
I just try to use the R to solve some statistic problem recently. but i 
found that there are no a good way to edit the data , it is not friendly to 
deal with data like excel when i use command "edit()" or "fix()". i even 
canot copy one column data. it just let me copy one cell data. so i think 
probably there are some other command can solve this trouble better. it 
will be very help if yuo can tell me.

thanks

kj.

_________________________________________________________________




From csardi at rmki.kfki.hu  Thu May  6 02:18:19 2004
From: csardi at rmki.kfki.hu (Csardi Gabor)
Date: Thu, 6 May 2004 02:18:19 +0200
Subject: [R] copying R objects in C
Message-ID: <20040506001819.GB26976@bifur.rmki.kfki.hu>

Dear R Users,

do you know a way to copy an R object using C code? I know that
there is a copyMatrix and also a copyVector function. There is
also something called copyListMatrix, what is this good for? Is
there anything for copying a list (of course deep copy is
needed)? 

Thank you for your help,
Gabor

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK



From jwdougherty at mcihispeed.net  Thu May  6 03:35:50 2004
From: jwdougherty at mcihispeed.net (JWDougherty)
Date: Wed, 5 May 2004 18:35:50 -0700
Subject: [R] reading data
In-Reply-To: <6.0.3.0.1.20040505113104.01afc498@mail.med.up.pt>
References: <6.0.3.0.1.20040505113104.01afc498@mail.med.up.pt>
Message-ID: <200405051835.50854.jwdougherty@mcihispeed.net>

On Wednesday 05 May 2004 03:37, Margarida J??lia Rodrigues Igreja wrote:
> Hello,
> I??m trying to read data from a text file but i can??t
>
> When i print:
>  > a<-read.table(file="C:/dados10.txt")
>
> The next error appears:
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `C:/dados10.txt'
>   Can you help me?
>
Margarida,

It depends on a number of things.  First, is the "C:" a local harddrive (on 
the machine you are using) non-local.  Second, "C:\" is a DOS/Windows 
construct and the slash particular will be interpreted differently under a 
*nix system than under DOS.  *nixes use the "/" instead.  "C:/dados.txt" 
would seem to indicate the "dados.txt" file in the root directory of a DOS or 
Windows machine.  SO, first be certain on which machine, and on which drive, 
and in which directory on that machine your file is located.  After that, if 
the file is on a non-local drive, then be certain that the drive and 
directory are mounted and readable from the machine on which you are running 
R.  Also, you must determine if you have read rights for the drive, 
directory, and file.  If you don not, you need to have the administrator or 
file owner grant them to you.  Once these steps are done, then by providing 
are the mounted alias of the drive, directory and filename, you should be 
good.  Otherwise, you should be able to copy the data to your working 
directory.  

Good luck,
John Dougherty



From d.scott at auckland.ac.nz  Thu May  6 04:00:25 2004
From: d.scott at auckland.ac.nz (David Scott)
Date: Thu, 6 May 2004 14:00:25 +1200 (NZST)
Subject: [R] strptime
Message-ID: <Pine.LNX.4.44.0405061347520.8584-100000@stat71.stat.auckland.ac.nz>


Delving into the murky world of dates and times I found this:

dates <- c("02/27/92", "02/27/92", "01/14/92", "02/28/92", "02/01/92")
> times <- c("23:03:20", "22:29:56", "01:03:30", "18:21:03", "16:56:26")
> x <- paste(dates, times)
> z <- strptime(x, "%m/%d/%y %H:%M:%S")
> z
[1] "1992-02-27 23:03:20" "1992-02-27 22:29:56" "1992-01-14 01:03:30"
[4] "1992-02-28 18:21:03" "1992-02-01 16:56:26"

which I understand. But then 

> length(dates)
[1] 5
> length(times)
[1] 5
> length(z)
[1] 9
> 

which I don't.

It seems that length of a POSIXlt vector (which z is), always returns 9. 

David Scott

PS: Using 1.9.0 on linux





_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
		The University of Auckland, PB 92019
		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz 


Graduate Officer, Department of Statistics



From andy_liaw at merck.com  Thu May  6 04:10:24 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 5 May 2004 22:10:24 -0400
Subject: [R] strptime
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D24@usrymx25.merck.com>

Here's a hint:

> str(unclass(z))
List of 9
 $ sec  : int [1:5] 20 56 30 3 26
 $ min  : int [1:5] 3 29 3 21 56
 $ hour : int [1:5] 23 22 1 18 16
 $ mday : int [1:5] 27 27 14 28 1
 $ mon  : int [1:5] 1 1 0 1 1
 $ year : int [1:5] 92 92 92 92 92
 $ wday : int [1:5] 4 4 2 5 6
 $ yday : int [1:5] 57 57 13 58 31
 $ isdst: int [1:5] 0 0 0 0 0

Andy

> From: David Scott
> 
> Delving into the murky world of dates and times I found this:
> 
> dates <- c("02/27/92", "02/27/92", "01/14/92", "02/28/92", "02/01/92")
> > times <- c("23:03:20", "22:29:56", "01:03:30", "18:21:03", 
> "16:56:26")
> > x <- paste(dates, times)
> > z <- strptime(x, "%m/%d/%y %H:%M:%S")
> > z
> [1] "1992-02-27 23:03:20" "1992-02-27 22:29:56" "1992-01-14 01:03:30"
> [4] "1992-02-28 18:21:03" "1992-02-01 16:56:26"
> 
> which I understand. But then 
> 
> > length(dates)
> [1] 5
> > length(times)
> [1] 5
> > length(z)
> [1] 9
> > 
> 
> which I don't.
> 
> It seems that length of a POSIXlt vector (which z is), always 
> returns 9. 
> 
> David Scott
> 
> PS: Using 1.9.0 on linux
> 
> 
> 
> 
> 
> _________________________________________________________________
> David Scott	Department of Statistics, Tamaki Campus
> 		The University of Auckland, PB 92019
> 		Auckland	NEW ZEALAND
> Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
> Email:	d.scott at auckland.ac.nz 
> 
> 
> Graduate Officer, Department of Statistics
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From edd at debian.org  Thu May  6 04:11:14 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 5 May 2004 21:11:14 -0500
Subject: [R] strptime
In-Reply-To: <Pine.LNX.4.44.0405061347520.8584-100000@stat71.stat.auckland.ac.nz>
References: <Pine.LNX.4.44.0405061347520.8584-100000@stat71.stat.auckland.ac.nz>
Message-ID: <20040506021114.GA7565@sonny.eddelbuettel.com>

On Thu, May 06, 2004 at 02:00:25PM +1200, David Scott wrote:
> 
> Delving into the murky world of dates and times I found this:
> 
> dates <- c("02/27/92", "02/27/92", "01/14/92", "02/28/92", "02/01/92")
> > times <- c("23:03:20", "22:29:56", "01:03:30", "18:21:03", "16:56:26")
> > x <- paste(dates, times)
> > z <- strptime(x, "%m/%d/%y %H:%M:%S")
> > z
> [1] "1992-02-27 23:03:20" "1992-02-27 22:29:56" "1992-01-14 01:03:30"
> [4] "1992-02-28 18:21:03" "1992-02-01 16:56:26"
> 
> which I understand. But then 
> 
> > length(dates)
> [1] 5
> > length(times)
> [1] 5
> > length(z)
> [1] 9
> > 
> 
> which I don't.
> 
> It seems that length of a POSIXlt vector (which z is), always returns 9. 

Yup, as documented. It takes a little getting used to, but if you read
help(DateTimeClasses), preferably a few times and with coffee or tea at your
side, it all becomes clear.  What you wanted was possibly a cast to POSIXct:

> length(z)
[1] 9
> length(as.POSIXct(z))
[1] 5

Hth, Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From ggrothendieck at myway.com  Thu May  6 04:12:39 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 6 May 2004 02:12:39 +0000 (UTC)
Subject: [R] strptime
References: <Pine.LNX.4.44.0405061347520.8584-100000@stat71.stat.auckland.ac.nz>
Message-ID: <loom.20040506T041126-767@post.gmane.org>


Issuing the command:

   unclass(z)

will show what is going on here.


David Scott <d.scott <at> auckland.ac.nz> writes:

: 
: Delving into the murky world of dates and times I found this:
: 
: dates <- c("02/27/92", "02/27/92", "01/14/92", "02/28/92", "02/01/92")
: > times <- c("23:03:20", "22:29:56", "01:03:30", "18:21:03", "16:56:26")
: > x <- paste(dates, times)
: > z <- strptime(x, "%m/%d/%y %H:%M:%S")
: > z
: [1] "1992-02-27 23:03:20" "1992-02-27 22:29:56" "1992-01-14 01:03:30"
: [4] "1992-02-28 18:21:03" "1992-02-01 16:56:26"
: 
: which I understand. But then 
: 
: > length(dates)
: [1] 5
: > length(times)
: [1] 5
: > length(z)
: [1] 9
: > 
: 
: which I don't.
: 
: It seems that length of a POSIXlt vector (which z is), always returns 9. 
: 
: David Scott
: 
: PS: Using 1.9.0 on linux
: 
: 
: _________________________________________________________________
: David Scott	Department of Statistics, Tamaki Campus
: 		The University of Auckland, PB 92019
: 		Auckland	NEW ZEALAND
: Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
: Email:	d.scott <at> auckland.ac.nz 
: 
: Graduate Officer, Department of Statistics
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From james-chapman at uiowa.edu  Thu May  6 04:55:46 2004
From: james-chapman at uiowa.edu (James Chapman)
Date: Wed, 5 May 2004 21:55:46 -0500
Subject: [R] R on Windows Hangs on Packages Built from Sources
Message-ID: <200405060255.i462tsfG021903@hypatia.math.ethz.ch>

Hi,

I am currently having the following problem with R 1.9.0. Any package that
contains C or Fortran code hangs after I have built it and load it into R.
I've tried this with RMySQL and udunits, originally I thought I had done
something subtly wrong in configuring these packages; but I just had the
same problem with a simple example R package that I wrote. I was able to
build and load the package on a Linux system at school so I figure I've,
hopefully, ruled out a programming problem on my part.

The system I'm having the problem on is as follows:
AMD AthlonXP
R 1.9.0 installed from binaries
GCC 3.3.1

Thanks,

James



From csardi at rmki.kfki.hu  Thu May  6 05:47:15 2004
From: csardi at rmki.kfki.hu (Csardi Gabor)
Date: Thu, 6 May 2004 05:47:15 +0200
Subject: [R] copying R objects in C
In-Reply-To: <20040506001819.GB26976@bifur.rmki.kfki.hu>
References: <20040506001819.GB26976@bifur.rmki.kfki.hu>
Message-ID: <20040506034715.GA30774@bifur.rmki.kfki.hu>

answer to myself:

the 'duplicate' function does this, am I right?
It seems so....

Gabor

On Thu, May 06, 2004 at 02:18:19AM +0200, Csardi Gabor wrote:
> Dear R Users,
> 
> do you know a way to copy an R object using C code? I know that
> there is a copyMatrix and also a copyVector function. There is
> also something called copyListMatrix, what is this good for? Is
> there anything for copying a list (of course deep copy is
> needed)? 
> 
> Thank you for your help,
> Gabor
[...]

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK



From dunn at usq.edu.au  Thu May  6 06:54:33 2004
From: dunn at usq.edu.au (Peter Dunn)
Date: Thu, 06 May 2004 14:54:33 +1000
Subject: [R] Printing ps pictures with transparent b'ground
Message-ID: <4099C509.8020703@usq.edu.au>

Hi all

I wish to create a ps file of a picture produced in R.
With my limited R, I see two ways:
1. Print direct to the postscript device
2. Print to the screen, and save to ps using dev.print.

I want a white (not transparent) background.  Option
1 above works fine, but 2 does not:  even when I say I
want a white background, I get transparent; perhaps I
misread the help files.

Here's some R code:

### Method 1
### - print straight to postscript device
postscript(horizontal=FALSE,
	onefile=FALSE,
	bg="white",
	width=4,
	height=4,
	paper="special",
    file="testfile.eps" )
curve( dnorm, from=-3, to=3)

dev.off()

### Method 2
### - print to screen, and save using  postscript

x11(width=4, height=4)
curve( dnorm, from=-3, to=3)

dev.print( postscript,
    horizontal=FALSE,
	onefile=FALSE,
	bg="white",
	width=4,
	height=4,
	paper="special",
    file="testfile2.eps" )


I then want to place these files in a LaTeX prosper document
for a presentation.  A typical (minimal) prosper file is:

\documentclass[pdf,colorBG,slideColor,whitecross]{prosper}

\begin{document}

\begin{slide}{Print to \textsc{ps} direct}
\includegraphics{testfile.eps}
\end{slide}

\begin{slide}{Print to screen first}
\includegraphics{testfile2.eps}
\end{slide}

\end{document}


The  whitecross  class provides a blue background for the
presentation.  testfile.eps  appears with a white background
on the slides, but  testfile2.eps  has a transparent
background.

I'd apprecaite if someone could explain why the two are not equivalent,
or how I can coerce the second option to have a white background?  Or
even explain my misunderstandings (assuming (with high probability)
that I have some).

Thanks.

P.

 > version
          _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    8.1
year     2003
month    11
day      21
language R



-- 
Dr Peter Dunn          (USQ CRICOS No. 00244B)
   Web:    http://www.sci.usq.edu.au/staff/dunn
   Email:  dunn @ usq.edu.au
Opinions expressed are mine, not those of USQ.  Obviously...



From ripley at stats.ox.ac.uk  Thu May  6 07:51:54 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 May 2004 06:51:54 +0100 (BST)
Subject: [R] R on Windows Hangs on Packages Built from Sources
In-Reply-To: <200405060255.i462tsfG021903@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0405060646240.7904-100000@gannet.stats>

It must be frustrating, but 

- that setup does work for other people
- I don't think we have ever seen a `hang' of that sort.

I would try one of the packages on CRAN which does have a recent binary 
compiled.  (I tend to use ash to test, as it is small and uses Fortran.)
If that fails then you need a way to debug the `hang' (and you haven't 
told us exactly where it is, so I can't suggest any).

On Wed, 5 May 2004, James Chapman wrote:

> Hi,
> 
> I am currently having the following problem with R 1.9.0. Any package that
> contains C or Fortran code hangs after I have built it and load it into R.
> I've tried this with RMySQL and udunits, originally I thought I had done
> something subtly wrong in configuring these packages; but I just had the
> same problem with a simple example R package that I wrote. I was able to
> build and load the package on a Linux system at school so I figure I've,
> hopefully, ruled out a programming problem on my part.
> 
> The system I'm having the problem on is as follows:
> AMD AthlonXP
> R 1.9.0 installed from binaries
> GCC 3.3.1

Just checking -- gcc 3.3.3 for MinGW as in

[c:/R/rw2000/src/gnuwin32]% gcc --version
gcc (GCC) 3.3.1 (mingw special 20030804-1)

?  Someone sent me several messages recently, and it transpired was trying
to use the cygwin compilers.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu May  6 08:00:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 May 2004 07:00:55 +0100 (BST)
Subject: [R] Printing ps pictures with transparent b'ground
In-Reply-To: <4099C509.8020703@usq.edu.au>
Message-ID: <Pine.LNX.4.44.0405060653560.7904-100000@gannet.stats>

It is the background when the picture is drawn that matters.  We do have 
(and recommend) dev.copy2eps for copying to eps files for inclusion in 
documents, but my first sentence still applies.  You are copying exactly 
what you plotted on screen.

If you want a solid background on your .eps file (unusual, and I think you 
should be doing it in the including application), you need to produce 
the plot to copy exactly as you want copied.  If you are copying from an 
x11() device, set bg="white" on that device (via par(bg="white") before 
plotting).

On Thu, 6 May 2004, Peter Dunn wrote:

> I wish to create a ps file of a picture produced in R.
> With my limited R, I see two ways:
> 1. Print direct to the postscript device
> 2. Print to the screen, and save to ps using dev.print.

Do you mean `plot', not `print' here?

> I want a white (not transparent) background.  Option
> 1 above works fine, but 2 does not:  even when I say I
> want a white background, I get transparent; perhaps I
> misread the help files.
> 
> Here's some R code:
> 
> ### Method 1
> ### - print straight to postscript device
> postscript(horizontal=FALSE,
> 	onefile=FALSE,
> 	bg="white",
> 	width=4,
> 	height=4,
> 	paper="special",
>     file="testfile.eps" )
> curve( dnorm, from=-3, to=3)
> 
> dev.off()
> 
> ### Method 2
> ### - print to screen, and save using  postscript
> 
> x11(width=4, height=4)
> curve( dnorm, from=-3, to=3)
> 
> dev.print( postscript,
>     horizontal=FALSE,
> 	onefile=FALSE,
> 	bg="white",
> 	width=4,
> 	height=4,
> 	paper="special",
>     file="testfile2.eps" )
> 
> 
> I then want to place these files in a LaTeX prosper document
> for a presentation.  A typical (minimal) prosper file is:
> 
> \documentclass[pdf,colorBG,slideColor,whitecross]{prosper}
> 
> \begin{document}
> 
> \begin{slide}{Print to \textsc{ps} direct}
> \includegraphics{testfile.eps}
> \end{slide}
> 
> \begin{slide}{Print to screen first}
> \includegraphics{testfile2.eps}
> \end{slide}
> 
> \end{document}
> 
> 
> The  whitecross  class provides a blue background for the
> presentation.  testfile.eps  appears with a white background
> on the slides, but  testfile2.eps  has a transparent
> background.
> 
> I'd apprecaite if someone could explain why the two are not equivalent,
> or how I can coerce the second option to have a white background?  Or
> even explain my misunderstandings (assuming (with high probability)
> that I have some).
> 
> Thanks.
> 
> P.
> 
>  > version
>           _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    8.1
> year     2003
> month    11
> day      21
> language R
> 
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From prechelt at pcpool.mi.fu-berlin.de  Thu May  6 08:47:21 2004
From: prechelt at pcpool.mi.fu-berlin.de (Lutz Prechelt)
Date: Thu, 6 May 2004 08:47:21 +0200
Subject: [R] need help!
Message-ID: <85D25331FFB7AE4C900EA467D4ADA39204592C@circle.pcpool.mi.fu-berlin.de>


There is a fairly good integration between Excel (if that is
what you are using, you did not tell us) and R.
You can find that on www.r-project.org.

Or you can just use Excel to edit your data, save it as
CSV, and then import in R with read.table.

Please use a more descriptive subject next time.

  Lutz Prechelt

> found that there are no a good way to edit the data , it is 
> not friendly to 
> deal with data like excel when i use command "edit()" or 
> "fix()". i even 
> canot copy one column data. it just let me copy one cell 
> data. so i think 
> probably there are some other command can solve this trouble 
> better. it 
> will be very help if yuo can tell me.
> 
> thanks
> 
> kj.
> 
> _________________________________________________________________
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From henric.nilsson at statisticon.se  Thu May  6 09:13:44 2004
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Thu, 06 May 2004 09:13:44 +0200
Subject: [R] GLMM with random slope
In-Reply-To: <Pine.LNX.4.44.0405051619300.2436-100000@muskrat.stat.umn.e
 du>
References: <Pine.LNX.4.44.0405041817210.24775-100000@gannet.stats>
	<Pine.LNX.4.44.0405051619300.2436-100000@muskrat.stat.umn.edu>
Message-ID: <6.0.3.0.0.20040506090622.04f23ee8@10.0.10.66>

Liliana,

At 23:20 2004-05-05, Liliana Forzani wrote:

>I was using GLMM to fit a model (binomial)
>with random slope.
>When I put random~1|ID  I got the results (random intercept)

I assume that you used random = ~ 1 | ID.
                                               ^^^

>when I put random~time|ID  I got an error

This is not very helpful, unless you really forgot the `=' sign. Please 
provide the output!

//Henric



From Laetitia.Marisa at cgm.cnrs-gif.fr  Thu May  6 10:05:34 2004
From: Laetitia.Marisa at cgm.cnrs-gif.fr (Laetitia Marisa)
Date: Thu, 06 May 2004 10:05:34 +0200
Subject: [R] choose.files function under unix
Message-ID: <4099F1CE.40404@cgm.cnrs-gif.fr>

Hello,

I can't find the choose.files function under my unix system that is by 
default under windows. Does this function exist for unix?
Thanks.

Laetitia



From ripley at stats.ox.ac.uk  Thu May  6 10:10:23 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 May 2004 09:10:23 +0100 (BST)
Subject: [R] choose.files function under unix
In-Reply-To: <4099F1CE.40404@cgm.cnrs-gif.fr>
Message-ID: <Pine.LNX.4.44.0405060909350.11334-100000@gannet.stats>

On Thu, 6 May 2004, Laetitia Marisa wrote:

> I can't find the choose.files function under my unix system that is by 
> default under windows. Does this function exist for unix?

No, but file.choose() does.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Thu May  6 10:18:39 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 06 May 2004 10:18:39 +0200
Subject: [R] syntax error in function 'for'
In-Reply-To: <20040505155316.TSFR11783.tomts22-srv.bellnexxia.net@JohnDesktop8300>
References: <1083769583.20658.9.camel@snowdon.science.uva.nl>
Message-ID: <409A10FF.27282.8DE198@localhost>

Hi

On 5 May 2004 at 11:53, John Fox wrote:

> Dear Ulrich,
> 
> I believe that you want ifelse(), not if(), but there are likely some
> other problems lurking here: You're removing missing data
> independently from the several vectors -- unless the NAs are all in
> the same places, things will not work or not work correctly. As well,
> what do you want to happen if the condition fails?

maybe complete.cases() is more appropriate but it also depends on what is A,B,C 
D and what is your real intention.

e.g.
> A<-1:10
> B<-11:20
> C<-101:110
> D<-runif(10)*10
> D
 [1] 3.834122 7.422188 2.741723 2.065324 2.775822 6.991390 1.899406 
7.741244 7.026734 3.417432
> A[5]<-NA
> C[8]<-NA
> D[2]<-NA
> fff<-function(a,b,c) a-b+sqrt(c)
> na.omit(subset(fff(A,B,C), sqrt(D)>2))
[1] 0.2956301 0.4403065
attr(,"na.action")
[1] 2
attr(,"class")
[1] "omit"


Cheers
Petr

> 
> John 
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ulrich
> > Leopold Sent: Wednesday, May 05, 2004 10:06 AM To: R-help Subject:
> > [R] syntax error in function 'for'
> > 
> > Dear list,
> > 
> > I get a syntax error for the following function:
> > 
> > for(na.omit(sqrt(D))>2) {na.omit(A)-(na.omit(B)+(na.omit(sqrt(C))))}
> > 
> > Any idea what is wrong?
> > 
> > I am using R 1.8.1 on Linux, Kernel 2.4.21-i686.
> > 
> > Regards, Ulrich
> > 
> > --
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From myint.tin-tin-htar at jvr.ap-hop-paris.fr  Thu May  6 10:17:31 2004
From: myint.tin-tin-htar at jvr.ap-hop-paris.fr (myint.tin-tin-htar@jvr.ap-hop-paris.fr)
Date: Thu, 06 May 2004 10:17:31 +0200
Subject: [R] receiver operating characteristic (ROC)
Message-ID: <4099F49B.5AA4063@jvr.ap-hop-paris.fr>

Dear R users,

I would like to get some simple syntaxes for ROC curves for the
research  of thresholds and cluster analysis for preliminary regrouping
of variables for a simple scoring system.

Thanks.
Tin Tin



From petr.pikal at precheza.cz  Thu May  6 10:27:48 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 06 May 2004 10:27:48 +0200
Subject: [R] need help!
In-Reply-To: <BAY14-F29zJUePldjMq00007e31@hotmail.com>
Message-ID: <409A1324.21063.964339@localhost>

Hi

On 5 May 2004 at 21:48, liao kaijun wrote:

> Dear:
> I just try to use the R to solve some statistic problem recently. but
> i found that there are no a good way to edit the data , it is not
> friendly to deal with data like excel when i use command "edit()" or
> "fix()". i even canot copy one column data. it just let me copy one

R is friendly if you accept its power with data management.

cbind, rbind, [], subset,.....

If you like to work like in Excel why not use Excel for preparing data and 
transfering them to R by read.table() functions.

!!! Thanks to all authors for "clipboard" extension!!! :-)

Cheers
Petr

> cell data. so i think probably there are some other command can solve
> this trouble better. it will be very help if yuo can tell me.
> 
> thanks
> 
> kj.
> 
> _________________________________________________________________

> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From uleopold at science.uva.nl  Thu May  6 11:25:02 2004
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: 06 May 2004 11:25:02 +0200
Subject: [R] X11 fonts cannot be loaded - SuSE Linux solution
Message-ID: <1083835502.5212.12.camel@snowdon.science.uva.nl>

Dear list,

I would like to make a comment how to solve the X11 font problem under
SuSE Linux (9.0) when you get the message:
"X11 font at size 16 could not be loaded".

After having modified /etc/X11/XF86config as root (see below) you have
to run 'SuSEconfig' as root as well else nothing might be changed in the
X-Server.

After that no further messages should appear.

HTH, Ulrich Leopold

> Marc Schwartz wrote:

> It sounds like you might not have scaled versions of your fonts loaded
> in /etc/X11/fs/config 
> 
> 
> Take a look in there for the following lines, depending upon whether 
> you have 75 or 100 dpi fonts loaded: 
> 
> 
> /usr/X11R6/lib/X11/fonts/75dpi:unscaled 
> /usr/X11R6/lib/X11/fonts/100dpi:unscaled 
> 
> 
> See if there are also the following lines: 
> 
> 
> /usr/X11R6/lib/X11/fonts/75dpi 
> /usr/X11R6/lib/X11/fonts/100dpi 
> 
> 
> If one of the second set of lines are not present to correspond with 
> one of the first two lines, it is likely that scaled versions of your 
> fonts are not being loaded by the font server. 
> 
> 
> You will need to add the appropriate line to /etc/X11/fs/config as 
> root when not running X and then restart X. 
> 
> 
> In RH (which I use), the console commands would be: 
> 
> 
> /usr/sbin/chkfontpath -q -r /usr/X11R6/lib/X11/fonts/75dpi 
> /usr/sbin/chkfontpath -q -a /usr/X11R6/lib/X11/fonts/75dpi 
> 
> 
> or 
> 
> 
> /usr/sbin/chkfontpath -q -r /usr/X11R6/lib/X11/fonts/100dpi 
> /usr/sbin/chkfontpath -q -a /usr/X11R6/lib/X11/fonts/100dpi 
> 
> 
> I don't want to assume that SUSE has the same commands and/or paths, 
> but perhaps. If not, you may just be able to edit /etc/X11/fs/config 
> directly, making sure that you verify the paths on your installation 
> as well. 
> 
> 
> Then restart X. 
> 
> 
> Perhaps another SUSE user here can verify the proper resolution. 
> 
> 
> Hope that helps. 
> 
> 
> Marc Schwartz


-- 
__________________________________________________

Ulrich Leopold MSc.

Computational Bio- and Physical Geography (CBPG)
Institute for Biodiversity and Ecosystem Dynamics (IBED)
Faculty of Science
University of Amsterdam
Nieuwe Achtergracht 166
NL-1018WV Amsterdam

Room:   B2.52
Phone:	+31 20 525 7456 (7451 Secretary)
Fax:	+31 20 525 7431
Mobile:	+31 64 220 3028
Email:	uleopold at science.uva.nl
URL:    www.science.uva.nl/ibed/cbpg



From laura at env.leeds.ac.uk  Thu May  6 11:41:12 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Thu, 6 May 2004 10:41:12 +0100 (BST)
Subject: [R] Problem with filled.contour/image
Message-ID: <Pine.LNX.4.44.0405061032350.4967-100000@env-pc-phd13>

Quick question - I am having problems creating an orographic image
(similar to volcano example). I have created a map matrix with 3 columns
and over 2million rows.

I have created the matrix as follows:
map<-read.table("map.dat",header=TRUE)
long.grid<-sort(unique(map$long)
lat.grid<-sort(unique(map$lat)
map.matrix<-matrix(map$height,nrow=length(lat.grid),byrow=TRUE)

The problem is when I type the filled.contour
command I get the following error message:

filled.contour(long.grid,lat.grid,t(map.matrix),color=terrain.colors)

Error in filledcontour(as.double(x), as.double(y), z, as.double(levels),
:
        dimension mismatch

and when I try using the image function:

image(long.grid,lat.grid,t(map.matrix),col=terrain.colors(50),axes=TRUE)

I get the following error:

Error in image.default(long.grid, lat.grid, t(map.matrix), col =
terrain.colors(50),  :
        dimensions of z are not length(x)(+1) times length(y)(+1)

Each long and lat point are unique and have a corresponding height
component so these messages don't make any sense to me - can anyone please
advise?

Thanks

Laura



From petr.pikal at precheza.cz  Thu May  6 12:18:18 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 06 May 2004 12:18:18 +0200
Subject: [R] Problem with filled.contour/image
In-Reply-To: <Pine.LNX.4.44.0405061032350.4967-100000@env-pc-phd13>
Message-ID: <409A2D0A.20356.FBAAC2@localhost>

Hi

Hi

x,y are supposed to be vectors with lengths n and m and the matrix is supposed to 
have dimensions n,m

> ?image
> data(volcano)
>      x <- 10*(1:nrow(volcano))
>      y <- 10*(1:ncol(volcano))
>      image(x, y, volcano, col = terrain.colors(100), axes = FALSE)
> length(x)
[1] 87
> length(y)
[1] 61
> dim(volcano)
[1] 87 61

did you get similar figures for your data?

Cheers
Petr



On 6 May 2004 at 10:41, Laura Quinn wrote:

> Quick question - I am having problems creating an orographic image
> (similar to volcano example). I have created a map matrix with 3
> columns and over 2million rows.
> 
> I have created the matrix as follows:
> map<-read.table("map.dat",header=TRUE)
> long.grid<-sort(unique(map$long)
> lat.grid<-sort(unique(map$lat)
> map.matrix<-matrix(map$height,nrow=length(lat.grid),byrow=TRUE)
> 
> The problem is when I type the filled.contour
> command I get the following error message:
> 
> filled.contour(long.grid,lat.grid,t(map.matrix),color=terrain.colors)
> 
> Error in filledcontour(as.double(x), as.double(y), z,
> as.double(levels), :
>         dimension mismatch
> 
> and when I try using the image function:
> 
> image(long.grid,lat.grid,t(map.matrix),col=terrain.colors(50),axes=TRU
> E)
> 
> I get the following error:
> 
> Error in image.default(long.grid, lat.grid, t(map.matrix), col =
> terrain.colors(50),  :
>         dimensions of z are not length(x)(+1) times length(y)(+1)
> 
> Each long and lat point are unique and have a corresponding height
> component so these messages don't make any sense to me - can anyone
> please advise?
> 
> Thanks
> 
> Laura
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From janeteborges at gmx.net  Thu May  6 12:29:57 2004
From: janeteborges at gmx.net (Janete Borges)
Date: Thu, 6 May 2004 12:29:57 +0200 (MEST)
Subject: [R] help on ks.test
References: <17928.1083668164@www18.gmx.net>
Message-ID: <26309.1083839397@www26.gmx.net>

Dear All

I need to test the goodness-of-fit of a (Negative) Exponential Distribution
to a dataset. The parameter of the distribution is unknown. What is the
appropriate test to do? I've tried the ks.test, although I think this
isn't the appropriate one, as I don't know the population parameter. 
Can anybody help me?
 
Thanks in advance,
Janete
 

--



From wolski at molgen.mpg.de  Thu May  6 12:48:09 2004
From: wolski at molgen.mpg.de (witek)
Date: Thu, 06 May 2004 12:48:09 +0200
Subject: [R] plot(hist.default(1:10,plot=F)) error.
Message-ID: <200405061248090007.05D6F394@mail.math.fu-berlin.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040506/f36aacee/attachment.pl

From dmurdoch at pair.com  Thu May  6 12:48:32 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 06 May 2004 06:48:32 -0400
Subject: [R] R on Windows Hangs on Packages Built from Sources
In-Reply-To: <200405060255.i462tsfG021903@hypatia.math.ethz.ch>
References: <200405060255.i462tsfG021903@hypatia.math.ethz.ch>
Message-ID: <6s5k905g1q365fe873e86vp6sr8qsi8all@4ax.com>

On Wed, 5 May 2004 21:55:46 -0500, "James Chapman"
<james-chapman at uiowa.edu> wrote:

>Hi,
>
>I am currently having the following problem with R 1.9.0. Any package that
>contains C or Fortran code hangs after I have built it and load it into R.

...

>The system I'm having the problem on is as follows:
>AMD AthlonXP
>R 1.9.0 installed from binaries
>GCC 3.3.1

Is that the MinGW GCC?  The Cygwin build hasn't been tested recently
with R, but in the past it wouldn't work.

Duncan Murdoch



From wildscop at yahoo.com  Thu May  6 13:09:13 2004
From: wildscop at yahoo.com (WilD KID)
Date: Thu, 6 May 2004 04:09:13 -0700 (PDT)
Subject: [R] Orthogonal Polynomial Regression Parameter Estimation
Message-ID: <20040506110913.33479.qmail@web11413.mail.yahoo.com>

Dear all,

Can any one tell me how can i perform Orthogonal
Polynomial Regression parameter estimation in R?

--------------------------------------------

Here is an "Orthogonal Polynomial" Regression problem
collected from Draper, Smith(1981), page 269. Note
that only value of alpha0 (intercept term) and signs
of each estimate match with the result obtained from
coef(orth.fit). What went wrong?

--------------------------------------------

Data:

> Z<-1957:1964
> Y<-c(0.93,0.99,1.11,1.33,1.52,1.60,1.47,1.33)
> X<-Z-1956
> X
[1] 1 2 3 4 5 6 7 8

--------------------------------------------

Using lm function to get orthogonal polynomial, we
get-

> orth.fit<-lm(Y~poly(X,degree =6))
> coef(orth.fit)

(Intercept)            poly(X, degree = 6)1   poly(X,
degree = 6)2 
1.285000000                     0.529260490          
-0.316321867 

poly(X, degree = 6)3   poly(X, degree = 6)4   poly(X,
degree = 6)5 
        -0.221564684            0.054795962           
0.062910192 

poly(X, degree = 6)6 
         0.006154575 

--------------------------------------------

And using the solution procedure given in Draper,
Smith(1981) is -

--------------------------------------------

The following values are coefficients of 0-6th order
(for n=8) polynomial collected from Pearson, Hartley
(1958) table, page 212:

> p0<-rep(1,8)
> p1<-c(-7,-5,-3,-1,1,3,5,7)
> p2<-c(7,1,-3,-5,-5,-3,1,7)
> p3<-c(-7,5,7,3,-3,-7,-5,7)
> p4<-c(7,-13,-3,9,9,-3,-13,7)
> p5<-c(-7,23,-17,-15,15,17,-23,7)
> p6<-c(1,-5,9,-5,-5,9,-5,1)

Now, the estimated parameters of the orthogonal
polynomial is calculated by the following formula:

> alpha0<-sum(Y*p0)/sum(p0^2);
alpha1<-sum(Y*p1)/sum(p1^2);
alpha2<-sum(Y*p2)/sum(p2^2);
alpha3<-sum(Y*p3)/sum(p3^2);
alpha4<-sum(Y*p4)/sum(p4^2);
alpha5<-sum(Y*p5)/sum(p5^2);
alpha6<-sum(Y*p6)/sum(p6^2)
> alpha0;alpha1;alpha2;alpha3;alpha4;alpha5;alpha6
[1] 1.285
[1] 0.04083333
[1] -0.02440476
[1] -0.01363636
[1] 0.002207792
[1] 0.001346154
[1] 0.0003787879

--------------------------------------------

Any response / help / comment / suggestion / idea /
web-link / replies will be greatly appreciated. 

Thanks in advance for your time.

_______________________

Mohammad Ehsanul Karim <wildscop at yahoo.com> 
Institute of Statistical Research and Training 
University of Dhaka, Dhaka- 1000, Bangladesh



From p.dalgaard at biostat.ku.dk  Thu May  6 13:35:08 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 May 2004 13:35:08 +0200
Subject: [R] X11 fonts cannot be loaded - SuSE Linux solution
In-Reply-To: <1083835502.5212.12.camel@snowdon.science.uva.nl>
References: <1083835502.5212.12.camel@snowdon.science.uva.nl>
Message-ID: <x2r7txkcur.fsf@biostat.ku.dk>

Ulrich Leopold <uleopold at science.uva.nl> writes:

> Dear list,
> 
> I would like to make a comment how to solve the X11 font problem under
> SuSE Linux (9.0) when you get the message:
> "X11 font at size 16 could not be loaded".
> 
> After having modified /etc/X11/XF86config as root (see below) you have
> to run 'SuSEconfig' as root as well else nothing might be changed in the
> X-Server.
> 
> After that no further messages should appear.

Actually, there is another fix (er, workaround for a long-standing bug
in R, perpetrated by yours truly...), namely to ensure that *both*
75dpi and 100dpi fontsets are installed. As in

> rpm -qa | grep dpi
XFree86-fonts-75dpi-4.3.0.1-33
XFree86-fonts-100dpi-4.3.0.1-33

The unscaled adobe fonts are much better designed than anything an
automatic scaler can come up with, so SuSE has a point in excluding
the latter. Adding the scaled fonts to the fontserver config may give
aesthetic unpleasantness in other places.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Thu May  6 13:42:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 May 2004 12:42:38 +0100 (BST)
Subject: [R] Orthogonal Polynomial Regression Parameter Estimation
In-Reply-To: <20040506110913.33479.qmail@web11413.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0405061235470.15757-100000@gannet.stats>

You have sent this to both the S and R lists under different names:  who
are you and which system are you interested in?

You use poly(), as you did, but the internals of poly() are not the same 
on the two systems.  Do read the documentation to find out which 
orthogonal polynomials are used.

Hint: The S-PLUS description says

   Returns a matrix of orthonormal polynomials, which represents a basis
   for polynomial regression.

Notice the difference?  Orthogonal polynomials are not uniquely defined
(nor are orthonormal ones, BTW).


On Thu, 6 May 2004, WilD KID wrote:

> Dear all,
> 
> Can any one tell me how can i perform Orthogonal
> Polynomial Regression parameter estimation in R?
> 
> --------------------------------------------
> 
> Here is an "Orthogonal Polynomial" Regression problem
> collected from Draper, Smith(1981), page 269. Note
> that only value of alpha0 (intercept term) and signs
> of each estimate match with the result obtained from
> coef(orth.fit). What went wrong?
> 
> --------------------------------------------
> 
> Data:
> 
> > Z<-1957:1964
> > Y<-c(0.93,0.99,1.11,1.33,1.52,1.60,1.47,1.33)
> > X<-Z-1956
> > X
> [1] 1 2 3 4 5 6 7 8
> 
> --------------------------------------------
> 
> Using lm function to get orthogonal polynomial, we
> get-
> 
> > orth.fit<-lm(Y~poly(X,degree =6))
> > coef(orth.fit)
> 
> (Intercept)            poly(X, degree = 6)1   poly(X,
> degree = 6)2 
> 1.285000000                     0.529260490          
> -0.316321867 
> 
> poly(X, degree = 6)3   poly(X, degree = 6)4   poly(X,
> degree = 6)5 
>         -0.221564684            0.054795962           
> 0.062910192 
> 
> poly(X, degree = 6)6 
>          0.006154575 
> 
> --------------------------------------------
> 
> And using the solution procedure given in Draper,
> Smith(1981) is -
> 
> --------------------------------------------
> 
> The following values are coefficients of 0-6th order
> (for n=8) polynomial collected from Pearson, Hartley
> (1958) table, page 212:
> 
> > p0<-rep(1,8)
> > p1<-c(-7,-5,-3,-1,1,3,5,7)
> > p2<-c(7,1,-3,-5,-5,-3,1,7)
> > p3<-c(-7,5,7,3,-3,-7,-5,7)
> > p4<-c(7,-13,-3,9,9,-3,-13,7)
> > p5<-c(-7,23,-17,-15,15,17,-23,7)
> > p6<-c(1,-5,9,-5,-5,9,-5,1)
> 
> Now, the estimated parameters of the orthogonal
> polynomial is calculated by the following formula:
> 
> > alpha0<-sum(Y*p0)/sum(p0^2);
> alpha1<-sum(Y*p1)/sum(p1^2);
> alpha2<-sum(Y*p2)/sum(p2^2);
> alpha3<-sum(Y*p3)/sum(p3^2);
> alpha4<-sum(Y*p4)/sum(p4^2);
> alpha5<-sum(Y*p5)/sum(p5^2);
> alpha6<-sum(Y*p6)/sum(p6^2)
> > alpha0;alpha1;alpha2;alpha3;alpha4;alpha5;alpha6
> [1] 1.285
> [1] 0.04083333
> [1] -0.02440476
> [1] -0.01363636
> [1] 0.002207792
> [1] 0.001346154
> [1] 0.0003787879
> 
> --------------------------------------------
> 
> Any response / help / comment / suggestion / idea /
> web-link / replies will be greatly appreciated. 
> 
> Thanks in advance for your time.
> 
> _______________________
> 
> Mohammad Ehsanul Karim <wildscop at yahoo.com> 
> Institute of Statistical Research and Training 
> University of Dhaka, Dhaka- 1000, Bangladesh
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu May  6 13:46:21 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 May 2004 12:46:21 +0100 (BST)
Subject: [R] weirdness in sourc()ing a dump()  (bug?)
In-Reply-To: <x265ba61jp.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0405061206030.15757-100000@gannet.stats>

There is already a bug report PR#4364 on an aspect of this.  The comment 
there is

  dump somehow needs to recognize that expressions in lists 
  probably need to be enclosed in quote().

  S does exactly the same though

(I think it is a symbol not a formal expression in the current examples.)

I believe it is rather difficult to determine what we cannot deparse
successfully, and trying to issue a warning/error would give a false sense
of security.  The code (src/main/deparse.c) suggests that at least

promises
environments
external pointers
weak references

will not get a useful textual representation.  I don't think the goal can
be as Peter describes -- it has to be more limited, and currently symbols
are also on the list.  (We might be able to solve symbols, but it is far
from straightforward -- terms in formulae are symbols, for example, so we
cannot just add quote() around symbols and that does indeed break code.)

There may well be others: it was not so long ago that integer vectors were 
dumped in a text representation that was read back in as numeric.


On 5 May 2004, Peter Dalgaard wrote:

> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> 
> > On Wed, 5 May 2004, Duncan Murdoch wrote:
> > 
> > > On Wed, 5 May 2004 20:20:51 +0100 (BST), Prof Brian Ripley
> > > <ripley at stats.ox.ac.uk> wrote :
> > > 
> > > >I don't think it is a bug.  Note that dump does not even claim to dump
> > > >lists let alone symbols, but ?dump says
> > > >
> > > >     At present the implementation of 'dump' is very incomplete and it
> > > >     really only works for functions and simple vectors.
> > > >
> > > >Given that, this is not unexpected. (Looks like more than one person did 
> > > >not check the help page ....)
> > > >
> > > >I think save/load is a much safer way to handle saving R objects, and it 
> > > >does work in PD's example.
> > > 
> > > I'd still call it a bug, since 'dump("x"); source("dumpdata.R")' could
> > > change the meaning of x without any warning, and that can't be
> > > desirable behaviour.  
> > 
> > That's not what it says it does, and not what the S version achieves 
> > either.  (Do see the documentation on `what is a bug' in the FAQ, which 
> > does not agree with you.)
> 
> Weelll.. The goal of dump/dput is to create a construct that can be
> evaluated so as to yield the original object. This is one place where
> we fail to meet that goal, so I'll call it a bug, documented or not.
> Especially, since it is something we might actually be able to fix
> fairly simply (note "might" -- we've had our share of "fixes" that
> didn't in the deparsing area).
> 
> > I was trying to be constructive: save/load *is* supposed to reproduce
> > objects, and it just not realistic to get dump/source to do that.  And we
> > do warn about it in the documentation and I can see nowhere that
> > recommends dump/save as a way of saving objects ....  (If there is such a 
> > place, then that is a bug and needs fixing.)
> 
> I don't disagree that save/load is a better strategy for data storage,
> but dump and friends do have the potential to create an *editable*
> text representation, so there is some point in trying to make them
> work predictably as far as possible.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Thu May  6 14:12:28 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 06 May 2004 07:12:28 -0500
Subject: [R] Orthogonal Polynomial Regression Parameter Estimation
In-Reply-To: <20040506110913.33479.qmail@web11413.mail.yahoo.com>
References: <20040506110913.33479.qmail@web11413.mail.yahoo.com>
Message-ID: <6rad0lycsz.fsf@bates4.stat.wisc.edu>

WilD KID <wildscop at yahoo.com> writes:

> Dear all,
> 
> Can any one tell me how can i perform Orthogonal
> Polynomial Regression parameter estimation in R?
> 
> --------------------------------------------
> 
> Here is an "Orthogonal Polynomial" Regression problem
> collected from Draper, Smith(1981), page 269. Note
> that only value of alpha0 (intercept term) and signs
> of each estimate match with the result obtained from
> coef(orth.fit). What went wrong?

Draper and Smith (1981) are using unnormalized orthogonal polynomials
whereas the R function poly(X, degree = 6) produces normalized
columns.  That is, up to rounding error, the crossproduct of the
columns of the matrix produced by poly(X, degree = 6) is the identity.

The columns given in Draper and Smith are a set of orthogonal columns
but there are an infinite number of such sets and they each produce
different estimates of the coefficients.  The normalized orthogonal
polynomial columns are unique up to sign changes so the magnitudes of
the coefficients are well defined.

Generally the predictions from a linear model are well defined but the
coefficients are not necessarily well defined.  A better test would be
to see if the predictions from the poly model and the Draper and Smith
model were similar.  It would be best to check using all.equal to
allow for minor differences caused by numerical imprecision.

> Z<-1957:1964
> X<-Z-1956
> poly(X, degree = 6)
               1           2          3          4          5           6
[1,] -0.54006172  0.54006172 -0.4308202  0.2820380 -0.1497862  0.06154575
[2,] -0.38575837  0.07715167  0.3077287 -0.5237849  0.4921546 -0.30772873
[3,] -0.23145502 -0.23145502  0.4308202 -0.1208734 -0.3637664  0.55391171
[4,] -0.07715167 -0.38575837  0.1846372  0.3626203 -0.3209704 -0.30772873
[5,]  0.07715167 -0.38575837 -0.1846372  0.3626203  0.3209704 -0.30772873
[6,]  0.23145502 -0.23145502 -0.4308202 -0.1208734  0.3637664  0.55391171
[7,]  0.38575837  0.07715167 -0.3077287 -0.5237849 -0.4921546 -0.30772873
[8,]  0.54006172  0.54006172  0.4308202  0.2820380  0.1497862  0.06154575
attr(,"degree")
[1] 1 2 3 4 5 6
attr(,"coefs")
attr(,"coefs")$alpha
[1] 4.5 4.5 4.5 4.5 4.5 4.5

attr(,"coefs")$norm2
[1]    1.000    8.000   42.000  168.000  594.000 1810.286 4457.143 7854.545

attr(,"class")
[1] "poly"   "matrix"
> zapsmall(crossprod(poly(X, degree = 6)))
  1 2 3 4 5 6
1 1 0 0 0 0 0
2 0 1 0 0 0 0
3 0 0 1 0 0 0
4 0 0 0 1 0 0
5 0 0 0 0 1 0
6 0 0 0 0 0 1
> 
> And using the solution procedure given in Draper,
> Smith(1981) is -
> 
> --------------------------------------------
> 
> The following values are coefficients of 0-6th order
> (for n=8) polynomial collected from Pearson, Hartley
> (1958) table, page 212:
> 
> > p0<-rep(1,8)
> > p1<-c(-7,-5,-3,-1,1,3,5,7)
> > p2<-c(7,1,-3,-5,-5,-3,1,7)
> > p3<-c(-7,5,7,3,-3,-7,-5,7)
> > p4<-c(7,-13,-3,9,9,-3,-13,7)
> > p5<-c(-7,23,-17,-15,15,17,-23,7)
> > p6<-c(1,-5,9,-5,-5,9,-5,1)
> 
> Now, the estimated parameters of the orthogonal
> polynomial is calculated by the following formula:
> 
> > alpha0<-sum(Y*p0)/sum(p0^2);
> alpha1<-sum(Y*p1)/sum(p1^2);
> alpha2<-sum(Y*p2)/sum(p2^2);
> alpha3<-sum(Y*p3)/sum(p3^2);
> alpha4<-sum(Y*p4)/sum(p4^2);
> alpha5<-sum(Y*p5)/sum(p5^2);
> alpha6<-sum(Y*p6)/sum(p6^2)
> > alpha0;alpha1;alpha2;alpha3;alpha4;alpha5;alpha6
> [1] 1.285
> [1] 0.04083333
> [1] -0.02440476
> [1] -0.01363636
> [1] 0.002207792
> [1] 0.001346154
> [1] 0.0003787879
> 
> --------------------------------------------
> 
> Any response / help / comment / suggestion / idea /
> web-link / replies will be greatly appreciated.



From christian.lederer at imse.med.tu-muenchen.de  Thu May  6 16:04:11 2004
From: christian.lederer at imse.med.tu-muenchen.de (Christian Lederer)
Date: Thu, 06 May 2004 16:04:11 +0200
Subject: [R] cgi/servlets/httpd  in R
In-Reply-To: <BB12D17A-9EB8-11D8-8BA1-0050E4C03977@warwick.ac.uk>
References: <BB12D17A-9EB8-11D8-8BA1-0050E4C03977@warwick.ac.uk>
Message-ID: <409A45DB.6050601@imse.med.tu-muenchen.de>


Hi,

if found that the easiest way for me doing CGI with R was
using the RSPerl package. So i could do all the CGI related things
in Perl and call R functions from Perl to do the statistics.
You can get RSPerl from http://www.omegahat.org.

If loading the data each time gives a performance problem,
i guess that you could use RSPerl together with fastcgi,
so the R initialization and loading the data would happen only
once. If you try this, i would be very interrested in your experiences.

The RSPerl package is somewhat outdated, but it worked well together
with R 1.6.0 (i didn't try newer versions).

Christian :-)



David Firth wrote:
> On Wednesday, May 5, 2004, at 18:09 Europe/London, foobar wrote:
> 
>> Hi R-helpers
>>
>> Has anyone had any experience doing CGI or Servlets or using an httpd 
>> server in R?
>>
>>
> 
> yes.  See the R FAQ, section 4.  (Or maybe you already have, in which 
> case I misunderstood the question...)
> 
> Best wishes,
> David
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From FWS4 at CDRH.FDA.GOV  Thu May  6 14:55:23 2004
From: FWS4 at CDRH.FDA.GOV (Samuelson, Frank*)
Date: Thu, 6 May 2004 08:55:23 -0400
Subject: [R] receiver operating characteristic (ROC)
Message-ID: <644D9337A02FC24689647BF9E48EC39E08ABB7E5@drm556>

www.bioconductor.org has an ROC package.  It stores the specificity and
sensitivity as an ROC object and can calculate partial areas.

-----Original Message-----
From: myint.tin-tin-htar at jvr.ap-hop-paris.fr
[mailto:myint.tin-tin-htar at jvr.ap-hop-paris.fr] 
Sent: Thursday, May 06, 2004 4:18 AM
To: R-help at stat.math.ethz.ch
Subject: [R] receiver operating characteristic (ROC)


Dear R users,

I would like to get some simple syntaxes for ROC curves for the
research  of thresholds and cluster analysis for preliminary regrouping
of variables for a simple scoring system.

Thanks.
Tin Tin

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From wildscop at yahoo.com  Thu May  6 15:14:41 2004
From: wildscop at yahoo.com (WilD KID)
Date: Thu, 6 May 2004 06:14:41 -0700 (PDT)
Subject: [R] Orthogonal Polynomial Regression Parameter Estimation
Message-ID: <20040506131441.39179.qmail@web11405.mail.yahoo.com>

Dear Prof Brian Ripley,

	First of all, thanks for your kind reply. 
	Actually, my subscribed e-mail account in both the
lists are different (due to space considerations) -
that is why e-mail ID's were different, not the name -
"Mohammad Ehsanul Karim". Also, i am interested in any
system that solves my problem (i use R 1.7.1 and
S-plus 4.0 version).

	Anyway, can you give me any suggestions how should i
solve my problem (in any given system)? Yes - it is
possible to solve my problem on a step-by-step basis -
but i thought that some functions might be available
to solve this Orthogonal Polynomial Regression problem
directly. If lm(Y~poly(X,degree = 6)) does not work -
then is there any other way - or i am using it in an
improper way?

	Thank you for your time and effort.

_______________________

Mohammad Ehsanul Karim <wildscop at yahoo.com>
Institute of Statistical Research and Training
University of Dhaka, Dhaka- 1000, Bangladesh



From wildscop at yahoo.com  Thu May  6 15:51:59 2004
From: wildscop at yahoo.com (WilD KID)
Date: Thu, 6 May 2004 06:51:59 -0700 (PDT)
Subject: [R] Orthogonal Polynomial Regression Parameter Estimation
Message-ID: <20040506135159.84219.qmail@web11409.mail.yahoo.com>

Dear Douglas Bates,

Thank you very much for your kind reply. 

_________________________

Mohammad Ehsanul Karim <wildscop at yahoo.com>
Institute of Statistical Research and Training
University of Dhaka, Dhaka- 1000, Bangladesh
_________________________


> Draper and Smith (1981) are using unnormalized
orthogonal 
> polynomials whereas the R function poly(X, degree =
6) 
> produces normalized columns.



From ivan.borozan at utoronto.ca  Thu May  6 15:54:07 2004
From: ivan.borozan at utoronto.ca (ivan.borozan@utoronto.ca)
Date: Thu,  6 May 2004 09:54:07 -0400
Subject: [R] question about plot.dendrogram
Message-ID: <1083851647.409a437f41f30@webmail.utoronto.ca>

hi all,

i'm trying to plot a dendrogram with labeled leaves


>rownames(f)<-v.names
>v<-rowMeans(f, na.rm=T)
>clust<-hclust(dist(v))
>dend<-as.dendrogram(clust,hang=0.05)
>clust2<-cut(dend, h=0.5)
>class(clust2$low[[1]])
>[1] "dendrogram"

then 

>plot(clust2$low[[1]],horiz=TRUE,frame=F,type = "tr"))

but my leaf labels do not fit entirely in the plot region. Has anyone an idea
how to get around this without using cex , something similar to "hang=0.5" so
that my labels do not start to hang from 0 ?

cheers

_______________________________________________
Bioconductor mailing list
Bioconductor at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/bioconductor

----- End forwarded message -----



From mikewhite.diu at tiscali.co.uk  Thu May  6 16:03:25 2004
From: mikewhite.diu at tiscali.co.uk (Mike White)
Date: Thu, 6 May 2004 15:03:25 +0100
Subject: [R] Problem with mclust surfacePlot function
Message-ID: <004601c43372$e66d2f20$835de150@FSSFQCV7BGDVED>

I am trying to follow the mclust examples in "MCLUST: Software for Model
Based Clustering, Density Estimation and Disriminant Analysis" by Chris
Fraley and Adrian Raftery, but I cannot reproduce the density and
uncertainty surfaces for the Lansing Woods maples.  I am using R 1.8.1 with
the code below.  The same code works fine in S-Plus 6.2

Am I missing something or is this a bug?

Thanks
Mike White

library(mclust)
data(lansing) # R only
maples<-lansing[as.character(lansing[,"species"]) == "maple", -3]
maplesBIC <- EMclust(maples)
maplesModel <- summary(maplesBIC, maples)
plotMaples2 <- function(type, what, transformation)
{
 out <- do.call("surfacePlot", c(maplesModel, list(data=maples, type=type,
what=what,transformation=transformation)))
 invisible()
}
par(pty="s", mfrow=c(1,2))
plotMaples2(type="contour", what="density", transformation="log")
par(pty="s")
plotMaples2(type="contour", what="uncertainty", transformation = "log")



From macq at llnl.gov  Thu May  6 16:01:15 2004
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 6 May 2004 07:01:15 -0700
Subject: [R] cgi/servlets/httpd  in R
In-Reply-To: <409A45DB.6050601@imse.med.tu-muenchen.de>
References: <BB12D17A-9EB8-11D8-8BA1-0050E4C03977@warwick.ac.uk>
	<409A45DB.6050601@imse.med.tu-muenchen.de>
Message-ID: <p06002005bcbff4d58ee7@[128.115.153.6]>

At 4:04 PM +0200 5/6/04, Christian Lederer wrote:
>Hi,
>
>if found that the easiest way for me doing CGI with R was
>using the RSPerl package. So i could do all the CGI related things
>in Perl and call R functions from Perl to do the statistics.
>You can get RSPerl from http://www.omegahat.org.
>
>If loading the data each time gives a performance problem,
>i guess that you could use RSPerl together with fastcgi,
>so the R initialization and loading the data would happen only
>once. If you try this, i would be very interrested in your experiences.

Regarding initialization, another possibility might be the perl 
module Statistics::R announced by Graciliano M.P. in an email to 
r-help on 2004-02-21. See
    http://search.cpan.org/~gmpassos/Statistics-R-0.01/

>The RSPerl package is somewhat outdated, but it worked well together
>with R 1.6.0 (i didn't try newer versions).
>
>Christian :-)
>
>
>
>David Firth wrote:
>>On Wednesday, May 5, 2004, at 18:09 Europe/London, foobar wrote:
>>
>>>Hi R-helpers
>>>
>>>Has anyone had any experience doing CGI or Servlets or using an 
>>>httpd server in R?
>>>
>>
>>yes.  See the R FAQ, section 4.  (Or maybe you already have, in 
>>which case I misunderstood the question...)
>>
>>Best wishes,
>>David
>>


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From p.dalgaard at biostat.ku.dk  Thu May  6 16:21:31 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 May 2004 16:21:31 +0200
Subject: [R] weirdness in sourc()ing a dump()  (bug?)
In-Reply-To: <Pine.LNX.4.44.0405061206030.15757-100000@gannet.stats>
References: <Pine.LNX.4.44.0405061206030.15757-100000@gannet.stats>
Message-ID: <x2n04lk55g.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> There is already a bug report PR#4364 on an aspect of this.  The comment 
> there is
> 
>   dump somehow needs to recognize that expressions in lists 
>   probably need to be enclosed in quote().
> 
>   S does exactly the same though
> 
> (I think it is a symbol not a formal expression in the current examples.)

The comment and the report are both a little unclear. Objects of mode
"expression" are not the issue, since they do deparse/eval correctly.
Symbols and calls are.

> I believe it is rather difficult to determine what we cannot deparse
> successfully, and trying to issue a warning/error would give a false sense
> of security.  The code (src/main/deparse.c) suggests that at least
> 
> promises
> environments
> external pointers
> weak references
> 
> will not get a useful textual representation.  I don't think the goal can
> be as Peter describes -- it has to be more limited, and currently symbols
> are also on the list. 

Yes, I know. I didn't mean a goal in the sense that it can always be
achieved. Promises can be forced, but the other types are not easy to
handle.(I don't think even save/load knows what to do with external
pointers.) 

> (We might be able to solve symbols, but it is far
> from straightforward -- terms in formulae are symbols, for example, so we
> cannot just add quote() around symbols and that does indeed break code.)

Hmm, I thought the issue was that we need to quote calls but cannot
quote formulas (which are calls).
 
> There may well be others: it was not so long ago that integer vectors were 
> dumped in a text representation that was read back in as numeric.

...so that we now have dput() output with as.integer() constructs all
over the place. (Can't have and eat, etc., I know.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tpapp at axelero.hu  Thu May  6 16:33:02 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Thu, 6 May 2004 16:33:02 +0200
Subject: [R] copying R objects in C
In-Reply-To: <20040506034715.GA30774@bifur.rmki.kfki.hu>
References: <20040506001819.GB26976@bifur.rmki.kfki.hu>
	<20040506034715.GA30774@bifur.rmki.kfki.hu>
Message-ID: <20040506143302.GA2420@localhost>

You can tell what a function does by looking at its help page, eg:

?duplicate

There is no such function in R (1.9.0), so I don't see how you came
across that function name.

R performs a deep copy "on demand", and generally you should not worry
about this, just use the assignment operator "<-".

PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

and the "Introduction to R", and the FAQ.

Best,

Tamas

On Thu, May 06, 2004 at 05:47:15AM +0200, Csardi Gabor wrote:

> answer to myself:
> 
> the 'duplicate' function does this, am I right?
> It seems so....
> 
> Gabor
> 
> On Thu, May 06, 2004 at 02:18:19AM +0200, Csardi Gabor wrote:
> > Dear R Users,
> > 
> > do you know a way to copy an R object using C code? I know that
> > there is a copyMatrix and also a copyVector function. There is
> > also something called copyListMatrix, what is this good for? Is
> > there anything for copying a list (of course deep copy is
> > needed)? 
> > 
> > Thank you for your help,
> > Gabor
> [...]
> 
> -- 
> Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From p.dalgaard at biostat.ku.dk  Thu May  6 16:32:15 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 May 2004 16:32:15 +0200
Subject: [R] help on ks.test
In-Reply-To: <26309.1083839397@www26.gmx.net>
References: <17928.1083668164@www18.gmx.net> <26309.1083839397@www26.gmx.net>
Message-ID: <x2isf9k4nk.fsf@biostat.ku.dk>

"Janete Borges" <janeteborges at gmx.net> writes:

> Dear All
> 
> I need to test the goodness-of-fit of a (Negative) Exponential Distribution
> to a dataset. The parameter of the distribution is unknown. What is the
> appropriate test to do? I've tried the ks.test, although I think this
> isn't the appropriate one, as I don't know the population parameter. 
> Can anybody help me?
>  
> Thanks in advance,
> Janete

The bias of the K-S test with estimated parameters is well known to be
substantial, but I haven't heard about correction terms except (I
think) for the normal distribution.

Embedding the exponential distribution as a hypothesis in a larger
class of distributions (e.g. Gamma or Weibull) might be a useful way
to proceed.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Thu May  6 16:51:08 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 May 2004 15:51:08 +0100 (BST)
Subject: [R] copying R objects in C
In-Reply-To: <20040506143302.GA2420@localhost>
Message-ID: <Pine.LNX.4.44.0405061549140.20610-100000@gannet.stats>

On Thu, 6 May 2004, Tamas Papp wrote:

> You can tell what a function does by looking at its help page, eg:
> 
> ?duplicate
> 
> There is no such function in R (1.9.0), so I don't see how you came
> across that function name.

It's a C function (see the subject line), except that the external symbol
name gets remapped to Rf_duplicate.  You need this for writing code for
the .Call and similar interfaces.

> R performs a deep copy "on demand", and generally you should not worry
> about this, just use the assignment operator "<-".

Not `from C'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Thu May  6 16:51:07 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 6 May 2004 07:51:07 -0700 (PDT)
Subject: [R] copying R objects in C
In-Reply-To: <20040506143302.GA2420@localhost>
References: <20040506001819.GB26976@bifur.rmki.kfki.hu>
	<20040506034715.GA30774@bifur.rmki.kfki.hu>
	<20040506143302.GA2420@localhost>
Message-ID: <Pine.A41.4.58.0405060749400.26970@homer09.u.washington.edu>

On Thu, 6 May 2004, Tamas Papp wrote:

> You can tell what a function does by looking at its help page, eg:
>
> ?duplicate
>
> There is no such function in R (1.9.0), so I don't see how you came
> across that function name.
>
> R performs a deep copy "on demand", and generally you should not worry
> about this, just use the assignment operator "<-".

He's programming in C, not in R.  duplicate is a C function that
copies an object.


>
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> and the "Introduction to R", and the FAQ.


Please read the question, too.

	-thomas


> Best,
>
> Tamas
>
> On Thu, May 06, 2004 at 05:47:15AM +0200, Csardi Gabor wrote:
>
> > answer to myself:
> >
> > the 'duplicate' function does this, am I right?
> > It seems so....
> >
> > Gabor
> >
> > On Thu, May 06, 2004 at 02:18:19AM +0200, Csardi Gabor wrote:
> > > Dear R Users,
> > >
> > > do you know a way to copy an R object using C code? I know that
> > > there is a copyMatrix and also a copyVector function. There is
> > > also something called copyListMatrix, what is this good for? Is
> > > there anything for copying a list (of course deep copy is
> > > needed)?
> > >
> > > Thank you for your help,
> > > Gabor
> > [...]
> >
> > --
> > Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> --
> Tam??s K. Papp
> E-mail: tpapp at axelero.hu
> Please try to send only (latin-2) plain text, not HTML or other garbage.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From p.b.pynsent at bham.ac.uk  Thu May  6 16:52:56 2004
From: p.b.pynsent at bham.ac.uk (P. B. Pynsent)
Date: Thu, 6 May 2004 15:52:56 +0100
Subject: [R] Analysis of ordinal categorical data
In-Reply-To: <200405051245.i45Cj4mO019098@smtp.hispeed.ch>
References: <200405051245.i45Cj4mO019098@smtp.hispeed.ch>
Message-ID: <0F47CAE4-9F6D-11D8-95EF-000A95B0CE8A@bham.ac.uk>

Thomas,
R code for Agresti's book "Catagorical Data Analysis  is available on  
Laura Thompson's
  web site.
http://math.cl.uh.edu/~thompsonla/
You might find the book and the code helpful.
Paul
On 5 May 2004, at 13:45, thsudler at swissonline.ch wrote:

> Hi
>
> I would like to analyse an ordinal categorical variable. I know how I 
> can analyse a nominal categorical variable (with multinom or if there 
> are only two levels with glm).
>
> Does somebody know which command I need in R to analyse an ordinal 
> categorical variable?
>
> I want to describe the variable y with the variables x1,x2,x3 and x4. 
> So my model looks like: y ~ x1+x2+x3+x4.
>
> y: ordinal factor variable with levels (never, rare, bychance, often).
>
> Thanks a lot in advance
> Thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
P. B. Pynsent,
Research & Teaching Centre,
Royal Orthopaedic Hospital,
Northfield,
Birmingham, B31 2AP,
U. K.



From dtrenkler at nts6.oec.uni-osnabrueck.de  Thu May  6 17:01:00 2004
From: dtrenkler at nts6.oec.uni-osnabrueck.de (Trenkler, Dietrich)
Date: Thu, 6 May 2004 17:01:00 +0200 
Subject: [R] help on ks.test
Message-ID: <FB75CFC167F3D311B11D00A0CC20FB0E88546B@nts7.oec.Uni-Osnabrueck.DE>



> -----Original Message-----
> From:	Peter Dalgaard 
> Sent:	Thursday, May 06, 2004 4:32 PM
> To:	Janete Borges
> Cc:	r-help at stat.math.ethz.ch
> Subject:	Re: [R] help on ks.test
> 
> "Janete Borges" <janeteborges at gmx.net> writes:
> 
> > Dear All
> > 
> > I need to test the goodness-of-fit of a (Negative) Exponential
> Distribution
> > to a dataset. The parameter of the distribution is unknown. What is the
> > appropriate test to do? I've tried the ks.test, although I think this
> > isn't the appropriate one, as I don't know the population parameter. 
> > Can anybody help me?
> >  
> > Thanks in advance,
> > Janete
> 
> The bias of the K-S test with estimated parameters is well known to be
> substantial, but I haven't heard about correction terms except (I
> think) for the normal distribution.
	 
	[Dietrich Trenkler]  There is a Lilliefors-version of the KS-test 
	for the exponential distribution. See e.g.

	@ARTICLE{Lilliefors69a,
	  author = {H. W. Lilliefors},
	  year = 1969,
	  title = {On the {K}olmogorov-{S}mirnov Test for Exponential
	           Distribution with Mean Unknown Variance Unknown},
	  journal = {Journal of the American Statistical Association},
	  volume = 64,
	  pages = {387--389},
	  keywords = {Lilliefors Test for Exponentiality; Goodness-of-Fit;
	             Kolmogorov's Test}
	}                                

	 or

	@ARTICLE{Mason86,
	  author = {Andrew L. Mason and C.B. Bell},
	  year = 1986,
	  title = {New {L}illiefors and {S}rinivasan Tables with
Applications},
	  journal = {Communications in Statistics, Part B--Simulation and
Computation},
	  volume = 15,
	  pages = {451--477},
	  comment = {BIB 2},
	  keywords = {Lilliefors Test; Goodness-of-Fit; Simulation}
	}              
	 
	HTH

	Let me stress that the KS-test may not be very powerful.

	 Dietrich



From FWS4 at CDRH.FDA.GOV  Thu May  6 17:01:25 2004
From: FWS4 at CDRH.FDA.GOV (Samuelson, Frank*)
Date: Thu, 6 May 2004 11:01:25 -0400
Subject: [R] cgi/servlets/httpd  in R
Message-ID: <644D9337A02FC24689647BF9E48EC39E08ABB7E6@drm556>

Here's a related question:  Do any of the mentioned R-web interfaces
(Rweb, R-Online, CGIwithR, RSPerl) support reusing the same R process,
eliminating the startup overhead?  This would be useful to me as well.

Currently I use such a method on my computing cluster:  All 40 
compute nodes run an R process/compute server that listens at a socket for
any 
connection and subsequent commands from another computer. 
When the master process disconnects, the R processes go back to listening
at the socket.  Connecting to the R compute servers this way
takes < 2 milliseconds rather than the typical ~2 second R startup time.

Thanks for any tips.

-Frank



-----Original Message-----
From: Christian Lederer [mailto:christian.lederer at imse.med.tu-muenchen.de] 
Sent: Thursday, May 06, 2004 10:04 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] cgi/servlets/httpd in R



Hi,

if found that the easiest way for me doing CGI with R was
using the RSPerl package. So i could do all the CGI related things
in Perl and call R functions from Perl to do the statistics.
You can get RSPerl from http://www.omegahat.org.

If loading the data each time gives a performance problem,
i guess that you could use RSPerl together with fastcgi,
so the R initialization and loading the data would happen only
once. If you try this, i would be very interrested in your experiences.

The RSPerl package is somewhat outdated, but it worked well together
with R 1.6.0 (i didn't try newer versions).

Christian :-)



David Firth wrote:
> On Wednesday, May 5, 2004, at 18:09 Europe/London, foobar wrote:
> 
>> Hi R-helpers
>>
>> Has anyone had any experience doing CGI or Servlets or using an httpd 
>> server in R?
>>
>>
> 
> yes.  See the R FAQ, section 4.  (Or maybe you already have, in which 
> case I misunderstood the question...)
> 
> Best wishes,
> David
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From d.firth at warwick.ac.uk  Thu May  6 17:26:36 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Thu, 6 May 2004 16:26:36 +0100
Subject: [R] cgi/servlets/httpd  in R
In-Reply-To: <644D9337A02FC24689647BF9E48EC39E08ABB7E6@drm556>
Message-ID: <C35D13AE-9F71-11D8-B939-000A95A6625E@warwick.ac.uk>

On Thursday, May 6, 2004, at 16:01 Europe/London, Samuelson, Frank* 
wrote:

> Here's a related question:  Do any of the mentioned R-web interfaces
> (Rweb, R-Online, CGIwithR, RSPerl) support reusing the same R process,
> eliminating the startup overhead?  This would be useful to me as well.
>
> Currently I use such a method on my computing cluster:  All 40
> compute nodes run an R process/compute server that listens at a socket 
> for
> any
> connection and subsequent commands from another computer.
> When the master process disconnects, the R processes go back to 
> listening
> at the socket.  Connecting to the R compute servers this way
> takes < 2 milliseconds rather than the typical ~2 second R startup 
> time.
>
>

I only know about CGIwithR, which is very simple and starts a new R for 
every request.  Startup time on my Mac is around 1.3 seconds; for my 
own purposes this is absolutely fine, but I can appreciate that it 
could well be problematic in certain kinds of application (eg where a 
very large amount of data has to be loaded).

Best wishes,
David



From rpeng at jhsph.edu  Thu May  6 17:17:34 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 06 May 2004 11:17:34 -0400
Subject: [R] copying R objects in C
In-Reply-To: <20040506034715.GA30774@bifur.rmki.kfki.hu>
References: <20040506001819.GB26976@bifur.rmki.kfki.hu>
	<20040506034715.GA30774@bifur.rmki.kfki.hu>
Message-ID: <409A570E.9090703@jhsph.edu>

The source for `duplicate' and its usage in the R source seems to 
imply that it copies objects in general.

I've never used it though, so my $0.02 has been devalued.

-roger

Csardi Gabor wrote:
> answer to myself:
> 
> the 'duplicate' function does this, am I right?
> It seems so....
> 
> Gabor
> 
> On Thu, May 06, 2004 at 02:18:19AM +0200, Csardi Gabor wrote:
> 
>>Dear R Users,
>>
>>do you know a way to copy an R object using C code? I know that
>>there is a copyMatrix and also a copyVector function. There is
>>also something called copyListMatrix, what is this good for? Is
>>there anything for copying a list (of course deep copy is
>>needed)? 
>>
>>Thank you for your help,
>>Gabor
> 
> [...]
>



From Kerstin.Gross at ebs.de  Thu May  6 17:40:21 2004
From: Kerstin.Gross at ebs.de (Gross, Kerstin)
Date: Thu, 6 May 2004 17:40:21 +0200 
Subject: [R] IE5 and the html help function
Message-ID: <45C2456041B5D31183A4009027C3938B02635B5E@BIGIEE>

I recently formatted and reinstalled my laptop. Since then html-help
function is not working properly. 

I can open the page, however, searching for any term or opening any link
does not work. 
The Internet explorer just mentions an error on the page if I try to open a
links and instead of searching it reloads the page.

Reinstalling R did not help and now I am not sure if it is the IE, or R, or
the java script. Any idea how I could get the html functions working?
Thanks!

Kerstin Gross



From ripley at stats.ox.ac.uk  Thu May  6 17:47:43 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 May 2004 16:47:43 +0100 (BST)
Subject: [R] cgi/servlets/httpd  in R
In-Reply-To: <C35D13AE-9F71-11D8-B939-000A95A6625E@warwick.ac.uk>
Message-ID: <Pine.LNX.4.44.0405061644470.19271-100000@gannet.stats>

Can I remind people that R will start up very much faster if you don't 
need all the standard packages loaded: in particular, in half the time 
without methods loaded and in 10% of the time if you only need base.
We hope come 2.0.0 to have halved the existing time by using 
load-on-demand of objects.

On Thu, 6 May 2004, David Firth wrote:

> On Thursday, May 6, 2004, at 16:01 Europe/London, Samuelson, Frank* 
> wrote:
> 
> > Here's a related question:  Do any of the mentioned R-web interfaces
> > (Rweb, R-Online, CGIwithR, RSPerl) support reusing the same R process,
> > eliminating the startup overhead?  This would be useful to me as well.
> >
> > Currently I use such a method on my computing cluster:  All 40
> > compute nodes run an R process/compute server that listens at a socket 
> > for
> > any
> > connection and subsequent commands from another computer.
> > When the master process disconnects, the R processes go back to 
> > listening
> > at the socket.  Connecting to the R compute servers this way
> > takes < 2 milliseconds rather than the typical ~2 second R startup 
> > time.
> >
> >
> 
> I only know about CGIwithR, which is very simple and starts a new R for 
> every request.  Startup time on my Mac is around 1.3 seconds; for my 
> own purposes this is absolutely fine, but I can appreciate that it 
> could well be problematic in certain kinds of application (eg where a 
> very large amount of data has to be loaded).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu May  6 17:53:39 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 May 2004 16:53:39 +0100 (BST)
Subject: [R] IE5 and the html help function
In-Reply-To: <45C2456041B5D31183A4009027C3938B02635B5E@BIGIEE>
Message-ID: <Pine.LNX.4.44.0405061648050.19271-100000@gannet.stats>

Is it html help or the search in html help (as you mention java)?

If the latter, please read the instructions and follow the link on the
html search page (and if you can't see it, you are not using the current
R).  It is likely you don't have a JVM installed (since I suppose this is 
Windows and not MacOS on which you have `IE5').

If the former, then try setting your file associations again, or even 
installing another browser (Firefox is highly recommended).

On Thu, 6 May 2004, Gross, Kerstin wrote:

> I recently formatted and reinstalled my laptop. Since then html-help
> function is not working properly. 
> 
> I can open the page, however, searching for any term or opening any link
> does not work. 
> The Internet explorer just mentions an error on the page if I try to open a
> links and instead of searching it reloads the page.
> 
> Reinstalling R did not help and now I am not sure if it is the IE, or R, or
> the java script. Any idea how I could get the html functions working?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From macq at llnl.gov  Thu May  6 17:56:51 2004
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 6 May 2004 08:56:51 -0700
Subject: [R] segmentation fault with sprintf(), sometimes
Message-ID: <p06002007bcc010a4138d@[128.115.153.6]>

By mistake I supplied sprintf() with a bad format specification. I
got a segmentation fault. But not every time.

>   version
           _
platform sparc-sun-solaris2.8
arch     sparc
os       solaris2.8
system   sparc, solaris2.8
status   Patched
major    1
minor    9.0
year     2004
month    04
day      30
language R

>   sprintf('%.-0.999f',3)
Segmentation fault

The format string makes no sense, of course, so one should expect
something bad to happen. But preferably not that bad!

Also, the behavior is to some degree indeterminate. Sometimes I get this:

>   sprintf('%.-0.999f',3)
[1]
"0.00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000!
  0
000000000000"

I haven't identified anything that might determine which the above
responses occurs.

On another platform, note that the formatted string begins with "3",
not "0" as above.

>   version
           _
platform powerpc-apple-darwin6.8.5
arch     powerpc
os       darwin6.8.5
system   powerpc, darwin6.8.5
status   Patched
major    1
minor    9.0
year     2004
month    04
day      30
language R
>    sprintf('%.-0.999f',3)
[1]
"3.00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000!
  0
000000000000"
>

The behavior is no doubt dependent on the operating system's sprintf,
for I find in R's sprintf.c:

/* Simple wrapper for C sprintf function: now (1.6.0) checks the
     types and handles the R specials.
*/

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From james-chapman at uiowa.edu  Thu May  6 18:02:04 2004
From: james-chapman at uiowa.edu (James Chapman)
Date: Thu, 6 May 2004 11:02:04 -0500
Subject: [R] R on Windows Hangs on Packages Built from Sources
In-Reply-To: <Pine.LNX.4.44.0405060646240.7904-100000@gannet.stats>
Message-ID: <200405061602.i46G26uj043914@night.its.uiowa.edu>

Hi,

Thanks, after I emailed the help list I figured I should try building R
since then I would have a kit that should be able to build packages
properly. I immediately realized, as you both pointed out, that I needed a
MinGW GCC; I was using Cygwin's compiler.

I downloaded the ash source and got it to compile properly.

Thanks for the information,

James

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Thursday, May 06, 2004 00:52
> To: James Chapman
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] R on Windows Hangs on Packages Built from Sources
> 
> It must be frustrating, but
> 
> - that setup does work for other people
> - I don't think we have ever seen a `hang' of that sort.
> 
> I would try one of the packages on CRAN which does have a recent binary
> compiled.  (I tend to use ash to test, as it is small and uses Fortran.)
> If that fails then you need a way to debug the `hang' (and you haven't
> told us exactly where it is, so I can't suggest any).
> 
> On Wed, 5 May 2004, James Chapman wrote:
> 
> > Hi,
> >
> > I am currently having the following problem with R 1.9.0. Any package
> that
> > contains C or Fortran code hangs after I have built it and load it into
> R.
> > I've tried this with RMySQL and udunits, originally I thought I had done
> > something subtly wrong in configuring these packages; but I just had the
> > same problem with a simple example R package that I wrote. I was able to
> > build and load the package on a Linux system at school so I figure I've,
> > hopefully, ruled out a programming problem on my part.
> >
> > The system I'm having the problem on is as follows:
> > AMD AthlonXP
> > R 1.9.0 installed from binaries
> > GCC 3.3.1
> 
> Just checking -- gcc 3.3.3 for MinGW as in
> 
> [c:/R/rw2000/src/gnuwin32]% gcc --version
> gcc (GCC) 3.3.1 (mingw special 20030804-1)
> 
> ?  Someone sent me several messages recently, and it transpired was trying
> to use the cygwin compilers.
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rrsilva at ib.usp.br  Thu May  6 18:55:18 2004
From: rrsilva at ib.usp.br (=?iso-8859-1?q?Rog=E9rio_Rosa_da_Silva?=)
Date: Thu, 6 May 2004 13:55:18 -0300
Subject: [R] constrained sample
Message-ID: <200405061355.18268.rrsilva@ib.usp.br>

Dear List,

Is there an way to do a randomization (with sample) on a column and that 
maintain fixed the occurrence totals (i.e, numbers different of zeros) on a 
factor column ?

Thanks in advance

-- 
Rog??rio R. Silva
MZUSP http://www.mz.usp.br
Linux User #354364
Linux counter http://counter.li.org

# description file:
factors	occurrence
A	1
A	7
A	5
A	0
B	1
B	5
B	0
B	0
C	3
C	4
C	5
C	0
D	0
D	0
D	0
D	1



From bates at stat.wisc.edu  Thu May  6 18:52:01 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 06 May 2004 11:52:01 -0500
Subject: [R] An untimely death
Message-ID: <6risf94hxq.fsf@bates4.stat.wisc.edu>

The Department of Statistics at the University of Wisconsin-Madison is
immensely saddened to announce the death of our friend and colleague
Greg Reinsel (http://www.stat.wisc.edu/~reinsel/) on Wednesday, May 5,
2004 at the untimely age of 56.  He collapsed and died during his
regular early morning run.

Greg's many students, colleagues and friends may send messages via
Candy Smith <candy at stat.wisc.edu>.  She will ensure that they reach
his family.

I would appreciate suggestions from those in the time series community
of ways that I could convey this unfortunate news to time series
analysts.



From nlwhitehouse at yahoo.com  Thu May  6 19:12:49 2004
From: nlwhitehouse at yahoo.com (Nathan Whitehouse)
Date: Thu, 6 May 2004 10:12:49 -0700 (PDT)
Subject: [R] Re: R web interfaces
Message-ID: <20040506171249.11883.qmail@web12401.mail.yahoo.com>

cashaw at bcm.tmc.edu, 
    youngas7 at yahoo.com
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii

Hi,

  First, does anyone think it is a good idea to put up
a web server site similar to Phillippe Grosjean's site
for GUIs?  

  To answer foobar's question-

  There are a several web 'interfaces', with different
focuses and degrees of sophistication.
  Apologies to the developers if I characterize them
wrongly.  They are all tailored to slightly different
purposes.

  CGI/(transaction based) -
       CGIWithR, RWeb & RCGI(unmaintained)

  TCP/IP Servers(sessioned)-
        RServe
       -RServe has a homegrown protocol for large
datasets

  Web/HTTP Servers(sessioned)-
       RZope/RStatServer
        -A Zope/Python/RPython facility for executing
scripts/application development

       Rho
        -A servlet application/application development
suite to selectively expose R code & manage
datasets/projects 

  There are three or so different things to consider
with these:
    1)How R-based processing is made available or
whether the client supplies them(like RWeb)
    2)The extent to which a framework/system is an
'application development system' as opposed to 'a way
to submit R code on the web'
    3)How R is running
        a)spawned from apache using CGI- one
spawn/transaction 
        b)an R process on the server that takes up
requests in a queue
        c)a set of processes that are spawned
dynamically and communicate through SOAP/CORBA etc.
These may exist on multiple internal computers.

   Although there are other issues, which we'd be
excited to talk to somebody about at UseR.

  Best,
  Nathan Whitehouse

=====
Nathan Whitehouse
Statistics/Programming
Baylor College of Medicine
Houston, TX, USA
nlwhitehouse at yahoo.com
work: 1-713-798-9029
cell:    1-512-293-5840

http://rho-project.org: rho- open source web services for R.
http://franklin.imgen.bcm.tmc.edu: Shaw laboratory, bcm.



From HStevens at MUOhio.edu  Thu May  6 19:49:57 2004
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Thu, 6 May 2004 13:49:57 -0400
Subject: [R] IE5 and the html help function
In-Reply-To: <45C2456041B5D31183A4009027C3938B02635B5E@BIGIEE>
References: <45C2456041B5D31183A4009027C3938B02635B5E@BIGIEE>
Message-ID: <CA3AEB8C-9F85-11D8-B534-000A958F43CC@MUOhio.edu>

I am running R 1.9.0 on Mac OSX 10.3.3.
I have the same problem when I try to use the search engine within the 
R help html index page. If I use help.start() to open the index page, I 
can then use "?" to search html help pages, but this provides a more 
limited access to the help files. This above is true whether I am using 
RAqua or R(?) within ESS and Emacs.
Hank Stevens

On May 6, 2004, at 11:40 AM, Gross, Kerstin wrote:

> I recently formatted and reinstalled my laptop. Since then html-help
> function is not working properly.
>
> I can open the page, however, searching for any term or opening any 
> link
> does not work.
> The Internet explorer just mentions an error on the page if I try to 
> open a
> links and instead of searching it reloads the page.
>
> Reinstalling R did not help and now I am not sure if it is the IE, or 
> R, or
> the java script. Any idea how I could get the html functions working?
> Thanks!
>
> Kerstin Gross
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/



From HStevens at MUOhio.edu  Thu May  6 19:53:03 2004
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Thu, 6 May 2004 13:53:03 -0400
Subject: [R] IE5 and the html help function RESEND
In-Reply-To: <45C2456041B5D31183A4009027C3938B02635B5E@BIGIEE>
References: <45C2456041B5D31183A4009027C3938B02635B5E@BIGIEE>
Message-ID: <38B22C38-9F86-11D8-B534-000A958F43CC@MUOhio.edu>

I should have specified in my previous email that I have tried Safari 
(the Mac internet application) as well as Firefox 0.8 and IE5.2.

I am running R 1.9.0 on Mac OSX 10.3.3.
I have the same problem when I try to use the search engine within the 
R help html index page. If I use help.start() to open the index page, I 
can then use "?" to search html help pages, but this provides a more 
limited access to the help files. This above is true whether I am using 
RAqua or R(?) within ESS and Emacs. Hank Stevens

On May 6, 2004, at 11:40 AM, Gross, Kerstin wrote:

> I recently formatted and reinstalled my laptop. Since then html-help
> function is not working properly.
>
> I can open the page, however, searching for any term or opening any 
> link
> does not work.
> The Internet explorer just mentions an error on the page if I try to 
> open a
> links and instead of searching it reloads the page.
>
> Reinstalling R did not help and now I am not sure if it is the IE, or 
> R, or
> the java script. Any idea how I could get the html functions working?
> Thanks!
>
> Kerstin Gross
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/



From prechelt at pcpool.mi.fu-berlin.de  Thu May  6 20:00:32 2004
From: prechelt at pcpool.mi.fu-berlin.de (Lutz Prechelt)
Date: Thu, 6 May 2004 20:00:32 +0200
Subject: [R] constrained sample
Message-ID: <85D25331FFB7AE4C900EA467D4ADA39204593A@circle.pcpool.mi.fu-berlin.de>

I'm afraid I do not understand what you need.
What is sampled from where and what do you need to keep constant?
And what is the relationship between the 'column' and the 'factor column'?

Maybe you can provide a complete example and counterexample?

  Lutz

> Is there an way to do a randomization (with sample) on a 
> column and that 
> maintain fixed the occurrence totals (i.e, numbers different 
> of zeros) on a factor column ?



From ramasamy at cancer.org.uk  Thu May  6 20:22:01 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: 06 May 2004 19:22:01 +0100
Subject: [R] constrained sample
In-Reply-To: <85D25331FFB7AE4C900EA467D4ADA39204593A@circle.pcpool.mi.fu-berlin.de>
References: <85D25331FFB7AE4C900EA467D4ADA39204593A@circle.pcpool.mi.fu-berlin.de>
Message-ID: <1083867721.4774.66.camel@vpn202001.lif.icnet.uk>

Possible something like this ?

> grp <- factor(rep(c("odd", "even"), 3)); val <- c(1,2,3,4,5,6)
> data.frame(grp, val)
   grp val
1  odd   1
2 even   2
3  odd   3
4 even   4
5  odd   5
6 even   6
> ( newval.list <- tapply(val, grp, sample) )
$even
[1] 6 4 2

$odd
[1] 3 1 5

> for(i in 1:length(newval.list)){
       val[ grp == names(newval.list)[i] ] <- newval.list[[i]]
  }
> data.frame(grp, val)
   grp val
1  odd   3
2 even   6
3  odd   1
4 even   4
5  odd   5
6 even   2



On Thu, 2004-05-06 at 19:00, Lutz Prechelt wrote:
> I'm afraid I do not understand what you need.
> What is sampled from where and what do you need to keep constant?
> And what is the relationship between the 'column' and the 'factor column'?
> 
> Maybe you can provide a complete example and counterexample?
> 
>   Lutz
> 
> > Is there an way to do a randomization (with sample) on a 
> > column and that 
> > maintain fixed the occurrence totals (i.e, numbers different 
> > of zeros) on a factor column ?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From lanzi at elet.polimi.it  Fri May  7 05:10:18 2004
From: lanzi at elet.polimi.it (Pier Luca Lanzi)
Date: Thu, 06 May 2004 20:10:18 -0700
Subject: [R] *** GOODNESS OF FIT FOR BINOMIAL DISTRIBUTED DATA
Message-ID: <1083899417.2053.53.camel@linux.local>

Hi, 

this is probably a very newbie statistical question.

I have some experimental data. 

My hypothesis is that the data are binomially distributed with a known N
and p. 

I am trying to obtain a sort of p-value to tell me whether or not my
hypothesis is correct. 

What can I do with R?

Thank you,
Pier Luca



From Achim.Zeileis at wu-wien.ac.at  Thu May  6 20:39:09 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 6 May 2004 20:39:09 +0200
Subject: [R] *** GOODNESS OF FIT FOR BINOMIAL DISTRIBUTED DATA
In-Reply-To: <1083899417.2053.53.camel@linux.local>
References: <1083899417.2053.53.camel@linux.local>
Message-ID: <20040506203909.3f9f331b.Achim.Zeileis@wu-wien.ac.at>

On Thu, 06 May 2004 20:10:18 -0700 Pier Luca Lanzi wrote:

> Hi, 
> 
> this is probably a very newbie statistical question.
> 
> I have some experimental data. 
> 
> My hypothesis is that the data are binomially distributed with a known
> N and p. 
> 
> I am trying to obtain a sort of p-value to tell me whether or not my
> hypothesis is correct. 
> 
> What can I do with R?

You can look at the package vcd, in particular the functions goodfit()
with corresponding methods and distplot(). See also
  example(Saxony)
For more details on the methods, look at Michael Friendly's book
"Visualizing Categorical Data".

hth,
Z



> Thank you,
> Pier Luca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From Max_Kuhn at bd.com  Thu May  6 20:47:19 2004
From: Max_Kuhn at bd.com (Max_Kuhn@bd.com)
Date: Thu, 6 May 2004 14:47:19 -0400
Subject: [R] modifying the text size in splom
Message-ID: <OF6FDF3C75.6E40AFBA-ON85256E8C.00666592@bd.com>

All,

I have long variable names that are being fed through splom (R 1.8.1). I'd
like to resize the text printed on the diagonals to better display the
names (unless anyone can suggest another approach - creative use of
varnames). I've looked at the code, R-Help, ?splom and the Trellis User's
Guide to no avail.

Any suggestions? Thanks in advance,

Max Kuhn, Ph.D.
Becton Dickinson Diagnostic Systems




-----------------------------------------
This message is intended only for the designated recipient(s...{{dropped}}



From deepayan at stat.wisc.edu  Thu May  6 21:39:39 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 6 May 2004 14:39:39 -0500
Subject: [R] modifying the text size in splom
In-Reply-To: <OF6FDF3C75.6E40AFBA-ON85256E8C.00666592@bd.com>
References: <OF6FDF3C75.6E40AFBA-ON85256E8C.00666592@bd.com>
Message-ID: <200405061439.39728.deepayan@stat.wisc.edu>

On Thursday 06 May 2004 13:47, Max_Kuhn at bd.com wrote:
> All,
>
> I have long variable names that are being fed through splom (R
> 1.8.1). I'd like to resize the text printed on the diagonals to
> better display the names (unless anyone can suggest another approach
> - creative use of varnames). I've looked at the code, R-Help, ?splom
> and the Trellis User's Guide to no avail.
>
> Any suggestions? Thanks in advance,

Not really much you can do in 1.8.1. If you upgrade to 1.9.0, you could 
do 

splom(<...>, varname.cex = .5)

and you could even supply your own function to draw the diagonal panels.

Hth,

Deepayan



From James_A_Rogers at groton.pfizer.com  Thu May  6 23:04:05 2004
From: James_A_Rogers at groton.pfizer.com (Rogers, James A [PGRD Groton])
Date: Thu, 6 May 2004 17:04:05 -0400 
Subject: [R] sporadic errors with nlrq() / optim()  
Message-ID: <C735670CCC69D61193DA0002A58EE9900D7F51B5@groexmb07.pfizer.com>

Dear List, 

Apologies if this is a known problem ... I wasn't able to find it on the bug
list, but it is a problem that does not seem to occur with a MAC build of R
2.0, so perhaps this problem has already been addressed for the future.  

I am getting *sporadic* errors when refitting the same model to the same
data set, using nlrq() in the nlrq package. The algorithm is not stochastic,
so I would expect to get errors either every time, or never.

###

library(stats) # or library(nls) if using R < 1.9.0
library(nlrq)

test <- data.frame(x = c(7.60090245954208, 6.90775527898214,
6.21460809842219, 5.52146091786225, 4.60517018598809, 3.91202300542815,
3.2188758248682 , 2.52572864430826, 1.83258146374831, 7.60090245954208,
6.90775527898214, 6.21460809842219, 5.52146091786225, 4.60517018598809,
3.91202300542815, 3.2188758248682 , 2.52572864430826, 1.83258146374831,
6.21460809842219, 6.21460809842219),
                   y = c( 11.0161506644269, 9.84267541313937,
8.66146668057266, 7.48099216286952, 6.50578406012823, 6.24027584517077,
5.63121178182137, 5.71702770140622, 5.64190707093811, 10.8983676287705,
9.91857318995417, 8.74608021735751, 7.58120982619635, 6.361302477573 ,
5.91889385427315, 5.63835466933375 , 5.80211837537706, 5.64897423816121,
8.6195692580331 , 8.70367275835886)
                   )

i <- 1
while(i < 500) {    # I usually hit an error within 50 iterations
  cat(i, "\n")
  nlrq(y ~ SSfpl(x, A, B, xmid, scal), data = test)
  i <- i + 1
}

###

Errors occur with version 1.8.1 and 1.9.0 on both Windows (two different
machines) and UNIX, but not on version 2.0 on a MAC (these are the only R
version - OS permutations I was able to get reports on easily). 

Anyone understand what is happening here?

Thanks,
Jim  





LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From p.dalgaard at biostat.ku.dk  Thu May  6 23:21:14 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 May 2004 23:21:14 +0200
Subject: [R] sporadic errors with nlrq() / optim()
In-Reply-To: <C735670CCC69D61193DA0002A58EE9900D7F51B5@groexmb07.pfizer.com>
References: <C735670CCC69D61193DA0002A58EE9900D7F51B5@groexmb07.pfizer.com>
Message-ID: <x24qqtfe0l.fsf@biostat.ku.dk>

"Rogers, James A [PGRD Groton]" <James_A_Rogers at groton.pfizer.com> writes:

> Dear List, 
> 
> Apologies if this is a known problem ... I wasn't able to find it on the bug
> list, but it is a problem that does not seem to occur with a MAC build of R
> 2.0, so perhaps this problem has already been addressed for the future.  
> 
> I am getting *sporadic* errors when refitting the same model to the same
> data set, using nlrq() in the nlrq package. The algorithm is not stochastic,
> so I would expect to get errors either every time, or never.
> 
> ###
> 
> library(stats) # or library(nls) if using R < 1.9.0
> library(nlrq)
> 
> test <- data.frame(x = c(7.60090245954208, 6.90775527898214,
> 6.21460809842219, 5.52146091786225, 4.60517018598809, 3.91202300542815,
> 3.2188758248682 , 2.52572864430826, 1.83258146374831, 7.60090245954208,
> 6.90775527898214, 6.21460809842219, 5.52146091786225, 4.60517018598809,
> 3.91202300542815, 3.2188758248682 , 2.52572864430826, 1.83258146374831,
> 6.21460809842219, 6.21460809842219),
>                    y = c( 11.0161506644269, 9.84267541313937,
> 8.66146668057266, 7.48099216286952, 6.50578406012823, 6.24027584517077,
> 5.63121178182137, 5.71702770140622, 5.64190707093811, 10.8983676287705,
> 9.91857318995417, 8.74608021735751, 7.58120982619635, 6.361302477573 ,
> 5.91889385427315, 5.63835466933375 , 5.80211837537706, 5.64897423816121,
> 8.6195692580331 , 8.70367275835886)
>                    )
> 
> i <- 1
> while(i < 500) {    # I usually hit an error within 50 iterations
>   cat(i, "\n")
>   nlrq(y ~ SSfpl(x, A, B, xmid, scal), data = test)
>   i <- i + 1
> }
> 
> ###
> 
> Errors occur with version 1.8.1 and 1.9.0 on both Windows (two different
> machines) and UNIX, but not on version 2.0 on a MAC (these are the only R
> version - OS permutations I was able to get reports on easily). 
> 
> Anyone understand what is happening here?

There's no "version 2.0", only "2.0.0 Under development (unstable)". 
If you look at the NEWS file for that version (or for 1.9.0-patched)
under 1.9.1 changes, you'll find

   o   The L-BFGS-B option of optim() apparently needs part of its
        workspace zeroed.  (PR#6720)

which gave problems of the sort you experiences.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From lmassis at yahoo.com.br  Thu May  6 23:42:14 2004
From: lmassis at yahoo.com.br (Leonard assis)
Date: Thu, 6 May 2004 18:42:14 -0300
Subject: [R] sporadic errors with nlrq() / optim()
In-Reply-To: <x24qqtfe0l.fsf@biostat.ku.dk>
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAHlebCTgy30WZ5WwsVbJtq8KAAAAQAAAAh5/442FIxkKxvlWvRFBbEAEAAAAA@yahoo.com.br>

In my computer, there's no error

WIN XP
PENTIUM4 1.67GHz
1GB RAM
R 1.9.0 Patched 


[]s
Leonard Assis
Estat??stico /  CONFE 7439
UIN : 41-764-523 /  Skype : lmassis /  msn : lmassis at msn.com

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Peter Dalgaard
Sent: Thursday, May 06, 2004 6:21 PM
To: Rogers, James A [PGRD Groton]
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R] sporadic errors with nlrq() / optim()

"Rogers, James A [PGRD Groton]" <James_A_Rogers at groton.pfizer.com> writes:

> Dear List,
> 
> Apologies if this is a known problem ... I wasn't able to find it on 
> the bug list, but it is a problem that does not seem to occur with a 
> MAC build of R 2.0, so perhaps this problem has already been addressed for
the future.
> 
> I am getting *sporadic* errors when refitting the same model to the 
> same data set, using nlrq() in the nlrq package. The algorithm is not 
> stochastic, so I would expect to get errors either every time, or never.
> 
> ###
> 
> library(stats) # or library(nls) if using R < 1.9.0
> library(nlrq)
> 
> test <- data.frame(x = c(7.60090245954208, 6.90775527898214, 
> 6.21460809842219, 5.52146091786225, 4.60517018598809, 
> 3.91202300542815,
> 3.2188758248682 , 2.52572864430826, 1.83258146374831, 
> 7.60090245954208, 6.90775527898214, 6.21460809842219, 
> 5.52146091786225, 4.60517018598809, 3.91202300542815, 3.2188758248682 
> , 2.52572864430826, 1.83258146374831, 6.21460809842219, 6.21460809842219),
>                    y = c( 11.0161506644269, 9.84267541313937, 
> 8.66146668057266, 7.48099216286952, 6.50578406012823, 
> 6.24027584517077, 5.63121178182137, 5.71702770140622, 
> 5.64190707093811, 10.8983676287705, 9.91857318995417, 
> 8.74608021735751, 7.58120982619635, 6.361302477573 , 5.91889385427315, 
> 5.63835466933375 , 5.80211837537706, 5.64897423816121,
> 8.6195692580331 , 8.70367275835886)
>                    )
> 
> i <- 1
> while(i < 500) {    # I usually hit an error within 50 iterations
>   cat(i, "\n")
>   nlrq(y ~ SSfpl(x, A, B, xmid, scal), data = test)
>   i <- i + 1
> }
> 
> ###
> 
> Errors occur with version 1.8.1 and 1.9.0 on both Windows (two 
> different
> machines) and UNIX, but not on version 2.0 on a MAC (these are the 
> only R version - OS permutations I was able to get reports on easily).
> 
> Anyone understand what is happening here?

There's no "version 2.0", only "2.0.0 Under development (unstable)". 
If you look at the NEWS file for that version (or for 1.9.0-patched) under
1.9.1 changes, you'll find

   o   The L-BFGS-B option of optim() apparently needs part of its
        workspace zeroed.  (PR#6720)

which gave problems of the sort you experiences.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From lmassis at yahoo.com.br  Thu May  6 23:50:00 2004
From: lmassis at yahoo.com.br (Leonard assis)
Date: Thu, 6 May 2004 18:50:00 -0300
Subject: [R] sporadic errors with nlrq() / optim()
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAHlebCTgy30WZ5WwsVbJtq8KAAAAQAAAAh5/442FIxkKxvlWvRFBbEAEAAAAA@yahoo.com.br>
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAHlebCTgy30WZ5WwsVbJtq8KAAAAQAAAAzb/ta0xfm0WmMfig1n5ZtQEAAAAA@yahoo.com.br>

 
Only theese: :(

 
495 
496 
497 
498 
499 
There were 50 or more warnings (use warnings() to see the first 50)
> 
> warnings()
Warning messages:
1: multi-argument returns are deprecated in: return(coef, w) 
2: multi-argument returns are deprecated in: return(coef, w) 
3: multi-argument returns are deprecated in: return(coef, w) 
4: multi-argument returns are deprecated in: return(coef, w) 
5: multi-argument returns are deprecated in: return(coef, w) 
6: multi-argument returns are deprecated in: return(coef, w) 
7: multi-argument returns are deprecated in: return(coef, w) 
8: multi-argument returns are deprecated in: return(coef, w) 
9: multi-argument returns are deprecated in: return(coef, w) 
10: multi-argument returns are deprecated in: return(coef, w)
...
50: multi-argument returns are deprecated in: return(coef, w)
[]s
Leonard Assis
Estat??stico /  CONFE 7439
UIN : 41-764-523 /  Skype : lmassis /  msn : lmassis at msn.com

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Leonard assis
Sent: Thursday, May 06, 2004 6:42 PM
To: 'Peter Dalgaard'; 'Rogers, James A [PGRD Groton]'
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] sporadic errors with nlrq() / optim()

In my computer, there's no error

WIN XP
PENTIUM4 1.67GHz
1GB RAM
R 1.9.0 Patched 


[]s
Leonard Assis
Estat??stico /  CONFE 7439
UIN : 41-764-523 /  Skype : lmassis /  msn : lmassis at msn.com

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Peter Dalgaard
Sent: Thursday, May 06, 2004 6:21 PM
To: Rogers, James A [PGRD Groton]
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R] sporadic errors with nlrq() / optim()

"Rogers, James A [PGRD Groton]" <James_A_Rogers at groton.pfizer.com> writes:

> Dear List,
> 
> Apologies if this is a known problem ... I wasn't able to find it on 
> the bug list, but it is a problem that does not seem to occur with a 
> MAC build of R 2.0, so perhaps this problem has already been addressed 
> for
the future.
> 
> I am getting *sporadic* errors when refitting the same model to the 
> same data set, using nlrq() in the nlrq package. The algorithm is not 
> stochastic, so I would expect to get errors either every time, or never.
> 
> ###
> 
> library(stats) # or library(nls) if using R < 1.9.0
> library(nlrq)
> 
> test <- data.frame(x = c(7.60090245954208, 6.90775527898214, 
> 6.21460809842219, 5.52146091786225, 4.60517018598809, 
> 3.91202300542815,
> 3.2188758248682 , 2.52572864430826, 1.83258146374831, 
> 7.60090245954208, 6.90775527898214, 6.21460809842219, 
> 5.52146091786225, 4.60517018598809, 3.91202300542815, 3.2188758248682 
> , 2.52572864430826, 1.83258146374831, 6.21460809842219, 6.21460809842219),
>                    y = c( 11.0161506644269, 9.84267541313937, 
> 8.66146668057266, 7.48099216286952, 6.50578406012823, 
> 6.24027584517077, 5.63121178182137, 5.71702770140622, 
> 5.64190707093811, 10.8983676287705, 9.91857318995417, 
> 8.74608021735751, 7.58120982619635, 6.361302477573 , 5.91889385427315,
> 5.63835466933375 , 5.80211837537706, 5.64897423816121,
> 8.6195692580331 , 8.70367275835886)
>                    )
> 
> i <- 1
> while(i < 500) {    # I usually hit an error within 50 iterations
>   cat(i, "\n")
>   nlrq(y ~ SSfpl(x, A, B, xmid, scal), data = test)
>   i <- i + 1
> }
> 
> ###
> 
> Errors occur with version 1.8.1 and 1.9.0 on both Windows (two 
> different
> machines) and UNIX, but not on version 2.0 on a MAC (these are the 
> only R version - OS permutations I was able to get reports on easily).
> 
> Anyone understand what is happening here?

There's no "version 2.0", only "2.0.0 Under development (unstable)". 
If you look at the NEWS file for that version (or for 1.9.0-patched) under
1.9.1 changes, you'll find

   o   The L-BFGS-B option of optim() apparently needs part of its
        workspace zeroed.  (PR#6720)

which gave problems of the sort you experiences.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From godbless_maria at hotmail.com  Fri May  7 02:49:57 2004
From: godbless_maria at hotmail.com (Maria Gu)
Date: Fri, 07 May 2004 00:49:57 +0000
Subject: [R] R example of Mahalanobis, Kolmogrov, ROC, Gini, Delta
Message-ID: <BAY2-F73D5euwdUTaGm00005ad4@hotmail.com>

Dear R helpers:

I have another question regarding "R" command. It is also measuring Credit 
Scoring.

I need to measure the classifying method for customer's credit score. (ex. 
regression line by Fisher)

If credit card company already classify  their customers credit :
Good customers / Bad customers
[by using regression line; ex) inside of line: Good/ outside: Bad]

And I found out from the statistics book that there are following method 
also used to "measure" if credit card company's  classification method is 
proper or not.

-Mahalanobis distance
-Kolmogorov-smirnow statistics
-ROC curve
-Gini coefficient
-Delta approach

Actually,I have not heard of these method and I also need to make some  "R" 
command using some of this statistical method to measure classification. Any 
example is fine! I just want to look at how these method can be used to 
measure any data classification!
Please let me know any R command you can think of!
I hope I won't bother you a lot and I appreciate your help this time, too!!!


Thank you!
Have a nice day!

True blessings,

Maria Gu
SFSU MBA
510-418-1240



From wildscop at yahoo.com  Fri May  7 03:43:01 2004
From: wildscop at yahoo.com (WilD KID)
Date: Thu, 6 May 2004 18:43:01 -0700 (PDT)
Subject: [R] Orthogonal Polynomial Regression Parameter Estimation
Message-ID: <20040507014301.68881.qmail@web11407.mail.yahoo.com>

Dear all,

I came up with some sort of solution(!), which is :

--------------------------------------------
>  orth.fit<-lm(Y~poly(X,degree = 6))
>  co<-coef(orth.fit)
>  s<-c(sum(p0^2), sum(p1^2), sum(p2^2), sum(p3^2),
sum(p4^2), sum(p5^2), sum(p6^2)) # these pi's were
previously defined
>  nor<-co/sqrt(ss)
> 
co1<-c(alpha0,alpha1,alpha2,alpha3,alpha4,alpha5,alpha6)
# from previous results
>  cbind(co,ss,nor,co1)
                               co   ss           nor  
        co1
(Intercept)           1.285000000    8  0.4543161069 
1.2850000000
poly(X, degree = 6)1  0.529260490  168  0.0408333333 
0.0408333333
poly(X, degree = 6)2 -0.316321867  168 -0.0244047619
-0.0244047619
poly(X, degree = 6)3 -0.221564684  264 -0.0136363636
-0.0136363636
poly(X, degree = 6)4  0.054795962  616  0.0022077922 
0.0022077922
poly(X, degree = 6)5  0.062910192 2184  0.0013461538 
0.0013461538
poly(X, degree = 6)6  0.006154575  264  0.0003787879 
0.0003787879
--------------------------------------------

Note that all values of "nor" (modified R result) and
"co1" (Draper and Smith result) matches, except the
intercept term! But i guess i can live with it:p
However, if any one has any more suggestions, please
let me know.

Thanks to all who helped me here (Douglas Bates and
Prof Brian Ripley) and elsewhere (including Dale
McLerran of comp.soft-sys.sas and Nick Cox of Stata
list).

Thank you very much for all your support.

_______________________

Mohammad Ehsanul Karim <wildscop at yahoo.com> 
Institute of Statistical Research and Training 
University of Dhaka, Dhaka- 1000, Bangladesh



From p.murrell at auckland.ac.nz  Fri May  7 03:45:44 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 07 May 2004 13:45:44 +1200
Subject: [R] question about plot.dendrogram
References: <1083851647.409a437f41f30@webmail.utoronto.ca>
Message-ID: <409AEA48.9040609@stat.auckland.ac.nz>

Hi


ivan.borozan at utoronto.ca wrote:
> hi all,
> 
> i'm trying to plot a dendrogram with labeled leaves
> 
>>rownames(f)<-v.names
>>v<-rowMeans(f, na.rm=T)
>>clust<-hclust(dist(v))
>>dend<-as.dendrogram(clust,hang=0.05)
>>clust2<-cut(dend, h=0.5)
>>class(clust2$low[[1]])
>>[1] "dendrogram"
> 
> then 
> 
>>plot(clust2$low[[1]],horiz=TRUE,frame=F,type = "tr"))
> 
> but my leaf labels do not fit entirely in the plot region. Has anyone an idea
> how to get around this without using cex , something similar to "hang=0.5" so
> that my labels do not start to hang from 0 ?


Does making the bottom figure margin bigger help?  e.g., ...

par(mar=c(10, 4, 4, 2))

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From p.murrell at auckland.ac.nz  Fri May  7 03:53:48 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 07 May 2004 13:53:48 +1200
Subject: [R] plot(hist.default(1:10,plot=F)) error.
References: <200405061248090007.05D6F394@mail.math.fu-berlin.de>
Message-ID: <409AEC2C.30302@stat.auckland.ac.nz>

Hi


witek wrote:
> How to find out which plot function is used when i call
> plot(hist.default(1:10,plot=F)) and all works fine ?
> 
> The reason why I would like to know it is that after loading some self written R functions
> 
>>plot(hist.default(1:10,plot=F))
> 
> Error in xy.coords(x, y, xlabel, ylabel, log) :
>  x and y lengths differ
> 
>>traceback()
> 
> 5: stop("x and y lengths differ")
> 4: xy.coords(x, y, xlabel, ylabel, log)
> 3: plot.default(hist.default(1:10, plot = F))
> 2: plot(hist.default(1:10, plot = F))
> 1: plot(hist.default(1:10, plot = F))
> 
> gives an error.
> It seems that instead of the function normally used to plot histograms
> plot.default is called. But which one is normally used?
> 
> 
> How in general i can find out to find out which plot function is called by an object.


 > x <- hist(1:10, plot=FALSE)
 > class(x)
[1] "histogram"
 > methods("plot")
  [1] plot.acf*           plot.data.frame*    plot.Date*
  [4] plot.decomposed.ts* plot.default        plot.dendrogram*
  [7] plot.density        plot.ecdf           plot.factor*
[10] plot.formula*       plot.hclust*        plot.histogram*
[13] plot.HoltWinters*   plot.isoreg*        plot.lm
[16] plot.medpolish*     plot.mlm            plot.POSIXct*
[19] plot.POSIXlt*       plot.ppr*           plot.prcomp*
[22] plot.princomp*      plot.profile.nls*   plot.shingle*
[25] plot.spec           plot.spec.coherency plot.spec.phase
[28] plot.stepfun        plot.stl*           plot.table*
[31] plot.ts             plot.tskernel*      plot.TukeyHSD

     Non-visible functions are asterisked


Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From arinbasu at softhome.net  Fri May  7 05:55:41 2004
From: arinbasu at softhome.net (arinbasu@softhome.net)
Date: Thu, 06 May 2004 21:55:41 -0600
Subject: [R] Bluefish Editor with R
In-Reply-To: <200405061001.i46A0b9A026526@hypatia.math.ethz.ch> 
References: <200405061001.i46A0b9A026526@hypatia.math.ethz.ch>
Message-ID: <courier.409B08BD.000064C0@softhome.net>

Dear List: 

Somewhere in the R-Statistical Software website, I remember having read 
about using the opensource Bluefish editor with R. During a recent visit to 
the site, I could not find the link or reference. Also, when I searched the 
list archives (http://maths.newcastle.edu.au/~rking/R/about.html) for 
"bluefish", the search returned no result. 

Has anyone in the list used bluefish as an editor for writing R commands and 
functions? Are there any tutorials available? 

TIA,
Arin Basu



From ripley at stats.ox.ac.uk  Fri May  7 06:18:40 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 May 2004 05:18:40 +0100 (BST)
Subject: [R] IE5 and the html help function RESEND
In-Reply-To: <38B22C38-9F86-11D8-B534-000A958F43CC@MUOhio.edu>
Message-ID: <Pine.LNX.4.44.0405070516110.20222-100000@gannet.stats>

See my earlier reply.  Neither of you have described `the same problem' 
precisely enough to know what to suggest.

If the problem is with search, there is a link to the R-admin manual, and 
that has links to diagnostic pages.  Please go through all that before 
reporting back.

On Thu, 6 May 2004, Martin Henry H. Stevens wrote:

> I should have specified in my previous email that I have tried Safari 
> (the Mac internet application) as well as Firefox 0.8 and IE5.2.
> 
> I am running R 1.9.0 on Mac OSX 10.3.3.
> I have the same problem when I try to use the search engine within the 
> R help html index page. If I use help.start() to open the index page, I 
> can then use "?" to search html help pages, but this provides a more 
> limited access to the help files. This above is true whether I am using 
> RAqua or R(?) within ESS and Emacs. Hank Stevens
> 
> On May 6, 2004, at 11:40 AM, Gross, Kerstin wrote:
> 
> > I recently formatted and reinstalled my laptop. Since then html-help
> > function is not working properly.
> >
> > I can open the page, however, searching for any term or opening any 
> > link
> > does not work.
> > The Internet explorer just mentions an error on the page if I try to 
> > open a
> > links and instead of searching it reloads the page.
> >
> > Reinstalling R did not help and now I am not sure if it is the IE, or 
> > R, or
> > the java script. Any idea how I could get the html functions working?
> > Thanks!
> >
> > Kerstin Gross
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> >
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
> 
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/botany/bot/henry.html
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tpapp at axelero.hu  Fri May  7 07:53:26 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Fri, 7 May 2004 07:53:26 +0200
Subject: sorry (was Re: [R] copying R objects in C)
In-Reply-To: <20040506143302.GA2420@localhost>
References: <20040506001819.GB26976@bifur.rmki.kfki.hu>
	<20040506034715.GA30774@bifur.rmki.kfki.hu>
	<20040506143302.GA2420@localhost>
Message-ID: <20040507055325.GA695@localhost>

On Thu, May 06, 2004 at 04:33:02PM +0200, Tamas Papp wrote:

> [something utterly stupid]

I somehow missed the end of the subject line.  I sincerely apologize
for my stupid and irrelevant answer.

Tamas

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From phddas at yahoo.com  Fri May  7 09:13:47 2004
From: phddas at yahoo.com (Fred J.)
Date: Fri, 7 May 2004 00:13:47 -0700 (PDT)
Subject: [R] generating data
Message-ID: <20040507071347.59537.qmail@web20503.mail.yahoo.com>

Hello
I am trying to generate data in say 2D "x,y" for a
circle. grid.circle {grid} does not do. any ides is
appreciated.

Thanks
F.J.



From prechelt at pcpool.mi.fu-berlin.de  Fri May  7 09:42:44 2004
From: prechelt at pcpool.mi.fu-berlin.de (Lutz Prechelt)
Date: Fri, 7 May 2004 09:42:44 +0200
Subject: [R] generating data
Message-ID: <85D25331FFB7AE4C900EA467D4ADA39204593B@circle.pcpool.mi.fu-berlin.de>

Do you mean random data?
Generate polar coordinates (angle in range 0..2pi, radius in range 0..1)
and convert.

  Lutz

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Fred J.
> Sent: Freitag, 7. Mai 2004 09:14
> To: r help
> Subject: [R] generating data
> 
> 
> Hello
> I am trying to generate data in say 2D "x,y" for a
> circle. grid.circle {grid} does not do. any ides is
> appreciated.
> 
> Thanks
> F.J.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From M.Mamin at intershop.de  Fri May  7 09:57:41 2004
From: M.Mamin at intershop.de (Marc Mamin)
Date: Fri, 7 May 2004 09:57:41 +0200
Subject: [R] Problem (Bug?) with readLines on Suze
Message-ID: <A03188C6623C0D46A703CB5AA59907F2170647@JENMAIL01.ad.intershop.net>


Hello,

I called readLines on  Suze 9.0 with a directory as parameter instead of a file.
R freezed for a very long time; this morning I could read following error message:

Error in readLines(paste("/home/",foo,"/",sep=""))  :  cannot allocate buffer in readLines


under W2K I get a more logical error ("cannot open file")


(I'm still using R 1.8.1)

cheers,

Marc



From alexpegucci at yahoo.com  Fri May  7 10:02:44 2004
From: alexpegucci at yahoo.com (alex pegucci)
Date: Fri, 7 May 2004 01:02:44 -0700 (PDT)
Subject: [R] sampling weights for lme
Message-ID: <20040507080244.35593.qmail@web14427.mail.yahoo.com>

Dear All,

I have a complex survey data with observations having differing
probabilities of selection into the sample. I would like to run a
linear mixed effects model and also to use weighting that takes this
into consideration. As far as I know, however, the weighting option for
the lme command from nlme package (or glmmPQL from MASS, for that
matter) is related to heteroscedasticity. Is there a sampling weights
option for these packages that I am not aware of? 

Regards,

Alex



From daniel.hoppe at univie.ac.at  Fri May  7 10:09:34 2004
From: daniel.hoppe at univie.ac.at (Daniel Hoppe)
Date: Fri, 7 May 2004 10:09:34 +0200
Subject: [R] Gaussian Hypergeometric Series _2F_1(a,b,c;z)
Message-ID: <002f01c4340a$a2c47d80$82b98283@DH>

Dear all,

I am working on a small package which is supposed to provide evaluation
of the gaussian hypergeometric series. It will be based on the
Fortran-code by Robert Forrey. Does anyone beside me use this function
and would be willing to test the package or discuss requirements?

All the best,

Daniel



From ripley at stats.ox.ac.uk  Fri May  7 10:12:30 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 May 2004 09:12:30 +0100 (BST)
Subject: [R] Problem (Bug?) with readLines on Suze
In-Reply-To: <A03188C6623C0D46A703CB5AA59907F2170647@JENMAIL01.ad.intershop.net>
Message-ID: <Pine.LNX.4.44.0405070902500.9027-100000@gannet.stats>

You asked R to read a binary file line-by-line, and it did its best.
Given that an incorrect operation resulted in an error message, it did 
reasonably well.

It looks to me as if end of directory is not being detected, and I'll dig 
deeper to see it that can be improved.

On Fri, 7 May 2004, Marc Mamin wrote:

> I called readLines on  Suze 9.0 with a directory as parameter instead of a file.
> R freezed for a very long time; this morning I could read following error message:
> 
> Error in readLines(paste("/home/",foo,"/",sep=""))  :  cannot allocate buffer in readLines
> 
> 
> under W2K I get a more logical error ("cannot open file")

That's because on Windows a directory is not a text file.  We could 
probably add such a check on Unix.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rksh at soc.soton.ac.uk  Fri May  7 10:24:54 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Fri, 7 May 2004 09:24:54 +0100
Subject: [R] Gaussian Hypergeometric Series _2F_1(a,b,c;z)
In-Reply-To: <002f01c4340a$a2c47d80$82b98283@DH>
References: <002f01c4340a$a2c47d80$82b98283@DH>
Message-ID: <a0600200abcc0f775bf00@[139.166.242.29]>

Hi Daniel

try hypergeo in library(Davies)

best

rksh




>Dear all,
>
>I am working on a small package which is supposed to provide evaluation
>of the gaussian hypergeometric series. It will be based on the
>Fortran-code by Robert Forrey. Does anyone beside me use this function
>and would be willing to test the package or discuss requirements?
>
>All the best,
>
>Daniel
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From schnitzlerj at lyon.who.int  Fri May  7 11:36:31 2004
From: schnitzlerj at lyon.who.int (Johannes SCHNITZLER)
Date: Fri, 7 May 2004 11:36:31 +0200
Subject: [R] Rterm
Message-ID: <AD1C47A0C9C12C46987E2D31EE1E63B4040306@lps001.lyon.who.int>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040507/14f2623a/attachment.pl

From fzoellne at TechFak.Uni-Bielefeld.DE  Fri May  7 12:14:10 2004
From: fzoellne at TechFak.Uni-Bielefeld.DE (Frank Gerrit Zoellner)
Date: Fri, 7 May 2004 12:14:10 +0200
Subject: [R] svm question
Message-ID: <20040507101410.GA24772@hindemith.TechFak.Uni-Bielefeld.DE>

Hi!

I have a questionaccording to classifing new examples from an already trained svm. I have tarined a svm (e1071 package) with a training set of 1526 examples.
Now I have another data set with 2163 examples and I want to use the already trained svm for prediction:

 pred<-predict(a.svm,newdata);

Afterwards for further processessing I add further information to the results of teh classification from the original input (also 2163 x N matrix) 

result<-as.data.frame(cbind(newdata[81:84],pred))

But I receive an error:

Error in data.frame(..., check.names = FALSE) : 
        arguments imply differing number of rows: 2163, 1526

So I wonder why the svm is stick to a resultset of 1526 although I put in 2613 examples? To my mind I thought that the classification/predictin depends on the length of the feature vector not on the number of examples? Or am I doing something wrong?

Thanks 
-- 
Frank G. Zoellner
AG Angewandte Informatik
Technische Fakult"at
Universit"at Bielefeld
phone: +49(0)521-106-2951
fax:   +49(0)521-106-2992
email: fzoellne at techfak.uni-bielefeld.de



From jasont at indigoindustrial.co.nz  Fri May  7 12:15:20 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 7 May 2004 22:15:20 +1200 (NZST)
Subject: [R] Rterm
In-Reply-To: <AD1C47A0C9C12C46987E2D31EE1E63B4040306@lps001.lyon.who.int>
References: <AD1C47A0C9C12C46987E2D31EE1E63B4040306@lps001.lyon.who.int>
Message-ID: <54964.203.9.176.60.1083924920.squirrel@webmail.maxnet.co.nz>

> With R1090
>
> C:\Program Files\R\rw1090\bin\rterm.exe --vanilla <test.r --args "Arg1"
> "Arg2"
>
> There is the error message: Rterm.exe is not a valid Win32 application
>
> I tried on Windows 2000 and  XP
>
> I couldn't find out what to change.

Weird.  Did you install in C:\Program Files\R\rw1090\?  On my XP machine,
it did, and rterm is valid.  The above works from a command prompt,
provided I wrap the executable path and name in quotes.  Failing that, is
it a corrupt binary install?

Here's the md5 of my (working) R-1.9.0, downloaded from CRAN (NOT the
patched version, and not built by me)

C:\Program Files\R\rw1090\bin> md5sum.exe Rterm.exe
2565cd848bbd86b964624a0490352da2 *Rterm.exe

> I would like to set the working directory as well, in the same command,
> when calling an r script with rterm.exe from the command line.
>
> Is there a way to do this?

Inside R: setwd("your/path/here")  With the usual warning about using "/"
slashes, or "\\" slashes (doubled).  I just stick with "/".

Cheers

Jason



From JonesW at kssg.com  Fri May  7 12:03:08 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Fri, 7 May 2004 11:03:08 +0100 
Subject: [R] loess and as.POSIXct
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02955EE2@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040507/51eed68a/attachment.pl

From j.hall at beatson.gla.ac.uk  Fri May  7 12:29:58 2004
From: j.hall at beatson.gla.ac.uk (Jacqueline Hall)
Date: Fri, 7 May 2004 11:29:58 +0100
Subject: [R] scores from multinomial logistic regression
Message-ID: <000901c4341e$3f3eccc0$62e8d182@o1jh>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040507/812afb1f/attachment.pl

From David.Jutier at pge.cnrs-gif.fr  Fri May  7 13:20:14 2004
From: David.Jutier at pge.cnrs-gif.fr (David Jutier)
Date: Fri, 7 May 2004 13:20:14 +0200
Subject: [R] contrasts in a type III anova
Message-ID: <200405071320.15370.David.Jutier@pge.cnrs-gif.fr>

Hello,

I use a type III anova ("car" package) to analyse an unbalanced data design. I 
have two factors and I would have the effect of the interaction. I read that 
the result could be strongly influenced by the contrasts. I am really not an 
expert and I am not sure to understand indeed about what it is...

Consequently, I failed to properly used the fit.contrast function (gregmisc 
package) because I don't understand what the fonction need in the argument 
"coeff".

The two factors are Y (Ya, Yb,..., Ye) and Auto (Auto1, Auto2,...., Auto10)
The responses are binomial (counts in the matrice "mat") and gaussian 
(variable "tot"). I use the glm procedure :

glm1 <- glm (mat ~ y*auto, data, family=binomial)
glm2 <- glm (tot ~ y*auto, data, family=gaussian)

Subsequently I use the Type III anova :

Anova (glm1, type="III")
Anova (glm2, type="III")

Using the contrast.treatment for both factors Y and Auto, R gives coherent 
results, but I really not sure that this contrasts are appropriate !

Thank's for your advices !
David



From schnitzlerj at lyon.who.int  Fri May  7 13:56:57 2004
From: schnitzlerj at lyon.who.int (Johannes SCHNITZLER)
Date: Fri, 7 May 2004 13:56:57 +0200
Subject: [R] Rterm
Message-ID: <AD1C47A0C9C12C46987E2D31EE1E63B4040308@lps001.lyon.who.int>

Dear Jason,

Thank you very much, the first problem is solved. 
It was a corrupted file. After downloading a new version rterm works!

The second question:
I was trying to set the working directory while I'm calling a script
with Rterm.exe from the command line.
Something like
c:\Program Files\R\rw1090\bin\rterm.exe --vanilla "workingdir=c:/data/"
<test.r --args "Arg1" "Arg2"

Thank's again

Johannes



-----Original Message-----
From: Jason Turner [mailto:jasont at indigoindustrial.co.nz] 
Sent: 07 May 2004 12:15
To: Johannes SCHNITZLER
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Rterm

> With R1090
>
> C:\Program Files\R\rw1090\bin\rterm.exe --vanilla <test.r --args
"Arg1"
> "Arg2"
>
> There is the error message: Rterm.exe is not a valid Win32 application
>
> I tried on Windows 2000 and  XP
>
> I couldn't find out what to change.

Weird.  Did you install in C:\Program Files\R\rw1090\?  On my XP
machine,
it did, and rterm is valid.  The above works from a command prompt,
provided I wrap the executable path and name in quotes.  Failing that,
is
it a corrupt binary install?

Here's the md5 of my (working) R-1.9.0, downloaded from CRAN (NOT the
patched version, and not built by me)

C:\Program Files\R\rw1090\bin> md5sum.exe Rterm.exe
2565cd848bbd86b964624a0490352da2 *Rterm.exe

> I would like to set the working directory as well, in the same
command,
> when calling an r script with rterm.exe from the command line.
>
> Is there a way to do this?

Inside R: setwd("your/path/here")  With the usual warning about using
"/"
slashes, or "\\" slashes (doubled).  I just stick with "/".

Cheers

Jason



From m.abdolell at utoronto.ca  Fri May  7 14:02:13 2004
From: m.abdolell at utoronto.ca (Mohamed Abdolell)
Date: Fri,  7 May 2004 08:02:13 -0400
Subject: [R] x-axis tick mark labels running vertically
Message-ID: <1083931333.409b7ac59c4a0@webmail.utoronto.ca>

I'm plotting obesity rates (y-axis) vs Public Health Unit (x-axis) for the 
province of Ontario and would like to have the Public Health Unit names appear 
vertically rather than the default, horizontally.

I'm actually using the 'barplot2' function in the {gregmisc} library ... I 
haven't been able to find a solution in either the barplot2 options or the 
general plotting options.

Any pointers would be appreciated.

- Mohamed



From bjooe at online.no  Fri May  7 14:22:10 2004
From: bjooe at online.no (=?iso-8859-1?Q?Bj=F8rn_=D8kland?=)
Date: Fri, 7 May 2004 14:22:10 +0200
Subject: [R] Start problem
Message-ID: <000801c4342d$ec3d75c0$bd00a8c0@skogforsk.no>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040507/e35d6feb/attachment.pl

From martinol at ensam.inra.fr  Fri May  7 14:40:17 2004
From: martinol at ensam.inra.fr (Martin Olivier)
Date: Fri, 07 May 2004 14:40:17 +0200
Subject: [R] help with histogram
Message-ID: <409B83B1.2050400@ensam.inra.fr>

Hi all,

I need some help with the function histogram. Let x be a vector.
The command hist(x,col="blue") gives an histogram for the vector x.
I would like to add some colors in the graphics such that the histogram is
red if abs(x)>1.669 and blue otherwise...and what is the solution if I 
want to
change the  filling instead of the color

Thanks for your help,
Olivier



From MSchwartz at MedAnalytics.com  Fri May  7 14:36:31 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 07 May 2004 07:36:31 -0500
Subject: [R] x-axis tick mark labels running vertically
In-Reply-To: <1083931333.409b7ac59c4a0@webmail.utoronto.ca>
References: <1083931333.409b7ac59c4a0@webmail.utoronto.ca>
Message-ID: <1083933391.30646.125.camel@localhost.localdomain>

On Fri, 2004-05-07 at 07:02, Mohamed Abdolell wrote:
> I'm plotting obesity rates (y-axis) vs Public Health Unit (x-axis) for the 
> province of Ontario and would like to have the Public Health Unit names appear 
> vertically rather than the default, horizontally.
> 
> I'm actually using the 'barplot2' function in the {gregmisc} library ... I 
> haven't been able to find a solution in either the barplot2 options or the 
> general plotting options.
> 
> Any pointers would be appreciated.
> 
> - Mohamed


You need to adjust par("las") to alter the orientation of the of the
axis labels:

barplot2(1:4, names.arg = c("one", "two", "three", "four"), las = 2)

You can also use the axis() function separately:

barplot2(1:4)
axis(1, labels = c("one", "two", "three", "four"), las = 2)

Setting par(las = 2) rotates the axis labels so that they are
perpendicular to the axis.

See ?par for more information.

HTH,

Marc Schwartz



From Stefano.Guazzetti at ausl.re.it  Fri May  7 14:45:22 2004
From: Stefano.Guazzetti at ausl.re.it (Guazzetti Stefano)
Date: Fri, 7 May 2004 14:45:22 +0200
Subject: R: [R] help with histogram
Message-ID: <F298786BF61DE64590054AF31EA1B4C8016D1FA5@PEPI.ausl.org>

Maybe you want something like:

x<-rnorm(1000)
hist(x, breaks=100,
 col=ifelse(abs((hist(x, breaks=100, main=""))$breaks) < 1.669,
 4,2))

see also the density argument in ?hist
Stefano

> -----Messaggio originale-----
> Da: Martin Olivier [mailto:martinol at ensam.inra.fr]
> Inviato: venerd?? 7 maggio 2004 14.40
> A: r-help
> Oggetto: [R] help with histogram
> 
> 
> Hi all,
> 
> I need some help with the function histogram. Let x be a vector.
> The command hist(x,col="blue") gives an histogram for the vector x.
> I would like to add some colors in the graphics such that the 
> histogram is
> red if abs(x)>1.669 and blue otherwise...and what is the 
> solution if I 
> want to
> change the  filling instead of the color
> 
> Thanks for your help,
> Olivier
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From M.Mamin at intershop.de  Fri May  7 14:50:47 2004
From: M.Mamin at intershop.de (Marc Mamin)
Date: Fri, 7 May 2004 14:50:47 +0200
Subject: [R] help with histogram
Message-ID: <A03188C6623C0D46A703CB5AA59907F2170649@JENMAIL01.ad.intershop.net>

Hi,

you can use subset of data and superpose different histograms for each of them.

hth,

Marc



From rpeng at jhsph.edu  Fri May  7 14:52:11 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 07 May 2004 08:52:11 -0400
Subject: [R] Bluefish Editor with R
In-Reply-To: <courier.409B08BD.000064C0@softhome.net>
References: <200405061001.i46A0b9A026526@hypatia.math.ethz.ch>
	<courier.409B08BD.000064C0@softhome.net>
Message-ID: <409B867B.5000105@jhsph.edu>

I think you can download it here

http://bluefish.openoffice.nl/index.html

I used it once a while back and it's nice since it has built in 
support for R w/syntax highlighting.  But at this point I'm wedded to 
Emacs.

I thought it actually came bundled with a recent RedHat/Fedora Linux 
but now I can't find it....

-roger

arinbasu at softhome.net wrote:
> Dear List:
> Somewhere in the R-Statistical Software website, I remember having read 
> about using the opensource Bluefish editor with R. During a recent visit 
> to the site, I could not find the link or reference. Also, when I 
> searched the list archives 
> (http://maths.newcastle.edu.au/~rking/R/about.html) for "bluefish", the 
> search returned no result.
> Has anyone in the list used bluefish as an editor for writing R commands 
> and functions? Are there any tutorials available?
> TIA,
> Arin Basu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From isung at affinnova.com  Fri May  7 15:13:11 2004
From: isung at affinnova.com (Iyue Sung)
Date: Fri, 7 May 2004 09:13:11 -0400
Subject: [R] Font and Color documentation
Message-ID: <90821ABF429A074DA88E56D1DF7A71610130CA2A@afifs1.affinnova.com>


Hello R-ians,

  Could someone please point me to documentation on legal font and color
specifications (and other 'par' parameters); i.e. font=6 for Times New
Roman, col='Red', etc.?  Searches in "?par", MASS (1st ed.) and other
areas were unsuccessful. I thought I remember seeing it
before...somewhere.

Thanks,
Iyue



From RBaskin at ahrq.gov  Fri May  7 15:42:49 2004
From: RBaskin at ahrq.gov (Baskin, Robert)
Date: Fri, 7 May 2004 09:42:49 -0400 
Subject: [R] sampling weights for lme
Message-ID: <6BCD3F430455B1418750004BCD27925905C6C3@exchange2.ahrq.gov>

< I would like to run a linear *mixed effects* model and also to use
(sample) weighting ...>
I've been trying to do this for 2 decades :)

See
< 9. Pfeffermann, D. , Skinner, C. J. , Holmes, D. J. , Goldstein, H. , and
Rasbash, J.  (1998), ``Weighting for unequal selection probabilities in
multilevel models (Disc: p41-56)'', Journal of the Royal Statistical
Society, Series B, Methodological, 60 , 23-40 >

which refers back to:
<29. Pfeffermann, D. , and LaVange, L.  (1989), ``Regression models for
stratified multi-stage cluster samples'', Analysis of Complex Surveys,
237-260 >


If you don't like statistical papers, then see section 4.5 of <8. Korn,
Edward Lee , and Graubard, Barry I.  (1999), ``Analysis of health surveys'',
John Wiley & Sons (New York; Chichester) > They explain the idea of using
weights in a model fairly simply.


And I would always recommend Rick's (us hillbillies gotta stick together:)
book:  <5. Valliant, Richard , Dorfman, Alan H. , and Royall, Richard M.
(2000), ``Finite population sampling and inference: a prediction approach'',
John Wiley & Sons (New York; Chichester) > as a general fun read.

I didn't really answer your question but...
Bob



-----Original Message-----
From: alex pegucci [mailto:alexpegucci at yahoo.com] 
Sent: Friday, May 07, 2004 4:03 AM
To: r-help at stat.math.ethz.ch
Subject: [R] sampling weights for lme

Dear All,

I have a complex survey data with observations having differing
probabilities of selection into the sample. I would like to run a
linear mixed effects model and also to use weighting that takes this
into consideration. As far as I know, however, the weighting option for
the lme command from nlme package (or glmmPQL from MASS, for that
matter) is related to heteroscedasticity. Is there a sampling weights
option for these packages that I am not aware of? 

Regards,

Alex

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From daniel.hoppe at univie.ac.at  Fri May  7 15:44:28 2004
From: daniel.hoppe at univie.ac.at (Daniel Hoppe)
Date: Fri, 7 May 2004 15:44:28 +0200
Subject: [R] Anyone in need of fast evaluation of Gaussian Hypergeometric
	Series?
In-Reply-To: <002f01c4340a$a2c47d80$82b98283@DH>
Message-ID: <000301c43439$6ba67db0$82b98283@DH>

Dear all,

sorry for the repost, but I think that the subject line of my previous
posting did not really make my point clear. 

Is there anyone who would be interesting in testing and giving me
feedback about a package which evaluates the _2F_1 series and 
- is fast compared to the straightforward summation and
- is more precise especially near to the circle of convergence |z|~1?

If you are interested please send me a short note.

Daniel



From jasont at indigoindustrial.co.nz  Fri May  7 15:59:49 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sat, 08 May 2004 01:59:49 +1200
Subject: [R] Rterm
In-Reply-To: <AD1C47A0C9C12C46987E2D31EE1E63B4040308@lps001.lyon.who.int>
References: <AD1C47A0C9C12C46987E2D31EE1E63B4040308@lps001.lyon.who.int>
Message-ID: <409B9655.3010407@indigoindustrial.co.nz>

Johannes SCHNITZLER wrote:
> The second question:
> I was trying to set the working directory while I'm calling a script
> with Rterm.exe from the command line.
> Something like
> c:\Program Files\R\rw1090\bin\rterm.exe --vanilla "workingdir=c:/data/"
> <test.r --args "Arg1" "Arg2"

Not sure - if you could pass the working directory as an arg, then R can 
handle it from there - use the setwd() command.  What I usually do on 
Un*x-like systems is to cd to the directory first, then start the R run. 
  Something like....

cd "my favorite dir"
R --vanilla ...

Since you're already specifying the absolute path for Rterm, the above 
should work...

Cheers

Jason



From ripley at stats.ox.ac.uk  Fri May  7 16:07:10 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 May 2004 15:07:10 +0100 (BST)
Subject: [R] scores from multinomial logistic regression
In-Reply-To: <000901c4341e$3f3eccc0$62e8d182@o1jh>
Message-ID: <Pine.LNX.4.44.0405071502220.25954-100000@gannet.stats>

What do you mean by the scores?

What multinom does is to fit probabilities (which you can extract by 
fitted()): the response is a discrete probability distribution.
There is an underlying linear predictor but

(a) it is K-dimensional and
(b) there is a degree of ambiguity, usually resolved by setting the 
predictor for one category to zero (but not in this code).

That linear predictor is only generated in the underlying C code.

On Fri, 7 May 2004, Jacqueline Hall wrote:

> Dear all,
>  
> I'm interested in extracting the score from multinomial logistic regression
> models fit using multinom, to assess the stregth of assocation of the
> parameter with the response (akin to the score from clogit/cox regression).
> currently I'm using R 1.8.1.
> Is there a function that will extract the score from a multinom object or
> how i can get back to it? or from using glm?
> I investigated the documention for Design but those functions seem to apply
> to binary logistic.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri May  7 16:16:09 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 May 2004 15:16:09 +0100 (BST)
Subject: [R] Rterm
In-Reply-To: <409B9655.3010407@indigoindustrial.co.nz>
Message-ID: <Pine.LNX.4.44.0405071510580.25954-100000@gannet.stats>

On Sat, 8 May 2004, Jason Turner wrote:

> Johannes SCHNITZLER wrote:
> > The second question:
> > I was trying to set the working directory while I'm calling a script
> > with Rterm.exe from the command line.
> > Something like
> > c:\Program Files\R\rw1090\bin\rterm.exe --vanilla "workingdir=c:/data/"
> > <test.r --args "Arg1" "Arg2"
> 
> Not sure - if you could pass the working directory as an arg, then R can 
> handle it from there - use the setwd() command.  What I usually do on 
> Un*x-like systems is to cd to the directory first, then start the R run. 
>   Something like....
> 
> cd "my favorite dir"
> R --vanilla ...
> 
> Since you're already specifying the absolute path for Rterm, the above 
> should work...

That's the only way.  The `working directory' is the directory from which 
you launch an application (although you can fix that by a shortcut).  R 
looks in the working directory for several things, e.g. a .Rprofile file, 
before it ever runs any R code like setwd.  If that is not a problem you 
can use something like (from a decent shell)

(echo "setwd(somewhere"); cat test.r) | Rterm.exe --args "Arg1"

to make the first R code run change directories.  Or you can have at the 
top of test.r

setwd(Sys.getenv("WD"))

and use 

Rterm.exe WD="c:/data" < test.r --args "Arg1" "Arg2"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pigood at verizon.net  Fri May  7 16:18:36 2004
From: pigood at verizon.net (Phillip Good)
Date: Fri, 7 May 2004 07:18:36 -0700
Subject: [R] How does the lm() function work?
Message-ID: <004801c4343e$3031c000$ade70804@dslverizon.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040507/b9272446/attachment.pl

From JonesW at kssg.com  Fri May  7 16:10:33 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Fri, 7 May 2004 15:10:33 +0100 
Subject: [R] How does the lm() function work?
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02955EEC@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040507/ff9c14a5/attachment.pl

From rpeng at jhsph.edu  Fri May  7 16:28:11 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 07 May 2004 10:28:11 -0400
Subject: [R] How does the lm() function work?
In-Reply-To: <004801c4343e$3031c000$ade70804@dslverizon.net>
References: <004801c4343e$3031c000$ade70804@dslverizon.net>
Message-ID: <409B9CFB.6010902@jhsph.edu>

lm() itself does not implement any model selection procedures.  step() 
and stepAIC() in the MASS library do.

-roger

Phillip Good wrote:
> Does the lm() function use forward, backward, stepwise or some other method of multivariable regression?  Where can I look up the details?
> 
> Phillip Good
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From reid_huntsinger at merck.com  Fri May  7 16:34:20 2004
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri, 7 May 2004 10:34:20 -0400
Subject: [R] generating data
Message-ID: <D9A95B4B7B20354992E165EEADA319990233D128@uswpmx00.merck.com>

Keep in mind that the change of coordinates introduces a distortion; "dxdy"
becomes in polar coordinates "rdrdtheta". So if you wanted a uniform
distribution on the disk you could generate theta uniform on [0,2pi] and r
from a distribution with density f(r)=2r on [0,1]. 

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Lutz Prechelt
Sent: Friday, May 07, 2004 3:43 AM
To: r-help at stat.math.ethz.ch
Subject: RE: [R] generating data


Do you mean random data?
Generate polar coordinates (angle in range 0..2pi, radius in range 0..1)
and convert.

  Lutz

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Fred J.
> Sent: Freitag, 7. Mai 2004 09:14
> To: r help
> Subject: [R] generating data
> 
> 
> Hello
> I am trying to generate data in say 2D "x,y" for a
> circle. grid.circle {grid} does not do. any ides is
> appreciated.
> 
> Thanks
> F.J.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From pigood at verizon.net  Fri May  7 16:40:15 2004
From: pigood at verizon.net (Phillip Good)
Date: Fri, 7 May 2004 07:40:15 -0700
Subject: [R] How does the lm() function work?
References: <004801c4343e$3031c000$ade70804@dslverizon.net>
	<409B9CFB.6010902@jhsph.edu>
Message-ID: <005c01c43441$3659f440$ade70804@dslverizon.net>

Thank you.  I'll install the MASS library.

----- Original Message -----
From: Roger D. Peng <rpeng at jhsph.edu>
To: Phillip Good <pigood at verizon.net>
Cc: <r-help at stat.math.ethz.ch>
Sent: Friday, May 07, 2004 7:28 AM
Subject: Re: [R] How does the lm() function work?


> lm() itself does not implement any model selection procedures.  step()
> and stepAIC() in the MASS library do.
>
> -roger
>
> Phillip Good wrote:
> > Does the lm() function use forward, backward, stepwise or some other
method of multivariable regression?  Where can I look up the details?
> >
> > Phillip Good
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> >



From schnitzlerj at lyon.who.int  Fri May  7 16:51:51 2004
From: schnitzlerj at lyon.who.int (Johannes SCHNITZLER)
Date: Fri, 7 May 2004 16:51:51 +0200
Subject: [R] Rterm
Message-ID: <AD1C47A0C9C12C46987E2D31EE1E63B404030E@lps001.lyon.who.int>

Thank you very much for the fast answers,

It work's very well

Johannes

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: 07 May 2004 16:16
To: Jason Turner
Cc: Johannes SCHNITZLER; r-help at stat.math.ethz.ch
Subject: Re: [R] Rterm

On Sat, 8 May 2004, Jason Turner wrote:

> Johannes SCHNITZLER wrote:
> > The second question:
> > I was trying to set the working directory while I'm calling a script
> > with Rterm.exe from the command line.
> > Something like
> > c:\Program Files\R\rw1090\bin\rterm.exe --vanilla
"workingdir=c:/data/"
> > <test.r --args "Arg1" "Arg2"
> 
> Not sure - if you could pass the working directory as an arg, then R
can 
> handle it from there - use the setwd() command.  What I usually do on 
> Un*x-like systems is to cd to the directory first, then start the R
run. 
>   Something like....
> 
> cd "my favorite dir"
> R --vanilla ...
> 
> Since you're already specifying the absolute path for Rterm, the above

> should work...

That's the only way.  The `working directory' is the directory from
which 
you launch an application (although you can fix that by a shortcut).  R 
looks in the working directory for several things, e.g. a .Rprofile
file, 
before it ever runs any R code like setwd.  If that is not a problem you

can use something like (from a decent shell)

(echo "setwd(somewhere"); cat test.r) | Rterm.exe --args "Arg1"

to make the first R code run change directories.  Or you can have at the

top of test.r

setwd(Sys.getenv("WD"))

and use 

Rterm.exe WD="c:/data" < test.r --args "Arg1" "Arg2"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Fri May  7 17:03:19 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 7 May 2004 11:03:19 -0400
Subject: [R] contrasts in a type III anova
In-Reply-To: <200405071320.15370.David.Jutier@pge.cnrs-gif.fr>
Message-ID: <20040507150319.XID17358.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear David,

The short answer is that in a two-way ANOVA (or an analogous generalized
linear model), the test for the interaction doesn't depend upon the contrast
type, and is identical for "Type-II" and "Type-III" (and, indeed, "Type-I"
-- i.e., sequential) tests. It's the main-effect tests that depend upon
contrast type (for "Type-III" tests), and for which "Type-II" and "Type-III"
tests differ. There's a longer answer in the book with which the car package
is associated (and a longer one still in my Applied Regression text, as well
as other places).

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of David Jutier
> Sent: Friday, May 07, 2004 6:20 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] contrasts in a type III anova
> 
> Hello,
> 
> I use a type III anova ("car" package) to analyse an 
> unbalanced data design. I have two factors and I would have 
> the effect of the interaction. I read that the result could 
> be strongly influenced by the contrasts. I am really not an 
> expert and I am not sure to understand indeed about what it is...
> 
> Consequently, I failed to properly used the fit.contrast 
> function (gregmisc
> package) because I don't understand what the fonction need in 
> the argument "coeff".
> 
> The two factors are Y (Ya, Yb,..., Ye) and Auto (Auto1, 
> Auto2,...., Auto10) The responses are binomial (counts in the 
> matrice "mat") and gaussian (variable "tot"). I use the glm 
> procedure :
> 
> glm1 <- glm (mat ~ y*auto, data, family=binomial)
> glm2 <- glm (tot ~ y*auto, data, family=gaussian)
> 
> Subsequently I use the Type III anova :
> 
> Anova (glm1, type="III")
> Anova (glm2, type="III")
> 
> Using the contrast.treatment for both factors Y and Auto, R 
> gives coherent results, but I really not sure that this 
> contrasts are appropriate !
> 
> Thank's for your advices !
> David
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Fri May  7 17:12:17 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 7 May 2004 17:12:17 +0200
Subject: [R] How does the lm() function work?
In-Reply-To: <005c01c43441$3659f440$ade70804@dslverizon.net>
References: <004801c4343e$3031c000$ade70804@dslverizon.net>
	<409B9CFB.6010902@jhsph.edu>
	<005c01c43441$3659f440$ade70804@dslverizon.net>
Message-ID: <16539.42833.157859.960580@gargle.gargle.HOWL>

>>>>> "Phillip" == Phillip Good <pigood at verizon.net>
>>>>>     on Fri, 7 May 2004 07:40:15 -0700 writes:

    Phillip> Thank you.  I'll install the MASS library.

Two things:

- it's the MASS  >> package <<

- if library(MASS)  does not work for you,
  you have either a very old version of R, or a broken one.
  In both cases, rather re-install R than trying to install
  MASS.

  But I assume you just didn't know that  
  library(MASS)
  would work for you.

Regards,
Martin



From nlwhitehouse at yahoo.com  Fri May  7 17:12:26 2004
From: nlwhitehouse at yahoo.com (Nathan Whitehouse)
Date: Fri, 7 May 2004 08:12:26 -0700 (PDT)
Subject: [R] Re: R web interfaces
In-Reply-To: <C7857A42-A01D-11D8-9722-0050E4C03977@warwick.ac.uk>
Message-ID: <20040507151226.93454.qmail@web12406.mail.yahoo.com>

Hi,
 
> I don't see any replies to this, but it does seem
> quite a good idea, 
> especially as the existing information (eg in the
> FAQ) is rather thin 
> and probably incomprehensible to most.  I have no
> time to do it myself, 
> though.

  Someone in this lab(Andrew Young, Chad Shaw or I)
would be willing to put together a page.  I think it's
a good way to collect a lot of current development.
 
> 
> I look forward to meeting you there.

  I think circumstances will prevent me from going,
which I'm disappointed about.
  
  That said, both the PI of our lab and another guy
will be there(Chad Shaw & Andrew Young).  They will be
very keen to discuss stuff more.
  Best, 
  Nathan 

> Cheers,
> David
> 


=====
Nathan Whitehouse
Statistics/Programming
Baylor College of Medicine
Houston, TX, USA
nlwhitehouse at yahoo.com
work: 1-713-798-9029
cell:    1-512-293-5840

http://rho-project.org: rho- open source web services for R.
http://franklin.imgen.bcm.tmc.edu: Shaw laboratory, bcm.



From maechler at stat.math.ethz.ch  Fri May  7 17:20:28 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 7 May 2004 17:20:28 +0200
Subject: [R] help with histogram
In-Reply-To: <F298786BF61DE64590054AF31EA1B4C8016D1FA5@PEPI.ausl.org>
References: <F298786BF61DE64590054AF31EA1B4C8016D1FA5@PEPI.ausl.org>
Message-ID: <16539.43324.807147.749836@gargle.gargle.HOWL>

>>>>> "Guazzetti" == Guazzetti Stefano <Stefano.Guazzetti at ausl.re.it>
>>>>>     on Fri, 7 May 2004 14:45:22 +0200 writes:

    Guazzetti> Maybe you want something like:

    Guazzetti> x<-rnorm(1000)
    Guazzetti> hist(x, breaks=100,
    Guazzetti>    col=ifelse(abs((hist(x, breaks=100, main=""))$breaks) < 1.669,
    Guazzetti>    4,2))

    Guazzetti> see also the density argument in ?hist

very good!

Even slightly better {not calling  hist() twice} is

 x <- rnorm(1000)
 hx <- hist(x, breaks=100,plot=FALSE)
 plot(hx, col=ifelse(abs(hx$breaks) < 1.669, 4, 2))

Regards, Martin



From nlwhitehouse at yahoo.com  Fri May  7 17:24:14 2004
From: nlwhitehouse at yahoo.com (Nathan Whitehouse)
Date: Fri, 7 May 2004 08:24:14 -0700 (PDT)
Subject: [R] Re: Sessioned R web interfaces
Message-ID: <20040507152414.97946.qmail@web12407.mail.yahoo.com>

Frank,

  Both RZope and Rho solve this problem.  
  
  RZope
(http://www.analytics.washington.edu/statcomp/projects/rzope/)solves
it by using *nix's fork command, which takes as much
time as a memcopy.  
 
  Rho(http://rho-project.org) solves it by maintaining
a pool of idling R processes, which it maintains
active & can pull to do a calculation immediately.

  Both of these are pretty immediate & allow
multistep/session calculations.(As compared to CGI
stuff)

  cheers,
  Nathan

Here's a related question:  Do any of the mentioned
R-web interfaces
(Rweb, R-Online, CGIwithR, RSPerl) support reusing the
same R process,
eliminating the startup overhead?  This would be
useful to me as well.

Currently I use such a method on my computing cluster:
 All 40 
compute nodes run an R process/compute server that
listens at a socket 
for
any 
connection and subsequent commands from another
computer. 
When the master process disconnects, the R processes
go back to 
listening
at the socket.  Connecting to the R compute servers
this way
takes < 2 milliseconds rather than the typical ~2
second R startup 
time.

Thanks for any tips.

-Frank

=====
Nathan Whitehouse
Statistics/Programming
Baylor College of Medicine
Houston, TX, USA
nlwhitehouse at yahoo.com
work: 1-713-798-9029
cell:    1-512-293-5840

http://rho-project.org: rho- open source web services for R.
http://franklin.imgen.bcm.tmc.edu: Shaw laboratory, bcm.



From clayton.springer at pharma.novartis.com  Fri May  7 17:26:04 2004
From: clayton.springer at pharma.novartis.com (clayton.springer@pharma.novartis.com)
Date: Fri, 7 May 2004 11:26:04 -0400
Subject: [R] randomForests and Y-scrambling on a small synthetic dataset
Message-ID: <OFAD8068AD.FEBBB0E6-ON85256E8D.004DC559-85256E8D.00547806@EU.novartis.net>

Dear r-help,


The following dataset (generated with perl) has 10 observations of 100 
dependant variables (integers drawn uniformly
from [1:9]) which is split evenly between two classes..

First I show some work, and then ask two questions at the end.

> data <- read.table ("rf_input.dat")
> library (randomForest)
# if we do randomForest one time it looks like this:

> rf <- randomForest (factor(V101) ~. ,data=data)
> rf$confusion
  1 2 class.error
1 5 5         0.5
2 4 6         0.4

# now we do it 100 times 

> 
tnum <- numeric()

for (i in 1:100) { MT <- data$V101
   MT.rf <- randomForest (factor(MT) ~ . ,data =data[-c(101)])
   number <- as.integer (summary ( predict(MT.rf) == MT)[3]     )
   tnum <- c(tnum,number)
}

> > > > + + + + + + + > 

# and this distribution of results (about 13 correct out of 20) 
>  quantile (tnum,probs = seq (0,1,0.1),na.rm = T)
  0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% 
   9   11   12   12   13   13   13   14   14   15   17 

# now lets permute (re-randomize?) the classes and repeat 1000 times: 

> library (gregmisc)
tnum <- numeric()

for (i in 1:1000) { MT <- permute (data$V101)
   MT.rf <- randomForest (factor(MT) ~ . ,data =data[-c(101)])
   number <- as.integer (summary ( predict(MT.rf) == MT)[3]     )
   tnum <- c(tnum,number)
}

# I get these results: the average is about 8 correct (out of 20) with 13 
correct being at about
# the 95% confidence level

> quantile (tnum,probs = seq (0,1,0.1),na.rm = T)
  0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% 
   1    4    5    6    7    8    8    9   10   12   18 
>  quantile (tnum,probs = seq (0.9,1,0.01),na.rm = T)
 90%  91%  92%  93%  94%  95%  96%  97%  98%  99% 100% 
  12   12   12   12   12   13   13   14   14   15   18 

--------

My two questions:

Question 1: Naively I might have expected to get 10/20 for the Y-scrambled 
examples, but instead I got 8/20.  Why is that?
(Persumably has something to do with the randomForest only training on 2/3 
of the examples.)

Question 2: With my Y scrambling exercise I seem to have demonstrated that 
the original dataset was not random. But yet it
is random by construction. Is this just a fluke, or is something wrong 
with my protocol?

thanks in advance,

Clayton

From j.hall at beatson.gla.ac.uk  Fri May  7 17:25:11 2004
From: j.hall at beatson.gla.ac.uk (Jacqueline Hall)
Date: Fri, 7 May 2004 16:25:11 +0100
Subject: [R] scores from multinomial logistic regression
In-Reply-To: <Pine.LNX.4.44.0405071502220.25954-100000@gannet.stats>
Message-ID: <000301c43447$7ca72e30$62e8d182@o1jh>

Hi,

Sorry for not making this clear,

By "score" I meant the score from the score test, for assessing the addition
of a new variable to the model. (first derivative of the log likeihood/
information matrix, the ratio (score)having a chi squared distribution of
appropriate df)

I'm looking for something similar/appropraite for logistic regression, my
outcome (response) variable has 4 categories (hence the interest in
multinom), the covariates are continuous.

Thanks again,

Jacqui

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: 07 May 2004 15:07
To: Jacqueline Hall
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] scores from multinomial logistic regression


What do you mean by the scores?

What multinom does is to fit probabilities (which you can extract by 
fitted()): the response is a discrete probability distribution. There is an
underlying linear predictor but

(a) it is K-dimensional and
(b) there is a degree of ambiguity, usually resolved by setting the 
predictor for one category to zero (but not in this code).

That linear predictor is only generated in the underlying C code.

On Fri, 7 May 2004, Jacqueline Hall wrote:

> Dear all,
>  
> I'm interested in extracting the score from multinomial logistic 
> regression models fit using multinom, to assess the stregth of 
> assocation of the parameter with the response (akin to the score from 
> clogit/cox regression). currently I'm using R 1.8.1. Is there a 
> function that will extract the score from a multinom object or how i 
> can get back to it? or from using glm? I investigated the documention 
> for Design but those functions seem to apply to binary logistic.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri May  7 17:39:09 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 May 2004 16:39:09 +0100 (BST)
Subject: [R] scores from multinomial logistic regression
In-Reply-To: <000301c43447$7ca72e30$62e8d182@o1jh>
Message-ID: <Pine.LNX.4.44.0405071629480.7999-100000@gannet.stats>

Note the coxph docs call these `efficient scores', which helps. However,
what the `score' part of a coxph object gives is not the score for the
addition of a new variable, but for the addition of all the variables, as
I understand it. (You could do repeated fits using init=, but that's not
what you said.)

I am not aware of a good way to do that even for a glm. (Smart people
could make add1.lm do it, I guess.) I would just do likelihood ratio tests
since computation time is unlikely to be an issue these days.


On Fri, 7 May 2004, Jacqueline Hall wrote:

> Hi,
> 
> Sorry for not making this clear,
> 
> By "score" I meant the score from the score test, for assessing the addition
> of a new variable to the model. (first derivative of the log likeihood/
> information matrix, the ratio (score)having a chi squared distribution of
> appropriate df)
> 
> I'm looking for something similar/appropraite for logistic regression, my
> outcome (response) variable has 4 categories (hence the interest in
> multinom), the covariates are continuous.
> 
> Thanks again,
> 
> Jacqui
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: 07 May 2004 15:07
> To: Jacqueline Hall
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] scores from multinomial logistic regression
> 
> 
> What do you mean by the scores?
> 
> What multinom does is to fit probabilities (which you can extract by 
> fitted()): the response is a discrete probability distribution. There is an
> underlying linear predictor but
> 
> (a) it is K-dimensional and
> (b) there is a degree of ambiguity, usually resolved by setting the 
> predictor for one category to zero (but not in this code).
> 
> That linear predictor is only generated in the underlying C code.
> 
> On Fri, 7 May 2004, Jacqueline Hall wrote:
> 
> > Dear all,
> >  
> > I'm interested in extracting the score from multinomial logistic 
> > regression models fit using multinom, to assess the stregth of 
> > assocation of the parameter with the response (akin to the score from 
> > clogit/cox regression). currently I'm using R 1.8.1. Is there a 
> > function that will extract the score from a multinom object or how i 
> > can get back to it? or from using glm? I investigated the documention 
> > for Design but those functions seem to apply to binary logistic.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri May  7 17:49:30 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 May 2004 16:49:30 +0100 (BST)
Subject: [R] Font and Color documentation
In-Reply-To: <90821ABF429A074DA88E56D1DF7A71610130CA2A@afifs1.affinnova.com>
Message-ID: <Pine.LNX.4.44.0405071640140.7999-100000@gannet.stats>

This is R-specific, and R was but a glimmer of the eye when MASS (1st ed) 
was written in 1992/3.  pp. 79-84 of the current edition does have the 
information.

I think all the information you ask for is in ?par, or that points to the 
appropriate place.

Fonts are device specific.  ?par says

     'font' An integer which specifies which font to use for text.  If
          possible, device drivers arrange so that 1 corresponds to
          plain text, 2 to bold face, 3 to italic and 4 to bold italic.

and BTW, font 5 is always a symbol font.  To go beyond that you need to 
look at the documentation of the device you use.  Many devices (e.g. x11, 
windows, postscript, pdf) allow you to map fonts to those numbers.

There is a whole section on `Color Specification' in ?par, which says 
colors() gives all the known colour names, and valid numbers are from 0 to 
the size of the palette.


On Fri, 7 May 2004, Iyue Sung wrote:

>   Could someone please point me to documentation on legal font and color
> specifications (and other 'par' parameters); i.e. font=6 for Times New
> Roman, col='Red', etc.?  Searches in "?par", MASS (1st ed.) and other
> areas were unsuccessful. I thought I remember seeing it
> before...somewhere.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From zefern2000 at yahoo.com.br  Fri May  7 18:10:18 2004
From: zefern2000 at yahoo.com.br (=?iso-8859-1?q?Jos=E9=20Fernando=20Silva?=)
Date: Fri, 7 May 2004 13:10:18 -0300 (ART)
Subject: [R] Quantile of a function
Message-ID: <20040507161018.85698.qmail@web50004.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040507/d40c0b7a/attachment.pl

From ligges at statistik.uni-dortmund.de  Fri May  7 18:13:41 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 07 May 2004 18:13:41 +0200
Subject: [R] Start problem
In-Reply-To: <000801c4342d$ec3d75c0$bd00a8c0@skogforsk.no>
References: <000801c4342d$ec3d75c0$bd00a8c0@skogforsk.no>
Message-ID: <409BB5B5.3010801@statistik.uni-dortmund.de>

Bj??rn ??kland wrote:

> I had a well-working R 1.7, however, today the programme did not start, and I recieved an error message.
> I have uninstalled the R 1.7, and then installed R 1.9.
> Still it does not start, giving the error message "Fatal error: invalid HOMEDRIVE".
> How can I get it to work?
> 
> Bjorn Okland
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Either try out r-patched or look in the R-help archives for the string 
"Fatal error: invalid HOMEDRIVE". There were several discussions (and 
hints for a workaround) about that bug introduced by Microsoft's 
security patch.

Uwe Ligges



From carolin.strobl at gmx.de  Fri May  7 18:14:44 2004
From: carolin.strobl at gmx.de (Carolin Strobl)
Date: Fri, 7 May 2004 18:14:44 +0200 (MEST)
Subject: [R] rpart for CART with weights/priors
Message-ID: <9623.1083946484@www24.gmx.net>

Hi,
I have a technical question about rpart:
according to Breiman et al. 1984, different costs for misclassification in
CART can be modelled 
either by means of modifying the loss matrix or by means of using different
prior probabilities for the classes, 
which again should have the same effect as using different weights for the
response classes.

What I tried was this:

library(rpart)
data(kyphosis)

#fit1 from original unweighted data set
fit1 <- rpart(Kyphosis ~ Age + Number + Start, data=kyphosis)

#modify loss matrix
loss<-matrix(c(0,1,2,0),nrow=2,ncol=2)

#   true class?
#    [,1] [,2]
#[1,]    0    2 
#[2,]    1    0 predicted class?


#modify priors
prior=c(1/3,2/3)

fit2<- rpart(Kyphosis ~ Age + Number + Start, data=kyphosis,
parms=list(loss=loss))
fit3 <- rpart(Kyphosis ~ Age + Number + Start, data=kyphosis,
parms=list(prior=prior))

fit2
fit3

par(mfrow=c(2,1))
plot(fit2)
text(fit2,use.n=T)
plot(fit3)
text(fit3,use.n=T)

#lead to similar but not identical trees (similar topology but different
cutoff points), 
#while all other combinations (even complete reversion, i.e. preference for
the other class) 
#lead to totally different trees...

#third approach using weights:
#sorting of data to design weight vector
ind<-order(kyphosis[,1])
kyphosis1<-kyphosis[ind,]

summary(kyphosis1[,1])
weight<-c(rep(1,64),rep(2,17))
summary(as.factor(weight))

fit4 <- rpart(Kyphosis ~ Age + Number + Start, data=kyphosis1,
weights=weight)

#leads to result very similar to fit2 with
loss<-matrix(c(0,1,2,0),nrow=2,ncol=2)
#(same tree and cutoff points, but slightly different probabilities, maybe
numerical artefact?)

fit4
plot(fit4)
text(fit4,use.n=T)

#doule check with inverse loss matrix

loss<-matrix(c(0,1,2,0),nrow=2,ncol=2,byrow=T)
fit2<- rpart(Kyphosis ~ Age + Number + Start, data=kyphosis,
parms=list(loss=loss))

weight<-c(rep(2,64),rep(1,17))
fit4 <- rpart(Kyphosis ~ Age + Number + Start, data=kyphosis1,
weights=weight)

fit2
fit4
#also same except for probabilities yprob

I don't see 
1. why the approach using prior probabilities doesn't work
2. what causes the differences in predicted probabilities in the weights
approach

Any idea? Thank You! C.

--



From ligges at statistik.uni-dortmund.de  Fri May  7 18:29:24 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 07 May 2004 18:29:24 +0200
Subject: [R] Quantile of a function
In-Reply-To: <20040507161018.85698.qmail@web50004.mail.yahoo.com>
References: <20040507161018.85698.qmail@web50004.mail.yahoo.com>
Message-ID: <409BB964.5070207@statistik.uni-dortmund.de>

Jos?? Fernando Silva wrote:

> I have a simple doubt:
> I have a function, say:
>  
> test <- function (theta) {
> return (theta^2) }
>  
> I can use:
> integrate (test,0,1)
> to obtain the area under de function.
> Can I do the opposite? I`d like to give the lower limit and the area I need as arguments, in order to get the upper limit. In other words, I`d like to obtain the quantile of the function (the lower limit could be 0, for example).
> Thank you in advance.
>  

If you really want to do it numerically (assuming your function is much 
more complex and the exmaple one), try e.g.


solveit <- function (quant, foo, lw, area) {
    (integrate(foo, lw, quant)$value - area)^2
}
optimize(solveit, c(0, 100),
     foo = function(theta) theta^2, lw = 0, area = 0.95)


Uwe Ligges




> 
> 
> ---------------------------------
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From informatics at myhelios.net  Fri May  7 18:29:32 2004
From: informatics at myhelios.net (David L. Van Brunt, Ph.D.)
Date: Fri, 07 May 2004 11:29:32 -0500
Subject: [R] " cannot allocate vector of length 1072693248"
In-Reply-To: <20040412181107.GA29339@alphan.cse.psu.edu>
Message-ID: <BCC1239C.8ACC%informatics@myhelios.net>

Well, I've done everything I can think of the make the code more efficient,
but it seems (if I read this error message correctly) that I'm running out
of memory on what should be small data set.

Here's the sequence:

A vector of 30 possible identifiers
For each value, query a MySQL database to pull in 80 or so records
Run a few different random Forests on those data
Print the results as I go
"rm()" all the objects created in the loop, including all the old data
Next value, to repeat for each identifier.


Round the 3rd time through the loop, I get kicked out with:

"Error in as.vector(data) : cannot allocate vector of length 1072693248"

This is on Mac OS X, which is UNIX-based (from freeBSD, as I understand it),
so I haven't set anything special with the memory at startup. But then, I
only have 80 observations running through at a time, so it doesn't seem like
there should be a memory issue.

Any ideas?



From ripley at stats.ox.ac.uk  Fri May  7 18:42:50 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 May 2004 17:42:50 +0100 (BST)
Subject: [R] " cannot allocate vector of length 1072693248"
In-Reply-To: <BCC1239C.8ACC%informatics@myhelios.net>
Message-ID: <Pine.LNX.4.44.0405071739090.11307-100000@gannet.stats>

I think it is more likely that you have a bug.  Probably you have run out 
of address space, as that's almost 4Gb if an integer and 8Gb if real.

Can you do options(error=dump.frames) and debugger() after the error 
message and try to find out what `data' is and what size it is.

On Fri, 7 May 2004, David L. Van Brunt, Ph.D. wrote:

> Well, I've done everything I can think of the make the code more efficient,
> but it seems (if I read this error message correctly) that I'm running out
> of memory on what should be small data set.
> 
> Here's the sequence:
> 
> A vector of 30 possible identifiers
> For each value, query a MySQL database to pull in 80 or so records
> Run a few different random Forests on those data
> Print the results as I go
> "rm()" all the objects created in the loop, including all the old data
> Next value, to repeat for each identifier.
> 
> 
> Round the 3rd time through the loop, I get kicked out with:
> 
> "Error in as.vector(data) : cannot allocate vector of length 1072693248"
> 
> This is on Mac OS X, which is UNIX-based (from freeBSD, as I understand it),
> so I haven't set anything special with the memory at startup. But then, I
> only have 80 observations running through at a time, so it doesn't seem like
> there should be a memory issue.
> 
> Any ideas?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wwsprague at ucdavis.edu  Fri May  7 18:50:21 2004
From: wwsprague at ucdavis.edu (wwsprague@ucdavis.edu)
Date: Fri, 07 May 2004 09:50:21 -0700
Subject: [R] cgi/servlets/httpd  in R
In-Reply-To: <644D9337A02FC24689647BF9E48EC39E08ABB7E6@drm556>
References: <644D9337A02FC24689647BF9E48EC39E08ABB7E6@drm556>
Message-ID: <409BBE4D.7090308@ucdavis.edu>

Samuelson, Frank* wrote:


> Currently I use such a method on my computing cluster:  All 40 
> compute nodes run an R process/compute server that listens at a socket for
> any 
> connection and subsequent commands from another computer. 
> When the master process disconnects, the R processes go back to listening
> at the socket.  Connecting to the R compute servers this way
> takes < 2 milliseconds rather than the typical ~2 second R startup time.

Your solution seems what I am looking for, actually.  Questions:

1.  How do you communicate with an R process?  I can only think of 
embedded code like SQL in Perl.

2.  How do you find an R node that is open?

2.5  You are haveing cgi scripts connect to the R processes, right?  Or 
are the R processes available for another purpose?

3.  How much of your code are you willing to share :)?  We are 
interested in making demographic analysis tools available online 
(life-table-ish stuff to start with, then as much as we can get grant 
money for).

W



From dvanbrunt at well-wired.com  Fri May  7 18:53:45 2004
From: dvanbrunt at well-wired.com (David L. Van Brunt, Ph.D.)
Date: Fri, 07 May 2004 11:53:45 -0500
Subject: [R] " cannot allocate vector of length 1072693248"
In-Reply-To: <Pine.LNX.4.44.0405071739090.11307-100000@gannet.stats>
Message-ID: <BCC12949.8AD3%dvanbrunt@well-wired.com>

Thanks for the suggestion. If there's a bug in my code, I can't find it.

The code runs successfully several times through. And I have only a few
lines, but repeated in blocks with a few tweaks to make different
predictions each time.

If I comment out a line that preceeds a crash, it will run a little longer
before giving up next time. So it is as if something is slowly filling up
through each run, and is accumulating.

But I do "rm()" all the objects created inside of the "for" loop, and then
gc() before the loop is finished, also.

So I'm stumped.

When I called the debugger, the last item shown was the vector line, so I
chose that option and typed "ls()"... It had only "mode" and "x". The value
of "mode" was "any", and when I tried to display "x", I expected a slew of
data but instead R crashed.

Don't know if that's informative or not!

On 5/7/04 11:42, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

> I think it is more likely that you have a bug.  Probably you have run out
> of address space, as that's almost 4Gb if an integer and 8Gb if real.
> 
> Can you do options(error=dump.frames) and debugger() after the error
> message and try to find out what `data' is and what size it is.
> 
> On Fri, 7 May 2004, David L. Van Brunt, Ph.D. wrote:
> 
>> Well, I've done everything I can think of the make the code more efficient,
>> but it seems (if I read this error message correctly) that I'm running out
>> of memory on what should be small data set.
>> 
>> Here's the sequence:
>> 
>> A vector of 30 possible identifiers
>> For each value, query a MySQL database to pull in 80 or so records
>> Run a few different random Forests on those data
>> Print the results as I go
>> "rm()" all the objects created in the loop, including all the old data
>> Next value, to repeat for each identifier.
>> 
>> 
>> Round the 3rd time through the loop, I get kicked out with:
>> 
>> "Error in as.vector(data) : cannot allocate vector of length 1072693248"
>> 
>> This is on Mac OS X, which is UNIX-based (from freeBSD, as I understand it),
>> so I haven't set anything special with the memory at startup. But then, I
>> only have 80 observations running through at a time, so it doesn't seem like
>> there should be a memory issue.
>> 
>> Any ideas?
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>> 
>> 

-- 
David L. Van Brunt, Ph.D.
Outlier Consulting & Development
mailto: <ocd at well-wired.com>



From mail at joeconway.com  Fri May  7 19:53:07 2004
From: mail at joeconway.com (Joe Conway)
Date: Fri, 07 May 2004 10:53:07 -0700
Subject: [R] cgi/servlets/httpd  in R
In-Reply-To: <409BBE4D.7090308@ucdavis.edu>
References: <644D9337A02FC24689647BF9E48EC39E08ABB7E6@drm556>
	<409BBE4D.7090308@ucdavis.edu>
Message-ID: <409BCD03.6000707@joeconway.com>

wwsprague at ucdavis.edu wrote:
> Your solution seems what I am looking for, actually.  Questions:

FWIW, another possible option if your data is stored in an RDBMS is 
Postgres with PL/R; see:
   http://www.joeconway.com/plr/

As of Postgres 7.4 you can preload and initialize libraries at 
postmaster start, which means that each forked database backend includes 
a fully initialized copy of libR.

If you are interested, there is some information available regarding how 
to use this with PHP to generate online charts here:
http://www.joeconway.com/oscon-pres-2003-1.pdf

HTH,

Joe



From sdavis2 at mail.nih.gov  Tue May  4 04:36:43 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 3 May 2004 22:36:43 -0400
Subject: [R] I have some problem about "save and open"
References: <22380.203.144.212.245.1083637953.squirrel@www.gaccl.com>
Message-ID: <000001c4345e$9ca907f0$04653744@WATSON>

If you want to save the workspace to a file, type:

save.image("filename")

To load the file, type:

load("filename")

The save that you do when you exit R saves by default to a (typically)
hidden file called ".Rdata".  If you start R in a directory with a ".Rdata"
file in it, R will load that file automatically.

Sean
----- Original Message -----
From: <mathinee at gaccl.com>
To: <R-help at stat.math.ethz.ch>
Sent: Monday, May 03, 2004 10:32 PM
Subject: [R] I have some problem about "save and open"


> Hello R-help
>
> I use R program on linux.
> and when I would like to quick R, then I type q()
> after than has question "Save workspace image? [y/n/c]:"
> when I ans "y" , why not to ask about name of file.
> and when I would like to open last file , how can I do?
> thanks for your help.
> and sorry if my English not so good. I'm Thai people and I know
> English a little.
> Mathinee
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From vograno at evafunds.com  Fri May  7 21:40:09 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Fri, 7 May 2004 12:40:09 -0700
Subject: [R] dump.frames in non-interactive mode
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B32E6@phost015.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040507/0f09f8e5/attachment.pl

From ripley at stats.ox.ac.uk  Fri May  7 22:19:51 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 May 2004 21:19:51 +0100 (BST)
Subject: [R] dump.frames in non-interactive mode
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A54B32E6@phost015.intermedia.net>
Message-ID: <Pine.LNX.4.44.0405072109260.9566-100000@gannet.stats>

On Fri, 7 May 2004, Vadim Ogranovich wrote:

> recover() resorts to dump.frames() when called in non-interactive
> sessions. However dump.frames() still puts the dump into last.dump
> object and not into a file, which brings the question of how to get hold
> of the object once the session terminates.

This is discussed in the help file for dump.frames ...

     If 'dump.frames' is installed as the error handler, execution will
     continue even in non-interactive sessions. See the examples for
     how to dump and then quit.

> I guess the supposed answer is that last.dump is saved in .Rdata once R
> exits. However I find it more convenient on day-to-day basis to use
> --no-save --no-restore options and avoid .Rdata. So my question is how
> to best set a hook, in say .Rprofile, so that in non-interactive mode
> (and only in it) last.dump (and only it) will be saved in a file upon
> exit from R.

dump.frames has parameters to do exactly this.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From GPetris at uark.edu  Fri May  7 22:25:40 2004
From: GPetris at uark.edu (Giovanni Petris)
Date: Fri, 7 May 2004 15:25:40 -0500 (CDT)
Subject: [R] generating data
In-Reply-To: <20040507071347.59537.qmail@web20503.mail.yahoo.com>
	(phddas@yahoo.com)
References: <20040507071347.59537.qmail@web20503.mail.yahoo.com>
Message-ID: <200405072025.i47KPeAZ001412@definetti.uark.edu>


> Hello
> I am trying to generate data in say 2D "x,y" for a
> circle.        ^^^^^^^^

I think data are usually collected...

GP

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From richard.kittler at amd.com  Fri May  7 22:47:40 2004
From: richard.kittler at amd.com (richard.kittler@amd.com)
Date: Fri, 7 May 2004 13:47:40 -0700
Subject: [R] Lattice xyplot - problem trying to produce multiple output
 files with a 'for' loop
Message-ID: <858788618A93D111B45900805F85267A0BCB2C19@caexmta3.amd.com>

I am stuck on trying to get the Lattice xyplot to output a separate PNG file each time through my 'for' loop.  The files get produced but are empty.

Here is the code.  I'm running 1.9 on Windows.  BTW is there a more efficient way of creating the separate output files than looping over the levels and subsetting? 

.........................................................
lev <- levels(ds$TR)

for (byvar in lev) {

 file.png <- paste("u:/data/R/Scatter_CTY_HWY_CO_TR", byvar,  ".png", sep="")

 trellis.device( device="png", file=file.png, 
     width=1000, height=1000, pointsize=20, bg="transparent" )

 ds1 <- subset(ds, TR == byvar, select=c(CTY, HWY, CO))

 xyplot( ds1$CTY ~ ds1$HWY, groups=ds1$CO,
    auto.key=list(space="right"), ylab="CTY", xlab="HWY")

 dev.off()

}
.........................................................

--Rich

Richard Kittler 
AMD TDG
408-749-4099



From sundar.dorai-raj at PDF.COM  Fri May  7 22:56:37 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 07 May 2004 13:56:37 -0700
Subject: [R] Lattice xyplot - problem trying to produce multiple output
	files with a 'for' loop
In-Reply-To: <858788618A93D111B45900805F85267A0BCB2C19@caexmta3.amd.com>
References: <858788618A93D111B45900805F85267A0BCB2C19@caexmta3.amd.com>
Message-ID: <409BF805.8000708@pdf.com>



richard.kittler at amd.com wrote:

> I am stuck on trying to get the Lattice xyplot to output a separate PNG file each time through my 'for' loop.  The files get produced but are empty.
> 
> Here is the code.  I'm running 1.9 on Windows.  BTW is there a more efficient way of creating the separate output files than looping over the levels and subsetting? 
> 
> .........................................................
> lev <- levels(ds$TR)
> 
> for (byvar in lev) {
> 
>  file.png <- paste("u:/data/R/Scatter_CTY_HWY_CO_TR", byvar,  ".png", sep="")
> 
>  trellis.device( device="png", file=file.png, 
>      width=1000, height=1000, pointsize=20, bg="transparent" )
> 
>  ds1 <- subset(ds, TR == byvar, select=c(CTY, HWY, CO))
> 
>  xyplot( ds1$CTY ~ ds1$HWY, groups=ds1$CO,
>     auto.key=list(space="right"), ylab="CTY", xlab="HWY")
> 
>  dev.off()
> 
> }
> .........................................................
> 
> --Rich
> 
> Richard Kittler 
> AMD TDG
> 408-749-4099
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

See the FAQ.

you have to wrap the xyplot call with a print. I.e.

for(...) {
   ...
   print(xyplot(...))
   ...
}



From jstimson at email.unc.edu  Fri May  7 23:07:24 2004
From: jstimson at email.unc.edu (Jim Stimson)
Date: Fri, 07 May 2004 17:07:24 -0400
Subject: [R] Invalid HOMEDRIVE
Message-ID: <409BFA8C.4000501@email.unc.edu>

Attempting to install the most recent R on a Windows/XP machine, I get 
what appears to be a normal (completely default) installation. Then when 
I attempt to load rgui I get the fatal error message: Invalid HOMEDRIVE. 
Any explanation of the error or suggestions of fixes to files or 
registry would be appreciated.

-- 
Jim Stimson
Email: <jstimson at email.unc.edu>
Web: http://www.unc.edu/~jstimson
Phone: (919) 962-0428  Fax: (919) 962-0432  Home: (919) 968-0942
Department of Political Science
University of North Carolina at Chapel Hill
Chapel Hill, NC 27599-3265



From wwsprague at ucdavis.edu  Fri May  7 23:07:57 2004
From: wwsprague at ucdavis.edu (wwsprague@ucdavis.edu)
Date: Fri, 07 May 2004 14:07:57 -0700
Subject: [R] plotting planes and lines in wireframe()
Message-ID: <c7gtre$s55$1@sea.gmane.org>

Hi R-helpers

I would like to plot some planes which are perpendicular to the x-y 
plane, such as x=y.  Is there a way to do this in wireframe?  I realize 
that I am not plotting a function of x, y since there are infinite 
number of z's that satisfy the above relation....  Hmm...

Somewhat related, I would also like to plot a line in 3 d space...

Finally, if you are feeling really brave, I am interested in doing all 
of this based on sums generating vectors (I know there is a linear 
algebra term for this) -- ie generate the plane based on c_1*v_1 + 
c_2*v_2 for c_1 and c_2 in reals.

Thanks again to all you helpful folks!
W



From mark.threefoot at amd.com  Fri May  7 23:12:12 2004
From: mark.threefoot at amd.com (mark.threefoot@amd.com)
Date: Fri, 7 May 2004 14:12:12 -0700
Subject: [R] Error compiling ROracle on Windows 2000
Message-ID: <A6D472EC410FF84E8BE573FD654BAC4339808B@CAEXMTA9>


Hello,

I am trying to compile ROracle _0.5-4 under R 1.9.0 without much success.  I am running Windows 2000 SP4, Visual C++ 6.0 SP6, and Oracle client 9.2.0.1.0.  I was able to run the pre-compiled version of ROracle_0.5-2 under R 1.7.1, but does not work on R 1.8.1 or R 1.9.0.  Here is the output from nmake:

C:\Program Files\R\rw1090\library\ROracle\src>nmake

Microsoft (R) Program Maintenance Utility   Version 6.00.9782.0
Copyright (C) Microsoft Corp 1988-1998. All rights reserved.

        cl /I"C:\\Program Files\\R\\rw1090"\\src\\include /MT /Ox /D "MSVC" /D "
WIN32" /c RS-DBI.c
Microsoft (R) 32-bit C/C++ Optimizing Compiler Version 12.00.8804 for 80x86
Copyright (C) Microsoft Corp 1984-1998. All rights reserved.

RS-DBI.c
        cl /I"C:\\Program Files\\R\\rw1090"\\src\\include /MT /Ox /D "MSVC" /D "
WIN32" /c RS-Oracle.c
Microsoft (R) 32-bit C/C++ Optimizing Compiler Version 12.00.8804 for 80x86
Copyright (C) Microsoft Corp 1984-1998. All rights reserved.

RS-Oracle.c
NMAKE : fatal error U1073: don't know how to make '\src\\gnuwin32\\Rdll.lib'
Stop.

Here is a copy of my Makefile:

R_HOME = "C:\\Program Files\\R\\rw1090"
ORACLE_HOME = C:\\oracle\\oracle92
SRC  = RS-DBI.h RS-DBI.c RS-Oracle.h RS-Oracle.pc S4R.h
RLIB = $(R_HOME)\\src\\gnuwin32\\Rdll.lib
OBJ  = RS-DBI.obj RS-Oracle.obj 

##
## The Oracle ProC/C++ precompiler and options we need (these have worked
## on Linux, Solaris, and Windows 2000).
##

PROC=proc              ## this is the ProC/C++ executable
CODE=ANSI_C            ## the following are ProC/C++ options
MODE=ORACLE
PARSE=NONE             ## don't do any C parse
LINES=false            ## use true for debugging

ROracle.dll:  $(OBJ) $(RLIB)
	(cd $(R_HOME)\\src\\gnuwin32 && lib /def:R.exp /out:Rdll.lib)
	link /dll /def:ROracle.def /out:ROracle.dll $(ORACLE_HOME)\\precomp\\lib\\orasql9.lib *.obj $(R_HOME)\\src\\gnuwin32\\Rdll.lib 
	
RS-DBI.obj: RS-DBI.h RS-DBI.c S4R.h
	cl /I$(R_HOME)\\src\\include /MT /Ox /D "MSVC" /D "WIN32" /c RS-DBI.c

RS-Oracle.obj: RS-Oracle.h RS-Oracle.c S4R.h
	cl /I$(R_HOME)\\src\\include /MT /Ox /D "MSVC" /D "WIN32" /c RS-Oracle.c

RS-Oracle.c: RS-Oracle.h RS-Oracle.pc 
	$(PROC) CODE=$(CODE) MODE=$(MODE) INCLUDE=$(R_HOME)/include \
                PARSE=$(PARSE) LINES=$(LINES) RS-Oracle.pc
force-Rdll.lib:
	(cd $(R_HOME)\\src\\gnuwin32 && lib /def:R.exp /out:Rdll.lib)
clean:
	rm -f $(OBJ) *.a *.d *.rc 
clobber:
	rm -f $(RLIB) $(OBJ) RS-Oracle.c *.a *.d *.rc *.dll 

Thanks for your help,
Mark



From andy_liaw at merck.com  Fri May  7 23:15:44 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 7 May 2004 17:15:44 -0400
Subject: [R] re-ordering a vector by name
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D48@usrymx25.merck.com>

Dear R-help,

Let's say `x1' and `x2' are very long vectors (length=5e5, say) with same
set of names but in different order.  If I want to sort `x2' in the order of
`x1', I would do 

  x2[names(x1)]

but the amount of time that takes is quite prohibitive!  Does anyone have
any suggestion on a more efficient way to do this?

If the two vectors are exactly the same length (as I said above), sorting
both by names would probably be the fastest.  However, if the two vectors
differ in length (and the names for the shorter one are a subset of names of
the longer one) then that doesn't work...

Best,
Andy



From reid_huntsinger at merck.com  Fri May  7 23:30:59 2004
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri, 7 May 2004 17:30:59 -0400
Subject: [R] re-ordering a vector by name
Message-ID: <D9A95B4B7B20354992E165EEADA319990233D130@uswpmx00.merck.com>

I suspect three causes for slowness:

1) possibly names are lot of overhead (string compares, lookup, etc).
2) maybe it's just memory, in which case you could loop over chunks of the
names(x1) vector
3) you're basically asking for the permutation taking names(x2) into
names(x1) and then applying it to x2. The first step is a sort but perhaps
the indexing code doesn't optimize that.

Reid Huntsinger
-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
Sent: Friday, May 07, 2004 5:16 PM
To: r-help at stat.math.ethz.ch
Subject: [R] re-ordering a vector by name


Dear R-help,

Let's say `x1' and `x2' are very long vectors (length=5e5, say) with same
set of names but in different order.  If I want to sort `x2' in the order of
`x1', I would do 

  x2[names(x1)]

but the amount of time that takes is quite prohibitive!  Does anyone have
any suggestion on a more efficient way to do this?

If the two vectors are exactly the same length (as I said above), sorting
both by names would probably be the fastest.  However, if the two vectors
differ in length (and the names for the shorter one are a subset of names of
the longer one) then that doesn't work...

Best,
Andy

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

----------------------------------------------------------------------------
--
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From rossini at blindglobe.net  Fri May  7 23:42:53 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 07 May 2004 14:42:53 -0700
Subject: [R] cgi/servlets/httpd  in R
In-Reply-To: <644D9337A02FC24689647BF9E48EC39E08ABB7E6@drm556> (Frank
	Samuelson's message of "Thu, 6 May 2004 11:01:25 -0400")
References: <644D9337A02FC24689647BF9E48EC39E08ABB7E6@drm556>
Message-ID: <85k6zn52xu.fsf@servant.blindglobe.net>

"Samuelson, Frank*" <FWS4 at CDRH.FDA.GOV> writes:

> Here's a related question:  Do any of the mentioned R-web interfaces
> (Rweb, R-Online, CGIwithR, RSPerl) support reusing the same R process,
> eliminating the startup overhead?  This would be useful to me as well.

Greg Warnes' RSOAP allows you to pre-start a pool of processes to
eliminate this under light/moderate load.

It's on my lab group's WWW page.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From jasont at indigoindustrial.co.nz  Fri May  7 23:47:35 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sat, 08 May 2004 09:47:35 +1200
Subject: [R] Invalid HOMEDRIVE
In-Reply-To: <409BFA8C.4000501@email.unc.edu>
References: <409BFA8C.4000501@email.unc.edu>
Message-ID: <409C03F7.6050101@indigoindustrial.co.nz>

Jim Stimson wrote:
> Attempting to install the most recent R on a Windows/XP machine, I get 
> what appears to be a normal (completely default) installation. Then when 
> I attempt to load rgui I get the fatal error message: Invalid HOMEDRIVE. 
> Any explanation of the error or suggestions of fixes to files or 
> registry would be appreciated.
> 

1) Follow the instructions in the posting guide, which asks you to 
search the archives before posting (saves us both time).

2) From there, you'll find
https://www.stat.math.ethz.ch/pipermail/r-help/2004-April/048397.html

Short answer - it's a bug introduced by a Microsoft critical update (out 
with the old bugs, in with the new!).

Cheers

Jason



From sundar.dorai-raj at PDF.COM  Fri May  7 23:55:58 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 07 May 2004 14:55:58 -0700
Subject: [R] re-ordering a vector by name
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D48@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7D48@usrymx25.merck.com>
Message-ID: <409C05EE.3020706@pdf.com>



Liaw, Andy wrote:

> Dear R-help,
> 
> Let's say `x1' and `x2' are very long vectors (length=5e5, say) with same
> set of names but in different order.  If I want to sort `x2' in the order of
> `x1', I would do 
> 
>   x2[names(x1)]
> 
> but the amount of time that takes is quite prohibitive!  Does anyone have
> any suggestion on a more efficient way to do this?
> 
> If the two vectors are exactly the same length (as I said above), sorting
> both by names would probably be the fastest.  However, if the two vectors
> differ in length (and the names for the shorter one are a subset of names of
> the longer one) then that doesn't work...
> 
> Best,
> Andy
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Hi Andy,
   Using match seems to be *much* faster:

R> x1 <- 1:10000; names(x1) <- 1:10000
R> x2 <- 1:10000; names(x2) <- 10000:1
R> system.time(x3 <- x1[names(x2)])
[1] 1.88 0.00 1.88   NA   NA
R> system.time(x4 <- x1[match(names(x1), names(x2))])
[1] 0.01 0.00 0.01   NA   NA
R> all.equal(x3, x4)
[1] TRUE
R>

This should also work if x1 and x2 are of diffent lengths.

--sundar



From deepayan at stat.wisc.edu  Sat May  8 01:05:03 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 7 May 2004 18:05:03 -0500
Subject: [R] plotting planes and lines in wireframe()
In-Reply-To: <c7gtre$s55$1@sea.gmane.org>
References: <c7gtre$s55$1@sea.gmane.org>
Message-ID: <200405071805.03767.deepayan@stat.wisc.edu>

On Friday 07 May 2004 16:07, wwsprague at ucdavis.edu wrote:
> Hi R-helpers
>
> I would like to plot some planes which are perpendicular to the x-y
> plane, such as x=y.  Is there a way to do this in wireframe?  I
> realize that I am not plotting a function of x, y since there are
> infinite number of z's that satisfy the above relation....  Hmm...

Well, from R 1.9.0 onwards wireframe can draw arbitrary 3-D parametric 
surfaces (spheres and such) with a formula of the form z ~ x * y where 
x, y and z are all matrices. A plane is a very trivial application of 
this, e.g.:

x <- matrix(rep(1:10, 10), 10)
y <- x
z <- matrix(rep(1:10, each = 10), 10)
wireframe(z ~ x * y)

Of course, you are probably not interested in only this plane, in which 
case things may not be as easy, since (1) formally there's no way to 
specify multiple surfaces with this usage and (2) wireframe doesn't do 
hidden surface removal, so intersecting surfaces are messed up. But in 
many cases you can probably make do with a fine mesh and some 
innovative use of NA's. e.g. (continuing the earlier example):

xx <- cbind(x, NA, x)
yy <- cbind(y+50, NA, y^2)
zz <- cbind(z, NA, z)
wireframe(zz ~ xx * yy)

> Somewhat related, I would also like to plot a line in 3 d space...

That's also easy, e.g. cloud(1:3 ~ 3:1 * 1:3) (there seems to be bug 
with just 2 points, I'll fix that in the next release). To do this in a 
wireframe plot you would probably use the panel function 
panel.3dscatter. What's not easy, however, when you are combining 
planes and lines, is to make sure that the appropriate parts of the 
line are hidden.

> Finally, if you are feeling really brave, I am interested in doing
> all of this based on sums generating vectors (I know there is a
> linear algebra term for this) -- ie generate the plane based on
> c_1*v_1 + c_2*v_2 for c_1 and c_2 in reals.

You mean the span of v_1 and v_2 ? Very easy with the approach outlined 
above. Visualize a rectangular grid on the c_1-c_2 plane determining 
the ranges of c_1 and c_2. Let's say the ranges are c1 and c2, e.g., c1 
= c2 = seq(0, 1, length = 11). Next, evaluate the values of c1 and c2 
on this grid as matrices:

tmp = expand.grid(c1 = c1, c2 = c2)
mc1 = matrix(tmp$c1, length(c1))
mc2 = matrix(tmp$c2, length(c1))

Next evaluate the corresponding points on your plane:

x = v1[1] * mc1 + v2[1] * mc2
y = v1[2] * mc1 + v2[2] * mc2
z = v1[3] * mc1 + v2[3] * mc2

and plot them

wireframe(z ~ x * y)

If you don't like the distortion, you could use a wide range of c1 and 
c2 and then use appropriate x/y/zlim.

Deepayan



From andy_liaw at merck.com  Sat May  8 04:44:12 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 7 May 2004 22:44:12 -0400
Subject: [R] re-ordering a vector by name
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D4C@usrymx25.merck.com>

> From: Sundar Dorai-Raj 
> 
> Liaw, Andy wrote:
> 
> > Dear R-help,
> > 
> > Let's say `x1' and `x2' are very long vectors (length=5e5, 
> say) with same
> > set of names but in different order.  If I want to sort 
> `x2' in the order of
> > `x1', I would do 
> > 
> >   x2[names(x1)]
> > 
> > but the amount of time that takes is quite prohibitive!  
> Does anyone have
> > any suggestion on a more efficient way to do this?
> > 
> > If the two vectors are exactly the same length (as I said 
> above), sorting
> > both by names would probably be the fastest.  However, if 
> the two vectors
> > differ in length (and the names for the shorter one are a 
> subset of names of
> > the longer one) then that doesn't work...
> > 
> > Best,
> > Andy
> 
> Hi Andy,
>    
> Using match seems to be *much* faster:
> 
> R> x1 <- 1:10000; names(x1) <- 1:10000
> R> x2 <- 1:10000; names(x2) <- 10000:1
> R> system.time(x3 <- x1[names(x2)])
> [1] 1.88 0.00 1.88   NA   NA
> R> system.time(x4 <- x1[match(names(x1), names(x2))])
> [1] 0.01 0.00 0.01   NA   NA
> R> all.equal(x3, x4)
> [1] TRUE
> R>
> 
> This should also work if x1 and x2 are of diffent lengths.
> 
> --sundar

Sundar,

Thanks very much for the tip!  However, I think the arguments in match() is
backward:

> n = 1e4
> x1 = sample(n)
> x2 = sample(n)
> names(x1) = sample(n)
> names(x2) = sample(n)
> system.time(x3 <- x1[names(x2)])
[1] 5.71 0.00 6.02   NA   NA
> system.time(x4 <- x1[match(names(x1),names(x2))])
[1] 0.03 0.00 0.03   NA   NA
> all.equal(x3, x4)
[1] "Names: 9997 string mismatches"       "Mean relative  difference:
0.669837"
> names(x3[1:5])
 [1] "5391" "9927" "6499" "1863" "8287"
> names(x4[1:5])
 [1] "2560" "9914" "6348" "1291" "5718"
> system.time(x4 <- x1[match(names(x2),names(x1))])
[1] 0.03 0.00 0.03   NA   NA
> names(x4[1:5])
 [1] "5391" "9927" "6499" "1863" "8287"
> all.equal(x3, x4)
[1] TRUE

[Admittedly this is why I rarely use match():  I get mixed up easily.]

Reid: It isn't a memory problem.  For vectors of length 6e5, I killed the R
process after more than 5 hours on an Opteron 248.  The R process was taking
up about 114MB of RAM, out of 8GB in the box.  I'm rather surprised that
such seemingly simple operation would take so long, especially when sorting
such vectors is very fast.  What am I missing?

Best,
Andy



From ripley at stats.ox.ac.uk  Sat May  8 08:13:53 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 May 2004 07:13:53 +0100 (BST)
Subject: [R] Error compiling ROracle on Windows 2000
In-Reply-To: <A6D472EC410FF84E8BE573FD654BAC4339808B@CAEXMTA9>
Message-ID: <Pine.LNX.4.44.0405080709500.10368-100000@gannet.stats>

How to make Rdll.lib is in readme.packages, the basic documentation for 
making packages from sources pointed at from the rw-FAQ.

It seems to be the force-Rdll.lib target in that makefile.

You might also want to note the comments about paths with spaces in, in 
that basic documentation, and that you appear to be trying to build in the 
place the package should be installed.

On Fri, 7 May 2004 mark.threefoot at amd.com wrote:

> 
> Hello,
> 
> I am trying to compile ROracle _0.5-4 under R 1.9.0 without much success.  I am running Windows 2000 SP4, Visual C++ 6.0 SP6, and Oracle client 9.2.0.1.0.  I was able to run the pre-compiled version of ROracle_0.5-2 under R 1.7.1, but does not work on R 1.8.1 or R 1.9.0.  Here is the output from nmake:
> 
> C:\Program Files\R\rw1090\library\ROracle\src>nmake
> 
> Microsoft (R) Program Maintenance Utility   Version 6.00.9782.0
> Copyright (C) Microsoft Corp 1988-1998. All rights reserved.
> 
>         cl /I"C:\\Program Files\\R\\rw1090"\\src\\include /MT /Ox /D "MSVC" /D "
> WIN32" /c RS-DBI.c
> Microsoft (R) 32-bit C/C++ Optimizing Compiler Version 12.00.8804 for 80x86
> Copyright (C) Microsoft Corp 1984-1998. All rights reserved.
> 
> RS-DBI.c
>         cl /I"C:\\Program Files\\R\\rw1090"\\src\\include /MT /Ox /D "MSVC" /D "
> WIN32" /c RS-Oracle.c
> Microsoft (R) 32-bit C/C++ Optimizing Compiler Version 12.00.8804 for 80x86
> Copyright (C) Microsoft Corp 1984-1998. All rights reserved.
> 
> RS-Oracle.c
> NMAKE : fatal error U1073: don't know how to make '\src\\gnuwin32\\Rdll.lib'
> Stop.
> 
> Here is a copy of my Makefile:
> 
> R_HOME = "C:\\Program Files\\R\\rw1090"
> ORACLE_HOME = C:\\oracle\\oracle92
> SRC  = RS-DBI.h RS-DBI.c RS-Oracle.h RS-Oracle.pc S4R.h
> RLIB = $(R_HOME)\\src\\gnuwin32\\Rdll.lib
> OBJ  = RS-DBI.obj RS-Oracle.obj 
> 
> ##
> ## The Oracle ProC/C++ precompiler and options we need (these have worked
> ## on Linux, Solaris, and Windows 2000).
> ##
> 
> PROC=proc              ## this is the ProC/C++ executable
> CODE=ANSI_C            ## the following are ProC/C++ options
> MODE=ORACLE
> PARSE=NONE             ## don't do any C parse
> LINES=false            ## use true for debugging
> 
> ROracle.dll:  $(OBJ) $(RLIB)
> 	(cd $(R_HOME)\\src\\gnuwin32 && lib /def:R.exp /out:Rdll.lib)
> 	link /dll /def:ROracle.def /out:ROracle.dll $(ORACLE_HOME)\\precomp\\lib\\orasql9.lib *.obj $(R_HOME)\\src\\gnuwin32\\Rdll.lib 
> 	
> RS-DBI.obj: RS-DBI.h RS-DBI.c S4R.h
> 	cl /I$(R_HOME)\\src\\include /MT /Ox /D "MSVC" /D "WIN32" /c RS-DBI.c
> 
> RS-Oracle.obj: RS-Oracle.h RS-Oracle.c S4R.h
> 	cl /I$(R_HOME)\\src\\include /MT /Ox /D "MSVC" /D "WIN32" /c RS-Oracle.c
> 
> RS-Oracle.c: RS-Oracle.h RS-Oracle.pc 
> 	$(PROC) CODE=$(CODE) MODE=$(MODE) INCLUDE=$(R_HOME)/include \
>                 PARSE=$(PARSE) LINES=$(LINES) RS-Oracle.pc
> force-Rdll.lib:
> 	(cd $(R_HOME)\\src\\gnuwin32 && lib /def:R.exp /out:Rdll.lib)
> clean:
> 	rm -f $(OBJ) *.a *.d *.rc 
> clobber:
> 	rm -f $(RLIB) $(OBJ) RS-Oracle.c *.a *.d *.rc *.dll 
> 
> Thanks for your help,
> Mark
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Sat May  8 10:55:59 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 May 2004 10:55:59 +0200
Subject: [R] re-ordering a vector by name
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D4C@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7D4C@usrymx25.merck.com>
Message-ID: <x2ad0jz49s.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> Reid: It isn't a memory problem.  For vectors of length 6e5, I killed the R
> process after more than 5 hours on an Opteron 248.  The R process was taking
> up about 114MB of RAM, out of 8GB in the box.  I'm rather surprised that
> such seemingly simple operation would take so long, especially when sorting
> such vectors is very fast.  What am I missing?

An opportunity to fix some horribly inefficient code in subscript.c

There's a double for-loop inside stringSubscript, which will make the
whole operation O(N^2). The match() function presumably does it in 
O(N log N) or there abouts.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From pallier at lscp.ehess.fr  Sat May  8 11:33:46 2004
From: pallier at lscp.ehess.fr (pallier)
Date: Sat, 08 May 2004 11:33:46 +0200
Subject: [R] Surprise when indexing with a factor.
Message-ID: <409CA97A.6030405@lscp.ehess.fr>

Hello,

I had been thinking for years, without having ever checked (shame on 
me), that indexing a named vector by a factor 'f' produced the same 
results as indexing it by 'as.character(f)'. I was wrong, as the 
following example shows:

  (m <- c(a=1,b=2))
  (f <- factor(c(1,2),labels=c('b','a')))

  m[f]
  m[as.character(f)]
  m[as.numeric(f)]

When the labels of a factor are not sorted alphabetically, m[f] and 
m[as.character(f)] yield different results. m[f] is actually equivalent 
to m[as.numeric(f)].

I'm not the first to have been beaten by this (documented) feature, as I 
discovered in a recent thread ("[R] Indexing by factor misfeature", 
<http://tolstoy.newcastle.edu.au/R/help/04/04/0937.html> see 
http://tolstoy.newcastle.edu.au/R/help/04/04/0938.html).

If I am breaking the posting rules by writing again about a previous 
subject, it is only
to suggest to add a short notice about that behavior in the section of 
'R-intro.pdf' about 'index vectors'. Currently, it does not mention the 
use of factors as indexes (It is true that factors are only defined 
later).  At least, this manual could tell the reader to read the help 
about Extract, or type '?"["' (which did not occur to me before writing 
this message...).

Christophe Pallier



From debene at unimc.it  Sat May  8 13:24:19 2004
From: debene at unimc.it (Luca De Benedictis)
Date: Sat, 08 May 2004 13:24:19 +0200
Subject: [R] xyplot, loess and se
Message-ID: <409CC363.9000103@unimc.it>

Dear R-friends,
in plotting x and y, conditioning on z, I am trying to find a way to 
make the standard errors appearing together with the loess in the 
trellis plot.
I have tried the following code without success.

x <- x
y <- y
z.two.groups <- equal.count(z, number=2, overlap=.1)
 > xyplot(x~y | z.two.groups,
+ prepanel = function(x, y)
+ prepanel.loess(x, y, span = .75, se = TRUE),
+ panel = function(x, y){
+ panel.grid(h = 2, v = 2, lwd = 2)
+ panel.xyplot(x, y, cex = 0.6)
+ panel.loess(x, y, span = .75, se = TRUE)
+ },
+ par.strip = list(cex = .75),aspect = 2,
+ xlab = list("x",cex = 1),
+ ylab = list("y",cex = 1),
+ main=list("", cex=2)
+ )

Any help would be appreciated

Luca



From ripley at stats.ox.ac.uk  Sat May  8 14:17:24 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 May 2004 13:17:24 +0100 (BST)
Subject: [R] xyplot, loess and se
In-Reply-To: <409CC363.9000103@unimc.it>
Message-ID: <Pine.LNX.4.44.0405081312070.13075-100000@gannet.stats>

My suggestion is that you look at the code for panel.loess, and then ask 
yourself what made you think this could possibly work.

-  what happens to arguments in ... ?
-  does panel.loess call loess?
-  does loess accept a se=TRUE argument?  Does loess.smooth?

You need to write your own panel and prepanel functions, calling loess and
then predict -- see ?predict.loess.

On Sat, 8 May 2004, Luca De Benedictis wrote:

> Dear R-friends,
> in plotting x and y, conditioning on z, I am trying to find a way to 
> make the standard errors appearing together with the loess in the 
> trellis plot.
> I have tried the following code without success.
> 
> x <- x
> y <- y
> z.two.groups <- equal.count(z, number=2, overlap=.1)
>  > xyplot(x~y | z.two.groups,
> + prepanel = function(x, y)
> + prepanel.loess(x, y, span = .75, se = TRUE),
> + panel = function(x, y){
> + panel.grid(h = 2, v = 2, lwd = 2)
> + panel.xyplot(x, y, cex = 0.6)
> + panel.loess(x, y, span = .75, se = TRUE)
> + },
> + par.strip = list(cex = .75),aspect = 2,
> + xlab = list("x",cex = 1),
> + ylab = list("y",cex = 1),
> + main=list("", cex=2)
> + )
> 
> Any help would be appreciated

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Sat May  8 14:23:03 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 8 May 2004 08:23:03 -0400
Subject: [R] Surprise when indexing with a factor.
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D50@usrymx25.merck.com>

It may be educational to read ?factor before you use a factor for some
operation (such as subscripting), I guess.  In part, it says:

Value:

     'factor' returns an object of class '"factor"' which has a set of
     numeric codes the length of 'x' with a '"levels"' attribute of
     mode 'character'.  If 'ordered' is true (or 'ordered' is used) the
     result has class 'c("ordered", "factor")'.

In other words, a factor is a numeric vector with a "levels" attribute.
What do you expect to happen when you use a numeric vector as subscript?

Andy

> From: pallier
> 
> Hello,
> 
> I had been thinking for years, without having ever checked (shame on 
> me), that indexing a named vector by a factor 'f' produced the same 
> results as indexing it by 'as.character(f)'. I was wrong, as the 
> following example shows:
> 
>   (m <- c(a=1,b=2))
>   (f <- factor(c(1,2),labels=c('b','a')))
> 
>   m[f]
>   m[as.character(f)]
>   m[as.numeric(f)]
> 
> When the labels of a factor are not sorted alphabetically, m[f] and 
> m[as.character(f)] yield different results. m[f] is actually 
> equivalent 
> to m[as.numeric(f)].
> 
> I'm not the first to have been beaten by this (documented) 
> feature, as I 
> discovered in a recent thread ("[R] Indexing by factor misfeature", 
> <http://tolstoy.newcastle.edu.au/R/help/04/04/0937.html> see 
> http://tolstoy.newcastle.edu.au/R/help/04/04/0938.html).
> 
> If I am breaking the posting rules by writing again about a previous 
> subject, it is only
> to suggest to add a short notice about that behavior in the 
> section of 
> 'R-intro.pdf' about 'index vectors'. Currently, it does not 
> mention the 
> use of factors as indexes (It is true that factors are only defined 
> later).  At least, this manual could tell the reader to read the help 
> about Extract, or type '?"["' (which did not occur to me 
> before writing 
> this message...).
> 
> Christophe Pallier
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From pallier at lscp.ehess.fr  Sat May  8 15:31:40 2004
From: pallier at lscp.ehess.fr (pallier)
Date: Sat, 08 May 2004 15:31:40 +0200
Subject: [R] Surprise when indexing with a factor.
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D50@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7D50@usrymx25.merck.com>
Message-ID: <409CE13C.4020303@lscp.ehess.fr>


>It may be educational to read ?factor before you use a factor for some
>operation (such as subscripting), I guess.  In part, it says:
>
>Value:
>
>     'factor' returns an object of class '"factor"' which has a set of
>     numeric codes the length of 'x' with a '"levels"' attribute of
>     mode 'character'.  If 'ordered' is true (or 'ordered' is used) the
>     result has class 'c("ordered", "factor")'.
>
>In other words, a factor is a numeric vector with a "levels" attribute.
>What do you expect to happen when you use a numeric vector as subscript?
>  
>

Hello,

Ok, I understand the point: I should have read the documentation better...

The 'warning' section of the help on 'factor' is even more enlightning:

 >    The interpretation of a factor depends on both the codes and the
 >    `"levels"' attribute.  Be careful only to compare factors with the
 >     same set of levels (in the same order).  In particular,
 >     `as.numeric' applied to a factor is meaningless, and may happen by
 >     implicit coercion.


Let me argue that when a factor is printed, you don't see the numeric 
codes, you just see the labels. From an ergonomic point of view, in many 
situations where labels are used, the numeric representation of a 
unordered factor is just an irrelevant 'internal' coding. (E.g. when 
factors are parsed automatically by read.table).

[Named vectors and labels in factors are part of the reasons why I like 
R better than, say, Matlab: you don't have to remember tons of numeric 
codes.]

Given a named vector 'm' and a factor 'f' whose levels match (e.g. when 
'm' is the result of a 'tapply' command using the factor f as INDEX), my 
intuition is that m[f] means m[as.character(f)]

Others persons with a more precise knowledge of R probably find it 
natural that a factor is numeric in *essence* (despite its *appearance* 
when printed).

I am not proposing to change R to adapt it to my intuition.
I just believed that the trap was dangerous enough to (1) dare display 
my ignorance and (2) suggest that a warning in the 'Introduction to R' 
would not a bad idea (maybe it is but I have not read carefully enough...)

Cheers,

Christophe Pallier



From patrick.giraudoux at univ-fcomte.fr  Sat May  8 15:45:20 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 8 May 2004 15:45:20 +0200
Subject: [R] metafile copy and R 1.9.0
Message-ID: <000901c43502$bb0ee9e0$49ebfb51@PC728329681112>

Dear all,


I'm running into problem in R-1.9.0 that hasn't happened  with R-1.8.x

If I make a plot with xyplot(), and use the menu to either save to a metafile or copy to clipboard as a metafile to export to eg
Powerpoint, I can just copy a blank then. This does not occur with the classical plot(). Thus, I suppose that it may come from
lattice or grid (going through the R-archives I checked that a similar trouble occur when R has been updated to 1.5).

Has this trouble been met already and is there a way to turn it?

Patrick Giraudoux



From ggrothendieck at myway.com  Sat May  8 16:12:21 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 8 May 2004 14:12:21 +0000 (UTC)
Subject: [R] Surprise when indexing with a factor.
References: <3A822319EB35174CA3714066D590DCD504AF7D50@usrymx25.merck.com>
	<409CE13C.4020303@lscp.ehess.fr>
Message-ID: <loom.20040508T154647-470@post.gmane.org>


Note that if f is a factor with Date labels, e.g.

   f <- factor(c("2000-02-02","2000-02-03"))

then as.Date has a factor method whose effect is such that (as of R 1.9.1):

   as.Date(f)

*is* the same as as.Date(as.character(f)) .  (Presumably this makes
it easier to use as.Date with read.table.)  




pallier <pallier <at> lscp.ehess.fr> writes:

: 
: >It may be educational to read ?factor before you use a factor for some
: >operation (such as subscripting), I guess.  In part, it says:
: >
: >Value:
: >
: >     'factor' returns an object of class '"factor"' which has a set of
: >     numeric codes the length of 'x' with a '"levels"' attribute of
: >     mode 'character'.  If 'ordered' is true (or 'ordered' is used) the
: >     result has class 'c("ordered", "factor")'.
: >
: >In other words, a factor is a numeric vector with a "levels" attribute.
: >What do you expect to happen when you use a numeric vector as subscript?
: >  
: >
: 
: Hello,
: 
: Ok, I understand the point: I should have read the documentation better...
: 
: The 'warning' section of the help on 'factor' is even more enlightning:
: 
:  >    The interpretation of a factor depends on both the codes and the
:  >    `"levels"' attribute.  Be careful only to compare factors with the
:  >     same set of levels (in the same order).  In particular,
:  >     `as.numeric' applied to a factor is meaningless, and may happen by
:  >     implicit coercion.
: 
: Let me argue that when a factor is printed, you don't see the numeric 
: codes, you just see the labels. From an ergonomic point of view, in many 
: situations where labels are used, the numeric representation of a 
: unordered factor is just an irrelevant 'internal' coding. (E.g. when 
: factors are parsed automatically by read.table).
: 
: [Named vectors and labels in factors are part of the reasons why I like 
: R better than, say, Matlab: you don't have to remember tons of numeric 
: codes.]
: 
: Given a named vector 'm' and a factor 'f' whose levels match (e.g. when 
: 'm' is the result of a 'tapply' command using the factor f as INDEX), my 
: intuition is that m[f] means m[as.character(f)]
: 
: Others persons with a more precise knowledge of R probably find it 
: natural that a factor is numeric in *essence* (despite its *appearance* 
: when printed).
: 
: I am not proposing to change R to adapt it to my intuition.
: I just believed that the trap was dangerous enough to (1) dare display 
: my ignorance and (2) suggest that a warning in the 'Introduction to R' 
: would not a bad idea (maybe it is but I have not read carefully enough...)
: 
: Cheers,
: 
: Christophe Pallier
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From deepayan at stat.wisc.edu  Sat May  8 16:18:23 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 8 May 2004 09:18:23 -0500
Subject: [R] metafile copy and R 1.9.0
In-Reply-To: <000901c43502$bb0ee9e0$49ebfb51@PC728329681112>
References: <000901c43502$bb0ee9e0$49ebfb51@PC728329681112>
Message-ID: <200405080918.23211.deepayan@stat.wisc.edu>


On Saturday 08 May 2004 08:45, Patrick Giraudoux wrote:
> Dear all,
>
>
> I'm running into problem in R-1.9.0 that hasn't happened  with
> R-1.8.x
>
> If I make a plot with xyplot(), and use the menu to either save to a
> metafile or copy to clipboard as a metafile to export to eg
> Powerpoint, I can just copy a blank then. This does not occur with
> the classical plot(). Thus, I suppose that it may come from lattice
> or grid (going through the R-archives I checked that a similar
> trouble occur when R has been updated to 1.5).
>
> Has this trouble been met already and is there a way to turn it?

This was reported by John Fox last month on r-windows at r-project.org -- 
but I can't find any archives for that list to refer you to. I'll 
forward Paul's reply to you off-list.

Deepayan



From ggrothendieck at myway.com  Sat May  8 16:36:19 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 8 May 2004 14:36:19 +0000 (UTC)
Subject: [R] metafile copy and R 1.9.0
References: <000901c43502$bb0ee9e0$49ebfb51@PC728329681112>
Message-ID: <loom.20040508T162834-16@post.gmane.org>

I don't know if this workaround suffers the same problem or not 
since I have not tried it but you could try using the xfig device 
for your graphics and then using xfig2dev to convert that file 
to .cgm format (which is also vector based) and then in Word use:
   Insert | Picture
or if a bitmapped format is sufficient just use that.


Patrick Giraudoux <patrick.giraudoux <at> univ-fcomte.fr> writes:

: 
: Dear all,
: 
: I'm running into problem in R-1.9.0 that hasn't happened  with R-1.8.x
: 
: If I make a plot with xyplot(), and use the menu to either save to a 
metafile or copy to clipboard as a metafile
: to export to eg
: Powerpoint, I can just copy a blank then. This does not occur with the 
classical plot(). Thus, I suppose that
: it may come from
: lattice or grid (going through the R-archives I checked that a similar 
trouble occur when R has been updated
: to 1.5).
: 
: Has this trouble been met already and is there a way to turn it?
: 
: Patrick Giraudoux
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From p.dalgaard at biostat.ku.dk  Sat May  8 16:31:39 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 May 2004 16:31:39 +0200
Subject: [R] Surprise when indexing with a factor.
In-Reply-To: <409CE13C.4020303@lscp.ehess.fr>
References: <3A822319EB35174CA3714066D590DCD504AF7D50@usrymx25.merck.com>
	<409CE13C.4020303@lscp.ehess.fr>
Message-ID: <x2llk3dm7o.fsf@biostat.ku.dk>

pallier <pallier at lscp.ehess.fr> writes:

> Given a named vector 'm' and a factor 'f' whose levels match (e.g.
> when 'm' is the result of a 'tapply' command using the factor f as
> INDEX), my intuition is that m[f] means m[as.character(f)]

It's not like we haven't visited this before. As I recall it, the main
argument for the actual behaviour is that otherwise you can *only*
index named vectors with levels a superset of those of the factor.
It makes little sense to have such a restriction, and even less to
have m[f] change if names are added to m.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From patrick.giraudoux at univ-fcomte.fr  Sat May  8 16:48:41 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 8 May 2004 16:48:41 +0200
Subject: [R] Re: metafile copy and R 1.9.0, trellis, grid
Message-ID: <00c001c4350b$91f2b010$49ebfb51@PC728329681112>

OK. Deepayan sent me the copy of a chat on another list between John Fox, Duncan Murdoch and Paul Murrell.  The bug in the gui.exe
looks like being reported with an example to turn it before he has been definetely fixed. Just try:

trellis.device("win.metafile", file="test.emf")
data(iris)
cloud(Sepal.Length ~ Petal.Length * Petal.Width | Species, data =
iris, screen = list(x = -90, y = 70), distance = .4, zoom = .6)
dev.off()

This set of commands create a file ("test.emf") in the working directory, write a cloud plot in the file and shut down the device.
The file "test.emf" can then be imported from any software reading metafiles. I tried it with my own xyplot trouble and got
absolutely good result. Very easy, even to me!!!

Thanks to them for the hint,

Patrick


----- Original Message ----- 
From: "Patrick Giraudoux" <patrick.giraudoux at univ-fcomte.fr>
To: "r-help" <r-help at stat.math.ethz.ch>
Sent: Saturday, May 08, 2004 3:45 PM
Subject: metafile copy and R 1.9.0


> Dear all,
>
>
> I'm running into problem in R-1.9.0 that hasn't happened  with R-1.8.x
>
> If I make a plot with xyplot(), and use the menu to either save to a metafile or copy to clipboard as a metafile to export to eg
> Powerpoint, I can just copy a blank then. This does not occur with the classical plot(). Thus, I suppose that it may come from
> lattice or grid (going through the R-archives I checked that a similar trouble occur when R has been updated to 1.5).
>
> Has this trouble been met already and is there a way to turn it?
>
> Patrick Giraudoux
>
>
>



From as_minaei at yahoo.com  Sat May  8 17:17:49 2004
From: as_minaei at yahoo.com (Asghar Minaei)
Date: Sat, 8 May 2004 08:17:49 -0700 (PDT)
Subject: [R] help about R
Message-ID: <20040508151749.64364.qmail@web20606.mail.yahoo.com>

Dear Sir/Madam
Hello

I'm Ph.D student of psychometric at the university of
Tehran.I use R version 1.8.1. I want to upgrade the R
into higher version.I downloaded the latest version
"R-1.9.0.tgz". Unfortunately I could not to upgrade
the R. Could you tell me how I can to upgrade the
R,please?

Best regards
Asghar Minaei

=====
Yours...Asghar Minaei



From as_minaei at yahoo.com  Sat May  8 17:19:36 2004
From: as_minaei at yahoo.com (Asghar Minaei)
Date: Sat, 8 May 2004 08:19:36 -0700 (PDT)
Subject: [R] help about R
Message-ID: <20040508151936.64477.qmail@web20606.mail.yahoo.com>

Dear Sir/Madam
Hello

I'm Ph.D student of psychometric at the university of
Tehran.I use R version 1.8.1. I want to upgrade the R
into higher version.I downloaded the latest version
"R-1.9.0.tgz". Unfortunately I could not to upgrade
the R. Could you tell me how I can to upgrade the
R,please?

Best regards
Asghar Minaei

=====
Yours...Asghar Minaei



From alain.yamakana at rogers.com  Sat May  8 17:22:25 2004
From: alain.yamakana at rogers.com (Alain Yamakana)
Date: Sat, 8 May 2004 11:22:25 -0400
Subject: [R] as.double.default()
Message-ID: <002a01c43510$453d2340$1d503141@bloor.phub.net.cable.rogers.com>

Hi there!

This is my second message in two weeks. I am regretting to get ride of my
R-1.4.1! In fact, since I upgraded to R-1.8.1 (directly from R-1.4.1) and
then to R-1.9.0 I am experiencing diffulties I never faced before. Professor
Ripley and Dr. Murdoch had helped with the "Fatal Error. HOMEDRIVE." Another
problem I am now facing is that R is not reading any matrix if I do not
specify as.numer(). For instance, if I want to operate on matrix M I need to
write operation_intended(as.numeric(M)) otherwise I got the following
message "Error in as.double.default(): object cannot be coerced to double."

I would appreciate your help to fix either the as.double.default() error or
the "R for Windows GUI front-end has encountered a problem and needs to
close. We are sorry for the inconvenience." encountered when running R-1.8.1
so that I can stay with this version I successfully used for while.

Best regards,
Alain



From ligges at statistik.uni-dortmund.de  Sat May  8 17:58:51 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 08 May 2004 17:58:51 +0200
Subject: [R] as.double.default()
In-Reply-To: <002a01c43510$453d2340$1d503141@bloor.phub.net.cable.rogers.com>
References: <002a01c43510$453d2340$1d503141@bloor.phub.net.cable.rogers.com>
Message-ID: <409D03BB.3050505@statistik.uni-dortmund.de>

Alain Yamakana wrote:

> Hi there!
> 
> This is my second message in two weeks. I am regretting to get ride of my
> R-1.4.1! In fact, since I upgraded to R-1.8.1 (directly from R-1.4.1) and
> then to R-1.9.0 I am experiencing diffulties I never faced before. Professor
> Ripley and Dr. Murdoch had helped with the "Fatal Error. HOMEDRIVE." Another
> problem I am now facing is that R is not reading any matrix if I do not
> specify as.numer(). For instance, if I want to operate on matrix M I need to
> write operation_intended(as.numeric(M)) otherwise I got the following
> message "Error in as.double.default(): object cannot be coerced to double."

We don't know what "operation_intended" is. We do not know what kind of 
object "M" is - and what is its mode? Hence we cannot help here....


> I would appreciate your help to fix either the as.double.default() error or
> the "R for Windows GUI front-end has encountered a problem and needs to
> close. We are sorry for the inconvenience." encountered when running R-1.8.1
> so that I can stay with this version I successfully used for while.

It's exactly the same problem as that one you quoted above for R-1.9.0: 
"Fatal Error. HOMEDRIVE.", just producing another kind of error. The 
same workaround applies here as well.

Uwe Ligges

> Best regards,
> Alain
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat May  8 18:03:34 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 08 May 2004 18:03:34 +0200
Subject: [R] help about R
In-Reply-To: <20040508151936.64477.qmail@web20606.mail.yahoo.com>
References: <20040508151936.64477.qmail@web20606.mail.yahoo.com>
Message-ID: <409D04D6.7010404@statistik.uni-dortmund.de>

Asghar Minaei wrote:

> Dear Sir/Madam
> Hello
> 
> I'm Ph.D student of psychometric at the university of
> Tehran.I use R version 1.8.1. I want to upgrade the R
> into higher version.I downloaded the latest version
> "R-1.9.0.tgz". Unfortunately I could not to upgrade
> the R. Could you tell me how I can to upgrade the
> R,please?

... and the Operating System is ???

Does the R Installation and Administration manual
(http://cran.r-project.org/doc/manuals/R-admin.pdf)
help?
Do the files Readme and Install within the mentioned tar archive help?

Uwe Ligges



> Best regards
> Asghar Minaei
> 
> =====
> Yours...Asghar Minaei
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From chris1 at psyctc.org  Sat May  8 18:09:54 2004
From: chris1 at psyctc.org (chris1)
Date: Sat, 8 May 2004 17:09:54 +0100
Subject: [R] Indexing column of a matrix with infix $
Message-ID: <1602725397.20040508170954@psyctc.org>

I'm using 1.9.0 on Windoze 2k and I created a numeric matrix and used
colnames() to give it some column names, but if I try to select a
column using matrixname$validname I get a null return but if I use
matrixname[,4] it works fine.  Looking at the help I think this is
because a matrix is not a recursive structure and I think it's saying
I shouldn't be surprised nor attempt this.

I'm in the process of transferring all my stats work to R having used
a mixture of SPSS, S and SAS (and snippets of other things) over the
years so sorry if I'm being dumb but this surprised me and I'd love a
kindly explanation as I thought indexing a matrix in this way was
something I did regularly (I think the last time was actually using it
on a dataframe though) and I also think it would be useful and produce
more readable code if I could.

Can some kindly soul explain?

TIA,

Chris



From rpeng at jhsph.edu  Sat May  8 18:23:18 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sat, 08 May 2004 12:23:18 -0400
Subject: [R] Indexing column of a matrix with infix $
In-Reply-To: <1602725397.20040508170954@psyctc.org>
References: <1602725397.20040508170954@psyctc.org>
Message-ID: <409D0976.7090603@jhsph.edu>

You can access a column of a dataframe using $ but not a matrix. 
    That's just how it is.  You can access a column of a matrix 
via its column name using, for example

 > m <- matrix(1:12, 4, 3)
 > colnames(m) <- c("a", "b", "c")
 > m[, "b"]
[1] 5 6 7 8

-roger

chris1 wrote:
> I'm using 1.9.0 on Windoze 2k and I created a numeric matrix and used
> colnames() to give it some column names, but if I try to select a
> column using matrixname$validname I get a null return but if I use
> matrixname[,4] it works fine.  Looking at the help I think this is
> because a matrix is not a recursive structure and I think it's saying
> I shouldn't be surprised nor attempt this.
> 
> I'm in the process of transferring all my stats work to R having used
> a mixture of SPSS, S and SAS (and snippets of other things) over the
> years so sorry if I'm being dumb but this surprised me and I'd love a
> kindly explanation as I thought indexing a matrix in this way was
> something I did regularly (I think the last time was actually using it
> on a dataframe though) and I also think it would be useful and produce
> more readable code if I could.
> 
> Can some kindly soul explain?
> 
> TIA,
> 
> Chris
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From soros at mac.com  Sat May  8 20:01:13 2004
From: soros at mac.com (Peter Soros)
Date: Sat, 8 May 2004 14:01:13 -0400
Subject: [R] wavelet analysis
Message-ID: <B1B273B3-A119-11D8-9816-000393757382@mac.com>

Hello everybody,

I would like to calculate a wavelet transformation of EEG data 
(preferably a Morlet transformation) and plot the results as a 
time-frequency power spectrum (using R 1.9.0 on Mac OS X). I have 
checked Rwave and the explanations in the book by R. Carmona et al., 
but couldn't make it work.

Is it possible to calculate Morlet wavelets with wavethresh or 
waveslim? Does anybody has some sample code for one of these packages 
(for calculation and for plotting)?

Thank you very much,

Peter Soros



From bates at stat.wisc.edu  Sat May  8 21:27:26 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 08 May 2004 14:27:26 -0500
Subject: [R] Indexing column of a matrix with infix $
In-Reply-To: <1602725397.20040508170954@psyctc.org>
References: <1602725397.20040508170954@psyctc.org>
Message-ID: <6r4qqqra75.fsf@bates4.stat.wisc.edu>

chris1 <chris1 at psyctc.org> writes:

> I'm using 1.9.0 on Windoze 2k and I created a numeric matrix and used
> colnames() to give it some column names, but if I try to select a
> column using matrixname$validname I get a null return but if I use
> matrixname[,4] it works fine.  Looking at the help I think this is
> because a matrix is not a recursive structure and I think it's saying
> I shouldn't be surprised nor attempt this.
> 
> I'm in the process of transferring all my stats work to R having used
> a mixture of SPSS, S and SAS (and snippets of other things) over the
> years so sorry if I'm being dumb but this surprised me and I'd love a
> kindly explanation as I thought indexing a matrix in this way was
> something I did regularly (I think the last time was actually using it
> on a dataframe though) and I also think it would be useful and produce
> more readable code if I could.
> 
> Can some kindly soul explain?

As Roger indirectly indicated in his response, you probably want to
use data frames and not matrices to store your data sets.  In the S
language the data frame is analogous to the SAS data set.



From Brian.Beckage at uvm.edu  Sat May  8 22:19:27 2004
From: Brian.Beckage at uvm.edu (Brian Beckage)
Date: Sat, 8 May 2004 16:19:27 -0400
Subject: [R] Installing R 1.9.0 on OSX
Message-ID: <p06100501bcc2ed74ea21@[10.0.1.2]>

I've downloaded and installed R 1.9.0 under OS X 10.3.3.  I then 
removed my previous R 1.8.0 installation by following the 
instructions in the readme file, e.g.,

1. drag the "StartR" icon into the Trash;

2) go inside your Home directory and search for the Library folder. 
Inside the Library folder in your Home directory 	       you'll 
find a RAqua directory: drag the RAqua folder into the Trash:

3) empty the Trash.

and I removed the directory /usr/local/lib/R and the file 
/usr/local/bin/R as instructed.

R 1.9.0 will start up from the applications window.  Since I usually 
run R using Xemacs and X11, I used the following commands (under zsh) 
to set up a symbolic link:

>  sudo ln -s /Library/Frameworks/R.framework/Resources/bin/R /usr/local/bin/R

which gives me an error that the file /usr/local/bin/R does not 
exist, which of course, it doesn't as I deleted it as described 
above.  R will start up fine if I use
>  /Library/Frameworks/R.framework/Resources/bin/R

In addition, usr/local/bin does exist and is on the search path.

>  echo $PATH
>/sw/bin:/sw/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/brianbeckage:/usr/X11R6/bin:.:/Users/brianbeckage/bin:/usr/local/bin


How do I correctly set up the symbolic link?

Thanks for you help,
Brian


-- 
*********************************************************************
Brian Beckage
Department of Botany
University of Vermont
Marsh Life Science Building
Burlington, VT 05405

Phone:  802 656-0197
Fax  :  802 656-0440
email:  Brian.Beckage at uvm.edu
web  :  www.uvm.edu/~bbeckage



From hb at maths.lth.se  Sat May  8 22:24:01 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sat, 8 May 2004 22:24:01 +0200
Subject: [R] as.double.default()
In-Reply-To: <002a01c43510$453d2340$1d503141@bloor.phub.net.cable.rogers.com>
Message-ID: <003f01c4353a$67653dc0$a80040d5@maths.lth.se>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Alain
Yamakana
> Sent: den 8 maj 2004 17:22
> To: r-help at stat.math.ethz.ch
> Subject: [R] as.double.default()
> 
> 
> Hi there!
> 
> This is my second message in two weeks. I am regretting to 
> get ride of my R-1.4.1! In fact, since I upgraded to R-1.8.1 
> (directly from R-1.4.1) and then to R-1.9.0 I am experiencing 
> diffulties I never faced before. Professor Ripley and Dr. 
> Murdoch had helped with the "Fatal Error. HOMEDRIVE." Another 
> problem I am now facing is that R is not reading any matrix 
> if I do not specify as.numer(). For instance, if I want to 
> operate on matrix M I need to write 
> operation_intended(as.numeric(M)) otherwise I got the 
> following message "Error in as.double.default(): object 
> cannot be coerced to double."
> 
> I would appreciate your help to fix either the 
> as.double.default() error or the "R for Windows GUI front-end 
> has encountered a problem and needs to close. We are sorry 
> for the inconvenience." encountered when running R-1.8.1 so 
> that I can stay with this version I successfully used for while.

Could you give a reproducible example that we can cut'n'paste and
which shows why your matrix operation is not working. Do you read the
matrix from file or generate it? What is typical elements of 'M' for
you? Try str(M).

BTW, I would say that the stability of R is improving all the time and
I would not recommend to stay with R v1.4.1, but you might be right
that you experience extra difficulties because haven't updated in two
years and small changes have been made at each new version. R v1.9.0
works perfectly fine for me on WinXP Pro.

> Best regards,
> Alain

Cheers

Henrik Bengtsson



From Atropin75 at t-online.de  Sat May  8 22:33:15 2004
From: Atropin75 at t-online.de (Felix Eschenburg)
Date: Sat, 8 May 2004 22:33:15 +0200
Subject: [R] Getting the groupmean for each person
Message-ID: <200405082233.15813.atropin75@t-online.de>

Hello list !

I have a huge data.frame with several variables observed on about 3000 
persons. For every person (row) there is variable called GROUP which indices 
the group the person belongs to. There is also another variable AV for each 
person. Now i want to create a new variable which holds the group mean of AV 
as a value for each person.
With tapply(AV,GROUP,mean) i get the means for each level of GROUP, but i 
cannot find out, how to give every person the groupmean as a value (every 
person should have the same value as every other person in the same group). 

Has anybody any ideas how to do that ?

Yours sincerly
Felix Eschenburg



From ggrothendieck at myway.com  Sat May  8 23:02:40 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 8 May 2004 21:02:40 +0000 (UTC)
Subject: [R] Getting the groupmean for each person
References: <200405082233.15813.atropin75@t-online.de>
Message-ID: <loom.20040508T225858-512@post.gmane.org>


predict(lm(AV~as.factor(GROUP)))



Felix Eschenburg <Atropin75 <at> t-online.de> writes:

: 
: Hello list !
: 
: I have a huge data.frame with several variables observed on about 3000 
: persons. For every person (row) there is variable called GROUP which indices 
: the group the person belongs to. There is also another variable AV for each 
: person. Now i want to create a new variable which holds the group mean of AV 
: as a value for each person.
: With tapply(AV,GROUP,mean) i get the means for each level of GROUP, but i 
: cannot find out, how to give every person the groupmean as a value (every 
: person should have the same value as every other person in the same group). 
: 
: Has anybody any ideas how to do that ?
: 
: Yours sincerly
: Felix Eschenburg



From ggrothendieck at myway.com  Sat May  8 23:39:20 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 8 May 2004 21:39:20 +0000 (UTC)
Subject: [R] Indexing column of a matrix with infix $
References: <1602725397.20040508170954@psyctc.org>
Message-ID: <loom.20040508T233747-453@post.gmane.org>


as.data.frame(matrixname)$validname

chris1 <chris1 <at> psyctc.org> writes:

: 
: I'm using 1.9.0 on Windoze 2k and I created a numeric matrix and used
: colnames() to give it some column names, but if I try to select a
: column using matrixname$validname I get a null return but if I use
: matrixname[,4] it works fine.  Looking at the help I think this is
: because a matrix is not a recursive structure and I think it's saying
: I shouldn't be surprised nor attempt this.
: 
: I'm in the process of transferring all my stats work to R having used
: a mixture of SPSS, S and SAS (and snippets of other things) over the
: years so sorry if I'm being dumb but this surprised me and I'd love a
: kindly explanation as I thought indexing a matrix in this way was
: something I did regularly (I think the last time was actually using it
: on a dataframe though) and I also think it would be useful and produce
: more readable code if I could.
: 
: Can some kindly soul explain?
: 
: TIA,
: 
: Chris
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From rgazaffi at uol.com.br  Sun May  9 04:15:07 2004
From: rgazaffi at uol.com.br (rgazaffi)
Date: Sat,  8 May 2004 23:15:07 -0300
Subject: [R] (no subject)
Message-ID: <HXFCX7$IcOj0WCJTAWdmoObOSD3WFO1lo_HK8rirYiJ@uol.com.br>

hello,

I am working with some data which i would like to find the 
best fit model for them.
First, this data are in a matrix. Each of the columns are 
treatments and the raws are repetions for the each tratment. 
So, i've already maden one chart with all the boxplot 
graphic, for each treatment.
Now, i need to find the best fit model for them, i know that 
exponetial or log model would be perfect in this situation 
(both can help me)

Therefore, i need to find the best exponential model for this 
data, and i would like draw this tendence line in my boxplot 
(if it is possible, of course.)


if someone could help me i would be appreciated.
i am trying to solve these, but i am not having sucess.

best wishes for all.
Rodrigo Gazaffi



 
---
Acabe com aquelas janelinhas que pulam na sua tela.
AntiPop-up UOL - ?? gr??tis! 
http://antipopup.uol.com.br



From Brian.Beckage at uvm.edu  Sun May  9 04:13:56 2004
From: Brian.Beckage at uvm.edu (Brian Beckage)
Date: Sat, 8 May 2004 22:13:56 -0400
Subject: [R] Installing R 1.9.0 on OSX
In-Reply-To: <p06100501bcc2ed74ea21@[10.0.1.2]>
References: <p06100501bcc2ed74ea21@[10.0.1.2]>
Message-ID: <p06100500bcc343adfc52@[10.0.1.2]>

Oops...the error was my own.

I had been typing
sudo ln -s /Library/Frameworks/R.framework/Resources/bin/R usr/local/bin/R

instead of

sudo ln -s /Library/Frameworks/R.framework/Resources/bin/R /usr/local/bin/R

which makes all the difference in the world.

Brian



>
>
>>  sudo ln -s /Library/Frameworks/R.framework/Resources/bin/R /usr/local/bin/R
>
>which gives me an error that the file /usr/local/bin/R does not 
>exist, which of course, it doesn't as I deleted it as described 
>above.  R will start up fine if I use
>>  /Library/Frameworks/R.framework/Resources/bin/R
>
>In addition, usr/local/bin does exist and is on the search path.
>
>>  echo $PATH
>>/sw/bin:/sw/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/brianbeckage:/usr/X11R6/bin:.:/Users/brianbeckage/bin:/usr/local/bin
>
>
>How do I correctly set up the symbolic link?
>
>Thanks for you help,
>Brian
>
>
>--
>*********************************************************************
>Brian Beckage
>Department of Botany
>University of Vermont
>Marsh Life Science Building
>Burlington, VT 05405
>
>Phone:  802 656-0197
>Fax  :  802 656-0440
>email:  Brian.Beckage at uvm.edu
>web  :  www.uvm.edu/~bbeckage
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
*********************************************************************
Brian Beckage
Department of Botany
University of Vermont
Marsh Life Science Building
Burlington, VT 05405

Phone:  802 656-0197
Fax  :  802 656-0440
email:  Brian.Beckage at uvm.edu
web  :  www.uvm.edu/~bbeckage



From jasont at indigoindustrial.co.nz  Sun May  9 05:04:48 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sun, 9 May 2004 15:04:48 +1200 (NZST)
Subject: [R] Upgrading (was: help about R)
In-Reply-To: <20040508151936.64477.qmail@web20606.mail.yahoo.com>
References: <20040508151936.64477.qmail@web20606.mail.yahoo.com>
Message-ID: <4224.210.86.41.209.1084071888.squirrel@webmail.maxnet.co.nz>

> Dear Sir/Madam
> Hello
>
> I'm Ph.D student of psychometric at the university of
> Tehran.I use R version 1.8.1. I want to upgrade the R
> into higher version.I downloaded the latest version
> "R-1.9.0.tgz". Unfortunately I could not to upgrade
> the R. Could you tell me how I can to upgrade the
> R,please?

Depends what type of comptuer/operating system you're on.

Check here for full instructions:

http://cran.r-project.org/doc/manuals/R-admin.pdf

Cheers

Jason



From ggrothendieck at myway.com  Sun May  9 13:25:05 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 9 May 2004 11:25:05 +0000 (UTC)
Subject: [R] Creating and editing networks
Message-ID: <loom.20040509T130852-267@post.gmane.org>


I want to draw and edit networks.  Currently I will do something like this  --
my actual networks are larger and more complex:

1. Plot network

# use polygon with nodes as example network
N <- 20
t. <- 2*pi*seq(N+1)/N
plot(cos(t.), sin(t.), type="b", pch=19, cex=5, col="blue", axes=F, ann=F)

2. copy and paste the graphic as a metafile into Word.

3. edit the network
there.   The editing typically just involves moving nodes and the attached
edges.  Of course, Word does not know the edges are attached to the nodes so I
have to move the nodes and then move the attached edges, as well.

The networks are too complex to create the diagrams by hand which is why
I want to create them in R and then edit them by hand.

The above strategy is marginally acceptable but 
I was wondering if anyone had a better strategy which retains the
simplicity of the present approach but gives me the capability to 
have the edges move along with attached nodes when editing them.

(Note that the strategy must consist of generating the network under program
control, preferably in R, and then editing it afterwards.  I am not looking
to create the entire network by hand since the networks are too complex for
that.  I had tried specifying the networks in dot from Bell Labs but 1. its 
still more work than generating the network in R   2. the automatic
layout it chooses is so far from what I need that its a lot of work to 
fix it up by hand in dotty and 3. I could never get them to look just how
I like.  I have also tried Excel and Powerpoint, both
of which support connectors, which are edges that move along with attached
nodes, but to use them I have to create the entire network by hand and
the networks have grown too complex to do that.)



From ligges at statistik.uni-dortmund.de  Sun May  9 14:35:02 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 09 May 2004 14:35:02 +0200
Subject: [R] Creating and editing networks
In-Reply-To: <loom.20040509T130852-267@post.gmane.org>
References: <loom.20040509T130852-267@post.gmane.org>
Message-ID: <409E2576.3030309@statistik.uni-dortmund.de>

Gabor Grothendieck wrote:
> I want to draw and edit networks.  Currently I will do something like this  --
> my actual networks are larger and more complex:
> 
> 1. Plot network
> 
> # use polygon with nodes as example network
> N <- 20
> t. <- 2*pi*seq(N+1)/N
> plot(cos(t.), sin(t.), type="b", pch=19, cex=5, col="blue", axes=F, ann=F)
> 
> 2. copy and paste the graphic as a metafile into Word.
> 
> 3. edit the network
> there.   The editing typically just involves moving nodes and the attached
> edges.  Of course, Word does not know the edges are attached to the nodes so I
> have to move the nodes and then move the attached edges, as well.
> 
> The networks are too complex to create the diagrams by hand which is why
> I want to create them in R and then edit them by hand.
> 
> The above strategy is marginally acceptable but 
> I was wondering if anyone had a better strategy which retains the
> simplicity of the present approach but gives me the capability to 
> have the edges move along with attached nodes when editing them.
> 
> (Note that the strategy must consist of generating the network under program
> control, preferably in R, and then editing it afterwards.  I am not looking
> to create the entire network by hand since the networks are too complex for
> that.  I had tried specifying the networks in dot from Bell Labs but 1. its 
> still more work than generating the network in R   2. the automatic
> layout it chooses is so far from what I need that its a lot of work to 
> fix it up by hand in dotty and 3. I could never get them to look just how
> I like.  I have also tried Excel and Powerpoint, both
> of which support connectors, which are edges that move along with attached
> nodes, but to use them I have to create the entire network by hand and
> the networks have grown too complex to do that.)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


Have you tried the CRAN package "dynamicGraph" by Jens Henrik Badsberg?

Uwe Ligges



From rgentlem at jimmy.harvard.edu  Sun May  9 15:18:07 2004
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Sun, 9 May 2004 09:18:07 -0400
Subject: [R] Creating and editing networks
In-Reply-To: <409E2576.3030309@statistik.uni-dortmund.de>;
	from ligges@statistik.uni-dortmund.de on Sun, May 09, 2004 at
	02:35:02PM +0200
References: <loom.20040509T130852-267@post.gmane.org>
	<409E2576.3030309@statistik.uni-dortmund.de>
Message-ID: <20040509091807.Z19524@jimmy.harvard.edu>

Or graph, RBGL and Rgraphviz from www.bioconductor.org....

On Sun, May 09, 2004 at 02:35:02PM +0200, Uwe Ligges wrote:
> Gabor Grothendieck wrote:
> > I want to draw and edit networks.  Currently I will do something like this  --
> > my actual networks are larger and more complex:
> > 
> > 1. Plot network
> > 
> > # use polygon with nodes as example network
> > N <- 20
> > t. <- 2*pi*seq(N+1)/N
> > plot(cos(t.), sin(t.), type="b", pch=19, cex=5, col="blue", axes=F, ann=F)
> > 
> > 2. copy and paste the graphic as a metafile into Word.
> > 
> > 3. edit the network
> > there.   The editing typically just involves moving nodes and the attached
> > edges.  Of course, Word does not know the edges are attached to the nodes so I
> > have to move the nodes and then move the attached edges, as well.
> > 
> > The networks are too complex to create the diagrams by hand which is why
> > I want to create them in R and then edit them by hand.
> > 
> > The above strategy is marginally acceptable but 
> > I was wondering if anyone had a better strategy which retains the
> > simplicity of the present approach but gives me the capability to 
> > have the edges move along with attached nodes when editing them.
> > 
> > (Note that the strategy must consist of generating the network under program
> > control, preferably in R, and then editing it afterwards.  I am not looking
> > to create the entire network by hand since the networks are too complex for
> > that.  I had tried specifying the networks in dot from Bell Labs but 1. its 
> > still more work than generating the network in R   2. the automatic
> > layout it chooses is so far from what I need that its a lot of work to 
> > fix it up by hand in dotty and 3. I could never get them to look just how
> > I like.  I have also tried Excel and Powerpoint, both
> > of which support connectors, which are edges that move along with attached
> > nodes, but to use them I have to create the entire network by hand and
> > the networks have grown too complex to do that.)
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> Have you tried the CRAN package "dynamicGraph" by Jens Henrik Badsberg?
> 
> Uwe Ligges
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20                            |
| Harvard School of Public Health  email: rgentlem at jimmy.harvard.edu        |
+---------------------------------------------------------------------------+



From Sebastian-Schubert at gmx.de  Sun May  9 17:24:23 2004
From: Sebastian-Schubert at gmx.de (Sebastian Schubert)
Date: Sun, 9 May 2004 17:24:23 +0200 (MEST)
Subject: [R] Using known errors and error bars
Message-ID: <2132.1084116263@www14.gmx.net>

Hi, 
 
I'm now to R and hope (actually, I'm quite sure) you can help me. I made 
an experiment and measured two values. As I know the errors of these 
values I want to use them with the linear regression, 
eg 
Value A 
1.1+-0.02 
1.9+-0.05 
3.05+-0.03 
4.0+-0.01 
5.1+-0.06 
 
Value B 
4.2+-0.14 
5.3+-0.05 
6.8+-0.11 
7.9+-0.01 
8.5+-0.02 
 
lm(B~A) does the linear regression but how can I use the fact that 1.1 is 
between 1.12 and 1.08? 
How can I put error bars for A and B in the plot (like Excel is capable 
of)? 
 
I hope I made myself understandable, 
thanks 
Sebastian 

--



From thpe at hhbio.wasser.tu-dresden.de  Sun May  9 17:42:59 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Sun, 09 May 2004 17:42:59 +0200
Subject: [R] Modalwert
In-Reply-To: <000501c42a1e$21eb49f0$fe79a8c0@amd26>
References: <000501c42a1e$21eb49f0$fe79a8c0@amd26>
Message-ID: <409E5183.1030009@hhbio.wasser.tu-dresden.de>

Sonja Dornieden wrote:
> Hai -
> kann mir jemand sagen, wie ich den Modalwert in R berechne?! IRgendwie finde
> ich den Befehl nicht....
> greetz und herzlichen Dank
> Sonja

Hi,

there was already a thread in this list about this question with subject 
"Computing the mode" on 24.02.2004. You will find several answers in the 
R-Help archive:

https://www.stat.math.ethz.ch/pipermail/r-help/2004-February/

Thomas P.



From ggrothendieck at myway.com  Sun May  9 17:45:29 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 9 May 2004 15:45:29 +0000 (UTC)
Subject: [R] Using known errors and error bars
References: <2132.1084116263@www14.gmx.net>
Message-ID: <loom.20040509T174436-841@post.gmane.org>


See plotCI in package gregmisc.


Sebastian Schubert <Sebastian-Schubert <at> gmx.de> writes:

: 
: Hi, 
: 
: I'm now to R and hope (actually, I'm quite sure) you can help me. I made 
: an experiment and measured two values. As I know the errors of these 
: values I want to use them with the linear regression, 
: eg 
: Value A 
: 1.1+-0.02 
: 1.9+-0.05 
: 3.05+-0.03 
: 4.0+-0.01 
: 5.1+-0.06 
: 
: Value B 
: 4.2+-0.14 
: 5.3+-0.05 
: 6.8+-0.11 
: 7.9+-0.01 
: 8.5+-0.02 
: 
: lm(B~A) does the linear regression but how can I use the fact that 1.1 is 
: between 1.12 and 1.08? 
: How can I put error bars for A and B in the plot (like Excel is capable 
: of)? 
: 
: I hope I made myself understandable, 
: thanks 
: Sebastian 
: 
: --
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From ripley at stats.ox.ac.uk  Sun May  9 17:52:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 9 May 2004 16:52:19 +0100 (BST)
Subject: [R] Using known errors and error bars
In-Reply-To: <2132.1084116263@www14.gmx.net>
Message-ID: <Pine.LNX.4.44.0405091643290.10113-100000@gannet.stats>

What do you actually know?

You don't have `known errors', as if you did you could correct the values.
I doubt if you actually have a known range, more likely a standard error 
or a confidence interval.  (If you think you do have a known range, how do 
you know?)

And if A is not known exactly, linear regression is not fully appropriate.  
If you know standard errors, then you need a homoscedastic 
errors-in-variables formulation.  One early account is 

Ripley, B. D. and Thompson, M.(1987) Regression techniques for the 
detection of analytical bias. Analyst 112, 177-183.

and its Fortran program is still available, and although I have never
coded it in R, I believe others have.

On Sun, 9 May 2004, Sebastian Schubert wrote:

> I'm now to R and hope (actually, I'm quite sure) you can help me. I made 
> an experiment and measured two values. As I know the errors of these 
> values I want to use them with the linear regression, 
> eg 
> Value A 
> 1.1+-0.02 
> 1.9+-0.05 
> 3.05+-0.03 
> 4.0+-0.01 
> 5.1+-0.06 
>  
> Value B 
> 4.2+-0.14 
> 5.3+-0.05 
> 6.8+-0.11 
> 7.9+-0.01 
> 8.5+-0.02 
>  
> lm(B~A) does the linear regression but how can I use the fact that 1.1 is 
> between 1.12 and 1.08? 
> How can I put error bars for A and B in the plot (like Excel is capable 
> of)? 

Many ways, for example using arrows() or plotCI in package gregmisc.

> I hope I made myself understandable, 
> thanks 
> Sebastian 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Sun May  9 21:32:21 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 9 May 2004 12:32:21 -0700 (PDT)
Subject: [R] Getting the groupmean for each person
In-Reply-To: <loom.20040508T225858-512@post.gmane.org>
References: <200405082233.15813.atropin75@t-online.de>
	<loom.20040508T225858-512@post.gmane.org>
Message-ID: <Pine.A41.4.58.0405091219460.40030@homer37.u.washington.edu>

On Sat, 8 May 2004, Gabor Grothendieck wrote:

>
> predict(lm(AV~as.factor(GROUP)))


If Felix actually has a "huge" data frame this will be slow. Instead
try

groupmeans<-rowsum(AV,GROUP,reorder=FALSE)
individual.means<- groupmeans[match(GROUP, unique(GROUP)]

It uses hashing and takes roughly O(MGlogG) time for M measurements on G
groups, whereas the lm solution takes O(MG^3) [and the space requirements
are O(MG) and O(MG^2)]

Admittedly, with only 3000 observations either one will be fast enough.

	-thomas


>
>
>
> Felix Eschenburg <Atropin75 <at> t-online.de> writes:
>
> :
> : Hello list !
> :
> : I have a huge data.frame with several variables observed on about 3000
> : persons. For every person (row) there is variable called GROUP which indices
> : the group the person belongs to. There is also another variable AV for each
> : person. Now i want to create a new variable which holds the group mean of AV
> : as a value for each person.
> : With tapply(AV,GROUP,mean) i get the means for each level of GROUP, but i
> : cannot find out, how to give every person the groupmean as a value (every
> : person should have the same value as every other person in the same group).
> :
> : Has anybody any ideas how to do that ?
> :
> : Yours sincerly
> : Felix Eschenburg
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From maj at stats.waikato.ac.nz  Sun May  9 23:32:48 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Mon, 10 May 2004 09:32:48 +1200
Subject: [R] Modalwert
In-Reply-To: <409E5183.1030009@hhbio.wasser.tu-dresden.de>
References: <000501c42a1e$21eb49f0$fe79a8c0@amd26>
	<409E5183.1030009@hhbio.wasser.tu-dresden.de>
Message-ID: <409EA380.2040507@stats.waikato.ac.nz>

Off-topic, I know, but when I try to follow secure links like this in 
Mozilla, I always get a message "The connection was refused when trying 
to contact www.stat.math.ethz.ch" and I am forced to use Internet 
Explorer instead. This is under Windows XP.

Is this because www.stat.math.ethz.ch is using some non-standard 
Microsoft extensions of html? Or is it because my Mozilla 1.6 browser is 
wrongly configured?

Why are the mail archives on secure pages anyway?

Murray Jorgensen

Thomas Petzoldt wrote:
> Sonja Dornieden wrote:
> 
>> Hai -
>> kann mir jemand sagen, wie ich den Modalwert in R berechne?! IRgendwie 
>> finde
>> ich den Befehl nicht....
>> greetz und herzlichen Dank
>> Sonja
> 
> 
> Hi,
> 
> there was already a thread in this list about this question with subject 
> "Computing the mode" on 24.02.2004. You will find several answers in the 
> R-Help archive:
> 
> https://www.stat.math.ethz.ch/pipermail/r-help/2004-February/
> 
> Thomas P.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From andy_liaw at merck.com  Mon May 10 04:41:12 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 9 May 2004 22:41:12 -0400
Subject: [R] strange behavior of names<-
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D54@usrymx25.merck.com>

Dear R-help,

I've encounter what seems to me a strange problem with "names<-".  Suppose I
define the function:

fun <- function(x, f) {
    m <- tapply(x, f, mean)
    ans <- x - m[match(f, unique(f))]
    names(ans) <- names(x)
    ans
}

which subtract out the means of `x' grouped by `f' (which is the same as,
e.g., resid(lm(x~f)) if `f' is a factor).  If `x' does not have names, then
I'd expect the output of the function not to have names, as names(x) would
be NULL, and assigning NULL to names(ans) should wipe out the names of
`ans'.  However, I get:

> x = rnorm(20)
> f = factor(sample(rep(letters[1:4], 5)))
> fun(x, f)
          a           b           c           b           c           c
d 
-0.53791639  1.03704065  0.95727411  0.89219177 -0.04218746  0.57976675
-2.15799919 
          a           c           d           a           d           b
d 
 1.28422452 -0.92881186  0.40526262 -0.13471983 -0.72599709  1.68726680
-0.95420354 
          a           c           a           b           b           d 
-2.28013373  1.02522037  0.07728352  0.54321899  0.95742354 -1.68420455 

What am I missing?

[BTW, this is using the tip that Thomas Lumley posted about forming the
group means.  I've wanted to write a `tsweep' function that's sort of the
cross of tapply() and sweep().]

Best,
Andy Liaw, PhD
Biometrics Research      PO Box 2000, RY33-300     
Merck Research Labs           Rahway, NJ 07065
mailto:andy_liaw at merck.com        732-594-0820



From ok at cs.otago.ac.nz  Mon May 10 05:29:26 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Mon, 10 May 2004 15:29:26 +1200 (NZST)
Subject: [R] Colouring hclust() trees
Message-ID: <200405100329.i4A3TQhx204497@atlas.otago.ac.nz>

I have a data set with  6 variables and 251 cases.
The people who supplied me with this data set believe that it falls
naturally into three groups, and have given me a rule for determining
group number from these 6 variables.

If I do
    scaled.stuff <- scale(stuff, TRUE, c(...the design ranges...))
    stuff.dist <- dist(scaled.stuff)
    stuff.hc <- hclust(stuff.dist)
    plot(stuff.hc)
I get a dendrogram which looks sort of plausible, but

(a) with this many leaves, the leaf labels really aren't legible at any
    plausible scaling, and would be best omitted.  I could figure out
    which point was which if there were some way to use identify(), but
    I'm justnot seeing it.

(b) what I'd really like to do is to colour the leaves according to the
    predicted group, or some other variable.  The obvious thing to try is
    plot(stuff.hc, col=c("red","green","blue")[stuff.predicted.group])
    but that doesn't work.  I read everything that seemed plausible, and
    came across nodePar, but

    col <- c("red","green","blue")[stuff.predicted.group]
    plot(stuff.hc, nodePar=list(col=list("black",col)))

    tells me repeatedly that

    parameter "nodePar" couldn't be set in high-level plot() function 

    while 

    plot(as.dendrogram(hc), nodePar=list(col=list("black",col)))

    draws the dendrogram (_much_ slower than plot() does) and still gives
    me no colouring at all.  Clearly I have misunderstood how to use
    nodePar.

(c) The obvious fall-back is to use points() to draw the nodes again in
    the colours I want, but if I could do that, I could use identify().

The frustrating thing is that when I do

    d <- dim(stuff))[1]
    plot(1:d, 1:d, col=col[stuff.hc$order])

shows me that there _is_ a strong connection between the groups found by
hclust() and the predicted groups, albeit not a simple one.

I have looked at plot.dendrogram() and plotNode() -- using getAnywhere() --
and it looks to me as though what I want *should* be doable, but I've
clearly misunderstood the details of how to do it.



From maj at stats.waikato.ac.nz  Mon May 10 06:23:56 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Mon, 10 May 2004 16:23:56 +1200
Subject: [R] Modalwert
In-Reply-To: <409EA380.2040507@stats.waikato.ac.nz>
References: <000501c42a1e$21eb49f0$fe79a8c0@amd26>	<409E5183.1030009@hhbio.wasser.tu-dresden.de>
	<409EA380.2040507@stats.waikato.ac.nz>
Message-ID: <409F03DC.9060603@stats.waikato.ac.nz>

It was a proxy settings problem. All fixed now. Sorry to disturb the list.

Murray Jorgensen

Murray Jorgensen wrote:

> Off-topic, I know, but when I try to follow secure links like this in 
> Mozilla, I always get a message "The connection was refused when trying 
> to contact www.stat.math.ethz.ch" and I am forced to use Internet 
> Explorer instead. This is under Windows XP.
> 
> Is this because www.stat.math.ethz.ch is using some non-standard 
> Microsoft extensions of html? Or is it because my Mozilla 1.6 browser is 
> wrongly configured?
> 
> Why are the mail archives on secure pages anyway?
> 
> Murray Jorgensen
> 
> Thomas Petzoldt wrote:
> 
>> Sonja Dornieden wrote:
>>
>>> Hai -
>>> kann mir jemand sagen, wie ich den Modalwert in R berechne?! 
>>> IRgendwie finde
>>> ich den Befehl nicht....
>>> greetz und herzlichen Dank
>>> Sonja
>>
>>
>>
>> Hi,
>>
>> there was already a thread in this list about this question with 
>> subject "Computing the mode" on 24.02.2004. You will find several 
>> answers in the R-Help archive:
>>
>> https://www.stat.math.ethz.ch/pipermail/r-help/2004-February/
>>
>> Thomas P.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>>
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From ggrothendieck at myway.com  Mon May 10 06:58:49 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 10 May 2004 04:58:49 +0000 (UTC)
Subject: [R] strange behavior of names<-
References: <3A822319EB35174CA3714066D590DCD504AF7D54@usrymx25.merck.com>
Message-ID: <loom.20040510T065237-401@post.gmane.org>


Execute these two commands:
   ans <- fun(x,f)
   attributes(ans)

and you get this:

   $dim
   [1] 20

   $dimnames
   $dimnames[[1]]
[1] "a" "a" "b" "c" "a" "d" "a" "b" "d" "d" "a" "b" "d" "c" "c" "c" "b" "c" "b"
[20] "d"

so ans does not have names, it has dimnames.  If you try dimnames(ans) <- NULL
then its dimnames do get nulled out.  


Liaw, Andy <andy_liaw <at> merck.com> writes:

: 
: Dear R-help,
: 
: I've encounter what seems to me a strange problem with "names<-".  Suppose I
: define the function:
: 
: fun <- function(x, f) {
:     m <- tapply(x, f, mean)
:     ans <- x - m[match(f, unique(f))]
:     names(ans) <- names(x)
:     ans
: }
: 
: which subtract out the means of `x' grouped by `f' (which is the same as,
: e.g., resid(lm(x~f)) if `f' is a factor).  If `x' does not have names, then
: I'd expect the output of the function not to have names, as names(x) would
: be NULL, and assigning NULL to names(ans) should wipe out the names of
: `ans'.  However, I get:
: 
: > x = rnorm(20)
: > f = factor(sample(rep(letters[1:4], 5)))
: > fun(x, f)
:           a           b           c           b           c           c
: d 
: -0.53791639  1.03704065  0.95727411  0.89219177 -0.04218746  0.57976675
: -2.15799919 
:           a           c           d           a           d           b
: d 
:  1.28422452 -0.92881186  0.40526262 -0.13471983 -0.72599709  1.68726680
: -0.95420354 
:           a           c           a           b           b           d 
: -2.28013373  1.02522037  0.07728352  0.54321899  0.95742354 -1.68420455 
: 
: What am I missing?
: 
: [BTW, this is using the tip that Thomas Lumley posted about forming the
: group means.  I've wanted to write a `tsweep' function that's sort of the
: cross of tapply() and sweep().]
: 
: Best,
: Andy Liaw, PhD
: Biometrics Research      PO Box 2000, RY33-300     
: Merck Research Labs           Rahway, NJ 07065
: mailto:andy_liaw <at> merck.com        732-594-0820
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From ripley at stats.ox.ac.uk  Mon May 10 08:21:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 May 2004 07:21:55 +0100 (BST)
Subject: [R] strange behavior of names<-
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D54@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0405100717080.8309-100000@gannet.stats>

Remember tapply with a single factor in R returns a 1D array.  What you
are seeing are the dimnames, not the names: look at attributes() on your
return value (or even name() or str() on it).

I suspect you intended an as.vector() call in the formation of m.

Brian

On Sun, 9 May 2004, Liaw, Andy wrote:

> I've encounter what seems to me a strange problem with "names<-".  Suppose I
> define the function:
> 
> fun <- function(x, f) {
>     m <- tapply(x, f, mean)
>     ans <- x - m[match(f, unique(f))]
>     names(ans) <- names(x)
>     ans
> }
> 
> which subtract out the means of `x' grouped by `f' (which is the same as,
> e.g., resid(lm(x~f)) if `f' is a factor).  If `x' does not have names, then
> I'd expect the output of the function not to have names, as names(x) would
> be NULL, and assigning NULL to names(ans) should wipe out the names of
> `ans'.  However, I get:
> 
> > x = rnorm(20)
> > f = factor(sample(rep(letters[1:4], 5)))
> > fun(x, f)
>           a           b           c           b           c           c
> d 
> -0.53791639  1.03704065  0.95727411  0.89219177 -0.04218746  0.57976675
> -2.15799919 
>           a           c           d           a           d           b
> d 
>  1.28422452 -0.92881186  0.40526262 -0.13471983 -0.72599709  1.68726680
> -0.95420354 
>           a           c           a           b           b           d 
> -2.28013373  1.02522037  0.07728352  0.54321899  0.95742354 -1.68420455 
> 
> What am I missing?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Mon May 10 09:33:02 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 May 2004 09:33:02 +0200
Subject: [R] strange behavior of names<-
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D54@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7D54@usrymx25.merck.com>
Message-ID: <x2r7tsag9d.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> [BTW, this is using the tip that Thomas Lumley posted about forming the
> group means.  I've wanted to write a `tsweep' function that's sort of the
> cross of tapply() and sweep().]

Also notice that this is

unsplit(lapply(split(x, g), scale, scale=FALSE), g)

and the generalized sweep might be written along the lines of

unsplit(mapply("-",split(x,g),tapply(x,g,mean)),g)

Can't vouch for the speed, though.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From pallier at lscp.ehess.fr  Mon May 10 10:09:17 2004
From: pallier at lscp.ehess.fr (Christophe Pallier)
Date: Mon, 10 May 2004 10:09:17 +0200
Subject: [R] Getting the groupmean for each person
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D54@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7D54@usrymx25.merck.com>
Message-ID: <409F38AD.80305@lscp.ehess.fr>



Liaw, Andy wrote:

>Suppose I
>define the function:
>
>fun <- function(x, f) {
>    m <- tapply(x, f, mean)
>    ans <- x - m[match(f, unique(f))]
>    names(ans) <- names(x)
>    ans
>}
>
>  
>

May I ask what is the purpose of match(f,unique(f)) ?

To remove the group means, I have be using:

x-tapply(x,f,mean)[f]

for a while, (and I am now changing to 
x-tapply(x,f,mean)[as.character(f)] because of the peculiarities of 
indexing named vectors with factors )

The use of tapply(x,f,mean)[match(f,unique(f))] assumes a particular 
order in the result of tapply, no? It seems a bit dangerous to me.


Christophe Pallier



From rgazaffi at uol.com.br  Sun May  9 04:14:57 2004
From: rgazaffi at uol.com.br (Rodrigo)
Date: Sat, 8 May 2004 23:14:57 -0300
Subject: [R] need help: regression models
Message-ID: <000101c43679$e2521770$278762c8@rodrigog>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040508/8869bc91/attachment.pl

From Maarten.van.der.Hoeven at knmi.nl  Mon May 10 12:34:20 2004
From: Maarten.van.der.Hoeven at knmi.nl (Hoeven, Maarten van der)
Date: Mon, 10 May 2004 12:34:20 +0200
Subject: [R] sqlSave with underscores in table fieldname
Message-ID: <1F8990C21AC73945BE6AAC5AD6D4CAE934CC7C@BCSXAC.knmi.nl>

Hi group,

I try to write a frame to a table (RODBC). I use
	colnames(temp6) <- c("ind_id","ser_id","period_id","year","calc","mean")
	sqlSave(channel, temp6, tablename = "series_indices_test",append= TRUE, rownames=FALSE, verbose = FALSE, test = FALSE, nastring = -999999, fast = FALSE)

This is giving me an error:
	Error in sqlSave(channel, temp6, tablename = "series_indices_test", append = TRUE,  : 
        	unable to append to table %sseries_indices_test

My table definition is:
ind_id smallint(3) 
ser_id smallint(4)
period_id tinyint(2)
year smallint(4)
calc mediumint(6)
mean mediumint(6)

This error is related to the underscores I use in the table. Because, when I change the table definition to (removing underscores):

indid smallint(3) 
serid smallint(4)
periodid tinyint(2)
year smallint(4)
calc mediumint(6)
mean mediumint(6)

and execute
	colnames(temp6) <- c("indid","serid","periodid","year","calc","mean")
	sqlSave(channel, temp6, tablename = "series_indices_test",append= TRUE, rownames=FALSE, verbose = FALSE, test = FALSE, nastring = -999999, fast = FALSE)


it goes well.

Not using the underscores is not really prefered, as this table with this underscores in the definition is used on a lot of places elsewhere. But if removing the underscores is the only solution, let me know as well.


Any clue?

Using R 1.9.0, RODBC-package 1.4.0 (underlying database MySQL 4.0.16-standard)

Thanks,
Maarten


+-------------------------------
| Maarten van der Hoeven
| KNMI, De Bilt
| +31-30-2206 402
| maarten.van.der.hoeven at knmi.nl
+-------------------------------
-------------------------------------------------------------- 

Zie ook/see also: http://www.knmi.nl/maildisclaimer.html



From kjetil at acelerate.com  Mon May 10 12:41:00 2004
From: kjetil at acelerate.com (kjetil@acelerate.com)
Date: Mon, 10 May 2004 06:41:00 -0400
Subject: [R] Getting the groupmean for each person
In-Reply-To: <409F38AD.80305@lscp.ehess.fr>
References: <3A822319EB35174CA3714066D590DCD504AF7D54@usrymx25.merck.com>
Message-ID: <409F23FC.10272.E15E5@localhost>

On 10 May 2004 at 10:09, Christophe Pallier wrote:

> 
> 
> Liaw, Andy wrote:
> 
> >Suppose I
> >define the function:
> >
> >fun <- function(x, f) {
> >    m <- tapply(x, f, mean)
> >    ans <- x - m[match(f, unique(f))]
> >    names(ans) <- names(x)
> >    ans
> >}
> >
> >  
> >
> 
> May I ask what is the purpose of match(f,unique(f)) ?
> 
> To remove the group means, I have be using:
> 
> x-tapply(x,f,mean)[f]
> 
> for a while, (and I am now changing to 
> x-tapply(x,f,mean)[as.character(f)] because of the peculiarities of

wouldn't 
 sweep(as.array(x), 1, tapply(x,f,mean)[as.character(f)] , "-")

be more natural?

Kjetil Halvorsen

> indexing named vectors with factors )
> 
> The use of tapply(x,f,mean)[match(f,unique(f))] assumes a particular
> order in the result of tapply, no? It seems a bit dangerous to me.
> 
> 
> Christophe Pallier
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From stephan.moratti at uni-konstanz.de  Mon May 10 12:46:37 2004
From: stephan.moratti at uni-konstanz.de (Stephan Moratti)
Date: Mon, 10 May 2004 12:46:37 +0200
Subject: [R] trellis plot problem with R-1.9.0-1
Message-ID: <200405101246.37290.stephan.moratti@uni-konstanz.de>


I tried following commands:

amp~time|subject/trial   #this was the grouping structure of the data


plot(dip,inner=~condition,layout=c(2,2))

after the plot command I obtained this error message:

Error in if(!any(cond.max.level - cond.current.level <0)&&(row-1)* :   
missing value where TRUE/FALSE needed

This error only occured in compination with "layout". It was no problem to 
plot all subjects on one page. Further, this error did not occur using older 
version of R (1.8 or 1.7). Did somebody encounter similar problems ?

Stephan Moratti
-- 
Dipl. Psych. Stephan Moratti
Dept. of Psychology
University of Konstanz
P.O. Box D25
D-78457 Konstanz, Germany
Tel.: +49 (0) 7531 882385



From christian.lederer at imse.med.tu-muenchen.de  Mon May 10 14:16:51 2004
From: christian.lederer at imse.med.tu-muenchen.de (Christian Lederer)
Date: Mon, 10 May 2004 14:16:51 +0200
Subject: [R] cgi/servlets/httpd  in R
In-Reply-To: <644D9337A02FC24689647BF9E48EC39E08ABB7E6@drm556>
References: <644D9337A02FC24689647BF9E48EC39E08ABB7E6@drm556>
Message-ID: <409F72B3.7070008@imse.med.tu-muenchen.de>


This was my point. Using RSPerl with ordinary CGI of course starts
a new process for each request.
But using fastcgi uses the same perl process for new requests. So, if
you can use fastcgi in conjunction with RSPerl (which i did not try),
there would be no startup overhead anymore.

Christian


Samuelson, Frank* wrote:
> Here's a related question:  Do any of the mentioned R-web interfaces
> (Rweb, R-Online, CGIwithR, RSPerl) support reusing the same R process,
> eliminating the startup overhead?  This would be useful to me as well.
> 
> Currently I use such a method on my computing cluster:  All 40 
> compute nodes run an R process/compute server that listens at a socket for
> any 
> connection and subsequent commands from another computer. 
> When the master process disconnects, the R processes go back to listening
> at the socket.  Connecting to the R compute servers this way
> takes < 2 milliseconds rather than the typical ~2 second R startup time.
> 
> Thanks for any tips.
> 
> -Frank
> 
> 
> 
> -----Original Message-----
> From: Christian Lederer [mailto:christian.lederer at imse.med.tu-muenchen.de] 
> Sent: Thursday, May 06, 2004 10:04 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] cgi/servlets/httpd in R
> 
> 
> 
> Hi,
> 
> if found that the easiest way for me doing CGI with R was
> using the RSPerl package. So i could do all the CGI related things
> in Perl and call R functions from Perl to do the statistics.
> You can get RSPerl from http://www.omegahat.org.
> 
> If loading the data each time gives a performance problem,
> i guess that you could use RSPerl together with fastcgi,
> so the R initialization and loading the data would happen only
> once. If you try this, i would be very interrested in your experiences.
> 
> The RSPerl package is somewhat outdated, but it worked well together
> with R 1.6.0 (i didn't try newer versions).
> 
> Christian :-)
> 
> 
> 
> David Firth wrote:
> 
>>On Wednesday, May 5, 2004, at 18:09 Europe/London, foobar wrote:
>>
>>
>>>Hi R-helpers
>>>
>>>Has anyone had any experience doing CGI or Servlets or using an httpd 
>>>server in R?
>>>
>>>
>>
>>yes.  See the R FAQ, section 4.  (Or maybe you already have, in which 
>>case I misunderstood the question...)
>>
>>Best wishes,
>>David
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From jasont at indigoindustrial.co.nz  Mon May 10 13:00:35 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 10 May 2004 23:00:35 +1200 (NZST)
Subject: [R] need help: regression models
In-Reply-To: <000101c43679$e2521770$278762c8@rodrigog>
References: <000101c43679$e2521770$278762c8@rodrigog>
Message-ID: <49683.203.9.176.60.1084186835.squirrel@webmail.maxnet.co.nz>

"Rodrigo" <rgazaffi at uol.com.br> said:
> I am working with some data which i would like to find the best fit model
> for them.
> First, this data are in a matrix. Each of the columns are treatments and
> the raws are repetions for the each tratment.

Is the response in a separate vector, or is it one of the columns?

...
> Now, i need to find the best fit model for them, i know that exponetial or
> log model would be perfect in this situation (both can help me)

Exponential models:
library(survival)
?Surv
?survreg

is the first thing I think of.

Log-linear models:
?glm

For either:
?predict
?fitted

to get the values to plot on the boxplot.

Hope that helps

Cheers

Jason



From andy_liaw at merck.com  Mon May 10 13:37:29 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 10 May 2004 07:37:29 -0400
Subject: [R] Getting the groupmean for each person
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D57@usrymx25.merck.com>

Both of you might have missed my question from Friday:  For very long `x'
(e.g., length=50000), indexing by names can take a long time.  See that
thread for detail.  (For small data, you can hardly tell the difference.)

Also, I'm trying to write the function in a way that one can pass in more
than one grouping variables in a list, much like tapply.  The version I
shown is a simplified version to demonstrate the `problem' I had.  I
obviously missed the fact that tapply returns 1D array...

Best,
Andy

> From: kjetil at acelerate.com 
> 
> On 10 May 2004 at 10:09, Christophe Pallier wrote:
> 
> > 
> > 
> > Liaw, Andy wrote:
> > 
> > >Suppose I
> > >define the function:
> > >
> > >fun <- function(x, f) {
> > >    m <- tapply(x, f, mean)
> > >    ans <- x - m[match(f, unique(f))]
> > >    names(ans) <- names(x)
> > >    ans
> > >}
> > >
> > >  
> > >
> > 
> > May I ask what is the purpose of match(f,unique(f)) ?
> > 
> > To remove the group means, I have be using:
> > 
> > x-tapply(x,f,mean)[f]
> > 
> > for a while, (and I am now changing to 
> > x-tapply(x,f,mean)[as.character(f)] because of the peculiarities of
> 
> wouldn't 
>  sweep(as.array(x), 1, tapply(x,f,mean)[as.character(f)] , "-")
> 
> be more natural?
> 
> Kjetil Halvorsen
> 
> > indexing named vectors with factors )
> > 
> > The use of tapply(x,f,mean)[match(f,unique(f))] assumes a particular
> > order in the result of tapply, no? It seems a bit dangerous to me.
> > 
> > 
> > Christophe Pallier
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > 
> 
> 
> 
>



From ripley at stats.ox.ac.uk  Mon May 10 13:52:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 May 2004 12:52:59 +0100 (BST)
Subject: [R] Getting the groupmean for each person
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D57@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0405101247250.17989-100000@gannet.stats>

On Mon, 10 May 2004, Liaw, Andy wrote:

> Both of you might have missed my question from Friday:  For very long `x'
> (e.g., length=50000), indexing by names can take a long time.  See that
> thread for detail.  (For small data, you can hardly tell the difference.)

That's solved in R-devel as of this morning.  You need a million to see a 
significant time in indexing.

However, I think that in this case you should be indexing by the codes of 
a factor, as tapply is guaranteed to produce results in the order of the 
levels of f (after conversion to a factor).  So the natural way to index 
by a factor is the default one.

It may come as no surprise then that lda has code like

    group.means <- tapply(x, list(rep(g, p), col(x)), mean)
            X <- x - group.means[g, ]

where g is a factor.

> Also, I'm trying to write the function in a way that one can pass in more
> than one grouping variables in a list, much like tapply.  The version I
> shown is a simplified version to demonstrate the `problem' I had.  I
> obviously missed the fact that tapply returns 1D array...
> 
> Best,
> Andy
> 
> > From: kjetil at acelerate.com 
> > 
> > On 10 May 2004 at 10:09, Christophe Pallier wrote:
> > 
> > > 
> > > 
> > > Liaw, Andy wrote:
> > > 
> > > >Suppose I
> > > >define the function:
> > > >
> > > >fun <- function(x, f) {
> > > >    m <- tapply(x, f, mean)
> > > >    ans <- x - m[match(f, unique(f))]
> > > >    names(ans) <- names(x)
> > > >    ans
> > > >}
> > > >
> > > >  
> > > >
> > > 
> > > May I ask what is the purpose of match(f,unique(f)) ?
> > > 
> > > To remove the group means, I have be using:
> > > 
> > > x-tapply(x,f,mean)[f]
> > > 
> > > for a while, (and I am now changing to 
> > > x-tapply(x,f,mean)[as.character(f)] because of the peculiarities of
> > 
> > wouldn't 
> >  sweep(as.array(x), 1, tapply(x,f,mean)[as.character(f)] , "-")
> > 
> > be more natural?
> > 
> > Kjetil Halvorsen
> > 
> > > indexing named vectors with factors )
> > > 
> > > The use of tapply(x,f,mean)[match(f,unique(f))] assumes a particular
> > > order in the result of tapply, no? It seems a bit dangerous to me.
> > > 
> > > 
> > > Christophe Pallier

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From deepayan at stat.wisc.edu  Mon May 10 14:49:04 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 10 May 2004 07:49:04 -0500
Subject: [R] trellis plot problem with R-1.9.0-1
In-Reply-To: <200405101246.37290.stephan.moratti@uni-konstanz.de>
References: <200405101246.37290.stephan.moratti@uni-konstanz.de>
Message-ID: <200405100749.04254.deepayan@stat.wisc.edu>

On Monday 10 May 2004 05:46, Stephan Moratti wrote:
> I tried following commands:
>
> amp~time|subject/trial   #this was the grouping structure of the data
>
>
> plot(dip,inner=~condition,layout=c(2,2))
>
> after the plot command I obtained this error message:
>
> Error in if(!any(cond.max.level - cond.current.level <0)&&(row-1)* :
> missing value where TRUE/FALSE needed

This looks like a bug, but there's not enough information in your 
message to reproduce it. Could you send me (off-list) the data set, 
preferably saved with save(dip, file = "dip.rda") ?

Deepayan



From FWS4 at CDRH.FDA.GOV  Mon May 10 15:20:55 2004
From: FWS4 at CDRH.FDA.GOV (Samuelson, Frank*)
Date: Mon, 10 May 2004 09:20:55 -0400
Subject: [R] cgi/servlets/httpd  in R
Message-ID: <644D9337A02FC24689647BF9E48EC39E08ABB7E9@drm556>

Actually, what I have is probably not what you want, and I wrote
it as an example of what I was looking for, and what is probably possible. 
My code is just a hack of the snow socket code.

To answer your questions:
1.  The communication is done by serializing R objects.  That is,
the process connecting to the R compute nodes is an R process as 
well.  Not helpful in this situation.

2. Again, not what you want.  In the cluster every node has 1 R
job, and all get connected simultaneously until 
they're done computing, then released simultaneously.

2.5  No, see 1.

3.  You may have the code if you want, but like I said, you probably don't.

These recent posts gave some good information though:
https://www.stat.math.ethz.ch/pipermail/r-help/2004-May/049239.html
https://www.stat.math.ethz.ch/pipermail/r-help/2004-May/049321.html

I think RZope/RSOAP and/or Rserve may be what 
we're looking for.   They're not on CRAN and weren't listed in the faq.

-Frank


-----Original Message-----
From: wwsprague at ucdavis.edu [mailto:wwsprague at ucdavis.edu] 
Sent: Friday, May 07, 2004 12:50 PM
To: Samuelson, Frank*
Subject: Re: [R] cgi/servlets/httpd in R


Samuelson, Frank* wrote:


> Currently I use such a method on my computing cluster:  All 40 
> compute nodes run an R process/compute server that listens at a socket for
> any 
> connection and subsequent commands from another computer. 
> When the master process disconnects, the R processes go back to listening
> at the socket.  Connecting to the R compute servers this way
> takes < 2 milliseconds rather than the typical ~2 second R startup time.

Your solution seems what I am looking for, actually.  Questions:

1.  How do you communicate with an R process?  I can only think of 
embedded code like SQL in Perl.

2.  How do you find an R node that is open?

2.5  You are haveing cgi scripts connect to the R processes, right?  Or 
are the R processes available for another purpose?

3.  How much of your code are you willing to share :)?  We are 
interested in making demographic analysis tools available online 
(life-table-ish stuff to start with, then as much as we can get grant 
money for).

W



From julien.glenat at imag.fr  Mon May 10 15:29:42 2004
From: julien.glenat at imag.fr (Julien Glenat)
Date: Mon, 10 May 2004 15:29:42 +0200
Subject: [R] question about possibility with R - Tcl/tk library
Message-ID: <200405101328.i4ADS8fY017275@kama.imag.fr>


Hi , i am using the R(1.8.1)  tcl/tk library in order to build a graphical 
user interface to mathematic function and i would like to know if it is 
possible to retrieve the value of a  tkentry to make a R vector

for exemple with an entry containing "1,2,3,4,5" i want to make a vector 
which contains 1 2 3 4 5 

i tried as.vector , as.list and even to write the object to a file with 
write.table and then re reading it with read.table(...,sep=",")
but nothing worked
so if you have an idea....

Thanks for any tips



From talitaperciano at hotmail.com  Mon May 10 15:52:23 2004
From: talitaperciano at hotmail.com (Talita Leite)
Date: Mon, 10 May 2004 10:52:23 -0300
Subject: [R] Model names - model-based clustering
Message-ID: <BAY14-F16eo6fQSgeR400022038@hotmail.com>

Hello!

Please, somebody could explain me what exactly means that model names? For 
example "VVV": ellipsoidal, varying volume, shape, and orientation. Thanks.



Talita Perciano Costa Leite
Graduanda em Ci??ncia da Computa????o
Universidade Federal de Alagoas - UFAL
Departamento de Tecnologia da Informa????o - TCI
Constru????o de Conhecimento por Agrupamento de Dados - CoCADa



From tlumley at u.washington.edu  Mon May 10 15:56:28 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 10 May 2004 06:56:28 -0700 (PDT)
Subject: [R] strange behavior of names<-
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D54@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7D54@usrymx25.merck.com>
Message-ID: <Pine.A41.4.58.0405100654060.93038@homer40.u.washington.edu>

On Sun, 9 May 2004, Liaw, Andy wrote:

> Dear R-help,
>
> I've encounter what seems to me a strange problem with "names<-".  Suppose I
> define the function:
>
> fun <- function(x, f) {
>     m <- tapply(x, f, mean)
>     ans <- x - m[match(f, unique(f))]
>     names(ans) <- names(x)
>     ans
> }
>
> which subtract out the means of `x' grouped by `f' (which is the same as,
> e.g., resid(lm(x~f)) if `f' is a factor).  If `x' does not have names, then
> I'd expect the output of the function not to have names, as names(x) would
> be NULL, and assigning NULL to names(ans) should wipe out the names of
> `ans'.  However, I get:

That's because ans is a 1-d matrix, not a vector. If you want ans to be a
vector you need
	ans <- as.vector(x-m[match(f, unique(f))])
	names(ans)<-names(x)

	-thomas



From tlumley at u.washington.edu  Mon May 10 15:59:48 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 10 May 2004 06:59:48 -0700 (PDT)
Subject: [R] Getting the groupmean for each person
In-Reply-To: <409F38AD.80305@lscp.ehess.fr>
References: <3A822319EB35174CA3714066D590DCD504AF7D54@usrymx25.merck.com>
	<409F38AD.80305@lscp.ehess.fr>
Message-ID: <Pine.A41.4.58.0405100658170.93038@homer40.u.washington.edu>

On Mon, 10 May 2004, Christophe Pallier wrote:
>
> The use of tapply(x,f,mean)[match(f,unique(f))] assumes a particular
> order in the result of tapply, no? It seems a bit dangerous to me.
>

My original code for the group means problem used rowsum(,reorder=FALSE)
rather than tapply(), and we do know that this produces the same order as
unique().

	-thomas



From p.dalgaard at biostat.ku.dk  Mon May 10 16:03:08 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 May 2004 16:03:08 +0200
Subject: [R] question about possibility with R - Tcl/tk library
In-Reply-To: <200405101328.i4ADS8fY017275@kama.imag.fr>
References: <200405101328.i4ADS8fY017275@kama.imag.fr>
Message-ID: <x2r7tsqt0j.fsf@biostat.ku.dk>

Julien Glenat <julien.glenat at imag.fr> writes:

> Hi , i am using the R(1.8.1)  tcl/tk library in order to build a graphical 
> user interface to mathematic function and i would like to know if it is 
> possible to retrieve the value of a  tkentry to make a R vector
> 
> for exemple with an entry containing "1,2,3,4,5" i want to make a vector 
> which contains 1 2 3 4 5 
> 
> i tried as.vector , as.list and even to write the object to a file with 
> write.table and then re reading it with read.table(...,sep=",")
> but nothing worked
> so if you have an idea....

Nothing to do with tcl/tk really. You have a character sting and want
a numeric vector:

> txt <- "1,2,3,4,5"
> as.numeric(strsplit(txt,",")[[1]])
[1] 1 2 3 4 5
> scan(textConnection(txt),sep=",")
Read 5 items
[1] 1 2 3 4 5

(possibly add quiet=TRUE in the latter case to get rid of the message)

Actually, now that you obviously have the string as a Tcl object and a
Tcl interpreter running, you might do the split on the Tcl side:

> x <- as.tclObj("1,2,3,4,5")
> as.numeric(tkcmd("split", x, ","))
[1] 1 2 3 4 5


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From aedin.culhane at ucd.ie  Mon May 10 16:09:05 2004
From: aedin.culhane at ucd.ie (aedin culhane)
Date: Mon, 10 May 2004 15:09:05 +0100 (IST)
Subject: [R] Solve for "Please set TMPDIR to a valid temporary directory"
Message-ID: <4858782.1084198145953.JavaMail.aedin.culhane@ucd.ie>

Dear R Help,
My apologies if this is widely known, but I didn't find this in the R 
archives. 

I am running WinXP pro and R 1.90.  Rcmd build or check fails with the 
error: "Please set TMPDIR to a valid temporary directory"

$TMPDIR is set to $TMPDIR or C:/TEMP in share\perl\R\Var.pm.  TMPDIR or 
c:\temp do not exist on WinXP on my laptop. I have C:\WUTemp and the 
env variables $TMP and $TEMP are set (..Is this normal?).  

The two work arounds I found are to create a C:\temp directory, or 
include $TMP or $TEMP in Var.pm. I did the latter, and it works for me. 
I include the fix below.


if($OSTYPE eq "windows"){
    ## DON'T add R_HOME/bin here: it might contain spaces and will not
    ## work using system() under Windows 98. 
    $R_EXE = "Rterm.exe";
    $R_CMD = "Rcmd.exe";
    getenv("TMPDIR", "TMP", "TEMP", "C:/TEMP"); # Edited to include TMP 
and TEMP
    print "tmpdir is $TMPDIR\n";   # Edited to include print
    if (-d $TMPDIR) {
	$TMPDIR = Win32::GetShortPathName($TMPDIR) if $TMPDIR =~ / /;
	$TMPDIR =~ s+\\+/+g;  ## ensure forward slashes only
    } else {
	$TMPDIR = "" 
    }
}


> version
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.0
year     2004
month    04
day      12
language R


Regards
Aedin



From ligges at statistik.uni-dortmund.de  Mon May 10 16:13:33 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 May 2004 16:13:33 +0200
Subject: [R] Solve for "Please set TMPDIR to a valid temporary directory"
In-Reply-To: <4858782.1084198145953.JavaMail.aedin.culhane@ucd.ie>
References: <4858782.1084198145953.JavaMail.aedin.culhane@ucd.ie>
Message-ID: <409F8E0D.8030409@statistik.uni-dortmund.de>

aedin culhane wrote:

> Dear R Help,
> My apologies if this is widely known, but I didn't find this in the R 
> archives. 
> 
> I am running WinXP pro and R 1.90.  Rcmd build or check fails with the 
> error: "Please set TMPDIR to a valid temporary directory"

OK. So why do you not set an environment variable TMPDIR=C:\Windows\temp
(which is the standard temp directory on Windows XP)?

Uwe Ligges


> $TMPDIR is set to $TMPDIR or C:/TEMP in share\perl\R\Var.pm.  TMPDIR or 
> c:\temp do not exist on WinXP on my laptop. I have C:\WUTemp and the 
> env variables $TMP and $TEMP are set (..Is this normal?).  
> 
> The two work arounds I found are to create a C:\temp directory, or 
> include $TMP or $TEMP in Var.pm. I did the latter, and it works for me. 
> I include the fix below.
> 
> 
> if($OSTYPE eq "windows"){
>     ## DON'T add R_HOME/bin here: it might contain spaces and will not
>     ## work using system() under Windows 98. 
>     $R_EXE = "Rterm.exe";
>     $R_CMD = "Rcmd.exe";
>     getenv("TMPDIR", "TMP", "TEMP", "C:/TEMP"); # Edited to include TMP 
> and TEMP
>     print "tmpdir is $TMPDIR\n";   # Edited to include print
>     if (-d $TMPDIR) {
> 	$TMPDIR = Win32::GetShortPathName($TMPDIR) if $TMPDIR =~ / /;
> 	$TMPDIR =~ s+\\+/+g;  ## ensure forward slashes only
>     } else {
> 	$TMPDIR = "" 
>     }
> }
> 
> 
> 
>>version
> 
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    9.0
> year     2004
> month    04
> day      12
> language R
> 
> 
> Regards
> Aedin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Heike.Schmitt at rivm.nl  Mon May 10 16:15:07 2004
From: Heike.Schmitt at rivm.nl (Heike Schmitt)
Date: Mon, 10 May 2004 16:15:07 +0200
Subject: [R] environmental data  as vector in PCA plots
Message-ID: <OF35E4EFFE.1F766D93-ONC1256E90.004E4981-C1256E90.004E49E6@rivm.nl>

Hi,
I want to include a vector representing the sites - environmental data
correlation in a PCA.
I currently use prcomp (no scaling) to perform the PCA, and envfit to
retrieve the coordinates of the environmental data vector. However, the
vector length is different from the one obtained in CAnoco when performing
a species - environmental biplot (scaling -2). How can I scale the vector
in order to be in accordance with Canoco, or which other scaling options
are there?


Thanks for help,
Heike


____________________________________________________________________________

"Dit bericht en eventuele aangehechte bestanden zijn vertrouwelijk en
uitsluitend bestemd voor de geadresseerde. Ongeautoriseerde verstrekking of
bekendmaking aan en gebruik door anderen zijn niet toegestaan. Als u dit
bericht per vergissing hebt ontvangen wordt u verzocht dit onmiddellijk aan
de afzender te melden en het bericht van uw systemen te verwijderen.
De werkgever van de afzender kan niet garanderen dat de verzonden en/of
ontvangen informatie juist is en aanvaardt geen aansprakelijkheid voor
schade die eruit kan voortvloeien."

"This message and any files transmitted with it may contain confidential
information and is solely intended for the addressee(s). Any unauthorized
disclosure or actions taken in reliance on it are forbidden. If you have
received this message in error, please delete it and notify the sender.
The employer of the sender does not guarantee that the information sent
and/or received is correct and does not accept any liability for damages
related thereto."



From talitaperciano at hotmail.com  Mon May 10 16:17:10 2004
From: talitaperciano at hotmail.com (Talita Leite)
Date: Mon, 10 May 2004 11:17:10 -0300
Subject: [R] function me
Message-ID: <BAY14-F35D3BktHbLUn000223d5@hotmail.com>

Hi!

Talking about the function me. One of the result values of this funtion is 
the loglik. I want to understand better what is this. Sombody could help me?



Talita Perciano Costa Leite
Graduanda em Ci??ncia da Computa????o
Universidade Federal de Alagoas - UFAL
Departamento de Tecnologia da Informa????o - TCI
Constru????o de Conhecimento por Agrupamento de Dados - CoCADa



From d.orme at imperial.ac.uk  Mon May 10 16:26:21 2004
From: d.orme at imperial.ac.uk (David Orme)
Date: Mon, 10 May 2004 15:26:21 +0100
Subject: [R] Lists and outer() like functionality?
Message-ID: <025FBC02-A28E-11D8-BC9C-000393DC1748@ic.ac.uk>

Hi,

I'm have a list of integer vectors and I want to perform an outer() 
like operation on the list. As an example, take the following list:

mylist <- list(1:5,3:9,8:12)

A simple example of the kind of thing I want to do is to find the sum 
of the shared numbers between each vector to give a result like:

result <- array(c(15,12,0,12,42,17,0,17,50), dim=c(3,3))

Two for() loops is the easiest way but I wondered if there was a 
neater/faster solution.

mylist.len <- length(mylist)
ind <- 1:mylist.len
result <- array(NA, dim=c(mylist.len,mylist.len))
for(x in ind){
   for(y in ind){
     result[x,y] <- sum(mylist[[x]][test[[x]] %in% test[[y]]])
   }
}


Many thanks,
David Orme



From p.dalgaard at biostat.ku.dk  Mon May 10 16:39:11 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 May 2004 16:39:11 +0200
Subject: [R] Lists and outer() like functionality?
In-Reply-To: <025FBC02-A28E-11D8-BC9C-000393DC1748@ic.ac.uk>
References: <025FBC02-A28E-11D8-BC9C-000393DC1748@ic.ac.uk>
Message-ID: <x2hduoqrcg.fsf@biostat.ku.dk>

David Orme <d.orme at imperial.ac.uk> writes:

> Hi,
> 
> I'm have a list of integer vectors and I want to perform an outer()
> like operation on the list. As an example, take the following list:
> 
> mylist <- list(1:5,3:9,8:12)
> 
> A simple example of the kind of thing I want to do is to find the sum
> of the shared numbers between each vector to give a result like:
> 
> result <- array(c(15,12,0,12,42,17,0,17,50), dim=c(3,3))
> 
> Two for() loops is the easiest way but I wondered if there was a
> neater/faster solution.
> 
> mylist.len <- length(mylist)
> ind <- 1:mylist.len
> result <- array(NA, dim=c(mylist.len,mylist.len))
> for(x in ind){
>    for(y in ind){
>      result[x,y] <- sum(mylist[[x]][test[[x]] %in% test[[y]]])
>    }
> }
> 

How about


> mysum <- function(x,y)mapply(function(x,y)sum(intersect(x,y)),x,y)
> outer(l,l,mysum)
     [,1] [,2] [,3]
[1,]   15   12    0
[2,]   12   42   17
[3,]    0   17   50


(notice that your problem really isn't that you have a list, but that
you have functions that don't vectorize over lists.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jasont at indigoindustrial.co.nz  Mon May 10 16:45:48 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 11 May 2004 02:45:48 +1200 (NZST)
Subject: [R] Lists and outer() like functionality?
In-Reply-To: <025FBC02-A28E-11D8-BC9C-000393DC1748@ic.ac.uk>
References: <025FBC02-A28E-11D8-BC9C-000393DC1748@ic.ac.uk>
Message-ID: <54783.203.9.176.60.1084200348.squirrel@webmail.maxnet.co.nz>

"David Orme" <d.orme at imperial.ac.uk> wrote:
...
> I'm have a list of integer vectors and I want to perform an outer()
> like operation on the list. As an example, take the following list:
>
> mylist <- list(1:5,3:9,8:12)
>
> A simple example of the kind of thing I want to do is to find the sum
> of the shared numbers between each vector to give a result like:
>
> result <- array(c(15,12,0,12,42,17,0,17,50), dim=c(3,3))
>
> Two for() loops is the easiest way but I wondered if there was a
> neater/faster solution.
>
> mylist.len <- length(mylist)
> ind <- 1:mylist.len
> result <- array(NA, dim=c(mylist.len,mylist.len))
> for(x in ind){
>    for(y in ind){
>      result[x,y] <- sum(mylist[[x]][test[[x]] %in% test[[y]]])
>    }
> }
>

I'm having a hard time figuring out what you want.  Who is this mystery
object "test"?  When I drop "test" from the text, and use:

result[x,y] <- sum(mylist[[x]] %in% mylist[[y]])

It doesn't give a syntax error, but the result is nothing like the one you
posted above.

As a style point, ind <- seq(along=mylist) is a bit more foolproof in the
case of empty lists being accidentally passed to the code (been bitten
that way once or twice).

Cheers

Jason



From d.orme at imperial.ac.uk  Mon May 10 17:42:41 2004
From: d.orme at imperial.ac.uk (David Orme)
Date: Mon, 10 May 2004 16:42:41 +0100
Subject: [R] Lists and outer() like functionality?
In-Reply-To: <54783.203.9.176.60.1084200348.squirrel@webmail.maxnet.co.nz>
References: <025FBC02-A28E-11D8-BC9C-000393DC1748@ic.ac.uk>
	<54783.203.9.176.60.1084200348.squirrel@webmail.maxnet.co.nz>
Message-ID: <ABE51934-A298-11D8-BC9C-000393DC1748@ic.ac.uk>


On 10 May 2004, at 15:45, Jason Turner wrote:

>
> I'm having a hard time figuring out what you want.  Who is this mystery
> object "test"?

Ah - sorry all. That should be:

for(x in ind){
    for(y in ind){
      result[x,y] <- sum(mylist[[x]][mylist[[x]] %in% mylist[[y]]])
    }
}

>
> As a style point, ind <- seq(along=mylist) is a bit more foolproof in 
> the
> case of empty lists being accidentally passed to the code (been bitten
> that way once or twice).
>

Yup - thanks for the hint.

Following up on Peter Dalgaard's suggestion, I've tried vectorizing the 
function properly. Now I get the same answers from both the two for() 
loops and the vectorized outer() call. What puzzles me slightly is that 
using outer is about 13 times slower. I realize that
loops aren't always bad but it seems odd that this should be so much 
slower. Have I got something wrong (the function phylo.overlap probably 
isn't optimal but this should effect relative timings)?

Thanks,
David



myfunc <- function(x,y){mapply 
function(x,y){phylo.overlap(x,y,parrot.cm)},x,y)}
 > system.time(outer.test <- outer(assemblages, assemblages, myfunc))
[1] 62.99  0.25 63.35  0.00  0.00
 > x[1:10,1:5]
       19916 19917 20275 20992 22787 23008 23009 23145 23146 23147
19916 17466 16443 17397 14368 12687     0     0  8396  9843 12687
19917 16443 17032 16374 14368 12687     0     0  8396  9843 12687
20275 17397 16374 18420 15391 13710     0     0  8396 10866 13710
20992 14368 14368 15391 19735 17812     0     0 10452 14968 17812
22787 12687 12687 13710 17812 19908     0     0 12548 17064 19908

 > assemblage.len <- length(assemblages)
 > ind <- seq(along=assemblages)
 > loop.test <- array(dim=c(assemblage.len,assemblage.len))
 >
 > system.time(
+ for(x in ind){
+         if(x %% 100 == 0) cat(x,"\n")
+         for(y in ind){
+                 loop.test[x,y] <- phylo.overlap(assemblages[[x]], 
assemblages[[y]], parrot.cm)
+         }
+ }
+ )
[1] 4.34 0.17 4.52 0.00 0.00
 > result[1:10,1:5]
        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
  [1,] 17466 16443 17397 14368 12687     0     0  8396  9843 12687
  [2,] 16443 17032 16374 14368 12687     0     0  8396  9843 12687
  [3,] 17397 16374 18420 15391 13710     0     0  8396 10866 13710
  [4,] 14368 14368 15391 19735 17812     0     0 10452 14968 17812
  [5,] 12687 12687 13710 17812 19908     0     0 12548 17064 19908

 >



From p.dalgaard at biostat.ku.dk  Mon May 10 17:56:10 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 May 2004 17:56:10 +0200
Subject: [R] Lists and outer() like functionality?
In-Reply-To: <ABE51934-A298-11D8-BC9C-000393DC1748@ic.ac.uk>
References: <025FBC02-A28E-11D8-BC9C-000393DC1748@ic.ac.uk>
	<54783.203.9.176.60.1084200348.squirrel@webmail.maxnet.co.nz>
	<ABE51934-A298-11D8-BC9C-000393DC1748@ic.ac.uk>
Message-ID: <x2ad0gqns5.fsf@biostat.ku.dk>

David Orme <d.orme at imperial.ac.uk> writes:

> Following up on Peter Dalgaard's suggestion, I've tried vectorizing
> the function properly. Now I get the same answers from both the two
> for() loops and the vectorized outer() call. What puzzles me slightly
> is that using outer is about 13 times slower. I realize that
> loops aren't always bad but it seems odd that this should be so much
> slower. Have I got something wrong (the function phylo.overlap
> probably isn't optimal but this should effect relative timings)?


outer() generally works by expanding out the lists like

Y <- rep(y,length(x))
X <- rep(x,each=length(y)) # or maybe it's vice versa, never mind...
FUN(X,Y,extras)

and then adds dims and dimnames. If FUN vectorizes, this is the
efficient way, but it does not in your case and the rep()s are
probably not cheap when lists are involved.

you might try this sort of stuff:

myfunc2 <- function(i,j)
    mapply(function(i,j)
             phylo.overlap(assemblages[[i]],assemblages[[j]],parrot.cm),
           i,j)
ind <- seq(along=assemblages)
outer(ind,ind,myfunc2)


> myfunc <- function(x,y){mapply
> function(x,y){phylo.overlap(x,y,parrot.cm)},x,y)}
>  > system.time(outer.test <- outer(assemblages, assemblages, myfunc))
> [1] 62.99  0.25 63.35  0.00  0.00
>  > x[1:10,1:5]
>        19916 19917 20275 20992 22787 23008 23009 23145 23146 23147
> 19916 17466 16443 17397 14368 12687     0     0  8396  9843 12687
> 19917 16443 17032 16374 14368 12687     0     0  8396  9843 12687
> 20275 17397 16374 18420 15391 13710     0     0  8396 10866 13710
> 20992 14368 14368 15391 19735 17812     0     0 10452 14968 17812
> 22787 12687 12687 13710 17812 19908     0     0 12548 17064 19908
> 
>  > assemblage.len <- length(assemblages)
>  > ind <- seq(along=assemblages)
>  > loop.test <- array(dim=c(assemblage.len,assemblage.len))
>  >
>  > system.time(
> + for(x in ind){
> +         if(x %% 100 == 0) cat(x,"\n")
> +         for(y in ind){
> +                 loop.test[x,y] <- phylo.overlap(assemblages[[x]],
> assemblages[[y]], parrot.cm)
> +         }
> + }
> + )
> [1] 4.34 0.17 4.52 0.00 0.00
>  > result[1:10,1:5]
>         [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
>   [1,] 17466 16443 17397 14368 12687     0     0  8396  9843 12687
>   [2,] 16443 17032 16374 14368 12687     0     0  8396  9843 12687
>   [3,] 17397 16374 18420 15391 13710     0     0  8396 10866 13710
>   [4,] 14368 14368 15391 19735 17812     0     0 10452 14968 17812
>   [5,] 12687 12687 13710 17812 19908     0     0 12548 17064 19908
> 
>  >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From d.orme at imperial.ac.uk  Mon May 10 18:16:16 2004
From: d.orme at imperial.ac.uk (David Orme)
Date: Mon, 10 May 2004 17:16:16 +0100
Subject: [R] Lists and outer() like functionality?
In-Reply-To: <x2ad0gqns5.fsf@biostat.ku.dk>
References: <025FBC02-A28E-11D8-BC9C-000393DC1748@ic.ac.uk>
	<54783.203.9.176.60.1084200348.squirrel@webmail.maxnet.co.nz>
	<ABE51934-A298-11D8-BC9C-000393DC1748@ic.ac.uk>
	<x2ad0gqns5.fsf@biostat.ku.dk>
Message-ID: <5D30B42A-A29D-11D8-BC9C-000393DC1748@ic.ac.uk>

>
> outer() generally works by expanding out the lists like
>
> Y <- rep(y,length(x))
> X <- rep(x,each=length(y)) # or maybe it's vice versa, never mind...
> FUN(X,Y,extras)
>
> and then adds dims and dimnames. If FUN vectorizes, this is the
> efficient way, but it does not in your case and the rep()s are
> probably not cheap when lists are involved.
>
> you might try this sort of stuff:
>
> myfunc2 <- function(i,j)
>     mapply(function(i,j)
>              
> phylo.overlap(assemblages[[i]],assemblages[[j]],parrot.cm),
>            i,j)
> ind <- seq(along=assemblages)
> outer(ind,ind,myfunc2)
>

That now runs at about the same speed as the loops (although the loops 
still just have the edge).

Many thanks for the suggestions.

David



From wwsprague at ucdavis.edu  Mon May 10 18:15:53 2004
From: wwsprague at ucdavis.edu (Webb Sprague)
Date: Mon, 10 May 2004 09:15:53 -0700
Subject: [R] "#!/usr/bin/R"
Message-ID: <c7o9vj$vlp$1@sea.gmane.org>

Hi all,

Is there any documentation on running R like one would run a shell or 
Perl script, with out/input directed appropriately, environment variable 
access, and command switch processing?

I looked some, and even remembered to check the FAQ, but couldn't find 
anything.

Thanks
W



From jari.oksanen at oulu.fi  Mon May 10 18:09:16 2004
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Mon, 10 May 2004 19:09:16 +0300
Subject: [R] environmental data  as vector in PCA plots
In-Reply-To: <OF35E4EFFE.1F766D93-ONC1256E90.004E4981-C1256E90.004E49E6@rivm.nl>
References: <OF35E4EFFE.1F766D93-ONC1256E90.004E4981-C1256E90.004E49E6@rivm.nl>
Message-ID: <629D19E0-A29C-11D8-B2E8-000A95C76CA8@oulu.fi>


On 10 May 2004, at 17:15, Heike Schmitt wrote:

> I want to include a vector representing the sites - environmental data
> correlation in a PCA.
> I currently use prcomp (no scaling) to perform the PCA, and envfit to
> retrieve the coordinates of the environmental data vector. However, the
> vector length is different from the one obtained in CAnoco when 
> performing
> a species - environmental biplot (scaling -2). How can I scale the 
> vector
> in order to be in accordance with Canoco, or which other scaling 
> options
> are there?

Canoco scaling abs(2) does not scale sites, but the sum of squares of 
site scores = 1 for all axes. In contrast, prcomp scales site axes by 
eigenvalue, like does Canoco with scaling abs(1). Therefore you cannot 
get similar results as in Canoco. A simple solution that *may* (or may 
not) work is to transpose your data: instead of prcomp(x), try 
prcomp(t(scale(x, scale=F), center=F). This does the centring to the 
columns of x (like it should be done), then transposes your data and 
prcomp's without  new centring -- which was already made for columns (I 
didn't test this, but this way it was done in the olden times). Another 
alternative is to use the function rda in the same package where you 
found envfit (vegan), since it is not unlike Canoco in its scaling. 
However, it won't give you negative scalings of PCA (RDA without 
constraints), since its author (that's I) thinks that you shouldn't use 
negative scaling of Canoco in RDA/PCA. The package ships with a pdf 
document which discusses PCA scaling in prcomp, princomp, rda (of 
vegan) and Canoco (of Cajo ter Braak), and even hints how to get the 
minus scalings that the author doesn't approve.

cheers, jari oksanen
--
Jari Oksanen, Oulu, Finland



From andy_liaw at merck.com  Mon May 10 18:26:07 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 10 May 2004 12:26:07 -0400
Subject: [R] "#!/usr/bin/R"
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D5C@usrymx25.merck.com>

Someone had modified the R source to handle this, but it has not been
incorporated into the official R source, if I'm not mistaken.  Search the
R-devel archive.

HTH,
Andy

> From: Webb Sprague
> 
> Hi all,
> 
> Is there any documentation on running R like one would run a shell or 
> Perl script, with out/input directed appropriately, 
> environment variable 
> access, and command switch processing?
> 
> I looked some, and even remembered to check the FAQ, but 
> couldn't find 
> anything.
> 
> Thanks
> W


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From revelle at northwestern.edu  Mon May 10 18:28:39 2004
From: revelle at northwestern.edu (William Revelle)
Date: Mon, 10 May 2004 11:28:39 -0500
Subject: [R] problem with loadURL -- claims newer version used
Message-ID: <p0601021dbcc5598a4559@[66.239.20.171]>

Dear list,

I am trying to prepare a handout showing how to use R for factor 
analysis.  As part of the exercise I want to save a correlation 
matrix on a tutorial web page.  I can save with no problem (saving 
locally and then transferring to the web site).  Although I can 
load() the local file, I am having problems getting loadURL to read 
the remote file.   I have tried saving it as an ascii file or just 
using the default format.

Using R 1.9.0 on a Mac with OS 10.3


I first saved the file:
save(big5r,file="big5r.txt",ascii=TRUE)
and
save(big5r,file="big5r")
I can load either version from a local file using load().

I then have moved these files to a webserver and tried to load them 
using the loadURL() command.

Using loadURL() I get the following message

  >loadURL("http://personality-project.org/r/datasets/big5r") 
#the default format
Error: restore file may be from a newer version of R -- no data loaded
>loadURL("http://personality-project.org/r/datasets/big5r.txt")   #ascii format
Error: restore file may be from a newer version of R -- no data loaded

I  can list the second file using a web browser and I can move the 
first file back to my machine and load it locally.
My problem seems to be with loadURL.

Any help would be appreciated.

Bill


-- 
----------------------------
William Revelle               http://pmc.psych.northwestern.edu/revelle.html
Department of Psychology, Northwestern University
Personality Project: http://personality-project.org/personality.html



From p.dalgaard at biostat.ku.dk  Mon May 10 18:52:23 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 May 2004 18:52:23 +0200
Subject: [R] "#!/usr/bin/R"
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D5C@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7D5C@usrymx25.merck.com>
Message-ID: <x265b4ql6g.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> Someone had modified the R source to handle this, but it has not been
> incorporated into the official R source, if I'm not mistaken.  Search the
> R-devel archive.

You can do stuff like this though:

>cat test.R
#!/bin/sh
tail +3 "$0" | R --vanilla --args $@ ; exit $?
x <- 2+2
x
ls()
print(x)
commandArgs()


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Mon May 10 19:20:46 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 May 2004 18:20:46 +0100 (BST)
Subject: [R] problem with loadURL -- claims newer version used
In-Reply-To: <p0601021dbcc5598a4559@[66.239.20.171]>
Message-ID: <Pine.LNX.4.44.0405101811300.18944-100000@gannet.stats>

big5r.txt is delimited by CR not LF, and as R writes it as a binary file, 
that's not the file that got saved.

Same problem with the header on big5r.  

Try some octal dumps and find out which step is changing the file.

BTW, I would use load(url(someURL)) these days.

On Mon, 10 May 2004, William Revelle wrote:

> Dear list,
> 
> I am trying to prepare a handout showing how to use R for factor 
> analysis.  As part of the exercise I want to save a correlation 
> matrix on a tutorial web page.  I can save with no problem (saving 
> locally and then transferring to the web site).  Although I can 
> load() the local file, I am having problems getting loadURL to read 
> the remote file.   I have tried saving it as an ascii file or just 
> using the default format.
> 
> Using R 1.9.0 on a Mac with OS 10.3
> 
> 
> I first saved the file:
> save(big5r,file="big5r.txt",ascii=TRUE)
> and
> save(big5r,file="big5r")
> I can load either version from a local file using load().
> 
> I then have moved these files to a webserver and tried to load them 
> using the loadURL() command.
> 
> Using loadURL() I get the following message
> 
>   >loadURL("http://personality-project.org/r/datasets/big5r") 
> #the default format
> Error: restore file may be from a newer version of R -- no data loaded
> >loadURL("http://personality-project.org/r/datasets/big5r.txt")   #ascii format
> Error: restore file may be from a newer version of R -- no data loaded
> 
> I  can list the second file using a web browser and I can move the 
> first file back to my machine and load it locally.
> My problem seems to be with loadURL.
> 
> Any help would be appreciated.
> 
> Bill
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From thoar at cgd.ucar.edu  Mon May 10 19:25:31 2004
From: thoar at cgd.ucar.edu (Tim Hoar)
Date: Mon, 10 May 2004 11:25:31 -0600 (MDT)
Subject: [R] R 1.9.0 on AIX, 64-bit
In-Reply-To: <40963AC3.1000702@stny.rr.com>
Message-ID: <Pine.GSO.4.30.0405101038370.5002-100000@sunray1>

So --

I am getting the same thing - as far as the base-Ex.Rout.fail --
did undefining HAVE_WORKING STRPTIME  fix the problem?

Despite using the suggestions on page 21 of the install guide,
I cannot seem to find the set of options necessary for dynamic linking.
I am loading with xlc, MAIN_LDFLAGS = -brtl and SHLIB_LDFLAGS = -G

and still get the dreaded:

"> library(SparseM)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"/home/blackforest/thoar/R/R-1.9.0/library/SparseM/libs/SparseM.so":

Error in library(SparseM) : .First.lib failed"


I need to compile in 64 bit mode so I can access more than 2GB of memory.
(so my CFLAGS, FFLAGS, LD_FLAGS  all have extra baggage)
Have you done this?  If you have -- would you care to share your environment
variable settings as well as your call to configure? (exists in config.log)
I'm getting pretty frustrated with this.

I am stepping back to see if I can get the 32bit compile to accept the dynamic
loading - so anything would help.

Thanks -- Tim


> Date: Mon, 03 May 2004 08:27:47 -0400
> From: Andy Pierce <apierce at stny.rr.com>
> To: r-help at stat.math.ethz.ch
> Subject: [R] R 1.9.0 on AIX, 64-bit
>
> I'm trying to get R 1.9.0 running on AIX 5.1 with the standard AIX
> compilers (xlc, xlf) and it is failing 2 of the tests,
> test-Reg in reg-tests-1.R like this:
>
> bash-2.05b$ tail -30 reg-tests-1.Rout.fail
>       [,1] [,2]
> [1,] 1    3
> [2,] 2    4
> [3,] 1    3
> [4,] 2    4
>  > stopifnot(typeof(res) == "list")
>  > ## were not implemented in 1.8.1
>  >
>  >
>  > ## Date objects with NA's
>  > (t1 <- strptime(c("6. Aug. 1930", "3. Nov. 1925", "28. Mar. 1959",
> +                  NA, paste(1:29," Feb. 1960", sep=".")),
> +                format = "%d. %b. %Y"))
>   [1] "1930-08-06" "1925-11-03" "1959-03-28" NA           "1960-02-01"
>   [6] "1960-02-02" "1960-02-03" "1960-02-04" "1960-02-05" "1960-02-06"
> [11] "1960-02-07" "1960-02-08" "1960-02-09" "1960-02-10" "1960-02-11"
> [16] "1960-02-12" "1960-02-13" "1960-02-14" "1960-02-15" "1960-02-16"
> [21] "1960-02-17" "1960-02-18" "1960-02-19" "1960-02-20" "1960-02-21"
> [26] "1960-02-22" "1960-02-23" "1960-02-24" "1960-02-25" "1960-02-26"
> [31] "1960-02-27" "1960-02-28" "1960-02-29"
>  > stopifnot(6 == length(print(s1 <- summary(t1))),
> +           s1== summary(as.POSIXct(t1)),
> +           6 == length(print(format(as.Date(s1)))) )
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>       NA      NA      NA      NA      NA      NA
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>       NA      NA      NA      NA      NA      NA
> Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r)))
> stop(paste(deparse(mc[[i +  :
>          missing value where TRUE/FALSE needed
> Execution halted
>
> and also in base-Ex.R like this:
>
> bash-2.05b$ tail base-Ex.Rout.fail
>  > ### Title: Generate Regular Sequences of Dates
>  > ### Aliases: seq.Date
>  > ### Keywords: manip chron
>  >
>  > ### ** Examples
>  >
>  > ## first days of years
>  > seq(as.Date("1910/1/1"), as.Date("1999/1/1"), "years")
> Error in fromchar(x) : character string is not in a standard unambiguous
> format
> Execution halted
>
> Does anyone have any ideas on how to fix this?
>
> Andy Pierce
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

## Tim Hoar, Associate Scientist              email: thoar at ucar.edu     ##
## Geophysical Statistics Project             phone: 303-497-1708       ##
## National Center for Atmospheric Research   FAX  : 303-497-1333       ##
## Boulder, CO  80307                    http://www.cgd.ucar.edu/~thoar ##



From petzoldt at rcs.urz.tu-dresden.de  Mon May 10 20:49:32 2004
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Mon, 10 May 2004 20:49:32 +0200
Subject: [R] Colouring hclust() trees
In-Reply-To: <200405100329.i4A3TQhx204497@atlas.otago.ac.nz>
References: <200405100329.i4A3TQhx204497@atlas.otago.ac.nz>
Message-ID: <409FCEBC.5090901@rcs.urz.tu-dresden.de>

Richard A. O'Keefe wrote:
> I have a data set with  6 variables and 251 cases.
> The people who supplied me with this data set believe that it falls
> naturally into three groups, and have given me a rule for determining
> group number from these 6 variables.

One possibility is to extract the coordinates used by the dendrogram 
using par("usr") and then to do annotations using ?text, but as a global 
alternative in cases like this (many cases and known number of classes), 
I would suggest a different cluster alorithm, e.g. ?kmeans. If you want 
to get a visual idea you may try to apply an ordination method (e.g. 
princomp or isoMDS the latter from package MASS) and color the objects 
according to their class found by kmeans.

Hope it helps

Thomas P.



From ggrothendieck at myway.com  Mon May 10 21:00:07 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 10 May 2004 19:00:07 +0000 (UTC)
Subject: [R] Lists and outer() like functionality?
References: <025FBC02-A28E-11D8-BC9C-000393DC1748@ic.ac.uk>
	<54783.203.9.176.60.1084200348.squirrel@webmail.maxnet.co.nz>
	<ABE51934-A298-11D8-BC9C-000393DC1748@ic.ac.uk>
	<x2ad0gqns5.fsf@biostat.ku.dk>
	<5D30B42A-A29D-11D8-BC9C-000393DC1748@ic.ac.uk>
Message-ID: <loom.20040510T205434-299@post.gmane.org>

David Orme <d.orme <at> imperial.ac.uk> writes:

: 
: >
: > outer() generally works by expanding out the lists like
: >
: > Y <- rep(y,length(x))
: > X <- rep(x,each=length(y)) # or maybe it's vice versa, never mind...
: > FUN(X,Y,extras)
: >
: > and then adds dims and dimnames. If FUN vectorizes, this is the
: > efficient way, but it does not in your case and the rep()s are
: > probably not cheap when lists are involved.
: >
: > you might try this sort of stuff:
: >
: > myfunc2 <- function(i,j)
: >     mapply(function(i,j)
: >              
: > phylo.overlap(assemblages[[i]],assemblages[[j]],parrot.cm),
: >            i,j)
: > ind <- seq(along=assemblages)
: > outer(ind,ind,myfunc2)
: >
: 
: That now runs at about the same speed as the loops (although the loops 
: still just have the edge).
: 
: Many thanks for the suggestions.
: 
: David


Actually if you are debating between for and outer, note that 
one could implement this without for and without outer:

sapply(mylist,function(x)sapply(mylist,function(y)sum(intersect(x,y)))



From Sebastian-Schubert at gmx.de  Mon May 10 21:32:07 2004
From: Sebastian-Schubert at gmx.de (Sebastian Schubert)
Date: Mon, 10 May 2004 21:32:07 +0200 (MEST)
Subject: [R] Using known errors and error bars
References: <Pine.LNX.4.44.0405091643290.10113-100000@gannet.stats>
Message-ID: <32159.1084217527@www11.gmx.net>

> What do you actually know? 
>  
> You don't have `known errors', as if you did you could correct the 
>values. 
> I doubt if you actually have a known range, more likely a standard error  
> or a confidence interval.  (If you think you do have a known range, how 
> do 
> you know?) 
 
Firstly, I must admit that I do not know much about statistics (and, in 
addition, do not always know the right English terms). I had to measure an 
electric potential difference and I know from the technical dates of the 
device that the confidence interval (?) is 5% of the maximum value on the 
scale (eg I measured 1.2V on a 2V scale so I have (1.2+-0.1)V). 
 
 
> And if A is not known exactly, linear regression is not fully 
appropriate. 
>   
> If you know standard errors, then you need a homoscedastic  
> errors-in-variables formulation.  One early account is  
>  
> Ripley, B. D. and Thompson, M.(1987) Regression techniques for the  
> detection of analytical bias. Analyst 112, 177-183. 
>  
> and its Fortran program is still available, and although I have never 
> coded it in R, I believe others have. 
 
I will look for it. 
 
> > How can I put error bars for A and B in the plot (like Excel is 
capable  
> > of)?  
>  
> Many ways, for example using arrows() or plotCI in package gregmisc. 
 
I tried the last one and it worked well. 
Thank you for your advice 
Sebastian Schubert 

--



From anthony at darrouzet-nardi.net  Mon May 10 22:45:22 2004
From: anthony at darrouzet-nardi.net (Anthony Darrouzet-Nardi)
Date: Mon, 10 May 2004 13:45:22 -0700
Subject: [R] RODBC in RAqua
Message-ID: <p05210634bcc58e7c2bb1@[10.10.13.41]>

I've been trying to get RODBC working in RAqua. For my database, 
let's call it "mydb", when I enter

odbcConnect("mydb")
or
odbcConnect("mydb", uid="postgres", pwd="secret"),

RAqua thinks for about 10 seconds, then crashes.

mydb is a PostgreSQL 7.4.2 database running on my machine (Mac OS X 
10.3.3). I am using the pgsqlodbc 7.2.5 driver and the driver manager 
that comes built in to OS X 10.2 and later, which is some version of 
iodbc.

I should point out that the utility "odbctest", a simple command-line 
ODBC compliant interactive SQL client, can successfully connect to my 
database with the ODBC connect strings DSN=mydb or DSN=mydb;UID= 
postgres;PWD=secret

The odbc.ini file generated by ODBC Administrator (an GUI tool that 
comes with OS X) looks like this:

[ODBC Data Sources]
mydb       = PostgreSQL

[ODBC]
Trace         = 0
TraceAutoStop = 0
TraceFile     =
TraceLibrary  =

[mydb]
Driver      = /usr/local/lib/psqlodbc.so
Description = This is my database
username    = postgres
password    = secret
servername  = localhost
port        = 5432
database    = mydb

How might I get this working?

Anthony



From slist at oomvanlieshout.net  Mon May 10 22:55:04 2004
From: slist at oomvanlieshout.net (Slist)
Date: Mon, 10 May 2004 22:55:04 +0200
Subject: [R] Coordinate projection with proj4R: the Albers Equal-Area Conic
 projection?
Message-ID: <6.1.0.6.0.20040510222350.02568be8@localhost>

Hi all!

I am trying to project coordinates collected by GPS collars. The data is in 
decimal degrees and provides locations for two Sable antelope running 
around in Kruger NP South Africa.

After a wide search it seems that proj4R provides most options for 
projection of coordinates. However I can not get around the following error 
message when I try to project my coordinates using the Albers Equal Area 
Conic projection.

According to the proj4 pages, the following parameters should be supplied:
http://www.remotesensing.org/geotiff/proj_list/albers_equal_area_conic.html
PROJ.4 Organization
   +proj=aea   +lat_1=Latitude of first standard parallel
               +lat_2=Latitude of second standard parallel
               +lat_0=Latitude of false origin
               +lon_0=Longitude of false origin
               +x_0=Easting of false origin
               +y_0=Northing of false origin

But when running the command in R, I get the following error message

 > library(proj4R)
 >
 > res <- project(cbind(x, y),  "+proj=aea +lon_0=24 +lat_0=0 +lat_1=18s 
+lat_2=32s +x_0=0 +y_0=0 ") #
Error in project(cbind(x, y), "+proj=aea +lon_0=24 +lat_0=0 +lat_1=18s 
+lat_2=32s +x_0=0 +y_0=0 ") :
         major axis or radius = 0 or not given
 >

I have also tried:
 > res <- project(cbind(x, y),  "+proj=aea +lon_0=24 +lat_0=0 +lat_1=-18 
+lat_2=-32 +x_0=0 +y_0=0 ") #
with the same error.

Any suggestions?

Thanks,

Sander.



From ripley at stats.ox.ac.uk  Mon May 10 22:55:39 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 May 2004 21:55:39 +0100 (BST)
Subject: [R] RODBC in RAqua
In-Reply-To: <p05210634bcc58e7c2bb1@[10.10.13.41]>
Message-ID: <Pine.LNX.4.44.0405102149590.19262-100000@gannet.stats>

Does any other driver work?  See the comments in the RODBC README.

In particular, does a 7.2.5 driver really work with 7.4.2, and do you have 
a functioning driver -- the bundled one used to do exactly this.

On Mon, 10 May 2004, Anthony Darrouzet-Nardi wrote:

> I've been trying to get RODBC working in RAqua. For my database, 
> let's call it "mydb", when I enter
> 
> odbcConnect("mydb")
> or
> odbcConnect("mydb", uid="postgres", pwd="secret"),
> 
> RAqua thinks for about 10 seconds, then crashes.
> 
> mydb is a PostgreSQL 7.4.2 database running on my machine (Mac OS X 
> 10.3.3). I am using the pgsqlodbc 7.2.5 driver and the driver manager 
> that comes built in to OS X 10.2 and later, which is some version of 
> iodbc.
> 
> I should point out that the utility "odbctest", a simple command-line 
> ODBC compliant interactive SQL client, can successfully connect to my 
> database with the ODBC connect strings DSN=mydb or DSN=mydb;UID= 
> postgres;PWD=secret

Yes, but that doesn't ask the driver for its capabilities.

> The odbc.ini file generated by ODBC Administrator (an GUI tool that 
> comes with OS X) looks like this:
> 
> [ODBC Data Sources]
> mydb       = PostgreSQL
> 
> [ODBC]
> Trace         = 0
> TraceAutoStop = 0
> TraceFile     =
> TraceLibrary  =
> 
> [mydb]
> Driver      = /usr/local/lib/psqlodbc.so
> Description = This is my database
> username    = postgres
> password    = secret
> servername  = localhost
> port        = 5432
> database    = mydb
> 
> How might I get this working?
> 
> Anthony
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From macq at llnl.gov  Mon May 10 22:59:07 2004
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 10 May 2004 13:59:07 -0700
Subject: [R] "#!/usr/bin/R"
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D5C@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7D5C@usrymx25.merck.com>
Message-ID: <p06002006bcc59913e808@[128.115.153.6]>

That someone might have been me; I did at one time figure out how to 
execute scripts based on a first line like that of the subject line 
of this thread.

As I recall, what I did was
   1) before attempting to execute a script having such a first line, 
define the env vars that R.bin needs
   2) specify R.bin, rather than R, on that first line.

I have only a very shallow understanding of how the OS interprets and 
executes such scripts, but I believe that it doesn't work when the 
file being pointed to (/usr/bin/R in this case) is a shell script. It 
has to be an executable binary. Hence, the env vars that R.bin needs, 
that are set in the "R" shell script, need to be manually defined 
first (or in a user's shell startup script such as .tcshrc, or in a 
webserver's configuration files).

Associated with that attempt was a modification of the sources that I 
made, commenting out two lines in system.c, specifically:

See file ./source/src/unix/system.c
line 239 in R-1.8.1 patched as of 12/3/03
             snprintf(msg, 1024, "ARGUMENT '%s' __ignored__\n", *av);
             R_ShowMessage(msg);

This was because I wanted to use R for cgi scripts, and that warning 
message preceded the html headers that, according to html 
specifications, *must* come first. Otherwise the broswer chokes.

If I recall correctly, that modification is not necessary simply to 
create and run such scripts. Only in the context of using R as a cgi 
engine did I find it necessary.

Of course, there may have been a better way, or there may be a better 
way now, but that is what I found at the time.

-Don

At 12:26 PM -0400 5/10/04, Liaw, Andy wrote:
>Someone had modified the R source to handle this, but it has not been
>incorporated into the official R source, if I'm not mistaken.  Search the
>R-devel archive.
>
>HTH,
>Andy
>
>>  From: Webb Sprague
>>
>>  Hi all,
>>
>>  Is there any documentation on running R like one would run a shell or
>>  Perl script, with out/input directed appropriately,
>>  environment variable
>>  access, and command switch processing?
>>
>>  I looked some, and even remembered to check the FAQ, but
>>  couldn't find
>>  anything.
>>
>>  Thanks
>>  W
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments,...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From Roger.Bivand at nhh.no  Mon May 10 23:04:37 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 10 May 2004 23:04:37 +0200 (CEST)
Subject: [R] Coordinate projection with proj4R: the Albers
	Equal-AreaConicprojection?
In-Reply-To: <6.1.0.6.0.20040510222350.02568be8@localhost>
Message-ID: <Pine.LNX.4.44.0405102259050.4436-100000@reclus.nhh.no>

This concerns a draft package not on CRAN, perhaps better discussed off 
list for now. Could you please attach a few example points for me to look 
at, and details of your R version and the proj4 library version you are 
using? What happens when you run proj from the command line?

Roger Bivand

On Mon, 10 May 2004, Slist wrote:

> Hi all!
> 
> I am trying to project coordinates collected by GPS collars. The data is in 
> decimal degrees and provides locations for two Sable antelope running 
> around in Kruger NP South Africa.
> 
> After a wide search it seems that proj4R provides most options for 
> projection of coordinates. However I can not get around the following error 
> message when I try to project my coordinates using the Albers Equal Area 
> Conic projection.
> 
> According to the proj4 pages, the following parameters should be supplied:
> http://www.remotesensing.org/geotiff/proj_list/albers_equal_area_conic.html
> PROJ.4 Organization
>    +proj=aea   +lat_1=Latitude of first standard parallel
>                +lat_2=Latitude of second standard parallel
>                +lat_0=Latitude of false origin
>                +lon_0=Longitude of false origin
>                +x_0=Easting of false origin
>                +y_0=Northing of false origin
> 
> But when running the command in R, I get the following error message
> 
>  > library(proj4R)
>  >
>  > res <- project(cbind(x, y),  "+proj=aea +lon_0=24 +lat_0=0 +lat_1=18s 
> +lat_2=32s +x_0=0 +y_0=0 ") #
> Error in project(cbind(x, y), "+proj=aea +lon_0=24 +lat_0=0 +lat_1=18s 
> +lat_2=32s +x_0=0 +y_0=0 ") :
>          major axis or radius = 0 or not given
>  >
> 
> I have also tried:
>  > res <- project(cbind(x, y),  "+proj=aea +lon_0=24 +lat_0=0 +lat_1=-18 
> +lat_2=-32 +x_0=0 +y_0=0 ") #
> with the same error.
> 
> Any suggestions?
> 
> Thanks,
> 
> Sander.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From wwsprague at ucdavis.edu  Mon May 10 23:15:07 2004
From: wwsprague at ucdavis.edu (wwsprague@ucdavis.edu)
Date: Mon, 10 May 2004 14:15:07 -0700
Subject: [R] "#!/usr/bin/R"
In-Reply-To: <p06002006bcc59913e808@[128.115.153.6]>
References: <3A822319EB35174CA3714066D590DCD504AF7D5C@usrymx25.merck.com>
	<p06002006bcc59913e808@[128.115.153.6]>
Message-ID: <c7orcq$sfu$1@sea.gmane.org>

Hi

> Associated with that attempt was a modification of the sources that I 
> made, commenting out two lines in system.c, specifically:
> 
> See file ./source/src/unix/system.c
> line 239 in R-1.8.1 patched as of 12/3/03
>             snprintf(msg, 1024, "ARGUMENT '%s' __ignored__\n", *av);
>             R_ShowMessage(msg);

I would argue that this code should be removed or made optional, because 
it gets in the way of using R or R.bin in pipelines, cgi scripts, or 
whatever (and thus violates Unix design principles).  Is there some 
other reason for its inclusion?  (I haven't looked at the source, so 
take my comments with the appropriate grains of salt.)

> 
> This was because I wanted to use R for cgi scripts, and that warning 
> message preceded the html headers that, according to html 
> specifications, *must* come first. Otherwise the broswer chokes.
> 
> If I recall correctly, that modification is not necessary simply to 
> create and run such scripts. Only in the context of using R as a cgi 
> engine did I find it necessary.

That is my reason for wanting to use a #! thing too.

> Of course, there may have been a better way, or there may be a better 
> way now, but that is what I found at the time.

I think that a goal should be that R is as easy to incorporate into 
scripts as Perl or sh are.  Thoughts?  Have I bit myself off a project?

Webb



From rpeng at jhsph.edu  Mon May 10 23:36:34 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 10 May 2004 17:36:34 -0400
Subject: [R] "#!/usr/bin/R"
In-Reply-To: <c7o9vj$vlp$1@sea.gmane.org>
References: <c7o9vj$vlp$1@sea.gmane.org>
Message-ID: <409FF5E2.8090006@jhsph.edu>

You may be interested in this thread from R-devel last October:

https://www.stat.math.ethz.ch/pipermail/r-devel/2003-October/027862.html

If I recall correctly, Duncan Temple Lang is working on different 
ways to initialize R but I'm not sure what the status of that is.

-roger

Webb Sprague wrote:
> Hi all,
> 
> Is there any documentation on running R like one would run a shell or 
> Perl script, with out/input directed appropriately, environment variable 
> access, and command switch processing?
> 
> I looked some, and even remembered to check the FAQ, but couldn't find 
> anything.
> 
> Thanks
> W
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ggrothendieck at myway.com  Tue May 11 00:01:42 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 10 May 2004 22:01:42 +0000 (UTC)
Subject: [R] "#!/usr/bin/R"
References: <c7o9vj$vlp$1@sea.gmane.org>
Message-ID: <loom.20040510T234814-489@post.gmane.org>

Webb Sprague <wwsprague <at> ucdavis.edu> writes:

: Is there any documentation on running R like one would run a shell or 
: Perl script, with out/input directed appropriately, environment variable 
: access, and command switch processing?
: 
: I looked some, and even remembered to check the FAQ, but couldn't find 
: anything.
: 

I think this would be useful beyond cgi scripts too.  In fact, in my 
top 10 New Year's wishes for R it was listed (#10):
http://tolstoy.newcastle.edu.au/R/devel/04a/0039.html

I used to use awk heavily but as I use R more and more I find that
I think in R more than the others, effectively losing my facility
with those other languages.  In fact, whenever I have something that seems 
more appropriate for awk than for R, then if I do write it in awk 
I will often see if I can rewrite it in R to keep the number of tools 
used to a minimum. At this point, I would like to do everything I used 
to do in awk in R to simplify things down to one language since R
is inevitably used somewhere along the line whenever I use awk.

I am not sure what facilities would be useful for this but I think
that making awk-like things easy, might involve more than just cleaning 
up the initialization.



From pauljohn at ku.edu  Tue May 11 01:59:46 2004
From: pauljohn at ku.edu (Paul Johnson)
Date: Mon, 10 May 2004 18:59:46 -0500
Subject: [R] Explaining Survival difference between Stata and R
Message-ID: <40A01772.9020304@ku.edu>

Dear Everybody:

I'm doing my usual "how does that work in R" thing with some Stata 
projects.  I find a gross gap between the Stata and R in Cox PH models, 
and I hope you can give me some pointers about what goes wrong.  I'm 
getting signals from R/Survival that the model just can't be estimated, 
but Stata spits out numbers just fine.

I wonder if I should specify initial values for coxph?

I got a dataset from a student who uses Stata and try to replicate in R. 
I will share data to you in case you want to see for yourself.  Let me 
know if you want text or Stata data file.

In R, I try this:

 > cox2 <- coxph(Surv(yrs2,ratify)~ accession+ haz.wst+ haz.in +haz.out+ 
wefgov+ rle+ rqe + pol.free +tai.2001 + ny.gdp.pcap.pp.cd + eio, 
data=dat3, control=coxph.control(iter.max=1000),singular.ok=T)
Warning message:
Ran out of iterations and did not converge in: fitter(X, Y, strats, 
offset, init, control, weights = weights,

So I wrote out the file exatly as it was in R into Stata dataset

 > write.dta(dat3,"cleanBasel.dta")
Warning message:
Abbreviating variable names in: write.dta(dat3, "cleanBasel.dta")


Here's the Stata output:

. use "/home/pauljohn/ps/ps909/AdvancedRegression/duration_2/cleanBasel.dta"
(Written by R.              )

. stset yrs2, failure (ratify)

      failure event:  ratify != 0 & ratify < .
obs. time interval:  (0, yrs2]
  exit on or before:  failure

----------------------------------------------------------------------------
 > --
        21  total obs.
         0  exclusions
----------------------------------------------------------------------------
 > --
        21  obs. remaining, representing
        21  failures in single record/single failure data
        78  total analysis time at risk, at risk from t =         0
                              earliest observed entry t =         0

. stcox accessin haz_wst  haz_in  haz_out  wefgov  rle  rqe  pol_free 
tai_2001 ny_gd  eio, robust
 >  nohr

          failure _d:  ratify
    analysis time _t:  yrs2

Iteration 0:   log pseudo-likelihood = -49.054959
Iteration 1:   log pseudo-likelihood = -45.021682
Iteration 2:   log pseudo-likelihood = -44.525187
Iteration 3:   log pseudo-likelihood = -44.521588
Iteration 4:   log pseudo-likelihood = -44.521586
Refining estimates:
Iteration 0:   log pseudo-likelihood = -44.521586

Cox regression -- Breslow method for ties

No. of subjects       =           21               Number of obs   = 
     21
No. of failures       =           21
Time at risk          =           78
                                                    Wald chi2(11)   = 
   81.64
Log pseudo-likelihood =   -44.521586               Prob > chi2     = 
0.0000

------------------------------------------------------------------------------
              |               Robust
           _t |      Coef.   Std. Err.      z    P>|z|
-------------+----------------------------------------------------------------
     accessin |  -1.114101   .6343663    -1.76   0.079
      haz_wst |   2.32e-08   1.08e-07     0.22   0.829
       haz_in |   3.78e-06   2.46e-06     1.54   0.124
      haz_out |  -3.80e-07   3.76e-07    -1.01   0.312
       wefgov |   2.139127   .9136992     2.34   0.019
          rle |   1.827482   1.500878     1.22   0.223
          rqe |  -3.126696   1.332069    -2.35   0.019
     pol_free |  -.4498276    .291764    -1.54   0.123
     tai_2001 |  -2.895922   2.577401    -1.12   0.261
     ny_gd___ |  -.0003223   .0002194    -1.47   0.142
          eio |  -.0577773   .0726064    -0.80   0.426
------------------------------------------------------------------------------

.
                                  last observed exit t =         7


----------------------------------



Paul Johnson
Dept. of Political Science
University of Kansas



From cgwiggner at yahoo.com  Tue May 11 03:37:15 2004
From: cgwiggner at yahoo.com (Claus Gwiggner)
Date: Mon, 10 May 2004 18:37:15 -0700 (PDT)
Subject: [R] lm with predictor matrix
Message-ID: <20040511013715.13522.qmail@web90104.mail.scd.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040510/20dbfe90/attachment.pl

From andy_liaw at merck.com  Tue May 11 03:48:30 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 10 May 2004 21:48:30 -0400
Subject: [R] lm with predictor matrix
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D65@usrymx25.merck.com>

Try:

x = matrix(runif(30), 10, 3)
newx = matrix(runif(15), 5, 3)
y = rnorm(10)

fit = lm(y ~ x)
newyhat = predict(fit, newdata=data.frame(x=I(newx)))

HTH,
Andy

> From: Claus Gwiggner
> 
> Hello,
>   
>   can someone give me an example of how to fit a linear model 
> where the
>   response is a matrix, please? (other than a loop over lm calls)
>   The ?lm points me to model.matrix but it is not clear to me 
> how to use a
>   model matrix in an lm call.
>  
>   fit<-lm(headmatrix ~ tailmatrix) causes problems as soon as I
>  use predict(fit,newframe). The variables in tailmatrix are 
> not found in
>  newframe.
>  
>   Thanks,
>   
>   Claus



From rpeng at jhsph.edu  Tue May 11 04:02:39 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 10 May 2004 22:02:39 -0400
Subject: [R] lm with predictor matrix
In-Reply-To: <20040511013715.13522.qmail@web90104.mail.scd.yahoo.com>
References: <20040511013715.13522.qmail@web90104.mail.scd.yahoo.com>
Message-ID: <40A0343F.1040004@jhsph.edu>

Your problem might be that the names of 'newframe' don't match 
the column names of 'tailmatrix'.  It's hard to tell because you 
don't provide an example.

Is 'newframe' a matrix or a dataframe?

If it is a dataframe, try:

names(newframe) <- colnames(tailmatrix)

predict(fit, newframe)

-roger

Claus Gwiggner wrote:

> Hello,
>   
>   can someone give me an example of how to fit a linear model where the
>   response is a matrix, please? (other than a loop over lm calls)
>   The ?lm points me to model.matrix but it is not clear to me how to use a
>   model matrix in an lm call.
>  
>   fit<-lm(headmatrix ~ tailmatrix) causes problems as soon as I
>  use predict(fit,newframe). The variables in tailmatrix are not found in
>  newframe.
>  
>   Thanks,
>   
>   Claus
> 
> 
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From arinbasu at softhome.net  Tue May 11 05:13:49 2004
From: arinbasu at softhome.net (arinbasu@softhome.net)
Date: Mon, 10 May 2004 21:13:49 -0600
Subject: [R] Re: Mozilla Misbehavior
In-Reply-To: <200405101002.i4AA27Xc010282@hypatia.math.ethz.ch> 
References: <200405101002.i4AA27Xc010282@hypatia.math.ethz.ch>
Message-ID: <courier.40A044ED.000055EE@softhome.net>

Hi Murray: 

Perhaps the errors are thrown by Mozilla because it encounters an 
encrypted/secure page and does not know what to do (..:)..)? Would it help 
if you went to Edit > Preferences... > Privacy and Security > select SSL or 
Certificates drop down list 

and then once in SSL, or once in Certificates tab, make the necessary 
changes so that Mozilla can at least show you the certificates which you can 
then accept or reject before proceeding. 

And indeed, why are mail archives on secure pages? 

HTH,
Arin 

 

> Message: 9
> Date: Mon, 10 May 2004 09:32:48 +1200
> From: Murray Jorgensen <maj at stats.waikato.ac.nz>
> Subject: Re: [R] Modalwert
> To: r-help at stat.math.ethz.ch
> Message-ID: <409EA380.2040507 at stats.waikato.ac.nz>
> Content-Type: text/plain; charset=us-ascii; format=flowed 
> 
> Off-topic, I know, but when I try to follow secure links like this in 
> Mozilla, I always get a message "The connection was refused when trying 
> to contact www.stat.math.ethz.ch" and I am forced to use Internet 
> Explorer instead. This is under Windows XP. 
> 
> Is this because www.stat.math.ethz.ch is using some non-standard 
> Microsoft extensions of html? Or is it because my Mozilla 1.6 browser is 
> wrongly configured? 
> 
> Why are the mail archives on secure pages anyway? 
> 
> Murray Jorgensen



From ok at cs.otago.ac.nz  Tue May 11 05:24:15 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Tue, 11 May 2004 15:24:15 +1200 (NZST)
Subject: [R] Colouring hclust() trees
Message-ID: <200405110324.i4B3OFxh224264@atlas.otago.ac.nz>

I asked about putting some kind of coloured rug under a dendrogram.

Thomas Petzoldt <petzoldt at rcs.urz.tu-dresden.de> replied:
	One possibility is to extract the coordinates used by the dendrogram 
	using par("usr") ...

Er, the documentation for par("usr") says
    'usr' A vector of the form 'c(x1, x2, y1, y2)' giving the extremes
          of the user coordinates of the plotting region.  When a
          logarithmic scale is in use (i.e., 'par("xlog")' is true, see
          below), then the x-limits will be '10 ^ par("usr")[1:2]'. 
          Similarly for the y-axis.
But I _know_ the (logical) coordinates of the plotting region; what I need
is the coordinates of the leaves of the dendrogram.

	but as a global alternative in cases like this (many cases and
	known number of classes), I would suggest a different cluster
	alorithm, e.g. ?kmeans.

That doesn't really help, amongst other things because kmeans is not
a hierarchical algorithm.  I *DON'T* know the true number of classes.
I know how many classes the person who collected the data thinks there
are, and I don't need to do any clustering to find them, he gave me a
simple rule.  What I want to know is how many clusters there OUGHT to be
and how similar these clusters are to the ones he thought there were.
>From poking around, the "right" number of clusters is somewhere between
2 and 6.  (For the record, I _have_ tried kmeans and I've tabulated the
kmeans groups against the prespecified groups.)

	If you want to get a visual idea you may try to apply an
	ordination method (e.g. princomp or isoMDS the latter from
	package MASS) and color the objects according to their class
	found by kmeans.
	
I had already done that (using the prespecified classes, not classes found
by kmeans).  But it didn't solve my present problem, which was overlaying
the *prespecified* classes onto a dendrogram.

Two other people gave me answers that are spot on.
Unfortunately, I've now lost their messages, so I can't name them.

Suggestion 1:  use the RowSideColors (or ColSideColors) argument of heatmap().
This gives me two dendrograms (and I can suppress one if I want) and a heat
image of the data, and all things considered, it's *better* than what I wanted.
(I was aware of heatmap, but I'd failed to notice the relevance, or even the
existence, of the ???SideColors arguments.)  In this particular case, the
graph _beautifully_ displays what I want it to display.

Suggestion 2:  use the draw.clust function from the maptree packages.
I have now installed this package (which R makes *so* easy) and it does
exactly what I asked for.

Both of these approaches work with any dendrogram.

I'm beginning to suspect that if something isn't already available in R,
I'll never be able to imagine a need for it.  But then I'm a bear of
very little brain...



From revelle at northwestern.edu  Tue May 11 05:36:31 2004
From: revelle at northwestern.edu (William Revelle)
Date: Mon, 10 May 2004 22:36:31 -0500
Subject: [R] problem with loadURL -- claims newer version used- fixed
In-Reply-To: <Pine.LNX.4.44.0405101811300.18944-100000@gannet.stats>
References: <Pine.LNX.4.44.0405101811300.18944-100000@gannet.stats>
Message-ID: <p06010222bcc5f84e7b7d@[66.239.20.171]>

>big5r.txt is delimited by CR not LF, and as R writes it as a binary file,
>that's not the file that got saved.

Thanks.  That was the problem.  I was transferring the files from my 
Mac to my web server (also a Mac) using Interarchy.  It was putting 
in CRs rather than LFs (the Interarchy options were "old Mac cr" vs. 
Unix (lf)").  Changing that transfer option makes it work.

>
>Same problem with the header on big5r. 
>
>Try some octal dumps and find out which step is changing the file.
>
>BTW, I would use load(url(someURL)) these days.

load(url(someURL))  works (once I fixed the transfer to the server), 
although I used the other form because I was following the help for 
load. Perhaps the ?load comments could be modified to suggest 
load(url(someURL)) instead of suggesting loadURL(someURL).

Thanks for the very rapid response.

Bill



>
>On Mon, 10 May 2004, William Revelle wrote:
>
>>  Dear list,
>>
>>  I am trying to prepare a handout showing how to use R for factor
>>  analysis.  As part of the exercise I want to save a correlation
>>  matrix on a tutorial web page.  I can save with no problem (saving
>>  locally and then transferring to the web site).  Although I can
>>  load() the local file, I am having problems getting loadURL to read
>>  the remote file.   I have tried saving it as an ascii file or just
>>  using the default format.
>>
>>  Using R 1.9.0 on a Mac with OS 10.3
>>
>>
>>  I first saved the file:
>>  save(big5r,file="big5r.txt",ascii=TRUE)
>>  and
>>  save(big5r,file="big5r")
>>  I can load either version from a local file using load().
>>
>>  I then have moved these files to a webserver and tried to load them
>>  using the loadURL() command.
>>
>>  Using loadURL() I get the following message
>>
>>    >loadURL("http://personality-project.org/r/datasets/big5r")
>>  #the default format
>>  Error: restore file may be from a newer version of R -- no data loaded
>>  >loadURL("http://personality-project.org/r/datasets/big5r.txt") 
>>#ascii format
>>  Error: restore file may be from a newer version of R -- no data loaded
>>
>>  I  can list the second file using a web browser and I can move the
>>  first file back to my machine and load it locally.
>>  My problem seems to be with loadURL.
>>
>>  Any help would be appreciated.
>>
>>  Bill
>>
>>
>>
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
----------------------------
William Revelle 
http://pmc.psych.northwestern.edu/revelle.html    
Department of Psychology, Northwestern University
Personality Project: http://personality-project.org/personality.html



From maj at stats.waikato.ac.nz  Tue May 11 05:50:37 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue, 11 May 2004 15:50:37 +1200
Subject: [R] Re: Mozilla Misbehavior
In-Reply-To: <courier.40A044ED.000055EE@softhome.net>
References: <200405101002.i4AA27Xc010282@hypatia.math.ethz.ch>
	<courier.40A044ED.000055EE@softhome.net>
Message-ID: <40A04D8D.5090205@stats.waikato.ac.nz>

It was a proxy settings problem. All fixed now. Sorry to disturb the list.

Murray Jorgensen

arinbasu at softhome.net wrote:

> Hi Murray:
> Perhaps the errors are thrown by Mozilla because it encounters an 
> encrypted/secure page and does not know what to do (..:)..)? Would it 
> help if you went to Edit > Preferences... > Privacy and Security > 
> select SSL or Certificates drop down list
> and then once in SSL, or once in Certificates tab, make the necessary 
> changes so that Mozilla can at least show you the certificates which you 
> can then accept or reject before proceeding.
> And indeed, why are mail archives on secure pages?
> HTH,
> Arin
> 
> 
>> Message: 9
>> Date: Mon, 10 May 2004 09:32:48 +1200
>> From: Murray Jorgensen <maj at stats.waikato.ac.nz>
>> Subject: Re: [R] Modalwert
>> To: r-help at stat.math.ethz.ch
>> Message-ID: <409EA380.2040507 at stats.waikato.ac.nz>
>> Content-Type: text/plain; charset=us-ascii; format=flowed
>> Off-topic, I know, but when I try to follow secure links like this in 
>> Mozilla, I always get a message "The connection was refused when 
>> trying to contact www.stat.math.ethz.ch" and I am forced to use 
>> Internet Explorer instead. This is under Windows XP.
>> Is this because www.stat.math.ethz.ch is using some non-standard 
>> Microsoft extensions of html? Or is it because my Mozilla 1.6 browser 
>> is wrongly configured?
>> Why are the mail archives on secure pages anyway?
>> Murray Jorgensen
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From hi_ono2001 at ybb.ne.jp  Tue May 11 05:54:20 2004
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Tue, 11 May 2004 12:54:20 +0900
Subject: [R] How to draw holes generated by gpclib using plot function
Message-ID: <004501c4370b$a42bac30$258001db@webgis>

Hi.

 I've tried to create a polygon with one hole by gpclib using following
example script.

 holepoly <- read.polyfile(system.file("poly-ex/hole-poly.txt", package
="gpclib"), nohole = FALSE)
 area.poly(holepoly)
 plot(holepoly,poly.args=list(col="red",border="blue"))

 And I noticed plot function couldn't draw polygons with holes correctly.

 Does anyone know how to solve this situation?

 Regards.



From vograno at evafunds.com  Tue May 11 08:08:58 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Mon, 10 May 2004 23:08:58 -0700
Subject: [R] test for end of file on connection
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B32F7@phost015.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040510/5332ea0b/attachment.pl

From Arne.Muller at aventis.com  Mon May 10 16:36:58 2004
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Mon, 10 May 2004 16:36:58 +0200
Subject: [R] R versus SAS: lm performance
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1D0@crbsmxsusr04.pharma.aventis.com>

Hello,

A collegue of mine has compared the runtime of a linear model + anova in SAS and S+. He got the same results, but SAS took a bit more than a minute whereas S+ took 17 minutes. I've tried it in R (1.9.0) and it took 15 min. Neither machine run out of memory, and I assume that all machines have similar hardware, but the S+ and SAS machines are on windows whereas the R machine is Redhat Linux 7.2.

My question is if I'm doing something wrong (technically) calling the lm routine, or (if not), how I can optimize the call to lm or even using an alternative to lm. I'd like to run about 12,000 of these models in R (for a gene expression experiment - one model per gene, which would take far too long).

I've run the follwong code in R (and S+):

> options(contrasts=c('contr.helmert', 'contr.poly'))

The 1st colum is the value to be modeled, and the others are factors.

> names(df.gene1data) <- c("Va", "Ba", "Ti", "Do", "Ar", "Pr")
> df[c(1:2,1343:1344),]
           Va    Do  Ti  Ba Ar    Pr
1    2.317804 000mM 24h NEW  1     1
2    2.495390 000mM 24h NEW  2     1
8315 2.979641 025mM 04h PRG 83    16
8415 4.505787 000mM 04h PRG 84    16

this is a dataframe with 1344 rows.

x <- Sys.time();
wlm <- lm(Va ~
Ba+Ti+Do+Pr+Ba:Ti+Ba:Do+Ba:Pr+Ti:Do+Ti:Pr+Do:Pr+Ba:Ti:Do+Ba:Ti:Pr+Ba:Do:Pr+Ti:Do:Pr+Ba:Ti:Do:Pr+(Ba:Ti:Do)/Ar, data=df, singular=T);
difftime(Sys.time(), x)

Time difference of 15.33333 mins

> anova(wlm)
Analysis of Variance Table

Response: Va
             Df Sum Sq Mean Sq   F value    Pr(>F)    
Ba            2    0.1     0.1    0.4262  0.653133    
Ti            1    2.6     2.6   16.5055 5.306e-05 ***
Do            4    6.8     1.7   10.5468 2.431e-08 ***
Pr           15 5007.4   333.8 2081.8439 < 2.2e-16 ***
Ba:Ti         2    3.2     1.6    9.8510 5.904e-05 ***
Ba:Do         7    2.8     0.4    2.5054  0.014943 *  
Ba:Pr        30   80.6     2.7   16.7585 < 2.2e-16 ***
Ti:Do         4    8.7     2.2   13.5982 9.537e-11 ***
Ti:Pr        15    2.4     0.2    1.0017  0.450876    
Do:Pr        60   10.2     0.2    1.0594  0.358551    
Ba:Ti:Do      7    1.4     0.2    1.2064  0.296415    
Ba:Ti:Pr     30    5.6     0.2    1.1563  0.259184    
Ba:Do:Pr    105   14.2     0.1    0.8445  0.862262    
Ti:Do:Pr     60   14.8     0.2    1.5367  0.006713 ** 
Ba:Ti:Do:Pr 105   15.8     0.2    0.9382  0.653134    
Ba:Ti:Do:Ar  56   26.4     0.5    2.9434 2.904e-11 ***
Residuals   840  134.7     0.2                        

The corresponding SAS program from my collegue is:

proc glm data = "the name of the data set";

class B T D A P;

model V = B T D P B*T B*D B*P T*D T*P D*P B*T*D B*T*P B*D*P T*D*P B*T*D*P A(B*T*D);

run;

Note, V = Va, B = Ba, T = Ti, D = Do, P = Pr, A = Ar of the R-example

	kind regards + thanks a lot for your help,

	Arne



From ripley at stats.ox.ac.uk  Tue May 11 09:02:26 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 May 2004 08:02:26 +0100 (BST)
Subject: [R] problem with loadURL -- claims newer version used- fixed
In-Reply-To: <p06010222bcc5f84e7b7d@[66.239.20.171]>
Message-ID: <Pine.LNX.4.44.0405110748500.19954-100000@gannet.stats>

On Mon, 10 May 2004, William Revelle wrote:

> >big5r.txt is delimited by CR not LF, and as R writes it as a binary file,
> >that's not the file that got saved.
> 
> Thanks.  That was the problem.  I was transferring the files from my 
> Mac to my web server (also a Mac) using Interarchy.  It was putting 
> in CRs rather than LFs (the Interarchy options were "old Mac cr" vs. 
> Unix (lf)").  Changing that transfer option makes it work.
> 
> >
> >Same problem with the header on big5r. 
> >
> >Try some octal dumps and find out which step is changing the file.
> >
> >BTW, I would use load(url(someURL)) these days.
> 
> load(url(someURL))  works (once I fixed the transfer to the server), 
> although I used the other form because I was following the help for 
> load. Perhaps the ?load comments could be modified to suggest 
> load(url(someURL)) instead of suggesting loadURL(someURL).

They don't suggest loadURL (that page is also ?loadURL).  What they say is

     'load' can load R objects saved in the current or any earlier
     format.  It can read a compressed file (see 'save') directly from
     a file or from a suitable connection.

     'loadURL' is a convenience wrapper which downloads a file, loads
     it and deletes the downloaded copy.

A `suitable connection' can include a call to url(), and that has the 
advantage (and possibly also disadvantage on a flaky connection) of not 
making a local copy.

I will add a warning about needing to preserve binary files, though.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue May 11 09:07:41 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 May 2004 08:07:41 +0100 (BST)
Subject: [R] R versus SAS: lm performance
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1D0@crbsmxsusr04.pharma.aventis.com>
Message-ID: <Pine.LNX.4.44.0405110803400.19954-100000@gannet.stats>

The way to time things in R is system.time().

Without knowing much more about your problem we can only guess where R is 
spending the time.  But you can find out by profiling -- see `Writing R 
Extensions'.

If you want multiple fits with the same design matrix (do you?) you 
could look at the code of lm and call lm.fit repeatedly yourself.

On Mon, 10 May 2004 Arne.Muller at aventis.com wrote:

> Hello,
> 
> A collegue of mine has compared the runtime of a linear model + anova in SAS and S+. He got the same results, but SAS took a bit more than a minute whereas S+ took 17 minutes. I've tried it in R (1.9.0) and it took 15 min. Neither machine run out of memory, and I assume that all machines have similar hardware, but the S+ and SAS machines are on windows whereas the R machine is Redhat Linux 7.2.
> 
> My question is if I'm doing something wrong (technically) calling the lm routine, or (if not), how I can optimize the call to lm or even using an alternative to lm. I'd like to run about 12,000 of these models in R (for a gene expression experiment - one model per gene, which would take far too long).
> 
> I've run the follwong code in R (and S+):
> 
> > options(contrasts=c('contr.helmert', 'contr.poly'))
> 
> The 1st colum is the value to be modeled, and the others are factors.
> 
> > names(df.gene1data) <- c("Va", "Ba", "Ti", "Do", "Ar", "Pr")
> > df[c(1:2,1343:1344),]
>            Va    Do  Ti  Ba Ar    Pr
> 1    2.317804 000mM 24h NEW  1     1
> 2    2.495390 000mM 24h NEW  2     1
> 8315 2.979641 025mM 04h PRG 83    16
> 8415 4.505787 000mM 04h PRG 84    16
> 
> this is a dataframe with 1344 rows.
> 
> x <- Sys.time();
> wlm <- lm(Va ~
> Ba+Ti+Do+Pr+Ba:Ti+Ba:Do+Ba:Pr+Ti:Do+Ti:Pr+Do:Pr+Ba:Ti:Do+Ba:Ti:Pr+Ba:Do:Pr+Ti:Do:Pr+Ba:Ti:Do:Pr+(Ba:Ti:Do)/Ar, data=df, singular=T);
> difftime(Sys.time(), x)
> 
> Time difference of 15.33333 mins
> 
> > anova(wlm)
> Analysis of Variance Table
> 
> Response: Va
>              Df Sum Sq Mean Sq   F value    Pr(>F)    
> Ba            2    0.1     0.1    0.4262  0.653133    
> Ti            1    2.6     2.6   16.5055 5.306e-05 ***
> Do            4    6.8     1.7   10.5468 2.431e-08 ***
> Pr           15 5007.4   333.8 2081.8439 < 2.2e-16 ***
> Ba:Ti         2    3.2     1.6    9.8510 5.904e-05 ***
> Ba:Do         7    2.8     0.4    2.5054  0.014943 *  
> Ba:Pr        30   80.6     2.7   16.7585 < 2.2e-16 ***
> Ti:Do         4    8.7     2.2   13.5982 9.537e-11 ***
> Ti:Pr        15    2.4     0.2    1.0017  0.450876    
> Do:Pr        60   10.2     0.2    1.0594  0.358551    
> Ba:Ti:Do      7    1.4     0.2    1.2064  0.296415    
> Ba:Ti:Pr     30    5.6     0.2    1.1563  0.259184    
> Ba:Do:Pr    105   14.2     0.1    0.8445  0.862262    
> Ti:Do:Pr     60   14.8     0.2    1.5367  0.006713 ** 
> Ba:Ti:Do:Pr 105   15.8     0.2    0.9382  0.653134    
> Ba:Ti:Do:Ar  56   26.4     0.5    2.9434 2.904e-11 ***
> Residuals   840  134.7     0.2                        
> 
> The corresponding SAS program from my collegue is:
> 
> proc glm data = "the name of the data set";
> 
> class B T D A P;
> 
> model V = B T D P B*T B*D B*P T*D T*P D*P B*T*D B*T*P B*D*P T*D*P B*T*D*P A(B*T*D);
> 
> run;
> 
> Note, V = Va, B = Ba, T = Ti, D = Do, P = Pr, A = Ar of the R-example

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ihaka at stat.auckland.ac.nz  Tue May 11 09:40:15 2004
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Tue, 11 May 2004 19:40:15 +1200
Subject: [R] How to draw holes generated by gpclib using plot function
In-Reply-To: <004501c4370b$a42bac30$258001db@webgis>
References: <004501c4370b$a42bac30$258001db@webgis>
Message-ID: <40A0835F.6090009@stat.auckland.ac.nz>

Hisaji ONO wrote:
> Hi.
> 
>  I've tried to create a polygon with one hole by gpclib using following
> example script.
> 
>  holepoly <- read.polyfile(system.file("poly-ex/hole-poly.txt", package
> ="gpclib"), nohole = FALSE)
>  area.poly(holepoly)
>  plot(holepoly,poly.args=list(col="red",border="blue"))
> 
>  And I noticed plot function couldn't draw polygons with holes correctly.
> 
>  Does anyone know how to solve this situation?

This is basic constraint in the R graphics system.  Polygons must
consist of a single (possibly self-intersecting) ring.  It would be
possible to implement a primitive which is bounded by several
non-intersecting rings by joining the interior holes to the outer
boundary to create a simply connected shape. Then you could draw
the interior with the existing polygon primitive.  You can find a
more precise description of the process in the FIST (fast
industrial-strength triangulation) paper:

 M. Held (2001):
``FIST: Fast Industrial-Strength Triangulation of Polygons''.
Algorithmica 30(4): 563-596, 2001.

It would be VERY useful to have an implementation of this (hint, hint!)

Alternatively, I think that gpc has an option to return a triangulated
version of the polygon.  If you get hold of this you could just draw the
triangles. though this might be slow for complex polygons.


-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand



From HeikeNewslists at gmx.de  Tue May 11 09:50:11 2004
From: HeikeNewslists at gmx.de (Heike Heidemeier)
Date: Tue, 11 May 2004 09:50:11 +0200 (MEST)
Subject: [R] Meta-Analysis using lme
Message-ID: <29719.1084261811@www7.gmx.net>

Dear list-members,

I am trying to use R to conduct a meta-analysis, i.e. I'd like to use a
multi-level model to integrate the findings of a number of primary research
studies. 
 
I set up a simple two level-model (only summary statistics are provided by
each study) as follows:

sapp.lme <- lme(D ~ 1, data = sapp.frame, random = ~ 1 | STUDYNR, 
weights=varFixed(~-1+STDERR_D),na.action = na.exclude)

The intercept is random on both levels and the variable stderr_D (the
sampling variance) is supposed to be random only on level one. Besides, I
need to constrain the variance of stderr_d to equal 1. 

Could anybody help me correct the code I provided? Thanks in advance for
your time.

Cheers, 
Heike Heidemeier



--



From Paul.Livingstone at dsto.defence.gov.au  Tue May 11 10:32:21 2004
From: Paul.Livingstone at dsto.defence.gov.au (Livingstone, Paul)
Date: Tue, 11 May 2004 18:32:21 +1000
Subject: [R] - making a Windows library from Unix source code
Message-ID: <27D22054C09AD611B16700306E01B9F1012BEDDA@fmbex504.dsto.defence.gov.au>

Hi All,

I'm using R1.8.1 on Windows XP.

I'm having trouble producing an R library from source code.  A colleague has written the source code, in Unix.  I've copied the source code across to Windows (with the help files, data files, description and index) and am trying to compile it into a library.  

I've "sourced" each of the *.r files and they appear to work.

I've very carefully followed the instructions in the "R for Windows FAQ" and "readme.packages".  I've downloaded and installed Perl, R tools, copied across the text to 

C:\Program Files\R\rw1081\src\library\fatigue

(note: the package is called "fatigue") then I type at the DOS prompt

cd "c:\Program Files\R\rw1081\src\gnuwin32"
make pkg-fatigue

and get the error message(s)

make[1]: *** [zzzfirst] Error 255
make: *** [pkg-fatigue] Error 2

How do I look up what Error 255 means?  
Or can you tell me what Error 255 means and how I might fix it?  
Any other hints or ideas on how to use "make" or compile code that appears to work?


thanks,
Paul.



From ripley at stats.ox.ac.uk  Tue May 11 10:59:42 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 May 2004 09:59:42 +0100 (BST)
Subject: [R] - making a Windows library from Unix source code
In-Reply-To: <27D22054C09AD611B16700306E01B9F1012BEDDA@fmbex504.dsto.defence.gov.au>
Message-ID: <Pine.LNX.4.44.0405110956490.23765-100000@gannet.stats>

On Tue, 11 May 2004, Livingstone, Paul wrote:

> I'm using R1.8.1 on Windows XP.
> 
> I'm having trouble producing an R library from source code.  A colleague has written the source code, in Unix.  I've copied the source code across to Windows (with the help files, data files, description and index) and am trying to compile it into a library.  
> 
> I've "sourced" each of the *.r files and they appear to work.
> 
> I've very carefully followed the instructions in the "R for Windows FAQ"
> and "readme.packages".  I've downloaded and installed Perl, R tools,
> copied across the text to

Not `very carefully' as you have spaces in your path: that may well be 
the problem.  We don't know what else you have not followed, I am afraid.

> C:\Program Files\R\rw1081\src\library\fatigue
> 
> (note: the package is called "fatigue") then I type at the DOS prompt
> 
> cd "c:\Program Files\R\rw1081\src\gnuwin32"
> make pkg-fatigue
> 
> and get the error message(s)
> 
> make[1]: *** [zzzfirst] Error 255
> make: *** [pkg-fatigue] Error 2
> 
> How do I look up what Error 255 means?  
> Or can you tell me what Error 255 means and how I might fix it?  

It's a make error.  What came before that?  All error 255 is telling you 
is that there has been a fatal error.

> Any other hints or ideas on how to use "make" or compile code that
> appears to work?

It's not the code, rather the Windows setup.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maysawasdee at hotmail.com  Tue May 11 11:06:26 2004
From: maysawasdee at hotmail.com (may nongmay)
Date: Tue, 11 May 2004 16:06:26 +0700
Subject: [R] How to import file from excle?
Message-ID: <BAY12-F116oo9tjxqxP0000daaf@hotmail.com>

Hi R-help

I have some question.
First I have data in Excle ,then I would like to fit distribution
from this data, how to import this data from excle? What's command?

Thaks for first answer

Second

I learn R program from The Basics of S and S-plus book because it's basic,
and then when I use command is attact(geyser) [follow from book] but I can't 
.
Because it's command only S (i think some command can't use in R???)

Thanks

Best regards
Mathinee



From maysawasdee at hotmail.com  Tue May 11 11:06:26 2004
From: maysawasdee at hotmail.com (may nongmay)
Date: Tue, 11 May 2004 16:06:26 +0700
Subject: [R] How to import file from excle?
Message-ID: <BAY12-F1116rXtU3xZo0000db53@hotmail.com>

Hi R-help

I have some question.
First I have data in Excle ,then I would like to fit distribution
from this data, how to import this data from excle? What's command?

Thaks for first answer

Second

I learn R program from The Basics of S and S-plus book because it's basic,
and then when I use command is attact(geyser) [follow from book] but I can't 
.
Because it's command only S (i think some command can't use in R???)

Thanks

Best regards
Mathinee



From ccleland at optonline.net  Tue May 11 11:22:26 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 11 May 2004 05:22:26 -0400
Subject: [R] How to import file from excle?
In-Reply-To: <BAY12-F1116rXtU3xZo0000db53@hotmail.com>
References: <BAY12-F1116rXtU3xZo0000db53@hotmail.com>
Message-ID: <40A09B52.50402@optonline.net>

may nongmay wrote:
> ...
> I learn R program from The Basics of S and S-plus book because it's basic,
> and then when I use command is attact(geyser) [follow from book] but I 
> can't .
> Because it's command only S (i think some command can't use in R???)

   In R, you need library(MASS) as a first step.  Also, I believe 
you want attach(geyser), not attact(geyser).
   You could have found the geyser dataset with 
help.search("geyser").

hope this helps

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ligges at statistik.uni-dortmund.de  Tue May 11 11:27:29 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 11 May 2004 11:27:29 +0200
Subject: [R] How to import file from excle?
In-Reply-To: <BAY12-F116oo9tjxqxP0000daaf@hotmail.com>
References: <BAY12-F116oo9tjxqxP0000daaf@hotmail.com>
Message-ID: <40A09C81.7040806@statistik.uni-dortmund.de>

may nongmay wrote:

> Hi R-help
> 
> I have some question.
> First I have data in Excle ,then I would like to fit distribution
> from this data, how to import this data from excle? What's command?

There is an "R Import/Export manual". Please read it.


> Thaks for first answer
> 
> Second
> 
> I learn R program from The Basics of S and S-plus book because it's basic,
> and then when I use command is attact(geyser) [follow from book] but I 
> can't .
> Because it's command only S (i think some command can't use in R???)

help.search("geyser") and reviewing the help files for the multiple hits 
tells you: the data "geyser" you are looking for is available in package 
MASS:

  library("MASS")
  data("geyser")
  attach(geyser)

Uwe Ligges



> Thanks
> 
> Best regards
> Mathinee
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From clothilde13 at yahoo.fr  Tue May 11 12:01:01 2004
From: clothilde13 at yahoo.fr (=?iso-8859-1?q?clothilde=20kussener?=)
Date: Tue, 11 May 2004 12:01:01 +0200 (CEST)
Subject: [R] Probleme with Kmeans...
Message-ID: <20040511100101.72131.qmail@web61109.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040511/80ee59e0/attachment.pl

From Matthias.Templ at statistik.gv.at  Tue May 11 12:19:09 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Tue, 11 May 2004 12:19:09 +0200
Subject: [R] Probleme with Kmeans...
Message-ID: <83536658864BC243BE3C06D7E936ABD5015368D4@xchg1.statistik.local>

Hello,
When clustering with kmeans, your data should have more than one variable.
Matthias

-----Urspr??ngliche Nachricht-----
Von: clothilde kussener [mailto:clothilde13 at yahoo.fr] 
Gesendet: Dienstag, 11. Mai 2004 12:01
An: r-help at stat.math.ethz.ch
Betreff: [R] Probleme with Kmeans...


Hello,
I would like to have any help with the function Kmeans of R..
I use this to do a classification of my data...I have chosen 12 classes but, I have always an error message: 
Error: empty cluster: try a better set of initial centers

So, I don't understand the probleme with this function..
Thank you to help me!!
All the Best
Clothilde
 
Clothilde Kussener
CNRS - CEBC
79360 Villiers en bois
France

		
---------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue May 11 12:19:48 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 11 May 2004 12:19:48 +0200
Subject: [R] Probleme with Kmeans...
In-Reply-To: <20040511100101.72131.qmail@web61109.mail.yahoo.com>
References: <20040511100101.72131.qmail@web61109.mail.yahoo.com>
Message-ID: <40A0A8C4.8060106@statistik.uni-dortmund.de>

clothilde kussener wrote:

> Hello,
> I would like to have any help with the function Kmeans of R..
> I use this to do a classification of my data...I have chosen 12 classes but, I have always an error message: 
> Error: empty cluster: try a better set of initial centers
>
> So, I don't understand the probleme with this function..
> Thank you to help me!!

Well, after running, there are less than 12 clusters with observations 
found by kmeans(). The error message suggests to specify initial cluster 
centers instead of randomly chosen ones, if you have got a rough guess 
where centers will be.

BTW: If you have got known "classes", don't you want to perform 
classification rather than clustering???

Uwe Ligges




> All the Best
> Clothilde
>  
> Clothilde Kussener
> CNRS - CEBC
> 79360 Villiers en bois
> France
> 
> 		
> ---------------------------------
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From j.hall at beatson.gla.ac.uk  Tue May 11 12:20:41 2004
From: j.hall at beatson.gla.ac.uk (Jacqueline Hall)
Date: Tue, 11 May 2004 11:20:41 +0100
Subject: [R] stability measures for heirarchical clustering
Message-ID: <000301c43741$9cc9cf90$80e8d182@o1jh>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040511/742e258e/attachment.pl

From Arne.Muller at aventis.com  Tue May 11 13:00:00 2004
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Tue, 11 May 2004 13:00:00 +0200
Subject: [R] R versus SAS: lm performance
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1D6@crbsmxsusr04.pharma.aventis.com>

Hello,

thanks for your reply. I've now done the profiling, and I interpret that the most time is spend in the fortran routine(s):

Each sample represents 0.02 seconds.
Total run time: 920.219999999453 seconds.

Total seconds: time spent in function and callees.
Self seconds: time spent in function alone.

   %       total       %       self
 total    seconds     self    seconds    name
100.00    920.22      0.02      0.16     "lm"
 99.96    919.88      0.10      0.88     "lm.fit"
 99.74    917.84     99.74    917.84     ".Fortran"
  0.07      0.66      0.02      0.14     "storage.mode<-"
  0.06      0.52      0.00      0.00     "eval"
  0.06      0.52      0.04      0.34     "as.double"
  0.02      0.22      0.02      0.22     "colnames<-"
  0.02      0.20      0.02      0.20     "structure"
  0.02      0.18      0.02      0.18     "model.matrix.default"
  0.02      0.18      0.02      0.18     "as.double.default"
  0.02      0.18      0.00      0.00     "model.matrix"
  0.01      0.08      0.01      0.08     "list"

   %       self        %       total
 self     seconds    total    seconds    name
 99.74    917.84     99.74    917.84     ".Fortran"
  0.10      0.88     99.96    919.88     "lm.fit"
  0.04      0.34      0.06      0.52     "as.double"
  0.02      0.22      0.02      0.22     "colnames<-"
  0.02      0.20      0.02      0.20     "structure"
  0.02      0.18      0.02      0.18     "as.double.default"
  0.02      0.18      0.02      0.18     "model.matrix.default"
  0.02      0.16    100.00    920.22     "lm"
  0.02      0.14      0.07      0.66     "storage.mode<-"
  0.01      0.08      0.01      0.08     "list"

I guess this actually means I cannot do anything about it ... other than maybe splitting the problem into different (independaent parts - which I actually may be able to).

Regarding the usage of lm.fit instead of lm, this might be a good idea, since I am using the same model.matrix for all fits! However, I'd need to recreate an lm object from the output, because I'd like to run the anova function on this. I'll first do some profiling on lm versus lm.fit for the 12,000 models ...

	kind regards + thanks again for your help,

	Arne

--
Arne Muller, Ph.D.
Toxicogenomics, Aventis Pharma
arne dot muller domain=aventis com

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: 11 May 2004 09:08
> To: Muller, Arne PH/FR
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] R versus SAS: lm performance
> 
> 
> The way to time things in R is system.time().
> 
> Without knowing much more about your problem we can only 
> guess where R is 
> spending the time.  But you can find out by profiling -- see 
> `Writing R 
> Extensions'.
> 
> If you want multiple fits with the same design matrix (do you?) you 
> could look at the code of lm and call lm.fit repeatedly yourself.
> 
> On Mon, 10 May 2004 Arne.Muller at aventis.com wrote:
> 
> > Hello,
> > 
> > A collegue of mine has compared the runtime of a linear 
> model + anova in SAS and S+. He got the same results, but SAS 
> took a bit more than a minute whereas S+ took 17 minutes. 
> I've tried it in R (1.9.0) and it took 15 min. Neither 
> machine run out of memory, and I assume that all machines 
> have similar hardware, but the S+ and SAS machines are on 
> windows whereas the R machine is Redhat Linux 7.2.
> > 
> > My question is if I'm doing something wrong (technically) 
> calling the lm routine, or (if not), how I can optimize the 
> call to lm or even using an alternative to lm. I'd like to 
> run about 12,000 of these models in R (for a gene expression 
> experiment - one model per gene, which would take far too long).
> > 
> > I've run the follwong code in R (and S+):
> > 
> > > options(contrasts=c('contr.helmert', 'contr.poly'))
> > 
> > The 1st colum is the value to be modeled, and the others 
> are factors.
> > 
> > > names(df.gene1data) <- c("Va", "Ba", "Ti", "Do", "Ar", "Pr")
> > > df[c(1:2,1343:1344),]
> >            Va    Do  Ti  Ba Ar    Pr
> > 1    2.317804 000mM 24h NEW  1     1
> > 2    2.495390 000mM 24h NEW  2     1
> > 8315 2.979641 025mM 04h PRG 83    16
> > 8415 4.505787 000mM 04h PRG 84    16
> > 
> > this is a dataframe with 1344 rows.
> > 
> > x <- Sys.time();
> > wlm <- lm(Va ~
> > 
> Ba+Ti+Do+Pr+Ba:Ti+Ba:Do+Ba:Pr+Ti:Do+Ti:Pr+Do:Pr+Ba:Ti:Do+Ba:Ti
> :Pr+Ba:Do:Pr+Ti:Do:Pr+Ba:Ti:Do:Pr+(Ba:Ti:Do)/Ar, data=df, singular=T);
> > difftime(Sys.time(), x)
> > 
> > Time difference of 15.33333 mins
> > 
> > > anova(wlm)
> > Analysis of Variance Table
> > 
> > Response: Va
> >              Df Sum Sq Mean Sq   F value    Pr(>F)    
> > Ba            2    0.1     0.1    0.4262  0.653133    
> > Ti            1    2.6     2.6   16.5055 5.306e-05 ***
> > Do            4    6.8     1.7   10.5468 2.431e-08 ***
> > Pr           15 5007.4   333.8 2081.8439 < 2.2e-16 ***
> > Ba:Ti         2    3.2     1.6    9.8510 5.904e-05 ***
> > Ba:Do         7    2.8     0.4    2.5054  0.014943 *  
> > Ba:Pr        30   80.6     2.7   16.7585 < 2.2e-16 ***
> > Ti:Do         4    8.7     2.2   13.5982 9.537e-11 ***
> > Ti:Pr        15    2.4     0.2    1.0017  0.450876    
> > Do:Pr        60   10.2     0.2    1.0594  0.358551    
> > Ba:Ti:Do      7    1.4     0.2    1.2064  0.296415    
> > Ba:Ti:Pr     30    5.6     0.2    1.1563  0.259184    
> > Ba:Do:Pr    105   14.2     0.1    0.8445  0.862262    
> > Ti:Do:Pr     60   14.8     0.2    1.5367  0.006713 ** 
> > Ba:Ti:Do:Pr 105   15.8     0.2    0.9382  0.653134    
> > Ba:Ti:Do:Ar  56   26.4     0.5    2.9434 2.904e-11 ***
> > Residuals   840  134.7     0.2                        
> > 
> > The corresponding SAS program from my collegue is:
> > 
> > proc glm data = "the name of the data set";
> > 
> > class B T D A P;
> > 
> > model V = B T D P B*T B*D B*P T*D T*P D*P B*T*D B*T*P B*D*P 
> T*D*P B*T*D*P A(B*T*D);
> > 
> > run;
> > 
> > Note, V = Va, B = Ba, T = Ti, D = Do, P = Pr, A = Ar of the 
> R-example
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
>



From martin at ist.org  Tue May 11 13:47:51 2004
From: martin at ist.org (Martin Keller-Ressel)
Date: Tue, 11 May 2004 13:47:51 +0200
Subject: [R] Colouring hclust() trees
Message-ID: <opr7t211p1jigwsf@mail.ist.org>

How about this:

"hc" is your hclust object,"colv" the color vector ordered like the 
original data
and "height" the height of the color bar as fraction of dendrogram height.

colorplot.hclust <- function(hc,colv,height=.05) {
     plot(hc,lab=FALSE,hang=0)
     stopifnot(length(hc$order) == length(colv))
     xy.mat <- list(x=1:length(colv),y=c(-max(hc$height)*height,0))
     image(xy.mat,z=matrix(colv[hc$order],ncol=1),add=TRUE)
}

## Example:

data(iris)
hc1 <- hclust(dist(scale(iris[,1:4])),method="ward")
colorplot.hclust(hc1,as.numeric(iris[,5]))


hth,

Martin Keller-Ressel



--



From mendola at dssm.unipa.it  Tue May 11 13:39:51 2004
From: mendola at dssm.unipa.it (mendola@dssm.unipa.it)
Date: Tue, 11 May 2004 13:39:51 +0200 (CEST)
Subject: [R] bilinear and non linear
Message-ID: <4494.193.205.179.2.1084275591.squirrel@dssm.unipa.it>

Dear all,
there are R packages able to simulate or estimate bilinear model for time
series?
I know it is an open problem, but do exist something for very simplified
bilinear models?

Alternatively, what kinfd of non linear time series models are performed
in R?

If R is not able, could someone suggest me for some commercial softwares
to deal with bilinear models?
i'm afraid of a negative answer ...
thanks in advance,
Daria
****************************

Daria Mendola
Dipartimento di Scienze Statistiche e Matematiche
"Silvio Vianelli"
Universit?? di Palermo
Viale delle Scienze - Edificio 13
90128 Palermo, Italia
tel. +39 091 6626210
fax  +39 091 485726
email: mendola at dssm.unipa.it



From ramzi.temanni at laposte.net  Tue May 11 13:45:09 2004
From: ramzi.temanni at laposte.net (Ramzi TEMANNI)
Date: Tue, 11 May 2004 13:45:09 +0200
Subject: [R] SDP & QCQP
In-Reply-To: <4494.193.205.179.2.1084275591.squirrel@dssm.unipa.it>
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA/SScWgRDKkWYRSKuOxiKY8KAAAAQAAAAHV0aP1aLXkqECFKS9UygOgEAAAAA@laposte.net>

Hi,

Are there package in R that can solve semidefinite programming problem and
Quadratically Constrained Quadratic Programming ?

Thanks in advance,
Ramzi



TEMANNI Ramzi
DEA Student

Lim&Bio
http://www.limbio-paris13.org
UFR de Sant??, M??decine et
Biologie Humaine (SMBH)
L??onard de Vinci
74, rue Marcel Cachin
93017 Bobigny Cedex
France.
http://temanni.ramzi.free.fr



From bates at stat.wisc.edu  Tue May 11 14:07:14 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 May 2004 07:07:14 -0500
Subject: [R] R versus SAS: lm performance
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1D0@crbsmxsusr04.pharma.aventis.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1D0@crbsmxsusr04.pharma.aventis.com>
Message-ID: <6r8yfz4171.fsf@bates4.stat.wisc.edu>

<Arne.Muller at aventis.com> writes:

> Hello,
> 
> A collegue of mine has compared the runtime of a linear model + anova in SAS and S+. He got the same results, but SAS took a bit more than a minute whereas S+ took 17 minutes. I've tried it in R (1.9.0) and it took 15 min. Neither machine run out of memory, and I assume that all machines have similar hardware, but the S+ and SAS machines are on windows whereas the R machine is Redhat Linux 7.2.
> 
> My question is if I'm doing something wrong (technically) calling the lm routine, or (if not), how I can optimize the call to lm or even using an alternative to lm. I'd like to run about 12,000 of these models in R (for a gene expression experiment - one model per gene, which would take far too long).
> 
> I've run the follwong code in R (and S+):

...

As Brian Ripley mentioned, you could save the model matrix and use it
with each of your responses.  Versions 0.8-1 and later of the Matrix
package have a vignette that provides comparative timings of various
ways of obtaining the least squares estimates.  If you use the classes
from the Matrix package and create and save the crossproduct of the
model matrix

mm = as(model.matrix(Va ~ Ba+Ti..., df), "geMatrix")
cprod = crossprod(mm)

then successive calls to

coef = solve(cprod, crossprod(mm, df$Va))

will produce the coefficient estimates much faster than will calls to
lm, which each do all the work of generating and decomposing the very
large model matrix.

Note that this method only produces the coefficient estimates, which
may be enough for your purposes.  Also, this method will not handle
missing data or rank-deficient model matrices in the elegant way that
lm does.

If you are doing this 12,000 times it may be worthwhile checking if
the sparse matrix formulation

mmS = as(mm, "cscMatrix")
cprodS = crossprod(mmS)

is faster.

The dense matrix formulation (but not the sparse) can benefit from
installation of optimized BLAS routines such as Atlas or Goto's BLAS.

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From ripley at stats.ox.ac.uk  Tue May 11 14:15:42 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 May 2004 13:15:42 +0100 (BST)
Subject: [R] R versus SAS: lm performance
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1D6@crbsmxsusr04.pharma.aventis.com>
Message-ID: <Pine.LNX.4.44.0405111304580.23940-100000@gannet.stats>

BTW, I forgot to mention that using multiple lhs's (but not all 12,000 at 
once) in a call to lm will help a lot: you may well be able to do 1000 
fits in the same time as one, and that may be sufficient speed-up for you.

Can you tell us how big the model matrix X is, and how much singularity 
there is (since you set singular = TRUE)?

My guess is that you have a 1344 x p matrix X for large p, and it is the
QR decomposition of X which is taking the time.  Both R and S-PLUS use 
LINPACK, and it is possibly much faster to use LAPACK with a tuned BLAS.
Since R contains a LAPACK-based QR decomposition, we can probably write an 
alternative to lm.fit which would be much faster.  However, the exact way 
that singularities are handled in lm.fit would be hard to reproduce, which 
is why we still use LINPACK there.

On Tue, 11 May 2004 Arne.Muller at aventis.com wrote:

> Hello,
> 
> thanks for your reply. I've now done the profiling, and I interpret that the most time is spend in the fortran routine(s):
> 
> Each sample represents 0.02 seconds.
> Total run time: 920.219999999453 seconds.
> 
> Total seconds: time spent in function and callees.
> Self seconds: time spent in function alone.
> 
>    %       total       %       self
>  total    seconds     self    seconds    name
> 100.00    920.22      0.02      0.16     "lm"
>  99.96    919.88      0.10      0.88     "lm.fit"
>  99.74    917.84     99.74    917.84     ".Fortran"
>   0.07      0.66      0.02      0.14     "storage.mode<-"
>   0.06      0.52      0.00      0.00     "eval"
>   0.06      0.52      0.04      0.34     "as.double"
>   0.02      0.22      0.02      0.22     "colnames<-"
>   0.02      0.20      0.02      0.20     "structure"
>   0.02      0.18      0.02      0.18     "model.matrix.default"
>   0.02      0.18      0.02      0.18     "as.double.default"
>   0.02      0.18      0.00      0.00     "model.matrix"
>   0.01      0.08      0.01      0.08     "list"
> 
>    %       self        %       total
>  self     seconds    total    seconds    name
>  99.74    917.84     99.74    917.84     ".Fortran"
>   0.10      0.88     99.96    919.88     "lm.fit"
>   0.04      0.34      0.06      0.52     "as.double"
>   0.02      0.22      0.02      0.22     "colnames<-"
>   0.02      0.20      0.02      0.20     "structure"
>   0.02      0.18      0.02      0.18     "as.double.default"
>   0.02      0.18      0.02      0.18     "model.matrix.default"
>   0.02      0.16    100.00    920.22     "lm"
>   0.02      0.14      0.07      0.66     "storage.mode<-"
>   0.01      0.08      0.01      0.08     "list"
> 
> I guess this actually means I cannot do anything about it ... other than maybe splitting the problem into different (independaent parts - which I actually may be able to).
> 
> Regarding the usage of lm.fit instead of lm, this might be a good idea, since I am using the same model.matrix for all fits! However, I'd need to recreate an lm object from the output, because I'd like to run the anova function on this. I'll first do some profiling on lm versus lm.fit for the 12,000 models ...
> 
> 	kind regards + thanks again for your help,
> 
> 	Arne
> 
> --
> Arne Muller, Ph.D.
> Toxicogenomics, Aventis Pharma
> arne dot muller domain=aventis com
> 
> > -----Original Message-----
> > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > Sent: 11 May 2004 09:08
> > To: Muller, Arne PH/FR
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] R versus SAS: lm performance
> > 
> > 
> > The way to time things in R is system.time().
> > 
> > Without knowing much more about your problem we can only 
> > guess where R is 
> > spending the time.  But you can find out by profiling -- see 
> > `Writing R 
> > Extensions'.
> > 
> > If you want multiple fits with the same design matrix (do you?) you 
> > could look at the code of lm and call lm.fit repeatedly yourself.
> > 
> > On Mon, 10 May 2004 Arne.Muller at aventis.com wrote:
> > 
> > > Hello,
> > > 
> > > A collegue of mine has compared the runtime of a linear 
> > model + anova in SAS and S+. He got the same results, but SAS 
> > took a bit more than a minute whereas S+ took 17 minutes. 
> > I've tried it in R (1.9.0) and it took 15 min. Neither 
> > machine run out of memory, and I assume that all machines 
> > have similar hardware, but the S+ and SAS machines are on 
> > windows whereas the R machine is Redhat Linux 7.2.
> > > 
> > > My question is if I'm doing something wrong (technically) 
> > calling the lm routine, or (if not), how I can optimize the 
> > call to lm or even using an alternative to lm. I'd like to 
> > run about 12,000 of these models in R (for a gene expression 
> > experiment - one model per gene, which would take far too long).
> > > 
> > > I've run the follwong code in R (and S+):
> > > 
> > > > options(contrasts=c('contr.helmert', 'contr.poly'))
> > > 
> > > The 1st colum is the value to be modeled, and the others 
> > are factors.
> > > 
> > > > names(df.gene1data) <- c("Va", "Ba", "Ti", "Do", "Ar", "Pr")
> > > > df[c(1:2,1343:1344),]
> > >            Va    Do  Ti  Ba Ar    Pr
> > > 1    2.317804 000mM 24h NEW  1     1
> > > 2    2.495390 000mM 24h NEW  2     1
> > > 8315 2.979641 025mM 04h PRG 83    16
> > > 8415 4.505787 000mM 04h PRG 84    16
> > > 
> > > this is a dataframe with 1344 rows.
> > > 
> > > x <- Sys.time();
> > > wlm <- lm(Va ~
> > > 
> > Ba+Ti+Do+Pr+Ba:Ti+Ba:Do+Ba:Pr+Ti:Do+Ti:Pr+Do:Pr+Ba:Ti:Do+Ba:Ti
> > :Pr+Ba:Do:Pr+Ti:Do:Pr+Ba:Ti:Do:Pr+(Ba:Ti:Do)/Ar, data=df, singular=T);
> > > difftime(Sys.time(), x)
> > > 
> > > Time difference of 15.33333 mins
> > > 
> > > > anova(wlm)
> > > Analysis of Variance Table
> > > 
> > > Response: Va
> > >              Df Sum Sq Mean Sq   F value    Pr(>F)    
> > > Ba            2    0.1     0.1    0.4262  0.653133    
> > > Ti            1    2.6     2.6   16.5055 5.306e-05 ***
> > > Do            4    6.8     1.7   10.5468 2.431e-08 ***
> > > Pr           15 5007.4   333.8 2081.8439 < 2.2e-16 ***
> > > Ba:Ti         2    3.2     1.6    9.8510 5.904e-05 ***
> > > Ba:Do         7    2.8     0.4    2.5054  0.014943 *  
> > > Ba:Pr        30   80.6     2.7   16.7585 < 2.2e-16 ***
> > > Ti:Do         4    8.7     2.2   13.5982 9.537e-11 ***
> > > Ti:Pr        15    2.4     0.2    1.0017  0.450876    
> > > Do:Pr        60   10.2     0.2    1.0594  0.358551    
> > > Ba:Ti:Do      7    1.4     0.2    1.2064  0.296415    
> > > Ba:Ti:Pr     30    5.6     0.2    1.1563  0.259184    
> > > Ba:Do:Pr    105   14.2     0.1    0.8445  0.862262    
> > > Ti:Do:Pr     60   14.8     0.2    1.5367  0.006713 ** 
> > > Ba:Ti:Do:Pr 105   15.8     0.2    0.9382  0.653134    
> > > Ba:Ti:Do:Ar  56   26.4     0.5    2.9434 2.904e-11 ***
> > > Residuals   840  134.7     0.2                        
> > > 
> > > The corresponding SAS program from my collegue is:
> > > 
> > > proc glm data = "the name of the data set";
> > > 
> > > class B T D A P;
> > > 
> > > model V = B T D P B*T B*D B*P T*D T*P D*P B*T*D B*T*P B*D*P 
> > T*D*P B*T*D*P A(B*T*D);
> > > 
> > > run;
> > > 
> > > Note, V = Va, B = Ba, T = Ti, D = Do, P = Pr, A = Ar of the 
> > R-example
> > 
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > 
> > 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Tue May 11 14:19:40 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 11 May 2004 08:19:40 -0400
Subject: [R] R versus SAS: lm performance
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D6D@usrymx25.merck.com>

I tried the following on an Opteron 248, R-1.9.0 w/Goto's BLAS:

> y <- matrix(rnorm(14000*1344), 1344)
> x <- matrix(runif(1344*503),1344)
> system.time(fit <- lm(y~x))
[1] 106.00  55.60 265.32   0.00   0.00

The resulting fit object is over 600MB.  (The coefficient compoent is a 504
x 14000 matrix.)

If I'm not mistaken, SAS sweeps on the extended cross product matrix to fit
regression models.  That, I believe, in usually faster than doing QR
decomposition on the model matrix itself, but there are trade-offs.  You
could try what Prof. Bates suggested.

Andy

> From: Arne.Muller at aventis.com
> 
> Hello,
> 
> thanks for your reply. I've now done the profiling, and I 
> interpret that the most time is spend in the fortran routine(s):
> 
> Each sample represents 0.02 seconds.
> Total run time: 920.219999999453 seconds.
> 
> Total seconds: time spent in function and callees.
> Self seconds: time spent in function alone.
> 
>    %       total       %       self
>  total    seconds     self    seconds    name
> 100.00    920.22      0.02      0.16     "lm"
>  99.96    919.88      0.10      0.88     "lm.fit"
>  99.74    917.84     99.74    917.84     ".Fortran"
>   0.07      0.66      0.02      0.14     "storage.mode<-"
>   0.06      0.52      0.00      0.00     "eval"
>   0.06      0.52      0.04      0.34     "as.double"
>   0.02      0.22      0.02      0.22     "colnames<-"
>   0.02      0.20      0.02      0.20     "structure"
>   0.02      0.18      0.02      0.18     "model.matrix.default"
>   0.02      0.18      0.02      0.18     "as.double.default"
>   0.02      0.18      0.00      0.00     "model.matrix"
>   0.01      0.08      0.01      0.08     "list"
> 
>    %       self        %       total
>  self     seconds    total    seconds    name
>  99.74    917.84     99.74    917.84     ".Fortran"
>   0.10      0.88     99.96    919.88     "lm.fit"
>   0.04      0.34      0.06      0.52     "as.double"
>   0.02      0.22      0.02      0.22     "colnames<-"
>   0.02      0.20      0.02      0.20     "structure"
>   0.02      0.18      0.02      0.18     "as.double.default"
>   0.02      0.18      0.02      0.18     "model.matrix.default"
>   0.02      0.16    100.00    920.22     "lm"
>   0.02      0.14      0.07      0.66     "storage.mode<-"
>   0.01      0.08      0.01      0.08     "list"
> 
> I guess this actually means I cannot do anything about it ... 
> other than maybe splitting the problem into different 
> (independaent parts - which I actually may be able to).
> 
> Regarding the usage of lm.fit instead of lm, this might be a 
> good idea, since I am using the same model.matrix for all 
> fits! However, I'd need to recreate an lm object from the 
> output, because I'd like to run the anova function on this. 
> I'll first do some profiling on lm versus lm.fit for the 
> 12,000 models ...
> 
> 	kind regards + thanks again for your help,
> 
> 	Arne
> 
> --
> Arne Muller, Ph.D.
> Toxicogenomics, Aventis Pharma
> arne dot muller domain=aventis com
> 
> > -----Original Message-----
> > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > Sent: 11 May 2004 09:08
> > To: Muller, Arne PH/FR
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] R versus SAS: lm performance
> > 
> > 
> > The way to time things in R is system.time().
> > 
> > Without knowing much more about your problem we can only 
> > guess where R is 
> > spending the time.  But you can find out by profiling -- see 
> > `Writing R 
> > Extensions'.
> > 
> > If you want multiple fits with the same design matrix (do you?) you 
> > could look at the code of lm and call lm.fit repeatedly yourself.
> > 
> > On Mon, 10 May 2004 Arne.Muller at aventis.com wrote:
> > 
> > > Hello,
> > > 
> > > A collegue of mine has compared the runtime of a linear 
> > model + anova in SAS and S+. He got the same results, but SAS 
> > took a bit more than a minute whereas S+ took 17 minutes. 
> > I've tried it in R (1.9.0) and it took 15 min. Neither 
> > machine run out of memory, and I assume that all machines 
> > have similar hardware, but the S+ and SAS machines are on 
> > windows whereas the R machine is Redhat Linux 7.2.
> > > 
> > > My question is if I'm doing something wrong (technically) 
> > calling the lm routine, or (if not), how I can optimize the 
> > call to lm or even using an alternative to lm. I'd like to 
> > run about 12,000 of these models in R (for a gene expression 
> > experiment - one model per gene, which would take far too long).
> > > 
> > > I've run the follwong code in R (and S+):
> > > 
> > > > options(contrasts=c('contr.helmert', 'contr.poly'))
> > > 
> > > The 1st colum is the value to be modeled, and the others 
> > are factors.
> > > 
> > > > names(df.gene1data) <- c("Va", "Ba", "Ti", "Do", "Ar", "Pr")
> > > > df[c(1:2,1343:1344),]
> > >            Va    Do  Ti  Ba Ar    Pr
> > > 1    2.317804 000mM 24h NEW  1     1
> > > 2    2.495390 000mM 24h NEW  2     1
> > > 8315 2.979641 025mM 04h PRG 83    16
> > > 8415 4.505787 000mM 04h PRG 84    16
> > > 
> > > this is a dataframe with 1344 rows.
> > > 
> > > x <- Sys.time();
> > > wlm <- lm(Va ~
> > > 
> > Ba+Ti+Do+Pr+Ba:Ti+Ba:Do+Ba:Pr+Ti:Do+Ti:Pr+Do:Pr+Ba:Ti:Do+Ba:Ti
> > :Pr+Ba:Do:Pr+Ti:Do:Pr+Ba:Ti:Do:Pr+(Ba:Ti:Do)/Ar, data=df, 
> singular=T);
> > > difftime(Sys.time(), x)
> > > 
> > > Time difference of 15.33333 mins
> > > 
> > > > anova(wlm)
> > > Analysis of Variance Table
> > > 
> > > Response: Va
> > >              Df Sum Sq Mean Sq   F value    Pr(>F)    
> > > Ba            2    0.1     0.1    0.4262  0.653133    
> > > Ti            1    2.6     2.6   16.5055 5.306e-05 ***
> > > Do            4    6.8     1.7   10.5468 2.431e-08 ***
> > > Pr           15 5007.4   333.8 2081.8439 < 2.2e-16 ***
> > > Ba:Ti         2    3.2     1.6    9.8510 5.904e-05 ***
> > > Ba:Do         7    2.8     0.4    2.5054  0.014943 *  
> > > Ba:Pr        30   80.6     2.7   16.7585 < 2.2e-16 ***
> > > Ti:Do         4    8.7     2.2   13.5982 9.537e-11 ***
> > > Ti:Pr        15    2.4     0.2    1.0017  0.450876    
> > > Do:Pr        60   10.2     0.2    1.0594  0.358551    
> > > Ba:Ti:Do      7    1.4     0.2    1.2064  0.296415    
> > > Ba:Ti:Pr     30    5.6     0.2    1.1563  0.259184    
> > > Ba:Do:Pr    105   14.2     0.1    0.8445  0.862262    
> > > Ti:Do:Pr     60   14.8     0.2    1.5367  0.006713 ** 
> > > Ba:Ti:Do:Pr 105   15.8     0.2    0.9382  0.653134    
> > > Ba:Ti:Do:Ar  56   26.4     0.5    2.9434 2.904e-11 ***
> > > Residuals   840  134.7     0.2                        
> > > 
> > > The corresponding SAS program from my collegue is:
> > > 
> > > proc glm data = "the name of the data set";
> > > 
> > > class B T D A P;
> > > 
> > > model V = B T D P B*T B*D B*P T*D T*P D*P B*T*D B*T*P B*D*P 
> > T*D*P B*T*D*P A(B*T*D);
> > > 
> > > run;
> > > 
> > > Note, V = Va, B = Ba, T = Ti, D = Do, P = Pr, A = Ar of the 
> > R-example
> > 
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From rrsilva at ib.usp.br  Tue May 11 14:30:15 2004
From: rrsilva at ib.usp.br (=?iso-8859-1?q?Rog=E9rio_Rosa_da_Silva?=)
Date: Tue, 11 May 2004 09:30:15 -0300
Subject: [R] calling data frames
Message-ID: <200405110930.15291.rrsilva@ib.usp.br>

Dear List,

I've around 1000 *.txt files, I've generate with other software.
I've now done the following code (below).
My question is how can I automate this (with do.call () ?), so it could be 
done for all the  *.txt files.

Thanks in advance,
Rog??rio


names<- list.files()
file <- "BLU_Var_%04d.txt"
for(i in 1:1000){
blumenau<-read.table("Blu_1.txt",h=T)   # 1000 *.txt files
Guildas<-data.frame(cbind(t(blumenau[2:50])))
Guilda1<-cbind(X27,X48)
Guilda2<-cbind(X5,X17,X19,X20,X21,X24,X25,X26,X40,X41,X77)
Guilda3<-cbind(X22,X28,X69)
Guilda4<-cbind(X29,X30,X31,X32,X33,X34,X35,X36,X37,X78)
Guilda5<-cbind(X3,X8,X18,X23,X63,X82,X83)
Guilda6<-cbind(X6,X38,X39,X44,X45,X46,X47,X49,X50,X51,X52,X53,X54,X55,X56,X57,X58,X59,X60,X61,X62,X84)
Guilda7<-cbind(X1,X2,X42,X43,X64,X65,X66,X67,X68,X79,X80)
Guilda8<-cbind(X7,X15,X16,X70,X71,X72,X73,X74,X75,X76)
Guilda9<-cbind(X4,X9,X10,X11,X12,X13,X14,X81)
Resul.Guilda1<-sum(apply(Guilda1,2,sum))
Resul.Guilda2<-sum(apply(Guilda2,2,sum))
Resul.Guilda3<-sum(apply(Guilda3,2,sum))
Resul.Guilda4<-sum(apply(Guilda4,2,sum))
Resul.Guilda5<-sum(apply(Guilda5,2,sum))
Resul.Guilda6<-sum(apply(Guilda6,2,sum))
Resul.Guilda7<-sum(apply(Guilda7,2,sum))
Resul.Guilda8<-sum(apply(Guilda8,2,sum))
Resul.Guilda9<-sum(apply(Guilda9,2,sum))
Guild.Richness<-cbind(Resul.Guilda1,Resul.Guilda2,Resul.Guilda3,Resul.Guilda4,Resul.Guilda5,Resul.Guilda6,Resul.Guilda7,Resul.Guilda8,Resul.Guilda9)
write(Guild.Richness, file = sprintf(file, i), ncol = 9)
}


-- 
Rog??rio R. Silva
MZUSP http://www.mz.usp.br
Linux User #354364
Linux counter http://counter.li.org



From fm3a004 at math.uni-hamburg.de  Tue May 11 14:33:38 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Tue, 11 May 2004 14:33:38 +0200 (MET DST)
Subject: [R] stability measures for heirarchical clustering
In-Reply-To: <000301c43741$9cc9cf90$80e8d182@o1jh>
Message-ID: <Pine.GSO.3.95q.1040511142551.3049B-100000@sun11.math.uni-hamburg.de>

Dear Jacqueline,

may be the corrected rand index implemented in cluster.stats, package fpc,
and the literature on its help page may be of interest to you. As far as I
know, the corrected rand is the index cited most often for comparing
different clusterings on the same points. This can be used together with
bootstrapping, for example. Perhaps something reasonable can
also be done with jaccard; I am not sure.

Best,
Christian

PS:
On Tue, 11 May 2004, Jacqueline Hall wrote:

> Dear R users,
>  
> I'm interested in measuring the stability of a heirarchical clustering, of
> the overall clustering and finding sub clusters (from cutting the
> heirarchical clustering at different levels) which demonstrate stability. 
> I saw some postings on the R help from a while back about bootstrapping for
> clustering (using sample and generating a consesus tree with a web based
> tool CONSENSE) but i wondered if there have been any advances on the
> "bootstrapping clustering" front? 
> In terms of finding stability in sub sections of the clustering I'm thinking
> of modifying the jaccard function from prabclus to look at pairwise
> similarities in different cluster partitions of sub-samples of the data,
> with high similarity being indicative of stability. 
> I wondered if anyone has already looked at stability measures for clustering
> (particularly thos which interface with hclust), and if any are available
> already in R but i have just missed them?
>  
> I realise there are problems with heirarchical clustering..and i may have to
> consider using a different method,

...there are often good reasons for hierarchical clustering, so if
you know what you are doing, do not let the others confuse you..


***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From rkoenker at uiuc.edu  Tue May 11 14:42:41 2004
From: rkoenker at uiuc.edu (roger koenker)
Date: Tue, 11 May 2004 07:42:41 -0500
Subject: [R] R versus SAS: lm performance
In-Reply-To: <6r8yfz4171.fsf@bates4.stat.wisc.edu>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1D0@crbsmxsusr04.pharma.aventis.com>
	<6r8yfz4171.fsf@bates4.stat.wisc.edu>
Message-ID: <B1549A4A-A348-11D8-873F-000A95A7E3AA@uiuc.edu>

I would be curious to know how sparse the model.matrix for this problem 
is...
Unless it is quite dense, or as Brian implies quite singular, I might 
suggest
computing a Cholesky factorization in SparseM.


url:	www.econ.uiuc.edu/~roger        	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On May 11, 2004, at 7:07 AM, Douglas Bates wrote:

> <Arne.Muller at aventis.com> writes:
>
>> Hello,
>>
>> A collegue of mine has compared the runtime of a linear model + anova 
>> in SAS and S+. He got the same results, but SAS took a bit more than 
>> a minute whereas S+ took 17 minutes. I've tried it in R (1.9.0) and 
>> it took 15 min. Neither machine run out of memory, and I assume that 
>> all machines have similar hardware, but the S+ and SAS machines are 
>> on windows whereas the R machine is Redhat Linux 7.2.
>>
>> My question is if I'm doing something wrong (technically) calling the 
>> lm routine, or (if not), how I can optimize the call to lm or even 
>> using an alternative to lm. I'd like to run about 12,000 of these 
>> models in R (for a gene expression experiment - one model per gene, 
>> which would take far too long).
>>
>> I've run the follwong code in R (and S+):
>
> ...
>
> As Brian Ripley mentioned, you could save the model matrix and use it
> with each of your responses.  Versions 0.8-1 and later of the Matrix
> package have a vignette that provides comparative timings of various
> ways of obtaining the least squares estimates.  If you use the classes
> from the Matrix package and create and save the crossproduct of the
> model matrix
>
> mm = as(model.matrix(Va ~ Ba+Ti..., df), "geMatrix")
> cprod = crossprod(mm)
>
> then successive calls to
>
> coef = solve(cprod, crossprod(mm, df$Va))
>
> will produce the coefficient estimates much faster than will calls to
> lm, which each do all the work of generating and decomposing the very
> large model matrix.
>
> Note that this method only produces the coefficient estimates, which
> may be enough for your purposes.  Also, this method will not handle
> missing data or rank-deficient model matrices in the elegant way that
> lm does.
>
> If you are doing this 12,000 times it may be worthwhile checking if
> the sparse matrix formulation
>
> mmS = as(mm, "cscMatrix")
> cprodS = crossprod(mmS)
>
> is faster.
>
> The dense matrix formulation (but not the sparse) can benefit from
> installation of optimized BLAS routines such as Atlas or Goto's BLAS.
>
> -- 
> Douglas Bates                            bates at stat.wisc.edu
> Statistics Department                    608/262-2598
> University of Wisconsin - Madison        
> http://www.stat.wisc.edu/~bates/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Tue May 11 14:37:51 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 May 2004 14:37:51 +0200
Subject: [R] R versus SAS: lm performance
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D6D@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF7D6D@usrymx25.merck.com>
Message-ID: <x2ekpr3zs0.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> I tried the following on an Opteron 248, R-1.9.0 w/Goto's BLAS:
> 
> > y <- matrix(rnorm(14000*1344), 1344)
> > x <- matrix(runif(1344*503),1344)
> > system.time(fit <- lm(y~x))
> [1] 106.00  55.60 265.32   0.00   0.00
> 
> The resulting fit object is over 600MB.  (The coefficient compoent is a 504
> x 14000 matrix.)
> 
> If I'm not mistaken, SAS sweeps on the extended cross product matrix to fit
> regression models.  That, I believe, in usually faster than doing QR
> decomposition on the model matrix itself, but there are trade-offs.  You
> could try what Prof. Bates suggested.

Hmm. Shouldn't be all that much faster, but it will produce the Type I
SS as you go along, whereas R probably wants to fit the 15 different
models. 

I'm still surprised that R/S-PLUS manages to use a full 15 minutes on
a single response variable. It might be due to the singularities --
the SAS code indicated that there was a nesting issue with the "A"
factor in the last 4-factor interaction. If so, a reformulation of the
model might help. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rpeng at jhsph.edu  Tue May 11 14:50:24 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 11 May 2004 08:50:24 -0400
Subject: [R] How to draw holes generated by gpclib using plot function
In-Reply-To: <004501c4370b$a42bac30$258001db@webgis>
References: <004501c4370b$a42bac30$258001db@webgis>
Message-ID: <40A0CC10.40602@jhsph.edu>

Sorry, but this limitation in plotting is something that I probably 
should have mentioned in the help page.  At the time when I wrote this 
plotting wasn't really a priority so I never thought much of it.

The GPC C library has a function has a function to return a collection 
of tristrips but this is not implemented in the R package.  It 
shouldn't be too difficult to include and I will hopefully include it 
with the next release.

-roger

Hisaji ONO wrote:
> Hi.
> 
>  I've tried to create a polygon with one hole by gpclib using following
> example script.
> 
>  holepoly <- read.polyfile(system.file("poly-ex/hole-poly.txt", package
> ="gpclib"), nohole = FALSE)
>  area.poly(holepoly)
>  plot(holepoly,poly.args=list(col="red",border="blue"))
> 
>  And I noticed plot function couldn't draw polygons with holes correctly.
> 
>  Does anyone know how to solve this situation?
> 
>  Regards.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue May 11 14:59:17 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 May 2004 13:59:17 +0100 (BST)
Subject: [R] R versus SAS: lm performance
In-Reply-To: <x2ekpr3zs0.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0405111350060.1134-100000@gannet.stats>

On 11 May 2004, Peter Dalgaard wrote:

> "Liaw, Andy" <andy_liaw at merck.com> writes:
> 
> > I tried the following on an Opteron 248, R-1.9.0 w/Goto's BLAS:
> > 
> > > y <- matrix(rnorm(14000*1344), 1344)
> > > x <- matrix(runif(1344*503),1344)
> > > system.time(fit <- lm(y~x))
> > [1] 106.00  55.60 265.32   0.00   0.00
> > 
> > The resulting fit object is over 600MB.  (The coefficient compoent is a 504
> > x 14000 matrix.)
> > 
> > If I'm not mistaken, SAS sweeps on the extended cross product matrix to fit
> > regression models.  That, I believe, in usually faster than doing QR
> > decomposition on the model matrix itself, but there are trade-offs.  

Roughly twice as fast but the price is accuracy.

> You
> > could try what Prof. Bates suggested.
> 
> Hmm. Shouldn't be all that much faster, but it will produce the Type I
> SS as you go along, whereas R probably wants to fit the 15 different
> models. 

Nope, R can read off the Type I SSQs from the QR decomposition so only one 
fit is done.  (Effectively you remove the effect of one column at a time, 
and you get the change in residual/regression SSq as a side effect. Take 
a look at anova.lm, which just aggregates squared effects over terms.)

> I'm still surprised that R/S-PLUS manages to use a full 15 minutes on
> a single response variable. It might be due to the singularities --
> the SAS code indicated that there was a nesting issue with the "A"
> factor in the last 4-factor interaction. If so, a reformulation of the
> model might help. 

I think we need to understand this better.  My guess (but only a guess) is 
that the model matrix has very many columns and is highly singular.  If 
the singularity is by design, a reformulation will help.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Tue May 11 15:06:00 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 11 May 2004 09:06:00 -0400
Subject: [R] calling data frames
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D6E@usrymx25.merck.com>

Not sure how "automated" you want, but the following might work (obviously
untested):

Guilda.list <- list(Guilda1 = c(27,48),
                    Guilda2 = c(5,17,19,20,21,24:26,40,41,77),
                    Guilda3 = c(22,28,69),
                    Guilda4 = c(29:37,78),
                    Guilda5 = c(3,8,18,23,63,82,83),
                    Guilda6 = c(6,38,39,44:62,84),
                    Guilda7 = c(1,2,42,43,64:68,79,80),
                    Guilda8 = c(7,15,16,70:76),
                    Guilda9 = c(4,9,10:14,81))
fnames<- list.files(pattern=".txt")
outfile <- "BLU_Var_%04d.txt"
for(i in seq(along=fnames)) {
    blumenau <- data.matrix(read.table(fnames[i],h=T)[2:50])
    Guild.Richness <- sapply(Guilda.list, function(idx) sum(Guildas[idx,]))
    write(Guild.Richness, file = sprintf(outfile, i), ncol = 9)
}

You can replace the for loop with lapply(), but that probably won't make
much difference...

HTH,
Andy

> From: Rog??rio Rosa da Silva
> 
> Dear List,
> 
> I've around 1000 *.txt files, I've generate with other software.
> I've now done the following code (below).
> My question is how can I automate this (with do.call () ?), 
> so it could be 
> done for all the  *.txt files.
> 
> Thanks in advance,
> Rog??rio
> 
> 
> names<- list.files()
> file <- "BLU_Var_%04d.txt"
> for(i in 1:1000){
> blumenau<-read.table("Blu_1.txt",h=T)   # 1000 *.txt files
> Guildas<-data.frame(cbind(t(blumenau[2:50])))
> Guilda1<-cbind(X27,X48)
> Guilda2<-cbind(X5,X17,X19,X20,X21,X24,X25,X26,X40,X41,X77)
> Guilda3<-cbind(X22,X28,X69)
> Guilda4<-cbind(X29,X30,X31,X32,X33,X34,X35,X36,X37,X78)
> Guilda5<-cbind(X3,X8,X18,X23,X63,X82,X83)
> Guilda6<-cbind(X6,X38,X39,X44,X45,X46,X47,X49,X50,X51,X52,X53,
> X54,X55,X56,X57,X58,X59,X60,X61,X62,X84)
> Guilda7<-cbind(X1,X2,X42,X43,X64,X65,X66,X67,X68,X79,X80)
> Guilda8<-cbind(X7,X15,X16,X70,X71,X72,X73,X74,X75,X76)
> Guilda9<-cbind(X4,X9,X10,X11,X12,X13,X14,X81)
> Resul.Guilda1<-sum(apply(Guilda1,2,sum))
> Resul.Guilda2<-sum(apply(Guilda2,2,sum))
> Resul.Guilda3<-sum(apply(Guilda3,2,sum))
> Resul.Guilda4<-sum(apply(Guilda4,2,sum))
> Resul.Guilda5<-sum(apply(Guilda5,2,sum))
> Resul.Guilda6<-sum(apply(Guilda6,2,sum))
> Resul.Guilda7<-sum(apply(Guilda7,2,sum))
> Resul.Guilda8<-sum(apply(Guilda8,2,sum))
> Resul.Guilda9<-sum(apply(Guilda9,2,sum))
> Guild.Richness<-cbind(Resul.Guilda1,Resul.Guilda2,Resul.Guilda
> 3,Resul.Guilda4,Resul.Guilda5,Resul.Guilda6,Resul.Guilda7,Resu
> l.Guilda8,Resul.Guilda9)
> write(Guild.Richness, file = sprintf(file, i), ncol = 9)
> }
> 
> 
> -- 
> Rog??rio R. Silva
> MZUSP http://www.mz.usp.br
> Linux User #354364
> Linux counter http://counter.li.org
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From p.dalgaard at biostat.ku.dk  Tue May 11 15:13:51 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 May 2004 15:13:51 +0200
Subject: [R] R versus SAS: lm performance
In-Reply-To: <Pine.LNX.4.44.0405111350060.1134-100000@gannet.stats>
References: <Pine.LNX.4.44.0405111350060.1134-100000@gannet.stats>
Message-ID: <x2ad0f3y40.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> > Hmm. Shouldn't be all that much faster, but it will produce the Type I
> > SS as you go along, whereas R probably wants to fit the 15 different
> > models. 
> 
> Nope, R can read off the Type I SSQs from the QR decomposition so only one 
> fit is done.  (Effectively you remove the effect of one column at a time, 
> and you get the change in residual/regression SSq as a side effect. Take 
> a look at anova.lm, which just aggregates squared effects over terms.)

OK, thanks.
 
> > I'm still surprised that R/S-PLUS manages to use a full 15 minutes on
> > a single response variable. It might be due to the singularities --
> > the SAS code indicated that there was a nesting issue with the "A"
> > factor in the last 4-factor interaction. If so, a reformulation of the
> > model might help. 
> 
> I think we need to understand this better.  My guess (but only a guess) is 
> that the model matrix has very many columns and is highly singular.  If 
> the singularity is by design, a reformulation will help.

It's certainly not a completely balanced factorial: 

1344=2*2*2*2*2*2*3*7

so it could be one in several way, but not with a main effects with 4 DF. 

An even less well-founded guess is that it might help to replace the
last term with interaction(Ar,Ba,Ti,Pr,drop=TRUE) (if I remembered the
names correctly). 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tlumley at u.washington.edu  Tue May 11 16:04:23 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 11 May 2004 07:04:23 -0700 (PDT)
Subject: [R] Meta-Analysis using lme
In-Reply-To: <29719.1084261811@www7.gmx.net>
References: <29719.1084261811@www7.gmx.net>
Message-ID: <Pine.A41.4.58.0405110702140.34626@homer37.u.washington.edu>

On Tue, 11 May 2004, Heike Heidemeier wrote:

> Dear list-members,
>
> I am trying to use R to conduct a meta-analysis, i.e. I'd like to use a
> multi-level model to integrate the findings of a number of primary research
> studies.
>
> I set up a simple two level-model (only summary statistics are provided by
> each study) as follows:
>
> sapp.lme <- lme(D ~ 1, data = sapp.frame, random = ~ 1 | STUDYNR,
> weights=varFixed(~-1+STDERR_D),na.action = na.exclude)
>
> The intercept is random on both levels and the variable stderr_D (the
> sampling variance) is supposed to be random only on level one. Besides, I
> need to constrain the variance of stderr_d to equal 1.
>

I think someone posted a way of doing this some time ago, but in this case
I would recommend the rmeta package

sapp.meta <- meta.summaries(D,STDERR_D, method="random", data=sapp.frame)

which will also do forest plots of the results.


	-thomas



From rolf at math.unb.ca  Tue May 11 16:10:08 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 11 May 2004 11:10:08 -0300 (ADT)
Subject: [R] Hypertext links in help files.
Message-ID: <200405111410.i4BEA8lt026005@erdos.math.unb.ca>


I've recently (finally!) installed R 1.9.0 on my laptop.  Having
done so I've encountered a mild problem with hypertext links from
help files in add-on packages to ``native'' R functions.  For example
if I load the ``spatstat'' package, and ask for help on mpl(), I can
see in the browser (I'm using mozilla) a link to glm().  When I click
on this link I get an error message:

	The file /tmp/RtmpLqFtcQ/.R/library/base/html/glm.html
	cannot be found.  Please check the location and try
	again.

(Hah!)  Well, it's no wonder that it can't be found --- glm() is no
longer in the base package, but rather in the stats package.  So
the browser should be looking for:

	/tmp/RtmpLqFtcQ/.R/library/stats/html/glm.html

The problem arises, I guess, because the package, as it stands, was
installed using R 1.8.1.  The code in ..../spatstat/html/mpl.html
does indeed point to ../../base/html/glm.html and not to
../../stat/html/glm.html as it should.

But when I re-installed spatstat using R 1.9.0, nothing changed
in this regard.

I presume I could fix things by completely removing the directory
containiny the installed version of spatstat and then re-installing
again under R 1.9.0.  But this seems a trifle indelicate.  Is there
a more graceful way of handling this problem?  Or is there something
that I should have done which would have kept this problem from
arising?  I had a fairly thorough read of the ``NEWS'' file and
could find no relevent information.

					cheers,

						Rolf Turner
						rolf at math.unb.ca

P. S. Version info:

         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    9.0              
year     2004             
month    04               
day      12               
language R



From tlumley at u.washington.edu  Tue May 11 16:10:36 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 11 May 2004 07:10:36 -0700 (PDT)
Subject: [R] Explaining Survival difference between Stata and R
In-Reply-To: <40A01772.9020304@ku.edu>
References: <40A01772.9020304@ku.edu>
Message-ID: <Pine.A41.4.58.0405110707100.34626@homer37.u.washington.edu>

On Mon, 10 May 2004, Paul Johnson wrote:

> Dear Everybody:
>
> I'm doing my usual "how does that work in R" thing with some Stata
> projects.  I find a gross gap between the Stata and R in Cox PH models,
> and I hope you can give me some pointers about what goes wrong.  I'm
> getting signals from R/Survival that the model just can't be estimated,
> but Stata spits out numbers just fine.
>
> I wonder if I should specify initial values for coxph?

It's worth a try. The other question is whether Stata has in fact
converged -- if the range of rqe is not small then its coefficient may
actually be infinite.

> I got a dataset from a student who uses Stata and try to replicate in R.
> I will share data to you in case you want to see for yourself.  Let me
> know if you want text or Stata data file.

I'd like to look at the data.  We should be able to get coxph to converge
when there is a finite mle -- the log partial likelihood is concave.

	-thomas


> In R, I try this:
>
>  > cox2 <- coxph(Surv(yrs2,ratify)~ accession+ haz.wst+ haz.in +haz.out+
> wefgov+ rle+ rqe + pol.free +tai.2001 + ny.gdp.pcap.pp.cd + eio,
> data=dat3, control=coxph.control(iter.max=1000),singular.ok=T)
> Warning message:
> Ran out of iterations and did not converge in: fitter(X, Y, strats,
> offset, init, control, weights = weights,
>
> So I wrote out the file exatly as it was in R into Stata dataset
>
>  > write.dta(dat3,"cleanBasel.dta")
> Warning message:
> Abbreviating variable names in: write.dta(dat3, "cleanBasel.dta")
>
>
> Here's the Stata output:
>
> . use "/home/pauljohn/ps/ps909/AdvancedRegression/duration_2/cleanBasel.dta"
> (Written by R.              )
>
> . stset yrs2, failure (ratify)
>
>       failure event:  ratify != 0 & ratify < .
> obs. time interval:  (0, yrs2]
>   exit on or before:  failure
>
> ----------------------------------------------------------------------------
>  > --
>         21  total obs.
>          0  exclusions
> ----------------------------------------------------------------------------
>  > --
>         21  obs. remaining, representing
>         21  failures in single record/single failure data
>         78  total analysis time at risk, at risk from t =         0
>                               earliest observed entry t =         0
>
> . stcox accessin haz_wst  haz_in  haz_out  wefgov  rle  rqe  pol_free
> tai_2001 ny_gd  eio, robust
>  >  nohr
>
>           failure _d:  ratify
>     analysis time _t:  yrs2
>
> Iteration 0:   log pseudo-likelihood = -49.054959
> Iteration 1:   log pseudo-likelihood = -45.021682
> Iteration 2:   log pseudo-likelihood = -44.525187
> Iteration 3:   log pseudo-likelihood = -44.521588
> Iteration 4:   log pseudo-likelihood = -44.521586
> Refining estimates:
> Iteration 0:   log pseudo-likelihood = -44.521586
>
> Cox regression -- Breslow method for ties
>
> No. of subjects       =           21               Number of obs   =
>      21
> No. of failures       =           21
> Time at risk          =           78
>                                                     Wald chi2(11)   =
>    81.64
> Log pseudo-likelihood =   -44.521586               Prob > chi2     =
> 0.0000
>
> ------------------------------------------------------------------------------
>               |               Robust
>            _t |      Coef.   Std. Err.      z    P>|z|
> -------------+----------------------------------------------------------------
>      accessin |  -1.114101   .6343663    -1.76   0.079
>       haz_wst |   2.32e-08   1.08e-07     0.22   0.829
>        haz_in |   3.78e-06   2.46e-06     1.54   0.124
>       haz_out |  -3.80e-07   3.76e-07    -1.01   0.312
>        wefgov |   2.139127   .9136992     2.34   0.019
>           rle |   1.827482   1.500878     1.22   0.223
>           rqe |  -3.126696   1.332069    -2.35   0.019
>      pol_free |  -.4498276    .291764    -1.54   0.123
>      tai_2001 |  -2.895922   2.577401    -1.12   0.261
>      ny_gd___ |  -.0003223   .0002194    -1.47   0.142
>           eio |  -.0577773   .0726064    -0.80   0.426
> ------------------------------------------------------------------------------
>
> .
>                                   last observed exit t =         7
>
>
> ----------------------------------
>
>
>
> Paul Johnson
> Dept. of Political Science
> University of Kansas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From Bernhard.Pfaff at drkw.com  Tue May 11 16:22:01 2004
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Tue, 11 May 2004 16:22:01 +0200
Subject: [R] bilinear and non linear
Message-ID: <18D602BD42B7E24EB810D6454A58DB900A29B900@ibfftce505.is.de.dresdnerkb.com>

> 
> Dear all,
> there are R packages able to simulate or estimate bilinear 
> model for time
> series?
> I know it is an open problem, but do exist something for very 
> simplified
> bilinear models?

Hello Dario,

well, it should be possible to estimate a bilinear model by employing nls()
or optim().

> 
> Alternatively, what kinfd of non linear time series models 
> are performed
> in R?

Almost any, have a look at the contributed packages "tseries" and "ts". You
can as well set up your own likelihood function and solve numerically (see
above). There are/should be no limitations.

> 
> If R is not able, could someone suggest me for some 
> commercial softwares
> to deal with bilinear models?


by googling on "bilenear models", I found the following link, which mentions
"XploRe" of Prof. H??rdle:

http://www.quantlet.com/mdstat/scripts/xlg/html/xlghtmlnode53.html
http://www.xplore-stat.de/index_js.html


HTH,
Bernhard 


> i'm afraid of a negative answer ...
> thanks in advance,
> Daria
> ****************************
> 
> Daria Mendola
> Dipartimento di Scienze Statistiche e Matematiche
> "Silvio Vianelli"
> Universit?? di Palermo
> Viale delle Scienze - Edificio 13
> 90128 Palermo, Italia
> tel. +39 091 6626210
> fax  +39 091 485726
> email: mendola at dssm.unipa.it
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From agustin.perez at umh.es  Tue May 11 16:31:21 2004
From: agustin.perez at umh.es (Perez Martin, Agustin)
Date: Tue, 11 May 2004 16:31:21 +0200
Subject: [R] Problem with 'expression'
Message-ID: <5AFDDD57E2771B409224CD858CC6DE0D02DAB409@mailer-e051.umh.es>

DeaR useRs:

Excuses by my English.
I have a problem with 'expression' function.

For example:

	a<-expression(exp(-x^2))
	b<-expression(exp(x^2))

And I want to calculate:

	a*b

And R returns:

	Error in a * b : non-numeric argument to binary operator

I don't know what happend.
Which is the way to making operations with expressions?
Thanks.



From Matthias.Templ at statistik.gv.at  Tue May 11 16:40:00 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Tue, 11 May 2004 16:40:00 +0200
Subject: AW: [R] Probleme with Kmeans...
Message-ID: <83536658864BC243BE3C06D7E936ABD50153A595@xchg1.statistik.local>

Sorry, to solve your question I had tried:

data(faithful)
kmeans(faithful[c(1:20),1],10)
Error: empty cluster: try a better set of initial centers

But when I run this a second time it will be ok.


It seems, that kmeans has problems to initialize good starting points, because of the random choose of these starting initial points.
With kmeans(data,k,centers=c(...) the problem can be solved.
Generally, the starting points can be choose equidistant on a hyperplane of the data, which is also a simple way to get the intitial points 
(www.fuzzyclustering.de , fc-package of H??ppner, manual). 


Thank you for your comment,
Matthias


-----Urspr??ngliche Nachricht-----
Von: Unung Istopo Hartanto [mailto:unung at enciety.com] 
Gesendet: Dienstag, 11. Mai 2004 16:23
An: TEMPL Matthias
Betreff: Re: [R] Probleme with Kmeans...


Hello Matthias,

I think kmeans able to process only one variable.

It's an example, but give me a clearly explanation if i make a mistake.

> univ
 [1] 0.7051308 0.9126754 0.6170866 0.6663761 5.8541014 0.6665355 0.9695508  [8] 1.1980253 0.9489970 0.9058717 4.0864110 0.9962518 0.7530303 1.0312622 [15] 5.0822132 3.1867548 2.3203937 0.5405755 3.6957646 0.8957396 0.8477315 [22] 0.6210427 0.8471373 3.5451798 0.4220632 0.5377178 0.3173005 0.7181018 [29] 0.9034660 1.2406042 0.9529861 3.3889001 0.8462411 0.8338748 1.8540691 [36] 1.3624104 6.9509700

> kmeans(univ,ncl)
$cluster
 [1] 5 3 5 5 4 5 3 3 3 3 1 3 5 3 4 1 2 5 1 3 3 5 3 1 5 5 5 5 3 3 3 1 3 3 2 3 4

$centers
       [,1]
1 3.5806021
2 2.0872314
3 0.9808016
4 5.9624282
5 0.5968146

$withinss
[1] 0.4622251 0.1087293 0.3637454 1.7637280 0.1768656

$size
[1]  5  2 16  3 11

Thanks a lot,

Unung Istopo

On Tue, 2004-05-11 at 17:19, TEMPL Matthias wrote:
> Hello,
> When clustering with kmeans, your data should have more than one 
> variable. Matthias



From I.Wilson at maths.abdn.ac.uk  Tue May 11 16:41:54 2004
From: I.Wilson at maths.abdn.ac.uk (Ian Wilson)
Date: Tue, 11 May 2004 15:41:54 +0100
Subject: [R] xtable with a table ?
In-Reply-To: <x265b4ql6g.fsf@biostat.ku.dk>
Message-ID: <EPEKIKNBILEAHHOLHEJDOEEMCBAA.I.Wilson@maths.abdn.ac.uk>

Any more elegant solutions to this?

> a <- sample(c("a","d","c"),100,replace=T)
> b <- sample(c("d","e","f",100,replace=T)
> t <- table(a,b)
> xtable(t)
Error in xtable(t) : no applicable method for "xtable"

The problem is that while t is a table (and
hence also a matrix)

> is.matrix(t)
[1] TRUE

 data.frame(t) produces

> data.frame(t)
  a b Freq
1 1 1   12
2 2 1   12
3 3 1    7
4 1 2    8
5 2 2   12
6 3 2   11
7 1 3   13
8 2 3   17
9 3 3    8

After a horrible solution, I have 
ct <- apply(t,2,cbind);
rownames(ct) <- rownames(t);
xtable(ct)

Is this a bug/feature, and if so how do I get round it?

Ian Wilson



From elvis at xlsolutions-corp.com  Tue May 11 16:47:00 2004
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 11 May 2004 07:47:00 -0700
Subject: [R] R/S-plus Course***In  Raleigh/Durham-RTP,
	NC***R/Splus Fundamentals and Programming Techniques,
	May 27-28, 2004
Message-ID: <20040511144700.20710.qmail@webmail-2-6.mesa1.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud 
 to announce May 2004 2-day "R/S-plus Fundamentals and 
 Programming Techniques". 

 ****Raleigh/Durham-RTP, NC --------------------> May, 27-28


 Interested in our R/Splus Advanced Programming course? Please email 
 us! 
 Reserve your seat now at the early bird rates! Payment due AFTER the 
 class. 


 Course Description: 
 This two-day beginner to intermediate R/S-plus course focuses 
  on a broad spectrum of topics, 
 from reading raw data to a comparison of R and S. We will learn 
 the essentials of data manipulation, graphical visualization 
 and R/S-plus programming. We will explore statistical data analysis 
 tools,including graphics with data sets. How to enhance your plots. 
 We will perform basic statistics and fit linear regression models. 
 Participants are encouraged to bring data for interactive sessions 


 With the following outline: 
 - An Overview of R and S 
 - Data Manipulation and Graphics 
 - Using Lattice Graphics 
 - A Comparison of R and S-Plus 
 - How can R Complement SAS? 
 - Writing Functions 
 - Avoiding Loops 
 - Vectorization 
 - Statistical Modeling 
 - Project Management 
 - Techniques for Effective use of R and S 
 - Enhancing Plots 
 - Using High-level Plotting Functions 
 - Building and Distributing Packages (libraries) 


 Email us for group discounts. 
 Email Sue Turner: sue at xlsolutions-corp.com 
 Phone: 206-686-1578 
 Visit us: www.xlsolutions-corp.com/training.htm 
 Please let us know if you and your colleagues are interested in this 
 classto take advantage of group discount. Register now to secure your 
 seat! 
 Interested in R/Splus Advanced course? email us. 


 Cheers, 
 Elvis Miller, PhD 
 Manager Training. 
 XLSolutions Corporation 
 206 686 1578 
 www.xlsolutions-corp.com 
 elvis at xlsolutions-corp.com



From p.dalgaard at biostat.ku.dk  Tue May 11 17:08:22 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 May 2004 17:08:22 +0200
Subject: [R] xtable with a table ?
In-Reply-To: <EPEKIKNBILEAHHOLHEJDOEEMCBAA.I.Wilson@maths.abdn.ac.uk>
References: <EPEKIKNBILEAHHOLHEJDOEEMCBAA.I.Wilson@maths.abdn.ac.uk>
Message-ID: <x265b33st5.fsf@biostat.ku.dk>

"Ian Wilson" <I.Wilson at maths.abdn.ac.uk> writes:

> Any more elegant solutions to this?
> 
> > a <- sample(c("a","d","c"),100,replace=T)
> > b <- sample(c("d","e","f",100,replace=T)
> > t <- table(a,b)
> > xtable(t)
> Error in xtable(t) : no applicable method for "xtable"


Others might get a different error:

> xtable(t)
Error: couldn't find function "xtable"
> library(xtable)
Error in library(xtable) : There is no package called 'xtable'


I.e. do remember to say when you're using a contributed package (and
also which version)

> After a horrible solution, I have 
> ct <- apply(t,2,cbind);
> rownames(ct) <- rownames(t);
> xtable(ct)
> 
> Is this a bug/feature, and if so how do I get round it?

I got away with 

 xtable(unclass(tb))

but of course there ought to be an xtable.table method. You still lose
the dimname-names though.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tpapp at axelero.hu  Tue May 11 17:13:24 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Tue, 11 May 2004 17:13:24 +0200
Subject: [R] Problem with 'expression'
In-Reply-To: <5AFDDD57E2771B409224CD858CC6DE0D02DAB409@mailer-e051.umh.es>
References: <5AFDDD57E2771B409224CD858CC6DE0D02DAB409@mailer-e051.umh.es>
Message-ID: <20040511151324.GA2923@localhost>

On Tue, May 11, 2004 at 04:31:21PM +0200, Perez Martin, Agustin wrote:

> For example:
> 
> 	a<-expression(exp(-x^2))
> 	b<-expression(exp(x^2))
> 
> And I want to calculate:
> 
> 	a*b

Use

t<-2
expression(a, list(x=t))*expression(b, list(x=t))

I am not sure what you are using these for, but maybe you could also
use functions --- more convenient for calculations.  Eg

a <- function(x) { exp(-x^2) }
b <- function(x) { exp(x^2) }
a(x)*b(x) # =1

For evaluating the same functions many times, see ?sapply and the
related pages.

Best,

Tamas

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From ripley at stats.ox.ac.uk  Tue May 11 17:25:36 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 May 2004 16:25:36 +0100 (BST)
Subject: [R] Hypertext links in help files.
In-Reply-To: <200405111410.i4BEA8lt026005@erdos.math.unb.ca>
Message-ID: <Pine.LNX.4.44.0405111618380.1488-100000@gannet.stats>

Reinstallation should solve this, and did for me.
Are you sure you have picked up the reinstalled version and not one in 
some other library tree?

library(help=spatstat) will tell you when it was built.

On Tue, 11 May 2004, Rolf Turner wrote:

> 
> I've recently (finally!) installed R 1.9.0 on my laptop.  Having
> done so I've encountered a mild problem with hypertext links from
> help files in add-on packages to ``native'' R functions.  For example
> if I load the ``spatstat'' package, and ask for help on mpl(), I can
> see in the browser (I'm using mozilla) a link to glm().  When I click
> on this link I get an error message:
> 
> 	The file /tmp/RtmpLqFtcQ/.R/library/base/html/glm.html
> 	cannot be found.  Please check the location and try
> 	again.
> 
> (Hah!)  Well, it's no wonder that it can't be found --- glm() is no
> longer in the base package, but rather in the stats package.  So
> the browser should be looking for:
> 
> 	/tmp/RtmpLqFtcQ/.R/library/stats/html/glm.html
> 
> The problem arises, I guess, because the package, as it stands, was
> installed using R 1.8.1.  The code in ..../spatstat/html/mpl.html
> does indeed point to ../../base/html/glm.html and not to
> ../../stat/html/glm.html as it should.
> 
> But when I re-installed spatstat using R 1.9.0, nothing changed
> in this regard.
> 
> I presume I could fix things by completely removing the directory
> containiny the installed version of spatstat and then re-installing
> again under R 1.9.0.  But this seems a trifle indelicate.  Is there
> a more graceful way of handling this problem?  Or is there something
> that I should have done which would have kept this problem from
> arising?  I had a fairly thorough read of the ``NEWS'' file and
> could find no relevent information.
> 
> 					cheers,
> 
> 						Rolf Turner
> 						rolf at math.unb.ca
> 
> P. S. Version info:
> 
>          _                
> platform i686-pc-linux-gnu
> arch     i686             
> os       linux-gnu        
> system   i686, linux-gnu  
> status                    
> major    1                
> minor    9.0              
> year     2004             
> month    04               
> day      12               
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tplate at blackmesacapital.com  Tue May 11 17:30:05 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue, 11 May 2004 09:30:05 -0600
Subject: [R] test for end of file on connection
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A54B32F7@phost015.intermedia .net>
References: <C698D707214E6F4AB39AB7096C3DE5A54B32F7@phost015.intermedia.net>
Message-ID: <6.1.0.6.2.20040511092827.0453a738@mailhost.blackmesacapital.com>

With the text of your message copied to the clipboard:

 > con <- file("clipboard", "r")
 > readLines(con, 1)
[1] "I am looking for a function to test for end-of-file on a connection."
 > readLines(con, 1)
[1] "Apparently this question was already asked a couple of years ago and"
 > readLines(con, 1)
[1] "then P. Dalgaard suggested to look at help(connections),"
 > readLines(con, 1)
[1] "help(readLines). Unfortunately, I couldn't find such a function on those"
 > readLines(con, 1)
[1] "pages, maybe I am missing something."
 > readLines(con, 1)
character(0)
 >

i.e., readLines() returns a zero length result upon reaching end of 
file.  AFAIK the other file reading functions have similar behavior.  It's 
still worth reading in detail the help for readLines().

hope this helps,

Tony Plate


At Tuesday 12:08 AM 5/11/2004, Vadim Ogranovich wrote:
>Hi,
>
>I am looking for a function to test for end-of-file on a connection.
>Apparently this question was already asked a couple of years ago and
>then P. Dalgaard suggested to look at help(connections),
>help(readLines). Unfortunately, I couldn't find such a function on those
>pages, maybe I am missing something.
>
>Did anyone figure this out?
>
>Thanks,
>Vadim
>
>
>
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From tpapp at axelero.hu  Tue May 11 17:31:33 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Tue, 11 May 2004 17:31:33 +0200
Subject: [R] Problem with 'expression'
In-Reply-To: <20040511151324.GA2923@localhost>
References: <5AFDDD57E2771B409224CD858CC6DE0D02DAB409@mailer-e051.umh.es>
	<20040511151324.GA2923@localhost>
Message-ID: <20040511153133.GA3473@localhost>

On Tue, May 11, 2004 at 05:13:24PM +0200, Tamas Papp wrote:

> > 	a<-expression(exp(-x^2))
> > 	b<-expression(exp(x^2))
> > 
> > And I want to calculate:
> > 
> > 	a*b
> 
> Use
> 
> t<-2
> expression(a, list(x=t))*expression(b, list(x=t))

Of course, I meant "eval" instead of "expression". Sorry.

Tamas

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From bolker at zoo.ufl.edu  Tue May 11 17:57:40 2004
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 11 May 2004 11:57:40 -0400 (EDT)
Subject: [R] installing mgcv (Knoppix/Debian unstable)
Message-ID: <Pine.LNX.4.44.0405111154380.26554-100000@bolker.zoo.ufl.edu>


  Just in case anyone cares or is hitting the same problem:

to install current mgcv (1.0-5) on 1.9.0 on Knoppix/Debian unstable I had 
to:

# cd /usr/lib
# ln -s /usr/lib/atlas/libblas.so.3 libblas-3.so
# ln -s /usr/lib/atlas/liblapack.so.3 liblapack-3.so

Otherwise compilation couldn't find -lblas-3 or -llapack-3
 
(I could have gotten away with the links in /usr/lib/atlas instead of
/usr/lib, as /usr/lib/atlas was listed in /etc/ld.so.conf)


-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From ggrothendieck at myway.com  Tue May 11 17:48:19 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 11 May 2004 15:48:19 +0000 (UTC)
Subject: [R] xtable with a table ?
References: <x265b4ql6g.fsf@biostat.ku.dk>
	<EPEKIKNBILEAHHOLHEJDOEEMCBAA.I.Wilson@maths.abdn.ac.uk>
Message-ID: <loom.20040511T174646-519@post.gmane.org>


t. <- table(a,b)
xtable(format(t.))

From:   Ian Wilson <I.Wilson at maths.abdn.ac.uk>
:  
: Any more elegant solutions to this?
: 
: > a <- sample(c("a","d","c"),100,replace=T)
: > b <- sample(c("d","e","f",100,replace=T)
: > t <- table(a,b)
: > xtable(t)
: Error in xtable(t) : no applicable method for "xtable"
: 
: The problem is that while t is a table (and
: hence also a matrix)
: 
: > is.matrix(t)
: [1] TRUE
: 
: data.frame(t) produces
: 
: > data.frame(t)
: a b Freq
: 1 1 1 12
: 2 2 1 12
: 3 3 1 7
: 4 1 2 8
: 5 2 2 12
: 6 3 2 11
: 7 1 3 13
: 8 2 3 17
: 9 3 3 8
: 
: After a horrible solution, I have 
: ct <- apply(t,2,cbind);
: rownames(ct) <- rownames(t);
: xtable(ct)
: 
: Is this a bug/feature, and if so how do I get round it?
: 
: Ian Wilson
:



From joans at breastcenter.tmc.edu  Tue May 11 17:54:14 2004
From: joans at breastcenter.tmc.edu (Joan Snodgrass)
Date: Tue, 11 May 2004 10:54:14 -0500
Subject: [R] ROracle package error
Message-ID: <005c01c43770$5135c640$4c38f980@ad.bcm.edu>

I am running R 1.8.1 on a Solaris 8 64-bit machine and using Oracle
9.2.0.4. I noticed that the readme for ROracle lists a problem and
suggests the following to work around it:
R CMD INSTALL --configure-args='--enable-extralibs' ROracle_0.5-4.tar.gz

I ran the following to install since we have 32-bit R and 64-bit Oracle:
R CMD INSTALL --configure-args='--enable-oracle32--enable-extralibs'
ROracle_0.5-4.tar.gz

I receive no errors during the install, but when I try to load the
package I receive the following error (which is very similar to the one
listed in the readme):
> library(ROracle)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
unable to load shared library "/usr/local/lib/R/library/ROracle/libs/ROr
acle.so": ld.so.1: /usr/local/lib/R/bin/R.bin: fatal: relocation error:
file /usr/local/lib/R/library/ROracle/libs/ROracle.so: symbol sqlcxt:
referenced symbol not found
Error in library(ROracle) : .First.lib failed

Has anyone else experienced this?  Any help would be greatly
appreciated!

Regards, 
Joan 

Joan Snodgrass <joans at breastcenter.tmc.edu>



From edd at debian.org  Tue May 11 18:01:24 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 11 May 2004 11:01:24 -0500
Subject: [R] installing mgcv (Knoppix/Debian unstable)
In-Reply-To: <Pine.LNX.4.44.0405111154380.26554-100000@bolker.zoo.ufl.edu>
References: <Pine.LNX.4.44.0405111154380.26554-100000@bolker.zoo.ufl.edu>
Message-ID: <20040511160124.GA17086@sonny.eddelbuettel.com>


Hi Ben,

On Tue, May 11, 2004 at 11:57:40AM -0400, Ben Bolker wrote:
> 
>   Just in case anyone cares or is hitting the same problem:

Any reason you choose to not install install the evailable package?

edd at chibud:~> apt-cache policy r-cran-mgcv
r-cran-mgcv:
  Installed: 0.9.6-3
  Candidate: 0.9.6-3
  Version Table:
     1.0.4-1 0
         -1 http://basebud unstable/main Packages
 *** 0.9.6-3 0
        500 http://basebud testing/main Packages
        100 /var/lib/dpkg/status
edd at chibud:~> 

> to install current mgcv (1.0-5) on 1.9.0 on Knoppix/Debian unstable I had 
> to:
> 
> # cd /usr/lib
> # ln -s /usr/lib/atlas/libblas.so.3 libblas-3.so
> # ln -s /usr/lib/atlas/liblapack.so.3 liblapack-3.so
>
> Otherwise compilation couldn't find -lblas-3 or -llapack-3

The R package may need a recompilation if something changed w.r.t. to the
libraries, though Camm is typically careful not to require this. I need to
check this, unfortunately my main build machine is currently sick.
  
> (I could have gotten away with the links in /usr/lib/atlas instead of
> /usr/lib, as /usr/lib/atlas was listed in /etc/ld.so.conf)

You should never need a fudge like this on Debian system. Something else is
not right, and we need to fix that.

Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From bolker at zoo.ufl.edu  Tue May 11 18:28:57 2004
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 11 May 2004 12:28:57 -0400 (EDT)
Subject: [R] installing mgcv (Knoppix/Debian unstable)
In-Reply-To: <20040511160124.GA17086@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.44.0405111226380.26571-100000@bolker.zoo.ufl.edu>


  Didn't know it was there (and it didn't occur to me to look ...).

  I have installed a few other of the Debianized packages, but I'm fairly
new to Debian and don't know offhand how to get a list of which packages
exist in Debian form and what their names are (or how to say "install all
R packages")

  cheers,
    Ben

On Tue, 11 May 2004, Dirk Eddelbuettel wrote:

> 
> Hi Ben,
> 
> On Tue, May 11, 2004 at 11:57:40AM -0400, Ben Bolker wrote:
> > 
> >   Just in case anyone cares or is hitting the same problem:
> 
> Any reason you choose to not install install the evailable package?
> 
> edd at chibud:~> apt-cache policy r-cran-mgcv
> r-cran-mgcv:
>   Installed: 0.9.6-3
>   Candidate: 0.9.6-3
>   Version Table:
>      1.0.4-1 0
>          -1 http://basebud unstable/main Packages
>  *** 0.9.6-3 0
>         500 http://basebud testing/main Packages
>         100 /var/lib/dpkg/status
> edd at chibud:~> 
> 
> > to install current mgcv (1.0-5) on 1.9.0 on Knoppix/Debian unstable I had 
> > to:
> > 
> > # cd /usr/lib
> > # ln -s /usr/lib/atlas/libblas.so.3 libblas-3.so
> > # ln -s /usr/lib/atlas/liblapack.so.3 liblapack-3.so
> >
> > Otherwise compilation couldn't find -lblas-3 or -llapack-3
> 
> The R package may need a recompilation if something changed w.r.t. to the
> libraries, though Camm is typically careful not to require this. I need to
> check this, unfortunately my main build machine is currently sick.
>   
> > (I could have gotten away with the links in /usr/lib/atlas instead of
> > /usr/lib, as /usr/lib/atlas was listed in /etc/ld.so.conf)
> 
> You should never need a fudge like this on Debian system. Something else is
> not right, and we need to fix that.
> 
> Dirk
> 
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From maechler at stat.math.ethz.ch  Tue May 11 18:26:05 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 11 May 2004 18:26:05 +0200
Subject: [R] SDP & QCQP
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA/SScWgRDKkWYRSKuOxiKY8KAAAAQAAAAHV0aP1aLXkqECFKS9UygOgEAAAAA@laposte.net>
References: <4494.193.205.179.2.1084275591.squirrel@dssm.unipa.it>
	<!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA/SScWgRDKkWYRSKuOxiKY8KAAAAQAAAAHV0aP1aLXkqECFKS9UygOgEAAAAA@laposte.net>
Message-ID: <16544.65181.361252.500948@gargle.gargle.HOWL>

>>>>> "Ramzi" == Ramzi TEMANNI <ramzi.temanni at laposte.net>
>>>>>     on Tue, 11 May 2004 13:45:09 +0200 writes:

    Ramzi> Hi, Are there package in R that can solve
    Ramzi> semidefinite programming problem and Quadratically
    Ramzi> Constrained Quadratic Programming ?

You have probably seen the 'quadprog' package which only
deals with quadratic "programming" of linear constraints.

as for "semidefinite" (I don't know what you mean with exactly),
note that the  solve.QP() function in the quadprog package has
an argument 'meq' :

     meq: the first `meq' constraints are treated as equality
          constraints, all further as inequality constraints (defaults
          to 0). 

so you can have both equality and inequality constraints.

---

Other constrained optimization problems can be solved with
"standard R"'s  function  constrOptim()  {thanks to Brian Ripley}; 
but that too allows only linear constraints.

Regards,
Martin Maechler



From edd at debian.org  Tue May 11 18:44:24 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 11 May 2004 11:44:24 -0500
Subject: [R] installing mgcv (Knoppix/Debian unstable)
In-Reply-To: <Pine.LNX.4.44.0405111226380.26571-100000@bolker.zoo.ufl.edu>
References: <20040511160124.GA17086@sonny.eddelbuettel.com>
	<Pine.LNX.4.44.0405111226380.26571-100000@bolker.zoo.ufl.edu>
Message-ID: <20040511164424.GA17686@sonny.eddelbuettel.com>

On Tue, May 11, 2004 at 12:28:57PM -0400, Ben Bolker wrote:
> 
>   Didn't know it was there (and it didn't occur to me to look ...).
> 
>   I have installed a few other of the Debianized packages, but I'm fairly
> new to Debian and don't know offhand how to get a list of which packages
> exist in Debian form and what their names are (or how to say "install all
> R packages")

Communicating that is indeed a problem, as is keeping up changes in CRAN (as
I had missed the 1.0.5 of mgcv).  IIRC Doug Bates had recently posted a nice
expression to be run from inside R. I tend to use the shell, so something
like this works (but it still 'misses' goodies like ESS or Ggobi):

edd at homebud:~> apt-cache search "r-" | grep "^r-"
r-base - GNU R statistical computing language and environment
r-base-core - GNU R core of statistical computing language and environment
r-base-dev - GNU R installation of auxiliary GNU R packages
r-base-html - GNU R html docs for statistical computing system functions
r-base-latex - GNU R LaTeX docs for statistical computing system functions
r-cran-abind - GNU R abind multi-dimensional array combination function
r-cran-boot - GNU R package for bootstrapping functions from Davison and Hinkley
r-cran-car - GNU R Companion to Applied Regression by John Fox
r-cran-cluster - GNU R package for cluster analysis by Rousseeuw et al
r-cran-coda - Output analysis and diagnostics for MCMC simulations in R
r-cran-dbi - database interface for R
r-cran-design - GNU R regression modeling strategies tools by Frank Harrell
r-cran-effects - GNU R graphical and tabular effects display for glm models
r-cran-foreign - GNU R package to read / write data from other statistical systems
r-cran-gtkdevice - GNU R Gtk device driver package
r-cran-hmisc - GNU R miscellaneous functions by Frank Harrell
r-cran-its - GNU R package for handling irregular time series
r-cran-kernsmooth - GNU R package for kernel smoothing and density estimation
r-cran-lattice - GNU R package for 'Trellis' graphics
r-cran-lmtest - GNU R package for diagnostic checking in linear models
r-cran-mapdata - GNU R support for producing geographic maps (supplemental data)
r-cran-maps - GNU R support for producing geographic maps
r-cran-mcmcpack - GNU R routines for Markov chain Monte Carlo model estimation
r-cran-mgcv - GNU R package for multiple parameter smoothing estimation
r-cran-multcomp - GNU R package for multiple comparison procedures
r-cran-mvtnorm - GNU R package to compute multivariate Normal and T distributions
r-cran-nlme - GNU R package for (non-)linear mixed effects models
r-cran-qtl - [Biology] GNU R package for genetic marker linkage analysis
r-cran-quadprog - GNU R package for solving quadratic programming problems
r-cran-rcmdr - GNU R platform-independent basic-statistics GUI
r-cran-relimp - GNU R package for inference on relative importance of regressors
r-cran-rgl - GNU R package for three-dimensional visualisation using OpenGL
r-cran-rmysql - MySQL interface for R
r-cran-rodbc - GNU R package for ODBC database access
r-cran-rpart - GNU R package for recursive partitioning and regression trees
r-cran-rquantlib - GNU R package interfacing the QuantLib finance library
r-cran-sm - GNU R package for kernel smoothing methods
r-cran-statdataml - GNU R package for XML-based data exchange
r-cran-survival - GNU R package for survival analysis
r-cran-tkrplot - GNU R embedded Tk plotting device package
r-cran-tseries - GNU R package for time-series analysis and comp. finance
r-cran-vr - GNU R package accompanying the Venables and Ripley book on S
r-cran-xml - An XML package for the R language
r-doc-html - GNU R html manuals for statistical computing system
r-doc-info - GNU R info manuals statistical computing system
r-doc-pdf - GNU R pdf manuals for statistical computing system
r-gnome - GNU R Gnome gui for statistical computing system
r-mathlib - GNU R standalone mathematics library
r-noncran-lindsey - GNU R libraries contributed by Jim and Patrick Lindsey
r-omegahat-rgtk - GNU R binding for Gtk
r-other-gking-zelig - GNU R package providing a unified front-end for estimating statistical models
r-recommended - GNU R collection of recommended packages [metapackage]
r-omegahat-ggobi - GNU R package for the GGobi data visualization system
r-cran-mapproj - GNU R support for cartographic projections of map data
r-cran-cgiwithr - GNU R package for interpretation and creation of web forms
r-cran-cgiwithr-doc - GNU R package CGIwithR - documentation
r-cran-gregmisc - GNU R package with miscellaneous functions by Greg Warnes et al
r-cran-rpvm - GNU R package interfacing PVM libraries for distributed computing
r-cran-rmpi - GNU R package interfacing MPI libraries for distributed computing
r-cran-snow - GNU R package for 'simple network of workstations' dist. computing
edd at homebud:~> 

This list is probably longer than what you'd get on your system as it
contains some local packages not yet in Debian (e.g. pvm, mpi, snow) and
maybe something I did as Debian package sponsoring too ...

We try to be "formal" about the names, so it should be 
	r-cran-$CRANNAME
or
	r-other-$AUTHOR-$NAME    (as with Gary King et al's 'zelig')
but that isn't religiously enforced yet.

Lastly, if you're already based on Knoppix, you could also try using my
Quantian derivative of Knoppix -- it will have most if not all of the above
already installed; see http://dirk.eddelbuettel.com/quantian for details.  

Regards, Dirk

> 
>   cheers,
>     Ben
> 
> On Tue, 11 May 2004, Dirk Eddelbuettel wrote:
> 
> > 
> > Hi Ben,
> > 
> > On Tue, May 11, 2004 at 11:57:40AM -0400, Ben Bolker wrote:
> > > 
> > >   Just in case anyone cares or is hitting the same problem:
> > 
> > Any reason you choose to not install install the evailable package?
> > 
> > edd at chibud:~> apt-cache policy r-cran-mgcv
> > r-cran-mgcv:
> >   Installed: 0.9.6-3
> >   Candidate: 0.9.6-3
> >   Version Table:
> >      1.0.4-1 0
> >          -1 http://basebud unstable/main Packages
> >  *** 0.9.6-3 0
> >         500 http://basebud testing/main Packages
> >         100 /var/lib/dpkg/status
> > edd at chibud:~> 
> > 
> > > to install current mgcv (1.0-5) on 1.9.0 on Knoppix/Debian unstable I had 
> > > to:
> > > 
> > > # cd /usr/lib
> > > # ln -s /usr/lib/atlas/libblas.so.3 libblas-3.so
> > > # ln -s /usr/lib/atlas/liblapack.so.3 liblapack-3.so
> > >
> > > Otherwise compilation couldn't find -lblas-3 or -llapack-3
> > 
> > The R package may need a recompilation if something changed w.r.t. to the
> > libraries, though Camm is typically careful not to require this. I need to
> > check this, unfortunately my main build machine is currently sick.
> >   
> > > (I could have gotten away with the links in /usr/lib/atlas instead of
> > > /usr/lib, as /usr/lib/atlas was listed in /etc/ld.so.conf)
> > 
> > You should never need a fudge like this on Debian system. Something else is
> > not right, and we need to fix that.
> > 
> > Dirk
> > 
> > 
> 
> -- 
> 620B Bartram Hall                            bolker at zoo.ufl.edu
> Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
> Box 118525                                   (ph)  352-392-5697
> Gainesville, FL 32611-8525                   (fax) 352-392-3704
> 
> 

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From bates at stat.wisc.edu  Tue May 11 19:15:37 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 May 2004 12:15:37 -0500
Subject: [R] SDP & QCQP
In-Reply-To: <16544.65181.361252.500948@gargle.gargle.HOWL>
References: <4494.193.205.179.2.1084275591.squirrel@dssm.unipa.it>
	<!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA/SScWgRDKkWYRSKuOxiKY8KAAAAQAAAAHV0aP1aLXkqECFKS9UygOgEAAAAA@laposte.net>
	<16544.65181.361252.500948@gargle.gargle.HOWL>
Message-ID: <6r65b2996u.fsf@bates4.stat.wisc.edu>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> >>>>> "Ramzi" == Ramzi TEMANNI <ramzi.temanni at laposte.net>
> >>>>>     on Tue, 11 May 2004 13:45:09 +0200 writes:
> 
>     Ramzi> Hi, Are there package in R that can solve
>     Ramzi> semidefinite programming problem and Quadratically
>     Ramzi> Constrained Quadratic Programming ?
> 
> You have probably seen the 'quadprog' package which only
> deals with quadratic "programming" of linear constraints.
> 
> as for "semidefinite" (I don't know what you mean with exactly),

It means optimizing a function of the elements of a positive
semidefinite symmetric matrix so the constraints are with respect to
the matrix properties.  See
        http://rutcor.rutgers.edu/~alizadeh/Sdppage/index.html
or
        http://www-user.tu-chemnitz.de/~helmberg/semidef.html



From Arne.Muller at aventis.com  Tue May 11 19:50:12 2004
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Tue, 11 May 2004 19:50:12 +0200
Subject: [R] R versus SAS: lm performance
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1D7@crbsmxsusr04.pharma.aventis.com>

Thanks All, for your help. There seems to be a lot I can try to speed up the fits. However, I'd like to go for a much simpler model which I think is justified  by the experiment itself, e.g; I may think about removing the nestinh "(Ba:Ti:Do)/Ar".

The model matrix has 1344 rows and 2970 columns, and the rank of the matrix is 504. Therefore I think I should reformulate the model.

I was just stroke my the massive difference in performance when my collegue told me about the difference between SAS and S+.

	kind regards,

	Arne

--
Arne Muller, Ph.D.
Toxicogenomics, Aventis Pharma
arne dot muller domain=aventis com

> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com]
> Sent: 11 May 2004 14:20
> To: Muller, Arne PH/FR; ripley at stats.ox.ac.uk
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] R versus SAS: lm performance
> 
> 
> I tried the following on an Opteron 248, R-1.9.0 w/Goto's BLAS:
> 
> > y <- matrix(rnorm(14000*1344), 1344)
> > x <- matrix(runif(1344*503),1344)
> > system.time(fit <- lm(y~x))
> [1] 106.00  55.60 265.32   0.00   0.00
> 
> The resulting fit object is over 600MB.  (The coefficient 
> compoent is a 504
> x 14000 matrix.)
> 
> If I'm not mistaken, SAS sweeps on the extended cross product 
> matrix to fit
> regression models.  That, I believe, in usually faster than doing QR
> decomposition on the model matrix itself, but there are 
> trade-offs.  You
> could try what Prof. Bates suggested.
> 
> Andy
> 
> > From: Arne.Muller at aventis.com
> > 
> > Hello,
> > 
> > thanks for your reply. I've now done the profiling, and I 
> > interpret that the most time is spend in the fortran routine(s):
> > 
> > Each sample represents 0.02 seconds.
> > Total run time: 920.219999999453 seconds.
> > 
> > Total seconds: time spent in function and callees.
> > Self seconds: time spent in function alone.
> > 
> >    %       total       %       self
> >  total    seconds     self    seconds    name
> > 100.00    920.22      0.02      0.16     "lm"
> >  99.96    919.88      0.10      0.88     "lm.fit"
> >  99.74    917.84     99.74    917.84     ".Fortran"
> >   0.07      0.66      0.02      0.14     "storage.mode<-"
> >   0.06      0.52      0.00      0.00     "eval"
> >   0.06      0.52      0.04      0.34     "as.double"
> >   0.02      0.22      0.02      0.22     "colnames<-"
> >   0.02      0.20      0.02      0.20     "structure"
> >   0.02      0.18      0.02      0.18     "model.matrix.default"
> >   0.02      0.18      0.02      0.18     "as.double.default"
> >   0.02      0.18      0.00      0.00     "model.matrix"
> >   0.01      0.08      0.01      0.08     "list"
> > 
> >    %       self        %       total
> >  self     seconds    total    seconds    name
> >  99.74    917.84     99.74    917.84     ".Fortran"
> >   0.10      0.88     99.96    919.88     "lm.fit"
> >   0.04      0.34      0.06      0.52     "as.double"
> >   0.02      0.22      0.02      0.22     "colnames<-"
> >   0.02      0.20      0.02      0.20     "structure"
> >   0.02      0.18      0.02      0.18     "as.double.default"
> >   0.02      0.18      0.02      0.18     "model.matrix.default"
> >   0.02      0.16    100.00    920.22     "lm"
> >   0.02      0.14      0.07      0.66     "storage.mode<-"
> >   0.01      0.08      0.01      0.08     "list"
> > 
> > I guess this actually means I cannot do anything about it ... 
> > other than maybe splitting the problem into different 
> > (independaent parts - which I actually may be able to).
> > 
> > Regarding the usage of lm.fit instead of lm, this might be a 
> > good idea, since I am using the same model.matrix for all 
> > fits! However, I'd need to recreate an lm object from the 
> > output, because I'd like to run the anova function on this. 
> > I'll first do some profiling on lm versus lm.fit for the 
> > 12,000 models ...
> > 
> > 	kind regards + thanks again for your help,
> > 
> > 	Arne
> > 
> > --
> > Arne Muller, Ph.D.
> > Toxicogenomics, Aventis Pharma
> > arne dot muller domain=aventis com
> > 
> > > -----Original Message-----
> > > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > > Sent: 11 May 2004 09:08
> > > To: Muller, Arne PH/FR
> > > Cc: r-help at stat.math.ethz.ch
> > > Subject: Re: [R] R versus SAS: lm performance
> > > 
> > > 
> > > The way to time things in R is system.time().
> > > 
> > > Without knowing much more about your problem we can only 
> > > guess where R is 
> > > spending the time.  But you can find out by profiling -- see 
> > > `Writing R 
> > > Extensions'.
> > > 
> > > If you want multiple fits with the same design matrix (do 
> you?) you 
> > > could look at the code of lm and call lm.fit repeatedly yourself.
> > > 
> > > On Mon, 10 May 2004 Arne.Muller at aventis.com wrote:
> > > 
> > > > Hello,
> > > > 
> > > > A collegue of mine has compared the runtime of a linear 
> > > model + anova in SAS and S+. He got the same results, but SAS 
> > > took a bit more than a minute whereas S+ took 17 minutes. 
> > > I've tried it in R (1.9.0) and it took 15 min. Neither 
> > > machine run out of memory, and I assume that all machines 
> > > have similar hardware, but the S+ and SAS machines are on 
> > > windows whereas the R machine is Redhat Linux 7.2.
> > > > 
> > > > My question is if I'm doing something wrong (technically) 
> > > calling the lm routine, or (if not), how I can optimize the 
> > > call to lm or even using an alternative to lm. I'd like to 
> > > run about 12,000 of these models in R (for a gene expression 
> > > experiment - one model per gene, which would take far too long).
> > > > 
> > > > I've run the follwong code in R (and S+):
> > > > 
> > > > > options(contrasts=c('contr.helmert', 'contr.poly'))
> > > > 
> > > > The 1st colum is the value to be modeled, and the others 
> > > are factors.
> > > > 
> > > > > names(df.gene1data) <- c("Va", "Ba", "Ti", "Do", "Ar", "Pr")
> > > > > df[c(1:2,1343:1344),]
> > > >            Va    Do  Ti  Ba Ar    Pr
> > > > 1    2.317804 000mM 24h NEW  1     1
> > > > 2    2.495390 000mM 24h NEW  2     1
> > > > 8315 2.979641 025mM 04h PRG 83    16
> > > > 8415 4.505787 000mM 04h PRG 84    16
> > > > 
> > > > this is a dataframe with 1344 rows.
> > > > 
> > > > x <- Sys.time();
> > > > wlm <- lm(Va ~
> > > > 
> > > Ba+Ti+Do+Pr+Ba:Ti+Ba:Do+Ba:Pr+Ti:Do+Ti:Pr+Do:Pr+Ba:Ti:Do+Ba:Ti
> > > :Pr+Ba:Do:Pr+Ti:Do:Pr+Ba:Ti:Do:Pr+(Ba:Ti:Do)/Ar, data=df, 
> > singular=T);
> > > > difftime(Sys.time(), x)
> > > > 
> > > > Time difference of 15.33333 mins
> > > > 
> > > > > anova(wlm)
> > > > Analysis of Variance Table
> > > > 
> > > > Response: Va
> > > >              Df Sum Sq Mean Sq   F value    Pr(>F)    
> > > > Ba            2    0.1     0.1    0.4262  0.653133    
> > > > Ti            1    2.6     2.6   16.5055 5.306e-05 ***
> > > > Do            4    6.8     1.7   10.5468 2.431e-08 ***
> > > > Pr           15 5007.4   333.8 2081.8439 < 2.2e-16 ***
> > > > Ba:Ti         2    3.2     1.6    9.8510 5.904e-05 ***
> > > > Ba:Do         7    2.8     0.4    2.5054  0.014943 *  
> > > > Ba:Pr        30   80.6     2.7   16.7585 < 2.2e-16 ***
> > > > Ti:Do         4    8.7     2.2   13.5982 9.537e-11 ***
> > > > Ti:Pr        15    2.4     0.2    1.0017  0.450876    
> > > > Do:Pr        60   10.2     0.2    1.0594  0.358551    
> > > > Ba:Ti:Do      7    1.4     0.2    1.2064  0.296415    
> > > > Ba:Ti:Pr     30    5.6     0.2    1.1563  0.259184    
> > > > Ba:Do:Pr    105   14.2     0.1    0.8445  0.862262    
> > > > Ti:Do:Pr     60   14.8     0.2    1.5367  0.006713 ** 
> > > > Ba:Ti:Do:Pr 105   15.8     0.2    0.9382  0.653134    
> > > > Ba:Ti:Do:Ar  56   26.4     0.5    2.9434 2.904e-11 ***
> > > > Residuals   840  134.7     0.2                        
> > > > 
> > > > The corresponding SAS program from my collegue is:
> > > > 
> > > > proc glm data = "the name of the data set";
> > > > 
> > > > class B T D A P;
> > > > 
> > > > model V = B T D P B*T B*D B*P T*D T*P D*P B*T*D B*T*P B*D*P 
> > > T*D*P B*T*D*P A(B*T*D);
> > > > 
> > > > run;
> > > > 
> > > > Note, V = Va, B = Ba, T = Ti, D = Do, P = Pr, A = Ar of the 
> > > R-example
> > > 
> > > -- 
> > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > Professor of Applied Statistics,  
> http://www.stats.ox.ac.uk/~ripley/
> > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > > 
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its 
> affiliates (which may be known outside the United States as 
> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted 
> and/or legally privileged. It is intended solely for the use 
> of the individual or entity named on this message.  If you 
> are not the intended recipient, and have received this 
> message in error, please notify us immediately by reply 
> e-mail and then delete it from your system.
> --------------------------------------------------------------
> ----------------
>



From fciclone at bol.com.br  Tue May 11 20:30:41 2004
From: fciclone at bol.com.br (fciclone)
Date: Tue, 11 May 2004 15:30:41 -0300
Subject: [R] lags and differences
Message-ID: <HXKBF5$008120B5828404D9349B43E99FF9D364@bol.com.br>

Dear all, could someone please clarify me if this 
works, so as to implement lags and differences for 
example in y and in a independent x1 of a  regression?

model<-lm((diff(y), -i)~x1+lag(x1,-1), data=anydata)


Thanks, a lot,
Alexandre.


---------- In??cio da mensagem original -----------

      De: r-help-bounces at stat.math.ethz.ch
    Para: r-help at stat.math.ethz.ch
      Cc: 
    Data: Tue, 11 May 2004 15:48:19 +0000 (UTC)
 Assunto: Re: [R] xtable with a table ?

> 
> t. <- table(a,b)
> xtable(format(t.))
> 
> From:   Ian Wilson <I.Wilson at maths.abdn.ac.uk>
> :  
> : Any more elegant solutions to this?
> : 
> : > a <- sample(c("a","d","c"),100,replace=T)
> : > b <- sample(c("d","e","f",100,replace=T)
> : > t <- table(a,b)
> : > xtable(t)
> : Error in xtable(t) : no applicable method 
for "xtable"
> : 
> : The problem is that while t is a table (and
> : hence also a matrix)
> : 
> : > is.matrix(t)
> : [1] TRUE
> : 
> : data.frame(t) produces
> : 
> : > data.frame(t)
> : a b Freq
> : 1 1 1 12
> : 2 2 1 12
> : 3 3 1 7
> : 4 1 2 8
> : 5 2 2 12
> : 6 3 2 11
> : 7 1 3 13
> : 8 2 3 17
> : 9 3 3 8
> : 
> : After a horrible solution, I have 
> : ct <- apply(t,2,cbind);
> : rownames(ct) <- rownames(t);
> : xtable(ct)
> : 
> : Is this a bug/feature, and if so how do I get round 
it?
> : 
> : Ian Wilson
> :
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-
project.org/posting-guide.html
> 
 
__________________________________________________________________________
Acabe com aquelas janelinhas que pulam na sua tela.
AntiPop-up UOL - ?? gr??tis!
http://antipopup.uol.com.br/



From ripley at stats.ox.ac.uk  Tue May 11 20:47:50 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 May 2004 19:47:50 +0100 (BST)
Subject: [R] lags and differences
In-Reply-To: <HXKBF5$008120B5828404D9349B43E99FF9D364@bol.com.br>
Message-ID: <Pine.LNX.4.44.0405111943240.1907-100000@gannet.stats>

Lags apply to time series, and are ignored by lm.  You need to do 
something like

    dat <- ts.intersect(y1=diff(y), x1, x11 = lag(x1,-1), dframe=TRUE)
    lm(y1 ~ x1 + x11, data=dat)

On Tue, 11 May 2004, fciclone wrote:

> Dear all, could someone please clarify me if this 
> works, so as to implement lags and differences for 
> example in y and in a independent x1 of a  regression?
> 
> model<-lm((diff(y), -i)~x1+lag(x1,-1), data=anydata)

And DON'T tag onto an irrelevant post from another thread, as the posting 
guide specifically asks you not to!


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Roger.Bivand at nhh.no  Tue May 11 21:40:21 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 11 May 2004 21:40:21 +0200 (CEST)
Subject: [R] How to draw holes generated by gpclib using plot function
In-Reply-To: <40A0835F.6090009@stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0405112105270.5082-100000@reclus.nhh.no>

On Tue, 11 May 2004, Ross Ihaka wrote:

> Hisaji ONO wrote:
> > Hi.
> > 
> >  I've tried to create a polygon with one hole by gpclib using following
> > example script.
> > 
> >  holepoly <- read.polyfile(system.file("poly-ex/hole-poly.txt", package
> > ="gpclib"), nohole = FALSE)
> >  area.poly(holepoly)
> >  plot(holepoly,poly.args=list(col="red",border="blue"))
> > 
> >  And I noticed plot function couldn't draw polygons with holes correctly.
> > 
> >  Does anyone know how to solve this situation?
> 
> This is basic constraint in the R graphics system.  Polygons must
> consist of a single (possibly self-intersecting) ring.  It would be
> possible to implement a primitive which is bounded by several
> non-intersecting rings by joining the interior holes to the outer
> boundary to create a simply connected shape. Then you could draw
> the interior with the existing polygon primitive.  You can find a
> more precise description of the process in the FIST (fast
> industrial-strength triangulation) paper:
> 
>  M. Held (2001):
> ``FIST: Fast Industrial-Strength Triangulation of Polygons''.
> Algorithmica 30(4): 563-596, 2001.
> 
> It would be VERY useful to have an implementation of this (hint, hint!)
> 

Is an unpleasing fix to accept the overfilling, and to order (and mark if
known) the contained polygons - some GIS use ring direction to suggest
which are lakes and which islands? This may mean that some polygons get
painted several times, but I don't know if this is avoidable at present.
For Hisaji's problem this would mean overpainting the later hole with a
background colour (not "transparent" or NA), setting this as the col=
argument in polygon(). For many polygons finding which are inside which,
to set the painting order, could be messy by brute force, but would just
need to output an index vector to re-order the polygons and the painting
col= argument. Before several packages try to solve/find working though
admittedly ugly fixes to this separately, should we share ideas?

> Alternatively, I think that gpc has an option to return a triangulated
> version of the polygon.  If you get hold of this you could just draw the
> triangles. though this might be slow for complex polygons.
> 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From tapo at novozymes.com  Tue May 11 22:24:19 2004
From: tapo at novozymes.com (TAPO (Thomas Agersten Poulsen))
Date: Tue, 11 May 2004 22:24:19 +0200
Subject: [R] Fitting data from a spectrophotometer.
Message-ID: <76F96CFE2AA2114C886B028A065A7FC402074E5A@exdkba020.novo.dk>

Dear R-list,

	It is not uncommon for laboratory equipment (e.g. spectrophotometers) to have a linear response in a certain interval and then go into saturation. I wonder if there is an R-function that models this; for instance by estimating the breakpoint and fitting a line below the breakpoint and a constant above.

Best regards
Thomas Poulsen

--
Thomas Poulsen		      Research Scientist. PhD, MSc
Novozymes A/S			Protein Design / Bioinformatics
Brudelysvej 26, 1US.24		Phone:	+45 44 42 27 23
DK-2880 Bagsv??rd.



From GPetris at uark.edu  Tue May 11 22:31:53 2004
From: GPetris at uark.edu (Giovanni Petris)
Date: Tue, 11 May 2004 15:31:53 -0500 (CDT)
Subject: [R] Question about predict.multinom()
Message-ID: <200405112031.i4BKVrqi005073@definetti.uark.edu>


Hello,

This is the fitted model:

> fit
Call:
multinom(formula = resp ~ pred$cls + pred$smoke)

Coefficients:
             (Intercept)  pred$cls2   pred$cls3   pred$cls4  pred$cls5 pred$smoke2 pred$smoke3
Proteinuria    -1.140520  0.1616644  0.05554898 -0.01584927 0.02574805  -0.4057245  -0.2898425
Hypertension   -2.691215 -0.3699690 -0.22582107  0.01615898 0.26318005   0.1239051   0.2413282
Both           -2.285950 -0.4473108 -0.16212932 -0.10477158 0.01272335  -0.4852405  -0.6290152

Residual Deviance: 22809.76 
AIC: 22851.76 

... and these, to my understanding, should be the estimated category
probabilities for a subject in the first `cls' category and 3rd
`smoke' category:

> predict(fit, newdata=data.frame(cls=factor("1",levels=levels(pred$cls)),
+ smoke=factor("3",levels=levels(pred$smoke))), type="probs")
     Neither  Proteinuria Hypertension         Both 
   0.6715336    0.7394394    0.7247787    0.6722327 

Why I am not getting probabilities? Could somebody tell me what I am
missing? 

Thank you in advance,
Giovanni

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From sundar.dorai-raj at PDF.COM  Tue May 11 22:43:23 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 11 May 2004 13:43:23 -0700
Subject: [R] Fitting data from a spectrophotometer.
In-Reply-To: <76F96CFE2AA2114C886B028A065A7FC402074E5A@exdkba020.novo.dk>
References: <76F96CFE2AA2114C886B028A065A7FC402074E5A@exdkba020.novo.dk>
Message-ID: <40A13AEB.90407@pdf.com>



TAPO (Thomas Agersten Poulsen) wrote:
 > Dear R-list,
 >
 > 	It is not uncommon for laboratory equipment (e.g. 
spectrophotometers) to have a linear response in a certain interval and 
then go into saturation. I wonder if there is an R-function that models 
this; for instance by estimating the breakpoint and fitting a line below 
the breakpoint and a constant above.
 >
 > Best regards
 > Thomas Poulsen
 >
 > --
 > Thomas Poulsen		      Research Scientist. PhD, MSc
 > Novozymes A/S			Protein Design / Bioinformatics
 > Brudelysvej 26, 1US.24		Phone:	+45 44 42 27 23
 > DK-2880 Bagsv??rd.
 >
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

I don't know if there is something this specific out there already, but 
you could use ?optim to do this. Here's a quick example:

set.seed(1)
x <- rnorm(100)
y <- ifelse(x < 0, 1 + 4 * x, 1) + rnorm(100, sd = 0.2)

brk <- function(par, x, y) {
   a <- par[1] # intercept
   b <- par[2] # slope
   p <- par[3] # break point
   h <- par[4] # height of saturation
   yhat <- ifelse(x < p, a + b * x, h)
   sum((y - yhat)^2)
}

st <- coef(lm(y ~ x)) # starting values
fit <- optim(c(st, 0, 0), brk, x = x, y = y)
a <- fit$par[1]
b <- fit$par[2]
p <- fit$par[3]
h <- fit$par[4]

yhat <- ifelse(x < p, a + b * x, h)
plot(y ~ x)
lines(x[order(x)], yhat[order(x)])



From rwang at math.ucalgary.ca  Tue May 11 23:18:43 2004
From: rwang at math.ucalgary.ca (Rui)
Date: Tue, 11 May 2004 15:18:43 -0600
Subject: [R] How to use c routines in the exiting package?
Message-ID: <000201c4379d$89e38900$f63d9f88@math.ucalgary.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040511/86ad6f3b/attachment.pl

From vograno at evafunds.com  Tue May 11 23:29:54 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Tue, 11 May 2004 14:29:54 -0700
Subject: [R] recover should send messages to stderr, not stdout
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B32FB@phost015.EVAFUNDS.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040511/dfc0a143/attachment.pl

From thoar at cgd.ucar.edu  Tue May 11 23:41:56 2004
From: thoar at cgd.ucar.edu (Tim Hoar)
Date: Tue, 11 May 2004 15:41:56 -0600 (MDT)
Subject: [R] R 1.9.0 on AIX, 64-bit
In-Reply-To: <40963AC3.1000702@stny.rr.com>
Message-ID: <Pine.GSO.4.30.0405111453160.1132-100000@sunray1>

Here is a followup to Andy's post -- I have a working 64-bit R on AIX ...

My institution is running AIX 5.1.

Several things are needed to build R 1.9.0 and use dynamic loading of .so
objects.

*) setenv OBJECT_MODE 64       or the equivalent.

*) There is a quirk (bug?) in the AIX compilers in 64bit mode that requires
   changing configure:line 36555      to initialize a variable to zero.
   Line 36555 should be:  time_t ct=0;

   without the change -- configure hits a test for POSIX times and hangs ...

   This can also be overcome by using -qinitauto=00, but it is
   a performance hit ... so it is probably undesirable in the long run.

   Note that in 32bit mode, this is not needed.

*) The dynamic linking options specified in the R Installation and
   Administration Guide: Section B.7.8 did not work for me --
   the ones that did work are:

OBJECT_MODE=64
LDFLAGS='-brtl'
CFLAGS='-O -qstrict'
FFLAGS='-O -qstrict'
CXXFLAGS='-O -qstrict'
CC=/usr/bin/xlc_r
F77=/usr/bin/xlf_r
CXX=/usr/bin/xlC_r

   furthermore, I was able to configure with the X11 libraries (and did not
   have to supply the "--without-blas" option):

   ./configure --prefix='blah_blah_blah'

   it is nice to be able to plot!
   Our IBM rep indicated that with LDFLAGS set as above, "configure" is
   generally smart enough to figure out everything else -- kudos to the R
   configure team. I have not tried a higher level of optimization.

*) Our system does not have a 32,64-bit /lib/crt0.o  -- ours is only 32bit.
   Our 64bit one is /lib/crt0_64.o   so after configure generates a
   Makeconf file, it must be edited to use /lib/crt0_64.o  instead of crt0.o

*) (credit to Andy Pierce)

> Date: Mon, 10 May 2004 13:31:22 -0400
> From: Andy Pierce <apierce at stny.rr.com>
> To: Tim Hoar <thoar at ucar.edu>
> Subject: Re: [R] R 1.9.0 on AIX, 64-bit
>
> I worked the problem down to where there seems to be something wrong
> with mktime in the way that R uses it.... I modified src/main/datetime.c
> to add the lines for _AIX which you see below...  oddly, if you
> extract out the mktime code from here and stuff it into a standalone
> routine, it seems to work fine. It's all in the handling of dates from
> before the epoch (1970).
>
> static Rboolean have_broken_mktime(void)
> {
> #ifdef _AIX
>      return TRUE;
> #else
> #ifdef Win32
>
>      return TRUE;
>
> (the rest of the existing function....
>
> #endif
> }

*) Our system is configured such that it is guaranteed to fail the
   "running tests of Internet and socket function" tests, so I have
   not run any of the tests after that -- yet.

*) (again - credit to Andy Pierce)
   When I tried to build the SparseM package -- there was an unresolved
   external -- "etime"

   Adding a file "etime.c" to the SparseM/src  with the following:

#include <sys/time.h>
#include <sys/resource.h>
float etime(tt)
float tt[2];
{
   int who;
   struct rusage used;
   who = 0;
   getrusage(who,&used);
/*   tt[0] = used.ru_exutime.tv_sec+((used.ru_exutime.tv_usec)/1000000.); */
   tt[0] = used.ru_utime.tv_sec+((used.ru_utime.tv_usec)/1000000.);
   tt[1] = used.ru_stime.tv_sec+((used.ru_stime.tv_usec)/1000000.);
   return(tt[0]+tt[1]);
}

I did not find any problems in the config.log or the build output that
indicates etime is a problem anywhere else.

-=-=-=-=-=-=-=-=-=-=-

After all the above -- I can dyn.load(), generate figures, etc.
Hope this helps someone ...

Tim

<Andy's post from Mon, 03 May 2004 08:27:47 -0400  deleted>


## Tim Hoar, Associate Scientist              email: thoar at ucar.edu     ##
## Geophysical Statistics Project             phone: 303-497-1708       ##
## National Center for Atmospheric Research   FAX  : 303-497-1333       ##
## Boulder, CO  80307                    http://www.cgd.ucar.edu/~thoar ##



From lmassis at yahoo.com.br  Wed May 12 02:12:28 2004
From: lmassis at yahoo.com.br (Leonard assis)
Date: Tue, 11 May 2004 21:12:28 -0300
Subject: [R] Sem error - subscript out of bounds
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAHlebCTgy30WZ5WwsVbJtq8KAAAAQAAAA9JWb2hydDUCTPrUn4OqMDAEAAAAA@yahoo.com.br>


What??s happening with this following code:

require(sem)
Celpe.Mod.RAM <- matrix(c(
                       #  path                           parametro    Inicio
                          "Produ????o    ->  T1",          "gamma.11",  NA,
                          "Produ????o    ->  T2",          "gamma.12",  NA,
                          "Produ????o    ->  T3",          "gamma.13",  NA,
                          "Produ????o    ->  T4",          "gamma.14",  NA,
                          "Compreens??o ->  T1",          "gamma.21",  NA,
                          "Compreens??o ->  T2",          "gamma.22",  NA,
                          "Compreens??o ->  PI",          "gamma.23",  NA,
                          "Certificado ->  Produ????o",    "alpha.11",  NA,
                          "Certificado ->  Compreens??o", "alpha.12",  NA,
                          "Compreens??o <-> Produ????o",    "alpha.21",  NA
                          ),
                        ncol=3, byrow=TRUE)

Celpe.cov <- cov(Celpe.Dados.Fatorial[3:7])
Celpe.cfa.sem <- sem(ram=Celpe.Mod.RAM, S=Celpe.cov,
N=1443,refit=TRUE,debug=TRUE)

Here comes the Results:

> Celpe.cfa.sem <- sem(ram=Celpe.Mod.RAM, S=Celpe.cov,
N=1443,refit=TRUE,debug=TRUE)

 observed variables:
[1] "1:T1" "2:T2" "3:T3" "4:T4" "5:PI"


 latent variables:
[1] "6:Produ????o"    "7:Compreens??o" "8:Certificado"


 parameters:
 [1] "1:gamma.11"  "2:gamma.12"  "3:gamma.13"  "4:gamma.14"  "5:gamma.21"
"6:gamma.22"  "7:gamma.23"  "8:alpha.11"  "9:alpha.12" 
[10] "10:alpha.21"


 RAM:
      heads to from parameter start
 [1,]     1  1    6         1    NA
 [2,]     1  2    6         2    NA
 [3,]     1  3    6         3    NA
 [4,]     1  4    6         4    NA
 [5,]     1  1    7         5    NA
 [6,]     1  2    7         6    NA
 [7,]     1  5    7         7    NA
 [8,]     1  6    8         8    NA
 [9,]     1  7    8         9    NA
[10,]     2  6    7        10    NA
Error in startvalues(S, ram, debug = debug, tol = start.tol) : 
        subscript out of bounds
> Celpe.cov
          T1        T2        T3        T4        PI
T1 1.2459212 0.6072653 0.6410553 0.4030267 0.7001731
T2 0.6072653 0.9369251 0.5762526 0.3293337 0.6282211
T3 0.6410553 0.5762526 1.5346904 0.3888291 0.6064140
T4 0.4030267 0.3293337 0.3888291 0.5377340 0.3840199
PI 0.7001731 0.6282211 0.6064140 0.3840199 1.9750506
> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status   Patched        
major    1              
minor    9.0            
year     2004           
month    04             
day      28             
language R              
> 

[]s
Leonard Assis
Estat??stico /  CONFE 7439
UIN : 41-764-523 /  Skype : lmassis /  msn : lmassis at msn.com



From unung at enciety.com  Wed May 12 02:20:45 2004
From: unung at enciety.com (Unung Istopo Hartanto)
Date: Wed, 12 May 2004 07:20:45 +0700
Subject: AW: [R] Probleme with Kmeans...
In-Reply-To: <83536658864BC243BE3C06D7E936ABD50153A595@xchg1.statistik.local>
References: <83536658864BC243BE3C06D7E936ABD50153A595@xchg1.statistik.local>
Message-ID: <1084321244.2845.10.camel@IT05>

Ups... I understand now about your comment before that Kmeans has
problems to process one variable.

Thank you very much.
Unung


On Tue, 2004-05-11 at 21:40, TEMPL Matthias wrote:
> Sorry, to solve your question I had tried:
> 
> data(faithful)
> kmeans(faithful[c(1:20),1],10)
> Error: empty cluster: try a better set of initial centers
> 
> But when I run this a second time it will be ok.
> 
> 
> It seems, that kmeans has problems to initialize good starting points, because of the random choose of these starting initial points.
> With kmeans(data,k,centers=c(...) the problem can be solved.
> Generally, the starting points can be choose equidistant on a hyperplane of the data, which is also a simple way to get the intitial points 
> (www.fuzzyclustering.de , fc-package of H??ppner, manual). 
> 
> 
> Thank you for your comment,
> Matthias



From jfox at mcmaster.ca  Wed May 12 02:41:50 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 11 May 2004 20:41:50 -0400
Subject: [R] Sem error - subscript out of bounds
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAHlebCTgy30WZ5WwsVbJtq8KAAAAQAAAA9JWb2hydDUCTPrUn4OqMDAEAAAAA@yahoo.com.br>
Message-ID: <20040512004148.PFXI20511.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Leonard,

There are no error variances defined for the endogenous variables in the
model. Have you read the document that describes how sem() works (at
http://socserv.socsci.mcmaster.ca/jfox/Books/Companion/appendix-sems.pdf)?
If not, that might help you specify the model. It should also help to study
the examples in ?sem.

The soon-to-be-released next version of the sem package will print a more
informative error message for this kind of error.

I hope that this helps,
 John 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Leonard assis
> Sent: Tuesday, May 11, 2004 7:12 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Sem error - subscript out of bounds
> 
> 
> What??s happening with this following code:
> 
> require(sem)
> Celpe.Mod.RAM <- matrix(c(
>                        #  path                           
> parametro    Inicio
>                           "Produ????o    ->  T1",          
> "gamma.11",  NA,
>                           "Produ????o    ->  T2",          
> "gamma.12",  NA,
>                           "Produ????o    ->  T3",          
> "gamma.13",  NA,
>                           "Produ????o    ->  T4",          
> "gamma.14",  NA,
>                           "Compreens??o ->  T1",          
> "gamma.21",  NA,
>                           "Compreens??o ->  T2",          
> "gamma.22",  NA,
>                           "Compreens??o ->  PI",          
> "gamma.23",  NA,
>                           "Certificado ->  Produ????o",    
> "alpha.11",  NA,
>                           "Certificado ->  Compreens??o", 
> "alpha.12",  NA,
>                           "Compreens??o <-> Produ????o",    
> "alpha.21",  NA
>                           ),
>                         ncol=3, byrow=TRUE)
> 
> Celpe.cov <- cov(Celpe.Dados.Fatorial[3:7]) Celpe.cfa.sem <- 
> sem(ram=Celpe.Mod.RAM, S=Celpe.cov,
> N=1443,refit=TRUE,debug=TRUE)
> 
> Here comes the Results:
> 
> > Celpe.cfa.sem <- sem(ram=Celpe.Mod.RAM, S=Celpe.cov,
> N=1443,refit=TRUE,debug=TRUE)
> 
>  observed variables:
> [1] "1:T1" "2:T2" "3:T3" "4:T4" "5:PI"
> 
> 
>  latent variables:
> [1] "6:Produ????o"    "7:Compreens??o" "8:Certificado"
> 
> 
>  parameters:
>  [1] "1:gamma.11"  "2:gamma.12"  "3:gamma.13"  "4:gamma.14"  
> "5:gamma.21"
> "6:gamma.22"  "7:gamma.23"  "8:alpha.11"  "9:alpha.12" 
> [10] "10:alpha.21"
> 
> 
>  RAM:
>       heads to from parameter start
>  [1,]     1  1    6         1    NA
>  [2,]     1  2    6         2    NA
>  [3,]     1  3    6         3    NA
>  [4,]     1  4    6         4    NA
>  [5,]     1  1    7         5    NA
>  [6,]     1  2    7         6    NA
>  [7,]     1  5    7         7    NA
>  [8,]     1  6    8         8    NA
>  [9,]     1  7    8         9    NA
> [10,]     2  6    7        10    NA
> Error in startvalues(S, ram, debug = debug, tol = start.tol) : 
>         subscript out of bounds
> > Celpe.cov
>           T1        T2        T3        T4        PI
> T1 1.2459212 0.6072653 0.6410553 0.4030267 0.7001731
> T2 0.6072653 0.9369251 0.5762526 0.3293337 0.6282211
> T3 0.6410553 0.5762526 1.5346904 0.3888291 0.6064140
> T4 0.4030267 0.3293337 0.3888291 0.5377340 0.3840199 PI 
> 0.7001731 0.6282211 0.6064140 0.3840199 1.9750506
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status   Patched        
> major    1              
> minor    9.0            
> year     2004           
> month    04             
> day      28             
> language R              
> > 
> 
> []s
> Leonard Assis
> Estat??stico /  CONFE 7439
> UIN : 41-764-523 /  Skype : lmassis /  msn : lmassis at msn.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From kjetil at acelerate.com  Wed May 12 03:45:32 2004
From: kjetil at acelerate.com (kjetil@acelerate.com)
Date: Tue, 11 May 2004 21:45:32 -0400
Subject: [R] Problems with package foreign
Message-ID: <40A1497C.28378.20C879A@localhost>

In using read.spss I get:

Error in read.spss("Chu_cambios2.sav", to.data.frame = TRUE) : 
        Error reading system-file header.
In addition: Warning message: 
Chu_cambios2.sav: File layout code has unexpected value 50331648.  
Value should be 2, in big-endian or little-endian format. 
> 

This file was written with spss version 10.0.7, 
and this is on windows XP.

Kjetil Halvorsen



From ggrothendieck at myway.com  Wed May 12 05:44:15 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 12 May 2004 03:44:15 +0000 (UTC)
Subject: [R] lags and differences
References: <HXKBF5$008120B5828404D9349B43E99FF9D364@bol.com.br>
Message-ID: <loom.20040512T053828-798@post.gmane.org>


In this particular case, i.e. regressing diff(y) against 
x and x lagged one could write this:

   lm(diff(y)~., data=as.data.frame(embed(x,2)))

which works since the length of diff(y) happens
to equal the number of rows in embed(x,2).

fciclone <fciclone <at> bol.com.br> writes:

: 
: Dear all, could someone please clarify me if this 
: works, so as to implement lags and differences for 
: example in y and in a independent x1 of a  regression?
: 
: model<-lm((diff(y), -i)~x1+lag(x1,-1), data=anydata)
: 
: Thanks, a lot,
: Alexandre.



From ripley at stats.ox.ac.uk  Wed May 12 08:16:16 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 May 2004 07:16:16 +0100 (BST)
Subject: [R] How to use c routines in the exiting package?
In-Reply-To: <000201c4379d$89e38900$f63d9f88@math.ucalgary.ca>
Message-ID: <Pine.LNX.4.44.0405120711080.2857-100000@gannet.stats>

On Tue, 11 May 2004, Rui wrote:

> Hi all,
>  
> I want to know some details about the c routine "lasso" in the functions
> of "gl1ce()" .  However, I have following troubles. First, I can not
> find the routine in the local directories of this function (or package).

Then something is wrong with your search techniques.  You have obtained
the *sources* of the package from CRAN, haven't you?  Look in the
lasso2/src directory of the tarball lasso2_1.2-0.tar.gz.

> Second, if I found the routine, could I call it just like this way, say,
> fit <- .C("lasso", ....,PACKAGE = "lasso2") in my own functions. 

Yes.

> My system
> is Windows98 with R1.80.

R is at 1.9.1, and unlikely to reach 1.80 before 2.0.0

Your mail contains some strange characters.  Please use ASCII text in 
emails, not Windows extras (and not HTML).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed May 12 08:21:28 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 May 2004 07:21:28 +0100 (BST)
Subject: [R] recover should send messages to stderr, not stdout
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A54B32FB@phost015.EVAFUNDS.intermedia.net>
Message-ID: <Pine.LNX.4.44.0405120716240.2857-100000@gannet.stats>

recover() is a pure R function, so you can very easily edit it to meet
your requirements.  You could also submit a patched version for
consideration after testing.

Note that some of us consider recover() to be designed for 
interactive-only use, and use something like

    options(error=expression(if(interactive()) recover() else dump.calls()))


On Tue, 11 May 2004, Vadim Ogranovich wrote:

> recover() sends all its messages, which I consider to be error messages,
> to stdout. I think they more properly belong to stderr.
>  
> This is an important difference for those of us who use R in batch mode
> to generate ASCII files.

Only to the subset who believe that recover() is a useful error option in 
non-interactive use.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rkoenker at uiuc.edu  Fri May  7 00:03:33 2004
From: rkoenker at uiuc.edu (roger koenker)
Date: Thu, 6 May 2004 17:03:33 -0500
Subject: [R] sporadic errors with nlrq() / optim()
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAHlebCTgy30WZ5WwsVbJtq8KAAAAQAAAAzb/ta0xfm0WmMfig1n5ZtQEAAAAA@yahoo.com.br>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAHlebCTgy30WZ5WwsVbJtq8KAAAAQAAAAzb/ta0xfm0WmMfig1n5ZtQEAAAAA@yahoo.com.br>
Message-ID: <3770069A-9FA9-11D8-9352-000A95A7E3AA@uiuc.edu>

I've recently updated nlrq to get rid of these warnings.  Peter's diagnosis
of the optim problem seems entirely consistent with the evidence: my mac
running R-devel was Jim's source on the error free case.  And my solaris
machine (running 1.9.0 unpatched) does eventually have a problem with
optim:

140
141
142
Error in optim(par = 1, fn = model.step, method = "L-BFGS-B", lower = 
0,  :
         non-finite value supplied by optim
In addition: There were 50 or more warnings (use warnings() to see the 
first 50)
 > traceback()
3: optim(par = 1, fn = model.step, method = "L-BFGS-B", lower = 0,
        upper = 1, Step = Step, model = model, pars = Pars, control = 
optim.ctrl)
2: nlrq.calc(m, ctrl, trace)
1: nlrq(y ~ SSfpl(x, A, B, xmid, scal), data = test)

Roger

url:	www.econ.uiuc.edu/~roger        	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On May 6, 2004, at 4:50 PM, Leonard assis wrote:

>
> Only theese: :(
>
>
> 495
> 496
> 497
> 498
> 499
> There were 50 or more warnings (use warnings() to see the first 50)
>>
>> warnings()
> Warning messages:
> 1: multi-argument returns are deprecated in: return(coef, w)
> 2: multi-argument returns are deprecated in: return(coef, w)
> 3: multi-argument returns are deprecated in: return(coef, w)
> 4: multi-argument returns are deprecated in: return(coef, w)
> 5: multi-argument returns are deprecated in: return(coef, w)
> 6: multi-argument returns are deprecated in: return(coef, w)
> 7: multi-argument returns are deprecated in: return(coef, w)
> 8: multi-argument returns are deprecated in: return(coef, w)
> 9: multi-argument returns are deprecated in: return(coef, w)
> 10: multi-argument returns are deprecated in: return(coef, w)
> ...
> 50: multi-argument returns are deprecated in: return(coef, w)
> []s
> Leonard Assis
> Estat??stico /  CONFE 7439
> UIN : 41-764-523 /  Skype : lmassis /  msn : lmassis at msn.com
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Leonard assis
> Sent: Thursday, May 06, 2004 6:42 PM
> To: 'Peter Dalgaard'; 'Rogers, James A [PGRD Groton]'
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] sporadic errors with nlrq() / optim()
>
> In my computer, there's no error
>
> WIN XP
> PENTIUM4 1.67GHz
> 1GB RAM
> R 1.9.0 Patched
>
>
> []s
> Leonard Assis
> Estat??stico /  CONFE 7439
> UIN : 41-764-523 /  Skype : lmassis /  msn : lmassis at msn.com
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Peter Dalgaard
> Sent: Thursday, May 06, 2004 6:21 PM
> To: Rogers, James A [PGRD Groton]
> Cc: 'r-help at stat.math.ethz.ch'
> Subject: Re: [R] sporadic errors with nlrq() / optim()
>
> "Rogers, James A [PGRD Groton]" <James_A_Rogers at groton.pfizer.com> 
> writes:
>
>> Dear List,
>>
>> Apologies if this is a known problem ... I wasn't able to find it on
>> the bug list, but it is a problem that does not seem to occur with a
>> MAC build of R 2.0, so perhaps this problem has already been addressed
>> for
> the future.
>>
>> I am getting *sporadic* errors when refitting the same model to the
>> same data set, using nlrq() in the nlrq package. The algorithm is not
>> stochastic, so I would expect to get errors either every time, or 
>> never.
>>
>> ###
>>
>> library(stats) # or library(nls) if using R < 1.9.0
>> library(nlrq)
>>
>> test <- data.frame(x = c(7.60090245954208, 6.90775527898214,
>> 6.21460809842219, 5.52146091786225, 4.60517018598809,
>> 3.91202300542815,
>> 3.2188758248682 , 2.52572864430826, 1.83258146374831,
>> 7.60090245954208, 6.90775527898214, 6.21460809842219,
>> 5.52146091786225, 4.60517018598809, 3.91202300542815, 3.2188758248682
>> , 2.52572864430826, 1.83258146374831, 6.21460809842219, 
>> 6.21460809842219),
>>                    y = c( 11.0161506644269, 9.84267541313937,
>> 8.66146668057266, 7.48099216286952, 6.50578406012823,
>> 6.24027584517077, 5.63121178182137, 5.71702770140622,
>> 5.64190707093811, 10.8983676287705, 9.91857318995417,
>> 8.74608021735751, 7.58120982619635, 6.361302477573 , 5.91889385427315,
>> 5.63835466933375 , 5.80211837537706, 5.64897423816121,
>> 8.6195692580331 , 8.70367275835886)
>>                    )
>>
>> i <- 1
>> while(i < 500) {    # I usually hit an error within 50 iterations
>>   cat(i, "\n")
>>   nlrq(y ~ SSfpl(x, A, B, xmid, scal), data = test)
>>   i <- i + 1
>> }
>>
>> ###
>>
>> Errors occur with version 1.8.1 and 1.9.0 on both Windows (two
>> different
>> machines) and UNIX, but not on version 2.0 on a MAC (these are the
>> only R version - OS permutations I was able to get reports on easily).
>>
>> Anyone understand what is happening here?
>
> There's no "version 2.0", only "2.0.0 Under development (unstable)".
> If you look at the NEWS file for that version (or for 1.9.0-patched) 
> under
> 1.9.1 changes, you'll find
>
>    o   The L-BFGS-B option of optim() apparently needs part of its
>         workspace zeroed.  (PR#6720)
>
> which gave problems of the sort you experiences.
>
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From gb at stat.umu.se  Wed May 12 08:54:15 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 12 May 2004 08:54:15 +0200
Subject: [R] Explaining Survival difference between Stata and R
In-Reply-To: <Pine.A41.4.58.0405110707100.34626@homer37.u.washington.edu>
References: <40A01772.9020304@ku.edu>
	<Pine.A41.4.58.0405110707100.34626@homer37.u.washington.edu>
Message-ID: <20040512065415.GA20792@stat.umu.se>

On Tue, May 11, 2004 at 07:10:36AM -0700, Thomas Lumley wrote:
> On Mon, 10 May 2004, Paul Johnson wrote:
> 
> > Dear Everybody:
> >
> > I'm doing my usual "how does that work in R" thing with some Stata
> > projects.  I find a gross gap between the Stata and R in Cox PH models,
> > and I hope you can give me some pointers about what goes wrong.  I'm
> > getting signals from R/Survival that the model just can't be estimated,
> > but Stata spits out numbers just fine.
> >
> > I wonder if I should specify initial values for coxph?
> 
> It's worth a try. The other question is whether Stata has in fact
> converged -- if the range of rqe is not small then its coefficient may
> actually be infinite.
> 
> > I got a dataset from a student who uses Stata and try to replicate in R.
> > I will share data to you in case you want to see for yourself.  Let me
> > know if you want text or Stata data file.
> 
> I'd like to look at the data.  We should be able to get coxph to converge
> when there is a finite mle -- the log partial likelihood is concave.

Paul and Thomas,

'coxph' or the data (I got it from Paul) indeed has a problem:
------------------------------------------------------------
Call:
coxph(formula = Surv(yrs2, ratify) ~ haz.wst + pol.free, data = dat)


             coef exp(coef) se(coef)     z    p
haz.wst  8.53e-08         1 9.47e-08 0.901 0.37
pol.free       NA        NA 0.00e+00    NA   NA

Likelihood ratio test=0.76  on 1 df, p=0.385  n= 21 
Warning message: 
X matrix deemed to be singular; variable 2 in: 
coxph(Surv(yrs2, ratify) ~ haz.wst + pol.free, data = dat) 
---------------------------------------------------------------

Is it the data? Let's try 'coxreg' (eha):
---------------------------------------------------------------
Call:
coxreg(formula = Surv(yrs2, ratify) ~ haz.wst + pol.free, data = dat)

Covariate           Mean       Coef        RR       Wald p
haz.wst           2054901     0.000     1.000        0.372 
pol.free            2.090     0.009     1.009        0.958 

Events                    21 
Total time at risk            78 
Max. log. likelihood      -45.001 
LR test statistic         0.76 
Degrees of freedom        2 
Overall p-value           0.684583
----------------------------------------------------------------

This worked just fine (Paul, same results as in Stata?). But, we 
seem to have a scaling problem; lok at the means of the covariates!
Some rescaling gives:
----------------------------------------------------------------
Call:
coxph(formula = Surv(yrs2, ratify) ~ I(haz.wst * 1e-06) + pol.free, 
    data = dat)


                      coef exp(coef) se(coef)      z    p
I(haz.wst * 1e-06) 0.08479      1.09    0.095 0.8920 0.37
pol.free           0.00896      1.01    0.170 0.0526 0.96

Likelihood ratio test=0.76  on 2 df, p=0.685  n= 21 
----------------------------------------------------------------
and now 'coxph' gets the same results as 'coxreg'. I don't know about coxph
for sure, but I do know that coxreg centers all covariates before the NR
procedure starts. Maybe we also should rescale to unit variance? And of
course scale back the coefficients and se:s at the end? 

BTW, Paul's data is heavily tied. Could be an idea to use a discrete time
version of the PH model: you can do that with 'mlreg' (eha): 
--------------------------------------------------------------- 
Call:
mlreg(formula = Surv(yrs2, ratify) ~ I(haz.wst * 1e-06) + pol.free, 
    data = dat)

Covariate           Mean       Coef        RR     Wald p
I(haz.wst * 1e-06)  2.055     0.097     1.102      0.320 
pol.free            2.090     0.003     1.003      0.985 

Events                    21 
Total time at risk            78 
Max. log. likelihood      -36.324 
LR test statistic         0.93 
Degrees of freedom        2 
Overall p-value           0.627056
----------------------------------------------------------------
Doesn't make much of a difference, though. Efron's method is quite
robust. (You might check if there are any differences with 'breslow')

Best,

G??ran

[...]
-- 
 G??ran Brostr??m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume?? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume??, Sweden             e-mail: gb at stat.umu.se



From m.kerick at mucosa.de  Wed May 12 10:22:43 2004
From: m.kerick at mucosa.de (Martin Kerick)
Date: Wed, 12 May 2004 10:22:43 +0200
Subject: [R] how to sort the contents of a  list-object?
Message-ID: <000101c437fa$4d5bf3c0$7dbc5ec2@mucosalab.de>

Dear all,

I have a list-object RGList named RG containing two vectors (RG$R and RG$G)
and a data.frame(RG$genes) with 8 variables. Each of the variables of the
data.frame have the same length as the two vectors. I think the data in the
RGList is structured in such a way, that the first entry in the vector RG$R
belongs to the first entry in the data.frame variable e.g. RG$genes$Row.
Now my question:
Is it possible to sort the RGList object by the values of one variable of my
data.frame e.g. RG$genes$Row without loosing the ties between the different
parts of the list ?

Any help would be greatly appreciated,

Martin



From ripley at stats.ox.ac.uk  Wed May 12 10:39:42 2004
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 12 May 2004 09:39:42 +0100 (GMT Daylight Time)
Subject: [R] how to sort the contents of a  list-object?
In-Reply-To: <000101c437fa$4d5bf3c0$7dbc5ec2@mucosalab.de>
References: <000101c437fa$4d5bf3c0$7dbc5ec2@mucosalab.de>
Message-ID: <Pine.WNT.4.58.0405120935140.1648@auk>

On Wed, 12 May 2004, Martin Kerick wrote:

> I have a list-object RGList named RG containing two vectors (RG$R and RG$G)
> and a data.frame(RG$genes) with 8 variables. Each of the variables of the
> data.frame have the same length as the two vectors. I think the data in the
> RGList is structured in such a way, that the first entry in the vector RG$R
> belongs to the first entry in the data.frame variable e.g. RG$genes$Row.
> Now my question:

> Is it possible to sort the RGList object by the values of one variable of my
> data.frame e.g. RG$genes$Row without loosing the ties between the different
> parts of the list ?

Yes.  Did you also want to know how?  If so, see later.

But why?  It looks like R and G should be additional columns of the data
frame and if you had a better data organization you would *know* what
matched what and operations like this would be obvious.





















ord <- sort.list(RG$genes$Row)
RG <- lapply(RG, function(x) if(is.data.frame) x[ord,] else x[ord])

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From swantje.lobel at ebc.uu.se  Wed May 12 10:58:44 2004
From: swantje.lobel at ebc.uu.se (=?iso-8859-1?Q?Swantje_L=F6bel?=)
Date: Wed, 12 May 2004 10:58:44 +0200
Subject: [R] variation explained by the non-spatial and spatial component
	using variogram models fitted to residuals of a non-spatial
	model (GeoR)
Message-ID: <20040512085841.06604EC9@pernis.its.uu.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040512/8fb9c4a7/attachment.pl

From i.visser at uva.nl  Wed May 12 11:31:09 2004
From: i.visser at uva.nl (Ingmar Visser)
Date: Wed, 12 May 2004 11:31:09 +0200
Subject: [R] bus error macosx/off-topic
Message-ID: <BCC7BB7D.2676%i.visser@uva.nl>

Hi All,
I'm building a package using C/C++ and Fortran code which usually runs fine.
However I do get occasional bus errors around the time of exiting one of the
C functions. 

Where do I need to be looking to solve this problem?
Do bus errors stem from unmapped memory exceptions? How can I find out if
that is what is happening while running R?

Any hints greatly appreciated.

Best, ingmar visser



From wolski at molgen.mpg.de  Wed May 12 12:19:41 2004
From: wolski at molgen.mpg.de (witek)
Date: Wed, 12 May 2004 12:19:41 +0200
Subject: [R] Problem with plot.
Message-ID: <200405121219410263.24A35A42@mail.math.fu-berlin.de>

Hi!
After loading some functions in R1.9.0 and some computations I am getting the following errors (see below with plot).
I have now idea how to figure out whats wrong. Can anyone give me a hint where to start to debug?

Eryk

plot(1,1) fine. 

plot(hist(1:10,plot=F))
Error in xy.coords(x, y, xlabel, ylabel, log) : 
	x and y lengths differ

plot(hclust(res))
Error in plot.window(xlim, ylim, log, asp, ...) : 
	need finite xlim values
In addition: Warning messages: 
1: no finite arguments to min; returning Inf 
2: no finite arguments to max; returning -Inf 
3: no finite arguments to min; returning Inf 
4: no finite arguments to max; returning -Inf



From ramzi.temanni at laposte.net  Wed May 12 12:37:21 2004
From: ramzi.temanni at laposte.net (Ramzi TEMANNI)
Date: Wed, 12 May 2004 12:37:21 +0200
Subject: [R] solving 2 variable quadratic program
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA/SScWgRDKkWYRSKuOxiKY8KAAAAQAAAAOOfEc2+wZk6TclACIrIyZwEAAAAA@laposte.net>

Dear All,

 

I?m trying to solve a two variable Quadratic Program, is there a way to
solve the following problem with quadpro in R  :

 

Min(K) Max(alfa){ C>= alfa >=0;t(alfa)%*%y=0}    
t(e)%*% alfa - 0.5t(alfa)%*% D %*%alfa

subject to 
   trace(K) = c
   K =  \sum_{i=1}^m  mu_i K_i
   K >= 0
   mu >= 0 

where :
   y,alfa: vector  
   C,c : constant
   e matrix: e(i,i)=1 e(i,j)=0 i<>j
   K matrix, 

 
Thanks in advance,

Regards,
Ramzi

 



TEMANNI Ramzi
DEA Student

Lim&Bio
http://www.limbio-paris13.org
UFR de Sant??, M??decine et Biologie Humaine (SMBH)  L??onard de Vinci
74, rue Marcel Cachin
93017 Bobigny Cedex
France.
 
T??l : 01.48.38.73.07
T??l : 06.21.43.27.59
temanni.ramzi at free.fr 
http://temanni.ramzi.free.fr



From ramzi.temanni at laposte.net  Wed May 12 12:37:21 2004
From: ramzi.temanni at laposte.net (Ramzi TEMANNI)
Date: Wed, 12 May 2004 12:37:21 +0200
Subject: [R] solving 2 variable quadratic program
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA/SScWgRDKkWYRSKuOxiKY8KAAAAQAAAAOOfEc2+wZk6TclACIrIyZwEAAAAA@laposte.net>

Dear All,

 

I?m trying to solve a two variable Quadratic Program, is there a way to
solve the following problem with quadpro in R  :

 

Min(K) Max(alfa){ C>= alfa >=0;t(alfa)%*%y=0}    
t(e)%*% alfa - 0.5t(alfa)%*% D %*%alfa

subject to 
   trace(K) = c
   K =  \sum_{i=1}^m  mu_i K_i
   K >= 0
   mu >= 0 

where :
   y,alfa: vector  
   C,c : constant
   e matrix: e(i,i)=1 e(i,j)=0 i<>j
   K matrix, 

 
Thanks in advance,

Regards,
Ramzi

 



TEMANNI Ramzi
DEA Student

Lim&Bio
http://www.limbio-paris13.org
UFR de Sant??, M??decine et Biologie Humaine (SMBH)  L??onard de Vinci
74, rue Marcel Cachin
93017 Bobigny Cedex
France.
 
T??l : 01.48.38.73.07
T??l : 06.21.43.27.59
temanni.ramzi at free.fr 
http://temanni.ramzi.free.fr



From ligges at statistik.uni-dortmund.de  Wed May 12 13:11:06 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 12 May 2004 13:11:06 +0200
Subject: [R] Problem with plot.
In-Reply-To: <200405121219410263.24A35A42@mail.math.fu-berlin.de>
References: <200405121219410263.24A35A42@mail.math.fu-berlin.de>
Message-ID: <40A2064A.5000706@statistik.uni-dortmund.de>

witek wrote:

> Hi!
> After loading some functions in R1.9.0 and some computations I am getting the following errors (see below with plot).
> I have now idea how to figure out whats wrong. Can anyone give me a hint where to start to debug?
> 
> Eryk
> 
> plot(1,1) fine. 
> 
> plot(hist(1:10,plot=F))
> Error in xy.coords(x, y, xlabel, ylabel, log) : 
> 	x and y lengths differ

Works for me, hence probably a problem with your installation of R (BTW: 
Your OS is???). Or do you have strange versions of "plot()", "hist()" or 
"F" in your workspace?

Uwe Ligges


> plot(hclust(res))
> Error in plot.window(xlim, ylim, log, asp, ...) : 
> 	need finite xlim values
> In addition: Warning messages: 
> 1: no finite arguments to min; returning Inf 
> 2: no finite arguments to max; returning -Inf 
> 3: no finite arguments to min; returning Inf 
> 4: no finite arguments to max; returning -Inf
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From tpapp at axelero.hu  Wed May 12 13:26:51 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Wed, 12 May 2004 13:26:51 +0200
Subject: [R] Problem with plot.
In-Reply-To: <200405121219410263.24A35A42@mail.math.fu-berlin.de>
References: <200405121219410263.24A35A42@mail.math.fu-berlin.de>
Message-ID: <20040512112651.GA957@localhost>

On Wed, May 12, 2004 at 12:19:41PM +0200, witek wrote:

> Hi!
> After loading some functions in R1.9.0 and some computations I am getting the following errors (see below with plot).
> I have now idea how to figure out whats wrong. Can anyone give me a hint where to start to debug?
> 
> Eryk
> 
> plot(1,1) fine. 
> 
> plot(hist(1:10,plot=F))
> Error in xy.coords(x, y, xlabel, ylabel, log) : 
> 	x and y lengths differ

plot(hist(1:10,plot=F))

works fine on my system (as expected).  plot calls the appropriate
method (plot.histogram) in this case to make a plot.  You mentioned
"loading some functions", what functions where these?

Do you get the same error when you load nothing before these commands?
If so, then try to isolate the cause of the problem.  See if hist()
and plot.histogram() are redefined anywhere.

Best,

Tamas

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From p.dalgaard at biostat.ku.dk  Wed May 12 13:48:55 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 May 2004 13:48:55 +0200
Subject: [R] Explaining Survival difference between Stata and R
In-Reply-To: <20040512065415.GA20792@stat.umu.se>
References: <40A01772.9020304@ku.edu>
	<Pine.A41.4.58.0405110707100.34626@homer37.u.washington.edu>
	<20040512065415.GA20792@stat.umu.se>
Message-ID: <x2k6zhsw60.fsf@biostat.ku.dk>

G??ran Brostr??m <gb at stat.umu.se> writes:

>                       coef exp(coef) se(coef)      z    p
> I(haz.wst * 1e-06) 0.08479      1.09    0.095 0.8920 0.37
> pol.free           0.00896      1.01    0.170 0.0526 0.96
> 
> Likelihood ratio test=0.76  on 2 df, p=0.685  n= 21 
> ----------------------------------------------------------------
> and now 'coxph' gets the same results as 'coxreg'. I don't know about coxph
> for sure, but I do know that coxreg centers all covariates before the NR
> procedure starts. Maybe we also should rescale to unit variance? And of
> course scale back the coefficients and se:s at the end? 

It's not the only place one bumps into this effect. It stems from the
matrix routines' heuristics for detecting singularities, and one of
them is that a column of very small numbers (relative to the other
columns) is indistinguishable from zero. 

It is not obvious that this is really done optimally for a statistical
context. E.g., it would definitely be possible to have a Choleski
factorization that looks for relative loss of precision instead of
looking at the numeric value of the computed diagonal elements.
However, the routines in standard libraries were typically developed
for situations where the scale is similar for all coordinates.

On the other hand, choosing always to rescale to unit variance,
prevents catching those cases where a column really is zero up to
roundoff in the computations. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From danbebber at forestecology.co.uk  Wed May 12 14:09:03 2004
From: danbebber at forestecology.co.uk (Daniel Bebber)
Date: Wed, 12 May 2004 13:09:03 +0100
Subject: [R] Extracting data from matrices
Message-ID: <000301c43819$ea79b880$da41fea9@dops7026>

Dear R list

I have an m * n matrix P and a vector V of length n containing indices for
rows in P.
For each of the m columns I want to extract the value in the row specified
by V, and put these values into a new vector W of length n.
At present I am doing this with a for.... loop, but I imagine there is a faster
way that doesn?t involve loops.
If anyone knows the way I would be most grateful.

Below is the code I am using at present-

for (i in 1:n){
W[i]<-P[V[i],i]}

Many thanks,
Dan Bebber
____________________________
Department of Plant Sciences
University of Oxford
South Parks Road
Oxford OX1 3RB
UK
Tel. 01865 275060
Fax. 01865 275074



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed May 12 14:32:30 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 12 May 2004 14:32:30 +0200
Subject: [R] Extracting data from matrices
References: <000301c43819$ea79b880$da41fea9@dops7026>
Message-ID: <000a01c4381d$326e4130$ad133a86@www.domain>

Dear Dan,

you could just use the following:

V <- cbind(V, 1:n)
W <- P[V]

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Daniel Bebber" <danbebber at forestecology.co.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, May 12, 2004 2:09 PM
Subject: [R] Extracting data from matrices


> Dear R list
>
> I have an m * n matrix P and a vector V of length n containing
indices for
> rows in P.
> For each of the m columns I want to extract the value in the row
specified
> by V, and put these values into a new vector W of length n.
> At present I am doing this with a for. loop, but I imagine there is
a faster
> way that doesn't involve loops.
> If anyone knows the way I would be most grateful.
>
> Below is the code I am using at present-
>
> for (i in 1:n){
> W[i]<-P[V[i],i]}
>
> Many thanks,
> Dan Bebber
> ____________________________
> Department of Plant Sciences
> University of Oxford
> South Parks Road
> Oxford OX1 3RB
> UK
> Tel. 01865 275060
> Fax. 01865 275074
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From H.Andersson at nioo.knaw.nl  Wed May 12 14:36:09 2004
From: H.Andersson at nioo.knaw.nl (Andersson, Henrik)
Date: Wed, 12 May 2004 14:36:09 +0200
Subject: [R] Greek letters and subscripts in axis labels or titles
Message-ID: <65F6E1EC64DCA6489800C09A2007FC6E1817A5@cememail1.nioo.int>

A very brief question.

I have managed to put greek letters in my axis labels using
expression().

Question is, is there an easier (shorter) way than typing 

plot(runif(10),ylab=expression(NH[4]~(mu~M)),xlab="Time (h)")

to get the subscripts and micro sign.

Like NH$_4$ $\mu M$ would be nice :)
-------------------------------------------------------------
Henrik Andersson
Netherlands Institute of Ecology -
Centre for Estuarine and Marine Ecology
P.O. Box 140
4400 AC Yerseke
Phone: +31 113 577473
h.andersson at nioo.knaw.nl
http://www.nioo.knaw.nl/ppages/handersson



From ligges at statistik.uni-dortmund.de  Wed May 12 14:39:24 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 12 May 2004 14:39:24 +0200
Subject: [R] Extracting data from matrices
In-Reply-To: <000301c43819$ea79b880$da41fea9@dops7026>
References: <000301c43819$ea79b880$da41fea9@dops7026>
Message-ID: <40A21AFC.3080704@statistik.uni-dortmund.de>

Daniel Bebber wrote:

> Dear R list
> 
> I have an m * n matrix P and a vector V of length n containing indices for
> rows in P.
> For each of the m columns I want to extract the value in the row specified
> by V, and put these values into a new vector W of length n.
> At present I am doing this with a for.... loop, but I imagine there is a faster
> way that doesn?t involve loops.
> If anyone knows the way I would be most grateful.
> 
> Below is the code I am using at present-
> 
> for (i in 1:n){
> W[i]<-P[V[i],i]}

So, nrow(P)=n and ncol(P)=m ? What happens if you have less columns than 
rows to be selected? Anyway:

W <- P[V + nrow(P) * (seq(along = V) - 1)]

Uwe Ligges



> Many thanks,
> Dan Bebber
> ____________________________
> Department of Plant Sciences
> University of Oxford
> South Parks Road
> Oxford OX1 3RB
> UK
> Tel. 01865 275060
> Fax. 01865 275074
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed May 12 14:43:42 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 12 May 2004 14:43:42 +0200
Subject: [R] Greek letters and subscripts in axis labels or titles
In-Reply-To: <65F6E1EC64DCA6489800C09A2007FC6E1817A5@cememail1.nioo.int>
References: <65F6E1EC64DCA6489800C09A2007FC6E1817A5@cememail1.nioo.int>
Message-ID: <40A21BFE.4070401@statistik.uni-dortmund.de>

Andersson, Henrik wrote:

> A very brief question.
> 
> I have managed to put greek letters in my axis labels using
> expression().
> 
> Question is, is there an easier (shorter) way than typing 
> 
> plot(runif(10),ylab=expression(NH[4]~(mu~M)),xlab="Time (h)")
> 
> to get the subscripts and micro sign.
> 
> Like NH$_4$ $\mu M$ would be nice :)

No, and your R version already *is* shorter:

nchar("NH$_4$ $\mu M$")
[1] 13
nchar("NH[4]~(mu~M)")
[1] 12

Uwe Ligges



> -------------------------------------------------------------
> Henrik Andersson
> Netherlands Institute of Ecology -
> Centre for Estuarine and Marine Ecology
> P.O. Box 140
> 4400 AC Yerseke
> Phone: +31 113 577473
> h.andersson at nioo.knaw.nl
> http://www.nioo.knaw.nl/ppages/handersson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Maarten.van.der.Hoeven at knmi.nl  Wed May 12 14:42:36 2004
From: Maarten.van.der.Hoeven at knmi.nl (Hoeven, Maarten van der)
Date: Wed, 12 May 2004 14:42:36 +0200
Subject: [R] sqlSave with underscores in table fieldname
Message-ID: <1F8990C21AC73945BE6AAC5AD6D4CAE934CC8B@BCSXAC.knmi.nl>

Hi,

resending this question; guess someone missed it (?)

Thanks,
Maarten

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Hoeven, Maarten
> van der
> Sent: Monday, May 10, 2004 12:34 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] sqlSave with underscores in table fieldname
> 
> 
> Hi group,
> 
> I try to write a frame to a table (RODBC). I use
> 	colnames(temp6) <- 
> c("ind_id","ser_id","period_id","year","calc","mean")
> 	sqlSave(channel, temp6, tablename = 
> "series_indices_test",append= TRUE, rownames=FALSE, verbose = 
> FALSE, test = FALSE, nastring = -999999, fast = FALSE)
> 
> This is giving me an error:
> 	Error in sqlSave(channel, temp6, tablename = 
> "series_indices_test", append = TRUE,  : 
>         	unable to append to table %sseries_indices_test
> 
> My table definition is:
> ind_id smallint(3) 
> ser_id smallint(4)
> period_id tinyint(2)
> year smallint(4)
> calc mediumint(6)
> mean mediumint(6)
> 
> This error is related to the underscores I use in the table. 
> Because, when I change the table definition to (removing underscores):
> 
> indid smallint(3) 
> serid smallint(4)
> periodid tinyint(2)
> year smallint(4)
> calc mediumint(6)
> mean mediumint(6)
> 
> and execute
> 	colnames(temp6) <- 
> c("indid","serid","periodid","year","calc","mean")
> 	sqlSave(channel, temp6, tablename = 
> "series_indices_test",append= TRUE, rownames=FALSE, verbose = 
> FALSE, test = FALSE, nastring = -999999, fast = FALSE)
> 
> 
> it goes well.
> 
> Not using the underscores is not really prefered, as this 
> table with this underscores in the definition is used on a 
> lot of places elsewhere. But if removing the underscores is 
> the only solution, let me know as well.
> 
> 
> Any clue?
> 
> Using R 1.9.0, RODBC-package 1.4.0 (underlying database MySQL 
> 4.0.16-standard)
> 
> Thanks,
> Maarten
> 
> 
> +-------------------------------
> | Maarten van der Hoeven
> | KNMI, De Bilt
> | +31-30-2206 402
> | maarten.van.der.hoeven at knmi.nl
> +-------------------------------
> -------------------------------------------------------------- 
> 
> Zie ook/see also: http://www.knmi.nl/maildisclaimer.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
-------------------------------------------------------------- 

Zie ook/see also: http://www.knmi.nl/maildisclaimer.html



From ripley at stats.ox.ac.uk  Wed May 12 14:52:31 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 May 2004 13:52:31 +0100 (BST)
Subject: [R] bus error macosx/off-topic
In-Reply-To: <BCC7BB7D.2676%i.visser@uva.nl>
Message-ID: <Pine.LNX.4.44.0405121350080.16719-100000@gannet.stats>

These normally occur (at that point) from having written off one end of an
array. (If you are using .C/.Fortran, they try to copy back the
arguments.) Compiling with bounds checking turned on can help, at least
with Fortran.

On Wed, 12 May 2004, Ingmar Visser wrote:

> I'm building a package using C/C++ and Fortran code which usually runs fine.
> However I do get occasional bus errors around the time of exiting one of the
> C functions. 
> 
> Where do I need to be looking to solve this problem?
> Do bus errors stem from unmapped memory exceptions? How can I find out if
> that is what is happening while running R?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Maarten.van.der.Hoeven at knmi.nl  Wed May 12 15:04:23 2004
From: Maarten.van.der.Hoeven at knmi.nl (Hoeven, Maarten van der)
Date: Wed, 12 May 2004 15:04:23 +0200
Subject: [R] sqlSave with underscores in table fieldname
Message-ID: <1F8990C21AC73945BE6AAC5AD6D4CAE934CC8D@BCSXAC.knmi.nl>

Don't understand... What patch do you expect from me? And, I thought my analysis is quite reproducable and thorough. It is im my situation, though.

I'm not patching something, or writing/issueing R-code. I'm 'just' an R-user with a problem/question. 

In short: using underscores in SQL-tablefields  doesnt work, not using underscores in SQL-tablefields does work. See below. 

Question: is my observation correct, that RODBC cannot handle underscores in Mysql-tablefield? If not correct, what is the solution I need to apply?


Thanks,
Maarten

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Wednesday, May 12, 2004 2:50 PM
> To: Hoeven, Maarten van der
> Subject: RE: [R] sqlSave with underscores in table fieldname
> 
> 
> No, we saw it.
> 
> What I missed was the analysis and patch I was expecting from you.
> 
> On Wed, 12 May 2004, Hoeven, Maarten van der wrote:
> 
> > Hi,
> > 
> > resending this question; guess someone missed it (?)
> > 
> > Thanks,
> > Maarten
> > 
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of 
> Hoeven, Maarten
> > > van der
> > > Sent: Monday, May 10, 2004 12:34 PM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] sqlSave with underscores in table fieldname
> > > 
> > > 
> > > Hi group,
> > > 
> > > I try to write a frame to a table (RODBC). I use
> > > 	colnames(temp6) <- 
> > > c("ind_id","ser_id","period_id","year","calc","mean")
> > > 	sqlSave(channel, temp6, tablename = 
> > > "series_indices_test",append= TRUE, rownames=FALSE, verbose = 
> > > FALSE, test = FALSE, nastring = -999999, fast = FALSE)
> > > 
> > > This is giving me an error:
> > > 	Error in sqlSave(channel, temp6, tablename = 
> > > "series_indices_test", append = TRUE,  : 
> > >         	unable to append to table %sseries_indices_test
> > > 
> > > My table definition is:
> > > ind_id smallint(3) 
> > > ser_id smallint(4)
> > > period_id tinyint(2)
> > > year smallint(4)
> > > calc mediumint(6)
> > > mean mediumint(6)
> > > 
> > > This error is related to the underscores I use in the table. 
> > > Because, when I change the table definition to (removing 
> underscores):
> > > 
> > > indid smallint(3) 
> > > serid smallint(4)
> > > periodid tinyint(2)
> > > year smallint(4)
> > > calc mediumint(6)
> > > mean mediumint(6)
> > > 
> > > and execute
> > > 	colnames(temp6) <- 
> > > c("indid","serid","periodid","year","calc","mean")
> > > 	sqlSave(channel, temp6, tablename = 
> > > "series_indices_test",append= TRUE, rownames=FALSE, verbose = 
> > > FALSE, test = FALSE, nastring = -999999, fast = FALSE)
> > > 
> > > 
> > > it goes well.
> > > 
> > > Not using the underscores is not really prefered, as this 
> > > table with this underscores in the definition is used on a 
> > > lot of places elsewhere. But if removing the underscores is 
> > > the only solution, let me know as well.
> > > 
> > > 
> > > Any clue?
> > > 
> > > Using R 1.9.0, RODBC-package 1.4.0 (underlying database MySQL 
> > > 4.0.16-standard)
> > > 
> > > Thanks,
> > > Maarten
> > > 
> > > 
> > > +-------------------------------
> > > | Maarten van der Hoeven
> > > | KNMI, De Bilt
> > > | +31-30-2206 402
> > > | maarten.van.der.hoeven at knmi.nl
> > > +-------------------------------
> > > -------------------------------------------------------------- 
> > > 
> > > Zie ook/see also: http://www.knmi.nl/maildisclaimer.html
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > >
> > -------------------------------------------------------------- 
> > 
> > Zie ook/see also: http://www.knmi.nl/maildisclaimer.html
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
>
-------------------------------------------------------------- 

Zie ook/see also: http://www.knmi.nl/maildisclaimer.html



From migreja at med.up.pt  Wed May 12 15:12:52 2004
From: migreja at med.up.pt (Margarida =?iso-8859-1?Q?J=FAlia?= Rodrigues Igreja)
Date: Wed, 12 May 2004 14:12:52 +0100
Subject: [R] mannwitney
Message-ID: <6.0.3.0.1.20040512141118.01b00d98@mail.med.up.pt>

Hi,

I would like to do a MannWitney test.
Can anyone help me with the propper command?

Thanks,
Margarida



From Maarten.van.der.Hoeven at knmi.nl  Wed May 12 15:09:36 2004
From: Maarten.van.der.Hoeven at knmi.nl (Hoeven, Maarten van der)
Date: Wed, 12 May 2004 15:09:36 +0200
Subject: [R] sqlSave with underscores in table fieldname
Message-ID: <1F8990C21AC73945BE6AAC5AD6D4CAE934CC8F@BCSXAC.knmi.nl>

my apologies; this messages shouldnt have been send to the list. I did reply to Brian directly.

Sorry for your time.

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Hoeven, Maarten
> van der
> Sent: Wednesday, May 12, 2004 3:04 PM
> To: r-help at stat.math.ethz.ch
> Subject: RE: [R] sqlSave with underscores in table fieldname
> 
> 
> Don't understand... What patch do you expect from me? And, I 
> thought my analysis is quite reproducable and thorough. It is 
> im my situation, though.
> 
> I'm not patching something, or writing/issueing R-code. I'm 
> 'just' an R-user with a problem/question. 
> 
> In short: using underscores in SQL-tablefields  doesnt work, 
> not using underscores in SQL-tablefields does work. See below. 
> 
> Question: is my observation correct, that RODBC cannot handle 
> underscores in Mysql-tablefield? If not correct, what is the 
> solution I need to apply?
> 
> 
> Thanks,
> Maarten
> 
> > -----Original Message-----
> > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > Sent: Wednesday, May 12, 2004 2:50 PM
> > To: Hoeven, Maarten van der
> > Subject: RE: [R] sqlSave with underscores in table fieldname
> > 
> > 
> > No, we saw it.
> > 
> > What I missed was the analysis and patch I was expecting from you.
> > 
> > On Wed, 12 May 2004, Hoeven, Maarten van der wrote:
> > 
> > > Hi,
> > > 
> > > resending this question; guess someone missed it (?)
> > > 
> > > Thanks,
> > > Maarten
> > > 
> > > > -----Original Message-----
> > > > From: r-help-bounces at stat.math.ethz.ch
> > > > [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of 
> > Hoeven, Maarten
> > > > van der
> > > > Sent: Monday, May 10, 2004 12:34 PM
> > > > To: r-help at stat.math.ethz.ch
> > > > Subject: [R] sqlSave with underscores in table fieldname
> > > > 
> > > > 
> > > > Hi group,
> > > > 
> > > > I try to write a frame to a table (RODBC). I use
> > > > 	colnames(temp6) <- 
> > > > c("ind_id","ser_id","period_id","year","calc","mean")
> > > > 	sqlSave(channel, temp6, tablename = 
> > > > "series_indices_test",append= TRUE, rownames=FALSE, verbose = 
> > > > FALSE, test = FALSE, nastring = -999999, fast = FALSE)
> > > > 
> > > > This is giving me an error:
> > > > 	Error in sqlSave(channel, temp6, tablename = 
> > > > "series_indices_test", append = TRUE,  : 
> > > >         	unable to append to table %sseries_indices_test
> > > > 
> > > > My table definition is:
> > > > ind_id smallint(3) 
> > > > ser_id smallint(4)
> > > > period_id tinyint(2)
> > > > year smallint(4)
> > > > calc mediumint(6)
> > > > mean mediumint(6)
> > > > 
> > > > This error is related to the underscores I use in the table. 
> > > > Because, when I change the table definition to (removing 
> > underscores):
> > > > 
> > > > indid smallint(3) 
> > > > serid smallint(4)
> > > > periodid tinyint(2)
> > > > year smallint(4)
> > > > calc mediumint(6)
> > > > mean mediumint(6)
> > > > 
> > > > and execute
> > > > 	colnames(temp6) <- 
> > > > c("indid","serid","periodid","year","calc","mean")
> > > > 	sqlSave(channel, temp6, tablename = 
> > > > "series_indices_test",append= TRUE, rownames=FALSE, verbose = 
> > > > FALSE, test = FALSE, nastring = -999999, fast = FALSE)
> > > > 
> > > > 
> > > > it goes well.
> > > > 
> > > > Not using the underscores is not really prefered, as this 
> > > > table with this underscores in the definition is used on a 
> > > > lot of places elsewhere. But if removing the underscores is 
> > > > the only solution, let me know as well.
> > > > 
> > > > 
> > > > Any clue?
> > > > 
> > > > Using R 1.9.0, RODBC-package 1.4.0 (underlying database MySQL 
> > > > 4.0.16-standard)
> > > > 
> > > > Thanks,
> > > > Maarten
> > > > 
> > > > 
> > > > +-------------------------------
> > > > | Maarten van der Hoeven
> > > > | KNMI, De Bilt
> > > > | +31-30-2206 402
> > > > | maarten.van.der.hoeven at knmi.nl
> > > > +-------------------------------
> > > > -------------------------------------------------------------- 
> > > > 
> > > > Zie ook/see also: http://www.knmi.nl/maildisclaimer.html
> > > > 
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide! 
> > > > http://www.R-project.org/posting-guide.html
> > > >
> > > -------------------------------------------------------------- 
> > > 
> > > Zie ook/see also: http://www.knmi.nl/maildisclaimer.html
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > > 
> > > 
> > 
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > 
> >
> -------------------------------------------------------------- 
> 
> Zie ook/see also: http://www.knmi.nl/maildisclaimer.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
-------------------------------------------------------------- 

Zie ook/see also: http://www.knmi.nl/maildisclaimer.html



From daniel.hoppe at univie.ac.at  Wed May 12 15:15:48 2004
From: daniel.hoppe at univie.ac.at (Daniel Hoppe)
Date: Wed, 12 May 2004 15:15:48 +0200
Subject: AW: [R] mannwitney
In-Reply-To: <6.0.3.0.1.20040512141118.01b00d98@mail.med.up.pt>
Message-ID: <000c01c43823$3f1db9a0$82b98283@DH>

Hi,

did you look at wilcox.test?

Daniel

-----Urspr??ngliche Nachricht-----
Von: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] Im Auftrag von Margarida J??lia
Rodrigues Igreja
Gesendet: Mittwoch, 12. Mai 2004 15:13
An: r-help at stat.math.ethz.ch
Betreff: [R] mannwitney


Hi,

I would like to do a MannWitney test.
Can anyone help me with the propper command?

Thanks,
Margarida

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ccleland at optonline.net  Wed May 12 15:19:42 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 12 May 2004 09:19:42 -0400
Subject: [R] mannwitney
In-Reply-To: <6.0.3.0.1.20040512141118.01b00d98@mail.med.up.pt>
References: <6.0.3.0.1.20040512141118.01b00d98@mail.med.up.pt>
Message-ID: <40A2246E.9010809@optonline.net>

   See ?wilcox.test.  In particular, see the details section.

Margarida J??lia Rodrigues Igreja wrote:
> I would like to do a MannWitney test.
> Can anyone help me with the propper command?

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From tmchoi at ris.chonnam.ac.kr  Wed May 12 15:35:10 2004
From: tmchoi at ris.chonnam.ac.kr (Taemyong Choi)
Date: Wed, 12 May 2004 22:35:10 +0900
Subject: [R] How to know the row number of raw matrix after resampling?
Message-ID: <200405121334.i4CDYfVt007466@ris.chonnam.ac.kr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040512/74cc9888/attachment.pl

From nood at ext.sir.no  Wed May 12 15:59:13 2004
From: nood at ext.sir.no (=?ISO-8859-1?Q?Oddmund_Nordg=E5rd?=)
Date: Wed, 12 May 2004 15:59:13 +0200 (CEST)
Subject: [R] Power of paired proportions test
Message-ID: <Pine.LNX.4.56.0405121559000.25045@localhost>



Is there a function in R for the computation of test power (and sample
size) when comparing two proportions from dependent samples.
Can power.prot.test be used or does it require independent samples?

Oddmund Nordg??rd

******************************************

  Oddmund Nordg??rd

  Department of Haematology and Oncology
  Rogaland Central Hospital
  P.O. Box 8100
  4068 STAVANGER
  Phone: 51 51 89 34
  Email: nood at ext.sir.no

*****************************************
Registered linux user #44149



From joans at breastcenter.tmc.edu  Wed May 12 15:59:40 2004
From: joans at breastcenter.tmc.edu (Joan Snodgrass)
Date: Wed, 12 May 2004 08:59:40 -0500
Subject: [R] RE: ROracle package error - Solution
Message-ID: <001101c43829$5e9f76a0$4c38f980@ad.bcm.edu>

Thank you to David James for the solution to this one!

David James wrote:
> The workaround in the README.Oracle9 files is intended for the symbol
> sqlda (I think), but the sqlctx symbol apparently is defined in
> -lclntsh.  
> So, could you try the following?

R CMD INSTALL --configure-args='--enable-oracle32
--enable-extralibs="-lsqlplus -lclntsh"' ROracle_0.5-4.tar.gz

Regards, 
Joan

-----Original Message-----
From: Joan Snodgrass [mailto:joans at breastcenter.tmc.edu] 
Sent: Tuesday, May 11, 2004 10:54 AM
To: 'r-help at stat.math.ethz.ch'
Subject: ROracle package error

I am running R 1.8.1 on a Solaris 8 64-bit machine and using Oracle
9.2.0.4. I noticed that the readme for ROracle lists a problem and
suggests the following to work around it:
R CMD INSTALL --configure-args='--enable-extralibs' ROracle_0.5-4.tar.gz

I ran the following to install since we have 32-bit R and 64-bit Oracle:
R CMD INSTALL --configure-args='--enable-oracle32--enable-extralibs'
ROracle_0.5-4.tar.gz

I receive no errors during the install, but when I try to load the
package I receive the following error (which is very similar to the one
listed in the readme):
> library(ROracle)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
unable to load shared library "/usr/local/lib/R/library/ROracle/libs/ROr
acle.so": ld.so.1: /usr/local/lib/R/bin/R.bin: fatal: relocation error:
file /usr/local/lib/R/library/ROracle/libs/ROracle.so: symbol sqlcxt:
referenced symbol not found
Error in library(ROracle) : .First.lib failed

Has anyone else experienced this?  Any help would be greatly
appreciated!

Regards, 
Joan 

Joan Snodgrass <joans at breastcenter.tmc.edu>



From Giovanna.Jonalasinio at uniroma1.it  Wed May 12 16:01:53 2004
From: Giovanna.Jonalasinio at uniroma1.it (Giovanna.Jonalasinio@uniroma1.it)
Date: Wed, 12 May 2004 16:01:53 +0200
Subject: [R] Giovanna Jonalasinio
 =?iso-8859-1?q?=E8_fuori_ufficio-_away_from_?=
 =?iso-8859-1?q?the_office?=
Message-ID: <OF6BD6BBF9.BEB47679-ONC1256E92.004D13F6-C1256E92.004D13F7@Uniroma1.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040512/20eb3cec/attachment.pl

From salfner at informatik.hu-berlin.de  Wed May 12 16:22:13 2004
From: salfner at informatik.hu-berlin.de (Felix Salfner)
Date: Wed, 12 May 2004 16:22:13 +0200
Subject: [R] Problem installing SparseM on Debian stable
Message-ID: <40A23315.1050609@informatik.hu-berlin.de>


I have troubles installing the "SparseM" package on my Debian stable 
Linux system.

Debian's version of R is:
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    1
minor    5.1
year     2002
month    06
day      17
language R


This is the installation output:

 > R CMD INSTALL -l /usr/lib/R/ SparseM_0.36.tar.gz
* Installing *source* package 'SparseM' ...
** libs
g77   -fPIC  -g -O2 -c bckslv.f -o bckslv.o
g77   -fPIC  -g -O2 -c chol.f -o chol.o
g77   -fPIC  -g -O2 -c cholesky.f -o cholesky.o
g77   -fPIC  -g -O2 -c csr.f -o csr.o
g77   -fPIC  -g -O2 -c extract.f -o extract.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 
-c iohb.c -o iohb.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 
-c readwrite.c -o readwrite.o
g77   -fPIC  -g -O2 -c sparskit.f -o sparskit.o
g77   -fPIC  -g -O2 -c subscr.f -o subscr.o
gcc -shared  -o SparseM.so bckslv.o chol.o cholesky.o csr.o extract.o 
iohb.o readwrite.o sparskit.o
subscr.o   -L/usr/lib/gcc-lib/i386-linux/2.95.4 -lreadline -ldl 
-lncurses -lg2c-pic -lm -L/usr/lib/R/bin -lR
** R
** data
** demo
** inst
** save image
Loading required package: methods
[1] TRUE
[1] "matrix.csr"
Error in conformMethod(signature, mnames, fnames) :
        Formal arguments omitted in the method definition cannot be in 
the signature: object
Execution halted
ERROR: execution of package source for 'SparseM' failed

The same happens if I try to install it from within R by calling 
install.packages("SparseM").

Could anybody help me to get SparseM running?

Thanks in advance
Felix



From petr.pikal at precheza.cz  Wed May 12 16:27:11 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 12 May 2004 16:27:11 +0200
Subject: [R] How to know the row number of raw matrix after resampling?
In-Reply-To: <200405121334.i4CDYfVt007466@ris.chonnam.ac.kr>
Message-ID: <40A2505F.6496.1A335B0@localhost>



From tlumley at u.washington.edu  Wed May 12 16:27:50 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 12 May 2004 07:27:50 -0700 (PDT)
Subject: [R] Explaining Survival difference between Stata and R
In-Reply-To: <20040512065415.GA20792@stat.umu.se>
References: <40A01772.9020304@ku.edu>
	<Pine.A41.4.58.0405110707100.34626@homer37.u.washington.edu>
	<20040512065415.GA20792@stat.umu.se>
Message-ID: <Pine.A41.4.58.0405120716410.198264@homer07.u.washington.edu>

On Wed, 12 May 2004, [iso-8859-1] G??ran Brostr??m wrote:

>
> Is it the data? Let's try 'coxreg' (eha):
> ---------------------------------------------------------------
> Call:
> coxreg(formula = Surv(yrs2, ratify) ~ haz.wst + pol.free, data = dat)
>
> Covariate           Mean       Coef        RR       Wald p
> haz.wst           2054901     0.000     1.000        0.372
> pol.free            2.090     0.009     1.009        0.958
>
> Events                    21
> Total time at risk            78
> Max. log. likelihood      -45.001
> LR test statistic         0.76
> Degrees of freedom        2
> Overall p-value           0.684583
> ----------------------------------------------------------------
>
> This worked just fine (Paul, same results as in Stata?). But, we
> seem to have a scaling problem; lok at the means of the covariates!

Yes.

> Some rescaling gives:
> ----------------------------------------------------------------
> Call:
> coxph(formula = Surv(yrs2, ratify) ~ I(haz.wst * 1e-06) + pol.free,
>     data = dat)
>
>
>                       coef exp(coef) se(coef)      z    p
> I(haz.wst * 1e-06) 0.08479      1.09    0.095 0.8920 0.37
> pol.free           0.00896      1.01    0.170 0.0526 0.96
>
> Likelihood ratio test=0.76  on 2 df, p=0.685  n= 21
> ----------------------------------------------------------------
> and now 'coxph' gets the same results as 'coxreg'. I don't know about coxph
> for sure, but I do know that coxreg centers all covariates before the NR
> procedure starts. Maybe we also should rescale to unit variance? And of
> course scale back the coefficients and se:s at the end?

That would make sense.  coxph does center, but it doesn't scale.


	-thomas



From anne.piotet at urbanet.ch  Wed May 12 16:42:36 2004
From: anne.piotet at urbanet.ch (Anne)
Date: Wed, 12 May 2004 16:42:36 +0200
Subject: [R] missing values imputation
Message-ID: <004401c4382f$5ebdec60$6c00a8c0@mtd4>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040512/a8917bd4/attachment.pl

From ripley at stats.ox.ac.uk  Wed May 12 16:54:16 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 May 2004 15:54:16 +0100 (BST)
Subject: [R] Problem installing SparseM on Debian stable
In-Reply-To: <40A23315.1050609@informatik.hu-berlin.de>
Message-ID: <Pine.LNX.4.44.0405121548060.17037-100000@gannet.stats>

You need to find a version of SparseM in the CRAN archive of comparable 
age to your R version (nearly two years),

*or*, much better, update your R to 1.9.0 (or the current patched version)

Hint to maintainers of packages using S4 methods: you almost certainly 
need to declare a dependence on a rather recent version of R since the 
methods code has changed a lot in the last two years.

On Wed, 12 May 2004, Felix Salfner wrote:

> I have troubles installing the "SparseM" package on my Debian stable 
> Linux system.
> 
> Debian's version of R is:
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status
> major    1
> minor    5.1
> year     2002
> month    06
> day      17
> language R

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Wed May 12 16:58:17 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 12 May 2004 16:58:17 +0200
Subject: [R] How to know the row number of raw matrix after r
Message-ID: <40A257A9.16771.1BFB1CD@localhost>



From rolf at math.unb.ca  Wed May 12 17:00:56 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 12 May 2004 12:00:56 -0300 (ADT)
Subject: [R] missing values imputation
Message-ID: <200405121500.i4CF0uew020189@erdos.math.unb.ca>

Anne Piotet wrote:

> What R functionnalities are there to do missing values imputation
> (substantial proportion of missing data)?  I would prefer to use
> maximum likelihood methods ; is the EM algorithm implemented? in
> which package?

	The so-called ``EM algorithm'' is ***NOT*** an
	algorithm.  It is a methodology or a unifying concept.
	It would be impossible to ``implement'' it.  (Except
	possibly by means of some extremely advanced and
	sophisticated Artificial Intelligence software.)

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From migreja at med.up.pt  Wed May 12 17:10:29 2004
From: migreja at med.up.pt (Margarida =?iso-8859-1?Q?J=FAlia?= Rodrigues Igreja)
Date: Wed, 12 May 2004 16:10:29 +0100
Subject: [R] qui-squared test
Message-ID: <6.0.3.0.1.20040512160936.01aeec78@mail.med.up.pt>

Hi,
I would like to do a quisquared test, can you help me with the command?

Margarida



From petr.pikal at precheza.cz  Wed May 12 17:08:50 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 12 May 2004 17:08:50 +0200
Subject: [R] How to know the row number of raw matrix after r
Message-ID: <40A25A22.13234.1C9599A@localhost>

Sorry, last attempt, before contacting our computer people.

Well, I am not sure what was wrong but my reply to Taemyong Choi's question  
was somehow mismatched so I try again. 

Hi  

On 12 May 2004 at 22:35, Taemyong Choi wrote:  

> > DATA  
>   
>             [,1]  
>   
>  [1,] -2.0314185  
>   
>  [2,] -0.3594015  
>   
>  [3,] -1.3225832  
>   
>  [4,]  1.5050892  
>   
>  [5,] -0.4535558  
>   
>  [6,]  3.6335036  
>   
>  [7,]  5.1965750  
>   
>  [8,]  4.2923129  
>   
>  [9,]  6.0913187  
>   
> [10,]  4.9131070  
>   
> > RESA  
>   
>            [,1]       [,2]       [,3]       [,4]       [,5]  
>   
> [1,] -2.0314185  1.5050892 -1.3225832 -1.3225832 -2.0314185  
>   
> [2,] -0.3594015 -0.3594015  4.2923129 -0.3594015 -0.4535558  
>   
> [3,]  4.9131070  4.9131070 -2.0314185  4.9131070  3.6335036  
>   
> [4,]  3.6335036 -0.4535558  3.6335036  1.5050892 -0.3594015  
>   
> [5,]  1.5050892  6.0913187 -0.3594015  4.2923129  6.0913187  
>   
> [6,]  6.0913187  3.6335036  5.1965750 -2.0314185  5.1965750  
>   
> [7,] -0.4535558  5.1965750  6.0913187  3.6335036  4.9131070  
>   
> First,  
>   
> RESA matrix consists of resampling DATA matrix. I would like to know  
> the row number of RESA matrix's value in DATA matrix.  
>   
> For example, RESA[1,1] = -2.0314185 and its row number in DATA matrix  
> is 1.  
>   
>                   RESA[1,3]=4.9131070 and its row number in DATA  
>                   matrix is  
> 10.  

set.seed(1)  
x<-runif(10)  
y<-rep(sample(x,7),5)  
y<-matrix(y,7,5,byrow=T)  
match(y,x)  
[1] 10  8  2  5  4  9  1  5  4  9  1 10  8  2  1 10  8  2  5  4  9  2  5  4  9  1 10  8  9    
1 10  8  2  5  4  


>   
>   
>   
> Is there a simple way to know the row number?  
>   
> I  
>   
> > clus  
>   
>      col1 col2 col3 col4 col5  
>   
> [1,]    1    1    1    1    1  
>   
> [2,]    2    2    0    2    1  
>   
> [3,]    2    1    1    2    2  
>   
> [4,]    1    2    2    1    2  
>   
> [5,]    3    1    2    2    3  
>   
> [6,]    3    3    0    3    2  
>   
> [7,]    1    3    2    0    0  

>   
> Second, I want to count columns of each row without 0  
>   
> i.e. The number of clus[2,]'s columns is 4.   
>   

2.  
     [,1] [,2] [,3] [,4] [,5]  
[1,]    1    3    1    5    0  
[2,]    0    1    2    0    1  
[3,]    4    3    4    5    4  
[4,]    2    1    1    3    0  
[5,]    5    4    1    2    5  
> clus<-matrix(clus,5,5,byrow=T)  
> clus>0  
      [,1] [,2] [,3]  [,4]  [,5]  
[1,]  TRUE TRUE TRUE  TRUE FALSE  
[2,] FALSE TRUE TRUE FALSE  TRUE  
[3,]  TRUE TRUE TRUE  TRUE  TRUE  
[4,]  TRUE TRUE TRUE  TRUE FALSE  
[5,]  TRUE TRUE TRUE  TRUE  TRUE  
> rowSums(clus>0)  
[1] 4 3 5 4 5  

>   
>   
> I solve this with next code.  
>   
> number <- c(rep(1,5))  # 5 is total column number.  
>   
> sum(number[clus[2,]!=0])   
>   
> Is there more simple method?  
>   
>   
>   
> Finally, clus[2,]'s mode is 2. I try to find function to know mode,  
> but I have failed.  

Maybe names(which.max(table(clus))) is what you want?  

> table(clus)  
clus  
0 1 2 3 4 5   
4 7 3 3 4 4   

Cheers  
Petr  


>   
> What's the function to know mode?  
>   
Petr Pikal
petr.pikal at precheza.cz



From elw at stderr.org  Wed May 12 17:10:56 2004
From: elw at stderr.org (elijah wright)
Date: Wed, 12 May 2004 10:10:56 -0500 (CDT)
Subject: [R] Problem installing SparseM on Debian stable
In-Reply-To: <Pine.LNX.4.44.0405121548060.17037-100000@gannet.stats>
References: <Pine.LNX.4.44.0405121548060.17037-100000@gannet.stats>
Message-ID: <Pine.LNX.4.58.0405121008470.17853@illuminati.stderr.org>


> You need to find a version of SparseM in the CRAN archive of comparable
> age to your R version (nearly two years),
>
> *or*, much better, update your R to 1.9.0 (or the current patched
> version)

What you said.  :)

the current R packages available in debian unstable work VERY well.
as a bonus, quite a few of the CRAN packages have been debianized and are
quite easy to install.

so, to sum up, there's likely no good reason for someone to be running
that ancient version of R on a debian machine, other than sheer
stubbornness.

elijah


> > I have troubles installing the "SparseM" package on my Debian stable
> > Linux system.



From edd at debian.org  Wed May 12 17:27:50 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 12 May 2004 10:27:50 -0500
Subject: [R] Problem installing SparseM on Debian stable
In-Reply-To: <Pine.LNX.4.58.0405121008470.17853@illuminati.stderr.org>
References: <Pine.LNX.4.44.0405121548060.17037-100000@gannet.stats>
	<Pine.LNX.4.58.0405121008470.17853@illuminati.stderr.org>
Message-ID: <20040512152750.GA31971@sonny.eddelbuettel.com>

On Wed, May 12, 2004 at 10:10:56AM -0500, elijah wright wrote:
> 
> > You need to find a version of SparseM in the CRAN archive of comparable
> > age to your R version (nearly two years),
> >
> > *or*, much better, update your R to 1.9.0 (or the current patched
> > version)

CRAN has Debian packages of R itself up to version 1.8.1 -- so an upgrade of
R itself to an almost recent version may help in getting SparseM built.

I had promised to try building 1.9.0 for the Debian stable release, but have
not found time to do so. If someone wants to step in, it would certainly be
appreciated by the users of Debian 'stable'.  

> the current R packages available in debian unstable work VERY well.
> as a bonus, quite a few of the CRAN packages have been debianized and are
> quite easy to install.

Hopefully we'll get to making most of CRAN available that way, but it may
only be for the testing / unstable release branches.

Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From Patrik.Waldmann at genfys.slu.se  Wed May 12 17:29:40 2004
From: Patrik.Waldmann at genfys.slu.se (Patrik Waldmann)
Date: Wed, 12 May 2004 17:29:40 +0200
Subject: [R] Identity matrix
Message-ID: <9BE977B02923D311AADA00105AF497830365BFEB@tilia.slu.se>

Hello,

I cannot find a function that forms the identity matrix from a factor, is
there any?

Patrik Waldmann###########################################

This message has been scanned by F-Secure 
Anti-Virus for Microsoft Exchange.

###########################################



From ligges at statistik.uni-dortmund.de  Wed May 12 17:32:29 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 12 May 2004 17:32:29 +0200
Subject: [R] qui-squared test
In-Reply-To: <6.0.3.0.1.20040512160936.01aeec78@mail.med.up.pt>
References: <6.0.3.0.1.20040512160936.01aeec78@mail.med.up.pt>
Message-ID: <40A2438D.2060304@statistik.uni-dortmund.de>

Margarida J??lia Rodrigues Igreja wrote:

> Hi,
> I would like to do a quisquared test, can you help me with the command?

I guess you are looking for
?chisq.test

Uwe Ligges


> Margarida
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed May 12 17:35:53 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 12 May 2004 17:35:53 +0200
Subject: [R] Identity matrix
In-Reply-To: <9BE977B02923D311AADA00105AF497830365BFEB@tilia.slu.se>
References: <9BE977B02923D311AADA00105AF497830365BFEB@tilia.slu.se>
Message-ID: <40A24459.3080506@statistik.uni-dortmund.de>

Patrik Waldmann wrote:

> Hello,
> 
> I cannot find a function that forms the identity matrix from a factor, is
> there any?

For the identity matrix in general see ?diag.

What do you expect to get when forming a "identity matrix from a factor"?

Uwe Ligges


> Patrik Waldmann###########################################
> 
> This message has been scanned by F-Secure 
> Anti-Virus for Microsoft Exchange.
> 
> ###########################################
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From kmw at mail.rockefeller.edu  Wed May 12 17:48:57 2004
From: kmw at mail.rockefeller.edu (Knut M. Wittkowski)
Date: Wed, 12 May 2004 11:48:57 -0400
Subject: [R] mannwitney
In-Reply-To: <6.0.3.0.1.20040512141118.01b00d98@mail.med.up.pt>
Message-ID: <5.1.0.14.0.20040512110700.01df5258@imap.rockefeller.edu>

At 14:12 2004-05-12 +0100, you wrote:
>Hi,
>
>I would like to do a MannWitney test.
>Can anyone help me with the proper command?
>
>Thanks,
>Margarida

You may use wilcox.test or qwilcox, but beware of some subtleties, which 
can result in a bit of confusion (see the below comments and it's 
discussion in the List in June 2003):

 > The function 'wilcox.test' in R and S gives (almost) identical results (see
 > below). 'qwilcox' however, does not:
 >
 > > qwilcox(p,5,5)
 >
 > p: 0.025 0.975
 > --------------------
 > R> 3 22
 > S> 18 37
 >
 > The S-Plus quantiles are almost correct (they are the limits of the region
 > of acceptance, rather than the quantiles). The description in the R help 
file
 >
 > Distribution of the Wilcoxon Rank Sum Statistic
 >
 > suggests that R:qwilcox also gives quantiles for the rank sum (which the
 > Wilcoxon rank sum test is based on). In fact, however, it gives quantiles
 > for the u-statistic (which the Mann-Whitney test is based upon). While the
 > tests are logically equivalent, the particular test statistics
 >
 > - sum(Xi>c(X,Y)) rank sum (Wilcoxon)
 > - sum(Xi>c( Y)) u statistic (Mann-Whitney)
 >
 > are different (apologies for the non-standard notation). Since
 > "wilcox.test" relates to the rank sums in both R and S, as does qwilcox in
 > S, the name 'qwilcox' in R may be misleading. It might be more
 > appropriately be viewed as 'qmannwhitney'.
 >
 > Here are the rank sums and test statistics for two particular examples:
 >
 > > x1 <- c(1,2,3, 5,6 )
 > > x2 <- c( 4, 7,8,9,10)
 > > sum(x1)
 > [1] 17
 > > sum(x2)
 > [1] 38
 >
 > R> wilcox.test(x1,x2,alternative="two.sided")
 > Wilcoxon rank sum test: p-value = 0.03175
 >
 > > x1 <- c(1,2, 4,5,6 )
 > > x2 <- c( 3, 7,8,9,10)
 > > sum(x1)
 > [1] 18
 > > sum(x2)
 > [1] 37
 >
 > R> wilcox.test(x1,x2,alternative="two.sided")
 > Wilcoxon rank sum test: p-value = 0.05556

As you can see, the rank sum quantile for the .05 level (two-sided) is 18,
the result of

S> qwilcox(.025,5,5)
[1] 18

while the result of R

R> qwilcox(.025,5,5)
[1] 3

doesn't directly compare to the results of wilcox.test (both R and S).

I hope this helps.
Knut


Knut M. Wittkowski, PhD,DSc
------------------------------------------
The Rockefeller University, GCRC
Experimental Design and Biostatistics
1230 York Ave #121B, Box 322, NY,NY 10021
+1(212)327-7175, +1(212)327-8450 (Fax)
kmw at rockefeller.edu
http://www.rucares.org/clinicalresearch/dept/biometry/



From Patrik.Waldmann at genfys.slu.se  Wed May 12 18:34:19 2004
From: Patrik.Waldmann at genfys.slu.se (Patrik Waldmann)
Date: Wed, 12 May 2004 18:34:19 +0200
Subject: [R] Design matrix not identity
Message-ID: <9BE977B02923D311AADA00105AF497830365BFED@tilia.slu.se>

Hello again,

I was too quick before. What I was looking for was a function that
constructs the design (or incidence) matrix (X in a linear model) from a
factor. Uwe Ligges suggested using model.matrix and this does almost what I
want, but it is first necessary to construct a data variable. It also asigns
ones to all rows of the first column (because this is set to be the
contrast, not really what I want - see below). Maybe time for a function
that just converts a factor into a design matrix?

I have a factor
factor<-as.factor(c(1,1,2,2,3,3,3))

and I want a matrix
1 0 0
1 0 0
0 1 0
0 1 0
0 0 1
0 0 1
0 0 1


Patrik Waldmann###########################################

This message has been scanned by F-Secure 
Anti-Virus for Microsoft Exchange.

###########################################



From ggrothendieck at myway.com  Wed May 12 18:36:32 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 12 May 2004 16:36:32 +0000 (UTC)
Subject: [R] How to know the row number of raw matrix after resampling?
References: <200405121334.i4CDYfVt007466@ris.chonnam.ac.kr>
Message-ID: <loom.20040512T183208-797@post.gmane.org>


For your first question the simplest way to handle it is to 
sample the indices rather than the data.  For example,

x <- seq(10,200,10) # data
ix <- sample(length(x),10,rep=T) # 10 samples from 1:length(x)
s <- x[ix]  # samples

Now ix has the indices of s.


Taemyong Choi <tmchoi <at> ris.chonnam.ac.kr> writes:

: 
: > DATA
: 
:             [,1]
: 
:  [1,] -2.0314185
: 
:  [2,] -0.3594015
: 
:  [3,] -1.3225832
: 
:  [4,]  1.5050892
: 
:  [5,] -0.4535558
: 
:  [6,]  3.6335036
: 
:  [7,]  5.1965750
: 
:  [8,]  4.2923129
: 
:  [9,]  6.0913187
: 
: [10,]  4.9131070
: 
: > RESA
: 
:            [,1]       [,2]       [,3]       [,4]       [,5]
: 
: [1,] -2.0314185  1.5050892 -1.3225832 -1.3225832 -2.0314185
: 
: [2,] -0.3594015 -0.3594015  4.2923129 -0.3594015 -0.4535558
: 
: [3,]  4.9131070  4.9131070 -2.0314185  4.9131070  3.6335036
: 
: [4,]  3.6335036 -0.4535558  3.6335036  1.5050892 -0.3594015
: 
: [5,]  1.5050892  6.0913187 -0.3594015  4.2923129  6.0913187
: 
: [6,]  6.0913187  3.6335036  5.1965750 -2.0314185  5.1965750
: 
: [7,] -0.4535558  5.1965750  6.0913187  3.6335036  4.9131070
: 
: First,
: 
: RESA matrix consists of resampling DATA matrix. I would like to know the row
: number of RESA matrix's value in DATA matrix.
: 
: For example, RESA[1,1] = -2.0314185 and its row number in DATA matrix is 1.
: 
:                   RESA[1,3]=4.9131070 and its row number in DATA matrix is
: 10.
: 
: Is there a simple way to know the row number?
: 
: I
: 
: > clus
: 
:      col1 col2 col3 col4 col5
: 
: [1,]    1    1    1    1    1
: 
: [2,]    2    2    0    2    1
: 
: [3,]    2    1    1    2    2
: 
: [4,]    1    2    2    1    2
: 
: [5,]    3    1    2    2    3
: 
: [6,]    3    3    0    3    2
: 
: [7,]    1    3    2    0    0
: 
: Second, I want to count columns of each row without 0
: 
: i.e. The number of clus[2,]'s columns is 4. 
: 
: I solve this with next code.
: 
: number <- c(rep(1,5))  # 5 is total column number.
: 
: sum(number[clus[2,]!=0]) 
: 
: Is there more simple method?
: 
: Finally, clus[2,]'s mode is 2. I try to find function to know mode, but I
: have failed.
: 
: What's the function to know mode?
: 
: 	[[alternative HTML version deleted]]
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From jeff.hamann at forestinformatics.com  Wed May 12 18:41:24 2004
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Wed, 12 May 2004 09:41:24 -0700
Subject: [R] summary table newbie question
Message-ID: <000d01c4383f$fa2e9b30$0c00a8c0@rodan>

I've got a newbie question and I got a little lost in the "table helps".
I've got a data.frame I would like to summarize as a (and pardon for the
lack of correct vernacular) data collection matrix. My data looks like,

   stand siteindex age      acres  pct.acres
1    232       116  45  8477.3105 0.56159458
2    234       121  25 11120.1530 0.73667441
3    235       132  25  5399.4605 0.35769691
4    236       115   5  6308.3969 0.41791103
5    240       116  45   473.1533 0.03134489
6    241       116  15 21790.9595 1.44358105
7    245       171  25   686.9867 0.04551066
8    246       134  25 15176.8082 1.00541478
9    247        99  35  1754.9282 0.11625835
10   251       125  55  7396.1098 0.48996851
...blah, blah, blah...


and when I attempt to create a summary table using aggregate, I get the
following results,

> aggregate( stands$acres, by=list(stands$age,stands$siteindex), sum )

    Group.1 Group.2          x
1        95      86  6403.5457
2         5      88  1517.6781
3        45      88  3555.3213
4       125      89  6269.2633
5        95      90  3154.3531
6        55      93 14006.9781
7        15      94    98.9918
8        35      94  2241.0531
9       105      94   431.0281

but what I really want is a matrix where the rows and columns are classes
(in increments of 5 or 10 or whatever) and the cells are the sums (or means
or whatever) for the data.frame. I guess it would be equivalent to like
surf.ls/surf.gls without fitting a trend but that would also allow me to
plot the results graphically in addition to simply printing out the table
using xtable.

Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
541-754-1428
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From ggrothendieck at myway.com  Wed May 12 18:42:01 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 12 May 2004 16:42:01 +0000 (UTC)
Subject: [R] Design matrix not identity
References: <9BE977B02923D311AADA00105AF497830365BFED@tilia.slu.se>
Message-ID: <loom.20040512T184051-545@post.gmane.org>


f<-as.factor(c(1,1,2,2,3,3,3))
model.matrix(~f-1)

Patrik Waldmann <Patrik.Waldmann <at> genfys.slu.se> writes:

: 
: Hello again,
: 
: I was too quick before. What I was looking for was a function that
: constructs the design (or incidence) matrix (X in a linear model) from a
: factor. Uwe Ligges suggested using model.matrix and this does almost what I
: want, but it is first necessary to construct a data variable. It also asigns
: ones to all rows of the first column (because this is set to be the
: contrast, not really what I want - see below). Maybe time for a function
: that just converts a factor into a design matrix?
: 
: I have a factor
: factor<-as.factor(c(1,1,2,2,3,3,3))
: 
: and I want a matrix
: 1 0 0
: 1 0 0
: 0 1 0
: 0 1 0
: 0 0 1
: 0 0 1
: 0 0 1
: 
: 
: Patrik Waldmann###########################################
: 
: This message has been scanned by F-Secure 
: Anti-Virus for Microsoft Exchange.
: 
: ###########################################
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From p.dalgaard at biostat.ku.dk  Wed May 12 18:37:11 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 May 2004 18:37:11 +0200
Subject: [R] Design matrix not identity
In-Reply-To: <9BE977B02923D311AADA00105AF497830365BFED@tilia.slu.se>
References: <9BE977B02923D311AADA00105AF497830365BFED@tilia.slu.se>
Message-ID: <x2zn8d8uvc.fsf@biostat.ku.dk>

Patrik Waldmann <Patrik.Waldmann at genfys.slu.se> writes:

> Hello again,
> 
> I was too quick before. What I was looking for was a function that
> constructs the design (or incidence) matrix (X in a linear model) from a
> factor. Uwe Ligges suggested using model.matrix and this does almost what I
> want, but it is first necessary to construct a data variable. It also asigns
> ones to all rows of the first column (because this is set to be the
> contrast, not really what I want - see below). Maybe time for a function
> that just converts a factor into a design matrix?
> 
> I have a factor
> factor<-as.factor(c(1,1,2,2,3,3,3))

That could get you in trouble by masking the factor() function...

> and I want a matrix
> 1 0 0
> 1 0 0
> 0 1 0
> 0 1 0
> 0 0 1
> 0 0 1
> 0 0 1

 f <- factor(c(1,1,2,2,3,3,3))
 model.matrix(~f-1)


Or, a different approach:

 diag(3)[f,]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From sundar.dorai-raj at PDF.COM  Wed May 12 18:44:03 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 12 May 2004 09:44:03 -0700
Subject: [R] Design matrix not identity
In-Reply-To: <9BE977B02923D311AADA00105AF497830365BFED@tilia.slu.se>
References: <9BE977B02923D311AADA00105AF497830365BFED@tilia.slu.se>
Message-ID: <40A25453.6050902@pdf.com>



Patrik Waldmann wrote:

> Hello again,
> 
> I was too quick before. What I was looking for was a function that
> constructs the design (or incidence) matrix (X in a linear model) from a
> factor. Uwe Ligges suggested using model.matrix and this does almost what I
> want, but it is first necessary to construct a data variable. It also asigns
> ones to all rows of the first column (because this is set to be the
> contrast, not really what I want - see below). Maybe time for a function
> that just converts a factor into a design matrix?
> 
> I have a factor
> factor<-as.factor(c(1,1,2,2,3,3,3))
> 
> and I want a matrix
> 1 0 0
> 1 0 0
> 0 1 0
> 0 1 0
> 0 0 1
> 0 0 1
> 0 0 1
> 
> 
> Patrik Waldmann###########################################


model.matrix will do this for you.

R> fac <- as.factor(c(1, 1, 2, 2, 3, 3, 3))
R> model.matrix(~ fac - 1)
   fac1 fac2 fac3
1    1    0    0
2    1    0    0
3    0    1    0
4    0    1    0
5    0    0    1
6    0    0    1
7    0    0    1
attr(,"assign")
[1] 1 1 1
attr(,"contrasts")
attr(,"contrasts")$fac
[1] "contr.treatment"

The "-1" drops the intercept.

Is this what you need?

--sundar



From andy_liaw at merck.com  Wed May 12 18:45:29 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 12 May 2004 12:45:29 -0400
Subject: [R] Design matrix not identity
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D80@usrymx25.merck.com>

I don't think the design matrix and the incidence matrix are the same thing.
A design matrix is the X matrix in a usual linear model, which would
(usually) include the column of ones, and the contrasts.  So model.matrix()
is the right thing for a design matrix.

For incidence matrix, you can try:

> f <- as.factor(c(1,1,2,2,3,3,3))
> sapply(levels(f), function(x) as.numeric(f == x))
     1 2 3
[1,] 1 0 0
[2,] 1 0 0
[3,] 0 1 0
[4,] 0 1 0
[5,] 0 0 1
[6,] 0 0 1
[7,] 0 0 1


Andy

> From: Patrik Waldmann
> 
> Hello again,
> 
> I was too quick before. What I was looking for was a function that
> constructs the design (or incidence) matrix (X in a linear 
> model) from a
> factor. Uwe Ligges suggested using model.matrix and this does 
> almost what I
> want, but it is first necessary to construct a data variable. 
> It also asigns
> ones to all rows of the first column (because this is set to be the
> contrast, not really what I want - see below). Maybe time for 
> a function
> that just converts a factor into a design matrix?
> 
> I have a factor
> factor<-as.factor(c(1,1,2,2,3,3,3))
> 
> and I want a matrix
> 1 0 0
> 1 0 0
> 0 1 0
> 0 1 0
> 0 0 1
> 0 0 1
> 0 0 1
> 
> 
> Patrik Waldmann###########################################
> 
> This message has been scanned by F-Secure 
> Anti-Virus for Microsoft Exchange.
> 
> ###########################################
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ripley at stats.ox.ac.uk  Wed May 12 18:47:02 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 May 2004 17:47:02 +0100 (BST)
Subject: [R] Design matrix not identity
In-Reply-To: <9BE977B02923D311AADA00105AF497830365BFED@tilia.slu.se>
Message-ID: <Pine.LNX.4.44.0405121741380.17292-100000@gannet.stats>

On Wed, 12 May 2004, Patrik Waldmann wrote:

> I was too quick before. What I was looking for was a function that
> constructs the design (or incidence) matrix (X in a linear model) from a
> factor. Uwe Ligges suggested using model.matrix and this does almost what I
> want, but it is first necessary to construct a data variable. 

Eh?  You have to construct the factor, and nothing else.

> It also asigns ones to all rows of the first column (because this is set
> to be the contrast, not really what I want - see below). Maybe time for
> a function that just converts a factor into a design matrix?

Uwe was quite correct, and you were still too quick.

[Don't call an object after an R function. Let's use a sensible name like
`f'.]

f <- as.factor(c(1,1,2,2,3,3,3))
model.matrix(~ 0 + f)

or

diag(nlevels(f))[f,]

gives what you illustrate.

> I have a factor
> factor<-as.factor(c(1,1,2,2,3,3,3))
> 
> and I want a matrix
> 1 0 0
> 1 0 0
> 0 1 0
> 0 1 0
> 0 0 1
> 0 0 1
> 0 0 1

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

PLEASE do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Wed May 12 18:55:46 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 12 May 2004 12:55:46 -0400
Subject: [R] missing values imputation
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D82@usrymx25.merck.com>

> From: Rolf Turner
> 
> Anne Piotet wrote:
> 
> > What R functionnalities are there to do missing values imputation
> > (substantial proportion of missing data)?  I would prefer to use
> > maximum likelihood methods ; is the EM algorithm implemented? in
> > which package?
> 
> 	The so-called ``EM algorithm'' is ***NOT*** an
> 	algorithm.  It is a methodology or a unifying concept.
> 	It would be impossible to ``implement'' it.  (Except
> 	possibly by means of some extremely advanced and
> 	sophisticated Artificial Intelligence software.)

Yes, but EM for missing value imputation is a bit narrower, I guess.  At
least the `norm' package on CRAN has em.norm() for multivariate gaussian...

Andy

 
> 				cheers,
> 
> 					Rolf Turner
> 					rolf at math.unb.ca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From Ted.Harding at nessie.mcc.ac.uk  Wed May 12 18:57:53 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 12 May 2004 17:57:53 +0100 (BST)
Subject: [R] missing values imputation
In-Reply-To: <200405121500.i4CF0uew020189@erdos.math.unb.ca>
Message-ID: <XFMail.040512175753.Ted.Harding@nessie.mcc.ac.uk>

On 12-May-04 Rolf Turner wrote:
> Anne Piotet wrote:
> 
>> What R functionnalities are there to do missing values imputation
>> (substantial proportion of missing data)?  I would prefer to use
>> maximum likelihood methods ; is the EM algorithm implemented? in
>> which package?
> 
>       The so-called ``EM algorithm'' is ***NOT*** an
>       algorithm.  It is a methodology or a unifying concept.
>       It would be impossible to ``implement'' it.  (Except
>       possibly by means of some extremely advanced and
>       sophisticated Artificial Intelligence software.)

Do we understand the same thing by "EM Algorithm"?

The one I'm thinking of -- formulated under that name by Dempster,
Laird and Rubin in 1977 ("Maximum likelihood estimation from incomplete
data via the EM  algorithm", JRSS(B) 39, 1-38) -- is indeed an algorithm
in exactly the same sense as any iterative search for the maximum of a
function.

Essentially, in the context of data modelled by an underlying exponential
family distribution where there is incomplete information about the
values which have this distribution, it proceeds by

Start: Choose starting estimates for the parameters of the distribution
E: Using the current parameter values, compute the expected vaues
   of the sufficient statistics conditional on the observed information
M: Solve the maximum-likelihood equations (which are functions of the
   sufficient statistics) using the expected values computed in (E)
If sufficently converged, stop. Otherwise, make the current parameter
values equal to the values estimated in (M) and return to (E).

Algorithm, this, or not????

And where does "extremely advanced and sophisticated Artificial
Intelligence software" come into it? You can, in some cases, perform
the above EM algorithm by hand.

Which "EM Algorithm" are you thinking of?

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 12-May-04                                       Time: 17:57:53
------------------------------ XFMail ------------------------------



From Ted.Harding at nessie.mcc.ac.uk  Wed May 12 18:44:50 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 12 May 2004 17:44:50 +0100 (BST)
Subject: [R] missing values imputation
In-Reply-To: <004401c4382f$5ebdec60$6c00a8c0@mtd4>
Message-ID: <XFMail.040512174450.Ted.Harding@nessie.mcc.ac.uk>

On 12-May-04 Anne wrote:
>  What R functionnalities are there to do missing values imputation
> (substantial proportion of missing data)? 
> I would prefer to use maximum likelihood methods ; is the EM algorithm
> implemented? in which package?

Hi Anne,
R already has packages/libraries called "cat", "norm" and "mix" which,
while they are not part of the standard installation, can be readily
downloaded and installed from any CRAN website -- see under "contributed
sources".

These implement in R Schafer's S code for what he calls "CAT", "NORM"
and "MIX". These are for imputing missing data where the data are
respectively entirely categorical, entirley continous ("norm" operates
on the basis that the data are a sample from a multivariate normal
distribution) and a mixture of both (some variables categorical, some
continuous). All include routines for multiple imputation, and for
extracting appropriate information about the parameters from the
imputations.

Schafer also has an S function "PAN" which imoputes missing values
from "panel" data. I don;t think this has been implemented for R yet.

There is one type of data which also, I think, has nothing implemented
for R (and I have not heard of a specially written routine for S-plus
either). This is so-called "semi-continuous" data -- where the value
of a variable may either be "continuous" or else take a specific
value (typically zero). E.g. "How much did you spend on alcohol last
week?" -- answer may be a positive amount, maybe log-normally distributed,
or else zero. You can approach data of this kind with missing values
by combining "cat" and "norm", but it's tricky and may not correspond
to a valid model.

All of Schafer's methods use maximum-likelihood estimation of the
parameters for the first phase of the imputation, using the EM algorithm
(and I'll respond to Rolf Turner's comments shortly).

After that, you can make a simple imputation by sampling from the
distribution thus estimated, or in a more general and indeed sounder
way, first sample from the posterior parameter distribution, sample
imputed values from the resulting distribution, and then repeat
sampling from parameters and resulting distributions to build up
an array of datasets with the missing data filled in by multiple
imputation.

Hoping this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 12-May-04                                       Time: 17:44:50
------------------------------ XFMail ------------------------------



From ripley at stats.ox.ac.uk  Wed May 12 19:15:21 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 May 2004 18:15:21 +0100 (BST)
Subject: [R] missing values imputation
In-Reply-To: <XFMail.040512175753.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0405121812350.17465-100000@gannet.stats>

That's not an algorithm.  It is a recipe for deriving an algorithm.

  algorithm - A detailed sequence of actions to perform to accomplish some
  task. Named after an Iranian mathematician, Al-Khawarizmi.

  Technically, an algorithm must reach a result after a finite number of
  steps, thus ruling out brute force search methods for certain problems,
  though some might claim that brute force search was also a valid (generic)  
  algorithm. The term is also used loosely for any sequence of actions
  (which may or may not terminate).

Paul E. Black's Dictionary of Algorithms, Data Structures, and Problems.

On Wed, 12 May 2004 Ted.Harding at nessie.mcc.ac.uk wrote:

> On 12-May-04 Rolf Turner wrote:
> > Anne Piotet wrote:
> > 
> >> What R functionnalities are there to do missing values imputation
> >> (substantial proportion of missing data)?  I would prefer to use
> >> maximum likelihood methods ; is the EM algorithm implemented? in
> >> which package?
> > 
> >       The so-called ``EM algorithm'' is ***NOT*** an
> >       algorithm.  It is a methodology or a unifying concept.
> >       It would be impossible to ``implement'' it.  (Except
> >       possibly by means of some extremely advanced and
> >       sophisticated Artificial Intelligence software.)
> 
> Do we understand the same thing by "EM Algorithm"?
> 
> The one I'm thinking of -- formulated under that name by Dempster,
> Laird and Rubin in 1977 ("Maximum likelihood estimation from incomplete
> data via the EM  algorithm", JRSS(B) 39, 1-38) -- is indeed an algorithm
> in exactly the same sense as any iterative search for the maximum of a
> function.
> 
> Essentially, in the context of data modelled by an underlying exponential
> family distribution where there is incomplete information about the
> values which have this distribution, it proceeds by
> 
> Start: Choose starting estimates for the parameters of the distribution
> E: Using the current parameter values, compute the expected vaues
>    of the sufficient statistics conditional on the observed information
> M: Solve the maximum-likelihood equations (which are functions of the
>    sufficient statistics) using the expected values computed in (E)
> If sufficently converged, stop. Otherwise, make the current parameter
> values equal to the values estimated in (M) and return to (E).
> 
> Algorithm, this, or not????
> 
> And where does "extremely advanced and sophisticated Artificial
> Intelligence software" come into it? You can, in some cases, perform
> the above EM algorithm by hand.
> 
> Which "EM Algorithm" are you thinking of?
> 
> Best wishes,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 12-May-04                                       Time: 17:57:53
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rossini at blindglobe.net  Wed May 12 19:23:05 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 12 May 2004 10:23:05 -0700
Subject: [R] missing values imputation
In-Reply-To: <XFMail.040512175753.Ted.Harding@nessie.mcc.ac.uk>
	(Ted.Harding@nessie.mcc.ac.uk's
	message of "Wed, 12 May 2004 17:57:53 +0100 (BST)")
References: <XFMail.040512175753.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <85y8nxo8zq.fsf@servant.blindglobe.net>

(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:

> On 12-May-04 Rolf Turner wrote:
>> Anne Piotet wrote:
>> 
>>> What R functionnalities are there to do missing values imputation
>>> (substantial proportion of missing data)?  I would prefer to use
>>> maximum likelihood methods ; is the EM algorithm implemented? in
>>> which package?
>> 
>>       The so-called ``EM algorithm'' is ***NOT*** an
>>       algorithm.  It is a methodology or a unifying concept.
>>       It would be impossible to ``implement'' it.  (Except
>>       possibly by means of some extremely advanced and
>>       sophisticated Artificial Intelligence software.)
>
> Do we understand the same thing by "EM Algorithm"?
>
> The one I'm thinking of -- formulated under that name by Dempster,
> Laird and Rubin in 1977 ("Maximum likelihood estimation from incomplete
> data via the EM  algorithm", JRSS(B) 39, 1-38) -- is indeed an algorithm
> in exactly the same sense as any iterative search for the maximum of a
> function.
>
> Essentially, in the context of data modelled by an underlying exponential
> family distribution where there is incomplete information about the
> values which have this distribution, it proceeds by
>
> Start: Choose starting estimates for the parameters of the distribution
> E: Using the current parameter values, compute the expected vaues
>    of the sufficient statistics conditional on the observed information
> M: Solve the maximum-likelihood equations (which are functions of the
>    sufficient statistics) using the expected values computed in (E)
> If sufficently converged, stop. Otherwise, make the current parameter
> values equal to the values estimated in (M) and return to (E).
>
> Algorithm, this, or not????
>
> And where does "extremely advanced and sophisticated Artificial
> Intelligence software" come into it? You can, in some cases, perform
> the above EM algorithm by hand.
>
> Which "EM Algorithm" are you thinking of?

Thanks, Ted :-) -- to extend it a bit, one can imagine the use of
approximate solutions to the 2 steps (simulation methods to get
expected values, similar range of approaches for the maximization) and
get a general (but possibly not robust)  computational solution for
the parametric problem.  Just plug in a formula for the likelihood and
the sufficient statistics...

Of course, thousands of papers have been written on these variations
(likelihood, specific implementations of the E and M steps).  

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From rossini at blindglobe.net  Wed May 12 19:34:30 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 12 May 2004 10:34:30 -0700
Subject: [R] missing values imputation
In-Reply-To: <Pine.LNX.4.44.0405121812350.17465-100000@gannet.stats> (Brian
	Ripley's message of "Wed, 12 May 2004 18:15:21 +0100 (BST)")
References: <Pine.LNX.4.44.0405121812350.17465-100000@gannet.stats>
Message-ID: <85lljxo8gp.fsf@servant.blindglobe.net>


Picky, picky.

Details are in the eyes of the beholder.

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> That's not an algorithm.  It is a recipe for deriving an algorithm.
>
>   algorithm - A detailed sequence of actions to perform to accomplish some
>   task. Named after an Iranian mathematician, Al-Khawarizmi.
>
>   Technically, an algorithm must reach a result after a finite number of
>   steps, thus ruling out brute force search methods for certain problems,
>   though some might claim that brute force search was also a valid (generic)  
>   algorithm. The term is also used loosely for any sequence of actions
>   (which may or may not terminate).
>
> Paul E. Black's Dictionary of Algorithms, Data Structures, and Problems.
>
> On Wed, 12 May 2004 Ted.Harding at nessie.mcc.ac.uk wrote:
>
>> On 12-May-04 Rolf Turner wrote:
>> > Anne Piotet wrote:
>> > 
>> >> What R functionnalities are there to do missing values imputation
>> >> (substantial proportion of missing data)?  I would prefer to use
>> >> maximum likelihood methods ; is the EM algorithm implemented? in
>> >> which package?
>> > 
>> >       The so-called ``EM algorithm'' is ***NOT*** an
>> >       algorithm.  It is a methodology or a unifying concept.
>> >       It would be impossible to ``implement'' it.  (Except
>> >       possibly by means of some extremely advanced and
>> >       sophisticated Artificial Intelligence software.)
>> 
>> Do we understand the same thing by "EM Algorithm"?
>> 
>> The one I'm thinking of -- formulated under that name by Dempster,
>> Laird and Rubin in 1977 ("Maximum likelihood estimation from incomplete
>> data via the EM  algorithm", JRSS(B) 39, 1-38) -- is indeed an algorithm
>> in exactly the same sense as any iterative search for the maximum of a
>> function.
>> 
>> Essentially, in the context of data modelled by an underlying exponential
>> family distribution where there is incomplete information about the
>> values which have this distribution, it proceeds by
>> 
>> Start: Choose starting estimates for the parameters of the distribution
>> E: Using the current parameter values, compute the expected vaues
>>    of the sufficient statistics conditional on the observed information
>> M: Solve the maximum-likelihood equations (which are functions of the
>>    sufficient statistics) using the expected values computed in (E)
>> If sufficently converged, stop. Otherwise, make the current parameter
>> values equal to the values estimated in (M) and return to (E).
>> 
>> Algorithm, this, or not????
>> 
>> And where does "extremely advanced and sophisticated Artificial
>> Intelligence software" come into it? You can, in some cases, perform
>> the above EM algorithm by hand.
>> 
>> Which "EM Algorithm" are you thinking of?
>> 
>> Best wishes,
>> Ted.
>> 
>> 
>> --------------------------------------------------------------------
>> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
>> Fax-to-email: +44 (0)870 167 1972
>> Date: 12-May-04                                       Time: 17:57:53
>> ------------------------------ XFMail ------------------------------
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>> 
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From B.Rowlingson at lancaster.ac.uk  Wed May 12 19:41:47 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 12 May 2004 18:41:47 +0100
Subject: [R] missing values imputation
In-Reply-To: <85lljxo8gp.fsf@servant.blindglobe.net>
References: <Pine.LNX.4.44.0405121812350.17465-100000@gannet.stats>
	<85lljxo8gp.fsf@servant.blindglobe.net>
Message-ID: <40A261DB.10604@lancaster.ac.uk>

A.J. Rossini wrote:
> Picky, picky.
> 
> Details are in the eyes of the beholder.

>>  algorithm - A detailed sequence of actions to perform to accomplish some
>>  task. Named after an Iranian mathematician, Al-Khawarizmi.

Personally I like the first definition of 'Algorism, Algorithm' in the 
1913 Websters Revised Unabridged:

  1. The art of calculating by nine figures and zero.

Barry



From jfox at mcmaster.ca  Wed May 12 20:26:47 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 12 May 2004 14:26:47 -0400
Subject: [R] Design matrix not identity
In-Reply-To: <9BE977B02923D311AADA00105AF497830365BFED@tilia.slu.se>
Message-ID: <20040512182645.HMBH17358.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Patrick,

Try model.matrix(~ factor - 1).

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrik Waldmann
> Sent: Wednesday, May 12, 2004 11:34 AM
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] Design matrix not identity
> 
> Hello again,
> 
> I was too quick before. What I was looking for was a function 
> that constructs the design (or incidence) matrix (X in a 
> linear model) from a factor. Uwe Ligges suggested using 
> model.matrix and this does almost what I want, but it is 
> first necessary to construct a data variable. It also asigns 
> ones to all rows of the first column (because this is set to 
> be the contrast, not really what I want - see below). Maybe 
> time for a function that just converts a factor into a design matrix?
> 
> I have a factor
> factor<-as.factor(c(1,1,2,2,3,3,3))
> 
> and I want a matrix
> 1 0 0
> 1 0 0
> 0 1 0
> 0 1 0
> 0 0 1
> 0 0 1
> 0 0 1
> 
> 
> Patrik Waldmann###########################################
>



From lamkelj at yahoo.com  Wed May 12 20:38:19 2004
From: lamkelj at yahoo.com (=?iso-8859-1?q?Kel?=)
Date: Wed, 12 May 2004 11:38:19 -0700 (PDT)
Subject: [R] Random Forest with highly imbalanced data
Message-ID: <20040512183819.39266.qmail@web12508.mail.yahoo.com>

Hi group,

I am trying to do a RF with approx 250,000
cases.  My objective is to determine the risk factors
of a person being readmitted to hospital (response=1)
or else (response=0).  Only 10%, or 25,000 cases were
readmitted.  I've heard about down-sampling and class
weight approach and am wondering if R can do it.  Even
some reference to articles will help.  

>From the statistical point of view, is there any rule
of thumb of the positive/negative response ratio so
that adjustment has to be applied?

Thank you so much.  

Regards,
Kelvin



From Ted.Harding at nessie.mcc.ac.uk  Wed May 12 20:44:20 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 12 May 2004 19:44:20 +0100 (BST)
Subject: [R] missing values imputation
In-Reply-To: <85y8nxo8zq.fsf@servant.blindglobe.net>
Message-ID: <XFMail.040512194420.Ted.Harding@nessie.mcc.ac.uk>

On 12-May-04 A.J. Rossini wrote:
> (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:
> [...]
>> Algorithm, this, or not????
> [...]
> Thanks, Ted :-) -- to extend it a bit, one can imagine the use of
> approximate solutions to the 2 steps (simulation methods to get
> expected values, similar range of approaches for the maximization) and
> get a general (but possibly not robust)  computational solution for
> the parametric problem.  Just plug in a formula for the likelihood and
> the sufficient statistics...

And thank you, Tony!

I confess to having deliberately been a bit provocative, since I see an
issue here on which I have a view (apparently shared by Tony).

For example:

Question: In your view, is the following "exchange sort" procedure
an algorithm? Or merely "a recipe for deriving an algorithm"?

A: Starting at the intended "low" end of the line compare each
   i-th item X[i] with the (i+1)-th item X[i+1] for i=1,2,...
B: If you find an i such that X[i] > X[i+1],
     exchange the positions of X[i] and X[i+1]
C: If you have reached the end of the line, stop.
   Otherwise, go to (A).

Now, I think this is an algorithm. However, before reading on,
please decide what you think yourself about this question.

















Well, you could use this to sort a line of people into order of
increasing height, without recourse to a measuring scale.

Just get X[i] and X[i+1] to stand up straight and look into each
others eyes. If X[i] has to look down into the eyes of X[i+1}, then
X[i] > X[i+1]; otherwise not.

The point is, illustrated naively by this example, that the above
description of "exchange sort" doesn't explain anything about ">".
So something has to be "plugged in" (in Tony's words) for ">", and
hence the algorithm, to have a meaning or an implementation. There
has to be a "sort key" with respect to which there is an implementation
of ">" in order to render the "algorithm" (my terminology ... ) concrete.
So yes, if being picky, the above description of "exchange sort" could be
called a "recipe for deriving an algorithm". But then a different
algorithm would result for (a) every different kind of thing which could
be sorted; (b) every different kind of interpretation of ">" (e.g. it
would not then be the same "algorithm" if you measured people's heights
with a scale). OK, now perhaps being "picky" in my turn ...

However, the general point is that an "algorithm", in my and no doubt
Tony's notion of it, usually needs a plugin or two or several in order
to be implemented for any particular case.

So for the EM algorithm.

It needs, specifically, a specification of the exponential-family
distribution, a means for computing a conditional expected value
with this distribution, and a solver for the complete-data maximum
likelihood equations. Once these are provided, the implementation
is complete.

Just as a coded computer routine can call a subroutine or co-routine,
so also one can envisage an algorithm calling a sub-algorithm.

Final question: What, for instance, is the status of the R function
"integrate"?

  plugin <- function(x){x*(1-x)}
  integrate(plugin,0,1)

uses (I quote):

  For a finite interval, globally adaptive interval subdivision is
  used in connection with extrapolation by the Epsilon algorithm.

If "plugin" has not been specified, does the code for "integrate"
represent an algorithm or not? Well, I rather think it does!

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 12-May-04                                       Time: 19:44:20
------------------------------ XFMail ------------------------------



From ggrothendieck at myway.com  Wed May 12 20:56:08 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 12 May 2004 18:56:08 +0000 (UTC)
Subject: [R] summary table newbie question
References: <000d01c4383f$fa2e9b30$0c00a8c0@rodan>
Message-ID: <loom.20040512T205535-598@post.gmane.org>


Check out aggregate.table in package gregmisc .

Jeff D. Hamann <jeff.hamann <at> forestinformatics.com> writes:

: 
: I've got a newbie question and I got a little lost in the "table helps".
: I've got a data.frame I would like to summarize as a (and pardon for the
: lack of correct vernacular) data collection matrix. My data looks like,
: 
:    stand siteindex age      acres  pct.acres
: 1    232       116  45  8477.3105 0.56159458
: 2    234       121  25 11120.1530 0.73667441
: 3    235       132  25  5399.4605 0.35769691
: 4    236       115   5  6308.3969 0.41791103
: 5    240       116  45   473.1533 0.03134489
: 6    241       116  15 21790.9595 1.44358105
: 7    245       171  25   686.9867 0.04551066
: 8    246       134  25 15176.8082 1.00541478
: 9    247        99  35  1754.9282 0.11625835
: 10   251       125  55  7396.1098 0.48996851
: ...blah, blah, blah...
: 
: and when I attempt to create a summary table using aggregate, I get the
: following results,
: 
: > aggregate( stands$acres, by=list(stands$age,stands$siteindex), sum )
: 
:     Group.1 Group.2          x
: 1        95      86  6403.5457
: 2         5      88  1517.6781
: 3        45      88  3555.3213
: 4       125      89  6269.2633
: 5        95      90  3154.3531
: 6        55      93 14006.9781
: 7        15      94    98.9918
: 8        35      94  2241.0531
: 9       105      94   431.0281
: 
: but what I really want is a matrix where the rows and columns are classes
: (in increments of 5 or 10 or whatever) and the cells are the sums (or means
: or whatever) for the data.frame. I guess it would be equivalent to like
: surf.ls/surf.gls without fitting a trend but that would also allow me to
: plot the results graphically in addition to simply printing out the table
: using xtable.
: 
: Jeff.
: 
: ---
: Jeff D. Hamann
: Forest Informatics, Inc.
: PO Box 1421
: Corvallis, Oregon USA 97339-1421
: 541-754-1428
: jeff.hamann <at> forestinformatics.com
: www.forestinformatics.com
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From vograno at evafunds.com  Wed May 12 20:59:48 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed, 12 May 2004 11:59:48 -0700
Subject: [R] recover should send messages to stderr, not stdout
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B32FC@phost015.EVAFUNDS.intermedia.net>



> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Tuesday, May 11, 2004 11:21 PM
> To: Vadim Ogranovich
> Cc: R-Help
> Subject: Re: [R] recover should send messages to stderr, not stdout
> 
...
> 
> Note that some of us consider recover() to be designed for 
> interactive-only use, and use something like

Unfortunately, R help doesn't reflect the apparent diversity of
opinions. Regarding recover it says


     The use of 'recover' largely supersedes 'dump.frames' as an error
     option, unless you really want to wait to look at the error.  If
     'recover' is called in non-interactive mode, it behaves like
     'dump.frames'.  <...>

>     options(error=expression(if(interactive()) recover() else 
> dump.calls()))

This is useful. Thank you very much for the tip!

> On Tue, 11 May 2004, Vadim Ogranovich wrote:
> 
> > recover() sends all its messages, which I consider to be error 
> > messages, to stdout. I think they more properly belong to stderr.
> >  
> > This is an important difference for those of us who use R in batch 
> > mode to generate ASCII files.
> 
> Only to the subset who believe that recover() is a useful 
> error option in 
> non-interactive use.

This subset is likely to include everyone who carefully reads the
documentation, see the above excerpt from a help page.


Thanks,
Vadim



From Jesus.Frias at dit.ie  Wed May 12 21:13:09 2004
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Wed, 12 May 2004 20:13:09 +0100
Subject: [R] Change default values of a function
Message-ID: <LGECJJCANFBOOHCMGPJEGEOMDCAA.Jesus.Frias@dit.ie>

Dear R-helpers,
	I would like to change the default value of a functions that is call by a
package. The function deparse() is called by a set of functions from a
library and because I don't think is appropriate to change the library, I am
trying to change the default value in deparse().

	At the moment the only solution I have come across is to place a function
in my working environment like this,

deparse <- function(expr,width.cutoff=400,backtick=mode(expr) %in%
c("call","expression","("),...) deparse(expr,width.cutoff=400,backtick,...)

	I only want to change the width.cutoff of the function and I wonder of
there is any more elegant way to do it.

regards,

Jesus



--------------------------------------------------------------
Jes??s Mar??a Fr??as Celayeta
School of Food Sci. and Env. Health.
Faculty of Tourism and Food
Dublin Institute of Technology
Cathal Brugha St., Dublin 1. Ireland
t +353 1 4024459 f +353 1 4024495
w www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------


-- 
This message has been scanned for content and 
viruses by the DIT Information Services MailScanner 
Service, and is believed to be clean.
http://www.dit.ie



From ripley at stats.ox.ac.uk  Wed May 12 21:30:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 May 2004 20:30:01 +0100 (BST)
Subject: [R] recover should send messages to stderr, not stdout
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A54B32FC@phost015.EVAFUNDS.intermedia.net>
Message-ID: <Pine.LNX.4.44.0405122025240.17678-100000@gannet.stats>

On Wed, 12 May 2004, Vadim Ogranovich wrote:

> 
> 
> > -----Original Message-----
> > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> > Sent: Tuesday, May 11, 2004 11:21 PM
> > To: Vadim Ogranovich
> > Cc: R-Help
> > Subject: Re: [R] recover should send messages to stderr, not stdout
> > 
> ...
> > 
> > Note that some of us consider recover() to be designed for 
> > interactive-only use, and use something like
> 
> Unfortunately, R help doesn't reflect the apparent diversity of
> opinions. Regarding recover it says

Well, I got my suggestion from the work of the author of those words,
on page 268 of the Green Book, so I don't think your `apparent' is based 
on careful reading.

>      The use of 'recover' largely supersedes 'dump.frames' as an error
>      option, unless you really want to wait to look at the error.  If
>      'recover' is called in non-interactive mode, it behaves like
>      'dump.frames'.  <...>
> 
> >     options(error=expression(if(interactive()) recover() else 
> > dump.calls()))
> 
> This is useful. Thank you very much for the tip!
> 
> > On Tue, 11 May 2004, Vadim Ogranovich wrote:
> > 
> > > recover() sends all its messages, which I consider to be error 
> > > messages, to stdout. I think they more properly belong to stderr.
> > >  
> > > This is an important difference for those of us who use R in batch 
> > > mode to generate ASCII files.
> > 
> > Only to the subset who believe that recover() is a useful 
> > error option in 
> > non-interactive use.
> 
> This subset is likely to include everyone who carefully reads the
> documentation, see the above excerpt from a help page.

Everyone who reads that carefully will realize that in batch use you do
want (and need) to wait for the error.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rolf at math.unb.ca  Wed May 12 21:38:13 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 12 May 2004 16:38:13 -0300 (ADT)
Subject: [R] missing values imputation
Message-ID: <200405121938.i4CJcD7b001529@erdos.math.unb.ca>

Thanks  Brian.

The EM algorithm requires an ``E'' step and an ``M'' step.  Harding
and Rossini appear to be seriously suggesting that an R function
could be written which would

	(a) Perform the E step in arbitrary contexts, and
	(b) For that given expected value, work out a procedure
	    to effect its maximization.

Or maybe they're not serious.

For the M step (b) general numerical optimization would theoretically
do the trick.  (But would be fraught with peril.)  For the E step
(a), forget it.

The point is, the EM ``algorithm'' is NOT an algorithm which could be
effected by an R function.  This is in complete contrast with
integrate() --- it's there; the code is written.  Hand integrate() an
integration problem, and it'll do it.  One of the differences is that
the input to an itegration problem is clearly defined and readily
specifiable as an R function.  The input to a general missing values
problem is amorphous.

Arguing about what constitutes an algorithm according to some
abstract definition is mindless.  If you define ``algorithm'' to suit
yourself, then the EM algorithm is an algorithm; otherwise not.

The original questioner wanted an R function to effect the EM
algorithm.  My point was that this is a silly request because such a
function would be impossible to write.

Call the EM algorithm an algorithm if it makes you happy.  But
remember that by doing so you'll mislead the naive inquirer
who will expect there to be a real live implementation of that
algorithm.  In computer (R) code.  Like integrate().

If you can write an R function to effect the EM ``algorithm'' --- in
general, not just in a special case --- you'll win the Chambers Prize
in computing and a few other things as well.


				cheers,

					Rolf Turner
					rolf at math.unb.ca



From rossini at blindglobe.net  Wed May 12 21:52:44 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 12 May 2004 12:52:44 -0700
Subject: [R] missing values imputation
In-Reply-To: <200405121938.i4CJcD7b001529@erdos.math.unb.ca> (Rolf Turner's
	message of "Wed, 12 May 2004 16:38:13 -0300 (ADT)")
References: <200405121938.i4CJcD7b001529@erdos.math.unb.ca>
Message-ID: <8565b1mnhv.fsf@servant.blindglobe.net>

Rolf Turner <rolf at math.unb.ca> writes:

> The EM algorithm requires an ``E'' step and an ``M'' step.  Harding
> and Rossini appear to be seriously suggesting that an R function
> could be written which would
>
> 	(a) Perform the E step in arbitrary contexts, and
> 	(b) For that given expected value, work out a procedure
> 	    to effect its maximization.
>
> Or maybe they're not serious.

Serious for a range of reasonable specific problems and appropriate
specification of the function (Remember that sufficient statistics
aren't unique, and would have to be specified!).  Think of it as a
macro.  Exercise left to the reader, see below.

> If you can write an R function to effect the EM ``algorithm'' --- in
> general, not just in a special case --- you'll win the Chambers Prize
> in computing and a few other things as well.

I believe there is an eligibility issue with the award you mention
(perhaps you are thinking of the ACM award?), but I suspect the
results, as in most software "publications", would be severe headaches
and grief from having to listen to complaints, gripes, and groaning.

Seldom are prizes, credit, and gratitude given, else Brian would be
drowning in them.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From andy_liaw at merck.com  Wed May 12 21:54:26 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 12 May 2004 15:54:26 -0400
Subject: [R] Random Forest with highly imbalanced data
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D86@usrymx25.merck.com>

Breiman & Cutler's version 5 of the Fortran code implements a weighting
scheme that is more effective than the old classwt.  Basically:

1. class weights are used in computing the Gini index.
2. At terminal nodes, weighted votes are taken to determine the prediction
for the node.
3. Average weights within terminal nodes are computed, and used as weights
for the final weighted vote.

This has not been implemented in the R version of the package (and is one of
the reasons the version number for the package is still 4.x-y instead of
5.x-y).  Do note that one usually needs to `tune' the class weights a bit to
get the desired result.

The current version of the R package does offer the sampsize option; i.e.,
randomForest(..., sampsize=c(100, 100), ...) will draw 100 cases within each
class, with replacement, to grow each tree.  (This is the `down-sampling'
approach.)  We have found this to work quite well in general.

[Advertisement:  I will present both at the Interface in a few weeks.]

Best,
Andy

> From: Kel
> 
> Hi group,
> 
> I am trying to do a RF with approx 250,000
> cases.  My objective is to determine the risk factors
> of a person being readmitted to hospital (response=1)
> or else (response=0).  Only 10%, or 25,000 cases were
> readmitted.  I've heard about down-sampling and class
> weight approach and am wondering if R can do it.  Even
> some reference to articles will help.  
> 
> >From the statistical point of view, is there any rule
> of thumb of the positive/negative response ratio so
> that adjustment has to be applied?
> 
> Thank you so much.  
> 
> Regards,
> Kelvin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From DAVID.BICKEL at PIONEER.COM  Wed May 12 22:03:27 2004
From: DAVID.BICKEL at PIONEER.COM (Bickel, David)
Date: Wed, 12 May 2004 15:03:27 -0500
Subject: [R] non-interactive call to R (running an R package as a
	stand-alone application)
Message-ID: <5F883C17941B9F4E80E5FA8C9F1C5E0EBD5B75@jhms08.phibred.com>

Is there a way I can have R automatically execute the commands in a source file without ever having to use R interactively? If so, what arguments should I pass to the UNIX call to R? I need to do this to run several R jobs in parallel.

An alternative may be to have R and an R package behave as a stand-alone application that can be called from the UNIX command line. Is there any documentation on this? S-PLUS can do something like this.

I will be using Red Hat Linux.

Thank you,
David
______________________________
David Bickel  http://davidbickel.com
Research Scientist
Pioneer Hi-Bred International
Bioinformatics & Discovery Research
7250 NW 62nd Ave., PO Box 552
Johnston, Iowa 50131-0552
706-736-9151 Home
515-334-4739 Work
515-334-6634 Fax
david.bickel at pioneer.com, bickel at prueba.info



This communication is for use by the intended recipient and ...{{dropped}}



From ihaka at stat.auckland.ac.nz  Wed May 12 22:13:32 2004
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Thu, 13 May 2004 08:13:32 +1200
Subject: [R] How to draw holes generated by gpclib using plot function
In-Reply-To: <Pine.LNX.4.44.0405112105270.5082-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0405112105270.5082-100000@reclus.nhh.no>
Message-ID: <40A2856C.1060609@stat.auckland.ac.nz>

Roger Bivand wrote:

> Is an unpleasing fix to accept the overfilling, and to order (and mark if
> known) the contained polygons - some GIS use ring direction to suggest
> which are lakes and which islands? This may mean that some polygons get
> painted several times, but I don't know if this is avoidable at present.
> For Hisaji's problem this would mean overpainting the later hole with a
> background colour (not "transparent" or NA), setting this as the col=
> argument in polygon(). For many polygons finding which are inside which,
> to set the painting order, could be messy by brute force, but would just
> need to output an index vector to re-order the polygons and the painting
> col= argument. Before several packages try to solve/find working though
> admittedly ugly fixes to this separately, should we share ideas?

This is a partial fix for the GIS case, but it would be nice to have
a general fix.  You might, for example, want to see things through
the holes in the polygons.

I have a collection of material on this and other useful geometric
problems, but no time at the moment to pursue it.  I'd be happy
collaborate.  Give me a prod in about four weeks (when my teaching
finishes) and  I'll try to assemble what I have into a coherent form.

-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand



From p.dalgaard at biostat.ku.dk  Wed May 12 22:29:35 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 May 2004 22:29:35 +0200
Subject: [R] non-interactive call to R (running an R package as a
	stand-alone application)
In-Reply-To: <5F883C17941B9F4E80E5FA8C9F1C5E0EBD5B75@jhms08.phibred.com>
References: <5F883C17941B9F4E80E5FA8C9F1C5E0EBD5B75@jhms08.phibred.com>
Message-ID: <x21xlp75jk.fsf@biostat.ku.dk>

"Bickel, David" <DAVID.BICKEL at PIONEER.COM> writes:

> Is there a way I can have R automatically execute the commands in a
> source file without ever having to use R interactively? If so, what
> arguments should I pass to the UNIX call to R? I need to do this to
> run several R jobs in parallel.

Yes; help(BATCH) tells you one of them. (Somewhat surprising, this is
not in the FAQ. It is mentioned in the R-intro manual though, and
comes out of R --help).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From iaw4 at welch.som.yale.edu  Wed May 12 22:59:19 2004
From: iaw4 at welch.som.yale.edu (ivo welch)
Date: Wed, 12 May 2004 16:59:19 -0400
Subject: [R] lm without a formula?
Message-ID: <40A29027.2060805@welch.som.yale.edu>


hi:  I have a y vector and an x data frame.  is it possible to use the 
standard linear regression (lm, summary.lm) without having to construct 
a formula, i.e., all x variables should be used.

    x <- data.frame( rnorm(10), rnorm(10) );  # <-- well, this would 
really be read from a file
    y <- rnorm(10);  # ok, also read from the file.
    lm (y ~ x);  # this is sort of what I want to do, but of course, it 
is not.

thanks for any tips.  regards, /iaw



From ripley at stats.ox.ac.uk  Wed May 12 23:05:29 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 May 2004 22:05:29 +0100 (BST)
Subject: [R] lm without a formula?
In-Reply-To: <40A29027.2060805@welch.som.yale.edu>
Message-ID: <Pine.LNX.4.44.0405122203240.7480-100000@gannet.stats>

x <- data.frame( x1=rnorm(10), x2=rnorm(10) )
lm(y ~., data=x)

seems to be what you want.

BTW, R is not C/Perl/... and ; is a separator, not a terminator.

On Wed, 12 May 2004, ivo welch wrote:

> 
> hi:  I have a y vector and an x data frame.  is it possible to use the 
> standard linear regression (lm, summary.lm) without having to construct 
> a formula, i.e., all x variables should be used.
> 
>     x <- data.frame( rnorm(10), rnorm(10) );  # <-- well, this would 
> really be read from a file
>     y <- rnorm(10);  # ok, also read from the file.
>     lm (y ~ x);  # this is sort of what I want to do, but of course, it 
> is not.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Wed May 12 23:05:54 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 12 May 2004 21:05:54 +0000 (UTC)
Subject: [R] lm without a formula?
References: <40A29027.2060805@welch.som.yale.edu>
Message-ID: <loom.20040512T230511-353@post.gmane.org>


lm(y~.,data=x)


ivo welch <iaw4 <at> welch.som.yale.edu> writes:

: 
: hi:  I have a y vector and an x data frame.  is it possible to use the 
: standard linear regression (lm, summary.lm) without having to construct 
: a formula, i.e., all x variables should be used.
: 
:     x <- data.frame( rnorm(10), rnorm(10) );  # <-- well, this would 
: really be read from a file
:     y <- rnorm(10);  # ok, also read from the file.
:     lm (y ~ x);  # this is sort of what I want to do, but of course, it 
: is not.
: 
: thanks for any tips.  regards, /iaw



From bacolli at uark.edu  Wed May 12 23:11:08 2004
From: bacolli at uark.edu (Bret Collier)
Date: Wed, 12 May 2004 16:11:08 -0500
Subject: [R] Setting max values for rpois
In-Reply-To: <x21xlp75jk.fsf@biostat.ku.dk>
References: <5F883C17941B9F4E80E5FA8C9F1C5E0EBD5B75@jhms08.phibred.com>
	<5F883C17941B9F4E80E5FA8C9F1C5E0EBD5B75@jhms08.phibred.com>
Message-ID: <5.2.1.1.0.20040512160017.00b045d0@mail.uark.edu>

R-users,
         I am simulating a birth process for 4 classes of individuals with 
l[i] being the average No. fetuses per individual.  However, I need to 
bound the resulting values for each generated rpois to be <=3 (no 
individual can have > 3 offspring).  I have not been able to figure out how 
to incorporate this into the below example.  Any suggestions on integrating 
would be appreciated.


recruit.f <- c(12, 12, 25, 51)  #No. females in each age class
l <- c(.05, 1.22, 1.6, 1.8)  #mean No. fetuses for each age class
x <- sapply(lapply(1:4, function(i) rpois(recruit.f[i], l[i])), sum)

TIA,

Bret A. Collier
Arkansas Cooperative Fish and Wildlife Research Unit
University of Arkansas



From Ted.Harding at nessie.mcc.ac.uk  Wed May 12 23:05:08 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 12 May 2004 22:05:08 +0100 (BST)
Subject: [R] missing values imputation
In-Reply-To: <200405121938.i4CJcD7b001529@erdos.math.unb.ca>
Message-ID: <XFMail.040512220508.Ted.Harding@nessie.mcc.ac.uk>

On 12-May-04 Rolf Turner wrote:
> The EM algorithm requires an ``E'' step and an ``M'' step.  Harding
> and Rossini appear to be seriously suggesting that an R function
> could be written which would
> 
>       (a) Perform the E step in arbitrary contexts, and
>       (b) For that given expected value, work out a procedure
>           to effect its maximization.
> 
> Or maybe they're not serious.
> 
> For the M step (b) general numerical optimization would theoretically
> do the trick.  (But would be fraught with peril.)  For the E step
> (a), forget it.
> 
> The point is, the EM ``algorithm'' is NOT an algorithm which could be
> effected by an R function.
> [...]
> The original questioner wanted an R function to effect the EM
> algorithm.  My point was that this is a silly request because such a
> function would be impossible to write.

Well, I think there's been enough hair-splitting on the "algorithm"
issue!

To revert to the point about the original query from Anne Piotet.
She said she would prefer to use maximum likelihood methods, and asked
if the EM algorithm was available, in the context of imputing missing
data.

I don't think she was asking about whether R was blessed with a "universal
EM algorithm" into which any incomplete-data problem could be plugged
(and I agree that the generality of the problem, especially expressing
the conditioning corresponding to arbitrary incompleteness, would make
such a thing very elusive).

What I believe she *was* asking was whether, using R, she could do
imputation with maximum-likelihood methods using the EM algorithm.
There are plenty of imputation methods which dodge likelihood altogether,
and thereby lose efficiency, so the question has a lot of point, and
the EM algorithm is of course the natural approach since no information
is more manifestly incomplete than when there are holes in the data.

Schafer's methods (and thanks, Chuck, for the pointer to "pan") all
implement the EM algorithm to obtain maximum likelihood estimates in
the first instance. As far as replying to Anne was concerned, I think
all that was needed was to give this information.

To receive a response which asserted (in effect) that it was
unimplementable must have come as a bit of a surpise, in the context!

Anyway, 'nuff said, probably ...

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 12-May-04                                       Time: 22:05:08
------------------------------ XFMail ------------------------------



From andrew_white at hmsa.com  Wed May 12 23:15:46 2004
From: andrew_white at hmsa.com (Andrew White)
Date: Wed, 12 May 2004 11:15:46 -1000
Subject: [R] help with generalized list function in R
Message-ID: <8B9604D41941A14F90E094B07713F953027D0E02@HON10036.corp.hmsa.com>

In S-plus I have depended upon a simple extended ls() function developed by John wallace called lsx()

Reason: lsx() allows me to search for object names in my local workspace matching an unquoted character string.
Since I forget all the function names or data object names I have added, I can quickly find any/all names matching any specified string.

BUT: the lsx() function when installed (successfully, no errors reported) in R does not work in R.  
Why ? Can it be fixed so it can work?

Code is below:
---------------------------
lsx<-function(pattern, pos = 1, wild = T, long = F, mode = "function")
{
	#   lsx = extended listing: pattern match on quoted string, incl wildcards
	#
	#   LS-eXtended (saved as ls3.s): list objects all or matching <pattern>
	#   DATE WRITTEN:  February 1995      LAST REVISED:   15 August 1995
	#   AUTHOR:  John R. Wallace (jw at u.washington.edu)
	#
	if(!missing(pattern)) {
		if(!is.character(substitute(pattern, frame = sys.nframe())))
			pattern <- deparse(substitute(pattern, frame = sys.nframe()))
		if(wild)
			pattern <- paste("*", pattern,"*", sep = "")
		if(!(substring(as.character(version)[1], 2, 4) == "WIN"))
			pattern <- pat2grep(pattern)
		if(long)
			print(out <- objects.summary(objects(pos, pat = pattern), where = pos))
		else print(out <- objects(pos, pat = pattern), q = F)
	}
	else {
		if(long)
			print(out <- objects.summary(where = pos, mode = mode))
		else {
			if(substring(as.character(version)[1], 2, 4) == "WIN") {
				pattern <- "[!.]*"
				print(out <- objects(pos, pat = pattern), q = F)
			}
			else {
				all <- objects(pos)
				print(out <- all[!match(all, objects(pos, pat = "^\\."),no = 0)], q = F)
			}
		}
	}
	invisible(out)
}

---------------------------

Andy White
Andrew N. White, Ph.D. - Manager Research Unit
Financial Reporting & Medical Economics Dept.
Hawaii Medical Service Association
- Blue Cross Blue Shield of Hawaii
An Independent Licensee of the Blue Cross and Blue Shield Association -
818 Keeaumoku Street, Honolulu, HI 96814
Ph. 808-948-5344 - Email: andrew_white at hmsa.com



From jedwards at ucar.edu  Wed May 12 23:27:27 2004
From: jedwards at ucar.edu (Jim Edwards)
Date: Wed, 12 May 2004 21:27:27 +0000
Subject: [R] R 1.9.0 on AIX, 64-bit
In-Reply-To: <Pine.GSO.4.30.0405111453160.1132-100000@sunray1>
References: <Pine.GSO.4.30.0405111453160.1132-100000@sunray1>
Message-ID: <40A296BF.1090703@ucar.edu>

Tim,

On the configure problem I've determined that this is a bug in the file 
acinclude.m4 provided in the R distribution.  The test function  
R_SYS_POSIX_LEAPSECONDS  needs to have ct initialized.  That it works on 
other systems is fortuitous.  Can you provide this feedback to the 
developers?  Thanks

Jim



Tim Hoar wrote:

>Here is a followup to Andy's post -- I have a working 64-bit R on AIX ...
>
>My institution is running AIX 5.1.
>
>Several things are needed to build R 1.9.0 and use dynamic loading of .so
>objects.
>
>*) setenv OBJECT_MODE 64       or the equivalent.
>
>*) There is a quirk (bug?) in the AIX compilers in 64bit mode that requires
>   changing configure:line 36555      to initialize a variable to zero.
>   Line 36555 should be:  time_t ct=0;
>
>   without the change -- configure hits a test for POSIX times and hangs ...
>
>   This can also be overcome by using -qinitauto=00, but it is
>   a performance hit ... so it is probably undesirable in the long run.
>
>   Note that in 32bit mode, this is not needed.
>
>*) The dynamic linking options specified in the R Installation and
>   Administration Guide: Section B.7.8 did not work for me --
>   the ones that did work are:
>
>OBJECT_MODE=64
>LDFLAGS='-brtl'
>CFLAGS='-O -qstrict'
>FFLAGS='-O -qstrict'
>CXXFLAGS='-O -qstrict'
>CC=/usr/bin/xlc_r
>F77=/usr/bin/xlf_r
>CXX=/usr/bin/xlC_r
>
>   furthermore, I was able to configure with the X11 libraries (and did not
>   have to supply the "--without-blas" option):
>
>   ./configure --prefix='blah_blah_blah'
>
>   it is nice to be able to plot!
>   Our IBM rep indicated that with LDFLAGS set as above, "configure" is
>   generally smart enough to figure out everything else -- kudos to the R
>   configure team. I have not tried a higher level of optimization.
>
>*) Our system does not have a 32,64-bit /lib/crt0.o  -- ours is only 32bit.
>   Our 64bit one is /lib/crt0_64.o   so after configure generates a
>   Makeconf file, it must be edited to use /lib/crt0_64.o  instead of crt0.o
>
>*) (credit to Andy Pierce)
>
>  
>
>>Date: Mon, 10 May 2004 13:31:22 -0400
>>From: Andy Pierce <apierce at stny.rr.com>
>>To: Tim Hoar <thoar at ucar.edu>
>>Subject: Re: [R] R 1.9.0 on AIX, 64-bit
>>
>>I worked the problem down to where there seems to be something wrong
>>with mktime in the way that R uses it.... I modified src/main/datetime.c
>>to add the lines for _AIX which you see below...  oddly, if you
>>extract out the mktime code from here and stuff it into a standalone
>>routine, it seems to work fine. It's all in the handling of dates from
>>before the epoch (1970).
>>
>>static Rboolean have_broken_mktime(void)
>>{
>>#ifdef _AIX
>>     return TRUE;
>>#else
>>#ifdef Win32
>>
>>     return TRUE;
>>
>>(the rest of the existing function....
>>
>>#endif
>>}
>>    
>>
>
>*) Our system is configured such that it is guaranteed to fail the
>   "running tests of Internet and socket function" tests, so I have
>   not run any of the tests after that -- yet.
>
>*) (again - credit to Andy Pierce)
>   When I tried to build the SparseM package -- there was an unresolved
>   external -- "etime"
>
>   Adding a file "etime.c" to the SparseM/src  with the following:
>
>#include <sys/time.h>
>#include <sys/resource.h>
>float etime(tt)
>float tt[2];
>{
>   int who;
>   struct rusage used;
>   who = 0;
>   getrusage(who,&used);
>/*   tt[0] = used.ru_exutime.tv_sec+((used.ru_exutime.tv_usec)/1000000.); */
>   tt[0] = used.ru_utime.tv_sec+((used.ru_utime.tv_usec)/1000000.);
>   tt[1] = used.ru_stime.tv_sec+((used.ru_stime.tv_usec)/1000000.);
>   return(tt[0]+tt[1]);
>}
>
>I did not find any problems in the config.log or the build output that
>indicates etime is a problem anywhere else.
>
>-=-=-=-=-=-=-=-=-=-=-
>
>After all the above -- I can dyn.load(), generate figures, etc.
>Hope this helps someone ...
>
>Tim
>
><Andy's post from Mon, 03 May 2004 08:27:47 -0400  deleted>
>
>
>## Tim Hoar, Associate Scientist              email: thoar at ucar.edu     ##
>## Geophysical Statistics Project             phone: 303-497-1708       ##
>## National Center for Atmospheric Research   FAX  : 303-497-1333       ##
>## Boulder, CO  80307                    http://www.cgd.ucar.edu/~thoar ##
>
>  
>


-- 
Jim Edwards             jedwards at ucar.edu
IBM Applications Analyst
NCAR SCD
BOULDER CO  303-497-1842



From GPetris at uark.edu  Wed May 12 23:31:49 2004
From: GPetris at uark.edu (Giovanni Petris)
Date: Wed, 12 May 2004 16:31:49 -0500 (CDT)
Subject: [R] Setting max values for rpois
In-Reply-To: <5.2.1.1.0.20040512160017.00b045d0@mail.uark.edu> (message from
	Bret Collier on Wed, 12 May 2004 16:11:08 -0500)
References: <5F883C17941B9F4E80E5FA8C9F1C5E0EBD5B75@jhms08.phibred.com>
	<5F883C17941B9F4E80E5FA8C9F1C5E0EBD5B75@jhms08.phibred.com>
	<5.2.1.1.0.20040512160017.00b045d0@mail.uark.edu>
Message-ID: <200405122131.i4CLVnES006435@definetti.uark.edu>


Bret,

the following should do:

x <- sum(pmin(rpois(recruit.f, l),3))

Giovanni

> Date: Wed, 12 May 2004 16:11:08 -0500
> From: Bret Collier <bacolli at uark.edu>
> Sender: r-help-bounces at stat.math.ethz.ch
> Precedence: list
> 
> R-users,
>          I am simulating a birth process for 4 classes of individuals with 
> l[i] being the average No. fetuses per individual.  However, I need to 
> bound the resulting values for each generated rpois to be <=3 (no 
> individual can have > 3 offspring).  I have not been able to figure out how 
> to incorporate this into the below example.  Any suggestions on integrating 
> would be appreciated.
> 
> 
> recruit.f <- c(12, 12, 25, 51)  #No. females in each age class
> l <- c(.05, 1.22, 1.6, 1.8)  #mean No. fetuses for each age class
> x <- sapply(lapply(1:4, function(i) rpois(recruit.f[i], l[i])), sum)
> 
> TIA,
> 
> Bret A. Collier
> Arkansas Cooperative Fish and Wildlife Research Unit
> University of Arkansas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From chenxr at stanford.edu  Wed May 12 23:33:40 2004
From: chenxr at stanford.edu (Xiaorong Chen)
Date: Wed, 12 May 2004 14:33:40 -0700
Subject: [R] Formula of power.t.test
Message-ID: <1084397620.40a29834587e9@webmail.stanford.edu>

Dear Sir or Madam,

What is the formula for power.t.test(delta=delta, sd=segma, sig.level=0.05, 
power=0.8, type="one.sample", alternative="one.sided")$n?

Thank you very much for the help!

Best,

Xiaorong



From loveland.1 at nd.edu  Wed May 12 23:48:28 2004
From: loveland.1 at nd.edu (Matt Loveland)
Date: Wed, 12 May 2004 16:48:28 -0500
Subject: [R] GLMM question
Message-ID: <003a01c4386a$dcbeff10$a3b74a81@loveland>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040512/12cb6d00/attachment.pl

From Ted.Harding at nessie.mcc.ac.uk  Wed May 12 23:55:47 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 12 May 2004 22:55:47 +0100 (BST)
Subject: [R] Setting max values for rpois
In-Reply-To: <5.2.1.1.0.20040512160017.00b045d0@mail.uark.edu>
Message-ID: <XFMail.040512224508.Ted.Harding@nessie.mcc.ac.uk>

On 12-May-04 Bret Collier wrote:
> R-users,
>          I am simulating a birth process for 4 classes of individuals
> with l[i] being the average No. fetuses per individual.  However, I
> need to bound the resulting values for each generated rpois to be <=3
> (no individual can have > 3 offspring).  I have not been able to
> figure out how to incorporate this into the below example.  Any
> suggestions on integrating  would be appreciated.
> 
> 
> recruit.f <- c(12, 12, 25, 51)  #No. females in each age class
> l <- c(.05, 1.22, 1.6, 1.8)  #mean No. fetuses for each age class
> x <- sapply(lapply(1:4, function(i) rpois(recruit.f[i], l[i])), sum)

It looks as though you are seeking to sample randomly from a Poisson
truncated at 3. This is in effect a multinomial with n=1, so one
approach could be (using your (51,1.8) case as illustration)

  prob<-dpois((0:3),1.8); prob<-prob/sum(prob);
  Nfetuses <- t((0:3))*rmultinom(51,1,prob)

which would give you 51 draws of 1 from the distribution
P(0)=0.1854599, P(1)=0.3338279, P(2)=0.3004451, P(3)=0.1802671
(though there may be a more direct way).

Anyway, whatever method you use to get the sample, you can wrap it
in a function to replace 'rpois' in your expression above.

Ted.



From ggrothendieck at myway.com  Thu May 13 01:10:02 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 12 May 2004 23:10:02 +0000 (UTC)
Subject: [R] help with generalized list function in R
References: <8B9604D41941A14F90E094B07713F953027D0E02@HON10036.corp.hmsa.com>
Message-ID: <loom.20040513T010759-462@post.gmane.org>


You can do that with ls and the pattern= argument.  For example,

ls(pattern = "my")

finds all objects with my anywhere in the name.  See ?ls

Andrew White <andrew_white <at> hmsa.com> writes:

: 
: In S-plus I have depended upon a simple extended ls() function developed by 
John wallace called lsx()
: 
: Reason: lsx() allows me to search for object names in my local workspace 
matching an unquoted character string.
: Since I forget all the function names or data object names I have added, I 
can quickly find any/all names
: matching any specified string.
: 
: BUT: the lsx() function when installed (successfully, no errors reported) in 
R does not work in R.  
: Why ? Can it be fixed so it can work?
: 
: Code is below:
: ---------------------------
: lsx<-function(pattern, pos = 1, wild = T, long = F, mode = "function")
: {
: 	#   lsx = extended listing: pattern match on quoted string, incl 
wildcards
: 	#
: 	#   LS-eXtended (saved as ls3.s): list objects all or matching 
<pattern>
: 	#   DATE WRITTEN:  February 1995      LAST REVISED:   15 August 1995
: 	#   AUTHOR:  John R. Wallace (jw <at> u.washington.edu)
: 	#
: 	if(!missing(pattern)) {
: 		if(!is.character(substitute(pattern, frame = sys.nframe())))
: 			pattern <- deparse(substitute(pattern, frame = 
sys.nframe()))
: 		if(wild)
: 			pattern <- paste("*", pattern,"*", sep = "")
: 		if(!(substring(as.character(version)[1], 2, 4) == "WIN"))
: 			pattern <- pat2grep(pattern)
: 		if(long)
: 			print(out <- objects.summary(objects(pos, pat = 
pattern), where = pos))
: 		else print(out <- objects(pos, pat = pattern), q = F)
: 	}
: 	else {
: 		if(long)
: 			print(out <- objects.summary(where = pos, mode = mode))
: 		else {
: 			if(substring(as.character(version)[1], 2, 4) == "WIN") 
{
: 				pattern <- "[!.]*"
: 				print(out <- objects(pos, pat = pattern), q = 
F)
: 			}
: 			else {
: 				all <- objects(pos)
: 				print(out <- all[!match(all, objects(pos, pat 
= "^\\."),no = 0)], q = F)
: 			}
: 		}
: 	}
: 	invisible(out)
: }
: 
: ---------------------------
: 
: Andy White
: Andrew N. White, Ph.D. - Manager Research Unit
: Financial Reporting & Medical Economics Dept.
: Hawaii Medical Service Association
: - Blue Cross Blue Shield of Hawaii
: An Independent Licensee of the Blue Cross and Blue Shield Association -
: 818 Keeaumoku Street, Honolulu, HI 96814
: Ph. 808-948-5344 - Email: andrew_white <at> hmsa.com
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From deepayan at stat.wisc.edu  Thu May 13 01:32:07 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 12 May 2004 18:32:07 -0500
Subject: [R] GLMM question
In-Reply-To: <003a01c4386a$dcbeff10$a3b74a81@loveland>
References: <003a01c4386a$dcbeff10$a3b74a81@loveland>
Message-ID: <200405121832.07104.deepayan@stat.wisc.edu>

On Wednesday 12 May 2004 16:48, Matt Loveland wrote:
> Hi
>
> I'm using lme4 to do random effects modelling.
>
> I keep getting the following error message:
>
> Error in "EMsteps<-"(*tmp*', value = control) :
>             invalid source matrix
>
> I get the error when I include more than one random effect in the
> model, sometime I'm able to get two.  I've looked into the variables
> that cause the problems aren't highly correlated, but they are dummy
> variables with small percentages receiving a score of 1 (6%, 11%).

Could you give us a reproducible example (along with information on what 
versions of R and lme4 you are using) ?

Deepayan



From ndesnoyers at att.net  Thu May 13 01:39:05 2004
From: ndesnoyers at att.net (Neil Desnoyers)
Date: Wed, 12 May 2004 23:39:05 +0000
Subject: [R] Barchart questions
Message-ID: <051220042339.19374.40A2B598000D537C00004BAE2160281302FF8C8D9A8690918C9A9B@att.net>

I am attempting to produce a bar chart and am having some trouble with the panel.barchart command. The definition of X is that it's the "proper extent of the bar". Is that the maximum value? Or is it the labels for my vertical axis, since the axes seem to be switched for this command? Is there a better/different command I should be using for barcharts (i.e. barplot)?

Thanks for your assistance.

Neil Desnoyers



From ggrothendieck at myway.com  Thu May 13 01:52:46 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 12 May 2004 23:52:46 +0000 (UTC)
Subject: [R] Fitting data from a spectrophotometer.
References: <76F96CFE2AA2114C886B028A065A7FC402074E5A@exdkba020.novo.dk>
Message-ID: <loom.20040513T014106-923@post.gmane.org>


Perhaps you really prefer something with a continuous first derivative?
In that case, all the continuous cumulative distribution functions have 
a sigmoidal shape and might be suitable.  You could fit pnorm, plogis or tanh
with suitable scaling and location parameters using nls.  An example
of fitting a logistic is at

https://stat.ethz.ch/pipermail/r-help/2004-April/048385.html 


TAPO (Thomas Agersten Poulsen <tapo <at> novozymes.com> writes:

: 
: Dear R-list,
: 
: 	It is not uncommon for laboratory equipment (e.g. spectrophotometers) 
to have a linear response in a
: certain interval and then go into saturation. I wonder if there is an R-
function that models this; for
: instance by estimating the breakpoint and fitting a line below the 
breakpoint and a constant above.
: 
: Best regards
: Thomas Poulsen



From jeff.hamann at forestinformatics.com  Thu May 13 02:39:31 2004
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Wed, 12 May 2004 17:39:31 -0700
Subject: [R] xtable without rownames
Message-ID: <000901c43882$c1c147f0$0c00a8c0@rodan>

When I tried to read all the entries (after searching the FAQ) for "row
names xtable", I get


START-INFO-DIR-ENTRY * R FAQ: (R-FAQ). The R statistical system ...
... xtable* Export data to LaTeX and HTML tables. ... For dropping the row
names of a matrix
`x', it may be easier to use `rownames(x) <- NULL', similarly for column ...
cvs.r-project.org/cgi-bin/viewcvs.cgi/R/FAQ?rev=1.301 - 101k - Supplemental
Result - Cached - Similar pages
I wasn't able to follow the link. I'd like to use xtable to generate latex
tables for using with Sweave and can't figure out how to not include the row
names. When I attempt to NULL out the row names using,

but cannot follow the links. Browser tells me the page is unavailable. When
I attempt to blank out the row names using,

rownames(summary.table) <- NULL

I get the following error

> rownames(rta) <- NULL
Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
 invalid dimnames given for data frame
>

the resulting (incorrect) table appears as,

> xtable( rta )
% latex table generated in R 1.9.0 by xtable 1.2-2 package
% Wed May 12 17:38:21 2004
\begin{table}[ht]
\begin{center}
\begin{tabular}{rlr}
\hline
 & site.index & acres \\
\hline
1 &  80 & 20.90 \\
2 &  90 & 64.42 \\
...blah, blah, blah...
8 & 150 & 53.32 \\
9 & 170 & 0.69 \\
\hline
\end{tabular}
\end{center}
\end{table}
>

with the rownames. How do I get them out?

I'm stuck. Help.

Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
541-754-1428
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From xt_wang at cs.concordia.ca  Thu May 13 02:48:26 2004
From: xt_wang at cs.concordia.ca (xt_wang@cs.concordia.ca)
Date: Wed, 12 May 2004 20:48:26 -0400
Subject: [R] question about dyn.load()
Message-ID: <1084409306.40a2c5da38db9@mailhost.cs.concordia.ca>

Hello, everybody,

I met a big problem. What I want is to use c code in R. I have load a test 
code "conv.c" in R and run it successfully. However, in my real code, I use 
matlab c library (Matrix Inverse function). After I use command "R CMD SHLIB" 
to share library, I can not use "dyn.load" to load the object in 
R.  "undefined symbol: mclCleanupProtectedItems" always be mentioned. 

My question is that whether I can compile, load and use a c code in R which 
includes other library. If I can, How can I do? Could you help me find out 
where is the error during the whole operation? If I can not load a c code with 
other library in R, can I load a c code with R library  in R ( which include 
matrix inverse function)? If so, where can I find the R library with matrix 
inverse function that has a c interface? 

I will appreciate very much if somebody can help me resolve this problem.

Thanks in advance!

Yours,

Maggie

The whole successful and failed process are as follows: 

[credsim at confsys ~/src]$ R CMD SHLIB ~/src/conv.c
make: `/home/credsim/src/conv.so' is up to date.
[credsim at confsys ~/src]$ R

R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

> dyn.load("./conv.so")
> "%+%" <- function(a,b)
+ .C("conv", as.double(a), as.integer(length(a)), 
+            as.double(b), as.integer(length(b)),
+            ab=double(length(a)+length(b)-1))$ab
> u <-rep(1,5)
> u %+% u
[1] 1 2 3 4 5 4 3 2 1

"conv.c"
void conv (double *a, int *na, double *b, int *nb, double *ab)
{
  int i, j, nab=*na+*nb-1;

  for (i=0;i<nab;i++)
    ab[i]=0.0;
  for (i=0;i<*na;i++)
    for (j=0;j<*nb;j++)
     ab[i+j]+=a[i]*b[j];
}

The new operation process with matlab c library :

[credsim at confsys ~/src]$ R CMD SHLIB ~/src/conv.c
gcc -I/usr/local/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -
mieee-fp  -fPIC  -g -O2 -c /home/credsim/src/conv.c -o /home/credsim/src/conv.o
gcc -shared -L/usr/local/lib -
o /home/credsim/src/conv.so /home/credsim/src/conv.o   
[credsim at confsys ~/src]$ R

R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> dyn.load("./conv.so")
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library "/b2/home/credsim/src/./conv.so":
  /b2/home/credsim/src/./conv.so: undefined symbol: mclCleanupProtectedItems
>

new code "conv.c"

#include "/a3/matlab/extern/include/matlab.h"
#include <math.h>

void conv (double *a, int *na, double *b, int *nb, double *ab)
{
  int i, j, nab=*na+*nb-1;

  for (i=0;i<nab;i++)
    ab[i]=0.0;
  for (i=0;i<*na;i++)
    for (j=0;j<*nb;j++)
     ab[i+j]+=a[i]*b[j];
}



From p.dalgaard at biostat.ku.dk  Thu May 13 03:02:40 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 May 2004 03:02:40 +0200
Subject: [R] Fitting data from a spectrophotometer.
In-Reply-To: <loom.20040513T014106-923@post.gmane.org>
References: <76F96CFE2AA2114C886B028A065A7FC402074E5A@exdkba020.novo.dk>
	<loom.20040513T014106-923@post.gmane.org>
Message-ID: <x2sme55ebz.fsf@biostat.ku.dk>

Gabor Grothendieck <ggrothendieck at myway.com> writes:

> Perhaps you really prefer something with a continuous first derivative?
> In that case, all the continuous cumulative distribution functions have 
> a sigmoidal shape and might be suitable.  You could fit pnorm, plogis or tanh
> with suitable scaling and location parameters using nls.  An example
> of fitting a logistic is at
> 
> https://stat.ethz.ch/pipermail/r-help/2004-April/048385.html 

Actually, an exponential dampening towards an asymptote is what comes
out in simple models of saturation. If the detector is 1/3 full, you'd
expect 2/3 marginal sensitivity to changes in the input, or more
generally (y: output, x: input)

  dy/dx = 1 - y/ymax

taking reciprocals and integrating both sides wrt. y gives

 x = -ymax * log(1-y/ymax) + C

and C has to be zero if you want a curve through the origin so you
wind up with

 y = ymax*(1-exp(-x/ymax))


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From dmurdoch at pair.com  Thu May 13 03:30:10 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 12 May 2004 21:30:10 -0400
Subject: [R] Change default values of a function
In-Reply-To: <LGECJJCANFBOOHCMGPJEGEOMDCAA.Jesus.Frias@dit.ie>
References: <LGECJJCANFBOOHCMGPJEGEOMDCAA.Jesus.Frias@dit.ie>
Message-ID: <d2b5a0l3he0gn4brq7cgp5lcsr1mq81d6n@4ax.com>

On Wed, 12 May 2004 20:13:09 +0100, Jesus Frias <Jesus.Frias at dit.ie>
wrote:

>Dear R-helpers,
>	I would like to change the default value of a functions that is call by a
>package. The function deparse() is called by a set of functions from a
>library and because I don't think is appropriate to change the library, I am
>trying to change the default value in deparse().
>
>	At the moment the only solution I have come across is to place a function
>in my working environment like this,
>
>deparse <- function(expr,width.cutoff=400,backtick=mode(expr) %in%
>c("call","expression","("),...) deparse(expr,width.cutoff=400,backtick,...)
>
>	I only want to change the width.cutoff of the function and I wonder of
>there is any more elegant way to do it.

That looks like an infinite recursion; I assume you meant 

 deparse <- function(expr,width.cutoff=400,backtick=mode(expr) %in%
c("call","expression","("),...) {
	  base::deparse(expr,width.cutoff=400,backtick,...)
 }

I think this is unlikely to work due to namespaces.  A package with a
namespace will certainly find the base deparse() function rather than
yours. (I forget the search order for packages without namespaces.)

A better strategy is to modify the function that you call yourself,
i.e. the function in the package that calls deparse().  If you don't
call that one directly, you may need to make extensive changes to the
package:  and it might be a good idea to explain to the package author
why width flexibility is useful to you, and then they'll incorporate
the patch you supply into the main distribution of the package.

Duncan Murdoch



From ggrothendieck at myway.com  Thu May 13 03:41:42 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 13 May 2004 01:41:42 +0000 (UTC)
Subject: [R] xtable without rownames
References: <000901c43882$c1c147f0$0c00a8c0@rodan>
Message-ID: <loom.20040513T033101-607@post.gmane.org>

Don't know about xtable but here is an alternative:

require(Hmisc)
data(iris)
iris4 <- iris[1:4,]  # first 4 rows of iris as test
latex(iris4,file="") # with row names
attr(iris4,"row.names") <- NULL
latex(iris4,file="") # without row names

Jeff D. Hamann <jeff.hamann <at> forestinformatics.com> writes:

: 
: When I tried to read all the entries (after searching the FAQ) for "row
: names xtable", I get
: 
: 
: START-INFO-DIR-ENTRY * R FAQ: (R-FAQ). The R statistical system ...
: ... xtable* Export data to LaTeX and HTML tables. ... For dropping the row
: names of a matrix
: `x', it may be easier to use `rownames(x) <- NULL', similarly for column ...
: cvs.r-project.org/cgi-bin/viewcvs.cgi/R/FAQ?rev=1.301 - 101k - Supplemental
: Result - Cached - Similar pages
: I wasn't able to follow the link. I'd like to use xtable to generate latex
: tables for using with Sweave and can't figure out how to not include the row
: names. When I attempt to NULL out the row names using,
: 
: but cannot follow the links. Browser tells me the page is unavailable. When
: I attempt to blank out the row names using,
: 
: rownames(summary.table) <- NULL
: 
: I get the following error
: 
: > rownames(rta) <- NULL
: Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
:  invalid dimnames given for data frame
: >
: 
: the resulting (incorrect) table appears as,
: 
: > xtable( rta )
: % latex table generated in R 1.9.0 by xtable 1.2-2 package
: % Wed May 12 17:38:21 2004
: \begin{table}[ht]
: \begin{center}
: \begin{tabular}{rlr}
: \hline
:  & site.index & acres \\
: \hline
: 1 &  80 & 20.90 \\
: 2 &  90 & 64.42 \\
: ...blah, blah, blah...
: 8 & 150 & 53.32 \\
: 9 & 170 & 0.69 \\
: \hline
: \end{tabular}
: \end{center}
: \end{table}
: >
: 
: with the rownames. How do I get them out?
: 
: I'm stuck. Help.
: 
: Jeff.
: 
: ---
: Jeff D. Hamann
: Forest Informatics, Inc.
: PO Box 1421
: Corvallis, Oregon USA 97339-1421
: 541-754-1428
: jeff.hamann <at> forestinformatics.com
: www.forestinformatics.com
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From ligges at statistik.uni-dortmund.de  Thu May 13 08:52:41 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 May 2004 08:52:41 +0200
Subject: [R] Formula of power.t.test
In-Reply-To: <1084397620.40a29834587e9@webmail.stanford.edu>
References: <1084397620.40a29834587e9@webmail.stanford.edu>
Message-ID: <40A31B39.5010404@statistik.uni-dortmund.de>

Xiaorong Chen wrote:

> Dear Sir or Madam,
> 
> What is the formula for power.t.test(delta=delta, sd=segma, sig.level=0.05, 
> power=0.8, type="one.sample", alternative="one.sided")$n?

See the code of power.t.test by just typing the name of that function 
into the console:

   power.t.test

and you'll easily see that the code collapses in your case to:

   tsample <- 1
   tside <- 1
   p.body <- quote({
     nu <- (n - 1) * tsample
     pt(qt(sig.level/tside, nu, lower = FALSE),
       nu, ncp = sqrt(n/tsample) * delta/sd, lower = FALSE)
   })
   n <- uniroot(function(n) eval(p.body) - power, c(2, 1e+07))$root


Uwe Ligges


> Thank you very much for the help!
> 
> Best,
> 
> Xiaorong
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From pauljohn at ku.edu  Thu May 13 09:10:35 2004
From: pauljohn at ku.edu (Paul Johnson)
Date: Thu, 13 May 2004 02:10:35 -0500
Subject: [R] Explaining Survival difference between Stata and R
In-Reply-To: <20040512065415.GA20792@stat.umu.se>
References: <40A01772.9020304@ku.edu>
	<Pine.A41.4.58.0405110707100.34626@homer37.u.washington.edu>
	<20040512065415.GA20792@stat.umu.se>
Message-ID: <40A31F6B.8050102@ku.edu>

Dear Goran (and others)

I did not know about the "eha" package, but reading the docs, I see many 
things I've been looking for, including the parametric hazard model with 
Weibull baseline.  Thanks for the tip, and the package.

I still don't quite understand your point about the reason that coxph 
crashes.  Why does the difference of scale between the variables cause 
trouble?  I understand that a redundant set of variables would cause 
singularity, but do not see why differing scales for variables would 
cause that.  Does the explanation lie in the optimization algorithm 
itself?  I'll read the eha package coxreg source code. I bet that will 
show me what's going on in your fix, anyway.

Still, I wish coxph just handled all that stuff.

Just for fun, here are the Stata results for the same small model that 
you report.  If I ask stata to use the efron method of breaking ties, 
then the results do  almost exactly match what you found.

stset yrs2, failure (ratify)
stcox haz_wst  pol_free  , robust nohr efron

Iteration 0:   log pseudo-likelihood = -45.380139
Iteration 1:   log pseudo-likelihood =  -45.00981
Iteration 2:   log pseudo-likelihood = -45.001196
Iteration 3:   log pseudo-likelihood = -45.001193
Refining estimates:
Iteration 0:   log pseudo-likelihood = -45.001193

Cox regression -- Efron method for ties

No. of subjects       =           21               Number of obs   = 
     21
No. of failures       =           21
Time at risk          =           78
                                                    Wald chi2(2)    = 
    1.09
Log pseudo-likelihood =   -45.001193               Prob > chi2     = 
0.5785

------------------------------------------------------------------------------
              |               Robust
           _t |      Coef.   Std. Err.      z    P>|z|     [95% Conf. 
Interval]
-------------+----------------------------------------------------------------
      haz_wst |   8.48e-08   8.63e-08     0.98   0.326    -8.43e-08 
2.54e-07
     pol_free |   .0089626   .1047656     0.09   0.932    -.1963741 
.2142994
------------------------------------------------------------------------------



G??ran Brostr??m wrote:

> Paul and Thomas,
> 
> 'coxph' or the data (I got it from Paul) indeed has a problem:
> ------------------------------------------------------------
> Call:
> coxph(formula = Surv(yrs2, ratify) ~ haz.wst + pol.free, data = dat)
> 
> 
>              coef exp(coef) se(coef)     z    p
> haz.wst  8.53e-08         1 9.47e-08 0.901 0.37
> pol.free       NA        NA 0.00e+00    NA   NA
> 
> Likelihood ratio test=0.76  on 1 df, p=0.385  n= 21 
> Warning message: 
> X matrix deemed to be singular; variable 2 in: 
> coxph(Surv(yrs2, ratify) ~ haz.wst + pol.free, data = dat) 
> ---------------------------------------------------------------
> 
> Is it the data? Let's try 'coxreg' (eha):
> ---------------------------------------------------------------
> Call:
> coxreg(formula = Surv(yrs2, ratify) ~ haz.wst + pol.free, data = dat)
> 
> Covariate           Mean       Coef        RR       Wald p
> haz.wst           2054901     0.000     1.000        0.372 
> pol.free            2.090     0.009     1.009        0.958 
> 
> Events                    21 
> Total time at risk            78 
> Max. log. likelihood      -45.001 
> LR test statistic         0.76 
> Degrees of freedom        2 
> Overall p-value           0.684583
> ----------------------------------------------------------------
> 
> This worked just fine (Paul, same results as in Stata?). But, we 
> seem to have a scaling problem; lok at the means of the covariates!
> Some rescaling gives:
> ----------------------------------------------------------------
> Call:
> coxph(formula = Surv(yrs2, ratify) ~ I(haz.wst * 1e-06) + pol.free, 
>     data = dat)
> 
> 
>                       coef exp(coef) se(coef)      z    p
> I(haz.wst * 1e-06) 0.08479      1.09    0.095 0.8920 0.37
> pol.free           0.00896      1.01    0.170 0.0526 0.96
> 
> Likelihood ratio test=0.76  on 2 df, p=0.685  n= 21 
> ----------------------------------------------------------------
> and now 'coxph' gets the same results as 'coxreg'. I don't know about coxph
> for sure, but I do know that coxreg centers all covariates before the NR
> procedure starts. Maybe we also should rescale to unit variance? And of
> course scale back the coefficients and se:s at the end? 
> 
> BTW, Paul's data is heavily tied. Could be an idea to use a discrete time
> version of the PH model: you can do that with 'mlreg' (eha): 
> --------------------------------------------------------------- 
> Call:
> mlreg(formula = Surv(yrs2, ratify) ~ I(haz.wst * 1e-06) + pol.free, 
>     data = dat)
> 
> Covariate           Mean       Coef        RR     Wald p
> I(haz.wst * 1e-06)  2.055     0.097     1.102      0.320 
> pol.free            2.090     0.003     1.003      0.985 
> 
> Events                    21 
> Total time at risk            78 
> Max. log. likelihood      -36.324 
> LR test statistic         0.93 
> Degrees of freedom        2 
> Overall p-value           0.627056
> ----------------------------------------------------------------
> Doesn't make much of a difference, though. Efron's method is quite
> robust. (You might check if there are any differences with 'breslow')
> 
> Best,
> 
> G??ran
> 
> [...]


-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From gb at stat.umu.se  Thu May 13 09:25:23 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 13 May 2004 09:25:23 +0200
Subject: [R] Explaining Survival difference between Stata and R
In-Reply-To: <40A31F6B.8050102@ku.edu>
References: <40A01772.9020304@ku.edu>
	<Pine.A41.4.58.0405110707100.34626@homer37.u.washington.edu>
	<20040512065415.GA20792@stat.umu.se> <40A31F6B.8050102@ku.edu>
Message-ID: <20040513072523.GA31329@stat.umu.se>

On Thu, May 13, 2004 at 02:10:35AM -0500, Paul Johnson wrote:
> Dear Goran (and others)
> 
> I did not know about the "eha" package, but reading the docs, I see many 
> things I've been looking for, including the parametric hazard model with 
> Weibull baseline.  Thanks for the tip, and the package.

You can find that in 'survival' too. See ?survreg. Watch up for
non-standard parametrization, though.

> I still don't quite understand your point about the reason that coxph 
> crashes.  Why does the difference of scale between the variables cause 
> trouble?  I understand that a redundant set of variables would cause 
> singularity, but do not see why differing scales for variables would 
> cause that.  Does the explanation lie in the optimization algorithm 
> itself?  I'll read the eha package coxreg source code. I bet that will 
> show me what's going on in your fix, anyway.

Nothing special is going on there. I use only standard linpack routines
(found in R) for solving linear equations, and matrix inversion at the
end. I think 'coxph' has its own optimizing routines.

Peter D. explained why scaling can be a problem.

G??ran
[...]
-- 
 G??ran Brostr??m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume?? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume??, Sweden             e-mail: gb at stat.umu.se



From smyth at wehi.edu.au  Thu May 13 09:56:45 2004
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Thu, 13 May 2004 17:56:45 +1000
Subject: [R] using trace() on S4 coerce method
Message-ID: <6.0.1.1.1.20040513174153.02a431d0@imaphost.wehi.edu.au>

I'm trying to use trace() on an S4 coerce method, but get the error

    Error in bindingIsLocked(what, whereM) : no binding for "coerce"

What am I doing wrong? Example code follows.

(I've googled the R mailing lists for "trace coerce" and "trace 
bindingisLocked" without finding anything relevant. Perhaps I should 
re-define the method in terms of an ordinary function and trace the later 
function, as suggested by John Chambers to another user:
https://stat.ethz.ch/pipermail/r-devel/2003-August/027249.html
But it would be nice to be able to trace the method directly.)

Thanks
Gordon

 > setClass("MyClass1",representation(a="numeric"))
[1] "MyClass1"
 > setClass("MyClass2",representation(a="character"))
[1] "MyClass2"
 > setAs("MyClass1","MyClass2",function(from,to) 
new(to,a=as.character(from at a)))
 > x <- new("MyClass1",a=20)
 > as(x,"MyClass2")
An object of class "MyClass2"
Slot "a":
[1] "20"

 > tracingState(on=TRUE)
[1] FALSE
 > getMethod("coerce",c("MyClass1","MyClass2"))
Method Definition (Class "MethodDefinition"):

function (from, to = "MyClass2", strict = TRUE)
new(to, a = as.character(from at a))

Signatures:
         from       to
target  "MyClass1" "MyClass2"
defined "MyClass1" "MyClass2"
 > trace("coerce",browser,signature=c("MyClass1","MyClass2"))
Error in bindingIsLocked(what, whereM) : no binding for "coerce"

 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.0
year     2004
month    04
day      12
language R



From Mark.Bravington at csiro.au  Thu May 13 10:08:01 2004
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Thu, 13 May 2004 18:08:01 +1000
Subject: [R] GLMMs & LMEs: dispersion parameters, fixed variances,
	design matrices
Message-ID: <C4178DC99E08604EA5E2BDB989F0938002618D06@extas2-hba.tas.csiro.au>

Three related questions on LMEs and GLMMs in R:

(1) Is there a way to fix the dispersion parameter (at 1) in either glmmPQL (MASS) or GLMM (lme4)? 

Note: lme does not let you fix any variances in advance (presumably because it wants to "profile out" an overall sigma^2 parameter) and glmmPQL repeatedly calls lme, so I couldn't see how glmmPQL would be able to fix the dispersion parameter. The section on glmmPQL in V&R4 says that the default is to estimate the dispersion parameter, but didn't seem to say how to change the default.

(2) Is there a way to tell lme (either in nlme or lme4) to just use a specified design matrix Z for the random effects, rather than constructing one itself from factors? Sometimes I would really like to use my own funny-looking Z matrix (e.g. with non-integer coefficients), and even with contrasts() I haven't managed to do this.

(3) Are there any plans to allow some variances to be fixed in lme? It would be useful e.g. for meta-analysis (and indeed for glmms with fixed dispersion).

Note: it has occurred to me that lme can possibly be tricked into fixing the measurement error variance (i.e. var[y|b] where b is the random effects and y the observed data) at some specified value e.g. 1 by adding two pseudo-observations at +/-1, with all zeros in the corresponding rows of the X and Z matrices, and with huge weights. Then sum( w*(y-E[y|b,params])^2) / sum(w) will be approximately 1, and any attempt to change the estimate of sigma^2 away from 1 will be "deterred" by a large penalty. Similar tricks might be possible for fixing other variances. However this approach is not nice and perhaps might cause computational problems-- and I haven't actually tried it yet.

Thanks for any help

Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington at csiro.au



From ripley at stats.ox.ac.uk  Thu May 13 10:32:48 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 May 2004 09:32:48 +0100 (BST)
Subject: [R] GLMMs & LMEs: dispersion parameters, fixed variances, design
	matrices
In-Reply-To: <C4178DC99E08604EA5E2BDB989F0938002618D06@extas2-hba.tas.csiro.au>
Message-ID: <Pine.LNX.4.44.0405130928320.1734-100000@gannet.stats>

On Thu, 13 May 2004 Mark.Bravington at csiro.au wrote:

> Three related questions on LMEs and GLMMs in R:
> 
> (1) Is there a way to fix the dispersion parameter (at 1) in either
> glmmPQL (MASS) or GLMM (lme4)?

not glmmPQL in R (can be done in S-PLUS).

> Note: lme does not let you fix any variances in advance (presumably
> because it wants to "profile out" an overall sigma^2 parameter) and
> glmmPQL repeatedly calls lme, so I couldn't see how glmmPQL would be
> able to fix the dispersion parameter. The section on glmmPQL in V&R4
> says that the default is to estimate the dispersion parameter, but
> didn't seem to say how to change the default.

It's done in the same way as for lme via the control parameter (that is, 
not at all in R).

> (2) Is there a way to tell lme (either in nlme or lme4) to just use a
> specified design matrix Z for the random effects, rather than
> constructing one itself from factors? Sometimes I would really like to
> use my own funny-looking Z matrix (e.g. with non-integer coefficients),
> and even with contrasts() I haven't managed to do this.
> 
> (3) Are there any plans to allow some variances to be fixed in lme? It
> would be useful e.g. for meta-analysis (and indeed for glmms with fixed
> dispersion).

It has been possible for a while in S-PLUS.

> Note: it has occurred to me that lme can possibly be tricked into fixing
> the measurement error variance (i.e. var[y|b] where b is the random
> effects and y the observed data) at some specified value e.g. 1 by
> adding two pseudo-observations at +/-1, with all zeros in the
> corresponding rows of the X and Z matrices, and with huge weights. Then
> sum( w*(y-E[y|b,params])^2) / sum(w) will be approximately 1, and any
> attempt to change the estimate of sigma^2 away from 1 will be "deterred"
> by a large penalty. Similar tricks might be possible for fixing other
> variances. However this approach is not nice and perhaps might cause
> computational problems-- and I haven't actually tried it yet.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From joehl at gmx.de  Thu May 13 11:06:08 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Thu, 13 May 2004 11:06:08 +0200 (MEST)
Subject: [R] please help with estimation of true correlations and
	reliabilities
Message-ID: <2326.1084439168@www8.gmx.net>


Can someone point me to literature and/or R software to solve the following
problem:

Assume n true scores t measured as x with uncorrelated errors e , i.e. 
x = t + e 
and assume each true score to a have a certain amount of correlation with
some of the other true scores.

The correlation matrix cx of x will have its off-diagonal entries reduced by
measurement error compared to the true correlation matrix ct of t, however
the diagonal entries remain without attenuation. Consequently the
correlation matrix of observed variables has different things on- and
off-diagonal. 

I would like to estimate 
1) the true correlation matrix ct
2) the measurement reliabilities rxx, i.e. the correlation of a score with
itself attenuated by its measurement error (as if we had two measurements of
the same score).
but I don't have predefined asumptions about structure in the variable set
as I guess would be needed for SEM.

Is R software available to do this?

Best regards


Jens Oehlschl??gel

--



From simon at stats.gla.ac.uk  Thu May 13 11:53:32 2004
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Thu, 13 May 2004 10:53:32 +0100 (BST)
Subject: [R] GLMMs & LMEs: dispersion parameters, fixed variances, design
	matrices
In-Reply-To: <C4178DC99E08604EA5E2BDB989F0938002618D06@extas2-hba.tas.csiro.au>
References: <C4178DC99E08604EA5E2BDB989F0938002618D06@extas2-hba.tas.csiro.au>
Message-ID: <Pine.SOL.4.58.0405131043560.26557@moon.stats.gla.ac.uk>

Hi Mark,

> (2) Is there a way to tell lme (either in nlme or lme4) to just use a
> specified design matrix Z for the random effects, rather than
> constructing one itself from factors? Sometimes I would really like to
> use my own funny-looking Z matrix (e.g. with non-integer coefficients),
> and even with contrasts() I haven't managed to do this.

Here's a simple example showing a `standard' call to lme, and a
less standard one doing the same thing with a specified Z....

library(nlme)
data(Rail)
lme(travel~1,Rail,~1|Rail) # simple r.e. model example

## now repeat fit with home-made Z...
Rail$all<-factor(rep(1,18)) # all one group
## create a simple Z ...
Rail$Z<-model.matrix(~factor(Rail$Rail,ordered=FALSE)-1)
## use pdIdent to force r.e.s to be independent ...
lme(travel~1,Rail,list(all=pdIdent(~Z)))


best,
Simon



From i.visser at uva.nl  Thu May 13 12:12:23 2004
From: i.visser at uva.nl (Ingmar Visser)
Date: Thu, 13 May 2004 12:12:23 +0200
Subject: [R] bus error macosx/off-topic
In-Reply-To: <Pine.LNX.4.44.0405121350080.16719-100000@gannet.stats>
Message-ID: <BCC916A7.2732%i.visser@uva.nl>

Dear Prof Ripley,
Thanks for your answer.

On 5/12/04 2:52 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

> These normally occur (at that point) from having written off one end of an
> array. (If you are using .C/.Fortran, they try to copy back the
> arguments.) Compiling with bounds checking turned on can help, at least
> with Fortran.

Can I invoke compile options if/when I use R cmd install etc. to install
packages? 

The situation is this: I pass arguments from R to C, then most of these are
passed on to a Fortran routine, and then the same way back.

I suppose that at the end of the C-routine the arguments are copied back to
R. Where/who or what decides what the length of a vector is that is passed
back to R?

Best, ingmar



From ripley at stats.ox.ac.uk  Thu May 13 12:46:25 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 May 2004 11:46:25 +0100 (BST)
Subject: [R] bus error macosx/off-topic
In-Reply-To: <BCC916A7.2732%i.visser@uva.nl>
Message-ID: <Pine.LNX.4.44.0405131145070.3244-100000@gannet.stats>

On Thu, 13 May 2004, Ingmar Visser wrote:

> Dear Prof Ripley,
> Thanks for your answer.
> 
> On 5/12/04 2:52 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
> 
> > These normally occur (at that point) from having written off one end of an
> > array. (If you are using .C/.Fortran, they try to copy back the
> > arguments.) Compiling with bounds checking turned on can help, at least
> > with Fortran.
> 
> Can I invoke compile options if/when I use R cmd install etc. to install
> packages? 

By using a Makevars file: see Writing R Extensions.

> The situation is this: I pass arguments from R to C, then most of these are
> passed on to a Fortran routine, and then the same way back.
> 
> I suppose that at the end of the C-routine the arguments are copied back to
> R. Where/who or what decides what the length of a vector is that is passed
> back to R?

You do. It's the same length as you passed in.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ciradhwg at mweb.co.zw  Thu May 13 13:49:28 2004
From: ciradhwg at mweb.co.zw (Hwange Project)
Date: Thu, 13 May 2004 13:49:28 +0200
Subject: [R] Bootstrapping kendall cor
Message-ID: <IEEFKHGFNDGNNFCJALMFGEGDCEAA.ciradhwg@mweb.co.zw>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040513/c10f43a9/attachment.pl

From jfox at mcmaster.ca  Thu May 13 14:24:25 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 13 May 2004 08:24:25 -0400
Subject: [R] please help with estimation of true correlations
	andreliabilities
In-Reply-To: <2326.1084439168@www8.gmx.net>
Message-ID: <20040513122424.VGCG11783.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Jens,

It sounds as if you're postulating a single-factor model underlying the x's
(which is an assumption about the structure of the variables). If that's the
case, then you could either use the factanal function in the stats package
or the sem function in the sem package to estimate the model. The former
would be simpler. 

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jens 
> Oehlschl??gel
> Sent: Thursday, May 13, 2004 4:06 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] please help with estimation of true correlations 
> andreliabilities
> 
> 
> Can someone point me to literature and/or R software to solve 
> the following
> problem:
> 
> Assume n true scores t measured as x with uncorrelated errors 
> e , i.e. 
> x = t + e
> and assume each true score to a have a certain amount of 
> correlation with some of the other true scores.
> 
> The correlation matrix cx of x will have its off-diagonal 
> entries reduced by measurement error compared to the true 
> correlation matrix ct of t, however the diagonal entries 
> remain without attenuation. Consequently the correlation 
> matrix of observed variables has different things on- and 
> off-diagonal. 
> 
> I would like to estimate
> 1) the true correlation matrix ct
> 2) the measurement reliabilities rxx, i.e. the correlation of 
> a score with itself attenuated by its measurement error (as 
> if we had two measurements of the same score).
> but I don't have predefined asumptions about structure in the 
> variable set as I guess would be needed for SEM.
> 
> Is R software available to do this?
> 
> Best regards
> 
> 
> Jens Oehlschl??gel
> 
> --
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From chad_yang at pchome.com.tw  Thu May 13 20:33:46 2004
From: chad_yang at pchome.com.tw (chad_yang@pchome.com.tw)
Date: Thu, 13 May 2004 20:33:46
Subject: [R] [Help! feature selection]
Message-ID: <20040513123500.CA53C5E6871@msx.pchome.com.tw>

Hi, 
   I would like to find some methods about feature selection, but I 
only know the package "randomForest" after searching for a while.  
Could you recommend some other packages of feature selection?
Thank you very much.

Sincerely yours,
Chad Yang.
==========================================================



From ripley at stats.ox.ac.uk  Thu May 13 14:48:22 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 May 2004 13:48:22 +0100 (BST)
Subject: [R] Bootstrapping kendall cor
In-Reply-To: <IEEFKHGFNDGNNFCJALMFGEGDCEAA.ciradhwg@mweb.co.zw>
Message-ID: <Pine.LNX.4.44.0405131345490.16197-100000@gannet.stats>

Your problem is that some bootstrap samples have no variation in x at all.  
How can you expect a sensible answer from such a sample?

On Thu, 13 May 2004, Hwange Project wrote:

> I'm fighting with the following problem :
> I want to do bootstrapping on a Kendall correlation with the following code

Using package boot, uncredited!

> > cor.function <- function(data,i) cor(data[i, 1], data[i,
> 2],method="kendall")
> > boot.ci <- boot.ci(boot.cor <- boot(cbind(x,y),cor.function,
>      R=1000),conf=c(0.95,0.99))
> 
> However, I've got problems because I've got ties in my x variables :
> for example, it does not work with :
> 
> x <-
> c(8.67,3.67,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,6.80,0.00,0.00,3.96)
> y <- c(329,264,274,339,302,334,334,312,355,327,287,319,361,355)
> cor.function <- function(data,i) cor(data[i, 1], data[i,
> 2],method="kendall")
> boot.ci <- boot.ci(boot.cor <- boot(cbind(x,y),cor.function,
>      R=1000),conf=c(0.95,0.99))
> 
> I would appreciate any advice, even of changing from kendall to something
> else, knowing that my x variables have a lot of ties and is far from
> normally distributed.

Given that you haven't told us your objective, we cannot help you choose 
anything better.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From GPetris at uark.edu  Thu May 13 15:09:35 2004
From: GPetris at uark.edu (Giovanni Petris)
Date: Thu, 13 May 2004 08:09:35 -0500 (CDT)
Subject: [R] Setting max values for rpois
In-Reply-To: <200405122131.i4CLVnES006435@definetti.uark.edu> (message from
	Giovanni Petris on Wed, 12 May 2004 16:31:49 -0500 (CDT))
References: <5F883C17941B9F4E80E5FA8C9F1C5E0EBD5B75@jhms08.phibred.com>
	<5F883C17941B9F4E80E5FA8C9F1C5E0EBD5B75@jhms08.phibred.com>
	<5.2.1.1.0.20040512160017.00b045d0@mail.uark.edu>
	<200405122131.i4CLVnES006435@definetti.uark.edu>
Message-ID: <200405131309.i4DD9ZoN006998@definetti.uark.edu>


Bret,

At a second thought, probably what you want is the following:

> sum(apply(outer(0:3,l*recruit.f,dpois),2,function(x) sample(0:3,1,prob=x))) 

In this case the distribution of offsprings for each female is Poisson,
conditional on # of offsprings <= 3. 

Giovanni

> Date: Wed, 12 May 2004 16:31:49 -0500 (CDT)
> From: Giovanni Petris <GPetris at uark.edu>
> Sender: r-help-bounces at stat.math.ethz.ch
> Cc: r-help at stat.math.ethz.ch
> Precedence: list
> 
> 
> Bret,
> 
> the following should do:
> 
> x <- sum(pmin(rpois(recruit.f, l),3))
> 
> Giovanni
> 
> > Date: Wed, 12 May 2004 16:11:08 -0500
> > From: Bret Collier <bacolli at uark.edu>
> > Sender: r-help-bounces at stat.math.ethz.ch
> > Precedence: list
> > 
> > R-users,
> >          I am simulating a birth process for 4 classes of individuals with 
> > l[i] being the average No. fetuses per individual.  However, I need to 
> > bound the resulting values for each generated rpois to be <=3 (no 
> > individual can have > 3 offspring).  I have not been able to figure out how 
> > to incorporate this into the below example.  Any suggestions on integrating 
> > would be appreciated.
> > 
> > 
> > recruit.f <- c(12, 12, 25, 51)  #No. females in each age class
> > l <- c(.05, 1.22, 1.6, 1.8)  #mean No. fetuses for each age class
> > x <- sapply(lapply(1:4, function(i) rpois(recruit.f[i], l[i])), sum)
> > 
> > TIA,
> > 
> > Bret A. Collier
> > Arkansas Cooperative Fish and Wildlife Research Unit
> > University of Arkansas
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> -- 
> 
>  __________________________________________________
> [                                                  ]
> [ Giovanni Petris                 GPetris at uark.edu ]
> [ Department of Mathematical Sciences              ]
> [ University of Arkansas - Fayetteville, AR 72701  ]
> [ Ph: (479) 575-6324, 575-8630 (fax)               ]
> [ http://definetti.uark.edu/~gpetris/              ]
> [__________________________________________________]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From LUCKE at uthscsa.edu  Thu May 13 15:19:29 2004
From: LUCKE at uthscsa.edu (Lucke, Joseph F)
Date: Thu, 13 May 2004 08:19:29 -0500
Subject: [R] please help with estimation of true correlations and	reli
	abilities
Message-ID: <C4A57662D47C7B44B781D39E4C8F06940E31EE@SAIGA.win.uthscsa.edu>

Jens
I'm not sure what you intend by "predefined assumptions".

1. If you merely want to conduct an exploratory rather than confirmatory
analysis for the relevant paths, there are ways within SEM to do this. (In
this case you could use John Fox's SEM package).
2. If you do not wish to assume multivariate normality, then you may use a
variety of alternative (to maximum likelihood) estimation algorithms
available in most SEM programs.
3. If you do not wish to assume either the outcome variable or the latent
variable is continuous, there are SEM programs for this (Mplus being the
most prominent.)
4. If you do not wish to assume the true score is a linear function (or
generalized linear function for categorical variables) of the attribute
being measured, then you have a more difficult problem.

If presume you are familiar with SEMnet at
http://www.gsu.edu/~mkteer/semnet.html.
Joe

-----Original Message-----
From: "Jens Oehlschl??gel" [mailto:joehl at gmx.de] 
Sent: Thursday, May 13, 2004 4:06 AM
To: r-help at stat.math.ethz.ch
Subject: [R] please help with estimation of true correlations and
reliabilities



Can someone point me to literature and/or R software to solve the following
problem:

Assume n true scores t measured as x with uncorrelated errors e , i.e. 
x = t + e 
and assume each true score to a have a certain amount of correlation with
some of the other true scores.

The correlation matrix cx of x will have its off-diagonal entries reduced by
measurement error compared to the true correlation matrix ct of t, however
the diagonal entries remain without attenuation. Consequently the
correlation matrix of observed variables has different things on- and
off-diagonal. 

I would like to estimate 
1) the true correlation matrix ct
2) the measurement reliabilities rxx, i.e. the correlation of a score with
itself attenuated by its measurement error (as if we had two measurements of
the same score). but I don't have predefined asumptions about structure in
the variable set as I guess would be needed for SEM.

Is R software available to do this?

Best regards


Jens Oehlschl??gel

--

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From edgar at cs.uprm.edu  Thu May 13 16:25:02 2004
From: edgar at cs.uprm.edu (Edgar Acuna)
Date: Thu, 13 May 2004 10:25:02 -0400 (EDT)
Subject: [R] [Help! feature selection]
In-Reply-To: <20040513123500.CA53C5E6871@msx.pchome.com.tw>
Message-ID: <Pine.GSO.4.33.0405131022450.12196-100000@cs.uprm.edu>

Hi,
Feature selection in which context?. regression,
supervised classification, clustering?

Edgar Acuna
UPRM

On Thu, 13 May 2004 chad_yang at pchome.com.tw wrote:

> Hi,
>    I would like to find some methods about feature selection, but I
> only know the package "randomForest" after searching for a while.
> Could you recommend some other packages of feature selection?
> Thank you very much.
>
> Sincerely yours,
> Chad Yang.
> ==========================================================



From deepayan at stat.wisc.edu  Thu May 13 15:53:11 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 13 May 2004 08:53:11 -0500
Subject: [R] trellis plot problem with R-1.9.0-1
In-Reply-To: <200405101246.37290.stephan.moratti@uni-konstanz.de>
References: <200405101246.37290.stephan.moratti@uni-konstanz.de>
Message-ID: <200405130853.11779.deepayan@stat.wisc.edu>

On Monday 10 May 2004 05:46, Stephan Moratti wrote:
> I tried following commands:
>
> amp~time|subject/trial   #this was the grouping structure of the data
>
>
> plot(dip,inner=~condition,layout=c(2,2))
>
> after the plot command I obtained this error message:
>
> Error in if(!any(cond.max.level - cond.current.level <0)&&(row-1)* :
> missing value where TRUE/FALSE needed
>
> This error only occured in compination with "layout". It was no
> problem to plot all subjects on one page. Further, this error did not
> occur using older version of R (1.8 or 1.7). Did somebody encounter
> similar problems ?

Thanks for the report. This turns out to be a bug in the calculation of 
'skip', caused by my using the wrong variable name (this was introduced 
fairly recently when the behaviour of skip changed for multipage 
displays). Anyway, I'll post an updated version, meanwhile, a 
workaround is to specify skip explicitly, e.g., 

plot(dip,inner=~condition,layout=c(2,2), skip = rep(FALSE, 76))

Deepayan



From Lorenz.Gygax at fat.admin.ch  Thu May 13 15:56:08 2004
From: Lorenz.Gygax at fat.admin.ch (Lorenz.Gygax@fat.admin.ch)
Date: Thu, 13 May 2004 15:56:08 +0200
Subject: [R] glmmPQL - predict (..., type= 'response')?
Message-ID: <BF74FADD4B44554CA7E53D0B5242CD6A018DAF59@evd-s7014.evd.admin.ch>


Dear R users,

Is there something like predict (..., type= 'response') for glmmPQL objects
or how would I get fitted values on the scale of the response variable for
the binomial and the poisson family?

Any pointers are appreciated.

Thanks, Lorenz
- 
Lorenz Gygax, Dr. sc. nat.
Tel: +41 (0)52 368 33 84 / lorenz.gygax at fat.admin.ch      

Tag der offenen T??r, 11./12. Juni 2004: http://www.fat.ch/2004

Center for proper housing of ruminants and pigs
Swiss Veterinary Office
agroscope FAT T??nikon, CH-8356 Ettenhausen / Switzerland
Fax : +41 (0)52 365 11 90 / Tel: +41 (0)52 368 31 31



From bates at stat.wisc.edu  Thu May 13 15:57:49 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 13 May 2004 08:57:49 -0500
Subject: [R] question about dyn.load()
In-Reply-To: <1084409306.40a2c5da38db9@mailhost.cs.concordia.ca>
References: <1084409306.40a2c5da38db9@mailhost.cs.concordia.ca>
Message-ID: <6rbrksmntu.fsf@bates4.stat.wisc.edu>

xt_wang at cs.concordia.ca writes:

> Hello, everybody,
> 
> I met a big problem. What I want is to use c code in R. I have load
> a test code conv.c in R and run it successfully. However, in my real
> code, I use matlab c library (Matrix Inverse function). After I use
> command R CMD SHLIB to share library, I can not use dyn.load to load
> the object in R.  undefined symbol: mclCleanupProtectedItems always
> be mentioned.
> 
> My question is that whether I can compile, load and use a c code in
> R which includes other library. If I can, How can I do? Could you
> help me find out where is the error during the whole operation? If I
> can not load a c code with other library in R, can I load a c code
> with R library in R ( which include matrix inverse function)? If so,
> where can I find the R library with matrix inverse function that has
> a c interface?
> 
> I will appreciate very much if somebody can help me resolve this problem.
> 
> Thanks in advance!
> 
> Yours,
> 
> Maggie

To begin with, you probably don't need a matrix inverse.  Although
formulae are frequently written in terms of a matrix inverse they
should be evaluated using a decomposition, such as the LU
decomposition or the QR decomposition, of the coefficient matrix. 

If your code does require numerical linear algebra the best approach
is to create an R package for your code and list the LAPACK and BLAS
libraries in the PACKAGE_LIBS macro definition, as described in the
manual Writing R Extensions.  Please read that manual.  I would also
recommend that you read the sections of the Lapack manual (available
online) that deal with the LU decomposition.

This may seem to be a difficult approach to something as "simple" as
creating a matrix inverse.  The reason for the complexity is because
creating a matrix inverse quickly and stably is not simple and usually
unnecessary.



From tlumley at u.washington.edu  Thu May 13 16:35:17 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 13 May 2004 07:35:17 -0700 (PDT)
Subject: [R] Explaining Survival difference between Stata and R
In-Reply-To: <40A31F6B.8050102@ku.edu>
References: <40A01772.9020304@ku.edu>
	<Pine.A41.4.58.0405110707100.34626@homer37.u.washington.edu>
	<20040512065415.GA20792@stat.umu.se> <40A31F6B.8050102@ku.edu>
Message-ID: <Pine.A41.4.58.0405130729520.104678@homer35.u.washington.edu>

On Thu, 13 May 2004, Paul Johnson wrote:

>
> I still don't quite understand your point about the reason that coxph
> crashes.  Why does the difference of scale between the variables cause
> trouble?

Because exp(beta*x) is very, very, large for many values of beta when x
is that large. If exp(beta*x) ever becomes Inf the computations will
break down.

A better approach than scaling the x would be to update the step-halving
code to handle infinities, because scaling doesn't necessarily fix the
problem (though it does here), and has possible bad effects in masking a
singular design matrix (as Peter Dalgaard pointed out).


	-thomas



From bates at stat.wisc.edu  Thu May 13 16:57:49 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 13 May 2004 09:57:49 -0500
Subject: [R] GLMMs & LMEs: dispersion parameters, fixed variances,
	design matrices
In-Reply-To: <C4178DC99E08604EA5E2BDB989F0938002618D06@extas2-hba.tas.csiro.au>
References: <C4178DC99E08604EA5E2BDB989F0938002618D06@extas2-hba.tas.csiro.au>
Message-ID: <6r3c64ml1u.fsf@bates4.stat.wisc.edu>

<Mark.Bravington at csiro.au> writes:

> Three related questions on LMEs and GLMMs in R:
> 
> (1) Is there a way to fix the dispersion parameter (at 1) in either
> glmmPQL (MASS) or GLMM (lme4)?
> 
> Note: lme does not let you  fix any variances in advance (presumably
> because it wants to "profile out"  an overall sigma^2 parameter) and
> glmmPQL repeatedly calls lme, so I couldn't see how glmmPQL would be
> able to fix the dispersion parameter. The section on glmmPQL in V&R4
> says that the  default is to estimate  the dispersion parameter, but
> didn't seem to say how to change the default.

At the core of the lme calculations is the solution of a penalized
least squares problem defined by the relative dispersion matrix of the
random effects and the model matrices for the random effects and the
fixed effects.  In versions 0.6-1 and later of the lme4 package (the
first release candidate is available from my web site
http://www.stat.wisc.edu/~bates/) the components of the log-likelihood
or the REML criterion are available as the devComp slot of the S4
object that represents the model and that is used to solve the
penalized least squares problem.  If, using these components, you can
write the log-likelihood for the model that you wish to fit then you
can give it to an optimizer such as optim or nlm to fit.

In the notation of Bates and DebRoy (2004), "Linear mixed models and
penalized least squares" (to appear in J. of Multivariate Analysis,
available in preprint form from my web site), the components are 

log(|Z'Z + \Omega|), log(|\Omega|), log(|R_{XX}|^2), and log(r_{yy}^2)

The C code that uses these to evaluate the deviance form of the
profiled log-likelihood criterion or the profiled REML criterion from
these components is in src/ssclme.c from the Matrix package.

Modifying the criteria for a fixed dispersion parameter may be trivial
or it may not.

> (3) Are there any plans to allow some variances to be fixed in lme? 
> It would be useful e.g. for meta-analysis (and indeed for glmms with
> fixed dispersion).

The method = 'Laplacian' version of the GLMM function fixes the
dispersion parameter in those families where it should be fixed.  As
we continue to develop lme4 we will provide a further enhancement
using an adaptive Gauss-Hermite evalution of the log-likelihood for
GLMMs that will also have this property.



From joehl at gmx.de  Thu May 13 17:09:14 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Thu, 13 May 2004 17:09:14 +0200 (MEST)
Subject: [R] please help with estimation of true correlations
	andreliabilities
Message-ID: <29198.1084460954@www19.gmx.net>


Dear John,
Dear Joseph,

Thank you for your quick answers and the pointer to semnet. 
I try to clarify on my assumptions:

- yes, I am willing to assume multivariate normality
- no, I don't want to assume a single factor model
- I assume there is an unknown number of factors, and I do not know which
items belong to which factors

but I still want to estimate single item reliabilities

Is this impossible?
How can one specify such unspecified model to sem?
Which (exploratory?) function would me help doing this?
Or just: what should I read?

Thanks for any help


Jens Oehlschl??gel

--



From Arne.Muller at aventis.com  Thu May 13 17:11:34 2004
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Thu, 13 May 2004 17:11:34 +0200
Subject: [R] storage of lm objects in a database
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1DC@crbsmxsusr04.pharma.aventis.com>

Hello,

I'd like to use DBI to store lm objects in a database. I've to analyze many of linear models and I cannot store them in a single R-session (not enough memory). Also it'd be nice to have them persistent.

Maybe it's possible to create a compact binary representation of the object (the kind of format created created by "save"), so that one doesn't need to write a conversion routine for these objects (or maybe there's already a conversion available for lm?). I assume that the data do not need to be analyzed with a any other software than R.

I'm happy for any suggestions and links to get some more info on this.

	kid regards,

	Arne

--
Arne Muller, Ph.D.
Toxicogenomics, Aventis Pharma
arne dot muller domain=aventis com



From ripley at stats.ox.ac.uk  Thu May 13 17:16:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 May 2004 16:16:01 +0100 (BST)
Subject: [R] storage of lm objects in a database
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1DC@crbsmxsusr04.pharma.aventis.com>
Message-ID: <Pine.LNX.4.44.0405131613260.9702-100000@gannet.stats>

On Thu, 13 May 2004 Arne.Muller at aventis.com wrote:

> I'd like to use DBI to store lm objects in a database. I've to analyze
> many of linear models and I cannot store them in a single R-session (not
> enough memory). Also it'd be nice to have them persistent.
> 
> Maybe it's possible to create a compact binary representation of the
> object (the kind of format created created by "save"), so that one
> doesn't need to write a conversion routine for these objects (or maybe
> there's already a conversion available for lm?). I assume that the data
> do not need to be analyzed with a any other software than R.

?serialize.  It's exactly the "save" format.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sdavis2 at mail.nih.gov  Thu May 13 17:22:19 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 13 May 2004 11:22:19 -0400
Subject: [R] storage of lm objects in a database
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1DC@crbsmxsusr04.pharma.aventis.com>
Message-ID: <BCC90AEB.7FD5%sdavis2@mail.nih.gov>

Arne,

There are several database access packages for R.  I use RMySQL, but there
are several others (ODBC, etc.).  However, as far as I know (and I may be
wrong), there is not a persistence API for R objects (in a relational DB
sense), but you could certainly deconstruct the objects and store their
parts for later reconstruction of the objects.  I guess another option would
be a scheme of saved results (files) indexed in some way so that you could
get the results, but I can't think of a way to make this fast.

Sean

On 5/13/04 11:11 AM, "Arne.Muller at aventis.com" <Arne.Muller at aventis.com>
wrote:

> Hello,
> 
> I'd like to use DBI to store lm objects in a database. I've to analyze many of
> linear models and I cannot store them in a single R-session (not enough
> memory). Also it'd be nice to have them persistent.
> 
> Maybe it's possible to create a compact binary representation of the object
> (the kind of format created created by "save"), so that one doesn't need to
> write a conversion routine for these objects (or maybe there's already a
> conversion available for lm?). I assume that the data do not need to be
> analyzed with a any other software than R.
> 
> I'm happy for any suggestions and links to get some more info on this.
> 
> kid regards,
> 
> Arne
> 
> --
> Arne Muller, Ph.D.
> Toxicogenomics, Aventis Pharma
> arne dot muller domain=aventis com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From s-cotter at kellogg.northwestern.edu  Thu May 13 17:59:25 2004
From: s-cotter at kellogg.northwestern.edu (s-cotter@kellogg.northwestern.edu)
Date: Thu, 13 May 2004 15:59:25 +0000
Subject: [R] using --internet2 with DCom interface
Message-ID: <200405131559.i4DFxnhH010266@merle.it.northwestern.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040513/1c1a65c9/attachment.pl

From Brian.J.GREGOR at odot.state.or.us  Thu May 13 18:13:20 2004
From: Brian.J.GREGOR at odot.state.or.us (Brian.J.GREGOR@odot.state.or.us)
Date: Thu, 13 May 2004 09:13:20 -0700
Subject: [R] xtable without rownames
Message-ID: <372EFF9FE4E42E419C978E7A305DC5FE0379AD91@exsalem5.odot.state.or.us>

You can just set the rownames to an empty character string ("") and xtable
will work fine.

> -----Original Message-----
> From: Jeff D. Hamann [mailto:jeff.hamann at forestinformatics.com]
> Sent: Wednesday, May 12, 2004 5:40 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] xtable without rownames
> 
> 
> When I tried to read all the entries (after searching the 
> FAQ) for "row
> names xtable", I get
> 
> 
> START-INFO-DIR-ENTRY * R FAQ: (R-FAQ). The R statistical system ...
> ... xtable* Export data to LaTeX and HTML tables. ... For 
> dropping the row
> names of a matrix
> `x', it may be easier to use `rownames(x) <- NULL', similarly 
> for column ...
> cvs.r-project.org/cgi-bin/viewcvs.cgi/R/FAQ?rev=1.301 - 101k 
> - Supplemental
> Result - Cached - Similar pages
> I wasn't able to follow the link. I'd like to use xtable to 
> generate latex
> tables for using with Sweave and can't figure out how to not 
> include the row
> names. When I attempt to NULL out the row names using,
> 
> but cannot follow the links. Browser tells me the page is 
> unavailable. When
> I attempt to blank out the row names using,
> 
> rownames(summary.table) <- NULL
> 
> I get the following error
> 
> > rownames(rta) <- NULL
> Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
>  invalid dimnames given for data frame
> >
> 
> the resulting (incorrect) table appears as,
> 
> > xtable( rta )
> % latex table generated in R 1.9.0 by xtable 1.2-2 package
> % Wed May 12 17:38:21 2004
> \begin{table}[ht]
> \begin{center}
> \begin{tabular}{rlr}
> \hline
>  & site.index & acres \\
> \hline
> 1 &  80 & 20.90 \\
> 2 &  90 & 64.42 \\
> ...blah, blah, blah...
> 8 & 150 & 53.32 \\
> 9 & 170 & 0.69 \\
> \hline
> \end{tabular}
> \end{center}
> \end{table}
> >
> 
> with the rownames. How do I get them out?
> 
> I'm stuck. Help.
> 
> Jeff.
> 
> ---
> Jeff D. Hamann
> Forest Informatics, Inc.
> PO Box 1421
> Corvallis, Oregon USA 97339-1421
> 541-754-1428
> jeff.hamann at forestinformatics.com
> www.forestinformatics.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From Arne.Muller at aventis.com  Thu May 13 18:13:59 2004
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Thu, 13 May 2004 18:13:59 +0200
Subject: [R] storage of lm objects in a database
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADECDD189@crbsmxsusr04.pharma.aventis.com>

Thanks for your reply. I think I'll go for Prof Ripley's suggestion to use "serialize", since I don't need to query attributes of the objects via SQL. So a crude BLOB will do ...

	thanks,

	Arne

--
Arne Muller, Ph.D.
Toxicogenomics, Aventis Pharma
arne dot muller domain=aventis com

> -----Original Message-----
> From: Sean Davis [mailto:sdavis2 at mail.nih.gov]
> Sent: 13 May 2004 17:22
> To: Muller, Arne PH/FR; r-help
> Subject: Re: [R] storage of lm objects in a database
> 
> 
> Arne,
> 
> There are several database access packages for R.  I use 
> RMySQL, but there
> are several others (ODBC, etc.).  However, as far as I know 
> (and I may be
> wrong), there is not a persistence API for R objects (in a 
> relational DB
> sense), but you could certainly deconstruct the objects and 
> store their
> parts for later reconstruction of the objects.  I guess 
> another option would
> be a scheme of saved results (files) indexed in some way so 
> that you could
> get the results, but I can't think of a way to make this fast.
> 
> Sean
> 
> On 5/13/04 11:11 AM, "Arne.Muller at aventis.com" 
> <Arne.Muller at aventis.com>
> wrote:
> 
> > Hello,
> > 
> > I'd like to use DBI to store lm objects in a database. I've 
> to analyze many of
> > linear models and I cannot store them in a single R-session 
> (not enough
> > memory). Also it'd be nice to have them persistent.
> > 
> > Maybe it's possible to create a compact binary 
> representation of the object
> > (the kind of format created created by "save"), so that one 
> doesn't need to
> > write a conversion routine for these objects (or maybe 
> there's already a
> > conversion available for lm?). I assume that the data do 
> not need to be
> > analyzed with a any other software than R.
> > 
> > I'm happy for any suggestions and links to get some more 
> info on this.
> > 
> > kid regards,
> > 
> > Arne
> > 
> > --
> > Arne Muller, Ph.D.
> > Toxicogenomics, Aventis Pharma
> > arne dot muller domain=aventis com
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html
>



From allan at stats.uct.ac.za  Thu May 13 18:32:11 2004
From: allan at stats.uct.ac.za (allan clark)
Date: Thu, 13 May 2004 18:32:11 +0200
Subject: [R] factor analysis
Message-ID: <40A3A30B.F9A64854@stats.uct.ac.za>

hi all

this is a stats question.

when undertaking factor analysis should the variables included always be
continiuos random variables? could one include categorical data? e.g
some survey type data

my gut feeling is that one should not include categorical type data
since factor analysis is based on the eigenanalysis of the correlation
matrix of a group of variables. The introduction of categorical data
into a data set might "mess up" the corelation matrix.



From loveland.1 at nd.edu  Thu May 13 18:41:12 2004
From: loveland.1 at nd.edu (Matt Loveland)
Date: Thu, 13 May 2004 11:41:12 -0500
Subject: [R] GLMM error message/reproducible example
Message-ID: <00bb01c43909$1a0d61b0$a3b74a81@loveland>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040513/67cea6b5/attachment.pl

From gilesh at stanford.edu  Thu May 13 19:41:57 2004
From: gilesh at stanford.edu (Giles Hooker)
Date: Thu, 13 May 2004 10:41:57 -0700 (PDT)
Subject: [R] R 1.9.0 and pred.rpart
Message-ID: <Pine.LNX.4.44.0405131038010.4612-100000@cardinal4.Stanford.EDU>


I have just upgraded from R 1.7.3 to R 1.9.0 and have found that the
predict function no longer works for rpart:

> predict(hmmm,sim3[1:10,])
Error in predict.rpart(hmmm, sim3[1:10, ]) :
	couldn't find function "pred.rpart"

I have re-installed the rpart package to no avail. Any ideas?

Giles Hooker



From ligges at statistik.uni-dortmund.de  Thu May 13 19:50:19 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 May 2004 19:50:19 +0200
Subject: [R] R 1.9.0 and pred.rpart
In-Reply-To: <Pine.LNX.4.44.0405131038010.4612-100000@cardinal4.Stanford.EDU>
References: <Pine.LNX.4.44.0405131038010.4612-100000@cardinal4.Stanford.EDU>
Message-ID: <40A3B55B.4080108@statistik.uni-dortmund.de>

Giles Hooker wrote:
> I have just upgraded from R 1.7.3 to R 1.9.0 and have found that the
> predict function no longer works for rpart:
> 
> 
>>predict(hmmm,sim3[1:10,])
> 
> Error in predict.rpart(hmmm, sim3[1:10, ]) :
> 	couldn't find function "pred.rpart"
> 
> I have re-installed the rpart package to no avail. Any ideas?

You need to (re-)install a recent version of rpart (that might be the 
case for other contributed packages as well!).

Uwe Ligges


> Giles Hooker
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From v.demartino2 at virgilio.it  Thu May 13 21:59:04 2004
From: v.demartino2 at virgilio.it (Vittorio)
Date: Thu, 13 May 2004 20:59:04 +0100
Subject: [R] tapply & hist
Message-ID: <200405132059.04787.v.demartino2@virgilio.it>

I'm learning how to use tapply. 
Now I'm having a go at the following code in which dati contains almost 600 
lines, Pot - numeric - are the capacities of power plants and SGruppo - text 
- the corresponding six technologies ("CCC", "CIC","TGC", "CSC","CPC", "TE").     
.....................................................

dati=sqlQuery(canale,"select Id,SGruppo,Classe, NGruppo,ProdNetta,Pot from 
SintesiQuery")
attach(dati)
# Grouping by technology
tapply(Pot,SGruppo,sum)
...................................
# Histograms by technology
par(mfrow=c(2,3)) 
tapply(Pot,SGruppo,hist)
detach(dati)

It all works great but  tapply(Pot,SGruppo,hist) produces 6 histograms with 
the titles and the xlab labels in a generic form, something like integer[1], 
integer[2], ....... while I'd like to have each graph indicating the 
mentioned technologies.
I've been trying issuing 
tech=c("CCC", "CIC","TGC", "CSC","CPC", "TE")
tapply(Pot,SGruppo,hist, main=tech)

but R prints in each histogram the six values in the title without cycling 
among them.

How can I obtain what I want?

Ciao
Vittorio 


to no avail



From jfox at mcmaster.ca  Thu May 13 20:02:55 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 13 May 2004 14:02:55 -0400
Subject: [R] please help with estimation of true correlations
	andreliabilities
In-Reply-To: <29198.1084460954@www19.gmx.net>
Message-ID: <web-39263920@cgpsrv2.cis.mcmaster.ca>

Dear Jens,

If you're willing to assume multinormality but don't have in mind a
specific model to estimate, then why not use factanal? The uniquenesses
are estimates of the unreliability of the items.

I hope this helps,
 John

On Thu, 13 May 2004 17:09:14 +0200 (MEST)
 "Jens Oehlschl??gel" <joehl at gmx.de> wrote:
> 
> Dear John,
> Dear Joseph,
> 
> Thank you for your quick answers and the pointer to semnet. 
> I try to clarify on my assumptions:
> 
> - yes, I am willing to assume multivariate normality
> - no, I don't want to assume a single factor model
> - I assume there is an unknown number of factors, and I do not know
> which
> items belong to which factors
> 
> but I still want to estimate single item reliabilities
> 
> Is this impossible?
> How can one specify such unspecified model to sem?
> Which (exploratory?) function would me help doing this?
> Or just: what should I read?
> 
> Thanks for any help
> 
> 
> Jens Oehlschl??gel
> 
> --
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html


--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From gilesh at stanford.edu  Thu May 13 20:05:10 2004
From: gilesh at stanford.edu (Giles Hooker)
Date: Thu, 13 May 2004 11:05:10 -0700 (PDT)
Subject: [R] R 1.9.0 and pred.rpart
In-Reply-To: <40A3B55B.4080108@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0405131103300.4612-100000@cardinal4.Stanford.EDU>


I installed from the CRAN website:

install.packages(rpart)

and also checked

old.packages()

which returned NULL.

More clues?

Giles Hooker


> Giles Hooker wrote:
> > I have just upgraded from R 1.7.3 to R 1.9.0 and have found that the
> > predict function no longer works for rpart:
> >
> >
> >>predict(hmmm,sim3[1:10,])
> >
> > Error in predict.rpart(hmmm, sim3[1:10, ]) :
> > 	couldn't find function "pred.rpart"
> >
> > I have re-installed the rpart package to no avail. Any ideas?
>
> You need to (re-)install a recent version of rpart (that might be the
> case for other contributed packages as well!).
>
> Uwe Ligges
>
>
> > Giles Hooker
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From jfox at mcmaster.ca  Thu May 13 20:05:12 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 13 May 2004 14:05:12 -0400
Subject: [R] factor analysis
In-Reply-To: <40A3A30B.F9A64854@stats.uct.ac.za>
Message-ID: <web-39264544@cgpsrv2.cis.mcmaster.ca>

Dear Allan,

I assume that the categorical data are ordinal. There are methods for
factor analyzing ordinal data (e.g., using polychoric correlations) and
mixed ordinal and interval data, but as far as I know, these aren't
implemented in R.

John

On Thu, 13 May 2004 18:32:11 +0200
 allan clark <allan at stats.uct.ac.za> wrote:
> hi all
> 
> this is a stats question.
> 
> when undertaking factor analysis should the variables included always
> be
> continiuos random variables? could one include categorical data? e.g
> some survey type data
> 
> my gut feeling is that one should not include categorical type data
> since factor analysis is based on the eigenanalysis of the
> correlation
> matrix of a group of variables. The introduction of categorical data
> into a data set might "mess up" the corelation matrix.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html


--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From Rheaume.Pascal at hydro.qc.ca  Thu May 13 20:13:38 2004
From: Rheaume.Pascal at hydro.qc.ca (Rheaume.Pascal@hydro.qc.ca)
Date: Thu, 13 May 2004 14:13:38 -0400
Subject: [R] List of data frames...
Message-ID: <2D5048494293D411809800508BF900FC16526C57@msxcentral1.hydro.qc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040513/598b8eb7/attachment.pl

From isung at affinnova.com  Thu May 13 20:40:50 2004
From: isung at affinnova.com (Iyue Sung)
Date: Thu, 13 May 2004 14:40:50 -0400
Subject: [R] OT: Job Posting
Message-ID: <90821ABF429A074DA88E56D1DF7A7161012D5CBF@afifs1.affinnova.com>

Open Position for Statistician.

Come join Affinnova, an exciting and growing company in market research!
Our primary distinction is the use of genetic algorithms (GA) in product
development.  These GAs are applied to online surveys, in which
respondents 'evolve' and reduce the number of product designs that are
being considered.

We are open to candidates from diverse backgrounds and experiences.  The
primary characteristic we seek is the ability to apply statistical
methods to business objectives.  Our toolbox is diverse, in both
applications and complexity.  Hence, there are varied levels of
contribution, from direct analysis and interpretation of data, to
research into quantitative methods.  

Please see the following URL for details:
http://www.affinnova.com/company/careers.shtml

Interested candidates may reply to: isung AT affinnova DOT com


------------------------------------------
Iyue Sung, Ph.D.
Senior Statistician
Affinnova
52 Second Avenue, 2nd Floor South
Waltham, MA 02451
P: 781.461.4741        F: 781.464.4701



From Pierre.Bady at univ-lyon1.fr  Thu May 13 20:50:12 2004
From: Pierre.Bady at univ-lyon1.fr (Pierre BADY)
Date: Thu, 13 May 2004 20:50:12 +0200 (CEST)
Subject: [R] factor analysis
In-Reply-To: <web-39264544@cgpsrv2.cis.mcmaster.ca>
References: <web-39264544@cgpsrv2.cis.mcmaster.ca>
Message-ID: <1084474212.40a3c36483c65@webmail.univ-lyon1.fr>

hi all,

In the library 'ade4?, there are two eigenanalysis which enable the ordination 
of the categorical variables. 

1- Multiple Correspondence Analysis (MCA, Tenenhaus & Young 1985) performs the 
multiple correspondence analysis of a factor table (see the 
function 'dudi.acm?). 

2- the "mixed factorial analysis" (Hill & Smith 1976)  enables the ordination 
of tables mixing quantitative variables and factors (functions 'dudi.mix? 
or  'dudi.hillsmith?).


I hope this helps,

P.BADY



En r??ponse ?? John Fox <jfox at mcmaster.ca>:
> Dear Allan,
> 
> I assume that the categorical data are ordinal. There are methods for
> factor analyzing ordinal data (e.g., using polychoric correlations)
> and
> mixed ordinal and interval data, but as far as I know, these aren't
> implemented in R.
> 
> John
> 
> On Thu, 13 May 2004 18:32:11 +0200
>  allan clark <allan at stats.uct.ac.za> wrote:
> > hi all
> > 
> > this is a stats question.
> > 
> > when undertaking factor analysis should the variables included
> always
> > be
> > continiuos random variables? could one include categorical data? e.g
> > some survey type data
> > 
> > my gut feeling is that one should not include categorical type data
> > since factor analysis is based on the eigenanalysis of the
> > correlation
> > matrix of a group of variables. The introduction of categorical data
> > into a data set might "mess up" the corelation matrix.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> 
> 
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> 



---------------------------------------------------------
Pierre BADY 
Universit?? Claude Bernard Lyon 1
UMR CNRS 5023, LEHF
bat Alphonse Forel
43 boulevard du 11 novembre 1918 
F-69622 VILLEURBANNE CEDEX 
FRANCE
TEL : +33 (0)4 72 44 62 34 
FAX : +33 (0)4 72 43 28 92 
MEL : pierre.bady at univ-lyon1.fr
http://limnologie.univ-lyon1.fr
http://badgloup.ifrance.com



From p.dalgaard at biostat.ku.dk  Thu May 13 21:00:09 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 May 2004 21:00:09 +0200
Subject: [R] List of data frames...
In-Reply-To: <2D5048494293D411809800508BF900FC16526C57@msxcentral1.hydro.qc.ca>
References: <2D5048494293D411809800508BF900FC16526C57@msxcentral1.hydro.qc.ca>
Message-ID: <x2u0ykb1ae.fsf@biostat.ku.dk>

Rheaume.Pascal at hydro.qc.ca writes:

> Hi, 
> 
> I would like to create a list of data frames that I could access via index
> manipulation. An array pointer of dataframe...
> 
>  for (i in 1:length(InputFilelist))
>  {
>     # create data.frame
>     temp <- read.table (file = InputFilelist[i] , header = T, skip = 4)
>     # append data.frame	
>     InputDataFrame <<- list(InputDataFrame,temp)
>  }
> 
> Thanks in advance !

You don't want to extend the list on every iteration (it involves
copying the current contents!). 

Try this:

lapply(InputFilelist, read.table, header=TRUE, skip=4)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From thpe at hhbio.wasser.tu-dresden.de  Thu May 13 21:08:33 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Thu, 13 May 2004 21:08:33 +0200
Subject: [R] List of data frames...
In-Reply-To: <2D5048494293D411809800508BF900FC16526C57@msxcentral1.hydro.qc.ca>
References: <2D5048494293D411809800508BF900FC16526C57@msxcentral1.hydro.qc.ca>
Message-ID: <40A3C7B1.6040806@hhbio.wasser.tu-dresden.de>

Rheaume.Pascal at hydro.qc.ca wrote:
> Hi, 
> 
> I would like to create a list of data frames that I could access via index
> manipulation. An array pointer of dataframe...
> 
>  for (i in 1:length(InputFilelist))
>  {
>     # create data.frame
>     temp <- read.table (file = InputFilelist[i] , header = T, skip = 4)
>     # append data.frame	
>     InputDataFrame <<- list(InputDataFrame,temp)
>  }

I think, the following example my help you:

InputDataFrame <- NULL
for (i in 1:3)
{
      # create data.frame
      temp <- data.frame(x=1:5, y=rnorm(5))
      # append data.frame	
      InputDataFrame <- c(InputDataFrame, list(temp))
}

# show the result
str(InputDataFrame)


--
Thomas P.



From jasont at indigoindustrial.co.nz  Fri May 14 21:28:54 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 14 May 2004 07:28:54 -1200 (NZST)
Subject: [R] tapply & hist
In-Reply-To: <200405132059.04787.v.demartino2@virgilio.it>
References: <200405132059.04787.v.demartino2@virgilio.it>
Message-ID: <57023.203.9.176.60.1084476534.squirrel@webmail.maxnet.co.nz>

> ...................................
> # Histograms by technology
> par(mfrow=c(2,3))
> tapply(Pot,SGruppo,hist)
> detach(dati)
>
> It all works great but  tapply(Pot,SGruppo,hist) produces 6 histograms
> with
> the titles and the xlab labels in a generic form, something like
> integer[1],
> integer[2], ....... while I'd like to have each graph indicating the

tapply takes atomic data (usually vectors).  You want to pass rows of a
data frame, so the Pot *and* SGruppo will be sent together; "by()" is very
good for this.  It might be possible (even easy?) to use tapply, but I
just use "by" for these things.

Since dati is your data frame, try this (untested!):

by(dati,dati$SGruppo, function(x,...){
  hist(x$Pot,main=as.character(x$SGruppo[1])) } )

Or, use Lattice:

library(lattice)
histogram( ~ Pot | SGruppo, data=dati)

Cheers

Jason



From deepayan at stat.wisc.edu  Thu May 13 21:51:31 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 13 May 2004 14:51:31 -0500
Subject: [R] Barchart questions
In-Reply-To: <051220042339.19374.40A2B598000D537C00004BAE2160281302FF8C8D9A8690918C9A9B@att.net>
References: <051220042339.19374.40A2B598000D537C00004BAE2160281302FF8C8D9A8690918C9A9B@att.net>
Message-ID: <200405131451.31987.deepayan@stat.wisc.edu>


On Wednesday 12 May 2004 18:39, Neil Desnoyers wrote:

> I am attempting to produce a bar chart and am having some trouble
> with the panel.barchart command. 

That's not really helpful. If you expect us to help, you will have to 
tell us exactly what you did and why you are unhappy with the results. 

> The definition of X is that it's the 
> "proper extent of the bar". Is that the maximum value? Or is it the
> labels for my vertical axis, since the axes seem to be switched for
> this command? 

It has nothing to do with the labels. In the usual formulation, the 'x' 
values (in the formula y ~ x) are supposed to be heights of the bars. 
There should be only one x-value for each y-value (for each panel), so 
I'm not sure what you mean by 'maximum'.

> Is there a better/different command I should be using 
> for barcharts (i.e. barplot)?

barplot also draws bar charts. It's difficult to say which is more 
suitable for your purpose unless we know what you are trying to do.

Deepayan



From blaine at mix.wvu.edu  Thu May 13 22:30:16 2004
From: blaine at mix.wvu.edu (Brittany Erin Laine)
Date: Thu, 13 May 2004 16:30:16 -0400 (EDT)
Subject: [R] code for functions in base package
Message-ID: <3985723.1084480216252.JavaMail.blaine@mix.wvu.edu>

Is there any way that I can see the step by step code for functions in 
the base package? For instance the dexp function. I am a student 
working on writing my own function for something that is similar to 
this dexp function and I would like to see the step by step code.

Brittany Laine
GTA WVU Statistics Department
331 Hodges



From Benjamin.STABLER at odot.state.or.us  Thu May 13 22:39:00 2004
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Thu, 13 May 2004 13:39:00 -0700
Subject: [R] code for functions in base package
Message-ID: <76A000A82289D411952F001083F9DD06047FE67C@exsalem4-bu.odot.state.or.us>

If you want to see the code (function definition) just type the function
without any parenthesizes or arguments.  In this case, the dexp function
calls C code since the .Internal function is called.  To see internal C code
you have to look at the R source.

> dexp
function (x, rate = 1, log = FALSE) 
.Internal(dexp(x, 1/rate, log))
<environment: namespace:base>


Benjamin Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
555 13th Street NE, Suite 2
Salem, OR 97301  Ph: 503-986-4104

>-----Original Message-----
>From: Brittany Erin Laine [mailto:blaine at mix.wvu.edu]
>Sent: Thursday, May 13, 2004 1:30 PM
>To: R-help at stat.math.ethz.ch
>Subject: [R] code for functions in base package
>
>
>Is there any way that I can see the step by step code for functions in 
>the base package? For instance the dexp function. I am a student 
>working on writing my own function for something that is similar to 
>this dexp function and I would like to see the step by step code.
>
>Brittany Laine
>GTA WVU Statistics Department
>331 Hodges
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
>



From ggrothendieck at myway.com  Thu May 13 22:46:40 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 13 May 2004 20:46:40 +0000 (UTC)
Subject: [R] tapply & hist
References: <200405132059.04787.v.demartino2@virgilio.it>
Message-ID: <loom.20040513T224351-293@post.gmane.org>


As another respondent already mentioned, Lattice is probably the way to
go on this one but if you do want to use tapply try this:

names(Pot) <- SGruppo
dummy <- tapply(Pot,SGruppo,function(x)hist(x,main=names(x)[1],xlab=NULL))


Vittorio <v.demartino2 <at> virgilio.it> writes:

: 
: I'm learning how to use tapply. 
: Now I'm having a go at the following code in which dati contains almost 600 
: lines, Pot - numeric - are the capacities of power plants and SGruppo - text 
: - the corresponding six technologies 
("CCC", "CIC","TGC", "CSC","CPC", "TE").     
: .....................................................
: 
: dati=sqlQuery(canale,"select Id,SGruppo,Classe, NGruppo,ProdNetta,Pot from 
: SintesiQuery")
: attach(dati)
: # Grouping by technology
: tapply(Pot,SGruppo,sum)
: ...................................
: # Histograms by technology
: par(mfrow=c(2,3)) 
: tapply(Pot,SGruppo,hist)
: detach(dati)
: 
: It all works great but  tapply(Pot,SGruppo,hist) produces 6 histograms with 
: the titles and the xlab labels in a generic form, something like integer[1], 
: integer[2], ....... while I'd like to have each graph indicating the 
: mentioned technologies.
: I've been trying issuing 
: tech=c("CCC", "CIC","TGC", "CSC","CPC", "TE")
: tapply(Pot,SGruppo,hist, main=tech)
: 
: but R prints in each histogram the six values in the title without cycling 
: among them.
: 
: How can I obtain what I want?
: 
: Ciao
: Vittorio



From pnelson at ucsd.edu  Thu May 13 23:08:19 2004
From: pnelson at ucsd.edu (Peter Nelson)
Date: Thu, 13 May 2004 14:08:19 -0700
Subject: [R] BIO-ENV procedure
Message-ID: <A931E540-A521-11D8-90E8-000393569FBE@ucsd.edu>

I've been unable to find a R package that provides the means of 
performing Clarke & Ainsworth's BIO-ENV procedure or something 
comparable. Briefly, they describe a method for comparing two separate 
sample ordinations, one from species data and the second from 
environmental data. The analysis includes selection of the 'best' 
subset of environmental variables for explaining the observed spp 
ordination.  Is there something available or being developed?

Thanks, Pete



From edarmas at esalq.usp.br  Thu May 13 23:00:04 2004
From: edarmas at esalq.usp.br (Eduardo Dutra de Armas)
Date: Thu, 13 May 2004 18:00:04 -0300
Subject: [R] solving equation
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAlkN94tU7pE2294PPHpOIAsKAAAAQAAAAsoOOlyguCkejWOmFtC89bgEAAAAA@esalq.usp.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040513/60f05438/attachment.pl

From kjetil at acelerate.com  Thu May 13 23:22:07 2004
From: kjetil at acelerate.com (kjetil@acelerate.com)
Date: Thu, 13 May 2004 17:22:07 -0400
Subject: [R] code for functions in base package
In-Reply-To: <3985723.1084480216252.JavaMail.blaine@mix.wvu.edu>
Message-ID: <40A3AEBF.27944.B75365@localhost>

On 13 May 2004 at 16:30, Brittany Erin Laine wrote:

> Is there any way that I can see the step by step code for functions in
> the base package? For instance the dexp function. I am a student
> working on writing my own function for something that is similar to
> this dexp function and I would like to see the step by step code.
> 

Then a useful way is to say 
debug(dexp)
and then step through the code, thiugh I think that function rapidly 
disappears into internal C code.
>From within a debug() session, tou can use ? (help)
and other functions to investigate the objects, readinfg the help for 
function you see used, and so on.

Kjetil Halvorsen

> Brittany Laine
> GTA WVU Statistics Department
> 331 Hodges
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Fri May 14 00:37:47 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 13 May 2004 15:37:47 -0700
Subject: [R] solving equation
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAlkN94tU7pE2294PPHpOIAsKAAAAQAAAAsoOOlyguCkejWOmFtC89bgEAAAAA@esalq.usp.br>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAlkN94tU7pE2294PPHpOIAsKAAAAQAAAAsoOOlyguCkejWOmFtC89bgEAAAAA@esalq.usp.br>
Message-ID: <40A3F8BB.3050607@pdf.com>

      Have you considered making contour plots, e.g., using "contour"?  
See also Venables and Ripley, Modern Applied Statistics with S. 

      Your function is a parabola opening up.  For this, you can obtain 
the axes of the ellipse, etc., using eigen.  The eigenvalues can then 
tell you how far out in these axes you can go. 

      hope this helps.  spencer graves

Eduardo Dutra de Armas wrote:

>Dear R-users,
>
>I'm trying to solve the following equation, to get a set of values
>satisfying it and I'd like to know if its possible to do that in R.
>
>0.85*(54.6-X)^2 + 4.65*(25.2 - Y)^2 -2*0.84*(54.6-X)*(25.2-Y) <= 8.29
>
>Thanks a lot,
>
>Eduardo Armas
>
>
>---
>
>
>
> 
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From andy_liaw at merck.com  Fri May 14 00:56:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 13 May 2004 18:56:36 -0400
Subject: [R] R 1.9.0 and pred.rpart
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D92@usrymx25.merck.com>

Is it possible that you somehow have a copy of predict.rpart in your global
environment, that is overriding the one in the package?

Andy

[ps: R-1.7.3?  Where did you find such a version?]

> From: Giles Hooker
> 
> I installed from the CRAN website:
> 
> install.packages(rpart)
> 
> and also checked
> 
> old.packages()
> 
> which returned NULL.
> 
> More clues?
> 
> Giles Hooker
> 
> 
> > Giles Hooker wrote:
> > > I have just upgraded from R 1.7.3 to R 1.9.0 and have 
> found that the
> > > predict function no longer works for rpart:
> > >
> > >
> > >>predict(hmmm,sim3[1:10,])
> > >
> > > Error in predict.rpart(hmmm, sim3[1:10, ]) :
> > > 	couldn't find function "pred.rpart"
> > >
> > > I have re-installed the rpart package to no avail. Any ideas?
> >
> > You need to (re-)install a recent version of rpart (that 
> might be the
> > case for other contributed packages as well!).
> >
> > Uwe Ligges
> >
> >
> > > Giles Hooker
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> >
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From rpeng at jhsph.edu  Fri May 14 01:34:43 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 13 May 2004 19:34:43 -0400
Subject: [R] code for functions in base package
In-Reply-To: <3985723.1084480216252.JavaMail.blaine@mix.wvu.edu>
References: <3985723.1084480216252.JavaMail.blaine@mix.wvu.edu>
Message-ID: <40A40613.8010903@jhsph.edu>

For dexp() need to look at the C source code for R.  It's part of 
the nmath library.

-roger

Brittany Erin Laine wrote:

> Is there any way that I can see the step by step code for functions in 
> the base package? For instance the dexp function. I am a student 
> working on writing my own function for something that is similar to 
> this dexp function and I would like to see the step by step code.
> 
> Brittany Laine
> GTA WVU Statistics Department
> 331 Hodges
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From bates at stat.wisc.edu  Fri May 14 01:40:12 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 13 May 2004 18:40:12 -0500
Subject: [R] code for functions in base package
In-Reply-To: <40A3AEBF.27944.B75365@localhost>
References: <40A3AEBF.27944.B75365@localhost>
Message-ID: <6r7jvflwv7.fsf@bates4.stat.wisc.edu>

> On 13 May 2004 at 16:30, Brittany Erin Laine wrote:
> 
> > Is there any way that I can see the step by step code for functions in
> > the base package? For instance the dexp function. I am a student
> > working on writing my own function for something that is similar to
> > this dexp function and I would like to see the step by step code.
> > 
> > Brittany Laine
> > GTA WVU Statistics Department
> > 331 Hodges

As several people have pointed out the dexp function in R immediately
calls .Internal and drops down to C code.  For many of the d-p-q
functions like dexp, pexp, and qexp there are short C functions
defined in the src/nmath directory that do the calculation for a
single element of the response vector.  The C code that is called
directly by the .Internal is rather complicated but its only purpose
is to provide for the vectorization of the R function.  The real
evaluation goes on in dexp.c.  In fact, other than checking for error
conditions it amounts to a single statement

    return (give_log ?
	    (-x / scale) - log(scale) :
	    exp(-x / scale) / scale);

This is all to say that you probably don't want to go through the
step-by-step evaluation of the C code in a symbolic debugger because
most of the code that you will step through is devoted to the
vectorization.  Go directly to the corresponding C function in the
src/nmath directory.



From ksm32 at student.canterbury.ac.nz  Fri May 14 01:45:34 2004
From: ksm32 at student.canterbury.ac.nz (Karla Meurk)
Date: Fri, 14 May 2004 11:45:34 +1200
Subject: [R] watermarks
Message-ID: <40A4089E.60103@student.canterbury.ac.nz>

Hi, I would like to plot a graph which sits in the background as a 
watermark with other plots in the foreground - on top.  I have looked 
through the threads on the r-project website but they seem to concern 
background colours rather than actual background plots.  I have also 
searched through the demo's and pars but can't find any eg's

any ideas - I only want to plot a simple graph using pie.chart()

Thanks

Carla



From jasont at indigoindustrial.co.nz  Sat May 15 01:50:16 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 14 May 2004 11:50:16 -1200 (NZST)
Subject: [R] watermarks
In-Reply-To: <40A4089E.60103@student.canterbury.ac.nz>
References: <40A4089E.60103@student.canterbury.ac.nz>
Message-ID: <46298.203.9.176.60.1084492216.squirrel@webmail.maxnet.co.nz>

> Hi, I would like to plot a graph which sits in the background as a
> watermark with other plots in the foreground - on top.

"par()" is where most of these questions lead.  Try

?par

particularly the "new" argument.

Cheers

Jason



From maj at stats.waikato.ac.nz  Fri May 14 04:25:35 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Fri, 14 May 2004 14:25:35 +1200
Subject: [R] Problem with logtrans, from library MASS
Message-ID: <40A42E1F.4030202@stats.waikato.ac.nz>

Greetings all!

This problem occurs using R 1.8.1 on Windows XP. I downloaded the 
binaries for R and all packages, including the VR bundle, in December 2003.

The data consists of NZ$ prices and attributes for 643 cars.

 > summary(price)
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
   14290   35800   48990   65400   79000  285000       2
 > library(MASS)
 > boxcox(price ~ doors+CC+KW+KG+LENGTH, lambda=seq(-0.1,0.5,length=30))
 > boxcox(price ~ doors+CC+KW+KG+LENGTH, lambda=seq(-0.5,0.1,length=30))

This all works fine, I get a fairly sharp peak near lambda=-0.25, but then:

 > logtrans(price ~ doors+CC+KW+KG+LENGTH, alpha=seq(-10000,0,length=30))
Error in eval(expr, envir, enclos) : Object "price" not found


Comments welcome,

Murray
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From davidD at qimr.edu.au  Fri May 14 04:57:24 2004
From: davidD at qimr.edu.au (David Duffy)
Date: Fri, 14 May 2004 12:57:24 +1000 (EST)
Subject: [R] disattenuated correlations
In-Reply-To: <200405131004.i4DA39h9003780@hypatia.math.ethz.ch>
References: <200405131004.i4DA39h9003780@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0405141252000.15643@orpheus.qimr.edu.au>

Jens Oehlschl??gel asked:
>
> Can someone point me to literature and/or R software to solve the following
> problem:
>
> Assume n true scores t measured as x with uncorrelated errors e , i.e.
> x = t + e
> and assume each true score to a have a certain amount of correlation with
> some of the other true scores.
>
> but I don't have predefined asumptions about structure in the variable set
> as I guess would be needed for SEM.
>

No, the sem package will do this, providing you have the
reliabilities/repeat measures.  This is a standard "measurement model".



From jarioksa at sun3.oulu.fi  Fri May 14 08:10:10 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 14 May 2004 09:10:10 +0300
Subject: [R] BIO-ENV procedure
In-Reply-To: <A931E540-A521-11D8-90E8-000393569FBE@ucsd.edu>
References: <A931E540-A521-11D8-90E8-000393569FBE@ucsd.edu>
Message-ID: <1084515010.26550.1.camel@biol102145.oulu.fi>

On Fri, 2004-05-14 at 00:08, Peter Nelson wrote:
> I've been unable to find a R package that provides the means of 
> performing Clarke & Ainsworth's BIO-ENV procedure or something 
> comparable. Briefly, they describe a method for comparing two separate 
> sample ordinations, one from species data and the second from 
> environmental data. The analysis includes selection of the 'best' 
> subset of environmental variables for explaining the observed spp 
> ordination.  Is there something available or being developed?
> 
Send a reference to the exact algorithm (or to recipe to algorithm) so
that someone can implement the method. Your post is not sufficient to
know what should be there.

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From uleopold at science.uva.nl  Fri May 14 10:13:47 2004
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: Fri, 14 May 2004 10:13:47 +0200
Subject: [R] Export summary statistics to latex
Message-ID: <40A47FBB.2020107@science.uva.nl>

Dear list,

I would like to export the summary statistics of a regression to latex code.
Is there an easy way of doing that?

Ulrich

-- 
__________________________________________________

Ulrich Leopold MSc.

Computational Bio- and Physical Geography (CBPG)
Institute for Biodiversity and Ecosystem Dynamics (IBED)
Faculty of Science
University of Amsterdam
Nieuwe Achtergracht 166
NL-1018WV Amsterdam

Room:   B2.52
Phone:	+31 20 525 7456 (7451 Secretary)
Fax:	+31 20 525 7431
Mobile:	+31 64 220 3028
Email:	uleopold at science.uva.nl
URL:    www.science.uva.nl/ibed/cbpg



From jarioksa at sun3.oulu.fi  Fri May 14 10:20:34 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 14 May 2004 11:20:34 +0300
Subject: [R] BIO-ENV procedure
In-Reply-To: <A931E540-A521-11D8-90E8-000393569FBE@ucsd.edu>
References: <A931E540-A521-11D8-90E8-000393569FBE@ucsd.edu>
Message-ID: <1084522833.26550.48.camel@biol102145.oulu.fi>

On Fri, 2004-05-14 at 00:08, Peter Nelson wrote:
> I've been unable to find a R package that provides the means of 
> performing Clarke & Ainsworth's BIO-ENV procedure or something 
> comparable. Briefly, they describe a method for comparing two separate 
> sample ordinations, one from species data and the second from 
> environmental data. The analysis includes selection of the 'best' 
> subset of environmental variables for explaining the observed spp 
> ordination.  Is there something available or being developed?
> 
I found a photocopy of Clarke's & Ainsworth's paper (our library does
not subscribe to the Marine Ecology Progress Series, because salty seas
are too far away). It may be that you don't have a canned "BIO-ENV"
routine in R, but you can get very close to the procedure using R (and
the only missing piece looks unessential to me). However, I know that
Bill Venables was working with Clarke's PRIMER, and he may have canned
even BIO-ENV.

The following discussion is based on Clarke & Ainsworth, Mar. Ecol.
Prog. Ser. 92, 205-219; 1993. It seems that this is not an "algorithm",
because it uses brute force and we have no idea if it converges to
anywhere. Let's call this a procedure. C&A suggest analysis with
separate ordination of community data, and then selecting a subset of
environmental variables that is similar to the species data. Please note
that this is not constrained (or `canonical') ordination: species
ordination is done  independently. Further, the similarity of
environmental and biological structure is analysed apart from
ordination, so that you may have cases with good species -- environment
relationship, but not in ordination.

1. An NMDS of community data using Bray-Curtis dissimilarities. Use
isoMDS function of Ripley's & Venables's MASS library for NMDS.
Bray-Curtis dissimilarity is available at least in vegan, and probably
in ade4 and possibly in many other packages.

2. For evaluating species -- environment relationship, they suggest
using rank correlation between Bray-Curtis dissimilarities of community
data and Euclidean distances of environmental data with certain set of
environmental variables. You have Euclidean distances in stats function
dist (or in vegan and N other packages), and you can get rank
correlations with cor.test.  However, Clarke & Ainsworth suggest a new
type of rank correalation that they call ``harmonic rank correlation''
and this may not be in R (haven't searched, though). I do think that is
unessential for the method, so you can do with the existing rank
correlations.

3. Then comes the hard work. You have to try with all possible
combinations of environmental variables (and there may be several
combinations of them). This could be canned, because this is boring and
error prone. Thomas Lumley's leaps package does this for regression
analysis, and model could be taken from there. Now you can do this, but
it may be a bit hard work.

4. Now you select the best subset, or the subset giving highest rank
correlation. There is no guarantee that there is such a unique, clear
case, but you may be lucky.

5. Take that subset, get Euclidean distances, and ordinate those
distances using NMDS, and plot your two ordinations side by side. Clarke
& Ainsworth recommend using NMDS instead of metric (or classic) MDS, and
they warn against Procrustes comparison of these two solutions (but I
would suggest Procrustes comparison). 


> library(MASS)
> library(vegan)
> data(varespec)
> data(varechem)
> env <- varechem[, c("N","P","K")]
> d <- vegdist(varespec, "bray")
> env <- scale(env)
> cor.test(d, dist(env[,1]), method="spear")$est
      rho
0.1712362
> cor.test(d, dist(env[,2]), method="spear")$est
      rho
0.1803071
> cor.test(d, dist(env[,3]), method="spear")$est
      rho
0.2427814
> cor.test(d, dist(env[,c(1,2)]), method="spear")$est
      rho
0.2422454
> cor.test(d, dist(env[,c(1,3)]), method="spear")$est
      rho
0.2471631
> cor.test(d, dist(env[,c(2,3)]), method="spear")$est
      rho
0.2081135
> cor.test(d, dist(env[,c(1,2,3)]), method="spear")$est
      rho
0.2441523

Some warnings on ties were removed. This suggest that the best subset
uses variables 2 and 3 or N and K. In this case we can skip the NMDS of
community data, since it has rank 2 (only two environmental variables),
and can be exactly plotted in 2 dim without ordination. 

> mds.comm <- isoMDS(d)
> par(mfrow=c(1,2))
> plot(mds.comm$points, asp=1)
> plot(env[, c(1,3)], asp=1)

Or, possibly:

> par(mfrow=c(1,1))
> plot(procrustes(env[,c(1,3)], mds.comm))

So you can do it. The missing pieces are the harmonic rank correlation
(if you think that's essential) and automating variable selection.
Somebody could do them (not me, though).

cheers, jari oksanen

-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From Matthias.Templ at statistik.gv.at  Fri May 14 10:23:29 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Fri, 14 May 2004 10:23:29 +0200
Subject: AW: [R] Export summary statistics to latex
Message-ID: <83536658864BC243BE3C06D7E936ABD5015368E5@xchg1.statistik.local>

Try: Search in Google for     r code latex
And look for eg. the second entry.

You kann also use Sweave  (library(tools))

Matthias

-----Urspr??ngliche Nachricht-----
Von: Ulrich Leopold [mailto:uleopold at science.uva.nl] 
Gesendet: Freitag, 14. Mai 2004 10:14
An: r-help at stat.math.ethz.ch
Betreff: [R] Export summary statistics to latex


Dear list,

I would like to export the summary statistics of a regression to latex code. Is there an easy way of doing that?

Ulrich

-- 
__________________________________________________

Ulrich Leopold MSc.

Computational Bio- and Physical Geography (CBPG)
Institute for Biodiversity and Ecosystem Dynamics (IBED) Faculty of Science University of Amsterdam Nieuwe Achtergracht 166 NL-1018WV Amsterdam

Room:   B2.52
Phone:	+31 20 525 7456 (7451 Secretary)
Fax:	+31 20 525 7431
Mobile:	+31 64 220 3028
Email:	uleopold at science.uva.nl
URL:    www.science.uva.nl/ibed/cbpg

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Fri May 14 11:36:44 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 May 2004 11:36:44 +0200
Subject: [R] Problem with logtrans, from library MASS
In-Reply-To: <40A42E1F.4030202@stats.waikato.ac.nz>
References: <40A42E1F.4030202@stats.waikato.ac.nz>
Message-ID: <x2n04bl58z.fsf@biostat.ku.dk>

Murray Jorgensen <maj at stats.waikato.ac.nz> writes:

> Greetings all!
> 
> This problem occurs using R 1.8.1 on Windows XP. I downloaded the
> binaries for R and all packages, including the VR bundle, in December
> 2003.
> 
> The data consists of NZ$ prices and attributes for 643 cars.
> 
>  > summary(price)
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
>    14290   35800   48990   65400   79000  285000       2
>  > library(MASS)
>  > boxcox(price ~ doors+CC+KW+KG+LENGTH, lambda=seq(-0.1,0.5,length=30))
>  > boxcox(price ~ doors+CC+KW+KG+LENGTH, lambda=seq(-0.5,0.1,length=30))
> 
> This all works fine, I get a fairly sharp peak near lambda=-0.25, but then:
> 
>  > logtrans(price ~ doors+CC+KW+KG+LENGTH, alpha=seq(-10000,0,length=30))
> Error in eval(expr, envir, enclos) : Object "price" not found
> 

The issue is that logtrans has a 'data' argument that defaults to NULL
(the author(s) may have a reason for having this inconsistent with
boxplot?). Adding data=.GlobalEnv seems to work.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Fri May 14 11:57:03 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 May 2004 10:57:03 +0100 (BST)
Subject: [R] Problem with logtrans, from library MASS
In-Reply-To: <x2n04bl58z.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0405141054430.22045-100000@gannet.stats>

On 14 May 2004, Peter Dalgaard wrote:

> Murray Jorgensen <maj at stats.waikato.ac.nz> writes:
> 
> > Greetings all!
> > 
> > This problem occurs using R 1.8.1 on Windows XP. I downloaded the
> > binaries for R and all packages, including the VR bundle, in December
> > 2003.
> > 
> > The data consists of NZ$ prices and attributes for 643 cars.
> > 
> >  > summary(price)
> >     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
> >    14290   35800   48990   65400   79000  285000       2
> >  > library(MASS)
> >  > boxcox(price ~ doors+CC+KW+KG+LENGTH, lambda=seq(-0.1,0.5,length=30))
> >  > boxcox(price ~ doors+CC+KW+KG+LENGTH, lambda=seq(-0.5,0.1,length=30))
> > 
> > This all works fine, I get a fairly sharp peak near lambda=-0.25, but then:
> > 
> >  > logtrans(price ~ doors+CC+KW+KG+LENGTH, alpha=seq(-10000,0,length=30))
> > Error in eval(expr, envir, enclos) : Object "price" not found
> > 
> 
> The issue is that logtrans has a 'data' argument that defaults to NULL
> (the author(s) may have a reason for having this inconsistent with
> boxplot?). Adding data=.GlobalEnv seems to work.

It's an R/S difference.  data=NULL or list() in S does give you the normal
search path.  I guess this got noticed for boxplot and not logtrans.

Using a data argument would in any case be a very good idea.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Darren.Shaw at ed.ac.uk  Fri May 14 12:11:07 2004
From: Darren.Shaw at ed.ac.uk (Darren Shaw)
Date: Fri, 14 May 2004 11:11:07 +0100
Subject: [R] NLME model question
Message-ID: <5.1.0.14.2.20040514110535.00b80c70@staffmail.ed.ac.uk>

Dear R-helpers

I have a problem related to the use of NLME

I think is simply a matter of getting the nlme coding correct, but i cannot 
get my brain around it

I am analysing some 24 growth curves of some cells , and i wanted to say 
that there are significant differences between the curves in two parameters 
that describe the pattern of growth.  these parameters are from a logistic 
(r & k) .

i have attempted to construct a self starting routine for nlme ie:

SSGrowth_function(x, r, k)
{
         .expr2 <- (k - 100000)/100000
         .expr5 <- exp(((r * -1) * x))
         .expr7 <- 1 + (.expr2 * .expr5)
         .expr13 <- .expr7^2
         .value <- k/.expr7
         .actualArgs <- match.call()[c("r", "k")]
         if(all(unlist(lapply(as.list(.actualArgs), is.name)))) {
                 .grad <- array(0, c(length(.value), 2), list(NULL, c("r", 
"k")))
                 .grad[, "r"] <-  - ((k * (.expr2 * (.expr5 * (-1 * 
x))))/.expr13)
                 .grad[, "k"] <- (1/.expr7) - ((k * (1e-005 * .expr5))/.expr13)
                 dimnames(.grad) <- list(NULL, .actualArgs)
                 attr(.value, "gradient") <- .grad
         }
         .value
}

where x = time, 100000 = known starting conditions, r = growth and k = 
carrying capacity

  i guessed i should then write

nlme(NoofCells~SSGrowth(Time,r,k),fixed=r+k~1,data=CellData,random=r+k~1)


This runs and tells me that r & k's do differ

BUT.  The "CellData" actually consists of replicates - ie there are 4 cell 
types, but they are done 6 times each.  Therefore, I do not want to ask if 
there are significant differences in r & k between 24 sets of data 
("Runs")- rather I want to be able to say that there are differences 
between the four cell types occurring 6 times each.  So how do 
i  incorporate "CellType" explicitly into my model structure??

i.e. If i was lust looking at say linear growth and was using lme I would 
have written something like

lme(NoofCells~Time*CellType,random=~1|Runs,data=CellData)

Any thoughts/suggestions gratefully received

Darren Shaw

-----------------------------------------------------------------
Dr Darren J Shaw
Centre for Tropical Veterinary Medicine (CTVM)
Royal School of Veterinary Studies
The University of Edinburgh
Scotland



From ramzi.temanni at laposte.net  Fri May 14 12:26:58 2004
From: ramzi.temanni at laposte.net (Ramzi TEMANNI)
Date: Fri, 14 May 2004 12:26:58 +0200
Subject: [R] quadratic problem with quadratic constraint
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA/SScWgRDKkWYRSKuOxiKY8KAAAAQAAAAHN1aI4hqaUyOVlG+W3LBzQEAAAAA@laposte.net>

Hi all,
Can we solve Quadratic Program with Quadratic Constraint in R ?




Regards,

TEMANNI Ramzi
DEA Student
Lim&Bio
http://www.limbio-paris13.org
UFR de Sant??, M??decine et Biologie Humaine (SMBH) 
L??onard de Vinci 74, rue Marcel Cachin
93017 Bobigny Cedex
France.
T??l : 01.48.38.73.07
T??l : 06.21.43.27.59
temanni.ramzi at free.fr
http://temanni.ramzi.free.fr



From ale.ambrosi at unipd.it  Fri May 14 12:27:35 2004
From: ale.ambrosi at unipd.it (ale.ambrosi@unipd.it)
Date: Fri, 14 May 2004 12:27:35 +0200 (MET DST)
Subject: [R] how add objects to an svm graphic
Message-ID: <1084530455.40a49f171c874@webmail.unipd.it>

Dear all,

I'm not able to solve easily the following simple problem. 
I really hope someone can give me some hints.

I trained an svm (e1071). Now I'd like to show the results graphically.
I used plot.svm and I'd like to add some other objects to the plot:
points, (coloured) ellipses to indicate some intersting regions, curves, 
and so on...
I tried to pass these as additional graphics parameters to pass to 
filled.contour, as indicated in ?plot.svm and in examples in
filled.contour help.

But it doesn't seem to work.

Where is my foult? Can anyone help me? 

Best,
Alessandro


PS: I use R 1.9.0 on a WinXP OS


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
Alessandro Ambrosi, Ph.D.       |
Oncological Surgical Sc. Dept.  | mail: ale.ambrosi at unipd.it
Surg. Cl. II 			|       ambrosi at stat.unipd.it
University of Padua		| fax:  +39 049 651891
via Giustiniani, 2 		| tel:  +39 049 8212055
I-35128 Padua (ITALY)           | url:  www.stat.unipd.it/~ambrosi 	    
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


-------------------------------------------------
This mail sent through IMP: webmail.unipd.it



From maj at stats.waikato.ac.nz  Fri May 14 12:36:29 2004
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Fri, 14 May 2004 22:36:29 +1200
Subject: [R] Problem with logtrans, from library MASS
In-Reply-To: <Pine.LNX.4.44.0405141054430.22045-100000@gannet.stats>
References: <Pine.LNX.4.44.0405141054430.22045-100000@gannet.stats>
Message-ID: <40A4A12D.5070004@stats.waikato.ac.nz>

Thanks for the help.

The variables do all come from a frame but with various transformations 
and manipulations. I prefer not to stick them all into a new frame just 
to call one function.

Thanks again,

Murray Jorgensen

Prof Brian Ripley wrote:
> On 14 May 2004, Peter Dalgaard wrote:
> 
> 
>>Murray Jorgensen <maj at stats.waikato.ac.nz> writes:
>>
>>
>>>Greetings all!
>>>
>>>This problem occurs using R 1.8.1 on Windows XP. I downloaded the
>>>binaries for R and all packages, including the VR bundle, in December
>>>2003.
>>>
>>>The data consists of NZ$ prices and attributes for 643 cars.
>>>
>>> > summary(price)
>>>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
>>>   14290   35800   48990   65400   79000  285000       2
>>> > library(MASS)
>>> > boxcox(price ~ doors+CC+KW+KG+LENGTH, lambda=seq(-0.1,0.5,length=30))
>>> > boxcox(price ~ doors+CC+KW+KG+LENGTH, lambda=seq(-0.5,0.1,length=30))
>>>
>>>This all works fine, I get a fairly sharp peak near lambda=-0.25, but then:
>>>
>>> > logtrans(price ~ doors+CC+KW+KG+LENGTH, alpha=seq(-10000,0,length=30))
>>>Error in eval(expr, envir, enclos) : Object "price" not found
>>>
>>
>>The issue is that logtrans has a 'data' argument that defaults to NULL
>>(the author(s) may have a reason for having this inconsistent with
>>boxplot?). Adding data=.GlobalEnv seems to work.
> 
> 
> It's an R/S difference.  data=NULL or list() in S does give you the normal
> search path.  I guess this got noticed for boxplot and not logtrans.
> 
> Using a data argument would in any case be a very good idea.
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From bates at stat.wisc.edu  Fri May 14 13:49:43 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 14 May 2004 06:49:43 -0500
Subject: [R] NLME model question
In-Reply-To: <5.1.0.14.2.20040514110535.00b80c70@staffmail.ed.ac.uk>
References: <5.1.0.14.2.20040514110535.00b80c70@staffmail.ed.ac.uk>
Message-ID: <6r7jvfut2g.fsf@bates4.stat.wisc.edu>

Darren Shaw <Darren.Shaw at ed.ac.uk> writes:

> Dear R-helpers
> 
> I have a problem related to the use of NLME
> 
> I think is simply a matter of getting the nlme coding correct, but i
> cannot get my brain around it
> 
> 
> I am analysing some 24 growth curves of some cells , and i wanted to
> say that there are significant differences between the curves in two
> parameters that describe the pattern of growth.  these parameters are
> from a logistic (r & k) .
> 
> 
> i have attempted to construct a self starting routine for nlme ie:
> 
> SSGrowth_function(x, r, k)
> {
>          .expr2 <- (k - 100000)/100000
>          .expr5 <- exp(((r * -1) * x))
>          .expr7 <- 1 + (.expr2 * .expr5)
>          .expr13 <- .expr7^2
>          .value <- k/.expr7
>          .actualArgs <- match.call()[c("r", "k")]
>          if(all(unlist(lapply(as.list(.actualArgs), is.name)))) {
>                  .grad <- array(0, c(length(.value), 2), list(NULL,
>                  c("r", "k")))
> 
>                  .grad[, "r"] <-  - ((k * (.expr2 * (.expr5 * (-1 *
>                  x))))/.expr13)
> 
>                  .grad[, "k"] <- (1/.expr7) - ((k * (1e-005 * .expr5))/.expr13)
>                  dimnames(.grad) <- list(NULL, .actualArgs)
>                  attr(.value, "gradient") <- .grad
>          }
>          .value
> }
> 
> where x = time, 100000 = known starting conditions, r = growth and k =
> carrying capacity
> 
> 
>   i guessed i should then write
> 
> nlme(NoofCells~SSGrowth(Time,r,k),fixed=r+k~1,data=CellData,random=r+k~1)
> 
> 
> This runs and tells me that r & k's do differ
> 
> BUT.  The "CellData" actually consists of replicates - ie there are 4
> cell types, but they are done 6 times each.  Therefore, I do not want
> to ask if there are significant differences in r & k between 24 sets
> of data ("Runs")- rather I want to be able to say that there are
> differences between the four cell types occurring 6 times each.  So
> how do i  incorporate "CellType" explicitly into my model structure??
> 
> 
> i.e. If i was lust looking at say linear growth and was using lme I
> would have written something like
> 
> 
> lme(NoofCells~Time*CellType,random=~1|Runs,data=CellData)
> 
> Any thoughts/suggestions gratefully received

I believe you want

nlme(NoofCells~SSGrowth(Time,r,k),fixed=r+k~1,data=CellData,random=r+k~1|Runs)



From rn001 at cebas.csic.es  Fri May 14 13:53:11 2004
From: rn001 at cebas.csic.es (javier garcia - CEBAS)
Date: Fri, 14 May 2004 13:53:11 +0200
Subject: [R] integrate over a serie
Message-ID: <200405141152.i4EBqcE09006@natura.cebas.csic.es>

Hi all;

I've got temporal series of data. And I'm plotting it with the type 'l', and 
with a interpolating slipe.

Could you advise me about the best way  to calculate the area under any of 
these curves.  

I know it is very easy to calculate the first one, although have no idea of 
the second one. But, perhaps there is a function that I can't find to do 
directly these integration?

Thanks and best regards,

Javier



From kjetil at acelerate.com  Fri May 14 14:32:02 2004
From: kjetil at acelerate.com (kjetil@acelerate.com)
Date: Fri, 14 May 2004 08:32:02 -0400
Subject: [R] Export summary statistics to latex
In-Reply-To: <40A47FBB.2020107@science.uva.nl>
Message-ID: <40A48402.7157.3F85DE1@localhost>

On 14 May 2004 at 10:13, Ulrich Leopold wrote:

> Dear list,
> 
> I would like to export the summary statistics of a regression to latex
> code. Is there an easy way of doing that?
> 
> Ulrich
> 

See function latex() in package 
Hmisc

Kjetil Halvorsen

> -- 
> __________________________________________________
> 
> Ulrich Leopold MSc.
> 
> Computational Bio- and Physical Geography (CBPG)
> Institute for Biodiversity and Ecosystem Dynamics (IBED)
> Faculty of Science
> University of Amsterdam
> Nieuwe Achtergracht 166
> NL-1018WV Amsterdam
> 
> Room:   B2.52
> Phone:	+31 20 525 7456 (7451 Secretary)
> Fax:	+31 20 525 7431
> Mobile:	+31 64 220 3028
> Email:	uleopold at science.uva.nl
> URL:    www.science.uva.nl/ibed/cbpg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From kjetil at acelerate.com  Fri May 14 14:32:01 2004
From: kjetil at acelerate.com (kjetil@acelerate.com)
Date: Fri, 14 May 2004 08:32:01 -0400
Subject: [R] watermarks
In-Reply-To: <40A4089E.60103@student.canterbury.ac.nz>
Message-ID: <40A48401.23981.3F85D83@localhost>

On 14 May 2004 at 11:45, Karla Meurk wrote:

> Hi, I would like to plot a graph which sits in the background as a
> watermark with other plots in the foreground - on top.  I have looked
> through the threads on the r-project website but they seem to concern
> background colours rather than actual background plots.  I have also
> searched through the demo's and pars but can't find any eg's
> 
> any ideas - I only want to plot a simple graph using pie.chart()
> 

You can do this with the pixmap package. 
library(pixmap) and so
?pixmap
An example based on ?pixmap:

> ## Another example that math can be beautiful
>  x <- seq(-3,3,length=100)
>  z1 <- outer(x,x,function(x,y) abs(sin(x)*sin(y)))
>  z2 <- outer(x,x,function(x,y) abs(sin(2*x)*sin(y)))
>  z3 <- outer(x,x,function(x,y) abs(sin(x)*sin(2*y)))
> 
>  ## Notice that we specify a bounding box to get the correct
>  ## coordinates on the axes. z1, z2 and z3 are used as red,
>  ## green and blue channel, respectively.
>  z <- pixmapRGB(c(z1,z2,z3), 100, 100, bbox=c(-1,-1,1,1))
>  plot(z, axes=TRUE)
> par(new=TRUE)
> plot( (-20:20)/20, (-20:20)/20, xaxt="n", yaxt="n", ann=FALSE)
> 


Kjetil Halvorsen

> Thanks
> 
> Carla
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From kjetil at acelerate.com  Fri May 14 14:32:01 2004
From: kjetil at acelerate.com (kjetil@acelerate.com)
Date: Fri, 14 May 2004 08:32:01 -0400
Subject: [R] NLME model question
In-Reply-To: <5.1.0.14.2.20040514110535.00b80c70@staffmail.ed.ac.uk>
Message-ID: <40A48401.301.3F85D16@localhost>

On 14 May 2004 at 11:11, Darren Shaw wrote:

> Dear R-helpers
> 
> I have a problem related to the use of NLME
> 
> I think is simply a matter of getting the nlme coding correct, but i
> cannot get my brain around it
> 
> I am analysing some 24 growth curves of some cells , and i wanted to
> say that there are significant differences between the curves in two
> parameters that describe the pattern of growth.  these parameters are
> from a logistic (r & k) .
> 
> i have attempted to construct a self starting routine for nlme ie:
> 
> SSGrowth_function(x, r, k)
> {
>          .expr2 <- (k - 100000)/100000
>          .expr5 <- exp(((r * -1) * x))
>          .expr7 <- 1 + (.expr2 * .expr5)
>          .expr13 <- .expr7^2
>          .value <- k/.expr7
>          .actualArgs <- match.call()[c("r", "k")]
>          if(all(unlist(lapply(as.list(.actualArgs), is.name)))) {
>                  .grad <- array(0, c(length(.value), 2), list(NULL,
>                  c("r", 
> "k")))
>                  .grad[, "r"] <-  - ((k * (.expr2 * (.expr5 * (-1 *
> x))))/.expr13)
>                  .grad[, "k"] <- (1/.expr7) - ((k * (1e-005 *
>                  .expr5))/.expr13) dimnames(.grad) <- list(NULL,
>                  .actualArgs) attr(.value, "gradient") <- .grad
>          }
>          .value
> }
> 
> where x = time, 100000 = known starting conditions, r = growth and k =
> carrying capacity
> 
>   i guessed i should then write
> 
> nlme(NoofCells~SSGrowth(Time,r,k),fixed=r+k~1,data=CellData,random=r+k
> ~1)
> 
> 
> This runs and tells me that r & k's do differ
> 
> BUT.  The "CellData" actually consists of replicates - ie there are 4
> cell types, but they are done 6 times each.  Therefore, I do not want
> to ask if there are significant differences in r & k between 24 sets
> of data ("Runs")- rather I want to be able to say that there are
> differences between the four cell types occurring 6 times each.  So
> how do i  incorporate "CellType" explicitly into my model structure??

Something like
 nlme(NoofCells~SSGrowth(Time,r,k),fixed=r+k~1,data=CellData,random=r+k
 ~1 | CellType)
?

Kjetil Halvorsen

> 
> i.e. If i was lust looking at say linear growth and was using lme I
> would have written something like
> 
> lme(NoofCells~Time*CellType,random=~1|Runs,data=CellData)
> 
> Any thoughts/suggestions gratefully received
> 
> Darren Shaw
> 
> ----------------------------------------------------------------- Dr
> Darren J Shaw Centre for Tropical Veterinary Medicine (CTVM) Royal
> School of Veterinary Studies The University of Edinburgh Scotland
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Fri May 14 14:39:42 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 14 May 2004 08:39:42 -0400
Subject: [R] how add objects to an svm graphic
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7D99@usrymx25.merck.com>

You probably won't be able to do that without modifying plot.svm().  It
calls filled.contour() like this:

            filled.contour(xr, yr, matrix(as.numeric(preds), 
                nr = length(xr), byrow = TRUE), plot.axes = {
                axis(1)
                axis(2)
                colors <- as.numeric(model.response(model.frame(x, 
                  data)))
                points(formula, data = data[-x$index, ], col =
colors[-x$index])
                points(formula, data = data[x$index, ], pch = "x", 
                  col = colors[x$index])
            }, levels = 1:(length(unique(as.numeric(preds))) + 
                1), key.axes = axis(4, 1:length(unique(as.numeric(preds))) +

                0.5, labels = levels(preds)[unique(preds)], las = 3), 
                plot.title = title(main = "SVM classification plot", 
                  xlab = names(lis)[2], ylab = names(lis)[1]), 
                ...)
      

Note the elaborate `plot.axes=' argument.  You can try add another argument
to plot.svm, which takes an plotting expression, then plug that expression
to the end of the `plot.axes=' expression shown above.

[Note to David:  There's a typo in ?plot.svm (spelling for `vector').]

HTH,
Andy

> From: ale.ambrosi at unipd.it
> 
> Dear all,
> 
> I'm not able to solve easily the following simple problem. 
> I really hope someone can give me some hints.
> 
> I trained an svm (e1071). Now I'd like to show the results 
> graphically.
> I used plot.svm and I'd like to add some other objects to the plot:
> points, (coloured) ellipses to indicate some intersting 
> regions, curves, 
> and so on...
> I tried to pass these as additional graphics parameters to pass to 
> filled.contour, as indicated in ?plot.svm and in examples in
> filled.contour help.
> 
> But it doesn't seem to work.
> 
> Where is my foult? Can anyone help me? 
> 
> Best,
> Alessandro
> 
> 
> PS: I use R 1.9.0 on a WinXP OS
> 
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
> Alessandro Ambrosi, Ph.D.       |
> Oncological Surgical Sc. Dept.  | mail: ale.ambrosi at unipd.it
> Surg. Cl. II 			|       ambrosi at stat.unipd.it
> University of Padua		| fax:  +39 049 651891
> via Giustiniani, 2 		| tel:  +39 049 8212055
> I-35128 Padua (ITALY)           | url:  
> www.stat.unipd.it/~ambrosi 	    
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> 
> -------------------------------------------------
> This mail sent through IMP: webmail.unipd.it
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From feh3k at spamcop.net  Fri May 14 07:48:35 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Fri, 14 May 2004 07:48:35 +0200
Subject: [R] Export summary statistics to latex
In-Reply-To: <40A47FBB.2020107@science.uva.nl>
References: <40A47FBB.2020107@science.uva.nl>
Message-ID: <20040514074835.4e3a0ba4.feh3k@spamcop.net>

On Fri, 14 May 2004 10:13:47 +0200
Ulrich Leopold <uleopold at science.uva.nl> wrote:

> Dear list,
> 
> I would like to export the summary statistics of a regression to latex
> code. Is there an easy way of doing that?
> 
> Ulrich

Depending on the regression model and the summary statistics, you can use
the latex function in the Design package to typeset certain model fits in
algebraic notation and to get ANOVA and effect tables.  Do ?summary.Design
?latex.ols ?anova.Design for more info.

Frank Harrell

> 
> -- 
> __________________________________________________
> 
> Ulrich Leopold MSc.
> 
> Computational Bio- and Physical Geography (CBPG)
> Institute for Biodiversity and Ecosystem Dynamics (IBED)
> Faculty of Science
> University of Amsterdam
> Nieuwe Achtergracht 166
> NL-1018WV Amsterdam
> 
> Room:   B2.52
> Phone:	+31 20 525 7456 (7451 Secretary)
> Fax:	+31 20 525 7431
> Mobile:	+31 64 220 3028
> Email:	uleopold at science.uva.nl
> URL:    www.science.uva.nl/ibed/cbpg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html


---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From JLi2 at prdus.jnj.com  Fri May 14 15:30:06 2004
From: JLi2 at prdus.jnj.com (Li, James [PRDUS Non-J&J])
Date: Fri, 14 May 2004 09:30:06 -0400
Subject: [R] rma and gcrma do not work in R 1.9.0
Message-ID: <73FC8D4DCAD8D41190B300508B6980C20A14813C@rarusraexs13.prius.jnj.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040514/cae4b1c8/attachment.pl

From ruedi.epple at bluewin.ch  Fri May 14 15:39:33 2004
From: ruedi.epple at bluewin.ch (Ruedi Epple)
Date: Fri, 14 May 2004 15:39:33 +0200
Subject: [R] R-help
Message-ID: <406A6C1000161366@mssazhb-int.msg.bluewin.ch>

Hi,
I have begun to use R some months ago. I have solved many problems, but now
I do not reach my aim.
I have written a function ?Tranmer.cor? with the parameters x, y and N, which
calculates weighted correlation coefficients. It works, when I define the
parameters each time I want to run it. But I cannot tell ?Tranmer.cor? that
it works trough a whole matrix, so that I get a correlation matrix with all
the combinations of variables I have in my data.frame.
There must be a little thing that I have not checked yet.
Thanks for your advice.
Ruedi Epple

------------------------
Dr. Ruedi Epple
Stebligerweg 4
CH-4450 Sissach
061/971 67 15
ruedi.epple at bluewin.ch
ruedi.epple at bfs.admin.ch



From joehl at gmx.de  Fri May 14 15:52:06 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Fri, 14 May 2004 15:52:06 +0200 (MEST)
Subject: [R] please help with estimation of true correlations and
	reliabilities
Message-ID: <16558.1084542726@www7.gmx.net>


Dear John,

I checked for the uniquenesses from factanal() and found out that these
estimates need an a priori assumption about the number of latent factors
(and they depend strongly on that assumption). What I want is an estimate of
reliablity independent of such an assumption.  Is it possible to specify
such "structure" to sem or another SEM software? (no assumption about number
of factors, no assumptions about which variables group together).

Best regards


Jens Oehlschl??gel

--



From rossini at blindglobe.net  Fri May 14 15:34:57 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 14 May 2004 06:34:57 -0700
Subject: [R] rma and gcrma do not work in R 1.9.0
In-Reply-To: <73FC8D4DCAD8D41190B300508B6980C20A14813C@rarusraexs13.prius.jnj.com>
	(James Li's message of "Fri, 14 May 2004 09:30:06 -0400")
References: <73FC8D4DCAD8D41190B300508B6980C20A14813C@rarusraexs13.prius.jnj.com>
Message-ID: <853c63rv26.fsf@servant.blindglobe.net>


This is a bioconductor issue, and better suited for that list.

"Li, James [PRDUS Non-J&J]" <JLi2 at prdus.jnj.com> writes:

> I run R 1.9.0 on windows 2000, and have the following libraries installed:
>
> affydata_1.3.1
> affy_1.4.23
> Biobase_1.4.10
> DynDoc_1.3.14
> gcrma_1.0.6
> hgu133acdf_1.4.3
> hgu95av2cdf_1.4.3
> hgu95av2probe_1.0
> matchprobes_1.0.7
> moe430acdf_1.4.3
> multcomp_0.4-6
> mvtnorm_0.6-6
> rae230acdf_1.4.3
> reposTools_1.3.29
> rgu34acdf_1.4.3
> tkWidgets_1.5.1
> widgetTools_1.2.7
>
> 1. The rma function (in affy library) always crashes.
> 2. When executing the sample code in gcrma function's document, the
> following error occures:
> 	Loading required package: matchprobes 
> 	Error in f(libname, pkgname) : couldn't find function
> "addVigs2WinMenu"
>
> Does any one known any quick fix or workaround?
>
> James
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From ripley at stats.ox.ac.uk  Fri May 14 15:54:47 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 May 2004 14:54:47 +0100 (BST)
Subject: [R] rma and gcrma do not work in R 1.9.0
In-Reply-To: <73FC8D4DCAD8D41190B300508B6980C20A14813C@rarusraexs13.prius.jnj.com>
Message-ID: <Pine.LNX.4.44.0405141448190.22442-100000@gannet.stats>

Isn't this a report on problems with Bioconductor packages?  If so, please
ask the Bioconductor list as people there will have a much better idea of
what you are trying to do.

On Fri, 14 May 2004, Li, James [PRDUS Non-J&J] wrote:

> I run R 1.9.0 on windows 2000, and have the following libraries installed:

...

> 1. The rma function (in affy library) always crashes.
> 2. When executing the sample code in gcrma function's document, the
> following error occures:
> 	Loading required package: matchprobes 
> 	Error in f(libname, pkgname) : couldn't find function
> "addVigs2WinMenu"

Do take a look at what the R posting guide says about `crashes', though.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Fri May 14 16:16:50 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 14 May 2004 14:16:50 +0000 (UTC)
Subject: [R] R-help
References: <406A6C1000161366@mssazhb-int.msg.bluewin.ch>
Message-ID: <loom.20040514T160134-146@post.gmane.org>


If you want pairwise correlations for the cols of matrix x and N
is some parameter to your routine that does not vary throughout
the calculation then:

apply(x,2,function(a)apply(x,2,function(b)Transmer.cor(a,b,N)))

Replace both occurrences of 2 with 1 if you want rows.

Ruedi Epple <ruedi.epple <at> bluewin.ch> writes:

: 
: Hi,
: I have begun to use R some months ago. I have solved many problems, but now
: I do not reach my aim.
: I have written a function ?Tranmer.cor? with the parameters x, y and N, which
: calculates weighted correlation coefficients. It works, when I define the
: parameters each time I want to run it. But I cannot tell ?Tranmer.cor? that
: it works trough a whole matrix, so that I get a correlation matrix with all
: the combinations of variables I have in my data.frame.
: There must be a little thing that I have not checked yet.
: Thanks for your advice.
: Ruedi Epple
: 
: ------------------------
: Dr. Ruedi Epple
: Stebligerweg 4
: CH-4450 Sissach
: 061/971 67 15
: ruedi.epple <at> bluewin.ch
: ruedi.epple <at> bfs.admin.ch
:



From ivo.welch at yale.edu  Fri May 14 16:22:31 2004
From: ivo.welch at yale.edu (ivo welch)
Date: Fri, 14 May 2004 10:22:31 -0400
Subject: [R] type checking --- just a thought
Message-ID: <40A4D627.7050707@yale.edu>


hi:  would it be useful to build into R an optional mechanism that 
typechecks arguments?  for example,

    sum.across <- function (  inpmatrix : matrixtype( dim[1]>1, dim[2]>3 
) ) : vector { }
       # this would define a sum.across function that can take matrices 
or data sets, but not vectors,
       # and which indicates that it will return a vector.

    xsum <- sum.across( 1:10 );  # error

    repeat <- function( series : vector( dim>0 ),  times : scalar( 
value>0 ) ) : vector;

similarly, a common input error condition may be calling a function with 
a NULL vector, or with a vector with fewer than N observations.  many 
statistical functions have such hard-wired limits.  I know that "if" 
statements can do this, but this might make for a nice standardized 
language feature.  on the other hand, the effort and complexity may not 
be worth the extra functionality.

and one beg to the language maintainers for something that I hope is simple:

    in R 1.8.2, please add to the "source" function information where 
(file:linenumber) dies or ends.

regards,

/ivo



From song.baiyi at udo.edu  Fri May 14 16:28:34 2004
From: song.baiyi at udo.edu (Song Baiyi)
Date: Fri, 14 May 2004 16:28:34 +0200
Subject: [R] A question about default output on the screen 
Message-ID: <40A4D792.3030805@udo.edu>

Hello everyone,


I got a problem to change the default output on the screen and I use 
Xemacs ESS and R.

When I happen to show a data.frame with thousands of records (type a 
variable name and return), the screen just freeze or keep scrolling for 
minutes, because of the large quantity of records.

Therefore I decide to write a more clever "show" method, which will 
check the number of items to print on the screen. If there are too many 
records, it will just prompt a warning message and return. How can I do 
it? I tried it setMethod("show","ANY", 
function(object){....;standerdGenetic("show");}), but it did not work.

Can anyone give me some ideas?

Thanks in advance




Baiyi Song
LS fr. Datenverarbeitungssysteme | Tel. +49 231-755-7009
Universit??t Dortmund            
44221 Dortmund / Germany



From matthew_wiener at merck.com  Fri May 14 16:43:46 2004
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Fri, 14 May 2004 10:43:46 -0400
Subject: [R] type checking --- just a thought
Message-ID: <45AAE6FD142DCB43A38C00A11FF5DF3EE36202@uswsmx03.merck.com>

Ivo --

The "stopifnot" statement can be used to do this sort of check.  For
example, if you need to check that one of your arguments is a vector with
length >= N, you can add

stopifnot(is.vector(myarg))
stopifnot(length(myarg) >= N)

To the beginning of your function.  This will throw an error if one of the
conditions is not met.  The rest of your conditions can be checked
similarly.

Hope this helps,

Matt Wiener



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of ivo welch
Sent: Friday, May 14, 2004 10:23 AM
To: r-help at stat.math.ethz.ch
Subject: [R] type checking --- just a thought



hi:  would it be useful to build into R an optional mechanism that 
typechecks arguments?  for example,

    sum.across <- function (  inpmatrix : matrixtype( dim[1]>1, dim[2]>3 
) ) : vector { }
       # this would define a sum.across function that can take matrices 
or data sets, but not vectors,
       # and which indicates that it will return a vector.

    xsum <- sum.across( 1:10 );  # error

    repeat <- function( series : vector( dim>0 ),  times : scalar( 
value>0 ) ) : vector;

similarly, a common input error condition may be calling a function with 
a NULL vector, or with a vector with fewer than N observations.  many 
statistical functions have such hard-wired limits.  I know that "if" 
statements can do this, but this might make for a nice standardized 
language feature.  on the other hand, the effort and complexity may not 
be worth the extra functionality.

and one beg to the language maintainers for something that I hope is simple:

    in R 1.8.2, please add to the "source" function information where 
(file:linenumber) dies or ends.

regards,

/ivo

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Fri May 14 16:53:47 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 14 May 2004 14:53:47 +0000 (UTC)
Subject: [R] type checking --- just a thought
References: <45AAE6FD142DCB43A38C00A11FF5DF3EE36202@uswsmx03.merck.com>
Message-ID: <loom.20040514T164747-439@post.gmane.org>


If its just arg 1 then you can use S3 generics for this.  Here it is
but we have extended it to data frames too which isn't so easy
if you can only specify one type:

sum.across <- function(x) UseMethod("sum.across")
sum.across.matrix <- function(x) { stopifnot(is.numeric(x)); c(rowMeans(x)) }
sum.across.data.frame <- function(x) 
                           c(sum.across(as.matrix(x[,sapply(x,is.numeric)])))

# test
z1 <- sum.across(matrix(1:4,2))  
data(iris); z2 <- sum.across(iris)   
z3 <- sum.across(1:2) # error
z4 <- sum.across(letters) # error

Also note use of stopifnot in sum.across.matrix .

ivo welch <ivo.welch <at> yale.edu> writes:

: 
: hi:  would it be useful to build into R an optional mechanism that 
: typechecks arguments?  for example,
: 
:     sum.across <- function (  inpmatrix : matrixtype( dim[1]>1, dim[2]>3 
: ) ) : vector { }
:        # this would define a sum.across function that can take matrices 
: or data sets, but not vectors,
:        # and which indicates that it will return a vector.
: 
:     xsum <- sum.across( 1:10 );  # error
: 
:     repeat <- function( series : vector( dim>0 ),  times : scalar( 
: value>0 ) ) : vector;
: 
: similarly, a common input error condition may be calling a function with 
: a NULL vector, or with a vector with fewer than N observations.  many 
: statistical functions have such hard-wired limits.  I know that "if" 
: statements can do this, but this might make for a nice standardized 
: language feature.  on the other hand, the effort and complexity may not 
: be worth the extra functionality.
: 
: and one beg to the language maintainers for something that I hope is simple:
: 
:     in R 1.8.2, please add to the "source" function information where 
: (file:linenumber) dies or ends.
: 
: regards,
: 
: /ivo



From mrufino at cmima.csic.es  Fri May 14 16:54:51 2004
From: mrufino at cmima.csic.es (mrufino@cmima.csic.es)
Date: Fri, 14 May 2004 16:54:51 +0200
Subject: [R] covariates in lm
Message-ID: <1084546491.40a4ddbbe10da@webmail.cmima.csic.es>

Dear R list,

I have been trying to do a linear model, extracting the effect of a 
covariate.... and the results do not match, when I do it with other programs 
(e.g. minitab).... so it is obvious that I was doing something wrong.

Whan  I do it with minitab, I have this results: (sector is a factor and depth 
is the covariate):

Source         DF     Seq SS     Adj SS     Adj MS       F      P
sector          6     9.0605     2.9989     0.4998    1.21  0.297
depth           1    34.2072    11.9973    11.9973   29.16  0.000
sector*depth    6     1.5364     1.5364     0.2561    0.62  0.712
Error         578   237.7830   237.7830     0.4114
Total         591   282.5871  


If I do with R, I have been trying everything it occurrs to me and looked 
everywhere and I could not obtain the same results and nothing is clear to 
me... (I am so sorry... probably it is lack of statistical knowledge):

If I do:
> anova(lm(Expr1~depth*sector))
Analysis of Variance Table

Response: Expr1
              Df Sum Sq Mean Sq F value Pr(>F)    
depth          1   38.2    38.2   92.76 <2e-16 ***
sector         6    5.1     0.9    2.07  0.055 .  
depth:sector   6    1.5     0.3    0.62  0.712    
Residuals    578  237.8     0.4                   

I am simply fitting a crossed anova, or because depth is continuos ... what is 
it doing?

then, as it was not right, I went to look in the manuals, and in 'an 
introduction to R' states:
y ~ A + x Single classification analysis of covariance model of y, with classes 
determined by A, and with covariate x. Is it like this?
> anova(lm(Expr1~sector+depth)) #I don't think so...

But I interpreted this as a additive model... and besides it did not work as 
well, so I tried what a friend recomended, i.e. x:z, whereas we are extacting 
the effect of x (covariate) on y... but it does not work as well...
> anova(lm(Expr1~sector+depth+depth:sector)) # Would it be like this?
Analysis of Variance Table

Response: Expr1
              Df Sum Sq Mean Sq F value Pr(>F)    
sector         6    9.1     1.5    3.67 0.0014 ** 
depth          1   34.2    34.2   83.15 <2e-16 ***
sector:depth   6    1.5     0.3    0.62 0.7124    
Residuals    578  237.8     0.4                   
-
or like:  anova(lm(Expr1~depth:depth*sector))


I am lost... in the other times I just did with minitab, but I realy wanted to 
do it with R... can someone give me some lights?
Is it very difficult to do it with R?
Sorry for the long and messy email,

thank you very much in advance,
Marta



From andy_liaw at merck.com  Fri May 14 17:06:27 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 14 May 2004 11:06:27 -0400
Subject: [R] covariates in lm
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7DA1@usrymx25.merck.com>

>From the output you've shown, Minitab and R give the same thing when you ask
for the same thing.  In Minitab,

> Source         DF     Seq SS     Adj SS     Adj MS       F      P
> sector          6     9.0605     2.9989     0.4998    1.21  0.297
> depth           1    34.2072    11.9973    11.9973   29.16  0.000
> sector*depth    6     1.5364     1.5364     0.2561    0.62  0.712
> Error         578   237.7830   237.7830     0.4114
> Total         591   282.5871  

In R:

> Response: Expr1
>               Df Sum Sq Mean Sq F value Pr(>F)    
> sector         6    9.1     1.5    3.67 0.0014 ** 
> depth          1   34.2    34.2   83.15 <2e-16 ***
> sector:depth   6    1.5     0.3    0.62 0.7124    
> Residuals    578  237.8     0.4                   

Note the R output matches the `Seq SS' in Minitab, because that's what R
says it does: sequential tests.  By `Adj. SS' and associated tests, I guess
Minitab meant `adjusting for other terms in the model'.  If so, use drop1().

HTH,
Andy

> From: mrufino at cmima.csic.es
> 
> Dear R list,
> 
> I have been trying to do a linear model, extracting the effect of a 
> covariate.... and the results do not match, when I do it with 
> other programs 
> (e.g. minitab).... so it is obvious that I was doing something wrong.
> 
> Whan  I do it with minitab, I have this results: (sector is a 
> factor and depth 
> is the covariate):
> 
> Source         DF     Seq SS     Adj SS     Adj MS       F      P
> sector          6     9.0605     2.9989     0.4998    1.21  0.297
> depth           1    34.2072    11.9973    11.9973   29.16  0.000
> sector*depth    6     1.5364     1.5364     0.2561    0.62  0.712
> Error         578   237.7830   237.7830     0.4114
> Total         591   282.5871  
> 
> 
> If I do with R, I have been trying everything it occurrs to 
> me and looked 
> everywhere and I could not obtain the same results and 
> nothing is clear to 
> me... (I am so sorry... probably it is lack of statistical knowledge):
> 
> If I do:
> > anova(lm(Expr1~depth*sector))
> Analysis of Variance Table
> 
> Response: Expr1
>               Df Sum Sq Mean Sq F value Pr(>F)    
> depth          1   38.2    38.2   92.76 <2e-16 ***
> sector         6    5.1     0.9    2.07  0.055 .  
> depth:sector   6    1.5     0.3    0.62  0.712    
> Residuals    578  237.8     0.4                   
> 
> I am simply fitting a crossed anova, or because depth is 
> continuos ... what is 
> it doing?
> 
> then, as it was not right, I went to look in the manuals, and in 'an 
> introduction to R' states:
> y ~ A + x Single classification analysis of covariance model 
> of y, with classes 
> determined by A, and with covariate x. Is it like this?
> > anova(lm(Expr1~sector+depth)) #I don't think so...
> 
> But I interpreted this as a additive model... and besides it 
> did not work as 
> well, so I tried what a friend recomended, i.e. x:z, whereas 
> we are extacting 
> the effect of x (covariate) on y... but it does not work as well...
> > anova(lm(Expr1~sector+depth+depth:sector)) # Would it be like this?
> Analysis of Variance Table
> 
> Response: Expr1
>               Df Sum Sq Mean Sq F value Pr(>F)    
> sector         6    9.1     1.5    3.67 0.0014 ** 
> depth          1   34.2    34.2   83.15 <2e-16 ***
> sector:depth   6    1.5     0.3    0.62 0.7124    
> Residuals    578  237.8     0.4                   
> -
> or like:  anova(lm(Expr1~depth:depth*sector))
> 
> 
> I am lost... in the other times I just did with minitab, but 
> I realy wanted to 
> do it with R... can someone give me some lights?
> Is it very difficult to do it with R?
> Sorry for the long and messy email,
> 
> thank you very much in advance,
> Marta
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From nlwhitehouse at yahoo.com  Fri May 14 17:44:21 2004
From: nlwhitehouse at yahoo.com (Nathan Whitehouse)
Date: Fri, 14 May 2004 08:44:21 -0700 (PDT)
Subject: [R] Re: R web servers
Message-ID: <20040514154421.24259.qmail@web12402.mail.yahoo.com>

Hi,

  On the basis of a couple of supportive e-mails,
we've set up a page listing the R web 'servers'
similar to Philippe Grosjean's R-GUI site.
 
http://franklin.imgen.bcm.tmc.edu/R.web.servers/index.html

  If people are keen, we'd be happy to provide it or
have it linked from R-project.  
  
  It's skinny now, but more can be added.

  If we've missed any projects, please tell us.

  Best,
  Nathan Whitehouse
  Shaw laboratory

=====
Nathan Whitehouse
Statistics/Programming
Baylor College of Medicine
Houston, TX, USA
nlwhitehouse at yahoo.com
work: 1-713-798-9029
cell:    1-512-293-5840

http://rho-project.org: rho- open source web services for R.
http://franklin.imgen.bcm.tmc.edu: Shaw laboratory, bcm.



From ripley at stats.ox.ac.uk  Fri May 14 17:48:44 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 May 2004 16:48:44 +0100 (BST)
Subject: [R] A question about default output on the screen 
In-Reply-To: <40A4D792.3030805@udo.edu>
Message-ID: <Pine.LNX.4.44.0405141646420.22593-100000@gannet.stats>

But R does not call show() to print, it calls print() unless you have an
object with a formal class.  You can try setting a new data.frame method
for print, but an S3 method, please.

On Fri, 14 May 2004, Song Baiyi wrote:

> I got a problem to change the default output on the screen and I use 
> Xemacs ESS and R.
> 
> When I happen to show a data.frame with thousands of records (type a 
> variable name and return), the screen just freeze or keep scrolling for 
> minutes, because of the large quantity of records.
> 
> Therefore I decide to write a more clever "show" method, which will 
> check the number of items to print on the screen. If there are too many 
> records, it will just prompt a warning message and return. How can I do 
> it? I tried it setMethod("show","ANY", 
> function(object){....;standerdGenetic("show");}), but it did not work.
> 
> Can anyone give me some ideas?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rossini at blindglobe.net  Fri May 14 17:36:26 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 14 May 2004 08:36:26 -0700
Subject: [R] type checking --- just a thought
In-Reply-To: <40A4D627.7050707@yale.edu> (ivo welch's message of "Fri, 14
	May 2004 10:22:31 -0400")
References: <40A4D627.7050707@yale.edu>
Message-ID: <85n04b3ts5.fsf@servant.blindglobe.net>


S4 methods take care of some of this checking (more specification
needed). 

best,
-tony

ivo welch <ivo.welch at yale.edu> writes:

> hi:  would it be useful to build into R an optional mechanism that
> typechecks arguments?  for example,
>
>     sum.across <- function (  inpmatrix : matrixtype( dim[1]>1,
>     dim[2]>3 ) ) : vector { }
>        # this would define a sum.across function that can take
>        # matrices or data sets, but not vectors,
>        # and which indicates that it will return a vector.
>
>     xsum <- sum.across( 1:10 );  # error
>
>     repeat <- function( series : vector( dim>0 ),  times : scalar(
>     value>0 ) ) : vector;
>
> similarly, a common input error condition may be calling a function
> with a NULL vector, or with a vector with fewer than N observations.
> many statistical functions have such hard-wired limits.  I know that
> "if" statements can do this, but this might make for a nice
> standardized language feature.  on the other hand, the effort and
> complexity may not be worth the extra functionality.
>
> and one beg to the language maintainers for something that I hope is simple:
>
>     in R 1.8.2, please add to the "source" function information where
>     (file:linenumber) dies or ends.
>
> regards,
>
> /ivo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From Jonathan.Swinton at astrazeneca.com  Fri May 14 18:03:01 2004
From: Jonathan.Swinton at astrazeneca.com (Swinton, Jonathan)
Date: Fri, 14 May 2004 17:03:01 +0100
Subject: [R] RE: How to write an S4 method for sum or a Summary generic
Message-ID: <FCA5F290CE7FFD42A6F1515497B0F0A204362211@ukapphresmsx02.ukapd.astrazeneca.net>


I asked a couple of weeks ago about how to write an S4 method for sum, or
another member of the Summary group generics. This prompted an informed and
somewhat over my head email discussion off list, but for the benefit of
posterity the current answer is

1) Redefine the generic for sum as follows:
-----------
setGeneric("sum", function(x, ..., na.rm = FALSE)
standardGeneric("sum"),group="Summary", 
   useAsDefault = function(x, ..., na.rm = FALSE) .Internal(sum(x, ...,na.rm
= na.rm)))
-----------
2) This allows the following to work as expected 
----------
setClass("Foo", representation(a="numeric"))
aFoo <- new("Foo", a=c(1,NA))

setMethod("Summary", "Foo",
          function(x, ..., na.rm = FALSE) {
              cat("Foo method\n")
              callGeneric(x at a, ..., na.rm = na.rm)
          })

sum(aFoo)
sum(aFoo, na.rm=TRUE)
----------

Without step 1)  this does not work in R 1.9.0 but is reported to work in
S-Plus 6.2.

3) Repeat for each other Summary group generic you wish to write a method
for. 

Thanks to Brian Ripley and John Chambers for taking the time on this.


Jonathan Swinton, Statistical Scientist, Computational Biology, Pathways,
Global Sciences and Information, AstraZeneca, Alderley Park, Cheshire SK10
4TG UK



From p.dalgaard at biostat.ku.dk  Fri May 14 18:12:28 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 May 2004 18:12:28 +0200
Subject: [R] type checking --- just a thought
In-Reply-To: <40A4D627.7050707@yale.edu>
References: <40A4D627.7050707@yale.edu>
Message-ID: <x265azt2c3.fsf@biostat.ku.dk>

ivo welch <ivo.welch at yale.edu> writes:

> and one beg to the language maintainers for something that I hope is simple:
> 
>     in R 1.8.2, please add to the "source" function information where
> (file:linenumber) dies or ends.

It's not simple because it is not a simple line-by-line evaluation.
The whole file is parsed and the resulting code then executed, by
which time the line information has been lost. If you can come up with
a well thought out scheme for retaining it, patches might be
considered. (There's not much chance of getting an R 1.8.2, though.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Philippe.Hupe at curie.fr  Fri May 14 18:37:37 2004
From: Philippe.Hupe at curie.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Fri, 14 May 2004 18:37:37 +0200
Subject: [R] problem with aggregate
In-Reply-To: <40BB9383.19485.294ACD0@localhost>
References: <40BB9383.19485.294ACD0@localhost>
Message-ID: <40A4F5D1.3030900@curie.fr>

Hi,

I am trying to do the following  aggregation :


 data <- data.frame(a=rep(2,10),b=rep("a",10))
 aggregate(data$a, by=list(a1=data$a, b1=data$b), NROW)

but I have the following error message


Error in "names<-.default"(`*tmp*`, value = c(names(by), names(x))) :
        names attribute [3] must be the same length as the vector [2]
In addition: Warning message:
row names were found from a short variable and have been discarded in: 
data.frame(w, lapply(y, unlist, use.names = FALSE))

It works if there are more than 2 modalities in data$b. I can test if 
there is only one modality of course but there is no reason for the 
function not working in this particular case.


I use R 1.9.0 under Solaris

-- 
Philippe Hup??
UMR 144 - Service Bioinformatique
Institut Curie
Laboratoire de Transfert (4??me ??tage)
26 rue d'Ulm
75005 Paris - France
 	
Email :  Philippe.Hupe at curie.fr
T??l :	 +33 (0)1 44 32 42 75
Fax :  	 +33 (0)1 42 34 65 28



From monica.palaseanu-lovejoy at stud.man.ac.uk  Fri May 14 19:11:55 2004
From: monica.palaseanu-lovejoy at stud.man.ac.uk (Monica Palaseanu-Lovejoy)
Date: Fri, 14 May 2004 18:11:55 +0100
Subject: [R] log Y scales for parplot
Message-ID: <E1BOgEF-000Oyy-Ir@serenity.mcc.ac.uk>

Hi,

I am doing a barplot, and the fist bar is very big (high values) and 
the rest of the bars are quite small (small values). So - is there any 
way to make the  Y scale logarithmic so that i have a wider 
distance from 0 to 50 for example than for 50 to 100, and so on? 

Thanks in advance for any help,

Monica



From Max_Kuhn at bd.com  Fri May 14 19:31:36 2004
From: Max_Kuhn at bd.com (Max_Kuhn@bd.com)
Date: Fri, 14 May 2004 13:31:36 -0400
Subject: [R] variable selection methods for SVMs
Message-ID: <OF7D4079D0.3DF5B654-ON85256E94.0060170C@bd.com>

Hi,

Has anyone implemented techniques for model selection in support vector
machines in R? I have seen recursive feature wrappers and other methods in
the literature, but I can't find implementations.

Thanks in advance,

Max Kuhn
BD Diagnostic Systems




-----------------------------------------
This message is intended only for the designated recipient(s...{{dropped}}



From ripley at stats.ox.ac.uk  Fri May 14 20:09:36 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 May 2004 19:09:36 +0100 (BST)
Subject: [R] problem with aggregate
In-Reply-To: <40A4F5D1.3030900@curie.fr>
Message-ID: <Pine.LNX.4.44.0405141904500.22838-100000@gannet.stats>

Someone forgot drop=FALSE was needed.  Fixed in R-patched.

BTW, calling an object `data' is not a good idea.

On Fri, 14 May 2004, Philippe Hup?? wrote:

> Hi,
> 
> I am trying to do the following  aggregation :
> 
> 
>  data <- data.frame(a=rep(2,10),b=rep("a",10))
>  aggregate(data$a, by=list(a1=data$a, b1=data$b), NROW)
> 
> but I have the following error message
> 
> 
> Error in "names<-.default"(`*tmp*`, value = c(names(by), names(x))) :
>         names attribute [3] must be the same length as the vector [2]
> In addition: Warning message:
> row names were found from a short variable and have been discarded in: 
> data.frame(w, lapply(y, unlist, use.names = FALSE))
> 
> It works if there are more than 2 modalities in data$b. I can test if 
> there is only one modality of course but there is no reason for the 
> function not working in this particular case.
> 
> 
> I use R 1.9.0 under Solaris
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From scott.waichler at pnl.gov  Fri May 14 20:40:05 2004
From: scott.waichler at pnl.gov (Scott Waichler)
Date: Fri, 14 May 2004 11:40:05 -0700
Subject: [R] Tagging identical rows of a matrix
Message-ID: <200405141840.i4EIe5i09818@snow.pnl.gov>

I would like to generate a vector having the same length
as the number of rows in a matrix.  The vector should contain
an integer indicating the "group" of the row, where identical
matrix rows are in a group, and a unique row has a unique integer.
Thus, for

a <- c(1,2)
b <- c(1,3)
c <- c(1,2)
d <- c(1,2)
e <- c(1,3)
f <- c(2,1)
mat <- rbind(a,b,c,d,e,f)

I would like to get the vector c(1,2,1,1,2,3).  I know dist() gives
part of the answer, but I can't figure out how to use it for
this purpose without doing a lot of looping.  I need to apply this
to matrices up to ~100000 rows.

Thanks,
Scott Waichler
Pacific Northwest National Laboratory
scott.waichler_at_pnl.gov



From jfox at mcmaster.ca  Fri May 14 20:40:42 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 14 May 2004 14:40:42 -0400
Subject: [R] please help with estimation of true correlations and
	reliabilities
In-Reply-To: <16558.1084542726@www7.gmx.net>
Message-ID: <20040514184040.JLGA8285.tomts5-srv.bellnexxia.net@JohnDesktop8300>

Dear Jens,

One of the nice features of maximum-likelihood factor analysis, implemented
in factanal(), is that you can test for the number of common factors.

More generally, the estimated uniquenesses will depend upon the number of
common factors. Using sem() requires a stronger initial specification -- not
only the number of common factors, but a prior specification of which
variables load on each. If you make the model too general, it won't be
identified.

Furthermore, although I suggested that you use the uniquenesses to assess
unreliability, the justification for this is clearest in models in which
each variable loads on just one factor. I guess it would help to know a bit
more about the application.

Regards,
 John

> -----Original Message-----
> From: Jens Oehlschl??gel [mailto:joehl at gmx.de] 
> Sent: Friday, May 14, 2004 8:52 AM
> To: jfox at mcmaster.ca
> Cc: r-help at hypatia.math.ethz.ch
> Subject: Re: [R] please help with estimation of true 
> correlations and reliabilities
> 
> 
> Dear John,
> 
> I checked for the uniquenesses from factanal() and found out 
> that these estimates need an a priori assumption about the 
> number of latent factors (and they depend strongly on that 
> assumption). What I want is an estimate of reliablity 
> independent of such an assumption.  Is it possible to specify 
> such "structure" to sem or another SEM software? (no 
> assumption about number of factors, no assumptions about 
> which variables group together).
> 
> Best regards
> 
> 
> Jens Oehlschl??gel
>



From andy_liaw at merck.com  Fri May 14 20:50:41 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 14 May 2004 14:50:41 -0400
Subject: [R] Tagging identical rows of a matrix
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7DA3@usrymx25.merck.com>

Here's one possibility:

> index <- as.numeric(factor(apply(mat, 1, paste, collapse=":")))
> index
[1] 1 2 1 1 2 3


There's probably some better way though...

Andy

> From: Scott Waichler
> 
> I would like to generate a vector having the same length
> as the number of rows in a matrix.  The vector should contain
> an integer indicating the "group" of the row, where identical
> matrix rows are in a group, and a unique row has a unique integer.
> Thus, for
> 
> a <- c(1,2)
> b <- c(1,3)
> c <- c(1,2)
> d <- c(1,2)
> e <- c(1,3)
> f <- c(2,1)
> mat <- rbind(a,b,c,d,e,f)
> 
> I would like to get the vector c(1,2,1,1,2,3).  I know dist() gives
> part of the answer, but I can't figure out how to use it for
> this purpose without doing a lot of looping.  I need to apply this
> to matrices up to ~100000 rows.
> 
> Thanks,
> Scott Waichler
> Pacific Northwest National Laboratory
> scott.waichler_at_pnl.gov
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From bates at stat.wisc.edu  Fri May 14 20:52:59 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 14 May 2004 13:52:59 -0500
Subject: [R] Tagging identical rows of a matrix
In-Reply-To: <200405141840.i4EIe5i09818@snow.pnl.gov>
References: <200405141840.i4EIe5i09818@snow.pnl.gov>
Message-ID: <6r1xlmj0xg.fsf@bates4.stat.wisc.edu>

Scott Waichler <scott.waichler at pnl.gov> writes:

> I would like to generate a vector having the same length
> as the number of rows in a matrix.  The vector should contain
> an integer indicating the "group" of the row, where identical
> matrix rows are in a group, and a unique row has a unique integer.
> Thus, for
> 
> a <- c(1,2)
> b <- c(1,3)
> c <- c(1,2)
> d <- c(1,2)
> e <- c(1,3)
> f <- c(2,1)
> mat <- rbind(a,b,c,d,e,f)
> 
> I would like to get the vector c(1,2,1,1,2,3).  I know dist() gives
> part of the answer, but I can't figure out how to use it for
> this purpose without doing a lot of looping.  I need to apply this
> to matrices up to ~100000 rows.

I believe you want to start with unique which, when applied to a
matrix, provides the unique rows.

> unique(mat)
  [,1] [,2]
a    1    2
b    1    3
f    2    1

I'm sure others will be able to provide clever ways of doing the
matching against the unique rows.



From ripley at stats.ox.ac.uk  Fri May 14 21:23:43 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 May 2004 20:23:43 +0100 (BST)
Subject: [R] Tagging identical rows of a matrix
In-Reply-To: <6r1xlmj0xg.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0405142020120.22985-100000@gannet.stats>

The trick is to collapse the rows, as Andy Liaw pointed out and
unique.matrix (and .data.frame) does.  Once you have the collapsed rows as
character vectors, unique and match will do a fast job (via internal
hashing). (Andy's solution via factor() is the same thing with a bit of
extra baggage.)

On 14 May 2004, Douglas Bates wrote:

> Scott Waichler <scott.waichler at pnl.gov> writes:
> 
> > I would like to generate a vector having the same length
> > as the number of rows in a matrix.  The vector should contain
> > an integer indicating the "group" of the row, where identical
> > matrix rows are in a group, and a unique row has a unique integer.
> > Thus, for
> > 
> > a <- c(1,2)
> > b <- c(1,3)
> > c <- c(1,2)
> > d <- c(1,2)
> > e <- c(1,3)
> > f <- c(2,1)
> > mat <- rbind(a,b,c,d,e,f)
> > 
> > I would like to get the vector c(1,2,1,1,2,3).  I know dist() gives
> > part of the answer, but I can't figure out how to use it for
> > this purpose without doing a lot of looping.  I need to apply this
> > to matrices up to ~100000 rows.
> 
> I believe you want to start with unique which, when applied to a
> matrix, provides the unique rows.
> 
> > unique(mat)
>   [,1] [,2]
> a    1    2
> b    1    3
> f    2    1
> 
> I'm sure others will be able to provide clever ways of doing the
> matching against the unique rows.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Fri May 14 21:47:56 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 14 May 2004 19:47:56 +0000 (UTC)
Subject: [R] Tagging identical rows of a matrix
References: <200405141840.i4EIe5i09818@snow.pnl.gov>
Message-ID: <loom.20040514T210853-410@post.gmane.org>



The shortest expression I can think of is:

as.numeric(interaction(mat[,1],mat[,2],drop=T))

Completing the thought of those who suggested dist or
unique:

N <- nrow(mat)
dd <- as.matrix(dist(rbind(mat,unique(mat))))[-seq(N),seq(N)]
apply(dd,2,function(x)match(0,x))


Scott Waichler <scott.waichler <at> pnl.gov> writes:

: 
: I would like to generate a vector having the same length
: as the number of rows in a matrix.  The vector should contain
: an integer indicating the "group" of the row, where identical
: matrix rows are in a group, and a unique row has a unique integer.
: Thus, for
: 
: a <- c(1,2)
: b <- c(1,3)
: c <- c(1,2)
: d <- c(1,2)
: e <- c(1,3)
: f <- c(2,1)
: mat <- rbind(a,b,c,d,e,f)
: 
: I would like to get the vector c(1,2,1,1,2,3).  I know dist() gives
: part of the answer, but I can't figure out how to use it for
: this purpose without doing a lot of looping.  I need to apply this
: to matrices up to ~100000 rows.
: 
: Thanks,
: Scott Waichler
: Pacific Northwest National Laboratory
: scott.waichler_at_pnl.gov



From HStevens at MUOhio.edu  Fri May 14 22:04:31 2004
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Fri, 14 May 2004 16:04:31 -0400
Subject: [R] Work around for TukeyHSD names
Message-ID: <E9F469E2-A5E1-11D8-941E-000A958F43CC@MUOhio.edu>

R Version 2.0.0 Under development (unstable) (2004-05-07)
I have been wanting to use TukeyHSD for two and three way aov's, as 
they are especially simple for students to use correctly. I realize 
model simplification is usually a preferred methodology, but my 
disciplinary enertia and simplicity of TukeyHSD is also compelling.
However, the lack of names on the comparisons for the higher order 
interactions has frustrated us. Here I present a simple, if clumsy 
work-around to provide names for both the tabluar and plot outputs.

ANY FEEDBACK would be appreciated.

My work-around example:

data(warpbreaks)
fm1 <- aov(breaks ~ wool * tension, data = warpbreaks)

a <- TukeyHSD(fm1, "wool:tension") ; a # Gives unlabeled differences

wt <- warpbreaks$tension:warpbreaks$wool # Creates interaction term 
with the correct order of comparisons

b <-TukeyHSD(aov(breaks~wt,warpbreaks))) # Correctly labels differences 
, but provides differences that, I think, are slightly inaccurate.

rowames(a) <- rownames(b) # Provides rownames for the correct 
differences

par(mar=c(5,10,4,2)+0.1)
plot(a, las=1) # Puts correct labels on differences.

Thanks for any comments,
Hank Stevens



Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/



From Scott.Waichler at pnl.gov  Fri May 14 22:12:08 2004
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Fri, 14 May 2004 13:12:08 -0700
Subject: [R] Tagging identical rows of a matrix
Message-ID: <62AE0CF1D4875C4BBDEC29DB9924ACE87F21DB@pnlmse25.pnl.gov>


Thanks to all of you who responded to my help request.
Here is the very efficient upshot of your advice:

> mat2 <- apply(mat, 1, paste, collapse=":")
> vec <- match(mat2, unique(mat2))
> vec
[1] 1 2 1 1 2 3


P.S.  I found that Andy Liaw's method didn't preserve the
index order that I wanted; it yields

2 3 2 2 3 1

To get the order of integers I was looking for required an
invocation of unique:

as.numeric(factor(apply(mat, 1, paste, collapse=":"),
                  levels=unique(apply(mat, 1, paste, collapse=":"))))

But the first method above is obviously cleaner and is twice
as fast, only 9 seconds for a 100000 row matrix on an ordinary PC.  

Regards,
Scott Waichler

> > I would like to generate a vector having the same length
> > as the number of rows in a matrix.  The vector should contain an 
> > integer indicating the "group" of the row, where identical 
> matrix rows 
> > are in a group, and a unique row has a unique integer. Thus, for
> >
> > a <- c(1,2)
> > b <- c(1,3)
> > c <- c(1,2)
> > d <- c(1,2)
> > e <- c(1,3)
> > f <- c(2,1)
> > mat <- rbind(a,b,c,d,e,f)
> >
> > I would like to get the vector c(1,2,1,1,2,3).  I know dist() gives 
> > part of the answer, but I can't figure out how to use it for this 
> > purpose without doing a lot of looping.  I need to apply this to 
> > matrices up to ~100000 rows.



From ggrothendieck at myway.com  Fri May 14 23:03:45 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 14 May 2004 21:03:45 +0000 (UTC)
Subject: [R] Tagging identical rows of a matrix
References: <62AE0CF1D4875C4BBDEC29DB9924ACE87F21DB@pnlmse25.pnl.gov>
Message-ID: <loom.20040514T222448-769@post.gmane.org>

Waichler, Scott R <Scott.Waichler <at> pnl.gov> writes:

> 
> Thanks to all of you who responded to my help request.
> Here is the very efficient upshot of your advice:
> 
> > mat2 <- apply(mat, 1, paste, collapse=":")
> > vec <- match(mat2, unique(mat2))
> > vec
> [1] 1 2 1 1 2 3
> 
> 
> P.S.  I found that Andy Liaw's method didn't preserve the
> index order that I wanted; it yields
> 
> 2 3 2 2 3 1
> 
> To get the order of integers I was looking for required an
> invocation of unique:
> 
> as.numeric(factor(apply(mat, 1, paste, collapse=":"),
>                   levels=unique(apply(mat, 1, paste, collapse=":"))))
> 
> But the first method above is obviously cleaner and is twice
> as fast, only 9 seconds for a 100000 row matrix on an ordinary PC.  

The interaction solution gives an identical result, is shorter and
is one or two orders of magnitude faster.  Here is a comparison of the three:

R> set.seed(1)
R> mat <- matrix(sample(20,100000,rep=T),50000)
R> 
R> f0 <- function(mat) {
+ mat2 <- apply(mat, 1, paste, collapse=":");
+ match(mat2, unique(mat2))
+ }
R> 
R> 
R> f1 <- function(mat) { z <- apply(mat, 1, paste, collapse=":")
+ as.numeric(factor(z,levels=unique(z)))
+ }
R> 
R> f2 <- function(mat) as.numeric(interaction(mat[,1],mat[,2],drop=T))
R> 
R> dummy <- gc(); system.time(z0 <- f0(mat))
[1] 5.24 0.02 5.52   NA   NA
R> dummy <- gc(); system.time(z1 <- f1(mat))
[1] 5.18 0.00 5.52   NA   NA
R> dummy <- gc(); system.time(z2 <- f2(mat))
[1] 0.1 0.0 0.1  NA  NA
R> all.equal(z0,z1)
[1] TRUE
R> all.equal(z0,z2)
[1] TRUE
R> all.equal(z2,z1)
[1] TRUE



From lsjensen at micron.com  Fri May 14 23:20:58 2004
From: lsjensen at micron.com (lsjensen@micron.com)
Date: Fri, 14 May 2004 15:20:58 -0600
Subject: [R] Anova precision
Message-ID: <363801FFD7B74240A329CEC3F7FE4CC402B83FDE@ntxboimbx07.micron.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040514/08740936/attachment.pl

From jeff.hamann at forestinformatics.com  Sat May 15 01:21:39 2004
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Fri, 14 May 2004 16:21:39 -0700
Subject: [R] xtable without rownames
References: <372EFF9FE4E42E419C978E7A305DC5FE0379AD91@exsalem5.odot.state.or.us>
Message-ID: <001101c43a0a$36175800$0c00a8c0@rodan>

I just can't get it to work... I've got a data.frame that looks like,

> ata
   age.class     acres
1          0  94.25871
2         10 202.58106
3         20 254.74497
4         30 326.43598
5         40 170.75596
6         50 146.50230
7         60  76.84737
8         70  90.65786
9         80  44.59983
10        90  56.42965
11       100  34.48122
12       200  11.21226
>

and when I attempt to set the row names using,

> rownames( ata ) <- rep( "", nrow(ata) )

I cannot print out the data.frame as I get the error message,

> rta
Error in data.frame(site.index = c("80", "90", "100", "110", "120", "130",
:
 duplicate row.names:
>

and setting the values to NULL, yields,

> rownames( ata ) <- NULL
Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
 invalid dimnames given for data frame
> rownames( ata ) <- rep( NULL, nrow(ata) )
Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
 invalid dimnames given for data frame
>

So just how do I do it?

----- Original Message ----- 
From: <Brian.J.GREGOR at odot.state.or.us>
To: <jeff.hamann at forestinformatics.com>; <r-help at stat.math.ethz.ch>
Sent: Thursday, May 13, 2004 9:13 AM
Subject: RE: [R] xtable without rownames


> You can just set the rownames to an empty character string ("") and xtable
> will work fine.
>
> > -----Original Message-----
> > From: Jeff D. Hamann [mailto:jeff.hamann at forestinformatics.com]
> > Sent: Wednesday, May 12, 2004 5:40 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] xtable without rownames
> >
> >
> > When I tried to read all the entries (after searching the
> > FAQ) for "row
> > names xtable", I get
> >
> >
> > START-INFO-DIR-ENTRY * R FAQ: (R-FAQ). The R statistical system ...
> > ... xtable* Export data to LaTeX and HTML tables. ... For
> > dropping the row
> > names of a matrix
> > `x', it may be easier to use `rownames(x) <- NULL', similarly
> > for column ...
> > cvs.r-project.org/cgi-bin/viewcvs.cgi/R/FAQ?rev=1.301 - 101k
> > - Supplemental
> > Result - Cached - Similar pages
> > I wasn't able to follow the link. I'd like to use xtable to
> > generate latex
> > tables for using with Sweave and can't figure out how to not
> > include the row
> > names. When I attempt to NULL out the row names using,
> >
> > but cannot follow the links. Browser tells me the page is
> > unavailable. When
> > I attempt to blank out the row names using,
> >
> > rownames(summary.table) <- NULL
> >
> > I get the following error
> >
> > > rownames(rta) <- NULL
> > Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
> >  invalid dimnames given for data frame
> > >
> >
> > the resulting (incorrect) table appears as,
> >
> > > xtable( rta )
> > % latex table generated in R 1.9.0 by xtable 1.2-2 package
> > % Wed May 12 17:38:21 2004
> > \begin{table}[ht]
> > \begin{center}
> > \begin{tabular}{rlr}
> > \hline
> >  & site.index & acres \\
> > \hline
> > 1 &  80 & 20.90 \\
> > 2 &  90 & 64.42 \\
> > ...blah, blah, blah...
> > 8 & 150 & 53.32 \\
> > 9 & 170 & 0.69 \\
> > \hline
> > \end{tabular}
> > \end{center}
> > \end{table}
> > >
> >
> > with the rownames. How do I get them out?
> >
> > I'm stuck. Help.
> >
> > Jeff.
> >
> > ---
> > Jeff D. Hamann
> > Forest Informatics, Inc.
> > PO Box 1421
> > Corvallis, Oregon USA 97339-1421
> > 541-754-1428
> > jeff.hamann at forestinformatics.com
> > www.forestinformatics.com
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From Arne.Muller at aventis.com  Sat May 15 01:44:55 2004
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Sat, 15 May 2004 01:44:55 +0200
Subject: [R] help with memory greedy storage
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1E0@crbsmxsusr04.pharma.aventis.com>

Hello,

I've a problem with a self written routine taking a lot of memory (>1.2Gb). Maybe you can suggest some enhancements, I'm pretty sure that my implementation is not optimal ...

I'm creating many linear models and store coefficients, anova p-values ... all I need in different lists which are then finally returned in a list (list of lists).

The input is a matrix with 84 rows and >100,000 rows. The routine probeDf below creates a data frame that assigns the 84 rows to the different factors, but not just for one row but for several rows, depending what which(rows == g),] returns, and a new factor ('probe') is generated. This results in a 1344 by 6 data frame.

Example data frame returned by probeDf:

       Value batch time  dose array probe
1   2.317804   NEW  24h 000mM     1     1
2   2.495390   NEW  24h 000mM     2     1
3   2.412247   NEW  24h 000mM     3     1
...
144 8.851469   OLD  04h 100mM    60     2
145 8.801430   PRG  24h 000mM    61     2
146 8.308224   PRG  24h 000mM    62     2
...

This data frame is not the problem since, it gets generated on-the-fly per gene and is discarded afterwards (just that it takes some time to generate it).

Here comes the problematic routine:

### emat: matrix, model: formular for lm, contr: optional contrasts
probe.fit <- function(emat, factors, model, contr=NULL)
{
        rows <- rownames(emat)
        genes <- unique(rows)
        l <- length(genes) 
        ### generate proper lables (names) for the anova p-values
        difflabels <- attr(terms(model),"term.labels")
	  aov    <- list() # anova p-values for factors + interactions
        coef   <- list() # lm coefficients
        coefp  <- list() # p-valuies for coefficients
        rsq    <- list() # R-squared of fit
        fitted <- list() # fitted values
        value  <- list() # orig. values (used with fitted to get residuals)

	  for ( g in genes ) { # loop over >12,000 genes
          ### g is the name that identifies 14 to 16 rows in emat
          ### d is the data frame for the lm
          d <- probeDf(emat[which(rows == g),], facts)
          fit <- lm(model, data = d, contrasts=contr)
          fit.sum <- summary(fit)
          aov[[g]]   <- as.vector(na.omit(anova(fit)$'Pr(>F)'))
          names(aov[[g]]) <- difflabels
          coef[[g]]   <- coef(fit)[-1]
          coefp[[g]]  <- coef(fit.sum)[-1,'Pr(>|t|)']
          rsq[[g]]    <- fit.sum$'r.squared'
          value[[g]] <- d$Value
          fitted[[g]] <- fitted(fit)
	}
      list(aov=aov, coefs=coef, coefp=coefp, rsq=rsq,
           fitted=fitted, values=values)
}

### create a data frame from a matrix (usually 16 rows and 84 columns)
### and a list of factors. Basically this repates the factors 16 times
### (for each row in the matrix). This results in a data frame with 84*16
### rows as many columns as there are factors + 2 (probe factor + value
### to be modeled later)
probeDf <- function(emat, facts) {
    df <- NULL
    n <- 1
    nsamp <- ncol(emat)
    for ( i in 1:nrow(emat) ) {
        values <- c(t(emat[i,]))
        df.new <- data.frame(Value = values, facts, probe = rep(n, nsamp))
        n <- n + 1
        if ( !is.null(df) ) {
           df <- rbind(df, df.new)
        } else {
           df <- df.new
        }
    }
    df$probe <- as.factor(df$probe)
    df
}

If I remove coef, coefp, value and fitted from the loop in probe.fit the memory usage is moderate.

The problem is that each of the 12,000 genes contributes 148 coefficients (the model contains quite a few factors) and p-values, the fitted and value vectors are >1300 elements long. I couldn't find a more compact form of storage that I is still easy to explore afterwards.

Suggestions on how to get this done more efficiently (in terms of memory) are greatfully received.

     kind regards,

     Arne

--
Arne Muller, Ph.D.
Toxicogenomics, Aventis Pharma
arne dot muller domain=aventis com



From ggrothendieck at myway.com  Sat May 15 01:48:03 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 14 May 2004 23:48:03 +0000 (UTC)
Subject: [R] xtable without rownames
References: <372EFF9FE4E42E419C978E7A305DC5FE0379AD91@exsalem5.odot.state.or.us>
	<001101c43a0a$36175800$0c00a8c0@rodan>
Message-ID: <loom.20040515T013515-690@post.gmane.org>

Data frames are supposed to have unique rownames but it
seems xtable does not know that so just set them all
to "" anyways on a copy of ata that you throw away later:

ata2 <- ata
rownames(ata2) <- rep("",nrow(ata2))
xtable(ata2)
rm(ata2)


Jeff D. Hamann <jeff.hamann <at> forestinformatics.com> writes:

: 
: I just can't get it to work... I've got a data.frame that looks like,
: 
: > ata
:    age.class     acres
: 1          0  94.25871
: 2         10 202.58106
: 3         20 254.74497
: 4         30 326.43598
: 5         40 170.75596
: 6         50 146.50230
: 7         60  76.84737
: 8         70  90.65786
: 9         80  44.59983
: 10        90  56.42965
: 11       100  34.48122
: 12       200  11.21226
: >
: 
: and when I attempt to set the row names using,
: 
: > rownames( ata ) <- rep( "", nrow(ata) )
: 
: I cannot print out the data.frame as I get the error message,
: 
: > rta
: Error in data.frame(site.index = c("80", "90", "100", "110", "120", "130",
: :
:  duplicate row.names:
: >
: 
: and setting the values to NULL, yields,
: 
: > rownames( ata ) <- NULL
: Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
:  invalid dimnames given for data frame
: > rownames( ata ) <- rep( NULL, nrow(ata) )
: Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
:  invalid dimnames given for data frame
: >
: 
: So just how do I do it?
: 
: ----- Original Message ----- 
: From: <Brian.J.GREGOR <at> odot.state.or.us>
: To: <jeff.hamann <at> forestinformatics.com>; <r-help <at> stat.math.ethz.ch>
: Sent: Thursday, May 13, 2004 9:13 AM
: Subject: RE: [R] xtable without rownames
: 
: 
: > You can just set the rownames to an empty character string ("") and xtable
: > will work fine.
: >
: > > -----Original Message-----
: > > From: Jeff D. Hamann [mailto:jeff.hamann <at> forestinformatics.com]
: > > Sent: Wednesday, May 12, 2004 5:40 PM
: > > To: r-help <at> stat.math.ethz.ch
: > > Subject: [R] xtable without rownames
: > >
: > >
: > > When I tried to read all the entries (after searching the
: > > FAQ) for "row
: > > names xtable", I get
: > >
: > >
: > > START-INFO-DIR-ENTRY * R FAQ: (R-FAQ). The R statistical system ...
: > > ... xtable* Export data to LaTeX and HTML tables. ... For
: > > dropping the row
: > > names of a matrix
: > > `x', it may be easier to use `rownames(x) <- NULL', similarly
: > > for column ...
: > > cvs.r-project.org/cgi-bin/viewcvs.cgi/R/FAQ?rev=1.301 - 101k
: > > - Supplemental
: > > Result - Cached - Similar pages
: > > I wasn't able to follow the link. I'd like to use xtable to
: > > generate latex
: > > tables for using with Sweave and can't figure out how to not
: > > include the row
: > > names. When I attempt to NULL out the row names using,
: > >
: > > but cannot follow the links. Browser tells me the page is
: > > unavailable. When
: > > I attempt to blank out the row names using,
: > >
: > > rownames(summary.table) <- NULL
: > >
: > > I get the following error
: > >
: > > > rownames(rta) <- NULL
: > > Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
: > >  invalid dimnames given for data frame
: > > >
: > >
: > > the resulting (incorrect) table appears as,
: > >
: > > > xtable( rta )
: > > % latex table generated in R 1.9.0 by xtable 1.2-2 package
: > > % Wed May 12 17:38:21 2004
: > > \begin{table}[ht]
: > > \begin{center}
: > > \begin{tabular}{rlr}
: > > \hline
: > >  & site.index & acres \\
: > > \hline
: > > 1 &  80 & 20.90 \\
: > > 2 &  90 & 64.42 \\
: > > ...blah, blah, blah...
: > > 8 & 150 & 53.32 \\
: > > 9 & 170 & 0.69 \\
: > > \hline
: > > \end{tabular}
: > > \end{center}
: > > \end{table}
: > > >
: > >
: > > with the rownames. How do I get them out?
: > >
: > > I'm stuck. Help.
: > >
: > > Jeff.
: > >
: > > ---
: > > Jeff D. Hamann
: > > Forest Informatics, Inc.
: > > PO Box 1421
: > > Corvallis, Oregon USA 97339-1421
: > > 541-754-1428
: > > jeff.hamann <at> forestinformatics.com
: > > www.forestinformatics.com
:



From MSchwartz at MedAnalytics.com  Sat May 15 02:54:23 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 14 May 2004 19:54:23 -0500
Subject: [R] log Y scales for parplot
In-Reply-To: <E1BOgEF-000Oyy-Ir@serenity.mcc.ac.uk>
References: <E1BOgEF-000Oyy-Ir@serenity.mcc.ac.uk>
Message-ID: <1084582463.7354.84.camel@localhost.localdomain>

On Fri, 2004-05-14 at 12:11, Monica Palaseanu-Lovejoy wrote:
> Hi,
> 
> I am doing a barplot, and the fist bar is very big (high values) and 
> the rest of the bars are quite small (small values). So - is there any 
> way to make the  Y scale logarithmic so that i have a wider 
> distance from 0 to 50 for example than for 50 to 100, and so on? 
> 
> Thanks in advance for any help,
> 
> Monica


Monica,

See the barplot2() function in the 'gregmisc' package on CRAN, which
supports the use of log axis scaling.

For example:

barplot2(c(5000, 50, 75, 100), log = "y")


HTH,

Marc Schwartz



From wcvinyard at earthlink.net  Sat May 15 02:56:20 2004
From: wcvinyard at earthlink.net (Bill Vinyard)
Date: Fri, 14 May 2004 20:56:20 -0400
Subject: [R] help with memory greedy storage
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF1E0@crbsmxsusr04.pharma.aventis.com>
Message-ID: <MJENLJEPCHEMCAGNPDMGOEKFCCAA.wcvinyard@earthlink.net>

Real rough estimate ... looks like you're trying to store about 38 million
numbers in the data frame.  Do you need all of the models in the dataframe
at the end or are you just trying to generate the output and look at it
later?

Perhaps you could save intermediate results to file, that is, create a
separate file for each gene model, or after each set of n gene models.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of
Arne.Muller at aventis.com
Sent: Friday, May 14, 2004 19:45
To: r-help at stat.math.ethz.ch
Subject: [R] help with memory greedy storage


Hello,

I've a problem with a self written routine taking a lot of memory (>1.2Gb).
Maybe you can suggest some enhancements, I'm pretty sure that my
implementation is not optimal ...

I'm creating many linear models and store coefficients, anova p-values ...
all I need in different lists which are then finally returned in a list
(list of lists).

The input is a matrix with 84 rows and >100,000 rows. The routine probeDf
below creates a data frame that assigns the 84 rows to the different
factors, but not just for one row but for several rows, depending what
which(rows == g),] returns, and a new factor ('probe') is generated. This
results in a 1344 by 6 data frame.

Example data frame returned by probeDf:

       Value batch time  dose array probe
1   2.317804   NEW  24h 000mM     1     1
2   2.495390   NEW  24h 000mM     2     1
3   2.412247   NEW  24h 000mM     3     1
...
144 8.851469   OLD  04h 100mM    60     2
145 8.801430   PRG  24h 000mM    61     2
146 8.308224   PRG  24h 000mM    62     2
...

This data frame is not the problem since, it gets generated on-the-fly per
gene and is discarded afterwards (just that it takes some time to generate
it).

Here comes the problematic routine:

### emat: matrix, model: formular for lm, contr: optional contrasts
probe.fit <- function(emat, factors, model, contr=NULL)
{
        rows <- rownames(emat)
        genes <- unique(rows)
        l <- length(genes)
        ### generate proper lables (names) for the anova p-values
        difflabels <- attr(terms(model),"term.labels")
	  aov    <- list() # anova p-values for factors + interactions
        coef   <- list() # lm coefficients
        coefp  <- list() # p-valuies for coefficients
        rsq    <- list() # R-squared of fit
        fitted <- list() # fitted values
        value  <- list() # orig. values (used with fitted to get residuals)

	  for ( g in genes ) { # loop over >12,000 genes
          ### g is the name that identifies 14 to 16 rows in emat
          ### d is the data frame for the lm
          d <- probeDf(emat[which(rows == g),], facts)
          fit <- lm(model, data = d, contrasts=contr)
          fit.sum <- summary(fit)
          aov[[g]]   <- as.vector(na.omit(anova(fit)$'Pr(>F)'))
          names(aov[[g]]) <- difflabels
          coef[[g]]   <- coef(fit)[-1]
          coefp[[g]]  <- coef(fit.sum)[-1,'Pr(>|t|)']
          rsq[[g]]    <- fit.sum$'r.squared'
          value[[g]] <- d$Value
          fitted[[g]] <- fitted(fit)
	}
      list(aov=aov, coefs=coef, coefp=coefp, rsq=rsq,
           fitted=fitted, values=values)
}

### create a data frame from a matrix (usually 16 rows and 84 columns)
### and a list of factors. Basically this repates the factors 16 times
### (for each row in the matrix). This results in a data frame with 84*16
### rows as many columns as there are factors + 2 (probe factor + value
### to be modeled later)
probeDf <- function(emat, facts) {
    df <- NULL
    n <- 1
    nsamp <- ncol(emat)
    for ( i in 1:nrow(emat) ) {
        values <- c(t(emat[i,]))
        df.new <- data.frame(Value = values, facts, probe = rep(n, nsamp))
        n <- n + 1
        if ( !is.null(df) ) {
           df <- rbind(df, df.new)
        } else {
           df <- df.new
        }
    }
    df$probe <- as.factor(df$probe)
    df
}

If I remove coef, coefp, value and fitted from the loop in probe.fit the
memory usage is moderate.

The problem is that each of the 12,000 genes contributes 148 coefficients
(the model contains quite a few factors) and p-values, the fitted and value
vectors are >1300 elements long. I couldn't find a more compact form of
storage that I is still easy to explore afterwards.

Suggestions on how to get this done more efficiently (in terms of memory)
are greatfully received.

     kind regards,

     Arne

--
Arne Muller, Ph.D.
Toxicogenomics, Aventis Pharma
arne dot muller domain=aventis com

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Sat May 15 03:20:21 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 14 May 2004 21:20:21 -0400
Subject: [R] Tagging identical rows of a matrix
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7DAD@usrymx25.merck.com>

The problem with interaction() is that it doesn't scale with increasing
number of columns:

> set.seed(1)
> mat2 <- matrix(sample(20,5e4,rep=T), 1e4)
> invisible(gc()); system.time(z0 <- f0(mat2))
[1] 1.58 0.01 1.85   NA   NA
> invisible(gc()); system.time(z1 <- f1(mat2))
[1] 1.57 0.00 1.66   NA   NA
> invisible(gc()); system.time(z2 <- f2g(mat2))
[1] 34.14  0.60 57.45    NA    NA

[f2g is the slightly modified version of f2 to allow for any number of
columns:
f2g <- function(mat) as.numeric(interaction(as.data.frame(mat), drop=T))]

With 10 columns in the matrix, f0 and f1 ran fine in under 10 seconds, but
f2g started thrashing, and ran out of memory after a while.  If you look at
how interaction() is written you'll quickly see why...

Andy

> From: Gabor Grothendieck
> 
> Waichler, Scott R <Scott.Waichler <at> pnl.gov> writes:
> 
> > 
> > Thanks to all of you who responded to my help request.
> > Here is the very efficient upshot of your advice:
> > 
> > > mat2 <- apply(mat, 1, paste, collapse=":")
> > > vec <- match(mat2, unique(mat2))
> > > vec
> > [1] 1 2 1 1 2 3
> > 
> > 
> > P.S.  I found that Andy Liaw's method didn't preserve the
> > index order that I wanted; it yields
> > 
> > 2 3 2 2 3 1
> > 
> > To get the order of integers I was looking for required an
> > invocation of unique:
> > 
> > as.numeric(factor(apply(mat, 1, paste, collapse=":"),
> >                   levels=unique(apply(mat, 1, paste, 
> collapse=":"))))
> > 
> > But the first method above is obviously cleaner and is twice
> > as fast, only 9 seconds for a 100000 row matrix on an ordinary PC.  
> 
> The interaction solution gives an identical result, is shorter and
> is one or two orders of magnitude faster.  Here is a 
> comparison of the three:
> 
> R> set.seed(1)
> R> mat <- matrix(sample(20,100000,rep=T),50000)
> R> 
> R> f0 <- function(mat) {
> + mat2 <- apply(mat, 1, paste, collapse=":");
> + match(mat2, unique(mat2))
> + }
> R> 
> R> 
> R> f1 <- function(mat) { z <- apply(mat, 1, paste, collapse=":")
> + as.numeric(factor(z,levels=unique(z)))
> + }
> R> 
> R> f2 <- function(mat) as.numeric(interaction(mat[,1],mat[,2],drop=T))
> R> 
> R> dummy <- gc(); system.time(z0 <- f0(mat))
> [1] 5.24 0.02 5.52   NA   NA
> R> dummy <- gc(); system.time(z1 <- f1(mat))
> [1] 5.18 0.00 5.52   NA   NA
> R> dummy <- gc(); system.time(z2 <- f2(mat))
> [1] 0.1 0.0 0.1  NA  NA
> R> all.equal(z0,z1)
> [1] TRUE
> R> all.equal(z0,z2)
> [1] TRUE
> R> all.equal(z2,z1)
> [1] TRUE
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From r-stats at arcriswell.com  Sat May 15 04:43:23 2004
From: r-stats at arcriswell.com (Andrew Criswell)
Date: Sat, 15 May 2004 09:43:23 +0700
Subject: [R] factor analysis
In-Reply-To: <web-39264544@cgpsrv2.cis.mcmaster.ca>
References: <web-39264544@cgpsrv2.cis.mcmaster.ca>
Message-ID: <40A583CB.5090804@arcriswell.com>

Hello:

The website 
http://ourworld.compuserve.com/homepages/jsuebersax/tetra.htm might 
provide you with further hints and information on implementing 
polychoric correlations. Further information related to your inquiry can 
also be found on http://www.unt.edu/rss/class/rich/5840/

In addition, possibly relevant S+ code can be found on 
http://www.biostat.wustl.edu/archives/html/s-news/2001-02/msg00079.html

ANDREW

John Fox wrote:

>Dear Allan,
>
>I assume that the categorical data are ordinal. There are methods for
>factor analyzing ordinal data (e.g., using polychoric correlations) and
>mixed ordinal and interval data, but as far as I know, these aren't
>implemented in R.
>
>John
>
>On Thu, 13 May 2004 18:32:11 +0200
> allan clark <allan at stats.uct.ac.za> wrote:
>  
>
>>hi all
>>
>>this is a stats question.
>>
>>when undertaking factor analysis should the variables included always
>>be
>>continiuos random variables? could one include categorical data? e.g
>>some survey type data
>>
>>my gut feeling is that one should not include categorical type data
>>since factor analysis is based on the eigenanalysis of the
>>correlation
>>matrix of a group of variables. The introduction of categorical data
>>into a data set might "mess up" the corelation matrix.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
>>    
>>
>
>
>--------------------------------
>John Fox
>Department of Sociology
>McMaster University
>Hamilton, Ontario, Canada
>http://socserv.mcmaster.ca/jfox/
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From ggrothendieck at myway.com  Sat May 15 05:34:37 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 15 May 2004 03:34:37 +0000 (UTC)
Subject: [R] Tagging identical rows of a matrix
References: <3A822319EB35174CA3714066D590DCD504AF7DAD@usrymx25.merck.com>
Message-ID: <loom.20040515T052511-17@post.gmane.org>

OK. Good point.  I have revised the interaction solution (which is
now unfortunately not as short) but it is nearly an order of
magnitude faster than the other two using 5 columns.  It is solution 
f4, below:

R> set.seed(1)
R> mat <- matrix(sample(20,100000,rep=T),nc=5)
R> 
R> f0 <- function(mat) {
+ mat2 <- apply(mat, 1, paste, collapse=":")
+ match(mat2, unique(mat2))
+ }
R> 
R> f1 <- function(mat) { 
+ z <- apply(mat, 1, paste, collapse=":")
+ as.numeric(factor(z,levels=unique(z)))
+ }
R> 
R> f4 <- function(mat) {
+ z <- apply(mat,2,factor)
+ as.numeric(interaction(z %*% ((max(z)+1)^(seq(ncol(z))-1)),drop=T))
+ }
R> 
R> 
R> invisible(gc()); system.time(z0 <- f0(mat))
[1] 2.05 0.00 2.17   NA   NA
R> invisible(gc()); system.time(z1 <- f1(mat))
[1] 2.22 0.01 2.37   NA   NA
R> invisible(gc()); system.time(z4 <- f4(mat))
[1] 0.26 0.00 0.30   NA   NA
R> 
R> all.equal(z0,z1)
[1] TRUE
R> all.equal(z0,z4)
[1] TRUE
R> all.equal(z4,z1)
[1] TRUE
R> 
R> 



Liaw, Andy <andy_liaw <at> merck.com> writes:

: 
: The problem with interaction() is that it doesn't scale with increasing
: number of columns:
: 
: > set.seed(1)
: > mat2 <- matrix(sample(20,5e4,rep=T), 1e4)
: > invisible(gc()); system.time(z0 <- f0(mat2))
: [1] 1.58 0.01 1.85   NA   NA
: > invisible(gc()); system.time(z1 <- f1(mat2))
: [1] 1.57 0.00 1.66   NA   NA
: > invisible(gc()); system.time(z2 <- f2g(mat2))
: [1] 34.14  0.60 57.45    NA    NA
: 
: [f2g is the slightly modified version of f2 to allow for any number of
: columns:
: f2g <- function(mat) as.numeric(interaction(as.data.frame(mat), drop=T))]
: 
: With 10 columns in the matrix, f0 and f1 ran fine in under 10 seconds, but
: f2g started thrashing, and ran out of memory after a while.  If you look at
: how interaction() is written you'll quickly see why...
: 
: Andy
: 
: > From: Gabor Grothendieck
: > 
: > Waichler, Scott R <Scott.Waichler <at> pnl.gov> writes:
: > 
: > > 
: > > Thanks to all of you who responded to my help request.
: > > Here is the very efficient upshot of your advice:
: > > 
: > > > mat2 <- apply(mat, 1, paste, collapse=":")
: > > > vec <- match(mat2, unique(mat2))
: > > > vec
: > > [1] 1 2 1 1 2 3
: > > 
: > > 
: > > P.S.  I found that Andy Liaw's method didn't preserve the
: > > index order that I wanted; it yields
: > > 
: > > 2 3 2 2 3 1
: > > 
: > > To get the order of integers I was looking for required an
: > > invocation of unique:
: > > 
: > > as.numeric(factor(apply(mat, 1, paste, collapse=":"),
: > >                   levels=unique(apply(mat, 1, paste, 
: > collapse=":"))))
: > > 
: > > But the first method above is obviously cleaner and is twice
: > > as fast, only 9 seconds for a 100000 row matrix on an ordinary PC.  
: > 
: > The interaction solution gives an identical result, is shorter and
: > is one or two orders of magnitude faster.  Here is a 
: > comparison of the three:
: > 
: > R> set.seed(1)
: > R> mat <- matrix(sample(20,100000,rep=T),50000)
: > R> 
: > R> f0 <- function(mat) {
: > + mat2 <- apply(mat, 1, paste, collapse=":");
: > + match(mat2, unique(mat2))
: > + }
: > R> 
: > R> 
: > R> f1 <- function(mat) { z <- apply(mat, 1, paste, collapse=":")
: > + as.numeric(factor(z,levels=unique(z)))
: > + }
: > R> 
: > R> f2 <- function(mat) as.numeric(interaction(mat[,1],mat[,2],drop=T))
: > R> 
: > R> dummy <- gc(); system.time(z0 <- f0(mat))
: > [1] 5.24 0.02 5.52   NA   NA
: > R> dummy <- gc(); system.time(z1 <- f1(mat))
: > [1] 5.18 0.00 5.52   NA   NA
: > R> dummy <- gc(); system.time(z2 <- f2(mat))
: > [1] 0.1 0.0 0.1  NA  NA
: > R> all.equal(z0,z1)
: > [1] TRUE
: > R> all.equal(z0,z2)
: > [1] TRUE
: > R> all.equal(z2,z1)
: > [1] TRUE
: > 
: > ______________________________________________
: > R-help <at> stat.math.ethz.ch mailing list
: > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: > PLEASE do read the posting guide! 
: > http://www.R-project.org/posting-guide.html
: > 
: >
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From ripley at stats.ox.ac.uk  Sat May 15 07:48:29 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 15 May 2004 06:48:29 +0100 (BST)
Subject: [R] xtable without rownames
In-Reply-To: <001101c43a0a$36175800$0c00a8c0@rodan>
Message-ID: <Pine.LNX.4.44.0405150623140.5139-100000@gannet.stats>

rownames  are for a matrix.
row.names are for a data frame.
I think you have confused your helpers.  Try coercing to a matrix first.

I am not sure it will `work fine': it does still seem to have an empty 
column for the row names.  This is hard-coded in print.xtable in the lines

    cols <- matrix("", nrow = nrow(x), ncol = ncol(x) + 1)
    cols[, 1] <- row.names(x)

and since e.g. write.table has options to not include row and column 
names, it would be nice if this could be added to xtable.

Also, this ought not to work.  xtable.matrix makes use of
dimnames<-.data.frame which fails to check if the row names are duplicated 
and so creates an invalid data frame.  That is a bug, and it will be 
fixed in due course.


On Fri, 14 May 2004, Jeff D. Hamann wrote:

> I just can't get it to work... I've got a data.frame that looks like,
> 
> > ata
>    age.class     acres
> 1          0  94.25871
> 2         10 202.58106
> 3         20 254.74497
> 4         30 326.43598
> 5         40 170.75596
> 6         50 146.50230
> 7         60  76.84737
> 8         70  90.65786
> 9         80  44.59983
> 10        90  56.42965
> 11       100  34.48122
> 12       200  11.21226
> >
> 
> and when I attempt to set the row names using,
> 
> > rownames( ata ) <- rep( "", nrow(ata) )
> 
> I cannot print out the data.frame as I get the error message,
> 
> > rta
> Error in data.frame(site.index = c("80", "90", "100", "110", "120", "130",
> :
>  duplicate row.names:

Where did `rta' and `site.index' come from?

> and setting the values to NULL, yields,
> 
> > rownames( ata ) <- NULL
> Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
>  invalid dimnames given for data frame
> > rownames( ata ) <- rep( NULL, nrow(ata) )
> Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
>  invalid dimnames given for data frame
> >
> 
> So just how do I do it?
> 
> ----- Original Message ----- 
> From: <Brian.J.GREGOR at odot.state.or.us>
> To: <jeff.hamann at forestinformatics.com>; <r-help at stat.math.ethz.ch>
> Sent: Thursday, May 13, 2004 9:13 AM
> Subject: RE: [R] xtable without rownames
> 
> 
> > You can just set the rownames to an empty character string ("") and xtable
> > will work fine.
> >
> > > -----Original Message-----
> > > From: Jeff D. Hamann [mailto:jeff.hamann at forestinformatics.com]
> > > Sent: Wednesday, May 12, 2004 5:40 PM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] xtable without rownames
> > >
> > >
> > > When I tried to read all the entries (after searching the
> > > FAQ) for "row
> > > names xtable", I get
> > >
> > >
> > > START-INFO-DIR-ENTRY * R FAQ: (R-FAQ). The R statistical system ...
> > > ... xtable* Export data to LaTeX and HTML tables. ... For
> > > dropping the row
> > > names of a matrix
> > > `x', it may be easier to use `rownames(x) <- NULL', similarly
> > > for column ...
> > > cvs.r-project.org/cgi-bin/viewcvs.cgi/R/FAQ?rev=1.301 - 101k
> > > - Supplemental
> > > Result - Cached - Similar pages
> > > I wasn't able to follow the link. I'd like to use xtable to
> > > generate latex
> > > tables for using with Sweave and can't figure out how to not
> > > include the row
> > > names. When I attempt to NULL out the row names using,
> > >
> > > but cannot follow the links. Browser tells me the page is
> > > unavailable. When
> > > I attempt to blank out the row names using,
> > >
> > > rownames(summary.table) <- NULL
> > >
> > > I get the following error
> > >
> > > > rownames(rta) <- NULL
> > > Error in "dimnames<-.data.frame"(`*tmp*`, value = dn) :
> > >  invalid dimnames given for data frame
> > > >
> > >
> > > the resulting (incorrect) table appears as,
> > >
> > > > xtable( rta )
> > > % latex table generated in R 1.9.0 by xtable 1.2-2 package
> > > % Wed May 12 17:38:21 2004
> > > \begin{table}[ht]
> > > \begin{center}
> > > \begin{tabular}{rlr}
> > > \hline
> > >  & site.index & acres \\
> > > \hline
> > > 1 &  80 & 20.90 \\
> > > 2 &  90 & 64.42 \\
> > > ...blah, blah, blah...
> > > 8 & 150 & 53.32 \\
> > > 9 & 170 & 0.69 \\
> > > \hline
> > > \end{tabular}
> > > \end{center}
> > > \end{table}
> > > >
> > >
> > > with the rownames. How do I get them out?
> > >
> > > I'm stuck. Help.
> > >
> > > Jeff.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From matt_lindon at yahoo.com  Sat May 15 10:20:46 2004
From: matt_lindon at yahoo.com (matt lindon)
Date: Sat, 15 May 2004 01:20:46 -0700 (PDT)
Subject: [R] how to get data and post it on R
Message-ID: <20040515082046.4173.qmail@web90106.mail.scd.yahoo.com>

Hi , i'm having  trouble getting data from outside and
trying to do either a discrimination analysis or a
regression analysis.I don't know what kind of data i
need to use and also what are the packages i need to
use.
Please get me some direction so i can begin .
		
__________________________________


From k.wang at auckland.ac.nz  Sat May 15 10:41:19 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 15 May 2004 20:41:19 +1200
Subject: [R] how to get data and post it on R
In-Reply-To: <20040515082046.4173.qmail@web90106.mail.scd.yahoo.com>
Message-ID: <20040515084132.KDNB3371.web3-rme.xtra.co.nz@kevinlpt>

Hi,

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of matt lindon
> Sent: Saturday, May 15, 2004 8:21 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] how to get data and post it on R
>
> Hi , i'm having  trouble getting data from outside and
> trying to do either a discrimination analysis or a
> regression analysis.I don't know what kind of data i
> need to use and also what are the packages i need to
> use.
> Please get me some direction so i can begin .

Have you tried reading the documentation?

E.g. R Data Import/Export  and the FAQs?

Kevin

--------------------------------------------
Ko-Kang Kevin Wang, MSc(Hon)
SLC Stats Workshops Co-ordinator
The University of Auckland
New Zealand



From ale.ambrosi at unipd.it  Sat May 15 11:51:13 2004
From: ale.ambrosi at unipd.it (ale.ambrosi@unipd.it)
Date: Sat, 15 May 2004 11:51:13 +0200 (MET DST)
Subject: [R] how add objects to an svm graphic
In-Reply-To: <BCCA19F8.80A6%sdavis2@mail.nih.gov>
References: <BCCA19F8.80A6%sdavis2@mail.nih.gov>
Message-ID: <1084614673.40a5e811e2bc7@webmail.unipd.it>


Hi all, 
First of all thanks for the answers.

I'd like to add some objects to a plot.svm graphic.
To give a more precise idea here I make a simple example. 
First I train a SVM.

> m.svm <- svm(status~., data = dati.svm, 
	kernel="radial", cross=20, scale=TRUE
	)

Then I generates a scatter plot of a svm fit:

> plot.svm(m.svm, data=dati.svm, v.1 ~ v.2, slice = list(...), 
        grid = 100)

This works well.
Now I have several data frames of points relatives to different samples, 
say dati.1, dati.2,... (of course of the same kind of dati.svm). I'd like to 
add them to the plot, each with different symbol and their (elliptic) hull.
How can I do it?

BTW: Are there any way to reppresent the model giving (the idea of) a 
third dimension? 


Thanks,
Alessandro


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
Alessandro Ambrosi, Ph.D.       |
Oncological Surgical Sc. Dept.  | mail: ale.ambrosi at unipd.it
Surg. Cl. II 			|       ambrosi at stat.unipd.it
University of Padua		| fax:  +39 049 651891
via Giustiniani, 2 		| tel:  +39 049 8212055
I-35128 Padua (ITALY)           | url:  www.stat.unipd.it/~ambrosi 	    
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


-------------------------------------------------
This mail sent through IMP: webmail.unipd.it



From 0034058 at fudan.edu.cn  Sat May 15 18:23:13 2004
From: 0034058 at fudan.edu.cn (vinkwai wong)
Date: Sun, 16 May 2004 00:23:13 +0800
Subject: [R] what  statistical method should i use?
Message-ID: <0HXR00HDDJX2WH@mail.fudan.edu.cn>

in order to know which production the custumer most like,i design a question as follow :

Q:there are six production listed below.according to your preference,the production you like most is_____,the production you secondly like is ____,and the third is_____.
productionA      productionB      productionC      productionD     productionE      productionF 

when the data is collected. i type in a stata in such format:

firstlike          secondlike          thirdlike
A                      C                   D
E                      A                   E


if i want to make a decision what production should i choose as my main production according to the survey,what statistical method should i use to analysis my data ?

my aim is to let the analysis result support my descision.

any suggestion is appreciated.

thank you .



From baron at psych.upenn.edu  Sat May 15 18:48:26 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sat, 15 May 2004 12:48:26 -0400
Subject: [R] what  statistical method should i use?
In-Reply-To: <0HXR00HDDJX2WH@mail.fudan.edu.cn>
References: <0HXR00HDDJX2WH@mail.fudan.edu.cn>
Message-ID: <20040515164826.GA8242@psych>

On 05/16/04 00:23, vinkwai wong wrote:
>in order to know which production the custumer most like,i design a question as follow
>:
>
>Q:there are six production listed below.according to your preference,the production
>you like most is_____,the production you secondly like is ____,and the third is_____.
>productionA      productionB      productionC      productionD     productionE     
>productionF
>
>when the data is collected. i type in a stata in such format:
>
>firstlike          secondlike          thirdlike
>A                      C                   D
>E                      A                   E
>
>
>if i want to make a decision what production should i choose as my main production
>according to the survey,what statistical method should i use to analysis my data ?
>
>my aim is to let the analysis result support my descision.

This isn't an R question yet, so it is off topic, but let me
answer in that spirit.  (It may become an R topic when it gets to
the point of converting the ranks into numbers, but you didn't
ask about that.)

I don't think this is a statistical question so much as a
question about decision making (my field, sort of).  And my
answer would be that you need to think about your goals (what you
are trying to achieve) and also about what could be producing
these rankings.

You mention customers.  If you are trying to produce something
that competes in a market, you need to think about market share.
If there are competitors, you need to think about them.  It could
be that the best option is not the one with the highest ranking
but rather the one that fills a gap (niche) in the market that
nobody else is filling very well.

If, on the other hand, these judgments are simply expert opinions
about the answer to the same question, then your task is
simpler.  You might make some simplifying assumptions, which
would allow you to base your decision on the average rank of each
option.

There are other models you could apply, such as the Rasch model,
or various models in the same spirit that often go under the name
of "random utility" models, although most of them derive in some
way from Thurstone scaling.

If the judgments are votes, then it would depend on what you told
the voters.  There are various methods for getting winners out of
rankings, but they make sense only if the voters know in advance
which method would be used.  Two of these are the Borda count
(which essentially adds the ranks) and the "single transferable
vote" or "instant runoff," which looks for a majority winner from
the first ranks, then, if it doesn't get one, takes the biggest
loser's second-place votes and adds them, and so on.

Finally, you could do some sort of cluster or classifcation
analysis on your subjects, to see if they really fall into
distinct groups with very different opinions.

I have used R for many of the things I just listed (but not all),
so I might be able to provide examples.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From Atropin75 at t-online.de  Sat May 15 19:40:50 2004
From: Atropin75 at t-online.de (Felix Eschenburg)
Date: Sat, 15 May 2004 19:40:50 +0200
Subject: [R] Again some questions about multilevelanalysis
Message-ID: <200405151940.50726.atropin75@t-online.de>

Dear list,

I asked some questions about multilevelanalysis a couple of months ago. In the 
meantime I did some reading about the subject. Now I'd like to check, if I 
understood it all correctly. If you think my questions are not appropriate 
for this list, please tell me so and i will immediatly stop asking them. 

I have a dataset with one predicted variable (y), two explanatory variables 
(x[1] and x[2]) at the first (the subject) level, a grouping variable at the 
second level (G), and an explanatory variable at the second level (z[1]) 

If I am correct, this leads to the following model (I will write indices in 
squared brackets and gamma as gm):

y = gamma[00] + gm[10]x[1ij] + gm[20] x[2ij] + gm[01]z[1j]+ gm[11]z[1j]x[1ij] 
+ gm[21]z[1j]x[2ij] + U[0j] + U[1j]x[1ij] + U[2j]x[2ij] + R[ij]  


Now I start modelling step by step and I would appreciate any corrections if I 
got something wrong.

An empty model:
e.model <- lme(y~1,random=~1|G)

With one explanatory variable:
fm1.lme <- lme(y~x1,random = ~1|G)

With two exp. variables, assuming that there are only maineffects for my 
variables:
fm2.lme <- lme(y ~ x1 + x2+ ... + x7, random = ~1|G)

The same, adding an interaction effect:
fm3.lme <- lme(y~x1*x2,random=~1|G)

This is how far i got. Now i would like to add the z-variable into the model.
How do i do this ?

Yours sincerly 
Felix Eschenburg



From bates at stat.wisc.edu  Sat May 15 20:34:21 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 15 May 2004 13:34:21 -0500
Subject: [R] Again some questions about multilevelanalysis
In-Reply-To: <200405151940.50726.atropin75@t-online.de>
References: <200405151940.50726.atropin75@t-online.de>
Message-ID: <6rfza1v8sy.fsf@bates4.stat.wisc.edu>

Atropin75 at t-online.de (Felix Eschenburg) writes:

> Dear list,
> 
> I asked some questions about multilevelanalysis a couple of months ago. In the 
> meantime I did some reading about the subject. Now I'd like to check, if I 
> understood it all correctly. If you think my questions are not appropriate 
> for this list, please tell me so and i will immediatly stop asking them. 
> 
> I have a dataset with one predicted variable (y), two explanatory variables 
> (x[1] and x[2]) at the first (the subject) level, a grouping variable at the 
> second level (G), and an explanatory variable at the second level (z[1]) 
> 
> If I am correct, this leads to the following model (I will write indices in 
> squared brackets and gamma as gm):
> 
> y = gamma[00] + gm[10]x[1ij] + gm[20] x[2ij] + gm[01]z[1j]+ gm[11]z[1j]x[1ij] 
> + gm[21]z[1j]x[2ij] + U[0j] + U[1j]x[1ij] + U[2j]x[2ij] + R[ij]  
> 
> 
> Now I start modelling step by step and I would appreciate any corrections if I 
> got something wrong.
> 
> An empty model:
> e.model <- lme(y~1,random=~1|G)
> 
> With one explanatory variable:
> fm1.lme <- lme(y~x1,random = ~1|G)
> 
> With two exp. variables, assuming that there are only maineffects for my 
> variables:
> fm2.lme <- lme(y ~ x1 + x2+ ... + x7, random = ~1|G)
> 
> The same, adding an interaction effect:
> fm3.lme <- lme(y~x1*x2,random=~1|G)
> 
> This is how far i got. Now i would like to add the z-variable into the model.
> How do i do this ?
> 
> Yours sincerly 
> Felix Eschenburg

Just add it in the formula for the fixed-effects. 

lme(y ~ x1*x2 + z,random = ~1|G)

Many references on multilevel modeling present the model in such a way
as to give the mistaken impression that a covariate defined to take
the same value across groups may only enter the model at the level of
those groups.  Groups are not relevant to fixed effects.  They only
matter in the definition of the random effects.



From dvanbrunt at well-wired.com  Sat May 15 20:52:02 2004
From: dvanbrunt at well-wired.com (David L. Van Brunt, Ph.D.)
Date: Sat, 15 May 2004 13:52:02 -0500
Subject: [R] " cannot allocate vector of length 1072693248"
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF7D8A@usrymx25.merck.com>
Message-ID: <BCCBD102.8F7D%dvanbrunt@well-wired.com>

Andy;

Well, that about does it....

I'm copying this one back to the list for the benefit of those who may hit
this thread while searching the archives.  Your changes to the code run just
fine on the my Windows machine, but gives the vector length error on the G4
whether I'm using the OS X build of R (as in Raqua) or the X11 build (for
Darwin). It is worth noting that I have nearly twice as much RAM and HD on
the OS X G4 as I have on the Pentium.

So it's definitely a platform specific problem. What on earth does one do
about that?

It's not emergent, but whomever works on the R source would probably like to
know.


On 5/12/04 20:29, "Liaw, Andy" <andy_liaw at merck.com> wrote:

> That's because I _attach()_ the .rda file you sent me, so that copy of
> `USdata' is in search position 2.  The subset statement makes a copy
> containing the subset in the workspace (aka global environment).  At the end
> of the loop, that copy is rm()'ed, but the copy in search position 2 is
> still accessible.
> 
> One thing I could have done is:
> 
> data.list <- split(USdata, USdata$symbol)
> 
> then inside the loop, just use data.list[[i]].
> 
> Andy
> 
>> -----Original Message-----
>> From: David L. Van Brunt, Ph.D. [mailto:dvanbrunt at well-wired.com]
>> Sent: Wednesday, May 12, 2004 9:14 PM
>> To: Liaw, Andy
>> Subject: Re: [R] " cannot allocate vector of length 1072693248"
>> 
>> 
>> I  took it for a spin.
>> 
>> Odd, but looking at your code, it doesn??t look like it should run, and
>> indeed it doesn??t, past the second loop. Early in the loop
>> you overwrite
>> ??USData?? as follows:
>> 
>>        USdata <- USdata[USdata$symbol == tickernames[i], -54]
>> 
>> Then at the end of the loop your remove it with:
>> 
>>           rm(USdata) ## ,risk.rf,risk.pred,risk.rsq,
>> 
>> So on my second pass, I get the following error:
>> 
>>> finished 1 of 30
>>> Just loaded:  2 of 30 .  AIG  Assigning vectors and outcomes....
>>> Error: Object "USdata" not found
>> 
>> 
>> I see you "attached" the dataset prior to the loop, but this
>> seems to be
>> circumvented in that you call "USdata$<somevar" in each case
>> within the
>> loop.
>> 
>> I've had it happen that after noodling around, I'm working
>> only by virtue of
>> having leftovers from prior work, but with a fresh launch I
>> discover that it
>> won't work after all.
>> 
>> Did I miss something?
>> 
>> Anyway, I'll try to rework my code to more closely
>> approximate yours (or
>> rather, vise-versa) and let you know how that goes.
>> 
>> Sorry so many delays on my end. Hell at work, just wiped out
>> by the time I
>> get home. Saw your post on the balancing of data, too, by the
>> way... Very
>> interesting, and very helpful.
>> 
>> On 5/10/04 21:05, "Liaw, Andy" <andy_liaw at merck.com> wrote:
>> 
>>> David,
>>> 
>>> I changed the code a bit so that it runs one ticker symbol
>> worth of data in
>>> each iteration.  Is that what you were doing?  You can see
>> from the attached
>>> file that I still don't get any error.  Memory usage was
>> less, and the code
>>> ran a lot faster (of course).
>>> 
>>> Andy
>>>> 
>>>> 
>>>> -----Original Message-----
>>>> From: David L. Van  Brunt, Ph.D. [mailto:dvanbrunt at well-wired.com]
>>>> Sent: Monday, May  10, 2004 12:05 AM
>>>> To: Liaw, Andy
>>>> Subject: Re: [R] " cannot  allocate vector of length 1072693248"
>>>> 
>>>> Thanks. I did just the opposite  today, ran through 500
>> loops using only the
>>>> regression forests, to be sure  there was no issue there.
>>>> 
>>>> Worked fine. But the classifications crash  even when run alone.
>>>> 
>>>> I'm not sure what you mean in your first sentence.  The
>> data set I posted is
>>>> the full data, which I would normally query out of  within
>> the loop to pull
>>>> each ticker symbol out one at a time.
>>>> 
>>>> Maybe  that's the secret sauce.... I'm doing a MySQL query
>> inside that loop,
>>>> whereas  you loaded the data from a file. Each time I do
>> the run, I'm working
>>>> with a  different subset of the data, i.e., a different
>> result set of the
>>>> MySQL query.  I think, unless I missed something, that you
>> are repeating the
>>>> same analysis  on the same data 20 times.
>>>> 
>>>> Running the code as you sent it back to me,  I had similar
>> results to what
>>>> you did. But it wasn't the same analysis. Each  result
>> set- or group of
>>>> results for each iteration of the loop-- should be on  a
>> new subset of data.
>>>> Said differently, the first time through the loop, all
>> the cases should have
>>>> a value of "AA" for "symbol", next time through they
>> should all be "AIG",
>>>> etc. The file had 30 loops worth (the Dow), but it
>> usually dies around 6 or
>>>> 7. Don't know why just repeating them seems to work,  though...
>>>> 
>>>> I thought at one time to get all the data from outside the
>>  loop, then just
>>>> subset differently (with the "testset" and "predset"
>> definition) each time
>>>> through... That's the way it was originally, and when  the
>> problem first
>>>> showed up. I only moved the query inside the loop because
>> I  thought it would
>>>> spare me the overhead of partially duplicating the data in  memory.
>>>> 
>>>> Man, this is a head-scratcher.
>>>> 
>>>> 
>>>> On 5/9/04 21:05,  "Liaw, Andy" <andy_liaw at merck.com> wrote:
>>>> 
>>>> 
>>>>> David,
>>>>> 
>>>>> I assume the data you  posted is iteration worth in your
>> for loop?  I looped
>>>>> over it 20 times  and didn't get any errors (did have to
>> change the code a
>>>>> bit to make it  run).  Please look over the attached file
>> to see if what I
>>>>> tested is  close to what you would expect.  I ran it on
>> an Opteron 248 with
>>>>> 8GB of  RAM.  From `top', the maximum memory usage for
>> the R process is
>>>>> 366MB.   It took just over an hour to run the 20 reps, so
>> it was not using
>>>>> anywhere close to 1GB of RAM as your error message would
>> indicate.
>>>>> 
>>>>> I would really appreciate it if  you can strip the code
>> down as much as
>>>>> possible to only the part that  produce the error.  E.g.,
>> if none of the
>>>>> regression runs were causing  problems, comment them out
>> and see if you
>>>>> still get the error.  Saves  running time and eye-balling time.
>>>>> 
>>>>> Best,
>>>>> Andy
>>>>> 
>>>>>> 
>>>>>> 
>>>>>> -----Original  Message-----
>>>>>> From: David L. Van  Brunt, Ph.D.
>> [mailto:dvanbrunt at well-wired.com]
>>>>>> Sent: Friday, May  07, 2004 11:21 PM
>>>>>> To: Liaw,  Andy
>>>>>> Subject: Re: [R] " cannot  allocate vector of length  1072693248"
>>>>>> 
>>>>>> Good news/Bad  news....
>>>>>> 
>>>>>> 4.2-1  installed without a hitch from source on OS X.
>> But the same
>>>>>> behavior  occurred, and in the same place. In the
>> syntax code I sent, I
>>>>>> had commented  out the prediction call after
>> "checkpoint 1", but that only
>>>>>> stays the  execution... It dies at 5 of  30 if I leave
>> those lines in, but
>>>>>> dies anyway at  12 of 30 on "gain2"  if  I take 'em out.
>>>>>> 
>>>>>> HTH. 
>>>>>> 
>>>>>> On 5/7/04  21:09, "Liaw,  Andy" <andy_liaw at merck.com> wrote:
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>>> David,  Please see reply inline below.    Andy
>>>>>>> 
>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> -----Original   Message-----
>>>>>>>> From: David L. Van  Brunt, Ph.D.
>> [mailto:dvanbrunt at well-wired.com]
>>>>>>>> Sent: Friday, May  07, 2004 8:01  PM
>>>>>>>> To: Liaw,  Andy
>>>>>>>> Subject: Re: [R] " cannot   allocate vector of length
>> 1072693248"
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Thanks very much for   taking a crack at  this. It's
>> been a ton of fun,
>>>>>>>> but this bump in the  road sure   has me stumped.
>>>>>>>> 
>>>>>>>> I realized after emailing you   earlier that I left
>> out  important
>>>>>>>> information. Here   goes...
>>>>>>>> 
>>>>>>>> -Using R version 1.90 beta for OS  X, but  also did it
>>  on the latest
>>>>>>>> Windows version (same behavior), and  on  version 8.1
>> for Windows.
>>>>>>>> (same  behavior)
>>>>>>>> -randomForest 4.0-7
>>>>>>>> -No   problems at all on  regression.... Only happens with
>>>>>>>> classification!
>>>>>>>> [AL] Could you try version 4.2-1  at
>>>>>>>> 
>> http://home.comcast.net/~andyliaw/randomForest_4.2-1.tar.gz
>>  (source)
>>>>>>>> or 
>> http://home.comcast.net/~andyliaw/randomForest_4.2-1.zip    (Windows
>>>>>>>> binary) and see if that makes any    difference?
>>>>>>>> 
>>>>>>>> Here's the code .. If I remove   one code block, it
>> will give  the same
>>>>>>>> error on another  code block,  always failing with the
>>  memory overflow
>>>>>>>> right after "checkpoint  1"
>>>>>>>> 
>>>>>>>> Be   gentle,
>>>>>>>> [AL] Don't worry, I won't    bite...
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> I'm new at   this! This is all a learning  experience
>> for me, and I
>>>>>>>> thought some  readily available data would make for a
>> good  exercise.
>>>>>>>> This specific  challenge is to loop through the Dow  data, make
>>>>>>>> predictions for each  member, save out the  results to
>> a table. Yes, it
>>>>>>>> is  silly, but it's  a great way  to learn your way
>> around a new program!
>>>>>>>> 
>>>>>>>> The  data   file is quite large, which is why I use
>> MySQL and only pull
>>>>>>>> in a  little   bit at a time. That's what I initially
>> thought was  wrong
>>>>>>>> (too much  data in  memory, as I read in the whole
>> thing) and why I put
>>>>>>>> the  select query inside  the loop to  only pull out
>> one member at a
>>>>>>>> time.   I'm attaching the  data,  so you can get the
>> structure. I'm sure
>>>>>>>> there are a  lot of ways I could write  this better,
>> but it does work
>>>>>>>> for the first few times through. Here's the   code...
>>>>>>>> [AL] If you sent  the data as zip file,  it would have
>>  been stripped off
>>>>>>>> silently by  our email  servers.  Could you post it
>> on a web site
>>>>>>>> somewhere   that I can download, or use the bzip2
>> format  instead?   It's
>>>>>>>> hard for me to diagnose without   data.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>>> 
>> --------------------------------------------------------------
>> ------------
>>>>>>> ----
>>>>>>> Notice:    This e-mail message, together with any
>> attachments, contains
>>>>>>> information of Merck  Co., Inc. (One Merck Drive,
>> Whitehouse  Station,
>>>>>>> New Jersey, USA 08889), and/or its affiliates (which
>> may  be known outside
>>>>>>> the United States as Merck Frosst, Merck Sharp   Dohme
>> or MSD and in
>>>>>>> Japan, as Banyu) that may be  confidential, proprietary
>> copyrighted and/or
>>>>>>> legally privileged.  It is intended solely for the use
>> of the individual
>>>>>>> or  entity  named on this message.  If you are not the
>> intended recipient,
>>>>>>> and have received this message in error, please notify
>> us  immediately by
>>>>>>> reply e-mail and then delete it from your   system.
>>>>>>> 
>> --------------------------------------------------------------
>> ------------
>>>>>>> ----
>>>>>>> 
>>>>>> 
>>>> 
>> 
>> 
>> -- 
>> David L. Van Brunt, Ph.D.
>> Outlier Consulting & Development
>> mailto: <ocd at well-wired.com>
>> 
>> 
>> 
>> 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments, contains
> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New
> Jersey, USA 08889), and/or its affiliates (which may be known outside the
> United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as
> Banyu) that may be confidential, proprietary copyrighted and/or legally
> privileged. It is intended solely for the use of the individual or entity
> named on this message.  If you are not the intended recipient, and have
> received this message in error, please notify us immediately by reply e-mail
> and then delete it from your system.
> ------------------------------------------------------------------------------

-- 
David L. Van Brunt, Ph.D.
Outlier Consulting & Development
mailto: <ocd at well-wired.com>



From deanylee at hotmail.com  Sat May 15 22:13:54 2004
From: deanylee at hotmail.com (Dean Lee)
Date: Sun, 16 May 2004 04:13:54 +0800
Subject: [R] questions about optim
Message-ID: <Sea1-F66MHXVtIXIETO00014af4@hotmail.com>

Hi,
I am trying to do parameter estimation with optim, but I can't get it to 
work quite right-- I have an equation X = Y where X is a gaussian, Y is a 
multinomial distribution, and I am trying to estimate the probabilities of 
Y( the mean and sd of X are known ), Theta1, Theta2, Theta3, and Theta4; I 
do not know how I can specify the constraint that Theta1 + Theta2 + Theta3 + 
Theta4 = 1 in optim. Is there another method/package that I should use for 
this?
Also, I wonder if there's a more elegant way to code this equation in R; 
right now my function looks something like Y/rnorm( 10000, mean, sd), and I 
try to maximize it to 1; is it possible to "plug" the entire gaussian( 
instead of using rnorm ) into the equation? Thanks.

Regards,

-Dean



From spencer.graves at pdf.com  Sat May 15 22:38:38 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 15 May 2004 13:38:38 -0700
Subject: [R] questions about optim
In-Reply-To: <Sea1-F66MHXVtIXIETO00014af4@hotmail.com>
References: <Sea1-F66MHXVtIXIETO00014af4@hotmail.com>
Message-ID: <40A67FCE.6030807@pdf.com>

      1.  Have you considered parameterizing the problem in terms of 
(Theta1, Theta2, Theta3), and then computing Theta4 <- 
(1-Theta1-Theta2-Theta3) in the function you ask "optim" to optimize? 

      2.  Beyond this, I don't understand what you are trying to do.  Do 
you want to estimate a multinomial approximation to a normal 
distribution?  If yes, are you given the mean and standard deviation of 
the normal distribution PLUS the break points?  If yes, then what about 
the following: 

 > Breaks <- 1:3
 > Mean <- 0
 > Sd <- 1
 > Theta1 <- pnorm((Breaks[1]-Mean)/Sd)
 > Theta2 <- (pnorm((Breaks[2]-Mean)/Sd)-Theta1)
 > Theta3 <- (pnorm((Breaks[3]-Mean)/Sd)-Theta2)
 > Theta4 <- pnorm((Breaks[3]-Mean)/Sd, lower.tail=FALSE)
 > Breaks <- 1:3
 > Mean <- 0
 > Sd <- 1
 > Theta1 <- pnorm((Breaks[1]-Mean)/Sd)
 > Theta2 <- (pnorm((Breaks[2]-Mean)/Sd)-Theta1)
 > Theta3 <- (pnorm((Breaks[3]-Mean)/Sd)-Theta2)
 > Theta4 <- pnorm((Breaks[3]-Mean)/Sd, lower.tail=FALSE)
 > Theta1;Theta2;Theta3;Theta4
[1] 0.8413447
[1] 0.1359051
[1] 0.862745
[1] 0.001349898
 
       hope this helps.  spencer graves

Dean Lee wrote:

> Hi,
> I am trying to do parameter estimation with optim, but I can't get it 
> to work quite right-- I have an equation X = Y where X is a gaussian, 
> Y is a multinomial distribution, and I am trying to estimate the 
> probabilities of Y( the mean and sd of X are known ), Theta1, Theta2, 
> Theta3, and Theta4; I do not know how I can specify the constraint 
> that Theta1 + Theta2 + Theta3 + Theta4 = 1 in optim. Is there another 
> method/package that I should use for this?
> Also, I wonder if there's a more elegant way to code this equation in 
> R; right now my function looks something like Y/rnorm( 10000, mean, 
> sd), and I try to maximize it to 1; is it possible to "plug" the 
> entire gaussian( instead of using rnorm ) into the equation? Thanks.
>
> Regards,
>
> -Dean
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From sdhyok at email.unc.edu  Sat May 15 22:53:49 2004
From: sdhyok at email.unc.edu (Shin)
Date: 15 May 2004 16:53:49 -0400
Subject: [R] How to restore and edit saved graphics?
Message-ID: <1084654429.1904.4.camel@localhost.localdomain>

I am looking for a function to restore saved graphics for further
editing, such as changing its title, labels, or legend.
How can I do it in R? Thanks in advance.

-- 
Daehyok Shin (Peter)
Geography Department
Univ. of North Carolina-Chapel Hill



From ozric at web.de  Sat May 15 23:18:23 2004
From: ozric at web.de (Christian Schulz)
Date: Sat, 15 May 2004 23:18:23 +0200
Subject: [R] what  statistical method should i use?
In-Reply-To: <0HXR00HDDJX2WH@mail.fudan.edu.cn>
References: <0HXR00HDDJX2WH@mail.fudan.edu.cn>
Message-ID: <200405152318.25026.ozric@web.de>

IMHO  Conjoint-Analysis and MarketSimluations -
there exist some nice  extensions 
for practical problems like 
adaptive-conjoint-analysis ,
choice-based conjoint analysis  etc.

christian

Am Samstag, 15. Mai 2004 18:23 schrieb vinkwai wong:
> in order to know which production the custumer most like,i design a
> question as follow :
>
> Q:there are six production listed below.according to your preference,the
> production you like most is_____,the production you secondly like is
> ____,and the third is_____. productionA      productionB      productionC  
>    productionD     productionE      productionF
>
> when the data is collected. i type in a stata in such format:
>
> firstlike          secondlike          thirdlike
> A                      C                   D
> E                      A                   E
> 
>
> if i want to make a decision what production should i choose as my main
> production according to the survey,what statistical method should i use to
> analysis my data ?
>
> my aim is to let the analysis result support my descision.
>
> any suggestion is appreciated.
>
> thank you .
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From deanylee at hotmail.com  Sat May 15 23:45:50 2004
From: deanylee at hotmail.com (Dean Lee)
Date: Sun, 16 May 2004 05:45:50 +0800
Subject: [R] questions about optim
Message-ID: <Sea1-F137mvg5VYy9KR00014a0e@hotmail.com>

Hi Spencer,
Thanks for the reply.

1) When I was playing with optim before sometimes the probabilities came up 
to be negative. I am not sure what I did before, but now it seems to work 
correctly after I specify the lower and upper bounds on the Thetas using the 
L-BFGS-B method in optim.

2) No the break points are not given. But yes, I am trying to estimate a 
multinomial to a normal; sorry I wasn't being clear. What are some of the 
approaches that I can try in this case? Thanks.

Regards,

-Dean





>From: Spencer Graves <spencer.graves at pdf.com>
>To: Dean Lee <deanylee at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] questions about optim
>Date: Sat, 15 May 2004 13:38:38 -0700
>
>      1.  Have you considered parameterizing the problem in terms of 
>(Theta1, Theta2, Theta3), and then computing Theta4 <- 
>(1-Theta1-Theta2-Theta3) in the function you ask "optim" to optimize?
>
>      2.  Beyond this, I don't understand what you are trying to do.  Do 
>you want to estimate a multinomial approximation to a normal distribution?  
>If yes, are you given the mean and standard deviation of the normal 
>distribution PLUS the break points?  If yes, then what about the following:
>
> > Breaks <- 1:3
> > Mean <- 0
> > Sd <- 1
> > Theta1 <- pnorm((Breaks[1]-Mean)/Sd)
> > Theta2 <- (pnorm((Breaks[2]-Mean)/Sd)-Theta1)
> > Theta3 <- (pnorm((Breaks[3]-Mean)/Sd)-Theta2)
> > Theta4 <- pnorm((Breaks[3]-Mean)/Sd, lower.tail=FALSE)
> > Breaks <- 1:3
> > Mean <- 0
> > Sd <- 1
> > Theta1 <- pnorm((Breaks[1]-Mean)/Sd)
> > Theta2 <- (pnorm((Breaks[2]-Mean)/Sd)-Theta1)
> > Theta3 <- (pnorm((Breaks[3]-Mean)/Sd)-Theta2)
> > Theta4 <- pnorm((Breaks[3]-Mean)/Sd, lower.tail=FALSE)
> > Theta1;Theta2;Theta3;Theta4
>[1] 0.8413447
>[1] 0.1359051
>[1] 0.862745
>[1] 0.001349898
>
>       hope this helps.  spencer graves



From spencer.graves at pdf.com  Sat May 15 23:59:32 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 15 May 2004 14:59:32 -0700
Subject: [R] questions about optim
In-Reply-To: <Sea1-F137mvg5VYy9KR00014a0e@hotmail.com>
References: <Sea1-F137mvg5VYy9KR00014a0e@hotmail.com>
Message-ID: <40A692C4.6080606@pdf.com>

      I gather you are trying to solve a system of 5 equations with 7 
unknowns:  The 5 equations are the constraint that the probabilities sum 
to 0 plus the 4 equations I wrote?  This is an underdetermined system, 
and you should not need "optim" for that. 

      Why do you want a multinomial approximation to a normal with the 
breakpoints unknown?  What's the problem for which an answer to your 
question should provide a solution? 

      hope this helps.  spencer graves

Dean Lee wrote:

> Hi Spencer,
> Thanks for the reply.
>
> 1) When I was playing with optim before sometimes the probabilities 
> came up to be negative. I am not sure what I did before, but now it 
> seems to work correctly after I specify the lower and upper bounds on 
> the Thetas using the L-BFGS-B method in optim.
>
> 2) No the break points are not given. But yes, I am trying to estimate 
> a multinomial to a normal; sorry I wasn't being clear. What are some 
> of the approaches that I can try in this case? Thanks.
>
> Regards,
>
> -Dean
>
>
>
>
>
>> From: Spencer Graves <spencer.graves at pdf.com>
>> To: Dean Lee <deanylee at hotmail.com>
>> CC: r-help at stat.math.ethz.ch
>> Subject: Re: [R] questions about optim
>> Date: Sat, 15 May 2004 13:38:38 -0700
>>
>>      1.  Have you considered parameterizing the problem in terms of 
>> (Theta1, Theta2, Theta3), and then computing Theta4 <- 
>> (1-Theta1-Theta2-Theta3) in the function you ask "optim" to optimize?
>>
>>      2.  Beyond this, I don't understand what you are trying to do.  
>> Do you want to estimate a multinomial approximation to a normal 
>> distribution?  If yes, are you given the mean and standard deviation 
>> of the normal distribution PLUS the break points?  If yes, then what 
>> about the following:
>>
>> > Breaks <- 1:3
>> > Mean <- 0
>> > Sd <- 1
>> > Theta1 <- pnorm((Breaks[1]-Mean)/Sd)
>> > Theta2 <- (pnorm((Breaks[2]-Mean)/Sd)-Theta1)
>> > Theta3 <- (pnorm((Breaks[3]-Mean)/Sd)-Theta2)
>> > Theta4 <- pnorm((Breaks[3]-Mean)/Sd, lower.tail=FALSE)
>> > Breaks <- 1:3
>> > Mean <- 0
>> > Sd <- 1
>> > Theta1 <- pnorm((Breaks[1]-Mean)/Sd)
>> > Theta2 <- (pnorm((Breaks[2]-Mean)/Sd)-Theta1)
>> > Theta3 <- (pnorm((Breaks[3]-Mean)/Sd)-Theta2)
>> > Theta4 <- pnorm((Breaks[3]-Mean)/Sd, lower.tail=FALSE)
>> > Theta1;Theta2;Theta3;Theta4
>> [1] 0.8413447
>> [1] 0.1359051
>> [1] 0.862745
>> [1] 0.001349898
>>
>>       hope this helps.  spencer graves
>
>
> _________________________________________________________________
> MSN 8 with e-mail virus protection service: 2 months FREE* 
> http://join.msn.com/?page=features/virus
>



From ozric at web.de  Sun May 16 00:02:56 2004
From: ozric at web.de (Christian Schulz)
Date: Sun, 16 May 2004 00:02:56 +0200
Subject: [R] filter out many data.frames
Message-ID: <200405160002.57228.ozric@web.de>

Hi ,

i would like  filter out all combinations of a  data-mining result?
How i have to declare X because in every loop step it have another lengths ?

  X <- numeric(length(i1,...,i64))  ?

Many thanks
Christian


 tres <- function(data.frame) {
+ data <- expand.grid(class02 = c("A","B","C","D"), class04 = 
c("A","B","C","D"),PREDICT = c("A","B","C","D"))
+     for (i in 1:nrow(data)){
+     X[i]<- dtree[dtree$class02 == paste(data$class02[i]) & dtree$class04 == 
paste(data$class04[i]) & dtree$PREDICT==paste(data$PREDICT[i]),]
+     }
+     return(X[i])
+     }
> 
>  tres(dtree)
Error: Object "X" not found



From ozric at web.de  Sun May 16 00:12:22 2004
From: ozric at web.de (Christian Schulz)
Date: Sun, 16 May 2004 00:12:22 +0200
Subject: [R] Fwd: filter out many data.frames
Message-ID: <200405160012.26269.ozric@web.de>

  X <- numeric(length(data.frame))
before the loop maybe work, because
my computer works and works !? 

christian


----------  Weitergeleitete Nachricht  ----------

Subject: filter out many data.frames
Date: Sonntag, 16. Mai 2004 00:02
From: Christian Schulz <ozric at web.de>
To: r-help at stat.math.ethz.ch

Hi ,

i would like  filter out all combinations of a  data-mining result?
How i have to declare X because in every loop step it have another lengths ?

  X <- numeric(length(i1,...,i64))  ?

Many thanks
Christian


 tres <- function(data.frame) {
+ data <- expand.grid(class02 = c("A","B","C","D"), class04 =
c("A","B","C","D"),PREDICT = c("A","B","C","D"))
+     for (i in 1:nrow(data)){
+     X[i]<- dtree[dtree$class02 == paste(data$class02[i]) & dtree$class04 ==
paste(data$class04[i]) & dtree$PREDICT==paste(data$PREDICT[i]),]
+     }
+     return(X[i])
+     }

>  tres(dtree)

Error: Object "X" not found



From baron at psych.upenn.edu  Sun May 16 04:36:01 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sat, 15 May 2004 22:36:01 -0400
Subject: [R] How to restore and edit saved graphics?
In-Reply-To: <1084654429.1904.4.camel@localhost.localdomain>
References: <1084654429.1904.4.camel@localhost.localdomain>
Message-ID: <20040516023601.GA12916@psych>

On 05/15/04 16:53, Shin wrote:
>I am looking for a function to restore saved graphics for further
>editing, such as changing its title, labels, or legend.
>How can I do it in R? Thanks in advance.

Probably the easiest way is simply to save the code that you used
to make the graphic, edit the code, and run it again.  This is a
good way to work with R anyway.

If, for some reason, the graphics tools available for R are not
sufficient - and I find this hard to imagine - you can also save
graphics as xfig files and then edit them with xfig, assuming
that you are using Unix/Linux.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron



From sdhyok at email.unc.edu  Sun May 16 04:49:36 2004
From: sdhyok at email.unc.edu (Shin, Daehyok)
Date: Sat, 15 May 2004 22:49:36 -0400
Subject: [R] How to restore and edit saved graphics?
In-Reply-To: <20040516023601.GA12916@psych>
Message-ID: <OAEOKPIGCLDDHAEMCAKIOENOCMAA.sdhyok@email.unc.edu>

Is it so difficult to develop a function or an object to generate all the
code automatically in R?

Daehyok Shin (Peter)
Terrestrial Hydrological Ecosystem Modellers
Geography Department
University of North Carolina-Chapel Hill
sdhyok at email.unc.edu

"We can do no great things,
only small things with great love."
                         - Mother Teresa

> -----Original Message-----
> From: Jonathan Baron [mailto:baron at psych.upenn.edu]
> Sent: Saturday, May 15, 2004 PM 10:36
> To: Shin
> Cc: R Help
> Subject: Re: [R] How to restore and edit saved graphics?
>
>
> On 05/15/04 16:53, Shin wrote:
> >I am looking for a function to restore saved graphics for further
> >editing, such as changing its title, labels, or legend.
> >How can I do it in R? Thanks in advance.
>
> Probably the easiest way is simply to save the code that you used
> to make the graphic, edit the code, and run it again.  This is a
> good way to work with R anyway.
>
> If, for some reason, the graphics tools available for R are not
> sufficient - and I find this hard to imagine - you can also save
> graphics as xfig files and then edit them with xfig, assuming
> that you are using Unix/Linux.
>
> Jon
> --
> Jonathan Baron, Professor of Psychology, University of Pennsylvania
> Home page:            http://www.sas.upenn.edu/~baron
>



From grr at grell.mailshell.com  Sun May 16 05:40:41 2004
From: grr at grell.mailshell.com (grr@grell.mailshell.com)
Date: Sat, 15 May 2004 20:40:41 -0700
Subject: [R] importing text file with duplicate rows / indexing rows and
	columns
Message-ID: <1084678841.40a6e2b9ea61c@www.mailshell.com>

Could somebody advise me about importing a txt file as a frame? I am using the command:

test <- read.delim ("~/docs/perl/expr_ctx.txt2", header=T, sep = "\t", row.names = 1)

This gives me an error because there are duplicate rows. 

In the txt file, the columns are unique subjects and the rows are variables, so I had planned to transform the file after importing. The first row and column are text labels, which I could either leave in (with duplicate rows) or ask R to remove for me, saving another file with index values. But I can't figure out how to do either of these things.

Thanks for any help,

Graham



From ggrothendieck at myway.com  Sun May 16 05:58:59 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 16 May 2004 03:58:59 +0000 (UTC)
Subject: [R] How to restore and edit saved graphics?
References: <1084654429.1904.4.camel@localhost.localdomain>
Message-ID: <loom.20040516T053602-867@post.gmane.org>

Saving of the low level graphics that R displays can be 
1. turned on with dev.control(displaylist="enable") and 
2. turned off with dev.control(displaylist="inhibit").  
recordPlot() can be used to save the display list in a variable.

For example:

# turn on display list, perform plot, turn off display list, add title
# do not need next line if graphics device already active
windows()  # or x11() on unix
dev.control(displaylist="enable") 
plot(1:10)
myplot <- recordPlot() 
dev.control(displaylist="inhibit")  
title(main="My Title")

# now redisplay plot as it was before title and reissue title
myplot 
title(main="My Other Title")

Shin <sdhyok <at> email.unc.edu> writes:

: 
: I am looking for a function to restore saved graphics for further
: editing, such as changing its title, labels, or legend.
: How can I do it in R? Thanks in advance.
:



From ajayshah at mayin.org  Sun May 16 08:15:12 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Sun, 16 May 2004 11:45:12 +0530
Subject: [R] Moving window regressions - how can I improve this code?
In-Reply-To: <6rvfjpbhqa.fsf@bates4.stat.wisc.edu>
References: <20040424050921.GI732@igidr.ac.in>
	<6rvfjpbhqa.fsf@bates4.stat.wisc.edu>
Message-ID: <20040516061512.GR791@igidr.ac.in>

Prof. Bates, Gabor,

I had written a posting, some weeks ago, where I had written
fortrannish code for "moving window regressions" (also called 'rolling
window regression'), and asked how to do the code better. Both of you
had put much pain on this, and emerged with this great code:

   data(women)
   movingWindow2 <- function(formula, data, width, ...) {
       mCall = match.call()
       mCall$width = NULL
       mCall[[1]] = as.name("lm")
       mCall$x = mCall$y = TRUE
       bigfit = eval(mCall, parent.frame())
       ncoef = length(coef(bigfit))
       nr = nrow(data)
       width = as.integer(width)[1]
       stopifnot(width >= ncoef, width <= nr)
       y = bigfit$y
       x = bigfit$x
       terms = bigfit$terms
       inds = embed(seq(nr), width)[, rev(seq(width))]
       sumrys <- lapply(seq(nrow(inds)),
                        function(st) {
                            ind = inds[st,]
                            fit = lm.fit(x[ind,], y[ind])
                            fit$terms = terms
                            class(fit) = "lm"
                            summary(fit)
                        })
       list(coefficients = sapply(sumrys, function(sm) coef(sm)[,"Estimate"]),
            Std.Error = sapply(sumrys, function(sm) coef(sm)[,"Std. Error"]),
            sigma = sapply(sumrys, "[[", "sigma"),
            r.squared = sapply(sumrys, "[[", "r.squared"))
   }

I have one piece of information, and one bugreport:

  * I timed this, and compared it against my fortrannish code, and
    this is roughly 2.5x faster :-)

    > junk = data.frame(x=runif(1000), y=runif(1000))
    > system.time(movingWindowRegression(women, 1000, 9, weight ~ height, 2))
    [1] 20.07  0.01 20.80  0.00  0.00
    > system.time(movingWindow2(y ~ x, junk, 10))
    [1] 8.27 0.03 8.43 0.00 0.00

    (My notebook is a Celeron @ 500 Mhz).

  * I find it breaks when I ask him to do a regression on 1:

    > r = movingWindowRegression(junk, 1000, 10, y ~ 1, 1)
    > movingWindow2(y ~ 1, junk, 10) 
    Error in lm.fit(x[ind, ], y[ind]) : `x' must be a matrix


I am in awe of the movingWindow2 code but don't quite know what to
tamper with! :-) Could you please help?

movingWindow2 should be renamed to movingWindow, and it should really
be in some standard CRAN package. I know a lot of people who do moving
window estimation all the time and this fits. It does moving window
regressions, and using the formula X ~ 1, it also gives you rolling
window means and standard deviations.

For anyone who reads this post, and is interested in moving window
regressions, please do go back into the list archives and follow this
thread. The comments and suggestions by everyone have been incredibly
insightful. For the sake of completeness, my old code is at EOF here -
you will find it useful only in case you want to run
movingWindowRegression in my bugdemo above.


As an aside, I noticed there are roll() and rollOLS() functions in the
(commercial) Finmetrics library that's sold with S+. Their prototypes
are :

  rollOLS(formula, data, subset, na.rm=F, contrasts=NULL, start=NULL,
          end=NULL, width=NULL, incr=1, tau=1e-10, trace=T, ...)

  roll(FUNCTION, data, width, incr=1, start=NULL, end=NULL,
       na.rm=F, save.list=NULL, arg.data="data", trace=T, ...)

here FUNCTION is the name of a S function for which rolling estimation
will be performed. The function must take an option "data". 

Their examples are:

  stack.dat = data.frame(Loss=stack.loss, stack.x)
  roll("OLS", stack.dat, 7, formula=Loss~Air.Flow+Water.Temp, save.list="coef")
  rollOLS(Loss~Water.Temp, data=stack.dat, width=6, incr=2)

In the case of rollOLS, they say that an efficient addition and
deletion algorithm is used for fast exection.

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi








# Using moving windows, we do an OLS regression.
#
# The function returns a matrix with T rows. So there are plenty of
# "NA" values in it. The columns are organised as:
#    beta1 s1 beta2 s2 beta3 s3 sigma R^2
# i.e. we have each regression coefficient followed by it's sigma,
# and then at the end we have the residual sigma and the regression R^2.
movingWindowRegression <- function(data, T, width, model, K) {
  results = matrix(nrow=T, ncol=2*K+2)
  for (i in width:T) {
    details <- summary.lm(lm(model, data[(i-width+1):i,]))
    n=1;
    for (j in 1:K) {
      results[i, n:(n+1)]   = details$coefficients[j, 1:2]
      n = n + 2
    }
    results[i, n] = details$sigma
    results[i, n+1] = details$r.squared
  }
  return(results)
}



From ripley at stats.ox.ac.uk  Sun May 16 08:24:13 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 May 2004 07:24:13 +0100 (BST)
Subject: [R] importing text file with duplicate rows / indexing rows and
	columns
In-Reply-To: <1084678841.40a6e2b9ea61c@www.mailshell.com>
Message-ID: <Pine.LNX.4.44.0405160721140.32514-100000@gannet.stats>

The issue is not `duplicate rows' but duplicated row names.  You asked R 
explicitly to make a column into row names -- if they are not suitable row 
names, don't do that.  You can remove duplicated rows later (see ?unique) 
but you cannot have duplicated row names in a data frame so leave them as 
numbers.


On Sat, 15 May 2004 grr at grell.mailshell.com wrote:

> Could somebody advise me about importing a txt file as a frame? I am using the command:
> 
> test <- read.delim ("~/docs/perl/expr_ctx.txt2", header=T, sep = "\t", row.names = 1)
> 
> This gives me an error because there are duplicate rows. 
> 
> In the txt file, the columns are unique subjects and the rows are
> variables, so I had planned to transform the file after importing. The
> first row and column are text labels, which I could either leave in
> (with duplicate rows) or ask R to remove for me, saving another file
> with index values. But I can't figure out how to do either of these
> things.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun May 16 08:31:20 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 May 2004 07:31:20 +0100 (BST)
Subject: [R] Moving window regressions - how can I improve this code?
In-Reply-To: <20040516061512.GR791@igidr.ac.in>
Message-ID: <Pine.LNX.4.44.0405160724470.32514-100000@gannet.stats>

You forgot drop=FALSE, one of the commonest S programmers' oversights.
The lm.fit call should be

                            fit = lm.fit(x[ind, , drop = FALSE], y[ind])

Please don't mix assignment operators in posted code, BTW.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From siewlengteng at yahoo.com  Sun May 16 10:07:20 2004
From: siewlengteng at yahoo.com (Siew Leng TENG)
Date: Sun, 16 May 2004 01:07:20 -0700 (PDT)
Subject: [R] Error in using coxph()
Message-ID: <20040516080720.25357.qmail@web50606.mail.yahoo.com>

Hi,

I am getting errors of the following kind. I can't
seem to point the source of the error. I would greatly
appreciate any advice.

Many thanks and good day,
-Melinda


Error message :
----------------
"Ran out of iterations and did not converge in:
fitter(X, Y, strats, offset, init, control, weights =
weights,..."

Details :
---------
E is a vector of survival times (or censored times),
1-F is a vector of '0's, and cov is a matrix of 1
column. There are altogether 75 observations.

Tried :
------
P <- try(surv.cox <- coxph(Surv(E, 1-F) ~ cov,
coxph.control(iter.max=1e10, eps = 1e-03)))

Output (from above command) :
-----------------------------
Call:
coxph(formula = Surv(E, F) ~ cov, data =
coxph.control(iter.max = 1e+10, 
    eps = 0.001))


      coef exp(coef) se(coef)     z     p
cov -0.233     0.793     0.11 -2.11 0.035

Likelihood ratio test=4.51  on 1 df, p=0.0336  n= 75 


Machine Specs :
----------------
Unix/ Windows XP
R-1.8.1
Survival package
		
__________________________________


From ripley at stats.ox.ac.uk  Sun May 16 11:52:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 May 2004 10:52:19 +0100 (BST)
Subject: [R] Error in using coxph()
In-Reply-To: <20040516080720.25357.qmail@web50606.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0405161038510.2679-100000@gannet.stats>

Note you said you used 1-F but the output said you used F. You also say
`1-F is a vector of '0's' so I think you may have declared that all
observations are right-censored.  (NB if you give Surv an event vector of
all 1's it is ambiguous, so don't do this.)

If you did declare all observations as censored, then it seems the coxph
algorithm does not cope (although I did not try to run it for 1e10
iterations).  That's really an undetected user error, as there is no 
information in the partial likelihood about the coefficient (and no 
recorded events).

On Sun, 16 May 2004, Siew Leng TENG wrote:

> I am getting errors of the following kind. I can't
> seem to point the source of the error. I would greatly
> appreciate any advice.

Please read the posting guide and try to avoid us having to guess what you 
actually did.

> Error message :
> ----------------
> "Ran out of iterations and did not converge in:
> fitter(X, Y, strats, offset, init, control, weights =
> weights,..."
> 
> Details :
> ---------
> E is a vector of survival times (or censored times),
> 1-F is a vector of '0's, and cov is a matrix of 1
> column. There are altogether 75 observations.
> 
> Tried :
> ------
> P <- try(surv.cox <- coxph(Surv(E, 1-F) ~ cov,
> coxph.control(iter.max=1e10, eps = 1e-03)))
> 
> Output (from above command) :
> -----------------------------
> Call:
> coxph(formula = Surv(E, F) ~ cov, data =
> coxph.control(iter.max = 1e+10, 
>     eps = 0.001))
> 
> 
>       coef exp(coef) se(coef)     z     p
> cov -0.233     0.793     0.11 -2.11 0.035
> 
> Likelihood ratio test=4.51  on 1 df, p=0.0336  n= 75 
> 
> 
> Machine Specs :
> ----------------
> Unix/ Windows XP
> R-1.8.1
> Survival package

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Sun May 16 12:48:40 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 16 May 2004 12:48:40 +0200
Subject: [R] Fwd: filter out many data.frames
In-Reply-To: <200405160012.26269.ozric@web.de>
References: <200405160012.26269.ozric@web.de>
Message-ID: <40A74708.8000208@statistik.uni-dortmund.de>

Christian Schulz wrote:
>   X <- numeric(length(data.frame))
> before the loop maybe work, because
> my computer works and works !? 
> 
> christian
> 
> 
> ----------  Weitergeleitete Nachricht  ----------
> 
> Subject: filter out many data.frames
> Date: Sonntag, 16. Mai 2004 00:02
> From: Christian Schulz <ozric at web.de>
> To: r-help at stat.math.ethz.ch
> 
> Hi ,
> 
> i would like  filter out all combinations of a  data-mining result?
> How i have to declare X because in every loop step it have another lengths ?
> 
>   X <- numeric(length(i1,...,i64))  ?
> 
> Many thanks
> Christian
> 
> 
>  tres <- function(data.frame) {
> + data <- expand.grid(class02 = c("A","B","C","D"), class04 =
> c("A","B","C","D"),PREDICT = c("A","B","C","D"))
> +     for (i in 1:nrow(data)){
> +     X[i]<- dtree[dtree$class02 == paste(data$class02[i]) & dtree$class04 ==
> paste(data$class04[i]) & dtree$PREDICT==paste(data$PREDICT[i]),]
> +     }
> +     return(X[i])
> +     }


Eh. You really want to rewrite that code. It depends on objects 
available in its parent (or grand-parent) envrionment.
I don't see why you need all those calls to paste().
You do *not* want to call an argument data.frame nor any other object 
data, but you *do* want to use the arguments specified.

Now, if X is initialized with numeric(), X is a numeric (n x 1) vector. 
I think you need at least a matrix or better a list, if the subsetting 
stuff returns more or even less than one row.

For a list X use, e.g.,
  X <- vector(nrow(data), mode = "list")
just before the for loop.

Uwe Ligges


> 
>> tres(dtree)
> 
> 
> Error: Object "X" not found
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From bates at stat.wisc.edu  Sun May 16 12:51:39 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 May 2004 05:51:39 -0500
Subject: [R] Moving window regressions - how can I improve this code?
In-Reply-To: <20040516061512.GR791@igidr.ac.in>
References: <20040424050921.GI732@igidr.ac.in>
	<6rvfjpbhqa.fsf@bates4.stat.wisc.edu>
	<20040516061512.GR791@igidr.ac.in>
Message-ID: <6r8yfsve4k.fsf@bates4.stat.wisc.edu>

Ajay Shah <ajayshah at mayin.org> writes:

> I had written a posting, some weeks ago, where I had written
> fortrannish code for "moving window regressions" (also called 'rolling
> window regression'), and asked how to do the code better. Both of you
> had put much pain on this, and emerged with this great code:
> 
>    data(women)
>    movingWindow2 <- function(formula, data, width, ...) {
>        mCall = match.call()
>        mCall$width = NULL
>        mCall[[1]] = as.name("lm")
>        mCall$x = mCall$y = TRUE
>        bigfit = eval(mCall, parent.frame())
>        ncoef = length(coef(bigfit))
>        nr = nrow(data)
>        width = as.integer(width)[1]
>        stopifnot(width >= ncoef, width <= nr)
>        y = bigfit$y
>        x = bigfit$x
>        terms = bigfit$terms
>        inds = embed(seq(nr), width)[, rev(seq(width))]
>        sumrys <- lapply(seq(nrow(inds)),
>                         function(st) {
>                             ind = inds[st,]
>                             fit = lm.fit(x[ind,], y[ind])
>                             fit$terms = terms
>                             class(fit) = "lm"
>                             summary(fit)
>                         })
>        list(coefficients = sapply(sumrys, function(sm) coef(sm)[,"Estimate"]),
>             Std.Error = sapply(sumrys, function(sm) coef(sm)[,"Std. Error"]),
>             sigma = sapply(sumrys, "[[", "sigma"),
>             r.squared = sapply(sumrys, "[[", "r.squared"))
>    }
> 
> I have one piece of information, and one bugreport:
> 
>   * I timed this, and compared it against my fortrannish code, and
>     this is roughly 2.5x faster :-)
> 
>     > junk = data.frame(x=runif(1000), y=runif(1000))
>     > system.time(movingWindowRegression(women, 1000, 9, weight ~ height, 2))
>     [1] 20.07  0.01 20.80  0.00  0.00
>     > system.time(movingWindow2(y ~ x, junk, 10))
>     [1] 8.27 0.03 8.43 0.00 0.00

You seem to be comparing timings on different data sets and models.
Did you mean to use junk and y ~ x in your first timing call?

>     (My notebook is a Celeron @ 500 Mhz).
> 
>   * I find it breaks when I ask him to do a regression on 1:
> 
>     > r = movingWindowRegression(junk, 1000, 10, y ~ 1, 1)
>     > movingWindow2(y ~ 1, junk, 10) 
>     Error in lm.fit(x[ind, ], y[ind]) : `x' must be a matrix

It looks like I made the common mistake of forgetting to add
drop=FALSE when extracting a subset of a matrix in a context where the
result must be a matrix.  (With the default of drop = TRUE, dimensions
for which the range of the index is of length 1 are dropped.)

Try changing the call of lm.fit to 
   lm.fit(x[ind, , drop = FALSE), y[ind])



From bates at stat.wisc.edu  Sun May 16 13:23:11 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 May 2004 06:23:11 -0500
Subject: [R] Moving window regressions - how can I improve this code?
In-Reply-To: <6r8yfsve4k.fsf@bates4.stat.wisc.edu>
References: <20040424050921.GI732@igidr.ac.in>
	<6rvfjpbhqa.fsf@bates4.stat.wisc.edu>
	<20040516061512.GR791@igidr.ac.in>
	<6r8yfsve4k.fsf@bates4.stat.wisc.edu>
Message-ID: <6r1xlkvco0.fsf@bates4.stat.wisc.edu>

Douglas Bates <bates at cs.wisc.edu> writes:

...
> Try changing the call of lm.fit to 
>    lm.fit(x[ind, , drop = FALSE), y[ind])

It will probably work better without the syntax error, as
                lm.fit(x[ind, , drop = FALSE], y[ind])



From ozric at web.de  Sun May 16 14:08:57 2004
From: ozric at web.de (Christian Schulz)
Date: Sun, 16 May 2004 14:08:57 +0200
Subject: [R] Fwd: filter out many data.frames
In-Reply-To: <40A74708.8000208@statistik.uni-dortmund.de>
References: <200405160012.26269.ozric@web.de>
	<40A74708.8000208@statistik.uni-dortmund.de>
Message-ID: <200405161408.57479.ozric@web.de>

Yes, i have recognized my stupid approach.
Now it works but any help how i get
the names in tList from the expand.grid combinaton's instead
number from 1:64 would like great!

Thanks Christian



data <- expand.grid(class02 = c("A","B","C","D"), class04 = 
c("A","B","C","D"),PREDICT = c("A","B","C","D"))
tList  <- vector("list", numeric(length(data)))

tasign <- paste("tList[[n]]  <-   try(summary(dtree[dtree$class02 == 
paste(data$class02[n]) & dtree$class04 == paste(data$class04[n]) & 
dtree$PREDICT==paste(data$PREDICT[n]),]))")
tasign <-  parse(text=tasign)[[1]]
          
for(n in 1:nrow(data)) {
  TAsign <- do.call("substitute",list(tasign,list(n=n,X=as.name(n))))
  eval(TAsign)
}




Am Sonntag, 16. Mai 2004 12:48 schrieb Uwe Ligges:
> Christian Schulz wrote:
> >   X <- numeric(length(data.frame))
> > before the loop maybe work, because
> > my computer works and works !?
> >
> > christian
> >
> >
> > ----------  Weitergeleitete Nachricht  ----------
> >
> > Subject: filter out many data.frames
> > Date: Sonntag, 16. Mai 2004 00:02
> > From: Christian Schulz <ozric at web.de>
> > To: r-help at stat.math.ethz.ch
> >
> > Hi ,
> >
> > i would like  filter out all combinations of a  data-mining result?
> > How i have to declare X because in every loop step it have another
> > lengths ?
> >
> >   X <- numeric(length(i1,...,i64))  ?
> >
> > Many thanks
> > Christian
> >
> >
> >  tres <- function(data.frame) {
> > + data <- expand.grid(class02 = c("A","B","C","D"), class04 =
> > c("A","B","C","D"),PREDICT = c("A","B","C","D"))
> > +     for (i in 1:nrow(data)){
> > +     X[i]<- dtree[dtree$class02 == paste(data$class02[i]) &
> > dtree$class04 == paste(data$class04[i]) &
> > dtree$PREDICT==paste(data$PREDICT[i]),] +     }
> > +     return(X[i])
> > +     }
>
> Eh. You really want to rewrite that code. It depends on objects
> available in its parent (or grand-parent) envrionment.
> I don't see why you need all those calls to paste().
> You do *not* want to call an argument data.frame nor any other object
> data, but you *do* want to use the arguments specified.
>
> Now, if X is initialized with numeric(), X is a numeric (n x 1) vector.
> I think you need at least a matrix or better a list, if the subsetting
> stuff returns more or even less than one row.
>
> For a list X use, e.g.,
>   X <- vector(nrow(data), mode = "list")
> just before the for loop.
>
> Uwe Ligges
>
> >> tres(dtree)
> >
> > Error: Object "X" not found
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Sun May 16 14:28:22 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 16 May 2004 08:28:22 -0400 (EDT)
Subject: [R] Moving window regressions - how can I improve this code?
Message-ID: <20040516122822.C9B983967@mprdmxin.myway.com>


Others have already addressed the bug.

Your other question seems to be how to get some simplification.
Note that Greg Warnes responded in:
http://article.gmane.org/gmane.comp.lang.r.general/18033
regarding the use of running in gregmisc. 

Another thing you could do
if you want to retain the speed of the lm.fit solution yet
not deal with the argument manipulations in that solution is
that you could pass the lm structure to your routine instead 
of reconstructing the lm structure in the routine, itself.  
That provides some simplification at the expense of a slightly 
more complex calling sequence:

# e.g. movingWindow3( lm(weight ~ height, women, x=TRUE, y=TRUE), 9 )
movingWindow3 <- function(lm., width) {
	x = lm.$x
	y = lm.$y
	nr = NROW(y)
	ncoef = length(coef(lm.))
	stopifnot(width >= ncoef, width <= nr)
	terms = lm.$terms
	inds = embed(1:nr, width)[, width:1]
	sumrys <- apply(inds, 1, function(ix) {
			fit = lm.fit(x[ix,,drop=F], y[ix])
			fit$terms = terms
			class(fit) = "lm"
			summary(fit)
	})
	list(coefficients = sapply(sumrys, function(sm) coef(sm)[,"Estimate"]),
	  Std.Error = sapply(sumrys, function(sm) coef(sm)[,"Std. Error"]),
	  sigma = sapply(sumrys, "[[", "sigma"),
	  r.squared = sapply(sumrys, "[[", "r.squared"))
}
z3 <- movingWindow3( lm(weight ~ height, women, x=TRUE, y=TRUE), 9 


--- 
Ajay Shah <ajayshah at mayin.org> writes:

> I had written a posting, some weeks ago, where I had written
> fortrannish code for "moving window regressions" (also called 'rolling
> window regression'), and asked how to do the code better. Both of you
> had put much pain on this, and emerged with this great code:
> 
> data(women)
> movingWindow2 <- function(formula, data, width, ...) {
> mCall = match.call()
> mCall$width = NULL
> mCall[[1]] = as.name("lm")
> mCall$x = mCall$y = TRUE
> bigfit = eval(mCall, parent.frame())
> ncoef = length(coef(bigfit))
> nr = nrow(data)
> width = as.integer(width)[1]
> stopifnot(width >= ncoef, width <= nr)
> y = bigfit$y
> x = bigfit$x
> terms = bigfit$terms
> inds = embed(seq(nr), width)[, rev(seq(width))]
> sumrys <- lapply(seq(nrow(inds)),
> function(st) {
> ind = inds[st,]
> fit = lm.fit(x[ind,], y[ind])
> fit$terms = terms
> class(fit) = "lm"
> summary(fit)
> })
> list(coefficients = sapply(sumrys, function(sm) coef(sm)[,"Estimate"]),
> Std.Error = sapply(sumrys, function(sm) coef(sm)[,"Std. Error"]),
> sigma = sapply(sumrys, "[[", "sigma"),
> r.squared = sapply(sumrys, "[[", "r.squared"))
> }
> 
> I have one piece of information, and one bugreport:
> 
> * I timed this, and compared it against my fortrannish code, and
> this is roughly 2.5x faster :-)
> 
> > junk = data.frame(x=runif(1000), y=runif(1000))
> > system.time(movingWindowRegression(women, 1000, 9, weight ~ height, 2))
> [1] 20.07 0.01 20.80 0.00 0.00
> > system.time(movingWindow2(y ~ x, junk, 10))
> [1] 8.27 0.03 8.43 0.00 0.00

You seem to be comparing timings on different data sets and models.
Did you mean to use junk and y ~ x in your first timing call?

> (My notebook is a Celeron @ 500 Mhz).
> 
> * I find it breaks when I ask him to do a regression on 1:
> 
> > r = movingWindowRegression(junk, 1000, 10, y ~ 1, 1)
> > movingWindow2(y ~ 1, junk, 10) 
> Error in lm.fit(x[ind, ], y[ind]) : `x' must be a matrix



From p.dalgaard at biostat.ku.dk  Sun May 16 14:25:07 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 May 2004 14:25:07 +0200
Subject: [R] Error in using coxph()
In-Reply-To: <Pine.LNX.4.44.0405161038510.2679-100000@gannet.stats>
References: <Pine.LNX.4.44.0405161038510.2679-100000@gannet.stats>
Message-ID: <x2vfiwv9ss.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> Note you said you used 1-F but the output said you used F. You also say
> `1-F is a vector of '0's' so I think you may have declared that all
> observations are right-censored.  (NB if you give Surv an event vector of
> all 1's it is ambiguous, so don't do this.)

Actually, it *is* documented that this is interpreted as "all-died"
and the advice in ?Surv is just to avoid 1/2 coding if all data are
censored. It's a bit puzzling that we don't allow explicit
disambiguation (e.g., by passing the event as a two-level factor),
though.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Sun May 16 15:10:58 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 16 May 2004 15:10:58 +0200
Subject: [R] Fwd: filter out many data.frames
In-Reply-To: <200405161408.57479.ozric@web.de>
References: <200405160012.26269.ozric@web.de>
	<40A74708.8000208@statistik.uni-dortmund.de>
	<200405161408.57479.ozric@web.de>
Message-ID: <40A76862.8060800@statistik.uni-dortmund.de>

Christian Schulz wrote:
> Yes, i have recognized my stupid approach.
> Now it works but any help how i get
> the names in tList from the expand.grid combinaton's instead
> number from 1:64 would like great!
> 
> Thanks Christian
> 
> 
> 
> data <- expand.grid(class02 = c("A","B","C","D"), class04 = 
> c("A","B","C","D"),PREDICT = c("A","B","C","D"))
> tList  <- vector("list", numeric(length(data)))

No. I told you to use vector(nrow(data), mode = "list").
length(data) equal 3 in your case, and numeric(3) is 0, hence you get an 
empty list. But you want to get one intitialized with 64 elements!

Furthermore, I told you that there are better ideas than calling an 
object "data".


> tasign <- paste("tList[[n]]  <-   try(summary(dtree[dtree$class02 == 
> paste(data$class02[n]) & dtree$class04 == paste(data$class04[n]) & 
> dtree$PREDICT==paste(data$PREDICT[n]),]))")
> tasign <-  parse(text=tasign)[[1]]
>           
> for(n in 1:nrow(data)) {
>   TAsign <- do.call("substitute",list(tasign,list(n=n,X=as.name(n))))
>   eval(TAsign)
> }

So, why are you doing these complicated things?

Just using
     names(theList) <- apply(data, 1, paste, collapse="")
(you want to replace data by the corrected name) after your loop in your 
first version would be sufficient, if you are going to name the list 
elements....

Uwe Ligges


> 
> 
> 
> Am Sonntag, 16. Mai 2004 12:48 schrieb Uwe Ligges:
> 
>>Christian Schulz wrote:
>>
>>>  X <- numeric(length(data.frame))
>>>before the loop maybe work, because
>>>my computer works and works !?
>>>
>>>christian
>>>
>>>
>>>----------  Weitergeleitete Nachricht  ----------
>>>
>>>Subject: filter out many data.frames
>>>Date: Sonntag, 16. Mai 2004 00:02
>>>From: Christian Schulz <ozric at web.de>
>>>To: r-help at stat.math.ethz.ch
>>>
>>>Hi ,
>>>
>>>i would like  filter out all combinations of a  data-mining result?
>>>How i have to declare X because in every loop step it have another
>>>lengths ?
>>>
>>>  X <- numeric(length(i1,...,i64))  ?
>>>
>>>Many thanks
>>>Christian
>>>
>>>
>>> tres <- function(data.frame) {
>>>+ data <- expand.grid(class02 = c("A","B","C","D"), class04 =
>>>c("A","B","C","D"),PREDICT = c("A","B","C","D"))
>>>+     for (i in 1:nrow(data)){
>>>+     X[i]<- dtree[dtree$class02 == paste(data$class02[i]) &
>>>dtree$class04 == paste(data$class04[i]) &
>>>dtree$PREDICT==paste(data$PREDICT[i]),] +     }
>>>+     return(X[i])
>>>+     }
>>
>>Eh. You really want to rewrite that code. It depends on objects
>>available in its parent (or grand-parent) envrionment.
>>I don't see why you need all those calls to paste().
>>You do *not* want to call an argument data.frame nor any other object
>>data, but you *do* want to use the arguments specified.
>>
>>Now, if X is initialized with numeric(), X is a numeric (n x 1) vector.
>>I think you need at least a matrix or better a list, if the subsetting
>>stuff returns more or even less than one row.
>>
>>For a list X use, e.g.,
>>  X <- vector(nrow(data), mode = "list")
>>just before the for loop.
>>
>>Uwe Ligges
>>
>>
>>>>tres(dtree)
>>>
>>>Error: Object "X" not found
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>>http://www.R-project.org/posting-guide.html



From gned at optusnet.com.au  Sun May 16 15:34:40 2004
From: gned at optusnet.com.au (Ned)
Date: Sun, 16 May 2004 23:34:40 +1000
Subject: [R] obtaining the name of a named list
Message-ID: <4.2.2.20040516233100.00b1ba50@pop-server>

I have a list d, in which the names of each elements are single characters, 
and the actual elements are bit sequences representing those characters. If 
I type d[1], I get the name and the bit sequence. If I type d[[1]], I get 
only the bit sequence.

What I want is some way to be able to get the name of the element, 
preferably by specifying an index into the array.

e.g.

 > d
       A       B           C
"00000" "00001"  "0001"

I want some way of saying "give me the name for element number 2" and it 
should return B.


cheers,

Ned



From ligges at statistik.uni-dortmund.de  Sun May 16 16:03:33 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 16 May 2004 16:03:33 +0200
Subject: [R] obtaining the name of a named list
In-Reply-To: <4.2.2.20040516233100.00b1ba50@pop-server>
References: <4.2.2.20040516233100.00b1ba50@pop-server>
Message-ID: <40A774B5.4020601@statistik.uni-dortmund.de>

Ned wrote:

> I have a list d, in which the names of each elements are single 
> characters, and the actual elements are bit sequences representing those 
> characters. If I type d[1], I get the name and the bit sequence. If I 
> type d[[1]], I get only the bit sequence.

d[1] returns a list of length 1, while d[[1]] returns only the element.

> What I want is some way to be able to get the name of the element, 
> preferably by specifying an index into the array.
> 
> e.g.
> 
>  > d
>       A       B           C
> "00000" "00001"  "0001"
> 
> I want some way of saying "give me the name for element number 2" and it 
> should return B.

names(B)[2]

Uwe Ligges

BTW: If all list elements are character of length 1, why are you not 
using a character vector instead?



> 
> cheers,
> 
> Ned
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From gb at stat.umu.se  Sun May 16 16:05:57 2004
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sun, 16 May 2004 16:05:57 +0200
Subject: [R] Error in using coxph()
In-Reply-To: <x2vfiwv9ss.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0405161038510.2679-100000@gannet.stats>
	<x2vfiwv9ss.fsf@biostat.ku.dk>
Message-ID: <20040516140557.GA23967@stat.umu.se>

On Sun, May 16, 2004 at 02:25:07PM +0200, Peter Dalgaard wrote:
> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> 
> > Note you said you used 1-F but the output said you used F. You also say
> > `1-F is a vector of '0's' so I think you may have declared that all
> > observations are right-censored.  (NB if you give Surv an event vector of
> > all 1's it is ambiguous, so don't do this.)
> 
> Actually, it *is* documented that this is interpreted as "all-died"
> and the advice in ?Surv is just to avoid 1/2 coding if all data are
> censored. It's a bit puzzling that we don't allow explicit
> disambiguation (e.g., by passing the event as a two-level factor),
> though.

But note the following:

>  library(survival)

> enter <- c(0,0,0)
> exit <- c(1,2,3)
> event <- c(0,0,0)
> x <- c(1,0,1)
> coxph(Surv(exit, event) ~ x)
Call:
coxph(formula = Surv(exit, event) ~ x)


  coef exp(coef) se(coef)   z   p
x    0         1        0 NaN NaN

Likelihood ratio test=0  on 1 df, p=1  n= 3 
Warning message: 
Ran out of iterations and did not converge in: 
fitter(X, Y, strats, offset, init, control, weights = weights,  

But:

> coxph(Surv(enter, exit, event) ~ x)
Error in fitter(X, Y, strats, offset, init, control, weights = weights,  : 
        Can't fit a Cox model with zero failures

This is the kind of message we want (before this check was introduced,
coxph crashed (segfault) if there were no events).

Recommendation 1: Give 'Surv' three arguments! (time, time2, event)

Recommendation 2: 'event' should be a logical, with 'FALSE' = 'censored'.
Meaning that if event is numeric, '0' = 'censored', anything else is an
event. This is advantageous when you have data with several types of
events. For instance, event = 0: censored, event = 1: death of cause 1,
event = 2: death of cause 2. Then you can (i) use event as is for total
mortality, (event == x) for for cause-specific mortality, x = 1, 2.  

You can get this behaviour now by using (event != 0) for total mortality,
of course.

G??ran

> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
 G??ran Brostr??m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume?? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume??, Sweden             e-mail: gb at stat.umu.se



From sdhyok at catchlab.org  Sun May 16 17:15:25 2004
From: sdhyok at catchlab.org (Shin, Daehyok)
Date: Sun, 16 May 2004 11:15:25 -0400
Subject: [R] How to restore and edit saved graphics?
In-Reply-To: <loom.20040516T053602-867@post.gmane.org>
Message-ID: <OAEOKPIGCLDDHAEMCAKIAEOECMAA.sdhyok@catchlab.org>

Thanks for the interesting solution.
I am happy to find a way to save all graphic options into a file.
There is a minor glitch.
Is there is any way to replace title, not to overwrite it?
And if I want to change the color of a line or the ranges of x or y axis,
how can I do it with the restored plot?

Interestingly, there is no mention about  dev.control() in the help document
of recordPlot(). I think it should be there.

Thanks again.

Daehyok Shin (Peter)

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Gabor Grothendieck
> Sent: Saturday, May 15, 2004 PM 11:59
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] How to restore and edit saved graphics?
>
>
> Saving of the low level graphics that R displays can be
> 1. turned on with dev.control(displaylist="enable") and
> 2. turned off with dev.control(displaylist="inhibit").
> recordPlot() can be used to save the display list in a variable.
>
> For example:
>
> # turn on display list, perform plot, turn off display list, add title
> # do not need next line if graphics device already active
> windows()  # or x11() on unix
> dev.control(displaylist="enable")
> plot(1:10)
> myplot <- recordPlot()
> dev.control(displaylist="inhibit")
> title(main="My Title")
>
> # now redisplay plot as it was before title and reissue title
> myplot
> title(main="My Other Title")
>
> Shin <sdhyok <at> email.unc.edu> writes:
>
> :
> : I am looking for a function to restore saved graphics for further
> : editing, such as changing its title, labels, or legend.
> : How can I do it in R? Thanks in advance.
> :
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From ozric at web.de  Sun May 16 17:17:31 2004
From: ozric at web.de (Christian Schulz)
Date: Sun, 16 May 2004 17:17:31 +0200
Subject: [R] Fwd: filter out many data.frames
In-Reply-To: <40A76862.8060800@statistik.uni-dortmund.de>
References: <200405160012.26269.ozric@web.de> <200405161408.57479.ozric@web.de>
	<40A76862.8060800@statistik.uni-dortmund.de>
Message-ID: <200405161717.31378.ozric@web.de>


> So, why are you doing these complicated things?

Hmm, want upgrade my sklls, because
i need more and more function's to reduce
complexity in my analysis. 
And try , do.call and match.call seems very usefuel and 
i want at long last understand the flexbilty of this functions.

>
> Just using
>      names(theList) <- apply(data, 1, paste, collapse="")
> (you want to replace data by the corrected name) after your loop in your
> first version would be sufficient, if you are going to name the list
> elements....

Yes many thanks, now it works and nrow or others things
could be easy changed or add.

Chrstian 


data <- expand.grid(class02 = c("A","B","C","D"), class04 = 
c("A","B","C","D"),PREDICT = c("A","B","C","D"))
tList  <- vector("list", numeric(nrow(data)))
#names(tList) <- apply(data, 1, paste, collapse="")
tasign <- paste("tList[[n]]  <-   try(nrow(dtree[dtree$class02 == 
paste(data$class02[n]) & dtree$class04 == paste(data$class04[n]) & 
dtree$PREDICT==paste(data$PREDICT[n]),]))")
tasign <-  parse(text=tasign)[[1]]
          
for(n in 1:nrow(data)) {
  TAsign <- do.call("substitute",list(tasign,list(n=n,X=as.name(n))))
  eval(TAsign)
}

names(tList) <- apply(data, 1, paste, collapse="")
results <- as.data.frame(unlist(dfl))
names(results) <- c("n")
results



From ggrothendieck at myway.com  Sun May 16 17:40:37 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 16 May 2004 15:40:37 +0000 (UTC)
Subject: [R] How to restore and edit saved graphics?
References: <loom.20040516T053602-867@post.gmane.org>
	<OAEOKPIGCLDDHAEMCAKIAEOECMAA.sdhyok@catchlab.org>
Message-ID: <loom.20040516T173340-38@post.gmane.org>


I don't think you can produce a graphic in R and then easily edit it
*in R* to change the title and so on; however, if you are using Windows you
can save the graphic as a Windows metafile (right click graphic and
save as a Windows metafile or just copy it as Windows metafile to clipboard)
and then import or paste it into Word and change 
everything you want.  The titles, etc. will be accessible as separate 
objects and you can easily change them and their properties. Its 
remarkably easy to do.

This should actually be possible for any vector format provided you
have a vector editor for it so there are undoubtedly solutions 
involving SVG and other vector formats too.


Shin, Daehyok <sdhyok <at> catchlab.org> writes:

: 
: Thanks for the interesting solution.
: I am happy to find a way to save all graphic options into a file.
: There is a minor glitch.
: Is there is any way to replace title, not to overwrite it?
: And if I want to change the color of a line or the ranges of x or y axis,
: how can I do it with the restored plot?
: 
: Interestingly, there is no mention about  dev.control() in the help document
: of recordPlot(). I think it should be there.
: 
: Thanks again.
: 
: Daehyok Shin (Peter)
: 
: > -----Original Message-----
: > From: r-help-bounces <at> stat.math.ethz.ch
: > [mailto:r-help-bounces <at> stat.math.ethz.ch]On Behalf Of Gabor 
Grothendieck
: > Sent: Saturday, May 15, 2004 PM 11:59
: > To: r-help <at> stat.math.ethz.ch
: > Subject: Re: [R] How to restore and edit saved graphics?
: >
: >
: > Saving of the low level graphics that R displays can be
: > 1. turned on with dev.control(displaylist="enable") and
: > 2. turned off with dev.control(displaylist="inhibit").
: > recordPlot() can be used to save the display list in a variable.
: >
: > For example:
: >
: > # turn on display list, perform plot, turn off display list, add title
: > # do not need next line if graphics device already active
: > windows()  # or x11() on unix
: > dev.control(displaylist="enable")
: > plot(1:10)
: > myplot <- recordPlot()
: > dev.control(displaylist="inhibit")
: > title(main="My Title")
: >
: > # now redisplay plot as it was before title and reissue title
: > myplot
: > title(main="My Other Title")
: >
: > Shin <sdhyok <at> email.unc.edu> writes:
: >
: > :
: > : I am looking for a function to restore saved graphics for further
: > : editing, such as changing its title, labels, or legend.
: > : How can I do it in R? Thanks in advance.

:



From ripley at stats.ox.ac.uk  Sun May 16 18:24:32 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 May 2004 17:24:32 +0100 (BST)
Subject: [R] Error in using coxph()
In-Reply-To: <x2vfiwv9ss.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0405161721380.9478-100000@gannet.stats>

On 16 May 2004, Peter Dalgaard wrote:

> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> 
> > Note you said you used 1-F but the output said you used F. You also say
> > `1-F is a vector of '0's' so I think you may have declared that all
> > observations are right-censored.  (NB if you give Surv an event vector of
> > all 1's it is ambiguous, so don't do this.)
> 
> Actually, it *is* documented that this is interpreted as "all-died"

Yes, I know.  What I do not know is what the OP actually did, since the 
case of 1-F == 0 and using F should mean no censoring, and you cna omit 
the event arg in that case.

Nevertheless, it *is* ambiguous (has two possible meanings) and you have
to check the documentation to know which is used (unless you have an
incredibly good memory or make a habit of doing this).

> and the advice in ?Surv is just to avoid 1/2 coding if all data are
> censored. It's a bit puzzling that we don't allow explicit
> disambiguation (e.g., by passing the event as a two-level factor),
> though.

Logical is allowed and clearer.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun May 16 18:38:21 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 May 2004 17:38:21 +0100 (BST)
Subject: [R] How to restore and edit saved graphics?
In-Reply-To: <OAEOKPIGCLDDHAEMCAKIAEOECMAA.sdhyok@catchlab.org>
Message-ID: <Pine.LNX.4.44.0405161730490.9478-100000@gannet.stats>

The display list on a screen device is enabled unless you explicitly
disable it, and if you know how to do that you will understand the help
for recordPlot, which says that it saves the display list so there had
better be one.

I suspect only a handful of R users have ever used dev.control and I am 
not one of them.  I only added the ability to re-enable the display list 
for a single user's very specific problem.

On Sun, 16 May 2004, Shin, Daehyok wrote:

> Thanks for the interesting solution.

But it is not a solution.  You asked how to `restore and edit saved 
graphs'.  recordPlot saves graphs, and does not allow you to edit them.

> I am happy to find a way to save all graphic options into a file.
> There is a minor glitch.
> Is there is any way to replace title, not to overwrite it?
> And if I want to change the color of a line or the ranges of x or y axis,
> how can I do it with the restored plot?
> 
> Interestingly, there is no mention about  dev.control() in the help document
> of recordPlot(). I think it should be there.

See above.

> Thanks again.
> 
> Daehyok Shin (Peter)
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Gabor Grothendieck
> > Sent: Saturday, May 15, 2004 PM 11:59
> > To: r-help at stat.math.ethz.ch
> > Subject: Re: [R] How to restore and edit saved graphics?
> >
> >
> > Saving of the low level graphics that R displays can be
> > 1. turned on with dev.control(displaylist="enable") and
> > 2. turned off with dev.control(displaylist="inhibit").
> > recordPlot() can be used to save the display list in a variable.
> >
> > For example:
> >
> > # turn on display list, perform plot, turn off display list, add title
> > # do not need next line if graphics device already active
> > windows()  # or x11() on unix
> > dev.control(displaylist="enable")
> > plot(1:10)
> > myplot <- recordPlot()
> > dev.control(displaylist="inhibit")
> > title(main="My Title")
> >
> > # now redisplay plot as it was before title and reissue title
> > myplot
> > title(main="My Other Title")
> >
> > Shin <sdhyok <at> email.unc.edu> writes:
> >
> > :
> > : I am looking for a function to restore saved graphics for further
> > : editing, such as changing its title, labels, or legend.
> > : How can I do it in R? Thanks in advance.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun May 16 21:40:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 May 2004 20:40:12 +0100 (BST)
Subject: [R] How to restore and edit saved graphics?
In-Reply-To: <Pine.LNX.4.44.0405161730490.9478-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0405162033170.9790-100000@gannet.stats>

Unfortunately a bug has been introduced into the recordPlot/replayPlot
internal code, so what is saved is the current display list and not a
snapshot.  (For cognescenti, especially Paul M: duplicate() is required or
the saved object will get a pointer to the actual display list.) There are
many ways to work around this, but using save/load is a good one.

In R-patched you can just do

plot(1:10)
myplot <- recordPlot()
title(main="My Title")

myplot
title(main="My Other Title")

but in R 1.9.0 you need to do something like

plot(1:10)
myplot <- recordPlot()
save("myplot", file="myplot")
title(main="My Title")

load("myplot")
myplot
title(main="My Other Title")


On Sun, 16 May 2004, Prof Brian Ripley wrote:

> The display list on a screen device is enabled unless you explicitly
> disable it, and if you know how to do that you will understand the help
> for recordPlot, which says that it saves the display list so there had
> better be one.
> 
> I suspect only a handful of R users have ever used dev.control and I am 
> not one of them.  I only added the ability to re-enable the display list 
> for a single user's very specific problem.
> 
> On Sun, 16 May 2004, Shin, Daehyok wrote:
> 
> > Thanks for the interesting solution.
> 
> But it is not a solution.  You asked how to `restore and edit saved 
> graphs'.  recordPlot saves graphs, and does not allow you to edit them.
> 
> > I am happy to find a way to save all graphic options into a file.
> > There is a minor glitch.
> > Is there is any way to replace title, not to overwrite it?
> > And if I want to change the color of a line or the ranges of x or y axis,
> > how can I do it with the restored plot?
> > 
> > Interestingly, there is no mention about  dev.control() in the help document
> > of recordPlot(). I think it should be there.
> 
> See above.
> 
> > Thanks again.
> > 
> > Daehyok Shin (Peter)
> > 
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Gabor Grothendieck
> > > Sent: Saturday, May 15, 2004 PM 11:59
> > > To: r-help at stat.math.ethz.ch
> > > Subject: Re: [R] How to restore and edit saved graphics?
> > >
> > >
> > > Saving of the low level graphics that R displays can be
> > > 1. turned on with dev.control(displaylist="enable") and
> > > 2. turned off with dev.control(displaylist="inhibit").
> > > recordPlot() can be used to save the display list in a variable.
> > >
> > > For example:
> > >
> > > # turn on display list, perform plot, turn off display list, add title
> > > # do not need next line if graphics device already active
> > > windows()  # or x11() on unix
> > > dev.control(displaylist="enable")
> > > plot(1:10)
> > > myplot <- recordPlot()
> > > dev.control(displaylist="inhibit")
> > > title(main="My Title")
> > >
> > > # now redisplay plot as it was before title and reissue title
> > > myplot
> > > title(main="My Other Title")
> > >
> > > Shin <sdhyok <at> email.unc.edu> writes:
> > >
> > > :
> > > : I am looking for a function to restore saved graphics for further
> > > : editing, such as changing its title, labels, or legend.
> > > : How can I do it in R? Thanks in advance.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From adelmaas at musc.edu  Sun May 16 21:52:50 2004
From: adelmaas at musc.edu (adelmaas@musc.edu)
Date: Sun, 16 May 2004 15:52:50 -0400
Subject: [R] Newbie Poisson regression question
Message-ID: <9CEC9B62-A772-11D8-BA3A-000A9591E11C@musc.edu>

Greetings.

I'm getting started learning R, and I'm trying to reproduce some models 
I've done previously in SAS.  I'm trying to fit simple Poisson 
regressions, and I keep getting impossible results:  the models predict 
negative numbers of cases for many observations.  The code for the 
models are:

Female.model <- glm(Observed ~ Black + Other, family = 
poisson(link=log), offset=log(PYAR), data=Females)

and

Male.model <- glm(Observed ~ Black + Other + 
poly(Minus.log.proportion.moved,3), family = poisson(link=log), 
offset=log(PYAR), data=Males)

where Observed is the number of cases of childhood ALL in a race-gender 
stratum of a county, Black and Other are Boolean variables what race a 
race-gender stratum of a county belongs to, Minus.log.proportion.moved 
is -log(proportion in county who moved between 1985 and 1990), PYAR is 
person-years at risk for a race-gender stratum of a county, and Females 
and Males are the data sets for females and males respectively.  As far 
as I can tell, this is set up the same way as examples of Poisson 
regressions in R I've found on the Net.  I've checked, and my data 
seems to be read in properly (code not shown).  Can anyone tell me if 
there's anything obviously wrong I've missed?  Thanks in advance for 
any help anyone can provide.

Aaron
Macintosh PowerBook G4 (867 MHz, 1 GB RAM, 40 GB hard drive, Mac OS X 
10.3.3, R 1.9.0)

-------------
Aaron Solomon (ben Saul Joseph) Adelman
E-mail:  adelmaas at musc.edu
Web site:  http://people.musc.edu/~adelmaas/
AOL Instant Messenger & Yahoo! Messenger:  Hiergargo
AOL chat room:  Adelmania



From p.dalgaard at biostat.ku.dk  Sun May 16 22:18:34 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 May 2004 22:18:34 +0200
Subject: [R] Newbie Poisson regression question
In-Reply-To: <9CEC9B62-A772-11D8-BA3A-000A9591E11C@musc.edu>
References: <9CEC9B62-A772-11D8-BA3A-000A9591E11C@musc.edu>
Message-ID: <x23c6015yd.fsf@biostat.ku.dk>

adelmaas at musc.edu writes:

> Greetings.
> 
> I'm getting started learning R, and I'm trying to reproduce some
> models I've done previously in SAS.  I'm trying to fit simple Poisson
> regressions, and I keep getting impossible results:  the models
> predict negative numbers of cases for many observations.  The code for
> the models are:
> 
> Female.model <- glm(Observed ~ Black + Other, family =
> poisson(link=log), offset=log(PYAR), data=Females)
> 
> and
> 
> Male.model <- glm(Observed ~ Black + Other +
> poly(Minus.log.proportion.moved,3), family = poisson(link=log),
> offset=log(PYAR), data=Males)
> 
> where Observed is the number of cases of childhood ALL in a
> race-gender stratum of a county, Black and Other are Boolean variables
> what race a race-gender stratum of a county belongs to,
> Minus.log.proportion.moved is -log(proportion in county who moved
> between 1985 and 1990), PYAR is person-years at risk for a race-gender
> stratum of a county, and Females and Males are the data sets for
> females and males respectively.  As far as I can tell, this is set up
> the same way as examples of Poisson regressions in R I've found on the
> Net.  I've checked, and my data seems to be read in properly (code not
> shown).  Can anyone tell me if there's anything obviously wrong I've
> missed?  Thanks in advance for any help anyone can provide.

You're not telling us what the perceived problem is. What exactly
makes you think that the models are predicting negative numbers of
cases? Are you using predict() (and if so, on what scale) or what?

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From loveland.1 at nd.edu  Sun May 16 23:03:44 2004
From: loveland.1 at nd.edu (Matt Loveland)
Date: Sun, 16 May 2004 16:03:44 -0500
Subject: [R] GLMM error message
References: <200405151940.50726.atropin75@t-online.de>
	<6rfza1v8sy.fsf@bates4.stat.wisc.edu>
Message-ID: <007401c43b89$46557320$a3b74a81@loveland>


Hi,

I wrote a few days ago about an error message I'm getting when I use GLMM
from lme4 to do random effects modelling.
When I add random effects, I get the following error message:   Error in
"EMsteps<-"(`*tmp*`, value = control) : invalid source matrix.

(I wanted to note that I've only just started to learn about random effects
modelling and R, so am a novice at both, but R/lme4 have been great up to
this hiccup)

I was asked to provide a reproducable example, so here is my try, using the
guImmun data frame included with the package:

library(lme4)
     data(guImmun)

 fm1 = GLMM(immun ~ kid2p + mom25p + momWork,
               data = guImmun, family = binomial,
               random = ~1|mom)

  fm2 = GLMM(immun ~ kid2p + mom25p + momWork,
               data = guImmun, family = binomial,
               random = ~kid2p|mom)
**
fm1 produces output, and fm2 gives me the following error message:

        Error in "EMsteps<-"(`*tmp*`, value = control) :
              invalid source matrix

Is my model statement incorrect?  Are there possible data problems I should
direct my attention to?
Any help will be appreciated.

I'm using R 1.8.1

thanks for any feedback,

Matt



From Jason.L.Higbee at stls.frb.org  Sun May 16 23:05:46 2004
From: Jason.L.Higbee at stls.frb.org (Jason.L.Higbee@stls.frb.org)
Date: Sun, 16 May 2004 16:05:46 -0500
Subject: [R] Re: what  statistical method should i use?
Message-ID: <20040516210547.D85FF85753@p3fed1.frb.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040516/17faff94/attachment.pl

From deepayan at stat.wisc.edu  Sun May 16 23:49:00 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 16 May 2004 16:49:00 -0500
Subject: [R] GLMM error message
In-Reply-To: <007401c43b89$46557320$a3b74a81@loveland>
References: <200405151940.50726.atropin75@t-online.de>
	<6rfza1v8sy.fsf@bates4.stat.wisc.edu>
	<007401c43b89$46557320$a3b74a81@loveland>
Message-ID: <200405161649.00717.deepayan@stat.wisc.edu>

On Sunday 16 May 2004 16:03, Matt Loveland wrote:
> Hi,
>
> I wrote a few days ago about an error message I'm getting when I use
> GLMM from lme4 to do random effects modelling.
> When I add random effects, I get the following error message:   Error
> in "EMsteps<-"(`*tmp*`, value = control) : invalid source matrix.
>
> (I wanted to note that I've only just started to learn about random
> effects modelling and R, so am a novice at both, but R/lme4 have been
> great up to this hiccup)
>
> I was asked to provide a reproducable example, so here is my try,
> using the guImmun data frame included with the package:
>
> library(lme4)
>      data(guImmun)
>
>  fm1 = GLMM(immun ~ kid2p + mom25p + momWork,
>                data = guImmun, family = binomial,
>                random = ~1|mom)
>
>   fm2 = GLMM(immun ~ kid2p + mom25p + momWork,
>                data = guImmun, family = binomial,
>                random = ~kid2p|mom)
> **
> fm1 produces output, and fm2 gives me the following error message:
>
>         Error in "EMsteps<-"(`*tmp*`, value = control) :
>               invalid source matrix
>
> Is my model statement incorrect?  Are there possible data problems I
> should direct my attention to?
> Any help will be appreciated.

I have looked at this a bit, but haven't been able to figure out why 
this is happening. I'm not very familiar with the code, and since this 
implementation of lme4 has been abandoned in favor of a new approach, 
I'm not sure how much effort we will be able to invest to fix this. 

As for the new approach, the good news is that this problem doesn't 
happen with it. The bad news is that GLMM works only partially, and 
needs some more work before it can be usable.

Deepayan



From p.dalgaard at biostat.ku.dk  Mon May 17 00:16:03 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 May 2004 00:16:03 +0200
Subject: [R] GLMM error message
In-Reply-To: <007401c43b89$46557320$a3b74a81@loveland>
References: <200405151940.50726.atropin75@t-online.de>
	<6rfza1v8sy.fsf@bates4.stat.wisc.edu>
	<007401c43b89$46557320$a3b74a81@loveland>
Message-ID: <x2ekpk9fx8.fsf@biostat.ku.dk>

"Matt Loveland" <loveland.1 at nd.edu> writes:

> Hi,
> 
> I wrote a few days ago about an error message I'm getting when I use GLMM
> from lme4 to do random effects modelling.
> When I add random effects, I get the following error message:   Error in
> "EMsteps<-"(`*tmp*`, value = control) : invalid source matrix.
> 
> (I wanted to note that I've only just started to learn about random effects
> modelling and R, so am a novice at both, but R/lme4 have been great up to
> this hiccup)
> 
> I was asked to provide a reproducable example, so here is my try, using the
> guImmun data frame included with the package:
> 
> library(lme4)
>      data(guImmun)
> 
>  fm1 = GLMM(immun ~ kid2p + mom25p + momWork,
>                data = guImmun, family = binomial,
>                random = ~1|mom)
> 
>   fm2 = GLMM(immun ~ kid2p + mom25p + momWork,
>                data = guImmun, family = binomial,
>                random = ~kid2p|mom)
> **
> fm1 produces output, and fm2 gives me the following error message:
> 
>         Error in "EMsteps<-"(`*tmp*`, value = control) :
>               invalid source matrix
> 
> Is my model statement incorrect?  Are there possible data problems I should
> direct my attention to?
> Any help will be appreciated.

> I'm using R 1.8.1

I get the same thing with R 1.9.0. Looks like it might be a bug, but I
notice that quite few moms have more than a single observation:

> with(guImmun, table(table(mom)))

   1    2    3
1063  500   32

and digging a bit deeper, I see that only 287 moms have observations
with different values of kid2p. This kind of data pattern has been
known to confuse lme-type algorithms before.

We probably need to leave further investigation to the package author.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tlumley at u.washington.edu  Mon May 17 00:38:36 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 16 May 2004 15:38:36 -0700 (PDT)
Subject: [R] Error in using coxph()
In-Reply-To: <20040516080720.25357.qmail@web50606.mail.yahoo.com>
References: <20040516080720.25357.qmail@web50606.mail.yahoo.com>
Message-ID: <Pine.A41.4.58.0405161537330.124242@homer39.u.washington.edu>

On Sun, 16 May 2004, Siew Leng TENG wrote:

> Hi,
>
> I am getting errors of the following kind. I can't
> seem to point the source of the error. I would greatly
> appreciate any advice.

In addition to things other people have pointed out, you didn't actually
set any of the control parameters you were trying to set.  As the output
shows, you set the data= argument to coxph.control(iter.max=1e10,
eps=1e-3), rather than the control= argument.

	-thomas


>
> Many thanks and good day,
> -Melinda
>
>
> Error message :
> ----------------
> "Ran out of iterations and did not converge in:
> fitter(X, Y, strats, offset, init, control, weights =
> weights,..."
>
> Details :
> ---------
> E is a vector of survival times (or censored times),
> 1-F is a vector of '0's, and cov is a matrix of 1
> column. There are altogether 75 observations.
>
> Tried :
> ------
> P <- try(surv.cox <- coxph(Surv(E, 1-F) ~ cov,
> coxph.control(iter.max=1e10, eps = 1e-03)))
>
> Output (from above command) :
> -----------------------------
> Call:
> coxph(formula = Surv(E, F) ~ cov, data =
> coxph.control(iter.max = 1e+10,
>     eps = 0.001))
>
>
>       coef exp(coef) se(coef)     z     p
> cov -0.233     0.793     0.11 -2.11 0.035
>
> Likelihood ratio test=4.51  on 1 df, p=0.0336  n= 75
>
>
> Machine Specs :
> ----------------
> Unix/ Windows XP
> R-1.8.1
> Survival package
>
>
>
>
>
> __________________________________
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From grr at grell.mailshell.com  Mon May 17 00:49:36 2004
From: grr at grell.mailshell.com (grr@grell.mailshell.com)
Date: Sun, 16 May 2004 15:49:36 -0700
Subject: [R] importing text file with duplicate rows / indexing rows and
	columns
In-Reply-To: <Pine.LNX.4.44.0405160721140.32514-100000@gannet.stats>
References: <Pine.LNX.4.44.0405160721140.32514-100000@gannet.stats>
Message-ID: <20040516224941.7511.qmail@mailshell.com>

Thank you so much. I'll tell it not to use the row names.

Also, if you have advice for basic texts for learning the programming 
language, please let me know. I am using Dalgaard's Introductory 
Statistics with R, but would like to find something with more of the 
command line options, regardless of the statistics.

Best wishes,

Graham

On May 15, 2004, at 11:24 PM, Prof Brian Ripley wrote:

> The issue is not `duplicate rows' but duplicated row names.  You asked 
> R
> explicitly to make a column into row names -- if they are not suitable 
> row
> names, don't do that.  You can remove duplicated rows later (see 
> ?unique)
> but you cannot have duplicated row names in a data frame so leave them 
> as
> numbers.
>
>
> On Sat, 15 May 2004 grr at grell.mailshell.com wrote:
>
>> Could somebody advise me about importing a txt file as a frame? I am 
>> using the command:
>>
>> test <- read.delim ("~/docs/perl/expr_ctx.txt2", header=T, sep = 
>> "\t", row.names = 1)
>>
>> This gives me an error because there are duplicate rows.
>>
>> In the txt file, the columns are unique subjects and the rows are
>> variables, so I had planned to transform the file after importing. The
>> first row and column are text labels, which I could either leave in
>> (with duplicate rows) or ask R to remove for me, saving another file
>> with index values. But I can't figure out how to do either of these
>> things.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  
> http://rd.mailshell.com/www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From p.murrell at auckland.ac.nz  Mon May 17 03:58:34 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 17 May 2004 13:58:34 +1200
Subject: [R] How to restore and edit saved graphics?
References: <OAEOKPIGCLDDHAEMCAKIAEOECMAA.sdhyok@catchlab.org>
Message-ID: <40A81C4A.7000208@stat.auckland.ac.nz>

Hi


Shin, Daehyok wrote:
> Thanks for the interesting solution.
> I am happy to find a way to save all graphic options into a file.
> There is a minor glitch.
> Is there is any way to replace title, not to overwrite it?
> And if I want to change the color of a line or the ranges of x or y axis,
> how can I do it with the restored plot?


The grid graphics package provides support for this sort of thing.  If 
you have R 1.9.0 there are some vignettes describing grid and how to do 
this sort of thing in grid -- see vignette("grid") and 
vignette("interactive") for a start.

This may or may not be sufficient for your purposes right now -- grid 
doesn't give you any high-level plots and, although the lattice package 
does give you high-level plots, it doesn't make use of the bits of grid 
that would allow this sort of interaction just yet (we're working on it) 
-- so its immediate usefulness will depend on what you're trying to do.

Paul


> Interestingly, there is no mention about  dev.control() in the help document
> of recordPlot(). I think it should be there.
> 
> Thanks again.
> 
> Daehyok Shin (Peter)
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch
>>[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Gabor Grothendieck
>>Sent: Saturday, May 15, 2004 PM 11:59
>>To: r-help at stat.math.ethz.ch
>>Subject: Re: [R] How to restore and edit saved graphics?
>>
>>
>>Saving of the low level graphics that R displays can be
>>1. turned on with dev.control(displaylist="enable") and
>>2. turned off with dev.control(displaylist="inhibit").
>>recordPlot() can be used to save the display list in a variable.
>>
>>For example:
>>
>># turn on display list, perform plot, turn off display list, add title
>># do not need next line if graphics device already active
>>windows()  # or x11() on unix
>>dev.control(displaylist="enable")
>>plot(1:10)
>>myplot <- recordPlot()
>>dev.control(displaylist="inhibit")
>>title(main="My Title")
>>
>># now redisplay plot as it was before title and reissue title
>>myplot
>>title(main="My Other Title")
>>
>>Shin <sdhyok <at> email.unc.edu> writes:
>>
>>:
>>: I am looking for a function to restore saved graphics for further
>>: editing, such as changing its title, labels, or legend.
>>: How can I do it in R? Thanks in advance.
>>:
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From knoblauch at lyon.inserm.fr  Mon May 17 08:59:48 2004
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Mon, 17 May 2004 08:59:48 +0200
Subject: [R] adding a line to a single panel of a lattice plot
Message-ID: <1084777188.40a862e4e6cad@webmail.lyon.inserm.fr>

I'm struggling to find a way to add a line (abline, lline or lmline) to
a single panel of a lattice plot.  In one panel, there is an outlier
and I'd like to include a second lmline fit to the data without this
point.  I've looked through nine pages of the archives on lattice
and it wasn't obvious (to me) what additional search keyword to add 
to hone in on this, although I would think that it's an issue that
would have come up before. I've played around with the
groups, subscripts and panel.superpose arguments and looked through
the lattice.par.get list but haven't found the way to do it yet.
Here is the structure of thecommand that I'm working with, 
but with the abline appearing on all (3 in my case) panels:

xyplot(y ~ x | z, data = my.df,
  panel=function(x,y) {
    panel.xyplot(x,y)
    panel.lmline(x,y)
   panel.abline(c(0.25,0.79,lty=2) #would like this only on panel 1
  },
       layout=c(3,1),aspect="x",
       scales=list(cex=1.2),
       xlab=list(label="x"),
       ylab=list(label="y")

Thanks for any help or directions thereto, in advance.

Ken


____________________
Ken Knoblauch
Inserm U 371
Cerveau et Vision
18 avenue du Doyen Lepine
69675 Bron cedex
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: 06 84 10 64 10



From adiamond at fas.harvard.edu  Mon May 17 09:24:55 2004
From: adiamond at fas.harvard.edu (adiamond@fas.harvard.edu)
Date: Mon, 17 May 2004 03:24:55 -0400
Subject: [R] drawing half-circles
Message-ID: <1084778695.40a868c7bd60d@webmail.fas.harvard.edu>

Dear wonderful R community,

I've been creating color-coded concentric circles using the "points" function, 
but I just realized that what I would really like to do is draw color-coded 
concentric half-circles.

(Because I want to communicate information about the diameters-- 
half-circles are sufficient to show diameters AND they leave ample room to one 
side of the figure to label the circles' diameter measurements.)

What should I do?

Thank you for your help,

Alexis Diamond
adiamond at fas.harvard.edu



From B.Rowlingson at lancaster.ac.uk  Mon May 17 10:39:01 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 17 May 2004 09:39:01 +0100
Subject: [R] drawing half-circles
In-Reply-To: <1084778695.40a868c7bd60d@webmail.fas.harvard.edu>
References: <1084778695.40a868c7bd60d@webmail.fas.harvard.edu>
Message-ID: <40A87A25.5070401@lancaster.ac.uk>

adiamond at fas.harvard.edu wrote:
> Dear wonderful R community,
> 
> I've been creating color-coded concentric circles using the "points" function, 
> but I just realized that what I would really like to do is draw color-coded 
> concentric half-circles.

> What should I do?

Write a 'halfCircle' function.

halfCircle <- function(x,y,r,start=0,end=pi,nsteps=30,...){
   rs <- seq(start,end,len=nsteps)
   xc <- x+r*cos(rs)
   yc <- y+r*sin(rs)
   lines(xc,yc,...)
}

Then try it out:

plot(1:10)

# default draws top halves:
halfCircle(5,5,2)
halfCircle(6,6,1,col="red")

# draw right half:
halfCircle(5,4,1,start=-pi/2,end=pi/2,lwd=2,col="blue")

  Note that you'll have to call halfCircle once for each point, since 
its not 'vectorised' in any way.

  It's also capable of drawing any circle fragments. I should have 
called it 'partCircle'. Oh well.

Barry



From Matthias.Templ at statistik.gv.at  Mon May 17 10:46:58 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Mon, 17 May 2004 10:46:58 +0200
Subject: [R] Accessing data
Message-ID: <83536658864BC243BE3C06D7E936ABD50153A59F@xchg1.statistik.local>

Hello,

I would like to access my data frame without one variable. 

E.g.:
> colnames(x)
[1] "Besch"  "Ang.m"  "Arb.m"  "i10"    "Umsatz" "arbstd"

I can try x[,-1], but this variable must be called by it??s name.

x[,-"Besch"]
x[,!"Besch"]
attach(x)
x[-Besch]
...
...
does not work.


I could not found a solution of this little problem in any scripts about R and in google.

Should I type in   x[,c("Ang.m","Arb.m","i10","Umsatz","arbstd")] to access my data frame without variable "Besch", or is there any better solution.

Some of my data frames has ~100 variables and so is x[,c(...)] a little bit exhausting.

Thanks for any help,

Matthias



From petr.pikal at precheza.cz  Mon May 17 10:53:03 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 17 May 2004 10:53:03 +0200
Subject: [R] Accessing data
In-Reply-To: <83536658864BC243BE3C06D7E936ABD50153A59F@xchg1.statistik.local>
Message-ID: <40A8998F.9592.1A87FE@localhost>

Hi

On 17 May 2004 at 10:46, TEMPL Matthias wrote:

> Hello,
> 
> I would like to access my data frame without one variable. 
> 
> E.g.:
> > colnames(x)
> [1] "Besch"  "Ang.m"  "Arb.m"  "i10"    "Umsatz" "arbstd"
> 
> I can try x[,-1], but this variable must be called by it??s name.
> 

x[,names(x)!="Besch"]

should work but maybe there is some better solution

Cheers
Petr

> x[,-"Besch"]
> x[,!"Besch"]
> attach(x)
> x[-Besch]
> ...
> ...
> does not work.
> 
> 
> I could not found a solution of this little problem in any scripts
> about R and in google.
> 
> Should I type in   x[,c("Ang.m","Arb.m","i10","Umsatz","arbstd")] to
> access my data frame without variable "Besch", or is there any better
> solution.
> 
> Some of my data frames has ~100 variables and so is x[,c(...)] a
> little bit exhausting.
> 
> Thanks for any help,
> 
> Matthias
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From dimitris.rizopoulos at med.kuleuven.ac.be  Mon May 17 10:56:27 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Mon, 17 May 2004 10:56:27 +0200
Subject: [R] Accessing data
References: <83536658864BC243BE3C06D7E936ABD50153A59F@xchg1.statistik.local>
Message-ID: <00a701c43bec$d7d46c80$ad133a86@www.domain>

Dear Matthias,

you could try something like:

x <- matrix(rnorm(30*6), 30, 6)
colnames(x) <- c("Besch", "Ang.m", "Arb.m", "i10", "Umsatz", "arbstd")
your.choice <- "Besch"

x[,match(your.choice, colnames(x))]
x[,-match(your.choice, colnames(x))]

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "TEMPL Matthias" <Matthias.Templ at statistik.gv.at>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, May 17, 2004 10:46 AM
Subject: [R] Accessing data


> Hello,
>
> I would like to access my data frame without one variable.
>
> E.g.:
> > colnames(x)
> [1] "Besch"  "Ang.m"  "Arb.m"  "i10"    "Umsatz" "arbstd"
>
> I can try x[,-1], but this variable must be called by it??s name.
>
> x[,-"Besch"]
> x[,!"Besch"]
> attach(x)
> x[-Besch]
> ...
> ...
> does not work.
>
>
> I could not found a solution of this little problem in any scripts
about R and in google.
>
> Should I type in   x[,c("Ang.m","Arb.m","i10","Umsatz","arbstd")] to
access my data frame without variable "Besch", or is there any better
solution.
>
> Some of my data frames has ~100 variables and so is x[,c(...)] a
little bit exhausting.
>
> Thanks for any help,
>
> Matthias
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From knoblauch at lyon.inserm.fr  Mon May 17 11:01:14 2004
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Mon, 17 May 2004 11:01:14 +0200
Subject: [R] Re :adding a line to a single panel of a lattice plot 
Message-ID: <1084784474.40a87f5ac22bc@webmail.lyon.inserm.fr>


OK, I've found the solution myself adapted from the example on p. 101 
of V&R MASS, 4th edition.  This works as I would like it to, plotting 
an abline on a single panel:

xyplot(y ~ x | z, data = my.df, subscripts=TRUE, ID=my.df$z,
  panel=function(x,y) {
    panel.xyplot(x,y)
    panel.lmline(x,y)
    which = unique(ID[subscripts])
   if (which==1) panel.abline(c(0.25,0.79),lty=2) 
  },
       layout=c(3,1),aspect="x",
       scales=list(cex=1.2),
       xlab=list(label="x"),
       ylab=list(label="y")

I needed to explore one more source to find the solution. Sorry to
have bothered the help precociously.

____________________
Ken Knoblauch
Inserm U 371
Cerveau et Vision
18 avenue du Doyen Lepine
69675 Bron cedex
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: 06 84 10 64 10


____________________
Ken Knoblauch
Inserm U 371
Cerveau et Vision
18 avenue du Doyen Lepine
69675 Bron cedex
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: 06 84 10 64 10



From i.visser at uva.nl  Mon May 17 11:13:49 2004
From: i.visser at uva.nl (Ingmar Visser)
Date: Mon, 17 May 2004 11:13:49 +0200
Subject: [R] ld warning when installing packages with dll/so
Message-ID: <BCCE4EED.2938%i.visser@uva.nl>


Hi All,
When installing a package using C/Fortran routines I get a large of the
following ld warnings:


ld: warning multiple definitions of symbol _adler32
/Library/Frameworks/R.framework/R(adler32.o) definition of _adler32
/usr/lib/libz.1.dylib(adler32.o) definition of _adler32
ld: warning multiple definitions of symbol _BC
/Library/Frameworks/R.framework/Resources/bin/Frameworks/libreadline.4.3.dyl
ib(terminal.so) definition of _BC
/usr/lib/libncurses.5.dylib(lib_termcap.o) definition of _BC

My platform is:
platform powerpc-apple-darwin6.8
arch     powerpc   
os       darwin6.8 
system   powerpc, darwin6.8
status             
major    1         
minor    9.0       
year     2004      
month    04        
day      12        
language R  

The package seems to work fine, but I am surprised to get these warnings
because I did not them when installing under R 1.8
What is the reason of these warnings and how can I prevent them?

best, ingmar



From BROSTAUX.Y at fsagx.ac.be  Mon May 17 12:04:01 2004
From: BROSTAUX.Y at fsagx.ac.be (Yves Brostaux)
Date: Mon, 17 May 2004 12:04:01 +0200
Subject: [R] automated response
Message-ID: <10405171204.AA8261804@mail.fsagx.ac.be>

Je suis absent du bureau jusqu'au mardi 1er juin. Vous pouvez faire suivre les demandes urgentes au secrtariat de STATINFO qui transmettra  qui de droit (statinfo at fsagx.ac.be)



From muteau at ensam.inra.fr  Mon May 17 12:18:47 2004
From: muteau at ensam.inra.fr (Vincent MUTEAUD)
Date: Mon, 17 May 2004 12:18:47 +0200
Subject: [R] Problem with package SJava
Message-ID: <5.0.2.1.2.20040517120243.00a78fd0@ensam.inra.fr>

Hello all,
I'm trying to run SJava package (0.65 modified downloaded from : 
http://stats.math.uni-augsburg.de/iPlots/alpha/) on windows NT 2000 and R 
1.8.01. I have also downloaded the PDF Calling R from Java and when I want 
to execute the following code:
import org.omegahat.R.Java.*;
import java.io.*;
public class Essai{
	public static void main (String [] args) {
		REvaluator e = new REvaluator();
		Object val = e.eval("objects()");
		if (val!= null)  {
			String[] objects = (String[]) val;
			for (int i = 0; i< objects.length; i++) {
				System.out.println("("+i+") " + objects[i]);
			}
		}
	}
}
I have in return:


An unexpected exception has been detected in native code outside the VM.
Unexpected Signal : EXCEPTION_ACCESS_VIOLATION (0xc0000005) occurred at 
PC=0x6B4B85E3
Function=R_SetMaxNSize+0xC3
Library=c:\Program Files\R\rw1081\bin\R.dll

Current Java thread:
	at org.omegahat.R.Java.REvaluator.eval(Native Method)
	at org.omegahat.R.Java.REvaluator.eval(REvaluator.java:86)
	at org.omegahat.R.Java.REvaluator.eval(REvaluator.java:36)
	at Toto.main(Toto.java:22)

Dynamic libraries:
0x00400000 - 0x00406000 	C:\j2sdk1.4.2_03\bin\java.exe
0x78460000 - 0x784E3000 	C:\WINNT\system32\ntdll.dll
0x78ED0000 - 0x78F32000 	C:\WINNT\system32\ADVAPI32.dll
0x77E70000 - 0x77F33000 	C:\WINNT\system32\KERNEL32.DLL
0x770C0000 - 0x77131000 	C:\WINNT\system32\RPCRT4.DLL
0x78000000 - 0x78045000 	C:\WINNT\system32\MSVCRT.dll
0x08000000 - 0x08138000 	C:\j2sdk1.4.2_03\jre\bin\client\jvm.dll
0x77E00000 - 0x77E65000 	C:\WINNT\system32\USER32.dll
0x77F40000 - 0x77F7E000 	C:\WINNT\system32\GDI32.DLL
0x77540000 - 0x77571000 	C:\WINNT\system32\WINMM.dll
0x10000000 - 0x10007000 	C:\j2sdk1.4.2_03\jre\bin\hpi.dll
0x007C0000 - 0x007CE000 	C:\j2sdk1.4.2_03\jre\bin\verify.dll
0x007D0000 - 0x007E9000 	C:\j2sdk1.4.2_03\jre\bin\java.dll
0x007F0000 - 0x007FD000 	C:\j2sdk1.4.2_03\jre\bin\zip.dll
0x18270000 - 0x18287000 	C:\Program Files\R\rw1081\library\SJava\libs\SJava.dll
0x6B400000 - 0x6B61B000 	c:\Program Files\R\rw1081\bin\R.dll
0x68180000 - 0x6819F000 	c:\Program Files\R\rw1081\bin\Rblas.dll
0x77B40000 - 0x77BC9000 	C:\WINNT\system32\COMCTL32.DLL
0x76B00000 - 0x76B3E000 	C:\WINNT\system32\COMDLG32.DLL
0x63180000 - 0x631C8000 	C:\WINNT\system32\SHLWAPI.DLL
0x77580000 - 0x777CF000 	C:\WINNT\system32\SHELL32.DLL
0x77810000 - 0x77817000 	C:\WINNT\system32\VERSION.dll
0x75950000 - 0x75956000 	C:\WINNT\system32\LZ32.DLL
0x77910000 - 0x77933000 	C:\WINNT\system32\imagehlp.dll
0x72970000 - 0x7299D000 	C:\WINNT\system32\DBGHELP.dll
0x68EA0000 - 0x68EAB000 	C:\WINNT\system32\PSAPI.DLL

Heap at VM Abort:
Heap
  def new generation   total 576K, used 227K [0x10010000, 0x100b0000, 
0x104f0000)
   eden space 512K,  44% used [0x10010000, 0x10048f68, 0x10090000)
   from space 64K,   0% used [0x10090000, 0x10090000, 0x100a0000)
   to   space 64K,   0% used [0x100a0000, 0x100a0000, 0x100b0000)
  tenured generation   total 1408K, used 0K [0x104f0000, 0x10650000, 
0x14010000)
    the space 1408K,   0% used [0x104f0000, 0x104f0000, 0x104f0200, 0x10650000)
  compacting perm gen  total 4096K, used 1039K [0x14010000, 0x14410000, 
0x18010000)
    the space 4096K,  25% used [0x14010000, 0x14113de0, 0x14113e00, 0x14410000)

Local Time = Mon May 17 09:22:41 2004
Elapsed Time = 17
#
# The exception above was detected in native code outside the VM
#
# Java VM: Java HotSpot(TM) Client VM (1.4.2_03-b02 mixed mode)
#

I try to recompile the native interfaces and I think that some files or 
directories are missing like:
antlr\commonAST.class
jas.classEnv

I don't know what I should do so I hope that anybody could help me.
thanks,
Regards

Vincent



From i.visser at uva.nl  Mon May 17 12:32:33 2004
From: i.visser at uva.nl (Ingmar Visser)
Date: Mon, 17 May 2004 12:32:33 +0200
Subject: [R] bus error macosx/off-topic
In-Reply-To: <Pine.LNX.4.44.0405131145070.3244-100000@gannet.stats>
Message-ID: <BCCE6161.2941%i.visser@uva.nl>

On 5/13/04 12:46 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

> On Thu, 13 May 2004, Ingmar Visser wrote:
> 
>> Dear Prof Ripley,
>> Thanks for your answer.
>> 
>> On 5/12/04 2:52 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
>> 
>>> These normally occur (at that point) from having written off one end of an
>>> array. (If you are using .C/.Fortran, they try to copy back the
>>> arguments.) Compiling with bounds checking turned on can help, at least
>>> with Fortran.
>> 
>> Can I invoke compile options if/when I use R cmd install etc. to install
>> packages? 
> 
> By using a Makevars file: see Writing R Extensions.


I got Makevars to work with bounds checking for the fortran files. Does
something similar exist for C/C++ code?

ingmar visser



From P.Lemmens at nici.kun.nl  Mon May 17 12:49:13 2004
From: P.Lemmens at nici.kun.nl (Paul Lemmens)
Date: Mon, 17 May 2004 12:49:13 +0200
Subject: [R] Accessing data
In-Reply-To: <83536658864BC243BE3C06D7E936ABD50153A59F@xchg1.statistik.local>
References: <83536658864BC243BE3C06D7E936ABD50153A59F@xchg1.statistik.local>
Message-ID: <5F704A00C29AD1EF3B88FAE6@lemmens.socsci.kun.nl>

Hoi TEMPL,

--On maandag 17 mei 2004 10:46 +0200 TEMPL Matthias 
<Matthias.Templ at statistik.gv.at> wrote:

> Hello,
>
> I would like to access my data frame without one variable.
>
> E.g.:
>> colnames(x)
> [1] "Besch"  "Ang.m"  "Arb.m"  "i10"    "Umsatz" "arbstd"
>
> I can try x[,-1], but this variable must be called by it??s name.
>
> x[,-"Besch"]
> x[,!"Besch"]
> attach(x)
> x[-Besch]
> ...
>
Try

x2 <- subset(x, select=-Besch)


kind regards,
Paul


-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.05)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066



From ripley at stats.ox.ac.uk  Mon May 17 12:57:10 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 May 2004 11:57:10 +0100 (BST)
Subject: [R] bus error macosx/off-topic
In-Reply-To: <BCCE6161.2941%i.visser@uva.nl>
Message-ID: <Pine.LNX.4.44.0405171156100.13595-100000@gannet.stats>

On Mon, 17 May 2004, Ingmar Visser wrote:

> On 5/13/04 12:46 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
> 
> > On Thu, 13 May 2004, Ingmar Visser wrote:
> > 
> >> Dear Prof Ripley,
> >> Thanks for your answer.
> >> 
> >> On 5/12/04 2:52 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
> >> 
> >>> These normally occur (at that point) from having written off one end of an
> >>> array. (If you are using .C/.Fortran, they try to copy back the
> >>> arguments.) Compiling with bounds checking turned on can help, at least
> >>> with Fortran.
> >> 
> >> Can I invoke compile options if/when I use R cmd install etc. to install
> >> packages? 
> > 
> > By using a Makevars file: see Writing R Extensions.
> 
> 
> I got Makevars to work with bounds checking for the fortran files. Does
> something similar exist for C/C++ code?

Depends on your compiler, which you have not mentioned and if on MacOS X 
(sic) I would not know about.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Mon May 17 13:02:08 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 17 May 2004 07:02:08 -0400
Subject: [R] drawing half-circles
In-Reply-To: <40A87A25.5070401@lancaster.ac.uk>
References: <1084778695.40a868c7bd60d@webmail.fas.harvard.edu>
	<40A87A25.5070401@lancaster.ac.uk>
Message-ID: <ao6ha09aolc72uk42nm1rblh6tdd2ql7ob@4ax.com>

On Mon, 17 May 2004 09:39:01 +0100, Barry Rowlingson
<B.Rowlingson at lancaster.ac.uk> wrote:

>adiamond at fas.harvard.edu wrote:
>> Dear wonderful R community,
>> 
>> I've been creating color-coded concentric circles using the "points" function, 
>> but I just realized that what I would really like to do is draw color-coded 
>> concentric half-circles.
>
>> What should I do?
>
>Write a 'halfCircle' function.
>
>halfCircle <- function(x,y,r,start=0,end=pi,nsteps=30,...){
>   rs <- seq(start,end,len=nsteps)
>   xc <- x+r*cos(rs)
>   yc <- y+r*sin(rs)
>   lines(xc,yc,...)
>}

Alexis, besides lines(), you should look at the polygon() function
(which can fill the regions).

Duncan Murdoch



From sdavis2 at mail.nih.gov  Mon May 17 13:09:34 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 17 May 2004 07:09:34 -0400
Subject: [R] Fw: add objects to svm plot
Message-ID: <003a01c43bff$72c6d8b0$04653744@WATSON>

Reposting to the group for input....

Thanks for any help you can provide.

Sean
----- Original Message -----
From: <ale.ambrosi at unipd.it>
To: <sdavis2 at mail.nih.gov>
Sent: Monday, May 17, 2004 4:22 AM
Subject: add objects to svm plot


>
> >at 06.38 14/05/2004 -0400, you wrote:
> >It might be helpful if you could send your code to the list along with
any
> >error messages, etc.
> >
> >Sean
>
> Dear Sean,
>
> Thank so much for your answer.
> I try to give you the idea of my problem by means a simple example
>
> To give a more precise idea here I make a simple example.
> First of all I train a SVM.
>
> > m.svm <- svm(status~., data = dati.svm,
> kernel="radial", cross=20, scale=TRUE
> )
>
> dati.svm is a data.frame with four column, say: v.1, v.2, v.3, status.
> Then I generates a scatter plot of a svm fit:
>
> > plot.svm(m.svm, data=dati.svm, v.1 ~ v.2, slice = list(...),
>         grid = 100)
>
> This works well; regions and support vectors are plotted.
> the secon step is my problem.
> I have some data frames of points relatives to different samples,
> say dati.1, dati.2,... (of the same kind of dati.svm). I'd like to
> add them to the plot, each with different symbol and their (elliptic)
hull.
> I hope to be clear.
> How can I do it?
>
> Please, could you help me or give me some hints to solve?
>
> thanks,
> Alessandro
>
>
> BTW: Are there any way to reppresent the model giving (the idea of) a
> third dimension?
>
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Alessandro Ambrosi, Ph.D.       |
> Oncological Surgical Sc. Dept.  | mail: ale.ambrosi at unipd.it
> Surg. Cl. II |       ambrosi at stat.unipd.it
> University of Padua | fax:  +39 049 651891
> via Giustiniani, 2 | tel:  +39 049 8212055
> I-35128 Padua (ITALY)           | url:  www.stat.unipd.it/~ambrosi
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>
>
> -------------------------------------------------
> This mail sent through IMP: webmail.unipd.it
>



From i.visser at uva.nl  Mon May 17 13:11:57 2004
From: i.visser at uva.nl (Ingmar Visser)
Date: Mon, 17 May 2004 13:11:57 +0200
Subject: [R] bus error macosx/off-topic
In-Reply-To: <Pine.LNX.4.44.0405171156100.13595-100000@gannet.stats>
Message-ID: <BCCE6A9D.2949%i.visser@uva.nl>

On 5/17/04 12:57 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

> On Mon, 17 May 2004, Ingmar Visser wrote:
> 
>> On 5/13/04 12:46 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
>> 
>>> On Thu, 13 May 2004, Ingmar Visser wrote:
>>> 
>>>> Dear Prof Ripley,
>>>> Thanks for your answer.
>>>> 
>>>> On 5/12/04 2:52 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
>>>> 
>>>>> These normally occur (at that point) from having written off one end of an
>>>>> array. (If you are using .C/.Fortran, they try to copy back the
>>>>> arguments.) Compiling with bounds checking turned on can help, at least
>>>>> with Fortran.
>>>> 
>>>> Can I invoke compile options if/when I use R cmd install etc. to install
>>>> packages? 
>>> 
>>> By using a Makevars file: see Writing R Extensions.
>> 
>> 
>> I got Makevars to work with bounds checking for the fortran files. Does
>> something similar exist for C/C++ code?
> 
> Depends on your compiler, which you have not mentioned and if on MacOS X
> (sic) I would not know about.

I use the gcc compilers that are invoked by using R CMD INSTALL, ie g++ and
g77 respectively for c++ and fortran code.

ingmar visser



From Matthias.Schmidt at forst.bwl.de  Mon May 17 13:17:33 2004
From: Matthias.Schmidt at forst.bwl.de (Schmidt.Matthias (FORST))
Date: Mon, 17 May 2004 13:17:33 +0200
Subject: [R] residuals in multinom
Message-ID: <855D381F618DE84FA58C035BA803FCE6B9A717@fvafr-se1.forst.bwl.de>

Hi,

is there a possibility to calculate the different "types" of residuals
directly using the multinom function from MASS as it is possible for the
functions gam, glm
using type="deviance" or "working" or "pearson" or  "response"? I tried it
but got always the "response" type, I guess. 

thanx

Matthias

***********************************************************
Matthias Schmidt
Forstliche Versuchs- und Forschungsanstalt Baden-W??rttemberg (FVA) 
Abteilung Biometrie und Informatik
Wonnhaldestr. 4
79100 Freiburg i. Br
Tel.: + 49 (0)761 / 4018 -187
Fax: + 49 (0)761 / 4018 - 333



From HaroldD at ccsso.org  Mon May 17 14:30:57 2004
From: HaroldD at ccsso.org (Harold Doran)
Date: Mon, 17 May 2004 08:30:57 -0400
Subject: [R] Fatal Error
Message-ID: <CFF85773D9245040A333571B7E6D651702C4937F@ccssosrv1.ccsso.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040517/db7158aa/attachment.pl

From ramasamy at cancer.org.uk  Mon May 17 14:42:02 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: 17 May 2004 13:42:02 +0100
Subject: [R] Fatal Error
In-Reply-To: <CFF85773D9245040A333571B7E6D651702C4937F@ccssosrv1.ccsso.org>
References: <CFF85773D9245040A333571B7E6D651702C4937F@ccssosrv1.ccsso.org>
Message-ID: <1084797722.4394.28.camel@vpn202001.lif.icnet.uk>

Try renaming (or moving or deleting) the .Rdata file.

The .Rdata could be in somewhere like "c:\Program Files\R\rw1090\". It
is be considered a hidden file, so you may not be able to see it.
Go to Tools->Folder Options->View and select "show hidden files and
folders" or use dos prompt.

On Mon, 2004-05-17 at 13:30, Harold Doran wrote:
> Dear List:
> 
> When trying to open 1.9.0 this morning, I have the following error:
> 
> "Fatal Error: Unable to restore saved data in .Rdata"
> 
> I am using Windows 2000.
> 
> The program then quits. Do I need to reinstall?
> 
> Harold C. Doran
> One Massachusetts Avenue, NW  Suite 700 
> Washington, DC 20001-1431
> 202.336.7075
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dmurdoch at pair.com  Mon May 17 14:44:48 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 17 May 2004 08:44:48 -0400
Subject: [R] Fatal Error
In-Reply-To: <CFF85773D9245040A333571B7E6D651702C4937F@ccssosrv1.ccsso.org>
References: <CFF85773D9245040A333571B7E6D651702C4937F@ccssosrv1.ccsso.org>
Message-ID: <6mcha01t921sq09ikgi51q485e5d4ach8f@4ax.com>

On Mon, 17 May 2004 08:30:57 -0400, "Harold Doran" <HaroldD at ccsso.org>
wrote:

>Dear List:
>
>When trying to open 1.9.0 this morning, I have the following error:
>
>"Fatal Error: Unable to restore saved data in .Rdata"
>
>I am using Windows 2000.
>
>The program then quits. Do I need to reinstall?

It should be sufficient to delete the bad .Rdata file.  It's normally
stored in the directory that's current when R starts; if you're using
Windows, you can look in the shortcut to find what the starting
directory is.

If you can make this error reproducible, we'd like to hear about it.

Duncan Murdoch



From HaroldD at ccsso.org  Mon May 17 14:47:02 2004
From: HaroldD at ccsso.org (Harold Doran)
Date: Mon, 17 May 2004 08:47:02 -0400
Subject: [R] Fatal Error
Message-ID: <CFF85773D9245040A333571B7E6D651702C49381@ccssosrv1.ccsso.org>

Thank you. Locating and deleting the bad .Rdata file did the trick and I can now work in R.

Thanks.

-----Original Message-----
From: Duncan Murdoch [mailto:dmurdoch at pair.com]
Sent: Monday, May 17, 2004 8:45 AM
To: Harold Doran
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Fatal Error


On Mon, 17 May 2004 08:30:57 -0400, "Harold Doran" <HaroldD at ccsso.org>
wrote:

>Dear List:
>
>When trying to open 1.9.0 this morning, I have the following error:
>
>"Fatal Error: Unable to restore saved data in .Rdata"
>
>I am using Windows 2000.
>
>The program then quits. Do I need to reinstall?

It should be sufficient to delete the bad .Rdata file.  It's normally
stored in the directory that's current when R starts; if you're using
Windows, you can look in the shortcut to find what the starting
directory is.

If you can make this error reproducible, we'd like to hear about it.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Mon May 17 14:49:50 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 May 2004 13:49:50 +0100 (BST)
Subject: [R] residuals in multinom
In-Reply-To: <855D381F618DE84FA58C035BA803FCE6B9A717@fvafr-se1.forst.bwl.de>
Message-ID: <Pine.LNX.4.44.0405171325500.13677-100000@gannet.stats>

A multinom model is not a glm, and its residuals() method follows the 
arguments of the generic and so is not otherwise documented. You got what 
?residuals tells you.

There is no analogue of `working': the model is not fitted by IWLS, and
the linear predictor is multidimensional.

One could calculate deviance and Pearson residuals, but I have never seen 
them used for multinom model.  It is not entirely clear how one would 
define Pearson residuals as there are K outcomes: do you want all K or 
only the one that happened?

On Mon, 17 May 2004, Schmidt.Matthias (FORST) wrote:

> is there a possibility to calculate the different "types" of residuals
> directly using the multinom function from MASS as it is possible for the
> functions gam, glm
> using type="deviance" or "working" or "pearson" or  "response"? I tried it
> but got always the "response" type, I guess. 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May 17 14:53:49 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 May 2004 13:53:49 +0100 (BST)
Subject: [R] Fatal Error
In-Reply-To: <6mcha01t921sq09ikgi51q485e5d4ach8f@4ax.com>
Message-ID: <Pine.LNX.4.44.0405171350530.13677-100000@gannet.stats>

On Mon, 17 May 2004, Duncan Murdoch wrote:

> On Mon, 17 May 2004 08:30:57 -0400, "Harold Doran" <HaroldD at ccsso.org>
> wrote:
> 
> >Dear List:
> >
> >When trying to open 1.9.0 this morning, I have the following error:
> >
> >"Fatal Error: Unable to restore saved data in .Rdata"
> >
> >I am using Windows 2000.
> >
> >The program then quits. Do I need to reinstall?
> 
> It should be sufficient to delete the bad .Rdata file.  It's normally
> stored in the directory that's current when R starts; if you're using
> Windows, you can look in the shortcut to find what the starting
> directory is.
> 
> If you can make this error reproducible, we'd like to hear about it.

It used (at least) to be possible to save a workspace that needed more
memory to load than it occupies and so you could hit the maximum memory
allocation when trying to load it.  If the .Rdata file looks comparable in
size with the RAM (and remember .Rdata is compressed) it might be worth
increasing --max-mem-size on the command line and trying again.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From slist at oomvanlieshout.net  Mon May 17 15:13:29 2004
From: slist at oomvanlieshout.net (Slist)
Date: Mon, 17 May 2004 15:13:29 +0200
Subject: [R] Plotting Time against Date for time series data?
Message-ID: <6.1.0.6.0.20040517131117.02526be0@localhost>

Dear all,

I have a data set containing GPS fixes of animal locations. To check that 
the GPS's are working properly, I would like to plot the time of the fixes 
(y-axis) against the date of the fixes (x-axis). If all works well, the 
plot should show four regular fixes per day. The x-axis should be labelled 
with month/year (i.e. 11/04) and the y-axis by hour from 00 to 24. I would 
like to control the x-axis limits.

I have looked at several date and time related help pages, but get horribly 
lost in all the terminology. The main challenge is to isolate date and time 
from the date/time object for plotting (marked ???). Therefore, I would 
like the following example code to work:

 >
 >
dates <- c("02/27/92", "02/27/92", "01/14/92", "01/14/92", "03/28/92", 
"03/28/92") #
times <- c("23:03:20", "10:29:56", "01:03:30", "13:03:30", "18:21:03", 
"06:56:26") #
x <- paste(dates, times) #
DateTime <- strptime(x, "%m/%d/%y %H:%M:%S") #

Date <- DateTime ??? #
Time <- DateTime ??? #
plot(x=Date, y=Time,
         xlab= "Date (month/year)", ylab= "Time (hours)", xaxt="n", yaxt="n",
         xlim=c(as.Date("01/01/92", format="%m/%d/%y"), as.Date("04/01/92", 
format="%m/%d/%y")),
         ylim=c(0, 24)
         ) #
r <- as.POSIXct(round(range(Date), "days")) #
axis.POSIXct(1, at=seq(r[1], r[2], by="month"), format="%m/%y") #
r <- as.POSIXct(round(range(Time), "hours")) #
axis.POSIXct(2, at=seq(r[1], r[2], by="hour"), format="%H") #
 >
 >

Thanks for any suggestions,

Sander Oom.



--------------------------------------------------------------
Dr. Sander P. Oom
Animal, Plant and Environmental Sciences
University of the Witwatersrand
Private Bag 3
Wits 2050
South Africa

Tel (work)      +27 (0)11 717 64 04
Tel (home)      +27 (0)18 297 44 51
Fax             +27 (0)18 299 24 64

Email   sander at oomvanlieshout.net
Web     www.oomvanlieshout.net/sander



From ripley at stats.ox.ac.uk  Mon May 17 15:58:54 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 May 2004 14:58:54 +0100 (BST)
Subject: [R] Plotting Time against Date for time series data?
In-Reply-To: <6.1.0.6.0.20040517131117.02526be0@localhost>
Message-ID: <Pine.LNX.4.44.0405171452010.14150-100000@gannet.stats>

On Mon, 17 May 2004, Slist wrote:

> I have a data set containing GPS fixes of animal locations. To check that 
> the GPS's are working properly, I would like to plot the time of the fixes 
> (y-axis) against the date of the fixes (x-axis). If all works well, the 
> plot should show four regular fixes per day. The x-axis should be labelled 
> with month/year (i.e. 11/04) and the y-axis by hour from 00 to 24. I would 
> like to control the x-axis limits.
> 
> I have looked at several date and time related help pages, but get horribly 
> lost in all the terminology. The main challenge is to isolate date and time 
> from the date/time object for plotting (marked ???). Therefore, I would 
> like the following example code to work:
> 
>  >
>  >
> dates <- c("02/27/92", "02/27/92", "01/14/92", "01/14/92", "03/28/92", "03/28/92") #
> times <- c("23:03:20", "10:29:56", "01:03:30", "13:03:30", "18:21:03", "06:56:26") #
> x <- paste(dates, times) #
> DateTime <- strptime(x, "%m/%d/%y %H:%M:%S") #

Why do you end lines with #?  It is rather confusing.

Date <- trunc(DateTime, "day")
Time <- DateTime - Date
plot(Date, Time)

appears to do what you want (except the x axis labelling, which you can 
alter by a call to axis.POSIXct and x-axis limits, which need to be set 
via xlim as a POSIXct object.).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kreil at ebi.ac.uk  Mon May 17 16:07:59 2004
From: kreil at ebi.ac.uk (David Kreil)
Date: Mon, 17 May 2004 15:07:59 +0100
Subject: [R] Change in how R handles assignments?
Message-ID: <200405171407.i4HE7xX00898@puffin.ebi.ac.uk>


Dear R-users and experts,

I have been using the following code in earlier versions of R:

  q[,names(info)]<-info[no,];

with

> class(info)
[1] "data.frame"
> class(q)
[1] "data.frame"
> dim(q)
[1] 7488   68
> dim(info)
[1] 12  8
> dim(info[no,])
[1] 1 8

The column names(info) did not exist in q before the assignment.

What used to happen (as intended) was that they would be created, and each of 
the 7488 rows would be set the same value, info[no,].

Now, in the current version of R this gives the error:

Error in "[[<-.data.frame"(`*tmp*`, k, value = rep(value[[k]], len = n)) : 
	replacement has 7488 rows, data has 1

I can use the following as a workaround

    for (n in names(info))
      q[,n]<-info[no,n];

but it seems clunky. Is there a more elegant/simple way to do the same thing 
in the current version of R? It seems I'm unintentionally forcing it to do 
something it doesn't "like".

Comments much appreciated.

Best regards,

David.


------------------------------------------------------------------------
Dr David Philip Kreil                 ("`-''-/").___..--''"`-._
Research Fellow                        `6_ 6  )   `-.  (     ).`-.__.`)
University of Cambridge                (_Y_.)'  ._   )  `._ `. ``-..-'
++44 1223 764107, fax 333992         _..`--'_..-_/  /--'_.' ,'
www.inference.phy.cam.ac.uk/dpk20   (il),-''  (li),'  ((!.-'



From macq at llnl.gov  Mon May 17 16:19:59 2004
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 17 May 2004 07:19:59 -0700
Subject: [R] Export summary statistics to latex
In-Reply-To: <40A47FBB.2020107@science.uva.nl>
References: <40A47FBB.2020107@science.uva.nl>
Message-ID: <p06002001bcce7a4ab985@[128.115.153.6]>

There is also the xtable package.
-Don

>  library(xtable)
>  x <- 1:3 ; y <- rnorm(3)
>  foo <- lm(y~x)
>  foo

Call:
lm(formula = y ~ x)

Coefficients:
(Intercept)            x 
      -2.552        1.090 

>  bah <- xtable(foo)
>  bah
% latex table generated in R 1.9.0 by xtable 1.2-3 package
% Mon May 17 07:18:40 2004
\begin{table}[ht]
\begin{center}
\begin{tabular}{rrrrr}
\hline
  & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
\hline
(Intercept) & $-$2.5523 & 2.1197 & $-$1.20 & 0.4412 \\
x & 1.0900 & 0.9812 & 1.11 & 0.4666 \\
\hline
\end{tabular}
\end{center}
\end{table}


At 10:13 AM +0200 5/14/04, Ulrich Leopold wrote:
>Dear list,
>
>I would like to export the summary statistics of a regression to latex code.
>Is there an easy way of doing that?
>
>Ulrich
>
>--
>__________________________________________________
>
>Ulrich Leopold MSc.
>
>Computational Bio- and Physical Geography (CBPG)
>Institute for Biodiversity and Ecosystem Dynamics (IBED)
>Faculty of Science
>University of Amsterdam
>Nieuwe Achtergracht 166
>NL-1018WV Amsterdam
>
>Room:   B2.52
>Phone:	+31 20 525 7456 (7451 Secretary)
>Fax:	+31 20 525 7431
>Mobile:	+31 64 220 3028
>Email:	uleopold at science.uva.nl
>URL:    www.science.uva.nl/ibed/cbpg
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From ripley at stats.ox.ac.uk  Mon May 17 16:44:17 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 May 2004 15:44:17 +0100 (BST)
Subject: [R] Change in how R handles assignments?
In-Reply-To: <200405171407.i4HE7xX00898@puffin.ebi.ac.uk>
Message-ID: <Pine.LNX.4.44.0405171525540.14150-100000@gannet.stats>

Note, this is how R handles `replacement subsetting of data frames'.

On Mon, 17 May 2004, David Kreil wrote:

> I have been using the following code in earlier versions of R:

What `earlier versions'?  As far as I know this was changed in 1.8.0.

>   q[,names(info)]<-info[no,];

You do not need to terminate lines in ;, BTW.

> with
> 
> > class(info)
> [1] "data.frame"
> > class(q)
> [1] "data.frame"
> > dim(q)
> [1] 7488   68
> > dim(info)
> [1] 12  8
> > dim(info[no,])
> [1] 1 8
> 
> The column names(info) did not exist in q before the assignment.
> 
> What used to happen (as intended) was that they would be created, and each of 
> the 7488 rows would be set the same value, info[no,].

But that was not what was documented.  The intention is that the rhs be a 
list, not a data frame.

> Now, in the current version of R this gives the error:
> 
> Error in "[[<-.data.frame"(`*tmp*`, k, value = rep(value[[k]], len = n)) : 
> 	replacement has 7488 rows, data has 1
> 
> I can use the following as a workaround
> 
>     for (n in names(info))
>       q[,n]<-info[no,n];
> 
> but it seems clunky. Is there a more elegant/simple way to do the same thing 
> in the current version of R? It seems I'm unintentionally forcing it to do 
> something it doesn't "like".

Here's a simple example that does the same in 1.8.0 as R-patched:

x <- data.frame(a=1:3, b=4:6, c=7:9)
info <- x[1:2]
x[, names(info)] <-  info[1, ]

You can do
x[, names(info)] <-  info[rep(1,3), ]
or
x[, names(info)] <- unclass(info[1, ])

We'll unclass a data frame rhs internally in future.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wuertz at itp.phys.ethz.ch  Mon May 17 16:53:24 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Mon, 17 May 2004 14:53:24 +0000
Subject: [R] Rmetrics
Message-ID: <40A8D1E4.7030308@itp.phys.ethz.ch>



Rmetrics - New Version is available for R 1.9 !!

_____________________________________________________________________
Rmetrics
is an environment and a collection of functions which may be useful
for teaching "Financial Engineering and Computational Finance".
Rmetrics can be used on top of R which is Gnu's S. Rmetrics is a
free Open Source Initiative.

_____________________________________________________________________
Download:
You can download the four library packages

    fBasics      - Markets, Basic Statistics, Date and Time Management
    fSeries   - The Dynamical Process Behind Financial Markets
    fExtremes - Beyond the Sample: Dealing with Extreme values
    fOptions  - The Valuation of Options
    
in R-binary and R-source form from the site "http://www.rmetrics.org",
and install the binary "zip" files in the usual way via the menu
button "Packages: Install package(s) from local zip file". For a quick
overview inspect the Index files. Thanks to ITP at ETH Zurich for
hosting the Download site.

_____________________________________________________________________
Support:
The response on Rmetrics is overwhelming, and so I have first to
apologize, that it is no longer possible to answer each e-mail I
received. Sorry about this.

_____________________________________________________________________
Presentation:
Rmetrics will be presented at the "useR!" conference in Vienna,
May 20-22, 2004.

_____________________________________________________________________
What's next?
Some of the topics which will become part of the next version of
Rmetrics can be found on the "Documentation" page, follow the links
on "xmpR", these are example files which include already a large
number of the new functionalities.

_____________________________________________________________________
Feedback:
I would be very pleased to get feedback about Rmetrics, it would be
helpful for future developments.


Diethelm Wuertz
ITP, ETH Zurich


www.rmetrics.org | info at rmetrics.org
www.itp.phys.ethz.ch | wuertz at itp.phys.ethz.ch



From clists at perrin.socsci.unc.edu  Mon May 17 18:03:56 2004
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Mon, 17 May 2004 12:03:56 -0400 (EDT)
Subject: [R] "ghost" image in .eps file
Message-ID: <Pine.LNX.4.53.0405171159570.11952@perrin.socsci.unc.edu>

Greetings-

An odd situation has developed. I use the following code to create .eps
files of two very similar graphs:

postscript(file='resources.bygt.eps', onefile=FALSE, horizontal=TRUE)
barplot(resources.bygt.matrix,
        beside = TRUE,
	legend.text=c('narrative','doubt'),
	names.arg=c('business','catholic','protestant','sports','union'),
	density=1:2*10,
	col=1,
	horiz=TRUE)
dev.off()

postscript(file='logics.bysc.eps', onefile=FALSE, horizontal=TRUE)
barplot(logics.bysc.matrix,
        beside = TRUE,
	legend.text=c('morality','interests','capacity'),
	names.arg=c('airport','chemco','halfin','profile'),
	density=1:3*10,
	col=1,
	horiz=TRUE)
dev.off()

The second of these works fine. However, the first (resources.bygt.eps)
contains a "ghost" image of a different graph. When I include this in a
LaTeX file, the resulting document has the ghost graph superimposed upon
the real graph.  When I use gv to see the graph, clicking the "redisplay"
button causes the ghost graph to appear.

Any idea why this is happening?

Environment is:
R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3


Both .eps files are in http://perrin.socsci.unc.edu/stuff for your
information.

Thanks for any advice.

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu



From slist at oomvanlieshout.net  Mon May 17 18:29:33 2004
From: slist at oomvanlieshout.net (Sander Oom)
Date: Mon, 17 May 2004 18:29:33 +0200
Subject: [R] Plotting Time against Date for time series data?
In-Reply-To: <Pine.LNX.4.44.0405171452010.14150-100000@gannet.stats>
References: <6.1.0.6.0.20040517131117.02526be0@localhost>
	<Pine.LNX.4.44.0405171452010.14150-100000@gannet.stats>
Message-ID: <6.1.0.6.0.20040517175726.024333c0@localhost>

The plot is nearly there! Using the axis.POSIXct command I have got the 
x-axis under control. However, the units for the y-axis (Time) are in 
seconds by default (i.e. range is from 0 to 1440). I'm trying to plot hours 
along the y-axis, without changing the units for the plot itself, but 
without any luck.

The #'s were a quick solution to stop WinEdt reformatting my code 
automatically, now I discovered I can switch to a different wrap mode.

This is the code just now:

 >
 > psDateTime <- function(DateTime, FileName){
+     strFileName <- paste("Analysis\\Graphics\\time_date_", FileName, sep 
= "")
+     startMonth <- as.POSIXct(as.Date("01/09/2003", format="%d/%m/%Y"))
+     endMonth <- as.POSIXct(as.Date("01/06/2004", format="%d/%m/%Y"))
+     startTime <- as.POSIXct(as.Date("00:00:00", format="%H:%m:%s"))
+     endTime <- as.POSIXct(as.Date("23:59:59", format="%H:%m:%s"))
+     Date <- trunc(DateTime, "day")
+     Time <- DateTime - Date
+     postscript(strFileName)
+     plot(x=Date, y=Time,
+         xlab= "Date (month/year)", ylab= "Time (hours)", xaxt="n", #yaxt="n",
+         xlim=c(as.POSIXct(startMonth), as.POSIXct(endMonth)),
+         ylim=c(as.POSIXct(startTime), as.POSIXct(endTime))
+         )
+     axis.POSIXct(1, at=seq(startMonth, endMonth, by="month"), format="%m/%y")
+     axis.POSIXct(2, at=seq(startTime, endTime, by="hours"), format="%H")
+     pstamp(pwd=FALSE, time=TRUE)
+     dev.off()
+ }
 > psDateTime(datKruger1$DaTim, "datKruger1.eps")
Error in plot.window(xlim, ylim, log, asp, ...) :
         need finite ylim values
 >

and when removing the ylim line from the above code, an error associated 
with the 'axis.POSICct(2....)' line:

 > psDateTime(datKruger1$DaTim, "datKruger1.eps")
Error in if (to <= from) stop("`to' must be later than `from'") :
         missing value where TRUE/FALSE needed
 >

Any help much appreciated,

Sander.

At 15:58 2004/05/17, you wrote:
>On Mon, 17 May 2004, Slist wrote:
>
> > I have a data set containing GPS fixes of animal locations. To check that
> > the GPS's are working properly, I would like to plot the time of the fixes
> > (y-axis) against the date of the fixes (x-axis). If all works well, the
> > plot should show four regular fixes per day. The x-axis should be labelled
> > with month/year (i.e. 11/04) and the y-axis by hour from 00 to 24. I would
> > like to control the x-axis limits.
> >
> > I have looked at several date and time related help pages, but get 
> horribly
> > lost in all the terminology. The main challenge is to isolate date and 
> time
> > from the date/time object for plotting (marked ???). Therefore, I would
> > like the following example code to work:
> >
> >  >
> >  >
> > dates <- c("02/27/92", "02/27/92", "01/14/92", "01/14/92", "03/28/92", 
> "03/28/92") #
> > times <- c("23:03:20", "10:29:56", "01:03:30", "13:03:30", "18:21:03", 
> "06:56:26") #
> > x <- paste(dates, times) #
> > DateTime <- strptime(x, "%m/%d/%y %H:%M:%S") #
>
>Why do you end lines with #?  It is rather confusing.
>
>Date <- trunc(DateTime, "day")
>Time <- DateTime - Date
>plot(Date, Time)
>
>appears to do what you want (except the x axis labelling, which you can
>alter by a call to axis.POSIXct and x-axis limits, which need to be set
>via xlim as a POSIXct object.).
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May 17 18:39:30 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 May 2004 17:39:30 +0100 (BST)
Subject: [R] Plotting Time against Date for time series data?
In-Reply-To: <6.1.0.6.0.20040517175726.024333c0@localhost>
Message-ID: <Pine.LNX.4.44.0405171736110.5200-100000@gannet.stats>

On Mon, 17 May 2004, Sander Oom wrote:

> The plot is nearly there! Using the axis.POSIXct command I have got the 
> x-axis under control. However, the units for the y-axis (Time) are in 
> seconds by default (i.e. range is from 0 to 1440). I'm trying to plot hours 
> along the y-axis, without changing the units for the plot itself, but 
> without any luck.

I got hours for your example, I believe, but it does depend on the data.

Try

Time <- difftime(Date, DateTime, units="hours")

and treat them as numbers, not as POSIXct (they are not dates).


> 
> The #'s were a quick solution to stop WinEdt reformatting my code 
> automatically, now I discovered I can switch to a different wrap mode.
> 
> This is the code just now:
> 
>  >
>  > psDateTime <- function(DateTime, FileName){
> +     strFileName <- paste("Analysis\\Graphics\\time_date_", FileName, sep 
> = "")
> +     startMonth <- as.POSIXct(as.Date("01/09/2003", format="%d/%m/%Y"))
> +     endMonth <- as.POSIXct(as.Date("01/06/2004", format="%d/%m/%Y"))
> +     startTime <- as.POSIXct(as.Date("00:00:00", format="%H:%m:%s"))
> +     endTime <- as.POSIXct(as.Date("23:59:59", format="%H:%m:%s"))

Just startTime <- 0, endTime <- 24 should do.

> +     Date <- trunc(DateTime, "day")
> +     Time <- DateTime - Date
> +     postscript(strFileName)
> +     plot(x=Date, y=Time,
> +         xlab= "Date (month/year)", ylab= "Time (hours)", xaxt="n", #yaxt="n",
> +         xlim=c(as.POSIXct(startMonth), as.POSIXct(endMonth)),
> +         ylim=c(as.POSIXct(startTime), as.POSIXct(endTime))
> +         )
> +     axis.POSIXct(1, at=seq(startMonth, endMonth, by="month"), format="%m/%y")
> +     axis.POSIXct(2, at=seq(startTime, endTime, by="hours"), format="%H")
> +     pstamp(pwd=FALSE, time=TRUE)
> +     dev.off()
> + }
>  > psDateTime(datKruger1$DaTim, "datKruger1.eps")
> Error in plot.window(xlim, ylim, log, asp, ...) :
>          need finite ylim values
>  >
> 
> and when removing the ylim line from the above code, an error associated 
> with the 'axis.POSICct(2....)' line:
> 
>  > psDateTime(datKruger1$DaTim, "datKruger1.eps")
> Error in if (to <= from) stop("`to' must be later than `from'") :
>          missing value where TRUE/FALSE needed
>  >
> 
> Any help much appreciated,
> 
> Sander.
> 
> At 15:58 2004/05/17, you wrote:
> >On Mon, 17 May 2004, Slist wrote:
> >
> > > I have a data set containing GPS fixes of animal locations. To check that
> > > the GPS's are working properly, I would like to plot the time of the fixes
> > > (y-axis) against the date of the fixes (x-axis). If all works well, the
> > > plot should show four regular fixes per day. The x-axis should be labelled
> > > with month/year (i.e. 11/04) and the y-axis by hour from 00 to 24. I would
> > > like to control the x-axis limits.
> > >
> > > I have looked at several date and time related help pages, but get 
> > horribly
> > > lost in all the terminology. The main challenge is to isolate date and 
> > time
> > > from the date/time object for plotting (marked ???). Therefore, I would
> > > like the following example code to work:
> > >
> > >  >
> > >  >
> > > dates <- c("02/27/92", "02/27/92", "01/14/92", "01/14/92", "03/28/92", 
> > "03/28/92") #
> > > times <- c("23:03:20", "10:29:56", "01:03:30", "13:03:30", "18:21:03", 
> > "06:56:26") #
> > > x <- paste(dates, times) #
> > > DateTime <- strptime(x, "%m/%d/%y %H:%M:%S") #
> >
> >Why do you end lines with #?  It is rather confusing.
> >
> >Date <- trunc(DateTime, "day")
> >Time <- DateTime - Date
> >plot(Date, Time)
> >
> >appears to do what you want (except the x axis labelling, which you can
> >alter by a call to axis.POSIXct and x-axis limits, which need to be set
> >via xlim as a POSIXct object.).
> >
> >--
> >Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >University of Oxford,             Tel:  +44 1865 272861 (self)
> >1 South Parks Road,                     +44 1865 272866 (PA)
> >Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jpgranadeiro at fc.ul.pt  Mon May 17 19:24:09 2004
From: jpgranadeiro at fc.ul.pt (J. Pedro Granadeiro)
Date: Mon, 17 May 2004 18:24:09 +0100
Subject: [R] displaying column numbers when listing structure of an object
Message-ID: <200405171824.09878.jpgranadeiro@fc.ul.pt>

Dear R helpers,

Is there any simple way to display the column(s) numbers(s) when listing the 
structure of objects (especially for objects with large number of columns)?

Example on a data.frame:

 str(data.frame(v1=c(1:10),v2=(11:20)))
`data.frame':   10 obs. of  2 variables:
1.. $ v1: int  1 2 3 4 5 6 7 8 9 10
2.. $ v2: int  11 12 13 14 15 16 17 18 19 20

I checked the examples in ?str and the searchable mail archives, and made 
several attempts with "indent.str", but it was hopeless...

Thank you.

Jos?? Pedro Granadeiro



From monica.palaseanu-lovejoy at stud.man.ac.uk  Mon May 17 19:45:01 2004
From: monica.palaseanu-lovejoy at stud.man.ac.uk (Monica Palaseanu-Lovejoy)
Date: Mon, 17 May 2004 18:45:01 +0100
Subject: [R] basics: how do you sort a table?
Message-ID: <E1BPmAq-0003Li-E4@serenity.mcc.ac.uk>

Hi,

This may be a very basic question but it seems i cannot figure it 
out does not matter what.

how do you sort a table (ascending or descending) after the values 
in one particular column? I want to do something like the sort 
function in Xcel.

Also, is there any other plot function that accepts log for y axes 
like the parplot2() from gregmisc? Thanks for the tip Marc about 
barplot2. very useful indeed!

Thank you again for all the help,

Monica



From ripley at stats.ox.ac.uk  Mon May 17 20:30:22 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 May 2004 19:30:22 +0100 (BST)
Subject: [R] basics: how do you sort a table?
In-Reply-To: <E1BPmAq-0003Li-E4@serenity.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0405171922260.8439-100000@gannet.stats>

On Mon, 17 May 2004, Monica Palaseanu-Lovejoy wrote:

> This may be a very basic question but it seems i cannot figure it 
> out does not matter what.
> 
> how do you sort a table (ascending or descending) after the values 
> in one particular column? I want to do something like the sort 
> function in Xcel.

Well, what is `Xcel' and what is a `table'?  What Excel calls sheets are
usually represented as data frames in R, and ?order will tell you how to
do this.

help.search("sort") would surely have got you there -- did you try it?

> Also, is there any other plot function that accepts log for y axes 
> like the parplot2() from gregmisc? Thanks for the tip Marc about 
> barplot2. very useful indeed!

Look at `log' under ?par.  Almost all basic plot methods do. (It seems an
oversight that barplot does not.) This is in an `Introduction to R', for
example -- have you read that yet?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From slist at oomvanlieshout.net  Mon May 17 21:14:47 2004
From: slist at oomvanlieshout.net (Sander Oom)
Date: Mon, 17 May 2004 21:14:47 +0200
Subject: [R] Plotting Time against Date for time series data? (2)
In-Reply-To: <Pine.LNX.4.44.0405171736110.5200-100000@gannet.stats>
References: <6.1.0.6.0.20040517175726.024333c0@localhost>
	<Pine.LNX.4.44.0405171736110.5200-100000@gannet.stats>
Message-ID: <6.1.0.6.0.20040517210243.0248c790@localhost>

Almost but not quite:

Someone told me R would produce such high quality graphics, I would never 
need a separate graphics package again. This does however mean that I need 
to be able to draw the graph exactly the way I want it to look!

I have searched the web and help files extensively, but there are few 
references on plotting time on an axis. The function presented here 
(http://tolstoy.newcastle.edu.au/R/help/00a/1031.html) could be useful, but 
I'm not sure how to implement it in my example. Anyway there should be a 
simpler way.

The following code uses the example again. It does have hours on the 
x-axis, but the tic marks are printed as: 0, 5, 10, 15, 20. Not a very 
intuitive frequency of tic marks. How do I get R to plot tic marks at: 0, 
4, 8, 12, 16, 20, 24 or 0, 2, 4..., 24? I want the tic marks to be fixed, 
i.e. they should still go from 0-24 even when the range of the data is smaller.

dates <- c("02/27/92", "02/27/92", "01/14/92", "01/14/92", "03/28/92", 
"03/28/92") #
times <- c("23:03:20", "10:29:56", "01:03:30", "13:03:30", "18:21:03", 
"06:56:26") #
x <- paste(dates, times) #
DateTime <- strptime(x, "%m/%d/%y %H:%M:%S") #
Date <- trunc(DateTime, "day")
Time <- difftime(DateTime, Date, units="hours")
startMonth <- as.POSIXct(as.Date("01/01/1992", format="%d/%m/%Y"))
endMonth <- as.POSIXct(as.Date("01/05/1992", format="%d/%m/%Y"))
plot(x=Date, y=Time,
         xlab= "Date (month/year)", ylab= "Time (hours)", xaxt="n", yaxt="n",
         xlim=c(startMonth, endMonth),
         ylim=c(0, 24)
         ) #
axis.POSIXct(1, at=seq(startMonth, endMonth, by="month"), format="%m/%y")
#r <- as.POSIXct(range(Time), "hours") #
clock24 <- 
strptime(c("0","2","4","6","8","10","12","14","16","18","20","22","23"), "%H")
r <- as.POSIXct(round(range(clock24), "hours"))
axis.POSIXct(2, at=seq(r[1], r[2], by="hour"), format="%H") #

More suggestions welcome,

Sander



At 18:39 2004/05/17, you wrote:
>On Mon, 17 May 2004, Sander Oom wrote:
>
> > The plot is nearly there! Using the axis.POSIXct command I have got the
> > x-axis under control. However, the units for the y-axis (Time) are in
> > seconds by default (i.e. range is from 0 to 1440). I'm trying to plot 
> hours
> > along the y-axis, without changing the units for the plot itself, but
> > without any luck.
>
>I got hours for your example, I believe, but it does depend on the data.
>
>Try
>
>Time <- difftime(Date, DateTime, units="hours")
>
>and treat them as numbers, not as POSIXct (they are not dates).
>
>
> >
> > The #'s were a quick solution to stop WinEdt reformatting my code
> > automatically, now I discovered I can switch to a different wrap mode.
> >
> > This is the code just now:
> >
> >  >
> >  > psDateTime <- function(DateTime, FileName){
> > +     strFileName <- paste("Analysis\\Graphics\\time_date_", FileName, sep
> > = "")
> > +     startMonth <- as.POSIXct(as.Date("01/09/2003", format="%d/%m/%Y"))
> > +     endMonth <- as.POSIXct(as.Date("01/06/2004", format="%d/%m/%Y"))
> > +     startTime <- as.POSIXct(as.Date("00:00:00", format="%H:%m:%s"))
> > +     endTime <- as.POSIXct(as.Date("23:59:59", format="%H:%m:%s"))
>
>Just startTime <- 0, endTime <- 24 should do.
>
> > +     Date <- trunc(DateTime, "day")
> > +     Time <- DateTime - Date
> > +     postscript(strFileName)
> > +     plot(x=Date, y=Time,
> > +         xlab= "Date (month/year)", ylab= "Time (hours)", xaxt="n", 
> #yaxt="n",
> > +         xlim=c(as.POSIXct(startMonth), as.POSIXct(endMonth)),
> > +         ylim=c(as.POSIXct(startTime), as.POSIXct(endTime))
> > +         )
> > +     axis.POSIXct(1, at=seq(startMonth, endMonth, by="month"), 
> format="%m/%y")
> > +     axis.POSIXct(2, at=seq(startTime, endTime, by="hours"), format="%H")
> > +     pstamp(pwd=FALSE, time=TRUE)
> > +     dev.off()
> > + }
> >  > psDateTime(datKruger1$DaTim, "datKruger1.eps")
> > Error in plot.window(xlim, ylim, log, asp, ...) :
> >          need finite ylim values
> >  >
> >
> > and when removing the ylim line from the above code, an error associated
> > with the 'axis.POSICct(2....)' line:
> >
> >  > psDateTime(datKruger1$DaTim, "datKruger1.eps")
> > Error in if (to <= from) stop("`to' must be later than `from'") :
> >          missing value where TRUE/FALSE needed
> >  >
> >
> > Any help much appreciated,
> >
> > Sander.
> >
> > At 15:58 2004/05/17, you wrote:
> > >On Mon, 17 May 2004, Slist wrote:
> > >
> > > > I have a data set containing GPS fixes of animal locations. To 
> check that
> > > > the GPS's are working properly, I would like to plot the time of 
> the fixes
> > > > (y-axis) against the date of the fixes (x-axis). If all works well, the
> > > > plot should show four regular fixes per day. The x-axis should be 
> labelled
> > > > with month/year (i.e. 11/04) and the y-axis by hour from 00 to 24. 
> I would
> > > > like to control the x-axis limits.
> > > >
> > > > I have looked at several date and time related help pages, but get
> > > horribly
> > > > lost in all the terminology. The main challenge is to isolate date and
> > > time
> > > > from the date/time object for plotting (marked ???). Therefore, I would
> > > > like the following example code to work:
> > > >
> > > >  >
> > > >  >
> > > > dates <- c("02/27/92", "02/27/92", "01/14/92", "01/14/92", "03/28/92",
> > > "03/28/92") #
> > > > times <- c("23:03:20", "10:29:56", "01:03:30", "13:03:30", "18:21:03",
> > > "06:56:26") #
> > > > x <- paste(dates, times) #
> > > > DateTime <- strptime(x, "%m/%d/%y %H:%M:%S") #
> > >
> > >Why do you end lines with #?  It is rather confusing.
> > >
> > >Date <- trunc(DateTime, "day")
> > >Time <- DateTime - Date
> > >plot(Date, Time)
> > >
> > >appears to do what you want (except the x axis labelling, which you can
> > >alter by a call to axis.POSIXct and x-axis limits, which need to be set
> > >via xlim as a POSIXct object.).
> > >
> > >--
> > >Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > >Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > >University of Oxford,             Tel:  +44 1865 272861 (self)
> > >1 South Parks Road,                     +44 1865 272866 (PA)
> > >Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From i.visser at uva.nl  Mon May 17 21:21:58 2004
From: i.visser at uva.nl (Ingmar Visser)
Date: Mon, 17 May 2004 21:21:58 +0200
Subject: [R] ld: warning ... Max osx
Message-ID: <BCCEDD76.2971%i.visser@uva.nl>


Hi All,

When installing a package using C++/Fortran routines I get a large number of
ld warnings:

ld: warning multiple definitions of symbol _adler32
/Library/Frameworks/R.framework/R(adler32.o) definition of _adler32
/usr/lib/libz.1.dylib(adler32.o) definition of _adler32
ld: warning multiple definitions of symbol _BC
/Library/Frameworks/R.framework/Resources/bin/Frameworks/libreadline.4.3.dyl
ib(terminal.so) definition of _BC
/usr/lib/libncurses.5.dylib(lib_termcap.o) definition of _BC

and many more 


My platform is:
platform powerpc-apple-darwin6.8
arch     powerpc   
os       darwin6.8 
system   powerpc, darwin6.8
status             
major    1         
minor    9.0       
year     2004      
month    04        
day      12        
language R  

The package seems to work fine, but I am surprised to get these warnings
because I did not them when installing the same package under R 1.8

What is the reason of these warnings and how can I prevent them?

best, ingmar



From ripley at stats.ox.ac.uk  Mon May 17 21:30:13 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 May 2004 20:30:13 +0100 (BST)
Subject: [R] Plotting Time against Date for time series data? (2)
In-Reply-To: <6.1.0.6.0.20040517210243.0248c790@localhost>
Message-ID: <Pine.LNX.4.44.0405172027270.8577-100000@gannet.stats>

On Mon, 17 May 2004, Sander Oom wrote:

> Almost but not quite:
> 
> Someone told me R would produce such high quality graphics, I would never 
> need a separate graphics package again. This does however mean that I need 
> to be able to draw the graph exactly the way I want it to look!
> 
> I have searched the web and help files extensively, but there are few 
> references on plotting time on an axis. 

You don't have `time', you have a set of numbers in 0-24.  I did suggest
you treat them as such.

> The function presented here 
> (http://tolstoy.newcastle.edu.au/R/help/00a/1031.html) could be useful, but 
> I'm not sure how to implement it in my example. Anyway there should be a 
> simpler way.
> 
> The following code uses the example again. It does have hours on the 
> x-axis, but the tic marks are printed as: 0, 5, 10, 15, 20. Not a very 
> intuitive frequency of tic marks. How do I get R to plot tic marks at: 0, 
> 4, 8, 12, 16, 20, 24 or 0, 2, 4..., 24? I want the tic marks to be fixed, 

Use axis(), of course. That is in all the basic info on R, as well as all
good books on S/R.

> i.e. they should still go from 0-24 even when the range of the data is
> smaller.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kreil at ebi.ac.uk  Mon May 17 21:48:12 2004
From: kreil at ebi.ac.uk (David Kreil)
Date: Mon, 17 May 2004 20:48:12 +0100
Subject: [R] Change in how R handles assignments? 
In-Reply-To: Your message of "Mon, 17 May 2004 15:44:17 BST."
	<Pine.LNX.4.44.0405171525540.14150-100000@gannet.stats> 
Message-ID: <200405171948.i4HJmCH06393@puffin.ebi.ac.uk>


Dear Prof Brian Ripley,

Thank you very much for your fast and helpful answer!


> > I have been using the following code in earlier versions of R:
> 
> What `earlier versions'?  As far as I know this was changed in 1.8.0.

Yes, that fits my observations. We have an old 1.7.1-beta installation and a 
newer 1.8.1; the "old" code runs on the 1.7.1 but not on the 1.8.1.

> >   q[,names(info)]<-info[no,];
> You do not need to terminate lines in ;, BTW.
Thanks! A "bad" C-habit, I suppose.

> But that was not what was documented.  The intention is that the rhs be a 
> list, not a data frame.

Ah! Is
  q[,names(info)]<-c(info[no,]);
a good way of writing it then? It seems to work.


> You can do
> x[, names(info)] <- unclass(info[1, ])

Great, thanks! Is there any advantage of using unclass() vs c()?

> We'll unclass a data frame rhs internally in future.

Does that mean that the "old" 1.7.1 code will work again in future R releases? 
That would save me from fixing quite a number of our R programs (we'd stick to 
the 1.7.1 with the old code in the mean time).

With many thanks again for your help,

David Kreil.

------------------------------------------------------------------------
Dr David Philip Kreil                 ("`-''-/").___..--''"`-._
Research Fellow                        `6_ 6  )   `-.  (     ).`-.__.`)
University of Cambridge                (_Y_.)'  ._   )  `._ `. ``-..-'
++44 1223 764107, fax 333992         _..`--'_..-_/  /--'_.' ,'
www.inference.phy.cam.ac.uk/dpk20   (il),-''  (li),'  ((!.-'



From tlumley at u.washington.edu  Mon May 17 21:53:33 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 17 May 2004 12:53:33 -0700 (PDT)
Subject: [R] ld: warning ... Max osx
In-Reply-To: <BCCEDD76.2971%i.visser@uva.nl>
References: <BCCEDD76.2971%i.visser@uva.nl>
Message-ID: <Pine.A41.4.58.0405171250150.168346@homer04.u.washington.edu>

On Mon, 17 May 2004, Ingmar Visser wrote:

>
> Hi All,
>
> When installing a package using C++/Fortran routines I get a large number of
> ld warnings:

Yes, you do.  They are harmless.

	-thomas

> ld: warning multiple definitions of symbol _adler32
> /Library/Frameworks/R.framework/R(adler32.o) definition of _adler32
> /usr/lib/libz.1.dylib(adler32.o) definition of _adler32
> ld: warning multiple definitions of symbol _BC
> /Library/Frameworks/R.framework/Resources/bin/Frameworks/libreadline.4.3.dyl
> ib(terminal.so) definition of _BC
> /usr/lib/libncurses.5.dylib(lib_termcap.o) definition of _BC
>
> and many more
>
>
> My platform is:
> platform powerpc-apple-darwin6.8
> arch     powerpc
> os       darwin6.8
> system   powerpc, darwin6.8
> status
> major    1
> minor    9.0
> year     2004
> month    04
> day      12
> language R
>
> The package seems to work fine, but I am surprised to get these warnings
> because I did not them when installing the same package under R 1.8
>
> What is the reason of these warnings and how can I prevent them?
>
> best, ingmar
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From ripley at stats.ox.ac.uk  Mon May 17 21:54:58 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 May 2004 20:54:58 +0100 (BST)
Subject: [R] Change in how R handles assignments? 
In-Reply-To: <200405171948.i4HJmCH06393@puffin.ebi.ac.uk>
Message-ID: <Pine.LNX.4.44.0405172050220.12003-100000@gannet.stats>

On Mon, 17 May 2004, David Kreil wrote:

> 
> Dear Prof Brian Ripley,
> 
> Thank you very much for your fast and helpful answer!
> 
> 
> > > I have been using the following code in earlier versions of R:
> > 
> > What `earlier versions'?  As far as I know this was changed in 1.8.0.
> 
> Yes, that fits my observations. We have an old 1.7.1-beta installation
> and a newer 1.8.1; the "old" code runs on the 1.7.1 but not on the
> 1.8.1.

1.9.0 is current, and R-patched (will become 1.9.1 is a few weeks) is 
already available with this patched.  1.8.1 is `an earlier version' 
already.

> > >   q[,names(info)]<-info[no,];
> > You do not need to terminate lines in ;, BTW.
> Thanks! A "bad" C-habit, I suppose.
> 
> > But that was not what was documented.  The intention is that the rhs be a 
> > list, not a data frame.
> 
> Ah! Is
>   q[,names(info)]<-c(info[no,]);
> a good way of writing it then? It seems to work.
> 
> 
> > You can do
> > x[, names(info)] <- unclass(info[1, ])
> 
> Great, thanks! Is there any advantage of using unclass() vs c()?

c() works only for a single row and columns of the same type.  unclass 
always works, as a list is the specified value in the docs.

> > We'll unclass a data frame rhs internally in future.
> 
> Does that mean that the "old" 1.7.1 code will work again in future R
> releases?  That would save me from fixing quite a number of our R
> programs (we'd stick to the 1.7.1 with the old code in the mean time).

I don't know.  It means that using a data frame as the rhs with the wrong
number of rows will again recycle each column.  Lots of things used to
`work' pre-1.8.0, but were undocumented and not as people expected, often
resulting in corrupted data frames.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kreil at ebi.ac.uk  Mon May 17 22:00:31 2004
From: kreil at ebi.ac.uk (David Kreil)
Date: Mon, 17 May 2004 21:00:31 +0100
Subject: [R] Change in how R handles assignments? 
In-Reply-To: Your message of "Mon, 17 May 2004 20:54:58 BST."
	<Pine.LNX.4.44.0405172050220.12003-100000@gannet.stats> 
Message-ID: <200405172000.i4HK0VL09193@puffin.ebi.ac.uk>


Dear Prof Brian Ripley,

Thank you very much for the fast and helpful explanation!

We'll get 1.9.1 as soon as it's out.

With many thanks again,

David Kreil.


------------------------------------------------------------------------
Dr David Philip Kreil                 ("`-''-/").___..--''"`-._
Research Fellow                        `6_ 6  )   `-.  (     ).`-.__.`)
University of Cambridge                (_Y_.)'  ._   )  `._ `. ``-..-'
++44 1223 764107, fax 333992         _..`--'_..-_/  /--'_.' ,'
www.inference.phy.cam.ac.uk/dpk20   (il),-''  (li),'  ((!.-'



From rossini at blindglobe.net  Mon May 17 22:36:11 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 17 May 2004 13:36:11 -0700
Subject: [R] Bioconductor 1.4 released
Message-ID: <85smdyiyf8.fsf@servant.blindglobe.net>


Greetings!  

The Bioconductor core group would like to announce the 5th release of
Bioconductor, version 1.4.  There are many new packages as well as
several major upgrades and fixes in older packages, and users are
encouraged to upgrade existing tools and check out the new packages.

Release 1.4 is intended to be operated with R version 1.9.x, which can
be obtained at CRAN (http://cran.r-project.org/)


WHAT FEATURES DOES THIS RELEASE PROVIDE?
========================================

All packages from the 1.3 release are included.  All current bug fixes
have been applied, and most have upgraded and provide enhanced
functionality.

SOME OF THE MAJOR UPGRADES FOR RELEASE 1.4:
===========================================

-- Proteomics (PROcess, gpls, apComplex)

-- Array CGH (DNAcopy, aCGH)

-- Cell cycle analysis (GeneTS)

-- Packages for lab assay analysis and management (prada)

-- Agilent arrays handling in limma

-- Annotation tools (Resourcer, GOstat, goTools, ontoTools)

-- Improved interfaces (limmaGUI, affylmGUI, webbioc, 

-- MAGE file processing (RMAGEML)

-- affymetrix processing:  many improvements, gcrma, affypdnn
   (probe-dependent nearest neighbors), affyPLM (probe-level models). 

-- marray (next generation of the depreciated marrayClasses, marrayNorm,
   marrayPlots, marrayTools packages)

-- General analysis tools (rama, qvalue, pickgene, EBarrays, impute,
   pamr, bim, )

-- QA/QC (arrayMagic, arrayQuality, LPE)

-- sequence analysis (pairseqsim, Biostrings)

-- interface to the GeneSpring data analysis program (GeneSpring)



TOOLS:
======

The released packages include tools which facilitate:

* annotation

* data management and organization through the use of the S4 class
  structure 

* identification of differentially expressed genes and clustering 

* quality assurance and control

* analysis of Affymetrix expression array data 

* diagnostic plots and normalization for cDNA array data

* storage and retrieval of large datasets 

* user interaction widgets

* sequence analysis

* proteomics

There are currently 81 packages, not including precomputed annotation
data packages for Affymetrix GeneChips(tm) and prepackaged general
annotation databases such as KEGG, GO, and LocusLink.


HELP AND RESOURCES:
===================

The packages and more details may be found on the Bioconductor WWW
site: 

      http://www.bioconductor.org/

Information on subscribing to the mailing list and viewing its archives
can be found at:

      http://www.stat.math.ethz.ch/mailman/listinfo/bioconductor

Please use that list to discuss Bioconductor specific issues, bugs,
and problems.  Note that every package has a vignette (a literate
program which provides an annotated example of the package's use) as
well as possibly some "HOWTO"s.  These document the tool's usage, and
are provided in the "doc" subdirectory of each package library.  Try:

    library(tkWidgets)
    vExplorer()

for assistance after installing BioConductor.


WHO:
====

For the Bioconductor development team:

Douglas Bates, University of Wisconsin, USA.
Ben Bolstad, Division of Biostatistics, UC Berkeley, USA.
Vince Carey, Harvard Medical School, USA.
Marcel Dettling, Federal Inst. Technology, Switzerland.
Sandrine Dudoit, Division of Biostatistics, UC Berkeley, USA.
Byron Ellis, Harvard Department of Statistics, USA.
Laurent Gautier, Technial University of Denmark, Denmark.
Robert Gentleman, Harvard Medical School, USA.
Jeff Gentry, Dana-Farber Cancer Institute, USA.
Kurt Hornik, Technische Universitat Wien, Austria.
Torsten Hothorn, Institut fuer Medizininformatik,
	Biometrie und Epidemiologie, Germany.
Wolfgang Huber, DKFZ Heidelberg, Molecular Genome Analysis, Germany.
Stefano Iacus, Italy
Rafael Irizarry, Department of Biostatistics (JHU), USA.
Friedrich Leisch, Technische Universitat Wien, Austria.
Martin Maechler, Federal Inst. Technology, Switzerland.
Colin Smith, Scripps Research Institute, USA.
Gordon Smyth, Walter and Eliza Hall Institute, Australia.
A.J. Rossini, Medical Eduction and Biomedical Informatics, University
     of Washington and Biostatistics, Fred Hutchinson Cancer Research
     Center, USA.  
Gunther Sawitzki, Institute fur Angewandte Mathematik, Germany.
Luke Tierney, University of Iowa, USA.
Jean Yee Hwa Yang, University of California, San Francisco, USA.
Jianhua (John) Zhang, Dana-Farber Cancer Institute, USA.

With special thanks to many contributors from around the world.





best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From Meredith.Briggs at team.telstra.com  Tue May 18 03:06:00 2004
From: Meredith.Briggs at team.telstra.com (Briggs, Meredith M)
Date: Tue, 18 May 2004 11:06:00 +1000
Subject: [R] How do you force runif to return non-duplicate results eg
	runif(0, 1, n=10)? thanks
Message-ID: <3B5823541A25D311B3B90008C7F9056410E35500@ntmsg0092.corpmail.telstra.com.au>



From ripley at stats.ox.ac.uk  Tue May 18 06:55:30 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 May 2004 05:55:30 +0100 (BST)
Subject: [R] How do you force runif to return non-duplicate results eg
	runif(0, 1, n=10)? thanks
In-Reply-To: <3B5823541A25D311B3B90008C7F9056410E35500@ntmsg0092.corpmail.telstra.com.au>
Message-ID: <Pine.LNX.4.44.0405180550290.13132-100000@gannet.stats>

On Tue, 18 May 2004, Briggs, Meredith M wrote:

<nothing>

runif by definition samples independently from U(0,1).  So by defnition 
the results are not duplicated.  It is possible due to finite computer 
representations that you would get duplicates to computer accuracy but the 
chance of that in sample size of 10 is about the chance of winning the UK 
lottery twice in a row, and much less plausible than a computer fault.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From arcane at arcanemethods.com  Tue May 18 05:19:30 2004
From: arcane at arcanemethods.com (Bob Cain)
Date: Mon, 17 May 2004 20:19:30 -0700
Subject: [R] R vs Matlab: which is more "programmer friendly"?
In-Reply-To: <loom.20040425T142147-830@post.gmane.org>
References: <20040425090809.GA704@localhost>
	<loom.20040425T142147-830@post.gmane.org>
Message-ID: <c8bvbt$m54$1@sea.gmane.org>



Gabor Grothendieck wrote:

> Also, there is a document on the R site that
> provides a translation between Octave and R that might give you some
> insight into your questions:
> http://cran.r-project.org/doc/contrib/R-and-octave-2.txt

Drool.  If someone could do that from Matlab to R, I'd be 
outta there in a heartbeat.


Bob



From ripley at stats.ox.ac.uk  Tue May 18 07:55:18 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 May 2004 06:55:18 +0100 (BST)
Subject: [R] "ghost" image in .eps file
In-Reply-To: <Pine.LNX.4.53.0405171159570.11952@perrin.socsci.unc.edu>
Message-ID: <Pine.LNX.4.44.0405180649590.20310-100000@gannet.stats>

I can't see this in your examples: which viewer did you use?  I do see it 
in phantom.ps.

However, looking at resources.bygt.eps, the file is corrupt with a load 
of bytes after 

%%EOF

starting with nulls and then some postscript.  So I don't think this is an
R problem but an OS problem.  (Please see the posting guide about required
background info!) An intelligent viewer will stop at the %%EOF comment.

Please try deleting the file resources.bygt.eps, starting a new R session
and repeating the plot call.


On Mon, 17 May 2004, Andrew Perrin wrote:

> Greetings-
> 
> An odd situation has developed. I use the following code to create .eps
> files of two very similar graphs:
> 
> postscript(file='resources.bygt.eps', onefile=FALSE, horizontal=TRUE)
> barplot(resources.bygt.matrix,
>         beside = TRUE,
> 	legend.text=c('narrative','doubt'),
> 	names.arg=c('business','catholic','protestant','sports','union'),
> 	density=1:2*10,
> 	col=1,
> 	horiz=TRUE)
> dev.off()
> 
> postscript(file='logics.bysc.eps', onefile=FALSE, horizontal=TRUE)
> barplot(logics.bysc.matrix,
>         beside = TRUE,
> 	legend.text=c('morality','interests','capacity'),
> 	names.arg=c('airport','chemco','halfin','profile'),
> 	density=1:3*10,
> 	col=1,
> 	horiz=TRUE)
> dev.off()
> 
> The second of these works fine. However, the first (resources.bygt.eps)
> contains a "ghost" image of a different graph. When I include this in a
> LaTeX file, the resulting document has the ghost graph superimposed upon
> the real graph.  When I use gv to see the graph, clicking the "redisplay"
> button causes the ghost graph to appear.
> 
> Any idea why this is happening?
> 
> Environment is:
> R : Copyright 2003, The R Foundation for Statistical Computing
> Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3
> 
> 
> Both .eps files are in http://perrin.socsci.unc.edu/stuff for your
> information.
> 
> Thanks for any advice.
> 
> ----------------------------------------------------------------------
> Andrew J Perrin - http://www.unc.edu/~aperrin
> Assistant Professor of Sociology, U of North Carolina, Chapel Hill
> clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Melanie.Pelegrini at imed.jussieu.fr  Tue May 18 16:09:38 2004
From: Melanie.Pelegrini at imed.jussieu.fr (=?ISO-8859-1?Q?M=E9lanie_PELEGRINI-ISSAC?=)
Date: Tue, 18 May 2004 16:09:38 +0200
Subject: [R] Build R-1.9.0 with static libraries ?
Message-ID: <40AA1922.9060003@imed.jussieu.fr>

Dear all,

Which options should I use when running the configure script
            and/or
which changes should I make to Makeconf
to build the binary for R-1.9.0 but using only statically linked libraries ?

I need to build a binary that is portable between several different 
Linux (RedHat) distributions.

Thanks in advance for your help,

Melanie

-- 
http://recherche-en-danger.apinc.org

M??lanie PELEGRINI-ISSAC
Unit?? 483 INSERM		
9, quai Saint-Bernard           email :Melanie.Pelegrini at imed.jussieu.fr
Bat C 6e etage 75005 PARIS



From ozric at web.de  Tue May 18 10:18:13 2004
From: ozric at web.de (Christian Schulz)
Date: Tue, 18 May 2004 10:18:13 +0200
Subject: [R] list & calculaton in many df subsets
Message-ID: <200405181018.13509.ozric@web.de>

Hi,

have anybody a hint /starting point how i can 
enlarge my code that's posiible for me make any  calculaton's
with variables in the  64 subset's.

Example: 
I want calculate difference of two variables inside every
of the 64 subset data.frames  and getting this value in tList!

Many thanks,
Christian


tasign <- paste("tList[[n]]  <-   try(dtree[dtree$class02 == 
paste(data$class02[n]) & dtree$class04 == paste(data$class04[n]) & 
dtree$PREDICT==paste(data$PREDICT[n]),])")
tasign <-  parse(text=tasign)[[1]]
          
for(n in 1:nrow(data)) {
  TAsign <- do.call("substitute",list(tasign,list(n=n,X=as.name(n))))
  eval(TAsign)
}



From ripley at stats.ox.ac.uk  Tue May 18 10:31:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 May 2004 09:31:59 +0100 (BST)
Subject: [R] Build R-1.9.0 with static libraries ?
In-Reply-To: <40AA1922.9060003@imed.jussieu.fr>
Message-ID: <Pine.LNX.4.44.0405180928210.23184-100000@gannet.stats>

You make the changes to config.site, not Makeconf directly.  I think you 
want to alter

## The flags which are necessary for loading main program which will
## load DLLs at runtime.  HP-UX and Linux-elf are examples of platforms
## which use this.  These platforms are already taken care of by
## configure, and anything set here will be in addition unless MAIN_LD
## is given.
## For example, one can set flags for profiling here.
## MAIN_LDFLAGS=

My guess is that you want -Bstatic.

On Tue, 18 May 2004, M??lanie PELEGRINI-ISSAC wrote:

> Dear all,
> 
> Which options should I use when running the configure script
>             and/or
> which changes should I make to Makeconf
> to build the binary for R-1.9.0 but using only statically linked libraries ?
> 
> I need to build a binary that is portable between several different 
> Linux (RedHat) distributions.
> 
> Thanks in advance for your help,
> 
> Melanie
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From danbebber at forestecology.co.uk  Tue May 18 10:36:28 2004
From: danbebber at forestecology.co.uk (Dan Bebber)
Date: Tue, 18 May 2004 09:36:28 +0100
Subject: [R] Circular statistics with (direction,size) data
Message-ID: <000901c43cb3$36d41de0$442501a3@plants.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040518/ee39ed68/attachment.pl

From H.Andersson at nioo.knaw.nl  Tue May 18 11:59:47 2004
From: H.Andersson at nioo.knaw.nl (Andersson, Henrik)
Date: Tue, 18 May 2004 11:59:47 +0200
Subject: [R] Isotopic notation in plots
Message-ID: <65F6E1EC64DCA6489800C09A2007FC6E1817B4@cememail1.nioo.int>

I really like to use R for all my graphs, and as I work with stable
isotopes I want to have a proper chemical notation in my plots

I have looked at ?plotmath, but didn't find the answer and also searched
the R website.
------------------------------------------------------------------------
--

plot(1:10,xlab=expression(^{14}*C))  # I want to have a superscript with
nothing in front, but it doesn't work 

plot(1:10,xlab=expresssion(.^{14}*C))  # this works, but is not
beautiful

Any ideas ?


-------------------------------------------------------------
Henrik Andersson
Netherlands Institute of Ecology -
Centre for Estuarine and Marine Ecology
P.O. Box 140
4400 AC Yerseke
Phone: +31 113 577473
h.andersson at nioo.knaw.nl
http://www.nioo.knaw.nl/ppages/handersson



From Rau at demogr.mpg.de  Tue May 18 12:22:23 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Tue, 18 May 2004 12:22:23 +0200
Subject: [R] Isotopic notation in plots
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A09AC@hermes.demogr.mpg.de>

Hi!

> -----Original Message-----
> From:	Andersson, Henrik [SMTP:H.Andersson at nioo.knaw.nl]
> Sent:	Tuesday, May 18, 2004 12:00 PM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] Isotopic notation in plots
> 
> plot(1:10,xlab=expresssion(.^{14}*C))  # this works, but is not
> 
	I wonder how this works.... Isn't there one 's' too much in the
expresssion? ;-)
	Anyway: you want to have the notation without the dot?
	Why not try:
	plot(1:10,xlab=expression({ }^{14}*C))

	Hope this is what you wanted...or what did you mean by saying "not
beautiful"?

	Best,
	Roland





+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From cdeclercq at nordnet.fr  Tue May 18 12:26:37 2004
From: cdeclercq at nordnet.fr (Christophe Declercq)
Date: Tue, 18 May 2004 12:26:37 +0200
Subject: [R] Isotopic notation in plots
In-Reply-To: <65F6E1EC64DCA6489800C09A2007FC6E1817B4@cememail1.nioo.int>
Message-ID: <MJELLLFFFCNHMHOOLCMBMEFLCGAA.cdeclercq@nordnet.fr>

Try:

> plot(1:10,xlab=expression(phantom(0)^{14}*C))

Christophe
--
Christophe Declercq, MD
Observatoire regional de la sante Nord-Pas-de-Calais
13, rue Faidherbe
F-59046 LILLE Cedex
Phone 33 3 20 15 49 24
Fax 33 3 20 55 92 30
E-mail c.declercq at orsnpdc.org
 


> -----Message d'origine-----
> De : r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]De la part de Andersson, Henrik
> Envoye : mardi 18 mai 2004 11:00
> A : r-help at stat.math.ethz.ch
> Objet : [R] Isotopic notation in plots
> 
> 
> I really like to use R for all my graphs, and as I work with stable
> isotopes I want to have a proper chemical notation in my plots
> 
> I have looked at ?plotmath, but didn't find the answer and also searched
> the R website.
> ------------------------------------------------------------------------
> --
> 
> plot(1:10,xlab=expression(^{14}*C))  # I want to have a superscript with
> nothing in front, but it doesn't work 
> 
> plot(1:10,xlab=expresssion(.^{14}*C))  # this works, but is not
> beautiful
> 
> Any ideas ?
> 
> 
> -------------------------------------------------------------
> Henrik Andersson
> Netherlands Institute of Ecology -
> Centre for Estuarine and Marine Ecology
> P.O. Box 140
> 4400 AC Yerseke
> Phone: +31 113 577473
> h.andersson at nioo.knaw.nl
> http://www.nioo.knaw.nl/ppages/handersson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From etauber at eudoramail.com  Tue May 18 12:59:07 2004
From: etauber at eudoramail.com (Eran Tauber)
Date: Tue, 18 May 2004 10:59:07  0000
Subject: [R] 1-way anova, nested model
Message-ID: <OFFENHBNCCHDNBAA@whowhere.com>

Dear all,

We compared the gene expression level in two conditions: high (H) and low (L), using real-time PCR. We had 3 samples of each condition, and we quantified each sample twice (i.e. a technical replication). 
Our data looks like: 
H1 H1 H2 H2 H3 H3 L1 L1 L2 L2 L3 L3

We want to test if the level in H vs L is significantly different. I would like to use ANOVA  and I guess a nested model with the samples as random  variables should be used. How do you do it with R? (assume we don't have much experience with R, nor with statistics) 


Thanks in advance, Eran
 



Need a new email address that people can remember
Check out the new EudoraMail at
http://www.eudoramail.com



From HankeA at mar.dfo-mpo.gc.ca  Tue May 18 13:27:01 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Tue, 18 May 2004 08:27:01 -0300
Subject: [R] Isotopic notation in plots
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE1249A2@msgmarsta01.bio.dfo.ca>

Henrik, Please try:
plot(1:10,xlab=expression({}^{14}*C))

-----Original Message-----
From: Andersson, Henrik [mailto:H.Andersson at nioo.knaw.nl] 
Sent: May 18, 2004 7:00 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Isotopic notation in plots


I really like to use R for all my graphs, and as I work with stable
isotopes I want to have a proper chemical notation in my plots

I have looked at ?plotmath, but didn't find the answer and also searched
the R website.
------------------------------------------------------------------------
--

plot(1:10,xlab=expression(^{14}*C))  # I want to have a superscript with
nothing in front, but it doesn't work 

plot(1:10,xlab=expresssion(.^{14}*C))  # this works, but is not
beautiful

Any ideas ?


-------------------------------------------------------------
Henrik Andersson
Netherlands Institute of Ecology -
Centre for Estuarine and Marine Ecology
P.O. Box 140
4400 AC Yerseke
Phone: +31 113 577473
h.andersson at nioo.knaw.nl
http://www.nioo.knaw.nl/ppages/handersson

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From clists at perrin.socsci.unc.edu  Tue May 18 13:41:44 2004
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Tue, 18 May 2004 07:41:44 -0400 (EDT)
Subject: [R] Re: "ghost" image in .eps file
Message-ID: <Pine.LNX.4.53.0405180736010.17335@perrin.socsci.unc.edu>

Brian Ripley wrote:
>I can't see this in your examples: which viewer did you use?  I do see it
>in phantom.ps.
>
>However, looking at resources.bygt.eps, the file is corrupt with a load
>of bytes after
>
>%%EOF
>
>starting with nulls and then some postscript.  So I don't think this is an
>R problem but an OS problem.  (Please see the posting guide about required
>background info!) An intelligent viewer will stop at the %%EOF comment.
>

Sorry - environment is debian/testing linux. Viewer is ghostscript's gv
viewer.

>Please try deleting the file resources.bygt.eps, starting a new R session
>and repeating the plot call.

That seems to ahve worked - sorry to bother you.

ap

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu



From ggrothendieck at myway.com  Tue May 18 14:14:26 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 18 May 2004 12:14:26 +0000 (UTC)
Subject: [R] How do you force runif to return non-duplicate results
	=?utf-8?b?ZWcJcnVuaWYoMCw=?= 1, n=10)? thanks
References: <3B5823541A25D311B3B90008C7F9056410E35500@ntmsg0092.corpmail.telstra.com.au>
Message-ID: <loom.20040518T140430-692@post.gmane.org>

Briggs, Meredith M <Meredith.Briggs <at> team.telstra.com> writes:

How do you force runif to return non-duplicate results 
eg	runif(0, 1, n=10)? thanks

On my Windows XP machine I find that the first 100,000 random numbers
starting from seed 11 are unique even to machine precision. Is that enough?

R> set.seed(11); length(unique(runif(100000)))
[1] 100000

If you need 100 numbers that are unique to two decimal places, say, 
you can do this:

(sample(100, 100, rep=F)-1)/100



From Ted.Harding at nessie.mcc.ac.uk  Tue May 18 14:24:47 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 18 May 2004 13:24:47 +0100 (BST)
Subject: [R] Isotopic notation in plots
In-Reply-To: <65F6E1EC64DCA6489800C09A2007FC6E1817B4@cememail1.nioo.int>
Message-ID: <XFMail.040518112740.Ted.Harding@nessie.mcc.ac.uk>

On 18-May-04 Andersson, Henrik wrote:
> plot(1:10,xlab=expression(^{14}*C))  # I want to have a superscript
> with
> nothing in front, but it doesn't work 
> 
> plot(1:10,xlab=expresssion(.^{14}*C))   # this works, but is not
> beautiful

Try:

  plot(1:10,xlab=expresssion(""^{14}*C))

??

Ted.



From hjjin at pearl.cs.pusan.ac.kr  Tue May 18 14:50:43 2004
From: hjjin at pearl.cs.pusan.ac.kr (=?ks_c_5601-1987?B?wfjI8cGk?=)
Date: Tue, 18 May 2004 21:50:43 +0900
Subject: [R] Help : trellis.device
Message-ID: <200405181249.i4ICnjt204516@jade.cs.pusan.ac.kr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040518/1cb6229e/attachment.pl

From jasont at indigoindustrial.co.nz  Wed May 19 15:03:24 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 19 May 2004 01:03:24 -1200 (NZST)
Subject: [R] Help : trellis.device
In-Reply-To: <200405181249.i4ICnjt204516@jade.cs.pusan.ac.kr>
References: <200405181249.i4ICnjt204516@jade.cs.pusan.ac.kr>
Message-ID: <26686.203.9.176.60.1084885404.squirrel@webmail.maxnet.co.nz>

> Hi, R members.
>
> I want to save plots. So I use the R as fallows :
> --------------------------------
> a <- c(1,10)
> b <- c(1,10)
> c <- c(2,20)
> d <- c(2,20)
> require(lattice)
> trellis.device("bmp", file = "test.bmp", bg = "white")
> print(plot(a,b))
> print(plot(c,d))
> dev.off()
> --------------------------------
>
> However, I got a image of plot(c,d).
> I want to get a image of plot(a,b) and plot(c,d).

What happens when you type the above without "trellis.device(...)" and
"dev.off()".  Does that look like the plot you wrote to file?

R is one of those funny software tools that does what you tell it.

1) "plot()" isn't a lattice function, so using the function "bmp(file =
"test.bmp", bg = "white")" instead of "trellis.device()" is safer.

2) you haven't told R that you want two plots on one page, nor how you
want to arrange them.  See ?layout and ?par.  On the par help page, pay
careful attention to the mfcol and mfrow arguments.

3) type "help.start()", and follow the link to "An Introduction to R",
particularly the graphics section.

Then play with this.

par(mfcol=c(2,1))

plot(a,b)
plot(c,d)

Have fun!

Jason



From ccleland at optonline.net  Tue May 18 15:05:16 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 18 May 2004 09:05:16 -0400
Subject: [R] Help : trellis.device
In-Reply-To: <200405181249.i4ICnjt204516@jade.cs.pusan.ac.kr>
References: <200405181249.i4ICnjt204516@jade.cs.pusan.ac.kr>
Message-ID: <40AA0A0C.4090507@optonline.net>

   If you want to save both figures in the same file and if PDF is 
acceptable, try this:

a <- c(1,10)
b <- c(1,10)
c <- c(2,20)
d <- c(2,20)
library(lattice) # require is design for use inside functions

pdf("test.pdf")
trellis.device(new = FALSE, col = TRUE, bg = "white")
plot(a,b)
plot(c,d)
dev.off()

hope this helps,

Chuck

??? wrote:
> I want to save plots. So I use the R as fallows :
> --------------------------------
> a <- c(1,10)
> b <- c(1,10)
> c <- c(2,20)
> d <- c(2,20)
> require(lattice)
> trellis.device("bmp", file = "test.bmp", bg = "white")
> print(plot(a,b))
> print(plot(c,d))
> dev.off()
> --------------------------------
>  
> However, I got a image of plot(c,d).
> I want to get a image of plot(a,b) and plot(c,d).
>  
> Can anyone suggest a solution?

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From r.knell at qmul.ac.uk  Tue May 18 15:48:25 2004
From: r.knell at qmul.ac.uk (Rob Knell)
Date: Tue, 18 May 2004 14:48:25 +0100
Subject: [R] mixed models
Message-ID: <0948BFB6-A8D2-11D8-9DB7-0003937D2D6A@qmul.ac.uk>

Hi folks

Can anyone direct me to a guide to analysing mixed models in R that is 
understandable by mere mortals (or worse, mere biologists)? I have read 
MASS and also Mick Crawley's book on the subject, have thrashed my way 
through the various help files from the NLME package and I'm afraid I 
remain baffled :-(. Particularly confusing is exactly what groupedData 
does, how I should use it to define the structure of my dataset and how 
I then use that to define a model in LME. So pretty much everything 
then.

Thanks for any help

Rob Knell



From evelina at artax.karlin.mff.cuni.cz  Tue May 18 15:49:06 2004
From: evelina at artax.karlin.mff.cuni.cz (Eva Gelnarova)
Date: Tue, 18 May 2004 15:49:06 +0200
Subject: [R] Nonlinear robust regression
Message-ID: <20040518134906.GA17879@artax.karlin.mff.cuni.cz>

Hello,
 I would like to make a nonlinar fit (exactly the exponencial fit)
 to the data. But my data set is not
 ideal at all, so any robust method (such as LTS) would be bettre then
 LS. Could you advice me, please, if there is any R package or R function 
 which provides the nonlinear robust regression? 
 Thank you 
 Eva Gelnarova



From sdhyok at email.unc.edu  Tue May 18 16:14:56 2004
From: sdhyok at email.unc.edu (Shin, Daehyok)
Date: Tue, 18 May 2004 10:14:56 -0400
Subject: [R] How to define a destructor of an object?
Message-ID: <OAEOKPIGCLDDHAEMCAKIKEACCNAA.sdhyok@email.unc.edu>

Is there any way to define a destructor method of an object,
which is called automatically when garbage collector reclaims it?

Daehyok Shin



From jasont at indigoindustrial.co.nz  Wed May 19 16:19:23 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 19 May 2004 02:19:23 -1200 (NZST)
Subject: [R] mixed models
In-Reply-To: <0948BFB6-A8D2-11D8-9DB7-0003937D2D6A@qmul.ac.uk>
References: <0948BFB6-A8D2-11D8-9DB7-0003937D2D6A@qmul.ac.uk>
Message-ID: <29709.203.9.176.60.1084889963.squirrel@webmail.maxnet.co.nz>

> Hi folks
>
> Can anyone direct me to a guide to analysing mixed models in R that is
> understandable by mere mortals (or worse, mere biologists)? I have read
> MASS and also Mick Crawley's book on the subject, have thrashed my way
> through the various help files from the NLME package and I'm afraid I
> remain baffled :-(. Particularly confusing is exactly what groupedData
> does, how I should use it to define the structure of my dataset and how
> I then use that to define a model in LME. So pretty much everything
> then.

The canonical reference is "Mixed Effects Models in S and S-PLUS", by
Pinhero and Bates, and it is thorough and readable.  As a secondary source
to get you started while you find the first, the S-PLUS statistical manual
has a pretty good chapter on it (including a demo of groupedData).

http://www.insightful.com/support/splus60unix/statman1.pdf

See chapter 14.

Cheers

Jason



From v.demartino2 at virgilio.it  Tue May 18 16:19:32 2004
From: v.demartino2 at virgilio.it (v.demartino2@virgilio.it)
Date: Tue, 18 May 2004 16:19:32 +0200
Subject: [R] Debian & R
Message-ID: <4087DF4500081EE2@ims3e.cp.tin.it>

I use linux debian testing for which the latest debianized version of R
is 1.8.1. Therefore I installed:

 r-base-core_1.8.1-0.cran.1_i386.deb 
 r-base-dev_1.8.1-0.cran.1_all.deb   
 r-base-html_1.8.1-0.cran.1_all.deb  
 r-base-latex_1.8.1-0.cran.1_all.deb
 r-base_1.8.1-0.cran.1_all.deb      
 r-doc-html_1.8.1-0.cran.1_all.deb  
 r-doc-info_1.8.1-0.cran.1_all.deb  
 r-doc-pdf_1.8.1-0.cran.1_all.deb   
 r-gnome_1.8.1-0.cran.1_i386.deb    
 r-mathlib_1.8.1-0.cran.1_i386.deb  
 r-recommended_1.8.1-0.cran.1_i386.deb 

Being impatient of moving to R v. 1.9.0 I would like to install and compile
R from the source code in the *.tgz file from CRAN.

My question is:

In so doing will  anything be missing with respect to the deb packages I've
mentioned?
(e.g. r-gnome? r-mathlab?)

 Ciao
Vittorio



From ozric at web.de  Tue May 18 16:22:30 2004
From: ozric at web.de (Christian Schulz)
Date: Tue, 18 May 2004 16:22:30 +0200
Subject: [R] delete duplicated from data.frame
Message-ID: <200405181622.31221.ozric@web.de>

Hi,

?unique
unique returns a vector, data frame or array like x * but with duplicate 
elements removed *

what i'm doing wrong delete duplicated rows with same MEMEBRNO.  

februar <-  dmsegment[unique(dmsegment$MEMBERNO),]

This reduce from 197.188 rows to 184.199  but duplicated MEMBERNO  didn't left 
all what a Primary Key setting in mysql me say and with a fix(februar) could 
recognize .

Courious why MEMEBRNO 4,5 ,6 and 11  are left !
dmsegment$MEMBERNO[1:10]
[1] 1  4  5  6  7  9  10  11  16  21

februar$MEMBERNO[1:10]
[1] 1  6  7  9  10  16  21  26  53  72 

Using unique with a single vector it works like i expect.


P.S.
i try -duplcated but get not better succes?

Many Thanks,
Christian



From tlumley at u.washington.edu  Tue May 18 16:28:37 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 18 May 2004 07:28:37 -0700 (PDT)
Subject: [R] How to define a destructor of an object?
In-Reply-To: <OAEOKPIGCLDDHAEMCAKIKEACCNAA.sdhyok@email.unc.edu>
References: <OAEOKPIGCLDDHAEMCAKIKEACCNAA.sdhyok@email.unc.edu>
Message-ID: <Pine.A41.4.58.0405180726210.163418@homer36.u.washington.edu>

On Tue, 18 May 2004, Shin, Daehyok wrote:

> Is there any way to define a destructor method of an object,
> which is called automatically when garbage collector reclaims it?
>

yes, there is support for finalizers at both the C and R levels. For the R
level see ?reg.finalizer. I thought there was documentation for the C
stuff on developer.r-project.org, but I can't see it now.

	-thomas



From rbaer at atsu.edu  Tue May 18 16:32:30 2004
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Tue, 18 May 2004 09:32:30 -0500
Subject: [R] Isotopic notation in plots
References: <MJELLLFFFCNHMHOOLCMBMEFLCGAA.cdeclercq@nordnet.fr>
Message-ID: <003601c43ce4$f330fae0$2e80010a@BigBaer>

From: "Christophe Declercq" <cdeclercq at nordnet.fr>
> Try:
>
> > plot(1:10,xlab=expression(phantom(0)^{14}*C))

Just out of interest, how do I find out what phantom(0) does?  I tried both
?phantom and help.search("phantom") without getting any hits, and yet the
expression posed above creates a leading blank space in the axis label.  I
take the latter to mean that phantom() is available withinin the basic
packages (search path).

Where do I read more?

Thanks,
Rob



From ligges at statistik.uni-dortmund.de  Tue May 18 16:37:28 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 18 May 2004 16:37:28 +0200
Subject: [R] Isotopic notation in plots
In-Reply-To: <003601c43ce4$f330fae0$2e80010a@BigBaer>
References: <MJELLLFFFCNHMHOOLCMBMEFLCGAA.cdeclercq@nordnet.fr>
	<003601c43ce4$f330fae0$2e80010a@BigBaer>
Message-ID: <40AA1FA8.2090401@statistik.uni-dortmund.de>

Robert W. Baer, Ph.D. wrote:

> From: "Christophe Declercq" <cdeclercq at nordnet.fr>
> 
>>Try:
>>
>>
>>>plot(1:10,xlab=expression(phantom(0)^{14}*C))
> 
> 
> Just out of interest, how do I find out what phantom(0) does?  I tried both
> ?phantom and help.search("phantom") without getting any hits, and yet the
> expression posed above creates a leading blank space in the axis label.  I
> take the latter to mean that phantom() is available withinin the basic
> packages (search path).
> 
> Where do I read more?

?plotmath

Uwe Ligges

> Thanks,
> Rob
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at PDF.COM  Tue May 18 16:38:11 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 18 May 2004 07:38:11 -0700
Subject: [R] delete duplicated from data.frame
In-Reply-To: <200405181622.31221.ozric@web.de>
References: <200405181622.31221.ozric@web.de>
Message-ID: <40AA1FD3.6030509@pdf.com>



Christian Schulz wrote:

> Hi,
> 
> ?unique
> unique returns a vector, data frame or array like x * but with duplicate 
> elements removed *
> 
> what i'm doing wrong delete duplicated rows with same MEMEBRNO.  
> 
> februar <-  dmsegment[unique(dmsegment$MEMBERNO),]
> 
> This reduce from 197.188 rows to 184.199  but duplicated MEMBERNO  didn't left 
> all what a Primary Key setting in mysql me say and with a fix(februar) could 
> recognize .
> 
> Courious why MEMEBRNO 4,5 ,6 and 11  are left !
> dmsegment$MEMBERNO[1:10]
> [1] 1  4  5  6  7  9  10  11  16  21
> 
> februar$MEMBERNO[1:10]
> [1] 1  6  7  9  10  16  21  26  53  72 
> 
> Using unique with a single vector it works like i expect.
> 
> 
> P.S.
> i try -duplcated but get not better succes?
> 
> Many Thanks,
> Christian

Hi,
   Did you try unique(dmsegment$MEMBERNO) to see what you get? Looks 
like you are expecting an index. But, as you pointed out unique returns 
a vector, data frame or array like x *but with duplicate  elements 
removed*, which means unique returns the non-duplicated elements of 
dmsegment$MEMBERNO. To accomplish what I think you are trying to do, try:

februar <-  dmsegment[!duplicated(dmsegment$MEMBERNO), ]

Of course, this is a guess and may not be what you really want.

--sundar



From sundar.dorai-raj at PDF.COM  Tue May 18 16:39:53 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 18 May 2004 07:39:53 -0700
Subject: [R] Isotopic notation in plots
In-Reply-To: <003601c43ce4$f330fae0$2e80010a@BigBaer>
References: <MJELLLFFFCNHMHOOLCMBMEFLCGAA.cdeclercq@nordnet.fr>
	<003601c43ce4$f330fae0$2e80010a@BigBaer>
Message-ID: <40AA2039.40702@pdf.com>



Robert W. Baer, Ph.D. wrote:

> From: "Christophe Declercq" <cdeclercq at nordnet.fr>
> 
>>Try:
>>
>>
>>>plot(1:10,xlab=expression(phantom(0)^{14}*C))
> 
> 
> Just out of interest, how do I find out what phantom(0) does?  I tried both
> ?phantom and help.search("phantom") without getting any hits, and yet the
> expression posed above creates a leading blank space in the axis label.  I
> take the latter to mean that phantom() is available withinin the basic
> packages (search path).
> 
> Where do I read more?
> 
> Thanks,
> Rob
> 

See ?plotmath.

  *Syntax*                     *Meaning*
  'x + phantom(0) + y'         leave gap for "0", but don't draw it

--sundar



From ligges at statistik.uni-dortmund.de  Tue May 18 16:39:59 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 18 May 2004 16:39:59 +0200
Subject: [R] delete duplicated from data.frame
In-Reply-To: <200405181622.31221.ozric@web.de>
References: <200405181622.31221.ozric@web.de>
Message-ID: <40AA203F.6070904@statistik.uni-dortmund.de>

Christian Schulz wrote:

> Hi,
> 
> ?unique
> unique returns a vector, data frame or array like x * but with duplicate 
> elements removed *
> 
> what i'm doing wrong delete duplicated rows with same MEMEBRNO.  
> 
> februar <-  dmsegment[unique(dmsegment$MEMBERNO),]

unique() returns values, but not indices nor logicl values.
Try instead:

februar <-  dmsegment[!duplicated(dmsegment$MEMBERNO),]

Uwe Ligges

> This reduce from 197.188 rows to 184.199  but duplicated MEMBERNO  didn't left 
> all what a Primary Key setting in mysql me say and with a fix(februar) could 
> recognize .
> 
> Courious why MEMEBRNO 4,5 ,6 and 11  are left !
> dmsegment$MEMBERNO[1:10]
> [1] 1  4  5  6  7  9  10  11  16  21
> 
> februar$MEMBERNO[1:10]
> [1] 1  6  7  9  10  16  21  26  53  72 
> 
> Using unique with a single vector it works like i expect.
> 
> 
> P.S.
> i try -duplcated but get not better succes?
> 
> Many Thanks,
> Christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rkoenker at uiuc.edu  Tue May 18 16:45:01 2004
From: rkoenker at uiuc.edu (roger koenker)
Date: Tue, 18 May 2004 09:45:01 -0500
Subject: [R] Nonlinear robust regression
In-Reply-To: <20040518134906.GA17879@artax.karlin.mff.cuni.cz>
References: <20040518134906.GA17879@artax.karlin.mff.cuni.cz>
Message-ID: <F1681D8A-A8D9-11D8-9A45-000A95A7E3AA@uiuc.edu>

The package nlrq does nonlinear l1 regression.  This isn't robust in the
design directions, but is in the response direction.

url:	www.econ.uiuc.edu/~roger        	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On May 18, 2004, at 8:49 AM, Eva Gelnarova wrote:

> Hello,
>  I would like to make a nonlinar fit (exactly the exponencial fit)
>  to the data. But my data set is not
>  ideal at all, so any robust method (such as LTS) would be bettre then
>  LS. Could you advice me, please, if there is any R package or R 
> function
>  which provides the nonlinear robust regression?
>  Thank you
>  Eva Gelnarova
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From B.Rowlingson at lancaster.ac.uk  Tue May 18 16:46:04 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 18 May 2004 15:46:04 +0100
Subject: [R] Isotopic notation in plots
In-Reply-To: <XFMail.040518112740.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.040518112740.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <40AA21AC.3000208@lancaster.ac.uk>


> Try:
> 
>   plot(1:10,xlab=expresssion(""^{14}*C))
> 
> ??

Is there a way of showing atomic number and atomic mass next to the symbol?

This:
plot(1:10,xlab=expression({}[7]^{14}*C))

almost works, but the 7 is adjacent to the invisible {}, instead of 
being right-aligned next to the C.

Slightly closer is:
plot(1:10,xlab=expression(scriptstyle(atop(7,14))*C))

but the 7 and 14 are centre-aligned.

Padding the 7 out with a phantom 0 looks okay though:

expression({}[phantom(0)*7]^{14}*C))

Apologies to chemists if I've got my atomic number and atomic mass the 
wrong way up.

Barry



From ozric at web.de  Tue May 18 16:51:24 2004
From: ozric at web.de (Christian Schulz)
Date: Tue, 18 May 2004 16:51:24 +0200
Subject: [R] delete duplicated from data.frame
In-Reply-To: <40AA203F.6070904@statistik.uni-dortmund.de>
References: <200405181622.31221.ozric@web.de>
	<40AA203F.6070904@statistik.uni-dortmund.de>
Message-ID: <200405181651.24489.ozric@web.de>

Uwe and Sundar,

many thanks  and sorry for my confusion with indexes,values etc..
christian


Am Dienstag, 18. Mai 2004 16:39 schrieb Uwe Ligges:
> Christian Schulz wrote:
> > Hi,
> >
> > ?unique
> > unique returns a vector, data frame or array like x * but with duplicate
> > elements removed *
> >
> > what i'm doing wrong delete duplicated rows with same MEMEBRNO.
> >
> > februar <-  dmsegment[unique(dmsegment$MEMBERNO),]
>
> unique() returns values, but not indices nor logicl values.
> Try instead:
>
> februar <-  dmsegment[!duplicated(dmsegment$MEMBERNO),]
>
> Uwe Ligges
>
> > This reduce from 197.188 rows to 184.199  but duplicated MEMBERNO  didn't
> > left all what a Primary Key setting in mysql me say and with a
> > fix(februar) could recognize .
> >
> > Courious why MEMEBRNO 4,5 ,6 and 11  are left !
> > dmsegment$MEMBERNO[1:10]
> > [1] 1  4  5  6  7  9  10  11  16  21
> >
> > februar$MEMBERNO[1:10]
> > [1] 1  6  7  9  10  16  21  26  53  72
> >
> > Using unique with a single vector it works like i expect.
> >
> >
> > P.S.
> > i try -duplcated but get not better succes?
> >
> > Many Thanks,
> > Christian
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Tue May 18 17:18:33 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 18 May 2004 08:18:33 -0700
Subject: [R] list & calculaton in many df subsets
In-Reply-To: <200405181018.13509.ozric@web.de>
References: <200405181018.13509.ozric@web.de>
Message-ID: <40AA2949.8090202@pdf.com>

Have you considered "lapply(by(...), ...)"?  The help for "by" includes 
an example using sapply.  See also Venables and Ripley, Modern Applied 
Statistics with S. 

hope this helps.  spencer graves

Christian Schulz wrote:

>Hi,
>
>have anybody a hint /starting point how i can 
>enlarge my code that's posiible for me make any  calculaton's
>with variables in the  64 subset's.
>
>Example: 
>I want calculate difference of two variables inside every
>of the 64 subset data.frames  and getting this value in tList!
>
>Many thanks,
>Christian
>
>
>tasign <- paste("tList[[n]]  <-   try(dtree[dtree$class02 == 
>paste(data$class02[n]) & dtree$class04 == paste(data$class04[n]) & 
>dtree$PREDICT==paste(data$PREDICT[n]),])")
>tasign <-  parse(text=tasign)[[1]]
>          
>for(n in 1:nrow(data)) {
>  TAsign <- do.call("substitute",list(tasign,list(n=n,X=as.name(n))))
>  eval(TAsign)
>}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From abderrahim.oulhaj at pharmacology.oxford.ac.uk  Tue May 18 17:24:54 2004
From: abderrahim.oulhaj at pharmacology.oxford.ac.uk (Abderrahim Oulhaj)
Date: Tue, 18 May 2004 16:24:54 +0100
Subject: [R] nlme: Initial parameter estimates
Message-ID: <00bb01c43cec$4529eb20$40ca01a3@optima.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040518/27687176/attachment.pl

From nlwhitehouse at yahoo.com  Tue May 18 17:41:03 2004
From: nlwhitehouse at yahoo.com (Nathan Whitehouse)
Date: Tue, 18 May 2004 08:41:03 -0700 (PDT)
Subject: [R] Problem with package SJava
Message-ID: <20040518154103.84523.qmail@web12405.mail.yahoo.com>

Hi,

  This main method on class Essai will fail at least
for one reason becaue you need to instantiate a
ROmegahatInterpreter.
  
  Referencing this causes the R DLLs & the SJava DLLs
to load.  
   However, it appears that they are already loaded,
judging from your output below based on the signal
11/Page fault error.

  Try adding it and seeing if it works.  Can you get
it to work under linux?

  About the java compilation issue:
  
  you need to have the following jars in your
CLASSPATH

    $SJAVA_HOME/org/omegahat/Jars/jas.jar
    $SJAVA_HOME/org/omegahat/Jars/antlr.jar
    $SJAVA_HOME/org/omegahat/Jars/Environment.jar

  This might cause the compilation issue.

  Hope that is a little help.  If you still have
problems, hopefully we can figure them out.

  Nathan

Hello all,
I'm trying to run SJava package (0.65 modified
downloaded from : 
http://stats.math.uni-augsburg.de/iPlots/alpha/) on
windows NT 2000 and 
R 
1.8.01. I have also downloaded the PDF Calling R from
Java and when I 
want 
to execute the following code:
import org.omegahat.R.Java.*;
import java.io.*;
public class Essai{
	public static void main (String [] args) {
		REvaluator e = new REvaluator();
		Object val = e.eval("objects()");
		if (val!= null)  {
			String[] objects = (String[]) val;
			for (int i = 0; i< objects.length; i++) {
				System.out.println("("+i+") " + objects[i]);
			}
		}
	}
}
I have in return:


An unexpected exception has been detected in native
code outside the 
VM.
Unexpected Signal : EXCEPTION_ACCESS_VIOLATION
(0xc0000005) occurred at 
PC=0x6B4B85E3
Function=R_SetMaxNSize+0xC3
Library=c:\Program Files\R\rw1081\bin\R.dll

Current Java thread:
	at org.omegahat.R.Java.REvaluator.eval(Native Method)
	at
org.omegahat.R.Java.REvaluator.eval(REvaluator.java:86)
	at
org.omegahat.R.Java.REvaluator.eval(REvaluator.java:36)
	at Toto.main(Toto.java:22)

Dynamic libraries:
0x00400000 - 0x00406000 	C:\j2sdk1.4.2_03\bin\java.exe
0x78460000 - 0x784E3000 	C:\WINNT\system32\ntdll.dll
0x78ED0000 - 0x78F32000 
C:\WINNT\system32\ADVAPI32.dll
0x77E70000 - 0x77F33000 
C:\WINNT\system32\KERNEL32.DLL
0x770C0000 - 0x77131000 	C:\WINNT\system32\RPCRT4.DLL
0x78000000 - 0x78045000 	C:\WINNT\system32\MSVCRT.dll
0x08000000 - 0x08138000 
C:\j2sdk1.4.2_03\jre\bin\client\jvm.dll
0x77E00000 - 0x77E65000 	C:\WINNT\system32\USER32.dll
0x77F40000 - 0x77F7E000 	C:\WINNT\system32\GDI32.DLL
0x77540000 - 0x77571000 	C:\WINNT\system32\WINMM.dll
0x10000000 - 0x10007000 
C:\j2sdk1.4.2_03\jre\bin\hpi.dll
0x007C0000 - 0x007CE000 
C:\j2sdk1.4.2_03\jre\bin\verify.dll
0x007D0000 - 0x007E9000 
C:\j2sdk1.4.2_03\jre\bin\java.dll
0x007F0000 - 0x007FD000 
C:\j2sdk1.4.2_03\jre\bin\zip.dll
0x18270000 - 0x18287000 	C:\Program 
Files\R\rw1081\library\SJava\libs\SJava.dll
0x6B400000 - 0x6B61B000 	c:\Program
Files\R\rw1081\bin\R.dll
0x68180000 - 0x6819F000 	c:\Program
Files\R\rw1081\bin\Rblas.dll
0x77B40000 - 0x77BC9000 
C:\WINNT\system32\COMCTL32.DLL
0x76B00000 - 0x76B3E000 
C:\WINNT\system32\COMDLG32.DLL
0x63180000 - 0x631C8000 	C:\WINNT\system32\SHLWAPI.DLL
0x77580000 - 0x777CF000 	C:\WINNT\system32\SHELL32.DLL
0x77810000 - 0x77817000 	C:\WINNT\system32\VERSION.dll
0x75950000 - 0x75956000 	C:\WINNT\system32\LZ32.DLL
0x77910000 - 0x77933000 
C:\WINNT\system32\imagehlp.dll
0x72970000 - 0x7299D000 	C:\WINNT\system32\DBGHELP.dll
0x68EA0000 - 0x68EAB000 	C:\WINNT\system32\PSAPI.DLL

Heap at VM Abort:
Heap
  def new generation   total 576K, used 227K
[0x10010000, 0x100b0000, 
0x104f0000)
   eden space 512K,  44% used [0x10010000, 0x10048f68,
0x10090000)
   from space 64K,   0% used [0x10090000, 0x10090000,
0x100a0000)
   to   space 64K,   0% used [0x100a0000, 0x100a0000,
0x100b0000)
  tenured generation   total 1408K, used 0K
[0x104f0000, 0x10650000, 
0x14010000)
    the space 1408K,   0% used [0x104f0000,
0x104f0000, 0x104f0200, 
0x10650000)
  compacting perm gen  total 4096K, used 1039K
[0x14010000, 0x14410000, 
0x18010000)
    the space 4096K,  25% used [0x14010000,
0x14113de0, 0x14113e00, 
0x14410000)

Local Time = Mon May 17 09:22:41 2004
Elapsed Time = 17
#
# The exception above was detected in native code
outside the VM
#
# Java VM: Java HotSpot(TM) Client VM (1.4.2_03-b02
mixed mode)
#

I try to recompile the native interfaces and I think
that some files or 
directories are missing like:
antlr\commonAST.class
jas.classEnv

I don't know what I should do so I hope that anybody
could help me.
thanks,
Regards

Vincent

=====
Nathan Whitehouse
Statistics/Programming
Baylor College of Medicine
Houston, TX, USA
nlwhitehouse at yahoo.com
work: 1-713-798-9029
cell:    1-512-293-5840

http://rho-project.org: rho- open source web services for R.
http://franklin.imgen.bcm.tmc.edu: Shaw laboratory, bcm.



From ripley at stats.ox.ac.uk  Tue May 18 19:00:40 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 May 2004 18:00:40 +0100 (BST)
Subject: [R] Isotopic notation in plots
In-Reply-To: <003601c43ce4$f330fae0$2e80010a@BigBaer>
Message-ID: <Pine.LNX.4.44.0405181759210.23643-100000@gannet.stats>

On Tue, 18 May 2004, Robert W. Baer, Ph.D. wrote:

> From: "Christophe Declercq" <cdeclercq at nordnet.fr>
> > Try:
> >
> > > plot(1:10,xlab=expression(phantom(0)^{14}*C))
> 
> Just out of interest, how do I find out what phantom(0) does?  I tried both
> ?phantom and help.search("phantom") without getting any hits, and yet the
> expression posed above creates a leading blank space in the axis label.  I
> take the latter to mean that phantom() is available withinin the basic
> packages (search path).

No, as it is part of plotmath syntax, not an R function.

> Where do I read more?

library(graphics)
?plotmath
demo(plotmath)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From phgrosjean at sciviews.org  Tue May 18 19:21:49 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 18 May 2004 19:21:49 +0200
Subject: [R] SciViews-R, a GUI layer and companion applications for R
Message-ID: <MABBLJDICACNFOLGIHJOMECGEHAA.phgrosjean@sciviews.org>

Hello,
An alpha version (unstable, still in development) of SciViews-R can be
downloaded from http://www.sciviews.org/SciViews-R. See also screenshots at
http://www.sciviews.org/software/rconsole.htm.

The SciViews R package provides functions to implement GUI features (object
explorer, script with context-sensitive help and completion lists, ...) and
to ease the communication with external programs (export, copy, ...). Views
are HTML representations of R objects mixing text, nicely formatted tables
and graphs. A reporting feature allows to append views to a report as the
analysis is run, and to edit the resulting document. All these functions are
expandable and can be used as a starting point to implement GUIs on top of R
for various platforms.

SciViews-R is an additional component that provides such a GUI environment
for R, using functions in the package. It proposes an enhanced
console/script, a report editor, and a code editor. It runs under Windows
(only tested under Windows XP for the moment).

Finally, a slightly modified version of John Fox's R Commander
(http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/index.html) is made
compatible with this new environment.

Best Regards,

Philippe Grosjean
On behalf of the SciViews Team

.......................................................<??}))><....
 ) ) ) ) )
( ( ( ( (   Prof. Philippe Grosjean
\  ___   )
 \/ECO\ (   Numerical Ecology of Aquatic Systems
 /\___/  )  Mons-Hainaut University, Pentagone
/ ___  /(   8, Av. du Champ de Mars, 7000 Mons, Belgium
 /NUM\/  )
 \___/\ (   phone: + 32.65.37.34.97, fax: + 32.65.37.33.12
       \ )  email: Philippe.Grosjean at umh.ac.be
 ) ) ) ) )  SciViews project coordinator (http://www.sciviews.org)
( ( ( ( (
...................................................................



From sdhyok at catchlab.org  Tue May 18 19:31:56 2004
From: sdhyok at catchlab.org (Shin, Daehyok)
Date: Tue, 18 May 2004 13:31:56 -0400
Subject: [R] How to define a destructor of an object?
In-Reply-To: <Pine.A41.4.58.0405180726210.163418@homer36.u.washington.edu>
Message-ID: <OAEOKPIGCLDDHAEMCAKICEAICNAA.sdhyok@catchlab.org>

Thanks, Thomas. This is exactly what I want.
I am wondering why there is no explicit mention about this function,
such as, in the help document of gc().


Daehyok Shin (Peter)

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Thomas Lumley
> Sent: Tuesday, May 18, 2004 AM 10:29
> To: Shin, Daehyok
> Cc: R, Help
> Subject: Re: [R] How to define a destructor of an object?
>
>
> On Tue, 18 May 2004, Shin, Daehyok wrote:
>
> > Is there any way to define a destructor method of an object,
> > which is called automatically when garbage collector reclaims it?
> >
>
> yes, there is support for finalizers at both the C and R levels. For the R
> level see ?reg.finalizer. I thought there was documentation for the C
> stuff on developer.r-project.org, but I can't see it now.
>
> 	-thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From ajayshah at mayin.org  Tue May 18 21:02:32 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Wed, 19 May 2004 00:32:32 +0530
Subject: Windows versus Unix packages in CRAN (Was Re: [R] Rmetrics)
Message-ID: <40A8D1E4.7030308@itp.phys.ethz.ch>

> Rmetrics - New Version is available for R 1.9 !!

> in R-binary and R-source form from the site "http://www.rmetrics.org",
> and install the binary "zip" files in the usual way via the menu

I'm confused - does the fact that you are only distributing ".zip"
files means that (shudder) I need Microsoft Windows in order to run
this? (I hunted on the website but you seemed to only have .zip
files. That's very odd; normally on Unix we don't ship .zip files).

More generally: Do all R packages automatically run on Unix, or are we
fragmenting the CRAN code base into Unix and non-Unix packages? One of
my reasons for shifting to R was that it felt like a system that was
built by Unix people (roots in Bell Labs etc.). So it will have a
function like sink() as a nice counterpart to a function like source()
:-)

Ox, for example, has nice functionality but it felt like it was done
by Windows guys, so it wasn't going to be useful to me, and I kept
away.

If R packages are actually in two (intersecting) sets : those that run
on Unix and those that run on Windows, then do we need a CRAN/Unix and
CRAN/M$ directories to distinguish them? It will avoid a lot of wasted
time... e.g. I blew half an hour on investigating Rmetrics before
deciding they're a Windows crowd.

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From ripley at stats.ox.ac.uk  Tue May 18 21:36:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 May 2004 20:36:38 +0100 (BST)
Subject: Windows versus Unix packages in CRAN (Was Re: [R] Rmetrics)
In-Reply-To: <40A8D1E4.7030308@itp.phys.ethz.ch>
Message-ID: <Pine.LNX.4.44.0405182016110.23888-100000@gannet.stats>

Note that Rmetrics is not on CRAN, so you have a false premise.

As far as I know only one CRAN package runs only on Windows, mimR, because 
mim only runs on Windows.  All the others run on some (suitably equipped)
Linux system.

Quite a few CRAN packages do not compile out of the box on Windows, and I
provide binaries for a few that need special attention.  A few more (e.g.  
RMySQL) really do need to be compiled against compatible versions of R and
something else (and David James does a sterling job tracking those).  I am
not aware of any that with enough effort could not be made to work under
Windows, but I have not in all cases made the effort (I did for a few
years ...).

On Wed, 19 May 2004, Ajay Shah wrote:

> > Rmetrics - New Version is available for R 1.9 !!

There is no such thing as R 1.9, of course.

> > in R-binary and R-source form from the site "http://www.rmetrics.org",
> > and install the binary "zip" files in the usual way via the menu
> 
> I'm confused - does the fact that you are only distributing ".zip"
> files means that (shudder) I need Microsoft Windows in order to run
> this? (I hunted on the website but you seemed to only have .zip
> files. That's very odd; normally on Unix we don't ship .zip files).

I was not aware that _you_ distributed any R packages -- could you give us
the details, please?  Shipping .zip files for sources is not uncommon in 
Open Source projects.

> More generally: Do all R packages automatically run on Unix, or are we
> fragmenting the CRAN code base into Unix and non-Unix packages? One of
> my reasons for shifting to R was that it felt like a system that was
> built by Unix people (roots in Bell Labs etc.). So it will have a
> function like sink() as a nice counterpart to a function like source()
> :-)
> 
> Ox, for example, has nice functionality but it felt like it was done
> by Windows guys, so it wasn't going to be useful to me, and I kept
> away.
> 
> If R packages are actually in two (intersecting) sets : those that run
> on Unix and those that run on Windows, then do we need a CRAN/Unix and
> CRAN/M$ directories to distinguish them? It will avoid a lot of wasted
> time... e.g. I blew half an hour on investigating Rmetrics before
> deciding they're a Windows crowd.

`Category error' as a biologist friend of mine says.

I think you are off target here, for I did

mkdir fBasics
unzip fBasics.zip -d fBasics
rm fBasics/src/*.o
R CMD check fBasics

and that took me about 3 minutes.  It would of course be nice if the 
developers had done

R CMD check fBasics
and sorted out the errors, then
R CMD build fBasics

but those errors are equally problematic on Unix or Windows.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jeaneid at chass.utoronto.ca  Tue May 18 22:05:07 2004
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Tue, 18 May 2004 16:05:07 -0400
Subject: [R] Debian & R
In-Reply-To: <4087DF4500081EE2@ims3e.cp.tin.it>
Message-ID: <Pine.SGI.4.40.0405181604480.16982818-100000@origin.chass.utoronto.ca>

I have done that with no problems...

Jean,

On Tue, 18 May 2004 v.demartino2 at virgilio.it wrote:

> I use linux debian testing for which the latest debianized version of R
> is 1.8.1. Therefore I installed:
>
>  r-base-core_1.8.1-0.cran.1_i386.deb
>  r-base-dev_1.8.1-0.cran.1_all.deb
>  r-base-html_1.8.1-0.cran.1_all.deb
>  r-base-latex_1.8.1-0.cran.1_all.deb
>  r-base_1.8.1-0.cran.1_all.deb
>  r-doc-html_1.8.1-0.cran.1_all.deb
>  r-doc-info_1.8.1-0.cran.1_all.deb
>  r-doc-pdf_1.8.1-0.cran.1_all.deb
>  r-gnome_1.8.1-0.cran.1_i386.deb
>  r-mathlib_1.8.1-0.cran.1_i386.deb
>  r-recommended_1.8.1-0.cran.1_i386.deb
>
> Being impatient of moving to R v. 1.9.0 I would like to install and compile
> R from the source code in the *.tgz file from CRAN.
>
> My question is:
>
> In so doing will  anything be missing with respect to the deb packages I've
> mentioned?
> (e.g. r-gnome? r-mathlab?)
>
>  Ciao
> Vittorio
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue May 18 21:38:30 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 May 2004 20:38:30 +0100 (BST)
Subject: [R] Help : trellis.device
In-Reply-To: <40AA0A0C.4090507@optonline.net>
Message-ID: <Pine.LNX.4.44.0405182036570.23888-100000@gannet.stats>

On Tue, 18 May 2004, Chuck Cleland wrote:

>    If you want to save both figures in the same file and if PDF is 
> acceptable, try this:

and if it is not, ?bmp will tell you how to specify the file= in a way 
that you will get 2 .bmp files.

> 
> a <- c(1,10)
> b <- c(1,10)
> c <- c(2,20)
> d <- c(2,20)
> library(lattice) # require is design for use inside functions
> 
> pdf("test.pdf")
> trellis.device(new = FALSE, col = TRUE, bg = "white")

# trellis.device is designed for lattice plots, so not needed here.

> plot(a,b)
> plot(c,d)
> dev.off()
> 
> hope this helps,
> 
> Chuck
> 
> ??? wrote:
> > I want to save plots. So I use the R as fallows :
> > --------------------------------
> > a <- c(1,10)
> > b <- c(1,10)
> > c <- c(2,20)
> > d <- c(2,20)
> > require(lattice)
> > trellis.device("bmp", file = "test.bmp", bg = "white")
> > print(plot(a,b))
> > print(plot(c,d))
> > dev.off()
> > --------------------------------
> >  
> > However, I got a image of plot(c,d).
> > I want to get a image of plot(a,b) and plot(c,d).
> >  
> > Can anyone suggest a solution?
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.connolly at hortresearch.co.nz  Wed May 19 00:10:30 2004
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Wed, 19 May 2004 10:10:30 +1200
Subject: [R] Using pointsize with postscript trellis.device
Message-ID: <20040519101030.Q2137@hortresearch.co.nz>

I've been accustomed to specifying a postscript file and pointsize
like so:

trellis.device(postscript, file = "something.ps", pointsize = 8)

Using version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    9.0              
year     2004             
month    04               
day      12               
language R     ,           

the pointsize does not seem to have any effect (i.e. the default
pointsize is still at 12).  I tried specifically setting pointsize as
a ps.option, but also to no avail.

The same idea works with regular plots and I'm sure I used to be able
to do this with previous versions with lattice plots also.

Have I overlooked something?

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From deepayan at stat.wisc.edu  Wed May 19 02:35:37 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 18 May 2004 19:35:37 -0500
Subject: [R] Using pointsize with postscript trellis.device
In-Reply-To: <20040519101030.Q2137@hortresearch.co.nz>
References: <20040519101030.Q2137@hortresearch.co.nz>
Message-ID: <200405181935.38254.deepayan@stat.wisc.edu>

On Tuesday 18 May 2004 17:10, Patrick Connolly wrote:
> I've been accustomed to specifying a postscript file and pointsize
> like so:
>
> trellis.device(postscript, file = "something.ps", pointsize = 8)
>
> Using version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    9.0
> year     2004
> month    04
> day      12
> language R     ,
>
> the pointsize does not seem to have any effect (i.e. the default
> pointsize is still at 12).  I tried specifically setting pointsize as
> a ps.option, but also to no avail.
>
> The same idea works with regular plots and I'm sure I used to be able
> to do this with previous versions with lattice plots also.

This is an issue which is still somewhat open. I know why this doesn't 
work, but I'm not sure if it's the best way to handle things and I'm 
open to suggestions.

The size of various grid components are controlled by the grid gpar 
`fontsize', which seems to default to the pointsize of the device (I'm 
not sure if this is documented). The problem is that while the default 
of 12 is OK for text, it seems too big for points. Also, it probably 
makes sense to have this as a lattice setting, and not a par() value 
(although this is debatable).

So, right now this is controlled by 
> trellis.par.get("fontsize")
$text
[1] 12

$points
[1] 8

which is supposed to be used for text and points respectively. In 
practice, the "text" component is only used as the default when setting 
up the main viewport, and the "points" component is used individually 
by any functions that draw points.

You could probably get what you want with something like

trellis.device(postscript, file = "something.ps", 
               theme = list(fontsize = 
               list(text = 8, points = 6)))

Deepayan



From r-stats at arcriswell.com  Wed May 19 03:11:29 2004
From: r-stats at arcriswell.com (Andrew Criswell)
Date: Wed, 19 May 2004 08:11:29 +0700
Subject: Windows versus Unix packages in CRAN (Was Re: [R] Rmetrics)
In-Reply-To: <40A8D1E4.7030308@itp.phys.ethz.ch>
References: <40A8D1E4.7030308@itp.phys.ethz.ch>
Message-ID: <40AAB441.205@arcriswell.com>

Yes, I agree with Ajay Shah's comments. The Rmetrics website makes a 
virtue of open source yet the Rmetrics people do not make available 
their package for the open source platform, Linux.

Ajay Shah wrote:

>>Rmetrics - New Version is available for R 1.9 !!
>>    
>>
>
>  
>
>>in R-binary and R-source form from the site "http://www.rmetrics.org",
>>and install the binary "zip" files in the usual way via the menu
>>    
>>
>
>I'm confused - does the fact that you are only distributing ".zip"
>files means that (shudder) I need Microsoft Windows in order to run
>this? (I hunted on the website but you seemed to only have .zip
>files. That's very odd; normally on Unix we don't ship .zip files).
>
>More generally: Do all R packages automatically run on Unix, or are we
>fragmenting the CRAN code base into Unix and non-Unix packages? One of
>my reasons for shifting to R was that it felt like a system that was
>built by Unix people (roots in Bell Labs etc.). So it will have a
>function like sink() as a nice counterpart to a function like source()
>:-)
>
>Ox, for example, has nice functionality but it felt like it was done
>by Windows guys, so it wasn't going to be useful to me, and I kept
>away.
>
>If R packages are actually in two (intersecting) sets : those that run
>on Unix and those that run on Windows, then do we need a CRAN/Unix and
>CRAN/M$ directories to distinguish them? It will avoid a lot of wasted
>time... e.g. I blew half an hour on investigating Rmetrics before
>deciding they're a Windows crowd.
>
>  
>



From gunter.berton at gene.com  Wed May 19 03:20:06 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 18 May 2004 18:20:06 -0700
Subject: [R] R Optimization 101 for R Newcomers: An extended example
Message-ID: <40AAB646.6196E5A2@gene.com>

To new R-Programmers:

This long-winded note gives an example of optimizing in R that should
only be of interest to newcomers to the language. Others should ignore.
My hope is that it might help illuminate some basic notions of code
improvement, looping, and vectorization in R. However, I welcome
comments from anyone that enlarge, correct, or improve it. I remain a
novice R programmer.

For the curious, the hardware/opsys details are a 1.5 ghz Windows 2000
machine, R1.9.0.

The task is this: I have a data set, mydat, consisting of values >=0,
and a fixed constant, K, that is "much" larger than any of the values. I
want to simulate the distribution of the number of bootstrap draws
(random sampling with replacement) from mydat that is needed  to make
the sum of the values drawn just exceed K. That is, repeatedly bootstrap
sample from mydat until the sum of the results exceeds K. Suppose this
requires 7 draws. Then 7 is a random sample of size 1 from the
distribution I'm interested in. I want to repeat this procedure a
"large" number, nsim, of times to estimate the distribution.

Before reading on, I invite R novices to consider how -- or better yet
write code -- to do this.

Approach 1 (Naive/ straightforward): Perform the simulation exactly as
described by using a nested loop. The outer loop goes from 1 to nsim to
record the number of draws needed. The inner loop repeatedly draws a
sample of size 1 from mydat and accumulates and checks the sum until it
exceeds K, returning the number of times it took to do this to the outer
loop.

This is easy to program up using a "while" loop for the inner loop and
takes about a short look's time out my window (a few seconds) to run for
modest nsim (5-10K). But surely one can do better...

Approach 2: Was essentially the same, except all the sampling is done
"at once." That is, each execution of the inner loop in (1) required R
to call the "sample()" function to get a bootstrap sample of size 1.
This is very inefficient, because there is a high overhead of making
that function call at each iteration. It can be avoided by calling
sample() only once -- or at most a small number of times -- to get a
large sample and then using indexing to work one's way through the large
sample. This turns out to be a little more complicated than approach 1
because you first have to figure how large a "large" sample should be
and then have to be a little careful about setting up your indexing. But
it's not very difficult (especially for any C programmer who can
manipulate pointers), and random sampling is so fast that it's no
problem to generate a sample WAYYY bigger than you need (5 or 10 times
as large, even) just to be safe. Or generate a not so big version and
just check at each outer loop iteration whether you need to generate
some more.

Doing it this way -- now using indexing, not function calls in the inner
loop -- made a considerable improvement (5 - 10 fold). It now took about
one quick glance out the window time to generate the distribution (less
than a second). This was more than adequate for my needs under any
conceivable situation. But still, self-respecting R programmers are
supposed to eschew looping, and here was this ugly(?) loop within a
loop!  So let us persevere.

Approach 3: So the question is -- how to remove that inner loop? Again,
I invite novice R programmers to think about that before continuing
on...

The key here is that the inner loop is doing a very simple calculation:
just accumulating a sum.  Forsooth! -- the answer fairly leaps out: R
already has a cumsum() function that does this (looping in the
underlying C code), so one only has to figure out how to make use of it.

The essential idea to do this is to get a small sample from the large
mydat sample that is guaranteed to be bigger than one needs to total up
to more than K. Again, one can be profligate: if I need about 10 mydat
values on average to sum up to K, if I sample 30 or 40 or some such
thing, I'm sure to have enough (and can always add a check or use
"try()" to make sure if I am faint of heart). If smallsamp is this
sample of the next 30 or 40 values from my large bootstrap sample, then
the following code vectorizes the inner loops:

count <- sum(cumsum(smallsamp)<K)+1

Note a trick here: The <K produces a vector of logical TRUE's for all
cumsum values <K. This is silently treated as numeric 1's when added by
sum(). A moment's thought will make clear why 1 must be added at the
end..

Sure enough, this vectorization  reduced the time about another twofold
-- to an eyeblink --  for my modest nsim sizes.

Approach 4: The last stage, of course, is to get rid of the outer loop,
which fills the vector for the distribution one element at a time, again
another R no-no. One way to do this -- the ONLY way I could think of (so
a challenge to smarter R programmers) -- is to make use of apply(),
which basically always can remove loops. Unfortunately, this is an
illusion, because what the apply() functions actually do is hide the
loops in clever R code, not remove them. Their virtue, as will be seen
here, is making the code more transparent by transferring the
bookkeeping of indexing to the R functions rather than having to
explicitly handle it yourself.

To use apply, the simple idea is just to make up a matrix with nsim
columns with enough rows so that each column contains "enough" random
draws from mydat to sum to more than K. Let's say that we decide M rows
will do it. Then the code for the whole simulation is:

   drawmat<-matrix(sample(mydat,M*nsim,rep=TRUE),ncol=nsim)
    drawmat <-apply(drawmat,2,cumsum)<K
    result<- colSums(drawmat)+1

The first statement generates the matrix of bootstrap samples, while the
second and third use the same trick as previously to get the number of
rows needed for each column to total more than K. Note that I used the
handy (and fast) internal colSums function to add up the 1's in the
columns. This code is much shorter, and I would say more transparent,
then the code produced by the previous explicit looping strategies.

However, not surprisingly, it does not run any faster (nor slower) than
the Approach 3 code.The looping is still there hidden in the apply().

I hope that this long-winded example will help R newcomers in their
entry into what may seem like a daunting programming language. As others
have, I would urge all to consult R's quite remarkable documentation and
Help facility (BEFORE they post to this list), as well as Venables's and
Ripley's two indispensable books on S language programming and data
analysis.

Cheers,
Bert Gunter

Non-Clinical Biostatistics
Genentech

"The business of the statistician is to catalyze the scientific learning
process."

 -- George E.P. Box



From thchung at tgen.org  Wed May 19 03:59:03 2004
From: thchung at tgen.org (Tae-Hoon Chung)
Date: Tue, 18 May 2004 18:59:03 -0700
Subject: [R] Web-application using R
Message-ID: <1A61E874-A938-11D8-A1A6-000A95B43CDE@tgen.org>

Hi, all;

Our group is planning to develop a web-based analysis package with R. I 
have some questions.
(1) Can we use R as a daemon-like way such that, after invoking R and 
making it run in a kind of background mode, just put some R script into 
R using some pipe-like mechanism and retrieve the result out of it?
(2) If this is possible, then how can we do it? If this is not 
possible, then what is the best way to accomplish this thing? Should we 
just use "R BATCH ..." thing all the time? The concern is that, in this 
case, we have to invoke R every time we want to use it, which will 
cause some time delay for loading R programs every time and may cause 
some system overhead when multiple users try to use R at the same time.
(3) I have a package developed in R with GUI in tcltk and want to port 
it in Java (because there are some other functionalities that have 
already been developed in Java and want to extend existing 
functionalities). The problem is that there does not seem to be an easy 
way to invoke R inside a Java program. I know there is a library called 
RSJava that is supposed to help this kind of situation but what I found 
was that it seemed to work only in Unix environment and it seemed to 
focus mainly users that try to use Java in R not users try to use R in 
Java. What will be the best solution?

Thanks in advance,
Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724



From ross.lazarus at channing.harvard.edu  Wed May 19 04:25:19 2004
From: ross.lazarus at channing.harvard.edu (Ross Lazarus)
Date: Tue, 18 May 2004 22:25:19 -0400
Subject: [R] R 1.90 make problem with /usr/X11R6/include/X11/Xutil.h on suse
 linux 9.1?
Message-ID: <40AAC58F.6070206@channing.harvard.edu>

This is probably a Suse specific problem and not a bug in R, but I'm 
reporting it in case it's useful for someone to know about....

Trying to compile R1.9.0 from source on a standard Suse 9.1 install 
(athlon in a shuttle sn41g2).
configure seems fine but the Suse X11R6 Xlib.h might be toxic.

In case it helps, here's the sad end to the make output. I can post the 
Xlib.h if that would help...

Please email me directly for more information if needed as I don't 
normally read this list....meanwhile, I'll go try the rpm....

making rotated.d from rotated.c
making rbitmap.d from rbitmap.c
make[4]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules/X11'
make[4]: Entering directory `/home/rossl/src/R-1.9.0/src/modules/X11'
gcc -I. -I../../../src/include -I../../../src/include 
-I/usr/X11R6/include -I/usr/local/include -DHAVE_CONFIG_H 
-D__NO_MATH_INLINES -mieee-fp -fPIC  -g -O2 -c dataentry.c -o dataentry.lo
In file included from dataentry.c:31:
/usr/X11R6/include/X11/Xlib.h:1400: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1488: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:1516: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1520: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:1542: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1577: error: parse error before '*' token
/usr/X11R6/include/X11/Xlib.h:1586: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1611: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1661: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1667: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1714: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:1753: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1994: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2078: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2331: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2341: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2413: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2423: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2581: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2596: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2789: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2856: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2861: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:2975: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3001: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3012: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3037: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3046: error: parse error before "char"
/usr/X11R6/include/X11/Xlib.h:3059: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3202: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3251: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3283: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3374: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3381: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3401: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3407: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3419: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3429: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3439: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3445: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3546: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3563: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3614: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3657: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3663: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3669: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3675: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3683: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3691: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3699: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3711: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3723: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3770: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3781: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3792: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3803: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3814: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3825: error: parse error before "_Xconst"
In file included from dataentry.c:32:
/usr/X11R6/include/X11/Xutil.h:566: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:606: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:666: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:678: error: parse error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:801: error: parse error before "_Xconst"
dataentry.c: In function `GetKey':
dataentry.c:1272: warning: passing arg 4 of `XLookupString' from 
incompatible pointer type
dataentry.c: In function `GetCharP':
dataentry.c:1281: warning: passing arg 4 of `XLookupString' from 
incompatible pointer type
dataentry.c: In function `doControl':
dataentry.c:1302: warning: passing arg 4 of `XLookupString' from 
incompatible pointer type
make[4]: *** [dataentry.lo] Error 1
make[4]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules/X11'
make[3]: *** [R] Error 2
make[3]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules/X11'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/rossl/src/R-1.9.0/src'
make: *** [R] Error 1
rossl at small:~/src/R-1.9.0>
-- 
Ross Lazarus MBBS MPH, Director of Bioinformatics
Channing Laboratory, 181 Longwood Ave., Boston MA 02115, USA.
Voice: +617 525 2730  Fax: +617 525 0958



From ok at cs.otago.ac.nz  Wed May 19 04:37:57 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Wed, 19 May 2004 14:37:57 +1200 (NZST)
Subject: [R] Installing packages from ZIP files
Message-ID: <200405190237.i4J2bv5b238256@atlas.otago.ac.nz>

I have R 1.9.0 running under Solaris 2.9 ona  SunBlade 100, and am
very happy with it.  I heard about the stuff at www.rmetrics.org and
thought it might be worth looking at.  However, what I found there is
a bunch of .zip files.  The entry page suggests that there is some
way to install packages from .zip files in R, but I have searched all
the documentation I have and cannot find it.

_Is_ there a way to install a package from a local .zip file in
R 1.9.0 for Unix, and if so, what is it?



From bates at stat.wisc.edu  Wed May 19 10:07:07 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 19 May 2004 03:07:07 -0500
Subject: [R] Debian & R
In-Reply-To: <4087DF4500081EE2@ims3e.cp.tin.it>
References: <4087DF4500081EE2@ims3e.cp.tin.it>
Message-ID: <6ru0ycn8lw.fsf@bates4.stat.wisc.edu>

v.demartino2 at virgilio.it writes:

> I use linux debian testing for which the latest debianized version of R
> is 1.8.1. Therefore I installed:
> 
>  r-base-core_1.8.1-0.cran.1_i386.deb 
>  r-base-dev_1.8.1-0.cran.1_all.deb   
>  r-base-html_1.8.1-0.cran.1_all.deb  
>  r-base-latex_1.8.1-0.cran.1_all.deb
>  r-base_1.8.1-0.cran.1_all.deb      
>  r-doc-html_1.8.1-0.cran.1_all.deb  
>  r-doc-info_1.8.1-0.cran.1_all.deb  
>  r-doc-pdf_1.8.1-0.cran.1_all.deb   
>  r-gnome_1.8.1-0.cran.1_i386.deb    
>  r-mathlib_1.8.1-0.cran.1_i386.deb  
>  r-recommended_1.8.1-0.cran.1_i386.deb 
> 
> Being impatient of moving to R v. 1.9.0 I would like to install and compile
> R from the source code in the *.tgz file from CRAN.
> 
> My question is:
> 
> In so doing will  anything be missing with respect to the deb packages I've
> mentioned?
> (e.g. r-gnome? r-mathlab?)

An alternative is to download and expand the sources for R-1.9.0 then
cd to the top-level R source directory and run

 dpkg-buildpackage -us -uc 

That will build all of the Debian R packages in a form suitable for your
system.  

We are still working out how to provide R packages for Debian testing
and Debian stable on CRAN again.  As Dirk Eddelbuettel and Fritz
Leisch and I will have a chance to discuss this during useR!2004 we
should be able to have a new system for the Debian section of CRAN in
place for the 1.9.1 release of R.



From muteau at ensam.inra.fr  Wed May 19 10:20:28 2004
From: muteau at ensam.inra.fr (Vincent MUTEAUD)
Date: Wed, 19 May 2004 10:20:28 +0200
Subject: [R] Re: Problem with package SJava
In-Reply-To: <20040518154103.84523.qmail@web12405.mail.yahoo.com>
Message-ID: <5.0.2.1.2.20040519093255.00a71520@ensam.inra.fr>

I have instanciated the ROmegahatInterpreter and I have a new message that 
I have no R_HOME environment variable value ??
when I do :
  > .javaConfig
I obtain:
$classPath
[1] "C:/PROGRA~1/R/rw1081/library/SJava/org/omegahat/Jars/Environment.jar"
[2] "C:/PROGRA~1/R/rw1081/library/SJava/org/.."
[3] "C:/PROGRA~1/R/rw1081/library/SJava/org/omegahat/Jars/antlr.jar"
[4] "C:/PROGRA~1/R/rw1081/library/SJava/org/omegahat/Jars/jas.jar"
[5] "C:/PROGRA~1/R/rw1081/library/SJava/org/omegahat/Jars/jhall.jar"

$properties
                                                                  EmbeddedInR
                                                                       "true"
                                                        InterfaceManagerClass
              "org/omegahat/Interfaces/NativeInterface/OmegaInterfaceManager"
                                                    ForeignReferenceBaseClass
                                      "org/omegahat/R/Java/RForeignReference"
                                                                java.compiler
                                                                       "NONE"
                                                                   OMEGA_HOME
                            "C:/PROGRA~1/R/rw1081/library/SJava/org/omegahat"
                                                           OmegahatSearchPath
".,${OMEGA_HOME}/Environment/Scripts/Run,${OMEGA_HOME}/Jars/Environment.jar"
                                                            java.library.path
                                    "C:/PROGRA~1/R/rw1081/library/SJava/libs"

$libraryPath
[1] "C:/PROGRA~1/R/rw1081/library/SJava/libs"

Wat I should do?



A 08:41 18/05/2004 -0700, Nathan Whitehouse a ??crit :
>Hi,
>
>   This main method on class Essai will fail at least
>for one reason becaue you need to instantiate a
>ROmegahatInterpreter.
>
>   Referencing this causes the R DLLs & the SJava DLLs
>to load.
>    However, it appears that they are already loaded,
>judging from your output below based on the signal
>11/Page fault error.
>
>   Try adding it and seeing if it works.  Can you get
>it to work under linux?
>
>   About the java compilation issue:
>
>   you need to have the following jars in your
>CLASSPATH
>
>     $SJAVA_HOME/org/omegahat/Jars/jas.jar
>     $SJAVA_HOME/org/omegahat/Jars/antlr.jar
>     $SJAVA_HOME/org/omegahat/Jars/Environment.jar
>
>   This might cause the compilation issue.
>
>   Hope that is a little help.  If you still have
>problems, hopefully we can figure them out.
>
>   Nathan
>
>Hello all,
>I'm trying to run SJava package (0.65 modified
>downloaded from :
>http://stats.math.uni-augsburg.de/iPlots/alpha/) on
>windows NT 2000 and
>R
>1.8.01. I have also downloaded the PDF Calling R from
>Java and when I
>want
>to execute the following code:
>import org.omegahat.R.Java.*;
>import java.io.*;
>public class Essai{
>         public static void main (String [] args) {
>                 REvaluator e = new REvaluator();
>                 Object val = e.eval("objects()");
>                 if (val!= null)  {
>                         String[] objects = (String[]) val;
>                         for (int i = 0; i< objects.length; i++) {
>                                 System.out.println("("+i+") " + objects[i]);
>                         }
>                 }
>         }
>}
>I have in return:
>
>
>An unexpected exception has been detected in native
>code outside the
>VM.
>Unexpected Signal : EXCEPTION_ACCESS_VIOLATION
>(0xc0000005) occurred at
>PC=0x6B4B85E3
>Function=R_SetMaxNSize+0xC3
>Library=c:\Program Files\R\rw1081\bin\R.dll
>
>Current Java thread:
>         at org.omegahat.R.Java.REvaluator.eval(Native Method)
>         at
>org.omegahat.R.Java.REvaluator.eval(REvaluator.java:86)
>         at
>org.omegahat.R.Java.REvaluator.eval(REvaluator.java:36)
>         at Toto.main(Toto.java:22)
>
>Dynamic libraries:
>0x00400000 - 0x00406000         C:\j2sdk1.4.2_03\bin\java.exe
>0x78460000 - 0x784E3000         C:\WINNT\system32\ntdll.dll
>0x78ED0000 - 0x78F32000
>C:\WINNT\system32\ADVAPI32.dll
>0x77E70000 - 0x77F33000
>C:\WINNT\system32\KERNEL32.DLL
>0x770C0000 - 0x77131000         C:\WINNT\system32\RPCRT4.DLL
>0x78000000 - 0x78045000         C:\WINNT\system32\MSVCRT.dll
>0x08000000 - 0x08138000
>C:\j2sdk1.4.2_03\jre\bin\client\jvm.dll
>0x77E00000 - 0x77E65000         C:\WINNT\system32\USER32.dll
>0x77F40000 - 0x77F7E000         C:\WINNT\system32\GDI32.DLL
>0x77540000 - 0x77571000         C:\WINNT\system32\WINMM.dll
>0x10000000 - 0x10007000
>C:\j2sdk1.4.2_03\jre\bin\hpi.dll
>0x007C0000 - 0x007CE000
>C:\j2sdk1.4.2_03\jre\bin\verify.dll
>0x007D0000 - 0x007E9000
>C:\j2sdk1.4.2_03\jre\bin\java.dll
>0x007F0000 - 0x007FD000
>C:\j2sdk1.4.2_03\jre\bin\zip.dll
>0x18270000 - 0x18287000         C:\Program
>Files\R\rw1081\library\SJava\libs\SJava.dll
>0x6B400000 - 0x6B61B000         c:\Program
>Files\R\rw1081\bin\R.dll
>0x68180000 - 0x6819F000         c:\Program
>Files\R\rw1081\bin\Rblas.dll
>0x77B40000 - 0x77BC9000
>C:\WINNT\system32\COMCTL32.DLL
>0x76B00000 - 0x76B3E000
>C:\WINNT\system32\COMDLG32.DLL
>0x63180000 - 0x631C8000         C:\WINNT\system32\SHLWAPI.DLL
>0x77580000 - 0x777CF000         C:\WINNT\system32\SHELL32.DLL
>0x77810000 - 0x77817000         C:\WINNT\system32\VERSION.dll
>0x75950000 - 0x75956000         C:\WINNT\system32\LZ32.DLL
>0x77910000 - 0x77933000
>C:\WINNT\system32\imagehlp.dll
>0x72970000 - 0x7299D000         C:\WINNT\system32\DBGHELP.dll
>0x68EA0000 - 0x68EAB000         C:\WINNT\system32\PSAPI.DLL
>
>Heap at VM Abort:
>Heap
>   def new generation   total 576K, used 227K
>[0x10010000, 0x100b0000,
>0x104f0000)
>    eden space 512K,  44% used [0x10010000, 0x10048f68,
>0x10090000)
>    from space 64K,   0% used [0x10090000, 0x10090000,
>0x100a0000)
>    to   space 64K,   0% used [0x100a0000, 0x100a0000,
>0x100b0000)
>   tenured generation   total 1408K, used 0K
>[0x104f0000, 0x10650000,
>0x14010000)
>     the space 1408K,   0% used [0x104f0000,
>0x104f0000, 0x104f0200,
>0x10650000)
>   compacting perm gen  total 4096K, used 1039K
>[0x14010000, 0x14410000,
>0x18010000)
>     the space 4096K,  25% used [0x14010000,
>0x14113de0, 0x14113e00,
>0x14410000)
>
>Local Time = Mon May 17 09:22:41 2004
>Elapsed Time = 17
>#
># The exception above was detected in native code
>outside the VM
>#
># Java VM: Java HotSpot(TM) Client VM (1.4.2_03-b02
>mixed mode)
>#
>
>I try to recompile the native interfaces and I think
>that some files or
>directories are missing like:
>antlr\commonAST.class
>jas.classEnv
>
>I don't know what I should do so I hope that anybody
>could help me.
>thanks,
>Regards
>
>Vincent
>
>=====
>Nathan Whitehouse
>Statistics/Programming
>Baylor College of Medicine
>Houston, TX, USA
>nlwhitehouse at yahoo.com
>work: 1-713-798-9029
>cell:    1-512-293-5840
>
>http://rho-project.org: rho- open source web services for R.
>http://franklin.imgen.bcm.tmc.edu: Shaw laboratory, bcm.



From Melanie.Pelegrini at imed.jussieu.fr  Wed May 19 17:10:30 2004
From: Melanie.Pelegrini at imed.jussieu.fr (=?ISO-8859-1?Q?M=E9lanie_PELEGRINI-ISSAC?=)
Date: Wed, 19 May 2004 17:10:30 +0200
Subject: [R] Build R-1.9.0 with static libraries ?
In-Reply-To: <Pine.LNX.4.44.0405180928210.23184-100000@gannet.stats>
References: <Pine.LNX.4.44.0405180928210.23184-100000@gannet.stats>
Message-ID: <40AB78E6.2090805@imed.jussieu.fr>


> ## For example, one can set flags for profiling here.
> ## MAIN_LDFLAGS=
> 
> My guess is that you want -Bstatic.
> 

Sorry to bother the mailing list again, but I'm not a specialist in 
compiling, so I'm quite lost...

I tried
MAIN_LDFLAGS=-Bstatic
in config.site

Incidentally, after running configure I get in Makeconf file the 
following flag
MAIN_LDFLAGS = -Bstatic -Wl,--export-dynamic

R compiles fine, however when I try to run it from another machine I get 
the following error
myDirectory/R.bin: error while loading shared libraries: libg2c.so.0: 
cannot open shared object file: No such file or directory

So I think it didn't solve my problem... and R still looks for shared 
objects. I tried
MAIN_LDFLAGS=-Bstatic -static-libgcc
in config.site
but it didn't work either.

How can I force R to use static versions of shared objects such as
LIBS =  -lreadline -ldl -lncurses -lm
FLIBS = -lfrtbegin -lg2c -lm -lgcc_s
???

Any hint would be much appreciated...

Melanie


------------------
M??lanie PELEGRINI-ISSAC         tel : (33 0)1 53 82 84 20
Unit?? 483 INSERM		fax : (33 0)1 53 82 84 48
9, quai Saint-Bernard           email :Melanie.Pelegrini at imed.jussieu.fr
Bat C 6e etage 75005 PARIS



From uleopold at science.uva.nl  Wed May 19 12:04:18 2004
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: 19 May 2004 12:04:18 +0200
Subject: [R] symbol size in plot
Message-ID: <1084961058.19281.10.camel@maximir>

Dear list,

 I have been reading the archives already but I do not manage to plot
the correct size of symbols without running into other problems.

When I use the syntax below I get the size of symbols and text right but
the text overlays on top of the axis rather than be in the right
position when you using the defaults for plot. Furthermore the ticks of
the axis appear to be too small. Is there a way of getting things
correct like in the default plot?


par(mfrow=c(2,2),cex=0.2, cex.main=5, cex.sub=5, cex.axis=5,pch=16)
plot(x,y)



Regards, Ulrich



From michael.watson at bbsrc.ac.uk  Wed May 19 13:35:45 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Wed, 19 May 2004 12:35:45 +0100
Subject: [R] Help with hclust() and plot()
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9516EE41@iahce2knas1.iah.bbsrc.reserved>

Hi

When I use plot(hclust(dist..)...)...) etc to create a dendrogram of a
hierarchial cluster analysis, I end up with a vertical tree.  What do I
need to do to get a horizontal tree?

Also, my users are used to seeing trees who's leaves all "end" at the
same place (eg. Like in minitab).  Is this possible in R?

Thanks

Mick

Michael Watson
Head of Informatics
Institute for Animal Health,
Compton Laboratory,
Compton,
Newbury,
Berkshire RG20 7NN
UK

Phone : +44 (0)1635 578411 ext. 2535
Mobile: +44 (0)7990 827831
E-mail: michael.watson at bbsrc.ac.uk



From ripley at stats.ox.ac.uk  Wed May 19 13:40:31 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 May 2004 12:40:31 +0100 (BST)
Subject: [R] Build R-1.9.0 with static libraries ?
In-Reply-To: <40AB78E6.2090805@imed.jussieu.fr>
Message-ID: <Pine.LNX.4.44.0405191238210.1246-100000@gannet.stats>

On Wed, 19 May 2004, M??lanie PELEGRINI-ISSAC wrote:

Very important information clipped here.


Quoting me with attribution:
> > ## For example, one can set flags for profiling here.
> > ## MAIN_LDFLAGS=
> > 
> > My guess is that you want -Bstatic.
> > 
> 
> Sorry to bother the mailing list again, but I'm not a specialist in 
> compiling, so I'm quite lost...
> 
> I tried
> MAIN_LDFLAGS=-Bstatic
> in config.site
> 
> Incidentally, after running configure I get in Makeconf file the 
> following flag
> MAIN_LDFLAGS = -Bstatic -Wl,--export-dynamic
> 
> R compiles fine, however when I try to run it from another machine I get 
> the following error
> myDirectory/R.bin: error while loading shared libraries: libg2c.so.0: 
> cannot open shared object file: No such file or directory
> 
> So I think it didn't solve my problem... and R still looks for shared 
> objects. I tried
> MAIN_LDFLAGS=-Bstatic -static-libgcc
> in config.site
> but it didn't work either.

Note, it says

## The flags which are necessary for loading main program which will
## load DLLs at runtime.  HP-UX and Linux-elf are examples of platforms
## which use this.  These platforms are already taken care of by
## configure, and anything set here will be in addition unless MAIN_LD
## is given.
## For example, one can set flags for profiling here.
## MAIN_LDFLAGS=

so please set MAIN_LD as it suggests (and that's why I quoted the whole 
thing for you to read!)

> How can I force R to use static versions of shared objects such as
> LIBS =  -lreadline -ldl -lncurses -lm
> FLIBS = -lfrtbegin -lg2c -lm -lgcc_s
> ???

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed May 19 13:41:44 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 May 2004 12:41:44 +0100 (BST)
Subject: [R] Installing packages from ZIP files
In-Reply-To: <200405190237.i4J2bv5b238256@atlas.otago.ac.nz>
Message-ID: <Pine.LNX.4.44.0405191241140.1246-100000@gannet.stats>

On Wed, 19 May 2004, Richard A. O'Keefe wrote:

> I have R 1.9.0 running under Solaris 2.9 ona  SunBlade 100, and am
> very happy with it.  I heard about the stuff at www.rmetrics.org and
> thought it might be worth looking at.  However, what I found there is
> a bunch of .zip files.  The entry page suggests that there is some
> way to install packages from .zip files in R, but I have searched all
> the documentation I have and cannot find it.
> 
> _Is_ there a way to install a package from a local .zip file in
> R 1.9.0 for Unix, and if so, what is it?

Unzip it into a suitable dir, then R CMD INSTALL.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From v_bill_pikounis at merck.com  Wed May 19 14:56:35 2004
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Wed, 19 May 2004 08:56:35 -0400
Subject: Windows versus Unix packages in CRAN (Was Re: [R] Rmetrics)
Message-ID: <CFBD404F5E0C9547B4E10B7BDC3DFA2F0415634C@usrymx18.merck.com>

Hi Andrew,

You mentioned:

> Yes, I agree with Ajay Shah's comments. The Rmetrics website makes a 
> virtue of open source yet the Rmetrics people do not make available 
> their package for the open source platform, Linux.

Actually, I think they do.  A quick perusal of the site indicated to me on
page 2 of the Overview Flyer
http://www.itp.phys.ethz.ch/econophysics/R/pdf/DocRmetrics.pdf:

"Why using MS Windows? In
the financial community Windows is the
mostly used operating system. For a broad
distribution and acceptance of Rmetrics, we
decided to develop the software under Windows
2000/XP. But nevertheless, since all
source code is available it may be straightforward
to adapt and compile the software
for other operating systems."

And right on the home page, I see

"The growing Rmetrics collection is based on many statistical and financial
functions which were contributed by myself, my students, or were ported from
other sources during the last few years. The work is by far not complete and
parts of the software are still untested, and may contain some bugs. "

It seems to me Dr Wuertz has done an awful lot already, and that "out of the
box" availability for Linux or other platforms will likely come as the
community of its users grows.

I found a folder in the Downloads section called

http://www.itp.phys.ethz.ch/econophysics/R/bin/windows/contrib/1.9/Sources/

and if I remember correctly, there are multiple Linux/Unix utilities out
there to handle "Windows" .zip files.

Finally I must say that this is the first time I can ever recall objections
about R or any *open source* software that was available on Windows but not
on Linux/Unix.  Of course the opposite direction case still occurs often
enough, I guess.

Best Regards,
Bill


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Andrew Criswell
> Sent: Tuesday, May 18, 2004 9:11 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: Windows versus Unix packages in CRAN (Was Re: 
> [R] Rmetrics)
> 
> 
> Yes, I agree with Ajay Shah's comments. The Rmetrics website makes a 
> virtue of open source yet the Rmetrics people do not make available 
> their package for the open source platform, Linux.
> 
> Ajay Shah wrote:
> 
> >>Rmetrics - New Version is available for R 1.9 !!
> >>    
> >>
> >
> >  
> >
> >>in R-binary and R-source form from the site 
> "http://www.rmetrics.org",
> >>and install the binary "zip" 
> files in the usual way via the menu
> >>    
> >>
> >
> >I'm confused - does the fact that you are only distributing ".zip"
> >files means that (shudder) I need Microsoft Windows in order to run
> >this? (I hunted on the website but you seemed to only have .zip
> >files. That's very odd; normally on Unix we don't ship .zip files).
> >
> >More generally: Do all R packages automatically run on Unix, 
> or are we
> >fragmenting the CRAN code base into Unix and non-Unix 
> packages? One of
> >my reasons for shifting to R was that it felt like a system that was
> >built by Unix people (roots in Bell Labs etc.). So it will have a
> >function like sink() as a nice counterpart to a function 
> like source()
> >:-)
> >
> >Ox, for example, has nice functionality but it felt like it was done
> >by Windows guys, so it wasn't going to be useful to me, and I kept
> >away.
> >
> >If R packages are actually in two (intersecting) sets : 
> those that run
> >on Unix and those that run on Windows, then do we need a 
> CRAN/Unix and
> >CRAN/M$ directories to distinguish them? It will avoid a lot 
> of wasted
> >time... e.g. I blew half an hour on investigating Rmetrics before
> >deciding they're a Windows crowd.
> >
> >  
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From jgentry at jimmy.harvard.edu  Wed May 19 15:10:05 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Wed, 19 May 2004 09:10:05 -0400 (EDT)
Subject: Windows versus Unix packages in CRAN (Was Re: [R] Rmetrics)
In-Reply-To: <40AAB441.205@arcriswell.com>
Message-ID: <Pine.SOL.4.20.0405190909480.25443-100000@santiam.dfci.harvard.edu>

> Yes, I agree with Ajay Shah's comments. The Rmetrics website makes a 
> virtue of open source yet the Rmetrics people do not make available 
> their package for the open source platform, Linux.

It wouldn't be difficult to create a source tarball and submit it to them
....



From f.calboli at ucl.ac.uk  Wed May 19 16:14:58 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 19 May 2004 15:14:58 +0100
Subject: [R] RE: 1-way anova, nested model
Message-ID: <1084976098.2962.14.camel@monkey>

>From what I gather you have 

2 treatments
6 samples nested in treatment
12 replicates in sample.

I do not know what your dependent veriable is, but I would:

code the two treatments as T1 and T2
code the 6 samples as a, b, c, d, e, f so the first three samples
belonging to T1 are not confused with the other three (coding them as
1,2,3 for T1 and 1,2,3 for T2 is a bad idea)
code the replicates as a1, a2, b1, b2....

here I am being extra paranoid in the coding, btw, but it helps and
saves grief later on, in my experience.

The model would be:

library(nlme) # needed!
mod<-lme(response ~ treatment, random = ~ 1|sample/replicate, mydata)

An anova test would give only one F test for the fixed factor, with 1
and 4 df (if I am not mistaken, double check!)

Federico
-- 



=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 209 4286

f.calboli at ucl.ac.uk
fcalboli at alma.unibo.it



From otoomet at econ.dk  Wed May 19 15:14:57 2004
From: otoomet at econ.dk (Ott Toomet)
Date: Wed, 19 May 2004 15:14:57 +0200
Subject: [R] band matrices
Message-ID: <200405191314.i4JDEv9n002494@localhost.localdomain>

Hi,

are there routines for creating and manipulatin band matrices?  I am
estimating a problem using penalised likelihood and I have to
calculate the penalty term (using notation by Green & Silvermann
(1994))

t(g) %*% Q %*% solve(R) %*% t(Q) %*% g

It can be done using diag(), some indexing, and perhaps sparseM
package.  Are there better ways?

Thanks in advance,

Ott

-- 
Ott Toomet
PhD Student

Dept. of Economics
??rhus University
Building 322
Universitetsparken
8000 ??rhus C
Denmark

otoomet (a) econ au dk
ph: (+45) 89 42 20 40
-------------------------------------------

 (o_         (*_         (O_         (o< -!  
//\         //\         //\         //\      
V_/_        V_/_        V_/_        V_/_     
					     
standard    drunken     shocked     noisy    
penguin     penguin     penguin     penguin



From f.calboli at ucl.ac.uk  Wed May 19 16:27:40 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 19 May 2004 15:27:40 +0100
Subject: [R] Re: Debian & R
Message-ID: <1084976860.2962.23.camel@monkey>

I have R 1.9.0 on sid, apt-getting stuff from cran... I too noticed that
cran has R 1.8.1 for Debian, but as I got R 1.9.0 I just ignored the
differences in labelling.

BTW, it is R that tells me it is R 1.9.0 when I fire it up. And has the
"stats" library that I did not remember in R 1.8.*

Federico
-- 



=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 209 4286

f.calboli at ucl.ac.uk
fcalboli at alma.unibo.it



From Melanie.Pelegrini at imed.jussieu.fr  Wed May 19 22:04:17 2004
From: Melanie.Pelegrini at imed.jussieu.fr (=?ISO-8859-1?Q?M=E9lanie_PELEGRINI-ISSAC?=)
Date: Wed, 19 May 2004 22:04:17 +0200
Subject: [R] Build R-1.9.0 with static libraries ?
In-Reply-To: <Pine.LNX.4.44.0405191238210.1246-100000@gannet.stats>
References: <Pine.LNX.4.44.0405191238210.1246-100000@gannet.stats>
Message-ID: <40ABBDC1.5040309@imed.jussieu.fr>


> so please set MAIN_LD as it suggests (and that's why I quoted the whole 
> thing for you to read!)
> 

OK, I've set MAIN_LD to 'gcc -Bstatic'
but now 'make' fails for the following reason:


Error in dyn.load(x, as.logical(local), as.logical(now)) :
	unable to load shared library "$BuildDir/library/methods/libs/methods.so":
   $BuildDir/library/methods/libs/methods.so: undefined symbol: R_GlobalEnv
Execution halted
Error in dyn.load(x, as.logical(local), as.logical(now)) :
	unable to load shared library "$BuildDir/library/stats/libs/stats.so":
   $BuildDir/library/stats/libs/stats.so: undefined symbol: R_GlobalEnv
Execution halted
Error in dyn.load(x, as.logical(local), as.logical(now)) :
	unable to load shared library "$BuildDir/library/tools/libs/tools.so":
   $BuilDir/library/tools/libs/tools.so: undefined symbol: R_NaString
Error: couldn't find function ".installPackageNamespaceInfo"
In addition: Warning message:
package tools in options("defaultPackages") was not found
Execution halted



So I'm afraid I'm still missing a flag somewhere... I'm sorry but I'm 
not used compiling such packages so I cannot figure out where I made a 
mistake.

Thanks again for your patience :-(

Melanie



From macq at llnl.gov  Wed May 19 16:36:47 2004
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 19 May 2004 07:36:47 -0700
Subject: [R] Web-application using R
In-Reply-To: <1A61E874-A938-11D8-A1A6-000A95B43CDE@tgen.org>
References: <1A61E874-A938-11D8-A1A6-000A95B43CDE@tgen.org>
Message-ID: <p06002004bcd12134daf8@[128.115.153.6]>

See the following email, which was sent to r-help 2004-02-21
-Don


From: "Graciliano M. P." <gmpowers at terra.com.br>
To: "Module Authors" <module-authors at perl.org>
Cc: r-help at stat.math.ethz.ch
Subject: [R] New Perl module Statistics::R

I have released the new module Statistics::R and need some feedback of it's
status.
This will permit the control of the the R (R-project) interpreter through
Perl in different architectures and OS.

You can for example, start only one instance of the R interpreter and have
different Perl process accessing it. What will save the initiation time of R
and memory.

Soo, I will appreciate if some one can test it in different OS. Tested with
Win32 and Linux.

http://search.cpan.org/~gmpassos/Statistics-R-0.01/

Thanks in advance.

Regards,
Graciliano M. P.


At 6:59 PM -0700 5/18/04, Tae-Hoon Chung wrote:
>Hi, all;
>
>Our group is planning to develop a web-based analysis package with 
>R. I have some questions.
>(1) Can we use R as a daemon-like way such that, after invoking R 
>and making it run in a kind of background mode, just put some R 
>script into R using some pipe-like mechanism and retrieve the result 
>out of it?
>(2) If this is possible, then how can we do it? If this is not 
>possible, then what is the best way to accomplish this thing? Should 
>we just use "R BATCH ..." thing all the time? The concern is that, 
>in this case, we have to invoke R every time we want to use it, 
>which will cause some time delay for loading R programs every time 
>and may cause some system overhead when multiple users try to use R 
>at the same time.
>(3) I have a package developed in R with GUI in tcltk and want to 
>port it in Java (because there are some other functionalities that 
>have already been developed in Java and want to extend existing 
>functionalities). The problem is that there does not seem to be an 
>easy way to invoke R inside a Java program. I know there is a 
>library called RSJava that is supposed to help this kind of 
>situation but what I found was that it seemed to work only in Unix 
>environment and it seemed to focus mainly users that try to use Java 
>in R not users try to use R in Java. What will be the best solution?
>
>Thanks in advance,
>Tae-Hoon Chung, Ph.D
>
>Post-doctoral Research Fellow
>Molecular Diagnostics and Target Validation Division
>Translational Genomics Research Institute
>1275 W Washington St, Tempe AZ 85281 USA
>Phone: 602-343-8724
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From Maarten.van.der.Hoeven at knmi.nl  Wed May 19 16:47:20 2004
From: Maarten.van.der.Hoeven at knmi.nl (Hoeven, Maarten van der)
Date: Wed, 19 May 2004 16:47:20 +0200
Subject: [R] Web-application using R
Message-ID: <1F8990C21AC73945BE6AAC5AD6D4CAE934CCAA@BCSXAC.knmi.nl>

This is something I'm looking for too :)

Did someone test this? Is it quick? Is there a website that features a real online demo?

Thanks,



> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Don MacQueen
> Sent: Wednesday, May 19, 2004 4:37 PM
> To: Tae-Hoon Chung; R-help at stat.math.ethz.ch
> Subject: Re: [R] Web-application using R
> 
> 
> See the following email, which was sent to r-help 2004-02-21
> -Don
> 
> 
> From: "Graciliano M. P." <gmpowers at terra.com.br>
> To: "Module Authors" <module-authors at perl.org>
> Cc: r-help at stat.math.ethz.ch
> Subject: [R] New Perl module Statistics::R
> 
> I have released the new module Statistics::R and need some 
> feedback of it's
> status.
> This will permit the control of the the R (R-project) 
> interpreter through
> Perl in different architectures and OS.
> 
> You can for example, start only one instance of the R 
> interpreter and have
> different Perl process accessing it. What will save the 
> initiation time of R
> and memory.
> 
> Soo, I will appreciate if some one can test it in different 
> OS. Tested with
> Win32 and Linux.
> 
> http://search.cpan.org/~gmpassos/Statistics-R-0.01/
> 
> Thanks in advance.
> 
> Regards,
> Graciliano M. P.
> 
> 
> At 6:59 PM -0700 5/18/04, Tae-Hoon Chung wrote:
> >Hi, all;
> >
> >Our group is planning to develop a web-based analysis package with 
> >R. I have some questions.
> >(1) Can we use R as a daemon-like way such that, after invoking R 
> >and making it run in a kind of background mode, just put some R 
> >script into R using some pipe-like mechanism and retrieve the result 
> >out of it?
> >(2) If this is possible, then how can we do it? If this is not 
> >possible, then what is the best way to accomplish this thing? Should 
> >we just use "R BATCH ..." thing all the time? The concern is that, 
> >in this case, we have to invoke R every time we want to use it, 
> >which will cause some time delay for loading R programs every time 
> >and may cause some system overhead when multiple users try to use R 
> >at the same time.
> >(3) I have a package developed in R with GUI in tcltk and want to 
> >port it in Java (because there are some other functionalities that 
> >have already been developed in Java and want to extend existing 
> >functionalities). The problem is that there does not seem to be an 
> >easy way to invoke R inside a Java program. I know there is a 
> >library called RSJava that is supposed to help this kind of 
> >situation but what I found was that it seemed to work only in Unix 
> >environment and it seemed to focus mainly users that try to use Java 
> >in R not users try to use R in Java. What will be the best solution?
> >
> >Thanks in advance,
> >Tae-Hoon Chung, Ph.D
> >
> >Post-doctoral Research Fellow
> >Molecular Diagnostics and Target Validation Division
> >Translational Genomics Research Institute
> >1275 W Washington St, Tempe AZ 85281 USA
> >Phone: 602-343-8724
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-------------------------------------------------------------- 

Zie ook/see also: http://www.knmi.nl/maildisclaimer.html



From rxg218 at psu.edu  Wed May 19 16:50:33 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Wed, 19 May 2004 10:50:33 -0400
Subject: [R] storing binary numbers
Message-ID: <1084978233.4863.15.camel@blue.chem.psu.edu>

Hi,
  is there any function that would allow me to read in a string of 1 or
0's (which can be very long) and then convert that to a binary number so
that I cn do logical operations (as well as operations such number of
1's or number of 0's)

Currently I do it by creating a vector and have written functions to do
what I need - I was wondering whether there was anything native to R for
this type of thing (bitset)

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Q: What's yellow, linear, normed and complete?
A: A Bananach space.



From adi at roda.ro  Wed May 19 17:43:47 2004
From: adi at roda.ro (Adrian Dusa)
Date: Wed, 19 May 2004 18:43:47 +0300
Subject: [R] indexing question
Message-ID: <1084981427.40ab80b3188b3@ns.roda.ro>

Hi,

I have a problem and a rather poor solution that I would like to improve.
There a 2 datasets with different number of cases like this:

Dataset 'poploc?                                Dataset 'siruta?

Case no.     SIRUTA     TYPE                    Case no.     SIRUTA     TYPE
1            1017        0                      1            1017        3  
2            1026        0                      2            1020        5
3            42711       0                      3            1026        4
....                                               ....
13000        100234      0                      ....
                                                16000        160241      3

I want to bring the TIP variable in the 'poploc? dataset according to the 
SIRUTA variable (which has unique codes for each case, in both datasests).
The resulting dataset 'poploc' should look like this:

Case no.     SIRUTA     TYPE
1            1017        3
2            1026        4
3            42711       3
....
13000        100234      5

My current solution involves a combination of FOR looping and indexing, which 
takes about 3 minutes to complete.

for (i in 1:nrow(siruta))
poploc$TIP[poploc$SIRUTA %in% siruta$SIRUTA[i]] <- siruta$TIP[i]

I?m sure there are more clever solutions, any help appreciated. Thank you!
Adrian



From Benjamin.STABLER at odot.state.or.us  Wed May 19 17:50:18 2004
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Wed, 19 May 2004 08:50:18 -0700
Subject: [R] indexing question
Message-ID: <76A000A82289D411952F001083F9DD06047FE69F@exsalem4-bu.odot.state.or.us>

take a look at match or maybe merge

>-----Original Message-----
>From: Adrian Dusa [mailto:adi at roda.ro]
>Sent: Wednesday, May 19, 2004 8:44 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] indexing question
>
>
>Hi,
>
>I have a problem and a rather poor solution that I would like 
>to improve.
>There a 2 datasets with different number of cases like this:
>
>Dataset 'poploc'                                Dataset 'siruta'
>
>Case no.     SIRUTA     TYPE                    Case no.     
>SIRUTA     TYPE
>1            1017        0                      1            
>1017        3  
>2            1026        0                      2            
>1020        5
>3            42711       0                      3            
>1026        4
>...                                               ...
>13000        100234      0                      ...
>                                                16000        
>160241      3
>
>I want to bring the TIP variable in the 'poploc' dataset 
>according to the 
>SIRUTA variable (which has unique codes for each case, in both 
>datasests).
>The resulting dataset 'poploc' should look like this:
>
>Case no.     SIRUTA     TYPE
>1            1017        3
>2            1026        4
>3            42711       3
>...
>13000        100234      5
>
>My current solution involves a combination of FOR looping and 
>indexing, which 
>takes about 3 minutes to complete.
>
>for (i in 1:nrow(siruta))
>poploc$TIP[poploc$SIRUTA %in% siruta$SIRUTA[i]] <- siruta$TIP[i]
>
>I'm sure there are more clever solutions, any help 
>appreciated. Thank you!
>Adrian
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at PDF.COM  Wed May 19 17:53:57 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 19 May 2004 08:53:57 -0700
Subject: [R] indexing question
In-Reply-To: <1084981427.40ab80b3188b3@ns.roda.ro>
References: <1084981427.40ab80b3188b3@ns.roda.ro>
Message-ID: <40AB8315.1030105@pdf.com>



Adrian Dusa wrote:

> Hi,
> 
> I have a problem and a rather poor solution that I would like to improve.
> There a 2 datasets with different number of cases like this:
> 
> Dataset 'poploc?                                Dataset 'siruta?
> 
> Case no.     SIRUTA     TYPE                    Case no.     SIRUTA     TYPE
> 1            1017        0                      1            1017        3  
> 2            1026        0                      2            1020        5
> 3            42711       0                      3            1026        4
> ....                                               ....
> 13000        100234      0                      ....
>                                                 16000        160241      3
> 
> I want to bring the TIP variable in the 'poploc? dataset according to the 
> SIRUTA variable (which has unique codes for each case, in both datasests).
> The resulting dataset 'poploc' should look like this:
> 
> Case no.     SIRUTA     TYPE
> 1            1017        3
> 2            1026        4
> 3            42711       3
> 
> 13000        100234      5
> 
> My current solution involves a combination of FOR looping and indexing, which 
> takes about 3 minutes to complete.
> 
> for (i in 1:nrow(siruta))
> poploc$TIP[poploc$SIRUTA %in% siruta$SIRUTA[i]] <- siruta$TIP[i]
> 
> I?m sure there are more clever solutions, any help appreciated. Thank you!
> Adrian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

I think you are looking for ?merge.

# note that poploc has no `TYPE' column
poploc <- data.frame(no = 1:3, SIRUTA = c(1017, 1026, 42711))
siruta <- data.frame(no = c(1:3, 16000),
                      SIRUTA = c(1017, 1026, 42711, 160241),
                      TYPE = c(3, 5, 4, 3))
merge(poploc, siruta)



From FWS4 at CDRH.FDA.GOV  Wed May 19 17:54:38 2004
From: FWS4 at CDRH.FDA.GOV (Samuelson, Frank*)
Date: Wed, 19 May 2004 11:54:38 -0400
Subject: [R] Web-application using R
Message-ID: <644D9337A02FC24689647BF9E48EC39E08ABB7F0@drm556>

http://franklin.imgen.bcm.tmc.edu/R.web.servers/index.html

-----Original Message-----
From: Tae-Hoon Chung [mailto:thchung at tgen.org] 
Sent: Tuesday, May 18, 2004 9:59 PM
To: R-help at stat.math.ethz.ch
Subject: [R] Web-application using R


Hi, all;

Our group is planning to develop a web-based analysis package with R. I 
have some questions.
(1) Can we use R as a daemon-like way such that, after invoking R and 
making it run in a kind of background mode, just put some R script into 
R using some pipe-like mechanism and retrieve the result out of it?
(2) If this is possible, then how can we do it? If this is not 
possible, then what is the best way to accomplish this thing? Should we 
just use "R BATCH ..." thing all the time? The concern is that, in this 
case, we have to invoke R every time we want to use it, which will 
cause some time delay for loading R programs every time and may cause 
some system overhead when multiple users try to use R at the same time.
(3) I have a package developed in R with GUI in tcltk and want to port 
it in Java (because there are some other functionalities that have 
already been developed in Java and want to extend existing 
functionalities). The problem is that there does not seem to be an easy 
way to invoke R inside a Java program. I know there is a library called 
RSJava that is supposed to help this kind of situation but what I found 
was that it seemed to work only in Unix environment and it seemed to 
focus mainly users that try to use Java in R not users try to use R in 
Java. What will be the best solution?

Thanks in advance,
Tae-Hoon Chung, Ph.D

Post-doctoral Research Fellow
Molecular Diagnostics and Target Validation Division
Translational Genomics Research Institute
1275 W Washington St, Tempe AZ 85281 USA
Phone: 602-343-8724

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From adi at roda.ro  Wed May 19 18:01:47 2004
From: adi at roda.ro (Adrian Dusa)
Date: Wed, 19 May 2004 19:01:47 +0300
Subject: [R] indexing question
In-Reply-To: <40AB8315.1030105@pdf.com>
Message-ID: <000701c43dba$a2f6c830$6901a8c0@roda.local>

Many many thanks.
merge is the function I needed.
Regards,
Adrian

-----Original Message-----
From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at PDF.COM] 
Sent: Wednesday, May 19, 2004 6:54 PM
To: Adrian Dusa
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] indexing question




Adrian Dusa wrote:

> Hi,
> 
> I have a problem and a rather poor solution that I would like to 
> improve. There a 2 datasets with different number of cases like this:
> 
> Dataset 'poploc'                                Dataset 'siruta'
> 
> Case no.     SIRUTA     TYPE                    Case no.     SIRUTA
TYPE
> 1            1017        0                      1            1017
3  
> 2            1026        0                      2            1020
5
> 3            42711       0                      3            1026
4
> .                                               .
> 13000        100234      0                      .
>                                                 16000        160241
3
> 
> I want to bring the TIP variable in the 'poploc' dataset according to 
> the
> SIRUTA variable (which has unique codes for each case, in both
datasests).
> The resulting dataset 'poploc' should look like this:
> 
> Case no.     SIRUTA     TYPE
> 1            1017        3
> 2            1026        4
> 3            42711       3
> 
> 13000        100234      5
> 
> My current solution involves a combination of FOR looping and 
> indexing, which
> takes about 3 minutes to complete.
> 
> for (i in 1:nrow(siruta))
> poploc$TIP[poploc$SIRUTA %in% siruta$SIRUTA[i]] <- siruta$TIP[i]
> 
> I'm sure there are more clever solutions, any help appreciated. Thank 
> you! Adrian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

I think you are looking for ?merge.

# note that poploc has no `TYPE' column
poploc <- data.frame(no = 1:3, SIRUTA = c(1017, 1026, 42711)) siruta <-
data.frame(no = c(1:3, 16000),
                      SIRUTA = c(1017, 1026, 42711, 160241),
                      TYPE = c(3, 5, 4, 3))
merge(poploc, siruta)



From christopher.albert at mcgill.ca  Wed May 19 18:34:19 2004
From: christopher.albert at mcgill.ca (Christopher Albert)
Date: Wed, 19 May 2004 12:34:19 -0400
Subject: [R] Building R on Fedora Core 2 from the src rpm
Message-ID: <40AB8C8B.8010301@mcgill.ca>

Hi,

The libtk8.3 dependencies in the R-1.9.0 rpm generate apt conflicts 
after an upgrade from Fedora Core 1 to Fedora core 2.
In trying to rebuild the rpm from the source rpm provided on CRAN,
the build fails when it comes time to compile

src/modules/X11/dataentry.c

you get many errors of the form :
> In file included from dataentry.c:34:
> /usr/X11R6/include/X11/Xlib.h:1400: error: syntax error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1488: error: syntax error before "char"
> /usr/X11R6/include/X11/Xlib.h:1516: error: syntax error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1520: error: syntax error before "char"
> /usr/X11R6/include/X11/Xlib.h:1542: error: syntax error before "_Xconst"
...

This could have something to do with the change from X1186 to xorg.

A workaround is simply to change the line in src/modules/X11/dataentry.c:
> /* don't use X11 function prototypes (which tend to ...): */
> #define NeedFunctionPrototypes 0
to
 > #define NeedFunctionPrototypes 1 .

As a patch:
> diff -crN R-1.9.0.orig/src/modules/X11/dataentry.c R-1.9.0/src/modules/X11/dataentry.c
> *** R-1.9.0.orig/src/modules/X11/dataentry.c    2004-03-22 06:00:16.000000000 -0500
> --- R-1.9.0/src/modules/X11/dataentry.c 2004-05-19 11:35:21.903803616 -0400
> ***************
> *** 29,35 ****
>   #include "Print.h"
>    
>   /* don't use X11 function prototypes (which tend to ...): */
> ! #define NeedFunctionPrototypes 0
>   #include <X11/X.h>
>   #include <X11/Xlib.h>
>   #include <X11/Xutil.h>
> --- 29,35 ----
>   #include "Print.h"
>    
>   /* don't use X11 function prototypes (which tend to ...): */
> ! #define NeedFunctionPrototypes 1
>   #include <X11/X.h>
>   #include <X11/Xlib.h>
>   #include <X11/Xutil.h>

Then the rpm builds fine.

Someone who knows the code will need to confirm that this is an 
acceptable solution.


Chris Albert



From baron at psych.upenn.edu  Wed May 19 18:42:51 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Wed, 19 May 2004 12:42:51 -0400
Subject: [R] Building R on Fedora Core 2 from the src rpm
In-Reply-To: <40AB8C8B.8010301@mcgill.ca>
References: <40AB8C8B.8010301@mcgill.ca>
Message-ID: <20040519164251.GA20177@psych>

On 05/19/04 12:34, Christopher Albert wrote:
>Hi,
>
>The libtk8.3 dependencies in the R-1.9.0 rpm generate apt conflicts
>after an upgrade from Fedora Core 1 to Fedora core 2.

Although I did not use apt or attempt to rebuild the rpm, I was
able to install the rpm by first installing the versions of tcl
and tk that came with Fedora Core 1, thus replacing the Core 2
versions with older versions.  Today I just updated to the final
version of Core 2 and let the installer update tk and tcl.  I am
still able to run R (although I haven't tried anything that
depends on tcl or tk, such Rcmdr).  I think there is a single
file that matters to the RPM.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From Han-Lin.Lai at noaa.gov  Wed May 19 18:46:41 2004
From: Han-Lin.Lai at noaa.gov (Han-Lin Lai)
Date: Wed, 19 May 2004 09:46:41 -0700
Subject: [R] mixed models for analyzing survey data with unequal selection 
 probability
Message-ID: <40AB8F71.F4598731@noaa.gov>

Hi,

I need the help on this topic because this is out of my statistical
trianing as biologist.  Here is my brief description of the problem.

I have a survey that VESSELs are selected at random with the probability
of p(j).  Then the tows within the jth VESSEL are sampled at random with
probability of p(i|j).  I write my model as

y = XB + Zb + e
where XB is fixed part, Zb is for random effect (VESSEL) and e is
within-vessel error.

I feel that I should weight the Zb part by p(j) and the e-part by
p(i,j)=p(j)*p(i|j). Is this a correct weighting?

How can I implement the weightings in nlme (or lme)?  I think that
p(i,j) can be specified by nlme(..., weights=p(i,j),...)?  Where is p(j)
to be used in nlme?

I appreciate anyone can provide examples and literature for this
problem.

Cheers!
Han

From rvaradha at jhsph.edu  Wed May 19 19:26:04 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Wed, 19 May 2004 13:26:04 -0400
Subject: [R] Finding indices where
Message-ID: <a0e726a0c5a1.a0c5a1a0e726@jhsph.edu>

Hi:

Suppose I have the following vector:

> x <- c(1,4:8,11,13:14,17,19,23:28,35:38)
> x
 [1]  1  4  5  6  7  8  11 13 14 17 19 23 24 25 26 27 28 35 36 37 38
> 

and I would like to pick out the first and last indices of all the 
consecutive "runs" of integers, where the length of a run is no smaller 
than a specified value, say, nmin.  That is, in the above example, for 
nmin=4, I would like to get the following 3 by 2 matrix:

4 8
23 28
35 38

For nmin=5, I would get the following 2 by 2 matrix

4 8
23 28

and for nmin=6, I would get the following 1 by 2 matrix

23 28

Is there an efficient and elegant way to do this?

Thanks very much for any help/suggestions.
Ravi.



From wuertz at itp.phys.ethz.ch  Wed May 19 19:42:36 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Wed, 19 May 2004 17:42:36 +0000
Subject: [R] FAQ for Rmetrics
Message-ID: <40AB9C8C.5060402@itp.phys.ethz.ch>

FAQ available for Rmetrics!

Best regards
Diethelm Wuertz



From wwsprague at ucdavis.edu  Wed May 19 20:22:04 2004
From: wwsprague at ucdavis.edu (wwsprague@ucdavis.edu)
Date: Wed, 19 May 2004 11:22:04 -0700
Subject: [R] GUI data browsers
Message-ID: <c8g8kk$r24$1@sea.gmane.org>

Hi R-helpers,

Does anyone know of a good Tk (or other) script that allows somewhat 
intuitive viewing of all of the variables (especially complex lists) in 
a session?  I would also like to delete, save to file, and rename them 
graphically.  I would also like a lot of supplemental information like 
class, atrributes, names, modes, whatever else...

Context:  I am running simulations (demographic) which generate big, 
complex datastructures that I store as lists of lists of lists of... 
(you understand).  Some of the components are informational things (like 
date of the run, the call, etc), while some are results of computation 
(like eigenvalues of a transition matrix, or generated vectors for each 
generation).  I vary the parameters and do runs, graph certain pieces of 
a bunch of runs (like the  largest eigenvalue against a certain 
parameter across all runs).

My inspiration (ahem) for this idea is ARCGIS, which, it's other 
problems aside, is pretty good at helping one keep track of all the 
various layers that go into a map.

If this would help anyone, it might be a good project for me to take 
on--please send feature requests!  I would probably try to extend some 
of the tcltk examples, especially the tree thingy.

I *don't* need form based windows for doing analyses.  I am quite 
comfortable on the command line, I just lose track of all the variables 
I generate.

Sorry for the extensive verbiage....

W



From wwsprague at ucdavis.edu  Wed May 19 20:31:01 2004
From: wwsprague at ucdavis.edu (wwsprague@ucdavis.edu)
Date: Wed, 19 May 2004 11:31:01 -0700
Subject: [R] GUI data browsers
In-Reply-To: <c8g8kk$r24$1@sea.gmane.org>
References: <c8g8kk$r24$1@sea.gmane.org>
Message-ID: <c8g95e$rml$1@sea.gmane.org>

wwsprague at ucdavis.edu wrote:

> Hi R-helpers,
> 
> Does anyone know of a good Tk (or other) script that allows somewhat 
> intuitive viewing of all of the variables (especially complex lists) in 
> a session?  

<SNIP>

I guess maybe some sort of object browser type thing.  If anyone has any 
Smalltalk experience, maybe he/she could weigh in on nice features

W



From wwsprague at ucdavis.edu  Wed May 19 21:06:22 2004
From: wwsprague at ucdavis.edu (wwsprague@ucdavis.edu)
Date: Wed, 19 May 2004 12:06:22 -0700
Subject: [R] match.call() with default parameters
Message-ID: <c8gb7q$225$1@sea.gmane.org>

version 1.9.0
debian linux

Is there a way to get match.call() to return the parameters that are 
assigned by default?

E.G.:

  f = function(x, y=2, ...) {return(as.list(match.call()))
f(33, z=4)

I want:

[[1]]
f

$x
[1] 33

$y
[1] 2

$z
[1] 4

I get:

[[1]]
f

$x
[1] 33

$z
[1] 4

Thx
W



From Allen.Joel at epamail.epa.gov  Wed May 19 21:24:38 2004
From: Allen.Joel at epamail.epa.gov (Allen.Joel@epamail.epa.gov)
Date: Wed, 19 May 2004 15:24:38 -0400
Subject: [R] POSIX to ts and back to POSIX
Message-ID: <OFE18C037F.A481D40B-ON85256E99.00687DA9-85256E99.006AA0A3@epamail.epa.gov>





I am trying to use POSIX datetime objects rather than chron datetime
objects but am having difficulty with POSIX in a time series.  My
question:  Once a POSIXct vector is bound to a time series, is there a
function to convert back to POSIXct?  The following code demonstrates
what I am trying to do.

> ts(as.POSIXct(strptime(tmp,"%m/%d/%Y %H:%M:%S")),freq=1440)
Time Series:
Start = c(1, 1)
End = c(1, 10)
Frequency = 1440
 [1] 1074022572 1074022632 1074022693 1074022753 1074022813 1074022874
1074022934 1074022994 1074023055 1074023115
attr(,"tzone")
[1]
> as.POSIXct(ts(as.POSIXct(strptime(tmp,"%m/%d/%Y
%H:%M:%S")),freq=1440))
Error in as.POSIXct.default(ts(as.POSIXct(strptime(tmp, "%m/%d/%Y
%H:%M:%S")),  :
      Don't know how to convert `ts(as.POSIXct(strptime(tmp, "%m/%d/%Y
%H:%M:%S")), freq = 1440)' to class "POSIXct"

this does not work either

> as.POSIXct(as.numeric(as.POSIXct(strptime(tmp,"%m/%d/%Y %H:%M:%S"))))
Error in as.POSIXct.default(as.numeric(as.POSIXct(strptime(tmp,
"%m/%d/%Y %H:%M:%S")))) :
      Don't know how to convert `as.numeric(as.POSIXct(strptime(tmp,
"%m/%d/%Y %H:%M:%S")))' to class "POSIXct"

Thanks in advance.

H. Joel Allen, PhD
Environmental Scientist
U.S. EPA
NRMRL, Water Quality Management Branch
26 W. Martin Luther King Dr
Cincinnati, OH 45268

Phone: 513 487-2806
Fax: 513 569-7052
Email: allen.joel at epa.gov



From sjerniga at GMACCM.com  Wed May 19 21:58:37 2004
From: sjerniga at GMACCM.com (Steve Jernigan - PA)
Date: Wed, 19 May 2004 15:58:37 -0400
Subject: [R] Accessing more than 2GB memory in Windows
Message-ID: <EED0EDE40B4773448997BB47AE04EC0B72CAC1@gcme2kmbx03.gmaccm.com>

Greetings,

Can anyone confirm that R can access more than 2GB 
of virtual memory on Windows? We are in the process
of porting a memory-hungry routine from Linux.

We are using R 1.8.1 on Windows 2000 Advanced Server;
we've set the 3GB switch in boot.ini, and rebooted
twice. We have run editbin against Rgui.exe ad Rterm.exe
and confirmed the header settings with dumpbin.exe.

We are invoking R with 
"C:\Program Files\R\rw1081\bin\Rgui" --max-mem-size=3G

Does anyone have a simple script that they have used to
confirm that R can access more than 2GB? We have tried
a few without success.

Regards,

Steve Jernigan



From aolinto_r at bignet.com.br  Wed May 19 22:32:32 2004
From: aolinto_r at bignet.com.br (Antonio Olinto)
Date: Wed, 19 May 2004 17:32:32 -0300
Subject: [R] greek letters in plots
Message-ID: <1084998752.40abc46089c40@webmail.bignet.com.br>

Hi,

I want to write in x axis label "fitted value of lambda" (lambda in greek 
letter).

xlab=expression(lambda) gives the "lambda", I tryed things like xlab=paste
("fitted value of ", expression(lambda)) but I didn't get the greek letter.

Thanks in advance for any hint.

Antonio Olinto


-------------------------------------------------
WebMail Bignet - O seu provedor do litoral
www.bignet.com.br



From andrewr at uidaho.edu  Wed May 19 22:38:07 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Wed, 19 May 2004 13:38:07 -0700 (PDT)
Subject: [R] greek letters in plots
In-Reply-To: <1084998752.40abc46089c40@webmail.bignet.com.br>
References: <1084998752.40abc46089c40@webmail.bignet.com.br>
Message-ID: <Pine.GSO.4.56.0405191336410.2361@cyclone.csrv.uidaho.edu>

Try

xlab=expression(paste("fitted value of ", lambda))

Cheers,

Andrew

On Wed, 19 May 2004, Antonio Olinto wrote:

> Hi,
>
> I want to write in x axis label "fitted value of lambda" (lambda in greek
> letter).
>
> xlab=expression(lambda) gives the "lambda", I tryed things like xlab=paste
> ("fitted value of ", expression(lambda)) but I didn't get the greek letter.
>
> Thanks in advance for any hint.
>
> Antonio Olinto
>
>
> -------------------------------------------------
> WebMail Bignet - O seu provedor do litoral
> www.bignet.com.br
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Andrew Robinson			     Ph: 208 885 7115
Department of Forest Resources	     Fa: 208 885 6226
University of Idaho		     E : andrewr at uidaho.edu
PO Box 441133			     W : http://www.uidaho.edu/~andrewr
Moscow ID 83843			     Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From Katarina.Domijan at agresearch.co.nz  Wed May 19 22:47:12 2004
From: Katarina.Domijan at agresearch.co.nz (Domijan, Katarina)
Date: Thu, 20 May 2004 08:47:12 +1200
Subject: [R] greek letters in plots
Message-ID: <4105FF527D8A1D4081C07B1147BF741502DFA8C3@rocket.agresearch.co.nz>

Try 
xlab= (expression("fitted value of "*lambda)) 

Katarina

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Antonio Olinto
> Sent: Thursday, 20 May 2004 8:33 a.m.
> To: R Help
> Subject: [R] greek letters in plots
> 
> Hi,
> 
> I want to write in x axis label "fitted value of lambda" 
> (lambda in greek 
> letter).
> 
> xlab=expression(lambda) gives the "lambda", I tryed things 
> like xlab=paste
> ("fitted value of ", expression(lambda)) but I didn't get the 
> greek letter.
> 
> Thanks in advance for any hint.
> 
> Antonio Olinto
> 
> 
> -------------------------------------------------
> WebMail Bignet - O seu provedor do litoral
> www.bignet.com.br
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
=======================================================================
Attention: The information contained in this message and/or ...{{dropped}}



From ihaka at stat.auckland.ac.nz  Wed May 19 22:57:26 2004
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Thu, 20 May 2004 08:57:26 +1200
Subject: [R] greek letters in plots
In-Reply-To: <1084998752.40abc46089c40@webmail.bignet.com.br>
References: <1084998752.40abc46089c40@webmail.bignet.com.br>
Message-ID: <40ABCA36.4020509@stat.auckland.ac.nz>

Antonio Olinto wrote:
> Hi,
> 
> I want to write in x axis label "fitted value of lambda" (lambda in greek 
> letter).
> 
> xlab=expression(lambda) gives the "lambda", I tryed things like xlab=paste
> ("fitted value of ", expression(lambda)) but I didn't get the greek letter.
> 
> Thanks in advance for any hint.

Try xlab=expression("fitted value of"~lambda) or
xlab=expression("fitted value of "*lambda).
-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand



From ross.lazarus at channing.harvard.edu  Thu May 20 00:33:19 2004
From: ross.lazarus at channing.harvard.edu (Ross Lazarus)
Date: Wed, 19 May 2004 18:33:19 -0400
Subject: [R] Re: R 1.90 make problem with /usr/X11R6/include/X11/Xutil.h on
 suse linux 9.1?
In-Reply-To: <40AAC58F.6070206@channing.harvard.edu>
References: <40AAC58F.6070206@channing.harvard.edu>
Message-ID: <40ABE0AF.9090008@channing.harvard.edu>

Suse problem solved - thanks to Chris Albert for providing a fix to the 
problem on Fedora Core 2 - same fix works a treat for Suse 9.1 - edit 
src/modules/X11/dataentry.c and change the define NeedFunctionProtypes 
to 1 :

> Hi,
> 
> The libtk8.3 dependencies in the R-1.9.0 rpm generate apt conflicts 
> after an upgrade from Fedora Core 1 to Fedora core 2.
> In trying to rebuild the rpm from the source rpm provided on CRAN,
> the build fails when it comes time to compile
> 
> src/modules/X11/dataentry.c
> 
> you get many errors of the form :
>> In file included from dataentry.c:34:
>> /usr/X11R6/include/X11/Xlib.h:1400: error: syntax error before "_Xconst"
>> /usr/X11R6/include/X11/Xlib.h:1488: error: syntax error before "char"
>> /usr/X11R6/include/X11/Xlib.h:1516: error: syntax error before "_Xconst"
>> /usr/X11R6/include/X11/Xlib.h:1520: error: syntax error before "char"
>> /usr/X11R6/include/X11/Xlib.h:1542: error: syntax error before "_Xconst"
> ...
> 
> This could have something to do with the change from X1186 to xorg.
> 
> A workaround is simply to change the line in src/modules/X11/dataentry.c:
>> /* don't use X11 function prototypes (which tend to ...): */
>> #define NeedFunctionPrototypes 0
> to
>  > #define NeedFunctionPrototypes 1 .
> 
> As a patch:
>> diff -crN R-1.9.0.orig/src/modules/X11/dataentry.c R-1.9.0/src/modules/X11/dataentry.c
>> *** R-1.9.0.orig/src/modules/X11/dataentry.c    2004-03-22 06:00:16.000000000 -0500
>> --- R-1.9.0/src/modules/X11/dataentry.c 2004-05-19 11:35:21.903803616 -0400
>> ***************
>> *** 29,35 ****
>>   #include "Print.h"
>>    
>>   /* don't use X11 function prototypes (which tend to ...): */
>> ! #define NeedFunctionPrototypes 0
>>   #include <X11/X.h>
>>   #include <X11/Xlib.h>
>>   #include <X11/Xutil.h>
>> --- 29,35 ----
>>   #include "Print.h"
>>    
>>   /* don't use X11 function prototypes (which tend to ...): */
>> ! #define NeedFunctionPrototypes 1
>>   #include <X11/X.h>
>>   #include <X11/Xlib.h>
>>   #include <X11/Xutil.h>
> 
> Then the rpm builds fine.
> 
> Someone who knows the code will need to confirm that this is an 
> acceptable solution.
> 
> 
> Chris Albert


Ross Lazarus wrote:
> This is probably a Suse specific problem and not a bug in R, but I'm 
> reporting it in case it's useful for someone to know about....
> 
> Trying to compile R1.9.0 from source on a standard Suse 9.1 install 
> (athlon in a shuttle sn41g2).
> configure seems fine but the Suse X11R6 Xlib.h might be toxic.
> 
> In case it helps, here's the sad end to the make output. I can post the 
> Xlib.h if that would help...
> 
> Please email me directly for more information if needed as I don't 
> normally read this list....meanwhile, I'll go try the rpm....
> 
> making rotated.d from rotated.c
> making rbitmap.d from rbitmap.c
> make[4]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules/X11'
> make[4]: Entering directory `/home/rossl/src/R-1.9.0/src/modules/X11'
> gcc -I. -I../../../src/include -I../../../src/include 
> -I/usr/X11R6/include -I/usr/local/include -DHAVE_CONFIG_H 
> -D__NO_MATH_INLINES -mieee-fp -fPIC  -g -O2 -c dataentry.c -o dataentry.lo
> In file included from dataentry.c:31:
> /usr/X11R6/include/X11/Xlib.h:1400: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1488: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:1516: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1520: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:1542: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1577: error: parse error before '*' token
> /usr/X11R6/include/X11/Xlib.h:1586: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1611: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1661: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1667: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1714: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:1753: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:1994: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2078: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2331: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2341: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2413: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2423: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2581: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2596: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2789: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2856: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:2861: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:2975: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3001: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3012: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3037: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3046: error: parse error before "char"
> /usr/X11R6/include/X11/Xlib.h:3059: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3202: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3251: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3283: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3374: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3381: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3401: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3407: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3419: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3429: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3439: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3445: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3546: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3563: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3614: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3657: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3663: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3669: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3675: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3683: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3691: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3699: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3711: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3723: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3770: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3781: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3792: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3803: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3814: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xlib.h:3825: error: parse error before "_Xconst"
> In file included from dataentry.c:32:
> /usr/X11R6/include/X11/Xutil.h:566: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xutil.h:606: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xutil.h:666: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xutil.h:678: error: parse error before "_Xconst"
> /usr/X11R6/include/X11/Xutil.h:801: error: parse error before "_Xconst"
> dataentry.c: In function `GetKey':
> dataentry.c:1272: warning: passing arg 4 of `XLookupString' from 
> incompatible pointer type
> dataentry.c: In function `GetCharP':
> dataentry.c:1281: warning: passing arg 4 of `XLookupString' from 
> incompatible pointer type
> dataentry.c: In function `doControl':
> dataentry.c:1302: warning: passing arg 4 of `XLookupString' from 
> incompatible pointer type
> make[4]: *** [dataentry.lo] Error 1
> make[4]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules/X11'
> make[3]: *** [R] Error 2
> make[3]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules/X11'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/rossl/src/R-1.9.0/src'
> make: *** [R] Error 1
> rossl at small:~/src/R-1.9.0>

-- 
Ross Lazarus MBBS MPH, Director of Bioinformatics
Channing Laboratory, 181 Longwood Ave., Boston MA 02115, USA.
Voice: +617 525 2730  Fax: +617 525 0958



From ok at cs.otago.ac.nz  Thu May 20 01:27:29 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Thu, 20 May 2004 11:27:29 +1200 (NZST)
Subject: [R] Installing packages from ZIP files
Message-ID: <200405192327.i4JNRTh8455033@atlas.otago.ac.nz>

I asked about installing R packages from ZIP files,
specifically with respect to the Rmetrics packages.

"Sean Davis" <sdavis2 at mail.nih.gov> asked:
	Have you tried R CMD INSTALL filename.zip?
	If that didn't work, could you simply unzip filename.zip and
	install using R CMD INSTALL filename?
	If you can't unzip the zip files (using command unzip),
	that may be the problem.
	
Yes, I have tried R CMD INSTALL filename.zip, and it doesn't work.
I can unzip the files, and I get perfectly reasonable-looking
directory trees when I do this (except for the thrice-accursed MS-DOS
carriage returns all over the place, which presumably do R no harm).

f% ls -l *.zip
-rw-r--r--   1 ok       comsci    472733 May 19 13:57 evir_1.0.zip
-rw-r--r--   1 ok       comsci   1391119 May 19 14:01 fBasics_190.10051.zip
-rw-r--r--   1 ok       comsci    255366 May 19 13:56 fExtremes_190.10051.zip
-rw-r--r--   1 ok       comsci    370293 May 19 13:57 fOptions_190.10051.zip
-rw-r--r--   1 ok       comsci    938564 May 19 13:59 fSeries_190.10051.zip
f% unzip -l evir_1.0.zip
Archive:  evir_1.0.zip
 Length    Date    Time    Name
 ------    ----    ----    ----
   1875  11-21-02  14:24   evir/INDEX
     37  11-21-02  14:24   evir/TITLE
   2174  11-21-02  14:24   evir/RCHANGES
   1923  11-21-02  14:24   evir/README
    624  11-21-02  14:24   evir/DESCRIPTION
      0  11-21-02  14:24   evir/R/
  49555  11-21-02  14:24   evir/R/evir
      0  11-21-02  14:24   evir/demo/
    246  11-21-02  14:24   evir/demo/00Index  ...
      0  11-21-02  14:24   evir/data/
    367  11-21-02  14:24   evir/data/00Index  ...
      0  11-21-02  14:24   evir/man/
  41581  11-21-02  14:24   evir/man/evir.Rd   ...
      0  11-21-02  14:24   evir/help/
    644  11-21-02  14:24   evir/help/AnIndex  ...
      0  11-21-02  14:24   evir/html/
   4867  11-21-02  14:24   evir/html/00Index.html ...
   1165  11-21-02  14:24   evir/html/bmw.html
      0  11-21-02  14:24   evir/latex/
    781  11-21-02  14:24   evir/latex/bmw.tex ...
      0  11-21-02  14:24   evir/R-ex/
    295  11-21-02  14:24   evir/R-ex/decluster.R ...
   4971  11-21-02  14:24   evir/CONTENTS
      0  11-21-02  14:24   evir/chtml/
  52043  11-21-02  14:24   evir/chtml/evir.chm
      0  11-21-02  14:24   evir/
 ------                    -------
1150125                    161 files

But

f% /users/local/bin/R CMD INSTALL evir_1.0.zip
gzip: evir_1.0.zip has more than one entry--rest ignored
tar: tape blocksize error
error: cannot extract package from 'evir_1.0.zip':
	No such file or directory for reading errors.
f% /users/local/bin/R CMD INSTALL fBasics_190.10051.zip
gzip: fBasics_190.10051.zip has more than one entry--rest ignored
tar: blocksize = 0
error: cannot extract package from 'fBasics_190.10051.zip':
	No such file or directory for reading errors.
f% /users/local/bin/R CMD INSTALL fExtremes_190.10051.zip
gzip: fExtremes_190.10051.zip has more than one entry--rest ignored
tar: blocksize = 0
error: cannot extract package from 'fExtremes_190.10051.zip':
	No such file or directory for reading errors.

R CMD INSTALL --help
talks about *making* ZIP files, but says nothing about *using* ZIP files.

I would have assumed, on the grounds of silence, that R couldn't install
from ZIP files except that www.rmetrics.org evidently think it *can*.

The suggestion to unzip the file and then pass the name of the
*directory* (not a plain file) to R CMD INSTALL seems to be working.

Perhaps one sentence could be added to ?INSTALL or R CMD INSTALL --help
saying "To install from a ZIP file, first unzip the file and then install
the resulting directory."



From ggrothendieck at myway.com  Thu May 20 03:18:59 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 20 May 2004 01:18:59 +0000 (UTC)
Subject: [R] GUI data browsers
References: <c8g8kk$r24$1@sea.gmane.org>
Message-ID: <loom.20040520T031746-799@post.gmane.org>


This is not a full answer to what you are looking for but you might
try

?browseEnv

 <wwsprague <at> ucdavis.edu> writes:

: 
: Hi R-helpers,
: 
: Does anyone know of a good Tk (or other) script that allows somewhat 
: intuitive viewing of all of the variables (especially complex lists) in 
: a session?  I would also like to delete, save to file, and rename them 
: graphically.  I would also like a lot of supplemental information like 
: class, atrributes, names, modes, whatever else...
: 
: Context:  I am running simulations (demographic) which generate big, 
: complex datastructures that I store as lists of lists of lists of... 
: (you understand).  Some of the components are informational things (like 
: date of the run, the call, etc), while some are results of computation 
: (like eigenvalues of a transition matrix, or generated vectors for each 
: generation).  I vary the parameters and do runs, graph certain pieces of 
: a bunch of runs (like the  largest eigenvalue against a certain 
: parameter across all runs).
: 
: My inspiration (ahem) for this idea is ARCGIS, which, it's other 
: problems aside, is pretty good at helping one keep track of all the 
: various layers that go into a map.
: 
: If this would help anyone, it might be a good project for me to take 
: on--please send feature requests!  I would probably try to extend some 
: of the tcltk examples, especially the tree thingy.
: 
: I *don't* need form based windows for doing analyses.  I am quite 
: comfortable on the command line, I just lose track of all the variables 
: I generate.
: 
: Sorry for the extensive verbiage....
: 
: W



From ggrothendieck at myway.com  Thu May 20 03:30:05 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 20 May 2004 01:30:05 +0000 (UTC)
Subject: [R] POSIX to ts and back to POSIX
References: <OFE18C037F.A481D40B-ON85256E99.00687DA9-85256E99.006AA0A3@epamail.epa.gov>
Message-ID: <loom.20040520T032505-31@post.gmane.org>

Is your question how to convert a vector v containing
seconds since the Epoch to POSIXct?  If that's it, then
one way is:

now <- Sys.time()
Epoch <- now - as.numeric(now)
Epoch + v



 <Allen.Joel <at> epamail.epa.gov> writes:
: 
: I am trying to use POSIX datetime objects rather than chron datetime
: objects but am having difficulty with POSIX in a time series.  My
: question:  Once a POSIXct vector is bound to a time series, is there a
: function to convert back to POSIXct?  The following code demonstrates
: what I am trying to do.
: 
: > ts(as.POSIXct(strptime(tmp,"%m/%d/%Y %H:%M:%S")),freq=1440)
: Time Series:
: Start = c(1, 1)
: End = c(1, 10)
: Frequency = 1440
:  [1] 1074022572 1074022632 1074022693 1074022753 1074022813 1074022874
: 1074022934 1074022994 1074023055 1074023115
: attr(,"tzone")
: [1]
: > as.POSIXct(ts(as.POSIXct(strptime(tmp,"%m/%d/%Y
: %H:%M:%S")),freq=1440))
: Error in as.POSIXct.default(ts(as.POSIXct(strptime(tmp, "%m/%d/%Y
: %H:%M:%S")),  :
:       Don't know how to convert `ts(as.POSIXct(strptime(tmp, "%m/%d/%Y
: %H:%M:%S")), freq = 1440)' to class "POSIXct"
: 
: this does not work either
: 
: > as.POSIXct(as.numeric(as.POSIXct(strptime(tmp,"%m/%d/%Y %H:%M:%S"))))
: Error in as.POSIXct.default(as.numeric(as.POSIXct(strptime(tmp,
: "%m/%d/%Y %H:%M:%S")))) :
:       Don't know how to convert `as.numeric(as.POSIXct(strptime(tmp,
: "%m/%d/%Y %H:%M:%S")))' to class "POSIXct"
: 
: Thanks in advance.
: 
: H. Joel Allen, PhD
: Environmental Scientist
: U.S. EPA
: NRMRL, Water Quality Management Branch
: 26 W. Martin Luther King Dr
: Cincinnati, OH 45268
: 
: Phone: 513 487-2806
: Fax: 513 569-7052
: Email: allen.joel <at> epa.gov
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From kuroki at oak.dti.ne.jp  Thu May 20 04:02:41 2004
From: kuroki at oak.dti.ne.jp (Chihiro Kuroki)
Date: Thu, 20 May 2004 11:02:41 +0900
Subject: [R] pmvt problem in multcomp
Message-ID: <87vfirzwhq.wl@oak.dti.ne.jp>

Hi, all:

Two examples are shown below. 

I want to use the multiple comparison of Dunnett.
It succeeded in upper case "example 1". 

However, the lower case "example 2" went wrong. 

In "example 2", the function pmvt return NaN, so I cannot show
this simtest result. Is there any solution?

(I changed the variable "maxpts" to a large number in front of
the function pmvt ... but, the function mvt returned an error. )

-- example 1 -------------------------------
require(multcomp)
Loading required package: multcomp 
Loading required package: mvtnorm 
[1] TRUE

y <- as.vector(t$int)
f <- as.factor(t$group1)

table(f)
f
    1     2     3 
20988 20988 20988 

dat <- cbind(as.data.frame(y),f)
gc()
summary(simtest(y ~ f, data=dat, type="Dunnett"))

	 Simultaneous tests: Dunnett contrasts 

Call: 
simtest.formula(formula = y ~ f, data = dat, type = "Dunnett")

	 Dunnett contrasts for factor f

Contrast matrix:
        f1 f2 f3
f2-f1 0 -1  1  0
f3-f1 0 -1  0  1


Absolute Error Tolerance:  0.001 

Coefficients:
      Estimate t value Std.Err. p raw p Bonf p adj
f2-f1    4.015  -0.677    5.934 0.499  0.997 0.722
f3-f1    2.486  -0.419    5.934 0.675  0.997 0.722
---------------------------------

-- example 2 -------------------------------
require(multcomp)
Loading required package: multcomp 
Loading required package: mvtnorm 
[1] TRUE

y <- as.vector(t$int)
f <- as.factor(t$group2)
table(f)
f
     1      2      3      4      5 
104940 104940 104940 104940 104940 

dat <- cbind(as.data.frame(y),f)
gc()
summary(simtest(y ~ f, data=dat, type="Dunnett"))

[1] "des <- model.matrix(ff, mf)"
  (Intercept) aaa1 aaa2 aaa3 aaa4
1           1    1    0    0    0
2           1    0    1    0    0
3           1    0    0    1    0
4           1    0    0    0    1
attr(,"assign")
[1] 0 1 1 1 1
attr(,"contrasts")
attr(,"contrasts")$aaa
[1] "ct"

[1] "gls     <- rep(0,nrow(contonly))"
[1] 0 0 0 0

[1] "gls[i1]    <- 1-prob"
[1] NaN   0   0   0
[1] "gls[i1]    <- 1-prob"
[1] NaN NaN   0   0
[1] "gls[i1]    <- 1-prob"
[1]          NaN          NaN -7.01661e-14  0.00000e+00
[1] "gls[i1]    <- 1-prob"
[1]           NaN           NaN -7.016610e-14  3.362133e-11

[1] "glsbig"
  aaa1 aaa2         aaa3         aaa4
1  NaN  NaN          NaN          NaN
2  NaN  NaN          NaN          NaN
3    0    0 -7.01661e-14 0.000000e+00
4    0    0  0.00000e+00 3.362133e-11

[1] "glsp"
aaa1 aaa2 aaa3 aaa4 
 NaN  NaN  NaN  NaN 
Error in if (glsp[i] < glsp[i - 1]) { : missing value where TRUE/FALSE needed
Execution halted
---------------------------------

-- 
kuroki at oak.dti.ne.jp
GnuPG fingerprint = 90FD FE79 905F 26F9 29C4  096F 8AA2 2C42 5130 1469



From MDavy at hortresearch.co.nz  Thu May 20 04:38:32 2004
From: MDavy at hortresearch.co.nz (Marcus Davy)
Date: Thu, 20 May 2004 14:38:32 +1200
Subject: [R] Accessing more than 2GB memory in Windows
Message-ID: <s0acc30c.007@hrp3.palm.cri.nz>


Hi,
I am also interested in the same topic, that is windows 32bit
restriction to 4Gigs of virtual 
address space partitioning into User and System space.
For your reconfigured server 3:1 User to System space what does

memory.limit()

say is available?

For those interested a windows FAQ link on this subject is

http://www.stats.ox.ac.uk/pub/R/rw-FAQ.html#There%20seems%20to%20be%20a%20limit%20on%20the%20memory%20it%20uses!



marcus


>>> "Steve Jernigan - PA" <sjerniga at GMACCM.com> 20/05/2004 7:58:37 AM
>>>
Greetings,

Can anyone confirm that R can access more than 2GB 
of virtual memory on Windows? We are in the process
of porting a memory-hungry routine from Linux.

We are using R 1.8.1 on Windows 2000 Advanced Server;
we've set the 3GB switch in boot.ini, and rebooted
twice. We have run editbin against Rgui.exe ad Rterm.exe
and confirmed the header settings with dumpbin.exe.

We are invoking R with 
"C:\Program Files\R\rw1081\bin\Rgui" --max-mem-size=3G

Does anyone have a simple script that they have used to
confirm that R can access more than 2GB? We have tried
a few without success.

Regards,

Steve Jernigan

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

______________________________________________________

The contents of this e-mail are privileged and/or confidenti...{{dropped}}



From ok at cs.otago.ac.nz  Thu May 20 05:01:20 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Thu, 20 May 2004 15:01:20 +1200 (NZST)
Subject: Windows versus Unix packages in CRAN (Was Re: [R] Rmetrics)
Message-ID: <200405200301.i4K31KIp454163@atlas.otago.ac.nz>

Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
	mkdir fBasics
	unzip fBasics.zip -d fBasics
	rm fBasics/src/*.o
	R CMD check fBasics
	
	and that took me about 3 minutes.

Now me, I just did

	unzip -a fBasics_190.10051.zip
	R CMD INSTALL fBasics
	rm -rf fBasics

in a naive and trusting manner.  It took me considerably longer than 3
minutes to learn that this was what I should do, and when I did learn,
I wondered "if it's this simple, why can't R CMD INSTALL do it?"

Now I discover that it isn't that simple.  The installation apparently
went smoothly.  This is R, right?  Never occurred to me that there might
be problems.

Now, B-G--R!  It turns out that core stuff is supplied as .dll files,
which of course my UltraSPARC can do nothing with.

The author of the Rmetrics code has a perfect right to provide his code
in any form he wants under any conditions he wants (subject to GPL &c).
In particular, if he wants to provide a distribution which only works under
Windows, that's perfectly OK.

**BUT** when a distribution is peculiar to one operating system, that really
should be highlighted in big bold letters:  this is a WINDOWS BINARY
version, so that people who can't use Windows .DLL files are spared a day
of trying to figure out how to unpack and of doing an installation which
reports no errors at all and of them finding that things do not work.

There is *NOTHING* on http://www.itp.phys.ethz.ch/econophysics/R/download.htm
that says "Windows only".  Click on "I accept"and the page you arrive at has
nothing in the text anywhere that says "Windows only" or "what to do if not
Windows".  (The http://.../R/bin/windows/contrib/1.9 address of the page
was, in retrospect, a big clue, sigh.)

	It would of course be nice if the developers had done
	
	R CMD check fBasics

But if you go into the Sources directory, which I suppose you must have,
for each of {fBasics,fExtremes,fOptions,fSeries} there is an
xxx-00check.log.txt, so they _did_ run R CMD check.

	and sorted out the errors, then
	R CMD build fBasics
	
Those same check logs show errors (like failure to build .dvi files).

Will it work if I download the Sources packages?



From dvanbrunt at well-wired.com  Thu May 20 05:52:26 2004
From: dvanbrunt at well-wired.com (David L. Van Brunt, Ph.D.)
Date: Wed, 19 May 2004 22:52:26 -0500
Subject: [R] Memory Leak in OS X version of R?
Message-ID: <BCD195AA.912F%dvanbrunt@well-wired.com>

This is the conclusion from a prior thread ([R] " cannot allocate vector of
length 1072693248") which ended with no other answer but that there must be
a problem in the OS X version of R, or in the compile of the source on OS X.

I??ve posted code and data here:
http://www.well-wired.com/reflibrary/uploads/1084503247.zip

If you setwd() into the directory that is made, then ??source()?? the ??.R??
file, it should run fine on Windows but crash on any machine with OS X
(Panther) giving: ??Error in as.vector(data) : cannot allocate vector of
length 1073741824?? after a few iterations of the loop.

I've repeated this on a Powerbook G4 with 500 MB of RAM, an iMac with 128M
of RAM, and a Dual 2GHz G5 with 1.5 Gig of RAM. Have used the Raqua, the
Frameworks installation, and a fresh compile of the source using Fink in the
X11 implementation. No matter the machine or the version (1.8x through 1.9,
OS X or Unix X11), I get the same result.

Thanks to Andy Liaw for helping me tune the code this far.

I'm stumped. Would love to hear others' experience with this, and if they
can reproduce the problem elsewhere.


-- 
David L. Van Brunt, Ph.D.
Outlier Consulting & Development
mailto: <ocd at well-wired.com>



From mcclatchie.sam at saugov.sa.gov.au  Thu May 20 06:53:46 2004
From: mcclatchie.sam at saugov.sa.gov.au (McClatchie, Sam (PIRSA-SARDI))
Date: Thu, 20 May 2004 14:23:46 +0930
Subject: [R] irregular time series
Message-ID: <032A8573186A2B4EBBAEFA5784D0523555A155@sagemsg0007.sagemsmrd01.sa.gov.au>

Background:
OS: Linux Mandrake 9.1
release: R 1.9.0 
editor: Xemacs 21.4
frontend: ESS 5.1.23
---------------------------------

Colleagues

I have two time series (upwelling index and water temperature) of evenly
spaced, daily data over 18 months, but the upwelling index  series has a gap
of about 2 months right in the middle of it. I want to do the acf, pacf,
ccf, and a cross-spectral analysis of the two series.

I realise that I could just break each series into two segments and
cross-correlate with the shorter series, but I'd rather deal with the whole
series to increase the nyquist frequency. I think the its function in the
irregular time series package will create a class its object with the right
time stamps, but can this then be used in the same was as a class ts object
for the correlation and spectral anayses?  

Sam
----
Sam McClatchie,
Sub-program leader, Pelagic Fisheries
South Australian Aquatic Sciences Centre
PO Box 120, Henley Beach 5022
Adelaide, South Australia
email <mcclatchie.sam at saugov.sa.gov.au>
Telephone: (61-8) 8200 2448
FAX: (61-8) 8200 2481
Research home page <http://www.smcc.150m.com/>
  
                   /\
      ...>><xX(??> 
                //// \\\\
                   <??)Xx><<
              /////  \\\\\\
                        ><(((??> 
  >><(((??>   ...>><xX(??>O<??)Xx><<



From wasserberg at wisc.edu  Thu May 20 07:11:46 2004
From: wasserberg at wisc.edu (GIDEON WASSERBERG)
Date: Wed, 19 May 2004 23:11:46 -0600
Subject: [R] Repeated measures ANOVA
Message-ID: <8e1e48d815.8d8158e1e4@wiscmail.wisc.edu>


  
 
Dear friends

I am not sure that I am conducting this analysis correctly. I would really appreciate if someone can verify what I've done.
I conducted repeated measures ANOVA for some bugs data. These bugs were measured repeatedly over 32 weeks at the same trapping plots. I want to test a full model for the effect of time ("week") (the "within subject" variable), and the main effects are: place, station,species, and all the interactions thereof.

Below, I pasted the commands I used, the analysis output, and a segment of my data (2 out of the 32 weeks) in order to show how I coded the data. 

> Rep1<-read.csv("C:/Documents and Settings/Gideon/My Documents/Vasily-Alon paper/Seasonal2.csv")
> summary(aov(Total~Place*Station*Species*Week+Error(Subject/Week),data=Rep1)
+ )


Output:

Error: Subject
      Df Sum Sq Mean Sq
Place  1 2570.3  2570.3

Error: Subject:Week
     Df Sum Sq Mean Sq
Week  1 977.08  977.08

Error: Within
                             Df Sum Sq Mean Sq F value    Pr(>F)    
Place                         2   9764    4882 45.4435 < 2.2e-16 ***
Station                       3   7120    2373 22.0930 5.068e-14 ***
Species                       4  35145    8786 81.7883 < 2.2e-16 ***
Week                          1      5       5  0.0421 0.8374211    
Place:Station                 3   1355     452  4.2048 0.0056664 ** 
Place:Species                10  44468    4447 41.3934 < 2.2e-16 ***
Station:Species              15  20277    1352 12.5833 < 2.2e-16 ***
Place:Week                    2   1674     837  7.7894 0.0004298 ***
Station:Week                  3   2617     872  8.1194 2.286e-05 ***
Species:Week                  4   4104    1026  9.5500 1.244e-07 ***
Place:Station:Species        15   6155     410  3.8196 9.862e-07 ***
Place:Station:Week            3    457     152  1.4188 0.2355024    
Place:Species:Week           10   5830     583  5.4268 5.984e-08 ***
Station:Species:Week         15   4484     299  2.7826 0.0002802 ***
Place:Station:Species:Week   15   3363     224  2.0867 0.0084501 ** 
Residuals                  1620 174033     107                      
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> 


Data:

Subject Place Station Species Week Total
1 Amnun Garden Aa 1 1
2 Amnun Garden As 1 0
3 Amnun Garden Lp 1 0
4 Amnun Garden Ls 1 0
5 Amnun Garden Lt 1 1
6 Amnun Garden Ps 1 0
7 Amnun Grass Aa 1 0
8 Amnun Grass As 1 0
9 Amnun Grass Lp 1 0
10 Amnun Grass Ls 1 0
11 Amnun Grass Lt 1 0
12 Amnun Grass Ps 1 0
13 Amnun Rocks Aa 1 1
14 Amnun Rocks As 1 0
15 Amnun Rocks Lp 1 0
16 Amnun Rocks Ls 1 0
17 Amnun Rocks Lt 1 0
18 Amnun Rocks Ps 1 0
19 Korazim 1 Garden Aa 1 0
20 Korazim 1 Garden As 1 0
21 Korazim 1 Garden Lp 1 0
22 Korazim 1 Garden Ls 1 0
23 Korazim 1 Garden Lt 1 0
24 Korazim 1 Garden Ps 1 0
25 Korazim 1 Grass Aa 1 0
26 Korazim 1 Grass As 1 0
27 Korazim 1 Grass Lp 1 0
28 Korazim 1 Grass Ls 1 0
29 Korazim 1 Grass Lt 1 0
30 Korazim 1 Grass Ps 1 0
31 Korazim 1 Rocks Aa 1 0
32 Korazim 1 Rocks As 1 0
33 Korazim 1 Rocks Lp 1 0
34 Korazim 1 Rocks Ls 1 0
35 Korazim 1 Rocks Lt 1 3
36 Korazim 1 Rocks Ps 1 0
37 Korazim 2 Garden Aa 1 0
38 Korazim 2 Garden As 1 0
39 Korazim 2 Garden Lp 1 0
40 Korazim 2 Garden Ls 1 0
41 Korazim 2 Garden Lt 1 0
42 Korazim 2 Garden Ps 1 0
43 Korazim 2 Ochard Aa 1 0
44 Korazim 2 Ochard As 1 0
45 Korazim 2 Ochard Lp 1 0
46 Korazim 2 Ochard Ls 1 0
47 Korazim 2 Ochard Lt 1 0
48 Korazim 2 Ochard Ps 1 0
49 Korazim 2 Rocks Aa 1 0
50 Korazim 2 Rocks As 1 0
51 Korazim 2 Rocks Lp 1 0
52 Korazim 2 Rocks Ls 1 0
53 Korazim 2 Rocks Lt 1 4
54 Korazim 2 Rocks Ps 1 0
1 Amnun Garden Aa 2 0
2 Amnun Garden As 2 0
3 Amnun Garden Lp 2 0
4 Amnun Garden Ls 2 0
5 Amnun Garden Lt 2 1
6 Amnun Garden Ps 2 0
7 Amnun Grass Aa 2 0
8 Amnun Grass As 2 0
9 Amnun Grass Lp 2 0
10 Amnun Grass Ls 2 0
11 Amnun Grass Lt 2 0
12 Amnun Grass Ps 2 0
13 Amnun Rocks Aa 2 0
14 Amnun Rocks As 2 0
15 Amnun Rocks Lp 2 0
16 Amnun Rocks Ls 2 0
17 Amnun Rocks Lt 2 0
18 Amnun Rocks Ps 2 0
19 Korazim 1 Garden Aa 2 0
20 Korazim 1 Garden As 2 0
21 Korazim 1 Garden Lp 2 0
22 Korazim 1 Garden Ls 2 0
23 Korazim 1 Garden Lt 2 0
24 Korazim 1 Garden Ps 2 0
25 Korazim 1 Grass Aa 2 0
26 Korazim 1 Grass As 2 0
27 Korazim 1 Grass Lp 2 0
28 Korazim 1 Grass Ls 2 0
29 Korazim 1 Grass Lt 2 0
30 Korazim 1 Grass Ps 2 0
31 Korazim 1 Rocks Aa 2 0
32 Korazim 1 Rocks As 2 0
33 Korazim 1 Rocks Lp 2 0
34 Korazim 1 Rocks Ls 2 0
35 Korazim 1 Rocks Lt 2 1
36 Korazim 1 Rocks Ps 2 0
37 Korazim 2 Garden Aa 2 0
38 Korazim 2 Garden As 2 0
39 Korazim 2 Garden Lp 2 0
40 Korazim 2 Garden Ls 2 0
41 Korazim 2 Garden Lt 2 0
42 Korazim 2 Garden Ps 2 0
43 Korazim 2 Ochard Aa 2 0
44 Korazim 2 Ochard As 2 0
45 Korazim 2 Ochard Lp 2 0
46 Korazim 2 Ochard Ls 2 0
47 Korazim 2 Ochard Lt 2 0
48 Korazim 2 Ochard Ps 2 0
49 Korazim 2 Rocks Aa 2 0
50 Korazim 2 Rocks As 2 0
51 Korazim 2 Rocks Lp 2 0
52 Korazim 2 Rocks Ls 2 0
53 Korazim 2 Rocks Lt 2 4
54 Korazim 2 Rocks Ps 2 0


Very Much obliged


Gideon Wasserberg 
Wildlife research unit,
Department of wildlife ecology,
University of Wisconsin
218 Russell labs, 1630 Linden dr.,
Madison, Wisconsin 53706, USA.
Tel.:608 265 2130, Fax: 608 262 6099



From jkawczak at math.uncc.edu  Thu May 20 08:08:25 2004
From: jkawczak at math.uncc.edu (Janusz Kawczak)
Date: Thu, 20 May 2004 02:08:25 -0400
Subject: Windows versus Unix packages in CRAN (Was Re: [R] Rmetrics)
References: <200405200301.i4K31KIp454163@atlas.otago.ac.nz>
Message-ID: <40AC4B59.8E857FC4@math.uncc.edu>

And it seems that this vicious circle continues forever. Before
posting these kind of messages can you please read the INSTRUCTIONS.
fBasics_190.10051.zip is a COMPILED version of the package, not
a source as you claim to be!

It works with no problems; well, at least under Linux.

Janusz.

"Richard A. O'Keefe" wrote:

> Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>         mkdir fBasics
>         unzip fBasics.zip -d fBasics
>         rm fBasics/src/*.o
>         R CMD check fBasics
>
>         and that took me about 3 minutes.
>
> Now me, I just did
>
>         unzip -a fBasics_190.10051.zip
>         R CMD INSTALL fBasics
>         rm -rf fBasics
>
> in a naive and trusting manner.  It took me considerably longer than 3
> minutes to learn that this was what I should do, and when I did learn,
> I wondered "if it's this simple, why can't R CMD INSTALL do it?"
>
> Now I discover that it isn't that simple.  The installation apparently
> went smoothly.  This is R, right?  Never occurred to me that there might
> be problems.
>
> Now, B-G--R!  It turns out that core stuff is supplied as .dll files,
> which of course my UltraSPARC can do nothing with.
>
> The author of the Rmetrics code has a perfect right to provide his code
> in any form he wants under any conditions he wants (subject to GPL &c).
> In particular, if he wants to provide a distribution which only works under
> Windows, that's perfectly OK.
>
> **BUT** when a distribution is peculiar to one operating system, that really
> should be highlighted in big bold letters:  this is a WINDOWS BINARY
> version, so that people who can't use Windows .DLL files are spared a day
> of trying to figure out how to unpack and of doing an installation which
> reports no errors at all and of them finding that things do not work.
>
> There is *NOTHING* on http://www.itp.phys.ethz.ch/econophysics/R/download.htm
> that says "Windows only".  Click on "I accept"and the page you arrive at has
> nothing in the text anywhere that says "Windows only" or "what to do if not
> Windows".  (The http://.../R/bin/windows/contrib/1.9 address of the page
> was, in retrospect, a big clue, sigh.)
>
>         It would of course be nice if the developers had done
>
>         R CMD check fBasics
>
> But if you go into the Sources directory, which I suppose you must have,
> for each of {fBasics,fExtremes,fOptions,fSeries} there is an
> xxx-00check.log.txt, so they _did_ run R CMD check.
>
>         and sorted out the errors, then
>         R CMD build fBasics
>
> Those same check logs show errors (like failure to build .dvi files).
>
> Will it work if I download the Sources packages?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From petr.pikal at precheza.cz  Thu May 20 10:13:19 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 20 May 2004 10:13:19 +0200
Subject: [R] symbol size in plot
In-Reply-To: <1084961058.19281.10.camel@maximir>
Message-ID: <40AC84BF.6755.8D1222@localhost>



On 19 May 2004 at 12:04, Ulrich Leopold wrote:

> Dear list,
> 
>  I have been reading the archives already but I do not manage to plot
> the correct size of symbols without running into other problems.
> 
> When I use the syntax below I get the size of symbols and text right
> but the text overlays on top of the axis rather than be in the right
> position when you using the defaults for plot. Furthermore the ticks
> of the axis appear to be too small. Is there a way of getting things
> correct like in the default plot?

Hi

I am not sure what do you want to accomplish. What is wrong on default plot.
If you want to shrink just points use cex in

par(mfrow=c(2,2))
plot(x,y, pch=16, cex=0.2)

and if you want to enlarge some characters in plot use cex.axis or cex.... 
according to par help page

e.g.

plot(x,y, pch=16, cex=0.2, cex.lab=2, cex.axis=2)

par(mfrow=c(2,2))
plot(1:10,1:10)
plot(1:10,1:10, cex=.2)
plot(1:10,1:10, cex=.2, cex.axis=2)
plot(1:10,1:10, cex=.2, cex.axis=2, cex.lab=2)

I suppose that in your definition of par you first shrink all points and characters in 
plot to 0.2 of their default size and then you increase the size of some 5 times e.g. 
to the default size, but I may be wrong.

Cheers
Petr



> 
> 
> par(mfrow=c(2,2),cex=0.2, cex.main=5, cex.sub=5, cex.axis=5,pch=16)
> plot(x,y)
> 
> 
> 
> Regards, Ulrich
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From petr.pikal at precheza.cz  Thu May 20 10:28:34 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 20 May 2004 10:28:34 +0200
Subject: [R] Finding indices where
In-Reply-To: <a0e726a0c5a1.a0c5a1a0e726@jhsph.edu>
Message-ID: <40AC8852.28215.9B0935@localhost>



On 19 May 2004 at 13:26, Ravi Varadhan wrote:

> Hi:
> 
> Suppose I have the following vector:
> 
> > x <- c(1,4:8,11,13:14,17,19,23:28,35:38)
> > x
>  [1]  1  4  5  6  7  8  11 13 14 17 19 23 24 25 26 27 28 35 36 37 38 >
> 
> 
> and I would like to pick out the first and last indices of all the
> consecutive "runs" of integers, where the length of a run is no
> smaller than a specified value, say, nmin.  That is, in the above
> example, for nmin=4, I would like to get the following 3 by 2 matrix:
> 
> 4 8
> 23 28
> 35 38
> 
> For nmin=5, I would get the following 2 by 2 matrix
> 
> 4 8
> 23 28
> 
> and for nmin=6, I would get the following 1 by 2 matrix
> 
> 23 28
> 
> Is there an efficient and elegant way to do this?

Hallo
not complete maybe not ellegant but

y<-rle(diff(x))
res1<-x[(cumsum(y$length))[y$length>1]]+1
res2<-res1-y$length[y$length>1]

gives you the numbers you want in two vectors (res1,  res2). Than you can do 
any formating and selection you want.

Cheers
Petr

> 
> Thanks very much for any help/suggestions.
> Ravi.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From quietroom78 at hotmail.com  Thu May 20 11:57:48 2004
From: quietroom78 at hotmail.com (bang jeong sook)
Date: Thu, 20 May 2004 09:57:48 +0000
Subject: [R] function for running MS-DOS from R
Message-ID: <BAY16-F8yzu23LiC1h1000333cc@hotmail.com>


I had downloaded the program that runs on MS-DOS.
Is it possible for MS-DOS to be run in R such as WinBugs1.4?
I wonder whether there is the R function for running MS-DOS from R.

_________________________________________________________________



From dave at evocapital.com  Thu May 20 12:52:12 2004
From: dave at evocapital.com (David Khabie-Zeitoune)
Date: Thu, 20 May 2004 11:52:12 +0100
Subject: [R] quadratic problem with quadratic constraint
Message-ID: <8D0F30FE2EB3314182D4A33F738BB19D17977C@sqlsrvr.evocapital.com>

Sure -- just use a Lagrangian multiplier to bring the constraint into the objective function and then use a QP routine like quadprog (in the quadprog library). You will need to run an *outer* optimisation to find the value of the Langrangian multiplier.

-----Original Message-----
From: Ramzi TEMANNI [mailto:ramzi.temanni at laposte.net] 
Sent: 14 May 2004 11:27
To: r-help at stat.math.ethz.ch
Subject: [R] quadratic problem with quadratic constraint


Hi all,
Can we solve Quadratic Program with Quadratic Constraint in R ?




Regards,

TEMANNI Ramzi
DEA Student
Lim&Bio
http://www.limbio-paris13.org
UFR de Sant??, M??decine et Biologie Humaine (SMBH) 
L??onard de Vinci 74, rue Marcel Cachin
93017 Bobigny Cedex
France.
T??l : 01.48.38.73.07
T??l : 06.21.43.27.59
temanni.ramzi at free.fr
http://temanni.ramzi.free.fr

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Thu May 20 13:22:20 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 20 May 2004 11:22:20 +0000 (UTC)
Subject: [R] function for running MS-DOS from R
References: <BAY16-F8yzu23LiC1h1000333cc@hotmail.com>
Message-ID: <loom.20040520T131947-58@post.gmane.org>

bang jeong sook <quietroom78 <at> hotmail.com> writes:

> 
> I had downloaded the program that runs on MS-DOS.
> Is it possible for MS-DOS to be run in R such as WinBugs1.4?
> I wonder whether there is the R function for running MS-DOS from R.

On my XP system this works:

R> system("cmd")

to drop into the Windows command line and exit at the
Windows command line get you back.  

One can slso do this:

R> system("cmd /c dir > listing.txt")
R> listing <- readLines("listing.txt")



From rxg218 at psu.edu  Thu May 20 16:11:32 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Thu, 20 May 2004 10:11:32 -0400
Subject: [R] column sorting a matrix with indices returned
Message-ID: <1085062292.10562.11.camel@blue.chem.psu.edu>

Hi,
  I'm trying to translate some Matlab code to R and I'm trying to
implement the behavior of Matlab's sort() which when applied to a matrix
will sort the columns returning the column  sorted matrix as well as a
matrix of permuted indices.

Doing:

> x <- matrix(c(3,4,2,6,3,4,8,7,5), nr=3)
> x
     [,1] [,2] [,3]
[1,]    3    6    8
[2,]    4    3    7
[3,]    2    4    5

What I want after sorting x are two matrices:

(the column sorted x)
2 3 5
3 4 7
4 6 8

and (the index matrix)
3 2 3
1 3 2
2 1 1

Doing,
> sx <- apply(x, c(2), sort, index.return=T)

results in sx being a series of lists. I know I could then go through
the list and create a sorted matrix and an index matrix. 

But is there a neater way to do this?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Accuracy, n.:
The vice of being right



From vito.muggeo at giustizia.it  Thu May 20 16:17:55 2004
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Thu, 20 May 2004 16:17:55 +0200
Subject: R: [R] column sorting a matrix with indices returned
References: <1085062292.10562.11.camel@blue.chem.psu.edu>
Message-ID: <02a401c43e75$41db3fc0$5c13070a@PROCGEN>

A possible solution is using apply + order:

> apply(x,2,order)
     [,1] [,2] [,3]
[1,]    3    2    3
[2,]    1    3    2
[3,]    2    1    1
> apply(x,2,function(x)x[order(x)])
     [,1] [,2] [,3]
[1,]    2    3    5
[2,]    3    4    7
[3,]    4    6    8
>

best,
vito


----- Original Message -----
From: Rajarshi Guha <rxg218 at psu.edu>
To: R <r-help at stat.math.ethz.ch>
Sent: Thursday, May 20, 2004 4:11 PM
Subject: [R] column sorting a matrix with indices returned


> Hi,
>   I'm trying to translate some Matlab code to R and I'm trying to
> implement the behavior of Matlab's sort() which when applied to a matrix
> will sort the columns returning the column  sorted matrix as well as a
> matrix of permuted indices.
>
> Doing:
>
> > x <- matrix(c(3,4,2,6,3,4,8,7,5), nr=3)
> > x
>      [,1] [,2] [,3]
> [1,]    3    6    8
> [2,]    4    3    7
> [3,]    2    4    5
>
> What I want after sorting x are two matrices:
>
> (the column sorted x)
> 2 3 5
> 3 4 7
> 4 6 8
>
> and (the index matrix)
> 3 2 3
> 1 3 2
> 2 1 1
>
> Doing,
> > sx <- apply(x, c(2), sort, index.return=T)
>
> results in sx being a series of lists. I know I could then go through
> the list and create a sorted matrix and an index matrix.
>
> But is there a neater way to do this?
>
> Thanks,
>
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> Accuracy, n.:
> The vice of being right
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From rxg218 at psu.edu  Thu May 20 16:22:45 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Thu, 20 May 2004 10:22:45 -0400
Subject: [R] column sorting a matrix with indices returned
In-Reply-To: <1085062292.10562.11.camel@blue.chem.psu.edu>
References: <1085062292.10562.11.camel@blue.chem.psu.edu>
Message-ID: <1085062964.10562.15.camel@blue.chem.psu.edu>

On Thu, 2004-05-20 at 10:11, Rajarshi Guha wrote:
> Hi,
>   I'm trying to translate some Matlab code to R and I'm trying to
> implement the behavior of Matlab's sort() which when applied to a matrix
> will sort the columns returning the column  sorted matrix as well as a
> matrix of permuted indices.
> 
> Doing:
> 
> > x <- matrix(c(3,4,2,6,3,4,8,7,5), nr=3)
> > x
>      [,1] [,2] [,3]
> [1,]    3    6    8
> [2,]    4    3    7
> [3,]    2    4    5
> 
> What I want after sorting x are two matrices:
> 
> (the column sorted x)
> 2 3 5
> 3 4 7
> 4 6 8
> 
> and (the index matrix)
> 3 2 3
> 1 3 2
> 2 1 1

I worked out a way:

sorted <- apply(x, c(2), sort, index.return=T)

sortedmatrix <- matrix(unlist(lapply(sorted, function(x) { x$x })),
nr=length(sortstruct))

sortedindices <- matrix(unlist(lapply(sorted, function(x) { x$ix })),
nr=length(sorted))

Is this efficient, as the matrices will be large  (or can it be made
into a 1 liner)?


-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
A man is known by the company he organizes.
-- Ambrose Bierce



From RBaskin at ahrq.gov  Thu May 20 16:25:03 2004
From: RBaskin at ahrq.gov (Baskin, Robert)
Date: Thu, 20 May 2004 10:25:03 -0400
Subject: [R] mixed models for analyzing survey data with unequal selec
	tion  probability
Message-ID: <6BCD3F430455B1418750004BCD27925905C6D6@exchange2.ahrq.gov>

Han-Lin

I don't think I have seen a reply so I will suggest that maybe you could try
a different approach than what you are thinking about doing.  I believe the
current best practice is to use the weights as a covariate in a regression
model - and bytheway - the weights are the inverse of the probabilities of
selection - not the probabilities.

Fundamentally, there is a difficulty in making sense out of 'random effects'
in a finite population setting.

(plagiarized from some unknown source)
See: < 9. Pfeffermann, D. , Skinner, C. J. , Holmes, D. J. , Goldstein, H. ,
and Rasbash, J.  (1998), ``Weighting for unequal selection probabilities in
multilevel models (Disc: p41-56)'', Journal of the Royal Statistical
Society, Series B, Methodological, 60 , 23-40 >

which refers back to:
<29. Pfeffermann, D. , and LaVange, L.  (1989), ``Regression models for
stratified multi-stage cluster samples'', Analysis of Complex Surveys,
237-260 >

If you don't like statistical papers, then see section 4.5 of <8. Korn,
Edward Lee , and Graubard, Barry I.  (1999), ``Analysis of health surveys'',
John Wiley & Sons (New York; Chichester) > They explain the idea of using
weights in a model fairly simply.

Bob


-----Original Message-----
From: Han-Lin Lai [mailto:Han-Lin.Lai at noaa.gov] 
Sent: Wednesday, May 19, 2004 12:47 PM
To: r-help at stat.math.ethz.ch
Subject: [R] mixed models for analyzing survey data with unequal selection
probability

Hi,

I need the help on this topic because this is out of my statistical
trianing as biologist.  Here is my brief description of the problem.

I have a survey that VESSELs are selected at random with the probability
of p(j).  Then the tows within the jth VESSEL are sampled at random with
probability of p(i|j).  I write my model as

y = XB + Zb + e
where XB is fixed part, Zb is for random effect (VESSEL) and e is
within-vessel error.

I feel that I should weight the Zb part by p(j) and the e-part by
p(i,j)=p(j)*p(i|j). Is this a correct weighting?

How can I implement the weightings in nlme (or lme)?  I think that
p(i,j) can be specified by nlme(..., weights=p(i,j),...)?  Where is p(j)
to be used in nlme?

I appreciate anyone can provide examples and literature for this
problem.

Cheers!
Han



From tlumley at u.washington.edu  Thu May 20 17:14:34 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 20 May 2004 08:14:34 -0700 (PDT)
Subject: [R] mixed models for analyzing survey data with unequal selec
	tion  probability
In-Reply-To: <6BCD3F430455B1418750004BCD27925905C6D6@exchange2.ahrq.gov>
References: <6BCD3F430455B1418750004BCD27925905C6D6@exchange2.ahrq.gov>
Message-ID: <Pine.A41.4.58.0405200805530.98828@homer35.u.washington.edu>

On Thu, 20 May 2004, Baskin, Robert wrote:

> Han-Lin
>
> I don't think I have seen a reply so I will suggest that maybe you could try
> a different approach than what you are thinking about doing.  I believe the
> current best practice is to use the weights as a covariate in a regression
> model - and bytheway - the weights are the inverse of the probabilities of
> selection - not the probabilities.
>
> Fundamentally, there is a difficulty in making sense out of 'random effects'
> in a finite population setting.

I would have thought that it matters why you are fitting a mixed model.
Often people use mixed models when they are just interested in inference
about the mean and need to model the covariances to get valid standard
errors. In that situation you could use an ordinary survey regression to
get a design-based result.

If you are actually interested in variance components then you need some
other approach, and putting the weights into the model as a covariate will
presumably give a valid model-based result (since the weights carry all
the biased sampling information --- like a propensity score).  Presumably
this is also more efficient.

However, it could well be that you don't want those variables in the
model. If the sampling depends on a variable Z correlated with Y and X and
you want to model the distribution of Y given X, not the distribution of Y
given X and Z, you are still in trouble.


	-thomas



> (plagiarized from some unknown source)
> See: < 9. Pfeffermann, D. , Skinner, C. J. , Holmes, D. J. , Goldstein, H. ,
> and Rasbash, J.  (1998), ``Weighting for unequal selection probabilities in
> multilevel models (Disc: p41-56)'', Journal of the Royal Statistical
> Society, Series B, Methodological, 60 , 23-40 >
>
> which refers back to:
> <29. Pfeffermann, D. , and LaVange, L.  (1989), ``Regression models for
> stratified multi-stage cluster samples'', Analysis of Complex Surveys,
> 237-260 >
>
> If you don't like statistical papers, then see section 4.5 of <8. Korn,
> Edward Lee , and Graubard, Barry I.  (1999), ``Analysis of health surveys'',
> John Wiley & Sons (New York; Chichester) > They explain the idea of using
> weights in a model fairly simply.
>
> Bob
>
>
> -----Original Message-----
> From: Han-Lin Lai [mailto:Han-Lin.Lai at noaa.gov]
> Sent: Wednesday, May 19, 2004 12:47 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] mixed models for analyzing survey data with unequal selection
> probability
>
> Hi,
>
> I need the help on this topic because this is out of my statistical
> trianing as biologist.  Here is my brief description of the problem.
>
> I have a survey that VESSELs are selected at random with the probability
> of p(j).  Then the tows within the jth VESSEL are sampled at random with
> probability of p(i|j).  I write my model as
>
> y = XB + Zb + e
> where XB is fixed part, Zb is for random effect (VESSEL) and e is
> within-vessel error.
>
> I feel that I should weight the Zb part by p(j) and the e-part by
> p(i,j)=p(j)*p(i|j). Is this a correct weighting?
>
> How can I implement the weightings in nlme (or lme)?  I think that
> p(i,j) can be specified by nlme(..., weights=p(i,j),...)?  Where is p(j)
> to be used in nlme?
>
> I appreciate anyone can provide examples and literature for this
> problem.
>
> Cheers!
> Han
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From jonathan_wang at sbcglobal.net  Thu May 20 17:20:53 2004
From: jonathan_wang at sbcglobal.net (Jonathan Wang)
Date: Thu, 20 May 2004 08:20:53 -0700 (PDT)
Subject: [R] 'start' argument for fitdistr()
Message-ID: <20040520152053.85282.qmail@web81203.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040520/a847b26c/attachment.pl

From jasont at indigoindustrial.co.nz  Thu May 20 17:33:19 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 21 May 2004 03:33:19 +1200
Subject: [R] POSIX to ts and back to POSIX
In-Reply-To: <OFE18C037F.A481D40B-ON85256E99.00687DA9-85256E99.006AA0A3@epamail.epa.gov>
References: <OFE18C037F.A481D40B-ON85256E99.00687DA9-85256E99.006AA0A3@epamail.epa.gov>
Message-ID: <20040520153319.GB3308@kryten.akl.indigoindustrial.co.nz>

On Wed, May 19, 2004 at 03:24:38PM -0400, Allen.Joel at epamail.epa.gov wrote:
> I am trying to use POSIX datetime objects rather than chron datetime
> objects but am having difficulty with POSIX in a time series.  My
> question:  Once a POSIXct vector is bound to a time series, is there a
> function to convert back to POSIXct?  The following code demonstrates
> what I am trying to do.
> 
> > ts(as.POSIXct(strptime(tmp,"%m/%d/%Y %H:%M:%S")),freq=1440)
> Time Series:
> Start = c(1, 1)
> End = c(1, 10)
> Frequency = 1440
>  [1] 1074022572 1074022632 1074022693 1074022753 1074022813 1074022874
> 1074022934 1074022994 1074023055 1074023115
> attr(,"tzone")
> [1]
...

for the reverse process, something like....

## UNTESTED!
yourts <- ts(as.POSIXct(strptime(tmp,"%m/%d/%Y %H:%M:%S")),freq=1440)
ISOdate(1970,1,1,0,0,0,UTC) + time(yourts)

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From michael.watson at bbsrc.ac.uk  Thu May 20 17:35:10 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 20 May 2004 16:35:10 +0100
Subject: [R] Help with hclust() and plot()
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9516EE4D@iahce2knas1.iah.bbsrc.reserved>


Hi

When I use plot(hclust(dist..)...)...) etc to create a dendrogram of a
hierarchial cluster analysis, I end up with a vertical tree.  What do I
need to do to get a horizontal tree?

Also, my users are used to seeing trees who's leaves all "end" at the
same place (eg. Like in minitab).  Is this possible in R?

Thanks

Mick

Michael Watson
Head of Informatics
Institute for Animal Health,
Compton Laboratory,
Compton,
Newbury,
Berkshire RG20 7NN
UK

Phone : +44 (0)1635 578411 ext. 2535
Mobile: +44 (0)7990 827831
E-mail: michael.watson at bbsrc.ac.uk



From sundar.dorai-raj at PDF.COM  Thu May 20 17:49:25 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Thu, 20 May 2004 08:49:25 -0700
Subject: [R] Help with hclust() and plot()
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9516EE4D@iahce2knas1.iah.bbsrc.reserved>
References: <8975119BCD0AC5419D61A9CF1A923E9516EE4D@iahce2knas1.iah.bbsrc.reserved>
Message-ID: <40ACD385.6010803@pdf.com>



michael watson (IAH-C) wrote:
> Hi
> 
> When I use plot(hclust(dist..)...)...) etc to create a dendrogram of a
> hierarchial cluster analysis, I end up with a vertical tree.  What do I
> need to do to get a horizontal tree?
> 
> Also, my users are used to seeing trees who's leaves all "end" at the
> same place (eg. Like in minitab).  Is this possible in R?
> 
> Thanks
> 
> Mick
> 

Mick,
   If you use as.dendrogram first then the plot method for dendrograms 
has a horizontal option:

data(USArrests)
hc <- hclust(dist(USArrests), "ave")
dend1 <- as.dendrogram(hc)
plot(dend1, horiz = TRUE)

This also puts the leave at the end.

R version 1.9.0, 2004-05-06
Windows 2000

--sundar



From jasont at indigoindustrial.co.nz  Thu May 20 17:44:48 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 21 May 2004 03:44:48 +1200
Subject: [R] irregular time series
In-Reply-To: <032A8573186A2B4EBBAEFA5784D0523555A155@sagemsg0007.sagemsmrd01.sa.gov.au>
References: <032A8573186A2B4EBBAEFA5784D0523555A155@sagemsg0007.sagemsmrd01.sa.gov.au>
Message-ID: <20040520154448.GC3308@kryten.akl.indigoindustrial.co.nz>

On Thu, May 20, 2004 at 02:23:46PM +0930, McClatchie, Sam (PIRSA-SARDI) wrote:
[long time series, broken in two with a gap]
> I realise that I could just break each series into two segments and
> cross-correlate with the shorter series, but I'd rather deal with the whole
> series to increase the nyquist frequency. I think the its function in the
> irregular time series package will create a class its object with the right
> time stamps, but can this then be used in the same was as a class ts object
> for the correlation and spectral anayses?  

its does some nice things for storing, plotting, and manipulating
irregular time series, but isn't long on the analysis.

A few options:

1) Analyze the two sub-series separately.
2) There is some merit to de-mean or de-trending both series,
zero-padding the shorter so its length matches the longer, and 
performing spectral analysis that way.  Frequencies near zero
should be treated with suspicion, however.
3) Jim Lindsey has some continuous ARMA and Kalman filter routines
on his site (Google for "Lindsey" and "rmutil", which is the
name of one of those packages).
4) I'm working on an R version of the Lomb periodogram, which
was built for irregular series, but I've no guarantees when I'll
roll it up - rather busy most days.  I do remember seeing an S
version on someone's web page, but that was a while ago, and it
was the "direct" or slow method.

Hope that helps

Jason



-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From jasont at indigoindustrial.co.nz  Thu May 20 17:55:13 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 21 May 2004 03:55:13 +1200
Subject: [R] Repeated measures ANOVA
In-Reply-To: <8e1e48d815.8d8158e1e4@wiscmail.wisc.edu>
References: <8e1e48d815.8d8158e1e4@wiscmail.wisc.edu>
Message-ID: <20040520155513.GD3308@kryten.akl.indigoindustrial.co.nz>

On Wed, May 19, 2004 at 11:11:46PM -0600, GIDEON WASSERBERG wrote:
> Dear friends
> 
> I am not sure that I am conducting this analysis correctly. 
> I would really appreciate if someone can verify what I've done.

> I conducted repeated measures ANOVA for some bugs data. 
> These bugs were measured repeatedly over 32 weeks at the 
> same trapping plots. I want to test a full model for the 
> effect of time ("week") (the "within subject" variable), 
> and the main effects are: place, station,species, and all 
> the interactions thereof.

Since there's likely some serious time and location dependence 
here, I suggest you get a copy of Pinheiro and Bates.

@Book{PinheiroBates2000,
  author =	 {Jos\'e C. Pinheiro and Douglas M. Bates},
  title =	 "Mixed-Effects Models in S and S-PLUS",
  publisher =	 {Springer-Verlag},
  year =	 {2000},
  address =	 {New York}
}

Since performing statistical consulting for free is a 
dangerous prescedent to the profession, I'll leave it
at that :)

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From agustin.perez at umh.es  Thu May 20 17:57:56 2004
From: agustin.perez at umh.es (Perez Martin, Agustin)
Date: Thu, 20 May 2004 17:57:56 +0200
Subject: [R] write in fixed format
Message-ID: <5AFDDD57E2771B409224CD858CC6DE0D02DAB41A@mailer-e051.umh.es>

DeaR useRs:

I have a problem, because I have a file in fixed width format and I can read
it with 'read.fwf' and after I can use these data to do generate new columns
(variables) and when I am going to write this set of data (data.frame) I
can't find a function which storages my data.frame in fixed width format.

Can you help me?
Thanks in advance.

Agust??n P??rez
Universidad Miguel Hern??ndez de Elche.



From spencer.graves at pdf.com  Thu May 20 18:06:44 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 20 May 2004 09:06:44 -0700
Subject: [R] mixed models for analyzing survey data with unequal selec
	tion  probability
In-Reply-To: <Pine.A41.4.58.0405200805530.98828@homer35.u.washington.edu>
References: <6BCD3F430455B1418750004BCD27925905C6D6@exchange2.ahrq.gov>
	<Pine.A41.4.58.0405200805530.98828@homer35.u.washington.edu>
Message-ID: <40ACD794.4020005@pdf.com>

      Cassel, Sarndal and Wretman (1977) Foundations of Inference in 
Survey Sampling (Krieger) insisted that for infinite population 
inference (what Deming called an 'analytic study'), the sampling 
probabilities should be ignored UNLESS they related somehow to something 
of interest in the model.  In other words, is the sampling informative 
or noninformative?  If noninformative, the sampling probabilities do not 
appear in the likelihood and therefore should not affect inference.  As 
I recall, Cassel, Sarndal and Wretman said that if stratified random 
sampling is used, and if the stratification system is included in the 
model, then the sampling is noninformative, and the sampling 
probabilities should not affect inference. 

      From this paradigm, using weights inversely proportional to 
sampling probabilities is (primarily?) a tool for finite population 
inference -- what Deming called an 'enumerative study'.  For an 
enumerative study, the purpose is to make inference about a fixed, 
finite population, e.g., how to feed the people in Japan who would 
otherwise starve within the next week or month, which was the situation 
when Deming directed a survey there shortly after World War II.  For an 
analytic study, the purpose is more long term, e.g., how to design a 
national alimentary system to feed the people who will be there 10 or 30 
years from now.  Since most of my work has dealt processed that will 
create the future, rather than dealing with fixed, finite populations, I 
have ignored sampling probabilities in most of my work (though I have 
not worked much recently with sample surveys). 

      Is this still consistent with current thinking?  Is it feasible to 
summarize in a few words what Pferrermann, Korn et al. say about this? 

      Thanks,
      spencer graves

Thomas Lumley wrote:

>On Thu, 20 May 2004, Baskin, Robert wrote:
>
>  
>
>>Han-Lin
>>
>>I don't think I have seen a reply so I will suggest that maybe you could try
>>a different approach than what you are thinking about doing.  I believe the
>>current best practice is to use the weights as a covariate in a regression
>>model - and bytheway - the weights are the inverse of the probabilities of
>>selection - not the probabilities.
>>
>>Fundamentally, there is a difficulty in making sense out of 'random effects'
>>in a finite population setting.
>>    
>>
>
>I would have thought that it matters why you are fitting a mixed model.
>Often people use mixed models when they are just interested in inference
>about the mean and need to model the covariances to get valid standard
>errors. In that situation you could use an ordinary survey regression to
>get a design-based result.
>
>If you are actually interested in variance components then you need some
>other approach, and putting the weights into the model as a covariate will
>presumably give a valid model-based result (since the weights carry all
>the biased sampling information --- like a propensity score).  Presumably
>this is also more efficient.
>
>However, it could well be that you don't want those variables in the
>model. If the sampling depends on a variable Z correlated with Y and X and
>you want to model the distribution of Y given X, not the distribution of Y
>given X and Z, you are still in trouble.
>
>
>	-thomas
>
>
>
>  
>
>>(plagiarized from some unknown source)
>>See: < 9. Pfeffermann, D. , Skinner, C. J. , Holmes, D. J. , Goldstein, H. ,
>>and Rasbash, J.  (1998), ``Weighting for unequal selection probabilities in
>>multilevel models (Disc: p41-56)'', Journal of the Royal Statistical
>>Society, Series B, Methodological, 60 , 23-40 >
>>
>>which refers back to:
>><29. Pfeffermann, D. , and LaVange, L.  (1989), ``Regression models for
>>stratified multi-stage cluster samples'', Analysis of Complex Surveys,
>>237-260 >
>>
>>If you don't like statistical papers, then see section 4.5 of <8. Korn,
>>Edward Lee , and Graubard, Barry I.  (1999), ``Analysis of health surveys'',
>>John Wiley & Sons (New York; Chichester) > They explain the idea of using
>>weights in a model fairly simply.
>>
>>Bob
>>
>>
>>-----Original Message-----
>>From: Han-Lin Lai [mailto:Han-Lin.Lai at noaa.gov]
>>Sent: Wednesday, May 19, 2004 12:47 PM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] mixed models for analyzing survey data with unequal selection
>>probability
>>
>>Hi,
>>
>>I need the help on this topic because this is out of my statistical
>>trianing as biologist.  Here is my brief description of the problem.
>>
>>I have a survey that VESSELs are selected at random with the probability
>>of p(j).  Then the tows within the jth VESSEL are sampled at random with
>>probability of p(i|j).  I write my model as
>>
>>y = XB + Zb + e
>>where XB is fixed part, Zb is for random effect (VESSEL) and e is
>>within-vessel error.
>>
>>I feel that I should weight the Zb part by p(j) and the e-part by
>>p(i,j)=p(j)*p(i|j). Is this a correct weighting?
>>
>>How can I implement the weightings in nlme (or lme)?  I think that
>>p(i,j) can be specified by nlme(..., weights=p(i,j),...)?  Where is p(j)
>>to be used in nlme?
>>
>>I appreciate anyone can provide examples and literature for this
>>problem.
>>
>>Cheers!
>>Han
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>    
>>
>
>Thomas Lumley			Assoc. Professor, Biostatistics
>tlumley at u.washington.edu	University of Washington, Seattle
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From michael.watson at bbsrc.ac.uk  Thu May 20 18:12:50 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 20 May 2004 17:12:50 +0100
Subject: [R] Help with hclust() and plot()
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9516EE50@iahce2knas1.iah.bbsrc.reserved>

Hi

Thanks for that!  BUT if I use as.dendrogram, I can't use my labels
anymore!

>plot(hclust(...etc), labels=p[,1])

Works fine.  But:

>plot(as.dendrogram(hclust(...etc)), labels=p[,1]) 

Gives me errors:

Error in axis(side, at, labels, tick, line, pos, outer, font, vfont,
lty,  :
	location and label lengths differ, 6 != 24

I have 24 labels.  I have no idea where it gets 6 from!

My 'dendrogram' has '2 branches and 24 members total'.

SOOO, how do I get my dendrogram horizontal, or vertical for that
matter, with useful labels instead of 1,2,3,4,5,etc

Thanks in advance for your help!

Mick

-----Original Message-----
From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at PDF.COM] 
Sent: 20 May 2004 16:49
To: michael watson (IAH-C)
Cc: R-Help (E-mail)
Subject: Re: [R] Help with hclust() and plot()




michael watson (IAH-C) wrote:
> Hi
> 
> When I use plot(hclust(dist..)...)...) etc to create a dendrogram of a

> hierarchial cluster analysis, I end up with a vertical tree.  What do 
> I need to do to get a horizontal tree?
> 
> Also, my users are used to seeing trees who's leaves all "end" at the 
> same place (eg. Like in minitab).  Is this possible in R?
> 
> Thanks
> 
> Mick
> 

Mick,
   If you use as.dendrogram first then the plot method for dendrograms 
has a horizontal option:

data(USArrests)
hc <- hclust(dist(USArrests), "ave")
dend1 <- as.dendrogram(hc)
plot(dend1, horiz = TRUE)

This also puts the leave at the end.

R version 1.9.0, 2004-05-06
Windows 2000

--sundar



From mmiller3 at iupui.edu  Thu May 20 18:13:42 2004
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Thu, 20 May 2004 11:13:42 -0500
Subject: [R] R 1.8.1 - 1.9.0 incompatability: Underscore in syntactically
 valid names
Message-ID: <874qqbrs95.fsf@lumen.indyrad.iupui.edu>

Dear R-gang,

I have a question about handling underscores in names in R 1.8.1
and 1.9.0.  I recently installed 1.9.0 on a machine and found
that many codes no longer work as a result of the changed
behavior in make.names.

I have numerous data files that have dashes, periods and
underscores in the header row.  I've got numerous R codes that
read those files with read.table and read.csv and then use the
names expecting the underscores and dashes to be changed to
periods in the column names.  Since this no longer happens in
1.9.0, lots of codes are failing.  One way to work around this is
to repair a lot of codes to take this backward incompatibility
into account (both R scripts and data sources, so that is a
significant project, here at least).  Or I can stay with 1.8.1,
but that is just a sure route to eventual incomparability with
something else, so I'll gradually start migrating code over and
adding version checks.

Can anyone suggest a way to maintain compatibility between R
versions?  I suppose I could write a wrapper around make.names to
replace _ with ., but I'm not sure what that might break in 1.9.0
that now expects the new behavior.  I'd appreciate any
suggestions.

Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine



From myao at ou.edu  Thu May 20 18:38:43 2004
From: myao at ou.edu (Yao, Minghua)
Date: Thu, 20 May 2004 11:38:43 -0500
Subject: [R] Get Slot from a Class
Message-ID: <78B50CF247E5D04B8A5E02D001CC8E9A595C63@XMAIL.sooner.net.ou.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040520/48e412f8/attachment.pl

From tlumley at u.washington.edu  Thu May 20 18:46:09 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 20 May 2004 09:46:09 -0700 (PDT)
Subject: [R] mixed models for analyzing survey data with unequal selec
	tion  probability
In-Reply-To: <40ACD794.4020005@pdf.com>
References: <6BCD3F430455B1418750004BCD27925905C6D6@exchange2.ahrq.gov>
	<Pine.A41.4.58.0405200805530.98828@homer35.u.washington.edu>
	<40ACD794.4020005@pdf.com>
Message-ID: <Pine.A41.4.58.0405200931550.98828@homer35.u.washington.edu>

On Thu, 20 May 2004, Spencer Graves wrote:

>       Cassel, Sarndal and Wretman (1977) Foundations of Inference in
> Survey Sampling (Krieger) insisted that for infinite population
> inference (what Deming called an 'analytic study'), the sampling
> probabilities should be ignored UNLESS they related somehow to something
> of interest in the model.  In other words, is the sampling informative
> or noninformative?  If noninformative, the sampling probabilities do not
> appear in the likelihood and therefore should not affect inference.  As
> I recall, Cassel, Sarndal and Wretman said that if stratified random
> sampling is used, and if the stratification system is included in the
> model, then the sampling is noninformative, and the sampling
> probabilities should not affect inference.

This is the point of including the sampling weights as a predictor.  These
weights carry all the informativeness of the sampling scheme, and so
correctly modelling them is sufficient.  If the sampling is already
non-informative then including them as a predictor is harmless.

However, my point was that you may not want to condition on all the
variables that go into the sampling scheme, in which case the simplest
solution may be design-based inference.

	-thomas



From tlumley at u.washington.edu  Thu May 20 18:49:40 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 20 May 2004 09:49:40 -0700 (PDT)
Subject: [R] Get Slot from a Class
In-Reply-To: <78B50CF247E5D04B8A5E02D001CC8E9A595C63@XMAIL.sooner.net.ou.edu>
References: <78B50CF247E5D04B8A5E02D001CC8E9A595C63@XMAIL.sooner.net.ou.edu>
Message-ID: <Pine.A41.4.58.0405200946240.98828@homer35.u.washington.edu>

On Thu, 20 May 2004, Yao, Minghua wrote:

> Hello, everyone,
>
> I don't quite understand the following message:
>
> > TTT <- t.test(1:10, y=c(7:20))
> > class(TTT)
> [1] "htest"
> > TTT at p.value
> Error: Trying to get slot "p.value" from an object whose class ("htest")
> is not defined
> > TTT$p.value
> [1] 1.855282e-05
>
> Why the message says the class of TTT is not defined while class(TTT)
> gets "htest"?

The classical tests use the S3 class system, not the S4 system.  They
don't have slots, and they don't have formal class representations (they
weren't created with setClass).

The message could perhaps be clearer, but it is saying that there is no
formal definition of a "htest" class and so you can't use the @ operator
on these objects.

	-thomas



From ligges at statistik.uni-dortmund.de  Thu May 20 18:47:36 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 May 2004 18:47:36 +0200
Subject: [R] function for running MS-DOS from R
In-Reply-To: <loom.20040520T131947-58@post.gmane.org>
References: <BAY16-F8yzu23LiC1h1000333cc@hotmail.com>
	<loom.20040520T131947-58@post.gmane.org>
Message-ID: <40ACE128.30803@statistik.uni-dortmund.de>

Gabor Grothendieck wrote:
> bang jeong sook <quietroom78 <at> hotmail.com> writes:
> 
> 
>>I had downloaded the program that runs on MS-DOS.
>>Is it possible for MS-DOS to be run in R such as WinBugs1.4?
>>I wonder whether there is the R function for running MS-DOS from R.
> 
> 
> On my XP system this works:
> 
> R> system("cmd")
> 
> to drop into the Windows command line and exit at the
> Windows command line get you back.  
> 
> One can slso do this:
> 
> R> system("cmd /c dir > listing.txt")
> R> listing <- readLines("listing.txt")
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Or shell(), which is the more user-friendly wrapper for system() under 
Windows.


Uwe Ligges



From ligges at statistik.uni-dortmund.de  Thu May 20 18:51:41 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 May 2004 18:51:41 +0200
Subject: [R] write in fixed format
In-Reply-To: <5AFDDD57E2771B409224CD858CC6DE0D02DAB41A@mailer-e051.umh.es>
References: <5AFDDD57E2771B409224CD858CC6DE0D02DAB41A@mailer-e051.umh.es>
Message-ID: <40ACE21D.9020603@statistik.uni-dortmund.de>

Perez Martin, Agustin wrote:

> DeaR useRs:
> 
> I have a problem, because I have a file in fixed width format and I can read
> it with 'read.fwf' and after I can use these data to do generate new columns
> (variables) and when I am going to write this set of data (data.frame) I
> can't find a function which storages my data.frame in fixed width format.
> 
> Can you help me?
> Thanks in advance.
> 
> Agust??n P??rez
> Universidad Miguel Hern??ndez de Elche.
> 

See ?write.matrix in package MASS.

Uwe Ligges


  ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu May 20 18:50:05 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 May 2004 18:50:05 +0200
Subject: [R] Get Slot from a Class
In-Reply-To: <78B50CF247E5D04B8A5E02D001CC8E9A595C63@XMAIL.sooner.net.ou.edu>
References: <78B50CF247E5D04B8A5E02D001CC8E9A595C63@XMAIL.sooner.net.ou.edu>
Message-ID: <40ACE1BD.4010103@statistik.uni-dortmund.de>

Yao, Minghua wrote:

> Hello, everyone,
>  
> I don't quite understand the following message:
>  
> 
>>TTT <- t.test(1:10, y=c(7:20))
>>class(TTT)
> 
> [1] "htest"
> 
>>TTT at p.value
> 
> Error: Trying to get slot "p.value" from an object whose class ("htest") is not defined 
> 
>>TTT$p.value
> 
> [1] 1.855282e-05
> 
> Why the message says the class of TTT is not defined while class(TTT) gets "htest"?
> 
> I appreciate the explanations?

Well, you are mixing S3 with S4 classes. The slot extractor "@" epects 
an S4 class. And htest is an S3 class ....

Uwe Ligges
> -Minghua
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dhoysak at ccs.carleton.ca  Thu May 20 18:57:20 2004
From: dhoysak at ccs.carleton.ca (Drew Hoysak)
Date: Thu, 20 May 2004 12:57:20 -0400
Subject: [R] Spearman probabilities and SuppDists
Message-ID: <1085072240.2217.19.camel@localhost.localdomain>


cor.test and SuppDists give me different P-values for the same
Spearman's rho.  Which is correct, or am I doing something wrong?



> x <- c(44.4, 45.9, 41.9, 53.3, 44.7, 44.1, 50.7, 45.2, 60.1)
> y <- c( 2.6,  3.1,  2.5,  5.0,  3.6,  4.0,  5.2,  2.8,  3.8)

> cor.test(x,y,method="spearman")

	Spearman's rank correlation rho

data:  x and y 
S = 48, p-value = 0.0968
alternative hypothesis: true rho is not equal to 0 
sample estimates:
rho 
0.6 


> 2*(1-pSpearman(.6,9))
[1] 0.08572531





Drew Hoysak



From spencer.graves at pdf.com  Thu May 20 19:06:38 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 20 May 2004 10:06:38 -0700
Subject: [R] mixed models for analyzing survey data with unequal selec
	tion  probability
In-Reply-To: <Pine.A41.4.58.0405200931550.98828@homer35.u.washington.edu>
References: <6BCD3F430455B1418750004BCD27925905C6D6@exchange2.ahrq.gov>	<Pine.A41.4.58.0405200805530.98828@homer35.u.washington.edu>	<40ACD794.4020005@pdf.com>
	<Pine.A41.4.58.0405200931550.98828@homer35.u.washington.edu>
Message-ID: <40ACE59E.20603@pdf.com>

Dear Thomas:  Thanks for your reply.  Spencer Graves

Thomas Lumley wrote:

>On Thu, 20 May 2004, Spencer Graves wrote:
>
>  
>
>>      Cassel, Sarndal and Wretman (1977) Foundations of Inference in
>>Survey Sampling (Krieger) insisted that for infinite population
>>inference (what Deming called an 'analytic study'), the sampling
>>probabilities should be ignored UNLESS they related somehow to something
>>of interest in the model.  In other words, is the sampling informative
>>or noninformative?  If noninformative, the sampling probabilities do not
>>appear in the likelihood and therefore should not affect inference.  As
>>I recall, Cassel, Sarndal and Wretman said that if stratified random
>>sampling is used, and if the stratification system is included in the
>>model, then the sampling is noninformative, and the sampling
>>probabilities should not affect inference.
>>    
>>
>
>This is the point of including the sampling weights as a predictor.  These
>weights carry all the informativeness of the sampling scheme, and so
>correctly modelling them is sufficient.  If the sampling is already
>non-informative then including them as a predictor is harmless.
>
>However, my point was that you may not want to condition on all the
>variables that go into the sampling scheme, in which case the simplest
>solution may be design-based inference.
>
>	-thomas
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From vograno at evafunds.com  Thu May 20 19:49:25 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Thu, 20 May 2004 10:49:25 -0700
Subject: [R] ifelse when test is shorter than yes/no
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B3313@phost015.EVAFUNDS.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040520/bd5702fb/attachment.pl

From sundar.dorai-raj at PDF.COM  Thu May 20 20:03:49 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Thu, 20 May 2004 11:03:49 -0700
Subject: [R] Help with hclust() and plot()
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9516EE50@iahce2knas1.iah.bbsrc.reserved>
References: <8975119BCD0AC5419D61A9CF1A923E9516EE50@iahce2knas1.iah.bbsrc.reserved>
Message-ID: <40ACF305.3060408@pdf.com>



michael watson (IAH-C) wrote:

> Hi
> 
> Thanks for that!  BUT if I use as.dendrogram, I can't use my labels
> anymore!
> 
> 
>>plot(hclust(...etc), labels=p[,1])
> 
> 
> Works fine.  But:
> 
> 
>>plot(as.dendrogram(hclust(...etc)), labels=p[,1]) 
> 
> 
> Gives me errors:
> 
> Error in axis(side, at, labels, tick, line, pos, outer, font, vfont,
> lty,  :
> 	location and label lengths differ, 6 != 24
> 
> I have 24 labels.  I have no idea where it gets 6 from!
> 
> My 'dendrogram' has '2 branches and 24 members total'.
> 
> SOOO, how do I get my dendrogram horizontal, or vertical for that
> matter, with useful labels instead of 1,2,3,4,5,etc
> 
> Thanks in advance for your help!
> 
> Mick
> 

Mick,
   Change the labels in hclust first:

data(USArrests)
hc <- hclust(dist(USArrests), "ave")
hc$labels <- 1:50
dend1 <- as.dendrogram(hc)
plot(dend1, horiz = TRUE)

--sundar



From wwsprague at ucdavis.edu  Thu May 20 20:46:02 2004
From: wwsprague at ucdavis.edu (foobar)
Date: Thu, 20 May 2004 11:46:02 -0700
Subject: [R] GUI data browsers
In-Reply-To: <loom.20040520T031746-799@post.gmane.org>
References: <c8g8kk$r24$1@sea.gmane.org>
	<loom.20040520T031746-799@post.gmane.org>
Message-ID: <c8iudb$jf8$1@sea.gmane.org>

Gabor Grothendieck wrote:

 > This is not a full answer to what you are looking for but you might
 > try
 >
 > ?browseEnv

Seems to be among the best answers out there :).  There is a TODO item 
in browseEnv regarding using Tk, so if I am up to the challenge...

?str is helpful too

W



From ggrothendieck at myway.com  Thu May 20 21:19:34 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 20 May 2004 19:19:34 +0000 (UTC)
Subject: [R] GUI data browsers
References: <c8g8kk$r24$1@sea.gmane.org>
	<loom.20040520T031746-799@post.gmane.org>
	<c8iudb$jf8$1@sea.gmane.org>
Message-ID: <loom.20040520T211907-14@post.gmane.org>

foobar <wwsprague <at> ucdavis.edu> writes:
> 
> ?str is helpful too

If you are interested in str then you might also be interested in dput.



From bwheeler at echip.com  Thu May 20 21:28:37 2004
From: bwheeler at echip.com (Bob Wheeler)
Date: Thu, 20 May 2004 15:28:37 -0400
Subject: [R] Spearman probabilities and SuppDists
References: <1085072240.2217.19.camel@localhost.localdomain>
Message-ID: <40AD06E5.8090102@echip.com>

cor.test is giving Pr(x<0.6), SuppDists is giving Pr(x<=0.6). My 
recollection is that it is the custom in R for discrete distributions to 
include the point in the left tail.


Drew Hoysak wrote:
> cor.test and SuppDists give me different P-values for the same
> Spearman's rho.  Which is correct, or am I doing something wrong?
> 
> 
> 
> 
>>x <- c(44.4, 45.9, 41.9, 53.3, 44.7, 44.1, 50.7, 45.2, 60.1)
>>y <- c( 2.6,  3.1,  2.5,  5.0,  3.6,  4.0,  5.2,  2.8,  3.8)
> 
> 
>>cor.test(x,y,method="spearman")
> 
> 
> 	Spearman's rank correlation rho
> 
> data:  x and y 
> S = 48, p-value = 0.0968
> alternative hypothesis: true rho is not equal to 0 
> sample estimates:
> rho 
> 0.6 
> 
> 
> 
>>2*(1-pSpearman(.6,9))
> 
> [1] 0.08572531
> 
> 
> 
> 
> 
> Drew Hoysak
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Bob Wheeler --- http://www.bobwheeler.com/
         ECHIP, Inc. ---
Randomness comes in bunches.



From krcabrer at perseus.unalmed.edu.co  Thu May 20 22:52:22 2004
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Thu, 20 May 2004 15:52:22 -0500
Subject: [R] for() to lapply()
Message-ID: <opr8bf9kd8faouaq@200.24.8.4>

Hi dear R-users:

I have the following problem:
I have a list of data.frames (12 variables and 60000 rows, each)

I have to merge from an specific point of the list to the
end of the list, I am doing so with a for() loop but it is
too inefficient and it exhausts memory.

How can I convert this for() loop in a function and then use
lapply?
-------------------------------------------------------------
LIST: list of data frames.
m:point of start merging.

result<-merge(LIST[[m]],LIST[[m+1]],by="key",all.x=T)
for (i in (m+2):length(LIST))
{
   result<-merge(result,LIST[[i]],by="key",all.x=T)
}

The problem is the acumulative: "result<-merge(result,...)"

I can think in a function like this:

mergeListelem<-function(i,LS,m)
{
  merge(LS[[m]],LS[[i]],by="key",all.x=T)
}

ind<-m:length(LIST)
lapply(ind,mergeListelem,LIST,m)

But I just obtain a list of merged data.frames,
and I dont know how to join all the elements
of the list in just one final data.frame.

Thank you for your help

-- 
Kenneth Cabrera
Universidad Nacional de Colombia
Tel Of 430 9351
Cel 315 504 9339
Medelln



From andy_liaw at merck.com  Thu May 20 23:19:44 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 20 May 2004 17:19:44 -0400
Subject: [R] ifelse when test is shorter than yes/no
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7DCA@usrymx25.merck.com>

> From: Vadim Ogranovich
> 
> Hi,
>  
> It turns out that the 'test' vector in ifelse(test, yes, no) is not
> recycled if it is shorter than the other arguments, e.g.
>  
> > ifelse(TRUE, seq(10), -seq(10))
> [1] 1
> 
>  
> Is there any particular reason it is not recycled? If there is one
> indeed a warning message might be in order when someone calls ifelse
> with a shorter 'test'.

?ifelse says:

Value:

     A vector of the same length and attributes (including class) as
     'test' and data values from the values of 'yes' or 'no'.  ...

Seems to me it works as documented.  Why do you expected otherwise?

Andy
  
> This is R1.8.1 on RH-7.3
>  
> Thanks,
> Vadim
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From vograno at evafunds.com  Fri May 21 00:54:34 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Thu, 20 May 2004 15:54:34 -0700
Subject: [R] ifelse when test is shorter than yes/no
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B3314@phost015.EVAFUNDS.intermedia.net>

It does work as documented. My question was why it was designed to work
this way. I can not think of a practical situation when someone might
want to ifelse() on a 'test' that is shorter than yes/no w/o expecting
'test' to recycle (therefore I was asking for a warning).

I find this behavior inconsistent with the (spirit of) R's recycling
rules. For example if 'test', 'yes', 'no' are all of the same length
then the following two expressions are equivalent:

1.
x <- ifelse(test, yes, no)

2.
x <- no; x[test] <- yes[test]

This equivalence breaks when 'test' is shorter than yes/no: in the
second case 'test' will be recycled. And I don't see a good reason for
having them behave differently.

If I had to implement ifelse() I'd probably do:

ifelse2 <- function(test, yes, no) {
	x <- rep(no, length.out=max(length(test), length(yes),
length(no)))
	x[test] <- yes[test]

	x
}

(If there is interest I can extend it to take care of NA-s and submit as
a (trivial) patch)


Here is a simple test:
> ifelse2(c(TRUE, FALSE), seq(10), -seq(5))
 [1]  1 -2  3 -4  5 -1  7 -3  9 -5



Maybe it will help if I tell how I stumbled upon this problem. I had two
m*n matrices, 'yes' and 'no', and a 'test' vector of length m. I wanted
to create a m*n matrix which has 'yes' rows where test==TRUE and 'no'
rows otherwise. So I did

x <- matrix(ifelse(test, yes, no), nrow(yes), ncol(yes))

priding myself for doing it the "whole object way" ... and 'test' did
not recycle (in full accordance with the help page) w/o a warning.


Thanks,
Vadim




> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com] 
> Sent: Thursday, May 20, 2004 2:20 PM
> To: Vadim Ogranovich; R-Help
> Subject: RE: [R] ifelse when test is shorter than yes/no
> 
> 
> > From: Vadim Ogranovich
> > 
> > Hi,
> >  
> > It turns out that the 'test' vector in ifelse(test, yes, no) is not 
> > recycled if it is shorter than the other arguments, e.g.
> >  
> > > ifelse(TRUE, seq(10), -seq(10))
> > [1] 1
> > 
> >  
> > Is there any particular reason it is not recycled? If there is one 
> > indeed a warning message might be in order when someone 
> calls ifelse 
> > with a shorter 'test'.
> 
> ?ifelse says:
> 
> Value:
> 
>      A vector of the same length and attributes (including class) as
>      'test' and data values from the values of 'yes' or 'no'.  ...
> 
> Seems to me it works as documented.  Why do you expected otherwise?
> 
> Andy
>   
> > This is R1.8.1 on RH-7.3
> >  
> > Thanks,
> > Vadim
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its 
> affiliates (which may be known outside the United States as 
> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted 
> and/or legally privileged. It is intended solely for the use 
> of the individual or entity named on this message.  If you 
> are not the intended recipient, and have received this 
> message in error, please notify us immediately by reply 
> e-mail and then delete it from your system.
> --------------------------------------------------------------
> ----------------
>



From jasont at indigoindustrial.co.nz  Fri May 21 02:43:56 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 21 May 2004 12:43:56 +1200
Subject: [R] for() to lapply()
In-Reply-To: <opr8bf9kd8faouaq@200.24.8.4>
References: <opr8bf9kd8faouaq@200.24.8.4>
Message-ID: <20040521004356.GA4952@kryten.akl.indigoindustrial.co.nz>

On Thu, May 20, 2004 at 03:52:22PM -0500, Kenneth Cabrera wrote:
> Hi dear R-users:
> 
> I have the following problem:
> I have a list of data.frames (12 variables and 60000 rows, each)
> 
> I have to merge from an specific point of the list to the
> end of the list, I am doing so with a for() loop but it is
> too inefficient and it exhausts memory.
> 
> How can I convert this for() loop in a function and then use
> lapply?

There's still a better way to do it, I'm sure, but something
like...

##untested!

myMerge <- function(x,y,...) {
	zz <- merge(x,y,...)
	gc()
}

foo <- lapply(my.df.list[[-1]],myMerge,my.df.list[[1]])

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From pwilkinson at videotron.ca  Fri May 21 02:58:37 2004
From: pwilkinson at videotron.ca (Peter Wilkinson)
Date: Thu, 20 May 2004 20:58:37 -0400
Subject: [R] Memory usage of R on Windows XP
Message-ID: <5.2.0.9.0.20040520204754.00b3c2b0@pop.videotron.ca>


I am running R 1.8.1 on windows xp. I have been using the 'apply' R 
function to run a short function against a matrix of 19000 x 340 rows ... 
yes it is a big matrix. every item in the matrix is a float that can have a 
maximum value of 2^16 ~ 65k.

The function:

mask256 <- function(value) {
     if (value < 256) {
        result = 0
     }
     else {
        result = 1
     }
     result
}

what happens is that the memory required for the session to run starts 
ballooning. The matrix with a few other objects starts at about 160M, but 
then quickly goes up to 750M, and stays there when the function has completed

I am fairly new to R. Is there something I should know about writing 
functions , i.e. do I need to clean-up at the end of the function? It seems 
R can not release the memory once it has been used. When I close the R 
application and open the R application again then the memory is back down 
to what it is supposed to be, the size of the workspace, plus any new 
objects that I have created

Does anybody know what is going on?

Peter



From h.wickham at auckland.ac.nz  Fri May 21 03:17:29 2004
From: h.wickham at auckland.ac.nz (Hadley Wickham)
Date: Fri, 21 May 2004 13:17:29 +1200
Subject: [R] for() to lapply()
In-Reply-To: <opr8bf9kd8faouaq@200.24.8.4>
References: <opr8bf9kd8faouaq@200.24.8.4>
Message-ID: <40AD58A9.3040001@auckland.ac.nz>

> I have the following problem:
> I have a list of data.frames (12 variables and 60000 rows, each)
> 
> I have to merge from an specific point of the list to the
> end of the list, I am doing so with a for() loop but it is
> too inefficient and it exhausts memory.

How about:

a <- list(
	data.frame(a=1),
	data.frame(a=2),
	data.frame(a=3),
	data.frame(a=4)
)
do.call("rbind", a)
do.call("rbind", a[3:4])

(assuming that the data frames have the same variables)

Hadley



From r-stats at arcriswell.com  Fri May 21 03:41:58 2004
From: r-stats at arcriswell.com (Andrew Criswell)
Date: Fri, 21 May 2004 08:41:58 +0700
Subject: Windows versus Unix packages in CRAN (Was Re: [R] Rmetrics)
In-Reply-To: <40AC4B59.8E857FC4@math.uncc.edu>
References: <200405200301.i4K31KIp454163@atlas.otago.ac.nz>
	<40AC4B59.8E857FC4@math.uncc.edu>
Message-ID: <40AD5E66.1060609@arcriswell.com>

Hello all:

On my linux platform, I ran the commands,

mkdir fBasics
unzip fBasics.zip -d fBasics
rm fBasics/src/*.o
R CMD check fBasics

That was 3 minutes. Next, I copied the files contained in 
fBasics.Rcheck/fBasics to the R library.

 > library(fBasics)

fBasics:    Markets, Basic Statistics, Date and TimeError in 
try(winMenuAdd("Rmetrics")) : couldn't find function "winMenuAdd"
 >

So, how do I get it to work "with no problems" in Linux??

Thanks,
Andrew

Janusz Kawczak wrote:

>And it seems that this vicious circle continues forever. Before
>posting these kind of messages can you please read the INSTRUCTIONS.
>fBasics_190.10051.zip is a COMPILED version of the package, not
>a source as you claim to be!
>
>It works with no problems; well, at least under Linux.
>
>Janusz.
>
>"Richard A. O'Keefe" wrote:
>
>  
>
>>Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>        mkdir fBasics
>>        unzip fBasics.zip -d fBasics
>>        rm fBasics/src/*.o
>>        R CMD check fBasics
>>
>>        and that took me about 3 minutes.
>>
>>Now me, I just did
>>
>>        unzip -a fBasics_190.10051.zip
>>        R CMD INSTALL fBasics
>>        rm -rf fBasics
>>
>>in a naive and trusting manner.  It took me considerably longer than 3
>>minutes to learn that this was what I should do, and when I did learn,
>>I wondered "if it's this simple, why can't R CMD INSTALL do it?"
>>
>>Now I discover that it isn't that simple.  The installation apparently
>>went smoothly.  This is R, right?  Never occurred to me that there might
>>be problems.
>>
>>Now, B-G--R!  It turns out that core stuff is supplied as .dll files,
>>which of course my UltraSPARC can do nothing with.
>>
>>The author of the Rmetrics code has a perfect right to provide his code
>>in any form he wants under any conditions he wants (subject to GPL &c).
>>In particular, if he wants to provide a distribution which only works under
>>Windows, that's perfectly OK.
>>
>>**BUT** when a distribution is peculiar to one operating system, that really
>>should be highlighted in big bold letters:  this is a WINDOWS BINARY
>>version, so that people who can't use Windows .DLL files are spared a day
>>of trying to figure out how to unpack and of doing an installation which
>>reports no errors at all and of them finding that things do not work.
>>
>>There is *NOTHING* on http://www.itp.phys.ethz.ch/econophysics/R/download.htm
>>that says "Windows only".  Click on "I accept"and the page you arrive at has
>>nothing in the text anywhere that says "Windows only" or "what to do if not
>>Windows".  (The http://.../R/bin/windows/contrib/1.9 address of the page
>>was, in retrospect, a big clue, sigh.)
>>
>>        It would of course be nice if the developers had done
>>
>>        R CMD check fBasics
>>
>>But if you go into the Sources directory, which I suppose you must have,
>>for each of {fBasics,fExtremes,fOptions,fSeries} there is an
>>xxx-00check.log.txt, so they _did_ run R CMD check.
>>
>>        and sorted out the errors, then
>>        R CMD build fBasics
>>
>>Those same check logs show errors (like failure to build .dvi files).
>>
>>Will it work if I download the Sources packages?
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From quietroom78 at hotmail.com  Fri May 21 04:09:10 2004
From: quietroom78 at hotmail.com (bang jeong sook)
Date: Fri, 21 May 2004 02:09:10 +0000
Subject: [R] function for running MS-DOS on R
Message-ID: <BAY16-F104sI5gECk7T00036510@hotmail.com>


I had downloaded the program that runs on MS-DOS.
Is it possible for MS-DOS to be run in R such as WinBugs1.4?
I wonder whether there is the R function for running MS-DOS from R such as  
the 'bug.r' function to make Winbugs practicable in R.

I had heard Rterm.exe that runs on MS-DOS.
However, What I need is to run MS-DOS in R but to run R in MS-DOS.

_________________________________________________________________
     MSN Hotmail  .    
http://loginnet.passport.com/login.srf?id=2&svc=mail&cbid=24325&msppjph=1&lc=1042



From maustin at amgen.com  Fri May 21 04:32:12 2004
From: maustin at amgen.com (Austin, Matt)
Date: Thu, 20 May 2004 19:32:12 -0700
Subject: [R] function for running MS-DOS on R
Message-ID: <E7D5AB4811D20B489622AABA9C53859101F10DA9@teal-exch.amgen.com>

Perhaps you could use the R2WinBugs package?

--Matt

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
bounces at stat.math.ethz.ch]On Behalf Of bang jeong sook
Sent: Thursday, May 20, 2004 19:9 PM
To: R-help at stat.math.ethz.ch
Subject: [R] function for running MS-DOS on R



I had downloaded the program that runs on MS-DOS.
Is it possible for MS-DOS to be run in R such as WinBugs1.4?
I wonder whether there is the R function for running MS-DOS from R such as  
the 'bug.r' function to make Winbugs practicable in R.

I had heard Rterm.exe that runs on MS-DOS.
However, What I need is to run MS-DOS in R but to run R in MS-DOS.

_________________________________________________________________
     MSN Hotmail  .    
http://loginnet.passport.com/login.srf?id=2&svc=mail&cbid=24325&msppjph=1&lc
=1042

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-
guide.html



From jkawczak at uncc.edu  Fri May 21 05:43:44 2004
From: jkawczak at uncc.edu (Janusz Kawczak)
Date: Thu, 20 May 2004 23:43:44 -0400 (EDT)
Subject: Windows versus Unix packages in CRAN (Was Re: [R] Rmetrics)
In-Reply-To: <40AD5E66.1060609@arcriswell.com>
References: <200405200301.i4K31KIp454163@atlas.otago.ac.nz>
	<40AC4B59.8E857FC4@math.uncc.edu> <40AD5E66.1060609@arcriswell.com>
Message-ID: <Pine.GSO.4.55.0405202337380.21892@ws80.uncc.edu>

Here is what I get:

R : Copyright 2004, The R Foundation for Statistical Computing
Version 1.9.0  (2004-04-12), ISBN 3-900051-00-3

>>> .....  <<<
[Previously saved workspace restored]

> library(fBasics)
---------------------------------------------------------------
fLibraries: A SOFTWARE COLLECTION FOR FINANCIAL ENGINEERS
fBasics:    Markets, Basic Statistics, Date and Time
---------------------------------------------------------------
>

(there were no alterations done to the above output except where >>> ....
<<< occurs!)

You simply need to remove the stuff related to MS Win from zzz.R;
in partricular the lines after if( .... ) to clear your message.
As you can see, the info relates to the WinMenu under MS Win.

Hope this helps.

Janusz.

On Fri, 21 May 2004, Andrew Criswell wrote:

> Hello all:
>
> On my linux platform, I ran the commands,
>
> mkdir fBasics
> unzip fBasics.zip -d fBasics
> rm fBasics/src/*.o
> R CMD check fBasics
>
> That was 3 minutes. Next, I copied the files contained in
> fBasics.Rcheck/fBasics to the R library.
>
>  > library(fBasics)
>
> fBasics:    Markets, Basic Statistics, Date and TimeError in
> try(winMenuAdd("Rmetrics")) : couldn't find function "winMenuAdd"
>  >
>
> So, how do I get it to work "with no problems" in Linux??
>
> Thanks,
> Andrew
>
> Janusz Kawczak wrote:
>
> >And it seems that this vicious circle continues forever. Before
> >posting these kind of messages can you please read the INSTRUCTIONS.
> >fBasics_190.10051.zip is a COMPILED version of the package, not
> >a source as you claim to be!
> >
> >It works with no problems; well, at least under Linux.
> >
> >Janusz.
> >
> >"Richard A. O'Keefe" wrote:
> >
> >
> >
> >>Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> >>        mkdir fBasics
> >>        unzip fBasics.zip -d fBasics
> >>        rm fBasics/src/*.o
> >>        R CMD check fBasics
> >>
> >>        and that took me about 3 minutes.
> >>
> >>Now me, I just did
> >>
> >>        unzip -a fBasics_190.10051.zip
> >>        R CMD INSTALL fBasics
> >>        rm -rf fBasics
> >>
> >>in a naive and trusting manner.  It took me considerably longer than 3
> >>minutes to learn that this was what I should do, and when I did learn,
> >>I wondered "if it's this simple, why can't R CMD INSTALL do it?"
> >>
> >>Now I discover that it isn't that simple.  The installation apparently
> >>went smoothly.  This is R, right?  Never occurred to me that there might
> >>be problems.
> >>
> >>Now, B-G--R!  It turns out that core stuff is supplied as .dll files,
> >>which of course my UltraSPARC can do nothing with.
> >>
> >>The author of the Rmetrics code has a perfect right to provide his code
> >>in any form he wants under any conditions he wants (subject to GPL &c).
> >>In particular, if he wants to provide a distribution which only works under
> >>Windows, that's perfectly OK.
> >>
> >>**BUT** when a distribution is peculiar to one operating system, that really
> >>should be highlighted in big bold letters:  this is a WINDOWS BINARY
> >>version, so that people who can't use Windows .DLL files are spared a day
> >>of trying to figure out how to unpack and of doing an installation which
> >>reports no errors at all and of them finding that things do not work.
> >>
> >>There is *NOTHING* on http://www.itp.phys.ethz.ch/econophysics/R/download.htm
> >>that says "Windows only".  Click on "I accept"and the page you arrive at has
> >>nothing in the text anywhere that says "Windows only" or "what to do if not
> >>Windows".  (The http://.../R/bin/windows/contrib/1.9 address of the page
> >>was, in retrospect, a big clue, sigh.)
> >>
> >>        It would of course be nice if the developers had done
> >>
> >>        R CMD check fBasics
> >>
> >>But if you go into the Sources directory, which I suppose you must have,
> >>for each of {fBasics,fExtremes,fOptions,fSeries} there is an
> >>xxx-00check.log.txt, so they _did_ run R CMD check.
> >>
> >>        and sorted out the errors, then
> >>        R CMD build fBasics
> >>
> >>Those same check logs show errors (like failure to build .dvi files).
> >>
> >>Will it work if I download the Sources packages?
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>
> >>
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
> >
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From petr.pikal at precheza.cz  Fri May 21 07:24:28 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 21 May 2004 07:24:28 +0200
Subject: [R] Memory usage of R on Windows XP
In-Reply-To: <5.2.0.9.0.20040520204754.00b3c2b0@pop.videotron.ca>
Message-ID: <40ADAEAC.32596.39B725@localhost>



On 20 May 2004 at 20:58, Peter Wilkinson wrote:

> 
> I am running R 1.8.1 on windows xp. I have been using the 'apply' R
> function to run a short function against a matrix of 19000 x 340 rows
> ... yes it is a big matrix. every item in the matrix is a float that
> can have a maximum value of 2^16 ~ 65k.

Hi

I would go for computing only, should be quicker.

(yourmatrix>=256)*1

will give you 1 on places where was number greater or equal 256 and 0 where it 
was lower.

Not sure about memory issues but I suppose better performance than if else apply 
construction.

Cheers
Petr


> 
> The function:
> 
> mask256 <- function(value) {
>      if (value < 256) {
>         result = 0
>      }
>      else {
>         result = 1
>      }
>      result
> }
> 
> what happens is that the memory required for the session to run starts
> ballooning. The matrix with a few other objects starts at about 160M,
> but then quickly goes up to 750M, and stays there when the function
> has completed
> 
> I am fairly new to R. Is there something I should know about writing
> functions , i.e. do I need to clean-up at the end of the function? It
> seems R can not release the memory once it has been used. When I close

I suppose R is doing it best but Windows does not take it back.

> the R application and open the R application again then the memory is
> back down to what it is supposed to be, the size of the workspace,
> plus any new objects that I have created
> 
> Does anybody know what is going on?
> 
> Peter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From fzoellne at TechFak.Uni-Bielefeld.DE  Fri May 21 10:00:51 2004
From: fzoellne at TechFak.Uni-Bielefeld.DE (Frank Gerrit Zoellner)
Date: Fri, 21 May 2004 10:00:51 +0200
Subject: [R] screeplot
In-Reply-To: <40ADAEAC.32596.39B725@localhost>
References: <5.2.0.9.0.20040520204754.00b3c2b0@pop.videotron.ca>
	<40ADAEAC.32596.39B725@localhost>
Message-ID: <20040521080051.GA31313@hindemith.TechFak.Uni-Bielefeld.DE>

Hi!

I have a question concerning the screeplot function in R. What is the meaning of the colours in the plot. I applied princomp object to the screeplot funtion and it plotted the components against its variance, that's ok. But I have no idea about the different colouring of the boxes. I attached a plot so that you can see what I mean.

Thanks,
-- 
Frank G. Zoellner
AG Angewandte Informatik
Technische Fakult"at
Universit"at Bielefeld
phone: +49(0)521-106-2951
fax:   +49(0)521-106-2992
email: fzoellne at techfak.uni-bielefeld.de
-------------- next part --------------
A non-text attachment was scrubbed...
Name: pcachi1ARG.pdf
Type: application/pdf
Size: 6918 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20040521/17036b83/pcachi1ARG.pdf

From vidali at med.unipmn.it  Fri May 21 11:03:43 2004
From: vidali at med.unipmn.it (Matteo Vidali)
Date: Fri, 21 May 2004 10:03:43 +0100
Subject: [R] bars with sd
Message-ID: <20040521084042.M78574@med.unipmn.it>

I need some help for a curious question of a friend of mine.
She usually does some experiments (3-5 repeats for each exp) and then she 
calculates mean and standard deviation. 
In microsoft excel she writes something like the following

sample  mean   sd
a       1.25   0.35
b       2.65   0.65
c       3.45   0.50

She can do a vertical barplot graph just giving mean value and specifying 
the standard deviation value for each bar in the graph.

My friend wants to know if it is possible to do the same with R. She has 
tried also with Open Office and seen that in that program you can plot mean 
values as bars but it is not possible to specify a different sd for each 
bar 'cause the program, if you ask to put the standard deviation, calculates 
a common sd using the mean values. 
I was not able to give her an answer for the barplot function in R. I have 
just said to her that it is likely due to the fact that using a barplot 
graph to plot mean and standard deviation values it is non a good practice, 
since the height (or the area) of bars should represent frequency and that 
putting a standard deviation in that way it is at least quite confusing for 
the reader to interpret the graph. Some scientific journal revisors 
discourage this practice. She should instead use a boxplot or just plotting 
the different repetition values for each sample as points and add a linea 
indicating the mean.
But if this is correct why in some programs like open office you can plot 
bars with a common standard deviation???? when will you need this last type 
of graph?

any suggestion? any help?
thanks in advance
Matteo



From Timur.Elzhov at jinr.ru  Fri May 21 10:18:07 2004
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri, 21 May 2004 12:18:07 +0400
Subject: [R] .First() in R 1.9.0
Message-ID: <20040521081807.GA16881@nf034.jinr.ru>

Dear R experts,

I just upgraded R from 1.8.1 to 1.9.0 version. My .First()
function in ~/.Rprofile contains x11() and par() functions.

.First <- function() {
    x11(display = "", 8.0, 5.0)
    par(las = 1, ...)
##  ...
}

And, R claims now, on startup:

    [hello messages skiped ...]
    Error in .First() : couldn't find function "x11"
    >

I commented "x11" string, and get the same error about par:
    Error in .First() : couldn't find function "par"
    > 

There was no such a problen with previos R version.
Why .First function knows nothing about "x11" and "par" functions?
Thanks.

--
WBR,
Timur



From angel_lul at hotmail.com  Fri May 21 14:38:22 2004
From: angel_lul at hotmail.com (Angel Lopez)
Date: Fri, 21 May 2004 14:38:22 +0200
Subject: [R] axis labels disappear
Message-ID: <40ADF83E.1040706@hotmail.com>

When I do a plot, e.g.
plot(1:10)
and resize the window so that the x-axis becomes too small to hold all 
the x-axis labels, R automatically makes some of the labels disappear so 
that the remaining fit in the available space.
I would like to be able to tell R which labels should not be removed.

I've tried plotting the axis with axis() but this behaviour is still there.
plot(1:10,xaxt="n")
axis(side=1,at=1:10,labels=c("1","","","","5","","","","","10"))

In my case when I resize the window first the "10" disappears and the 
the "5". Also if I start the graph with a 'small' window (e.g. 
X11(width=3,height=3) I do not get the "10".
Is there a way to force that these labels are not removed automatically?

I've searched the documentation but couldn't find any reference, Could 
anyone point me to the right documentation for this feature?
Thanks
Angel



From michael.watson at bbsrc.ac.uk  Fri May 21 12:53:10 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Fri, 21 May 2004 11:53:10 +0100
Subject: [R] Help with hclust() and plot()
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9516EE56@iahce2knas1.iah.bbsrc.reserved>

Hi

Thanks again, but it *still* doesn't work!  I used the following
commands:

> eucomplete <- hclust(d = dist(p[, 2:13], method = "euclidean"), method
= "complete")
> eucomplete$labels
 [1] "1"  "2"  "3"  "4"  "5"  "6"  "7"  "8"  "9"  "10" "11" "12" "13"
"14" "15"
[16] "16" "17" "18" "19" "20" "21" "22" "23" "24"
> eucomplete$labels <- p[,1]
> eucomplete$labels
 [1] NB Hippo S2_824   ME7 Hippo S2_0    ME7 Hippo S2_949  ME7 Hippo
S2_952
 [5] ME7 Hippo S2_823  NB Hippo S2_819D  ME7 Hippo S2_772D ME7 Hippo
S2_#003
 [9] NB Hippo S2_818D  NB Hippo S2_1     NB Hippo S2_#010  NB Hippo
S2_775D
[13] NB Hippo S2_774D  NB Hippo S2_#009  NB Hippo S2_950   NB Hippo
S2_826
[17] NB Hippo S2_#007  NB Hippo S2_951   ME7 Hippo S2_#004 ME7 Hippo
S2_820D
[21] ME7 Hippo S2_#005 ME7 Hippo S2_773D ME7 Hippo S2_#006 ME7 Hippo
S2_822D
24 Levels: ME7 Hippo S2_#003 ME7 Hippo S2_#004 ... NB Hippo S2_951
> plot(as.dendrogram(eucomplete))

I get a lovely formatted dendrogram but the labels are still numbers
1-24! :-(

As can be seen, I have changed eucomplete$labels to be the text I want,
but the plot command still writes out numbers :-(

>plot(eucomplete)

Does work, and I get the right labels.  But I want a dendrogram!

Thanks in advance for your help

Mick



-----Original Message-----
From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at PDF.COM] 
Sent: 20 May 2004 19:04
To: michael watson (IAH-C)
Cc: R-Help (E-mail)
Subject: Re: [R] Help with hclust() and plot()




michael watson (IAH-C) wrote:

> Hi
> 
> Thanks for that!  BUT if I use as.dendrogram, I can't use my labels 
> anymore!
> 
> 
>>plot(hclust(...etc), labels=p[,1])
> 
> 
> Works fine.  But:
> 
> 
>>plot(as.dendrogram(hclust(...etc)), labels=p[,1])
> 
> 
> Gives me errors:
> 
> Error in axis(side, at, labels, tick, line, pos, outer, font, vfont, 
> lty,  :
> 	location and label lengths differ, 6 != 24
> 
> I have 24 labels.  I have no idea where it gets 6 from!
> 
> My 'dendrogram' has '2 branches and 24 members total'.
> 
> SOOO, how do I get my dendrogram horizontal, or vertical for that 
> matter, with useful labels instead of 1,2,3,4,5,etc
> 
> Thanks in advance for your help!
> 
> Mick
> 

Mick,
   Change the labels in hclust first:

data(USArrests)
hc <- hclust(dist(USArrests), "ave")
hc$labels <- 1:50
dend1 <- as.dendrogram(hc)
plot(dend1, horiz = TRUE)

--sundar



From sdavis2 at mail.nih.gov  Fri May 21 13:03:00 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 21 May 2004 07:03:00 -0400
Subject: [R] screeplot
In-Reply-To: <20040521080051.GA31313@hindemith.TechFak.Uni-Bielefeld.DE>
Message-ID: <BCD35A24.835C%sdavis2@mail.nih.gov>

As far as I know, these are the "standard" heat colors and do not hold
meaning.  Try doing a barplot (on which screeplot is built) of some
data--same colors, but no meaning.  They are just there to make our eyes
happy.

Sean

On 5/21/04 4:00 AM, "Frank Gerrit Zoellner"
<fzoellne at TechFak.Uni-Bielefeld.DE> wrote:

> Hi!
> 
> I have a question concerning the screeplot function in R. What is the meaning
> of the colours in the plot. I applied princomp object to the screeplot funtion
> and it plotted the components against its variance, that's ok. But I have no
> idea about the different colouring of the boxes. I attached a plot so that you
> can see what I mean.
> 
> Thanks,



From michael.watson at bbsrc.ac.uk  Fri May 21 13:12:21 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Fri, 21 May 2004 12:12:21 +0100
Subject: [R] Help with hclust() and plot()
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9516EE57@iahce2knas1.iah.bbsrc.reserved>

OK, I have it working now
I just read in my data a little differently and now it works

HOWEVER, now my labels shoot off the end of the plot - so the labels are
truncated as they hit the edge of the window.  This happens for both
horizontal and vertical dendrograms

I guess this is an argument to plot that I need to set, but which one ?
:-(

Thanks

Mick

-----Original Message-----
From: michael watson (IAH-C) 
Sent: 21 May 2004 11:53
To: sundar.dorai-raj at pdf.com
Cc: R-Help (E-mail)
Subject: RE: [R] Help with hclust() and plot()


Hi

Thanks again, but it *still* doesn't work!  I used the following
commands:

> eucomplete <- hclust(d = dist(p[, 2:13], method = "euclidean"), method
= "complete")
> eucomplete$labels
 [1] "1"  "2"  "3"  "4"  "5"  "6"  "7"  "8"  "9"  "10" "11" "12" "13"
"14" "15" [16] "16" "17" "18" "19" "20" "21" "22" "23" "24"
> eucomplete$labels <- p[,1]
> eucomplete$labels
 [1] NB Hippo S2_824   ME7 Hippo S2_0    ME7 Hippo S2_949  ME7 Hippo
S2_952
 [5] ME7 Hippo S2_823  NB Hippo S2_819D  ME7 Hippo S2_772D ME7 Hippo
S2_#003
 [9] NB Hippo S2_818D  NB Hippo S2_1     NB Hippo S2_#010  NB Hippo
S2_775D
[13] NB Hippo S2_774D  NB Hippo S2_#009  NB Hippo S2_950   NB Hippo
S2_826
[17] NB Hippo S2_#007  NB Hippo S2_951   ME7 Hippo S2_#004 ME7 Hippo
S2_820D
[21] ME7 Hippo S2_#005 ME7 Hippo S2_773D ME7 Hippo S2_#006 ME7 Hippo
S2_822D 24 Levels: ME7 Hippo S2_#003 ME7 Hippo S2_#004 ... NB Hippo
S2_951
> plot(as.dendrogram(eucomplete))

I get a lovely formatted dendrogram but the labels are still numbers
1-24! :-(

As can be seen, I have changed eucomplete$labels to be the text I want,
but the plot command still writes out numbers :-(

>plot(eucomplete)

Does work, and I get the right labels.  But I want a dendrogram!

Thanks in advance for your help

Mick



-----Original Message-----
From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at PDF.COM] 
Sent: 20 May 2004 19:04
To: michael watson (IAH-C)
Cc: R-Help (E-mail)
Subject: Re: [R] Help with hclust() and plot()




michael watson (IAH-C) wrote:

> Hi
> 
> Thanks for that!  BUT if I use as.dendrogram, I can't use my labels
> anymore!
> 
> 
>>plot(hclust(...etc), labels=p[,1])
> 
> 
> Works fine.  But:
> 
> 
>>plot(as.dendrogram(hclust(...etc)), labels=p[,1])
> 
> 
> Gives me errors:
> 
> Error in axis(side, at, labels, tick, line, pos, outer, font, vfont,
> lty,  :
> 	location and label lengths differ, 6 != 24
> 
> I have 24 labels.  I have no idea where it gets 6 from!
> 
> My 'dendrogram' has '2 branches and 24 members total'.
> 
> SOOO, how do I get my dendrogram horizontal, or vertical for that
> matter, with useful labels instead of 1,2,3,4,5,etc
> 
> Thanks in advance for your help!
> 
> Mick
> 

Mick,
   Change the labels in hclust first:

data(USArrests)
hc <- hclust(dist(USArrests), "ave")
hc$labels <- 1:50
dend1 <- as.dendrogram(hc)
plot(dend1, horiz = TRUE)

--sundar

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From sdavis2 at mail.nih.gov  Fri May 21 13:29:37 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 21 May 2004 07:29:37 -0400
Subject: [R] Help with hclust() and plot()
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9516EE57@iahce2knas1.iah.bbsrc.reserved>
Message-ID: <BCD36061.8360%sdavis2@mail.nih.gov>

See ?par.  It is a long help, but pay particular attention to
par(mar=c(...)).  It changes margins on plots.

Sean

On 5/21/04 7:12 AM, "michael watson (IAH-C)" <michael.watson at bbsrc.ac.uk>
wrote:

> OK, I have it working now
> I just read in my data a little differently and now it works
> 
> HOWEVER, now my labels shoot off the end of the plot - so the labels are
> truncated as they hit the edge of the window.  This happens for both
> horizontal and vertical dendrograms
> 
> I guess this is an argument to plot that I need to set, but which one ?
> :-(
> 
> Thanks
> 
> Mick
> 
> -----Original Message-----
> From: michael watson (IAH-C)
> Sent: 21 May 2004 11:53
> To: sundar.dorai-raj at pdf.com
> Cc: R-Help (E-mail)
> Subject: RE: [R] Help with hclust() and plot()
> 
> 
> Hi
> 
> Thanks again, but it *still* doesn't work!  I used the following
> commands:
> 
>> eucomplete <- hclust(d = dist(p[, 2:13], method = "euclidean"), method
> = "complete")
>> eucomplete$labels
> [1] "1"  "2"  "3"  "4"  "5"  "6"  "7"  "8"  "9"  "10" "11" "12" "13"
> "14" "15" [16] "16" "17" "18" "19" "20" "21" "22" "23" "24"
>> eucomplete$labels <- p[,1]
>> eucomplete$labels
> [1] NB Hippo S2_824   ME7 Hippo S2_0    ME7 Hippo S2_949  ME7 Hippo
> S2_952
> [5] ME7 Hippo S2_823  NB Hippo S2_819D  ME7 Hippo S2_772D ME7 Hippo
> S2_#003
> [9] NB Hippo S2_818D  NB Hippo S2_1     NB Hippo S2_#010  NB Hippo
> S2_775D
> [13] NB Hippo S2_774D  NB Hippo S2_#009  NB Hippo S2_950   NB Hippo
> S2_826
> [17] NB Hippo S2_#007  NB Hippo S2_951   ME7 Hippo S2_#004 ME7 Hippo
> S2_820D
> [21] ME7 Hippo S2_#005 ME7 Hippo S2_773D ME7 Hippo S2_#006 ME7 Hippo
> S2_822D 24 Levels: ME7 Hippo S2_#003 ME7 Hippo S2_#004 ... NB Hippo
> S2_951
>> plot(as.dendrogram(eucomplete))
> 
> I get a lovely formatted dendrogram but the labels are still numbers
> 1-24! :-(
> 
> As can be seen, I have changed eucomplete$labels to be the text I want,
> but the plot command still writes out numbers :-(
> 
>> plot(eucomplete)
> 
> Does work, and I get the right labels.  But I want a dendrogram!
> 
> Thanks in advance for your help
> 
> Mick
> 
> 
> 
> -----Original Message-----
> From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at PDF.COM]
> Sent: 20 May 2004 19:04
> To: michael watson (IAH-C)
> Cc: R-Help (E-mail)
> Subject: Re: [R] Help with hclust() and plot()
> 
> 
> 
> 
> michael watson (IAH-C) wrote:
> 
>> Hi
>> 
>> Thanks for that!  BUT if I use as.dendrogram, I can't use my labels
>> anymore!
>> 
>> 
>>> plot(hclust(...etc), labels=p[,1])
>> 
>> 
>> Works fine.  But:
>> 
>> 
>>> plot(as.dendrogram(hclust(...etc)), labels=p[,1])
>> 
>> 
>> Gives me errors:
>> 
>> Error in axis(side, at, labels, tick, line, pos, outer, font, vfont,
>> lty,  :
>> location and label lengths differ, 6 != 24
>> 
>> I have 24 labels.  I have no idea where it gets 6 from!
>> 
>> My 'dendrogram' has '2 branches and 24 members total'.
>> 
>> SOOO, how do I get my dendrogram horizontal, or vertical for that
>> matter, with useful labels instead of 1,2,3,4,5,etc
>> 
>> Thanks in advance for your help!
>> 
>> Mick
>> 
> 
> Mick,
>  Change the labels in hclust first:
> 
> data(USArrests)
> hc <- hclust(dist(USArrests), "ave")
> hc$labels <- 1:50
> dend1 <- as.dendrogram(hc)
> plot(dend1, horiz = TRUE)
> 
> --sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From michael.watson at bbsrc.ac.uk  Fri May 21 13:51:35 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Fri, 21 May 2004 12:51:35 +0100
Subject: [R] Help with hclust() and plot()
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9516EE58@iahce2knas1.iah.bbsrc.reserved>

Hi Sean

I obviously wasn't cut out for this.

Just to try it out, I tried:

>plot(1:8, 1:8, mar=c(5,4,4,2))

(this is the default according to the help)

All I got was:

"there were twelve warnings"

>warnings()
1: parameter "mar" couldn't be set in high-level plot() function

BUT in the help, the example is given as:

<highlevel plot> (..., <tag> = <value>)

So, I know I must be doing something stupid, but I have no idea what....

Mick

-----Original Message-----
From: Sean Davis [mailto:sdavis2 at mail.nih.gov] 
Sent: 21 May 2004 12:30
To: michael watson (IAH-C); sundar.dorai-raj at pdf.com
Cc: r-help
Subject: Re: [R] Help with hclust() and plot()


See ?par.  It is a long help, but pay particular attention to
par(mar=c(...)).  It changes margins on plots.

Sean

On 5/21/04 7:12 AM, "michael watson (IAH-C)"
<michael.watson at bbsrc.ac.uk>
wrote:

> OK, I have it working now
> I just read in my data a little differently and now it works
> 
> HOWEVER, now my labels shoot off the end of the plot - so the labels 
> are truncated as they hit the edge of the window.  This happens for 
> both horizontal and vertical dendrograms
> 
> I guess this is an argument to plot that I need to set, but which one 
> ? :-(
> 
> Thanks
> 
> Mick
> 
> -----Original Message-----
> From: michael watson (IAH-C)
> Sent: 21 May 2004 11:53
> To: sundar.dorai-raj at pdf.com
> Cc: R-Help (E-mail)
> Subject: RE: [R] Help with hclust() and plot()
> 
> 
> Hi
> 
> Thanks again, but it *still* doesn't work!  I used the following
> commands:
> 
>> eucomplete <- hclust(d = dist(p[, 2:13], method = "euclidean"), 
>> method
> = "complete")
>> eucomplete$labels
> [1] "1"  "2"  "3"  "4"  "5"  "6"  "7"  "8"  "9"  "10" "11" "12" "13" 
> "14" "15" [16] "16" "17" "18" "19" "20" "21" "22" "23" "24"
>> eucomplete$labels <- p[,1]
>> eucomplete$labels
> [1] NB Hippo S2_824   ME7 Hippo S2_0    ME7 Hippo S2_949  ME7 Hippo
> S2_952
> [5] ME7 Hippo S2_823  NB Hippo S2_819D  ME7 Hippo S2_772D ME7 Hippo 
> S2_#003
> [9] NB Hippo S2_818D  NB Hippo S2_1     NB Hippo S2_#010  NB Hippo
> S2_775D
> [13] NB Hippo S2_774D  NB Hippo S2_#009  NB Hippo S2_950   NB Hippo
> S2_826
> [17] NB Hippo S2_#007  NB Hippo S2_951   ME7 Hippo S2_#004 ME7 Hippo
> S2_820D
> [21] ME7 Hippo S2_#005 ME7 Hippo S2_773D ME7 Hippo S2_#006 ME7 Hippo 
> S2_822D 24 Levels: ME7 Hippo S2_#003 ME7 Hippo S2_#004 ... NB Hippo 
> S2_951
>> plot(as.dendrogram(eucomplete))
> 
> I get a lovely formatted dendrogram but the labels are still numbers 
> 1-24! :-(
> 
> As can be seen, I have changed eucomplete$labels to be the text I 
> want, but the plot command still writes out numbers :-(
> 
>> plot(eucomplete)
> 
> Does work, and I get the right labels.  But I want a dendrogram!
> 
> Thanks in advance for your help
> 
> Mick
> 
> 
> 
> -----Original Message-----
> From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at PDF.COM]
> Sent: 20 May 2004 19:04
> To: michael watson (IAH-C)
> Cc: R-Help (E-mail)
> Subject: Re: [R] Help with hclust() and plot()
> 
> 
> 
> 
> michael watson (IAH-C) wrote:
> 
>> Hi
>> 
>> Thanks for that!  BUT if I use as.dendrogram, I can't use my labels 
>> anymore!
>> 
>> 
>>> plot(hclust(...etc), labels=p[,1])
>> 
>> 
>> Works fine.  But:
>> 
>> 
>>> plot(as.dendrogram(hclust(...etc)), labels=p[,1])
>> 
>> 
>> Gives me errors:
>> 
>> Error in axis(side, at, labels, tick, line, pos, outer, font, vfont, 
>> lty,  : location and label lengths differ, 6 != 24
>> 
>> I have 24 labels.  I have no idea where it gets 6 from!
>> 
>> My 'dendrogram' has '2 branches and 24 members total'.
>> 
>> SOOO, how do I get my dendrogram horizontal, or vertical for that 
>> matter, with useful labels instead of 1,2,3,4,5,etc
>> 
>> Thanks in advance for your help!
>> 
>> Mick
>> 
> 
> Mick,
>  Change the labels in hclust first:
> 
> data(USArrests)
> hc <- hclust(dist(USArrests), "ave")
> hc$labels <- 1:50
> dend1 <- as.dendrogram(hc)
> plot(dend1, horiz = TRUE)
> 
> --sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From sdavis2 at mail.nih.gov  Fri May 21 13:56:02 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 21 May 2004 07:56:02 -0400
Subject: [R] Help with hclust() and plot()
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9516EE58@iahce2knas1.iah.bbsrc.reserved>
Message-ID: <BCD36692.8369%sdavis2@mail.nih.gov>

The use for par is:

> plot(1:8,1:8) #you must have an open graphics window before par has an effect
> par(mar=c(5,4,4,2)) #this will stay in effect until you either close the
graphics window or change it with another call to par
> plot(1:8,1:8)

In other words, par works on an open graphics device and applies to all
subsequent plots to that device.  You can't put it in the plot command--a
bit awkward at times, but often does save time and is very general.

Sean

On 5/21/04 7:51 AM, "michael watson (IAH-C)" <michael.watson at bbsrc.ac.uk>
wrote:

> Hi Sean
> 
> I obviously wasn't cut out for this.
> 
> Just to try it out, I tried:
> 
>> plot(1:8, 1:8, mar=c(5,4,4,2))
> 
> (this is the default according to the help)
> 
> All I got was:
> 
> "there were twelve warnings"
> 
>> warnings()
> 1: parameter "mar" couldn't be set in high-level plot() function
> 
> BUT in the help, the example is given as:
> 
> <highlevel plot> (..., <tag> = <value>)
> 
> So, I know I must be doing something stupid, but I have no idea what....
> 
> Mick
> 
> -----Original Message-----
> From: Sean Davis [mailto:sdavis2 at mail.nih.gov]
> Sent: 21 May 2004 12:30
> To: michael watson (IAH-C); sundar.dorai-raj at pdf.com
> Cc: r-help
> Subject: Re: [R] Help with hclust() and plot()
> 
> 
> See ?par.  It is a long help, but pay particular attention to
> par(mar=c(...)).  It changes margins on plots.
> 
> Sean
> 
> On 5/21/04 7:12 AM, "michael watson (IAH-C)"
> <michael.watson at bbsrc.ac.uk>
> wrote:
> 
>> OK, I have it working now
>> I just read in my data a little differently and now it works
>> 
>> HOWEVER, now my labels shoot off the end of the plot - so the labels
>> are truncated as they hit the edge of the window.  This happens for
>> both horizontal and vertical dendrograms
>> 
>> I guess this is an argument to plot that I need to set, but which one
>> ? :-(
>> 
>> Thanks
>> 
>> Mick
>> 
>> -----Original Message-----
>> From: michael watson (IAH-C)
>> Sent: 21 May 2004 11:53
>> To: sundar.dorai-raj at pdf.com
>> Cc: R-Help (E-mail)
>> Subject: RE: [R] Help with hclust() and plot()
>> 
>> 
>> Hi
>> 
>> Thanks again, but it *still* doesn't work!  I used the following
>> commands:
>> 
>>> eucomplete <- hclust(d = dist(p[, 2:13], method = "euclidean"),
>>> method
>> = "complete")
>>> eucomplete$labels
>> [1] "1"  "2"  "3"  "4"  "5"  "6"  "7"  "8"  "9"  "10" "11" "12" "13"
>> "14" "15" [16] "16" "17" "18" "19" "20" "21" "22" "23" "24"
>>> eucomplete$labels <- p[,1]
>>> eucomplete$labels
>> [1] NB Hippo S2_824   ME7 Hippo S2_0    ME7 Hippo S2_949  ME7 Hippo
>> S2_952
>> [5] ME7 Hippo S2_823  NB Hippo S2_819D  ME7 Hippo S2_772D ME7 Hippo
>> S2_#003
>> [9] NB Hippo S2_818D  NB Hippo S2_1     NB Hippo S2_#010  NB Hippo
>> S2_775D
>> [13] NB Hippo S2_774D  NB Hippo S2_#009  NB Hippo S2_950   NB Hippo
>> S2_826
>> [17] NB Hippo S2_#007  NB Hippo S2_951   ME7 Hippo S2_#004 ME7 Hippo
>> S2_820D
>> [21] ME7 Hippo S2_#005 ME7 Hippo S2_773D ME7 Hippo S2_#006 ME7 Hippo
>> S2_822D 24 Levels: ME7 Hippo S2_#003 ME7 Hippo S2_#004 ... NB Hippo
>> S2_951
>>> plot(as.dendrogram(eucomplete))
>> 
>> I get a lovely formatted dendrogram but the labels are still numbers
>> 1-24! :-(
>> 
>> As can be seen, I have changed eucomplete$labels to be the text I
>> want, but the plot command still writes out numbers :-(
>> 
>>> plot(eucomplete)
>> 
>> Does work, and I get the right labels.  But I want a dendrogram!
>> 
>> Thanks in advance for your help
>> 
>> Mick
>> 
>> 
>> 
>> -----Original Message-----
>> From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at PDF.COM]
>> Sent: 20 May 2004 19:04
>> To: michael watson (IAH-C)
>> Cc: R-Help (E-mail)
>> Subject: Re: [R] Help with hclust() and plot()
>> 
>> 
>> 
>> 
>> michael watson (IAH-C) wrote:
>> 
>>> Hi
>>> 
>>> Thanks for that!  BUT if I use as.dendrogram, I can't use my labels
>>> anymore!
>>> 
>>> 
>>>> plot(hclust(...etc), labels=p[,1])
>>> 
>>> 
>>> Works fine.  But:
>>> 
>>> 
>>>> plot(as.dendrogram(hclust(...etc)), labels=p[,1])
>>> 
>>> 
>>> Gives me errors:
>>> 
>>> Error in axis(side, at, labels, tick, line, pos, outer, font, vfont,
>>> lty,  : location and label lengths differ, 6 != 24
>>> 
>>> I have 24 labels.  I have no idea where it gets 6 from!
>>> 
>>> My 'dendrogram' has '2 branches and 24 members total'.
>>> 
>>> SOOO, how do I get my dendrogram horizontal, or vertical for that
>>> matter, with useful labels instead of 1,2,3,4,5,etc
>>> 
>>> Thanks in advance for your help!
>>> 
>>> Mick
>>> 
>> 
>> Mick,
>>  Change the labels in hclust first:
>> 
>> data(USArrests)
>> hc <- hclust(dist(USArrests), "ave")
>> hc$labels <- 1:50
>> dend1 <- as.dendrogram(hc)
>> plot(dend1, horiz = TRUE)
>> 
>> --sundar
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>> 
>



From rolf at math.unb.ca  Fri May 21 14:02:15 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 21 May 2004 09:02:15 -0300 (ADT)
Subject: [R] Re: Windows versus Unix packages in CRAN ...
Message-ID: <200405211202.i4LC2F49003939@erdos.math.unb.ca>


Janusz Kawczak wrote:

> You simply need to remove the stuff related to MS Win from zzz.R;
> in partricular the lines after if( .... ) to clear your message.
> As you can see, the info relates to the WinMenu under MS Win.

I think people have been more than a little disingenuous in claiming
that getting the Rmetrics package to go under Linux is transparent.
If you have to dig into the code and edit it, then transparent it
ain't.  It may be perfectly easy ***once you know what you're
doing***, but that's a big ``once''.

It is particularly unfair to snarl exasperatedly at inquirers for not
reading the instructions --- as someone did recently --- when there
are in fact NO instructions telling you that you have to dig in and
edit the code.

And I think it is perfectly ***fair*** to say to say that the package
maintainers could and should have done a better job of setting up the
package to make it run out-of-the-box on Linux.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From petr.pikal at precheza.cz  Fri May 21 14:33:35 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 21 May 2004 14:33:35 +0200
Subject: [R] .First() in R 1.9.0
In-Reply-To: <20040521081807.GA16881@nf034.jinr.ru>
Message-ID: <40AE133F.20230.1C2D2E3@localhost>

Hi

I suppose it was answered in few weeks ago and you probably can 
avoid it by setting

library(graphics)

before calling x11 and par in your .First fuction

The correct solution is probably with setHook function 

?setHook

but I was not able to get it work in my .Rprofile, though I read the 
help page and made some trial and errors.

Cheers
Petr

On 21 May 2004 at 12:18, Timur Elzhov wrote:

> Dear R experts,
> 
> I just upgraded R from 1.8.1 to 1.9.0 version. My .First()
> function in ~/.Rprofile contains x11() and par() functions.
> 
> .First <- function() {
>     x11(display = "", 8.0, 5.0)
>     par(las = 1, ...)
> ##  ...
> }
> 
> And, R claims now, on startup:
> 
>     [hello messages skiped ...]
>     Error in .First() : couldn't find function "x11"
>     >
> 
> I commented "x11" string, and get the same error about par:
>     Error in .First() : couldn't find function "par"
>     > 
> 
> There was no such a problen with previos R version.
> Why .First function knows nothing about "x11" and "par" functions?
> Thanks.
> 
> --
> WBR,
> Timur
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From rpeng at jhsph.edu  Fri May 21 14:34:12 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 21 May 2004 08:34:12 -0400
Subject: [R] .First() in R 1.9.0
In-Reply-To: <20040521081807.GA16881@nf034.jinr.ru>
References: <20040521081807.GA16881@nf034.jinr.ru>
Message-ID: <40ADF744.9090605@jhsph.edu>

The startup of R has changed in 1.9.0 and x11() and par() are now in 
the `graphics' package.  I think if you precede your calls to x11() 
and par() with library(graphics), it should work.  Or you could run 
graphics::x11() and graphics::par().  This is the blurb from the 1.9.0 
NEWS file:

         Users may notice that code in .Rprofile is run with only the
         new base loaded and so functions may now not be found.  For
         example, ps.options(horizontal = TRUE) should be preceded by
         library(graphics) or called as graphics::ps.options or,
         better, set as a hook -- see ?setHook.

-roger

Timur Elzhov wrote:
> Dear R experts,
> 
> I just upgraded R from 1.8.1 to 1.9.0 version. My .First()
> function in ~/.Rprofile contains x11() and par() functions.
> 
> .First <- function() {
>     x11(display = "", 8.0, 5.0)
>     par(las = 1, ...)
> ##  ...
> }
> 
> And, R claims now, on startup:
> 
>     [hello messages skiped ...]
>     Error in .First() : couldn't find function "x11"
>     >
> 
> I commented "x11" string, and get the same error about par:
>     Error in .First() : couldn't find function "par"
>     > 
> 
> There was no such a problen with previos R version.
> Why .First function knows nothing about "x11" and "par" functions?
> Thanks.
> 
> --
> WBR,
> Timur
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Fri May 21 15:32:13 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 May 2004 15:32:13 +0200
Subject: [R] R 1.90 make problem with /usr/X11R6/include/X11/Xutil.h on
	suse linux 9.1?
In-Reply-To: <40AAC58F.6070206@channing.harvard.edu>
References: <40AAC58F.6070206@channing.harvard.edu>
Message-ID: <x2u0y9aote.fsf@biostat.ku.dk>

Ross Lazarus <ross.lazarus at channing.harvard.edu> writes:

> This is probably a Suse specific problem and not a bug in R, but I'm
> reporting it in case it's useful for someone to know about....
> 
> Trying to compile R1.9.0 from source on a standard Suse 9.1 install
> (athlon in a shuttle sn41g2).
> configure seems fine but the Suse X11R6 Xlib.h might be toxic.
> 
> In case it helps, here's the sad end to the make output. I can post
> the Xlib.h if that would help...

Looking over the mailing list archives might help more... It's a
problem with recent X releases, same thing as seen on Fedora Core 2.
The current patch-version should be OK -- see the "Snapshots" section
on http://cran.r-project.org/sources.html

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tpapp at axelero.hu  Fri May 21 15:35:20 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Fri, 21 May 2004 15:35:20 +0200
Subject: [R] Help with hclust() and plot()
In-Reply-To: <BCD36692.8369%sdavis2@mail.nih.gov>
References: <8975119BCD0AC5419D61A9CF1A923E9516EE58@iahce2knas1.iah.bbsrc.reserved>
	<BCD36692.8369%sdavis2@mail.nih.gov>
Message-ID: <20040521133520.GB853@localhost>

On Fri, May 21, 2004 at 07:56:02AM -0400, Sean Davis wrote:

> The use for par is:
> 
> > plot(1:8,1:8) #you must have an open graphics window before par has an effect

Instead of making a plot you will discard anyway (since you are making
another when par() takes effect), you might want to initialize the
device using the appropriate functions, eg x11(), postscript(), etc.

> > par(mar=c(5,4,4,2)) #this will stay in effect until you either close the
> graphics window or change it with another call to par
> > plot(1:8,1:8)
> 
> In other words, par works on an open graphics device and applies to all
> subsequent plots to that device.  You can't put it in the plot command--a
> bit awkward at times, but often does save time and is very general.

Best,

Tamas

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From tpapp at axelero.hu  Fri May 21 15:41:18 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Fri, 21 May 2004 15:41:18 +0200
Subject: [R] Re: Windows versus Unix packages in CRAN ...
In-Reply-To: <200405211202.i4LC2F49003939@erdos.math.unb.ca>
References: <200405211202.i4LC2F49003939@erdos.math.unb.ca>
Message-ID: <20040521134118.GC853@localhost>

On Fri, May 21, 2004 at 09:02:15AM -0300, Rolf Turner wrote:

> And I think it is perfectly ***fair*** to say to say that the package
> maintainers could and should have done a better job of setting up the
> package to make it run out-of-the-box on Linux.

You are probably right in saying that they _could_ have done better,
but I would not use "should" in this context.  AFAIK the package is
free (as in beer) software, which means that you are not paying for
it.  The maintainers probably do not need a Linux version (yet), so it
was not easy to use it under Linux.  Feel free to contribute.  

But if you ask nicely and propose the solution that appeared on this
list, they will probably make it work from linux out-of-the-box.

Best,

Tamas

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From f.calboli at ucl.ac.uk  Fri May 21 16:41:23 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 21 May 2004 15:41:23 +0100
Subject: [R] Sum of Squares in a lme model
Message-ID: <1085150483.2960.211.camel@monkey>

Dear All,

I would like to ask how to get the Sum of Squares from fitted lme model.
I appreciate that lme maximises the likelihood (or REML) and uses
likelihood ratio tests, but I just fail why I could not get the SS if I
want them. I could use lm to calculate them, but it looks quite
pointless to fit a second (and wrong in a way) model for something so
trivial.

I know that the issue has been dealt with before, but I could not find a
clear cut answer searching through the archives.

Regards 

Federico Calboli

-- 



=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 209 4286

f.calboli at ucl.ac.uk
fcalboli at alma.unibo.it



From p.dalgaard at biostat.ku.dk  Fri May 21 15:53:50 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 May 2004 15:53:50 +0200
Subject: [R] FAQ for Rmetrics
In-Reply-To: <40AB9C8C.5060402@itp.phys.ethz.ch>
References: <40AB9C8C.5060402@itp.phys.ethz.ch>
Message-ID: <x2u0y9998x.fsf@biostat.ku.dk>

Diethelm Wuertz <wuertz at itp.phys.ethz.ch> writes:

> FAQ available for Rmetrics!

Q 0.0: Where?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rolf at math.unb.ca  Fri May 21 16:12:36 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 21 May 2004 11:12:36 -0300 (ADT)
Subject: [R] Help with hclust() and plot()
Message-ID: <200405211412.i4LECakH009596@erdos.math.unb.ca>


Tamas Papp wrote:

> On Fri, May 21, 2004 at 07:56:02AM -0400, Sean Davis wrote:
> 
> > The use for par is:
> > 
> > > plot(1:8,1:8) #you must have an open graphics window before
> >                 #par has an effect
> 
> Instead of making a plot you will discard anyway (since you are making
> another when par() takes effect), you might want to initialize the
> device using the appropriate functions, eg x11(), postscript(), etc.

	Just issue the par() command, and if no device is open, an
	x11 window will be opened automatically.  Sean Davis's
	assertion that ``you must have an open graphics window before
	par has an effect'' simply isn't true.  At least it's not
	true under R 1.8.1 on Solaris nor under R 1.9.0 on Linux.


				cheers,

					Rolf Turner
					rolf at math.unb.ca



From p.dalgaard at biostat.ku.dk  Fri May 21 16:10:00 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 May 2004 16:10:00 +0200
Subject: [R] R 1.8.1 - 1.9.0 incompatability: Underscore in syntactically
	valid names
In-Reply-To: <874qqbrs95.fsf@lumen.indyrad.iupui.edu>
References: <874qqbrs95.fsf@lumen.indyrad.iupui.edu>
Message-ID: <x2pt8x98hz.fsf@biostat.ku.dk>

mmiller3 at iupui.edu (Michael A. Miller) writes:

> I have numerous data files that have dashes, periods and
> underscores in the header row.  I've got numerous R codes that
> read those files with read.table and read.csv and then use the
> names expecting the underscores and dashes to be changed to
> periods in the column names.  Since this no longer happens in
> 1.9.0, lots of codes are failing. 

Gah! I could swear we discussed that particular issue leading up to
1.9.x and had plans for a compatibility option.

You might file a bug report at least for the docs, since the example
is clearly wrong...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From michael.watson at bbsrc.ac.uk  Fri May 21 16:17:37 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Fri, 21 May 2004 15:17:37 +0100
Subject: [R] Help with hclust() and plot()
Message-ID: <8975119BCD0AC5419D61A9CF1A923E957C25AB@iahce2knas1.iah.bbsrc.reserved>

Thank you one and all, I have figured it out now;  Cheers Sean!

-----Original Message-----
From: Rolf Turner [mailto:rolf at math.unb.ca] 
Sent: 21 May 2004 15:13
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Help with hclust() and plot()



Tamas Papp wrote:

> On Fri, May 21, 2004 at 07:56:02AM -0400, Sean Davis wrote:
> 
> > The use for par is:
> > 
> > > plot(1:8,1:8) #you must have an open graphics window before
> >                 #par has an effect
> 
> Instead of making a plot you will discard anyway (since you are making

> another when par() takes effect), you might want to initialize the 
> device using the appropriate functions, eg x11(), postscript(), etc.

	Just issue the par() command, and if no device is open, an
	x11 window will be opened automatically.  Sean Davis's
	assertion that ``you must have an open graphics window before
	par has an effect'' simply isn't true.  At least it's not
	true under R 1.8.1 on Solaris nor under R 1.9.0 on Linux.


				cheers,

					Rolf Turner
					rolf at math.unb.ca

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From sdavis2 at mail.nih.gov  Fri May 21 16:18:24 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 21 May 2004 10:18:24 -0400
Subject: [R] Help with hclust() and plot()
In-Reply-To: <200405211412.i4LECakH009596@erdos.math.unb.ca>
Message-ID: <BCD387F0.8380%sdavis2@mail.nih.gov>

On 5/21/04 10:12 AM, "Rolf Turner" <rolf at math.unb.ca> wrote:

> 
> Tamas Papp wrote:
> 
>> On Fri, May 21, 2004 at 07:56:02AM -0400, Sean Davis wrote:
>> 
>>> The use for par is:
>>> 
>>>> plot(1:8,1:8) #you must have an open graphics window before
>>>                 #par has an effect
>> 
>> Instead of making a plot you will discard anyway (since you are making
>> another when par() takes effect), you might want to initialize the
>> device using the appropriate functions, eg x11(), postscript(), etc.
> 
> Just issue the par() command, and if no device is open, an
> x11 window will be opened automatically.  Sean Davis's
> assertion that ``you must have an open graphics window before
> par has an effect'' simply isn't true.  At least it's not
> true under R 1.8.1 on Solaris nor under R 1.9.0 on Linux.

Yep.  Sorry about "asserting" stuff.  I stand corrected.

Sean



From spencer.graves at pdf.com  Fri May 21 17:15:45 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 21 May 2004 08:15:45 -0700
Subject: [R] bars with sd
In-Reply-To: <20040521084042.M78574@med.unipmn.it>
References: <20040521084042.M78574@med.unipmn.it>
Message-ID: <40AE1D21.6080406@pdf.com>

 > DF <- data.frame(mean=c(1.25, 2.65, 3.45), sd=c(.35, .65, .5),
+            row.names=letters[1:3])
 > plot(1:3, DF$mean, ylim=range(DF$mean-2*DF$sd, DF$mean+2*DF$sd))
 > segments(1:3, DF$mean-2*DF$sd, 1:3, DF$mean+2*DF$sd)

hope this helps.  spencer graves

Matteo Vidali wrote:

>I need some help for a curious question of a friend of mine.
>She usually does some experiments (3-5 repeats for each exp) and then she 
>calculates mean and standard deviation. 
>In microsoft excel she writes something like the following
>
>sample  mean   sd
>a       1.25   0.35
>b       2.65   0.65
>c       3.45   0.50
>
>She can do a vertical barplot graph just giving mean value and specifying 
>the standard deviation value for each bar in the graph.
>
>My friend wants to know if it is possible to do the same with R. She has 
>tried also with Open Office and seen that in that program you can plot mean 
>values as bars but it is not possible to specify a different sd for each 
>bar 'cause the program, if you ask to put the standard deviation, calculates 
>a common sd using the mean values. 
>I was not able to give her an answer for the barplot function in R. I have 
>just said to her that it is likely due to the fact that using a barplot 
>graph to plot mean and standard deviation values it is non a good practice, 
>since the height (or the area) of bars should represent frequency and that 
>putting a standard deviation in that way it is at least quite confusing for 
>the reader to interpret the graph. Some scientific journal revisors 
>discourage this practice. She should instead use a boxplot or just plotting 
>the different repetition values for each sample as points and add a linea 
>indicating the mean.
>But if this is correct why in some programs like open office you can plot 
>bars with a common standard deviation???? when will you need this last type 
>of graph?
>
>any suggestion? any help?
>thanks in advance
>Matteo
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From sdavis2 at mail.nih.gov  Fri May 21 17:22:14 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 21 May 2004 11:22:14 -0400
Subject: [R] bars with sd
In-Reply-To: <40AE1D21.6080406@pdf.com>
Message-ID: <BCD396E6.838E%sdavis2@mail.nih.gov>

Matteo,

I think that in the gregmisc package, there is barplot2 which is an
enhancement to barplot that allows error bars.  You might look into that
option, also.

Sean

On 5/21/04 11:15 AM, "Spencer Graves" <spencer.graves at pdf.com> wrote:

>> DF <- data.frame(mean=c(1.25, 2.65, 3.45), sd=c(.35, .65, .5),
> +            row.names=letters[1:3])
>> plot(1:3, DF$mean, ylim=range(DF$mean-2*DF$sd, DF$mean+2*DF$sd))
>> segments(1:3, DF$mean-2*DF$sd, 1:3, DF$mean+2*DF$sd)
> 
> hope this helps.  spencer graves
> 
> Matteo Vidali wrote:
> 
>> I need some help for a curious question of a friend of mine.
>> She usually does some experiments (3-5 repeats for each exp) and then she
>> calculates mean and standard deviation.
>> In microsoft excel she writes something like the following
>> 
>> sample  mean   sd
>> a       1.25   0.35
>> b       2.65   0.65
>> c       3.45   0.50
>> 
>> She can do a vertical barplot graph just giving mean value and specifying
>> the standard deviation value for each bar in the graph.
>> 
>> My friend wants to know if it is possible to do the same with R. She has
>> tried also with Open Office and seen that in that program you can plot mean
>> values as bars but it is not possible to specify a different sd for each
>> bar 'cause the program, if you ask to put the standard deviation, calculates
>> a common sd using the mean values.
>> I was not able to give her an answer for the barplot function in R. I have
>> just said to her that it is likely due to the fact that using a barplot
>> graph to plot mean and standard deviation values it is non a good practice,
>> since the height (or the area) of bars should represent frequency and that
>> putting a standard deviation in that way it is at least quite confusing for
>> the reader to interpret the graph. Some scientific journal revisors
>> discourage this practice. She should instead use a boxplot or just plotting
>> the different repetition values for each sample as points and add a linea
>> indicating the mean.
>> But if this is correct why in some programs like open office you can plot
>> bars with a common standard deviation???? when will you need this last type
>> of graph?
>> 
>> any suggestion? any help?
>> thanks in advance
>> Matteo
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>  
>> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From cepl at surfbest.net  Fri May 21 17:35:16 2004
From: cepl at surfbest.net (Matej Cepl)
Date: Fri, 21 May 2004 11:35:16 -0400
Subject: [R] No load() from script
Message-ID: <200405211135.19048.cepl@surfbest.net>

Hi,

when I try to load data from a file _in a script_ (run either 
with R --vanilla < script.R, or R BATCH --vanilla script.R, or 
even with source() from inside R), then I got this error message 
and scripts halts

	> #data.multiple <- read.table(file="multiple.csv",sep="\t")
	> load(file="multiple.RData")
	Error in open.connection(con, "rb") : unable to open connection
	In addition: Warning message:
	cannot open compressed file `multiple.RData'
	Execution halted
	komensky:work$

However, I still can easily load the same data with plain 
load("multiple.RData") from R's command line. What'e even more 
strange is, that I get *exactly* same error message even when 
multiple.RData where created with save(compress=FALSE).

I use R 1.8.0 on Debian/woody (binary package from CRAN). Please, 
do not tell me to compile the newest R from source -- I don't 
have enough time to sleep, so I would probably rather survive 
for some time with loading data "by hand".

	Thanks,

		Matej

-- 
Matej Cepl, http://www.ceplovi.cz/matej
GPG Finger: 89EF 4BC6 288A BF43 1BAB  25C3 E09F EF25 D964 84AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
I feel so miserable without you, it's almost like having you
here.
      -- Stephen Bishop



From HaroldD at ccsso.org  Fri May 21 18:41:53 2004
From: HaroldD at ccsso.org (Harold Doran)
Date: Fri, 21 May 2004 12:41:53 -0400
Subject: [R] Help with Plotting Function
Message-ID: <CFF85773D9245040A333571B7E6D651702C5FD1D@ccssosrv1.ccsso.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040521/d9e9ddd2/attachment.pl

From sundar.dorai-raj at PDF.COM  Fri May 21 18:49:11 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 21 May 2004 09:49:11 -0700
Subject: [R] Help with Plotting Function
In-Reply-To: <CFF85773D9245040A333571B7E6D651702C5FD1D@ccssosrv1.ccsso.org>
References: <CFF85773D9245040A333571B7E6D651702C5FD1D@ccssosrv1.ccsso.org>
Message-ID: <40AE3307.3030103@pdf.com>



Harold Doran wrote:

> Dear List:
> 
> I cannot seem to find a way to plot my data correctly. I have a small data frame with 6 total variables (x_1 ... x_6).
> 
> I am trying to plot x_1 against x_2 and x_3.
> 
> I have tried
> 
> plot(x_2, x_1) #obviously works fine
> 
> plot(x_3, x_1, add=TRUE) # Does not work. I keep getting error messages. 
> 
> I would also like to add ablines to this plot.
> 
> I have experimented with a number of other plotting functions and I cannot seem to get this to work.
> 
> The data are student achievement data. I am trying to plot percentile ranks against scale scores for different grade levels. When plotted as such, they look like logistic curves. I am trying to show graphically the distance along x a student must grow simply to remain at the same percentile rank, y. 
> 
> Thanks.
>  
> 
> Harold C. Doran
> One Massachusetts Avenue, NW ?? Suite 700 
> Washington, DC 20001-1431
> 202.336.7075
> 
> 

Harold,

Looks like you're looking for ?points or ?lines.

plot(x_2, x_1)
lines(x_3, x_1)

--sundar



From Jason.L.Higbee at stls.frb.org  Fri May 21 18:48:16 2004
From: Jason.L.Higbee at stls.frb.org (Jason.L.Higbee@stls.frb.org)
Date: Fri, 21 May 2004 11:48:16 -0500
Subject: [R] RQuantlib ?Windows Binary?
Message-ID: <20040521164818.48C04863B7@p3fed1.frb.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040521/767ed955/attachment.pl

From pgilbert at bank-banque-canada.ca  Fri May 21 19:11:40 2004
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 21 May 2004 13:11:40 -0400
Subject: [R]  Windows versus Unix packages in CRAN ...
In-Reply-To: <20040521134118.GC853@localhost>
References: <200405211202.i4LC2F49003939@erdos.math.unb.ca>
	<20040521134118.GC853@localhost>
Message-ID: <40AE384C.7030805@bank-banque-canada.ca>

Tamas Papp wrote:

>On Fri, May 21, 2004 at 09:02:15AM -0300, Rolf Turner wrote:
>
>  
>
>>And I think it is perfectly ***fair*** to say to say that the package
>>maintainers could and should have done a better job of setting up the
>>package to make it run out-of-the-box on Linux.
>>    
>>
>
>You are probably right in saying that they _could_ have done better,
>but I would not use "should" in this context.  AFAIK the package is
>free (as in beer) software, which means that you are not paying for
>it.  The maintainers probably do not need a Linux version (yet), so it
>was not easy to use it under Linux.  Feel free to contribute.  
>
I spend nearly no time supporting the Windows versions of my packages, 
so it would be unreasonable for me to suggest that the maintainers 
should do something special to support systems they don't use.  
However,  they *should* put the code in a standard R package format for 
there own purposes. The package support tools are extremely powerful and 
make a big difference in the amount of support time necessary to 
maintain code. There are additional benefits to doing this and putting 
it on CRAN, to name a few:

  - the code will run on  all R platforms with almost no effort.
  - several aspects of the code and documentario will be checked 
automatically
  - the code will be automatically tested with beta releases of R, so 
there will be an early warning of potential problems.

(BTW,  I would be curious to see the data supporting the claim that "In 
the financial community Windows is the mostly used operating system."   
I would be especially interested if the data is specific to the 
financial engineering and computational finance communities. Is anyone 
aware of a source for this data?)

Paul Gilbert
******



From Han-Lin.lai at noaa.gov  Fri May 21 20:06:58 2004
From: Han-Lin.lai at noaa.gov (Han-Lin Lai)
Date: Fri, 21 May 2004 11:06:58 -0700
Subject: [Fwd: Re: [R] mixed models for analyzing survey data with unequal 
	selection  probability]
Message-ID: <40AE4542.BC091B9D@noaa.gov>

Hi, All

Thanks to Robert Baskin, Thomas Lumley, and Spencer Graves for the
valuable helps.  I have learned a lot from this discussion. 

I put all discussions together without editing, so we can see how things
are evolved.  Likely, I have a lot of articles to read.  As in the
discussion, mixed modeling approach is a poosible but may be over-kill
in my posted data analyses.  I will explore other plausible methods as
suggested in the discussion.

Best Regards,
Han


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
From: Thomas Lumley

On Thu, 20 May 2004, Spencer Graves wrote:

>       Cassel, Sarndal and Wretman (1977) Foundations of Inference in
> Survey Sampling (Krieger) insisted that for infinite population
> inference (what Deming called an 'analytic study'), the sampling
> probabilities should be ignored UNLESS they related somehow to something
> of interest in the model.  In other words, is the sampling informative
> or noninformative?  If noninformative, the sampling probabilities do not
> appear in the likelihood and therefore should not affect inference.  As
> I recall, Cassel, Sarndal and Wretman said that if stratified random
> sampling is used, and if the stratification system is included in the
> model, then the sampling is noninformative, and the sampling
> probabilities should not affect inference.

This is the point of including the sampling weights as a predictor. 
These
weights carry all the informativeness of the sampling scheme, and so
correctly modelling them is sufficient.  If the sampling is already
non-informative then including them as a predictor is harmless.

However, my point was that you may not want to condition on all the
variables that go into the sampling scheme, in which case the simplest
solution may be design-based inference.

        -thomas

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
From: Spencer Graves <>

      Cassel, Sarndal and Wretman (1977) Foundations of Inference in 
Survey Sampling (Krieger) insisted that for infinite population 
inference (what Deming called an 'analytic study'), the sampling 
probabilities should be ignored UNLESS they related somehow to something 
of interest in the model.  In other words, is the sampling informative 
or noninformative?  If noninformative, the sampling probabilities do not 
appear in the likelihood and therefore should not affect inference.  As 
I recall, Cassel, Sarndal and Wretman said that if stratified random 
sampling is used, and if the stratification system is included in the 
model, then the sampling is noninformative, and the sampling 
probabilities should not affect inference. 

      From this paradigm, using weights inversely proportional to 
sampling probabilities is (primarily?) a tool for finite population 
inference -- what Deming called an 'enumerative study'.  For an 
enumerative study, the purpose is to make inference about a fixed, 
finite population, e.g., how to feed the people in Japan who would 
otherwise starve within the next week or month, which was the situation 
when Deming directed a survey there shortly after World War II.  For an 
analytic study, the purpose is more long term, e.g., how to design a 
national alimentary system to feed the people who will be there 10 or 30 
years from now.  Since most of my work has dealt processed that will 
create the future, rather than dealing with fixed, finite populations, I 
have ignored sampling probabilities in most of my work (though I have 
not worked much recently with sample surveys). 

      Is this still consistent with current thinking?  Is it feasible to 
summarize in a few words what Pferrermann, Korn et al. say about this? 

      Thanks,
      spencer graves

Thomas Lumley wrote:

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
>On Thu, 20 May 2004, Baskin, Robert wrote:
>
>  
>
>>Han-Lin
>>
>>I don't think I have seen a reply so I will suggest that maybe you could try
>>a different approach than what you are thinking about doing.  I believe the
>>current best practice is to use the weights as a covariate in a regression
>>model - and bytheway - the weights are the inverse of the probabilities of
>>selection - not the probabilities.
>>
>>Fundamentally, there is a difficulty in making sense out of 'random effects'
>>in a finite population setting.
>>    
>>
>
>I would have thought that it matters why you are fitting a mixed model.
>Often people use mixed models when they are just interested in inference
>about the mean and need to model the covariances to get valid standard
>errors. In that situation you could use an ordinary survey regression to
>get a design-based result.
>
>If you are actually interested in variance components then you need some
>other approach, and putting the weights into the model as a covariate will
>presumably give a valid model-based result (since the weights carry all
>the biased sampling information --- like a propensity score).  Presumably
>this is also more efficient.
>
>However, it could well be that you don't want those variables in the
>model. If the sampling depends on a variable Z correlated with Y and X and
>you want to model the distribution of Y given X, not the distribution of Y
>given X and Z, you are still in trouble.
>
>
>	-thomas
>
>
>
>  
>
>>(plagiarized from some unknown source)
>>See: < 9. Pfeffermann, D. , Skinner, C. J. , Holmes, D. J. , Goldstein, H. ,
>>and Rasbash, J.  (1998), ``Weighting for unequal selection probabilities in
>>multilevel models (Disc: p41-56)'', Journal of the Royal Statistical
>>Society, Series B, Methodological, 60 , 23-40 >
>>
>>which refers back to:
>><29. Pfeffermann, D. , and LaVange, L.  (1989), ``Regression models for
>>stratified multi-stage cluster samples'', Analysis of Complex Surveys,
>>237-260 >
>>
>>If you don't like statistical papers, then see section 4.5 of <8. Korn,
>>Edward Lee , and Graubard, Barry I.  (1999), ``Analysis of health surveys'',
>>John Wiley & Sons (New York; Chichester) > They explain the idea of using
>>weights in a model fairly simply.
>>
>>Bob
>>
>>
>>-----Original Message-----
>>From: Han-Lin Lai [mailto:Han-Lin.Lai at noaa.gov]
>>Sent: Wednesday, May 19, 2004 12:47 PM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] mixed models for analyzing survey data with unequal selection
>>probability
>>
>>Hi,
>>
>>I need the help on this topic because this is out of my statistical
>>trianing as biologist.  Here is my brief description of the problem.
>>
>>I have a survey that VESSELs are selected at random with the probability
>>of p(j).  Then the tows within the jth VESSEL are sampled at random with
>>probability of p(i|j).  I write my model as
>>
>>y = XB + Zb + e
>>where XB is fixed part, Zb is for random effect (VESSEL) and e is
>>within-vessel error.
>>
>>I feel that I should weight the Zb part by p(j) and the e-part by
>>p(i,j)=p(j)*p(i|j). Is this a correct weighting?
>>
>>How can I implement the weightings in nlme (or lme)?  I think that
>>p(i,j) can be specified by nlme(..., weights=p(i,j),...)?  Where is p(j)
>>to be used in nlme?
>>
>>I appreciate anyone can provide examples and literature for this
>>problem.
>>
>>Cheers!
>>Han
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>    
>>
>
>Thomas Lumley			Assoc. Professor, Biostatistics
>tlumley at u.washington.edu	University of Washington, Seattle
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From arrayprofile at yahoo.com  Fri May 21 20:31:18 2004
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 21 May 2004 11:31:18 -0700 (PDT)
Subject: [R] interval-censored data in coxph
Message-ID: <20040521183118.22635.qmail@web41202.mail.yahoo.com>

Hi,

I am wondering how to specify interval-censored data
in coxph? The example in the help page 

summary(coxph(Surv(start, stop, event) ~ x, data =
test2)) 

is for counting process data, is the counting process
data the same as interval-censored data?

Thanks


	
		
__________________________________




From tlumley at u.washington.edu  Fri May 21 21:19:03 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 21 May 2004 12:19:03 -0700 (PDT)
Subject: [R] interval-censored data in coxph
In-Reply-To: <20040521183118.22635.qmail@web41202.mail.yahoo.com>
References: <20040521183118.22635.qmail@web41202.mail.yahoo.com>
Message-ID: <Pine.A41.4.58.0405211215250.17368@homer34.u.washington.edu>

On Fri, 21 May 2004, array chip wrote:

> Hi,
>
> I am wondering how to specify interval-censored data
> in coxph? The example in the help page
>
> summary(coxph(Surv(start, stop, event) ~ x, data =
> test2))
>
> is for counting process data, is the counting process
> data the same as interval-censored data?
>

No. You can't use interval-censored data in the Cox model, only in the
parametric survival models (survreg()).

There are two ways of specifying interval-censored data.  In the
simpler one the syntax is  Surv(before,after, type="interval2")

Here 'before' is the start of the interval and after is the end of the
interval.  You can combine this with exact failure times (before==after)
and right-censoring (after=NA) and left censoring (before=NA).


	-thomas



From jianqings at yahoo.com  Fri May 21 21:19:59 2004
From: jianqings at yahoo.com (Mike)
Date: Fri, 21 May 2004 12:19:59 -0700 (PDT)
Subject: [R] Is there a "symbolic" package in R?
Message-ID: <20040521191959.32356.qmail@web41005.mail.yahoo.com>

I know Matlab has symbolic tools to do analysis
symbolically. I greatly appreciate your kind help. 

Thanks.

Mike
		
__________________________________


From arrayprofile at yahoo.com  Fri May 21 22:47:57 2004
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 21 May 2004 13:47:57 -0700 (PDT)
Subject: [R] survival analysis sampling question
Message-ID: <20040521204757.74083.qmail@web41204.mail.yahoo.com>

Hi, not sure if this is the best place to ask this
statistical question, but here it goes:

Does doing survival analysis mandatorily require
consecutively recruited patients? If I have a
retrospective patient sample, but not consecutively
recruited, does it necessitate invalidity of the use
of survival analysis (for example: Kaplan Meier
analysis or Cox regression, etc). Or as long as the
patient sample is a random sample of the population
(though it may be hard to prove that), it will be ok?

Thanks for sharing your thoughts
		
__________________________________


From pauljohn at ku.edu  Sat May 22 04:35:57 2004
From: pauljohn at ku.edu (Paul Johnson)
Date: Fri, 21 May 2004 22:35:57 -0400
Subject: [R] R-release.diff + R-1.9 -> success on Fedora Core 2, R RPM
 available; ess-emacs-5.1.20 also available
Message-ID: <40AEBC8D.5010901@ku.edu>

Dear Everybody:

I have Fedora Core 2  and R-1.9.0 does not build "out of the box". After 
applying the daily patch file R-release.diff, I find it does build and 
I've made RPMS and SRPM.

In case you want to save yourself a recompile, you can find Fedora Core 
RPMs in here:

http://lark.cc.ku.edu/~pauljohn/software/R

These are based on the standard R distribution SPEC file, only the patch 
was added.

Also, I have created an RPM for ESS for Emacs on Fedora Core 2 (not 
Xemacs) and you can find that here:

http://lark.cc.ku.edu/~pauljohn/software/favoriteEmacsFiles

--------------------------

While I'm on the RPM subject, can I ask an R RPM packaging question?  I 
want the R RPM to install so that post install then R starts and runs
 > update.packages()

as well as

install.packages(c("Design","Hmisc","lmtest","car","rgl","effects"))

well, you get the idea. I want to add in more packages, of course.  Can 
I ask what might be the best way to package this?

pj

ps: Here's the error that results if you do not patch R-1.9.0 on FC2:

gcc -I. -I../../../src/include -I../../../src/include 
-I/usr/X11R6/include -I/usr/local/incl 

ude -DHAVE_CONFIG_H -D__NO_MATH_INLINES -mieee-fp -fPIC  -O2 -g -pipe 
-march=i386 -mcpu=i686 

  -c dataentry.c -o dataentry.lo
In file included from dataentry.c:31:
/usr/X11R6/include/X11/Xlib.h:1400: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1488: error: syntax error before "char"
/usr/X11R6/include/X11/Xlib.h:1516: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1520: error: syntax error before "char"
/usr/X11R6/include/X11/Xlib.h:1542: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1577: error: syntax error before '*' token
/usr/X11R6/include/X11/Xlib.h:1586: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1611: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1661: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1667: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1714: error: syntax error before "char"
/usr/X11R6/include/X11/Xlib.h:1753: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:1994: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2078: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2331: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2341: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2413: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2423: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2581: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2596: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2789: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2856: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:2861: error: syntax error before "char"
/usr/X11R6/include/X11/Xlib.h:2975: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3001: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3012: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3037: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3046: error: syntax error before "char"
/usr/X11R6/include/X11/Xlib.h:3059: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3202: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3251: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3283: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3374: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3381: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3401: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3407: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3419: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3429: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3770: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3781: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3792: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3803: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3814: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xlib.h:3825: error: syntax error before "_Xconst"
In file included from dataentry.c:32:
/usr/X11R6/include/X11/Xutil.h:566: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:606: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:666: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:678: error: syntax error before "_Xconst"
/usr/X11R6/include/X11/Xutil.h:801: error: syntax error before "_Xconst"
dataentry.c: In function `GetKey':
dataentry.c:1272: warning: passing arg 4 of `XLookupString' from 
incompatible pointer type
dataentry.c: In function `GetCharP':
dataentry.c:1281: warning: passing arg 4 of `XLookupString' from 
incompatible pointer type
dataentry.c: In function `doControl':
dataentry.c:1302: warning: passing arg 4 of `XLookupString' from 
incompatible pointer type
make[4]: *** [dataentry.lo] Error 1
make[4]: Leaving directory 
`/home/pauljohn/LinuxDownloads/redhat/BUILD/R-1.9.0/src/modules/X 

11'
make[3]: *** [R] Error 2
make[3]: Leaving directory 
`/home/pauljohn/LinuxDownloads/redhat/BUILD/R-1.9.0/src/modules/X 


-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From max.marinucci at ya.com  Sat May 22 02:01:11 2004
From: max.marinucci at ya.com (Max Marinucci)
Date: Sat, 22 May 2004 02:01:11 +0200
Subject: [R] Mixreg package
Message-ID: <001c01c43f8f$e4cd9cd0$625f7cd9@maxmad9rubu4nk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040522/16750cb9/attachment.pl

From ggrothendieck at myway.com  Sat May 22 03:09:26 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 22 May 2004 01:09:26 +0000 (UTC)
Subject: [R] Is there a "symbolic" package in R?
References: <20040521191959.32356.qmail@web41005.mail.yahoo.com>
Message-ID: <loom.20040522T030751-58@post.gmane.org>

Mike <jianqings <at> yahoo.com> writes:
: I know Matlab has symbolic tools to do analysis
: symbolically. I greatly appreciate your kind help. 


?deriv

can do symbolic derivatives



From deepayan at stat.wisc.edu  Sat May 22 04:58:52 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 21 May 2004 21:58:52 -0500
Subject: [R] Sum of Squares in a lme model
In-Reply-To: <1085150483.2960.211.camel@monkey>
References: <1085150483.2960.211.camel@monkey>
Message-ID: <200405212158.52996.deepayan@stat.wisc.edu>

On Friday 21 May 2004 09:41, Federico Calboli wrote:
> Dear All,
>
> I would like to ask how to get the Sum of Squares from fitted lme
> model. I appreciate that lme maximises the likelihood (or REML) and
> uses likelihood ratio tests, but I just fail why I could not get the
> SS if I want them. I could use lm to calculate them, but it looks
> quite pointless to fit a second (and wrong in a way) model for
> something so trivial.

Exactly what do you wish to square and sum ? If it's the 'errors' (which 
in this context is ambiguous), extract them (see ?residuals.lme), 
square them and sum them. But what are you planning to do with this 
after you get it ?

Deepayan



From ligges at statistik.uni-dortmund.de  Sat May 22 08:46:30 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 22 May 2004 08:46:30 +0200
Subject: [R] RQuantlib ?Windows Binary?
In-Reply-To: <20040521164818.48C04863B7@p3fed1.frb.org>
References: <20040521164818.48C04863B7@p3fed1.frb.org>
Message-ID: <40AEF746.5040105@statistik.uni-dortmund.de>

Jason.L.Higbee at stls.frb.org wrote:

> R:
> 
> Is there a reason why there isn't a Windows Binary version of RQuantlib on 
> CRAN?  Usually when there is no binary, I just source the source code, but 
> this one appears to have various calls and methods and things like that so 
> I'm hesitant to do so.  I know there has been a big discussion on why 
> Rmetrics doesn't have source for unix/linux, but that isn't on CRAN. 
> Through that Rmetrics thread, I think I read that all CRAN packages have 
> source (except for one), but shouldn't all CRAN packages also have binary?

All CRAN packages *do* have a source version.
But *not* all CRAN packages have binaries.

See http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html 
what hapens to the package. hat page points you to 
http://cran.r-project.org/bin/windows/contrib/1.9/ReadMe

Uwe Ligges



>  Think they should.
> 
> Jason Higbee
> Research Associate
> Federal Reserve Bank of St. Louis
> E: jason.l.higbee at stls.frb.org
> The views expressed in this email are the author's and not necessarily 
> those of the Federal Reserve Bank of St. Louis or the Federal Reserve 
> System
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat May 22 08:50:30 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 22 May 2004 08:50:30 +0200
Subject: [R] Mixreg package
In-Reply-To: <001c01c43f8f$e4cd9cd0$625f7cd9@maxmad9rubu4nk>
References: <001c01c43f8f$e4cd9cd0$625f7cd9@maxmad9rubu4nk>
Message-ID: <40AEF836.9010808@statistik.uni-dortmund.de>

Max Marinucci wrote:

> Dear R users
> it's my first time using R and I am specially interested in doing analyses with the "mixreg" package.
> 
> I use W2000 but it seems the code for R is available only for Linux Os. Anyway I I downloaded the *tar.gz file of the package for R and the converted it in a *zip file.


1. What is the mixreg package (it is not available on CRAN, as far as I 
know)?

2. You need to INSTALL the package from sources by Rcmd INSTALL. See the 
docs how to do so.

Uwe Ligges


> Apparently the installation process was ok, but when loading it I got the following error:
> 
> Error in testRversion(descfields) : This package has not been installed properly
>  See the Note in ?library
> 
> I suppose that this is due to the fact I have a windows version and the conversion of the tar.gz in a *zip file was not legal.
> 
> I wonder if someone could help me to run mixreg in W2000.
> thanx a lot
> max
> /*****************************************
> Max Marinucci
> Phd candidate 
> Universidad Complutense Madrid
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jasont at indigoindustrial.co.nz  Sat May 22 10:02:30 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sat, 22 May 2004 20:02:30 +1200
Subject: [R] No load() from script
In-Reply-To: <200405211135.19048.cepl@surfbest.net>
References: <200405211135.19048.cepl@surfbest.net>
Message-ID: <20040522080229.GA15011@kryten.akl.indigoindustrial.co.nz>

On Fri, May 21, 2004 at 11:35:16AM -0400, Matej Cepl wrote:
...
> 	> #data.multiple <- read.table(file="multiple.csv",sep="\t")
> 	> load(file="multiple.RData")
> 	Error in open.connection(con, "rb") : unable to open connection
> 	In addition: Warning message:
> 	cannot open compressed file `multiple.RData'
> 	Execution halted
> 	komensky:work$
> 
> However, I still can easily load the same data with plain 
> load("multiple.RData") from R's command line. What'e even more 
> strange is, that I get *exactly* same error message even when 
> multiple.RData where created with save(compress=FALSE).
...

The only time I get that message is when running R as  a
script in the wrong directory.  Have you tried using an
absolute pathname? e.g.
load(file="/home/komensky/work/multiple.RData")

or wherever it really is.

Cheers

Jason

-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From f.calboli at ucl.ac.uk  Sat May 22 11:30:58 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 22 May 2004 10:30:58 +0100
Subject: [R] Sum of Squares in a lme model
In-Reply-To: <200405212158.52996.deepayan@stat.wisc.edu>
References: <1085150483.2960.211.camel@monkey>
	<200405212158.52996.deepayan@stat.wisc.edu>
Message-ID: <1085218258.2944.6.camel@monkey>

On Sat, 2004-05-22 at 03:58, Deepayan Sarkar wrote:

> 
> Exactly what do you wish to square and sum ? If it's the 'errors' (which 
> in this context is ambiguous), extract them (see ?residuals.lme), 
> square them and sum them. But what are you planning to do with this 
> after you get it ?

Make a "oh so nice" anova table for people who have never seen anything
but an anova table with SS and MS and all the standard trappings (sensu
Sokal and Rohlf or Zar), and would get perturbed if they did not get
what they expected, together with the "oh so nice" stars next to the p
value of the F-test...

I know it is silly, I do not make the rules though. Also, I am probably
just ranting.

Fede
-- 



=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 209 4286

f.calboli at ucl.ac.uk
fcalboli at alma.unibo.it



From ripley at stats.ox.ac.uk  Sat May 22 10:40:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 May 2004 09:40:59 +0100 (BST)
Subject: [R] Re: R 1.90 make problem with /usr/X11R6/include/X11/Xutil.h
	on suse linux 9.1?
In-Reply-To: <40ABE0AF.9090008@channing.harvard.edu>
Message-ID: <Pine.LNX.4.44.0405220938241.4289-100000@gannet.stats>

But that is not the best fix, and this have been discussed several times
in the R-help/R-devel lists.  A better fix is already in R-patched, whose
NEWS file says

INSTALLATION ISSUES

    o	src/modules/X11/dataentry.c would not build on some XFree
	4.4.0 systems.	(This is a bug in their header files but we have
	added a workaround.)

Please do send in bug reports to your distributions, as there is a bug in 
their distributions, not R's.


On Wed, 19 May 2004, Ross Lazarus wrote:

> Suse problem solved - thanks to Chris Albert for providing a fix to the 
> problem on Fedora Core 2 - same fix works a treat for Suse 9.1 - edit 
> src/modules/X11/dataentry.c and change the define NeedFunctionProtypes 
> to 1 :
> 
> > Hi,
> > 
> > The libtk8.3 dependencies in the R-1.9.0 rpm generate apt conflicts 
> > after an upgrade from Fedora Core 1 to Fedora core 2.
> > In trying to rebuild the rpm from the source rpm provided on CRAN,
> > the build fails when it comes time to compile
> > 
> > src/modules/X11/dataentry.c
> > 
> > you get many errors of the form :
> >> In file included from dataentry.c:34:
> >> /usr/X11R6/include/X11/Xlib.h:1400: error: syntax error before "_Xconst"
> >> /usr/X11R6/include/X11/Xlib.h:1488: error: syntax error before "char"
> >> /usr/X11R6/include/X11/Xlib.h:1516: error: syntax error before "_Xconst"
> >> /usr/X11R6/include/X11/Xlib.h:1520: error: syntax error before "char"
> >> /usr/X11R6/include/X11/Xlib.h:1542: error: syntax error before "_Xconst"
> > ...
> > 
> > This could have something to do with the change from X1186 to xorg.
> > 
> > A workaround is simply to change the line in src/modules/X11/dataentry.c:
> >> /* don't use X11 function prototypes (which tend to ...): */
> >> #define NeedFunctionPrototypes 0
> > to
> >  > #define NeedFunctionPrototypes 1 .
> > 
> > As a patch:
> >> diff -crN R-1.9.0.orig/src/modules/X11/dataentry.c R-1.9.0/src/modules/X11/dataentry.c
> >> *** R-1.9.0.orig/src/modules/X11/dataentry.c    2004-03-22 06:00:16.000000000 -0500
> >> --- R-1.9.0/src/modules/X11/dataentry.c 2004-05-19 11:35:21.903803616 -0400
> >> ***************
> >> *** 29,35 ****
> >>   #include "Print.h"
> >>    
> >>   /* don't use X11 function prototypes (which tend to ...): */
> >> ! #define NeedFunctionPrototypes 0
> >>   #include <X11/X.h>
> >>   #include <X11/Xlib.h>
> >>   #include <X11/Xutil.h>
> >> --- 29,35 ----
> >>   #include "Print.h"
> >>    
> >>   /* don't use X11 function prototypes (which tend to ...): */
> >> ! #define NeedFunctionPrototypes 1
> >>   #include <X11/X.h>
> >>   #include <X11/Xlib.h>
> >>   #include <X11/Xutil.h>
> > 
> > Then the rpm builds fine.
> > 
> > Someone who knows the code will need to confirm that this is an 
> > acceptable solution.
> > 
> > 
> > Chris Albert
> 
> 
> Ross Lazarus wrote:
> > This is probably a Suse specific problem and not a bug in R, but I'm 
> > reporting it in case it's useful for someone to know about....
> > 
> > Trying to compile R1.9.0 from source on a standard Suse 9.1 install 
> > (athlon in a shuttle sn41g2).
> > configure seems fine but the Suse X11R6 Xlib.h might be toxic.
> > 
> > In case it helps, here's the sad end to the make output. I can post the 
> > Xlib.h if that would help...
> > 
> > Please email me directly for more information if needed as I don't 
> > normally read this list....meanwhile, I'll go try the rpm....
> > 
> > making rotated.d from rotated.c
> > making rbitmap.d from rbitmap.c
> > make[4]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules/X11'
> > make[4]: Entering directory `/home/rossl/src/R-1.9.0/src/modules/X11'
> > gcc -I. -I../../../src/include -I../../../src/include 
> > -I/usr/X11R6/include -I/usr/local/include -DHAVE_CONFIG_H 
> > -D__NO_MATH_INLINES -mieee-fp -fPIC  -g -O2 -c dataentry.c -o dataentry.lo
> > In file included from dataentry.c:31:
> > /usr/X11R6/include/X11/Xlib.h:1400: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:1488: error: parse error before "char"
> > /usr/X11R6/include/X11/Xlib.h:1516: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:1520: error: parse error before "char"
> > /usr/X11R6/include/X11/Xlib.h:1542: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:1577: error: parse error before '*' token
> > /usr/X11R6/include/X11/Xlib.h:1586: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:1611: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:1661: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:1667: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:1714: error: parse error before "char"
> > /usr/X11R6/include/X11/Xlib.h:1753: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:1994: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:2078: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:2331: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:2341: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:2413: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:2423: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:2581: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:2596: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:2789: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:2856: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:2861: error: parse error before "char"
> > /usr/X11R6/include/X11/Xlib.h:2975: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3001: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3012: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3037: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3046: error: parse error before "char"
> > /usr/X11R6/include/X11/Xlib.h:3059: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3202: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3251: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3283: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3374: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3381: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3401: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3407: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3419: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3429: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3439: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3445: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3546: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3563: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3614: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3657: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3663: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3669: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3675: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3683: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3691: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3699: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3711: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3723: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3770: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3781: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3792: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3803: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3814: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xlib.h:3825: error: parse error before "_Xconst"
> > In file included from dataentry.c:32:
> > /usr/X11R6/include/X11/Xutil.h:566: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xutil.h:606: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xutil.h:666: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xutil.h:678: error: parse error before "_Xconst"
> > /usr/X11R6/include/X11/Xutil.h:801: error: parse error before "_Xconst"
> > dataentry.c: In function `GetKey':
> > dataentry.c:1272: warning: passing arg 4 of `XLookupString' from 
> > incompatible pointer type
> > dataentry.c: In function `GetCharP':
> > dataentry.c:1281: warning: passing arg 4 of `XLookupString' from 
> > incompatible pointer type
> > dataentry.c: In function `doControl':
> > dataentry.c:1302: warning: passing arg 4 of `XLookupString' from 
> > incompatible pointer type
> > make[4]: *** [dataentry.lo] Error 1
> > make[4]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules/X11'
> > make[3]: *** [R] Error 2
> > make[3]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules/X11'
> > make[2]: *** [R] Error 1
> > make[2]: Leaving directory `/home/rossl/src/R-1.9.0/src/modules'
> > make[1]: *** [R] Error 1
> > make[1]: Leaving directory `/home/rossl/src/R-1.9.0/src'
> > make: *** [R] Error 1
> > rossl at small:~/src/R-1.9.0>
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat May 22 12:11:48 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 May 2004 11:11:48 +0100 (BST)
Subject: [R] Accessing more than 2GB memory in Windows
In-Reply-To: <s0acc30c.007@hrp3.palm.cri.nz>
Message-ID: <Pine.LNX.4.44.0405221105230.12636-100000@gannet.stats>

R can.

R 1.8.1 cannot, but it is obselete.

On Thu, 20 May 2004, Marcus Davy wrote:

> I am also interested in the same topic, that is windows 32bit
> restriction to 4Gigs of virtual 
> address space partitioning into User and System space.
> For your reconfigured server 3:1 User to System space what does
> 
> memory.limit()
> 
> say is available?
> 
> For those interested a windows FAQ link on this subject is
> 
> http://www.stats.ox.ac.uk/pub/R/rw-FAQ.html#There%20seems%20to%20be%20a%20limit%20on%20the%20memory%20it%20uses!

(and in the distribution, lonked from the menus). That explicitly says

  The information here applies only to recent versions of R for Windows, 
  (1.9.0 or later); the current version is often called something like 
  rw1090 (although not officially).

At least two users who were interested have reported success after 
following those instructions (during the pre-release testing phase).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From f.calboli at ucl.ac.uk  Sat May 22 16:27:53 2004
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: 22 May 2004 15:27:53 +0100
Subject: [R] Sum of Squares in a lme model
In-Reply-To: <40AF42A0.8040807@cirad.fr>
References: <1085150483.2960.211.camel@monkey>
	<200405212158.52996.deepayan@stat.wisc.edu>
	<1085218258.2944.6.camel@monkey>  <40AF42A0.8040807@cirad.fr>
Message-ID: <1085236073.2944.57.camel@monkey>

On Sat, 2004-05-22 at 13:08, Renaud Lancelot wrote:

> 
> So you might want to use the anova method for lme objects. You probably 
> need to set the argument type to "marginal", which is not the default value.
> 
> Best,
> 
> Renaud

Using anova(my.lme.model), of any type, does not produce the desired MS
and SS. That's despite the help for anova.lme stating:

" When only one fitted model object is present, a data frame with    
the sums of squares, numerator degrees of freedom, denominator    
degrees of freedom, F-values, and P-values for Wald tests for the    
terms in the model (when 'Terms' and 'L' are 'NULL') [they are by
default]..."

I realise this Sum of Squares thing is silly, and fitting a parallel
"lm" model would give me the required SS and MS, but I simply fail to
see why I have to do this considering that the help for anova.lme states
I can get them somehow.  

I do hope I am not ranting too much.

Regards,

Federico Calboli

-- 



=================================

Federico C. F. Calboli

Dipartimento di Biologia
Via Selmi 3
40126 Bologna
Italy

tel (+39) 051 209 4187
fax (+39) 051 209 4286

f.calboli at ucl.ac.uk
fcalboli at alma.unibo.it



From rolf at math.unb.ca  Sat May 22 15:47:58 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Sat, 22 May 2004 10:47:58 -0300 (ADT)
Subject: [R] Mixreg package
Message-ID: <200405221347.i4MDlw8C013984@erdos.math.unb.ca>


Uwe Ligges wrote:

> 1. What is the mixreg package (it is not available on CRAN, as far as
> I know)?

Presumably the ``mixreg'' package is mine, and was obtained from my
web page.  Since this is the second expression of interest in this
package that I've heard in the last month or so, I guess there is
enough interest to make it worth submitting the package to CRAN,
which I shall do forthwith.  (I ***think*** I got it to jump through
all the ``R CMD check'' hoops before I put it up on my own page ---
:-) --- so it shouldn't take long.  Said he, hopelfully.)

			cheers,

				Rolf Turner
				rolf at math.unb.ca



From max.marinucci at ya.com  Sat May 22 16:07:14 2004
From: max.marinucci at ya.com (Max Marinucci)
Date: Sat, 22 May 2004 16:07:14 +0200
Subject: [R] Mixreg package
References: <200405221347.i4MDlw8C013984@erdos.math.unb.ca>
Message-ID: <000e01c44006$168dcdf0$5a567cd9@maxmad9rubu4nk>

Dear all
yes I did download mixreg from Rolf's homepage. 
I hope that the package will be submitted at CRAN in the future. 
Also I will be pleased to give you a feedback about how it works.

Thanks a lot!
max


----- Original Message ----- 
From: "Rolf Turner" <rolf at math.unb.ca>
To: <r-help at stat.math.ethz.ch>
Cc: <ligges at statistik.uni-dortmund.de>; <max.marinucci at ya.com>
Sent: Saturday, May 22, 2004 15:47
Subject: Re: [R] Mixreg package


> 
> Uwe Ligges wrote:
> 
> > 1. What is the mixreg package (it is not available on CRAN, as far as
> > I know)?
> 
> Presumably the ``mixreg'' package is mine, and was obtained from my
> web page.  Since this is the second expression of interest in this
> package that I've heard in the last month or so, I guess there is
> enough interest to make it worth submitting the package to CRAN,
> which I shall do forthwith.  (I ***think*** I got it to jump through
> all the ``R CMD check'' hoops before I put it up on my own page ---
> :-) --- so it shouldn't take long.  Said he, hopelfully.)
> 
> cheers,
> 
> Rolf Turner
> rolf at math.unb.ca
>



From christopher.albert at mcgill.ca  Sat May 22 16:41:25 2004
From: christopher.albert at mcgill.ca (chris albert)
Date: Sat, 22 May 2004 10:41:25 -0400
Subject: [R] RPM post-install scripts to update R
In-Reply-To: <200405221001.i4MA0pFH000801@hypatia.math.ethz.ch>
References: <200405221001.i4MA0pFH000801@hypatia.math.ethz.ch>
Message-ID: <40AF6695.1080502@mcgill.ca>

Hi,

Paul Johnson asked:

    While I'm on the RPM subject, can I ask an R RPM packaging question? I
    want the R RPM to install so that post install then R starts and runs
    > update.packages()

    as well as

    install.packages(c("Design","Hmisc","lmtest","car","rgl","effects"))

    well, you get the idea. I want to add in more packages, of course. Can
    I ask what might be the best way to package this?

You can add scripts to the %post macro section.
If you look at the recent R.spec you'll see that there are already some :

    %post
    # Create directory entries for info files
    # (optional doc files, so we must check that they are installed)
    for doc in admin exts FAQ intro lang; do
       file=%{_infodir}/R-${doc}.info.gz
       if [ -e $file ]; then
          /sbin/install-info ${file} %{_infodir}/dir
       fi
    done
    # Update package indices
    %{_bindir}/R CMD perl %{_libdir}/R/share/perl/build-help.pl --htmllists
    %__cat %{_libdir}/R/library/*/CONTENTS >
    %{_libdir}/R/doc/html/search/index.txt

One way to do what you want would be to add something like the following
at the beginning:

    %post
    cat > /tmp/RPM_postinstall.R << EOF
    update.packages(ask=F)
    install.packages(c("Design","Hmisc","lmtest","car","rgl","effects"))
    EOF
    %{_bindir}/R BATCH /tmp/RPM_postinstall.R
    echo "Please check /tmp/RPM_postinstall.Rout for the update results"

This may not be the best way to do it. You'll need to decide what kind
of error checking to do, whether you want to run that batch command in
the background, and so on. However, this is how such tasks are often
dome in rpm spec files.

Chris



From wuertz at itp.phys.ethz.ch  Sat May 22 18:29:36 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Sat, 22 May 2004 16:29:36 +0000
Subject: [R] Rmetrics, RQuantlib
In-Reply-To: <40AEF746.5040105@statistik.uni-dortmund.de>
References: <20040521164818.48C04863B7@p3fed1.frb.org>
	<40AEF746.5040105@statistik.uni-dortmund.de>
Message-ID: <40AF7FF0.6070608@itp.phys.ethz.ch>

Dear Rmetrics User,

Rmetrics is currently availalble as source and binary packages for all 4 
packages fBasics, fSeries, fExtremes and fOptions
(for Windows).
Linux, Mac )X - Currently I remove all Windows specific parts from the 
sources. If the packages pass all checks I will
move the packages to the CRAN server. Please apologize if this takes 
some more time.

RQuantlib offers a lot of material for financial engineers.  It is 
especially strong for American options. I would also be happy
to see it on CRAN (compiled) and hopefully somebody helps me to make it 
usable from Rmetrics.

Diethelm Wuertz
www.rmetrics.org

Uwe Ligges wrote:

> Jason.L.Higbee at stls.frb.org wrote:
>
>> R:
>>
>> Is there a reason why there isn't a Windows Binary version of 
>> RQuantlib on CRAN?  Usually when there is no binary, I just source 
>> the source code, but this one appears to have various calls and 
>> methods and things like that so I'm hesitant to do so.  I know there 
>> has been a big discussion on why Rmetrics doesn't have source for 
>> unix/linux, but that isn't on CRAN. Through that Rmetrics thread, I 
>> think I read that all CRAN packages have source (except for one), but 
>> shouldn't all CRAN packages also have binary?
>
>
> All CRAN packages *do* have a source version.
> But *not* all CRAN packages have binaries.
>
> See http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html 
> what hapens to the package. hat page points you to 
> http://cran.r-project.org/bin/windows/contrib/1.9/ReadMe
>
> Uwe Ligges
>
>
>
>>  Think they should.
>>
>> Jason Higbee
>> Research Associate
>> Federal Reserve Bank of St. Louis
>> E: jason.l.higbee at stls.frb.org
>> The views expressed in this email are the author's and not 
>> necessarily those of the Federal Reserve Bank of St. Louis or the 
>> Federal Reserve System
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From wuertz at itp.phys.ethz.ch  Sat May 22 18:33:10 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Sat, 22 May 2004 16:33:10 +0000
Subject: [R] FAQ for Rmetrics
In-Reply-To: <x2u0y9998x.fsf@biostat.ku.dk>
References: <40AB9C8C.5060402@itp.phys.ethz.ch> <x2u0y9998x.fsf@biostat.ku.dk>
Message-ID: <40AF80C6.5090209@itp.phys.ethz.ch>

Sorry for the missing link,

Goto www.Rmetrics.org

Diethelm Wuertz



Peter Dalgaard wrote:

>Diethelm Wuertz <wuertz at itp.phys.ethz.ch> writes:
>
>  
>
>>FAQ available for Rmetrics!
>>    
>>
>
>Q 0.0: Where?
>
>  
>



From DJNordlund at aol.com  Sat May 22 20:18:50 2004
From: DJNordlund at aol.com (DJNordlund@aol.com)
Date: Sat, 22 May 2004 14:18:50 EDT
Subject: [R] How to define specific location of tick marks in plot()
Message-ID: <1ed.214512e5.2de0f38a@aol.com>

Hi,

I wish to create a series of plots  with the same x-axis range and the same 
placement of tick marks.  In  addition I want to force the tick marks to be at 
specific locations.  For  example, if I wish to have an x-axis which goes from 
40 to 110, with tick marks  at 40, 50, 60, ... , How can I accomplish that?  
The various parameters I  have tried changing just seem to be suggestions for 
an internal  definition.

I'm sure this is easy, but I'm obviously missing something in  the 
docmentation.

Dan Nordlund



From ripley at stats.ox.ac.uk  Sat May 22 20:40:53 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 May 2004 19:40:53 +0100 (BST)
Subject: [R] How to define specific location of tick marks in plot()
In-Reply-To: <1ed.214512e5.2de0f38a@aol.com>
Message-ID: <Pine.LNX.4.44.0405221936510.7656-100000@gannet.stats>

On Sat, 22 May 2004 DJNordlund at aol.com wrote:

> I wish to create a series of plots with the same x-axis range and the
> same placement of tick marks.  In addition I want to force the tick
> marks to be at specific locations.  For example, if I wish to have an
> x-axis which goes from 40 to 110, with tick marks at 40, 50, 60, ... ,
> How can I accomplish that?  The various parameters I have tried changing
> just seem to be suggestions for an internal definition.
> 
> I'm sure this is easy, but I'm obviously missing something in  the 
> docmentation.

par(xaxs="d") is what you want, but it is not currently implemented.  So 
for now use xaxt="n" and then call axis() with at=.

plot(20:120, 20:120, xaxt="n")
axis(1, at = seq(40, 110, 10))

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From DJNordlund at aol.com  Sat May 22 22:58:53 2004
From: DJNordlund at aol.com (DJNordlund@aol.com)
Date: Sat, 22 May 2004 16:58:53 EDT
Subject: [R] How to define specific location of tick marks in plot()
Message-ID: <5a.2bcc0e94.2de1190d@aol.com>

Thanks to Prof. Ripley for the rapid response and solution.  The R  
developers and contributors to this list are very helpful and generous with  their time 
and advice.
Dan Nordlund  
In a message dated 5/22/2004 11:41:13 AM Pacific Daylight Time,  
ripley at stats.ox.ac.uk writes:
On Sat, 22 May 2004 DJNordlund at aol.com  wrote:

> I wish to create a series of plots with the same x-axis range  and the
> same placement of tick marks.  In addition I want to force  the tick
> marks to be at specific locations.  For example, if I wish  to have an
> x-axis which goes from 40 to 110, with tick marks at 40, 50,  60, ... ,
> How can I accomplish that?  The various parameters I have  tried changing
> just seem to be suggestions for an internal  definition.
> 
> I'm sure this is easy, but I'm obviously missing  something in  the 
> docmentation.

par(xaxs="d") is what you  want, but it is not currently implemented.  So 
for now use xaxt="n" and  then call axis() with at=.

plot(20:120, 20:120, xaxt="n")
axis(1, at =  seq(40, 110, 10))

-- 
Brian D.  Ripley,                   ripley at stats.ox.ac.uk
Professor of Applied Statistics,   http://www.stats.ox.ac.uk/~ripley/
University of  Oxford,              Te:  +44 1865 272861 (self)
1 South Parks  Road,                      +44 1865 272866 (PA)
Oxford OX1 3TG,  UK                 Fax:  +44 1865 272595



From jasont at indigoindustrial.co.nz  Sat May 22 11:40:09 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sat, 22 May 2004 21:40:09 +1200
Subject: [R] Help with Plotting Function
In-Reply-To: <CFF85773D9245040A333571B7E6D651702C5FD1D@ccssosrv1.ccsso.org>
References: <CFF85773D9245040A333571B7E6D651702C5FD1D@ccssosrv1.ccsso.org>
Message-ID: <20040522094009.GA24715@kryten.akl.indigoindustrial.co.nz>

On Fri, May 21, 2004 at 12:41:53PM -0400, Harold Doran wrote:
> Dear List:
> 
> I cannot seem to find a way to plot my data correctly. I have a small data frame with 6 total variables (x_1 ... x_6).
> 
> I am trying to plot x_1 against x_2 and x_3.
> 

Sundar has already answered the question - here's another trick for
displaying multiple data sets with lines, etc, to avoide cluttering
any one plot too much...

data(iris)
library(lqs)
plot(iris[,1:3],panel=function(x,y,...) {
    points(x,y,...)
    zz <- ltsreg(y~x)
    abline(zz)
})

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From thondeboer at yahoo.com  Sun May 23 09:00:54 2004
From: thondeboer at yahoo.com (Thon de Boer)
Date: Sun, 23 May 2004 00:00:54 -0700 (PDT)
Subject: [R] Running scripts automatically from Rgui (Windows)
Message-ID: <20040523070054.43319.qmail@web41510.mail.yahoo.com>

I am trying to get a script to start automatically
when I run the GUI version of R version 1.9.0, started
from a .bat file (WINDOWS), but I'm getting strange
errors

In version 1.8.1 I was able to run a script
automatically by copying the script into the file
.Rprofile and running Rgui from a .bat script, but in
version 1.9.0 I'm getting errors like:

Error in inherits(x, "factor") : couldn't find
function "winMenuNames"
In addition: Warning message: 
In the method signature for function "contents", class
"environment" has no current definition in:
matchSignature(signature, fdef, where) 
Error in library(Biobase) : .First.lib failed

Does anyone know if anything changed in version 1.9.0
that could explain these errors?

Thanks

Thon


P.S. Below you find the script I use. %1 will contain
the script that I try to run...



-------------
@echo off
copy %1 .Rprofile > copy-output.txt
shift
:Loop
IF "%1" == "" GOTO Continue
set %1=%2
shift
shift
GOTO Loop
:Continue
cat.exe > GS_R_in.txt
"C:\Program Files\R\rw1090\bin\Rgui.exe" --no-save
--no-restore
cat.exe < GS_R_out.txt
del GS_R_in.txt GS_R_out.txt copy-output.txt .Rprofile

-----------



From ripley at stats.ox.ac.uk  Sun May 23 09:23:19 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 May 2004 08:23:19 +0100 (BST)
Subject: [R] Running scripts automatically from Rgui (Windows)
In-Reply-To: <20040523070054.43319.qmail@web41510.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0405230819210.5466-100000@gannet.stats>

Please do read the NEWS file for R 1.9.0, which not only tells you this 
will happen but also tells you how to do this properly.

On Sun, 23 May 2004, Thon de Boer wrote:

> I am trying to get a script to start automatically
> when I run the GUI version of R version 1.9.0, started
> from a .bat file (WINDOWS), but I'm getting strange
> errors
> 
> In version 1.8.1 I was able to run a script
> automatically by copying the script into the file
> .Rprofile and running Rgui from a .bat script, but in
> version 1.9.0 I'm getting errors like:
> 
> Error in inherits(x, "factor") : couldn't find
> function "winMenuNames"
> In addition: Warning message: 
> In the method signature for function "contents", class
> "environment" has no current definition in:
> matchSignature(signature, fdef, where) 
> Error in library(Biobase) : .First.lib failed
> 
> Does anyone know if anything changed in version 1.9.0
> that could explain these errors?

There is a NEWS file, and this was also in the announcement of 1.9.0. Also
so discussion on R-help at about the time of release. How did you manage
to miss them?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Torsten.Hothorn at rzmail.uni-erlangen.de  Sun May 23 11:40:51 2004
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Sun, 23 May 2004 11:40:51 +0200 (CEST)
Subject: [R] pmvt problem in multcomp
In-Reply-To: <87vfirzwhq.wl@oak.dti.ne.jp>
References: <87vfirzwhq.wl@oak.dti.ne.jp>
Message-ID: <Pine.LNX.4.51.0405231138160.19910@artemis.imbe.med.uni-erlangen.de>


Yes, `pmvt' returns NaN without indicating this error. We need to check.
Thanks for the report (and *please* cc emails reporting problems with
packages to the maintainer!),

Torsten

On Thu, 20 May 2004, Chihiro Kuroki wrote:

> Hi, all:
>
> Two examples are shown below.
>
> I want to use the multiple comparison of Dunnett.
> It succeeded in upper case "example 1".
>
> However, the lower case "example 2" went wrong.
>
> In "example 2", the function pmvt return NaN, so I cannot show
> this simtest result. Is there any solution?
>
> (I changed the variable "maxpts" to a large number in front of
> the function pmvt ... but, the function mvt returned an error. )
>
> -- example 1 -------------------------------
> require(multcomp)
> Loading required package: multcomp
> Loading required package: mvtnorm
> [1] TRUE
>
> y <- as.vector(t$int)
> f <- as.factor(t$group1)
>
> table(f)
> f
>     1     2     3
> 20988 20988 20988
>
> dat <- cbind(as.data.frame(y),f)
> gc()
> summary(simtest(y ~ f, data=dat, type="Dunnett"))
>
> 	 Simultaneous tests: Dunnett contrasts
>
> Call:
> simtest.formula(formula = y ~ f, data = dat, type = "Dunnett")
>
> 	 Dunnett contrasts for factor f
>
> Contrast matrix:
>         f1 f2 f3
> f2-f1 0 -1  1  0
> f3-f1 0 -1  0  1
>
>
> Absolute Error Tolerance:  0.001
>
> Coefficients:
>       Estimate t value Std.Err. p raw p Bonf p adj
> f2-f1    4.015  -0.677    5.934 0.499  0.997 0.722
> f3-f1    2.486  -0.419    5.934 0.675  0.997 0.722
> ---------------------------------
>
> -- example 2 -------------------------------
> require(multcomp)
> Loading required package: multcomp
> Loading required package: mvtnorm
> [1] TRUE
>
> y <- as.vector(t$int)
> f <- as.factor(t$group2)
> table(f)
> f
>      1      2      3      4      5
> 104940 104940 104940 104940 104940
>
> dat <- cbind(as.data.frame(y),f)
> gc()
> summary(simtest(y ~ f, data=dat, type="Dunnett"))
>
> [1] "des <- model.matrix(ff, mf)"
>   (Intercept) aaa1 aaa2 aaa3 aaa4
> 1           1    1    0    0    0
> 2           1    0    1    0    0
> 3           1    0    0    1    0
> 4           1    0    0    0    1
> attr(,"assign")
> [1] 0 1 1 1 1
> attr(,"contrasts")
> attr(,"contrasts")$aaa
> [1] "ct"
>
> [1] "gls     <- rep(0,nrow(contonly))"
> [1] 0 0 0 0
>
> [1] "gls[i1]    <- 1-prob"
> [1] NaN   0   0   0
> [1] "gls[i1]    <- 1-prob"
> [1] NaN NaN   0   0
> [1] "gls[i1]    <- 1-prob"
> [1]          NaN          NaN -7.01661e-14  0.00000e+00
> [1] "gls[i1]    <- 1-prob"
> [1]           NaN           NaN -7.016610e-14  3.362133e-11
>
> [1] "glsbig"
>   aaa1 aaa2         aaa3         aaa4
> 1  NaN  NaN          NaN          NaN
> 2  NaN  NaN          NaN          NaN
> 3    0    0 -7.01661e-14 0.000000e+00
> 4    0    0  0.00000e+00 3.362133e-11
>
> [1] "glsp"
> aaa1 aaa2 aaa3 aaa4
>  NaN  NaN  NaN  NaN
> Error in if (glsp[i] < glsp[i - 1]) { : missing value where TRUE/FALSE needed
> Execution halted
> ---------------------------------
>
> --
> kuroki at oak.dti.ne.jp
> GnuPG fingerprint = 90FD FE79 905F 26F9 29C4  096F 8AA2 2C42 5130 1469
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From ligges at statistik.uni-dortmund.de  Sun May 23 13:19:23 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 23 May 2004 13:19:23 +0200
Subject: [R] axis labels disappear
In-Reply-To: <40ADF83E.1040706@hotmail.com>
References: <40ADF83E.1040706@hotmail.com>
Message-ID: <40B088BB.4020104@statistik.uni-dortmund.de>

Angel Lopez wrote:
> When I do a plot, e.g.
> plot(1:10)
> and resize the window so that the x-axis becomes too small to hold all 
> the x-axis labels, R automatically makes some of the labels disappear so 
> that the remaining fit in the available space.
> I would like to be able to tell R which labels should not be removed.
> 
> I've tried plotting the axis with axis() but this behaviour is still there.
> plot(1:10,xaxt="n")
> axis(side=1,at=1:10,labels=c("1","","","","5","","","","","10"))
> 
> In my case when I resize the window first the "10" disappears and the 
> the "5". Also if I start the graph with a 'small' window (e.g. 
> X11(width=3,height=3) I do not get the "10".
> Is there a way to force that these labels are not removed automatically?
> 
> I've searched the documentation but couldn't find any reference, Could 
> anyone point me to the right documentation for this feature?

Well, I think you cannot suppress that behaviour entirely, instead, you 
might want to just draw ticks and add labels with mtext()...

Uwe Ligges


> Thanks
> Angel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From dmurdoch at pair.com  Sun May 23 17:31:26 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 23 May 2004 11:31:26 -0400
Subject: [R] Re: Windows versus Unix packages in CRAN ...
In-Reply-To: <20040521134118.GC853@localhost>
References: <200405211202.i4LC2F49003939@erdos.math.unb.ca>
	<20040521134118.GC853@localhost>
Message-ID: <tdlua01flkn1hjgq1up163rnbp10vdg548@4ax.com>

On Fri, 21 May 2004 15:41:18 +0200, Tamas Papp <tpapp at axelero.hu>
wrote:

>You are probably right in saying that they _could_ have done better,
>but I would not use "should" in this context.  AFAIK the package is
>free (as in beer) software, which means that you are not paying for
>it.  The maintainers probably do not need a Linux version (yet), so it
>was not easy to use it under Linux.  Feel free to contribute.  

Yes, indeed!  

Duncan Murdoch



From munoz at stat.wisc.edu  Sun May 23 20:18:37 2004
From: munoz at stat.wisc.edu (Alejandro Munoz del Rio)
Date: Sun, 23 May 2004 13:18:37 -0500
Subject: [R] subset of documentation for a given recommended package
Message-ID: <1085336317.40b0eafd6590d@www-auth.cs.wisc.edu>

Dear R-help readers,

In R 1.8.1 it was easy to print the documentation for recommended packages: go
to the full reference manual (refman.pdf) and print the relevant pages, which
were contiguous. With R 1.9.0 some of those packages (e.g. "ts") have become
part of the "stats" package, and hence their documentation is scattered
throughout that of the other component packages of "stats". Is there a way of
regenerating the documentation of a specific package, short of painstakingly
identifying the relevant pages in the new reference manual?

alejandro



From ripley at stats.ox.ac.uk  Sun May 23 20:53:28 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 May 2004 19:53:28 +0100 (BST)
Subject: [R] subset of documentation for a given recommended package
In-Reply-To: <1085336317.40b0eafd6590d@www-auth.cs.wisc.edu>
Message-ID: <Pine.LNX.4.44.0405231948300.13898-100000@gannet.stats>

First, neither ts nor stats are/were *recommended* packages, as their 
DESCRIPTION files makes clear.

Second, package ts is now empty, so your question makes no sense.  Nor I
think did it before, as the time series functionality was never entirely
in package ts, and at least now it is entirely in stats.

On Sun, 23 May 2004, Alejandro Munoz del Rio wrote:

> In R 1.8.1 it was easy to print the documentation for recommended
> packages: go to the full reference manual (refman.pdf) and print the
> relevant pages, which were contiguous. With R 1.9.0 some of those
> packages (e.g. "ts") have become part of the "stats" package, and hence
> their documentation is scattered throughout that of the other component
> packages of "stats". Is there a way of regenerating the documentation of
> a specific package, short of painstakingly identifying the relevant
> pages in the new reference manual?

You can easily select help files with keyword `ts' and use Rd2dvi on them
to produce a printable manual.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rbaer at atsu.edu  Mon May 24 01:28:08 2004
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Sun, 23 May 2004 18:28:08 -0500
Subject: [R] bars with sd
References: <20040521084042.M78574@med.unipmn.it>
Message-ID: <00bc01c4411d$9b473a50$2e80010a@BigBaer>

You want to read the help ?segments.  Try the following to get the barplots:

ymean=c(1.25,2.65,3.45)
ysd=c(0.35,0.65,0.50)
xpos=barplot(ymean,ylim=c(0,max(ymean)+max(ysd)),col='yellow')
segments(xpos,ymean-ysd,xpos,ymean+ysd)

HTH,
Rob Baer

----- Original Message ----- 
From: "Matteo Vidali" <vidali at med.unipmn.it>
To: <R-help at stat.math.ethz.ch>
Sent: Friday, May 21, 2004 4:03 AM
Subject: [R] bars with sd


> I need some help for a curious question of a friend of mine.
> She usually does some experiments (3-5 repeats for each exp) and then she
> calculates mean and standard deviation.
> In microsoft excel she writes something like the following
>
> sample  mean   sd
> a       1.25   0.35
> b       2.65   0.65
> c       3.45   0.50
>
> She can do a vertical barplot graph just giving mean value and specifying
> the standard deviation value for each bar in the graph.
>
> My friend wants to know if it is possible to do the same with R. She has
> tried also with Open Office and seen that in that program you can plot
mean
> values as bars but it is not possible to specify a different sd for each
> bar 'cause the program, if you ask to put the standard deviation,
calculates
> a common sd using the mean values.
> I was not able to give her an answer for the barplot function in R. I have
> just said to her that it is likely due to the fact that using a barplot
> graph to plot mean and standard deviation values it is non a good
practice,
> since the height (or the area) of bars should represent frequency and that
> putting a standard deviation in that way it is at least quite confusing
for
> the reader to interpret the graph. Some scientific journal revisors
> discourage this practice. She should instead use a boxplot or just
plotting
> the different repetition values for each sample as points and add a linea
> indicating the mean.
> But if this is correct why in some programs like open office you can plot
> bars with a common standard deviation???? when will you need this last
type
> of graph?
>
> any suggestion? any help?
> thanks in advance
> Matteo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From ok at cs.otago.ac.nz  Mon May 24 01:32:20 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Mon, 24 May 2004 11:32:20 +1200 (NZST)
Subject: [R] Re: Windows versus Unix packages in CRAN ...
Message-ID: <200405232332.i4NNWKGo007991@atlas.otago.ac.nz>



From ok at cs.otago.ac.nz  Mon May 24 01:59:04 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Mon, 24 May 2004 11:59:04 +1200 (NZST)
Subject: [R] Re: Windows versus Unix packages in CRAN ...
Message-ID: <200405232359.i4NNx4UE008463@atlas.otago.ac.nz>

Concerning the Rmetrics packages,

(1) There is a _much_ better thing to do than
	>simply ... to remove the stuff related to MS Win from zzz.R;
	> in partricular the lines after if( .... ) to clear your message.
	> As you can see, the info relates to the WinMenu under MS Win.
    as Janusz Kawczak suggests, and that is to *wrap* the troublesome code
    in
	if (exists("winMenuAdd")) {
	    ... original code goes here ...
	}
    The resulting code should then work *both* in Windows *and* in Unix.

    The documentation in the FAQ *does* provide quite a clear indication
    that this is something to watch out for; I found it fairly easy to
    find and work around this bit.

(2) By manually editing the 'Built:' line in the 'evir' package,
    which is a "binary" package that contains no object files,
    I was able to get a clear install of 'evir' for which all the
    examples I tried seemed to work (defined as "didn't crash" and
    "vaguely plausible output").

    The documentation doesn't mention this anywhere; it was a crazy thing
    to try, but noticing that the package didn't contain any .obj .dll
    .lib .o .a .so &c files suggested to me that it might work.

(3) Getting the sources of the fBasics package and putting the
    if (exists("winMenuAdd")) {} wrapper in zzz.R was not sufficient to
    make fBasics "work" under Solaris:  one of the Fortran codes exercised
    by example(distributionFits) crashes (UNIX signal).  My understanding
    is that it also does this under Linux.
	
    At this point my knowledge and skills ran out.  I'm a fairly fluent
    "speaker" of Fortran, but know nothing about *debugging* a mixture of
    R, R internals, and Fortran.  The fact that it was an addressing fault
    which showed up in Unix but not Windows makes me suspect a data alignment
    problem, possibly triggered by a data length error, but it's going to
    need someone else to fix it.



From christianlederer at t-online.de  Mon May 24 05:53:14 2004
From: christianlederer at t-online.de (Christian Lederer)
Date: Mon, 24 May 2004 05:53:14 +0200
Subject: [R] coxph covariance matrix
Message-ID: <40B171AA.1020606@trium.de>

Hi,

when calculating the Cox model for a factor with n levels
(using treatment contrasts), i noticed that the off diagonal elements
of the estimated covariance matrix are always nearly (but not exactly)
equal.

On the one hand, this is plausible to me: If i could obtain estimates
x_i, 1<=i<=n, for the log hazard ratios relative to the baseline hazard,
then of course the off diagonal elements of the covariance matrix for
the estimated contrasts y_i = x_i - x_1 would be exactly equal.

On the other hand, the coxph model estimates the contrasts directly,
and numerically the off diagonal elements are just very close, but not 
equal.

Any explanation, hint or reference would be highly appreciated.

Christian



From ypeng at math.mun.ca  Mon May 24 05:48:24 2004
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Mon, 24 May 2004 01:18:24 -0230
Subject: [R] Cannot call R's ISNAN() from a C code in >1.7 versions.
Message-ID: <40B17088.1000304@math.mun.ca>

Dear R users,

Have you experienced any difficulty in calling R's ISNAN() from a C
code? I have C codes including ISNAN() calls and they worked well until
I upgraded my R from 1.7 to later versions. When I tried to compile the
codes in the version 1.8 and 1.9, I got error messages like this:

   test.obj : error LNK2001: unresolved external symbol _isnan
   .\testR.dll : fatal error LNK1120: 1 unresolved externals
   NMAKE : fatal error U1077: 'link.exe' : return code '0x460'
   Stop.

I checked "Writing R Extensions" and did not find any changes in the API
entry point for ISNAN in the later versions. Could any one enlighten me
on why _isnan cannot be resolved? The compiler I used is MSVC++ 6.0 and
the platform is WinXP. Many thanks.

Paul.



From sfelten at uwinst.unizh.ch  Mon May 24 08:07:27 2004
From: sfelten at uwinst.unizh.ch (Stefanie von Felten)
Date: Mon, 24 May 2004 08:07:27 +0200
Subject: [R] Manova and specifying the model
Message-ID: <001b01c44155$63ccfaa0$3e183c82@p4a2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040524/b22d1e02/attachment.pl

From sfelten at uwinst.unizh.ch  Mon May 24 08:13:32 2004
From: sfelten at uwinst.unizh.ch (Stefanie von Felten)
Date: Mon, 24 May 2004 08:13:32 +0200
Subject: [R] discriminant analysis
Message-ID: <002801c44156$3d56d430$3e183c82@p4a2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040524/07a6ee7d/attachment.pl

From ripley at stats.ox.ac.uk  Mon May 24 08:26:33 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 May 2004 07:26:33 +0100 (BST)
Subject: [R] Manova and specifying the model
In-Reply-To: <001b01c44155$63ccfaa0$3e183c82@p4a2>
Message-ID: <Pine.LNX.4.44.0405240725110.14723-100000@gannet.stats>

See the examples in ?summary.manova, please.

Y <- cbind(tear, gloss, opacity)

shows how to make a multiple response.

On Mon, 24 May 2004, Stefanie von Felten wrote:

> I would like to conduct a MANOVA. I know that there 's the manova()
> funciton and the summary.manova() function to get the appropriate
> summary of test statistics.
> 
> I just don't manage to specify my model in the manova() call. How to
> specify a model with multiple responses and one explanatory factor?
> 
> If I type:
> pcor.manova<-manova(isol+hcom+habarea+inclin+windprot+shrubcov+herbh+baregr+flowcov~pcor, data=pcor.df)
> 
> I always get error messages like:
> Error in manova(isol + hcom + habarea + inclin + windprot + shrubcov +  : 
>         need multiple response


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May 24 08:28:27 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 May 2004 07:28:27 +0100 (BST)
Subject: [R] discriminant analysis
In-Reply-To: <002801c44156$3d56d430$3e183c82@p4a2>
Message-ID: <Pine.LNX.4.44.0405240726430.14723-100000@gannet.stats>

On Mon, 24 May 2004, Stefanie von Felten wrote:

> I have done different discriminant function analysis of multivariat

Using lda in contributed package MASS, uncredited.

> data. With the CV=True option I was not able to perform the predict()
> call. What do I have to do? Or is there no possibility at all? You also

It makes no sense.  You ask for LOO cross-validation, and that is n 
separate fits, not a single fit from which you can predict.

> need the predicted values to produce a plot of the analysis, as far as I
> know.
> 
> Here my code:
> 
> pcor.lda2<-lda(pcor~habarea+hcom+isol+flowcov+herbh+inclin+windprot+shrubcov+baregr, data=pcor.df, CV=T)
> table2<-table(pcor.df$pcor, pcor.lda2$class)
> table2
> 
> #doesn't work, becoause CV=True?
> pcor.ld2<-predict(pcor.lda2, dimen=1)$x
> plot(pcor.ld2)
> plot(pcor.lda2, type="density", dimen=1) #kernel density estimates 
> 
> I am happy if I get an answer from somebody!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May 24 08:40:42 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 May 2004 07:40:42 +0100 (BST)
Subject: [R] Cannot call R's ISNAN() from a C code in >1.7 versions.
In-Reply-To: <40B17088.1000304@math.mun.ca>
Message-ID: <Pine.LNX.4.44.0405240729290.14723-100000@gannet.stats>

First, there are no versions 1.7, 1.8 and 1.9.

Was your version of R compiled against MSVC++ 6.0?  The binary on CRAN was
not, and binaries for different versions of R were compiled with different
versions of MinGW.  The entry point isnan is part of the statically linked
runtime on modern MinGW.

MSVC++ 6.0 does supply _isnan (as it really should as it is part of the
C99 ISO standard), and you need to link against it appropriately.  Hint:
it may have an extra underline, since it seems it is known to C as _isnan.
You may need to add

#undef ISNAN
#define ISNAN(x) _isnan(x)


We don't support adding extensions to R using a different compiler to the 
one used to build R.  Changes already made for future releases of R will 
make this less likely to work in R 2.0.x.


On Mon, 24 May 2004, Paul Y. Peng wrote:

> Dear R users,
> 
> Have you experienced any difficulty in calling R's ISNAN() from a C
> code? I have C codes including ISNAN() calls and they worked well until
> I upgraded my R from 1.7 to later versions. When I tried to compile the
> codes in the version 1.8 and 1.9, I got error messages like this:
> 
>    test.obj : error LNK2001: unresolved external symbol _isnan
>    .\testR.dll : fatal error LNK1120: 1 unresolved externals
>    NMAKE : fatal error U1077: 'link.exe' : return code '0x460'
>    Stop.
> 
> I checked "Writing R Extensions" and did not find any changes in the API
> entry point for ISNAN in the later versions. Could any one enlighten me
> on why _isnan cannot be resolved? The compiler I used is MSVC++ 6.0 and
> the platform is WinXP. Many thanks.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Lorenz.Gygax at fat.admin.ch  Mon May 24 08:56:44 2004
From: Lorenz.Gygax at fat.admin.ch (Lorenz.Gygax@fat.admin.ch)
Date: Mon, 24 May 2004 08:56:44 +0200
Subject: [R] bug in cor (..., use= ...)?
Message-ID: <BF74FADD4B44554CA7E53D0B5242CD6A018DAF82@evd-s7014.evd.admin.ch>

Dear R users,

I have not found anything on this in the archives. Does anyone know whehther
the parameter use= is not functioning in cor or enlighten me what it is
supposed to do?

My R version is "R version 1.8.1, 2003-11-21" on Windows 2000. I am hoping
to be able to update to 1.9.1 as soon as it has appeared (we are not allowed
here to install software on our own and thus I am trying to be able to have
the .1 versions installed ...).

Test code:

x <- 1:10
y <- 2:11

x [1] <- NA
y [10] <- 12

cor (x, y, use= 'all.obs', method= 'kendall')
cor (x, y, use= 'complete.obs', method= 'kendall')
cor (x, y, use= 'pairwise.complete.obs', method= 'kendall')

As I understand, the first one of this should result in an error which it
does not. All the results are the same and seemingly treat the NA as if it
was 0.

Any ideas are appreciated.

Thanks and regards, Lorenz
- 
Lorenz Gygax, Dr. sc. nat.
Tel: +41 (0)52 368 33 84 / lorenz.gygax at fat.admin.ch      

Tag der offenen T??r, 11./12. Juni 2004: http://www.fat.ch/2004

Center for proper housing of ruminants and pigs
Swiss Veterinary Office
agroscope FAT T??nikon, CH-8356 Ettenhausen / Switzerland
Fax : +41 (0)52 365 11 90 / Tel: +41 (0)52 368 31 31



From ripley at stats.ox.ac.uk  Mon May 24 09:08:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 May 2004 08:08:12 +0100 (BST)
Subject: [R] bug in cor (..., use= ...)?
In-Reply-To: <BF74FADD4B44554CA7E53D0B5242CD6A018DAF82@evd-s7014.evd.admin.ch>
Message-ID: <Pine.LNX.4.44.0405240805580.23344-100000@gannet.stats>

>From the NEWS file for 1.9.0

    o	The cor() function did not remove missing values in the
	non-Pearson case.

Your example works correctly there.  (I am fairly sure this has been 
discussed on the mailing lists.)

On Mon, 24 May 2004 Lorenz.Gygax at fat.admin.ch wrote:

> Dear R users,
> 
> I have not found anything on this in the archives. Does anyone know whehther
> the parameter use= is not functioning in cor or enlighten me what it is
> supposed to do?
> 
> My R version is "R version 1.8.1, 2003-11-21" on Windows 2000. I am hoping
> to be able to update to 1.9.1 as soon as it has appeared (we are not allowed
> here to install software on our own and thus I am trying to be able to have
> the .1 versions installed ...).
> 
> Test code:
> 
> x <- 1:10
> y <- 2:11
> 
> x [1] <- NA
> y [10] <- 12
> 
> cor (x, y, use= 'all.obs', method= 'kendall')
> cor (x, y, use= 'complete.obs', method= 'kendall')
> cor (x, y, use= 'pairwise.complete.obs', method= 'kendall')
> 
> As I understand, the first one of this should result in an error which it
> does not. All the results are the same and seemingly treat the NA as if it
> was 0.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Mon May 24 09:15:10 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 24 May 2004 03:15:10 -0400
Subject: [R] subset of documentation for a given recommended package
In-Reply-To: <1085336317.40b0eafd6590d@www-auth.cs.wisc.edu>
References: <1085336317.40b0eafd6590d@www-auth.cs.wisc.edu>
Message-ID: <2s73b0l1bj8s852hqsgasv24rfnj4fqfdt@4ax.com>

On Sun, 23 May 2004 13:18:37 -0500, Alejandro Munoz del Rio
<munoz at stat.wisc.edu> wrote:

>Dear R-help readers,
>
>In R 1.8.1 it was easy to print the documentation for recommended packages: go
>to the full reference manual (refman.pdf) and print the relevant pages, which
>were contiguous. With R 1.9.0 some of those packages (e.g. "ts") have become
>part of the "stats" package, and hence their documentation is scattered
>throughout that of the other component packages of "stats". Is there a way of
>regenerating the documentation of a specific package, short of painstakingly
>identifying the relevant pages in the new reference manual?

If you have a list of the .Rd files you want, you can use 

R CMD Rd2dvi --pdf <list of files>

to produce pdf versions of a list of files.  

Duncan Murdoch



From v.demartino2 at virgilio.it  Mon May 24 12:00:46 2004
From: v.demartino2 at virgilio.it (v.demartino2@virgilio.it)
Date: Mon, 24 May 2004 12:00:46 +0200
Subject: [R] Tramo-seats
Message-ID: <4087DF45000A1F41@ims3e.cp.tin.it>

Working  - among other things- in the field of (short & long term) electricity
forecast,  we are now using too many & too expensive pieces of licensed
software: SAS, SPSS, EViews. This "sedimentation" is due to the fact that
my predecessors in the past used different consultant companies to manage
each procedure.

Having attended the useR2004! Conference with the aim of assessing if R
ALONE could "glue" all those fragmented and isolated procedures, I'm almost
convinced now that YES it could do the job!

Now - to start with - a first problem to solve:

we have to comply with the Tramo-seats closed-source procedure (http://www.bde.es/informes/be/docs/dt0014e.pdf)
to deal with seasonality of electricity monthly time-series, in line with
the methodology officially adopted by our  National Bureau of Statistics.

Searching in R-help mailing list I didn't find anything about a tramo-seats
R version. 

Does anyone know of unofficial R translation of tramo-seats?
OR What do you suggest?

Vittorio



From SabineBader at gmx.de  Mon May 24 14:22:19 2004
From: SabineBader at gmx.de (Sabine Bader)
Date: Mon, 24 May 2004 14:22:19 +0200 (MEST)
Subject: [R] problems with starting R
Message-ID: <7455.1085401339@www16.gmx.net>

When I try to start R from my desktop, an "information"-window pops up:
"Fatal error: Invalid HOMEDRIVE".
I already deleted and reinstalled the program, but the problem lasts.
How can I solve this problem?
I would be very glad, if you can give me a hint, what??s going wrong.

Best regards
Sabine Bader

-- 
Sabine Bader
Hamburger Str. 83
44135 Dortmund

0231/7950683



From Rau at demogr.mpg.de  Mon May 24 14:29:51 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Mon, 24 May 2004 14:29:51 +0200
Subject: [R] problems with starting R
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A09C9@hermes.demogr.mpg.de>

Hi Sabine,

> -----Original Message-----
> From:	Sabine Bader [SMTP:SabineBader at gmx.de]
> Sent:	Monday, May 24, 2004 2:22 PM
> To:	R-help at lists.R-project.org
> Subject:	[R] problems with starting R
> 
> When I try to start R from my desktop, an "information"-window pops up:
> "Fatal error: Invalid HOMEDRIVE".
> 
	This problem appeared dozens of times during the last few weeks.
	Best thing is probably to read one of the previous threads related
to this topic.
	If you go, for example, to: 
	http://maths.newcastle.edu.au/~rking/R/
	there is a searchable R-help archive.
	Enter the keywords:
	INVALID HOMEDRIVE
	and you will get many many results (I just tried it and it gave 128
hits).

	Hope this helps,
	Roland



+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From wolski at molgen.mpg.de  Mon May 24 14:35:50 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 24 May 2004 14:35:50 +0200
Subject: [R] problems with starting R
In-Reply-To: <7455.1085401339@www16.gmx.net>
References: <7455.1085401339@www16.gmx.net>
Message-ID: <200405241435500357.00D58645@mail.math.fu-berlin.de>

Hi!
This problem was discussed on the list.
For searching the mail archives you can use eg.

http://maths.newcastle.edu.au/~rking/R/

The link to this page can be found at:
http://cran.r-project.org/search.html

Entering 
"Fatal error: Invalid HOMEDRIVE".
Will provide you many answers to your question.

Eg.:
http://tolstoy.newcastle.edu.au/R/help/04/04/1171.html

Sincerely
Eryk




*********** REPLY SEPARATOR  ***********

On 5/24/2004 at 2:22 PM Sabine Bader wrote:

>When I try to start R from my desktop, an "information"-window pops up:
>"Fatal error: Invalid HOMEDRIVE".
>I already deleted and reinstalled the program, but the problem lasts.
>How can I solve this problem?
>I would be very glad, if you can give me a hint, what??s going wrong.
>
>Best regards
>Sabine Bader
>
>-- 
>Sabine Bader
>Hamburger Str. 83
>44135 Dortmund
>
>0231/7950683
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From Murk at polderland.nl  Mon May 24 15:58:57 2004
From: Murk at polderland.nl (Murk Wuite)
Date: Mon, 24 May 2004 15:58:57 +0200
Subject: [R] non-hierarchical non-exclusive clustering of large data sets
Message-ID: <999F1D23DA11C142BEE24D0FD92CEE6D09E697@water.Polderland.local>

Hi,

I'm trying to use R to cluster words with related meanings. Does anyone
know of a non-hierarchical clustering method in R that produces
non-exclusive clusters? With non-exclusive, I mean that words should be
allowed to be part of multiple clusters. So my data matrix would look
something like:

		T1	T2	T3
CLOWN_N	0	1	0
BANK_N	3	0	2
RIVER_N	0	0	2
FLOW_V	0	0	3
MONEY_N	2	0	0
PAY_V		2	0	0

The first line indicates the noun "clown" occurred only once in my text
collection, namely in text 2. Ideally, the clustering method would
produce the clusters [bank_n,river_n,flow_v], [bank_n,money_n,pay_v] and
[clown_n].
The data matrix I would use would be much bigger than the one above, its
dimensions would be in the order of (100000,100000). Does anyone know if
this would cause practical problems, perhaps very slow clustering?

Best wishes,

Murk Wuite, MA student
Department of Language and Speech
Katholieke Universiteit Nijmegen, The Netherlands



From wolski at molgen.mpg.de  Mon May 24 15:57:48 2004
From: wolski at molgen.mpg.de (witek)
Date: Mon, 24 May 2004 15:57:48 +0200
Subject: [R] replacing backslashes with slashes using gsub
Message-ID: <200405241557480231.011FF2F7@mail.math.fu-berlin.de>

Hi!

I am trying to replace backslashes with slashes using gsub (R1.9.0 on XP)

gsub("\\\\","/","D:\Prog\R\rw1090\library\cluster\libs")
[1] "D:ProgR\rw1090libraryclusterlibs"

?

Sincerely Eryk



From bxc at steno.dk  Mon May 24 15:58:32 2004
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Mon, 24 May 2004 15:58:32 +0200
Subject: [R] Month names
Message-ID: <0ABD88905D18E347874E0FB71C0B29E90179EB20@exdkba022.novo.dk>

This is how I get the month names from within R:

> mon <- rep(strptime("01/01/1952", format = "%d/%m/%Y"), 12)
> mon$mon <- mon$mon + 0:11
> mnam <- months(mon, abbreviate = F)
> mnam
 [1] "januar"    "februar"   "marts"     "april"     "maj"       "juni"
"juli"      "august"    "september"
[10] "oktober"   "november"  "december" 

Surely someone on the list can beat that in elegance?

Bendix Carstensen
----------------------
Bendix Carstensen
Senior Statistician
Steno Diabetes Center
Niels Steensens Vej 2
DK-2820 Gentofte
Denmark
tel: +45 44 43 87 38
mob: +45 30 75 87 38
fax: +45 44 43 07 06
bxc at steno.dk
www.biostat.ku.dk/~bxc



From jgentry at jimmy.harvard.edu  Mon May 24 16:03:07 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon, 24 May 2004 10:03:07 -0400 (EDT)
Subject: [R] replacing backslashes with slashes using gsub
In-Reply-To: <200405241557480231.011FF2F7@mail.math.fu-berlin.de>
Message-ID: <Pine.SOL.4.20.0405241002480.3138-100000@santiam.dfci.harvard.edu>

> gsub("\\\\","/","D:\Prog\R\rw1090\library\cluster\libs")
> [1] "D:ProgR\rw1090libraryclusterlibs"

Probably not the best way, but what about escaping all the backslashes in
the original string?
 gsub("\\\\","/","D:\\Prog\\R\\rw1090\\library\\cluster\\libs")



From ripley at stats.ox.ac.uk  Mon May 24 16:06:47 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 May 2004 15:06:47 +0100 (BST)
Subject: [R] Month names
In-Reply-To: <0ABD88905D18E347874E0FB71C0B29E90179EB20@exdkba022.novo.dk>
Message-ID: <Pine.LNX.4.44.0405241503330.12324-100000@gannet.stats>

format(ISOdate(2000, 1:12, 1), "%B")

On Mon, 24 May 2004, BXC (Bendix Carstensen) wrote:

> This is how I get the month names from within R:
> 
> > mon <- rep(strptime("01/01/1952", format = "%d/%m/%Y"), 12)
> > mon$mon <- mon$mon + 0:11
> > mnam <- months(mon, abbreviate = F)
> > mnam
>  [1] "januar"    "februar"   "marts"     "april"     "maj"       "juni"
> "juli"      "august"    "september"
> [10] "oktober"   "november"  "december" 
> 
> Surely someone on the list can beat that in elegance?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bhaskar at cacmnet.com  Mon May 24 17:12:28 2004
From: bhaskar at cacmnet.com (Bhaskar S. Manda)
Date: Mon, 24 May 2004 09:12:28 -0600
Subject: [R] non-hierarchical non-exclusive clustering of large data sets
In-Reply-To: <999F1D23DA11C142BEE24D0FD92CEE6D09E697@water.Polderland.local>
References: <999F1D23DA11C142BEE24D0FD92CEE6D09E697@water.Polderland.local>
Message-ID: <20040524141218.M19812@cacmnet.com>

On Mon, 24 May 2004 15:58:57 +0200, Murk Wuite wrote: 
> I'm trying to use R to cluster words with related meanings. Does anyone
> know of a non-hierarchical clustering method in R that produces
> non-exclusive clusters? With non-exclusive, I mean that words should 

The "fanny" method in library(cluster) outputs probabilities of membership in
each cluster.

> the one above, its dimensions would be in the order of (100000,
> 100000). Does anyone know if this would cause practical problems,
>  perhaps very slow clustering?

I had a much smaller matrix, 4000x3, fanny took about 4 minutes wall clock
time on a lightly loaded (there were many other processes, but none
computational) 1.4 GHz Athlon, It was completely CPU-bound. 

--
bhaskar



From carly.whittaker at imperial.ac.uk  Mon May 24 16:17:36 2004
From: carly.whittaker at imperial.ac.uk (Whittaker, Carly)
Date: Mon, 24 May 2004 15:17:36 +0100
Subject: [R] (no subject)
Message-ID: <7F7467484936BA4F98C2A72E684AF561080375@icex34.cc.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040524/8da3ea29/attachment.pl

From jgentry at jimmy.harvard.edu  Mon May 24 16:24:03 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon, 24 May 2004 10:24:03 -0400 (EDT)
Subject: [R] (no subject)
In-Reply-To: <7F7467484936BA4F98C2A72E684AF561080375@icex34.cc.ic.ac.uk>
Message-ID: <Pine.SOL.4.20.0405241022550.3138-100000@santiam.dfci.harvard.edu>

> Hello! Please!How do I download R from the internet?

http://cran.r-project.org/doc/FAQ/R-FAQ.html#How%20can%20R%20be%20obtained%3f



From ligges at statistik.uni-dortmund.de  Mon May 24 16:24:31 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 24 May 2004 16:24:31 +0200
Subject: [R] (no subject)
In-Reply-To: <7F7467484936BA4F98C2A72E684AF561080375@icex34.cc.ic.ac.uk>
References: <7F7467484936BA4F98C2A72E684AF561080375@icex34.cc.ic.ac.uk>
Message-ID: <40B2059F.6010203@statistik.uni-dortmund.de>

Whittaker, Carly wrote:

> Hello! Please!How do I download R from the internet?

Several ways, one ist to right click and say something like "save to 
..." in your browser when visiting  CRAN at http://cran.r-project.org/ 
and having "browsed" to the sources or the binary version that is the 
right one for your OS.

Uwe Ligges


> Thankyou for your time
> carly
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andrewr at uidaho.edu  Mon May 24 16:37:46 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Mon, 24 May 2004 07:37:46 -0700 (PDT)
Subject: [R] Stopping the process after a certain time
Message-ID: <Pine.GSO.4.56.0405240731560.14554@cyclone.csrv.uidaho.edu>

Greetings R-community,

I'm running simulations within R that I wrote in C.  The simulations
require fitting that occasionally fails to finish.  I was wondering if
there is any kind of tool for process control in R, such that after e.g.
15 minutes I could kill the process, record the state for post-hoc
analysis, and move to the next simulation?

I'm running FreeBSD and could almost surely do something in Perl but I'd
rather stay inside R if possible.

Thanks,

Andrew

Andrew Robinson			     Ph: 208 885 7115
Department of Forest Resources	     Fa: 208 885 6226
University of Idaho		     E : andrewr at uidaho.edu
PO Box 441133			     W : http://www.uidaho.edu/~andrewr
Moscow ID 83843			     Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From rpeng at jhsph.edu  Mon May 24 16:38:09 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 24 May 2004 10:38:09 -0400
Subject: [R] Month names
In-Reply-To: <0ABD88905D18E347874E0FB71C0B29E90179EB20@exdkba022.novo.dk>
References: <0ABD88905D18E347874E0FB71C0B29E90179EB20@exdkba022.novo.dk>
Message-ID: <40B208D1.3010100@jhsph.edu>

How about `month.name'?

-roger


BXC (Bendix Carstensen) wrote:
> This is how I get the month names from within R:
> 
> 
>>mon <- rep(strptime("01/01/1952", format = "%d/%m/%Y"), 12)
>>mon$mon <- mon$mon + 0:11
>>mnam <- months(mon, abbreviate = F)
>>mnam
> 
>  [1] "januar"    "februar"   "marts"     "april"     "maj"       "juni"
> "juli"      "august"    "september"
> [10] "oktober"   "november"  "december" 
> 
> Surely someone on the list can beat that in elegance?
> 
> Bendix Carstensen
> ----------------------
> Bendix Carstensen
> Senior Statistician
> Steno Diabetes Center
> Niels Steensens Vej 2
> DK-2820 Gentofte
> Denmark
> tel: +45 44 43 87 38
> mob: +45 30 75 87 38
> fax: +45 44 43 07 06
> bxc at steno.dk
> www.biostat.ku.dk/~bxc
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Matthias.Templ at statistik.gv.at  Mon May 24 16:39:33 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Mon, 24 May 2004 16:39:33 +0200
Subject: AW: [R] non-hierarchical non-exclusive clustering of large data sets
Message-ID: <83536658864BC243BE3C06D7E936ABD50153A5AA@xchg1.statistik.local>

I think the "cmeans" method in library(e1071) works better for large data sets as "fanny".

(note,not for this data: fanny has also problems with standardized large data sets - here produce fanny the same memberships for all observations; cmeans works "correctly")

Matthias


> -----Urspr??ngliche Nachricht-----
> Von: Bhaskar S. Manda [mailto:bhaskar at cacmnet.com] 
> Gesendet: Montag, 24. Mai 2004 17:12
> An: r-help at stat.math.ethz.ch
> Betreff: Re: [R] non-hierarchical non-exclusive clustering of 
> large data sets
> 
> 
> On Mon, 24 May 2004 15:58:57 +0200, Murk Wuite wrote: 
> > I'm trying to use R to cluster words with related meanings. Does 
> > anyone know of a non-hierarchical clustering method in R 
> that produces 
> > non-exclusive clusters? With non-exclusive, I mean that words should
> 
> The "fanny" method in library(cluster) outputs probabilities 
> of membership in each cluster.
> 
> > the one above, its dimensions would be in the order of (100000, 
> > 100000). Does anyone know if this would cause practical problems,  
> > perhaps very slow clustering?
> 
> I had a much smaller matrix, 4000x3, fanny took about 4 
> minutes wall clock time on a lightly loaded (there were many 
> other processes, but none
> computational) 1.4 GHz Athlon, It was completely CPU-bound. 
> 
> --
> bhaskar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Jesus.Frias at dit.ie  Mon May 24 16:36:15 2004
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Mon, 24 May 2004 15:36:15 +0100
Subject: [R] Metafiiles  into Word R 1.9.0
Message-ID: <LGECJJCANFBOOHCMGPJEKEENDDAA.Jesus.Frias@dit.ie>

Dear R-helpers,

	I recently upgraded to R 1.9.0 in my computer at work and at home:

	1.-The computer at home has Windows XP and Office XP and it seems to work
perfectly and I copy-paste graphics perfectly.

	2.-The computer at work has Microsoft Windows 2000 (5.00.2195 Service Pack
2) and Word 2000 (9.0.4402 SR-1) I cannot copy-paste windows metafiles into
Office applications in my computer at work. The resulting object is empty.

	Is there any way of overcoming this other than going back in R versions?
(an indication to patch from Microsoft Office that can take new metafiles
:-).

best regards,

Jesus

P.S.: this mail is probably a similar topic as Patrick Giraudoux email at
the beginning of the month, I apologise for the duplication.


platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.0
year     2004
month    04
day      12
language R




--------------------------------------------------------------
Jes??s Mar??a Fr??as Celayeta
School of Food Sci. and Env. Health.
Faculty of Tourism and Food
Dublin Institute of Technology
Cathal Brugha St., Dublin 1. Ireland
t +353 1 4024459 f +353 1 4024495
w www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------


-- 
This message has been scanned for content and 
viruses by the DIT Information Services MailScanner 
Service, and is believed to be clean.
http://www.dit.ie



From maechler at stat.math.ethz.ch  Mon May 24 16:43:54 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 24 May 2004 16:43:54 +0200
Subject: [R] Month names
In-Reply-To: <40B208D1.3010100@jhsph.edu>
References: <0ABD88905D18E347874E0FB71C0B29E90179EB20@exdkba022.novo.dk>
	<40B208D1.3010100@jhsph.edu>
Message-ID: <16562.2602.466113.303535@gargle.gargle.HOWL>

>>>>> "Roger" == Roger D Peng <rpeng at jhsph.edu>
>>>>>     on Mon, 24 May 2004 10:38:09 -0400 writes:

    Roger> How about `month.name'?

English only.

Note that he got the names in Danish (I think)
Martin

    Roger> BXC (Bendix Carstensen) wrote:
    >> This is how I get the month names from within R:
    >> 
    >> 
    >>> mon <- rep(strptime("01/01/1952", format = "%d/%m/%Y"), 12)
    >>> mon$mon <- mon$mon + 0:11
    >>> mnam <- months(mon, abbreviate = F)
    >>> mnam
    >> 
    >> [1] "januar"    "februar"   "marts"     "april"     "maj"       "juni"
    >> "juli"      "august"    "september"
    >> [10] "oktober"   "november"  "december" 
    >> 
    >> Surely someone on the list can beat that in elegance?
    >> 
    >> Bendix Carstensen
    >> ----------------------
    >> Bendix Carstensen
    >> Senior Statistician
    >> Steno Diabetes Center
    >> Niels Steensens Vej 2
    >> DK-2820 Gentofte
    >> Denmark
    >> tel: +45 44 43 87 38
    >> mob: +45 30 75 87 38
    >> fax: +45 44 43 07 06
    >> bxc at steno.dk
    >> www.biostat.ku.dk/~bxc



From ernesto at ipimar.pt  Mon May 24 16:56:20 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon, 24 May 2004 15:56:20 +0100
Subject: [R] RMySQL problem
Message-ID: <1085410580.27999.111.camel@gandalf.local>

Hi,

I'm using R 1.9.0 with RMySQL 0.5-4 and MySQL 3.23.55 on a suse 8.2 box.

I have a simulation study and (as usual for newbies in simulation, I
guess) I have a lot of data that I want to store in MySQL. I want to
write an R script that reads data from RData files and writes it to a
MySQL database. 

I read some R documents (R Data Import/Export and DSC papers) but I'm
finding differences between the documents and the packages (RMySQL and
DBI). I don't find the methods to write data like "dbWriteTable"...

On the other hand I've tryied to build a sql statement to insert data
but I'm stucked because of ... who knows, my ignorance probably. I want
to take advantage of MySQl INSERT INTO statement that deals with several
rows at once to insert a complete data.frame into a table. I've tryied
to use "paste" to build the sql string but It works "by column" and I
need it "by row" ...

The sql systax should be something like:

INSERT INTO TABLEA(COL1, COL2, COL3) VALUES
	(VAL11, VAL12, VAL13),
	(VAL21, VAL22, VAL23),
	...
	(VALN1, VALN2, VALN3);

and I have a data.frame with 3 columns corresponding to that table
columns.

How can I do this ?

Thanks

EJ



From p.dalgaard at biostat.ku.dk  Mon May 24 16:55:32 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 May 2004 16:55:32 +0200
Subject: [R] RPM post-install scripts to update R
In-Reply-To: <40AF6695.1080502@mcgill.ca>
References: <200405221001.i4MA0pFH000801@hypatia.math.ethz.ch>
	<40AF6695.1080502@mcgill.ca>
Message-ID: <x23c5pyivv.fsf@biostat.ku.dk>

chris albert <christopher.albert at mcgill.ca> writes:

> Hi,
> 
> Paul Johnson asked:
> 
>     While I'm on the RPM subject, can I ask an R RPM packaging question? I
>     want the R RPM to install so that post install then R starts and runs
>     > update.packages()
> 
>     as well as
> 
>     install.packages(c("Design","Hmisc","lmtest","car","rgl","effects"))
> 
>     well, you get the idea. I want to add in more packages, of course. Can
>     I ask what might be the best way to package this?
> 
> You can add scripts to the %post macro section.

...etc...

Erm, but would you really want the result of installing an RPM to
depend on the install date and the previous configuration of the
system?

I can appreciate Paul's desire to automate, but when designing an RPM,
you also have to consider that you'd be doing things that the user
may not even know what mean. That sort of thing easily becomes a
support nightmare. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rolf at math.unb.ca  Mon May 24 17:20:12 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 24 May 2004 12:20:12 -0300 (ADT)
Subject: [R] Null model for arima.sim().
Message-ID: <200405241520.i4OFKC4h010733@erdos.math.unb.ca>


In some time series simulations I'm doing, I occasionally want the
model to be ``white noise'', i.e. no model at all.  I thought it
would be nice if I could fit this into the arima.sim() context,
without making an exceptional case.  I.e. one ***could*** do
something to the effect

	if(length(model)==0) x <- rnorm(n) else x <- arima.sim(model,n)

but it would be more suave if one could just use arima.sim() all the
time.

Experimenting I found that arima.sim() accepts an empty list as the
model, e.g.

	x <- arima.sim(list(),100)

and the result appears to be white noise.  There are a couple of
funnies, but.  One is that the resulting x is of length 99, rather
than 100.  The other is that if I do

	set.seed(42)
	x <- arima.sim(list(),101)
	set.seed(42)
	y <- rnorm(100)

the results are, modulo the order in which they appear, virtually
identical.  But not ***quite*** identical!  If I do
``sort(x)-sort(y)'' I get  zeroes (to 9 decimal places) everywhere,
except for entries 86 to 90, which are

    [86] -0.013709324 -0.087867933 -0.002327022 -0.015243692 -0.050845101

Perhaps arima.sim() is not really intended to accept an empty list
as a model, and the fact that I'm getting something like the output
of rnorm() by feeding it an empty list is just serendipity.  But
it would seem that there may be something subtle going on here.
Any ideas?

				cheers,

					Rolf Turner
					rolf at math.unb.ca

P. S.:
 > version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    9.0
year     2004
month    04
day      12
language R



From p.dalgaard at biostat.ku.dk  Mon May 24 17:18:52 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 May 2004 17:18:52 +0200
Subject: [R] Re: Windows versus Unix packages in CRAN ...
In-Reply-To: <tdlua01flkn1hjgq1up163rnbp10vdg548@4ax.com>
References: <200405211202.i4LC2F49003939@erdos.math.unb.ca>
	<20040521134118.GC853@localhost>
	<tdlua01flkn1hjgq1up163rnbp10vdg548@4ax.com>
Message-ID: <x2y8nhx38j.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch at pair.com> writes:

> On Fri, 21 May 2004 15:41:18 +0200, Tamas Papp <tpapp at axelero.hu>
> wrote:
> 
> >You are probably right in saying that they _could_ have done better,
> >but I would not use "should" in this context.  AFAIK the package is
> >free (as in beer) software, which means that you are not paying for
> >it.  The maintainers probably do not need a Linux version (yet), so it
> >was not easy to use it under Linux.  Feel free to contribute.  
> 
> Yes, indeed!  

Well, yes and no. Yes, people should feel free to help out with the
maintenance, but no, it is not reasonable to leave cross-platform
issues unaddressed.

Go look on Statlib and I'm sure you'll find code that built and ran
with HP-UX Fortran vintage 1992 or so, and got submitted with exactly
that sentiment: "It works for me, it's yours for free, but you have to
do the work." Of course, not even the original author would know how
to make it work again by now. This kind of "bitrot" is what CRAN and
all of its red tape was designed to avoid.

Whereas we cannot reasonably require people to test code on platforms
that they haven't got, we can and should require them to adhere to
reasonable standards and test procedures (which, mind you, other
people have invested a serious amount of time in working out).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From macq at llnl.gov  Mon May 24 17:25:14 2004
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 24 May 2004 08:25:14 -0700
Subject: [R] as.matrix.data.frame() in R 1.9.0 converts to character when it
 should (?) convert to numeric
Message-ID: <p06002000bcd7b9e6ab13@[128.115.153.6]>

Conversion of a data frame to a matrix using as.matrix() when a 
column of the data frame is POSIXt and all other columns are numeric 
has changed in R 1.9.0 from R 1.8.1. The new behavior issues a 
warning message and converts to a character matrix. In R 1.8.1, such 
an object was converted to a numeric matrix.

Here is an example.

#### R 1.9.0 ####
>  foo <- data.frame( x=1:3,dt=ISOdatetime(2003,1,1:3,0,0,0))

>  as.matrix(foo)
   x   dt         
1 "1" "2003-01-01"
2 "2" "2003-01-02"
3 "3" "2003-01-03"
Warning message:
longer object length
         is not a multiple of shorter object length in: cl == 
c("Date", "POSIXct", "POSIXlt")

>  version
          _                  
platform sparc-sun-solaris2.8
arch     sparc              
os       solaris2.8         
system   sparc, solaris2.8  
status   Patched            
major    1                  
minor    9.0                
year     2004               
month    04                 
day      30                 
language R                  
>


### R 1.8.1 ####
>  foo <- data.frame( x=1:3,dt=ISOdatetime(2003,1,1:3,0,0,0))
>  foo
   x         dt
1 1 2003-01-01
2 2 2003-01-02
3 3 2003-01-03

>  as.matrix(foo)
   x         dt
1 1 1041408000
2 2 1041494400
3 3 1041580800

>  version
          _                  
platform sparc-sun-solaris2.8
arch     sparc              
os       solaris2.8         
system   sparc, solaris2.8  
status   Patched            
major    1                  
minor    8.1                
year     2003               
month    12                 
day      03                 
language R                  


####
In both versions:
>  class(foo$dt)
[1] "POSIXt"  "POSIXct"

####
In R 1.8.1, as.matrix.data.frame() has these lines:
         if (length(levels(xj)) > 0 || !(is.numeric(xj) || is.complex(xj)) ||
             (!is.null(cl <- attr(xj, "class")) && any(cl == c("POSIXct",
                 "POSIXlt"))))

####
In R 1.9.0 there is instead
         if (length(levels(xj)) > 0 || !(is.numeric(xj) || is.complex(xj)) ||
             (!is.null(cl <- attr(xj, "class")) && any(cl == c("Date",
                 "POSIXct", "POSIXlt"))))

And that, I think, explains the warning message.

####
 From ?as.matrix() in R 1.9.0:

      'as.matrix' is a generic function. The method for data frames will
      convert any non-numeric/complex column into a character vector
      using 'format' and so return a character matrix, except that
      all-logical data frames will be coerced to a logical matrix.

The POSIXt element is numeric, and so should be converted to numeric
>  is.numeric(foo$dt)
[1] TRUE
>

####
I think this might qualify for bug status, either in and of itself or 
relative to documentation. But I'm not, as the posting guide says, 
"completely and utterly sure". So I'm posting to r-help first...I 
will send a bug report if an R-core member asks me to.

Thanks
-Don
-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From tlumley at u.washington.edu  Mon May 24 17:32:31 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 24 May 2004 08:32:31 -0700 (PDT)
Subject: [R] Re: Windows versus Unix packages in CRAN ...
In-Reply-To: <x2y8nhx38j.fsf@biostat.ku.dk>
References: <200405211202.i4LC2F49003939@erdos.math.unb.ca>
	<20040521134118.GC853@localhost>
	<tdlua01flkn1hjgq1up163rnbp10vdg548@4ax.com>
	<x2y8nhx38j.fsf@biostat.ku.dk>
Message-ID: <Pine.A41.4.58.0405240830210.16508@homer07.u.washington.edu>

On Mon, 24 May 2004, Peter Dalgaard wrote:
>
> Whereas we cannot reasonably require people to test code on platforms
> that they haven't got, we can and should require them to adhere to
> reasonable standards and test procedures (which, mind you, other
> people have invested a serious amount of time in working out).
>

Well, yes, for CRAN.  That's presumably one reason why the packages in
question aren't on CRAN.

	-thomas



From tlumley at u.washington.edu  Mon May 24 17:42:51 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 24 May 2004 08:42:51 -0700 (PDT)
Subject: [R] Stopping the process after a certain time
In-Reply-To: <Pine.GSO.4.56.0405240731560.14554@cyclone.csrv.uidaho.edu>
References: <Pine.GSO.4.56.0405240731560.14554@cyclone.csrv.uidaho.edu>
Message-ID: <Pine.A41.4.58.0405240841170.16508@homer07.u.washington.edu>

On Mon, 24 May 2004, Andrew Robinson wrote:

> Greetings R-community,
>
> I'm running simulations within R that I wrote in C.  The simulations
> require fitting that occasionally fails to finish.  I was wondering if
> there is any kind of tool for process control in R, such that after e.g.
> 15 minutes I could kill the process, record the state for post-hoc
> analysis, and move to the next simulation?
>
> I'm running FreeBSD and could almost surely do something in Perl but I'd
> rather stay inside R if possible.
>

As one component of this, if you send an R process SIGUSR1 it will quit
and save .RData (approximately the equivalent of CTRL-C, q("yes")).


	-thomas



From p.dalgaard at biostat.ku.dk  Mon May 24 17:40:48 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 May 2004 17:40:48 +0200
Subject: [R] Month names
In-Reply-To: <16562.2602.466113.303535@gargle.gargle.HOWL>
References: <0ABD88905D18E347874E0FB71C0B29E90179EB20@exdkba022.novo.dk>
	<40B208D1.3010100@jhsph.edu>
	<16562.2602.466113.303535@gargle.gargle.HOWL>
Message-ID: <x2u0y5x27z.fsf@biostat.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> >>>>> "Roger" == Roger D Peng <rpeng at jhsph.edu>
> >>>>>     on Mon, 24 May 2004 10:38:09 -0400 writes:
> 
>     Roger> How about `month.name'?
> 
> English only.
> 
> Note that he got the names in Danish (I think)
> Martin

Yep. Notice, however, that even with Brian's solution, you do need to
set the locale first:

> format(ISOdate(2004,1:12,1),"%B")
 [1] "January"   "February"  "March"     "April"     "May"       "June"
 [7] "July"      "August"    "September" "October"   "November"  "December"
> Sys.setlocale("LC_TIME","da_DK") ;format(ISOdate(2004,1:12,1),"%B")
[1] "da_DK"
 [1] "januar"    "februar"   "marts"     "april"     "maj"       "juni"
 [7] "juli"      "august"    "september" "oktober"   "november"  "december"


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Mon May 24 18:02:21 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 May 2004 17:02:21 +0100 (BST)
Subject: [R] as.matrix.data.frame() in R 1.9.0 converts to character when
	it should (?) convert to numeric
In-Reply-To: <p06002000bcd7b9e6ab13@[128.115.153.6]>
Message-ID: <Pine.LNX.4.44.0405241700010.4717-100000@gannet.stats>

I don't think a POSIXt element *is* numeric (that's a basic atomic
vector), so the new behaviour seems right to me.  The Warning is wrong,
though, and will be fixed.

On Mon, 24 May 2004, Don MacQueen wrote:

> Conversion of a data frame to a matrix using as.matrix() when a 
> column of the data frame is POSIXt and all other columns are numeric 
> has changed in R 1.9.0 from R 1.8.1. The new behavior issues a 
> warning message and converts to a character matrix. In R 1.8.1, such 
> an object was converted to a numeric matrix.
> 
> Here is an example.
> 
> #### R 1.9.0 ####
> >  foo <- data.frame( x=1:3,dt=ISOdatetime(2003,1,1:3,0,0,0))
> 
> >  as.matrix(foo)
>    x   dt         
> 1 "1" "2003-01-01"
> 2 "2" "2003-01-02"
> 3 "3" "2003-01-03"
> Warning message:
> longer object length
>          is not a multiple of shorter object length in: cl == 
> c("Date", "POSIXct", "POSIXlt")
> 
> >  version
>           _                  
> platform sparc-sun-solaris2.8
> arch     sparc              
> os       solaris2.8         
> system   sparc, solaris2.8  
> status   Patched            
> major    1                  
> minor    9.0                
> year     2004               
> month    04                 
> day      30                 
> language R                  
> >
> 
> 
> ### R 1.8.1 ####
> >  foo <- data.frame( x=1:3,dt=ISOdatetime(2003,1,1:3,0,0,0))
> >  foo
>    x         dt
> 1 1 2003-01-01
> 2 2 2003-01-02
> 3 3 2003-01-03
> 
> >  as.matrix(foo)
>    x         dt
> 1 1 1041408000
> 2 2 1041494400
> 3 3 1041580800
> 
> >  version
>           _                  
> platform sparc-sun-solaris2.8
> arch     sparc              
> os       solaris2.8         
> system   sparc, solaris2.8  
> status   Patched            
> major    1                  
> minor    8.1                
> year     2003               
> month    12                 
> day      03                 
> language R                  
> 
> 
> ####
> In both versions:
> >  class(foo$dt)
> [1] "POSIXt"  "POSIXct"
> 
> ####
> In R 1.8.1, as.matrix.data.frame() has these lines:
>          if (length(levels(xj)) > 0 || !(is.numeric(xj) || is.complex(xj)) ||
>              (!is.null(cl <- attr(xj, "class")) && any(cl == c("POSIXct",
>                  "POSIXlt"))))
> 
> ####
> In R 1.9.0 there is instead
>          if (length(levels(xj)) > 0 || !(is.numeric(xj) || is.complex(xj)) ||
>              (!is.null(cl <- attr(xj, "class")) && any(cl == c("Date",
>                  "POSIXct", "POSIXlt"))))
> 
> And that, I think, explains the warning message.
> 
> ####
>  From ?as.matrix() in R 1.9.0:
> 
>       'as.matrix' is a generic function. The method for data frames will
>       convert any non-numeric/complex column into a character vector
>       using 'format' and so return a character matrix, except that
>       all-logical data frames will be coerced to a logical matrix.
> 
> The POSIXt element is numeric, and so should be converted to numeric
> >  is.numeric(foo$dt)
> [1] TRUE
> >
> 
> ####
> I think this might qualify for bug status, either in and of itself or 
> relative to documentation. But I'm not, as the posting guide says, 
> "completely and utterly sure". So I'm posting to r-help first...I 
> will send a bug report if an R-core member asks me to.
> 
> Thanks
> -Don
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mmiller3 at iupui.edu  Mon May 24 18:04:18 2004
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Mon, 24 May 2004 11:04:18 -0500
Subject: [R] R 1.8.1 - 1.9.0 incompatability: Underscore in
	syntactically valid names
In-Reply-To: <x2pt8x98hz.fsf@biostat.ku.dk> (Peter Dalgaard's message of "21
	May 2004 16:10:00 +0200")
References: <874qqbrs95.fsf@lumen.indyrad.iupui.edu>
	<x2pt8x98hz.fsf@biostat.ku.dk>
Message-ID: <87d64tq0al.fsf@lumen.indyrad.iupui.edu>

>>>>> "Peter" == Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

    > Gah! I could swear we discussed that particular issue
    > leading up to 1.9.x and had plans for a compatibility
    > option.

    > You might file a bug report at least for the docs, since
    > the example is clearly wrong...

Done.  

I tried to write some version dependencies into a sample code,
but I'm stumped by the fact that _ is not allowed before 1.9.0.
For example, suppose I have a data file, example.dat, like this: 

a b x   some_factor
1 1 0.4 orange
2 1 0.3 blue
1 1 0.2 dog
2 1 0.1 orange
1 2 0.4 blue
2 2 0.3 dog
1 2 0.2 orange
2 2 0.1 blue

To read and use this in a version independent way, I've tried this:

df <- read.table('example.dat',header=T)
if ( version['minor'] == "9.0" ) {
  plot(x ~ some_factor, data=df)
} else {
  plot(x ~ some.factor, data=df)
}


This fails in R 1.8.1, because some_factor throws a syntax error:

  > df <- read.table('example.dat',header=T)
  > if ( version['minor'] == "9.0" ) {
  + if ( version['minor'] == "9.0" ) {
  +   plot(x ~ some_factor, data=df)
  Error: syntax error
  > 

Ick.  Is there a known idiom for handling this sort of version
dependency in R?  I'm going to avoid R 1.9.x for now, and I
encourage any authors of contributing packages to do their best
to maintain backwards compatibility for those of us who cannot
make the switch quickly.

Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine



From andrewr at uidaho.edu  Mon May 24 18:04:39 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Mon, 24 May 2004 09:04:39 -0700 (PDT)
Subject: [R] Stopping the process after a certain time
In-Reply-To: <Pine.A41.4.58.0405240841170.16508@homer07.u.washington.edu>
References: <Pine.GSO.4.56.0405240731560.14554@cyclone.csrv.uidaho.edu>
	<Pine.A41.4.58.0405240841170.16508@homer07.u.washington.edu>
Message-ID: <Pine.GSO.4.56.0405240858110.14554@cyclone.csrv.uidaho.edu>

Thomas,

that's very interesting - thanks!  That will be helpful.

Andrew

On Mon, 24 May 2004, Thomas Lumley wrote:

> On Mon, 24 May 2004, Andrew Robinson wrote:
>
> > Greetings R-community,
> >
> > I'm running simulations within R that I wrote in C.  The simulations
> > require fitting that occasionally fails to finish.  I was wondering if
> > there is any kind of tool for process control in R, such that after e.g.
> > 15 minutes I could kill the process, record the state for post-hoc
> > analysis, and move to the next simulation?
> >
> > I'm running FreeBSD and could almost surely do something in Perl but I'd
> > rather stay inside R if possible.
> >
>
> As one component of this, if you send an R process SIGUSR1 it will quit
> and save .RData (approximately the equivalent of CTRL-C, q("yes")).
>
>
> 	-thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Andrew Robinson			     Ph: 208 885 7115
Department of Forest Resources	     Fa: 208 885 6226
University of Idaho		     E : andrewr at uidaho.edu
PO Box 441133			     W : http://www.uidaho.edu/~andrewr
Moscow ID 83843			     Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From ripley at stats.ox.ac.uk  Mon May 24 18:12:41 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 May 2004 17:12:41 +0100 (BST)
Subject: [R] Month names
In-Reply-To: <x2u0y5x27z.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0405241708310.5031-100000@gannet.stats>

As far as I know the original solution uses the current locale, and mine 
is just a much-simplified version of the same underlying call.

On 24 May 2004, Peter Dalgaard wrote:

> Martin Maechler <maechler at stat.math.ethz.ch> writes:
> 
> > >>>>> "Roger" == Roger D Peng <rpeng at jhsph.edu>
> > >>>>>     on Mon, 24 May 2004 10:38:09 -0400 writes:
> > 
> >     Roger> How about `month.name'?
> > 
> > English only.
> > 
> > Note that he got the names in Danish (I think)
> > Martin
> 
> Yep. Notice, however, that even with Brian's solution, you do need to
> set the locale first:

Just as you did with the original code, which gives English names on my 
machine.

> > format(ISOdate(2004,1:12,1),"%B")
>  [1] "January"   "February"  "March"     "April"     "May"       "June"
>  [7] "July"      "August"    "September" "October"   "November"  "December"
> > Sys.setlocale("LC_TIME","da_DK") ;format(ISOdate(2004,1:12,1),"%B")
> [1] "da_DK"
>  [1] "januar"    "februar"   "marts"     "april"     "maj"       "juni"
>  [7] "juli"      "august"    "september" "oktober"   "november"  "december"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May 24 19:18:05 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 May 2004 18:18:05 +0100 (BST)
Subject: [R] Null model for arima.sim().
In-Reply-To: <200405241520.i4OFKC4h010733@erdos.math.unb.ca>
Message-ID: <Pine.LNX.4.44.0405241816170.1986-100000@gannet.stats>

It's not really intended to work, but a small change makes it work.
(1:nstart is wrong for a null model.)

list(ar=numeric(0), ma=numeric(0)) might be a little clearer.


On Mon, 24 May 2004, Rolf Turner wrote:

> 
> In some time series simulations I'm doing, I occasionally want the
> model to be ``white noise'', i.e. no model at all.  I thought it
> would be nice if I could fit this into the arima.sim() context,
> without making an exceptional case.  I.e. one ***could*** do
> something to the effect
> 
> 	if(length(model)==0) x <- rnorm(n) else x <- arima.sim(model,n)
> 
> but it would be more suave if one could just use arima.sim() all the
> time.
> 
> Experimenting I found that arima.sim() accepts an empty list as the
> model, e.g.
> 
> 	x <- arima.sim(list(),100)
> 
> and the result appears to be white noise.  There are a couple of
> funnies, but.  One is that the resulting x is of length 99, rather
> than 100.  The other is that if I do
> 
> 	set.seed(42)
> 	x <- arima.sim(list(),101)
> 	set.seed(42)
> 	y <- rnorm(100)
> 
> the results are, modulo the order in which they appear, virtually
> identical.  But not ***quite*** identical!  If I do
> ``sort(x)-sort(y)'' I get  zeroes (to 9 decimal places) everywhere,
> except for entries 86 to 90, which are
> 
>     [86] -0.013709324 -0.087867933 -0.002327022 -0.015243692 -0.050845101
> 
> Perhaps arima.sim() is not really intended to accept an empty list
> as a model, and the fact that I'm getting something like the output
> of rnorm() by feeding it an empty list is just serendipity.  But
> it would seem that there may be something subtle going on here.
> Any ideas?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rafael.najmanovich at ebi.ac.uk  Mon May 24 20:06:59 2004
From: rafael.najmanovich at ebi.ac.uk (Rafael Najmanovich)
Date: Mon, 24 May 2004 19:06:59 +0100
Subject: [R] Mac OS X jpg
Message-ID: <266D509C-ADAD-11D8-9569-000D93C28564@ebi.ac.uk>

	Hi,
	I am using R 1.9.0 (2004-04-12) for Mac OS X.	I am having trouble 
printing to a jpg file. This only happens when I use R in batch (with 
the BATCH option) mode. If I launch the R GUI or the command line 
version and run the script from either, I have no problems. Only when 
running in BATCH mode I get a file with the same name as my script 
where I find the following message at the end:

> Error in jpeg(filename = file, width = 1500, height = 2000, pointsize 
> = 12,  :
>         R_X11 module cannot be loaded
> In addition: Warning message:
> X11 module is not available under this GUI
> Execution halted

	When I run the same script with the only difference that it prints to 
a postscript file instead, all works fine.

	Any  suggestions as to what could the problem be?

	thank you in advance,


Dr. Rafael Najmanovich
European Bioinformatics Institute
Wellcome Trust Genome Campus
Cambridge CB10 1SD
United Kingdom

rafael.najmanovich at ebi.ac.uk - www.ebi.ac.uk/~rafi
+44-1223-492599 (voice) +44-7786-968257(mobile) +44-1223-494468 (fax)



From ypeng at math.mun.ca  Mon May 24 20:46:49 2004
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Mon, 24 May 2004 16:16:49 -0230
Subject: [R] Cannot call R's ISNAN() from a C code in >1.7 versions.
In-Reply-To: <Pine.LNX.4.44.0405240729290.14723-100000@gannet.stats>
References: <Pine.LNX.4.44.0405240729290.14723-100000@gannet.stats>
Message-ID: <40B24319.5070906@math.mun.ca>

Prof Brian Ripley wrote:
> First, there are no versions 1.7, 1.8 and 1.9.

Sorry for my misuse of the version numbers.

> Was your version of R compiled against MSVC++ 6.0?  The binary on CRAN was
> not, and binaries for different versions of R were compiled with different
> versions of MinGW.  The entry point isnan is part of the statically linked
> runtime on modern MinGW.

I used the binary on CRAN.

> MSVC++ 6.0 does supply _isnan (as it really should as it is part of the
> C99 ISO standard), and you need to link against it appropriately.  Hint:
> it may have an extra underline, since it seems it is known to C as _isnan.
> You may need to add
> 
> #undef ISNAN
> #define ISNAN(x) _isnan(x)

Many thanks for this suggestion. It works, as always. The extra
underline is required.

> We don't support adding extensions to R using a different compiler to the 
> one used to build R.  Changes already made for future releases of R will 
> make this less likely to work in R 2.0.x.

I wish that the R API entry points documented in "Writing R Extensions"
be supported in the future versions of R, because it will make programs
built with R more portable than directly using compiler-specific
functions, such as testing and generating the IEEE 754 special values.
The existing entry points have saved me trouble to chase these values
whenever I moved to an environment with a different compiler.

Thank you Brian for your help.
Paul.



From ripley at stats.ox.ac.uk  Mon May 24 20:48:16 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 May 2004 19:48:16 +0100 (BST)
Subject: [R] Mac OS X jpg
In-Reply-To: <266D509C-ADAD-11D8-9569-000D93C28564@ebi.ac.uk>
Message-ID: <Pine.LNX.4.44.0405241943250.31140-100000@gannet.stats>

I think the message is very clear.  Try ?BATCH

     Using 'R CMD BATCH' sets the GUI to '"none"', so none of 'x11',
     'jpeg' and 'png' are available.

and ?jpeg

     R can be compiled without support for either or both of these
     devices: this will be reported if you attempt to use them on a
     system where they are not supported.  They will not be available
     if R has been started with '--gui=none' (and will give a different
     error message), and they may not be usable unless the X11 display
     is available to the owner of the R process.

The bitmap() device will work under R CMD BATCH.

On Mon, 24 May 2004, Rafael Najmanovich wrote:

> 	I am using R 1.9.0 (2004-04-12) for Mac OS X.	I am having trouble 
> printing to a jpg file. This only happens when I use R in batch (with 
> the BATCH option) mode. If I launch the R GUI or the command line 
> version and run the script from either, I have no problems. Only when 
> running in BATCH mode I get a file with the same name as my script 
> where I find the following message at the end:
> 
> > Error in jpeg(filename = file, width = 1500, height = 2000, pointsize 
> > = 12,  :
> >         R_X11 module cannot be loaded
> > In addition: Warning message:
> > X11 module is not available under this GUI
> > Execution halted
> 
> 	When I run the same script with the only difference that it prints to 
> a postscript file instead, all works fine.
> 
> 	Any  suggestions as to what could the problem be?

Failure to consult the documentation, I believe.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May 24 21:07:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 May 2004 20:07:01 +0100 (BST)
Subject: [R] Cannot call R's ISNAN() from a C code in >1.7 versions.
In-Reply-To: <40B24319.5070906@math.mun.ca>
Message-ID: <Pine.LNX.4.44.0405241948440.31140-100000@gannet.stats>

On Mon, 24 May 2004, Paul Y. Peng wrote:

> Prof Brian Ripley wrote:
> > First, there are no versions 1.7, 1.8 and 1.9.
> 
> Sorry for my misuse of the version numbers.
> 
> > Was your version of R compiled against MSVC++ 6.0?  The binary on CRAN was
> > not, and binaries for different versions of R were compiled with different
> > versions of MinGW.  The entry point isnan is part of the statically linked
> > runtime on modern MinGW.
> 
> I used the binary on CRAN.

Then please use the compilers described in readme.packages which match it.

> > MSVC++ 6.0 does supply _isnan (as it really should as it is part of the
> > C99 ISO standard), and you need to link against it appropriately.  Hint:
> > it may have an extra underline, since it seems it is known to C as _isnan.
> > You may need to add
> > 
> > #undef ISNAN
> > #define ISNAN(x) _isnan(x)
> 
> Many thanks for this suggestion. It works, as always. The extra
> underline is required.
> 
> > We don't support adding extensions to R using a different compiler to the 
> > one used to build R.  Changes already made for future releases of R will 
> > make this less likely to work in R 2.0.x.
> 
> I wish that the R API entry points documented in "Writing R Extensions"
> be supported in the future versions of R, because it will make programs
> built with R more portable than directly using compiler-specific
> functions, such as testing and generating the IEEE 754 special values.
> The existing entry points have saved me trouble to chase these values
> whenever I moved to an environment with a different compiler.

Who said they would not supported?  What I said is that using a different
compilers to compile different parts of R is not supported (and never has
been).  And that is even less likely to work in future releases.  All we
guarantee is that ISNAN and R_FINITE produce calls to functions that work
under the system used to configure R.  As on Windows R_FINITE now produces
a call to a MinGW macro, that is not going to work under VC++ 6.

We are not talking about using `compiler-specific functions' here, like
_isnan.  What R core is doing is using *standard* C99 functions where
available, and a problem with VC++ 6.0 is that it is far from compliant
with IEC60559 aka IEEE754.  Given that the recommended compiler is freely 
available, it is unreasonable to expect any support for less capable 
compilers.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ferri.leberl at gmx.at  Mon May 24 22:05:23 2004
From: ferri.leberl at gmx.at (Mag. Ferri Leberl)
Date: Mon, 24 May 2004 22:05:23 +0200
Subject: [R] adress the current index
Message-ID: <200405242205.23750.ferri.leberl@gmx.at>

How can I adress the current index of a vector?

I want to work with time series and therefore give the n-th element of a 
vector some value dependent on the value of the n-1th element.

Thank you in advance.



From maechler at stat.math.ethz.ch  Mon May 24 22:16:15 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 24 May 2004 22:16:15 +0200
Subject: [R] what does "numeric" mean? {was ... as.matrix.data.frame() ...}
In-Reply-To: <Pine.LNX.4.44.0405241700010.4717-100000@gannet.stats>
References: <p06002000bcd7b9e6ab13@[128.115.153.6]>
	<Pine.LNX.4.44.0405241700010.4717-100000@gannet.stats>
Message-ID: <16562.22543.823840.710442@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Mon, 24 May 2004 17:02:21 +0100 (BST) writes:

    BDR> I don't think a POSIXt element *is* numeric (that's a
    BDR> basic atomic vector), 

well, yes, in some strict sense, but at least

 > is.atomic( ISOdatetime(2003,1,1:3,0,0,0))
 [1] TRUE

    BDR> so the new behaviour seems right to me.  The Warning is
    BDR> wrong, though, and will be fixed.

Further note that   data.matrix(.) still does convert to
numeric, and  AFAIK all good books on S / R  tell you to rather
use data.matrix(df) in situations you want a numeric matrix from a
data frame df.

    BDR> On Mon, 24 May 2004, Don MacQueen wrote:

    >> Conversion of a data frame to a matrix using as.matrix() when a 
    >> column of the data frame is POSIXt and all other columns are numeric 
    >> has changed in R 1.9.0 from R 1.8.1. The new behavior issues a 
    >> warning message and converts to a character matrix. In R 1.8.1, such 
    >> an object was converted to a numeric matrix.
    >> 
    >> Here is an example.
    >> 
    >> #### R 1.9.0 ####
    >> > foo <- data.frame( x=1:3,dt=ISOdatetime(2003,1,1:3,0,0,0))
    >> 
    >> > as.matrix(foo)
    >> x   dt         
    >> 1 "1" "2003-01-01"
    >> 2 "2" "2003-01-02"
    >> 3 "3" "2003-01-03"
    >> Warning message:
    >> longer object length is not a multiple of shorter object length in: 
    >> cl == c("Date", "POSIXct", "POSIXlt")


  <................>


    >> From ?as.matrix() in R 1.9.0:
    >> 
    >> 'as.matrix' is a generic function. The method for data frames will
    >> convert any non-numeric/complex column into a character vector
    >> using 'format' and so return a character matrix, except that
    >> all-logical data frames will be coerced to a logical matrix.
    >> 
    >> The POSIXt element is numeric, and so should be converted to numeric
    >> >  is.numeric(foo$dt)
    >> [1] TRUE

that is a point, particularly together with the above
is.atomic(foo$dt)  |-> TRUE

    >> ####
    >> I think this might qualify for bug status, either in and of itself or 
    >> relative to documentation. But I'm not, as the posting guide says, 
    >> "completely and utterly sure". So I'm posting to r-help first...I 
    >> will send a bug report if an R-core member asks me to.
    >> 
    >> Thanks
    >> -Don

Note that with a factor (instead of POSIX*t),
things are similar

 > str(ffoo <- data.frame(x=1:3, f=gl(3,1)))
 `data.frame':	3 obs. of  2 variables:
  $ x: int  1 2 3
  $ f: Factor w/ 3 levels "1","2","3": 1 2 3
 > as.matrix(ffoo)
   x   f  
 1 "1" "1"
 2 "2" "2"
 3 "3" "3"
 > data.matrix(ffoo)
   x f
 1 1 1
 2 2 2
 3 3 3

but in that case,

  > is.numeric(ffoo$f)
  [1] FALSE

hence, all according to the docs

------

Maybe we should either be more specific in  help(as.matrix)
{and more other places ?} about what "numeric" means there,
or consider -- and this may well be unfeasible because it
potentially breaks current code -- to redefine
'is.numeric(.)' to be more restrictive:

e.g.,

   if (is.object(x))  ===>   ! is.numeric(x) 

?

Martin



From cguevel at deis.gov.ar  Mon May 24 22:18:54 2004
From: cguevel at deis.gov.ar (Carlos Guevel)
Date: Mon, 24 May 2004 17:18:54 -0300
Subject: [R] barplot
Message-ID: <3AD1AED00301DA4ABD29E80702FB6A8306D910@email.promin>

I??ve tried version 1.9.0 barplot  with these (and others) example from  the
help page:

tN <- table(Ni <- rpois(100, lambda=5))
r <- barplot(tN, col='gray') 
I get :


 <<...OLE_Obj...>> 
Same example with version 1.8.1 gives the following result:


 <<...OLE_Obj...>> 

What is wrong with v.1.9.0?

Thanks,

Carlos Guevel



From djogo at lbc.ludwig.org.br  Mon May 24 22:17:14 2004
From: djogo at lbc.ludwig.org.br (Diogo FC Patrao)
Date: Mon, 24 May 2004 17:17:14 -0300
Subject: [R] identify() in script
Message-ID: <1085429834.4519.12.camel@hansolo>

hallo,

I want a script of mine to run identify(), and possibly switch to
interactive mode at some point. Is it possible?

Thanks in advance



From dimasmm at visgraf.impa.br  Mon May 24 23:19:32 2004
From: dimasmm at visgraf.impa.br (Dimas Martnez Morera)
Date: Mon, 24 May 2004 18:19:32 -0300
Subject: [R] Applications of the Distance from a Point to a Curve
Message-ID: <200405241819.32532.dimasmm@visgraf.impa.br>

I would like to know if anyone knows about (real) situations where it is 
necessary to compute the euclidean distance from a point to a curve (or even 
the point where it is reached), you may not assume that the point is very 
close to the curve (unlike the usual fitting problems).
I have special interest in applications to phisics.

Thanks in advance,

Dimas



From sundar.dorai-raj at PDF.COM  Mon May 24 22:34:34 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Mon, 24 May 2004 15:34:34 -0500
Subject: [R] barplot
In-Reply-To: <3AD1AED00301DA4ABD29E80702FB6A8306D910@email.promin>
References: <3AD1AED00301DA4ABD29E80702FB6A8306D910@email.promin>
Message-ID: <40B25C5A.5040807@pdf.com>



Carlos Guevel wrote:
> I??ve tried version 1.9.0 barplot  with these (and others) example from  the
> help page:
> 
> tN <- table(Ni <- rpois(100, lambda=5))
> r <- barplot(tN, col='gray') 
> I get :
> 
> 
>  <<...OLE_Obj...>> 
> Same example with version 1.8.1 gives the following result:
> 
> 
>  <<...OLE_Obj...>> 
> 
> What is wrong with v.1.9.0?
> 
> Thanks,
> 
> Carlos Guevel
> 

This has been reported a while back:

http://r-bugs.biostat.ku.dk/cgi-bin/R/Graphics?id=6777;expression=barplot;user=guest

which also suggests a workaround.

tN <- table(Ni <- rpois(100, lambda=5))
r <- barplot(as.vector(tN), col='gray')

Alternatively, barplot2 in the gregmisc package should also work.

library(gregmisc)
tN <- table(Ni <- rpois(100, lambda=5))
r <- barplot2(tN, col='gray')

--sundar



From mark.threefoot at amd.com  Mon May 24 22:36:55 2004
From: mark.threefoot at amd.com (mark.threefoot@amd.com)
Date: Mon, 24 May 2004 13:36:55 -0700
Subject: [R] ROracle on RHEL 3 x86_64
Message-ID: <A6D472EC410FF84E8BE573FD654BAC43398105@CAEXMTA9>


Hello,

I am trying to configure my system with ROracle.  I am running RHEL 3 AS x86_64.  I have the Oracle client 9.2.0.4 x86_64.  I have successfully compiled and run both R-1.8.1 and R-1.9.0 (tried ROracle on both installations).  I am using DBI 1.8 and ROracle 0.5-4.  I have used both the default Redhat installed gcc 3.2.3 and gcc 3.4.  I am able to compile ROracle successfully with the following command:

R CMD INSTALL --configure-args='--enable-extralibs="-lsqlplus"' ROracle_0.5-4.tar.gz

When I run R, I get a Segmentation fault after the dbConnect call:

> library('ROracle')
> ora <- Oracle()
> con <- dbConnect(ora, "username/password at database")
Segmentation fault (core dumped)

Has anyone run into this, or are running the same configuration?  Any help would be appreciated.

Thanks,
Mark Threefoot 
mark.threefoot at amd.com



From msby at mscc.huji.ac.il  Mon May 24 23:51:25 2004
From: msby at mscc.huji.ac.il (Benjamin Yakir)
Date: Mon, 24 May 2004 23:51:25 +0200
Subject: [R] installing R on Fedora Core 2 test 2
Message-ID: <001101c441d9$5b3846e0$1c00a8c0@Lily>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040524/642eee34/attachment.pl

From ripley at stats.ox.ac.uk  Mon May 24 23:02:29 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 May 2004 22:02:29 +0100 (BST)
Subject: [R] installing R on Fedora Core 2 test 2
In-Reply-To: <001101c441d9$5b3846e0$1c00a8c0@Lily>
Message-ID: <Pine.LNX.4.44.0405242159580.7907-100000@gannet.stats>

What was the failure?

For the sources, there is a bug in the X11 headers it ships.  Please use 
the R-patched tarball from ftp://ftp.stat.math.ethz.ch/Software/R/, which 
has a workaround.

On Mon, 24 May 2004, Benjamin Yakir wrote:

> I am new to Linux and just installed Fedora Core 2. Tried to install R
> from Fedora core 1 binaries and from the source files according to the
> manual but failed. Would appreciate any help.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From umalvarez at fata.unam.mx  Mon May 24 23:05:42 2004
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Mon, 24 May 2004 16:05:42 -0500 (CDT)
Subject: [R] installing R on Fedora Core 2 test 2
In-Reply-To: <001101c441d9$5b3846e0$1c00a8c0@Lily>
Message-ID: <Pine.LNX.4.44.0405241600020.30653-100000@athena.fata.unam.mx>

Hello:

Please give more info, how did you proceed?, when you install/upgrade 
Fedora what kind on instalation did you made? 

A few days ago I upgrade my computer from FC-1 to FC-2 (workstation). 
After that, I install the binaries (from CRAN) and everything went just 
fine.

On Mon, 24 May 2004, Benjamin Yakir wrote:

> I am new to Linux and just installed Fedora Core 2. Tried to install R from Fedora core 1 binaries and from the source files according to the manual but failed. Would appreciate any help.
> 
> Benny Yakir
> Department of Statistics
> The Hebrew University
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From paul_bivand at blueyonder.co.uk  Mon May 24 23:07:53 2004
From: paul_bivand at blueyonder.co.uk (Paul Bivand)
Date: Mon, 24 May 2004 22:07:53 +0100
Subject: [R] Tramo-seats
In-Reply-To: <4087DF45000A1F41@ims3e.cp.tin.it>
References: <4087DF45000A1F41@ims3e.cp.tin.it>
Message-ID: <200405242207.54050.paul_bivand@blueyonder.co.uk>

On Monday 24 May 2004 11:00, v.demartino2 at virgilio.it wrote:
> Working  - among other things- in the field of (short & long term)
> electricity forecast,  we are now using too many & too expensive pieces of
> licensed software: SAS, SPSS, EViews. This "sedimentation" is due to the
> fact that my predecessors in the past used different consultant companies
> to manage each procedure.
>
> Having attended the useR2004! Conference with the aim of assessing if R
> ALONE could "glue" all those fragmented and isolated procedures, I'm almost
> convinced now that YES it could do the job!
>
> Now - to start with - a first problem to solve:
>
> we have to comply with the Tramo-seats closed-source procedure
> (http://www.bde.es/informes/be/docs/dt0014e.pdf) to deal with seasonality
> of electricity monthly time-series, in line with the methodology officially
> adopted by our  National Bureau of Statistics.
>
> Searching in R-help mailing list I didn't find anything about a tramo-seats
> R version.
>
> Does anyone know of unofficial R translation of tramo-seats?
> OR What do you suggest?
>
> Vittorio
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Not an R response I'm afraid, but have you looked at Demetra 
http://forum.europa.eu.int/irc/dsis/eurosam/info/data/demetra.htm which 
appears to be an officially sponsored windows-only implementation of 
Tramo-seats and X-12 ARIMA. 

The licence is not clear from the website, but it looks free as in beer but 
probably not open source.

Paul Bivand



From keithc at rotellacapital.com  Mon May 24 23:15:16 2004
From: keithc at rotellacapital.com (Keith Campbell)
Date: Mon, 24 May 2004 14:15:16 -0700
Subject: [R] Seasonal ARIMA question - stat package (formerly ts)
Message-ID: <053B1BC31740FE46B5EC8369B953F5F7397F8D@XOC1VEXC002.xoc1.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040524/0d3bc9a2/attachment.pl

From edd at debian.org  Mon May 24 23:22:18 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 24 May 2004 16:22:18 -0500
Subject: [R] RQuantlib ?Windows Binary?
In-Reply-To: <20040521164818.48C04863B7@p3fed1.frb.org>
References: <20040521164818.48C04863B7@p3fed1.frb.org>
Message-ID: <20040524212217.GB31858@sonny.eddelbuettel.com>


Jason,

On Fri, May 21, 2004 at 11:48:16AM -0500, Jason.L.Higbee at stls.frb.org wrote:
> R:
> 
> Is there a reason why there isn't a Windows Binary version of RQuantlib on 
> CRAN?  Usually when there is no binary, I just source the source code, but

Yes, there is. 

On windows, QuantLib wants to be built with Visual C++ whereas R wants to be
built with MinGW.  When I first published RQuantLib, I thought it to be
impossible to be built on Windows ... only to receive an email from Tsvetan
Stoyanov who detailed how to build both under win2000.  I did try that at
one point an succeeded. The recipe is still on my page for RQuantLib at 

    http://dirk.eddelbuettel.com/code/rquantlib.html
    
The recipe may well need updating.  If you try it, would you mind sharing
your experience, maybe in a private email, so that I can update the page?

> this one appears to have various calls and methods and things like that so 
> I'm hesitant to do so.  I know there has been a big discussion on why 
> Rmetrics doesn't have source for unix/linux, but that isn't on CRAN. 
> Through that Rmetrics thread, I think I read that all CRAN packages have 
> source (except for one), but shouldn't all CRAN packages also have binary? 
>  Think they should.

Not that easy as Uwe mentioned.

Hope this helps,  Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From jasont at indigoindustrial.co.nz  Tue May 25 23:30:17 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 25 May 2004 09:30:17 -1200 (NZST)
Subject: [R] Metafiiles  into Word R 1.9.0
In-Reply-To: <LGECJJCANFBOOHCMGPJEKEENDDAA.Jesus.Frias@dit.ie>
References: <LGECJJCANFBOOHCMGPJEKEENDDAA.Jesus.Frias@dit.ie>
Message-ID: <37700.203.9.176.60.1085434217.squirrel@webmail.maxnet.co.nz>

> 	2.-The computer at work has Microsoft Windows 2000 (5.00.2195 Service
> Pack
> 2) and Word 2000 (9.0.4402 SR-1) I cannot copy-paste windows metafiles
> into
> Office applications in my computer at work. The resulting object is empty.
>

Is it genuinely empty, or can you see the graphs in print layout view, or
print preview?  I've seen that particular Word bug before.  It happens
with Visio drawings too (Visio is a M$ product).

Cheers

Jason



From MDavy at hortresearch.co.nz  Mon May 24 23:39:39 2004
From: MDavy at hortresearch.co.nz (Marcus Davy)
Date: Tue, 25 May 2004 09:39:39 +1200
Subject: [R] Accessing more than 2GB memory in Windows
Message-ID: <s0b31475.055@hrp3.palm.cri.nz>


Hi,
thanks to Prof Brian Ripley for clarifying this, I should have stated
that the FAQ link I provided 
was for R 1.9.0 for windows. 

A nice summary of the issue on 32 bit systems and physical RAM
limitations of (more recent) 
windows operating systems can be found at:

 http://www.michna.com/kb/WxMoreThan2GB.htm.

According to microsoft information the  /3GB switch in the Boot.ini is
available for the following 
operating systems;

Windows XP Professional
Windows Server 2003
Windows Server 2003, Enterprise Edition
Windows Server 2003, Datacenter Edition
Windows 2000 Advanced Server
Windows 2000 Datacenter Server
Windows NT Server 4.0, Enterprise Edition 


marcus


>>> Prof Brian Ripley <ripley at stats.ox.ac.uk> 22/05/2004 10:11:48 PM
>>>
R can.

R 1.8.1 cannot, but it is obselete.

On Thu, 20 May 2004, Marcus Davy wrote:

> I am also interested in the same topic, that is windows 32bit
> restriction to 4Gigs of virtual 
> address space partitioning into User and System space.
> For your reconfigured server 3:1 User to System space what does
> 
> memory.limit()
> 
> say is available?
> 
> For those interested a windows FAQ link on this subject is
> 
>
http://www.stats.ox.ac.uk/pub/R/rw-FAQ.html#There%20seems%20to%20be%20a%20limit%20on%20the%20memory%20it%20uses!


(and in the distribution, lonked from the menus). That explicitly says

  The information here applies only to recent versions of R for
Windows, 
  (1.9.0 or later); the current version is often called something like

  rw1090 (although not officially).

At least two users who were interested have reported success after 
following those instructions (during the pre-release testing phase).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk 
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/ 
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


______________________________________________________

The contents of this e-mail are privileged and/or confidenti...{{dropped}}



From dj at research.bell-labs.com  Mon May 24 23:44:58 2004
From: dj at research.bell-labs.com (David James)
Date: Mon, 24 May 2004 17:44:58 -0400
Subject: [R] RMySQL problem
In-Reply-To: <1085410580.27999.111.camel@gandalf.local>;
	from ernesto@ipimar.pt on Mon, May 24, 2004 at 03:56:20PM +0100
References: <1085410580.27999.111.camel@gandalf.local>
Message-ID: <20040524174457.A24945@jessie.research.bell-labs.com>

Hi,

The method for dbWriteTable() uses the MySQL bulk loading faciliy
"LOAD DATA LOCAL INFILE" to efficiently upload a file into the
server.  So you should be able to issue something like
  > sim.result <- big.simulation(...)
  > dbWriteTable(con, "table_name", sim.results, append = TRUE)
to append the rows in sim.results into the MySQL "table_name".

However, I should mention that the currently implementation
outputs the contents of the data.frame into a temporary file
using the function write.table(), which in the past could be
slow.

Hope this helps,

--
David

Ernesto Jardim wrote:
> Hi,
> 
> I'm using R 1.9.0 with RMySQL 0.5-4 and MySQL 3.23.55 on a suse 8.2 box.
> 
> I have a simulation study and (as usual for newbies in simulation, I
> guess) I have a lot of data that I want to store in MySQL. I want to
> write an R script that reads data from RData files and writes it to a
> MySQL database. 
> 
> I read some R documents (R Data Import/Export and DSC papers) but I'm
> finding differences between the documents and the packages (RMySQL and
> DBI). I don't find the methods to write data like "dbWriteTable"...
> 
> On the other hand I've tryied to build a sql statement to insert data
> but I'm stucked because of ... who knows, my ignorance probably. I want
> to take advantage of MySQl INSERT INTO statement that deals with several
> rows at once to insert a complete data.frame into a table. I've tryied
> to use "paste" to build the sql string but It works "by column" and I
> need it "by row" ...
> 
> The sql systax should be something like:
> 
> INSERT INTO TABLEA(COL1, COL2, COL3) VALUES
> 	(VAL11, VAL12, VAL13),
> 	(VAL21, VAL22, VAL23),
> 	...
> 	(VALN1, VALN2, VALN3);
> 
> and I have a data.frame with 3 columns corresponding to that table
> columns.
> 
> How can I do this ?
> 
> Thanks
> 
> EJ
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From msby at mscc.huji.ac.il  Tue May 25 00:24:56 2004
From: msby at mscc.huji.ac.il (Benjamin Yakir)
Date: Tue, 25 May 2004 01:24:56 +0300
Subject: [R] installing R on Fedora Core 2 test 2
In-Reply-To: <Pine.LNX.4.44.0405242159580.7907-100000@gannet.stats>
References: <Pine.LNX.4.44.0405242159580.7907-100000@gannet.stats>
Message-ID: <1085437496.2443.2.camel@localhost.localdomain>

Dear Prof Ripley

Thank you very much. Half the night is over but running the patch
worked.

Benny

On Tue, 2004-05-25 at 00:02, Prof Brian Ripley wrote:
> What was the failure?
> 
> For the sources, there is a bug in the X11 headers it ships.  Please use 
> the R-patched tarball from ftp://ftp.stat.math.ethz.ch/Software/R/, which 
> has a workaround.
> 
> On Mon, 24 May 2004, Benjamin Yakir wrote:
> 
> > I am new to Linux and just installed Fedora Core 2. Tried to install R
> > from Fedora core 1 binaries and from the source files according to the
> > manual but failed. Would appreciate any help.



From djogo at lbc.ludwig.org.br  Tue May 25 00:44:22 2004
From: djogo at lbc.ludwig.org.br (Diogo FC Patrao)
Date: Mon, 24 May 2004 19:44:22 -0300
Subject: [R] Re: identify() in script
In-Reply-To: <1085438583.4519.33.camel@hansolo>
References: <1085429834.4519.12.camel@hansolo>
	<1085438583.4519.33.camel@hansolo>
Message-ID: <1085438662.4519.35.camel@hansolo>

On Mon, 2004-05-24 at 19:43, Diogo FC Patrao wrote:
> On Mon, 2004-05-24 at 17:17, Diogo FC Patrao wrote:
>  hallo,
>  
>  I want a script of mine to run identify(), and possibly switch to
>  interactive mode at some point. Is it possible?
>  
>  Thanks in advance

I think I didn`t explained my point properly. Consider I have a file
named, say, test.R, which contains

x=rnorm(100)
y=rnorm(100)
plot( x,y )
identify(x,y,1:100)

and want to invoke it as a batch, running (in linux)

$ R < test.R

just by doing this, no plot appear. That's my doubt: is it possible to
do this? or, there is a command which halts the execution at some point
and allow me to enter commands, as I've invoked R in interactive mode?

thanks for your patience,

dfcp



From s.su at qut.edu.au  Tue May 25 01:23:08 2004
From: s.su at qut.edu.au (Steve Su)
Date: Tue, 25 May 2004 09:23:08 +1000
Subject: [R] yeardays
Message-ID: <001501c441e6$13996500$2032b583@qut.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040525/684bc2d4/attachment.pl

From dmurdoch at pair.com  Tue May 25 01:31:24 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 24 May 2004 19:31:24 -0400
Subject: [R] Re: Windows versus Unix packages in CRAN ...
In-Reply-To: <x2y8nhx38j.fsf@biostat.ku.dk>
References: <200405211202.i4LC2F49003939@erdos.math.unb.ca>
	<20040521134118.GC853@localhost>
	<tdlua01flkn1hjgq1up163rnbp10vdg548@4ax.com>
	<x2y8nhx38j.fsf@biostat.ku.dk>
Message-ID: <8i05b01k97ad646lmhceucfgi4v4sk37v4@4ax.com>

On 24 May 2004 17:18:52 +0200, Peter Dalgaard
<p.dalgaard at biostat.ku.dk> wrote:

>Duncan Murdoch <dmurdoch at pair.com> writes:
>
>> On Fri, 21 May 2004 15:41:18 +0200, Tamas Papp <tpapp at axelero.hu>
>> wrote:
>> 
>> >You are probably right in saying that they _could_ have done better,
>> >but I would not use "should" in this context.  AFAIK the package is
>> >free (as in beer) software, which means that you are not paying for
>> >it.  The maintainers probably do not need a Linux version (yet), so it
>> >was not easy to use it under Linux.  Feel free to contribute.  
>> 
>> Yes, indeed!  
>
>Well, yes and no. Yes, people should feel free to help out with the
>maintenance, but no, it is not reasonable to leave cross-platform
>issues unaddressed.

There's a list of packages on CRAN in
/bin/windows/contrib/1.9/@ReadMe that fail to build on Windows for one
reason or another.   Should we critcize the authors of those packages
for not addressing cross-platform issues?  I don't think so.

Why should it be any different when the situation is reversed?

Duncan Murdoch



From spencer.graves at pdf.com  Tue May 25 02:26:43 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 24 May 2004 17:26:43 -0700
Subject: [R] Applications of the Distance from a Point to a Curve
In-Reply-To: <200405241819.32532.dimasmm@visgraf.impa.br>
References: <200405241819.32532.dimasmm@visgraf.impa.br>
Message-ID: <40B292C3.5070601@pdf.com>

      With maps in R, it can sometimes be desirable to compute the 
minimum distance between two polygons and / or find any intersections 
between two lines and / or polygons. 

      Some clustering algorithms use the minimum distance between a 
given point and all points in a cluster. 

      Are examples like this relevant to your question? 

      spencer graves

Dimas Martnez Morera wrote:

>I would like to know if anyone knows about (real) situations where it is 
>necessary to compute the euclidean distance from a point to a curve (or even 
>the point where it is reached), you may not assume that the point is very 
>close to the curve (unlike the usual fitting problems).
>I have special interest in applications to phisics.
>
>Thanks in advance,
>
>Dimas
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From rupenshrestha at hotmail.com  Tue May 25 02:56:40 2004
From: rupenshrestha at hotmail.com (Rupen Shrestha)
Date: Tue, 25 May 2004 10:56:40 +1000
Subject: [R] loess
Message-ID: <BAY8-F76McRGmQSlmZL0000902c@hotmail.com>

Hi,

When I was running the function "loess(y~x, span=0.0020)", I got a warning 
message "k-d tree limited by memory. ncmax= 4231"

Does that mean the function has not been computed correctly ? If it has not, 
is there any way to adjust it so that it will do correctly ?

Thanks.

Rupen.









***************
If you fail to plan, you are planning to fail.

_________________________________________________________________
Download music tracks from 95c here:



From skikne at stanford.edu  Tue May 25 04:28:08 2004
From: skikne at stanford.edu (Sarah Skikne)
Date: Mon, 24 May 2004 19:28:08 -0700
Subject: [R] Scheire-Ray-Hare extension to Kruskal-Wallis
Message-ID: <00c801c441ff$eb1a6ce0$72430c80@skikne>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040524/fa2d36e9/attachment.pl

From ok at cs.otago.ac.nz  Tue May 25 06:38:44 2004
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Tue, 25 May 2004 16:38:44 +1200 (NZST)
Subject: [R] e1071, R1.9.0, Solaris 2.9, should I be worried?
Message-ID: <200405250438.i4P4cicw034303@atlas.otago.ac.nz>

In R 1.9.0 running under Solaris 2.9 on a SunBlade 100,
with "Sun WorkShop 6 update 2 C++ 5.3 2001/05/15" as the
C++ compiler, I just did
> install.packages("e1071")
The output includes these lines, which I have wrapped to fit nicely in mail:
** libs
cc -I/users/local/lib/R/include -I/usr/local/include  -KPIC -xlibmil \
 -dalign -xO4 -c cmeans.c -o cmeans.o
cc -I/users/local/lib/R/include -I/usr/local/include  -KPIC -xlibmil \
 -dalign  -xO4 -c cshell.c -o cshell.o
cc -I/users/local/lib/R/include -I/usr/local/include  -KPIC -xlibmil \
 -dalign -xO4 -c floyd.c -o floyd.o
cc -I/users/local/lib/R/include -I/usr/local/include  -KPIC -xlibmil \
 -dalign -xO4 -c Rsvm.c -o Rsvm.o
CC -I/users/local/lib/R/include -I/usr/local/include  -KPIC -xlibmil \
 -dalign -xO4 -c svm.cpp -o svm.o
"svm.cpp", line 444: Warning: l hides Solver::l.
"svm.cpp", line 444: Warning: Q hides Solver::Q.
"svm.cpp", line 444: Warning: Cp hides Solver::Cp.
"svm.cpp", line 444: Warning: Cn hides Solver::Cn.
"svm.cpp", line 444: Warning: eps hides Solver::eps.
"svm.cpp", line 507: Warning:
    String literal converted to char* in formal argument fmt 
    in call to info(char*, ...).
"svm.cpp", line 517: Warning:
    String literal converted to char* in formal argument fmt 
    in call to info(char*, ...).
"svm.cpp", line 690: Warning:
    String literal converted to char* in formal argument fmt 
    in call to info(char*, ...).
"svm.cpp", line 881: Warning: l hides Solver::l.
"svm.cpp", line 881: Warning: Q hides Solver::Q.
"svm.cpp", line 881: Warning: b hides Solver::b.
"svm.cpp", line 881: Warning: y hides Solver::y.
"svm.cpp", line 881: Warning: alpha hides Solver::alpha.
"svm.cpp", line 881: Warning: Cp hides Solver::Cp.
"svm.cpp", line 881: Warning: Cn hides Solver::Cn.
"svm.cpp", line 881: Warning: eps hides Solver::eps.
"svm.cpp", line 881: Warning: si hides Solver_NU::si.
"svm.cpp", line 1278: Warning:
    String literal converted to char* in formal argument fmt 
    in call to info(char*, ...).
"svm.cpp", line 1328: Warning:
    String literal converted to char* in formal argument fmt 
    in call to info(char*, ...).
"svm.cpp", line 1404: Warning:
    String literal converted to char* in formal argument fmt 
    in call to info(char*, ...).
"svm.cpp", line 1439: Warning:
    String literal converted to char* in formal argument fmt 
    in call to info(char*, ...).
"svm.cpp", line 1483: Warning:
    String literal converted to char* in formal argument fmt 
    in call to info(char*, ...).
"svm.cpp", line 1507: Warning:
    String literal converted to char* in formal argument fmt 
    in call to info(char*, ...).
"svm.cpp", line 1719: Warning:
    String literal converted to char* in formal argument fmt 
    in call to info(char*, ...).
24 Warning(s) detected.

How worried should I be?
I guess the "Warning: x hides Solver::x" warnings related to a deliberate
style choice, but what about the "String literal converted to char*" ones?



From ripley at stats.ox.ac.uk  Tue May 25 08:12:36 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 May 2004 07:12:36 +0100 (BST)
Subject: [R] loess
In-Reply-To: <BAY8-F76McRGmQSlmZL0000902c@hotmail.com>
Message-ID: <Pine.LNX.4.44.0405250707460.29454-100000@gannet.stats>

On Tue, 25 May 2004, Rupen Shrestha wrote:

> When I was running the function "loess(y~x, span=0.0020)", I got a warning 
> message "k-d tree limited by memory. ncmax= 4231"
> 
> Does that mean the function has not been computed correctly ? If it has not, 
> is there any way to adjust it so that it will do correctly ?

It was computed a little inaccurately.  You can alter many things: see
?loess.control, especially its first item. *However*, that span is so
small that this makes little sense, with too few neighbours for any 
visually apparent smoothing.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue May 25 08:18:03 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 May 2004 07:18:03 +0100 (BST)
Subject: [R] yeardays
In-Reply-To: <001501c441e6$13996500$2032b583@qut.edu.au>
Message-ID: <Pine.LNX.4.44.0405250713050.29454-100000@gannet.stats>

On Tue, 25 May 2004, Steve Su wrote:

> Is there a R (Windows) equivalent of yeardays in Splus 6.0 for Windows?
> I am using XP.

You could tell us what that did ... that version of S-PLUS (sic) is long 
obselete and most readers will not have access to it (or any other recent 
version of S-PLUS).

It would appear to be one plus the yday component of a POSIXlt object, so

as.POSIXlt(x)$yday + 1

should be equivalent.  See ?months for relevant comments.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Tue May 25 09:19:35 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 25 May 2004 09:19:35 +0200
Subject: [R] Scheire-Ray-Hare extension to Kruskal-Wallis
In-Reply-To: <00c801c441ff$eb1a6ce0$72430c80@skikne>
References: <00c801c441ff$eb1a6ce0$72430c80@skikne>
Message-ID: <x23c5pkm7s.fsf@biostat.ku.dk>

"Sarah Skikne" <skikne at stanford.edu> writes:

> Hi,
> 
> I was wondering if it was possible to do the "Scheirer-Ray-Hare"
> extension of the Kruskal-Wallis test using R, or if it was possible
> to use some other non-parametric test for the following situation:
> 
> I have continuous data that is grouped by 2 factor variables. I
> would like a non-parametric test because the group variances are not
> equal. I would like to look for the effects of either factor
> variable and their interaction.

It is a common misconception that nonparametric tests do not assume
equal variances. In fact, they generally assume that entire
distributions are the same (under the null hypothesis). Testing for
interactions also pretty much assumes effects are on a particular
scale, which is not really very different from making parametric
assumptions. I'd consider a weighted linear model in such cases,
possibly supplemented by simulation or bootstrapping to get an
improved estimate of the p-values etc.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Tue May 25 09:33:45 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 25 May 2004 09:33:45 +0200
Subject: [R] adress the current index
In-Reply-To: <200405242205.23750.ferri.leberl@gmx.at>
References: <200405242205.23750.ferri.leberl@gmx.at>
Message-ID: <40B2F6D9.8010404@statistik.uni-dortmund.de>

Mag. Ferri Leberl wrote:

> How can I adress the current index of a vector?

How do you define "current" in this context?
You might want to get the length() of the vector...

Uwe Ligges


> I want to work with time series and therefore give the n-th element of a 
> vector some value dependent on the value of the n-1th element.
> 
> Thank you in advance.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From n.bouget at laposte.net  Tue May 25 09:38:42 2004
From: n.bouget at laposte.net (n.bouget)
Date: Tue, 25 May 2004 09:38:42 +0200
Subject: [R] Question
Message-ID: <HY9EKI$6C3D32FBC04D6D7E123073009B41F297@laposte.net>

[R]:Agnes vs Hclust

Hi,
I want to know if there is a difference between the two
hierarchical methods Agnes and hclust when there are used with
the same method and the same metric on the same data! I ask
this question because I've got a difference, the clusters are
not the same even if there are some similarities...
Is anybody know why i have this difference?
Thanks
Nicolas BOUGET 





From wolski at molgen.mpg.de  Tue May 25 10:01:15 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Tue, 25 May 2004 10:01:15 +0200
Subject: [R] Hiding internal package functions for the doc. pkg-internal.Rd
Message-ID: <200405251001150072.0047068D@mail.math.fu-berlin.de>

Hallo!

I would like that the internal package functions  does not appear in the documentation.
I placed they names as aliases in the file nameofmypackage-internal.Rd as advised.

After R CMD check (which runs neatly) they are still listed in 00Index.html.

Is there no way to hide internal functions from the doc?
Have I overlook something?

Sincerely Eryk.



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From Giles.Heywood at CommerzbankIB.com  Tue May 25 11:11:50 2004
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Tue, 25 May 2004 10:11:50 +0100
Subject: [R] irregular time series
Message-ID: <E65C272ECD3BD51196E500508B6658FE08CD946A@xmx6lonib.lonib.commerzbank.com>

The 'its' class may be useful to you for printing/plotting/aligning data,
but as Jason says, you will need to rely on other packages such as stats
(formerly ts) for analysis, using the appropriate na.action.

Two comments in addition:

Since your data is (from what you say) regular but incomplete, you may well
not need any of the irregular time-series functionality.

In the frequency domain, I should point out that Nyquist frequency is a
reciprocal function of the sample interval (e.g. daily), not the sample
length.  Increasing the sample length will in fact reduce the sampling
interval in the frequency domain, leaving Nyquist unchanged.

- Giles

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Jason Turner
> Sent: 20 May 2004 16:45
> To: McClatchie, Sam (PIRSA-SARDI)
> Cc: 'r-help at lists.R-project.org'
> Subject: Re: [R] irregular time series
> 
> 
> On Thu, May 20, 2004 at 02:23:46PM +0930, McClatchie, Sam 
> (PIRSA-SARDI) wrote:
> [long time series, broken in two with a gap]
> > I realise that I could just break each series into two segments and
> > cross-correlate with the shorter series, but I'd rather 
> deal with the whole
> > series to increase the nyquist frequency. I think the its 
> function in the
> > irregular time series package will create a class its 
> object with the right
> > time stamps, but can this then be used in the same was as a 
> class ts object
> > for the correlation and spectral anayses?  
> 
> its does some nice things for storing, plotting, and manipulating
> irregular time series, but isn't long on the analysis.
> 
> A few options:
> 
> 1) Analyze the two sub-series separately.
> 2) There is some merit to de-mean or de-trending both series,
> zero-padding the shorter so its length matches the longer, and 
> performing spectral analysis that way.  Frequencies near zero
> should be treated with suspicion, however.
> 3) Jim Lindsey has some continuous ARMA and Kalman filter routines
> on his site (Google for "Lindsey" and "rmutil", which is the
> name of one of those packages).
> 4) I'm working on an R version of the Lomb periodogram, which
> was built for irregular series, but I've no guarantees when I'll
> roll it up - rather busy most days.  I do remember seeing an S
> version on someone's web page, but that was a while ago, and it
> was the "direct" or slow method.
> 
> Hope that helps
> 
> Jason
> 
> 
> 
> -- 
> Indigo Industrial Controls Ltd.
> http://www.indigoindustrial.co.nz
> 64-21-343-545
> jasont at indigoindustrial.co.nz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From ernesto at ipimar.pt  Tue May 25 11:34:23 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 25 May 2004 10:34:23 +0100
Subject: [R] RMySQL problem
In-Reply-To: <20040524174457.A24945@jessie.research.bell-labs.com>
References: <1085410580.27999.111.camel@gandalf.local>
	<20040524174457.A24945@jessie.research.bell-labs.com>
Message-ID: <1085477662.32532.8.camel@gandalf.local>

Hi,

I found the dbWriteTable function. 

Sorry for the work but I'm still trying to understand how the S4
documentation works. If you do "help(package="RMySQL")" the
"dbWriteTable" method does not exist. It exists a "dbReadTable" method
wich has an alias to "dbWriteTable". It should be intuitive but it
wasn't for me ...

Now the method: I could only import 555 rows ... Is there some flag
about the number of rows it can import ?

Regards

EJ 

On Mon, 2004-05-24 at 22:44, David James wrote:
> Hi,
> 
> The method for dbWriteTable() uses the MySQL bulk loading faciliy
> "LOAD DATA LOCAL INFILE" to efficiently upload a file into the
> server.  So you should be able to issue something like
>   > sim.result <- big.simulation(...)
>   > dbWriteTable(con, "table_name", sim.results, append = TRUE)
> to append the rows in sim.results into the MySQL "table_name".
> 
> However, I should mention that the currently implementation
> outputs the contents of the data.frame into a temporary file
> using the function write.table(), which in the past could be
> slow.
> 
> Hope this helps,
> 
> --
> David
> 
> Ernesto Jardim wrote:
> > Hi,
> > 
> > I'm using R 1.9.0 with RMySQL 0.5-4 and MySQL 3.23.55 on a suse 8.2 box.
> > 
> > I have a simulation study and (as usual for newbies in simulation, I
> > guess) I have a lot of data that I want to store in MySQL. I want to
> > write an R script that reads data from RData files and writes it to a
> > MySQL database. 
> > 
> > I read some R documents (R Data Import/Export and DSC papers) but I'm
> > finding differences between the documents and the packages (RMySQL and
> > DBI). I don't find the methods to write data like "dbWriteTable"...
> > 
> > On the other hand I've tryied to build a sql statement to insert data
> > but I'm stucked because of ... who knows, my ignorance probably. I want
> > to take advantage of MySQl INSERT INTO statement that deals with several
> > rows at once to insert a complete data.frame into a table. I've tryied
> > to use "paste" to build the sql string but It works "by column" and I
> > need it "by row" ...
> > 
> > The sql systax should be something like:
> > 
> > INSERT INTO TABLEA(COL1, COL2, COL3) VALUES
> > 	(VAL11, VAL12, VAL13),
> > 	(VAL21, VAL22, VAL23),
> > 	...
> > 	(VALN1, VALN2, VALN3);
> > 
> > and I have a data.frame with 3 columns corresponding to that table
> > columns.
> > 
> > How can I do this ?
> > 
> > Thanks
> > 
> > EJ
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rksh at soc.soton.ac.uk  Tue May 25 11:33:04 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Tue, 25 May 2004 10:33:04 +0100
Subject: [R] vectorize an expression
Message-ID: <a06002001bcd8c2476065@[139.166.242.29]>

Hi guys.  Another thing I cannot vectorize:

I have an array "a", of size 5-by-2, for example, of 5 2D vectors.  I
also have a distance function that computes the distance between two
vectors (usual Euclidean distance is a good example but I have other metrics I
want to use as well).  I want a 5-by-5 array with the [i,j]th element being
  the distance from a[i,] to a[j,]

To Wit:

   a <- matrix(1:10,5,2)
   array <- matrix(NA, 5, 5)
   dist <- function(x1,x2){sqrt(sum(x1-x2)^2)}

   #NONVECTORIZED BIT FOLLOWS
   for(i in 1:5) {
     for(j in 1:5) {
       array[i,j] <- dist(a[i,] , a[j,])
     }
   }

(note that array[i,i]=0 for i=1:5 as expected).

How to vectorize this?


-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From hb at maths.lth.se  Tue May 25 11:48:31 2004
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 25 May 2004 11:48:31 +0200 (CEST)
Subject: [R] Hiding internal package functions for the doc. pkg-internal.Rd
In-Reply-To: <200405251001150072.0047068D@mail.math.fu-berlin.de>
References: <200405251001150072.0047068D@mail.math.fu-berlin.de>
Message-ID: <Pine.LNX.4.53.0405251144510.31403@markov.maths.lth.se>

Add \keyword{internal} to the Rd files you would like to hide from the
index. From section "Documenting functions" in "Writing R Extensions" (for
R v1.9.0):

"\keyword{key}
  Each \keyword entry should specify one of the standard keywords (as
listed in the file R_HOME/doc/KEYWORDS.db). There must be at least one
\keyword entry, but can be more that one if the R object being documented
falls into more than one category.

 The special keyword 'internal' marks a page of internal objects that are
not part of the packages' API. If the help page for object foo has keyword
internal, then help(foo) gives this help page, but foo is excluded from
several object indices, like the alphabetical list of objects in the HTML
help system."

Cheers

Henrik Bengtsson

Dept. of Mathematical Statistics @ Centre for Mathematical Sciences
Lund Institute of Technology/Lund University, Sweden (+2h UTC)
+46 46 2229611 (off), +46 708 909208 (cell), +46 46 2224623 (fax)
h b @ m a t h s . l t h . s e, http://www.maths.lth.se/~hb/

On Tue, 25 May 2004, Wolski wrote:

> Hallo!
>
> I would like that the internal package functions  does not appear in the documentation.
> I placed they names as aliases in the file nameofmypackage-internal.Rd as advised.
>
> After R CMD check (which runs neatly) they are still listed in 00Index.html.
>
> Is there no way to hide internal functions from the doc?
> Have I overlook something?
>
> Sincerely Eryk.
>
>
>
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic
> Ihnestrasse 63-73 14195 Berlin       'v'
> tel: 0049-30-83875219               /   \
> mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Jesus.Frias at dit.ie  Tue May 25 11:44:33 2004
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Tue, 25 May 2004 10:44:33 +0100
Subject: [R] Metafiiles  into Word R 1.9.0
In-Reply-To: <37700.203.9.176.60.1085434217.squirrel@webmail.maxnet.co.nz>
Message-ID: <LGECJJCANFBOOHCMGPJEGEFIDDAA.Jesus.Frias@dit.ie>

Hi again,

The object is genuinely empty. No image on print-preview, and if I try to
"Edit Picture" when it is open there are no objects in it.

	There is one more thing that might shed some light (or not) on it: I have
just found that I can actually copy-paste a plot in the device coming from a
plot call but not from a lattice object call. There it is my toy example:

> example(plot)
> savePlot("exampleplot.wmf",type="wmf")
> library(lattice)
> example(xyplot)
> savePlot("examplexyplot.wmf",type="wmf")

	I have no problem importing exampleplot.wmf into Word, but I can't do the
same with examplexyplot.wmf. The file seems empty, it has only 696 bytes.

	I am attaching the two files.

regards,

Jesus

         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.0
year     2004
month    04
day      12
language R

--------------------------------------------------------------
Jes??s Mar??a Fr??as Celayeta
School of Food Sci. and Env. Health.
Faculty of Tourism and Food
Dublin Institute of Technology
Cathal Brugha St., Dublin 1. Ireland
t +353 1 4024459 f +353 1 4024495
w www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Jason Turner
> Sent: 25 May 2004 22:30
> To: Jesus Frias
> Cc: R-Help
> Subject: Re: [R] Metafiiles into Word R 1.9.0
>
>
> > 	2.-The computer at work has Microsoft Windows 2000
> (5.00.2195 Service
> > Pack
> > 2) and Word 2000 (9.0.4402 SR-1) I cannot copy-paste windows metafiles
> > into
> > Office applications in my computer at work. The resulting
> object is empty.
> >
>
> Is it genuinely empty, or can you see the graphs in print layout view, or
> print preview?  I've seen that particular Word bug before.  It happens
> with Visio drawings too (Visio is a M$ product).
>
> Cheers
>
> Jason
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

--
This message has been scanned for content and
viruses by the DIT Information Services MailScanner
Service, and is believed to be clean.
http://www.dit.ie

-- 
This message has been scanned for content and 
viruses by the DIT Information Services MailScanner 
Service, and is believed to be clean.
http://www.dit.ie


From wolski at molgen.mpg.de  Tue May 25 11:58:40 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Tue, 25 May 2004 11:58:40 +0200
Subject: [R] Hiding internal package functions for the doc. pkg-internal.Rd
In-Reply-To: <Pine.LNX.4.53.0405251144510.31403@markov.maths.lth.se>
References: <200405251001150072.0047068D@mail.math.fu-berlin.de>
	<Pine.LNX.4.53.0405251144510.31403@markov.maths.lth.se>
Message-ID: <200405251158400483.00B287AF@mail.math.fu-berlin.de>

Hallo Henrik!
Thanks a lot. 
Sincerely
Eryk

*********** REPLY SEPARATOR  ***********

On 5/25/2004 at 11:48 AM Henrik Bengtsson wrote:

>Add \keyword{internal} to the Rd files you would like to hide from the
>index. From section "Documenting functions" in "Writing R Extensions" (for
>R v1.9.0):
>
>"\keyword{key}
>  Each \keyword entry should specify one of the standard keywords (as
>listed in the file R_HOME/doc/KEYWORDS.db). There must be at least one
>\keyword entry, but can be more that one if the R object being documented
>falls into more than one category.
>
> The special keyword 'internal' marks a page of internal objects that are
>not part of the packages' API. If the help page for object foo has keyword
>internal, then help(foo) gives this help page, but foo is excluded from
>several object indices, like the alphabetical list of objects in the HTML
>help system."
>
>Cheers
>
>Henrik Bengtsson
>
>Dept. of Mathematical Statistics @ Centre for Mathematical Sciences
>Lund Institute of Technology/Lund University, Sweden (+2h UTC)
>+46 46 2229611 (off), +46 708 909208 (cell), +46 46 2224623 (fax)
>h b @ m a t h s . l t h . s e, http://www.maths.lth.se/~hb/
>
>On Tue, 25 May 2004, Wolski wrote:
>
>> Hallo!
>>
>> I would like that the internal package functions  does not appear in the
>documentation.
>> I placed they names as aliases in the file nameofmypackage-internal.Rd
>as advised.
>>
>> After R CMD check (which runs neatly) they are still listed in
>00Index.html.
>>
>> Is there no way to hide internal functions from the doc?
>> Have I overlook something?
>>
>> Sincerely Eryk.
>>
>>
>>
>> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic
>> Ihnestrasse 63-73 14195 Berlin       'v'
>> tel: 0049-30-83875219               /   \
>> mail: wolski at molgen.mpg.de        ---W-W----   
>http://www.molgen.mpg.de/~wolski
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From cristian at biometria.univr.it  Tue May 25 12:27:40 2004
From: cristian at biometria.univr.it (Cristian Pattaro)
Date: Tue, 25 May 2004 12:27:40 +0200
Subject: [R] Histogram
Message-ID: <40B31F9C.6080305@biometria.univr.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040525/b8ab1a7d/attachment.pl

From ligges at statistik.uni-dortmund.de  Tue May 25 12:57:49 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 25 May 2004 12:57:49 +0200
Subject: [R] Histogram
In-Reply-To: <40B31F9C.6080305@biometria.univr.it>
References: <40B31F9C.6080305@biometria.univr.it>
Message-ID: <40B326AD.20602@statistik.uni-dortmund.de>

Cristian Pattaro wrote:

> Dear all,
> 
> I have a surprising problem with the representation of frequencies in a 
> histogram.
> 
> Consider, for example, the R code:
> 
> b<-rnorm(2000,3.5,0.3)
> hist(b,freq=F)
> 
> When I plotted the histogram, I expected that values in the y-axis (the 
> probability) varied between 0 and 1. Instead, they varied within the 
> range 0-1.3.
> 
> Have you got any suggestion for obtaining a correct graph with 
> probability within the range 0-1?


Note that width * height (and *not* the height solely) corresponds to 
the probability in a histogram.

Uwe Ligges



> Thank you very much!
> 
> Bests
> /Cristian/
> 
> =============================================
> Cristian Pattaro
> =============================================
> Unit of Epidemiology & Medical Statistics
> Department of Medicine and Public Health
> University of Verona
> 
> http://biometria.univr.it
> cristian at biometria.univr.it
> =============================================
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Achim.Zeileis at wu-wien.ac.at  Tue May 25 12:58:01 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 25 May 2004 12:58:01 +0200
Subject: [R] Histogram
In-Reply-To: <40B31F9C.6080305@biometria.univr.it>
References: <40B31F9C.6080305@biometria.univr.it>
Message-ID: <20040525125801.7c216a71.Achim.Zeileis@wu-wien.ac.at>

On Tue, 25 May 2004 12:27:40 +0200 Cristian Pattaro wrote:

> Dear all,
> 
> I have a surprising problem with the representation of frequencies in
> a histogram.
> 
> Consider, for example, the R code:
> 
> b<-rnorm(2000,3.5,0.3)
> hist(b,freq=F)
> 
> When I plotted the histogram, I expected that values in the y-axis
> (the probability) varied between 0 and 1. Instead, they varied within
> the range 0-1.3.

The y-axis gives the density not the probability!

And the density you are sampling from has

R> dnorm(3.5, mean = 3.5, sd = 0.3)
[1] 1.329808

so you shouldn't be surprised by this.
Z

> Have you got any suggestion for obtaining a correct graph with 
> probability within the range 0-1?
>
> Thank you very much!
> 
> Bests
> /Cristian/
> 
> =============================================
> Cristian Pattaro
> =============================================
> Unit of Epidemiology & Medical Statistics
> Department of Medicine and Public Health
> University of Verona
> 
> http://biometria.univr.it
> cristian at biometria.univr.it
> =============================================
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From Ted.Harding at nessie.mcc.ac.uk  Tue May 25 13:15:20 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 25 May 2004 12:15:20 +0100 (BST)
Subject: [R] Histogram
In-Reply-To: <40B31F9C.6080305@biometria.univr.it>
Message-ID: <XFMail.040525121520.Ted.Harding@nessie.mcc.ac.uk>

On 25-May-04 Cristian Pattaro wrote:
> I have a surprising problem with the representation of
> frequencies in a histogram.
> 
> Consider, for example, the R code:
> 
> b<-rnorm(2000,3.5,0.3)
> hist(b,freq=F)
> 
> When I plotted the histogram, I expected that values in
> the y-axis (the probability) varied between 0 and 1.
> Instead, they varied within the range 0-1.3.
> 
> Have you got any suggestion for obtaining a correct graph
> with probability within the range 0-1?

It depends on the widths of the bins, since what is plotted
in the histogram when freq=F is vertically scaled so that

  sum over bins of  h*(width of bin) = 1

where h is the height of the histogram bar according to the
vertical scale. In other words, hist plots a per-bin estimate
of the probability density in the sense of "amount of probability
per bin divided by width of bin". If your bin widths are narrow
(and your SD above is 0,3, so you will get quite narrow bins,
0.2 in this case) and you may well get values exceeding 1.

Exactly, indeed, as for the density of the normal distribution
itself: (1/(sqrt(2*pi)*sigma))*exp(-0.5* ... ) where small values
of sigma give density > 1 near x=0.

If you need the actual value of the probabilities in the bins
(i.e. n_i/N) then you can force it by constructing a new hist
object on the lines of

  h<-hist(b,freq=F)
  h$counts <- h$counts/sum(h$counts)
  plot(h)

When I do this with your above example, whereas the original
gives a y-axis from 0 to 1.2 with the tallest bar at about 1.3,
"plot(h)" give exactly the same graph but with the y-axis
labelled from 0 to 0.25, with the tallest bar at 0.2625, which
shows the probabilities.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 25-May-04                                       Time: 12:15:20
------------------------------ XFMail ------------------------------



From v.demartino2 at virgilio.it  Tue May 25 15:22:21 2004
From: v.demartino2 at virgilio.it (Vittorio)
Date: Tue, 25 May 2004 14:22:21 +0100
Subject: [R] Tramo-seats
In-Reply-To: <200405242207.54050.paul_bivand@blueyonder.co.uk>
References: <4087DF45000A1F41@ims3e.cp.tin.it>
	<200405242207.54050.paul_bivand@blueyonder.co.uk>
Message-ID: <200405251422.22176.v.demartino2@virgilio.it>

On Monday 24 May 2004 22:07, Paul Bivand wrote:
> On Monday 24 May 2004 11:00, v.demartino2 at virgilio.it wrote:
...............
> > Now - to start with - a first problem to solve:
> >
> > we have to comply with the Tramo-seats closed-source procedure
> > (http://www.bde.es/informes/be/docs/dt0014e.pdf) to deal with seasonality
> > of electricity monthly time-series, in line with the methodology
> > officially adopted by our  National Bureau of Statistics.
> >
> > Searching in R-help mailing list I didn't find anything about a
> > tramo-seats R version.
> >
> > Does anyone know of unofficial R translation of tramo-seats?
> > OR What do you suggest?
> >
> > Vittorio

>
> Not an R response I'm afraid, but have you looked at Demetra
> http://forum.europa.eu.int/irc/dsis/eurosam/info/data/demetra.htm which
> appears to be an officially sponsored windows-only implementation of
> Tramo-seats and X-12 ARIMA.
>
> The licence is not clear from the website, but it looks free as in beer but
> probably not open source.
>
> Paul Bivand
>
Paul,
Thanks for your answer.

As a matter of fact Demetra (tramo-seats is not definetely open source!) is 
what we are currently using but, you know, this doesn't match our desire to 
move to R from many other licenced pieces of software!

Ciao
Vittorio



From ggrothendieck at myway.com  Tue May 25 13:42:17 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 25 May 2004 11:42:17 +0000 (UTC)
Subject: [R] vectorize an expression
References: <a06002001bcd8c2476065@[139.166.242.29]>
Message-ID: <loom.20040525T133819-792@post.gmane.org>



apply(a,1,function(y)apply(a,1,function(x)dist(x,y)))


Robin Hankin <rksh <at> soc.soton.ac.uk> writes:

: 
: Hi guys.  Another thing I cannot vectorize:
: 
: I have an array "a", of size 5-by-2, for example, of 5 2D vectors.  I
: also have a distance function that computes the distance between two
: vectors (usual Euclidean distance is a good example but I have other metrics 
I
: want to use as well).  I want a 5-by-5 array with the [i,j]th element being
:   the distance from a[i,] to a[j,]
: 
: To Wit:
: 
:    a <- matrix(1:10,5,2)
:    array <- matrix(NA, 5, 5)
:    dist <- function(x1,x2){sqrt(sum(x1-x2)^2)}
: 
:    #NONVECTORIZED BIT FOLLOWS
:    for(i in 1:5) {
:      for(j in 1:5) {
:        array[i,j] <- dist(a[i,] , a[j,])
:      }
:    }
: 
: (note that array[i,i]=0 for i=1:5 as expected).
: 
: How to vectorize this?
:



From vtas at uosis.mif.vu.lt  Tue May 25 14:02:38 2004
From: vtas at uosis.mif.vu.lt (vtas@uosis.mif.vu.lt)
Date: Tue, 25 May 2004 15:02:38 +0300 (EEST)
Subject: [R] Tramo-seats
Message-ID: <3059.193.219.42.109.1085486558.squirrel@kedras.mif.vu.lt>

Hi,
take a look at gretl (http://gretl.sourceforge.net/), which integrates
econometrics, X-12-ARIMA, TRAMO/SEATS and R.

Vytautas Maniusis,
Vilnius University, Lithuania



From James.Callahan at CityofOrlando.net  Tue May 25 14:11:00 2004
From: James.Callahan at CityofOrlando.net (James.Callahan@CityofOrlando.net)
Date: Tue, 25 May 2004 08:11:00 -0400
Subject: [R] Tramo-seats support in GRETL, but not R
In-Reply-To: <200405251001.i4PA0na6023381@hypatia.math.ethz.ch>
Message-ID: <OFD10BF78C.76AD243C-ON85256E9F.004062CD-85256E9F.0042DA93@ci.orlando.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040525/afbf2cda/attachment.pl

From djogo at lbc.ludwig.org.br  Tue May 25 14:17:46 2004
From: djogo at lbc.ludwig.org.br (Diogo FC Patrao)
Date: Tue, 25 May 2004 09:17:46 -0300
Subject: [R] Re: identify() in script
In-Reply-To: <1085438662.4519.35.camel@hansolo>
References: <1085429834.4519.12.camel@hansolo>
	<1085438583.4519.33.camel@hansolo> <1085438662.4519.35.camel@hansolo>
Message-ID: <1085487466.17243.2.camel@hansolo>

> >  I want a script of mine to run identify(), and possibly switch to
> >  interactive mode at some point. Is it possible?

in case you're interested, I found myself a solution for my problem.
create a file (test.R) containing

x=rnorm(100)
y=rnorm(100)
x11()
plot( x,y )
identify(x,y,1:100)

then $ R < test.R will do the trick



From n.bouget at laposte.net  Tue May 25 14:33:58 2004
From: n.bouget at laposte.net (n.bouget)
Date: Tue, 25 May 2004 14:33:58 +0200
Subject: [R] equivalent of the Splus function "eboulis()"
Message-ID: <HY9S8M$E1451BF7C9040FDC9CE9FCE8CCBBA0B5@laposte.net>

Hi,
Is there a equivalent of the function "eboulis()" (which is a
new funtion on Splus) on R? 
Otherwise, with which function can we see the best number of
cluster we have to choose?
Thanks in advance,
Nicolas BOUGET




From abderrahim.oulhaj at pharmacology.oxford.ac.uk  Tue May 25 14:36:24 2004
From: abderrahim.oulhaj at pharmacology.oxford.ac.uk (Abderrahim Oulhaj)
Date: Tue, 25 May 2004 13:36:24 +0100
Subject: [R] NLME
Message-ID: <013501c44254$e3f2c200$40ca01a3@optima.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040525/ba593ad2/attachment.pl

From ripley at stats.ox.ac.uk  Tue May 25 14:47:25 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 May 2004 13:47:25 +0100 (BST)
Subject: [R] equivalent of the Splus function "eboulis()"
In-Reply-To: <HY9S8M$E1451BF7C9040FDC9CE9FCE8CCBBA0B5@laposte.net>
Message-ID: <Pine.LNX.4.44.0405251342300.2168-100000@gannet.stats>

On Tue, 25 May 2004, n.bouget wrote:

> Is there a equivalent of the function "eboulis()" (which is a
> new funtion on Splus) on R? 

There is no such function in the latest S-PLUS, version 6.2.  Further,
S-PLUS is an English product and `eboulis' appears to be French.

> Otherwise, with which function can we see the best number of
> cluster we have to choose?

Please check out where you got that function from, and give us a 
description of what you are looking for.  We cannot tell you the 
equivalent of a non-existent function (except to give you a list of 
non-existent R functions).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Jan.Verbesselt at agr.kuleuven.ac.be  Tue May 25 14:52:33 2004
From: Jan.Verbesselt at agr.kuleuven.ac.be (Jan Verbesselt)
Date: Tue, 25 May 2004 14:52:33 +0200
Subject: [R] correlation coefficient of ARIMA() or GLS() ?
Message-ID: <000401c44257$25f52fb0$1145210a@agr.ad10.intern.kuleuven.ac.be>

Hi R-helpers,

I fitted the following ARIMA model onto de-seasonlised time series 1 and
2, which were strongly seasonal. How can the R?? or the coefficient of
determination for the structural term be calculated between these two
fitted time series? 

Is an GLS() the solution (difference between ARIMA and GLS) ? Is it
possible to calculated an R?? from a GLS() model ? # nlme and MASS
package


***************************
reg.model <- arima(serie2.dd, order=c(6,0,0), xreg = serie1.dd, method =
"ML") 
tsdiag(reg.model)  #  =>looks OK. residuals are not autocorrelated
(ljung-box statistic)  but not normally distributed.Problem?

> reg.model
Call:
arima(x = serie2.dd, order = c(6, 0, 0), xreg = serie1.dd, method =
"ML")
Coefficients:
         ar1     ar2     ar3     ar4     ar5     ar6 intercept serie1.dd

     -0.1033 -0.3957 -0.0423 -0.2719 -0.2969 -0.1401   -2.3535  585.9007
s.e.  0.0843  0.0823  0.0831  0.0857  0.0795  0.0829    3.1520  118.1323

sigma^2 estimated as 6932:  log likelihood = -829.9,  aic = 1677.79
>

gls.ddm2 <- gls(serie2.ddm ~ serie1.ddm -1, correlation=corARMA(p=6),
method="ML") # fit of a gls without intercept because the intercept was
not significant but residuals are still auto correlated...?!
****************************************************

Tips, advice or examples are mostly welcome.
Many thanks in advance,
Regards,
Jan

_____________________________________________________________________
Jan Verbesselt 
Research Associate 
Lab of Geomatics and Forest Engineering K.U. Leuven
Vital Decosterstraat 102. B-3000 Leuven Belgium 
Tel:+32-16-329750   Fax: +32-16-329760
http://gloveg.kuleuven.ac.be/



From n.bouget at laposte.net  Tue May 25 15:06:12 2004
From: n.bouget at laposte.net (n.bouget@laposte.net)
Date: Tue, 25 May 2004 15:06:12 +0200
Subject: [R] equivalent of the Splus function "eboulis()"
Message-ID: <HY9TQC$00C36167DAB3F68003CF888BB0AB2D85@laposte.net>

This function already exists in the package multidim (see
http://cran.r-project.org/doc/packages/multidim.pdf)
What i want to do is to choose the good number of cluster
after using the function hclust on 6934 instances. 
> hc <- hclust(dist(AGRIINSTTableFinaleCR), "ward")
I use the following expression
> barplot(sort((hc$height/sum(hc$height))*100,decreasing=TRUE))
and i choose as number of cluster the number before a big fall
but i'm not sure that is the good mean to choose the number of
cluster!

> On Tue, 25 May 2004, n.bouget wrote:
> 
> > Is there a equivalent of the function "eboulis()" (which is a
> > new funtion on Splus) on R? 
> 
> There is no such function in the latest S-PLUS, version 6.2.
 Further,
> S-PLUS is an English product and `eboulis' appears to be French.
> 
> > Otherwise, with which function can we see the best number of
> > cluster we have to choose?
> 
> Please check out where you got that function from, and give
us a 
> description of what you are looking for.  We cannot tell you
the 
> equivalent of a non-existent function (except to give you a
list of 
> non-existent R functions).
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics, 
http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 




From ripley at stats.ox.ac.uk  Tue May 25 15:14:57 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 May 2004 14:14:57 +0100 (BST)
Subject: [R] vectorize an expression
In-Reply-To: <a06002001bcd8c2476065@[139.166.242.29]>
Message-ID: <Pine.LNX.4.44.0405251406310.2515-100000@gannet.stats>

Suggestion 1: Use the R function `dist'.

Suggestion 2: Don't mask an R system function name.

Suggestion 3: Time this.  I don't think it is worth vectorizing.

Suggestion 4: The bit which is actually nonvectorized is your function 
dist.  If you had a vectorized distance function, you could do

for(i in 1:5) array[i,] <- dist(a[i,,drop=FALSE] , a)

but that would need

dist <- function(x1,x2) sqrt(rowSums(x1-x2)^2)

I could tell you how to fully vectorize it, but I doubt if it would have 
any benefit.

(None of this is tested, because of 1 and 3.)

On Tue, 25 May 2004, Robin Hankin wrote:

> Hi guys.  Another thing I cannot vectorize:
> 
> I have an array "a", of size 5-by-2, for example, of 5 2D vectors.  I
> also have a distance function that computes the distance between two
> vectors (usual Euclidean distance is a good example but I have other metrics I
> want to use as well).  I want a 5-by-5 array with the [i,j]th element being
>   the distance from a[i,] to a[j,]
> 
> To Wit:
> 
>    a <- matrix(1:10,5,2)
>    array <- matrix(NA, 5, 5)
>    dist <- function(x1,x2){sqrt(sum(x1-x2)^2)}
> 
>    #NONVECTORIZED BIT FOLLOWS
>    for(i in 1:5) {
>      for(j in 1:5) {
>        array[i,j] <- dist(a[i,] , a[j,])
>      }
>    }
> 
> (note that array[i,i]=0 for i=1:5 as expected).
> 
> How to vectorize this?
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue May 25 15:17:30 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 May 2004 14:17:30 +0100 (BST)
Subject: [R] equivalent of the Splus function "eboulis()"
In-Reply-To: <HY9TQC$00C36167DAB3F68003CF888BB0AB2D85@laposte.net>
Message-ID: <Pine.LNX.4.44.0405251415100.2515-100000@gannet.stats>

But multidim is not part of S-PLUS, and it does seem to exist for R.
So the equivalent of "eboulis()" in R is "eboulis()"!

On Tue, 25 May 2004, n.bouget at laposte.net wrote:

> This function already exists in the package multidim (see
> http://cran.r-project.org/doc/packages/multidim.pdf)
> What i want to do is to choose the good number of cluster
> after using the function hclust on 6934 instances. 
> > hc <- hclust(dist(AGRIINSTTableFinaleCR), "ward")
> I use the following expression
> > barplot(sort((hc$height/sum(hc$height))*100,decreasing=TRUE))
> and i choose as number of cluster the number before a big fall
> but i'm not sure that is the good mean to choose the number of
> cluster!
> 
> > On Tue, 25 May 2004, n.bouget wrote:
> > 
> > > Is there a equivalent of the function "eboulis()" (which is a
> > > new funtion on Splus) on R? 
> > 
> > There is no such function in the latest S-PLUS, version 6.2.
>  Further,
> > S-PLUS is an English product and `eboulis' appears to be French.
> > 
> > > Otherwise, with which function can we see the best number of
> > > cluster we have to choose?
> > 
> > Please check out where you got that function from, and give
> us a 
> > description of what you are looking for.  We cannot tell you
> the 
> > equivalent of a non-existent function (except to give you a
> list of 
> > non-existent R functions).
> > 
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > 
> > 
> 

> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ernesto at ipimar.pt  Tue May 25 15:48:06 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 25 May 2004 14:48:06 +0100
Subject: [R] RMySQL problem - SOLVED
In-Reply-To: <BCD8ADF0.83F1%sdavis2@mail.nih.gov>
References: <BCD8ADF0.83F1%sdavis2@mail.nih.gov>
Message-ID: <1085492886.32532.22.camel@gandalf.local>

Hi,

The problem was the row.names that were sent to the database and created
an primary key duplicate. Now it works fine.

BTW congratulations for the package. It copied 15300 rows by 11 columns
in less than 5 seconds, in my PIII 833 with 1 GB RAM.

> system.time(dbWriteTable(con, "TBL_SIMDATA", TBL.SIMDATA, append =
TRUE, row.names=F))
[1] 3.87 0.05 4.86 0.01 0.00
 

Just one suggestion. It would be usefull to have a more verbose output,
maybe the "LOAD DATA INFILE" output. 

Thanks for your help.

EJ


On Tue, 2004-05-25 at 13:01, Sean Davis wrote:
> I have written tables with 10,000 rows before without incident, so I'm not
> sure what is going on--out of my league.  Is this idiosyncratic to your
> data?  In other words, can you load a simple 2-column table with 10000 rows?
> If not, I would suggest writing R code to construct the 10000  row toy
> example, write the table to MySQL, and then a dbReadTable and show that the
> number of rows is incorrect and post the code and results to the list.
> 
> Sean
> 
> On 5/25/04 7:24 AM, "Ernesto Jardim" <ernesto at ipimar.pt> wrote:
> 
> > On Tue, 2004-05-25 at 11:00, Sean Davis wrote:
> >> The function that you are looking for is:
> >> 
> >> help.search("writetable")
> >> 
> >> Or whatever in quotes you like.  Also, you can try help.start() which will
> >> give you the browser window with HTML versions of docs and a search
> >> facility.  
> >> 
> >> When you say "import", what do you mean?  Reading an Rdata file, a text
> >> file, or reading from mysql?
> > 
> > I'm referring to the number of rows that R sent to MySQL with the
> > dbWriteTable method. The dataframe has 13500 rows but when I do
> > 
> >> dbWriteTable(con, "TBL_SIMDATA", TBL.SIMDATA, append = TRUE)
> > [1] TRUE
> > 
> > the TBL_SIMDATA table in MySQL has only 555 rows ...
> > 
> > EJ
> > 
> >> Sean
> >> 
> >> 
> >> On 5/25/04 5:34 AM, "Ernesto Jardim" <ernesto at ipimar.pt> wrote:
> >> 
> >>> Hi,
> >>> 
> >>> I found the dbWriteTable function.
> >>> 
> >>> Sorry for the work but I'm still trying to understand how the S4
> >>> documentation works. If you do "help(package="RMySQL")" the
> >>> "dbWriteTable" method does not exist. It exists a "dbReadTable" method
> >>> wich has an alias to "dbWriteTable". It should be intuitive but it
> >>> wasn't for me ...
> >>> 
> >>> Now the method: I could only import 555 rows ... Is there some flag
> >>> about the number of rows it can import ?
> >>> 
> >>> Regards
> >>> 
> >>> EJ 
> >>> 
> >>> On Mon, 2004-05-24 at 22:44, David James wrote:
> >>>> Hi,
> >>>> 
> >>>> The method for dbWriteTable() uses the MySQL bulk loading faciliy
> >>>> "LOAD DATA LOCAL INFILE" to efficiently upload a file into the
> >>>> server.  So you should be able to issue something like
> >>>>> sim.result <- big.simulation(...)
> >>>>> dbWriteTable(con, "table_name", sim.results, append = TRUE)
> >>>> to append the rows in sim.results into the MySQL "table_name".
> >>>> 
> >>>> However, I should mention that the currently implementation
> >>>> outputs the contents of the data.frame into a temporary file
> >>>> using the function write.table(), which in the past could be
> >>>> slow.
> >>>> 
> >>>> Hope this helps,
> >>>> 
> >>>> --
> >>>> David
> >>>> 
> >>>> Ernesto Jardim wrote:
> >>>>> Hi,
> >>>>> 
> >>>>> I'm using R 1.9.0 with RMySQL 0.5-4 and MySQL 3.23.55 on a suse 8.2 box.
> >>>>> 
> >>>>> I have a simulation study and (as usual for newbies in simulation, I
> >>>>> guess) I have a lot of data that I want to store in MySQL. I want to
> >>>>> write an R script that reads data from RData files and writes it to a
> >>>>> MySQL database.
> >>>>> 
> >>>>> I read some R documents (R Data Import/Export and DSC papers) but I'm
> >>>>> finding differences between the documents and the packages (RMySQL and
> >>>>> DBI). I don't find the methods to write data like "dbWriteTable"...
> >>>>> 
> >>>>> On the other hand I've tryied to build a sql statement to insert data
> >>>>> but I'm stucked because of ... who knows, my ignorance probably. I want
> >>>>> to take advantage of MySQl INSERT INTO statement that deals with several
> >>>>> rows at once to insert a complete data.frame into a table. I've tryied
> >>>>> to use "paste" to build the sql string but It works "by column" and I
> >>>>> need it "by row" ...
> >>>>> 
> >>>>> The sql systax should be something like:
> >>>>> 
> >>>>> INSERT INTO TABLEA(COL1, COL2, COL3) VALUES
> >>>>> (VAL11, VAL12, VAL13),
> >>>>> (VAL21, VAL22, VAL23),
> >>>>> ...
> >>>>> (VALN1, VALN2, VALN3);
> >>>>> 
> >>>>> and I have a data.frame with 3 columns corresponding to that table
> >>>>> columns.
> >>>>> 
> >>>>> How can I do this ?
> >>>>> 
> >>>>> Thanks
> >>>>> 
> >>>>> EJ
> >>>>> 
> >>>>> ______________________________________________
> >>>>> R-help at stat.math.ethz.ch mailing list
> >>>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide!
> >>>>> http://www.R-project.org/posting-guide.html
> >>> 
> >>> ______________________________________________
> >>> R-help at stat.math.ethz.ch mailing list
> >>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide!
> >>> http://www.R-project.org/posting-guide.html
> >>> 
> >



From mihastaut at hotmail.com  Tue May 25 15:57:33 2004
From: mihastaut at hotmail.com (Miha STAUT)
Date: Tue, 25 May 2004 13:57:33 +0000
Subject: [R] Bivariate interpolation
Message-ID: <BAY2-F113FRaqbC8wSA0002cb7d@hotmail.com>

Hello,

Is there any other bivariate pointwise interpolation command besides akima's 
interpp? I tried to search through the J. Baron's page without luck.

The problem is that I have got regularly spaced data (in x and y) what is 
not acceptable for interpp.

I am not very much interested in the method of interpolation as the data are 
dense and the error would not be to high.

Thanks in advance, Miha



From acalatr at umich.edu  Tue May 25 16:11:12 2004
From: acalatr at umich.edu (Agustin Calatroni)
Date: Tue, 25 May 2004 10:11:12 -0400
Subject: [R] UseR 2004 Proceeding
Message-ID: <000001c44262$22685e70$2a7fd38d@D789L01>

In the past conference (i.e. DSC 2003) the proceedings were available
for download. This year UseR website only has the abstracts of the
papers. Does anybody know if the full text will be available for
download?

Thanks,
Agustin Calatroni ;-)



From n.bouget at laposte.net  Tue May 25 16:20:42 2004
From: n.bouget at laposte.net (n.bouget)
Date: Tue, 25 May 2004 16:20:42 +0200
Subject: [R] Agnes and Hclust
Message-ID: <HY9X6J$5291835FD81E572666593CF246C44A28@laposte.net>

Hi,

I want to know if there is a difference between the two
hierarchical methods Agnes and hclust when there are used with
the same method and the same metric on the same data! I ask
this question because I executed the following program: 
hc <- hclust(dist(AGRIINSTTableFinaleCR), "ward")
agnes<-agnes(dist(AGRIINSTTableFinaleCR),method="ward")
And clusters are not the same even if they are a little similar!

Is anybody know why i have this difference?

Thanks in advance

Nicolas BOUGET 


From MSchwartz at MedAnalytics.com  Tue May 25 16:24:54 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 25 May 2004 09:24:54 -0500
Subject: [R] UseR 2004 Proceeding
In-Reply-To: <000001c44262$22685e70$2a7fd38d@D789L01>
References: <000001c44262$22685e70$2a7fd38d@D789L01>
Message-ID: <1085495094.7195.84.camel@localhost.localdomain>

On Tue, 2004-05-25 at 09:11, Agustin Calatroni wrote:
> In the past conference (i.e. DSC 2003) the proceedings were available
> for download. This year UseR website only has the abstracts of the
> papers. Does anybody know if the full text will be available for
> download?
> 
> Thanks,
> Agustin Calatroni ;-)


According to an announcement made on Saturday there will not be a
proceedings.

Some authors may post their complete presentation on their web sites
(where available) or perhaps may be willing to e-mail their presentation
in PDF format. You may be best served to contact the author(s) directly,
if there is a particular paper you are interested in.

HTH,

Marc Schwartz



From klemens.barfus at gmx.de  Tue May 25 16:28:14 2004
From: klemens.barfus at gmx.de (Klemens Barfus)
Date: Tue, 25 May 2004 16:28:14 +0200 (MEST)
Subject: [R] Description of profiles ?
References: <200405251003.i4PA0nag023381@hypatia.math.ethz.ch>
Message-ID: <8460.1085495294@www10.gmx.net>

Hello together,
I am working on liquid water profiles of clouds and would like to describe
these profiles in relation to a reference profile.
What is the best way to do this ? RMSE would equal positiv and negativ
deviations. Is it better to use a correlation coefficient ?
What is the best way, espacially when I want to find out profiles with the
same behaviour / shape, which are just more or less shifted / just have a
different mean value ?
Thanks for your help in advance !

Klemens

Dipl.-Geogr. Klemens Barfus
Institute for Hydrology and Meteorology
Technical University of Dresden
Germany

--



From edd at debian.org  Tue May 25 16:53:35 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 25 May 2004 09:53:35 -0500
Subject: [R] Tramo-seats support in GRETL, but not R
In-Reply-To: <OFD10BF78C.76AD243C-ON85256E9F.004062CD-85256E9F.0042DA93@ci.orlando.fl.us>
References: <200405251001.i4PA0na6023381@hypatia.math.ethz.ch>
	<OFD10BF78C.76AD243C-ON85256E9F.004062CD-85256E9F.0042DA93@ci.orlando.fl.us>
Message-ID: <20040525145335.GA10029@sonny.eddelbuettel.com>


FYI: GNU Gretl and GNU R are on every Debian mirror. My Quantian cdroms also
have x12a (deb package derived from the rpm on Cottrell's gretl site) which
is way less awkward to use via gretl than directly.  

However, tramo-seat _cannot_ be redistributed freely due to license issues.
Pity. If anybody feels like petitioning the good folks at the Bank of Spain,
go for it.

Regards, Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From qamruz.zaman at uibk.ac.at  Tue May 25 17:22:44 2004
From: qamruz.zaman at uibk.ac.at (Qamruz Zaman)
Date: Tue, 25 May 2004 17:22:44 +0200
Subject: [R] code for functions in base package
Message-ID: <40B364C4.1070606@uibk.ac.at>

Hello
My name is qamruz zaman and i want to see the codes of Kaplan meier and 
Bootstrap. Is it possible, if yes then please guide me step by step and 
also show me how to write my own functions.
Bye



From thpe at hhbio.wasser.tu-dresden.de  Tue May 25 17:25:37 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Tue, 25 May 2004 17:25:37 +0200
Subject: [R] adress the current index
In-Reply-To: <200405242205.23750.ferri.leberl@gmx.at>
References: <200405242205.23750.ferri.leberl@gmx.at>
Message-ID: <40B36571.6030005@hhbio.wasser.tu-dresden.de>

Mag. Ferri Leberl wrote:

> How can I adress the current index of a vector?
> 
> I want to work with time series and therefore give the n-th element of a 
> vector some value dependent on the value of the n-1th element.

Sorry, your question is not really clear, but possibly the following may 
help:

1) If you have a vector x, you can create a shifted vector by removing 
the first element, e.g.:

xnew <- x[-1] + somevalue # or apply a function f(x[-1])

2) The last element can be removed with:

xnew <- x[-length(x)]

3) ... and sometimes vector concatenation ?c or the ?ifelse function can 
be useful in such circumstances.

Thomas P.

PS: there is more about such things in the docs.



From sje at mast.queensu.ca  Tue May 25 17:37:15 2004
From: sje at mast.queensu.ca (Stoyan Iliev)
Date: Tue, 25 May 2004 11:37:15 -0400
Subject: [R] readline
Message-ID: <40B3682B.3030306@mast.queensu.ca>

problem: readline does not work

background: readline installed OK. R found it and listed as available 
library. when I start R none of the readline command editing is 
available, just raw "sh" editing.
system: Solaris 9 on Sparc

any help is appreciated.
thanks
stoyan



From angel_lul at hotmail.com  Tue May 25 19:38:38 2004
From: angel_lul at hotmail.com (Angel Lopez)
Date: Tue, 25 May 2004 19:38:38 +0200
Subject: [R] Bivariate interpolation
In-Reply-To: <BAY2-F113FRaqbC8wSA0002cb7d@hotmail.com>
References: <BAY2-F113FRaqbC8wSA0002cb7d@hotmail.com>
Message-ID: <40B3849E.4040803@hotmail.com>

library(fields)
?interp.surface

Best,
Angel

Miha STAUT wrote:
> Hello,
> 
> Is there any other bivariate pointwise interpolation command besides 
> akima's interpp? I tried to search through the J. Baron's page without 
> luck.
> 
> The problem is that I have got regularly spaced data (in x and y) what 
> is not acceptable for interpp.
> 
> I am not very much interested in the method of interpolation as the data 
> are dense and the error would not be to high.
> 
> Thanks in advance, Miha
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> .
>



From wolski at molgen.mpg.de  Tue May 25 17:38:10 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Tue, 25 May 2004 17:38:10 +0200
Subject: [R] Object "silhouette.default" not found. But I knew that it is
 there.
Message-ID: <200405251738100965.01E957A7@mail.math.fu-berlin.de>

Hi!

 
>library(cluster)
In this lib a function called silhoutte.default is defined
than on the R prompt it type
>silhouette.default
Error: Object "silhouette.default" not found 
R1.9.0
The same error are at R1.8.1
And I knew that a function silhoutte.default are present.

But the same piece of code works in R1.6.2

???

Eryk

Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From paulojus at est.ufpr.br  Tue May 25 17:42:07 2004
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Tue, 25 May 2004 12:42:07 -0300 (BRT)
Subject: [R] readline
In-Reply-To: <40B3682B.3030306@mast.queensu.ca>
References: <40B3682B.3030306@mast.queensu.ca>
Message-ID: <Pine.LNX.4.58L0.0405251241210.5805@est.ufpr.br>

have you installed readline-dev ?

In my Debian Linux I need
libreadlin4-dev

Cheers
P.J.

On Tue, 25 May 2004, Stoyan Iliev wrote:

> problem: readline does not work
>
> background: readline installed OK. R found it and listed as available
> library. when I start R none of the readline command editing is
> available, just raw "sh" editing.
> system: Solaris 9 on Sparc
>
> any help is appreciated.
> thanks
> stoyan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat??stica
Universidade Federal do Paran??
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From gruen at ci.tuwien.ac.at  Tue May 25 17:43:56 2004
From: gruen at ci.tuwien.ac.at (Bettina Gruen)
Date: Tue, 25 May 2004 17:43:56 +0200
Subject: [R] useR! 2004 pictures online
Message-ID: <40B369BC.6070300@ci.tuwien.ac.at>

Dear useRs,

pictures from the first R user conference useR! 2004 are now available
online at the conference web page:

http://www.ci.tuwien.ac.at/Conferences/useR-2004/Photos/index.html	

Pictures from other participants will be included on the web page if 
they are sent to me. Feel free to contribute!

Best wishes,
Bettina



From ligges at statistik.uni-dortmund.de  Tue May 25 18:17:11 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 25 May 2004 18:17:11 +0200
Subject: [R] Object "silhouette.default" not found. But I knew that it
	is there.
In-Reply-To: <200405251738100965.01E957A7@mail.math.fu-berlin.de>
References: <200405251738100965.01E957A7@mail.math.fu-berlin.de>
Message-ID: <40B37187.2080408@statistik.uni-dortmund.de>

Wolski wrote:

> Hi!
> 
>  
> 
>>library(cluster)
> 
> In this lib a function called silhoutte.default is defined
> than on the R prompt it type
> 
>>silhouette.default
> 
> Error: Object "silhouette.default" not found 
> R1.9.0
> The same error are at R1.8.1
> And I knew that a function silhoutte.default are present.
> 
> But the same piece of code works in R1.6.2
> 
> ???

Well, namespaces have been introduced in the meantime, and you have 
learned at the useR to call the generic silhouette() directly
or to use
    cluster:::silhouette.default
to get the code.

Uwe Ligges



> Eryk
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
> Ihnestrasse 63-73 14195 Berlin       'v'    
> tel: 0049-30-83875219               /   \    
> mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From wolski at molgen.mpg.de  Tue May 25 18:29:21 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Tue, 25 May 2004 18:29:21 +0200
Subject: [R] Object "silhouette.default" not found. But I knew
	that it is there.
In-Reply-To: <40B37187.2080408@statistik.uni-dortmund.de>
References: <200405251738100965.01E957A7@mail.math.fu-berlin.de>
	<40B37187.2080408@statistik.uni-dortmund.de>
Message-ID: <200405251829210875.0218304A@mail.math.fu-berlin.de>

Hi!

Thanks! You right. Have not realised it.

I do not wanted to call the function but I wanted to see the function definition. Its a great feature of R to be able to do it.
I knew I cant do it because the function object is not in the namespace.
Ive been confronted with the reverse side of namespaces.

On the other hand: 
?silhouette.default  works.
It would be nice to have a way to display to source without going into the library directory.



Sincerely
Eryk

PS.


*********** REPLY SEPARATOR  ***********

On 5/25/2004 at 6:17 PM Uwe Ligges wrote:

>Wolski wrote:
>
>> Hi!
>> 
>>  
>> 
>>>library(cluster)
>> 
>> In this lib a function called silhoutte.default is defined
>> than on the R prompt it type
>> 
>>>silhouette.default
>> 
>> Error: Object "silhouette.default" not found 
>> R1.9.0
>> The same error are at R1.8.1
>> And I knew that a function silhoutte.default are present.
>> 
>> But the same piece of code works in R1.6.2
>> 
>> ???
>
>Well, namespaces have been introduced in the meantime, and you have 
>learned at the useR to call the generic silhouette() directly
>or to use
>    cluster:::silhouette.default
>to get the code.
>
>Uwe Ligges
>
>
>
>> Eryk
>> 
>> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
>> Ihnestrasse 63-73 14195 Berlin       'v'    
>> tel: 0049-30-83875219               /   \    
>> mail: wolski at molgen.mpg.de        ---W-W----   
>http://www.molgen.mpg.de/~wolski
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From ligges at statistik.uni-dortmund.de  Tue May 25 18:38:47 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 25 May 2004 18:38:47 +0200
Subject: [R] Object "silhouette.default" not found. But I knew	that it
	is there.
In-Reply-To: <200405251829210875.0218304A@mail.math.fu-berlin.de>
References: <200405251738100965.01E957A7@mail.math.fu-berlin.de>	<40B37187.2080408@statistik.uni-dortmund.de>
	<200405251829210875.0218304A@mail.math.fu-berlin.de>
Message-ID: <40B37697.7010806@statistik.uni-dortmund.de>

Wolski wrote:

> Hi!
> 
> Thanks! You right. Have not realised it.
> 
> I do not wanted to call the function but I wanted to see the function definition. Its a great feature of R to be able to do it.
> I knew I cant do it because the function object is not in the namespace.
> Ive been confronted with the reverse side of namespaces.
> 
> On the other hand: 
> ?silhouette.default  works.
> It would be nice to have a way to display to source without going into the library directory.

I just told you (and Fritz did so last week in his keynote lecture) to 
specify the namespace explicitly using the ":::" operator as in:

  cluster:::silhouette.default

and you will see the source, so what's the point?

Uwe



> 
> 
> Sincerely
> Eryk
> 
> PS.
> 
> 
> *********** REPLY SEPARATOR  ***********
> 
> On 5/25/2004 at 6:17 PM Uwe Ligges wrote:
> 
> 
>>Wolski wrote:
>>
>>
>>>Hi!
>>>
>>> 
>>>
>>>
>>>>library(cluster)
>>>
>>>In this lib a function called silhoutte.default is defined
>>>than on the R prompt it type
>>>
>>>
>>>>silhouette.default
>>>
>>>Error: Object "silhouette.default" not found 
>>>R1.9.0
>>>The same error are at R1.8.1
>>>And I knew that a function silhoutte.default are present.
>>>
>>>But the same piece of code works in R1.6.2
>>>
>>>???
>>
>>Well, namespaces have been introduced in the meantime, and you have 
>>learned at the useR to call the generic silhouette() directly
>>or to use
>>   cluster:::silhouette.default
>>to get the code.
>>
>>Uwe Ligges
>>
>>
>>
>>
>>>Eryk
>>>
>>>Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
>>>Ihnestrasse 63-73 14195 Berlin       'v'    
>>>tel: 0049-30-83875219               /   \    
>>>mail: wolski at molgen.mpg.de        ---W-W----   
>>
>>http://www.molgen.mpg.de/~wolski
>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>
>>http://www.R-project.org/posting-guide.html
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> 
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
> Ihnestrasse 63-73 14195 Berlin       'v'    
> tel: 0049-30-83875219               /   \    
> mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Tue May 25 18:39:13 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 25 May 2004 18:39:13 +0200
Subject: [R] Object "silhouette.default" not found...
 there.
In-Reply-To: <200405251738100965.01E957A7@mail.math.fu-berlin.de>
References: <200405251738100965.01E957A7@mail.math.fu-berlin.de>
Message-ID: <16563.30385.213721.539203@gargle.gargle.HOWL>


>>>>> "Eryk" == Eryk Wolski <wolski at molgen.mpg.de>
>>>>>     on Tue, 25 May 2004 17:38:10 +0200 writes:

    Eryk> Hi!
    >> library(cluster)
    Eryk> In this lib a function called silhoutte.default is defined
    Eryk> than on the R prompt it type
    >> silhouette.default
    Eryk> Error: Object "silhouette.default" not found 
    Eryk> R1.9.0
    Eryk> The same error are at R1.8.1
    Eryk> And I knew that a function silhoutte.default are present.

Hi Eryk,

please do learn about namespaces;  many good R packages (incl.
all standard and recommended packages) nowadays make use of
namespaces, and we expect even more in the future.

One big advantage of 'namespacing a package' is that
you can make sure that your functions call your other functions
even if they have the same name as someone's functions in
another package.  Another big "pro" is that you can use as many
``package-internal'' objects {"helper-functions" in my useR talk}
as you want: They won't be visible to the user and not clutter
the global namespace.
One side effect of namespaces: We usually do not export (S3)
methods such as silhouette.default() :

A user should call silhouette(...) and the method dispatching
chooses the corresponding method.

Now, to see "hidden" objects, you can 

1) use  getAnywhere()	        { getAnywhere("silhouette.default") }
2) use  <namespace>:::<object>  { cluster:::silhouette.default }

and for S3 methods,

3) getS3method("<generic>", "<class>")

   i.e., in this case getS3method("silhouette", "default")

----------

BUT:  You won't see the source code of silhouette.default !

Instead:

  1) Learn how to get and unpack the package source and then
     see    cluster/R/silhouette.R

  2) if "1)" is too difficult,
     open the filename you get from
	   system.file("../cluster/R/cluster")
     in a text editor -- preferably an R-aware one ...
     which gives you a large file with all R source from the
     cluster package.   Now look for what you want.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From karruo at utu.fi  Tue May 25 18:42:56 2004
From: karruo at utu.fi (Kari Ruohonen)
Date: Tue, 25 May 2004 19:42:56 +0300
Subject: [R] debian packages and html help on linux
Message-ID: <87k6z0ihkf.fsf@utu.fi>

I have a fresh installation of R from debian unstable packages. The
html index found in /usr/lib/R/doc/html/index.html works in Mozilla
and under the link of 'packages' on this page I have a list and
corresponding links. However, it appears that not all packages I have
installed from available deb files via apt-get, will get their link
updated to this package index. Specifically, from packages
r-cran-boot, r-cran-car, r-cran-coda, r-cran-design, r-cran-effects,
r-cran-foreign, r-cran-gregmisc, r-cran-hmisc, r-cran-its,
r-cran-lattice, r-cran-lmtest, r-cran-mcmcpack, r-cran-mgcv,
r-cran-multcomp, r-cran-relimp, r-cran-rgl, r-cran-rpart, r-cran-sm,
r-cran-tseries, r-cran-vr, r-omegahat-ggobi, r-cran-kernsmooth none
appeared to html package index. This also means that html search
doesn't find functions within these packages although it otherwise
works perfectly with my Mozilla.

What shall I do to get also these package to the package index?

Regards, Kari Ruohonen



From wolski at molgen.mpg.de  Tue May 25 18:56:38 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Tue, 25 May 2004 18:56:38 +0200
Subject: [R] Object "silhouette.default" not found... there.
In-Reply-To: <16563.30385.213721.539203@gargle.gargle.HOWL>
References: <200405251738100965.01E957A7@mail.math.fu-berlin.de>
	<16563.30385.213721.539203@gargle.gargle.HOWL>
Message-ID: <200405251856380708.02312A2B@mail.math.fu-berlin.de>

Hallo!

Thanks too James Holtman, Douglas Grove, Uwe Ligges, Martin Maechler,  for helpfull answers
to my questions.

Sincerely
Eryk

*********** REPLY SEPARATOR  ***********

On 5/25/2004 at 6:39 PM Martin Maechler wrote:

>>>>>> "Eryk" == Eryk Wolski <wolski at molgen.mpg.de>
>>>>>>     on Tue, 25 May 2004 17:38:10 +0200 writes:
>
>    Eryk> Hi!
>    >> library(cluster)
>    Eryk> In this lib a function called silhoutte.default is defined
>    Eryk> than on the R prompt it type
>    >> silhouette.default
>    Eryk> Error: Object "silhouette.default" not found 
>    Eryk> R1.9.0
>    Eryk> The same error are at R1.8.1
>    Eryk> And I knew that a function silhoutte.default are present.
>
>Hi Eryk,
>
>please do learn about namespaces;  many good R packages (incl.
>all standard and recommended packages) nowadays make use of
>namespaces, and we expect even more in the future.
>
>One big advantage of 'namespacing a package' is that
>you can make sure that your functions call your other functions
>even if they have the same name as someone's functions in
>another package.  Another big "pro" is that you can use as many
>``package-internal'' objects {"helper-functions" in my useR talk}
>as you want: They won't be visible to the user and not clutter
>the global namespace.
>One side effect of namespaces: We usually do not export (S3)
>methods such as silhouette.default() :
>
>A user should call silhouette(...) and the method dispatching
>chooses the corresponding method.
>
>Now, to see "hidden" objects, you can 
>
>1) use  getAnywhere()	        { getAnywhere("silhouette.default") }
>2) use  <namespace>:::<object>  { cluster:::silhouette.default }
>
>and for S3 methods,
>
>3) getS3method("<generic>", "<class>")
>
>   i.e., in this case getS3method("silhouette", "default")
>
>----------
>
>BUT:  You won't see the source code of silhouette.default !
>
>Instead:
>
>  1) Learn how to get and unpack the package source and then
>     see    cluster/R/silhouette.R
>
>  2) if "1)" is too difficult,
>     open the filename you get from
>	   system.file("../cluster/R/cluster")
>     in a text editor -- preferably an R-aware one ...
>     which gives you a large file with all R source from the
>     cluster package.   Now look for what you want.
>
>Regards,
>Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
>Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
>ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
>phone: x-41-1-632-3408		fax: ...-1228			<><



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From tpapp at axelero.hu  Tue May 25 18:55:59 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Tue, 25 May 2004 18:55:59 +0200
Subject: [R] Object "silhouette.default" not found... there.
In-Reply-To: <16563.30385.213721.539203@gargle.gargle.HOWL>
References: <200405251738100965.01E957A7@mail.math.fu-berlin.de>
	<16563.30385.213721.539203@gargle.gargle.HOWL>
Message-ID: <20040525165559.GA1111@localhost>

On Tue, May 25, 2004 at 06:39:13PM +0200, Martin Maechler wrote:

> please do learn about namespaces;  many good R packages (incl.
> all standard and recommended packages) nowadays make use of
> namespaces, and we expect even more in the future.

I also want to learn about namespaces.  I have looked at ?":::", but I
think that a tutorial-like document would help me apply and understand
namespaces better.  So where should I look for "a gentle introduction
to namespaces", with examples, if there is such a thing?

Tamas

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From tpapp at axelero.hu  Tue May 25 19:01:37 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Tue, 25 May 2004 19:01:37 +0200
Subject: [R] code for functions in base package
In-Reply-To: <40B364C4.1070606@uibk.ac.at>
References: <40B364C4.1070606@uibk.ac.at>
Message-ID: <20040525170137.GB1111@localhost>

On Tue, May 25, 2004 at 05:22:44PM +0200, Qamruz Zaman wrote:

> Hello
> My name is qamruz zaman and i want to see the codes of Kaplan meier and 
> Bootstrap. Is it possible, if yes then please guide me step by step and 
> also show me how to write my own functions.
> Bye
>
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

Please read the posting guide, and the Introduction to R.  It will
provide a very detailed introduction to writing your own functions
(and to R in general).

Simply typing the function name at the R prompt will display the
source code of the function (unless it was not exported, then use
getAnywhere).

Best,

Tamas

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From ripley at stats.ox.ac.uk  Tue May 25 19:14:42 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 May 2004 18:14:42 +0100 (BST)
Subject: [R] debian packages and html help on linux
In-Reply-To: <87k6z0ihkf.fsf@utu.fi>
Message-ID: <Pine.LNX.4.44.0405251803020.2728-100000@gannet.stats>

On Tue, 25 May 2004, Kari Ruohonen wrote:

> I have a fresh installation of R from debian unstable packages. The
> html index found in /usr/lib/R/doc/html/index.html works in Mozilla
> and under the link of 'packages' on this page I have a list and
> corresponding links. However, it appears that not all packages I have
> installed from available deb files via apt-get, will get their link
> updated to this package index. Specifically, from packages
> r-cran-boot, r-cran-car, r-cran-coda, r-cran-design, r-cran-effects,
> r-cran-foreign, r-cran-gregmisc, r-cran-hmisc, r-cran-its,
> r-cran-lattice, r-cran-lmtest, r-cran-mcmcpack, r-cran-mgcv,
> r-cran-multcomp, r-cran-relimp, r-cran-rgl, r-cran-rpart, r-cran-sm,
> r-cran-tseries, r-cran-vr, r-omegahat-ggobi, r-cran-kernsmooth none
> appeared to html package index. This also means that html search
> doesn't find functions within these packages although it otherwise
> works perfectly with my Mozilla.
> 
> What shall I do to get also these package to the package index?

Use the correct index: see ?help.start.  Installing a package does not 
update /usr/lib/R/doc/html/packages.html, but help.start() creates a 
current index dynamically.

If you really want to do this without running R, use

R CMD perl /usr/lib/R/share/perl/build-help.pl --htmllists

to update the static index.  From inside R you can run 
make.packages.html().  In both cases, you need write permission in 
/usr/lib/R/doc/html.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From edd at debian.org  Tue May 25 19:43:18 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 25 May 2004 12:43:18 -0500
Subject: [R] debian packages and html help on linux
In-Reply-To: <Pine.LNX.4.44.0405251803020.2728-100000@gannet.stats>
References: <87k6z0ihkf.fsf@utu.fi>
	<Pine.LNX.4.44.0405251803020.2728-100000@gannet.stats>
Message-ID: <20040525174318.GA12101@sonny.eddelbuettel.com>

On Tue, May 25, 2004 at 06:14:42PM +0100, Prof Brian Ripley wrote:
> On Tue, 25 May 2004, Kari Ruohonen wrote:
> 
> > I have a fresh installation of R from debian unstable packages. The
> > html index found in /usr/lib/R/doc/html/index.html works in Mozilla
> > and under the link of 'packages' on this page I have a list and
> > corresponding links. However, it appears that not all packages I have
> > installed from available deb files via apt-get, will get their link
> > updated to this package index. Specifically, from packages
> > r-cran-boot, r-cran-car, r-cran-coda, r-cran-design, r-cran-effects,
> > r-cran-foreign, r-cran-gregmisc, r-cran-hmisc, r-cran-its,
> > r-cran-lattice, r-cran-lmtest, r-cran-mcmcpack, r-cran-mgcv,
> > r-cran-multcomp, r-cran-relimp, r-cran-rgl, r-cran-rpart, r-cran-sm,
> > r-cran-tseries, r-cran-vr, r-omegahat-ggobi, r-cran-kernsmooth none
> > appeared to html package index. This also means that html search
> > doesn't find functions within these packages although it otherwise
> > works perfectly with my Mozilla.
> > 
> > What shall I do to get also these package to the package index?
> 
> Use the correct index: see ?help.start.  Installing a package does not 
> update /usr/lib/R/doc/html/packages.html, but help.start() creates a 
> current index dynamically.
> 
> If you really want to do this without running R, use
> 
> R CMD perl /usr/lib/R/share/perl/build-help.pl --htmllists
> 
> to update the static index.  From inside R you can run 
> make.packages.html().  In both cases, you need write permission in 
> /usr/lib/R/doc/html.

That sounds like something we could easily execute via the postinst script
once the package as been unpacked. As that step runs as root, permissions
would not be an issue.

Would that step alleviate the need for the per-user ~/.R/ index ?

Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From cashaw at bcm.tmc.edu  Tue May 25 19:52:20 2004
From: cashaw at bcm.tmc.edu (Chad Shaw)
Date: Tue, 25 May 2004 12:52:20 -0500
Subject: [R] thanks again
Message-ID: <40B387D4.7050802@bcm.tmc.edu>

Achim:

Thanks again for the conference.  We had good fun.

I have 2 requests:
1)  I'd like to email my R-foundation membership to you.
I will scan the form and send just like I did for the meeting.

2)  I want a useR t-shirt.  After lots of drinking and discussion with 
Fritz Leisch at dinner on saturday, I feel there will be no chance for 
an official T-shirt.

My question is:  any advice/ thoughts on how there can be T-shirts for 
the conference?

Chad



From ecashin at uga.edu  Tue May 25 19:55:31 2004
From: ecashin at uga.edu (Ed L Cashin)
Date: Tue, 25 May 2004 13:55:31 -0400
Subject: [R] accessing function arguments as text, macro style
Message-ID: <87d64sl7cc.fsf@uga.edu>

Hi.  In a case like this, I can get strip headings that have the name
"c" and the value for c.

  d <- data.frame(a=1:5,b=6:10,c=11:15)
  > xyplot(a ~ b | paste("c", c), data=d)
  > 

For more complicated examples, instead of using paste repeatedly I
would like to use a function.  It seems like what I really want is a
macro, though.  I'm not quite familiar enough with R's treatment of
function parameters to know how to do something like this (ficticious
example):

  f <- function(x) { paste(identifier(x), value(x)) }
  > rambo <- "brave"
  > f(rambo)
  "rambo brave"

I've checked ?function, ?args, ?eval, and some others, but I think
I'm barking up the wrong tree.  Any pointers would be most
appreciated. 
  
-- 
--Ed L Cashin            |   PGP public key:
  ecashin at uga.edu        |   http://noserose.net/e/pgp/



From ggrothendieck at myway.com  Tue May 25 20:15:50 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 25 May 2004 18:15:50 +0000 (UTC)
Subject: [R] accessing function arguments as text, macro style
References: <87d64sl7cc.fsf@uga.edu>
Message-ID: <loom.20040525T201511-168@post.gmane.org>

Ed L Cashin <ecashin <at> uga.edu> writes:
> function parameters to know how to do something like this (ficticious
> example):
> 
>   f <- function(x) { paste(identifier(x), value(x)) }
>   > rambo <- "brave"
>   > f(rambo)
>   "rambo brave"


R> f <- function(x) paste(as.character(substitute(x)),x)
R> z <- 3
R> f(z)
[1] "z 3"



From ecashin at uga.edu  Tue May 25 20:22:22 2004
From: ecashin at uga.edu (Ed L Cashin)
Date: Tue, 25 May 2004 14:22:22 -0400
Subject: [R] accessing function arguments as text, macro style
References: <87d64sl7cc.fsf@uga.edu> <loom.20040525T201511-168@post.gmane.org>
Message-ID: <877jv0l63l.fsf@uga.edu>

Gabor Grothendieck <ggrothendieck at myway.com> writes:

...
> R> f <- function(x) paste(as.character(substitute(x)),x)
> R> z <- 3
> R> f(z)
> [1] "z 3"

Fantastic.  Works like a charm.  

-- 
--Ed L Cashin            |   PGP public key:
  ecashin at uga.edu        |   http://noserose.net/e/pgp/



From ripley at stats.ox.ac.uk  Tue May 25 20:29:42 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 May 2004 19:29:42 +0100 (BST)
Subject: [R] debian packages and html help on linux
In-Reply-To: <20040525174318.GA12101@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.44.0405251925080.2915-100000@gannet.stats>

On Tue, 25 May 2004, Dirk Eddelbuettel wrote:

> On Tue, May 25, 2004 at 06:14:42PM +0100, Prof Brian Ripley wrote:
> > On Tue, 25 May 2004, Kari Ruohonen wrote:
> > 
> > > I have a fresh installation of R from debian unstable packages. The
> > > html index found in /usr/lib/R/doc/html/index.html works in Mozilla
> > > and under the link of 'packages' on this page I have a list and
> > > corresponding links. However, it appears that not all packages I have
> > > installed from available deb files via apt-get, will get their link
> > > updated to this package index. Specifically, from packages
> > > r-cran-boot, r-cran-car, r-cran-coda, r-cran-design, r-cran-effects,
> > > r-cran-foreign, r-cran-gregmisc, r-cran-hmisc, r-cran-its,
> > > r-cran-lattice, r-cran-lmtest, r-cran-mcmcpack, r-cran-mgcv,
> > > r-cran-multcomp, r-cran-relimp, r-cran-rgl, r-cran-rpart, r-cran-sm,
> > > r-cran-tseries, r-cran-vr, r-omegahat-ggobi, r-cran-kernsmooth none
> > > appeared to html package index. This also means that html search
> > > doesn't find functions within these packages although it otherwise
> > > works perfectly with my Mozilla.
> > > 
> > > What shall I do to get also these package to the package index?
> > 
> > Use the correct index: see ?help.start.  Installing a package does not 
> > update /usr/lib/R/doc/html/packages.html, but help.start() creates a 
> > current index dynamically.
> > 
> > If you really want to do this without running R, use
> > 
> > R CMD perl /usr/lib/R/share/perl/build-help.pl --htmllists
> > 
> > to update the static index.  From inside R you can run 
> > make.packages.html().  In both cases, you need write permission in 
> > /usr/lib/R/doc/html.
> 
> That sounds like something we could easily execute via the postinst script
> once the package as been unpacked. As that step runs as root, permissions
> would not be an issue.

Might be a good idea.  R (except on Windows/MacOSX) is not really set up 
for binary package installs, but on Windows install.packages() does the 
R-level equivalent (and I remembered wrongly: on Unix make.packages.html() 
works in tmpdir/.R).

> Would that step alleviate the need for the per-user ~/.R/ index ?

Actually, it is per-session in a tempdir these days.  Not really, as
there can be several library trees in use.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From phgrosjean at sciviews.org  Tue May 25 20:38:29 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 25 May 2004 20:38:29 +0200
Subject: [R] Update of the R GUI projects web site
Message-ID: <MABBLJDICACNFOLGIHJOKEHFEHAA.phgrosjean@sciviews.org>

Hi all,

GUIs for R is an active field of research, as illustrated by contributions
in this topic at the recent UseR! conference. I have just updated
http://www.r-project.org/GUI to reflect changes and new projects like JGR,
wxPython, Rho and SciViews-R.
Best,

Philippe Grosjean

.......................................................<??}))><....
 ) ) ) ) )
( ( ( ( (   Prof. Philippe Grosjean
\  ___   )
 \/ECO\ (   Numerical Ecology of Aquatic Systems
 /\___/  )  Mons-Hainaut University, Pentagone
/ ___  /(   8, Av. du Champ de Mars, 7000 Mons, Belgium
 /NUM\/  )
 \___/\ (   phone: + 32.65.37.34.97, fax: + 32.65.37.33.12
       \ )  email: Philippe.Grosjean at umh.ac.be
 ) ) ) ) )  SciViews project coordinator (http://www.sciviews.org)
( ( ( ( (
...................................................................



From phgrosjean at sciviews.org  Tue May 25 20:41:05 2004
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 25 May 2004 20:41:05 +0200
Subject: [R] thanks again
In-Reply-To: <40B387D4.7050802@bcm.tmc.edu>
Message-ID: <MABBLJDICACNFOLGIHJOMEHGEHAA.phgrosjean@sciviews.org>

Chad,

Do not forget that, due to the contaminant character of the GPL license, if
you put a R logo on a t-shirt, you have to share and distribute it freely to
the community,... and do not forget to distribute the source with it ;-)

Best,

Philippe Grosjean

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Chad Shaw
Sent: Tuesday, 25 May, 2004 19:52
To: r-help at stat.math.ethz.ch
Subject: [R] thanks again


Achim:

Thanks again for the conference.  We had good fun.

I have 2 requests:
1)  I'd like to email my R-foundation membership to you.
I will scan the form and send just like I did for the meeting.

2)  I want a useR t-shirt.  After lots of drinking and discussion with
Fritz Leisch at dinner on saturday, I feel there will be no chance for
an official T-shirt.

My question is:  any advice/ thoughts on how there can be T-shirts for
the conference?

Chad

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From gunter.berton at gene.com  Tue May 25 20:51:45 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 25 May 2004 11:51:45 -0700
Subject: [R] accessing function arguments as text, macro style
References: <87d64sl7cc.fsf@uga.edu> <loom.20040525T201511-168@post.gmane.org>
	<877jv0l63l.fsf@uga.edu>
Message-ID: <40B395C1.76791A7A@gene.com>

This solution may not quite work as you intend. I believe that the preferred
solution is:
 f <- function(x) paste(deparse(substitute(x)),x)

This would give the same result with the z<-3 example below, but try it for both
versions with the call:
f(sin(3))

The subtlety is that substitute returns the parse TREE of its
(expression)argument, which you probably want deparsed rather than cast by
as.character().

Cheers,
Bert

Ed L Cashin wrote:

> Gabor Grothendieck <ggrothendieck at myway.com> writes:
>
> ...
> > R> f <- function(x) paste(as.character(substitute(x)),x)
> > R> z <- 3
> > R> f(z)
> > [1] "z 3"
>
> Fantastic.  Works like a charm.
>
> --
> --Ed L Cashin            |   PGP public key:
>   ecashin at uga.edu        |   http://noserose.net/e/pgp/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

--

Bert Gunter

Non-Clinical Biostatistics
Genentech
MS: 240B
Phone: 650-467-7374


"The business of the statistician is to catalyze the scientific learning
process."

 -- George E.P. Box



From rolf at math.unb.ca  Tue May 25 21:32:07 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 25 May 2004 16:32:07 -0300 (ADT)
Subject: [R] (OT) Fourier coefficients.
Message-ID: <200405251932.i4PJW7PM028491@erdos.math.unb.ca>

This posting has nothing to do with R (except maybe that I am using R
very heavily in writing the paper to which the question pertains.)  I
simply wish to draw upon the impressive knowledge and wisdom of the R
community.

Since this question is way off topic, if anybody has the urge to
reply, they should probably email me directly:

			rolf at math.unb.ca

rather than via this list.

My question is essentially about Fourier coefficients:

Suppose

                   pi
                   /
	2*pi*a_k = | f(omega)*exp(-i*k*omega) d omega
                   /
                  -pi

and
                   pi
                   /
	2*pi*b_k = | G(omega)*f(omega)*exp(-i*k*omega) d omega
                   /
                  -pi

(The ``*''-s just mean multiplication here, not convolution; i is
of course sqrt(-1).)

The function f() is positive and symmetric about 0 (it's actually
a spectral density function) and G() is the gain of a nice (ARMA)
filter

                   | p(exp(i*omega) |^2
	G(omega) = | -------------- |
                   | q(exp(i*omega) |

where p() and q() are polynomials (with real coefficients); q() has
no zeroes inside the unit disk.

Suppose that the a_k satisfy an asymptotic condition:
a_k * ln k ---> 0 as k ---> infinity.  (The ``Berman condition''.)

Can I say that the b_k satisfy this condition?  If not, where
would I look for a counter-example?  And could I add some extra
not-too-stringent restrictions on the spectrum f() so that I
***could*** say that the b_k satisfy the Berman condition?

Any hints gratefully received.

					cheers,

						Rolf Turner
						rolf at math.unb.ca



From ligges at statistik.uni-dortmund.de  Tue May 25 21:59:46 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 25 May 2004 21:59:46 +0200
Subject: [R] Object "silhouette.default" not found... there.
In-Reply-To: <20040525165559.GA1111@localhost>
References: <200405251738100965.01E957A7@mail.math.fu-berlin.de>	<16563.30385.213721.539203@gargle.gargle.HOWL>
	<20040525165559.GA1111@localhost>
Message-ID: <40B3A5B2.2080306@statistik.uni-dortmund.de>

Tamas Papp wrote:
> On Tue, May 25, 2004 at 06:39:13PM +0200, Martin Maechler wrote:
> 
> 
>>please do learn about namespaces;  many good R packages (incl.
>>all standard and recommended packages) nowadays make use of
>>namespaces, and we expect even more in the future.
> 

For example in R News:

@Article{Rnews:Tierney:2003,
   author       = {Luke Tierney},
   title	       = {Name Space Management for {R}},
   journal      = {R News},
   year	       = 2003,
   volume       = 3,
   number       = 1,
   pages	       = {2--6},
   month	       = {June},
   url	       = {http://CRAN.R-project.org/doc/Rnews/}
}

and in "Writing R Extensions".

Uwe Ligges


> I also want to learn about namespaces.  I have looked at ?":::", but I
> think that a tutorial-like document would help me apply and understand
> namespaces better.  So where should I look for "a gentle introduction
> to namespaces", with examples, if there is such a thing?
> 
> Tamas
>



From lauraholt_983 at hotmail.com  Tue May 25 22:19:36 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Tue, 25 May 2004 15:19:36 -0500
Subject: [R] use of do.call and rep
Message-ID: <BAY12-F6FDOkU46M74M0002fc51@hotmail.com>

If I use this:

rep(1:2,c(5,5))

I'll get
1 1 1 1 1 2 2 2 2 2

Is there a way to do this more efficiently, please?
Maybe via do.call?

Thanks,
Laura
mailto: lauraholt_983 at hotmail.com

_________________________________________________________________

http://toolbar.msn.click-url.com/go/onm00200415ave/direct/01/



From p.dalgaard at biostat.ku.dk  Tue May 25 22:17:15 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 25 May 2004 22:17:15 +0200
Subject: [R] thanks again
In-Reply-To: <MABBLJDICACNFOLGIHJOMEHGEHAA.phgrosjean@sciviews.org>
References: <MABBLJDICACNFOLGIHJOMEHGEHAA.phgrosjean@sciviews.org>
Message-ID: <x2aczwgt2s.fsf@biostat.ku.dk>

"Philippe Grosjean" <phgrosjean at sciviews.org> writes:

> Chad,
> 
> Do not forget that, due to the contaminant character of the GPL license, if
> you put a R logo on a t-shirt, you have to share and distribute it freely to
> the community,... and do not forget to distribute the source with it ;-)

And don't forget to implement the impossible-to-take-it-off feature,
so that we can use it for capture-recapture experiments to estimate
the size of the R user base.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Tue May 25 22:44:23 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 May 2004 21:44:23 +0100 (BST)
Subject: [R] use of do.call and rep
In-Reply-To: <BAY12-F6FDOkU46M74M0002fc51@hotmail.com>
Message-ID: <Pine.LNX.4.44.0405252142180.28532-100000@gannet.stats>

rep(1:2, each=5) is simpler to parse and comprehend, but I don't think 
efficiency comes into this.  Did you have some very much larger example in 
mind.

On Tue, 25 May 2004, Laura Holt wrote:

> If I use this:
> 
> rep(1:2,c(5,5))
> 
> I'll get
> 1 1 1 1 1 2 2 2 2 2
> 
> Is there a way to do this more efficiently, please?
> Maybe via do.call?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From elvis at xlsolutions-corp.com  Tue May 25 22:52:28 2004
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 25 May 2004 13:52:28 -0700
Subject: [R] R/S-plus Course***In  Houston,
	TX***R/Splus Fundamentals and Programming Techniques,
	June  24-25, 2004
Message-ID: <20040525205228.7723.qmail@webmail01.mesa1.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud 
to announce June 2004 2-day "R/S-plus Fundamentals and 
Programming Techniques". 

****Houston, TX --------------------------------------> June, 24-25

Interested in our R/Splus Advanced Programming course? Please email 
us! 
Reserve your seat now at the early bird rates! Payment due AFTER the 
class. 


Course Description: 
This two-day beginner to intermediate R/S-plus course focuses 
on a broad spectrum of topics, 
from reading raw data to a comparison of R and S. We will learn 
the essentials of data manipulation, graphical visualization 
and R/S-plus programming. We will explore statistical data analysis 
tools,including graphics with data sets. How to enhance your plots. 
We will perform basic statistics and fit linear regression models. 
Participants are encouraged to bring data for interactive sessions 


With the following outline: 
- An Overview of R and S 
- Data Manipulation and Graphics 
- Using Lattice Graphics 
- A Comparison of R and S-Plus 
- How can R Complement SAS? 
- Writing Functions 
- Avoiding Loops 
- Vectorization 
- Statistical Modeling 
- Project Management 
- Techniques for Effective use of R and S 
- Enhancing Plots 
- Using High-level Plotting Functions 
- Building and Distributing Packages (libraries) 


Email us for group discounts. 
Email Sue Turner: sue at xlsolutions-corp.com 
Phone: 206-686-1578 
Visit us: www.xlsolutions-corp.com/training.htm 
Please let us know if you and your colleagues are interested in this 
classto take advantage of group discount. Register now to secure your 
seat! 
Interested in R/Splus Advanced course? email us. 


Cheers, 
Elvis Miller, PhD 
Manager Training. 
XLSolutions Corporation 
206 686 1578 
www.xlsolutions-corp.com 
elvis at xlsolutions-corp.com



From cashaw at bcm.tmc.edu  Tue May 25 23:09:34 2004
From: cashaw at bcm.tmc.edu (Chad Shaw)
Date: Tue, 25 May 2004 16:09:34 -0500
Subject: [R] this is no joke
In-Reply-To: <x2aczwgt2s.fsf@biostat.ku.dk>
References: <MABBLJDICACNFOLGIHJOMEHGEHAA.phgrosjean@sciviews.org>
	<x2aczwgt2s.fsf@biostat.ku.dk>
Message-ID: <40B3B60E.6030701@bcm.tmc.edu>

Peter

>And don't forget to implement the impossible-to-take-it-off feature,
>so that we can use it for capture-recapture experiments to estimate
>the size of the R user base.
>  
>
The relevance of T-shirts to the R scientific enterprise is beyond refute.
How can we compute those who compute without data?

I think the R-core should move rapidly to fill this void.
No more NULL values.
Let's gather the data.

Let's mark the useRs with a symbol. Not the scarlet A,
but something soothing and COOL.

useR
cashaw



From nettel at math.ucalgary.ca  Wed May 26 00:43:11 2004
From: nettel at math.ucalgary.ca (Alberto Nettel Aguirre)
Date: Tue, 25 May 2004 16:43:11 -0600 (MDT)
Subject: [R] Saving/exporting graphs
Message-ID: <Pine.SOL.4.44.0405251641090.9601-100000@ms1.math.ucalgary.ca>

HI:

I have tried to find a way in which to export/save graphs via the command
line. I know i can right click on it and save it as wmf etc.
But I was wandering if there is a function such as Splus'
export.graph

Thanks


>From Alberto Nettel's Desk
University of Calgary
Math & Stats Department.
Room 346, ext 7199
E-mail: nettel at math.ucalgary.ca



From jasont at indigoindustrial.co.nz  Thu May 27 00:52:10 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 26 May 2004 10:52:10 -1200 (NZST)
Subject: [R] Saving/exporting graphs
In-Reply-To: <Pine.SOL.4.44.0405251641090.9601-100000@ms1.math.ucalgary.ca>
References: <Pine.SOL.4.44.0405251641090.9601-100000@ms1.math.ucalgary.ca>
Message-ID: <35496.203.9.176.60.1085525530.squirrel@webmail.maxnet.co.nz>

> HI:
>
> I have tried to find a way in which to export/save graphs via the command
> line. I know i can right click on it and save it as wmf etc.
> But I was wandering if there is a function such as Splus'
> export.graph

?win.metafile

as in

win.metafile("c:/foo.wmf")
plot(blah,blah,blah)
dev.off()

Cheers

Jason



From sundar.dorai-raj at PDF.COM  Wed May 26 00:52:59 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 25 May 2004 17:52:59 -0500
Subject: [R] Saving/exporting graphs
In-Reply-To: <Pine.SOL.4.44.0405251641090.9601-100000@ms1.math.ucalgary.ca>
References: <Pine.SOL.4.44.0405251641090.9601-100000@ms1.math.ucalgary.ca>
Message-ID: <40B3CE4B.30304@pdf.com>



Alberto Nettel Aguirre wrote:

> HI:
> 
> I have tried to find a way in which to export/save graphs via the command
> line. I know i can right click on it and save it as wmf etc.
> But I was wandering if there is a function such as Splus'
> export.graph
> 
> Thanks
> 
> 
>>From Alberto Nettel's Desk
> University of Calgary
> Math & Stats Department.
> Room 346, ext 7199
> E-mail: nettel at math.ucalgary.ca

See ?Devices and in particular ?win.metafile. Also see ?savePlot.

--sundar



From janef at stat.Berkeley.EDU  Wed May 26 01:17:57 2004
From: janef at stat.Berkeley.EDU (Jane Fridlyand)
Date: Tue, 25 May 2004 16:17:57 -0700 (PDT)
Subject: [R] cor and missing values. Bug?
Message-ID: <Pine.SOL.4.50.0405251607530.20070-100000@toto.Berkeley.EDU>


There seems to be an issue in computing rank correlations with missing
values present. I think this comes from the way rank() function works but
I am not sure how to go about this. Rank function places missing values at
the end by default thus skewing the rank relationship between two vectors:

Example:

R : Copyright 2003, The R Foundation for Statistical Computing
Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

> vec1 <- 1:10
> vec2 <- 2*vec1
> vec1[c(1, 5)] <- NA
> cor(vec1, vec2, use="pair", method="pearson")
[1] 1
> cor(vec1[-c(1,5)], vec2[-c(1,5)], use="pair", method="pearson")
[1] 1
#pearson is OK
> cor(vec1, vec2, use="pair", method="spearman")
[1] 0.3212121
> cor(vec1[-c(1,5)], vec2[-c(1,5)], use="pair", method="spearman")
[1] 1
> cor(vec1, vec2, use="complete", method="spearman")
[1] 0.3212121
#BUG?
Interestingly, "complete" option which should exclude missing values
entirely does not fix an issue either. I think that rank function must be
applied before "use" is used (actually it is the case looking at the
actual code of cor).

I looked though the archives but have not seen this reported. Is it a bug
of rank-correlations or am I misinterpreting the intention?

Thank you

Jane



********************************************************************************
Jane Fridlyand, Assistant Professor
Department of Epidemiology and Biostatistics
Center for Bioinformatics and Molecular Biostatistics
UCSF Comprehensive Cancer Center,
Box 0128 San Francisco, CA 94143-0128
Office: Room N224 Tel: (415)476-0168 Fax: (415)502-3179



From p.dalgaard at biostat.ku.dk  Wed May 26 01:22:44 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 May 2004 01:22:44 +0200
Subject: [R] cor and missing values. Bug?
In-Reply-To: <Pine.SOL.4.50.0405251607530.20070-100000@toto.Berkeley.EDU>
References: <Pine.SOL.4.50.0405251607530.20070-100000@toto.Berkeley.EDU>
Message-ID: <x2zn7whz23.fsf@biostat.ku.dk>

Jane Fridlyand <janef at stat.berkeley.edu> writes:

> There seems to be an issue in computing rank correlations with missing
> values present. I think this comes from the way rank() function works but
> I am not sure how to go about this. Rank function places missing values at
> the end by default thus skewing the rank relationship between two vectors:
> 
> Example:
> 
> R : Copyright 2003, The R Foundation for Statistical Computing
> Version 1.8.1  (2003-11-21), ISBN 3-900051-00-3

Not to put too fine a point on it, but did you consider checking the
NEWS file for the most recent version (1.9.0,
http://cran.r-project.org/src/base/NEWS)?

    o   The cor() function did not remove missing values in the
        non-Pearson case.



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From dbeyer at u.washington.edu  Wed May 26 01:44:56 2004
From: dbeyer at u.washington.edu (Dick Beyer)
Date: Tue, 25 May 2004 16:44:56 -0700 (PDT)
Subject: [R] No direct or inherited method for function "update"
In-Reply-To: <200405251001.i4PA0nZx023381@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.43.0405251644560.1441@hymn11.u.washington.edu>

I used to be able to call update() for lme objects. Now I get this error:

>   ge.lme <- update(ge.lme, data=dat)
Error in update(ge.lme, data = dat) : No direct or inherited method for function "update" for this call


Here is the relevant portion of my code:

ge     <- eset[1,]
dat    <- data.frame(age, gen, fdr, ge)
ge.lme <- lme(fixed=ge~age+gen+age*gen, data=dat, random=~ 1| fdr)
for (i in 1:nrow(eset)) {
  dat$ge <- c(eset[i,])
  ge.lme <- update(ge.lme, data=dat)
  .
  .
  .
}

I am using:
base 1.9.0 
utils 1.9.0 
graphics 1.9.0 
stats 1.9.0 
methods 1.9.0 
Biobase 1.4.14 
affy 1.4.30 
gcrma 1.1.0 
annaffy 1.0.7 
KEGG 1.4.0 
GO 1.5.1 
mgu74av2 1.4.0 
nlme 3.1-48 
xtable 1.2-1 

Any help or suggestions would be most appreciated.

Thanks much,
Dick
*******************************************************************************
Richard P. Beyer, Ph.D.	University of Washington
Tel.:(206) 616 7378	Env. & Occ. Health Sci. , Box 354695
Fax: (206) 685 4696	4225 Roosevelt Way NE, # 100
			Seattle, WA 98105-6099
http://depts.washington.edu/ceeh/ServiceCores/FC5/FC5.html



From mark.threefoot at amd.com  Wed May 26 02:56:29 2004
From: mark.threefoot at amd.com (mark.threefoot@amd.com)
Date: Tue, 25 May 2004 17:56:29 -0700
Subject: [R] RE: ROracle on RHEL 3 x86_64
Message-ID: <A6D472EC410FF84E8BE573FD654BAC43398119@CAEXMTA9>


Hello,

I have gotten past the segmentation fault issue.  I needed to set the environment variable LD_PRELOAD to libclntsh.so.9.0.  I still have another issue, whenever I query the database I get back an empty result set.  Has anyone come across this?  Here is the example code that I am using:

> library('ROracle')
> ora <- Oracle()
> con <- dbConnect(ora, "username/password at database")
> rs <- dbGetQuery(con, "select x, g from R_TEST")
> rs
<Expired OraResult:(7115,0,1)>

or alternatively:

> library('ROracle')
> ora <- Oracle()
> con <- dbConnect(ora, "username/password at database")
> res <- dbSendQuery(con, statement = paste("SELECT X, G FROM R_TEST"))
> res
<OraResult:(7054,0,1)>
> data1 <- fetch(res, n = 100)
Warning message: 
no more records to fetch in: oraFetch(res, n, ...) 
> data1
NULL data frame with 0 rows
> dim(data1)
[1] 0 0

Thanks,
Mark Threefoot

	 -----Original Message-----
	From: 	Threefoot, Mark  
	Sent:	Monday, May 24, 2004 1:37 PM
	To:	'r-help at stat.math.ethz.ch'
	Subject:	ROracle on RHEL 3 x86_64


	Hello,

	I am trying to configure my system with ROracle.  I am running RHEL 3 AS x86_64.  I have the Oracle client 9.2.0.4 x86_64.  I have successfully compiled and run both R-1.8.1 and R-1.9.0 (tried ROracle on both installations).  I am using DBI 1.8 and ROracle 0.5-4.  I have used both the default Redhat installed gcc 3.2.3 and gcc 3.4.  I am able to compile ROracle successfully with the following command:

	R CMD INSTALL --configure-args='--enable-extralibs="-lsqlplus"' ROracle_0.5-4.tar.gz

	When I run R, I get a Segmentation fault after the dbConnect call:

	> library('ROracle')
	> ora <- Oracle()
	> con <- dbConnect(ora, "username/password at database")
	Segmentation fault (core dumped)

	Has anyone run into this, or are running the same configuration?  Any help would be appreciated.

	Thanks,
	Mark Threefoot 
	mark.threefoot at amd.com



From nettel at math.ucalgary.ca  Wed May 26 03:20:26 2004
From: nettel at math.ucalgary.ca (Alberto Nettel Aguirre)
Date: Tue, 25 May 2004 19:20:26 -0600 (MDT)
Subject: [R] apology
Message-ID: <Pine.SOL.4.44.0405251919140.16726-100000@ms1.math.ucalgary.ca>

I apologise, I asked about exporting graphs and said I could not find it.
Well I did, saveplot.
my apologies.

>From Alberto Nettel's Desk
University of Calgary
Math & Stats Department.
Room 346, ext 7199
E-mail: nettel at math.ucalgary.ca



From max.marinucci at ya.com  Wed May 26 03:34:14 2004
From: max.marinucci at ya.com (Max Marinucci)
Date: Wed, 26 May 2004 03:34:14 +0200
Subject: [R] Need help on Mclus output
Message-ID: <001201c442c1$a14547d0$b2537cd9@maxmad9rubu4nk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040526/2c961b73/attachment.pl

From m.g.walker at massey.ac.nz  Wed May 26 07:07:43 2004
From: m.g.walker at massey.ac.nz (Matthew Walker)
Date: Wed, 26 May 2004 17:07:43 +1200
Subject: [R] Turning pass/fail results into a proportion
Message-ID: <40B4261F.9050709@massey.ac.nz>

Please forgive me, I feel exceptionally like a newbie.  Although I've 
read screeds of documentation, I just can't see how this is done.

I have a data frame that contains a number of pass/fails for certain 
variable sizes.  From that, I would like to form another data frame that 
contains the proportions of pass/fails per variable.

So, for example:

df <- data.frame( Var=c(3,3,3,4,4), 
Result=c("pass","fail","fail","pass","pass"), SampleSize=c(3,3,3,2,2))

And I'd like to produce the equivalent of:

data.frame( Var=c(3,4), ProportionPass=c(0.33, 1) )

I have found the table() function:

table( df$Var, df$Result)

which potentially seems to be part of the solution, however it turns the 
Var column into factors.

As an aside, is the storage of SampleSize (above) the best technique?  
Or is it better to store it in a data frame of its own:

data.frame( Var=c(3,4), SamepleSize=c(3,2) )

and then utilise some sort of "lookup" function?

Thank you for your thoughts,

Matthew Walker



From ripley at stats.ox.ac.uk  Wed May 26 07:18:29 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 May 2004 06:18:29 +0100 (BST)
Subject: [R] No direct or inherited method for function "update"
In-Reply-To: <Pine.LNX.4.43.0405251644560.1441@hymn11.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0405260616100.29295-100000@gannet.stats>

Try doing this without all those Bioconductor packages loaded.  It does 
work in base R, and I suspect that one of your packages has redefined 
update (by adding S4 methods?).  If you track down exactly which package 
causes the problem, you can report it to the appropriate person.

On Tue, 25 May 2004, Dick Beyer wrote:

> I used to be able to call update() for lme objects. Now I get this error:
> 
> >   ge.lme <- update(ge.lme, data=dat)
> Error in update(ge.lme, data = dat) : No direct or inherited method for function "update" for this call
> 
> 
> Here is the relevant portion of my code:
> 
> ge     <- eset[1,]
> dat    <- data.frame(age, gen, fdr, ge)
> ge.lme <- lme(fixed=ge~age+gen+age*gen, data=dat, random=~ 1| fdr)
> for (i in 1:nrow(eset)) {
>   dat$ge <- c(eset[i,])
>   ge.lme <- update(ge.lme, data=dat)
>   .
>   .
>   .
> }
> 
> I am using:
> base 1.9.0 
> utils 1.9.0 
> graphics 1.9.0 
> stats 1.9.0 
> methods 1.9.0 
> Biobase 1.4.14 
> affy 1.4.30 
> gcrma 1.1.0 
> annaffy 1.0.7 
> KEGG 1.4.0 
> GO 1.5.1 
> mgu74av2 1.4.0 
> nlme 3.1-48 
> xtable 1.2-1 
> 
> Any help or suggestions would be most appreciated.
> 
> Thanks much,
> Dick
> *******************************************************************************
> Richard P. Beyer, Ph.D.	University of Washington
> Tel.:(206) 616 7378	Env. & Occ. Health Sci. , Box 354695
> Fax: (206) 685 4696	4225 Roosevelt Way NE, # 100
> 			Seattle, WA 98105-6099
> http://depts.washington.edu/ceeh/ServiceCores/FC5/FC5.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lauraholt_983 at hotmail.com  Wed May 26 07:19:43 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Wed, 26 May 2004 00:19:43 -0500
Subject: [R] SJava
Message-ID: <BAY12-F43KS7vzxgLNn00002d00@hotmail.com>

Hi again!

I'm trying to download SJava from the http://www.omegahat.org/RSJava/ 
website.

I'm trying to get the binary.

I download the version from BDR's website.

When I unzip the file via unzip.exe, the new folder appears as SJAVA (upper 
case).


>library(SJava)
Error in library(SJava) : There is no package called 'SJava'
>library(SJAVA)
Error in library(SJAVA) : There is no package called 'SJAVA'
>

Any suggestions, please?

TIA
Laura
mailto: lauraholt_983 at hotmail.com

_________________________________________________________________
Best Restaurant Giveaway Ever! Vote for your favorites for a chance to win 
$1 million! http://local.msn.com/special/giveaway.asp



From ripley at stats.ox.ac.uk  Wed May 26 07:32:18 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 May 2004 06:32:18 +0100 (BST)
Subject: [R] apology
In-Reply-To: <Pine.SOL.4.44.0405251919140.16726-100000@ms1.math.ucalgary.ca>
Message-ID: <Pine.LNX.4.44.0405260629440.29295-100000@gannet.stats>

I think it is savePlot ....  You seemed to be talking about R 
on Windows without mentioning it, and savePlot is only on Windows.
There are lots of other possibilities, e.g. dev.copy, on all R platforms.

On Tue, 25 May 2004, Alberto Nettel Aguirre wrote:

> I apologise, I asked about exporting graphs and said I could not find it.
> Well I did, saveplot.
> my apologies.
> 
> >From Alberto Nettel's Desk

[We prefer people's minds to be involved.]

> University of Calgary
> Math & Stats Department.
> Room 346, ext 7199
> E-mail: nettel at math.ucalgary.ca


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From DJNordlund at aol.com  Wed May 26 07:57:22 2004
From: DJNordlund at aol.com (DJNordlund@aol.com)
Date: Wed, 26 May 2004 01:57:22 EDT
Subject: [R] SJava
Message-ID: <39.484defde.2de58bc2@aol.com>

In a message dated 5/25/2004 10:20:10 PM Pacific Daylight Time,  
lauraholt_983 at hotmail.com writes:
Hi again!

I'm trying to download SJava from the  http://www.omegahat.org/RSJava/ 
website.

I'm trying to get the  binary.

I download the version from BDR's website.

When I unzip  the file via unzip.exe, the new folder appears as SJAVA (upper  
case).


>library(SJava)
Error in library(SJava) : There is  no package called 'SJava'
>library(SJAVA)
Error in library(SJAVA) :  There is no package called 'SJAVA'
>

Any suggestions,  please?

TIA
Laura
mailto: _lauraholt_983 at hotmail.com_ (mailto:lauraholt_983 at hotmail.com) 
-----------------Reply---------------

Laura,

If you are using  an MS Windows platform I suspect you don't want to manually 
unzip the file; it  needs to be installed.  Rather, start Rgui, and from the 
Packages menu  select "Install package(s) from local zip file..." and follow 
the  directions.

Dan Nordlund



From kuroki at oak.dti.ne.jp  Wed May 26 11:00:48 2004
From: kuroki at oak.dti.ne.jp (Chihiro Kuroki)
Date: Wed, 26 May 2004 18:00:48 +0900
Subject: [R] pmvt problem in multcomp
In-Reply-To: <Pine.LNX.4.51.0405231138160.19910@artemis.imbe.med.uni-erlangen.de>
References: <87vfirzwhq.wl@oak.dti.ne.jp>
	<Pine.LNX.4.51.0405231138160.19910@artemis.imbe.med.uni-erlangen.de>
Message-ID: <87oeobimv3.wl@oak.dti.ne.jp>

Dear Mr.Torsten:

At Sun, 23 May 2004 11:40:51 +0200 (CEST),
Torsten Hothorn wrote:
> 
> Yes, `pmvt' returns NaN without indicating this error. We need to check.
> Thanks for the report (and *please* cc emails reporting problems with
> packages to the maintainer!),

I am dreadfully sorry I did not cc mail to you. 

> If the question relates to a package that is downloaded from
> CRAN try contacting the package maintainers first.

I overlooked the above-mentioned sentence.


BTW, I have another strange example of simtest. I want to know
why simtest returns these p-values.

-- example 1 -------------------------------
rm(list = ls())
require(multcomp)
y1 <- c(seq(3,7),seq(3,7))
y2 <- c(rep(c(6,7,8,9),7))
sort(runif(28),index=T) -> a
y3 <- numeric(0)
for(i in 1:28){
  y3[i] <- y2[a$ix[i]]
}
y4 <- c(y1,y3,14,18)

f2 <- factor(c(rep(1,10),rep(2,8),rep(3,8),rep(4,8),rep(5,6)))
dat2 <- cbind(as.data.frame(y4),f2)
summary(simtest(y4 ~ f2, data=dat2, type="Dunnett"))

> dat2
   y4 f2
1   3  1
2   4  1
3   5  1
4   6  1
5   7  1
6   3  1
7   4  1
8   5  1
9   6  1
10  7  1
11  6  2
12  7  2
13  6  2
14  9  2
15  7  2
16  8  2
17  6  2
18  8  2
19  9  3
20  8  3
21  7  3
22  9  3
23  6  3
24  8  3
25  9  3
26  7  3
27  7  4
28  9  4
29  6  4
30  6  4
31  9  4
32  8  4
33  7  4
34  9  4
35  6  5
36  8  5
37  8  5
38  7  5
39 14  5
40 18  5
> summary(simtest(y4 ~ f2, data=dat2, type="Dunnett"))

	 Simultaneous tests: Dunnett contrasts 

Call: 
simtest.formula(formula = y4 ~ f2, data = dat2, type = "Dunnett")

	 Dunnett contrasts for factor f2

Contrast matrix:
          f21 f22 f23 f24 f25
f22-f21 0  -1   1   0   0   0
f23-f21 0  -1   0   1   0   0
f24-f21 0  -1   0   0   1   0
f25-f21 0  -1   0   0   0   1


Absolute Error Tolerance:  0.001 

Coefficients:
        Estimate t value Std.Err. p raw p Bonf p adj
f25-f21    5.167  -4.644    1.022 0.000  0.000 0.000
f23-f21    2.875  -2.813    1.022 0.008  0.024 0.022
f24-f21    2.625  -2.569    1.022 0.015  0.029 0.028
f22-f21    2.125  -2.079    1.113 0.045  0.045 0.045
---------------------------------

I got the following inequality from the appended chart of a
book.

2.558 < d(5, 35, 0.4263464, 0.05) < 2.598

Are these "p adj" values right?
Or do I misunderstand some? 
-- 
kuroki
GnuPG fingerprint = 90FD FE79 905F 26F9 29C4  096F 8AA2 2C42 5130 1469



From Jesus.Frias at dit.ie  Wed May 26 11:45:51 2004
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Wed, 26 May 2004 10:45:51 +0100
Subject: [R] Metafiiles  into Word R 1.9.0
In-Reply-To: <54816.203.9.176.60.1085519483.squirrel@webmail.maxnet.co.nz>
Message-ID: <LGECJJCANFBOOHCMGPJEAEGJDDAA.Jesus.Frias@dit.ie>

Hi again,

	Thanks a lot to Jason Turner for the hint to the FAQ-windows. savePlot()
seems to be in trouble with lattice objects as much as any other device,
which I did not know. I can generate now the metafiles:

> library(lattice)
> example(xyplot)
> win.metafile()
> print(dotplot(variety ~ yield | year * site, data = barley))
> dev.off()
windows
      2

	This gives an alternative solution to the problem I had with the drop-down
menu on the windows() device "Copy as metafile".

best regards,

Jesus

--------------------------------------------------------------
Jes??s Mar??a Fr??as Celayeta
School of Food Sci. and Env. Health.
Faculty of Tourism and Food
Dublin Institute of Technology
Cathal Brugha St., Dublin 1. Ireland
t +353 1 4024459 f +353 1 4024495
w www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------

> -----Original Message-----
> From: Jason Turner [mailto:jasont at indigoindustrial.co.nz]
> Sent: 26 May 2004 22:11
> To: Jesus Frias
> Subject: RE: [R] Metafiiles into Word R 1.9.0
>
>
> > 	There is one more thing that might shed some light (or not)
> on it: I have
> > just found that I can actually copy-paste a plot in the device
> coming from
> > a
> > plot call but not from a lattice object call. There it is my
> toy example:
> >
> >> example(plot)
> >> savePlot("exampleplot.wmf",type="wmf")
> >> library(lattice)
> >> example(xyplot)
> >> savePlot("examplexyplot.wmf",type="wmf")
> >
> > 	I have no problem importing exampleplot.wmf into Word, but
> I can't do the
> > same with examplexyplot.wmf. The file seems empty, it has only
> 696 bytes.
> >
>
> Yes, it does shed light.  This is a FAQ.
>
> http://cran.au.r-project.org/doc/FAQ/R-FAQ.html#Why%20do%20lattice
%2ftrellis%20graphics%20not%20work%3f

Cheers

Jason

--
This message has been scanned for content and
viruses by the DIT Information Services MailScanner
Service, and is believed to be clean.
http://www.dit.ie


-- 
This message has been scanned for content and 
viruses by the DIT Information Services MailScanner 
Service, and is believed to be clean.
http://www.dit.ie



From Jorgen.Wallerman at resgeom.slu.se  Wed May 26 12:08:36 2004
From: Jorgen.Wallerman at resgeom.slu.se (=?iso-8859-1?Q?J=F6rgen_Wallerman?=)
Date: Wed, 26 May 2004 12:08:36 +0200
Subject: [R] Using R in C++
Message-ID: <9BE977B02923D311AADA00105AF49783015C97E4@tilia.slu.se>

Hello,

Is it possible to use R functions (in my case: ks.test()) from C++
-applications? That is, I get the impression R can execute C/C++ code, but
is there any possibility to do the opposite? Where can I find help?


-------------------------------------------
Ph. D. J??rgen Wallerman
Swedish University of Agricultural Sciences
Remote Sensing Laboratory
S901 83 UME??
 
###########################################

This message has been scanned by F-Secure 
Anti-Virus for Microsoft Exchange.

###########################################



From mdowle at concordiafunds.com  Wed May 26 12:31:44 2004
From: mdowle at concordiafunds.com (Matthew Dowle)
Date: Wed, 26 May 2004 11:31:44 +0100
Subject: [R] is.weekend() odd behaviour
Message-ID: <78166BFC5165D811AA0400065BF0324B1B9181@wisconsin.concordia>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040526/c7e715c8/attachment.pl

From lecoutre at stat.ucl.ac.be  Wed May 26 12:23:32 2004
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Wed, 26 May 2004 12:23:32 +0200
Subject: [R] Once again in search of memory
Message-ID: <6.0.1.1.2.20040526121307.02263ab0@stat4ux.stat.ucl.ac.be>


Hello any R user,

Working on R 1.8.1 or R 1.9 on Windows, 256 Mb RAM.
I am trying to debug/correct/speedup the execution of one of our student's 
program. Basically, we perform simulations.
R is launched with high memory-limits.
One execution of the program requires nearly 200 Mbs and is OK the first 
time.  Then, launching it again does strange things: seen from Windows 
manager, the RAM used by R never exceed those 200 Mbs (often near 130Mb). 
seen from R:

 > gc(TRUE)
Garbage collection 280 = 85+59+136 (level 2) ...
396784 cons cells free (40%)
145.7 Mbytes of heap free (53%)
            used  (Mb) gc trigger  (Mb)
Ncells   587240  15.7     984024  26.3
Vcells 16866491 128.7   35969653 274.5

And then each new call to the function
foo()
will always imply a grow of this memory use (Vcells)
How comes Windows Manager states R only uses 71 Mb RAM as seen in the 
attached screenshot?
Is this a known issue? Is there any tip to "really" release memory for all 
those objects we dont use anymore?

I tried also memory.profile() which states there are more list-type 
objects. We wanipulated matrices. Could they come from calls to 'apply'?

Thansk for insights and advices on how to handle memory. I am turning and 
turning round on help pages.

Eric





Eric Lecoutre
UCL /  Institut de Statistique
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
Belgium

tel: (+32)(0)10473050
lecoutre at stat.ucl.ac.be
http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

If the statistics are boring, then you've got the wrong numbers. -Edward 
Tufte



From jpgranadeiro at fc.ul.pt  Wed May 26 12:40:17 2004
From: jpgranadeiro at fc.ul.pt (J. Pedro Granadeiro)
Date: Wed, 26 May 2004 11:40:17 +0100
Subject: [R] Common principle components
Message-ID: <200405261140.17842.jpgranadeiro@fc.ul.pt>

	Dear all,

Can anyone point me to a package that can perform Common principle components?

Thank you.

Jos?? P. Granadeiro



From Matthias.Templ at statistik.gv.at  Wed May 26 12:47:33 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Wed, 26 May 2004 12:47:33 +0200
Subject: AW: [R] Question
Message-ID: <83536658864BC243BE3C06D7E936ABD50153A5AE@xchg1.statistik.local>

A small comment:
The code of Agnes is written in Fortran. Following book give more details:

     Kaufman, L. and Rousseeuw, P.J. (1990). _Finding Groups in Data:
     An Introduction to Cluster Analysis_. Wiley, New York.

The 'hclust' function is based an Algorithm contributed to STATLIB
by F. Murtagh and the code is written in C.

Probably the differences between agnes and hclust causes from the different code and the different implementation.

Matthias

> -----Urspr??ngliche Nachricht-----
> Von: n.bouget [mailto:n.bouget at laposte.net] 
> Gesendet: Dienstag, 25. Mai 2004 09:39
> An: R-help
> Betreff: [R] Question
> 
> 
> [R]:Agnes vs Hclust
> 
> Hi,
> I want to know if there is a difference between the two 
> hierarchical methods Agnes and hclust when there are used 
> with the same method and the same metric on the same data! I 
> ask this question because I've got a difference, the clusters 
> are not the same even if there are some similarities... Is 
> anybody know why i have this difference? Thanks Nicolas BOUGET 
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Wed May 26 12:55:06 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 26 May 2004 12:55:06 +0200
Subject: [R] is.weekend() odd behaviour
In-Reply-To: <78166BFC5165D811AA0400065BF0324B1B9181@wisconsin.concordia>
References: <78166BFC5165D811AA0400065BF0324B1B9181@wisconsin.concordia>
Message-ID: <40B4778A.9070703@statistik.uni-dortmund.de>

Matthew Dowle wrote:

> It seems is.weekend() is unsure ?

It is completely sure, if an object is given is.weekend() knows about as in:

table(is.weekend(sapply(1:100, 
function(i){Sys.sleep(0.05);as.chron(Sys.time())})))

(note the as.chron() call!)

Uwe Ligges



> # Start R 1.9.0 with --vanilla on windows xp
> # load package chron
> 
> 
>>table(is.weekend(sapply(1:100, function(i){Sys.sleep(0.05);Sys.time()})))
> 
> FALSE  TRUE 
>    68    32 
> 
>>date()
> 
> [1] "Wed May 26 11:18:56 2004"
> 
> 
>>version         _              
> 
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    9.0            
> year     2004           
> month    04             
> day      12             
> language R              
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From laura at env.leeds.ac.uk  Wed May 26 13:51:58 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Wed, 26 May 2004 12:51:58 +0100 (BST)
Subject: [R] multi read.table function and read.table function not accepting
 col.names
Message-ID: <Pine.LNX.4.44.0405261246520.28125-100000@env-pc-phd13>

I am using R-1.8.0 on Debian.

I'm trying to read in a large table (1441*16) which currently has no
header line. I have set up a list of column names which is 16 names long.

when i try the following:

myfiledate.01<-read.table("filenamedate.01",row.names=NULL,col.names="names",na.strings="-999.00")

I am returned with an error saying there are more columsh than column
names. I am sure I have done this successfully in the past so can't
understand the problem. I have done the read.table function without
specifying col.names and it works fine and i end up with a 1441*16
data.frame.

Also as I have several hundred of these tables to read into R, all having
the same dimension and all having the same column names, is it possible to
automate R so they will all be read in at once - each table represents a
different days worth of data.

Thanks

Laura



From mdowle at concordiafunds.com  Wed May 26 14:02:16 2004
From: mdowle at concordiafunds.com (Matthew Dowle)
Date: Wed, 26 May 2004 13:02:16 +0100
Subject: [R] is.weekend() odd behaviour
Message-ID: <78166BFC5165D811AA0400065BF0324B1B9186@wisconsin.concordia>


Thanks. When is.weekend() is given an object it doesn't know about, could a
warning or error be added? At the moment, I think you're agreeing, that it
silently returns a random TRUE/FALSE.

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: 26 May 2004 11:55
To: Matthew Dowle
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R] is.weekend() odd behaviour


Matthew Dowle wrote:

> It seems is.weekend() is unsure ?

It is completely sure, if an object is given is.weekend() knows about as in:

table(is.weekend(sapply(1:100, 
function(i){Sys.sleep(0.05);as.chron(Sys.time())})))

(note the as.chron() call!)

Uwe Ligges



> # Start R 1.9.0 with --vanilla on windows xp
> # load package chron
> 
> 
>>table(is.weekend(sapply(1:100, 
>>function(i){Sys.sleep(0.05);Sys.time()})))
> 
> FALSE  TRUE 
>    68    32 
> 
>>date()
> 
> [1] "Wed May 26 11:18:56 2004"
> 
> 
>>version         _              
> 
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    9.0            
> year     2004           
> month    04             
> day      12             
> language R              
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From vaclav.petricek at mff.cuni.cz  Wed May 26 14:00:46 2004
From: vaclav.petricek at mff.cuni.cz (Vaclav Petricek)
Date: Wed, 26 May 2004 14:00:46 +0200 (CEST)
Subject: [R] Page's trend test?
Message-ID: <Pine.BSF.4.50.0405261353180.83214-100000@sec.ms.mff.cuni.cz>


Hello

Is there an R implementation of the "Page's trend test" as described
in http://en.wikipedia.org/wiki/Page%27s_trend_test or something
equivalent?

Thanks for your help,

Vaclav



From wolski at molgen.mpg.de  Wed May 26 14:06:08 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 26 May 2004 14:06:08 +0200
Subject: [R] multi read.table function and read.table function not
	accepting col.names
In-Reply-To: <Pine.LNX.4.44.0405261246520.28125-100000@env-pc-phd13>
References: <Pine.LNX.4.44.0405261246520.28125-100000@env-pc-phd13>
Message-ID: <200405261406080990.00FDBFF8@mail.math.fu-berlin.de>

Hi!

1.
assuning that names is the vector with the names.
try col.names=names instead of "names"

2.
Several ways
a)
use 
lapply(listwithpathstofiles,read.tabel,remaining, options) //u will get it stored in the list.
b)
or use for loop and append to list. mylist<-list()
c)
or look
?assing
to generate several hundred objects in the envrovment.

Sincerely Eryk

*********** REPLY SEPARATOR  ***********

On 5/26/2004 at 12:51 PM Laura Quinn wrote:

>I am using R-1.8.0 on Debian.
>
>I'm trying to read in a large table (1441*16) which currently has no
>header line. I have set up a list of column names which is 16 names long.
>
>when i try the following:
>
>myfiledate.01<-read.table("filenamedate.01",row.names=NULL,col.names="names",na.strings="-999.00")
>
>I am returned with an error saying there are more columsh than column
>names. I am sure I have done this successfully in the past so can't
>understand the problem. I have done the read.table function without
>specifying col.names and it works fine and i end up with a 1441*16
>data.frame.
>
>Also as I have several hundred of these tables to read into R, all having
>the same dimension and all having the same column names, is it possible to
>automate R so they will all be read in at once - each table represents a
>different days worth of data.
>
>Thanks
>
>Laura
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From ligges at statistik.uni-dortmund.de  Wed May 26 14:20:00 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 26 May 2004 14:20:00 +0200
Subject: [R] is.weekend() odd behaviour
In-Reply-To: <78166BFC5165D811AA0400065BF0324B1B9186@wisconsin.concordia>
References: <78166BFC5165D811AA0400065BF0324B1B9186@wisconsin.concordia>
Message-ID: <40B48B70.6060904@statistik.uni-dortmund.de>

Matthew Dowle wrote:

> Thanks. When is.weekend() is given an object it doesn't know about, could a
> warning or error be added? At the moment, I think you're agreeing, that it
> silently returns a random TRUE/FALSE.

It's not random, it depends on the value of Sys.time(), which also 
includes seconds .....
I agree that a warning or error might be sensible. So I think you are 
about to write a note to the maintainer of package "chron" including 
patches for is.weekend() and friends?

Uwe Ligges





> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> Sent: 26 May 2004 11:55
> To: Matthew Dowle
> Cc: 'r-help at stat.math.ethz.ch'
> Subject: Re: [R] is.weekend() odd behaviour
> 
> 
> Matthew Dowle wrote:
> 
> 
>>It seems is.weekend() is unsure ?
> 
> 
> It is completely sure, if an object is given is.weekend() knows about as in:
> 
> table(is.weekend(sapply(1:100, 
> function(i){Sys.sleep(0.05);as.chron(Sys.time())})))
> 
> (note the as.chron() call!)
> 
> Uwe Ligges
> 
> 
> 
> 
>># Start R 1.9.0 with --vanilla on windows xp
>># load package chron
>>
>>
>>
>>>table(is.weekend(sapply(1:100, 
>>>function(i){Sys.sleep(0.05);Sys.time()})))
>>
>>FALSE  TRUE 
>>   68    32 
>>
>>
>>>date()
>>
>>[1] "Wed May 26 11:18:56 2004"
>>
>>
>>
>>>version         _              
>>
>>platform i386-pc-mingw32
>>arch     i386           
>>os       mingw32        
>>system   i386, mingw32  
>>status                  
>>major    1              
>>minor    9.0            
>>year     2004           
>>month    04             
>>day      12             
>>language R              
>>
>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list 
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html



From wolfram at fischer-zim.ch  Wed May 26 14:27:34 2004
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Wed, 26 May 2004 14:27:34 +0200
Subject: [R] lattice/postscript/pdf: size of striptext and xlab and other
	strings
Message-ID: <20040526122734.GA6894@s1x.local>

____PROBLEM_________________

When comparing the output from:
	data(barley); dotplot(variety ~ yield | year * site, data = barley)

run with R 1.8.1 and with R 1.9.0, one gets different
sizes of striptexts and xlabs.

____OBSERVATIONS____________

- The result is the same when the output is redirected
  by postscript() or by pdf().

- trellis.par.get() shows the same cex-values in both R versions.

____QUESTION________________

How can I get the same text sizes as in R 1.8.1 for lattice output
using R 1.9.0? (And hopefully reuse older scripts without changing
their code?)

Thanks Wolfram



From ggrothendieck at myway.com  Wed May 26 14:46:15 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 26 May 2004 12:46:15 +0000 (UTC)
Subject: [R] is.weekend() odd behaviour
References: <78166BFC5165D811AA0400065BF0324B1B9181@wisconsin.concordia>
	<40B4778A.9070703@statistik.uni-dortmund.de>
Message-ID: <loom.20040526T143834-18@post.gmane.org>

Uwe Ligges <ligges <at> statistik.uni-dortmund.de> writes:
> Matthew Dowle wrote:
> > 
> >>table(is.weekend(sapply(1:100, function(i){Sys.sleep(0.05);Sys.time()})))
> > 
> > FALSE  TRUE 
> >    68    32 
> 
> > It seems is.weekend() is unsure ?
> 
> It is completely sure, if an object is given is.weekend() knows about as in:
> 
> table(is.weekend(sapply(1:100, 
> function(i){Sys.sleep(0.05);as.chron(Sys.time())})))
> 
> (note the as.chron() call!)

Note that converting a POSIXct to chron using as.chron uses
the GMT datetime, not the datetime in your timezone.  So if its the
weekend in the GMT timezone but not in yours it will indicate that
its the weekend.  Similarly if its the weekend in your timezone
but not in the GMT timezone then it will indicate its not in the
weekend.

If you want the result relative to your timezone convert
to chron like this:

   now <- Sys.time()
   chron(unclass(as.Date(format(now))))

or even easier:

    chron(unclass(Sys.Date()))

Now apply is.weekend to that.



From JonesW at kssg.com  Wed May 26 15:08:47 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Wed, 26 May 2004 14:08:47 +0100
Subject: [R] Venn diagrams
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02955F27@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040526/82f7b2c4/attachment.pl

From ccleland at optonline.net  Wed May 26 15:28:52 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 26 May 2004 09:28:52 -0400
Subject: [R] Venn diagrams
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB02955F27@gimli.middleearth.kssg.com>
References: <6B5A9304046AD411BD0200508BDFB6CB02955F27@gimli.middleearth.kssg.com>
Message-ID: <40B49B94.9080307@optonline.net>

http://www.stats.uwo.ca/faculty/murdoch/software/

   Also, a google search [Venn r-project] returns a number of 
promising hits.

hope this helps,

Chuck Cleland

Wayne Jones wrote:
> Does anyone know how to plot venn diagrams in R?
> Ive searched the mail archive lists but to no avail. 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From laura at env.leeds.ac.uk  Wed May 26 15:45:39 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Wed, 26 May 2004 14:45:39 +0100 (BST)
Subject: [R] multi read.table function and read.table function not 
	accepting col.names
In-Reply-To: <200405261406080990.00FDBFF8@mail.math.fu-berlin.de>
Message-ID: <Pine.LNX.4.44.0405261442440.28125-100000@env-pc-phd13>

Thank you for your earlier help, I have a couple of related questions.

With the lapply function, is it still possible to assign column names to
each column of every data frame, again I have tried and it doesn't seem to
like it..

and is it also possible to assign names to each data frame when I do
lapply rather than each one being a subset of a larger frame (I don't seem
to be able to attach these as individual objects).

Thanks again,
Laura

On Wed, 26 May 2004, Wolski wrote:

> Hi!
>
> 1.
> assuning that names is the vector with the names.
> try col.names=names instead of "names"
>
> 2.
> Several ways
> a)
> use
> lapply(listwithpathstofiles,read.tabel,remaining, options) //u will get it stored in the list.
> b)
> or use for loop and append to list. mylist<-list()
> c)
> or look
> ?assing
> to generate several hundred objects in the envrovment.
>
> Sincerely Eryk
>
> *********** REPLY SEPARATOR  ***********
>
> On 5/26/2004 at 12:51 PM Laura Quinn wrote:
>
> >I am using R-1.8.0 on Debian.
> >
> >I'm trying to read in a large table (1441*16) which currently has no
> >header line. I have set up a list of column names which is 16 names long.
> >
> >when i try the following:
> >
> >myfiledate.01<-read.table("filenamedate.01",row.names=NULL,col.names="names",na.strings="-999.00")
> >
> >I am returned with an error saying there are more columsh than column
> >names. I am sure I have done this successfully in the past so can't
> >understand the problem. I have done the read.table function without
> >specifying col.names and it works fine and i end up with a 1441*16
> >data.frame.
> >
> >Also as I have several hundred of these tables to read into R, all having
> >the same dimension and all having the same column names, is it possible to
> >automate R so they will all be read in at once - each table represents a
> >different days worth of data.
> >
> >Thanks
> >
> >Laura
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic
> Ihnestrasse 63-73 14195 Berlin       'v'
> tel: 0049-30-83875219               /   \
> mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski
>
>



From partha_bagchi at hgsi.com  Wed May 26 15:58:10 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Wed, 26 May 2004 09:58:10 -0400
Subject: [R] thanks again
Message-ID: <OFE2B0D3B3.0036090A-ON85256EA0.004CA46C-85256EA0.004CBD3E@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040526/1eb82481/attachment.pl

From ggrothendieck at myway.com  Wed May 26 16:04:57 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 26 May 2004 14:04:57 +0000 (UTC)
Subject: [R] Turning pass/fail results into a proportion
References: <40B4261F.9050709@massey.ac.nz>
Message-ID: <loom.20040526T160045-168@post.gmane.org>

Matthew Walker <m.g.walker <at> massey.ac.nz> writes:
 
: I have a data frame that contains a number of pass/fails for certain 
: variable sizes.  From that, I would like to form another data frame that 
: contains the proportions of pass/fails per variable.
: 
: So, for example:
: df <- data.frame( Var=c(3,3,3,4,4), 
: Result=c("pass","fail","fail","pass","pass"), SampleSize=c(3,3,3,2,2))
: 
: And I'd like to produce the equivalent of:
: data.frame( Var=c(3,4), ProportionPass=c(0.33, 1) )


Try using aggregate like this:

 aggregate( data.frame(ProportionPass = as.numeric(df$Result)-1), 
      list(Var = df$Var), mean)



From gilles.guillot at inapg.inra.fr  Wed May 26 18:04:39 2004
From: gilles.guillot at inapg.inra.fr (Gilles GUILLOT)
Date: Wed, 26 May 2004 16:04:39 +0000
Subject: [R] I/O fortran instructions and dyn.load
Message-ID: <200405261604.39795.gilles.guillot@inapg.inra.fr>

I have the following Fortran code

subroutine sub(path)
character*100 path
open(10,file=path)
end

saved as test.f

which I compile with
g77 -c test.f

then I make the shared libary in R (Version 1.9.0) with
system("R CMD SHLIB test.o")

so far, everything OK.

But
dyn.load("test.so")
returns the following error message:
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library "test.so":
  test.so: undefined symbol: f_open

I get similar error messages with r/w Fortran instructions like 
write(*,*) , read(*,*)

I used to use such programs on my computer under mandrake linux 10.
The problem reported occurs on a new server operating under 
another linux distrib (debian).

Thanks in advance for any help, 
Gilles 
-- 
_____________________________________________________________________
Gilles GUILLOT
INRA -D??partement Math??matiques et Informatique Appliqu??es

Unit?? de Mixte de Recherche
INRA - INAPG - ENGREF
Institut National Agronomique de Paris-Grignon
16 rue Claude Bernard
75231 Paris cedex 5

Aile Claude Bernard
Niveau cours +3 ??tages

tel : +33 (0)1 44 08 72 71
fax : +33 (0)1 44 08 16 66
http://www.inapg.fr/ens_rech/mathinfo/personnel/guillot/welcome.html



From r.real at web.de  Wed May 26 16:15:16 2004
From: r.real at web.de (Ruben Real)
Date: Wed, 26 May 2004 16:15:16 +0200
Subject: [R] power analysis
Message-ID: <1173517717@web.de>

Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit
Received-SPF: none (hypatia: domain of r.real at web.de does not designate permitted sender hosts)
X-Virus-Scanned: by amavisd-new
X-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on hypatia.math.ethz.ch
X-Spam-Level: *
X-Spam-Status: No, hits=1.6 required=5.0 tests=BAYES_60 autolearn=no version=2.63

Hello,

do you know if there is a R-package on power analysis for planned contrasts (and the like)?

thanks

Ruben
_______________________________________________________________________
Moechten Sie Ihre SMS noch ausdrucksstaerker und emotionaler gestalten?



From rbaer at atsu.edu  Wed May 26 15:43:56 2004
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Wed, 26 May 2004 08:43:56 -0500
Subject: [R] cor and missing values. Bug?
References: <Pine.SOL.4.50.0405251607530.20070-100000@toto.Berkeley.EDU>
	<x2zn7whz23.fsf@biostat.ku.dk>
Message-ID: <001001c4432b$dffbeaa0$2e80010a@BigBaer>

> Not to put too fine a point on it, but did you consider checking the
> NEWS file for the most recent version (1.9.0,
> http://cran.r-project.org/src/base/NEWS)?
>
>     o   The cor() function did not remove missing values in the
>         non-Pearson case.


There is still something a little strange in version 1.9.0. What  is the
source of the discrpancy between cor() and cor.test()?

> vec1 <- 1:10
> vec2 <- 2*vec1
> vec1[c(1, 5)] <- NA
> cor(vec1[-c(1,5)], vec2[-c(1,5)], use="pair", method="spearman")
[1] 1
> cor(vec1, vec2, use="complete", method="spearman")
[1] 0.99544
> cor.test(vec1, vec2, use="complete", method="spearman")

        Spearman's rank correlation rho

data:  vec1 and vec2
S = 0, p-value = 4.96e-05
alternative hypothesis: true rho is not equal to 0
sample estimates:
rho
  1

Rob Baer



From ripley at stats.ox.ac.uk  Wed May 26 16:23:08 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 May 2004 15:23:08 +0100 (BST)
Subject: [R] I/O fortran instructions and dyn.load
In-Reply-To: <200405261604.39795.gilles.guillot@inapg.inra.fr>
Message-ID: <Pine.LNX.4.44.0405261521000.3584-100000@gannet.stats>

Try

R CMD SHLIB test.f

If SHLIB know it has to deal with Fortran code, it adds the appropriate 
libraries.

On Wed, 26 May 2004, Gilles GUILLOT wrote:

> I have the following Fortran code
> 
> subroutine sub(path)
> character*100 path
> open(10,file=path)
> end
> 
> saved as test.f
> 
> which I compile with
> g77 -c test.f
> 
> then I make the shared libary in R (Version 1.9.0) with
> system("R CMD SHLIB test.o")
> 
> so far, everything OK.
> 
> But
> dyn.load("test.so")
> returns the following error message:
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library "test.so":
>   test.so: undefined symbol: f_open
> 
> I get similar error messages with r/w Fortran instructions like 
> write(*,*) , read(*,*)
> 
> I used to use such programs on my computer under mandrake linux 10.
> The problem reported occurs on a new server operating under 
> another linux distrib (debian).
> 
> Thanks in advance for any help, 
> Gilles 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mdowle at concordiafunds.com  Wed May 26 16:36:42 2004
From: mdowle at concordiafunds.com (Matthew Dowle)
Date: Wed, 26 May 2004 15:36:42 +0100
Subject: FW: [R] is.weekend() odd behaviour
Message-ID: <78166BFC5165D811AA0400065BF0324B1B918A@wisconsin.concordia>


Kurt,

Uwe suggested I write to you as maintainer of chron ... at the start of
is.weekend, in the check on the argument type, maybe just change chron() to
as.chron()? This would ensure as.chron.POSIXt gets called on POSIXt
arguments, and (I think) fixes the problem. I tested and it seems ok. No
warning/error required.

> is.weekend
function(x)
{
    if(!inherits(x, "dates"))
        if(is.character(x) || is.numeric(x))
            x <- as.chron(x)   # was  x <- chron(x)
        else stop("x must inherit from dates")
    ....
}

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: 26 May 2004 13:20
To: Matthew Dowle
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R] is.weekend() odd behaviour


Matthew Dowle wrote:

> Thanks. When is.weekend() is given an object it doesn't know about, 
> could a warning or error be added? At the moment, I think you're 
> agreeing, that it silently returns a random TRUE/FALSE.

It's not random, it depends on the value of Sys.time(), which also 
includes seconds .....
I agree that a warning or error might be sensible. So I think you are 
about to write a note to the maintainer of package "chron" including 
patches for is.weekend() and friends?

Uwe Ligges





> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Sent: 26 May 2004 11:55
> To: Matthew Dowle
> Cc: 'r-help at stat.math.ethz.ch'
> Subject: Re: [R] is.weekend() odd behaviour
> 
> 
> Matthew Dowle wrote:
> 
> 
>>It seems is.weekend() is unsure ?
> 
> 
> It is completely sure, if an object is given is.weekend() knows about 
> as in:
> 
> table(is.weekend(sapply(1:100,
> function(i){Sys.sleep(0.05);as.chron(Sys.time())})))
> 
> (note the as.chron() call!)
> 
> Uwe Ligges
> 
> 
> 
> 
>># Start R 1.9.0 with --vanilla on windows xp
>># load package chron
>>
>>
>>
>>>table(is.weekend(sapply(1:100,
>>>function(i){Sys.sleep(0.05);Sys.time()})))
>>
>>FALSE  TRUE 
>>   68    32 
>>
>>
>>>date()
>>
>>[1] "Wed May 26 11:18:56 2004"
>>
>>
>>
>>>version         _              
>>
>>platform i386-pc-mingw32
>>arch     i386           
>>os       mingw32        
>>system   i386, mingw32  
>>status                  
>>major    1              
>>minor    9.0            
>>year     2004           
>>month    04             
>>day      12             
>>language R              
>>
>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html



From gilles.guillot at inapg.inra.fr  Wed May 26 18:55:52 2004
From: gilles.guillot at inapg.inra.fr (Gilles GUILLOT)
Date: Wed, 26 May 2004 16:55:52 +0000
Subject: [R] I/O fortran instructions and dyn.load
In-Reply-To: <Pine.LNX.4.44.0405261521000.3584-100000@gannet.stats>
References: <Pine.LNX.4.44.0405261521000.3584-100000@gannet.stats>
Message-ID: <200405261655.52772.gilles.guillot@inapg.inra.fr>

It works with  R CMD SHLIB test.f
Thanks.

Gilles 

> Try
>
> R CMD SHLIB test.f
>
> If SHLIB know it has to deal with Fortran code, it adds the appropriate
> libraries.
>
> On Wed, 26 May 2004, Gilles GUILLOT wrote:
> > I have the following Fortran code
> >
> > subroutine sub(path)
> > character*100 path
> > open(10,file=path)
> > end
> >
> > saved as test.f
> >
> > which I compile with
> > g77 -c test.f
> >
> > then I make the shared libary in R (Version 1.9.0) with
> > system("R CMD SHLIB test.o")
> >
> > so far, everything OK.
> >
> > But
> > dyn.load("test.so")
> > returns the following error message:
> > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> >         unable to load shared library "test.so":
> >   test.so: undefined symbol: f_open
> >
> > I get similar error messages with r/w Fortran instructions like
> > write(*,*) , read(*,*)
> >
> > I used to use such programs on my computer under mandrake linux 10.
> > The problem reported occurs on a new server operating under
> > another linux distrib (debian).
> >
> > Thanks in advance for any help,
> > Gilles

-- 
_____________________________________________________________________
Gilles GUILLOT
INRA -D??partement Math??matiques et Informatique Appliqu??es

Unit?? de Mixte de Recherche
INRA - INAPG - ENGREF
Institut National Agronomique de Paris-Grignon
16 rue Claude Bernard
75231 Paris cedex 5

Aile Claude Bernard
Niveau cours +3 ??tages

tel : +33 (0)1 44 08 72 71
fax : +33 (0)1 44 08 16 66
http://www.inapg.fr/ens_rech/mathinfo/personnel/guillot/welcome.html



From jpgranadeiro at fc.ul.pt  Wed May 26 17:01:22 2004
From: jpgranadeiro at fc.ul.pt (J. Pedro Granadeiro)
Date: Wed, 26 May 2004 16:01:22 +0100
Subject: [R] Common principle components
In-Reply-To: <95A1F7CE-AF10-11D8-A723-000A958F43CC@MUOhio.edu>
References: <200405261140.17842.jpgranadeiro@fc.ul.pt>
	<95A1F7CE-AF10-11D8-A723-000A958F43CC@MUOhio.edu>
Message-ID: <200405261601.22424.jpgranadeiro@fc.ul.pt>

I am sorry for not being clear. I meant the methods detailed in:

Flury, B. (1988). Common Principle Components Analysis and Related 
Multivariate Models, John Wiley and Sons, New York. 

(see also:
http://www.quantlet.com/mdstat/scripts/mva/htmlbook/mvahtmlframe97.html).

Thank you very much.

Jos?? Pedro Granadeiro

On Quarta Maio 26 2004 13:31, you wrote:
> Not sure what that (Common pc) is, but check prcomp() and princomp().
> Hank Stevens
>
> On May 26, 2004, at 6:40 AM, J. Pedro Granadeiro wrote:
> > 	Dear all,
> >
> > Can anyone point me to a package that can perform Common principle
> > components?
> >
> > Thank you.
> >
> > Jos?? P. Granadeiro
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
>
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/botany/bot/henry.html
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/



From wolski at molgen.mpg.de  Wed May 26 17:20:15 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 26 May 2004 17:20:15 +0200
Subject: [R] multi read.table function and read.table function not
	accepting col.names
In-Reply-To: <Pine.LNX.4.44.0405261442440.28125-100000@env-pc-phd13>
References: <Pine.LNX.4.44.0405261442440.28125-100000@env-pc-phd13>
Message-ID: <200405261720150447.01AF75F1@mail.math.fu-berlin.de>

Hi!

?

1.
?lapply

mydataframelist<- lapply(listwithpathstofile, read.table,col.names=names,na.strings="-999.00")

If you like to do more with the read in table say read.table and than some name assignments
you can also define a own function and pass it to lapply.
(or use the for loop.)


* by the way,by defining the variable names you mask the function names.

2.
Not shure if I understand you problem.
lapply returns a list and not a data.frame 
you can access each data.frame by eg. mydataframelist[[1]] etc. separatly



Eryk.

Ps. At 13.5.2004 there where an e-mail exchange concerning reading.tables.

*********** REPLY SEPARATOR  ***********

On 5/26/2004 at 2:45 PM Laura Quinn wrote:

>Thank you for your earlier help, I have a couple of related questions.
>
>With the lapply function, is it still possible to assign column names to
>each column of every data frame, again I have tried and it doesn't seem to
>like it..
>
>and is it also possible to assign names to each data frame when I do
>lapply rather than each one being a subset of a larger frame (I don't seem
>to be able to attach these as individual objects).
>
>Thanks again,
>Laura
>
>On Wed, 26 May 2004, Wolski wrote:
>
>> Hi!
>>
>> 1.
>> assuning that names is the vector with the names.
>> try col.names=names instead of "names"
>>
>> 2.
>> Several ways
>> a)
>> use
>> lapply(listwithpathstofiles,read.tabel,remaining, options) //u will get
>it stored in the list.
>> b)
>> or use for loop and append to list. mylist<-list()
>> c)
>> or look
>> ?assing
>> to generate several hundred objects in the envrovment.
>>
>> Sincerely Eryk
>>
>> *********** REPLY SEPARATOR  ***********
>>
>> On 5/26/2004 at 12:51 PM Laura Quinn wrote:
>>
>> >I am using R-1.8.0 on Debian.
>> >
>> >I'm trying to read in a large table (1441*16) which currently has no
>> >header line. I have set up a list of column names which is 16 names
>long.
>> >
>> >when i try the following:
>> >
>>
>>myfiledate.01<-read.table("filenamedate.01",row.names=NULL,col.names="names",na.strings="-999.00")
>> >
>> >I am returned with an error saying there are more columsh than column
>> >names. I am sure I have done this successfully in the past so can't
>> >understand the problem. I have done the read.table function without
>> >specifying col.names and it works fine and i end up with a 1441*16
>> >data.frame.
>> >
>> >Also as I have several hundred of these tables to read into R, all
>having
>> >the same dimension and all having the same column names, is it possible
>to
>> >automate R so they will all be read in at once - each table represents a
>> >different days worth of data.
>> >
>> >Thanks
>> >
>> >Laura
>> >
>> >______________________________________________
>> >R-help at stat.math.ethz.ch mailing list
>> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>>
>>
>>
>> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic
>> Ihnestrasse 63-73 14195 Berlin       'v'
>> tel: 0049-30-83875219               /   \
>> mail: wolski at molgen.mpg.de        ---W-W----   
>http://www.molgen.mpg.de/~wolski
>>
>>



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From Maarten.van.der.Hoeven at knmi.nl  Wed May 26 17:25:43 2004
From: Maarten.van.der.Hoeven at knmi.nl (Hoeven, Maarten van der)
Date: Wed, 26 May 2004 17:25:43 +0200
Subject: [R] Subtracting number of days from a date
Message-ID: <1F8990C21AC73945BE6AAC5AD6D4CAE9086CD3@BCSXAC.knmi.nl>

Hi group,

suppose I have a date, say May 15 2004, and I want to now what date it is 23 days before that date. The way to calculate the new date should (...) take account of leap years :)


In pseudocode:

olddate <- "May 15 2004"
newdate <- olddate-23

I looked around in POSIXct etc..., maybe I overlooked?

Thanks,
Maarten
-------------------------------------------------------------- 

Zie ook/see also: http://www.knmi.nl/maildisclaimer.html



From kwright at eskimo.com  Wed May 26 17:32:02 2004
From: kwright at eskimo.com (Kevin Wright)
Date: Wed, 26 May 2004 08:32:02 -0700 (PDT)
Subject: [R] Opening help pages in new tab of existing Mozilla Firebird
Message-ID: <200405261532.IAA10520@eskimo.com>


Subject pretty much says it all.  I currently have options()$browser
set to open help pages in Mozilla Firebird, but it starts a new window 
each time and I would like a new 'tab' in an existing window.

Sorry if this is obvious, but I can't find anything.

Kevin Wright



From bhaskar at cacmnet.com  Wed May 26 18:36:39 2004
From: bhaskar at cacmnet.com (Bhaskar S. Manda)
Date: Wed, 26 May 2004 10:36:39 -0600
Subject: [R] Need help on Mclus output
In-Reply-To: <20040526143313.M57395@cacmnet.com>
References: <001201c442c1$a14547d0$b2537cd9@maxmad9rubu4nk>
	<20040526143313.M57395@cacmnet.com>
Message-ID: <20040526153612.M79021@cacmnet.com>

On Wed, 26 May 2004 03:34:14 +0200, Max Marinucci wrote
> I have fitted a mixture with 4 normal components on a univariate 
> distribution using the Mclust package. Now, I would like to get a 
> variable with the cluster membership of each class, or in

If you've loaded
   library(mclust)

you can do
   print(my_Mclust_object$classification)

or assign it to a variable. 
   help(Mclust)

shows the following to be similarly available.
   bic,BIC,modelName,classification,uncertainty,mu,sigma,pro,z,loglik



From dbeyer at u.washington.edu  Wed May 26 17:52:55 2004
From: dbeyer at u.washington.edu (Dick Beyer)
Date: Wed, 26 May 2004 08:52:55 -0700 (PDT)
Subject: [R] No direct or inherited method for function "update"
In-Reply-To: <Pine.LNX.4.44.0405260616100.29295-100000@gannet.stats>
Message-ID: <Pine.LNX.4.43.0405260852550.25327@hymn11.u.washington.edu>

Thanks very much for your help.  Following your suggestion, I found that the offending bioconductor package is affy.  I will report that to the bioconductor folks.

*******************************************************************************
Richard P. Beyer, Ph.D.	University of Washington
Tel.:(206) 616 7378	Env. & Occ. Health Sci. , Box 354695
Fax: (206) 685 4696	4225 Roosevelt Way NE, # 100
			Seattle, WA 98105-6099
http://depts.washington.edu/ceeh/ServiceCores/FC5/FC5.html
*******************************************************************************

On Wed, 26 May 2004, Prof Brian Ripley wrote:

> Try doing this without all those Bioconductor packages loaded.  It does 
> work in base R, and I suspect that one of your packages has redefined 
> update (by adding S4 methods?).  If you track down exactly which package 
> causes the problem, you can report it to the appropriate person.
> 
> On Tue, 25 May 2004, Dick Beyer wrote:
> 
> > I used to be able to call update() for lme objects. Now I get this error:
> > 
> > >   ge.lme <- update(ge.lme, data=dat)
> > Error in update(ge.lme, data = dat) : No direct or inherited method for function "update" for this call
> > 
> > 
> > Here is the relevant portion of my code:
> > 
> > ge     <- eset[1,]
> > dat    <- data.frame(age, gen, fdr, ge)
> > ge.lme <- lme(fixed=ge~age+gen+age*gen, data=dat, random=~ 1| fdr)
> > for (i in 1:nrow(eset)) {
> >   dat$ge <- c(eset[i,])
> >   ge.lme <- update(ge.lme, data=dat)
> >   .
> >   .
> >   .
> > }
> > 
> > I am using:
> > base 1.9.0 
> > utils 1.9.0 
> > graphics 1.9.0 
> > stats 1.9.0 
> > methods 1.9.0 
> > Biobase 1.4.14 
> > affy 1.4.30 
> > gcrma 1.1.0 
> > annaffy 1.0.7 
> > KEGG 1.4.0 
> > GO 1.5.1 
> > mgu74av2 1.4.0 
> > nlme 3.1-48 
> > xtable 1.2-1 
> > 
> > Any help or suggestions would be most appreciated.
> > 
> > Thanks much,
> > Dick
> > *******************************************************************************
> > Richard P. Beyer, Ph.D.	University of Washington
> > Tel.:(206) 616 7378	Env. & Occ. Health Sci. , Box 354695
> > Fax: (206) 685 4696	4225 Roosevelt Way NE, # 100
> > 			Seattle, WA 98105-6099
> > http://depts.washington.edu/ceeh/ServiceCores/FC5/FC5.html
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
>



From vograno at evafunds.com  Wed May 26 17:52:44 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed, 26 May 2004 08:52:44 -0700
Subject: [R] Using R in C++
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A54B331C@phost015.EVAFUNDS.intermedia.net>

Look at "Writing R Extensions" guide. It covers both R-from-C and C-from-R.

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of J??rgen 
> Wallerman
> Sent: Wednesday, May 26, 2004 3:09 AM
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] Using R in C++
> 
> 
> Hello,
> 
> Is it possible to use R functions (in my case: ks.test()) 
> from C++ -applications? That is, I get the impression R can 
> execute C/C++ code, but is there any possibility to do the 
> opposite? Where can I find help?
> 
> 
> -------------------------------------------
> Ph. D. J??rgen Wallerman
> Swedish University of Agricultural Sciences
> Remote Sensing Laboratory
> S901 83 UME??
>  
> ###########################################
> 
> This message has been scanned by F-Secure 
> Anti-Virus for Microsoft Exchange.
> 
> ###########################################
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From mmorley at mail.med.upenn.edu  Wed May 26 17:56:51 2004
From: mmorley at mail.med.upenn.edu (Michael Morley)
Date: Wed, 26 May 2004 11:56:51 -0400
Subject: [R] Opening help pages in new tab of existing Mozilla Firebird
In-Reply-To: <200405261532.IAA10520@eskimo.com>
References: <200405261532.IAA10520@eskimo.com>
Message-ID: <40B4BE43.1070806@mail.med.upenn.edu>

Try this Mozilla Firefox extension,

http://www.intraplanar.net/projects/tabprefs/

If you more control over tabs there is this extension as well

http://white.sakura.ne.jp/~piro/xul/_tabextensions.html.en

-Mike


Kevin Wright wrote:

>Subject pretty much says it all.  I currently have options()$browser
>set to open help pages in Mozilla Firebird, but it starts a new window 
>each time and I would like a new 'tab' in an existing window.
>
>Sorry if this is obvious, but I can't find anything.
>
>Kevin Wright
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Michael Morley
Bioinformatics Specialist
University of Pennsylvania
Department of Pediatrics
3516 Civic Center Blvd.,
510B Abramson Pediatric Research Center,
Philadelphia, PA 19104-4318.
Phone: (215) 590-7673
FAX: (215) 590-3709



From MSchwartz at MedAnalytics.com  Wed May 26 18:06:59 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 26 May 2004 11:06:59 -0500
Subject: [R] Opening help pages in new tab of existing Mozilla Firebird
In-Reply-To: <200405261532.IAA10520@eskimo.com>
References: <200405261532.IAA10520@eskimo.com>
Message-ID: <1085587619.6915.64.camel@localhost.localdomain>

On Wed, 2004-05-26 at 10:32, Kevin Wright wrote:
> Subject pretty much says it all.  I currently have options()$browser
> set to open help pages in Mozilla Firebird, but it starts a new window
> each time and I would like a new 'tab' in an existing window.
> 
> Sorry if this is obvious, but I can't find anything.
> 
> Kevin Wright


You do not indicate which OS you are running, but under Linux, you can
use a script such as the following. It will check the current process
list to see if an instance of Firefox is already present. If so, it will
open a new tab. Otherwise, it opens a new window.

#!/bin/sh 

# if 'firefox-bin' in current ps listing,
if ps -e|grep firefox-bin >/dev/null 2>&1; then
  firefox -remote "openURL(${1}, new-tab)" && exit 0
else 
#open new instance 
  firefox $1 && exit 0
fi


Copy the above into a script file and set it to be executable (chmod +x
ScriptFileName). Then set options()$browser to use the script file.

Note also that the recent version of the Mozilla standalone browser is
called Firefox, in recognition of the existence of the Firebird
(formerly Interbase) SQL database project.

HTH,

Marc Schwartz



From maechler at stat.math.ethz.ch  Wed May 26 18:16:39 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 26 May 2004 18:16:39 +0200
Subject: [R] Common principle components
In-Reply-To: <200405261601.22424.jpgranadeiro@fc.ul.pt>
References: <200405261140.17842.jpgranadeiro@fc.ul.pt>
	<95A1F7CE-AF10-11D8-A723-000A958F43CC@MUOhio.edu>
	<200405261601.22424.jpgranadeiro@fc.ul.pt>
Message-ID: <16564.49895.634360.288389@gargle.gargle.HOWL>

>>>>> "JosePG" == J Pedro Granadeiro <jpgranadeiro at fc.ul.pt>
>>>>>     on Wed, 26 May 2004 16:01:22 +0100 writes:

    JosePG> I am sorry for not being clear. I meant the methods detailed in:
    JosePG> Flury, B. (1988). Common Principle Components Analysis and Related 
    JosePG> Multivariate Models, John Wiley and Sons, New York. 

Well, I'm 100% sure the title of that book is different
(and so should be your e-mail subject)

Hint: Look carefully at the end of the 2nd word ...



From spencer.graves at pdf.com  Wed May 26 18:25:27 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 26 May 2004 09:25:27 -0700
Subject: [R] Common principle components
In-Reply-To: <16564.49895.634360.288389@gargle.gargle.HOWL>
References: <200405261140.17842.jpgranadeiro@fc.ul.pt>	<95A1F7CE-AF10-11D8-A723-000A958F43CC@MUOhio.edu>	<200405261601.22424.jpgranadeiro@fc.ul.pt>
	<16564.49895.634360.288389@gargle.gargle.HOWL>
Message-ID: <40B4C4F7.8060800@pdf.com>

Google just returned "about" 1.8M hits for "principle components" and 
3.2M hits for "principal components".  Evidently, eigenvectors are more 
your friend (pal) than a structure for the space by a factor of roughly 
2 to 1. 

spencer graves

Martin Maechler wrote:

>>>>>>"JosePG" == J Pedro Granadeiro <jpgranadeiro at fc.ul.pt>
>>>>>>    on Wed, 26 May 2004 16:01:22 +0100 writes:
>>>>>>            
>>>>>>
>
>    JosePG> I am sorry for not being clear. I meant the methods detailed in:
>    JosePG> Flury, B. (1988). Common Principle Components Analysis and Related 
>    JosePG> Multivariate Models, John Wiley and Sons, New York. 
>
>Well, I'm 100% sure the title of that book is different
>(and so should be your e-mail subject)
>
>Hint: Look carefully at the end of the 2nd word ...
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From Achim.Zeileis at wu-wien.ac.at  Wed May 26 18:30:40 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 26 May 2004 18:30:40 +0200
Subject: [R] thanks again
In-Reply-To: <40B387D4.7050802@bcm.tmc.edu>
References: <40B387D4.7050802@bcm.tmc.edu>
Message-ID: <20040526183040.0cb1944a.Achim.Zeileis@wu-wien.ac.at>

Chad:

> Thanks again for the conference.  We had good fun.

Thanks, we too ;-) If only I could get some sleep now...

> I want a useR t-shirt.  After lots of drinking and discussion with
> Fritz Leisch at dinner on saturday, I feel there will be no chance for
> an official T-shirt.
> 
> My question is:  any advice/ thoughts on how there can be T-shirts for
> the conference?

As this useR! is over, I guess it's a bit too late for a useR! 2004
shirt.

In general, I would agree with you that it would be nice (and not only
for fun) to have shirts (and coffee mugs and basecaps and ...) with R
logos or maybe useR! logos. This has been discussed now and then and if
I recall it correctly the reason that nobody actually started doing it
is that you would have to spend some time setting it up - and most
people prefer writing R code instead of mailing R shirts around the
world. Time was the main reason for me not do organize shirts for the
useR! - there were so many other things to do and prepare.
Another point which always kept me from thinking about something like
this more seriously is the poor quality of the R logo.
But John Fox mentioned in a discussion that instead of some R user
doing the work, maybe there are T-shirt mailorders around which could do
most of the work. So maybe I will have the time to look at this.

Best wishes from Vienna,
Achim



From ggrothendieck at myway.com  Wed May 26 18:34:23 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 26 May 2004 16:34:23 +0000 (UTC)
Subject: FW: [R] is.weekend() odd behaviour
References: <78166BFC5165D811AA0400065BF0324B1B918A@wisconsin.concordia>
Message-ID: <loom.20040526T182307-732@post.gmane.org>


I think the user should be forced to convert explicitly from POSIXct
to chron before is.weekend is used.  That way the user will know for 
sure what time zone he is converting with respect to.  Having it done 
silently will just cause subtle errors.

IMHO the correct functionality is to give an error message if the user
attempts to provide a POSIXct date.


Matthew Dowle <mdowle <at> concordiafunds.com> writes:

: 
: Kurt,
: 
: Uwe suggested I write to you as maintainer of chron ... at the start of
: is.weekend, in the check on the argument type, maybe just change chron() to
: as.chron()? This would ensure as.chron.POSIXt gets called on POSIXt
: arguments, and (I think) fixes the problem. I tested and it seems ok. No
: warning/error required.
: 
: > is.weekend
: function(x)
: {
:     if(!inherits(x, "dates"))
:         if(is.character(x) || is.numeric(x))
:             x <- as.chron(x)   # was  x <- chron(x)
:         else stop("x must inherit from dates")
:     ....
: }
: 
: -----Original Message-----
: From: Uwe Ligges [mailto:ligges <at> statistik.uni-dortmund.de] 
: Sent: 26 May 2004 13:20
: To: Matthew Dowle
: Cc: 'r-help <at> stat.math.ethz.ch'
: Subject: Re: [R] is.weekend() odd behaviour
: 
: 
: Matthew Dowle wrote:
: 
: > Thanks. When is.weekend() is given an object it doesn't know about, 
: > could a warning or error be added? At the moment, I think you're 
: > agreeing, that it silently returns a random TRUE/FALSE.
: 
: It's not random, it depends on the value of Sys.time(), which also 
: includes seconds .....
: I agree that a warning or error might be sensible. So I think you are 
: about to write a note to the maintainer of package "chron" including 
: patches for is.weekend() and friends?
: 
: Uwe Ligges
: 
: 
: > -----Original Message-----
: > From: Uwe Ligges [mailto:ligges <at> statistik.uni-dortmund.de]
: > Sent: 26 May 2004 11:55
: > To: Matthew Dowle
: > Cc: 'r-help <at> stat.math.ethz.ch'
: > Subject: Re: [R] is.weekend() odd behaviour
: > 
: > 
: > Matthew Dowle wrote:
: > 
: > 
: >>It seems is.weekend() is unsure ?
: > 
: > 
: > It is completely sure, if an object is given is.weekend() knows about 
: > as in:
: > 
: > table(is.weekend(sapply(1:100,
: > function(i){Sys.sleep(0.05);as.chron(Sys.time())})))
: > 
: > (note the as.chron() call!)
: > 
: > Uwe Ligges
: > 
: > 
: > 
: > 
: >># Start R 1.9.0 with --vanilla on windows xp
: >># load package chron
: >>
: >>
: >>
: >>>table(is.weekend(sapply(1:100,
: >>>function(i){Sys.sleep(0.05);Sys.time()})))
: >>
: >>FALSE  TRUE 
: >>   68    32 
: >>
: >>
: >>>date()
: >>
: >>[1] "Wed May 26 11:18:56 2004"
: >>
: >>
: >>
: >>>version         _              
: >>
: >>platform i386-pc-mingw32
: >>arch     i386           
: >>os       mingw32        
: >>system   i386, mingw32  
: >>status                  
: >>major    1              
: >>minor    9.0            
: >>year     2004           
: >>month    04             
: >>day      12             
: >>language R



From edd at debian.org  Wed May 26 18:36:27 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 26 May 2004 11:36:27 -0500
Subject: [R] thanks again
In-Reply-To: <20040526183040.0cb1944a.Achim.Zeileis@wu-wien.ac.at>
References: <40B387D4.7050802@bcm.tmc.edu>
	<20040526183040.0cb1944a.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <20040526163626.GA27667@sonny.eddelbuettel.com>

On Wed, May 26, 2004 at 06:30:40PM +0200, Achim Zeileis wrote:
> As this useR! is over, I guess it's a bit too late for a useR! 2004
> shirt.
> 
> In general, I would agree with you that it would be nice (and not only
> for fun) to have shirts (and coffee mugs and basecaps and ...) with R
> logos or maybe useR! logos. This has been discussed now and then and if
> I recall it correctly the reason that nobody actually started doing it
> is that you would have to spend some time setting it up - and most
> people prefer writing R code instead of mailing R shirts around the
> world. Time was the main reason for me not do organize shirts for the
> useR! - there were so many other things to do and prepare.
> Another point which always kept me from thinking about something like
> this more seriously is the poor quality of the R logo.
> But John Fox mentioned in a discussion that instead of some R user
> doing the work, maybe there are T-shirt mailorders around which could do
> most of the work. So maybe I will have the time to look at this.

I visited such a site a few months back, but cannot recall the name or URL.
They had e.g. numerous Debian things.  If the useR png image was made
available, they could do the commercialisation.  With a bit of luck, we may
find a shop that would also donate back a percentage of the proceeds the
family^H^H^H^H^H^foundation. There is probably less merit in the purely
commerical play.

Dirk

-- 
The relationship between the computed price and reality is as yet unknown.  
                                             -- From the pac(8) manual page



From andrewr at uidaho.edu  Wed May 26 18:40:38 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Wed, 26 May 2004 09:40:38 -0700 (PDT)
Subject: [R] thanks again
In-Reply-To: <20040526163626.GA27667@sonny.eddelbuettel.com>
References: <40B387D4.7050802@bcm.tmc.edu>
	<20040526183040.0cb1944a.Achim.Zeileis@wu-wien.ac.at>
	<20040526163626.GA27667@sonny.eddelbuettel.com>
Message-ID: <Pine.GSO.4.56.0405260940090.19635@cyclone.csrv.uidaho.edu>

http://www.cafepress.com/

is one such option.  I have no personal experience with it.

Andrew

On Wed, 26 May 2004, Dirk Eddelbuettel
wrote:

> On Wed, May 26, 2004 at 06:30:40PM +0200, Achim Zeileis wrote:
> > As this useR! is over, I guess it's a bit too late for a useR! 2004
> > shirt.
> >
> > In general, I would agree with you that it would be nice (and not only
> > for fun) to have shirts (and coffee mugs and basecaps and ...) with R
> > logos or maybe useR! logos. This has been discussed now and then and if
> > I recall it correctly the reason that nobody actually started doing it
> > is that you would have to spend some time setting it up - and most
> > people prefer writing R code instead of mailing R shirts around the
> > world. Time was the main reason for me not do organize shirts for the
> > useR! - there were so many other things to do and prepare.
> > Another point which always kept me from thinking about something like
> > this more seriously is the poor quality of the R logo.
> > But John Fox mentioned in a discussion that instead of some R user
> > doing the work, maybe there are T-shirt mailorders around which could do
> > most of the work. So maybe I will have the time to look at this.
>
> I visited such a site a few months back, but cannot recall the name or URL.
> They had e.g. numerous Debian things.  If the useR png image was made
> available, they could do the commercialisation.  With a bit of luck, we may
> find a shop that would also donate back a percentage of the proceeds the
> family^H^H^H^H^H^foundation. There is probably less merit in the purely
> commerical play.
>
> Dirk
>
> --
> The relationship between the computed price and reality is as yet unknown.
>                                              -- From the pac(8) manual page
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Andrew Robinson			     Ph: 208 885 7115
Department of Forest Resources	     Fa: 208 885 6226
University of Idaho		     E : andrewr at uidaho.edu
PO Box 441133			     W : http://www.uidaho.edu/~andrewr
Moscow ID 83843			     Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From ggrothendieck at myway.com  Wed May 26 18:36:20 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 26 May 2004 16:36:20 +0000 (UTC)
Subject: [R] Subtracting number of days from a date
References: <1F8990C21AC73945BE6AAC5AD6D4CAE9086CD3@BCSXAC.knmi.nl>
Message-ID: <loom.20040526T183524-588@post.gmane.org>

Hoeven, Maarten van der <Maarten.van.der.Hoeven <at> knmi.nl> writes:

: suppose I have a date, say May 15 2004, and I want to now what date it is 23 
days before that date. The way to
: calculate the new date should (...) take account of leap years :)
: 
: In pseudocode:
: 
: olddate <- "May 15 2004"
: newdate <- olddate-23
: 
: I looked around in POSIXct etc..., maybe I overlooked?

as.Date("2005-05-24")-23



From ripley at stats.ox.ac.uk  Wed May 26 18:41:22 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 May 2004 17:41:22 +0100 (BST)
Subject: [R] Subtracting number of days from a date
In-Reply-To: <1F8990C21AC73945BE6AAC5AD6D4CAE9086CD3@BCSXAC.knmi.nl>
Message-ID: <Pine.LNX.4.44.0405261739310.1032-100000@gannet.stats>

On Wed, 26 May 2004, Hoeven, Maarten van der wrote:

> suppose I have a date, say May 15 2004, and I want to now what date it
> is 23 days before that date. The way to calculate the new date should
> (...) take account of leap years :)
> 
> 
> In pseudocode:
> 
> olddate <- "May 15 2004"
> newdate <- olddate-23
> 
> I looked around in POSIXct etc..., maybe I overlooked?

olddate <- as.Date("May 15 2004", "%B %d %Y")
newdate <- olddate - 23
newdate
[1] "2004-04-22"
format(newdate, "%B %d %Y")
[1] "April 22 2004"

looks straightforward enough to me (and it knows about leap years).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wolski at molgen.mpg.de  Wed May 26 18:53:51 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 26 May 2004 18:53:51 +0200
Subject: [R] thanks again
In-Reply-To: <Pine.GSO.4.56.0405260940090.19635@cyclone.csrv.uidaho.edu>
References: <40B387D4.7050802@bcm.tmc.edu>
	<20040526183040.0cb1944a.Achim.Zeileis@wu-wien.ac.at>
	<20040526163626.GA27667@sonny.eddelbuettel.com>
	<Pine.GSO.4.56.0405260940090.19635@cyclone.csrv.uidaho.edu>
Message-ID: <200405261853510322.020521F2@mail.math.fu-berlin.de>

Hi!

"The magic cauldron"

http://www.catb.org/~esr/writings/magic-cauldron/magic-cauldron.html

and

http://www.catb.org/~esr/writings/magic-cauldron/magic-cauldron-9.html#ss9.4


Sincerely
Eryk

*********** REPLY SEPARATOR  ***********

On 5/26/2004 at 9:40 AM Andrew Robinson wrote:

>http://www.cafepress.com/
>
>is one such option.  I have no personal experience with it.
>
>Andrew
>
>On Wed, 26 May 2004, Dirk Eddelbuettel
>wrote:
>
>> On Wed, May 26, 2004 at 06:30:40PM +0200, Achim Zeileis wrote:
>> > As this useR! is over, I guess it's a bit too late for a useR! 2004
>> > shirt.
>> >
>> > In general, I would agree with you that it would be nice (and not only
>> > for fun) to have shirts (and coffee mugs and basecaps and ...) with R
>> > logos or maybe useR! logos. This has been discussed now and then and if
>> > I recall it correctly the reason that nobody actually started doing it
>> > is that you would have to spend some time setting it up - and most
>> > people prefer writing R code instead of mailing R shirts around the
>> > world. Time was the main reason for me not do organize shirts for the
>> > useR! - there were so many other things to do and prepare.
>> > Another point which always kept me from thinking about something like
>> > this more seriously is the poor quality of the R logo.
>> > But John Fox mentioned in a discussion that instead of some R user
>> > doing the work, maybe there are T-shirt mailorders around which could
>do
>> > most of the work. So maybe I will have the time to look at this.
>>
>> I visited such a site a few months back, but cannot recall the name or
>URL.
>> They had e.g. numerous Debian things.  If the useR png image was made
>> available, they could do the commercialisation.  With a bit of luck, we
>may
>> find a shop that would also donate back a percentage of the proceeds the
>> family^H^H^H^H^H^foundation. There is probably less merit in the purely
>> commerical play.
>>
>> Dirk
>>
>> --
>> The relationship between the computed price and reality is as yet
>unknown.
>>                                              -- From the pac(8) manual
>page
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>>
>
>Andrew Robinson			     Ph: 208 885 7115
>Department of Forest Resources	     Fa: 208 885 6226
>University of Idaho		     E : andrewr at uidaho.edu
>PO Box 441133			     W : http://www.uidaho.edu/~andrewr
>Moscow ID 83843			     Or: http://www.biometrics.uidaho.edu
>No statement above necessarily represents my employer's opinion.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From drhosini at hotmail.com  Wed May 26 19:20:42 2004
From: drhosini at hotmail.com (Moustafa ElHousinie)
Date: Wed, 26 May 2004 17:20:42 +0000
Subject: [R] (no subject)
Message-ID: <BAY14-F30T7J7mgsQQI00005d6f@hotmail.com>

I have data on disappearance of virus C from blood of acutely infected
    humans.  Blood samples were taken approximately 2, 3 and 6 months after 
the
    expected date of exposure.  It is noted that :
    1- not all timepoints are available
    2- in few cases the person turned negative early (2-3 months) to turm 
back
    to positive after 6 months
    3- the definition of spontaneos clearance is not well established but
    usually treatement, if any, should be started if the person remain 
positive
    after 5-6 months from exposure
    the questions are:
    is this a logistic regression problem or time to event (lifetable 
analysis)
    problem? and in either case HOW to proceed with R
    thanks in advance
    Mostafa



From rn001 at cebas.csic.es  Wed May 26 19:23:25 2004
From: rn001 at cebas.csic.es (javier garcia - CEBAS)
Date: Wed, 26 May 2004 19:23:25 +0200
Subject: [R] identify() - image()
Message-ID: <200405261722.i4QHMnp18928@natura.cebas.csic.es>

Hi all;
Just to ask if you know about any available function in R to identify points 
in a image plotted in X11. Something like the function identify(), but able 
to extract (x,y,value) groups from the image.

Thanks and best regards,

Javier



From B.Rowlingson at lancaster.ac.uk  Wed May 26 19:40:42 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 26 May 2004 18:40:42 +0100
Subject: [R] identify() - image()
In-Reply-To: <200405261722.i4QHMnp18928@natura.cebas.csic.es>
References: <200405261722.i4QHMnp18928@natura.cebas.csic.es>
Message-ID: <40B4D69A.80600@lancaster.ac.uk>

javier garcia - CEBAS wrote:
> Hi all;
> Just to ask if you know about any available function in R to identify points 
> in a image plotted in X11. Something like the function identify(), but able 
> to extract (x,y,value) groups from the image.

  this is what I use:

image.identify <- function(xyz, mark=T, digits=3){

   nx <- length(xyz$x) - 1
   ny <- length(xyz$y) - 1
   if(!all(dim(xyz$z)==c(nx,ny))){
     stop("Really need image specified by cell edges")
   }
   res <- data.frame()
   xy <- locator(1)
   while(!is.null(xy)){
     xbin <- as.numeric(cut(xy$x,xyz$x))
     ybin <- as.numeric(cut(xy$y,xyz$y))
     if(mark){
       points(xy$x,xy$y,pch=19,cex=.5,col="blue")

text(xy$x,xy$y,format(xyz$z[xbin,ybin],digits=digits),adj=-.2,col="blue")
     }
     cat("[",xbin,",",ybin,"] = ",xyz$z[xbin,ybin],"\n",sep='')
     res <- 
rbind(res,data.frame(i=xbin,j=ybin,x=xy$x,y=xy$y,z=xyz$z[xbin,ybin]))
     xy <- locator(1)
   }
   res
}

Try:

  > m=list(x=1:11,y=1:11,z=matrix(runif(100),10,10))
  > image(m)
  > identify.image(m)

  then click some things. Button 2 to finish.

  The returned data frame gives row and column in the 'z' matrix, x and 
y coordinates, and value of the z matrix at that point.

  Baz



From thpe at hhbio.wasser.tu-dresden.de  Wed May 26 19:51:03 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Wed, 26 May 2004 19:51:03 +0200
Subject: [R] identify() - image()
In-Reply-To: <200405261722.i4QHMnp18928@natura.cebas.csic.es>
References: <200405261722.i4QHMnp18928@natura.cebas.csic.es>
Message-ID: <40B4D907.4060709@hhbio.wasser.tu-dresden.de>

javier garcia - CEBAS wrote:
> Hi all;
> Just to ask if you know about any available function in R to identify points 
> in a image plotted in X11. Something like the function identify(), but able 
> to extract (x,y,value) groups from the image.

Maybe, something like that?

z <- matrix(runif(100),10,10)
image(list(x = 0:9, y = 0:9, z = z))
p <- locator(1)
z[round(p$x), round(p$y)]

Thomas P.



From solares at unsl.edu.ar  Wed May 26 20:00:21 2004
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Wed, 26 May 2004 15:00:21 -0300 (ART)
Subject: [R] time
Message-ID: <47659.170.210.173.216.1085594421.squirrel@inter17.unsl.edu.ar>

Hi, i need select data from data frame, for example:
x is a data frame with values in jump to 5 seconds
12:10:00 51 //one minute
12:10:05 63
12:10:10 75
12:10:15 88
..
12:10:59 45
12:11:00 46 //another minute
12:11:05 11
..
Have a command what to select the data minute to  minute, for example
in the example above i need the maximun values minute to  minute
1?? minute-->88
2?? minute--> 46
Thanks Ruben



From wasserberg at wisc.edu  Wed May 26 21:03:21 2004
From: wasserberg at wisc.edu (GIDEON WASSERBERG)
Date: Wed, 26 May 2004 14:03:21 -0500
Subject: [R] 2 way repeated measures ANOVA using R: syntax and reporting
	question
Message-ID: <bdb685bdc317.bdc317bdb685@wiscmail.wisc.edu>

Dear Friends

I have a technical question about conducting 2 way repeated measures ANOVA analysis using R.

1. Data set: repeated measurement of activity over night (2 hr. intervals)
repeated (within subject)factor: Hours
Between subject: Species, Sex
Dependent variables: specimens

Here is how the data arranged for the analysis:

Subject	Replicate	Hour	Sp.	Specimens
1	1	       1	a	
2	1	       1	a	
3	1	       1	b	
4	1	       1	b	
5	2	       1	a	
6	2	       1	a	
7	2	       1	b	
8	2	       1	b	
1	1	       2	a	
2	1	       2	a	
3	1	       2	b	
4	1	       2	b	
5	2	       2	a
6	2	       2	a
7	2	       2	b
8	2	       2	b


here's the command I used: 
summary(aov(Specimens~Species*Sex*Hours+Error(Subject/Hours),data=SP)).

My question is - is that the correct way to do it??

2. Below is the results output:
A. I am not sure I understand what is the meaning of the two error terms I get. 
Does the first one show error between subjetcs
and the second - error within subjects?

Error: Subject - 
        Df  Sum Sq Mean Sq
Species  1 0.60715 0.60715

Error: Subject:Hours
      Df Sum Sq Mean Sq
Hours  1 158.24  158.24

Error: Within
                    Df Sum Sq Mean Sq F value    Pr(>F)    
Species              2  35.19   17.59 34.3017 2.733e-15 ***
Sex                  1  18.98   18.98 37.0092 1.493e-09 ***
Hours                1  40.02   40.02 78.0278 < 2.2e-16 ***
Species:Sex          2   1.29    0.64  1.2568    0.2849    
Species:Hours        2   9.95    4.97  9.6993 6.530e-05 ***
Sex:Hours            1   0.66    0.66  1.2778    0.2585    
Species:Sex:Hours    2   1.38    0.69  1.3498    0.2596    
Residuals         1486 762.20    0.51                      
---
B. How do I summarize this information for a report?
Is the below suggestion acceptable?
-------------------------------------------------------------------------------

Source	              df	SS	MS	                 F	    P
-----------------------------------------------------------------------------
Species	               2	35.19	17.59	                34.3     <0.0001
Sex          	       1	18.98	18.98	                37.01	  <0.0001
Species:Sex          	2	1.29	0.64  	               1.2568    0.2849    
Subject(Species)	1	0.60715	0.60715		
Subject(Hours)	       1	158.24  158.24  		
Hour	                1	40.02	  40.02	                78.0278	   <0.0001
Species:Hours        	2	9.95            4.97  	         9.6993	   <0.0001
Sex:Hours            	1	0.66    	0.66             1.2778    0.2585    
Species:Sex:Hours    	2	1.38    	0.69  	         1.3498	0.2596    
Residuals	     1486	762.20    	0.51 
---------------------------------------------------------------------------------                     		
Very much obliged for your kind response

Gideon


Gideon Wasserberg (Ph.D.)
Wildlife research unit,
Department of wildlife ecology,
University of Wisconsin
218 Russell labs, 1630 Linden dr.,
Madison, Wisconsin 53706, USA.
Tel.:608 265 2130, Fax: 608 262 6099



From kwright at eskimo.com  Wed May 26 21:31:03 2004
From: kwright at eskimo.com (Kevin Wright)
Date: Wed, 26 May 2004 12:31:03 -0700 (PDT)
Subject: [R] Outlier identification according to Hardin & Rocke (1999) 
Message-ID: <200405261931.MAA11989@eskimo.com>

I'm trying to use a paper by Hardin & Rocke: http://handel.cipic.ucdavis.edu/~dmrocke/Robdist5.pdf
as a guide for a function to identify outliers in multivariate data.  Attached below is a function that is my attempt to reproduce their method and also a test to see what fraction of the data are identified as outliers.  Using this function I am able to reproduce their results regarding the asymptotic chi-square method, but not their new method using an asymptotic F method.  In particular, the asymptotic F method (and adjusted F method) seem to give critical distances that are too large and therefore no (or few) points are identified as outliers.

I have tried unsuccessfully to contact the authors of the paper to seek further information and / or numerical examples.

I would be most interested if anybody has used the method of Hardin & Rocke or can take the function I have provided below and modify it to reproduce their results.  Note: The mvtnorm package is required.

Best,

Kevin Wright




outliers.id <- function(x, alpha=.05){
  # See: Hardin & Rocke (1999), "The Distribution of Robust Distances"
  # http://handel.cipic.ucdavis.edu/~dmrocke/Robdist5.pdf

  # See: Hardin & Rocke (2002), "Outlier Detection in the Multiple Cluster
  # Setting Using the Minimum Covariance Determinant Estimator"
  # http://bioinfo.cipic.ucdavis.edu/publications/print_pub?pub_id=736&category=1
  
  # Drop factors first
  factors <- names(x)[sapply(x,is.factor)] 
  if(length(factors)>0)
    x <- x[-factors]

  # Get the robust location/scale estimates
  require(MASS)
  covResult <- cov.rob(x)
  
  # Calculate the mahalanobis distance for each datum
  distance <- mahalanobis(x,covResult$center,covResult$cov)
  
  n <- nrow(x)
  p <- ncol(x)
  h <- floor((n+p+1)/2)

  # Asymptotic chi-square method (page 11)
  # Often identifies too many points as outliers
  critical.chi <- qchisq(1-alpha, p)
  cat("Chi square critical distance:", critical.chi,"\n")

  # Now the approximate F method.  First estimate c (page 19)
  c <- pchisq(qchisq(1-h/n, p),p+2) / (h/n)
  
  # Now to estimate m (page 22)
  a <- (n-h)/n
  qa <- qchisq(1-a,p)
  ca <- (1-a)/pchisq(qa,p+2)
  c2 <- -pchisq(qa,p+2)/2
  c3 <- -pchisq(qa,p+4)/2
  c4 <- 3 * c3
  b1 <- ca * (c3 - c4) / (1-a)
  b2 <- 0.5 + ca/(1-a) * (c3 - qa/p * (c2 + (1-a)/2))
  v1 <- (1-a) * b1^2 * (a * (ca * qa/p -1)^2 -1) -
    2 * c3 * ca^2 * (3* (b1 - p * b2)^2 + (p+2) * b2 * (2*b1 - p*b2))
  v2 <- n * (b1 * (b1 - p*b2) * (1-a))^2 * ca^2
  v <- v1/v2
  m <- 2/(ca^2 * v)

  # (page 17)
  critical.F.asy <- p*m * qf(1-alpha, p, m-p+1) / (c * (m-p+1))
  cat("Asymptotic F critical distance:",critical.F.asy,"\n")
  
  # The small-sample (hundreds of points) adjustment to m.
  # Hardin & Rocke, 2002, page 631
  m <- m * exp(0.725 - 0.00663*p -0.0780 * log(n))
  # Finally, the critical point (using adjusted m)
  critical.F.adj <- p*m*qf(1-alpha, p, m-p+1) / (c * (m-p+1))
  cat("Adjusted asymptotic F critical distance:",critical.F.adj,"\n")
      
  #outliers <- as.integer(distance > critical)
  x$Distances <- distance
  #x$Outliers <- outliers
  attr(x,"critical.chi") <- critical.chi
  attr(x,"critical.F.asy") <- critical.F.asy
  attr(x,"critical.F.adj") <- critical.F.adj
  return(x)
}

# Try to reproduce the tables in the paper
if(FALSE){
  require(mvtnorm)
  # Simulate data
  n <- 500;p <- 5
  dat <- rmvnorm(n,rep(0,p),diag(p))

  # Identify outliers
  dat.out <- outliers.id(as.data.frame(dat),alpha=.05)
  
  # Now see what percent are identified as outliers
  cat("Chi-square \n")
  100*sum(dat.out$Distances>attr(dat.out,"critical.chi"))/n
  cat("Approximate F asymptotic \n")
  100*sum(dat.out$Distances>attr(dat.out,"critical.F.asy"))/n
  cat("Approximate F adjusted \n")
  100*sum(dat.out$Distances>attr(dat.out,"critical.F.adj"))/n
}



From wang at galton.uchicago.edu  Wed May 26 21:34:04 2004
From: wang at galton.uchicago.edu (Yong Wang)
Date: Wed, 26 May 2004 14:34:04 -0500 (CDT)
Subject: [R] A data selection problem, suggestions highly appreciated
In-Reply-To: <200405261001.i4QA1Jpp024115@hypatia.math.ethz.ch>
References: <200405261001.i4QA1Jpp024115@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0405261412390.10220@aitken.uchicago.edu>

Hi, All
I get following question:
A data format like following:

[Day time  x y]

Jan1 18:56:24 x1 y1
Jan1 18:56:25 x2 y2
Jan1 18:56:27 x3 y3
Jan1 18:56:28 x4 y4
Jan1 18:56:31 x5 y5
.....................
.....................

what I wanna do is to partion the time interval by unit of 5 seconds.
and pick x,y corresponding to the last time within that interval. for the 
example above,
suppose 18:56:24 is the starting time, the time included in the interval 
will be up to 18:56:28, therefore I want to get x4 and y4, and store them 
somewhere else. 
you might know this is the so called high frequency data. can you let me 
know how to do this partion and pick in R or Splus. 
suggestions are really and hihgly appreciated. 

thank you very much.
best regards
yong



From joseclaudio.faria at terra.com.br  Wed May 26 21:58:53 2004
From: joseclaudio.faria at terra.com.br (joseclaudio.faria)
Date: Wed, 26 May 2004 16:58:53 -0300
Subject: [R] R: Help (two-way analysis of variance with contrasts)
Message-ID: <001d01c4435b$e4c99e80$01fea8c0@sapetinga>

Dears members of R list,

It would like that a more experienced statician in R helped me to complete
the analysis to follow:

r = gl(3, 8, label = c('r1', 'r2', 'r3'))
e = rep(gl(2, 4, label = c('e1', 'e2')), 3)
y = c(26.2, 26.0, 25.0, 25.4, 24.8, 24.6, 26.7, 25.2, 25.7, 26.3, 25.1,
26.4,
         19.6, 21.1, 19.0, 18.6, 22.8, 19.4, 18.8, 19.2, 19.8, 21.4, 22.8,
21.3)

df = data.frame(r, e, y)
attach(df)
  par(mfrow=c(2,1))
  interaction.plot(r, e, y, col = 'blue', ylab = 'y', xlab = 'r')

  interaction.plot(e, r, y, col = 'blue', ylab = 'y', xlab = 'r')
  av1 = aov(y ~ r*e)

  av2 = aov(y ~ r/e)
  efR_E = summary(av2, split = list('r:e' = list('e1 vs e2/r1' = 1, 'e1 vs
e2/r2' = 2, 'e1 vs e2/r3' = 3)))

  av3  = aov(y ~ e/r)
  efE_R = summary(av3, split = list('e:r' = list('r/e1' = c(1,3), 'r/e2' =
c(2,4))))

  mds = model.tables(av1, ty = 'means')
detach(df)

cat('\nData:'); cat('\n')
print(df)

cat('\nMeans:'); cat('\n')
print(mds)

cat('\nANOVA:'); cat('\n')
print(summary(av1)); cat('\n')

cat('\nANOVA - E effect in R levels:'); cat('\n')
print(efR_E); cat('\n')

cat('\nANOVA - R effect in E levels:'); cat('\n')
print(efE_R); cat('\n')

#I would like to get as resulted (efE_R) like this:
# ANOVA - R effect (contrasts) in E levels:
#                                Df       Sum Sq    Mean Sq   F value
Pr(>F)
# e                               1     19.082
#  e:r                           (4)  (156.622)
#    e:r: r/e1                 (2)    (87.122)
#      r1 vs (r2,r3)/e1     1      ?                           ?
?            ?
#      r2 vs r3/e1            1      ?                           ?
?            ?
#    e:r: r/e2                  (2)   (69.500)
#      r1 vs (r2,r3)/e1      1      ?                           ?
?            ?
#      r2 vs r3/e2             1      ?                           ?
?            ?
# Residuals                  18      23.090     1.283



#Through manual calculations I got:
# ANOVA - R effect in E levels:
#                           Df       Sum Sq    Mean Sq   F value    Pr(>F)
# e                          1     19.082
#  e:r                       (4)  (156.622)
#    e:r: r/e1             (2)    (87.122)
#      r1 vs (r2,r3)/e   1      19.26
#      r2 vs r3/e1        1      67.86
#    e:r: r/e2             (2)    (69.500)
#      r1 vs (r2,r3)/e   1      63.38
#      r2 vs r3/e2        1        6.12
# Residuals            18       23.090     1.283

Best regards,

Jos?? Cl??udio Faria
UESC/DCET
Brasil
73-634.2779
joseclaudio.faria at terra.com.br
jc_faria at uol.com.br



From rxg218 at psu.edu  Wed May 26 22:44:35 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Wed, 26 May 2004 16:44:35 -0400
Subject: [R] an SJava array question
Message-ID: <1085604274.9434.9.camel@blue.chem.psu.edu>

Hi,
  I'm using SJava (0.65) to interface some Java code I have and am
having trouble understanding the use of arrays. I have a function:

tmv <- function(fname) {
    a <- .JavaArrayConstructor("int", dim=c(3,0))
    .JavaSetArrayElement(a, .JavaArrayConstructor("int", dim=3), 1)
    .JavaSetArrayElement(a, .JavaArrayConstructor("int", dim=3), 2)
    .JavaSetArrayElement(a, .JavaArrayConstructor("int", dim=3), 3)
    for (i in 1:3) {
        for (j in 1:3) {
            .JavaSetArrayElement(a, as.integer(i*j), i,j)
        }
    }
    print(.JavaGetArrayElement(a, 1,1))
}

I expect that I should see 1 print out but instead I get

[[1]]
[1] 1 2 3
 
[[2]]
[1] 1 2 3

The SJava manual seems to indicate that .JavaGetArrayElement(a, 1,1)
gives the first element of the first array. 

Could anybody throw some light on this?

A related question is the an array of Strings.

Does .JavaArrayConstructor("String",3) give me an array of 3 Strings
(which are not yet defined) or a String of length 3? Or if I need to
allocate an array of Strings should I do:

r <- .JavaArrayConstructor( "String", c(3,0) )

and then for each element of r add a new array and then finally set the
individual elements to the actuial string values?

Is there any example code available that I could take a look at?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Q: What's purple and commutes?
A: An abelian grape.



From wolski at molgen.mpg.de  Wed May 26 22:52:48 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 26 May 2004 22:52:48 +0200
Subject: [R] time
In-Reply-To: <47659.170.210.173.216.1085594421.squirrel@inter17.unsl.edu.ar>
References: <47659.170.210.173.216.1085594421.squirrel@inter17.unsl.edu.ar>
Message-ID: <200405262252480005.0039244C@mail.math.fu-berlin.de>

Hi!
I would extract the minutes from the time using sub (see ?sub) or (?grep)
than use them as factors (?as.factors)
and finally
?tapply

eg.
tt<-1:10
 fac<-c(rep(0,4),rep(1,6)) # here put the minutes from the time
fac
 [1] 0 0 0 0 1 1 1 1 1 1
fac<-as.factor(fac)
fac
 [1] 0 0 0 0 1 1 1 1 1 1
Levels: 0 1

tapply(t,fac,max)
 0  1 
 4 10 

Sincerely Eryk.



*********** REPLY SEPARATOR  ***********

On 5/26/2004 at 3:00 PM solares at unsl.edu.ar wrote:

>Hi, i need select data from data frame, for example:
>x is a data frame with values in jump to 5 seconds
>12:10:00 51 //one minute
>12:10:05 63
>12:10:10 75
>12:10:15 88
>..
>12:10:59 45
>12:11:00 46 //another minute
>12:11:05 11
>..
>Have a command what to select the data minute to  minute, for example
>in the example above i need the maximun values minute to  minute
>1?? minute-->88
>2?? minute--> 46
>Thanks Ruben
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From gerifalte28 at hotmail.com  Wed May 26 23:21:58 2004
From: gerifalte28 at hotmail.com (F Z)
Date: Wed, 26 May 2004 21:21:58 +0000
Subject: [R] 2 way repeated measures ANOVA using R: syntax and
	reportingquestion
Message-ID: <BAY99-F3SWcfA9piVH000023c89@hotmail.com>

Dear Gideon

Unless you are willing to accept uncorrelated measures in time and 
homogeneity of variance I would go for a linear mixed model instead. You 
might be surprised on how diffrent can be your results. Try;
>?lme

I hope that this helps

Francisco


>From: GIDEON WASSERBERG <wasserberg at wisc.edu>
>To: "R-help at lists.R-project.org" <R-help at stat.math.ethz.ch>
>Subject: [R] 2 way repeated measures ANOVA using R: syntax and 
>reportingquestion
>Date: Wed, 26 May 2004 14:03:21 -0500
>
>Dear Friends
>
>I have a technical question about conducting 2 way repeated measures ANOVA 
>analysis using R.
>
>1. Data set: repeated measurement of activity over night (2 hr. intervals)
>repeated (within subject)factor: Hours
>Between subject: Species, Sex
>Dependent variables: specimens
>
>Here is how the data arranged for the analysis:
>
>Subject	Replicate	Hour	Sp.	Specimens
>1	1	       1	a
>2	1	       1	a
>3	1	       1	b
>4	1	       1	b
>5	2	       1	a
>6	2	       1	a
>7	2	       1	b
>8	2	       1	b
>1	1	       2	a
>2	1	       2	a
>3	1	       2	b
>4	1	       2	b
>5	2	       2	a
>6	2	       2	a
>7	2	       2	b
>8	2	       2	b
>
>
>here's the command I used:
>summary(aov(Specimens~Species*Sex*Hours+Error(Subject/Hours),data=SP)).
>
>My question is - is that the correct way to do it??
>
>2. Below is the results output:
>A. I am not sure I understand what is the meaning of the two error terms I 
>get.
>Does the first one show error between subjetcs
>and the second - error within subjects?
>
>Error: Subject -
>         Df  Sum Sq Mean Sq
>Species  1 0.60715 0.60715
>
>Error: Subject:Hours
>       Df Sum Sq Mean Sq
>Hours  1 158.24  158.24
>
>Error: Within
>                     Df Sum Sq Mean Sq F value    Pr(>F)
>Species              2  35.19   17.59 34.3017 2.733e-15 ***
>Sex                  1  18.98   18.98 37.0092 1.493e-09 ***
>Hours                1  40.02   40.02 78.0278 < 2.2e-16 ***
>Species:Sex          2   1.29    0.64  1.2568    0.2849
>Species:Hours        2   9.95    4.97  9.6993 6.530e-05 ***
>Sex:Hours            1   0.66    0.66  1.2778    0.2585
>Species:Sex:Hours    2   1.38    0.69  1.3498    0.2596
>Residuals         1486 762.20    0.51
>---
>B. How do I summarize this information for a report?
>Is the below suggestion acceptable?
>-------------------------------------------------------------------------------
>
>Source	              df	SS	MS	                 F	    P
>-----------------------------------------------------------------------------
>Species	               2	35.19	17.59	                34.3     <0.0001
>Sex          	       1	18.98	18.98	                37.01	  <0.0001
>Species:Sex          	2	1.29	0.64  	               1.2568    0.2849
>Subject(Species)	1	0.60715	0.60715
>Subject(Hours)	       1	158.24  158.24
>Hour	                1	40.02	  40.02	                78.0278	   <0.0001
>Species:Hours        	2	9.95            4.97  	         9.6993	   <0.0001
>Sex:Hours            	1	0.66    	0.66             1.2778    0.2585
>Species:Sex:Hours    	2	1.38    	0.69  	         1.3498	0.2596
>Residuals	     1486	762.20    	0.51
>---------------------------------------------------------------------------------
>Very much obliged for your kind response
>
>Gideon
>
>
>Gideon Wasserberg (Ph.D.)
>Wildlife research unit,
>Department of wildlife ecology,
>University of Wisconsin
>218 Russell labs, 1630 Linden dr.,
>Madison, Wisconsin 53706, USA.
>Tel.:608 265 2130, Fax: 608 262 6099
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html

_________________________________________________________________




From joseclaudio.faria at terra.com.br  Wed May 26 23:37:48 2004
From: joseclaudio.faria at terra.com.br (joseclaudio.faria)
Date: Wed, 26 May 2004 18:37:48 -0300
Subject: [R] Aid on two-way ANOVA with contrasts
Message-ID: <003b01c44369$b2b6d490$01fea8c0@sapetinga>

Dears members of R list,

It would like that a more experienced statician in R helped me to complete
the analysis to follow:

r = gl(3, 8, label = c('r1', 'r2', 'r3'))
e = rep(gl(2, 4, label = c('e1', 'e2')), 3)
y = c(26.2, 26.0, 25.0, 25.4, 24.8, 24.6, 26.7, 25.2, 25.7, 26.3, 25.1, 26.4,
         19.6, 21.1, 19.0, 18.6, 22.8, 19.4, 18.8, 19.2, 19.8, 21.4, 22.8, 21.3)

df = data.frame(r, e, y)
attach(df)
  par(mfrow=c(2,1))
  interaction.plot(r, e, y, col = 'blue', ylab = 'y', xlab = 'r')

  interaction.plot(e, r, y, col = 'blue', ylab = 'y', xlab = 'r')
  av1 = aov(y ~ r*e)

  av2 = aov(y ~ r/e)
  efR_E = summary(av2, split = list('r:e' = list('e1 vs e2/r1' = 1, 'e1 vs
e2/r2' = 2, 'e1 vs e2/r3' = 3)))

  av3  = aov(y ~ e/r)
  efE_R = summary(av3, split = list('e:r' = list('r/e1' = c(1,3), 'r/e2' =
c(2,4))))

  mds = model.tables(av1, ty = 'means')
detach(df)

cat('\nData:'); cat('\n')
print(df)

cat('\nMeans:'); cat('\n')
print(mds)

cat('\nANOVA:'); cat('\n')
print(summary(av1)); cat('\n')

cat('\nANOVA - E effect in R levels:'); cat('\n')
print(efR_E); cat('\n')

cat('\nANOVA - R effect in E levels:'); cat('\n')
print(efE_R); cat('\n')

#I would like to get as resulted (efE_R) like this:
# ANOVA - R effect (contrasts) in E levels:
#                                    Df       Sum Sq    Mean Sq   F value
Pr(>F)
# e                                  1     19.082
#  e:r                            (4)  (156.622)
#    e:r: r/e1                 (2)     (87.122)
#      r1 vs (r2,r3)/e1     1      ?...
#      r2 vs r3/e1            1      ?
#    e:r: r/e2                  (2)   (69.500)
#      r1 vs (r2,r3)/e1      1      ?...
#      r2 vs r3/e2             1      ?...
# Residuals                  18   23.090     1.283



#Through manual calculations I got:
# ANOVA - R effect in E levels:
#                                Df       Sum Sq    Mean Sq   F value    Pr(>F)
# e                              1         19.082
#  e:r                        (4)      (156.622)
#    e:r: r/e1             (2)         (87.122)
#      r1 vs (r2,r3)/e   1           19.26
#      r2 vs r3/e1        1           67.86
#    e:r: r/e2             (2)         (69.500)
#      r1 vs (r2,r3)/e   1           63.38
#      r2 vs r3/e2        1             6.12
# Residuals            18          23.090     1.283

Best regards,

Jos?? Cl??udio Faria
UESC/DCET
Brasil
73-634.2779
joseclaudio.faria at terra.com.br
jc_faria at uol.com.br



From p.dalgaard at biostat.ku.dk  Thu May 27 00:20:17 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 May 2004 00:20:17 +0200
Subject: [R] cor and missing values. Bug?
In-Reply-To: <001001c4432b$dffbeaa0$2e80010a@BigBaer>
References: <Pine.SOL.4.50.0405251607530.20070-100000@toto.Berkeley.EDU>
	<x2zn7whz23.fsf@biostat.ku.dk>
	<001001c4432b$dffbeaa0$2e80010a@BigBaer>
Message-ID: <x2zn7u4yqm.fsf@biostat.ku.dk>

"Robert W. Baer, Ph.D." <rbaer at atsu.edu> writes:

> > Not to put too fine a point on it, but did you consider checking the
> > NEWS file for the most recent version (1.9.0,
> > http://cran.r-project.org/src/base/NEWS)?
> >
> >     o   The cor() function did not remove missing values in the
> >         non-Pearson case.
> 
> 
> There is still something a little strange in version 1.9.0. What  is the
> source of the discrpancy between cor() and cor.test()?

One ranks x and y before removing missing values, the other one
removes them first and then ranks. It is not really desirable, but a
better solution is nontrivial (esp. in the "pairwise.complete.obs"
case) and we did document it in ?cor:

                  Notice also that the ranking is (currently) done
     removing only cases that are missing on the variable itself,
     which may not be what you expect if you let 'use' be '"complete.obs"'
     or '"pairwise.complete.obs"'.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Thu May 27 00:29:12 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 May 2004 00:29:12 +0200
Subject: [R] Common principle components
In-Reply-To: <40B4C4F7.8060800@pdf.com>
References: <200405261140.17842.jpgranadeiro@fc.ul.pt>
	<95A1F7CE-AF10-11D8-A723-000A958F43CC@MUOhio.edu>
	<200405261601.22424.jpgranadeiro@fc.ul.pt>
	<16564.49895.634360.288389@gargle.gargle.HOWL>
	<40B4C4F7.8060800@pdf.com>
Message-ID: <x2vfii4ybr.fsf@biostat.ku.dk>

Spencer Graves <spencer.graves at pdf.com> writes:

> Google just returned "about" 1.8M hits for "principle components" and
> 3.2M hits for "principal components".  Evidently, eigenvectors are
> more your friend (pal) than a structure for the space by a factor of
> roughly 2 to 1. spencer graves

Of course, principles might actually have components. Take the Ten
Commandments for example....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From feh3k at spamcop.net  Wed May 26 21:16:38 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Wed, 26 May 2004 21:16:38 +0200
Subject: [R] cor and missing values. Bug?
In-Reply-To: <x2zn7u4yqm.fsf@biostat.ku.dk>
References: <Pine.SOL.4.50.0405251607530.20070-100000@toto.Berkeley.EDU>
	<x2zn7whz23.fsf@biostat.ku.dk>
	<001001c4432b$dffbeaa0$2e80010a@BigBaer>
	<x2zn7u4yqm.fsf@biostat.ku.dk>
Message-ID: <20040526211638.254d2e7d.feh3k@spamcop.net>

On 27 May 2004 00:20:17 +0200
Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:

> "Robert W. Baer, Ph.D." <rbaer at atsu.edu> writes:
> 
> > > Not to put too fine a point on it, but did you consider checking the
> > > NEWS file for the most recent version (1.9.0,
> > > http://cran.r-project.org/src/base/NEWS)?
> > >
> > >     o   The cor() function did not remove missing values in the
> > >         non-Pearson case.
> > 
> > 
> > There is still something a little strange in version 1.9.0. What  is
> > the source of the discrpancy between cor() and cor.test()?
> 
> One ranks x and y before removing missing values, the other one
> removes them first and then ranks. It is not really desirable, but a
> better solution is nontrivial (esp. in the "pairwise.complete.obs"
> case) and we did document it in ?cor:
> 
>                   Notice also that the ranking is (currently) done
>      removing only cases that are missing on the variable itself,
>      which may not be what you expect if you let 'use' be
>      '"complete.obs"' or '"pairwise.complete.obs"'.
> 
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> 

Some of you may want to look at the old rcorr function in the Hmisc
package, which uses the pairwise complete obs method, uses some C code for
Spearman correlation, and is fast for large matrices.

Frank

---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From trengove at it.uts.edu.au  Thu May 27 06:44:25 2004
From: trengove at it.uts.edu.au (Chris Trengove)
Date: Thu, 27 May 2004 14:44:25 +1000
Subject: [R] Source Code for Linear Discriminant Analysis
Message-ID: <001001c443a5$4af74380$38e7fea9@venus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040527/07f1a7b4/attachment.pl

From ligges at statistik.uni-dortmund.de  Thu May 27 08:50:12 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 27 May 2004 08:50:12 +0200
Subject: [R] Source Code for Linear Discriminant Analysis
In-Reply-To: <001001c443a5$4af74380$38e7fea9@venus>
References: <001001c443a5$4af74380$38e7fea9@venus>
Message-ID: <40B58FA4.4040608@statistik.uni-dortmund.de>

Chris Trengove wrote:
> Dear R users,
> 
>   I am not an R user myself, but someone searching the web for C source code that will do linear discriminant function analysis.
>   The only lead I have been able to locate is that R contains a function called "lda" which is contained in the MASS package.
> (http://stat.ethz.ch/R-manual/R-devel/library/MASS/html/lda.html)
>   I downloaded the R source file R-1.9.0.tgz, and found a huge collection of C programs in various package directories, but I could not find the source file for lda, nor could I find a directory for the MASS package.
>   Can anyone help me please?
> 
> Regards,
> Chris Trengove.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

MASS is in the VR package bundle. The current version is available at 
CRAN: /src/contrib/VR_7.2-2.tar.gz

Uwe Ligges



From jarioksa at sun3.oulu.fi  Thu May 27 08:49:48 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 27 May 2004 09:49:48 +0300
Subject: [R] Common principle components
In-Reply-To: <200405261601.22424.jpgranadeiro@fc.ul.pt>
References: <200405261140.17842.jpgranadeiro@fc.ul.pt>
	<95A1F7CE-AF10-11D8-A723-000A958F43CC@MUOhio.edu>
	<200405261601.22424.jpgranadeiro@fc.ul.pt>
Message-ID: <1085640588.8835.16.camel@biol102145.oulu.fi>

On Wed, 2004-05-26 at 18:01, J. Pedro Granadeiro wrote:
> I am sorry for not being clear. I meant the methods detailed in:
> 
> Flury, B. (1988). Common Principle Components Analysis and Related 
> Multivariate Models, John Wiley and Sons, New York. 
> 

Judging from the lack of positive answers, there may not be such a
utility in R. I checked Flury's book, and it seems that he gives there
his algorithm in such a detail that it might be possible to implement
the code in R, including the FORTRAN code for his crucial FG step.
Naturally, you should expect some complication in real world
implementations of long and winding book algorithms, but it might be
doable even for me, and somebody good in multivariate analysis might
find it fairly easy. I am not sure about the licensing of his FORTRAN
code: it was submitted to IMSL and you just cannot use IMSL code in free
software (actually, back in 1980s I got the complete FORTRAN code from
Flury himself, but it was under NDA, and I don't have the FORTRAN source
any longer). 

The most natural choice is to Google and find this page:
http://darkwing.uoregon.edu/~pphil/programs/cpc/cpc.htm. The page has
CPC binaries for more platforms than you have R, and you can pick your
own. However, the software uses Numerical Recipes, and the source code
cannot be made available, but the author writes there: "f you want to
run the software on a particular platform without a current compiled
version, get in contact with me to see what we can do." Sounds
promising: replacing NR pieces with R pieces may be easy (as  long as
you are careful in moving arrays to the genuine C zero offset). That was
a hint.

Finally, there are many brands of CPC. Flury discusses Krzanowski's
Common Space Analysis in his book, and describes its algorithm, too.
(Both of these algorithms are concisely given on pages 204-205.) Then
there is the classical SINDSCAL of the Bell Labs. I have had a look at
its code, and it looks like it would be easish to port to R -- if that
only would be legal. The first lines of the source files read: 

C THIS INFORMATION IS PROPRIETARY AND IS THE
C PROPERTY OF BELL TELEPHONE LABORATORIES,
C INCORPORATED.  ITS REPRODUCTION OR DISCLOSURE
C TO OTHERS, EITHER ORALLY OR IN WRITING, IS
C PROHIBITED WITHOUT WRITTEN PRERMISSION OF
C BELL LABORATORIES.

So you are not even allowed to anybody that you have the software, nor
tell how to use it. This must be the most restrictive source license
around. Further, it says in several places:

C    THESE IMSL ROUTINES ARE PROPRIETARY SOFTWARE, OWNED BY IMSL.
C    THEY MAY BE USED ONLY IN THE CODE IN WHICH THEY ARE EMBEDDED
C    NO OTHER USE OF THESE ROUTINES IS PERMITTED. SMTI   7

So it just cannot be ported to R.

Anybody interested in working with porting CPC? (Better forget the
easier task of porting SINDSCAL.)

cheers, jari oksanen

-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From Giles.Heywood at CommerzbankIB.com  Thu May 27 08:56:00 2004
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Thu, 27 May 2004 07:56:00 +0100
Subject: [R] Common principle components
Message-ID: <E65C272ECD3BD51196E500508B6658FE08CD9473@xmx6lonib.lonib.commerzbank.com>

I was a lttle shocked to see your report of 3.2M hits for the correct
speeling versus 1.8M for incorrect.  This is a ratio of just 1.8!  Google
normally has much higher power than this, as the arbiter of spelling
disputes.

A quick google reveals however that your search is for
"principal"+"components" and principle"+"components".  A search for the
complete strings yields a ratio of 14.8 in favour of the latter.

- Giles



> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Spencer Graves
> Sent: 26 May 2004 17:25
> To: Martin Maechler
> Cc: R-help at stat.math.ethz.ch
> Subject: Re: [R] Common principle components
> 
> 
> Google just returned "about" 1.8M hits for "principle components" and 
> 3.2M hits for "principal components".  Evidently, 
> eigenvectors are more 
> your friend (pal) than a structure for the space by a factor 
> of roughly 
> 2 to 1. 
> 
> spencer graves
> 
> Martin Maechler wrote:
> 
> >>>>>>"JosePG" == J Pedro Granadeiro <jpgranadeiro at fc.ul.pt>
> >>>>>>    on Wed, 26 May 2004 16:01:22 +0100 writes:
> >>>>>>            
> >>>>>>
> >
> >    JosePG> I am sorry for not being clear. I meant the 
> methods detailed in:
> >    JosePG> Flury, B. (1988). Common Principle Components 
> Analysis and Related 
> >    JosePG> Multivariate Models, John Wiley and Sons, New York. 
> >
> >Well, I'm 100% sure the title of that book is different
> >(and so should be your e-mail subject)
> >
> >Hint: Look carefully at the end of the 2nd word ...
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >  
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From david.netherway at adelaide.edu.au  Thu May 27 09:04:58 2004
From: david.netherway at adelaide.edu.au (David J. Netherway)
Date: Thu, 27 May 2004 16:34:58 +0930
Subject: [R] Getting the same values of adjusted mean and standard errors as
	SAS
Message-ID: <40B5931A.7090203@adelaide.edu.au>

Hello,
 
I am trying to get the same values for the adjusted means and standard 
errors using R that are given in SAS for the
following data. The model is Measurement ~ Age + Gender + Group. I can 
get the adusted means at the mean age  
by using predict. I do not know how to get the appropriate standard 
errors at the adjusted means for Gender
using values from predict. So I attempted to get them directly from the 
residuals as follows. The data is at the end
of the email. While there is a match for the males there is a large 
difference for the females indicating that what I am doing is wrong.
 
#  
meanAge <- mean(dd$Age)
meanAgeM <- mean(dd$Age[d$Gender=="M"])
meanAgeF <- mean(dd$Age[d$Gender=="F"])
 
# determine adjusted means for the males and females at meanAge using 
predict
# set up data frame to get predicted values at meanAge
evalDF <- data.frame(Age = meanAge, Gender = c("F","M"),  
       Group = c("1NC","1NC", "2UCLP", "2UCLP", "3BCLP", "3BCLP", 
"4ICP", "4ICP", "5CLPP", "5CLPP"))
mod <-lm(Measurement ~ Age + Gender + Group, data=dd)
pred <- predict(mod, evalDF, se.fit = TRUE)
adjDF <- data.frame(evalDF,fit = pred$fit, se = pred$se.fit)
adjMeanMale <- mean(adjDF$fit[adjDF$Gender=="M"]); # match: 3.889965 cf 
3.88996483
adjMeanFemale <- mean(adjDF$fit[adjDF$Gender=="F"]); # match: 3.91111 cf 
3.91111036
 
# Try to get standard errors at the adjusted means for Gender as follows:
ddr <- data.frame(dd, res = residuals(mod))
nM <- summary(ddr$Gender)[["M"]]
seRegM <- sqrt(mean( ddr$res[ddr$Gender=="M"]**2 ))
sxxM <- sum((dd$Age[d$Gender=="M"]-meanAgeM)**2)
syM <- seRegM * sqrt(1/nM + (meanAge-meanAgeM)**2/sxxM); #0.1103335 cf 
0.11032602 - matches to 5 decimal places
nF <- summary(ddr$Gender)[["F"]]
seRegF <- sqrt(mean( ddr$res[ddr$Gender=="F"]**2 ))
sxxF <- sum((dd$Age[d$Gender=="F"]-meanAgeF)**2)
syF <- seRegF * sqrt(1/nF + (meanAge-meanAgeF)**2/sxxF); # wrong: 
0.07279221 cf 0.14256466
 
 
 > dd
   Measurement Age Gender Group
1       3.8  94      M 3BCLP
2       2.7  88      F 3BCLP
3       3.0 155      M 3BCLP
4       2.7  33      M 3BCLP
5       4.6 109      M 5CLPP
6       5.1 325      M 5CLPP
7       3.9  79      M 5CLPP
8       4.2 126      M 5CLPP
9       3.9  77      F 5CLPP
10      4.0  61      F 5CLPP
11      3.6  49      F 5CLPP
12      3.7  14      F  4ICP
13      4.2 160      F  4ICP
14      3.9  60      M  4ICP
15      5.0  61      M  4ICP
16      3.9 222      F  4ICP
17      3.8  82      F  4ICP
18      4.8 340      F  4ICP
19      3.2 206      M  4ICP
20      3.8  19      M   1NC
21      4.9 166      M   1NC
22      3.8  93      M   1NC
23      3.6 142      M   1NC
24      4.8 241      M   1NC
25      3.9  81      M   1NC
26      4.5  41      M   1NC
27      5.1 244      F   1NC
28      4.6 100      M   1NC
29      5.1 122      F   1NC
30      4.7 194      F   1NC
31      5.1 297      M   1NC
32      3.9  69      M 2UCLP
33      2.5 141      M 2UCLP
34      3.2 104      M 2UCLP
35      3.8  90      M 2UCLP
36      3.8  92      M 2UCLP
37      3.6 149      F 2UCLP
38      3.8  53      F 2UCLP
39      4.7 111      M 2UCLP
40      3.8 116      F 2UCLP
41      3.3  81      M 2UCLP
 >



From Giles.Heywood at CommerzbankIB.com  Thu May 27 09:05:55 2004
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Thu, 27 May 2004 08:05:55 +0100
Subject: [R] Common principle components
Message-ID: <E65C272ECD3BD51196E500508B6658FE08CD9474@xmx6lonib.lonib.commerzbank.com>

A typo in previous post: for latter, read former.  Apologies for the
confusion.


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From Matthias.Templ at statistik.gv.at  Thu May 27 09:19:31 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Thu, 27 May 2004 09:19:31 +0200
Subject: [R] Rcmd check, windows xp, perl
Message-ID: <83536658864BC243BE3C06D7E936ABD50153690D@xchg1.statistik.local>

Dear R users,

With package.skeleton() i have produced successfully my .Rd??s, ...
Now i will run Rcmd check on ..\R\bin\

But Rcmd check (and build) on my Windows XP does not work.
It`s a problem with "perl".
(Translated i get the message:
The instruction Perl is either wrongly written or could not not be found.)

In help("check") I found this:
     "These may not work correctly under Windows 95/98/ME because of
     problems Perl has launching programs on those limited OSes."

And in the R-devel I found following from Prof. Brian Ripley:
     "2) On Windows, we did hope to make Rcmd check the standard way. 
     Unfortunately, a whole series Perl builds were broken, so make 
     pkgcheck-foo is still preferred." 

But i can not find something like "pkgcheck" and Rcmd does not work.

(I use R version 1.9.0 on Windows XP, IBM Computer)

Can anybody help me please?

Regards,

Matthias



From ligges at statistik.uni-dortmund.de  Thu May 27 09:26:03 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 27 May 2004 09:26:03 +0200
Subject: [R] Rcmd check, windows xp, perl
In-Reply-To: <83536658864BC243BE3C06D7E936ABD50153690D@xchg1.statistik.local>
References: <83536658864BC243BE3C06D7E936ABD50153690D@xchg1.statistik.local>
Message-ID: <40B5980B.7050005@statistik.uni-dortmund.de>

TEMPL Matthias wrote:

> Dear R users,
> 
> With package.skeleton() i have produced successfully my .Rd??s, ...
> Now i will run Rcmd check on ..\R\bin\
> 
> But Rcmd check (and build) on my Windows XP does not work.
> It`s a problem with "perl".
> (Translated i get the message:
> The instruction Perl is either wrongly written or could not not be found.)
> 
> In help("check") I found this:
>      "These may not work correctly under Windows 95/98/ME because of
>      problems Perl has launching programs on those limited OSes."
> 
> And in the R-devel I found following from Prof. Brian Ripley:
>      "2) On Windows, we did hope to make Rcmd check the standard way. 
>      Unfortunately, a whole series Perl builds were broken, so make 
>      pkgcheck-foo is still preferred." 
> 
> But i can not find something like "pkgcheck" and Rcmd does not work.
> 
> (I use R version 1.9.0 on Windows XP, IBM Computer)

On Windows XP everything is fine.

Please read ..../src/gnuwin32/readme.packages and follow the 
instructions therein exactly.
In particular: Do you have perl installed?

Uwe Ligges


> Can anybody help me please?
> 
> Regards,
> 
> Matthias
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From wolski at molgen.mpg.de  Thu May 27 09:25:54 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 27 May 2004 09:25:54 +0200
Subject: [R] Rcmd check, windows xp, perl
References: <83536658864BC243BE3C06D7E936ABD50153690D@xchg1.statistik.local>
	<200405270925200059.00445316@mail.math.fu-berlin.de>
Message-ID: <200405270925540005.0044D8E9@mail.math.fu-berlin.de>

Hi!
How about installing perl from e.g. activestate? or if installed adding the path to perl.exe to you %PATH% variable?
Sincerely

*********** REPLY SEPARATOR  ***********

On 5/27/2004 at 9:19 AM TEMPL Matthias wrote:

>Dear R users,
>
>With package.skeleton() i have produced successfully my .Rd??s, ...
>Now i will run Rcmd check on ..\R\bin\
>
>But Rcmd check (and build) on my Windows XP does not work.
>It`s a problem with "perl".
>(Translated i get the message:
>The instruction Perl is either wrongly written or could not not be found.)
>
>In help("check") I found this:
>     "These may not work correctly under Windows 95/98/ME because of
>     problems Perl has launching programs on those limited OSes."
>
>And in the R-devel I found following from Prof. Brian Ripley:
>     "2) On Windows, we did hope to make Rcmd check the standard way. 
>     Unfortunately, a whole series Perl builds were broken, so make 
>     pkgcheck-foo is still preferred." 
>
>But i can not find something like "pkgcheck" and Rcmd does not work.
>
>(I use R version 1.9.0 on Windows XP, IBM Computer)
>
>Can anybody help me please?
>
>Regards,
>
>Matthias
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From jarioksa at sun3.oulu.fi  Thu May 27 09:31:21 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 27 May 2004 10:31:21 +0300
Subject: [R] Common principle components
In-Reply-To: <200405261601.22424.jpgranadeiro@fc.ul.pt>
References: <200405261140.17842.jpgranadeiro@fc.ul.pt>
	<95A1F7CE-AF10-11D8-A723-000A958F43CC@MUOhio.edu>
	<200405261601.22424.jpgranadeiro@fc.ul.pt>
Message-ID: <1085643080.8835.23.camel@biol102145.oulu.fi>

On Wed, 2004-05-26 at 18:01, J. Pedro Granadeiro wrote:
> I am sorry for not being clear. I meant the methods detailed in:
> 
> Flury, B. (1988). Common Principle Components Analysis and Related 
> Multivariate Models, John Wiley and Sons, New York. 

After writing my previous (long) response to this message, I started to
think that it would be strange if the ade4 people of Lyon had not
written something similar. Indeed they have: there are several
alternative methods for multivariate analysis of K tables in ade4. They
may not be exactly identical to Flury's Common Principal Components, but
they do similar things. Some of the methods may even be identical: The
ade4 people cite French sources, and Flury does not cite French sources
-- and there are at least two parallel universes in multivariate
analysis that rarely cross each other. Just go to CRAN and get ade4, and
try to figure out how to do the analysis you need.

cheers, jari oksanen 
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From tmulholl at bigpond.net.au  Thu May 27 09:40:55 2004
From: tmulholl at bigpond.net.au (Tom Mulholland)
Date: Thu, 27 May 2004 15:40:55 +0800
Subject: [R] Common principle components
In-Reply-To: <1085640588.8835.16.camel@biol102145.oulu.fi>
Message-ID: <000101c443bd$f2902770$2202a8c0@ACER>

I think the answers were positive they suggest that you try using principal
instead of principle.

Try typing help.search("principal") rather than help.search("principle")


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Jari Oksanen
Sent: Thursday, May 27, 2004 2:50 PM
To: J. Pedro Granadeiro
Cc: R-News
Subject: Re: [R] Common principle components


On Wed, 2004-05-26 at 18:01, J. Pedro Granadeiro wrote:
> I am sorry for not being clear. I meant the methods detailed in:
>
> Flury, B. (1988). Common Principle Components Analysis and Related
> Multivariate Models, John Wiley and Sons, New York.
>

Judging from the lack of positive answers, there may not be such a
utility in R. I checked Flury's book, and it seems that he gives there
his algorithm in such a detail that it might be possible to implement
the code in R, including the FORTRAN code for his crucial FG step.
Naturally, you should expect some complication in real world
implementations of long and winding book algorithms, but it might be
doable even for me, and somebody good in multivariate analysis might
find it fairly easy. I am not sure about the licensing of his FORTRAN
code: it was submitted to IMSL and you just cannot use IMSL code in free
software (actually, back in 1980s I got the complete FORTRAN code from
Flury himself, but it was under NDA, and I don't have the FORTRAN source
any longer).

The most natural choice is to Google and find this page:
http://darkwing.uoregon.edu/~pphil/programs/cpc/cpc.htm. The page has
CPC binaries for more platforms than you have R, and you can pick your
own. However, the software uses Numerical Recipes, and the source code
cannot be made available, but the author writes there: "f you want to
run the software on a particular platform without a current compiled
version, get in contact with me to see what we can do." Sounds
promising: replacing NR pieces with R pieces may be easy (as  long as
you are careful in moving arrays to the genuine C zero offset). That was
a hint.

Finally, there are many brands of CPC. Flury discusses Krzanowski's
Common Space Analysis in his book, and describes its algorithm, too.
(Both of these algorithms are concisely given on pages 204-205.) Then
there is the classical SINDSCAL of the Bell Labs. I have had a look at
its code, and it looks like it would be easish to port to R -- if that
only would be legal. The first lines of the source files read:

C THIS INFORMATION IS PROPRIETARY AND IS THE
C PROPERTY OF BELL TELEPHONE LABORATORIES,
C INCORPORATED.  ITS REPRODUCTION OR DISCLOSURE
C TO OTHERS, EITHER ORALLY OR IN WRITING, IS
C PROHIBITED WITHOUT WRITTEN PRERMISSION OF
C BELL LABORATORIES.

So you are not even allowed to anybody that you have the software, nor
tell how to use it. This must be the most restrictive source license
around. Further, it says in several places:

C    THESE IMSL ROUTINES ARE PROPRIETARY SOFTWARE, OWNED BY IMSL.
C    THEY MAY BE USED ONLY IN THE CODE IN WHICH THEY ARE EMBEDDED
C    NO OTHER USE OF THESE ROUTINES IS PERMITTED. SMTI   7

So it just cannot be ported to R.

Anybody interested in working with porting CPC? (Better forget the
easier task of porting SINDSCAL.)

cheers, jari oksanen

--
Jari Oksanen <jarioksa at sun3.oulu.fi>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

---
Incoming mail is certified Virus Free.



---



From k.wang at auckland.ac.nz  Thu May 27 09:41:32 2004
From: k.wang at auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu, 27 May 2004 19:41:32 +1200
Subject: [R] More Photos from Vienna/useR! 2004
References: <F9E47473E3BCD1118C0500204808C390061A0840@GLO_003>
	<x2brlb5iso.fsf@biostat.ku.dk>
Message-ID: <007801c443be$0776cd10$6433d882@stat.auckland.ac.nz>

Other than the photos posted by Bettina, I've got some scenery photos of
Vienna on http://www.stat.auckland.ac.nz/~kwan022/tmp/Vienna/

Cheers,

Kevin



From Giles.Heywood at CommerzbankIB.com  Thu May 27 09:58:36 2004
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Thu, 27 May 2004 08:58:36 +0100
Subject: [R] A data selection problem, suggestions highly appreciated
Message-ID: <E65C272ECD3BD51196E500508B6658FE08CD9476@xmx6lonib.lonib.commerzbank.com>

First convert your dates to POSIXct, similar to the following:

tmp <- strptime("Jan1 18:56:24",format="%b%d %H:%M:%S")

[Here is a synthetic example for demo purposes] 

tmp <- seq.POSIXt(from=Sys.time(),length=100,by=1)

Then assign observations to 5s periods, and detect changes in these:

a5secperiod <- floor(as.numeric(tmp)/5)
lastinperiod <- tmp[which(diff(c(a5secperiod[1],a5secperiod))!=0)-1]

You may find it convenient to use the class 'its' in package 'its' (on CRAN)
to store the data and POSIX dates in a single object.

- Giles

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Yong Wang
> Sent: 26 May 2004 20:34
> To: r-help-request at stat.math.ethz.ch
> Cc: r-help at stat.math.ethz.ch
> Subject: [R] A data selection problem, suggestions highly appreciated
> 
> 
> Hi, All
> I get following question:
> A data format like following:
> 
> [Day time  x y]
> 
> Jan1 18:56:24 x1 y1
> Jan1 18:56:25 x2 y2
> Jan1 18:56:27 x3 y3
> Jan1 18:56:28 x4 y4
> Jan1 18:56:31 x5 y5
> .....................
> .....................
> 
> what I wanna do is to partion the time interval by unit of 5 seconds.
> and pick x,y corresponding to the last time within that 
> interval. for the 
> example above,
> suppose 18:56:24 is the starting time, the time included in 
> the interval 
> will be up to 18:56:28, therefore I want to get x4 and y4, 
> and store them 
> somewhere else. 
> you might know this is the so called high frequency data. can 
> you let me 
> know how to do this partion and pick in R or Splus. 
> suggestions are really and hihgly appreciated. 
> 
> thank you very much.
> best regards
> yong
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From Jorgen.Wallerman at resgeom.slu.se  Thu May 27 10:07:36 2004
From: Jorgen.Wallerman at resgeom.slu.se (=?iso-8859-1?Q?J=F6rgen_Wallerman?=)
Date: Thu, 27 May 2004 10:07:36 +0200
Subject: [R] Using R in C++
Message-ID: <9BE977B02923D311AADA00105AF49783015C97E8@tilia.slu.se>


I have read the "Writing R Extensions Guide", and got the impression it is
only possible to access some "basic" mathematical functions from R in C, not
including ks.test(). My question is if it is possible to go further than
those "basic" functions. I guess what I want to do is to execute an R
function within R but from C++, where all execution is started and
controlled from the C-end. For example, it is possible to run R from the
prompt with the function as an argument? How do I then get access to the
result? Is there a better way than that? Is there a C-interface for
ks.test() allowing it to be compiled and included in a C-application? Which
parts in the help am I missing?

-------------------------------------------
Ph. D. J??rgen Wallerman
Swedish University of Agricultural Sciences
Remote Sensing Laboratory
S901 83 UME??
 

> -----Original Message-----
> From: Vadim Ogranovich [mailto:vograno at evafunds.com]
> Sent: den 26 maj 2004 17:53
> To: J??rgen Wallerman; r-help at stat.math.ethz.ch
> Subject: RE: [R] Using R in C++
> 
> 
> Look at "Writing R Extensions" guide. It covers both R-from-C
> and C-from-R.
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of J??rgen 
> > Wallerman
> > Sent: Wednesday, May 26, 2004 3:09 AM
> > To: 'r-help at stat.math.ethz.ch'
> > Subject: [R] Using R in C++
> > 
> > 
> > Hello,
> > 
> > Is it possible to use R functions (in my case: ks.test()) from C++ 
> > -applications? That is, I get the impression R can execute C/C++ 
> > code, but is there any possibility to do the opposite? Where can I 
> > find help?
> > 
> > 
> > -------------------------------------------
> > Ph. D. J??rgen Wallerman
> > Swedish University of Agricultural Sciences
> > Remote Sensing Laboratory
> > S901 83 UME??
> >  
> > ###########################################
> > 
> > This message has been scanned by F-Secure
> > Anti-Virus for Microsoft Exchange.
> > 
> > ###########################################
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help PLEASE
> > do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> 
###########################################

This message has been scanned by F-Secure 
Anti-Virus for Microsoft Exchange.

###########################################



From rksh at soc.soton.ac.uk  Thu May 27 10:24:39 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Thu, 27 May 2004 09:24:39 +0100
Subject: [R] block diagonal matrix function
Message-ID: <a06002006bcdb54ceba89@[139.166.242.29]>

Hello List

I have just written a little function that takes two matrices as
arguments and returns a large matrix that is composed of the two input
matrices in upper-left position and lower-right position with a padding
value everywhere else. (function definition and toy example below).  I
need nonsquare matrices and rowname() and colname() inherited appropriately.

Two questions:

(1) Is there a better way to do this? (kronecker() isn't applicable here)

(2) How do I generalize it to take an arbitrary number of matrices as
     inputs?


TIV

Robin



"blockdiag" <-
function (m1, m2, p.tr = 0, p.ll = 0)
{
     ## p.tr and p.ll are padding values
     topleft <- m1
     topright <- matrix(p.tr, nrow(m1), ncol(m2))
     colnames(topright) <- colnames(m2)
     lowleft <- matrix(p.ll, nrow(m2), ncol(m1))
     lowright <- m2
     rbind(cbind(topleft, topright), cbind(lowleft, lowright))
}

m1 <-
structure(c(1, 1, 3, 1, 3, 4), .Dim = as.integer(c(2, 3)), .Dimnames = list(
     c("a", "b"), c("x", "y", "z")))

m2 <-
structure(c(2, 1, 1, 0, 3, 2, 2, 2, 0), .Dim = as.integer(c(3,
3)), .Dimnames = list(c("I", "II", "III"), c("A", "B", "C")))

R> m1
   x y z
a 1 3 3
b 1 1 4

R> m2
     A B C
I   2 0 2
II  1 3 2
III 1 2 0

R> blockdiag(m1,m2)
     x y z A B C
a   1 3 3 0 0 0
b   1 1 4 0 0 0
I   0 0 0 2 0 2
II  0 0 0 1 3 2
III 0 0 0 1 2 0
R>
-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From maechler at stat.math.ethz.ch  Thu May 27 10:30:49 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 27 May 2004 10:30:49 +0200
Subject: [R] Source Code for Linear Discriminant Analysis
In-Reply-To: <40B58FA4.4040608@statistik.uni-dortmund.de>
References: <001001c443a5$4af74380$38e7fea9@venus>
	<40B58FA4.4040608@statistik.uni-dortmund.de>
Message-ID: <16565.42809.791798.860514@gargle.gargle.HOWL>

>>>>> "UweL" == Uwe Ligges <ligges at statistik.uni-dortmund.de>
>>>>>     on Thu, 27 May 2004 08:50:12 +0200 writes:

    UweL> Chris Trengove wrote:
    >> Dear R users,
    >> 
    >> I am not an R user myself, but someone searching the web
    >> for C source code that will do linear discriminant
    >> function analysis.  The only lead I have been able to
    >> locate is that R contains a function called "lda" which
    >> is contained in the MASS package.
    >> (http://stat.ethz.ch/R-manual/R-devel/library/MASS/html/lda.html)
    >> I downloaded the R source file R-1.9.0.tgz, and found a
    >> huge collection of C programs in various package
    >> directories, but I could not find the source file for
    >> lda, nor could I find a directory for the MASS package.
    >> Can anyone help me please?
    >> 
    >> Regards, Chris Trengove.

    UweL> MASS is in the VR package bundle. The current version
    UweL> is available at CRAN: /src/contrib/VR_7.2-2.tar.gz

and to really answer Chris' question:

The MASS source *is* of course inside the R-1.9.0.tgz that
you've downloaded.
Unfortunately (for a good reason, but still unfortunately!)
the recommended packages' sources (and MASS is one of those) are
*still* compressed even after unpacking R-1.9.0.tgz :

After unpacking R-1.9.0.tgz, to see the source, you need to
 unpack (the symbolic link) VR.tgz as well :
 R-1.9.0/src/library/Recommended/VR.tgz
and then VR/MASS/R/lda.R  and (a small part of)  VR/MASS/src/MASS.c

This is a bit unfortunate for those of us who like to search
inside the sources..

NOTE: This is copyrighted and GPL'ed (GNU public licenced) code
      and you are only allowed to use the code accordingly!

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu May 27 10:34:54 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 27 May 2004 10:34:54 +0200
Subject: [R] block diagonal matrix function
References: <a06002006bcdb54ceba89@[139.166.242.29]>
Message-ID: <009e01c443c5$7d103910$ad133a86@www.domain>

Dear Robin,

you could use the following function which has been submitted to
s-news some time ago:

bdiag <- function(x){
     if(!is.list(x)) stop("x not a list")
     n <- length(x)
     if(n==0) return(NULL)
     x <- lapply(x, function(y) if(length(y)) as.matrix(y) else
stop("Zero-length component in x"))
     d <- array(unlist(lapply(x, dim)), c(2, n))
     rr <- d[1,]
     cc <- d[2,]
     rsum <- sum(rr)
     csum <- sum(cc)
     out <- array(0, c(rsum, csum))
     ind <- array(0, c(4, n))
     rcum <- cumsum(rr)
     ccum <- cumsum(cc)
     ind[1,-1] <- rcum[-n]
     ind[2,] <- rcum
     ind[3,-1] <- ccum[-n]
     ind[4,] <- ccum
     imat <- array(1:(rsum * csum), c(rsum, csum))
     iuse <- apply(ind, 2, function(y, imat) imat[(y[1]+1):y[2],
(y[3]+1):y[4]], imat=imat)
     iuse <- as.vector(unlist(iuse))
     out[iuse] <- unlist(x)
     return(out)
}

#########################

mats <- list(matrix(1:20, 5, 4), matrix(1:12, 4, 3), matrix(1:25, 5,
5))
bdiag(mats)

Regarding the dimnames of the matrices, I think you can easily create
a function thas calls bdiag and gives the appropriate names to the
final matrix.

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Robin Hankin" <rksh at soc.soton.ac.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, May 27, 2004 10:24 AM
Subject: [R] block diagonal matrix function


> Hello List
>
> I have just written a little function that takes two matrices as
> arguments and returns a large matrix that is composed of the two
input
> matrices in upper-left position and lower-right position with a
padding
> value everywhere else. (function definition and toy example below).
I
> need nonsquare matrices and rowname() and colname() inherited
appropriately.
>
> Two questions:
>
> (1) Is there a better way to do this? (kronecker() isn't applicable
here)
>
> (2) How do I generalize it to take an arbitrary number of matrices
as
>      inputs?
>
>
> TIV
>
> Robin
>
>
>
> "blockdiag" <-
> function (m1, m2, p.tr = 0, p.ll = 0)
> {
>      ## p.tr and p.ll are padding values
>      topleft <- m1
>      topright <- matrix(p.tr, nrow(m1), ncol(m2))
>      colnames(topright) <- colnames(m2)
>      lowleft <- matrix(p.ll, nrow(m2), ncol(m1))
>      lowright <- m2
>      rbind(cbind(topleft, topright), cbind(lowleft, lowright))
> }
>
> m1 <-
> structure(c(1, 1, 3, 1, 3, 4), .Dim = as.integer(c(2, 3)), .Dimnames
= list(
>      c("a", "b"), c("x", "y", "z")))
>
> m2 <-
> structure(c(2, 1, 1, 0, 3, 2, 2, 2, 0), .Dim = as.integer(c(3,
> 3)), .Dimnames = list(c("I", "II", "III"), c("A", "B", "C")))
>
> R> m1
>    x y z
> a 1 3 3
> b 1 1 4
>
> R> m2
>      A B C
> I   2 0 2
> II  1 3 2
> III 1 2 0
>
> R> blockdiag(m1,m2)
>      x y z A B C
> a   1 3 3 0 0 0
> b   1 1 4 0 0 0
> I   0 0 0 2 0 2
> II  0 0 0 1 3 2
> III 0 0 0 1 2 0
> R>
> -- 
> Robin Hankin
> Uncertainty Analyst
> Southampton Oceanography Centre
> SO14 3ZH
> tel +44(0)23-8059-7743
> initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam
precaution)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ajayshah at mayin.org  Thu May 27 11:29:11 2004
From: ajayshah at mayin.org (Ajay Shah)
Date: Thu, 27 May 2004 14:59:11 +0530
Subject: [R] Date parsing question
Message-ID: <20040527092911.GA14353@igidr.ac.in>

How do I parse a date "yyyymmdd"? I tried asking chron(s, "ymd") but
that didn't work. Would the date parsing routines of the Date class of
1.9 grok this?

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From p.dalgaard at biostat.ku.dk  Thu May 27 11:31:31 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 May 2004 11:31:31 +0200
Subject: [R] Date parsing question
In-Reply-To: <20040527092911.GA14353@igidr.ac.in>
References: <20040527092911.GA14353@igidr.ac.in>
Message-ID: <x2n03u2p3g.fsf@biostat.ku.dk>

Ajay Shah <ajayshah at mayin.org> writes:

> How do I parse a date "yyyymmdd"? I tried asking chron(s, "ymd") but
> that didn't work. Would the date parsing routines of the Date class of
> 1.9 grok this?

Yes, trivially:

> as.Date("20040527",format="%Y%m%d")
[1] "2004-05-27"


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tobias.verbeke at bivv.be  Thu May 27 11:38:56 2004
From: tobias.verbeke at bivv.be (tobias.verbeke@bivv.be)
Date: Thu, 27 May 2004 11:38:56 +0200
Subject: [R] Date parsing question
In-Reply-To: <20040527092911.GA14353@igidr.ac.in>
Message-ID: <OFF46B3545.2ACBC8D2-ONC1256EA1.0034F320-C1256EA1.003500ED@BIVV.BE>





r-help-bounces at stat.math.ethz.ch wrote on 27/05/2004 11:29:11:

> How do I parse a date "yyyymmdd"? I tried asking chron(s, "ymd") but
> that didn't work. Would the date parsing routines of the Date class of
> 1.9 grok this?

> a <- "20030527"
> as.Date(a, "%Y%m%d")
[1] "2003-05-27"

HTH,
Tobias

>
> --
> Ajay Shah                                                   Consultant
> ajayshah at mayin.org                      Department of Economic Affairs
> http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu May 27 12:00:44 2004
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 27 May 2004 12:00:44 +0200 (CEST)
Subject: [R] pmvt problem in multcomp
In-Reply-To: <87vfirzwhq.wl@oak.dti.ne.jp>
References: <87vfirzwhq.wl@oak.dti.ne.jp>
Message-ID: <Pine.LNX.4.51.0405271158500.1100@artemis.imbe.med.uni-erlangen.de>

On Thu, 20 May 2004, Chihiro Kuroki wrote:

> Hi, all:
>
> Two examples are shown below.
>
> I want to use the multiple comparison of Dunnett.
> It succeeded in upper case "example 1".
>
> However, the lower case "example 2" went wrong.
>

it was due to an error in the code underlying the `mvtnorm' package. The
problem was fixed by Alan Genz and I uploaded a revised version (0.6-7) of
the package to CRAN a few minutes ago.

Best,

Torsten


> In "example 2", the function pmvt return NaN, so I cannot show
> this simtest result. Is there any solution?
>
> (I changed the variable "maxpts" to a large number in front of
> the function pmvt ... but, the function mvt returned an error. )
>
> -- example 1 -------------------------------
> require(multcomp)
> Loading required package: multcomp
> Loading required package: mvtnorm
> [1] TRUE
>
> y <- as.vector(t$int)
> f <- as.factor(t$group1)
>
> table(f)
> f
>     1     2     3
> 20988 20988 20988
>
> dat <- cbind(as.data.frame(y),f)
> gc()
> summary(simtest(y ~ f, data=dat, type="Dunnett"))
>
> 	 Simultaneous tests: Dunnett contrasts
>
> Call:
> simtest.formula(formula = y ~ f, data = dat, type = "Dunnett")
>
> 	 Dunnett contrasts for factor f
>
> Contrast matrix:
>         f1 f2 f3
> f2-f1 0 -1  1  0
> f3-f1 0 -1  0  1
>
>
> Absolute Error Tolerance:  0.001
>
> Coefficients:
>       Estimate t value Std.Err. p raw p Bonf p adj
> f2-f1    4.015  -0.677    5.934 0.499  0.997 0.722
> f3-f1    2.486  -0.419    5.934 0.675  0.997 0.722
> ---------------------------------
>
> -- example 2 -------------------------------
> require(multcomp)
> Loading required package: multcomp
> Loading required package: mvtnorm
> [1] TRUE
>
> y <- as.vector(t$int)
> f <- as.factor(t$group2)
> table(f)
> f
>      1      2      3      4      5
> 104940 104940 104940 104940 104940
>
> dat <- cbind(as.data.frame(y),f)
> gc()
> summary(simtest(y ~ f, data=dat, type="Dunnett"))
>
> [1] "des <- model.matrix(ff, mf)"
>   (Intercept) aaa1 aaa2 aaa3 aaa4
> 1           1    1    0    0    0
> 2           1    0    1    0    0
> 3           1    0    0    1    0
> 4           1    0    0    0    1
> attr(,"assign")
> [1] 0 1 1 1 1
> attr(,"contrasts")
> attr(,"contrasts")$aaa
> [1] "ct"
>
> [1] "gls     <- rep(0,nrow(contonly))"
> [1] 0 0 0 0
>
> [1] "gls[i1]    <- 1-prob"
> [1] NaN   0   0   0
> [1] "gls[i1]    <- 1-prob"
> [1] NaN NaN   0   0
> [1] "gls[i1]    <- 1-prob"
> [1]          NaN          NaN -7.01661e-14  0.00000e+00
> [1] "gls[i1]    <- 1-prob"
> [1]           NaN           NaN -7.016610e-14  3.362133e-11
>
> [1] "glsbig"
>   aaa1 aaa2         aaa3         aaa4
> 1  NaN  NaN          NaN          NaN
> 2  NaN  NaN          NaN          NaN
> 3    0    0 -7.01661e-14 0.000000e+00
> 4    0    0  0.00000e+00 3.362133e-11
>
> [1] "glsp"
> aaa1 aaa2 aaa3 aaa4
>  NaN  NaN  NaN  NaN
> Error in if (glsp[i] < glsp[i - 1]) { : missing value where TRUE/FALSE needed
> Execution halted
> ---------------------------------
>
> --
> kuroki at oak.dti.ne.jp
> GnuPG fingerprint = 90FD FE79 905F 26F9 29C4  096F 8AA2 2C42 5130 1469
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu May 27 12:08:45 2004
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 27 May 2004 12:08:45 +0200 (CEST)
Subject: [R] pmvt problem in multcomp
In-Reply-To: <87oeobimv3.wl@oak.dti.ne.jp>
References: <87vfirzwhq.wl@oak.dti.ne.jp>
	<Pine.LNX.4.51.0405231138160.19910@artemis.imbe.med.uni-erlangen.de>
	<87oeobimv3.wl@oak.dti.ne.jp>
Message-ID: <Pine.LNX.4.51.0405271205330.1100@artemis.imbe.med.uni-erlangen.de>

>
> BTW, I have another strange example of simtest. I want to know
> why simtest returns these p-values.
>
> -- example 1 -------------------------------
> rm(list = ls())
> require(multcomp)
> y1 <- c(seq(3,7),seq(3,7))
> y2 <- c(rep(c(6,7,8,9),7))
> sort(runif(28),index=T) -> a
> y3 <- numeric(0)
> for(i in 1:28){
>   y3[i] <- y2[a$ix[i]]
> }
> y4 <- c(y1,y3,14,18)
>
> f2 <- factor(c(rep(1,10),rep(2,8),rep(3,8),rep(4,8),rep(5,6)))
> dat2 <- cbind(as.data.frame(y4),f2)
> summary(simtest(y4 ~ f2, data=dat2, type="Dunnett"))
>
> > dat2
>    y4 f2
> 1   3  1
> 2   4  1
> 3   5  1
> 4   6  1
> 5   7  1
> 6   3  1
> 7   4  1
> 8   5  1
> 9   6  1
> 10  7  1
> 11  6  2
> 12  7  2
> 13  6  2
> 14  9  2
> 15  7  2
> 16  8  2
> 17  6  2
> 18  8  2
> 19  9  3
> 20  8  3
> 21  7  3
> 22  9  3
> 23  6  3
> 24  8  3
> 25  9  3
> 26  7  3
> 27  7  4
> 28  9  4
> 29  6  4
> 30  6  4
> 31  9  4
> 32  8  4
> 33  7  4
> 34  9  4
> 35  6  5
> 36  8  5
> 37  8  5
> 38  7  5
> 39 14  5
> 40 18  5
> > summary(simtest(y4 ~ f2, data=dat2, type="Dunnett"))
>
> 	 Simultaneous tests: Dunnett contrasts
>
> Call:
> simtest.formula(formula = y4 ~ f2, data = dat2, type = "Dunnett")
>
> 	 Dunnett contrasts for factor f2
>
> Contrast matrix:
>           f21 f22 f23 f24 f25
> f22-f21 0  -1   1   0   0   0
> f23-f21 0  -1   0   1   0   0
> f24-f21 0  -1   0   0   1   0
> f25-f21 0  -1   0   0   0   1
>
>
> Absolute Error Tolerance:  0.001
>
> Coefficients:
>         Estimate t value Std.Err. p raw p Bonf p adj
> f25-f21    5.167  -4.644    1.022 0.000  0.000 0.000
> f23-f21    2.875  -2.813    1.022 0.008  0.024 0.022
> f24-f21    2.625  -2.569    1.022 0.015  0.029 0.028
> f22-f21    2.125  -2.079    1.113 0.045  0.045 0.045
> ---------------------------------
>
> I got the following inequality from the appended chart of a
> book.
>

hm, without knowing what

> 2.558 < d(5, 35, 0.4263464, 0.05) < 2.598

means it is hard to tell what the problem is. Could you please explain it
further?

Best,

Torsten

>
> Are these "p adj" values right?
> Or do I misunderstand some?
> --
> kuroki
> GnuPG fingerprint = 90FD FE79 905F 26F9 29C4  096F 8AA2 2C42 5130 1469
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From dvumani at hotmail.com  Thu May 27 12:23:48 2004
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Thu, 27 May 2004 10:23:48 +0000
Subject: [R] manipulating elements of a vector
Message-ID: <BAY16-F10BPR5h7Gt4x0004abff@hotmail.com>

Dear R users;

I would like to convert a series of vectors to matrices in the following 
way;
(2,1,1) to a matrix
1 0 0
1 0 0
0 1 0
0 0 1

The idea is that the column sum of the matrix should be equal to the 
elements of the vector.

Thanks.

Vumani



From p.dalgaard at biostat.ku.dk  Thu May 27 12:27:44 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 May 2004 12:27:44 +0200
Subject: [R] manipulating elements of a vector
In-Reply-To: <BAY16-F10BPR5h7Gt4x0004abff@hotmail.com>
References: <BAY16-F10BPR5h7Gt4x0004abff@hotmail.com>
Message-ID: <x2isei2mhr.fsf@biostat.ku.dk>

"Vumani Dlamini" <dvumani at hotmail.com> writes:

> Dear R users;
> 
> I would like to convert a series of vectors to matrices in the
> following way;
> (2,1,1) to a matrix
> 1 0 0
> 1 0 0
> 0 1 0
> 0 0 1
> 
> The idea is that the column sum of the matrix should be equal to the
> elements of the vector.

Didn't we just do that? (No, that was incidence matrices...)
  
  i <- rep(1:3,c(2,1,1))
  diag(3)[i,]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jps at sanger.ac.uk  Thu May 27 12:34:24 2004
From: jps at sanger.ac.uk (Jason Skelton)
Date: Thu, 27 May 2004 11:34:24 +0100
Subject: [R] Stats package
Message-ID: <40B5C430.9070907@sanger.ac.uk>


Hi

The cor function in the stats package calculates the correlation between 
columns of data, does anyone know if it is at all possible to calculate 
the correlation between rows instead ?
Or is there an appropriate package or function that is more appropriate
I'd like to calculate spearman & pearson correlations between rows.

Many thanks

Jason



-- 
--------------------------------
Jason Skelton
Pathogen Microarrays
Wellcome Trust Sanger Institute
Hinxton
Cambridge
CB10 1SA

Tel +44(0)1223 834244 Ext 7123
Fax +44(0)1223 494919



From lecoutre at stat.ucl.ac.be  Thu May 27 12:31:37 2004
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Thu, 27 May 2004 12:31:37 +0200
Subject: [R] manipulating elements of a vector
In-Reply-To: <BAY16-F10BPR5h7Gt4x0004abff@hotmail.com>
References: <BAY16-F10BPR5h7Gt4x0004abff@hotmail.com>
Message-ID: <6.0.1.1.2.20040527123048.02065460@stat4ux.stat.ucl.ac.be>

Hi,

What about:

   dummy=function(x){
         diag(length(x))[rep(1:length(x),x),]
   }

   >  dummy(c(3,2,4))
       [,1] [,2] [,3]
  [1,]    1    0    0
  [2,]    1    0    0
  [3,]    1    0    0
  [4,]    0    1    0
  [5,]    0    1    0
  [6,]    0    0    1
  [7,]    0    0    1
  [8,]    0    0    1
  [9,]    0    0    1

HTH,

Eric

At 12:23 27/05/2004, you wrote:
>Dear R users;
>
>I would like to convert a series of vectors to matrices in the following way;
>(2,1,1) to a matrix
>1 0 0
>1 0 0
>0 1 0
>0 0 1
>
>The idea is that the column sum of the matrix should be equal to the 
>elements of the vector.
>
>Thanks.
>
>Vumani

Eric Lecoutre
UCL /  Institut de Statistique
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
Belgium

tel: (+32)(0)10473050
lecoutre at stat.ucl.ac.be
http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

If the statistics are boring, then you've got the wrong numbers. -Edward 
Tufte



From wolski at molgen.mpg.de  Thu May 27 12:46:00 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 27 May 2004 12:46:00 +0200
Subject: [R] Stats package
In-Reply-To: <40B5C430.9070907@sanger.ac.uk>
References: <40B5C430.9070907@sanger.ac.uk>
Message-ID: <200405271246000890.00FC0B99@mail.math.fu-berlin.de>

Hi

cor(t(matrix))
t=Transpose matrix
Eryk

*********** REPLY SEPARATOR  ***********

On 5/27/2004 at 11:34 AM Jason Skelton wrote:

>Hi
>
>The cor function in the stats package calculates the correlation between 
>columns of data, does anyone know if it is at all possible to calculate 
>the correlation between rows instead ?
>Or is there an appropriate package or function that is more appropriate
>I'd like to calculate spearman & pearson correlations between rows.
>
>Many thanks
>
>Jason
>
>
>
>-- 
>--------------------------------
>Jason Skelton
>Pathogen Microarrays
>Wellcome Trust Sanger Institute
>Hinxton
>Cambridge
>CB10 1SA
>
>Tel +44(0)1223 834244 Ext 7123
>Fax +44(0)1223 494919
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From sdavis2 at mail.nih.gov  Thu May 27 12:48:07 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 27 May 2004 06:48:07 -0400
Subject: [R] Stats package
In-Reply-To: <40B5C430.9070907@sanger.ac.uk>
Message-ID: <BCDB3FA7.8562%sdavis2@mail.nih.gov>

Jason,

If you have a matrix m, you can take

cor(t(m))

Where t is the transpose operator.

Sean

On 5/27/04 6:34 AM, "Jason Skelton" <jps at sanger.ac.uk> wrote:

> 
> Hi
> 
> The cor function in the stats package calculates the correlation between
> columns of data, does anyone know if it is at all possible to calculate
> the correlation between rows instead ?
> Or is there an appropriate package or function that is more appropriate
> I'd like to calculate spearman & pearson correlations between rows.
> 
> Many thanks
> 
> Jason
> 
>



From ggrothendieck at myway.com  Thu May 27 12:50:05 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 27 May 2004 10:50:05 +0000 (UTC)
Subject: [R] Date parsing question
References: <20040527092911.GA14353@igidr.ac.in>
Message-ID: <loom.20040527T124224-184@post.gmane.org>

Ajay Shah <ajayshah <at> mayin.org> writes:

> 
> How do I parse a date "yyyymmdd"? I tried asking chron(s, "ymd") but
> that didn't work. Would the date parsing routines of the Date class of
> 1.9 grok this?
> 


Others have already mentioned z <- as.Date("20040527",format="%Y%m%d")
and if you want it as a chron date try:

chron(unclass(z))

The percent codes in Date are convenient so that's probably the way
to go but just for fun, to do it in chron without using the Date class
you could convert it to the form 05/27/2004 using sub and then apply 
chron:

chron(sub("(....)(..)(..)","\\2/\\3/\\1","20040527"))



From ggrothendieck at myway.com  Thu May 27 12:57:16 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 27 May 2004 10:57:16 +0000 (UTC)
Subject: [R] block diagonal matrix function
References: <a06002006bcdb54ceba89@[139.166.242.29]>
Message-ID: <loom.20040527T125031-578@post.gmane.org>

The zoo package can handle multiway merges of this sort.  The
following example uses your two matrices m1 and m2 but any
number could have been supplied.  Each matrix must be converted
to a zoo object with successive times and then NAs in the result
replaced with zeros.  If the names are important you would have
to set those yourself afterwards:

R> require(zoo)
[1] TRUE
R> m1. <- zoo(m1,1:2)
R> m2. <- zoo(m2,3:5)
R> m. <- merge(m1., m2.)
R> ifelse(is.na(m.),0,m.)
     m1..x m1..y m1..z m2..A m2..B m2..C
[1,]     1     3     3     0     0     0
[2,]     1     1     4     0     0     0
[3,]     0     0     0     2     0     2
[4,]     0     0     0     1     3     2
[5,]     0     0     0     1     2     0


Robin Hankin <rksh <at> soc.soton.ac.uk> writes:

: 
: Hello List
: 
: I have just written a little function that takes two matrices as
: arguments and returns a large matrix that is composed of the two input
: matrices in upper-left position and lower-right position with a padding
: value everywhere else. (function definition and toy example below).  I
: need nonsquare matrices and rowname() and colname() inherited appropriately.
: 
: Two questions:
: 
: (1) Is there a better way to do this? (kronecker() isn't applicable here)
: 
: (2) How do I generalize it to take an arbitrary number of matrices as
:      inputs?
: 
: TIV
: 
: Robin
: 
: 
: "blockdiag" <-
: function (m1, m2, p.tr = 0, p.ll = 0)
: {
:      ## p.tr and p.ll are padding values
:      topleft <- m1
:      topright <- matrix(p.tr, nrow(m1), ncol(m2))
:      colnames(topright) <- colnames(m2)
:      lowleft <- matrix(p.ll, nrow(m2), ncol(m1))
:      lowright <- m2
:      rbind(cbind(topleft, topright), cbind(lowleft, lowright))
: }
: 
: m1 <-
: structure(c(1, 1, 3, 1, 3, 4), .Dim = as.integer(c(2, 3)), .Dimnames = list(
:      c("a", "b"), c("x", "y", "z")))
: 
: m2 <-
: structure(c(2, 1, 1, 0, 3, 2, 2, 2, 0), .Dim = as.integer(c(3,
: 3)), .Dimnames = list(c("I", "II", "III"), c("A", "B", "C")))
: 
: R> m1
:    x y z
: a 1 3 3
: b 1 1 4
: 
: R> m2
:      A B C
: I   2 0 2
: II  1 3 2
: III 1 2 0
: 
: R> blockdiag(m1,m2)
:      x y z A B C
: a   1 3 3 0 0 0
: b   1 1 4 0 0 0
: I   0 0 0 2 0 2
: II  0 0 0 1 3 2
: III 0 0 0 1 2 0
: R>



From joshini at mail.nih.gov  Thu May 27 13:43:30 2004
From: joshini at mail.nih.gov (Joshi, Nina (NIH/NCI))
Date: Thu, 27 May 2004 07:43:30 -0400
Subject: [R] automating aov function
Message-ID: <27C204BD76CBC142BA1AE46D62A8548E0D806568@nihexchange9.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040527/80553393/attachment.pl

From jonathan.williams at pharmacology.oxford.ac.uk  Thu May 27 14:21:21 2004
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Thu, 27 May 2004 13:21:21 +0100
Subject: [R] Is it possible to read jpeg files into R?
Message-ID: <NGBBKJEMOMLJFCOIEGCECEJHJLAA.jonathan.williams@pharm.ox.ac.uk>

Hi Helpers,
Does anyone know how to read jpeg, bmp or png files into R? 
I have some photos of brain scans and I want to quantify
some aspects of their size. I might be able to do this
with the 'locator' function, if I could figure out how
to read the files in and make them into an image that
I can display on the R Windows device. I have experimented
with readBin, using a simple black-and-white line graph,
but the numeric result appears to be much too complex for
a simple line graph and I cannot see how to use image or
contour to re-create the original jpeg image. Is there an
R routine to do this?

Thanks, in advance, for your help,

Jonathan Williams
OPTIMA
Radcliffe Infirmary
Woodstock Road
OXFORD OX2 6HE
Tel +1865 (2)24356



From Matthias.Kohl at uni-bayreuth.de  Thu May 27 15:01:51 2004
From: Matthias.Kohl at uni-bayreuth.de (Matthias Kohl)
Date: Thu, 27 May 2004 14:01:51 +0100
Subject: [R] "privileged slots"
Message-ID: <40B5E6BF.1090100@uni-bayreuth.de>

Hi all,

in the help for RClassUtils I found the expression "privileged slots" in 
function "checkSlotAssignment" with the explanation:

/privileged slots (those that can only be set by accesor functions 
defined along with the class itself)/

I thought all slots of a (not private) class can be a accessed by a user 
via the @ Operator.
Is there a way to make a single slot of a class (not the whole class) 
private, so that you can access this slot only via an accessor function 
(not via @)?

Thanks, for your help
Matthias



From wolski at molgen.mpg.de  Thu May 27 14:08:06 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 27 May 2004 14:08:06 +0200
Subject: [R] Is it possible to read jpeg files into R?
In-Reply-To: <NGBBKJEMOMLJFCOIEGCECEJHJLAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCECEJHJLAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <200405271408060804.0147348C@mail.math.fu-berlin.de>

Hallo Jonathan!
help.search("jpeg") is R users friend.

#search result.
Help files with alias or concept or title matching 'jpeg' using
regular expression matching:
f.plot.ica.fmri.jpg(AnalyzeFMRI)
                        Plot the components of the ouput of f.ica.fmri
                        to a series of jpeg files
bmp(graphics)           BMP, JPEG and PNG graphics devices
cat.picture(rimage)     JPEG picture of a cat
read.jpeg(rimage)       Read JPEG file
Type 'help(FOO, package = PKG)' to inspect entry 'FOO(PKG) TITLE'.



library(rimage)
> ?read.jpeg

     This function reads a jpeg image file and return an imagematrix
     object.

Sincerely


*********** REPLY SEPARATOR  ***********

On 5/27/2004 at 1:21 PM Jonathan Williams wrote:

>Hi Helpers,
>Does anyone know how to read jpeg, bmp or png files into R? 
>I have some photos of brain scans and I want to quantify
>some aspects of their size. I might be able to do this
>with the 'locator' function, if I could figure out how
>to read the files in and make them into an image that
>I can display on the R Windows device. I have experimented
>with readBin, using a simple black-and-white line graph,
>but the numeric result appears to be much too complex for
>a simple line graph and I cannot see how to use image or
>contour to re-create the original jpeg image. Is there an
>R routine to do this?
>
>Thanks, in advance, for your help,
>
>Jonathan Williams
>OPTIMA
>Radcliffe Infirmary
>Woodstock Road
>OXFORD OX2 6HE
>Tel +1865 (2)24356
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From Matthias.Templ at statistik.gv.at  Thu May 27 14:20:35 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Thu, 27 May 2004 14:20:35 +0200
Subject: [R] Rcmd check, windows xp, perl (2)
Message-ID: <83536658864BC243BE3C06D7E936ABD501536910@xchg1.statistik.local>

 Thank you for your help. I??m sorry that I found not the right 
 entries in the R-devel. Now, I have again a problem.
 
 After installing all needed things I have run 
 Rcmd INSTALL -l ../mypkg  	and respectively 
 make mypkg 
 
 By running Rcmd check I get following message:
 	* checking for working latex ...Error: environment 
 variable TMPDIR not set (or set to unusable value) and no 	
 default available. At 
 D:\Programme\R\rw1090\share\perl/R/Utils.pm line 153
 
 By running Rcmd built I get following message:
 	Please set TMPDIR to a valid temporary directory
 
 My TMPDIR is on "D:\temp" , which is known by R.
 In "Utils.pm" I have no idea how to set TMPDIR at  sub R_tempfile
 
 Maybe this problem was discussed in Oct 2002.
 
 Can anybody help me again please?
 
 Thanks,
 Matthias
 
 (I??m running R version 1.9.0 on Windows XP, perl 5.8.3)
 
> > -----Urspr??ngliche Nachricht-----
> > Von: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> > Gesendet: Donnerstag, 27. Mai 2004 09:26
> > An: TEMPL Matthias
> > Cc: R-help at stat.math.ethz.ch
> > Betreff: Re: [R] Rcmd check, windows xp, perl
> > 
> > 
> > TEMPL Matthias wrote:
> > 
> > > Dear R users,
> > > 
> > > With package.skeleton() i have produced successfully my
> > .Rd??s, ... Now
> > > i will run Rcmd check on ..\R\bin\
> > > 
> > > But Rcmd check (and build) on my Windows XP does not work. It`s a
> > > problem with "perl". (Translated i get the message:
> > > The instruction Perl is either wrongly written or could not 
> > not be found.)
> > > 
> > > In help("check") I found this:
> > >      "These may not work correctly under Windows 95/98/ME 
> because of
> > >      problems Perl has launching programs on those limited OSes."
> > > 
> > > And in the R-devel I found following from Prof. Brian Ripley:
> > >      "2) On Windows, we did hope to make Rcmd check the
> > standard way.
> > >      Unfortunately, a whole series Perl builds were 
> broken, so make 
> > >      pkgcheck-foo is still preferred."
> > > 
> > > But i can not find something like "pkgcheck" and Rcmd 
> does not work.
> > > 
> > > (I use R version 1.9.0 on Windows XP, IBM Computer)
> > 
> > On Windows XP everything is fine.
> > 
> > Please read ..../src/gnuwin32/readme.packages and follow the
> > instructions therein exactly.
> > In particular: Do you have perl installed?
> > 
> > Uwe Ligges
> > 
> > 
> > > Can anybody help me please?
> > > 
> > > Regards,
> > > 
> > > Matthias
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > 
> > 
>



From rbaer at atsu.edu  Thu May 27 14:25:23 2004
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Thu, 27 May 2004 07:25:23 -0500
Subject: [R] Is it possible to read jpeg files into R?
References: <NGBBKJEMOMLJFCOIEGCECEJHJLAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <002d01c443e5$af15f4c0$2e80010a@BigBaer>

?pixmap in the pixmap library might be of use to you.

Rob Baer

----- Original Message ----- 
From: "Jonathan Williams" <jonathan.williams at pharmacology.oxford.ac.uk>
To: "Ethz. Ch" <r-help at stat.math.ethz.ch>
Sent: Thursday, May 27, 2004 7:21 AM
Subject: [R] Is it possible to read jpeg files into R?


> Hi Helpers,
> Does anyone know how to read jpeg, bmp or png files into R?
> I have some photos of brain scans and I want to quantify
> some aspects of their size. I might be able to do this
> with the 'locator' function, if I could figure out how
> to read the files in and make them into an image that
> I can display on the R Windows device. I have experimented
> with readBin, using a simple black-and-white line graph,
> but the numeric result appears to be much too complex for
> a simple line graph and I cannot see how to use image or
> contour to re-create the original jpeg image. Is there an
> R routine to do this?
>
> Thanks, in advance, for your help,
>
> Jonathan Williams
> OPTIMA
> Radcliffe Infirmary
> Woodstock Road
> OXFORD OX2 6HE
> Tel +1865 (2)24356
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Thu May 27 14:27:32 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 27 May 2004 14:27:32 +0200
Subject: [R] Rcmd check, windows xp, perl (2)
In-Reply-To: <83536658864BC243BE3C06D7E936ABD501536910@xchg1.statistik.local>
References: <83536658864BC243BE3C06D7E936ABD501536910@xchg1.statistik.local>
Message-ID: <40B5DEB4.7030602@statistik.uni-dortmund.de>

TEMPL Matthias wrote:

>  Thank you for your help. I??m sorry that I found not the right 
>  entries in the R-devel. Now, I have again a problem.
>  
>  After installing all needed things I have run 
>  Rcmd INSTALL -l ../mypkg  	and respectively 
>  make mypkg 
>  
>  By running Rcmd check I get following message:
>  	* checking for working latex ...Error: environment 
>  variable TMPDIR not set (or set to unusable value) and no 	
>  default available. At 
>  D:\Programme\R\rw1090\share\perl/R/Utils.pm line 153
>  
>  By running Rcmd built I get following message:
>  	Please set TMPDIR to a valid temporary directory
>  
>  My TMPDIR is on "D:\temp" , which is known by R.
>  In "Utils.pm" I have no idea how to set TMPDIR at  sub R_tempfile
>  
>  Maybe this problem was discussed in Oct 2002.
>  
>  Can anybody help me again please?
>  
>  Thanks,
>  Matthias


Obviously you have *not* set an environment variable TMPDIR. Try for 
example (if c:\Windows\temp exists and you have got write access):

set TMPDIR=c:\Windows\temp
R CMD INSTALL mypkg

Uwe Ligges




>  (I??m running R version 1.9.0 on Windows XP, perl 5.8.3)
>  
> 
>>>-----Urspr??ngliche Nachricht-----
>>>Von: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
>>>Gesendet: Donnerstag, 27. Mai 2004 09:26
>>>An: TEMPL Matthias
>>>Cc: R-help at stat.math.ethz.ch
>>>Betreff: Re: [R] Rcmd check, windows xp, perl
>>>
>>>
>>>TEMPL Matthias wrote:
>>>
>>>
>>>>Dear R users,
>>>>
>>>>With package.skeleton() i have produced successfully my
>>>
>>>.Rd??s, ... Now
>>>
>>>>i will run Rcmd check on ..\R\bin\
>>>>
>>>>But Rcmd check (and build) on my Windows XP does not work. It`s a
>>>>problem with "perl". (Translated i get the message:
>>>>The instruction Perl is either wrongly written or could not 
>>>
>>>not be found.)
>>>
>>>>In help("check") I found this:
>>>>     "These may not work correctly under Windows 95/98/ME 
>>
>>because of
>>
>>>>     problems Perl has launching programs on those limited OSes."
>>>>
>>>>And in the R-devel I found following from Prof. Brian Ripley:
>>>>     "2) On Windows, we did hope to make Rcmd check the
>>>
>>>standard way.
>>>
>>>>     Unfortunately, a whole series Perl builds were 
>>
>>broken, so make 
>>
>>>>     pkgcheck-foo is still preferred."
>>>>
>>>>But i can not find something like "pkgcheck" and Rcmd 
>>
>>does not work.
>>
>>>>(I use R version 1.9.0 on Windows XP, IBM Computer)
>>>
>>>On Windows XP everything is fine.
>>>
>>>Please read ..../src/gnuwin32/readme.packages and follow the
>>>instructions therein exactly.
>>>In particular: Do you have perl installed?
>>>
>>>Uwe Ligges
>>>
>>>
>>>
>>>>Can anybody help me please?
>>>>
>>>>Regards,
>>>>
>>>>Matthias
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! 
>>>>http://www.R-project.org/posting-guide.html
>>>
>>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From wolski at molgen.mpg.de  Thu May 27 14:30:29 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 27 May 2004 14:30:29 +0200
Subject: [R] Rcmd check, windows xp, perl (2)
In-Reply-To: <83536658864BC243BE3C06D7E936ABD501536910@xchg1.statistik.local>
References: <83536658864BC243BE3C06D7E936ABD501536910@xchg1.statistik.local>
Message-ID: <200405271430290114.015BAFF2@mail.math.fu-berlin.de>

Hi!

In the bat file where you specified the paths to perl, miktex bin directory you can also set the TMPDIR by:

set TMPDIR =c:/path/toAnExistingTempDirectory

Eryk


*********** REPLY SEPARATOR  ***********

On 5/27/2004 at 2:20 PM TEMPL Matthias wrote:

>Thank you for your help. I??m sorry that I found not the right 
> entries in the R-devel. Now, I have again a problem.
> 
> After installing all needed things I have run 
> Rcmd INSTALL -l ../mypkg  	and respectively 
> make mypkg 
> 
> By running Rcmd check I get following message:
> 	* checking for working latex ...Error: environment 
> variable TMPDIR not set (or set to unusable value) and no 	
> default available. At 
> D:\Programme\R\rw1090\share\perl/R/Utils.pm line 153
> 
> By running Rcmd built I get following message:
> 	Please set TMPDIR to a valid temporary directory
> 
> My TMPDIR is on "D:\temp" , which is known by R.
> In "Utils.pm" I have no idea how to set TMPDIR at  sub R_tempfile
> 
> Maybe this problem was discussed in Oct 2002.
> 
> Can anybody help me again please?
> 
> Thanks,
> Matthias
> 
> (I??m running R version 1.9.0 on Windows XP, perl 5.8.3)
> 
>> > -----Urspr??ngliche Nachricht-----
>> > Von: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
>> > Gesendet: Donnerstag, 27. Mai 2004 09:26
>> > An: TEMPL Matthias
>> > Cc: R-help at stat.math.ethz.ch
>> > Betreff: Re: [R] Rcmd check, windows xp, perl
>> > 
>> > 
>> > TEMPL Matthias wrote:
>> > 
>> > > Dear R users,
>> > > 
>> > > With package.skeleton() i have produced successfully my
>> > .Rd??s, ... Now
>> > > i will run Rcmd check on ..\R\bin\
>> > > 
>> > > But Rcmd check (and build) on my Windows XP does not work. It`s a
>> > > problem with "perl". (Translated i get the message:
>> > > The instruction Perl is either wrongly written or could not 
>> > not be found.)
>> > > 
>> > > In help("check") I found this:
>> > >      "These may not work correctly under Windows 95/98/ME 
>> because of
>> > >      problems Perl has launching programs on those limited OSes."
>> > > 
>> > > And in the R-devel I found following from Prof. Brian Ripley:
>> > >      "2) On Windows, we did hope to make Rcmd check the
>> > standard way.
>> > >      Unfortunately, a whole series Perl builds were 
>> broken, so make 
>> > >      pkgcheck-foo is still preferred."
>> > > 
>> > > But i can not find something like "pkgcheck" and Rcmd 
>> does not work.
>> > > 
>> > > (I use R version 1.9.0 on Windows XP, IBM Computer)
>> > 
>> > On Windows XP everything is fine.
>> > 
>> > Please read ..../src/gnuwin32/readme.packages and follow the
>> > instructions therein exactly.
>> > In particular: Do you have perl installed?
>> > 
>> > Uwe Ligges
>> > 
>> > 
>> > > Can anybody help me please?
>> > > 
>> > > Regards,
>> > > 
>> > > Matthias
>> > > 
>> > > ______________________________________________
>> > > R-help at stat.math.ethz.ch mailing list
>> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide! 
>> > > http://www.R-project.org/posting-guide.html
>> > 
>> > 
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From lauraholt_983 at hotmail.com  Thu May 27 14:42:20 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Thu, 27 May 2004 07:42:20 -0500
Subject: [R] socketConnection and readLines
Message-ID: <BAY12-F957kTo0fKfFk00033fb1@hotmail.com>

Dear R People:


I have tried the following code:

>con <- socketConnection(port=13, host="tick.usno.navy.mil")
>readLines(con)


The socketConnection function works, but the readLines command just sits.

This has happened on R for Windows 1.8.1 and 1.9.0 and R on LINUX 1.8.1

Any suggestions, please


Thanks,
Laura
mailto: lauraholt_983 at hotmail.com

_________________________________________________________________




From feh3k at spamcop.net  Thu May 27 08:44:49 2004
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Thu, 27 May 2004 08:44:49 +0200
Subject: [R] Getting the same values of adjusted mean and standard
	errors as SAS
In-Reply-To: <40B5931A.7090203@adelaide.edu.au>
References: <40B5931A.7090203@adelaide.edu.au>
Message-ID: <20040527084449.4a035892.feh3k@spamcop.net>

On Thu, 27 May 2004 16:34:58 +0930
"David J. Netherway" <david.netherway at adelaide.edu.au> wrote:

> Hello,
>  
> I am trying to get the same values for the adjusted means and standard 
> errors using R that are given in SAS for the
> following data. The model is Measurement ~ Age + Gender + Group. I can 
> get the adusted means at the mean age  
> by using predict. I do not know how to get the appropriate standard 
> errors at the adjusted means for Gender
> using values from predict. So I attempted to get them directly from the 
> residuals as follows. The data is at the end
> of the email. While there is a match for the males there is a large 
> difference for the females indicating that what I am doing is wrong.
>  
> #  
> meanAge <- mean(dd$Age)
> meanAgeM <- mean(dd$Age[d$Gender=="M"])
> meanAgeF <- mean(dd$Age[d$Gender=="F"])
. . . .

By using sex-specific means of age you are not getting adjusted estimates
in the usual sense.

I prefer to think of effects as differences in predicted values rather
than as complex SAS-like contrasts. The Design package's contrast function
makes this easy (including SEs and confidence limits):

library(Design)   # also requires Hmisc
d <- datadist(dd); options(datadist='d')
f <- ols(y ~ age + sex + group, data=dd)
contrast(f, list(sex='M'), list(sex='F'))   # usual adjusted difference M
vs F
contrast(f, list(sex='M',age=mean(dd$age[dd$sex=='M']),
            list(sex='F',age=mean(dd$age[dd$sex=='F')) # M vs F not
holding age constant

You can also experiment with specifying age=tapply(age, sex, mean,
na.rm=TRUE) using some of the contrast.Design options.
---
Frank E Harrell Jr   Professor and Chair           School of Medicine
                     Department of Biostatistics   Vanderbilt University



From mmorley at mail.med.upenn.edu  Thu May 27 14:46:32 2004
From: mmorley at mail.med.upenn.edu (Michael Morley)
Date: Thu, 27 May 2004 08:46:32 -0400
Subject: [R] automating aov function
In-Reply-To: <27C204BD76CBC142BA1AE46D62A8548E0D806568@nihexchange9.nih.gov>
References: <27C204BD76CBC142BA1AE46D62A8548E0D806568@nihexchange9.nih.gov>
Message-ID: <40B5E328.4070600@mail.med.upenn.edu>

If you want a matrix (perhaps a data.frame so you can add different data 
types(gene name, accession, etc) of just the F and Ps from each anova.
Something like this works for me. Though I'm a newbie too, so if there 
is a better way someone let me know!
----------------------
#create 2 by # genes matrix, can add row names or col names
#precomputing your matrix will save some computational time as compare 
to rbind
#assume genes is some matrix or data.frame

results <- matrix(ncol=2, nrow=length(genes[,1]))

for(i in 1:length(genes[,1]){
     an <- anova(lm(formula,data))
     results[i,] <- c(an$F[1], an$P[1] )
}

------------------

Don't forget about the multiple testing!

-Mike


Joshi, Nina (NIH/NCI) wrote:

> 
>
>I am running the aov function to determine the linear relationship between
>individual genes and a number of covariates in a micro-array data set.  My
>aov function is working, but I have not been able to write a code to save
>these results in a matrix.  I am using the following code or a slight
>variation of this code:
>
> 
>
>for(i in 1(length(m[1,])-20)
>
> 
>
>{tmp<- aov(m[,i]~treat, data=m)
>
> 
>
>{results [i] <- tmp}}
>
> 
>
>Any help would be appreciated.
>
> 
>
> 
>
>Thanks,
>
> 
>
>Nina
>
> 
>
> 
>
>Nina Joshi, PhD
>
>NIH/NCI/ Genetics Branch
>
>National Naval Medical Center, Bldg. 8, Rm. 5101
>
>8901 Wisconsin Ave.
>
>Bethesda, MD. 20889-5101
>
>(301) 435-5436 - phone
>
>(301) 496-0047 - fax
>
> 
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Michael Morley
Bioinformatics Specialist
University of Pennsylvania
Department of Pediatrics
3516 Civic Center Blvd.,
510B Abramson Pediatric Research Center,
Philadelphia, PA 19104-4318.
Phone: (215) 590-7673
FAX: (215) 590-3709



From wolski at molgen.mpg.de  Thu May 27 14:56:29 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 27 May 2004 14:56:29 +0200
Subject: [R] "privileged slots"
In-Reply-To: <40B5E6BF.1090100@uni-bayreuth.de>
References: <40B5E6BF.1090100@uni-bayreuth.de>
Message-ID: <200405271456290658.01737FD2@mail.math.fu-berlin.de>

Hi!

I think that there are no mechanism in S4 to make slots "private".
But you as a package developer can of course provide accessor functions to a public slot anyway and use slot(myslot,value,check=FALSE)
to switch of the function checkSlotAssignment function and speed up your code.

This is how I interpretation of this text of John Chambers.


Sincerely
Eryk



*********** REPLY SEPARATOR  ***********

On 5/27/2004 at 2:01 PM Matthias Kohl wrote:

>Hi all,
>
>in the help for RClassUtils I found the expression "privileged slots" in 
>function "checkSlotAssignment" with the explanation:
>
>/privileged slots (those that can only be set by accesor functions 
>defined along with the class itself)/
>
>I thought all slots of a (not private) class can be a accessed by a user 
>via the @ Operator.
>Is there a way to make a single slot of a class (not the whole class) 
>private, so that you can access this slot only via an accessor function 
>(not via @)?
>
>Thanks, for your help
>Matthias
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From wolski at molgen.mpg.de  Thu May 27 14:59:29 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 27 May 2004 14:59:29 +0200
Subject: [R] "privileged slots"
In-Reply-To: <200405271456290658.01737FD2@mail.math.fu-berlin.de>
References: <40B5E6BF.1090100@uni-bayreuth.de>
	<200405271456290658.01737FD2@mail.math.fu-berlin.de>
Message-ID: <200405271459290617.01763EC9@mail.math.fu-berlin.de>


There is a mistake in my e-mail
Of course should be
slot(object,name,check=FALSE)<-value

Sorry.
Eryk


*********** REPLY SEPARATOR  ***********

On 5/27/2004 at 2:56 PM Wolski wrote:

>Hi!
>
>I think that there are no mechanism in S4 to make slots "private".
>But you as a package developer can of course provide accessor functions to
>a public slot anyway and use slot(myslot,value,check=FALSE)
>to switch of the function checkSlotAssignment function and speed up your
>code.
>
>This is how I interpretation of this text of John Chambers.
>
>
>Sincerely
>Eryk
>
>
>
>*********** REPLY SEPARATOR  ***********
>
>On 5/27/2004 at 2:01 PM Matthias Kohl wrote:
>
>>Hi all,
>>
>>in the help for RClassUtils I found the expression "privileged slots" in 
>>function "checkSlotAssignment" with the explanation:
>>
>>/privileged slots (those that can only be set by accesor functions 
>>defined along with the class itself)/
>>
>>I thought all slots of a (not private) class can be a accessed by a user 
>>via the @ Operator.
>>Is there a way to make a single slot of a class (not the whole class) 
>>private, so that you can access this slot only via an accessor function 
>>(not via @)?
>>
>>Thanks, for your help
>>Matthias
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>
>
>
>Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
>Ihnestrasse 63-73 14195 Berlin       'v'    
>tel: 0049-30-83875219               /   \    
>mail: wolski at molgen.mpg.de        ---W-W----   
>http://www.molgen.mpg.de/~wolski
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From Matthias.Schmidt at forst.bwl.de  Thu May 27 15:10:00 2004
From: Matthias.Schmidt at forst.bwl.de (Schmidt.Matthias (FORST))
Date: Thu, 27 May 2004 15:10:00 +0200
Subject: [R] specifying starting values in nlsList/conversion problems
Message-ID: <855D381F618DE84FA58C035BA803FCE6B9A723@fvafr-se1.forst.bwl.de>

Hi 
I am using nlsList from the nlme package to estimate group specific
coefficient sets to get a first impression of the structure of coefficients
in relation to potential predictor variables. In some cases I got
coefficients in other there are conversion problems due to bad start values
I guess, resulting in typical error messages as known from nls:

Error in nls(formula = formula, data = data, start = start, control =
control) : 
        singular gradient
Error in nls(formula = formula, data = data, start = start, control =
control) : 
        step factor 0.000488281 reduced below `minFactor' of 0.000976563
Error in numericDeriv(form[[3]], names(ind), env) : 
        Missing value or an Infinity produced when evaluating the model

is there a possibility to specifiy group specific starting or an algorithm
which tests a matrix of starting with a certain stepwidth to overcome the
conversion problems?

thanx for help

***********************************************************
Matthias Schmidt
Forstliche Versuchs- und Forschungsanstalt Baden-W??rttemberg (FVA) 
Abteilung Biometrie und Informatik
Wonnhaldestr. 4
79100 Freiburg i. Br
Tel.: + 49 (0)761 / 4018 -187
Fax: + 49 (0)761 / 4018 - 333



From rnassa at rediffmail.com  Thu May 27 15:12:06 2004
From: rnassa at rediffmail.com (Rakesh  Nassa)
Date: 27 May 2004 13:12:06 -0000
Subject: [R] How to use R Library in VC++ wrapper dll  (SOS)
Message-ID: <20040527131206.18231.qmail@mailweb33.rediffmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040527/7ce9f5f7/attachment.pl

From adi at roda.ro  Thu May 27 16:19:35 2004
From: adi at roda.ro (Adrian Dusa)
Date: Thu, 27 May 2004 17:19:35 +0300
Subject: [R] extract columns using their names
Message-ID: <000c01c443f5$af212510$6901a8c0@roda.local>

Hello,

Is there a way to extract multiple columns from a dataframe using their
names instead of their numbers?

Currently I use:

data2 <- data1[, c(1,3,9)]

And I am looking for something like

data2 <- data1[, c("XX","YY","ZZ")]


I use the same dataframe for many purposes, and I run codes that change
the order of the columns every time.

Many thanks,
Adrian

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Adrian Dusa (adi at roda.ro)
Romanian Social Data Archive (www.roda.ro)
1, Schitu Magureanu Bd.
050025 Bucharest sector 5
Romania
Tel./Fax: +40 (21) 312.66.18\ 
              +40 (21) 312.02.10/ int.101



From macq at llnl.gov  Thu May 27 16:20:56 2004
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 27 May 2004 07:20:56 -0700
Subject: [R] time
In-Reply-To: <200405262252480005.0039244C@mail.math.fu-berlin.de>
References: <47659.170.210.173.216.1085594421.squirrel@inter17.unsl.edu.ar>
	<200405262252480005.0039244C@mail.math.fu-berlin.de>
Message-ID: <p06002002bcdba72b4af2@[128.115.153.6]>

Here is another way, not necessarily better.

Since you didn't provide any column names, let 
df$tm refer to the column of times, which I will 
assume is a vector of character strings.

## as a one-liner, results in a character object 
(the '2004-5-1' is arbitrary, use any valid date)
minute <- format(as.POSIXct(paste('2004-5-1',df$tm,sep='-')),'%M')

## in multiple lines, making it possible to plot 
the data with an axis having an accurate time 
scale
tm <- as.POSIXct(paste('2004-5-1',df$tm,sep='-'))

## as above, minute is a character object
minute <- format(tm,'%M')

## or this way, minute is a POSIXt object, also 
suitable for use with a time-scaled plot
minute <- trunc(tm,'mins')

-Don

At 10:52 PM +0200 5/26/04, Wolski wrote:
>Hi!
>I would extract the minutes from the time using sub (see ?sub) or (?grep)
>than use them as factors (?as.factors)
>and finally
>?tapply
>
>eg.
>tt<-1:10
>  fac<-c(rep(0,4),rep(1,6)) # here put the minutes from the time
>fac
>  [1] 0 0 0 0 1 1 1 1 1 1
>fac<-as.factor(fac)
>fac
>  [1] 0 0 0 0 1 1 1 1 1 1
>Levels: 0 1
>
>tapply(t,fac,max)
>  0  1
>  4 10
>
>Sincerely Eryk.
>
>
>
>*********** REPLY SEPARATOR  ***********
>
>On 5/26/2004 at 3:00 PM solares at unsl.edu.ar wrote:
>
>>Hi, i need select data from data frame, for example:
>>x is a data frame with values in jump to 5 seconds
>>12:10:00 51 //one minute
>>12:10:05 63
>>12:10:10 75
>>12:10:15 88
>>..
>>12:10:59 45
>>12:11:00 46 //another minute
>>12:11:05 11
>>..
>>Have a command what to select the data minute to  minute, for example
>>in the example above i need the maximun values minute to  minute
>>1?? minute-->88
>>2?? minute--> 46
>>Thanks Ruben
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic  
>Ihnestrasse 63-73 14195 Berlin       'v'   
>tel: 0049-30-83875219               /   \   
>mail: wolski at molgen.mpg.de        ---W-W---- 
>http://www.molgen.mpg.de/~wolski
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From grimm.heinz at rcc.ch  Thu May 27 16:27:34 2004
From: grimm.heinz at rcc.ch (Heinz Grimm)
Date: Thu, 27 May 2004 16:27:34 +0200
Subject: [R] Using R in C++
Message-ID: <40B5FAD6.D1793FA2@rcc.ch>

>Hello,

Hi Jorgen,

>
>Is it possible to use R functions (in my case: ks.test()) from C++
>-applications? That is, I get the impression R can execute C/C++ code,
but
>is there any possibility to do the opposite? Where can I find help?

You can use R-(D)COM to call R functions from a C++ application.
R-(D)COM is a COM-server and comes with sample code, that
shows how to call R from Visual Basic (via the COM-server).
If you know, how to access COM objects from C++, you can
easily translate the Visual Basic Code to C++. You didn't mention,
which platform you are using, of course this works only for Windows.
You find R-(D)COM at http://cran.at.r-project.org/other-software.html
and the R-(D)COM mailing list at
http://mailman.csd.univie.ac.at/pipermail/rcom-l/

Heinz

>
>
>-------------------------------------------
Ph. D. J??rgen Wallerman
Swedish University of Agricultural Sciences
Remote Sensing Laboratory
S901 83 UME??

###########################################

This message has been scanned by F-Secure
Anti-Virus for Microsoft Exchange.

###########################################


This e-mail transmission contains confidential or legally privileged
information that is intended for the addressee(s) only. You are hereby
notified that any disclosure, copying, distribution or use of the
contents of this e-mail is strictly prohibited if you are not the
intended recipient. Please inform the sender and delete the message from
your system if you have received this e-mail transmission in error.
Thank you.



From lecoutre at stat.ucl.ac.be  Thu May 27 16:27:18 2004
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Thu, 27 May 2004 16:27:18 +0200
Subject: [R] extract columns using their names
In-Reply-To: <000c01c443f5$af212510$6901a8c0@roda.local>
References: <000c01c443f5$af212510$6901a8c0@roda.local>
Message-ID: <6.0.1.1.2.20040527162557.0220aec0@stat4ux.stat.ucl.ac.be>



Hello,

I dont clearly see why you have a problem... What you have to us works 
perfectly.

?? mat=diag(3)
?? colnames(mat)=letters[1:3]
?? mat
      a b c
[1,] 1 0 0
[2,] 0 1 0
[3,] 0 0 1
?? mat[,c("a","c")]
      a c
[1,] 1 0
[2,] 0 0
[3,] 0 1

Only condition is to have *set* the names if those columns. See 'colnames' 
or 'dimnames' for that.

Eric

At 16:19 27/05/2004, you wrote:
>Hello,
>Is there a way to extract multiple columns from a dataframe using their
>names instead of their numbers?
>Currently I use:
>data2 <- data1[, c(1,3,9)]
>And I am looking for something like
>data2 <- data1[, c("XX","YY","ZZ")]
>I use the same dataframe for many purposes, and I run codes that change
>the order of the columns every time.
>Many thanks,
>Adrian
>
>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>Adrian Dusa (adi at roda.ro)
>Romanian Social Data Archive (www.roda.ro)
>1, Schitu Magureanu Bd.
>050025 Bucharest sector 5
>Romania
>Tel./Fax: +40 (21) 312.66.18\
>               +40 (21) 312.02.10/ int.101
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Eric Lecoutre
UCL /  Institut de Statistique
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
Belgium

tel: (+32)(0)10473050
lecoutre at stat.ucl.ac.be
http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

If the statistics are boring, then you've got the wrong numbers. -Edward 
Tufte



From wolski at molgen.mpg.de  Thu May 27 16:28:51 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 27 May 2004 16:28:51 +0200
Subject: [R] extract columns using their names
In-Reply-To: <000c01c443f5$af212510$6901a8c0@roda.local>
References: <000c01c443f5$af212510$6901a8c0@roda.local>
Message-ID: <200405271628510279.01C80B99@mail.math.fu-berlin.de>

?subset

*********** REPLY SEPARATOR  ***********

On 5/27/2004 at 5:19 PM Adrian Dusa wrote:

>Hello,
>
>Is there a way to extract multiple columns from a dataframe using their
>names instead of their numbers?
>
>Currently I use:
>
>data2 <- data1[, c(1,3,9)]
>
>And I am looking for something like
>
>data2 <- data1[, c("XX","YY","ZZ")]
>
>
>I use the same dataframe for many purposes, and I run codes that change
>the order of the columns every time.
>
>Many thanks,
>Adrian
>
>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>Adrian Dusa (adi at roda.ro)
>Romanian Social Data Archive (www.roda.ro)
>1, Schitu Magureanu Bd.
>050025 Bucharest sector 5
>Romania
>Tel./Fax: +40 (21) 312.66.18\ 
>              +40 (21) 312.02.10/ int.101
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu May 27 16:28:59 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 27 May 2004 16:28:59 +0200
Subject: [R] extract columns using their names
References: <000c01c443f5$af212510$6901a8c0@roda.local>
Message-ID: <00b201c443f6$f410e420$ad133a86@www.domain>

Dear Adrian,

you could use something like:

x <- matrix(1:30,5,6)
colnames(x) <- letters[1:6]

your.choices <- c("a", "d", "f")
x[,match(your.choices, colnames(x))]

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Adrian Dusa" <adi at roda.ro>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, May 27, 2004 4:19 PM
Subject: [R] extract columns using their names


> Hello,
>
> Is there a way to extract multiple columns from a dataframe using
their
> names instead of their numbers?
>
> Currently I use:
>
> data2 <- data1[, c(1,3,9)]
>
> And I am looking for something like
>
> data2 <- data1[, c("XX","YY","ZZ")]
>
>
> I use the same dataframe for many purposes, and I run codes that
change
> the order of the columns every time.
>
> Many thanks,
> Adrian
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Adrian Dusa (adi at roda.ro)
> Romanian Social Data Archive (www.roda.ro)
> 1, Schitu Magureanu Bd.
> 050025 Bucharest sector 5
> Romania
> Tel./Fax: +40 (21) 312.66.18\
>               +40 (21) 312.02.10/ int.101
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From petr.pikal at precheza.cz  Thu May 27 16:32:35 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 27 May 2004 16:32:35 +0200
Subject: [R] extract columns using their names
In-Reply-To: <000c01c443f5$af212510$6901a8c0@roda.local>
Message-ID: <40B61823.5502.1E6D3AF@localhost>



On 27 May 2004 at 17:19, Adrian Dusa wrote:

> Hello,
> 
> Is there a way to extract multiple columns from a dataframe using
> their names instead of their numbers?
> 
> Currently I use:
> 
> data2 <- data1[, c(1,3,9)]
> 
> And I am looking for something like
> 
> data2 <- data1[, c("XX","YY","ZZ")]

Hi

Did you try it? Works on R 1.9.0 W2000

> data1<-data.frame(alfa=rnorm(10),beta=rnorm(10,5),gama=rnorm(10,.1))
> data1
          alfa     beta        gama
1  -0.68536013 5.310451  1.55570932
2  -0.43824815 4.998961  0.51348779
3  -1.20083111 4.585788  0.68135905
4  -0.07962607 6.443884  0.05560703
5  -0.03044263 5.355516 -0.16195279
6  -0.19878437 4.142789  0.07888565
7   1.90507619 4.691988  0.88832135
8  -0.51817154 4.844728 -0.80310925
9  -1.19614142 4.457188 -1.00103103
10  0.50957999 6.178542 -1.06628714
> data1[,c("alfa","gama")]
          alfa        gama
1  -0.68536013  1.55570932
2  -0.43824815  0.51348779
3  -1.20083111  0.68135905
4  -0.07962607  0.05560703
5  -0.03044263 -0.16195279
6  -0.19878437  0.07888565
7   1.90507619  0.88832135
8  -0.51817154 -0.80310925
9  -1.19614142 -1.00103103
10  0.50957999 -1.06628714

Cheers
Petr
> 
> 
> I use the same dataframe for many purposes, and I run codes that
> change the order of the columns every time.
> 
> Many thanks,
> Adrian
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Adrian Dusa (adi at roda.ro)
> Romanian Social Data Archive (www.roda.ro)
> 1, Schitu Magureanu Bd.
> 050025 Bucharest sector 5
> Romania
> Tel./Fax: +40 (21) 312.66.18\ 
>               +40 (21) 312.02.10/ int.101
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From adi at roda.ro  Thu May 27 16:35:49 2004
From: adi at roda.ro (Adrian Dusa)
Date: Thu, 27 May 2004 17:35:49 +0300
Subject: [R] extract columns using their names
In-Reply-To: <6.0.1.1.2.20040527162557.0220aec0@stat4ux.stat.ucl.ac.be>
Message-ID: <000d01c443f7$f737f840$6901a8c0@roda.local>

Right...

As was under the impression that, if I dind't attach the dataframe, I
have to use data1$XX, data1$YY and so on.
I tried
data2 <- data1[, c("data1$XX","data1$YY","data1$ZZ")]

I see my error now.

Thank you very much,
Adrian

-----Original Message-----
From: Eric Lecoutre [mailto:lecoutre at stat.ucl.ac.be] 
Sent: Thursday, May 27, 2004 5:27 PM
To: adi at roda.ro
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] extract columns using their names




Hello,

I dont clearly see why you have a problem... What you have to us works 
perfectly.

> mat=diag(3)
> colnames(mat)=letters[1:3]
> mat
      a b c
[1,] 1 0 0
[2,] 0 1 0
[3,] 0 0 1
> mat[,c("a","c")]
      a c
[1,] 1 0
[2,] 0 0
[3,] 0 1

Only condition is to have *set* the names if those columns. See
'colnames' 
or 'dimnames' for that.

Eric

At 16:19 27/05/2004, you wrote:
>Hello,
>Is there a way to extract multiple columns from a dataframe using their

>names instead of their numbers? Currently I use:
>data2 <- data1[, c(1,3,9)]
>And I am looking for something like
>data2 <- data1[, c("XX","YY","ZZ")]
>I use the same dataframe for many purposes, and I run codes that change
>the order of the columns every time.
>Many thanks,
>Adrian
>
>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>Adrian Dusa (adi at roda.ro)
>Romanian Social Data Archive (www.roda.ro)
>1, Schitu Magureanu Bd.
>050025 Bucharest sector 5
>Romania
>Tel./Fax: +40 (21) 312.66.18\
>               +40 (21) 312.02.10/ int.101
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list 
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html

Eric Lecoutre
UCL /  Institut de Statistique
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
Belgium

tel: (+32)(0)10473050
lecoutre at stat.ucl.ac.be http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

If the statistics are boring, then you've got the wrong numbers. -Edward

Tufte



From ernesto at ipimar.pt  Thu May 27 16:55:51 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu, 27 May 2004 15:55:51 +0100
Subject: [R] identation in Rd file, section "details"
Message-ID: <1085669750.4997.259.camel@gandalf.local>

Hi,

I want to describe an algoritm in the details section of an Rd file and
I'm having trouble to ident the different text rows. Can someone tell me
how I can ident text in Rd files ?

Thanks

EJ



From tlumley at u.washington.edu  Thu May 27 17:06:11 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 27 May 2004 08:06:11 -0700 (PDT)
Subject: [R] socketConnection and readLines
In-Reply-To: <BAY12-F957kTo0fKfFk00033fb1@hotmail.com>
References: <BAY12-F957kTo0fKfFk00033fb1@hotmail.com>
Message-ID: <Pine.A41.4.58.0405270805340.149074@homer04.u.washington.edu>

On Thu, 27 May 2004, Laura Holt wrote:

> Dear R People:
>
>
> I have tried the following code:
>
> >con <- socketConnection(port=13, host="tick.usno.navy.mil")
> >readLines(con)
>
>
> The socketConnection function works, but the readLines command just sits.

You want readLines(con, n=1)

	-thomas

> This has happened on R for Windows 1.8.1 and 1.9.0 and R on LINUX 1.8.1
>
> Any suggestions, please
>
>
> Thanks,
> Laura
> mailto: lauraholt_983 at hotmail.com
>
> _________________________________________________________________

>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From jfox at mcmaster.ca  Thu May 27 17:48:18 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 27 May 2004 11:48:18 -0400
Subject: [R] Getting the same values of adjusted mean and standarderrors
	as SAS
In-Reply-To: <20040527084449.4a035892.feh3k@spamcop.net>
Message-ID: <20040527154819.BZEU9492.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear David,

You might also take a look at the effects package, which can compute
"adjusted" means and a variety of other adjusted effects. 

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank 
> E Harrell Jr
> Sent: Thursday, May 27, 2004 1:45 AM
> To: David J. Netherway
> Cc: R-help at stat.math.ethz.ch
> Subject: Re: [R] Getting the same values of adjusted mean and 
> standarderrors as SAS
> 
> On Thu, 27 May 2004 16:34:58 +0930
> "David J. Netherway" <david.netherway at adelaide.edu.au> wrote:
> 
> > Hello,
> >  
> > I am trying to get the same values for the adjusted means 
> and standard 
> > errors using R that are given in SAS for the following 
> data. The model 
> > is Measurement ~ Age + Gender + Group. I can get the 
> adusted means at 
> > the mean age by using predict. I do not know how to get the 
> > appropriate standard errors at the adjusted means for Gender using 
> > values from predict. So I attempted to get them directly from the 
> > residuals as follows. The data is at the end of the email. 
> While there 
> > is a match for the males there is a large difference for 
> the females 
> > indicating that what I am doing is wrong.
> >  
> > #
> > meanAge <- mean(dd$Age)
> > meanAgeM <- mean(dd$Age[d$Gender=="M"]) meanAgeF <- 
> > mean(dd$Age[d$Gender=="F"])
> . . . .
> 
> By using sex-specific means of age you are not getting 
> adjusted estimates
> in the usual sense.
> 
> I prefer to think of effects as differences in predicted values rather
> than as complex SAS-like contrasts. The Design package's 
> contrast function
> makes this easy (including SEs and confidence limits):
> 
> library(Design)   # also requires Hmisc
> d <- datadist(dd); options(datadist='d')
> f <- ols(y ~ age + sex + group, data=dd)
> contrast(f, list(sex='M'), list(sex='F'))   # usual adjusted 
> difference M
> vs F
> contrast(f, list(sex='M',age=mean(dd$age[dd$sex=='M']),
>             list(sex='F',age=mean(dd$age[dd$sex=='F')) # M vs F not
> holding age constant
> 
> You can also experiment with specifying age=tapply(age, sex, mean,
> na.rm=TRUE) using some of the contrast.Design options.
> ---
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                      Department of Biostatistics   Vanderbilt 
> University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Thu May 27 17:50:52 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 27 May 2004 17:50:52 +0200
Subject: [R] "privileged slots"
In-Reply-To: <40B5E6BF.1090100@uni-bayreuth.de>
References: <40B5E6BF.1090100@uni-bayreuth.de>
Message-ID: <16566.3676.127996.996941@gargle.gargle.HOWL>

>>>>> "Matthias" == Matthias Kohl <Matthias.Kohl at uni-bayreuth.de>
>>>>>     on Thu, 27 May 2004 14:01:51 +0100 writes:

    Matthias> Hi all, in the help for RClassUtils I found the
    Matthias> expression "privileged slots" in function
    Matthias> "checkSlotAssignment" with the explanation:

    Matthias> /privileged slots (those that can only be set by
    Matthias> accesor functions defined along with the class
    Matthias> itself)/


RClassUtils ???

 > help.search("RClassUtils")

 No help files found with alias or concept or title matching
 'RClassUtils' using fuzzy matching.

-----

So I guess that's not something in a standard R document.
You should rather keep to the 'official documentation' ...

    Matthias> I thought all slots of a (not private) class can
    Matthias> be a accessed by a user via the @ Operator.  

I tend to agree with your thoughts...

    Matthias> Is there a way to make a single slot of a class (not
    Matthias> the whole class) private, so that you can access
    Matthias> this slot only via an accessor function (not via @)?

I'd rather guess not.

    Matthias> Thanks, for your help Matthias

Martin



From maechler at stat.math.ethz.ch  Thu May 27 18:18:16 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 27 May 2004 18:18:16 +0200
Subject: [R] indentation(?) in Rd file, section "details"
In-Reply-To: <1085669750.4997.259.camel@gandalf.local>
References: <1085669750.4997.259.camel@gandalf.local>
Message-ID: <16566.5320.314530.812207@gargle.gargle.HOWL>

>>>>> "Ernesto" == Ernesto Jardim <ernesto at ipimar.pt>
>>>>>     on Thu, 27 May 2004 15:55:51 +0100 writes:

    Ernesto> Hi, I want to describe an algoritm in the details
    Ernesto> section of an Rd file and I'm having trouble to
    Ernesto> ident the different text rows. Can someone tell me
    Ernesto> how I can ident text in Rd files ?

Do you mean "indent(ation)" (2nd letter = 'n') ?
If yes,
you might consider using
  \describe{ ........ } or \itemize{ .... }

You can find many examples in R's sources, or directly looking inside
the (large) file

    system.file("man/base.Rd")

look for '\name{DateTimeClasses}' and its \details{..} section

------

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ernesto at ipimar.pt  Thu May 27 18:38:33 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu, 27 May 2004 17:38:33 +0100
Subject: [R] indentation(?) in Rd file, section "details"
In-Reply-To: <16566.5320.314530.812207@gargle.gargle.HOWL>
References: <1085669750.4997.259.camel@gandalf.local>
	<16566.5320.314530.812207@gargle.gargle.HOWL>
Message-ID: <1085675913.4998.363.camel@gandalf.local>

On Thu, 2004-05-27 at 17:18, Martin Maechler wrote:
> >>>>> "Ernesto" == Ernesto Jardim <ernesto at ipimar.pt>
> >>>>>     on Thu, 27 May 2004 15:55:51 +0100 writes:
> 
>     Ernesto> Hi, I want to describe an algoritm in the details
>     Ernesto> section of an Rd file and I'm having trouble to
>     Ernesto> ident the different text rows. Can someone tell me
>     Ernesto> how I can ident text in Rd files ?
> 
> Do you mean "indent(ation)" (2nd letter = 'n') ?
> If yes,
> you might consider using
>   \describe{ ........ } or \itemize{ .... }
> 
> You can find many examples in R's sources, or directly looking inside
> the (large) file
> 
>     system.file("man/base.Rd")
> 
> look for '\name{DateTimeClasses}' and its \details{..} section
> 
> ------
> 
> Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
> ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
> phone: x-41-1-632-3408		fax: ...-1228			<><

Hi,

I want to do something like

step1
loop1
	step2
	loop2
		step3
	next2
next1
step4
step5 


I thought I could use \hspace{1cm} ...

The environments only use 1 level of identation, I think. I may be able
to do it with a table but I'd like to know if there's a better way.

Regards

EJ



From wolski at molgen.mpg.de  Thu May 27 19:12:10 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 27 May 2004 19:12:10 +0200
Subject: [R] "privileged slots",
In-Reply-To: <16566.3676.127996.996941@gargle.gargle.HOWL>
References: <40B5E6BF.1090100@uni-bayreuth.de>
	<16566.3676.127996.996941@gargle.gargle.HOWL>
Message-ID: <200405271912100128.025D8E16@mail.math.fu-berlin.de>

Hi!

Everyone knew that there are some more and less official documents.
And there are tons of things that are "more, more more and a little less". 
Thanks god that this time this "more and less" is so less that its not worthwhile to make fuss about.

But this document is quite intersting.

I have just two R questions which arised reading the document which a core members of the R-project cant find.
1. Is it intended to introduce privileged slots in the future version of R?
2. Is it true that one can gain execution speed by accessing slots using the function slots(object,name,check=FALSE)<-value
would speed up execution?

Sincerely
Eryk

*********** REPLY SEPARATOR  ***********

On 5/27/2004 at 5:50 PM Martin Maechler wrote:

>>>>>> "Matthias" == Matthias Kohl <Matthias.Kohl at uni-bayreuth.de>
>>>>>>     on Thu, 27 May 2004 14:01:51 +0100 writes:
>
>    Matthias> Hi all, in the help for RClassUtils I found the
>    Matthias> expression "privileged slots" in function
>    Matthias> "checkSlotAssignment" with the explanation:
>
>    Matthias> /privileged slots (those that can only be set by
>    Matthias> accesor functions defined along with the class
>    Matthias> itself)/
>
>
>RClassUtils ???
>
> > help.search("RClassUtils")
>
> No help files found with alias or concept or title matching
> 'RClassUtils' using fuzzy matching.
>
>-----
>
>So I guess that's not something in a standard R document.
>You should rather keep to the 'official documentation' ...
>
>    Matthias> I thought all slots of a (not private) class can
>    Matthias> be a accessed by a user via the @ Operator.  
>
>I tend to agree with your thoughts...
>
>    Matthias> Is there a way to make a single slot of a class (not
>    Matthias> the whole class) private, so that you can access
>    Matthias> this slot only via an accessor function (not via @)?
>
>I'd rather guess not.
>
>    Matthias> Thanks, for your help Matthias
>
>Martin
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From NBarrowman at cheo.on.ca  Thu May 27 20:10:09 2004
From: NBarrowman at cheo.on.ca (Barrowman, Nick)
Date: Thu, 27 May 2004 14:10:09 -0400
Subject: [R] axis.POSIXct: Datetime data and plotting
Message-ID: <E2AD017CFE22764998D37A6026B8A01D46B3C8@exchsrv1.cheo.int>

I've run into a problem with the datetime axis generated by axis.POSIXct.  It appears a similar issue was discussed in October 2003 under the subject line "datetime data and plotting" (see https://stat.ethz.ch/pipermail/r-help/2003-October/039071.html), but I wasn't able to determine whether there is a straightforward solution.

The code below produces a graph with apparently contradictory date labels on the top and bottom axes:

f <- "%Y/%m/%d"
d <- as.POSIXct(strptime(c("2003/1/15","2003/1/16",
  "2003/1/17","2003/1/18","2003/1/19"),format=f))
plot(d,1:length(d),axes=F);box()
axis(2)
abline(v=d[3])
axis.POSIXct(1,d,format=f)
axis.POSIXct(3,at=d,format=f)

On my copy of R (I have appended the version information below my signature), this produces a graph with a vertical line that lines up with "2003/01/17" on the top axis, but not on the bottom axis.

The issue seems to relate to time zones: here's what d looks like on my computer:

> d
[1] "2003-01-15 Eastern Standard Time"
[2] "2003-01-16 Eastern Standard Time"
[3] "2003-01-17 Eastern Standard Time"
[4] "2003-01-18 Eastern Standard Time"
[5] "2003-01-19 Eastern Standard Time"

(Actually I'm on Eastern Daylight Time, but let's ignore that for now.)

Changing the axes to display not only the date but also the time shows what's going on:

f <- "%Y/%m/%d"
f2 <- "%Y-%m-%d %H:%M"
d <- as.POSIXct(strptime(c("2003/1/15","2003/1/16",
  "2003/1/17","2003/1/18","2003/1/19"),format=f))
plot(d,1:length(d),axes=F);box()
axis(2)
abline(v=d[3])
axis.POSIXct(1,d,format=f2)
axis.POSIXct(3,at=d,format=f2)

The bottom axis put the ticks at 19:00 on each date.  This seems an odd time until you note that Eastern Standard Time is 5 hours behind UTC, so 19:00 EST is 00:00 UTC.

But is there any easy way to avoid this problem?  It is confusing and inconvenient that axis.POSIXct(1,d,format=f) and axis.POSIXct(3,at=d,format=f) give seemingly contradictory scales.

Many thanks for any help!

Nick Barrowman, Ph.D.
Chief Biostatistician, Chalmers Research Group
Children's Hospital of Eastern Ontario Research Institute
401 Smyth Road, Ottawa, Ontario, K1H 8L1, Canada
Tel   (613) 737-7600 ext. 3971
Fax   (613) 738-4800
Email nbarrowman at cheo.on.ca
URL   www.chalmersresearch.com


> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    9.0            
year     2004           
month    04             
day      12             
language R



From ryszard.czerminski at pharma.novartis.com  Thu May 27 20:11:26 2004
From: ryszard.czerminski at pharma.novartis.com (ryszard.czerminski@pharma.novartis.com)
Date: Thu, 27 May 2004 14:11:26 -0400
Subject: [R] R-1.9.0: Error in paste(ncomp,
 "LV's") : Argument "ncomp" is missing, with no default
Message-ID: <OF599BB652.5187B8C9-ON85256EA1.00638033-85256EA1.00641D2D@EU.novartis.net>

Is it just my installation or bug in 1.9.0 ?
The same thing works fine in 1.8.1

Best regards,

Ryszard

# R-1.9.0
library(pls.pcr)
nr <- 8; ndim <- 2
x <- matrix(rnorm(nr*ndim), nrow=nr)
y <- as.matrix(x[,1])
for (i in 2:ndim) y <- y + x[,i]
y <- y + rnorm(length(y))
m <- pls(x,y,validation='CV')
# Error in paste(ncomp, "LV's") : Argument "ncomp" is missing, with no 
default



From ggrothendieck at myway.com  Thu May 27 20:23:05 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 27 May 2004 18:23:05 +0000 (UTC)
Subject: [R] axis.POSIXct: Datetime data and plotting
References: <E2AD017CFE22764998D37A6026B8A01D46B3C8@exchsrv1.cheo.int>
Message-ID: <loom.20040527T202100-563@post.gmane.org>


Use the Date class rather than POSIXct since Date does not have
time zones in the first place:

d <- as.Date(c("2003/1/15","2003/1/16","2003/1/17","2003/1/18","2003/1/19"))
plot(d,1:length(d),axes=F);box()
axis(2)
abline(v=d[3])
axis.Date(1,d,format=f)
axis.Date(3,at=d,format=f)




Barrowman, Nick <NBarrowman <at> cheo.on.ca> writes:

: 
: I've run into a problem with the datetime axis generated by axis.POSIXct.  
It appears a similar issue was
: discussed in October 2003 under the subject line "datetime data and 
plotting" (see
: https://stat.ethz.ch/pipermail/r-help/2003-October/039071.html), but I 
wasn't able to determine
: whether there is a straightforward solution.
: 
: The code below produces a graph with apparently contradictory date labels on 
the top and bottom axes:
: 
: f <- "%Y/%m/%d"
: d <- as.POSIXct(strptime(c("2003/1/15","2003/1/16",
:   "2003/1/17","2003/1/18","2003/1/19"),format=f))
: plot(d,1:length(d),axes=F);box()
: axis(2)
: abline(v=d[3])
: axis.POSIXct(1,d,format=f)
: axis.POSIXct(3,at=d,format=f)
: 
: On my copy of R (I have appended the version information below my 
signature), this produces a graph with a
: vertical line that lines up with "2003/01/17" on the top axis, but not on 
the bottom axis.
: 
: The issue seems to relate to time zones: here's what d looks like on my 
computer:
: 
: > d
: [1] "2003-01-15 Eastern Standard Time"
: [2] "2003-01-16 Eastern Standard Time"
: [3] "2003-01-17 Eastern Standard Time"
: [4] "2003-01-18 Eastern Standard Time"
: [5] "2003-01-19 Eastern Standard Time"
: 
: (Actually I'm on Eastern Daylight Time, but let's ignore that for now.)
: 
: Changing the axes to display not only the date but also the time shows 
what's going on:
: 
: f <- "%Y/%m/%d"
: f2 <- "%Y-%m-%d %H:%M"
: d <- as.POSIXct(strptime(c("2003/1/15","2003/1/16",
:   "2003/1/17","2003/1/18","2003/1/19"),format=f))
: plot(d,1:length(d),axes=F);box()
: axis(2)
: abline(v=d[3])
: axis.POSIXct(1,d,format=f2)
: axis.POSIXct(3,at=d,format=f2)
: 
: The bottom axis put the ticks at 19:00 on each date.  This seems an odd time 
until you note that Eastern
: Standard Time is 5 hours behind UTC, so 19:00 EST is 00:00 UTC.
: 
: But is there any easy way to avoid this problem?  It is confusing and 
inconvenient that
: axis.POSIXct(1,d,format=f) and axis.POSIXct(3,at=d,format=f) give seemingly 
contradictory scales.
: 
: Many thanks for any help!
: 
: Nick Barrowman, Ph.D.
: Chief Biostatistician, Chalmers Research Group
: Children's Hospital of Eastern Ontario Research Institute
: 401 Smyth Road, Ottawa, Ontario, K1H 8L1, Canada
: Tel   (613) 737-7600 ext. 3971
: Fax   (613) 738-4800
: Email nbarrowman <at> cheo.on.ca
: URL   www.chalmersresearch.com
: 
: > version
:          _              
: platform i386-pc-mingw32
: arch     i386           
: os       mingw32        
: system   i386, mingw32  
: status                  
: major    1              
: minor    9.0            
: year     2004           
: month    04             
: day      12             
: language R
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From ligges at statistik.uni-dortmund.de  Thu May 27 20:31:21 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 27 May 2004 20:31:21 +0200
Subject: [R] R-1.9.0: Error in paste(ncomp, "LV's") : Argument "ncomp"
	is missing, with no default
In-Reply-To: <OF599BB652.5187B8C9-ON85256EA1.00638033-85256EA1.00641D2D@EU.novartis.net>
References: <OF599BB652.5187B8C9-ON85256EA1.00638033-85256EA1.00641D2D@EU.novartis.net>
Message-ID: <40B633F9.5080508@statistik.uni-dortmund.de>

ryszard.czerminski at pharma.novartis.com wrote:
> Is it just my installation or bug in 1.9.0 ?
> The same thing works fine in 1.8.1
> 
> Best regards,
> 
> Ryszard
> 
> # R-1.9.0
> library(pls.pcr)
> nr <- 8; ndim <- 2
> x <- matrix(rnorm(nr*ndim), nrow=nr)
> y <- as.matrix(x[,1])
> for (i in 2:ndim) y <- y + x[,i]
> y <- y + rnorm(length(y))
> m <- pls(x,y,validation='CV')
> # Error in paste(ncomp, "LV's") : Argument "ncomp" is missing, with no 
> default
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


That's a bug in the recent version of the package "pls.pcr" (and not 
related to the R version). Please report it to the package maintainer.

Uwe Ligges



From sorenh at agrsci.dk  Thu May 27 20:39:33 2004
From: sorenh at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Thu, 27 May 2004 20:39:33 +0200
Subject: [R] Crossed random effects in lme
Message-ID: <005d01c44419$f9e5e1c0$8276f9c3@djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040527/39d5e7a1/attachment.pl

From rn001 at cebas.csic.es  Thu May 27 20:59:20 2004
From: rn001 at cebas.csic.es (javier garcia - CEBAS)
Date: Thu, 27 May 2004 20:59:20 +0200
Subject: [R] identify() - image()
In-Reply-To: <40B4D69A.80600@lancaster.ac.uk>
References: <200405261722.i4QHMnp18928@natura.cebas.csic.es>
	<40B4D69A.80600@lancaster.ac.uk>
Message-ID: <200405271858.i4RIwhp13329@natura.cebas.csic.es>

Thanks Barry (and Thomas),

I wanted it to extract information from imported maps from the GIS GRASS, 
with a few modifications the functions works also very well for this.

Best regards,

Javier
-----------
El Mi?? 26 May 2004 19:40, Barry Rowlingson escribi??:
> javier garcia - CEBAS wrote:
> > Hi all;
> > Just to ask if you know about any available function in R to identify
> > points in a image plotted in X11. Something like the function identify(),
> > but able to extract (x,y,value) groups from the image.
>
>   this is what I use:
>
> image.identify <- function(xyz, mark=T, digits=3){
>
>    nx <- length(xyz$x) - 1
>    ny <- length(xyz$y) - 1
>    if(!all(dim(xyz$z)==c(nx,ny))){
>      stop("Really need image specified by cell edges")
>    }
>    res <- data.frame()
>    xy <- locator(1)
>    while(!is.null(xy)){
>      xbin <- as.numeric(cut(xy$x,xyz$x))
>      ybin <- as.numeric(cut(xy$y,xyz$y))
>      if(mark){
>        points(xy$x,xy$y,pch=19,cex=.5,col="blue")
>
> text(xy$x,xy$y,format(xyz$z[xbin,ybin],digits=digits),adj=-.2,col="blue")
>      }
>      cat("[",xbin,",",ybin,"] = ",xyz$z[xbin,ybin],"\n",sep='')
>      res <-
> rbind(res,data.frame(i=xbin,j=ybin,x=xy$x,y=xy$y,z=xyz$z[xbin,ybin]))
>      xy <- locator(1)
>    }
>    res
> }
>
> Try:
>   > m=list(x=1:11,y=1:11,z=matrix(runif(100),10,10))
>   > image(m)
>   > identify.image(m)
>
>   then click some things. Button 2 to finish.
>
>   The returned data frame gives row and column in the 'z' matrix, x and
> y coordinates, and value of the z matrix at that point.
>
>   Baz



From martin.klaffenboeck at inode.at  Thu May 27 21:15:48 2004
From: martin.klaffenboeck at inode.at (Martin Klaffenboeck)
Date: Thu, 27 May 2004 21:15:48 +0200
Subject: [R] English or German?
Message-ID: <20040527191548.GC4890@martin.kleinerdrache.org>

Hello,

My first question is:  Is this english or german?

I will ask in english here, but if this list is a german list, feel  
free to answer me in german, (my mothers language is german).

I have a few questions.  Please answer me.

Martin



From mail at svenhartenstein.de  Thu May 27 21:33:13 2004
From: mail at svenhartenstein.de (Sven Hartenstein)
Date: Thu, 27 May 2004 21:33:13 +0200
Subject: [R] English or German?
In-Reply-To: <20040527191548.GC4890@martin.kleinerdrache.org> (Martin
	Klaffenboeck's message of "Thu, 27 May 2004 21:15:48 +0200")
References: <20040527191548.GC4890@martin.kleinerdrache.org>
Message-ID: <87brk9br7q.fsf@svenhartenstein.de>

Hello Martin, 

> My first question is:  Is this english or german?

The list is in english.

Viele Gr????e, 

Sven



From sasprog474 at yahoo.com  Thu May 27 21:53:46 2004
From: sasprog474 at yahoo.com (Greg Tarpinian)
Date: Thu, 27 May 2004 12:53:46 -0700 (PDT)
Subject: [R] SCO & R
Message-ID: <20040527195346.64802.qmail@web41402.mail.yahoo.com>

I apologize if this has been addressed before;
recently
I read an article in Forbes which discussed how SCO
was going after companies that have been using Linux.
The article made the point that the ideas behind GPL
are under attack precisely because no one is making
sure
that the code being put into the freely avail.
packages
isn't owned by someone else.

Here's my question:  Is R vulnerable in any way to the
sorts of lawsuits that SCO is bringing against the
Linux community?

Thanks in advance,

    Greg


	
		
__________________________________




From martin.klaffenboeck at inode.at  Thu May 27 21:58:47 2004
From: martin.klaffenboeck at inode.at (Martin Klaffenboeck)
Date: Thu, 27 May 2004 21:58:47 +0200
Subject: [R] Sorting Data?
Message-ID: <20040527195847.GE4890@martin.kleinerdrache.org>

Hello,

Im reading through some manuals, but I cannot find my answer.

I have a file containing many data:

Vpn	Code	Family	Age	F1	F2	...	F17
1	1	M	46	1	2	...	1
2	1	D	18	3	2	...	4
3	2	M	50	3	3	...	3
...
and so on.

Now I can read it by:

F = read.table("file", header=T)

but now I want to seperate the mothers (M) and daugthers (D) of the  
family with all the data in all other fields.  How can I do that?

The 'Code' Tells me which mother belongs to which dougther.  I want to  
make a matrix where I have the mothers on one and the daugthers on the  
other axis and compair the distance of every question (F1...F17) and  
the distance of the sum of this questions.  The questions are semantic  
differencials, 5 values.  F4, and F7 must have reverse polarity in this  
case.

Hm.  How do I have to do now?

Thanks,
Martin



From clists at perrin.socsci.unc.edu  Thu May 27 22:00:22 2004
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Thu, 27 May 2004 16:00:22 -0400 (EDT)
Subject: [R] SCO & R
In-Reply-To: <20040527195346.64802.qmail@web41402.mail.yahoo.com>
References: <20040527195346.64802.qmail@web41402.mail.yahoo.com>
Message-ID: <Pine.LNX.4.53.0405271600060.13365@perrin.socsci.unc.edu>

On Thu, 27 May 2004, Greg Tarpinian wrote:

> I apologize if this has been addressed before;
> recently
> I read an article in Forbes which discussed how SCO
> was going after companies that have been using Linux.
> The article made the point that the ideas behind GPL
> are under attack precisely because no one is making
> sure
> that the code being put into the freely avail.
> packages
> isn't owned by someone else.
>
> Here's my question:  Is R vulnerable in any way to the
> sorts of lawsuits that SCO is bringing against the
> Linux community?

No - and neither is anybody else.

http://opensource.org/sco-vs-ibm.html#ftn.id2756929


----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu



From howardjp at vocito.com  Thu May 27 22:04:06 2004
From: howardjp at vocito.com (James P. Howard, II)
Date: Thu, 27 May 2004 16:04:06 -0400
Subject: [R] SCO & R 
In-Reply-To: <20040527195346.64802.qmail@web41402.mail.yahoo.com> 
References: <20040527195346.64802.qmail@web41402.mail.yahoo.com>
Message-ID: <200405272004.i4RK46TM019859@foxxy.triohost.com>


On 27 May 2004 at 12:53, Greg Tarpinian <sasprog474 at yahoo.com> wrote:

> Here's my question:  Is R vulnerable in any way to the
> sorts of lawsuits that SCO is bringing against the
> Linux community?

Everyone is vulnerable at all times to the threat of lawsuits.  I
could sue right now for asking too long a question.  The important
question is, would I be likely to win?  And until that question is
answered in the SCO/Linux case, it is difficult to answer that
question about anything else.

James

--
James P. Howard, II  --  howardjp at vocito.com
http://www.jameshoward.us/  --  202-390-4933



From mfowle at navicominc.com  Thu May 27 22:10:44 2004
From: mfowle at navicominc.com (Mark Fowle)
Date: Thu, 27 May 2004 16:10:44 -0400
Subject: [R] SCO & R
Message-ID: <00B717603414D21187AD00104B94A2DAB23B6E@EXCHANGE>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040527/6f146045/attachment.pl

From p.gamble at zeria.com  Thu May 27 22:09:00 2004
From: p.gamble at zeria.com (Patrick Gamble)
Date: Thu, 27 May 2004 21:09:00 +0100
Subject: [R] SCO and R
Message-ID: <000c01c44426$73674410$2201a8c0@home46b07kcgr8>

>The article made the point that the ideas behind GPL
> are under attack precisely because no one is making
> sure that the code being put into the freely available
> packages isn't owned by someone else.

Shouldn't that be rephrased?

How about

'can't be sure that a bunch of unprincipled people won't attempt 
to use the law to grab money on the basis of very, very dubious 
patents'?



From tlumley at u.washington.edu  Thu May 27 22:11:56 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 27 May 2004 13:11:56 -0700 (PDT)
Subject: [R] SCO & R
In-Reply-To: <00B717603414D21187AD00104B94A2DAB23B6E@EXCHANGE>
References: <00B717603414D21187AD00104B94A2DAB23B6E@EXCHANGE>
Message-ID: <Pine.A41.4.58.0405271308150.89532@homer05.u.washington.edu>

On Thu, 27 May 2004, Mark Fowle wrote:

> I'm a bit over my head hear, but my understanding is that R is a derivative
> of S and is fully endorsed by the S group(I can not find any references at
> the moment, but I believe that there is information on this somewhere with
> in the R web site).

No, this is not at all the case.  R is not a derivative of S, it is an
independent implementation of the published descriptions of S (with some
differences).

	-thomas



From baron at psych.upenn.edu  Thu May 27 22:43:02 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 27 May 2004 16:43:02 -0400
Subject: [R] Sorting Data?
In-Reply-To: <20040527195847.GE4890@martin.kleinerdrache.org>
References: <20040527195847.GE4890@martin.kleinerdrache.org>
Message-ID: <20040527204302.GA7557@psych>

On 05/27/04 21:58, Martin Klaffenboeck wrote:
>Hello,
>
>Im reading through some manuals, but I cannot find my answer.
>
>I have a file containing many data:
>
>Vpn	Code	Family	Age	F1	F2	...	F17
>1	1	M	46	1	2	...	1
>2	1	D	18	3	2	...	4
>3	2	M	50	3	3	...	3
>...
>and so on.
>
>Now I can read it by:
>
>F = read.table("file", header=T)
>
>but now I want to seperate the mothers (M) and daugthers (D) of the
>family with all the data in all other fields.  How can I do that?
>
>The 'Code' Tells me which mother belongs to which dougther.  I want to
>make a matrix where I have the mothers on one and the daugthers on the
>other axis and compair the distance of every question (F1...F17) and
>the distance of the sum of this questions.  The questions are semantic
>differencials, 5 values.  F4, and F7 must have reverse polarity in this
>case.

The following is not tested and probably contains at least one error.

Lets assume that there is one mother per daughter and one
daughter per mother, and your file is Myfile, and the Codes are
in order.  One way is this:

Myfile$F4 <- -Myfile$F4 # reverse polarity
Myfile$F7 <- -Myfile$F7

Mothers <- Myfile[Family="M",]
Daughters <- Myfile[Family="D",]

Itemdiffs <- Mothers[,-(1:4)]-Daughters[,-(1:4)] # the -(1:4)
                                                 # removes cols 1:4
or
Itemdiffs <- (Mothers-Daughters)[,-(1:4)]
or
Itemdiffs <- abs(Mothers[,-(1:4)]-Daughters[,-(1:4)])
or maybe
Itemdiffs <- rowMeans(abs(Mothers[,-(1:4)]-Daughters[,-(1:4)]))

and for the difference of the sums

Sumdiffs <- rowMeans(Mothers[,-(1:4)]-Daughters[,-(1:4)])

If my assumptions are wrong, then more work is needed.  You might
have to sort by Code, e.g.,

Myfile <- Myfile[sort(Myfile$Code),]

And you might have to match by Code, assuming each daughter has
one mother but one mother can have 2 daughters.  Here is a VERY
CRUDE way (which may not work):

Itemdiff <- matrix(NA,nrow(Daughter),NUMBER OF ITEMS) # fill this in
for (i in 1:nrow(Daughter))
 {Itemdiff[i,] <- Daughter[i,]-Mother[Mother$Code==Daughter[i,Code]}

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R search page:        http://finzi.psych.upenn.edu/



From youngas7 at yahoo.com  Thu May 27 22:44:48 2004
From: youngas7 at yahoo.com (Andrew Young)
Date: Thu, 27 May 2004 13:44:48 -0700 (PDT)
Subject: [R] blocking question with socketConnections
Message-ID: <20040527204448.45349.qmail@web61009.mail.yahoo.com>

I am writing a function to make a multi-part form
request with binary data.  I am running R 1.8.1 on
Linux ReadHat.

The sockectConnection is initialized with open="a+b"
and blocking=TRUE.

After writing the Post request using writeChar and
writeBin and flushing the connection I use
socketSelect to check if the socketConnection is
availabe for reading.  This call consistently takes 15
seconds or so (15.01 seconds; checked using
system.time).  After this the response is read using
readChar no problem.

However, when I perform the same operation using an
HTML form the whole operation takes approximately one
second.  I get the impression this has something to do
with blocking or something?  Is there a way to get
around blocking easily?  I tried initializing the
socketConnection with blocking=FALSE and creating a
loop that waits for selectSocket to return TRUE for
the connection in question, but this also takes about
15 seconds...

Why is this?  Is there anyway around this?

Any help is greatly appreciated.

-Andrew Young
youngas7 at yahoo.com
http://www.rho-project.org



	
		
__________________________________



From baron at psych.upenn.edu  Thu May 27 22:46:03 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 27 May 2004 16:46:03 -0400
Subject: [R] Sorting Data?
In-Reply-To: <20040527204302.GA7557@psych>
References: <20040527195847.GE4890@martin.kleinerdrache.org>
	<20040527204302.GA7557@psych>
Message-ID: <20040527204603.GA15208@psych>

OK. Maybe 2 errors.  I already found one:

On 05/27/04 16:43, Jonathan Baron wrote:
>Sumdiffs <- rowMeans(Mothers[,-(1:4)]-Daughters[,-(1:4)])

should be

Sumdiffs <- rowMeans(Mothers[,-(1:4)])-rowMeans(Daughters[,-(1:4)])



From Torsten.Steuernagel at gmx.de  Thu May 27 22:55:20 2004
From: Torsten.Steuernagel at gmx.de (Torsten Steuernagel)
Date: Thu, 27 May 2004 22:55:20 +0200
Subject: [R] "privileged slots",
In-Reply-To: <200405271912100128.025D8E16@mail.math.fu-berlin.de>
References: <16566.3676.127996.996941@gargle.gargle.HOWL>
Message-ID: <40B671D8.20218.25D99F1@localhost>

On 27 May 2004 at 19:12, Wolski wrote:

> But this document is quite intersting.

Which document are you refering to ?
 
> I have just two R questions which arised reading the document which a
> core members of the R-project cant find. 

I can't find it either.

> 1. Is it intended to introduce privileged slots in the future version of
> R?

You are talking about access control like C++ (private, protected, 
public) has, aren't you ? I can't answer for the R Core Team but I'm 
also interested in a similar functionality. Please check the setClass() 
docs for the "access" argument. I suppose this is intended to provide 
such functionality in the future.
 
> 2. Is it true
> that one can gain execution speed by accessing slots using the
> function slots(object,name,check=FALSE)<-value would speed up
> execution?

Try this:

> get("@<-")
function (object, name, value) 
{
    arg <- substitute(name)
    if (is.name(arg)) 
        name <- as.character(arg)
    "slot<-"(object, name, TRUE, value)
}

So "@<-" actually calls "slot<-". Using "slot<-" instead, you save the 
additional overhead the call to "@<-" introduces. If there will be a real 
performance gain in replacing "@<-" certainly depends on what you're 
doing.

- Torsten



From joseclaudio.faria at terra.com.br  Thu May 27 23:40:14 2004
From: joseclaudio.faria at terra.com.br (joseclaudio.faria)
Date: Thu, 27 May 2004 18:40:14 -0300
Subject: [R] ANOVA and contrasts
Message-ID: <00ed01c44433$363af1b0$01fea8c0@sapetinga>

Dears members of R list,

I would like that a more experienced R user help me to complete
this analysis:

r = gl(3, 8, label = c('r1', 'r2', 'r3'))
e = rep(gl(2, 4, label = c('e1', 'e2')), 3)
y = c(26.2, 26.0, 25.0, 25.4, 24.8, 24.6, 26.7, 25.2, 25.7, 26.3, 25.1, 26.4,
         19.6, 21.1, 19.0, 18.6, 22.8, 19.4, 18.8, 19.2, 19.8, 21.4, 22.8, 21.3)

df = data.frame(r, e, y)
attach(df)
  par(mfrow=c(2,1))
  interaction.plot(r, e, y, col = 'blue', ylab = 'y', xlab = 'r')

  interaction.plot(e, r, y, col = 'blue', ylab = 'y', xlab = 'r')
  av1 = aov(y ~ r*e)

  av2 = aov(y ~ r/e)
  efR_E = summary(av2, split = list('r:e' = list('e1 vs e2/r1' = 1, 'e1 vs
e2/r2' = 2, 'e1 vs e2/r3' = 3)))

  av3  = aov(y ~ e/r)
  efE_R = summary(av3, split = list('e:r' = list('r/e1' = c(1,3), 'r/e2' =
c(2,4))))

# ------------------------------Begin the problem-------------------------
#
# I woud like to compare r/e1 (SS = 87.122 with 2 GL) like this:
# r1 vs (r2,r3 ) / e1
# r2 vs r3 / e1


# And compare r/e2 (SS = 69.500 with 2 GL) like this:
# r1 vs (r2,r3 ) / e2
# r2 vs r3 / r1 / e2

#
# ------------------------------End the problem----------------------------

  mds = model.tables(av1, ty = 'means')
detach(df)

cat('\nData:'); cat('\n')
print(df)

cat('\nMeans:'); cat('\n')
print(mds)

cat('\nANOVA:'); cat('\n')
print(summary(av1)); cat('\n')

cat('\nANOVA - E effect in R levels:'); cat('\n')
print(efR_E); cat('\n')

cat('\nANOVA - R effect in E levels:'); cat('\n')
print(efE_R); cat('\n')

Best regards,

Sauda????es,

Jos?? Cl??udio Faria
UESC/DCET
Brasil
73-634.2779
joseclaudio.faria at terra.com.br
jc_faria at uol.com.br



From jasont at indigoindustrial.co.nz  Fri May 28 00:18:26 2004
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Fri, 28 May 2004 10:18:26 +1200
Subject: [R] SCO & R
In-Reply-To: <20040527195346.64802.qmail@web41402.mail.yahoo.com>
References: <20040527195346.64802.qmail@web41402.mail.yahoo.com>
Message-ID: <20040527221826.GA3526@kryten.akl.indigoindustrial.co.nz>

On Thu, May 27, 2004 at 12:53:46PM -0700, Greg Tarpinian wrote:
...
> recently
> I read an article in Forbes which discussed how SCO
> was going after companies that have been using Linux.

It couldn't have been that recent; SCO dropped the most Linux-
relevant portions of its lawsuit back in January.

http://www.groklaw.net/article.php?story=20040206175445975

Further, SCO is under investigation for racketeering in 
Australia.  The "pay us money, because we own Unix" letters 
may be a form of illegal shakedown in Oz.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From jeff.hamann at forestinformatics.com  Fri May 28 00:24:40 2004
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Thu, 27 May 2004 15:24:40 -0700 (PDT)
Subject: [R] no transparent background in bmp
Message-ID: <3163.67.171.204.151.1085696680.squirrel@www.forestinformatics.com>

I've been attempting to export a graphics file of my lattice plots and no
matter what color I use for the bg= argument in the bmp/jpeg/png function,
the background is grey.

bmp(filename = "c:/my_paper/resids.bmp", width=1024, height=1024,
pointsize=10, bg="transparent")

# these are lattice plots. plot them in a 3x2 matrix
print( hgqqplot, position=c(0.0, 0.66, 0.5, 1.0 ), more=TRUE )
print( hgplot, position=c(0.5, 0.66, 1.0, 1.0 ), more=TRUE )
print( dgqqplot, position=c(0.0, 0.33, 0.5, 0.66 ), more=TRUE )
print( dgplot, position=c(0.5, 0.33, 1.0, 0.66 ), more=TRUE )
print( cwgqqplot, position=c(0.0, 0.0, 0.5, 0.33 ), more=TRUE )
print( cwgplot, position=c(0.5, 0.0, 1.0, 0.33 ), more=FALSE )

dev.off()

I've tried white, no argument at all, transparent, etc. and all yield the
same results. Is this broken, or am I not using the function correctly.

Thanks,
Jeff.


-- 
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon 97339-1421
phone 541-754-1428
jeff.hamann at forestinformatics.com
http://www.forestinformatics.com



From gerifalte28 at hotmail.com  Fri May 28 00:34:30 2004
From: gerifalte28 at hotmail.com (F Z)
Date: Thu, 27 May 2004 22:34:30 +0000
Subject: [R] ANOVA and contrasts
Message-ID: <BAY99-F39yEXUIEAOeI0001e59b@hotmail.com>

Oi Claudio

Check ?contrasts ?C or to create your custom contrasts to then be used in 
your model

i.e.

>MyContrast<-matrix(c(1,1,0,1,0,0),ncol=2)
>MyContrast
     [,1] [,2]
[1,]    1    1
[2,]    1    0
[3,]    0    0
>data(iris)
>attach(iris)
>contrasts(Species)
           versicolor virginica
setosa              0         0
versicolor          1         0
virginica           0         1
>contrasts(Species)<-MyContrast
>contrasts(Species)
           [,1] [,2]
setosa        1    1
versicolor    1    0
virginica     0    0

I hope that this helps

Francisco



>From: "joseclaudio.faria" <joseclaudio.faria at terra.com.br>
>To: R - Grupo de discusso R <r-help at stat.math.ethz.ch>
>Subject: [R] ANOVA and contrasts
>Date: Thu, 27 May 2004 18:40:14 -0300
>
>Dears members of R list,
>
>I would like that a more experienced R user help me to complete
>this analysis:
>
>r = gl(3, 8, label = c('r1', 'r2', 'r3'))
>e = rep(gl(2, 4, label = c('e1', 'e2')), 3)
>y = c(26.2, 26.0, 25.0, 25.4, 24.8, 24.6, 26.7, 25.2, 25.7, 26.3, 25.1, 
>26.4,
>          19.6, 21.1, 19.0, 18.6, 22.8, 19.4, 18.8, 19.2, 19.8, 21.4, 22.8, 
>21.3)
>
>df = data.frame(r, e, y)
>attach(df)
>   par(mfrow=c(2,1))
>   interaction.plot(r, e, y, col = 'blue', ylab = 'y', xlab = 'r')
>
>   interaction.plot(e, r, y, col = 'blue', ylab = 'y', xlab = 'r')
>   av1 = aov(y ~ r*e)
>
>   av2 = aov(y ~ r/e)
>   efR_E = summary(av2, split = list('r:e' = list('e1 vs e2/r1' = 1, 'e1 vs
>e2/r2' = 2, 'e1 vs e2/r3' = 3)))
>
>   av3  = aov(y ~ e/r)
>   efE_R = summary(av3, split = list('e:r' = list('r/e1' = c(1,3), 'r/e2' =
>c(2,4))))
>
># ------------------------------Begin the problem-------------------------
>#
># I woud like to compare r/e1 (SS = 87.122 with 2 GL) like this:
># r1 vs (r2,r3 ) / e1
># r2 vs r3 / e1
>
>
># And compare r/e2 (SS = 69.500 with 2 GL) like this:
># r1 vs (r2,r3 ) / e2
># r2 vs r3 / r1 / e2
>
>#
># ------------------------------End the problem----------------------------
>
>   mds = model.tables(av1, ty = 'means')
>detach(df)
>
>cat('\nData:'); cat('\n')
>print(df)
>
>cat('\nMeans:'); cat('\n')
>print(mds)
>
>cat('\nANOVA:'); cat('\n')
>print(summary(av1)); cat('\n')
>
>cat('\nANOVA - E effect in R levels:'); cat('\n')
>print(efR_E); cat('\n')
>
>cat('\nANOVA - R effect in E levels:'); cat('\n')
>print(efE_R); cat('\n')
>
>Best regards,
>
>Saudaes,
>
>Jos Cludio Faria
>UESC/DCET
>Brasil
>73-634.2779
>joseclaudio.faria at terra.com.br
>jc_faria at uol.com.br
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html

_________________________________________________________________

http://toolbar.msn.click-url.com/go/onm00200415ave/direct/01/



From vasileios_p at yahoo.gr  Fri May 28 00:44:03 2004
From: vasileios_p at yahoo.gr (=?iso-8859-7?q?vasilis=20pappas?=)
Date: Thu, 27 May 2004 23:44:03 +0100 (BST)
Subject: [R] Different results
Message-ID: <20040527224403.27841.qmail@web12908.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040527/02558bb3/attachment.pl

From d.scott at auckland.ac.nz  Fri May 28 00:53:01 2004
From: d.scott at auckland.ac.nz (David Scott)
Date: Fri, 28 May 2004 10:53:01 +1200 (NZST)
Subject: [R] Different results
In-Reply-To: <20040527224403.27841.qmail@web12908.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0405281050210.7528-100000@hydra.stat.auckland.ac.nz>

On Thu, 27 May 2004, [iso-8859-7] vasilis pappas wrote:

> Hello everybody,
>    I've been practicing with some data in R and SPSS and I noticed that there are some differences in ANOVA results.
>  
> For example with :
> y<-c(1,2,34,2,3,45,2,1,67,3,2,67,2,2,98,4,4,23,1,1,23,2,3,45) and
> x<-rep(c(1,2,3),8)
>  
>    I get in R ( with summary(aov(y~x)) )
> MSres=350.7
> df=22
>  
>    while in SPSS I get
> MSres=221.9
> df=21
>  
> Can enyone explain me what is the problem or what am I doing wrong?

If you want to do a traditional one-way anova, you have to declare x
to be a factor:

> y<-c(1,2,34,2,3,45,2,1,67,3,2,67,2,2,98,4,4,23,1,1,23,2,3,45)
> x<-rep(c(1,2,3),8)
> summary(aov(y~x))
            Df Sum Sq Mean Sq F value    Pr(>F)    
x            1 9264.1  9264.1  26.414 3.761e-05 ***
Residuals   22 7715.9   350.7                      
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> xf<-as.factor(x)
> summary(aov(y~xf))
            Df  Sum Sq Mean Sq F value    Pr(>F)    
xf           2 12320.1  6160.0  27.761 1.269e-06 ***
Residuals   21  4659.9   221.9                      
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 


Notice that when x is not a factor there is only one degree of freedom for 
x.

David Scott






_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
		The University of Auckland, PB 92019
		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz 


Graduate Officer, Department of Statistics



From gunter.berton at gene.com  Fri May 28 00:54:38 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 27 May 2004 15:54:38 -0700
Subject: [R] Different results
References: <20040527224403.27841.qmail@web12908.mail.yahoo.com>
Message-ID: <40B671AE.60D63B27@gene.com>

x is numeric, so R consider this to be a linear regression, not a 3 group analysis. To do the latter in R:

x<-factor(1:3)

Read the R Introductory manuals or the first few and other relevant chapters Venables' and Ripley's MASS first, please!

-- Bert Gunter

vasilis pappas wrote:

> Hello everybody,
>    I've been practicing with some data in R and SPSS and I noticed that there are some differences in ANOVA results.
>
> For example with :
> y<-c(1,2,34,2,3,45,2,1,67,3,2,67,2,2,98,4,4,23,1,1,23,2,3,45) and
> x<-rep(c(1,2,3),8)
>
>    I get in R ( with summary(aov(y~x)) )
> MSres=350.7
> df=22
>
>    while in SPSS I get
> MSres=221.9
> df=21
>
> Can enyone explain me what is the problem or what am I doing wrong?
>                          Thanks for your interest a priori,
>                                                                        Vasileios.
>
> ---------------------------------
>
> ????????????????? ?????? ???????????? ??????@yahoo.gr
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

--

Bert Gunter

Non-Clinical Biostatistics
Genentech
MS: 240B
Phone: 650-467-7374


"The business of the statistician is to catalyze the scientific learning process."

 -- George E.P. Box



From p.dalgaard at biostat.ku.dk  Fri May 28 00:49:30 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 May 2004 00:49:30 +0200
Subject: [R] Different results
In-Reply-To: <20040527224403.27841.qmail@web12908.mail.yahoo.com>
References: <20040527224403.27841.qmail@web12908.mail.yahoo.com>
Message-ID: <x265ah5vut.fsf@biostat.ku.dk>

vasilis pappas <vasileios_p at yahoo.gr> writes:

> Hello everybody,
>    I've been practicing with some data in R and SPSS and I noticed that there are some differences in ANOVA results.
>  
> For example with :
> y<-c(1,2,34,2,3,45,2,1,67,3,2,67,2,2,98,4,4,23,1,1,23,2,3,45) and
> x<-rep(c(1,2,3),8)
>  
>    I get in R ( with summary(aov(y~x)) )
> MSres=350.7
> df=22
>  
>    while in SPSS I get
> MSres=221.9
> df=21
>  
> Can enyone explain me what is the problem or what am I doing wrong?

You need  x <- factor(x) , I guess.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From sundar.dorai-raj at PDF.COM  Fri May 28 00:56:07 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Thu, 27 May 2004 17:56:07 -0500
Subject: [R] no transparent background in bmp
In-Reply-To: <3163.67.171.204.151.1085696680.squirrel@www.forestinformatics.com>
References: <3163.67.171.204.151.1085696680.squirrel@www.forestinformatics.com>
Message-ID: <40B67207.1020900@pdf.com>



Jeff D. Hamann wrote:

> I've been attempting to export a graphics file of my lattice plots and no
> matter what color I use for the bg= argument in the bmp/jpeg/png function,
> the background is grey.
> 
> bmp(filename = "c:/my_paper/resids.bmp", width=1024, height=1024,
> pointsize=10, bg="transparent")
> 
> # these are lattice plots. plot them in a 3x2 matrix
> print( hgqqplot, position=c(0.0, 0.66, 0.5, 1.0 ), more=TRUE )
> print( hgplot, position=c(0.5, 0.66, 1.0, 1.0 ), more=TRUE )
> print( dgqqplot, position=c(0.0, 0.33, 0.5, 0.66 ), more=TRUE )
> print( dgplot, position=c(0.5, 0.33, 1.0, 0.66 ), more=TRUE )
> print( cwgqqplot, position=c(0.0, 0.0, 0.5, 0.33 ), more=TRUE )
> print( cwgplot, position=c(0.5, 0.0, 1.0, 0.33 ), more=FALSE )
> 
> dev.off()
> 
> I've tried white, no argument at all, transparent, etc. and all yield the
> same results. Is this broken, or am I not using the function correctly.
> 
> Thanks,
> Jeff.
> 

I haven't tried it but perhaps you need trellis.device:

library(lattice)
trellis.device(bmp, filename = "c:/my_paper/resids.bmp",
                width=1024, height=1024, pointsize=10,
                bg="transparent")
# these are lattice plots. plot them in a 3x2 matrix
print( hgqqplot, position=c(0.0, 0.66, 0.5, 1.0 ), more=TRUE )
print( hgplot, position=c(0.5, 0.66, 1.0, 1.0 ), more=TRUE )
print( dgqqplot, position=c(0.0, 0.33, 0.5, 0.66 ), more=TRUE )
print( dgplot, position=c(0.5, 0.33, 1.0, 0.66 ), more=TRUE )
print( cwgqqplot, position=c(0.0, 0.0, 0.5, 0.33 ), more=TRUE )
print( cwgplot, position=c(0.5, 0.0, 1.0, 0.33 ), more=FALSE )
dev.off()


--sundar



From deepayan at stat.wisc.edu  Fri May 28 01:16:56 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 27 May 2004 18:16:56 -0500
Subject: [R] no transparent background in bmp
In-Reply-To: <3163.67.171.204.151.1085696680.squirrel@www.forestinformatics.com>
References: <3163.67.171.204.151.1085696680.squirrel@www.forestinformatics.com>
Message-ID: <200405271816.56677.deepayan@stat.wisc.edu>

On Thursday 27 May 2004 17:24, Jeff D. Hamann wrote:
> I've been attempting to export a graphics file of my lattice plots
> and no matter what color I use for the bg= argument in the
> bmp/jpeg/png function, the background is grey.
>
> bmp(filename = "c:/my_paper/resids.bmp", width=1024, height=1024,
> pointsize=10, bg="transparent")

This doesn't affect lattice's own settings, which is what's going to be 
used. You should instead use

trellis.device(bmp, 
               filename = "c:/my_paper/resids.bmp", 
               width=1024, height=1024,
               pointsize=10, # probably useless
               bg="transparent")

or call 

lset(list(background = list(col = "transparent")))

after the bmp device is opened using bmp() directly. 

(this works for me with png at least, my installation doesn't seem to 
have a bmp device)

Deepayan



From lauraholt_983 at hotmail.com  Fri May 28 01:30:32 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Thu, 27 May 2004 18:30:32 -0500
Subject: [R] modes of objects
Message-ID: <BAY12-F95aQYrVjYKtW00035ab3@hotmail.com>

Hi R People:


I am looking for some objects:

>objects(pat="f")
[1] "dufus"   "f"       "f1"      "fake.df" "ff"      "fm1"     "one.df"  
"one1.df" "x.df"    "xf"
>mode(objects(pat="f"))
[1] "character"
>

I would like to determine the mode of these objects.  For instance, dufus 
and f are functions, while fake.df and one.df are data frames.

I tried writing to a list, but still can't get it!

Thanks in advance!

Laura
mailto: lauraholt_983 at hotmail.com



From joseclaudio.faria at terra.com.br  Fri May 28 01:36:54 2004
From: joseclaudio.faria at terra.com.br (=?Windows-1252?Q?Jos=E9_Cl=E1udio_Faria?=)
Date: Thu, 27 May 2004 20:36:54 -0300
Subject: [R] Statistics Avec R (Vincente Zoonekynd): portuguese translation
Message-ID: <001d01c44443$81d93590$01fea8c0@sapetinga>

Dears friends,

I have been translating and extended, with educational porposes only, the available material in the www
(http://zoonek2.free.fr/UNIX/48_R/all.html) "Statistcs avec R" for the Portuguese of Brazil.

I consider the material very good and would like to share this work with anothers users R.

Already I translated and I extended two chapters: Introduction to the R and analysis of variance.

I request to the author (Vincente Zoonekynd) an explicit authorization, a time that it authorizes it for the English,
but still I did not receive answers.

I can disponibilizar the material in HTML for the interested parties.

What do you think about it?

Best regards,

Jos Cludio Faria
UESC/DCET
Brasil
73-634.2779
joseclaudio.faria at terra.com.br
jc_faria at uol.com.br



From gunter.berton at gene.com  Fri May 28 01:40:28 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 27 May 2004 16:40:28 -0700
Subject: [R] modes of objects
References: <BAY12-F95aQYrVjYKtW00035ab3@hotmail.com>
Message-ID: <40B67C6C.788CF177@gene.com>

sapply(ls(), function(x)mode(get(x)))

Cheers,
Bert

Laura Holt wrote:

> Hi R People:
>
> I am looking for some objects:
>
> >objects(pat="f")
> [1] "dufus"   "f"       "f1"      "fake.df" "ff"      "fm1"     "one.df"
> "one1.df" "x.df"    "xf"
> >mode(objects(pat="f"))
> [1] "character"
> >
>
> I would like to determine the mode of these objects.  For instance, dufus
> and f are functions, while fake.df and one.df are data frames.
>
> I tried writing to a list, but still can't get it!
>
> Thanks in advance!
>
> Laura
> mailto: lauraholt_983 at hotmail.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

--

Bert Gunter

Non-Clinical Biostatistics
Genentech
MS: 240B
Phone: 650-467-7374


"The business of the statistician is to catalyze the scientific learning
process."

 -- George E.P. Box



From bdavenhall at sbcglobal.net  Fri May 28 02:54:24 2004
From: bdavenhall at sbcglobal.net (Brian Davenhall)
Date: Thu, 27 May 2004 17:54:24 -0700
Subject: [R] Generate a sequence of random integer values
Message-ID: <003501c4444e$54c96880$c2e5fea9@oemcomputer>

I'm trying to generate a sequence of random integer values.  I've tried to
combine the random (r) and the sequence (seq) functions but this approach
does not work.  For example, if I use the following command:

> a <- seq(1:100)
> a
  [1]   1   2   3   4   5   6   7   8   9  etc.

This is a good start, but what I really want is something that would look
like this instead

 [1]  3 96 45 67 8 24 99 63 8, etc.

where the integer numbers between 1 and 100 are randomly chosen.

Any help would be great, I've found workarounds in other stat packages, but
would prefer to do this in R.



From wcvinyard at earthlink.net  Fri May 28 03:07:14 2004
From: wcvinyard at earthlink.net (Bill Vinyard)
Date: Thu, 27 May 2004 21:07:14 -0400
Subject: [R] Generate a sequence of random integer values
In-Reply-To: <003501c4444e$54c96880$c2e5fea9@oemcomputer>
Message-ID: <MJENLJEPCHEMCAGNPDMGCEALCDAA.wcvinyard@earthlink.net>

help(sample)

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Brian Davenhall
Sent: Thursday, May 27, 2004 20:54
To: r-help at stat.math.ethz.ch
Subject: [R] Generate a sequence of random integer values


I'm trying to generate a sequence of random integer values.  I've tried to
combine the random (r) and the sequence (seq) functions but this approach
does not work.  For example, if I use the following command:

> a <- seq(1:100)
> a
  [1]   1   2   3   4   5   6   7   8   9  etc.

This is a good start, but what I really want is something that would look
like this instead

 [1]  3 96 45 67 8 24 99 63 8, etc.

where the integer numbers between 1 and 100 are randomly chosen.

Any help would be great, I've found workarounds in other stat packages, but
would prefer to do this in R.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From sasprog474 at yahoo.com  Fri May 28 03:18:58 2004
From: sasprog474 at yahoo.com (Greg Tarpinian)
Date: Thu, 27 May 2004 18:18:58 -0700 (PDT)
Subject: [R] SCO & R
In-Reply-To: <20040527221826.GA3526@kryten.akl.indigoindustrial.co.nz>
Message-ID: <20040528011858.58630.qmail@web41410.mail.yahoo.com>

Actually, it was very recent.  I pulled the electronic
version of the article from the Forbes website:

"Has SCO's Stance Slowed Linux's Momentum?
Arik Hesseldahl, 04.20.04, 3:00 PM ET

NEW YORK - The open-source Linux operating system may
be mostly free, but there is company that thinks that
if you use Linux, you owe it money. That company is
SCO (nasdaq: SCOX - news - people ), based in Lindon,
Utah. SCO has sued IBM (nyse: IBM - news - people ),
asserting that Big Blue took code from Unix, on which
SCO has some copyrights, and inserted that code into
Linux, which is given away for free.

Recently, SCO has taken to suing high-profile
corporate Linux users, among them AutoZone (nyse: AZO
- news - people ) and DaimlerChrysler (nyse: DCX -
news - people ), claiming they're infringing on SCO
copyrights. SCO's aggressive legal stance, which is
controversial among Linux backers, may exert a
chilling effect on the migration toward open-source
software...."

The full article was much longer, of course.  I have
also been seeing ads for Linux versions (like SuSE)
where the distributor is now indemnifying the buyers
against lawsuits.  The unfortunate part is that to be
indemnified, you have to agree not to modify the 
distribution, which eliminates one of the major
benefits of using Linux in the first place.  I think
the key point is that corporations are going to be
more leery of Linux until this plays out.  And even
if SCO loses, the trend toward using R instead of
(say)
SAS may be blunted or halted due to legal concerns.

Thanks for pointing out SCO's racketeering invest-
igation, that was news to me.

Best,

    Greg


	
		
__________________________________



From deepayan at stat.wisc.edu  Fri May 28 04:08:12 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 27 May 2004 21:08:12 -0500
Subject: [R] SCO & R
In-Reply-To: <20040528011858.58630.qmail@web41410.mail.yahoo.com>
References: <20040528011858.58630.qmail@web41410.mail.yahoo.com>
Message-ID: <200405272108.12664.deepayan@stat.wisc.edu>

On Thursday 27 May 2004 20:18, Greg Tarpinian wrote:

> Actually, it was very recent.  I pulled the electronic
> version of the article from the Forbes website:

I would think twice before taking forbes articles too seriously. For 
instance, they seem to think that protecting intellectual property 
rights are all right when it's some big commercial company doing the 
protecting, but not when they are on the other side of the table. See 
this article from last year:

http://www.forbes.com/2003/10/14/cz_dl_1014linksys.html

Deepayan



From Duncan.Mackay at flinders.edu.au  Fri May 28 04:10:58 2004
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Fri, 28 May 2004 11:40:58 +0930
Subject: [R] Generate a sequence of random integer values
In-Reply-To: <003501c4444e$54c96880$c2e5fea9@oemcomputer>
Message-ID: <003b01c44459$042f66d0$71e66081@duncanlt>

Hello,
Have a look at the "sample" command.

E.g.
> sample(20)
 [1]  3  2 18  6 10  5  9 20 19 13  8 15 17  7  4 14 11  1 12 16


Duncan

*****************************************
Dr. Duncan Mackay
School of Biological Sciences
Flinders University
GPO Box 2100
Adelaide
S.A.    5001
AUSTRALIA

Ph (08) 8201 2627    FAX (08) 8201 3015


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Brian Davenhall
Sent: Friday, 28 May 2004 10:24 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Generate a sequence of random integer values


I'm trying to generate a sequence of random integer values.  I've tried
to combine the random (r) and the sequence (seq) functions but this
approach does not work.  For example, if I use the following command:

> a <- seq(1:100)
> a
  [1]   1   2   3   4   5   6   7   8   9  etc.

This is a good start, but what I really want is something that would
look like this instead

 [1]  3 96 45 67 8 24 99 63 8, etc.

where the integer numbers between 1 and 100 are randomly chosen.

Any help would be great, I've found workarounds in other stat packages,
but would prefer to do this in R.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From rpeng at jhsph.edu  Fri May 28 04:47:41 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 27 May 2004 22:47:41 -0400
Subject: [R] SCO & R
In-Reply-To: <20040528011858.58630.qmail@web41410.mail.yahoo.com>
References: <20040528011858.58630.qmail@web41410.mail.yahoo.com>
Message-ID: <40B6A84D.5090903@jhsph.edu>

I've never understood why people think that proprietary software 
is somehow immune from copyright violation.  Or that corporations 
are somehow less likely to steal code.

If I were working for SAS, i'd steal all the R code I could. 
Besides, who's going to catch me?

-roger

Greg Tarpinian wrote:

> Actually, it was very recent.  I pulled the electronic
> version of the article from the Forbes website:
> 
> "Has SCO's Stance Slowed Linux's Momentum?
> Arik Hesseldahl, 04.20.04, 3:00 PM ET
> 
> NEW YORK - The open-source Linux operating system may
> be mostly free, but there is company that thinks that
> if you use Linux, you owe it money. That company is
> SCO (nasdaq: SCOX - news - people ), based in Lindon,
> Utah. SCO has sued IBM (nyse: IBM - news - people ),
> asserting that Big Blue took code from Unix, on which
> SCO has some copyrights, and inserted that code into
> Linux, which is given away for free.
> 
> Recently, SCO has taken to suing high-profile
> corporate Linux users, among them AutoZone (nyse: AZO
> - news - people ) and DaimlerChrysler (nyse: DCX -
> news - people ), claiming they're infringing on SCO
> copyrights. SCO's aggressive legal stance, which is
> controversial among Linux backers, may exert a
> chilling effect on the migration toward open-source
> software...."
> 
> The full article was much longer, of course.  I have
> also been seeing ads for Linux versions (like SuSE)
> where the distributor is now indemnifying the buyers
> against lawsuits.  The unfortunate part is that to be
> indemnified, you have to agree not to modify the 
> distribution, which eliminates one of the major
> benefits of using Linux in the first place.  I think
> the key point is that corporations are going to be
> more leery of Linux until this plays out.  And even
> if SCO loses, the trend toward using R instead of
> (say)
> SAS may be blunted or halted due to legal concerns.
> 
> Thanks for pointing out SCO's racketeering invest-
> igation, that was news to me.
> 
> Best,
> 
>     Greg
> 
> 
> 	
> 		
> __________________________________
> 

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Fri May 28 06:35:08 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 27 May 2004 21:35:08 -0700
Subject: [R] gauss.hermite?
Message-ID: <40B6C17C.9000003@pdf.com>

      The search at www.r-project.org mentioned a function 
"gauss.hermite{rmutil}".  However, 'install.packages("rmutil")' 
produced, 'No package "rmutil" on CRAN.'  How can I find the current 
status of "gauss.hermite" and "rmutil"? 

      Thanks,
      Spencer Graves



From andy_liaw at merck.com  Fri May 28 06:43:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 28 May 2004 00:43:36 -0400
Subject: [R] gauss.hermite?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF7DD9@usrymx25.merck.com>

That sounds like one of Jim Lindsay's packages, for which there's link on
CRAN to his web page.  They are not on CRAN.

Andy

> From: Spencer Graves
> 
>       The search at www.r-project.org mentioned a function 
> "gauss.hermite{rmutil}".  However, 'install.packages("rmutil")' 
> produced, 'No package "rmutil" on CRAN.'  How can I find the current 
> status of "gauss.hermite" and "rmutil"? 
> 
>       Thanks,
>       Spencer Graves



From MSchwartz at MedAnalytics.com  Fri May 28 06:46:17 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 27 May 2004 23:46:17 -0500
Subject: [R] gauss.hermite?
In-Reply-To: <40B6C17C.9000003@pdf.com>
References: <40B6C17C.9000003@pdf.com>
Message-ID: <1085719577.16972.17.camel@localhost.localdomain>

On Thu, 2004-05-27 at 23:35, Spencer Graves wrote:
>       The search at www.r-project.org mentioned a function 
> "gauss.hermite{rmutil}".  However, 'install.packages("rmutil")' 
> produced, 'No package "rmutil" on CRAN.'  How can I find the current 
> status of "gauss.hermite" and "rmutil"? 
> 
>       Thanks,
>       Spencer Graves


Spencer,

A Google search indicates that rmutil is listed on
http://cran.r-project.org/other-software.html. There is a link at the
bottom of the page to Jim Lindsey's site at:

http://popgen0146uns50.unimaas.nl/~jlindsey/rcode.html

There are links for rmutil.tgz and rmutil.zip below the middle of the
page.

HTH,

Marc Schwartz



From kuochen at mac.com  Fri May 28 07:12:19 2004
From: kuochen at mac.com (Kuo-Chen Chan)
Date: Fri, 28 May 2004 01:12:19 -0400
Subject: [R] cannot load R help
Message-ID: <97F5A82E-B065-11D8-9DAD-000393B3A8C8@mac.com>

Dear Sir,

After installing the OSX 10.3.4 update recently, I find that I cannot 
load R help and get the message:
 > help.start()
Making links in per-session dir ...
If /usr/bin/open is already running, it is *not* restarted, and you 
must switch to its
     window.
Otherwise, be patient ...

Please help me to fix this problem. Thank you very much.

KC



From lauraholt_983 at hotmail.com  Fri May 28 08:57:39 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Fri, 28 May 2004 01:57:39 -0500
Subject: [R] orca binary?
Message-ID: <BAY12-F117SK7b9m5PJ0003662e@hotmail.com>

Dear R People:

Is there a binary version for rorca, please?

Thanks,
Laura
mailto: lauraholt_983 at hotmail.com

R Windows 1.9.0



From dimitris.rizopoulos at med.kuleuven.ac.be  Fri May 28 09:04:53 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Fri, 28 May 2004 09:04:53 +0200
Subject: [R] gauss.hermite?
References: <40B6C17C.9000003@pdf.com>
Message-ID: <00b001c44482$1489f800$ad133a86@www.domain>

Dear Spencer,

In Dr. Gray's course notes for Advanced Statistical Computing
(Appendix of Chapter 6) there are some functions for computing
abscissas and corresponding weights for several Gaussian integration
rules:

http://icommons.harvard.edu/~hsph-bio248-01/Lecture_Notes/

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Spencer Graves" <spencer.graves at pdf.com>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, May 28, 2004 6:35 AM
Subject: [R] gauss.hermite?


>       The search at www.r-project.org mentioned a function
> "gauss.hermite{rmutil}".  However, 'install.packages("rmutil")'
> produced, 'No package "rmutil" on CRAN.'  How can I find the current
> status of "gauss.hermite" and "rmutil"?
>
>       Thanks,
>       Spencer Graves
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From n.bouget at laposte.net  Fri May 28 09:37:35 2004
From: n.bouget at laposte.net (n.bouget)
Date: Fri, 28 May 2004 09:37:35 +0200
Subject: [R] distance in the function kmeans
Message-ID: <HYEYIN$999344BCC451662F160AA62400532F59@laposte.net>

Hi,
I want to know which distance is using in the function kmeans
and if we can change this distance. 
Indeed, in the function pam, we can put a distance matrix in
parameter (by the line "pam<-pam(dist(matrixdata),k=7)" ) but
we can't do it in the function kmeans, we have to put the
matrix of data directly ...
Thanks in advance,
Nicolas BOUGET




From lauraholt_983 at hotmail.com  Fri May 28 09:39:37 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Fri, 28 May 2004 02:39:37 -0500
Subject: [R] Building packages and Rcmd check
Message-ID: <BAY12-F38SWYOLU2RnX00036a4f@hotmail.com>

Hello yet again!

I'm trying to build a package.

The Rcmd build works fine.

But the Rcmd check produces an error because I don't have latex on my 
laptop.

Any suggestions, please?

R Windows 1.9.0

thanks again,
Laura

_________________________________________________________________
Learn to simplify your finances and your life in Streamline Your Life from 
MSN Money. http://special.msn.com/money/0405streamline.armx



From Matthias.Kohl at uni-bayreuth.de  Fri May 28 10:45:10 2004
From: Matthias.Kohl at uni-bayreuth.de (Matthias Kohl)
Date: Fri, 28 May 2004 09:45:10 +0100
Subject: [R] "privileged slots"
In-Reply-To: <16566.3676.127996.996941@gargle.gargle.HOWL>
References: <40B5E6BF.1090100@uni-bayreuth.de>
	<16566.3676.127996.996941@gargle.gargle.HOWL>
Message-ID: <40B6FC16.2000006@uni-bayreuth.de>

Martin Maechler schrieb:

>>>>>>"Matthias" == Matthias Kohl <Matthias.Kohl at uni-bayreuth.de>
>>>>>>    on Thu, 27 May 2004 14:01:51 +0100 writes:
>>>>>>            
>>>>>>
>
>    Matthias> Hi all, in the help for RClassUtils I found the
>    Matthias> expression "privileged slots" in function
>    Matthias> "checkSlotAssignment" with the explanation:
>
>    Matthias> /privileged slots (those that can only be set by
>    Matthias> accesor functions defined along with the class
>    Matthias> itself)/
>
>
>RClassUtils ???
>
> > help.search("RClassUtils")
>  
>
your right, sorry

but, at least a R Site search in "Functions"
gives me one match: "Utilities for Managing Class Definitions"
which hast the "title": RClassUtils{methods}             R Documentation

> No help files found with alias or concept or title matching
> 'RClassUtils' using fuzzy matching.
>
>-----
>
>So I guess that's not something in a standard R document.
>You should rather keep to the 'official documentation' ...
>  
>
I thought this is a official documentation ...

>    Matthias> I thought all slots of a (not private) class can
>    Matthias> be a accessed by a user via the @ Operator.  
>
>I tend to agree with your thoughts...
>
>    Matthias> Is there a way to make a single slot of a class (not
>    Matthias> the whole class) private, so that you can access
>    Matthias> this slot only via an accessor function (not via @)?
>
>I'd rather guess not.
>
>    Matthias> Thanks, for your help Matthias
>
>Martin
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From ligges at statistik.uni-dortmund.de  Fri May 28 10:09:45 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 May 2004 10:09:45 +0200
Subject: [R] Building packages and Rcmd check
In-Reply-To: <BAY12-F38SWYOLU2RnX00036a4f@hotmail.com>
References: <BAY12-F38SWYOLU2RnX00036a4f@hotmail.com>
Message-ID: <40B6F3C9.9040504@statistik.uni-dortmund.de>

Laura Holt wrote:
> Hello yet again!
> 
> I'm trying to build a package.
> 
> The Rcmd build works fine.
> 
> But the Rcmd check produces an error because I don't have latex on my 
> laptop.
> 
> Any suggestions, please?


Rcmd check --help  tells you that you can use the option:

   --no-latex        do not run LaTeX on help files

if you don't want LaTeX porcessing to be checked.

... or install LaTeX ...

Uwe Ligges



> R Windows 1.9.0
> 
> thanks again,
> Laura
> 
> _________________________________________________________________
> Learn to simplify your finances and your life in Streamline Your Life 
> from MSN Money. http://special.msn.com/money/0405streamline.armx
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri May 28 10:12:43 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 May 2004 10:12:43 +0200
Subject: [R] distance in the function kmeans
In-Reply-To: <HYEYIN$999344BCC451662F160AA62400532F59@laposte.net>
References: <HYEYIN$999344BCC451662F160AA62400532F59@laposte.net>
Message-ID: <40B6F47B.4020706@statistik.uni-dortmund.de>

n.bouget wrote:

> Hi,
> I want to know which distance is using in the function kmeans
> and if we can change this distance. 
> Indeed, in the function pam, we can put a distance matrix in
> parameter (by the line "pam<-pam(dist(matrixdata),k=7)" ) but
> we can't do it in the function kmeans, we have to put the
> matrix of data directly ...
> Thanks in advance,
> Nicolas BOUGET

As the name says, kmeans() calculates *means* (centres) of clusters. It 
does not any make sense to do that on distances ...

Uwe Ligges


> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri May 28 10:17:07 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 May 2004 10:17:07 +0200
Subject: [R] orca binary?
In-Reply-To: <BAY12-F117SK7b9m5PJ0003662e@hotmail.com>
References: <BAY12-F117SK7b9m5PJ0003662e@hotmail.com>
Message-ID: <40B6F583.9030800@statistik.uni-dortmund.de>

Laura Holt wrote:

> Dear R People:
> 
> Is there a binary version for rorca, please?


Given I recall correctly, I tried to build rorca for Windows one or two 
years ago without success. But maybe Tony (In this context I recall that 
I'm still owing him a pizza) knows of a binary?

Uwe Ligges



> Thanks,
> Laura
> mailto: lauraholt_983 at hotmail.com
> 
> R Windows 1.9.0
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From fm3a004 at math.uni-hamburg.de  Fri May 28 10:22:34 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Fri, 28 May 2004 10:22:34 +0200 (MET DST)
Subject: [R] distance in the function kmeans
In-Reply-To: <40B6F47B.4020706@statistik.uni-dortmund.de>
Message-ID: <Pine.GSO.3.95q.1040528101922.12644A-100000@sun11.math.uni-hamburg.de>

On Fri, 28 May 2004, Uwe Ligges wrote:

> n.bouget wrote:
> 
> > Hi,
> > I want to know which distance is using in the function kmeans
> > and if we can change this distance. 
> > Indeed, in the function pam, we can put a distance matrix in
> > parameter (by the line "pam<-pam(dist(matrixdata),k=7)" ) but
> > we can't do it in the function kmeans, we have to put the
> > matrix of data directly ...
> > Thanks in advance,
> > Nicolas BOUGET
> 
> As the name says, kmeans() calculates *means* (centres) of clusters. It 
> does not any make sense to do that on distances ...
> 
> Uwe Ligges

That's not really true. There is an equivalent to the k-means target
criterion in terms of distances, and that uses squared Euklidean
distances. However, as far as I know, you cannot compute it directly in
R for any other distance. Using pam is the thing which comes closest.

Christian Hennig


***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From tpapp at axelero.hu  Fri May 28 10:26:09 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Fri, 28 May 2004 10:26:09 +0200
Subject: [R] gauss.hermite?
In-Reply-To: <00b001c44482$1489f800$ad133a86@www.domain>
References: <40B6C17C.9000003@pdf.com>
	<00b001c44482$1489f800$ad133a86@www.domain>
Message-ID: <20040528082609.GA840@localhost>

On Fri, May 28, 2004 at 09:04:53AM +0200, Dimitris Rizopoulos wrote:
> Dear Spencer,
> 
> In Dr. Gray's course notes for Advanced Statistical Computing
> (Appendix of Chapter 6) there are some functions for computing
> abscissas and corresponding weights for several Gaussian integration
> rules:
> 
> http://icommons.harvard.edu/~hsph-bio248-01/Lecture_Notes/

Also have a look at 

@Book{judd98,
  author =       {Judd, Kenneth L},
  title =        {Numerical methods in economics},
  publisher =    {MIT Press},
  year =         1998
}

especially one of the early chapters ("integration" is in its title,
but I don't have the book at the moment), which covers theory and
practice of numerical integration and quadrature rules.

Implementing these in R has been on my TODO list for a while, so I
would be happy to cooperate on this (but only in July or later).

Best,

Tamas

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From n.bouget at laposte.net  Fri May 28 10:30:33 2004
From: n.bouget at laposte.net (n.bouget@laposte.net)
Date: Fri, 28 May 2004 10:30:33 +0200
Subject: [R] distance in the function kmeans
Message-ID: <HYF0YX$00B4A5CDA0E53AB89D13149BACD6D987@laposte.net>

> n.bouget wrote:
> 
> > Hi,
> > I want to know which distance is using in the function kmeans
> > and if we can change this distance. 
> > Indeed, in the function pam, we can put a distance matrix in
> > parameter (by the line "pam<-pam(dist(matrixdata),k=7)" ) but
> > we can't do it in the function kmeans, we have to put the
> > matrix of data directly ...
Yes but how can we choose the distance to calculate centers?

> > Thanks in advance,
> > Nicolas BOUGET
> 
> As the name says, kmeans() calculates *means* (centres) of
clusters. It 
> does not any make sense to do that on distances ...
> 
> Uwe Ligges
> 
> 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.
math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> 
> 


From Matthias.Templ at statistik.gv.at  Fri May 28 10:34:24 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Fri, 28 May 2004 10:34:24 +0200
Subject: [R] R CMD check, latex
Message-ID: <83536658864BC243BE3C06D7E936ABD50153A5B5@xchg1.statistik.local>

Hello,

I'm trying to build a package and the R CMD build works fine.

The R CMD check produces an error, because no latex is found.
But I have MikTeX installed and it works fine (only?) in combination with WinEdt.

After reinstallation of MikTeX (no errors) I have the same problem. I??m not sure if this is a problem of my latex or a problem of the communication from R to my latex.

(I??m running R 1.9.0 on Windows XP)

I??m really happy if anybody can help me again.

Thanks,
Matthias



From martin.klaffenboeck at gmx.at  Fri May 28 10:40:36 2004
From: martin.klaffenboeck at gmx.at (Martin Klaffenboeck)
Date: Fri, 28 May 2004 10:40:36 +0200
Subject: [R] Sorting Data?
In-Reply-To: <40B64B58.819F35A@gene.com> (from gunter.berton@gene.com on Do,
	Mai 27, 2004 at 22:11:04 +0200)
References: <20040527195847.GE4890@martin.kleinerdrache.org>
	<40B64B58.819F35A@gene.com>
Message-ID: <20040528084036.GA4117@martin.kleinerdrache.org>

Am 27.05.2004 22:11:04 schrieb(en) Berton Gunter:
>  Your question does not make a lot of sense to me. If you only want  
> to  compute  distances between mothers and THEIR daughters, you  
> cannot have a  matrix, because  different mothers have different  
> numbers of daughters.

Thats true, but we took only one mother and one daugther in our sample,  
so in this sample we have only on daugther from one mother.

>  Do you want to  define the  distance between a mother and someone  
> else's daughter as 0 or INF ?  Do  you want  to show that mothers and  
> their daughters are more similar then  mothers  and  someone else's  
> daughters?

Thats my question, yes. ;-)

>  You either need to think about what you wish to do more carefully or   
> express it  more carefully. At least for me. Maybe someone else will  
> understand  you better.

Sorry, its the first time for me to talking about statistics in english  
and so I have to learn to express it better.

Martin





> -- Bert
> 
> Martin Klaffenboeck wrote:
> 
> > Hello,
> >
> > Im reading through some manuals, but I cannot find my answer.
> >
> > I have a file containing many data:
> >
> > Vpn     Code    Family  Age     F1      F2      ...     F17
> > 1       1       M       46      1       2       ...     1
> > 2       1       D       18      3       2       ...     4
> > 3       2       M       50      3       3       ...     3
> > ...
> > and so on.
> >
> > Now I can read it by:
> >
> > F = read.table("file", header=T)
> >
> > but now I want to seperate the mothers (M) and daugthers (D) of the
> > family with all the data in all other fields.  How can I do that?
> >
> > The 'Code' Tells me which mother belongs to which dougther.  I want
> to
> > make a matrix where I have the mothers on one and the daugthers on
> the
> > other axis and compair the distance of every question (F1...F17)  
> and
> > the distance of the sum of this questions.  The questions are
> semantic
> > differencials, 5 values.  F4, and F7 must have reverse polarity in
> this
> > case.
> >
> > Hm.  How do I have to do now?
> >
> > Thanks,
> > Martin
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> --
> 
> Bert Gunter
> 
> Non-Clinical Biostatistics
> Genentech
> MS: 240B
> Phone: 650-467-7374
> 
> 
> "The business of the statistician is to catalyze the scientific
> learning
> process."
> 
>  -- George E.P. Box
> 
> 
> 
> 
>



From martin.klaffenboeck at gmx.at  Fri May 28 10:57:44 2004
From: martin.klaffenboeck at gmx.at (Martin Klaffenboeck)
Date: Fri, 28 May 2004 10:57:44 +0200
Subject: [R] Sorting Data?
In-Reply-To: <40B64CC0.5070100@pburns.seanet.com> (from
	pburns@pburns.seanet.com on Do, Mai 27, 2004 at 22:17:04 +0200)
References: <20040527195847.GE4890@martin.kleinerdrache.org>
	<40B64CC0.5070100@pburns.seanet.com>
Message-ID: <20040528085744.GC4117@martin.kleinerdrache.org>

Am 27.05.2004 22:17:04 schrieb(en) Patrick Burns:
> First comment:  "F" is a bad name to use for an object as it
> masks the commonly used meaning of FALSE.

Oh, thanks, I just took F because 'Fragebogen' is such a long variable.   
But you are right, I will change that.

> You'll probably get some better answers, but you can ensure
> a standard order with:
> 
> Fsort <- Fdf[order(Fdf[, 'Code'], Fdf[, 'Family']), ]
> 
> And then perhaps use "reshape".

I will look at this closer.  Im now reshaping arround and don't know  
how I can then create a intercorrelation matrix or a (euklidic)  
distance matrix.

But thanks,
Martin

> Patrick Burns
> 
> Burns Statistics
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
> 
> Martin Klaffenboeck wrote:
> 
>> Hello,
>> 
>> Im reading through some manuals, but I cannot find my answer.
>> 
>> I have a file containing many data:
>> 
>> Vpn    Code    Family    Age    F1    F2    ...    F17
>> 1    1    M    46    1    2    ...    1
>> 2    1    D    18    3    2    ...    4
>> 3    2    M    50    3    3    ...    3
>> ...
>> and so on.
>> 
>> Now I can read it by:
>> 
>> F = read.table("file", header=T)
>> 
>> but now I want to seperate the mothers (M) and daugthers (D) of the   
>> family with all the data in all other fields.  How can I do that?
>> 
>> The 'Code' Tells me which mother belongs to which dougther.  I want  
>> to  make a matrix where I have the mothers on one and the daugthers  
>> on the  other axis and compair the distance of every question (F1... 
>> F17) and  the distance of the sum of this questions.  The questions  
>> are semantic  differencials, 5 values.  F4, and F7 must have reverse  
>> polarity in this  case.
>> 
>> Hm.  How do I have to do now?
>> 
>> Thanks,
>> Martin
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!  
>> http://www.R-project.org/posting-guide.html
>> 
>>
> 
> 
> 
> 
>



From Matthias.Templ at statistik.gv.at  Fri May 28 11:03:42 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Fri, 28 May 2004 11:03:42 +0200
Subject: [R] R CMD check, latex
Message-ID: <83536658864BC243BE3C06D7E936ABD501536915@xchg1.statistik.local>


It was an (for me not understandable) problem on miktex
I??m solving my problem, by copying ..\texmf\miktex\bin\etex.exe to latex.exe I??m wondering that now R CMD check works now.

Sorry, for my question to R help.

Matthias

> -----Urspr??ngliche Nachricht-----
> Von: TEMPL Matthias 
> Gesendet: Freitag, 28. Mai 2004 10:34
> An: r-help at stat.math.ethz.ch
> Betreff: [R] R CMD check, latex
> 
> 
> Hello,
> 
> I'm trying to build a package and the R CMD build works fine.
> 
> The R CMD check produces an error, because no latex is found. 
> But I have MikTeX installed and it works fine (only?) in 
> combination with WinEdt.
> 
> After reinstallation of MikTeX (no errors) I have the same 
> problem. I??m not sure if this is a problem of my latex or a 
> problem of the communication from R to my latex.
> 
> (I??m running R 1.9.0 on Windows XP)
> 
> I??m really happy if anybody can help me again.
> 
> Thanks,
> Matthias
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> PLEASE 
> do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From dieter.menne at menne-biomed.de  Fri May 28 11:04:13 2004
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 28 May 2004 11:04:13 +0200
Subject: [R] Pr(>|z|) in lme4
Message-ID: <INEGIMHGODBGKFPOJBBMKEGJCBAA.dieter.menne@menne-biomed.de>

Dear List,

I am struggling understanding S4 classes. For example, when GLMM 

  summary(glmmML( whatever))

outputs the following line:

            Estimate Std. Error DF z value Pr(>|z|)
(Intercept)    0.856      0.319 45    2.68   0.0073

How do I access the Pr column? 

Dieter



From ernesto at ipimar.pt  Fri May 28 11:15:54 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Fri, 28 May 2004 10:15:54 +0100
Subject: [R] Statistics Avec R (Vincente Zoonekynd): portuguese translation
In-Reply-To: <001d01c44443$81d93590$01fea8c0@sapetinga>
References: <001d01c44443$81d93590$01fea8c0@sapetinga>
Message-ID: <1085735754.16138.3.camel@gandalf.local>

On Fri, 2004-05-28 at 00:36, Jos?? Cl??udio Faria wrote:
> Dears friends,
> 
> I have been translating and extended, with educational porposes only, the available material in the www
> (http://zoonek2.free.fr/UNIX/48_R/all.html) "Statistcs avec R" for the Portuguese of Brazil.
> 
> I consider the material very good and would like to share this work with anothers users R.
> 
> Already I translated and I extended two chapters: Introduction to the R and analysis of variance.
> 
> I request to the author (Vincente Zoonekynd) an explicit authorization, a time that it authorizes it for the English,
> but still I did not receive answers.
> 
> I can disponibilizar the material in HTML for the interested parties.
> 
> What do you think about it?
> 
> Best regards,
> 
> Jos?? Cl??udio Faria
> UESC/DCET
> Brasil
> 73-634.2779
> joseclaudio.faria at terra.com.br
> jc_faria at uol.com.br
> 

Ol??,

Under what license is this book ? You have to check if the book is
licensed and act in agreement with the license rules. You may not need
his authorization.

Best regards and hope you finish you're translation. I'll be glad to
read it.

EJ



From ligges at statistik.uni-dortmund.de  Fri May 28 11:11:04 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 May 2004 11:11:04 +0200
Subject: [R] distance in the function kmeans
In-Reply-To: <HYF0YX$00B4A5CDA0E53AB89D13149BACD6D987@laposte.net>
References: <HYF0YX$00B4A5CDA0E53AB89D13149BACD6D987@laposte.net>
Message-ID: <40B70228.7060104@statistik.uni-dortmund.de>

n.bouget at laposte.net wrote:

>>n.bouget wrote:
>>
>>
>>>Hi,
>>>I want to know which distance is using in the function kmeans
>>>and if we can change this distance. 
>>>Indeed, in the function pam, we can put a distance matrix in
>>>parameter (by the line "pam<-pam(dist(matrixdata),k=7)" ) but
>>>we can't do it in the function kmeans, we have to put the
>>>matrix of data directly ...
> 
> Yes but how can we choose the distance to calculate centers?

Ah, you are going to use different distance measure (e.g. euclidean, 
manhattan, ...) as in other cluster methods? Well, that's not possible 
with the kmeans() implementation. See ?kmeans which tells you:


   The data given by x is clustered by the k-means algorithm. When this
   terminates, all cluster centres are at the mean of their Voronoi sets
   (the set of data points which are nearest to the cluster centre).

   The algorithm of Hartigan and Wong (1979) is used.


Of course, you can do some projection based on the calculation of 
distances, but I don't think there are functions available to do that 
completely automatical - and interpretation of results won't be that 
easy ...

Uwe Ligges



> 
>>>Thanks in advance,
>>>Nicolas BOUGET
>>
>>As the name says, kmeans() calculates *means* (centres) of
> 
> clusters. It 
> 
>>does not any make sense to do that on distances ...
>>
>>Uwe Ligges
>>
>>
>>
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.
> 
> math.ethz.ch/mailman/listinfo/r-help
> 
>>>PLEASE do read the posting guide!
> 
> http://www.R-project.org/posting-guide.html
> 
>>
> 
> 
> 
>



From maechler at stat.math.ethz.ch  Fri May 28 11:11:55 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 28 May 2004 11:11:55 +0200
Subject: [R] Pr(>|z|) in lme4
In-Reply-To: <INEGIMHGODBGKFPOJBBMKEGJCBAA.dieter.menne@menne-biomed.de>
References: <INEGIMHGODBGKFPOJBBMKEGJCBAA.dieter.menne@menne-biomed.de>
Message-ID: <16567.603.690831.433808@gargle.gargle.HOWL>

>>>>> "Dieter" == Dieter Menne <dieter.menne at menne-biomed.de>
>>>>>     on Fri, 28 May 2004 11:04:13 +0200 writes:

    Dieter> Dear List, I am struggling understanding S4
    Dieter> classes. For example, when GLMM

    Dieter>   summary(glmmML( whatever))

    Dieter> outputs the following line:

    Dieter>             Estimate Std. Error DF z value Pr(>|z|)
    Dieter> (Intercept) 0.856 0.319 45 2.68 0.0073

    Dieter> How do I access the Pr column?

Did you try

    s <- summary(glmmML( whatever))
    s ## to give the above

    str(s) ## to show the internal structure

If 's' itself is an object with a formal class (aka "S4 class"),
str() will give sub-optimal (but still helpful) output in the
current version of R [exposing the current implementation of S4
slots, which you should never make use of].

Rather in "R Version 2.0.0 Under development (unstable)" 
aka 'R-devel', it gives much nicer output

Martin



From ligges at statistik.uni-dortmund.de  Fri May 28 11:26:38 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 May 2004 11:26:38 +0200
Subject: [R] Pr(>|z|) in lme4
In-Reply-To: <16567.603.690831.433808@gargle.gargle.HOWL>
References: <INEGIMHGODBGKFPOJBBMKEGJCBAA.dieter.menne@menne-biomed.de>
	<16567.603.690831.433808@gargle.gargle.HOWL>
Message-ID: <40B705CE.8060407@statistik.uni-dortmund.de>

Martin Maechler wrote:

>>>>>>"Dieter" == Dieter Menne <dieter.menne at menne-biomed.de>
>>>>>>    on Fri, 28 May 2004 11:04:13 +0200 writes:
> 
> 
>     Dieter> Dear List, I am struggling understanding S4
>     Dieter> classes. For example, when GLMM
> 
>     Dieter>   summary(glmmML( whatever))
> 
>     Dieter> outputs the following line:
> 
>     Dieter>             Estimate Std. Error DF z value Pr(>|z|)
>     Dieter> (Intercept) 0.856 0.319 45 2.68 0.0073
> 
>     Dieter> How do I access the Pr column?
> 
> Did you try
> 
>     s <- summary(glmmML( whatever))
>     s ## to give the above
> 
>     str(s) ## to show the internal structure
> 
> If 's' itself is an object with a formal class (aka "S4 class"),
> str() will give sub-optimal (but still helpful) output in the
> current version of R [exposing the current implementation of S4
> slots, which you should never make use of].
> 
> Rather in "R Version 2.0.0 Under development (unstable)" 
> aka 'R-devel', it gives much nicer output
> 
> Martin
> 


Well, I wonder what Dieter Menne is looking for. GLMM() is in lme4 and 
uses S4 classes. glmmML() is in "glmmML" and uses S3 classes.

In the latter case, the p-values are calculated within print.glmmML() 
and the corresponding code is:

   1 - pchisq((coef(x)/x$sd)^2, 1)

where x is the glmmML object.

Uwe Ligges



From dieter.menne at menne-biomed.de  Fri May 28 11:31:20 2004
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 28 May 2004 11:31:20 +0200
Subject: [R] Pr(>|z|) in lme4
In-Reply-To: <16567.603.690831.433808@gargle.gargle.HOWL>
Message-ID: <INEGIMHGODBGKFPOJBBMKEGKCBAA.dieter.menne@menne-biomed.de>

Martin,

>     s <- summary(glmmML( whatever))
>     s ## to give the above
>     str(s) ## to show the internal structure

str() is my favorite, it's essentially how I learned R.

It was no problem to find my way in nlme, but still lost in lme4.

Uwe Liggges wrote:

>Well, I wonder what Dieter Menne is looking for. GLMM() is in lme4 and
uses S4 classes. glmmML() is in "glmmML" and uses S3 classes.>>

You have reasons to wonder. I meant

>     s <- summary(GLMM( whatever))

but had also used Goran's glmmML,which did not handle na.omit as nicely as
GLMM does.


Dieter



From maechler at stat.math.ethz.ch  Fri May 28 11:39:49 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 28 May 2004 11:39:49 +0200
Subject: [R] distance in the function kmeans
In-Reply-To: <HYEYIN$999344BCC451662F160AA62400532F59@laposte.net>
References: <HYEYIN$999344BCC451662F160AA62400532F59@laposte.net>
Message-ID: <16567.2277.707646.336764@gargle.gargle.HOWL>

>>>>> "n\" == n\ bouget <n>
>>>>>     on Fri, 28 May 2004 09:37:35 +0200 writes:

    n\> Hi, I want to know which distance is using in the
    n\> function kmeans and if we can change this distance.
    n\> Indeed, in the function pam, we can put a distance
    n\> matrix in parameter (by the line
    n\> "pam<-pam(dist(matrixdata),k=7)" ) but we can't do it in
    n\> the function kmeans, we have to put the matrix of data
    n\> directly ...  Thanks in advance, Nicolas BOUGET

It might be interesting to look at this from the pam()
perspective:
What exactly is pam() lacking that kmeans() does for you?

Christian, are you suggesting that pam() could do the job if

1) there was a dist(., method="a la kmeans") 
2) pam() allowed to be started by a user-specified set of
	 medoids instead of the "Kaufman-Rousseeuw-optimal" ones
?

Regards,
Martin Maechler



From fm3a004 at math.uni-hamburg.de  Fri May 28 12:06:40 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Fri, 28 May 2004 12:06:40 +0200 (MET DST)
Subject: [R] distance in the function kmeans
In-Reply-To: <16567.2277.707646.336764@gargle.gargle.HOWL>
Message-ID: <Pine.GSO.3.95q.1040528115739.12644B-100000@sun11.math.uni-hamburg.de>

On Fri, 28 May 2004, Martin Maechler wrote:

> >>>>> "n\" == n\ bouget <n>
> >>>>>     on Fri, 28 May 2004 09:37:35 +0200 writes:
> 
>     n\> Hi, I want to know which distance is using in the
>     n\> function kmeans and if we can change this distance.
>     n\> Indeed, in the function pam, we can put a distance
>     n\> matrix in parameter (by the line
>     n\> "pam<-pam(dist(matrixdata),k=7)" ) but we can't do it in
>     n\> the function kmeans, we have to put the matrix of data
>     n\> directly ...  Thanks in advance, Nicolas BOUGET
> 
> It might be interesting to look at this from the pam()
> perspective:
> What exactly is pam() lacking that kmeans() does for you?
> 
> Christian, are you suggesting that pam() could do the job if
> 
> 1) there was a dist(., method="a la kmeans") 
> 2) pam() allowed to be started by a user-specified set of
> 	 medoids instead of the "Kaufman-Rousseeuw-optimal" ones
> ?

The k-means criterion is equivalent to:
Find a partition C=C_1 \cup...\cup C_k such that
\sum_{i=1}^k \sum_{x_j,x_l\in C_i} d(x_j,x_l)/|C_i|=min!

d is squared Euklidean distance (see the Bock book). You may wonder to 
what clustering this would lead with another distance.

The difference to pam is that pam minimizes sums of distances to centroid
objects, which have to be part of the dataset. k-means does not need
centroid objects, no "mean objects" are needed. Thus, pam with squared
Euklidean distances is a kind of approximation to k-means. (In practice,
both are approximations to a global optimum.)

There would also be a further version if other distances would be allowed,
the pam criterion would be optimized, but the cluster centers would be
allowed to lie elsewhere than on an object of the sample. 

Of course, pam and the original k-means are more or less easy to compute,
while the suggested alternatives may be computationally complex.

Best,
Christian


> 
> Regards,
> Martin Maechler
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From martin.klaffenboeck at gmx.at  Fri May 28 12:21:42 2004
From: martin.klaffenboeck at gmx.at (Martin Klaffenboeck)
Date: Fri, 28 May 2004 12:21:42 +0200
Subject: [R] Sorting Data?
In-Reply-To: <20040527204302.GA7557@psych> (from baron@psych.upenn.edu on Do,
	Mai 27, 2004 at 22:43:02 +0200)
References: <20040527195847.GE4890@martin.kleinerdrache.org>
	<20040527204302.GA7557@psych>
Message-ID: <20040528102142.GE4117@martin.kleinerdrache.org>

Am 27.05.2004 22:43:02 schrieb(en) Jonathan Baron:
> On 05/27/04 21:58, Martin Klaffenboeck wrote:
> >Hello,
> >
> >Im reading through some manuals, but I cannot find my answer.
> >
> >I have a file containing many data:
> >
> >Vpn	Code	Family	Age	F1	F2	...	F17
> >1	1	M	46	1	2	...	1
> >2	1	D	18	3	2	...	4
> >3	2	M	50	3	3	...	3
> >...
> >and so on.
> >
> >Now I can read it by:
> >
> >F = read.table("file", header=T)
> >
> >but now I want to seperate the mothers (M) and daugthers (D) of the
> >family with all the data in all other fields.  How can I do that?
> >
> >The 'Code' Tells me which mother belongs to which dougther.  I want
> to
> >make a matrix where I have the mothers on one and the daugthers on
> the
> >other axis and compair the distance of every question (F1...F17) and
> >the distance of the sum of this questions.  The questions are
> semantic
> >differencials, 5 values.  F4, and F7 must have reverse polarity in
> this
> >case.
> 
> The following is not tested and probably contains at least one error.

Thanks, that helps me much as I am a R newbie.

> Lets assume that there is one mother per daughter and one
> daughter per mother, and your file is Myfile, and the Codes are
> in order.  One way is this:

Ok, we really have only one daughter per mother in our sample.
Im sorting by:

Myfile <- read.table("Fragebogen.data", header=TRUE)
Myfile <- Myfile[order(e[, 'Code'], Myfile[, 'Family']), ]

Code has one equal code for mother and daugther the same - so I know  
which mother has which daughter, Family tells me if the person it she  
mother or the daugther.

> Myfile$F4 <- -Myfile$F4 # reverse polarity
> Myfile$F7 <- -Myfile$F7

Is this also true, if we have a semantic differential with 5 steps? 
(from 1 to five.  I have one missing value (NA), should I set it to 0?) 
(please tell me also if I use incorrect words).
You didn't know that I assume.  So now I'm doing:

Myfile$F3 <- 5-Myfile$F3

that seems to be good for me, please tell me what you think.

> Mothers <- Myfile[Family="M",]
> Daughters <- Myfile[Family="D",]

Hm.  This seems not to work for me i was testing arround, for me seems  
to work:

Mothers <- Myfile[Myfile[["Family"]]=="M",]
Daugthers <- ...

I hope we have the same results now. ;-)  Im really a newbie in R.

> Itemdiffs <- Mothers[,-(1:4)]-Daughters[,-(1:4)] # the -(1:4)
>                                                  # removes cols 1:4

Ok, this seems to work, also but I don't really know what I am doing  
with it.  Also the other things.

I have to test the hypothesis:  Does a daugther answer the questions  
(semantic differential) more equal the own mother and more different to  
the mothers of the other daugthers.  I hope you get that in  
english. ;-)

Thanks,
Martin



From thpe at hhbio.wasser.tu-dresden.de  Fri May 28 12:41:36 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 28 May 2004 12:41:36 +0200
Subject: [R] distance in the function kmeans
In-Reply-To: <HYEYIN$999344BCC451662F160AA62400532F59@laposte.net>
References: <HYEYIN$999344BCC451662F160AA62400532F59@laposte.net>
Message-ID: <40B71760.60201@hhbio.wasser.tu-dresden.de>

n.bouget wrote:
> Hi,
> I want to know which distance is using in the function kmeans
> and if we can change this distance. 
> Indeed, in the function pam, we can put a distance matrix in
> parameter (by the line "pam<-pam(dist(matrixdata),k=7)" ) but
> we can't do it in the function kmeans, we have to put the
> matrix of data directly ...
> Thanks in advance,
> Nicolas BOUGET

One solution is to transform the data in a way, that the euclidean 
distance of the transformed values represents some other distance of the 
original values. This works at least for the Mahalanobis-Distance, when 
one applies a multivariate technique to a PCA transformed and re-scaled 
matrix, but I don't know if there are transformations for some other 
distance measures.

Thomas P.



From n.bouget at laposte.net  Fri May 28 12:54:29 2004
From: n.bouget at laposte.net (n.bouget@laposte.net)
Date: Fri, 28 May 2004 12:54:29 +0200
Subject: [R] distance in the function kmeans
Message-ID: <HYF7MT$0BFA428B97ABF8D7BFD367598B943F78@laposte.net>

I don't exactly understand what you do, could you show me the
program that you execute to do that?

> n.bouget wrote:
> > Hi,
> > I want to know which distance is using in the function kmeans
> > and if we can change this distance. 
> > Indeed, in the function pam, we can put a distance matrix in
> > parameter (by the line "pam<-pam(dist(matrixdata),k=7)" ) but
> > we can't do it in the function kmeans, we have to put the
> > matrix of data directly ...
> > Thanks in advance,
> > Nicolas BOUGET
> 
> One solution is to transform the data in a way, that the
euclidean 
> distance of the transformed values represents some other
distance of the 
> original values. This works at least for the
Mahalanobis-Distance, when 
> one applies a multivariate technique to a PCA transformed
and re-scaled 
> matrix, but I don't know if there are transformations for
some other 
> distance measures.
> 
> Thomas P.
> 




From Achim.Zeileis at wu-wien.ac.at  Fri May 28 13:15:37 2004
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 28 May 2004 13:15:37 +0200
Subject: [R] useR! 2004 keynote lecture slides
Message-ID: <20040528131537.57660028.Achim.Zeileis@wu-wien.ac.at>

Dear useRs,

there has been some interest on this list into material about the
presentations at useR! 2004.

The slides from the keynote lectures are now available from the
conference web page at 
  http://www.ci.tuwien.ac.at/Conferences/useR-2004/
thanks to the R-core team members who were willing to give the talks and
provide their pdf-slides.

For the user-contributed presentations, there are (mostly) only
abstracts available on the conference web page - for further information
you could look at the web pages of the presenters which are in many
cases linked from the participants page.

For the useR! organization team,
Achim



From rpugh at mango-solutions.com  Fri May 28 13:19:02 2004
From: rpugh at mango-solutions.com (Richard Pugh)
Date: Fri, 28 May 2004 12:19:02 +0100
Subject: [R] R Tshirts, mugs etc ....
In-Reply-To: <Pine.GSO.4.56.0405260940090.19635@cyclone.csrv.uidaho.edu>
Message-ID: <000501c444a5$97a6a530$b7c68651@vsn.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040528/154d55aa/attachment.pl

From gavin.simpson at ucl.ac.uk  Fri May 28 13:21:44 2004
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 28 May 2004 12:21:44 +0100
Subject: [R] distance in the function kmeans
In-Reply-To: <40B71760.60201@hhbio.wasser.tu-dresden.de>
References: <HYEYIN$999344BCC451662F160AA62400532F59@laposte.net>
	<40B71760.60201@hhbio.wasser.tu-dresden.de>
Message-ID: <40B720C8.1010307@ucl.ac.uk>

Thomas Petzoldt wrote:
> n.bouget wrote:
> 
>> Hi,
>> I want to know which distance is using in the function kmeans
>> and if we can change this distance. Indeed, in the function pam, we 
>> can put a distance matrix in
>> parameter (by the line "pam<-pam(dist(matrixdata),k=7)" ) but
>> we can't do it in the function kmeans, we have to put the
>> matrix of data directly ...
>> Thanks in advance,
>> Nicolas BOUGET
> 
> 
> One solution is to transform the data in a way, that the euclidean 
> distance of the transformed values represents some other distance of the 
> original values. This works at least for the Mahalanobis-Distance, when 
> one applies a multivariate technique to a PCA transformed and re-scaled 
> matrix, but I don't know if there are transformations for some other 
> distance measures.
> 
> Thomas P.
> 

Other solutions from an ecological paper are:

Chord distance
Chi square metric
Chi square distance
Hellinger Distance
Distance between species profiles

All these can be seen as Euclidean distances of some transformation of 
the data.

The paper "Ecologically meaningful transformations for ordination of 
species data" Pierre Legendre, and Eugene D. Gallagher (2001) Oecologia 
Vol. 129, Issue 2, 271-280, explains the concept and how to do the 
transformations.

An R example is given in the help file of decostand() in Jari Oksanen's 
vegan library for two of the transformations mentioned above.

Gav

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From gavin.simpson at ucl.ac.uk  Fri May 28 13:35:51 2004
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 28 May 2004 12:35:51 +0100
Subject: [R] distance in the function kmeans
In-Reply-To: <40B720C8.1010307@ucl.ac.uk>
References: <HYEYIN$999344BCC451662F160AA62400532F59@laposte.net>
	<40B71760.60201@hhbio.wasser.tu-dresden.de>
	<40B720C8.1010307@ucl.ac.uk>
Message-ID: <40B72417.6030005@ucl.ac.uk>

Gavin Simpson wrote:
...
> 
> An R example is given in the help file of decostand() in Jari Oksanen's 
> vegan library for two of the transformations mentioned above.
         ^^^^^^^
Pre-empting the usual response about proper terminology, I of course 
meant package not library.

Gav
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From wolski at molgen.mpg.de  Fri May 28 14:07:20 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 28 May 2004 14:07:20 +0200
Subject: [R] - making a Windows library from Unix source code
In-Reply-To: <27D22054C09AD611B16700306E01B9F1012BEDDA@fmbex504.dsto.defence.gov.au>
References: <27D22054C09AD611B16700306E01B9F1012BEDDA@fmbex504.dsto.defence.gov.au>
Message-ID: <200405281407200386.066CC225@mail.math.fu-berlin.de>

Hi!
Normally you are building R packages using
cd c:\Program Files\R\rw1081\src
R CMD build fatigue

Sincerely.

*********** REPLY SEPARATOR  ***********

On 5/11/2004 at 6:32 PM Livingstone, Paul wrote:

>Hi All,
>
>I'm using R1.8.1 on Windows XP.
>
>I'm having trouble producing an R library from source code.  A colleague
>has written the source code, in Unix.  I've copied the source code across
>to Windows (with the help files, data files, description and index) and am
>trying to compile it into a library.  
>
>I've "sourced" each of the *.r files and they appear to work.
>
>I've very carefully followed the instructions in the "R for Windows FAQ"
>and "readme.packages".  I've downloaded and installed Perl, R tools,
>copied across the text to 
>
>C:\Program Files\R\rw1081\src\library\fatigue
>
>(note: the package is called "fatigue") then I type at the DOS prompt
>
>cd "c:\Program Files\R\rw1081\src\gnuwin32"
>make pkg-fatigue
>
>and get the error message(s)
>
>make[1]: *** [zzzfirst] Error 255
>make: *** [pkg-fatigue] Error 2
>
>How do I look up what Error 255 means?  
>Or can you tell me what Error 255 means and how I might fix it?  
>Any other hints or ideas on how to use "make" or compile code that appears
>to work?
>
>
>thanks,
>Paul.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From dmurdoch at pair.com  Fri May 28 14:19:14 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 28 May 2004 08:19:14 -0400
Subject: [R] "privileged slots",
In-Reply-To: <40B671D8.20218.25D99F1@localhost>
References: <16566.3676.127996.996941@gargle.gargle.HOWL>
	<200405271912100128.025D8E16@mail.math.fu-berlin.de>
	<40B671D8.20218.25D99F1@localhost>
Message-ID: <rvaeb051m69kao6q6g1e14eiev9i3okcgt@4ax.com>

On Thu, 27 May 2004 22:55:20 +0200, "Torsten Steuernagel"
<Torsten.Steuernagel at gmx.de> wrote :


>> 2. Is it true
>> that one can gain execution speed by accessing slots using the
>> function slots(object,name,check=FALSE)<-value would speed up
>> execution?
>
>Try this:
>
>> get("@<-")
>function (object, name, value) 
>{
>    arg <- substitute(name)
>    if (is.name(arg)) 
>        name <- as.character(arg)
>    "slot<-"(object, name, TRUE, value)
>}
>
>So "@<-" actually calls "slot<-". Using "slot<-" instead, you save the 
>additional overhead the call to "@<-" introduces. If there will be a real 
>performance gain in replacing "@<-" certainly depends on what you're 
>doing.

I'd advise against doing this kind of optimization.  It will make your
code harder to maintain, and while it might be faster today, if "@<-"
is really a major time sink, it's an obvious candidate for
optimization in R, e.g. by making it .Internal or .Primitive.  When
that happens, your "optimized" code will likely be slower (if it even
works at all).

Duncan Murdoch



From laura at env.leeds.ac.uk  Fri May 28 14:27:36 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Fri, 28 May 2004 13:27:36 +0100 (BST)
Subject: [R] Adding key to simple plot() function
Message-ID: <Pine.LNX.4.44.0405281323350.3942-100000@env-pc-phd13>

I am generating a simple x,y plot to show geographical positions where
point data has been taken. Rather than plot a graph and lay points on top
I've opted to generate the map from the point data, ie plot(-x,-y). This
works fine, though I am wanting to label each point 1:20 and have a key
alongside - is this possible without getting into trellis plots? I have
very limited time available so don't want to embark on trellis functions
which I've never used before..

Also, my x,y  labels currently have a negative sign in front of them which
I'd like to remove, but if I negate the labels they no longer fit on the
graph as my data points are -x and -y...

Any suggestions?

Thanks,
Laura



From Benjamin.Planque at ifremer.fr  Fri May 28 14:29:30 2004
From: Benjamin.Planque at ifremer.fr (Benjamin PLANQUE)
Date: Fri, 28 May 2004 14:29:30 +0200
Subject: [R] Regression model type II
Message-ID: <40B730AA.9090704@ifremer.fr>

I am trying to fit regression models type II with R, but it seems to me 
that most (all) of the linear model functions are for type I regressions.

Does anyone knows whether type II regressions functions exist in R.

Benjamin

-- 
Benjamin Planque
IFREMER
Laboratoire d'Ecologie Halieutique
BP 21105
44311 Nantes Cedex 03
France

Tel: +33 (0)2 40 37 41 17
Fax: +33 (0)2 40 37 40 75
e-mail: Benjamin.Planque at ifremer.fr
http://www.ifremer.fr/drvecohal/



From sdavis2 at mail.nih.gov  Fri May 28 14:35:45 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 28 May 2004 08:35:45 -0400
Subject: [R] Adding key to simple plot() function
In-Reply-To: <Pine.LNX.4.44.0405281323350.3942-100000@env-pc-phd13>
Message-ID: <BCDCAA61.87EE%sdavis2@mail.nih.gov>

Laura,

For your axis issues, look at plotting without axes [plot(....,axes=F) and
then see ?axis for making them on your own.  As for labeling your data, look
at ?points and ?text.

Sean

On 5/28/04 8:27 AM, "Laura Quinn" <laura at env.leeds.ac.uk> wrote:

> I am generating a simple x,y plot to show geographical positions where
> point data has been taken. Rather than plot a graph and lay points on top
> I've opted to generate the map from the point data, ie plot(-x,-y). This
> works fine, though I am wanting to label each point 1:20 and have a key
> alongside - is this possible without getting into trellis plots? I have
> very limited time available so don't want to embark on trellis functions
> which I've never used before..
> 
> Also, my x,y  labels currently have a negative sign in front of them which
> I'd like to remove, but if I negate the labels they no longer fit on the
> graph as my data points are -x and -y...
> 
> Any suggestions?
> 
> Thanks,
> Laura
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From rksh at soc.soton.ac.uk  Fri May 28 14:41:51 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Fri, 28 May 2004 13:41:51 +0100
Subject: [R] optim(method="SANN")
Message-ID: <a0600200abcdce3752b61@[139.166.242.29]>

Hello List

I'm working on a combinatoric problem in which the object is to
minimize the badness() of a vector.  I think this class of problem is only
soluble by optim() using method=SANN.

The badness() of anything is >= 0, and when I've found a solution with
zero badness, I want optim() to stop (carrying on beyond zero badness
cannot improve the solution).  Efficiency is crucial here.

The  ?optim manpage states

           For '"SANN"' 'maxit' gives the total number of function
           evaluations. There is no other stopping criterion.

How best to make optim() stop as soon as it finds a zero badness
solution?



-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From thpe at hhbio.wasser.tu-dresden.de  Fri May 28 14:47:10 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 28 May 2004 14:47:10 +0200
Subject: [R] distance in the function kmeans
In-Reply-To: <HYF7MT$0BFA428B97ABF8D7BFD367598B943F78@laposte.net>
References: <HYF7MT$0BFA428B97ABF8D7BFD367598B943F78@laposte.net>
Message-ID: <40B734CE.6060903@hhbio.wasser.tu-dresden.de>

n.bouget at laposte.net wrote:

 > I don't exactly understand what you do, could you show me the
 > program that you execute to do that?

I did such things sometimes ago, so the following is (as usual) without
warranty. There are several methods, e.g. using Choleski factorization,
singular value decomposition or principal components. Given "mdata" as
original data matrix it works with hclust and should be applicable to
kmeans too:

# with svd
z <- svd(scale(mdata, scale=F))$u
cl <- hclust(dist(z), method="ward")

# with princomp (rescaled)
pc <- princomp(mdata, cor=FALSE)
pcdata <- as.data.frame(scale(pc$scores))
cl <- hclust(dist(pcdata), method="ward")


... but as I mentioned, this is only an example, that methods working
with the Euclidean distance can be applied to other distance measures,
when an appropriate transformation of the data exist and, according to
Gavin, there are indeed some other possibilities.

Thomas P.



From sdavis2 at mail.nih.gov  Fri May 28 14:49:30 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 28 May 2004 08:49:30 -0400
Subject: [R] Simple list manipulation question
Message-ID: <BCDCAD9A.87F3%sdavis2@mail.nih.gov>

I have a list of vectors

$A
"AB" "BC" "CD"

$B
"GF" "HG" "FH" "FJ"

and I want to convert it into a dataframe of form

A  AB
A  BC
A  CD
B  GF
B  HG
B  FH
B  FJ

Just can't quite come up with a nice "R" solution for it.

Thanks,
Sean



From wolski at molgen.mpg.de  Fri May 28 14:52:59 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 28 May 2004 14:52:59 +0200
Subject: [R] Simple list manipulation question
In-Reply-To: <BCDCAD9A.87F3%sdavis2@mail.nih.gov>
References: <BCDCAD9A.87F3%sdavis2@mail.nih.gov>
Message-ID: <200405281452590333.06968C2F@mail.math.fu-berlin.de>

Hallo!
x<-unlist(yourlist)
names(x)  # maybee you have to postprocess the names a little
dataframe(names(x),x)

Sincerely
Eryk

*********** REPLY SEPARATOR  ***********

On 5/28/2004 at 8:49 AM Sean Davis wrote:

>I have a list of vectors
>
>$A
>"AB" "BC" "CD"
>
>$B
>"GF" "HG" "FH" "FJ"
>
>and I want to convert it into a dataframe of form
>
>A  AB
>A  BC
>A  CD
>B  GF
>B  HG
>B  FH
>B  FJ
>
>Just can't quite come up with a nice "R" solution for it.
>
>Thanks,
>Sean
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From ggrothendieck at myway.com  Fri May 28 14:56:54 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 28 May 2004 12:56:54 +0000 (UTC)
Subject: [R] Simple list manipulation question
References: <BCDCAD9A.87F3%sdavis2@mail.nih.gov>
Message-ID: <loom.20040528T145609-617@post.gmane.org>

R> L <- list(A=c("AB","BC","CD"),B=c("GF","HG","FH","FJ"))
R> stack(L)
  values ind
1     AB   A
2     BC   A
3     CD   A
4     GF   B
5     HG   B
6     FH   B
7     FJ   B
 

Sean Davis <sdavis2 <at> mail.nih.gov> writes:

: 
: I have a list of vectors
: 
: $A
: "AB" "BC" "CD"
: 
: $B
: "GF" "HG" "FH" "FJ"
: 
: and I want to convert it into a dataframe of form
: 
: A  AB
: A  BC
: A  CD
: B  GF
: B  HG
: B  FH
: B  FJ
: 
: Just can't quite come up with a nice "R" solution for it.
: 
: Thanks,
: Sean

:



From lauraholt_983 at hotmail.com  Fri May 28 14:58:42 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Fri, 28 May 2004 07:58:42 -0500
Subject: [R] any simple examples for SJAVA please
Message-ID: <BAY12-F92nENMgbHMm300037073@hotmail.com>

Hi!

Are there any simple examples for SJAVA please?

Thanks,
Laura
R Version 1.9.0 Windows

_________________________________________________________________




From wolski at molgen.mpg.de  Fri May 28 15:09:26 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 28 May 2004 15:09:26 +0200
Subject: [R] any simple examples for SJAVA please
In-Reply-To: <BAY12-F92nENMgbHMm300037073@hotmail.com>
References: <BAY12-F92nENMgbHMm300037073@hotmail.com>
Message-ID: <200405281509260442.06A59C14@mail.math.fu-berlin.de>

Hallo Laura!
What I have heard at UseR there are no stable running SJava at the Windows platform. ( I wish that I am wrong!) I knew that Simon Urbanek is using and developing a java interface to R.
google: simon urbanek

Sincerely
Eryk

*********** REPLY SEPARATOR  ***********

On 5/28/2004 at 7:58 AM Laura Holt wrote:

>Hi!
>
>Are there any simple examples for SJAVA please?
>
>Thanks,
>Laura
>R Version 1.9.0 Windows
>
>_________________________________________________________________
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From wolski at molgen.mpg.de  Fri May 28 15:09:49 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 28 May 2004 15:09:49 +0200
Subject: [R] "privileged slots"
In-Reply-To: <40B671D8.20218.25D99F1@localhost>
References: <16566.3676.127996.996941@gargle.gargle.HOWL>
	<40B671D8.20218.25D99F1@localhost>
Message-ID: <200405281509490996.06A5F816@mail.math.fu-berlin.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040528/d8a4ce3a/attachment.pl

From muteau at ensam.inra.fr  Fri May 28 15:10:29 2004
From: muteau at ensam.inra.fr (Vincent MUTEAUD)
Date: Fri, 28 May 2004 15:10:29 +0200
Subject: [R] any simple examples for SJAVA please
In-Reply-To: <BAY12-F92nENMgbHMm300037073@hotmail.com>
Message-ID: <5.0.2.1.2.20040528150243.00abc940@ensam.inra.fr>

Hi,
like you I'm trying to use SJava and I meet with many difficulties.
I try to run examples from "Calling R from Java" written by Duncan Temple 
Lang available from http://www.omegahat.org/SJava (there are many examples 
on this web site).
Now I have an error that my R version is R 1.6.1 while I have version 1.9.0 
on windows NT. This causes a crash when I run my Java code:
fatal error: enable to open the  base package
I still waiting for a solution
Best

A 07:58 28/05/2004 -0500, Laura Holt a ??crit :
>Hi!
>
>Are there any simple examples for SJAVA please?
>
>Thanks,
>Laura
>R Version 1.9.0 Windows
>
>_________________________________________________________________
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From baron at psych.upenn.edu  Fri May 28 15:18:58 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Fri, 28 May 2004 09:18:58 -0400
Subject: [R] Sorting Data?
In-Reply-To: <20040528102142.GE4117@martin.kleinerdrache.org>
References: <20040527195847.GE4890@martin.kleinerdrache.org>
	<20040527204302.GA7557@psych>
	<20040528102142.GE4117@martin.kleinerdrache.org>
Message-ID: <20040528131858.GA8410@psych>

On 05/28/04 12:21, Martin Klaffenboeck wrote:
>Am 27.05.2004 22:43:02 schrieb(en) Jonathan Baron:
>> On 05/27/04 21:58, Martin Klaffenboeck wrote:
>> >Hello,
>> >
>> >Im reading through some manuals, but I cannot find my answer.
>> >
>> >I have a file containing many data:
>> >
>> >Vpn	Code	Family	Age	F1	F2	...	F17
>> >1	1	M	46	1	2	...	1
>> >2	1	D	18	3	2	...	4
>> >3	2	M	50	3	3	...	3
>> >...
>> >and so on.
>> >
>> >Now I can read it by:
>> >
>> >F = read.table("file", header=T)
>> >
>> >but now I want to seperate the mothers (M) and daugthers (D) of the
>> >family with all the data in all other fields.  How can I do that?
>> >
>> >The 'Code' Tells me which mother belongs to which dougther.  I want
>> to
>> >make a matrix where I have the mothers on one and the daugthers on
>> the
>> >other axis and compair the distance of every question (F1...F17) and
>> >the distance of the sum of this questions.  The questions are
>> semantic
>> >differencials, 5 values.  F4, and F7 must have reverse polarity in
>> this
>> >case.
>>
>> The following is not tested and probably contains at least one error.
>
>Thanks, that helps me much as I am a R newbie.
>
>> Lets assume that there is one mother per daughter and one
>> daughter per mother, and your file is Myfile, and the Codes are
>> in order.  One way is this:
>
>Ok, we really have only one daughter per mother in our sample.
>Im sorting by:
>
>Myfile <- read.table("Fragebogen.data", header=TRUE)
>Myfile <- Myfile[order(e[, 'Code'], Myfile[, 'Family']), ]
>
>Code has one equal code for mother and daugther the same - so I know
>which mother has which daughter, Family tells me if the person it she
>mother or the daugther.
>
>> Myfile$F4 <- -Myfile$F4 # reverse polarity
>> Myfile$F7 <- -Myfile$F7
>
>Is this also true, if we have a semantic differential with 5 steps?
>(from 1 to five.  I have one missing value (NA), should I set it to 0?)
>(please tell me also if I use incorrect words).
>You didn't know that I assume.  So now I'm doing:
>
>Myfile$F3 <- 5-Myfile$F3
>
>that seems to be good for me, please tell me what you think.
>
>> Mothers <- Myfile[Family="M",]
>> Daughters <- Myfile[Family="D",]
>
>Hm.  This seems not to work for me i was testing arround, for me seems
>to work:
>
>Mothers <- Myfile[Myfile[["Family"]]=="M",]
>Daugthers <- ...

My mistake here was to use = instead of ==.  If you use my method
with ==, it might work too.

>I hope we have the same results now. ;-)  Im really a newbie in R.
>
>> Itemdiffs <- Mothers[,-(1:4)]-Daughters[,-(1:4)] # the -(1:4)
>>                                                  # removes cols 1:4
>
>Ok, this seems to work, also but I don't really know what I am doing
>with it.  

Type the names of the variables to find out what you are doing.
If they are too big, then subset them, for example, 

Mothers[1:5,]
Daughters[1:5,]
Itemdiffs[1:5,]

>Also the other things.
>
>I have to test the hypothesis:  Does a daugther answer the questions
>(semantic differential) more equal the own mother and more different to
>the mothers of the other daugthers.  

I don't think this is a trivial problem at all, so I am hesitant
to offer advice.  I see now that you reall do want a matrix,
where you have mothers in the columns and daughters in the rows,
and distance (difference, similarity) measures in the cells.
Perhaps you have several such measures, so you want a
three-dimensional array.

You might do something like this.  First define a function to
measure your distance, like

Itemdist <- function(x,y) {sum(abs(x[-(1:4)]-y[-(1:4)]))}

Dists <- matrix(NA,nrow(Daughters),nrow(Mothers))

for (i in 1:nrow(Daughters) 
 {for (j in 1:nrow(Mothers))
  {Dists[i,j] <- Itemdist(Daughters[i,],Mothers[j,])}}

Then you would want to show that the diagonal of the resulting
matrix is higher (or lower) than the other cells.  Here is where
I yield to experts.  If I were doing it, I might consider
comparing these cells to some measure of the expectation of what
they ought to be, but I would not just do a t test comparing them
to all the other cells because the other cells are not
independent of each other.  (One daughter might by odd and be
dissimilar from everyone, and this would show up in an entire
row.)  I'm sure there is some simple idea that I'm missing here.

>I hope you get that in
>english. ;-)

It seems that many people on the list read German (including me,
but I'm scared to write it), but the official language is
English.

>Thanks,
>Martin
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R search page:               http://finzi.psych.upenn.edu/



From HaroldD at ccsso.org  Fri May 28 15:22:48 2004
From: HaroldD at ccsso.org (Harold Doran)
Date: Fri, 28 May 2004 09:22:48 -0400
Subject: [R] Merging nlme output
Message-ID: <CFF85773D9245040A333571B7E6D651702C5FD46@ccssosrv1.ccsso.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040528/5a0ebe4c/attachment.pl

From laura at env.leeds.ac.uk  Fri May 28 14:54:46 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Fri, 28 May 2004 13:54:46 +0100 (BST)
Subject: [R] Adding key to simple plot() function
In-Reply-To: <BCDCAA61.87EE%sdavis2@mail.nih.gov>
Message-ID: <Pine.LNX.4.44.0405281344520.3942-100000@env-pc-phd13>

I already tried this but encountered a number of problems - firstly the
point labels overlie the actual points meaning the labels are
unreadable..and I was hoping to have a separate key within which to
describe the labels, is this feasible?



On Fri, 28 May 2004, Sean Davis wrote:

> Laura,
>
> For your axis issues, look at plotting without axes [plot(....,axes=F) and
> then see ?axis for making them on your own.  As for labeling your data, look
> at ?points and ?text.
>
> Sean
>
> On 5/28/04 8:27 AM, "Laura Quinn" <laura at env.leeds.ac.uk> wrote:
>
> > I am generating a simple x,y plot to show geographical positions where
> > point data has been taken. Rather than plot a graph and lay points on top
> > I've opted to generate the map from the point data, ie plot(-x,-y). This
> > works fine, though I am wanting to label each point 1:20 and have a key
> > alongside - is this possible without getting into trellis plots? I have
> > very limited time available so don't want to embark on trellis functions
> > which I've never used before..
> >
> > Also, my x,y  labels currently have a negative sign in front of them which
> > I'd like to remove, but if I negate the labels they no longer fit on the
> > graph as my data points are -x and -y...
> >
> > Any suggestions?
> >
> > Thanks,
> > Laura
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>
>



From bates at stat.wisc.edu  Fri May 28 16:05:45 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 28 May 2004 09:05:45 -0500
Subject: [R] Crossed random effects in lme
In-Reply-To: <005d01c44419$f9e5e1c0$8276f9c3@djf.agrsci.dk>
References: <005d01c44419$f9e5e1c0$8276f9c3@djf.agrsci.dk>
Message-ID: <6rekp4sl3a.fsf@bates4.stat.wisc.edu>

S??ren H??jsgaard <sorenh at agrsci.dk> writes:

> Dear all,
> In the SASmixed package there is an example of an analysis of a split-plot experiment. The model is
> 
>   fm1Semi <- lme( resistance ~ ET * position, data = Semiconductor, random = ~ 1 | Grp)
> 
> where Grp in the Semiconductor dataset is defined as ET*Wafer. Is it possible to specify the grouping directly some way, e.g. like 
> 
>   fm1Semi <- lme( resistance ~ ET * position, data = Semiconductor, random = ~ 1 | ET*Wafer)

Actually that does work with lme from the as-yet-unreleased version
0.6-1 of the lme4 package.  See the slides from my presentation at
useR!2004
 http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Bates.pdf

I'm back at my home now and will endeavor to get lme4_0.6-1 released
as soon as possible.

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From rossini at blindglobe.net  Fri May 28 16:05:19 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 28 May 2004 07:05:19 -0700
Subject: [R] orca binary?
In-Reply-To: <40B6F583.9030800@statistik.uni-dortmund.de> (Uwe Ligges's
	message of "Fri, 28 May 2004 10:17:07 +0200")
References: <BAY12-F117SK7b9m5PJ0003662e@hotmail.com>
	<40B6F583.9030800@statistik.uni-dortmund.de>
Message-ID: <853c5kve8w.fsf@servant.blindglobe.net>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

> Laura Holt wrote:
>
>> Dear R People:
>> Is there a binary version for rorca, please?
>
>
> Given I recall correctly, I tried to build rorca for Windows one or
> two years ago without success. But maybe Tony (In this context I
> recall that I'm still owing him a pizza) knows of a binary?

Hah.  I should swing by and collect next week.

Seriously, you should be able to do a source install or a quick build
(I probably could do one later today using the Linux cross-compiler),
since it's just raw R code.

If someone does it before I do, let me know.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From duncan at wald.ucdavis.edu  Fri May 28 16:09:17 2004
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Fri, 28 May 2004 07:09:17 -0700
Subject: [R] any simple examples for SJAVA please
In-Reply-To: <5.0.2.1.2.20040528150243.00abc940@ensam.inra.fr>
References: <BAY12-F92nENMgbHMm300037073@hotmail.com>
	<5.0.2.1.2.20040528150243.00abc940@ensam.inra.fr>
Message-ID: <20040528140917.GA2143@wald.ucdavis.edu>


The SJava package is a very flexible and general bidirectional
interface between R and Java that can allow not only 
simple data and complex data structures to be passed between
the languages, but also references to objects
including using R functions as Java methods.  Other approaches
to inter-system interfaces are much simpler and direct
but as  a result are more limited for general computation.
There is a great deal of infrastructure under SJava that makes
it a general Java interpreter. 
And building a variety of different communication mechanisms
to R really ignores the existng literature  in the subject.

Unfortunately, there are more opinions about the SJava
package than people who actually understand the issues.
At the moment, what is a real problem is that 
there isn't a significant culture for people
to help package authors distribute Windows binaries,
but more that Windows users require software
without any additional effort.
Unfortunately, I do not have the time to keep my Windows machine upgraded for service
packages, virus software, etc. simply to create binaries for
Windows users that I currently do not need.   

I would be very happy to work with someone who uses Windows
and wanted to take on providing binaries. I can 
both explain and simplify the build process
(dropping the support for S-Plus).  But it is prohibitive
to spend all my time supporting the Omegahat packages and R  on numerous platforms
while still doing research so that people have fresh ideas in 5 years time.
There is a real danger that statistical computing research will become
bogged down servicing currrent needs of users and extending 
concepts that were research topics 20 years ago  rather than
working on new concepts that will needed for the future.

So I am hoping that one or more people can volunteer to 
help with maintaining the Windows port.
It is definitely not trivial as the SJava package is more complex
in nature (and implemenation) than  many others, but it is 
feasible.


  D.

  





Vincent MUTEAUD wrote:
> Hi,
> like you I'm trying to use SJava and I meet with many difficulties.
> I try to run examples from "Calling R from Java" written by Duncan Temple 
> Lang available from http://www.omegahat.org/SJava (there are many examples 
> on this web site).
> Now I have an error that my R version is R 1.6.1 while I have version 1.9.0 
> on windows NT. This causes a crash when I run my Java code:
> fatal error: enable to open the  base package
> I still waiting for a solution
> Best
> 
> A 07:58 28/05/2004 -0500, Laura Holt a ??crit :
> >Hi!
> >
> >Are there any simple examples for SJAVA please?
> >
> >Thanks,
> >Laura
> >R Version 1.9.0 Windows
> >
> >_________________________________________________________________
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> >http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

-- 
Duncan Temple Lang                        duncan at wald.ucdavis.edu
 371, Kerr Hall
 University of California at Davis

Phone: (530) 752-4782
FAX:   (530) 752-7099



From joseclaudio.faria at terra.com.br  Fri May 28 16:28:30 2004
From: joseclaudio.faria at terra.com.br (=?Windows-1252?Q?Jos=E9_Cl=E1udio_Faria?=)
Date: Fri, 28 May 2004 11:28:30 -0300
Subject: [R] ANOVA and contrasts 
Message-ID: <006101c444c0$13a6e1d0$01fea8c0@sapetinga>

Dear FZ

In one way I have not problem...

The problem arise to establish the contrasts for 2 way with interactions and I desire the SS of each one of the
contrasts.

Thanks,

Jos Cludio Faria
UESC/DCET
Brasil
73-634.2779
joseclaudio.faria at terra.com.br
jc_faria at uol.com.br



From macq at llnl.gov  Fri May 28 16:34:59 2004
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 28 May 2004 07:34:59 -0700
Subject: [R] axis.POSIXct: Datetime data and plotting
In-Reply-To: <E2AD017CFE22764998D37A6026B8A01D46B3C8@exchsrv1.cheo.int>
References: <E2AD017CFE22764998D37A6026B8A01D46B3C8@exchsrv1.cheo.int>
Message-ID: <p06002008bcdcfb8e1396@[128.115.153.6]>

At 2:10 PM -0400 5/27/04, Barrowman, Nick wrote:
>But is there any easy way to avoid this problem?  It is confusing 
>and inconvenient that axis.POSIXct(1,d,format=f) and 
>axis.POSIXct(3,at=d,format=f) give seemingly contradictory scales.

In one case you provide the locations of the tick marks, in the other 
case you let the function decide the locations. Why, in general, 
would anyone expect the two to be the same? (And that applies 
regardless of whether we're dealing with datetime values; the regular 
axis() function doesn't always give me tick marks at locations that I 
prefer.)

Gabor Grothendieck's suggestion to use the Date class instead of 
POSIXt is a good one.

-Don

At 2:10 PM -0400 5/27/04, Barrowman, Nick wrote:
>I've run into a problem with the datetime axis generated by 
>axis.POSIXct.  It appears a similar issue was discussed in October 
>2003 under the subject line "datetime data and plotting" (see 
>https://stat.ethz.ch/pipermail/r-help/2003-October/039071.html), but 
>I wasn't able to determine whether there is a straightforward 
>solution.
>
>The code below produces a graph with apparently contradictory date 
>labels on the top and bottom axes:
>
>f <- "%Y/%m/%d"
>d <- as.POSIXct(strptime(c("2003/1/15","2003/1/16",
>   "2003/1/17","2003/1/18","2003/1/19"),format=f))
>plot(d,1:length(d),axes=F);box()
>axis(2)
>abline(v=d[3])
>axis.POSIXct(1,d,format=f)
>axis.POSIXct(3,at=d,format=f)
>
>On my copy of R (I have appended the version information below my 
>signature), this produces a graph with a vertical line that lines up 
>with "2003/01/17" on the top axis, but not on the bottom axis.
>
>The issue seems to relate to time zones: here's what d looks like on 
>my computer:
>
>>  d
>[1] "2003-01-15 Eastern Standard Time"
>[2] "2003-01-16 Eastern Standard Time"
>[3] "2003-01-17 Eastern Standard Time"
>[4] "2003-01-18 Eastern Standard Time"
>[5] "2003-01-19 Eastern Standard Time"
>
>(Actually I'm on Eastern Daylight Time, but let's ignore that for now.)
>
>Changing the axes to display not only the date but also the time 
>shows what's going on:
>
>f <- "%Y/%m/%d"
>f2 <- "%Y-%m-%d %H:%M"
>d <- as.POSIXct(strptime(c("2003/1/15","2003/1/16",
>   "2003/1/17","2003/1/18","2003/1/19"),format=f))
>plot(d,1:length(d),axes=F);box()
>axis(2)
>abline(v=d[3])
>axis.POSIXct(1,d,format=f2)
>axis.POSIXct(3,at=d,format=f2)
>
>The bottom axis put the ticks at 19:00 on each date.  This seems an 
>odd time until you note that Eastern Standard Time is 5 hours behind 
>UTC, so 19:00 EST is 00:00 UTC.
>
>But is there any easy way to avoid this problem?  It is confusing 
>and inconvenient that axis.POSIXct(1,d,format=f) and 
>axis.POSIXct(3,at=d,format=f) give seemingly contradictory scales.
>
>Many thanks for any help!
>
>Nick Barrowman, Ph.D.
>Chief Biostatistician, Chalmers Research Group
>Children's Hospital of Eastern Ontario Research Institute
>401 Smyth Road, Ottawa, Ontario, K1H 8L1, Canada
>Tel   (613) 737-7600 ext. 3971
>Fax   (613) 738-4800
>Email nbarrowman at cheo.on.ca
>URL   www.chalmersresearch.com
>
>
>>  version
>          _             
>platform i386-pc-mingw32
>arch     i386          
>os       mingw32       
>system   i386, mingw32 
>status                 
>major    1             
>minor    9.0           
>year     2004          
>month    04            
>day      12            
>language R
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From c.wallace at qmul.ac.uk  Fri May 28 17:07:24 2004
From: c.wallace at qmul.ac.uk (Chris Wallace)
Date: Fri, 28 May 2004 16:07:24 +0100
Subject: [R] simulate dependent probabilities
Message-ID: <m3r7t4bnf7.fsf@qmul.ac.uk>

I need to simulate from a random process and am not sure how to go
about it.  The process is the probability of an event occuring between
a pair of points on a line. (This probability is between 0 and 0.5).

I have estimates of these probabilities for a series of points, their
standard errors and the correlation matrix (which is AR(1)).  Eg (for
4 points)

             estimated prob (q):   0.1163  0.1280  0.0698

                 standard error:   0.0320  0.0288  0.0259

  asymptotic correlation matrix:   1.0000
                                  -0.0880  1.0000
                                   0.0000 -0.0739  1.0000

The vector q is used in a further analysis, treated as known.  I would
like to simulate alternative vectors q, which could be used in the
further analysis in order to generate some empirical confidence
interval.  But I don't know where to start with such simulation.  (In
practice, q has about 50 elements).

Although I know how to use cholesky decomposition to simulate
dependent variables from a MVN distribution, I am stuck on two counts
here:
- the distribution for q
- how to incorporate the dependence into the simulation.

I would appreciate any suggestions.

Chris.



From Amer.Siddique at ssa.gov  Fri May 28 17:31:17 2004
From: Amer.Siddique at ssa.gov (Siddique, Amer)
Date: Fri, 28 May 2004 10:31:17 -0500
Subject: [R] RE: SCO & R
Message-ID: <F151C5EFCA66314D9FE66CB7199F4AADE0F20B@sad6cd1.ch.ssa.gov>

SCO is grasping for straws. and is now gasping. vexatious lawsuits will only
drive so far before puttering out. eventually the curtain gets pulled back
on glorified attempts at racketeering. cheers.


Message: 76
Date: Thu, 27 May 2004 21:08:12 -0500
From: Deepayan Sarkar <deepayan at stat.wisc.edu>
Subject: Re: [R] SCO & R
To: r-help at stat.math.ethz.ch
Message-ID: <200405272108.12664.deepayan at stat.wisc.edu>
Content-Type: text/plain;  charset="iso-8859-1"

On Thursday 27 May 2004 20:18, Greg Tarpinian wrote:

> Actually, it was very recent.  I pulled the electronic version of the 
> article from the Forbes website:

I would think twice before taking forbes articles too seriously. For 
instance, they seem to think that protecting intellectual property 
rights are all right when it's some big commercial company doing the 
protecting, but not when they are on the other side of the table. See 
this article from last year:

http://www.forbes.com/2003/10/14/cz_dl_1014linksys.html



From Melanie.Pelegrini at imed.jussieu.fr  Sat May 29 01:44:20 2004
From: Melanie.Pelegrini at imed.jussieu.fr (=?ISO-8859-1?Q?M=E9lanie_PELEGRINI-ISSAC?=)
Date: Sat, 29 May 2004 01:44:20 +0200
Subject: [R] Build R-1.9.0 with static libraries ?
In-Reply-To: <40ABBDC1.5040309@imed.jussieu.fr>
References: <Pine.LNX.4.44.0405191238210.1246-100000@gannet.stats>
	<40ABBDC1.5040309@imed.jussieu.fr>
Message-ID: <40B7CED4.608@imed.jussieu.fr>

I am still unable to build a binary for R (linux Red Hat 9 distribution) 
which would be self-consistent (without shared objects and use of 
dynamics librairies).

I would be very grateful if someone could explain and/or help me...


> 
>> so please set MAIN_LD as it suggests (and that's why I quoted the 
>> whole thing for you to read!)
>>
> 
  OK, I've set MAIN_LD to 'gcc -Bstatic'
  but now 'make' fails for the following reason:


  Error in dyn.load(x, as.logical(local), as.logical(now)) :
      unable to load shared library
  "$BuildDir/library/methods/libs/methods.so":
    $BuildDir/library/methods/libs/methods.so: undefined symbol: R_GlobalEnv
  Execution halted
  Error in dyn.load(x, as.logical(local), as.logical(now)) :
      unable to load shared library "$BuildDir/library/stats/libs/stats.so":
    $BuildDir/library/stats/libs/stats.so: undefined symbol: R_GlobalEnv
  Execution halted
  Error in dyn.load(x, as.logical(local), as.logical(now)) :
      unable to load shared library "$BuildDir/library/tools/libs/tools.so":
    $BuilDir/library/tools/libs/tools.so: undefined symbol: R_NaString
  Error: couldn't find function ".installPackageNamespaceInfo"
  In addition: Warning message:
  package tools in options("defaultPackages") was not found
  Execution halted



  So I'm afraid I'm still missing a flag somewhere... I'm sorry but I'm
  not used compiling such packages so I cannot figure out where I made a
  mistake.

  Thanks again for your patience :-(

  Melanie


-- 
Me'lanie PELEGRINI-ISSAC         tel : (33 0)1 53 82 84 20
Unite' 483 INSERM		fax : (33 0)1 53 82 84 48
9, quai Saint-Bernard           email :Melanie.Pelegrini at imed.jussieu.fr
Bat C 6e etage 75005 PARIS



From luisr at frs.fo  Fri May 28 17:58:58 2004
From: luisr at frs.fo (Luis Rideau Cruz)
Date: Fri, 28 May 2004 16:58:58 +0100
Subject: [R] How to insert a bitmap in a grph device
Message-ID: <s0b76fdc.066@ffdata.setur.fo>

If I have a plot and I want to insert a bitmap in the same device,,,,how to do it?

Thank you

Luis Ridao Cruz
Fiskiranns??knarstovan
N??at??n 1
P.O. Box 3051
FR-110 T??rshavn
Faroe Islands
Phone:             +298 353900
Phone(direct): +298 353912
Mobile:             +298 580800
Fax:                 +298 353901
E-mail:              luisr at frs.fo
Web:                www.frs.fo



From gunter.berton at gene.com  Fri May 28 18:04:54 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 28 May 2004 09:04:54 -0700
Subject: [R] RE: SCO & R
References: <F151C5EFCA66314D9FE66CB7199F4AADE0F20B@sad6cd1.ch.ssa.gov>
Message-ID: <40B76326.B0AA24A7@gene.com>

My $.02 (sorry, couldn't resist).

This is but one skirmish in the whole vexatious battle on "intellectual property
rights," which extends from software to many other venues, one of the most
interesting of which is patents on human genes. An example I heard on the radio
this morning was eHarmony.com patenting their algorithm for matchmaking, which,
the commentator said, is based on a 431 item questionnaire (yet another reason to
celebrate my long marriage; 431 questions -- yikes!) ! Needless to say, the
potential fodder for editorializing both for and against this intrusion of
"scientific method" into romance seems limitless. Do you think support vector
machines or neural nets lurk in the background of their "algorithm"?

Anyway, the only predictions that I think it safe to make are: (1) We have only
begun to fight -- and, yes, seeming samaritans (or is it samurai?) like R and GPL
may yet have to engage; (2) advances in technology will only turn the heat up and
pose yet more problems, as we move relentlessly from "thingy" inventions running
our world to 'idea-y" inventions running it.

Matchmaking, anyone?

(Thanks for your indulgence).

Cheers,
Bert

"Siddique, Amer" wrote:

> SCO is grasping for straws. and is now gasping. vexatious lawsuits will only
> drive so far before puttering out. eventually the curtain gets pulled back
> on glorified attempts at racketeering. cheers.
>
> Message: 76
> Date: Thu, 27 May 2004 21:08:12 -0500
> From: Deepayan Sarkar <deepayan at stat.wisc.edu>
> Subject: Re: [R] SCO & R
> To: r-help at stat.math.ethz.ch
> Message-ID: <200405272108.12664.deepayan at stat.wisc.edu>
> Content-Type: text/plain;  charset="iso-8859-1"
>
> On Thursday 27 May 2004 20:18, Greg Tarpinian wrote:
>
> > Actually, it was very recent.  I pulled the electronic version of the
> > article from the Forbes website:
>
> I would think twice before taking forbes articles too seriously. For
> instance, they seem to think that protecting intellectual property
> rights are all right when it's some big commercial company doing the
> protecting, but not when they are on the other side of the table. See
> this article from last year:
>
> http://www.forbes.com/2003/10/14/cz_dl_1014linksys.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

--

Bert Gunter

Non-Clinical Biostatistics
Genentech
MS: 240B
Phone: 650-467-7374


"The business of the statistician is to catalyze the scientific learning
process."

 -- George E.P. Box



From anoly16b at hotmail.com  Fri May 28 18:05:36 2004
From: anoly16b at hotmail.com (anoly)
Date: Fri, 28 May 2004 12:05:36 -0400
Subject: [R] how to pass defined function with more than one arguments to
	apply?
References: <40B31F9C.6080305@biometria.univr.it>
Message-ID: <SEA2-DAV23yPCTsc7Ke000248d3@hotmail.com>

Dear all:
I meet a problem of apply function. I have a matrix called tb
>tb
   V1 V2 V3
1   0  3  1
2   1  4  0
3   0  3  0
4   0  4  0
5   0  3  1
6   1  4  1
7   1  1  0
8   1  3  0
9   0  1  1
10  0  3  1

I hope to get the number of row that match c(0,3,1)
I do this way:
>length(apply(t(tb) = = c (0,3,1), 2, all))
 I defined a funtion, compare<-function(vector1, vector2){...}. For example,
compare(1:3, 1:3) will return TRUE. compare(1:3,2:4) return FALSE.
Then I hope to call  apply(tb,1,compare). But this can not work, because
apply only pass one argument to compare function. Does anyone know how to
solve this problem?

Thanks so much.
Anoly



From wolski at molgen.mpg.de  Fri May 28 18:15:55 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 28 May 2004 18:15:55 +0200
Subject: [R] how to pass defined function with more than one
	arguments to apply?
In-Reply-To: <SEA2-DAV23yPCTsc7Ke000248d3@hotmail.com>
References: <40B31F9C.6080305@biometria.univr.it>
	<SEA2-DAV23yPCTsc7Ke000248d3@hotmail.com>
Message-ID: <200405281815550100.07505291@mail.math.fu-berlin.de>

Hi!

?apply
...: optional arguments to 'FUN'.

you can pass more arguments to your function.
length(apply(tb,comare,c(0,3,1)))


Sincerely
Eryk.

*********** REPLY SEPARATOR  ***********

On 5/28/2004 at 12:05 PM anoly wrote:

>Dear all:
>I meet a problem of apply function. I have a matrix called tb
>>tb
>   V1 V2 V3
>1   0  3  1
>2   1  4  0
>3   0  3  0
>4   0  4  0
>5   0  3  1
>6   1  4  1
>7   1  1  0
>8   1  3  0
>9   0  1  1
>10  0  3  1
>
>I hope to get the number of row that match c(0,3,1)
>I do this way:
>>length(apply(t(tb) = = c (0,3,1), 2, all))
> I defined a funtion, compare<-function(vector1, vector2){...}. For
>example,
>compare(1:3, 1:3) will return TRUE. compare(1:3,2:4) return FALSE.
>Then I hope to call  apply(tb,1,compare). But this can not work, because
>apply only pass one argument to compare function. Does anyone know how to
>solve this problem?
>
>Thanks so much.
>Anoly
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From edd at debian.org  Fri May 28 18:19:47 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 28 May 2004 11:19:47 -0500
Subject: [R] How to insert a bitmap in a grph device
In-Reply-To: <s0b76fdc.066@ffdata.setur.fo>
References: <s0b76fdc.066@ffdata.setur.fo>
Message-ID: <20040528161947.GA26681@sonny.eddelbuettel.com>

On Fri, May 28, 2004 at 04:58:58PM +0100, Luis Rideau Cruz wrote:
> If I have a plot and I want to insert a bitmap in the same device,,,,how to do it?

IIRC the pixmap package on CRAN helps with that.

Dirk

-- 
FEATURE:  VW Beetle license plate in California



From thpe at hhbio.wasser.tu-dresden.de  Fri May 28 18:28:43 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 28 May 2004 18:28:43 +0200
Subject: [R] How to insert a bitmap in a grph device
In-Reply-To: <s0b76fdc.066@ffdata.setur.fo>
References: <s0b76fdc.066@ffdata.setur.fo>
Message-ID: <40B768BB.9080908@hhbio.wasser.tu-dresden.de>

Luis Rideau Cruz wrote:
> If I have a plot and I want to insert a bitmap in the same device,,,,how to do it?

Yesterday we have learned, how to load and plot jpeg images (see: Is it 
possible to read jpeg files into R?) Now you need a way to insert this 
into another figure. For this purpose the grid and gridBase packages can 
be applied, which is explained in an article from Paul Murrel in R-News 
02/2003 and in his lecture at the useR! conference, see:

http://cran.r-project.org/doc/Rnews/

and

http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/


useR! Thomas P.



From thpe at hhbio.wasser.tu-dresden.de  Fri May 28 18:34:51 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 28 May 2004 18:34:51 +0200
Subject: [R] How to insert a bitmap in a grph device
In-Reply-To: <20040528161947.GA26681@sonny.eddelbuettel.com>
References: <s0b76fdc.066@ffdata.setur.fo>
	<20040528161947.GA26681@sonny.eddelbuettel.com>
Message-ID: <40B76A2B.3080605@hhbio.wasser.tu-dresden.de>

Dirk Eddelbuettel wrote:

  > IIRC the pixmap package on CRAN helps with that.

Ah, I see, ?addlogo is much easier than grid in this case, as one sees 
in a (slightly modified) version of the help example:

x <- read.pnm(system.file("pictures/logo.ppm", package="pixmap")[1])
plot(sample(1:100))
for (i in 1:7)
   addlogo(x, px=c(0, (101/77)*11), py=c((i-1)*11, i*11), asp=1)


Thank you

Thomas P.



From Ted.Harding at nessie.mcc.ac.uk  Fri May 28 18:33:52 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 28 May 2004 17:33:52 +0100 (BST)
Subject: [R] Generate a sequence of random integer values
In-Reply-To: <003501c4444e$54c96880$c2e5fea9@oemcomputer>
Message-ID: <XFMail.040528173352.Ted.Harding@nessie.mcc.ac.uk>


On 28-May-04 Brian Davenhall wrote:
> I'm trying to generate a sequence of random integer values. I've
> tried to combine the random (r) and the sequence (seq) functions
> but this approach does not work.  For example, if I use the
> following command:
> 
>> a <- seq(1:100)
>> a
>   [1]   1   2   3   4   5   6   7   8   9  etc.
> 
> This is a good start, but what I really want is something that
> would look like this instead
> 
>  [1]  3 96 45 67 8 24 99 63 8, etc.
> 
> where the integer numbers between 1 and 100 are randomly chosen.
> 
> Any help would be great, I've found workarounds in other stat packages,
> but would prefer to do this in R.

(1:100)[sort(runif(100),index.return=TRUE)$ix]

37  99  22  66  12  36  90  48  55  45  98  59  92  20  46  23   2 74
80   5  63  27  56  60  51  76  39  87  19  96  29  15  18 100  52  3
70   8  67  42  43  57  91  21  25  78  41   1  34  68  77   9  72 73
11  89  83  94  65  13  14  81  24  58  35  44  10  79  50  49   6 28
17  33   4  71  82  31  75  30  85  93  26  69  38  84  32  54  64 53
88  61  86  97   7  62  95  47  16  40

but there may be a slicker way ...
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 28-May-04                                       Time: 17:33:52
------------------------------ XFMail ------------------------------



From rvalliant at survey.umd.edu  Fri May 28 18:53:51 2004
From: rvalliant at survey.umd.edu (Richard Valliant)
Date: Fri, 28 May 2004 12:53:51 -0400
Subject: [R] dotchart questions
Message-ID: <s0b7366f.016@SURVEYGWIA.UMD.EDU>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040528/8e8f86ca/attachment.pl

From kehler at mathstat.dal.ca  Fri May 28 18:54:48 2004
From: kehler at mathstat.dal.ca (Dan Kehler)
Date: Fri, 28 May 2004 13:54:48 -0300 (ADT)
Subject: [R] Negative binomial glm and dispersion
Message-ID: <Pine.GSO.3.96.1040528133631.18220B-100000@chase>


Using  R 1.8.1, and the negative binomial glm implemented in MASS, 
the default when using anova and a chi-square test is to divide the
deviance by the estimated dispersion.  Using my UNIX version of S-plus (v
3.4), and the same MASS functions, the deviances are *not* divided by the
estimated dispersion. 

Firstly, I'm wondering if anyone can enlighten about the correct procedure
(I thought the F-test was more appropriate when dispersion is estimated)? 

Secondly, after a bit of muddling with the negative binomial pdf, I
concluded that, like for the Poisson, phi is actually 1.  This result is
borne out by simulations. Is this correct?

# an example in R 1.81 with library(MASS) 
 y<-rnegbin(n=100,mu=1,theta=1)
 x<-1:length(y) 

 model<-glm(y~x,family=neg.bin(1))

 summary(model)$dispersion
 [1] 1.288926

 anova(model,test='Chisq")
#...
     Df Deviance Resid. Df Resid. Dev P(>|Chi|)
NULL                    99    102.038          
x     1    0.185        98    101.853     0.705

# But the "real" chi-square probability is 

  1-pchisq(0.185,1)
[1] 0.6671111


Thanks in advance, 

Dan 

____________________________________
Daniel Kehler
Dept. of Biology 
Dalhousie University, B3H 4J1
Halifax, Nova Scotia, Canada
Office: LSC 800
email: kehler at mscs.dal.ca 
phone: 902 494 3910



From wolski at molgen.mpg.de  Fri May 28 18:56:21 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 28 May 2004 18:56:21 +0200
Subject: [R] Is there a way to represent the ... argument in signature?
Message-ID: <200405281856210125.07755657@mail.math.fu-berlin.de>

Hi!

I guess that it cant work. but maybee I am wrong.
I would like to define a function rbind.
> rbind
function (..., deparse.level = 1) 
{
which works only for objects of class Myclass

Is it possible to use something like
setMethod("rbind",signature(...="Myclass",deparse.level="numeric")
This gives an error. 
Or should I use
rbind.Myclass

Eryk.

Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From Ted.Harding at nessie.mcc.ac.uk  Fri May 28 18:57:56 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 28 May 2004 17:57:56 +0100 (BST)
Subject: [R] Generate a sequence of random integer values
In-Reply-To: <XFMail.040528173352.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.040528175756.Ted.Harding@nessie.mcc.ac.uk>

On 28-May-04 Ted Harding wrote:
>
> (1:100)[sort(runif(100),index.return=TRUE)]
> 
> 37  99  22  66  12  36  90  48  55  45  98  59  92  20  46  23   2 74
> 80   5  63  27  56  60  51  76  39  87  19  96  29  15  18 100  52  3
> 70   8  67  42  43  57  91  21  25  78  41   1  34  68  77   9  72 73
> 11  89  83  94  65  13  14  81  24  58  35  44  10  79  50  49   6 28
> 17  33   4  71  82  31  75  30  85  93  26  69  38  84  32  54  64 53
> 88  61  86  97   7  62  95  47  16  40
> 
> but there may be a slicker way ...
> Ted.

Of course there is (if what you want in random order is (1:100))
since that's what

  sort(runif(100),index.return=TRUE)$ix

gives you anyway, and the initial (1;100) is redundant!

However, if it's some other set X of 100 items that you want in
random order then

  X[sort(runif(100),index.return=TRUE)$ix]

is indeed what you need.

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 28-May-04                                       Time: 17:57:56
------------------------------ XFMail ------------------------------



From ggrothendieck at myway.com  Fri May 28 19:27:00 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 28 May 2004 17:27:00 +0000 (UTC)
Subject: [R] Is there a way to represent the ... argument in signature?
References: <200405281856210125.07755657@mail.math.fu-berlin.de>
Message-ID: <loom.20040528T192551-794@post.gmane.org>


Have a look at rbind.zoo in the zoo package for an example.


Wolski <wolski <at> molgen.mpg.de> writes:

: 
: Hi!
: 
: I guess that it cant work. but maybee I am wrong.
: I would like to define a function rbind.
: > rbind
: function (..., deparse.level = 1) 
: {
: which works only for objects of class Myclass
: 
: Is it possible to use something like
: setMethod("rbind",signature(...="Myclass",deparse.level="numeric")
: This gives an error. 
: Or should I use
: rbind.Myclass
: 
: Eryk.
: 
: Dipl. bio-chem. Eryk Witold Wolski     <at>     MPI-Moleculare Genetic   
: Ihnestrasse 63-73 14195 Berlin       'v'    
: tel: 0049-30-83875219               /   \    
: mail: wolski <at> molgen.mpg.de        ---W-W----    
http://www.molgen.mpg.de/~wolski



From rossini at blindglobe.net  Fri May 28 19:31:58 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 28 May 2004 10:31:58 -0700
Subject: [R] orca binary?
In-Reply-To: <853c5kve8w.fsf@servant.blindglobe.net> (A. J. Rossini's
	message of "Fri, 28 May 2004 07:05:19 -0700")
References: <BAY12-F117SK7b9m5PJ0003662e@hotmail.com>
	<40B6F583.9030800@statistik.uni-dortmund.de>
	<853c5kve8w.fsf@servant.blindglobe.net>
Message-ID: <85ekp4jw4x.fsf@servant.blindglobe.net>


I cross compiled it.  If someone wants to donate a pre-configured
Windows computer to my research group, I could test it.  Else, someone
else will have to.  I can't.

It is  http://www.analytics.washington.edu/~rossini/rorca/rorca.zip

best,
-tony


rossini at blindglobe.net (A.J. Rossini) writes:

> Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
>
>> Laura Holt wrote:
>>
>>> Dear R People:
>>> Is there a binary version for rorca, please?
>>
>>
>> Given I recall correctly, I tried to build rorca for Windows one or
>> two years ago without success. But maybe Tony (In this context I
>> recall that I'm still owing him a pizza) knows of a binary?
>
> Hah.  I should swing by and collect next week.
>
> Seriously, you should be able to do a source install or a quick build
> (I probably could do one later today using the Linux cross-compiler),
> since it's just raw R code.
>
> If someone does it before I do, let me know.
>
> best,
> -tony
>
> -- 
> rossini at u.washington.edu            http://www.analytics.washington.edu/ 
> Biomedical and Health Informatics   University of Washington
> Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
> UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
> FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email
>
> CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From martin.klaffenboeck at gmx.at  Fri May 28 19:48:55 2004
From: martin.klaffenboeck at gmx.at (Martin Klaffenboeck)
Date: Fri, 28 May 2004 19:48:55 +0200
Subject: [R] Sorting Data?
In-Reply-To: <20040528131858.GA8410@psych> (from baron@psych.upenn.edu on Fr,
	Mai 28, 2004 at 15:18:58 +0200)
References: <20040527195847.GE4890@martin.kleinerdrache.org>
	<20040527204302.GA7557@psych>
	<20040528102142.GE4117@martin.kleinerdrache.org>
	<20040528131858.GA8410@psych>
Message-ID: <20040528174855.GC3509@martin.kleinerdrache.org>

Am 28.05.2004 15:18:58 schrieb(en) Jonathan Baron:

> >Also the other things.
> >
> >I have to test the hypothesis:  Does a daugther answer the questions
> >(semantic differential) more equal the own mother and more different
> to
> >the mothers of the other daugthers.
> 
> I don't think this is a trivial problem at all, so I am hesitant
> to offer advice.  I see now that you reall do want a matrix,
> where you have mothers in the columns and daughters in the rows,
> and distance (difference, similarity) measures in the cells.
> Perhaps you have several such measures, so you want a
> three-dimensional array.

Hm.  I don't know.  I tried the following:

Creating a new Variable by:

Fbg[['F.gesamt']] <- rowSums(Fbg[11:27], na.rm=TRUE)

Which contains everything from F01 to F17 as sum().

Than I do the thing to split mothers from daugthers as you told me.   
The next step i get:

dist(Muetter['F.gesamt'] - Toechter['F.gesamt'])

Which gives me some output, where I am not sure what it is.  ;-(

But it looks like the thing I want, but I think I don't really have the  
right data inside.

> You might do something like this.  First define a function to
> measure your distance, like
> 
> Itemdist <- function(x,y) {sum(abs(x[-(1:4)]-y[-(1:4)]))}
> 
> Dists <- matrix(NA,nrow(Daughters),nrow(Mothers))
> 
> for (i in 1:nrow(Daughters)
>  {for (j in 1:nrow(Mothers))
>   {Dists[i,j] <- Itemdist(Daughters[i,],Mothers[j,])}}

Hm. I get some syntax errors inside this.  If you want you can have my  
small sample I'm now createing a source file about.  There I have 12  
mother daugther pairs.  I will get about 20 pairs within the next two  
months, but then I will have my source file (loading by source("file. 
R")) ready.  The small sample is just to work now.

Thanks for your help,
Martin



From spencer.graves at pdf.com  Fri May 28 19:51:23 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 28 May 2004 10:51:23 -0700
Subject: [R] RE: SCO & R
In-Reply-To: <40B76326.B0AA24A7@gene.com>
References: <F151C5EFCA66314D9FE66CB7199F4AADE0F20B@sad6cd1.ch.ssa.gov>
	<40B76326.B0AA24A7@gene.com>
Message-ID: <40B77C1B.4060506@pdf.com>

      The intellectual property questions raised by the GNU General 
Public License (GPL) are under active discussion in PDF Solutions, where 
Sundar Dorai-Raj and I work.  Sundar and I have recommended linking PDF 
commercial software to R.  However, we have to be careful how we do 
this, because the GPL requires that the source for "all derivative 
works" be made public.  Unfortunately, it seems unclear exactly what 
constitutes a "derivative work", although the GPL states that it does 
not apply to "independent and separate works ... when you distribute 
them as separate works." 

       Does anyone have information on this, beyond the groklaw and 
Forbes items already mentioned?  For example, are there good examples to 
follow, or are all the published case studies negative like those 
already been mentioned? 

      It seems to me that a commercial company could comply with the GPL 
without jeopardizing its ability to pay employees and stockholders by 
distributing its  software in two, separately installed pieces:  The 
first would provide the base, commercial, proprietary software under a 
commercial license.  The second would include all components distributed 
under the GPL license, and would add capabilities to the first.  I think 
something like this would benefit both the R Foundation and commercial 
software distributors.  However, our legal department has yet to rule on 
this, and our management is not eager to move without the blessing of 
our corporate legal. Therefore, more solid information, published case 
studies, etc., would help. 

      Thanks,
      spencer graves

Berton Gunter wrote:

>My $.02 (sorry, couldn't resist).
>
>This is but one skirmish in the whole vexatious battle on "intellectual property
>rights," which extends from software to many other venues, one of the most
>interesting of which is patents on human genes. An example I heard on the radio
>this morning was eHarmony.com patenting their algorithm for matchmaking, which,
>the commentator said, is based on a 431 item questionnaire (yet another reason to
>celebrate my long marriage; 431 questions -- yikes!) ! Needless to say, the
>potential fodder for editorializing both for and against this intrusion of
>"scientific method" into romance seems limitless. Do you think support vector
>machines or neural nets lurk in the background of their "algorithm"?
>
>Anyway, the only predictions that I think it safe to make are: (1) We have only
>begun to fight -- and, yes, seeming samaritans (or is it samurai?) like R and GPL
>may yet have to engage; (2) advances in technology will only turn the heat up and
>pose yet more problems, as we move relentlessly from "thingy" inventions running
>our world to 'idea-y" inventions running it.
>
>Matchmaking, anyone?
>
>(Thanks for your indulgence).
>
>Cheers,
>Bert
>
>"Siddique, Amer" wrote:
>
>  
>
>>SCO is grasping for straws. and is now gasping. vexatious lawsuits will only
>>drive so far before puttering out. eventually the curtain gets pulled back
>>on glorified attempts at racketeering. cheers.
>>
>>Message: 76
>>Date: Thu, 27 May 2004 21:08:12 -0500
>>From: Deepayan Sarkar <deepayan at stat.wisc.edu>
>>Subject: Re: [R] SCO & R
>>To: r-help at stat.math.ethz.ch
>>Message-ID: <200405272108.12664.deepayan at stat.wisc.edu>
>>Content-Type: text/plain;  charset="iso-8859-1"
>>
>>On Thursday 27 May 2004 20:18, Greg Tarpinian wrote:
>>
>>    
>>
>>>Actually, it was very recent.  I pulled the electronic version of the
>>>article from the Forbes website:
>>>      
>>>
>>I would think twice before taking forbes articles too seriously. For
>>instance, they seem to think that protecting intellectual property
>>rights are all right when it's some big commercial company doing the
>>protecting, but not when they are on the other side of the table. See
>>this article from last year:
>>
>>http://www.forbes.com/2003/10/14/cz_dl_1014linksys.html
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>    
>>
>
>--
>
>Bert Gunter
>
>Non-Clinical Biostatistics
>Genentech
>MS: 240B
>Phone: 650-467-7374
>
>
>"The business of the statistician is to catalyze the scientific learning
>process."
>
> -- George E.P. Box
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From rwang at math.ucalgary.ca  Fri May 28 19:52:58 2004
From: rwang at math.ucalgary.ca (Rui)
Date: Fri, 28 May 2004 11:52:58 -0600
Subject: [R] How could I find R.exp?
Message-ID: <001001c444dc$9c86f280$f63d9f88@math.ucalgary.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040528/69c94ebd/attachment.pl

From dmurdoch at pair.com  Fri May 28 20:02:08 2004
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 28 May 2004 14:02:08 -0400
Subject: [R] How could I find R.exp?
In-Reply-To: <001001c444dc$9c86f280$f63d9f88@math.ucalgary.ca>
References: <001001c444dc$9c86f280$f63d9f88@math.ucalgary.ca>
Message-ID: <ufveb0hmvtu88cr2usdfuq0jbvbtjngcup@4ax.com>

On Fri, 28 May 2004 11:52:58 -0600, "Rui" <rwang at math.ucalgary.ca>
wrote :

>Hi all,
> 
>I try to create an import library for using dll. Following the
>instruction in the readme.package, I used the command "lib /def:R.exp
>/out:Rdll.lib", however, the error message showed "Cannot open file
>R.exp". I downloaded the source code R-1.9.0.tgz, but I can not find
>R.exp. Thanks!

It's not part of the source code, it's produced when R is built, and
should be in the src/gnuwin32 directory, as long as you chose to
install "Source Package Installation Files".

Duncan Murdoch



From spencer.graves at pdf.com  Fri May 28 20:02:25 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 28 May 2004 11:02:25 -0700
Subject: [R] gauss.hermite?
In-Reply-To: <20040528082609.GA840@localhost>
References: <40B6C17C.9000003@pdf.com>	<00b001c44482$1489f800$ad133a86@www.domain>
	<20040528082609.GA840@localhost>
Message-ID: <40B77EB1.2080505@pdf.com>

      Thanks to Andy Liaw, Marc Schwartz, Dimitris Rizopoulos and Tamas 
Papp for quick replies.  Before I sent the email, I found that it was 
written by Jim Lindsey, but I could not find further information on him, 
so I appreciate the links.  Also, the Advanced Statistical Computing 
course notes look quite interesting.  In particular, the function 
"gaulag" providing "Gauss-Laguerre" may help with a related problem, 
taking expected values with respect to gamma distributions.  (Laguerre 
polynomials are orthogonal with respect to the a gamma distribution, and 
perform the same role as Hermite polynomials relative to a normal 
distribution.) 

      Thanks again.  spencer graves

Tamas Papp wrote:

>On Fri, May 28, 2004 at 09:04:53AM +0200, Dimitris Rizopoulos wrote:
>  
>
>>Dear Spencer,
>>
>>In Dr. Gray's course notes for Advanced Statistical Computing
>>(Appendix of Chapter 6) there are some functions for computing
>>abscissas and corresponding weights for several Gaussian integration
>>rules:
>>
>>http://icommons.harvard.edu/~hsph-bio248-01/Lecture_Notes/
>>    
>>
>
>Also have a look at 
>
>@Book{judd98,
>  author =       {Judd, Kenneth L},
>  title =        {Numerical methods in economics},
>  publisher =    {MIT Press},
>  year =         1998
>}
>
>especially one of the early chapters ("integration" is in its title,
>but I don't have the book at the moment), which covers theory and
>practice of numerical integration and quadrature rules.
>
>Implementing these in R has been on my TODO list for a while, so I
>would be happy to cooperate on this (but only in July or later).
>
>Best,
>
>Tamas
>
>  
>



From zhuw at mail.smu.edu  Fri May 28 20:11:01 2004
From: zhuw at mail.smu.edu (Zhu Wang)
Date: Fri, 28 May 2004 13:11:01 -0500
Subject: [R] Problem: creating shared objects using lapack and blas
In-Reply-To: <200405281003.i4SA2sO4000900@hypatia.math.ethz.ch>
References: <200405281003.i4SA2sO4000900@hypatia.math.ethz.ch>
Message-ID: <1085767860.2209.16.camel@zwang.stat.smu.edu>

I am having trouble with creating shared objects with Fortran files,
which use numerical libraries Lapack and Blas. I have read the section
in "Writing R Extensions" but could not find what I needed and I am not
at the stage to create a library.

What I did was 

$R CMD SHLIB --output=car file1.f file2.f ... file50.f -llapack -lblas

No error message so far,

But

$>dyn.load("./car")
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
	unable to load shared library "/home/zwang/R/pkg/car/src/./car":
  /home/zwang/R/pkg/car/src/./car: undefined symbol: slamch_

I think the way I used to link Lapack and Blas was not correct, even
though it worked fine when I used for running Fortran code before.

Thanks for any advice.

Zhu Wang

Statistical Science Department
Southern Methodist University
Dallas, TX 75275-0332



From jdd at greatschools.net  Fri May 28 20:30:30 2004
From: jdd at greatschools.net (John David Duncan)
Date: Fri, 28 May 2004 11:30:30 -0700 (PDT)
Subject: [R] intro statistics course in San Francisco bay area
Message-ID: <Pine.OSX.4.52.0405281123380.403@dh8.office.greatschools.net>


I'm in San Francisco looking for a basic statistics course...
using R.  I'll be using R for real work later on, so I'd prefer
not to have to do the coursework with some other software.

All leads are appreciated...

Thanks,

- JD



From ccleland at optonline.net  Fri May 28 21:10:30 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 28 May 2004 15:10:30 -0400
Subject: [R] dotchart questions
In-Reply-To: <s0b7366f.016@SURVEYGWIA.UMD.EDU>
References: <s0b7366f.016@SURVEYGWIA.UMD.EDU>
Message-ID: <40B78EA6.8010602@optonline.net>

   Instead of dotchart, you might try a lattice dotplot after 
restructuring the data.

FACT1 <- vector("character", 15)

for(i in 1:15){
     FACT1[i] <- paste(rep(LETTERS[i], 20), collapse ="")}

mydata <- data.frame(FACT1 = rep(FACT1, 9),
              FACT2 = rep(c("E", "F", "G"), c(15, 15, 15)),
              RESPVAL = runif(45*3),
              RESPVAR = rep(c("V1", "V2", "V3"), c(45, 45, 45)))

library(lattice)

trellis.device(width=11, height=8.5, new = FALSE, col = FALSE,
              bg = "white")

dotplot(FACT1 ~ RESPVAL | RESPVAR * FACT2, data = mydata,
              between = list(x = 0.5, y = 0))

hope this helps,

Chuck Cleland

Richard Valliant wrote:
> I am trying to put 3 dotcharts side-by-side with minimal space between
> each.  Each chart is for a different variable, but the vertical axes are
> the same. 
>  
> I want to have vertical axis labels on the lefthand chart but no
> vertical axis labels on the other two. Plus, I would like very little
> space between charts 1 & 2 and between charts 2 & 3.
>  
> I have one approach but am not too happy with the results. A stripped
> down version of the code is below. Matrix A has the row labels (which
> are about 20 characters long in the real data). Matrix A1 has no row
> labels.
>  
>  
> A <- matrix(1:12, ncol=3, byrow=F)
> A1 <- A
> dimnames(A) <- list(letters[1:4], letters[5:7])
> dimnames(A1) <- list(rep("",4), rep("",3))
>  
> par(mfrow = c(1,3), mgp = c(1.75, 1, 0.5), mar = c(3, 0, 1.5, 0), oma =
> c(2,2,2,2))
>  
> dotchart(A)
> dotchart(A1)
> dotchart(A1)
> 
> Two questions:
> (1) Is there a way with par or something else to make the charts closer
> together.
> (2) With a lot of rows (45 in the real data) is there a way to control
> row spacing (other than getting rid of some rows).

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From tapo at novozymes.com  Fri May 28 21:10:47 2004
From: tapo at novozymes.com (TAPO (Thomas Agersten Poulsen))
Date: Fri, 28 May 2004 21:10:47 +0200
Subject: [R] Converting data frame to array?
Message-ID: <76F96CFE2AA2114C886B028A065A7FC402074E81@exdkba020.novo.dk>

Dear List,

	Please bear with a poor newbee, who might be doing everything
backwards (I was brought up in pure math).

	I want to make a simple multi-linear regression on a set of
data. I did some expreiments, and if X is a 4 by 2 array and Y is a 4 by
1 array, I can do a linear regression by lm(y~x). 

	Now I have a tab-delimited text file with 10 rows of 300
measurements and an other file with 10 rows of one value each. When I
read in those files using read.delim(), I get data frames, and
apparently I can no longer do the multi-linear regression.

	Is there a way to convert the data frames into arrays, or am I
going the wrong way about this?

Sincerely
Thomas Poulsen



From rwang at math.ucalgary.ca  Fri May 28 21:18:15 2004
From: rwang at math.ucalgary.ca (Rui)
Date: Fri, 28 May 2004 13:18:15 -0600
Subject: [R] About creating an import library
Message-ID: <001701c444e8$86930520$f63d9f88@math.ucalgary.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040528/12329fac/attachment.pl

From wwsprague at ucdavis.edu  Fri May 28 21:22:22 2004
From: wwsprague at ucdavis.edu (wwsprague@ucdavis.edu)
Date: Fri, 28 May 2004 12:22:22 -0700
Subject: [R] vector normal to a plane
Message-ID: <c983hm$nc0$1@sea.gmane.org>

Hi All,

(I have a degree in math, but I am too embarassed to ask my colleagues, 
so here goes:)

I would like to get a vector normal (orthogonal) to a plane formed by 
two other vectors.  In matlab I do this:

v1 = [.4, .6, .8]; v2 = [.9, .7, .2]; nn = cross(v1,v2) (gives ~[-.48, 
.65, -.24]

if I do R> cross(v1, v2), I get .94.  Huh?

Thanks for all your help, again.

W



From wolski at molgen.mpg.de  Fri May 28 21:33:06 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 28 May 2004 21:33:06 +0200
Subject: [R] vector normal to a plane
In-Reply-To: <c983hm$nc0$1@sea.gmane.org>
References: <c983hm$nc0$1@sea.gmane.org>
Message-ID: <200405282133060585.0804D73B@mail.math.fu-berlin.de>

Hi!
In which library is this function?
I cant find it using help.search() on my R installation.
Eryk

*********** REPLY SEPARATOR  ***********

On 5/28/2004 at 12:22 PM wwsprague at ucdavis.edu wrote:

>Hi All,
>
>(I have a degree in math, but I am too embarassed to ask my colleagues, 
>so here goes:)
>
>I would like to get a vector normal (orthogonal) to a plane formed by 
>two other vectors.  In matlab I do this:
>
>v1 = [.4, .6, .8]; v2 = [.9, .7, .2]; nn = cross(v1,v2) (gives ~[-.48, 
>.65, -.24]
>
>if I do R> cross(v1, v2), I get .94.  Huh?
>
>Thanks for all your help, again.
>
>W
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From wwsprague at ucdavis.edu  Fri May 28 21:34:35 2004
From: wwsprague at ucdavis.edu (wwsprague@ucdavis.edu)
Date: Fri, 28 May 2004 12:34:35 -0700
Subject: [R] (Correction) vector normal to a plane
In-Reply-To: <c983hm$nc0$1@sea.gmane.org>
References: <c983hm$nc0$1@sea.gmane.org>
Message-ID: <c9848h$pag$1@sea.gmane.org>


> 
> if I do R> cross(v1, v2), I get .94.  Huh?

Meant to say "R> crossprod(v1, v2)"

Sorry



From ligges at statistik.uni-dortmund.de  Fri May 28 22:40:22 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 May 2004 22:40:22 +0200
Subject: [R] vector normal to a plane
In-Reply-To: <c983hm$nc0$1@sea.gmane.org>
References: <c983hm$nc0$1@sea.gmane.org>
Message-ID: <40B7A3B6.8030202@statistik.uni-dortmund.de>

wwsprague at ucdavis.edu wrote:
> Hi All,
> 
> (I have a degree in math, but I am too embarassed to ask my colleagues, 
> so here goes:)
> 
> I would like to get a vector normal (orthogonal) to a plane formed by 
> two other vectors.  In matlab I do this:
> 
> v1 = [.4, .6, .8]; v2 = [.9, .7, .2]; nn = cross(v1,v2) (gives ~[-.48, 
> .65, -.24]

Huh?

I don't have access to Matlab. Can you tell me how cross() is defined in 
Matlab (it's not obvious to me - at least not at 10:40 pm - how can 
anything get negative)?


> 
> if I do R> cross(v1, v2), I get .94.  Huh?

Ha! ;-)

crossprod(v1, v2):
0.4*0.9 + 0.6*0.7 + 0.8*0.2 = 0.94

Uwe Ligges



> Thanks for all your help, again.
> 
> W
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From thpe at hhbio.wasser.tu-dresden.de  Fri May 28 22:55:16 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 28 May 2004 22:55:16 +0200
Subject: [R] Converting data frame to array?
In-Reply-To: <76F96CFE2AA2114C886B028A065A7FC402074E81@exdkba020.novo.dk>
References: <76F96CFE2AA2114C886B028A065A7FC402074E81@exdkba020.novo.dk>
Message-ID: <40B7A734.8030009@hhbio.wasser.tu-dresden.de>

TAPO (Thomas Agersten Poulsen) wrote:


> 	Is there a way to convert the data frames into arrays, or am I
> going the wrong way about this?

This is possible, but the behaviour depends on the datatype, e.g. 
numeric or character. Simply look for ?as.matrix or ?as.array

Thomas P.



From ligges at statistik.uni-dortmund.de  Fri May 28 23:35:27 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 May 2004 23:35:27 +0200
Subject: [R] vector normal to a plane
In-Reply-To: <40B7A3B6.8030202@statistik.uni-dortmund.de>
References: <c983hm$nc0$1@sea.gmane.org>
	<40B7A3B6.8030202@statistik.uni-dortmund.de>
Message-ID: <40B7B09F.4010006@statistik.uni-dortmund.de>

Uwe Ligges wrote:

> wwsprague at ucdavis.edu wrote:
> 
>> Hi All,
>>
>> (I have a degree in math, but I am too embarassed to ask my 
>> colleagues, so here goes:)
>>
>> I would like to get a vector normal (orthogonal) to a plane formed by 
>> two other vectors.  In matlab I do this:
>>
>> v1 = [.4, .6, .8]; v2 = [.9, .7, .2]; nn = cross(v1,v2) (gives ~[-.48, 
>> .65, -.24]
> 
> 
> Huh?
> 
> I don't have access to Matlab. Can you tell me how cross() is defined in 
> Matlab (it's not obvious to me - at least not at 10:40 pm - how can 
> anything get negative)?

My apologies - and thanks to Rolf Turner who told me the truth (well, I 
anticipated that it's getting too late this friday evening).

OK, I don't think what you are looking for is defined as a function in 
R. Anyway, for the 3D case it's pretty easy to write the result in one 
line of code ...

Uwe


> 
> 
>>
>> if I do R> cross(v1, v2), I get .94.  Huh?
> 
> 
> Ha! ;-)
> 
> crossprod(v1, v2):
> 0.4*0.9 + 0.6*0.7 + 0.8*0.2 = 0.94
> 
> Uwe Ligges
> 
> 
> 
>> Thanks for all your help, again.
>>
>> W
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From tlumley at u.washington.edu  Fri May 28 23:55:48 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 28 May 2004 14:55:48 -0700 (PDT)
Subject: [R] vector normal to a plane
In-Reply-To: <40B7A3B6.8030202@statistik.uni-dortmund.de>
References: <c983hm$nc0$1@sea.gmane.org>
	<40B7A3B6.8030202@statistik.uni-dortmund.de>
Message-ID: <Pine.A41.4.58.0405281433000.25454@homer03.u.washington.edu>


W is looking for the vector cross product (a specifically
three-dimensional object important in physics and engineering). The
crossproduct() function provides a matrix product so that crossprod(x,y)
is t(x)%*%y, something completely different.

For the three-dimensional case you could define the cross and dot products

 "%x%"<-function(a,b) {c(a[2]*b[3]-a[3]*b[2], -a[1]*b[3]+a[3]*b[1],
a[1]*b[2]-a[2]*b[1])}

 "%.%%<-function(a,b) sum(a*b)


It would make sense, of course, to check that the arguments actually were
vectors of length 3.



	-thomas



From jfox at mcmaster.ca  Sat May 29 01:24:26 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 28 May 2004 19:24:26 -0400
Subject: [R] Converting data frame to array?
In-Reply-To: <76F96CFE2AA2114C886B028A065A7FC402074E81@exdkba020.novo.dk>
Message-ID: <20040528232426.RAOV24047.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Thomas,

In fact, the more common way to fit a linear regression in R is to use
variables in a data frame (or list) along with a model formula specifying
the model. All of this is explained in the Introduction to R manual that is
distributed with R: see, in particular, Sec. 6.3 on data frames, Sec. 7 on
reading data from files, and Sec. 11 on statistical models.

Given two data frames, say d1 and d2, the first containing, e.g.,
observations on variables x1 and x2 and the second on y, one could do lm(y ~
x1 + x2, data=c(x1, x2)) or lm(y ~ x1 + x2, data=data.frame(x1, x2)). 

That said, it's not altogether clear to me what it is that you're trying to
do. Are there 10 observations on 300 variables in the first data frame,
constituting the predictors, and 10 observations on 1 variable in the second
data frame, constituting the response? If so, you have many more predictors
than observations, and it's not reasonable to perform a regression. Of
course, I may not have this straight.

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of TAPO 
> (Thomas Agersten Poulsen)
> Sent: Friday, May 28, 2004 2:11 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Converting data frame to array?
> 
> Dear List,
> 
> 	Please bear with a poor newbee, who might be doing 
> everything backwards (I was brought up in pure math).
> 
> 	I want to make a simple multi-linear regression on a 
> set of data. I did some expreiments, and if X is a 4 by 2 
> array and Y is a 4 by
> 1 array, I can do a linear regression by lm(y~x). 
> 
> 	Now I have a tab-delimited text file with 10 rows of 
> 300 measurements and an other file with 10 rows of one value 
> each. When I read in those files using read.delim(), I get 
> data frames, and apparently I can no longer do the 
> multi-linear regression.
> 
> 	Is there a way to convert the data frames into arrays, 
> or am I going the wrong way about this?
> 
> Sincerely
> Thomas Poulsen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Sat May 29 01:31:32 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 28 May 2004 23:31:32 +0000 (UTC)
Subject: [R] vector normal to a plane
References: <c983hm$nc0$1@sea.gmane.org>
	<40B7A3B6.8030202@statistik.uni-dortmund.de>
	<Pine.A41.4.58.0405281433000.25454@homer03.u.washington.edu>
Message-ID: <loom.20040529T013001-346@post.gmane.org>

Thomas Lumley <tlumley <at> u.washington.edu> writes:

: 
: W is looking for the vector cross product (a specifically
: three-dimensional object important in physics and engineering). The
: crossproduct() function provides a matrix product so that crossprod(x,y)
: is t(x)%*%y, something completely different.
: 
: For the three-dimensional case you could define the cross and dot products
: 
:  "%x%"<-function(a,b) {c(a[2]*b[3]-a[3]*b[2], -a[1]*b[3]+a[3]*b[1],
: a[1]*b[2]-a[2]*b[1])}


Alternately, you could get the cofactors from solve:

cross3 <- function(a,b) {
	m <- cbind(a,b,1)
	solve(m)[3,]*det(m)
}



From Torsten.Steuernagel at gmx.de  Sat May 29 02:00:38 2004
From: Torsten.Steuernagel at gmx.de (Torsten Steuernagel)
Date: Sat, 29 May 2004 02:00:38 +0200
Subject: [R] "privileged slots"
In-Reply-To: <200405281509490996.06A5F816@mail.math.fu-berlin.de>
References: <40B671D8.20218.25D99F1@localhost>
Message-ID: <40B7EEC6.9051.2748A9B@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040529/6226c65c/attachment.pl

From spencer.graves at pdf.com  Sat May 29 02:32:53 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 28 May 2004 17:32:53 -0700
Subject: [R] GLMM error in ..1?
Message-ID: <40B7DA35.4000505@pdf.com>

      I'm trying to use GLMM in library(lme4), R 1.9.0pat, updated just 
now.  I get an error message I can't decipher: 

library(lme4)
set.seed(1)
n <- 10
N <- 1000
DF <- data.frame(yield=rbinom(n, N, .99)/N, nest=1:n)
fit <- GLMM(yield~1, random=~1|nest, family=binomial, data=DF,
              weights=rep(N, n))

Error in eval(expr, envir, enclos) : ..1 used in an incorrect context, 
no ... to look in

      Is there something I can do to get past this short of working 
through the code for GLMM line by line? 

      Also, I gather GLMM does not currently accept 
binomial(link="cloglog"): 

 > fit <- GLMM(1-yield~1, random=~1|nest, family=binomial(link="cloglog"),
+               data=DF,weights=rep(N, n))
Error in getClass(thisClass) : "family" is not a defined class
Error in GLMM(1 - yield ~ 1, random = ~1 | nest, family = binomial(link 
= "cloglog"),  :
    S language method selection got an error when called from internal 
dispatch for function "GLMM"
 >

      Thanks,
      spencer graves



From ggrothendieck at myway.com  Sat May 29 03:13:48 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 29 May 2004 01:13:48 +0000 (UTC)
Subject: [R] how to pass defined function with more than one arguments
	=?utf-8?b?dG8JYXBwbHk/?=
References: <40B31F9C.6080305@biometria.univr.it>
	<SEA2-DAV23yPCTsc7Ke000248d3@hotmail.com>
Message-ID: <loom.20040529T030832-660@post.gmane.org>


Not sure what you intend with regard to length but to get a logical
vector indicating which rows equal a particular vector:

f1 <- function(tb, row) apply(tb,1,function(x)all(x==row))

# or without using apply:

f2 <- function(tb, row) colSums( abs( (t(tb) - row) ) ) == 0

# or in terms of a general compare function:

f3 <- function(tb, row, compare = function(x)all(x==row)) apply(tb,1,compare)

row <- c(0,3,1)
f1(tb,row)
f2(tb,row)
f3(tb,row)

# If you want the number of matching rows:

length(which(f1(tb,row)))
etc.



anoly <anoly16b <at> hotmail.com> writes:

: 
: Dear all:
: I meet a problem of apply function. I have a matrix called tb
: >tb
:    V1 V2 V3
: 1   0  3  1
: 2   1  4  0
: 3   0  3  0
: 4   0  4  0
: 5   0  3  1
: 6   1  4  1
: 7   1  1  0
: 8   1  3  0
: 9   0  1  1
: 10  0  3  1
: 
: I hope to get the number of row that match c(0,3,1)
: I do this way:
: >length(apply(t(tb) = = c (0,3,1), 2, all))
:  I defined a funtion, compare<-function(vector1, vector2){...}. For example,
: compare(1:3, 1:3) will return TRUE. compare(1:3,2:4) return FALSE.
: Then I hope to call  apply(tb,1,compare). But this can not work, because
: apply only pass one argument to compare function. Does anyone know how to
: solve this problem?
: 
: Thanks so much.
: Anoly
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From spencer.graves at pdf.com  Sat May 29 04:11:07 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 28 May 2004 19:11:07 -0700
Subject: [R] glmmPQL: 
Message-ID: <40B7F13B.7040301@pdf.com>

      I'm getting a strange error from glmmPQL.  Consider the following 
sample code: 

set.seed(8)
N. <- 1000
z <- rnorm(N.)
pr.good <- exp(-1e-4*exp(2+2*z))
quantile(pr.good)
DF. <- data.frame(yield=rbinom(N., N., pr.good)/N.,
       Offset=rep(-10, N.), nest=1:N.)
fit <- glmmPQL(fixed=1-yield~offset(Offset), random=~1|nest,
       family=binomial(link="cloglog"),
       data=DF., weights=rep(N., N.))

      Using R 1.9.0pat, Windows 2000, with MASS updated just a few hours 
ago, I get the following error: 

iteration 1
iteration 2
Error in logLik.reStruct(object, conLin) :
    NA/NaN/Inf in foreign function call (arg 3)

      Any suggestions? 

      Best Wishes,
      Spencer Graves



From deepayan at stat.wisc.edu  Sat May 29 04:40:20 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 28 May 2004 21:40:20 -0500
Subject: [R] GLMM error in ..1?
In-Reply-To: <40B7DA35.4000505@pdf.com>
References: <40B7DA35.4000505@pdf.com>
Message-ID: <200405282140.21024.deepayan@stat.wisc.edu>


Is this the new experimental lme4 (version 0.6-x) ? If so, this is due 
to an error in our use of method dispatch. It has been fixed in the 
development version, and there should be a new release in a few days.


On Friday 28 May 2004 19:32, Spencer Graves wrote:
>       I'm trying to use GLMM in library(lme4), R 1.9.0pat, updated
> just now.  I get an error message I can't decipher:
>
> library(lme4)
> set.seed(1)
> n <- 10
> N <- 1000
> DF <- data.frame(yield=rbinom(n, N, .99)/N, nest=1:n)
> fit <- GLMM(yield~1, random=~1|nest, family=binomial, data=DF,
>               weights=rep(N, n))
>
> Error in eval(expr, envir, enclos) : ..1 used in an incorrect
> context, no ... to look in
>
>       Is there something I can do to get past this short of working
> through the code for GLMM line by line?
>
>       Also, I gather GLMM does not currently accept
>
> binomial(link="cloglog"):
>  > fit <- GLMM(1-yield~1, random=~1|nest,
>  > family=binomial(link="cloglog"),
>
> +               data=DF,weights=rep(N, n))
> Error in getClass(thisClass) : "family" is not a defined class
> Error in GLMM(1 - yield ~ 1, random = ~1 | nest, family =
> binomial(link = "cloglog"),  :
>     S language method selection got an error when called from
> internal dispatch for function "GLMM"



From zhuw at mail.smu.edu  Sat May 29 07:13:30 2004
From: zhuw at mail.smu.edu (Zhu Wang)
Date: Sat, 29 May 2004 00:13:30 -0500
Subject: [R] Re: Problem: creating shared objects using lapack and blas
In-Reply-To: <1085767860.2209.16.camel@zwang.stat.smu.edu>
References: <200405281003.i4SA2sO4000900@hypatia.math.ethz.ch>
	<1085767860.2209.16.camel@zwang.stat.smu.edu>
Message-ID: <1085807609.4753.3.camel@zwang.stat.smu.edu>

To solve my own problem, it seems better to follow instructions in
"Writing R Extensions" to build a library. I am making progress.

Thanks,

Zhu Wang

Statistical Science Department
Southern Methodist University
Dallas, TX 75275-0332

On Fri, 2004-05-28 at 13:11, Zhu Wang wrote:
> I am having trouble with creating shared objects with Fortran files,
> which use numerical libraries Lapack and Blas. I have read the section
> in "Writing R Extensions" but could not find what I needed and I am not
> at the stage to create a library.
> 
> What I did was 
> 
> $R CMD SHLIB --output=car file1.f file2.f ... file50.f -llapack -lblas
> 
> No error message so far,
> 
> But
> 
> $>dyn.load("./car")
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
> 	unable to load shared library "/home/zwang/R/pkg/car/src/./car":
>   /home/zwang/R/pkg/car/src/./car: undefined symbol: slamch_
> 
> I think the way I used to link Lapack and Blas was not correct, even
> though it worked fine when I used for running Fortran code before.
> 
> Thanks for any advice.
> 
> Zhu Wang
> 
> Statistical Science Department
> Southern Methodist University
> Dallas, TX 75275-0332
--



From jari.oksanen at oulu.fi  Sat May 29 07:53:11 2004
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Sat, 29 May 2004 08:53:11 +0300
Subject: [R] distance in the function kmeans
Message-ID: <77E46C91-B134-11D8-B848-000A95C76CA8@oulu.fi>

My thread broke as I write this at home and there were no new messages 
on this subject after I got  home. I hope this still reaches interested 
parties.

There are several methods that find centroids (means) from distance 
data. Centroid clustering methods do so, and so does classic scaling 
a.k.a. metric multidimensional scaling a.k.a. principal co-ordinates 
analysis (in R function cmdscale the means are found in C function 
dblcen.c in R sources). Strictly this centroid finding only works with 
Euclidean distances, but these methods willingly handle any other 
dissimilarities (or distances). Sometimes this results in anomalies 
like upper levels being below lower levels in cluster diagrams or in 
negative eigenvalues in cmdscale. In principle, kmeans could do the 
same if she only wanted.

Is it correct to use non-Euclidean dissimilarities when Euclidean 
distances were assumed? In my field (ecology) we know that Euclidean 
distances are often poor, and some other dissimilarities have better 
properties, and I think it is OK to break the rules (or `violate the 
assumptions'). Now we don't know what kind of dissimilarities were used 
in the original post (I think I never saw this specified), so we don't 
know if they can be euclidized directly using ideas of Petzold or 
Simpson. They might be semimetric or other sinful dissimilarities, too. 
These would be bad in the sense Uwe Ligges wrote: you wouldn't get 
centres of Voronoi polygons in original space, not even non-overlapping 
polygons. Still they might work better than the original space (who 
wants to be in the original space when there are better spaces floating 
around?)

The following trick handles the problem euclidizing space implied by 
any dissimilarity meaasure (metric or semimetric). Here mdata is your 
original (rectangular) data matrix, and dis is any dissimilarity data:

tmp <- cmdscale(dis, k=min(dim(mdata))-1, eig=TRUE)
eucspace <- tmp$points[, tmp$eig > 0.01]

The condition removes axes with negative or almost-zero eigenvalues 
that you will get with semimetric dissimilarities.

Then just call kmeans with eucspace as argument. If your dis is 
Euclidean, this is only a rotation and kmeans of eucspace and mdata 
should be equal. For other types of dis (even for semimetric 
dissimilarity) this maps your dissimilarities onto Euclidean space 
which in effect is the same as performing kmeans with your original 
dissimilarity.

Cheers, jari oksanen
--
Jari Oksanen, Oulu, Finland



From Aurelie.Cohas at univ-lyon1.fr  Sat May 29 10:45:43 2004
From: Aurelie.Cohas at univ-lyon1.fr (Aurelie.Cohas@univ-lyon1.fr)
Date: Sat, 29 May 2004 10:45:43 +0200 (CEST)
Subject: [R] multiple nesting levels in GEE
Message-ID: <1085820343.40b84db7dcce3@webmail.univ-lyon1.fr>

 Hello,

I'm actually trying to fit a gee model with 2 nesting levels since I expect a 
correlation between all members of a litter at a first level and between all 
individuals sharing a mother at a second superior level with an exchangeable 
matrix. I order my dataframe by both mother and litter

I try several syntaxes:
id= mother*litter which give the same correlation matrix as id= litter*mother
and id=litter with a matrix size of 7*7 which correspond to the maximum number of 
young per litter

id=litter|mother which give the same correlation matrix as id=mother|litter with 
a correlation matrix size of 235*235 which correspond to the number of 
observations

id=litter/mother and id=mother/litter give different result with a strange matrix 
of 11*11 with no 1 on the diagonal

If anybody know if it is possible to construct nesting levels in R and what is 
the good syntax for this kind of model?

Thanks in advance


Aur??lie Cohas



From internet at seesen.de  Sat May 29 13:57:34 2004
From: internet at seesen.de (internet@seesen.de)
Date: Sat, 29 May 2004 11:57:34 +0000
Subject: [R] eTrust Antivirus Gateway SMTP: Virus notification message
Message-ID: <20040529095500.D00F432CD54@mail-gw.eenet.de>

eTrust Antivirus Gateway SMTP on ci2000
detected a virus infection in an e-mail from
r-help at hypatia.math.ethz.ch.

Infected attachment(s):

	[your_document.zip] infected by Virus [Win32/Netsky.P.ZIP.Trojan]
	[document.txt                                                   
?qB] in your_document.zip infected by Virus [Win32/Netsky.P.Worm]

Action taken:

	The e-mail was blocked

The header for the e-mail message includes this information:

	Received: from uhura.eenet.de (212.184.21.33) by CI2000 (62.138.240.249)
	Received: from seesen.de (pD95EBA68.dip.t-dialin.net [217.94.186.104])
		by mail-gw.eenet.de ((i386)) with ESMTP id 284E332CD54
		for <info at seesen.de>; Sat, 29 May 2004 11:54:49 +0200 (CEST)
	From: r-help at lists.r-project.org
	To: info at seesen.de
	Subject: Shocking document
	Date: Sat, 29 May 2004 11:54:50 +0200
	MIME-Version: 1.0
	Content-Type: multipart/mixed;
		boundary="----=_NextPart_000_0016----=_NextPart_000_0016"
	X-Priority: 3
	X-MSMail-Priority: Normal
	Message-Id: <20040529095449.284E332CD54 at mail-gw.eenet.de>



From tlumley at u.washington.edu  Sat May 29 18:12:03 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 29 May 2004 09:12:03 -0700 (PDT)
Subject: [R] multiple nesting levels in GEE
In-Reply-To: <1085820343.40b84db7dcce3@webmail.univ-lyon1.fr>
References: <1085820343.40b84db7dcce3@webmail.univ-lyon1.fr>
Message-ID: <Pine.A41.4.58.0405290905390.148958@homer07.u.washington.edu>

On Sat, 29 May 2004 Aurelie.Cohas at univ-lyon1.fr wrote:

>  Hello,
>
> I'm actually trying to fit a gee model with 2 nesting levels since I expect a
> correlation between all members of a litter at a first level and between all
> individuals sharing a mother at a second superior level with an exchangeable
> matrix. I order my dataframe by both mother and litter

The gee() function does not compute this correlation structure (because
no-one has implemented it).  I don't think other software implements it
either, although people keep pointing out that it would be useful.

  This need not matter -- the point of GEE is that the correlation
structure is not important for validity of inference (although it may
affect efficiency).  If you are fitting a linear model I would recommend
lme(), otherwise you should just be able to use an exchangeable model at
the largest clustering size.

	-thomas


> I try several syntaxes:
> id= mother*litter which give the same correlation matrix as id= litter*mother
> and id=litter with a matrix size of 7*7 which correspond to the maximum number of
> young per litter
>
> id=litter|mother which give the same correlation matrix as id=mother|litter with
> a correlation matrix size of 235*235 which correspond to the number of
> observations
>
> id=litter/mother and id=mother/litter give different result with a strange matrix
> of 11*11 with no 1 on the diagonal
>
> If anybody know if it is possible to construct nesting levels in R and what is
> the good syntax for this kind of model?
>
> Thanks in advance
>
>
> Aur??lie Cohas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From lschwei at ucla.edu  Sat May 29 18:26:23 2004
From: lschwei at ucla.edu (Lisa Schweitzer)
Date: Sat, 29 May 2004 09:26:23 -0700
Subject: [R] Rhelp: Need help interpreting plots in spatstat 
Message-ID: <20040529092623250975.GyazMail.lschwei@ucla.edu>

Hello everybody--

I have been playing with my data in spatstat, and what I'd like to 
present is a basic exploratory spatial analysis. I have used the 
following code, using a ppp.object called tsdspoints.  The code 
develops the simulations and the envelopes I want, but  I don't 
understand my first plot here, the [tsds.ghat.short$r, 
tsds.ghat.short$raw]...I cobbled together this code from some class 
examples used by a prof of mine, and I don't really know how to 
interpret what is going on. The subsequent lines, I'm pretty sure, 
represent the empirical Ghat and the simulation envelope...but that 
first plot stumps me. 

You can see a pdf of the resulting plot if you download it from my 
website : www.bol.ucla.edu/~lschwei/sample.pdf WARNING: this is 
immediate download. 

THE CODE: ######

ghat.env <- function(n, s, r, win=owin(myOwin){
hold <- matrix(0, s, length(r))
for(i in 1:s){
hold[i,] <- Gest(runifpoint(n, win=myOwin), r=r)$raw
}
mn <- apply(hold, 2, mean)
Up <- apply(hold, 2, max)
Down <- apply(hold, 2, min)
return(data.frame(mn, Up, Down))
}
tsds.ghat <- Gest(tsdspoints)
tsds.ghat.short <- tsds.ghat[tsds.ghat$r <= .15, ]
tsds.cdf <- 1-exp(-40*pi*(tsds.ghat.short$r^2))
plot(tsds.ghat.short$r, tsds.ghat.short$raw, xlab="Distance (degrees)", 
ylab="Ghat", main=" Transport, Storage, and Disposal sites (TSDs)")
lines(tsds.ghat.short$r, tsds.cdf)
tsds.env <- ghat.env(n=40, s=100, r=tsds.ghat$r)
tsds.env.short <- tsds.env[tsds.ghat$r <= .15, ]
lines(tsds.ghat.short$r, tsds.env.short$Up, lty=5)
lines(tsds.ghat.short$r, tsds.env.short$Down, lty=5)
###############

Many Thanks, 

Lisa
who was working on her stinking dissertation while everybody else was 
learning cool things in Vienna.



From anthony at darrouzet-nardi.net  Sat May 29 22:24:03 2004
From: anthony at darrouzet-nardi.net (Anthony Darrouzet-Nardi)
Date: Sat, 29 May 2004 13:24:03 -0700
Subject: [R] panel function in a conditioned lattice graphic
Message-ID: <p05210619bcde9a2dc4fb@[4.243.164.183]>

I'm trying to use plotting character to encode the variable "block" 
from my dataset in a conditioned lattice graphic (R 1.9.0 on Mac OS 
10.3.3). The data I'm using is the dataframe "dryoutcover" which is 
here (4k):

http://anthony.darrouzet-nardi.net/downloads/dryoutcover.Rdata

The code that generates my graphic almost correctly is as follows:

xyplot(coversage ~ dryout | year,
	data=dryoutcover,
	panel = function(x,y) {
		panel.lmline(x,y)
		one <- dryoutcover$block==1
		two <- dryoutcover$block==2
		thr <- dryoutcover$block==3
		fou <- dryoutcover$block==4
		fiv <- dryoutcover$block==5
		six <- dryoutcover$block==6
		grid.points(x[one], y[one], pch=49)
		grid.points(x[two], y[two], pch=50)
		grid.points(x[thr], y[thr], pch=51)
		grid.points(x[fou], y[fou], pch=52)
		grid.points(x[fiv], y[fiv], pch=53)
		grid.points(x[six], y[six], pch=54)
		}
	)

The only thing wrong is that this does not correctly encode blocks 5 
and 6, which only appear in the third year of the study, 2003 (the 
third panel of the graphic). It instead labels blocks 5 and 6 as 
blocks 1 and 2 as if another year had started over (but on the same 
panel). For example, the point farthest to the right in the third 
panel says "2" when I want it to say "6." When I do not condition by 
year, it correctly displays blocks 5 and 6.

How can I correct this in the conditioned graphic?

Anthony Darrouzet-Nardi



From osman.al.radi at utoronto.ca  Sat May 29 22:54:03 2004
From: osman.al.radi at utoronto.ca (Osman)
Date: Sat, 29 May 2004 16:54:03 -0400
Subject: [R] bar plot patterns
Message-ID: <001a01c445bf$136b3680$ac90148e@Toshi>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040529/a5d4e49c/attachment.pl

From deepayan at stat.wisc.edu  Sat May 29 23:33:14 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 29 May 2004 16:33:14 -0500
Subject: [R] panel function in a conditioned lattice graphic
In-Reply-To: <p05210619bcde9a2dc4fb@[4.243.164.183]>
References: <p05210619bcde9a2dc4fb@[4.243.164.183]>
Message-ID: <200405291633.14892.deepayan@stat.wisc.edu>

On Saturday 29 May 2004 15:24, Anthony Darrouzet-Nardi wrote:
> I'm trying to use plotting character to encode the variable "block"
> from my dataset in a conditioned lattice graphic (R 1.9.0 on Mac OS
> 10.3.3). The data I'm using is the dataframe "dryoutcover" which is
> here (4k):
>
> http://anthony.darrouzet-nardi.net/downloads/dryoutcover.Rdata
>
> The code that generates my graphic almost correctly is as follows:
>
> xyplot(coversage ~ dryout | year,
> 	data=dryoutcover,
> 	panel = function(x,y) {
> 		panel.lmline(x,y)
> 		one <- dryoutcover$block==1
> 		two <- dryoutcover$block==2
> 		thr <- dryoutcover$block==3
> 		fou <- dryoutcover$block==4
> 		fiv <- dryoutcover$block==5
> 		six <- dryoutcover$block==6
> 		grid.points(x[one], y[one], pch=49)
> 		grid.points(x[two], y[two], pch=50)
> 		grid.points(x[thr], y[thr], pch=51)
> 		grid.points(x[fou], y[fou], pch=52)
> 		grid.points(x[fiv], y[fiv], pch=53)
> 		grid.points(x[six], y[six], pch=54)
> 		}
> 	)
>
> The only thing wrong is that this does not correctly encode blocks 5
> and 6, which only appear in the third year of the study, 2003 (the
> third panel of the graphic). It instead labels blocks 5 and 6 as
> blocks 1 and 2 as if another year had started over (but on the same
> panel). For example, the point farthest to the right in the third
> panel says "2" when I want it to say "6." When I do not condition by
> year, it correctly displays blocks 5 and 6.
>
> How can I correct this in the conditioned graphic?

This probably happens because things like `one <- dryoutcover$block==1` 
are logical vectors as long as the total number of rows in the data 
frame, whereas x and y (which you subset using x[one], y[one]) are 
shorter (only those rows for a particular year). Consequently, the 
vector you are indexing and the indexing vector are not comparable.

I would suggest you use the feature meant for this sort of display, 
namely as:

xyplot(coversage ~ dryout | year, 
       data=dryoutcover, groups = block, pch = c(49:54))

Hope that helps,

Deepayan



From jimmcloughlin at earthlink.net  Sun May 30 00:21:22 2004
From: jimmcloughlin at earthlink.net (Jim McLoughlin)
Date: Sat, 29 May 2004 15:21:22 -0700
Subject: [R] cross-sectional density plot
In-Reply-To: <001701c444e8$86930520$f63d9f88@math.ucalgary.ca>
References: <001701c444e8$86930520$f63d9f88@math.ucalgary.ca>
Message-ID: <842F02C0-B1BE-11D8-A539-000393B2DF14@earthlink.net>

Hi,

I'm a newbie and am trying to figure out the following:

- I have an N x T panel of stock returns on (N stocks, T time periods), 
with some missing values
- I am able to plot the cross-sectional density of returns for a given 
time t
- I would like to create a surface plot that combines all of the cross 
sectional densities - any tips here?
- Also is there any type of kernel estimation that will smooth out this 
plot across time?  (As opposed to rougher aggregation of the individual 
density cross-sections).

Many thanks for any suggestions here.

Regards,

Jim M



From anthony at darrouzet-nardi.net  Sun May 30 03:18:00 2004
From: anthony at darrouzet-nardi.net (Anthony Darrouzet-Nardi)
Date: Sat, 29 May 2004 18:18:00 -0700
Subject: [R] panel function in a conditioned lattice graphic
Message-ID: <p0521061abcdedce26749@[4.243.164.183]>

>On Saturday 29 May 2004 15:24, Anthony Darrouzet-Nardi wrote:
>  > I'm trying to use plotting character to encode the variable "block"
>  > from my dataset in a conditioned lattice graphic (R 1.9.0 on Mac OS
>  > 10.3.3). The data I'm using is the dataframe "dryoutcover" which is
>  > here (4k):
>  >
>  > http://anthony.darrouzet-nardi.net/downloads/dryoutcover.Rdata
>  >
>  > The code that generates my graphic almost correctly is as follows:
>  >
>  > xyplot(coversage ~ dryout | year,
>  >         data=dryoutcover,
>  >         panel = function(x,y) {
>  >                 panel.lmline(x,y)
>  >                 one <- dryoutcover$block==1
>  >                 two <- dryoutcover$block==2
>  >                 thr <- dryoutcover$block==3
>  >                 fou <- dryoutcover$block==4
>  >                 fiv <- dryoutcover$block==5
>  >                 six <- dryoutcover$block==6
>  >                 grid.points(x[one], y[one], pch=49)
>  >                 grid.points(x[two], y[two], pch=50)
>  >                 grid.points(x[thr], y[thr], pch=51)
>  >                 grid.points(x[fou], y[fou], pch=52)
>  >                 grid.points(x[fiv], y[fiv], pch=53)
>  >                 grid.points(x[six], y[six], pch=54)
>  >                 }
>  >         )
>  >
>  > The only thing wrong is that this does not correctly encode blocks 5
>  > and 6, which only appear in the third year of the study, 2003 (the
>  > third panel of the graphic). It instead labels blocks 5 and 6 as
>  > blocks 1 and 2 as if another year had started over (but on the same
>  > panel). For example, the point farthest to the right in the third
>  > panel says "2" when I want it to say "6." When I do not condition by
>  > year, it correctly displays blocks 5 and 6.
>  >
>  > How can I correct this in the conditioned graphic?
>
>This probably happens because things like `one <- dryoutcover$block==1`
>are logical vectors as long as the total number of rows in the data
>frame, whereas x and y (which you subset using x[one], y[one]) are
>shorter (only those rows for a particular year). Consequently, the
>vector you are indexing and the indexing vector are not comparable.
>
>I would suggest you use the feature meant for this sort of display,
>namely as:
>
>xyplot(coversage ~ dryout | year,
>        data=dryoutcover, groups = block, pch = c(49:54))
>
>Hope that helps,
>
>Deepayan


Oh yes, that does indeed help. I should have thought of using 
"groups". And more importantly, thanks for explaining why the 
indexing method was not working.

I have a followup question. Suppose I want to encode two different 
variables within a panel: one variable encoded by plotting character 
and one variable encoded by symbol color (as if I could use two 
"groups" variables). The dataframe I discussed above also includes a 
variable called treatment. If I start with the existing code modified 
with your suggestions:

xyplot(coversage ~ dryout | year,
	data = dryoutcover,
	groups = block,
	panel = function(x,y, ...) {
		panel.lmline(x,y)
		panel.superpose(x,y,
			pch = 49:54,
			cex = rep(2,6),
			col = rep("black", 6), ...)
		}
	)

how could I make all of the symbols of one treatment red and all of 
the symbols of the other black while maintaining the encodings of 
block by plotting character? This would be a superbly useful 
technique as it would allow 4 dimensional data on a single panel 
(maybe even 5 using a point cloud!).

Anthony



From wang at galton.uchicago.edu  Sun May 30 03:24:37 2004
From: wang at galton.uchicago.edu (Yong Wang)
Date: Sat, 29 May 2004 20:24:37 -0500 (CDT)
Subject: [R] how to remove "." or replace it with NA?
In-Reply-To: <200405281003.i4SA2sOB000900@hypatia.math.ethz.ch>
References: <200405281003.i4SA2sOB000900@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0405292020180.9495@aitken.uchicago.edu>

Hi,all
a quick question
A larger file include many"." (stands for missing 
value) for variable, say, x. after
read in the file and assign it another name such as :

x1<-data$x

but x1 is always a facotor but not numerical. 

so How can I get a numeric vector from the read in data frame.
how can I replace those "." with "NA" to perform analysis.

thank you very much
best regards



From jfox at mcmaster.ca  Sun May 30 05:14:28 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 29 May 2004 23:14:28 -0400
Subject: [R] how to remove "." or replace it with NA?
In-Reply-To: <Pine.LNX.4.58.0405292020180.9495@aitken.uchicago.edu>
Message-ID: <20040530031428.WXD24047.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Yong Wang,

When you read the data with read.table, specify the argument na.strings=".".
See ?read.table for details.

I hope that this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yong Wang
> Sent: Saturday, May 29, 2004 8:25 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] how to remove "." or replace it with NA?
> 
> Hi,all
> a quick question
> A larger file include many"." (stands for missing
> value) for variable, say, x. after
> read in the file and assign it another name such as :
> 
> x1<-data$x
> 
> but x1 is always a facotor but not numerical. 
> 
> so How can I get a numeric vector from the read in data frame.
> how can I replace those "." with "NA" to perform analysis.
> 
> thank you very much
> best regards
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From wang at galton.uchicago.edu  Sun May 30 06:13:30 2004
From: wang at galton.uchicago.edu (Yong Wang)
Date: Sat, 29 May 2004 23:13:30 -0500 (CDT)
Subject: [R] What's wrong with this simple code???
In-Reply-To: <200405281003.i4SA2sOB000900@hypatia.math.ethz.ch>
References: <200405281003.i4SA2sOB000900@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0405292305340.10179@aitken.uchicago.edu>

Hi, all
I can not figure this out, please have a look and help me out.
thank you! 

Note: this is in SPLUS, not R.

I have following code
***********************************
modfit<-function(yir,yew, ft) {

n<-length(yew)
yew<-yew[1:(n-1)]

yy<-yir-ft
xx<-yew-ft

n<-length(xx)
xx0<-xx[2:n]
yy0 <-yy [2:n]

xx1<-xx[1:(n-1)]

fit <- garch(yy0~xx0 + xx1+var.in.mean, ~garch(1,1),cond.dist='ged')
summary(fit)
}

fs1hca<-modfit(s1hca.r, s1hca.ew, zfr)

**************error message is ***************

Problem in garch(yy0 ~ xx0 + xx1 + var.in.mean,  ~ ..: Object "xx0" not 
found Use traceback() to see the call stack

It is really weird, I  tried step by step, the code works,
but what's the problem with xx0,I can't figure it out.

thank you for any suggestion.

best regards
yong



From SamirMishra at cbuae.gov.ae  Sun May 30 06:02:51 2004
From: SamirMishra at cbuae.gov.ae (Samir Mishra)
Date: Sun, 30 May 2004 08:02:51 +0400
Subject: [R] how to remove "." or replace it with NA?
Message-ID: <211AD0070D42D1118C7B00A024FF19AE2EC0B1@AUHEXCH>

If the data file is in text format, is large with a lot of "."s, use sed.
It's MUCH faster than any other tool for this sort of thing.

-----Original Message-----
From: Yong Wang [mailto:wang at galton.uchicago.edu]
Sent: Sunday, May 30, 2004 05:25
To: r-help at stat.math.ethz.ch
Subject: [R] how to remove "." or replace it with NA?


Hi,all
a quick question
A larger file include many"." (stands for missing 
value) for variable, say, x. after
read in the file and assign it another name such as :

x1<-data$x

but x1 is always a facotor but not numerical. 

so How can I get a numeric vector from the read in data frame.
how can I replace those "." with "NA" to perform analysis.

thank you very much
best regards

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From fernando.pineda at jhu.edu  Sun May 30 06:23:16 2004
From: fernando.pineda at jhu.edu (Fernando Pineda)
Date: Sun, 30 May 2004 00:23:16 -0400
Subject: [R] R Wrappers for "scanf-like" c functions.
Message-ID: <a06020401bcdf0ecc06b1@[192.168.0.17]>

I'm having difficulty trying to figure out how to write an R wrapper 
for a C                                           function that has a 
"scanf-like" argument list. Recall that in C, functions like scanf() 
return their values through a variable number of arguments whose type 
and number is determined by a format string. In C this is handled by 
parsing the format string and then applying the types and functions 
declared in <stdarg.h>.  I've been banging my head against the wall 
for a few days trying to figure out how I might do such a thing. Does 
anyone know how to write an R wrapper for functions like this?

Thanks,

-- Fernando

-- 
Fernando Pineda
Associate Professor
Dept. of Molecular Microbiology & Immunology
Johns Hopkins Bloomberg School of Public Health
Room E5146
615 N. Wolfe St., Baltimore, MD 21205-2179
fernando.pineda at jhu.edu
443-287-3673 (office)
410-955-0105 (fax)
http://www.pinedalab.jhsph.edu



From wang at galton.uchicago.edu  Sun May 30 06:51:00 2004
From: wang at galton.uchicago.edu (Yong Wang)
Date: Sat, 29 May 2004 23:51:00 -0500 (CDT)
Subject: [R] how to remove "." or replace it with NA?
In-Reply-To: <211AD0070D42D1118C7B00A024FF19AE2EC0B1@AUHEXCH>
References: <211AD0070D42D1118C7B00A024FF19AE2EC0B1@AUHEXCH>
Message-ID: <Pine.LNX.4.58.0405292350290.10179@aitken.uchicago.edu>

Samir, can you give an example for the use of sed?



On Sun, 30 May 2004, Samir Mishra wrote:

> If the data file is in text format, is large with a lot of "."s, use sed.
> It's MUCH faster than any other tool for this sort of thing.
> 
> -----Original Message-----
> From: Yong Wang [mailto:wang at galton.uchicago.edu]
> Sent: Sunday, May 30, 2004 05:25
> To: r-help at stat.math.ethz.ch
> Subject: [R] how to remove "." or replace it with NA?
> 
> 
> Hi,all
> a quick question
> A larger file include many"." (stands for missing 
> value) for variable, say, x. after
> read in the file and assign it another name such as :
> 
> x1<-data$x
> 
> but x1 is always a facotor but not numerical. 
> 
> so How can I get a numeric vector from the read in data frame.
> how can I replace those "." with "NA" to perform analysis.
> 
> thank you very much
> best regards
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From tpapp at axelero.hu  Sun May 30 07:45:05 2004
From: tpapp at axelero.hu (Tamas Papp)
Date: Sun, 30 May 2004 07:45:05 +0200
Subject: [R] bar plot patterns
Message-ID: <20040530054505.GB1731@localhost>

On Sat, May 29, 2004 at 04:54:03PM -0400, Osman wrote:

> Dear R users,
> 
> Is there a package or function that can produce multiple fill
> patterns to be used instead of colors in barplots or pie charts?
> Shades of grey are difficult to differentiate if more than 3 to 5..

Install the RColorBrewer package.  Have a look at rcolorbrewer.org for
helpful advice on color schemes and their usage.

You may also find the density= parameter useful for shading areas in
plots, available in many plotting functions.

Best,

Tamas

-- 
Tam??s K. Papp
E-mail: tpapp at axelero.hu
Please try to send only (latin-2) plain text, not HTML or other garbage.



From deepayan at stat.wisc.edu  Sun May 30 09:14:02 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 30 May 2004 02:14:02 -0500
Subject: [R] panel function in a conditioned lattice graphic
In-Reply-To: <p0521061abcdedce26749@[4.243.164.183]>
References: <p0521061abcdedce26749@[4.243.164.183]>
Message-ID: <200405300214.02921.deepayan@stat.wisc.edu>

On Saturday 29 May 2004 20:18, Anthony Darrouzet-Nardi wrote:

> I have a followup question. Suppose I want to encode two different
> variables within a panel: one variable encoded by plotting character
> and one variable encoded by symbol color (as if I could use two
> "groups" variables). The dataframe I discussed above also includes a
> variable called treatment. If I start with the existing code modified
> with your suggestions:
>
> xyplot(coversage ~ dryout | year,
> 	data = dryoutcover,
> 	groups = block,
> 	panel = function(x,y, ...) {
> 		panel.lmline(x,y)
> 		panel.superpose(x,y,
> 			pch = 49:54,
> 			cex = rep(2,6),
> 			col = rep("black", 6), ...)
> 		}
> 	)
>
> how could I make all of the symbols of one treatment red and all of
> the symbols of the other black while maintaining the encodings of
> block by plotting character? This would be a superbly useful
> technique as it would allow 4 dimensional data on a single panel
> (maybe even 5 using a point cloud!).

I would use the same construct, forming a new grouping variable and 
using suitably modified pch and col arguments:

xyplot(coversage ~ dryout | year, data=dryoutcover, cex = 2, 
       groups = interaction(block, treatment), 
       pch = rep(49:54, 2), 
       col = rep(c('red', 'black'), each = 5))

(2 and 5 being the nlevels() of treatment and block respectively). You 
would also probably prefer factor(year) rather than year.

Deepayan



From ligges at statistik.uni-dortmund.de  Sun May 30 11:51:31 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 30 May 2004 11:51:31 +0200
Subject: [R] What's wrong with this simple code???
In-Reply-To: <Pine.LNX.4.58.0405292305340.10179@aitken.uchicago.edu>
References: <200405281003.i4SA2sOB000900@hypatia.math.ethz.ch>
	<Pine.LNX.4.58.0405292305340.10179@aitken.uchicago.edu>
Message-ID: <40B9AEA3.8080308@statistik.uni-dortmund.de>

Yong Wang wrote:

> Hi, all
> I can not figure this out, please have a look and help me out.
> thank you! 
> 
> Note: this is in SPLUS, not R.

Note 1: This mailing list is about R, not S-PLUS.

Note 2: Your code is not reproducible - we don't have the data.

I'd suggest that you repost your question including an easily 
reproducible example on the S-News mailing list.

Uwe Ligges


> I have following code
> ***********************************
> modfit<-function(yir,yew, ft) {
> 
> n<-length(yew)
> yew<-yew[1:(n-1)]
> 
> yy<-yir-ft
> xx<-yew-ft
> 
> n<-length(xx)
> xx0<-xx[2:n]
> yy0 <-yy [2:n]
> 
> xx1<-xx[1:(n-1)]
> 
> fit <- garch(yy0~xx0 + xx1+var.in.mean, ~garch(1,1),cond.dist='ged')
> summary(fit)
> }
> 
> fs1hca<-modfit(s1hca.r, s1hca.ew, zfr)
> 
> **************error message is ***************
> 
> Problem in garch(yy0 ~ xx0 + xx1 + var.in.mean,  ~ ..: Object "xx0" not 
> found Use traceback() to see the call stack
> 
> It is really weird, I  tried step by step, the code works,
> but what's the problem with xx0,I can't figure it out.
> 
> thank you for any suggestion.
> 
> best regards
> yong
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Sun May 30 18:23:27 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 30 May 2004 09:23:27 -0700
Subject: [R] how to remove "." or replace it with NA?
In-Reply-To: <Pine.LNX.4.58.0405292350290.10179@aitken.uchicago.edu>
References: <211AD0070D42D1118C7B00A024FF19AE2EC0B1@AUHEXCH>
	<Pine.LNX.4.58.0405292350290.10179@aitken.uchicago.edu>
Message-ID: <40BA0A7F.4050304@pdf.com>

      It's apparently a unix command;  www.r-project.org -> search -> "R 
site search" -> sed produced at least one hit with the following example: 

scan(pipe("sed -e s/,$// data2"), sep=",")

      For the rest of this comment, see the R site search.  hope this 
helps.  spencer graves

Yong Wang wrote:

>Samir, can you give an example for the use of sed?
>
>
>
>On Sun, 30 May 2004, Samir Mishra wrote:
>
>  
>
>>If the data file is in text format, is large with a lot of "."s, use sed.
>>It's MUCH faster than any other tool for this sort of thing.
>>
>>-----Original Message-----
>>From: Yong Wang [mailto:wang at galton.uchicago.edu]
>>Sent: Sunday, May 30, 2004 05:25
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] how to remove "." or replace it with NA?
>>
>>
>>Hi,all
>>a quick question
>>A larger file include many"." (stands for missing 
>>value) for variable, say, x. after
>>read in the file and assign it another name such as :
>>
>>x1<-data$x
>>
>>but x1 is always a facotor but not numerical. 
>>
>>so How can I get a numeric vector from the read in data frame.
>>how can I replace those "." with "NA" to perform analysis.
>>
>>thank you very much
>>best regards
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From apiszcz at solarrain.com  Sun May 30 20:47:47 2004
From: apiszcz at solarrain.com (Al Piszcz)
Date: Sun, 30 May 2004 14:47:47 -0400 (EDT)
Subject: [R] prcomp help
Message-ID: <Pine.LNX.4.60.0405301443290.21797@l1>


Slackware 9.1, R 1.9.0, 2.54GHZ P4, 2GB RAM

example(prcomp) never finishes


> example(prcomp)

prcomp> data(USArrests)

prcomp> prcomp(USArrests)


====

The following test also appears to hang.

> a<-matrix(rnorm(100,mean=32,sd=31),10,10)
> b<-prcomp(a)



====

What is the recommended debug approach?

Thank you.



From feldesmanm at pdx.edu  Sun May 30 20:50:38 2004
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Sun, 30 May 2004 11:50:38 -0700
Subject: [R] summary.lm
Message-ID: <6.0.3.0.2.20040530114400.01f5ad20@pop4.attglobal.net>

I ran across this error the other day while using lm().  I confess that I 
haven't used it for awhile and haven't been tracking the changes between 
versions of R.  However, the piece of code below is a tiny modification of 
the example in the help file for "lm".  I just separated the commands apart 
for clarity.  A similar piece comes from the help file for "summary.lm".

Aside from simply typing >lm.D90 at the command line, is there no longer a 
working summary method for lm.  I've looked at the code for summary.lm and 
its first two lines are:

z <- .Alias(object)
     Qr <- .Alias(object$qr)


 >lm.D90 <- lm(weight ~ group )
 > summary(lm.D90)
Error: '.Alias' is defunct.
See ?Defunct.

platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.0
year     2004
month    04
day      12
language R

I'd be perfectly happy to be straightened out here.

Thanks.



Dr. Marc R. Feldesman
Professor and Chairman Emeritus
Anthropology Department - Portland State University
email:  feldesmanm at pdx.edu
email:  feldesman at attglobal.net
fax:    503-725-3905


"Don't knock on my door if you don't know my Rottweiler's name"  Warren Zevon
"Its midnight and I'm not famous yet"  Jimmy Buffett



From rpeng at jhsph.edu  Sun May 30 21:00:30 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sun, 30 May 2004 15:00:30 -0400
Subject: [R] summary.lm
In-Reply-To: <6.0.3.0.2.20040530114400.01f5ad20@pop4.attglobal.net>
References: <6.0.3.0.2.20040530114400.01f5ad20@pop4.attglobal.net>
Message-ID: <40BA2F4E.40907@jhsph.edu>

Is it possible you have a locally modified version of 
summary.lm() lying around.  Here are the first few lines of 
summary.lm() in R 1.9.0:

 > head(summary.lm)

1 function (object, correlation = FALSE, symbolic.cor = FALSE,
2     ...)
3 {
4     z <- object
5     p <- z$rank
6     if (p == 0) {
 >

So I'm not sure were you're getting your version.  What does 
`getAnywhere(summary.lm)' give you?

-roger

Marc R. Feldesman wrote:
> I ran across this error the other day while using lm().  I confess that 
> I haven't used it for awhile and haven't been tracking the changes 
> between versions of R.  However, the piece of code below is a tiny 
> modification of the example in the help file for "lm".  I just separated 
> the commands apart for clarity.  A similar piece comes from the help 
> file for "summary.lm".
> 
> Aside from simply typing >lm.D90 at the command line, is there no longer 
> a working summary method for lm.  I've looked at the code for summary.lm 
> and its first two lines are:
> 
> z <- .Alias(object)
>     Qr <- .Alias(object$qr)
> 
> 
>  >lm.D90 <- lm(weight ~ group )
>  > summary(lm.D90)
> Error: '.Alias' is defunct.
> See ?Defunct.
> 
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    9.0
> year     2004
> month    04
> day      12
> language R
> 
> I'd be perfectly happy to be straightened out here.
> 
> Thanks.
> 
> 
> 
> Dr. Marc R. Feldesman
> Professor and Chairman Emeritus
> Anthropology Department - Portland State University
> email:  feldesmanm at pdx.edu
> email:  feldesman at attglobal.net
> fax:    503-725-3905
> 
> 
> "Don't knock on my door if you don't know my Rottweiler's name"  Warren 
> Zevon
> "Its midnight and I'm not famous yet"  Jimmy Buffett
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Sun May 30 22:01:58 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 30 May 2004 22:01:58 +0200
Subject: [R] prcomp help
In-Reply-To: <Pine.LNX.4.60.0405301443290.21797@l1>
References: <Pine.LNX.4.60.0405301443290.21797@l1>
Message-ID: <40BA3DB6.9080501@statistik.uni-dortmund.de>

Al Piszcz wrote:
> 
> Slackware 9.1, R 1.9.0, 2.54GHZ P4, 2GB RAM
> 
> example(prcomp) never finishes
> 
> 
>> example(prcomp)
> 
> 
> prcomp> data(USArrests)
> 
> prcomp> prcomp(USArrests)
> 
> 
> ====
> 
> The following test also appears to hang.
> 
>> a<-matrix(rnorm(100,mean=32,sd=31),10,10)
>> b<-prcomp(a)

Works on Windows and several other OSs.

Do you have a local copy of prcomp() (which is different from the 
original one)?

What happens if you start R with --vanilla and try again?

What happened after
   make check
during your R installation? make check should have reported an error 
here (or hang itself)....

Uwe Ligges




> 
> 
> 
> ====
> 
> What is the recommended debug approach?
> 
> Thank you.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From apiszcz at solarrain.com  Sun May 30 22:07:34 2004
From: apiszcz at solarrain.com (Al Piszcz)
Date: Sun, 30 May 2004 16:07:34 -0400 (EDT)
Subject: [R] prcomp help
In-Reply-To: <40BA3DB6.9080501@statistik.uni-dortmund.de>
References: <Pine.LNX.4.60.0405301443290.21797@l1>
	<40BA3DB6.9080501@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.60.0405301606080.21797@l1>


I am pretty sure it is something to do with my local installation.
I have R running on 6 other systems with no proble.s

1] R --vanilla (same bevhavior, does not finish)
2] I will reinstall and report back shortly if there is still
    an issue.

Thank you.




On Sun, 30 May 2004, Uwe Ligges wrote:

> Date: Sun, 30 May 2004 22:01:58 +0200
> From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
> To: Al Piszcz <apiszcz at solarrain.com>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] prcomp help
> 
> Al Piszcz wrote:
>> 
>> Slackware 9.1, R 1.9.0, 2.54GHZ P4, 2GB RAM
>> 
>> example(prcomp) never finishes
>> 
>> 
>>> example(prcomp)
>> 
>> 
>> prcomp> data(USArrests)
>> 
>> prcomp> prcomp(USArrests)
>> 
>> 
>> ====
>> 
>> The following test also appears to hang.
>> 
>>> a<-matrix(rnorm(100,mean=32,sd=31),10,10)
>>> b<-prcomp(a)
>
> Works on Windows and several other OSs.
>
> Do you have a local copy of prcomp() (which is different from the original 
> one)?
>
> What happens if you start R with --vanilla and try again?
>
> What happened after
>  make check
> during your R installation? make check should have reported an error here (or 
> hang itself)....
>
> Uwe Ligges
>
>
>
>
>> 
>> 
>> 
>> ====
>> 
>> What is the recommended debug approach?
>> 
>> Thank you.
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>



From lauraholt_983 at hotmail.com  Sun May 30 22:19:24 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Sun, 30 May 2004 15:19:24 -0500
Subject: [R] zipping a new package
Message-ID: <BAY12-F100Jzt47kBeq0003aa29@hotmail.com>

Dear R People:

I have finally created a little R package.

Do I need to do anything special to create a zip file for that package, or 
just use Winzip, please?

thanks so much

R Windows Version 1.9.0

Thanks,
Laura
mailto: lauraholt_983 at hotmail.com



From apiszcz at solarrain.com  Sun May 30 22:27:39 2004
From: apiszcz at solarrain.com (Al Piszcz)
Date: Sun, 30 May 2004 16:27:39 -0400 (EDT)
Subject: [R] prcomp help
In-Reply-To: <40BA3DB6.9080501@statistik.uni-dortmund.de>
References: <Pine.LNX.4.60.0405301443290.21797@l1>
	<40BA3DB6.9080501@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.60.0405301627090.1941@l1>


There may be some compilation issues with XFree86 4.4.0



gcc -Wl,--export-dynamic -L/usr/local/lib -o R.bin  CConverters.o Rdynload.o RN
G.o apply.o arithmetic.o apse.o array.o attrib.o base.o bind.o builtin.o charac
ter.o coerce.o colors.o complex.o connections.o context.o cov.o cum.o dcf.o dat
etime.o debug.o devPS.o devPicTeX.o deparse.o deriv.o devices.o dotcode.o dounz
ip.o dstruct.o duplicate.o engine.o envir.o errors.o eval.o format.o fourier.o 
gram.o gram-ex.o graphics.o identical.o internet.o iosupport.o lapack.o list.o 
logic.o main.o mapply.o match.o memory.o model.o names.o objects.o optim.o opti
mize.o options.o par.o paste.o pcre.o platform.o plot.o plot3d.o plotmath.o pri
nt.o printarray.o printvector.o printutils.o qsort.o random.o regex.o relop.o s
aveload.o scan.o seq.o serialize.o size.o sort.o source.o split.o sprintf.o sub
assign.o subscript.o subset.o summary.o unique.o util.o version.o vfonts.o regi
stration.o xxxpr.o ../unix/libunix.a ../appl/libappl.a ../nmath/libnmath.a   -L
/usr/local/lib -L/a/app/gcc-3.4.0/bin/../lib/gcc/i686-pc-linux-gnu/3.4.0 -L/a/a
pp/gcc-3.4.0/bin/../lib/gcc -L/vapp/lib -L/app/gcc-3.4.0/lib/gcc/i686-pc-linux-
gnu/3.4.0 -L/a/app/gcc-3.4.0/bin/../lib/gcc/i686-pc-linux-gnu/3.4.0/../../.. -L
/app/gcc-3.4.0/lib/gcc/i686-pc-linux-gnu/3.4.0/../../.. -lfrtbegin -lg2c -lm -l
gcc_s  ../extra/zlib/libz.a ../extra/bzip2/libbz2.a ../extra/pcre/libpcre.a -lr
eadline -ldl -lncurses -lm
make[4]: Entering directory `/x/r/R-1.9.0/src/main'
make[4]: Leaving directory `/x/r/R-1.9.0/src/main'
make[3]: Leaving directory `/x/r/R-1.9.0/src/main'
make[2]: Leaving directory `/x/r/R-1.9.0/src/main'
make[2]: Entering directory `/x/r/R-1.9.0/src/modules'
make[3]: Entering directory `/x/r/R-1.9.0/src/modules/X11'
make[4]: Entering directory `/x/r/R-1.9.0/src/modules/X11'
making dataentry.d from dataentry.c
making devX11.d from devX11.c
making rotated.d from rotated.c
making rbitmap.d from rbitmap.c
make[4]: Leaving directory `/x/r/R-1.9.0/src/modules/X11'
make[4]: Entering directory `/x/r/R-1.9.0/src/modules/X11'
gcc -I. -I../../../src/include -I../../../src/include -I/usr/X11R6/include -I/u
sr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES -mieee-fp -fPIC  -g -O2 -c
  dataentry.c -o dataentry.lo
In file included from dataentry.c:31:
/usr/include/X11/Xlib.h:1390: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:1478: error: parse error before "char"
/usr/include/X11/Xlib.h:1506: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:1510: error: parse error before "char"
/usr/include/X11/Xlib.h:1532: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:1567: error: parse error before '*' token
/usr/include/X11/Xlib.h:1576: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:1601: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:1651: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:1657: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:1704: error: parse error before "char"
/usr/include/X11/Xlib.h:1743: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:1984: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:2068: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:2321: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:2331: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:2403: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:2413: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:2571: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:2586: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:2779: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:2846: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:2851: error: parse error before "char"
/usr/include/X11/Xlib.h:2965: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:2991: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3002: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3027: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3036: error: parse error before "char"
/usr/include/X11/Xlib.h:3049: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3192: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3241: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3273: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3364: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3371: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3391: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3397: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3409: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3419: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3429: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3435: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3536: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3553: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3604: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3647: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3653: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3659: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3665: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3673: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3681: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3689: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3701: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3713: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3760: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3771: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3782: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3793: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3804: error: parse error before "_Xconst"
/usr/include/X11/Xlib.h:3815: error: parse error before "_Xconst"
In file included from dataentry.c:32:
/usr/include/X11/Xutil.h:566: error: parse error before "_Xconst"
/usr/include/X11/Xutil.h:606: error: parse error before "_Xconst"
/usr/include/X11/Xutil.h:666: error: parse error before "_Xconst"
/usr/include/X11/Xutil.h:678: error: parse error before "_Xconst"
/usr/include/X11/Xutil.h:801: error: parse error before "_Xconst"
dataentry.c: In function `GetKey':
dataentry.c:1272: warning: passing arg 4 of `XLookupString' from incompatible p
ointer type
dataentry.c: In function `GetCharP':
dataentry.c:1281: warning: passing arg 4 of `XLookupString' from incompatible p
ointer type
dataentry.c: In function `doControl':
dataentry.c:1302: warning: passing arg 4 of `XLookupString' from incompatible p
ointer type
make[4]: *** [dataentry.lo] Error 1
make[4]: Leaving directory `/x/r/R-1.9.0/src/modules/X11'
make[3]: *** [R] Error 2
make[3]: Leaving directory `/x/r/R-1.9.0/src/modules/X11'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/x/r/R-1.9.0/src/modules'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/x/r/R-1.9.0/src'
make: *** [R] Error 1

real    6m23.270s
user    1m35.338s
sys     0m8.069s





On Sun, 30 May 2004, Uwe Ligges wrote:

> Date: Sun, 30 May 2004 22:01:58 +0200
> From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
> To: Al Piszcz <apiszcz at solarrain.com>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] prcomp help
> 
> Al Piszcz wrote:
>> 
>> Slackware 9.1, R 1.9.0, 2.54GHZ P4, 2GB RAM
>> 
>> example(prcomp) never finishes
>> 
>> 
>>> example(prcomp)
>> 
>> 
>> prcomp> data(USArrests)
>> 
>> prcomp> prcomp(USArrests)
>> 
>> 
>> ====
>> 
>> The following test also appears to hang.
>> 
>>> a<-matrix(rnorm(100,mean=32,sd=31),10,10)
>>> b<-prcomp(a)
>
> Works on Windows and several other OSs.
>
> Do you have a local copy of prcomp() (which is different from the original 
> one)?
>
> What happens if you start R with --vanilla and try again?
>
> What happened after
>  make check
> during your R installation? make check should have reported an error here (or 
> hang itself)....
>
> Uwe Ligges
>
>
>
>
>> 
>> 
>> 
>> ====
>> 
>> What is the recommended debug approach?
>> 
>> Thank you.
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>



From jfox at mcmaster.ca  Sun May 30 22:35:15 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 30 May 2004 16:35:15 -0400
Subject: [R] how to remove "." or replace it with NA?
In-Reply-To: <40BA0A7F.4050304@pdf.com>
Message-ID: <20040530203514.RNGG26030.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Spenser et al.,

sed stands for "string editor," I believe, and it is a Unix utility,
although there are implementations for other OS's including Windows.

For Yong Wang's problem, I think that it is more natural to use the
na.strings argument to read.table(), as I previously suggested, than to edit
the data file.

Regards,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Spencer Graves
> Sent: Sunday, May 30, 2004 11:23 AM
> To: Yong Wang
> Cc: r-help at stat.math.ethz.ch; Samir Mishra
> Subject: Re: [R] how to remove "." or replace it with NA?
> 
>       It's apparently a unix command;  www.r-project.org -> 
> search -> "R site search" -> sed produced at least one hit 
> with the following example: 
> 
> scan(pipe("sed -e s/,$// data2"), sep=",")
> 
>       For the rest of this comment, see the R site search.  
> hope this helps.  spencer graves
> 
> Yong Wang wrote:
> 
> >Samir, can you give an example for the use of sed?
> >
> >
> >
> >On Sun, 30 May 2004, Samir Mishra wrote:
> >
> >  
> >
> >>If the data file is in text format, is large with a lot of 
> "."s, use sed.
> >>It's MUCH faster than any other tool for this sort of thing.
> >>
> >>-----Original Message-----
> >>From: Yong Wang [mailto:wang at galton.uchicago.edu]
> >>Sent: Sunday, May 30, 2004 05:25
> >>To: r-help at stat.math.ethz.ch
> >>Subject: [R] how to remove "." or replace it with NA?
> >>
> >>
> >>Hi,all
> >>a quick question
> >>A larger file include many"." (stands for missing
> >>value) for variable, say, x. after
> >>read in the file and assign it another name such as :
> >>
> >>x1<-data$x
> >>
> >>but x1 is always a facotor but not numerical. 
> >>
> >>so How can I get a numeric vector from the read in data frame.
> >>how can I replace those "." with "NA" to perform analysis.
> >>
> >>thank you very much
> >>best regards
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide!
> >>http://www.R-project.org/posting-guide.html
> >>
> >>    
> >>
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> >http://www.R-project.org/posting-guide.html
> >  
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Sun May 30 22:42:10 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 30 May 2004 16:42:10 -0400
Subject: [R] zipping a new package
In-Reply-To: <BAY12-F100Jzt47kBeq0003aa29@hotmail.com>
Message-ID: <20040530204210.JXHI14757.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Laura,

The normal way to build R packages is to use package-building tools.
Instructions are in the manual Writing R Extensions, which is part of the
standard R distribution, and, for Windows, at the web site
<http://www.murdoch-sutherland.com/Rtools/>. 

If you're willing to forgo documentation, you can "fake" a package for R for
Windows by making a zip file. Some slightly out-of-date instructions for
doing so are at
<http://socserv.socsci.mcmaster.ca/jfox/Books/Companion/instructors.html>. 

Although it's initially more trouble, I'd recommend going the former route.

I hope this helps,
 John 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Laura Holt
> Sent: Sunday, May 30, 2004 3:19 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] zipping a new package
> 
> Dear R People:
> 
> I have finally created a little R package.
> 
> Do I need to do anything special to create a zip file for 
> that package, or just use Winzip, please?
> 
> thanks so much
> 
> R Windows Version 1.9.0
> 
> Thanks,
> Laura
> mailto: lauraholt_983 at hotmail.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From lauraholt_983 at hotmail.com  Sun May 30 22:45:10 2004
From: lauraholt_983 at hotmail.com (Laura Holt)
Date: Sun, 30 May 2004 15:45:10 -0500
Subject: [R] zipping a new package revisited
Message-ID: <BAY12-F16oPAzdaQYrV0003afc0@hotmail.com>

In case you're wondering, here it is:

Rcmd build --binary --use-zip packname

Sorry that I didn't read the Writing R Extensions first.

Sincerely,
Laura



From apiszcz at solarrain.com  Sun May 30 22:55:36 2004
From: apiszcz at solarrain.com (Al Piszcz)
Date: Sun, 30 May 2004 16:55:36 -0400 (EDT)
Subject: [R] prcomp help
In-Reply-To: <Pine.LNX.4.60.0405301627090.1941@l1>
References: <Pine.LNX.4.60.0405301443290.21797@l1>
	<40BA3DB6.9080501@statistik.uni-dortmund.de>
	<Pine.LNX.4.60.0405301627090.1941@l1>
Message-ID: <Pine.LNX.4.60.0405301654220.21625@l1>


I located this: (same file with previous issues)

Sat Mar 27 13:46:11 UTC 2004, ripley
   adjust to work with XFree86 4.4.0 headers (and some missing casts)
   R NEWS,1.2033
   R/src/modules/X11 dataentry.c,1.17


AND 1.9.0 release notes


     o	The X11 module can now be built against XFree86 4.4.0 headers 
(still
 	with some warnings).







On Sun, 30 May 2004, Al Piszcz wrote:

> Date: Sun, 30 May 2004 16:27:39 -0400 (EDT)
> From: Al Piszcz <apiszcz at solarrain.com>
> To: Uwe Ligges <ligges at statistik.uni-dortmund.de>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] prcomp help
> 
>
> There may be some compilation issues with XFree86 4.4.0
>
>
>
> gcc -Wl,--export-dynamic -L/usr/local/lib -o R.bin  CConverters.o Rdynload.o 
> RN
> G.o apply.o arithmetic.o apse.o array.o attrib.o base.o bind.o builtin.o 
> charac
> ter.o coerce.o colors.o complex.o connections.o context.o cov.o cum.o dcf.o 
> dat
> etime.o debug.o devPS.o devPicTeX.o deparse.o deriv.o devices.o dotcode.o 
> dounz
> ip.o dstruct.o duplicate.o engine.o envir.o errors.o eval.o format.o 
> fourier.o gram.o gram-ex.o graphics.o identical.o internet.o iosupport.o 
> lapack.o list.o logic.o main.o mapply.o match.o memory.o model.o names.o 
> objects.o optim.o opti
> mize.o options.o par.o paste.o pcre.o platform.o plot.o plot3d.o plotmath.o 
> pri
> nt.o printarray.o printvector.o printutils.o qsort.o random.o regex.o relop.o 
> s
> aveload.o scan.o seq.o serialize.o size.o sort.o source.o split.o sprintf.o 
> sub
> assign.o subscript.o subset.o summary.o unique.o util.o version.o vfonts.o 
> regi
> stration.o xxxpr.o ../unix/libunix.a ../appl/libappl.a ../nmath/libnmath.a 
> -L
> /usr/local/lib -L/a/app/gcc-3.4.0/bin/../lib/gcc/i686-pc-linux-gnu/3.4.0 
> -L/a/a
> pp/gcc-3.4.0/bin/../lib/gcc -L/vapp/lib 
> -L/app/gcc-3.4.0/lib/gcc/i686-pc-linux-
> gnu/3.4.0 -L/a/app/gcc-3.4.0/bin/../lib/gcc/i686-pc-linux-gnu/3.4.0/../../.. 
> -L
> /app/gcc-3.4.0/lib/gcc/i686-pc-linux-gnu/3.4.0/../../.. -lfrtbegin -lg2c -lm 
> -l
> gcc_s  ../extra/zlib/libz.a ../extra/bzip2/libbz2.a ../extra/pcre/libpcre.a 
> -lr
> eadline -ldl -lncurses -lm
> make[4]: Entering directory `/x/r/R-1.9.0/src/main'
> make[4]: Leaving directory `/x/r/R-1.9.0/src/main'
> make[3]: Leaving directory `/x/r/R-1.9.0/src/main'
> make[2]: Leaving directory `/x/r/R-1.9.0/src/main'
> make[2]: Entering directory `/x/r/R-1.9.0/src/modules'
> make[3]: Entering directory `/x/r/R-1.9.0/src/modules/X11'
> make[4]: Entering directory `/x/r/R-1.9.0/src/modules/X11'
> making dataentry.d from dataentry.c
> making devX11.d from devX11.c
> making rotated.d from rotated.c
> making rbitmap.d from rbitmap.c
> make[4]: Leaving directory `/x/r/R-1.9.0/src/modules/X11'
> make[4]: Entering directory `/x/r/R-1.9.0/src/modules/X11'
> gcc -I. -I../../../src/include -I../../../src/include -I/usr/X11R6/include 
> -I/u
> sr/local/include -DHAVE_CONFIG_H -D__NO_MATH_INLINES -mieee-fp -fPIC  -g -O2 
> -c
> dataentry.c -o dataentry.lo
> In file included from dataentry.c:31:
> /usr/include/X11/Xlib.h:1390: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:1478: error: parse error before "char"
> /usr/include/X11/Xlib.h:1506: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:1510: error: parse error before "char"
> /usr/include/X11/Xlib.h:1532: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:1567: error: parse error before '*' token
> /usr/include/X11/Xlib.h:1576: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:1601: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:1651: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:1657: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:1704: error: parse error before "char"
> /usr/include/X11/Xlib.h:1743: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:1984: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:2068: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:2321: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:2331: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:2403: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:2413: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:2571: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:2586: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:2779: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:2846: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:2851: error: parse error before "char"
> /usr/include/X11/Xlib.h:2965: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:2991: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3002: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3027: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3036: error: parse error before "char"
> /usr/include/X11/Xlib.h:3049: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3192: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3241: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3273: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3364: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3371: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3391: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3397: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3409: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3419: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3429: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3435: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3536: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3553: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3604: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3647: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3653: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3659: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3665: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3673: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3681: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3689: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3701: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3713: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3760: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3771: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3782: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3793: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3804: error: parse error before "_Xconst"
> /usr/include/X11/Xlib.h:3815: error: parse error before "_Xconst"
> In file included from dataentry.c:32:
> /usr/include/X11/Xutil.h:566: error: parse error before "_Xconst"
> /usr/include/X11/Xutil.h:606: error: parse error before "_Xconst"
> /usr/include/X11/Xutil.h:666: error: parse error before "_Xconst"
> /usr/include/X11/Xutil.h:678: error: parse error before "_Xconst"
> /usr/include/X11/Xutil.h:801: error: parse error before "_Xconst"
> dataentry.c: In function `GetKey':
> dataentry.c:1272: warning: passing arg 4 of `XLookupString' from incompatible 
> p
> ointer type
> dataentry.c: In function `GetCharP':
> dataentry.c:1281: warning: passing arg 4 of `XLookupString' from incompatible 
> p
> ointer type
> dataentry.c: In function `doControl':
> dataentry.c:1302: warning: passing arg 4 of `XLookupString' from incompatible 
> p
> ointer type
> make[4]: *** [dataentry.lo] Error 1
> make[4]: Leaving directory `/x/r/R-1.9.0/src/modules/X11'
> make[3]: *** [R] Error 2
> make[3]: Leaving directory `/x/r/R-1.9.0/src/modules/X11'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/x/r/R-1.9.0/src/modules'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/x/r/R-1.9.0/src'
> make: *** [R] Error 1
>
> real    6m23.270s
> user    1m35.338s
> sys     0m8.069s
>
>
>
>
>
> On Sun, 30 May 2004, Uwe Ligges wrote:
>
>> Date: Sun, 30 May 2004 22:01:58 +0200
>> From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
>> To: Al Piszcz <apiszcz at solarrain.com>
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] prcomp help
>> 
>> Al Piszcz wrote:
>>> 
>>> Slackware 9.1, R 1.9.0, 2.54GHZ P4, 2GB RAM
>>> 
>>> example(prcomp) never finishes
>>> 
>>> 
>>>> example(prcomp)
>>> 
>>> 
>>> prcomp> data(USArrests)
>>> 
>>> prcomp> prcomp(USArrests)
>>> 
>>> 
>>> ====
>>> 
>>> The following test also appears to hang.
>>> 
>>>> a<-matrix(rnorm(100,mean=32,sd=31),10,10)
>>>> b<-prcomp(a)
>> 
>> Works on Windows and several other OSs.
>> 
>> Do you have a local copy of prcomp() (which is different from the original 
>> one)?
>> 
>> What happens if you start R with --vanilla and try again?
>> 
>> What happened after
>>  make check
>> during your R installation? make check should have reported an error here 
>> (or hang itself)....
>> 
>> Uwe Ligges
>> 
>> 
>> 
>> 
>>> 
>>> 
>>> 
>>> ====
>>> 
>>> What is the recommended debug approach?
>>> 
>>> Thank you.
>>> 
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>> 
>



From bates at stat.wisc.edu  Sun May 30 23:11:40 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 30 May 2004 16:11:40 -0500
Subject: [R] Re: the name 'sed' [was: how to remove "." or replace it with
	NA?]
In-Reply-To: <20040530203514.RNGG26030.tomts20-srv.bellnexxia.net@JohnDesktop8300>
References: <20040530203514.RNGG26030.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <6rk6ytaacz.fsf@bates4.stat.wisc.edu>

"John Fox" <jfox at mcmaster.ca> writes:

> Dear Spenser et al.,
> 
> sed stands for "string editor," I believe, and it is a Unix utility,

Actually it is a contraction of "stream editor".  From the manual page
for sed on my system

DESCRIPTION
       Sed  is a stream editor.  A stream editor is used to perform basic text
       transformations on an input stream (a file or input from  a  pipeline).
       While  in  some  ways similar to an editor which permits scripted edits
       (such as ed), sed works by making only one pass over the input(s),  and
       is consequently more efficient.  But it is sed's ability to filter text
       in a pipeline which particularly distinguishes it from other  types  of
       editors.



From apiszcz at solarrain.com  Sun May 30 23:44:29 2004
From: apiszcz at solarrain.com (Al Piszcz)
Date: Sun, 30 May 2004 17:44:29 -0400 (EDT)
Subject: [R] prcomp help
In-Reply-To: <40BA3DB6.9080501@statistik.uni-dortmund.de>
References: <Pine.LNX.4.60.0405301443290.21797@l1>
	<40BA3DB6.9080501@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.60.0405301741360.9996@l1>


I removed dataentry.c from the Makefile at:
  R-1.9.0/src/modules/X11

The build appeared to be successful. However when I run make
check as you recommend, it 'hangs' or continues to run with no progress.

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  9987 ap        25   0 25808  21m 5280 R 23.9  1.1   0:47.61 R.bin

  R-1.9.0_27 $ time make check
make[1]: Entering directory `/x/r/R-1.9.0/tests'
make[2]: Entering directory `/x/r/R-1.9.0/tests'
make[3]: Entering directory `/x/r/R-1.9.0/tests/Examples'
make[4]: Entering directory `/x/r/R-1.9.0/tests/Examples'
make[4]: `Makedeps' is up to date.
make[4]: Leaving directory `/x/r/R-1.9.0/tests/Examples'
make[4]: Entering directory `/x/r/R-1.9.0/tests/Examples'
running code in 'base-Ex.R' ...



The update to the machine which is slackeware 9.1 was KDE 3.2.





On Sun, 30 May 2004, Uwe Ligges wrote:

> Date: Sun, 30 May 2004 22:01:58 +0200
> From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
> To: Al Piszcz <apiszcz at solarrain.com>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] prcomp help
> 
> Al Piszcz wrote:
>> 
>> Slackware 9.1, R 1.9.0, 2.54GHZ P4, 2GB RAM
>> 
>> example(prcomp) never finishes
>> 
>> 
>>> example(prcomp)
>> 
>> 
>> prcomp> data(USArrests)
>> 
>> prcomp> prcomp(USArrests)
>> 
>> 
>> ====
>> 
>> The following test also appears to hang.
>> 
>>> a<-matrix(rnorm(100,mean=32,sd=31),10,10)
>>> b<-prcomp(a)
>
> Works on Windows and several other OSs.
>
> Do you have a local copy of prcomp() (which is different from the original 
> one)?
>
> What happens if you start R with --vanilla and try again?
>
> What happened after
>  make check
> during your R installation? make check should have reported an error here (or 
> hang itself)....
>
> Uwe Ligges
>
>
>
>
>> 
>> 
>> 
>> ====
>> 
>> What is the recommended debug approach?
>> 
>> Thank you.
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>



From Meredith.Briggs at team.telstra.com  Mon May 31 00:56:55 2004
From: Meredith.Briggs at team.telstra.com (Briggs, Meredith M)
Date: Mon, 31 May 2004 08:56:55 +1000
Subject: [R] Application of tree() to get alternative confidence bounds - is
	this feasible?
Message-ID: <3B5823541A25D311B3B90008C7F9056410E3555A@ntmsg0092.corpmail.telstra.com.au>



> Hello
> 
> I'm currently using Monte Carlo techniques to estimate prices (variable not static) from the following type of data:
> 
> 	  << OLE Object: Microsoft Excel Worksheet >> 
> 
> 
> 
> Each row is a record from group A and the cells in all but the last column are the volumes of 'widgets' in the record. The last column is the cost of all the widgets in the record. Any widget can have a different prices in each record but the price is assumed to be normally distributed with a starting price and deviation.
> 
> The aim is to apply the estimated prices to eg an average record (in terms of volumes of widgets per record) from group B and compare the cost of this average record against the cost of an average record from group A.
> 
> I've used a Monte Carlo approach to estimate confidence intervals but thought another view could be obtained by using tree() to split the records into two disparate groups and run these two groups separately through the Monte Carlo model. 
> 
> Is this feasible?
> 
> thanks
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
>



From apiszcz at solarrain.com  Mon May 31 01:35:05 2004
From: apiszcz at solarrain.com (Al Piszcz)
Date: Sun, 30 May 2004 19:35:05 -0400 (EDT)
Subject: [R] prcomp help
In-Reply-To: <40BA3DB6.9080501@statistik.uni-dortmund.de>
References: <Pine.LNX.4.60.0405301443290.21797@l1>
	<40BA3DB6.9080501@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.60.0405301930110.1617@l1>


I downloaded and built the development version
of R dated 30 May. make check, and prcomp
were successful.



On Sun, 30 May 2004, Uwe Ligges wrote:

> Date: Sun, 30 May 2004 22:01:58 +0200
> From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
> To: Al Piszcz <apiszcz at solarrain.com>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] prcomp help
> 
> Al Piszcz wrote:
>> 
>> Slackware 9.1, R 1.9.0, 2.54GHZ P4, 2GB RAM
>> 
>> example(prcomp) never finishes
>> 
>> 
>>> example(prcomp)
>> 
>> 
>> prcomp> data(USArrests)
>> 
>> prcomp> prcomp(USArrests)
>> 
>> 
>> ====
>> 
>> The following test also appears to hang.
>> 
>>> a<-matrix(rnorm(100,mean=32,sd=31),10,10)
>>> b<-prcomp(a)
>
> Works on Windows and several other OSs.
>
> Do you have a local copy of prcomp() (which is different from the original 
> one)?
>
> What happens if you start R with --vanilla and try again?
>
> What happened after
>  make check
> during your R installation? make check should have reported an error here (or 
> hang itself)....
>
> Uwe Ligges
>
>
>
>
>> 
>> 
>> 
>> ====
>> 
>> What is the recommended debug approach?
>> 
>> Thank you.
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>



From feldesmanm at pdx.edu  Mon May 31 01:35:58 2004
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Sun, 30 May 2004 16:35:58 -0700
Subject: [R] summary.lm
In-Reply-To: <40BA2F4E.40907@jhsph.edu>
References: <6.0.3.0.2.20040530114400.01f5ad20@pop4.attglobal.net>
	<40BA2F4E.40907@jhsph.edu>
Message-ID: <6.0.3.0.2.20040530163438.02049518@pop4.attglobal.net>

At 12:00 PM 5/30/2004, Roger D. Peng wrote:
 >Is it possible you have a locally modified version of
 >summary.lm() lying around.  Here are the first few lines of
 >summary.lm() in R 1.9.0:
 >

That was the problem.  But since I've never even looked at summary.lm until 
the past few days when this error began, I'm utterly bewildered by how it 
happened to get modified and stored in my global workspace.

Thanks for clearly up this mystery.



From anthony at darrouzet-nardi.net  Mon May 31 02:55:53 2004
From: anthony at darrouzet-nardi.net (Anthony Darrouzet-Nardi)
Date: Sun, 30 May 2004 17:55:53 -0700
Subject: [R] panel function in a conditioned lattice graphic
In-Reply-To: <200405300214.02921.deepayan@stat.wisc.edu>
References: <p0521061abcdedce26749@[4.243.164.183]>
	<200405300214.02921.deepayan@stat.wisc.edu>
Message-ID: <p0521061ebce02f09a3d9@[4.243.164.183]>

>On Saturday 29 May 2004 20:18, Anthony Darrouzet-Nardi wrote:
>
>>  I have a followup question. Suppose I want to encode two different
>>  variables within a panel: one variable encoded by plotting character
>>  and one variable encoded by symbol color (as if I could use two
>>  "groups" variables). The dataframe I discussed above also includes a
>>  variable called treatment. If I start with the existing code modified
>>  with your suggestions:
>>
>>  xyplot(coversage ~ dryout | year,
>>	data = dryoutcover,
>>	groups = block,
>>	panel = function(x,y, ...) {
>>		panel.lmline(x,y)
>>		panel.superpose(x,y,
>>			pch = 49:54,
>>			cex = rep(2,6),
>>			col = rep("black", 6), ...)
>>		}
>>	)
>>
>>  how could I make all of the symbols of one treatment red and all of
>>  the symbols of the other black while maintaining the encodings of
>>  block by plotting character? This would be a superbly useful
>>  technique as it would allow 4 dimensional data on a single panel
>>  (maybe even 5 using a point cloud!).
>
>I would use the same construct, forming a new grouping variable and
>using suitably modified pch and col arguments:
>
>xyplot(coversage ~ dryout | year, data=dryoutcover, cex = 2,
>        groups = interaction(block, treatment),
>        pch = rep(49:54, 2),
>        col = rep(c('red', 'black'), each = 5))
>
>(2 and 5 being the nlevels() of treatment and block respectively). You
>would also probably prefer factor(year) rather than year.
>
>Deepayan

Bravo! That works wonderfully. I foresee myself using this method a 
lot. For the record, nlevels(block) is 6, so each = 6 in the col 
argument for the final version. Makes sense to switch to factor(year) 
as well (like the barley data).

Thanks for your help,

Anthony



From spencer.graves at pdf.com  Mon May 31 04:06:49 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 30 May 2004 19:06:49 -0700
Subject: [R] glmm?
Message-ID: <40BA9339.1040406@pdf.com>

      Is there an easy way to get confidence intervals from "glmm" in 
Jim Lindsey's library(repeated)?  Consider the following slight 
modification of an example from the help page: 

 >  df <- data.frame(r=rbinom(10,10,0.5), n=rep(10,10), x=c(rep(0,5),
+              rep(1,5)), nest=1:10)
 > fit <- glmm(cbind(r,n-r)~x, family=binomial, nest=nest, data=df)
 > summary(fit)
Error in print.summary.glmm(structure(list(call = glmm(cbind(r, n - r) ~  :
        couldn't find function "print.summary.glm"
 > confint(fit)
Waiting for profiling to be done...
Error in glmm(cbind(r, n - r) ~ x, family = binomial, nest = nest, data 
= df,  :
        unused argument(s) (method ...)

      I'm running R 1.9.0pat under Windows 2000. 

      Thanks,
      spencer graves



From adrian at maths.uwa.edu.au  Mon May 31 04:10:46 2004
From: adrian at maths.uwa.edu.au (Adrian Baddeley)
Date: Mon, 31 May 2004 10:10:46 +0800
Subject: [R] Re: Rhelp: Need help interpreting plots in spatstat 
Message-ID: <16570.37926.351650.674832@maths.uwa.edu.au>

Dear Lisa

'spatstat' has extensive help files which would help you
to resolve this.

help(Gest) says that the output value of Gest() includes a 
vector Gest()$raw which is the raw (i.e. without edge correction)
estimate of the G function. It is not a very good estimate of G
because it can be severely biased. But it can be used for
hypothesis testing.

 > ghat.env <- function(n, s, r, win=owin(myOwin){
 > hold <- matrix(0, s, length(r))
 > for(i in 1:s){
 > hold[i,] <- Gest(runifpoint(n, win=myOwin), r=r)$raw
 > }
 > mn <- apply(hold, 2, mean)
 > Up <- apply(hold, 2, max)
 > Down <- apply(hold, 2, min)
 > return(data.frame(mn, Up, Down))
 > }

    This defines a function 'ghat.env' which generates 's' independent
    simulated realisations of a pattern of 'n' points in the window 'myOwin',
    computes the raw estimate of the G function for each realisation,
    then takes the pointwise sample mean, maximum, and minimum of these
    estimates. If the estimates are denoted G1(r), ... Gn(r)
    then mn[i] is the sample mean of G1(r[i]), ...., Gn(r[i]).
    
 > tsds.ghat <- Gest(tsdspoints)
 > tsds.ghat.short <- tsds.ghat[tsds.ghat$r <= .15, ]

    These compute the G function estimates for your dataset 'tddspoints'
    and discard the estimates for r > 0.15.
    The result is a data frame containing several different estimates of G,
    including $raw.

 > tsds.cdf <- 1-exp(-40*pi*(tsds.ghat.short$r^2))

    This computes the theoretical G function for a Poisson process
    with intensity 40. 

 > plot(tsds.ghat.short$r, tsds.ghat.short$raw, xlab="Distance (degrees)", 
 > ylab="Ghat", main=" Transport, Storage, and Disposal sites (TSDs)")

    This plots the RAW estimate of G() from your dataset 'tddspoints'
    against r. 

 > lines(tsds.ghat.short$r, tsds.cdf)

    This superimposes a plot of the theoretical G function for a Poisson
    process with intensity 40.

    ****NOTE**** THESE FUNCTIONS ARE NOT COMPARABLE!!!!
    The raw estimate is a severely biased estimate of G.
    
 > tsds.env <- ghat.env(n=40, s=100, r=tsds.ghat$r)
   
    This invokes the function ghat.env as described above,
    with n=40. Thus it simulates realisations of a random pattern
    of a FIXED number n=40 of points. 

    The results of these simulations are not strictly
    comparable with the Poisson process of intensity 40.
    A Poisson process has a random number of points.

    The mean number of points in the window equals 40 times the area
    of the window - I hope your window has area 1 or these simulations
    are completely incompatible with the 'tsds.cdf' curve.

 > tsds.env.short <- tsds.env[tsds.ghat$r <= .15, ]
   
    Discards estimates of G(r) for r > 0.15

 > lines(tsds.ghat.short$r, tsds.env.short$Up, lty=5)
 > lines(tsds.ghat.short$r, tsds.env.short$Down, lty=5)

    Plots the pointwise maxima and minima of the simulations
    in a classical Monte Carlo test plot.

--------------------------------------------------
I suggest you use the following code instead.

I've changed $raw to $trans which gives you the 'translation correction',
yielding an unbiased estimator of G(r). If you really want the raw estimate,
edit $trans to $raw everywhere. 

regards
Adrian Baddeley


-------------------------------

ghat.env <- function(n, s, r, win=owin(myOwin){
   hold <- matrix(0, s, length(r))
   for(i in 1:s){
      hold[i,] <- Gest(runifpoint(n, win=win), r=r)$trans
   }
   mn <- apply(hold, 2, mean)
   Up <- apply(hold, 2, max)
   Down <- apply(hold, 2, min)
   return(data.frame(mn, Up, Down))
}

tsds.ghat <- Gest(tsdspoints)
tsds.ghat.short <- tsds.ghat[tsds.ghat$r <= .15, ]

# empirical G function 
plot(tsds.ghat.short$r, tsds.ghat.short$trans, 
     xlab="Distance (degrees)", ylab="Ghat", 
     main=" Transport, Storage, and Disposal sites (TSDs)",
     type="l", lwd=2)

# 100 simulations of n points 

forty <- tsdspoints$n
tsds.env <- ghat.env(n=forty, s=100, r=tsds.ghat$r)
tsds.env.short <- tsds.env[tsds.ghat$r <= .15, ]

# upper and lower envelopes
lines(tsds.ghat.short$r, tsds.env.short$Up, lty=5)
lines(tsds.ghat.short$r, tsds.env.short$Down, lty=5)

# mean G function from simulations of n points
lines(tsds.ghat.short$r, tsds.env.short$mn,lty=2)



From p.murrell at auckland.ac.nz  Mon May 31 04:22:48 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 31 May 2004 14:22:48 +1200
Subject: [R] Adding key to simple plot() function
References: <Pine.LNX.4.44.0405281344520.3942-100000@env-pc-phd13>
Message-ID: <40BA96F8.1040004@stat.auckland.ac.nz>

Hi

The text() function has a "pos" argument for positioning labels "beside" 
(x,y) locations.

Do you know about the legend() function for creating a key?

Paul


Laura Quinn wrote:
> I already tried this but encountered a number of problems - firstly the
> point labels overlie the actual points meaning the labels are
> unreadable..and I was hoping to have a separate key within which to
> describe the labels, is this feasible?
> 
> 
> 
> On Fri, 28 May 2004, Sean Davis wrote:
> 
> 
>>Laura,
>>
>>For your axis issues, look at plotting without axes [plot(....,axes=F) and
>>then see ?axis for making them on your own.  As for labeling your data, look
>>at ?points and ?text.
>>
>>Sean
>>
>>On 5/28/04 8:27 AM, "Laura Quinn" <laura at env.leeds.ac.uk> wrote:
>>
>>
>>>I am generating a simple x,y plot to show geographical positions where
>>>point data has been taken. Rather than plot a graph and lay points on top
>>>I've opted to generate the map from the point data, ie plot(-x,-y). This
>>>works fine, though I am wanting to label each point 1:20 and have a key
>>>alongside - is this possible without getting into trellis plots? I have
>>>very limited time available so don't want to embark on trellis functions
>>>which I've never used before..
>>>
>>>Also, my x,y  labels currently have a negative sign in front of them which
>>>I'd like to remove, but if I negate the labels they no longer fit on the
>>>graph as my data points are -x and -y...
>>>
>>>Any suggestions?
>>>
>>>Thanks,
>>>Laura
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From arinbasu at softhome.net  Mon May 31 04:40:20 2004
From: arinbasu at softhome.net (arinbasu@softhome.net)
Date: Sun, 30 May 2004 20:40:20 -0600
Subject: [R] problems with quantreg installation
In-Reply-To: <200405301004.i4UA3Phl025118@hypatia.math.ethz.ch> 
References: <200405301004.i4UA3Phl025118@hypatia.math.ethz.ch>
Message-ID: <courier.40BA9B14.00007AC1@softhome.net>

Hi All: 

I tried to download and install "quantreg" (a package for doing quantile 
regression) from CRAN. When I ran install.packages ("quantreg") within an R 
session, I got the following error message: 

<----Beginning of error message ---> 

* Installing *source* package 'quantreg' ...
** libs
g77 -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c akj.f -o akj.o
make: g77: Command not found
make: *** [akj.o] Error 127
ERROR: compilation failed for package 'quantreg'
** Removing '/usr/lib/R/library/quantreg' 

<---end of error message ---> 

I use R version 1.9.0 on a fedora core 1 operating system. The installation 
was attempted in superuser mode. Would greatly appreciate if you can provide 
solutions about how to install the package. 

TIA,
Arin Basu



From rossini at blindglobe.net  Mon May 31 05:14:28 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Sun, 30 May 2004 20:14:28 -0700
Subject: [R] orca binary?
In-Reply-To: <40B8CA40.60908@statistik.uni-dortmund.de> (Uwe Ligges's
	message of "Sat, 29 May 2004 19:37:04 +0200")
References: <BAY12-F117SK7b9m5PJ0003662e@hotmail.com>
	<40B6F583.9030800@statistik.uni-dortmund.de>
	<853c5kve8w.fsf@servant.blindglobe.net>
	<85ekp4jw4x.fsf@servant.blindglobe.net>
	<40B8CA40.60908@statistik.uni-dortmund.de>
Message-ID: <857jutb84r.fsf@servant.blindglobe.net>


Thanks to Uwe for the binary build -- ROrca 0.4 now is available for
Windows (I've copied his files onto the canonical site, it's available
at 

  http://www.analytics.washington.edu/~rossini/rorca/rorca_0.4.zip

).

For those unfamiliar with Orca, it is a toolkit for building dynamic
interactive visualizations with Java.  ROrca (requires SJava to be
working and installed) allows you to build these using R.  There is an
R script in the same directory as the rorca files which describes use
for multiviews with linked brushing across plots.


best,
-tony


Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

> A.J. Rossini wrote:
>
>> I cross compiled it.  If someone wants to donate a pre-configured
>> Windows computer to my research group, I could test it.  Else, someone
>> else will have to.  I can't.
>> It is  http://www.analytics.washington.edu/~rossini/rorca/rorca.zip
>> best,
>> -tony
>>
>
> Tony, Laura,
>
> there seems to be a bug in the cross compiled binary:
>
>     library(rorca)
>
> Loading required package: SJava
> using JAVA_HOME = c:\Programme\Java\j2re1.4.2_04
> [1] "Orca Home Dir = t:/R/library/rorca"
>
>     my.test2 <- as.data.frame(matrix(rnorm(100),ncol=10))
>     my.test <- VarSelect2d(my.test2)
>
> Error in .JNew("DataStore", pd$getDataHash(), pd$getDataHash(),
> pd$getOtherHash(),  :
>          attempt to apply non-function
>
> Also, note that the md5 checksums are incorrect.
>
> You might want to work on your documentation. Some stuff is
> undocumented, another function is documented but not in the code
> ..... (see R CMD check).
>
>
> Anyway, building under Windows works like a charm these days and Orca
> runs smoothly. I've put up the binary to (only temporarily, Tony might
> want to mirror it):
>
> http://www.statistik.uni-dortmund.de/~ligges/rorca_0.4.zip
>
>
> Uwe
>
>
>
>
>> rossini at blindglobe.net (A.J. Rossini) writes:
>>
>>>Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
>>>
>>>
>>>>Laura Holt wrote:
>>>>
>>>>
>>>>>Dear R People:
>>>>>Is there a binary version for rorca, please?
>>>>
>>>>
>>>>Given I recall correctly, I tried to build rorca for Windows one or
>>>>two years ago without success. But maybe Tony (In this context I
>>>>recall that I'm still owing him a pizza) knows of a binary?
>>>
>>>Hah.  I should swing by and collect next week.
>>>
>>>Seriously, you should be able to do a source install or a quick build
>>>(I probably could do one later today using the Linux cross-compiler),
>>>since it's just raw R code.
>>>
>>>If someone does it before I do, let me know.
>>>
>>>best,
>>>-tony
>>>
>>> -- 
>>> rossini at u.washington.edu
>>> http://www.analytics.washington.edu/ Biomedical and Health
>>> Informatics   University of Washington
>>>Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
>>>UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
>>>FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email
>>>
>>>CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>
>
>

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From wuertz at itp.phys.ethz.ch  Mon May 31 09:29:46 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Mon, 31 May 2004 07:29:46 +0000
Subject: [R] Rmetrics New Built
Message-ID: <40BADEEA.2000506@itp.phys.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040531/e50d4d0b/attachment.pl

From david.netherway at adelaide.edu.au  Mon May 31 10:09:46 2004
From: david.netherway at adelaide.edu.au (David J. Netherway)
Date: Mon, 31 May 2004 17:39:46 +0930
Subject: [R] Getting the same values of adjusted mean and standard errors
	as SAS
In-Reply-To: <20040527084449.4a035892.feh3k@spamcop.net>
References: <40B5931A.7090203@adelaide.edu.au>
	<20040527084449.4a035892.feh3k@spamcop.net>
Message-ID: <40BAE84A.5090703@adelaide.edu.au>

Thanks for the help.

Both the "Design" package and the "effects" package look as though they are
what I need although it will probably take me a while to get on top of both.

I have had a brief  go at the Design package and the contrast function 
is particularly useful.

A question on the Design package:

There are 5 types for factor "group", one is the reference - call it "a".

f <- ols(y ~ age + sex + group, data=dd)
contrast(f, list(group='a'), list(group='b'))

I can use this to contrast pairs but can I use this to contrast b against c,d, and e as a group.
Also "a" against the rest?


Thanks, David

Frank E Harrell Jr wrote:

>On Thu, 27 May 2004 16:34:58 +0930
>"David J. Netherway" <david.netherway at adelaide.edu.au> wrote:
>
>  
>
>>Hello,
>> 
>>I am trying to get the same values for the adjusted means and standard 
>>errors using R that are given in SAS for the
>>following data. The model is Measurement ~ Age + Gender + Group. I can 
>>get the adusted means at the mean age  
>>by using predict. I do not know how to get the appropriate standard 
>>errors at the adjusted means for Gender
>>using values from predict. So I attempted to get them directly from the 
>>residuals as follows. The data is at the end
>>of the email. While there is a match for the males there is a large 
>>difference for the females indicating that what I am doing is wrong.
>> 
>>#  
>>meanAge <- mean(dd$Age)
>>meanAgeM <- mean(dd$Age[d$Gender=="M"])
>>meanAgeF <- mean(dd$Age[d$Gender=="F"])
>>    
>>
>. . . .
>
>By using sex-specific means of age you are not getting adjusted estimates
>in the usual sense.
>
>I prefer to think of effects as differences in predicted values rather
>than as complex SAS-like contrasts. The Design package's contrast function
>makes this easy (including SEs and confidence limits):
>
>library(Design)   # also requires Hmisc
>d <- datadist(dd); options(datadist='d')
>f <- ols(y ~ age + sex + group, data=dd)
>contrast(f, list(sex='M'), list(sex='F'))   # usual adjusted difference M
>vs F
>contrast(f, list(sex='M',age=mean(dd$age[dd$sex=='M']),
>            list(sex='F',age=mean(dd$age[dd$sex=='F')) # M vs F not
>holding age constant
>
>You can also experiment with specifying age=tapply(age, sex, mean,
>na.rm=TRUE) using some of the contrast.Design options.
>---
>Frank E Harrell Jr   Professor and Chair           School of Medicine
>                     Department of Biostatistics   Vanderbilt University
>  
>



From petr.pikal at precheza.cz  Mon May 31 11:01:39 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 31 May 2004 11:01:39 +0200
Subject: [R] bar plot patterns
In-Reply-To: <001a01c445bf$136b3680$ac90148e@Toshi>
Message-ID: <40BB1093.23325.1FD412@localhost>



From f.harrell at vanderbilt.edu  Mon May 31 06:38:44 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 31 May 2004 06:38:44 +0200
Subject: [R] Getting the same values of adjusted mean and standard errors
	as SAS
In-Reply-To: <40BAE84A.5090703@adelaide.edu.au>
References: <40B5931A.7090203@adelaide.edu.au>	<20040527084449.4a035892.feh3k@spamcop.net>
	<40BAE84A.5090703@adelaide.edu.au>
Message-ID: <40BAB6D4.1050205@vanderbilt.edu>

David J. Netherway wrote:
> Thanks for the help.
> 
> Both the "Design" package and the "effects" package look as though they are
> what I need although it will probably take me a while to get on top of 
> both.
> 
> I have had a brief  go at the Design package and the contrast function 
> is particularly useful.
> 
> A question on the Design package:
> 
> There are 5 types for factor "group", one is the reference - call it "a".
> 
> f <- ols(y ~ age + sex + group, data=dd)
> contrast(f, list(group='a'), list(group='b'))
> 
> I can use this to contrast pairs but can I use this to contrast b 
> against c,d, and e as a group.
> Also "a" against the rest?
> 

Type ?contrast.Design.  You'll see examples of 'vector' contrasts with 
and without weighted/unweighted averaging of effects.  E.g. contrast(f, 
list(group='b'), list(group=c('c','d','e'))) will give 3 contrasts. 
There is an option to average these.

Frank
> 
> Thanks, David
> 
> Frank E Harrell Jr wrote:
> 
>> On Thu, 27 May 2004 16:34:58 +0930
>> "David J. Netherway" <david.netherway at adelaide.edu.au> wrote:
>>
>>  
>>
>>> Hello,
>>>
>>> I am trying to get the same values for the adjusted means and 
>>> standard errors using R that are given in SAS for the
>>> following data. The model is Measurement ~ Age + Gender + Group. I 
>>> can get the adusted means at the mean age  by using predict. I do not 
>>> know how to get the appropriate standard errors at the adjusted means 
>>> for Gender
>>> using values from predict. So I attempted to get them directly from 
>>> the residuals as follows. The data is at the end
>>> of the email. While there is a match for the males there is a large 
>>> difference for the females indicating that what I am doing is wrong.
>>>
>>> #  meanAge <- mean(dd$Age)
>>> meanAgeM <- mean(dd$Age[d$Gender=="M"])
>>> meanAgeF <- mean(dd$Age[d$Gender=="F"])
>>>   
>>
>> . . . .
>>
>> By using sex-specific means of age you are not getting adjusted estimates
>> in the usual sense.
>>
>> I prefer to think of effects as differences in predicted values rather
>> than as complex SAS-like contrasts. The Design package's contrast 
>> function
>> makes this easy (including SEs and confidence limits):
>>
>> library(Design)   # also requires Hmisc
>> d <- datadist(dd); options(datadist='d')
>> f <- ols(y ~ age + sex + group, data=dd)
>> contrast(f, list(sex='M'), list(sex='F'))   # usual adjusted difference M
>> vs F
>> contrast(f, list(sex='M',age=mean(dd$age[dd$sex=='M']),
>>            list(sex='F',age=mean(dd$age[dd$sex=='F')) # M vs F not
>> holding age constant
>>
>> You can also experiment with specifying age=tapply(age, sex, mean,
>> na.rm=TRUE) using some of the contrast.Design options.
>> ---
>> Frank E Harrell Jr   Professor and Chair           School of Medicine
>>                     Department of Biostatistics   Vanderbilt University
>>  
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From bates at stat.wisc.edu  Mon May 31 14:20:40 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 31 May 2004 07:20:40 -0500
Subject: [R] glmm?
In-Reply-To: <40BA9339.1040406@pdf.com>
References: <40BA9339.1040406@pdf.com>
Message-ID: <6rvficokiv.fsf@bates4.stat.wisc.edu>

Spencer Graves <spencer.graves at pdf.com> writes:

>       Is there an easy way to get confidence intervals from "glmm" in
>       Jim Lindsey's library(repeated)?  Consider the following slight
>       modification of an example from the help page: >  df <-
>       data.frame(r=rbinom(10,10,0.5), n=rep(10,10), x=c(rep(0,5),
> 
> +              rep(1,5)), nest=1:10)
>  > fit <- glmm(cbind(r,n-r)~x, family=binomial, nest=nest, data=df)
>  > summary(fit)
> Error in print.summary.glmm(structure(list(call = glmm(cbind(r, n - r) ~  :
>         couldn't find function "print.summary.glm"

It's a namespace problem.  The S3 method, which is being called
directly, is now in a namespace.  

> getAnywhere("print.summary.glm")
A single object matching 'print.summary.glm' was found
It was found in the following places
  registered S3 method for print from namespace stats
  namespace:stats

Check the form of the call in question to see if the object being
printed does have class summary.glm, in which case the generic
function print should be used instead of print.summary.glm.



From osman.al.radi at utoronto.ca  Mon May 31 16:06:51 2004
From: osman.al.radi at utoronto.ca (Osman)
Date: Mon, 31 May 2004 10:06:51 -0400
Subject: [R] bar plot patterns
References: <40BB1093.23325.1FD412@localhost>
Message-ID: <003501c44718$85741120$ac90148e@Toshi>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040531/b214cbc4/attachment.pl

From elw at stderr.org  Mon May 31 16:54:21 2004
From: elw at stderr.org (elijah wright)
Date: Mon, 31 May 2004 09:54:21 -0500 (CDT)
Subject: [R] Rmetrics New Built
In-Reply-To: <40BADEEA.2000506@itp.phys.ethz.ch>
References: <40BADEEA.2000506@itp.phys.ethz.ch>
Message-ID: <Pine.LNX.4.58.0405310949130.4526@illuminati.stderr.org>


> What are the next steps?
>
> Maybe somebody is around and can try to build the packages for (Debian)
> Linux and Mac OSX. This would be a great help for me! The *.tar.gz files
> are availalble on

> If the Linux and Mac OSX builds are successfully done, I will submit the
> packages to the CRAN server.

all four of the packages successfully build on Debian unstable - no
errors, nor warnings.  this is a Good Thing.  I would guesstimate that
they should build trivially on OSX as well, but i'm at home today [in the
US, today is Memorial day - a sort of low-key holiday when people tend to
have picnics and things] and have no intention of driving to campus...

maybe you can sucker Dirk into packaging them for Debian and getting them
into the system there?  :)

--elijah



From slist at oomvanlieshout.net  Mon May 31 17:25:27 2004
From: slist at oomvanlieshout.net (Sander Oom)
Date: Mon, 31 May 2004 17:25:27 +0200
Subject: [R] Calculating distances between points in a data frame?
In-Reply-To: <p0521061ebce02f09a3d9@[4.243.164.183]>
References: <p0521061abcdedce26749@[4.243.164.183]>
	<200405300214.02921.deepayan@stat.wisc.edu>
	<p0521061ebce02f09a3d9@[4.243.164.183]>
Message-ID: <6.1.0.6.0.20040531170406.0242d978@localhost>

Dear list,

I would like to calculate the distance between consecutive points in a data 
frame. Of course the first point in the data frame does not have a point of 
origin, and should get a value NA. I have tried two different loops, which 
both result in error:

 > num <- seq(0,10,1)
 > X <- seq(0,30,3)
 > Y <- seq(0,40,4)
 > XY <- data.frame(num, X, Y)
 > attach(XY)
 > summary(XY)
       num             X              Y
  Min.   : 0.0   Min.   : 0.0   Min.   : 0
  1st Qu.: 2.5   1st Qu.: 7.5   1st Qu.:10
  Median : 5.0   Median :15.0   Median :20
  Mean   : 5.0   Mean   :15.0   Mean   :20
  3rd Qu.: 7.5   3rd Qu.:22.5   3rd Qu.:30
  Max.   :10.0   Max.   :30.0   Max.   :40
 > plot(X,Y)
 > rngNum <- range(num)
 > for (i in rngNum){
+     XY$DistXY[i] <- sqrt( ((X[i]-X[i-1])^2) + ((Y[i]-Y[i-1])^2) )
+ }
Error in "$<-.data.frame"(`*tmp*`, "DistXY", value = sqrt(((X[i] - X[i -  :
         replacement has 10 rows, data has 11
 > for (i in rngNum){
+     XY$DistXY2[i] <- ifelse(i=min(rngNum), NA, sqrt(((X[i]-X[i-1])^2) + 
((Y[i]-Y[i-1])^2)) )
+ }
Error in ifelse(i = min(rngNum), NA, sqrt(((X[i] - X[i - 1])^2) + ((Y[i] -  :
         unused argument(s) (i ...)
 > detach(XY)
 >

Any suggestions much appreciated,

Sander Oom.


--------------------------------------------------------------
Dr. Sander P. Oom
Animal, Plant and Environmental Sciences
University of the Witwatersrand
Private Bag 3
Wits 2050
South Africa

Tel (work)      +27 (0)11 717 64 04
Tel (home)      +27 (0)18 297 44 51
Fax             +27 (0)18 299 24 64

Email   sander at oomvanlieshout.net
Web     www.oomvanlieshout.net/sander



From Ted.Harding at nessie.mcc.ac.uk  Mon May 31 16:51:53 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 31 May 2004 15:51:53 +0100 (BST)
Subject: [R] [OT] "plot y against x"
Message-ID: <XFMail.040531155153.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

I'd be grateful for some views on the following.

When I say "plot y against x" I mean that y is on the vertical
axis and x is on the horizontal axis. I acquired this usage so
long ago that I can no longer remember how I acquired it, and
therefore can not cite my "authority" for my usage. There can
also be an implication that y is a function of x (or y is a
"dependent" variable and x an "independent" variable).
To the best of my knowledge, this is the standard usage.

However, I have had a query which suggests that the "transposed"
meaning may be quite frequently adopted, i.e.

  "plot x [horizontal axis] against y [vertical axis]"

Google tells me that "plot y against x" throws up about 147 hits,
while "plot x against y" throws up about 54 hits. One of the
latter is unequivocal and comes from a respected department of
mathematics:

http://www.maths.lancs.ac.uk/dept/coursenotes/lab100/pdffiles/a12.pdf

  Q 12.1 A simple plot.
  Invoke Matlab in an Xterm window and position the
  Figure window so that you can see it properly.
  x = -3:5    % plotting values (range)
  y = 2*x + 3 % a linear function of x
  plot(x,y)   % plot x against y

and at least two refer to "Statistical analysis with R" (so maybe
I'm not so off-topic after all), also unequivocal, e.g.:

http://www.nbn.ac.za/Education/11-stats-2004/R1.8/r_workshop.pdf 

  Example: Plotting functions
  Assume that you were to plot a function by hand. One possibility
  of doing it is to
  1. Select some xvalues from the range to be plotted
  2. Compute the corresponding y = f(x) values
  3. Plot x against y
  4. Add a (more or less) smooth line connecting the (x; y)points
  ...
  plot(x, y)            # plots x against y

(However, in R itself, "?plot" is discretely silent about what is
 "against" what!)

I'd value commments on whether the above "transposed" usage is in
fact sufficiently common (perhaps mainly in certain subject areas)
as to constitute a "linguistic enclave" with a valid dialectal
usage which is the opposite of the standard. Or maybe there isn't
really a standard.

This would help to respond to the query, which whether in writing
something which uses "plot y against x" it would be worth while
including an explicit explanation of which way round it is meant,
so that it's clear to any reader, whichever dialectal group they
belong to.

There was also a related query on whether "regression of Y on X"
could be understood the "wrong way round" and about usage of the
phrase "a model for Y against X". Where regression is concerned,
I don't think there is room for doubt and anyone who interpreted
it on the lines of "X~Y" is simply wrong. "Model for Y against X",
however, is not a standard phrase, I think (though clear enough
if you make the analogy with "plot"), and would need the same
disambiguation as "plot y against x" (if any is needed).

With thanks!
Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 31-May-04                                       Time: 15:51:53
------------------------------ XFMail ------------------------------



From wolski at molgen.mpg.de  Mon May 31 17:37:32 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 31 May 2004 17:37:32 +0200
Subject: [R] Calculating distances between points in a data frame?
In-Reply-To: <6.1.0.6.0.20040531170406.0242d978@localhost>
References: <p0521061abcdedce26749@[4.243.164.183]>
	<200405300214.02921.deepayan@stat.wisc.edu>
	<p0521061ebce02f09a3d9@[4.243.164.183]>
	<6.1.0.6.0.20040531170406.0242d978@localhost>
Message-ID: <200405311737320028.001FD93F@mail.math.fu-berlin.de>

Hi!
It may bee that the function dist can be of some use to you?
?diff

I have something like this in mind. (you do not need a loop.)
XY$DistXY <- sqrt(diff(X)^2+diff(Y)^2)

Have fun trying.
Sincerely Eryk

*********** REPLY SEPARATOR  ***********

On 5/31/2004 at 5:25 PM Sander Oom wrote:

>Dear list,
>
>I would like to calculate the distance between consecutive points in a
>data 
>frame. Of course the first point in the data frame does not have a point
>of 
>origin, and should get a value NA. I have tried two different loops, which 
>both result in error:
>
> > num <- seq(0,10,1)
> > X <- seq(0,30,3)
> > Y <- seq(0,40,4)
> > XY <- data.frame(num, X, Y)
> > attach(XY)
> > summary(XY)
>       num             X              Y
>  Min.   : 0.0   Min.   : 0.0   Min.   : 0
>  1st Qu.: 2.5   1st Qu.: 7.5   1st Qu.:10
>  Median : 5.0   Median :15.0   Median :20
>  Mean   : 5.0   Mean   :15.0   Mean   :20
>  3rd Qu.: 7.5   3rd Qu.:22.5   3rd Qu.:30
>  Max.   :10.0   Max.   :30.0   Max.   :40
> > plot(X,Y)
> > rngNum <- range(num)
> > for (i in rngNum){
>+     XY$DistXY[i] <- sqrt( ((X[i]-X[i-1])^2) + ((Y[i]-Y[i-1])^2) )
>+ }
>Error in "$<-.data.frame"(`*tmp*`, "DistXY", value = sqrt(((X[i] - X[i -  :
>         replacement has 10 rows, data has 11
> > for (i in rngNum){
>+     XY$DistXY2[i] <- ifelse(i=min(rngNum), NA, sqrt(((X[i]-X[i-1])^2) + 
>((Y[i]-Y[i-1])^2)) )
>+ }
>Error in ifelse(i = min(rngNum), NA, sqrt(((X[i] - X[i - 1])^2) + ((Y[i] -
> :
>         unused argument(s) (i ...)
> > detach(XY)
> >
>
>Any suggestions much appreciated,
>
>Sander Oom.
>
>
>--------------------------------------------------------------
>Dr. Sander P. Oom
>Animal, Plant and Environmental Sciences
>University of the Witwatersrand
>Private Bag 3
>Wits 2050
>South Africa
>
>Tel (work)      +27 (0)11 717 64 04
>Tel (home)      +27 (0)18 297 44 51
>Fax             +27 (0)18 299 24 64
>
>Email   sander at oomvanlieshout.net
>Web     www.oomvanlieshout.net/sander
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin       'v'    
tel: 0049-30-83875219               /   \    
mail: wolski at molgen.mpg.de        ---W-W----    http://www.molgen.mpg.de/~wolski



From Charles.Annis at StatisticalEngineering.com  Mon May 31 17:44:55 2004
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Mon, 31 May 2004 11:44:55 -0400
Subject: [R] [OT] "plot y against x"
In-Reply-To: <XFMail.040531155153.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <200405311544.i4VFiomG025802@hypatia.math.ethz.ch>

Engineers have been plotting stress (or strain, or log of either) as y
against log(fatigue lifetime) as x for 100 years or more.  Thus it appears
that allowable stress is a function of required cycles, and that is how the
plot is interpreted.  The underlying regression, however, correctly treats
observed lifetime as the dependent variable (even though it's plotted as x)
and testing stress (or strain, in a strain-controlled test) as the
independent variable (plotted as y).  Errors are in the horizontal
direction.  The curve is just "plotted wrong."  However, the convention of
plotting stress (or strain) vertically and lifetime horizontally is so
universal among engineers, that a statistician risks loss of credibility to
present a curve with the axes exchanged, even though both plots have the
identical underlying regression.  

Charles Annis, P.E.
 
Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  503-217-5849
http://www.StatisticalEngineering.com

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ted Harding
Sent: Monday, May 31, 2004 10:52 AM
To: r-help at stat.math.ethz.ch
Subject: [R] [OT] "plot y against x"

Hi Folks,

I'd be grateful for some views on the following.

When I say "plot y against x" I mean that y is on the vertical
axis and x is on the horizontal axis. I acquired this usage so
long ago that I can no longer remember how I acquired it, and
therefore can not cite my "authority" for my usage. There can
also be an implication that y is a function of x (or y is a
"dependent" variable and x an "independent" variable).
To the best of my knowledge, this is the standard usage.

However, I have had a query which suggests that the "transposed"
meaning may be quite frequently adopted, i.e.

  "plot x [horizontal axis] against y [vertical axis]"

Google tells me that "plot y against x" throws up about 147 hits,
while "plot x against y" throws up about 54 hits. One of the
latter is unequivocal and comes from a respected department of
mathematics:

http://www.maths.lancs.ac.uk/dept/coursenotes/lab100/pdffiles/a12.pdf

  Q 12.1 A simple plot.
  Invoke Matlab in an Xterm window and position the
  Figure window so that you can see it properly.
  x = -3:5    % plotting values (range)
  y = 2*x + 3 % a linear function of x
  plot(x,y)   % plot x against y

and at least two refer to "Statistical analysis with R" (so maybe
I'm not so off-topic after all), also unequivocal, e.g.:

http://www.nbn.ac.za/Education/11-stats-2004/R1.8/r_workshop.pdf 

  Example: Plotting functions
  Assume that you were to plot a function by hand. One possibility
  of doing it is to
  1. Select some xvalues from the range to be plotted
  2. Compute the corresponding y = f(x) values
  3. Plot x against y
  4. Add a (more or less) smooth line connecting the (x; y)points
  ...
  plot(x, y)            # plots x against y

(However, in R itself, "?plot" is discretely silent about what is
 "against" what!)

I'd value commments on whether the above "transposed" usage is in
fact sufficiently common (perhaps mainly in certain subject areas)
as to constitute a "linguistic enclave" with a valid dialectal
usage which is the opposite of the standard. Or maybe there isn't
really a standard.

This would help to respond to the query, which whether in writing
something which uses "plot y against x" it would be worth while
including an explicit explanation of which way round it is meant,
so that it's clear to any reader, whichever dialectal group they
belong to.

There was also a related query on whether "regression of Y on X"
could be understood the "wrong way round" and about usage of the
phrase "a model for Y against X". Where regression is concerned,
I don't think there is room for doubt and anyone who interpreted
it on the lines of "X~Y" is simply wrong. "Model for Y against X",
however, is not a standard phrase, I think (though clear enough
if you make the analogy with "plot"), and would need the same
disambiguation as "plot y against x" (if any is needed).

With thanks!
Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 31-May-04                                       Time: 15:51:53
------------------------------ XFMail ------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From zhuw at mail.smu.edu  Mon May 31 18:02:28 2004
From: zhuw at mail.smu.edu (Zhu Wang)
Date: Mon, 31 May 2004 11:02:28 -0500
Subject: [R] Question about building library and BLAS
Message-ID: <1086019347.2399.21.camel@zwang.stat.smu.edu>

Dear helpers,

I am trying to create a library which uses some Fortran source files and Lapack and Blas
subroutines. The Fortran source files from the original author contain subroutines 
isamax.f, sgefa.f and sgesl.f, which are part of BLAS subroutines on my Linux computer,
but maybe different (old) versions. So in addition to these subroutines, there are other
Lapack and Blas subroutines involved. There is no problem to compile and run these files
using g77, such as the following to create car:

g77 -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 car
isamax.f, sgefa.f sgesl.f foo1.f ... foo20.f -llapack -lblas

By doing this, the procedure does not use subroutines isamax.f, sgefa.f sgesl.f in BLAS,
as expected. In fact, there are problems to use these subroutines in BLAS, for some reason.

Now what I want is to build an R library. The Makefile is the following:

LIBNAME=car
 
PKG_LIBS = $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)
 
OBJS=isamax.o saxpy.o sscal.o foo1.o ... foo20.o -llapack -lblas

$(LIBNAME)$(SHLIB_EXT): $(OBJS)
        $(SHLIB_LD) $(SHLIB_LDFLAGS) -o $@ $(OBJS) $(FLIBS)
 
clean:
        @rm -f *.o *.$(SHLIB_EXT)
 
realclean: clean

Some compiling outputs are the following:

g77 -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c isamax.f
-o isamax.o
...
g77 -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c foo1.f -o
foo1.o
......
gcc -shared -o car.so isamax.o ...... foo20.o -llapack -lblas
-L/usr/local/lib -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.2
-L/usr/lib/gcc-lib/i386-redhat-linux/3.3.2/../../.. -lfrtbegin -lg2c
-lm -lgcc_s

However, it turns out that this process did not take into account these 
three files isamax, sgefa.f and sgesl.f. 
Instead, it used subroutines in Blas, but again for some reason, it provided
error. 

My question is how do I set up my Makefile, or maybe other files, such that I have
the same result as I did to compile and run these Fortran files directly.

Thanks in advance.

-- 
Zhu Wang

Statistical Science Department
Southern Methodist University
Dallas, TX 75275-0332
Phone:(214)768-2453  Fax:(214)768-4035
zhuw at mail.smu.edu



From edd at debian.org  Mon May 31 18:18:52 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 31 May 2004 11:18:52 -0500
Subject: [R] Rmetrics New Built
In-Reply-To: <Pine.LNX.4.58.0405310949130.4526@illuminati.stderr.org>
References: <40BADEEA.2000506@itp.phys.ethz.ch>
	<Pine.LNX.4.58.0405310949130.4526@illuminati.stderr.org>
Message-ID: <20040531161852.GA31422@sonny.eddelbuettel.com>

On Mon, May 31, 2004 at 09:54:21AM -0500, elijah wright wrote:
> > If the Linux and Mac OSX builds are successfully done, I will submit the
> > packages to the CRAN server.
> 
> all four of the packages successfully build on Debian unstable - no
> errors, nor warnings.  this is a Good Thing.  I would guesstimate that

Ah, thanks, good to know. Did you try 'R CMD check' too, for good measure?

> they should build trivially on OSX as well, but i'm at home today [in the
> US, today is Memorial day - a sort of low-key holiday when people tend to
> have picnics and things] and have no intention of driving to campus...
> 
> maybe you can sucker Dirk into packaging them for Debian and getting them
> into the system there?  :)

That has of course been the plan all along, for both Debian and Quantian.

I'm a little behind on a few other things, but knowing that these build out
of the box may well move them up the priority queue :)

Thanks, Dirk

-- 
FEATURE:  VW Beetle license plate in California



From bates at stat.wisc.edu  Mon May 31 18:29:19 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 31 May 2004 11:29:19 -0500
Subject: [R] Question about building library and BLAS
In-Reply-To: <1086019347.2399.21.camel@zwang.stat.smu.edu>
References: <1086019347.2399.21.camel@zwang.stat.smu.edu>
Message-ID: <6risecmug0.fsf@bates4.stat.wisc.edu>

Zhu Wang <zhuw at mail.smu.edu> writes:

> I am trying to create a library which uses some Fortran source files

  Someone named Martin Maechler will shortly be sending you email
  regarding the distinction between 'library' and 'package' :-)

  (You are creating a package, not a library, despite the fact that
   you will later attach it using a function called 'library'.)

> and Lapack and Blas subroutines. The Fortran source files from the
> original author contain subroutines isamax.f, sgefa.f and sgesl.f,
> which are part of BLAS subroutines on my Linux computer, but maybe
> different (old) versions. So in addition to these subroutines, there
> are other Lapack and Blas subroutines involved. There is no problem
> to compile and run these files using g77, such as the following to
> create car:
> 
> g77 -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 car
> isamax.f, sgefa.f sgesl.f foo1.f ... foo20.f -llapack -lblas
> 
> By doing this, the procedure does not use subroutines isamax.f, sgefa.f sgesl.f in BLAS,
> as expected. In fact, there are problems to use these subroutines in BLAS, for some reason.
> 
> Now what I want is to build an R library. The Makefile is the following:
> 
> LIBNAME=car
>  
> PKG_LIBS = $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)
>  
> OBJS=isamax.o saxpy.o sscal.o foo1.o ... foo20.o -llapack -lblas
> 
> $(LIBNAME)$(SHLIB_EXT): $(OBJS)
>         $(SHLIB_LD) $(SHLIB_LDFLAGS) -o $@ $(OBJS) $(FLIBS)
>  
> clean:
>         @rm -f *.o *.$(SHLIB_EXT)
>  
> realclean: clean
> 
> Some compiling outputs are the following:
> 
> g77 -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c isamax.f
> -o isamax.o
> ...
> g77 -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c foo1.f -o
> foo1.o
> ......
> gcc -shared -o car.so isamax.o ...... foo20.o -llapack -lblas
> -L/usr/local/lib -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.2
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.2/../../.. -lfrtbegin -lg2c
> -lm -lgcc_s
> 
> However, it turns out that this process did not take into account these 
> three files isamax, sgefa.f and sgesl.f. 
> Instead, it used subroutines in Blas, but again for some reason, it provided
> error. 

I think you are working too hard.  Temporarily move the source files
for the BLAS and Lapack routines to backup names, such as
isamax.f.old, then do the same to the Makefile (i.e. move it to
Makefile.old) then create a file called Makevars containing

PKG_LIBS = $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)



From bates at stat.wisc.edu  Mon May 31 18:39:38 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: 31 May 2004 11:39:38 -0500
Subject: [R] Question about building library and BLAS
In-Reply-To: <6risecmug0.fsf@bates4.stat.wisc.edu>
References: <1086019347.2399.21.camel@zwang.stat.smu.edu>
	<6risecmug0.fsf@bates4.stat.wisc.edu>
Message-ID: <6rekp0mtyt.fsf@bates4.stat.wisc.edu>

Douglas Bates <bates at cs.wisc.edu> writes:

> Zhu Wang <zhuw at mail.smu.edu> writes:
> 
> > I am trying to create a library which uses some Fortran source files
> 
>   Someone named Martin Maechler will shortly be sending you email
>   regarding the distinction between 'library' and 'package' :-)
> 
>   (You are creating a package, not a library, despite the fact that
>    you will later attach it using a function called 'library'.)
> 
> > and Lapack and Blas subroutines. The Fortran source files from the
> > original author contain subroutines isamax.f, sgefa.f and sgesl.f,
> > which are part of BLAS subroutines on my Linux computer, but maybe
> > different (old) versions. So in addition to these subroutines, there
> > are other Lapack and Blas subroutines involved. There is no problem
> > to compile and run these files using g77, such as the following to
> > create car:
> > 
> > g77 -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 car
> > isamax.f, sgefa.f sgesl.f foo1.f ... foo20.f -llapack -lblas
> > 
> > By doing this, the procedure does not use subroutines isamax.f, sgefa.f sgesl.f in BLAS,
> > as expected. In fact, there are problems to use these subroutines in BLAS, for some reason.
> > 
> > Now what I want is to build an R library. The Makefile is the following:
> > 
> > LIBNAME=car
> >  
> > PKG_LIBS = $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)
> >  
> > OBJS=isamax.o saxpy.o sscal.o foo1.o ... foo20.o -llapack -lblas
> > 
> > $(LIBNAME)$(SHLIB_EXT): $(OBJS)
> >         $(SHLIB_LD) $(SHLIB_LDFLAGS) -o $@ $(OBJS) $(FLIBS)
> >  
> > clean:
> >         @rm -f *.o *.$(SHLIB_EXT)
> >  
> > realclean: clean
> > 
> > Some compiling outputs are the following:
> > 
> > g77 -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c isamax.f
> > -o isamax.o
> > ...
> > g77 -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c foo1.f -o
> > foo1.o
> > ......
> > gcc -shared -o car.so isamax.o ...... foo20.o -llapack -lblas
> > -L/usr/local/lib -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.2
> > -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.2/../../.. -lfrtbegin -lg2c
> > -lm -lgcc_s
> > 
> > However, it turns out that this process did not take into account these 
> > three files isamax, sgefa.f and sgesl.f. 
> > Instead, it used subroutines in Blas, but again for some reason, it provided
> > error. 
> 
> I think you are working too hard.  Temporarily move the source files
> for the BLAS and Lapack routines to backup names, such as
> isamax.f.old, then do the same to the Makefile (i.e. move it to
> Makefile.old) then create a file called Makevars containing
> 
> PKG_LIBS = $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)

I should have read your message more carefully.  Those three Fortran
routines that you mention are single precision and it would be silly
to use them on modern computers.  R only provides single precision
floating point for compatibility.  All numerical linear algebra is
doing in double precision.  Check where sgefa and sgesl are being
called and see if they really need to be in single precision.  I'm
sure if you replace them by calls to dgefa and dgesl (and suitably
change the precision of the arguments) they will run as fast as
before.  In fact you can probably use the Lapack routines dgetrf and
dgetrs instead and get a performance boost.



From ggrothendieck at myway.com  Mon May 31 18:44:28 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 31 May 2004 16:44:28 +0000 (UTC)
Subject: [R] Calculating distances between points in a data frame?
References: <p0521061abcdedce26749@[4.243.164.183]>
	<200405300214.02921.deepayan@stat.wisc.edu>
	<p0521061ebce02f09a3d9@[4.243.164.183]>
	<6.1.0.6.0.20040531170406.0242d978@localhost>
Message-ID: <loom.20040531T182159-597@post.gmane.org>


Try using running from the gregmisc package with pad = TRUE:


require(gregmisc)
XY <- data.frame(num = seq(0,10), X = seq(0,30,3), Y = seq(0, 40, 4) )
DistXY <- function(idx) {
   i <- idx[2]
   with(XY, sqrt( (X[i]-X[i-1])^2 + (Y[i]-Y[i-1])^2 ) )
}
XY$Dist <- running( 1:nrow(XY), width=2, fun = DistXY, pad = TRUE )


Sander Oom <slist <at> oomvanlieshout.net> writes:

: 
: Dear list,
: 
: I would like to calculate the distance between consecutive points in a data 
: frame. Of course the first point in the data frame does not have a point of 
: origin, and should get a value NA. I have tried two different loops, which 
: both result in error:
: 
:  > num <- seq(0,10,1)
:  > X <- seq(0,30,3)
:  > Y <- seq(0,40,4)
:  > XY <- data.frame(num, X, Y)
:  > attach(XY)
:  > summary(XY)
:        num             X              Y
:   Min.   : 0.0   Min.   : 0.0   Min.   : 0
:   1st Qu.: 2.5   1st Qu.: 7.5   1st Qu.:10
:   Median : 5.0   Median :15.0   Median :20
:   Mean   : 5.0   Mean   :15.0   Mean   :20
:   3rd Qu.: 7.5   3rd Qu.:22.5   3rd Qu.:30
:   Max.   :10.0   Max.   :30.0   Max.   :40
:  > plot(X,Y)
:  > rngNum <- range(num)
:  > for (i in rngNum){
: +     XY$DistXY[i] <- sqrt( ((X[i]-X[i-1])^2) + ((Y[i]-Y[i-1])^2) )
: + }
: Error in "$<-.data.frame"(`*tmp*`, "DistXY", value = sqrt(((X[i] - X[i -  :
:          replacement has 10 rows, data has 11
:  > for (i in rngNum){
: +     XY$DistXY2[i] <- ifelse(i=min(rngNum), NA, sqrt(((X[i]-X[i-1])^2) + 
: ((Y[i]-Y[i-1])^2)) )
: + }
: Error in ifelse(i = min(rngNum), NA, sqrt(((X[i] - X[i - 1])^2) + ((Y[i] -  :
:          unused argument(s) (i ...)
:  > detach(XY)
:  >
: 
: Any suggestions much appreciated,
: 
: Sander Oom.
: 
: --------------------------------------------------------------
: Dr. Sander P. Oom
: Animal, Plant and Environmental Sciences
: University of the Witwatersrand
: Private Bag 3
: Wits 2050
: South Africa
: 
: Tel (work)      +27 (0)11 717 64 04
: Tel (home)      +27 (0)18 297 44 51
: Fax             +27 (0)18 299 24 64
: 
: Email   sander <at> oomvanlieshout.net
: Web     www.oomvanlieshout.net/sander
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From grr at grell.mailshell.com  Mon May 31 18:44:20 2004
From: grr at grell.mailshell.com (grr@grell.mailshell.com)
Date: Mon, 31 May 2004 09:44:20 -0700
Subject: [R] Putting referenced titles on plots
In-Reply-To: <Pine.LNX.4.44.0405160721140.32514-100000@gannet.stats>
References: <Pine.LNX.4.44.0405160721140.32514-100000@gannet.stats>
Message-ID: <20040531164428.9755.qmail@mailshell.com>

I have a data frame "ctx" and an array "names", where names[i] is the 
column name for ctx[i], and am making histograms for each column of 
ctx:

for (i in 2:ncol(ctx)){hist(ctx[,i], br=100, main=names[i])}

The titles don't come out like I expect. Each names[i] is something 
like "1098_s_at" and R doesn't seem to like printing these. Instead, it 
prints "1" or "2" or "3" etc.

I have also tried binding ctx and names into a single data frame and 
referencing the first row of each [i] as the title, but I get the same 
result.

Can someone tell me how to get these titles attached?

Thanks,

Graham



From kafernan at uwaterloo.ca  Mon May 31 19:10:05 2004
From: kafernan at uwaterloo.ca (Kimberly Ann Fernandes)
Date: Mon, 31 May 2004 13:10:05 -0400
Subject: [R] Contrasts
Message-ID: <000001c44732$21545b90$7bf86181@CONCEPTUALNESS>

Hello,

I am trying to figure out how to conduct a t-test on a specific contrast
for my data.  I have four factors in my data and would like to conduct a
t-test on the average of the data from the first two factors against the
average of the data on the second two factor (i.e. is the average of the
first two different from the average of the second two).  Is there a
quick way to do this?  I found the contrast function, but wasn't sure
how to apply it.

Thank you,
Kim



From angel_lul at hotmail.com  Mon May 31 23:18:28 2004
From: angel_lul at hotmail.com (Angel Lopez)
Date: Mon, 31 May 2004 23:18:28 +0200
Subject: [R] Regression model type II
In-Reply-To: <40B730AA.9090704@ifremer.fr>
References: <40B730AA.9090704@ifremer.fr>
Message-ID: <40BBA124.4040602@hotmail.com>

Hi Benjamin,
Maybe this link is useful to you:
http://eeb37.biosci.arizona.edu/~brian/splus.html
It has a function 'slope' that calculates different type II regressions 
and a link to a paper comparing them.
Although it was written for S-plus it works in R too.
If you get any better solutions, let me know.
Best regards,
Angel

Benjamin PLANQUE wrote:
> I am trying to fit regression models type II with R, but it seems to me 
> that most (all) of the linear model functions are for type I regressions.
> 
> Does anyone knows whether type II regressions functions exist in R.
> 
> Benjamin
>



From ligges at statistik.uni-dortmund.de  Mon May 31 19:36:21 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 31 May 2004 19:36:21 +0200
Subject: [R] Putting referenced titles on plots
In-Reply-To: <20040531164428.9755.qmail@mailshell.com>
References: <Pine.LNX.4.44.0405160721140.32514-100000@gannet.stats>
	<20040531164428.9755.qmail@mailshell.com>
Message-ID: <40BB6D15.4000904@statistik.uni-dortmund.de>

grr at grell.mailshell.com wrote:

> I have a data frame "ctx" and an array "names", where names[i] is the 
> column name for ctx[i], and am making histograms for each column of ctx:
> 
> for (i in 2:ncol(ctx)){hist(ctx[,i], br=100, main=names[i])}
>

Works for me. Are you sure "names" is a vector containing the stuff you 
expect to be printed?

Uwe Ligges


> The titles don't come out like I expect. Each names[i] is something like 
> "1098_s_at" and R doesn't seem to like printing these. Instead, it 
> prints "1" or "2" or "3" etc.
> 
> I have also tried binding ctx and names into a single data frame and 
> referencing the first row of each [i] as the title, but I get the same 
> result.
> 
> Can someone tell me how to get these titles attached?
> 
> Thanks,
> 
> Graham
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From zhuw at mail.smu.edu  Mon May 31 19:33:40 2004
From: zhuw at mail.smu.edu (Zhu Wang)
Date: Mon, 31 May 2004 12:33:40 -0500
Subject: [R] Question about building library and BLAS
In-Reply-To: <6rekp0mtyt.fsf@bates4.stat.wisc.edu>
References: <1086019347.2399.21.camel@zwang.stat.smu.edu>
	<6risecmug0.fsf@bates4.stat.wisc.edu>
	<6rekp0mtyt.fsf@bates4.stat.wisc.edu>
Message-ID: <1086024819.2399.37.camel@zwang.stat.smu.edu>

On Mon, 2004-05-31 at 11:39, Douglas Bates wrote:

> I should have read your message more carefully.  Those three Fortran
> routines that you mention are single precision and it would be silly
> to use them on modern computers.  R only provides single precision
> floating point for compatibility.  All numerical linear algebra is
> doing in double precision.  Check where sgefa and sgesl are being
> called and see if they really need to be in single precision.  I'm
> sure if you replace them by calls to dgefa and dgesl (and suitably
> change the precision of the arguments) they will run as fast as
> before. 

Thanks. I have replaced sgefa and sgesl with dgefa and dgesl. The
results are confirmed by running the compiled Fortran code. I will
convey this to the original author.

>  In fact you can probably use the Lapack routines dgetrf and
> dgetrs instead and get a performance boost.

I will try to improve later.

-- 
Zhu Wang



From spencer.graves at pdf.com  Mon May 31 19:37:08 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 31 May 2004 10:37:08 -0700
Subject: [R] Putting referenced titles on plots
In-Reply-To: <20040531164428.9755.qmail@mailshell.com>
References: <Pine.LNX.4.44.0405160721140.32514-100000@gannet.stats>
	<20040531164428.9755.qmail@mailshell.com>
Message-ID: <40BB6D44.7060409@pdf.com>

      1.  That seems strange.  The following simplification of your 
function produced sensible results for me: 

             hist(1:4, main= "1098_s_at")

      I got similar results from your exact statement after first 
defining names and ctx as follows: 

      names <- letters[1:3]
      ctx <- data.frame(x=1:4, y=1:4, a=1:4)

      In each case, I got a histogram with a standard text title at the 
top.  What version of R are you running?  If it's NOT R 1.9.0pat, you 
might try upgrading -- and then running "update.packages()". 

      2. "names" is that name of a function, and it is generally 
considered bad practice to mask function names with names of other 
objects, even though R can often (though not always) determine which 
object you want from the context.  What do you get from "conflicts()"? 

      hope this helps.  spencer graves

grr at grell.mailshell.com wrote:

> I have a data frame "ctx" and an array "names", where names[i] is the 
> column name for ctx[i], and am making histograms for each column of ctx:
>
> for (i in 2:ncol(ctx)){hist(ctx[,i], br=100, main=names[i])}
>
> The titles don't come out like I expect. Each names[i] is something 
> like "1098_s_at" and R doesn't seem to like printing these. Instead, 
> it prints "1" or "2" or "3" etc.
>
> I have also tried binding ctx and names into a single data frame and 
> referencing the first row of each [i] as the title, but I get the same 
> result.
>
> Can someone tell me how to get these titles attached?
>
> Thanks,
>
> Graham
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From slist at oomvanlieshout.net  Mon May 31 19:40:29 2004
From: slist at oomvanlieshout.net (Sander Oom)
Date: Mon, 31 May 2004 19:40:29 +0200
Subject: [R] Calculating distances between points in a data frame?
In-Reply-To: <loom.20040531T182159-597@post.gmane.org>
References: <p0521061abcdedce26749@[4.243.164.183]>
	<200405300214.02921.deepayan@stat.wisc.edu>
	<p0521061ebce02f09a3d9@[4.243.164.183]>
	<6.1.0.6.0.20040531170406.0242d978@localhost>
	<loom.20040531T182159-597@post.gmane.org>
Message-ID: <6.1.0.6.0.20040531193749.02497ae0@localhost>

Hi Gabor,

Thanks for your suggestion. However when installing the package gregmisc, I 
get the following error:

 > local({a <- CRAN.packages()
+ install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a)})
trying URL `http://cran.r-project.org/bin/windows/contrib/1.9/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 17940 bytes
opened URL
downloaded 17Kb

trying URL 
`http://cran.r-project.org/bin/windows/contrib/1.9/gregmisc_1.11.0.zip'
Error in download.file(url, destfile, method, mode = "wb") :
         cannot open URL 
`http://cran.r-project.org/bin/windows/contrib/1.9/gregmisc_1.11.0.zip'
In addition: Warning message:
cannot open: HTTP status was `404 Not Found'
 >

I was quite surprised as well! I tried different mirrors, but to no avail.

Maybe tomorrow,

Sander.


At 18:44 2004/05/31, you wrote:

>Try using running from the gregmisc package with pad = TRUE:
>
>
>require(gregmisc)
>XY <- data.frame(num = seq(0,10), X = seq(0,30,3), Y = seq(0, 40, 4) )
>DistXY <- function(idx) {
>    i <- idx[2]
>    with(XY, sqrt( (X[i]-X[i-1])^2 + (Y[i]-Y[i-1])^2 ) )
>}
>XY$Dist <- running( 1:nrow(XY), width=2, fun = DistXY, pad = TRUE )
>
>
>Sander Oom <slist <at> oomvanlieshout.net> writes:
>
>:
>: Dear list,
>:
>: I would like to calculate the distance between consecutive points in a data
>: frame. Of course the first point in the data frame does not have a point of
>: origin, and should get a value NA. I have tried two different loops, which
>: both result in error:
>:
>:  > num <- seq(0,10,1)
>:  > X <- seq(0,30,3)
>:  > Y <- seq(0,40,4)
>:  > XY <- data.frame(num, X, Y)
>:  > attach(XY)
>:  > summary(XY)
>:        num             X              Y
>:   Min.   : 0.0   Min.   : 0.0   Min.   : 0
>:   1st Qu.: 2.5   1st Qu.: 7.5   1st Qu.:10
>:   Median : 5.0   Median :15.0   Median :20
>:   Mean   : 5.0   Mean   :15.0   Mean   :20
>:   3rd Qu.: 7.5   3rd Qu.:22.5   3rd Qu.:30
>:   Max.   :10.0   Max.   :30.0   Max.   :40
>:  > plot(X,Y)
>:  > rngNum <- range(num)
>:  > for (i in rngNum){
>: +     XY$DistXY[i] <- sqrt( ((X[i]-X[i-1])^2) + ((Y[i]-Y[i-1])^2) )
>: + }
>: Error in "$<-.data.frame"(`*tmp*`, "DistXY", value = sqrt(((X[i] - X[i -  :
>:          replacement has 10 rows, data has 11
>:  > for (i in rngNum){
>: +     XY$DistXY2[i] <- ifelse(i=min(rngNum), NA, sqrt(((X[i]-X[i-1])^2) +
>: ((Y[i]-Y[i-1])^2)) )
>: + }
>: Error in ifelse(i = min(rngNum), NA, sqrt(((X[i] - X[i - 1])^2) + ((Y[i] 
>-  :
>:          unused argument(s) (i ...)
>:  > detach(XY)
>:  >
>:
>: Any suggestions much appreciated,
>:
>: Sander Oom.
>:
>: --------------------------------------------------------------
>: Dr. Sander P. Oom
>: Animal, Plant and Environmental Sciences
>: University of the Witwatersrand
>: Private Bag 3
>: Wits 2050
>: South Africa
>:
>: Tel (work)      +27 (0)11 717 64 04
>: Tel (home)      +27 (0)18 297 44 51
>: Fax             +27 (0)18 299 24 64
>:
>: Email   sander <at> oomvanlieshout.net
>: Web     www.oomvanlieshout.net/sander
>:
>: ______________________________________________
>: R-help <at> stat.math.ethz.ch mailing list
>: https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>: PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
>:
>:
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Mon May 31 19:49:13 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 31 May 2004 10:49:13 -0700
Subject: [R] Contrasts
In-Reply-To: <000001c44732$21545b90$7bf86181@CONCEPTUALNESS>
References: <000001c44732$21545b90$7bf86181@CONCEPTUALNESS>
Message-ID: <40BB7019.4050002@pdf.com>

      I hope you get a reply from someone who knows more about this than 
I.  However, in the spirit that a quick hack is sometimes better than an 
elegant answer later, consider the following: 

     DF <- data.frame(a=rep(letters[1:4], 2), y=1:8)
 >       DF$b <- ((DF$a %in% letters[1:2])-(DF$a%in% letters[3:4]))
 >       fit <- lm(y~b+a, DF, singular.ok=T)
 >       summary(fit)

Call:
lm(formula = y ~ b + a, data = DF, singular.ok = T)

Residuals:
 1  2  3  4  5  6  7  8
-2 -2 -2 -2  2  2  2  2

Coefficients: (1 not defined because of singularities)
            Estimate Std. Error t value Pr(>|t|) 
(Intercept)    4.500      1.414   3.182   0.0335 *
b             -1.500      1.414  -1.061   0.3486 
ab             1.000      2.828   0.354   0.7415 
ac            -1.000      2.828  -0.354   0.7415 
ad                NA         NA      NA       NA 
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 2.828 on 4 degrees of freedom
Multiple R-Squared: 0.2381,     Adjusted R-squared: -0.3333
F-statistic: 0.4167 on 3 and 4 DF,  p-value: 0.751

      This will give you what you want ONLY if you have the same number 
of observations in the two subsets to be compared.  If not, then you can 
redefine DF$b to produce what you want. 

     hope this helps.  spencer graves

Kimberly Ann Fernandes wrote:

>Hello,
>
>I am trying to figure out how to conduct a t-test on a specific contrast
>for my data.  I have four factors in my data and would like to conduct a
>t-test on the average of the data from the first two factors against the
>average of the data on the second two factor (i.e. is the average of the
>first two different from the average of the second two).  Is there a
>quick way to do this?  I found the contrast function, but wasn't sure
>how to apply it.
>
>Thank you,
>Kim
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From wcvinyard at earthlink.net  Mon May 31 19:50:04 2004
From: wcvinyard at earthlink.net (Bill Vinyard)
Date: Mon, 31 May 2004 13:50:04 -0400
Subject: [R] [OT] "plot y against x"
In-Reply-To: <XFMail.040531155153.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <MJENLJEPCHEMCAGNPDMGCECHCDAA.wcvinyard@earthlink.net>

It would not matter if the relationship you are trying to plot is monotonic
and therefore invertible.  If the relationship is non-monotonic and
therefore not invertible, then it does matter which variable you call
dependent, since in this latter case you have a multi-valued relationship.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Ted Harding
Sent: Monday, May 31, 2004 10:52
To: r-help at stat.math.ethz.ch
Subject: [R] [OT] "plot y against x"


Hi Folks,

I'd be grateful for some views on the following.

When I say "plot y against x" I mean that y is on the vertical
axis and x is on the horizontal axis. I acquired this usage so
long ago that I can no longer remember how I acquired it, and
therefore can not cite my "authority" for my usage. There can
also be an implication that y is a function of x (or y is a
"dependent" variable and x an "independent" variable).
To the best of my knowledge, this is the standard usage.

However, I have had a query which suggests that the "transposed"
meaning may be quite frequently adopted, i.e.

  "plot x [horizontal axis] against y [vertical axis]"

Google tells me that "plot y against x" throws up about 147 hits,
while "plot x against y" throws up about 54 hits. One of the
latter is unequivocal and comes from a respected department of
mathematics:

http://www.maths.lancs.ac.uk/dept/coursenotes/lab100/pdffiles/a12.pdf

  Q 12.1 A simple plot.
  Invoke Matlab in an Xterm window and position the
  Figure window so that you can see it properly.
  x = -3:5    % plotting values (range)
  y = 2*x + 3 % a linear function of x
  plot(x,y)   % plot x against y

and at least two refer to "Statistical analysis with R" (so maybe
I'm not so off-topic after all), also unequivocal, e.g.:

http://www.nbn.ac.za/Education/11-stats-2004/R1.8/r_workshop.pdf

  Example: Plotting functions
  Assume that you were to plot a function by hand. One possibility
  of doing it is to
  1. Select some x-values from the range to be plotted
  2. Compute the corresponding y = f(x) values
  3. Plot x against y
  4. Add a (more or less) smooth line connecting the (x; y)-points
  ...
  plot(x, y)            # plots x against y

(However, in R itself, "?plot" is discretely silent about what is
 "against" what!)

I'd value commments on whether the above "transposed" usage is in
fact sufficiently common (perhaps mainly in certain subject areas)
as to constitute a "linguistic enclave" with a valid dialectal
usage which is the opposite of the standard. Or maybe there isn't
really a standard.

This would help to respond to the query, which whether in writing
something which uses "plot y against x" it would be worth while
including an explicit explanation of which way round it is meant,
so that it's clear to any reader, whichever dialectal group they
belong to.

There was also a related query on whether "regression of Y on X"
could be understood the "wrong way round" and about usage of the
phrase "a model for Y against X". Where regression is concerned,
I don't think there is room for doubt and anyone who interpreted
it on the lines of "X~Y" is simply wrong. "Model for Y against X",
however, is not a standard phrase, I think (though clear enough
if you make the analogy with "plot"), and would need the same
disambiguation as "plot y against x" (if any is needed).

With thanks!
Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 31-May-04                                       Time: 15:51:53
------------------------------ XFMail ------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Mon May 31 20:00:37 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 31 May 2004 20:00:37 +0200
Subject: [R] Calculating distances between points in a data frame?
In-Reply-To: <6.1.0.6.0.20040531193749.02497ae0@localhost>
References: <p0521061abcdedce26749@[4.243.164.183]>	<200405300214.02921.deepayan@stat.wisc.edu>	<p0521061ebce02f09a3d9@[4.243.164.183]>	<6.1.0.6.0.20040531170406.0242d978@localhost>	<loom.20040531T182159-597@post.gmane.org>
	<6.1.0.6.0.20040531193749.02497ae0@localhost>
Message-ID: <40BB72C5.8050604@statistik.uni-dortmund.de>

Sander Oom wrote:

> Hi Gabor,
> 
> Thanks for your suggestion. However when installing the package 
> gregmisc, I get the following error:
> 
>  > local({a <- CRAN.packages()
> + install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a)})
> trying URL `http://cran.r-project.org/bin/windows/contrib/1.9/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 17940 bytes
> opened URL
> downloaded 17Kb
> 
> trying URL 
> `http://cran.r-project.org/bin/windows/contrib/1.9/gregmisc_1.11.0.zip'
> Error in download.file(url, destfile, method, mode = "wb") :
>         cannot open URL 
> `http://cran.r-project.org/bin/windows/contrib/1.9/gregmisc_1.11.0.zip'
> In addition: Warning message:
> cannot open: HTTP status was `404 Not Found'
>  >
> 
> I was quite surprised as well! I tried different mirrors, but to no avail.
> 
> Maybe tomorrow,
> 
> Sander.

There is a bug in the script that uploads binary packages to CRAN.

The PACKAGES file for R-1.9.x/R-2.0.x for Windows erroneously indicates 
that gregmisc_1.11.0.zip is available, but it isn't (at least the 
PACKAGES file will be fixed tomorrow).

gregmisc does not pass the checks (well, it even does not install) on 
Windows, see: CRAN/bin/windows/contrib/checkSummaryWin.html
There is a note on that page which points you to an outdated but still 
available Windows version: 
CRAN/bin/windows/contrib/1.9/last/gregmisc_0.10.2.zip

Uwe Ligges







> 
> At 18:44 2004/05/31, you wrote:
> 
>> Try using running from the gregmisc package with pad = TRUE:
>>
>>
>> require(gregmisc)
>> XY <- data.frame(num = seq(0,10), X = seq(0,30,3), Y = seq(0, 40, 4) )
>> DistXY <- function(idx) {
>>    i <- idx[2]
>>    with(XY, sqrt( (X[i]-X[i-1])^2 + (Y[i]-Y[i-1])^2 ) )
>> }
>> XY$Dist <- running( 1:nrow(XY), width=2, fun = DistXY, pad = TRUE )
>>
>>
>> Sander Oom <slist <at> oomvanlieshout.net> writes:
>>
>> :
>> : Dear list,
>> :
>> : I would like to calculate the distance between consecutive points in 
>> a data
>> : frame. Of course the first point in the data frame does not have a 
>> point of
>> : origin, and should get a value NA. I have tried two different loops, 
>> which
>> : both result in error:
>> :
>> :  > num <- seq(0,10,1)
>> :  > X <- seq(0,30,3)
>> :  > Y <- seq(0,40,4)
>> :  > XY <- data.frame(num, X, Y)
>> :  > attach(XY)
>> :  > summary(XY)
>> :        num             X              Y
>> :   Min.   : 0.0   Min.   : 0.0   Min.   : 0
>> :   1st Qu.: 2.5   1st Qu.: 7.5   1st Qu.:10
>> :   Median : 5.0   Median :15.0   Median :20
>> :   Mean   : 5.0   Mean   :15.0   Mean   :20
>> :   3rd Qu.: 7.5   3rd Qu.:22.5   3rd Qu.:30
>> :   Max.   :10.0   Max.   :30.0   Max.   :40
>> :  > plot(X,Y)
>> :  > rngNum <- range(num)
>> :  > for (i in rngNum){
>> : +     XY$DistXY[i] <- sqrt( ((X[i]-X[i-1])^2) + ((Y[i]-Y[i-1])^2) )
>> : + }
>> : Error in "$<-.data.frame"(`*tmp*`, "DistXY", value = sqrt(((X[i] - 
>> X[i -  :
>> :          replacement has 10 rows, data has 11
>> :  > for (i in rngNum){
>> : +     XY$DistXY2[i] <- ifelse(i=min(rngNum), NA, 
>> sqrt(((X[i]-X[i-1])^2) +
>> : ((Y[i]-Y[i-1])^2)) )
>> : + }
>> : Error in ifelse(i = min(rngNum), NA, sqrt(((X[i] - X[i - 1])^2) + 
>> ((Y[i] -  :
>> :          unused argument(s) (i ...)
>> :  > detach(XY)
>> :  >
>> :
>> : Any suggestions much appreciated,
>> :
>> : Sander Oom.
>> :
>> : --------------------------------------------------------------
>> : Dr. Sander P. Oom
>> : Animal, Plant and Environmental Sciences
>> : University of the Witwatersrand
>> : Private Bag 3
>> : Wits 2050
>> : South Africa
>> :
>> : Tel (work)      +27 (0)11 717 64 04
>> : Tel (home)      +27 (0)18 297 44 51
>> : Fax             +27 (0)18 299 24 64
>> :
>> : Email   sander <at> oomvanlieshout.net
>> : Web     www.oomvanlieshout.net/sander
>> :
>> : ______________________________________________
>> : R-help <at> stat.math.ethz.ch mailing list
>> : https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> : PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>> :
>> :
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From elw at stderr.org  Mon May 31 20:29:52 2004
From: elw at stderr.org (elijah wright)
Date: Mon, 31 May 2004 13:29:52 -0500 (CDT)
Subject: [R] Rmetrics New Built
In-Reply-To: <20040531161852.GA31422@sonny.eddelbuettel.com>
References: <40BADEEA.2000506@itp.phys.ethz.ch>
	<Pine.LNX.4.58.0405310949130.4526@illuminati.stderr.org>
	<20040531161852.GA31422@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.58.0405311306060.3564@illuminati.stderr.org>


> > > If the Linux and Mac OSX builds are successfully done, I will submit
> > > the packages to the CRAN server.
> >
> > all four of the packages successfully build on Debian unstable - no
> > errors, nor warnings.  this is a Good Thing.  I would guesstimate that
>
> Ah, thanks, good to know. Did you try 'R CMD check' too, for good
> measure?


good idea.  doing that reveals the following.  dirk, most of this is for
your reference as a repackager, so that you know what dependencies will
have to be met for useful debian packages.  :)  there are also some
problems that become evident with the packages...

1) fBasics requires package "date"

after i fixed the date package dependency, i get this error from R check:

Running examples in fBasics-Ex.R failed.
The error most likely occurred in:

> ### * B1-ghypDistribution
>
> flush(stderr()); flush(stdout())



2) fExtremes requires packages "evd" and "ismev"

after fixing those two dependencies, R CMD check produces the following
output:

* checking S3 generic/method consistency ... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :
        .First.lib failed
Execution halted
* checking for replacement functions with final arg not named 'value' ...
WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :
        .First.lib failed
Execution halted
* checking foreign function calls ... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :
        .First.lib failed
Execution halted
* checking Rd files ... WARNING
Rd files with non-standard keywords:
  'man/C3-gpdglmFit.Rd': fExtremes
  'man/C1-gpdFamily.Rd': fExtremes
  'man/C6-rlargFit.Rd': fExtremes
  'man/C5-ppFit.Rd': fExtremes
  'man/B1-gevFamily.Rd': fExtremes
  'man/Z1-fExtremesTools.Rd': fExtremes
  'man/B4-mdaPlots.Rd': fExtremes
  'man/B2-gevFit.Rd': fExtremes
  'man/D1-exindexPlots.Rd': fExtremes
  'man/C4-potFit.Rd': fExtremes
  'man/A2-getExtremes.Rd': fExtremes
  'man/B3-gevglmFit.Rd': fExtremes
  'man/A1-evPlots.Rd': fExtremes
  'man/C2-gpdFit.Rd': fExtremes
Each '\keyword' entry should specify one of the standard keywords (as
listed in file 'KEYWORDS.db' in the 'doc' subdirectory of the R home
directory).
See chapter 'Writing R documentation files' in manual 'Writing R
Extensions'.
* checking for missing documentation entries ... ERROR
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :




3) fOptions documentation needs work?

* checking Rd files ... WARNING
Rd files with non-standard keywords:
  'man/D2-MonteCarloOptions.Rd': fOptions
  'man/C2-HestonNandiOptions.Rd': fOptions
  'man/B2-MultAssetsOptions.Rd': fOptions
  'man/B5-BinaryOptions.Rd': fOptions
  'man/C1-hngarchFit.Rd': fOptions
  'man/A2-BasicAmericanOptions.Rd': fOptions
  'man/Z1-fOptionsTools.Rd': fOptions
  'man/B1-MultExercisesOptions.Rd': fOptions
  'man/D1-LowDiscrepancy.Rd': fOptions
  'man/B3-LookbackOptions.Rd': fOptions
  'man/A3-BinomialTreeOptions.Rd': fOptions
  'man/B6-AsianOptions.Rd': fOptions
  'man/B4-BarrierOptions.Rd': fOptions
  'man/A1-PlainVanillaOptions.Rd': fOptions
  'man/B7-FXTransOptions.Rd': fOptions
Each '\keyword' entry should specify one of the standard keywords (as
listed in file 'KEYWORDS.db' in the 'doc' subdirectory of the R home
directory).


4) fSeries:

Packages required but not available:
  mda polspline


fixed these dependencies on my local system - no biggie - then from R
CMD check got:

* checking S3 generic/method consistency ... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :
        .First.lib failed
Execution halted
* checking for replacement functions with final arg not named 'value' ...
WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :
        .First.lib failed
Execution halted
* checking foreign function calls ... WARNING
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :
        .First.lib failed
Execution halted
* checking Rd files ... WARNING
Rd files with non-standard keywords:
  'man/D1-fSeriesData.Rd': fSeries
  'man/Z1-fSeriesTools.Rd': fSeries
  'man/B2-lmTests.Rd': fSeries
  'man/B1-regressionModelling.Rd': fSeries
  'man/C3-rollingAnalysis.Rd': fSeries
  'man/A4-randomInnovations.Rd': fSeries
  'man/A3-garchModelling.Rd': fSeries
  'man/C2-benchmarkAnalysis.Rd': fSeries
  'man/A2-armaStatistics.Rd': fSeries
  'man/A1-armaModelling.Rd': fSeries
  'man/A5-tseriesTests.Rd': fSeries
  'man/C1-technicalAnalysis.Rd': fSeries
Each '\keyword' entry should specify one of the standard keywords (as
listed in file 'KEYWORDS.db' in the 'doc' subdirectory of the R home
directory).
See chapter 'Writing R documentation files' in manual 'Writing R
Extensions'.
* checking for missing documentation entries ... ERROR
Error in .tryQuietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :



methinks that some things may not be quite right just yet - even though
the builds of individual packages complete successfully.

Diethelm, consider this an extended bug report...  :)


> > they should build trivially on OSX as well, but i'm at home today [in
> > the US, today is Memorial day - a sort of low-key holiday when people
> > tend to have picnics and things] and have no intention of driving to
> > campus...
> >
> > maybe you can sucker Dirk into packaging them for Debian and getting
> > them into the system there?  :)
>
> That has of course been the plan all along, for both Debian and
> Quantian.

hooray!  i'm sure many people are glad to hear this.

> I'm a little behind on a few other things, but knowing that these build
> out of the box may well move them up the priority queue :)

it looks like the emergent issues may be the same across the four
packages.  perhaps Diethelm has thoughts?

thanks,

elijah



From grr at grell.mailshell.com  Mon May 31 20:43:39 2004
From: grr at grell.mailshell.com (grr@grell.mailshell.com)
Date: Mon, 31 May 2004 11:43:39 -0700
Subject: [R] Putting referenced titles on plots
In-Reply-To: <40BB6D44.7060409@pdf.com>
References: <Pine.LNX.4.44.0405160721140.32514-100000@gannet.stats>
	<20040531164428.9755.qmail@mailshell.com>
	<40BB6D44.7060409@pdf.com>
Message-ID: <20040531184413.7496.qmail@mailshell.com>

Thank you both for the help. The below 1. works for me, too, both 
cases. I am not actually using "names" as an object name. I am writing:

	for (i in 2:nrow(ctxheadlogtrans)){hist(ctxheadlogtrans[,i], br=100, 
main=gene.names.head[i])}

which gives me histograms titled "1", "2", "3", etc. But:

	gene.names.head[1]

gives me "1007_s_at", and 	

	gene.names.head[2]

gives me "1053_at" and

	for (i in 2:5){print(gene.names.head[i])}

gives me a list of the titles I want.

I am using RAqua 1.8.1 on Mac OS X.

Is there something I am missing?

Thanks,

Graham

On May 31, 2004, at 10:37 AM, Spencer Graves wrote:

>      1.  That seems strange.  The following simplification of your 
> function produced sensible results for me:
>             hist(1:4, main= "1098_s_at")
>
>      I got similar results from your exact statement after first 
> defining names and ctx as follows:
>      names <- letters[1:3]
>      ctx <- data.frame(x=1:4, y=1:4, a=1:4)
>
>      In each case, I got a histogram with a standard text title at the 
> top.  What version of R are you running?  If it's NOT R 1.9.0pat, you 
> might try upgrading -- and then running "update.packages()".
>      2. "names" is that name of a function, and it is generally 
> considered bad practice to mask function names with names of other 
> objects, even though R can often (though not always) determine which 
> object you want from the context.  What do you get from "conflicts()"?
>      hope this helps.  spencer graves
>
> grr at grell.mailshell.com wrote:
>
>> I have a data frame "ctx" and an array "names", where names[i] is the 
>> column name for ctx[i], and am making histograms for each column of 
>> ctx:
>>
>> for (i in 2:ncol(ctx)){hist(ctx[,i], br=100, main=names[i])}
>>
>> The titles don't come out like I expect. Each names[i] is something 
>> like "1098_s_at" and R doesn't seem to like printing these. Instead, 
>> it prints "1" or "2" or "3" etc.
>>
>> I have also tried binding ctx and names into a single data frame and 
>> referencing the first row of each [i] as the title, but I get the 
>> same result.
>>
>> Can someone tell me how to get these titles attached?
>>
>> Thanks,
>>
>> Graham
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://rd.mailshell.com/www.R-project.org/posting-guide.html
>
>
>



From rpeng at jhsph.edu  Mon May 31 20:44:29 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 31 May 2004 14:44:29 -0400
Subject: [R] Putting referenced titles on plots
In-Reply-To: <20040531164428.9755.qmail@mailshell.com>
References: <Pine.LNX.4.44.0405160721140.32514-100000@gannet.stats>
	<20040531164428.9755.qmail@mailshell.com>
Message-ID: <40BB7D0D.3010500@jhsph.edu>

Is `names' by any chance a factor?  What is class(names)?  If 
`names' is a factor, then you're getting the underlying numeric 
representation rather than the factor levels.

-roger

grr at grell.mailshell.com wrote:

> I have a data frame "ctx" and an array "names", where names[i] is the 
> column name for ctx[i], and am making histograms for each column of ctx:
> 
> for (i in 2:ncol(ctx)){hist(ctx[,i], br=100, main=names[i])}
> 
> The titles don't come out like I expect. Each names[i] is something like 
> "1098_s_at" and R doesn't seem to like printing these. Instead, it 
> prints "1" or "2" or "3" etc.
> 
> I have also tried binding ctx and names into a single data frame and 
> referencing the first row of each [i] as the title, but I get the same 
> result.
> 
> Can someone tell me how to get these titles attached?
> 
> Thanks,
> 
> Graham
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From grr at grell.mailshell.com  Mon May 31 21:18:34 2004
From: grr at grell.mailshell.com (grr@grell.mailshell.com)
Date: Mon, 31 May 2004 12:18:34 -0700
Subject: [R] Putting referenced titles on plots
In-Reply-To: <40BB7D0D.3010500@jhsph.edu>
References: <Pine.LNX.4.44.0405160721140.32514-100000@gannet.stats>
	<20040531164428.9755.qmail@mailshell.com>
	<40BB7D0D.3010500@jhsph.edu>
Message-ID: <20040531191839.24230.qmail@mailshell.com>

Yes! Thank you. It is a factor (I don't know how it became a factor). I 
created an array based on the 'names' factor, and can get the titles by 
referencing the new array.

Thanks so much,

Graham

On May 31, 2004, at 11:44 AM, Roger D. Peng wrote:

> Is `names' by any chance a factor?  What is class(names)?  If `names' 
> is a factor, then you're getting the underlying numeric representation 
> rather than the factor levels.
>
> -roger
>
> grr at grell.mailshell.com wrote:
>
>> I have a data frame "ctx" and an array "names", where names[i] is the 
>> column name for ctx[i], and am making histograms for each column of 
>> ctx:
>> for (i in 2:ncol(ctx)){hist(ctx[,i], br=100, main=names[i])}
>> The titles don't come out like I expect. Each names[i] is something 
>> like "1098_s_at" and R doesn't seem to like printing these. Instead, 
>> it prints "1" or "2" or "3" etc.
>> I have also tried binding ctx and names into a single data frame and 
>> referencing the first row of each [i] as the title, but I get the 
>> same result.
>> Can someone tell me how to get these titles attached?
>> Thanks,
>> Graham
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://rd.mailshell.com/www.R-project.org/posting-guide.html
>



From tapo at novozymes.com  Mon May 31 21:25:53 2004
From: tapo at novozymes.com (TAPO (Thomas Agersten Poulsen))
Date: Mon, 31 May 2004 21:25:53 +0200
Subject: [R] Converting data frame to array?
Message-ID: <76F96CFE2AA2114C886B028A065A7FC402074E83@exdkba020.novo.dk>

Dear John,

	Thank you for your helpful answer. I was obviously being stupid,
as I have, as you point out, more predictors than observations.

	What I was hoping to get was some sort of an "explaining linear
combination" of my predictors: which predictors are important for the
results I see (if any) and which are irrelevant. 

	Any hints on how to achieve that?
	
Cheers
Thomas

-----Original Message-----
From: John Fox [mailto:jfox at mcmaster.ca] 
Sent: 29. maj 2004 01:24
To: TAPO (Thomas Agersten Poulsen)
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] Converting data frame to array?


Dear Thomas,

In fact, the more common way to fit a linear regression in R is to use
variables in a data frame (or list) along with a model formula
specifying the model. All of this is explained in the Introduction to R
manual that is distributed with R: see, in particular, Sec. 6.3 on data
frames, Sec. 7 on reading data from files, and Sec. 11 on statistical
models.

Given two data frames, say d1 and d2, the first containing, e.g.,
observations on variables x1 and x2 and the second on y, one could do
lm(y ~ x1 + x2, data=c(x1, x2)) or lm(y ~ x1 + x2, data=data.frame(x1,
x2)). 

That said, it's not altogether clear to me what it is that you're trying
to do. Are there 10 observations on 300 variables in the first data
frame, constituting the predictors, and 10 observations on 1 variable in
the second data frame, constituting the response? If so, you have many
more predictors than observations, and it's not reasonable to perform a
regression. Of course, I may not have this straight.

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of TAPO 
> (Thomas Agersten Poulsen)
> Sent: Friday, May 28, 2004 2:11 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Converting data frame to array?
> 
> Dear List,
> 
> 	Please bear with a poor newbee, who might be doing
> everything backwards (I was brought up in pure math).
> 
> 	I want to make a simple multi-linear regression on a
> set of data. I did some expreiments, and if X is a 4 by 2 
> array and Y is a 4 by
> 1 array, I can do a linear regression by lm(y~x). 
> 
> 	Now I have a tab-delimited text file with 10 rows of
> 300 measurements and an other file with 10 rows of one value 
> each. When I read in those files using read.delim(), I get 
> data frames, and apparently I can no longer do the 
> multi-linear regression.
> 
> 	Is there a way to convert the data frames into arrays,
> or am I going the wrong way about this?
> 
> Sincerely
> Thomas Poulsen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From v.demartino2 at virgilio.it  Mon May 31 21:38:54 2004
From: v.demartino2 at virgilio.it (v.demartino2@virgilio.it)
Date: Mon, 31 May 2004 21:38:54 +0200
Subject: [R] ffnet problem
Message-ID: <4087DF45000CD4F8@ims3e.cp.tin.it>

Context:Linux debian testing, compiled R 1.9.0 from source.

I've just installed the contributed ffnet package wit no problem at all.
But when loading the library the following error message is popping up and
no ffnet command seems to work:

>library("ffnet")
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
	unable to load shared library "/usr/local/lib/R/library/ffnet/libs/ffnet.so":
  libstdc++.so.2.8: cannot open shared object file: No such file or directory
Error in library("ffnet") : .First.lib failed
......................
What should I do?
Ciao
Vittorio



From edd at debian.org  Mon May 31 21:41:21 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 31 May 2004 14:41:21 -0500
Subject: [R] ffnet problem
In-Reply-To: <4087DF45000CD4F8@ims3e.cp.tin.it>
References: <4087DF45000CD4F8@ims3e.cp.tin.it>
Message-ID: <20040531194121.GA990@sonny.eddelbuettel.com>

On Mon, May 31, 2004 at 09:38:54PM +0200, v.demartino2 at virgilio.it wrote:
> Context:Linux debian testing, compiled R 1.9.0 from source.
> 
> I've just installed the contributed ffnet package wit no problem at all.

"No problem at all" seems unlikely in light of ...

> But when loading the library the following error message is popping up and
> no ffnet command seems to work:
> 
> >library("ffnet")
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
> 	unable to load shared library "/usr/local/lib/R/library/ffnet/libs/ffnet.so":
>   libstdc++.so.2.8: cannot open shared object file: No such file or directory
> Error in library("ffnet") : .First.lib failed

... this. Are you sure ffnet really built?

Dirk

-- 
FEATURE:  VW Beetle license plate in California



From joseclaudio.faria at terra.com.br  Mon May 31 21:42:03 2004
From: joseclaudio.faria at terra.com.br (=?iso-8859-1?Q?Jos=E9_Cl=E1udio_Faria?=)
Date: Mon, 31 May 2004 16:42:03 -0300
Subject: [R] Doubts on anova and use of contrasts in multcomp package
Message-ID: <004401c44747$5bf96e60$01fea8c0@sapetinga>

Dear list,

I have been studying R and I would like the aid of more experienced to solve the problems of the analysis below:

r = gl(3, 8, label = c('r1', 'r2', 'r3'))
e = rep(gl(2, 4, label = c('e1', 'e2')), 3)
y = c(26.2, 26.0, 25.0, 25.4, 24.8, 24.6, 26.7, 25.2, 25.7, 26.3, 25.1, 26.4,
      19.6, 21.1, 19.0, 18.6, 22.8, 19.4, 18.8, 19.2, 19.8, 21.4, 22.8, 21.3)

df = data.frame(r, e, y)

aux = sort(rep(letters[1:6], 4))  #auxiliary variable

df = data.frame(df, aux)

  attach(df)
    par(mfrow = c(2, 1))
    interaction.plot(r, e, y, col = 'blue', ylab = 'y', xlab = 'r')

    interaction.plot(e, r, y, col = 'blue', ylab = 'y', xlab = 'r')

    av1 = aov(y ~ r*e)

    av2 = aov(y ~ r/e)
    efR_E = summary(av2, split = list('r:e' = list(
                                    'e1 vs e2/r1' = 1, 'e1 vs e2/r2' = 2,
                                    'e1 vs e2/r3' = 3)))

    av3  = aov(y ~ e/r)
    efE_R = summary(av3, split = list('e:r' = list(
                                    'r/e1' = c(1,3), 'r/e2' = c(2,4))))

    mds = model.tables(av1, ty = 'means')
  detach(df)

   cat('\nData:'); cat('\n')
   print(df)

   cat('\nMeans:'); cat('\n')
   print(mds)

   cat('\nANOVA:'); cat('\n')
   print(summary(av1)); cat('\n')

   cat('\nANOVA - E effect in R levels:'); cat('\n')
   print(efR_E); cat('\n')

   cat('\nANOVA - R effect in E levels:'); cat('\n')
  print(efE_R); cat('\n')

#===Below: my original intention (post in this list and still not answered...)

# ANOVA - R effect in E levels:
#----------------------------------------------
#                              Df
#   e                           1
#  e:r                          4
#    e:r: r/e1               2
#      r1 vs (r2,r3)/e1 1    ?...
#      r2 vs r3/e1        1    ?...
#    e:r: r/e2               2
#      r1 vs (r2,r3)/e1 1    ?...
#      r2 vs r3/e2        1    ?...
#----------------------------------------------
#Residuals             18
#----------------------------------------------

#===Below: alternative using multcomp
# (with auxiliary variable - aux) to study R effect in E levels:

# a: r1/e1
# c: r2/e1
# e: r3/e1

# b: r1/e2
# d: r2/e2
# f: r3/e2

           #a   b   c   d    e   f
C1 = c(2,  0, -1,  0, -1,  0)    # r1 vs (r2,r3)/e1
C2 = c(0,  0,  1,  0, -1,  0)    # r2 vs r3/e1
C3 = c(0,  2,  0, -1,  0, -1)    # r1 vs (r2,r3)/e2
C4 = c(0,  0,  0,  1,  0, -1)    # r2 vs r3/e2

C = rbind(C1, C2, C3, C4)
row.names(C) = c('r1 vs (r2,r3)/e1', 'r2 vs r3/e1',
                                'r1 vs (r2,r3)/e2', 'r2 vs r3/e2')

lim1 = lm(y ~ aux, data = df)
print(anova(lim1))

tc1 = simtest(y ~ aux, data = df, conf.level = 0.9,
                       alternative = 'less', eps = 1e-04, cmatrix = C)
print(summary(tc1))

#===Below: verifying E effect in R levels (already analized in av2)
# (with auxiliary variable - aux)

# a: e1/r1
# c: e1/r2
# e: e1/r3

# b: e2/r1
# d: e2/r2
# f: e2/r3

           #a   b   c   d   e    f
C1 = c(1, -1,  0,  0,  0,  0)    # e1 vs e2/r1
C2 = c(0,  0,  1, -1,  0,  0)    # e1 vs e2/r2
C3 = c(0,  0,  0,  0,  1, -1)    # e1 vs e2/r3

C = rbind(C1, C2, C3)
row.names(C) = c('e1 vs e2/r1', 'e1 vs e2/r2', 'e1 vs e2/r3')

lim2 = lm(y ~ aux, data = df)
print(anova(lim2))

tc2 = simtest(y ~ aux, data = df, conf.level = 0.9,
              alternative = 'less', eps = 1e-04, cmatrix = C)
print(summary(tc2))

#===My Questions:
# a) Is possible the resolution of the original intention? How?
# b) Why p-values of soluctions av2 and lim2 dont agree?
# c) Are there another better way to lead of this analysis?
#===================================================================

Best regards,

Jos?? Cl??udio Faria
UESC/DCET
Brasil
73-634.2779
joseclaudio.faria at terra.com.br
jc_faria at uol.com.br



From chrysopa at insecta.ufv.br  Mon May 31 21:50:08 2004
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Mon, 31 May 2004 16:50:08 -0300
Subject: [R] Help on parameters
Message-ID: <200405311650.09074.chrysopa@insecta.ufv.br>

Hi,

I have a follow analysis

Trat1 = quantitative variable
Trat2 = qualitative variable with 3 levels (A, B, C)
Trat3 = qualitative variable with 3 levels (D, E, F)
Resp = Response

I try to get the parameters to compare with zero, so I make this model:

glm(Resp~Trat1*Trat2+Trat1*Trat3-Trat1-1)

The -Trat1 is to make comparison of slope with zero.
The -1 is to make comparison os intercept with zero.

The results that I want are:

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
Trat2A        
Trat2B        
Trat2C        
Trat3D
Trat3E        
Trat3F        
Trat1:Trat2A  
Trat1:Trat2B  
Trat1:Trat2C 
Trat1:Trat3D
Trat1:Trat3E 
Trat1:Trat3F 

But I get this:

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
Trat2A        1.35333    1.00307   1.349  0.18108    
Trat2B        1.35333    1.00307   1.349  0.18108    
Trat2C        4.29333    1.00307   4.280 5.14e-05 ***
Trat3E        0.86667    1.09881   0.789  0.43260    
Trat3F        0.92000    1.09881   0.837  0.40493    
Trat1:Trat2A  0.53657    0.16166   3.319  0.00136 ** 
Trat1:Trat2B  0.53657    0.16166   3.319  0.00136 ** 
Trat1:Trat2C -0.09313    0.16166  -0.576  0.56617    
Trat1:Trat3E  0.03636    0.17709   0.205  0.83783    
Trat1:Trat3F  0.34000    0.17709   1.920  0.05843 .  

Look that the intercept and slope of Trat3D dont appear

What is the problem?

Thanks
Ronaldo
-- 
How can you think and hit at the same time?
		-- Yogi Berra
--
|>   // | \\   [***********************************]
|   ( ??   ?? )  [Ronaldo Reis J??nior                ]
|>      V      [UFV/DBA-Entomologia                ]
|    /     \   [36571-000 Vi??osa - MG              ]
|>  /(.''`.)\  [Fone: 31-3899-2532                 ]
|  /(: :'  :)\ [chrysopa at insecta.ufv.br            ]
|>/ (`. `'` ) \[ICQ#: 5692561 | LinuxUser#: 205366 ]
|    ( `-  )   [***********************************]
|>>  _/   \_Powered by GNU/Debian Woody/Sarge



From spencer.graves at pdf.com  Mon May 31 21:48:39 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 31 May 2004 12:48:39 -0700
Subject: [R] Converting data frame to array?
In-Reply-To: <76F96CFE2AA2114C886B028A065A7FC402074E83@exdkba020.novo.dk>
References: <76F96CFE2AA2114C886B028A065A7FC402074E83@exdkba020.novo.dk>
Message-ID: <40BB8C17.6010107@pdf.com>

      stepAIC in library(MASS) or "step"? 

      hope this helps.  spencer graves

TAPO (Thomas Agersten Poulsen) wrote:

>Dear John,
>
>	Thank you for your helpful answer. I was obviously being stupid,
>as I have, as you point out, more predictors than observations.
>
>	What I was hoping to get was some sort of an "explaining linear
>combination" of my predictors: which predictors are important for the
>results I see (if any) and which are irrelevant. 
>
>	Any hints on how to achieve that?
>	
>Cheers
>Thomas
>
>-----Original Message-----
>From: John Fox [mailto:jfox at mcmaster.ca] 
>Sent: 29. maj 2004 01:24
>To: TAPO (Thomas Agersten Poulsen)
>Cc: r-help at stat.math.ethz.ch
>Subject: RE: [R] Converting data frame to array?
>
>
>Dear Thomas,
>
>In fact, the more common way to fit a linear regression in R is to use
>variables in a data frame (or list) along with a model formula
>specifying the model. All of this is explained in the Introduction to R
>manual that is distributed with R: see, in particular, Sec. 6.3 on data
>frames, Sec. 7 on reading data from files, and Sec. 11 on statistical
>models.
>
>Given two data frames, say d1 and d2, the first containing, e.g.,
>observations on variables x1 and x2 and the second on y, one could do
>lm(y ~ x1 + x2, data=c(x1, x2)) or lm(y ~ x1 + x2, data=data.frame(x1,
>x2)). 
>
>That said, it's not altogether clear to me what it is that you're trying
>to do. Are there 10 observations on 300 variables in the first data
>frame, constituting the predictors, and 10 observations on 1 variable in
>the second data frame, constituting the response? If so, you have many
>more predictors than observations, and it's not reasonable to perform a
>regression. Of course, I may not have this straight.
>
>I hope this helps,
> John
>
>  
>
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of TAPO 
>>(Thomas Agersten Poulsen)
>>Sent: Friday, May 28, 2004 2:11 PM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] Converting data frame to array?
>>
>>Dear List,
>>
>>	Please bear with a poor newbee, who might be doing
>>everything backwards (I was brought up in pure math).
>>
>>	I want to make a simple multi-linear regression on a
>>set of data. I did some expreiments, and if X is a 4 by 2 
>>array and Y is a 4 by
>>1 array, I can do a linear regression by lm(y~x). 
>>
>>	Now I have a tab-delimited text file with 10 rows of
>>300 measurements and an other file with 10 rows of one value 
>>each. When I read in those files using read.delim(), I get 
>>data frames, and apparently I can no longer do the 
>>multi-linear regression.
>>
>>	Is there a way to convert the data frames into arrays,
>>or am I going the wrong way about this?
>>
>>Sincerely
>>Thomas Poulsen
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list 
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From jfox at mcmaster.ca  Mon May 31 21:57:22 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 31 May 2004 15:57:22 -0400
Subject: [R] Converting data frame to array?
In-Reply-To: <76F96CFE2AA2114C886B028A065A7FC402074E83@exdkba020.novo.dk>
Message-ID: <20040531195721.BCHU14757.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Thomas,

I doubt whether there's anything useful that you can do with 300 predictors
and only 10 observations. A na??ve application of variable selection will
likely allow you to account perfectly for the variation in the response
variable just by capitalizing on chance.

John 

> -----Original Message-----
> From: TAPO (Thomas Agersten Poulsen) [mailto:tapo at novozymes.com] 
> Sent: Monday, May 31, 2004 2:26 PM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Converting data frame to array?
> 
> Dear John,
> 
> 	Thank you for your helpful answer. I was obviously 
> being stupid, as I have, as you point out, more predictors 
> than observations.
> 
> 	What I was hoping to get was some sort of an 
> "explaining linear combination" of my predictors: which 
> predictors are important for the results I see (if any) and 
> which are irrelevant. 
> 
> 	Any hints on how to achieve that?
> 	
> Cheers
> Thomas
> 
> -----Original Message-----
> From: John Fox [mailto:jfox at mcmaster.ca]
> Sent: 29. maj 2004 01:24
> To: TAPO (Thomas Agersten Poulsen)
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Converting data frame to array?
> 
> 
> Dear Thomas,
> 
> In fact, the more common way to fit a linear regression in R is to use
> variables in a data frame (or list) along with a model formula
> specifying the model. All of this is explained in the 
> Introduction to R
> manual that is distributed with R: see, in particular, Sec. 
> 6.3 on data
> frames, Sec. 7 on reading data from files, and Sec. 11 on statistical
> models.
> 
> Given two data frames, say d1 and d2, the first containing, e.g.,
> observations on variables x1 and x2 and the second on y, one could do
> lm(y ~ x1 + x2, data=c(x1, x2)) or lm(y ~ x1 + x2, data=data.frame(x1,
> x2)). 
> 
> That said, it's not altogether clear to me what it is that 
> you're trying
> to do. Are there 10 observations on 300 variables in the first data
> frame, constituting the predictors, and 10 observations on 1 
> variable in
> the second data frame, constituting the response? If so, you have many
> more predictors than observations, and it's not reasonable to 
> perform a
> regression. Of course, I may not have this straight.
> 
> I hope this helps,
>  John
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of TAPO 
> > (Thomas Agersten Poulsen)
> > Sent: Friday, May 28, 2004 2:11 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Converting data frame to array?
> > 
> > Dear List,
> > 
> > 	Please bear with a poor newbee, who might be doing
> > everything backwards (I was brought up in pure math).
> > 
> > 	I want to make a simple multi-linear regression on a
> > set of data. I did some expreiments, and if X is a 4 by 2 
> > array and Y is a 4 by
> > 1 array, I can do a linear regression by lm(y~x). 
> > 
> > 	Now I have a tab-delimited text file with 10 rows of
> > 300 measurements and an other file with 10 rows of one value 
> > each. When I read in those files using read.delim(), I get 
> > data frames, and apparently I can no longer do the 
> > multi-linear regression.
> > 
> > 	Is there a way to convert the data frames into arrays,
> > or am I going the wrong way about this?
> > 
> > Sincerely
> > Thomas Poulsen
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
>



From v.demartino2 at virgilio.it  Mon May 31 22:38:37 2004
From: v.demartino2 at virgilio.it (v.demartino2@virgilio.it)
Date: Mon, 31 May 2004 22:38:37 +0200
Subject: [R] ffnet problem
In-Reply-To: <20040531194121.GA990@sonny.eddelbuettel.com>
Message-ID: <4087DF45000CD8E9@ims3e.cp.tin.it>


>> 
>> I've just installed the contributed ffnet package wit no problem at all.
>
>"No problem at all" seems unlikely in light of ...

Dirk,

You're right! 
Here you are what happened:

desktop:/tmp# R INSTALL -l /usr/local/lib/R/library ffnet/
* Installing *source* package 'ffnet' ...
** libs
make: Nothing to be done for `all'.
** R
** help
 >>> Building/Updating help pages for package 'ffnet'
     Formats: text html latex example
......................................................
......................................................

And  the compilation of ffnet commands kept going on as though  there had
been no problems.... This was somewhat misleading to a newbye!!

Anyway, what steps should I take now?

Ciao
Vittorio



From wuertz at itp.phys.ethz.ch  Mon May 31 23:40:40 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Mon, 31 May 2004 21:40:40 +0000
Subject: [R] Rmetrics New Built
In-Reply-To: <Pine.LNX.4.58.0405311306060.3564@illuminati.stderr.org>
References: <40BADEEA.2000506@itp.phys.ethz.ch>
	<Pine.LNX.4.58.0405310949130.4526@illuminati.stderr.org>
	<20040531161852.GA31422@sonny.eddelbuettel.com>
	<Pine.LNX.4.58.0405311306060.3564@illuminati.stderr.org>
Message-ID: <40BBA658.7010604@itp.phys.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040531/c605814e/attachment.pl

